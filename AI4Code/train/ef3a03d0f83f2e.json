{"cell_type":{"f5b0df5d":"code","04bdd0bf":"code","ca1efe9c":"code","f129be03":"code","a39e28a3":"code","c2901306":"code","cf17facc":"code","6c10759d":"code","87c3fa6b":"code","8d46acb2":"code","dd919b07":"code","42f05632":"code","5c1285aa":"code","b2d37b2f":"code","c2517140":"markdown","1c5c9413":"markdown","3c07eaaf":"markdown","1bc4b86e":"markdown","ffc819bb":"markdown","9313d965":"markdown","a853fb87":"markdown","b4214ff4":"markdown","d9f86923":"markdown"},"source":{"f5b0df5d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n%matplotlib inline\nimport seaborn as sns","04bdd0bf":"# For iPlot graphs in Google Colab\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\n\ninit_notebook_mode(connected=True) # For Notebooks\ncf.go_offline() # For offline use","ca1efe9c":"dataset = pd.read_csv(\"..\/input\/classificationdata\/Social_Network_Ads.csv\")","f129be03":"dataset.head()","a39e28a3":"dataset.describe()","c2901306":"X = dataset.iloc[:,2:4].values\ny = dataset.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train)\nX_test = sc_x.transform(X_test)\n\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(X_train,y_train)\n\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nfig, (ax1, ax2) =  plt.subplots(1, 2, figsize=(20,10))\n# X1=age, X2=estimated salary\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax1.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax1.set_xlim(X1.min(), X1.max())\nax1.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax1.set_title('Logistic Regression Classifier (Training set)')\nax1.set_xlabel('Age')\nax1.set_ylabel('Estimated Salary')\nax1.legend()\n\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax2.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax2.set_xlim(X1.min(), X1.max())\nax2.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax2.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax2.set_title('Logistic Regression Classifier (Test set)')\nax2.set_xlabel('Age')\nax2.set_ylabel('Estimated Salary')\nax2.legend()\n\nplt.show()","cf17facc":"from sklearn.metrics import roc_curve,auc\nfrom sklearn.metrics import roc_auc_score\n\nlr_probs = classifier.predict_proba(X_test)\n#max(set(list(y_test)), key=list(y_test).count) => max occuring element\nns_probs = [max(set(list(y_test)), key=list(y_test).count) for _ in range(len(y_test))]\n\nns_auc = roc_auc_score(y_test, ns_probs)\nlr_auc = roc_auc_score(y_test, lr_probs[:,1])\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs[:,1])\n# plot the roc curve for the model\nplt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill: ROC AUC=%.3f' % (ns_auc))\nplt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic: ROC AUC=%.3f' % (lr_auc))\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","6c10759d":"dataset = pd.read_csv(\"..\/input\/classificationdata\/Social_Network_Ads.csv\")\ndataset.head()\n\nX = dataset.iloc[:,2:4].values\ny = dataset.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train)\nX_test = sc_x.transform(X_test)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=5)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nfig, (ax1, ax2) =  plt.subplots(1, 2, figsize=(20,10))\n# X1=age, X2=estimated salary\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax1.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax1.set_xlim(X1.min(), X1.max())\nax1.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax1.set_title('KNN Classifier (Training set)')\nax1.set_xlabel('Age')\nax1.set_ylabel('Estimated Salary')\nax1.legend()\n\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax2.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax2.set_xlim(X1.min(), X1.max())\nax2.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax2.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax2.set_title('KNN Classifier (Test set)')\nax2.set_xlabel('Age')\nax2.set_ylabel('Estimated Salary')\nax2.legend()\n\nplt.show()","87c3fa6b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n%matplotlib inline\nimport seaborn as sns\n\ndataset = pd.read_csv(\"..\/input\/classificationdata\/Social_Network_Ads.csv\")\ndataset.head()\n\nX = dataset.iloc[:,2:4].values\ny = dataset.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train)\nX_test = sc_x.transform(X_test)\n\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='rbf', random_state=0)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nfig, (ax1, ax2) =  plt.subplots(1, 2, figsize=(20,10))\n# X1=age, X2=estimated salary\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax1.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax1.set_xlim(X1.min(), X1.max())\nax1.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax1.set_title('SVM Classifier (Training set)')\nax1.set_xlabel('Age')\nax1.set_ylabel('Estimated Salary')\nax1.legend()\n\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax2.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax2.set_xlim(X1.min(), X1.max())\nax2.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax2.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax2.set_title('SVM Classifier(Test set)')\nax2.set_xlabel('Age')\nax2.set_ylabel('Estimated Salary')\nax2.legend()\n\nplt.show()","8d46acb2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n%matplotlib inline\nimport seaborn as sns\n\ndataset = pd.read_csv(\"..\/input\/classificationdata\/Social_Network_Ads.csv\")\ndataset.head()\n\nX = dataset.iloc[:,2:4].values\ny = dataset.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train)\nX_test = sc_x.transform(X_test)\n\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nfig, (ax1, ax2) =  plt.subplots(1, 2, figsize=(20,10))\n# X1=age, X2=estimated salary\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax1.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax1.set_xlim(X1.min(), X1.max())\nax1.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax1.set_title('Naive Bayes Classifier (Training set)')\nax1.set_xlabel('Age')\nax1.set_ylabel('Estimated Salary')\nax1.legend()\n\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax2.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax2.set_xlim(X1.min(), X1.max())\nax2.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax2.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax2.set_title('Naive Bayes Classifier(Test set)')\nax2.set_xlabel('Age')\nax2.set_ylabel('Estimated Salary')\nax2.legend()\n\nplt.show()","dd919b07":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n%matplotlib inline\nimport seaborn as sns\n\ndataset = pd.read_csv(\"..\/input\/classificationdata\/Social_Network_Ads.csv\")\ndataset.head()\n\nX = dataset.iloc[:,2:4].values\ny = dataset.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train)\nX_test = sc_x.transform(X_test)\n\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion='entropy',random_state=0)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nfig, (ax1, ax2) =  plt.subplots(1, 2, figsize=(20,10))\n# X1=age, X2=estimated salary\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax1.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax1.set_xlim(X1.min(), X1.max())\nax1.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax1.set_title('Decision Tree Classifier (Training set)')\nax1.set_xlabel('Age')\nax1.set_ylabel('Estimated Salary')\nax1.legend()\n\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax2.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax2.set_xlim(X1.min(), X1.max())\nax2.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax2.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax2.set_title('Decision Tree Classifier(Test set)')\nax2.set_xlabel('Age')\nax2.set_ylabel('Estimated Salary')\nax2.legend()\n\nplt.show()","42f05632":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n%matplotlib inline\nimport seaborn as sns\n\ndataset = pd.read_csv(\"..\/input\/classificationdata\/Social_Network_Ads.csv\")\ndataset.head()\n\nX = dataset.iloc[:,2:4].values\ny = dataset.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train)\nX_test = sc_x.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nfig, (ax1, ax2) =  plt.subplots(1, 2, figsize=(20,10))\n# X1=age, X2=estimated salary\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax1.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax1.set_xlim(X1.min(), X1.max())\nax1.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax1.set_title('Random Forest Classifier (Training set)')\nax1.set_xlabel('Age')\nax1.set_ylabel('Estimated Salary')\nax1.legend()\n\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax2.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax2.set_xlim(X1.min(), X1.max())\nax2.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax2.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax2.set_title('Random Forest Classifier(Test set)')\nax2.set_xlabel('Age')\nax2.set_ylabel('Estimated Salary')\nax2.legend()\n\nplt.show()","5c1285aa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n%matplotlib inline\nimport seaborn as sns\n\ndataset = pd.read_csv(\"..\/input\/classificationdata\/Social_Network_Ads.csv\")\ndataset.head()\n\nX = dataset.iloc[:,2:4].values\ny = dataset.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train)\nX_test = sc_x.transform(X_test)\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nclassifier = LinearDiscriminantAnalysis()\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nfig, (ax1, ax2) =  plt.subplots(1, 2, figsize=(20,10))\n# X1=age, X2=estimated salary\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax1.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax1.set_xlim(X1.min(), X1.max())\nax1.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax1.set_title('LDA Classifier (Training set)')\nax1.set_xlabel('Age')\nax1.set_ylabel('Estimated Salary')\nax1.legend()\n\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax2.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax2.set_xlim(X1.min(), X1.max())\nax2.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax2.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax2.set_title('LDA Classifier(Test set)')\nax2.set_xlabel('Age')\nax2.set_ylabel('Estimated Salary')\nax2.legend()\n\nplt.show()","b2d37b2f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n%matplotlib inline\nimport seaborn as sns\n\ndataset = pd.read_csv(\"..\/input\/classificationdata\/Social_Network_Ads.csv\")\ndataset.head()\n\nX = dataset.iloc[:,2:4].values\ny = dataset.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = sc_x.fit_transform(X_train)\nX_test = sc_x.transform(X_test)\n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nclassifier = QuadraticDiscriminantAnalysis()\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nfig, (ax1, ax2) =  plt.subplots(1, 2, figsize=(20,10))\n# X1=age, X2=estimated salary\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax1.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax1.set_xlim(X1.min(), X1.max())\nax1.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax1.set_title('QDA Classifier (Training set)')\nax1.set_xlabel('Age')\nax1.set_ylabel('Estimated Salary')\nax1.legend()\n\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nax2.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.3, cmap = ListedColormap(('red', 'green')))\nax2.set_xlim(X1.min(), X1.max())\nax2.set_ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    ax2.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nax2.set_title('QDA Classifier(Test set)')\nax2.set_xlabel('Age')\nax2.set_ylabel('Estimated Salary')\nax2.legend()\n\nplt.show()","c2517140":"* **Another method of model performance Evaluation - ROC Curve**","1c5c9413":"# **7. Linear Discriminant Analysis Classification**","3c07eaaf":"# **5. Decision Tree Classifier**","1bc4b86e":"# **8. Quadratic Discriminant Analysis Classification**","ffc819bb":"# **2. K-NN classifier**","9313d965":"# **1. Logistic Regression Classification**","a853fb87":"# **3. Support Vector Machines**","b4214ff4":"# **6. Random Forests Classification**","d9f86923":"# **4. Naive Bayes**"}}