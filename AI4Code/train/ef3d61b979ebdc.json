{"cell_type":{"c5218c4d":"code","e2a8f307":"code","23f24e87":"code","99d46367":"code","a88a6b46":"code","51991dd4":"code","61ddbdf8":"code","109a658b":"code","bb29c03f":"code","2153a55d":"code","4638a176":"code","866de320":"code","f760c6bb":"code","7b8cb6ad":"code","4d68bff9":"code","7f0ba0fc":"code","ccc2c513":"code","8126de76":"code","eaf2e97a":"code","3259fa80":"code","b9d9f1df":"code","a2807397":"code","d7b47888":"code","b055afdc":"code","17fbee61":"code","02078630":"code","8817d18e":"code","07b18772":"code","b47e160e":"code","f1137c09":"code","f24fcd61":"code","0741ccbc":"code","5cda8754":"code","aac0a4fc":"code","281b8d41":"code","91d701fc":"code","0d94ae6d":"markdown","e5160e7a":"markdown","eacbdebf":"markdown","3e1d3bce":"markdown","f2be50ee":"markdown","ac261d62":"markdown","2de3b4db":"markdown","807fb080":"markdown","84250c32":"markdown","811aa0e1":"markdown","3d24279f":"markdown","3382ca03":"markdown","1f88bdce":"markdown","47f2334c":"markdown","2d8aa1f4":"markdown","c4436ae4":"markdown","07b132f0":"markdown","5502386d":"markdown","471891f5":"markdown","cd2c894e":"markdown"},"source":{"c5218c4d":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pandas_profiling import ProfileReport\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM, GRU\nfrom keras.layers import Dropout\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import load_model\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nimport itertools\nimport random\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e2a8f307":"data =  pd.read_csv('..\/input\/stellar-cryptocurrency-dataset\/XLM-USD-Daily-09.15.14-10.30.21.csv',parse_dates=['Date'],infer_datetime_format=True, header=0)","23f24e87":"data.head()","99d46367":"print(data.columns)\nprint(data.shape)","a88a6b46":"data.iloc[:, 1:].describe()","51991dd4":"data.info()","61ddbdf8":"data[data[\"Open\"].isna()]","109a658b":"data=data.dropna()\ndata.shape","bb29c03f":"data.reset_index(drop=True, inplace=True)","2153a55d":"data[data[\"Open\"].isna()]","4638a176":"profile = ProfileReport(data)","866de320":"profile","f760c6bb":"data_prices = data.drop(['Date'], axis=1)\ndata_prices.head(10)","7b8cb6ad":"plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n\nplt.plot(data['Date'], data_prices['Open'], color='red', label = 'Opening Price')\nplt.plot(data['Date'], data_prices['Close'], color='green', label = 'Closing Price')\nplt.plot(data['Date'], data_prices['Low'], color='black', label = 'Low Price')\nplt.plot(data['Date'], data_prices['High'], color='blue', label = 'High Price')\nplt.plot(data['Date'], data_prices['Adj Close'], color='purple', label = 'High Price')\nplt.plot(data['Date'], data_prices['Volume'], color='orange', label = 'High Price')\nplt.legend(loc='best')\n\nplt.subplots(3, 2, figsize = (20, 24))\n\nax1 = plt.subplot(3, 2, 1)\nplt.plot(data['Date'], data_prices['Open'], color='red')\nplt.xlabel('Date')\nplt.ylabel('Opening Price')\n\nax2 = plt.subplot(3, 2, 2)\nplt.plot(data['Date'], data_prices['Close'], color='green')\nplt.xlabel('Date')\nplt.ylabel('Closing Price')\n\nax3 = plt.subplot(3, 2, 3)\nplt.plot(data['Date'], data_prices['Low'], color='black')\nplt.xlabel('Date')\nplt.ylabel('Low Price')\n\nax4 = plt.subplot(3, 2, 4)\nplt.plot(data['Date'], data_prices['High'], color='blue')\nplt.xlabel('Date')\nplt.ylabel('High Price')\n\nax4 = plt.subplot(3, 2, 5)\nplt.plot(data['Date'], data_prices['Adj Close'], color='purple')\nplt.xlabel('Date')\nplt.ylabel('Adjusted Close Price')\n\nax4 = plt.subplot(3, 2, 6)\nplt.plot(data['Date'], data_prices['Volume'], color='orange')\nplt.xlabel('Date')\nplt.ylabel('Volume')\n\nplt.legend(loc='best')","4d68bff9":"data_prices_for_prediction = data_prices[['Open', 'Volume']]","7f0ba0fc":"data_prices_for_prediction.shape","ccc2c513":"data_prices_for_prediction.head(10)","8126de76":"# Feature Scaling\nsc = MinMaxScaler(feature_range=(0, 1))\ndata_prices_scaled = sc.fit_transform(data_prices_for_prediction)","eaf2e97a":"data_prices_scaled.shape","3259fa80":"data_prices_scaled[:10, :]","b9d9f1df":"# Creating a data structure (it does not work when you have only one feature)\ndef create_data(df, n_future, n_past, train_test_split_percentage, validation_split_percentage):\n    n_feature = df.shape[1]\n    x_data, y_data = [], []\n    \n    for i in range(n_past, len(df) - n_future + 1):\n        x_data.append(df[i - n_past:i, 0:n_feature])\n        y_data.append(df[i + n_future - 1:i + n_future, 0])\n    \n    split_training_test_starting_point = int(round(train_test_split_percentage*len(x_data)))\n    split_train_validation_starting_point = int(round(split_training_test_starting_point*(1-validation_split_percentage)))\n    \n    x_train = x_data[:split_train_validation_starting_point]\n    y_train = y_data[:split_train_validation_starting_point]\n    \n    # if you want to choose the validation set by yourself, uncomment the below code.\n    x_val = x_data[split_train_validation_starting_point:split_training_test_starting_point]\n    y_val =  x_data[split_train_validation_starting_point:split_training_test_starting_point]                                             \n    \n    x_test = x_data[split_training_test_starting_point:]\n    y_test = y_data[split_training_test_starting_point:]\n    \n    return np.array(x_train), np.array(x_test), np.array(x_val), np.array(y_train), np.array(y_test), np.array(y_val)","a2807397":"# Number of days you want to predict into the future\n# Number of past days you want to use to predict the future\n\nX_train, X_test, X_val, y_train, y_test, y_val = create_data(data_prices_scaled, n_future=1, n_past=25, train_test_split_percentage=0.8,\n                                               validation_split_percentage = 0)","d7b47888":"print(X_train.shape)\nprint(X_test.shape)\n\nprint(y_train.shape)\nprint(y_test.shape)","b055afdc":"# ------------------LSTM-----------------------\nregressor = Sequential()\nregressor.add(LSTM(units=16, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\nregressor.add(Dropout(0.2))\n\nregressor.add(LSTM(units=16, return_sequences=False))\nregressor.add(Dropout(0.2))\nregressor.add(Dense(units=1, activation='linear'))\nregressor.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\nregressor.summary()","17fbee61":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n#mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n\n# fit model\nhistory = regressor.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=64, callbacks=[es])","02078630":"history.history.keys()","8817d18e":"fig = plt.figure(figsize=(20,7))\nfig.add_subplot(121)\n\n# Accuracy\nplt.plot(history.epoch, history.history['root_mean_squared_error'], label = \"rmse\")\nplt.plot(history.epoch, history.history['val_root_mean_squared_error'], label = \"val_rmse\")\n\nplt.title(\"RMSE\", fontsize=18)\nplt.xlabel(\"Epochs\", fontsize=15)\nplt.ylabel(\"RMSE\", fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\n\n#Adding Subplot 1 (For Loss)\nfig.add_subplot(122)\n\nplt.plot(history.epoch, history.history['loss'], label=\"loss\")\nplt.plot(history.epoch, history.history['val_loss'], label=\"val_loss\")\n\nplt.title(\"Loss\", fontsize=18)\nplt.xlabel(\"Epochs\", fontsize=15)\nplt.ylabel(\"Loss\", fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nplt.show()","07b18772":"results = regressor.evaluate(X_test, y_test)\nprint(\"test loss, test acc:\", np.round(results, 4))","b47e160e":"# detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n\ndef LSTM_HyperParameter_Tuning(config, x_train, y_train, x_test, y_test):\n    \n    first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = config\n    possible_combinations = list(itertools.product(first_additional_layer, second_additional_layer, third_additional_layer,\n                                                  n_neurons, n_batch_size, dropout))\n    \n    print(possible_combinations)\n    print('\\n')\n    \n    hist = []\n    \n    for i in range(0, len(possible_combinations)):\n        \n        print(f'{i+1}th of {len(possible_combinations)} total combinations: \\n')\n        print('--------------------------------------------------------------------')\n        \n        first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = possible_combinations[i]\n        \n        # instantiating the model in the strategy scope creates the model on the TPU\n        #with tpu_strategy.scope():\n        regressor = Sequential()\n        regressor.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n        regressor.add(Dropout(dropout))\n\n        if first_additional_layer:\n            regressor.add(LSTM(units=n_neurons, return_sequences=True))\n            regressor.add(Dropout(dropout))\n\n        if second_additional_layer:\n            regressor.add(LSTM(units=n_neurons, return_sequences=True))\n            regressor.add(Dropout(dropout))\n\n        if third_additional_layer:\n            regressor.add(GRU(units=n_neurons, return_sequences=True))\n            regressor.add(Dropout(dropout))\n\n        regressor.add(LSTM(units=n_neurons, return_sequences=False))\n        regressor.add(Dropout(dropout))\n        regressor.add(Dense(units=1, activation='linear'))\n        regressor.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\n        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n        '''''\n        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n        alidation_split arguments,then the loss on the validation dataset will be made available via the name \u201cval_loss.\u201d\n        '''''\n\n        file_path = 'best_model.h5'\n\n        mc = ModelCheckpoint(file_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\n        '''''\n        cb = Callback(...)  # First, callbacks must be instantiated.\n        cb_list = [cb, ...]  # Then, one or more callbacks that you intend to use must be added to a Python list.\n        model.fit(..., callbacks=cb_list)  # Finally, the list of callbacks is provided to the callback argument when fitting the model.\n        '''''\n\n        regressor.fit(x_train, y_train, validation_split=0.3, epochs=100, batch_size=n_batch_size, callbacks=[es, mc], verbose=0)\n\n        # load the best model\n        # regressor = load_model('best_model.h5')\n\n        train_accuracy = regressor.evaluate(x_train, y_train, verbose=0)\n        test_accuracy = regressor.evaluate(x_test, y_test, verbose=0)\n\n        hist.append(list((first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout,\n                          train_accuracy, test_accuracy)))\n\n        print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy} and test accuracy: {test_accuracy}')\n        \n        print('--------------------------------------------------------------------')\n        print('--------------------------------------------------------------------')\n        print('--------------------------------------------------------------------')\n        print('--------------------------------------------------------------------')\n         \n    return hist","f1137c09":"config = [[False], [False, True], [False, True], [8, 16, 32], [16, 32], [0.1, 0.2]]  \n\n# list of lists --> [[first_additional_layer(LSTM)], \n                    #[second_additional_layer(LSTM)], \n                    #[third_additional_layer (GRU)], \n                    #[n_neurons], \n                    #[n_batch_size], \n                    #[dropout]]\n\nhist = LSTM_HyperParameter_Tuning(config, X_train, y_train, X_test, y_test)  # change x_train shape","f24fcd61":"hist = pd.DataFrame(hist)\nhist = hist.sort_values(by=[7], ascending=True)\nhist","0741ccbc":"print(f'Best Combination: \\n first_additional_layer = {hist.iloc[0, 0]}\\n second_additional_layer = {hist.iloc[0, 1]}\\n third_additional_layer = {hist.iloc[0, 2]}\\n n_neurons = {hist.iloc[0, 3]}\\n n_batch_size = {hist.iloc[0, 4]}\\n dropout = {hist.iloc[0, 5]}')\nprint('**************************')\nprint(f'Results Before Tunning:\\n Test Set RMSE: {np.round(results, 4)[1]}\\n')\nprint(f'Results After Tunning:\\n Test Set RMSE: {np.round(hist.iloc[0, -1], 4)[1]}\\n')\nprint(f'{np.round((results[1] - hist.iloc[0, -1][1])*100\/np.round(results, 4)[1])}% Improvement')","5cda8754":"first_additional_layer, second_additional_layer, third_additional_layer, n_neurons, n_batch_size, dropout = list(hist.iloc[0, :-2])","aac0a4fc":"regressor = Sequential()\nregressor.add(LSTM(units=n_neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\nregressor.add(Dropout(dropout))\n\nif first_additional_layer:\n    regressor.add(LSTM(units=n_neurons, return_sequences=True))\n    regressor.add(Dropout(dropout))\n\nif second_additional_layer:\n    regressor.add(LSTM(units=n_neurons, return_sequences=True))\n    regressor.add(Dropout(dropout))\n\nif third_additional_layer:\n    regressor.add(GRU(units=n_neurons, return_sequences=True))\n    regressor.add(Dropout(dropout))\n\nregressor.add(LSTM(units=n_neurons, return_sequences=False))\nregressor.add(Dropout(dropout))\nregressor.add(Dense(units=1, activation='linear'))\nregressor.compile(optimizer='adam', loss='mse')\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n\nfile_path = 'best_model.h5'\n\nmc = ModelCheckpoint(file_path, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n\nregressor.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=n_batch_size, callbacks=[es, mc], verbose=0)","281b8d41":"regressor.evaluate(X_test, y_test)","91d701fc":"y_pred = regressor.predict(X_test)\n\nplt.figure(figsize=(16,8), dpi= 100, facecolor='w', edgecolor='k')\n\nplt.plot(y_test, color='red', label = 'Real Opening Price')\nplt.plot(y_pred, color='green', label = 'Predicted Opening Price')\nplt.legend(loc='best')","0d94ae6d":"I choose the opening price and volume as two attributes to consider in our model to predict the next day's opening price. You can change the bellow code to what you want to predict and what attributes you need to consider in the model input. It is recommended you choose at least two attributes since the code is written for at least two attributes in the input data. Nevertheless, the code can change slightly to account for one attribute as well.","e5160e7a":"<a id=\"5\"><\/a> <br>\n## Results","eacbdebf":"<a id=\"23\"><\/a> <br>\n## plotting Price through Time\n\nWhile the first big plot shows opening, closing, low, and high price altogether, the following four plots show each attribute separately. It may seem that all of the mentioned prices are the same, but as it is clear in the first big plot, they have a slight difference with each other.","3e1d3bce":"<a id=\"43\"><\/a> <br>\n## Early Stopping and Callback\n\nSince in the Grid Search, we have to train an LSTM model for each combination, it may take so much time to fit all the models and choose the best combination of the hyperparameters. One of the ways that we can prevent this from happening is through using Early Stopping and Callbacks. The idea here is to track a measure (like validation loss) and whenever a stopping criterion (like no improvement in the monitored measure value in successive steps, reaching a pre-specified limit for that measure, or a pre-specified increment in that measure) is satisfied, we can stop the training process. The measure that we are using here is validation loss since the validation set is not used in the training process. [This](https:\/\/machinelearningmastery.com\/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping\/) article is one of the best articles that I've read about using Early Stopping to halt the training of a model at the right time. In the below, I copied and pasted the parts that I found important:\n\n> 1. **es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)** ****-->**** Often, the first sign of no further improvement may not be the best time to stop training. This is because the model may coast into a plateau of no improvement or even get slightly worse before getting much better. We can account for this by adding a delay to the trigger in terms of the number of epochs on which we would like to see no improvement. This can be done by setting the \u201cpatience\u201d argument.\n    \n> 2. **es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1)** **-->** By default, any change in the performance measure, no matter how fractional, will be considered an improvement. You may want to consider an improvement that is a specific increment, such as 1 unit for mean squared error or 1% for accuracy. This can be specified via the \u201cmin_delta\u201d argument.\n\n> 3. **es = EarlyStopping(monitor='val_loss', mode='min', baseline=0.4)** **-->**  Finally, it may be desirable to only stop training if performance stays above or below a given threshold or baseline. For example, if you have familiarity with the training of the model (e.g. learning curves) and know that once a validation loss of a given value is achieved that there is no point in continuing training. This can be specified by setting the \u201cbaseline\u201d argument.\n    \n> 4. **mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1)** **-->** The EarlyStopping callback will stop training once triggered, but the model at the end of training may not be the model with best performance on the validation dataset. An additional callback is required that will save the best model observed during training for later use. This is the ModelCheckpoint callback.","f2be50ee":"In this notebook, we will use LSTM to predict Stellar (XLM) crypto price (more precisely, we are more interested in the rise and fall of the price based on previous information) in Keras. I will also use more than one feature in my model, and it could be interesting for you to see how we can create the LSTM input data required by Keras in this case.\n\nMoreover, we are going to implement a manual Grid Search to tune the hyperparameters. We will also take advantage of Early Stopping and Callback to reduce the hyperparameter tunning time.","ac261d62":"Sometimes we prefer to choose the validation set by ourselves. In this case, in the below code, you can pass a value in the range of (0, 1) for the validation_split_percentage when you are calling the create_data function, and use the below code to fit the model:\n\n- model.fit(train_X, train_y, validation_data=(val_x, val_y))  # manually splitting\n\nIn my case, I rathered to use the built-in parameter (validation_split) in the fit method of the Keras library.  It considers a fraction of the training data as the validation set to evaluate loss and metrics at the end of each epoch as follow:\n\n- model.fit(train_X, train_y, validation_split=0.3)  # automatically splitting","2de3b4db":"## Contents\n\n* [Import Libraries and the Data](#1)\n* [Descriptive Analysis](#2)\n    - [plotting Price through Time](#23)\n    - [Fearure Scaling](#24)\n    - [Creating LSTM input data](#25)\n* [Train LSTM Model](#3)\n* [Hyperparameter Tunning](#4)\n    - [Introduction](#41)\n    - [Grid Search](#42)\n    - [Early Stopping and Callback](#43)\n    - [Choosing the Best Model](#44)\n* [Results](#5)","807fb080":"<a id=\"25\"><\/a> <br>\n## Creating LSTM input data\n\nIn order to use LSTM, our input and output data should have a specific shape. It was a bit complicated for me when I was first introduced to LSTM, but I found [this](https:\/\/medium.com\/@shivajbd\/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e) comprehensive article to fully understand what was going on. In a nutshell, the input and output data in an LSTM model is a three-dimensional array where the first dimension represents **the number of samples (or batch size)** like the number of rows of data in a two-dimensional setting, the second dimension stands for **time steps** which indicates the amount of time that we want to go back through time, and the third dimension shows **the number of features (or input dimension)** that we want to include in the model for every element in our batch. So, it is like [number_of_samples, time_steps, input_dim]. The below image is retrieved from the mentioned article and could be a good illustration of the LSTM input and output data shape.\n![](https:\/\/miro.medium.com\/max\/665\/1*AQKRJsRdWx2HZ85H1yWoKw.png)","84250c32":"<a id=\"2\"><\/a> <br>\n## Descriptive Analysis","811aa0e1":"# If you liked my work then please upvote, Thank you.","3d24279f":"<a id=\"42\"><\/a> <br>\n## Grid Search\n\nGrid search is a traditional method to perform hyperparameter tunning. It basically works by defining a subset of candidate values for each hyperparameter, and training all the possible combination of the hyperparameters. Then, each possible fitted model is evaluated on a validation set, and the best configuration of the hyperparameter will be choosed at the end.","3382ca03":"<a id=\"44\"><\/a> <br>\n## Choosing the Best Model","1f88bdce":"We can also benefit from using Pandas Profiling as well. It is an interesting and amazing tool that can generate thorough profile reports for EDA and descriptive analysis purposes. ","47f2334c":"\nWe have two important terms in machine learning referred to as **model parameter** and **model hyperparamer**. So, first of all, what is a hyperparameter, and what is a parameter? Based on [here](https:\/\/www.datacamp.com\/community\/tutorials\/parameter-optimization-machine-learning-models),\n\n- A model **model hyperparameter** is a configuration that is external to the model and whose value cannot be estimated from the data and a **model parameter** is a configuration variable that is internal to the model and whose value can be estimated from the given data.\n\nIn the other words, a hyperparameter is used to construct the structure of the model and cannot be learned from the data and its value is set before the learning process begins. Therefore, hyperparameters are like the settings of an algorithm that can be adjusted to optimize performance and prevent overfitting. This is exactly what we do in the hyperparameter tuning. We try to choose a set of optimal hyperparameters for a learning algorithm to enhance the performance of the model. There are two frequently used methods to perform hyperparameter tunning called 1)Grid Search and 2)Random Search. In this notebook, I have used the former one because of its simplicity to implement and at the same time, its powerful performance. More information on both of the methods can be found in [here](https:\/\/blog.usejournal.com\/a-comparison-of-grid-search-and-randomized-search-using-scikit-learn-29823179bc85).","2d8aa1f4":"As it is clear in the plot, the trend (rise and fall) of the stock price is well predicted. Nice!","c4436ae4":"<a id=\"3\"><\/a> <br>\n## Train LSTM Model","07b132f0":"Here, at each point of the time, we will consider price and volume as our attributes in input_dim, and 25 days as our time_steps.","5502386d":"<a id=\"1\"><\/a> <br>\n## Import Libraries and the Data","471891f5":"<a id=\"24\"><\/a> <br>\n## Fearure Scaling","cd2c894e":"<a id=\"4\"><\/a> <br>\n## Hyperparameter Tunning"}}