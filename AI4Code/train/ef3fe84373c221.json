{"cell_type":{"68f42da0":"code","ee4c11ee":"code","7a6b5c5e":"code","43ec9a58":"code","63df535e":"code","fac6e95f":"code","f69f93c3":"code","64d9ac43":"code","dc69c2bd":"code","404547e2":"code","26618d03":"code","e85ae617":"code","8ff5c2f2":"code","7146b789":"code","2c9e9a19":"code","f6fe29d6":"code","49111a6b":"markdown"},"source":{"68f42da0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee4c11ee":"import pandas as pd \ntrain=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nprint(train.head())\n\noutput=pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ntrain.columns","7a6b5c5e":"test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nprint(test.head())\ntest.columns","43ec9a58":"print(train.shape)\nprint(test.shape)\n","63df535e":"x_axis=train['Ticket']\ny_axis=train['PassengerId']\nimport matplotlib.pyplot as plt \nfig=plt.figure()\nax=fig.add_subplot(1,1,1)\nax.scatter(x_axis,y_axis)\nplt.title('plot')\nplt.xlabel('ticket')\nplt.ylabel('survuved')\n","fac6e95f":"print(train.isna().sum())\nprint(test.isna().sum())\n","f69f93c3":"data = pd.concat([train, test], sort = False)\n\ndata.head()","64d9ac43":"\n#Fill Missing numbers with median\ndata['Age'] = data['Age'].fillna(value=data['Age'].median())\ndata['Fare'] = data['Fare'].fillna(value=data['Fare'].median())\ndata.info()\ndata['Embarked'] = data['Embarked'].fillna('S')\ndata['Cabin'] = data['Cabin'].fillna('NAN')\ndata['Cabin']=data['Cabin'].replace('NAN','C205')\ndata.info()\nprint(data.isna().sum())\nprint(data['Cabin'])","dc69c2bd":"# binarizing sex column\ndata.Sex[data.Sex == 'male'] = 1\ndata.Sex[data.Sex == 'female'] = 0\n\nprint(data['Sex'])","404547e2":"# names column titles\nimport re\ndef get_title(name):\n    title_search = re.search('([A-Za-z]+\\.)', name)\n    \n    if title_search:\n        return title_search.group(1)\n    return \"\"\ndata['Names'] = data['Name'].apply(get_title)\ndata['Names'].value_counts()\n\nprint(data['Names'])","26618d03":"#Age\ndata.loc[ data['Age'] <= 20, 'Age'] = 0\ndata.loc[(data['Age'] > 20) & (data['Age'] <= 40), 'Age'] = 1\ndata.loc[ data['Age'] > 40, 'Age'] = 2\nprint(data['Age'].head(100))","e85ae617":"print(data.head)\n","8ff5c2f2":"# survived column\nrand=np.random.randint(0,1)\ndata['Survived']=data['Survived'].replace(np.nan,rand)\nprint(data['Survived'])","7146b789":"import pandas as pd\n\ndata=pd.get_dummies(data)\n\n# making model\n\nX=data.drop(\"Survived\",axis=1)\ny=data['Survived']\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.1)\n\n# Logistic Regression \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\npred=[]\nlog=LogisticRegression(C=0.5,penalty='l2',l1_ratio=0)\nres=log.fit(X_train,y_train.values.ravel())\npred=log.predict(X_test)\nprint(accuracy_score(pred,y_test))\n\nprint('confusion matrix')\nprint(confusion_matrix(y_test, pred))\n\nprint(classification_report(y_test, pred))","2c9e9a19":"from sklearn.svm import SVC\n\n# Support vector\nsvc=SVC()\n\nmodel=svc.fit(X_train,y_train)\npred=svc.predict(X_test)\n\nsvc_score=svc.score(X_train,y_train)\n\nprint(svc_score)\nprint(confusion_matrix(y_test, pred))\n","f6fe29d6":"from sklearn.ensemble import RandomForestClassifier\n\nrfc=RandomForestClassifier(n_estimators=80)\nrfc.fit(X_train,y_train)\n\npred=rfc.predict(X_test)\nScore=rfc.score(X_test,y_test)\nprint(Score)\nprint(confusion_matrix(y_test, pred))","49111a6b":"End of feature enginering"}}