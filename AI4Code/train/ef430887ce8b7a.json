{"cell_type":{"26c468ce":"code","2fd042e7":"code","63236373":"code","6d4185b2":"code","4beedc14":"code","1c34bb5a":"code","9796d1d6":"code","bf602e9d":"code","ea64fe7b":"code","ac561755":"code","644d3fbc":"code","3652141b":"code","5beb6fac":"code","4d2194e6":"code","721b3fc0":"code","e864a4cd":"code","127cd35c":"code","fd250a13":"code","6dfc8c74":"code","2b2ee1cc":"code","b5b4ad38":"code","c44683d1":"code","d73fa8bd":"code","5a683fce":"code","405c1c21":"code","02a91899":"code","3acd9b66":"code","82af0f89":"code","bcc0bf7e":"code","e7bc8f1d":"code","dc960ee2":"code","2cf619a7":"code","61beac6f":"code","50933c0c":"code","04f21426":"code","e518f7b0":"code","6bb85839":"code","21e2ad04":"code","7f11febd":"code","c9e2a527":"markdown","89ef01fc":"markdown","f7cf4db5":"markdown","19b28f30":"markdown","77578f20":"markdown","43ae875a":"markdown","76bcb993":"markdown","5a225c85":"markdown","57ca8f3c":"markdown","6b54606b":"markdown","6c93579e":"markdown","9b8e84b1":"markdown","cbf9256a":"markdown","34a56651":"markdown","a4252c14":"markdown","937a34ab":"markdown","68d2fe3b":"markdown","e847fc4a":"markdown","de399d22":"markdown","672db1e8":"markdown","ed7a6a3c":"markdown","3c969020":"markdown","f13d1efe":"markdown","0a482582":"markdown","02481e9e":"markdown","1ef20b5e":"markdown","3d569f5e":"markdown","d8440d4c":"markdown","f0787e6a":"markdown","f6ce199e":"markdown","cf6f8fce":"markdown","16ca2aeb":"markdown","db096541":"markdown","8307efa6":"markdown","d5d6d3fb":"markdown","f5cabc9b":"markdown","77e45ed7":"markdown","f5e46812":"markdown","5726c4e7":"markdown","08f4dc60":"markdown","d21f6b8b":"markdown","3dbf18f0":"markdown","79f83e27":"markdown"},"source":{"26c468ce":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline","2fd042e7":"!wget -O loan_train.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/loan_train.csv","63236373":"df = pd.read_csv('loan_train.csv')\ndf.head().style.background_gradient(cmap='RdGy')","6d4185b2":"df.shape","4beedc14":"df['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf.head().style.background_gradient(cmap='RdGy')","1c34bb5a":"df['loan_status'].value_counts()","9796d1d6":"import seaborn as sns\n\nbins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","bf602e9d":"bins = np.linspace(df.age.min(), df.age.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'age', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()","ea64fe7b":"df['dayofweek'] = df['effective_date'].dt.dayofweek\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()\n","ac561755":"df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ndf.head().style.background_gradient(cmap='RdGy')","644d3fbc":"df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)","3652141b":"df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf.head().style.background_gradient(cmap='RdGy')","5beb6fac":"df.groupby(['education'])['loan_status'].value_counts(normalize=True)","4d2194e6":"df[['Principal','terms','age','Gender','education']].head().style.background_gradient(cmap='RdGy')","721b3fc0":"Feature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head().style.background_gradient(cmap='RdGy')\n","e864a4cd":"X = Feature\nX1 = X\nX[0:5]","127cd35c":"print(X.columns)","fd250a13":"y = df['loan_status'].values\ny[0:5]","6dfc8c74":"X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]","2b2ee1cc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","b5b4ad38":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n    std_acc[n-1]=np.std(yhat==y_test)\/np.sqrt(yhat.shape[0])\nmean_acc\n#Plot model accuracy for Different number of Neighbors\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+\/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Neighbors (K)')\nplt.tight_layout()\nplt.show()\nprint( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1)\n","c44683d1":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nk = 7 # For best K\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nyhat = neigh.predict(X_test)\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))","d73fa8bd":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\ndrugTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\ndrugTree # it shows the default parameters\ndrugTree.fit(X_train,y_train)\npredTree = drugTree.predict(X_test)\n\nfrom sklearn import metrics\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, predTree))","5a683fce":"#INSTALLATIONS TO VIEW THE DECISION TREE\n!conda install -c conda-forge pydotplus -y","405c1c21":"from sklearn.externals.six import StringIO\nimport pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n\n%matplotlib inline \ndot_data = StringIO()\nfilename = \"drugtree.png\"\nfeatureNames = df.columns[3: 11]\ntargetNames = df[\"loan_status\"].unique().tolist()\nout=tree.export_graphviz(drugTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_train), filled=True,  special_characters=True,rotate=False)  \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100, 200))\nplt.imshow(img,interpolation='nearest')","02a91899":"from sklearn import svm\nfrom sklearn import metrics\nclf2 = svm.SVC(kernel='linear')\nclf2.fit(X_train, y_train) \nyhat2 = clf2.predict(X_test)\nprint(\"SVM \", metrics.accuracy_score(y_test, yhat2))","3acd9b66":"clf2.support_vectors_","82af0f89":"print(X1.columns)","bcc0bf7e":"# Determining the most contributing features for SVM classifier\n\npd.Series(abs(clf2.coef_[0]), index=X1.columns).nlargest(10).plot(kind='barh',figsize=(8, 6))","e7bc8f1d":"clf2 = svm.SVC(kernel='rbf')\nclf2.fit(X_train, y_train) \nyhat2 = clf2.predict(X_test)\nprint(\"SVM \", metrics.accuracy_score(y_test, yhat2))","dc960ee2":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import jaccard_similarity_score\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nyhat = LR.predict(X_test)\nyhat_prob = LR.predict_proba(X_test)\nprint(\"Logistic Regression's Log Loss Accuracy: \", log_loss(y_test, yhat_prob))\nprint(\"Logistic Regression's Jaccard Similarity Accuracy: \", jaccard_similarity_score(y_test, yhat))\n","2cf619a7":"from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss","61beac6f":"!wget -O loan_test.csv https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/loan_test.csv","50933c0c":"test_df = pd.read_csv('loan_test.csv')\ntest_df.head().style.background_gradient(cmap='RdGy')","04f21426":"# Preprocessing the test data set\ntest_df['due_date'] = pd.to_datetime(test_df['due_date'])\ntest_df['effective_date'] = pd.to_datetime(test_df['effective_date'])\ntest_df['loan_status'].value_counts()\ntest_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\ntest_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ntest_df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)\ntest_df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ntest_df.groupby(['education'])['loan_status'].value_counts(normalize=True)\ntest_df[['Principal','terms','age','Gender','education']].head()\ntest_df[['Principal','terms','age','Gender','education']].head()\nFeature = test_df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(test_df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nX = Feature\ny_test = test_df['loan_status'].values\nX_test= preprocessing.StandardScaler().fit(X).transform(X)","e518f7b0":"# K Nearest Neighbor(KNN) Prediction\nyhat = neigh.predict(X_test)\nprint(\"KNN's Jaccard Similarity Accuracy: %.2f\" % jaccard_similarity_score(y_test, yhat))\nprint(\"KNN Avg F1-score: %.2f\" % f1_score(y_test, yhat, average='weighted'))","6bb85839":"# Support Vector Machine Prediction\nyhat2 = clf2.predict(X_test)\nprint(\"SVM's Jaccard Similarity Accuracy: %.2f\" % jaccard_similarity_score(y_test, yhat2))\nprint(\"SVM Avg F1-score: %.2f\" % f1_score(y_test, yhat2, average='weighted'))\n","21e2ad04":"# Logistic Regression Prediction\nyhat3 = LR.predict(X_test)\nyhat_prob3 = LR.predict_proba(X_test)\nprint(\"Logistic Regression's Jaccard Similarity Accuracy:  %.2f\" % jaccard_similarity_score(y_test, yhat3))\nprint(\"LRP Avg F1-score: %.2f\" % f1_score(y_test, yhat3, average='weighted'))\nprint(\"Logistic Regression's Log Loss Accuracy: %.2f\" % log_loss(y_test, yhat_prob3))","7f11febd":"# Decision Tree Prediction\npredTree = drugTree.predict(X_test)\nprint(\"DecisionTrees's Jaccard Similarity Accuracy: %.2f\" % jaccard_similarity_score(y_test, predTree))\nprint(\"DecisionTrees Avg F1-score: %.2f\" % f1_score(y_test, predTree, average='weighted'))","c9e2a527":"## One Hot Encoding  \n#### How about education?","89ef01fc":"### Feature selection","f7cf4db5":"What are our lables?","19b28f30":"Data Standardization give data zero mean and unit variance (technically should be done after train test split )","77578f20":"<a href=\"https:\/\/www.bigdatauniversity.com\"><img src=\"https:\/\/ibm.box.com\/shared\/static\/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width=\"400\" align=\"center\"><\/a>\n\n<h1 align=\"center\"><font size=\"5\">Classification with Python<\/font><\/h1>","43ae875a":"<h3>Thanks for completing this lesson!<\/h3>\n\nCredit :-\n<h4>Author of Solution and Visualization:  <a href=\"https:\/\/www.linkedin.com\/in\/rohit-kumar-singh1996\/\"> Rohit Kumar Singh <\/a> and  <a href=\"https:\/\/www.linkedin.com\/in\/bavalpreet-singh-a7b627172\/\"> Bavalpreet Singh <\/a><\/h4>\n<h4>Author of Format:  <a href=\"https:\/\/ca.linkedin.com\/in\/saeedaghabozorgi\">Saeed Aghabozorgi<\/a><\/h4>\n<p>Copyright &copy; 2018 <a href=\"https:\/\/cocl.us\/DX0108EN_CC\">Cognitive Class<\/a>. This notebook and its source code are released under the terms of the <a href=\"https:\/\/bigdatauniversity.com\/mit-license\/\">MIT License<\/a>.<\/p>","76bcb993":"Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\nYou should use the following algorithm:\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n\n\n__ Notice:__ \n- You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n- You should include the code of the algorithm in the following cells.","5a225c85":"### **For visualization purpose, using linear kernel for SVM.**","57ca8f3c":"<img src=\"https:\/\/d31bgfoj87qaaj.cloudfront.net\/blog\/wp-content\/uploads\/2019\/04\/Blog-Loan-Approved-Feature-min.jpg\" width=\"500\" align=\"center\">","6b54606b":"First, download and load the test set:","6c93579e":"### Load Test set for evaluation ","9b8e84b1":"### Convert to date time object ","cbf9256a":"Lets look at gender:","34a56651":"Lets plot some columns to underestand data better:","a4252c14":"## Normalize Data ","937a34ab":"# Report\nYou should be able to report the accuracy of the built model using different evaluation metrics:","68d2fe3b":"In this notebook we try to practice all the classification algorithms that we learned in this course.\n\nWe load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n\nLets first load required libraries:","e847fc4a":"# Classification ","de399d22":"# Pre-processing:  Feature selection\/extraction","672db1e8":"260 people have paid off the loan on time while 86 have gone into collection \n","ed7a6a3c":"### Load Data From CSV File  ","3c969020":"# Data visualization and pre-processing\n\n","f13d1efe":"<img src=\"https:\/\/miro.medium.com\/fit\/c\/1730\/520\/1*glrB0KgjOcTiKUEx7T8tcA.png\" width=\"600\" align=\"center\">","0a482582":"Lets defind feature sets, X:","02481e9e":"# Decision Tree","1ef20b5e":"## Convert Categorical features to numerical values","3d569f5e":"# Logistic Regression","d8440d4c":"| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | 0.67    |  0.63    | NA      |\n| Decision Tree      | 0.72    | 0.74     | NA      |\n| SVM                | 0.80    | 0.76     | NA      |\n| LogisticRegression | 0.74    | 0.66     | 0.57    |","f0787e6a":"Lets convert male to 0 and female to 1:\n","f6ce199e":"#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame ","cf6f8fce":"86 % of female pay there loans while only 73 % of males pay there loan\n","16ca2aeb":"## Different Classification with Python\n\n### *By Rohit Kumar Singh and Bavalpreet Singh*","db096541":"# Support Vector Machine","8307efa6":"This dataset is about past loans. The __Loan_train.csv__ data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n\n| Field          | Description                                                                           |\n|----------------|---------------------------------------------------------------------------------------|\n| Loan_status    | Whether a loan is paid off on in collection                                           |\n| Principal      | Basic principal loan amount at the                                                    |\n| Terms          | Origination terms which can be weekly (7 days), biweekly, and monthly payoff schedule |\n| Effective_date | When the loan got originated and took effects                                         |\n| Due_date       | Since it\u2019s one-time payoff schedule, each loan has one single due date                |\n| Age            | Age of applicant                                                                      |\n| Education      | Education of applicant                                                                |\n| Gender         | The gender of applicant                                                               |","d5d6d3fb":"### Lets look at the day of the week people get the loan ","f5cabc9b":"We see that people who get the loan at the end of the week dont pay it off, so lets use Feature binarization to set a threshold values less then day 4 ","77e45ed7":"#### Feature befor One Hot Encoding","f5e46812":"# K Nearest Neighbor(KNN)\nNotice: You should find the best k to build the model with the best accuracy.  \n**warning:** You should not use the __loan_test.csv__ for finding the best k, however, you can split your train_loan.csv into train and test to find the best __k__.","5726c4e7":"# Model Evaluation using Test set","08f4dc60":"Lets download the dataset","d21f6b8b":"Let\u2019s see how many of each class is in our data set ","3dbf18f0":"After complete evaluation of the models using the 4 above said algorithms, the SVM - Support Vector Machine holds the highest accuracy rate of 80% and 76% in both the evaluation models say Jaccard Index and F1-Score.","79f83e27":"### About dataset"}}