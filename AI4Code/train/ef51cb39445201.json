{"cell_type":{"b53dbdef":"code","08c1b1b7":"code","08463842":"code","6285bf2b":"code","1e12ddaf":"code","0f20d79e":"code","44fd700f":"code","b01745ff":"code","43d7ea6e":"code","26e271be":"code","29280910":"code","7b8b2f96":"code","1389389d":"code","5d8f4b1b":"code","78a2a384":"code","971515b5":"code","a6eafed9":"code","292ddb7c":"code","a6ede5ec":"code","9c0b2fd6":"code","f48958f0":"code","6ed139e6":"code","8fdabe6f":"code","531bbce8":"code","1ed2ef8e":"code","a782a8bb":"code","70e492f4":"code","e4a24d8a":"code","f8cdbe4a":"code","8e43603d":"code","6fbae874":"code","a59358ec":"code","01e3764a":"code","9fd95622":"code","5a495373":"markdown","edd842ab":"markdown","a7dc8b5a":"markdown"},"source":{"b53dbdef":"#importando bibliotecas\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style = \"whitegrid\")\n\n%matplotlib inline","08c1b1b7":"#importando os dados\nimport pandas as pd\n\ndf = pd.read_excel(\"..\/input\/covid19\/dataset.xlsx\")\n\ndf_raw = df","08463842":"df.shape","6285bf2b":"#Listing 5 first rows\ndf.head()","1e12ddaf":"#Distribuition os Positive case compared to Negative case. Note that 11% of cases are positive. Unbalanced dataset.\ndf.groupby(\"SARS-Cov-2 exam result\").size()\n","0f20d79e":"# Drop columns with insuficient data.\nColunas=['Serum Glucose',\n'Mycoplasma pneumoniae',\n'Alanine transaminase',\n'Aspartate transaminase',\n'Gamma-glutamyltransferase\u00a0',\n'Total Bilirubin',\n'Direct Bilirubin',\n'Indirect Bilirubin',\n'Alkaline phosphatase',\n'Ionized calcium\u00a0',\n'Strepto A',\n'Magnesium',\n'pCO2 (venous blood gas analysis)',\n'Hb saturation (venous blood gas analysis)',\n'Base excess (venous blood gas analysis)',\n'pO2 (venous blood gas analysis)',\n'Fio2 (venous blood gas analysis)',\n'Total CO2 (venous blood gas analysis)',\n'pH (venous blood gas analysis)',\n'HCO3 (venous blood gas analysis)',\n'Rods #',\n'Segmented',\n'Promyelocytes',\n'Metamyelocytes',\n'Myelocytes',\n'Myeloblasts',\n'Urine - Esterase',\n'Urine - Aspect',\n'Urine - pH',\n'Urine - Hemoglobin',\n'Urine - Bile pigments',\n'Urine - Ketone Bodies',\n'Urine - Nitrite',\n'Urine - Density',\n'Urine - Urobilinogen',\n'Urine - Protein',\n'Urine - Sugar',\n'Urine - Leukocytes',\n'Urine - Crystals',\n'Urine - Red blood cells',\n'Urine - Hyaline cylinders',\n'Urine - Granular cylinders',\n'Urine - Yeasts',\n'Urine - Color',\n'Partial thromboplastin time\u00a0(PTT)\u00a0',\n'Relationship (Patient\/Normal)',\n'International normalized ratio (INR)',\n'Lactic Dehydrogenase',\n'Prothrombin time (PT), Activity',\n'Vitamin B12',\n'Creatine phosphokinase\u00a0(CPK)\u00a0',\n'Ferritin',\n'Arterial Lactic Acid',\n'Lipase dosage',\n'D-Dimer',\n'Albumin',\n'Hb saturation (arterial blood gases)',\n'pCO2 (arterial blood gas analysis)',\n'Base excess (arterial blood gas analysis)',\n'pH (arterial blood gas analysis)',\n'Total CO2 (arterial blood gas analysis)',\n'HCO3 (arterial blood gas analysis)',\n'pO2 (arterial blood gas analysis)',\n'Arteiral Fio2',\n'Phosphor',\n'ctO2 (arterial blood gas analysis)',\n'Influenza B, rapid test',\n'Influenza A, rapid test'\n]\n\ndf.drop(Colunas , axis = 1, inplace = True) # 'axis' = 0 (row) | axis = 1 (column)","44fd700f":"# Drop columns with unnecessary data.\nColunas = ['Patient ID',\"Patient addmited to regular ward (1=yes, 0=no)\",\n           \"Patient addmited to semi-intensive unit (1=yes, 0=no)\",\n           \"Patient addmited to intensive care unit (1=yes, 0=no)\",\n           'Respiratory Syncytial Virus',\n            'Influenza A',\n            'Influenza B',\n            'Parainfluenza 1',\n            'CoronavirusNL63',\n            'Rhinovirus\/Enterovirus',\n            'Coronavirus HKU1',\n            'Parainfluenza 3',\n            'Chlamydophila pneumoniae',\n            'Adenovirus',\n            'Parainfluenza 4',\n            'Coronavirus229E',\n            'CoronavirusOC43',\n            'Inf A H1N1 2009',\n            'Bordetella pertussis',\n            'Metapneumovirus',\n            'Parainfluenza 2',\n]\ndf.drop(Colunas , axis = 1, inplace = True) # 'axis' = 0 (row) | axis = 1 (column)","b01745ff":"df.shape","43d7ea6e":"#Rename coluns to simplify coding\n\ndf.rename(columns={'Patient age quantile': 'age'}, inplace=True)\ndf.rename(columns={'SARS-Cov-2 exam result': 'target'}, inplace=True)\ndf.rename(columns={'Mean platelet volume ': 'Mean_platelet_volume'}, inplace=True)\ndf.rename(columns={'Red blood Cells': 'Red_blood_Cells'}, inplace=True)\n","26e271be":"#Resulting columns\ndf.columns","29280910":"df.isnull().sum()","7b8b2f96":"# removing NaN from dataset\ndf_NotNull = df.dropna()","1389389d":"df_NotNull.shape","5d8f4b1b":"mask = {'positive': 1, \n        'negative': 0,\n       }\n\ndf_NotNull = df_NotNull.replace(mask)","78a2a384":"# number of each paciente per COVID-19 Result\ndf_NotNull.groupby(\"target\").size()","971515b5":"# Correla\u00e7\u00e3o de Pearson (checando possibilidades de atributos colineares)\ndf_NotNull.corr(method = 'pearson')","a6eafed9":"correlations = df_NotNull.corr()\nk = 22  #number of columns\ncols = correlations.nlargest(k, \"target\")[\"target\"].index\ncm = np.corrcoef(df_NotNull[cols].values.T)\nsns.set(font_scale = 1.25)\nfig, ax = plt.subplots(figsize = (12, 6))\nax = sns.heatmap(cm, vmin = -1, vmax = 1, cmap = \"Reds\", cbar = True, annot = True, square = False, \n                 fmt = \".3f\", annot_kws = {\"size\": 12}, yticklabels = cols.values, xticklabels = cols.values)\nplt.show()","292ddb7c":"# Drop columns with colinear data.\nColunas = ['Hemoglobin','Red_blood_Cells']\ndf_NotNull.drop(Colunas , axis = 1, inplace = True) # 'axis' = 0 (row) | axis = 1 (column)","a6ede5ec":"sns.distplot(df_NotNull.age, fit = stats.norm)","9c0b2fd6":"sns.regplot(x = 'age', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\nsns.regplot(x = 'age', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')","f48958f0":"sns.distplot(df_NotNull.Hematocrit, fit = stats.norm)","6ed139e6":"sns.regplot(x = 'Hematocrit', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\nsns.regplot(x = 'Hematocrit', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')","8fdabe6f":"sns.distplot(df_NotNull.Platelets, fit = stats.norm)","531bbce8":"sns.regplot(x = 'Platelets', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\nsns.regplot(x = 'Platelets', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')","1ed2ef8e":"sns.distplot(df_NotNull.Mean_platelet_volume, fit = stats.norm)","a782a8bb":"sns.regplot(x = 'Mean_platelet_volume', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\nsns.regplot(x = 'Mean_platelet_volume', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')","70e492f4":"sns.distplot(df_NotNull.Lymphocytes, fit = stats.norm)","e4a24d8a":"sns.regplot(x = 'Lymphocytes', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = True, lowess = False, truncate = True, color = \"r\", marker = '.')\nsns.regplot(x = 'Lymphocytes', y = 'target', data = df_NotNull, x_ci = \"sd\", logistic = False, lowess = True, truncate = True, color = \"g\", marker = '.')","f8cdbe4a":"cols = list(df_NotNull.columns.values)\nprint(cols)","8e43603d":"# Move column target to the end of the dataset\n\ndf_NotNull = df_NotNull [['age', 'Hematocrit', 'Platelets', 'Mean_platelet_volume', 'Lymphocytes', 'Mean corpuscular hemoglobin concentration\\xa0(MCHC)', 'Leukocytes', 'Basophils', 'Mean corpuscular hemoglobin (MCH)', 'Eosinophils', 'Mean corpuscular volume (MCV)', 'Monocytes', 'Red blood cell distribution width (RDW)', 'Neutrophils', 'Urea', 'Proteina C reativa mg\/dL', 'Creatinine', 'Potassium', 'Sodium','target']]\ncols = list(df_NotNull.columns.values)\nprint(cols)","6fbae874":"df_NotNull.shape","a59358ec":"# MACHINE LEARNING - SELE\u00c7\u00c3O DE MODELO - auto\n# Import dos m\u00f3dulos\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import fbeta_score\n\ndados =  df_NotNull\narray = dados.values\n\n# Separando o array em componentes de input e output\nX = [array[:, 0:19]]\nstrX =  [\"array[:, 0:19]\"]\nY = array[:, 19]\n\n# Definindo os valores para o n\u00famero de folds\nnum_folds = 10\nseed = 7\na = 0\n\nfor i in X: \n    # Preparando a lista de modelos\n    modelos = []\n    modelos.append(('LR', LogisticRegression()))\n    modelos.append(('LDA', LinearDiscriminantAnalysis()))\n    modelos.append(('NB', GaussianNB()))\n    modelos.append(('KNN', KNeighborsClassifier()))\n    modelos.append(('CART', DecisionTreeClassifier()))\n    modelos.append(('MLPClassifier', MLPClassifier()))\n    modelos.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n    \n    \n\n    # Avaliando cada modelo em um loop\n    resultados = []\n    nomes = []\n\n    for nome, modelo in modelos:\n        kfold = KFold(n_splits = num_folds, shuffle = True, random_state = seed)\n        print(nome)\n        predictions = cross_val_predict(modelo, i, Y, cv = kfold)\n        print(classification_report(Y, predictions, digits = 4))\n        print(\"fbeta :\",fbeta_score(Y, predictions, average='macro', beta=3))\n        print()\n    \n    a = a + 1","01e3764a":"# Import dos m\u00f3dulos\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\n\ndados = df_NotNull\narray = dados.values\n\n# Separando o array em componentes de input e output\nX = array[:, 0:19]\nY = array[:, 19]\n\n# Definindo os valores para o n\u00famero de folds\nnum_folds = 10\nseed = 7\n\n# Separando os dados em folds\nkfold = KFold(num_folds, shuffle = True, random_state = seed)\n\n# Import dos m\u00f3dulos\nfrom sklearn.metrics import classification_report\n\n# Criando o modelo\nmodel_LR = LogisticRegression()\nmodel_LDA = LinearDiscriminantAnalysis()\nmodel_NB = GaussianNB()\nmodel_KNN = KNeighborsClassifier()\nmodel_CART = DecisionTreeClassifier()\nmodel_MLP =  MLPClassifier()\nmodel_Boosting =  GradientBoostingClassifier()\n\n# Cross Validation\nresultado_LR = cross_val_score(model_LR, X, Y, cv = kfold, scoring = 'roc_auc')\nresultado_LDA = cross_val_score(model_LDA, X, Y, cv = kfold, scoring = 'roc_auc')\nresultado_NB = cross_val_score(model_NB, X, Y, cv = kfold, scoring = 'roc_auc')\nresultado_KNN = cross_val_score(model_KNN, X, Y, cv = kfold, scoring = 'roc_auc')\nresultado_CART = cross_val_score(model_CART, X, Y, cv = kfold, scoring = 'roc_auc')\nresultado_MLP = cross_val_score(model_MLP, X, Y, cv = kfold, scoring = 'roc_auc')\nresultado_Boosting = cross_val_score(model_Boosting, X, Y, cv = kfold, scoring = 'roc_auc')\n\n\n# Print do resultado\n\nprint(\"AUC LR: %.3f\" % (resultado_LR.mean() * 100))\nprint(\"AUC LDA: %.3f\" % (resultado_LDA.mean() * 100))\nprint(\"AUC NB: %.3f\" % (resultado_NB.mean() * 100))\nprint(\"AUC KNN: %.3f\" % (resultado_KNN.mean() * 100))\nprint(\"AUC CART: %.3f\" % (resultado_CART.mean() * 100))\nprint(\"AUC MLP: %.3f\" % (resultado_MLP.mean() * 100))\nprint(\"AUC Boosting: %.3f\" % (resultado_Boosting.mean() * 100))\n\nimport matplotlib.patches as patches\nfrom sklearn.metrics import roc_curve,auc\nfrom scipy import interp\n\n# plot arrows\nfig1 = plt.figure(figsize = [12, 12])\nax1 = fig1.add_subplot(111, aspect = 'equal')\nax1.add_patch(\n    patches.Arrow(0.45, 0.5, -0.25, 0.25, width = 0.3, color = 'green', alpha = 0.5)\n    )\nax1.add_patch(\n    patches.Arrow(0.5, 0.45, 0.25, -0.25, width = 0.3, color = 'red', alpha = 0.5)\n    )\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\ni = 1\nfor train,test in kfold.split(X,Y):\n    prediction = model_NB.fit(pd.DataFrame(X).iloc[train],pd.DataFrame(Y).iloc[train]).predict_proba(pd.DataFrame(X).iloc[test])\n    fpr, tpr, t = roc_curve(Y[test], prediction[:, 1])\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw = 2, alpha = 0.3, label = 'ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n    i = i + 1\n\nplt.plot([0, 1],[0, 1], linestyle = '--', lw = 2, color = 'black')\nmean_tpr = np.mean(tprs, axis = 0)\nmean_auc = auc(mean_fpr, mean_tpr)\nplt.plot(mean_fpr, mean_tpr, color = 'blue',\n         label = r'Mean ROC (AUC = %0.2f )' % (mean_auc), lw = 2, alpha = 1)\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC - Naive Bayles')\nplt.legend(loc = \"lower right\")\nplt.text(0.32, 0.7, 'More accurate area', fontsize = 12)\nplt.text(0.63, 0.4, 'Less accurate area', fontsize = 12)\nplt.show()","9fd95622":"# Python script for confusion matrix creation.\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\n\ndados = df_NotNull\narray = dados.values\n\n# Separando o array em componentes de input e output\nX = array[:, 0:19]\nY = array[:, 19]\n\n# Definindo os valores para o n\u00famero de folds\nnum_folds = 10\nseed = 7\n\n# Criando o modelo\nmodelo_opt = GaussianNB(priors=None)\n# modelo_opt.fit(X, Y)\n\n# Fazendo as previs\u00f5es e construindo a Confusion Matrix\n# previsoes_opt = modelo_opt.predict(X)\n# matrix_opt = confusion_matrix(Y, previsoes_opt)\n\nkfold = KFold(n_splits = num_folds, shuffle = True, random_state = seed)\nprevisoes_opt = cross_val_predict(modelo_opt, X, Y, cv = kfold)\nmatrix_opt = confusion_matrix(Y, previsoes_opt)\n\n# Imprimindo a Confusion Matrix\nprint('Confusion Matrix :')\nprint(matrix_opt)\nprint()\nprint('roc_auc Score :',roc_auc_score(Y, previsoes_opt))\nprint()\nprint('Report : ')\nprint(classification_report(Y, previsoes_opt))","5a495373":"### WE VERIFIED THAT THE BEST MODEL TO PREDICT SARS-COV2 WITH OUR PROPOSAL IS NAIVE BAYES.\n### Metrics Priority: RECALL, PRECISION, Fbeta, ROC-AUC\n\nPrimeiramente observamos simultaneamente as m\u00e9tricas **_Recall_** e **_Precision_** especificamente da *classe 1* (positivo) para identificar quais foram os algoritmos com melhor performance. Posterior a essa sele\u00e7\u00e3o, observamos a m\u00e9trica _**f3**_ ( *fbeta* com o par\u00e2metro *beta=3*), de forma que se atribua um peso maior ao **_Recall_** do que ao **_Precision_**. Como \u00fatltima avalia\u00e7\u00e3o, observamos a m\u00e9trica **_ROC-AUC_** para checarmos a performance para definirmos nosso algoritmo final, o qual j\u00e1 informado, o **Naive Bayes - GaussianNB()**.","edd842ab":"### Results:\n\nTASK1 - Predict confirmed COVID-19 cases among suspected cases.\n\n    First, is important to inform that this is a classification problem, with two classes: 0 for Negative SARS-COV-2 and 1 for Positive SARS-COV-2. For better understanding, we named this field as TARGET, because is the result we want to predict with this model.\n    \n    We noticed that not all registers have proper fulfillment, which, in our opinion, represent that not all cases were considered for further research, maybe because the physician judged the full laboratory tests weren't necessary or just because the data collection during the patient\u2019s pass is not adequate. Regardless to this common issues, we notice a higher frequency of data related to blood test ( 11% ) and to others infections detection ( 24% ).\n    \n    Besides this, we identified a low occurrence of positive for SAR-COV-2 (11% of the dataset), which is the target we want to have high precision to predict. Which means that, if we had a dataset with more positive's SAR-COV-2 cases, we could improve the model to detect positives patients.\n\n    Another assumption taken is that all results Negative for SAR-COV-2 is because the test result was negative, and not because no testing was done.\n    \n    Among all the fields available, we noticed the lack of the most important data to improve any COVID-19 prediction model -- Oxygen Saturation by pulse oximeter obtained at the patient's entrance in the emergency room. If this data could be sent, we would certainly have better results, once the COVID-19 often brings respiratory dysfunction.\n    \n    In other to prepare the dataset to start the modeling, we had to remove some columns, either because had too much empty values (NaN), or was collinear with other fields, or simply it had nothing to do with the target.\n\n    \n    Considering this preliminary in sight, here is our findings:\n    \n    The data set have 5644 rows and 111 columns, but only 242 row and 20 columns was used to the research.\n        \n    In our research, we concluded that the NAIVE BAYES model have the best metrics for this problem, as showed bellow:\n    \n    Confusion Matrix :\n    [[167  32]\n     [ 12  31]]\n\n    roc_auc Score : 0.7800631062288185\n\n    Report : \n                  precision    recall  f1-score   support\n\n             0.0       0.93      0.84      0.88       199\n             1.0       0.49      0.72      0.58        43\n\n        accuracy                           0.82       242\n       macro avg       0.71      0.78      0.73       242\n    weighted avg       0.85      0.82      0.83       242\n    \n    \n    Our choice was based on a model with greater recall (less false negatives), greater fbeta (balance between precision and recall, with adjustment favorable to recall), and greater AUC (relationship between sensitivity and specificity or between true positive and false positive rates).\n    \n    We decided to invest on recall metric because we believe this model may help to decide which patients is more likelly to have the COVID-19, in a cenerious that not many testing kits is avalable.\n       \n    The choice was based more emphasys on recall than precision. So far, in the countries affected by the disease, still do not allow a good diagnostic assessment in terms of precision metrics, and for public health, a slower speed of viral transmission is aimed, as well as and greater patient protection, like everyday preventive actions at home, for the most of the mild symptomatic patients (70\/80% of all cases, as the actual reports say).\n\n    Blood count data, added to the patient's clinical data in the emergency room (mainly oxygen saturation by the oximeter), in a model with good recall\/f1 evaluation, seems to be a promise for an adequate screening of positive and negative cases in locations in that there are no specific covid-19 exams.","a7dc8b5a":"# Diagnosis of COVID-19 and its clinical spectrum\n\n### AI and Data Science supporting clinical decisions (from 28th Mar to 1st Apr)\n\n### Team:\n\n1. Dra. Karin Paola Crema - Medical Doctor and pos-gradutated in data science\n2. Luciana Carib\u00e9 Fialho Cantarelli - Computer Scientist and pos-gradutated in data science\n\n### Acknowledgement:\n\n Rodrigo Signorini - Data Scientist and Professor at Hospital Israelita Albert Einstein (HIAE) and Instituto Israelita de Ensino e Pesquisa Albert Einstein (IIEP)\n"}}