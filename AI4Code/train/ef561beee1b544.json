{"cell_type":{"6c0933fc":"code","8b8cfff3":"code","990f079c":"code","b4241d03":"code","98b063bb":"code","b345407c":"code","66c8b792":"code","ee366ee1":"code","4480974f":"code","363aa060":"code","24a21cd9":"code","866f3387":"markdown","9d6d5930":"markdown","172e7a4b":"markdown","931f16b7":"markdown"},"source":{"6c0933fc":"timm_path = \"..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\"\nimport sys\nsys.path.append(timm_path)\nimport timm\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport os\nfrom tqdm.notebook import tqdm\n\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import optim\n\nimport numpy as np, pandas as pd, gc\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\nimport tensorflow as tf\n# from tensorflow.keras.applications import EfficientNetB0\nprint('RAPIDS',cuml.__version__)\nprint('TF',tf.__version__)\nmetric='cosine'\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","8b8cfff3":"COMPUTE_CV = True\n\ntest = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')","990f079c":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\nprint('train shape is', train.shape )\ntrain.head()","b4241d03":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof'] = train.image_phash.map(tmp)","98b063bb":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score","b345407c":"train['f1'] = train.apply(getMetric('oof'),axis=1)\nprint('CV score for baseline =',train.f1.mean())","66c8b792":"if COMPUTE_CV:\n    test = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n    test_gf = cudf.DataFrame(test)\n    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\nelse:\n    test = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    test_gf = cudf.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    print('Test shape is', test_gf.shape )\ntest_gf.head()","ee366ee1":"BASE = '..\/input\/shopee-product-matching\/test_images\/'\nif COMPUTE_CV: BASE = '..\/input\/shopee-product-matching\/train_images\/'\n    \n\nimage_size = 192#256\nvalid_batch_size = 64\n\nvalid_aug = A.Compose([\n    A.LongestMaxSize(max_size=image_size, p=1.0),\n    A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=0, p=1.0),\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0)\n    ])\n\nclass Shopee(Dataset):\n    def __init__(self, df, augs=None):\n        self.df = df\n        self.augs = augs\n        \n    def __len__(self):\n        return(len(self.df))\n    \n    def __getitem__(self,idx):\n        img_src = self.df.loc[idx, 'image']\n        image = cv2.imread(BASE + img_src)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.uint8)\n        \n        if (self.augs):\n            transformed = self.augs(image=image)\n            image = transformed['image']\n            \n        return image\n    \n\ndef test_predict(model, dataloader, device):\n    model.eval()\n    embeds = []\n    \n    with torch.no_grad():    \n        for i, inputs in enumerate(tqdm(dataloader)):\n            inputs = inputs.to(device)\n            features = model(inputs).detach().cpu().numpy()\n            metric = features.reshape(features.shape[0], features.shape[1])\n            embeds.append(metric)\n            \n    return np.concatenate(embeds)\n\nvalid_data = test.copy()\nvalid_data = Shopee(valid_data.reset_index(drop=True), augs = valid_aug)\ntest_loader = DataLoader(valid_data,\n                          shuffle=False,\n                          num_workers=2,\n                          batch_size=valid_batch_size)\n\n\nnum_embeddings = 512\n\nmodel = timm.create_model('dm_nfnet_f0', pretrained=False)\nnum_features = model.head.fc.in_features\nmodel.head.fc = nn.Linear(num_features, num_embeddings)           \n_ = model.to(device)\nweights_path = \"..\/input\/shopee-embedding-df\/dm_nfnet.pth\"\nload_weghts = torch.load(weights_path)\nmodel.load_state_dict(load_weghts)\n\nimage_embeddings = test_predict(model, test_loader, device)\nprint('image embeddings shape',image_embeddings.shape)\n\ndel model\n_ = gc.collect()","4480974f":"KNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN,metric=metric)\nmodel.fit(image_embeddings)","363aa060":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings)\/\/CHUNK\nif len(image_embeddings)%CHUNK!=0: CTS += 1\nfor j in tqdm(range( CTS )):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(image_embeddings))\n    distances, indices = model.kneighbors(image_embeddings[a:b,])\n    \n    for k in range(b-a):\n        IDX = np.where(distances[k,]<0.65)[0]\n        IDS = indices[k,IDX]\n        o = test.iloc[IDS].posting_id.values\n        preds.append(o)\n\n_ = gc.collect()\n\ntest['image_embeddings'] = preds","24a21cd9":"if COMPUTE_CV:\n    tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n    test['target'] = test.label_group.map(tmp)\n    test['f1'] = test.apply(getMetric('image_embeddings'),axis=1)\n    print(f\" CV score for baseline =\",test.f1.mean())","866f3387":"# Use Image Embeddings","9d6d5930":"# Compute Baseline CV Score","172e7a4b":"# Load Train Data","931f16b7":"# Compute RAPIDS Model CV and Infer Submission"}}