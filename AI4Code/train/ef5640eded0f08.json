{"cell_type":{"2662c32a":"code","a10a6778":"code","834b0c9f":"code","18d751e8":"code","c5ecc61d":"code","63ba9446":"code","d9ea52bf":"code","4eb43899":"code","f8d7c2fb":"code","fef85542":"code","2a246667":"code","149a33c8":"code","bba84125":"code","5bee5537":"code","8fecf026":"code","1e51144f":"code","4661ad15":"code","5dc07c8c":"code","5aa76a06":"code","de596ace":"code","a78fb566":"markdown","856948e4":"markdown","19903739":"markdown","1600efde":"markdown","1eec6421":"markdown","273662c3":"markdown","81ee401b":"markdown","0d98a662":"markdown","49a3ffad":"markdown","811eaa50":"markdown","824028e9":"markdown","e885460b":"markdown","82201c46":"markdown","54c70dc2":"markdown","2b8e3319":"markdown"},"source":{"2662c32a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Other libraries import...\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\ntrain = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\n\nprint(\"The shape train data is \" + str(train.shape))\n# See how the data is like...\nprint(train.describe())","a10a6778":"# Check if there is any duplicate...\nduplicate_count = train[\"Id\"].nunique() - train.shape[0];\nif(duplicate_count == 0):\n    print(\"There is no duplicate data in the train data.\")\nelse:\n    print(\"There are %d duplicate data in the train data.\" %duplicate_count)\ntrain.drop(\"Id\", axis = 1, inplace = True)","834b0c9f":"sns.distplot(train['SalePrice'], kde=False)","18d751e8":"med = train['SalePrice'].median()\nmedAbsDev = abs(train['SalePrice'] - med).median()\n# expected value of MAD = 0.6745 * sigma\nind = (abs(train['SalePrice'] - med)*.6745 \/ medAbsDev) > 3.5\nprint(\"There are suspected %d outliers in the train data.\" % sum(ind))\ntrain = train[-ind]\n# removing further data as suggested by the author of the dataset\n# https:\/\/ww2.amstat.org\/publications\/jse\/v19n3\/decock.pdf\ntrain = train[train.GrLivArea < 4000]","c5ecc61d":"sns.heatmap(train.isnull(), yticklabels=False, cbar=False)","63ba9446":"train[\"Alley\"].fillna(\"None\", inplace=True) # NA = \"no alley access\"\ntrain[\"BsmtQual\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtCond\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtExposure\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtFinType1\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtFinSF1\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtFinType2\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtFinSF2\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtFullBath\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtHalfBath\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntrain[\"BsmtUnfSF\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntrain[\"TotalBsmtSF\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntrain[\"KitchenQual\"].fillna(0, inplace=True)\ntrain[\"Functional\"].fillna(0, inplace=True)\ntrain[\"FireplaceQu\"].fillna(\"None\", inplace=True) # NA = \"No Fireplace\"\ntrain[\"GarageType\"].fillna(\"None\", inplace=True) # NA = \"No Garage\"\ntrain[\"GarageQual\"].fillna(0, inplace=True) # NA = \"No Garage\"\ntrain[\"GarageCond\"].fillna(0, inplace=True) # NA = \"No Garage\"\ntrain[\"GarageYrBlt\"].fillna(\"None\", inplace=True) # NA = \"No Garage\"\ntrain[\"GarageFinish\"].fillna(\"None\", inplace=True) # NA = \"No Garage\"\ntrain[\"GarageCars\"].fillna(0, inplace=True) # NA = \"No Garage\"\ntrain[\"GarageArea\"].fillna(0, inplace=True) # NA = \"No Garage\"\ntrain[\"PoolQC\"].fillna(\"None\", inplace=True) # NA = \"No Pool\"\ntrain[\"Fence\"].fillna(\"None\", inplace=True) # NA = \"No Fence\"\ntrain[\"MiscFeature\"].fillna(\"None\", inplace=True) # NA = \"No MiscFeature\"\n\n# not clearly described\ntrain[\"LotFrontage\"].fillna(0, inplace=True)\ntrain[\"MasVnrType\"].fillna(\"None\", inplace=True)\ntrain[\"MasVnrArea\"].fillna(0, inplace=True)\ntrain[\"Electrical\"].fillna(\"SBrkr\", inplace=True)\ntrain[\"Utilities\"].fillna(\"None\", inplace=True)\n\n# no missing data\n# MSZoning, LotArea, Street, LotShape, LandContour, Utilities, LotConfig, LandSlope, Neighborhood, Condition1\n# Condition2, BldgType, HouseStyle, OverallQual, OverallCond, YearBuilt, YearRemodAdd, RoofStyle, RoofMatl\n# Exterior1st, Exterior2nd, ExterQual, ExterCond, Foundation, Heating, HeatingQC, CentralAir, 1stFlrSF, 2ndFlrSF\n# LowQualFinSF, GrLivArea, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr\n# TotRmsAbvGrd, Fireplaces, GarageCars, GarageArea, PavedDrive, WoodDeckSF, OpenPorchSF, EnclosedPorch\n# 3SsnPorch, ScreenPorch, PoolArea, MiscVal, MoSold, YrSold, SaleType, SaleCondition","d9ea52bf":"# convert suitable numerical columns to categorical columns\ntrain = train.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", 50 : \"SC50\", 60 : \"SC60\",\n    70 : \"SC70\", 75 : \"SC75\", 80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", 150 : \"SC150\", 160 : \"SC160\",\n    180 : \"SC180\", 190 : \"SC190\"},\n\"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\", 7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\",\n    10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"} })\n\n# convert suitable categorical columns to numerical columns\ntrain = train.replace({\"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n\"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n\"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6},\n\"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6},\n\"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n\"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n\"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n\"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n\"GarageCond\" : {\"None\" : 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"GarageQual\" : {\"None\" : 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n\"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n\"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n\"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n\"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n\"Utilities\" : {\"None\" : 0, \"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}} )","4eb43899":"# Grade\ntrain[\"OverallGrade\"] = train[\"OverallQual\"] * train[\"OverallCond\"]\ntrain[\"GarageGrade\"] = train[\"GarageQual\"] * train[\"GarageCond\"]\ntrain[\"ExterGrade\"] = train[\"ExterQual\"] * train[\"ExterCond\"]\n\n# Score\ntrain[\"KitchenScore\"] = train[\"KitchenAbvGr\"] * train[\"KitchenQual\"]\ntrain[\"FireplaceScore\"] = train[\"Fireplaces\"] * train[\"FireplaceQu\"]\ntrain[\"GarageScore\"] = train[\"GarageArea\"] * train[\"GarageQual\"]\ntrain[\"PoolScore\"] = train[\"PoolArea\"] * train[\"PoolQC\"]\n\n# Aggregate\ntrain[\"TotalBath\"] = train[\"BsmtFullBath\"] + train[\"BsmtHalfBath\"]\/2 + train[\"FullBath\"] + train[\"HalfBath\"]\/2\ntrain[\"AllSF\"] = train[\"GrLivArea\"] + train[\"TotalBsmtSF\"]\ntrain[\"AllFlrsSF\"] = train[\"1stFlrSF\"] + train[\"2ndFlrSF\"]\ntrain[\"AllPorchSF\"] = train[\"OpenPorchSF\"] + train[\"EnclosedPorch\"] + train[\"3SsnPorch\"] + train[\"ScreenPorch\"]","f8d7c2fb":"corr = train.corr()\ncorr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\ncorr.SalePrice","fef85542":"train[\"AllSF-s2\"] = train[\"AllSF\"] ** 2\n#train[\"AllSF-s3\"] = train[\"AllSF\"] ** 3\ntrain[\"AllSF-Sq\"] = np.sqrt(train[\"AllSF\"])\ntrain[\"OverallQual-s2\"] = train[\"OverallQual\"] ** 2\n#train[\"OverallQual-s3\"] = train[\"OverallQual\"] ** 3\ntrain[\"OverallQual-Sq\"] = np.sqrt(train[\"OverallQual\"])\ntrain[\"AllFlrsSF-s2\"] = train[\"AllFlrsSF\"] ** 2\n#train[\"AllFlrsSF-s3\"] = train[\"AllFlrsSF\"] ** 3\ntrain[\"AllFlrsSF-Sq\"] = np.sqrt(train[\"AllFlrsSF\"])\ntrain[\"GrLivArea-s2\"] = train[\"GrLivArea\"] ** 2\n#train[\"GrLivArea-s3\"] = train[\"GrLivArea\"] ** 3\ntrain[\"GrLivArea-Sq\"] = np.sqrt(train[\"GrLivArea\"])\ntrain[\"ExterQual-s2\"] = train[\"ExterQual\"] ** 2\n#train[\"ExterQual-s3\"] = train[\"ExterQual\"] ** 3\ntrain[\"ExterQual-Sq\"] = np.sqrt(train[\"ExterQual\"])","2a246667":"categorical_features = train.select_dtypes(include = [\"object\"]).columns\nnumerical_features = train.select_dtypes(exclude = [\"object\"]).columns\nnumerical_features = numerical_features.drop(\"SalePrice\")\ntrain_num = train[numerical_features]\ntrain_cat = train[categorical_features]\n\nfrom scipy.stats import skew\nskewness = train_num.apply(lambda x: skew(x))\nskewness = skewness[abs(skewness) > 0.5]\nprint(\"%d out of %d numerical features are skewed. Apply log transform to these features.\" % (skewness.shape[0],\n    train_num.shape[1]))\ntrain_num.loc[:,skewness.index] = np.log1p(np.asarray(train_num[skewness.index] , dtype=float))\n\n# Apply one-hot encoding on columns of categorical features\ntrain_cat = pd.get_dummies(train_cat)","149a33c8":"y = np.log1p(train[\"SalePrice\"])\nX_train, X_test, y_train, y_test = train_test_split(pd.concat([train_num, train_cat], axis = 1),\n                                                    y, test_size = 0.3, random_state = 514)\n# apply fitting only on training data\nstdSc = StandardScaler()\nX_train.loc[:, numerical_features] = stdSc.fit_transform(X_train.loc[:, numerical_features])\nX_test.loc[:, numerical_features] = stdSc.transform(X_test.loc[:, numerical_features])","bba84125":"# Define function of error measure to be root-mean-square error. Apply cross-validation using the error function.\nfrom sklearn.metrics import mean_squared_error, make_scorer\nscorer = make_scorer(mean_squared_error, greater_is_better = True)\n\ndef rmse_cv_train(model):\n    rmse = np.sqrt(cross_val_score(model, X_train, y_train, scoring = scorer, cv = 10))\n    return(rmse)\n\ndef rmse_cv_test(model):\n    rmse = np.sqrt(cross_val_score(model, X_test, y_test, scoring = scorer, cv = 10))\n    return(rmse)","5bee5537":"from sklearn.linear_model import LinearRegression\n# Linear Regression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nprint(\"Mean RMSE on Training set :\", rmse_cv_train(lr).mean()) # to-do: check why surprisingly high values may come up\nprint(\"Mean RMSE on Test set :\", rmse_cv_test(lr).mean())\ny_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\n\n# Plot residuals (using code by Julien)\nplt.scatter(y_train_pred, y_train_pred - y_train, c = \"blue\", marker = \"s\", label = \"Training House Prices\")\nplt.scatter(y_test_pred, y_test_pred - y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation House Prices\")\nplt.title(\"Linear regression\")\nplt.xlabel(\"Predicted values\")\nplt.ylabel(\"Residuals\")\nplt.legend(loc = \"upper left\")\nplt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\nplt.show()\n\n# Plot predictions\nplt.scatter(y_train_pred, y_train, c = \"blue\", marker = \"s\", label = \"Training House Prices\")\nplt.scatter(y_test_pred, y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation House Prices\")\nplt.title(\"Linear regression\")\nplt.xlabel(\"Predicted House Prices\")\nplt.ylabel(\"Real House Prices\")\nplt.legend(loc = \"upper left\")\nplt.show()","8fecf026":"# roughly search alpha and l1_ratio\nfrom sklearn.linear_model import ElasticNetCV\nelasticNet = ElasticNetCV(l1_ratio = [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1],\n                          alphas = [0.0001, 0.001, 0.01, 0.1, 1], \n                          max_iter = 50000, cv = 10)\nelasticNet.fit(X_train, y_train)\nalpha = elasticNet.alpha_\nratio = elasticNet.l1_ratio_\nprint(\"Best l1_ratio :\", ratio)\nprint(\"Best alpha :\", alpha )","1e51144f":"print(\"Try again for more precision with l1_ratio centered around \" + str(ratio))\nelasticNet = ElasticNetCV(l1_ratio = [ratio * .9, ratio * .95, ratio, ratio * 1.05, ratio * 1.1],\n                          alphas = [0.0001, 0.001, 0.01, 0.1, 1], \n                          max_iter = 50000, cv = 10)\nelasticNet.fit(X_train, y_train)\nalpha = elasticNet.alpha_\nratio = elasticNet.l1_ratio_\nprint(\"Best l1_ratio :\", ratio)\nprint(\"Best alpha :\", alpha )","4661ad15":"print(\"Now try again for more precision on alpha, with l1_ratio fixed at \" + str(ratio) + \n      \" and alpha centered around \" + str(alpha))\nelasticNet = ElasticNetCV(l1_ratio = ratio,\n                          alphas = [alpha * .6, alpha * .7, alpha * .8, alpha * .9, \n                                    alpha, alpha * 1.1, alpha * 1.2, alpha * 1.3, alpha * 1.4], \n                          max_iter = 50000, cv = 5)\nelasticNet.fit(X_train, y_train)\nprint(\"Best l1_ratio :\", elasticNet.l1_ratio_)\nprint(\"Best alpha :\", elasticNet.alpha_ )\n\nprint(\"ElasticNet RMSE on Training set :\", rmse_cv_train(elasticNet).mean())\nprint(\"ElasticNet RMSE on Test set :\", rmse_cv_test(elasticNet).mean())\ny_train_ela = elasticNet.predict(X_train)\ny_test_ela = elasticNet.predict(X_test)","5dc07c8c":"# Plot residuals\nplt.scatter(y_train_ela, y_train_ela - y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\nplt.scatter(y_test_ela, y_test_ela - y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\nplt.title(\"Linear regression with ElasticNet regularization\")\nplt.xlabel(\"Predicted values\")\nplt.ylabel(\"Residuals\")\nplt.legend(loc = \"upper left\")\nplt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\nplt.show()\n\n# Plot predictions\nplt.scatter(y_train, y_train_ela, c = \"blue\", marker = \"s\", label = \"Training data\")\nplt.scatter(y_test, y_test_ela, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\nplt.title(\"Linear regression with ElasticNet regularization\")\nplt.xlabel(\"Predicted values\")\nplt.ylabel(\"Real values\")\nplt.legend(loc = \"upper left\")\nplt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")\nplt.show()\n\n# Plot important coefficients\ncoefs = pd.Series(elasticNet.coef_, index = X_train.columns)\nprint(\"ElasticNet picked \" + str(sum(coefs != 0)) + \" features and eliminated the other \" +  str(sum(coefs == 0)) + \" features\")\nimp_coefs = pd.concat([coefs.sort_values().head(10),\n                     coefs.sort_values().tail(10)])\nimp_coefs.plot(kind = \"barh\")\nplt.title(\"Coefficients in the ElasticNet Model\")\nplt.show()","5aa76a06":"test = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\ntest[\"Alley\"].fillna(\"None\", inplace=True) # NA = \"no alley access\"\ntest[\"BsmtQual\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntest[\"BsmtCond\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntest[\"BsmtExposure\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntest[\"BsmtFinType1\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntest[\"BsmtFinSF1\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntest[\"BsmtFinType2\"].fillna(\"None\", inplace=True) # NA = \"No Basement\"\ntest[\"BsmtFinSF2\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntest[\"BsmtFullBath\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntest[\"BsmtHalfBath\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntest[\"BsmtUnfSF\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntest[\"TotalBsmtSF\"].fillna(0, inplace=True) # NA = \"No Basement\"\ntest[\"KitchenQual\"].fillna(0, inplace=True)\ntest[\"Functional\"].fillna(0, inplace=True)\ntest[\"FireplaceQu\"].fillna(\"None\", inplace=True) # NA = \"No Fireplace\"\ntest[\"GarageType\"].fillna(\"None\", inplace=True) # NA = \"No Garage\"\ntest[\"GarageQual\"].fillna(0, inplace=True) # NA = \"No Garage\"\ntest[\"GarageCond\"].fillna(0, inplace=True) # NA = \"No Garage\"\ntest[\"GarageYrBlt\"].fillna(\"None\", inplace=True) # NA = \"No Garage\"\ntest[\"GarageFinish\"].fillna(\"None\", inplace=True) # NA = \"No Garage\"\ntest[\"GarageCars\"].fillna(0, inplace=True) # NA = \"No Garage\"\ntest[\"GarageArea\"].fillna(0, inplace=True) # NA = \"No Garage\"\ntest[\"PoolQC\"].fillna(\"None\", inplace=True) # NA = \"No Pool\"\ntest[\"Fence\"].fillna(\"None\", inplace=True) # NA = \"No Fence\"\ntest[\"MiscFeature\"].fillna(\"None\", inplace=True) # NA = \"No MiscFeature\"\n\ntest[\"LotFrontage\"].fillna(0, inplace=True)\ntest[\"MasVnrType\"].fillna(\"None\", inplace=True)\ntest[\"MasVnrArea\"].fillna(0, inplace=True)\ntest[\"Electrical\"].fillna(\"SBrkr\", inplace=True)\ntest[\"Utilities\"].fillna(\"None\", inplace=True)\n\ntest = test.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", 50 : \"SC50\", 60 : \"SC60\",\n    70 : \"SC70\", 75 : \"SC75\", 80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", 150 : \"SC150\", 160 : \"SC160\",\n    180 : \"SC180\", 190 : \"SC190\"},\n\"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\", 7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\",\n    10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"} })\n\ntest = test.replace({\"Alley\" : {\"Grvl\" : 1, \"Pave\" : 2},\n\"BsmtCond\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"BsmtExposure\" : {\"No\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n\"BsmtFinType1\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6},\n\"BsmtFinType2\" : {\"No\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6},\n\"BsmtQual\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n\"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n\"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n\"FireplaceQu\" : {\"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n\"GarageCond\" : {\"None\" : 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"GarageQual\" : {\"None\" : 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n\"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n\"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n\"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n\"PoolQC\" : {\"No\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n\"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n\"Utilities\" : {\"None\" : 0, \"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4}} )\n\ntest[\"OverallGrade\"] = test[\"OverallQual\"] * test[\"OverallCond\"]\ntest[\"GarageGrade\"] = test[\"GarageQual\"] * test[\"GarageCond\"]\ntest[\"ExterGrade\"] = test[\"ExterQual\"] * test[\"ExterCond\"]\n\ntest[\"KitchenScore\"] = test[\"KitchenAbvGr\"] * test[\"KitchenQual\"]\ntest[\"FireplaceScore\"] = test[\"Fireplaces\"] * test[\"FireplaceQu\"]\ntest[\"GarageScore\"] = test[\"GarageArea\"] * test[\"GarageQual\"]\ntest[\"PoolScore\"] = test[\"PoolArea\"] * test[\"PoolQC\"]\n\ntest[\"TotalBath\"] = test[\"BsmtFullBath\"] + test[\"BsmtHalfBath\"]\/2 + test[\"FullBath\"] + test[\"HalfBath\"]\/2\ntest[\"AllSF\"] = test[\"GrLivArea\"] + test[\"TotalBsmtSF\"]\ntest[\"AllFlrsSF\"] = test[\"1stFlrSF\"] + test[\"2ndFlrSF\"]\ntest[\"AllPorchSF\"] = test[\"OpenPorchSF\"] + test[\"EnclosedPorch\"] + test[\"3SsnPorch\"] + test[\"ScreenPorch\"]\n\ntest[\"AllSF-s2\"] = test[\"AllSF\"] ** 2\n#test[\"AllSF-s3\"] = test[\"AllSF\"] ** 3\ntest[\"AllSF-Sq\"] = np.sqrt(test[\"AllSF\"])\ntest[\"OverallQual-s2\"] = test[\"OverallQual\"] ** 2\n#test[\"OverallQual-s3\"] = test[\"OverallQual\"] ** 3\ntest[\"OverallQual-Sq\"] = np.sqrt(test[\"OverallQual\"])\ntest[\"AllFlrsSF-s2\"] = test[\"AllFlrsSF\"] ** 2\n#test[\"AllFlrsSF-s3\"] = test[\"AllFlrsSF\"] ** 3\ntest[\"AllFlrsSF-Sq\"] = np.sqrt(test[\"AllFlrsSF\"])\ntest[\"GrLivArea-s2\"] = test[\"GrLivArea\"] ** 2\n#test[\"GrLivArea-s3\"] = test[\"GrLivArea\"] ** 3\ntest[\"GrLivArea-Sq\"] = np.sqrt(test[\"GrLivArea\"])\ntest[\"ExterQual-s2\"] = test[\"ExterQual\"] ** 2\n#test[\"ExterQual-s3\"] = test[\"ExterQual\"] ** 3\ntest[\"ExterQual-Sq\"] = np.sqrt(test[\"ExterQual\"])\n\ntest_num = test[numerical_features]\ntest_cat = test[categorical_features]\ntest_num.loc[:,skewness.index] = np.log1p(np.asarray(test_num[skewness.index] , dtype=float))\ntest_cat = pd.get_dummies(test_cat)\ntest_processed = pd.concat([test_num, test_cat], axis = 1)\ntest_processed.loc[:, numerical_features] = stdSc.transform(test_processed.loc[:, numerical_features])","de596ace":"final_train, final_test = X_train.align(test_processed, join='left', axis=1, fill_value=0)\ny_test = elasticNet.predict(final_test)\nsub = pd.DataFrame()\nsub['Id'] = test[\"Id\"]\nsub['SalePrice'] = np.expm1(y_test)\nsub.to_csv('submission.csv',index=False)","a78fb566":"Finally we apply our model to the test and submit the result. ","856948e4":"There are many columns that contain missing values. We can get how to deal with these missing data from the data description, and perform necessary conversion of numeric and categorical columns...","19903739":"Apply log transform of the skewed (with absolute value of skewness > 0.5) numerical features to lessen impact of outliers...\n\nRef: [Alexandru Papiu's script](https:\/\/www.kaggle.com\/apapiu\/house-prices-advanced-regression-techniques\/regularized-linear-models)","1600efde":"Apply StandardScaler to all numerical features after splitting of train set and data set...","1eec6421":"# Data visualization\nLet's have a first glance of data by visualizing the data feature...","273662c3":"Then we check the quality of data by viewing proportion of missing data by a heatmap...","81ee401b":"Practice linear regression and regularization algorithm.\n\nRef: [A study on Regression applied to the Ames dataset][1] by **Julien Cohen-Solal**\n\n[1]: https:\/\/www.kaggle.com\/juliencs\/a-study-on-regression-applied-to-the-ames-dataset","0d98a662":"It seems that there are quite a number of house prices that are \"abnormally\" high. Let's first calculate a robost estimator using the median absolute deviation. Then identify potential outliers from the corresponding modified z-scores with values higher than 3.5...\nAlso, it should be necessarily to apply log-transform since it is pretty skewed...","49a3ffad":"Many of the features seem reductant. We will create some more features:\n* Grade as Quality * Cond\n* Score as (Count or Area) * Quality\n* Aggregate as sum of (Count or Area) of similar features\n* square\/cubic\/root of the 5 most correlated features with sale prices","811eaa50":"We are ready to perform linear regression...","824028e9":"Create new features: up to cubic polynomials on the top 5 existing features...","e885460b":"The model is now ready. To predict the sale prices on the test data provided by this competition, the same feature \nengineering procedure must be applied first...","82201c46":"Note that we have improved RMSE on test set significiantly, probably a signal of overfitting in the regression model without regularization. ","54c70dc2":"The performance of the above linear regression is not bad. We can proceed to add regularation to the model. We directly apply ElasticNet, adding both L1 (Lasso) and L2 (Ridge) regularation to the model. We have to try using different regularation parameters (alpha and l1_ratio) to test which perform the best...","2b8e3319":"Apply correlation of SalePrice to other columns to find out the most important features..."}}