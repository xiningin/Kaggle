{"cell_type":{"e5ea856d":"code","4eb6f0b8":"code","ff246121":"code","967d4521":"code","0fcb3c8f":"code","0f4432b0":"code","0c7032b0":"code","1f2af774":"code","312b3e79":"code","fbf0b2b7":"code","aea95239":"code","d71d4d90":"code","c97d7d36":"code","8236d555":"code","9c9bd46a":"code","308e0cdc":"code","77e5d953":"code","5766dafd":"code","f9a7a5b9":"code","3fe19966":"code","a01b3e78":"code","c367f772":"code","b777c75b":"code","49c43023":"code","756a3091":"markdown","17464cf5":"markdown","9862c96b":"markdown","3f720be5":"markdown","09d507b4":"markdown","ebb5b74b":"markdown"},"source":{"e5ea856d":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nsns.set()","4eb6f0b8":"data = pd.read_csv(\"Classified Data\"  ,index_col=0)","ff246121":"data.head()","967d4521":"sns.pairplot(data)","0fcb3c8f":"from sklearn.preprocessing import StandardScaler","0f4432b0":"ss = StandardScaler()","0c7032b0":"ss.fit(data.drop('TARGET CLASS' , axis = 1))","1f2af774":"scaled_data = ss.transform(data.drop('TARGET CLASS' , axis = 1))","312b3e79":"scaled = pd.DataFrame(scaled_data , columns = data.columns[:-1])","fbf0b2b7":"scaled","aea95239":"from sklearn.model_selection import train_test_split\n","d71d4d90":"X_train , X_test , y_train , y_test = train_test_split( scaled , data['TARGET CLASS'] , test_size = 0.3 , random_state = 50)","c97d7d36":"from sklearn.neighbors import KNeighborsClassifier","8236d555":"knn = KNeighborsClassifier( n_neighbors = 5 )","9c9bd46a":"knn.fit(X_train , y_train)","308e0cdc":"pred = knn.predict(X_test)","77e5d953":"from sklearn.metrics import classification_report , confusion_matrix","5766dafd":"print( confusion_matrix( y_test , pred ))","f9a7a5b9":"print(classification_report(y_test,pred))","3fe19966":"# will try to select the k with min error rate \n\nerror_rate = []\n \nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n        ","a01b3e78":"plt.figure(figsize=(10,8))\n\nplt.plot( range(1,40) , error_rate , color = 'blue' , linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)","c367f772":"# lowest seems for 22 , will run the model again with 22 as K ","b777c75b":"knn = KNeighborsClassifier( n_neighbors = 22 )\nknn.fit(X_train , y_train)\npred_i = knn.predict(X_test)\nprint( confusion_matrix( y_test , pred_i ))","49c43023":"print(classification_report(y_test,pred_i))","756a3091":"# Standardize the Variables\nBecause the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the observations, and hence on the KNN classifier, than variables that are on a small scale.","17464cf5":"# Loading the KNN model ","9862c96b":"# Selecting perfect k value with elbow method","3f720be5":"# Evaluate the model ","09d507b4":"### We were able to squeeze some more performance out of our model by tuning to a better K value!","ebb5b74b":"# Train Test Split"}}