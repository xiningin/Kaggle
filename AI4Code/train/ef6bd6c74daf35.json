{"cell_type":{"eff0eacf":"code","acedf840":"code","6e7478ca":"code","1a787e3d":"code","73ab7b7c":"code","6335e8bc":"code","57b2d71e":"code","307aa07a":"code","c409aba4":"code","e564ba8a":"code","85972115":"code","b2dc5bc1":"code","8a1d5dfb":"code","f981d4c5":"code","92246d46":"code","ac2cb4ce":"code","f6864448":"code","90d92b67":"code","c9cf22a1":"markdown","5a39e04c":"markdown","d4da89ea":"markdown","00b8f545":"markdown","2cd074c1":"markdown"},"source":{"eff0eacf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","acedf840":"import pandas as pd\ndata = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\",low_memory=False)\ndata.head()","6e7478ca":"# pd.set_option(\"display.max_rows\",500)\n# pd.set_option(\"display.max_columns\",500)\n# pd.set_option('display.float_format', '{:.2f}'.format)","1a787e3d":"for i in data.loc[0]:\n    print(i)","73ab7b7c":"questions=data.loc[0]","6335e8bc":"data=data.drop(0)","57b2d71e":"for col in data.columns:\n  if data[col].nunique() == 1:\n    values=data[col].unique()\n    if pd.isna(values[0]):\n      col_name='_'.join([col.split('_')[0],data[col].unique()[1].lstrip().rstrip().replace(' ','-')])\n    else:\n      col_name='_'.join([col.split('_')[0],data[col].unique()[0].lstrip().rstrip().replace(' ','-')])\n    data[col]=data[col].apply(lambda x : 0 if pd.isna(x) else 1 )\n    data.rename(columns={col: col_name},inplace=True)","307aa07a":"for ind in questions.index:\n  if '_' not in ind:\n    # print(ind,\":\",questions[ind])\n    print(\"\\n\",questions[ind])\n    print(data[ind].value_counts())","c409aba4":"import seaborn as sns\nimport matplotlib.pyplot as plt","e564ba8a":"for ind in questions.index:\n  if '_' not in ind:\n    # print(ind,\":\",questions[ind])\n    plt.style.use('seaborn-whitegrid')\n    fig = plt.figure(figsize=(20,7))\n    ax = plt.axes()\n    plt.xlabel(questions[ind])\n    ax.plot(data[ind].value_counts().index, data[ind].value_counts())\n#     sns.barplot(x=data[ind].value_counts(), y=data[ind].value_counts().index, orient=\"v\", data=data, estimator=lambda x: len(x) \/ len(data) * 100)","85972115":"%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')","b2dc5bc1":"qSets=[]\nfor i in range(1,35):\n    mstr='Q'+str(i)\n#     print([x for x in data.columns if x.split('_')[0] == mstr])\n    qSets.append([x for x in data.columns if x.split('_')[0] == mstr])","8a1d5dfb":"for i in qSets:\n    if len(i)==1:\n        plt.figure(figsize=(16,6))\n#         print(i[0])\n        ln_grph = sns.barplot(x=i[0], y=i[0], orient=\"v\", data=data, estimator=lambda x: len(x) \/ len(data) * 100)\n        ln_grph.set(ylabel=\"Percent\")","f981d4c5":"for i in qSets:\n    if len(i)>1:\n        tmp=i+['Q1']\n        print(data[tmp].sum())","92246d46":"#Plot graph to get insight of defaulters percentage\nplt.figure(figsize=(16,6))\nln_grph = sns.barplot(x=\"Q2\", y=\"Q1\", orient=\"v\", data=data, estimator=lambda x: len(x) \/ len(data) * 100)\nln_grph.set(ylabel=\"Percent\")","ac2cb4ce":"for i in qSets:\n    if len(i)==1:\n        temp = data.groupby(['Q1',i[0]])[i[0]].count()\n        tmp=temp \/ temp.groupby(level=0).sum()*100\n\n        data1=pd.DataFrame()\n        for l in data.Q1.unique():\n            data1=data1.append(tmp[l])\n\n        data1['Q1']=data.Q1.unique()\n        data1.set_index('Q1',inplace=True)\n        #print(data.index)\n        plt.figure(figsize=(20,6))\n        grph = data1.sort_index().plot.barh(figsize=(20,7),stacked=True)\n        grph.set_xlabel(\"Percentage\")\n        grph.set_ylabel(\"Age\")","f6864448":"summary='<h2 style=\"color:blue;\"> This data says the today\\'s trend is more keen towards datasciences.<br>\\\nAmong the different countries the India and United States are more involved.<\/h2>'","90d92b67":"data_to_submit=pd.DataFrame([\"summary\",summary])\ndata_to_submit.to_csv('csv_to_submit_5.csv', header=True, index = False)","c9cf22a1":"<h2 style=\"color:blue;\"> This data says the today's trend is more keen towards datasciences.<br>\nAmong the different countries the India and United States are more involved.<\/h2>","5a39e04c":"# Summary","d4da89ea":"<ul>\n    <li>People of age between 20-30 are showing intreset towards the Datascience.<\/li>\n<li>Out of total no.of members participated in the servey, man are more compared to woman, \n    this also shows that more woman are moving towards datasciences.<\/li>\n<li>Majority of members are from India followed United states who are intreseted in Datasciences. <\/li>\n<li>Python is the most preferred language among all others.<\/li>\n<li>Most of the members are using their own laptops\/computers followed by cloud.<\/li>\n<li>Most of the members are keep learning as they getting experience and doing higher studies.<\/li>\n<li>Tableau is being used as business intellignence tools compared to all other tools.<\/li>\n<li>Mysql is the most used database language by all age groups.<\/li>\n<li>Members who are working in small companies\/startups are looking towards Data sciences.<\/li>\n<li>Members who has 3-5 years of experience in writting code are working in data sciences.<\/li>\n<li>Members who are having less money are more learning and working towards data sciences \n    to get better opportunities to increases their pay scales.<\/ul>","00b8f545":"## List of question that are asked in the survey","2cd074c1":"### Important Insights"}}