{"cell_type":{"4d3da1d6":"code","77059328":"code","6c4ce713":"code","4d909aa2":"code","39c31023":"code","926f0f17":"code","452e478f":"code","7462fa67":"code","8f67b38f":"code","480ac9ba":"code","7e0da49a":"code","2a47a4da":"code","5a91b663":"code","b22a99d3":"code","9fea7f34":"code","f3ea7a99":"code","79fe8852":"code","73216b57":"code","acaf81c2":"code","492fd035":"code","65cb4978":"code","ba3e0a99":"code","5adc07a6":"code","a5162ca1":"code","00bd6192":"code","e24d3211":"code","e815cbed":"code","ae07aa17":"code","f847da7d":"code","c72a93f7":"code","7f2cb883":"code","86235691":"code","3169b037":"code","711b940e":"code","105ae13f":"code","7edc5223":"code","b7d9d571":"code","7e679ee8":"code","73d23b9f":"code","668a7253":"code","f89714c2":"code","41570469":"code","2be32032":"code","15c238d5":"code","8e891172":"code","a29aaddf":"code","94720976":"code","0f1d8f83":"code","ce5032c4":"code","3382b8e8":"code","38db311c":"code","23e56b16":"code","233a79c0":"code","b23234d2":"code","9dbcad53":"code","7f04579f":"code","315d2b70":"code","828ffff1":"code","a43e9d68":"code","2a1f2b16":"code","b4054ed9":"code","3f352a76":"code","53c75019":"code","8de34595":"code","dc8435a8":"code","dcec3b60":"code","05bb9c8e":"code","c6600ad6":"code","edf2a231":"code","66a1159a":"code","6048534b":"code","faed71b0":"code","06baeedb":"code","ffe06bfa":"code","919451dc":"code","9259a60e":"code","0816233c":"markdown","b8fcfb07":"markdown","63b786ea":"markdown","9e334440":"markdown","5cdd7c3c":"markdown","21b4f281":"markdown","c7b22f3e":"markdown","be67b0aa":"markdown","9585a9bc":"markdown","cbb51a9d":"markdown","82d16ddb":"markdown","7697d81a":"markdown","2fdee647":"markdown","0b890771":"markdown","f027436d":"markdown","68849678":"markdown","fe644055":"markdown","60dcfe17":"markdown","958c4984":"markdown","e106a898":"markdown","20d81ec8":"markdown","cf4373a1":"markdown","3b6b462c":"markdown","0dff053a":"markdown","2acd6b8f":"markdown","88b4b2c2":"markdown","9caa4466":"markdown","7727bb43":"markdown","4679ef1d":"markdown","e7d49db4":"markdown","2f10b022":"markdown","8cbe6e5a":"markdown","a2e7133a":"markdown","84177e49":"markdown","1b56f45e":"markdown","477712f4":"markdown","97a5b5c7":"markdown"},"source":{"4d3da1d6":"# Python \u22653.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn \u22650.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\ntry:\n    # %tensorflow_version only exists in Colab.\n    %tensorflow_version 2.x\n    IS_COLAB = True\nexcept Exception:\n    IS_COLAB = False\n\n# TensorFlow \u22652.0 is required\nimport tensorflow as tf\nfrom tensorflow import keras\nassert tf.__version__ >= \"2.0\"\n\nif not tf.config.list_physical_devices('GPU'):\n    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n    if IS_COLAB:\n        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n\n# Common imports\nimport numpy as np\nimport os\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n# Where to save the figures\nPROJECT_ROOT_DIR = \".\"\nCHAPTER_ID = \"autoencoders\"\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\nos.makedirs(IMAGES_PATH, exist_ok=True)\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)","77059328":"def plot_image(image):\n    plt.imshow(image, cmap=\"binary\")\n    plt.axis(\"off\")","6c4ce713":"np.random.seed(4)\n\ndef generate_3d_data(m, w1=0.1, w2=0.3, noise=0.1):\n    angles = np.random.rand(m) * 3 * np.pi \/ 2 - 0.5\n    data = np.empty((m, 3))\n    data[:, 0] = np.cos(angles) + np.sin(angles)\/2 + noise * np.random.randn(m) \/ 2\n    data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) \/ 2\n    data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n    return data\n\nX_train = generate_3d_data(60)\nX_train = X_train - X_train.mean(axis=0, keepdims=0)","4d909aa2":"np.random.seed(42)\ntf.random.set_seed(42)\n\nencoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\ndecoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\nautoencoder = keras.models.Sequential([encoder, decoder])\n\nautoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1.5))","39c31023":"history = autoencoder.fit(X_train, X_train, epochs=20)","926f0f17":"codings = encoder.predict(X_train)","452e478f":"fig = plt.figure(figsize=(4,3))\nplt.plot(codings[:,0], codings[:, 1], \"b.\")\nplt.xlabel(\"$z_1$\", fontsize=18)\nplt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\nplt.grid(True)\nsave_fig(\"linear_autoencoder_pca_plot\")\nplt.show()","7462fa67":"(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\nX_train_full = X_train_full.astype(np.float32) \/ 255\nX_test = X_test.astype(np.float32) \/ 255\nX_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\ny_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]","8f67b38f":"def rounded_accuracy(y_true, y_pred):\n    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))","480ac9ba":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nstacked_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(30, activation=\"selu\"),\n])\nstacked_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\nstacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\nstacked_ae.compile(loss=\"binary_crossentropy\",\n                   optimizer=keras.optimizers.SGD(lr=1.5), metrics=[rounded_accuracy])\nhistory = stacked_ae.fit(X_train, X_train, epochs=120,\n                         validation_data=(X_valid, X_valid))","7e0da49a":"def show_reconstructions(model, images=X_valid, n_images=5):\n    reconstructions = model.predict(images[:n_images])\n    fig = plt.figure(figsize=(n_images * 1.5, 3))\n    for image_index in range(n_images):\n        plt.subplot(2, n_images, 1 + image_index)\n        plot_image(images[image_index])\n        plt.subplot(2, n_images, 1 + n_images + image_index)\n        plot_image(reconstructions[image_index])","2a47a4da":"show_reconstructions(stacked_ae)\nsave_fig(\"reconstruction_plot\")","5a91b663":"np.random.seed(42)\n\nfrom sklearn.manifold import TSNE\n\nX_valid_compressed = stacked_encoder.predict(X_valid)\ntsne = TSNE()\nX_valid_2D = tsne.fit_transform(X_valid_compressed)\nX_valid_2D = (X_valid_2D - X_valid_2D.min()) \/ (X_valid_2D.max() - X_valid_2D.min())","b22a99d3":"plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\nplt.axis(\"off\")\nplt.show()","9fea7f34":"# adapted from https:\/\/scikit-learn.org\/stable\/auto_examples\/manifold\/plot_lle_digits.html\nplt.figure(figsize=(10, 8))\ncmap = plt.cm.tab10\nplt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=cmap)\nimage_positions = np.array([[1., 1.]])\nfor index, position in enumerate(X_valid_2D):\n    dist = np.sum((position - image_positions) ** 2, axis=1)\n    if np.min(dist) > 0.02: # if far enough from other images\n        image_positions = np.r_[image_positions, [position]]\n        imagebox = mpl.offsetbox.AnnotationBbox(\n            mpl.offsetbox.OffsetImage(X_valid[index], cmap=\"binary\"),\n            position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n        plt.gca().add_artist(imagebox)\nplt.axis(\"off\")\nsave_fig(\"fashion_mnist_visualization_plot\")\nplt.show()","f3ea7a99":"class DenseTranspose(keras.layers.Layer):\n    def __init__(self, dense, activation=None, **kwargs):\n        self.dense = dense\n        self.activation = keras.activations.get(activation)\n        super().__init__(**kwargs)\n    def build(self, batch_input_shape):\n        self.biases = self.add_weight(name=\"bias\",\n                                      shape=[self.dense.input_shape[-1]],\n                                      initializer=\"zeros\")\n        super().build(batch_input_shape)\n    def call(self, inputs):\n        z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n        return self.activation(z + self.biases)","79fe8852":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\ndense_1 = keras.layers.Dense(100, activation=\"selu\")\ndense_2 = keras.layers.Dense(30, activation=\"selu\")\n\ntied_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    dense_1,\n    dense_2\n])\n\ntied_decoder = keras.models.Sequential([\n    DenseTranspose(dense_2, activation=\"selu\"),\n    DenseTranspose(dense_1, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\n\ntied_ae = keras.models.Sequential([tied_encoder, tied_decoder])\n\ntied_ae.compile(loss=\"binary_crossentropy\",\n                optimizer=keras.optimizers.SGD(lr=1.5), metrics=[rounded_accuracy])\nhistory = tied_ae.fit(X_train, X_train, epochs=10,\n                      validation_data=(X_valid, X_valid))","73216b57":"show_reconstructions(tied_ae)\nplt.show()","acaf81c2":"def train_autoencoder(n_neurons, X_train, X_valid, loss, optimizer,\n                      n_epochs=10, output_activation=None, metrics=None):\n    n_inputs = X_train.shape[-1]\n    encoder = keras.models.Sequential([\n        keras.layers.Dense(n_neurons, activation=\"selu\", input_shape=[n_inputs])\n    ])\n    decoder = keras.models.Sequential([\n        keras.layers.Dense(n_inputs, activation=output_activation),\n    ])\n    autoencoder = keras.models.Sequential([encoder, decoder])\n    autoencoder.compile(optimizer, loss, metrics=metrics)\n    autoencoder.fit(X_train, X_train, epochs=n_epochs,\n                    validation_data=(X_valid, X_valid))\n    return encoder, decoder, encoder(X_train), encoder(X_valid)","492fd035":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nK = keras.backend\nX_train_flat = K.batch_flatten(X_train) # equivalent to .reshape(-1, 28 * 28)\nX_valid_flat = K.batch_flatten(X_valid)\nenc1, dec1, X_train_enc1, X_valid_enc1 = train_autoencoder(\n    100, X_train_flat, X_valid_flat, \"binary_crossentropy\",\n    keras.optimizers.SGD(lr=1.5), output_activation=\"sigmoid\",\n    metrics=[rounded_accuracy])\nenc2, dec2, _, _ = train_autoencoder(\n    30, X_train_enc1, X_valid_enc1, \"mse\", keras.optimizers.SGD(lr=0.05),\n    output_activation=\"selu\")","65cb4978":"stacked_ae_1_by_1 = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    enc1, enc2, dec2, dec1,\n    keras.layers.Reshape([28, 28])\n])","ba3e0a99":"show_reconstructions(stacked_ae_1_by_1)\nplt.show()","5adc07a6":"stacked_ae_1_by_1.compile(loss=\"binary_crossentropy\",\n                          optimizer=keras.optimizers.SGD(lr=0.1), metrics=[rounded_accuracy])\nhistory = stacked_ae_1_by_1.fit(X_train, X_train, epochs=10,\n                                validation_data=(X_valid, X_valid))","a5162ca1":"show_reconstructions(stacked_ae_1_by_1)\nplt.show()","00bd6192":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nconv_encoder = keras.models.Sequential([\n    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n    keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n    keras.layers.MaxPool2D(pool_size=2)\n])\nconv_decoder = keras.models.Sequential([\n    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"VALID\", activation=\"selu\",\n                                 input_shape=[3, 3, 64]),\n    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"SAME\", activation=\"selu\"),\n    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\nconv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n\nconv_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.0),\n                metrics=[rounded_accuracy])\nhistory = conv_ae.fit(X_train, X_train, epochs=5,\n                      validation_data=(X_valid, X_valid))","e24d3211":"conv_encoder.summary()\nconv_decoder.summary()","e815cbed":"show_reconstructions(conv_ae)\nplt.show()","ae07aa17":"recurrent_encoder = keras.models.Sequential([\n    keras.layers.LSTM(100, return_sequences=True, input_shape=[28, 28]),\n    keras.layers.LSTM(30)\n])\nrecurrent_decoder = keras.models.Sequential([\n    keras.layers.RepeatVector(28, input_shape=[30]),\n    keras.layers.LSTM(100, return_sequences=True),\n    keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n])\nrecurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])\nrecurrent_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(0.1),\n                     metrics=[rounded_accuracy])","f847da7d":"history = recurrent_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))","c72a93f7":"show_reconstructions(recurrent_ae)\nplt.show()","7f2cb883":"tf.random.set_seed(42)\nnp.random.seed(42)\n\ndenoising_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.GaussianNoise(0.2),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(30, activation=\"selu\")\n])\ndenoising_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\ndenoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])\ndenoising_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.0),\n                     metrics=[rounded_accuracy])\nhistory = denoising_ae.fit(X_train, X_train, epochs=10,\n                           validation_data=(X_valid, X_valid))","86235691":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nnoise = keras.layers.GaussianNoise(0.2)\nshow_reconstructions(denoising_ae, noise(X_valid, training=True))\nplt.show()","3169b037":"tf.random.set_seed(42)\nnp.random.seed(42)\n\ndropout_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(30, activation=\"selu\")\n])\ndropout_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\ndropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\ndropout_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.0),\n                   metrics=[rounded_accuracy])\nhistory = dropout_ae.fit(X_train, X_train, epochs=10,\n                         validation_data=(X_valid, X_valid))","711b940e":"tf.random.set_seed(42)\nnp.random.seed(42)\n\ndropout = keras.layers.Dropout(0.5)\nshow_reconstructions(dropout_ae, dropout(X_valid, training=True))\nsave_fig(\"dropout_denoising_plot\", tight_layout=False)","105ae13f":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nsimple_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(30, activation=\"sigmoid\"),\n])\nsimple_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\nsimple_ae = keras.models.Sequential([simple_encoder, simple_decoder])\nsimple_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.),\n                  metrics=[rounded_accuracy])\nhistory = simple_ae.fit(X_train, X_train, epochs=10,\n                        validation_data=(X_valid, X_valid))","7edc5223":"show_reconstructions(simple_ae)\nplt.show()","b7d9d571":"def plot_percent_hist(ax, data, bins):\n    counts, _ = np.histogram(data, bins=bins)\n    widths = bins[1:] - bins[:-1]\n    x = bins[:-1] + widths \/ 2\n    ax.bar(x, counts \/ len(data), width=widths*0.8)\n    ax.xaxis.set_ticks(bins)\n    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(\n        lambda y, position: \"{}%\".format(int(np.round(100 * y)))))\n    ax.grid(True)","7e679ee8":"def plot_activations_histogram(encoder, height=1, n_bins=10):\n    X_valid_codings = encoder(X_valid).numpy()\n    activation_means = X_valid_codings.mean(axis=0)\n    mean = activation_means.mean()\n    bins = np.linspace(0, 1, n_bins + 1)\n\n    fig, [ax1, ax2] = plt.subplots(figsize=(10, 3), nrows=1, ncols=2, sharey=True)\n    plot_percent_hist(ax1, X_valid_codings.ravel(), bins)\n    ax1.plot([mean, mean], [0, height], \"k--\", label=\"Overall Mean = {:.2f}\".format(mean))\n    ax1.legend(loc=\"upper center\", fontsize=14)\n    ax1.set_xlabel(\"Activation\")\n    ax1.set_ylabel(\"% Activations\")\n    ax1.axis([0, 1, 0, height])\n    plot_percent_hist(ax2, activation_means, bins)\n    ax2.plot([mean, mean], [0, height], \"k--\")\n    ax2.set_xlabel(\"Neuron Mean Activation\")\n    ax2.set_ylabel(\"% Neurons\")\n    ax2.axis([0, 1, 0, height])","73d23b9f":"plot_activations_histogram(simple_encoder, height=0.35)\nplt.show()","668a7253":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nsparse_l1_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(300, activation=\"sigmoid\"),\n    keras.layers.ActivityRegularization(l1=1e-3)  # Alternatively, you could add\n                                                  # activity_regularizer=keras.regularizers.l1(1e-3)\n                                                  # to the previous layer.\n])\nsparse_l1_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\nsparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])\nsparse_l1_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.0),\n                     metrics=[rounded_accuracy])\nhistory = sparse_l1_ae.fit(X_train, X_train, epochs=10,\n                           validation_data=(X_valid, X_valid))","f89714c2":"show_reconstructions(sparse_l1_ae)","41570469":"plot_activations_histogram(sparse_l1_encoder, height=1.)\nplt.show()","2be32032":"p = 0.1\nq = np.linspace(0.001, 0.999, 500)\nkl_div = p * np.log(p \/ q) + (1 - p) * np.log((1 - p) \/ (1 - q))\nmse = (p - q)**2\nmae = np.abs(p - q)\nplt.plot([p, p], [0, 0.3], \"k:\")\nplt.text(0.05, 0.32, \"Target\\nsparsity\", fontsize=14)\nplt.plot(q, kl_div, \"b-\", label=\"KL divergence\")\nplt.plot(q, mae, \"g--\", label=r\"MAE ($\\ell_1$)\")\nplt.plot(q, mse, \"r--\", linewidth=1, label=r\"MSE ($\\ell_2$)\")\nplt.legend(loc=\"upper left\", fontsize=14)\nplt.xlabel(\"Actual sparsity\")\nplt.ylabel(\"Cost\", rotation=0)\nplt.axis([0, 1, 0, 0.95])\nsave_fig(\"sparsity_loss_plot\")","15c238d5":"K = keras.backend\nkl_divergence = keras.losses.kullback_leibler_divergence\n\nclass KLDivergenceRegularizer(keras.regularizers.Regularizer):\n    def __init__(self, weight, target=0.1):\n        self.weight = weight\n        self.target = target\n    def __call__(self, inputs):\n        mean_activities = K.mean(inputs, axis=0)\n        return self.weight * (\n            kl_divergence(self.target, mean_activities) +\n            kl_divergence(1. - self.target, 1. - mean_activities))","8e891172":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nkld_reg = KLDivergenceRegularizer(weight=0.05, target=0.1)\nsparse_kl_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(300, activation=\"sigmoid\", activity_regularizer=kld_reg)\n])\nsparse_kl_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\nsparse_kl_ae = keras.models.Sequential([sparse_kl_encoder, sparse_kl_decoder])\nsparse_kl_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.0),\n              metrics=[rounded_accuracy])\nhistory = sparse_kl_ae.fit(X_train, X_train, epochs=10,\n                           validation_data=(X_valid, X_valid))","a29aaddf":"show_reconstructions(sparse_kl_ae)","94720976":"plot_activations_histogram(sparse_kl_encoder)\nsave_fig(\"sparse_autoencoder_plot\")\nplt.show()","0f1d8f83":"class Sampling(keras.layers.Layer):\n    def call(self, inputs):\n        mean, log_var = inputs\n        return K.random_normal(tf.shape(log_var)) * K.exp(log_var \/ 2) + mean ","ce5032c4":"tf.random.set_seed(42)\nnp.random.seed(42)\n\ncodings_size = 10\n\ninputs = keras.layers.Input(shape=[28, 28])\nz = keras.layers.Flatten()(inputs)\nz = keras.layers.Dense(150, activation=\"selu\")(z)\nz = keras.layers.Dense(100, activation=\"selu\")(z)\ncodings_mean = keras.layers.Dense(codings_size)(z)\ncodings_log_var = keras.layers.Dense(codings_size)(z)\ncodings = Sampling()([codings_mean, codings_log_var])\nvariational_encoder = keras.models.Model(\n    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n\ndecoder_inputs = keras.layers.Input(shape=[codings_size])\nx = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\nx = keras.layers.Dense(150, activation=\"selu\")(x)\nx = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\noutputs = keras.layers.Reshape([28, 28])(x)\nvariational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n\n_, _, codings = variational_encoder(inputs)\nreconstructions = variational_decoder(codings)\nvariational_ae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n\nlatent_loss = -0.5 * K.sum(\n    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n    axis=-1)\nvariational_ae.add_loss(K.mean(latent_loss) \/ 784.)\nvariational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[rounded_accuracy])\nhistory = variational_ae.fit(X_train, X_train, epochs=25, batch_size=128,\n                             validation_data=(X_valid, X_valid))","3382b8e8":"show_reconstructions(variational_ae)\nplt.show()","38db311c":"def plot_multiple_images(images, n_cols=None):\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    plt.figure(figsize=(n_cols, n_rows))\n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","23e56b16":"tf.random.set_seed(42)\n\ncodings = tf.random.normal(shape=[12, codings_size])\nimages = variational_decoder(codings).numpy()\nplot_multiple_images(images, 4)\nsave_fig(\"vae_generated_images_plot\", tight_layout=False)","233a79c0":"tf.random.set_seed(42)\nnp.random.seed(42)\n\ncodings_grid = tf.reshape(codings, [1, 3, 4, codings_size])\nlarger_grid = tf.image.resize(codings_grid, size=[5, 7])\ninterpolated_codings = tf.reshape(larger_grid, [-1, codings_size])\nimages = variational_decoder(interpolated_codings).numpy()\n\nplt.figure(figsize=(7, 5))\nfor index, image in enumerate(images):\n    plt.subplot(5, 7, index + 1)\n    if index%7%2==0 and index\/\/7%2==0:\n        plt.gca().get_xaxis().set_visible(False)\n        plt.gca().get_yaxis().set_visible(False)\n    else:\n        plt.axis(\"off\")\n    plt.imshow(image, cmap=\"binary\")\nsave_fig(\"semantic_interpolation_plot\", tight_layout=False)","b23234d2":"np.random.seed(42)\ntf.random.set_seed(42)\n\ncodings_size = 30\n\ngenerator = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n    keras.layers.Dense(150, activation=\"selu\"),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\ndiscriminator = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(150, activation=\"selu\"),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(1, activation=\"sigmoid\")\n])\ngan = keras.models.Sequential([generator, discriminator])","9dbcad53":"discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\ndiscriminator.trainable = False\ngan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")","7f04579f":"batch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)","315d2b70":"def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n    generator, discriminator = gan.layers\n    for epoch in range(n_epochs):\n        print(\"Epoch {}\/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n        for X_batch in dataset:\n            # phase 1 - training the discriminator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            generated_images = generator(noise)\n            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(X_fake_and_real, y1)\n            # phase 2 - training the generator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            y2 = tf.constant([[1.]] * batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, y2)\n        plot_multiple_images(generated_images, 8)                     # not shown\n        plt.show()                                                    # not shown","828ffff1":"train_gan(gan, dataset, batch_size, codings_size, n_epochs=1)","a43e9d68":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nnoise = tf.random.normal(shape=[batch_size, codings_size])\ngenerated_images = generator(noise)\nplot_multiple_images(generated_images, 8)\nsave_fig(\"gan_generated_images_plot\", tight_layout=False)","2a1f2b16":"train_gan(gan, dataset, batch_size, codings_size)","b4054ed9":"tf.random.set_seed(42)\nnp.random.seed(42)\n\ncodings_size = 100\n\ngenerator = keras.models.Sequential([\n    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n    keras.layers.Reshape([7, 7, 128]),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",\n                                 activation=\"selu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"SAME\",\n                                 activation=\"tanh\"),\n])\ndiscriminator = keras.models.Sequential([\n    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"SAME\",\n                        activation=keras.layers.LeakyReLU(0.2),\n                        input_shape=[28, 28, 1]),\n    keras.layers.Dropout(0.4),\n    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",\n                        activation=keras.layers.LeakyReLU(0.2)),\n    keras.layers.Dropout(0.4),\n    keras.layers.Flatten(),\n    keras.layers.Dense(1, activation=\"sigmoid\")\n])\ngan = keras.models.Sequential([generator, discriminator])","3f352a76":"discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\ndiscriminator.trainable = False\ngan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")","53c75019":"X_train_dcgan = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape and rescale","8de34595":"batch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\ndataset = dataset.shuffle(1000)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)","dc8435a8":"train_gan(gan, dataset, batch_size, codings_size)","dcec3b60":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nnoise = tf.random.normal(shape=[batch_size, codings_size])\ngenerated_images = generator(noise)\nplot_multiple_images(generated_images, 8)\nsave_fig(\"dcgan_generated_images_plot\", tight_layout=False)","05bb9c8e":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nX_train_small = X_train[:500]\ny_train_small = y_train[:500]\n\nclassifier = keras.models.Sequential([\n    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n    keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(20, activation=\"selu\"),\n    keras.layers.Dense(10, activation=\"softmax\")\n])\nclassifier.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(lr=0.02),\n                   metrics=[\"accuracy\"])\nhistory = classifier.fit(X_train_small, y_train_small, epochs=20, validation_data=(X_valid, y_valid))","c6600ad6":"import pandas as pd\npd.DataFrame(history.history).plot()\nplt.show()","edf2a231":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nconv_encoder_clone = keras.models.clone_model(conv_encoder)\n\npretrained_clf = keras.models.Sequential([\n    conv_encoder_clone,\n    keras.layers.Flatten(),\n    keras.layers.Dense(20, activation=\"selu\"),\n    keras.layers.Dense(10, activation=\"softmax\")\n])","66a1159a":"conv_encoder_clone.trainable = False\npretrained_clf.compile(loss=\"sparse_categorical_crossentropy\",\n                       optimizer=keras.optimizers.SGD(lr=0.02),\n                       metrics=[\"accuracy\"])\nhistory = pretrained_clf.fit(X_train_small, y_train_small, epochs=30,\n                             validation_data=(X_valid, y_valid))","6048534b":"conv_encoder_clone.trainable = True\npretrained_clf.compile(loss=\"sparse_categorical_crossentropy\",\n                       optimizer=keras.optimizers.SGD(lr=0.02),\n                       metrics=[\"accuracy\"])\nhistory = pretrained_clf.fit(X_train_small, y_train_small, epochs=20,\n                             validation_data=(X_valid, y_valid))","faed71b0":"tf.random.set_seed(42)\nnp.random.seed(42)\n\nhashing_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.GaussianNoise(15.),\n    keras.layers.Dense(16, activation=\"sigmoid\"),\n])\nhashing_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[16]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\nhashing_ae = keras.models.Sequential([hashing_encoder, hashing_decoder])\nhashing_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.0),\n                   metrics=[rounded_accuracy])\nhistory = hashing_ae.fit(X_train, X_train, epochs=10,\n                         validation_data=(X_valid, X_valid))","06baeedb":"show_reconstructions(hashing_ae)\nplt.show()","ffe06bfa":"plot_activations_histogram(hashing_encoder)\nplt.show()","919451dc":"hashes = np.round(hashing_encoder.predict(X_valid)).astype(np.int32)\nhashes *= np.array([[2**bit for bit in range(16)]])\nhashes = hashes.sum(axis=1)\nfor h in hashes[:5]:\n    print(\"{:016b}\".format(h))\nprint(\"...\")","9259a60e":"n_bits = 4\nn_images = 8\nplt.figure(figsize=(n_images, n_bits))\nfor bit_index in range(n_bits):\n    in_bucket = (hashes & 2**bit_index != 0)\n    for index, image in zip(range(n_images), X_valid[in_bucket]):\n        plt.subplot(n_bits, n_images, bit_index * n_images + index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","0816233c":"## Using Convolutional Layers Instead of Dense Layers","b8fcfb07":"Build 3D dataset:","63b786ea":"Let's generate a few random codings, decode them and plot the resulting images:","9e334440":"Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders).","5cdd7c3c":"## Train all layers at once","21b4f281":"Now let's perform semantic interpolation between these images:","c7b22f3e":"# Stacked Autoencoders","be67b0aa":"## Generate Fashion Images","9585a9bc":"Let's use these functions to plot histograms of the activations of the encoding layer. The histogram on the left shows the distribution of all the activations. You can see that values close to 0 or 1 are more frequent overall, which is consistent with the saturating nature of the sigmoid function. The histogram on the right shows the distribution of mean neuron activations: you can see that most neurons have a mean activation close to 0.5. Both histograms tell us that each neuron tends to either fire close to 0 or 1, with about 50% probability each. However, some neurons fire almost all the time (right side of the right histogram).","cbb51a9d":"Using dropout:","82d16ddb":"# Recurrent Autoencoders","7697d81a":"A couple utility functions to plot grayscale 28x28 image:","2fdee647":"# Generative Adversarial Networks","0b890771":"Let's make this diagram a bit prettier:","f027436d":"Using Gaussian noise:","68849678":"# PCA with a linear Autoencoder","fe644055":"# Visualizing Fashion MNIST","60dcfe17":"Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders).","958c4984":"Let's use MNIST:","e106a898":"Let's create a small neural network for MNIST classification:","20d81ec8":"Let's use the KL Divergence loss instead to ensure sparsity, and target 10% sparsity rather than 0%:","cf4373a1":"Let's build a simple stacked autoencoder, so we can compare it to the sparse autoencoders we will build. This time we will use the sigmoid activation function for the coding layer, to ensure that the coding values range from 0 to 1:","3b6b462c":"## Autoencoders and GANs","0dff053a":"## Unsupervised pretraining","2acd6b8f":"It is common to tie the weights of the encoder and the decoder, by simply using the transpose of the encoder's weights as the decoder weights. For this, we need to use a custom layer.","88b4b2c2":"Now let's build the Autoencoder...","9caa4466":"## Training one Autoencoder at a Time","7727bb43":"# Variational Autoencoder","4679ef1d":"This function processes a few test images through the autoencoder and displays the original images and their reconstructions:","e7d49db4":"# Exercise Solutions","2f10b022":"## Hashing Using a Binary Autoencoder","8cbe6e5a":"Now let's add $\\ell_1$ regularization to the coding layer:","a2e7133a":"Let's create a couple functions to print nice activation histograms:","84177e49":"## Tying weights","1b56f45e":"# Deep Convolutional GAN","477712f4":"# Stacked denoising Autoencoder","97a5b5c7":"# Sparse Autoencoder"}}