{"cell_type":{"6a7a995e":"code","ee3927a0":"code","6993f5ec":"code","608d7b80":"code","8ed4e6b8":"code","ad6198f3":"code","3d183bf5":"code","821ed2fc":"code","91968e4b":"markdown","34406c7a":"markdown","3ae00891":"markdown","22da0714":"markdown","be46b3bc":"markdown"},"source":{"6a7a995e":"# Instead of sklearn TSNE implementation I'll use MulticoreTSNE \n# beacuse it much much faster\n!pip install MulticoreTSNE","ee3927a0":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom MulticoreTSNE import MulticoreTSNE as TSNE\n\nwarnings.filterwarnings('ignore')\npd.set_option('max_columns', None)\npd.set_option('max_rows', 100)","6993f5ec":"# I want ot define a couple of functions to make my code more DRY\ndef gen_dataset(samples):\n    '''\n    Generates dataset with all fraud transactions and \"samples\" part of non_fraud transactions\n    '''\n    # Sub-sampling dataset\n    fraud = df[df['Class'] == 1]\n    non_fraud = df[df['Class'] == 0].sample(samples, random_state = 1)\n    df_scaled = pd.concat([fraud, non_fraud])\n    df_scaled = shuffle(df_scaled, random_state = 1)\n\n    Y = df_scaled['Class']\n\n    df_scaled = df_scaled.drop('Class', axis = 1)\n\n    # Standardize the data to a mean of zero and a SD of 1 to remove the scale effect of the variables\n    scaler = StandardScaler()\n    df_scaled = pd.DataFrame(scaler.fit_transform(df_scaled), columns = df_scaled.columns)\n    return (df_scaled, Y)\n\ndef plots(df_2d, df3d, t = False):\n    '''\n    Creates 2d and 3d plots\n    '''\n    fig = plt.figure(figsize = (20, 8))\n    ax1 = fig.add_subplot(121)\n    if t:\n        sns.scatterplot(x = 'PC1', y = 'PC2', data = df_2d, hue = 'Class').set_title(f'TSNE with 2 components')\n    else:\n        sns.scatterplot(x = 'PC1', y = 'PC2', data = df_2d, hue = 'Class').set_title(f'PCA with 2 components\\nexpl. variance: {variance_2d}%')\n\n    ax2 = fig.add_subplot(122, projection = '3d')\n    f = df3d[df3d['Class'] == 1]\n    nf = df3d[df3d['Class'] == 0]\n    ax2.scatter(nf['PC1'], nf['PC2'], nf['PC3'], marker = 'o')\n    ax2.scatter(f['PC1'], f['PC2'], f['PC3'], marker = 'x')\n    ax2.view_init(30, 240)\n    if t:\n        plt.title(('TSNE with 3 components'))\n    else:\n        plt.title((f'PCA with 3 components\\nexpl. variance: {variance_3d}%'))\n    ax2.set_xlabel('PC1')\n    ax2.set_ylabel('PC2')\n    ax2.set_zlabel('PC3')\n    plt.show()","608d7b80":"# Loading dataset\ndf = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\nprint(df.shape)\ndf.head()","8ed4e6b8":"# Creating dataset for PCA\ndf_pca, Y = gen_dataset(50000)","ad6198f3":"# PCA with 2 components\npca_2d = PCA(n_components = 2, random_state = 1)\npca_df_2d = pca_2d.fit_transform(df_pca)\nvariance_2d = round(sum(pca_2d.explained_variance_ratio_) * 100, 2)\npca_df_2d = pd.DataFrame(pca_df_2d, columns = ['PC1', 'PC2'])\npca_df_2d['Class'] = Y.values\n\n# PCA with 3 components\npca_3d = PCA(n_components = 3, random_state = 1)\npca_df_3d = pca_3d.fit_transform(df_pca)\nvariance_3d = round(sum(pca_3d.explained_variance_ratio_) * 100, 2)\npca_df_3d = pd.DataFrame(pca_df_3d, columns = ['PC1', 'PC2', 'PC3'])\npca_df_3d['Class'] = Y.values\n\nplots(pca_df_2d, pca_df_3d)","3d183bf5":"# Creating dataset for TSNE\ndf_tsne, Y = gen_dataset(15000)","821ed2fc":"tsne_2d = TSNE(n_components = 2, \n            perplexity = 30, \n            early_exaggeration=12.0,\n            learning_rate=200.0,\n            n_iter=1000,\n            random_state = 1, \n            n_jobs = -1)\ntsne_df_2d = tsne_2d.fit_transform(df_tsne)\n\ntsne_df_2d = pd.DataFrame(tsne_df_2d, columns = ['PC1', 'PC2'])\ntsne_df_2d['Class'] = Y.values\n\ntsne_3d = TSNE(n_components = 3, \n            perplexity = 30, \n            early_exaggeration=12.0,\n            learning_rate=200.0,\n            n_iter=1000,\n            random_state = 1, \n            n_jobs = -1)\ntsne_df_3d = tsne_3d.fit_transform(df_tsne)\n\ntsne_df_3d = pd.DataFrame(tsne_df_3d, columns = ['PC1', 'PC2', 'PC3'])\ntsne_df_3d['Class'] = Y.values\n\nplots(tsne_df_2d, tsne_df_3d, t = True)","91968e4b":"In this short kernel I want to reduce dimensionality of data using PCA and MulticoreTSNE to find are there clusters of fraud and non_fraud transactions that can be easily separated.\n\nAlso check my another kernel on this dataset: [IsolatedForest and LOF fraud detection](https:\/\/www.kaggle.com\/trolukovich\/isolatedforest-and-lof-fraud-detection)","34406c7a":"Because TSNE can be very computational expensive, I'll use datasets with different number of samples, also I'm not balancing data, I want to see how these algorithms can handle imballanced dataset.","3ae00891":"I want to use number of components equal to 2 for 2D plot and 3, to form 3D plot:","22da0714":"We can see that fraud transactions forming a clearly distinctable cluster. \n\nConclusion:\nAs we can see, on this particular dataset, both - PCA and TSNE showed us good results - fraud transactions forms clusters that can be easily separable from non_fraud transactions using simple ML algorithms.","be46b3bc":"Despite of low amount of explained variance - 17.45% for 2 components and 22.58% for 3 components - we can see clearly distinctable clusters of fraud and non_fraud transactons. Theoretically, we can split these categories using line for 2 dimensions or plane for 3 dimensions.\n\nNext - let's try TSNE:"}}