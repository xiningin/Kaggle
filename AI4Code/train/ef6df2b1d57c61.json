{"cell_type":{"20279f4e":"code","bdc5260e":"code","e47c967e":"code","a5510d43":"code","59923453":"code","4f1c572a":"code","23bda852":"code","8447b165":"code","23dae5b4":"markdown","fd3c8dbb":"markdown","a9a7a902":"markdown","8afc2abd":"markdown","19119e06":"markdown","0f8e429e":"markdown","3be387ac":"markdown","071f2e56":"markdown","67478b01":"markdown","31de8e76":"markdown"},"source":{"20279f4e":"import pandas as pd\nimport numpy as np\ndataset=pd.read_csv('..\/input\/breast-cancer-prediction-dataset\/Breast_cancer_data.csv')","bdc5260e":"dataset.head()","e47c967e":"def hypothesis(X, theta):\n    z = np.dot(theta, X.T)\n    return 1\/(1+np.exp(-(z)))","a5510d43":"def cost(X, y, theta,lamb):\n    y1 = hypothesis(X, theta)\n    return -(1\/len(X)) * np.sum(y*np.log(y1) + (1-y)*np.log(1-y1))+(lamb\/(2*len(X)))*np.sum(np.square(theta[1:]))","59923453":"def gradient_descent(X, y, theta, alpha, epochs,lamb):\n    m =len(X) \n    for i in range(0, epochs):\n        h = hypothesis(X, theta)\n        theta[0]-=(alpha\/m) * np.sum((h-y)*X.iloc[:, 0])\n        for i in range(1, len(X.columns)):\n            theta[i] -= (alpha\/m) * np.sum((h-y)*X.iloc[:, i]+(lamb\/m)*theta[i])\n    return  theta","4f1c572a":"def predict(X, y, theta, alpha, epochs,lamb):\n    th = gradient_descent(X, y, theta, alpha, epochs,lamb) \n    h = hypothesis(X, th)\n    for i in range(len(h)):\n        h[i]=1 if h[i]>=0.5 else 0\n    y = list(y)\n    acc = np.sum([y[i] == h[i] for i in range(len(y))])\/len(y)\n    return  acc","23bda852":"y=dataset[\"diagnosis\"]\nX = dataset.drop(columns=[\"diagnosis\"])\nX= pd.concat([pd.Series(1, index = X.index, name = '00'), X], axis=1)\nX.head()","8447b165":"theta = [0]*len(X.columns)\nacc = predict(X, y, theta, 0.0001, 25000,0.1)\nprint(acc)","23dae5b4":"**Step 2: Determine the cost function.**","fd3c8dbb":"Step 1: Develop the hypothesis.\nThe hypothesis is simply the implementation of the sigmoid function.","a9a7a902":"you can vary learning rate ,number of iteration and regration parameter for better performance","8afc2abd":"**Data Preprocessing**","19119e06":"**Result:**\nI used learning rate=.0001 ,total number of iteration 25000 and regration parameter .1. then I print accuracy","0f8e429e":"**Step 3: Update the theta values.**\n in this step we will learn parameter (theta). Theta values need to keep updating until the cost function reaches its minimum. We should get our final theta values.","3be387ac":"**Step 4: Calculate the final prediction and accuracy**\nUse the theta values that come out of the \u2018gradient_descent\u2019 function and calculate the final prediction using the sigmoid function. Then, calculate the accuracy.","071f2e56":" Let\u2019s implement this model to solve a real problem.","67478b01":"I will use a dataset from Kaggle that contains the Breast cancer data.it has last column that diagnosis is or not.\nHere I will load the dataset. I will use pandas for that:","31de8e76":"The dataset looks like this:\n"}}