{"cell_type":{"cfbdf96c":"code","2d1127a8":"code","1810f428":"code","ad344bfc":"code","3641fc37":"code","cb9588c9":"code","dfb80442":"code","05ac7db0":"code","d352ff5d":"code","c9fea564":"code","5fb24c67":"code","d226416b":"code","57b00443":"code","b56f704f":"code","2cfef2b9":"code","ba35bb4a":"code","bdd66a97":"code","230b18ca":"code","0b6cb935":"code","d90127b1":"code","0ec698ed":"code","10d237b1":"code","27a466ba":"code","2e83fc9a":"code","73c4b717":"code","8531c62b":"code","909d25c3":"code","3ee86bb8":"code","4755f608":"code","4e7aed0a":"code","8dd3bb44":"code","6c40fc2c":"code","f84c00ea":"code","ab8f8b05":"code","484addf5":"code","b5ddcc32":"code","70825919":"code","1db4004a":"code","0ab7e0e6":"code","293d833a":"code","5953aef5":"code","bb01b81e":"code","6bc9c296":"code","6f66c487":"code","7c10e340":"code","7218e056":"code","a4af1872":"code","f39e4bec":"code","713a8e0a":"code","f26a7bc9":"code","75974bbd":"code","92b07c83":"code","26dca6b7":"code","505aad93":"code","ca1d653b":"code","e46edac6":"code","fd7a4abe":"code","2f830571":"code","f9600157":"code","6f532c02":"code","f8044f79":"code","83806c36":"code","46f05fe7":"code","2b8ae3be":"code","21fb4485":"code","366df6ba":"code","7aba9629":"code","00b42e7f":"code","f2711618":"code","744e361e":"code","5dfdff89":"code","ebba6c3b":"code","b15fc073":"code","1b06e633":"code","a113aa31":"code","b59c94d7":"code","68572803":"code","ea4c63ca":"code","f2f8e7bd":"code","6eb575d3":"markdown","1f9a3362":"markdown","01a52355":"markdown","c8efe5e8":"markdown","d41e36ab":"markdown","951f42e4":"markdown","9fea00bd":"markdown","6e7cd68b":"markdown","7ab25898":"markdown","298fbec5":"markdown","1a9224cd":"markdown","0a44830a":"markdown","faff94d4":"markdown","6400a994":"markdown","5d2a77f8":"markdown","c3db08a4":"markdown","adf571b2":"markdown","a0096d6d":"markdown","da68655c":"markdown","3c36382d":"markdown","a2357168":"markdown","5ee09a39":"markdown","1d0b12db":"markdown","ea7ed28e":"markdown","a92ecda6":"markdown"},"source":{"cfbdf96c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\ntitatrain = pd.read_csv(\"..\/input\/train.csv\")  #importing the train data\ntitatest = pd.read_csv(\"..\/input\/test.csv\")   #importing the test data\n\n# Any results you write to the current directory are saved as output.","2d1127a8":"titatrain.head()   #To view the head of the train data set ","1810f428":"titatest.head()     #To view the head of the test data set","ad344bfc":"titatrain.info()   #Finding the information(such as number of datas missing) on the training dataset","3641fc37":"titatest.info()","cb9588c9":"titatrain.describe()   #To see the max, min and other details that will help us","dfb80442":"titatrain.corr()","05ac7db0":"print(titatrain.keys())\nprint(titatest.keys())","d352ff5d":"plt.figure(figsize=(10,6))\nsns.heatmap(pd.isnull(titatrain))   #To see the missing values, the Cabin column has lots of missing values, The Age column might be useful to see what age people survived","c9fea564":"sns.distplot(titatrain['Age'].dropna(),bins=50)  # \".dropna()\" because, in our dataset there are NAN and we will get a Value Error if dropna is not present","5fb24c67":"sns.distplot(titatest['Age'].dropna(),bins=50)","d226416b":"sns.boxplot('Pclass','Age',data=titatrain)","57b00443":"PC1 = titatrain[titatrain['Pclass']==1]['Age'].mean()  #Finding the mean age of Pclass 1\nPC2 = titatrain[titatrain['Pclass']==2]['Age'].mean()  #Finding the mean age of Pclass 2\nPC3 = titatrain[titatrain['Pclass']==3]['Age'].mean()  #Finding the mean age of Pclass 3","b56f704f":"def mis(cont):                   #Will be using this function for test dataset too.\n    Age = cont[0]\n    Pclass = cont[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return PC1\n        elif Pclass == 2:\n            return PC2\n        else:\n            return PC3\n    else:\n        return Age","2cfef2b9":"titatrain['Age'] = titatrain[['Age','Pclass']].apply(mis,axis=1)","ba35bb4a":"titatrain.info()","bdd66a97":"sns.boxplot('Pclass','Age',data=titatest)","230b18ca":"PC1 = titatest[titatest['Pclass']==1]['Age'].mean()  #Finding the mean age of Pclass 1\nPC2 = titatest[titatest['Pclass']==2]['Age'].mean()  #Finding the mean age of Pclass 2\nPC3 = titatest[titatest['Pclass']==3]['Age'].mean()  #Finding the mean age of Pclass 3","0b6cb935":"titatest['Age'] = titatest[['Age','Pclass']].apply(mis,axis=1)","d90127b1":"titatest.info()","0ec698ed":"plt.figure(figsize=(13,6))\nsns.countplot('Survived',data=titatrain,hue='Sex').margins(x=0)\nplt.legend( loc = 'upper right')","10d237b1":"plt.figure(figsize=(13,6))\nsns.countplot('Survived',hue='Pclass',data=titatrain).margins(x=0)","27a466ba":"plt.figure(figsize=(13,6))\nsns.countplot('SibSp',data=titatrain).margins(x=0)","2e83fc9a":"sns.distplot(titatrain['Age'],kde=False,bins=20).margins(x=0)","73c4b717":"surages = titatrain[titatrain.Survived == 1][\"Age\"]\nnotsurages = titatrain[titatrain.Survived == 0][\"Age\"]\nplt.subplot(1, 2, 1)\nsns.distplot(surages, kde=False).margins(x=0)\nplt.title('Survived')\nplt.subplot(1, 2, 2)\nsns.distplot(notsurages, kde=False)\nplt.title('Not Survived')\nplt.subplots_adjust(right=2)","8531c62b":"sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=titatrain)","909d25c3":"sns.pairplot(titatrain,hue = 'Survived')","3ee86bb8":"Sextrain = pd.get_dummies(titatrain['Sex'],drop_first=True)\nEmbarkedtrain = pd.get_dummies(titatrain['Embarked'],drop_first=True)\nPclasstrain = pd.get_dummies(titatrain['Pclass'],drop_first=True)\n\nSextest =pd.get_dummies(titatest['Sex'],drop_first=True)\nEmbarkedtest = pd.get_dummies(titatest['Embarked'],drop_first=True)\nPclasstest = pd.get_dummies(titatest['Pclass'],drop_first=True)","4755f608":"titatrain = pd.concat([titatrain,Sextrain,Embarkedtrain,Pclasstrain],axis=1)\ntitatest = pd.concat([titatest,Sextest,Embarkedtest,Pclasstest],axis=1)","4e7aed0a":"titatrain.drop(['Embarked','Sex','Pclass','PassengerId','Cabin','Name','Ticket'],axis=1,inplace=True)","8dd3bb44":"titatrain.head()","6c40fc2c":"titatest.drop(['Pclass','Name','Sex','Ticket','Embarked','Cabin'],axis=1,inplace=True)","f84c00ea":"titatest.head()","ab8f8b05":"X_train = titatrain.drop('Survived',axis=1)  #We define the training label set\ny_train = titatrain['Survived']   #We define the training label set\ntitatest.fillna('0',inplace=True)\nX_test = titatest.drop('PassengerId',axis=1)     #We define the testing label set\n#we don't have y_test, that is what we're trying to predict with our model","484addf5":"from sklearn.model_selection import train_test_split\n\nX_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train,test_size = 0.3,random_state = 0)","b5ddcc32":"from sklearn.preprocessing import StandardScaler\n\nSc_X = StandardScaler()\nX_train = Sc_X.fit_transform(X_train)\nX_test = Sc_X.fit_transform(X_test)\nX_valid = Sc_X.fit_transform(X_valid)","70825919":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score #To evaluate the model performance\nfrom sklearn.metrics import classification_report,confusion_matrix","1db4004a":"lomo_train = LogisticRegression()\nlomo_train.fit(X_train,y_train)","0ab7e0e6":"lomo_predictions_train = lomo_train.predict(X_valid)","293d833a":"print(classification_report(y_valid,lomo_predictions_train))\nprint(confusion_matrix(y_valid,lomo_predictions_train))","5953aef5":"acc_lomo = accuracy_score(y_valid, lomo_predictions_train)\nacc_lomo","bb01b81e":"knn_train = KNeighborsClassifier(n_neighbors=1)\nknn_train.fit(X_train,y_train)","6bc9c296":"knn_predictions_train = knn_train.predict(X_valid)","6f66c487":"print(classification_report(y_valid,knn_predictions_train))\nprint(confusion_matrix(y_valid,knn_predictions_train))","7c10e340":"acc_knn1 = accuracy_score(y_valid, knn_predictions_train)\nacc_knn1","7218e056":"error_rate = []\nfor i in range(1,50):\n    \n    knn_train = KNeighborsClassifier(n_neighbors=i)\n    knn_train.fit(X_train,y_train)\n    knn_predictions_train_i = knn_train.predict(X_valid)\n    error_rate.append(np.mean(knn_predictions_train_i != y_valid))","a4af1872":"plt.figure(figsize=(10,6))\nplt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","f39e4bec":"knn_train = KNeighborsClassifier(n_neighbors=22)\nknn_train.fit(X_train,y_train)\nknn_predictions_train = knn_train.predict(X_valid)\nprint(classification_report(y_valid,knn_predictions_train))\nprint(confusion_matrix(y_valid,knn_predictions_train))","713a8e0a":"acc_knn = accuracy_score(y_valid, knn_predictions_train)\nacc_knn","f26a7bc9":"dtree_train = DecisionTreeClassifier()\ndtree_train.fit(X_train,y_train)","75974bbd":"dtree_predictions_train = dtree_train.predict(X_valid)","92b07c83":"print(classification_report(y_valid,dtree_predictions_train))\nprint(confusion_matrix(y_valid,dtree_predictions_train))","26dca6b7":"acc_dtree = accuracy_score(y_valid, dtree_predictions_train)\nacc_dtree","505aad93":"rfc_train = RandomForestClassifier(n_estimators=100)\nrfc_train.fit(X_train, y_train)","ca1d653b":"rfc_predictions_train = rfc_train.predict(X_valid)","e46edac6":"print(classification_report(y_valid,rfc_predictions_train))\nprint(confusion_matrix(y_valid,rfc_predictions_train))","fd7a4abe":"acc_rfc = accuracy_score(y_valid, dtree_predictions_train)\nacc_rfc","2f830571":"svm_train = SVC()\nsvm_train.fit(X_train, y_train)","f9600157":"svm_predictions_train = svm_train.predict(X_valid)","6f532c02":"print(classification_report(y_valid,svm_predictions_train))\nprint(confusion_matrix(y_valid,svm_predictions_train))","f8044f79":"acc_svm = accuracy_score(y_valid, svm_predictions_train)\nacc_svm","83806c36":"param_grid = {'C': [0.01,0.1,1, 10, 100, 1000,10000], 'gamma': [10,1,0.1,0.01,0.001,0.0001,0.00001], 'kernel': ['rbf']} ","46f05fe7":"grid_train = GridSearchCV(SVC(),param_grid,refit=True,verbose=10)","2b8ae3be":"grid_train.fit(X_train,y_train) ","21fb4485":"grid_train.best_params_   #to inspect the best parameters found by GridSearchCV","366df6ba":"grid_train.best_estimator_       #to inspect the best estimator found by GridSearchCV","7aba9629":"grid_predictions_train = grid_train.predict(X_valid)","00b42e7f":"print(classification_report(y_valid,grid_predictions_train))\nprint(confusion_matrix(y_valid,grid_predictions_train))","f2711618":"acc_grid_svm = accuracy_score(y_valid, grid_predictions_train)\nacc_grid_svm","744e361e":"linsvm_train = LinearSVC()\nlinsvm_train.fit(X_train, y_train)","5dfdff89":"linsvm_predictions_train = linsvm_train.predict(X_valid)","ebba6c3b":"print(classification_report(y_valid,linsvm_predictions_train))\nprint(confusion_matrix(y_valid,linsvm_predictions_train))","b15fc073":"acc_linsvm = accuracy_score(y_valid, svm_predictions_train)\nacc_linsvm","1b06e633":"xg_train = XGBClassifier()\nxg_train.fit(X_train,y_train)\nxg_predictions_train = xg_train.predict(X_valid)\nprint(classification_report(y_valid,knn_predictions_train))\nprint(confusion_matrix(y_valid,knn_predictions_train))","a113aa31":"acc_xg = accuracy_score(y_valid, xg_predictions_train)\nacc_xg","b59c94d7":"model_performance = pd.DataFrame({\n    \"Model\": [\"SVC\", \"Linear SVC\", \"Random Forest\", \n              \"Logistic Regression\", \"K Nearest Neighbors\",  \n              \"Decision Tree\",'XGB','SVC Grid'],\n    \"Accuracy\": [acc_svm, acc_linsvm, acc_rfc, \n              acc_lomo, acc_knn, acc_dtree,acc_xg,acc_grid_svm]\n})\n\nmodel_performance.sort_values(by=\"Accuracy\", ascending=False)","68572803":"xg_train.fit(X_train,y_train)","ea4c63ca":"submission_of_predictions = xg_train.predict(X_test)","f2f8e7bd":"submission = pd.DataFrame({\n        \"PassengerId\": titatest[\"PassengerId\"],\n        \"Survived\": submission_of_predictions\n    })\n\nsubmission.to_csv(\"titanic.csv\", index=False)\nprint(submission.shape)","6eb575d3":"**Logistic Regression**","1f9a3362":"**Decision Tree**","01a52355":"Approximately at K = 22 the error rate is very low, now let's change the value of K to 22","c8efe5e8":"I'm considering Class 3 to be cheapest (Ticket Price), Class 2 to be moderate (Ticket Price), and Class 3 to be costly (Ticket Price). From the above graph we can understand that the people from Class 3 have died more compared to other classes. Number of people survived is high in Class 1.","d41e36ab":"**Filling the data of Age for train and test dataset**\nWe need to fill the Age, we cannot fill one value to each missing value. We use Pclass and Age to find the mean Age of the person in the Class he is present and fill that value.","951f42e4":"So XGB has high accuracy than other models. Now let's submit","9fea00bd":"**CHECKING THE MODEL PERFORMANCE**","6e7cd68b":"We can find that the Female who survived are from Pclass 1 than from other Classes.","7ab25898":"**Linear SVM**","298fbec5":"The code runs the same loop with cross-validation, to find the best (parameter) combination, once the best combo is found then it runs fit again on all data passed to fit, all this is done to build a single new model using the best combination.","1a9224cd":"*** To convert the categorical features***  such as Sex, Embarked,Pclass and drop the First coloum in them to avoid Multicollinearity (If independent columns become dependent on each other then this happenes)","0a44830a":"**Random Forest****","faff94d4":"**XGB Classifier**","6400a994":"**Data Prediction**\n\nSeparate X and y in both Train and Test Data set","5d2a77f8":"This above prediction is for K = 1, now lets find the value of K where the error is minimum ","c3db08a4":"One of the great things about GridSearchCV is that it is a meta-estimator. It takes an estimator like SVC, and creates a new estimator, which behaves exactly the same.We should add (refit=True) and choose verbose to whatever number we want. Higher the number means there will be more verbose (where verbose means the text output describing the whole process).","adf571b2":"Importing Algorithms","a0096d6d":"**SVM using GRIDSEARCH**\n\n\nFinding the right parameters (like what C or gamma values to use) is a tricky task.The idea of creating a 'grid' of parameters and just trying out all the possible combinations is called a Gridsearch. The CV stands for cross-validation.\n\nGridSearchCV takes a dictionary that describes the parameters that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values a[](http:\/\/)re the settings to be tested.","da68655c":"**Visualization of data**","3c36382d":"We can see that the number of female survived is doubble than number of male survived. Whereas the number of male died is very high compared to female.","a2357168":"**EDA****We are going to explore the data and handle the missing values**","5ee09a39":"**KNN**","1d0b12db":"Feature Scaling","ea7ed28e":"**SVM(Suport Vector Machine)** SVC - SUPORT VECTOR CLASIFIER","a92ecda6":"We can see that most of the people have come alone and may be the '1' might be the person with spouce and very few families"}}