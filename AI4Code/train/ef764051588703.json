{"cell_type":{"d768e703":"code","30d9dff1":"code","1caa7075":"code","4458ca5c":"code","557a83d1":"code","d5662745":"code","2b28fe3b":"code","d3cf89d4":"code","60c08fd1":"code","9c5ab05a":"code","94522b7b":"code","e31962ac":"code","382bba42":"code","e009efe8":"code","35b979c0":"code","d47c4ba7":"code","9276576e":"code","555858d1":"code","19ec895e":"code","2f40d1aa":"code","c56ad491":"code","d1e93b7e":"code","c7962891":"code","fd7ccb2c":"code","68a3c815":"code","6d6a8a8a":"code","b5a7662c":"code","b1f23bcf":"code","2d823d9c":"code","76ca951b":"code","1d7199e1":"code","d7e3ffcb":"code","35e4c4e8":"code","b8406fae":"code","66a797d0":"code","b01b8e21":"code","4098b622":"code","efbd6940":"code","8d66b771":"code","cdbc395b":"code","d4393b3b":"code","b21f46f9":"code","215422aa":"code","5f907cac":"code","910d9d77":"code","f01b9759":"code","633fc531":"code","d6570798":"code","d49bc362":"code","35b15d4e":"code","c16685db":"code","8e8d2137":"code","55ae6f44":"code","563a0fb8":"code","34a0a817":"code","89bad20b":"code","4ed6f3d5":"code","fb8c5710":"code","017cb082":"code","c7fe3f26":"code","4b510e83":"code","fcbd595e":"code","4413ce08":"code","d869f20a":"code","024b31b8":"code","17818ac3":"code","731edf7d":"code","0e95421d":"code","e1551cb7":"code","121ec417":"code","a0f74383":"code","b6730bf8":"code","8fecac11":"code","711d9026":"code","faab1380":"code","957cdb07":"code","a513f052":"markdown","e6f35d04":"markdown","48b86809":"markdown","8297ba2c":"markdown","1d59221b":"markdown","c945bdf5":"markdown","06b25052":"markdown","bd8f826c":"markdown","c7c33acc":"markdown","77622953":"markdown","555dda76":"markdown","7ac8260c":"markdown","d91fdaf4":"markdown","cf4e60b1":"markdown","45d818ed":"markdown","5775ba45":"markdown","8df2ecbf":"markdown","60bf2a0d":"markdown","d9700001":"markdown","86cecc3b":"markdown","ca6c80d9":"markdown","66f9108d":"markdown","3a84b9d4":"markdown","252a7c9f":"markdown","e321912a":"markdown","2f374ab4":"markdown","9b33cb9e":"markdown","f93cc1d0":"markdown","2b8695b0":"markdown","5d7acd4b":"markdown","9e9ed131":"markdown","c3db2f39":"markdown","228b885a":"markdown","e50e7eca":"markdown","a81c567b":"markdown","839941ef":"markdown","38f12e17":"markdown","ffbcd4d0":"markdown","223409cb":"markdown","56a2e2be":"markdown","5a59c038":"markdown","09df4ad3":"markdown","e803c8bb":"markdown","402cee62":"markdown","22fbade6":"markdown","00a42694":"markdown","1407bfe2":"markdown","46729ec4":"markdown","310b2c2a":"markdown","37082be1":"markdown","cb639a03":"markdown","d9f54658":"markdown","1aa5602c":"markdown","1d7f43e9":"markdown","eb9725c3":"markdown","bb1220a6":"markdown","f65b4adc":"markdown"},"source":{"d768e703":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings # current version of seaborn generates a bunch of warnings that we'll ignore\nwarnings.filterwarnings(\"ignore\")\n\nplt.style.use('ggplot')\nsns.set(style=\"ticks\", context = 'talk', palette = 'bright', rc={'figure.figsize':(11.7,8.27)})","30d9dff1":"df = pd.read_csv('..\/input\/loan-predication\/train_u6lujuX_CVtuZ9i (1).csv')","1caa7075":"df.head()","4458ca5c":"print('Dataset has {} rows and {} columns.'.format(df.shape[0],df.shape[1]))","557a83d1":"df.dtypes","d5662745":"cat_cols = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area', 'Credit_History']\nnum_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']","2b28fe3b":"df.describe()","d3cf89d4":"df.isnull().sum()","60c08fd1":"df['Gender'].value_counts()","9c5ab05a":"df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)","94522b7b":"df['Married'].value_counts()","e31962ac":"df['Married'].fillna(df['Married'].mode()[0], inplace=True)","382bba42":"df['Dependents'].value_counts()","e009efe8":"sns.countplot(x='Dependents', hue='Married', data=df)","35b979c0":"df['Dependents'].fillna(df['Married'], inplace=True)\ndf['Dependents'] = df['Dependents'].apply(lambda x : {'No' : 0, 'Yes' : 1, '0' : 0, '1' : 1, '2' : 2, '3+' : 3}[x])","d47c4ba7":"df.loc[df['Dependents'].isna() & (df['Married'] == 'Yes')]['Dependents'].fillna('1', inplace=True)","9276576e":"df['Self_Employed'].value_counts()","555858d1":"df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)","19ec895e":"df['LoanAmount'].describe()","2f40d1aa":"sns.distplot(df['LoanAmount'], rug = True, color = 'r')","c56ad491":"df[~df['LoanAmount'].isnull()].groupby('Loan_Status').describe().T.loc['LoanAmount']","d1e93b7e":"for row in range(df.shape[0]):\n        if pd.isnull(df.loc[row, 'LoanAmount']):\n            if df.loc[row, 'Loan_Status'] == 'Y':\n                df.loc[row, 'LoanAmount'] = 151.22\n            elif df.loc[row, 'Loan_Status'] == 'N':\n                df.loc[row, 'LoanAmount'] = 144.29\n            else:\n                pass","c7962891":"df['Loan_Amount_Term'].describe()","fd7ccb2c":"df['Loan_Amount_Term'].value_counts()","68a3c815":"df[~df['Loan_Amount_Term'].isnull()].groupby('Loan_Status').describe().T.loc['Loan_Amount_Term']","6d6a8a8a":"df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)","b5a7662c":"df['Credit_History'].describe()","b1f23bcf":"df['Credit_History'].value_counts()","2d823d9c":"df[~df['Credit_History'].isnull()].groupby('Loan_Status').describe().T.loc['Credit_History']","76ca951b":"df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)","1d7199e1":"df.isna().sum()","d7e3ffcb":"df['Loan_Status'].value_counts()","35e4c4e8":"df['Loan_Status'].value_counts(normalize=True)","b8406fae":"sns.countplot(x = 'Loan_Status', data = df)","66a797d0":"plt.subplot(231)\ndf['Gender'].value_counts(normalize=True).plot.bar(figsize=(20,10), title= 'Gender')\n\nplt.subplot(232)\ndf['Married'].value_counts(normalize=True).plot.bar(title= 'Married')\n\nplt.subplot(233)\ndf['Self_Employed'].value_counts(normalize=True).plot.bar(title= 'Self_Employed')\n\nplt.subplot(234)\ndf['Credit_History'].value_counts(normalize=True).plot.bar(title= 'Credit_History')\n\nplt.subplot(235)\ndf['Education'].value_counts(normalize=True).plot.bar(title= 'Education')\n\nplt.show()","b01b8e21":"plt.subplot(121)\ndf['Dependents'].value_counts(normalize=True).plot.bar(figsize=(12,4), title= 'Dependents')\n\nplt.subplot(122)\ndf['Property_Area'].value_counts(normalize=True).plot.bar(title= 'Property_Area')\n\nplt.show()","4098b622":"plt.subplot(121)\nsns.distplot(df['ApplicantIncome']);\n\nplt.subplot(122)\ndf['ApplicantIncome'].plot.box(figsize=(16,5))\n\nplt.show()","efbd6940":"df.boxplot(column='ApplicantIncome', by = 'Education')\nplt.suptitle(\"\")","8d66b771":"plt.subplot(121)\nsns.distplot(df['CoapplicantIncome']);\n\nplt.subplot(122)\ndf['CoapplicantIncome'].plot.box(figsize=(16,5))\n\nplt.show()","cdbc395b":"plt.subplot(121)\nsns.distplot(df['LoanAmount']);\n\nplt.subplot(122)\ndf['LoanAmount'].plot.box(figsize=(16,5))\n\nplt.show()","d4393b3b":"df['Loan_Amount_Term'].value_counts(normalize=True).plot.bar(title='Loan Amount Term')","b21f46f9":"Gender = pd.crosstab(df['Gender'], df['Loan_Status'])\nprint(Gender)\nGender.div(Gender.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked=True)\nplt.ylabel('Percentage')","215422aa":"Married = pd.crosstab(df['Married'], df['Loan_Status'])\nprint(Married)\nMarried.div(Married.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked=True)\nplt.ylabel('Percentage')","5f907cac":"Edu = pd.crosstab(df['Education'], df['Loan_Status'])\nprint(Edu)\nEdu.div(Edu.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked=True)\nplt.ylabel('Percentage')","910d9d77":"SE = pd.crosstab(df['Self_Employed'], df['Loan_Status'])\nprint(SE)\nSE.div(SE.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked=True)\nplt.ylabel('Percentage')","f01b9759":"CH = pd.crosstab(df['Credit_History'], df['Loan_Status'])\nprint(CH)\nCH.div(CH.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked=True)\nplt.ylabel('Percentage')","633fc531":"prop = pd.crosstab(df['Property_Area'], df['Loan_Status'])\nprint(prop)\nprop.div(prop.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked=True)\nplt.ylabel('Percentage')","d6570798":"dep = pd.crosstab(df['Dependents'], df['Loan_Status'])\nprint(dep)\ndep.div(dep.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked=True)\nplt.ylabel('Percentage')","d49bc362":"term = pd.crosstab(df['Loan_Amount_Term'], df['Loan_Status'])\nprint(term)\nterm.div(term.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked=True)\nplt.ylabel('Percentage')","35b15d4e":"print(df.groupby('Loan_Status')['ApplicantIncome'].mean())\n\ndf.groupby('Loan_Status')['ApplicantIncome'].mean().plot.bar()\nplt.ylabel('Applicant Income')","c16685db":"bins = [0,2500,4000,6000,81000]\ngroup = ['Low','Average','High', 'Very high']\ndf['Income_bins'] = pd.cut(df['ApplicantIncome'],bins,labels=group)\n\nIncome_bin = pd.crosstab(df['Income_bins'],df['Loan_Status'])\nprint(Income_bin)\nIncome_bin.div(Income_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\nplt.xlabel('ApplicantIncome')\nP = plt.ylabel('Percentage')","8e8d2137":"bins = [0,1000,3000,42000]\ngroup = ['Low','Average','High']\ndf['Co_Income_bins'] = pd.cut(df['CoapplicantIncome'],bins,labels=group)\n\nCoIncome_bin = pd.crosstab(df['Co_Income_bins'],df['Loan_Status'])\nprint(CoIncome_bin)\nCoIncome_bin.div(CoIncome_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\nplt.xlabel('Co-Applicant Income')\nP = plt.ylabel('Percentage')","55ae6f44":"print(\"{:.2f}% of Co-applicant's income is 0\".format(len(df[df['CoapplicantIncome'] == 0])\/len(df)*100))","563a0fb8":"df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n\nbins = [0,2500,4000,6000,81000]\ngroup = ['Low','Average','High', 'Very high']\ndf['Total_Income_bins'] = pd.cut(df['Total_Income'],bins,labels=group)\n\nTotal_Income_bin = pd.crosstab(df['Total_Income_bins'],df['Loan_Status'])\nprint(Total_Income_bin)\nTotal_Income_bin.div(Total_Income_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\nplt.xlabel('Total Income')\nP = plt.ylabel('Percentage')","34a0a817":"bins = [0,100,300,700]\ngroup = ['Low','Average','High']\ndf['LoanAmount_bins'] = pd.cut(df['LoanAmount'],bins,labels=group)\n\nLoan_bin = pd.crosstab(df['LoanAmount_bins'],df['Loan_Status'])\nprint(Loan_bin)\nLoan_bin.div(Loan_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\nplt.xlabel('Loan Amount')\nP = plt.ylabel('Percentage')","89bad20b":"df.drop(['Income_bins', 'Co_Income_bins', 'Total_Income', 'Total_Income_bins', 'LoanAmount_bins'], axis=1, inplace=True)","4ed6f3d5":"df.columns","fb8c5710":"df['Loan_Status'] = df['Loan_Status'].apply(lambda x : {'N' : 0, 'Y' : 1}[x])","017cb082":"sns.heatmap(df.corr(), square=True, cmap='BuPu', annot=True)","c7fe3f26":"ax1 = plt.subplot(121)\ndf['LoanAmount'].hist(bins=20, figsize=(12,4))\nax1.set_title(\"Loan Amount\")","4b510e83":"df['LoanAmount'] = np.log(df['LoanAmount'])","fcbd595e":"ax1 = plt.subplot(121)\ndf['LoanAmount'].hist(bins=20, figsize=(12,4))\nax1.set_title(\"Loan Amount\")","4413ce08":"df.drop('Loan_ID', axis=1, inplace=True)","d869f20a":"df['Property_Area'].unique()","024b31b8":"df['Gender'] = df['Gender'].apply(lambda x : {'Male' : 1, 'Female' : 0}[x])\ndf['Married'] = df['Married'].apply(lambda x : {'Yes' : 1, 'No' : 0}[x])\ndf['Education'] = df['Education'].apply(lambda x : {'Graduate' : 1, 'Not Graduate' : 0}[x])\ndf['Self_Employed'] = df['Self_Employed'].apply(lambda x : {'Yes' : 1, 'No' : 0}[x])\ndf['Property_Area'] = df['Property_Area'].apply(lambda x : {'Semiurban': 2, 'Urban' : 1, 'Rural' : 0}[x])\ndf.dtypes","17818ac3":"df.head()","731edf7d":"df.describe()","0e95421d":"X = df.drop('Loan_Status', axis=1)\nY = df['Loan_Status']","e1551cb7":"models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost Classifier']\naccs = []\nf1 = []\naucs = []","121ec417":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","a0f74383":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, f1_score, classification_report, roc_curve, roc_auc_score\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\naccs.append(np.mean(y_pred==y_test)*100)\nf1.append(f1_score(y_test, y_pred))\n\nprint(classification_report(y_test, y_pred))\n\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\n\naucs.append(auc)\n\nplt.figure(figsize=(12,8))\nplt.plot(fpr,tpr,label=\"validation, auc=\"+str(auc))\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=4)\nplt.show()","b6730bf8":"from sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\naccs.append(np.mean(y_pred==y_test)*100)\nf1.append(f1_score(y_test, y_pred))\n\nprint(classification_report(y_test, y_pred))\n\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\nplt.figure(figsize=(12,8))\n\naucs.append(auc)\n\nplt.plot(fpr,tpr,label=\"validation, auc=\"+str(auc))\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=4)\nplt.show()","8fecac11":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\naccs.append(np.mean(y_pred==y_test)*100)\nf1.append(f1_score(y_test, y_pred))\n\nprint(classification_report(y_test, y_pred))\n\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\n\naucs.append(auc)\n\nplt.figure(figsize=(12,8))\nplt.plot(fpr,tpr,label=\"validation, auc=\"+str(auc))\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=4)\nplt.show()","711d9026":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(random_state=1, n_estimators=50, max_depth=4)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\naccs.append(np.mean(y_pred==y_test)*100)\nf1.append(f1_score(y_test, y_pred))\n\nprint(classification_report(y_test, y_pred))\n\nfpr, tpr, _ = roc_curve(y_test,  y_pred)\nauc = roc_auc_score(y_test, y_pred)\n\naucs.append(auc)\n\nplt.figure(figsize=(12,8))\nplt.plot(fpr,tpr,label=\"validation, auc=\"+str(auc))\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=4)\nplt.show()","faab1380":"report = pd.DataFrame({'Models': models, 'Accuracy': accs, 'F1-Score': f1, 'AUC': aucs})\nreport.sort_values('F1-Score', inplace=True, ascending=False)","957cdb07":"report","a513f052":"So for both the cases mean was of 360 so replcaing null values with 360","e6f35d04":"### Missing Values\n\nTo start with data analysis we whould first remove\/fill the missing values if any.","48b86809":"After having a look at the following description it is known that there are missing values in our dataset. So for that we will either fill the missing values with some value or we will discard those particular rows.","8297ba2c":"### *Target Variable (Categorical Yes\/No )*","1d59221b":"# Loan Status Prediction\n\n#### Problem Statement:\n\nAbout Company\n\nDream Housing Finance company deals in all home loans. They have presence across all urban, semi urban and rural areas. Customer first apply for home loan after that company validates the customer eligibility for loan.\n\nProblem\n\nCompany wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set.\n\n![image.png](attachment:image.png)","c945bdf5":"Now we have to check how each feature goes with the loan status, i.e. the correltaion with the target variable.\n\n### *Independent Variable v\/s Target Variable*","06b25052":"So the data is kind of balanced as it is 68% of Yes and 32% of No. So there is no need to remove samples","bd8f826c":"## Hypothesis\n\nHypothesis are all the possible factors that can affect the outcome i.e. which of the features will have an impact on whether a loan will be approved or not. Some of them are:\n\n1. Education - Applicants with higher education level i.e. graduate level should have higher chances of loan approval\n2. Income: Applicants with higher income should have more chances of loan approval\n3. Loan amount: If the loan amount is less, the chances of loan approval should be high\n4. Loan term: Loans with shorter time period should have higher chances of approval\n5. Previous credit history: Applicants who have repayed their previous debts should have higher chances of loan approval\n6. Monthly installment amount: If the monthly installment amount is low, the chances of loan approval should be high\n\nAnd so on. Some of the hypothesis seem intuitive while others may not. We will try to validate each of these hypothesis based on the dataset.","c7c33acc":"### *Ordinal Variables*","77622953":"So for approved loans the mean is 151.22 and for unapproved loans the mean is 144.29","555dda76":"## Univariate Analysis","7ac8260c":"Loan Amount Term","d91fdaf4":"With the above plots we can say that our hypothesis hold true, as applicant with low income are quite likey to not get the loan approval and also if the loan amount is high the loan approval chances becomes less.\n\nSo now we should drop the bins we have created.","cf4e60b1":"# Model Building\n\nBefore model building lets have a look at our data","45d818ed":"From the above plots we can infer that: \n* Applicant having a bad credit history will not get the loan. \n* Gender and Self-employed don't play a huge role in determining the loan status, i.e. irrespective of the gender and self-employement the applicant's loan approval chances are high.\n* Married applicants have higher chance of loan approval\n* Applicants who have graduated have higher chance of loan approval.\n* Applicants living in semi-urban areas are likely to get loan approval ahead of urban and rural area applicants.\n* Applicants having 2 dependents are likely to get loan approval as compared to other.\n* Since most of the applicants apply for 30 years term we can observe that there is a good chance of approval for 30 years term.","5775ba45":"The model performance is pretty good as we get a precision of 83% and recall of 99%","8df2ecbf":"So the applicant will be having higher probability of having a dependent when he is married. Otherwise the applicant would not have dependent. This would refer to having a child after marriage, so the child would be the dependent in this case. ","60bf2a0d":"Here it is observed that the data is not normally distributed. The above data is right skewed, so we would want to remove this skewness as the ML algorithms tend to work better if the data is normally distributed. Also the Applicant Income has a lot of outliers, we need to remove the outliers as they would create problem while model training.\n\nThe extreme values\/outliers at the applicant income can be caused by education, as people with different education have different income. Lets check that","d9700001":"There is not much difference in applicant income for approval and disapproval of the loan.\nSo we have to make bins i.e. sections like low income, average income, high income.","86cecc3b":"Gender","ca6c80d9":"As per our hypothesis loan amount and income are correlated to each other. Also credit history and loan status are strongly correlated with each other.","66f9108d":"Again the majority of the applicants are married we would replace the 3 null values with \"Yes\"","3a84b9d4":"Our target variable is not evenly distributed, i.e. more than 65% of the loans were approved while the rest were not.","252a7c9f":"# Data Pre-processing\n\nEarlier we replaced the null values with the correct values. Now we will do outlier treatment.\n\nAs we saw earlier in univariate analysis, LoanAmount contains outliers so we have to treat them as the presence of outliers affects the distribution of the data. Having outliers in the dataset often has a significant effect on the mean and standard deviation and hence affecting the distribution. We must take steps to remove outliers from our data sets.\n\nDue to these outliers bulk of the data in the loan amount is at the left and the right tail is longer. This is called right skewness (or positive skewness). One way to remove the skewness is by doing the log transformation. As we take the log transformation, it does not affect the smaller values much, but reduces the larger values. So, we get a distribution similar to normal distribution.\n\nLet\u2019s visualize the effect of log transformation. We will do the similar changes to the test file simultaneously.","e321912a":"Dependents","2f374ab4":"Since more than 75% applicants have credit history as 1 we will replace null values with 1.0","9b33cb9e":"As the majority of the aplicants are male we would simply fill the null values with Male gender.","f93cc1d0":"So simply filling the loan value with mean amount is not a good idea. Instead we should replace null according to the loan status i.e. if LoanStatus is YES then replace with the mean of approved loan amount and if it is NO then replace with the mean of unapproved loan amount. ","2b8695b0":"About 85% of the applicants have applied for a term of 360 months i.e. 30 years.","5d7acd4b":"Self-employed","9e9ed131":"Here the crosstab feature provides us the count of males and female whose loan is accepted and not accpeted.","c3db2f39":"Credit History","228b885a":"So nearly 85% of the applicants are not employed. So filling the null values as not employed.","e50e7eca":"So gender, married, dependents, self-employed, loan amount, loan amount term and credit history have null values\n\nSo first lets have a look at the variables and their distribution","a81c567b":"Since Loan_ID is not useful we will drop that","839941ef":"Such a huge number of co-applicants have 0 income so we will combine both the income and then see the result.","38f12e17":"### *Numerical Variables*","ffbcd4d0":"## Exploratory Data Analysis","223409cb":"Now we should check the correlation among the numerical features.","56a2e2be":"### Loading the dataset","5a59c038":"From the above plots it is found that:\n* Around 80% of the applicants are Male\n* More than 60% applicants are married\n* More than 80% applicants are not self-employed\n* More than 80% applicants have repaid their debts (credit history)\n* Around 80% applicants are Graduates.","09df4ad3":"Nearly 80% of the applicants loan amount terms were 360","e803c8bb":"Before we build our model we have to convert the categorical values into numbers. This can be done by simply replacing the values with 0, 1, 2 and so on. Or we can do a pd.get_dummies() to create a new dataframe with such data.","402cee62":"Married","22fbade6":"## Bivariate Analysis","00a42694":"The LoanAmount seems to be fairly normally distributed. But it is slightly right skewed. There are a lot of outliers in case of LoanAmount. We will have to treat them.","1407bfe2":"## Improvements to be done:\n* Feature engineering can be done, for example new features like total income, emi can be created using the current set of features\n* Use cross validation techniques to train the models. Techniques like k-fold cross validation, stratified cross validation and look out once cross validation can be used to get better results.\n* Comparison of features with others can be done, for example comparing the income with gender and so on. With this new patterns will be noticed and hence hypothesis generation will be enhanced.\n* One could use neural networks to train the model. Libraries like sklearn having MLP classifier, keras, tensorflow, pytorch can be used.","46729ec4":"From the above plots it is found that:\n* Majority of the applicants dont have any dependents.\n* Most of the applicants reside in semi urban regions.","310b2c2a":"There is a similar distribution in case of coapplicant income.","37082be1":"## *Numerical v\/s Target Variable*\n\nNow lets look at the relation of variables like LoanAmount, ApplicantIncome, CoapplicantIncome, Loan_Amount_term with the LoanStatus","cb639a03":"So graduates having higher income tend to be the outliers for us.","d9f54658":"### *Other Categorical Variable*","1aa5602c":"Everything is at its place so now lets start with model building. \n\nFirstly we have to seperate the features and target","1d7f43e9":"We have to check what percentage of co applicants income is 0","eb9725c3":"Looking at the datatypes it is found that there are a lot of categorical variables like Education, Self-Employed, Married, Gender, Dependents, Property Area and Loan Status. There a few numerical variables like Applicant Income, Loan Amount, Loan Amount Term, Credit History and Co-applicant income.\n\n","bb1220a6":"So now there are no null values and we will continue with univariate and bivariate analysis","f65b4adc":"Loan Amount"}}