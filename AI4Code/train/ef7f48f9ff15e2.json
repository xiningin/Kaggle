{"cell_type":{"cb318150":"code","c6b9e26b":"code","2d15811d":"code","b3ab97dd":"code","3b0cf5c7":"code","042d6722":"code","14e367a0":"code","51cde800":"code","5e61bc06":"code","a7f89962":"code","11816ac1":"code","1c803278":"code","97f30957":"code","0e2077c3":"code","7a92101c":"code","d82837ab":"code","6d3f8c67":"code","0246e0c7":"code","82b91018":"code","909b8f40":"code","53ca9dfe":"code","981a01b7":"code","6c2abc5e":"code","e411de29":"code","21f37342":"code","b2240d7a":"code","fe227eea":"code","1dae122e":"code","33fb27df":"code","d75980e8":"markdown","12bbd73f":"markdown","aed19122":"markdown","8eef241d":"markdown","d1e79735":"markdown","71c36d26":"markdown","a7fdc659":"markdown","3074ef78":"markdown","c22bb63e":"markdown","579121dc":"markdown","2fecdb00":"markdown","cf385add":"markdown","2fd0c6c2":"markdown","e6332a1f":"markdown"},"source":{"cb318150":"# Removing warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Importing files\nimport json\nfrom pandas.io.json import json_normalize\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import hstack\n\n# Visualisation\nimport matplotlib.pyplot as plt\n\n# Train\/Test split\nfrom sklearn.model_selection import train_test_split\n\n# Preprocessing\nimport re\nimport string\nimport gensim\n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Models\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\nfrom sklearn.model_selection import GridSearchCV\n\n# Evaluation\nfrom sklearn.metrics import roc_auc_score","c6b9e26b":"train = json.load(open('..\/input\/random-acts-of-pizza\/train.json'))\ntrain = json_normalize(train)\ntest = json.load(open('..\/input\/random-acts-of-pizza\/test.json'))\ntest = json_normalize(test)\n\nprint(\"Train :\", train.shape[0], \"rows\", train.shape[1], \"columns\")\nprint(\"Test :\", test.shape[0], \"rows\", test.shape[1], \"columns\")","2d15811d":"in_train_not_in_test = set(train.columns.values)-set(test.columns.values)\nin_test_but_not_in_train = set(test.columns.values)-set(train.columns.values)\nshared = set([c for c in train.columns.values if c in test.columns.values])\n\nprint(\"In train but not in test\")\nprint(in_train_not_in_test, \"\\n\")\nprint(\"In test but not in train\")\nprint(in_test_but_not_in_train, \"\\n\")\nprint(\"Shared\")\nprint(shared)","b3ab97dd":"shared.add('requester_received_pizza')\nshared = list(shared)\ntrain = train[shared]","3b0cf5c7":"dev_data, valid_data, dev_labels, valid_labels = \\\n    train_test_split(train, train['requester_received_pizza'], test_size=0.2)","042d6722":"dev_data.describe()","14e367a0":"success = dev_data[dev_data.requester_received_pizza == True]\nfailure = dev_data[dev_data.requester_received_pizza == False]\n\nprint(round(len(success)\/len(dev_data)*100, 2), \"% successfull requests\")","51cde800":"dev_data['datetime'] = pd.to_datetime(dev_data.unix_timestamp_of_request_utc, unit='s')\ndev_data['day'] = dev_data.datetime.dt.dayofweek\ndev_data['hour'] = dev_data.datetime.dt.hour\ndev_data['month'] = dev_data.datetime.dt.month\n\nplt.figure()\nplt.title(\"Distribution of requests accross the year\")\nplt.xlabel(\"Month of the year\")\nplt.ylabel(\"Percentage\")\nplt.xticks(list(range(12)), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\nplt.plot(list(range(12)), [len(dev_data[dev_data.month == i])\/len(dev_data)*100 for i in range(12)], 'bo', label='All requests')\nplt.plot(list(range(12)), [len(dev_data[dev_data.requester_received_pizza == True][dev_data.month == i])\/len(dev_data[dev_data.month == i])*100 if len(dev_data[dev_data.month == i]) > 0 else 0 for i in range(12)], 'rx', label='Successful requests')\nplt.legend()\n\nplt.figure()\nplt.title(\"Distribution of requests accross the week\")\nplt.xlabel(\"Day of the week\")\nplt.ylabel(\"Percentage\")\nplt.xticks(list(range(7)), ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\nplt.plot(list(range(7)), [len(dev_data[dev_data.day == i])\/len(dev_data)*100 for i in range(7)], 'bo', label='All requests')\nplt.plot(list(range(7)), [len(dev_data[dev_data.requester_received_pizza == True][dev_data.day == i])\/len(dev_data[dev_data.day == i])*100 for i in range(7)], 'rx', label='Successful requests')\nplt.legend()\n\nplt.figure()\nplt.title(\"Distribution of requests accross the clock\")\nplt.xlabel(\"Time of the day\")\nplt.ylabel(\"Percentage\")\nplt.plot(list(range(24)), [len(dev_data[dev_data.hour == i])\/len(dev_data)*100 for i in range(24)], 'bo', label='All requests')\nplt.plot(list(range(24)), [len(dev_data[dev_data.requester_received_pizza == True][dev_data.hour == i])\/len(dev_data[dev_data.hour == i])*100 for i in range(24)], 'rx', label='Successful requests')\nplt.legend()","5e61bc06":"def compare_criterion(data, column):\n    data.boxplot(column=[column], by='requester_received_pizza')","a7f89962":"# Age\ncompare_criterion(dev_data, 'requester_account_age_in_days_at_request')\n# Number of days since first post\ncompare_criterion(dev_data, 'requester_days_since_first_post_on_raop_at_request')\n# Subreddits\n#compare_criterion(dev_data, 'requester_subreddits_at_request')\ncompare_criterion(dev_data, 'requester_number_of_subreddits_at_request')\n# Comments\ncompare_criterion(dev_data, 'requester_number_of_comments_at_request')\ncompare_criterion(dev_data, 'requester_number_of_comments_in_raop_at_request')\n# Posts\ncompare_criterion(dev_data, 'requester_number_of_posts_at_request')\ncompare_criterion(dev_data, 'requester_number_of_posts_on_raop_at_request')\n# Upvotes\ncompare_criterion(dev_data, 'requester_upvotes_plus_downvotes_at_request')\ncompare_criterion(dev_data, 'requester_upvotes_minus_downvotes_at_request')","11816ac1":"def make_non_textual_features(data):\n    mat = pd.DataFrame()\n    \n    # Time\n    mat['datetime'] = pd.to_datetime(data['unix_timestamp_of_request_utc'], unit='s')\n    mat['month'] = mat['datetime'].dt.month\n    mat['day_of_week'] = mat['datetime'].dt.dayofweek\n    mat['day_of_month'] = mat['datetime'].dt.day\n    mat['hour'] = mat['datetime'].dt.hour\n    del mat['datetime']\n    \n    # Age\n    mat['age'] = data['requester_account_age_in_days_at_request']\n    mat['community_age'] = (pd.to_datetime(data['unix_timestamp_of_request_utc'], unit = 's') - pd.to_datetime('2010-12-8', format='%Y-%m-%d')).astype('timedelta64[D]')\n    \n    # Popularity and activity\n    mat['first_post']= data['requester_days_since_first_post_on_raop_at_request']\n    mat['subreddits'] = data['requester_number_of_subreddits_at_request']\n    mat['posts'] = data['requester_number_of_posts_at_request']\n    mat['posts_pizza'] = data['requester_number_of_posts_on_raop_at_request']\n    mat['comments'] = data['requester_number_of_comments_at_request']\n    mat['comments_pizza'] = data['requester_number_of_comments_in_raop_at_request']\n    mat['giver'] = data['giver_username_if_known'].apply(lambda x: 0 if x=='N\/A' else 1)\n    \n    # Votes\n    mat['upvotes_plus_downvotes'] = data['requester_upvotes_plus_downvotes_at_request']\n    mat['upvotes_minus_downvotes'] = data['requester_upvotes_minus_downvotes_at_request']\n    upvotes = mat.apply(lambda row : (row['upvotes_plus_downvotes'] + row['upvotes_minus_downvotes'])\/2, axis=1)\n    downvotes = mat.apply(lambda row : (row['upvotes_plus_downvotes'] - row['upvotes_minus_downvotes'])\/2, axis=1)\n    mat['upvotes'] = upvotes\n    mat['downvotes'] = downvotes\n    mat['votes_ratio'] = upvotes \/ (upvotes + downvotes + 1)\n\n    return mat.as_matrix()","1c803278":"dev_non_textual = make_non_textual_features(dev_data)\nvalid_non_textual = make_non_textual_features(valid_data)","97f30957":"en_stopwords = set(stopwords.words('english'))\npunctuation = set(string.punctuation)\nblacklist = set.union(en_stopwords, punctuation)","0e2077c3":"w2v = gensim.models.KeyedVectors.load_word2vec_format('..\/input\/google-word-to-vec\/GoogleNews-vectors-negative300.bin', binary=True)  ","7a92101c":"def tokenize(s):\n    tokens = \"\"\n    sentences = sent_tokenize(s.lower())\n    for sentence in sentences:\n        words = word_tokenize(sentence)\n        for word in words:\n            if len(word) and word not in blacklist and not(word.isdigit()):\n                tokens += word + \" \"\n    return tokens[:-1]","d82837ab":"def representation(s):\n    vector = np.zeros(w2v.wv['the'].shape)\n    count = 0\n    for word in s.split():\n        if word in w2v:\n            count += 1\n            vector = vector +  w2v[word]\n    if count:\n        vector \/= count\n    return vector","6d3f8c67":"dev_request_tokens = dev_data['request_text_edit_aware'].apply(tokenize)\ndev_request_len = dev_request_tokens.apply(lambda x : x.split()).apply(len)\ndev_title_tokens = dev_data['request_title'].apply(tokenize)\ndev_title_len = dev_title_tokens.apply(lambda x : x.split()).apply(len)\ndev_all_tokens = dev_title_tokens.map(str) + ' ' + dev_request_tokens\n\nvalid_request_tokens = valid_data['request_text_edit_aware'].apply(tokenize)\nvalid_request_len = valid_request_tokens.apply(lambda x : x.split()).apply(len)\nvalid_title_tokens = valid_data['request_title'].apply(tokenize)\nvalid_all_tokens = valid_title_tokens.map(str) + ' ' + valid_request_tokens","0246e0c7":"vectorizer = TfidfVectorizer(min_df=5, ngram_range=(1,2), norm='l2', sublinear_tf=True)\ndev_bow = vectorizer.fit_transform(dev_all_tokens)\nvalid_bow = vectorizer.transform(valid_all_tokens)\n\nlr = LogisticRegression(C=1,penalty='l1').fit(dev_bow, dev_labels)\nmodel = SelectFromModel(lr, prefit=True)\ndev_pruned_bow = model.transform(dev_bow)\nvalid_pruned_bow = model.transform(valid_bow)","82b91018":"cv = CountVectorizer(min_df=5,ngram_range=(1,1))\ndev_cv = cv.fit_transform(dev_all_tokens)\nvalid_cv = cv.transform(valid_all_tokens)\n\nlda = LDA(n_components = 5, learning_method=\"batch\", max_iter=30, learning_decay=.7)\ndev_topics = lda.fit_transform(dev_cv)\nvalid_topics = lda.transform(valid_cv)","909b8f40":"dev_representation = dev_all_tokens.apply(representation)\nvalid_representation = valid_all_tokens.apply(representation)","53ca9dfe":"dev_representation = np.array(dev_representation.tolist())\nvalid_representation = np.array(valid_representation.tolist())","981a01b7":"del dev_request_tokens, dev_title_tokens, dev_all_tokens\ndel valid_request_tokens, valid_title_tokens, valid_all_tokens","6c2abc5e":"dev_inputs = np.zeros((dev_non_textual.shape[0], dev_non_textual.shape[1] + 2))\ndev_inputs[:,:-2] = dev_non_textual\ndev_inputs[:,-2] = dev_request_len\ndev_inputs[:,-1] = dev_title_len\n\nvalid_inputs = np.zeros((valid_non_textual.shape[0], valid_non_textual.shape[1] + 2))\nvalid_inputs[:,:-2] = valid_non_textual\nvalid_inputs[:,-2] = valid_request_len\nvalid_inputs[:,-1] = valid_title_len","e411de29":"dev_input = hstack([dev_inputs, dev_pruned_bow, dev_topics, dev_representation])\nvalid_input = hstack([valid_inputs, valid_pruned_bow, valid_topics, valid_representation])","21f37342":"lr = LogisticRegression()\nparameters = {'C':np.linspace(0.005, 0.1, 100)}\ngs = GridSearchCV(lr, parameters, cv=5)\ngs.fit(dev_input, dev_data['requester_received_pizza'])","b2240d7a":"pred_valid_prob = gs.predict_proba(valid_input)[:,1]\npred_valid_labels = gs.predict(valid_input)\n\nprint(gs.best_params_)\nroc_auc_score(valid_data['requester_received_pizza'], pred_valid_prob, average='micro')","fe227eea":"valid_labelss = valid_data['requester_received_pizza'].as_matrix()\n\nsuccess_count = 0\nfailure_count = 0\n\nsuccess_correct = 0\nfailure_correct = 0\nfor i in range(len(valid_labelss)):\n    if valid_labelss[i]:\n        success_count += 1\n        if pred_valid_labels[i]:\n            success_correct += 1\n    else:\n        failure_count += 1\n        if not(pred_valid_labels[i]):\n            failure_correct += 1","1dae122e":"print(round(success_correct \/ success_count*100, 2), \"% accurate prediction on success\")\nprint(round(failure_correct \/ failure_count*100, 2), \"% accurate prediction on failure\")","33fb27df":"print(round((success_correct + failure_correct) \/ (success_count + failure_count)*100, 2), \"% accurate prediction in total\")","d75980e8":"### Word 2 Vec representation","12bbd73f":"# 4. Building model","aed19122":"# 2. Variables exploration","8eef241d":"# 3. Extracting features\n\n## 3.1 Non-textual features","d1e79735":"## 4.3. Detailed evaluation","71c36d26":"### Topics","a7fdc659":"## 4.2. Global evaluation","3074ef78":"# 1. Importing libraries and loading files","c22bb63e":"## 3.3 Merging inputs","579121dc":"## 4.1. Training","2fecdb00":"## 2.2 Other non-textual columns","cf385add":"## 2.1 Columns related to time","2fd0c6c2":"## 3.2 Textual features","e6332a1f":"### Bags of words"}}