{"cell_type":{"bf55e7cc":"code","e144b72f":"code","1bce389c":"code","0f32cc06":"code","29588b80":"code","44c247e8":"code","aad4d694":"code","bba02013":"code","ed1ef73b":"code","5ce4b2fd":"code","eba4b006":"code","015a756f":"code","ea7ccf3e":"code","079a03a3":"code","70676f77":"code","844f4cf0":"code","d28ebec6":"code","d1881dc2":"code","05fae8ef":"code","28096427":"code","c126f33b":"code","56aed83b":"code","362b4e7b":"code","bbc9b5ce":"code","6d1a1d1a":"code","0c6d938b":"code","2521c31d":"code","dfc20c7c":"code","0781bdf1":"code","f2e826a9":"code","012c0516":"code","5e57364b":"code","09651641":"code","db9afc92":"code","16125b4a":"code","adbe6e51":"code","40386cee":"code","22d79304":"code","75a288d1":"code","8840f38d":"code","9a2b19d7":"code","d99d9045":"code","60ccfe04":"code","c4d252bf":"code","5230b123":"code","bd0a13e0":"code","d9f276ef":"code","dae38169":"code","b2391503":"code","bdf9670b":"code","243d0531":"code","fe310d50":"code","71afec86":"code","fa082ae2":"code","dbf6291f":"code","8896557c":"code","c16f5696":"code","8602ef99":"code","e400e0b0":"code","bcb39f4b":"code","f663c700":"code","d76fb601":"code","65eef7c7":"code","d69719ea":"code","54822f40":"code","3be4ba80":"code","aeb40bb6":"code","a91d78a4":"code","504d4bbf":"code","556b7e26":"code","0d613be9":"code","fabfb4c1":"code","f6372c45":"code","599f919b":"code","4999fef9":"code","3e625ba2":"code","23464cfa":"code","57f1b579":"code","7a3643f2":"code","ddfbed1f":"code","01b980b2":"code","60a43ee3":"code","081ae69f":"code","a9932dd9":"code","49dada17":"code","928c9318":"code","9db79601":"code","0001a8d2":"code","e630384b":"code","687c6e0e":"code","35bee6e6":"code","f04777fc":"code","f5c075f7":"code","9a1ba899":"code","37c437e5":"code","3e4c1ea6":"code","747f48de":"code","7bf8f80e":"code","4155797b":"code","57474c2d":"code","a15d1eae":"code","a255131c":"code","f7aa390b":"code","f05e45be":"code","cee3e5b6":"code","deb4213a":"code","5e2a054e":"markdown","41824a93":"markdown","f940771e":"markdown","fb25c160":"markdown","ef4cdacd":"markdown","6df5744d":"markdown","d3c300a6":"markdown","d1ffb916":"markdown","73847388":"markdown","0e45742e":"markdown","1c0f2e4e":"markdown","532759c9":"markdown","fb01568b":"markdown","7cfd319b":"markdown","048d744d":"markdown","a170250c":"markdown","b2650085":"markdown","a4de6178":"markdown","4228d576":"markdown","7e6b22fa":"markdown","111eb721":"markdown","ba3705b9":"markdown","c5653eda":"markdown","cb1a9c05":"markdown","a812ba95":"markdown","0f7a7e1e":"markdown","075426e8":"markdown","84c49c54":"markdown","787a3ebb":"markdown","ab8d5f17":"markdown","49b968a5":"markdown","39c855ff":"markdown","1c21b6e4":"markdown","e03632dc":"markdown","0a3e8c99":"markdown","898c37d9":"markdown","b1ed4d57":"markdown","2f514b99":"markdown","5d261fbf":"markdown","9c0f37fa":"markdown","69d85b8a":"markdown"},"source":{"bf55e7cc":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","e144b72f":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","1bce389c":"# copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","0f32cc06":"train.head()","29588b80":"test.head()","44c247e8":"train.info()","aad4d694":"train.describe().T","bba02013":"train['Pclass'].value_counts()","ed1ef73b":"train['Sex'].value_counts()","5ce4b2fd":"train['SibSp'].value_counts()","eba4b006":"train['Parch'].value_counts()","015a756f":"train['Ticket'].value_counts()","ea7ccf3e":"train['Cabin'].value_counts()","079a03a3":"train['Embarked'].value_counts()","70676f77":"sns.barplot(x = 'Pclass', y = 'Survived', data = train);","844f4cf0":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","d28ebec6":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","d1881dc2":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","05fae8ef":"train.head()","28096427":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","c126f33b":"train.describe().T","56aed83b":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","362b4e7b":"Q1 = train['Fare'].quantile(0.25)\nQ3 = train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","bbc9b5ce":"# observations with Fare data higher than the upper limit:\n\ntrain['Fare'] > (upper_limit)","6d1a1d1a":"train.sort_values(\"Fare\", ascending=False).head()","0c6d938b":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \ntrain['Fare'] = train['Fare'].replace(512.3292, 300)","2521c31d":"train.sort_values(\"Fare\", ascending=False).head()","dfc20c7c":"test.sort_values(\"Fare\", ascending=False)","0781bdf1":"test['Fare'] = test['Fare'].replace(512.3292, 300)","f2e826a9":"test.sort_values(\"Fare\", ascending=False)","012c0516":"train.isnull().sum()","5e57364b":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","09651641":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","db9afc92":"train.isnull().sum()","16125b4a":"test.isnull().sum()","adbe6e51":"train.isnull().sum()","40386cee":"test.isnull().sum()","22d79304":"train[\"Embarked\"].value_counts()","75a288d1":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","8840f38d":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","9a2b19d7":"train.isnull().sum()","d99d9045":"test.isnull().sum()","60ccfe04":"test[test[\"Fare\"].isnull()]","c4d252bf":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","5230b123":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","bd0a13e0":"test[\"Fare\"].isnull().sum()","d9f276ef":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ntrain[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\ntrain.head()","dae38169":"train.isnull().sum()","b2391503":"test.isnull().sum()","bdf9670b":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","243d0531":"train.head()","fe310d50":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","71afec86":"train.head()","fa082ae2":"train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","dbf6291f":"train.head()","8896557c":"train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')","c16f5696":"test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","8602ef99":"train.head()","e400e0b0":"test.head()","bcb39f4b":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","f663c700":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","d76fb601":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","65eef7c7":"train.isnull().sum()","d69719ea":"test['Title'] = test['Title'].map(title_mapping)","54822f40":"test.head()","3be4ba80":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","aeb40bb6":"train.head()","a91d78a4":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)","504d4bbf":"# Map each Age value to a numerical value:\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)","556b7e26":"train.head()","0d613be9":"#dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","fabfb4c1":"train.head()","f6372c45":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])","599f919b":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","4999fef9":"train.head()","3e625ba2":"train.head()","23464cfa":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","57f1b579":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","7a3643f2":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","ddfbed1f":"train.head()","01b980b2":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","60a43ee3":"test.head()","081ae69f":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")","a9932dd9":"train.head()","49dada17":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")","928c9318":"test.head()","9db79601":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")","0001a8d2":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","e630384b":"train.head()","687c6e0e":"test.head()","35bee6e6":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","f04777fc":"x_train.shape","f5c075f7":"x_test.shape","9a1ba899":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","37c437e5":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","3e4c1ea6":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","747f48de":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","7bf8f80e":"xgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","4155797b":"xgb_cv_model.fit(x_train, y_train)","57474c2d":"xgb_cv_model.best_params_","a15d1eae":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","a255131c":"xgb_tuned =  xgb.fit(x_train,y_train)","f7aa390b":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","f05e45be":"test","cee3e5b6":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = xgb_tuned.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","deb4213a":"output.head()","5e2a054e":"**Variable Notes:**\n\nPclass: A proxy for socio-economic status (SES)\n- 1st = Upper\n- 2nd = Middle\n- 3rd = Lower\n\nAge: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nSibSp: The dataset defines family relations in this way...\n- Sibling = brother, sister, stepbrother, stepsister\n- Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nParch: The dataset defines family relations in this way...\n- Parent = mother, father\n- Child = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","41824a93":"## Variable Transformation","f940771e":"### AgeGroup","fb25c160":"## Feature Engineering","ef4cdacd":"### Basic summary statistics about the numerical data","6df5744d":"### Family Size","d3c300a6":"## Analysis and Visualization of Numeric and Categorical Variables","d1ffb916":"## Outlier Treatment","73847388":"## Missing Value Treatment","0e45742e":"## Gradient Boosting Classifier","1c0f2e4e":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","532759c9":"### Classes of some categorical variables","fb01568b":"### Visualization","7cfd319b":"### Cabin","048d744d":"## Deleting Unnecessary Variables","a170250c":"## Loading Data","b2650085":"### Fare","a4de6178":"# Business Understanding \/ Problem Definition","4228d576":"### Pclass","7e6b22fa":"#### SibSp vs survived:","111eb721":"# Data Preparation","ba3705b9":"### Name - Title","c5653eda":"# Modeling, Evaluation and Model Tuning","cb1a9c05":"### Embarked","a812ba95":"# Data Understanding (Exploratory Data Analysis)","0f7a7e1e":"#### Parch vs survived:","075426e8":"### Embarked","84c49c54":"#### Sex vs survived:","787a3ebb":"## Spliting the train data","ab8d5f17":"### Fare","49b968a5":"### Age","39c855ff":"#### Pclass vs survived:","1c21b6e4":"**Variables and Their Types:**\n\nSurvival: Survival -> 0 = No, 1 = Yes\n\nPclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n\nSex: Sex\n\nAge: Age in years\n\nSibSp: # of siblings \/ spouses aboard the Titanic\n\nParch: # of parents \/ children aboard the Titanic\n\nTicket: Ticket number\n\nFare: Passenger fare\n\nCabin: Cabin number\n\nEmbarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton","e03632dc":"## Random Forest","0a3e8c99":"**Titanic Survival Prediction:**\n\nUse machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","898c37d9":"### Embarked & Title","b1ed4d57":"# Deployment","2f514b99":"## Importing Librarires","5d261fbf":"### Sex","9c0f37fa":"## Logistic Regression","69d85b8a":"### Ticket"}}