{"cell_type":{"46414b1f":"code","dfcdb885":"code","d84274fb":"code","fae290bc":"code","96fd5196":"code","83dd8bb8":"code","b29b8f27":"code","2aa844ec":"code","4ade57d0":"code","207f9da7":"code","1d1d34ac":"code","93b60df1":"code","c79934ee":"code","fad9e975":"code","ca826610":"code","3415c52e":"code","660a1e93":"code","5e96504f":"code","68d3754f":"code","1f53907e":"code","50b451a2":"code","4b5c578f":"code","cb8d6656":"code","161c1921":"code","8cae483e":"code","dd0525aa":"code","694dddab":"code","7ff6a24e":"code","060898ee":"code","8e530ead":"code","43c96f33":"code","c5170a7d":"code","2f595787":"code","2b6e2291":"code","e86fcc8d":"code","c1bbdf49":"code","20453e16":"code","cfaaec41":"code","8ba8e046":"code","f9c3061b":"code","f8472441":"code","5a2f21b7":"code","0289bbba":"code","9c21dfdb":"markdown","db2bb8c5":"markdown","ef4802d1":"markdown","cb971789":"markdown","983d19ac":"markdown","ec390250":"markdown"},"source":{"46414b1f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","dfcdb885":"cancer = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ncancer.head()","d84274fb":"cancer.shape","fae290bc":"cancer.info()","96fd5196":"cancer['Unnamed: 32'].isnull().sum() #delete this column as all null values","83dd8bb8":"#drop id and Unnamed: 32 columns\ncancer.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)\ncancer.head()","b29b8f27":"cancer.dtypes #will need to encode diagnosis column values","2aa844ec":"cancer['diagnosis'].value_counts()","4ade57d0":"sns.countplot(cancer['diagnosis'], label = 'count of diagnoses')","207f9da7":"#encode diagnosis column values\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_Y = LabelEncoder()\ncancer.iloc[:,0] = labelencoder_Y.fit_transform(cancer.iloc[:,0].values)\ncancer.head()","1d1d34ac":"#lets look at correlation\nsns.pairplot(cancer, hue='diagnosis')","93b60df1":"cancer.corr()","c79934ee":"plt.figure(figsize=(20,20)) #make heatmap biger\nsns.heatmap(cancer.corr(), annot=True, fmt='.0%')","fad9e975":"#split data into X (features) and Y (labels)\nX = cancer.drop(['diagnosis'], axis=1)\nY = cancer['diagnosis']","ca826610":"#train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)","3415c52e":"X_train.shape","660a1e93":"X_test.shape","5e96504f":"Y_train.shape","68d3754f":"Y_test.shape","1f53907e":"#Feature scaling\n#from sklearn.preprocessing import StandardScaler\n#sc = StandardScaler()\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.fit_transform(X_test)","50b451a2":"from sklearn.model_selection import GridSearchCV\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=DeprecationWarning)","4b5c578f":"def print_results(results):\n    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n\n    means = results.cv_results_['mean_test_score']\n    stds = results.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n        print('{} (+\/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))","cb8d6656":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state = 0) \nparameters = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n}\n\ncv = GridSearchCV(lr, parameters, cv=5)\ncv.fit(X_train, Y_train)\n\nprint_results(cv)","161c1921":"cv.best_estimator_","8cae483e":"joblib.dump(cv.best_estimator_, '..\/..\/..\/LR_model.pkl')","dd0525aa":"from sklearn.svm import SVC\nsvc = SVC()\nparameters = {\n    'kernel': ['linear', 'rbf'],\n    'C': [0.1, 1, 10]\n}\n\ncv = GridSearchCV(svc, parameters, cv=5)\ncv.fit(X_train, Y_train)\n\nprint_results(cv)","694dddab":"cv.best_estimator_","7ff6a24e":"joblib.dump(cv.best_estimator_, '..\/..\/..\/SVM_model.pkl')","060898ee":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state = 0)\nparameters = {\n    'n_estimators': [5, 50, 250],\n    'max_depth': [2, 4, 8, 16, 32, None]\n}\n\ncv = GridSearchCV(rf, parameters, cv=5)\ncv.fit(X_train, Y_train)\n\nprint_results(cv)","8e530ead":"joblib.dump(cv.best_estimator_, '..\/..\/..\/RF_model.pkl')","43c96f33":"from sklearn.neural_network import MLPRegressor, MLPClassifier\n\nmlp = MLPClassifier()\nparameters = {\n    'hidden_layer_sizes': [(10,), (50,), (100,)],\n    'activation': ['relu', 'tanh', 'logistic'],\n    'learning_rate': ['constant', 'invscaling', 'adaptive']\n}\n\ncv = GridSearchCV(mlp, parameters, cv=5)\ncv.fit(X_train, Y_train)\n\nprint_results(cv)","c5170a7d":"cv.best_estimator_","2f595787":"joblib.dump(cv.best_estimator_, '..\/..\/..\/MLP_model.pkl')","2b6e2291":"from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n\ngb = GradientBoostingClassifier()\nparameters = {\n    'n_estimators': [5, 50, 250, 500],\n    'max_depth': [1, 3, 5, 7, 9],\n    'learning_rate': [0.01, 0.1, 1, 10, 100]\n}\n\ncv = GridSearchCV(gb, parameters, cv=5)\ncv.fit(X_train, Y_train)\n\nprint_results(cv)","e86fcc8d":"cv.best_estimator_","c1bbdf49":"joblib.dump(cv.best_estimator_, '..\/..\/..\/GB_model.pkl')","20453e16":"#from sklearn.naive_bayes import GaussianNB\n#gnb = GaussianNB()\n#gnb.fit(X_train, Y_train)\n\n#from sklearn.tree import DecisionTreeClassifier\n#dtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n#dtc.fit(X_train, Y_train)\n\n#from sklearn.neighbors import KNeighborsClassifier\n#knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n#knn.fit(X_train, Y_train)","cfaaec41":"models = {}\n\nfor mdl in ['LR', 'SVM', 'MLP', 'RF', 'GB']:\n    models[mdl] = joblib.load('..\/..\/..\/{}_model.pkl'.format(mdl))","8ba8e046":"from sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom time import time\n\ndef evaluate_model(name, model, features, labels):\n    start = time()\n    end = time()\n    pred = model.predict(features)\n    accuracy = round(accuracy_score(labels, pred), 3)\n    precision = round(precision_score(labels, pred), 3)\n    recall = round(recall_score(labels, pred), 3)\n    print('{} -- Accuracy: {} \/ Precision: {} \/ Recall: {} \/ Latency: {}ms'.format(name,\n                                                                                   accuracy,\n                                                                                   precision,\n                                                                                   recall,\n                                                                                   round((end - start)*1000, 1)))","f9c3061b":"for name, mdl in models.items():\n    evaluate_model(name, mdl, X_train, Y_train)","f8472441":"evaluate_model('svc', models['SVM'], X_test, Y_test)","5a2f21b7":"#check whether RF and GB are overfitting\nevaluate_model('rf', models['RF'], X_test, Y_test)","0289bbba":"evaluate_model('gb', models['GB'], X_test, Y_test)","9c21dfdb":"Examine and Clean the Dataset","db2bb8c5":"Evaluate Best Model on Test Set","ef4802d1":"Prepare Data","cb971789":"HyperParameter Tuning and Model Selection","983d19ac":"Read in Models","ec390250":"EDA"}}