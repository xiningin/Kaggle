{"cell_type":{"d02615d8":"code","3f8eb86b":"code","7ea75c58":"code","cba0db81":"code","5d21e4b7":"code","f9e3eb4d":"code","58a268f3":"code","f7b4f33a":"code","85289053":"code","0b5e7fa1":"code","98368977":"code","1d150170":"code","85c9690a":"code","df792394":"code","c9cfc29a":"code","280538c2":"code","d012bb79":"code","8a5e1d84":"code","b4a74242":"code","6127737c":"code","78d23f9d":"code","f2493d3a":"code","5980206c":"code","7846906a":"code","65979cbd":"code","d8284d15":"code","9f242b61":"code","17f88d72":"code","1f7d7e13":"code","10b6012e":"code","af494f82":"code","795fd32d":"code","c45b4287":"code","50a31fa8":"code","179e2892":"code","a00b3539":"code","6f403373":"code","9d4f5266":"code","9b26060f":"code","d65f9ef2":"markdown","f7f7a60e":"markdown","be836a4f":"markdown","bcd099ef":"markdown","497a4249":"markdown","48e19ce0":"markdown","78e1d173":"markdown","a959db59":"markdown","ab0d15f1":"markdown","d7110673":"markdown","2630078f":"markdown","a252923b":"markdown","b2967fd1":"markdown","110f5e4d":"markdown","b0861bca":"markdown","b4552798":"markdown","7d1b76e8":"markdown","766f0494":"markdown","25181558":"markdown","a1b3ed5a":"markdown","4b6602f2":"markdown","0f7ca8a6":"markdown","afe39fbe":"markdown","e2bfbb2f":"markdown","40559d32":"markdown","2c51e00a":"markdown","1e60ed91":"markdown","472d1e48":"markdown","ff1fbd39":"markdown","d1e8e193":"markdown","7ceb1923":"markdown","b47677d1":"markdown","8c30c5f4":"markdown","45ff017d":"markdown","3af333e6":"markdown","6928d7a6":"markdown","2be0bca0":"markdown","0946f842":"markdown","d2bf4f13":"markdown","221d8eea":"markdown"},"source":{"d02615d8":"import tensorflow as tf\ntf.__version__","3f8eb86b":"from tensorflow import keras\nkeras.__version__","7ea75c58":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nsns.set(style='white', context='notebook', palette='deep')\n\n# Los archivos de datos est\u00e1n disponibles en el directorio \"..\/input\/\" \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cba0db81":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntrain.head()","5d21e4b7":"print(\"Tama\u00f1o del dataset de entrenamiento\", train.shape)","f9e3eb4d":"test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntest.head()","58a268f3":"print(\"Tama\u00f1o del dataset de prueba\", test.shape)","f7b4f33a":"Y_train = train[\"label\"]\n\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\nY_train.head()","85289053":"sns.set(palette=\"tab10\")\nplt.rcParams['figure.dpi'] = 120","0b5e7fa1":"plt.figure(figsize=(20, 10))\nfor i in range(27):\n    plt.subplot(3, 9, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train.iloc[i].to_numpy().reshape((28,28,1)))\n    plt.title(Y_train[i],size = 20)\nplt.show()","98368977":"Y_train.value_counts()","1d150170":"grafico = dict(train['label'].value_counts())\ngrafico = dict(sorted(grafico.items()))","85c9690a":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize =(14,6))\nbackground_color = '#faf9f4'\nax1.set_facecolor(background_color)\nax2.set_facecolor(background_color) \nax1.pie(grafico.values(),wedgeprops=dict(width=0.3, edgecolor='w') ,labels=grafico.items(), radius=1)\nax2 = sns.countplot(train['label'])\nplt.show()","df792394":"X_train.isnull()","c9cfc29a":"print(\"Columnas nulas en conjunto de entrenamiento\", X_train.isnull().sum())","280538c2":"X_train.isnull().any().describe()","d012bb79":"X_train = X_train \/ 255.0\ntest = test \/ 255.0","8a5e1d84":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n\nprint(\"Tama\u00f1o del dataset de entrenamiento\", X_train.shape)\nprint(\"Tama\u00f1o del dataset de prueba\", test.shape)","b4a74242":"from keras.utils.np_utils import to_categorical\nY_train = to_categorical(Y_train, num_classes = 10)","6127737c":"random_seed = 2","78d23f9d":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.10, random_state=random_seed)","f2493d3a":"print(len(X_train))","5980206c":"print(len(X_val))","7846906a":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","65979cbd":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","d8284d15":" model.summary()","9f242b61":"optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)","17f88d72":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","1f7d7e13":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","10b6012e":"datagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=10, \n        zoom_range = 0.1,\n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip=False, \n        vertical_flip=False)  ","af494f82":"datagen.fit(X_train)","795fd32d":"history = model.fit(datagen.flow(X_train,Y_train, batch_size=86),\n                              epochs = 1, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0], \n                              callbacks=[learning_rate_reduction])","c45b4287":"print('Loss     : {} \\nAccuracy : {}'.format(history.history['loss'][-1],history.history['accuracy'][-1]))","50a31fa8":"Y_pred = model.predict(X_val)","179e2892":"Y_pred_classes = np.argmax(Y_pred ,axis = 1) \nY_true = np.argmax(Y_val, axis=1)","a00b3539":"confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\nf,ax = plt.subplots(figsize=(16,8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Blues\", linecolor=\"Green\", fmt='.1f', ax=ax)\nplt.xlabel(\"Valor predicho\")\nplt.ylabel(\"Valor real\")\nplt.title(\"Matriz de confusi\u00f3n\")\nplt.show()","6f403373":"Y_pred = model.predict(test)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nrows = 4\ncols = 6\nf = plt.figure(figsize=(2*cols,2*rows))\nf.suptitle(\"Predicciones\", fontsize=20)\nfor i in range(rows*cols): \n    f.add_subplot(rows,cols,i+1)\n    img = test[i]\n    img = img.reshape((28,28))\n    plt.imshow(img,\n               cmap='gray')\n    plt.axis(\"off\")\n    plt.title(\"Predicci\u00f3n: {}\".format(Y_pred_classes[i]),\n              y=-0.35,color=\"green\")\nf.tight_layout()\n    \nf.show()","9d4f5266":"submission = pd.DataFrame({'ImageId': range(1,28001), 'Label': Y_pred_classes})\nsubmission.to_csv('submission.csv', index=False)","9b26060f":"submission","d65f9ef2":"**Este Cuaderno tiene tres partes principales:**\n\n1. La preparaci\u00f3n de datos\n1. El modelado de la red convolucional\n1. La predicci\u00f3n y submission de resultados","f7f7a60e":"- Definimos la funci\u00f3n de p\u00e9rdida para medir el rendimiento de nuestro modelo.\n\n- La funci\u00f3n m\u00e1s importante es el optimizador. Esta funci\u00f3n mejorar\u00e1 iterativamente los  los valores del kernel y los pesos  para minimizar la p\u00e9rdida. RMSprop  o Adam son optimizadores muy efectivos.\n\n- La funci\u00f3n m\u00e9trica \"accuracy\" ","be836a4f":"Comprobamos cual es el resumen de las capas de nuestro modelo","bcd099ef":"Hay tres archivos que existen en este fichero: (1) train.csv, (2) test.csv, (3) sample_submission.csv ","497a4249":"Miramos el n\u00famero de ejemplos por cada etiqueta de salida. Vemos que todas tienen un valor similar de 4000 ejemplos, pero realizamos un gr\u00e1fico para verlo de manera m\u00e1s visual.","48e19ce0":" Inicializamos la semilla para la divisi\u00f3n del conjunto de datos","78e1d173":"Realizamos un Normalizaci\u00f3n de los datos tanto en entrenamiento como test. Si realizamos la normalizaci\u00f3n, CNN funciona m\u00e1s r\u00e1pido.","a959db59":"Representamos algunas de las im\u00e1genes con el valor predecido para ver si es correcto.","ab0d15f1":"En el conjunto de entrenamiento tenemos 37800 datos","d7110673":"# Digit Recognizer Competition ","2630078f":"A\u00f1adimos m\u00e1s librer\u00edas","a252923b":"La extracci\u00f3n de caracter\u00edsticas consta de tres operaciones b\u00e1sicas:\n1. Filtrar una imagen para una caracter\u00edstica en particular (convoluci\u00f3n)\n2. Detecta esa caracter\u00edstica dentro de la imagen filtrada (ReLU)\n3. Condensar la imagen para mejorar las caracter\u00edsticas (maximum pooling)\n\n-------------------------------------------------------------------------------------------------------------\nUna capa convolucional realiza el paso de filtrado. Los pesos que aprende una capa convolucional los llamamos kernels. Funciona escaneando una imagen y produciendo una suma ponderada de valores de p\u00edxeles.\n\nLos kernels definen c\u00f3mo se conecta una capa convolucional a la capa que sigue. Al establecer las dimensiones de los kernels con kernel_size, le est\u00e1 diciendo al convnet c\u00f3mo formar estas conexiones. La mayor\u00eda de las veces, un kernel tendr\u00e1 dimensiones impares, como kernel_size = (3, 3) o (5, 5)\n\nLos kernels en una capa convolucional determinan qu\u00e9 tipo de caracter\u00edsticas crea. Durante el entrenamiento, un convnet intenta aprender qu\u00e9 caracter\u00edsticas necesita para resolver el problema de clasificaci\u00f3n.\n\n-------------------------------------------------------------------------------------------------------------\n\nLas activaciones en la red las llamamos feature maps. Resultan cuando aplicamos un filtro a una imagen; ya que contienen las caracter\u00edsticas visuales del kernel. En este caso utilizamos la funci\u00f3n ReLU.\n\nLa activaci\u00f3n de ReLU dice que los valores negativos no son importantes y, por lo tanto, los establece en 0.\n\n------------------------------------------------------------------------------------------------------------\n\nLa \u00faltima es la de maximum pooling, que en Keras se realiza mediante una capa.\n\nUna capa MaxPool2D sa una funci\u00f3n m\u00e1xima  en lugar de un kernel, con el par\u00e1metro pool_size. Sin embargo, una capa MaxPool2D no tiene pesos entrenables.\n\nDespu\u00e9s de aplicar la funci\u00f3n ReLU, el mapa de caracter\u00edsticas termina con una gran cantidad de \"espacio muerto\", es decir, \u00e1reas grandes que contienen solo ceros. Hay que condensar el mapa de caracter\u00edsticas para retener solo la parte m\u00e1s \u00fatil.\nLa agrupaci\u00f3n m\u00e1xima toma las activaciones en el mapa de caracter\u00edsticas  y las reemplaza con la activaci\u00f3n m\u00e1xima.","b2967fd1":"Contamos el n\u00famero de valores nulos para cada columnas","110f5e4d":"Predecimos los resultados para el cojunto de datos de test. Una vez realizado el entrenamiento, le pasamos al modelo nuevos ejemplos que no ha visto para que realice una predicci\u00f3n.","b0861bca":"En esta celda cargamos el archivo test.csv.","b4552798":"La mejor forma de mejorar el rendimiento de un modelo de aprendizaje autom\u00e1tico es entrenarlo con m\u00e1s datos. \n\nUna forma sencilla de obtener m\u00e1s datos es utilizar los datos que ya tiene. Si podemos transformar las im\u00e1genes en nuestro conjunto de datos de manera que conserven la clase, podemos ense\u00f1ar a nuestro clasificador a ignorar ese tipo de transformaciones. \n\nY esa es toda la idea detr\u00e1s del aumento de datos: agregar algunos datos falsos adicionales que se parezcan razonablemente a los datos reales y el clasificador mejorar\u00e1.","7d1b76e8":"Mientras que en el conjunto de test tenemos 4200 datos","766f0494":"No hay valores nulos en el conjunto de datos de prueba y test. Podemos seguir adelante sin problema. ","25181558":"Guardamos la etiqueta de salida en la variable y_train. Adem\u00e1s quitamos la etiqueta del conjunto de datos","a1b3ed5a":"Realizamos adem\u00e1s un reshape de los datos de entrada.\n- Reformamos todos los datos en matrices 3D de 28x28x1.\n- Keras necesita al final una dimensi\u00f3n extra que corresponde a los canales. Nuestras im\u00e1genes est\u00e1n en escala de grises, por lo que solo usan un canal.","4b6602f2":"Definimos nuestro modelo CNN. Se utiliza para clasificaci\u00f3n de im\u00e1genes.","0f7ca8a6":"Dividimos el conjunto de datos de entrenamiento y el conjunto de test.\n- tama\u00f1o de entrenamiento es 90%\n- tama\u00f1o de test es 10%","afe39fbe":"- Rote aleatoriamente algunas im\u00e1genes \n- Zoom aleatorio algunas im\u00e1genes de entrenamiento\n- Cambiar las im\u00e1genes en un 10% del ancho\n- Cambiar las im\u00e1genes verticalmente en un 10% de la altura\n- etc ...\n\nDESPUES ENTRENAMOS EL CONJUNTO DE DATOS DE ENTRENAMIENTO","e2bfbb2f":"En esta parte cargamos y visualizamos los datos que ser\u00e1n los pixeles de entrada para cada imagen. En esta celda cargamos el archivo train.csv.","40559d32":"**RESUMEN**\n\nLa base de datos del MNIST (base de datos modificada del Instituto Nacional de Normas y Tecnolog\u00eda) es una gran base de datos de d\u00edgitos manuscritos que se utiliza com\u00fanmente para la capacitaci\u00f3n de diversos sistemas de procesamiento de im\u00e1genes. La base de datos tambi\u00e9n se utiliza ampliamente para la capacitaci\u00f3n y el ensayo en el campo del aprendizaje autom\u00e1tico. Se cre\u00f3 \"remezclando\" las muestras de los conjuntos de datos originales del NIST.  Adem\u00e1s, las im\u00e1genes en blanco y negro del NIST fueron normalizadas para que encajaran en un cuadro delimitador de 28x28 p\u00edxeles, lo que introdujo niveles de escala de grises.\n\nLa base de datos del MNIST contiene 42.000 im\u00e1genes de entrenamiento y 28.000 im\u00e1genes de prueba. En su papel original, utilizan una m\u00e1quina de soporte vectorial para obtener una tasa de error del 0,8%. En 2017 se ha publicado un conjunto de datos ampliado similar al MNIST llamado EMNIST, que contiene 240.000 im\u00e1genes de entrenamiento y 40.000 im\u00e1genes de prueba de d\u00edgitos y caracteres escritos a mano.","2c51e00a":"Para hacer que el optimizador converja m\u00e1s r\u00e1pido se utiliza una tasa de aprendizaje decreciente durante el entrenamiento para alcanzar de manera eficiente el m\u00ednimo global de la funci\u00f3n de p\u00e9rdida.\n\nEn este caso se disminuye el LR cada epoch dependiendo de si es necesario. Para ello se utiliza los callbacks.","1e60ed91":"Entrenamos nuestro modelo pas\u00e1ndole el conjunto de caracter\u00edsticas de entramiento y la salida final.\n\nUn tama\u00f1o de batch_size = 80 es habitual. Y con 30 epochs.","472d1e48":"**Realizamos una normalizaci\u00f3n de escala de grises. De esta manera, a menudo se puede aumentar la claridad de la imagen.**","ff1fbd39":"Miramos la longitud tras realizar la divisi\u00f3n","d1e8e193":"Tenemos 784 columnas de caracter\u00edsticas, ya que no contamos con la etiqueta final y 28000 instancias de datos. ","7ceb1923":"Las etiquetas son n\u00fameros de 10 d\u00edgitos del 0 al 9. Necesitamos codificar las etiquetas en un one hot vectors ([0,0,1,0,0,0,0,0,0,0,0])\n\nUn one-hot vector -> es 0 en la mayor\u00eda de las dimensiones y 1 en una sola dimensi\u00f3n.","b47677d1":"Tenemos 785 columnas de caracter\u00edsticas (cada pixel) y 42000 instancias de datos","8c30c5f4":"Se han almacenado im\u00e1genes de entrenamiento y prueba (28px x 28px) en un Dataframe de Pandas como vectores de 784 valores.","45ff017d":"Realizamos dos gr\u00e1ficos diferentes para visualizar el n\u00famero de etiquetas de salida que podemos obtener en el problema. Que ser\u00e1n datos etiquetados del 1 al 10.","3af333e6":"Importamos las librer\u00edas de tensorflow y keras para nuestro modelo de redes neuronales profundas. Y comprobamos la versi\u00f3n.","6928d7a6":"Tenemos n\u00fameros similares para los 10 d\u00edgitos.","2be0bca0":"Guardamos en archivo de submission los resultados","0946f842":"Realizamos una **visualizaci\u00f3n** de unas de las primeras im\u00e1genes con la etiqueta correspondiente que tienen.","d2bf4f13":"La primera es la capa convolucional (Conv2D). Establec\u00ed 32 filtros para las dos primeras y 64 filtros para las dos \u00faltimas. La matriz de filtro de kernel se aplica a toda la imagen. \n\nLa segunda capa importante es la capa MaxPool2D. Esta capa simplemente act\u00faa como un filtro de reducci\u00f3n de resoluci\u00f3n. Elige el valor m\u00e1ximo. Estos se utilizan para reducir el costo computacional.\n\nSe usan capas de Dropout, donde una proporci\u00f3n se ignora aleatoriamente (estableciendo sus pesos en cero) para cada muestra de entrenamiento. Esta t\u00e9cnica  reduce el sobreajuste.\n\nLa capa Flatten se utiliza para convertir los mapas de caracter\u00edsticas finales en un solo vector 1D.\n\nEn la \u00faltima capa (activaci\u00f3n = \"softmax\") -> probabilidad de cada clase en la salida.","221d8eea":"Vamos a comenzar a controlar el total de los valores nulos de las celdas."}}