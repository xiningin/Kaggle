{"cell_type":{"b8986e4d":"code","c03766cc":"code","fd97f2db":"code","e8e721e3":"code","284d753e":"code","1571dfa2":"code","78f14f47":"code","94534415":"code","c8c83cfc":"code","adb98ab2":"code","c4bc1569":"code","877bb008":"code","219da9a0":"markdown","462604d3":"markdown","c7e40333":"markdown","28486c31":"markdown","29eae2a4":"markdown"},"source":{"b8986e4d":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') \n\nsns.set()\n","c03766cc":"dataset = pd.read_csv(\"..\/input\/A_Z Handwritten Data\/A_Z Handwritten Data.csv\").astype('float32')\ndataset.rename(columns={'0':'label'}, inplace=True)\n\n# Splite data the X - Our data , and y - the prdict label\nX = dataset.drop('label',axis = 1)\ny = dataset['label']","fd97f2db":"print(\"shape:\",X.shape)\nprint(\"culoms count:\",len(X.iloc[1]))\nprint(\"784 = 28X28\")\n\nX.head()","e8e721e3":"from sklearn.utils import shuffle\n\nX_shuffle = shuffle(X)\n\nplt.figure(figsize = (12,10))\nrow, colums = 4, 4\nfor i in range(16):  \n    plt.subplot(colums, row, i+1)\n    plt.imshow(X_shuffle.iloc[i].values.reshape(28,28),interpolation='nearest', cmap='Greys')\nplt.show()","284d753e":"print(\"Amount of each labels\")\n\n# Change label to alphabets\nalphabets_mapper = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'} \ndataset_alphabets = dataset.copy()\ndataset['label'] = dataset['label'].map(alphabets_mapper)\n\nlabel_size = dataset.groupby('label').size()\nlabel_size.plot.barh(figsize=(10,10))\nplt.show()\n\nprint(\"We have very low observations for I and F \")\nprint(\"I count:\", label_size['I'])\nprint(\"F count:\", label_size['F'])","1571dfa2":"# splite the data\nX_train, X_test, y_train, y_test = train_test_split(X,y)\n\n# scale data\nstandard_scaler = MinMaxScaler()\nstandard_scaler.fit(X_train)\n\nX_train = standard_scaler.transform(X_train)\nX_test = standard_scaler.transform(X_test)","78f14f47":"print(\"Data after scaler\")\nX_shuffle = shuffle(X_train)\n\nplt.figure(figsize = (12,10))\nrow, colums = 4, 4\nfor i in range(16):  \n    plt.subplot(colums, row, i+1)\n    plt.imshow(X_shuffle[i].reshape(28,28),interpolation='nearest', cmap='Greys')\nplt.show()","94534415":"X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)","c8c83cfc":"cls = Sequential()\ncls.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\ncls.add(MaxPooling2D(pool_size=(2, 2)))\ncls.add(Dropout(0.3))\ncls.add(Flatten())\ncls.add(Dense(128, activation='relu'))\ncls.add(Dense(len(y.unique()), activation='softmax'))\n\ncls.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = cls.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=18, batch_size=200, verbose=2)\n\nscores = cls.evaluate(X_test,y_test, verbose=0)\nprint(\"CNN Score:\",scores[1])","adb98ab2":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","c4bc1569":"cm=confusion_matrix(y_test.argmax(axis=1),cls.predict(X_test).argmax(axis=1))\ndf_cm = pd.DataFrame(cm, range(26),\n                  range(26))\nplt.figure(figsize = (20,15))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# font size","877bb008":"!pip install --upgrade pip\n!pip install -U coremltools\nimport coremltools\n\ncls.save('my_model.h5')\n\noutput_labels = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\ncore_ml=coremltools.converters.keras.convert('my_model.h5', input_names=['image'], output_names=['output'], \n    class_labels=output_labels,image_scale=1\/255.0, is_bgr = False, image_input_names = \"image\")\ncore_ml.save('coreml_model.mlmodel')","219da9a0":"# Explore","462604d3":"look at the data images","c7e40333":"# Data preparation","28486c31":"# Build the model\n","29eae2a4":"# Import librarys and data\n"}}