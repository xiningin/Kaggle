{"cell_type":{"e0aaf8e0":"code","7485f864":"code","841377f6":"code","4a208ed9":"code","0be75a96":"code","5ee9bfdc":"code","f5839afb":"code","ac68cd2d":"code","98008834":"code","648d3897":"code","ac48e9e5":"code","d83dd450":"code","301eeddc":"code","cd6b34b5":"code","6217d169":"code","7f87a0ac":"code","10a7bbb1":"code","abf48aaa":"code","03bce702":"code","2e0e12c4":"code","fcd70e59":"code","74a96cb7":"code","43f3ff98":"code","968cb50f":"code","fc9b6da3":"code","e2e450cc":"code","cef84947":"code","62379b9d":"code","b1ea4ea8":"code","b03d48cd":"code","41118257":"code","0fee3f33":"code","e6028442":"code","7d73acee":"code","e60b9735":"code","baccaa06":"code","bd1d9de4":"code","3a6608ec":"code","ac423b78":"code","4ef7c3c3":"code","9d2a2178":"code","cf883f4b":"code","d017863f":"code","aad4d632":"code","89e25971":"code","e128fd3e":"code","1497a4b1":"code","b60f7ff4":"code","c522fcce":"code","79f0eec0":"code","f350ed38":"code","57132e4d":"code","22343fa2":"code","c32f6be2":"code","ce258846":"code","bf286a17":"code","8837350d":"code","4321aa83":"code","c4109835":"markdown","8b661a60":"markdown","95fe343d":"markdown","f442aad5":"markdown","56b9f3ae":"markdown","9d0becae":"markdown","a7ddc5ea":"markdown","00199e76":"markdown","0a6d9e39":"markdown","2670b85c":"markdown","03ff4c2f":"markdown","35044d14":"markdown","129a1b38":"markdown","3d503ea6":"markdown","3b4896f1":"markdown","4f5629d9":"markdown","28b68e5e":"markdown","9d75ce41":"markdown","9e5ff628":"markdown","b00c50c0":"markdown","28218f9b":"markdown","469a9afe":"markdown","0c38eed1":"markdown"},"source":{"e0aaf8e0":"import pandas as pd\npd.pandas.set_option('display.max_columns', 20)\n# Ensures that the output is on a single line.\npd.set_option('display.expand_frame_repr', False)\n#We will use two separate data for this project. \n# Let's download our movie.csv data, which is the 1st data, and examine it.\nmovie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nmovie.head()\n","7485f864":"#Now let's read our second data, ratings.csv.\nrating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\nrating.head()","841377f6":"# As you can see, movieIds are common in both data. In order to perform our recommendation operations, \n# we must combine these two data with the merge method.\ndf = movie.merge(rating, how=\"left\", on=\"movieId\")\ndf.head()","4a208ed9":"# In the data set we merged, the ratings given to the movies by the users can be seen. for this reason, \n# the movie names and ids have multiplied.\ndf.shape","0be75a96":"df['movieId'].nunique() # the number of the movie","5ee9bfdc":"df['userId'].nunique() #the number of the users","f5839afb":"# how many ratings for each movie\ncomment_counts = df['title'].value_counts() \ncomment_counts","ac68cd2d":"type(comment_counts)","98008834":"# First, let's convert comment_counts to dataframe.\ncomment_counts = pd.DataFrame(comment_counts)\ncomment_counts.head()","648d3897":"# We assign the videos with a rating less than 1000 to a variable.\nrare_movies = comment_counts[comment_counts[\"title\"] < 1000].index\nrare_movies","ac48e9e5":"common_movies = df[~df[\"title\"].isin(rare_movies)]\ncommon_movies.head()\n#More than 1000 commented movies came.","d83dd450":"common_movies.shape\n# so our data decreased from 20 million to 17 million.","301eeddc":"# To create our recommendation rules, rows must have userIds and movies in columns. \n# It is necessary to have ratings in terms of value. so we apply the pivot table method.\nuser_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\nuser_movie_df.head()","cd6b34b5":"user_movie_df.shape\n# According to these results, there are 138 thousand faulty user IDs and 3159 films.","6217d169":"# We collect the data processing operations we have done so far in a function.\n# def create_user_movie_df():\n#     import pandas as pd\n#     movie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\n#     rating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\n#     df = movie.merge(rating, how=\"left\", on=\"movieId\")\n#     comment_counts = pd.DataFrame(df[\"title\"].value_counts())\n#     rare_movies = comment_counts[comment_counts[\"title\"] <= 1000].index\n#     common_movies = df[~df[\"title\"].isin(rare_movies)]\n#     user_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n#     return user_movie_df\n# We can use this function directly in our operations.","7f87a0ac":"# user_movie_df = create_user_movie_df()\nuser_movie_df.iloc[0:5,0:5]","10a7bbb1":"random_user = 108170\n#Let's reduce our data according to the user we have determined.\nrandom_user_df = user_movie_df[user_movie_df.index == random_user]\nrandom_user_df\n","abf48aaa":"# We call random_user_df's columns without 'na' and assign it to a list.\nmovies_watched = random_user_df.columns[random_user_df.notna().any()].tolist()\nmovies_watched","03bce702":"len(movies_watched)","2e0e12c4":"movies_watched_df= user_movie_df[movies_watched]\n# Here, we assigned the reduced dataframe based on the movies watched \n# by the user we specified here, to our movies_wached_df variable.\nmovies_watched_df.head()","fcd70e59":"movies_watched_df.shape","74a96cb7":"# We reduced user_movie_df according to the movies watched by random_user.\nuser_movie_count = movies_watched_df.T.notnull().sum() \nuser_movie_count.head()\n# The information came about how many movies they watched together with the random user.","43f3ff98":"user_movie_count=user_movie_count.reset_index()\nuser_movie_count.head()","968cb50f":"user_movie_count.columns=['userId','movie_count']\nuser_movie_count.head()\n# We have obtained the number of movies that these users watch together with the user.","fc9b6da3":"perc = len(movies_watched) * 60 \/ 100\nusers_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > perc][\"userId\"]\nusers_same_movies\n# Now, we said that the number of movies watched jointly by the user and other users should be above 60%.","e2e450cc":"users_same_movies.count()","cef84947":"users_same_movies.head()\ntype(users_same_movies)","62379b9d":"final_df = movies_watched_df[movies_watched_df.index.isin(users_same_movies)]\nfinal_df.head()\n# We have brought the information of users watching 60% of the common movies.","b1ea4ea8":"\nfinal_df = movies_watched_df[movies_watched_df.index.isin(users_same_movies.index)]\nfinal_df.head()\nfinal_df.shape","b03d48cd":"final_df.shape","41118257":"#Now let's create our correlation matrix. User ids must be in columns. So we got the transpose.\nfinal_df.T.corr().head()","0fee3f33":"# If we apply unstack to this code to observe better, our matrix will be as follows.\nfinal_df.T.corr().unstack().head()","e6028442":"# Now, let's assign this correlation to the corr_df variable in order from largest to smallest.\ncorr_df=final_df.T.corr().unstack().sort_values()\ncorr_df.head()","7d73acee":"type(corr_df)","e60b9735":"# Let's convert the corr_df matrix to the pandas dataframe and assign the column name to corr.\ncorr_df = pd.DataFrame(corr_df,columns=['corr'])\ncorr_df.head()","baccaa06":"# We are changing the names of the user ids to make it easier to understand.\ncorr_df.index.names=['user_id_1','user_id_2']\ncorr_df.head()","bd1d9de4":"# Let's reset_index user_id1 and user_id2 to make columns.\ncorr_df=corr_df.reset_index()\ncorr_df.head()","3a6608ec":"corr_df[(corr_df[\"user_id_1\"] == random_user)].sort_values('corr',ascending=False).head()","ac423b78":"top_users = corr_df[(corr_df[\"user_id_1\"] == random_user) & (corr_df[\"corr\"] >= 0.65)][\n                                                [\"user_id_2\", \"corr\"]].reset_index(drop=True)\ntop_users\n# Those with a correlation higher than 65% came in.","4ef7c3c3":"top_users = top_users.sort_values(by='corr', ascending=False)\n# Let's order from largest to smallest.\ntop_users\n#The first value is random_user itself. The others have the most similar features to random_user.","9d2a2178":"top_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)\n# Let's rename user_id_2 using the rename method.\ntop_users","cf883f4b":"rating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\ntop_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')\ntop_users_ratings.head(5)\n# Here we are reading the rating data again. \n# And we merge with top_users in order to reach the rating information of the users through the intersection.","d017863f":"# Let's remove random_user from top_users_ratings.\ntop_users_ratings = top_users_ratings[top_users_ratings[\"userId\"] != random_user]\ntop_users_ratings.head(5)","aad4d632":"# So let's multiply the correlations and ratings and find the Weighted Average Score.\ntop_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\ntop_users_ratings.head()","89e25971":"recommendation_df=top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\n# Let's get groupby by movieId to find movies to recommend. \nrecommendation_df","e128fd3e":"recommendation_df = recommendation_df.reset_index()\nrecommendation_df.head(5)","1497a4b1":"recommendation_df.shape","b60f7ff4":"recommendation_df['weighted_rating'].max()","c522fcce":"recommendation_df['weighted_rating'].min()","79f0eec0":"recommendation_df[recommendation_df[\"weighted_rating\"] > 3.5]\n# By looking at the maximum and minimum values of Weighted_rating, we can say that those above 3.5 should come. ","f350ed38":"movies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 3.5].sort_values(\"weighted_rating\", ascending=False)[0:5]\nmovies_to_be_recommend","57132e4d":"# Since the names are in the movie data, let's read the movie data again.\nmovie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nmovie.head()","22343fa2":"# Let's merge the movieId and title columns of the movie data with the recommended movieId.\nmovies_to_be_recommend.merge(movie[[\"movieId\", \"title\"]]).head()","c32f6be2":"user = 108170\n\nmovie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nrating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')","ce258846":"\nmovie_id = rating[(rating[\"userId\"] == user) & (rating[\"rating\"] == 5.0)]. \\\n               sort_values(by=\"timestamp\", ascending=False)[\"movieId\"][0:1].values[0]\nmovie_id","bf286a17":"# The name of the movie that random_user last watched and gave a rating of 5 points.\nmovie[movie['movieId']==movie_id]","8837350d":"def item_based_recommender(movie_name, user_movie_df):\n    movie = user_movie_df[movie_name]\n    return user_movie_df.corrwith(movie).sort_values(ascending=False).head(10)","4321aa83":"movies_from_item_based = item_based_recommender(movie[movie[\"movieId\"] == movie_id][\"title\"].values[0], user_movie_df)\n# 0. indeksteki filmin kendisi oldugu icin onu koymadik.\nmovies_from_item_based[1:6].index","c4109835":"# ***Business Problem***\nEstimate using the item-based and user-based recommender methods for the user : 108170 whose ID is given.","8b661a60":"***item based metoduyla Wild at Heart filmi icin gelen 5 film tavsiyesi ***\n![image.png](attachment:f742da46-62ed-44fb-824b-295603fe9986.png)","95fe343d":"# **DATA PRE-PROCESSING**","f442aad5":"# **VARIABLES**\n**Movie Dataset:**\n\nmovieId: Unique movie ID\n\ntitle: Movie Name\n\n**Rating Dataset:**\n\nuserId: Unique user ID\n\nmovieId: Unique movie ID\n\nrating: User ratings for movies\n\ntimestamp: Date for rating","56b9f3ae":"***Now let's get to the names of these movieIds.***","9d0becae":"* ***To examine the data set, we can look at the rating amounts of how many users and how many movies are in it.***","a7ddc5ea":"* ***Art\u0131k amac\u0131m\u0131z ayn\u0131 filmleri izleyen kullan\u0131c\u0131lar\u0131n kimlik ve bilgilerine ula\u015fmak.***","00199e76":"# Make 5 item-based suggestions based on the name of the highest rated movie the user has watched most recently.","0a6d9e39":"*In the top output, all the movies that the user watched and did not watch came. but we only want to reach the information of the movies he watched.*","2670b85c":"***Now our goal is to find the correlation of the user with other users.***","03ff4c2f":"***There are 5 movies that can be recommended with the user based method.***","35044d14":"# **Dataset Story**\nThe dataset was provided by MovieLens, a movie recommendation service. It contains the rating scores for these movies along with the movies.\nIt contains 2,000,0263 ratings across 27,278 movies.\nThis data was created by 138,493 users between 09 January 1995 and 31 March 2015. This data set was created on October 17, 2016.\nUsers are randomly selected. It is known that all selected users voted for at least 20 movies.","129a1b38":"* ***In order to make it easier when creating recommendation systems in our data, let's remove the movies with a rating less than 1000 from our data. because these movies are rarely watched movies anyway.***","3d503ea6":"* ***We brought those whose number of watching movies together with the given user is above 60%. but they may not have the same liking behavior. In this section, our aim is to bring the users with the most similar liking behaviors from these users.***","3b4896f1":"# **ITEM BASED RECOMMEND**\n\nThe item-to-item filtering algorithm analyzes product similarities from user ratings. Click\/view rather than scoring can also be considered a variable. The purpose of this system is to ensure that the products purchased\/viewed by the user are recommended to other similar users by considering the similarity. In this method, product similarities are found using Pearson Correlation or cosine similarity methods, assuming the products are neighbors.","4f5629d9":"#  * **Find users who are most similar to the suggested user.**","28b68e5e":"*Now let's find the movies watched by the user to recommend.*","9d75ce41":"#  Calculating the Weighted Average Recommendation Score","9e5ff628":"# **Hybrid Recommender System(User-Based and Item-Based Collaborative Filtering)**\n![image.png](attachment:4cb8d854-ec67-4e7a-8c56-07554978d373.png)","b00c50c0":"*The correlation between the 1st users and the second users seems very comfortable at the moment.*","28218f9b":"***We found the user information with the highest correlation. But we still can't decide which movies to recommend.***","469a9afe":"***We found the correlation. Let's do one more filtering here. Let's say those with a correlation of more than 65% come. And since user_id1 is a random user, user_id2 and corr values will be enough for me. If we remove it from the index, we can observe much more easily.***","0c38eed1":"# **USER BASED RECOMMENDER**\n\nUser-based filtering is a system that takes into account the similarity of user tastes. If two users have bought joint products, it is based on the probability that the other user will also receive a product purchased later. According to the scores of the users, the prediction is made as a result of Pearson Correlation or cosine similarity methods."}}