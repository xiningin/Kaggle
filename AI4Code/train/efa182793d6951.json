{"cell_type":{"af7c9fe0":"code","d6cc817f":"code","e5bd02ab":"code","f3eba15d":"code","e2b70fdc":"code","2c2c0042":"code","2663dae1":"code","fb625808":"code","bc7b7600":"code","d48b2327":"code","8edf47b2":"markdown","94a3937b":"markdown","f0274e6b":"markdown","68558416":"markdown","aecdd4a0":"markdown","1a639e8a":"markdown"},"source":{"af7c9fe0":"from os import listdir\nfrom os.path import isfile, join\nimport pandas as pd\nimport librosa\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom timeit import default_timer as timer\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import regularizers, optimizers\nfrom tensorflow.keras.layers import Dense, Conv1D, Flatten, Activation, MaxPooling1D, Dropout\nfrom tensorflow.keras.utils import plot_model,to_categorical","d6cc817f":"class Diagnosis():\n  def __init__ (self, id, diagnosis, image_path):\n    self.id = id\n    self.diagnosis = diagnosis \n    self.image_path = image_path   ","e5bd02ab":"def get_wav_files():\n  audio_path = '..\/input\/respiratory-sound-database\/Respiratory_Sound_Database\/Respiratory_Sound_Database\/audio_and_txt_files\/'\n  files = [f for f in listdir(audio_path) if isfile(join(audio_path, f))]  #Gets all files in dir\n  wav_files = [f for f in files if f.endswith('.wav')]  # Gets wav files \n  wav_files = sorted(wav_files)\n  return wav_files, audio_path","f3eba15d":"def diagnosis_data():\n  diagnosis = pd.read_csv('..\/input\/respiratory-sound-database\/Respiratory_Sound_Database\/Respiratory_Sound_Database\/patient_diagnosis.csv')\n  \n  wav_files, audio_path = get_wav_files()\n  diag_dict = { 101 : \"URTI\"}  \n  diagnosis_list = []\n  \n  for index , row in diagnosis.iterrows():\n    diag_dict[row[0]] = row[1]     \n\n  c = 0\n  for f in wav_files:\n    diagnosis_list.append(Diagnosis(c, diag_dict[int(f[:3])], audio_path+f))  \n    c+=1  \n\n  return diagnosis_list","e2b70fdc":"def audio_features(filename): \n  sound, sample_rate = librosa.load(filename)\n  stft = np.abs(librosa.stft(sound))  \n \n  mfccs = np.mean(librosa.feature.mfcc(y=sound, sr=sample_rate, n_mfcc=40),axis=1)\n  chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate),axis=1)\n  mel = np.mean(librosa.feature.melspectrogram(sound, sr=sample_rate),axis=1)\n  contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate),axis=1)\n  tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(sound), sr=sample_rate),axis=1)\n    \n  concat = np.concatenate((mfccs,chroma,mel,contrast,tonnetz))\n  return concat\n\ndef data_points():\n  labels = []\n  images = []\n\n  to_hot_one = {\"COPD\":0, \"Healthy\":1, \"URTI\":2, \"Bronchiectasis\":3, \"Pneumonia\":4, \"Bronchiolitis\":5, \"Asthma\":6, \"LRTI\":7}\n\n  count = 0\n  for f in diagnosis_data():\n    print(count)\n    labels.append(to_hot_one[f.diagnosis]) \n    images.append(audio_features(f.image_path))\n    count+=1\n\n  return np.array(labels), np.array(images)","2c2c0042":"def preprocessing(labels, images):    \n\n  # Remove Asthma and LRTI\n  images = np.delete(images, np.where((labels == 7) | (labels == 6))[0], axis=0) \n  labels = np.delete(labels, np.where((labels == 7) | (labels == 6))[0], axis=0)      \n\n  # Split data\n  X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=10)\n\n  # Hot one encode the labels\n  y_train = to_categorical(y_train)\n  y_test = to_categorical(y_test)  \n\n  # Format new data\n  y_train = np.reshape(y_train, (y_train.shape[0], 6))\n  X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n  y_test = np.reshape(y_test, (y_test.shape[0], 6))\n  X_test = np.reshape(X_test, (X_test.shape[0], X_train.shape[1],  1))\n\n  return X_train, X_test, y_train, y_test","2663dae1":"start = timer()\n\nlabels, images = data_points()\nX_train, X_test, y_train, y_test = preprocessing(labels, images)\n\nprint('Time taken: ', (timer() - start))","fb625808":"model = Sequential()\nmodel.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=(193, 1)))\n\nmodel.add(Conv1D(128, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling1D(2)) \n\nmodel.add(Conv1D(256, kernel_size=5, activation='relu'))\n\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))   \nmodel.add(Dense(6, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=200, verbose=1)","bc7b7600":"score = model.evaluate(X_test, y_test, batch_size=60, verbose=0)\nprint('Accuracy: {0:.0%}'.format(score[1]\/1))\nprint(\"Loss: %.4f\\n\" % score[0])\n\n# Plot accuracy and loss graphs\nplt.figure(figsize = (15,5))\nplt.subplot(1,2,1)\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label = 'training acc')\nplt.plot(history.history['val_accuracy'], label = 'validation acc')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.title('Loss')\nplt.plot(history.history['loss'], label = 'training loss')\nplt.plot(history.history['val_loss'], label = 'validation loss')\nplt.legend()","d48b2327":"matrix_index = [\"COPD\", \"Healthy\", \"URTI\", \"Bronchiectasis\", \"Pneumoina\", \"Bronchiolitis\"]\n\npreds = model.predict(X_test)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \ny_testclass = np.argmax(y_test, axis=1) # true classes\n\ncm = confusion_matrix(y_testclass, classpreds)\nprint(classification_report(y_testclass, classpreds, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm \/ cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsn.heatmap(df_cm, annot=annot, fmt='')","8edf47b2":"# Preprocessing","94a3937b":"# Convolutional Neural Network ","f0274e6b":"# Overview\n\nHere we lay out an method to classify respiratory disease using a convolutional neural network. Image features are combined together to make the input. Because all these features need to be extracted it takes about 40 mins to run (make yourself a coffee or something). This method achieves an accuracy of 95% and a loss of around 0.2.","68558416":"# Feature Extraction","aecdd4a0":"# Parsing the Dataset","1a639e8a":"# Evaluation"}}