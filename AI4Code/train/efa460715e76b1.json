{"cell_type":{"9d33afb3":"code","99582f7f":"code","aae3cea7":"code","a13c3b5b":"code","2d56e59a":"code","d337b833":"code","35582fbe":"code","13924765":"code","7d2664dd":"code","c9d4e26c":"code","5fb1324c":"code","d3bbbfcb":"code","db7eda77":"code","97c72415":"code","d4cbf7bd":"code","5776f603":"code","6460616e":"code","4ce2235d":"code","e62433b5":"code","924e24e7":"code","5d7b9ec7":"code","56a95430":"code","abdc2d38":"code","956e76aa":"code","214b94f3":"markdown"},"source":{"9d33afb3":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler,RobustScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier","99582f7f":"train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')#.sample(frac=0.25,random_state=42)#,nrows=500000)\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')#,nrows=10000)","aae3cea7":"train['is_train'] = True\ntest['is_train'] = False\nX= train.append(test).reset_index(drop = True)\ndel train, test\n\nfeatures = list(set(X.columns)-{'claim','id','is_train'})\nX['n_missing'] = X[features].isna().sum(axis=1).astype('int')\nX['n_missing_std'] = X[features].isna().std(axis=1).astype('float')\nX['mean_orig'] = X[features].mean(axis=1)\nX[features] = X[features].fillna(X[features].mean())\nfor el in ['f40','f70','f45','f47','f1','f28']:\n    X[el+'log']= np.log(X[el].clip(lower=0)+1)\n\nscaler = RobustScaler()\nX[features] = scaler.fit_transform(X[features])\n\nX['med'] = X[features].median(axis=1)\n#X['max'] = X[features].max(axis=1)\nX['max2'] = X[features].abs().max(axis=1)\nX['min'] = X[features].min(axis=1)\n#X['min2'] = X[features].abs().min(axis=1)\nX['skew'] = X[features].skew(axis=1)\nX['mean2'] = (X[features]**2).mean(axis=1)\n\nfeatures = list(set(X.columns)-{'claim','id','is_train','f85'})","a13c3b5b":"y = X.loc[X.is_train,'claim']\ntest = X[~X.is_train]\nX = X.loc[X.is_train,features]","2d56e59a":"from lightgbm import LGBMClassifier\n\nfinal_predictions = []\nvalid_scores = []\nimp = pd.DataFrame(index = X.columns)\n    \nkf = KFold(n_splits=10, shuffle=True, random_state=42)\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X=X)):\n    X_train = X.loc[train_idx]\n    X_valid = X.loc[valid_idx]\n    y_train = y.loc[train_idx]\n    y_valid = y.loc[valid_idx]\n    X_test = test[features].copy()\n    \n    scaler = StandardScaler()\n    X_train= scaler.fit_transform(X_train)\n    X_valid = scaler.transform(X_valid)\n    X_test = scaler.transform(X_test)\n    \n    model = LGBMClassifier(\n        max_depth = 3,\n        num_leaves = 7,\n        n_estimators = 20000,\n        colsample_bytree = 0.3,\n        subsample = 0.5,\n        random_state = 42,\n        reg_alpha=18,\n        reg_lambda=17,\n        learning_rate = 0.095,\n        device = 'gpu',\n        objective= 'binary',        \n    )\n    \n    model.fit(X_train, y_train,\n             verbose = False,\n             eval_set = [(X_train, y_train), (X_valid, y_valid)],\n             eval_metric = \"auc\",\n             early_stopping_rounds = 400)\n    \n    preds_valid = model.predict_proba(X_valid)[:,1]\n    preds_test = model.predict_proba(X_test)[:,1]\n    score = roc_auc_score(y_valid, preds_valid)\n    final_predictions.append(preds_test)\n    valid_scores.append(score)\n    print(f'Valid score for Fold {fold} : {score}')\n    \n    imp[\"Fold_\"+str(fold)]=model.feature_importances_\n\nimp[\"Fold_mean\"] = imp.mean(axis=1)\nimp=imp.sort_values('Fold_mean',ascending=False)\n   \nprint('\\nAverage valid score: ', np.mean(valid_scores))\nprint('\\nFeature Importance\\n')\nimp.head(10)","d337b833":"sub = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\npreds = np.mean(np.column_stack(final_predictions), axis=1)\nsub[sub.columns[1]] = preds\nsub.to_csv(\"submission_mdl1.csv\", index=False)\nsub.describe()","35582fbe":"import numpy as np \nimport pandas as pd \nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom skimage.filters import threshold_otsu\nimport lightgbm as lgb\nimport gc\n\nSEED = 0","13924765":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\", index_col='id')\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\", index_col='id')","7d2664dd":"features = [x for x in train.columns.values if x[0]==\"f\"]","c9d4e26c":"train['n_missing'] = train[features].isna().sum(axis=1)\ntest['n_missing'] = test[features].isna().sum(axis=1)\n\ntrain['abs_sum'] = train[features].abs().sum(axis=1)\ntest['abs_sum'] = test[features].abs().sum(axis=1)\n\ntrain['sem'] = train[features].sem(axis=1)\ntest['sem'] = test[features].sem(axis=1)\n\ntrain['std'] = train[features].std(axis=1)\ntest['std'] = test[features].std(axis=1)\n\ntrain['avg'] = train[features].mean(axis=1)\ntest['avg'] = test[features].mean(axis=1)\n\ntrain['max'] = train[features].max(axis=1)\ntest['max'] = test[features].min(axis=1)\n\ntrain['min'] = train[features].min(axis=1)\ntest['min'] = test[features].min(axis=1)","5fb1324c":"X = train.drop([\"claim\"], axis=1)\nX_test = test\ny = train[\"claim\"]","d3bbbfcb":"imputer = SimpleImputer(strategy=\"median\")\nX = imputer.fit_transform(X)\nX_test = imputer.transform(X_test)","db7eda77":"scaler = RobustScaler()\nX = scaler.fit_transform(X)\nX_test = scaler.transform(X_test)","97c72415":"del test, train, scaler, imputer\ngc.collect()","d4cbf7bd":"# Model hyperparameters\nlgbm_params = {'objective': 'binary',\n               'boosting_type': 'gbdt',\n               'num_leaves': 6,\n               'max_depth': 2,\n               'n_estimators': 40000,\n               'reg_alpha': 25.0,\n               'reg_lambda': 76.7,\n               'random_state': SEED,\n               'bagging_seed': SEED, \n               'feature_fraction_seed': SEED,\n               'n_jobs': -1,\n               'subsample': 0.98,\n               'subsample_freq': 1,\n               'colsample_bytree': 0.69,\n               'min_child_samples': 54,\n               'min_child_weight': 256,\n               'metric': 'AUC',\n               'verbosity': -1,\n              }","5776f603":"%%time\n\nsplits = 5\nkf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=SEED)\n\npreds = np.zeros(len(X_test))\n\nfor train_idx, valid_idx in kf.split(X, y):    \n    lgb_train = lgb.Dataset(X[train_idx], y[train_idx], free_raw_data=False)\n    lgb_valid = lgb.Dataset(X[valid_idx], y[valid_idx], free_raw_data=False)\n\n    lgbm_params['learning_rate'] = 0.2\n    \n    model = lgb.train(lgbm_params,\n                      lgb_train,\n                      verbose_eval=-1,\n                      early_stopping_rounds=300,\n                      valid_sets=[lgb_valid])\n    \n    lgbm_params['learning_rate'] = 0.1\n    \n    model = lgb.train(lgbm_params,\n                      lgb_train,\n                      init_model=model,\n                      verbose_eval=-1,\n                      early_stopping_rounds=300,\n                      valid_sets=[lgb_valid])\n    \n    preds += model.predict(X_test) \/ splits\n    \n    gc.collect()","6460616e":"submission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv', index_col='id')\nsubmission['claim'] = preds\nsubmission.to_csv('submission_mdl5.csv')","4ce2235d":"# %%time\n# read dataframe\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\n\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","e62433b5":"# prepare dataframe for modeling\nX = df_train.drop(columns=['id','claim']).copy()\ny = df_train['claim'].copy()\n\ntest_data = df_test.drop(columns=['id']).copy()","924e24e7":"# feature Engineering\ndef get_stats_per_row(data):\n    data['mv_row'] = data.isna().sum(axis=1)\n    data['min_row'] = data.min(axis=1)\n    data['std_row'] = data.std(axis=1)\n    return data\n\nX = get_stats_per_row(X)\ntest_data = get_stats_per_row(test_data)","5d7b9ec7":"# create preprocessing pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\npipeline = Pipeline([\n    ('impute', SimpleImputer(strategy='mean')),\n    ('scale', StandardScaler())\n])\n\nX = pd.DataFrame(columns=X.columns, data=pipeline.fit_transform(X))\ntest_data = pd.DataFrame(columns=test_data.columns, data=pipeline.transform(test_data))","56a95430":"# params from optuna study, i've done earlier\nbest_params = {\n    'iterations': 15585, \n    'objective': 'CrossEntropy', \n    'bootstrap_type': 'Bernoulli', \n    'od_wait': 1144, \n    'learning_rate': 0.023575206684596582, \n    'reg_lambda': 36.30433203563295, \n    'random_strength': 43.75597655616195, \n    'depth': 7, \n    'min_data_in_leaf': 11, \n    'leaf_estimation_iterations': 1, \n    'subsample': 0.8227911142845009,\n    'task_type' : 'GPU',\n    'devices' : '0',\n    'verbose' : 0\n}","abdc2d38":"%%time\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_curve, auc\nfrom catboost import CatBoostClassifier\n\nkf = KFold(n_splits=5, shuffle=True, random_state=1)\n\npred_tmp = []\nscores = []\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X)):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n\n    model = CatBoostClassifier(**best_params)\n    model.fit(X_train, y_train)\n\n    # validation prediction\n    pred_valid = model.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\")\n    print('::'*20)\n    \n    # test prediction\n    y_hat = model.predict_proba(test_data)[:,1]\n    pred_tmp.append(y_hat)\n    \nprint(f\"Overall Validation Score: {np.mean(scores)}\")","956e76aa":"# average predictions over all folds\npredictions = np.mean(np.column_stack(pred_tmp),axis=1)\n\n# create submission file\nsample_submission['claim'] = predictions\nsample_submission.to_csv('.\/mdl_1212.csv', index=False)","214b94f3":"# model 3"}}