{"cell_type":{"2c5c2156":"code","76ee4921":"code","77c5c60e":"code","21b1a63c":"code","02246036":"code","f93c0cff":"code","149deee2":"code","0670be9f":"code","f4e9123f":"code","e80cd79c":"code","32c841c4":"code","f97d802f":"code","fe731c72":"code","b8186ebc":"code","80858975":"code","b32eaa08":"code","5a4f1b76":"code","7f4e135d":"code","1315ec61":"code","3bb1e205":"markdown","cf4bcc7b":"markdown","1fa09494":"markdown","bb176946":"markdown","6db42cd8":"markdown","1681ffca":"markdown","933005e4":"markdown","89c21975":"markdown","ae0cccb3":"markdown","5091bcb1":"markdown","3f772e30":"markdown","a9a38a57":"markdown","f08c41e9":"markdown","c58ba568":"markdown","78ec778c":"markdown","336a7e92":"markdown","d5781fb0":"markdown","6ad46c77":"markdown","aa2ca091":"markdown","26585eab":"markdown","053a598d":"markdown","e9613051":"markdown","52a583d6":"markdown","9f8f390d":"markdown","59531a85":"markdown","1a4dfb30":"markdown","f824779c":"markdown","00a18878":"markdown","077d48b3":"markdown","7b20dcb9":"markdown","69986674":"markdown","cecbb5dc":"markdown","bb0ddf82":"markdown"},"source":{"2c5c2156":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom scipy.signal import savgol_filter\nfrom statsmodels.sandbox.stats.runs import runstest_1samp\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score","76ee4921":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","77c5c60e":"data = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/audi.csv')\ndata","21b1a63c":"data_encode_dummy = pd.get_dummies(data,columns=['model', 'transmission','fuelType'], drop_first = True)\ndata_encode_dummy","02246036":"unique_model = data['model'].unique()\ntransmission_unique = data['transmission'].unique()\nfueltype_unique = data['fuelType'].unique()\n\nunique_model.sort()\ntransmission_unique.sort()\nfueltype_unique.sort()\n\nprint(data_encode_dummy.columns)\nprint(unique_model)\nprint(transmission_unique)\nprint(fueltype_unique)","f93c0cff":"X = data_encode_dummy.drop(columns = ['price'])\nY = data_encode_dummy['price']\n\ntitle = ['Price vs Year', \n         'Price vs Mileage', \n         'Price vs Tax', \n         'Price vs Mpg', \n         'Price vs Engine Size']\n\nfig,ax = plt.subplots(3,2,figsize=(20,20))\n\ni = 0\nfor rows in range(3):\n    for cols in range(2):\n        if rows == 2 and cols == 1:\n            fig.delaxes(ax[rows,cols])\n            break\n        ax[rows,cols].scatter(x = X[X.columns[i]], y = Y)\n        ax[rows,cols].set_title(title[i])\n        i = i+1\n        \nfig.subplots_adjust(hspace=0.5, wspace=0.5)","149deee2":"data_encode_dummy_transform = data_encode_dummy.copy()\ndata_encode_dummy_transform['price'] = np.log(data_encode_dummy_transform['price'])\ndata_encode_dummy_transform","0670be9f":"X = data_encode_dummy_transform.drop(columns = ['price'])\nY = data_encode_dummy_transform['price']\n\ntitle = ['Price vs Year', \n         'Price vs Mileage', \n         'Price vs Tax', \n         'Price vs Mpg', \n         'Price vs Engine Size']\n\nfig,ax = plt.subplots(3,2,figsize=(20,20))\n\ni = 0\nfor rows in range(3):\n    for cols in range(2):\n        if rows == 2 and cols == 1:\n            fig.delaxes(ax[rows,cols])\n            break\n        ax[rows,cols].scatter(x = X[X.columns[i]], y = Y)\n        ax[rows,cols].set_title(title[i])\n        i = i+1\n        \nfig.subplots_adjust(hspace=0.5, wspace=0.5)","f4e9123f":"X = data_encode_dummy_transform[['year','mileage','tax','mpg','engineSize']]\nX.corr()","e80cd79c":"VIF = pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], \n                index=X.columns)\nprint(VIF)","32c841c4":"X = data_encode_dummy_transform.drop(columns = ['price'])\nY = data_encode_dummy_transform['price']\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n\nX_train = X_train.reset_index(drop = True)\nX_test = X_test.reset_index(drop = True)\nY_train = Y_train.reset_index(drop = True)\nY_test = Y_test.reset_index(drop = True)","f97d802f":"# Define the PCA object\npca = PCA()\n\n# Preprocessing (1): first derivative\nd1X = savgol_filter(X_train, 25, polyorder = 5, deriv=1)\n\n# Preprocess (2) Standardize features by removing the mean and scaling to unit variance\nXstd = StandardScaler().fit_transform(d1X[:,:])\n\n# Run PCA producing the reduced variable Xreg and select the first pc components\nXreg = pca.fit_transform(Xstd)[:,:]\n\nXGB = XGBRegressor(random_state=0)\n\nXGB.fit(Xreg,Y_train)","fe731c72":"XGB.score(Xreg,Y_train)","b8186ebc":"Y_PCA_XGB = XGB.predict(Xreg)\n\nmean_squared_error(Y_train, Y_PCA_XGB)","80858975":"resid = Y_train - Y_PCA_XGB\n\nsns.distplot(resid)","b32eaa08":"result = runstest_1samp(resid)[1]\nprint('P-value :',result)","5a4f1b76":"plt.xlabel('Fitted Values')\nplt.ylabel('Residuals')\nplt.scatter(Y_PCA_XGB,resid)","7f4e135d":"# Preprocessing (1): first derivative\nd1X = savgol_filter(X_test, 25, polyorder = 5, deriv=1)\n\n# Preprocess (2) Standardize features by removing the mean and scaling to unit variance\nXstd = StandardScaler().fit_transform(d1X[:,:])\n\n# Run PCA producing the reduced variable Xreg and select the first pc components\nXreg = pca.fit_transform(Xstd)[:,:]\n\nprediction = XGB.predict(Xreg)\n\ndata_test = {\n    'Y_test' : Y_test,\n    'Prediction' : prediction\n}\n\npd.DataFrame(data_test)","1315ec61":"mean_squared_error(Y_test, prediction)","3bb1e205":"Next, we're going to check whether the independent variables are correlated each other. For an overview, we'll check the correlation matrix.","cf4bcc7b":"Well the $MSE$ of the data test using this model is higher than using PCR, but it's still low for me haha.... At least, it's great to know how to handle multicollinearity. Please comment in down below so that we can learn each other. :)\n\nNote: if we want to use this model, we must first standardize the independent variables. Then, after we get the predicted dependent variables, we should take the exponent instead to see the exact price.","1fa09494":"Next, we're going to check the asumptions for linear regression. I'll use linear regression because it's the very basic regression.","bb176946":"To check the autocorrelation of residuals, we will use run test with the null hypothesis is the residual values are random (there is no autocorrelation in residuals).","6db42cd8":"# Split Data","1681ffca":"Hi! This is my first time modelling a dataset with kaggle. I've read several submissions here and they are very great since their model's scores are so high. In my first version, I used two regression analysis, PCR (Principal Component Regression) and PLS (Partial Least Square), then I compared between those two models. Since PCR was the best model, I then realized that what if I combined PCA (Principal Component Analysis) and XGBRegressor since it is the best model this far. And what surprises me is that the score is 0.99! I don't know whether it's true or not (amateur shock). So let's get started and please comment in down below.","933005e4":"We can see that the VIF for 'year', 'mpg', and 'engineSize' are more than 10. It means that those variables correlate with the other variables (for example, 'year' variable effects the values of all of the other independent variables). So there is a multicollinearity in this data. From the statistics view, we can exclude the variables, but I don't know whether those variables are important to predict the price or not. So, I'll keep those variables.","89c21975":"The code above is used to see which is the reference category. We can see that model A1, transmission Automatic, and fuel type Diesel are the reference categories.","ae0cccb3":"# Import Packages and Data","5091bcb1":"### Normality of Residuals","3f772e30":"We can see that the correlation between 'mileage' and 'year' is so high. Not only them, but also 'mpg' and 'tax'. We need to check the VIF to see the overall correlation between the independent variables.","a9a38a57":"Well I saw that many people skip this step, but I'll keep doing this step.","f08c41e9":"### Autocorrelation of Residuals","c58ba568":"Since 'model', 'transmission', and 'fuel type' data types are categorical, I will change their values to numeric values. Here, I'll create dummy variables (binary encoding).","78ec778c":"We can see from the plots above that not all of the independent variables has a linear relationship with the dependent variable ('price' is the dependent variable and the rest are the independent variables). Therefore, we need to transform the data. Most of them have an exponentially relationship so we will only take the logarithm of the 'price' variable.","336a7e92":"### Homoscedasticity of Residuals","d5781fb0":"### Multicollinearity","6ad46c77":"After we transform it, we plot it again to check whether it's already linear or not. We can see that it's already linear so we can continue to the next step.\n\nNote: I'm sorry for the long variables name. I just want to make it clear what those variables are hehe...","aa2ca091":"### Transformation","26585eab":"# Create Model","053a598d":"With the plot looks like that, we can assume that the residuals are normal.","e9613051":"We can see that the residuals don't form any shape so that the variance is constant. Therefore, we can say that the homoscedasticity of residuals is achieved.\n\nSince this model has passed all of the diagnostic checkings, we can say that this model is well enough to predict the Audi car.","52a583d6":"As you can see, the $R^2$ is $0.989 \\sim 99\\%$ which is high enough and the $MSE$ is $0.0022$ which is small enough.","9f8f390d":"# Test Data","59531a85":"# Create Dummy Variables","1a4dfb30":"# Asumptions Check","f824779c":"As usual, we will split the train and test data.","00a18878":"And now for the main event, we will create the model. Because the data has a multicollinearity, we need a regression analysis that can handle multicollinearity. Like I said in the introduction, I've made a model before in my first version using PCR and PLS and then compare these models. Then I realized that what if I combined PCA and XGBRegressor. So first we will use PCA on independent variables matrix, then we will use XGBRegressor to create the model. I will use the code for PCA from [this site](https:\/\/nirpyresearch.com\/principal-component-regression-python\/).","077d48b3":"Now, we will test our model with the test data.","7b20dcb9":"### Linearity","69986674":"# Diagnostic Checking","cecbb5dc":"First, I'm going to import some packages I need and also the data.","bb0ddf82":"With significance $\\alpha=0.05$, we can see that p-value $> 0.05$. Therefore, we won't reject the null hypothesis so that there is no autocorrelation in residuals."}}