{"cell_type":{"ab2bcd9d":"code","ab6a858f":"code","8e373d7e":"code","f9d3c207":"code","d3912bc7":"code","a6efad54":"code","74f6f1d7":"code","962efa38":"code","9daa72db":"code","061a73b3":"code","1240bf51":"code","f88a14a4":"code","10666d00":"code","7d74adad":"code","7758a0b4":"code","5c4afd62":"code","91c2d852":"markdown","786287a1":"markdown"},"source":{"ab2bcd9d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nfrom PIL import Image\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport cv2\nimport fnmatch\nimport tensorflow as tf\nfrom time import sleep\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Dropout,Flatten,BatchNormalization,MaxPooling2D,Activation\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend as k\nimport matplotlib.image as mpimg","ab6a858f":"print(os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\"))","8e373d7e":"imagePatches_0 = glob('..\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected\/*.png', recursive=True)\nimagePatches_1 = glob('..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized\/*.png', recursive=True)\nprint(len(imagePatches_0))\nprint(len(imagePatches_1))","f9d3c207":"train_para=os.path.join('..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized\/')\ntrain_uninf=os.path.join('..\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected\/')\ntrain_para_names=os.listdir(train_para)\ntrain_uninf_names=os.listdir(train_uninf)\n\nnrows=4\nncols=4\n\npic_index=0\n\nfig=plt.gcf()\nfig.set_size_inches(ncols*4,nrows*4)\n\npic_index+=4\n\nnext_para_pix = [os.path.join(train_para,fname) for fname in train_para_names[pic_index-4:pic_index]]\nnext_uninf_pix = [os.path.join(train_uninf,fname) for fname in train_uninf_names[pic_index-4:pic_index]]\n\nfor i, img_path in enumerate(next_para_pix+next_uninf_pix):\n    sp=plt.subplot(nrows,ncols,i+1)\n    sp.axis('Off')\n    img=mpimg.imread(img_path)\n    plt.imshow(img)\nplt.show()","d3912bc7":"x=[]\ny=[]\nfor img in imagePatches_0:\n    full_size_image = cv2.imread(img)\n    im = cv2.resize(full_size_image, (128, 128), interpolation=cv2.INTER_CUBIC)\n    x.append(im)\n    y.append(0)\nfor img in imagePatches_1:\n    full_size_image = cv2.imread(img)\n    im = cv2.resize(full_size_image, (128, 128), interpolation=cv2.INTER_CUBIC)\n    x.append(im)\n    y.append(1)\nx = np.array(x)\ny = np.array(y)","a6efad54":"from sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 101)\ny_train = to_categorical(y_train, num_classes = 2)\ny_valid = to_categorical(y_valid, num_classes = 2)","74f6f1d7":"x_train.shape","962efa38":"x_valid.shape","9daa72db":"input_layer = tf.keras.layers.Input([128,128,3])\n\nconv1 = tf.keras.layers.Conv2D(filters = 32 , kernel_size = (5,5) , padding ='Same',\n        activation='relu')(input_layer)\npool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))( conv1)\n\n\nconv2 = tf.keras.layers.Conv2D(filters = 64 , kernel_size = (3,3) , padding ='Same',\n        activation='relu')(pool1)\npool2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2) , strides=(2,2))(conv2)\n\n\nconv3 = tf.keras.layers.Conv2D(filters = 128 , kernel_size = (3,3) , padding ='Same',\n        activation='relu')(pool2)\npool3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2) , strides=(2,2))(conv3)\n\n\nconv4 = tf.keras.layers.Conv2D(filters = 128 , kernel_size = (3,3) , padding ='Same',\n        activation='relu')(pool3)\npool4 = tf.keras.layers.MaxPooling2D(pool_size=(2,2) , strides=(2,2))(conv4)\n\nflatten = tf.keras.layers.Flatten()(pool4)\ndense = tf.keras.layers.Dense(512 , activation = 'relu')(flatten)\nout = tf.keras.layers.Dense(2 , activation='sigmoid' )(dense)\n\nmodel = tf.keras.Model(input_layer , out)\n","061a73b3":"model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])","1240bf51":"history = model.fit(x_train,y_train,batch_size = 32, epochs = 50, verbose=1,  validation_split=0.2)","f88a14a4":"fig = plt.figure()\nax = fig.add_subplot(111)\nax.set_facecolor('w')\nax.grid(b=False)\nax.plot(history.history['accuracy'], color='red')\nax.plot(history.history['val_accuracy'], color ='green')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()","10666d00":"fig = plt.figure()\nax = fig.add_subplot(111)\nax.set_facecolor('w')\nax.grid(b=False)\nax.plot(history.history['loss'], color='red')\nax.plot(history.history['val_loss'], color ='green')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","7d74adad":"from sklearn.metrics import classification_report\npred = model.predict(x_valid)\nprint(classification_report(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1)))","7758a0b4":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","5c4afd62":"from sklearn.metrics import confusion_matrix\nimport itertools  \ncm_plot_labels = ['Uninfected', 'Parasitized']\ncm = confusion_matrix(np.argmax(y_valid, axis = 1),np.argmax(pred, axis = 1))\nplot_confusion_matrix(cm = cm , classes= cm_plot_labels , title='Confution Matrix')","91c2d852":"# **Malaria-Cell-Classification**","786287a1":"In this project, I have used Convolutional Neural Network (CNN) to classify Malaria cell images as Parasitized or Uninfected. The dataset is available at https:\/\/www.kaggle.com\/iarunava\/cell-images-for-detecting-malaria. I have split the dataset into 80% training and 20% validation sets. The total number of training and testing images are 22046 and 5512 respectively. The dataset contains equal number of images in both the classes. I have implemented the code using tensorflow and keras. I have obtained a validation accuaracy of over 95%, training for 10 epochs only."}}