{"cell_type":{"ccdfc54a":"code","6aa28f52":"code","3f5f75b6":"code","1bb18930":"code","377017be":"code","a828fcaa":"code","142d2b3f":"code","d5c280fe":"code","5adb7a5e":"code","8c4fadee":"code","d391a95d":"code","6c74ddaa":"code","2165c0e0":"code","ad7b1360":"code","f5c8ee81":"code","d39fc1b4":"code","086f568a":"code","e357a278":"code","0b4d64ac":"code","43457285":"code","c95c62d0":"code","2df5e978":"code","699355e8":"code","331e27f6":"code","feb02911":"code","bd62a216":"code","a6e79978":"code","6fcd3bfe":"code","ca7f545e":"code","7e5bae70":"code","10894542":"code","9217d37d":"code","b2d4a93d":"code","b3952dda":"code","2b900b25":"code","8666d33f":"code","e9a684ac":"code","0b2367b7":"code","b74965e3":"code","8b15ba8b":"code","312f4312":"code","5d979e1a":"code","24242d11":"code","5243ff15":"code","a3d25e45":"markdown"},"source":{"ccdfc54a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6aa28f52":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","3f5f75b6":"import tensorflow as tf\ntf.__version__","1bb18930":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","377017be":"datagen = ImageDataGenerator( rescale = 1.0\/255,\n                                    # zoom_range = 0.2,\n                                    # samplewise_center = True,\n                                    # samplewise_std_normalization = True,\n                                   validation_split = 0.01)","a828fcaa":"train_generator = datagen.flow_from_directory( directory = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/',\n                                                     target_size = (224, 224),\n                                                     class_mode = 'categorical',\n                                                     batch_size = 128,\n                                                     shuffle = True,\n                                                     subset = 'training')\n","142d2b3f":"train_generator.class_indices","d5c280fe":"validation_generator = datagen.flow_from_directory( directory = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/',\n                                                     target_size = (224, 224),\n                                                     class_mode = 'categorical',\n                                                     batch_size = 128,\n                                                     subset = 'validation')\n","5adb7a5e":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model","8c4fadee":"base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape = (224, 224, 3))","d391a95d":"base_model.summary()","6c74ddaa":"len(base_model.layers)","2165c0e0":"i = 0\nfor layers in base_model.layers:\n  layers.trainable = False\n  i = i + 1\n  if(i > 19):\n    break\n","ad7b1360":"i","f5c8ee81":"from tensorflow.keras import optimizers","d39fc1b4":"x=base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024,activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(512,activation='relu')(x)\nx = Dropout(0.5)(x)\npreds = Dense(29,activation='softmax')(x)\nmodel = Model(inputs=base_model.input,outputs=preds)","086f568a":"model.compile(optimizer = optimizers.RMSprop(learning_rate = 0.0001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","e357a278":"history = model.fit_generator(train_generator, steps_per_epoch = 86130\/\/128, epochs = 1, validation_data = validation_generator, validation_steps = 870\/\/128)","0b4d64ac":"scoreSeg = model.evaluate_generator(validation_generator, 870\/\/128)\nprint(\"Accuracy = \", scoreSeg[1])\nprint(scoreSeg)","43457285":"model.save(\"third_main_model_3e.h5\")","c95c62d0":"import tensorflow as tf\nbring_model = tf.keras.models.load_model(\"..\/input\/model-sld\/main_model_12e.h5\")","2df5e978":"scoreSeg =  bring_model.evaluate_generator(validation_generator, 870\/\/128)\nprint(\"Accuracy = \", scoreSeg[1])\nprint(scoreSeg)","699355e8":"# To predict the Multiple Images","331e27f6":"import cv2\nimport glob\n\nimages = [cv2.imread(image) for image in glob.glob(\"..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test\/*\")]\nlabels = [image for image in glob.glob(\"..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test\/*\")]","feb02911":"def get_alpha(val):\n    names = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5,'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'DEL': 26, 'NOTHING': 27, 'SPACE': 28}\n    for key, value in names.items(): \n         if val == value: \n             return key \n  \n    return \"key doesn't exist\"\n","bd62a216":"len(images), len(labels)","a6e79978":"type(images[0])","6fcd3bfe":"for i in range(len(images)):\n    images[i] = images[i].astype(\"float32\")","ca7f545e":"for i in range(len(images)):\n    images[i] = cv2.resize(images[i], (224, 224), interpolation = cv2.INTER_AREA) \/ 255.0","7e5bae70":"images = np.asarray(images)","10894542":"for i in range(len(labels)):\n    labels[i] = (labels[i].split(\"\/\")[-1]).split(\"_\")[0]","9217d37d":"labels[0]","b2d4a93d":"def vectorization(labels):\n    names = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5,'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'DEL': 26, 'NOTHING': 27, 'SPACE': 28}\n    for i in range(len(labels)):\n        labels[i] = labels[i].upper()\n    \n    for i in range(len(labels)):\n        labels[i] = names[labels[i]]\n    \n    result = np.zeros((len(labels), 29))\n    for i, values in enumerate(labels):\n        result[i, values] = 1\n    return result\n","b3952dda":"y = vectorization(labels)","2b900b25":"y","8666d33f":"y_pred = bring_model.predict(images)","e9a684ac":"labels_pred = []\nfor i in range(len(y_pred)):\n    labels_pred.append(get_alpha(np.argmax(y_pred[i])))","0b2367b7":"labels_pred","b74965e3":"loss,acc = bring_model.evaluate(images, y)\nprint(loss, acc)\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))","8b15ba8b":"# For a particular image to pedict\nimage = \"Give a particular image from you choice\"\n''' Here I use first image of the test image '''","312f4312":"y_pred = bring_model.predict([images[0].reshape((1,) + images[0].shape)])","5d979e1a":"val = np.argmax(y_pred)","24242d11":"Alphabet_pred = get_alpha(val)\nprint(Alphabet_pred)","5243ff15":"                                            ''' Thank You '''","a3d25e45":"** Total 12 epochs and 20 freeze layers of MobileNet_v2"}}