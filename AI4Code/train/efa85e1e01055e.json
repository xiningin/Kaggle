{"cell_type":{"7589d50b":"code","8140efb3":"markdown","ec9dba80":"markdown","4d0833ff":"markdown"},"source":{"7589d50b":"from IPython.display import YouTubeVideo\nYouTubeVideo('kQmHaI5Jw1c', width=800, height=450)","8140efb3":"# Intro\n\nAt the end of this lesson, you will understand how stochastic gradient descent and back-propagation are used to set the weights in a deep learning model. These topics are complex, but many experts view them as the most important ideas in deep learning.\n\n# Lesson\n","ec9dba80":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum\/161321) to chat with other Learners.*","4d0833ff":"# Keep Going\nNow you are ready to **[train your own models from scratch](https:\/\/www.kaggle.com\/dansbecker\/deep-learning-from-scratch).**\n\n---\n**Links Mentioned**\n\n[ReLU activation function](https:\/\/www.kaggle.com\/dansbecker\/rectified-linear-units-relu-in-deep-learning)"}}