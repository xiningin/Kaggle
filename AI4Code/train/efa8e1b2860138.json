{"cell_type":{"71b16f23":"code","ccc5d9ec":"code","dbb91a12":"code","e65c85f5":"code","7ec1288b":"code","d464e684":"code","812cdb5e":"code","7a023599":"code","1849302a":"code","f9a7bfad":"code","73a97f63":"code","e1df3c63":"code","478092f0":"code","296e2b90":"code","e14049d6":"code","bccce00e":"code","c6567c27":"code","bcda3dd5":"code","f053026c":"code","0bd17dbd":"code","602521bf":"code","1f98845e":"code","5c5b5b0d":"code","90f1bf8a":"code","2156c821":"code","654bc576":"code","b085f330":"code","cd02ae0f":"code","58bf1a5d":"code","2ac47af0":"code","7cc144ba":"code","e8a1ee38":"code","96d6cb77":"code","cef51304":"code","a5a092c7":"code","53136117":"code","0bfede8c":"code","71009e8d":"code","300d0aa6":"code","6a2eb292":"code","8b2c4fd4":"code","e959bd27":"code","beb949b5":"code","25328b2d":"code","f5929c38":"code","fa220ecd":"code","f1245a86":"code","e17bd3ab":"code","ba84743b":"code","2938c8fa":"code","4f9ec06d":"code","50bb3c26":"code","743b7632":"code","0d4c374f":"code","dd20df4f":"code","324acf52":"code","ce821fba":"code","7ddf730a":"code","fa6fda50":"code","e767c98e":"code","e346d268":"code","1eb1aa24":"code","a1abaa15":"code","8feeff31":"code","2ffdd2f4":"code","c2b6a429":"code","d4832e09":"code","bc10660a":"code","972a9376":"code","92643a34":"code","830c485d":"code","6031d415":"markdown","09484bf7":"markdown","6b499a18":"markdown","a6653ada":"markdown"},"source":{"71b16f23":"import tensorflow as tf\nimport numpy as np\nimport os","ccc5d9ec":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","dbb91a12":"from kaggle_datasets import KaggleDatasets","e65c85f5":"#all_image_filename = KaggleDatasets().get_gcs_path(\"the-oxfordiiit-pet-dataset\")","7ec1288b":"GCS_PATH = KaggleDatasets().get_gcs_path()","d464e684":"all_image_filename = tf.io.gfile.glob(\n    \"gs:\/\/kds-c910bbd309ea6bdcabc10b9de962b91125a28a14b8e51638146d696e\/*\")","812cdb5e":"all_image_filename","7a023599":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg # mpimg \u7528\u4e8e\u8bfb\u53d6\u56fe\u7247\nimport numpy as np","1849302a":"images = tf.io.gfile.glob(\n    \"gs:\/\/kds-c910bbd309ea6bdcabc10b9de962b91125a28a14b8e51638146d696e\/images\/images\/*.jpg\")","f9a7bfad":"len(images)","73a97f63":"images[:5]","e1df3c63":"annotations = tf.io.gfile.glob(\n    \"gs:\/\/kds-c910bbd309ea6bdcabc10b9de962b91125a28a14b8e51638146d696e\/annotations\/annotations\/trimaps\/*.png\")","478092f0":"annotations[:5]","296e2b90":"img_names =  [img.split('images\/')[-1].split('.jpg')[0] for img in images]","e14049d6":"annotations = [ana for ana in annotations\n                if ana.split('trimaps\/')[-1].split('.png')[0] in img_names]","bccce00e":"len(annotations)","c6567c27":"annotations.sort(key=lambda x: x.split('trimaps\/')[-1].split('.png')[0])\nimages.sort(key=lambda x: x.split('images\/')[-1].split('.jpg')[0])","bcda3dd5":"annotations[1005]","f053026c":"images[1005]","0bd17dbd":"len(images), len(annotations)","602521bf":"np.random.seed(2019)\nindex = np.random.permutation(len(images))","1f98845e":"images = np.array(images)[index]","5c5b5b0d":"images[:5]","90f1bf8a":"anno = np.array(annotations)[index]","2156c821":"anno[:5]","654bc576":"dataset = tf.data.Dataset.from_tensor_slices((images, anno))","b085f330":"test_count = int(len(images)*0.2)","cd02ae0f":"test_count","58bf1a5d":"train_count = len(images) - test_count","2ac47af0":"dataset_train = dataset.skip(test_count)","7cc144ba":"dataset_test = dataset.take(test_count)","e8a1ee38":"def read_jpg(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    return img","96d6cb77":"def read_png(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_png(img, channels=1)\n    return img","cef51304":"def normalize(input_image, input_mask):\n    input_image = tf.cast(input_image, tf.float32)\/127.5 - 1\n    input_mask -= 1\n    input_mask = tf.cast(input_mask, tf.int32)\n    return input_image, input_mask","a5a092c7":"IMG_HEIGHT = 256\nIMG_WIDTH = 256","53136117":"img = read_jpg(images[0])","0bfede8c":"an = read_png(anno[0])","71009e8d":"an = tf.image.grayscale_to_rgb(an)","300d0aa6":"stacked_image = tf.stack([img, an], axis=0)","6a2eb292":"stacked_image.shape","8b2c4fd4":"stacked_image = tf.image.resize(stacked_image, (360, 360))","e959bd27":"stacked_image.shape","beb949b5":"cropped_image = tf.image.random_crop(\n        stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])","25328b2d":"cropped_image.shape","f5929c38":"img = cropped_image[0]","fa220ecd":"img.shape","f1245a86":"my_anno = cropped_image[1, :, :, :1]","e17bd3ab":"my_anno.shape","ba84743b":"plt.imshow(tf.keras.preprocessing.image.array_to_img(my_anno))","2938c8fa":"plt.imshow(tf.keras.preprocessing.image.array_to_img(img))","4f9ec06d":"def crop_img(img, mask):\n    concat_img = tf.concat([img, mask], axis=-1)\n    concat_img = tf.image.resize(concat_img, (280, 280),\n                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    crop_img = tf.image.random_crop(concat_img, [256, 256, 4])\n    return crop_img[ :, :, :3], crop_img[ :, :, 3:]","50bb3c26":"def load_image_train(input_image_path, input_mask_path):\n    input_image = read_jpg(input_image_path)\n    input_mask = read_png(input_mask_path)\n    \n    input_image, input_mask = crop_img(input_image, input_mask)\n    \n    if tf.random.uniform(()) > 0.5:\n        input_image = tf.image.flip_left_right(input_image)\n        input_mask = tf.image.flip_left_right(input_mask)\n\n    input_image, input_mask = normalize(input_image, input_mask)\n\n    return input_image, input_mask","743b7632":"def load_image_test(input_image_path, input_mask_path):\n    input_image = read_jpg(input_image_path)\n    input_mask = read_png(input_mask_path)\n    input_image = tf.image.resize(input_image, (IMG_HEIGHT, IMG_WIDTH))\n    input_mask = tf.image.resize(input_mask, (IMG_HEIGHT, IMG_WIDTH))\n\n    input_image, input_mask = normalize(input_image, input_mask)\n\n    return input_image, input_mask","0d4c374f":"BATCH_SIZE = 8 * tpu_strategy.num_replicas_in_sync\nBUFFER_SIZE = 1000\nSTEPS_PER_EPOCH = train_count \/\/ BATCH_SIZE\nVALIDATION_STEPS = test_count \/\/ BATCH_SIZE","dd20df4f":"AUTO = tf.data.experimental.AUTOTUNE","324acf52":"train = dataset_train.map(load_image_train, num_parallel_calls=AUTO)\ntest = dataset_test.map(load_image_test, num_parallel_calls=AUTO)","ce821fba":"train_dataset = train.cache().repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTO)\ntest_dataset = test.cache().batch(BATCH_SIZE)","7ddf730a":"train_dataset","fa6fda50":"%matplotlib inline","e767c98e":"OUTPUT_CHANNELS = 3","e346d268":"def create_model():\n    inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n    \n    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)     #  256*256*64\n    \n    x1 = tf.keras.layers.MaxPooling2D(padding='same')(x)   # 128*128*64\n    \n    x1 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)     \n    x1 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x1)\n    x1 = tf.keras.layers.BatchNormalization()(x1)     #  128*128*128\n    \n    x2 = tf.keras.layers.MaxPooling2D(padding='same')(x1)   # 64*64*128\n    \n    x2 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)     \n    x2 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x2)\n    x2 = tf.keras.layers.BatchNormalization()(x2)     #  64*64*256\n    \n    x3 = tf.keras.layers.MaxPooling2D(padding='same')(x2)   # 32*32*256\n    \n    x3 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x3)\n    x3 = tf.keras.layers.BatchNormalization()(x3)     \n    x3 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x3)\n    x3 = tf.keras.layers.BatchNormalization()(x3)     #  32*32*512\n    \n    x4 = tf.keras.layers.MaxPooling2D(padding='same')(x3)   # 16*16*512\n    \n    x4 = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu')(x4)\n    x4 = tf.keras.layers.BatchNormalization()(x4)     \n    x4 = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu')(x4)\n    x4 = tf.keras.layers.BatchNormalization()(x4)     #  16*16*1024\n    \n    #  \u4e0a\u91c7\u6837\u90e8\u5206\n    \n    x5 = tf.keras.layers.Conv2DTranspose(512, 2, strides=2,\n                                         padding='same', activation='relu')(x4) \n    x5 = tf.keras.layers.BatchNormalization()(x5)     #  32*32*512\n    \n    x6 = tf.concat([x3, x5], axis=-1)  #  32*32*1024\n    \n    x6 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x6)\n    x6 = tf.keras.layers.BatchNormalization()(x6)     \n    x6 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x6)\n    x6 = tf.keras.layers.BatchNormalization()(x6)     #  32*32*512\n    \n    x7 = tf.keras.layers.Conv2DTranspose(256, 2, strides=2,\n                                         padding='same', activation='relu')(x6) \n    x7 = tf.keras.layers.BatchNormalization()(x7)     #  64*64*256\n    \n    x8 = tf.concat([x2, x7], axis=-1)  #  64*64*512\n    \n    x8 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x8)\n    x8 = tf.keras.layers.BatchNormalization()(x8)     \n    x8 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x8)\n    x8 = tf.keras.layers.BatchNormalization()(x8)     #  64*64*256\n    \n    x9 = tf.keras.layers.Conv2DTranspose(128, 2, strides=2,\n                                         padding='same', activation='relu')(x8) \n    x9 = tf.keras.layers.BatchNormalization()(x9)     #  128*128*128\n    \n    x10 = tf.concat([x1, x9], axis=-1)  #  128*128*256\n    \n    x10 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x10)\n    x10 = tf.keras.layers.BatchNormalization()(x10)     \n    x10 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x10)\n    x10 = tf.keras.layers.BatchNormalization()(x10)     #  128*128*128\n    \n    x11 = tf.keras.layers.Conv2DTranspose(64, 2, strides=2,\n                                         padding='same', activation='relu')(x10) \n    x11 = tf.keras.layers.BatchNormalization()(x11)     #  256*256*64\n    \n    x12 = tf.concat([x, x11], axis=-1)  #  256*256*128\n    \n    x12 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x12)\n    x12 = tf.keras.layers.BatchNormalization()(x12)     \n    x12 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x12)\n    x12 = tf.keras.layers.BatchNormalization()(x12)     #  256*256*64\n    \n    output = tf.keras.layers.Conv2D(3, 1, padding='same', activation='softmax')(x12)\n    #  256*256*34\n    return tf.keras.Model(inputs=inputs, outputs=output)","1eb1aa24":"LR_START = 0.00001\nLR_MAX = 0.00005 * tpu_strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8","a1abaa15":"def lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)","8feeff31":"# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = create_model()\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(0.0001), \n        loss='sparse_categorical_crossentropy',\n         metrics=['acc'])","2ffdd2f4":"EPOCHS = 20","c2b6a429":"history = model.fit(train_dataset, \n                    epochs=EPOCHS,\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_steps=VALIDATION_STEPS,\n                    validation_data=test_dataset)\n#                    callbacks=[lr_callback],)","d4832e09":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(EPOCHS)\n\nplt.figure()\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss Value')\nplt.ylim([0, 1])\nplt.legend()\nplt.show()","bc10660a":"num = 3","972a9376":"for image, mask in test_dataset.take(1):\n    pred_mask = model.predict(image)\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    \n    plt.figure(figsize=(10, 10))\n    for i in range(num):\n        plt.subplot(num, 3, i*num+1)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(image[i]))\n        plt.subplot(num, 3, i*num+2)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[i]))\n        plt.subplot(num, 3, i*num+3)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_mask[i]))","92643a34":"for image, mask in train_dataset.take(1):\n    pred_mask = model.predict(image)\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    \n    plt.figure(figsize=(10, 10))\n    for i in range(num):\n        plt.subplot(num, 3, i*num+1)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(image[i]))\n        plt.subplot(num, 3, i*num+2)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[i]))\n        plt.subplot(num, 3, i*num+3)\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_mask[i]))","830c485d":"model.save('unet_v6.h5')","6031d415":"ignore_order = tf.data.Options()\nignore_order.experimental_deterministic = False","09484bf7":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","6b499a18":"for img, musk in train_dataset.take(1):\n    plt.subplot(1,2,1)\n    plt.imshow(tf.keras.preprocessing.image.array_to_img(img[0]))\n    plt.subplot(1,2,2)\n    plt.imshow(tf.keras.preprocessing.image.array_to_img(musk[0]))","a6653ada":"model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])"}}