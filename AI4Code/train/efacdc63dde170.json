{"cell_type":{"d6d53bb3":"code","404913b8":"code","75e8baf6":"code","a1927f1c":"code","f538c17d":"code","03349bb8":"code","11a7e57d":"code","28431c8e":"code","299f7226":"code","1c1a462c":"markdown","9ffcfe60":"markdown","5ffc8ffe":"markdown","4925e2d4":"markdown","19c89fa3":"markdown","2f48486c":"markdown","1a61b8d8":"markdown","724605f6":"markdown"},"source":{"d6d53bb3":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn import datasets\nfrom sklearn.decomposition import PCA\nimport numpy as np\nimport lightgbm as lgb\n\n# import some data to play with\niris = datasets.load_iris()\nX = iris.data[:, :2]  # we only take the first two features.\ny = iris.target\n\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n\nplt.figure(2, figsize=(8, 6))\nplt.clf()\n\n# Plot the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n            edgecolor='k')\nplt.xlabel('Sepal length')\nplt.ylabel('Sepal width')\n\nplt.xlim(x_min, x_max)\nplt.ylim(y_min, y_max)\nplt.xticks(())\nplt.yticks(())\n\n# To getter a better understanding of interaction of the dimensions\n# plot the first three PCA dimensions\nfig = plt.figure(1, figsize=(8, 6))\nax = Axes3D(fig, elev=-150, azim=110)\nX_reduced = PCA(n_components=3).fit_transform(iris.data)\nax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,\n           cmap=plt.cm.Set1, edgecolor='k', s=40)\nax.set_title(\"First three PCA directions\")\nax.set_xlabel(\"1st eigenvector\")\nax.w_xaxis.set_ticklabels([])\nax.set_ylabel(\"2nd eigenvector\")\nax.w_yaxis.set_ticklabels([])\nax.set_zlabel(\"3rd eigenvector\")\nax.w_zaxis.set_ticklabels([])\n\nplt.show()","404913b8":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX = iris.data  # we only take the first two features.\ny = iris.target\nprint(np.shape(X))\nprint(np.shape(y))\nle = preprocessing.LabelEncoder() #\ny_label=le.fit_transform(y)\nclasses=le.classes_","75e8baf6":"X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size=0.30, random_state=42)","a1927f1c":"params = {\n          \"objective\" : \"multiclass\",\n          \"num_class\" : 4,\n          \"num_leaves\" : 60,\n          \"max_depth\": -1,\n          \"learning_rate\" : 0.01,\n          \"bagging_fraction\" : 0.9,  # subsample\n          \"feature_fraction\" : 0.9,  # colsample_bytree\n          \"bagging_freq\" : 5,        # subsample_freq\n          \"bagging_seed\" : 2018,\n          \"verbosity\" : -1 }","f538c17d":"lgtrain, lgval = lgb.Dataset(X_train, y_train), lgb.Dataset(X_test, y_test)\nlgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)","03349bb8":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.multiclass import unique_labels\n\ny_pred =np.argmax(lgbmodel.predict(X_test),axis=1)\ny_true =y_test","11a7e57d":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","28431c8e":"plot_confusion_matrix(y_true, y_pred, classes=classes,\n                      title='Confusion matrix, without normalization')","299f7226":"from sklearn.metrics import accuracy_score\naccuracy_score(y_true, y_pred)","1c1a462c":"**Introduction**\n\nwe can import the iris flower data set from sklearn. It is basically a flower dataset that contain Sepal lenght, Sepal width, Petal Length and Petal Width as feature and classify it into 3** category of iris flower\n* Iris Setosa \n* Iris Versicolour \n* Iris Virginica\n","9ffcfe60":"**Visualising Data**","5ffc8ffe":"**Training Classiifer**","4925e2d4":"**Ploting Confusion Matrix**","19c89fa3":"**Light GBM**\n\nThe parameter detailed information can we found on\n[Light GBM Documentation](http:\/\/https:\/\/lightgbm.readthedocs.io\/en\/latest\/Parameters.html)","2f48486c":"**Spliting Data into Training and validation**\n\nThe data is split into 70% training data and 30% test data","1a61b8d8":"**Final Accuracy**","724605f6":"**Classifier**\n\nWe will label encode the target varibale to numerical using sklearn preprocessig function"}}