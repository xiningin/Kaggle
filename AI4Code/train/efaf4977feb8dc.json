{"cell_type":{"33d12a47":"code","dc9ed852":"code","cce64a6a":"code","af3b770e":"code","15f3951e":"code","3f383860":"code","2a91da17":"code","cd263a51":"code","92ddbbbc":"code","e88a554f":"code","01e91e6c":"code","cc15e510":"markdown"},"source":{"33d12a47":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nimport torch \nimport torch.backends.cudnn as cudnn\nfrom torchvision import models\nfrom torchvision import transforms as tfs\nfrom torch.utils.data import Dataset, DataLoader\nimport time\nfrom torch.autograd import Variable\nfrom PIL import Image\n\n\ndf = pd.read_csv('..\/input\/train.csv')    \ndf_test = pd.read_csv('..\/input\/sample_submission.csv')\nprint(os.listdir(\"..\/input\"))","dc9ed852":"def train_tf(x):\n    im_aug = tfs.Compose([\n        tfs.RandomHorizontalFlip(),\n        tfs.RandomCrop(32),\n        tfs.ToTensor()\n    ])\n    x = im_aug(x)\n    return x","cce64a6a":"train_img = []\ntrain_label = []\nfor i in tqdm(df.values):\n    img = cv2.imread(os.path.join('..\/input', 'train\/train', i[0]))\n#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    tf_img = Image.fromarray(img.astype('uint8')).convert('RGB')\n    if int(i[1]) == 1:\n        tf_img1 = train_tf(tf_img)\n        train_img.append((tf_img1, i[1]))\n    else:\n        for j in range(3):\n            tf_img1 = train_tf(tf_img)\n            train_img.append((tf_img1, i[1]))\n    img= np.transpose(img.astype(np.float32), (2, 1, 0))\n    img = torch.from_numpy(img)\n    train_img.append((img, i[1]))\n\ntest_img = []\nfor i in tqdm(df_test.values):\n    img = cv2.imread(os.path.join('..\/input', 'test\/test', i[0]))\n    img= np.transpose(img.astype(np.float32), (2, 1, 0))\n    img = torch.from_numpy(img)\n    test_img.append((img, i[1]))","af3b770e":"import random\nval_data = random.sample(train_img, int(0.1 * len(train_img)))\ntrain_data = list(set(train_img).difference(set(val_data)))\nprint(len(train_data), len(val_data), len(train_data)+len(val_data))","15f3951e":"model = models.resnet101(pretrained = False)\nclass_nums = 2\n########\u4fee\u6539\u6700\u540e\u4e00\u5c42\u8f93\u51fa\nchannel_in = model.fc.in_features\nmodel.fc = torch.nn.Linear(channel_in, class_nums)\noptimizer = torch.optim.SGD(model.parameters(), lr = 1e-5, momentum = 0.9)\nloss_func = torch.nn.CrossEntropyLoss()","3f383860":"train_loader = DataLoader(dataset = train_data, batch_size = 256, shuffle = True)\nval_loader = DataLoader(dataset = val_data, batch_size = 256)\nmodel = torch.nn.DataParallel(model, device_ids=[0])\nmodel.cuda()\ncudnn.benchmark = True\nfor epoch in range(2000):\n    batch_size_start = time.time()\n    train_loss = 0.\n    train_acc = 0.\n    for trainData,trainLabel in train_loader:\n        trainData= Variable(trainData.cuda())\n        trainLabel = Variable(trainLabel.cuda())\n        optimizer.zero_grad()\n        out = model(trainData)\n        \n        pred = torch.max(out, 1)[1]\n        train_correct = (pred == trainLabel).sum()\n        train_acc += train_correct.item()\n        \n        \n        loss = loss_func(out, trainLabel)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    \n#     print('Epoch [%d\/%d],Train Loss: %.4f,Acc: %.4f, need time %.4f'\n#                       % (epoch + 1, 500, train_loss \/ (len(train_data) \/ 256), train_acc \/ (len(train_data)\/256), time.time() - batch_size_start))\n    val_acc = 0.\n    val_loss = 0.\n    model.eval()\n    for (valData,valLabels) in val_loader:\n#         time_start = time.time()\n        valData = Variable(valData.cuda())\n        valLabels = Variable(valLabels.cuda())\n        outputs = model(valData)\n        val_loss += loss.item()\n        predict = torch.max(outputs.data, 1)[1]\n        correct = (predict == valLabels).sum()\n        val_acc += correct.item()\n    print('Epoch [%d\/%d],Train Loss: %.4f,Train acc: %.4f, Val Loss: %.4f, Val acc: %.4f,  need time %.4f'\n                      %(epoch + 1, 2000, train_loss \/ len(train_data) * 256,train_acc \/ len(train_data) \/ 256,val_loss \/ len(valData) \/ 256,val_acc \/ len(valData) \/ 256,  time.time() - batch_size_start))\n    if (epoch+1) % 400 == 0:torch.save(model.state_dict(), str(epoch)+'v2.pkl')","2a91da17":"# torch.save(model.state_dict(), '799v2.pkl')","cd263a51":"class MakeSubmission:\n    def __init__(self, test_img: list, csv_path: str, model_path: str):\n        model.load_state_dict(torch.load(model_path))\n        model.eval()\n        r = []\n        self.test_img = test_img\n        test_loader = DataLoader(dataset=test_img, batch_size=1)\n        for i, (inputs, labels) in enumerate(test_loader):\n            inputs, labels = Variable(inputs), Variable(labels)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            r.append(int(preds))\n        self.csv_path = csv_path\n        self.df = pd.read_csv(self.csv_path)\n        submission = pd.DataFrame({'id': self.df['id'], 'has_cactus': r})\n        submission.to_csv(model_path+\"sample_submission.csv\", index=False)\n","92ddbbbc":"MakeSubmission(test_img,  \"..\/input\/sample_submission.csv\", '799v2.pkl')","e88a554f":"# aaa = pd.read_csv('sample_submission.csv')","01e91e6c":"ls","cc15e510":"Load data!!!!!!!"}}