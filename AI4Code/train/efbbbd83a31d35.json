{"cell_type":{"fbea174a":"code","7fec2bc9":"code","d0658d47":"code","00d4419f":"code","a22444be":"code","47b44121":"code","6ffb324f":"code","cf39fdba":"code","3199eb28":"code","43cff259":"code","d18152a9":"code","8e19b393":"code","8d68c07e":"markdown","8d32e1b9":"markdown"},"source":{"fbea174a":"import os \nimport pathlib\n\n# For running inference on the TF-Hub module.\nimport tensorflow as tf\n\nimport tensorflow_hub as hub\n\n# For downloading the image.\nimport matplotlib.pyplot as plt\nimport tempfile\nfrom six.moves.urllib.request import urlopen\nfrom six import BytesIO\n\n# For drawing onto the image.\nimport numpy as np\nfrom PIL import Image\nfrom PIL import ImageColor\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageOps\n\n# For measuring the inference time.\nimport time","7fec2bc9":"# link to the model that we want to use \nmodule_handle = \"https:\/\/tfhub.dev\/google\/openimages_v4\/ssd\/mobilenet_v2\/1\"\n# load the model specified by the module_handle\nmodel = hub.load(module_handle)","d0658d47":"# take a look at the available signatures for this particular model\nmodel.signatures.keys()","00d4419f":"#choose the 'default' signature for the object detector.\ndetector = model.signatures['default']\n#detector = model.signatures['serving_default']","a22444be":"def display_image(image):\n    \"\"\"\n    Displays an image inside the notebook.\n    This is used by download_and_resize_image()\n    \"\"\"\n    fig = plt.figure(figsize=(20, 15))\n    plt.grid(False)\n    plt.imshow(image)\n\n\ndef download_and_resize_image(url_path, new_width=256, new_height=256, display=False):\n    '''\n    Fetches an image online or locally stored, resizes it and saves it locally.\n    \n    Args:\n        url_path (string) -- link to the image or path to a locall stored image \n        new_width (int) -- size in pixels used for resizing the width of the image\n        new_height (int) -- size in pixels used for resizing the length of the image\n        \n    Returns:\n        (string) -- path to the saved image\n    '''\n    \n    \n    # create a temporary file ending with \".jpg\"\n    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n    \n    if \"https\" in  str(url_path):\n    \n        # opens the given URL\n        response = urlopen(url_path)\n\n        # reads the image fetched from the URL\n        image_data_res = response.read()\n\n        # puts the image data in memory buffer\n        image_data = BytesIO(image_data_res)\n        \n    else:\n        image_data = url_path\n        \n        \n    # opens the image\n    pil_image = Image.open(image_data)\n\n    # resizes the image. will crop if aspect ratio is different.\n    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n\n    # converts to the RGB colorspace\n    pil_image_rgb = pil_image.convert(\"RGB\")\n\n    # saves the image to the temporary file created earlier\n    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n\n    print(\"Image downloaded to %s.\" % filename)\n\n    if display:\n        display_image(pil_image)\n        \n    return filename","47b44121":"# By Heiko Gorski, Source: https:\/\/commons.wikimedia.org\/wiki\/File:Naxos_Taverna.jpg\nimage_url = \"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/6\/60\/Naxos_Taverna.jpg\"  #@param\ndownloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)","6ffb324f":"def draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               color,\n                               font,\n                               thickness=4,\n                               display_str_list=()):\n\n    \"\"\"\n    Adds a bounding box to an image.\n    \n    Args:\n        image -- the image object\n        ymin -- bounding box coordinate\n        xmin -- bounding box coordinate\n        ymax -- bounding box coordinate\n        xmax -- bounding box coordinate\n        color -- color for the bounding box edges\n        font -- font for class label\n        thickness -- edge thickness of the bounding box\n        display_str_list -- class labels for each object detected\n    \n    \n    Returns:\n        No return.  The function modifies the `image` argument \n                    that gets passed into this function\n    \n    \"\"\"\n    draw = ImageDraw.Draw(image)\n    im_width, im_height = image.size\n    \n    # scale the bounding box coordinates to the height and width of the image\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                ymin * im_height, ymax * im_height)\n    \n    # define the four edges of the detection box\n    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n             (left, top)],\n            width=thickness,\n            fill=color)\n\n    # If the total height of the display strings added to the top of the bounding\n    # box exceeds the top of the image, stack the strings below the bounding box\n    # instead of above.\n    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n    # Each display_str has a top and bottom margin of 0.05x.\n    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n    if top > total_display_str_height:\n        text_bottom = top\n    else:\n        text_bottom = top + total_display_str_height\n        \n    # Reverse list and print from bottom to top.\n    for display_str in display_str_list[::-1]:\n        text_width, text_height = font.getsize(display_str)\n        margin = np.ceil(0.05 * text_height)\n        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n                        (left + text_width, text_bottom)],\n                       fill=color)\n        draw.text((left + margin, text_bottom - text_height - margin),\n                  display_str,\n                  fill=\"black\",\n                  font=font)\n        text_bottom -= text_height - 2 * margin\n\n\ndef draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n    \"\"\"\n    Overlay labeled boxes on an image with formatted scores and label names.\n    \n    Args:\n        image -- the image as a numpy array\n        boxes -- list of detection boxes\n        class_names -- list of classes for each detected object\n        scores -- numbers showing the model's confidence in detecting that object\n        max_boxes -- maximum detection boxes to overlay on the image (default is 10)\n        min_score -- minimum score required to display a bounding box\n    \n    Returns:\n        image -- the image after detection boxes and classes are overlaid on the original image.\n    \"\"\"\n    colors = list(ImageColor.colormap.values())\n\n    try:\n        font = ImageFont.truetype(\"\/usr\/share\/fonts\/truetype\/liberation\/LiberationSansNarrow-Regular.ttf\",\n                              25)\n    except IOError:\n        print(\"Font not found, using default font.\")\n        font = ImageFont.load_default()\n\n    for i in range(min(boxes.shape[0], max_boxes)):\n        \n        # only display detection boxes that have the minimum score or higher\n        if scores[i] >= min_score:\n            ymin, xmin, ymax, xmax = tuple(boxes[i])\n            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n                                         int(100 * scores[i]))\n            color = colors[hash(class_names[i]) % len(colors)]\n            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n\n            # draw one bounding box and overlay the class labels onto the image\n            draw_bounding_box_on_image(image_pil,\n                                       ymin,\n                                       xmin,\n                                       ymax,\n                                       xmax,\n                                       color,\n                                       font,\n                                       display_str_list=[display_str])\n            np.copyto(image, np.array(image_pil))\n        \n    return image","cf39fdba":"def load_img(path):\n    '''\n    Loads a JPEG image and converts it to a tensor.\n    \n    Args:\n        path (string) -- path to a locally saved JPEG image\n    \n    Returns:\n        (tensor) -- an image tensor\n    '''\n    \n    # read the file\n    img = tf.io.read_file(path)\n    \n    # convert to a tensor\n    img = tf.image.decode_jpeg(img, channels=3)\n    \n    return img\n\n\ndef run_detector(detector, path):\n    '''\n    Runs inference on a local file using an object detection model.\n    \n    Args:\n        detector (model) -- an object detection model loaded from TF Hub\n        path (string) -- path to an image saved locally\n    '''\n    \n    # load an image tensor from a local file path\n    img = load_img(path)\n\n    # add a batch dimension in front of the tensor\n    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n    \n    # run inference using the model\n    start_time = time.time()\n    result = detector(converted_img)\n    end_time = time.time()\n\n    # save the results in a dictionary\n    result = {key:value.numpy() for key,value in result.items()}\n\n    # print results\n    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n    print(\"Inference time: \", end_time-start_time)\n\n    # draw predicted boxes over the image\n    image_with_boxes = draw_boxes(\n      img.numpy(), result[\"detection_boxes\"],\n      result[\"detection_class_entities\"], result[\"detection_scores\"])\n\n    # display the image\n    display_image(image_with_boxes)","3199eb28":"run_detector(detector, downloaded_image_path)","43cff259":"test_img = pathlib.Path(r\"..\/input\/car-object-detection\/data\/testing_images\/vid_5_31020.jpg\")\ndownloaded_image_path = download_and_resize_image(test_img, 1280, 856, False)\nrun_detector(detector, downloaded_image_path)","d18152a9":"test_img = pathlib.Path(r\"..\/input\/car-object-detection\/data\/testing_images\/vid_5_27480.jpg\")\ndownloaded_image_path = download_and_resize_image(test_img, 1280, 856, False)\nrun_detector(detector, downloaded_image_path)","8e19b393":"test_img = pathlib.Path(r\"..\/input\/car-object-detection\/data\/testing_images\/vid_5_26920.jpg\")\ndownloaded_image_path = download_and_resize_image(test_img, 1280, 856, False)\nrun_detector(detector, downloaded_image_path)","8d68c07e":"**Thank you for reading, I hope you enjoyed and benefited from it.**\n\n**If you have any questions or notes please leave it in the commont section.**\n\n**If you like this notebook please press upvote and thanks again.**","8d32e1b9":"Hello everyone this is my first (touch on the surface) of object detection world \nI take the code from the course that I am taking now in coursera and modified the download_and_resize_image function to take also image paths. \n\nTensorflow hub has a lot of pretrained models that can be used for inference. the data that this model was trained on contain the car class so we can use it to make inference in the test data here. "}}