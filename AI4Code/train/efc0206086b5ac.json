{"cell_type":{"789699ad":"code","70069682":"code","63a54279":"code","5ddcfe04":"code","10142474":"code","4d136832":"code","80987a48":"code","debdee50":"code","2461e324":"code","a9cc743e":"code","54239472":"code","4560c3f9":"code","a155f93d":"code","fb4bb058":"code","b7e42c84":"code","21e5a87b":"code","58efa49c":"code","a51b3f32":"code","dd9ab508":"code","f3e9c88b":"code","3e2019ed":"markdown","395e0c13":"markdown","2193c319":"markdown","18296e21":"markdown","4fc7be34":"markdown","cd31d1ed":"markdown","3ed3b755":"markdown","61b47d77":"markdown","78003a71":"markdown","877f2441":"markdown","0a063d0e":"markdown","c80bcf7f":"markdown","43a5e019":"markdown","016ddf27":"markdown","b33f3366":"markdown","69aad1ad":"markdown"},"source":{"789699ad":"# System\nimport os\n\n# Numerical\nimport numpy as np\nimport pandas as pd\n\n# NLP\nimport re\n\n# Tools\nimport itertools\n\n# Machine Learning - Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Machine Learning - Model Selection\nfrom sklearn.model_selection import GridSearchCV\n\n\n# Machine Learning - Models\nfrom sklearn import svm\n\n# Machine Learning - Evaluation\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\n\n# Plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(os.listdir(\"..\/input\"))","70069682":"def get_plt_params():\n    params = {'legend.fontsize': 'x-large',\n              'figure.figsize' : (18, 8),\n              'axes.labelsize' : 'x-large',\n              'axes.titlesize' : 'x-large',\n              'xtick.labelsize': 'x-large',\n              'ytick.labelsize': 'x-large',\n              'font.size'      :  10}\n    return params","63a54279":"df = pd.read_csv(\"..\/input\/Iris.csv\")\nclass_names = df.Species.unique()\ndf.head()","5ddcfe04":"df.describe()","10142474":"df.info()","4d136832":"d = df\nall_columns = d.columns\ncolumns = list(set(all_columns) - set([\"Id\"]))\nfeature_columns = list(set(columns) - set([\"Species\"]))\ntarget = \"Species\"","80987a48":"# scaler = StandardScaler()\n# d = scaler.fit_transform(df) \n# d = pd.DataFrame(data=d, columns=df.columns)\n# print(scaler.mean_)\n# # scaler.transform(d)","debdee50":"figsize=(20, 8)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\ncol = target\nxlabel = \"Species\"\nylabel = \"Count\"\n\nsns.countplot(x=df[target])\nplt.title(\"Count of Species\")\nplt.xticks(rotation=90)\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)","2461e324":"sns.set(style=\"white\")\n\nfigsize=(20, 12)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nparams = get_plt_params()\nplt.rcParams.update(params)\n\n# sns.pairplot(df[columns])\n\ng = sns.PairGrid(df[columns])\ng.map(sns.lineplot);\n\n\nplt.plot()\nplt.show()","a9cc743e":"# g = sns.PairGrid(\n#     d, \n#     diag_sharey=True, \n#     height=2.5, \n#     aspect=1, \n#     despine=True, \n#     dropna=False)\n# g = g.map(plt.scatter)\n# g.map_diag(plt.hist)\n# g.map_offdiag(plt.scatter);","54239472":"sns.set(style=\"white\")\n\nfigsize=(20, 12)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nparams = get_plt_params()\nplt.rcParams.update(params)\n\nd = df[columns]\n\nsns.clustermap(d.corr(), \n               figsize=(18, 12),\n#                center=0,\n               cmap=\"vlag\",\n              )\n\n\nplt.plot()\nplt.show()\n","4560c3f9":"sns.set(style=\"white\")\nfig = plt.figure(figsize=(18, 12))\n\nd = df[columns]\n\nparams = get_plt_params()\nplt.rcParams.update(params)\n\n\ncorr = d.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(len(columns)*5, len(columns)*5))\n\ncmap = sns.diverging_palette(h_neg=220, h_pos=10, s=75, l=50, sep=10, n=len(columns), center='light', as_cmap=True)\n\nax = sns.heatmap(\n    corr,\n    cmap=cmap,\n    center=0,\n    robust=True,\n    annot=True,\n    linewidths=0.5,\n    linecolor='white',\n    cbar=True,\n    cbar_kws={\"shrink\": .5},\n    square=True,\n    mask=mask)\n\n# plt.yticks(rotation=0)\n# plt.xticks(rotation=90)","a155f93d":"target_val = set(df[\"Species\"])\nm = {i:v for v,i in enumerate(target_val)}\ndf[\"Species\"] = df[\"Species\"].map(m)","fb4bb058":"# df.dropna()\ny = df[\"Species\"]\nX = df.drop(columns=[\"Id\", \"Species\"])\n\nX = X.values\ny = y.values","b7e42c84":"def print_performance(model, X_test, y_test, class_names):\n    preds = model.predict(X_test)\n\n    # accuracy_score = metrics.accuracy_score(y_test, preds)\n    # auc = metrics.auc(y_test, preds)\n    # average_precision_score = metrics.average_precision_score(y_test, preds)\n    # balanced_accuracy_score = metrics.balanced_accuracy_score(y_test, preds)\n    # brier_score_loss = metrics.brier_score_loss(y_test, preds)\n    classification_report = metrics.classification_report(y_test, preds)\n    # cohen_kappa_score = metrics.cohen_kappa_score(y_test, preds)\n    confusion_matrix = metrics.confusion_matrix(y_test, preds)\n    f1_score_ = metrics.f1_score(y_test, preds, average=\"weighted\")\n    # fbeta_score = metrics.fbeta_score(y_test, preds, average=\"weighted\")\n    # hamming_loss = metrics.hamming_loss(y_test, preds)\n    # hinge_loss = metrics.hinge_loss(y_test, preds)\n    # jaccard_similarity_score = metrics.jaccard_similarity_score(y_test, preds)\n    # log_loss = metrics.log_loss(y_test, preds)\n    # matthews_corrcoef = metrics.matthews_corrcoef(y_test, preds)\n    # precision_recall_curve = metrics.precision_recall_curve(y_test, preds)\n    # precision_recall_fscore_support = metrics.precision_recall_fscore_support(y_test, preds)\n    # precision_score = metrics.precision_score(y_test, preds, average=\"weighted\")\n    # recall_score = metrics.recall_score(y_test, preds, average=\"weighted\")\n    # roc_auc_score = metrics.roc_auc_score(y_test, preds, average=\"weighted\")\n    # roc_curve = metrics.roc_curve(y_test, preds)\n    # zero_one_loss = metrics.zero_one_loss(y_test, preds)\n    \n    print(\"-\"*55)\n    print(\"Performance\")\n    print(\"-\"*55)\n    # print(\"{} : {:.4f} \".format(\"Accuracy Score                  \", accuracy_score))\n    # print(\"{} : {:.4f} \".format(\"AUC                             \", auc))\n    # print(\"{} : {:.4f} \".format(\"Average Precision Score         \", average_precision_score))\n    # print(\"{} : {:.4f} \".format(\"Balanced Accuracy Score         \", balanced_accuracy_score))\n    # print(\"{} : {:.4f} \".format(\"Brier Score Loss                \", brier_score_loss))\n#     print(\"{} : {:.4f} \".format(\"Classification Report           \", classification_report))\n    # print(\"{} : {:.4f} \".format(\"Cohen Kappa Score               \", cohen_kappa_score))\n#     print(\"{} : {:.4f} \".format(\"Confusion Matrix                \", confusion_matrix))\n    print(\"{} : {:.4f} \".format(\"F1 Score                        \", f1_score_))\n    # print(\"{} : {:.4f} \".format(\"Fbeta Score                     \", fbeta_score))\n    # print(\"{} : {:.4f} \".format(\"Hamming Loss                    \", hamming_loss))\n    # print(\"{} : {:.4f} \".format(\"Hinge Loss                      \", hinge_loss))\n    # print(\"{} : {:.4f} \".format(\"Jaccard Similarity Score        \", jaccard_similarity_score))\n    # print(\"{} : {:.4f} \".format(\"Log Loss                        \", log_loss))\n    # print(\"{} : {:.4f} \".format(\"Matthews Corrcoef               \", matthews_corrcoef))\n    # print(\"{} : {:.4f} \".format(\"Precision Recall Curve          \", precision_recall_curve))\n    # print(\"{} : {:.4f} \".format(\"Precision Recall Fscore Support \", precision_recall_fscore_support))\n    # print(\"{} : {:.4f} \".format(\"Precision Score                 \", precision_score))\n    # print(\"{} : {:.4f} \".format(\"Recall Score                    \", recall_score))\n    # print(\"{} : {:.4f} \".format(\"Roc Auc Score                   \", roc_auc_score))\n    # print(\"{} : {:.4f} \".format(\"Roc Curve                       \", roc_curve))\n    # print(\"{} : {:.4f} \".format(\"Zero One Loss                   \", zero_one_loss))\n    print(classification_report)\n    \n    print(\"-\"*55)\n    print(\"\\n\\n\")\n    \n\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.subplot(121)\n    plot_confusion_matrix(confusion_matrix, classes=class_names,\n                          title='Confusion matrix, without normalization')\n","21e5a87b":"def print_performance(model, X_test, y_test, class_names):\n    preds = model.predict(X_test)\n\n    # accuracy_score = metrics.accuracy_score(y_test, preds)\n    # auc = metrics.auc(y_test, preds)\n    # average_precision_score = metrics.average_precision_score(y_test, preds)\n    classification_report = metrics.classification_report(y_test, preds)\n    # cohen_kappa_score = metrics.cohen_kappa_score(y_test, preds)\n    confusion_matrix = metrics.confusion_matrix(y_test, preds)\n    f1_score_ = metrics.f1_score(y_test, preds, average=\"weighted\")\n    # precision_recall_curve = metrics.precision_recall_curve(y_test, preds)\n    # precision_score = metrics.precision_score(y_test, preds, average=\"weighted\")\n    # recall_score = metrics.recall_score(y_test, preds, average=\"weighted\")\n    # roc_auc_score = metrics.roc_auc_score(y_test, preds, average=\"weighted\")\n    # roc_curve = metrics.roc_curve(y_test, preds)\n    \n    print(\"-\"*55)\n    print(\"Performance\")\n    print(\"-\"*55)\n    # print(\"{} : {:.4f} \".format(\"Accuracy Score                  \", accuracy_score))\n    # print(\"{} : {:.4f} \".format(\"AUC                             \", auc))\n    # print(\"{} : {:.4f} \".format(\"Average Precision Score         \", average_precision_score))\n#     print(\"{} : {:.4f} \".format(\"Classification Report           \", classification_report))\n#     print(\"{} : {:.4f} \".format(\"Confusion Matrix                \", confusion_matrix))\n    print(\"{} : {:.4f} \".format(\"F1 Score                        \", f1_score_))\n    # print(\"{} : {:.4f} \".format(\"Precision Recall Curve          \", precision_recall_curve))\n    # print(\"{} : {:.4f} \".format(\"Precision Score                 \", precision_score))\n    # print(\"{} : {:.4f} \".format(\"Recall Score                    \", recall_score))\n    # print(\"{} : {:.4f} \".format(\"Roc Auc Score                   \", roc_auc_score))\n    # print(\"{} : {:.4f} \".format(\"Roc Curve                       \", roc_curve))\n    print(classification_report)\n    \n    print(\"-\"*55)\n    print(\"\\n\\n\")\n    \n\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.subplot(121)\n    plot_confusion_matrix(confusion_matrix, classes=class_names, title='Confusion matrix, without normalization')\n\n    # Plot normalized confusion matrix\n    plt.subplot(122)\n    plot_confusion_matrix(confusion_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix')\n\n    plt.show()\n    \ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n    \ndef print_performance_grid(clf):\n    # print(\"*\"*100)\n    # print(\"{}{}{}\".format(\"*\"*40,\"Performance\", \"*\"*40))\n    print(\"{}\".format(\"Performance\"))\n    print(\"*\"*100)\n    print(\"Score            : {}\".format(clf.score(X, y)))\n    print(\"Best Estimator   : {}\".format(clf.best_estimator_))\n    print(\"Best Score       : {}\".format(clf.best_score_))\n    print(\"Best Params      : {}\".format(clf.best_params_))\n    print(\"Best Index       : {}\".format(clf.best_index_))\n    # print(\"Scorer           : {}\".format(clf.scorer_))\n    print(\"Refit Time       : {}\".format(clf.refit_time_))\n    # print(\"CV Results       : {}\".format(clf.cv_results_))\n\n    params = clf.get_params()\n    best_estimator = clf.best_estimator_\n    cv_results = clf.cv_results_\n    \n    return params, best_estimator, cv_results","58efa49c":"kernel = ('linear', 'poly', 'rbf', 'sigmoid', 'precomputed')\ndegree = np.arange(1, 10, 1)\nC = np.array([np.arange(0.01, 0.1, 0.01), np.arange(0.1, 1, 0.1), np.arange(1, 10, 1)]).flatten()\ngamma = np.array([np.arange(0.01, 0.1, 0.01), np.arange(0.1, 1, 0.1), np.arange(1, 10, 1)]).flatten()\n\n\nparam_grid = {\n    'kernel': ('linear', 'rbf'), \n    'C': C,\n    'gamma': gamma\n}\n\nestimator = svm.SVC(class_weight='balanced')\n\ncv = 3\nverbose = 0\n\n\ngrid_clf = GridSearchCV(estimator=estimator,param_grid=param_grid, n_jobs=-1, cv=cv, verbose=verbose)\n\ngrid_clf.fit(X, y)","a51b3f32":"params, best_estimator, cv_results = print_performance_grid(grid_clf)","dd9ab508":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n\nmodel = svm.SVC(kernel=\"rbf\", C=0.4, gamma=2.0, class_weight='balanced')\n\nprint(\"Cross Val Score            : {}\".format(cross_val_score(estimator, X, y, cv=5)))\n\nmodel.fit(X_train, y_train)\n\nprint(\"Score (training data only) : {}\".format(model.score(X_train, y_train)))\n\ny_pred = model.predict(X_test)\nprint(\"F-1 Score                  : {}\".format(f1_score(y_test, y_pred, average='weighted')))\n      ","f3e9c88b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nprint(\"SVM\")\nmodel = model\nmodel.fit(X_train, y_train)\nprint_performance(model, X_test, y_test, class_names)","3e2019ed":"![](https:\/\/www.iris-cayeux.com\/3770-large_default\/the-flowers-are-blue-violet-and-the-plant-develops-abundant-bright-green-foliage-which-arches-down.jpg)","395e0c13":"# 6. Model Performance Evaluation Function","2193c319":"# 7. Model Training\n## 7.1. Grid search for best estimator and parameters selection for linear and radial kernel","18296e21":"# 4. Visualization","4fc7be34":"## 4.1. Preprocess Data for Visualization","cd31d1ed":"## 7.2.Trainning and Evaluation with Best Model and Parameters\n\nSVM with radial kernel, C=0.4, gamma=2.0 has shown much better result","3ed3b755":"# 5. Preprocessing","61b47d77":"# 1. Import","78003a71":"## 6.0. Classification Performance All Metrics (hidden)","877f2441":"## 4.5. Correleation of Features using Heatmap ","0a063d0e":"# 3. Read Data","c80bcf7f":"## 4.4. Cluster map for feature correleation and clustering\n### Search for feature correlation and hierarchical relationship among features","43a5e019":"# 8. Performance Visualization\nPlot of difference between actual value and predicted value without scaling","016ddf27":"## 4.2. Count Species in Dataset","b33f3366":"## 4.3. Linear Relationship Among Features","69aad1ad":"# 2. Functions"}}