{"cell_type":{"c69ea035":"code","9c107ed0":"code","1ac5d75a":"code","c8511c98":"code","e4791e2c":"code","9b9d91b9":"code","acb3cd20":"code","7beb1532":"code","2c4ede1e":"code","98d6fbf3":"code","e31339ce":"code","3307585f":"code","d06bb860":"code","8e0dba37":"code","fb9bef1c":"code","7cf9a3bb":"code","c8dc383e":"code","163a8841":"code","a88e297c":"code","79458622":"code","7a3cf06b":"code","c7f2201d":"code","c9038620":"code","86d70925":"code","8eb2baa0":"code","4b6508b5":"code","3a31f7be":"code","9b33414b":"code","6aa41024":"code","c9603d6c":"code","5a7ae0a6":"code","2e512e9a":"code","85bcf380":"markdown","5305e37c":"markdown","6d067fe5":"markdown","275973f0":"markdown","4436731b":"markdown","8910c017":"markdown","bafbfb39":"markdown"},"source":{"c69ea035":"from PIL import Image, ImageDraw, ImageFont\nfrom os import listdir\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data","9c107ed0":"fontsize = 50\n\nfont = ImageFont.truetype('..\/input\/font-data\/NotoSansCJKjp-Regular.otf', fontsize, encoding='utf-8')","1ac5d75a":"df_train = pd.read_csv('..\/input\/kuzushiji-recognition\/train.csv')\nunicode_map = {codepoint: char for codepoint, char in pd.read_csv('..\/input\/kuzushiji-recognition\/unicode_translation.csv').values}\nunicode_count = {codepoint: 0 for codepoint, _ in pd.read_csv('..\/input\/kuzushiji-recognition\/unicode_translation.csv').values}\nbox_hw_count = unicode_count.copy()\nbox_categorize = unicode_count.copy()","c8511c98":"# make label for prediction.\nunicode_label = {count:codeprint for count,(codeprint,_) in enumerate(unicode_map.items())}","e4791e2c":"# This function takes in a filename of an image, and the labels in the string format given in train.csv, and returns an image containing the bounding boxes and characters annotated\ndef visualize_training_data(image_fn, labels):\n    # Convert annotation string to array\n    labels = np.array(labels.split(' ')).reshape(-1, 5)\n    \n    # Read image\n    imsource = Image.open(image_fn).convert('RGBA')\n    bbox_canvas = Image.new('RGBA', imsource.size)\n    char_canvas = Image.new('RGBA', imsource.size)\n    bbox_draw = ImageDraw.Draw(bbox_canvas) # Separate canvases for boxes and chars so a box doesn't cut off a character\n    char_draw = ImageDraw.Draw(char_canvas)\n\n    for codepoint, x, y, w, h in labels:\n        x, y, w, h = int(x), int(y), int(w), int(h)\n        char = unicode_map[codepoint] # Convert codepoint to actual unicode character\n\n        # Draw bounding box around character, and unicode character next to it\n        bbox_draw.rectangle((x, y, x+w, y+h), fill=(255, 255, 255, 0), outline=(255, 0, 0, 255))\n        char_draw.text((x + w + fontsize\/4, y + h\/2 - fontsize), char, fill=(0, 0, 255, 255), font=font)\n\n    imsource = Image.alpha_composite(Image.alpha_composite(imsource, bbox_canvas), char_canvas)\n    imsource = imsource.convert(\"RGB\") # Remove alpha for saving in jpg format.\n    return np.asarray(imsource)","9b9d91b9":"np.random.seed(1337)\n\nfor i in range(2):\n    img, labels = df_train.values[np.random.randint(len(df_train))]\n    viz = visualize_training_data('..\/input\/kuzushiji-recognition\/train_images\/{}.jpg'.format(img), labels)\n    \n    plt.figure(figsize=(15, 15))\n    plt.title(img)\n    plt.imshow(viz, interpolation='lanczos')\n    plt.show()","acb3cd20":"for i in range(len(df_train)):\n    img, labels = df_train.values[i]\n    if type(labels) == float:\n        continue\n    # Convert annotation string to array\n    labels = np.array(labels.split(' ')).reshape(-1, 5)\n    \n    for codepoint, x, y, w, h in labels:\n        unicode_count[codepoint] += 1","7beb1532":"unicode_count_df = pd.io.json.json_normalize(unicode_count)\nunicode_count_dict ={\n    \"Unicode\": unicode_count_df.columns.tolist(),\n    \"char\":list(unicode_map.values()),\n    \"count\": list(unicode_count_df.values[0])\n}\nunicode_count_df = pd.DataFrame(unicode_count_dict)","2c4ede1e":"characters_sorted_by_count = unicode_count_df.query('count > 0').sort_values('count', ascending=False)\ncharacters_sorted_by_count","98d6fbf3":"characters_categorize = pd.DataFrame(\n    {\n        'number of appearances':['0','1~10','11~50','51~100','101~500','501~1000','1001~5,000','5,001~10,000','10,001~','1~','0~'],\n        'count':[len(unicode_count_df.query('count==0')),\n                 len(unicode_count_df.query('1<=count<=10')),\n                 len(unicode_count_df.query('11<=count<=50')),\n                len(unicode_count_df.query('51<=count<=100')),\n                len(unicode_count_df.query('101<=count<=500')),\n                len(unicode_count_df.query('501<=count<=1000')),\n                len(unicode_count_df.query('1001<=count<=5000')),\n                len(unicode_count_df.query('5001<=count<=10000')),\n                len(unicode_count_df.query('10001<=count')),\n                len(unicode_count_df.query('1<=count')),\n                len(unicode_count_df),]\n    }\n)","e31339ce":"characters_categorize","3307585f":"#  character list\nprint(unicode_count_df.query('count==0')[\"char\"].tolist())","d06bb860":"print(unicode_count_df.query('1<=count<=10')[\"char\"].tolist())","8e0dba37":"print(unicode_count_df.query('11<=count<=50')[\"char\"].tolist())","fb9bef1c":"print(unicode_count_df.query('51<=count<=100')[\"char\"].tolist())","7cf9a3bb":"print(unicode_count_df.query('101<=count<=500')[\"char\"].tolist())","c8dc383e":"print(unicode_count_df.query('501<=count<=1000')[\"char\"].tolist())","163a8841":"print(unicode_count_df.query('1001<=count<=5000')[\"char\"].tolist())","a88e297c":"print(unicode_count_df.query('5001<=count<=10000')[\"char\"].tolist())","79458622":"print(unicode_count_df.query('10001<=count')[\"char\"].tolist())","7a3cf06b":"for i in range(len(df_train)):\n    img, labels = df_train.values[i]\n    if type(labels) == float:\n        continue\n    # Convert annotation string to array\n    labels = np.array(labels.split(' ')).reshape(-1, 5)\n    \n    for codepoint, x, y, w, h in labels:\n        if h < w:\n            box_hw_count[codepoint] += 1","c7f2201d":"box_info_dict = unicode_count_dict.copy()\nbox_info_dict[\"h<w\"] = [box_hw_count[codeprint] for codeprint in unicode_count_dict[\"Unicode\"]]\n\nbox_info = pd.DataFrame(box_info_dict)\n\nbox_info","c9038620":"box_rate =  box_info['h<w'] \/ box_info['count']\nbox_info = pd.concat([box_info,box_rate],axis=1)\nbox_info.columns = ['Unicode','char','count','h<w','rate']\nbox_info","86d70925":"for i in range(len(box_info)):\n    if box_info.iat[i,4] >= 0.90:\n        box_categorize[box_info.iat[i,0]] = 1\n    elif box_info.iat[i,4] <= 0.10:\n        box_categorize[box_info.iat[i,0]] = 3\n    elif 0.10 < box_info.iat[i,4] < 0.90:\n        box_categorize[box_info.iat[i,0]] = 2\n    else :\n        box_categorize[box_info.iat[i,0]] = 0\n    \nbox_categorize_df = pd.DataFrame({'categorize':list(box_categorize.values())})\nbox_info = pd.concat([box_info,box_categorize_df],axis=1)\n\nbox_info","8eb2baa0":"box_info_restricted = box_info.query('count>100')","4b6508b5":"box_categorize_distribution = pd.DataFrame({\n    'category':[0,1,2,3],\n    'count':[\n        len(box_info.query('categorize == 0')),\n        len(box_info.query('categorize == 1')),\n        len(box_info.query('categorize == 2')),\n        len(box_info.query('categorize == 3')),\n    ]\n})","3a31f7be":"box_categorize_distribution","9b33414b":"box_categorize_distribution_ristricted = pd.DataFrame({\n    'category':[0,1,2,3,4],\n    'count':[\n        len(box_info_restricted.query('categorize == 0')),\n        len(box_info_restricted.query('categorize == 1')),\n        len(box_info_restricted.query('categorize == 2')),\n        len(box_info_restricted.query('categorize == 3')),\n        len(box_info_restricted.query('categorize == 4')),\n    ]\n})","6aa41024":"box_categorize_distribution_ristricted","c9603d6c":"box_info_restricted.query('categorize == 1')","5a7ae0a6":"box_info_restricted.query('categorize == 2')","2e512e9a":"box_info_restricted.query('categorize == 3')","85bcf380":"## Feature Engineering","5305e37c":"### 2. bounding box  information\nAs bounding box information, I will categorize by boxes's shape.","6d067fe5":"## Visualising the training data","275973f0":"To display the full range of Japanese characters,I use Noto Sans, an open source font by Google which can display very almost all the characters used within this competition.\nThis is the url \"https:\/\/www.google.com\/get\/noto\/#sans-jpan\".","4436731b":"I will categorize with boundingbox form.\ncategory 0 means NaN, 1 means h<w rate is more 99%, 2 means h<w rate is\u30001~99% , 3 means  h<w  rate is less than 1%.","8910c017":"### 1. character  information\nTo know about characters, I will serch how many times the character is appeared,and number of character types.","bafbfb39":"Next, I will restrict characters by count."}}