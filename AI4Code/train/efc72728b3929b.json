{"cell_type":{"5060e5e1":"code","59d0313c":"code","1caabfe5":"code","e29edd94":"code","30e828a7":"code","84473261":"code","4df6d10b":"code","6090b4ae":"code","0d744ff0":"code","1074b77c":"markdown"},"source":{"5060e5e1":"%%bash\npip install 'kaggle-environments>=0.1.6'","59d0313c":"%%writefile submission.py\n\nimport numpy as np\nimport pandas as pd\nimport random\n\nT = np.zeros((3, 3, 3))\n\nself_actions = np.full(1001, -1, dtype=int)\noppo_actions = np.full(1001, -1, dtype=int)\n\nobserve_until = 600\n\ndef observe_and_predict(observation, configuration):\n    \n    step = observation.step\n    global T, P\n    global self_actions, oppo_actions\n    global observe_until\n    \n    if step == 0:\n        self_act = np.random.randint(3)\n        self_actions[step] = self_act\n        return self_act\n    \n    self_1s_bef = self_actions[step - 1]\n    oppo_1s_bef = observation.lastOpponentAction\n    oppo_actions[step - 1] = oppo_1s_bef\n    \n    if 2 <= step < observe_until:\n        self_2s_bef = self_actions[step - 2]\n        oppo_2s_bef = oppo_actions[step - 2]\n        T[self_2s_bef][oppo_2s_bef][oppo_1s_bef] += 1\n\n    P = T \/ np.maximum(1, T.sum(axis=2)[..., None])    \n    p = P[self_1s_bef][oppo_1s_bef]\n    \n    if observe_until <= step and np.sum(p) == 1:\n        self_act = int((np.random.choice([0, 1, 2], p=p) + 1)) % 3\n    else:\n        self_act = np.random.randint(3)\n    \n    self_actions[step] = self_act\n    return self_act","1caabfe5":"%%writefile random_agent.py\nimport numpy as np\ndef random_agent(observation, configuration):\n    return np.random.randint(3)","e29edd94":"%%writefile copy_opponent.py\ndef copy_opponent_agent(observation, configuration):\n    if observation.step > 0:\n        return observation.lastOpponentAction\n    else:\n        return 0","30e828a7":"%%writefile win_last_opponent.py\nimport numpy as np\ndef win_last_opponent (observation, configuration):\n    if observation.step > 0:\n        opp_hand = observation.lastOpponentAction\n        return (opp_hand + 1) % 3\n    else:\n        return np.random.randint(3)","84473261":"from kaggle_environments import evaluate, make\nenv = make(\"rps\", configuration={\"episodeSteps\": 1000})","4df6d10b":"env.reset()\nenv.run([\"submission.py\", \"copy_opponent.py\"])\nenv.render(mode=\"ipython\", width=800, height=800)","6090b4ae":"env.reset()\nenv.run([\"submission.py\", \"win_last_opponent.py\"])\nenv.render(mode=\"ipython\", width=800, height=800)","0d744ff0":"env.reset()\nenv.run([\"submission.py\", \"random_agent.py\"])\nenv.render(mode=\"ipython\", width=800, height=800)","1074b77c":"## About\n\nThis agent randomly plays hands in for the first hundred steps and observes opponent's hands.  \nAfter that, it predicts a next opponent's hand using last **_self's_** and opponent's hand.\n  \nTransition Matrix is used for predicton. Thanks to: https:\/\/www.kaggle.com\/group16\/rps-opponent-transition-matrix"}}