{"cell_type":{"d92235f4":"code","5fde0129":"code","b6f68188":"code","0804d900":"code","60f694f9":"code","bc59504c":"code","ce61169e":"code","eb841d70":"code","e9d059e8":"code","9a960207":"code","7e09f4b2":"code","eee5ffd2":"code","f0251b6e":"code","5ca55df7":"code","7f1e35fd":"code","e63de6e0":"code","d4c228af":"code","14b9ecac":"markdown","60833882":"markdown","fe91b2af":"markdown","64034907":"markdown","076e3352":"markdown","0b84a8a8":"markdown","5f6384ca":"markdown"},"source":{"d92235f4":"!rm -r \/opt\/conda\/lib\/python3.6\/site-packages\/lightgbm\n!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM\n!apt-get install -y -qq libboost-all-dev","5fde0129":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","b6f68188":"!cd LightGBM\/python-package\/;python3 setup.py install --precompile\n!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","0804d900":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgbm\n\nimport gc\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","60f694f9":"dataset = pd.read_csv(\"\/kaggle\/input\/new-york-city-taxi-fare-prediction\/train.csv\", nrows = 25000000)\ndataset = dataset.dropna(how = 'any', axis = 'rows')","bc59504c":"def clean_df(df):\n    return df[(df.fare_amount > 2.5)  & (df.fare_amount <= 350) &\n          (df.passenger_count > 0) & (df.passenger_count <= 6)  &\n           ((df.pickup_longitude != 0) & (df.pickup_latitude != 0) & (df.dropoff_longitude != 0) & (df.dropoff_latitude != 0))]\n\ndataset = clean_df(dataset)\ndataset.describe()","ce61169e":"#Training on range of latitude and longitude based on test data\n\nBB = (-74.26, -72.98, 40.56, 41.70)\n\ndef select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n\ndataset = dataset[select_within_boundingbox(dataset, BB)]","eb841d70":"def add_datetime_info(dataset):\n    # Convert to datetime format\n    dataset['pickup_datetime'] = pd.to_datetime(dataset['pickup_datetime'],format=\"%Y-%m-%d %H:%M:%S UTC\")\n    \n    dataset['hour'] = dataset.pickup_datetime.dt.hour\n    dataset['day'] = dataset.pickup_datetime.dt.day\n    dataset['month'] = dataset.pickup_datetime.dt.month\n    dataset['year'] = dataset.pickup_datetime.dt.year\n    return dataset","e9d059e8":"def sphere_dist(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon):\n    # Define earth radius (km)\n    R_earth = 6371\n    \n    pickup_lat, pickup_lon, dropoff_lat, dropoff_lon = map(np.radians,\n                                                         [pickup_lat, pickup_lon, \n                                                          dropoff_lat, dropoff_lon])\n\n    # Compute distances along lat, lon dimensions\n    dlat = dropoff_lat - pickup_lat\n    dlon = dropoff_lon - pickup_lon\n    \n    # Compute haversine distance\n    a = np.sin(dlat\/2.0)**2 + np.cos(pickup_lat) * np.cos(dropoff_lat) * np.sin(dlon\/2.0)**2\n    return 2 * R_earth * np.arcsin(np.sqrt(a))\n\n\ndef sphere_dist_bear(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon):\n    #Define earth radius (km)\n    R_earth = 6371\n    \n    pickup_lat, pickup_lon, dropoff_lat, dropoff_lon = map(np.radians,\n                                                             [pickup_lat, pickup_lon, \n                                                              dropoff_lat, dropoff_lon])\n    #Compute distances along lat, lon dimensions\n    dlat = dropoff_lat - pickup_lat\n    dlon = pickup_lon - dropoff_lon\n    \n    #Compute bearing distance\n    a = np.arctan2(np.sin(dlon * np.cos(dropoff_lat)),np.cos(pickup_lat) * np.sin(dropoff_lat) - np.sin(pickup_lat) * np.cos(dropoff_lat) * np.cos(dlon))\n    return a\n\n\ndef add_airport_dist(dataset):\n    \"\"\"\n    Return minumum distance from pickup or dropoff coordinates to each airport.\n    JFK: John F. Kennedy International Airport\n    EWR: Newark Liberty International Airport\n    LGA: LaGuardia Airport\n    SOL: Statue of Liberty \n    NYC: Newyork Central\n    \"\"\"\n    jfk_coord = (40.639722, -73.778889)\n    ewr_coord = (40.6925, -74.168611)\n    lga_coord = (40.77725, -73.872611)\n    sol_coord = (40.6892,-74.0445) # Statue of Liberty\n    nyc_coord = (40.7141667,-74.0063889) \n    \n    \n    pickup_lat = dataset['pickup_latitude']\n    dropoff_lat = dataset['dropoff_latitude']\n    pickup_lon = dataset['pickup_longitude']\n    dropoff_lon = dataset['dropoff_longitude']\n    \n    pickup_jfk = sphere_dist(pickup_lat, pickup_lon, jfk_coord[0], jfk_coord[1]) \n    dropoff_jfk = sphere_dist(jfk_coord[0], jfk_coord[1], dropoff_lat, dropoff_lon) \n    pickup_ewr = sphere_dist(pickup_lat, pickup_lon, ewr_coord[0], ewr_coord[1])\n    dropoff_ewr = sphere_dist(ewr_coord[0], ewr_coord[1], dropoff_lat, dropoff_lon) \n    pickup_lga = sphere_dist(pickup_lat, pickup_lon, lga_coord[0], lga_coord[1]) \n    dropoff_lga = sphere_dist(lga_coord[0], lga_coord[1], dropoff_lat, dropoff_lon)\n    pickup_sol = sphere_dist(pickup_lat, pickup_lon, sol_coord[0], sol_coord[1]) \n    dropoff_sol = sphere_dist(sol_coord[0], sol_coord[1], dropoff_lat, dropoff_lon)\n    pickup_nyc = sphere_dist(pickup_lat, pickup_lon, nyc_coord[0], nyc_coord[1]) \n    dropoff_nyc = sphere_dist(nyc_coord[0], nyc_coord[1], dropoff_lat, dropoff_lon)\n    \n    \n    \n    dataset['jfk_dist'] = pickup_jfk + dropoff_jfk\n    dataset['ewr_dist'] = pickup_ewr + dropoff_ewr\n    dataset['lga_dist'] = pickup_lga + dropoff_lga\n    dataset['sol_dist'] = pickup_sol + dropoff_sol\n    dataset['nyc_dist'] = pickup_nyc + dropoff_nyc\n    \n    return dataset\n\ndef radian_conv(degree):\n    return  np.radians(degree)","9a960207":"dataset = add_datetime_info(dataset)\ndataset = add_airport_dist(dataset)\n                                  \ndataset['distance'] = sphere_dist(dataset['pickup_latitude'], dataset['pickup_longitude'], \n                                   dataset['dropoff_latitude'] , dataset['dropoff_longitude']) \n\ndataset['bearing'] = sphere_dist_bear(dataset['pickup_latitude'], dataset['pickup_longitude'], \n                                   dataset['dropoff_latitude'] , dataset['dropoff_longitude'])\n\ndataset['pickup_latitude'] = radian_conv(dataset['pickup_latitude'])\ndataset['pickup_longitude'] = radian_conv(dataset['pickup_longitude'])\ndataset['dropoff_latitude'] = radian_conv(dataset['dropoff_latitude'])\ndataset['dropoff_longitude'] = radian_conv(dataset['dropoff_longitude'])","7e09f4b2":"dataset.drop([\"pickup_datetime\", \"key\"], axis = 1, inplace = True)","eee5ffd2":"y = dataset['fare_amount']\ntrain = dataset.drop(columns=['fare_amount'])","f0251b6e":"x_train, x_test, y_train, y_test = train_test_split(train, y, random_state = 123, test_size=0.10)","5ca55df7":"del dataset\ndel train\ndel y\nimport gc\ngc.collect()","7f1e35fd":"params = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'nthread': 4,\n        'num_leaves': 31,\n        'learning_rate': 0.15,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 15,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,\n        'num_rounds':50000,\n        'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0\n        \n    }\n\ntrain_set = lgbm.Dataset(x_train, y_train, silent=False, categorical_feature=['year','month','day'])\nvalid_set = lgbm.Dataset(x_test, y_test, silent=False, categorical_feature=['year','month','day'])\ndel x_train, y_train, x_test, y_test\ngc.collect()\nmodel = lgbm.train(params, train_set = train_set, num_boost_round=10000, early_stopping_rounds=500, verbose_eval=500, valid_sets=valid_set)","e63de6e0":"test_df = pd.read_csv('\/kaggle\/input\/new-york-city-taxi-fare-prediction\/test.csv')\ntest_df = add_datetime_info(test_df)\ntest_df = add_airport_dist(test_df)\ntest_df['distance'] = sphere_dist(test_df['pickup_latitude'], test_df['pickup_longitude'], \n                                   test_df['dropoff_latitude'] , test_df['dropoff_longitude'])\n\ntest_df['bearing_distance'] = sphere_dist_bear(test_df['pickup_latitude'], test_df['pickup_longitude'], \n                                   test_df['dropoff_latitude'] , test_df['dropoff_longitude'])\n\ntest_df['pickup_latitude'] = radian_conv(test_df['pickup_latitude'])\ntest_df['pickup_longitude'] = radian_conv(test_df['pickup_longitude'])\ntest_df['dropoff_latitude'] = radian_conv(test_df['dropoff_latitude'])\ntest_df['dropoff_longitude'] = radian_conv(test_df['dropoff_longitude'])\n                                                                    \ntest_key = test_df['key']\ntest_df = test_df.drop(columns=['key', 'pickup_datetime'])\n\n#Predict from test set\nprediction = model.predict(test_df, num_iteration = model.best_iteration)      \nsubmission = pd.DataFrame({\n        \"key\": test_key,\n        \"fare_amount\": prediction\n})\nsubmission.to_csv(\"submission.csv\", index = False)","d4c228af":"ax = lgbm.plot_importance(model, figsize=(10,10))\nplt.show()","14b9ecac":"The below ideas of adding airport distances and other important locations is taken from other notebooks.\n\nCalculates the different types of distances between pickup and dropoff cordinates. Also calculating the distances from major locations like airport have proven to very effective in predicting the prices.","60833882":"Removing the outliers","fe91b2af":"Importing the dataset","64034907":"Installing the necessary libraries","076e3352":"Based on the test data, we are removing some rows that are not useful for training since, the co-ordinates not present in the test data won't serve any purpose to the traning model.","0b84a8a8":"Takes the pickup time column as a input and creates different columns for hour, day, month, year.","5f6384ca":"Installing the gpu version of lgbm"}}