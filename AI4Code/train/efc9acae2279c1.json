{"cell_type":{"a86bb7c3":"code","da035b16":"code","c84e548e":"code","7e0b2c56":"code","c9aea82f":"code","fc4a5bd1":"code","131794a1":"code","9ef1669b":"code","9b302945":"code","f3828961":"code","f2f5f321":"code","2c618c8a":"code","d26c394b":"markdown","e05a36af":"markdown","98720cd8":"markdown","56a0a15d":"markdown","5d62d28d":"markdown","f2d8dc28":"markdown","e7b0e6eb":"markdown","622a1571":"markdown","8cd27ca9":"markdown","12b8fb42":"markdown","769e0d92":"markdown"},"source":{"a86bb7c3":"import pandas as pd\nimport numpy as np\n# Loading in Iowa housing data\nmain_file_path = '..\/input\/house-prices-advanced-regression-techniques\/train.csv' \n# this is the path to the Iowa data that you will use\niowa_data = pd.read_csv(main_file_path)\nprint('Setup Complete...')","da035b16":"# import what we need for scikit to set up our model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\niowa_target = iowa_data.SalePrice\niowa_predictors = iowa_data.drop(['SalePrice'], axis=1)\n\n# we will only use numeric predictors for this model\niowa_numeric_predictors = iowa_predictors.select_dtypes(exclude=['object'])\nprint(iowa_numeric_predictors.columns)\n","c84e548e":"X_train, X_test, y_train, y_test = train_test_split(iowa_numeric_predictors, \n                                                    iowa_target,\n                                                    train_size=0.7, \n                                                    test_size=0.3, \n                                                    random_state=0)\n\ndef score_dataset(X_train, X_test, y_train, y_test):\n    model = RandomForestRegressor()\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    return mean_absolute_error(y_test, preds)","7e0b2c56":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning) #so pandas doesn't spit out a warning everytime\ncols_with_missing = [col for col in X_train.columns \n                                 if X_train[col].isnull().any()]\nreduced_X_train = X_train.drop(cols_with_missing, axis=1)\nreduced_X_test  = X_test.drop(cols_with_missing, axis=1)\nprint(\"Mean Absolute Error from dropping columns with Missing Values:\")\nprint(score_dataset(reduced_X_train, reduced_X_test, y_train, y_test))","c9aea82f":"from sklearn.preprocessing import Imputer as Imputer\nmy_imputer = Imputer()\nimputed_X_train = my_imputer.fit_transform(X_train)\nimputed_X_test = my_imputer.transform(X_test)\nprint(\"Mean Absolute Error from Imputation:\")\nprint(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))","fc4a5bd1":"imputed_X_train_plus = X_train.copy()\nimputed_X_test_plus = X_test.copy()\n\ncols_with_missing = (col for col in X_train.columns\n                                 if X_train[col].isnull().any())\nfor col in cols_with_missing:\n    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull()\n    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()\n\n# Imputation\nmy_imputer = Imputer()\nimputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\nimputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n\nprint(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))","131794a1":"# Read the data\n# import pandas as pd #ALREADY IMPORTED ABOVE\n\ntrain_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\n# Drop houses where the target is missing\ntrain_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\ntarget = train_data.SalePrice\n\n# Since missing values isn't the focus of this tutorial, we use the simplest\n# possible approach, which drops these columns. \n# For more detail (and a better approach) to missing values, see\n# https:\/\/www.kaggle.com\/dansbecker\/handling-missing-values\ncols_with_missing = [col for col in train_data.columns \n                                 if train_data[col].isnull().any()]                                  \ncandidate_train_predictors = train_data.drop(['Id', 'SalePrice'] + cols_with_missing, axis=1)\ncandidate_test_predictors = test_data.drop(['Id'] + cols_with_missing, axis=1)","9ef1669b":"low_cardinality_cols = [cname for cname in candidate_train_predictors.columns if\n                       candidate_train_predictors[cname].nunique() < 10 and\n                       candidate_train_predictors[cname].dtype == 'object']\nnumeric_cols = [cname for cname in candidate_train_predictors.columns if \n                                candidate_train_predictors[cname].dtype in ['int64', 'float64']]\nmy_cols = low_cardinality_cols + numeric_cols\ntrain_predictors = candidate_train_predictors[my_cols]\ntest_predictors = candidate_train_predictors[my_cols]","9b302945":"train_predictors.dtypes.sample(10)","f3828961":"one_hot_encoded_training_predictors = pd.get_dummies(train_predictors)","f2f5f321":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef get_mae(X,y):\n    # we multiply by -1 in this instance in order to ouput a positve MAE score \n    # instead of a negative value returned by sklearn\n    return -1 * cross_val_score(RandomForestRegressor(50),\n                                X,y,\n                                scoring = 'neg_mean_absolute_error').mean()\n\npredictors_without_categoricals = train_predictors.select_dtypes(exclude=['object'])\n\nmae_without_categoricals = get_mae(predictors_without_categoricals, target)\n\nmae_one_hot_encoded = get_mae(one_hot_encoded_training_predictors, target)\n\nprint('Mean Absolute Error when Dropping Categoricals: ' + str(int(mae_without_categoricals)))\nprint('Mean Absolute Error with One-Hot Encoding: ' + str(int(mae_one_hot_encoded)))\n\n# print('MSE: ' + mean_squared_error(one_hot_encoded_training_predictors, target))","2c618c8a":"one_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\none_hot_encoded_test_predictors = pd.get_dummies(test_predictors)\nfinal_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n                                                                   \n                                                                   join='left',\n                                                                   \n                                                                   axis=1)","d26c394b":"Pandas assigns a data type (called a dtype) to each column or Series. Let's see a random sample of dtypes from our prediction data:","e05a36af":"Now for fun we will get the model score for when we use imputation with extra columns showing","98720cd8":"First we will need to split our data into training and testing sets, then we create a function to compare the quality of the different approaches we will take to get rid of our missing values.","56a0a15d":"# One-Hot Encoding\n**This MAE is better than our previous results, but we are still throwing out a bunch of data by only predicting our Sale price based on only our numeric data. To solve this and get more accurate results we will start over and implement One-Hot Encoding.**","5d62d28d":"Now we will get the MAE for our model that uses Imputation instead","f2d8dc28":"The align command makes sure the columns show up in the same order in both datasets (it uses column names to identify which columns line up in each dataset.) The argument join='left' specifies that we will do the equivalent of SQL's left join. That means, if there are ever columns that show up in one dataset and not the other, we will keep exactly the columns from our training data. The argument join='inner' would do what SQL databases call an inner join, keeping only the columns showing up in both datasets. That's also a sensible choice.","e7b0e6eb":"First we will train a model that simply drops any columns with missing values and get its MAE","622a1571":"Alternatively, we can drop these object columns and compare the MAE of the two methods to see which works best for our dataset:\n\n1. One-hot encoded categoricals as well as numeric predictors\n\n2. Numerical predictors, where we drop categoricals.\n\n","8cd27ca9":"**Object** indicates a column has text (there are other things it could be theoretically be, but that's unimportant for our purposes). It's most common to one-hot encode these \"object\" columns, since they can't be plugged directly into most models. Pandas offers a convenient function called **get_dummies** to get one-hot encodings. Call it like this:","12b8fb42":"# Applying to Multiple Files\nSo far, you've one-hot-encoded your training data. What about when you have multiple files (e.g. a test dataset, or some other data that you'd like to make predictions for)? Scikit-learn is sensitive to the ordering of columns, so if the training dataset and test datasets get misaligned, your results will be nonsense. This could happen if a categorical had a different number of values in the training data vs the test data.\n\n**Ensure the test data is encoded in the same manner as the training data with the align command:**","769e0d92":"**\"Cardinality\" means the number of unique values in a column.\nWe use it as our only way to select categorical columns here. This is convenient, though a little arbitrary.**"}}