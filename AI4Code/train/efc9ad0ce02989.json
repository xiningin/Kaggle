{"cell_type":{"1ed9d0ac":"code","688a7b42":"code","2f859552":"code","9fd68f8f":"code","e88a5987":"code","07dda7ef":"code","387d2b25":"code","97f0797a":"code","13a04165":"code","5e546179":"code","e5d6795d":"code","4ec6bb90":"code","d1c73f98":"code","4be2ae81":"code","8db9e723":"code","69bef144":"code","e6b4aa40":"markdown","857724d6":"markdown","6426232e":"markdown"},"source":{"1ed9d0ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","688a7b42":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-may-2021\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-may-2021\/test.csv\")\n#display(train_df.head(10))\n#display(test_df.head(10))\nprint(train_df.columns)\nprint(test_df.columns)","2f859552":"print(train_df.target.nunique())\nunique_values = {}\nmx = -1\nmn = 10000001\nfor feature in train_df.columns.to_list():\n    if feature != \"id\":\n        unique_values[\"feature\"] = train_df[feature].nunique()\n        #print(unique_values[\"feature\"])\n        mx = max(mx, (unique_values[\"feature\"]))\n        mn = min(mn, (unique_values[\"feature\"]))\nprint(mx, mn)","9fd68f8f":"\nunique_values = {}\nmx = -1\nmn = 10000001\nfor feature in test_df.columns.to_list():\n    if feature != \"id\":\n        unique_values[\"feature\"] = test_df[feature].nunique()\n        #print(unique_values[\"feature\"])\n        mx = max(mx, (unique_values[\"feature\"]))\n        mn = min(mn, (unique_values[\"feature\"]))\nprint(mx, mn)","e88a5987":"#test_df.isnull().sum()\n# okay, we dont;t have any null values","07dda7ef":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncor = train_df.corr()\n#f, ax = plt.subplots(figsize=(20, 20))\n#sns.heatmap(cor, vmax=.8, square=True, annot= True);","387d2b25":"le = LabelEncoder()\n\nX = train_df.drop([\"id\", \"target\"], axis = 1)\ny =le.fit_transform(train_df.target)\nprint(y[0:100])","97f0797a":"test_df_without_id = test_df.drop(\"id\", axis = 1)","13a04165":"\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\npca = PCA(n_components=47)\n# prepare transform on dataset\npca.fit(X)\n# apply transform to dataset\n\ntransformed = pca.transform(X)\nprint(transformed.shape)\n#test_df_without_id = pca.transform(test_df_without_id)\n\n","5e546179":"\nfrom sklearn.preprocessing import MinMaxScaler\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, test_size=0.2, stratify=y)\nprint(X_train.shape)\nprint(X_val.shape)","e5d6795d":"from sklearn.metrics import confusion_matrix, log_loss\n\nxg = XGBClassifier(n_estimators = 150, learning_rate = 0.1, random_state = 0)\nlgbm = LGBMClassifier(random_state=12, num_iterations = 60, learning_rate = 0.1\n                     )\ncbc = CatBoostClassifier(random_state= 12)\n#rc = RandomForestClassifier(max_features= 7, random_state= 0, n_estimators = 150)\n\"\"\"\nrc.fit(X_train, y_train)\ny_pred=rc.predict_proba(X_val)\nlost = log_loss(y_val, y_pred)\nprint(lost)\ncbc.fit(X_train, y_train)\ny_pred=cbc.predict_proba(X_val)\ncm = log_loss(y_val, y_pred)\nprint(cm)\nxg.fit(X_train, y_train)\ny_pred=xg.predict_proba(X_val)\ncm = log_loss(y_val, y_pred)\nprint(cm)\n\"\"\"\n\nlgbm.fit(X_train, y_train)\ny_pred=lgbm.predict_proba(X_val)\ncm = log_loss(y_val, y_pred)\nprint(cm)","4ec6bb90":"res = lgbm.predict_proba(test_df_without_id)\n","d1c73f98":"print(res[300:400])","4be2ae81":"sample_submission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-may-2021\/sample_submission.csv\")\nsample_submission.columns","8db9e723":"submission = pd.DataFrame({'id': sample_submission['id'],\n                           'Class_1': res[:, 0],\n                           'Class_2': res[:, 1],\n                           'Class_3': res[:, 2],\n                           'Class_4': res[:, 3],})","69bef144":"submission.to_csv('submission.csv', index=False)","e6b4aa40":"Null Values Check","857724d6":"Correlation Matrix","6426232e":"Splitting the data"}}