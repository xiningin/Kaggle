{"cell_type":{"8e2aacea":"code","a2cb5779":"code","8c048a39":"code","e2df7444":"code","56232f8b":"code","9881d1c5":"code","2c8a677c":"code","70aaa7bb":"code","c6a85d99":"code","7db6bcbc":"code","dbea204c":"code","78e1d475":"code","a2af37a1":"code","67863324":"code","bb81ed3f":"code","df99e04e":"code","2d3debbb":"code","88261908":"code","4dcd7895":"code","5b34b0b7":"code","5895f27c":"code","445fd23c":"code","775dcaff":"code","d0c05675":"code","ac8a7bc9":"code","9494f3d2":"code","fc411791":"code","7100376e":"code","1294a792":"code","1ed9633c":"code","80ef7348":"code","8543b7f8":"code","18cc841f":"code","22f89552":"code","3a8344ef":"code","ab5c3841":"code","49899396":"code","5f1aab66":"code","6986aa81":"code","a54bfed9":"code","3bf3f84a":"code","1242852c":"code","4ba4a956":"code","171ee1d1":"code","3d474546":"code","11ce8f2e":"code","2c7eb063":"code","b2b0977f":"code","b1aa91ff":"code","d9ed32b8":"code","ed284c12":"code","78301e0b":"code","e100e58e":"code","921cdb96":"code","8913470c":"code","c7f4abd8":"code","b2978aaa":"code","5bfd621b":"code","250f914e":"code","ea0a3229":"code","36a30e14":"code","f170a761":"code","79cb9aa5":"code","c7144279":"code","57a747ca":"code","1310ae3b":"code","e1a7d7de":"code","66ee58f8":"code","8c44bf03":"code","c54c6542":"code","6d64f44c":"code","0b951006":"code","6923a195":"code","2f235a89":"code","e636c1dd":"code","692e4bcc":"code","dd955d92":"code","459fe9f8":"code","6c054046":"code","d01d88b6":"code","cf930fb1":"code","cd950d47":"code","a92fac56":"code","d946c53e":"code","4f33fb33":"markdown","750da4b7":"markdown","2ff68c66":"markdown","c6236978":"markdown","bcf8d370":"markdown","2a83f56a":"markdown","fbe0ebe2":"markdown","8763d683":"markdown","ff4993c6":"markdown","80ffd20a":"markdown","69e04bd9":"markdown","8bdf9e9d":"markdown","99a9c4d6":"markdown","cbad4a2c":"markdown","3c9621df":"markdown","89c4f3aa":"markdown","8ec3046f":"markdown","93856c28":"markdown","2ab377ad":"markdown","e80c5531":"markdown","7a086030":"markdown","ef7fec69":"markdown","047b24c1":"markdown","25974c28":"markdown","2708c296":"markdown","ddd9c374":"markdown","9388c23d":"markdown","ba58cf70":"markdown","c53d9ade":"markdown","0e341725":"markdown","e43d9d65":"markdown","ed0deea5":"markdown","8adb4da7":"markdown","9849e4df":"markdown","68c7f4bd":"markdown","044956c3":"markdown","f2543cde":"markdown","80e50c6e":"markdown","5b2275e5":"markdown","e5846d09":"markdown","09338dfb":"markdown","8113baf1":"markdown","b53e6904":"markdown","2357af94":"markdown","d37be724":"markdown","678b577a":"markdown","8e3be69c":"markdown","c6c7291c":"markdown","afb3983c":"markdown","df48bb6e":"markdown","efaa7138":"markdown","cb1c4c4a":"markdown","473ac3c1":"markdown","d45700c3":"markdown","393906ea":"markdown","d246f29e":"markdown","207eb213":"markdown","057cd4aa":"markdown","bd2eb2fa":"markdown","9e8a39aa":"markdown","79896016":"markdown","32942496":"markdown","af653b8c":"markdown"},"source":{"8e2aacea":"!pip install bar_chart_race","a2cb5779":"#-----General------#\nimport numpy as np\nimport pandas as pd\nimport os\nimport sys\n\n#-----Plotting-----#\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport seaborn as sns\nimport bar_chart_race as bcr\nfrom pandas_profiling import ProfileReport\n\n#-----Utility-----#\nimport math\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport re\nimport gc","8c048a39":"LOOK_AT = 10\nBCR_DISPLAY = True","e2df7444":"%%time\n\ngames_list = []\nfor dirname, _, filenames in os.walk(\"..\/input\/1-million-games-from-chessgames\/games\"):\n    for filename in filenames:\n        try:\n            games_list.append(pd.read_csv(os.path.join(dirname, filename)).drop(\"Unnamed: 0\", axis=1))\n        except Exception as e:\n            print(filename, e)","56232f8b":"df = pd.concat(games_list).reset_index(drop=True)\ndf","9881d1c5":"gc.collect()","2c8a677c":"report = ProfileReport(df)\nreport","70aaa7bb":"gc.collect()","c6a85d99":"df = df.loc[np.count_nonzero(df.isnull(), axis=1) == 0]","7db6bcbc":"df = df.loc[df['Move Count'] != 0]","dbea204c":"df['PGN'] = df['PGN'].map(lambda s : re.sub(r'\\.(?! )', '. ', re.sub(r' +', ' ', str(s))))\ndf.head()['PGN']","78e1d475":"%%time\n\ninclude_list = []\nfor i in df.index:\n    if i%100000 == 0:\n        print(i)\n    tmp_ser = df.loc[i]\n    try:\n        tmp_x, tmp_y = float(tmp_ser['White Elo']), float(tmp_ser['Black Elo'])\n        include_list.append(i)\n    except:\n        pass","a2af37a1":"df = df.loc[include_list]","67863324":"for column in df.columns:\n    try:\n        df[column] = pd.to_numeric(df[column])\n    except:\n        df[column] = df[column].astype(\"string\")\n        \ndf.dtypes","bb81ed3f":"gc.collect()","df99e04e":"original_features = df.columns\nprint(original_features, \"\\n\")\nprint(f\"Number of Features: {len(df.columns)}\")","2d3debbb":"df['Updated Date'] = df['Date'].str.replace('?', '0', regex=False)\ndf['Year'] = df['Updated Date'].str[:4].astype(int)\ndf.head()","88261908":"unique_years = df['Year'].unique()\nprint(f\"First year recorded: {unique_years[0]}, Second year recorded: {unique_years[1]}, Difference: {unique_years[1] - unique_years[0]} years.\")\n\ndf = df.loc[df['Year'] != 1620]","4dcd7895":"openings = pd.read_csv(\"..\/input\/1-million-games-from-chessgames\/openings.csv\").drop(\"Unnamed: 0\", axis=1)\nopenings","5b34b0b7":"eco_df = openings.set_index(\"ECO\")\ndf['Opening Names'] = df['ECO'].map(eco_df['Opening Names'])\ndf['Opening Moves'] = df['ECO'].map(eco_df['Moves'])\ndf.head()","5895f27c":"df['Captures'] = df['PGN'].str.count(\"x\")\ndf['Promotions'] = df['PGN'].str.count(\"=\")\ndf['Checks'] = df['PGN'].str.count(\"\\+\")\ndf['Checkmate'] = df['PGN'].str.count(\"#\").astype(bool)\ndf.head()","445fd23c":"def extract_move(move_num, color=\"White\"):\n    \"\"\"Function which extracts specific move. Not very efficient function but is good enough to get the job done right now.\"\"\"\n    \n    if color.lower() != \"white\" and color.lower() != \"black\":\n        raise Exception(\"Pass in a correct color (White\/Black).\")\n        \n    split_index = 3*move_num - 1 if color.lower() == \"white\" else 3*move_num\n    move = [x[split_index-1]  if len(x) >= split_index else \"No Move\" for x in df['PGN'].str.split(' ', n=split_index).tolist()]\n    return move","775dcaff":"first_move = extract_move(1)\ndf['First Move'] = first_move\ndf.head()","d0c05675":"unique_first_moves = df['First Move'].unique()\nunique_first_moves","ac8a7bc9":"LETTERS = \"abcdefgh\"\nlegal_first_moves = [f\"{letter}3\" for letter in LETTERS] + [f\"{letter}4\" for letter in LETTERS] + [\"Na3\", \"Nc3\", \"Nf3\", \"Nh3\"]\nlegal_first_moves","9494f3d2":"for move in unique_first_moves:\n    if move not in legal_first_moves:\n        df = df.loc[df['First Move'] != move]\n\ndf.head()","fc411791":"report = ProfileReport(df.drop(original_features, axis=1))\nreport","7100376e":"year_ser = df.groupby('Year').size()\nfor year in year_ser.keys():\n    if year_ser.loc[year] <= 50:\n        df = df.loc[df['Year'] != year]\n        \ndf.head()","1294a792":"gc.collect()","1ed9633c":"fig = px.line(df.groupby('Year').size())\nfig.update_layout(title={'text': f\"Number of Chess Games Played Each Year\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, showlegend=False, yaxis_title=\"Count\")\nfig.show()","80ef7348":"all_years = np.sort(df['Year'].unique())\nyear_event_df = df.groupby(['Year', 'Event']).count()\n\nevents_list = []\nfor year in all_years:\n    events_list.append(len(year_event_df.loc[year]))\n    \nyear_event_df = pd.Series(data=events_list, index=all_years)    \nfig = px.line(year_event_df)\nfig.update_layout(title={'text': f\"Number of Events Hosted Each Year\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, showlegend=False, yaxis_title=\"Count\")\nfig.show()","8543b7f8":"# Note, I added this drop condition halfway through the data gathering process; they are most likely unnecessary given the current state of the data\ndropped_tours = ['corr', 'Match', 'Simul', 'Consultation game', '?', 'Unknown', 'Blindfold simul, 10b', 'Casual game', 'Blindfold simul, 8b']","18cc841f":"tour_df = pd.DataFrame(df.groupby('Event').size().drop(dropped_tours).sort_values(ascending=False), columns=[\"Games Played\"])\nfig = px.bar(tour_df[:LOOK_AT], y='Games Played', color='Games Played')\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Tournaments in Terms of Games Played\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}})\nfig.show()","22f89552":"long_tour_df = df.groupby('Event').nunique().drop(dropped_tours).sort_values(\"Year\", ascending=False).rename(columns={\"Year\": \"Years Played\"})\nfig = px.bar(long_tour_df[:LOOK_AT], y='Years Played', color='Years Played')\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Tournaments in Terms of Unique Years Hosted\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}})\nfig.show()","3a8344ef":"gc.collect()","ab5c3841":"white_p_df = df[['White Player', 'Year', 'Move Count', 'Result']].rename(columns={\"White Player\": \"Name\"})\nblack_p_df = df[['Black Player', 'Year', 'Move Count', 'Result']].rename(columns={\"Black Player\": \"Name\"})\nall_players_df = pd.concat((white_p_df, black_p_df)).reset_index(drop=True)","49899396":"bin_width = 50\nplayer_games = all_players_df.groupby('Name').size().to_numpy()\n\nnbins = 2*math.ceil((player_games.max() - player_games.min()) \/ (bin_width))\n\nfig = px.histogram(player_games, nbins=nbins)\nfig.update_layout(title={'text': f\"Distribution of Games the {len(player_games)} Unique Players Play\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"Number of Games\", yaxis_title=\"Count (log scale)\", showlegend=False)\nfig.update_yaxes(type=\"log\")\nfig.show()","5f1aab66":"player_games_df = pd.DataFrame(all_players_df.groupby('Name').size().sort_values(ascending=False), columns=[\"Count\"])\nfig = px.bar(player_games_df[:LOOK_AT], y=\"Count\", color=\"Count\")\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Players With Most Chess Games Played\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}})\nfig.show()","6986aa81":"all_players_df['Games Played'] = all_players_df['Name'].map(all_players_df.groupby('Name').size())\nall_players_df","a54bfed9":"player_year_df = all_players_df.groupby(['Name', 'Year']).size()\nplayer_name_list = all_players_df['Name'].unique()\nyears_list = []\nfor name in player_name_list:\n    years_list.append(len(player_year_df[name]))\n    \nyears_played_df = pd.DataFrame(years_list, index=player_name_list, columns=[\"Count\"]).sort_values(\"Count\", ascending=False).drop(\"NN\")\nyears_played_df","3bf3f84a":"fig = px.histogram(years_played_df)\nfig.update_layout(title={'text': f\"Distribution of Number of Years Each Player Plays\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, showlegend=False)\nfig.show()","1242852c":"fig = px.bar(years_played_df[:LOOK_AT], y=\"Count\", color=\"Count\")\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Players With Most Years Played\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","4ba4a956":"white_df = pd.DataFrame(df.loc[df['Result'] == 'White Wins'].groupby('White Player').size().sort_values(ascending=False), columns=['Count'])\nfig = px.bar(white_df[:LOOK_AT], y=\"Count\", color=\"Count\")\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Players With the Most Wins with White\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","171ee1d1":"black_df = pd.DataFrame(df.loc[df['Result'] == 'Black Wins'].groupby('Black Player').size().sort_values(ascending=False), columns=['Count'])\nfig = px.bar(black_df[:LOOK_AT], y=\"Count\", color=\"Count\")\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Players With the Most Wins with Black\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","3d474546":"draw_df = pd.DataFrame(all_players_df.loc[all_players_df['Result'] == 'Draw'].groupby('Name').size().sort_values(ascending=False), columns=['Count'])\nfig = px.bar(draw_df[:LOOK_AT], y=\"Count\", color=\"Count\")\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Players With the Most Draws\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","11ce8f2e":"results_comb_df = pd.concat([white_df, black_df, draw_df], axis=1)\nresults_comb_df.columns = ['White', 'Black', 'Draw']\nresults_comb_df","2c7eb063":"MIN_VALUE = 100\nPERC_SHOWN = 50","b2b0977f":"white_perc_df = (white_df.loc[white_df['Count'] >= MIN_VALUE]['Count'])\/(df.groupby('White Player').size())\nwhite_perc_df = pd.DataFrame(100*white_perc_df.dropna().sort_values(ascending=False).round(5), columns=['Percentage'])\nwhite_perc_df['Count'] = df.groupby('White Player').size()\ntmp_white_df = white_perc_df.loc[white_perc_df['Percentage'] >= PERC_SHOWN]\nfig = px.bar(tmp_white_df, y=\"Percentage\", color=\"Percentage\", hover_data=[\"Count\"])\nfig.update_layout(title={'text': f\"The {len(tmp_white_df)} Players with More Than a {PERC_SHOWN}% White Win Rate\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","b1aa91ff":"black_perc_df = (black_df.loc[black_df['Count'] >= MIN_VALUE]['Count'])\/(df.groupby('Black Player').size())\nblack_perc_df = pd.DataFrame(100*black_perc_df.dropna().sort_values(ascending=False).round(5), columns=['Percentage'])\nblack_perc_df['Count'] = df.groupby('Black Player').size()\ntmp_black_df = black_perc_df.loc[black_perc_df['Percentage'] >= PERC_SHOWN]\nfig = px.bar(tmp_black_df, y=\"Percentage\", color=\"Percentage\", hover_data=[\"Count\"])\nfig.update_layout(title={'text': f\"The {len(tmp_black_df)} Players with More Than a {PERC_SHOWN}% Black Win Rate\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","d9ed32b8":"MIN_GAMES_PLAYED = 500","ed284c12":"all_colors_df = pd.concat([white_df, black_df, draw_df], axis=1)\nall_colors_df.columns = [\"White Win\", \"Black Win\", \"Draw\"]\nall_colors_df['White Loss'] = df.loc[df['Result'] == 'Black Wins'].groupby('White Player').size()\nall_colors_df['Black Loss'] = df.loc[df['Result'] == 'White Wins'].groupby('Black Player').size()\nall_colors_df['Total Games'] = all_colors_df.sum(axis=1)\nall_colors_df.fillna(0, inplace=True)\nall_colors_df = all_colors_df.loc[all_colors_df['Total Games'] >= MIN_GAMES_PLAYED]\nall_colors_df","78301e0b":"all_colors_df['Score'] = all_colors_df['White Win'] + all_colors_df['Black Win'] - all_colors_df['White Loss'] - all_colors_df['Black Loss']\nall_colors_df.sort_values(\"Score\", ascending=False, inplace=True)\nfig = px.bar(all_colors_df[:LOOK_AT], y=\"Score\", color=\"Score\", hover_data=[\"White Win\", \"Black Win\", \"White Loss\", \"Black Loss\", \"Total Games\"])\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Players by Raw Score\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","e100e58e":"all_colors_df['Prop'] = all_colors_df['Score']\/all_colors_df['Total Games']\nall_colors_df.sort_values(\"Prop\", ascending=False, inplace=True)\nfig = px.bar(all_colors_df[:LOOK_AT], y=\"Prop\", color=\"Prop\", hover_data=[\"Score\"])\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Players by Proportion Score\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","921cdb96":"ratings_list = []\nfor dirname, _, filenames in os.walk(\"..\/input\/1-million-games-from-chessgames\/ratings\"):\n    for filename in filenames:\n        try:\n            tmp_df = pd.read_csv(os.path.join(dirname, filename))\n            tmp_df = tmp_df.set_index(\"Unnamed: 0\")\n            ratings_list.append(tmp_df)\n        except Exception as e:\n            print(filename, e)","8913470c":"%%time\n\nrating_df = pd.concat(ratings_list, axis=1).sort_index()\nrating_df.index.name = \"Date\"\nrating_df['Year'] = rating_df.index.str.slice(0, 4)\nrating_df.index = rating_df.index.astype(\"datetime64[ns]\")\n#rating_df = rating_df.interpolate('linear', axis=0, limit=1)\nrating_df = rating_df.groupby('Year').mean()\nrating_df","c7f4abd8":"rank_players_df = pd.DataFrame(rating_df.columns.values[np.argsort(-rating_df.values, axis=1)[:, :LOOK_AT]], \n                  index=rating_df.index)\nrank_players_df","b2978aaa":"for j in rank_players_df.columns:\n    tmp_rating_list = []\n    tmp_df = rank_players_df.loc[:, j]\n    for i in rank_players_df.index:\n        tmp_rating_list.append(rating_df.loc[i, tmp_df.loc[i]])\n        \n    rank_players_df[f\"Rating {j}\"] = tmp_rating_list\n    \nrank_players_df","5bfd621b":"MIN_GAMES = 10","250f914e":"df['White Elo'] = df['White Elo'].replace(-1, np.nan)\ndf['Black Elo'] = df['Black Elo'].replace(-1, np.nan)\ndf.head()","ea0a3229":"white_rating_df = df.groupby(['Year', 'White Player']).mean()['White Elo']\nblack_rating_df = df.groupby(['Year', 'Black Player']).mean()['Black Elo']\ngames_played_by_white = df.groupby(['Year', 'White Player']).size()\ngames_played_by_black = df.groupby(['Year', 'Black Player']).size()\n\nother_ratings_list = []\nfor year in df['Year'].unique():\n    if year >= 2006:\n        white_ser = white_rating_df.loc[year]\n        black_ser = black_rating_df.loc[year]\n        comb_ser = (white_ser + black_ser)\/2\n        comb_ser.rename(year, inplace=True)\n        other_ratings_list.append(comb_ser.loc[games_played_by_white.loc[year] + games_played_by_black.loc[year] >= MIN_GAMES])","36a30e14":"other_ratings_df = pd.concat(other_ratings_list, axis=1).T.sort_index()\nother_ratings_df.index.rename(\"Year\", inplace=True)\nother_ratings_df.drop([\"Liren Ding\", \"Vachier-Lagrave, Maxime\"], axis=1, inplace=True)\nother_ratings_df = other_ratings_df.loc[:, ~other_ratings_df.columns.str.contains(\"Computer\")]\nother_rankings_df = pd.DataFrame(other_ratings_df.columns.values[np.argsort(-other_ratings_df.values, axis=1)[:, :LOOK_AT]], \n                  index=other_ratings_df.index)\nother_rankings_df","f170a761":"for j in range(len(other_rankings_df.iloc[0])):\n    tmp_list = []\n    for i in other_rankings_df.index:\n        tmp_list.append(other_ratings_df.loc[i].loc[other_rankings_df.loc[i][j]])\n        \n    other_rankings_df[f'Rating {j}'] = tmp_list\n    \nother_rankings_df","79cb9aa5":"all_rank_players_df = rank_players_df.append(other_rankings_df)\nall_rank_players_df","c7144279":"fig = go.Figure()\nfor i in range(LOOK_AT):\n    poss = all_rank_players_df[f'Rating {i}'] != 0\n    fig.add_trace(go.Scatter(x=all_rank_players_df.index[poss], y=all_rank_players_df[f\"Rating {i}\"][poss], text=all_rank_players_df[i][poss], name=f\"#{i+1}\"))\n\n    \nfig.update_layout(hovermode='x unified', title={'text': f\"Top {LOOK_AT} Players Each Year by Rating\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","57a747ca":"%time highest_rating_df = rating_df.apply(pd.Series.nlargest, axis=1, n=1)\nfig = px.line(highest_rating_df)\nfig.update_layout(hovermode='x unified', title={'text': f\"Players with the Highest Rating up until 2006\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","1310ae3b":"comb_rating_list = []\n\nfor i in range(len(rating_df)):\n    comb_rating_list.append(rating_df.iloc[i][rank_players_df.iloc[i][:LOOK_AT]])\n    \ncomb_rating_df = pd.concat(comb_rating_list, axis=1).T.append(other_ratings_df).fillna(0)\ncomb_rating_df.index = comb_rating_df.index.astype(\"string\").astype(\"datetime64[ns]\")\ncomb_rating_df","e1a7d7de":"if BCR_DISPLAY:\n    bcr_elo = bcr.bar_chart_race(\n        df=comb_rating_df, \n        filename=\"ratings.mp4\",\n        n_bars=5,\n        interpolate_period=True,\n        steps_per_period=12, \n        title=\"Top 10 Chess Players by Rating\",\n        period_fmt='%b %-d, %Y'\n    )","66ee58f8":"gc.collect()","8c44bf03":"first_moves_list = []\nmoves_names_list = []\nfirst_move_df = df.groupby(['First Move', 'Year']).size()\nfor move in legal_first_moves:\n    first_moves_list.append(first_move_df[move])\n    moves_names_list.append(move)\n    \nmoves_df = pd.concat(first_moves_list, axis=1)\nmoves_df.columns = moves_names_list\n\nreindex_columns = moves_df.sum().sort_values(ascending=False).keys().tolist()\nmoves_df = moves_df.reindex(reindex_columns, axis=1)\nmoves_df","c54c6542":"fig = px.histogram(x=moves_df.columns, y=moves_df.sum())\nfig.update_layout(title={'text': f\"Total Times First Moves Have Been Played\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}})\nfig.show()","6d64f44c":"fig = px.line(moves_df)\nfig.update_layout(title={'text': f\"History of Chess' First Move\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, yaxis_title=\"Number of Games\")\nfig.show()","0b951006":"proportion_df = moves_df.divide(moves_df.sum(axis=1), axis=0)\nproportion_df.fillna(0, inplace=True)\nfig = px.line(proportion_df)\nfig.update_layout(title={'text': f\"Proportion of First Moves Per Year\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, yaxis_title=\"Proportion of Games\")\nfig.show()","6923a195":"moves_df.fillna(0, inplace=True)\nmoves_cum = moves_df.cumsum()[1:] # Removes year=1620 since it's kinda glitchy\nmoves_cum.index = moves_cum.index.astype(\"string\").astype(\"datetime64[ns]\")\nmoves_cum","2f235a89":"if BCR_DISPLAY:\n    bcr_moves = bcr.bar_chart_race(\n        df=moves_cum, \n        filename=\"moves.mp4\",\n        interpolate_period=True,\n        steps_per_period=12, \n        title=\"First Move Bar Chart Race\",\n        period_fmt='%b %-d, %Y'\n    )","e636c1dd":"opening_df = pd.DataFrame(df.groupby('Opening Names').size().sort_values(ascending=False), columns=[\"Count\"]).reset_index()\nfig = px.bar(opening_df[:LOOK_AT], x=\"Opening Names\", y=\"Count\", color=\"Count\")\nfig.update_layout(title={'text': \"Total Openings Played\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}})\nfig.show()","692e4bcc":"yearly_opening_df = df.groupby(['Opening Names', 'Year']).size()\nunique_openings = df['Opening Names'].unique()\nopenings_list = []\nused_openings = []\nfor opening in unique_openings:\n    try:\n        openings_list.append(yearly_opening_df[opening])\n        used_openings.append(opening)\n    except:\n        pass\n    \ntotal_opening_df = pd.concat(openings_list, axis=1)\ntotal_opening_df.columns = used_openings\ntotal_opening_df.fillna(0, inplace=True)\ntotal_opening_df","dd955d92":"opening_cum = total_opening_df.cumsum()[1:]\nopening_cum.index = opening_cum.index.astype(\"string\").astype(\"datetime64[ns]\")\nopening_cum","459fe9f8":"if BCR_DISPLAY:\n    bcr_opening = bcr.bar_chart_race(\n        df=opening_cum, \n        filename=\"opening.mp4\",\n        n_bars=10,\n        interpolate_period=True,\n        steps_per_period=12, \n        title=\"Top 10 Openings Bar Chart Race\",\n        period_fmt='%b %-d, %Y'\n    )","6c054046":"MIN_OPENINGS_PLAYED = 100","d01d88b6":"winrate_opening_df = df.groupby(['Result', 'Opening Names']).size()\nopening_total_games = df.groupby(['Opening Names']).size()\nwinrate_opening_df","cf930fb1":"white_opening_df = pd.DataFrame((winrate_opening_df.loc['White Wins']\/opening_total_games*100).loc[opening_total_games.values >= MIN_OPENINGS_PLAYED], \n                                columns=[\"White Percentage Won\"]).round(3)\nwhite_opening_df['Total Games'] = opening_total_games\nwhite_opening_df.sort_values(\"White Percentage Won\", ascending=False, inplace=True)\n\nfig = px.bar(white_opening_df[:LOOK_AT], y=\"White Percentage Won\", color=\"White Percentage Won\", hover_data=[\"Total Games\"])\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Openings by White Winning Percentage\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","cd950d47":"black_opening_df = pd.DataFrame((winrate_opening_df.loc['Black Wins']\/opening_total_games*100).loc[opening_total_games.values >= MIN_OPENINGS_PLAYED], \n                                columns=[\"Black Percentage Won\"]).round(3)\nblack_opening_df['Total Games'] = opening_total_games\nblack_opening_df.sort_values(\"Black Percentage Won\", ascending=False, inplace=True)\n\nfig = px.bar(black_opening_df[:LOOK_AT], y=\"Black Percentage Won\", color=\"Black Percentage Won\", hover_data=[\"Total Games\"])\nfig.update_layout(title={'text': f\"Top {LOOK_AT} Openings by Black Winning Percentage\", 'x': 0.5,\n                         'xanchor': 'center', 'font': {'size': 20}}, xaxis_title=\"\")\nfig.show()","a92fac56":"gc.collect()","d946c53e":"df.to_csv(\"million_chessgames.csv\")","4f33fb33":"# Section 2: Quick Exploratory Data Analysis","750da4b7":"<h2> 1. Visualization of number of chess games played by each player. <\/h2>\n\nI will be going more in-depth with many of the visualizations, distributions, and analyses done here (which are similar to the initial EDA done in Section 2).","2ff68c66":"# Section 1: Setup the Packages, Variables, and Data","c6236978":"# Exporting the new DataFrame\n\nFeel free to download and use this Dataframe instead of the raw data!","bcf8d370":"<h2> 1. Adding the updated date + year. <\/h2>\n\nI would like to add ```year``` as a feature to this dataset so, in the future, I can use it to extract time-series data using Pandas built-in functions like ```.agg()``` and ```.groupby()```. \n\nTo do this, first, I convert all of the ```?``` in the original dates to ```0```. Then, I extract the year of each game by considering the fact all years in this dataset are 4 characters long (e.g. 1962, 2018).","2a83f56a":"Using the dataset of ratings (from 1843 to 2005):","fbe0ebe2":"Vasily Symslov, an elite Russian grandmaster, holds the title for the player with the most active years, with a game recorded from him for 63 unique years (out of the 89 years he lived!) Some other top grandmasters are not far behind him.","8763d683":"<h2> Import Data <\/h2>","ff4993c6":"Proportion score is calculated by dividing a player's raw score by the total number of games they played.","80ffd20a":"<h2> 3. Fix PGN spacing. <\/h2>\n\nI want the PGNs to have consistent spacing so the same function can be used to analyze the notation. In the original data, some games don't have a space after each move number. I change that through a regular expression statement. <a href=\"https:\/\/stackoverflow.com\/a\/29507362\"> Link to original Stack Overflow post detailing the syntax used here. <\/a>","69e04bd9":"For an extremely quick glance at the data, I love using ```ProfileReport```. This is an interactive automatic EDA library which provides an overview of the dataset, as well as its variables, interactions, correlations, and missing values. Feel free to take a look at the report shown below.","8bdf9e9d":"# Section 8. The End?\n\nIf you've read down this far in the notebook, thank you so much. This notebook took quite a long time to make, and to be honest, I'm releasing with far less than I planned to have. I'll link the document I used to outline this notebook <a href=\"https:\/\/docs.google.com\/document\/d\/1nMDrfFCiMltSBMS7EiwOq715AFer8ywRrXJxwnmDSeU\/edit\">here<\/a>... feel free to use my ideas to further explore the data!\n\nI'm also going to plug <a href=\"https:\/\/github.com\/IronicNinja\/chessgames_scraping\">my github repo<\/a> here which I used for scraping the data for this notebook.\n\nFinally, if you liked my work, please leave a like, comment, and maybe drop a follow! I'd really appreciate it :)","99a9c4d6":"<h2> 1. First Chess Move Over Time. <\/h2>","cbad4a2c":"**Possibility**: Use ARIMA\/time-series model to predict rating distributions of players.","3c9621df":"<h2> 3. Which players have the most wins\/win the most? <\/h2>","89c4f3aa":"<h2> 4. Convert All Datatypes. <\/h2>\n\nAs best practice, I convert the object data to string data. I do this after dropping null values since convert a ```NaN``` to a string results in ```<NA>```, which is not considered as a null value when we use ```isnull()```.","8ec3046f":"<h3> Most Longstanding Tournaments <\/h3>\n\nThese tournaments have been hosted for so many years it's hard to count (ok, not really, but they are very historic tournaments).","93856c28":"Most black wins:","2ab377ad":"With the Black pieces:","e80c5531":"<h2> 4. Who is the \"best\" player? <\/h2>\n\nWho is the best player, not according to ELO?\n\nCondition: ```Minimum played games is 500.```\n\nRaw score is calculated by wins minus losses.","7a086030":"Using ratings from the chessgames dataset:\n\nCondition: ```Minimum games played that year is 10.```","ef7fec69":"<h3> Most Legendary Tournaments <\/h3>\n\nThese are the tournaments that have the most games played in them (and therefore the highest chance for hosting some historic games).","047b24c1":"<h2> 5. Adding ELO to the equation. <\/h2>\n\nWe don't add ELO as a feature in Section 3 since ELO is more relevant when analyzing the dataset on a player-to-player basis. Sporadic changes in ELO can occur for each chess games, which is hard to account for with a sparse dataset of chess ratings.","25974c28":"<h2> What features do we have now? <\/h2>","2708c296":"Condition: ```Opening must be played at least 100 times.```","ddd9c374":"<h2> Packages <\/h2>","9388c23d":"# Section 4: Adding Features\n\nI could only extract a select few features from https:\/\/www.chessgames.com\/. There are many other features that would be great to have, so let's add them here!","ba58cf70":"With the White pieces:","c53d9ade":"<h3> By percentage: <\/h3>\n\nCondition: ```More than 100 games won with one color.```","0e341725":"The following line of code collects all of the garbage. We will do this after each section to ensure the rest of the program has enough RAM to proceed.","e43d9d65":"<h2> 2. Visualization of number of unique years played by each player. <\/h2>\n\nNote that in this analysis we drop ```NN``` (No Name), which is not a real player.","ed0deea5":"Chess players clearly win more when they are white compared to when they are black!","8adb4da7":"<h2> 1. Years with most chess played. <\/h2>","9849e4df":"# Section 6: What Players Do We Have in the Dataset?\n\nThe direction of a chess game is largely dependent on the players that are playing. Thus, it's important to know the distribution of players in the dataset.","68c7f4bd":"<h2> 2. Adding opening names + opening moves. <\/h2>\n\nI would like to convert the openings from ECO into more common opening names like the Queen's Gambit or King's Indian Attack so that those are not familiar with ECO (I certainly am not) can understand the data. I also add the opening moves of each opening, which could potentially be useful.\n\nI scraped the ```ECO -> Name -> Move``` relationship from https:\/\/www.chessgames.com\/chessecohelp.html using a Python script. All that is left after that is to use the ```.map``` Series method, which is an efficient, vectorized implementation of appending using a dictionary.","044956c3":"# Section 5: Start with the Setting","f2543cde":"<h2> 1. Drop any row with missing values. <\/h2>\n\nI do this by only keeping the rows where the DataFrame has more than one null value.","80e50c6e":"First moves as a proportion to other first moves that year:","5b2275e5":"<h1> Using Data to Understand Chess (with expert games) <\/h1>\n\nIn this notebook, I utilize data taken from <a href=\"https:\/\/www.kaggle.com\/ironicninja\/1-million-games-from-chessgames\">this dataset<\/a> to better understand the game of chess.\n\n<h2> Table of Contents <\/h2>\n<ol style=\"font-size: 16px\">\n    <li><a href=\"https:\/\/www.kaggle.com\/ironicninja\/using-data-to-understand-chess-with-expert-games#Section-1:-Setup-the-Packages,-Variables,-and-Data\">Setup the Packages, Variables, and Data<\/a><\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/ironicninja\/using-data-to-understand-chess-with-expert-games#Section-2:-Quick-Exploratory-Data-Analysis\">Quick Exploratory Data Analysis<\/a><\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/ironicninja\/using-data-to-understand-chess-with-expert-games#Section-3:-Data-Preprocessing\">Data Preprocessing<\/a><\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/ironicninja\/using-data-to-understand-chess-with-expert-games#Section-4:-Adding-Features\">Adding Features<\/a><\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/ironicninja\/using-data-to-understand-chess-with-expert-games\/data#Section-5:-Start-with-the-Setting\">Start with the Setting<\/a><\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/ironicninja\/using-data-to-understand-chess-with-expert-games\/data#Section-6:-What-Players-Do-We-Have-in-the-Dataset?\">What Players Do We Have in the Dataset<\/a><\/li>\n    <li><a href=\"https:\/\/www.kaggle.com\/ironicninja\/using-data-to-understand-chess-with-expert-games\/data#Section-7.-Opening-Analysis\">Opening Analysis<\/a><\/li>\n        <li><a href=\"https:\/\/www.kaggle.com\/ironicninja\/using-data-to-understand-chess-with-expert-games\/data#Section-8.-The-End?\">The End?<\/a><\/li>\n<\/ol>","e5846d09":"<h2> 2. The most popular tournaments every year. <\/h2>\n\nThere are some big name tournaments with some big name players that are held every year; Linares, Wijk Aan Zee (Tata Steel), London, etc. Let's take a look at them! Before we do though, let's drop the most popular events in this dataset which aren't actual tournaments.","09338dfb":"From this report, we can see that there are some missing cells which we need to account for in the next section, Data Preprocessing.","8113baf1":"<h3> By total wins:","b53e6904":"Games played:","2357af94":"<h2> 2. Drop any row which has a move count of zero. <\/h2>\n\nThis is pretty simple; only include indices where the Move Count isn't zero.","d37be724":"# Section 7. Opening Analysis","678b577a":"<h2> 3. Adding number of captures, promotions, checks, and checkmates. <\/h2>\n\nThe nice thing about doing this is that the characters ```x```, ```=```, ```+```, and ```#``` appear in the PGN only to symbolize captures, promotions, and checks, and checkmates, respectively. Thereofre, I will use the Series ```.str``` method for a quick vectorized counting.","8e3be69c":"<h2> 2. Openings Over Time. <\/h2>","c6c7291c":"What on earth are moves like d4# and Kb7? I have no idea, so let's just remove that data.","afb3983c":"# Section 3: Data Preprocessing\n\nBefore I continue with my analysis, I need to ensure that the data is clean and consistent. Doing so will minimize the number of bugs I encounter later in the notebook, which will in turn save me a tremendous amount of time debugging.","df48bb6e":"All of these players are elite and masters at the art of winning.","efaa7138":"<h2> 4. Adding First Moves + Removing Weird Games. <\/h2>\n\nYou'll see what I mean by weird games.","cb1c4c4a":"Most white wins:","473ac3c1":"# Section 4.5: Re-run the EDA With Our New Features","d45700c3":"<h2> Global Variables <\/h2>","393906ea":"Total number over time:","d246f29e":"Distribution of first moves:","207eb213":"Events hosted:","057cd4aa":"There are some games that don't have a recorded ECO, which means that those games also don't have an opening name or opening moves. Because there are so few games that have unrecorded ECO though, I opt not to fill in the opening names manually.\n\nThe last thing we need to do before working with the data is removing extraneous years with a low number of chess games (e.g. those that are played on \"Year 0\"). I'll drop any year with less than 50 chess games played.","bd2eb2fa":"Distribution:","9e8a39aa":"<h2> 3. Best Openings by Win Rate. <\/h2>","79896016":"<h2> 1.5. Remove Games from the Year 1620. <\/h2>\n\nThere is a large gap between the earliest year recorded with a chess game, 1620, and the next year recorded with a chess game, 1834. Therefore, it seems reasonable to remove all games played in the year 1620 in this analysis.","32942496":"By most games played:","af653b8c":"Draw:"}}