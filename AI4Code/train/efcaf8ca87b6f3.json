{"cell_type":{"7f32879a":"code","a0aeceb6":"code","62d27f3b":"code","5ece4582":"code","dda913a7":"code","542e5581":"code","4b767e46":"code","7384b0bd":"code","f99cd003":"code","fc28e538":"code","8dcad408":"code","4770b55e":"code","143ad177":"code","ba064aa3":"code","3ee32a3f":"code","216b1122":"code","eb4c2ad9":"code","652f3600":"code","feccd084":"code","62fef69f":"code","c16de12f":"code","a83e00c5":"code","c5a78aba":"markdown","dacb88db":"markdown","765cdbad":"markdown","2c517b76":"markdown","80f0fdda":"markdown","30c9fdff":"markdown","f4288059":"markdown","e0a4523b":"markdown","583944b5":"markdown","b4380882":"markdown","514ef55f":"markdown","10d1c226":"markdown","0aee7b3f":"markdown","83f79749":"markdown","138d8c75":"markdown","c408c75e":"markdown","57b90aab":"markdown","b2bdb615":"markdown","6d96477a":"markdown","ac2b471f":"markdown","bcb0905f":"markdown"},"source":{"7f32879a":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV","a0aeceb6":"# Set a filepath for the dataset\n\ndataset = pd.read_csv(\"..\/input\/heart-failure-prediction\/heart.csv\")","62d27f3b":"print(\"Missing entries in dataset:\")\nprint(dataset.isnull().sum())","5ece4582":"plt.title(\"Risk of heart disease \")\nplt.ylabel(\"Heart Disease\")\nplt.xlabel(\"Sex\")\nsns.barplot( x = dataset[\"Sex\"], y = dataset[\"HeartDisease\"])","dda913a7":"plt.title(\"Age distribution in dataset\")\nplt.xlabel(\"Age\")\nsns.kdeplot(data = dataset[\"Age\"], shade = True)\nplt.show()","542e5581":"plt.figure(figsize = (20,10))\nplt.title(\"Chest pain and resting blood pressure\")\nplt.ylabel(\"Resting blood pressure (mm Hg)\")\nplt.xlabel(\"Chest pain type\")\nsns.swarmplot(x = dataset[\"ChestPainType\"], y = dataset[\"RestingBP\"])\nplt.show()","4b767e46":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","7384b0bd":"print(X)","f99cd003":"print(y)","fc28e538":"X_numerical = dataset.iloc[:,[0,3,4,5,7,9,]].values\nX_categorical = dataset.iloc[:,[1,2,6,8,10]]","8dcad408":"#Encoding X_categorical\n\norginalNumOfColsOfX_categorical = X_categorical.shape[1]\nfor i in range(X_categorical.shape[1]): \n    currNumOfColsOfX_categorical = X_categorical.shape[1]\n    indexOfColumnToEncode = currNumOfColsOfX_categorical - orginalNumOfColsOfX_categorical + i\n    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(drop='first'), [indexOfColumnToEncode])], remainder='passthrough', sparse_threshold=0)\n    X_categorical = np.array(ct.fit_transform(X_categorical)) ","4770b55e":"# Concatenate the X_numerical and X_categorical together\n\nX = np.concatenate((X_numerical,X_categorical), axis=1)","143ad177":"print(X)","ba064aa3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","3ee32a3f":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","216b1122":"pca = PCA(n_components = 2)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","eb4c2ad9":"# Parameters: quality of split is measured by entropy.\n\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","652f3600":"y_pred = classifier.predict(X_test)\n\n# A list of prediction versus the actual results\n\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","feccd084":"# Confusion matrix\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","62fef69f":"accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","c16de12f":"classifier.get_params().keys()","a83e00c5":"parameters = [{\"criterion\":[\"gini\", \"entropy\"], \"max_depth\":range(1, 20),\n               \"min_samples_leaf\":range(1,10)}]\ngrid_search = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search.fit(X_train, y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\nprint(\"Best Parameters:\", best_parameters)","c5a78aba":"**Import libraries**","dacb88db":"**Training the decision tree classification on the training set**","765cdbad":"**Hypertune the parameters** A k-fold cross validation will be performed then a grid search to find the best model and parameters. These tests can help us identify the robustness of the model.","2c517b76":"**Principle Component Analysis** Principal Component Analysis (PCA) is an unsupervised, non-parametric statistical technique primarily used for dimensionality reduction in machine learning. It is recommended in tree classifications to reduce the dimensionality and improve the models ability to predict.","80f0fdda":"The types of chest pains all appear to fall within a similar range. Asymptomatic pain however, does have a greater occurance at all ranges.","30c9fdff":"An accuracy of 76% is not ideal however, the parameters have not been tuned yet and better results are to be expected once the grid search for the best parameters and accuracy has been completed.","f4288059":"**Data Analysis** Correlations and distributions in the data are to be unveiled. ","e0a4523b":"First the catergorical data and numerical data in X will be seperated\/split.","583944b5":"**Apply feature scaling** If not scaled, the features with high values will start dominating when calculating distances and will therefore become the prodominate features in the model. Decision tree models don't have to be scaled, but we will perform feature scaling to try improve the accuracy.","b4380882":"**Import Data**","514ef55f":"**Making predictions and calculating the accuracy**","10d1c226":"Age is normally distributed around with the highest density around late 50s to early 60s. This is to be expected as it is around this age that cardiovascular disease become a real threat for majority of the population.","0aee7b3f":"Our best model was run when 'gini' was used as the citerion to split the nodes and not 'entropy'. Gini impurity, calculates the amount of probability of a specific feature that is classified incorrectly when selected randomly. The best accuracy was 84.88% with Gini impurity, a max depth of 3 and a minimum sample leaves of 8.","83f79749":"**Split the data into a training and test set**","138d8c75":"**Create independent matrix of features (X) and dependent variable vector (y)**","c408c75e":"**Problem Identification** \n\nCardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. Four out of 5CVD deaths are due to heart attacks and strokes, and one-third of these deaths occur prematurely in people under 70 years of age. Heart failure is a common event caused by CVDs and this dataset contains 11 features that can be used to predict a possible heart disease. People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.\n\nSource\nThis dataset was created by combining different datasets already available independently but not combined before. In this dataset, 5 heart datasets are combined over 11 common features which makes it the largest heart disease dataset available so far for research purposes. The five datasets used for its curation are:\n* Cleveland: 303 observations\n* Hungarian: 294 observations\n* Switzerland: 123 observations\n* Long Beach VA: 200 observations\n* Stalog (Heart) Data Set: 270 observations\n* Total: 1190 observations\n* Duplicated: 272 observations\n\nA classification machine learning model will be utilized. The classifier will be a decision tree classifier. This model is interpretable, does not require feature scaling, and is effective of linear and non-linear problems. However, in this problem feature scaling will still be applied to strengthen the prediction.","57b90aab":"**The k-fold cross validation**","b2bdb615":"From this bargraph it is clear that men in this dataset are at higher risk of cardiovascular disease than the women in this dataset. ","6d96477a":"**Encoding categorical data**","ac2b471f":"**Attribute Information**\n* Age: age of the patient [years]\n* Sex: sex of the patient [M: Male, F: Female]\n* ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n* RestingBP: resting blood pressure [mm Hg]\n* Cholesterol: serum cholesterol [mm\/dl]\n* FastingBS: fasting blood sugar [1: if FastingBS > 120 mg\/dl, 0: otherwise]\n* RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]\n* MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]\n* ExerciseAngina: exercise-induced angina [Y: Yes, N: No]\n* Oldpeak: oldpeak = ST [Numeric value measured in depression]\n* ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n* HeartDisease: output class [1: heart disease, 0: Normal]","bcb0905f":"**The grid search**"}}