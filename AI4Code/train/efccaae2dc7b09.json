{"cell_type":{"09c1bfa3":"code","f5547958":"code","64413649":"code","f4ac4b89":"code","feaa3861":"code","e7d0f5f0":"code","9cb7d994":"code","a1ba3f49":"code","ae0e7aad":"code","148e8987":"code","eafc692e":"code","7eee09a4":"code","c3d0289c":"code","70af7d15":"code","4265ed3c":"code","b2037d3a":"code","8b08f742":"code","19ddf697":"code","b8848bd5":"code","c2d80b50":"code","80d084a7":"code","0cbbb763":"code","a5c4ba6c":"markdown","854216ff":"markdown","2c09cfe0":"markdown","ee684483":"markdown","cd59cc24":"markdown","683eedfb":"markdown","a7a9d5d6":"markdown","6fb4f3e1":"markdown","2326693d":"markdown","06df211d":"markdown"},"source":{"09c1bfa3":"from keras.utils import to_categorical\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.regularizers import l2","f5547958":"train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest= pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","64413649":"#Define the target and the features\nx_train = train.drop(columns=['label'])\ny_train = train.label\n\nx_test = test.drop(columns=['label'])\ny_test = test.label","f4ac4b89":"#Print the shape of target\ny_train.shape , y_test.shape","feaa3861":"#Print the number of class in the train target\nlist(y_train.unique())","e7d0f5f0":"#Print the number of class in the test target\nlist(y_test.unique())","9cb7d994":"x_train.max().sort_values().tail(1)","a1ba3f49":"x_test.max().sort_values().tail(1)","ae0e7aad":"#The max number is 255, so lets divide the target by this number\nx_train = x_train\/255\nx_test = x_test\/255","148e8987":"x_train = x_train.astype(float) \nx_test = x_test.astype(float)","eafc692e":"#Finally, lets get dummies of the target using the function presents in keras\nfrom keras.utils import to_categorical\n\ny_train = to_categorical(y_train,10) #10 levels of image\ny_test =  to_categorical(y_test,10) #10 levels of image","7eee09a4":"#Starting a neural network\nmodelo = Sequential()\n\n#Input the first layer in model with 50 neurals and the activation function will be Relu\nmodelo.add(Dense(50 #number os neurals\n                ,activation = 'relu' #activation function\n                ,input_shape = (784,) #Number of features in dataframe, let's pay attention, because keras need to receive a tuple, its the reason of (784,0)\n                ,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n                ))\n\n#Input the second layer in model with 50 neurals and the same activation function\nmodelo.add(Dense(30 \n                ,activation = 'relu' \n                ,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) \n                ))\n\n#Input the third layer in model with 20 neurals and the same activation function\nmodelo.add(Dense(20\n                ,activation = 'relu' \n                ,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) \n                ))\n\n#The final layes will be with 10 neurals because we have 10 class in this dataframe\n#The activation function is softmax because its will be normalize the output of neurals and it will be easier identify the probably of each class\nmodelo.add(Dense(10 #numero de classs\n                ,activation = 'softmax' #Vai normaliza as probabilidades por exponencial\n                ))\n\n#Finally, lets see the summary of the model and see how many parameters its have.\nmodelo.summary()","c3d0289c":"#I use the croos entropy, because its penalty high error for bad clasification and a loss error for good erro, its a commum metric using in classification problems\nmodelo.compile(\n                loss='categorical_crossentropy' \n               ,optimizer='adam' \n               ,metrics=['accuracy'] )","70af7d15":"history = modelo.fit(x_train,y_train\n         ,epochs=30 #number of times that model will through in train \n         ,batch_size = 128 #number of rows that will be consider to update the weights of layers\n         ,verbose = 1\n         ,validation_data=(x_test,y_test)\n         )","4265ed3c":"#Print loss and accuracy\nmodelo.evaluate(x_test,y_test,verbose = 0)","b2037d3a":"plt.subplots(figsize=(13, 8))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","8b08f742":"plt.subplots(figsize=(13, 8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","19ddf697":"#Predict the x_test\np = modelo.predict(x_test)\np = (p > 0.5)\nprint('ACC: %.3f%%' % (accuracy_score(y_test, p)*100))\nprint('---------')\nprint(classification_report(y_test, p))","b8848bd5":"from sklearn.neural_network import MLPClassifier\nmodel = MLPClassifier(hidden_layer_sizes=(50,30,20) #define 3 layers with 50, 30 and 20 neurals\n                      , batch_size=32 #Define the same bacth_size\n                      , solver = 'adam' #Define the optimization\n                      ,activation='relu' #Activation function\n                      , max_iter=30 #Number of epochs\n                      ,verbose=1\n                      , random_state=42)\n\nmodel.fit(x_train, y_train)","c2d80b50":"#Print the accuracy\nprint('Accuracy:', model.score(x_test, y_test))","80d084a7":"plt.rcParams['figure.figsize'] = 10, 10\n\nplt.plot(list(range(len(model.loss_curve_))), model.loss_curve_)","0cbbb763":"#Predict the x_test\np = model.predict(x_test)\np = (p > 0.5)\nprint('ACC: %.3f%%' % (accuracy_score(y_test, p)*100))\nprint('---------')\nprint(classification_report(y_test, p))","a5c4ba6c":"### Classification report of each class","854216ff":"### PLotting the loss during the increment of epochs","2c09cfe0":"### Applying Deep learning model to predict the image","ee684483":"# Try to do the same model in Scikit-learn","cd59cc24":"### Transform features in float\nAfter scaling the target let's transform the feature in float in order to reduce the risk of It converting in integer number ","683eedfb":"### Imports","a7a9d5d6":"# Try using Keras","6fb4f3e1":"### Read the dataframe","2326693d":"### Scale Pixel image\nFirst off all, let's identify that the max number in pixel image\n\nSo, after that I'll divide the target by this number to scale the target in this model","06df211d":"### PLotting the accuracy and loss during the increment of epochs"}}