{"cell_type":{"4e936022":"code","3a6b9313":"code","ab7f31fb":"code","317d2c21":"code","9babf8d4":"code","b7878f05":"code","ba9bc023":"code","dabd9390":"code","7d92f7ff":"code","35bcb3ad":"code","9ddce0c9":"code","b154e7cb":"code","74d0e18b":"code","f6578490":"code","c78ca6c3":"code","8f280978":"code","474a4957":"code","c7a16c70":"code","f09219ef":"code","d581b142":"code","eccc6f78":"code","84879f44":"code","0323ba56":"code","32abc425":"code","fbe231c8":"code","e4b967ae":"code","8043322e":"code","b428becd":"code","645a165e":"code","88827e43":"code","931066e1":"code","785b04ed":"code","bbf3f84e":"code","49a2dbee":"code","ab1ffe5d":"code","97479dae":"code","3e945bde":"code","89e611ff":"code","44bec990":"code","aca51a0f":"code","80eed57e":"code","ed301a38":"markdown","f0e1dfd5":"markdown","18c20d08":"markdown","1b43758d":"markdown","bac3def9":"markdown","9c0355b0":"markdown","29edc348":"markdown","c2329e35":"markdown","dae94a73":"markdown","8ab7c86f":"markdown","923d4a0a":"markdown","fc3265e8":"markdown","1763eddc":"markdown","04ec7817":"markdown","96dae51e":"markdown","b9153eec":"markdown"},"source":{"4e936022":"import os\nimport cv2\nimport subprocess\nfrom tqdm.auto import tqdm\nimport pandas as pd\nfrom IPython.display import Video, display, HTML\nimport warnings; warnings.simplefilter(\"ignore\")\n\n\nBASE_PATH = '..\/input\/tensorflow-great-barrier-reef\/train_images\/'\n\ndf = pd.read_csv(\"\/kaggle\/input\/tensorflow-great-barrier-reef\/train.csv\")\ndf['annotations'] = df['annotations'].apply(eval)\ndf['n_annotations'] = df['annotations'].str.len()\ndf['has_annotations'] = df['annotations'].str.len() > 0\ndf['has_2_or_more_annotations'] = df['annotations'].str.len() >= 2\ndf['doesnt_have_annotations'] = df['annotations'].str.len() == 0\ndf['image_path'] = BASE_PATH + \"video_\" + df['video_id'].astype(str) + \"\/\" + df['video_frame'].astype(str) + \".jpg\"","3a6b9313":"df['sequence'].unique()","ab7f31fb":"df['sequence'].nunique()","317d2c21":"df.groupby(\"sequence\")['video_id'].nunique()","9babf8d4":"# Videos 0 and 1 have 8 sequences, while video 2 has 4\ndf.groupby(\"video_id\")['sequence'].nunique()","b7878f05":"df_agg = df.groupby([\"video_id\", 'sequence']).agg({'sequence_frame': 'count', 'has_annotations': 'sum', 'doesnt_have_annotations': 'sum'})\\\n           .rename(columns={'sequence_frame': 'Total Frames', 'has_annotations': 'Frames with at least 1 object', 'doesnt_have_annotations': \"Frames with no object\"})\ndf_agg","ba9bc023":"df_agg.sort_values(\"Total Frames\")","dabd9390":"df_agg.sort_values(\"Frames with at least 1 object\")","7d92f7ff":"# image_id is a unique identifier for a row\ndf['image_id'].nunique() == len(df)","35bcb3ad":"df_agg.loc[[(0, 40258)]]","9ddce0c9":"pd.set_option(\"display.max_rows\", 500)\ndf[df['sequence'] == 40258]","b154e7cb":"df['start_cut_here'] = df['has_annotations'] & df['doesnt_have_annotations'].shift(1)  & df['doesnt_have_annotations'].shift(2)\ndf['end_cut_here'] = df['doesnt_have_annotations'] & df['has_annotations'].shift(1)  & df['has_annotations'].shift(2)\ndf['sequence_change'] = df['sequence'] != df['sequence'].shift(1)\ndf['last_row'] =  df.index == len(df)-1\ndf['cut_here'] = df['start_cut_here'] | df['end_cut_here'] | df['sequence_change'] | df['last_row']\n","74d0e18b":"start_idx = 0\nfor subsequence_id, end_idx in enumerate(df[df['cut_here']].index):\n    df.loc[start_idx:end_idx, 'subsequence_id'] = subsequence_id\n    start_idx = end_idx","f6578490":"df['subsequence_id'] = df['subsequence_id'].astype(int)","c78ca6c3":"df['subsequence_id'].nunique()","8f280978":"drop_cols = ['start_cut_here', 'end_cut_here', 'sequence_change', 'last_row', 'cut_here', 'has_2_or_more_annotations', 'doesnt_have_annotations']\ndf = df.drop(drop_cols, axis=1)\ndf.head()","474a4957":"df.groupby(\"subsequence_id\")['has_annotations'].mean().round(2).sort_values().value_counts()","c7a16c70":"df_subseq_agg = df.groupby(\"subsequence_id\")['has_annotations'].mean()\ndf_subseq_agg[~df_subseq_agg.isin([0, 1])]","f09219ef":"df[df['subsequence_id'] == 52]","d581b142":"df[df['subsequence_id'] == 53]","eccc6f78":"df[df['subsequence_id'] == 54]","84879f44":"! mkdir videos\/","0323ba56":"def load_image(img_path):\n    assert os.path.exists(img_path), f'{img_path} does not exist.'\n    img = cv2.imread(img_path)\n    return img\n\ndef load_image_with_annotations(img_path, annotations):\n    img = load_image(img_path)\n    if len(annotations) > 0:\n        for ann in annotations:\n            cv2.rectangle(img, (ann['x'], ann['y']),\n                (ann['x'] + ann['width'], ann['y'] + ann['height']),\n                (255, 255, 0), thickness=2,)\n    return img\n\ndef make_video(df, part_id, is_subsequence=False):\n    \"\"\"\n    Args:\n        - part_id: either a sequence or a subsequence id\n    \"\"\"\n    \n    if is_subsequence:\n        part_str = \"subsequence_id\"\n    else:\n        part_str = \"sequence\"\n    \n    print(f\"Creating video for part={part_id}, is_subsequence={is_subsequence} (querying by {part_str})\")\n    # partly borrowed from https:\/\/github.com\/RobMulla\/helmet-assignment\/blob\/main\/helmet_assignment\/video.py\n    fps = 15 # don't know exact value\n    width = 1280\n    height = 720\n    save_path = f'videos\/video_{part_str}_{part_id}.mp4'\n    tmp_path = f'videos\/tmp_video_{part_str}_{part_id}.mp4'\n    \n    \n    output_video = cv2.VideoWriter(tmp_path, cv2.VideoWriter_fourcc(*\"MP4V\"), fps, (width, height))\n    \n    df_part = df.query(f'{part_str} == @part_id')\n    for _, row in tqdm(df_part.iterrows(), total=len(df_part)):\n        img = load_image_with_annotations(row.image_path, row.annotations)\n        output_video.write(img)\n    \n    output_video.release()\n    # Not all browsers support the codec, we will re-load the file at tmp_output_path\n    # and convert to a codec that is more broadly readable using ffmpeg\n    if os.path.exists(save_path):\n        os.remove(save_path)\n    subprocess.run(\n        [\"ffmpeg\", \"-i\", tmp_path, \"-crf\", \"18\", \"-preset\", \"veryfast\", \"-vcodec\", \"libx264\", save_path],\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.DEVNULL\n    )\n    os.remove(tmp_path)\n    print(f\"Finished creating video for {part_id}... saved as {save_path}\")\n    return save_path","32abc425":"video_path = make_video(df, 40258)","fbe231c8":"Video(video_path, width= 1280\/2, height= 720\/2)","e4b967ae":"subsequences = df.loc[df['sequence'] == 40258, 'subsequence_id'].unique()\nsubsequences","8043322e":"for subsequence in subsequences:\n    video_path = make_video(df, subsequence, is_subsequence=True)\n    display(HTML(f\"<h2>Subsequence ID: {subsequence}<\/h2>\"))\n    display(Video(video_path, width= 1280\/2, height= 720\/2))","b428becd":"from sklearn.model_selection import train_test_split, StratifiedKFold\ndf.head()","645a165e":"df_split  = df.groupby(\"subsequence_id\").agg({'has_annotations': 'max', 'video_frame': 'count'}).astype(int).reset_index()\ndf_split.head()","88827e43":"!mkdir train-validation-split\/","931066e1":"def analize_split(df_train, df_val, df):\n     # Analize results\n    print(f\"   Train images                 : {len(df_train) \/ len(df):.3f}\")\n    print(f\"   Val   images                 : {len(df_val) \/ len(df):.3f}\")\n    print()\n    print(f\"   Train images with annotations: {len(df_train[df_train['has_annotations']]) \/ len(df[df['has_annotations']]):.3f}\")\n    print(f\"   Val   images with annotations: {len(df_val[df_val['has_annotations']]) \/ len(df[df['has_annotations']]):.3f}\")\n    print()\n    print(f\"   Train images w\/no annotations: {len(df_train[~df_train['has_annotations']]) \/ len(df[~df['has_annotations']]):.3f}\")\n    print(f\"   Val   images w\/no annotations: {len(df_val[~df_val['has_annotations']]) \/ len(df[~df['has_annotations']]):.3f}\")\n    print()\n    print(f\"   Train mean annotations       : {df_train['n_annotations'].mean():.3f}\")\n    print(f\"   Val   mean annotations       : {df_val['n_annotations'].mean():.3f}\")\n    \n    print()","785b04ed":"for test_size in [0.01, 0.05, 0.1, 0.2]:\n    print(f\"Generating train-validation split with {test_size*100}% validation\")\n    df_train_idx, df_val_idx = train_test_split(df_split['subsequence_id'], stratify=df_split[\"has_annotations\"], test_size=test_size, random_state=42)\n    df['is_train'] = df['subsequence_id'].isin(df_train_idx)\n    df_train, df_val = df[df['is_train']], df[~df['is_train']]\n    \n    # Print some statistics\n    analize_split(df_train, df_val, df)\n    \n    # Save to file\n    f_name = f\"train-validation-split\/train-{test_size}.csv\"\n    print(f\"Saving file to {f_name}\")\n    df.to_csv(f_name, index=False)\n    print()\n    ","bbf3f84e":"!ls -l train-validation-split\/","49a2dbee":"df = df.drop(\"is_train\", axis=1)","ab1ffe5d":"n_splits = 5\nkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2021)\nfor fold_id, (_, val_idx) in enumerate(kf.split(df_split['subsequence_id'], y=df_split[\"has_annotations\"])):\n    subseq_val_idx = df_split['subsequence_id'].iloc[val_idx]\n    df.loc[df['subsequence_id'].isin(subseq_val_idx), 'fold'] = fold_id\n    \ndf['fold'] = df['fold'].astype(int)\ndf['fold'].value_counts(dropna=False)","97479dae":"for fold_id in df['fold'].sort_values().unique():\n    print(\"=============================\")\n    print(f\"Analyzing fold {fold_id}\")\n    df_train, df_val = df[df['fold'] != fold_id], df[df['fold'] == fold_id]\n    analize_split(df_train, df_val, df)\n    print()","3e945bde":"!mkdir cross-validation\/","89e611ff":"df.to_csv(\"cross-validation\/train-5folds.csv\", index=False)","44bec990":"n_splits = 10\nkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2021)\nfor fold_id, (_, val_idx) in enumerate(kf.split(df_split['subsequence_id'], y=df_split[\"has_annotations\"])):\n    subseq_val_idx = df_split['subsequence_id'].iloc[val_idx]\n    df.loc[df['subsequence_id'].isin(subseq_val_idx), 'fold'] = fold_id\n    \ndf['fold'] = df['fold'].astype(int)\ndf['fold'].value_counts(dropna=False)","aca51a0f":"for fold_id in df['fold'].sort_values().unique():\n    print(\"=============================\")\n    print(f\"Analyzing fold {fold_id}\")\n    df_train, df_val = df[df['fold'] != fold_id], df[df['fold'] == fold_id]\n    analize_split(df_train, df_val, df)\n    print()","80eed57e":"df.to_csv(\"cross-validation\/train-10folds.csv\", index=False)","ed301a38":"## Create 5-folds cross validation","f0e1dfd5":"# Let's see how a sequence and a subsequence look like as videos!!\n\n## mp4 generating code from [create annotated video](https:\/\/www.kaggle.com\/bamps53\/create-annotated-video)\n\n### I changed it to have sequence as parameter instead of video_id","18c20d08":"## The total amount of frames in each sequence varies a lot, so it might be quite difficult to use sequences as the splitting unit.","1b43758d":"## Create 10-fold cross validation","bac3def9":"## Train-validation splits for 1%, 5%, 10% and 20%","9c0355b0":"### The sequence has 4 subsequences with objects surrounded by other parts with no objects at all. We could split this sequence in these 4 subsequences and use that as units for train-validation splits.\n\n\n### Here we cut continuous subsequence with objects and without objects:","29edc348":"# Can we go into a subsequence level? \n\nSo, one idea is the following: There are large gaps of a sequence with no objects in sights. May be we can split the sequence into a smaller piece during those \"empty\" times and that might ensure that the same region of the coral, with the same individuals, doesn't appear in both training and validation data.\n\n\n### See for example, sequence 40258:","c2329e35":"# Please, _DO_ upvote if you find this useful or interesting!","dae94a73":"### The method didn't work perfectly for some subsequences, but the \"broken ones\" don't look that bad so we are cool \ud83d\udc4d\ud83d\udc4d","8ab7c86f":"# \ud83d\udc20 Reef - CV strategy: subsequences!\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/31703\/logos\/header.png)\n\n## Problem: there are 3 videos. Using videos as split units for cross-validation or train-validation splits is not optimal, as it generates a too large validation portion.\n\n\n## In this notebook we explore sequences as potential units for cross-validation, but since there are only 20 sequences and their sizes are quite disimilar, we propose an approach to split them into smaller chunks, that we name _subsequences_.\n\nA **sequence**, as stated in the [data tab of the competition](https:\/\/www.kaggle.com\/c\/tensorflow-great-barrier-reef\/data), is:\n> sequence - ID of a gap-free subset of a given video. The sequence ids are not meaningfully ordered.\n\n**Subsequences**, as we will define them below,  are parts of a sequences where objects are continually present or are continually not present. We isolate 2 kind of subsequences: with objects and with no objects.\n\n&nbsp;\n\nLet's see an **example**. Consider the sequence `A` with the following frames:\n* `1-20` - No annotations present\n* `21-30` - Annotations present\n* `31-60` - No annotations\n* `61-80` - Annotations present\n\nIn this case, we say that the sequence `A` has `4` subsequences (`1-20`, `21-30`, `31-60`, `61-80`).\n\n&nbsp;\n\n\nA subsequence seems to me like the minimal atom for ensuring no leaks happen between train and test.\n\n\n&nbsp;\n&nbsp;\n&nbsp;\n\n---\n\nThe notebook goes as follows:\n1. Analize sequences as potential units for spliting\n2. Propose and create subsequences, and create videos for sequences and subsequences to get a feeling of them\n3. Create common train-validation splits (1%, 5%, 10%, 20%) using subsequences\n4. Create 5-fold splits and 10-fold splits using subsequences\n\n&nbsp;\n&nbsp;\n\n\n### The resulting dataframes are provided as a dataset for ease of use here: [reef-cv-strategy-subsequences-dataframes](https:\/\/www.kaggle.com\/julian3833\/reef-cv-strategy-subsequences-dataframes)\n\n\n# Please, _DO_ upvote if you find this useful or interesting!\n\n","923d4a0a":"# Video for sequence _40258_ and its subsequences","fc3265e8":"This looks good \ud83d\ude01, let's use it for creating the splits...\n\n# Generate some common splits based on _subsequences_","1763eddc":"**There are 20 sequences**:","04ec7817":"# Analyze sequences","96dae51e":"## What do we want, ideally?\n\nThe ideal scenario would be that, if we split 80 - 20 (train - validation)\nThen the 80% of the training data has:\n* 80% sequences\n* 80% of frames \n* 80% of frames with objects\n* 80% of individuals\n\nSplitting by sequence ensures that no region of the coral appears both in training and validation data.\n","b9153eec":"**\"sequence\" is a global identifier for a sequence (aka it's not relative to the video_id)**"}}