{"cell_type":{"84064611":"code","ae01575d":"code","ed5b1884":"code","9e48d2ee":"code","fa6ceb46":"code","84f4a456":"code","c11f9700":"code","55424651":"code","25e41e2b":"code","751e23f0":"code","2df6fed8":"code","e6798000":"code","44e062fb":"code","789e486b":"code","ce5a29af":"code","0d0321ce":"markdown","939c161a":"markdown","37bc716e":"markdown","683e5d57":"markdown","c2d02a67":"markdown","6b87c90b":"markdown","cdabc189":"markdown","a4d8dfe8":"markdown","a7f9aad5":"markdown","dae0f027":"markdown","c10f5748":"markdown"},"source":{"84064611":"import numpy as np\nimport pandas as pd\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# defining dir variables \nroot_dir = '..\/input\/emotion-detection-fer\/'\ntrain_dir = root_dir + 'train\/'\ntest_dir = root_dir + 'test\/'","ae01575d":"target_var = os.listdir(train_dir)\ntarget_var","ed5b1884":"import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 7, figsize=(20,8))\nfor i in range(len(target_var)):\n    d = train_dir+target_var[i]+'\/'+os.listdir(train_dir+target_var[i]+'\/')[0]\n    axes[i].imshow( plt.imread(d) )\n    axes[i].set_title(target_var[i])\nplt.show()","9e48d2ee":"x_train = np.array([ len(os.listdir(train_dir+i+'\/')) for i in target_var ])\nx_test = np.array([ len(os.listdir(test_dir+i+'\/')) for i in target_var ])\nlabel = target_var\n  \nfig, axes = plt.subplots(1, 2, figsize=(8,4))\naxes[0].pie(x_train, labels=label, autopct='%1.1f%%',shadow=True, startangle=90)\naxes[1].pie(x_test, labels=label, autopct='%1.1f%%',shadow=True, startangle=90)\naxes[0].set_title('Train')\naxes[1].set_title('Test')\nplt.show()\n\nfor i in target_var:\n    print('Emotion : ' + i )\n    print('\\tTraining : ' + str(len(os.listdir(train_dir+i+'\/'))) +'\\n\\t Testing : ' + str(len(os.listdir(test_dir+i+'\/'))))\n    \n","fa6ceb46":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Using IDG to load images from directory\ntrain_idg = ImageDataGenerator(rescale=1.\/255, validation_split=0.3) # 30 percent validation split for taining \ntest_idg = ImageDataGenerator(rescale=1.\/255)\n\n# Specify parameters\/arguments for data generation\nimg_size = (48, 48)\nbatch_size = 64\n\narg_train = {'target_size': img_size,\n             'color_mode': 'grayscale',\n             'class_mode' : 'categorical',\n             'batch_size': batch_size}\narg_test = {'target_size': img_size,\n            'color_mode': 'grayscale',\n            'class_mode' : 'categorical',\n            'batch_size': batch_size,\n            'shuffle': False}\n\ntrain = train_idg.flow_from_directory(directory=train_dir, subset='training', **arg_train)\nvalid = train_idg.flow_from_directory(directory=train_dir, subset='validation', **arg_train)\ntest  = test_idg.flow_from_directory(directory=test_dir, **arg_test)","84f4a456":"import tensorflow as tf\nfrom tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization","c11f9700":"model = tf.keras.Sequential()\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(7,kernel_initializer='he_normal'))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","55424651":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0005),loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(\n    train ,\n    validation_data=valid,\n    epochs=50)","25e41e2b":"plt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('CNN Metrices (Accuracy)')\nplt.ylabel('% value')\nplt.xlabel('Epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","751e23f0":"plt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation loss')\nplt.title('CNN Metrices(Loss)')\nplt.ylabel('% value')\nplt.xlabel('Epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","2df6fed8":"y_pred = model.predict(test)","e6798000":"y_pred_labels = []\nfor i in y_pred:\n    y_pred_labels.append(np.argmax(i))","44e062fb":"y_actual = test.classes[test.index_array]","789e486b":"from sklearn import metrics\ncm = metrics.confusion_matrix(y_actual, y_pred_labels)\ndisp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()\nplt.show()","ce5a29af":"from sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(y_actual, y_pred_labels, digits=4))","0d0321ce":"### Compile and run","939c161a":"## Desription\n\n    -  Images are categorized based on the emotion shown in the facial expressions (happiness, neutral, sadness, anger, surprise, disgust, fear).\n    -  We need to design a CNN which will classify images based on followinf facial expression ","37bc716e":"### Sample images ","683e5d57":"## CNN","c2d02a67":"## EDA (Exploring number of images in each class)","6b87c90b":"## Testing and evaluation\u00b6","cdabc189":"### Target labels in dataset","a4d8dfe8":"## Data loading and perprocessing\n\n    - 0\/1 Normalization \n    - Grayscale\n    - input shape resize for CNN (300x300)","a7f9aad5":"# CNN for happy and sad face detection","dae0f027":"### Bulding model","c10f5748":"## Dataset\n\n    The dataset contain 35,685 examples of 48x48 pixel gray scale images of faces divided into train and test dataset."}}