{"cell_type":{"f366176c":"code","d9e9b22b":"code","a7eccf16":"code","82832e6e":"code","53a49dc2":"code","b591db31":"code","4fdc38d4":"code","1aa77fa2":"code","48fe8bad":"code","260a2729":"code","15e29dc0":"code","95d6700f":"code","59e42c83":"code","9454417b":"code","0fda41cc":"code","90f5018a":"code","783d0d2d":"code","9be3fee5":"code","8d5a4d60":"code","f721e0d4":"code","1b8e562a":"code","619fc425":"code","2b6384f0":"code","d62dca44":"code","450d4382":"code","400a2268":"code","3520a5ae":"code","075573f2":"code","bf07ecd5":"code","1aec4072":"code","ef739918":"code","fad838f7":"markdown","4dbd187a":"markdown","3a89ab7b":"markdown","5c6ff067":"markdown","c3d4a90d":"markdown","dfe81e67":"markdown","1a3130dc":"markdown","e104c6d2":"markdown","e19e5d8b":"markdown","c3d08812":"markdown","f8db844e":"markdown","07710267":"markdown","bd64c592":"markdown","42078ed4":"markdown","749ffd6c":"markdown","293586d9":"markdown","e4354f89":"markdown","32c36db1":"markdown","037d93dd":"markdown","b8767aa3":"markdown"},"source":{"f366176c":"import os\nimport gc\nimport re\n\nimport cv2\nimport math\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\nimport tensorflow as tf\n\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Conv2DTranspose, concatenate, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\n\n\nimport warnings\nimport os \nimport pandas as pd\nimport plotly.graph_objs as go\nimport matplotlib.ticker as ticker\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","d9e9b22b":"data_dir = '..\/input\/plant-pathology-2020-fgvc7'\nimg_path = os.path.join(data_dir,'images')\nIMG_DIM = 256\n\nos.listdir(data_dir)","a7eccf16":"train_total=pd.read_csv(os.path.join(data_dir,\"train.csv\"))\ntest=pd.read_csv(os.path.join(data_dir,\"test.csv\"))\ntrain_total['image_id']=train_total['image_id']+'.jpg'\ntest['image_id']=test['image_id']+'.jpg'\ntrain_total['label'] = train_total.iloc[:,1:5].idxmax(1)","82832e6e":"train_total.head()","53a49dc2":"train, val = train_test_split(train_total, test_size = 0.15,stratify = train_total.label)\nprint(train.label.value_counts()\/train_total.label.value_counts()) # TO check the percentage by category","b591db31":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator( horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=.1,\n    fill_mode='nearest',\n    shear_range=0.1,\n    rescale=1\/255,\n    brightness_range=[0.5, 1.5])\n\nval_datagen = ImageDataGenerator( \n    rescale=1\/255)","4fdc38d4":"train_generator=train_datagen.flow_from_dataframe(train,directory=img_path,\n                                                      target_size=(IMG_DIM,IMG_DIM),\n                                                      x_col=\"image_id\",\n                                                      y_col=['healthy','multiple_diseases','rust','scab'],\n                                                      class_mode='raw',\n                                                      shuffle=False,\n                                                       subset='training',\n                                                      batch_size=16)\nval_generator=val_datagen.flow_from_dataframe(val,directory=img_path,\n                                                      target_size=(IMG_DIM,IMG_DIM),\n                                                      x_col=\"image_id\",\n                                                      y_col=['healthy','multiple_diseases','rust','scab'],\n                                                      class_mode='raw',\n                                                      shuffle=False,\n                                                      batch_size=16,\n                                                  )\n\ntest_generator=val_datagen.flow_from_dataframe(test,directory='\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/',\n                                                      target_size=(IMG_DIM,IMG_DIM),\n                                                      x_col=\"image_id\",\n                                                      y_col=None,\n                                                      class_mode=None,\n                                                      shuffle=False,\n                                                      batch_size=16)","1aa77fa2":"ds = tf.data.Dataset.from_generator(lambda: train_generator,\n                     output_types=(tf.float32,tf.float32),\n                     output_shapes=([None, IMG_DIM, IMG_DIM, 3],[None, 4])\n                     )\nval_ds = tf.data.Dataset.from_generator(lambda: val_generator ,\n                     output_types=(tf.float32,tf.float32),\n                     output_shapes=([None, IMG_DIM, IMG_DIM, 3],[None, 4])\n                     )","48fe8bad":"len(train_generator)","260a2729":"base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(IMG_DIM,IMG_DIM,3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\npredictions = Dense(4, activation=\"softmax\")(x)\n\nmodel_updated = Model(inputs=base_model.input, outputs=predictions)\nmodel_updated.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['accuracy'])","15e29dc0":"# from tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# history = model_updated.fit(ds,                                    \n#                                   steps_per_epoch=len(train_generator),\n#                                   epochs=30,validation_data=val_ds,validation_steps=len(val_generator)\n#                                   ,verbose=1,callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.3,patience=3, min_lr=0.000001)])","95d6700f":"# loss = history.history['loss']\n# val_loss = history.history['val_loss']\n\n# plt.plot(loss, label='Training Loss')\n# plt.plot(val_loss, label='Validation Loss')\n# plt.legend(loc='upper right')\n# plt.ylabel('Cross Entropy')\n# plt.title('Training and Validation Loss')\n# plt.xlabel('epoch')\n# plt.show()","59e42c83":"# model_updated.save('\/content\/drive\/My Drive\/Colab Notebooks\/Plant_256\/DenseNet pretrained.h5')\n# model_updated.save('\/content\/drive\/My Drive\/Colab Notebooks\/Plant_256\/DenseNet pretrained.h5')","9454417b":"from tensorflow.keras.models import load_model\nmodel_updated = load_model('\/kaggle\/input\/trainedmodel\/DenseNet\/DenseNet retrained.h5')\nmodel_pretrained = load_model('\/kaggle\/input\/trainedmodel\/DenseNet\/DenseNet pretrained.h5')","0fda41cc":"model_updated.summary()","90f5018a":"model_pretrained.summary()","783d0d2d":"train_total_generator=val_datagen.flow_from_dataframe(train_total,\n                                                        directory= img_path,\n                                                      target_size=(IMG_DIM,IMG_DIM),\n                                                      x_col=\"image_id\",\n                                                      y_col=['healthy','multiple_diseases','rust','scab'],\n                                                      class_mode='raw',\n                                                      shuffle=False,\n                                                      batch_size=32)\n\nds_total = tf.data.Dataset.from_generator(lambda: train_total_generator,\n                     output_types=(tf.float32,tf.float32),\n                     output_shapes=([None, IMG_DIM, IMG_DIM, 3],[None, 4])\n                     )","9be3fee5":"train_total_generator.reset()\nmodel_pretrained.evaluate(ds_total,steps=len(train_total_generator),verbose=1)","8d5a4d60":"train_total_generator.reset()\nmodel_updated.evaluate(ds_total,steps=len(train_total_generator),verbose=1)","f721e0d4":"# Redefine model too get 1024 feature output\nmodel_updated_feature = Model(inputs=model_updated.input,\n                              outputs=model_updated.get_layer(\"global_average_pooling2d_2\").output)\n\nmodel_pretrained_feature = Model(inputs=model_pretrained.input,\n                                 outputs=model_pretrained.get_layer(\"global_average_pooling2d_3\").output)\n\ntrain_total_generator.reset()\npreds_updated = model_updated_feature.predict(ds_total,steps=len(train_total_generator),verbose=1)\ntrain_total_generator.reset()\npreds_pretrained = model_pretrained_feature.predict(ds_total,steps=len(train_total_generator),verbose=1)","1b8e562a":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nle.fit(train_total['label'])\npreds_label = le.transform(train_total['label'])","619fc425":"preds_updated_avg = [preds_updated[np.where(preds_label == x)].mean(axis = 0) for x in range(4)]\npreds_pretrained_avg = [preds_pretrained[np.where(preds_label == x)].mean(axis = 0) for x in range(4)]","2b6384f0":"plt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nfor x in range(4):\n    plt.plot(preds_pretrained_avg[x], label = le.classes_[x])\n    plt.legend(loc='upper left')\nplt.subplot(1,2,2)\nfor x in range(4):\n    plt.plot(preds_updated_avg[x], label = le.classes_[x])\n    plt.legend(loc='upper left')","d62dca44":"train_total_generator.reset()\npreds = model_updated.predict(ds_total,steps=len(train_total_generator),verbose=1)","450d4382":"preds_df = pd.DataFrame(preds)\npreds_df = preds_df.rename(columns={0:'healthy',1:'multiple_diseases',2:'rust',3:'scab'})\n\npreds_df['p_label'] = preds_df.iloc[:,:4].idxmax(1)\n\nresult = pd.concat([train_total, preds_df], axis=1, sort=False)\n\nwrong_result = result[result.label != result.p_label]\n\nwrong_result.image_id.count()","400a2268":"def load_image(image_id):\n    image = load_img(os.path.join(data_dir,'images',image_id), target_size=(IMG_DIM,IMG_DIM ))\n    return img_to_array(image)\n\nid_list = wrong_result['image_id'].tolist()\nsuspisous_images = []\n\n\nfor ids in id_list:\n    suspisous_images.append(load_image(ids))\n\nsuspisous_images = np.array(suspisous_images,dtype='float32')","3520a5ae":"suspisous_images = suspisous_images\/256.\np_Label = wrong_result['p_label'].to_list()\nLabel = wrong_result['label'].to_list()","075573f2":"import sys\nsys.path.append('\/kaggle\/input\/gradcam')","bf07ecd5":"from gradcam import GradCAM\n\nheatmaps = []\n\nfor orig in suspisous_images:\n    image = np.expand_dims(orig, axis=0)\n    preds = model_updated.predict(image)\n    i = np.argmax(preds)\n    cam = GradCAM(model_updated, i)\n    heatmap = cam.compute_heatmap(image)\n    heatmap = cv2.resize(heatmap, (IMG_DIM, IMG_DIM))\n    heatmaps.append(heatmap)\n\nheatmaps = np.array(heatmaps,dtype='float32')","1aec4072":"plt.figure(figsize=(15,400))\nfor i in range(wrong_result.image_id.count()):\n    ax = plt.subplot(40,2,2*i+1)\n\n    ax.text(0.5, 1, 'GT : {} '.format(Label[i]),\n        verticalalignment='top', horizontalalignment='center',\n        transform=ax.transAxes,\n        color='White', fontsize=15)\n    ax.set_title(id_list[i])\n\n    plt.imshow(suspisous_images[i])\n        \n    ax = plt.subplot(40,2,2*i+2)\n    ax.text(0.5, 1, ' vs PRED : {}'.format(p_Label[i]),\n    verticalalignment='top', horizontalalignment='center',\n    transform=ax.transAxes,\n    color='White', fontsize=15)\n    ax.set_title(id_list[i])\n    \n    plt.imshow(suspisous_images[i])\n    plt.imshow(heatmaps[i],alpha=0.5)","ef739918":"wrong_result","fad838f7":"Prepare the dataset for total Training Dataset provided from Kaggle","4dbd187a":"Calculate the average 1024 feature output ","3a89ab7b":"Define Generator","5c6ff067":"Split the Dataset into Train and Validation set using the option (stratify) for have the same percentage smaple by category","c3d4a90d":"Two models were trained in Colab\n\nNow load two models","dfe81e67":"Evaluate Two models (92% vs 98%)","1a3130dc":"# DenseNet Imagenet pretrained vs retrined & GradCam\n\nBackground : The objectives of the analysis in this notebook is to find the answers of simple question.\n\n**Adding a couple of fully connected (Dense) Layer to the imagenet pretrained DenseNet model is good enough or do we need to train all layers of DenseNet?**\n\nSteps\n\n1. Train the DenseNet with trainset with the same hyperparameters. The only difference would be setting all DenseNet layers \"Trainable\" or \"Not Trainable\"\n2. Compare the performance between two (One is about 90% accuracy and the other is about 98%)\n3. See feature outputs (avegarge all outputs) for all training samples.\n\nAdditional\n\nInvesigate the error sample employing GradCam (ref : https:\/\/www.pyimagesearch.com\/2020\/03\/09\/grad-cam-visualize-class-activation-maps-with-keras-tensorflow-and-deep-learning\/) ","e104c6d2":"#### Step 1. Train DenseNet + two fullyconnected Layers","e19e5d8b":"Observation:\n\n1. Transfer Learning approach would be a good starting point. By setting all layers as \"Trainnable\" would improve the model accuracy as 1024 feature output provide the more information\n2. Trained model with ImageNet which comprises general total population of images for image identification should be retrained for this type of pupose with specific populations\n3. Not sure why around 500 channels from 1024 is not activley responsive (may be more training epoch requried?)\n4. Most errors is coming from \"multiple diseases\" Segemnt ==> What is exact definition of \"multiple diseases\". Is it both \"rust\" and \"scab\"?","c3d08812":"#### Step 2 Compare the performance between two (One is about 92% accuracy and the other is about 98%)","f8db844e":"#### Additional Step. Compare the ground truth labels and the predicted labels and investiagte the source of error by GradCam","07710267":"As you can see the plot in below, 1024 feature output of retrined model (set all layers \"Trainable\") provides more information as everyone can expect.","bd64c592":"#### Step 3. See feature outputs (avegarge all outputs) for all training samples.","42078ed4":"Check loss and accuracy bu epochs","749ffd6c":"Create Keras Imagegenerator with augmentation for trainset \/ No augmentation for Validation","293586d9":"Includes Packages","e4354f89":"Load image files of error sample","32c36db1":"Now, we are trying to see the level of difference (?) of feature output after average pooling layers (1024 outputs)of each model ","037d93dd":"load data","b8767aa3":"Change to tf.data format (performance improve?)"}}