{"cell_type":{"8d9ce733":"code","2ca0bfed":"code","80730f60":"code","4d4462ac":"code","9a461568":"code","5d9b1f26":"code","f826cac2":"code","12f06d41":"code","a2851ce9":"code","a68fb48b":"code","fb90711d":"code","02256c6c":"code","1b9a365b":"code","16e86ebf":"code","fa1ff6c8":"code","00d44fa6":"code","afa1d771":"code","95701c8c":"code","71f65fec":"code","93005278":"code","7825beb2":"code","aa862a36":"code","de388e85":"code","61c6a934":"code","963f5166":"code","9453be42":"code","930736ae":"code","d54aae01":"code","8bd4462d":"code","c527b1d0":"code","67b77be2":"code","af7e2372":"code","96d5e7a9":"code","6a36d7f9":"code","4ac7d73b":"markdown","b7454d43":"markdown","0e4904ca":"markdown","81fbea21":"markdown","2d327443":"markdown","3e40ddbd":"markdown","0d579cc8":"markdown","b0b6bed1":"markdown","78d2c0c4":"markdown","94612755":"markdown","f819be5f":"markdown","3cb8d614":"markdown","8a2229c0":"markdown","c1205018":"markdown","b7483f5b":"markdown","c8d3410e":"markdown","677857ee":"markdown","79135d4b":"markdown","9305bbe8":"markdown","7dcecd85":"markdown","91a128b3":"markdown","78ec691e":"markdown","5981836d":"markdown","5b97220a":"markdown","928ac5f9":"markdown","6f7b825a":"markdown","7ec1ec14":"markdown","bfe0f314":"markdown","cdeb842a":"markdown","599ce0d8":"markdown","ee4e6323":"markdown","7eb7641b":"markdown","e8a40022":"markdown"},"source":{"8d9ce733":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nplt.style.use('seaborn')","2ca0bfed":"adult = pd.read_csv(\"..\/input\/adult-pmr3508\/train_data.csv\",\n        names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nadult_test = pd.read_csv(\"..\/input\/adult-pmr3508\/test_data.csv\",\n        names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")","80730f60":"print('Formato do Dataset:', adult.shape)","4d4462ac":"adult.head()","9a461568":"adult.describe()","5d9b1f26":"print(\"Workclass:\")\nprint(adult.Workclass.describe())\n\nprint(\"\\nOccupation:\")\nprint(adult.Occupation.describe())\n\nprint(\"\\nCountry:\")\nprint(adult.Country.describe())","f826cac2":"x = adult.Workclass.describe().top\nadult.Workclass =  adult.Workclass.fillna(x)\n\nx = adult.Country.describe().top\nadult.Country =  adult.Country.fillna(x)\n\nx = adult.Occupation.describe().top\nadult.Occupation =  adult.Occupation.fillna(x)","12f06d41":"adult.describe()","a2851ce9":"x = adult_test.Workclass.describe().top\nadult_test.Workclass =  adult_test.Workclass.fillna(x)\n\nx = adult_test.Country.describe().top\nadult_test.Country =  adult_test.Country.fillna(x)\n\nx = adult_test.Occupation.describe().top\nadult_test.Occupation =  adult_test.Occupation.fillna(x)","a68fb48b":"adult.head()","fb90711d":"adult.describe()","02256c6c":"from sklearn import preprocessing\nLabelEncoder = preprocessing.LabelEncoder()\n\ncorrelationMap = adult.apply(preprocessing.LabelEncoder().fit_transform).corr()\ncorrelationMap.head()","1b9a365b":"plt.figure(figsize=(10,7))\nsns.heatmap(correlationMap, vmin=-0.3, vmax=0.3, cmap = 'mako')","16e86ebf":"def LabeledBarPlot(df, x, label):\n# plota um gr\u00e1fico de barra da coluna \"column\" enfatizando o r\u00f3tulo \"label\"\n\n    print('Graph of %s and %s' %(x,label))\n    \n    index = df[x].unique()\n    columns = df[label].sort_values().unique()\n    data_to_plot = pd.DataFrame({'index': index})\n    \n    for column in columns:\n        temp = []\n        for unique in index:\n            filtered_data = df[df[x] == unique]\n            filtered_data = filtered_data[filtered_data[label] == column]\n            \n            temp.append(filtered_data.shape[0])\n        data_to_plot = pd.concat([data_to_plot, pd.DataFrame({column: temp})], axis = 1)\n        \n    data_to_plot = data_to_plot.set_index('index', drop = True)\n    \n    ax = data_to_plot.plot.bar(rot=0, figsize = (14,7), alpha = 0.9, cmap = 'viridis')","fa1ff6c8":"LabeledBarPlot(adult.drop('Id', axis=0), 'Sex', 'Target')","00d44fa6":"LabeledBarPlot(adult.drop('Id', axis=0), 'Sex', 'Education-Num')","afa1d771":"adult['Race'].describe()","95701c8c":"LabeledBarPlot(adult.drop('Id', axis=0), 'Race', 'Target')","71f65fec":"adult['Country'].describe()","93005278":"numericalColumns = ['Age', 'Education-Num', 'Capital Gain', 'Capital Loss', 'Hours per week']\n\nsns.set()\nsns.pairplot(adult.drop('Id'), vars = numericalColumns, hue = 'Target', palette = 'mako', height = 2.5, diag_kws={'bw':'1.0'})","7825beb2":"numericalFeatures = ['Age', 'Education-Num', 'Capital Gain', 'Capital Loss', 'Hours per week']\nadult = adult.drop(columns = ['fnlwgt'])\nadult_test = adult_test.drop(columns = ['fnlwgt'])\n\ncategoricalFeatures = ['Workclass', 'Martial Status', 'Occupation', 'Relationship', 'Race', 'Sex']\nadult = adult.drop(columns = ['Education', 'Country'])\nadult_test = adult_test.drop(columns = ['Education', 'Country'])\n\nprint(\"Atributos num\u00e9ricos: \",numericalFeatures)\nprint(\"Atributos categ\u00f3ricos: \", categoricalFeatures)","aa862a36":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()","de388e85":"# Vamos criar uma c\u00f3pia para conseguir reverter essa exclus\u00e3o posteriormente\n\nadultCopy = adult.drop('Id', axis=0)\n\nadult_testCopy = adult_test.drop('Id', axis=0)","61c6a934":"adultCopy[numericalFeatures] = scaler.fit_transform(adultCopy[numericalFeatures])\n\nadult_testCopy[numericalFeatures] = scaler.fit_transform(adult_testCopy[numericalFeatures])","963f5166":"LabelEncoder = preprocessing.LabelEncoder()\n\n# training set\nadultCopy[categoricalFeatures] = adult[categoricalFeatures].apply(LabelEncoder.fit_transform)\n\n# testing set\nadult_testCopy[categoricalFeatures] = adult_test[categoricalFeatures].apply(LabelEncoder.fit_transform)","9453be42":"adultCopy.head()","930736ae":"adult_testCopy.head()","d54aae01":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\n# Training set\nXadult = adultCopy[['Age','Workclass','Education-Num','Martial Status','Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss','Hours per week']]\nYadult = adultCopy.Target\n\n# Testing set\nXtestAdult = adult_testCopy[['Age','Workclass','Education-Num','Martial Status','Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss','Hours per week']]\n\naccuracy = 0\nbestK = 10\nprint('\\nBuscando o melhor K...\\n')\n\nfor k in range(10,30):\n    \n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, Xadult, Yadult, cv=5)\n    accuracy_ = scores.mean()\n    \n    if accuracy_ > accuracy:\n        bestK = k\n        accuracy = accuracy_\n        \nprint('O hiperpar\u00e2metro K que minimiza a taxa de erro \u00e9: %d, com acur\u00e1cia de %0.2f %%' %(bestK, accuracy*100))","8bd4462d":"knn = KNeighborsClassifier(n_neighbors=24)\nknn.fit(Xadult,Yadult)","c527b1d0":"prediction = knn.predict(XtestAdult)\n\nprint('O nosso K-NN preveu os seguintes r\u00f3tulos: ',prediction)","67b77be2":"submission = pd.DataFrame(prediction)","af7e2372":"submission[1] = prediction\nsubmission[0] = adult_testCopy.index\nsubmission.columns = ['Id','Income']","96d5e7a9":"submission.head()","6a36d7f9":"submission.to_csv('submission.csv',index = False)","4ac7d73b":"Vamos come\u00e7ar analisando a quest\u00e3o do g\u00eanero relacionada os ganhos e horas de trabalho como citado anteriormente.","b7454d43":"## 3. Preprocessamento dos atributos\n### 3.1 Escolha de atributos (*feature engineering*)\nNessa etapa, vamos levar em considera\u00e7\u00e3o o car\u00e1ter do atributo (qualitativo ou num\u00e9rico) e selecionar, um pouco pela intui\u00e7\u00e3o e um pouco pela an\u00e1lise dos dados que foi feita, aqueles atributos que seriam interessantes na determina\u00e7\u00e3o do fato da renda ser superior\/inferior a 50k, isto \u00e9, \u00fateis para o nosso classificador. ","0e4904ca":"## 4. Aplica\u00e7\u00e3o do classificador K-NN\nAgora que j\u00e1 fizemos o tratamento, an\u00e1lise e preprocessamento dos dados, podemos finalmente aplicar o K-NN.\n### 4.1 Busca do melhor hiperpar\u00e2metro K\nNesa parte, iremos buscar o melhor K para utilizar no K-NN, isto \u00e9, o valor de vizinhos que resultar\u00e1 na melhor acur\u00e1cia para o classificador. Para isso, iremos avaliar a acur\u00e1cia para K entre 5 e 35 (intervalo determinado pela intui\u00e7\u00e3o).","81fbea21":"Vamos analisar agora a quest\u00e3o racial no nosso data set.","2d327443":"Agora, s\u00f3 precisamos exportar o nosso data frame com a predi\u00e7\u00e3o para o formato .csv","3e40ddbd":"Chegamos em uma quantidade de vizinhos igual a 24.\n\nAgora, vamos criar o K-NN com K=24 e trein\u00e1-lo com o nosso data set.","0d579cc8":"Percebemos que a base quase como um todo \u00e9 de americanos, o que torna pouco relevante para o modelo usar esse atributo.","b0b6bed1":"A nossa base de dados \u00e9 de certa forma complexa, apresentando 14 vari\u00e1veis diferentes, algumas com certa redund\u00e2ncia, como Education e Education-Num.","78d2c0c4":"Antes vamos precisar remover a primeira linha do data frame, pois ela conflita com a normaliza\u00e7\u00e3o. Isto ocorre porque essa primeira linha n\u00e3o \u00e9 um dado em si e muito menos num\u00e9rico, n\u00e3o sendo poss\u00edvel normaliz\u00e1-lo.","94612755":"Podemos tirar algumas conclus\u00f5es interessantes dessa correla\u00e7\u00e3o:\n- Justificadamente, a vari\u00e1vel **Martial Status** est\u00e1 intimamente relacionada com a vari\u00e1vel **Relationship**\n    \n    Apesar do fato de os tempos modernos estarem desconstruindo a ideia de um padr\u00e3o de fam\u00edlia, ainda h\u00e1 grande rela\u00e7\u00e3o entre o estado civil (casado, solteiro, divorciado, etc) e o tipo de rela\u00e7\u00e3o familiar que existe (vive em fam\u00edlia, tem\/n\u00e3o tem filhos, etc).\n    \n    \n- Obtivemos uma alta correla\u00e7\u00e3o na matriz entre **Sex** e **Hours per week** e uma correla\u00e7\u00e3o m\u00e9dia entre **Sex** e **Capital Gain**\n    \n    O fato do g\u00eanero estar altamente relacionado com o ganho de capital e com o n\u00famero de horas trabalhadas evidencia alguma desigualdade de g\u00eanero. Esse fato ser\u00e1 melhor analisado na an\u00e1lise explorat\u00f3ria na sequ\u00eancia.\n    \n    \n- A vari\u00e1vel **Income** (dada por Target) est\u00e1 altamente ligada \u00e0s vari\u00e1veis **Age, Sex, Capital Gain, Capital Loss e Hours per week**\n    \n    A terceira conclus\u00e3o e, provavelmente, a mais importante para o nosso modelo nos indica quais s\u00e3o as principais vari\u00e1veis que influenciam a renda anual da pessoa, justamente o que estamos interessados em classificar.\n    \n    \n    \n- Por \u00faltimo, vemos que a vari\u00e1vel **fnlwgt** apresenta rela\u00e7\u00e3o aproximadamente nula com todas as demais vari\u00e1veis presentes, sendo pouco \u00fatil, portanto, para o nosso classificador.","f819be5f":"### 4.2 Predi\u00e7\u00e3o\nAp\u00f3s determinar o melhor K e treinar o classificador, iremos fazer a predi\u00e7\u00e3o da vari\u00e1vel de classe Income do set de teste usando o K-NN.","3cb8d614":"Nas tabela acima vemos o resultado do nosso dataset ap\u00f3s o tratamento dos dados faltantes.\n\nRepetiremos o processo agora para o set de teste.","8a2229c0":"Agora sim podemos aplicar a normaliza\u00e7\u00e3o sobre os dados num\u00e9ricos.","c1205018":"# PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es\n\n#### $\\textit{- An\u00e1lise do dataset Adult e aplica\u00e7\u00e3o do classificador K-NN}$\n#### $\\textit{Autor: Victor Rocha da Silva - PMR3508-2020-177}$\n\n## 1. Preparando os dados (Data Prep)\n### 1.1 Importando bibliotecas e dados\n- Primeiramente, vamos importar algumas bibliotecas que ser\u00e3o \u00fateis ao trabalhar com esses dados e, logo em seguida, o dataset.","b7483f5b":"A partir da descri\u00e7\u00e3o acima, notamos que os dados faltantes se concentram em tr\u00eas atributos diferentes: **Workclass, Occupation e Country**. Essa conclus\u00e3o foi tirada pelo fato de que o contador identificou menos observa\u00e7\u00f5es do que o total de 32561 dispon\u00edveis a priori. Temos:\n- 1836 (5,63%) faltando em Workclass, \n- 1843 (5,66%) faltando em Occupation\n- 583 (1,79%) faltando em Country\n\nVamos analisar, de maneira breve, cada um desses tr\u00eas atributos, para decidirmos o melhor tratamento poss\u00edvel:","c8d3410e":"### 3.2 Processamento dos atributos num\u00e9ricos\nPara os atributos num\u00e9ricos, iremos aplicar uma normaliza\u00e7\u00e3o linear nos valores, j\u00e1 que nossas features apresentam intervalos muito diferentes de valores. O objetivo da normaliza\u00e7\u00e3o \u00e9 alterar os valores das colunas num\u00e9ricas no dataset para uma escala comum, sem distorcer as diferen\u00e7as nos intervalos de valores. Vamos precisar do m\u00f3dulo de pr\u00e9-processamento da biblioteca scikit-learn e do utilit\u00e1rio MinMaxScaler.\n\nFaremos isso tanto na base de treino como na de teste.","677857ee":"### 2.2 Busca por correla\u00e7\u00f5es entre as vari\u00e1veis\nPrecisamos buscar **correla\u00e7\u00f5es** entre as vari\u00e1veis, verificando quais influem significativamente na renda anual e quais n\u00e3o, para montar um modelo adequado e eficiente. Al\u00e9m disso, \u00e9 valido enxergar tamb\u00e9m quais vari\u00e1veis estao ligadas entre si na base. \n\nPara fazer isso, vamos ter que aplicar o LabelEncoder nos dados, da biblioteca scikit-learn.","79135d4b":"A principio vemos que na nossa base, 27815 das pessoas s\u00e3o brancas, o que representa 85.4% dos dados. Logo, devemos levar em considera\u00e7\u00e3o que isso pode influenciar o plot do gr\u00e1fico e enfatizar desproporcionalmente algumas conclus\u00f5es.","9305bbe8":"Vamos tamb\u00e9m acrescentar a coluna Id e renomear a coluna correspondente do data frame para Income, que \u00e9 o que estamos prevendo com o classificador.","7dcecd85":"Podemos observar que certas vari\u00e1veis num\u00e9ricas como Education-Num, Capital Gain, Capital Loss e Hours per week conseguem, de certa forma, evidenciar a separa\u00e7\u00e3o de r\u00f3tulos, sendo muito mais \u00fateis para treinar o modelo.","91a128b3":"### 1.2 Lidando com dados faltantes (*missing data*)\n- Aqui faremos uma an\u00e1lise acerca dos dados faltantes, verificando onde se concentram e qual a melhor maneira de lidar com eles.","78ec691e":"- Atributos num\u00e9ricos: Age, fnlwgt, Education-Num, Capital Gain, Capital Loss e Hours per week\n\nQuanto aos atributos num\u00e9ricos, descartaremos a vari\u00e1vel \"fnlwgt\", que representa o n\u00famero de pessoas na popula\u00e7\u00e3o alvo que aquela unidade correspodente representa, n\u00e3o tendo influ\u00eancia sobre a classifica\u00e7\u00e3o do KNN; \n\n- Atributos qualitativos: Workclass, Education, Martial Status, Occupation, Relationship, Race, Sex e Country\n\nQuanto aos atributos qualitativos, descartaremos a vari\u00e1vel Education, pois j\u00e1 existe uma vari\u00e1vel num\u00e9rica correspondente no dataset (Education-Num) e usar ambas seria redundante; descartaremos tamb\u00e9m a vari\u00e1vel Country, pois cerca de 91,3% (28059) das observa\u00e7\u00f5es do dataset correspondem a americanos, representando um grande desbalanceamento nos dados.\n\nAgora, vamos subdividir as vari\u00e1veis que consideramos relevantes em qualitativas e num\u00e9ricas para que seja poss\u00edvel process\u00e1-las de maneira diferente.","5981836d":"Percebemos, ent\u00e3o, que \u00e9 bastante v\u00e1lido substituir os dados faltantes pela **moda** (observa\u00e7\u00e3o de maior frequ\u00eancia), j\u00e1 que esta observa\u00e7\u00e3o tem alta ocorr\u00eancia no dataset:\n\nEnt\u00e3o, vamos imputar os dados faltantes pela moda nesses atributos.","5b97220a":"### 3.3 Processamento dos atributos categ\u00f3ricos (qualitativos)\nPara os atributos categ\u00f3ricos, iremos passar os dados para uma escala num\u00e9rica. Desse modo ser\u00e1 poss\u00edvel us\u00e1-los no nosso classificador K-NN. Para isso, podemos usar o utilit\u00e1rio LabelEncoder da biblioteca scikit-learn. \n\nFaremos isso tanto na base de treino como na de teste.","928ac5f9":"Com os dois gr\u00e1ficos acima, fica claro uma quest\u00e3o de desigualdade de g\u00eanero. \u00c9 not\u00e1vel que h\u00e1 uma grande desproporcionalidade entre o n\u00famero de homens e mulheres que ganham >50K, por mais que isso tamb\u00e9m ocorra em menor escala para <=50K.\nOutro fato \u00e9 que as mulheres possuem menos anos de estudo quando comparado aos homens.","6f7b825a":"Desconsiderando o desbalanceamento dos dados, o gr\u00e1fico nos mostra que o n\u00famero de brancos que ganham >50K \u00e9 muito maior do que as demais etnias. Isso indica tamb\u00e9m um problema de desigualdade racial.","7ec1ec14":"Feita essa an\u00e1lise de correla\u00e7\u00e3o, podemos partir agora para uma an\u00e1lise explorat\u00f3ria da base de dados.","bfe0f314":"Esse \u00e9 o resultado final do nosso preprocessamento dos dados de treino e teste:\n\nObs: devido a normaliza\u00e7\u00e3o, os dados ficaram sem \"significado real\", ent\u00e3o n\u00e3o devemos usar esses data frames para an\u00e1lise explorat\u00f3ria, por exemplo, temos valores da idade negativos. Isso foi feito somente para melhorar o classificador.","cdeb842a":"### 4.3 Submiss\u00e3o da predi\u00e7\u00e3o\nPrecisamos agora transformar esse array com as predi\u00e7\u00f5es em um data frame e em seguida export\u00e1-lo para o formato .csv.","599ce0d8":"## 2. Interpreta\u00e7\u00e3o e an\u00e1lise do data frame\nNessa etapa, temos como objetivo fazer uma an\u00e1lise geral do nosso dataframe, analisando a correla\u00e7\u00e3o entre as vari\u00e1veis e interpretando os dados que temos. Os gr\u00e1ficos ser\u00e3o uma ferramenta de grande import\u00e2ncia para fazer tal an\u00e1lise.\n\n### 2.1 Vis\u00e3o geral da base de dados\nCome\u00e7aremos nossa an\u00e1lise com alguma observa\u00e7\u00f5es simples e relevantes sobre a base de dados.","ee4e6323":"O jeito mais simples de enxergar essas correla\u00e7\u00f5es \u00e9 plotando um **Heat Map** da biblioteca seaborn.\nNele, como podemos ver na legenda da direita, quanto mais clara \u00e9 a c\u00e9lula, maior \u00e9 a correla\u00e7\u00e3o, e quanto mais escura \u00e9 a c\u00e9lula, menor \u00e9 a correla\u00e7\u00e3o entre as vari\u00e1veis.","7eb7641b":"### 2.3 An\u00e1lise explorat\u00f3ria dos dados\nIremos explorar os dados da base Adult e obter algumas conclus\u00f5es acerca dos dados, principalmente usando gr\u00e1ficos. Espera-se que tanto essa etapa, como a busca por correla\u00e7\u00e3o seja \u00fatil na escolha dos atributos e cria\u00e7\u00e3o do nosso modelo.\nPara os gr\u00e1ficos, usaremos as bibliotecas Matplotlib e Seaborn, j\u00e1 importadas.\n\nPrimeiro, precisamos criar uma fun\u00e7\u00e3o que cria um gr\u00e1fico de barras rotulado, isso ser\u00e1 bastante \u00fatil nas nossas observa\u00e7\u00f5es.","e8a40022":"- Aqui temos uma representa\u00e7\u00e3o de um trecho do dataset e de como ele se estrutura:"}}