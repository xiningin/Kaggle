{"cell_type":{"dabc55ef":"code","612be49e":"code","0fb0a733":"code","32a81998":"code","d1582903":"code","c5af38f9":"code","469b069e":"code","71d3f77d":"code","86f14721":"code","eee899fc":"code","4dc7fdd6":"code","d1ecef18":"code","2826ffb6":"code","d4ae6af2":"code","cf918f8b":"code","89fc5578":"code","22a33bbc":"code","6c922acb":"code","6cd19f09":"code","7f749215":"code","4c8489c2":"code","4c965595":"code","162a1ac1":"code","882c8fc3":"code","033b58c8":"code","20c47880":"code","f1e5e05e":"code","c64a0c0d":"code","081154cc":"markdown","aeca80a0":"markdown","40b688fe":"markdown","e35806e0":"markdown","b9239747":"markdown","e4eefa01":"markdown","c900d726":"markdown","bbcc677d":"markdown"},"source":{"dabc55ef":"\nfrom __future__ import print_function\nimport os\nos.environ[\"PATH\"] += os.pathsep + 'C:\/Program Files (x86)\/Graphviz\/bin\/'\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom tensorflow.keras.layers import AveragePooling2D, Input, Flatten\nimport time\nimport cv2\nimport numpy as np\nimport tensorflow\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nfrom tensorflow.keras.models import Model\n\n# from models.attention_module import attach_attention_module\n# from utils import lr_schedule\n# from load_img import load_image\nimport sklearn\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\nfrom tensorflow.keras import backend as K","612be49e":"def attach_attention_module(net, attention_module):\n  if attention_module == 'se_block': # SE_block\n    net = se_block(net)\n  elif attention_module == 'cbam_block': # CBAM_block\n    net = cbam_block(net)\n  else:\n    raise Exception(\"'{}' is not supported attention module!\".format(attention_module))\n\n  return net","0fb0a733":"def se_block(input_feature, ratio=8):\n\t\"\"\"Contains the implementation of Squeeze-and-Excitation(SE) block.\n\tAs described in https:\/\/arxiv.org\/abs\/1709.01507.\n\t\"\"\"\n\t\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature.shape[channel_axis]#_keras_shape\u6539\u4e3ashape\n\n\tse_feature = GlobalAveragePooling2D()(input_feature)\n\tse_feature = Reshape((1, 1, channel))(se_feature)\n\tassert se_feature.shape[1:] == (1,1,channel)\n\tse_feature = Dense(channel \/\/ ratio,\n\t\t\t\t\t   activation='relu',\n\t\t\t\t\t   kernel_initializer='he_normal',\n\t\t\t\t\t   use_bias=True,\n\t\t\t\t\t   bias_initializer='zeros')(se_feature)\n\tassert se_feature.shape[1:] == (1,1,channel\/\/ratio)\n\tse_feature = Dense(channel,\n\t\t\t\t\t   activation='sigmoid',\n\t\t\t\t\t   kernel_initializer='he_normal',\n\t\t\t\t\t   use_bias=True,\n\t\t\t\t\t   bias_initializer='zeros')(se_feature)\n\tassert se_feature.shape[1:] == (1,1,channel)\n\tif K.image_data_format() == 'channels_first':\n\t\tse_feature = Permute((3, 1, 2))(se_feature)\n\n\tse_feature = multiply([input_feature, se_feature])\n\treturn se_feature","32a81998":"def cbam_block(cbam_feature, ratio=8):\n\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n\tAs described in https:\/\/arxiv.org\/abs\/1807.06521.\n\t\"\"\"\n\t\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature)\n\treturn cbam_feature","d1582903":"def channel_attention(input_feature, ratio=8):\n\t\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature.shape[channel_axis]\n\t\n\tshared_layer_one = Dense(channel\/\/ratio,\n\t\t\t\t\t\t\t activation='relu',\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\t\n\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel\/\/ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\t\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel\/\/ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\t\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('sigmoid')(cbam_feature)\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\n\treturn multiply([input_feature, cbam_feature])","c5af38f9":"def spatial_attention(input_feature):\n\tkernel_size = 7\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature.shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature.shape[-1]\n\t\tcbam_feature = input_feature\n\t\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool.shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool.shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat.shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tactivation='sigmoid',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\t\n\tassert cbam_feature.shape[-1] == 1\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\t\n\treturn multiply([input_feature, cbam_feature])","469b069e":"def lr_schedule(epoch):\n    \"\"\"Learning Rate Schedule\n\n    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n    Called automatically every epoch as part of callbacks during training.\n\n    # Arguments\n        epoch (int): The number of epochs\n\n    # Returns\n        lr (float32): learning rate\n    \"\"\"\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr","71d3f77d":"def resnet_layerv1(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n\n    # Arguments\n        inputs (tensor): input tensor from input image or previous layer\n        num_filters (int): Conv2D number of filters\n        kernel_size (int): Conv2D square kernel dimensions\n        strides (int): Conv2D square stride dimensions\n        activation (string): activation name\n        batch_normalization (bool): whether to include batch normalization\n        conv_first (bool): conv-bn-activation (True) or\n            bn-activation-conv (False)\n\n    # Returns\n        x (tensor): tensor as input to the next layer\n    \"\"\"\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","86f14721":"def resnet_layerv2(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n\n    # Arguments\n        inputs (tensor): input tensor from input image or previous layer\n        num_filters (int): Conv2D number of filters\n        kernel_size (int): Conv2D square kernel dimensions\n        strides (int): Conv2D square stride dimensions\n        activation (string): activation name\n        batch_normalization (bool): whether to include batch normalization\n        conv_first (bool): conv-bn-activation (True) or\n            bn-activation-conv (False)\n\n    # Returns\n        x (tensor): tensor as input to the next layer\n    \"\"\"\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","eee899fc":"def resnet_v1(input_shape1,input_shape2, depth, num_classes=8, attention_module=None):\n\n    if (depth - 2) % 6 != 0:\n        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) \/ 6)\n\n    inputs_v1 = Input(shape=input_shape1)\n    x_v1 = resnet_layerv1(inputs=inputs_v1)\n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y_v1 = resnet_layerv1(inputs=x_v1,\n                             num_filters=num_filters,\n                             strides=strides)\n            y_v1 = resnet_layerv1(inputs=y_v1,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x_v1 = resnet_layerv1(inputs=x_v1,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            # attention_module\n            if attention_module is not None:\n                y_v1 = attach_attention_module(y_v1, attention_module)\n            x_v1 = keras.layers.add([x_v1, y_v1])\n            x_v1 = Activation('relu')(x_v1)\n        num_filters *= 2\n\n    # Add classifier on top.\n    # v1 does not use BN after last shortcut connection-ReLU\n    x_v1 = AveragePooling2D(pool_size=8)(x_v1)\n    y_v1 = Flatten()(x_v1)\n    outputs_res_v1 = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y_v1)\n\n    if (depth - 2) % 9 != 0:\n        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n        # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) \/ 9)\n\n    inputs_v2 = Input(shape=input_shape2)\n    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n    x = resnet_layerv2(inputs=inputs_v2,\n                       num_filters=num_filters_in,\n                       conv_first=True)\n# resnet_v2\n    if (depth - 2) % 9 != 0:\n        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n    # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) \/ 9)\n\n    inputs_v2 = Input(shape=input_shape2)\n    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n    x_v2 = resnet_layerv2(inputs=inputs_v2,\n                          num_filters=num_filters_in,\n                          conv_first=True)\n    # Instantiate the stack of residual units\n    for stage in range(3):\n        for res_block in range(num_res_blocks):\n            activation = 'relu'\n            batch_normalization = True\n            strides = 1\n            if stage == 0:\n                num_filters_out = num_filters_in * 4\n                if res_block == 0:  # first layer and first stage\n                    activation = None\n                    batch_normalization = False\n            else:\n                num_filters_out = num_filters_in * 2\n                if res_block == 0:  # first layer but not first stage\n                    strides = 2  # downsample\n\n            # bottleneck residual unit\n            y_v2 = resnet_layerv2(inputs=x_v2,\n                                  num_filters=num_filters_in,\n                                  kernel_size=1,\n                                  strides=strides,\n                                  activation=activation,\n                                  batch_normalization=batch_normalization,\n                                  conv_first=False)\n            y_v2 = resnet_layerv2(inputs=y_v2,\n                                  num_filters=num_filters_in,\n                                  conv_first=False)\n            y_v2 = resnet_layerv2(inputs=y_v2,\n                                  num_filters=num_filters_out,\n                                  kernel_size=1,\n                                  conv_first=False)\n            if res_block == 0:\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x_v2 = resnet_layerv2(inputs=x_v2,\n                                   num_filters=num_filters_out,\n                                   kernel_size=1,\n                                   strides=strides,\n                                   activation=None,\n                                   batch_normalization=False)\n            # attention_module\n            if attention_module is not None:\n                y_v2 = attach_attention_module(y_v2, attention_module)\n\n            x_v2 = keras.layers.add([x_v2, y_v2])\n\n        num_filters_in = num_filters_out\n\n    # Add classifier on top.\n    # v2 has BN-ReLU before Pooling\n    x_v2 = BatchNormalization()(x_v2)\n    x_v2 = Activation('relu')(x_v2)\n    x_v2 = AveragePooling2D(pool_size=8)(x_v2)\n    y_v2 = Flatten()(x_v2)\n    outputs_res_v2 = Dense(num_classes,\n                           activation='softmax',\n                           kernel_initializer='he_normal')(y_v2)\n\n    outputs_merge = keras.layers.add([outputs_res_v1, outputs_res_v2])\n\n    # Instantiate model.\n    model = Model(inputs=[inputs_v1,inputs_v2], outputs=tensorflow.nn.sigmoid(outputs_merge))\n    return model #outputs_res_v1","4dc7fdd6":"def dataframe_creation():\n    df4 = pd.read_csv('..\/input\/ocular-disease-recognition-odir5k\/full_df.csv')\n    df4['filename']='..\/input\/ocular-disease-recognition-odir5k\/preprocessed_images\/'+df4['filename']\n    df4['Left-Fundus']='..\/input\/ocular-disease-recognition-odir5k\/preprocessed_images\/'+df4['Left-Fundus']\n    df4['Right-Fundus']='..\/input\/ocular-disease-recognition-odir5k\/preprocessed_images\/'+df4['Right-Fundus']\n    df4['Line'] = df4['Left-Diagnostic Keywords']+' | '+df4['Right-Diagnostic Keywords']\n    df4 = df4.drop(['filepath','target'], axis=1)\n    return df4","d1ecef18":"df = dataframe_creation()\nprint(df.shape)\ndf.head()\ndf['Patient Sex'].unique()\n\nw , h= 160,160#\nfinal_class = 8\n\nlistImg = os.listdir('..\/input\/ocular-disease-recognition-odir5k\/preprocessed_images')\nstring = '..\/input\/ocular-disease-recognition-odir5k\/preprocessed_images\/'\nlist2 = list(map(lambda orig_string: string + orig_string , listImg))\nindexify =[]\nfor i in df.index:\n    if df.iloc[i]['Left-Fundus'] in list2 and df.iloc[i]['Right-Fundus'] in list2:\n        continue\n    else:\n        indexify.append(i)\ndf = df.drop(indexify)\n\nfrom tqdm import tqdm\nleft = []\nfor location in tqdm(df.iloc[:]['Left-Fundus']):\n    img = cv2.imread(location,1)\n    img = cv2.resize(img, (w,h), interpolation = cv2.INTER_AREA)\n    img = img.reshape(w,h,3)\n    # \u56fe\u50cf\u589e\u5f3a\n    b, g, r = cv2.split(img)\n    # r = cv2.equalizeHist(r)\n    g =cv2.equalizeHist(g)\n    # b = cv2.equalizeHist(b)\n    img = cv2.merge([b, g, r])\n\n    left.append(img)\nright = []\n\nfor location in tqdm(df.iloc[:]['Right-Fundus']):\n    img = cv2.imread(location,1)\n    img = cv2.resize(img, (w,h), interpolation = cv2.INTER_AREA)\n    img = img.reshape(w,h,3)\n    # \u56fe\u50cf\u589e\u5f3a\n    b, g, r = cv2.split(img)\n    # r = cv2.equalizeHist(r)\n    g =cv2.equalizeHist(g)\n    # b = cv2.equalizeHist(b)\n    img = cv2.merge([b, g, r])\n    # img=cv2.equalizeHist(img)\n    right.append(img)\nX1 = np.array(left)\nX2 = np.array(right)\n\nfrom sklearn.preprocessing import OneHotEncoder\ny = np.array(df.iloc[:][['N','D','G','C','A','H','M','O']])\ny = np.array(y)\nprint('Label :   '+str(y.shape))","2826ffb6":"def load_image():\n    #\u5212\u5206\u5de6\u53f3\u773c\u6570\u636e\u96c6\n    from sklearn.model_selection import train_test_split\n    X_train1, X_test1, X_train2, X_test2, y_train, y_test = train_test_split(X1, X2, y, test_size=0.20, random_state=42)\n    X_train1, X_valid1, X_train2, X_valid2, y_train, y_valid = train_test_split(X_train1, X_train2, y_train, test_size=0.20, random_state=42)\n   \n    return X1, X2, y, X_train1, X_test1, X_train2, X_test2, X_valid1, X_valid2, y_train, y_test, y_valid","d4ae6af2":"attention_module = 'cbam_block'\ndepth = 56\nbatch_size = 5\nepochs = 100\n\nstart_time = time.time()\n\nX1, X2, y, X_train1, X_test1, X_train2, X_test2, X_valid1, X_valid2, y_train, y_test, y_valid=load_image()","cf918f8b":"# Input image dimensions.\ninput_shape_v1 = X_train1.shape[1:]\ninput_shape_v2 = X_train2.shape[1:]\ninput_shape_merge= X_train1.shape[1:]","89fc5578":"model = resnet_v1(input_shape1=input_shape_v1,input_shape2=input_shape_v2, depth=depth, attention_module=attention_module)\n# model.summary()\nplot_model(model, show_shapes=True, show_layer_names=True, expand_nested=False, to_file='resnet_v1_v2_network.png')\n\nmetrics = [\n\n    keras.metrics.TruePositives(name='tp'),\n    keras.metrics.FalsePositives(name='fp'),\n    keras.metrics.TrueNegatives(name='tn'),\n    keras.metrics.FalseNegatives(name='fn'), \n    keras.metrics.BinaryAccuracy(name='accuracy'),\n    keras.metrics.Precision(name='precision'),\n    keras.metrics.Recall(name='recall'),\n    keras.metrics.AUC(name='auc'),\n        ]\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(learning_rate=lr_schedule(0)),\n              metrics=metrics)\n\nhistory = model.fit([X_train1, X_train2], y_train,\n                    epochs=epochs,\n                    batch_size=5,\n                    validation_data=([X_valid1,X_valid2],y_valid)\n                    # callbacks=keras.callbacks.EarlyStopping(\n                    #     monitor='val_loss',\n                    #     min_delta=0,\n                    #     patience=20,\n                    #     verbose=2,\n                    #     mode='max')\n                   )\n                    # batch_size=batch_size,\n                    # validation_data=(x_test, y_test),\n                    # shuffle=True, \n                    # callbacks=callbacks)\nhist_df = pd.DataFrame(history.history)\nhist_df.to_csv('128_Every_Epoch_df_enhance.csv',index=False)","22a33bbc":"# \u6bcf\u4e2aepoch\u7684acc\u548closs\u503c \ntime_model = time.time() - start_time \nprint(f\"Time to train the model: {int(time_model)} seconds\")","6c922acb":"# name_all = \"256_Every_Epoch_df.csv\"\n# name_train = \"256_train_score.csv\"\n# name_valid = \"256_valid_score.csv\"\n# name_test = \"256_test_score.csv\"\n# name_diease = '256_Class_Wise_Accuracy.csv'\n# name_model = '256_ODIR_ResNet'\n\nname_all = \"128_Every_Epoch_df_enhance.csv\"\nname_train = \"128_train_score_enhance.csv\"\nname_valid = \"128_valid_score_enhance.csv\"\nname_test = \"128_test_score_enhance.csv\"\nname_diease = '128_Class_Wise_Accuracy_enhance.csv'\nname_model = '128_ODIR_ResNet_enhance'","6cd19f09":"#\u4fdd\u5b58\u6a21\u578b\n# model_json = model.to_json()\n# # name = 'ODIR_ResNet_32'\n# with open(name_model + \".json\", \"w\") as json_file:\n#     json_file.write(model_json)\n# model.save_weights(name_model + \".h5\")\nfrom tensorflow.keras.models import model_from_json\nmodel_json = model.to_json()\nname = 'ODIR_ResNet'\nwith open(name+\".json\", \"w\") as json_file:\n    json_file.write(model_json)\nmodel.save_weights(name+\".h5\")\nimport pandas as pd\nhist_df = pd.DataFrame(history.history) \nhist_df.to_csv(name+'.csv',index = False)\nhist_df.tail()","7f749215":"# METRICS = [\n#                 'accuracy',\n#                 tensorflow.keras.metrics.FalseNegatives(),\n#                 tensorflow.keras.metrics.FalsePositives(),\n#                 tensorflow.keras.metrics.Precision(),\n#                 tensorflow.keras.metrics.Recall(),\n#                 tensorflow.keras.metrics.TrueNegatives(),\n#                 tensorflow.keras.metrics.TruePositives()\n#         ] ","4c8489c2":"json_file = open('.\/'+name+'.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\".\/\"+name+\".h5\")\nprint(\"Loaded model from disk\")","4c965595":"loaded_model.compile(\n                optimizer='Adam',\n                loss='binary_crossentropy',\n                metrics=metrics\n            )","162a1ac1":"# score = loaded_model.evaluate([X1,X2], y, verbose=0)","882c8fc3":"# \u8bad\u7ec3\u96c6\u7684\u6307\u6807\ntrain_score = loaded_model.evaluate([X1, X2], y, verbose=0)\n\nfor i in range(len(train_score)):\n    print(loaded_model.metrics_names[i] + \" : \" + str(train_score[i]))\ntrain_score_pd = pd.DataFrame(train_score)\ntrain_score_pd.to_csv(name_train, index=False)","033b58c8":"# \u9a8c\u8bc1\u96c6\u6307\u6807\nvalid_score = loaded_model.evaluate([X_valid1, X_valid2], y_valid, verbose=0)\nfor i in range(len(valid_score)):\n    print(loaded_model.metrics_names[i] + \" : \" + str(valid_score[i]))\nvalid_score_pd = pd.DataFrame(train_score)\nvalid_score_pd.to_csv(name_valid, index=False)","20c47880":"# \u6d4b\u8bd5\u96c6\u6307\u6807\ntest_score = loaded_model.evaluate([X_test1,X_test2], y_test, verbose=0)\nfor i in range(len(test_score)):\n    print(loaded_model.metrics_names[i] + \" : \" + str(test_score[i]))\ntest_score_pd = pd.DataFrame(test_score)\ntest_score_pd.to_csv(name_test, index=False)","f1e5e05e":"def plot_metrics(history):\n    metrics =  ['loss', 'accuracy', 'precision', 'recall']\n    for n, metric in enumerate(metrics):\n        name = metric\n        plt.subplot(2,2,n+1)\n        plt.plot(history.epoch,  history.history[metric],  label='Train')\n        plt.plot(history.epoch, history.history['val_'+metric],\n                 linestyle=\"--\", label='Val')\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        if metric == 'loss':\n            plt.ylim([0, plt.ylim()[1]])\n        elif metric == 'auc':\n            plt.ylim([0.8,1])\n        else:\n            plt.ylim([0,1])\n        plt.legend()\n        plt.savefig('train_'+metric)\n        plt.show()\n# train_score\nplot_metrics(history)","c64a0c0d":"# \u6bcf\u79cd\u75be\u75c5\u7684\u9884\u6d4b\u5206\u6570\nyhat = model.predict([X_test1, X_test2])\nyhat = yhat.round()\nprint(yhat)\nprint(y_test)\n# report=accuracy_score(y_test, np.argmax(yhat, axis=1))\nreport = classification_report(y_test, yhat)\n","081154cc":"# \u6a21\u578b\u7ed3\u6784","aeca80a0":"# \u8ba1\u7b97\u53c2\u6570","40b688fe":"\u7a7a\u95f4\u6ce8\u610f\u529b","e35806e0":"# \u83b7\u53d6\u6570\u636e","b9239747":"\u901a\u9053\u6ce8\u610f\u529b","e4eefa01":"# \u6ce8\u610f\u529b\u6a21\u5757","c900d726":"# \u5efa\u7acb\u6a21\u578b\u5e76\u8bad\u7ec3","bbcc677d":"# \u8bbe\u7f6e\u8d85\u53c2\u6570\uff0c\u83b7\u53d6\u6570\u636e\u96c6"}}