{"cell_type":{"2ec9fad8":"code","4648d50c":"code","dc3de0fa":"code","d4522b2d":"code","f0df4153":"code","8025dd5f":"code","fd272c63":"code","dd128f5c":"code","932c80d5":"code","f1dc1c68":"code","941a117e":"code","ead06c43":"code","a54e3d14":"code","7e7775e4":"code","e4eb39c8":"code","6975d68d":"code","19ffc167":"code","173a77c2":"code","74c37815":"code","cbdf05fa":"code","c068b631":"code","d9b6ce27":"code","1dba0a3a":"code","7e8523ff":"code","1047826a":"code","aca8c9ac":"code","2c956aae":"code","3f4f678d":"code","fa57dbef":"code","1ba2dc1b":"code","9c42d4a8":"code","db002049":"code","1df653c0":"code","9a3bd0cd":"code","1170a78d":"code","4ba51d38":"code","260be221":"code","eb45ca87":"code","0f7eaf61":"code","68685bc6":"code","f6c28452":"code","b7b956c3":"code","ee109ef5":"code","0a7f8965":"code","b2921820":"code","5ff3d85c":"code","93dd9dcd":"code","26cb9d42":"code","bbe5fe9b":"code","e746100c":"code","d2c246fd":"code","691809bc":"code","a1b2f267":"code","ce589b39":"code","cc6b5e23":"code","a37a04ff":"code","8941efa4":"code","73674a07":"code","eb1f6a0a":"code","10d73b3c":"code","3f226fe9":"code","21609dea":"code","6ae78575":"code","99e42682":"markdown","380c8833":"markdown","ef0e8585":"markdown","c0358012":"markdown","da5a8501":"markdown","76edf17a":"markdown","58e25251":"markdown","292f56f1":"markdown","be84ef75":"markdown","94f6fb57":"markdown","4ea3ec7e":"markdown","0c2cb806":"markdown","3197ca71":"markdown","941f8cd9":"markdown","449856db":"markdown","130f1e1d":"markdown","fb287bfe":"markdown","f33f49f0":"markdown","545c9d26":"markdown","7258cc02":"markdown","cc966afd":"markdown","e62efd7f":"markdown","6909fb73":"markdown","f6e638a5":"markdown","af11b911":"markdown","37e4c35d":"markdown","a324f378":"markdown","2ec8e425":"markdown","eb4087e7":"markdown","0f3c8ece":"markdown","51313886":"markdown","58974c73":"markdown","9c191edf":"markdown","3b2dd749":"markdown","6076842d":"markdown","7e93f3c8":"markdown","262efb74":"markdown","95795717":"markdown","b41fd5e2":"markdown","c1fdee35":"markdown","c0afa229":"markdown","af4d53fa":"markdown","809986bb":"markdown","053a0e9a":"markdown","ee7590b8":"markdown","3dd14706":"markdown","0ca949a3":"markdown","ef9b3f20":"markdown"},"source":{"2ec9fad8":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport json\nimport folium\nfrom IPython.display import HTML\nfrom branca.colormap import linear\n\nfrom catboost import CatBoostRegressor, Pool\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.stem import LancasterStemmer\nfrom nltk.tokenize import RegexpTokenizer\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","4648d50c":"data = pd.read_csv(\"..\/input\/chocolate-bar-ratings\/flavors_of_cacao.csv\")\ndata.head()","dc3de0fa":"data.columns","d4522b2d":"new_names = {\n     data.columns[0]: 'company',\n    'Specific Bean Origin\\nor Bar Name': 'bar_origin',\n    'REF': 'review_update_value',\n    'Review\\nDate': 'review_pub_date',\n    'Cocoa\\nPercent': 'cocoa_percentage',\n    'Company\\nLocation': 'company_location',\n    'Rating': 'rating',\n    'Bean\\nType': 'bean_type',\n    'Broad Bean\\nOrigin': 'bean_origin'\n}\ndata = data.rename(new_names, axis='columns')","f0df4153":"data.head(1)","8025dd5f":"def clean_cocperc(l):\n    fractions = l.split(\"%\")\n    return np.float32(fractions[0])\n\ndata.cocoa_percentage = data.cocoa_percentage.apply(lambda l: clean_cocperc(l))","fd272c63":"data.info()","dd128f5c":"data.rating = data.rating.apply(pd.to_numeric)","932c80d5":"data.head(10)","f1dc1c68":"for n in range(10):\n    value = data.bean_type.values[n]\n    instance_of = type(value)\n    print(\"This entry is of type {} and has the value {} and a length of {}\".format(instance_of, value, len(value)))","941a117e":"emptyness = data.bean_type.values[0]","ead06c43":"def turn_to_nan(l):\n    if l == emptyness:\n        return np.nan\n    else:\n        return l\n\nfor col in data.columns:\n    if data[col].dtype == 'O':\n        data[col] = data[col].apply(lambda l: turn_to_nan(l))","a54e3d14":"missing = data.isnull().sum()\nmissing = missing[missing > 0]\n\nplt.figure(figsize=(8,5))\nsns.barplot(x=missing.index, y=missing.values, palette=\"Purples\")\nplt.ylabel(\"Counts of missing values\");","7e7775e4":"rating_counts = data.rating.value_counts()\n\nplt.figure(figsize=(20,5))\nsns.barplot(x=rating_counts.index, y=rating_counts.values, palette=\"Greens\")\nplt.xlabel(\"Rating value\")\nplt.ylabel(\"Counts\")\nplt.title(\"Which rating counts are most common?\");","e4eb39c8":"def map_to_rating(l):\n    if l <= 2:\n        return 1\n    elif 2 < l <= 2.5:\n        return 2\n    elif 2.5 < l <= 3:\n        return 3\n    elif 3 < l <= 3.5:\n        return 4\n    elif 3.5 < l <= 3.75:\n        return 5\n    else:\n        return 6","6975d68d":"data[\"new_rating\"] = data.rating.apply(lambda l: map_to_rating(l))","19ffc167":"plt.figure(figsize=(20,5))\nsns.countplot(data.bean_type)\nplt.xticks(rotation=90);\nplt.title(\"Bean types\");","173a77c2":"data.bean_type.isnull().value_counts() \/ len(data) * 100","74c37815":"def check_bean(l, name):\n    l = l.lower()\n    if name in l:\n        return 1\n    return 0\n\ndata[\"criollo_bean\"] = data.bean_type.dropna().apply(lambda l: check_bean(l, \"criollo\"))\ndata[\"forastero_bean\"] = data.bean_type.dropna().apply(lambda l: check_bean(l, \"forastero\"))\ndata[\"trinitario_bean\"] = data.bean_type.dropna().apply(lambda l: check_bean(l, \"trinitario\"))\ndata[\"amazon_bean\"] = data.bean_type.dropna().apply(lambda l: check_bean(l, \"amazon\"))","cbdf05fa":"data[\"num_beans\"] = data.loc[\n    :,[\"criollo_bean\", \"forastero_bean\", \"trinitario_bean\", \"amazon_bean\"]\n].sum(axis=1)","c068b631":"blend_names = data.bean_type.dropna().apply(lambda l: np.where(\"blend\" in l.lower(), 1, 0))\nis_blend_idx = blend_names.loc[blend_names == 1].index.values\n\ndata[\"blend\"] = 0\ndata.loc[(data.num_beans > 1) | (data.index.isin(is_blend_idx)), \"blend\"] = 1 ","d9b6ce27":"data[\"missing_bean_type\"] = np.where(data.bean_type.isnull()==True, 1, 0)\ndata.missing_bean_type.value_counts()","1dba0a3a":"bean_type_counts = data.loc[\n    :,[\"criollo_bean\", \"forastero_bean\", \"trinitario_bean\", \"amazon_bean\"]\n].sum(axis=0)\n\nfig, ax = plt.subplots(2,2,figsize=(20,10))\n\nsns.barplot(x=bean_type_counts.index, y=bean_type_counts.values, ax=ax[0,0], palette=\"Set2\")\nsns.countplot(data.loc[data.missing_bean_type==0].blend, ax=ax[1,0], palette=\"Set2\");\nsns.countplot(data.loc[data.missing_bean_type==0].num_beans, ax=ax[0,1], palette=\"Set2\");","7e8523ff":"len(data.bean_origin.unique())","1047826a":"top_counts = data.bean_origin.value_counts().head(10)\nsparse_counts = data.bean_origin.value_counts().tail(10)\n\nplt.figure(figsize=(20,5))\nsns.barplot(x=top_counts.index, y=top_counts.values, palette=\"Blues_r\")\nplt.title(\"Where do most beans come from?\")\nplt.ylabel(\"count\");","aca8c9ac":"sparse_counts","2c956aae":"fig, ax = plt.subplots(1,2, figsize=(20,5))\nsns.distplot(data.bean_origin.value_counts(), ax=ax[0], color=\"Red\")\nsns.distplot(data.bean_origin.value_counts() \/ data.bean_origin.count() * 100, ax=ax[1], color=\"darkred\")\nax[0].set_xlabel(\"Number of counts\");\nax[0].set_ylabel(\"Frequency density\");\nax[0].set_title(\"Which value counts of bean types are most common?\")\nax[1].set_xlabel(\"Occurence in data in %\");\nax[1].set_ylabel(\"Frequency density\");\nax[1].set_title(\"How many % of the data are occupied by such counts?\");","3f4f678d":"stemmer=LancasterStemmer()\n\ndef stem(l):\n    tokenizer = RegexpTokenizer(r'\\w+')\n    token_words = tokenizer.tokenize(l)\n    stem_sentence=[]\n    for word in token_words:\n        stem_sentence.append(stemmer.stem(word))\n        stem_sentence.append(\" \")\n    return \"\".join(stem_sentence)\n\ndata[\"stemmed_bean_origin\"] = data.dropna().bean_origin.apply(lambda l: stem(l))","fa57dbef":"len(data.stemmed_bean_origin.unique())","1ba2dc1b":"data.dropna().groupby(\"stemmed_bean_origin\").bean_origin.value_counts().tail(10)","9c42d4a8":"vectorizer = CountVectorizer()\ncorpus = data.dropna().stemmed_bean_origin.values\nword_counts = vectorizer.fit_transform(corpus)\nword_counts.shape","db002049":"names = vectorizer.get_feature_names()","1df653c0":"word_counts_df = pd.DataFrame(index=data.dropna().index.values, data=word_counts.toarray(), columns=names)\nsingle_origin_counts = word_counts_df.sum().sort_values(ascending=False)\n\n\nplt.figure(figsize=(21,8))\nsns.barplot(single_origin_counts.index, single_origin_counts.values)\nplt.xticks(rotation=90);","9a3bd0cd":"col = \"papu\"\nviewer = word_counts_df[word_counts_df[col] == 1].sum()\nviewer[viewer > 0]","1170a78d":"def fuse_words(words):\n    return np.where(word_counts_df.loc[:, words].sum(axis=1) == len(words), 1, 0)","4ba51d38":"word_counts_df[\"domin_republ\"] = fuse_words([\"domin\", \"republ\"])\nword_counts_df[\"domint_republ\"] = fuse_words([\"domint\", \"republ\"])\nword_counts_df[\"dom_rep\"] = fuse_words([\"dom\", \"rep\"])\n\nword_counts_df[\"sao_tom\"] = fuse_words([\"sao\", \"tom\"])\nword_counts_df[\"papu_new_guine\"] = fuse_words([\"papu\", \"new\", \"guine\"])\nword_counts_df[\"cost_ric\"] = fuse_words([\"cost\", \"ric\"])\nword_counts_df[\"west_afric\"] = fuse_words([\"west\", \"afric\"])\nword_counts_df[\"st_luc\"] = fuse_words([\"st\", \"luc\"])\nword_counts_df[\"sou_americ\"] = fuse_words([\"sou\", \"americ\"])\nword_counts_df[\"sri_lank\"] = fuse_words([\"sri\", \"lank\"])\n\nword_counts_df = word_counts_df.drop(\n    [\"domin\", \"republ\", \"dom\", \"rep\", \"sao\", \"tom\", \"papu\", \"new\", \"guine\",\n     \"cost\", \"ric\", \"west\", \"afric\", \"st\", \"luc\", \"sou\", \"americ\", \"domint\",\n     \"sri\", \"lank\"], axis=1)","260be221":"def get_indices(col):\n    return word_counts_df.loc[word_counts_df[col] == 1].index.values","eb45ca87":"word_counts_df.loc[get_indices(\"ven\"), \"venezuel\"] = 1\nword_counts_df.loc[get_indices(\"princip\"), \"sao_tom\"] = 1\nword_counts_df.loc[get_indices(\"png\"), \"papu_new_guine\"] = 1\nword_counts_df.loc[get_indices(\"jam\"), \"jamaic\"] = 1\nword_counts_df.loc[get_indices(\"gre\"), \"grenad\"] = 1\nword_counts_df.loc[get_indices(\"haw\"), \"hawai\"] = 1\nword_counts_df.loc[get_indices(\"mad\"), \"madagasc\"] = 1\n\ntrinidad_index = set(get_indices(\"tri\")).union(get_indices(\"tobago\"))\nword_counts_df.loc[trinidad_index, \"trinidad\"] = 1\n\ndomin_index = set(get_indices(\"domint_republ\")).union(\n    set(get_indices(\"dom_rep\"))).union(\n    get_indices(\"dr\"))\nword_counts_df.loc[domin_index, \"domin_republ\"] = 1\n\n\nword_counts_df = word_counts_df.drop(\n    [\"ven\", \"domint_republ\", \"dom_rep\", \"dr\",\n     \"princip\", \"tri\", \"tobago\", \"jam\", \"gre\", \n     \"haw\", \"png\", \"mad\"], axis=1)","0f7eaf61":"len(word_counts_df.columns.values)","68685bc6":"prepared_data = data.copy()\nprepared_data.drop(\"bean_origin\", axis=1, inplace=True)\nprepared_data = prepared_data.join(word_counts_df)\nprepared_data.head()","f6c28452":"prepared_data.drop(\"stemmed_bean_origin\", axis=1, inplace=True)","b7b956c3":"prepared_data.columns","ee109ef5":"origin_names = {\n    \"venezuel\": \"VEN\",\n    \"boliv\": \"BOL\",\n    \"vietnam\": \"VNM\",\n    \"sri_lank\": \"LKA\",\n    \"st_luc\": \"LC\",\n    \"cost_ric\": \"CR\",\n    \"papu_new_guine\": \"PG\",\n    \"sao_tom\": \"STP\",\n    \"domint_republ\": \"DOM\",\n    \"vanuatu\": \"VUT\",\n    \"ugand\": \"UGA\",\n    \"trinidad\": \"TTO\",\n    \"tanzan\": \"TZA\",\n    \"surinam\": \"SUR\",\n    \"philippin\": \"PHL\",\n    \"peru\": \"PER\",\n    \"panam\": \"PAN\",\n    \"nicaragu\": \"NIC\",\n    \"mexico\": \"MEX\",\n    \"malays\": \"MYS\",\n    \"madagasc\": \"MDG\",\n    \"jamaic\": \"JAM\",\n    \"indones\": \"IDN\",\n    \"ind\": \"IND\",\n    \"hondura\": \"HND\",\n    \"hait\": \"HTI\",\n    \"guatemal\": \"GTM\",\n    \"grenad\": \"GRD\",\n    \"ghan\": \"GHA\",\n    \"fij\": \"FJI\",\n    \"ecuad\": \"ECU\",\n    \"cub\": \"CUB\",\n    \"congo\": \"COG\",\n    \"colomb\": \"COL\",\n    \"cameroon\": \"CMR\",\n    \"brazil\": \"BRA\",\n    \"bel\": \"BLZ\",\n    \"carrib\": \"BQ\",\n    \"bal\": \"Bali\",\n    \"hawai\": \"Hawai\",\n    \"jav\": \"Java\"\n}","0a7f8965":"top_bean_origins = data.bean_origin.value_counts().head(20)","b2921820":"data.loc[data.bean_origin.isin(top_bean_origins.index),:].shape[0] \/ data.shape[0] * 100","5ff3d85c":"focus_data = data.loc[data.bean_origin.isin(top_bean_origins.index),:].copy()\nbean_origin_ratings = focus_data.groupby(\"bean_origin\").new_rating.mean()","93dd9dcd":"geo_json_data = json.load(open(\"..\/input\/python-folio-country-boundaries\/world-countries.json\"))","26cb9d42":"colormap = linear.YlGnBu_09.scale(\n    bean_origin_ratings.min(),\n    bean_origin_ratings.max())\n\nused_names = []\ndef make_color(feature):\n    current_country = feature['properties']['name']\n    if current_country in bean_origin_ratings.index.values:\n        used_names.append(current_country)\n        return colormap(bean_origin_ratings[feature['properties']['name']])\n    else:\n        return \"floralwhite\"","bbe5fe9b":"m = folium.Map([0,0], zoom_start=1.5)\n\nfolium.GeoJson(\n    geo_json_data,\n    name='mean ratings of bean origin',\n    style_function=lambda feature: {\n        'fillColor': make_color(feature),\n        'color': 'grey',\n        'weight': 1,\n        'dashArray': '3, 3',\n        'fillOpacity': 0.8,\n    }\n).add_to(m)\n\ncolormap.caption = 'mean ratings of bean origin'\ncolormap.add_to(m)\nfolium.LayerControl().add_to(m)\n\nm.save(\"bean_origin_ratings.html\")\nHTML('<iframe src=bean_origin_ratings.html width=800 height=450><\/iframe>')","e746100c":"set(bean_origin_ratings.index.values).difference(set(used_names))","d2c246fd":"fig, ax = plt.subplots(2,2,figsize=(20,10))\n\nsns.distplot(data.cocoa_percentage, kde=False, color=\"sienna\", ax=ax[0,0])\nax[0,0].set_xlabel(\"% of cocoa\")\nax[0,0].set_ylabel(\"frequency\")\nax[0,0].set_title(\"Distribution of cocoa percentage\");\n\nsns.kdeplot(data.new_rating, data.cocoa_percentage, cmap=\"Reds\", shade=True, n_levels=20,\n            shade_lowest=False, ax=ax[0,1]);\nax[0,1].scatter(data.new_rating, data.cocoa_percentage, s=0.5, c=\"Brown\")\nax[0,1].set_ylabel(\"% of cocoa\")\nax[0,1].set_xlabel(\"rating\");\nax[0,1].set_title(\"Cocoa percentage vs. rating of chocolate bar\");\n\nsns.violinplot(x=data.new_rating, y=data.cocoa_percentage, ax=ax[1,0], palette=\"Reds\")\nsns.boxplot(x=data.new_rating, y=data.cocoa_percentage, ax=ax[1,1], palette=\"Reds\");","691809bc":"print(\"The first review was published {} and the last {}.\".format(\n    data.review_pub_date.min(), data.review_pub_date.max()))","a1b2f267":"prepared_data.head()","ce589b39":"prepared_data[\"company\"] = prepared_data[\"company\"].astype(\"category\")\nprepared_data[\"bar_origin\"] = prepared_data[\"bar_origin\"].astype(\"category\")\nprepared_data[\"company_location\"] = prepared_data[\"company_location\"].astype(\"category\")\nprepared_data[\"bean_type\"] = prepared_data[\"bean_type\"].astype(\"category\")\nprepared_data[\"review_update_value\"] = prepared_data[\"review_pub_date\"].astype(\"category\")","cc6b5e23":"prepared_data.dropna(inplace=True)\n\nto_drop = [\"rating\", \"new_rating\"]\nX = prepared_data.drop(to_drop, axis=1).copy()\ny = prepared_data.rating","a37a04ff":"cat_idx = []\nfor n in range(0, len(X.columns.values)):\n    col = X.columns.values[n]\n    col_type = X[col].dtype\n    if col_type.name == \"category\":\n        cat_idx.append(n)\nprint(len(cat_idx))","8941efa4":"x_train, x_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=0)","73674a07":"train_pool = Pool(x_train.values, y_train.values, cat_features=cat_idx)\ntest_pool = Pool(x_test.values, y_test.values, cat_features=cat_idx)","eb1f6a0a":"model = CatBoostRegressor(iterations=50, \n                           depth=3, \n                           learning_rate=1, \n                           loss_function='RMSE', \n                           logging_level='Verbose')","10d73b3c":"model.fit(train_pool)","3f226fe9":"# make the prediction using the resulting model\npreds = model.predict(test_pool)\nprint(preds[0:10])","21609dea":"y_test[0:10]","6ae78575":"importances = model.get_feature_importance()\nbest_idx = np.argsort(importances)[::-1][:10]\n\nplt.figure(figsize=(20,5))\nsns.barplot(x=X.columns.values[best_idx], y=np.array(importances)[best_idx], palette=\"Reds_r\")\nplt.xticks(rotation=90);","99e42682":"Ihh! :-) Ok, however this empty string looks like, we should transform it to np.nan and we should check whether this type of missing value representation was used in other object columns as well:","380c8833":"### What is given by the chocolate rating? <a class=\"anchor\" id=\"rating\"><\/a>\n\nThe dataset description says...\n\n1. Unpleasant (Mostly unpalatable)\n2. Disappointing\n3. Satisfactory (3) to praiseworthy (3.5)\n4. Premium\n5. Elite","ef0e8585":"Ok, almost 50 % are missing. Now, we need to setup some strategy how to deal with the bean types. A first attempt could be to focus on the names that occur most often:\n\n* Criollo\n* Trinitario\n* Forastero\n* Amazon\n\nIn addition we can see that most chocolate bars have mixed bean types and we may create a feature that counts how many of these 4 bean types are included. ","c0358012":"### Take-Away\n\n* The column names look a bit strange. It seems that they include newlines and I like to rename them for more comfortable work.\n* In addition we can see that the features need some more preprocessing and cleaning. Take a look at cocoa percent - you can see the annoying % symbol. \n* There are at least some missing values in the bean type. ","da5a8501":"### What bean types do we have? <a class=\"anchor\" id=\"bean_types\"><\/a>","76edf17a":"Ok, that sounds not so much. But nonetheless we may have redundant information that tells us the same only in different words. ","58e25251":"Ok, to get started, let's drop all missing values. I like to use some other models later that are able to fill in missing values... but at the moment just drop them ;-) ...","292f56f1":"### Where have all our missing values gone?","be84ef75":"## Exploring the flavours of chocolate... <a class=\"anchor\" id=\"eda1\"><\/a>\n\nIn this first exploratory data analysis I like to get an first intuition about the data. Perhaps we will gain some insights that may already help to understand what makes a chocolate bar tasty. I like to start with the important feature *rating* that I will use as a target for prediction later on. ","94f6fb57":"## Cleaning up the data <a class=\"anchor\" id=\"cleaning\"><\/a>\n\n### Getting rid of % in the cocoa percentages ","4ea3ec7e":"Ok, only ven is not recognized well. Perhaps we will find a way to tackle that, but I think this is sufficient to start with.","0c2cb806":"How much data is covered by these origins? How much data would we loose by skipping the others?","3197ca71":"Ok, let's start:","941f8cd9":"Ok, at a first glance everything looks nice now, but....\n\n* the rating should be of type float instead of object,\n* bean_type has only one missing value even though we can see a lot of empty rows in data.head\n\nThat's strange and perhaps this behaviour does not only hold for this feature. Ohoh! ","449856db":"Again, I feel astrong need to fuse bean types and turn them to something more general. In addition we know that we have a lot of missing values for the bean type. Let's check how many:","130f1e1d":"Ok, that's it.","fb287bfe":"Ok, first of all, let's see how many different origins are mentioned for the cocoa beans:","f33f49f0":"We can already see that we have some origins that can be easily fused with some of the top counts: Venezuela, Peru, Dominican Republic... To fuse categories it might be useful to know the distribution of value counts:","545c9d26":"** under construction ** ","7258cc02":"### Extracting bean origin codes\n\nWork in progress","cc966afd":"Now, how many different bean origins are left?","e62efd7f":"### What features can we find in this dataset?","6909fb73":"In addition it's useful to generate a feature that shows us if the bean type was missing:","f6e638a5":"Great! By focusing on the top 10 bean origins ... throwing the other away ... we still cover around 81 % of the data. Before I try to regain the lost information, let's explore if the quality of the chocolate is related to its bean origin. For this purpose I like to use folium. ","af11b911":"Interestingly chocolate with very high % of cocoa have a tendency to be not delicious. This might be related to bitter compounds in cocoa. In addition we can see that the distributions or cocoa percentage become narrower with increasing rates. It seems that all good chocolate bars have cocoa percentages close to 70 %. ","37e4c35d":"Jeha! We have turned 34 bean origins to some that are only named a bit differently. How does it look like for Venezuela?","a324f378":"Let's specify new column names. I was not able to rename the first column as the others and this is the reason why you see data.columns[0] instead of the original \"Company...\" name:","2ec8e425":"#### Exploring the ratings of bean origins - Focusing on the top\n\nTo get started I like to focus on the most common, top 10, bean origins:","eb4087e7":"Take a look at papua new guinea: It was splitted into three parts - papu, new, guine. Consequently if we compute the total number of origins for one entry it would add 3 instead of 1. Let's try to rework this part. To find pairs that I'm not sure of, I like to use this kind of filter:","0f3c8ece":"### Where do the beans come from? <a class=\"anchor\" id=\"bean_origin\"><\/a>","51313886":"#### Stemming bean origins\n\nOk, we have seen that many words acutally mean the same: Take a look at Venezuela. You can find words like Ven that are likely to be an abbreviation of Venezuela. In addition we can see that we sometimes have multiple origins for one entry. I'm new to natural language processing but as my attempt of this kernel is to learn I like to try out some methods. :-)\n\nThis first is **stemming: It reduces a word to its root which is called stem**. Consequenly different words can have the same stem. In contrast to lemmatization this stem **need not be a valid word in the current language**. I think this technique could be useful for our problem. Let's try to find out, if it helps:","58974c73":"Ok, this is sufficient for an experiment:","9c191edf":"How many bean origins are left now?","3b2dd749":"Crazy. The description says that we can find sublevels in the 3-rating category but as you can see they also appear for the 1 and 2 ratings and with more sublevels. I think it's not very useful to have such splittings in case of unpleasant chocolate bars. It should be sufficient to know that you can't enjoy the bar instead of knowing each subtle nuance of bad taste. ","6076842d":"### How much cocoa is contained in good chocolate? <a class=\"anchor\" id=\"cocoa\"><\/a>\n","7e93f3c8":" We can see that there are some origins of the top 10 that are more likely to yield a high quality chocolate bar. But which names were not used? (Have to fix this!)","262efb74":"### What is the specific geo region of a bean or chocolate bar? <a class=\"anchor\" id=\"geo_region\"><\/a>","95795717":"### When were the ratings published and updated?  <a class=\"anchor\" id=\"review_date\"><\/a>","b41fd5e2":"### Renaming the columns","c1fdee35":"## Hi Kaggler! :-)\n\nDo you know what characterizes good chocolate? Is it the type of beans or where they come from? Our is the taste already predetermined by the company that has produced it?\n\n<a title=\"Keith Weller, USDA ARS [Public domain], via Wikimedia Commons\" ref=\"https:\/\/commons.wikimedia.org\/wiki\/File:Cacao-pod-k4636-14.jpg\"><img width=\"512\" alt=\"Cacao-pod-k4636-14\" src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/01\/Cacao-pod-k4636-14.jpg\/512px-Cacao-pod-k4636-14.jpg\"><\/a>\n\nWith this kernel I invite you to find it out. Given the dataset of chocolate bar ratings we will explore the features of the dataset, perform **data cleaning as well as preprocessing**. Using catboost as our model to predict chocolate ratings we will try to **generate new features** that may boost our model performance. By the way we will **dive into the catboost library and try out different functionalities**. If you like my notebook **you can make me very happy with an upvote and\/or comment**. This way it's much more fun to share learning pathways. :-)\n\n### I like to know...\n\n* What properties does good chocolate have?\n* Where does good chocolate come from? \n* The darker the chocolate the better?\n* Are there companies that are more likely to produce good chocolate? If so, are they more unknown, small ones or common big companies?\n* Can we predict the rating of a chocolate?\n\n### Table of contents\n\n1. [Loading packages and data](#load) \n2. [Data cleaning](#cleaning) (complete)\n3. [EDA - Level 1 - Exploring the flavours of chocolate](#eda1)\n    * [What is given by the chocolate rating?](#rating) (complete)\n    * [What bean types do we have?](#bean_type) (complete)\n    * [Where do the beans come from?](#bean_origin) (almost complete)\n    * [What is the specific geo region of the chocolate bar or bean?](#geo_region)\n    * [How much cocoa is contained in good chocolate?](#cocoa) (complete)\n    * [When were the ratings published and updated?](#review_date)\n4. [Building up a validation strategy](#validation)\n5. [Setting up baseline models with Catboost](#catboost)\n6. [Analysing results](#results)\n7. [EDA - Level 2 - Feature engineering](#eda2)\n8. [Lift off models & turn to final predictions](#final)","c0afa229":"## Loading packages and data <a class=\"anchor\" id=\"load\"><\/a>","af4d53fa":"## Predicting the chocolate rating with catboost <a class=\"anchor\" id=\"catboost\"><\/a>\n\n**This part is heavily under construction and has currently nothing great to show**\n\nI'm new to catboost and one reason to start this kernel was to get started with it and to explore it's features thereby practicing feature exploration and engineering of categorical data.","809986bb":"Huuh, 11 years are covered by the data. As ingredients of chocolate bars might have changed during this period we should consider the up-to-dateness of the review as well ;-) . In the dataset description we can see that this is related to the review_update_value (REF). The higher this value the more recent was the entry in the database:","053a0e9a":"#### Take-Away\n\n* We can see that most of the origins have only a few counts. That confirms the need to fuse sparse bean type origins to gain more insights out of this data. Currently it contains too much detail to work with.\n* Only a very few origins have counts greater than 50. From the figures above you can see that Nicaragua, Brazil, Bolivia, Belize and Papua New Guinea have all counts close to 50 and from the second subplot here you can see that each of them only cover around 3-4 % of the data. It's probably not very fruitful to include origins that have lower value counts. ","ee7590b8":"Ok, finally there is one thing left: We should turn ven into venezuela and fuse all occurances of dominican republic:","3dd14706":"Now, we can easily sum up the number of bean types to describe a mixture in a chocolate bar. Besides that we should take into account that some bean type names are given by \"blend\". This name just tells us that we have a mixture of beans but there is no specification which kind of beans were used. Consequently it could be nice to create two more features:\n\n* the number of different bean types in a bar\n* if the bar contains a mixture (blend) or not","0ca949a3":"Great! We have clearly reduced the number of total bean origins from 66 to.... ","ef9b3f20":"And to fuse words in a list:"}}