{"cell_type":{"a1beb5cd":"code","a6244ead":"code","390a2242":"code","c9e1cd17":"code","57475fe7":"code","9d63f43f":"code","fcd8f18f":"code","4e8c8ebc":"code","8770435b":"code","8e5c4e04":"code","c6c4d312":"code","771cd48d":"code","7690ddb3":"code","768a03cd":"code","f212cf75":"code","1337d699":"code","1af7c8e8":"code","28e5366b":"code","20993d99":"code","1cf055af":"code","e79c0593":"code","3cd89d0f":"code","8e44e23a":"code","3a9b0604":"code","64a35d01":"code","4f05d51d":"code","5ad48c3c":"code","43db9610":"code","c716a687":"code","d5d2cbd2":"code","85a791ec":"code","05c7d408":"code","2b0d9416":"code","ec8c0f62":"code","130b5db0":"code","0371af29":"code","280aab02":"code","9dd758fb":"code","127a4a97":"code","0d02bf87":"markdown","d0867dc7":"markdown","c58ffd30":"markdown","8d37cabc":"markdown"},"source":{"a1beb5cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6244ead":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","390a2242":"data_path = '\/kaggle\/input\/titanic\/'\n\n\ntrain = pd.read_csv(os.path.join(data_path, 'train.csv'))\ntest = pd.read_csv(os.path.join(data_path, 'test.csv'))\n\nprint(\"the shape of train\",train.shape)\n","c9e1cd17":"train.info()","57475fe7":"df_train=train.copy()\ndf_train.head()","9d63f43f":"# drop dublicates rows \ndf_train.drop_duplicates(inplace=True)\ndf_train.shape","fcd8f18f":"#between gender and survival \ndf_train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","4e8c8ebc":"#between pclass and survival  \ndf_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","8770435b":"df_train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","8e5c4e04":"g = sns.FacetGrid(df_train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","c6c4d312":"df_train[\"Parch\"].value_counts()","771cd48d":"#Calculate the family size  \n\ndf_train['family_size'] = train['SibSp'] + train['Parch'] + 1\n\n\ntest['family_size'] = test['SibSp'] + test['Parch'] + 1\n\n    \n# isAlone default is 0 return 1 if fsize =1 \ndf_train['Alone'] = 0\ndf_train.loc[df_train['family_size'] == 1, 'Alone'] = 1\n\ntest['Alone'] = 0\ntest.loc[test['family_size'] == 1, 'Alone'] = 1","7690ddb3":"df_train.head()","768a03cd":"df_train.isna().sum()","f212cf75":"# there's only two missing values in Embarked so we can drop it\n# fill na with median in Age\ndf_train.dropna(subset=['Embarked'],inplace=True)\ndf_train['Age'].fillna(df_train['Age'].median(),inplace=True)","1337d699":"df_train.isna().sum()","1af7c8e8":"df_train['Embarked'].value_counts()","28e5366b":"# convert categorical columns to numerical\ndf_train['Embarked'] = df_train['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ntest['Embarked'] = test['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ndf_train['Sex'] = df_train['Sex'].map( {'male': 0, 'female': 1} ).astype(int)\ntest['Sex'] = test['Sex'].map( {'male': 0, 'female': 1} ).astype(int)\n\n","20993d99":"#Age as 5 category \nlabels=['children','teen','young','old','too old']\ndf_train['AgeCat']=pd.cut(df_train.Age, bins=5,labels=labels)\ntest['AgeCat']=pd.cut(df_train.Age, bins=5,labels=labels)\n\nlabels=['low','fair','mid','high','veryhigh','exel']\ndf_train['FareBin']=pd.cut(df_train.Fare, bins=6,labels=labels)\ntest['FareBin']=pd.cut(test.Fare, bins=6,labels=labels)\n\n","1cf055af":"df_train.info()","e79c0593":"# Cabin non null values is too small so we can drop it\ndrop_train_cols = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch','Fare','Age']\ndrop_test_cols = [ 'Name', 'Ticket', 'Cabin', 'SibSp','Parch','Fare','Age']\n\ndf_train.drop(drop_train_cols,axis=1,inplace=True)\ntest.drop(drop_test_cols,axis=1,inplace=True)","3cd89d0f":"df_train.head()","8e44e23a":"# Check the final data \ndf_train.info()\nprint(\"-------------------------------------------\")\ntest.info()","3a9b0604":"sns.heatmap(df_train.corr(),annot=True)","64a35d01":"def one_hot_encoding(data, column):\n    data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n    data = data.drop([column], axis=1)\n    return data\n\ncols = ['FareBin','AgeCat']\n\nfor col in cols:\n    df_train = one_hot_encoding(df_train, col)\n    test  = one_hot_encoding(test, col)\n","4f05d51d":"df_train.head()","5ad48c3c":"from sklearn.model_selection import train_test_split\n\nX = df_train.drop(columns=['Survived'])\ny = df_train['Survived']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)","43db9610":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\ndt = DecisionTreeClassifier()\ncv_results = cross_val_score(dt, X_train, y_train, cv=5)\n\nprint('Accuracies:',cv_results)\nprint(\"the mean is :\",np.mean(cv_results))\ndt.fit(X_train,y_train)\npred=dt.predict(X_valid)","c716a687":"from sklearn.metrics import confusion_matrix\nconf_mat=confusion_matrix(y_valid,pred)\nsns.heatmap(conf_mat,annot=True)\n","d5d2cbd2":"from sklearn.metrics import roc_curve , auc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_recall_curve\n# calculate dummies once\ndef plot_roc(y_valid,pred):\n    fig, ax = plt.subplots()\n    fpr, tpr, _ = roc_curve(y_valid,pred)\n    roc_auc = auc(fpr, tpr)\n    ax.plot([0, 1], [0, 1], 'k--')\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    ax.set_title('Receiver operating characteristic example')\n    ax.plot(fpr, tpr)\n    sns.despine()\n    plt.show()","85a791ec":"plot_roc(y_valid,pred)","05c7d408":"from sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\npred = svc.predict(X_valid)\ncv_results = cross_val_score(svc, X_train, y_train, cv=5)\n\nprint('Accuracies:',cv_results)\nprint(\"the mean is :\",np.mean(cv_results))","2b0d9416":"plot_roc(y_valid,pred)","ec8c0f62":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\npred=logreg.predict(X_valid)\n\ncv_results = cross_val_score(logreg, X_train, y_train, cv=5)\n\nprint('Accuracies:',cv_results)\nprint(\"the mean is :\",np.mean(cv_results))\n","130b5db0":"plot_roc(y_valid,pred)","0371af29":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=50)\nrandom_forest.fit(X_train, y_train)\npred=random_forest.predict(X_valid)\ncv_results = cross_val_score(random_forest, X_train, y_train, cv=5)\n\nprint('Accuracies:',cv_results)\nprint(\"the mean is :\",np.mean(cv_results))","280aab02":"plot_roc(y_valid,pred)","9dd758fb":"from sklearn.ensemble import VotingClassifier\nfrom sklearn import model_selection\n\nestimators = []\nmodel1 = LogisticRegression()\nestimators.append(('logistic', model1))\nmodel2 = DecisionTreeClassifier()\nestimators.append(('cart', model2))\nmodel3 = SVC()\nestimators.append(('svm', model3))\n# create the ensemble model\nmodel4 = RandomForestClassifier()\nestimators.append(('Rf', model4))\nensemble = VotingClassifier(estimators)\nresults = model_selection.cross_val_score(ensemble, X_train, y_train, cv=5)\nprint(results.mean())","127a4a97":"test_without =test.drop('PassengerId', 1)\npredictions = random_forest.predict(test_without)\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0d02bf87":"# Model","d0867dc7":"# Ensemble","c58ffd30":"# make differnt models ","8d37cabc":"# EDA"}}