{"cell_type":{"8bed59be":"code","99d1577b":"code","997319b0":"code","edfffff3":"code","b518fa9e":"code","c8715d37":"code","2f3178e7":"code","2ec79b99":"code","050aa4ff":"code","96f1ddd4":"code","df085243":"code","2c80d235":"code","ac7e1417":"code","a17b9d77":"code","029b1c45":"code","6f57336e":"code","6cceb596":"code","7465773d":"code","1ad13e34":"code","98d02858":"code","a979e743":"code","1f830ce3":"code","f4e94ca8":"code","0bcdd7d6":"code","cd80c58f":"code","5bffeb4c":"code","64e99b1a":"code","0fefeade":"code","b915835b":"code","c54e5be0":"code","ae07229d":"code","95ffa8c8":"code","fea034eb":"code","a3a7c145":"code","4795f93a":"code","5c74c6c6":"code","976eee11":"code","0fd8de74":"code","d41843a5":"code","891bbd40":"code","04c7cfb5":"code","36a227a6":"code","d6cb9bb8":"code","a9b99bde":"code","bb9b3d58":"code","af0613c9":"code","220c7cb9":"code","b2e5bcf2":"code","a6f7aaaa":"code","6d479ca6":"code","b2728e97":"code","26d4e962":"code","25502410":"code","699f589c":"code","bcde33bc":"code","0d5cae7b":"code","0ee72530":"code","eedf8dea":"code","a7f8e635":"code","a6f6bfb1":"code","f30d665c":"code","d0fd936f":"code","020e6152":"code","6353a913":"code","b300e5de":"code","9f7c9a50":"code","b305f965":"code","ab68a5ff":"code","2d39148d":"code","c46095c0":"code","70755780":"code","7c128d31":"code","248b9456":"code","479d1e52":"code","a0577c85":"code","603bd324":"code","27a781ce":"code","ada639f0":"code","8e34cdb5":"code","9002f449":"code","9e1c1ff6":"code","e29b6151":"code","ae5bfebb":"code","63a137c1":"code","9f0ced4b":"markdown","dd634255":"markdown","e75725f5":"markdown","72f5e8cf":"markdown","4d0228bb":"markdown","dab228bc":"markdown","fc36c7ee":"markdown","1a5e3a0f":"markdown","1d47b832":"markdown","813e5374":"markdown","f7f410eb":"markdown","4ffb9a68":"markdown","51be8f33":"markdown","0b2e44f0":"markdown","99cb40d7":"markdown","0a696b69":"markdown","de15074e":"markdown","b0a2f86a":"markdown","f99aa636":"markdown","a7f36225":"markdown"},"source":{"8bed59be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99d1577b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\nimport cufflinks as cf\n\nfrom plotly.offline import iplot\n%matplotlib inline\n","997319b0":"py.offline.init_notebook_mode(connected=True)\ncf.go_offline()","edfffff3":"df = pd.read_csv('..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv', index_col=0)\ndf.head()","b518fa9e":"df.drop(labels=['Title', 'Clothing ID'], axis=1, inplace=True)\ndf.head()","c8715d37":"df.isnull().sum()","2f3178e7":"df.dropna(subset=['Review Text', 'Division Name'], inplace=True)\ndf.isnull().sum()","2ec79b99":"' '.join(df['Review Text'].tolist())[:1000]","050aa4ff":"contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how does\",\n\"i'd\": \"i would\",\n\"i'd've\": \"i would have\",\n\"i'll\": \"i will\",\n\"i'll've\": \"i will have\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\" u \": \" you \",\n\" ur \": \" your \",\n\" n \": \" and \"}","96f1ddd4":"def cont_to_exp(x):\n    if type(x) is str:\n        x = x.replace('\\\\', '')\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key, value)\n        return x\n    else:\n        return x","df085243":"x = \"i don't know what date is today, I am 5'8\\\"\" ","2c80d235":"print(cont_to_exp(x))","ac7e1417":"%%time\ndf['Review Text'] = df['Review Text'].apply(lambda x: cont_to_exp(x))","a17b9d77":"df.head()","029b1c45":"print(' '.join(df['Review Text'].tolist())[:1000])","6f57336e":"from textblob import TextBlob","6cceb596":"df.head()","7465773d":"df['polarity'] = df['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)","1ad13e34":"df['review_len'] = df['Review Text'].apply(lambda x: len(x))","98d02858":"df['word_count'] = df['Review Text'].apply(lambda x: len(x.split()))","a979e743":"def get_avg_word_len(x):\n    words = x.split()\n    word_len = 0\n    for word in words:\n        word_len = word_len + len(word)\n    return word_len\/len(words)","1f830ce3":"df['avg_word_len'] = df['Review Text'].apply(lambda x: get_avg_word_len(x))","f4e94ca8":"df.head()","0bcdd7d6":"df.head()","cd80c58f":"df['polarity'].iplot(kind = 'hist', colors = 'red', bins = 50,\n                    xTitle = 'Polarity', yTitle = 'Count', title  = 'Sentiment Polarity Distribution')","5bffeb4c":"df['Rating'].iplot(kind='hist', xTitle='Rating', yTitle='Count',\n                  title='Review Rating Distribution')","64e99b1a":"df['Age'].iplot(kind='hist', bins=40, xTitle='Age', yTitle='Count',\n                  title='Reviewers Age Dist', colors='red', linecolor='black')","0fefeade":"df['review_len'].iplot(kind='hist', xTitle='Review Len', yTitle='Count',\n                      title='Review Text Len Dist')","b915835b":"df['word_count'].iplot(kind = 'hist', xTitle = 'Word Count', yTitle = 'Count',\n                       title = 'Word Count Distribution')","c54e5be0":"df['avg_word_len'].iplot(kind = 'hist', xTitle = 'Avg Word Len', yTitle = 'Count',\n                         title = 'Review Text Avg Word Len Dist')","ae07229d":"df['word_count'].iplot(kind = 'hist', xTitle = 'Word Count', yTitle = 'Count', \n                       title = 'Word Count Distribution')","95ffa8c8":"df.head(1)","fea034eb":"df['Department Name'].value_counts()","a3a7c145":"df.groupby('Department Name').count()","4795f93a":"df['Department Name'].value_counts().iplot(kind = 'bar', yTitle = 'Count', xTitle = 'Department',\n                                          title = \"Bar Chart of Department's Name\")","5c74c6c6":"df['Division Name'].value_counts().iplot(kind = 'bar', yTitle = 'Count', xTitle = 'Division',\n                                          title = \"Bar Chart of Division's Name\")","976eee11":"df['Class Name'].value_counts().iplot(kind = 'bar', yTitle = 'Count', xTitle = 'Class',\n                                          title = \"Bar Chart of Class Name\")","0fd8de74":"from sklearn.feature_extraction.text import CountVectorizer","d41843a5":"def get_top_n_words(x, n):\n    vec = CountVectorizer().fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","891bbd40":"words = get_top_n_words(df['Review Text'], 20)","04c7cfb5":"words","36a227a6":"df1 = pd.DataFrame(words, columns=['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1.iplot(kind='bar', xTitle = 'Unigram', yTitle = 'Count', title = ' Top 20 unigram words')","d6cb9bb8":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","a9b99bde":"words = get_top_n_words(df['Review Text'], 20)","bb9b3d58":"words","af0613c9":"df1 = pd.DataFrame(words, columns = ['Bigram', 'Frequency'])\ndf1 = df1.set_index('Bigram')\ndf1.iplot(kind = 'bar', xTitle = 'Bigram', yTitle = 'Count', title = ' Top 20 Bigram words')","220c7cb9":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(3, 3)).fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","b2e5bcf2":"words = get_top_n_words(df['Review Text'], 20)","a6f7aaaa":"words","6d479ca6":"df1 = pd.DataFrame(words, columns = ['Trigram', 'Frequency'])\ndf1 = df1.set_index('Trigram')\ndf1.iplot(kind = 'bar', xTitle = 'Trigram', yTitle = 'Count', title = ' Top 20 Trigram words')","b2728e97":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(1, 1), stop_words='english').fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","26d4e962":"words = get_top_n_words(df['Review Text'], 20)","25502410":"words","699f589c":"df1 = pd.DataFrame(words, columns = ['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1.iplot(kind = 'bar', xTitle = 'Unigram', yTitle = 'Count', title = ' Top 20 Unigram words')","bcde33bc":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","0d5cae7b":"words = get_top_n_words(df['Review Text'], 20)","0ee72530":"words","eedf8dea":"df1 = pd.DataFrame(words, columns = ['Bigram', 'Frequency'])\ndf1 = df1.set_index('Bigram')\ndf1.iplot(kind = 'bar', xTitle = 'Bigram', yTitle = 'Count', title = ' Top 20 Bigram words')","a7f8e635":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","a6f6bfb1":"words = get_top_n_words(df['Review Text'], 20)\nwords","f30d665c":"df1 = pd.DataFrame(words, columns = ['Trigram', 'Frequency'])\ndf1 = df1.set_index('Trigram')\ndf1.iplot(kind = 'bar', xTitle = 'Trigram', yTitle = 'Count', title = ' Top 20 Trigram words')","d0fd936f":"import nltk","020e6152":"print(str(df['Review Text']))","6353a913":"blob = TextBlob(str(df['Review Text']))","b300e5de":"print(nltk.help.upenn_tagset())","9f7c9a50":"pos_df = pd.DataFrame(blob.tags, columns=['words', 'pos'])\npos_df = pos_df['pos'].value_counts()\npos_df","b305f965":"pos_df.iplot(kind='bar')","ab68a5ff":"df.head(2)","2d39148d":"sns.pairplot(df)","c46095c0":"sns.catplot(x='Division Name', y='polarity', data=df)","70755780":"sns.catplot(x = 'Division Name', y = 'polarity', data = df, kind = 'box')","7c128d31":"sns.catplot(x = 'Department Name', y = 'polarity', data = df)","248b9456":"sns.catplot(x = 'Department Name', y = 'polarity', data = df, kind = 'box')","479d1e52":"sns.catplot(x = 'Division Name', y = 'review_len', data = df, kind = 'box')","a0577c85":"sns.catplot(x = 'Department Name', y = 'review_len', data = df, kind = 'box')","603bd324":"import plotly.express as px\nimport plotly.graph_objects as go","27a781ce":"x1 = df[df['Recommended IND']==1]['polarity']\nx0 = df[df['Recommended IND']==0]['polarity']","ada639f0":"type(x1)","8e34cdb5":"trace0 = go.Histogram(x = x0, name = 'Not Recommended', opacity = 0.7)\ntrace1 = go.Histogram(x = x1, name = 'Recommended', opacity = 0.7)","9002f449":"data = [trace0, trace1]\nlayout = go.Layout(barmode = 'overlay', title = 'Distribution of Sentiment Polarity of Reviews Based on the Recommendation')\nfig = go.Figure(data = data, layout = layout)\n\niplot(fig)","9e1c1ff6":"x1 = df[df['Recommended IND']==1]['Rating']\nx0 = df[df['Recommended IND']==0]['Rating']","e29b6151":"type(x1)","ae5bfebb":"trace0 = go.Histogram(x = x0, name = 'Not Recommended', opacity = 0.7)\ntrace1 = go.Histogram(x = x1, name = 'Recommended', opacity = 0.7)","63a137c1":"data = [trace0, trace1]\nlayout = go.Layout(barmode = 'overlay', title = 'Distribution of Reviews Rating Based on the Recommendation')\nfig = go.Figure(data = data, layout = layout)\n\niplot(fig)","9f0ced4b":"## Distribution of Top 20 Parts-of-Speech POS tags ","dd634255":"## Bivariate Analysis ","e75725f5":"## Feature Engineering ","72f5e8cf":"# Women's E-Commerce Clothing Reviews \n\nClothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\n\nAge: Positive Integer variable of the reviewers age.\n\nTitle: String variable for the title of the review.\n\nReview Text: String variable for the review body.\n\nRating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n\nRecommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not \nrecommended.\n\nPositive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\n\nDivision Name: Categorical name of the product high level division.\n\nDepartment Name: Categorical name of the product department name.\n\nClass Name: Categorical name of the product class name.","4d0228bb":"### Unigram ","dab228bc":"### Trigram ","fc36c7ee":"## Distribution of Sentiment Polarity of Reviews Based on the Recommendation ","1a5e3a0f":"## Distribution of Review Text Length and Word Length","1d47b832":"# Text Cleaning","813e5374":"### Bigram \n","f7f410eb":"## Distribution of Department, Division, and Class ","4ffb9a68":"## Distribution of Ratings Based on the Recommendation ","51be8f33":"## Distribution of Reviews Rating and Reviewers Age","0b2e44f0":"### Bigram ","99cb40d7":"### Unigram","0a696b69":"## Distribution of Sentiment Polarity ","de15074e":"### Trigram ","b0a2f86a":"## Distribution of Unigram, Bigram and Trigram ","f99aa636":"# Data Import","a7f36225":"## Distribution of Unigram, Bigram and Trigram without STOP WORDS"}}