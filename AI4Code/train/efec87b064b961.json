{"cell_type":{"17d8ed47":"code","bdedacba":"code","531a1052":"code","c058f3f7":"code","24b51a77":"code","64e413d6":"code","d225feba":"code","ae85e7de":"code","224ea2f5":"code","dc055e90":"code","a32aa8c9":"code","552c7dcb":"code","31348e9d":"code","336f9505":"code","a3b2ccb2":"code","384dcb8e":"code","464515be":"code","f340d95f":"code","74585565":"code","a443621f":"code","11563c29":"code","760a85d7":"code","7e23ee3e":"code","651f6cd1":"code","b10eba5f":"code","9575e758":"code","0e80174b":"code","e1d84354":"code","9174718d":"code","9f3d98d7":"code","ed117be8":"code","43e1b654":"code","b85a6f8c":"code","4cb1412c":"code","3f31c435":"code","b2f5bfb7":"code","fc4f5ce1":"code","e3bd99e4":"markdown","a787df4a":"markdown","d0725549":"markdown","05a7e060":"markdown","fc67f68e":"markdown","0f5b837b":"markdown","cd65a3b1":"markdown","64108ee2":"markdown","15cc1ef9":"markdown","69d413f9":"markdown"},"source":{"17d8ed47":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('bmh')\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor,VotingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_log_error\n%matplotlib inline\n\nfrom sklearn.preprocessing import MaxAbsScaler,PowerTransformer,MinMaxScaler,RobustScaler\n\nfrom sklearn.inspection import permutation_importance\n\nfrom xgboost import XGBRegressor\n\nfrom scipy.stats import skew\n\nfrom scipy import stats","bdedacba":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ntrain_df=pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest_df=pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')\ntest_date=test_df.datetime\ndisplay(train_df.head())","531a1052":"display(train_df.describe().T)\ndisplay(train_df.info())\ntrain_df[train_df['count']<0]","c058f3f7":"#duplicates Checking\ntrain_df.duplicated().sum()\n","24b51a77":"print(train_df.isnull().sum())\nprint(test_df.isnull().sum())","64e413d6":"# check when the not a workingday there is no rental of bike\n#But found there exist renting\nz=train_df[train_df['workingday']==0]\nz['count'].shape","d225feba":"#right Skewed Label\n_=sns.histplot(train_df['count'])\n_=plt.title(\"Visualizing Target column\")\n_=plt.xlabel(\"Rented bikes\")\n_=plt.ylabel(\"Frequency\")","ae85e7de":"#Data Distributions\nplt.figure(figsize=(25, 25))\nfor i, col in enumerate(list(train_df.columns)):\n    plt.subplot(7, 4, i+1)\n    sns.histplot(train_df[col], kde=True, bins=10)","224ea2f5":"def drawFeatures_VS_y(df):\n    for col in df.columns:\n        col_rental = df.groupby(col,as_index=False)['count'].mean()\n        sns.scatterplot(data = col_rental,x=col,y='count')\n        plt.title(col)\n        plt.show()","dc055e90":"#Draw scatter plot between each feature and Target\ndrawFeatures_VS_y(train_df)","a32aa8c9":"# see the mean of label to every unique value of each column\n#may be helpful to know most important features and for featur engineerng and encoding\ndef insights(df):\n    for col in df.columns:\n        if col=='count':\n            continue\n        else:\n            display(df[[col, 'count']].groupby([col], as_index=False).mean().sort_values(by='count', ascending=False).T)","552c7dcb":"insights(train_df)","31348e9d":"#Calc the skeweness of each continous feature\n\ndef calc_skew(df):\n    print(\"\\nIF THE DATA IS HIGHLY SKEWED IF SKWENESS  > 1 OR < -1 \\n\")\n    for col in df.loc[:, df.dtypes != np.object ]:\n        print(\"the skewness of \",col,\"is :\",df[col].skew())\n\ncalc_skew(train_df)","336f9505":"# Transform data\ndef transformation(df,columns,func):\n    for col in columns:\n        df[col]=func(df[col])\n    return df\n\n#Demo of function params\n#transformation(test_df,['Temperature(\ufffdC)','Hour'],np.log1p)","a3b2ccb2":"# Adding Day Month Year to data frame\ndef add_day_month_year(df):\n    df['Year'] =  pd.DatetimeIndex(df['datetime']).year\n    df['Month'] =  pd.DatetimeIndex(df['datetime']).month\n    df['weekday'] =  pd.DatetimeIndex(df['datetime']).dayofweek\n    df['weekofyear']= pd.DatetimeIndex(df['datetime']).weekofyear\n    df['dayofyear']= pd.DatetimeIndex(df['datetime']).dayofyear\n    df['Hour']= pd.DatetimeIndex(df['datetime']).hour\n    return df\n","384dcb8e":"#Calculate if it day or night and the hours of the day the bikes rented the most these ours are :8,17,18,19,20,21\ndef add_rush_hours(df):\n    df['RushHour']= df['Hour'].isin([8,17,18,19,20,21])\n    df['lowHour']= df['Hour'].isin([0,1,2,3,4])\n    return df","464515be":"def add_day_or_night(df):\n    df['DayorNight'] = (df['Hour'] >= 7) & (df['Hour'] <= 20)\n    return df","f340d95f":"def label_encoding(df):\n    cat_features = df.select_dtypes(exclude=[\"number\"])\n    for col in cat_features.columns:\n        if col != 'datetime':\n            df[col] = pd.factorize(df[col])[0].reshape(-1, 1)\n    return df \n","74585565":"def preprocessing(df):\n    new_df=add_day_month_year(df)\n    new_df=add_rush_hours(new_df)\n    new_df=add_day_or_night(new_df)\n    new_df=label_encoding(new_df)\n    return new_df","a443621f":"train_data=preprocessing(train_df)\ntest_data=preprocessing(test_df)","11563c29":"train_data.head()","760a85d7":"test_data.columns","7e23ee3e":"cols=['count','registered','casual']\n\nfinal_train_data=transformation(train_data,cols,np.log1p)\n","651f6cd1":"Y=final_train_data[['count']]\n\n\nfinal_train_data.drop(columns=['datetime','count','atemp','Year','registered','casual'],inplace = True)\ntest_data.drop(columns=['datetime','atemp','Year'],inplace = True)\n","b10eba5f":"X_train, X_valid, y_train, y_valid = train_test_split(final_train_data,Y, train_size=0.8, test_size=0.2,random_state=0)\n","9575e758":"#evaluation matrix\ndef rmsle(y_pred,y_true):\n    y_pred = np.expm1(y_pred)\n    y_true = np.expm1(y_true)\n    log1=np.log(y_pred + 1)\n    log2=np.log(y_true + 1)\n    se = (log1 - log2) ** 2 \n    mse=np.mean(se)\n    return np.sqrt(mse)\n\nfrom sklearn.metrics import make_scorer\nmyScorer = make_scorer(rmsle, greater_is_better=False)","0e80174b":"train_data.info()","e1d84354":"HistGradient = HistGradientBoostingRegressor()\n\nparam = {#n_estimators' : [180], \n    'max_iter':[115],\n    'max_depth' : [11],\n    'max_leaf_nodes':[15],\n    'max_bins':[150]\n         #min_samples_split':[2],\n         #min_samples_leaf':[1],\n        }\ngridSearch_HistGradient = GridSearchCV(HistGradient,param,scoring=myScorer,cv=10,verbose=3)\ngridSearch_HistGradient.fit(X_train,y_train.values.ravel())\n\nbest_HistGradient = gridSearch_HistGradient.best_estimator_\nbestHistGradient_testScore=best_HistGradient.score(X_train, y_train)","9174718d":"gridSearch_HistGradient.best_params_","9f3d98d7":"bestHistGradient_testScore","ed117be8":"pred=best_HistGradient.predict(X_valid)\nprint(rmsle(pred,y_valid.values.ravel()))","43e1b654":" r = permutation_importance(gridSearch_HistGradient, X_valid, y_valid.values.ravel(),\n                            n_repeats=30)\n\nfor i in r.importances_mean.argsort()[::-1]:\n\n    print(f\"{X_train.columns[i]} \"\n           f\"{r.importances_mean[i]:.3f} \"\n           f\" +\/- {r.importances_std[i]:.3f}\")","b85a6f8c":"plt.figure(figsize=(10,7))\nplt.barh(X_train.columns, r.importances_mean)","4cb1412c":"test_data.head(20)","3f31c435":"pred=np.fix(np.expm1(best_HistGradient.predict(test_data))).astype(int)\npredictions = pd.DataFrame({'datetime':test_date,\n                       'count': pred})","b2f5bfb7":"predictions.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","fc4f5ce1":"predictions.head(10)","e3bd99e4":"### Splitting Data into Features and target","a787df4a":"# Loading Train and Test Data","d0725549":"# EDA","05a7e060":"# Preprocessing And Feature Engineering","fc67f68e":"# \ud83d\ude04 Generating Submission File","0f5b837b":"# Importing Libraries","cd65a3b1":"**\u26a1 No Missing Data**","64108ee2":"# Grid Search","15cc1ef9":"**\u26a1 It's Right\nSkewed :(**","69d413f9":"**\u26a1 No Duplicates**"}}