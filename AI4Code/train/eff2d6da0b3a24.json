{"cell_type":{"8ddc0d5b":"code","2e0caec0":"code","90e17e99":"code","35ce4b66":"code","dcc588d9":"code","22c0b91a":"code","e4b95141":"code","e31addf2":"code","9865f85d":"code","ddb3e0c7":"code","2714ee31":"code","0b3b9519":"code","5ce9c0ea":"code","686b3d46":"code","e6b4c663":"code","2f1da9c1":"code","febb62f3":"code","e8d9224a":"code","1df0d0d3":"code","d3b28319":"code","a03f764b":"code","e9491d02":"code","6e48a59f":"code","993db459":"code","48c50156":"code","a62be700":"code","31a4cb70":"code","535d9293":"code","a79540c1":"code","582a7106":"code","e2ae810a":"code","cd8bf64d":"code","028a32d0":"code","846e10ea":"code","80422af0":"code","e5b61b23":"code","8d817595":"code","fe6ead1e":"code","889814fe":"code","ce22e203":"code","1ee08dbb":"code","c8222b04":"code","a7633d71":"code","e897e046":"code","d0906b7f":"code","84621038":"code","80ac4d03":"code","21e1aee4":"code","19600a5f":"code","ab218577":"code","d6aa1263":"code","1a98edca":"code","8c424447":"code","87b6fa3f":"code","991adfd9":"code","909432d9":"code","dd8608e2":"code","ef07f931":"code","f5edabbb":"code","b6105906":"code","3b39e9a1":"code","5359889b":"code","ecb3fed2":"markdown","73a6a537":"markdown","de9a27eb":"markdown","0e04ee85":"markdown","27b4688e":"markdown"},"source":{"8ddc0d5b":"from tensorflow import keras\nfrom keras.models import Sequential,load_model,Model\nfrom keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\nfrom keras.metrics import Recall, Precision \n# from keras.initializers import glorot_uniform\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nfrom keras import layers\nfrom keras.layers import Input","2e0caec0":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\n# from tensorflow.keras.applications import VGG19\n# from tensorflow.keras.applications.vgg19 import preprocess_input\n# from tensorflow.keras.applications.densenet import DenseNet121\n# from tensorflow.keras.applications.densenet import preprocess_input","90e17e99":"# base_model_tf=ResNet50(include_top=False,weights='imagenet',input_shape=(256,256,3),classes=26)\n\n# base_model_tf=VGG19(include_top=False,weights='imagenet',input_shape=(256,256,3),classes=26)\n\nbase_model_tf=DenseNet121(include_top=False,weights='imagenet',input_shape=(256,256,3),classes=26)","35ce4b66":"model_main = Sequential([    \n    \n    layers.Conv2D(64, (3, 3), input_shape=(256,256,3), activation = 'relu', padding='same'),\n    layers.Conv2D(64, (3, 3), activation = 'relu', padding='same'),\n    layers.MaxPooling2D((2,2), strides=2),\n    layers.Dropout(0.25),\n\n#     layers.Conv2D(128, (3, 3), activation = 'relu', padding='same'),\n    layers.Conv2D(128, (3, 3), activation = 'relu', padding='same'),\n    layers.Conv2D(128, (3, 3), activation = 'relu', padding='same'),\n    layers.MaxPooling2D((2,2), strides=2),\n    layers.Dropout(0.25),\n\n\n#     layers.Conv2D(256, (3, 3), activation = 'relu', padding='same'),\n    layers.Conv2D(256, (3, 3), activation = 'relu', padding='same'),\n    layers.Conv2D(256, (3, 3), activation = 'relu', padding='same'),\n    layers.MaxPooling2D((2,2), strides=2),\n    layers.Dropout(0.25),\n\n#     layers.Conv2D(1024, (3, 3), activation = 'relu', padding='same'),\n    layers.Conv2D(512, (3, 3), activation = 'relu', padding='same'),\n    layers.Conv2D(512, (3, 3), activation = 'relu', padding='same'),\n    layers.MaxPooling2D((2,2), strides=2),\n    layers.Dropout(0.25),\n    \n    layers.GlobalAveragePooling2D(),\n#     layers.Flatten(),\n#     layers.Dense(units = 512, activation = 'relu'),\n#     layers.Dropout(0.5),\n    layers.Dense(units = 256, activation = 'relu'),\n    layers.Dropout(0.5),\n    layers.Dense(units = 128, activation = 'relu'),\n    layers.Dropout(0.25),\n    layers.BatchNormalization(),\n    layers.Dense(units = 64, activation = 'relu'),\n    layers.Dropout(0.5),\n    layers.Dense(units = 26, activation = 'softmax')\n])\n# #Model building\n# base_model_tf.trainable=False\n\n# pt=Input(shape=(256,256,3))\n# func=tensorflow.cast(pt,tensorflow.float32)\n# x=preprocess_input(func) #This function used to zero-center each color channel wrt Imagenet dataset\n# model_resnet=base_model_tf(x,training=True)\n# model_resnet=GlobalAveragePooling2D()(model_resnet)\n# model_resnet=Dense(256,activation='relu')(model_resnet)\n# model_resnet=Dense(128,activation='relu')(model_resnet)\n# model_resnet=Dense(64,activation='relu')(model_resnet) \n# model_resnet=Dense(26,activation='softmax')(model_resnet)\n\n\n# model_main=Model(inputs=pt,outputs=model_resnet)\n# model_main.summary()\n\n#Model building\n# base_model_tf.trainable=False\n\n# pt=Input(shape=(256,256,3))\n# func=tensorflow.cast(pt,tensorflow.float32)\n# x=preprocess_input(func) #This function used to zero-center each color channel wrt Imagenet dataset\n# model_resnet=base_model_tf(x,training=False)\n# model_resnet=GlobalAveragePooling2D()(model_resnet)\n# model_resnet=Dense(256,activation='relu')(model_resnet)\n# model_resnet=Dense(128,activation='relu')(model_resnet)\n# model_resnet=Dense(64,activation='relu')(model_resnet)\n# model_resnet=Dense(38,activation='softmax')(model_resnet)\n\n\n# model_main=Model(inputs=pt,outputs=model_resnet)\n\n\n\n# model_main = model_custom()(model_main)\n\nmodel_main.summary()","dcc588d9":"tensorflow.keras.utils.plot_model(model_main, show_shapes=True)","22c0b91a":"#Image augmentation\n# train_datagen= ImageDataGenerator(shear_range=0.2,zoom_range=0.2,horizontal_flip=False,vertical_flip=False\n#                                   ,fill_mode='nearest',width_shift_range=0.2,height_shift_range=0.2)\n\n# val_datagen=ImageDataGenerator()\n\ndatagen=ImageDataGenerator(validation_split = 0.20, shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode='nearest',width_shift_range=0.2,height_shift_range=0.2)\n\n\n# path_train='\/kaggle\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/train'\n\n# path_valid='\/kaggle\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/valid'\n\npath='\/kaggle\/input\/no-augment-26-plant-disease'\n\ntrain = datagen.flow_from_directory(directory=path,batch_size=32,target_size=(256,256),color_mode='rgb',class_mode='categorical',seed=42, subset = \"training\")\n\nvalid = datagen.flow_from_directory(directory=path,batch_size=32,target_size=(256,256),color_mode='rgb',class_mode='categorical', subset = \"validation\")\n","e4b95141":"from collections import Counter\n\ncounter_train = Counter(train.classes)\ncounter_test = Counter(valid.classes)\nprint(counter_train.items())\nprint(counter_test.items())","e31addf2":"from collections import Counter\n\ncounter_train = Counter(train.classes)\ncounter_test = Counter(valid.classes)\nprint(counter_train.items())\nprint(counter_test.items())","9865f85d":"from collections import Counter\n\ncounter_train = Counter(train.classes)\ncounter_test = Counter(valid.classes)\nprint(counter_train.items())\nprint(counter_test.items())","ddb3e0c7":"import datetime","2714ee31":"path = \".\/\"\ndt = datetime.datetime.now()\ndt = \"{}{}{}_{}{}{}\".format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\nsave_path= path + \"model\" + dt + '.h5'\n\n#CallBacks\n# checkpoint = ModelCheckpoint(save_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nes=EarlyStopping(monitor='val_accuracy',verbose=1,patience=7,mode='auto')\nmc=ModelCheckpoint(save_path,monitor='val_accuracy',verbose=1,save_best_only=True, mode='max')\nlr=ReduceLROnPlateau(monitor='val_accuracy',verbose=1,patience=5,min_lr=0.001)","0b3b9519":"model_main.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy', Precision(), Recall()]) #, F1Score(num_classes=26, threshold=0.6)]) #'accuracy', f1_m, precision_m, recall_m]) #, F1Score(num_classes=38, threshold=0.8)])","5ce9c0ea":"#Training\nhis = model_main.fit(train,validation_data=valid,epochs=30,steps_per_epoch=700,verbose=1,callbacks=[mc,es,lr])","686b3d46":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np","e6b4c663":"predictions = model_main.predict(valid, steps=550)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = valid.classes\nclass_labels = list(valid.class_indices.keys())  \nreport = classification_report(true_classes, predicted_classes, target_names=class_labels)\nprint(report) ","2f1da9c1":"confusion_matrix = confusion_matrix(y_true=true_classes, y_pred=predicted_classes)\nprint(confusion_matrix)","febb62f3":"model_main.save(\"CUSTOM_PLANT_DISEASE_26class.h5\")","e8d9224a":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom PIL import Image","1df0d0d3":"print(his)\nprint(type(his))","d3b28319":"plt.figure(figsize=(10,5))\nplt.plot(his.history['loss'],color='b',label='Training loss')\nplt.plot(his.history['val_loss'],color='r',label='Validation loss')\nplt.legend(loc='upper right')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss_value\")\nplt.title(\"loss\")\nplt.show()\n","a03f764b":"plt.figure(figsize=(10,5))\nplt.plot(his.history['accuracy'],color='b',label='Training accuracy')\nplt.plot(his.history['val_accuracy'],color='r',label='Validation accuracy')\nplt.legend(loc='lower right')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.title(\"accuracy graph\")","e9491d02":"plt.figure(figsize=(10,5))\nplt.plot(his.history['precision'],color='b',label='Training precision')\nplt.plot(his.history['val_precision'],color='r',label='Validation precision')\nplt.legend(loc='lower right')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"precision\")\nplt.title(\"precision graph\")","6e48a59f":"plt.figure(figsize=(10,5))\nplt.plot(his.history['recall'],color='b',label='Training recall')\nplt.plot(his.history['val_recall'],color='r',label='Validation recall')\nplt.legend(loc='lower right')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"recall\")\nplt.title(\"recall graph\")","993db459":"!pip install imutils","48c50156":"test_loss, test_acc = his.evaluate(valid, batch_size=32, verbose=1)\n\nprint(test_acc)\nprint(test_loss)","a62be700":"import os\nprint(os.listdir(\".\/\"))","31a4cb70":"import pandas as pd\n\n# convert the history.history dict to a pandas DataFrame:     \nhist_df = pd.DataFrame(his.history) \n\n# save to json:  \nhist_json_file = 'history.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)\n\n# or save to csv: \nhist_csv_file = 'history.csv'\nwith open(hist_csv_file, mode='w') as f:\n    hist_df.to_csv(f)","535d9293":"!zip -r \/kaggle\/working\/custom_26epoch_28_12_21.zip \/kaggle\/working","a79540c1":"!pip install zip_files\n!zip-folder --auto-root --outfile \/kaggle\/working\/custom_26epoch_28_12_21.zip \/kaggle\/working\/","582a7106":"# import os\n# os.chdir(r'\/kaggle\/working\/')\nfrom IPython.display import FileLink\nFileLink(r'custom_26epoch_28_12_21.zip')","e2ae810a":"def indentity_block(X,f,stage,filters,block):\n\n    conv_base_name= 'res'+str(stage)+block+\"_branch\"\n    bn_name=\"bn\"+str(stage)+block+\"_branch\"\n  \n    F1,F2,F3=filters\n    X_shortcut=X\n\n    X=Conv2D(filters=F1, kernel_size=(1,1), padding='valid', strides=(1,1), name=conv_base_name+\"2a\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2a\")(X)\n    X=Activation('relu')(X)\n\n    X=Conv2D(filters=F2, kernel_size=(f,f), padding='same', strides=(1,1), name=conv_base_name+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2b\")(X)\n    X=Activation('relu')(X)\n\n    X=Conv2D(filters=F3, kernel_size=(1,1), padding='valid', strides=(1,1), name=conv_base_name+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2c\")(X)\n    X=Add()([X,X_shortcut])\n\n    X=Activation('relu')(X)\n\n    return(X)\n","cd8bf64d":"def convolution_block(X,f,stage,filters,block,s=2):\n    conv_base_name=\"res\"+str(stage)+block+\"_branch\"\n    bn_name=\"bn\"+str(stage)+block+\"_branch\"\n  \n    F1,F2,F3=filters\n    X_shortcut=X\n\n    X=Conv2D(filters=F1, kernel_size=(1,1), padding='valid', strides=(s,s), name=conv_base_name+\"2a\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2a\")(X)\n    X=Activation('relu')(X)\n\n    X=Conv2D(filters=F2, kernel_size=(f,f), padding='same', strides=(1,1), name=conv_base_name+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2b\")(X)\n    X=Activation('relu')(X)\n\n    X=Conv2D(filters=F3, kernel_size=(1,1), padding='valid', strides=(1,1), name=conv_base_name+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2c\")(X)\n  \n    X_shortcut=Conv2D(filters=F3,kernel_size=(1,1),padding='valid',strides=(s,s),name=conv_base_name+\"1\",kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut=BatchNormalization(axis=3,name=bn_name+\"1\")(X_shortcut)\n\n    X=Add()([X,X_shortcut])\n\n    X=Activation('relu')(X)\n\n    return(X)\n\n","028a32d0":"def resnet50(input_size=(256,256,3)):\n\n    X_input=Input(input_size)\n\n    X=ZeroPadding2D((3,3))(X_input)\n  \n    #STAGE 1\n    X=Conv2D(filters=64,kernel_size=(7,7),strides=(2,2),kernel_initializer=glorot_uniform(seed=0),name='conv1')(X)\n    X=BatchNormalization(axis=3,name='bn1')(X)\n    X=Activation('relu')(X)\n    X=MaxPool2D((3,3),strides=(2,2))(X)\n\n    #STAGE 2\n    X=convolution_block(X,f=3,filters=[64,64,256],block=\"a\",s=1,stage=2)\n    X=indentity_block(X,f=3,filters=[64,64,256],block='b',stage=2)\n    X=indentity_block(X,f=3,filters=[64,64,256],block='c',stage=2)\n\n    #STAGE 3\n    X=convolution_block(X,f=3,filters=[128,128,512],block=\"a\",s=2,stage=3)\n    X=indentity_block(X,f=3,filters=[128,128,512],block='b',stage=3)\n    X=indentity_block(X,f=3,filters=[128,128,512],block='c',stage=3)\n    X=indentity_block(X,f=3,filters=[128,128,512],block='d',stage=3)\n\n\n    #STAGE 4\n    X=convolution_block(X,f=3,filters=[256,256,1024],block=\"a\",s=2,stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='b',stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='c',stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='d',stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='e',stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='f',stage=4)\n\n\n    #STAGE 5\n    X=convolution_block(X,f=3,filters=[512,512,2048],block=\"a\",s=2,stage=5)\n    X=indentity_block(X,f=3,filters=[512,512,2048],block='b',stage=5)\n    X=indentity_block(X,f=3,filters=[512,512,2048],block='c',stage=5)\n\n    X=AveragePooling2D(pool_size=(2,2),padding='same')(X)\n\n    model=Model(inputs=X_input,outputs=X,name=\"RESNET50\")\n\n    return(model)\n\n","846e10ea":"\nbase_model=resnet50(input_size=(256,256,3))\n'''base_model.load_weights('\/content\/resnet50_weights_tf_dim_ordering_tf_kernels_notop(1).h5')'''","80422af0":"model1=base_model.output\nmodel1=Flatten()(model1)\nmodel1=Dense(256,activation='relu',name='Dense1')(model1)\nmodel1=Dropout(0.2)(model1)\nmodel1=Dense(128,activation='relu',name='Dense1.1')(model1)\nmodel1=Dropout(0.2)(model1)\nmodel1=Dense(64,activation='relu',name='Dense2')(model1)\nmodel1=Dropout(0.2)(model1)\n\nmodel1=Dense(39,activation='softmax',name='Dense3')(model1)\n\nmain_model=Model(inputs=base_model.input,outputs=model1)\nmain_model.summary()","e5b61b23":"tensorflow.keras.utils.plot_model(main_model, show_shapes=True)","8d817595":"!pip install visualkeras","fe6ead1e":"import visualkeras\nfrom keras.utils.vis_utils import plot_model","889814fe":"visualkeras.layered_view(main_model, legend=True)\n# plot_model(main_model, show_shapes=True, show_layer_names=True, )","ce22e203":"'''base_model.trainable=False\nfor layer in main_model.layers:\n  print(layer,layer.trainable)'''","1ee08dbb":"model_resnet=base_model_tf(x,training=True)\nmodel_resnet=GlobalAveragePooling2D()(model_resnet)\nmodel_resnet=Dense(256,activation='relu')(model_resnet)\nmodel_resnet=Dense(128,activation='relu')(model_resnet)\nmodel_resnet=Dense(64,activation='relu')(model_resnet)\nmodel_resnet=Dense(39,activation='softmax')(model_resnet)\nmodel_main=Model(inputs=pt,outputs=model_resnet)\nmain_model.summary()","c8222b04":"#IMPORTING LIBRARIES\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt","a7633d71":"path='\/kaggle\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/train'\nplt.figure(figsize=(70,70))\ncount=0\nplant_names=[]\ntotal_images=0\nfor i in os.listdir(path):\n  count+=1\n  plant_names.append(i)\n  plt.subplot(7,7,count)\n\n  images_path=os.listdir(path+\"\/\"+i)\n  print(\"Number of images of \"+i+\":\",len(images_path),\"||\",end=\" \")\n  total_images+=len(images_path)\n\n  image_show=plt.imread(path+\"\/\"+i+\"\/\"+images_path[0])\n  \n  plt.imshow(image_show)\n  plt.xlabel(i)\n  \n  plt.xticks([])\n  plt.yticks([])\n\n\nprint(\"Total number of images we have\",total_images)\n","e897e046":"import tensorflow\nfrom tensorflow import keras\nfrom keras.models import Sequential,load_model,Model\nfrom keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\nfrom keras.metrics import Recall, Precision \nfrom keras.initializers import glorot_uniform\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nfrom keras import layers\nfrom keras.layers import Input","d0906b7f":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\n# from tensorflow.keras.applications import VGG19\n# from tensorflow.keras.applications.vgg19 import preprocess_input","84621038":"base_model_tf=ResNet50(include_top=False,weights='imagenet',input_shape=(256,256,3),classes=38)\n\n# base_model_tf=VGG19(include_top=False,weights='imagenet',input_shape=(256,256,3),classes=38)","80ac4d03":"# #Model building\nbase_model_tf.trainable=False\n\npt=Input(shape=(256,256,3))\nfunc=tensorflow.cast(pt,tensorflow.float32)\nx=preprocess_input(func) #This function used to zero-center each color channel wrt Imagenet dataset\nmodel_resnet=base_model_tf(x,training=True)\nmodel_resnet=GlobalAveragePooling2D()(model_resnet)\nmodel_resnet=Dense(256,activation='relu')(model_resnet)\nmodel_resnet=Dense(128,activation='relu')(model_resnet)\nmodel_resnet=Dense(64,activation='relu')(model_resnet)\nmodel_resnet=Dense(38,activation='softmax')(model_resnet)\n\n\nmodel_main=Model(inputs=pt,outputs=model_resnet)\n\n# model_main = Sequential([    \n\n#     layers.Conv2D(128, (3, 3), input_shape=(256,256,3), activation = 'relu', padding='same'),\n#     layers.Conv2D(128, (3, 3), activation = 'relu', padding='same'),\n#     layers.MaxPooling2D((2,2), strides=2),\n#     layers.Dropout(0.25),\n\n#     layers.Conv2D(256, (3, 3), activation = 'relu', padding='same'),\n#     layers.Conv2D(256, (3, 3), activation = 'relu', padding='same'),\n#     # layers.Conv2D(256, (3, 3), activation = 'relu', padding='same'),\n#     layers.MaxPooling2D((2,2), strides=2),\n#     layers.Dropout(0.25),\n\n\n#     # layers.Conv2D(512, (3, 3), activation = 'relu', padding='same'),\n#     layers.Conv2D(512, (3, 3), activation = 'relu', padding='same'),\n#     layers.Conv2D(512, (3, 3), activation = 'relu', padding='same'),\n#     layers.MaxPooling2D((2,2), strides=2),\n#     layers.Dropout(0.25),\n\n#     # layers.Conv2D(1024, (3, 3), activation = 'relu', padding='same'),\n# #     layers.Conv2D(1024, (3, 3), activation = 'relu', padding='same'),\n# #     layers.Conv2D(1024, (3, 3), activation = 'relu', padding='same'),\n# #     layers.MaxPooling2D((2,2), strides=2),\n# #     layers.Dropout(0.25),\n\n#     layers.Flatten(),\n#     # layers.Dense(units = 512, activation = 'relu'),\n#     # layers.Dropout(0.25),\n#     layers.Dense(units = 512, activation = 'relu'),\n#     layers.Dropout(0.25),\n#     layers.Dense(units = 256, activation = 'relu'),\n#     layers.Dropout(0.25),\n#     layers.Dense(units = 256, activation = 'relu'),\n#     layers.Dropout(0.5),\n#     layers.Dense(units = 38, activation = 'softmax')\n# ])\n\nmodel_main.summary()","21e1aee4":"# Image augmentation\ntrain_datagen= ImageDataGenerator(shear_range=0.2,zoom_range=0.2,horizontal_flip=False,vertical_flip=False\n                                  ,fill_mode='nearest',width_shift_range=0.2,height_shift_range=0.2)\n\nval_datagen=ImageDataGenerator()\n\npath_train='\/kaggle\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/train'\n\npath_valid='\/kaggle\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/valid'\n\ntrain= train_datagen.flow_from_directory(directory=path_train,batch_size=32,target_size=(256,256),\n                                         color_mode='rgb',class_mode='categorical',seed=42)\n\nvalid=val_datagen.flow_from_directory(directory=path_valid,batch_size=32,target_size=(256,256),color_mode='rgb',class_mode='categorical')","19600a5f":"import datetime","ab218577":"path = \".\/\"\ndt = datetime.datetime.now()\ndt = \"{}{}{}_{}{}{}\".format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\nsave_path= path + \"model\" + dt + '.h5'\n\n#CallBacks\n# checkpoint = ModelCheckpoint(save_path, monitor='val_f1_m', verbose=1, save_best_only=True, mode='max')\nes=EarlyStopping(monitor='val_loss',verbose=1,patience=7,mode='auto')\nmc=ModelCheckpoint(save_path,monitor='val_loss',verbose=1,save_best_only=True)\nlr=ReduceLROnPlateau(monitor='val_loss',verbose=1,patience=5,min_lr=0.001)","d6aa1263":"from keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","1a98edca":"model_main.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy', f1_m, precision_m, recall_m]) #, F1Score(num_classes=38, threshold=0.8)])","8c424447":"#Training\nmodel_main.fit(train,validation_data=valid,epochs=30,steps_per_epoch=500,verbose=1,callbacks=[mc,es,lr])","87b6fa3f":"model_main.save(\"RESNET50_PLANT_DISEASE.h5\")","991adfd9":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom PIL import Image","909432d9":"plt.figure(figsize=(10,5))\nplt.plot(model_main.history.history['loss'],color='b',label='Training loss')\nplt.plot(model_main.history.history['val_loss'],color='r',label='Validation loss')\nplt.legend(loc='upper right')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss_value\")\nplt.title(\"loss\")\nplt.show()","dd8608e2":"plt.figure(figsize=(10,5))\nplt.plot(model_main.history.history['accuracy'],color='b',label='Training accuracy')\nplt.plot(model_main.history.history['val_accuracy'],color='r',label='Validation accuracy')\nplt.legend(loc='lower right')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.title(\"accuracy graph\")","ef07f931":"!pip install imutils","f5edabbb":"import os\nprint(os.listdir(\".\/\"))","b6105906":"import pandas as pd\n\n# convert the history.history dict to a pandas DataFrame:     \nhist_df = pd.DataFrame(his.history) \n\n# save to json:  \nhist_json_file = 'history.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)\n\n# or save to csv: \nhist_csv_file = 'history.csv'\nwith open(hist_csv_file, mode='w') as f:\n    hist_df.to_csv(f)","3b39e9a1":"!zip -r \/kaggle\/working\/custom_26epoch_28_12_21.zip \/kaggle\/working","5359889b":"from IPython.display import FileLink\nFileLink(r'model20211119_65150.h5')","ecb3fed2":"# Last but not the least\n\n1. **Give it a upvote if you love it , your upvote may be can help me to get a job :)**\n2. **Will come up with more notebooks**\n3. **Have any doubt please comment and ask , don't get appreciate If you really like my work**\n4. **If you are beginner and won't able to understand the code , tell me I will edit this notebook or provide you resources to get better intuition**\n5. **Thanks will meet on the next :)**","73a6a537":"**I will comment it out below code and you can take reference from here and can implement your own resnet architecture . Trust it will be fun :)**","de9a27eb":"1. **Do you know why I have not run below cells to get results, actually i have tried to run it but I was not getting even 50% accuracy on training set**\n\n2. **You know why? Well I don't use preprocessing function , what is it ? This function is Preprocessed numpy.array or a tf.Tensor with type float32.**\n\n3. **The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling**\n\n4. **sometimes data is not zero-centered according to the imagenet dataset and we don't get good results , so tensoflow has provided us this preprocess input , you can see I have used it in above model**\n\n5. **Read it from here:https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications\/resnet\/preprocess_input**","0e04ee85":"**RESNET50 CODE IMPLEMENTATION**","27b4688e":"**Well below is the implementation of Resnet50**\n\n1. **Resnet50 have 5 stages in which each stage contains both convolution block as well as identity block** \n\n![Resnet50](http:\/\/machinelearningknowledge.ai\/wp-content\/uploads\/2020\/12\/ResNet-Keras-Implementation-Architecture.png)\n\n\n\n2. **Also see from here(see 50 layer architecture) , I will suggest read blogs from above given links**\n\n![Layers](http:\/\/test.neurohive.io\/wp-content\/uploads\/2019\/01\/resnet-architectures-34-101.png)"}}