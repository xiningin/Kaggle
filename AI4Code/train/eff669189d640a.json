{"cell_type":{"8b8a0946":"code","4f72e438":"code","508a9314":"code","fcfc1687":"code","33e9d0b0":"code","e9c798c4":"code","b00e7e79":"code","7b02ad8d":"code","c934d82d":"code","2e53497c":"code","1897c5ba":"code","9c2d6e4b":"code","335ef94d":"code","fc8ba798":"code","9e8f8d53":"code","0fbd5fc3":"code","7560430b":"code","01539aaa":"code","30f09b14":"code","0c8778f5":"code","77d0e237":"code","1203a848":"code","7b6af4b0":"code","201f0d94":"code","02e42ab6":"code","403233b1":"code","5184842a":"code","424dae3a":"code","1410265b":"code","7431e1b5":"code","817aea06":"code","fa89001f":"markdown","fdb35070":"markdown","9848c248":"markdown","f683a4d3":"markdown","d476e93e":"markdown","3d0324c4":"markdown","3f561289":"markdown","19be3a34":"markdown","da800058":"markdown","dc36fe90":"markdown","c16629f6":"markdown","859754d7":"markdown","011b48cc":"markdown","a6a1d9ad":"markdown","c46195b3":"markdown","bac7bf56":"markdown","dc900623":"markdown","74ed13bb":"markdown","9a859072":"markdown","baa6581d":"markdown","11b87597":"markdown","61d96c83":"markdown","79f929d7":"markdown","8a0a732c":"markdown","1fec0f06":"markdown","64081ca3":"markdown"},"source":{"8b8a0946":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f72e438":"import numpy as np \nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n%matplotlib inline","508a9314":"benign_train = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/train\/benign\/'\nmalignant_train = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/train\/malignant\/'\n\nbenign_test = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/test\/benign\/'\nmalignant_test = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/test\/malignant\/'\n\n\nread = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\nims_benign = [read(os.path.join(benign_train, filename)) for filename in os.listdir(benign_train)]\nX_benign = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(malignant_train, filename)) for filename in os.listdir(malignant_train)]\nX_malignant = np.array(ims_malignant, dtype='uint8')\n\nims_benign = [read(os.path.join(benign_test, filename)) for filename in os.listdir(benign_test)]\nX_benign_test = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(malignant_test, filename)) for filename in os.listdir(malignant_test)]\nX_malignant_test = np.array(ims_malignant, dtype='uint8')\n","fcfc1687":"y_benign = np.zeros(X_benign.shape[0])\ny_malignant = np.ones(X_malignant.shape[0])\ny_benign_test = np.zeros(X_benign_test.shape[0])\ny_malignant_test = np.ones(X_malignant_test.shape[0])","33e9d0b0":"X_train = np.concatenate((X_benign, X_malignant), axis = 0)\ny_train = np.concatenate((y_benign, y_malignant), axis = 0)\n\nX_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\ny_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)\n","e9c798c4":"s = np.arange(X_train.shape[0])\nnp.random.shuffle(s)\nX_train = X_train[s]\ny_train = y_train[s]\n\ns = np.arange(X_test.shape[0])\nnp.random.shuffle(s)\nX_test = X_test[s]\ny_test = y_test[s]\n","b00e7e79":"w=30\nh=30\nfig=plt.figure(figsize=(12, 8))\ncolumns = 5\nrows = 2\n\nfor i in range(1, columns*rows +1):\n    ax = fig.add_subplot(rows, columns, i)\n    if y_train[i] == 0:\n        ax.title.set_text('Benign')\n    else:\n        ax.title.set_text('Malignant')\n    plt.imshow(X_train[i], interpolation='nearest')\nplt.show()\n\n\n","7b02ad8d":"blue,green,red = cv2.split(X_train[i])\nprint(blue,green,red)\n","c934d82d":"pca = PCA(10)\npca1=PCA(50)\npca2=PCA(200)\n \n#Applying to red channel and then applying inverse transform to transformed array.\nred_transformed = pca.fit_transform(red)\nred_inverted = pca.inverse_transform(red_transformed)\n\nred_transformed1 = pca1.fit_transform(red)\nred_inverted1 = pca1.inverse_transform(red_transformed1)\n\nred_transformed2 = pca2.fit_transform(red)\nred_inverted2 = pca2.inverse_transform(red_transformed2)\n\n \n#Applying to Green channel and then applying inverse transform to transformed array.\ngreen_transformed = pca.fit_transform(green)\ngreen_inverted = pca.inverse_transform(green_transformed)\n \ngreen_transformed1 = pca1.fit_transform(green)\ngreen_inverted1 = pca1.inverse_transform(green_transformed1)\n\ngreen_transformed2 = pca2.fit_transform(green)\ngreen_inverted2 = pca2.inverse_transform(green_transformed2)\n \n#Applying to Blue channel and then applying inverse transform to transformed array.\nblue_transformed = pca.fit_transform(blue)\nblue_inverted = pca.inverse_transform(blue_transformed)\n\nblue_transformed1 = pca1.fit_transform(blue)\nblue_inverted1 = pca1.inverse_transform(blue_transformed1)\n\nblue_transformed2 = pca2.fit_transform(blue)\nblue_inverted2 = pca2.inverse_transform(blue_transformed2)","2e53497c":"img_compressed = (np.dstack((red_inverted, red_inverted, red_inverted))).astype(np.uint8)\nimg_compressed1 = (np.dstack((red_inverted1, red_inverted1, red_inverted1))).astype(np.uint8)\nimg_compressed2 = (np.dstack((red_inverted2, red_inverted2, red_inverted2))).astype(np.uint8)","1897c5ba":"fig=plt.figure(figsize=(14, 10))\nplt.subplot(2,3,1)\nplt.imshow(img_compressed)\nplt.subplot(2,3,2)\nplt.imshow(img_compressed1)\nplt.subplot(2,3,3)\nplt.imshow(img_compressed2)","9c2d6e4b":"print(X_train.shape)\nprint(X_train.size)\nprint(len(X_train))\n","335ef94d":"from tensorflow.keras.utils import to_categorical\n\ny_train=to_categorical(\n    y_train, num_classes=2, dtype='float32'\n)\ny_test=to_categorical(\n    y_test, num_classes=2, dtype='float32'\n)\n","fc8ba798":"import numpy as np\nX_train = X_train\/ 255\nX_test = X_test\/ 255\n","9e8f8d53":"import keras\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, ReLU, BatchNormalization, Dropout, Dense, InputLayer, Flatten\nfrom keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom keras import regularizers","0fbd5fc3":"    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),padding = 'Same',input_shape=(224,224,3),\n                     activation= \"sigmoid\", kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size = (2, 2)))\n \n    model.add(Dropout(0.3))\n\n   \n    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same', \n                     activation =\"sigmoid\", kernel_initializer = 'he_uniform'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size = (2, 2)))\n  \n    model.add(Dropout(0.3))\n\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(2, activation='softmax'))\n    model.compile(loss= BinaryCrossentropy(),optimizer=Adam(0.001), metrics=['accuracy'])","7560430b":"model.summary()","01539aaa":"tf.keras.utils.plot_model(\n    model, to_file='model.png', show_shapes=True,\n    show_layer_names=True,\n)","30f09b14":"from keras import utils, callbacks\nearlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n                                        patience=5, restore_best_weights = True)","0c8778f5":"history = model.fit(X_train,y_train,verbose=1,epochs=10,callbacks = [earlystopping],validation_split=0.2)","77d0e237":"plt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\n","1203a848":"print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")","7b6af4b0":"from keras.models import load_model\nmodel.save('skincancer.h5')","201f0d94":"from sklearn.metrics import confusion_matrix\nY_pred=model.predict(X_test) \nY_pred=np.argmax(Y_pred, axis=1)\ny_test=np.argmax(y_test, axis=1)\ncm = confusion_matrix(y_test, Y_pred)\nprint(cm)","02e42ab6":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test, Y_pred, target_names = ['Benign (Class 0)','Malignant(Class 1)']))","403233b1":"correct = np.nonzero(Y_pred == y_test)[0]\nincorrect = np.nonzero(Y_pred != y_test)[0]","5184842a":"i = 0\nfor c in correct[:6]:\n    plt.subplot(3,2,i+1)\n    plt.imshow(X_test[c].reshape(224,672), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(Y_pred[c], y_test[c]))\n    plt.tight_layout()\n    i +=1\n    ","424dae3a":"i = 0\nfor c in incorrect[:6]:\n    plt.subplot(3,2,i+1)\n    plt.imshow(X_test[c].reshape(224,672), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(Y_pred[c], y_test[c]))\n    plt.tight_layout()\n    i += 1","1410265b":"import numpy as np # linear algebra\nimport cv2\nimport matplotlib.pyplot as plt","7431e1b5":"np.linalg.norm(np.random.uniform(0, 16, size=1000), ord=np.inf)","817aea06":"im_norm = lambda i: (i.astype(np.float32)-i.min()) \/ (i.max()-i.min())\n\nim = cv2.imread('..\/input\/skin-cancer-malignant-vs-benign\/test\/benign\/1.jpg')\n\nim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n\nim_adversarial = lambda pert: im + np.random.uniform(0, pert, size=im.shape)\n\nfig, ax = plt.subplots(4, 2, figsize=(14, 28))\n\nax = ax.ravel()\n\nperturbations = [4, 8, 16, 32, 64, 128, 256]\n\nax[0].imshow(im_norm(im), interpolation='nearest')\nax[0].set_title('Original')\n\nfor i, perturbation in enumerate(perturbations, 1):\n    ax[i].imshow(im_norm(im_adversarial(perturbation)), interpolation='nearest')\n    ax[i].set_title('Perturbation @{}'.format(perturbation))","fa89001f":"**Compression des images**\n\n*La transformation inverse est n\u00e9cessaire pour recr\u00e9er les dimensions originales de l'image de base..*","fdb35070":"**Plotting accuracy and loss**","9848c248":"Nous avons donc appliqu\u00e9 un bruit uniforme \u00e0 une image cible afin de visualiser ses effets. Voici les r\u00e9sultats :","f683a4d3":"**Quelques predictions correctes des classes**","d476e93e":"Nous remarquons que la norme de l'infini est li\u00e9e \u00e0 l'\u00e9tendue d'une distribution uniforme...","3d0324c4":"**Data shuffling**","3f561289":"**Training the model**","19be3a34":"**Analyse en composantes principales pour la compression des donn\u00e9es d'image**\n\n**Splitting des images en tableaux R,G,B**\n\n*une image num\u00e9rique en couleur est une combinaison de matrices R, G et B empil\u00e9es les unes sur les autres. Par cons\u00e9quent, on s\u00e9pare chaque canal de l'image et on extrait les composantes principales de chacun d'eux.*","da800058":"**Normalisation des pixels:** Mise \u00e0 l'\u00e9chelle des valeurs de pixel dans la plage 0-1.","dc36fe90":"**Predictions incorrectes des classes**","c16629f6":"**Affichage des 10 premi\u00e8res images de moles**","859754d7":"**Importation des libraries**","011b48cc":"**Application de PCA \u00e0 chaque tableau**","a6a1d9ad":"**Chargement d'images et lecture de plusieurs images RVB dans un tableau numpy**","c46195b3":"*Too many epochs can lead to overfitting of the training dataset, whereas too few may result in an underfit model. Early stopping is a method that allows you to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out validation dataset.*","bac7bf56":"**Creation des labels**","dc900623":"**fusion de donn\u00e9es**","74ed13bb":"# **Visualizing Max Perturbation**","9a859072":"Dans le domaine de l'apprentissage profond, un r\u00e9seau neuronal convolutif (CNN\/ConvNet) est une classe de r\u00e9seaux neuronaux profonds, le plus souvent appliqu\u00e9e \u00e0 l'analyse de l'imagerie visuelle.\nComme la couche convolutionnelle, la couche de mise en commun est responsable de la r\u00e9duction de la taille spatiale de la caract\u00e9ristique convolu\u00e9e. Cela permet de diminuer la puissance de calcul n\u00e9cessaire au traitement des donn\u00e9es par r\u00e9duction de la dimensionnalit\u00e9.\n\nIl existe deux types de mise en commun : Max Pooling et Average Pooling. \nLa mise en commun maximale renvoie la valeur maximale de la partie de l'image couverte par le noyau. D'autre part, la mise en commun moyenne renvoie la moyenne de toutes les valeurs de la partie de l'image couverte par le noyau.\n\nL'ajout d'une couche enti\u00e8rement connect\u00e9e est un moyen (g\u00e9n\u00e9ralement) bon march\u00e9 d'apprendre des combinaisons non lin\u00e9aires des caract\u00e9ristiques de haut niveau repr\u00e9sent\u00e9es par la sortie de la couche convolutive. Sur une s\u00e9rie d'\u00e9poques, le mod\u00e8le est capable de distinguer les caract\u00e9ristiques de bas niveau dominantes et certaines caract\u00e9ristiques de bas niveau dans les images et de les classer en utilisant la technique de classification Softmax.\nIci, j'ai utilis\u00e9 l'entropie crois\u00e9e binaire, qui compare chacune des probabilit\u00e9s pr\u00e9dites \u00e0 la sortie de classe r\u00e9elle qui peut \u00eatre soit 0 soit 1. \n\nLes abandons sont la technique de r\u00e9gularisation qui est utilis\u00e9e pour emp\u00eacher le surajustement du mod\u00e8le. Les abandons sont ajout\u00e9s pour commuter de mani\u00e8re al\u00e9atoire un certain pourcentage de neurones du r\u00e9seau. Il est toujours bon de ne commuter les neurones qu'\u00e0 50 %. Il est toujours bon de ne d\u00e9sactiver que 50 % des neurones. Si nous d\u00e9sactivons plus de 50 % des neurones, il est possible que le mod\u00e8le soit mal adapt\u00e9 et que les pr\u00e9dictions ne soient pas bonnes.\n\nUne couche de normalisation de lot examine chaque lot au fur et \u00e0 mesure qu'il arrive, en normalisant d'abord le lot avec sa propre moyenne et son propre \u00e9cart-type, puis en pla\u00e7ant les donn\u00e9es sur une nouvelle \u00e9chelle avec deux param\u00e8tres de remise \u00e0 l'\u00e9chelle pouvant \u00eatre entra\u00een\u00e9s. Batchnorm, en fait, effectue une sorte de remise \u00e0 l'\u00e9chelle coordonn\u00e9e de ses entr\u00e9es.\n","baa6581d":"**INTRODUCTION**","11b87597":"**Importation n\u00e9cessaires**","61d96c83":"**Visualisation des mages compress\u00e9es**","79f929d7":"Skin cancer is an abnormal growth of skin cells. It generally develops in areas that are exposed to the sun, but it can also form in places that don\u2019t normally get sun exposure.\nThe two main categories of skin cancers are defined by the cells involved.\nBasal and squamous cell carcinomas are the two most common types of skin cancer. They begin in the basal and squamous layers of the skin, respectively. Melanoma, the third most common type of skin cancer, begins in the melanocytes.\n\nGoal: To create a model, which can classify a mole visually into benign and malignant using Convolutional Neural Network.\n","8a0a732c":"**Categorical labels**","1fec0f06":"**Model plot**","64081ca3":"**Conclusion:** L'image de sortie devient plus claire en augmentant le nombre de composantes principales.. "}}