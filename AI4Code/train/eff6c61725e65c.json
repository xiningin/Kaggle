{"cell_type":{"adce9345":"code","120fc186":"code","7e86cb9c":"code","57ac4a42":"code","51b3eb81":"code","5eef5d5d":"code","85640551":"code","52fd19fe":"code","87e1c5c0":"code","8c34d5e2":"code","a32c7411":"code","ed625701":"code","c9ce4caa":"code","1d603cc6":"code","ff9e4e72":"code","a6913da6":"code","e0817c6a":"code","46c301eb":"code","b5727c4f":"code","87e7a55b":"code","52d189b3":"code","16aa1066":"code","82841641":"code","d931ff0b":"code","08f9316f":"code","89d0ae0b":"code","a7cc9f2c":"code","5f5460b3":"code","c0b8a7eb":"code","51238691":"code","9fe3b98c":"code","5de22531":"code","1e3ed5d4":"code","e25e1bbc":"code","a31d9f7c":"code","23fe86aa":"code","7951a484":"code","f74c36ee":"code","93445b08":"code","23d7ff9c":"code","4f7eec8c":"code","4da9ea84":"code","cf1a4055":"code","b36c26b6":"code","3e991c64":"code","aef721db":"markdown","89d6b1b2":"markdown","a513a0b4":"markdown","1c13f6b9":"markdown","afe6f1cf":"markdown","65a2950d":"markdown"},"source":{"adce9345":"import warnings\nwarnings.simplefilter(\"ignore\")","120fc186":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7e86cb9c":"df = pd.read_csv(\"..\/input\/heart.csv\")","57ac4a42":"df.head()","51b3eb81":"df.info()","5eef5d5d":"df.isnull().sum()","85640551":"df.shape","52fd19fe":"df.describe()","87e1c5c0":"df.target.value_counts()","8c34d5e2":"corr = df.corr()\nplt.figure(figsize=(18,10))\nsns.heatmap(corr, annot=True)\nplt.show()","a32c7411":"sns.countplot(df.target, palette=['green', 'red'])\nplt.title(\"[0] == Not Disease, [1] == Disease\");","ed625701":"plt.figure(figsize=(18, 10))\nsns.countplot(x='age', hue='target', data=df, palette=['#1CA53B', 'red'])\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","c9ce4caa":"#sns.set_style(\"whitegrid\")\nplt.figure(figsize=(18, 10))\nsns.distplot(df.age[df['target'] == 0], bins=30, color='#1CA53B', label='Not Disease')\nsns.distplot(df.age[df['target'] == 1], bins=30, color='red', label='Disease')\nplt.legend()\nplt.title('Heart Disease Distribution for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","1d603cc6":"fig, axes = plt.subplots(3, 2, figsize=(12,12))\nfs = ['cp', 'fbs', 'restecg','exang', 'slope', 'ca']\nfor i, axi in enumerate(axes.flat):\n    sns.countplot(x=fs[i], hue='target', data=df, palette='bwr', ax=axi) \n    axi.set(ylabel='Frequency')\n    axi.legend([\"Haven't Disease\", \"Have Disease\"])","ff9e4e72":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='trestbps',y='thalach',data=df,hue='target')\nplt.show()","a6913da6":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='chol',y='thalach',data=df,hue='target')\nplt.show()","e0817c6a":"plt.scatter(x=df.age[df.target==1], y=df.thalach[(df.target==1)], c=\"red\")\nplt.scatter(x=df.age[df.target==0], y=df.thalach[(df.target==0)])\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Maximum Heart Rate\")\nplt.show()","46c301eb":"from sklearn.preprocessing import StandardScaler\n\n# Import tools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.metrics import roc_curve, auc","b5727c4f":"# Define our feasures and leabels\nX = df.drop(['target'], axis=1).values\ny = df['target'].values","87e7a55b":"scale = StandardScaler()\nX = scale.fit_transform(X)","52d189b3":"class Model:\n    def __init__(self, model, X, y):\n        self.model = model\n        self.X = X\n        self.y = y\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.5, random_state=42)\n        \n        self.model.fit(self.X_train, self.y_train)\n        print(f\"{self.model_str()} Model Trained..\")\n        self.y_pred = self.model.predict(self.X_test)\n        \n    def model_str(self):\n        return str(self.model.__class__.__name__)\n    \n    def crossValScore(self, cv=5):\n        print(self.model_str() + \"\\n\" + \"=\"*60)\n        scores = [\"accuracy\", \"precision\", \"recall\", \"roc_auc\"]\n        for score in scores:  \n            cv_acc = cross_val_score(self.model, \n                                     self.X_train, \n                                     self.y_train, \n                                     cv=cv, \n                                     scoring=score).mean()\n            \n            print(\"Model \" + score + \" : \" + \"%.3f\" % cv_acc)\n        \n        \n    def accuracy(self):\n        accuarcy = accuracy_score(self.y_test, self.y_pred)\n        print(self.model_str() + \" Model \" + \"Accuracy is: \")\n        return accuarcy\n        \n    def confusionMatrix(self):        \n        plt.figure(figsize=(5, 5))\n        mat = confusion_matrix(self.y_test, self.y_pred)\n        sns.heatmap(mat.T, square=True, \n                    annot=True, \n                    cbar=False, \n                    xticklabels=[\"Haven't Disease\", \"Have Disease\"], \n                    yticklabels=[\"Haven't Disease\", \"Have Disease\"])\n        \n        plt.title(self.model_str() + \" Confusion Matrix\")\n        plt.xlabel('Predicted Values')\n        plt.ylabel('True Values');\n        plt.show();\n        \n    def classificationReport(self):\n        print(self.model_str() + \" Classification Report\" + \"\\n\" + \"=\"*60)\n        print(classification_report(self.y_test, \n                                    self.y_pred, \n                                    target_names=['Non Disease', 'Disease']))\n    \n    def rocCurve(self):\n        y_prob = self.model.predict_proba(self.X_test)[:,1]\n        fpr, tpr, thr = roc_curve(self.y_test, y_prob)\n        lw = 2\n        plt.figure(figsize=(8, 6))\n        plt.plot(fpr, tpr, \n                 color='darkorange', \n                 lw=lw, \n                 label=\"Curve Area = %0.3f\" % auc(fpr, tpr))\n        plt.plot([0, 1], [0, 1], color='green', \n                 lw=lw, linestyle='--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(self.model_str() + ' Receiver Operating Characteristic Plot')\n        plt.legend(loc=\"lower right\")\n        plt.show()","16aa1066":"from sklearn.ensemble import RandomForestClassifier\n\nclf = Model(model=RandomForestClassifier(), X=X, y=y)","82841641":"clf.crossValScore(cv=10)","d931ff0b":"clf.accuracy()","08f9316f":"clf.confusionMatrix()","89d0ae0b":"clf.classificationReport()","a7cc9f2c":"from sklearn.svm import SVC\n\nsvm = Model(model=SVC(C=5, probability=True), X=X, y=y)","5f5460b3":"svm.crossValScore(cv=10)","c0b8a7eb":"svm.accuracy()","51238691":"svm.confusionMatrix()","9fe3b98c":"svm.classificationReport()","5de22531":"import warnings\nwarnings.simplefilter(\"ignore\")\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import QuantileTransformer\n\nlr = LogisticRegression()\npipeline = make_pipeline(QuantileTransformer(output_distribution='normal'), lr)\n\npip = Model(model=pipeline, X=X, y=y)","1e3ed5d4":"pip.crossValScore()","e25e1bbc":"pip.accuracy()","a31d9f7c":"pip.confusionMatrix()","23fe86aa":"pip.classificationReport()","7951a484":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = Model(model=KNeighborsClassifier(n_neighbors=100), X=X, y=y)","f74c36ee":"knn.crossValScore()","93445b08":"knn.accuracy()","23d7ff9c":"knn.confusionMatrix()","4f7eec8c":"knn.classificationReport()","4da9ea84":"models = [clf, svm, pip, knn]\nfor model in models[:2]:\n    model.rocCurve()","cf1a4055":"models = [clf, svm, pip, knn]\nfor model in models[2:]:\n    model.rocCurve()","b36c26b6":"models = [clf, svm, pip, knn]\nnames = []\naccs = []\nfor model in models:\n    accs.append(model.accuracy());\n    names.append(model.model_str());","3e991c64":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,1.2,0.1))\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Algorithms\")\nsns.barplot(x=names, y=accs)\nplt.savefig('models_accuracy.png')\nplt.show()","aef721db":"# 4. Machine Learning","89d6b1b2":"# 2. Data Preparation","a513a0b4":"# 1. Introduction\nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to this date. The \"goal\" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4.","1c13f6b9":"<center><h2 style='color:red'>Heart Disease - Classifications<br>By Kassem@elcaiseri<\/h2><\/center>","afe6f1cf":"# 3. Visualization","65a2950d":"<h3>Heart Disease - Classifications + Visualization<h3>\n* *1. Introduction*\n* *2. Data Preparation*\n* *3. Visualization*\n* *4. Machine Learning*"}}