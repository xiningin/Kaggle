{"cell_type":{"a40547a6":"code","63996f6d":"code","efe30055":"code","024f181b":"code","ac730ac5":"code","8343aba4":"code","261191cc":"code","18faa570":"code","97bb0b0b":"markdown","65582b20":"markdown","27b3ce03":"markdown","8f2a7a1f":"markdown","f628c902":"markdown","b108acc3":"markdown","13be9efd":"markdown","1a077e6a":"markdown","e849f1b3":"markdown","041b8cd9":"markdown","4fee44d6":"markdown"},"source":{"a40547a6":"from mlbox.preprocessing import *\nfrom mlbox.optimisation import *\nfrom mlbox.prediction import *","63996f6d":"paths = [\"..\/input\/train.csv\",\"..\/input\/test.csv\"]\ntarget_name = \"SalePrice\"","efe30055":"rd = Reader(sep = \",\")\ndf = rd.train_test_split(paths, target_name)   #reading and preprocessing (dates, ...)","024f181b":"dft = Drift_thresholder()\ndf = dft.fit_transform(df)   #removing non-stable features (like ID,...)","ac730ac5":"rmse = make_scorer(lambda y_true, y_pred: np.sqrt(np.sum((y_true - y_pred)**2)\/len(y_true)), greater_is_better=False, needs_proba=False)\nopt = Optimiser(scoring = rmse, n_folds = 10)","8343aba4":"space = {\n    \n        'est__strategy':{\"search\":\"choice\",\n                                  \"space\":[\"LightGBM\"]},    \n        'est__n_estimators':{\"search\":\"choice\",\n                                  \"space\":[150]},    \n        'est__colsample_bytree':{\"search\":\"uniform\",\n                                  \"space\":[0.8,0.95]},\n        'est__subsample':{\"search\":\"uniform\",\n                                  \"space\":[0.8,0.95]},\n        'est__max_depth':{\"search\":\"choice\",\n                                  \"space\":[5,6,7,8,9]},\n        'est__learning_rate':{\"search\":\"choice\",\n                                  \"space\":[0.07]} \n    \n        }\n\nparams = opt.optimise(space, df,15)","261191cc":"prd = Predictor()\nprd.fit_predict(params, df)","18faa570":"submit = pd.read_csv(\"..\/input\/sample_submission.csv\",sep=',')\npreds = pd.read_csv(\"save\/\"+target_name+\"_predictions.csv\")\n\nsubmit[target_name] =  preds[target_name+\"_predicted\"].values\n\nsubmit.to_csv(\"mlbox.csv\", index=False)","97bb0b0b":"## ... to predict","65582b20":"If you like my new auto-ml package, please put a star on github and fork\/vote the Kaggle script :)","27b3ce03":"### Formatting for submission\n","8f2a7a1f":"# Now let MLBox do the job ! ","f628c902":"# Inputs & imports : that's all you need to give !","b108acc3":"# **That's all !!**","13be9efd":"**LightGBM**","1a077e6a":"Hi everyone ! My brand new Python package for Auto Machine Learning is now available on github\/PyPI\/Kaggle kernels ! :)\n\n**https:\/\/github.com\/AxeldeRomblay\/MLBox**\n\n- It is very easy to use (see **documentation** on github)\n- It provides state-of-the-art algorithms and technics such as deep learning\/entity embedding, stacking, leak detection, parallel processing, hyper-parameters optimization...\n- It has already been tested on Kaggle and performs well (see Kaggle \"Two Sigma Connect: Rental Listing Inquiries\" | Rank : **85\/2488**)\n\n**Please put a star on github and fork the script if you like it !** \n\nEnjoy :) ","e849f1b3":"But you can also tune the whole Pipeline ! Indeed, you can choose:\n\n* different strategies to impute missing values\n* different strategies to encode categorical features (entity embeddings, ...)\n* different strategies and thresholds to select relevant features (random forest feature importance, l1 regularization, ...)\n* to add stacking meta-features !\n* different models and hyper-parameters (XGBoost, Random Forest, Linear, ...)\n\n","041b8cd9":"## ... to read and clean all the files ","4fee44d6":"## ... to tune all the hyper-parameters"}}