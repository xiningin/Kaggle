{"cell_type":{"21ec2a84":"code","01805dda":"code","fd6cd5ef":"code","9371a83a":"code","534e8fac":"code","3a68c096":"code","01fd383e":"code","3d99aaa5":"code","86e9c3e9":"code","58b8c00a":"code","a71f1068":"code","812a4d5f":"code","8854be4b":"code","8fd67694":"code","c9141d0b":"code","069093e9":"code","3eb7c23a":"code","44931e61":"code","168ffc8f":"code","9a1cb03c":"code","b279bb4b":"code","e1f31ef4":"code","c538a01c":"code","390b19c5":"code","bbd4b7f5":"code","818a4de4":"code","7787de21":"code","2846f625":"code","338840fc":"code","3ded8398":"code","847b4011":"code","ddeef94f":"code","1379796b":"code","f4b59eec":"code","9e58bc99":"code","358159ce":"code","7d316cf2":"code","34ee24e0":"code","0ea24b3c":"code","21e122ec":"code","c8d4bbb3":"code","0a1d30c1":"code","0d1b647c":"code","7941f4fc":"code","b7f6627f":"code","cc33f715":"code","65ee7715":"code","b2747229":"code","73338ed3":"code","d8a04e6b":"code","6501623f":"code","939ae6a5":"code","463ee91c":"code","6491d081":"code","6523b4a5":"code","723520ca":"code","ad3053a1":"code","2e4ee41a":"code","1c2b53df":"code","98a58eab":"code","7e1ed98d":"code","3588c5aa":"code","e9dec912":"code","3ac3f70a":"code","6cd8edfe":"code","c84f475b":"code","89c2499d":"code","47fdac53":"code","4bf44935":"code","7457c0c7":"code","10189836":"code","ee0e37fe":"code","52b71bde":"code","3a69191d":"code","b49e35d8":"code","915e0243":"code","0474c32c":"code","579e98c5":"code","ca7aa09a":"code","4e3c732e":"code","4afbff44":"code","c15b8287":"code","cea7702b":"code","aaba6811":"code","8ead87ca":"code","c1c41cc7":"code","da736bae":"code","e4225eb0":"code","aba0a97b":"code","77f053c3":"code","57812b0f":"code","296efd7a":"code","0ba19501":"code","af510d22":"code","69655832":"code","64e06564":"code","49d4a154":"code","e009bc40":"code","d9f4749c":"code","6ab96096":"code","742dd02c":"code","5998e5ce":"code","bcf5f192":"code","88072dce":"code","f363f61f":"code","9b8b4f51":"code","385ef91b":"code","c146086f":"code","60d08c4f":"code","e819c253":"code","ec205502":"code","cdac7b80":"code","4f09c5c4":"code","d1c4ec75":"code","6562ddb4":"code","987b72f1":"code","77e79c64":"code","3d6e2df9":"code","54818dbf":"code","93fb69a3":"code","8471dbef":"code","365d5311":"code","61130d20":"code","645e2d7a":"code","ceb7f4a7":"code","90899bd3":"code","f0d66c9a":"code","1643f3e3":"markdown","84697b7b":"markdown","3daa6f5a":"markdown","188ce236":"markdown","ec3f19c1":"markdown","ca2efca1":"markdown","e025dd3e":"markdown","c1a5d0bd":"markdown","118877fb":"markdown","f2a8778b":"markdown","49d73a00":"markdown","b920fd05":"markdown","366e6600":"markdown","0f9ceb20":"markdown","1970ee3e":"markdown","33a797d3":"markdown","f80f8f67":"markdown","5c412442":"markdown","6729a73e":"markdown","67644fdb":"markdown","f0866ea6":"markdown","88fa7771":"markdown","587368dc":"markdown","06622b47":"markdown","ccf28472":"markdown","af3fe8e5":"markdown","5c1bdd44":"markdown","eea1f8a0":"markdown","286ad131":"markdown","a7fd1d9d":"markdown","30b3f5c8":"markdown","8c29f786":"markdown","3fb70994":"markdown","27f71b9a":"markdown","27ce9017":"markdown","fd606ddc":"markdown","04f8cbd9":"markdown","6d4dd0f3":"markdown","12bd66bb":"markdown"},"source":{"21ec2a84":"import numpy as np\nimport pandas as pd \nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import scale \nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import tree\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","01805dda":"diabetes = pd.read_csv(\"..\/input\/docspot\/datasets_228_482_diabetes.csv\")\ndata = diabetes.copy()\ndata = data.dropna()\ndata.head()","fd6cd5ef":"data.info()","9371a83a":"data.describe().T","534e8fac":"data[\"Outcome\"].value_counts()","3a68c096":"data[\"Outcome\"].value_counts().plot.barh();","01fd383e":"y = data[\"Outcome\"]\nX = data.drop([\"Outcome\"], axis=1)","3d99aaa5":"log = sm.Logit(y, X)\nlog_model = log.fit()","86e9c3e9":"log_model.summary()","58b8c00a":"from sklearn.linear_model import LogisticRegression\nlog = LogisticRegression(solver=\"liblinear\")\nlog_model = log.fit(X,y)\nlog_model","a71f1068":"log_model.intercept_","812a4d5f":"log_model.coef_","8854be4b":"y_pred = log_model.predict(X)","8fd67694":"confusion_matrix(y, y_pred)","c9141d0b":"accuracy_score(y,y_pred)","069093e9":"print(classification_report(y,y_pred))","3eb7c23a":"log_model.predict(X)[:5]","44931e61":"log_model.predict_proba(X)[:5]","168ffc8f":"y[:5]","9a1cb03c":"y_probs = log_model.predict_proba(X)\ny_probs = y_probs[:,1]","b279bb4b":"y_probs[:5]","e1f31ef4":"y_pred = [1 if i > 0.5 else 0 for i in y_probs]\ny_pred[:5]","c538a01c":"confusion_matrix(y, y_pred)","390b19c5":"accuracy_score(y,y_pred)","bbd4b7f5":"print(classification_report(y,y_pred))","818a4de4":"logit_roc_auc = roc_auc_score(y, log_model.predict(X))\n\nfpr, tpr, thresholds = roc_curve(y, log_model.predict_proba(X)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Ratio')\nplt.ylabel('True Positive Ratio')\nplt.title('ROC')\nplt.show()","7787de21":"X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","2846f625":"log = LogisticRegression(solver = \"liblinear\")\nlog_model = log.fit(X_train,y_train)\nlog_model","338840fc":"accuracy_score(y_test,log_model.predict(X_test))","3ded8398":"cross_val_score(log_model,X_test, y_test,cv=10).mean()","847b4011":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","ddeef94f":"nb = GaussianNB()\nnb_model = nb.fit(X_train,y_train)\nnb_model","1379796b":"nb_model.predict(X_test)[:10]","f4b59eec":"nb_model.predict_proba(X_test)[:10]","9e58bc99":"y_pred = nb_model.predict(X_test)\naccuracy_score(y_test,y_pred)","358159ce":"cross_val_score(nb_model,X_test, y_test,cv=10).mean()","7d316cf2":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","34ee24e0":"knn = KNeighborsClassifier()\nknn_model = knn.fit(X_train, y_train)\nknn_model","0ea24b3c":"y_pred = knn_model.predict(X_test)\naccuracy_score(y_test,y_pred)","21e122ec":"print(classification_report(y_test,y_pred))","c8d4bbb3":"cross_val_score(knn_model,X_test, y_test,cv=10).mean()","0a1d30c1":"knn_params = {\"n_neighbors\": np.arange(50)}","0d1b647c":"knn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn,knn_params, cv=10)\nknn_cv.fit(X_train,y_train)","7941f4fc":"print(\"Best Score:\" + str(knn_cv.best_score_))\nprint(\"Best Parameters: \" + str(knn_cv.best_params_[\"n_neighbors\"]))","b7f6627f":"knn = KNeighborsClassifier(11)\nknn_tuned =knn.fit(X_train,y_train)","cc33f715":"knn_tuned.score(X_test,y_test)","65ee7715":"y_pred = knn_tuned.predict(X_test)\naccuracy_score(y_test,y_pred)","b2747229":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","73338ed3":"svc_model = SVC(kernel=\"linear\").fit(X_train,y_train)\nsvc_model","d8a04e6b":"y_pred = svc_model.predict(X_test)","6501623f":"accuracy_score(y_test,y_pred)","939ae6a5":"svc_params = {\"C\": np.arange(1,10)}\n\nsvc = SVC(kernel=\"linear\")\nsvc_cv_model = GridSearchCV(svc, svc_params, cv=10, n_jobs=-1,verbose=2)\n\nsvc_cv_model.fit(X_train,y_train)","463ee91c":"print(\"Best Parameters: \" + str(svc_cv_model.best_params_[\"C\"]))","6491d081":"svc_tuned = SVC(kernel=\"linear\", C=5).fit(X_train,y_train)","6523b4a5":"y_pred = svc_tuned.predict(X_test)\naccuracy_score(y_test,y_pred)","723520ca":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","ad3053a1":"svc_model = SVC(kernel=\"rbf\").fit(X_train,y_train)\nsvc_model","2e4ee41a":"y_pred =svc_model.predict(X_test)\naccuracy_score(y_test,y_pred)","1c2b53df":"svc_params = \n{\n    \"C\": [0.0001,0.001,0.01,0.1,5,10,50,100,200],\n    \"gamma\": [0.0001,0.001,0.01,0.1,5,10,50,100,200]\n}","98a58eab":"svc = SVC()\nsvc_cv_model = GridSearchCV(svc,svc_params,cv = 10,n_jobs = -1, verbose=2)\nsvc_cv_model.fit(X_train,y_train)","7e1ed98d":"print(\"Best Parameters: \" + str(svc_cv_model.best_params_))","3588c5aa":"svc_tuned = SVC(C=10, gamma =0.0001).fit(X_train,y_train)","e9dec912":"y_pred = svc_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","3ac3f70a":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","6cd8edfe":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","c84f475b":"mlpc = MLPClassifier().fit(X_train_scaled,y_train)\nmlpc.coefs_","89c2499d":"y_pred = mlpc.predict(X_test_scaled)\naccuracy_score(y_test, y_pred)","47fdac53":"mlpc_params = \n{\n    \"alpha\": [0.1,0.01,0.02,0.005,0.001,0.0001,0.00001],\n    \"hidden_layer_sizes\": [(10,10,10),\n                           (100,100,100),\n                           (100,100),\n                           (3,5),\n                           (5,3)],\n    \"solver\": [\"lbfgs\",\"adam\",\"sgd\"],\n    \"activation\": [\"relu\",\"logistic\"]\n}","4bf44935":"mlpc = MLPClassifier()\nmlpc_cv_model = GridSearchCV(mlpc,mlpc_params,cv=10,n_jobs = -1, verbose=2)\nmlpc_cv_model.fit(X_train_scaled,y_train)","7457c0c7":"print(\"Best Parameters: \" + str(mlpc_cv_model.best_params_))","10189836":"mlpc_tuned = MLPClassifier(alpha = 0.001 , hidden_layer_sizes = (100, 100, 100), solver = \"sgd\", activation = \"relu\")","ee0e37fe":"mlpc_tuned.fit(X_train_scaled,y_train)\ny_pred = mlpc_tuned.predict(X_test_scaled)\naccuracy_score(y_test, y_pred)","52b71bde":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","3a69191d":"cart = DecisionTreeClassifier()\ncart_model = cart.fit(X_train,y_train)\ncart_model","b49e35d8":"x = [3]","915e0243":"y_pred = cart_model.predict(X_test_scaled)\naccuracy_score(y_test, y_pred)","0474c32c":"cart_grid = \n{\n    \"max_depth\": list(range(10)),\n    \"min_samples_split\": range(2,50),\n}","579e98c5":"cart = tree.DecisionTreeClassifier()\ncart_cv = GridSearchCV(cart,cart_grid, cv=10, n_jobs=-1,verbose=2)\ncart_cv_model = cart_cv.fit(X_train,y_train)","ca7aa09a":"print(\"Best Parameters: \" + str(cart_cv_model.best_params_))","4e3c732e":"cart = tree.DecisionTreeClassifier(max_depth = 5, min_samples_split = 19)\ncart_tuned = cart.fit(X_train, y_train)","4afbff44":"y_pred = cart_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","c15b8287":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","cea7702b":"from sklearn.ensemble import RandomForestClassifier","aaba6811":"rf_model = RandomForestClassifier().fit(X_train, y_train)","8ead87ca":"rf_model","c1c41cc7":"y_pred = rf_model.predict(X_test)\naccuracy_score(y_test, y_pred)","da736bae":"rf_params = {\n    \"max_depth\": [2,5,8,10],\n    \"max_features\": [5,8,10],\n    \"n_estimators\": [10,500,1000,2000],\n    \"min_samples_split\": [2,5,10]\n}","e4225eb0":"rf_model = RandomForestClassifier()","aba0a97b":"rf_cv_model = GridSearchCV(rf_model, rf_params,cv=10, n_jobs=-1, verbose=2)","77f053c3":"rf_cv_model.fit(X_train,y_train)","57812b0f":"print(\"Best Parameters: \" + str(rf_cv_model.best_params_))","296efd7a":"rf_tuned = RandomForestClassifier(max_depth = 10,max_features = 8,n_estimators = 1000,min_samples_split = 8)\nrf_tuned.fit(X_train, y_train)","0ba19501":"y_pred = rf_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","af510d22":"Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n                         index = X_train.columns)","69655832":"Importance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"Variable Significance Levels\");","64e06564":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","49d4a154":"gbc_model = GradientBoostingClassifier().fit(X_train,y_train)","e009bc40":"y_pred = gbc_model.predict(X_test)\naccuracy_score(y_test, y_pred)","d9f4749c":"gbm_params = {\n    \"learning_rate\":[0.001,0.01,0.1,0.05],\n    \"max_depth\": [3,5,10],\n    \"n_estimators\": [100,500,1000],\n    \"min_samples_split\": [2,5,10]\n    }","6ab96096":"gbm = GradientBoostingClassifier()\ngbm_cv = GridSearchCV(gbm,gbm_params,cv=10,n_jobs=-1,verbose=2)","742dd02c":"gbm_cv.fit(X_train,y_train)","5998e5ce":"print(\"Best Parameters: \" + str(gbm_cv.best_params_))","bcf5f192":"gbm = GradientBoostingClassifier(learning_rate=  0.1,max_depth = 3,n_estimators = 100,min_samples_split = 5)\ngbm_tuned = gbm.fit(X_train,y_train)\ny_pred = gbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","88072dce":"xgbm_model = XGBClassifier().fit(X_train,y_train)\ny_pred = xgbm_model.predict(X_test)\naccuracy_score(y_test, y_pred)","f363f61f":"xgbm = XGBClassifier()\nxgbm_params = {\n        'n_estimators': [100, 500, 1000],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5],\n        'learning_rate': [0.01,0.02,0.05],\n        \"min_samples_split\": [2,5,10]}\n\nxgbm_cv_model = GridSearchCV(xgbm,xgbm_params, cv=10,n_jobs=-1,verbose=2)\nxgbm_cv_model.fit(X_train,y_train)","9b8b4f51":"print(\"Best Parameters: \" + str(xgbm_cv_model.best_params_))","385ef91b":"xgb = XGBClassifier(learning_rate = 0.02, \n                    max_depth = 3,\n                    min_samples_split = 2,\n                    n_estimators = 100,\n                    subsample = 0.6)","c146086f":"xgb_tuned =  xgb.fit(X_train,y_train)\ny_pred = xgb_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","60d08c4f":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","e819c253":"lgbm_model = LGBMClassifier().fit(X_train,y_train)","ec205502":"y_pred = lgbm_model.predict(X_test)\naccuracy_score(y_test, y_pred)","cdac7b80":"lgbm_params = {\n        'n_estimators': [100, 500, 1000, 2000],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5,6],\n        'learning_rate': [0.1,0.01,0.02,0.05],\n        \"min_child_samples\": [5,10,20]}","4f09c5c4":"lgbm = LGBMClassifier()\n\nlgbm_cv_model = GridSearchCV(lgbm, lgbm_params, \n                             cv = 10, \n                             n_jobs = -1, \n                             verbose = 2)\n\nlgbm_cv_model.fit(X_train, y_train)","d1c4ec75":"lgbm_cv_model.best_params_","6562ddb4":"lgbm = LGBMClassifier(learning_rate = 0.01, \n                       max_depth = 3,\n                       subsample = 0.6,\n                       n_estimators = 500,\n                       min_child_samples = 20)","987b72f1":"lgbm_tuned = lgbm.fit(X_train,y_train)","77e79c64":"y_pred = lgbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","3d6e2df9":"df = diabetes.copy()\ndf = df.dropna()\ny = df[\"Outcome\"]\nX = df.drop(['Outcome'], axis=1)\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","54818dbf":"catb_model = CatBoostClassifier().fit(X_train,y_train)","93fb69a3":"y_pred = catb_model.predict(X_test)\naccuracy_score(y_test, y_pred)","8471dbef":"catb_params = {\n    'iterations': [200,500],\n    'learning_rate': [0.01,0.05, 0.1],\n    'depth': [3,5,8] }","365d5311":"catb = CatBoostClassifier()\ncatb_cv_model = GridSearchCV(catb, catb_params, cv=5, n_jobs = -1, verbose = 2)\ncatb_cv_model.fit(X_train, y_train)","61130d20":"catb_cv_model.best_params_","645e2d7a":"catb = CatBoostClassifier(iterations = 200, \n                          learning_rate = 0.01, \n                          depth = 8)\n\ncatb_tuned = catb.fit(X_train, y_train)\ny_pred = catb_tuned.predict(X_test)","ceb7f4a7":"y_pred = catb_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","90899bd3":"models = [\n    knn_tuned,\n    log_model,\n    svc_tuned,\n    nb_model,\n    mlpc_tuned,\n    cart_tuned,\n    rf_tuned,\n    gbm_tuned,\n    catb_tuned,\n    lgbm_tuned,\n    xgb_tuned\n    \n]\n\n\nfor model in models:\n    names = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"-\"*28)\n    print(names + \":\" )\n    print(\"Accuracy: {:.4%}\".format(accuracy))","f0d66c9a":"result = []\n\nresults = pd.DataFrame(columns= [\"Models\",\"Accuracy\"])\n\nfor model in models:\n    names = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)    \n    result = pd.DataFrame([[names, accuracy*100]], columns= [\"Models\",\"Accuracy\"])\n    results = results.append(result)\n    \n    \nsns.barplot(x= 'Accuracy', y = 'Models', data=results, color=\"r\")\nplt.xlabel('Accuracy %')\nplt.title('Accuracy Ratio of Models');    ","1643f3e3":"## Model & Predict","84697b7b":"### scikit-learn","3daa6f5a":"## Model Tuning","188ce236":"## Model Tuning","ec3f19c1":"## Model Tuning","ca2efca1":"## Predict & Model Tuning","e025dd3e":"## Model & Predict","c1a5d0bd":"## Model Tuning","118877fb":"## Model Tuning","f2a8778b":"# LightGBM","49d73a00":"# XGBoost","b920fd05":"## Model & Predict","366e6600":"# Comparison of All Models","0f9ceb20":"## Model & Predict","1970ee3e":"* # Logistic Regression","33a797d3":"## Model & Predict","f80f8f67":"## Model","5c412442":"# KNN","6729a73e":"# Gaussian Naive Bayes","67644fdb":"# Diabetes Prediction (using Classification Models)\n* In this notebook I will use classification models to predict who has diabetes and who has not. Besides that, I will show you which model is best.\n* Feel free to give me feedbacks.","f0866ea6":"# SVC (Support Vector Classifier)","88fa7771":"## Model Tuning","587368dc":"## Model Tuning","06622b47":"## Model & Predict","ccf28472":"# Artificial Neural Network","af3fe8e5":"## Model & Predict","5c1bdd44":"## Model & Predict","eea1f8a0":"# CART (Classification and Regression Trees)","286ad131":"## Model Tuning","a7fd1d9d":"# Random Forest","30b3f5c8":"# RBF SVC (Radial Basis Function Support Vector Machines)","8c29f786":"## Model & Predict","3fb70994":"## Model & Predict","27f71b9a":"### statsmodels","27ce9017":"# CatBoost","fd606ddc":"# Gradient Boosting Machines (GBM)","04f8cbd9":"## Model Tuning","6d4dd0f3":"## Model Tuning","12bd66bb":"## Model & Predict"}}