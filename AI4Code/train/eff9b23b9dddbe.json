{"cell_type":{"48eb5327":"code","312686c3":"code","e0ded7f1":"code","b58a6723":"code","d2e37d92":"code","9784cc99":"code","609a7cfa":"code","2cd35845":"code","ff283fab":"code","0ce51014":"code","19df5c31":"code","fe8c0376":"code","1d2a133d":"code","15b93002":"code","be57afc8":"code","eb5296af":"code","39a36784":"code","ab0ecac3":"code","0b8de194":"code","9a376b87":"code","2668716e":"code","62d19dc3":"code","ff16a83a":"code","27a1399b":"code","b71f9c23":"code","a62161e7":"code","0f902770":"code","2bfef4e7":"code","dfaa295e":"code","3d03d5e2":"code","97ef1135":"code","759a59ee":"code","5823a19c":"code","8461daa8":"code","b78119c1":"code","a36353d3":"markdown","905d014c":"markdown","a926b99c":"markdown","5cf80b40":"markdown","a035c536":"markdown","386346d8":"markdown","b832abdd":"markdown","cabc19a5":"markdown","8432ca6c":"markdown"},"source":{"48eb5327":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","312686c3":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom keras_preprocessing.text import Tokenizer\nfrom keras_preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, GRU, SimpleRNN, Embedding, Flatten","e0ded7f1":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\nprint(train.shape, test.shape, submission.shape)","b58a6723":"train.head()","d2e37d92":"test.head()","9784cc99":"submission.head(3)","609a7cfa":"train_text = train['text']\ny = train['target']","2cd35845":"max_len = 100\nmax_words = 10000","ff283fab":"tokenizer = Tokenizer(num_words=max_words)","0ce51014":"tokenizer.fit_on_texts(train_text)\nword_index = tokenizer.word_index\nlen(word_index)","19df5c31":"sequences = tokenizer.texts_to_sequences(train_text)\nX = pad_sequences(sequences, maxlen=max_len)\nX.shape","fe8c0376":"test_data = tokenizer.texts_to_sequences(test['text'])\ntest_data = pad_sequences(test_data, maxlen=max_len)\ntest_data.shape","1d2a133d":"y = np.array(y).reshape((-1,1))\ny.shape","15b93002":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.15)","be57afc8":"def train_model(model, batch_size=32, epochs=8):\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n    history = history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n    print('-' * 100)\n    print('Test data')\n    model.evaluate(X_test, y_test)\n    return history","eb5296af":"def visual_validation_and_accuracy(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs_plot = np.arange(1, len(loss) + 1)\n    plt.clf()\n\n    plt.plot(epochs_plot, acc, 'r', label='Training acc')\n    plt.plot(epochs_plot, val_acc, 'b', label='Validation acc')\n    plt.plot(epochs_plot, loss, 'r:', label='Training loss')\n    plt.plot(epochs_plot, val_loss, 'b:', label='Validation loss')\n    plt.title('Validation and accuracy')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()","39a36784":"model = Sequential([\n    Embedding(max_words, 32, input_length=max_len),\n    Flatten(),\n    Dense(16, activation='relu'),\n    Dropout(0.5),\n    Dense(8, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\nmodel.summary()","ab0ecac3":"history = train_model(model)","0b8de194":"visual_validation_and_accuracy(history)","9a376b87":"model = Sequential([\n    Embedding(max_words, 32, input_length=max_len),\n    SimpleRNN(32, return_sequences=True),\n    SimpleRNN(32),\n    Dense(1, activation='sigmoid')\n])\nmodel.summary()","2668716e":"history = train_model(model)","62d19dc3":"visual_validation_and_accuracy(history)","ff16a83a":"model = Sequential([\n    Embedding(max_words, 32, input_length=max_len),\n    LSTM(32, return_sequences=True),\n    LSTM(32),\n    Dense(1, activation='sigmoid')\n])\nmodel.summary()","27a1399b":"history = train_model(model)","b71f9c23":"visual_validation_and_accuracy(history)","a62161e7":"model = Sequential([\n    Embedding(max_words, 32, input_length=max_len),\n    GRU(32, return_sequences=True),\n    GRU(32),\n    Dense(1, activation='sigmoid')\n])\nmodel.summary()","0f902770":"history = train_model(model)","2bfef4e7":"visual_validation_and_accuracy(history)","dfaa295e":"model = Sequential([\n    Embedding(max_words, 32, input_length=max_len),\n    LSTM(32, return_sequences=True),\n    LSTM(32),\n    Dense(1, activation='sigmoid')\n])\nmodel.summary()","3d03d5e2":"history = train_model(model, batch_size=32, epochs=5)","97ef1135":"visual_validation_and_accuracy(history)","759a59ee":"predict = model.predict(test_data)\npredict.shape","5823a19c":"predict = (predict >= 0.5).astype(int)","8461daa8":"submission.target = predict\nsubmission.head(10)","b78119c1":"submission.to_csv('submission.csv', index=False)","a36353d3":"# Utils","905d014c":"# Load Data","a926b99c":"# Preparation of data","5cf80b40":"# LSTM Model","a035c536":"# SimpleRNN Model","386346d8":"# GRU Model","b832abdd":"# Predict Best Model","cabc19a5":"# Dense Model","8432ca6c":"# Imports\n"}}