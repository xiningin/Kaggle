{"cell_type":{"37741d45":"code","ea5f12ab":"code","332abed1":"code","e00715a9":"code","574a625c":"code","99b66387":"code","ae135351":"code","9004dfd9":"code","512b5b69":"code","e803e40f":"code","3ec7e31f":"code","59cd5725":"code","e62ea39b":"code","3e9e017e":"code","d42973a7":"code","492e340c":"code","0f09bf21":"code","6346e1ca":"code","439f8216":"code","0c7296ba":"code","64419a2e":"code","a6bea365":"code","50fb74dd":"code","8a892fe5":"code","bb457022":"code","6bdaf3a0":"code","4ec71ead":"code","5193df56":"code","c226f0b0":"code","ada1c85b":"code","3e4959cc":"code","d7fb77fc":"code","428bdf3f":"code","0ef48bac":"code","0b443475":"code","8c85f131":"code","b6fd326f":"code","864bfc3b":"code","d3ff04d2":"code","4fdd36ae":"markdown","a8372e7e":"markdown","8fecb765":"markdown","40b508d7":"markdown","008a7284":"markdown","d576a21a":"markdown","c4a14667":"markdown","a5b75e71":"markdown","9cdac8ed":"markdown","1c5084db":"markdown","65ee2c2c":"markdown","ba0342e2":"markdown","0592b054":"markdown","5fec0e62":"markdown","52a95056":"markdown","93c47436":"markdown","d14821bd":"markdown","5d4f4eff":"markdown","dc4f4f18":"markdown","dccb407e":"markdown","6872f3c2":"markdown","ebba6512":"markdown","74b71faa":"markdown","d31b3cc0":"markdown","072b3584":"markdown","dac82d6b":"markdown","9d469ad4":"markdown","1922029f":"markdown","378bfe21":"markdown","7f598a68":"markdown","92125ed1":"markdown"},"source":{"37741d45":"print(\"Contents of input\/facial-keypoints-detection directory: \")\n!ls ..\/input\/facial-keypoints-detection\/\n\nprint(\"\\nExtracting .zip dataset files to working directory ...\")\n!unzip -u ..\/input\/facial-keypoints-detection\/test.zip\n!unzip -u ..\/input\/facial-keypoints-detection\/training.zip\n\nprint(\"\\nCurrent working directory:\")\n!pwd\nprint(\"\\nContents of working directory:\")\n!ls","ea5f12ab":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom IPython.display import clear_output\nfrom time import sleep\nimport os","332abed1":"Train_Dir = 'training.csv'\nTest_Dir = 'test.csv'\nlookid_dir = '..\/input\/facial-keypoints-detection\/IdLookupTable.csv'\ntrain_data = pd.read_csv(Train_Dir)  \ntest_data = pd.read_csv(Test_Dir)\nlookid_data = pd.read_csv(lookid_dir)","e00715a9":"train_data.head().T","574a625c":"train_data.shape","99b66387":"train_data.describe()","ae135351":"train_data.info()","9004dfd9":"all_data_na = (train_data.isnull().sum() \/ len(train_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head(20)","512b5b69":"train_data.isnull().any()","e803e40f":"null_counts = train_data.isnull().sum()\nnull_counts[null_counts > 0].sort_values(ascending=False)","3ec7e31f":"# Set the limit\n# Drop columns using that limit\n# limit = len(train_data) * 0.7\n# new=train_data.dropna(axis=1, thresh=limit)\n# View columns in the dataset\n# new.columns","59cd5725":"type(train_data)","e62ea39b":"#train_data.fillna(method = 'ffill',inplace = True)\ntrain_data = train_data.fillna(pd.concat([train_data.ffill(), train_data.bfill()]).groupby(level=0).mean())","3e9e017e":"train_data.isnull().any()","d42973a7":"train_data.isnull().any().value_counts()","492e340c":"train_data[['Image']].describe()","0f09bf21":"imag = []\nfor i in range(0,7049):  \n    img = train_data['Image'][i].split(' ')\n    img = ['0' if x == '' else x for x in img]\n    imag.append(img)\n    \n    ","6346e1ca":"\ntimag = []\nfor i in range(0,1783):\n    timg = test_data['Image'][i].split(' ')\n    timg = ['0' if x == '' else x for x in timg]\n    \n    timag.append(timg)","439f8216":"image_list = np.array(imag,dtype = 'float')\nX_train = image_list.reshape(-1,96,96,1)","0c7296ba":"timage_list = np.array(timag,dtype = 'float')\nX_test = timage_list.reshape(-1,96,96,1) ","64419a2e":"plt.imshow(X_train[0].reshape(96,96),cmap='gray')\nplt.show()","a6bea365":"training = train_data.drop('Image',axis = 1)\n\ny_train = []\nfor i in range(0,7049):\n    y = training.iloc[i,:]\n\n    y_train.append(y)\ny_train = np.array(y_train,dtype = 'float')","50fb74dd":"from keras.layers.advanced_activations import LeakyReLU\n# from keras.layers import Activation\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D","8a892fe5":"training.shape","bb457022":"'''\n\nmodel = Sequential()\n\nmodel.add(Convolution2D(32, (3,3), padding='same', activation = 'selu', use_bias=False, input_shape=(96,96,1)))\n\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(32, (3,3), padding='same', activation = 'selu',use_bias=False))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, (3,3), padding='same',activation = 'selu', use_bias=False))\n\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(64, (3,3), padding='same',activation = 'selu', use_bias=False))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(128, (3,3),padding='same', activation = 'selu',use_bias=False))\n# model.add(BatchNormalization())\n\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(128, (3,3),padding='same', activation = 'selu',use_bias=False))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(256, (3,3),padding='same',activation = 'selu',use_bias=False))\n\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(256, (3,3),padding='same',activation = 'selu',use_bias=False))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(512, (3,3), padding='same', activation = 'selu',use_bias=False))\n\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(512, (3,3), padding='same',activation = 'selu', use_bias=False))\n\nmodel.add(BatchNormalization())\n\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()\n\n'''","6bdaf3a0":"model = Sequential()\n\nmodel.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n# model.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\n# I didn't use softmax here, because it's only used in logistic regression, \n# where the outputs are usually categorical. But here our outputs are a bunch of floating\n# values, which are not categorical\nmodel.summary()","4ec71ead":"import keras\nmodel.compile(optimizer='adam', \n              loss='mean_squared_error',\n              metrics=['accuracy'])\n\n'''\n# Compile with adam optimizer and cross-entropy loss\n\nmodel.compile(optimizer='adam', \n              loss='mean_squared_error',\n              metrics=['accuracy'])\n              \n# using adam  \nmodel.compile(optimizer=\"adam\", \n              loss=\"categorical_crossentropy\", \n              metrics=[\"accuracy\"])\n\n# Use sgd optimizer\nmodel.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# Use RMSprop\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n'''\n","5193df56":"log = model.fit(X_train,y_train,epochs = 50,batch_size = 512,validation_split = 0.2)","c226f0b0":"pred = model.predict(X_test)","ada1c85b":"# Plotting loss and accuracy curves for training and verification\nfig, ax = plt.subplots(2,1)\n\n# accuracy\nax[0].plot(log.history['accuracy'], color='b', label=\"Training accuracy\")\nax[0].plot(log.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[0].legend(loc='best', shadow=True)\n\n# loss\nax[1].plot(log.history['loss'], color='b', label=\"Training loss\")\nax[1].plot(log.history['val_loss'], color='r', label=\"validation loss\",axes =ax[1])\nlegend = ax[1].legend(loc='best', shadow=True)\nfig.show()\nplt.savefig('FacialKeypointsDetection.png')","3e4959cc":"# RowID\nrowid=list(lookid_data['RowId'])\n\nimageID = list(lookid_data['ImageId']-1)\nfeature_name = list(lookid_data['FeatureName'])","d7fb77fc":"pre_list = list(pred)","428bdf3f":"feature = []\nfor f in feature_name:\n    feature.append(feature_name.index(f))","0ef48bac":"# Location\n# predict using image and feature\nlocation = []\nfor x,y in zip(imageID,feature):\n    location.append(pre_list[x][y])","0b443475":"rowid = pd.Series(rowid,name = 'RowId')","8c85f131":"loc = pd.Series(location,name = 'Location')","b6fd326f":"loc = loc.clip(0.0,96.0)","864bfc3b":"submission = pd.concat([rowid,loc],axis = 1)\n\n","d3ff04d2":"submission.to_csv('FacialKeypointsDetection.csv',index = False)","4fdd36ae":"* Clearly our output function will be formed as regression value.Hence mean_squared_error is used as a loss function. \n* Adam seems to be more promising than rmsprop and sgd. It had to be, as Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum.","a8372e7e":"Drop data based on threshold","8fecb765":"I had tried with selu and relu as an activation function. relu gave slightly better validation accuracy then selu. Though training accuracy is better in case of selu.\nI would better focus on validation accuracy.","40b508d7":"Check the data types along with their corresponding values","008a7284":"Scrutinize the hightest values to get few insights.","d576a21a":"[<h1>Facial Keypoints Detection<\/h1>](https:\/\/www.kaggle.com\/c\/facial-keypoints-detection)\n\n* I have made this kernel in my own way, kind of newbie friendly. \n* My public and private score is successively 4.55126 and 4.24206.\n* I have tried to elaborate every code snippets.\n* An upvote is highly appreciated, if you get benifitted. So that it can reach more people.","c4a14667":"* here 7049 unique numbers exist in image column","a5b75e71":"As the shape of the model is 30. We will assert 30 inside the dense layer.","9cdac8ed":"Preparing training data","1c5084db":"As there are no missing values, we can now separate the labels and features.\nThe images are our features and other values are different labels of columns that we are gonna predict later.\nAs image column values are in string format and there is also some missing values so we have to split the string by space and append it and also handle missing values.","65ee2c2c":"**Based on X_train(image), our model will try to predict their corresponding shapes(y_train). Further we'll exploit the informations after fitting the model on test set**","ba0342e2":"At first, Unzip the necessary files.","0592b054":"Let's check for missing values (based on percentage)","5fec0e62":"Import Packages","52a95056":"Lets reshape and convert it into floating value.","93c47436":"Insert data","d14821bd":"According to the statements, size of the image is 96 pixel. If predicted location exceeds 96 pixel threshold, clip method will assert the highest value(96) on that field.","5d4f4eff":"I have assigned the mean value of ffill and bfill. The result is much more better than using just ffill method.","dc4f4f18":"Lets check the missing values now","dccb407e":"Now the last step is to create our submission file keeping in the mind required format.\nThere should be two columns :- RowId and Location\nLocation column values should be filled according to the provided lookup table( IdLookupTable.csv)\n","6872f3c2":"So there are missing values exist in 28 columns. We can do two things here. one remove the rows having missing values and another is the fill missing values with something. I used two option as removing rows will reduce our dataset. \nI filled the missing values with the previous values in that row.","ebba6512":"Lets explore our dataset","74b71faa":"**Regression Loss Functions**\n\n    1. Mean Squared Error Loss\n    2. Mean Squared Logarithmic Error Loss\n    3. Mean Absolute Error Loss\n\n**Binary Classification Loss Functions**\n\n    1. Binary Cross-Entropy\n    2. Hinge Loss\n    3. Squared Hinge Loss\n\n**Multi-Class Classification Loss Functions**\n\n    1. Multi-Class Cross-Entropy Loss\n    2. Sparse Multiclass Cross-Entropy Loss\n    3. Kullback Leibler Divergence Loss","d31b3cc0":"Preparing test data","072b3584":"Lets predict our results","dac82d6b":"Now lets separate labels.","9d469ad4":"Now our model is defined and we will train it by calling fit method. I ran it for 500 iteration keeping batch size and validtion set size as 20% ( 20% of the training data will be kept for validating the model ).","1922029f":"As our data is ready for training , lets define our model. I am using keras and simple dense layers. For loss function I am using 'mse' ( mean squared error ) as we have to predict new values. Our result evaluted on the basis of 'mae' ( mean absolute error ) . ","378bfe21":"* Convert the values to an image after normalizing so that it can be rendered through the convolutional network\n* The highest and lowest value of float is successively 1 and -1","7f598a68":"From Idlookup table I will fetch the feature using imageId and try to fetch the corresponding value of that particular feature from predictionlist(pre_list)","92125ed1":"Lets see what is the first image."}}