{"cell_type":{"db4bd79a":"code","9c806d86":"code","55cad99b":"code","036c5eb3":"code","dfa609ac":"code","e8d4d75f":"code","350a4f82":"code","c24a2e85":"code","587f54dc":"code","66d17741":"code","63c3907e":"code","ba632019":"code","328ce59c":"markdown","485e5239":"markdown","63df168d":"markdown","816523cd":"markdown","434fdfb7":"markdown","2dc1b80b":"markdown","ecc91efd":"markdown","8b7b50b4":"markdown","fa247f96":"markdown"},"source":{"db4bd79a":"\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport torchvision\nimport time\nfrom torchvision import transforms,models,datasets\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.optim as optim\nimport torch.nn as nn\nfrom collections import OrderedDict\nfrom PIL import Image\nimport numpy as np \nimport pandas as pd \nimport os\nimport json\nprint(os.listdir(\"..\/input\"))\n\n","9c806d86":"\ntrain_transforms=transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.CenterCrop(224),\n#         transforms.RandomRotation(45),\n#         transforms.RandomResizedCrop(224),\n#         transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ])\nvalid_transforms=transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ])\ntrain_datasets = datasets.ImageFolder('..\/input\/flower_data\/flower_data\/train',transform=train_transforms)\nvalid_datasets = datasets.ImageFolder('..\/input\/flower_data\/flower_data\/valid',transform=valid_transforms)\ntest_datasets = datasets.ImageFolder('..\/input\/test set\/',transform=valid_transforms)\n\ntrainloader=torch.utils.data.DataLoader(train_datasets, batch_size=512, shuffle=True)\nvalidloader=torch.utils.data.DataLoader(valid_datasets, batch_size=512, shuffle=True)\ntestloader=torch.utils.data.DataLoader(test_datasets, batch_size=512)\nprint(\"training examples : \",len(trainloader.dataset))\nprint(\"validation examples : \",len(validloader.dataset))\nprint(\"test examples : \",len(testloader.dataset))\n\nprint(\"training batches: \",len(trainloader))\nprint(\"validation batches : \",len(validloader))\nprint(\"test batches : \",len(testloader))\n\n","55cad99b":"def imshow(image, ax=None, title=None, normalize=True):\n  \"\"\"Imshow for Tensor.\"\"\"\n  if ax is None:\n      fig, ax = plt.subplots()\n  image = image.numpy().transpose((1, 2, 0))\n\n  if normalize:\n      mean = np.array([0.485, 0.456, 0.406])\n      std = np.array([0.229, 0.224, 0.225])\n      image = std * image + mean\n      image = np.clip(image, 0, 1)\n\n  ax.imshow(image)\n  ax.spines['top'].set_visible(False)\n  ax.spines['right'].set_visible(False)\n  ax.spines['left'].set_visible(False)\n  ax.spines['bottom'].set_visible(False)\n  ax.tick_params(axis='both', length=0)\n  ax.set_xticklabels('')\n  ax.set_yticklabels('')\n\n  return ax\ndata_iter = iter(trainloader)\nimages, labels = next(data_iter)\nimshow(images[0])\nprint(labels[0])\nprint(images[0].shape)","036c5eb3":"model = models.densenet121(pretrained=True) # we will use a pretrained model and we are going to change only the last layer\nfor param in model.parameters():\n  param.requires_grad= False\n","dfa609ac":"classifier  = nn.Sequential(nn.Linear(1024, 102),\n                      nn.LogSoftmax(dim=1))\nmodel.classifier=classifier\n","e8d4d75f":"if torch.cuda.is_available():\n  model.to('cuda')\n  device='cuda'\nelse:\n  model.to('cpu')\n  device='cpu'\nprint(device)\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.003,weight_decay=0.0001)\nvalid_loss_min = 99 #just a big number I could do np.Inf\nsave_file='mymodel.pth'\n","350a4f82":"epochs = 30\ntrain_loss_array = []\ntest_loss_array  = []\nrunning_loss = 0\nfor epoch in range(epochs):\n    time0=time.time()\n    for inputs, labels in trainloader:\n        # Move input and label tensors to the default device\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        logps = model.forward(inputs)\n        loss = criterion(logps, labels)\n\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        \n    else:\n        valid_loss = 0\n        accuracy = 0\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in validloader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                logps = model.forward(inputs)\n                batch_loss = criterion(logps, labels)\n                valid_loss += batch_loss.item()\n\n                    # Calculate accuracy\n                ps = torch.exp(logps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n            total_loss=valid_loss\/len(validloader)        \n            print(f\"Epoch {epoch+1}\/{epochs}.. \"\n            f\"Train loss: {running_loss\/(len(trainloader)*2):.3f}.. \"\n            f\"valid loss: {valid_loss\/len(validloader):.3f}.. \"\n            f\"valid accuracy: {accuracy\/len(validloader):.3f}\")\n            time_total=time.time() - time0\n            print(\"time for this epoch: \",end=\"\")\n            print(time_total)\n            train_loss_array.append(running_loss\/(len(trainloader)*2))\n            test_loss_array.append(valid_loss\/len(validloader))\n            if (total_loss) <= valid_loss_min:\n                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,total_loss))\n                torch.save(model.state_dict(), save_file)\n                valid_loss_min = total_loss\n            running_loss = 0\n        model.train()\nprint(time)","c24a2e85":"plt.plot(train_loss_array)\nplt.plot(test_loss_array)\nplt.show()","587f54dc":"device = \"cpu\"\nmodel.to(device)\nmodel.eval()\nwith torch.no_grad():\n    for inputs, labels in validloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        logps = model.forward(inputs)\n        ps = torch.exp(logps)\n        top_p, top_class = ps.topk(1, dim=1)\nprint(logps)\n","66d17741":"with open('..\/input\/cat_to_name.json', 'r') as f:\n    cat_to_name = json.load(f)","63c3907e":"top_class = top_class.numpy().reshape(-1)\npredicted_results = pd.DataFrame(columns=['output'])\nprint(top_class.shape[0])\ni = 0\nfor e in top_class:\n    predicted_results.loc[i] = cat_to_name[str(e+1)]\n    i += 1\n\n","ba632019":"predicted_results.head()","328ce59c":"one layer to avoid overfitting","485e5239":"the predicted results for each image in the test set folder","63df168d":"Hello, to my first pytorch and deeplearning real application,as part of the AI hackathon I am going to classify flowers based on their images to 102 class.","816523cd":"I used tranfer learning with resnet18 model since it pretty accurate and fast to train ","434fdfb7":"just displaying the images","2dc1b80b":"I actually trained my model up to 15 epochs but for some reasons after completing  the training I re-excute the problem ( I'am actually writing this 1 m before the end of the hackathon xd)","ecc91efd":"I will choose a pretrained model to apply transfer learning (I don't want to the biggest one because I want to have faster training but this will cost us in the preformance) ","8b7b50b4":"Now let's apply the algorithm on the test set","fa247f96":"compare the two loss graphs"}}