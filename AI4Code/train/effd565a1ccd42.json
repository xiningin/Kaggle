{"cell_type":{"a2c848bb":"code","76f92cf5":"code","e8b5f31b":"code","d4928226":"code","b744b70a":"code","c784a7da":"code","54b22e2f":"code","cbe567a7":"code","1bc828cc":"code","dc5c7527":"code","81e6f7fd":"code","ede3c1f8":"code","558cb80e":"code","2f8b961f":"code","fbcea006":"code","e8715d59":"code","6054d994":"code","09c70d0b":"code","de4e9c5a":"code","1e6cc5ae":"code","cbecb68c":"code","aac1adf9":"code","5fad765e":"code","d3bf6b9f":"code","d674c0bb":"code","e20a936a":"code","0dc6c3da":"code","d1339d4f":"code","4c2da65c":"code","139d954f":"code","a6f420fc":"code","8a9d87f4":"code","59d2b98a":"code","94780b1f":"code","0904a5b2":"code","1ec20afc":"code","b17b37b6":"code","337db992":"code","c455d57c":"code","343d8414":"code","91b5eaa6":"code","6725d05c":"code","c0d70fa4":"code","35b7ccb1":"code","914afa0e":"code","10ff9c07":"code","ee563843":"code","414f709d":"markdown","f28f4874":"markdown","2dd87e88":"markdown","fb7ee2e8":"markdown","d1e58958":"markdown","c87408c3":"markdown","4c5738a0":"markdown","b3a626f4":"markdown","da534a86":"markdown","2b9cc274":"markdown","6e8a59ca":"markdown","67cd89cd":"markdown","203ae8ed":"markdown"},"source":{"a2c848bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","76f92cf5":"# data analysis\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier","e8b5f31b":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\ncombine = [train_df, test_df]","d4928226":"train_df.columns","b744b70a":"test_df.columns","c784a7da":"train_df.head(5)","54b22e2f":"test_df.head(5)","cbe567a7":"train_df.info()","1bc828cc":"test_df.info()","dc5c7527":"train_df.describe().T","81e6f7fd":"test_df.describe().T","ede3c1f8":"train_df.shape","558cb80e":"test_df.shape","2f8b961f":"train_df.isna().sum()","fbcea006":"test_df.isna().sum()","e8715d59":"train_df.head(2)","6054d994":"plt.figure(figsize=(15,5))\nsns.barplot(x=\"Parch\", y=\"Survived\", hue=\"Sex\", data=train_df)\nplt.show()","09c70d0b":"plt.figure(figsize=(15,5))\nsns.barplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=train_df)\nplt.show()","de4e9c5a":"plt.figure(figsize=(15,5))\nsns.barplot(x=\"SibSp\", y=\"Survived\", hue=\"Sex\", data=train_df)\nplt.show()","1e6cc5ae":"train_df[\"SibSp\"].value_counts()","cbecb68c":"f,ax = plt.subplots(3,4,figsize=(20,16))\nsns.countplot('Pclass',data=train_df,ax=ax[0,0])\nsns.countplot('Sex',data=train_df,ax=ax[0,1])\nsns.boxplot(x='Pclass',y='Age',data=train_df,ax=ax[0,2])\nsns.countplot('SibSp',hue='Survived',data=train_df,ax=ax[0,3],palette='husl')\nsns.distplot(train_df['Fare'].dropna(),ax=ax[2,0],kde=False,color='b')\nsns.countplot('Embarked',data=train_df,ax=ax[2,2])\n\nsns.countplot('Pclass',hue='Survived',data=train_df,ax=ax[1,0],palette='husl')\nsns.countplot('Sex',hue='Survived',data=train_df,ax=ax[1,1],palette='husl')\nsns.distplot(train_df[train_df['Survived']==0]['Age'].dropna(),ax=ax[1,2],kde=False,color='r',bins=5)\nsns.distplot(train_df[train_df['Survived']==1]['Age'].dropna(),ax=ax[1,2],kde=False,color='g',bins=5)\nsns.countplot('Parch',hue='Survived',data=train_df,ax=ax[1,3],palette='husl')\nsns.swarmplot(x='Pclass',y='Fare',hue='Survived',data=train_df,palette='husl',ax=ax[2,1])\nsns.countplot('Embarked',hue='Survived',data=train_df,ax=ax[2,3],palette='husl')\n\nax[0,0].set_title('Total Passengers by Class')\nax[0,1].set_title('Total Passengers by Gender')\nax[0,2].set_title('Age Box Plot By Class')\nax[0,3].set_title('Survival Rate by SibSp')\nax[1,0].set_title('Survival Rate by Class')\nax[1,1].set_title('Survival Rate by Gender')\nax[1,2].set_title('Survival Rate by Age')\nax[1,3].set_title('Survival Rate by Parch')\nax[2,0].set_title('Fare Distribution')\nax[2,1].set_title('Survival Rate by Fare and Pclass')\nax[2,2].set_title('Total Passengers by Embarked')\nax[2,3].set_title('Survival Rate by Embarked')","aac1adf9":"train_df","5fad765e":"train_df = train_df.drop(['PassengerId'], axis=1)","d3bf6b9f":"# we can now drop the cabin feature\ntrain_df = train_df.drop(['Cabin'], axis=1)\ntest_df = test_df.drop(['Cabin'], axis=1)","d674c0bb":"train_df[\"Age\"].isna().sum()","e20a936a":"train_df.Age = train_df.Age.fillna(train_df.Age.mean())\ntrain_df","0dc6c3da":"train_df['Embarked'].describe()","d1339d4f":"common_value = 'S'\ndata = [train_df, test_df]\n\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)","4c2da65c":"train_df.info()","139d954f":"data = [train_df, test_df]\nfor dataset in data:\n    dataset['Fare'] = dataset['Fare'].fillna(0)\n    dataset['Fare'] = dataset[\"Fare\"].astype(int)","a6f420fc":"train_df = train_df.drop(['Name'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)","8a9d87f4":"genders = {\"male\":0, \"female\":1}\ndata = [train_df, test_df]\nfor dataset in data:\n    dataset['Sex'] = dataset['Sex'].map(genders)","59d2b98a":"train_df.head(2)","94780b1f":"train_df['Ticket'].describe()","0904a5b2":"train_df = train_df.drop(['Ticket'], axis=1)\ntest_df = test_df.drop(['Ticket'], axis=1)","1ec20afc":"train_df[\"Embarked\"].value_counts()","b17b37b6":"port = {\"S\":0, \"C\":1, \"Q\":2}\ndata = [train_df, test_df]\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].map(port)","337db992":"test_df.fillna(test_df.mean(), inplace=True)","c455d57c":"test_df.isna().sum()","343d8414":"data = [train_df, test_df]\nfor dataset in data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6","91b5eaa6":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()","6725d05c":"# Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nprint(round(acc_log,2,), \"%\")","c0d70fa4":"# Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nY_prediction = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nprint(round(acc_random_forest,2,), \"%\")","35b7ccb1":"# Gaussian Naive Bayes\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\n\nY_pred = gaussian.predict(X_test)\n\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nprint(round(acc_gaussian,2,), \"%\")","914afa0e":"# Decision Tree\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\n\nY_pred = decision_tree.predict(X_test)\n\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nprint(round(acc_decision_tree,2,), \"%\")","10ff9c07":"results = pd.DataFrame({\n    'Model': ['Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Decision Tree'],\n    'Score': [acc_log, acc_random_forest, acc_gaussian,\n              acc_decision_tree]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(9)","ee563843":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_prediction\n    })\nsubmission.to_csv('submission.csv', index=False)","414f709d":"pclass: A proxy for socio-economic status (SES)\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","f28f4874":"\n**Some Predictions:**\n\n    Sex: Females are more likely to survive.\n    SibSp\/Parch: People traveling alone are more likely to survive.\n    Age: Young children are more likely to survive.\n    Pclass: People of higher socioeconomic class are more likely to survive.\n\n","2dd87e88":"**Observations**:\n\n*     There are a total of 891 passengers in our training set.\n*     The Age feature is missing approximately 19.87 % of its values. I guess that the Age feature is pretty important to survival, so we should probably attempt to fill these gaps.\n*     The Cabin feature is missing approximately 77.1% of its values. Since so much of the feature is missing, it would be hard to fill in the missing values. We'll probably drop these values from our dataset.\n*     The Embarked feature is missing 0.22% of its values, which should be relatively harmless.","fb7ee2e8":"\n**Acquire data**\n\nThe Python Pandas packages helps us work with our datasets. We start by acquiring the training and testing datasets into Pandas DataFrames. We also combine these datasets to run certain operations on both datasets together.\n","d1e58958":"**Problem Statement:** Knowing from a training set of samples listing passengers who survived or did not survive the Titanic disaster. Can our model determine based on a given test dataset not containing the survival information, if these passengers in the test dataset survived or not.","c87408c3":"**Above you can see that 'Fare' is a float and we have to deal with 4 categorical features: Name, Sex, Ticket and Embarked. Lets investigate and transform one after another.**","4c5738a0":"**Categorical**: Survived, Sex, and Embarked\n\n**Ordinal**: Pclass\n\n**Continous**: Age, Fare\n\n**Discrete**: SibSp, Parch","b3a626f4":"**Convert \"Embarked\" feature into numeric**","da534a86":"**Analysis goal**\n\nThe Survived variable is the outcome or dependent variable. It is a binary nominal datatype of 1 for \"survived\" and 0 for \"did not survive\". All other variables are potential predictor or independent variables. The goal is to predict this dependent variable only using the available independent variables. A test dataset has been created to test our algorithm.\n","2b9cc274":"Creating Categories:\nWe will now create categories.\n\nAge: First we will convert it from float into integer.\nwe will create the new 'AgeGroup\" variable, by categorizing every age into a group.","6e8a59ca":"**MIXED data types**  - Numerical, ALPHANumeric data within same columns or Features. \n\nTicket Column is a MIX of numeric and alphanumeric data types. Cabin Column is ALPHANumeric.\n","67cd89cd":"**Data Visualization**","203ae8ed":"**Since the Ticket attribute has 681 unique tickets, it will be a bit tricky to convert them into useful categories. So we will drop it from the dataset.**"}}