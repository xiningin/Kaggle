{"cell_type":{"3d69d57a":"code","44e9776e":"code","605a7c8a":"code","06f50295":"code","dc37ee45":"code","5b33b845":"code","c14bdd5c":"code","a7e1651f":"code","07539184":"code","69d0b167":"code","5e4ba307":"code","fa9a14e9":"code","05032610":"code","471b92a0":"code","47a68e4d":"code","7a1e7732":"code","1cf31f5d":"code","3568af9f":"code","cc834ff1":"code","8c26b4aa":"code","12ce2517":"code","bf4b49b3":"code","60785669":"code","6775a4fe":"code","c597e997":"code","f654facc":"code","ab634879":"code","ffb562d3":"code","fa4870f5":"markdown","98c83ca2":"markdown","36346e96":"markdown","b0e3ad70":"markdown","103e0949":"markdown","ecfa14c5":"markdown","27c759a5":"markdown","724134a8":"markdown"},"source":{"3d69d57a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","44e9776e":"!pip install vaderSentiment","605a7c8a":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()","06f50295":"interactions = pd.read_excel('..\/input\/sale-forecasting-data\/interactions.xlsx')","dc37ee45":"#Calculating Interaction score\nscores =[]\ntext=interactions['Extracted Interaction Text']\ntext\nfor sentence in text:\n    score = analyser.polarity_scores(sentence)\n    scores.append(score)\n    \n#Converting List of Dictionaries into Dataframe\ndataFrame= pd.DataFrame(scores)\n#dataFrame.head(20)","5b33b845":"interactions= pd.concat([interactions,dataFrame.compound],axis=1)","c14bdd5c":"sales_data=pd.read_excel('..\/input\/sale-forecasting-data\/sales-pipeline.xlsx')#sales pipeline.xlsx","a7e1651f":"#merging interaction score in sales pipeline file\n#Calculating product acceptance rate for as product of a company or won to total opportunities for a company\n#\nfor em in interactions.fromEmailId.unique():\n    #interactions.loc[(interactions['fromEmailId']==em),'compound']=(interactions['compound'].where(interactions['fromEmailId']==em)).mean()\n    sales_data.loc[sales_data['SalesAgentEmailID']==em,'interaction_score']=(interactions['compound'].where(interactions['fromEmailId']==em)).mean()\nfor cm in sales_data.ContactEmailID.unique():\n    sales_data.loc[sales_data['ContactEmailID']==cm,'prod_acc_rate']=(sales_data.loc[sales_data['ContactEmailID']==cm,'Product']).where(sales_data.Deal_Stage=='Won').count()\/(sales_data.loc[sales_data['ContactEmailID']=='delila@konex.com','Product']).count()\n#sales_data['prod_acc_rate']","07539184":"i=(sales_data['Sales_Agent']=='Zane Levy').sum()#total opportunity of any rep\nj=(sales_data['Deal_Stage']=='Won').where(sales_data['Sales_Agent']=='Zane Levy').sum()#total deals closed for a rep\nk=(sales_data['Product']=='GTX Basic').where(sales_data['Deal_Stage']=='Won').sum()#total no. of deals won\nl=sales_data['DateDiff'].where(sales_data['Product']=='GTX Basic').sum()#sum of days\nm=(sales_data.loc[sales_data['ContactEmailID']=='delila@konex.com','Product']).where(sales_data.Deal_Stage=='Won').count()\nn=(sales_data.loc[sales_data['ContactEmailID']=='delila@konex.com','Product']).count()","69d0b167":"#opporunity Win rate for a sales rep\nfor agent in sales_data['Sales_Agent'].unique():\n    sales_data.loc[(sales_data['Sales_Agent']==agent),'win_rate']=((sales_data['Deal_Stage']=='Won').where(sales_data['Sales_Agent']==agent).sum()\/(sales_data['Sales_Agent']==agent).sum())\n#sales_data['win_rate']\n\n#Avg Sale cycle for a company\nfor prod in sales_data['Product'].unique():\n    sales_data.loc[(sales_data['Product']==prod),'avg_sale_cyc']=sales_data['DateDiff'].where(sales_data['Product']==prod).sum()\/((sales_data['Product']==prod).where(sales_data['Deal_Stage']=='Won').sum())\n#sales_data['avg_sale_cyc']","5e4ba307":"#Visualization\nimport seaborn as sb\nimport matplotlib.pyplot as plt","fa9a14e9":"f, ax = plt.subplots(figsize=(12, 12))\nsb.boxplot(x='Product',y='Close_Value',hue='Deal_Stage',data=sales_data,ax=ax)","05032610":"sb.barplot(y='Product',x='Close_Value',hue='Deal_Stage',data=sales_data)","471b92a0":"sb.countplot(y='Product',hue='Deal_Stage',data=sales_data)","47a68e4d":"f, ax = plt.subplots(figsize=(12, 12))\nsb.barplot(y='Account',x='prod_acc_rate',data=sales_data,ax=ax)","7a1e7732":"from sklearn.preprocessing import OneHotEncoder,LabelBinarizer\nOH_enc = OneHotEncoder(handle_unknown='ignore',sparse= False)\n#function to one hot encode columns\ndef OHE(df,col):\n    encprod=pd.DataFrame(OH_enc.fit_transform(df[col]))\n    encprod.index = df.index\n    encprod.columns=OH_enc.get_feature_names(col)\n    df=pd.concat([df,encprod],axis=1)\n    df=df.drop(col,axis=1)\n    return df","1cf31f5d":"#PREPROCESSING\n\n#if date difference is < than avg sale cycle then assign 1 else 0\nfor i in range(0,8800):\n    if(sales_data.loc[i,'DateDiff']<sales_data.loc[i,'avg_sale_cyc']):\n        sales_data.loc[i,'DateDiff']=1\n    else:\n        sales_data.loc[i,'DateDiff']=0\n\nsales_class=sales_data\nprog_df=sales_data.loc[sales_data.Deal_Stage=='In Progress',sales_data.columns]\nprog_df.reset_index(drop=True,inplace=True)\nprog_df=prog_df.drop(['Deal_Stage','Account', 'Opportunity_ID', 'Sales_Agent', 'SalesAgentEmailID',\n                'ContactEmailID','Created Date', 'Close Date','avg_sale_cyc'],axis=1)\nsales_class=sales_class.loc[sales_class.Deal_Stage!='In Progress',sales_class.columns]\nsales_class.reset_index(drop=True,inplace=True)\nsales_class=sales_class.drop(['Account', 'Opportunity_ID', 'Sales_Agent', 'SalesAgentEmailID',\n                              'ContactEmailID','Created Date', 'Close Date','avg_sale_cyc'],axis=1)\n#Label Binazrizer\nlb=LabelBinarizer()\nlb.fit_transform(sales_class['Deal_Stage'])\ndeal_class=sales_class['Deal_Stage']\nsales_class=sales_class.drop(['Deal_Stage'],axis=1)\n\ns = (sales_class.dtypes == 'object')\nobject_cols = list(s[s].index)\nprint(object_cols)\n\n#getting one on encoded columns\nsales_class=OHE(sales_class,object_cols)\nprog_df=OHE(prog_df,object_cols)","3568af9f":"correlation=sales_class.corr()\nplt.figure(figsize=(14,14))\nsb.heatmap(data=correlation,square=True,annot=True)","cc834ff1":"#Forecasting through classification\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\ntrain_X, val_X, train_y, val_y = train_test_split(sales_class, deal_class, random_state = 0)\n\n# logistic regression object \nlr = LogisticRegression() \n  \n# train the model on train set \nlr.fit(train_X, train_y) \n  \npred = lr.predict(val_X) \n  \n# print classification report \nprint(classification_report(val_y, pred))","8c26b4aa":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(lr, train_X, train_y, cv=5)\nscores\nprint(scores.mean(),scores.std())","12ce2517":"#predicting for in progress deals\npre_ipro=lr.predict(prog_df)\npre_df=sales_data.loc[sales_data.Deal_Stage=='In Progress',sales_data.columns]\npre_df.reset_index(drop=True,inplace=True)\npre=pd.Series(pre_ipro)\npre.value_counts()\npre_df=pd.concat([pre_df,pre],axis=1)\npre_df","bf4b49b3":"#printing the confusion matrix for Logistic regression\nLABELS = ['Won', 'Lost'] \nconf_matrix = confusion_matrix(val_y, pred) \nplt.figure(figsize =(12, 12)) \nsb.heatmap(conf_matrix, xticklabels = LABELS,  \n            yticklabels = LABELS, annot = True, fmt =\"d\"); \nplt.title(\"Confusion matrix\") \nplt.ylabel('True class') \nplt.xlabel('Predicted class') \nplt.show() ","60785669":"cluster_sales=pd.concat([sales_class,deal_class],axis=1)\nr = (cluster_sales.dtypes == 'object')\nobj_col = list(r[r].index)\nprint(obj_col)\n#cluster_sales=OHE(cluster_sales,obj_col)\ncluster_sales['Deal_Stage']=lb.fit_transform(cluster_sales['Deal_Stage'])\ncluster_sales\n# standardizing the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(cluster_sales)\n\n# statistics of scaled data\npd.DataFrame(data_scaled).describe()","6775a4fe":"from sklearn.cluster import KMeans\n# defining the kmeans function with initialization as k-means++\nkmeans = KMeans(n_clusters=2, init='k-means++')\n\n# fitting the k means algorithm on scaled data\nkmeans.fit(data_scaled)\nkmeans.inertia_\n#predicting\n#pred = kmeans.predict(data_scaled)\n#pred","c597e997":"# fitting multiple k-means algorithms and storing the values in an empty list\nSSE = []\nfor cluster in range(1,20):\n    kmeans = KMeans(n_jobs = -1, n_clusters = cluster, init='k-means++')\n    kmeans.fit(data_scaled)\n    SSE.append(kmeans.inertia_)\n\n# converting the results into a dataframe and plotting them\nframe = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\nplt.figure(figsize=(12,6))\nplt.plot(frame['Cluster'], frame['SSE'], marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')","f654facc":"pre_df['Deal_Stage']=pre_df[0]\npre_df.drop([0],axis=1)","ab634879":"#function to calculate the sum of close_value of WON deals in between a time period\ndef rev(start_date,end_date,df,su=0):\n    for i in range(0,df.shape[0]):\n        if((df.loc[i,'Close Date']>=start_date) & (df.loc[i,'Close Date']<=end_date)):\n            if(df.loc[i,'Deal_Stage']=='Won'):\n                su=su+df.loc[i,'Close_Value']\n    return su","ffb562d3":"from datetime import date\nstrt=date(2019,6,1)#change here\nend=date(2019,6,30)#change here\n#monthly revenue\ncur_rev=rev(strt,end,sales_data)+rev(strt,end,pre_df)\nprint(f'Estimated Revenue for Current month:{cur_rev}')","fa4870f5":"# **Unsupervised Sentiment Analysis**","98c83ca2":"# **Clustering Analysis**","36346e96":"# **We get an Accuracy of 77%**","b0e3ad70":"**PREPROCESSING**-making data model ready","103e0949":"# Forecasting revenue","ecfa14c5":"By changing the end and start date ","27c759a5":"# **Logistic Regression**","724134a8":"Cluster analysis shows around 7 clusters as most optimum division"}}