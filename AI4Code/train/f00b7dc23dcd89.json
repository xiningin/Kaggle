{"cell_type":{"5f9fded3":"code","1a972086":"code","b9fb6dae":"code","e8b4b479":"code","ba97e790":"code","9353400d":"code","7967711f":"code","2aa1feb2":"code","b0409b5a":"code","c7369834":"code","91518c81":"code","768b5c8b":"code","12755aba":"code","43329a50":"code","efcb122d":"code","03733ea8":"code","b841cd14":"code","9c38f8c4":"code","aec14fcc":"code","b5fa5634":"code","fdf2e28d":"code","da73e5e9":"code","7ec33bb7":"code","baf6e475":"code","2c55e587":"code","0da2e00a":"code","da0d7a6d":"code","56873857":"code","20014746":"code","5037a83f":"code","a9c92b23":"code","b4d30540":"code","263e0a88":"code","45b3f5e0":"code","577eae21":"code","232de9da":"code","14c81a79":"code","272f2d0b":"code","2a62ced7":"code","9dd99985":"code","00e5f012":"code","c88f1828":"code","71b54d46":"code","0504a17a":"code","93763744":"code","a5ac62c4":"code","f60acb78":"code","84ae5981":"code","0c86bbc4":"code","2037bae0":"code","2bd703e5":"code","2561643d":"code","4c2f22ea":"code","45bbdcb4":"code","d52a5775":"code","7cac1700":"code","07dbcc7d":"code","08c495a7":"code","b7a1bb9d":"code","27f24157":"code","1a31265f":"code","67956e5c":"code","30cefb4c":"code","f95cfaaa":"code","34f8527a":"code","b7c60776":"code","162fcc6e":"code","f603256f":"code","6650daa7":"code","adb5819e":"code","5737ed47":"code","1f82cbaf":"code","071bd6ce":"code","1ab293f4":"code","a7a2be17":"code","4305d15e":"code","37f397d9":"code","0c380748":"code","f4f8b075":"code","9ddd78ba":"code","41563e1a":"code","e039eba8":"code","5fe9396f":"code","5dd97ecc":"code","1b09658f":"code","97f6cf96":"code","8079b363":"code","7f7d4a72":"code","1b17520f":"code","8e3e2426":"code","18cf96e1":"code","83f570df":"code","a84d147c":"code","707329c4":"code","222553ce":"code","d1c747b6":"code","c4e1d07a":"code","86aa5e1e":"code","96f64b2d":"code","d37d49a9":"code","e904d10f":"code","18a4eb92":"code","ce3fe35c":"code","367800f7":"code","8b7514f8":"code","945050a5":"code","3fce3ae5":"code","4e8d88d2":"code","6b006d7e":"code","89d71083":"code","d58c8265":"code","69967610":"code","315b5c2e":"code","263eca84":"code","6bc9f844":"code","e092cfe7":"code","c5d72fb5":"code","275c5260":"code","dbff2788":"code","d1788824":"code","50b6e5e6":"code","ba879f99":"code","5146c020":"code","68820713":"code","5826dd88":"code","9315795b":"code","07fb64c3":"code","22a14abe":"code","59395b6b":"code","bd87de3e":"code","e2574a21":"code","b77b8de8":"code","dcbfc7a4":"code","75b811b6":"code","92e8e574":"markdown","739942e3":"markdown","94a1e460":"markdown","16bf06da":"markdown","9e27946a":"markdown","bcb689fc":"markdown","466eebe3":"markdown","f5cd2627":"markdown","4e56ccc4":"markdown","a9ffec37":"markdown","929cf427":"markdown","6fef165a":"markdown","6e9f111d":"markdown","2d9519d1":"markdown","bf265b65":"markdown"},"source":{"5f9fded3":"import pandas as pd","1a972086":"import statistics","b9fb6dae":"from datetime import datetime","e8b4b479":"df = pd.read_csv(\"..\/input\/trip.csv\")","ba97e790":"df.head()","9353400d":"#Convert to datetime so that it can be manipulated more easily\ndf.start_date = pd.to_datetime(df.start_date, format='%m\/%d\/%Y %H:%M')","7967711f":"#Extract the year, month, and day from start_date\ndf['date'] = df.start_date.dt.date","2aa1feb2":"#Each entry in the date feature is a trip. \n#By finding the total number of times a date is listed, we know how many trips were taken on that date.\ndates = {}\nfor d in df.date:\n    if d not in dates:\n        dates[d] = 1\n    else:\n        dates[d] += 1","b0409b5a":"#Create the data frame that will be used for training, with the dictionary we just created.\ndf2 = pd.DataFrame.from_dict(dates, orient = \"index\")","c7369834":"df2['date'] = df2.index","91518c81":"df2['trips'] = df2.iloc[:,0]","768b5c8b":"df2.head()","12755aba":"train = pd.DataFrame(df2.date)","43329a50":"train['trips'] = df2['trips']","efcb122d":"train.head()","03733ea8":"train.reset_index(drop = True, inplace = True)","b841cd14":"train.head()","9c38f8c4":"train = train.sort_values(by='date')","aec14fcc":"train.head()","b5fa5634":"train.tail()","fdf2e28d":"type(train.date[0])","da73e5e9":"weather = pd.read_csv(\"..\/input\/weather.csv\")","7ec33bb7":"weather.head()","baf6e475":"weather.events.unique()","2c55e587":"weather.loc[weather[\"events\"] == 'rain', 'events'] = 'Rain'","0da2e00a":"weather.events.unique()","da0d7a6d":"weather.loc[weather[\"events\"].isnull(), 'events'] = 'Normal'","56873857":"weather.events.unique()","20014746":"weather.zip_code.unique()","5037a83f":"for zipcode in (weather.zip_code.unique()):\n    print(zipcode)\n    print(weather[weather.zip_code == zipcode].isnull().sum())\n    print()","a9c92b23":"weather = weather[weather.zip_code == 94107]","b4d30540":"weather = weather.drop(['zip_code'], axis=1)","263e0a88":"weather.max_gust_speed_mph.describe()","45b3f5e0":"weather.corr()","577eae21":"w1 = weather.loc[:, ('max_wind_Speed_mph', 'max_gust_speed_mph')]","232de9da":"w1.corr()","14c81a79":"w1_null = w1[w1.max_gust_speed_mph.isnull()]","272f2d0b":"w1_null.head()","2a62ced7":"weather.loc[weather.max_gust_speed_mph.isnull(), 'max_gust_speed_mph'] = weather.max_wind_Speed_mph","9dd99985":"weather.max_gust_speed_mph.isnull().sum()","00e5f012":"weather.iloc[63]","c88f1828":"for i in weather.precipitation_inches[0:5]:\n    print(type(i))","71b54d46":"weather.precipitation_inches = pd.to_numeric(weather.precipitation_inches, errors = 'coerce')","0504a17a":"type(weather.precipitation_inches.iloc[1])","93763744":"weather.precipitation_inches.describe()","a5ac62c4":"statistics.median(weather[weather.precipitation_inches.notnull()].precipitation_inches)","f60acb78":"weather.precipitation_inches.isnull().sum()","84ae5981":"weather.loc[weather.precipitation_inches.isnull(), 'precipitation_inches'] = 0.0","0c86bbc4":"weather.precipitation_inches.isnull().sum()","2037bae0":"weather = weather.sort_values(by = 'date')","2bd703e5":"weather.reset_index(drop = True, inplace = True)","2561643d":"weather.date.head()","4c2f22ea":"train = train.merge(weather, on = train.date)","45bbdcb4":"train.head()","d52a5775":"train.drop(['key_0', 'date_y'],1, inplace= True)","7cac1700":"train = train.rename(columns={'date_x':'date'})","07dbcc7d":"train.head()","08c495a7":"stations = pd.read_csv(\"..\/input\/station.csv\")","b7a1bb9d":"stations.head()","27f24157":"stations.city.unique()","1a31265f":"stations = stations[stations.city == 'San Francisco']","67956e5c":"stations.reset_index(drop = True, inplace = True)","30cefb4c":"stations.shape","f95cfaaa":"stations.head()","34f8527a":"for i in stations.installation_date[0:5]:\n    print(i, type(i))","b7c60776":"stations.installation_date.shape","162fcc6e":"stations.installation_date = pd.to_datetime(stations.installation_date)","f603256f":"stations['installation_date'] = stations.installation_date.dt.date","6650daa7":"for str in stations.installation_date[0:5]:\n    print(type(str))","adb5819e":"print (stations.installation_date.min())\nprint (stations.installation_date.max())","5737ed47":"#For each day in train.date, find the number of docks (parking spots for individual bikes) that were installed \n#on or before that day.\ntotal_docks = []\nfor day in train.date:\n    total_docks.append(sum(stations[stations.installation_date <= day].dock_count))","1f82cbaf":"train['total_docks'] = total_docks","071bd6ce":"train.total_docks.unique()","1ab293f4":"from pandas.tseries.holiday import USFederalHolidayCalendar","a7a2be17":"#Find all of the holidays during out time span\ncalendar = USFederalHolidayCalendar()\nholidays = calendar.holidays(start=train.date.min(), end=train.date.max())","4305d15e":"holidays","37f397d9":"from pandas.tseries.offsets import CustomBusinessDay","0c380748":"#Find all of the business days in our time span\nus_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\nbusiness_days = pd.DatetimeIndex(start=train.date.min(), end=train.date.max(), freq=us_bd)","f4f8b075":"business_days","9ddd78ba":"business_days = pd.to_datetime(business_days, format = '%Y\/%m\/%d').date","41563e1a":"# if train.date is a business day or not\ntrain['business_days'] = train.date.isin(business_days)","e039eba8":"train['business_days'].head()","5fe9396f":"holidays = pd.to_datetime(holidays, format = '%Y\/%m\/%d').date","5dd97ecc":"# if train.date is a holiday or not\ntrain['holidays'] = train.date.isin(holidays)","1b09658f":"train['holidays'].head()","97f6cf96":"weekday = []\nfor i in train.date:\n    wkday = i.weekday()\n#    print(wkday)\n    if wkday in range(0,5):\n        weekday.append(1)\n#        print(1)\n    else:\n        weekday.append(0)\n#        print(0)","8079b363":"train['weekday'] = weekday","7f7d4a72":"train.head()","1b17520f":"train.business_days = [1 if i is True else 0 for i in train.business_days ]","8e3e2426":"train.holidays = [1 if i is True else 0 for i in train.holidays ]","18cf96e1":"train.head()","83f570df":"train['month'] = pd.to_datetime(train.date).dt.month","a84d147c":"train.head()","707329c4":"labels = train.trips","222553ce":"train.drop(['date', 'trips'],1, inplace = True)","d1c747b6":"train.tail()","c4e1d07a":"events = pd.get_dummies(train.events, drop_first = True)","86aa5e1e":"train = train.merge(events, left_index = True, right_index = True)","96f64b2d":"train.head()","d37d49a9":"train.drop(['events'], axis = 1, inplace=True)","e904d10f":"train.head()","18a4eb92":"from sklearn.model_selection import train_test_split","ce3fe35c":"X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state = 1)","367800f7":"import math\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict","8b7514f8":"regressor = LinearRegression()","945050a5":"predicted = cross_val_predict(regressor, X_train, y_train, cv=15)","3fce3ae5":"import matplotlib.pyplot as plt\nfig,ax = plt.subplots()\nax.scatter(y_train, predicted, edgecolors = (0,0,0))\nax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","4e8d88d2":"scoring = ['r2','neg_mean_squared_error','neg_mean_absolute_error']\nfor i in scoring:\n    scores = cross_val_score(regressor, X_train, y_train, cv=15, scoring = i)\n#    print(scores)\n    if i == 'r2':\n        print(i, ': ', scores.mean())\n    elif i == 'neg_mean_squared_error':    \n        x = -1*scores.mean()\n        y = math.sqrt(x) \n        print('RMSE: ', \"%0.2f\" % y)\n    elif i == 'neg_mean_absolute_error':\n        x = -1*scores.mean()\n        print(i, \": %0.2f (+\/- %0.2f)\" % (x, scores.std() * 2))   ","6b006d7e":"from sklearn.ensemble import RandomForestRegressor","89d71083":"rfr = RandomForestRegressor(n_estimators = 55,\n                            min_samples_leaf = 3,\n                            random_state = 2, bootstrap=False)","d58c8265":"predicted = cross_val_predict(rfr, X_train, y_train, cv=15)","69967610":"fig,ax = plt.subplots()\nax.scatter(y_train, predicted, edgecolors = (0,0,0))\nax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","315b5c2e":"scoring = ['r2','neg_mean_squared_error','neg_mean_absolute_error']\nfor i in scoring:\n    scores = cross_val_score(rfr, X_train, y_train, cv=15, scoring = i)\n#    print(scores)\n    if i == 'r2':\n        print(i, ': ', scores.mean())\n    elif i == 'neg_mean_squared_error':    \n        x = -1*scores.mean()\n        y = math.sqrt(x) \n        print('RMSE: ', \"%0.2f\" % y)\n    elif i == 'neg_mean_absolute_error':\n        x = -1*scores.mean()\n        print(i, \": %0.2f (+\/- %0.2f)\" % (x, scores.std() * 2))   ","263eca84":"rfr1 = RandomForestRegressor(n_estimators=60, criterion='mse', random_state=2)","6bc9f844":"predicted = cross_val_predict(rfr1, X_train, y_train, cv=15)","e092cfe7":"fig,ax = plt.subplots()\nax.scatter(y_train, predicted, edgecolors = (0,0,0))\nax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","c5d72fb5":"scoring = ['r2','neg_mean_squared_error','neg_mean_absolute_error']\nfor i in scoring:\n    scores = cross_val_score(rfr1, X_train, y_train, cv=15, scoring = i)\n#    print(scores)\n    if i == 'r2':\n        print(i, ': ', scores.mean())\n    elif i == 'neg_mean_squared_error':    \n        x = -1*scores.mean()\n        y = math.sqrt(x) \n        print('RMSE: ', \"%0.2f\" % y)\n    elif i == 'neg_mean_absolute_error':\n        x = -1*scores.mean()\n        print(i, \": %0.2f (+\/- %0.2f)\" % (x, scores.std() * 2))   ","275c5260":"from sklearn.neighbors import KNeighborsRegressor\nneigh = KNeighborsRegressor(n_neighbors=2)\nneigh.fit(X_train, y_train) ","dbff2788":"scoring = ['r2','neg_mean_squared_error','neg_mean_absolute_error']\nfor i in scoring:\n    scores = cross_val_score(neigh, X_train, y_train, cv=15, scoring = i)\n#    print(scores)\n    if i == 'r2':\n        print(i, ': ', scores.mean())\n    elif i == 'neg_mean_squared_error':    \n        x = -1*scores.mean()\n        y = math.sqrt(x) \n        print('RMSE: ', \"%0.2f\" % y)\n    elif i == 'neg_mean_absolute_error':\n        x = -1*scores.mean()\n        print(i, \": %0.2f (+\/- %0.2f)\" % (x, scores.std() * 2))   ","d1788824":"neigh1 = KNeighborsRegressor(n_neighbors=3)\nneigh1.fit(X_train, y_train) ","50b6e5e6":"scoring = ['r2','neg_mean_squared_error','neg_mean_absolute_error']\nfor i in scoring:\n    scores = cross_val_score(neigh1, X_train, y_train, cv=15, scoring = i)\n#    print(scores)\n    if i == 'r2':\n        print(i, ': ', scores.mean())\n    elif i == 'neg_mean_squared_error':    \n        x = -1*scores.mean()\n        y = math.sqrt(x) \n        print('RMSE: ', \"%0.2f\" % y)\n    elif i == 'neg_mean_absolute_error':\n        x = -1*scores.mean()\n        print(i, \": %0.2f (+\/- %0.2f)\" % (x, scores.std() * 2))   ","ba879f99":"from sklearn.ensemble import GradientBoostingRegressor","5146c020":"gbr = GradientBoostingRegressor(learning_rate = 0.12,\n                                n_estimators = 150,\n                                max_depth = 8,\n                                min_samples_leaf = 1,\n                                random_state = 2)","68820713":"scoring = ['r2','neg_mean_squared_error','neg_mean_absolute_error']\nfor i in scoring:\n    scores = cross_val_score(gbr, X_train, y_train, cv=15, scoring = i)\n#    print(scores)\n    if i == 'r2':\n        print(i, ': ', scores.mean())\n    elif i == 'neg_mean_squared_error':    \n        x = -1*scores.mean()\n        y = math.sqrt(x) \n        print('RMSE: ', \"%0.2f\" % y)\n    elif i == 'neg_mean_absolute_error':\n        x = -1*scores.mean()\n        print(i, \": %0.2f (+\/- %0.2f)\" % (x, scores.std() * 2))   ","5826dd88":"from sklearn.tree import DecisionTreeRegressor","9315795b":"dtr = DecisionTreeRegressor(min_samples_leaf = 3,\n                            max_depth = 8,\n                            random_state = 2)","07fb64c3":"scoring = ['r2','neg_mean_squared_error','neg_mean_absolute_error']\nfor i in scoring:\n    scores = cross_val_score(dtr, X_train, y_train, cv=15, scoring = i)\n#    print(scores)\n    if i == 'r2':\n        print(i, ': ', scores.mean())\n    elif i == 'neg_mean_squared_error':    \n        x = -1*scores.mean()\n        y = math.sqrt(x) \n        print('RMSE: ', \"%0.2f\" % y)\n    elif i == 'neg_mean_absolute_error':\n        x = -1*scores.mean()\n        print(i, \": %0.2f (+\/- %0.2f)\" % (x, scores.std() * 2))","22a14abe":"from sklearn.ensemble import AdaBoostRegressor","59395b6b":"abr = AdaBoostRegressor(n_estimators = 100,\n                        learning_rate = 0.1,\n                        loss = 'linear',\n                        random_state = 2)\n","bd87de3e":"scoring = ['r2','neg_mean_squared_error','neg_mean_absolute_error']\nfor i in scoring:\n    scores = cross_val_score(abr, X_train, y_train, cv=15, scoring = i)\n#    print(scores)\n    if i == 'r2':\n        print(i, ': ', scores.mean())\n    elif i == 'neg_mean_squared_error':    \n        x = -1*scores.mean()\n        y = math.sqrt(x) \n        print('RMSE: ', \"%0.2f\" % y)\n    elif i == 'neg_mean_absolute_error':\n        x = -1*scores.mean()\n        print(i, \": %0.2f (+\/- %0.2f)\" % (x, scores.std() * 2))     ","e2574a21":"rfr1.fit(X_train, y_train )\npredicted = rfr1.predict(X_test)","b77b8de8":"labels.describe()","dcbfc7a4":"y_test.reset_index(drop = True, inplace = True)","75b811b6":"plt.figure(figsize=(10,7))\nplt.plot(predicted)\nplt.plot(y_test)\nplt.legend(['Prediction', 'Acutal'])\nplt.ylabel(\"Number of Trips\", fontsize = 14)\nplt.xlabel(\"Predicted Date\", fontsize = 14)\nplt.title(\"Predicted Values vs Actual Values\", fontsize = 14)\nplt.show()","92e8e574":"# Random Forest","739942e3":"# High r2_score models:\nrfr1 - r2: 0.842963044947498, RMSE: 155.81, neg_mean_absolute_error : 105.08 (+\/- 28.14)              \nabr  - r2: 0.8029860904336908, RMSE: 174.65, neg_mean_absolute_error : 124.49 (+\/- 31.38)             \ngbr  - r2: 0.7993544716660546, RMSE: 176.35, neg_mean_absolute_error : 115.88 (+\/- 29.64)             \nrfr  - r2: 0.7615315265512614, RMSE: 191.96, neg_mean_absolute_error : 132.13 (+\/- 27.82)","94a1e460":"Gradient Boosting Regressor","16bf06da":"Knn Regressor not predicting well","9e27946a":"Does not provide good prediction with Linear model","bcb689fc":"Data is clean for 94107, 95113\nChoosing 94107 - San Francisco as more work carried on for this zip code and it is easier to check.","466eebe3":"Checking the zip code based data:","f5cd2627":"Knn Regressor:","4e56ccc4":"Train the model","a9ffec37":"to fill nulls for max_gust speed","929cf427":"Dock installations have been happening during this period.","6fef165a":"max_wind_Speed_mph and max_gust_speed_mph are correlated","6e9f111d":"Merging weather to train","2d9519d1":"The best model is rfr1.\nPredicting the number of trips with this model.","bf265b65":"Holidays"}}