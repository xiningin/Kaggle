{"cell_type":{"2cb6d4fc":"code","0cdaa14b":"code","2ad98655":"code","20c1ebf4":"code","4653483d":"code","ab6614ab":"code","34cab80f":"code","98743a88":"code","9638d132":"markdown"},"source":{"2cb6d4fc":"!git clone https:\/\/github.com\/Visual-Computing\/GPR1200.git","0cdaa14b":"!pip install timm\n%ls","2ad98655":"import numpy as np\n\ndef get_sorted_distances(features_DB, features_Q=None, k=None):\n\n    \"\"\"\n    Computes the cosine similarity of up to two sets of embeddings and returns\n    similarities and distances of k nearest neighbours\n    \n    Parameters\n    ----------\n    features_DB : array-like, shape = [n_samples, dimensionality]\n        Database feature vectors\n    features_Q : array-like, shape = [n_samples, dimensionality]\n        Query feature vectors. If this parameter is not given, the database fv\u00b4s are used as querries\n    k : int\n        k nearest neighbours\n    \"\"\"\n\n    sorted_distances, indices = [], []\n\n    if type(features_Q) == type(None):\n        features_Q = features_DB\n\n    if k is None:\n        k = len(features_DB)\n\n    f_db_t = features_DB.T\n    for f in features_Q:\n      \n        sims = f.dot(f_db_t)\n\n        sorted_indx = np.argsort(sims)[::-1]\n\n        indices.append(sorted_indx[:k])\n        sorted_distances.append(sims[sorted_indx[:k]])\n\n    sorted_distances, indices = np.array(sorted_distances), np.array(indices)\n    \n    \n    return sorted_distances, indices\n\n\ndef get_average_precision_score(y_true, k=None):\n    \"\"\"\n    Average precision at rank k\n    Modified to only work with sorted ground truth labels\n    From: https:\/\/gist.github.com\/mblondel\/7337391\n    \n    Parameters\n    ----------\n    y_true : array-like, shape = [n_samples]\n        Binary ground truth (True if relevant, False if irrelevant), sorted by the distances. \n    k : int\n        Rank.\n    Returns\n    -------\n    average precision @k : float\n    \"\"\"\n    if k is None:\n        k = np.inf\n    \n    n_positive = np.sum(y_true.astype(np.int) == 1)\n    \n    if n_positive == 0:\n        # early return in cases where no positives are among the ranks\n        return 0\n    \n    y_true = y_true[:min(y_true.shape[0], k)].astype(np.int)\n    \n    score = 0\n    n_positive_seen = 0\n    pos_indices = np.where(y_true == 1)[0]\n    \n    for i in pos_indices:\n        n_positive_seen += 1\n        score += n_positive_seen \/ (i + 1.0)\n    \n    return score \/ n_positive\n\n\ndef compute_mean_average_precision(categories_DB, \n                                    features_DB=None, \n                                    features_Q=None, \n                                    categories_Q=None, \n                                    indices=None, \n                                    k=None):\n    \"\"\"\n    Performs a search for k neirest neighboors with the specified indexing method and computes the mean average precision@k \n    \n    Parameters\n    ----------\n    features_DB : array-like, shape = [n_samples, dimensionality]\n        Database feature vectors\n    features_Q : array-like, shape = [n_samples, dimensionality]\n        Query feature vectors. If this parameter is not given, the database fv\u00b4s are used as querries\n    categories_DB : array-like, shape = [n_samples_DB]\n        Database categories\n    categories_Q : array-like, shape = [n_samples_Q]\n        Query categories. If this parameter is not given, the database categories are used\n    indices: array-lile, shape = [n_samples_Q, n_samples_DB]\n        Nearest neighbours indices \n    k : int\n        Mean average precision at @k value. If np.inf, this function computes the mean average precision score\n    Returns\n    -------\n    Mean average precision @k : float\n    \"\"\"\n\n    if (indices is None) & (features_DB is None):\n        raise ValueError(\"Either indices or features_DB has to be provided \")\n    \n    if features_Q is None: features_Q = features_DB\n    if categories_Q is None: categories_Q = categories_DB\n    \n    if (indices is None):\n        _, indices = get_sorted_distances(features_DB, features_Q, k=k)\n    \n    aps = []\n    for i in range(0, len(indices)):\n        aps.append(get_average_precision_score((categories_DB[indices[i]] == categories_Q[i]), k))\n    \n    return aps","20c1ebf4":"import numpy as np\nimport os\n\n\nclass GPR1200:\n\n    \"\"\"GPR1200 class\n    \n    The dataset contains 12k images from 1200 diverse categories. \n    \"\"\"\n    \n    _base_dir = None\n    \n    _image_data = None\n    _ground_truth = None\n    \n    _iterator_index = 0\n    \n    def __init__(self, base_dir):\n        \"\"\"\n        Load the image information from the drive\n        \n        Parameters\n        ----------\n        base_dir : string \n            GPR1200 base directory path\n        \"\"\"\n        self._base_dir = base_dir\n        \n        gpr10x1200_cats, gpr10x1200_files = [], []\n\n        data = sorted(os.listdir(base_dir), key=lambda a: int(os.path.basename(a).split(\"_\")[0]))\n        for file in data:\n            file_path = os.path.join(base_dir, file)\n            cat = os.path.basename(file).split(\"_\")[0]\n            gpr10x1200_cats.append(cat)\n            gpr10x1200_files.append(file_path)\n\n        gpr10x1200_cats, gpr10x1200_files = np.array(gpr10x1200_cats), np.array(gpr10x1200_files)\n        \n        #sorted_indx = np.argsort(ur10x1000_files)\n        self._image_files = gpr10x1200_files#[sorted_indx]\n        self._image_categories = gpr10x1200_cats#[sorted_indx]\n\n    @staticmethod\n    def __name__():\n        \"\"\"\n        Name of the  dataset\n        \"\"\"\n        return \"GPR1200\"\n        \n    def __str__(self): \n        \"\"\"\n        Readable string representation\n        \"\"\"\n        return \"\" + self.__name__() + \"(\" + str(self.__len__()) + \") in \" + self.base_dir\n    \n    def __len__(self): \n        \"\"\"\n        Amount of elements\n        \"\"\"\n        return len(self._image_data)\n\n    @property\n    def base_dir(self):\n        \"\"\"\n        Path to the base directory\n        \n        Returns\n        -------\n        path : str\n            Path to the base directory\n        \"\"\"\n        return self._base_dir\n\n    @property\n    def image_dir(self):\n        \"\"\"\n        Path to the image directory\n        \n        Returns\n        -------\n        path : str\n            Path to the image directory\n        \"\"\"\n        return self._base_dir + \"images\/\"\n\n    @property\n    def image_files(self): \n        \"\"\"\n        List of image files. The order of the list is important for other methods.\n        \n        Returns\n        -------\n        file_list : list(str)\n            List of file names\n        \"\"\"\n        return self._image_files\n\n\n    def evaluate(self, features=None, indices=None, compute_partial=False, float_n=4):\n        \"\"\"\n        Compute the mean average precision of each part of this combined data set. \n        Providing just the 'features' will assume the manhatten distance between all images will be computed \n        before calculating the mean average precision. This metric can \n        be changed with any scikit learn 'distance_metric'. \n      \n         \n        Parameters\n        ----------\n        features : ndarray \n            matrix representing the embeddings of all the images in the dataset\n        indices: array-lile, shape = [n_samples_Q, n_samples_DB]\n            Nearest neighbours indices \n        \"\"\"\n        \n        cats = self._image_categories\n\n        if (indices is None) & (features is None):\n            raise ValueError(\"Either indices or features_DB has to be provided \")\n\n        if indices is None:\n            aps = compute_mean_average_precision(cats, features_DB=features)\n        if features is None:\n            aps = compute_mean_average_precision(cats, indices=indices)\n\n        all_map = np.round(np.mean(aps), decimals=float_n)\n\n        if compute_partial: \n\n            cl_map = np.round(np.mean(aps[:2000]), decimals=float_n)\n            iNat_map = np.round(np.mean(aps[2000:4000]), decimals=float_n)\n            sketch_map = np.round(np.mean(aps[4000:6000]), decimals=float_n)\n            instre_map = np.round(np.mean(aps[6000:8000]), decimals=float_n)\n            sop_map = np.round(np.mean(aps[8000:10000]), decimals=float_n)\n            faces_map = np.round(np.mean(aps[10000:]), decimals=float_n)\n            \n            return all_map, cl_map, iNat_map, sketch_map, instre_map, sop_map, faces_map\n\n        return all_map","4653483d":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms as pth_transforms\n\nimport numpy as np\nfrom PIL import Image\n\nfrom tqdm import *\n\nimport time\nimport timm\n\nfrom timm.data import resolve_data_config\nfrom timm.data.transforms_factory import create_transform\n\n# from GPR1200 import GPR1200","ab6614ab":"model_list = [\n             \"resnetv2_101x1_bitm\",\n             \"resnetv2_101x1_bitm_in21k\",\n             \"resnetv2_101x3_bitm\",\n             \"resnetv2_101x3_bitm_in21k\",\n             \"tf_efficientnetv2_l\",\n             \"tf_efficientnetv2_l_in21ft1k\",\n             \"tf_efficientnetv2_l_in21k\",\n             \"vit_base_patch16_224\",\n             \"vit_base_patch16_224_in21k\",\n             \"vit_large_patch16_224\",\n             \"vit_large_patch16_224_in21k\",\n             \"deit_base_patch16_224\",\n             \"deit_base_distilled_patch16_224\",\n             \"swin_base_patch4_window7_224\",\n             \"swin_base_patch4_window7_224_in22k\",\n             \"swin_large_patch4_window7_224\",\n             \"swin_large_patch4_window7_224_in22k\"\n            ]","34cab80f":"class TestDataset(torch.utils.data.Dataset):\n  'Characterizes a dataset for PyTorch'\n  def __init__(self, file_paths):\n        'Initialization'\n        self.file_paths = file_paths\n        \n  def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.file_paths)\n\n  def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        return ppc_image(self.file_paths[index])\nGPR1200_dataset = GPR1200(\"..\/input\/gpr1200-dataset\/images\")\nimage_filepaths = GPR1200_dataset.image_files","98743a88":"# CUDA for PyTorch\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n\n\nfor m_name in model_list:\n    \n    # create models and their respective preprocessing chain\n    bb_model = timm.create_model(m_name, pretrained=True)\n    data_config = resolve_data_config({}, model=bb_model)\n    transform = create_transform(**data_config)\n    \n    bb_model.to(device)\n    bb_model.eval()\n    \n    \n    # Preprocessing that will be run on each individuall test image\n    def ppc_image(path):\n    \n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            img = img.convert('RGB')\n\n        img = transform(img)\n\n        return img\n    \n    # dataloader parameters\n    batch_size = 32\n    params = {'batch_size': batch_size,\n          'shuffle': False,\n          'num_workers': 6}\n\n    gpr1200_loader = torch.utils.data.DataLoader(TestDataset(image_filepaths), **params)\n    \n    \n    # some addtional info\n    time_start = time.time()\n    fv_list = []\n    \n    pbar = tqdm(enumerate(gpr1200_loader), position=0, leave=True, total=(int(len(image_filepaths) \/ batch_size)))\n    \n    with torch.set_grad_enabled(False):\n        for i, local_batch in pbar:\n\n            local_batch = local_batch.to(device)\n            fv = bb_model.forward_features(local_batch)\n            \n            if type(fv) == type((1,2)):\n                fv = fv[1]\n            if len(fv.size()) > 2:\n                fv = fv.mean(dim=[2,3])\n                \n            fv = fv \/ torch.norm(fv, dim=-1, keepdim=True)\n           \n            fv_list += list(fv.cpu().numpy())\n            pbar.update()\n    \n        print(fv.shape)\n    \n    # display some addtional info\n    fv_list = np.array(fv_list).astype(float)\n    print(\"---------name: {} -- dim: {}---------\".format(m_name, fv_list.shape))\n    time_needed = np.round((time.time() - time_start) \/ len(image_filepaths) * 1000, 2)\n    dim = fv_list.shape[-1]\n    input_size = data_config[\"input_size\"]\n    \n    \n    # run this line to evaluate dataset embeddings\n    gpr, lm, iNat, ims, instre, sop, faces = GPR1200_dataset.evaluate(fv_list, compute_partial=True)\n    print(\"GPR1200 mAP: {}\".format(gpr))\n    print(\"Landmarks: {}, IMSketch: {}, iNat: {}, Instre: {}, SOP: {}, faces: {}\".format(lm, ims, iNat, instre, sop, faces))\n    print()\n    \n    del bb_model","9638d132":"![Benchmark](https:\/\/github.com\/Visual-Computing\/GPR1200\/raw\/main\/images\/result_table.JPG)"}}