{"cell_type":{"0be72661":"code","7a3e34ae":"code","717d9325":"code","d273cb6b":"code","5b5a2669":"code","f3d81aa5":"code","c45565b0":"code","d3ff9df3":"code","122767b8":"code","f9b17b60":"code","4d6b6753":"markdown","c73ded7b":"markdown","7833d43c":"markdown","d477f261":"markdown","fac6dd75":"markdown","96d0c924":"markdown"},"source":{"0be72661":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score,f1_score\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.ensemble import RandomForestClassifier as RF\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.ensemble import AdaBoostClassifier as ABC\n%matplotlib inline","7a3e34ae":"data = pd.read_csv(\"..\/input\/mushrooms.csv\")\ndata.head(10)","717d9325":"labelEncoder = preprocessing.LabelEncoder()\nfor col in data.columns:\n    data[col] = labelEncoder.fit_transform(data[col])\n\n# Splitting test train set, with 20% of the data as the validation set\ntrain, test = train_test_split(data, test_size = 0.2) ","d273cb6b":"# Train set\ntrain_y = train['class']\ntrain_x = train[[x for x in train.columns if 'class' not in x]]\n# Test\/Validation set\ntest_y = test['class']\ntest_x = test[[x for x in test.columns if 'class' not in x]]\n\nmodels = [SVC(kernel='rbf', random_state=0), LR(), RF(),LDA(),ABC()]\nmodel_names = ['SVC_rbf', 'Logistic Regression', 'RandomForestClassifier', 'LinearDiscriminantAnalysis','AdaBoostClassifier']\nfor i, model in enumerate(models):\n    model.fit(train_x, train_y)\n    print ('The accurancy of ' + model_names[i] + ' is ' + str(accuracy_score(test_y, model.predict(test_x))) )\n    print ('The F1_score of ' + model_names[i] + ' is ' + str(f1_score(test_y, model.predict(test_x))) )","5b5a2669":"train, test = train_test_split(data, test_size = 0.99) #change test_size= 0.99, 0.95, 0.9 to see the result#","f3d81aa5":"# Train set\ntrain_y = train['class']\ntrain_x = train[[x for x in train.columns if 'class' not in x]]\n# Test\/Validation set\ntest_y = test['class']\ntest_x = test[[x for x in test.columns if 'class' not in x]]\n\nmodels = [SVC(kernel='rbf', random_state=0), LR(), RF(),LDA(),ABC()]\nmodel_names = ['SVC_rbf', 'Logistic Regression', 'RandomForestClassifier', 'LinearDiscriminantAnalysis','AdaBoostClassifier']\nfor i, model in enumerate(models):\n    model.fit(train_x, train_y)\n    print ('The accurancy of ' + model_names[i] + ' is ' + str(accuracy_score(test_y, model.predict(test_x))) )\n    print ('The F1_score of ' + model_names[i] + ' is ' + str(f1_score(test_y, model.predict(test_x))) )","c45565b0":"train, test = train_test_split(data, test_size = 0.2) ","d3ff9df3":"# Train set\ntrain_y = train['class']\ntrain_x = train[[x for x in train.columns if 'class' not in x]]\n# Test\/Validation set\ntest_y = test['class']\ntest_x = test[[x for x in test.columns if 'class' not in x]]\nSVCm=SVC()\nLRm=LR(C=1.0)#\"Please try between 0 and 1\"\nRFm=RF(n_estimators=100)#\"Please try between 1 and 100\"\nLDAm=LDA(solver='lsqr')#\"Please try \u2018svd\u2019,\u2018lsqr\u2019, or \u2018eigen\u2019:\"\nABCm=ABC(n_estimators=1000)#\"Please try between 1 and 1000\"\nmodels = [SVCm, LRm, RFm,LDAm,ABCm]\nmodel_names = ['SVC_rbf', 'Logistic Regression', 'RandomForestClassifier', 'LinearDiscriminantAnalysis','AdaBoostClassifier']\nresultdict=dict(modelname=[],accuracy=[],f1=[])\nfor i, model in enumerate(models):\n    model.fit(train_x, train_y)\n    resultdict['modelname'].append(model_names[i])\n    resultdict['accuracy'].append(accuracy_score(test_y, model.predict(test_x)))\n    resultdict['f1'].append(f1_score(test_y, model.predict(test_x)))","122767b8":"resultdict1=pd.DataFrame.from_dict(resultdict)","f9b17b60":"plot=resultdict1.plot.bar(x='modelname',rot=15, subplots=True)\nplot","4d6b6753":"**Hello, everyone: please change change (data, test_size = 0.99) to (data, test_size = 0.95), (data, test_size = 0.9), (data, test_size = 0.5) to see the result**","c73ded7b":"**Test 1: Changing the ratio between train and test set **\n","7833d43c":"**QUESTION: which algorithm (SVC_rbf,Logistic Regression,RandomForestClassifier,LinearDiscriminantAnalysis,AdaBoostClassifier) is more robust (use fewer train size can achieve the highest value of accuracy and f1) and which is not ? **\n","d477f261":"Question 2: When you change those parameters, did you see some difference, if not, please guess what happen.","fac6dd75":"**Test 2: Changing the hyperparameter of each method**","96d0c924":"Hello, everyone try change LR(C=1.0) to LR(C=0.5), LR(C=0.01), try change (n_estimators=100) to (n_estimators=1), (n_estimators=10), try change LDA(solver='lsqr') to LDA(solver='svd'') or LDA(solver='eigan''), try change (n_estimators=1000) to (n_estimators=100), (n_estimators=10)\n"}}