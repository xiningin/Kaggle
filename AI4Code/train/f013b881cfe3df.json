{"cell_type":{"4ee56966":"code","8e2d22f4":"code","aff305b1":"code","0dfee344":"code","06979184":"code","71d15f89":"code","723fbec1":"code","4cfc726f":"code","65cb9ab9":"code","beae240c":"code","9fa0bf0c":"code","64d43c4d":"code","aee36674":"code","91047b3f":"code","4cb53fc9":"code","0136439b":"markdown","15049718":"markdown","b93e7cf9":"markdown","7c5edfa1":"markdown","92effc57":"markdown","b846a66d":"markdown","07b8c186":"markdown","5c7809e1":"markdown","838906eb":"markdown","2059204c":"markdown","d3571b37":"markdown"},"source":{"4ee56966":"# import the libraries\nimport numpy as np \nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport spacy\nfrom spacy import displacy","8e2d22f4":"# Dataset\ndf = pd.read_csv('..\/input\/reviews\/Restaurant_Reviews.tsv',sep = '\\t')","aff305b1":"df.head()","0dfee344":"df.shape","06979184":"# check for the missing values\ndf.isna().sum()\n","71d15f89":"review_ = []\n\nfor i in range(0,11):\n    text = df[\"Review\"][i]\n    review_.append(text)\nprint(review_)\n# check the word dependancy using spacy.displacy()\nfor data in review_:\n    nlp = spacy.load('en_core_web_sm')\n    data = nlp(data)\n    displacy.render(data,style = 'dep', options = {'font':'Areal','distance':100\n                                              ,'color': 'green','bg':'white','compact' : True,}, jupyter =True)\n    ","723fbec1":"# remove the empty string from the review column.\nempty_loc  = []\nfor i, Rv,lk in df.itertuples():\n    if type(Rv) == str:\n        if Rv.isspace() == True:\n            empty_loc.append(i)\nprint(empty_loc)","4cfc726f":"# check the number of positive and negative reviews\ndf[\"Liked\"].value_counts()\n","65cb9ab9":"x = df[\"Review\"]\ny = df[\"Liked\"]\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.4)   # 40% of the data is reserved for testing\nprint(y_test.value_counts())\nprint(y_train.value_counts())","beae240c":"#Linear Classifier\nClassifier_svc = Pipeline([('tfIdf',TfidfVectorizer()),('cl',LinearSVC()),])\nClassifier_svc.fit(x_train,y_train)\npred = Classifier_svc.predict(x_test)","9fa0bf0c":"# model evaluation\ncm = confusion_matrix(y_test,pred)\nprint(cm)\nprint('\\n')\n\nprint(\"Accuracy : \", accuracy_score(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))\n\nsns.heatmap(cm,annot =True)","64d43c4d":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.1)  # 90% of the data used for training\nprint(y_train.value_counts())\nClassifier_svc.fit(x_train,y_train)\npred = Classifier_svc.predict(x_test)","aee36674":"# model evaluation -->  Linearsvc with trainset_percentage == 100\nprint(y_test.value_counts())\n\nprint('\\n')\nprint(\"confusion matrix : \")\ncm = confusion_matrix(y_test,pred)\nprint(cm)\nprint('\\n')\n\nprint(\"Accuracy : \", accuracy_score(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))\n\nsns.heatmap(cm,annot =True)","91047b3f":"print(Classifier_svc.predict([\"I was ate just on a whim because the parking lot was full. I had the Irish Skillet and it was Delicious. Not bad prices either between my friend and I we only paid just over 20 dollars. Service here is great even on a full day.\"]))\nprint(Classifier_svc.predict([\"Stopped here for breakfast because this has been a good restaurant for meals at any time of day for many years now. You can just count on a decent meal when you stop here. I like the breakfast skillets.\"]))","4cb53fc9":"print(Classifier_svc.predict([\"We can't get a decent hamburger, they over cook them & they don't know the difference between cornbread or cake. They only have 1 soup worth eating & the waitresses on Saturdays are terrible, they are rude & don't listen while your trying to place your order\"]))\nprint(Classifier_svc.predict([\"Stopped in there one evening while traveling through Monticello. Ordered the fish and chips that the menu AND the waitress said was Cod fillets. What was brought to us was overcooked mincemeat fish sticks that had been cooked for a while and just heated in the microwave. Will NOT stop there again.\"]))","0136439b":"Model is predicting well for the positive reviews, Let's check the performance with negative reviews.","15049718":"First review is predicted correctly and there is a wrong prediction for the second review(False positive).\nThe above Reviews are from the another restaurant(not the same restaurant data we used for training the model).","b93e7cf9":"# Testing the final model with new instances.","7c5edfa1":"**This kernel has below topics : **\n1. [Displacy for Text visualization.](#Displacy-for-Text-visualization.)\n1. [LinearSVC with 40% test data.](#LinearSVC-with-40%-test-data.)\n1. [LinearSVC with 10% test data.](#LinearSVC-with-10%-test-data.)\n1. [Model Evaluation](#4)\n1. [Testing the final model with new instances.](#Testing-the-final-model-with-new-instances.)","92effc57":"**Work in progress....**\n\nplease upvote if you like my work...","b846a66d":"# LinearSVC with 10% test data.\nLets train with 90% of the available data(i.e test_size = 10%).","07b8c186":"**What is Spacy?. **\n\nSpacy is an opensource advanced python module for natural language processing, It supports multiple languages( English, German, Spanish, Portuguese, French, Italian, Dutch).\n\n**Features** : \n1. Non-destructive tokenization\n2. Named entity recognition\n3. Support for 50+ languages\n4. Pre-trained statistical models and word vectors\n5. State-of-the-art speed\n6. Easy deep learning integration\n7. Part-of-speech tagging\n8. Labelled dependency parsing\n9. Syntax-driven sentence segmentation\n10. Built in visualizers for syntax and NER\n11. Convenient string-to-hash mapping\n12. Export to numpy data arrays\n13. Efficient binary serialization\n14. Easy model packaging and deployment\n15. Robust, rigorously evaluated accuracy\n\nFor more details [Click here.](https:\/\/github.com\/explosion\/spaCy)","5c7809e1":"1 -> Liked \n\n0 -> Not liked","838906eb":"There are 8 false positives and 9 false negatives.\nAccuracy is good compare to the previous model.","2059204c":"# Displacy for Text visualization.","d3571b37":"# LinearSVC with 40% test data."}}