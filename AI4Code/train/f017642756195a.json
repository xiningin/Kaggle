{"cell_type":{"355e27f6":"code","01acd9c5":"code","416d91bc":"code","1475ca2a":"code","af6c1445":"code","9f717919":"code","bf1adfd1":"code","252bf7e5":"code","45ffa2d8":"code","aac98776":"code","b28d4a9a":"code","5a2c1a62":"code","e29a01af":"code","373c3156":"code","cc5ed77c":"code","75847a88":"code","157e2d0d":"code","24d287d9":"code","2aec54fe":"code","5ea768fd":"code","87347793":"markdown","c05a6737":"markdown"},"source":{"355e27f6":"from itertools import product\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.preprocessing import StandardScaler\n\nplt.style.use('fivethirtyeight')\n\n","01acd9c5":"\nwith open('..\/input\/beauty\/beauty.csv') as f:\n    df = pd.read_csv(f, usecols=['wage', 'exper',\n                                 'goodhlth', 'black', 'female', 'married', 'educ'])\nf.close()\ndf.head()","416d91bc":"scaler = StandardScaler()\nscaler.fit(df)\nX_scale = scaler.transform(df)\ndf_scale = pd.DataFrame(X_scale, columns=df.columns)\ndf_scale.head()\n","1475ca2a":"plt.figure(figsize=(10, 5))\nnn = NearestNeighbors(n_neighbors=14).fit(df_scale)\ndistances, idx = nn.kneighbors(df_scale)\ndistances = np.sort(distances, axis=0)\ndistances = distances[:, 1]\nplt.plot(distances)\nplt.xlabel('Distance')\nplt.ylabel('Epsilon')\nplt.show()","af6c1445":"pca_eps_values = np.arange(0.2, 5, 0.1)\npca_min_samples = np.arange(12, 17, 1)\npca_dbscan_params = list(product(pca_eps_values, pca_min_samples))\npca_no_of_clusters = []\npca_sil_score = []\npca_epsvalues = []\npca_min_samp = []\nfor p in pca_dbscan_params:\n    try:\n        pca_dbscan_cluster = DBSCAN(eps=p[0], min_samples=p[1]).fit(df_scale)\n        pca_epsvalues.append(p[0])\n        pca_min_samp.append(p[1])\n        pca_no_of_clusters.append(len(np.unique(pca_dbscan_cluster.labels_)))\n        pca_sil_score.append(silhouette_score(df_scale, pca_dbscan_cluster.labels_))\n    except ValueError:\n        print('Error for values:')\n        print('epsilon: '+str(p[0]))\n        print('minimum samples: '+str(p[1])+'\\n')","9f717919":"pca_eps_min = list(zip(pca_no_of_clusters, pca_sil_score, pca_epsvalues, pca_min_samp))\npca_eps_min_df = pd.DataFrame(pca_eps_min,\n                              columns=['no_of_clusters', 'silhouette_score', 'epsilon_values', 'minimum_points'])\nddf = pca_eps_min_df.sort_values(by=['silhouette_score'], ascending=False)\nddf.to_csv(\"beauty_score.csv\")\nddf.head(100)","bf1adfd1":"plt.figure(figsize=(10, 5))\nfor i in range(12, 17, 1):\n    data = pca_eps_min_df.loc[pca_eps_min_df['minimum_points'] == i]\n    plt.plot(data[\"epsilon_values\"].to_numpy(), data[\"silhouette_score\"].to_numpy(), label='minPts=' + str(i))\nplt.legend()\nplt.xlabel('Epsilon')\nplt.ylabel('Silhouette score')\nplt.show()\n","252bf7e5":"db = DBSCAN(eps=4, min_samples=14).fit(df_scale)\nlabels = db.labels_\n# Liczba klastr\u00f3w w etykietach, ignorowanie szumu, je\u015bli wyst\u0119puje.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\nprint('Szacowana liczba klastr\u00f3w:% d' % n_clusters_)\nprint('Szacowana liczba punkt\u00f3w szumu:% d' % n_noise_)\nprint(\"Wsp\u00f3\u0142czynnik sylwetki:% 0.3f\" % metrics.silhouette_score(df_scale, labels))\nprint(\"calinski: %0.3f\" % metrics.calinski_harabasz_score(df_scale, labels))\nprint(\"davies: %0.3f\" % metrics.davies_bouldin_score(df_scale, labels))","45ffa2d8":"with open('..\/input\/iris-data\/iris.csv') as f:\n    df = pd.read_csv(f, usecols=['sepal length (cm)', 'sepal width (cm)',\n                                 'petal length (cm)', 'petal width (cm)'])\ndf.head()\n\n","aac98776":"scaler = StandardScaler()\nscaler.fit(df)\nX_scale = scaler.transform(df)\ndf_scale = pd.DataFrame(X_scale, columns=df.columns)\ndf_scale.head()","b28d4a9a":"pca_eps_values = np.arange(0.1, 2, 0.1)\npca_min_samples = np.arange(6, 11, 1)\npca_dbscan_params = list(product(pca_eps_values, pca_min_samples))\npca_no_of_clusters = []\npca_sil_score = []\npca_epsvalues = []\npca_min_samp = []\nfor p in pca_dbscan_params:\n    try:\n        pca_dbscan_cluster = DBSCAN(eps=p[0], min_samples=p[1]).fit(df_scale)\n        pca_epsvalues.append(p[0])\n        pca_min_samp.append(p[1])\n        pca_no_of_clusters.append(len(np.unique(pca_dbscan_cluster.labels_)))\n        pca_sil_score.append(silhouette_score(df_scale, pca_dbscan_cluster.labels_))\n    except ValueError:\n        print('Error for values:')\n        print('epsilon: %.1f' % p[0])\n        print('minimum samples: '+str(p[1])+'\\n')","5a2c1a62":"\npca_eps_min = list(zip(pca_no_of_clusters, pca_sil_score, pca_epsvalues, pca_min_samp))\npca_eps_min_df = pd.DataFrame(pca_eps_min, columns=['no_of_clusters', 'silhouette_score', 'epsilon_values', 'minimum_points'])\npca_eps_min_df.sort_values(by=['silhouette_score'], ascending=False)\n","e29a01af":"plt.figure (figsize = (10,5))\nfor i in range(6,11,1):\n    data = pca_eps_min_df.loc[pca_eps_min_df['minimum_points'] == i]\n    plt.plot(data[\"epsilon_values\"].to_numpy(),data[\"silhouette_score\"].to_numpy(), label='minPts='+str(i))\nplt.legend()\nplt.xlabel('Epsilon')\nplt.ylabel('Silhouette score')\nplt.show()","373c3156":"db = DBSCAN(eps=1.4, min_samples=9).fit(df_scale)\nlabels = db.labels_\n# Liczba klastr\u00f3w w etykietach, ignorowanie szumu, je\u015bli wyst\u0119puje.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\nprint('Szacowana liczba klastr\u00f3w:% d' % n_clusters_)\nprint('Szacowana liczba punkt\u00f3w szumu:% d' % n_noise_)\nprint(\"Wsp\u00f3\u0142czynnik sylwetki:% 0.3f\" % metrics.silhouette_score(df_scale, labels))\nprint(\"calinski: %0.3f\" % metrics.calinski_harabasz_score(df_scale, labels))\nprint(\"davies: %0.3f\" % metrics.davies_bouldin_score(df_scale, labels))\n\n","cc5ed77c":"with open('..\/input\/wine-data\/winequality-white.csv') as f:\n    df = pd.read_csv(f, usecols=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol'])\ndf.head()\n","75847a88":"scaler = StandardScaler()\nscaler.fit(df)\nX_scale = scaler.transform(df)\ndf_scale = pd.DataFrame(X_scale, columns=df.columns)\ndf_scale.head()","157e2d0d":"pca_eps_values = np.arange(0.5, 10, 0.5)\npca_min_samples = np.arange(18, 27, 2)\npca_dbscan_params = list(product(pca_eps_values, pca_min_samples))\npca_no_of_clusters = []\npca_sil_score = []\npca_epsvalues = []\npca_min_samp = []\nfor p in pca_dbscan_params:\n    try:\n        pca_dbscan_cluster = DBSCAN(eps=p[0], min_samples=p[1]).fit(df_scale)\n        pca_epsvalues.append(p[0])\n        pca_min_samp.append(p[1])\n        pca_no_of_clusters.append(len(np.unique(pca_dbscan_cluster.labels_)))\n        pca_sil_score.append(silhouette_score(df_scale, pca_dbscan_cluster.labels_))\n    except ValueError:\n        print('Error for values:')\n        print('epsilon: %.1f' % p[0])\n        print('minimum samples: '+str(p[1])+'\\n')","24d287d9":"db = DBSCAN(eps=2.5, min_samples=22).fit(df_scale)\nlabels = db.labels_\n# Liczba klastr\u00f3w w etykietach, ignorowanie szumu, je\u015bli wyst\u0119puje.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\nprint('Szacowana liczba klastr\u00f3w:% d' % n_clusters_)\nprint('Szacowana liczba punkt\u00f3w szumu:% d' % n_noise_)\nprint(\"Wsp\u00f3\u0142czynnik sylwetki:% 0.3f\" % metrics.silhouette_score(df_scale, labels))\nprint(\"calinski: %0.3f\" % metrics.calinski_harabasz_score(df_scale, labels))\nprint(\"davies: %0.3f\" % metrics.davies_bouldin_score(df_scale, labels))\n","2aec54fe":"pca_eps_min = list(zip(pca_no_of_clusters, pca_sil_score, pca_epsvalues, pca_min_samp))\npca_eps_min_df = pd.DataFrame(pca_eps_min, columns=['no_of_clusters', 'silhouette_score', 'epsilon_values', 'minimum_points'])\npca_eps_min_df.sort_values(by=['silhouette_score'], ascending=False)\n","5ea768fd":"\nddf = pca_eps_min_df.sort_values(by=['silhouette_score'], ascending=False)\nddf.to_csv(\"wine_score.csv\")\nplt.figure (figsize = (10,5))\nfor i in range(18,27,2):\n    data = pca_eps_min_df.loc[pca_eps_min_df['minimum_points'] == i]\n    plt.plot(data[\"epsilon_values\"].to_numpy(), data[\"silhouette_score\"].to_numpy(), label='minPts=' + str(i))\n    plt.legend()\n    plt.xlabel('Epsilon')\n    plt.ylabel('Silhouette score')\nplt.show()\n","87347793":"# **Iris**","c05a6737":"# **Wine**"}}