{"cell_type":{"56bf5d41":"code","518c95f1":"code","167d916d":"code","c8fb6bdd":"code","d7c6ad96":"code","7f55ab92":"code","d0bc358b":"code","cd0824f5":"code","f70880e7":"code","dbc5cfc5":"code","54a1598f":"code","c7c98090":"code","f24b2ce6":"code","2238cd12":"code","bc44fcf0":"markdown","40dd192d":"markdown","ed759530":"markdown","f3be78d3":"markdown","fdaee5b3":"markdown","5ce891e6":"markdown"},"source":{"56bf5d41":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nfrom PIL import Image\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndirname = '\/kaggle\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\/'\nfor filename in os.listdir(dirname):\n    print(os.path.join(dirname, filename))\n\ntorch.manual_seed(0)\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","518c95f1":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","167d916d":"def create_image_dataset(dirname=dirname,\n                         sources=['Normal','Lung_Opacity','Viral Pneumonia','COVID'],\n                         labels=['normal','lung_opacity','viral_pneumonia','covid']):\n    '''\n    Create a master dataset of all image paths and labels\n    '''\n    image_dataset = pd.DataFrame(columns=['image', 'label'])\n    for source, label in zip(sources, labels):\n        files = os.listdir(os.path.join(dirname, source))\n\n        temp_df = pd.DataFrame({\n             'image': [os.path.join(dirname, source, item) for item in files if item.lower().endswith('.png')]\n         })\n        temp_df['label'] = label\n\n        image_dataset = pd.concat([image_dataset, temp_df], ignore_index=True)\n    return image_dataset","c8fb6bdd":"image_dataset = create_image_dataset()\ntrain_dataset_paths, test_dataset_paths = train_test_split(image_dataset, test_size=0.15, stratify=image_dataset['label'])","d7c6ad96":"class XRayDataset(torch.utils.data.Dataset):\n    def __init__(self, image_dataset, transform):\n        self.image_dataset = image_dataset\n            \n        self.class_names = self.image_dataset['label'].unique().tolist()\n        self.transform = transform\n        \n        print(self.image_dataset['label'].value_counts())\n        \n    def __len__(self):\n        return len(self.image_dataset)\n    \n    def __getitem__(self, index):\n        row = self.image_dataset.iloc[index]\n        image_path = row['image']\n        label = row['label']\n        \n        image = Image.open(image_path).convert('RGB')\n        \n        return self.transform(image), self.class_names.index(label)","7f55ab92":"train_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                    std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                    std=[0.229, 0.224, 0.225])\n])","d0bc358b":"print('Train dataset')\ntrain_dataset = XRayDataset(train_dataset_paths, transform=train_transform)\nprint('\\nTest dataset')\ntest_dataset = XRayDataset(test_dataset_paths, transform=test_transform)\n\ndl_train = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\ndl_test = torch.utils.data.DataLoader(test_dataset, batch_size=6, shuffle=True)\n\nprint('Num of training batches', len(dl_train))\nprint('Num of test batches', len(dl_test))","cd0824f5":"class_names = train_dataset.class_names\n\ndef show_images(images, labels, preds):\n    plt.figure(figsize=(8,4))\n    for i, image in enumerate(images):\n        plt.subplot(1,6, i+1, xticks=[], yticks=[])\n        image = image.numpy().transpose((1,2,0))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = image*std+mean\n        image = np.clip(image, 0., 1.)\n        plt.imshow(image)\n        \n        col = 'green' if preds[i]==labels[i] else 'red'\n        \n        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)\n    plt.tight_layout()\n    plt.show()","f70880e7":"num_class = len(train_dataset.class_names)\nresnet18 = torchvision.models.resnet18(pretrained=True)\nresnet18.fc = torch.nn.Linear(in_features=512, out_features=num_class, bias=True)\nresnet18 = resnet18.to(device)\nprint(resnet18)","dbc5cfc5":"loss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=3e-5)","54a1598f":"def show_preds():\n    resnet18.eval()\n    images, labels = next(iter(dl_test))\n    outputs = resnet18(images)\n    _, preds = torch.max(outputs, 1)\n    show_images(images.cpu(), labels.cpu(), preds.cpu())","c7c98090":"def train(epochs):\n    print('Training started...')\n    for e in range(epochs):\n        print('='*20)\n        print(f'Starting epochs {e+1}\/{epochs}')\n        print('='*20)\n        \n        train_loss = 0\n        resnet18.train()\n        for train_step, (images, labels) in enumerate(dl_train):\n            optimizer.zero_grad()\n            images = images.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.long)\n            outputs = resnet18(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss\n            \n            if train_step%20 == 0:\n                print(f'Evaluating at step {train_step}')\n                acc = 0\n                val_loss = 0\n                resnet18.eval()\n                \n                for val_step, (images, labels) in enumerate(dl_test):\n                    images = images.to(device, dtype=torch.float)\n                    labels = labels.to(device, dtype=torch.long)\n                    outputs = resnet18(images)\n                    loss = loss_fn(outputs, labels)\n                    val_loss += loss\n                    \n                    _, preds = torch.max(outputs, 1)\n                    acc += sum((labels == preds).cpu().numpy())\n                acc \/= val_step\n                val_loss\/=(val_step + 1)\n                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {acc:.4f}')\n                show_preds()\n                \n                resnet18.train()\n                \n                if acc>0.95:\n                    print('Performance condition met...')\n                    return \n        train_loss = train_loss\/(train_step + 1)\n        print(f'Training loss: {train_loss:.4f}')","f24b2ce6":"train(1)","2238cd12":"show_preds()","bc44fcf0":"# Final Result","40dd192d":"# Create Dataset directory and split","ed759530":"# Training model","f3be78d3":"# Transformers","fdaee5b3":"# Dataloader","5ce891e6":"# Dataset"}}