{"cell_type":{"a01ce385":"code","cfe8358b":"code","c9edbfea":"code","632080a3":"code","15891974":"code","9032166e":"code","1cc200be":"code","5db75249":"code","64e7dd27":"code","40891c82":"code","7bb2ede6":"code","12fdeb75":"code","5379824d":"code","ba74fff9":"code","bd33eadd":"code","eb3e8162":"code","f329d1c0":"code","2f5031c8":"code","48b7760f":"code","8fa46f56":"code","e48c9e7e":"code","3b1f7cb8":"code","b08410dd":"code","516a4b8d":"code","7bb2fe73":"code","76efa6ee":"code","95711f8e":"code","59f352a9":"code","d26dfbaf":"code","b3fae9c4":"code","dae9e279":"code","04d90fc5":"code","ccc178f1":"code","819e5897":"code","2f31f0bd":"code","9f944ecb":"code","218842c0":"markdown","23d01174":"markdown","a185d31b":"markdown"},"source":{"a01ce385":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.utils import to_categorical\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.layers import Dense,Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam,Adamax\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","cfe8358b":"sample = pd.read_csv(\"..\/input\/sample_submission.csv\") #28 * 28 pixel\ntrain =  pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","c9edbfea":"img_size = 28 # image consists of 784 pixel which is 28 * 28 ","632080a3":"Y = train['label'] # target data","15891974":"X = train.drop(['label'],axis = 1) #train data","9032166e":"# Normalize the data\nX = X \/ 255.0\ntest = test \/ 255.0","1cc200be":"#The first 25 data point in train data and their labels\nplt.figure(figsize = (10,10))\nfor i in range (25) :\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.xlabel(Y[i])\n    plt.imshow(X.iloc[i,:].values.reshape(img_size,img_size))","5db75249":"# Then lets create x_train, y_train, x_test, y_test arrays\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n","64e7dd27":"print(\"X_train shape is : \",X_train.shape)\nprint(\"Y_train shape is : \", Y_train.shape)\nprint(\"X_test shape is \" , X_test.shape)\nprint(\"Y_test shape is \" , Y_test.shape)","40891c82":"#Firstly I tried logistic regression , to see compare the result with neural networks.\nfrom sklearn import linear_model\nlogreg = linear_model.LogisticRegression(random_state = 42,max_iter= 150,solver = 'sag', tol = 0.1,)\n","7bb2ede6":"Y_train =Y_train.values.reshape(-1,1)","12fdeb75":"logreg.fit(X_train,Y_train )","5379824d":"print(\"test accuracy: {} \".format(logreg.score(X_test, Y_test)))\nprint(\"train accuracy: {} \".format(logreg.score(X_train, Y_train)))","ba74fff9":"#keras optimizer for neural network\nadamax =Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)","bd33eadd":"#defining function for building neural network\ndef Classifier() :\n    model = Sequential() # initialize neural network\n    model.add(Dense(units = 240, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n    model.add(Dense(units = 240, kernel_initializer = 'uniform', activation = 'relu'))\n    model.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'softmax'))#softmax is used for classification\n    model.compile(optimizer = adamax, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    return model \n\n","eb3e8162":"model = Classifier()","f329d1c0":"Y_train = to_categorical(Y_train) #we are using 1 hot encoding here","2f5031c8":"history = model.fit(X_train , Y_train,epochs = 10,batch_size = 150 )#fitting our model","48b7760f":"test_loss, test_acc = model.evaluate(X_train, Y_train) #evaluating our model\nprint('Test accuracy:', test_acc)","8fa46f56":"#Plottling accuracy\nplt.plot(history.history['acc'])\n#plt.plot(history.history['loss'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['accuracy'], loc='upper left')\nplt.show()","e48c9e7e":"#Plotting loss values\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['loss'], loc='upper left')\nplt.show()","3b1f7cb8":"prediction = model.predict(test) ","b08410dd":"#First 15 samples of test database and result of them . It looks like we are taking corrects results\nplt.figure(figsize = (30,20))\nfor i in range (15):\n    plt.subplot(5,6, 1 + 2*i )\n    plt.imshow(test.iloc[i].values.reshape(img_size,img_size))\n    plt.subplot(5,6,2 +(2*i) )\n    plt.plot(prediction[i])","516a4b8d":"#Creating our CNN MODEL\nmodel3 = Sequential()\n\n","7bb2fe73":"#Add\u0131ng layers to our CNN model\nmodel3.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel3.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel3.add(MaxPool2D(pool_size=(2,2)))\nmodel3.add(Dropout(0.25))\n\nmodel3.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel3.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel3.add(MaxPool2D(pool_size=(2,2)))\nmodel3.add(Dropout(0.25))\n\n\nmodel3.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel3.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel3.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel3.add(Dropout(0.25))\n\n\nmodel3.add(Flatten())\nmodel3.add(Dense(256, activation = \"relu\"))\nmodel3.add(Dropout(0.5))\nmodel3.add(Dense(10, activation = \"softmax\"))","76efa6ee":"optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","95711f8e":"model3.compile(optimizer  = optimizer , loss = 'categorical_crossentropy',metrics =['accuracy'])","59f352a9":"# Then lets create x_train, y_train, x_test, y_test arrays\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n","d26dfbaf":"#Data Reshaping \nX_train = X_train.values.reshape(-1,28,28,1)\nY_train = to_categorical(Y_train, num_classes = 10)\nX_test = X_test.values.reshape(-1,28,28,1)\nY_test=to_categorical(Y_test , num_classes = 10)","b3fae9c4":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.5, # Randomly zoom image 5%\n        width_shift_range=0.5,  # randomly shift images horizontally 5%\n        height_shift_range=0.5,  # randomly shift images vertically 5%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","dae9e279":"print(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_test.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_test.shape)","04d90fc5":"# Fit the model\nhistory = model3.fit_generator(datagen.flow(X_train,Y_train, batch_size=140),\n                              epochs = 10, validation_data = (X_test,Y_test) )#steps_per_epoch=X_train.shape[0] \/\/ batch_size","ccc178f1":"model3.evaluate(X_train,Y_train)","819e5897":"#Evalution of models \n","2f31f0bd":"test = test.values.reshape(-1,28,28,1)","9f944ecb":"#Submit file\npredictions_class = model3.predict_classes(test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions_class)+1)),\n                         \"Label\": predictions_class})\nsubmissions.to_csv(\"Submission.csv\", index=False, header=True)\n","218842c0":"# Neural Network part\n<br>\n<br>\n<br>\n<a href= \"https:\/\/towardsdatascience.com\/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6\"><img src = \"https:\/\/cdn-images-1.medium.com\/max\/1600\/1*sX6T0Y4aa3ARh7IBS_sdqw.png\" alt=\"Neural Network\"><\/a>\n\n","23d01174":"* **Im beginner at data science , while I am creating these kernels , \u0131m also learning the topics from resources and other kernels by you . **\n* **I wiil be happy if you will give some feedback on my works . **\n* **Have a good day :)**","a185d31b":"**Convolutional Neural Network ( CNN) **\n<br>\n<br>\n\n<a href=\"https:\/\/medium.com\/@RaghavPrabhu\/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\"><img src=\"https:\/\/cdn-images-1.medium.com\/max\/1600\/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg\" alt=\"CNN\" border=\"0\"><\/a>"}}