{"cell_type":{"b0abf401":"code","5bb9daa3":"code","a11e7464":"code","115a2ca1":"code","243119d0":"code","06711a1d":"code","68cbd2ec":"code","ceaa0423":"code","35dda121":"code","b743823e":"code","564bf28e":"code","57f10630":"code","a8a79815":"code","a9f7cffa":"code","c596363b":"code","a4f39c55":"code","3c982055":"code","7aa9e698":"code","944b8008":"code","536d51b5":"markdown","0c24a081":"markdown","97374b32":"markdown","fd5cc3fb":"markdown","54f7e88d":"markdown","a87e2742":"markdown","e81bb956":"markdown","297f34f8":"markdown","5daac1f3":"markdown","72a1c47b":"markdown","aa93faca":"markdown","4a491533":"markdown","54ab8984":"markdown","343c758f":"markdown"},"source":{"b0abf401":"!pip install -q efficientnet","5bb9daa3":"import numpy as np\nimport pandas as pd\n\nimport re\nimport os\n\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom sklearn.metrics import confusion_matrix, f1_score\nfrom sklearn.metrics import precision_score, recall_score\n\nimport seaborn as sea\nimport matplotlib.pyplot as plt","a11e7464":"sea.set_style(\"darkgrid\")\nnp.random.seed(3)\ntf.random.set_seed(6)","115a2ca1":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nprint(\"Number of TPU cores\\t: \", tpu_strategy.num_replicas_in_sync)\nprint('Running on TPU\\t\\t: ', tpu.master())","243119d0":"gcs_path = KaggleDatasets().get_gcs_path(\"tpu-getting-started\")\ndata_path = os.path.join(gcs_path, \"tfrecords-jpeg-512x512\/\")\n\ntrain_path = os.path.join(gcs_path, \"tfrecords-jpeg-512x512\/train\/\")\nval_path = os.path.join(gcs_path, \"tfrecords-jpeg-512x512\/val\/\")\ntest_path = os.path.join(gcs_path, \"tfrecords-jpeg-512x512\/test\/\")","06711a1d":"classes = ['pink primrose',       'hard-leaved pocket orchid',\n           'canterbury bells',    'sweet pea', \n           'wild geranium',       'tiger lily',\n           'moon orchid',         'bird of paradise',\n           'monkshood',           'globe thistle', \n           'snapdragon',          \"colt's foot\",\n           'king protea',         'spear thistle',\n           'yellow iris',         'globe-flower',\n           'purple coneflower',   'peruvian lily',\n           'balloon flower',      'giant white arum lily',\n           'fire lily',           'pincushion flower',\n           'fritillary',          'red ginger',\n           'grape hyacinth',      'corn poppy',\n           'prince of wales feathers', 'stemless gentian',\n           'artichoke',           'sweet william',         \n           'carnation',           'garden phlox', \n           'love in the mist',    'cosmos',\n           'alpine sea holly',    'ruby-lipped cattleya',\n           'cape flower',         'great masterwort',\n           'siam tulip',          'lenten rose',\n           'barberton daisy',     'daffodil', \n           'sword lily',          'poinsettia',\n           'bolero deep blue',    'wallflower',\n           'marigold',            'buttercup',\n           'daisy',               'common dandelion', \n           'petunia',             'wild pansy',\n           'primula',             'sunflower',\n           'lilac hibiscus',      'bishop of llandaff',\n           'gaura',               'geranium',\n           'orange dahlia',       'pink-yellow dahlia',  \n           'cautleya spicata',    'japanese anemone',\n           'black-eyed susan',    'silverbush',\n           'californian poppy',   'osteospermum',\n           'spring crocus',       'iris',\n           'windflower',          'tree poppy',\n           'gazania',             'azalea',\n           'water lily',          'rose',\n           'thorn apple',         'morning glory',\n           'passion flower',      'lotus',\n           'toad lily',           'anthurium',\n           'frangipani',          'clematis',\n           'hibiscus',            'columbine',\n           'desert-rose',         'tree mallow',\n           'magnolia',            'cyclamen ',\n           'watercress',          'canna lily',\n           'hippeastrum ',        'bee balm',\n           'pink quill',          'foxglove',\n           'bougainvillea',       'camellia',\n           'mallow',              'mexican petunia',\n           'bromelia',            'blanket flower',\n           'trumpet creeper',     'blackberry lily',\n           'common tulip',        'wild rose']","68cbd2ec":"def read_record(example):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, features)\n    \n    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.reshape(image, [512,512,3])   \n    label = tf.cast(example[\"class\"], tf.int32)\n    \n    return image, label\n\ndef read_record_test(example):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, features)\n    \n    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.reshape(image, [512,512,3])\n    image_id = example[\"id\"]\n    \n    return image, image_id","ceaa0423":"AUTO = tf.data.experimental.AUTOTUNE\n\ndef get_size(filenames):    \n    # get number of examples from shard filenames\n    data_size = 0\n    for i in range(len(filenames)):\n\n        count = re.search(r\"-[0-9][0-9][0-9]\\.\", filenames[i]).group()\n        data_size = data_size + int(count[1:4])\n        \n    return data_size\n\ndef prepare_dataset(flag, order = False):\n\n    filenames = tf.io.gfile.glob(os.path.join(data_path, flag)+\"\/*.tfrec\")   \n    data_size = get_size(filenames)    \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    \n    # disregard the order of .tfrec files\n    ignore_order = tf.data.Options()\n    if order == False:\n        ignore_order.experimental_deterministic = False\n    else:\n        ignore_order.experimental_deterministic = True\n    dataset = dataset.with_options(ignore_order)\n    \n    if flag == \"test\":\n        dataset = dataset.map(read_record_test, num_parallel_calls=AUTO)\n    else:\n        dataset = dataset.map(read_record, num_parallel_calls=AUTO)\n        \n    return dataset, data_size\n    \ntrain_dataset, train_size = prepare_dataset(\"train\")\nval_dataset, val_size = prepare_dataset(\"val\")\ntest_dataset, test_size = prepare_dataset(\"test\")\n\nprint(\"Size of Training Dataset\\t: \", train_size)\nprint(\"Size of Validation Dataset\\t: \", val_size)\nprint(\"Size of Test Dataset\\t\\t: \", test_size)","35dda121":"def augment(image, label):    \n    \n    # random contrast parameters\n    cont_low = 0.8\n    cont_high = 1.2\n    \n    cont_factor = tf.random.uniform([], minval=cont_low,\n                                        maxval=cont_high,\n                                        dtype=tf.float32)\n\n    trn_image = tf.image.adjust_contrast(image, cont_factor)    \n    \n    return trn_image, label    ","b743823e":"# batch_size is scaled with the number of TPU cores\nbatch_size = 16 * tpu_strategy.num_replicas_in_sync\n\ntrain_dataset = train_dataset.map(augment,\n                num_parallel_calls = AUTO)\n\ntrain_dataset = train_dataset.repeat().shuffle(3000) \\\n                .batch(batch_size).prefetch(AUTO)\n    \nval_dataset = val_dataset.batch(batch_size).prefetch(AUTO)\ntest_dataset = test_dataset.batch(batch_size).prefetch(AUTO)","564bf28e":"show = train_dataset.unbatch().batch(9)\nimage, label = next(iter(show))\n\nfig, axes = plt.subplots(constrained_layout = True,\n                         nrows=3, ncols=3, figsize=(10, 10))\n\nfor i in range(3):\n    for j in range(3):       \n        axes[i][j].imshow(image[i*3+j], aspect=\"auto\")\n        axes[i][j].axis(\"off\")\n        axes[i][j].title.set_text(classes[label[i*3+j]])","57f10630":"with tpu_strategy.scope():\n    \n    base_model = efn.EfficientNetB5(include_top=False,\n                                    input_shape=(512,512,3),\n                                    weights='imagenet')\n    base_model.trainable = True  \n    \n    model = Sequential(name=\"Flower_Detector\")\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D(name=\"GAP\"))\n    model.add(Dense(104, activation=\"softmax\", name=\"Probs\"))\n    \n    model.compile(optimizer=tf.keras.optimizers.Adam(),\n                 loss=\"sparse_categorical_crossentropy\", \n                 metrics=[\"sparse_categorical_accuracy\"])\n    \nmodel.summary()","a8a79815":"epoch = 20\n\n# Learning rate scheduler\ndef decay(inp):   \n    lr_init = 0.00005\n    # max learning rate is scaled with the number of TPU cores\n    lr_max = 0.000125 * tpu_strategy.num_replicas_in_sync\n    lin_lr = 5\n    if inp <= lin_lr:\n        lr = inp*(lr_max - lr_init) \/ lin_lr + lr_init\n    else:\n        lr = lr_max * np.exp(-0.1*(inp - lin_lr))\n        \n    return lr\n\nlrs = LearningRateScheduler(decay)\n\nx = np.linspace(0,epoch,200)\ny = [decay(i) for i in x]\n\nplt.xticks(range(0,epoch+1,2))\nplt.plot(x,y);\nplt.ylabel(\"Learning Rate\");\nplt.xlabel(\"epoch\");","a9f7cffa":"step_per_epoch = train_size \/\/ batch_size\n\nhistory = model.fit(train_dataset,\n                    validation_data=val_dataset,\n                    steps_per_epoch=step_per_epoch,\n                    epochs=epoch,\n                    callbacks=[lrs])","c596363b":"e = np.linspace(1, epoch, epoch)\n\nfig, axes = plt.subplots(constrained_layout = True,\n                         nrows=1, ncols=2, figsize=(12, 5))\n\nsea.lineplot(x = e, y = history.history['loss'],\n             ax=axes[0], label=\"train\");\nsea.lineplot(x = e, y = history.history['val_loss'],\n             ax=axes[0], label=\"val\");\naxes[0].set_ylabel(\"Loss\")\naxes[0].set_xlabel(\"epoch\")\naxes[0].set_xticks(range(0,epoch+1,2))\n\nsea.lineplot(x = e, y = history.history['sparse_categorical_accuracy'],\n             ax=axes[1], label=\"train\");\nsea.lineplot(x = e, y = history.history['val_sparse_categorical_accuracy'],\n             ax=axes[1], label=\"val\");\naxes[1].set_ylabel(\"Sparse Categorical Accuracy\")\naxes[1].set_xlabel(\"epoch\")\naxes[1].set_xticks(range(0,epoch+1,2));","a4f39c55":"val_dataset, val_size = prepare_dataset(\"val\", True)\nval_dataset = val_dataset.batch(batch_size).prefetch(AUTO)\n\nval_image_dataset = val_dataset.map(lambda image,label: image)\nval_label_dataset = val_dataset.map(lambda image,label: label).unbatch()\nval_labels = next(iter(val_label_dataset.batch(val_size))).numpy()\n\nval_probs = model.predict(val_image_dataset)\nval_preds = np.argmax(val_probs, axis=-1)","3c982055":"con_mat = confusion_matrix(val_labels, val_preds,\n                           labels=range(len(classes)))\n\nprec = precision_score(val_labels, val_preds,\n                       labels=range(len(classes)),\n                       average='macro')\n\nrec = recall_score(val_labels, val_preds,\n                   labels=range(len(classes)),\n                   average='macro')\n\nf1 = f1_score(val_labels, val_preds,\n              labels=range(len(classes)),\n              average='macro')\n\n\nplt.figure(figsize=(10,10))\nax = plt.gca()\nax.matshow(con_mat, cmap='Greens')\nax.set_xticks(range(len(classes)))\nax.set_xticklabels(classes, fontdict={'fontsize': 6})\nplt.setp(ax.get_xticklabels(), rotation=65, ha=\"left\",\n                                rotation_mode=\"anchor\")\nax.set_yticks(range(len(classes)))\nax.set_yticklabels(classes, fontdict={'fontsize': 6})\nplt.setp(ax.get_yticklabels(), rotation=25, ha=\"right\",\n                                rotation_mode=\"anchor\")\nplt.show()\n\nprint('Precision \\t: {:.4f}'.format(prec))\nprint('Recall \\t\\t: {:.4f}'.format(rec))\nprint('F1 score \\t: {:.4f}'.format(f1))","7aa9e698":"test_dataset, test_size = prepare_dataset(\"test\", True)\ntest_dataset = test_dataset.batch(batch_size).prefetch(AUTO)\n\ntest_image_dataset = test_dataset.map(lambda image,idnum: image)\ntest_id_dataset = test_dataset.map(lambda image,idnum: idnum).unbatch()\ntest_ids = next(iter(test_id_dataset.batch(test_size))).numpy().astype('U')\n\ntest_probs = model.predict(test_image_dataset)\ntest_preds = np.argmax(test_probs, axis=-1)","944b8008":"#np.savetxt('submission.csv', np.rec.fromarrays([test_ids,test_preds]),\n#           fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')","536d51b5":"Compute **confusion matrix**, **precision**, **recall** and **f1-score** for validation dataset.","0c24a081":"**train_dataset** is repeated and shuffled. Repeat is necessary because training continues for more than 1 epoch. Shuffling is applied to a subset of dataset in a buffer. The size of the buffer is adjustable. Shuffling is not needed for validation and test sets.\n\nPrefetch is used to prepare next batch of examples while current batch is in use. Remember a copy of our model will be placed on each TPU core. Input data batch will be shared among cores. This is called data parallelism. So batch size should be resized according to the number of available cores.\n\nAugmentation can be incorporated in our data pipeline. For this notebook we will use random contrast adjustment. If you are interested in more advanced augmentation with tf.data, you can refer to my notebook on **Pneumonia Detection** where I describe the augmentation process and transformation functions in detail.","97374b32":"## Create Data Pipeline\n\nEach example in the dataset includes image and its label.","fd5cc3fb":"Loss and sparse categorical accuracy plots are depicted below for train and validation datasets.","54f7e88d":"## Initialize TPU\n\nSince TPU is a network connected accelerator, we need to locate it. Then we need to instantiate a TPU strategy. This strategy will enable us to define copies of our model on different cores. Data will be shared among the cores and model training will be accomplished in parallel.","a87e2742":"## Load Dataset\n\nThe dataset includes 104 types of flowers from five different public datasets. Dataset is located in **Google Cloud Storage (GCS)** bucket and is available in different resolutions. My choice is 512x512. First we get GCS location.","e81bb956":"Some of the training images are depicted below","297f34f8":"Names of 104 flower species are listed below","5daac1f3":"## Performance Details on Validation Set\n\nDuring training, read order of tfrec files isn't important. But for validation, we seperate images and labels. Their order is important.","72a1c47b":"## Training\n\nWe will use **EfficientNetB5** with imagenet weights. Model is defined inside **tpu_strategy.scope()**. This way a seperate copy of the model is created on each different core.","aa93faca":"As the amount of data and complexity of the deep learning models increase, the need for more capable hardware platforms also increases. **Tensor Processing Units (TPU)** are custom designed ASICs developed by **Google** specifically for deep learning. TPU v3-8, available on Kaggle, has 8 cores and 128 GB memory. Each core has vector processing unit (VPU) and matrix multiply unit (MXU).\n\nTPU is very fast at data processing, then data should also be fed in a fast way. TFRecord format is suitable for this purpose. If there are lots of files to be read from local disk or from a device on the network  and feeding data to your model is the bottleneck for your training process, try using TFRecord. Instead of locating, opening, reading and closing thousands of files again and again, TFRecord stores data serialized into a few files which are called shard.\n\nSharding a dataset into multiple files is a good practice because of the following reasons:\n\n* tf.data.Dataset API can read input examples in parallel\n* tf.data.Dataset API can shuffle the examples better with sharded files\n\nShard files are connected to tf.data pipeline. Data is read from all shards in parallel making data consumption very fast.\n\nConsider an image dataset which stores just label and image itself. To convert to TFRecord format, image is converted to tf.train.BytesList and label is converted to tf.train.Int64List. Then they are converted to tf.train.Feature format. Finally features are combined to produce tf.train.Example which are serialized and written to tfrec files sequentially.","4a491533":"## Submission\n\nPrepare and save csv file","54ab8984":"## Prediction on Test Set\n\nMake predictions on test images","343c758f":"We need to define a learning rate schedule function starting with a very small learning rate. Since we are fine-tuning the parameters of the base model, starting with a very small value is necessary for the adaptation of the pretrained coefficients. If we start with a high learning rate, the pretrained coefficients may change abruptly deteriorating the performance of the model.\n\nAlso, max learning rate should be scaled in accordance with the batch size. During backpropagation, the gradient may be noisy if batch size is small. Large batches are more dependable so learning rate can be increased as batch size increases."}}