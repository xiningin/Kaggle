{"cell_type":{"0a97a490":"code","6a2ed835":"code","689c80f6":"code","c1d581a1":"code","e7979661":"code","cb130eca":"code","1c4b7e6c":"code","a4da8d12":"markdown","b261afea":"markdown","b1a81971":"markdown","2e9af97a":"markdown","00b917dd":"markdown"},"source":{"0a97a490":"%%writefile base_agent.py\n\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col\n\ndef agent(obs_dict, config_dict):\n    \"\"\"This agent always moves toward observation.food[0] but does not take advantage of board wrapping\"\"\"\n    observation = Observation(obs_dict)\n    configuration = Configuration(config_dict)\n    player_index = observation.index\n    player_goose = observation.geese[player_index]\n    player_head = player_goose[0]\n    player_row, player_column = row_col(player_head, configuration.columns)\n    food = observation.food[0]\n    food_row, food_column = row_col(food, configuration.columns)\n\n    if food_row > player_row:\n        return Action.SOUTH.name\n    if food_row < player_row:\n        return Action.NORTH.name\n    if food_column > player_column:\n        return Action.EAST.name\n    return Action.WEST.name","6a2ed835":"%%writefile agent.py\n\nfrom kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col\nfrom random import choice, sample\n\ndef random_agent():\n    return choice([action for action in Action]).name\n\n\ndef translate(position: int, direction: Action, columns: int, rows: int):\n    row, column = row_col(position, columns)\n    row_offset, column_offset = direction.to_row_col()\n    row = (row + row_offset) % rows\n    column = (column + column_offset) % columns\n    return row * columns + column\n\n\ndef adjacent_positions(position: int, columns: int, rows: int):\n    return [\n        translate(position, action, columns, rows)\n        for action in Action\n    ]\n\n\ndef min_distance(position: int, food: [int], columns: int):\n    row, column = row_col(position, columns)\n    return min(\n        abs(row - food_row) + abs(column - food_column)\n        for food_position in food\n        for food_row, food_column in [row_col(food_position, columns)]\n    )\n\n\ndef agent(observation, configuration):\n    observation = Observation(observation)\n    configuration = Configuration(configuration)\n    rows, columns = configuration.rows, configuration.columns\n\n    food = observation.food\n    geese = observation.geese\n    opponents = [\n        goose\n        for index, goose in enumerate(geese)\n        if index != observation.index and len(goose) > 0\n    ]\n\n    # Don't move adjacent to any heads\n    head_adjacent_positions = {\n        opponent_head_adjacent\n        for opponent in opponents\n        for opponent_head in [opponent[0]]\n        for opponent_head_adjacent in adjacent_positions(opponent_head, rows, columns)\n    }\n    # Don't move into any bodies\n    bodies = {position for goose in geese for position in goose[0:-1]}\n    # Don't move into tails of heads that are adjacent to food\n    tails = {\n        opponent[-1]\n        for opponent in opponents\n        for opponent_head in [opponent[0]]\n        if any(\n            adjacent_position in food\n            # Head of opponent is adjacent to food so tail is not safe\n            for adjacent_position in adjacent_positions(opponent_head, rows, columns)\n        )\n    }\n\n    # Move to the closest food\n    position = geese[observation.index][0]\n    actions = {\n        action: min_distance(new_position, food, columns)\n        for action in Action\n        for new_position in [translate(position, action, columns, rows)]\n        if (\n            new_position not in head_adjacent_positions and\n            new_position not in bodies and\n            new_position not in tails\n        )\n    }\n\n    if any(actions):\n        return min(actions, key=actions.get).name\n\n    return random_agent()","689c80f6":"from kaggle_environments import *","c1d581a1":"env = make(\"hungry_geese\", configuration={\"columns\": 11, \"rows\": 7, \"hunger_rate\": 40, \"min_food\": 2 }, debug=True)","e7979661":"output = env.run([agent, 'random'])","cb130eca":"# print('Left player: action = %s, reward = %s, status = %s, info = %s' % (output[0][\"action\"], output[0]['reward'], output[0]['status'], output[0]['info']))\n# print('Right player: action = %s, reward = %s, status = %s, info = %s' % (output[1][\"action\"], output[1]['reward'], output[1]['status'], output[1]['info']))","1c4b7e6c":"env.render(mode=\"ipython\", width=800, height=600)","a4da8d12":"# baseline agent (just toward food)","b261afea":"# baseline agent (greedy)","b1a81971":"# Hungry Geese\n- You can play on Google\n![image.png](attachment:image.png)","2e9af97a":"# Render","00b917dd":"We will create an AI agent to play against others and survive the **longest** in this competition.\n\n### How To Play\n- Players will guide their goose throughout a 11 x 7 cell grid. You may instruct your goose to move `NORTH`, `SOUTH`, `EAST`, or `WEST`.\n- The episode continues for 200 rounds - the agent with the highest reward, or the last agent remaining, wins the episode.\n- The reward is calculated as the `current turn` + `goose length`.\n- Agents can add a segment to their goose by eating food which appears on the board. Food can be donuts, pizza, pie, or peppers.\n- There are a minimum of 2 food units on the board at all times. \n- Every 40 steps, the goose loses a segment.\n\n### Important point\n- That you have to be careful with the boundaries.\n- There is no risk of being eaten if you follow the border, but others may eat the food first.\n\nThe baseline code was taken from the following reference:\nhttps:\/\/github.com\/Kaggle\/kaggle-environments\/blob\/master\/kaggle_environments\/envs\/hungry_geese\/hungry_geese.py"}}