{"cell_type":{"3a995df3":"code","33c08e39":"code","5b637239":"code","c420a6ea":"code","6fa93dc7":"code","76762de1":"code","d11d39f9":"code","f7d8bd04":"code","0f6a1876":"code","d050da9e":"code","e4188fb4":"code","aff57daa":"code","f542be0f":"code","2414d335":"code","bb6845f0":"code","a321c8d7":"code","81ae6100":"code","541c9a09":"code","1aa6b683":"markdown","349b71c4":"markdown","8f41bede":"markdown","07bd4c17":"markdown","baa88107":"markdown"},"source":{"3a995df3":"import numpy as np \nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom lightgbm import LGBMRegressor\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error as mse\n\n\n\n\nroot_filepath = \"..\/input\/predict-volcanic-eruptions-ingv-oe\/\"\nsave_filepath = \".\/\"\nos.mkdir(\".\/preprocessed\")\nos.mkdir(\".\/predictions\")","33c08e39":"def get_signals(id, folder=\"train\"):\n    return pd.read_csv(root_filepath + f\"{folder}\/{str(id)}.csv\")\n","5b637239":"train = pd.read_csv(root_filepath+\"train.csv\")\ntest = pd.read_csv(root_filepath+\"sample_submission.csv\").drop(\"time_to_eruption\", axis=1)\nsorted_train = train.sort_values(\"time_to_eruption\")\nplt.hist((train[\"time_to_eruption\"]), bins=100)\nplt.show()","c420a6ea":"plt.figure(figsize=(25,20))\nfor i in range(20):\n    plt.subplot(10,2,i+1)\n    if i%2==0:\n        plt.plot(np.fft.fftshift(np.real(np.fft.fft(get_signals(list(sorted_train[\"segment_id\"])[12])[f\"sensor_{i\/\/2+1}\"].fillna(0)))))\n        plt.title(f\"{i\/\/2+1} MIN sensor\")\n    else:\n        plt.plot(np.fft.fftshift(np.real(np.fft.fft(get_signals(list(sorted_train[\"segment_id\"])[-12])[f\"sensor_{i\/\/2+1}\"].fillna(0)))))\n        plt.title(f\"{i\/\/2+1} maX sensor\")\n        \n","6fa93dc7":"plt.figure(figsize=(25,20))\nfor i in range(20):\n    plt.subplot(10,2,i+1)\n    if i%2==0:\n        plt.plot(get_signals(list(sorted_train[\"segment_id\"])[12])[f\"sensor_{i\/\/2+1}\"].fillna(0))\n        plt.title(f\"{i\/\/2+1} MIN sensor\")\n    else:\n        plt.plot(get_signals(list(sorted_train[\"segment_id\"])[-12])[f\"sensor_{i\/\/2+1}\"].fillna(0))\n        plt.title(f\"{i\/\/2+1} maX sensor\")\n","76762de1":"def create_feature_particle(signal, segment_id, sensor_id):\n    output = pd.DataFrame()\n    signal = signal.fillna(0)\n    furier = np.real(np.fft.fft(signal))\n    output.loc[segment_id, f\"5th_quantile_s{sensor_id}\"] = np.quantile(signal, 0.05)\n    output.loc[segment_id, f\"10th_quantile_s{sensor_id}\"] = np.quantile(signal, 0.1)    \n    output.loc[segment_id, f\"25th_quantile_s{sensor_id}\"] = np.quantile(signal, 0.25)    \n    output.loc[segment_id, f\"30th_quantile_s{sensor_id}\"] = np.quantile(signal, 0.3)    \n    output.loc[segment_id, f\"60th_quantile_s{sensor_id}\"] = np.quantile(signal, 0.6)    \n    output.loc[segment_id, f\"70th_quantile_s{sensor_id}\"] = np.quantile(signal, 0.7)    \n    output.loc[segment_id, f\"90th_quantile_s{sensor_id}\"] = np.quantile(signal, 0.9) \n    output.loc[segment_id, f\"mean_s{sensor_id}\"] = signal.mean()\n    output.loc[segment_id, f\"std_s{sensor_id}\"] = signal.std()\n    output.loc[segment_id, f\"var_s{sensor_id}\"] = signal.var()\n    output.loc[segment_id, f\"skew_s{sensor_id}\"] = signal.skew()\n    output.loc[segment_id, f\"fft_mean_s{sensor_id}\"] = furier.mean()\n    output.loc[segment_id, f\"fft_std_s{sensor_id}\"] = furier.std()\n    output.loc[segment_id, f\"fft_min_s{sensor_id}\"] = furier.min()\n    output.loc[segment_id, f\"fft_max_s{sensor_id}\"] = furier.max() \n    \n    return output\n\n\n\n    ","d11d39f9":"def create_na_feat(segment_id, folder=\"train\"):\n    output = pd.DataFrame()\n    data = get_signals(segment_id, folder=folder)\n    for i in range(1,11):\n        output.loc[segment_id, f\"na_percent_s{i}\"] = data[f\"sensor_{i}\"].isna().sum()\/len(data[f\"sensor_{i}\"])\n    return output","f7d8bd04":"def make_features(train, folder=\"train\"):\n    segments = []\n    ci = 0\n\n    for seg in train[\"segment_id\"]:\n        signals = get_signals(seg, folder=folder)\n        segment_row = []\n        if ci % 100 == 0:\n            print(ci)\n        for i in range(1,11):\n            segment_row.append(create_feature_particle(signals[f\"sensor_{i}\"], seg, i))\n        segments.append(pd.concat(segment_row + [create_na_feat(seg, folder=folder)], axis=1))\n        ci += 1\n\n    featured_train = pd.concat(segments, axis=0)\n    featured_train = featured_train.reset_index()\n    featured_train = featured_train.rename(columns={featured_train.columns[0]:\"segment_id\"})\n    return featured_train","0f6a1876":"\"\"\"featured_train = pd.merge(make_features(train), train, on=\"segment_id\")\nfeatured_train.to_csv(save_filepath + \"preprocessed\/featured_train.csv\")\nfeatured_test = make_features(test, folder=\"test\")\nfeatured_test.to_csv(save_filepath + \"preprocessed\/featured_test.csv\")\nprint(\"Save successful!\")\"\"\"","d050da9e":"featured_train = pd.read_csv(\"..\/input\/featured-train\/featured_train.csv\")\nfeatured_test = pd.read_csv(\"..\/input\/featured-train\/featured_test.csv\")\n\n","e4188fb4":"f_train = featured_train.drop([\"segment_id\", \"time_to_eruption\"]+list(featured_train.columns)[-10:], axis=1)\ncorr_matrix = f_train.corrwith(featured_train[\"time_to_eruption\"])\nfig = plt.figure(figsize=(8, 30))\nsns.scatterplot(x=list(corr_matrix), y=corr_matrix.index)","aff57daa":"dropped_cols = [i for i in corr_matrix.index if abs(corr_matrix[i])<0.01]\nprint(dropped_cols)","f542be0f":"X = featured_train.drop([\"segment_id\", \"time_to_eruption\"], axis=1)\ny = featured_train[\"time_to_eruption\"]\nrfe_test = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=70, step=3)\nrfe_test.fit(X,y)","2414d335":"mask = rfe_test.support_\nremoved = [col for ind, col in zip(mask, list(X.columns)[:-10]) if not ind]\nprint(removed)","bb6845f0":"X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=103, test_size=0.2, shuffle=True)","a321c8d7":"def rmse(true, pred):\n    return np.sqrt(mse(true,pred))","81ae6100":"params = {\n    'num_leaves': 29,\n    'n_estimators': 289,\n    'max_depth': 8,\n    'min_child_samples': 507,\n    'learning_rate': 0.0812634327662599,\n    'min_data_in_leaf': 13,\n    'bagging_fraction': 0.020521665677937423,\n    'feature_fraction': 0.05776459974779927,\n    'random_state': 101\n}\n\nlgb_model = LGBMRegressor(**params)\nlgb_model.fit(X_train, y_train)\npred = lgb_model.predict(X_val)\n\nprint(rmse(pred, y_val))    ","541c9a09":"submission = pd.concat([test,pd.DataFrame(lgb_model.predict(featured_test.drop([\"segment_id\"], axis=1)))], axis=1)\nsubmission.to_csv(\".\/submission.csv\")","1aa6b683":"Showing the same signals without fft","349b71c4":"Showing the furier transform for the signals of low and hight time eruption examples.","8f41bede":"Lets make the following features:\n    - for every sensor:\n        * 5,10,25,30,60,70,90% quantile\n        * signal mean\n        * signal std\n        * signal variance\n        * skew\n    - for its fft compute:\n        * min\n        * max\n        * mean\n        * std","07bd4c17":"# **A cell to preprocess the train and the test set**","baa88107":"Read the input files and do a little **preprocessing**"}}