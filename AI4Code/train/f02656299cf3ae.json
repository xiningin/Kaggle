{"cell_type":{"0e3ff833":"code","babd8d88":"code","ff3f15a1":"code","681ea0c1":"code","00b2f340":"code","b6d89405":"code","433b9c4f":"code","b6d31f05":"code","4c898f5f":"code","148e193d":"code","10da12d3":"code","40b95579":"code","2724b25b":"code","b03a32c0":"code","7ad1d339":"code","4c4a9d55":"code","fa01536d":"code","676a3a08":"code","d65821d5":"code","40a13479":"code","756824bc":"code","c24b737d":"code","37d6741e":"code","4b63a525":"code","17536ac2":"code","7d1bcb4e":"code","0c964af2":"code","74685444":"code","bda338ff":"code","36560880":"code","0de53e06":"code","1af7a4af":"markdown"},"source":{"0e3ff833":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","babd8d88":"import pandas as pd\nimport numpy as np\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nfrom sklearn.metrics import f1_score","ff3f15a1":"df_train = pd.read_csv(\"\/kaggle\/input\/av-employee-attrition\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/av-employee-attrition\/test.csv\")\ndf_sample_submission = pd.read_csv(\"\/kaggle\/input\/av-employee-attrition\/sample_submission.csv\")","681ea0c1":"display(df_sample_submission)\nprint(\"\\n\",df_sample_submission.columns)\nprint(\"\\n\",df_sample_submission.Target.unique())","00b2f340":"display(\"Train File:\",df_train.head(10))\nprint(\"\\n\")\ndisplay(\"Test File:\",df_test.head(10))","b6d89405":"print(\"Train File:\\n\",df_train.columns)\nprint(\"\\nTest File:\\n\",df_test.columns)","433b9c4f":"print(\"Train File:\\n\",df_train.dtypes)\nprint(\"\\nTest File:\\n\",df_test.dtypes)","b6d31f05":"print(\"Train File Shape:\",df_train.shape)\nprint(\"Test File Shape:\",df_test.shape)","4c898f5f":"def missing_data_percentage(a):\n    total = a.isnull().sum().sort_values(ascending=False)\n    percent = (a.isnull().sum()\/a.isnull().count()).sort_values(ascending=False)\n    percent = percent*100\n    b = pd.concat([total, percent], axis=1, keys=['Total NULL values', 'Percentage'])\n    return b\n\nprint(\"TRAIN FILE\\n\")\ndisplay(missing_data_percentage(df_train))\nprint(\"\\n TEST FILE \\n\")\ndisplay(missing_data_percentage(df_test))","148e193d":"sns.countplot(df_train['Education_Level'])","10da12d3":"sns.countplot(df_train['Gender'])","40b95579":"sns.countplot(df_train['Designation'])","2724b25b":"sns.countplot(df_train['Quarterly Rating'])","b03a32c0":"df_edu_sal = df_train.groupby('Education_Level').agg({'Salary':'mean'})\ndf_edu_sal = df_edu_sal['Salary'].apply(lambda x: round(x,2))\nprint(\"\\n\",df_edu_sal,\"\\n\")\nsns.barplot(x=df_edu_sal.index, y=df_edu_sal.values)","7ad1d339":"df_des_sal = df_train.groupby('Designation').agg({'Salary':'mean'})\ndf_des_sal = df_des_sal['Salary'].apply(lambda x: round(x,2))\nprint(\"\\n\",df_des_sal,\"\\n\")\nsns.barplot(x=df_des_sal.index, y=df_des_sal.values)","4c4a9d55":"df_train.rename(columns = {'MMM-YY':'Reporting_Date'}, inplace = True)\ndf_train['Reporting_Date'] = pd.to_datetime(df_train['Reporting_Date'])\ndf_train['Reporting_Date'] = df_train['Reporting_Date'].dt.date","fa01536d":"df_train['Dateofjoining'] = pd.to_datetime(df_train['Dateofjoining'])\ndf_train['Dateofjoining'] = df_train['Dateofjoining'].dt.date\ndf_train['LastWorkingDate'] = pd.to_datetime(df_train['LastWorkingDate'])\ndf_train['LastWorkingDate'] = df_train['LastWorkingDate'].dt.date","676a3a08":"df_train.dtypes","d65821d5":"df_train['LastWorkingDate'] = df_train['LastWorkingDate'].fillna(0)","40a13479":"from datetime import date\ndf_train['Experience'] = ''\nfor i in range(df_train.shape[0]):\n    if(df_train['LastWorkingDate'][i] == 0):\n        a = date.today()\n        b = df_train['Dateofjoining'][i]\n        df_train['Experience'][i] = (a-b).days\n    else:\n        a = df_train['LastWorkingDate'][i]\n        b = df_train['Dateofjoining'][i]\n        df_train['Experience'][i] = (a-b).days        ","756824bc":"df_train['Designation_Change'] = ''\nfor i in range(df_train.shape[0]):\n    df_train['Designation_Change'][i] = abs(df_train['Joining Designation'][i] - df_train['Designation'][i])","c24b737d":"df_grouped = df_train.groupby('Emp_ID').agg({'Age' : 'max',\n                                             'Salary' : 'max',\n                                             'Designation': 'max',\n                                             'Total Business Value': 'mean',\n                                             'Quarterly Rating' : 'mean',\n                                             'Designation_Change' : 'max',\n                                             'Experience' : 'max'})","37d6741e":"df_grouped","4b63a525":"df_grouped['Total Business Value'] = df_grouped['Total Business Value'].apply(lambda x: round(x,2))\ndf_grouped['Quarterly Rating'] = df_grouped['Quarterly Rating'].apply(lambda x: round(x,2))","17536ac2":"df_grouped = df_grouped.reset_index()","7d1bcb4e":"X = np.array(df_grouped)\n\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n\ndf_grouped['Target'] = kmeans.labels_","0c964af2":"df_grouped","74685444":"df_sub = pd.merge(df_test, df_grouped, on='Emp_ID', how='inner')","bda338ff":"df_sub = df_sub.drop(['Age', 'Salary', 'Designation', 'Total Business Value', 'Quarterly Rating', 'Experience', 'Designation_Change'], axis=1)","36560880":"df_sub","0de53e06":"df_sub.to_csv('Submission_File.csv', index =  False)","1af7a4af":"> How are output should be????"}}