{"cell_type":{"0a565694":"code","9aed600f":"code","14658948":"code","141ad823":"code","062afb52":"code","02a80df1":"code","60abd194":"code","242d3ee8":"code","f8667aef":"code","9c953e81":"code","f91d013a":"code","c0498f14":"code","ffa201f0":"code","f1e26d7a":"code","7b110633":"code","d1c62898":"code","f7358aa0":"code","20632df3":"code","95a9fec8":"code","f970a4da":"code","eca2e15b":"code","eaf16768":"code","f15d891a":"code","6d5364b8":"code","3bd12c3a":"code","cc0f73ee":"code","93164cf9":"code","40b2661d":"code","cc75e354":"code","5b5e1caa":"code","0ff0ed19":"code","3ca442d9":"code","3df54d60":"code","6b19a7b1":"code","8f1ff2a3":"code","5969062e":"code","71523795":"code","16c36295":"code","efa347c1":"markdown","82cbb8ea":"markdown","1dfa5cc6":"markdown"},"source":{"0a565694":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9aed600f":"# to plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n# Ignore Useless Warnings\nimport warnings\nwarnings.filterwarnings(action='ignore', message='^internal gelsd')","14658948":"# Reading the data\nhousing = pd.read_csv('..\/input\/housing\/housing.csv')","141ad823":"# Take a quick look at the data Structure\nhousing.head()","062afb52":"housing.info()","02a80df1":"housing['ocean_proximity'].value_counts()","60abd194":"housing.describe()","242d3ee8":"# Histogram\nhousing.hist(bins=50, figsize=(20, 15))\nplt.show()","f8667aef":"# Histogram\nhousing['median_house_value'].hist(bins=50, figsize=(12, 8))\nplt.show()","9c953e81":"# to make this notebook's output identical at every run\nnp.random.seed(42)","f91d013a":"housing['median_income'].hist()","c0498f14":"housing['income_cat'] = pd.cut(housing['median_income'], bins=[0, 1.5, 3., 4.5, 6, np.inf],\n                              labels=[1, 2, 3, 4, 5])\nhousing['income_cat'].hist()","ffa201f0":"# Splitting the data\nfrom sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)","f1e26d7a":"# Splitting by the row id\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing['income_cat']):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]\n\nstrat_train_set['income_cat'].value_counts() \/ len(strat_test_set)","7b110633":"def income_cat_proportions(data):\n    return data['income_cat'].value_counts() \/ len(data)\n\ncompare_props = pd.DataFrame({\n    \"Overall\":income_cat_proportions(housing),\n    \"Stratified\":income_cat_proportions(strat_test_set),\n    \"Random\":income_cat_proportions(test_set),\n}).sort_index()\ncompare_props[\"Rand. %error\"] = 100 * compare_props['Random'] \/ compare_props[\"Overall\"] - 100\ncompare_props[\"Strat. %error\"] = 100 * compare_props['Stratified'] \/ compare_props[\"Overall\"] - 100\ncompare_props","d1c62898":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)","f7358aa0":"# Discover and visualize the data to gain insights","20632df3":"housing = strat_train_set.copy()","95a9fec8":"housing.plot(kind='scatter', x='longitude', y='latitude', alpha=0.1,\n            s=housing['population']\/100, label='population', figsize=(10, 7),\n            c='median_house_value', cmap=plt.get_cmap('jet'), colorbar=True)","f970a4da":"# Looking for Correlation\ncorr_matrix=housing.corr()\ncorr_matrix['median_house_value'].sort_values(ascending=False)","eca2e15b":"# Scatter matrix\nfrom pandas.plotting import scatter_matrix\n\nattributes = ['median_house_value', 'median_income', 'total_rooms', 'housing_median_age']\nscatter_matrix(housing[attributes], figsize=(12, 8))","eaf16768":"housing.plot(kind='scatter', x='median_income', y='median_house_value', alpha=0.1)","f15d891a":"# Data Cleaning","6d5364b8":"housing = strat_train_set.drop('median_house_value', axis=1)\nhousing_labels = strat_train_set['median_house_value'].copy()","3bd12c3a":"# Missing Data\nsample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\nsample_incomplete_rows","cc0f73ee":"housing_num = housing.drop('ocean_proximity', axis=1)\nhousing_cat = housing['ocean_proximity']","93164cf9":"from sklearn.base import BaseEstimator, TransformerMixin\n\nrooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 4, 6# number of columns\n\nclass CombineAttributeAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room=True):#no *args or **kargs\n        self.add_bedrooms_per_room=add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self # nothing else to do\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix]\/ X[:, households_ix]\n        population_per_household = X[:, population_ix] \/ X[:, households_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\n        \nattr_adder = CombineAttributeAdder(add_bedrooms_per_room=False)\nhousing_extra_attribs = attr_adder.transform(housing.values)","40b2661d":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('attribs_addr', CombineAttributeAdder(add_bedrooms_per_room=False)),\n    ('std_scaler', StandardScaler()),\n])\n\nnum_attribs = list(housing_num)\ncat_attribs = ['ocean_proximity']\n\nfull_pipeline = ColumnTransformer([\n    ('num', num_pipeline, num_attribs),\n    ('cat', OneHotEncoder(), cat_attribs)\n])\n\nhousing_prepared = full_pipeline.fit_transform(housing)","cc75e354":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\nforest_reg.fit(housing_prepared, housing_labels)","5b5e1caa":"housing_predictions = forest_reg.predict(housing_prepared)\nforest_mse = mean_squared_error(housing_labels, housing_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","0ff0ed19":"from sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","3ca442d9":"scores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\npd.Series(np.sqrt(-scores)).describe()","3df54d60":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\nparam_distribs = {\n        'n_estimators': randint(low=1, high=200),\n        'max_features': randint(low=1, high=8),\n    }\n\nforest_reg = RandomForestRegressor(random_state=42)\nrnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\nrnd_search.fit(housing_prepared, housing_labels)","6b19a7b1":"cvres = rnd_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","8f1ff2a3":"feature_importances = rnd_search.best_estimator_.feature_importances_\nfeature_importances","5969062e":"extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"] # old solution\ncat_encoder = full_pipeline.named_transformers_[\"cat\"]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = num_attribs + extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)","71523795":"final_model = rnd_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_predictions = final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","16c36295":"final_rmse","efa347c1":"# Select and Train a Model","82cbb8ea":"# Trnasformation Pipelines","1dfa5cc6":"# Fine Tune The Model"}}