{"cell_type":{"aa0a4f0d":"code","0c18b986":"code","4856ac71":"code","e18cd789":"code","fd05d954":"code","ecfd7879":"code","857ad417":"code","6c841b41":"code","7e96cc54":"code","21c8c9e0":"code","c6c7b987":"code","5620cb89":"code","f0a80b1c":"markdown","c6760971":"markdown","c2a5bb41":"markdown","e6fc1a12":"markdown","f8b10b52":"markdown","d1254a4c":"markdown"},"source":{"aa0a4f0d":"import matplotlib.pyplot as plt\n\ndef no_axis_show(img, title='', cmap=None):\n    # imshow, \u7e2e\u653e\u6a21\u5f0f\u70banearest\u3002\n    fig = plt.imshow(img, interpolation='nearest', cmap=cmap)\n    # \u4e0d\u8981\u986f\u793aaxis\u3002\n    fig.axes.get_xaxis().set_visible(False)\n    fig.axes.get_yaxis().set_visible(False)\n    plt.title(title)\n\ntitles = ['horse', 'bed', 'clock', 'apple', 'cat', 'television', 'dog', 'dolphin', 'spider']\nplt.figure(figsize=(18, 18))\nfor i in range(9):\n    plt.subplot(1, 10, i+1)\n    fig = no_axis_show(plt.imread(f'..\/input\/njunnhw2\/train_data\/train_data\/{i}\/{500*i}.bmp'), title=titles[i])\n","0c18b986":"plt.figure(figsize=(18, 18))\nfor i in range(10):\n    plt.subplot(1, 10, i+1)\n    fig = no_axis_show(plt.imread(f'..\/input\/njunnhw2\/0\/0\/' + str(i).rjust(5, '0') + '.bmp'))","4856ac71":"import numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Function\n\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader","e18cd789":"source_transform = transforms.Compose([\n    # \u8f49\u7070\u968e: Canny \u4e0d\u5403 RGB\u3002\n    transforms.Grayscale(),\n    # cv2 \u4e0d\u5403 skimage.Image\uff0c\u56e0\u6b64\u8f49\u6210np.array\u5f8c\u518d\u505acv2.Canny\n    transforms.Lambda(lambda x: cv2.Canny(np.array(x), 170, 300)),\n    # \u91cd\u65b0\u5c07np.array \u8f49\u56de skimage.Image\n    transforms.ToPILImage(),\n    # \u6c34\u5e73\u7ffb\u8f49 (Augmentation)\n    transforms.RandomHorizontalFlip(),\n    # \u65cb\u8f4915\u5ea6\u5167 (Augmentation)\uff0c\u65cb\u8f49\u5f8c\u7a7a\u7684\u5730\u65b9\u88dc0\n    transforms.RandomRotation(15, fill=(0,)),\n    # \u6700\u5f8c\u8f49\u6210Tensor\u4f9bmodel\u4f7f\u7528\u3002\n    transforms.ToTensor(),\n])\ntarget_transform = transforms.Compose([\n    # \u8f49\u7070\u968e: \u5c07\u8f38\u51653\u7dad\u58d3\u62101\u7dad\u3002\n    transforms.Grayscale(),\n    # \u7e2e\u653e: \u56e0\u70basource data\u662f32x32\uff0c\u6211\u5011\u5c07target data\u768428x28\u653e\u5927\u621032x32\u3002\n    transforms.Resize((32, 32)),\n    # \u6c34\u5e73\u7ffb\u8f49 (Augmentation)\n    transforms.RandomHorizontalFlip(),\n    # \u65cb\u8f4915\u5ea6\u5167 (Augmentation)\uff0c\u65cb\u8f49\u5f8c\u7a7a\u7684\u5730\u65b9\u88dc0\n    transforms.RandomRotation(15, fill=(0,)),\n    # \u6700\u5f8c\u8f49\u6210Tensor\u4f9bmodel\u4f7f\u7528\u3002\n    transforms.ToTensor(),\n])\n\nsource_dataset = ImageFolder('..\/input\/njunnhw2\/train_data\/train_data', transform=source_transform)\ntstsrc_dataset = ImageFolder('..\/input\/njunnhw2\/train_data\/train_data', transform=target_transform)\ntarget_dataset = ImageFolder('..\/input\/njunnhw2\/0', transform=target_transform)\n\nsource_dataloader = DataLoader(source_dataset, batch_size=32, shuffle=True)\ntstsrc_dataloader = DataLoader(source_dataset, batch_size=128,shuffle=True)\ntarget_dataloader = DataLoader(target_dataset, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(target_dataset, batch_size=128, shuffle=False)","fd05d954":"class FeatureExtractor(nn.Module):\n\n    def __init__(self):\n        super(FeatureExtractor, self).__init__()\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(64, 128, 3, 1, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(128, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(256, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(256, 512, 3, 1, 1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n    def forward(self, x):\n        x = self.conv(x).squeeze()\n        return x\n\nclass LabelPredictor(nn.Module):\n\n    def __init__(self):\n        super(LabelPredictor, self).__init__()\n\n        self.layer = nn.Sequential(\n            nn.Linear(512, 512),\n            nn.ReLU(),\n\n            nn.Linear(512, 512),\n            nn.ReLU(),\n\n            nn.Linear(512, 9),\n        )\n\n    def forward(self, h):\n        c = self.layer(h)\n        return c\n\nclass DomainClassifier(nn.Module):\n\n    def __init__(self):\n        super(DomainClassifier, self).__init__()\n\n        self.layer = nn.Sequential(\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n\n            nn.Linear(512, 1),\n        )\n\n    def forward(self, h):\n        y = self.layer(h)\n        return y","ecfd7879":"feature_extractor = FeatureExtractor().cuda()\nlabel_predictor = LabelPredictor().cuda()\ndomain_classifier = DomainClassifier().cuda()\n\nclass_criterion = nn.CrossEntropyLoss()\ndomain_criterion = nn.BCEWithLogitsLoss()\n\noptimizer_F = optim.Adam(feature_extractor.parameters())\noptimizer_C = optim.Adam(label_predictor.parameters())\noptimizer_D = optim.Adam(domain_classifier.parameters())","857ad417":"def train_epoch(source_dataloader, target_dataloader, lamb):\n    '''\n      Args:\n        source_dataloader: source data\u7684dataloader\n        target_dataloader: target data\u7684dataloader\n        lamb: \u8abf\u63a7adversarial\u7684loss\u4fc2\u6578\u3002\n    '''\n\n    # D loss: Domain Classifier\u7684loss\n    # F loss: Feature Extrator & Label Predictor\u7684loss\n    # total_hit: \u8a08\u7b97\u76ee\u524d\u5c0d\u4e86\u5e7e\u7b46 total_num: \u76ee\u524d\u7d93\u904e\u4e86\u5e7e\u7b46\n    running_D_loss, running_F_loss = 0.0, 0.0\n    total_hit, total_num = 0.0, 0.0\n\n    for i, ((source_data, source_label), (target_data, _)) in enumerate(zip(source_dataloader, target_dataloader)):\n\n        source_data = source_data.cuda()\n        source_label = source_label.cuda()\n        target_data = target_data.cuda()\n        \n        # \u6211\u5011\u628asource data\u548ctarget data\u6df7\u5728\u4e00\u8d77\uff0c\u5426\u5247batch_norm\u53ef\u80fd\u6703\u7b97\u932f (\u5169\u908a\u7684data\u7684mean\/var\u4e0d\u592a\u4e00\u6a23)\n        mixed_data = torch.cat([source_data, target_data], dim=0)\n        domain_label = torch.zeros([source_data.shape[0] + target_data.shape[0], 1]).cuda()\n        # \u8a2d\u5b9asource data\u7684label\u70ba1\n        domain_label[:source_data.shape[0]] = 1\n\n        # Step 1 : \u8a13\u7df4Domain Classifier\n        feature = feature_extractor(mixed_data)\n        # \u56e0\u70ba\u6211\u5011\u5728Step 1\u4e0d\u9700\u8981\u8a13\u7df4Feature Extractor\uff0c\u6240\u4ee5\u628afeature detach\u907f\u514dloss backprop\u4e0a\u53bb\u3002\n        domain_logits = domain_classifier(feature.detach())\n        loss = domain_criterion(domain_logits, domain_label)\n        running_D_loss+= loss.item()\n        loss.backward()\n        optimizer_D.step()\n\n        # Step 2 : \u8a13\u7df4Feature Extractor\u548cLabel Predictor\n        class_logits = label_predictor(feature[:source_data.shape[0]])\n        domain_logits = domain_classifier(feature)\n        # loss\u70ba\u539f\u672c\u7684class CE - lamb * domain BCE\uff0c\u76f8\u6e1b\u7684\u539f\u56e0\u540cGAN\u4e2d\u7684Discriminator\u4e2d\u7684G loss\u3002\n        loss = class_criterion(class_logits, source_label) - lamb * domain_criterion(domain_logits, domain_label)\n        running_F_loss+= loss.item()\n        loss.backward()\n        optimizer_F.step()\n        optimizer_C.step()\n\n        optimizer_D.zero_grad()\n        optimizer_F.zero_grad()\n        optimizer_C.zero_grad()\n\n        total_hit += torch.sum(torch.argmax(class_logits, dim=1) == source_label).item()\n        total_num += source_data.shape[0]\n        print(i, end='\\r')\n\n    return running_D_loss \/ (i+1), running_F_loss \/ (i+1), total_hit \/ total_num\n\n# \u8a13\u7df4100 epochs\nfor epoch in range(401):\n    train_D_loss, train_F_loss, train_acc = train_epoch(source_dataloader, target_dataloader, lamb=0.1)\n    if epoch % 10 == 0:\n        fe_name = \"fe\"+str(epoch)+\".pth\"\n        lp_name = \"lp\"+str(epoch)+\".pth\"\n        dc_name = \"dc\"+str(epoch)+\".pth\"\n        torch.save(feature_extractor.state_dict(), fe_name)\n        torch.save(label_predictor.state_dict(), lp_name)\n        torch.save(domain_classifier.state_dict(), dc_name)\n\n    print('epoch {:>3d}: train D loss: {:6.4f}, train F loss: {:6.4f}, acc {:6.4f}'.format(epoch, train_D_loss, train_F_loss, train_acc))","6c841b41":"\n!wget https:\/\/box.nju.edu.cn\/f\/778d174e2ce748658744\/?dl=1 -q -O lp400.pth\n!wget https:\/\/box.nju.edu.cn\/f\/2288da1583df4f33b641\/?dl=1 -q -O fe400.pth\n","7e96cc54":"state_dict1 = torch.load('lp400.pth')\nstate_dict2 = torch.load('fe400.pth')\nlabel_predictor.load_state_dict(state_dict1)\nfeature_extractor.load_state_dict(state_dict2)","21c8c9e0":"target_transform = transforms.Compose([\n    # \u8f49\u7070\u968e: \u5c07\u8f38\u51653\u7dad\u58d3\u62101\u7dad\u3002\n    transforms.Grayscale(),\n    # \u7e2e\u653e: \u56e0\u70basource data\u662f32x32\uff0c\u6211\u5011\u5c07target data\u768428x28\u653e\u5927\u621032x32\u3002\n    transforms.Resize((32, 32)),\n    # \u6700\u5f8c\u8f49\u6210Tensor\u4f9bmodel\u4f7f\u7528\u3002\n    transforms.ToTensor(),\n])\n\ntarget_dataset = ImageFolder('..\/input\/njunnhw2\/0', transform=target_transform)\ntest_dataloader = DataLoader(target_dataset, batch_size=128, shuffle=False)","c6c7b987":"result = []\nlabel_predictor.eval()\nfeature_extractor.eval()\nfor i, (test_data, _) in enumerate(test_dataloader):\n    test_data = test_data.cuda()\n\n    class_logits = label_predictor(feature_extractor(test_data))\n\n    x = torch.argmax(class_logits, dim=1).cpu().detach().numpy()\n    result.append(x)\n\nimport pandas as pd\nresult = np.concatenate(result)\n\n# Generate your submission\ndf = pd.DataFrame({'id': np.arange(0,len(result)), 'label': result})\ndf.to_csv('DaNN_submission.csv',index=False)","5620cb89":"import numpy as np\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n\nfeature_extractor.eval()\nfor i, ((source_data, source_label), (target_data, _)) in enumerate(zip(tstsrc_dataloader, test_dataloader)):\n    source_data = source_data.cuda()\n    target_data = target_data.cuda()\n    res1 = feature_extractor(source_data).detach().cpu()\n    res2 = feature_extractor(target_data).detach().cpu()\n    if i == 0:\n        x1 = res1\n        x2 = res2\n    elif i > 20:\n        break\n    else:\n        x1 = torch.cat((x1,res1))\n        x2 = torch.cat((x2,res2))\n\nX = torch.cat((x1, x2))\nout = TSNE(n_components=2).fit_transform(X)\np1 = out.T[0]\np2 = out.T[1]\nplt.figure(figsize=(10,10))\nplt.scatter(p1[:2560],p2[:2560])\nplt.scatter(p1[2560:],p2[2560:])\nplt.show()","f0a80b1c":"## Visulization","c6760971":"## Pre-process","c2a5bb41":"## Test","e6fc1a12":"# NN hw02 DANN","f8b10b52":"## Data introduce","d1254a4c":"## Training"}}