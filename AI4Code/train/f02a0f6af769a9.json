{"cell_type":{"675d68c3":"code","5e5ff36c":"code","4775831d":"code","bfac56e5":"code","c0070e59":"code","eefced8d":"code","a5b49fb8":"code","7592b2af":"code","1d4e3c89":"code","3d1f0eb9":"code","8dd5192a":"code","4d8aa238":"code","b2f9c4f1":"code","637f30b3":"code","ba136952":"code","4029d109":"code","3bd0ce4c":"code","1e8875c5":"code","4afa6ac8":"code","4d620130":"code","5ef570a9":"code","95a9d896":"code","51699d72":"code","f420cfa2":"code","00e0f4ef":"code","80a88d6d":"code","5e52a178":"code","aba22581":"code","4e5c75b6":"code","9d453ed7":"code","05b23b11":"code","0317ce5f":"code","bf56d9fd":"code","4f5ae9ad":"code","6500ddd7":"code","a674dac6":"code","441db62d":"code","b1975d6d":"code","b7e4354d":"code","7523aa1f":"code","5cdb4a9f":"code","f7e36c2e":"code","3bab0b38":"code","ab5926ef":"code","a5039310":"code","ba375bc1":"markdown","e9634c3c":"markdown","6f2b45a9":"markdown","a6bc95ea":"markdown","7fb5e9a3":"markdown","0a82585e":"markdown","66a0e84b":"markdown","08e73ae5":"markdown","1dc1a327":"markdown","75222bd5":"markdown","21b7db83":"markdown","cc46da6b":"markdown","6daa4cfb":"markdown","7659e1fe":"markdown","19c3e2fc":"markdown","413062e3":"markdown","5ac56a33":"markdown","1e879d19":"markdown","eacbfecb":"markdown","90c80f7d":"markdown","995d22f0":"markdown","589fa7a0":"markdown"},"source":{"675d68c3":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten,GlobalAveragePooling2D,BatchNormalization, Activation\nimport glob\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\n\n\nimport os\n\n# from tensorflow.compat.v1 import ConfigProto\n# from tensorflow.compat.v1 import InteractiveSession\n# config = ConfigProto()\n# config.gpu_options.allow_growth = True\n# session = InteractiveSession(config=config)\n","5e5ff36c":"from tensorflow.keras.mixed_precision import experimental as mixed_precision\npolicy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\nmixed_precision.set_policy(policy)","4775831d":"SEED = 42\nDEBUG = False\n\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","bfac56e5":"df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ndf.head()","c0070e59":"df['path'] = '..\/input\/cassava-leaf-disease-classification\/train_images\/' + df['image_id']\ndf.label.value_counts(normalize=True) * 100\n","eefced8d":"if DEBUG:\n    _, df = train_test_split(df, test_size = 0.1, random_state=SEED, shuffle=True, stratify=df['label'])\n","a5b49fb8":"X_train, X_valid = train_test_split(df, test_size = 0.1, random_state=SEED, shuffle=True)","7592b2af":"train_ds = tf.data.Dataset.from_tensor_slices((X_train.path.values, X_train.label.values))\nvalid_ds = tf.data.Dataset.from_tensor_slices((X_valid.path.values, X_valid.label.values))","1d4e3c89":"for path, label in train_ds.take(5):\n    print ('Path: {}, Label: {}'.format(path, label))","3d1f0eb9":"for path, label in valid_ds.take(5):\n    print ('Path: {}, Label: {}'.format(path, label))","8dd5192a":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntarget_size_dim = 512","4d8aa238":"def process_data_train(image_path, label):\n    # load the raw data from the file as a string\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.random_brightness(img, 0.3)\n    img = tf.image.random_flip_left_right(img, seed=None)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_crop(img, size=[target_size_dim, target_size_dim, 3])\n    return img, label\n\ndef process_data_valid(image_path, label):\n    # load the raw data from the file as a string\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [target_size_dim,target_size_dim])\n    return img, label\n","b2f9c4f1":"# Set `num_parallel_calls` so multiple images are loaded\/processed in parallel.\ntrain_ds = train_ds.map(process_data_train, num_parallel_calls=AUTOTUNE)\nvalid_ds = valid_ds.map(process_data_valid, num_parallel_calls=AUTOTUNE)","637f30b3":"for image, label in train_ds.take(1):\n    plt.imshow(image.numpy().astype('uint8'))\n    plt.show()\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","ba136952":"def configure_for_performance(ds, batch_size = 32):\n    ds = ds.cache('\/kaggle\/dump.tfcache') \n    \n    ds = ds.shuffle(buffer_size=1024)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\nbatch_size = 8\n\ntrain_ds_batch = configure_for_performance(train_ds, batch_size)\nvalid_ds_batch = valid_ds.batch(batch_size)","4029d109":"image_batch, label_batch = next(iter(train_ds_batch))","3bd0ce4c":"\nplt.figure(figsize=(10, 10))\nfor i in range(8):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n    label = label_batch[i].numpy()\n    plt.title(label)\n    plt.axis(\"off\")","1e8875c5":"data_augmentation = keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2, interpolation='nearest'),\n        tf.keras.layers.experimental.preprocessing.RandomContrast((0.2 ))\n    ]\n)","4afa6ac8":"\nplt.figure(figsize=(10, 10))\nfor i in range(8):\n    augmented_images = data_augmentation(image_batch)\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(augmented_images[i].numpy().astype(\"uint8\"))\n    label = label_batch[i].numpy()\n    plt.title(label)\n    plt.axis(\"off\")","4d620130":"## Only available in tf2.3+\n\nfrom tensorflow.keras.applications import EfficientNetB4\n","5ef570a9":"def load_pretrained_model(weights_path, drop_connect, target_size_dim, layers_to_unfreeze=5):\n    model = EfficientNetB4(\n            weights=None, \n            include_top=False, \n            drop_connect_rate=0.4\n        )\n    \n    model.load_weights(weights_path)\n    \n    model.trainable = True\n\n    # for layer in model.layers[-layers_to_unfreeze:]:\n    #     if not isinstance(layer, tf.keras.layers.BatchNormalization): \n    #         layer.trainable = True\n\n    if DEBUG:\n        for layer in model.layers:\n            #print(layer.name, layer.trainable)\n            pass\n\n    return model\n\ndef build_my_model(base_model, optimizer, loss='sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy']):\n    \n    inputs = tf.keras.layers.Input(shape=(target_size_dim, target_size_dim, 3))\n    x = data_augmentation(inputs)\n    outputs_eff = base_model(x)\n    global_avg_pooling = GlobalAveragePooling2D()(outputs_eff)\n    dense_1= Dense(256)(global_avg_pooling)\n    bn_1 = BatchNormalization()(dense_1)\n    activation = Activation('relu')(bn_1)\n    dropout = Dropout(0.3)(activation)\n    dense_2 = Dense(5)(dropout)\n    outputs = Activation('softmax', dtype='float32', name='predictions')(dense_2)\n\n    my_model = tf.keras.Model(inputs, outputs)\n    \n    my_model.compile(\n        optimizer=optimizer,\n        loss=loss,\n        metrics=metrics\n        \n    )\n    return my_model\n\n","95a9d896":"#!wget https:\/\/storage.googleapis.com\/keras-applications\/efficientnetb3_notop.h5\n## to get model weights","51699d72":"model_weights_path = '..\/input\/effnetb4-ns\/effnetb4_ns.h5'\nmodel_weights_path","f420cfa2":"drop_rate = 0.4 ## value of dropout to be used in loaded network\nbase_model = load_pretrained_model( model_weights_path, drop_rate, target_size_dim )\n\noptimizer = tf.keras.optimizers.Adam(lr = 1e-4)\nmy_model = build_my_model(base_model, optimizer)\nmy_model.summary()","00e0f4ef":"weight_path_save = 'best_model.hdf5'\nlast_weight_path = 'last_model.hdf5'\n\ncheckpoint = ModelCheckpoint(weight_path_save, \n                             monitor= 'val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode= 'min', \n                             save_weights_only = False)\ncheckpoint_last = ModelCheckpoint(last_weight_path, \n                             monitor= 'val_loss', \n                             verbose=1, \n                             save_best_only=False, \n                             mode= 'min', \n                             save_weights_only = False)\n\n\nearly = EarlyStopping(monitor= 'val_loss', \n                      mode= 'min', \n                      patience=5)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.00001)\ncallbacks_list = [checkpoint, checkpoint_last, early, reduceLROnPlat]","80a88d6d":"print('Compute dtype: %s' % policy.compute_dtype)\nprint('Variable dtype: %s' % policy.variable_dtype)","5e52a178":"if DEBUG:\n    epochs = 3\nelse:\n    epochs = 15\n    \nprint(f\"Model will train for {epochs} epochs\")","aba22581":"if DEBUG:\n    history = my_model.fit(train_ds_batch, \n                              validation_data = valid_ds_batch, \n                              epochs = epochs, \n                              callbacks = callbacks_list,\n                               steps_per_epoch = 1,\n                               \n                           \n                              )\nelse:\n    history = my_model.fit(train_ds_batch, \n                              validation_data = valid_ds_batch, \n                              epochs = epochs, \n                              callbacks = callbacks_list\n                               \n                            \n                              )","4e5c75b6":"\ndef plot_hist(hist):\n    plt.figure(figsize=(15,5))\n    local_epochs = len(hist.history[\"sparse_categorical_accuracy\"])\n    plt.plot(np.arange(local_epochs, step=1), hist.history[\"sparse_categorical_accuracy\"], '-o', label='Train Accuracy',color='#ff7f0e')\n    plt.plot(np.arange(local_epochs, step=1), hist.history[\"val_sparse_categorical_accuracy\"], '-o',label='Val Accuracy',color='#1f77b4')\n    plt.xlabel('Epoch',size=14)\n    plt.ylabel('Accuracy',size=14)\n    plt.legend(loc=2)\n    \n    plt2 = plt.gca().twinx()\n    plt2.plot(np.arange(local_epochs, step=1) ,history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n    plt2.plot(np.arange(local_epochs, step=1) ,history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n    plt.legend(loc=3)\n    plt.ylabel('Loss',size=14)\n    plt.title(\"Model Accuracy and loss\")\n    \n    plt.savefig('loss.png')\n    plt.show()","9d453ed7":"plot_hist(history)","05b23b11":"from sklearn.metrics import confusion_matrix, classification_report","0317ce5f":"my_model.load_weights(weight_path_save) ## load the best model or all your metrics would be on the last run not on the best one","bf56d9fd":"pred_valid_y = my_model.predict(valid_ds_batch, workers=4, verbose = True)\npred_valid_y_labels = np.argmax(pred_valid_y, axis=-1)","4f5ae9ad":"valid_labels = np.concatenate([y.numpy() for x, y in valid_ds_batch], axis=0)","6500ddd7":"\nprint(classification_report(valid_labels, pred_valid_y_labels ))","a674dac6":"print(confusion_matrix(valid_labels, pred_valid_y_labels ))","441db62d":"import glob","b1975d6d":"test_images = glob.glob('..\/input\/cassava-leaf-disease-classification\/test_images\/*.jpg')\n#test_images = test_images * 5\nprint(test_images)","b7e4354d":"df_test = pd.DataFrame(np.array(test_images), columns=['Path'])\ndf_test.head()","7523aa1f":"test_ds = tf.data.Dataset.from_tensor_slices((df_test.Path.values))\n\n\ndef process_test(image_path):\n    # load the raw data from the file as a string\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.random_brightness(img, 0.3)\n    img = tf.image.random_flip_left_right(img, seed=None)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_crop(img, size=[target_size_dim, target_size_dim, 3])\n    return img\n    \ntest_ds = test_ds.map(process_test, num_parallel_calls=AUTOTUNE).batch(batch_size*2)","5cdb4a9f":"preds = []\nfor i in range(5):\n    \n    pred_test = my_model.predict(test_ds, workers=16, verbose=1)\n    preds.append(pred_test)\n    ","f7e36c2e":"pred_y = np.mean(preds, axis=0)","3bab0b38":"#pred_y = my_model.predict(test_ds, workers=4)\npred_y_argmax = np.argmax(pred_y, axis=-1)","ab5926ef":"df_test['image_id'] = df_test.Path.str.split('\/').str[-1]\ndf_test['label'] = pred_y_argmax\ndf_test= df_test[['image_id','label']]\ndf_test.head()","a5039310":"df_test.to_csv('submission.csv', index=False)","ba375bc1":"Adding Seed helps to reproduce results. Setting Debug Parameter will run the model on smaller number of epochs to validate the architecture.","e9634c3c":"## Mixed Precision Training","6f2b45a9":"## Creating Model","a6bc95ea":"### Spliting Dataset","7fb5e9a3":"## Prepare Data","0a82585e":"## Evaluating Model on Validation Set","66a0e84b":"Distribution of dataset:","08e73ae5":"## Update: 15\/11\n\n* Using Mixed Precision Training\n* Storing data cache in \/kaggle folder as it has more memory available","1dc1a327":"My other Notebooks in this competition:\n\n1. EfficientNetB3 Training with Pure Keras\/tf2 ImageDataGenerator Method: [Link](https:\/\/www.kaggle.com\/harveenchadha\/efficientnetb3-keras-tf2-baseline-training)\n2. EfficientNetB3 Inference with Pure Keras\/tf2 ImageDataGenerator Method: [Link](https:\/\/www.kaggle.com\/harveenchadha\/efficientnetb3-baseline-inference-keras-tf2)","75222bd5":"## Update: 24\/11\n\n* Using TTA * 15\n\n## Update: 24\/11\n\n* Using EfficientNetB4\n* Using TTA * 5","21b7db83":"![dia%20%281%29.png](attachment:dia%20%281%29.png)","cc46da6b":"### Improving Performance","6daa4cfb":"## Train Model","7659e1fe":"In this kernel I would use tf.data plus Keras to build a baseline, this type of baseline can be helpful to you in solving similar problems as well.","19c3e2fc":"### Data Generator","413062e3":"### Callbacks","5ac56a33":"## Data Loader using tf.Data","1e879d19":"\n\n### If you learnt something from this kernel kindly upvote :) This keeps me motivated to produce more kernels.","eacbfecb":"## Important Points:\n\n1. ~~Due to Kaggle's space and RAM limitation, I could not make use of cache~~\n2. ~~With the use of Cache, I can confirm I have achieved a 5x speed than ImageDataGenerator. Maybe I will do a kernel will small subset of the data confirming the same.~~\n\nI am using cache now!","90c80f7d":"## Predictions + Test Time Augmentation","995d22f0":"## Update: 14\/11\n\n* I was shuffling the validation dataset too, hence that was a bug. \n* Trying out NS.","589fa7a0":"## Data Augmentation"}}