{"cell_type":{"8674979a":"code","aa00ace3":"code","2a36b12b":"code","3f9907ad":"code","28da630b":"code","1491e189":"code","43274bd0":"code","bd19bd89":"code","3e93a27d":"code","7caf5f69":"code","40365c7e":"code","a25b5d7e":"code","6940a852":"code","d6f48974":"code","2c5f8ff5":"code","b6a67369":"code","6a49b295":"code","0b3b8eef":"code","16064230":"code","a260a760":"code","64fc63ed":"code","c72f5243":"code","02645a86":"code","82e83c56":"code","4ccdcde4":"code","97614166":"code","01a4ef80":"markdown","9d47e2ef":"markdown","4eeffae6":"markdown","40f39066":"markdown","4323945b":"markdown","44127d2e":"markdown","96880367":"markdown","402b473e":"markdown","50271552":"markdown","933d1859":"markdown","c4124210":"markdown","0ee3e1cf":"markdown","de90e2b2":"markdown","04a78884":"markdown","b5d6bb6f":"markdown"},"source":{"8674979a":"# suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","aa00ace3":"import pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.optimize import curve_fit\nimport os","2a36b12b":"# prettify plots\nsns.set_palette(sns.color_palette(\"muted\"))\nsns.set_style(\"ticks\")\n\n\n# prettify plots\nplt.rcParams['figure.figsize'] = [20.0, 5.0]","3f9907ad":"%%time\ndf_train = pd.read_csv(\"..\/input\/liverpool-ion-switching\/train.csv\")\ndf_test  = pd.read_csv(\"..\/input\/liverpool-ion-switching\/test.csv\")","28da630b":"training_batch_size = 500_000\ntraining_batch_range = [\n    [0, 500000],\n    [500000, 1000000],\n    [1000000, 1500000],\n    [1500000, 2000000],\n    [2000000, 2500000],\n    [2500000, 3000000],\n    [3000000, 3500000],\n    [3500000, 4000000],\n    [4000000, 4500000],\n    [4500000, 5000000]\n]\n\ntest_batch_size = 100_000\ntest_batch_range = [\n    [0, 100000],\n    [100000, 200000],\n    [200000, 300000],\n    [300000, 400000],\n    [400000, 500000],\n    [500000, 600000],\n    [600000, 700000],\n    [700000, 800000],\n    [800000, 900000],\n    [900000, 1000000],\n    [1000000, 1500000], # 11th batch (500_000)\n    [1500000, 2000000]  # 12th batches (500_000)\n]\n\ndef make_batches(df, batch_range):\n    batches = []\n    for start_batch, end_batch in batch_range:\n        print(f\"[start_batch: {start_batch}, end_batch: {end_batch}],\")\n        batches.append(df[start_batch: end_batch])\n        \n    return batches","1491e189":"df_train_batched = make_batches(df_train, training_batch_range)","43274bd0":"df_test_batched = make_batches(df_test, test_batch_range)","bd19bd89":"def plot_all(name, dataset, sublplot_index, start, end, increment):\n    plt.figure(figsize=(25, 5))\n    plt.subplot(sublplot_index)\n    plt.title(name)\n    plt.ylabel(\"Signal\")\n    plt.xticks(np.arange(start, end, increment))\n    for x in dataset:\n        plt.plot(x['time'], x['signal'], linewidth=.1)\n    plt.grid()\n\nplot_all(\"Train Original\",df_train_batched, 211, 0, 501, 50)\nplot_all(\"Test Original\", df_test_batched, 212, 500, 701, 10)","3e93a27d":"# ---- Linear drift \n\nlinear_train_idx = [1]\nlinear_test_idx = [0, 1, 4, 6, 7, 8]\n\n\ndef poly1(x, a, b):\n    return a * (x - b)\n\n\ndef linear_drift_fit(x, y):\n    popt, _ = curve_fit(poly1, x, y)\n    print(\"Linear drift, popt:\", popt)\n    return popt\n\n\ndef linear_drift(x, x0):\n    return 0.3 * (x - x0)\n\n\ndef my_sin(x, A, ph, d):\n    frequency = 0.01\n    omega = 2 * np.pi * frequency\n    return A * np.sin(omega * x + ph) + d\n\n\ndef remove_linear_drift(linear_idx, data, time_column_name, signal_column_name, batch_start, batch_end):\n    for idx in linear_idx:\n        data[idx].loc[data[idx].index[batch_start: batch_end], signal_column_name] = \\\n            data[idx][signal_column_name][batch_start: batch_end].values - linear_drift(\n            data[idx][time_column_name][batch_start: batch_end].values, data[idx][time_column_name][0:1].values)\n\n    return data","7caf5f69":"plt.figure(figsize=(30, 4))\nplt.subplot(\"171\")\nplt.title(\"Train 1 (part)\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.plot(df_train_batched[1]['time'][0:100000], df_train_batched[1]['signal'][0:100000], linewidth=.1)\nplt.grid()\nplt.ylim([np.min(df_train_batched[1]['signal'][0:100000]), np.min(df_train_batched[1]['signal'][0:100000]) + 15])\nfor n, idx in enumerate(linear_test_idx):\n    plt.subplot(\"17\" + str(n + 2))\n    plt.title(\"Test \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.ylim([np.min(df_test_batched[idx]['signal']), np.min(df_test_batched[idx]['signal']) + 15])\n    plt.plot(df_test_batched[idx]['time'], df_test_batched[idx]['signal'], linewidth=.1)\n    plt.grid()","40365c7e":"linear_params = []\ntrain_data = df_test_batched[linear_train_idx[0]][0:100000]\nlinear_params.append(linear_drift_fit(train_data['time'], train_data['signal']))\nfor idx in linear_test_idx:\n    linear_params.append(linear_drift_fit(df_test_batched[idx]['time'], df_test_batched[idx]['signal']))","a25b5d7e":"plt.figure(figsize=(30, 4))\nplt.subplot(\"171\")\nplt.title(\"Train 1 (part)\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.plot(df_train_batched[1]['time'][0:100000], df_train_batched[1]['signal'][0:100000], linewidth=.1)\nplt.plot(df_train_batched[1]['time'][0:100000], poly1(df_train_batched[1]['time'][0:100000], *linear_params[0]), 'y')\nplt.grid()\nplt.ylim([np.min(df_train_batched[1]['signal'][0:100000]), np.min(df_train_batched[1]['signal'][0:100000]) + 15])\nfor n, idx in enumerate(linear_test_idx):\n    plt.subplot(\"17\" + str(n + 2))\n    plt.title(\"Test \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.ylim([np.min(df_test_batched[idx]['signal']), np.min(df_test_batched[idx]['signal']) + 15])\n    plt.plot(df_test_batched[idx]['time'], df_test_batched[idx]['signal'], linewidth=.1)\n    plt.plot(df_test_batched[idx]['time'], poly1(df_test_batched[idx]['time'], *linear_params[1 + n]), 'y')\n    plt.grid()","6940a852":"df_train_linear_drift_removed = remove_linear_drift([1], df_train_batched, 'time', 'signal', 0, test_batch_size)\ndf_test_linear_drift_removed = remove_linear_drift(linear_test_idx, df_test_batched, 'time', 'signal', 0, test_batch_size)","d6f48974":"plot_all(\"Train - Linear Drift Removed\", df_train_linear_drift_removed, \"211\", 0, 501, 50)\nplot_all(\"Test - Linear Drift Removed\", df_test_linear_drift_removed, \"212\", 500, 701, 10)","2c5f8ff5":"# --- Parabolic drift\n\nparabola_train_idx = [6, 7, 8, 9]\nparabola_train_time = [0, 1, 0, 1]\nparabola_test_idx = [10]\n\ndef parabolic_drift_fit(x, y):\n    frequency = 0.01\n    omega = 2 * np.pi * frequency\n    M = np.array([[np.sin(omega * t), np.cos(omega * t), 1] for t in x])\n    y = np.array(y).reshape(len(y), 1)\n\n    (theta, _, _, _) = np.linalg.lstsq(M, y)\n\n    A = np.sqrt(theta[0, 0] ** 2 + theta[1, 0] ** 2)\n    ph = math.atan2(theta[1, 0], theta[0, 0])\n    d = theta[2, 0]\n\n    popt = [A, ph, d]\n    print(\"Parabolic drift, popt\", popt)\n    return popt\n\n\ndef parabolic_drift(x, t=0):\n    f = 0.01\n    omega = 2 * np.pi * f\n    return 5 * np.sin(omega * x + t * np.pi)\n\n\ndef remove_parabolic_drift(parabola_idx, parabola_time, data, time_column_name, signal_column_name, batch_start, batch_end):\n    for idx, ctr in zip(parabola_idx, range(len(parabola_idx))):\n        target_index = data[idx].index[batch_start:batch_end]\n        target_values = data[idx][time_column_name][batch_start:batch_end].values\n        data[idx].loc[target_index, signal_column_name] = \\\n            data[idx][signal_column_name][batch_start:batch_end].values - \\\n            parabolic_drift(target_values, parabola_time[ctr])\n\n    return data","b6a67369":"def plot_parabolic_drift(dataframe, name, subplot, parabola_indices):\n    for n, idx in enumerate(parabola_indices):\n        plt.subplot(str(subplot + n + 1))\n        plt.title(name.strip() + \" \" + str(idx))\n        plt.ylabel(\"Signal\", fontsize=8)\n        plt.plot(dataframe[idx]['time'], dataframe[idx]['signal'], linewidth=.1)\n        plt.grid()\n        plt.ylim([np.min(dataframe[idx]['signal']), np.min(dataframe[idx]['signal']) + 18])\n\nplt.figure(figsize=(30, 4))\nplot_parabolic_drift(df_train_linear_drift_removed, \"Train\", 150, parabola_train_idx)\nplot_parabolic_drift(df_test_linear_drift_removed, \"Test\", 154, parabola_test_idx)","6a49b295":"parabola_params = []\nfor idx in parabola_train_idx:\n    data = df_train_linear_drift_removed[idx]\n    parabola_params.append(parabolic_drift_fit(data['time'], data['signal']))\ndata = df_test_linear_drift_removed[parabola_test_idx[0]]\nparabola_params.append(parabolic_drift_fit(data['time'], data['signal']))","0b3b8eef":"plt.figure(figsize=(30, 4))\nfor n, idx in enumerate(parabola_train_idx):\n    plt.subplot(\"15\" + str(n + 1))\n    plt.title(\"Train \" + str(idx))\n    plt.ylabel(\"Signal\", fontsize=8)\n    plt.plot(df_train_linear_drift_removed[idx]['time'], df_train_linear_drift_removed[idx]['signal'], linewidth=.1)\n    plt.plot(df_train_linear_drift_removed[idx]['time'], my_sin(df_train_linear_drift_removed[idx]['time'], *parabola_params[n]), 'y')\n    plt.grid()\n    plt.ylim([np.min(df_train_linear_drift_removed[idx]['signal']), np.min(df_train_linear_drift_removed[idx]['signal']) + 18])\nplt.subplot(\"155\")\nplt.title(\"Test 10\")\nplt.ylabel(\"Signal\", fontsize=8)\nplt.ylim([np.min(df_test_linear_drift_removed[10]['signal']), np.min(df_test_linear_drift_removed[10]['signal']) + 18])\nplt.plot(df_test_linear_drift_removed[10]['time'], df_test_linear_drift_removed[10]['signal'], linewidth=.1)\nplt.plot(df_test_linear_drift_removed[10]['time'], my_sin(df_test_linear_drift_removed[10]['time'], *parabola_params[-1]), 'y')\nplt.grid()","16064230":"df_train_parabolic_drift_removed = remove_parabolic_drift(parabola_train_idx, parabola_train_time, df_train_linear_drift_removed, 'time', 'signal', 0, training_batch_size)\ndf_test_parabolic_drift_removed = remove_parabolic_drift([10], [0], df_test_linear_drift_removed, 'time', 'signal', 0, training_batch_size)","a260a760":"plot_all(\"Train - Without Drift (linear or parabolic)\", df_train_parabolic_drift_removed, \"211\", 0, 501, 50)\nplot_all(\"Test - Without Drift (linear or parabolic)\", df_test_parabolic_drift_removed, \"212\", 500, 701, 10)","64fc63ed":"def plot_dist(data, labels, m):\n    plt.title(\"Signal Distribution Model \" + str(m))\n    for i, x in enumerate(data):\n        x = x['signal']\n        sns.distplot(x, label=labels[i], kde=True, bins=np.arange(np.min(x), np.max(x), 0.01))\n#         sns.distplot(x, label=labels[i], kde=True)\n    plt.xlabel(\"signal value\")\n    plt.ylabel(\"frequency\")\n    plt.legend(loc=\"best\")    \n    \n\nM = [[df_train_parabolic_drift_removed[0], df_train_parabolic_drift_removed[1], df_test_parabolic_drift_removed[0], df_test_parabolic_drift_removed[3], df_test_parabolic_drift_removed[8], df_test_parabolic_drift_removed[10], df_test_parabolic_drift_removed[11]],\n     [df_train_parabolic_drift_removed[2], df_train_parabolic_drift_removed[6], df_test_parabolic_drift_removed[4]],\n     [df_train_parabolic_drift_removed[3], df_train_parabolic_drift_removed[7], df_test_parabolic_drift_removed[1], df_test_parabolic_drift_removed[9]],\n     [df_train_parabolic_drift_removed[4], df_train_parabolic_drift_removed[9], df_test_parabolic_drift_removed[5], df_test_parabolic_drift_removed[7]],\n     [df_train_parabolic_drift_removed[5], df_train_parabolic_drift_removed[8], df_test_parabolic_drift_removed[2], df_test_parabolic_drift_removed[6]]]\nlabels = [[\"train 0\", \"train 1 (line)\", \"test 0 (line)\", \"test 3\", \"test 8 (line)\", \"test 10 (sine)\", \"test 11\"],\n          [\"train 2\", \"train 6 (sine)\", \"test 4 (line)\"],\n          [\"train 3\", \"train 7 (sine)\", \"test 1 (line)\", \"test 9\"],\n          [\"train 4\", \"train 9 (sine)\", \"test 5\", \"test 7 (line)\"],\n          [\"train 5\", \"train 8 (sine)\", \"test 2\", \"test 6 (line)\"]]\n\nplt.figure(figsize=(25, 8))\nfor i in range(5):\n    plt.subplot(\"15\" + str(i + 1))\n    plot_dist(M[i], labels[i], i)","c72f5243":"def save_dataframe(dataframe: pd.DataFrame,\n                   filename_with_path: str,\n                   force_overwrite=False):\n    print(\"Shape:\", dataframe.shape)\n    print(\"Contents:\\n\", dataframe)\n    print()\n    print(f'force_overwrite = {force_overwrite}')\n    if force_overwrite or (not os.path.exists(filename_with_path)):\n        print(f\"Saving dataframe to {filename_with_path}.\")\n        dataframe.to_csv(filename_with_path, index=False, float_format='%.9f',\n                                       chunksize=100000, compression='gzip', encoding='utf-8')\n    else:\n        print(f\"{filename_with_path} already exists, not overwriting. Remove it and try again.\")\n\n\ndf_train_clean = df_train_parabolic_drift_removed[0]\ndf_test_clean = df_test_parabolic_drift_removed[0]\nfor df in df_train_parabolic_drift_removed[1:]:\n    df_train_clean = pd.concat([df_train_clean, df], ignore_index=True)\nfor df in df_test_parabolic_drift_removed[1:]:\n    df_test_clean = pd.concat([df_test_clean, df], ignore_index=True)","02645a86":"df_train_clean","82e83c56":"df_test_clean","4ccdcde4":"save_dataframe(df_train_clean, \"train_wo_drift_sine.csv.gz\")","97614166":"save_dataframe(df_test_clean, \"test_wo_drift_sine.csv.gz\")","01a4ef80":"The optimum A is 5 for all batches and the optimum phase is 0 or \\\\(\\pi\\\\) \n\n$$\n\\begin{align}\nA_{opt} &= 5 \\\\\n\\varphi_{opt} &= \n\\begin{cases}\n0 & \\text{ if train 6, train 8, test 10} \\\\ \n\\pi & \\text{ if train 7, train 9} \n\\end{cases}\n\\end{align}\n$$\n\nLet's remove this drift.","9d47e2ef":"# Save data\n\nI uploaded this data to [here][1]\n\n[1]:https:\/\/www.kaggle.com\/eunholee\/iondatawithoutdrift","4eeffae6":"### Parabolic drift (code)","40f39066":"# Introduction\n\nIn this notebook, I'll share my approach to finding synthetic drift function. It is no secret that the drift has been artificially added. In this competition's paper [here][1], you can find the description of the data like below:\n> *\"In some datasets additional drift was applied to the final data with MATLAB\"*\n\nThere's an excellent explanation for the drift. Please check Chris' explanation: [What is Drift?][2] \n\n\n\n[1]:https:\/\/www.nature.com\/articles\/s42003-019-0729-3\n[2]:https:\/\/www.kaggle.com\/c\/liverpool-ion-switching\/discussion\/133874\n[3]:https:\/\/www.kaggle.com\/friedchips\/clean-removal-of-data-drift","4323945b":"## Full credits to the author [Eun Ho Lee](https:\/\/www.kaggle.com\/eunholee) of the [original notebook](https:\/\/www.kaggle.com\/eunholee\/remove-drift-using-a-sine-function).\n\n#### I have just reorganised and refactored the code for my curiosity and learnings. Added console logs, and re-wrote datastructure to understand how the splits and batching is occuring\n\n### Find other such refactored notebooks [here](https:\/\/www.kaggle.com\/c\/liverpool-ion-switching\/discussion\/153653).","44127d2e":"It is ~~almost certain~~ that all data have the same slope => **0.3**. Let's remove it.","96880367":"## Batching","402b473e":"# How to fit a sine function\n\n$$\n\\hat{y} = A \\sin (\\omega x + \\varphi) + \\delta\n$$\n\nBecause each batch has the same length (50s), omega should be \\\\( \\omega = \\frac{2\\pi}{50 \\times 2} \\\\).\nBut it's not easy to find \\\\(A\\\\) and \\\\(\\varphi\\\\) with this form. \n\nLet's apply harmonic addition to the equation above.\n\n$$\n\\begin{align}\n\\hat{y} &= A \\sin (\\omega x + \\varphi) + \\delta \\\\\n&= A \\sin (\\omega x) \\cos (\\varphi) + A \\cos (\\omega x) \\sin (\\varphi) + \\delta \\\\\n&= A \\cos (\\varphi) \\sin (\\omega x) + A \\sin (\\varphi) \\cos (\\omega x) + \\delta \n\\end{align}\n$$\n\nNow we can represent it as a linear system.\n\n$$\n\\begin{bmatrix}\n\\sin(\\omega x_1) & \\cos(\\omega x_1) & 1 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\sin(\\omega x_N) & \\cos(\\omega x_N) & 1\n\\end{bmatrix}\n\\begin{bmatrix}\nA\\cos(\\varphi) \\\\\nA\\sin(\\varphi) \\\\\n\\delta\n\\end{bmatrix} = \n\\begin{bmatrix}\ny_1 \\\\ \\vdots \\\\ y_N\n\\end{bmatrix}\n$$\n\nwhere \\\\(\\mathbf{x} = (x_1, \\cdots, x_N) \\\\) is  ```df['time']``` and \\\\(\\mathbf{y} = (y_1, \\cdots, y_N) \\\\) is ```df['signal']``` with \\\\(N=500000 \\\\)\n\nor simply,\n$$\n\\mathbf{M}\\mathbf{\\theta} = \\mathbf{y}\n$$\n\n\nWe can find \\\\(\\mathbf{\\theta} \\\\) that minimizes the squared Euclidean 2-norm.\nThen, we can find our target parameters \\\\( A \\\\) and \\\\( \\varphi \\\\) from \\\\( \\mathbf{\\theta} = (\\theta_1, \\theta_2, \\theta_3) \\\\)\n\n$$\nA = \\sqrt{\\theta_1^2 + \\theta_2^2} \\\\\n\\varphi = \\arctan(\\frac{\\theta_2}{\\theta_1})\n$$","50271552":"The below datastrutures give a better idea of how the splits happened across the training and test data-frames. Easy to visualise when we can see the range of values. The `make_batches()` is also easier to read and change.","933d1859":"# Two types of drift\n\nAs you can see in the blow, there are two types of drift in our dataset, linear and parabolic drift.","c4124210":"# Parabolic drift\n\nThis kind of drift has more candidates. It could be a polynomial, a trigonometric, or something else. In this notebook, I'll assume it as a **sine function.**\n","0ee3e1cf":"# Linear drift\n\n~~It's easy to~~ figure out what linear drift function looks like.\n\n(**Update:** It turns out it's not easy...! Linear drift is not actually linear. Check here[1]. )\n\n[1]:https:\/\/www.kaggle.com\/c\/liverpool-ion-switching\/discussion\/137537","de90e2b2":"### Linear drift (code)","04a78884":"+) I'm not a native English speaker. Please let me know if there's a wrong sentence or anything you don't understand.","b5d6bb6f":"# Comparison of distributions\n\nLet's see if the distribution of a clean version matches the distribution of existing data in the same model."}}