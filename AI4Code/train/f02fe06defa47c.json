{"cell_type":{"6b4b25bf":"code","ebaacbd4":"code","5972bcc1":"code","9090e4c6":"code","74855a97":"code","ca491a5f":"code","d81ae0ff":"code","536f2d55":"code","8d285c3c":"code","b3387fd1":"code","a0205398":"code","b4afd21b":"code","0951af9c":"code","34f48ea0":"code","b0fc0cb0":"code","c1855720":"code","d129f095":"code","81ff0b46":"code","7893c2a2":"code","315ce59e":"code","992a584d":"code","6529eafc":"code","381d445c":"code","b89b7fd2":"code","f16fe835":"code","5a636aea":"code","6ec76291":"code","b1877f1c":"code","5c4ab80e":"code","63c18814":"code","3de20063":"code","aee03db4":"code","012fd049":"code","c02f1a01":"code","44c55d9a":"code","59551488":"markdown","dee44c12":"markdown","c575eff5":"markdown","43bbefb9":"markdown","3470a8a0":"markdown"},"source":{"6b4b25bf":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sns\nimport re\n\nrcParams['figure.figsize'] = 15, 20","ebaacbd4":"df = pd.read_csv('..\/input\/marvel-comic-books\/Marvel_Comics.csv')","5972bcc1":"df.head()","9090e4c6":"# Create new column from year of publish date\ndf['year'] = df['publish_date'].apply(lambda x: str(x)[-4:])","74855a97":"df.info()","ca491a5f":"df.isnull().sum()","d81ae0ff":"columns = ['active_years','penciler','writer','cover_artist','Format','Rating','Price','Imprint']\nfor i,column in enumerate(columns):\n    plt.subplot(len(columns), 2, i+1)\n    plt.suptitle(\"Top 10 Values\")\n    sns.countplot(data=df, y=column, order=df[column].value_counts().iloc[:10].index)\n    plt.title(f\"{column}\")\n    plt.tight_layout()","536f2d55":"# Without 'None' Value\nfor i,column in enumerate(columns):\n    plt.subplot(len(columns), 2, i+1)\n    plt.suptitle(\"Top 10 Without 'None' Value\")\n    sns.countplot(data=df, y=column, order=df[~(df[column]=='None')][column].value_counts().iloc[:10].index)\n    plt.title(f\"{column}\")\n    plt.tight_layout()","8d285c3c":"# TOP 1 Writer Activity\ntop1writer = df[~(df['writer']=='None')]['writer'].value_counts().iloc[:1].index[0]\nplt.figure(figsize=(10,5))\ndf[df['writer']==top1writer].groupby('year')['writer'].count().plot()\nplt.title(f\"{top1writer} Activities in Every Year\")\nplt.ylabel(\"Count Activity\")\nplt.show()","b3387fd1":"# TOP 1 Penciler Activity\ntop1penciler = df[~(df['penciler']=='None')]['penciler'].value_counts().iloc[:1].index[0]\nplt.figure(figsize=(10,5))\ndf[df['penciler']==top1penciler].groupby('year')['penciler'].count().plot()\nplt.title(f\"{top1penciler} Activities in Every Year\")\nplt.ylabel(\"Count Activity\")\nplt.show()","a0205398":"# TOP 1 Cover Artist Activity\ntop1coverartist = df[~(df['cover_artist']=='None')]['cover_artist'].value_counts().iloc[:1].index[0]\nplt.figure(figsize=(10,5))\ndf[df['cover_artist']==top1penciler].groupby('year')['cover_artist'].count().plot()\nplt.title(f\"{top1coverartist} Activities in Every Year\")\nplt.ylabel(\"Count Activity\")\nplt.show()","b4afd21b":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel","0951af9c":"df['issue_description'] = df['issue_description'].apply(lambda x: str.lower(x))","34f48ea0":"tfidf = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf.fit_transform(df['issue_description'])","b0fc0cb0":"cosine_sim = linear_kernel(tfidf_matrix,tfidf_matrix)","c1855720":"indices = pd.Series(df.index, index=df['comic_name']).drop_duplicates()","d129f095":"indices[:10]","81ff0b46":"# Function that takes in comic title as input and outputs most similar comic\ndef get_recommendations(title, ind=indices ,cosine_sim=cosine_sim):\n    idx = ind[title][0]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    comic_indices = [i[0] for i in sim_scores]\n    return df['comic_name'].iloc[comic_indices]","7893c2a2":"comic = df['comic_name'].sample(1).values[0]\ncomic","315ce59e":"get_recommendations(comic)","992a584d":"df.columns","6529eafc":"# Because Memory Reach The Limit, I'll just take some data\ndf_limit = df.sample(20000).reset_index(drop=True)","381d445c":"df_limit","b89b7fd2":"AttrCols = ['penciler','writer','cover_artist','Imprint','Format','Rating','Price']","f16fe835":"def clean_data(x):\n    x = str.lower(x.replace(\" \", \"\"))\n    x = re.sub(\"none\", '', x)\n    x = re.sub(\",\", ' ', x)\n    return x","5a636aea":"for AttrCol in AttrCols:\n    df_limit[AttrCol] = df_limit[AttrCol].apply(clean_data)","6ec76291":"def create_soup(x):\n    return x['penciler'] + ' ' + x['writer'] + ' ' + x['cover_artist'] + ' ' + x['Imprint'] + ' ' + x['Format'] + ' ' + x['Rating'] + ' ' + x['Price']","b1877f1c":"df_limit['Soup'] = df_limit.apply(create_soup, axis=1)","5c4ab80e":"df_limit['Soup']","63c18814":"def rem_double_space(x):\n    return re.sub(' +', ' ',x)\n\ndf_limit['Soup'] = df_limit['Soup'].apply(rem_double_space)","3de20063":"from sklearn.feature_extraction.text import CountVectorizer\n\ncount = CountVectorizer(stop_words='english')\ncount_matrix = count.fit_transform(df_limit['Soup'])","aee03db4":"cosine_sim2 = linear_kernel(count_matrix,count_matrix)","012fd049":"indices2 = pd.Series(df_limit.index, index=df_limit['comic_name']).drop_duplicates()","c02f1a01":"comic2 = df_limit['comic_name'].sample(1).values[0]\ncomic2","44c55d9a":"get_recommendations(comic2,ind=indices2, cosine_sim=cosine_sim2)","59551488":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Recommendation System Base On Comic Atrribute <\/center><\/h1> ","dee44c12":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Load Data <\/center><\/h1> ","c575eff5":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Recommendation System Base On Description <\/center><\/h1> ","43bbefb9":"<h1 style='background:#CCE2CB; border:0; color:black'><center> Importing Libraries <\/center><\/h1> ","3470a8a0":"<h1 style='background:#CCE2CB; border:0; color:black'><center> EDA <\/center><\/h1> "}}