{"cell_type":{"ff04c733":"code","ae8353f7":"code","a7378e3e":"code","99d5095f":"code","a04a838c":"code","719e4d4c":"code","dd186749":"code","7cb7774d":"code","72c97eb8":"code","d014e331":"code","4ad3ace5":"code","fe6c1ab0":"code","1c112089":"code","11c41bd2":"markdown","055dc8c2":"markdown","61f59ecc":"markdown"},"source":{"ff04c733":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ae8353f7":"data = pd.read_csv('\/kaggle\/input\/personal-loan\/Bank_Personal_Loan_Modelling-1.xlsx')","a7378e3e":"data.info()","99d5095f":"data.head(2)","a04a838c":"X = data.drop(['Personal Loan'], axis = 1)\ny = data['Personal Loan']","719e4d4c":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) \n#Random_state = 42 is to be tried later","dd186749":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n\ndef clf_scores(clf, y_predicted):\n    # Accuracy\n    acc_train = clf.score(X_train, y_train)*100\n    acc_test = clf.score(X_test, y_test)*100\n    \n    roc = roc_auc_score(y_test, y_predicted)*100 \n    tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n    cm = confusion_matrix(y_test, y_predicted)\n    correct = tp + tn\n    incorrect = fp + fn\n    \n    return acc_train, acc_test, roc, correct, incorrect, cm","7cb7774d":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression()\nclf_lr.fit(X_train, y_train)\n\nY_pred_lr = clf_lr.predict(X_test)\nprint(clf_scores(clf_lr, Y_pred_lr))\n\n# without random state - (90.97142857142858, 90.4, 62.7838637454022), 1350","72c97eb8":"#2. KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=3)\nclf_knn.fit(X_train, y_train)\n\nY_pred_knn = clf_knn.predict(X_test)\nprint(clf_scores(clf_knn, Y_pred_knn))\n#1348","d014e331":"#3. Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\nclf_gnb = GaussianNB()\nclf_gnb.fit(X_train, y_train)\n\nY_pred_gnb = clf_gnb.predict(X_test)\nprint(clf_scores(clf_gnb, Y_pred_gnb))\n","4ad3ace5":"#4. Decision tree\nfrom sklearn.tree import DecisionTreeClassifier\n\nclf_dt = DecisionTreeClassifier(random_state=0)\nclf_dt.fit(X_train, y_train)\nclf_dt.fit(X_train, y_train)\n\nY_pred_dt = clf_dt.predict(X_test)\nprint(clf_scores(clf_dt, Y_pred_dt))","fe6c1ab0":"#5. Radom forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf_rfc = RandomForestClassifier(max_depth=10, random_state=42)\nclf_rfc.fit(X_train, y_train)\n\nY_pred_rfc = clf_rfc.predict(X_test)\nprint(clf_scores(clf_rfc, Y_pred_rfc))\n","1c112089":"#6. Gradient boosting classifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nclf_gbc = GradientBoostingClassifier(random_state=42)\nclf_gbc.fit(X_train, y_train)\n\nY_pred_gbc = clf_gbc.predict(X_test)\nprint(clf_scores(clf_gbc, Y_pred_gbc))","11c41bd2":"## Video solution to this problem statement: https:\/\/youtu.be\/c2LGrKwkZgs\n![tutorial%203%20thumbnail.png](attachment:tutorial%203%20thumbnail.png)","055dc8c2":"70 - 30 train, test split","61f59ecc":"Target column distribution - X, y"}}