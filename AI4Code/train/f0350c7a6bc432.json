{"cell_type":{"60c06ceb":"code","1308e244":"code","8db6980f":"code","bdd9bd56":"code","369a3639":"code","a54fd6fa":"code","1034b983":"code","e30f9de1":"code","446025af":"code","5f74dbb4":"code","90393a6a":"code","72b459fc":"code","09fed315":"code","454362eb":"code","79992c96":"code","d13c5b75":"code","df69788a":"code","f9dae151":"code","d87a0d63":"code","9e609268":"markdown","ae4e1e0a":"markdown","c166088e":"markdown","7ce038ca":"markdown","b335b54e":"markdown","2f74c9f2":"markdown","94efd390":"markdown","3dfdac1e":"markdown","be57f9e6":"markdown","966cb23b":"markdown"},"source":{"60c06ceb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns","1308e244":"import tensorflow as tf\ntf.__version__","8db6980f":"data = pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")","bdd9bd56":"data.info()","369a3639":"data.head()","a54fd6fa":"data.isna().sum()","1034b983":"sns.countplot(data['target'], palette=\"bwr\")\nplt.show()\ndata['target'].value_counts(normalize=True);","e30f9de1":"X = data.drop('target', axis=1).to_numpy()\ny = data['target'].to_numpy()","446025af":"X.shape, y.shape","5f74dbb4":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","90393a6a":"from sklearn.model_selection import train_test_split\n\ntf.random.set_seed(42)\n\nX_train_vaild, X_test, y_train_vaild, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train_vaild.shape, X_test.shape, y_train_vaild.shape, y_test.shape","72b459fc":"tf.random.set_seed(42)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_vaild, y_train_vaild, test_size=0.25, random_state=42)\n\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","09fed315":"# let's build a model to find patterns in it\n\n# Set random seed\ntf.random.set_seed(42)\n\n# 1. Create a model\nmodel_1 = tf.keras.Sequential([\n           tf.keras.layers.Dense(3, input_dim=13, activation='relu'),\n           tf.keras.layers.Dense(3, activation='relu'), \n           tf.keras.layers.Dense(4, activation='relu'), \n           tf.keras.layers.Dense(2, activation='softmax')\n])\n\n# 2. Comile the model\nmodel_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                 metrics=['accuracy'])\n\n# 3. Fit the model\nhistory = model_1.fit(X_train, \n                      tf.one_hot(y_train, depth=2), \n                      epochs=250,\n                      verbose = 1,\n                      validation_data=(X_valid, tf.one_hot(y_valid, depth=2)))","454362eb":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.0, 1.0])\nplt.legend(loc='lower right');","79992c96":"plt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0.0, 1])\nplt.legend(loc='upper right');","d13c5b75":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(confusion_matrix(y_true=y_test, \n                 y_pred=model_1.predict(X_test).argmax(axis=1)), annot=True,\n                 fmt=\"d\");","df69788a":"model_1.evaluate(X_test, tf.one_hot(y_test, depth=2))[1] * 100","f9dae151":"model_1.summary()","d87a0d63":"# Let's check out a way of viewing our deep learning models\nfrom tensorflow.keras.utils import plot_model\n\n# See the inputs and outputs of each layer\nplot_model(model_1, show_shapes=True)","9e609268":"# Testing the model","ae4e1e0a":"# checking wheather if the target data is balanced or not.","c166088e":"# Feature scaling","7ce038ca":"# Building and Training our model","b335b54e":"# Check if there is null values","2f74c9f2":"# Quick Look at the Data\nLet\u2019s take a look at the top five rows:","94efd390":"# The Dataset\nFor this notebook we will use the Heart Disease UCI dataset.\n\nLet's define the path to the dataset:","3dfdac1e":"# Import Packages\nLets load all the needed packages for this notebook:","be57f9e6":"# Split Data","966cb23b":"# Splitting traning set"}}