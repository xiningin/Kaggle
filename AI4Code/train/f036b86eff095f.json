{"cell_type":{"88e9f68c":"code","2b3ddabb":"code","bc149dd7":"code","0629a608":"code","f2c22aad":"code","5f7333cd":"code","820da150":"code","6295c200":"code","8e2ba6f0":"code","8b074254":"markdown","df6ab72f":"markdown","751409ee":"markdown","d456afbf":"markdown","e2f54fea":"markdown","110fa915":"markdown","cb34e974":"markdown","96d4474d":"markdown"},"source":{"88e9f68c":"# Import everything I need\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom sklearn.metrics import confusion_matrix, classification_report","2b3ddabb":"# Defining the data directory and categories to import data\nDATADIR = \"..\/input\/satellite-image-classification\/data\"\nCATEGORIES = ['cloudy', 'desert', 'green_area', 'water']","bc149dd7":"img_test = cv2.imread(\"..\/input\/satellite-image-classification\/data\/cloudy\/train_12.jpg\") # I picked a random image\nimg_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB) # Converting from BGR to RGB to see the right colors\nimg_shape = img_test.shape # Get the shape of an image \nprint('Image shape :',img_shape,'\\n')\nplt.imshow(img_test)\nplt.axis('off')\nplt.title('Cloudy image')\nplt.show()","0629a608":"#Defining the main parameters\nIMG_SIZE = img_shape[0]\nCHANNELS = img_shape[2]\nBATCH_SIZE = 64","f2c22aad":"#import data with image_dataset_from_directory \n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    DATADIR,\n    labels = 'inferred',\n    label_mode = 'int',\n    batch_size = BATCH_SIZE,\n    image_size = (IMG_SIZE,IMG_SIZE),\n    shuffle = True,\n    seed = 27,\n    validation_split = 0.3,\n    subset = 'training'\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    DATADIR,\n    labels = 'inferred',\n    label_mode = 'int',\n    batch_size = BATCH_SIZE,\n    image_size = (IMG_SIZE,IMG_SIZE),\n    shuffle = True,\n    seed = 27,\n    validation_split = 0.3,\n    subset = 'validation'\n)\n\nprint('Classes : ',train_ds.class_names)","5f7333cd":"#rescaling and augmenting the data \nrescale = tf.keras.Sequential([layers.Rescaling(1.\/255)])\naugment = tf.keras.Sequential([\n    preprocessing.RandomFlip(mode='horizontal'),\n    preprocessing.RandomFlip(mode='vertical'),\n    preprocessing.RandomRotation(factor=0.3),\n])","820da150":"model =  tf.keras.Sequential([\n\nrescale,\naugment,\n\nlayers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same', strides=1, input_shape=(BATCH_SIZE,IMG_SIZE,IMG_SIZE,CHANNELS)),\nlayers.MaxPool2D(),\n\nlayers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same', strides=1),\nlayers.MaxPool2D(),\n    \nlayers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same', strides=1),\nlayers.MaxPool2D(),\n\nlayers.Flatten(),\nlayers.Dense(128),\nlayers.Dense(4,activation='softmax')\n\n])\n\n# if at more than 5 epochs the validation loss has not improve by 0.001, it stop the training and restore weights with best value\nEarlyStop = EarlyStopping(monitor='val_loss',min_delta=0.001,patience=5,restore_best_weights=True) \n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss='sparse_categorical_crossentropy', \n    metrics=['accuracy'])\n\nhistory = model.fit(\n    train_ds, \n    validation_data = val_ds, \n    epochs = 50, \n    callbacks=[EarlyStop])\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:,['loss', 'val_loss']].plot()\nhistory_df.loc[:,['accuracy', 'val_accuracy']].plot()","6295c200":"model.evaluate(val_ds)","8e2ba6f0":"true = np.array([])\npred = np.array([])\n\ni = 0\nfor data, labels in val_ds :\n    i += 1\n    y = np.argmax(model.predict(data), axis=1)\n    true = np.append(true, labels)\n    pred = np.append(pred, y)\n  \n    if i == val_ds.cardinality().numpy() + 1:\n        break\n\ncf_matrix = confusion_matrix(true,pred)\ndf_cf_matrix = pd.DataFrame(cf_matrix, index = [i for i in range(4)],\n                  columns = [i for i in range(4)])\n\nfig, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(df_cf_matrix, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='d')\nax.set_xticklabels(('Cloudy','Desert','Green area','Water'))\nax.set_yticklabels(('Cloudy','Desert','Green area','Water'))\n\n\nplt.title('confusion matrix')\n\nplt.show()\n\nprint(classification_report(true,pred)) # 0 = Cloudy, 1 = desert, 2 = green_area, 3 = water","8b074254":"We have now 2 sets, a training set and a validation set. The validation set represent 30% of the data. Because our files contains the name of the classes, the image_dataset_from_directory is able to extract the classes names. Now that I have imported the data I will rescale the pixels values from [0,255] to [0,1] :","df6ab72f":"I also added data augmentation by flipping and rotating the data.","751409ee":"Apparently my initial guess was right, most of the misclassified images are from the green area and water classes. Green area in specific. This is due to the similarity between the two areas.","d456afbf":"Now the model. I have no experience in CNN modeling. I've only watched videos on CNN architecture and I've done some research on the most successful CNNs like VGG, GoogLeNet or ResNet. But I wanted to try modeling one and see how it performs on this dataset instead of using transfer learning. \nSo I tried different depths with differents parameters in my network. I tried an architecture like VGG. On this dataset, I got weaker results with a deep model (like 3 conv blocks each containing 2 conv layers) than with a simpler model. The following architecture is quite simple with classical parameters such as 32 filters for the first conv layer and then 64 filters for the second. It's the same for the dense layers. I have only one fully connected layer of 128 neurons and then the last layers with 4 neurons because we have 4 classes. Here is a diagram of the model :","e2f54fea":"This model actually performs quite well, with an average accuracy of 0.93 over several runs. My model certainly not the most optimize model but I find that the accuracy is acceptable.","110fa915":"**I am a beginner and in this notebook I will try to explain what I did. If anything in my reasoning or code is wrong, please comment this notebook so I can correct my errors**","cb34e974":"The dataset is 22.58 MB, so I downloaded it and looked at the different images. There are 4 classes :\n* Cloudy\n* Desert\n* Green area\n* Water\n\nAt first glance Cloudy, Desert and Water, Green area seems to have the same main color. We can actually see the clouds and some of the desert plains very well, but many of green area and water images are blank with a uniform color. It's the same for some images in desert and cloudy classes. Since it's the first time using such a dataset, I have no idea how it will be processed but I think some of the green area images will be classified as water and vice versa.\nLet's start with preprocessing :","96d4474d":"![Model CNN sat class.jpg](attachment:8d28606b-7334-49f8-92e4-ce43f81ad48e.jpg)"}}