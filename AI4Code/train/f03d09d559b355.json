{"cell_type":{"b226963e":"code","77190794":"code","437c8ec7":"code","b8258190":"code","5e4e0cb1":"code","928b296b":"code","21250545":"code","28651bb1":"code","c2b0b630":"code","0cb3e659":"code","9d8620d5":"code","8930edbf":"code","d91e8b4c":"code","a163c14f":"code","1571d93a":"code","3efa395d":"code","2de8f456":"code","5f59d6e0":"code","dba02e35":"code","22e97c64":"code","94b352c4":"code","253905e6":"code","1acb4211":"code","5954ebf8":"code","de5e985f":"code","1703528f":"code","bca144ec":"code","08802d44":"code","99cbe7e1":"code","a78da741":"code","fb48c73d":"code","51f7f6ac":"code","1b344fc3":"code","1aa819ff":"code","e1f5782f":"code","a49758fe":"code","310c4c6f":"code","3cf069c5":"code","163c6b6b":"code","ab918fee":"code","5432304d":"code","9a85f0fa":"markdown","7d1ccebd":"markdown","632ba6b5":"markdown","3ca44baf":"markdown","1bc80828":"markdown","226235e6":"markdown"},"source":{"b226963e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77190794":"\ntrain_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender_submission_df = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","437c8ec7":"train_df.info()","b8258190":"train_df.head()","5e4e0cb1":"test_df.head()","928b296b":"train_df[train_df['Age'].isnull()]","21250545":"train_median = train_df.groupby(['SibSp','Parch']).median()\ntrain_age_median = train_median.reset_index()[['SibSp','Parch','Age']]\ntrain_age_isnull = train_df[train_df['Age'].isnull()]","28651bb1":"# Find the missing values of age and fill the values according to Sibsp and Parch columns.\nindex_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor each in index_nan_age:\n    x = train_df['Age'][(train_df['SibSp'].iloc[each]==train_df['SibSp']) & (train_df['Parch'].iloc[each]==train_df['Parch'])].median()\n    y = train_df['Age'].median()\n    if np.isnan(x):\n        train_df['Age'].iloc[each]=y\n    else:\n        train_df['Age'].iloc[each]=x\n#Check if there are still nan values in age column\ntrain_df[train_df['Age'].isnull()]\n    ","c2b0b630":"# Find the missing values of age and fill the values according to Sibsp and Parch columns.\nindex_nan_age = list(test_df[\"Age\"][test_df[\"Age\"].isnull()].index)\nfor each in index_nan_age:\n    x = test_df['Age'][(test_df['SibSp'].iloc[each]==test_df['SibSp']) & (test_df['Parch'].iloc[each]==test_df['Parch'])].median()\n    y = test_df['Age'].median()\n    if np.isnan(x):\n        test_df['Age'].iloc[each]=y\n    else:\n        test_df['Age'].iloc[each]=x\n#Check if there are still nan values in age column\ntest_df[test_df['Age'].isnull()]","0cb3e659":"train_df.groupby(['Embarked']).median()","9d8620d5":"#Embarked column is most related with Fare column. As our rows in dataframe whose Embarked values are nan has high Fare values \n#their values of Embarked should be 'C'\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df['Embarked'].isnull()]","8930edbf":"test_df[test_df['Embarked'].isnull()]","d91e8b4c":"train_df['cabin_first_letter']=np.nan\nnot_null_cabin_indexes =list(train_df[train_df['Cabin'].notnull()].index)\nfor each in not_null_cabin_indexes:\n    train_df['cabin_first_letter'].iloc[each]=train_df['Cabin'].iloc[each][0]\ntrain_df.groupby(['cabin_first_letter']).median()\n\ntest_df['cabin_first_letter']=np.nan\nnot_null_cabin_indexes =list(test_df[test_df['Cabin'].notnull()].index)\nfor each in not_null_cabin_indexes:\n    test_df['cabin_first_letter'].iloc[each]=test_df['Cabin'].iloc[each][0]\ntest_df.groupby(['cabin_first_letter']).median()","a163c14f":"train_df1 = train_df[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]","1571d93a":"train_df1['Sex']=[0 if each=='male' else 1 for each in train_df1['Sex']]","3efa395d":"train_df1['Sex']=train_df1['Sex'].astype(\"category\")","2de8f456":"train_df1['Pclass']=train_df1['Pclass'].astype(\"category\")","5f59d6e0":"train_df1['Age']=(train_df1['Age'] - train_df1['Age'].min()) \/ (train_df1['Age'].max() - train_df1['Age'].min())","dba02e35":"train_df1['Fare']=(train_df1['Fare'] - train_df1['Fare'].min()) \/ (train_df1['Fare'].max() - train_df1['Fare'].min())","22e97c64":"train_df1 = pd.get_dummies(train_df1,drop_first=True)","94b352c4":"train_df1","253905e6":"test_df1 = test_df[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\ntest_df1['Sex']=[0 if each=='male' else 1 for each in test_df1['Sex']]\ntest_df1['Sex']=test_df1['Sex'].astype(\"category\")\ntest_df1['Pclass']=test_df1['Pclass'].astype(\"category\")\ntest_df1['Age']=(test_df1['Age'] - test_df1['Age'].min()) \/ (test_df1['Age'].max() - test_df1['Age'].min())\ntest_df1['Fare']=(test_df1['Fare'] - test_df1['Fare'].min()) \/ (test_df1['Fare'].max() - test_df1['Fare'].min())\ntest_df1 = pd.get_dummies(test_df1,drop_first=True)\ntest_df1","1acb4211":"test_df1[\"Fare\"] = test_df1[\"Fare\"].fillna(np.mean(test_df1[\"Fare\"]))","5954ebf8":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(C=0.1)\nlr.fit(train_df1[['Age','Sex_1']],train_df['Survived'])","de5e985f":"lr.get_params","1703528f":"y_pred = lr.predict(test_df1[['Age','Sex_1']])","bca144ec":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_pred=y_pred,y_true=gender_submission_df['Survived'].values)","08802d44":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nrf = RandomForestClassifier()\nparams_rf={'max_depth':[2,3,4,5],'max_features':['auto','sqrt','log2'],'n_estimators':[0,100,150,200]}\ngrid_dt = GridSearchCV(estimator=rf, param_grid=params_rf, scoring='accuracy', cv=10, n_jobs=-1)","99cbe7e1":"grid_dt.fit(train_df1,train_df['Survived'])","a78da741":"from sklearn.metrics import confusion_matrix\nclassifier = grid_dt.best_estimator_\ny_pred_grid = classifier.predict(test_df1)\nconfusion_matrix(y_pred=y_pred_grid,y_true=gender_submission_df['Survived'].values)","fb48c73d":"classifier.get_params","51f7f6ac":"'''test_df['cabin_first_letter_T']=0\n'''","1b344fc3":"'''from sklearn.svm import SVC\nsvc = SVC(C=1)\nsvc.fit(df1,train_df['Survived'])\nsvc.score(test_df,gender_submission_df['Survived'])\n'''","1aa819ff":"#test_survived = pd.Series(svc.predict(test_df), name = \"Survived\").astype(int)\n#results = pd.concat([gender_submission_df['PassengerId'], test_survived],axis = 1)\n#results.to_csv(\"titanic.csv\", index = False)","e1f5782f":"'''from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\nrf.fit(df1,train_df['Survived'])\nrf.score(test_df,gender_submission_df['Survived'])\n'''","a49758fe":"'''test_survived = pd.Series(rf.predict(test_df), name = \"Survived\").astype(int)\nresults = pd.concat([gender_submission_df['PassengerId'], test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)\n'''","310c4c6f":"results_3 = pd.concat([gender_submission_df['PassengerId'], pd.Series(y_pred,name=\"Survived\").astype(int)],axis = 1)","3cf069c5":"results_3.to_csv(\"titanic3.csv\", index = False)","163c6b6b":"\n# Import xgboost\nimport xgboost as xgb\n\n\n# Instantiate the XGBClassifier: xg_cl\nxg_cl = xgb.XGBClassifier(objective='binary:logistic')\n\n# Fit the classifier to the training set\nxg_cl.fit(train_df1[['Age','Sex_1']],train_df['Survived'])\n\n# Predict the labels of the test set: preds\npreds = xg_cl.predict(test_df1[['Age','Sex_1']])\n\n","ab918fee":"confusion_matrix(y_pred=preds,y_true=gender_submission_df['Survived'].values)","5432304d":"train_df1.columns","9a85f0fa":"<a id=\"1\">  <\/a>\n## Read and Inspect the Data","7d1ccebd":"<a id=\"4\"> <\/a>\n### Embarked\nThere are 2 rows whose Embarked column has nan value. \n","632ba6b5":"<a id=\"3\"> <\/a>\n### Age","3ca44baf":"# Table of Contents\n\n* [Read and Inspect the Titanic Data](#1)\n* [Dealing with Missing Values](#2)\n    * [Age](#3)\n    * [Embarked](#4)","1bc80828":"*As you see*\n* PassengerId, Survived, PClass, SibSp, Parch are integer attributes\n* Name, Sex, Cabin, Embarked are string attibutes\n* Age, Fare are float attributes","226235e6":"<a id=\"3\"> <\/a>\n## Dealing with Missing Values"}}