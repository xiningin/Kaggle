{"cell_type":{"bd4dd7db":"code","46253fdd":"code","e4d4fb96":"code","5eead15d":"code","b0683004":"code","2fcd7fb5":"code","2e902ba8":"code","36d60ff0":"code","2330de71":"code","87025797":"code","23ed13da":"code","27e94c7d":"code","52e5e3d1":"code","18c45c09":"code","632605d6":"code","972fb1b6":"code","e988dc60":"code","d110f2e7":"code","00901c16":"code","2ce97de6":"code","33bb199e":"code","8ecf6f80":"code","e5af4852":"code","31d7bf74":"code","9c2d1db2":"code","4c12df31":"markdown","fbfe9c83":"markdown"},"source":{"bd4dd7db":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport torch.optim as optim\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom skimage import io, transform\nfrom PIL import Image\nimport random","46253fdd":"# Set random seed for reproducibility\nmanualSeed = 999\n#manualSeed = random.randint(1, 10000) # use if you want new results\nprint(\"Random Seed: \", manualSeed)\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)","e4d4fb96":"img_dir = \"..\/input\/highresolution-anime-face-dataset-512x512\/portraits\/\"\nimage_list = []\nfor item in os.listdir(img_dir):\n    image_list.append(item)\n\nprint(len(image_list))\nprint(image_list[0])","5eead15d":"#Basic Transforms\nSIZE = (64,64)\nmean = (0.5, 0.5, 0.5)\nstd = (0.5, 0.5, 0.5)\nnorm_tran = transforms.Compose([transforms.Resize(SIZE),\n                                transforms.ToTensor(), \n                                transforms.Normalize(mean=mean, std=std)])","b0683004":"class PhotoDatasetCreater(Dataset):\n\n    def __init__(self, image_list, root_dir, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.image_list = image_list\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(image_list)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        # Get the image path for each image\n        img_name = os.path.join(self.root_dir,self.image_list[idx])\n        #print(img_name)\n        image = Image.open(img_name)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image","2fcd7fb5":"img_dataset = PhotoDatasetCreater(image_list=image_list,root_dir=img_dir, transform=norm_tran)\nprint(len(img_dataset))","2e902ba8":"fig = plt.figure()\n\nfor i in range(5):\n    sample = img_dataset[i]\n    ax = plt.subplot(1, 4, i + 1)\n    plt.tight_layout()\n    ax.set_title('Sample #{}'.format(i))\n    ax.axis('off')\n    plt.imshow(sample.permute(1, 2, 0))\n\n    if i == 3:\n        plt.show()\n        break","36d60ff0":"# Data loaders\n# Parameters for setting up data loaders\nBATCH_SIZE = 256\nNUM_WORKERS = 2\nVALIDATION_SIZE = 0.15","2330de71":"# Create the dataloader\ndataloader = torch.utils.data.DataLoader(img_dataset, batch_size=BATCH_SIZE,\n                                         shuffle=True, num_workers=NUM_WORKERS)\n\n","87025797":"# Plot some training images\nreal_batch = next(iter(dataloader))\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\n\nfor i in range(5):\n    sample = real_batch[i]\n    ax = plt.subplot(1, 4, i + 1)\n    plt.tight_layout()\n    ax.set_title('Sample #{}'.format(i))\n    ax.axis('off')\n    plt.imshow(sample.permute(1, 2, 0))\n\n    if i == 3:\n        plt.show()\n        break","23ed13da":"real_batch.size()","27e94c7d":"#checking the availability of cuda devices\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","52e5e3d1":"# number of gpu's available\nngpu = 1\n# input noise dimension\nnz = 100\n# number of generator filters\nngf = 64\n#number of discriminator filters\nndf = 64\n# Number of Channels (For color images need 3)\nnc=3","18c45c09":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","632605d6":"class Generator(nn.Module):\n    def __init__(self, ngpu):\n        super(Generator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n    def forward(self, input):\n        if input.is_cuda and self.ngpu > 1:\n            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n        else:\n            output = self.main(input)\n            return output","972fb1b6":"netG = Generator(ngpu).to(device)\nnetG.apply(weights_init)\n#load weights to test the model\n#netG.load_state_dict(torch.load('weights\/netG_epoch_24.pth'))\nprint(netG)","e988dc60":"class Discriminator(nn.Module):\n    def __init__(self, ngpu):\n        super(Discriminator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is (nc) x 64 x 64\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        if input.is_cuda and self.ngpu > 1:\n            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n        else:\n            output = self.main(input)\n\n        return output.view(-1, 1).squeeze(1)","d110f2e7":"netD = Discriminator(ngpu).to(device)\nnetD.apply(weights_init)\n#load weights to test the model \n#netD.load_state_dict(torch.load('weights\/netD_epoch_24.pth'))\nprint(netD)","00901c16":"criterion = nn.BCELoss()","2ce97de6":"# setup optimizer\noptimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))","33bb199e":"fixed_noise = torch.randn(128, nz, 1, 1, device=device)\nreal_label = 1.0\nfake_label = 0.0","8ecf6f80":"niter = 1\niters = 0\nimg_list = []\ng_loss = []\nd_loss = []","e5af4852":"for epoch in range(niter):\n    for i, data in enumerate(dataloader):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        netD.zero_grad()\n        real_cpu = data.to(device)\n        batch_size = real_cpu.size(0)\n        label = torch.full((batch_size,), real_label, device=device)\n        #print(\"Real cpu size\", real_cpu.size())\n        output = netD(real_cpu)\n#         print(\"Output type {} value {}\".format(type(output), output))\n#         print(\"Label type {} value {}\".format(type(label), label))\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        # train with fake\n        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach())\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake)\n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        print('[%d\/%d][%d\/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f \/ %.4f' % (epoch, niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n        \n        #save the output\n        if i % 100 == 0:\n            print('saving the output')\n            utils.save_image(real_cpu,'.\/\/real_samples.png',normalize=True)\n            fake = netG(fixed_noise)\n            utils.save_image(fake.detach(),'.\/\/fake_samples_epoch_%03d.png' % (epoch),normalize=True)\n        # Check how the generator is doing by saving G's output on fixed_noise\n        if (iters % 500 == 0) or ((epoch == niter-1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = netG(fixed_noise).detach().cpu()\n            img_list.append(utils.make_grid(fake, padding=2, normalize=True))\n        iters += 1\n    \n    # Check pointing for every epoch\n    torch.save(netG.state_dict(), '.\/\/netG_epoch_%d.pth' % (epoch))\n    torch.save(netD.state_dict(), '.\/\/netD_epoch_%d.pth' % (epoch))","31d7bf74":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(g_loss,label=\"G\")\nplt.plot(d_loss,label=\"D\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","9c2d1db2":"# Plot the fake images from the last epoch\nplt.subplot(1,2,2)\nplt.axis(\"off\")\nplt.title(\"Fake Images\")\nplt.imshow(np.transpose(img_list[-1],(1,2,0)))\nplt.show()","4c12df31":"# Pytoch GAN Implementation","fbfe9c83":"# GAN Params "}}