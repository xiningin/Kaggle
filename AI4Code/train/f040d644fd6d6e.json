{"cell_type":{"c8c7d7ed":"code","720b9ec9":"code","f03fc2c0":"code","2e71502c":"code","841c2e2b":"code","0447fb39":"code","2ec50f90":"code","fa010326":"code","a8d93db9":"code","706c3f24":"code","907f39e3":"code","a37f8d0c":"code","74737d7e":"code","27223a23":"code","94bffd24":"code","f5867c6e":"code","56eaa758":"code","a71fb312":"code","2fd77a9e":"code","15887d17":"code","bfa21e10":"code","bc7212fa":"code","c8068d0d":"code","0c797d84":"code","64c13a0e":"code","023c0dcd":"code","d93a5752":"code","b692cdf2":"code","23f5bdf7":"code","8ee1581d":"code","3870714e":"code","d475e7bc":"code","ee638d68":"code","93b622d1":"markdown","b1e77798":"markdown","221531bd":"markdown","613f68f2":"markdown","7716e810":"markdown","3986cef2":"markdown","49b11a73":"markdown","049422a7":"markdown","cfcc880e":"markdown","3fcd2ec1":"markdown","1e66c704":"markdown","fa95d32c":"markdown","f91d4fce":"markdown","370bf01b":"markdown","91ee11a9":"markdown","378399f9":"markdown","fa7720d5":"markdown"},"source":{"c8c7d7ed":"import datatable as dt # for quicker loading of dataframes\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","720b9ec9":"train_df = dt.fread('\/kaggle\/input\/tabular-playground-series-dec-2021\/train.csv').to_pandas()","f03fc2c0":"train_df.info()","2e71502c":"train_df","841c2e2b":"train_df.drop(columns='Id', inplace=True)","0447fb39":"train_df.describe().T.style.background_gradient(cmap = 'Blues')\\\n                           .bar(subset = [\"mean\",], color = 'lightgreen')\\\n                           .bar(subset = [\"std\"], color = '#ee1f5f')\\\n                           .bar(subset = [\"max\"], color = '#FFA07A')","2ec50f90":"plt.figure(figsize=(20, 10))\nplt.xticks(rotation=45)\nax = sns.boxplot(data=train_df.select_dtypes(include=['int32']))","fa010326":"train_df.isna().any().sum()","a8d93db9":"train_df.duplicated().any().sum()","706c3f24":"sns.countplot(x=train_df.Cover_Type);","907f39e3":"train_df.Cover_Type.value_counts()","a37f8d0c":"# obtain a smaller subset of samples\ntrain_sample = train_df.sample(n=100000, random_state=42)\ntrain_sample.shape","74737d7e":"corr_all = train_sample.corr()\n#corr_all","27223a23":"sns.set(style=\"white\", font_scale=1)\nmask = np.zeros_like(corr_all, dtype=np.bool) # Generate a mask for the upper triangle\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(24, 18))\nf.suptitle(\"Correlation Matrix\", fontsize = 10)\ncmap = sns.diverging_palette(220, 10, as_cmap=True) # Generate a custom diverging colormap\nsns.heatmap(corr_all, mask=mask, cmap=cmap, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});","94bffd24":"train_df['Soil_Type7'].sum(), train_df['Soil_Type15'].sum()","f5867c6e":"train_df.drop(columns=['Soil_Type7', 'Soil_Type15'], inplace=True)\ntrain_df.shape","56eaa758":"train_sample = train_df.sample(n=100000, random_state=42)\ntrain_sample.shape","a71fb312":"train_sample.corrwith(train_sample.Cover_Type).plot.bar(figsize=(20,5),\n                  title='Correlation with Target Variable',\n                  fontsize=10, rot=90,\n                  grid=True);","2fd77a9e":"fig, axes = plt.subplots(5,2,figsize=(10, 7))\naxes = axes.flatten()\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data=train_sample, x=train_sample.columns[idx], fill=True, ax=ax)\n    ax.set_xticks([]); ax.set_yticks([]); ax.set_xlabel(''); ax.set_ylabel('')\n    ax.set_title(train_sample.columns[idx], loc='right', fontsize=12)\nfig.tight_layout()\nplt.show()","15887d17":"fig, axes = plt.subplots(5,2,figsize=(20, 15))\naxes = axes.flatten()\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data=train_sample, x=train_sample.columns[idx], fill=True, ax=ax, hue='Cover_Type', legend=idx==0)\n    ax.set_xticks([]); ax.set_yticks([]); ax.set_xlabel(''); ax.set_ylabel('')\n    ax.set_title(train_sample.columns[idx], loc='right', fontsize=12)\nfig.tight_layout()\nplt.show()","bfa21e10":"boolean_df = train_df.select_dtypes(include=['bool'])","bc7212fa":"boolean_sum = boolean_df.sum()\nboolean_sum","c8068d0d":"booleans_with_target = boolean_df.join(pd.Series(train_df.Cover_Type, name='Cover_Type'))\nbooleans_with_target","0c797d84":"group_wa_1 = booleans_with_target.groupby(['Wilderness_Area1', 'Cover_Type'])['Cover_Type'].count()\ngroup_wa_1","64c13a0e":"group_wa_1_df = group_wa_1.reset_index(level=[0])\ngroup_wa_1_df","023c0dcd":"cover_counts_by_type = train_df.Cover_Type.value_counts()\ncover_counts_by_type.sort_index()","d93a5752":"def apply_cover_count_to_row(row):\n#     print(row.name, row[1], cover_counts_by_type[row.name])\n    return row[1] \/ cover_counts_by_type[row.name]\n\ngroup_wa_1_df.apply(apply_cover_count_to_row, axis=1)","b692cdf2":"def apply_cover_count_percent(row):\n    return 1 - (row[1] \/ cover_counts_by_type[row.name])\n\ngroup_wa_1_df[group_wa_1_df.Wilderness_Area1 == False].apply(apply_cover_count_percent, axis=1)","23f5bdf7":"percents_df = pd.DataFrame(columns=boolean_df.columns)\npercents_df","8ee1581d":"def apply_cover_count_percent(row):\n    return 1 - (row[1] \/ cover_counts_by_type[row.name])\n\nfor column in boolean_df.columns:\n    group_by_cover_type = booleans_with_target.groupby([column, 'Cover_Type'])['Cover_Type'].count()\n    group_by_cover_type = group_by_cover_type.reset_index(level=[0])\n    percents = group_by_cover_type[group_by_cover_type[column] == False].apply(apply_cover_count_percent, axis=1)\n    percents_df[column] = percents","3870714e":"percents_df","d475e7bc":"# the heatmap works without problem even with NaNs though.\npercents_df = percents_df.replace(np.nan, 0)\npercents_df","ee638d68":"sns.set(style=\"white\", font_scale=1)\nf, ax = plt.subplots(figsize=(20, 6))\nf.suptitle(\"Percentage map by color\", fontsize = 10)\ncmap = sns.diverging_palette(220, 10, as_cmap=True) # Generate a custom diverging colormap\nsns.heatmap(percents_df, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});","93b622d1":"Some observations:\n* Soil type 7 and 15 are all nil\n* Wilderness Area 1 and 3 are negatively correlated","b1e77798":"Check for null\/missing values","221531bd":"Target balance","613f68f2":"Group each boolean column with the cover type to calculate the percentage representation for each one","7716e810":"Data distribution (on a subset of 100k samples)","3986cef2":"This is interpreted as follows: Wilderness Area 1 is present in 29.85% of Cover Type 1, 26.67% of Cover Type 2, and so on","49b11a73":"We can observe that the cover type adds to 1 for each true\/false pair, e.g. 0.701415 + 0.298585","049422a7":"## Analysis for boolean values","cfcc880e":"**Target is not well balanced**","3fcd2ec1":"Check for duplicates","1e66c704":"Data distrubution considering the target:","fa95d32c":"# Data correlations and distributions","f91d4fce":"Id column is not needed, so it will be dropped","370bf01b":"# Description\n\nFor this competition, you will be predicting a categorical target based on a number of feature columns given in the data. The data is synthetically generated by a GAN that was trained on a the data from the [Forest Cover Type Prediction](https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/overview). This dataset is (a) much larger, and (b) may or may not have the same relationship to the target as the original data.\n\nPlease refer to this [data page](https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/data) for a detailed explanation of the features.\n\nThe target is `Cover_Type`","91ee11a9":"Overview of data","378399f9":"# Data overview","fa7720d5":"Applying it to all boolean columns, we get a full table with these percentages"}}