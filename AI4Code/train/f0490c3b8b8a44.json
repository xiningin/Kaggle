{"cell_type":{"6b705cbc":"code","d50a86df":"code","1b83b853":"code","080f5b83":"code","705a12fa":"code","daabd982":"code","e10fe986":"code","51166d84":"code","8a0929d0":"code","2dfc1aa0":"code","9246c2f4":"code","77000367":"code","bf4aebcc":"code","4f972fd7":"code","70e9be93":"code","f100ac12":"code","05fb1c46":"code","c94a5ac3":"code","5d809d23":"code","c5525889":"code","50868ad1":"code","233ba031":"code","22fc029f":"code","9be74c0e":"markdown","c10dc32e":"markdown","cd3cdb51":"markdown","229b116b":"markdown","4b91abfe":"markdown","97c3c1ba":"markdown"},"source":{"6b705cbc":"!pip install seaborn --upgrade #installing\/updating seaborn as kaggle version is old","d50a86df":"#importing required libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter","1b83b853":"train_df = pd.read_csv(\"..\/input\/machine-hack-ecommerce-time-spent-data\/Train.csv\") #reading train csv\ntrain_df.head()","080f5b83":"train_df.info() # checking for column types and missing values","705a12fa":"train_df.describe() #checking for negative, min\/max ,std and values distribution","daabd982":"train_df[\"client_agent\"].iloc[0]","e10fe986":"train_df[\"device_details\"].iloc[0]","51166d84":"#after instecing the client_agent and device details we can see that more data can be extracted for many rows\n#as the device details does not provide much details on device platform we can extract it through the client_agent details\ndef split_client_platform_data(df):\n    \n    df[\"Platform_org\"] = [\"nan\" for i in range(len(df))]\n    df[\"Device_org\"] = [\"nan\" for i in range(len(df))]\n    for i,text in enumerate(df[\"device_details\"]):\n        df[\"Device_org\"].iloc[i], df[\"Platform_org\"].iloc[i] = re.split(\" - \", text)\n    \n    \n    df[\"Platform\"] = [\"nan\" for i in range(len(df))]\n    df[\"Device\"] = [\"nan\" for i in range(len(df))]\n    \n#     temp_list = []\n#     temp_list2 = []\n    \n    app_count=0\n    mozilla_count=0\n    safari_count=0\n    chrome_count=0\n    firefox_count=0\n    opera_count=0\n    iphone_count=0\n    ipad_count=0\n    windows_count=0\n    android_count=0\n    linux_count=0\n    mac_count=0\n    apple_device_count=0\n    count=0\n    \n    #iterating through the dataframe and adding counts for each encountered instance and adding found instance to new column\n    for i,text in enumerate(df[\"client_agent\"]):\n        if type(text) == str:\n            count+=1\n#             pattern = (\"product|mozilla|safari|chrome|firefox|opera\") \n#             if len(re.findall(pattern, text.lower())) < 1:\n#                 temp_list2.append(text)\n\n            if \"product\" in text.lower():\n                app_count+=1\n                df[\"Platform\"].iloc[i] = \"app\"\n                \n            elif \"chrome\" in text.lower():\n                chrome_count+=1\n                df[\"Platform\"].iloc[i] = \"chrome\"\n\n            elif \"safari\" in text.lower():\n                safari_count+=1\n                df[\"Platform\"].iloc[i] = \"safari\"\n\n            elif \"firefox\" in text.lower():\n                firefox_count+=1\n                df[\"Platform\"].iloc[i] = \"firefox\"\n                \n            elif \"opera\" in text.lower():\n                opera_count+=1\n                df[\"Platform\"].iloc[i] = \"opera\"\n                \n            elif \"mozilla\" in text.lower():\n                mozilla_count+=1\n                df[\"Platform\"].iloc[i] = \"mozilla\"\n            \n#             pattern = (\"windows|iphone|ipad|android|linux|macintosh|cfnetwork|cros\")\n#             if len(re.findall(pattern, text.lower())) < 1:\n#                 temp_list.append(text)\n\n            if \"windows\" in text.lower():\n                windows_count+=1\n                df[\"Device\"].iloc[i] = \"windows\"\n\n            elif \"iphone\" in text.lower():\n                iphone_count+=1\n                df[\"Device\"].iloc[i] = \"iphone\"\n\n            elif \"ipad\" in text.lower():\n                ipad_count+=1\n                df[\"Device\"].iloc[i] = \"ipad\"\n\n            elif \"android\" in text.lower():\n                android_count+=1\n                df[\"Device\"].iloc[i] = \"android\"\n\n            elif \"macintosh\" in text.lower():\n                mac_count+=1        \n                df[\"Device\"].iloc[i] = \"macintosh\"\n                \n            elif \"linux\" in text.lower():\n                linux_count+=1        \n                df[\"Device\"].iloc[i] = \"linux\"\n\n            elif len(re.findall(\"cfnetwork|cros\", text.lower())) > 0:\n                apple_device_count+=1        \n                df[\"Device\"].iloc[i] = \"apple device\"\n            \n        \n\n    print(\"Total Count:\", count)\n    print(\"app_count:\", app_count)\n    print(\"mozilla_count:\", mozilla_count)\n    print(\"safari_count:\", safari_count)\n    print(\"windows_count:\", windows_count)\n    print(\"chrome_count:\", chrome_count)\n    print(\"iphone_count:\", iphone_count)\n    print(\"ipad_count:\", ipad_count)\n    print(\"android_count:\", android_count)\n    print(\"firefox_count:\", firefox_count)\n    print(\"mac_count:\", mac_count)\n    print(\"linux_count:\", linux_count)\n    print(\"apple_device_count:\", apple_device_count)\n    \n#     print(app_count+safari_count+chrome_count+firefox_count)\n#     print(windows_count+iphone_count+ipad_count+android_count+mac_count)\n#     print(mozilla_count)\n    \n    return df","8a0929d0":"train_df = split_client_platform_data(train_df)\ntrain_df.head()","2dfc1aa0":"Counter(train_df[\"device_details\"])","9246c2f4":"Counter(train_df[\"Platform\"])","77000367":"Counter(train_df[\"Device\"])","bf4aebcc":"train_df.replace(\"nan\", np.nan, inplace=True)\ntrain_df.fillna(method=\"ffill\", inplace=True)","4f972fd7":"Counter(train_df[\"Platform\"])","70e9be93":"Counter(train_df[\"Device\"])","f100ac12":"#visualizing the distribution of platform & device we extracted vs what was in device details\nplt.figure(figsize=(16,16))\nplt.subplot(221), sns.histplot(train_df[\"Platform\"]), plt.xticks(rotation = 30)\nplt.subplot(222), sns.histplot(train_df[\"Device\"]), plt.xticks(rotation = 30)\nplt.subplot(223), sns.histplot(train_df[\"Platform_org\"]), plt.xticks(rotation = 30)\nplt.subplot(224), sns.histplot(train_df[\"Device_org\"]), plt.xticks(rotation = 30)\nplt.tight_layout(pad=5)","05fb1c46":"train_df.describe() #checking for negative, min\/max ,std and values distribution","c94a5ac3":"#visualizing data distribution and outliers\nplt.figure(figsize=(16,8))\ntrain_df.boxplot(vert=0)","5d809d23":"#converting dates to datetime and extracting data\ntrain_df[\"date\"] = pd.to_datetime(train_df[\"date\"])\ntrain_df[\"date_year\"] = pd.to_datetime(train_df[\"date\"]).dt.year\ntrain_df[\"date_month\"] = pd.to_datetime(train_df[\"date\"]).dt.month\ntrain_df[\"date_Dayofweek\"] = pd.to_datetime(train_df[\"date\"]).dt.dayofweek\ntrain_df[\"date_Day\"] = pd.to_datetime(train_df[\"date\"]).dt.day\ntrain_df[\"date_Hour\"] = pd.to_datetime(train_df[\"date\"]).dt.hour\ntrain_df.head()","c5525889":"#visualizing corelation of target column with data\nplt.figure(figsize=(16,8))\ndata_corr = train_df.corr()\nsns.heatmap(data_corr, annot=True, cmap=plt.cm.Reds)","50868ad1":"#checking for skewness in data\nplt.figure(figsize=(16,8))\nsns.kdeplot(train_df[\"time_spent\"])","233ba031":"#visualizing data points through scatter plot\nplt.figure(figsize=(16,8))\nsns.scatterplot(train_df.index, train_df[\"time_spent\"])","22fc029f":"#zooming in on data for better visualization\nplt.figure(figsize=(16,8))\nsns.scatterplot(train_df.index[train_df[\"time_spent\"]<500], train_df[\"time_spent\"][train_df[\"time_spent\"]<500])","9be74c0e":"### from the above plot it is conformed that the data is skewed and hence needs some corrective action to normalize the same","c10dc32e":"### as seen from above plot there is more data points in new platform & device which we extracted","cd3cdb51":"### Please leave a like if this helped you.","229b116b":"# Machine Hack E-Commerce Time Spent Basic EDA Notebook","4b91abfe":"### it is seen from above plot that the data is denser towards zero and getting more sparser going away from zero\n### we may need to take care of densely concentrated dulicates before training the model for better genralization","97c3c1ba":"### it is seen from above plot that the data is mostly concentrated around 50-100"}}