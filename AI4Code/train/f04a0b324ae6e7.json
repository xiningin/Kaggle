{"cell_type":{"37421bda":"code","f993d184":"code","21333e43":"code","25a84106":"code","f393c3b2":"code","3021607c":"code","c7e0c575":"code","3500fd86":"code","35db9ade":"code","eef2c581":"code","f289eb8f":"code","6d9c7948":"code","e19f7c21":"code","ad8055b3":"code","35131b97":"code","55e21c3a":"code","4b595303":"code","708a419f":"code","f6b19857":"code","6a50b064":"code","e32ad6b7":"code","85afb82b":"code","ed294b17":"code","a16d0734":"markdown"},"source":{"37421bda":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport sys\nimport random\nimport warnings\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\n\nfrom tqdm import tqdm_notebook, tnrange,notebook\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f993d184":"train_df=pd.read_csv('\/kaggle\/input\/tgs-salt-identification-challenge\/train.csv')\ntrain_df.head(5)","21333e43":"train_df[\"images\"] = [np.array(load_img(\"\/kaggle\/working\/train\/images\/{}.png\".format(idx), color_mode = \"grayscale\")) \/ 255 for idx in notebook.tqdm(train_df.id)]\ntrain_df[\"masks\"] = [np.array(load_img(\"\/kaggle\/working\/train\/masks\/{}.png\".format(idx), color_mode = \"grayscale\")) \/ 65535 for idx in notebook.tqdm(train_df.id)]","25a84106":"train_df[\"coverage\"] = train_df.masks.map(np.sum) \/ pow(101, 2)\n\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)","f393c3b2":"train_df.head(10)","3021607c":"train_df.coverage_class.value_counts()","c7e0c575":"import zipfile\nwith zipfile.ZipFile(\"\/kaggle\/input\/tgs-salt-identification-challenge\/train.zip\") as z:\n    z.extractall(\".\/train\/\")","3500fd86":"import zipfile\nwith zipfile.ZipFile(\"\/kaggle\/input\/tgs-salt-identification-challenge\/test.zip\") as z:\n    z.extractall(\".\/test\/\")","35db9ade":"TRAIN_IMAGE_DIR = '\/kaggle\/working\/train\/images\/'\nTRAIN_MASK_DIR = '\/kaggle\/working\/train\/masks\/'\nTEST_IMAGE_DIR = '\/kaggle\/working\/test\/images\/'\n\nim_width = 128\nim_height = 128\nim_chan = 1","eef2c581":"ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\nplt.figure(figsize=(20,10))\nfor j, img_name in enumerate(ids):\n    q = j+1\n    img = load_img(TRAIN_IMAGE_DIR + img_name + '.png')\n    img_mask = load_img(TRAIN_MASK_DIR + img_name + '.png')\n    \n    plt.subplot(1,2*(1+len(ids)),q*2-1)\n    plt.imshow(img)\n    plt.subplot(1,2*(1+len(ids)),q*2)\n    plt.imshow(img_mask)\nplt.show()","f289eb8f":"train_ids=os.listdir(TRAIN_IMAGE_DIR)","6d9c7948":"# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\n#sys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n    img = load_img(TRAIN_IMAGE_DIR + id_)\n    x = img_to_array(img)[:,:,1]\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_train[n] = x\n    mask = img_to_array(load_img(TRAIN_MASK_DIR + id_))[:,:,1]\n    Y_train[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\nprint('Done!')","e19f7c21":"ix = random.randint(0, len(train_ids))\nplt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\nplt.show()\ntmp = np.squeeze(Y_train[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()","ad8055b3":"X_train, X_valid, Y_train, Y_valid=train_test_split(X_train,Y_train,test_size=0.2, stratify=train_df.coverage_class, random_state=1337)","35131b97":"inputs = Input((im_height, im_width, im_chan))\ns = Lambda(lambda x: x \/ 255) (inputs)\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy',  metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\nmodel.summary()","55e21c3a":"callbacks =[EarlyStopping(patience=10, verbose=1),ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True),\nReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n           ]\nresults = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), shuffle=True,batch_size=16, epochs=50, \n                    callbacks=callbacks)","4b595303":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"loss\")\nplt.plot(results.history[\"val_loss\"], label=\"val_loss\")\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","708a419f":"test_ids=os.listdir(TEST_IMAGE_DIR)","f6b19857":"# Get and resize test images\nX_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    img = load_img(TEST_IMAGE_DIR + id_)\n    x = img_to_array(img)[:,:,1]\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n] = x\n\nprint('Done!')","6a50b064":"# Predict on train, val and test\n#model = load_model('model-tgs-salt-1.h5')\n\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","e32ad6b7":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","85afb82b":"ix = random.randint(0, len(preds_train_t))\nplt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\nplt.show()\ntmp = np.squeeze(Y_train[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()\ntmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()","ed294b17":"ix = random.randint(0, len(preds_test_t))\nplt.imshow(np.dstack((X_test[ix],X_test[ix],X_test[ix])))\nplt.show()\ntmp = np.squeeze(preds_test_t[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()","a16d0734":"Adapted from https:\/\/www.kaggle.com\/keegil\/keras-u-net-starter-lb-0-277 and https:\/\/www.kaggle.com\/jesperdramsch\/intro-to-seismic-salt-and-how-to-geophysics"}}