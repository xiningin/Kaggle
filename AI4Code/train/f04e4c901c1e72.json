{"cell_type":{"31c61f19":"code","49ad2fe1":"code","bbd4443b":"code","dd8367ef":"code","e9ee5c2c":"code","c99f4150":"code","fe9ecefe":"code","88976676":"code","100376b4":"code","50039779":"code","a2b55dd8":"code","2a5d7b41":"code","1916d2ee":"code","930f7ab8":"code","cf662441":"code","220bf4d4":"code","48e1b391":"code","9200af98":"code","298cd597":"code","ee95e52b":"code","e063e5f0":"code","f81c9f87":"code","ef46868e":"code","9b19becb":"code","90a27d47":"code","13a28755":"code","7ad042cd":"code","d470d35e":"code","b4629b3d":"markdown","f48303c8":"markdown","956016a4":"markdown","153f09a0":"markdown","cb6ba7f5":"markdown","ae28d821":"markdown","9f5bd72d":"markdown","dfac6ff8":"markdown","c02c782d":"markdown","8c1daa7d":"markdown","a518d6e3":"markdown","099f3cdc":"markdown","7d13bc7f":"markdown","d3fe071d":"markdown","171dec12":"markdown","bc647f89":"markdown","c1bd68fd":"markdown","87a5c6fa":"markdown","18d13794":"markdown","dc961860":"markdown","933136dd":"markdown","6be3f304":"markdown","a5f7e9ae":"markdown","6d4a0efe":"markdown","08ff8a6f":"markdown","3be91323":"markdown","032ad646":"markdown","3995a926":"markdown","ccd3ca80":"markdown"},"source":{"31c61f19":"# Linear algebra\nimport numpy as np\n\n# Data processing\nimport pandas as pd\n\n# Data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","49ad2fe1":"# Load the dataset\niris = pd.read_csv(\"..\/input\/Iris.csv\")","bbd4443b":"# Show the first 5 rows from the dataset\niris.head(5)","dd8367ef":"# Checking if there's any inconsistency in the dataset\niris.info()","e9ee5c2c":"iris.drop('Id',axis=1,inplace=True)","c99f4150":"fig = iris[iris.Species=='Iris-setosa'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='orange', label='Setosa')\niris[iris.Species=='Iris-versicolor'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='blue', label='versicolor',ax=fig)\niris[iris.Species=='Iris-virginica'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='green', label='virginica', ax=fig)\nfig.set_xlabel(\"Sepal Length\")\nfig.set_ylabel(\"Sepal Width\")\nfig.set_title(\"Sepal Length VS Width\")\nfig=plt.gcf()\nfig.set_size_inches(10,6)\nplt.show()","fe9ecefe":"fig = iris[iris.Species=='Iris-setosa'].plot.scatter(x='PetalLengthCm',y='PetalWidthCm',color='orange', label='Setosa')\niris[iris.Species=='Iris-versicolor'].plot.scatter(x='PetalLengthCm',y='PetalWidthCm',color='blue', label='versicolor',ax=fig)\niris[iris.Species=='Iris-virginica'].plot.scatter(x='PetalLengthCm',y='PetalWidthCm',color='green', label='virginica', ax=fig)\nfig.set_xlabel(\"Petal Length\")\nfig.set_ylabel(\"Petal Width\")\nfig.set_title(\" Petal Length VS Width\")\nfig=plt.gcf()\nfig.set_size_inches(10,6)\nplt.show()","88976676":"iris.hist(edgecolor='black', linewidth=1.2)\nfig=plt.gcf()\nfig.set_size_inches(12,6)\nplt.show()","100376b4":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.violinplot(x='Species',y='PetalLengthCm',data=iris)\nplt.subplot(2,2,2)\nsns.violinplot(x='Species',y='PetalWidthCm',data=iris)\nplt.subplot(2,2,3)\nsns.violinplot(x='Species',y='SepalLengthCm',data=iris)\nplt.subplot(2,2,4)\nsns.violinplot(x='Species',y='SepalWidthCm',data=iris)","50039779":"# importing all the necessary packages to use the various classification algorithms\nfrom sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\nfrom sklearn.model_selection import train_test_split # to split the dataset for training and testing\nfrom sklearn.neighbors import KNeighborsClassifier  # for K nearest neighbours\nfrom sklearn import svm  # for Support Vector Machine (SVM) Algorithm\nfrom sklearn import metrics # for checking the model accuracy\nfrom sklearn.tree import DecisionTreeClassifier # for using Decision Tree Algoithm","a2b55dd8":"# Check on the shape of the dataset\niris.shape","2a5d7b41":"# Draws heatmap with input as the correlation matrix calculted by(iris.corr())\nplt.figure(figsize=(7,4)) \nsns.heatmap(iris.corr(),annot=True,cmap='cubehelix_r') \nplt.show()","1916d2ee":"train, test = train_test_split(iris, test_size = 0.3)# in this our main data is split into train and test\n# the attribute test_size=0.3 splits the data into 70% and 30% ratio. train=70% and test=30%\nprint(train.shape)\nprint(test.shape)","930f7ab8":"train_X = train[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]# taking the training data features\ntrain_y=train.Species# output of our training data\ntest_X= test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']] # taking test data features\ntest_y =test.Species   #output value of test data","cf662441":"train_X.head(2)","220bf4d4":"test_X.head(2)","48e1b391":"train_y.head()  ##output of the training data","9200af98":"# Select the algorithm\nmodel = svm.SVC(gamma='auto')\n\n# Train the algorithm with the training data and the training output\nmodel.fit(train_X, train_y)\n\n# Pass the testing data into the trained algorithm\nprediction = model.predict(test_X)\n\n# Check the acuracy of the algorithm. We pass the predicted output by the model and the actual output. \nprint('The accuracy of the SVM is:', metrics.accuracy_score(prediction, test_y))","298cd597":"model = LogisticRegression()\nmodel.fit(train_X,train_y)\nprediction=model.predict(test_X)\nprint('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction,test_y))","ee95e52b":"model=DecisionTreeClassifier()\nmodel.fit(train_X,train_y)\nprediction=model.predict(test_X)\nprint('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction,test_y))","e063e5f0":"model=KNeighborsClassifier(n_neighbors=3) #this examines 3 neighbours for putting the new data into a class\nmodel.fit(train_X,train_y)\nprediction=model.predict(test_X)\nprint('The accuracy of the KNN is',metrics.accuracy_score(prediction,test_y))","f81c9f87":"a_index=list(range(1,11))\na=pd.Series()\nx=[1,2,3,4,5,6,7,8,9,10]\nfor i in list(range(1,11)):\n    model=KNeighborsClassifier(n_neighbors=i) \n    model.fit(train_X,train_y)\n    prediction=model.predict(test_X)\n    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_y)))\nplt.plot(a_index, a)\nplt.xticks(x)","ef46868e":"petal=iris[['PetalLengthCm','PetalWidthCm','Species']]\nsepal=iris[['SepalLengthCm','SepalWidthCm','Species']]","9b19becb":"train_p,test_p=train_test_split(petal,test_size=0.3,random_state=0)  #petals\ntrain_x_p=train_p[['PetalWidthCm','PetalLengthCm']]\ntrain_y_p=train_p.Species\ntest_x_p=test_p[['PetalWidthCm','PetalLengthCm']]\ntest_y_p=test_p.Species\n\n\ntrain_s,test_s=train_test_split(sepal,test_size=0.3,random_state=0)  #Sepal\ntrain_x_s=train_s[['SepalWidthCm','SepalLengthCm']]\ntrain_y_s=train_s.Species\ntest_x_s=test_s[['SepalWidthCm','SepalLengthCm']]\ntest_y_s=test_s.Species","90a27d47":"model=svm.SVC()\nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the SVM using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n\nmodel=svm.SVC()\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the SVM using Sepal is:',metrics.accuracy_score(prediction,test_y_s))","13a28755":"model = LogisticRegression()\nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the Logistic Regression using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the Logistic Regression using Sepals is:',metrics.accuracy_score(prediction,test_y_s))","7ad042cd":"model=DecisionTreeClassifier()\nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the Decision Tree using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the Decision Tree using Sepals is:',metrics.accuracy_score(prediction,test_y_s))","d470d35e":"model=KNeighborsClassifier(n_neighbors=3) \nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the KNN using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the KNN using Sepals is:',metrics.accuracy_score(prediction,test_y_s))","b4629b3d":"When we train any algorithm, the number of features and their correlation plays an important role. If there are features and many of the features are highly correlated, then training an algorithm with all the features will reduce the accuracy. Thus features selection should be done carefully. This dataset has less features but we will still see the correlation.","f48303c8":"### Logistic Regression","956016a4":"### Logistic Regression","153f09a0":"Above is the graph showing the accuracy for the KNN models using different values of n. ","cb6ba7f5":"### Decision Tree","ae28d821":"**Observation**\n\nThe Sepal Width and Length are not correlated\nThe Petal Width and Length are highly correlated\n\nWe will use all the features for training the algorithm and check the accuracy.\n\nThen we will use 1 Petal Feature and 1 Sepal Feature to check the accuracy of the algorithm as we are using only 2 features that are not correlated. Thus we can have a variance in the dataset which may help in better accuracy. We will check it later.","9f5bd72d":"#### Removing the unneeded column","dfac6ff8":"Lets check the Train and Test Dataset","c02c782d":"### How are the length and width are distributed?","8c1daa7d":"### K-Nearest Neighbours","a518d6e3":"### How the length and width vary according to the species?","099f3cdc":"Before we start, we need to clear some ML notations.\n\n**attributes**-->An attribute is a property of an instance that may be used to determine its classification. In the following dataset, the attributes are the petal and sepal length and width. It is also known as **Features**.\n\n**Target variable**, in the machine learning context is the variable that is or should be the output. Here the target variables are the 3 flower species.","7d13bc7f":"### Exploratory Data Analysis (EDA) on the Iris Dataset","d3fe071d":"### Using the classification algorithms to build a model.\n**Classification**: samples belong to two or more classes and we want to learn from already labeled data how to predict the class of unlabeled data\n\n**Regression**: if the desired output consists of one or more continuous variables, then the task is called regression. An example of a regression problem would be the prediction of the length of a salmon as a function of its age and weight.","171dec12":"### Splitting The Data into Training And Testing Dataset","bc647f89":"The above graph shows relationship between the sepal length and width. Now we will check relationship between the petal length and width.","c1bd68fd":"### K-Nearest Neighbours","87a5c6fa":"### Support Vector Machine (SVM)","18d13794":"### Creating petals and sepals training data ","dc961860":"### SVM","933136dd":"### Steps To Be followed When Applying an Algorithm\n\n 1. Split the dataset into training and testing dataset. The testing dataset is generally smaller than training one as it will help in training the model better.\n 2. Select any algorithm based on the problem (classification or regression) whatever you feel may be good.\n 3. Then pass the training dataset to the algorithm to train it. We use the **.fit()** method\n 4. Then pass the testing data to the trained algorithm to predict the outcome. We use the **.predict()** method.\n 5. We then check the accuracy by **passing the predicted outcome and the actual output** to the model.","6be3f304":"We can drop the Id column as it is unecessary, axis=1 specifies that it should be column wise, inplace =1 means the changes should be reflected into the dataframe","a5f7e9ae":"SVM is giving very good accuracy . We will continue to check the accuracy for different models. We will follow the same steps as above for training various machine learning algorithms.","6d4a0efe":"### Decision Tree","08ff8a6f":"Because there are no null values in the dataset, the data can be processed. ","3be91323":"The violinplot shows density of the length and width in the species. The thinner part denotes that there is less density whereas the bulkier part conveys higher density","032ad646":"As we can see that the Petal Features are giving a better cluster division compared to the Sepal features. This is an indication that the Petals can help in better and accurate Predictions over the Sepal. We will check that later.","3995a926":"### Let's check the accuracy for various values of n for K-Nearest neighbours","ccd3ca80":"### Observations:\n\n - Using Petals over Sepal for training the data gives a much better accuracy.\n - This was expected as we saw in the heatmap above that the correlation between the Sepal Width and Length was very low whereas the correlation between Petal Width and Length was very high. "}}