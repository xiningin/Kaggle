{"cell_type":{"70b3cf63":"code","54915863":"code","0d3046a1":"code","c273ca9f":"code","05d9dce6":"code","4863d2ff":"code","be37084a":"code","8e9df0a6":"code","1abeac3e":"code","48779624":"code","eaceb0b0":"code","c84c009f":"code","551383f8":"code","f2d26ebb":"code","c7a4e952":"code","f2423e3d":"code","498636cc":"code","3d830020":"code","61305df3":"code","2829eae3":"code","9a822e0e":"code","3ad706f3":"code","434d50a0":"code","c3f3a71d":"code","e637aeb3":"code","7df53f9c":"code","864d556f":"code","95daae8b":"code","935bd11a":"code","680a12bb":"code","3e37bc4d":"code","b4b34b4c":"code","969ceaba":"code","ab858f9b":"code","2a0de837":"code","8fbf27fd":"code","15390f2e":"code","1fe45f64":"code","29a6633c":"code","88626f3f":"code","f8c6cef7":"code","d394495a":"code","93c64d3e":"code","8fc658f5":"code","1cdd2005":"code","11cc65e4":"code","9b526a82":"code","da7da742":"code","1bfe9230":"code","189d8465":"markdown","2757a917":"markdown","4c9621de":"markdown","03c3a6d4":"markdown","b1009927":"markdown","ee2dafd6":"markdown","3029304d":"markdown","e1a91404":"markdown","9ac61b8c":"markdown","172743a6":"markdown","da5bebb7":"markdown","9e3441f9":"markdown","638c61e1":"markdown","ff89e966":"markdown","0143ed66":"markdown","af1caa24":"markdown","b47f4519":"markdown","e1bd94d5":"markdown","687bdda7":"markdown","d161f477":"markdown","91264e84":"markdown","cef98e2b":"markdown","86c187e0":"markdown","b0c3ef82":"markdown","fadb3b15":"markdown","9bbab0cc":"markdown"},"source":{"70b3cf63":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","54915863":"plt.style.use('fivethirtyeight')","0d3046a1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c273ca9f":"dataset = pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")","05d9dce6":"# Check for data types\ndataset.dtypes","4863d2ff":"# Statistics of the data\ndataset.describe()","be37084a":"# Check for missing data\ndataset.isnull().sum()","8e9df0a6":"# Check for duplicates\ndataset.duplicated().sum()\n","1abeac3e":"# Drop duplicates\ndataset.drop_duplicates(inplace=True)\n","48779624":"# Add an index column to the dataset\ndataset.reset_index(inplace=True, level=0)","eaceb0b0":"def plot_target(dataframe, column, title,  fontsize=11, figsize_=(18, 10), percentage=False, rot_=0):\n    '''\n    Plot target distribution by a feature\n    \n    Parameters:\n        dataframe: Dataset that has the features\n        column: The feature we want to plot it's distribution\n        title: Title of the plot\n    '''\n    feature = dataframe[[column, 'target', 'index']].groupby(\n        [column, 'target'])['index'].count().unstack(level=1, fill_value=0)\n    \n    ax_1 = feature.plot(kind='bar',\n                figsize=figsize_,\n                stacked=True,\n                rot=rot_,\n                title=title)\n    \n    # Add percentage to the plot\n    c = 0\n    df_len = len(feature)\n    if percentage == True:\n        for bar in ax_1.patches:\n            height = bar.get_height()\n            ax_1.text(bar.get_x() + bar.get_width() \/ 2,\n                     bar.get_y() + height \/ 2,\n                     '{:.0f}%'.format((height\/feature.iloc[c].sum())*100),\n                     ha='center',\n                     va='center')\n            c += 1\n            if c == df_len:\n                c = 0\n    \n    # Rename Legend\n    plt.legend(['Healthy', 'Patient'])\n    # Labels\n    plt.ylabel('Number of samples')\n    # Set xlabel fontsize\n    plt.xticks(fontsize=fontsize)\n    plt.tight_layout()\n","c84c009f":"plot_target(dataset, 'age', 'Age Feature')","551383f8":"plot_target(dataset, 'sex', 'Gender', figsize_=(12, 10), percentage=True)\n# 0 for female, 1 for male","f2d26ebb":"plot_target(dataset, 'cp', 'Chest pain type', figsize_=(15, 10), percentage=True)","c7a4e952":"plot_target(dataset, 'trestbps', 'Resting blood pressure', rot_=70)","f2423e3d":"plot_target(dataset, 'fbs', 'Fasting blood sugar', percentage=True)\n# 1 True, 0 False","498636cc":"plot_target(dataset, 'restecg', 'Resting electrocariographic results', percentage=True)","3d830020":"# Plot values with alot of patients\nheart_rate = dataset[['thalach', 'target', 'index']].groupby(\n        ['thalach', 'target'])['index'].count().unstack(level=1, fill_value=0)\nheart_rate = heart_rate[heart_rate[1] >= heart_rate[1].mean()]\nplt.figure(figsize=(12, 5))\nplt.plot(heart_rate[1],\n        color='red')\nplt.xlabel('Maximum heart reate achieved')\nplt.ylabel('Num of people')\nplt.title('Has heart disease')\nplt.tight_layout()","61305df3":"plot_target(dataset, 'exang', 'Exercise induced angina(chest pain)', percentage=True, figsize_=(8,7))\n# No: 0, Yes: 1","2829eae3":"# Old peak feature\nfeature = dataset[['oldpeak', 'target', 'index']].groupby(\n        ['oldpeak', 'target'])['index'].count().unstack(level=1, fill_value=0)\nplt.figure(figsize=(15, 5))\nplt.plot(feature[0])\nplt.plot(feature[1])\nplt.title('ST depression induced by exercise relative to rest')\nplt.xlabel('old peak')\nplt.ylabel('Num of people')\nplt.tight_layout()","9a822e0e":"plot_target(dataset, 'slope', 'The slope of the peak exercise ST segment', figsize_=(8, 7), percentage=True)","3ad706f3":"plot_target(dataset, 'ca', 'Number of major vessels')","434d50a0":"plot_target(dataset, 'thal', 'Thal(Blood disorder)', percentage=True)","c3f3a71d":"# Create 10 subplots\nfig = plt.figure(figsize=(18,10))\na1 = fig.add_subplot(531)\na2 = fig.add_subplot(532)\na3 = fig.add_subplot(533)\na4 = fig.add_subplot(534)\na5 = fig.add_subplot(535)\na6 = fig.add_subplot(536)\na7 = fig.add_subplot(537)\na8 = fig.add_subplot(538)\na9 = fig.add_subplot(539)\na10 = fig.add_subplot(5,3,11)\nfig.tight_layout(h_pad=2, w_pad=2)\naxes = [a1, a2, a3, a4, a5, a6, a7, a8, a9, a10]\n\n# Get columns of dataset\ncol = dataset.columns\nj = 0\nfor i in range(13):\n    if len(dataset[col[i]].value_counts()) > 2:\n        axes[j].boxplot(dataset[col[i]], vert=False)\n        axes[j].title.set_text(col[i])\n        j += 1","e637aeb3":"plt.boxplot(dataset['thal'], vert=False)\nplt.title('thal')","7df53f9c":"# Statistics of the data\ndataset.describe()","864d556f":"# Check unique values in thal feature\ndataset['thal'].value_counts()","95daae8b":"# Replace outliers in thal feature with the median\ndataset[dataset['thal'] == 0]['thal'] = dataset['thal'].median()\nplt.boxplot(dataset['thal'], vert=False)\nplt.title('thal')","935bd11a":"dataset['thal'].value_counts()","680a12bb":"# Check unique values in Ca feature\ndataset['ca'].value_counts()","3e37bc4d":"# Values must be between (0-3), replace values equal 4 with the median\ndataset[dataset['ca'] == 4]['ca'] = dataset['ca'].median()\nplt.boxplot(dataset['ca'], vert=False)\nplt.title('ca')","b4b34b4c":"# Check unique values in oldpeak feature\ndataset['oldpeak'].value_counts().sort_index()","969ceaba":"# Replace values greater than or equal 4 with the median value\ndataset[dataset['oldpeak'] >= 4]['oldpeak'] = dataset['oldpeak'].median()\nplt.boxplot(dataset['oldpeak'], vert=False)\nplt.title('oldpeak')","ab858f9b":"# Check for unique values in chol feature\ndataset['chol'].value_counts().sort_index(ascending=True).head(20)","2a0de837":"# Replace values greater than 350 or less than 120 with the median\ndataset[(dataset['chol'] >= 350) | (dataset['chol'] < 120)]['chol'] = dataset['chol'].median()\nplt.boxplot(dataset['chol'], vert=False)\nplt.title('chol')","8fbf27fd":"# Check for unique values in trestbps feature\ndataset['trestbps'].value_counts().sort_index(ascending=False)","15390f2e":"# Replace values greater than 170 or less than 90 with the median value\ndataset[(dataset['trestbps'] > 170) | (dataset['trestbps'] < 90)]['trest'] = dataset['trestbps'].median()\nplt.boxplot(dataset['trestbps'], vert=False)\nplt.title('trestbps')","1fe45f64":"dataset","29a6633c":"correlation = dataset.corr()\n\n# Plot correlation\nplt.figure(figsize=(19, 15))\nsns.heatmap(correlation, xticklabels=correlation.columns.values, \n            yticklabels=correlation.columns.values, annot=True, annot_kws={'size':10})\n\n# Axis ticks size\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","88626f3f":"# Shuffle rows and reset index\ndataset = dataset.sample(frac=1).reset_index()\n\n# Drop index column\ndataset.drop(columns='index', inplace=True)\n\nx = dataset.drop(columns='target')\ny = dataset['target']","f8c6cef7":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Perceptron\nclf = Perceptron(shuffle=True, penalty='l2', max_iter=1000)\nscores = cross_val_score(clf, x, y, cv=10).sum() \/ 10\nscores","d394495a":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nscores = cross_val_score(clf, x, y, cv=10).sum() \/ 10\nscores","93c64d3e":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\nscores = cross_val_score(clf, x, y, cv=10).sum() \/ 10\nscores","8fc658f5":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier(n_neighbors=3, )\nscores = cross_val_score(clf, x, y, cv=10).sum() \/ 10\nscores","1cdd2005":"from sklearn import svm\nclf = svm.SVC(kernel='linear')\nscores = cross_val_score(clf, x, y, cv=10).sum() \/ 10\nscores","11cc65e4":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(criterion='entropy')\nscores = cross_val_score(clf, x, y, cv=10).sum() \/ 10\nscores","9b526a82":"import xgboost as xgb\nclf = xgb.XGBClassifier(learning_rate=0.1,max_depth=6,n_estimators=500,n_jobs=-1)\nscores = cross_val_score(clf, x, y, cv=10).sum() \/ 10\nscores","da7da742":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)","1bfe9230":"from sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nclf = svm.SVC(kernel='linear')\nclf.fit(x_train, y_train)\ny_pred = clf.predict(x_test)\nconfusion_matrix(y_test, y_pred)","189d8465":"## thalach feature has alot of unique values, so we will plot maximum heart rate with the highest number of patients","2757a917":"## Logestic regression","4c9621de":"## Import dataset\n","03c3a6d4":"## Findings","b1009927":"## Model evaluation","ee2dafd6":"## Data Describing ","3029304d":"## K-nearest neighbours","e1a91404":"## Perceptron algorithm","9ac61b8c":"### Most of the patients didn't have exercise induced angina","172743a6":"## Naive Bayes","da5bebb7":"### There is no highly correlated variables","9e3441f9":"## Introduction","638c61e1":"### People having chest pain number 1 are more likely to have hear disease","ff89e966":"The goal of the Heart Disease UCI dataset is to develop a model able to classify whether a person has heart disease or not based on a number of variables with the target conditions.\n\nIn this notebook, we will go through some necessary steps of cleaning and visualizing the data to get a better understanding of our problem and finally choose the best model for our dataset.","0143ed66":"## Target distribution by features","af1caa24":"#### With the SVM model we were able to get nearly 99% accuracy, however, high percentage accuracy may be an indicator of overfitting so we shuffled the data then split it into a train and test data to make sure that our model doesn't overfit but the accuracy didn't change that much which may be due to dataset small size.","b47f4519":"## Check for variables correlation","e1bd94d5":"### We choose to use SVM model","687bdda7":"## Support vector machines","d161f477":"### We Can Clearly see that females are more likely to have heart disease than men","91264e84":"# Model evaluation","cef98e2b":"## Decision tree classification","86c187e0":"## Check for outliers\n\n","b0c3ef82":"## Chol feature has many unique values and plotting it won't be useful","fadb3b15":"## Matplotlib style\n","9bbab0cc":"## Import libraries"}}