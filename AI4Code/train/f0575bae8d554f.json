{"cell_type":{"7ea1cfa6":"code","f985b715":"code","227c7d76":"code","f9b27fa0":"code","c8729415":"code","2942ae43":"code","99e68ad1":"code","7b7142b5":"code","825e9a7f":"code","4127a9ef":"code","2b6aaaa1":"code","59939da8":"code","0674df9a":"code","d582f1d6":"code","433bbd67":"code","4556d93d":"code","a5fb3529":"markdown","513ea220":"markdown","a41d899e":"markdown","26e7ffcd":"markdown","64ba348c":"markdown","0e83cd9a":"markdown","4ae4a4ab":"markdown","4ba6eb54":"markdown"},"source":{"7ea1cfa6":"import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\n","f985b715":"df = pd.read_csv('..\/input\/predictingese\/amsPrediction - Sheet1.csv')\ndf.head()","227c7d76":"df.describe()","f9b27fa0":"corr=df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","c8729415":"endog = df['ESE']\nexog = sm.add_constant(df[['MSE','Attendance','HRS']])\nprint(exog)","2942ae43":"X=exog.to_numpy()\nY= endog.to_numpy()\ns1_xt =np.transpose(X)\nprint(s1_xt)\n","99e68ad1":"s2_mul1= np.matmul(s1_xt,X)\nprint(s2_mul1)","7b7142b5":"s3_inv=np.linalg.inv(s2_mul1)\nprint(s3_inv)","825e9a7f":"s4_mul= np.matmul(s3_inv,s1_xt)\nprint(s4_mul)","4127a9ef":"s5_res =np.matmul(s4_mul,Y)\nprint(s5_res)","2b6aaaa1":"mod = sm.OLS(endog, exog)\nresults = mod.fit()\nprint (results.summary())","59939da8":"def RSE(y_true, y_predicted):\n   \n    y_true = np.array(y_true)\n    y_predicted = np.array(y_predicted)\n    RSS = np.sum(np.square(y_true - y_predicted))\n\n    rse = math.sqrt(RSS \/ (len(y_true) - 2))\n    return rse","0674df9a":"yp= results.predict()\nypa = np.array(yp)\nyta = df['ESE']\neterms =yta-ypa\n\n\ndf1 = pd.DataFrame(eterms)\ndf1['ESE'].hist(bins=10)\n\n\n\n\n","d582f1d6":"rse= RSE(df['ESE'],results.predict())\nprint(rse)","433bbd67":"from sklearn import linear_model\nX = df[['MSE','Attendance','HRS']]\ny = df['ESE']\n\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X,y)\nlm.coef_","4556d93d":"lm.intercept_","a5fb3529":"# Multiple ways to implement Multiple Linear Regression (MLR) Modelling in Python.\n\nThis notebook aims to illustrate different ways in which one can implement Multiple Linear Regression in Python. To achieve this objective, I will be using a revised dataset created to predict the end semester examination marks. \n\nHere, I have added one more feature to make the task of predication a little bit interesting. I added a feature called HRS, which indicates the number of hours spent studying the course day before the examination. The values for the HRS vector are randomly generated in the range of 0 to 24, and they are not actual.\n\nThe notebook illustrates three different ways to implement MLR. These are:\n1. Ordinary Least Square method through Matrix operation.\n2. Ordinary Least Square method from StatsModels\n3. Gradient Descent Method from Scikit-Learn\n\nMy YouTube videos on MLR using [OLS](https:\/\/www.youtube.com\/watch?v=0qv9Ck24q1s) and [Gradient Descent algorithm](https:\/\/www.youtube.com\/watch?v=Y1J22hk_Vf0) explain the theory behind these methods.","513ea220":"> The follwoing code segment imports required modules and loads dataset as Panda's Dataframe.","a41d899e":"The follwing code converts the input and output vectors as numpy array in order to implement the  formula in a stepwise manner.\n\n\n\nIt also transpose the input vector.","26e7ffcd":"The correlation analysis shows no strong correlation between the input vectors, namely 'Attendance'(-0.10), 'HRS'(0.25) and output vector 'ESE'.","64ba348c":"The following code segment build the MLR model using  the OLS method from the statsmodel. ","0e83cd9a":"The dataset has four different feature vectors called Attendance, MSE, HRS and ESE. The 'ESE' is an output vector, and the rest of the columns are input vectors representing independent variables.","4ae4a4ab":"The following code segment builds the MLR model from Scikit-Learn module.","4ba6eb54":"The following code segment separates input and output vectors. Also, it adds a constant unit vector as a coefficient for *beta0* or *intercept*."}}