{"cell_type":{"27602c2c":"code","fead0232":"code","b823f0cc":"code","73fa55ab":"code","01f84fd5":"code","189ca2b8":"code","0b0265cb":"code","16c888d4":"code","bd27ca93":"code","5a234098":"code","d55eed01":"code","8a5ed444":"code","3f87acaa":"code","6069c91e":"code","9e623b19":"markdown","83890b97":"markdown","e65728c8":"markdown","6975d92f":"markdown","708df87d":"markdown","7efcba32":"markdown","da4c6232":"markdown","42e4e689":"markdown","18c79c05":"markdown","4a5b2546":"markdown","cfd69466":"markdown"},"source":{"27602c2c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport json","fead0232":"root_path = '\/kaggle\/input\/CORD-19-research-challenge\/'\nmetadata_path = f'{root_path}\/metadata.csv'\nmeta_df = pd.read_csv(metadata_path, dtype={\n    'pubmed_id': str,\n    'Microsoft Academic Paper ID': str, \n    'doi': str\n})\nmeta_df.head()","b823f0cc":"meta_df.info()","73fa55ab":"all_json = glob.glob(f'{root_path}\/**\/*.json', recursive=True)\nlen(all_json)","01f84fd5":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            self.paper_id = content['paper_id']\n            self.abstract = []\n            self.body_text = []\n            # Abstract\n            for entry in content['abstract']:\n                self.abstract.append(entry['text'])\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            self.abstract = '\\n'.join(self.abstract)\n            self.body_text = '\\n'.join(self.body_text)\n    def __repr__(self):\n        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\nfirst_row = FileReader(all_json[0])\nprint(first_row)","189ca2b8":"def get_breaks(content, length):\n    data = \"\"\n    words = content.split(' ')\n    total_chars = 0\n\n    # add break every length characters\n    for i in range(len(words)):\n        total_chars += len(words[i])\n        if total_chars > length:\n            data = data + \"<br>\" + words[i]\n            total_chars = 0\n        else:\n            data = data + \" \" + words[i]\n    return data","0b0265cb":"dict_ = {'paper_id': [], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\nfor idx, entry in enumerate(all_json):\n    if idx % (len(all_json) \/\/ 10) == 0:\n        print(f'Processing index: {idx} of {len(all_json)}')\n    content = FileReader(entry)\n    \n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    # no metadata, skip this paper\n    if len(meta_data) == 0:\n        continue\n    \n    dict_['paper_id'].append(content.paper_id)\n    dict_['abstract'].append(content.abstract)\n    dict_['body_text'].append(content.body_text)\n    \n    # also create a column for the summary of abstract to be used in a plot\n    if len(content.abstract) == 0: \n        # no abstract provided\n        dict_['abstract_summary'].append(\"Not provided.\")\n    elif len(content.abstract.split(' ')) > 100:\n        # abstract provided is too long for plot, take first 300 words append with ...\n        info = content.abstract.split(' ')[:100]\n        summary = get_breaks(' '.join(info), 40)\n        dict_['abstract_summary'].append(summary + \"...\")\n    else:\n        # abstract is short enough\n        summary = get_breaks(content.abstract, 40)\n        dict_['abstract_summary'].append(summary)\n        \n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    \n    try:\n        # if more than one author\n        authors = meta_data['authors'].values[0].split(';')\n        if len(authors) > 2:\n            # more than 2 authors, may be problem when plotting, so take first 2 append with ...\n            dict_['authors'].append(\". \".join(authors[:2]) + \"...\")\n        else:\n            # authors will fit in plot\n            dict_['authors'].append(\". \".join(authors))\n    except Exception as e:\n        # if only one author - or Null valie\n        dict_['authors'].append(meta_data['authors'].values[0])\n    \n    # add the title information, add breaks when needed\n    try:\n        title = get_breaks(meta_data['title'].values[0], 40)\n        dict_['title'].append(title)\n    # if title was not provided\n    except Exception as e:\n        dict_['title'].append(meta_data['title'].values[0])\n    \n    # add the journal information\n    dict_['journal'].append(meta_data['journal'].values[0])\n    \ndf_covid = pd.DataFrame(dict_, columns=['paper_id', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\ndf_covid.head()","16c888d4":"dict_ = None","bd27ca93":"df_covid['abstract_word_count'] = df_covid['abstract'].apply(lambda x: len(x.strip().split()))\ndf_covid['body_word_count'] = df_covid['body_text'].apply(lambda x: len(x.strip().split()))\ndf_covid.head()","5a234098":"df_covid.info()","d55eed01":"df_covid['abstract'].describe(include='all')","8a5ed444":"df_covid.drop_duplicates(['abstract', 'body_text'], inplace=True)\ndf_covid['abstract'].describe(include='all')","3f87acaa":"df_covid.head()","6069c91e":"df_covid.describe()","9e623b19":"### Load the Data into DataFrame","83890b97":"### Adding the Word Count Columns","e65728c8":"### Handle Possible Duplicates","6975d92f":"Get path to all JSON files:","708df87d":"### Fetch All of JSON File Path","7efcba32":"# Enigma Covid 19","da4c6232":"### Helper Functions","42e4e689":"### Data Ingestion \nUsing methods from: [Dataset Parsing Code | Kaggle, COVID EDA: Initial Exploration Tool](https:\/\/www.kaggle.com\/ivanegapratama\/covid-eda-initial-exploration-tool) \n","18c79c05":"### Take a Look at the Data:","4a5b2546":"### Dependencies","cfd69466":"It looks like we didn't have duplicates. Instead, it was articles without Abstracts."}}