{"cell_type":{"1999236c":"code","ab66f269":"code","4bc50fab":"code","429b5174":"code","98f34264":"code","3f6cd402":"code","a7be6278":"code","0a027744":"code","be65204e":"code","8d6555ec":"code","3b771fe0":"code","fe2f83ea":"code","4b79f77f":"code","dab4308e":"code","1c68f4d1":"code","59d6bc5d":"code","66d34755":"code","b0ade868":"markdown","e6309ab0":"markdown","c0633e3a":"markdown","383c5415":"markdown","4f886e23":"markdown","55f7e362":"markdown","0ec1c56f":"markdown","7441e406":"markdown","7be75fc5":"markdown","8e2a582f":"markdown","cb737b87":"markdown","c2c21ff7":"markdown","63d939eb":"markdown","b3031f1c":"markdown","4d375d20":"markdown","a4579da9":"markdown","250bf4ae":"markdown"},"source":{"1999236c":"import io\nimport random\nimport string\nimport warnings\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import words\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.sentiment.util import *\n\n\n# sklearn imports\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\n\n\n# python imports\nimport re\nimport json\nimport os\nfrom collections import Counter\nimport datetime as dt\n\n\n# Visualization\nfrom matplotlib import pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom wordcloud import WordCloud\nfrom tqdm import tqdm_notebook\n\n\n# Saving models\nimport pickle","ab66f269":"data_dir = '..\/input\/coronavirus-covid19-tweets-early-april\/2020-04-03 Coronavirus Tweets.CSV'\ntweets = pd.read_csv(data_dir)\n#     print(file)\n\ndf = pd.read_csv(data_dir)\ndf.tail()","4bc50fab":"fig = plt.figure(figsize=(20,8))\nax = fig.add_subplot(111)\nax.set(title='Temporal tweet frequency worldwide', xlabel='Time', ylabel='Tweet frequency per hour')\nplt.hist(pd.to_datetime(df.created_at), bins = 24*9, color = 'b')\nplt.show()","429b5174":"text_en = df['text']","98f34264":"text_en_lr = text_en.apply(lambda x: re.sub(r\"https\\S+\", \"\", str(x)))\ntext_en_lr.head()","3f6cd402":"text_en_lr_lc = text_en_lr.apply(lambda x: x.lower())\ntext_en_lr_lc.head()","a7be6278":"text_en_lr_lc_pr = text_en_lr_lc.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\ntext_en_lr_lc_pr.head()","0a027744":"stop_words = set(stopwords.words('english'))\nstop_words.update(['#coronavirus', '#coronavirusoutbreak', '#coronavirusPandemic', '#covid19', '#covid_19', '#epitwitter', '#ihavecorona', 'amp', 'coronavirus', 'covid19'])\n\ntext_en_lr_lc_pr_sr = text_en_lr_lc_pr.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\ntext_en_lr_lc_pr_sr.head()","be65204e":"word_list = [word for line in text_en_lr_lc_pr_sr for word in line.split()]\nword_list[:5]","8d6555ec":"sns.set(style=\"darkgrid\")\ncounts = Counter(word_list).most_common(50)\ncounts_df = pd.DataFrame(counts)\ncounts_df\ncounts_df.columns = ['word', 'frequency']\n\nfig, ax = plt.subplots(figsize = (12, 12))\nax = sns.barplot(y=\"word\", x='frequency', ax = ax, data=counts_df)\nplt.savefig('wordcount_bar.png')","3b771fe0":"wordcloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(word_list))\n\n\nplt.figure(figsize = (12, 10), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n\nplt.savefig('wordcloud.png')\n\n","fe2f83ea":"sid = SentimentIntensityAnalyzer()\nsentiment_scores = text_en_lr_lc_pr_sr.apply(lambda x: sid.polarity_scores(x))\nsent_scores_df = pd.DataFrame(list(sentiment_scores))\nsent_scores_df.tail()","4b79f77f":"sent_scores_df['val'] = sent_scores_df['compound'].apply(lambda x: 'neutral' if x == 0 else ('positive' if x > 0 else 'negative'))\nsent_scores_df.head()","dab4308e":"sent_counts = pd.DataFrame.from_dict(Counter(sent_scores_df['val']), orient = 'index').reset_index()\nsent_counts.columns = ['sentiment', 'count']\n\nsns.barplot(y=\"count\", x='sentiment', data=sent_counts)\nplt.savefig('sentiment.png')","1c68f4d1":"sentiments_time_df = pd.DataFrame()\nsentiments_time_df['time'] = df['created_at']\nsentiments_time_df['polarity'] = sent_scores_df['compound']\nsentiments_time_df.index = pd.to_datetime(sentiments_time_df['time'])\n\n\not = sentiments_time_df.sample(frac=.001)\not['time'] = pd.to_datetime(ot['time'])\not.index = pd.to_datetime(ot['time'])\not.sort_index(inplace=True)\not['expanding'] = ot['polarity'].expanding().mean()\not['rolling'] = ot['polarity'].rolling('1h').mean()\n\nfig = plt.figure(figsize=(20,5))\nax = fig.add_subplot(111)\nax.scatter(ot['time'],ot['polarity'], label='Tweet Sentiment', s = 10, color = 'y')\nax.plot(ot['time'],ot['rolling'], color ='r', label='Rolling Mean', linewidth = 5)\nax.plot(ot['time'],ot['expanding'], color='b', label='Expanding Mean', linewidth = 5)\nax.set_xlim([dt.date(2020,4,3),dt.date(2020,4,3)])\nax.set(title='Tweet Sentiments over Time', xlabel='Date', ylabel='Sentiment polarity')\nax.legend(loc='best')\nfig.tight_layout()\nplt.savefig('temporal_sentiments.png')\n","59d6bc5d":"fig = plt.figure(figsize=(10,5))\nax = fig.add_subplot(111)\nax.set(title='Tweet Sentiments distribution', xlabel='polarity', ylabel='frequency')\nsns.distplot(sentiments_time_df['polarity'], bins=30, ax=ax)\n# plt.show()\nplt.savefig('sentiment_distribution.png')","66d34755":"polar_tweets_df = pd.DataFrame()\npolar_tweets_df['tweet'] = text_en_lr_lc_pr_sr\npolar_tweets_df['polarity'] = sent_scores_df['val']\n\npositive = polar_tweets_df[polar_tweets_df['polarity'] == 'positive']['tweet']\nnegative = polar_tweets_df[polar_tweets_df['polarity'] == 'negative']['tweet']\nneutral = polar_tweets_df[polar_tweets_df['polarity'] == 'neutral']['tweet']\n\npositive_list = [word for line in positive for word in line.split()]\nnegative_list = [word for line in negative for word in line.split()]\nneutral_list = [word for line in neutral for word in line.split()]\n\npositive_cloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(positive_list))\n\nnegative_cloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(negative_list))\n\nneutral_cloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(neutral_list))\n\n\nfig, axs = plt.subplots(2, 2, figsize = (20, 12))\n# fig.suptitle('Clouds of polar words', fontsize = 30)\nfig.tight_layout(pad = 0)\n\naxs[0, 0].imshow(positive_cloud)\naxs[0, 0].set_title('Words from positive tweets', fontsize = 20)\naxs[0, 0].axis('off')\n# axs[0, 0].tight_layout(pad = 1)\n\naxs[0, 1].imshow(negative_cloud)\naxs[0, 1].set_title('Words from negative tweets', fontsize = 20)\naxs[0, 1].axis('off')\n# axs[0, 1].tight_layout(pad = 1)\n\naxs[1, 0].imshow(neutral_cloud)\naxs[1, 0].set_title('Words from neutral tweets', fontsize = 20)\naxs[1, 0].axis('off')\n# axs[1, 0].tight_layout(pad = 1)\n\naxs[1, 1].imshow(wordcloud)\naxs[1, 1].set_title('Words from all tweets', fontsize = 20)\naxs[1, 1].axis('off')\n# axs[1, 0].tight_layout(pad = 1)\nplt.savefig('joint_cloud.png')\n\n","b0ade868":"### Classifying the scores based on the compount polarity value","e6309ab0":"### Libraries","c0633e3a":"### Concatenating all the tweets into a list of words","383c5415":"### Reading the tweets","4f886e23":"### Word cloud of polar words","55f7e362":"### Converting all tweets to lowercase","0ec1c56f":"### Picking out the tweet texts","7441e406":"### Temporal frequency of tweets","7be75fc5":"### Removing stopwords","8e2a582f":"### Temporal plot of the sentiments","cb737b87":"## Sentiment Analysis","c2c21ff7":"### Plotting the sentiment score counts","63d939eb":"### Removing punctuations","b3031f1c":"### Getting the polarity scores for each tweet","4d375d20":"### Removing URLs from tweets","a4579da9":"### Sentiment scores distribution","250bf4ae":"### Calculating the Term Frequency"}}