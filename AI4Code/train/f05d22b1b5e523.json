{"cell_type":{"f1adcb36":"code","6dd66d44":"code","f11341ed":"code","a9ef15b4":"code","114c7622":"code","0364caf2":"code","81afb040":"code","52dfc5a8":"code","9b8772b4":"code","b1fe2ea9":"code","5d8f0c67":"code","5438b426":"code","f04bb1ee":"code","6eef66b1":"code","f5880531":"code","828addfe":"code","8fd902e4":"code","c05bcff1":"code","9f883a95":"code","a333c039":"code","0c69bcea":"code","3336c9cb":"code","cb42d37e":"markdown","5271f37d":"markdown","d710e436":"markdown","227379b7":"markdown","f4156ea3":"markdown","4cc3c0c0":"markdown","33a59247":"markdown","e1d8262e":"markdown","1abac1ee":"markdown","69777c23":"markdown","4581bbcc":"markdown","9fd2a5db":"markdown","b66afc08":"markdown","8a67478d":"markdown","7debbfa1":"markdown","412fa70d":"markdown","80f768ae":"markdown","3552c137":"markdown","9e4e56ad":"markdown","75cc411a":"markdown","29ad14d9":"markdown","67e006df":"markdown","17122327":"markdown","1a420147":"markdown","5216fb8b":"markdown","4d2e0f90":"markdown","f8b69faf":"markdown","09ad5cdf":"markdown","eeed7f97":"markdown","4a922490":"markdown","35355ad5":"markdown","d878e54f":"markdown","90ba4f44":"markdown"},"source":{"f1adcb36":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport numpy as np\n\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()","6dd66d44":"input_interval_file_path = '..\/input\/life_interval_data.csv'\ninput_total_file_path = '..\/input\/life_total_data.csv'\n\ndf_i = pd.read_csv(input_interval_file_path)\ndf_t = pd.read_csv(input_total_file_path,index_col='date')\n\n# Parse dates and times\n\ndef conv_to_timedelta(s):\n    # Hack to use pd.to_timedelta\n    return pd.to_timedelta(s+':00')\n\ndef conv_to_scalar(s):\n    return pd.to_timedelta(s+':00').total_seconds()\/3600\n\ndef timedelta_to_scalar(td):\n    return td.total_seconds()\/3600\n\ndf_i.date = pd.to_datetime(df_i.date)\ndf_i.start_time = pd.to_datetime(df_i.start_time)\n\ndf_i.time = df_i.time.map(conv_to_timedelta)\ndf_i['end_time'] = df_i.start_time + df_i.time\ndf_i.time = df_i.time.map(timedelta_to_scalar)\n\ndf_t = df_t.applymap(conv_to_scalar)","f11341ed":"df_i.head()","a9ef15b4":"df_t.head()","114c7622":"df_t.describe()","0364caf2":"df_t['productive'] = df_t['math'] + df_t['uni'] + df_t['work']\ndf_t.sum().plot.bar()","81afb040":"df_t_prod = df_t.filter(['math','uni','work'],axis=1)\ndf_t_prod.plot.bar(stacked=True,figsize=(16,6))","52dfc5a8":"col_prod = ['math','uni','work']\ndf_prod = df_t[col_prod].copy()\ndf_prod.head()\ndf_prod['total'] = df_prod.apply(lambda x: x.sum(),axis=1)\ndf_prod.head()","9b8772b4":"ax = df_prod.total.plot.line(figsize=(8,5),title='Total productivity over time (with mean)')\nax.axhline(df_prod.total.mean(),c='grey',ls='--')","b1fe2ea9":"start_day = '2019-05-06'\nstart_loc = df_prod.index.get_loc(start_day)\nprod_by_week = pd.Series()\n\nwhile True:\n    current_week = df_prod.total.iloc[start_loc:start_loc+7]\n    if len(current_week) != 7 :\n        break\n    prod_by_week[df_prod.index[start_loc]] = current_week.sum()\n    start_loc += 7\n\nprod_by_week.plot.line()","5d8f0c67":"df_tmp = df_prod[['total']].copy()\ndf_tmp['dow'] = df_prod.index.map(lambda x : pd.to_datetime(x).weekday())\ndf_tmp.head()","5438b426":"df_tmp.groupby('dow').mean().plot.bar()","f04bb1ee":"ax = df_tmp.boxplot(by='dow')\nax.set_title('')\nax","6eef66b1":"work_activities = ['self','uni','work']\n\ns_overtime = pd.Series()\n\nfor day in df_i.date.unique():\n    deadline = pd.to_datetime(day)+pd.to_timedelta('20h')\n    tot = 0\n    over_deadline = df_i[(df_i.date==day) & (df_i.activity.isin(work_activities)) & (df_i.end_time > deadline)]\n    for i,row in over_deadline.iterrows():\n        if row.start_time > deadline:\n            tot += row.time\n        else:\n            tot += timedelta_to_scalar(row.end_time - deadline)\n    s_overtime[pd.to_datetime(day).strftime('%Y-%m-%d')] = tot\n    \ns_overtime.plot.bar(figsize=(16,6))","f5880531":"df_food = df_t.copy().filter(['cook','eat'],axis=1)\ndf_food.plot.bar(stacked=True, figsize=(16,6))","828addfe":"sns.distplot(df_food.cook,label='cook')\nsns.distplot(df_food.eat,label='eat')\n\nprint((df_food.cook <= 0.5).sum()\/len(df_food))\nplt.legend()","8fd902e4":"# Assume: eating alone would take 1h every day\neat_entertainment = df_t.eat.map(lambda x: max(0, x-1))\neat_entertainment.name = 'entertainment'\nsns.distplot(eat_entertainment)","c05bcff1":"all_entertainment = eat_entertainment + df_t.pause + df_t.music\nprint(all_entertainment.describe())\nsns.distplot(all_entertainment)","9f883a95":"df_sleep = pd.DataFrame(columns=['start','end','duration'])\n\ndays = df_t.index\n\nfor i,day in enumerate(days):\n\n    # We only know the end time of sleep for days where we have data for the next day, too\n    # So, exclude the last one\n\n    if i == len(days)-1:\n        df_sleep.loc[day] = [np.nan,np.nan,np.nan]\n        continue\n    \n    # Get last activity of the day (which should be sleep)\n    last_activity = df_i[df_i.date==day]\n    if not len(last_activity):\n        df_sleep.loc[day] = [np.nan,np.nan,np.nan]\n        continue\n    last_activity = last_activity.iloc[-1]\n    \n    if last_activity.activity != 'sleep':\n        df_sleep.loc[day] = [np.nan,np.nan,np.nan]\n        continue\n    \n    # Get the first activity of the next day\n    first_activity = df_i[df_i.date==days[i+1]]\n    if not len(first_activity):\n        df_sleep.loc[day] = [np.nan,np.nan,np.nan]\n        continue\n    first_activity = first_activity.iloc[0]\n    \n    # Calculate start and end of sleep\n    sleep_start = last_activity.start_time\n    sleep_end = first_activity.start_time\n    duration = timedelta_to_scalar(sleep_end-sleep_start)\n    df_sleep.loc[day] = [sleep_start, sleep_end, duration]\n\nplt.title('Distribution of sleep duration')\nsns.distplot(df_sleep.duration.dropna())","a333c039":"# Nap time = all time spent sleeping except the main sleeping time\n\ns_nap_time = df_t.sleep - df_sleep.duration\ndf_sleep['nap'] = s_nap_time\n\ndf_sleep.filter(['duration','nap'],axis=1).plot.bar(stacked=True,figsize=(16,5),title='Sleep split into main sleep and naps')","0c69bcea":"optimal_time = [pd.to_datetime(i)+pd.to_timedelta('22h 30min') for i in df_sleep.index]\nviolation = df_sleep.start - pd.Series(optimal_time,index=df_sleep.index)\nviolation = violation.map(timedelta_to_scalar)*60\nviolation.plot.bar(figsize=(16,6),color='blue')","3336c9cb":"df_tmp = df_prod[['total']].copy()\nfor i in range(len(df_tmp)):\n    if i == 0:\n        continue\n    df_tmp.loc[df_tmp.index[i],'prev_sleep'] = df_sleep.iloc[i-1].duration\ndf_tmp.head()\ndf_tmp.corr()","cb42d37e":"## Read data","5271f37d":"## Total time per activity ","d710e436":"## Violation: working after 8pm ","227379b7":"## Observation\n\n* It seems that I barely ever violate this rule\n* And if so, then only by less than 1h (except for one day)!","f4156ea3":"# Eat and cook","4cc3c0c0":"## Hypothesis: More sleep => higher productivity\n\nHypothesis: If I have slept more the day before (i.e. the main sleep cycle was longer), then my productivity on the current day tends to be higher\n* Idea: If you sleep for a long time, this replenishes your energy reserves, which makes you more productive\n* **This turned out to be wrong: Sleep and productivity are not correlated!**","33a59247":"## Violations: Going to bed later than 10:30pm\n\nI try to go to bed at 10:30pm. How often and by how much do I violate this rule?","e1d8262e":"## Observations\n\n* **cook**\n    * I spend around 40min every day with cooking, which is reasonable\n* **eat**\n    * I was surprised that it takes me a lot more time to eat than to cook. \n    * But this can be explained with me doing something else while eating (like watching news), which then unnecessarily prolongs it.\n* **math\/uni\/work**\n    * I spend around 4-5h every day purely with math and university, which is a solid number\n    * Since I am also working for >2h every day, this is an acceptable amount (in May, this was primarily Data Science!)\n* **sleep**\n    * Sleep could be less, but still within reasonable limits\n    * I am somewhat worried about the high standard deviation here (3h!)\n    * The regularity of my sleep could be better!\n* **prep**\n    * Here, I included everything from morning routines to sports to reflection to groceries shopping\n    * It was to be expected that this takes a lot of time (< 4h)\n* **music\/meditation\/pause**\n    * All 0.5h to 1h with relatively low variance\n    * They all leave room for improvement, but they all lie within reason","1abac1ee":"## Total productive time ","69777c23":"## Productive activities over time ","4581bbcc":"# EDA: Broad overview","9fd2a5db":"## Productivity per day-of-week ","b66afc08":"## Observations\n\n* I notice that I am doing a fairly consistent amount of work over time\n* Except for two days, I worked for 6-8h every day!","8a67478d":"## Observations\n\n* I still struggle follow it by the letter, but in the past month, I went to bed before 11pm nearly every day","7debbfa1":"# Exploration","412fa70d":"## Nap time ","80f768ae":"# Productivity ","3552c137":"## Productivity per week","9e4e56ad":"# Consequences\n\n* This analysis confirms most of the intuitions that I had\n* However, one pattern that surprised me was the inconsistency of my sleep time and the need to compensate it during the day with naps\n* This probably is related to not going to bed on time\n* One probable cause of this is eating dinner too late\n* The usual time that I eat dinner is between 7pm and 8pm\n* **As a real-life consequence of this data analysis, I am having dinner one hour earlier from now on!**","75cc411a":"## Observations\n\n* I worked for around 45h a week in May\n* However, for this plot to be meaningful, more data is needed","29ad14d9":"## Observations\n\n* I should cut down on eating time and see whether I could optimize the 'prep' column\n* Sleep in total is more than productive work, which is disillusioning","67e006df":"## Observations\n\n* First chart\n    * From the data on eating times, we can roughly conclude that I spend 0-2.5h on things other than eating\n* Second chart\n    * If we sum this data with 'pause' and 'music', the result is roughly the total amount of entertainment\n    * Which is quite stable at 2-2.5h (for >50% of days)\n    * The relatively low variance can be explained by the fact that one type of entertainment (e.g. music) typically makes another type unnecessary (e.g. pause); in the end, they add up to roughly the same amount\n    * This data also shows that there is room for improvement","17122327":"I try to stop working at 8pm. On some days, I overstep that rule. The following graph displays the exact amount of overtime.","1a420147":"## Observation\n\n* On around half of days (48%), I spend less than 30min on cooking\n* The most frequently occurring eating time is 2-2.5h, which is probably split on 1h for lunch and 1h for dinner","5216fb8b":"# Sleep","4d2e0f90":"## Observations\n\n* On most days, I sleep around 6.5-7h, which is approximately the recommended sleeping time\n* On some days, I sleep too much (> 10h)\n* It would be desirable to have more consistency (i.e. lower variance)","f8b69faf":"## Observations\n\n* My productivity varies greatly depending on the day of the week\n* Tuesdays and Thursdays are a lot more productive than Wednesdays and Fridays\n* It is surprising that the second most productive day is Saturday!","09ad5cdf":"## Describe()","eeed7f97":"## Entertainment ","4a922490":"## Observations\n\n* Relatively consistent work in the first part of the month (if you consider the total)\n* University suffered in the second part of the month\n* Only one day without work (due to a special occasion)\n* Gradual switch from university to work (i.e. learning Data Science)\n* Some days, I am very motivated to do math; they stand out (such as 2019-05-14)\n* Very productive days are often followed by less productive ones (such as 2019-05-28 and the day after)","35355ad5":"This is part of a [larger project](https:\/\/github.com\/maxims94\/life-tracking-project).","d878e54f":"Calculate the duration of the **main** sleep cycle, excluding naps","90ba4f44":"## Observations\n\n* I cook little on most days, except for those when I prepare meals for days to come (e.g. 2019-05-24)\n* Eating time is quite high, but this is because I generally do something else while eating"}}