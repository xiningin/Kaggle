{"cell_type":{"1e9ffc8c":"code","5cc7b04f":"code","bfdd1e0e":"code","1a99dbbe":"code","b5288bfd":"code","ab06008b":"code","defd20f5":"code","5deac9c6":"code","233b7ba0":"code","07f7f9cb":"code","5096f7a3":"code","f7e55caf":"code","ad0c5d80":"code","cd9a2987":"code","bcba6980":"code","d60a0f60":"code","26b69ae7":"code","4c20dadd":"code","773de327":"code","37fad3c3":"code","4aab89d0":"code","a3a50621":"code","6dbb6342":"code","76011186":"code","7a78a432":"code","0f7614e4":"code","c2137535":"code","fdd3ad80":"code","b854131d":"code","4c336a22":"code","b64a4867":"code","ab79dafa":"code","5f80314d":"code","9b4e2bb3":"code","b847c002":"code","6c60b0b7":"code","afc3cea6":"code","b8977cb1":"code","4065f821":"code","9950ec24":"markdown","48edd1f8":"markdown","6c5c742d":"markdown","942c267e":"markdown","7e01ab22":"markdown","97b50053":"markdown","cf879c16":"markdown","98e1625c":"markdown","4fc534f0":"markdown"},"source":{"1e9ffc8c":"# importing train and test data into train_df and test_df dataframes\nimport pandas as pd\n\ntrain = pd.read_csv('\/kaggle\/input\/sce-data-science-2020-course\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/sce-data-science-2020-course\/test.csv')","5cc7b04f":"train.head()","bfdd1e0e":"test.head()","1a99dbbe":"# printing training data information \n# (number of non-null observations, datatype)\nprint(train.info())\nprint('-'*100)\nprint(test.info())","b5288bfd":"# Pritting how many values are missing \nprint(train.isnull().sum())\nprint('-'*100)\nprint(test.isnull().sum())","ab06008b":"\n#get the mean value of Age colum \nmean_age_train=train.Age.dropna().mean()\ntrain.Age.fillna(mean_age_train,inplace=True)\nprint(\"Average of the Age column is =\", mean_age_train)","defd20f5":"# replace the NAN value in Age column of train data set by the mean value \ntrain[\"Age\"] = train [\"Age\"].fillna(mean_age_train)\ntest[\"Age\"] = test [\"Age\"].fillna(mean_age_train)\n\n#Display\nprint(test.info())\nprint('-'*100)\nprint(train.info())","5deac9c6":"# replace the NAN value in Fare column of test by the median value \ntest[\"Fare\"].fillna(test[\"Fare\"].median(), inplace=True)","233b7ba0":"#Display\nprint(test.info())\nprint('-'*100)\nprint(train.info())","07f7f9cb":"#The Name feature contains information on passenger's title.\n#Since some passenger with distingused title may be preferred during the evacuation, it is interesting to add them to the model.\n\n\n# Searching for the titles and extracting them from the names column (train and test)\nimport re\ntrain['Title'] = train['Name'].map(lambda x: re.compile(\"([A-Za-z]+)\\.\").search(x).group())\ntest['Title'] = test['Name'].map(lambda x: re.compile(\"([A-Za-z]+)\\.\").search(x).group())\nprint(train['Title'].unique())","5096f7a3":"\ntrain[\"Title\"].head()","f7e55caf":"# now we have titles for Nobels like Master, Capt...\n# replacing by Dummy value highest amount (4) to the lowest (0)\n# in train \n\ntitle_mapping = {'Mr.': 4, 'Mrs.': 3, 'Miss.': 2, 'Master.' : 1,'Don.': 0, 'Rev.' : 0,'Dr.' : 0,'Mme.': 0, 'Ms.': 0, 'Major.': 0,\n 'Lady.': 0, 'Sir.': 0, 'Mlle.': 0, 'Col.': 0, 'Capt.': 0, 'Countess.':3, 'Jonkheer.': 0,'Dona.': 0,}\n\ntrain['Title'] = train['Title'].map(title_mapping)\n\n\n    \nprint(train['Title'].unique())","ad0c5d80":"# now we have titles for Nobels like Master, Capt...\n# replacing by Dummy value highest amount (4) to the lowest (0)\n# in test\n\ntitle_mapping = {'Mr.': 4, 'Mrs.': 3, 'Miss.': 2, 'Master.' : 1,'Don.': 0, 'Rev.' : 0,'Dr.' : 0,'Mme.': 0, 'Ms.': 0, 'Major.': 0,\n 'Lady.': 0, 'Sir.': 0, 'Mlle.': 0, 'Col.': 0, 'Capt.': 0, 'Countess.':3, 'Jonkheer.': 0,'Dona.': 0,}\n\n\ntest['Title'] = test['Title'].map(title_mapping)\n\n\n    \nprint(test['Title'].unique())","cd9a2987":"# Creating new feature in name \"fsize\" descriptor from SibSp and Parch\n\ntrain[\"Fsize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"Fsize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1\n\n","bcba6980":"train.head()\n","d60a0f60":"#Creating new features of family size (single ,small family, medium family, large family)\n\ntrain['Single'] = train['Fsize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallF'] = train['Fsize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedF'] = train['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeF'] = train['Fsize'].map(lambda s: 1 if s >= 5 else 0)\n\ntest['Single'] = test['Fsize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallF'] = test['Fsize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedF'] = test['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeF'] = test['Fsize'].map(lambda s: 1 if s >= 5 else 0)\n\n","26b69ae7":"train.head(50)","4c20dadd":"#Drop features (name,ticket,cabin,parch,sibsp)\n\ntrain = train.drop([\"Name\", \"Ticket\", \"Cabin\",\"Parch\",\"SibSp\"], axis=1)\ntest = test.drop([\"Name\", \"Ticket\", \"Cabin\",\"Parch\",\"SibSp\"], axis=1)","773de327":"train.head()\n","37fad3c3":"test.head()","4aab89d0":"#Display of data information \n\ntrain.info()\ntest.info()","a3a50621":"#Now it shows the new dataframe without the dropped columns\n\ntrain.head()","6dbb6342":"test.head()","76011186":"#replacing text values to numeric values.\n\nimport numpy as np\ntrain.Survived = np. where(train.Survived == 'T', 1, 0)\ntrain.Sex = np. where(train.Sex == 'male', 1, 0)\ntest.Sex = np. where(test.Sex == 'male', 1, 0)\n","7a78a432":"train = pd.get_dummies(train)\ntest = pd.get_dummies(test)","0f7614e4":"#Now we can see that the 'Sex','Survived' and 'Embarked' are now numerical columns.\ntrain.head()","c2137535":"test.head()","fdd3ad80":"#Checks if there is a NaN value for the train data and test data\n\nprint(test.info())\nprint('-'*100)\nprint(train.info())","b854131d":"#Checks if there is a NaN value for the train data and test data\n\ntrain.info()\ntest.info()","4c336a22":"#Import the necessary modules for the model\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split ","b64a4867":"#Defining model variables\n\nX = train.drop(\"Survived\", axis=1)\ny = train[\"Survived\"]\nRF=RandomForestClassifier()\nRF.fit(X,y)","ab79dafa":"\ntrain.head()","5f80314d":"Xtrain, Xvalidation, Ytrain, Yvalidation = train_test_split(X, y, test_size=0.2, random_state=True)","9b4e2bb3":"#Model\nmodel = RandomForestClassifier(n_estimators=100,\n                               max_leaf_nodes=16,\n                               max_depth=16,\n                               random_state=1)\n\n#The model lerning from the data\nmodel.fit(Xtrain, Ytrain)\nmodel.score(Xtrain, Ytrain)","b847c002":"\nfrom sklearn.metrics import accuracy_score\nYprediction = model.predict(Xvalidation)\naccuracy_score(Yvalidation , Yprediction)\n","6c60b0b7":"test.head()","afc3cea6":"train.head()","b8977cb1":"#create a new dataframe for the submission\nYprediction = pd.DataFrame.from_dict(data = dict(Survived = model.predict(test), PassengerId = test[\"PassengerId\"]))\n\nYprediction['Survived'] = np.where(Yprediction['Survived']==1, \"T\", \"F\")\n\n# save the submission as a '.csv' file\nYprediction.to_csv(\"forest.csv\", index=False)\n\n","4065f821":"Yprediction.head(50)","9950ec24":"# Library","48edd1f8":"**Random Forests Model**","6c5c742d":"# Explore Dataset","942c267e":"# Data Model","7e01ab22":"# Engineer New Features","97b50053":"# Cleaning Data","cf879c16":"# Taking care of missing values","98e1625c":"# Prediction & Submission","4fc534f0":"modle and accuracy score\n"}}