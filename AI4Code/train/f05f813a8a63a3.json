{"cell_type":{"37f9532d":"code","e21ba178":"code","1d84e107":"code","de246bcb":"code","e4a27639":"code","a278abe8":"code","9ac02417":"code","d2fef954":"code","30edd6a9":"code","65c191e2":"code","be1396ce":"code","3698691e":"code","eac6f3bb":"code","8705ed9f":"code","eb618fcd":"code","3e572b0c":"code","df2baaed":"code","f109199e":"code","b484fbb4":"code","ef71e176":"code","47744711":"code","caf1234f":"code","57702c55":"code","648ecac2":"code","15412fc9":"code","e607b63a":"code","913190aa":"code","d2606d0c":"code","74268a0b":"code","f972bada":"code","f36b47ad":"code","682b27ba":"code","3ffa26e2":"markdown","66707f7c":"markdown","49352f0a":"markdown","b255dff4":"markdown","3dca640d":"markdown","17b021b2":"markdown","bb956913":"markdown","7f78e384":"markdown","3f609331":"markdown","60067349":"markdown","2af0705d":"markdown","66febe0c":"markdown","035f95f4":"markdown","63497e12":"markdown","bd717ced":"markdown","91be0ba7":"markdown","5fad257e":"markdown","43a9b3e7":"markdown","38d027aa":"markdown","53546bbb":"markdown","6b89be0f":"markdown","ea93bd85":"markdown","cd190849":"markdown","1d6b669a":"markdown","72af3d94":"markdown","53375f2e":"markdown","62c56d0b":"markdown","bde073db":"markdown","01002079":"markdown","c2dd6cc5":"markdown","c329488f":"markdown","ed186c01":"markdown","045b1efe":"markdown"},"source":{"37f9532d":"#invite people for the Kaggle party\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","e21ba178":"#bring in the six packs\ndf_train = pd.read_csv('..\/input\/train.csv')","1d84e107":"#check the decoration\n\ndf_train.columns","de246bcb":"#descriptive statistics summary\ndf_train['SalePrice'].describe()","e4a27639":"\n#histogram\nsns.distplot(df_train['SalePrice']);","a278abe8":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","9ac02417":"#scatter plot grlivarea\/saleprice\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","d2fef954":"#scatter plot totalbsmtsf\/saleprice\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","30edd6a9":"#box plot overallqual\/saleprice\nvar = 'OverallQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","65c191e2":"var = 'YearBuilt'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);","be1396ce":"#correlation matrix\ncorrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","3698691e":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","eac6f3bb":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df_train[cols], size = 2.5)\nplt.show();","8705ed9f":"#missing data\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","eb618fcd":"#dealing with missing data\ndf_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\ndf_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\ndf_train.isnull().sum().max() #just checking that there's no missing data missing...","3e572b0c":"#standardizing data\nsaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","df2baaed":"#bivariate analysis saleprice\/grlivarea\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","f109199e":"#deleting points\ndf_train.sort_values(by = 'GrLivArea', ascending = False)[:2]\ndf_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\ndf_train = df_train.drop(df_train[df_train['Id'] == 524].index)","b484fbb4":"#bivariate analysis saleprice\/grlivarea\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","ef71e176":"#histogram and normal probability plot\nsns.distplot(df_train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","47744711":"#applying log transformation\ndf_train['SalePrice'] = np.log(df_train['SalePrice'])","caf1234f":"#transformed histogram and normal probability plot\nsns.distplot(df_train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","57702c55":"#histogram and normal probability plot\nsns.distplot(df_train['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt)","648ecac2":"#data transformation\ndf_train['GrLivArea'] = np.log(df_train['GrLivArea'])","15412fc9":"#transformed histogram and normal probability plot\nsns.distplot(df_train['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt)","e607b63a":"#histogram and normal probability plot\nsns.distplot(df_train['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['TotalBsmtSF'], plot=plt)","913190aa":"#create column for new variable (one is enough because it's a binary categorical feature)\n#if area>0 it gets 1, for area==0 it gets 0\ndf_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\ndf_train['HasBsmt'] = 0 \ndf_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1","d2606d0c":"#transform data\ndf_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])","74268a0b":"#histogram and normal probability plot\nsns.distplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","f972bada":"#scatter plot\nplt.scatter(df_train['GrLivArea'], df_train['SalePrice']);","f36b47ad":"#scatter plot\nplt.scatter(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], df_train[df_train['TotalBsmtSF']>0]['SalePrice']);","682b27ba":"#convert categorical variable into dummy\ndf_train = pd.get_dummies(df_train)","3ffa26e2":"The point here is to test 'SalePrice' in a very lean way. We'll do this paying attention to:\n\n* <b>Histogram<\/b> - Kurtosis and skewness.\n* <b>Normal probability plot<\/b> - Data distribution should closely follow the diagonal that represents the normal distribution.","66707f7c":"Done! Let's check what's going on with 'GrLivArea'.","49352f0a":"# 4. Missing data\n\nImportant questions when thinking about missing data:\n\n* How prevalent is the missing data?\n* Is missing data random or does it have a pattern?\n\nThe answer to these questions is important for practical reasons because missing data can imply a reduction of the sample size. This can prevent us from proceeding with the analysis. Moreover, from a substantive perspective, we need to ensure that the missing data process is not biased and hidding an inconvenient truth.","b255dff4":"### In the search for normality","3dca640d":"# 2. First things first: analysing 'SalePrice'\n","17b021b2":"### Univariate analysis","bb956913":"*'Amazing! If my love calculator is correct, our success probability is 97.834657%. I think we should meet again! Please, keep my number and give me a call if you're free next Friday. See you in a while, crocodile!'*","7f78e384":"Get ready for what you're about to see. I must confess that the first time I saw these scatter plots I was totally blown away! So much information in so short space... It's just amazing. Once more, thank you @seaborn! You make me 'move like Jagger'!","3f609331":"# 'SalePrice', her buddies and her interests","60067349":"*'TotalBsmtSF' is also a great friend of 'SalePrice' but this seems a much more emotional relationship! Everything is ok and suddenly, in a <b>strong linear (exponential?)<\/b> reaction, everything changes. Moreover, it's clear that sometimes 'TotalBsmtSF' closes in itself and gives zero credit to 'SalePrice'.*","2af0705d":"We can feel tempted to eliminate some observations (e.g. TotalBsmtSF > 3000) but I suppose it's not worth it. We can live with that, so we'll not do anything.","66febe0c":"### Relationship with categorical features","035f95f4":"Next, please...","63497e12":"# 3. Keep calm and work smart","bd717ced":"*'Ah! I see you that you use seaborn makeup when you're going out... That's so elegant! I also see that you:*\n\n* *<b>Deviate from the normal distribution.<\/b>*\n* *<b>Have appreciable positive skewness.<\/b>*\n* *<b>Show peakedness.<\/b>*\n\n*This is getting interesting! 'SalePrice', could you give me your body measures?'*","91be0ba7":"Older versions of this scatter plot (previous to log transformations), had a conic shape (go back and check 'Scatter plots between 'SalePrice' and correlated variables (move like Jagger style)'). As you can see, the current scatter plot doesn't have a conic shape anymore. That's the power of normality! Just by ensuring normality in some variables, we solved the homoscedasticity problem.\n\nNow let's check 'SalePrice' with 'TotalBsmtSF'.","5fad257e":"#### Correlation matrix (heatmap style)","43a9b3e7":"### In the search for writing 'homoscedasticity' right at the first attempt","38d027aa":"### Bivariate analysis","53546bbb":"Easy mode.","6b89be0f":"1. <b>Understand the problem<\/b>. We'll look at each variable and do a philosophical analysis about their meaning and importance for this problem.\n2. <b>Univariable study<\/b>. We'll just focus on the dependent variable ('SalePrice') and try to know a little bit more about it.\n3. <b>Multivariate study<\/b>. We'll try to understand how the dependent variable and independent variables relate.\n4. <b>Basic cleaning<\/b>. We'll clean the dataset and handle the missing data, outliers and categorical variables.\n5. <b>Test assumptions<\/b>. We'll check if our data meets the assumptions required by most multivariate techniques.\n\nNow, it's time to have fun!","ea93bd85":"# 1. So... What can we expect?\n* OverallQual (which is a variable that I don't like because I don't know how it was computed; a funny exercise would be to predict 'OverallQual' using all the other variables available).\n* YearBuilt.\n* TotalBsmtSF.\n* GrLivArea.\n","cd190849":"#### 'SalePrice' correlation matrix (zoomed heatmap style)","1d6b669a":"*Hmmm... It seems that 'SalePrice' and 'GrLivArea' are really old friends, with a <b>linear relationship.<\/b>*\n\n*And what about 'TotalBsmtSF'?*","72af3d94":"#### Scatter plots between 'SalePrice' and correlated variables (move like Jagger style)","53375f2e":"# Acknowledgements\n\nThanks to [Jo\u00e3o Rico](https:\/\/www.linkedin.com\/in\/joaomiguelrico\/) for reading drafts of this.","62c56d0b":"# Last but not the least, dummy variables","bde073db":"*Although it's not a strong tendency, I'd say that 'SalePrice' is more prone to spend more money in new stuff than in old relics.*\n\n<b>Note<\/b>: we don't know if 'SalePrice' is in constant prices. Constant prices try to remove the effect of inflation. If 'SalePrice' is not in constant prices, it should be, so than prices are comparable over the years.","01002079":"*Like all the pretty girls, 'SalePrice' enjoys 'OverallQual'. Note to self: consider whether McDonald's is suitable for the first date.*","c2dd6cc5":"We can say that, in general, 'SalePrice' exhibit equal levels of variance across the range of 'TotalBsmtSF'. Cool!","c329488f":"*'Very well... It seems that your minimum price is larger than zero. Excellent! You don't have one of those personal traits that would destroy my model! Do you have any picture that you can send me? I don't know... like, you in the beach... or maybe a selfie in the gym?'*","ed186c01":"> @ EXPLORATORY DATA ANALYSIS(EDA) WITH PYTHON\n - August 2019","045b1efe":"### Relationship with numerical variables"}}