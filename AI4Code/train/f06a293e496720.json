{"cell_type":{"fd64f93b":"code","7a796e9d":"code","18e365dd":"code","723e5a06":"code","b7260d28":"code","66be8e93":"code","0874f573":"code","9e9bae2f":"code","17662e28":"code","91c032b5":"code","e14c3c7c":"code","59766c79":"markdown","cb4d151e":"markdown","3b0d7069":"markdown","98913305":"markdown","7eced2af":"markdown"},"source":{"fd64f93b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7a796e9d":"from matplotlib import pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\nimport seaborn as sns","18e365dd":"train_data = pd.read_csv(\"..\/input\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\ntrain_data.head(3)","723e5a06":"train_data.info()","b7260d28":"def extract_ticket(ticket):\n    ticket = ticket.replace('.', '').replace('\/', '').split()\n    if len(ticket) > 1:\n        return ticket[0]\n    else:\n        return \"X\"\n\ndef map_family_size(size):\n    if size < 2:\n        return \"Single\"\n    elif 2 <= size < 4:\n        return \"Small\"\n    else:\n        return \"Large\"\n\nX_train = train_data[[\"Name\", \"Sex\", \"Age\", \"Pclass\", \"Fare\", \"Embarked\", \"SibSp\", \"Parch\", \"Cabin\", \"Ticket\"]]\nX_test = test_data[[\"Name\", \"Sex\", \"Age\", \"Pclass\", \"Fare\", \"Embarked\", \"SibSp\", \"Parch\", \"Cabin\", \"Ticket\"]]\ny_train = train_data[\"Survived\"]\n\nX_train[\"Honorific\"] = X_train[\"Name\"].map(lambda name: name.split('.')[0].split(', ')[-1])\nX_test[\"Honorific\"] = X_test[\"Name\"].map(lambda name: name.split('.')[0].split(', ')[-1])\nX_train.drop(\"Name\", axis=1, inplace=True)\nX_test.drop(\"Name\", axis=1, inplace=True)\n\nX_train[\"RelativesCount\"] = X_train[\"SibSp\"].combine(X_train[\"Parch\"], lambda x1, x2: x1+x2)\nX_test[\"RelativesCount\"] = X_test[\"SibSp\"].combine(X_test[\"Parch\"], lambda x1, x2: x1+x2)\nX_train.drop([\"SibSp\", \"Parch\"], axis=1, inplace=True)\nX_test.drop([\"SibSp\", \"Parch\"], axis=1, inplace=True)\n\nX_train[\"FamilySize\"] = X_train[\"RelativesCount\"].add(1).map(map_family_size)\nX_test[\"FamilySize\"] = X_test[\"RelativesCount\"].add(1).map(map_family_size)\n\nX_train[\"Deck\"] = X_train[\"Cabin\"].fillna('U').map(lambda s: s[0])\nX_test[\"Deck\"] = X_test[\"Cabin\"].fillna('U').map(lambda s: s[0])\nX_train.drop(\"Cabin\", axis=1, inplace=True)\nX_test.drop(\"Cabin\", axis=1, inplace=True)\n\nX_train[\"Ticket\"] = X_train[\"Ticket\"].map(extract_ticket)","66be8e93":"X_train[\"Age\"].fillna(X_train[\"Age\"].median(), inplace=True)\nX_test[\"Age\"].fillna(X_test[\"Age\"].median(), inplace=True)\n\nX_train[\"Embarked\"].fillna(X_train[\"Embarked\"].mode().values[0], inplace=True)\nX_test[\"Embarked\"].fillna(X_train[\"Embarked\"].mode().values[0], inplace=True)\n\nX_train[\"Fare\"].fillna(X_train[\"Fare\"].mean(), inplace=True)\nX_test[\"Fare\"].fillna(X_train[\"Fare\"].mean(), inplace=True)\n\nX_train[\"Pclass\"] = X_train[\"Pclass\"].astype(\"str\")\nX_test[\"Pclass\"] = X_test[\"Pclass\"].astype(\"str\")\n\nX_train = pd.get_dummies(X_train, columns=[\"Honorific\", \"Sex\", \"Pclass\", \"Embarked\", \"Deck\", \"Ticket\", \"FamilySize\"])\nX_test = pd.get_dummies(X_test, columns=[\"Honorific\", \"Sex\", \"Pclass\", \"Embarked\", \"Deck\", \"Ticket\", \"FamilySize\"])\n\nextra_columns = set(X_train.columns) - set(X_test.columns)\nfor col in extra_columns:\n    X_test[col] = 0\nX_test = X_test[X_train.columns]\nX_train.head()","0874f573":"params = {\n    \"n_estimators\": [10, 20, 30, 50, 100, 150, 200],\n    \"criterion\": [\"gini\", \"entropy\"],\n    \"max_features\": [\"auto\", \"sqrt\", \"log2\", None],\n    \"max_depth\": list(range(2, 11)) + [None]\n}\ngs = GridSearchCV(estimator=RandomForestClassifier(), param_grid=params, cv=5, scoring=\"accuracy\")\ngs.fit(X_train, y_train)\ngs.best_params_","9e9bae2f":"model = RandomForestClassifier(**gs.best_params_)\nmodel.fit(X_train, y_train)","17662e28":"print(\"Train score:\", model.score(X_train, y_train))\nprint(\"CV score:\", cross_val_score(model, X_train, y_train, scoring=\"accuracy\", cv=5).mean())","91c032b5":"y_pred = model.predict(X_test)\nresult = test_data[[\"PassengerId\"]].assign(Survived=y_pred)\nresult.head()","e14c3c7c":"result.to_csv(\"predictions.csv\", index=False)","59766c79":"# Parameter tuning","cb4d151e":"# Evaluating","3b0d7069":"# Feature Extraction","98913305":"# Preprocessing","7eced2af":"# Learning"}}