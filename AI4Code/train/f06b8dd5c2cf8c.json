{"cell_type":{"619a4b57":"code","04d36a5c":"code","e72dba4b":"code","ad73de5c":"code","94e700d0":"code","fd28ebfe":"code","b52d782c":"code","6f70df83":"code","bc6ed19c":"code","d5763055":"code","40c25a97":"code","dccda2ce":"code","b6feeed7":"code","8f343718":"code","c345176d":"code","07740973":"code","efa72f40":"code","da5a91b6":"code","4cc518f7":"code","f2f64e4c":"code","fc1f5363":"code","541b2f8b":"code","040b3f8e":"code","c94aa409":"code","2905a047":"code","f2cb44d5":"code","fdaf6413":"code","7783d04b":"code","91f641d2":"code","b92f3413":"code","e93a3913":"code","55c1f6f2":"code","4da66922":"code","1d12c023":"code","b479c496":"code","93082234":"code","facafc6b":"code","1866a77a":"code","0f7620ff":"code","0d134a3a":"markdown","5f0c6227":"markdown","1c6a0d09":"markdown","fce69b3f":"markdown","b3fe6fc4":"markdown","49fca21a":"markdown","d57d4f4e":"markdown","637704b5":"markdown","6ea93fea":"markdown"},"source":{"619a4b57":"# importing necessary libraries\nimport pandas as pd\nimport pandas_profiling\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error,accuracy_score\nfrom xgboost import XGBRegressor","04d36a5c":"# reading train data\ndf_train=pd.read_csv('..\/input\/titanic\/train.csv')\ndf_train.head()","e72dba4b":"# reading test data\ndf_test=pd.read_csv('..\/input\/titanic\/test.csv')\ndf_test.head()","ad73de5c":"print(f\"Test data shape {df_test.shape} \")\nprint(f\"Train data shape {df_train.shape}\")","94e700d0":"# information related to the data\nprint(\"Train data\")\ndisplay(df_train.info())\nprint(\"Test data\")\ndisplay(df_test.info())","fd28ebfe":"# checking statistical data related to info\nprint(\"Train Data\")\ndisplay(df_train.describe())\nprint(\"Test Data\")\ndisplay(df_test.describe())","b52d782c":"pandas_profiling.ProfileReport(df_train)","6f70df83":"def plot_bar(df,feat_x,feat_y,normalize=True):\n    \"\"\" Plot with vertical bars of the requested dataframe and features\"\"\"\n    \n    ct = pd.crosstab(df[feat_x], df[feat_y])\n    if normalize == True:\n        ct = ct.div(ct.sum(axis=1), axis=0)\n    return ct.plot(kind='bar', stacked=True)","bc6ed19c":"plot_bar(df_train,'Pclass','Survived')\nplt.title('Pclass VS Survived')","d5763055":"plot_bar(df_train,'Sex','Survived')\nplt.title('Sex VS Survived')","40c25a97":"# checking for missing values\nprint(\"Missing values  in the training data\")\ndisplay(df_train.isnull().sum())\nprint(\"Missing values in the test data\")\ndisplay(df_test.isnull().sum())","dccda2ce":"# checking for percent of missing values in the data\nprint(\"Train data\")\ndisplay(df_train.isnull().sum()\/len(df_train))\nprint(\"Test data\")\ndisplay(df_test.isnull().sum()\/len(df_test))","b6feeed7":"# cabin data is missing in both the datasets at a considerable amount\n# so we can drop the column\ndf_test.drop('Cabin',axis=1,inplace=True)\ndf_train.drop('Cabin',axis=1,inplace=True)\n\ndisplay(df_test.head())\ndisplay(df_train.head())","8f343718":"# we can replace the missing values with the medai for age\ndf_test['Age']=df_test['Age'].fillna(df_test['Age'].median())\ndf_train['Age']=df_train['Age'].fillna(df_train['Age'].median())","c345176d":"# for embarked values , check  which is the place most people embarked from\ndisplay(df_train.loc[df_train['Embarked'].isnull()])\ndf_train['Embarked'].value_counts(normalize=True)","07740973":"# replacing the missing embarked values with 'S'\ndf_train['Embarked']=df_train['Embarked'].fillna('S')","efa72f40":"# for the missing fare value, simply replace it with the median\ndf_test['Fare']=df_test.fillna(df_test['Fare'].median())","da5a91b6":"# printing missing values in the datasets\nprint(\"Test data\")\ndisplay(df_test.isnull().sum())\nprint(\"Train data\")\ndisplay(df_train.isnull().sum())","4cc518f7":"# finding co-relatoin between survivors\nplt.figure(figsize=(15,7))\nsns.heatmap(df_train.corr(),annot=True,cmap='YlGnBu')","f2f64e4c":"# from the heatmap we cann find that survival is highly corealed to Pclass and Fare","fc1f5363":"plt.figure(figsize=(15,7))\nsns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=df_train)","541b2f8b":"plt.figure(figsize=(15,7))\nsns.countplot(x='Survived',hue='Pclass',data=df_train,palette='rainbow')","040b3f8e":"from sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder() \ndf_train['Embarked']= label_encoder.fit_transform(df_train['Embarked']) \ndf_train['Sex']= label_encoder.fit_transform(df_train['Sex'])\ndf_test['Embarked']= label_encoder.fit_transform(df_test['Embarked']) \ndf_test['Sex']= label_encoder.fit_transform(df_test['Sex'])","c94aa409":"df_train.head()","2905a047":"# dropping non-usefull columns\ndf_test.drop(['Name','Ticket'],axis=1,inplace=True)\ndf_train.drop(['Name','Ticket'],axis=1,inplace=True)","f2cb44d5":"df_test.head()","fdaf6413":"from sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\ndf_train[['Age','Fare']]=scaler.fit_transform(df_train[['Age','Fare']])\ndf_test[['Age','Fare']]=scaler.fit_transform(df_test[['Age','Fare']])","7783d04b":"df_train.head()","91f641d2":"from sklearn.linear_model import LogisticRegression\n\nX_train = df_train.drop(['Survived','PassengerId'], axis=1)\ny_train = df_train[\"Survived\"]\nX_test  = df_test.drop(\"PassengerId\", axis=1)\nX_train.shape, y_train.shape, X_test.shape","b92f3413":"LR=LogisticRegression(max_iter=1000,random_state=1)\nLR.fit(X_train,y_train)\n\n# making predictions\ny_pred=LR.predict(X_test)","e93a3913":"# finding accuracy\nprint(\"Accuracy:\",round(LR.score(X_train, y_train)*100,2))","55c1f6f2":"dfs = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nfile = {\"PassengerId\":dfs[\"PassengerId\"],\"Survived\":y_pred}\nfile = pd.DataFrame(file)\n\nfile.to_csv(\"submission_Lr.csv\",index=False)","4da66922":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\npred = clf.predict(X_test)\n\n\nprint(\"Accuracy\",round(clf.score(X_train,y_train)*100,2))\n\n\ndfs = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nfile = {\"PassengerId\":dfs[\"PassengerId\"],\"Survived\":pred}\nfile = pd.DataFrame(file)\n\nfile.to_csv(\"submission_dt.csv\",index=False)","1d12c023":"train_x,val_x,train_y,val_y=train_test_split(X_train,y_train)","b479c496":"from sklearn.ensemble import RandomForestRegressor\n\n#Create a Gaussian Classifier\nclf=RandomForestRegressor(n_estimators=100)\n\nclf.fit(train_x,train_y)\npred=clf.predict(val_x)\n\nprint(\"MEA\",mean_absolute_error(pred,val_y))\nprint(\"RMSE\",mean_squared_error(pred,val_y,squared=False))","93082234":"#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\npred=clf.predict(X_test)\n\n# dfs = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nfile1 = {\"PassengerId\":dfs[\"PassengerId\"],\"Survived\":pred}\nfile1 = pd.DataFrame(file)\n\nfile.to_csv(\"submission_Rf.csv\",index=False)","facafc6b":"file.head()","1866a77a":"clf.score(X_train, y_train)\nrandom_forest = round(clf.score(X_train, y_train) * 100, 2)\nrandom_forest","0f7620ff":"file.head()","0d134a3a":"#  Understanding the Data","5f0c6227":"# Categorical Values to Numerical values","1c6a0d09":"# Cleaning the data","fce69b3f":"# Random Forest","b3fe6fc4":"> You  dont always have to find the missing values from the data , if you search wikipedia for the titanic data , you can find that these people \nwhose embarked values are missing embarked from Southampton.\nAlways keep in mind that Data Scince is not always about coding , its sometimes about research","49fca21a":"# Logistic Regression","d57d4f4e":"# Scaling","637704b5":"# Visualizing","6ea93fea":"# Decision Tree\n"}}