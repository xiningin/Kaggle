{"cell_type":{"5fb7de1b":"code","09439561":"code","e550adab":"code","b2dce2a9":"code","93afc45c":"code","eeb567db":"code","9d6a878c":"code","c746d997":"code","75327abe":"code","43823194":"code","a23e291d":"code","2857c38c":"code","3176880e":"code","f1f86066":"code","b3379bcd":"code","982b38af":"code","e3e8471d":"code","705cd911":"code","cbb1b656":"code","80717e23":"code","7be13a46":"code","3e3d4119":"code","a7b72749":"code","f120f853":"code","0f63131e":"code","837bdaea":"code","5cdb860b":"code","ced60cab":"code","5f329db4":"markdown","335fe91c":"markdown","f932f560":"markdown","d5d10394":"markdown","cf4e023c":"markdown","a831f22d":"markdown","4fa77427":"markdown","01c98e33":"markdown"},"source":{"5fb7de1b":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","09439561":"\n# standard\n#import numpy as np\n#import pandas as pd\n#import time\n\n# plots\n#import matplotlib.pyplot as plt\n#import seaborn as sns\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n","e550adab":"# load data + first glance\n#train = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\n#test = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')\n\n# first glance (training data)\n#train.head()\nLOCAL_FLAG = False\n\nINPUT_PATH = '\/kaggle\/input\/tabular-playground-series-mar-2021\/'\nTRAIN_FILE = 'train.csv'\nTEST_FILE = 'test.csv'\nSUBMISSION_FILE = 'sample_submission.csv'\n\n\nEARLY_STOPPING_ROUNDS = 200\nNUM_FOLDS = 10\nSEED = 42\n","b2dce2a9":"\n\n#cont_features = [\n #   \"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\", \"cont6\", \"cont7\",\n  #  \"cont8\", \"cont9\", \"cont10\",\n#]\n#cat_features = [\n #   \"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\",\n  #  \"cat8\", \"cat9\", \"cat10\", \"cat11\", \"cat12\", \"cat13\", \"cat14\", \"cat15\",\n  #  \"cat16\", \"cat17\", \"cat18\"\n#]\n#target = train[\"target\"]\n\ntrain = pd.read_csv(INPUT_PATH + TRAIN_FILE, index_col='id')\ntest = pd.read_csv(INPUT_PATH + TEST_FILE, index_col='id')\nsubmission = pd.read_csv(INPUT_PATH + SUBMISSION_FILE, index_col='id')\n\n","93afc45c":"print(train.nunique())","eeb567db":"#from category_encoders import LeaveOneOutEncoder\n#from sklearn.preprocessing import LabelEncoder\n\n#xgb_cat_features = []\n#lgb_cat_features = []\n#cb_cat_features = []\n#ridge_cat_features = []\n#hgbc_cat_features = []\n\n#loo_features = []\n#le_features = []\n\n#def label_encode(train_df, test_df, column):\n #   le = LabelEncoder()\n  #  new_feature = \"{}_le\".format(column)\n   # le.fit(train_df[column].unique().tolist() + test_df[column].unique().tolist())\n   # train_df[new_feature] = le.transform(train_df[column])\n   # test_df[new_feature] = le.transform(test_df[column])\n   # return new_feature\n\n#def loo_encode(train_df, test_df, column):\n #   loo = LeaveOneOutEncoder()\n  #  new_feature = \"{}_loo\".format(column)\n   # loo.fit(train_df[column], train_df[\"target\"])\n    #train_df[new_feature] = loo.transform(train_df[column])\n    #test_df[new_feature] = loo.transform(test_df[column])\n    #return new_feature\n\n#for feature in cat_features:\n #   loo_features.append(loo_encode(train, test, feature))\n  #  le_features.append(label_encode(train, test, feature))\n    \n#xgb_cat_features.extend(loo_features)\n#lgb_cat_features.extend(le_features)\n#cb_cat_features.extend(cat_features)\n#ridge_cat_features.extend(loo_features)\n#hgbc_cat_features.extend(loo_features)\n\n\nfor c in train.columns:\n    if train[c].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(train[c].values) + list(test[c].values))\n        train[c] = lbl.transform(train[c].values)\n        test[c] = lbl.transform(test[c].values)\n        \ntrain.head()","9d6a878c":"target = train.pop('target')","c746d997":"target = target.to_numpy()","75327abe":"target.shape","43823194":"columns = test.columns","a23e291d":"print(columns)","2857c38c":"train = pd.read_csv(INPUT_PATH + TRAIN_FILE, index_col='id')\ntest = pd.read_csv(INPUT_PATH + TEST_FILE, index_col='id')\n\nfor c in train.columns:\n    if train[c].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(train[c].values) + list(test[c].values))\n        train[c] = lbl.transform(train[c].values)\n        test[c] = lbl.transform(test[c].values)\n\n        \ntarget = train.pop('target')\ntarget = target.to_numpy()","3176880e":"def cross_valid(model, train, target, num_folds=10, random_state=42):#, init_model=pretrain_lgbm):\n\n    train_oof = np.zeros((len(train)))\n    test_preds = 0\n\n    kf = StratifiedKFold(n_splits=num_folds, random_state=SEED, shuffle=True)\n    aucs=[]\n\n    for f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        \n        train_target, val_target = target[train_ind], target[val_ind]\n\n        model.fit(train_df, \n        train_target,\n        eval_set= [(train_df, train_target), (val_df, val_target)], \n        eval_metric='auc', \n        verbose=0,\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n        #init_model=pretrain_lgbm,\n        )\n        \n        \n        temp_oof = model.predict_proba(val_df)[:, 1]\n        temp_test = model.predict_proba(test[columns])[:, 1]\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test\/num_folds\n        \n        aucs.append(roc_auc_score(val_target, temp_oof))\n        \n        print(f'Fold {f}: {roc_auc_score(val_target, temp_oof)}')\n        \n    print(\"Mean ROC AUC Score: \", np.mean(aucs))\n    \n    return train_oof, test_preds, np.mean(aucs)\n","f1f86066":"lgb_params={\n    'learning_rate': 0.01,\n    'metric': 'auc',\n    'n_estimators': 10000,\n    'num_leaves': 20067,\n    'max_depth': 27,\n    'reg_alpha': 9.630576598001266,\n    'reg_lambda': 2.346945113164939,\n    'colsample_bytree': 0.29858836720777177,\n    'subsample': 0.6267448547447422,\n    'min_child_samples': 61,\n    'subsample_freq': 2,\n    'subsample': 0.8329687190743886,\n    'max_bin': 899,\n    'min_data_per_group': 73,\n    'random_state': SEED,\n    'n_jobs': -1,\n    'bagging_seed': SEED,\n    'feature_fraction_seed': SEED\n}\n\n\nclf1 = LGBMClassifier(**lgb_params)\n\ntrain_oof_1, test_preds_1, score_oof_1 = cross_valid(clf1, train, target, num_folds=NUM_FOLDS, random_state=SEED)","b3379bcd":"print(f'Score oof: {score_oof_1:0.5f}') ","982b38af":"clf2  = LGBMClassifier(\n        n_estimators=12000,\n        num_leaves=105,\n        colsample_bytree=.8,\n        subsample=.8,\n        max_depth=7,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01\n    )\n\ntrain_oof_2, test_preds_2, score_oof_2 = cross_valid(clf2, train, target, num_folds=NUM_FOLDS, random_state=SEED)","e3e8471d":"print(f'Score oof: {score_oof_2:0.5f}') ","705cd911":"clf3 = LGBMClassifier(\n        n_estimators=12000,\n        num_leaves=50,\n        colsample_bytree=.8,\n        subsample=.8,\n        max_depth=8,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01\n    )\n\ntrain_oof_3, test_preds_3, score_oof_3 = cross_valid(clf3, train, target, num_folds=NUM_FOLDS, random_state=SEED)","cbb1b656":"print(f'Score oof: {score_oof_3:0.5f}') ","80717e23":"tt1 = clf1.predict_proba(test)[:, 1]\ntt2 = clf2.predict_proba(test)[:, 1]\ntt3 = clf3.predict_proba(test)[:, 1]","7be13a46":"submission['target'] = (test_preds_1 + test_preds_2 + test_preds_3)\/3 #(res['x'][0]*tt1+res['x'][1]*tt2+res['x'][2]*tt3)\/3\nsubmission.to_csv('submission.csv')\nsubmission.head()\n","3e3d4119":"submission['target'] =  (test_preds_1)#(res['x'][0]*tt1+res['x'][1]*tt2+res['x'][2]*tt3)\/3\nsubmission.to_csv('submission_model_1.csv')\nsubmission.head()\n","a7b72749":"submission['target'] =  (test_preds_2) #(res['x'][0]*tt1+res['x'][1]*tt2+res['x'][2]*tt3)\/3\nsubmission.to_csv('submission_model_2.csv')\nsubmission.head()","f120f853":"submission['target'] =  (test_preds_3) #(res['x'][0]*tt1+res['x'][1]*tt2+res['x'][2]*tt3)\/3\nsubmission.to_csv('submission_model_3.csv')\nsubmission.head()","0f63131e":"features_num = ['cont0', 'cont1', 'cont2', 'cont3', \n                'cont4', 'cont5', 'cont6', 'cont7',\n                'cont8', 'cont9', 'cont10']\n\n# plot distribution of numerical features\nfor f in features_num:\n    plt.figure(figsize=(8,4))\n    train[f].plot(kind='hist', bins=100)\n    plt.title(f)\n    plt.grid()\n    plt.show()\n","837bdaea":"import seaborn as sns\ncorr_pearson = train[features_num].corr(method='pearson')\ncorr_spearman = train[features_num].corr(method='spearman')\n\nfig = plt.figure(figsize = (12,9))\nsns.heatmap(corr_pearson, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\nplt.show()","5cdb860b":"\n\n# example of scatter plot - we pick pair having highest (Pearson) correlation\nsns.jointplot(data=train, x='cont5', y='cont10',\n              joint_kws = {'alpha': 0.1})\nplt.show()\n\n","ced60cab":"features_cat = ['cat0', 'cat1', 'cat2', 'cat3',\n                'cat4', 'cat5', 'cat6', 'cat7',\n                'cat8', 'cat9']\n\n# plot distribution of categorical features\nfor f in features_cat:\n    plt.figure(figsize=(8,4))\n    train[f].value_counts().plot(kind='bar')\n    plt.title(f)\n    plt.grid()\n    plt.show()","5f329db4":"# Some Visualizations","335fe91c":"## Categorical Feature Plot","f932f560":"## Libraries","d5d10394":"## Scatter plot","cf4e023c":"#### Implementation Part is at the start of Notebook, VIsualisation part is at the End.","a831f22d":"# Correlation","4fa77427":"## Data Import","01c98e33":"Thank You"}}