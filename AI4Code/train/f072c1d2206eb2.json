{"cell_type":{"6b26ba9a":"code","ff6ef0b4":"code","37e55d31":"code","9e159abc":"code","e838570c":"code","ded94b4e":"code","057ccfbd":"code","166491f0":"code","8176d193":"code","5e737931":"code","ae9093fc":"code","e86e8fef":"code","d2bcc84a":"code","7d27eeb1":"code","bcb4f331":"code","60d81af7":"code","e0d5e2fa":"code","d18904f7":"code","239e1a72":"code","1772b275":"code","d66a2320":"code","53348f3a":"code","dbf1db1e":"code","a3dadedc":"code","05d8034d":"code","6ea1a3a3":"code","d386b7d4":"code","42ff8564":"code","62c06c98":"code","956310c9":"code","5fb0537a":"code","a7108005":"code","a851c8f6":"code","edb26436":"code","c1cda917":"code","231a8b81":"code","ac0ddc49":"code","16a70b64":"code","79629769":"code","d38338a0":"code","92f0033c":"code","4338e56f":"code","7ef15c5b":"code","38d9a791":"code","acab1181":"code","f599e7c7":"code","4baeea65":"code","cb7e8995":"code","c1c32d3e":"code","9c8a7f9c":"code","fdb5a664":"markdown","2db7b3e3":"markdown","de15f416":"markdown","dd6c68c4":"markdown","eb872018":"markdown","38113e67":"markdown"},"source":{"6b26ba9a":"import numpy as np\nimport os\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn import model_selection\nimport gc\nfrom fastai.vision.all import *","ff6ef0b4":"seed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","37e55d31":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'","9e159abc":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nfrom timm import create_model","e838570c":"#best ensamble","ded94b4e":"set_seed(999, reproducible=True)\nBATCH_SIZE = 8","057ccfbd":"dataset_path = Path('..\/input\/petfinder-pawpularity-score\/')\ndataset_path.ls()","166491f0":"train_df = pd.read_csv(dataset_path\/'train.csv')\ntrain_df.head()","8176d193":"train_df['path'] = train_df['Id'].map(lambda x:str(dataset_path\/'train'\/x)+'.jpg')\ntrain_df = train_df.drop(columns=['Id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head()","5e737931":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")","ae9093fc":"train_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")","e86e8fef":"print(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")","d2bcc84a":"train_df['norm_score'] = train_df['Pawpularity']\/100\ntrain_df['norm_score']","7d27eeb1":"im = Image.open(train_df['path'][1])\nwidth, height = im.size\nprint(width,height)","bcb4f331":"im","60d81af7":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-large-transformer\/swin_large_patch4_window12_384_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window12_384_22kto1k.pth'\n","e0d5e2fa":"#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\n# num_bins","d18904f7":"train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","239e1a72":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\n\nN_FOLDS = 5\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","1772b275":"train_df[train_df['fold']==0].head()","d66a2320":"train_df[train_df['fold']==0]['bins'].value_counts()","53348f3a":"train_df[train_df['fold']==1]['bins'].value_counts()","dbf1db1e":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","a3dadedc":"def get_data_384(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n                               valid_col='is_valid', #\n                               seed=999, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               shuffle=False,\n                               item_tfms=Resize(384), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n    \n    return dls","05d8034d":"def get_data_224(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n                               valid_col='is_valid', #\n                               seed=999, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               shuffle=False,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n    \n    return dls","6ea1a3a3":"#Valid Kfolder size\nthe_data = get_data_384(0)\n#assert (len(the_data.train) + len(the_data.valid)) == (len(train_df)\/\/BATCH_SIZE)","d386b7d4":"def get_learner_384(fold_num):\n    data = get_data_384(fold_num)\n    \n    model = create_model('swin_large_patch4_window12_384', pretrained=True, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse)\n    \n    return learn","42ff8564":"def get_learner_224(fold_num):\n    data = get_data_224(fold_num)\n    \n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse)\n    \n    return learn","62c06c98":"test_df = pd.read_csv(dataset_path\/'test.csv')\ntest_df.head()","956310c9":"test_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path\/'test'\/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\ntrain_df['norm_score'] = train_df['Pawpularity']\/100","5fb0537a":"#get_learner(fold_num=0).lr_find(end_lr=3e-2)","a7108005":"import gc","a851c8f6":"class eval_after_N_steps(Callback):\n    \n    def __init__(self,fold=None,n_step=None,start_epoch=0):\n        self.counter = 0\n        self.start_epoch = start_epoch\n        self.n_step = n_step\n        self.fold = fold\n        self.best_rmse = 100000000\n        \n    def before_batch(self):\n        self.counter = self.counter + 1\n        if self.fold != None:\n            if self.counter % self.n_step == 0 and int(self.counter\/247) >= self.start_epoch :\n                preds_list = []\n                targ_list = []\n                current_rmse_loss_list = []\n                with torch.no_grad(): \n                    for xb,yb in learn.dls.valid:\n                        preds = self.learn.model(xb)\n                        current_rmse_loss_list.append(petfinder_rmse(preds,yb))\n                    current_rmse_loss_array = np.array(current_rmse_loss_list,dtype='float')\n                    current_rmse_loss = np.mean(current_rmse_loss_array)\n                if current_rmse_loss < self.best_rmse:\n                    self.best_rmse = current_rmse_loss\n                    self.save(f'best_model_fold_{self.fold}')\n                    print(f'best_rmse ----> {self.best_rmse}')\n","edb26436":"def petfinder_diff(input,target):\n    return torch.sum((100*((input.flatten()-target)))**2)","c1cda917":"len(os.listdir('..\/input\/petfinder-pawpularity-score\/test')) == 8","231a8b81":"all_preds = []\nimport numpy as np\nimport joblib\n# Both import methods supported\nfrom cuml import Ridge\nfrom cuml.linear_model import Ridge\n\nif len(os.listdir('..\/input\/petfinder-pawpularity-score\/test')) == 8:\n    debug = True\nelse:\n    debug = False\n    \nfor i in range(N_FOLDS):\n    #swin 384\n    print(f'Fold {i} results')\n    print('swin_384')\n    if i == 2:\n        learn = get_learner_384(fold_num=i)    \n        state = torch.load(f'..\/input\/transformer384-fold2\/best_model_fold_2.pth')  \n    else:\n        learn = get_learner_384(fold_num=i)    \n        state = torch.load(f'..\/input\/transformer384-fold{i}\/models\/best_model_fold_{i}.pth')          \n    learn.model.load_state_dict(state['model'])\n    #learn = learn.to_fp32()\n    \n    #learn.export(f'model_fold_{i}.pkl')\n    #learn.save(f'model_fold_{i}.pkl')\n    \n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               shuffle=False,\n                               item_tfms=Resize(384), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n\n    #val_preds, targs = learn.tta(n=10,beta=0.07)\n    #print(f'rmse fold-{i}={rmse(100*val_preds,100*targs)}')\n    #if len(os.listdir('..\/input\/petfinder-pawpularity-score\/test')) == 8:\n    test_dl = dls.test_dl(test_df)\n    test_dl_384 = dls.test_dl(test_df)\n    (preds_test_384_tta,preds_test_384), _ = learn.tta(dl=test_dl_384, n=4,beta=None)\n\n    ###########  ensambling svr-head-preds with swin384-preds #############  \n    \n    def get_activation(name):\n        def hook(model, input, output):\n            activation[name] = output.detach()\n        return hook\n    \n    activation = {}\n    fold_activation = []\n    targs = []\n    preds_test = np.array([])\n    extra_test_features = test_dl.items.iloc[:,:-2].values    \n    with torch.no_grad(): \n         for n,xb in enumerate(test_dl):\n              xb = xb[0]\n              learn.model.avgpool.register_forward_hook(get_activation('avgpool'))\n              preds = learn.model(xb)\n              preds_test =  np.concatenate((preds_test,preds.cpu().data.numpy().reshape(-1)),axis=0)\n              if n == len(test_dl) - 1:\n                 if xb.shape[0] == BATCH_SIZE:\n                    fold_activation.append(activation['avgpool'].cpu().data.numpy())\n                    fold_activation_array = np.array(fold_activation)\n                    fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n                    \n                 else:\n                    \n                    if debug == True:\n                        fold_activation.append(activation['avgpool'].cpu().data.numpy()) \n                        fold_activation_array = np.array(fold_activation)\n                        fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n\n                    else:\n                        fold_activation_array = np.array(fold_activation)\n                        fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n                        last_batch_activations = activation['avgpool'].cpu().data.numpy().reshape(-1,fold_activation_array.shape[1])\n                        fold_activation_array = np.concatenate((fold_activation_array,last_batch_activations),axis=0)\n              else:\n                  fold_activation.append(activation['avgpool'].cpu().data.numpy())\n    X_test =  np.concatenate((fold_activation_array,extra_test_features),axis=1)             \n    NN_preds = 1\/(1 + np.exp(- preds_test))                         \n    svr_model = joblib.load(f'..\/input\/petfindder-swin-384-svr-training-with-extra-data\/svr_head_model_swin384_fold{i}')\n    svr_preds = svr_model.predict(X_test)\n    svr_preds_head_swin384 = svr_preds\n    ridge = joblib.load(f'..\/input\/petfindder-swin-384-svr-training-with-extra-data\/blender_model_for_svr_NN_swin384_fold{i}')\n    X_test =  np.concatenate((svr_preds.reshape(-1,1),NN_preds.reshape(-1,1),extra_test_features),axis=1) \n    blender_svr_and_swin384_test_preds = ridge.predict(X_test)   \n    \n\n    del learn ,ridge, svr_model ,X_test ,NN_preds ,activation ,fold_activation ,extra_test_features ,preds_test\n    torch.cuda.empty_cache()\n    gc.collect()\n   \n    #swin 224\n    print('without_svr_head')\n    learn = get_learner_224(fold_num=i)    \n    state = torch.load(f'..\/input\/swintransformermodels\/models\/best_model_fold_{i}.pth')\n    learn.model.load_state_dict(state['model'])\n    learn.model.cuda()\n    #learn = learn.to_fp32()\n    #learn.export(f'model_fold_{i}.pkl')\n    #learn.save(f'model_fold_{i}.pkl')\n    \n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               shuffle=False,\n                               num_workers=8,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n    #val_preds, targs = learn.tta(n=10,beta=0.07)\n    #print(f'rmse fold-{i}={rmse(100*val_preds,100*targs)}')\n    #if len(os.listdir('..\/input\/petfinder-pawpularity-score\/test')) == 8:\n    test_dl = dls.test_dl(test_df)\n    test_dl_224 = dls.test_dl(test_df)\n    (preds_test_224_tta,preds_test_224), _ = learn.tta(dl=test_dl_224, n=4,beta=None)\n    ################# ensambling svr-head preds and  swin-224 preds ##################   \n\n    activation = {}\n    fold_activation = []\n    targs = []\n    preds_test = np.array([])\n    extra_test_features = test_dl.items.iloc[:,:-2].values    \n    with torch.no_grad(): \n         for n,xb in enumerate(test_dl):\n              xb = xb[0]\n              learn.model.avgpool.register_forward_hook(get_activation('avgpool'))\n              preds = learn.model(xb)\n              preds_test =  np.concatenate((preds_test,preds.cpu().data.numpy().reshape(-1)),axis=0)\n              if n == len(test_dl) - 1:\n                 if xb.shape[0] == BATCH_SIZE:\n                    fold_activation.append(activation['avgpool'].cpu().data.numpy())\n                    fold_activation_array = np.array(fold_activation)\n                    fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n                    \n                 else:\n                    \n                    if debug == True:\n                        fold_activation.append(activation['avgpool'].cpu().data.numpy()) \n                        fold_activation_array = np.array(fold_activation)\n                        fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n\n                    else:\n                        fold_activation_array = np.array(fold_activation)\n                        fold_activation_array = fold_activation_array.reshape(-1,fold_activation_array.shape[2])\n                        last_batch_activations = activation['avgpool'].cpu().data.numpy().reshape(-1,fold_activation_array.shape[1])\n                        fold_activation_array = np.concatenate((fold_activation_array,last_batch_activations),axis=0)\n              else:\n                  fold_activation.append(activation['avgpool'].cpu().data.numpy())\n    X_test =  np.concatenate((fold_activation_array,extra_test_features),axis=1)             \n    NN_preds = 1\/(1 + np.exp(- preds_test))                         \n    svr_model = joblib.load(f'..\/input\/fork-of-swin-224-svr-training-meta-data\/svr_head_model_swin224_fold{i}')\n    svr_preds = svr_model.predict(X_test)\n    svr_preds_head_swin224 = svr_preds\n    ridge = joblib.load(f'..\/input\/fork-of-swin-224-svr-training-meta-data\/blender_model_for_svr_NN_swin224_fold{i}')\n    X =  np.concatenate((svr_preds.reshape(-1,1),NN_preds.reshape(-1,1),extra_test_features),axis=1) \n    blender_svr_and_swin224_test_preds = ridge.predict(X)   \n      \n\n    del learn ,ridge, svr_model \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    #ensamble    \n    print('ensamble')\n    result_ridge = joblib.load(f'..\/input\/best-ensamble-with-training-blender\/final_blender_model_fold{i}')\n    X = pd.DataFrame()\n    X['preds_test_224'] = np.array(preds_test_224).reshape(-1)\n    X['svr_preds_head_swin224'] = np.array(svr_preds_head_swin224).reshape(-1)\n    X['preds_test_224_tta'] = np.array(preds_test_224_tta).reshape(-1)\n\n    X['preds_test_384'] = np.array(preds_test_384).reshape(-1)\n    X['svr_preds_head_swin384'] = np.array(svr_preds_head_swin384).reshape(-1)\n    X['preds_test_384_tta'] = np.array(preds_test_384_tta).reshape(-1)\n\n    meta_cols = ['Subject_Focus','Eyes','Face','Near','Action','Accessory','Group','Collage','Human','Occlusion','Info','Blur']    \n    X[meta_cols] = np.array(extra_test_features)\n    \n    all_preds.append(X.values)\n    del activation, fold_activation ,fold_activation_array ,X_test ,preds_test_224 ,preds_test_384 ,blender_svr_and_swin224_test_preds ,blender_svr_and_swin384_test_preds\n    gc.collect()\n","ac0ddc49":"X_test = np.mean(np.stack(all_preds), axis=0)\nX_test.shape","16a70b64":"result_ridge  = joblib.load(f'..\/input\/best-ensamble-with-training-final-blender\/final_blender_model')\nfinal_preds = result_ridge.predict(X_test)\npreds = final_preds","79629769":"preds_2 = preds*100","d38338a0":"#psudo_labeling","92f0033c":"path = Path('..\/input\/petfinder-pawpularity-score')\ndf_train = pd.read_csv(path\/'train.csv')\ndf_test  = pd.read_csv(path\/'test.csv')\ndf_train.Id = df_train.Id.map(lambda x:str(path) + '\/train\/' + x + '.jpg')\ndf_test.Id = df_test.Id.map(lambda x:str(path) + '\/test\/' + x + '.jpg')","4338e56f":"df_train['min_Pawpularity'] = df_train['Pawpularity']\ndf_train['max_Pawpularity'] = df_train['Pawpularity']","7ef15c5b":"df_test['Pawpularity'] = preds_2\nmin_test_Pawpularity = []\nmax_test_Pawpularity = []\nfor pred in list(preds_2):\n    if pred - 4 >= 0: \n        if pred + 4 <= 100:\n            min_test_Pawpularity.append(pred - 4)\n            max_test_Pawpularity.append(pred + 4)\n        else:\n            min_test_Pawpularity.append(pred - 4 - (pred + 4 - 100))\n            max_test_Pawpularity.append(100.0)            \n    else:\n        min_test_Pawpularity.append(0)\n        max_test_Pawpularity.append(pred + 4 - (pred - 4))     \ndf_test['min_Pawpularity'] = np.array(min_test_Pawpularity).reshape(-1)\ndf_test['max_Pawpularity'] = np.array(max_test_Pawpularity).reshape(-1)","38d9a791":"ymin = 0.00001\nymax = 100\n\nclass scaledSigmoid(nn.Module):\n    def forward(self, input):\n        return torch.sigmoid(input) * (ymax - ymin) + ymin\n\nclass clampedReLU(nn.Module):\n    def forward(self, input):\n        bottomClamp = input < ymin\n        topClamp = input > ymax\n        input[bottomClamp,] = ymin\n        input[topClamp,] = ymax\n        return input\n    ","acab1181":"def petfinder_rmse(input,target,segmoid=True):\n    if segmoid == True:\n        return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n    else:\n        return 100*torch.sqrt(F.mse_loss(input.flatten(), target))","f599e7c7":"data_with_psudolabel = pd.concat((df_train,df_test),axis=0)\ndef get_x(r):return r['Id']\ndef get_y(r):return random.choice(list(np.arange(r['min_Pawpularity'],r['max_Pawpularity'] + 1)))\/100\ndef get_dls(bs,size,df,mult=1):\n        dblock = DataBlock(blocks=(ImageBlock, RegressionBlock), #pass in train DataFrame\n                                   splitter=IndexSplitter([1]),\n                                   get_x=get_x, #filename\/path is in the second column of the DataFrame\n                                   get_y=get_y, #label is in the first column of the DataFrame\n                                   item_tfms=Resize(224), #pass in item_tfms\n                                   batch_tfms=setup_aug_tfms([Flip()]))\n        dls = dblock.dataloaders(data_with_psudolabel,bs=bs)\n        dsets = dblock.datasets(data_with_psudolabel)\n        return dls,dsets\ndls_psudolabel,dsets = get_dls(bs=8,size=224,df=data_with_psudolabel)\ndls_psudolabel.train.one_batch()[0].shape\ndls_psudolabel.show_batch()","4baeea65":"if df_test.shape[0] == 8:\n    debug=False\nelse:\n    debug=True\n\nif debug == True:\n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=1)\n    learn = Learner(dls_psudolabel,model,loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse)\n    learn.unfreeze()\n    learn.fit_one_cycle(17,2e-5)","cb7e8995":"if debug == True:\n    test_dls = dls_psudolabel.test_dl(df_test)\n    preds_1 = learn.get_preds(dl=test_dls)","c1c32d3e":"if debug == True:\n    torch.cuda.empty_cache()\n    gc.collect()","9c8a7f9c":"sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\nif debug == True:\n     sample_df['Pawpularity'] = 0.9 * preds_2 + 0.1 * np.array(preds_1[0]*100).reshape(-1) \nelse:\n     sample_df['Pawpularity'] = preds_2\n   \nsample_df.to_csv('submission.csv',index=False)\npd.read_csv('submission.csv').head()","fdb5a664":"Let's check an example image to see what it looks like:","2db7b3e3":"Let's check the distribution of the Pawpularity Score:","de15f416":"Okay, let's check how many images are available in the training dataset:","dd6c68c4":"Let's check what data is available to us:","eb872018":"## Data loading\nAfter my quick 'n dirty EDA, let's load the data into fastai as DataLoaders objects. We're using the normalized score as the label. I use some fairly basic augmentations here.","38113e67":"Note that the Pawpularity score is an integer, so in addition to being a regression problem, it could also be treated as a 100-class classification problem. Alternatively, it can be treated as a binary classification problem if the Pawpularity Score is normalized between 0 and 1:"}}