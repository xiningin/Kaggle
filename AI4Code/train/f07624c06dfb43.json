{"cell_type":{"90bf37fa":"code","95362c96":"code","0e3d6601":"code","a6828f47":"code","caad200c":"code","e3568c7e":"code","86f5de60":"code","ce0b2374":"code","a95a2dbd":"code","dfb2aeff":"code","185a1753":"code","c328bf6d":"code","c5068b55":"code","1479e911":"code","0b39c94e":"code","ed769b78":"code","dcd57842":"code","8a29d1e9":"code","c0b6e23c":"code","50d373d6":"code","95c3e5e3":"code","dd555921":"code","7d77a794":"code","d40cdf6c":"code","679ecf70":"code","3f0263dc":"code","ded70eaf":"code","bc51573c":"code","af2aaada":"code","39dd0b7c":"code","cfe1cecb":"code","711910ca":"code","4e1ed22d":"code","ffda13cf":"code","41c0aadc":"code","9c49036f":"code","55ce3b71":"code","171aac8a":"code","7e12b6d6":"markdown","3891020c":"markdown","979a46f7":"markdown"},"source":{"90bf37fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","95362c96":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold,train_test_split,KFold\nimport re\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score,f1_score","0e3d6601":"train_df = pd.read_csv('\/kaggle\/input\/train_0irEZ2H.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/test_nfaJ3J5.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/sample_submission_pzljTaX.csv')","a6828f47":"train_df = train_df.dropna(axis=0, subset=['total_price'])\ntrain_df['train_or_test']='train'\ntest_df['train_or_test']='test'\ndf=pd.concat([train_df,test_df])\nprint(train_df.isnull().sum())\nprint(test_df.dtypes)","caad200c":"train_df['week']= pd.to_datetime(train_df['week'])\ntest_df['week']= pd.to_datetime(test_df['week'])\ndf=pd.concat([train_df,test_df])","e3568c7e":"!pip install pendulum","86f5de60":"def create_date_featues(df):\n\n    df['Year'] = pd.to_datetime(df['week']).dt.year\n\n    df['Month'] = pd.to_datetime(df['week']).dt.month\n\n    df['DayOfyear'] = pd.to_datetime(df['week']).dt.dayofyear\n\n    df['Week'] = pd.to_datetime(df['week']).dt.week\n\n    #df['Quarter'] = pd.to_datetime(df['week']).dt.quarter \n\n    df['Is_month_start'] = pd.to_datetime(df['week']).dt.is_month_start\n\n    df['Is_month_end'] = pd.to_datetime(df['week']).dt.is_month_end\n    \n    \n    \n    #df['Is_quarter_start'] = pd.to_datetime(df['week']).dt.is_quarter_start\n\n    #f['Is_quarter_end'] = pd.to_datetime(df['week']).dt.is_quarter_end\n\n    #df['Semester'] = np.where(df['week'].isin([1,2]),1,2)\n\n    return df","ce0b2374":"df=create_date_featues(df)","a95a2dbd":"df['new_feat1'] = df['total_price'] - df['base_price']\ndf['More'] = np.where(df['new_feat1'] < 0, 1, 0)\ndf['less'] = np.where(df['new_feat1'] > 0, 1, 0)\ndf['same'] = np.where(df['new_feat1'] == 0, 1, 0)","dfb2aeff":"for col in ['sku_id','store_id']:\n    df = pd.get_dummies(df, columns=[col])","185a1753":"df['latest'] = df['store_id'] + df['sku_id']","c328bf6d":"for col in ['latest']:\n    df = pd.get_dummies(df, columns=[col])","c5068b55":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\n#df['sku_id'] = labelencoder.fit_transform(df['sku_id'])\n#df['store_id'] = labelencoder.fit_transform(df['store_id'])\ndf['latest'] = labelencoder.fit_transform(df['latest'])","1479e911":"plt.figure(figsize=(24, 6))\nplt.subplot(121)\nsns.distplot(df[\"total_price\"])\nplt.subplot(122)\nsns.distplot(np.log1p(df[\"total_price\"]))\nplt.show()","0b39c94e":"df['total_price']=np.log1p(df[\"total_price\"])","ed769b78":"plt.figure(figsize=(24, 6))\nplt.subplot(121)\nsns.distplot(df[\"base_price\"])\nplt.subplot(122)\nsns.distplot(np.log1p(df[\"base_price\"]))\nplt.show()","dcd57842":"df['base_price']=np.log1p(df[\"base_price\"])","8a29d1e9":"plt.figure(figsize=(24, 6))\nplt.subplot(121)\nsns.distplot(train_df[\"units_sold\"])\nplt.subplot(122)\nsns.distplot(np.log1p(train_df[\"units_sold\"]))\nplt.show()","c0b6e23c":"train=df.loc[df.train_or_test.isin(['train'])]\ntest=df.loc[df.train_or_test.isin(['test'])]\ntrain.drop(columns={'train_or_test'},axis=1,inplace=True)\ntest.drop(columns={'train_or_test'},axis=1,inplace=True)","50d373d6":"train['units_sold']=np.log1p(train['units_sold'])","95c3e5e3":"y = train.units_sold","dd555921":"np.expm1(y)","7d77a794":"train=train.drop(columns={'record_ID','week','units_sold'},axis=1)\ntest=test.drop(columns={'record_ID','week','units_sold'},axis=1)","d40cdf6c":"train=train.drop(columns={'record_ID','week','units_sold','total_price', 'base_price'},axis=1)\ntest=test.drop(columns={'record_ID','week','units_sold','total_price', 'base_price'},axis=1)","679ecf70":"print(train.shape,test.shape)","3f0263dc":"X_train, X_test, Y_train, Y_test = train_test_split(train, y, test_size = 0.1, random_state = 5)","ded70eaf":"features = [col for col in train.columns]\ncat = []","bc51573c":"import lightgbm as lgb\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\nfrom sklearn.metrics import mean_squared_error,mean_squared_log_error\nfrom math import sqrt\nimport keras\n","af2aaada":"param = {'boosting_type': 'gbdt','num_leaves':128, 'objective':'regression','max_depth':6,'eval_metric':'rmse','learning_rate':.2,'max_bin':100}","39dd0b7c":"folds = StratifiedKFold(n_splits=3, shuffle=True, random_state=1048)\nkf=StratifiedKFold(n_splits=3, shuffle=True, random_state=999)\nnum_classes = len(np.unique(y))\ny_train_categorical = keras.utils.to_categorical(y, num_classes)\npredictions = np.zeros((len(test), ))\nfeature_importance_df = pd.DataFrame()\n#for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, y.values)):\nfor fold_, (trn_idx, val_idx) in enumerate(kf.split(train, y_train_categorical.argmax(1))):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=y.iloc[trn_idx],categorical_feature=cat)\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=y.iloc[val_idx],categorical_feature=cat)\n\n    num_round = 1000000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 500)\n    predictions_val = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    #print(\"MSE: {:<8.5f}\".format(mean_squared_error(predictions_val, y.iloc[val_idx])))\n    #print(\"RMSLE: {:f}\".format(np.sqrt(mean_squared_log_error(np.expm1(y.iloc[val_idx]),np.expm1(predictions_val)))))\n    #print(\"RMSLE: {:f}\".format(np.sqrt(mean_squared_error(y.iloc[val_idx], predictions_val))))\n    def rmsle(y_true, y_pred):\n        assert len(y_true) == len(y_pred)\n        return np.sqrt(np.mean(np.power(np.log1p(y_true + 1) - np.log1p(y_pred + 1), 2)))\n    print(rmsle(np.expm1(y.iloc[val_idx]),np.expm1(predictions_val)))\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) \/ folds.n_splits","cfe1cecb":"nas_lgb =np.expm1(predictions)","711910ca":"from xgboost import XGBRegressor","4e1ed22d":"folds = StratifiedKFold(n_splits=2, shuffle=True, random_state=1048)\nkf=StratifiedKFold(n_splits=2, shuffle=True, random_state=999)\nnum_classes = len(np.unique(y))\ny_train_categorical = keras.utils.to_categorical(y, num_classes)\npredictions = np.zeros((len(test), ))\nfeature_importance_df = pd.DataFrame()\n#for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, y.values)):\nfor fold_, (trn_idx, val_idx) in enumerate(kf.split(train, y_train_categorical.argmax(1))):\n    print(\"Fold {}\".format(fold_))\n    #trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=y.iloc[trn_idx])\n    #val_data = lgb.Dataset(train.iloc[val_idx][features], label=y.iloc[val_idx])\n    model = XGBRegressor(\n    max_depth=8,\n    n_estimators=10000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,\n    seed=42)\n    #num_round = 1000000\n    #clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 500)\n    #predictions_val = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    model.fit(train.iloc[trn_idx][features], y.iloc[trn_idx],eval_metric=\"rmse\", \n    eval_set=[(train.iloc[trn_idx][features], y.iloc[trn_idx]), (train.iloc[val_idx][features], y.iloc[val_idx])], \n    verbose=1000, \n    early_stopping_rounds = 100)\n    predictions_val=model.predict(train.iloc[val_idx][features])\n    def rmsle(y_true, y_pred):\n        assert len(y_true) == len(y_pred)\n        return np.sqrt(np.mean(np.power(np.log1p(y_true + 1) - np.log1p(y_pred + 1), 2)))\n    print(rmsle(np.expm1(y.iloc[val_idx]),np.expm1(predictions_val)))\n    \n    predictions += model.predict(test[features]) \/ folds.n_splits","ffda13cf":"nas_xgb =np.expm1(predictions)","41c0aadc":"ens = nas_xgb* 0.6 + nas_lgb* 0.4","9c49036f":"final_dict = {'record_ID' : submission.record_ID, 'units_sold': ens}\nResult = pd.DataFrame(final_dict)","55ce3b71":"Result.head()\nResult.to_csv('finalsub.csv',index=False)","171aac8a":"fold_importance_df.sort_values('importance',ascending=False).head(50)\n#df.sort_values('2')","7e12b6d6":"# Model Building","3891020c":"# Log transforming units to have normal distribution .","979a46f7":"# Getting ack Train Test"}}