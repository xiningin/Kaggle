{"cell_type":{"a64bf191":"code","fe75c723":"code","11349ec1":"code","32208017":"code","54a9ebee":"code","43060efe":"code","67aa4cd1":"code","1816d5a7":"code","cdac7f82":"code","35f86462":"code","61d4fd32":"code","509e8e05":"code","37fb9ad8":"code","38d3f950":"code","552ce78f":"code","9effcc87":"code","a0bf7329":"code","888965b7":"code","f7fa42a0":"code","f92d9b56":"code","292c8728":"code","df434d6a":"code","719f78ba":"code","2e2fb2e5":"code","9ee9c896":"code","29ddc64f":"code","4ae23db5":"code","148dd449":"code","1e34cc14":"code","b58edd7f":"code","49536999":"code","c5d8dd9b":"code","809a0d9b":"code","71bfeb35":"code","08d9c64d":"code","2b3d1cfd":"code","f96cbdd7":"code","14d0d290":"code","24a0c2b6":"code","64c92a18":"code","e8b8e04a":"code","6f147e42":"code","d0f9d92f":"code","d627d80f":"code","73a06c1b":"code","3c429b3d":"code","da1c49f9":"code","5976e9d0":"code","d7be62fe":"code","a50ac635":"code","38a60fd0":"code","76a63855":"markdown","5a100ece":"markdown","8295b642":"markdown","3112537d":"markdown","838a7dae":"markdown","20aa6adf":"markdown","973e855e":"markdown","3cfd0acd":"markdown","43261982":"markdown","636e1347":"markdown","f992e4c0":"markdown","58e2bc76":"markdown","aacb9c31":"markdown","6c7d7b8f":"markdown","6466a602":"markdown","38ce19e8":"markdown","ff5d0160":"markdown","5547f7b1":"markdown","7fb4f090":"markdown","1b991d8d":"markdown","2402a954":"markdown","5a0f5005":"markdown","d746be1f":"markdown","39a27480":"markdown"},"source":{"a64bf191":"import pandas as pd\nimport numpy as np","fe75c723":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\")","11349ec1":"df.head()","32208017":"df.isnull().sum()","54a9ebee":"df[df['Embarked'].isnull()]","43060efe":"df[df['Cabin'].isnull()]","67aa4cd1":"# convert \"Cabin\" 1 or 0\ndf['cabin_null']  = np.where(df['Cabin'].isnull(), 1, 0)","1816d5a7":"df['cabin_null'].mean()","cdac7f82":"df.head()","35f86462":"df.columns","61d4fd32":"#compare cabin null with survived\ndf.groupby(['Survived'])['cabin_null'].mean()\n","509e8e05":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\", usecols = ['Age', 'Fare', 'Survived'])","37fb9ad8":"df.head()","38d3f950":"df.isnull()","552ce78f":"df.isnull().sum()","9effcc87":"df.isnull().mean()    #percentage of missing values","a0bf7329":"def impute_nan(df, variable, median):\n    \"\"\"fill the nan values with median\"\"\"\n    \n    df[variable+\"_median\"] = df[variable].fillna(median)\n    ","888965b7":"median = df.Age.median()","f7fa42a0":"print(\"median of age is : \"+str(median))\n","f92d9b56":"impute_nan(df, 'Age', median)","292c8728":"df.head()","df434d6a":"df.isnull().sum()","719f78ba":"print(\"standard deviation of age: {}\".format(df['Age'].std()))\nprint(\"standard deviation of Age_median: {}\".format(df['Age_median'].std()))","2e2fb2e5":"import matplotlib.pyplot as plt\n%matplotlib inline","9ee9c896":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde', ax=ax)\ndf.Age_median.plot(kind='kde', ax=ax, color = 'red')\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","29ddc64f":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\", usecols = ['Age', 'Fare', 'Survived'])\ndf.head()","4ae23db5":"df.isnull().sum()","148dd449":"df['Age'].dropna().sample()\n#this will replace NA with randomvalue\n#but this will replace only one value ....we need \n#177 values to replace","1e34cc14":"#for this we can use\n\"\"\"This will replace all the 177 values with random values\"\"\"\ndf['Age'].dropna().sample(df['Age'].isnull().sum(), random_state=0)\n\n","b58edd7f":"df[df['Age'].isnull()].index","49536999":"def impute_nan(df, variable, median):\n    \"\"\"fill the nan values with median\"\"\"\n    \n    df[variable+\"_median\"] = df[variable].fillna(median)\n    df[variable+\"_random\"] = df[variable]\n    ##It will have the random sample to fill the na\n    random_sample=df[variable].dropna().sample(df['Age'].isnull().sum(), random_state=0)\n    \n    #pandas need to have some index in order to merge the data set\n    random_sample.index = df[df[variable].isnull()].index\n    df.loc[df[variable].isnull(), variable+'_random'] = random_sample","c5d8dd9b":"median = df.Age.median()\nmedian","809a0d9b":"impute_nan(df, 'Age', median)\ndf.head()","71bfeb35":"import matplotlib.pyplot as plt\n%matplotlib inline","08d9c64d":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde', ax=ax)\ndf.Age_random.plot(kind = 'kde', ax=ax, color='green')\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines,labels,loc='best')","2b3d1cfd":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde', ax=ax)\ndf.Age_median.plot(kind = 'kde', ax=ax, color='red')\ndf.Age_random.plot(kind = 'kde', ax=ax, color='green')\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines,labels,loc='best')","f96cbdd7":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\", usecols = ['Age', 'Fare', 'Survived'])","14d0d290":"# Create a new feature and wherever there is null than replace with \n# 1 else replace with 0\n\ndf['Age_NAN'] = np.where(df['Age'].isnull() , 1,0)\ndf.head(20)","24a0c2b6":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\", usecols = ['Age', 'Fare', 'Survived'])","64c92a18":"df.Age.hist(bins=50)","e8b8e04a":"extreme=df.Age.mean() + 3* df.Age.std()\nextreme","6f147e42":"import seaborn as sns\nsns.boxplot('Age', data = df)","d0f9d92f":"def impute_nan(df, var, median, extreme):\n    \"\"\"Create a new Feature and fill with exteme value\"\"\"\n    \n    df[var+\"_end_distribution\"] = df[var].fillna(extreme)\n    df[var].fillna(median, inplace=True) #replace the age NaN with median","d627d80f":"impute_nan(df, 'Age',df.Age.median(), extreme)\ndf.head()","73a06c1b":"df['Age'].hist(bins=50)\n","3c429b3d":"df['Age_end_distribution'].hist(bins=50)","da1c49f9":"sns.boxplot('Age_end_distribution', data=df)","5976e9d0":"df = pd.read_csv(\"..\/input\/titanic\/train.csv\", usecols = ['Age', 'Fare', 'Survived'])\ndf.head()","d7be62fe":"df.Age.hist(bins=50)","a50ac635":"def impute_nan(df, var):\n    df[var+'_hundred'] = df[var].fillna(100)      #fill the NAN with 100 and create a new feature\n    df[var +'_zero']= df[var].fillna(0)        #fill NAN withh 0 and create a new feature.\n    ","38a60fd0":"impute_nan(df, 'Age')\ndf.head(20)","76a63855":"# 2. Random Sample Imputation\nIt assumes that data are missing completely at Random","5a100ece":"#### we will pick up the data after the 3rd SD of the graph","8295b642":"### Advantages\/Disadvantages \n\n##### 1. Advantages\n\n``--> Easy to Implement``\n\n``--> captures the importance of missing values``\n\n##### 2. DisAdvantages\n\n``--> Distorst the original distribution``\n\n``--> If missingnes is not importnatn, it may mask the predictive power of the original variable``\n\n``--> If the number of NA is big, it will mask true outliers in the distribution``\n\n``--> If the number of NA is small, the replaced NA may be considered an outlier and pre-processed ina subsequnt feature enginneering.``","3112537d":"## 1. Mean\/Median\/Mode Imputation\n\n###### When should we apply this:\nMean\/ Median Imputation has the assumption that the data are missing completely at random(MCAR).\n\n``Replace the NAN with most frequent occurance of variable``","838a7dae":"# 3. Capturing NAN with new features\nIt works well if the data are not missing completely at random","20aa6adf":"### Description of impute_nan\n\n`line 3` --> new feature is created and all nan will replace to median.\n\n`line 5` --> create another feature and it will copy the data to \"_random\".\n\n`line 7` --> pick all the null value index and put some random dat in it.\n\n` line 10` --> we have to match both index so random feature should be back to feature. \n\n`line 11` --> it will replace all the missing value with random values of median","973e855e":"Most of the NaN values are with \"age\" because the data is made after the accident happen... so the people who died didnt tell there age. and also they dont tell there cabin details.","3cfd0acd":"2. ##### Missing Data not at random(MNAR): Systematic misssing values\nTHere is absolutely some relationship between missing and any other values.","43261982":"With this we provide addtional feature for NaN value\nand now we can replace the values of 1 with either mean\/median\/mode","636e1347":"# Techniques to handling missing values\n``1. Mean\/Median Replacement``\n\n``2. Random Sample Imputation``\n  \n``3. Capturing NAN values with a new feature``\n\n``4. End of Distribution imputation``\n\n``5. Arbitrary Imputation``\n\n``6. Frequent Categories Imputation``\n  ","f992e4c0":"### Advantages\/Disadvantages of Capturing NAN\n\n##### 1. Advantages\n\n``--> Easy to Implement(Robust to Outliers)``\n\n``--> captures the importance of missing values``\n\n##### 2. DisAdvantages\n\n``--> THis method is creating additional feature`` This may lead to Curse of Dimensionality","58e2bc76":"# Handling Missing Values\n\n``We will use Titanic Data set``\n1. ##### Missing Completely at random (MCAR)\n\n#### TITANIC DATA IS EXAMPLE OF \"MISSING COMPLETELY AT RANDOM\"","aacb9c31":"So in the \"AGE\" column we have filled the NaN with median\nand also created the new column and replaced the nan with extreme value.\n\nLets compare","6c7d7b8f":"So bang..... ``We dont have any outliers now``","6466a602":"We replace NAN with Arbitrary value","38ce19e8":"### Advantages\n1. Easy to implement\n2. Captures importance of missingess if there is one.\n\n\n### Disadvantages\n1. Distorts the original distribution of the variable\n2. If missingness is not important, it may mask the predictive power of the orignial variable by distroting its distribution\n3. Hard to decide whhich value to use.","ff5d0160":"## Thank You\n\n\n**Resource: Krish Naik (YT)**","5547f7b1":" ##### LEts check the outliers","7fb4f090":"# 5. Arbitrary Value Imputation","1b991d8d":"###### Graph Description\nkde = kernel density estimators.\n\n``Blue color line is the real age.\nAfter imputation most values are come so curve has raised``\n\n\n### Advantages\/Disadvantages of Mean\/Median Imputation\n\n##### 1. Advantages\n\n``--> Easy to Implement(Robust to Outliers)``\n\n``--> Faster Way to Obtain the Complete Data set``\n\n##### 2. DisAdvantages\n\n``--> Change or Distortion in the original Variance``\n\n``--> Impacts Correlation``","2402a954":"### Advantages\/Disadvantages \n\n##### 1. Advantages\n\n``--> Easy to Implement``\n\n``--> Less Distortion in variance``\n\n##### 2. DisAdvantages\n\n``--> Easy situation randomness won't work``\n","5a0f5005":"##### IMP:\n``Arbitrary value should not be more frequently present ``\n\nthat's why we will take either least value or last oulier value","d746be1f":"wooohooooo we have replaced all nan with median","39a27480":"# 4. End of Distribution\nHere we are going to basically take the far end of the distribution(ie. end values of x-axis).\n\nFrom this distribution we replace the end of distribution"}}