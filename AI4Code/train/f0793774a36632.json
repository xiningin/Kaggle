{"cell_type":{"361923bf":"code","e6595176":"code","59e80220":"code","a1f99b69":"code","e61174f2":"code","738e5b86":"code","a4fec8cd":"code","80e47052":"code","c2a5492a":"code","3bd8936e":"code","a05f4fba":"code","5f094114":"code","919f056e":"code","fc75b5c1":"code","ab946408":"code","55e917a5":"code","e0436984":"markdown","30fe21de":"markdown","c6c66275":"markdown","97bb5c45":"markdown","c6b5d5f4":"markdown","2e89c73e":"markdown","96eb45d1":"markdown","f85fafbb":"markdown"},"source":{"361923bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e6595176":"# import dependencies\nimport pandas as pd\nimport matplotlib.pyplot as plt","59e80220":"# import data\ndata = pd.read_csv('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train.csv')","a1f99b69":"data.head()","e61174f2":"data.describe()","738e5b86":"data.info()","a4fec8cd":"# find unique titles and sort alphabetically\nsorted(data['cleaned_label'].unique()) # clearly same datasets but written in different ways","80e47052":"# label length\ncleaned_label = data['cleaned_label'].unique()\ncleaned_label_length = [len(x) for x in cleaned_label]\nplt.figure(figsize = (15,15))\nplt.bar(range(len(cleaned_label)), cleaned_label_length)\nplt.show()","c2a5492a":"# find unique titles and sort alphabetically\nsorted(data['dataset_title'].unique())","3bd8936e":"title_count = data.groupby(['dataset_title']).count()\ntitle_count.sort_values(by = 'Id', ascending = False)","a05f4fba":"title_count = data.groupby(['cleaned_label']).count()\ntitle_count.sort_values(by = 'Id', ascending = False)","5f094114":"from wordcloud import WordCloud, STOPWORDS\n\nwords_in_titles = list(data.pub_title.str.split(expand=True).stack())\n\nwordcloud = WordCloud(stopwords = STOPWORDS,\n                      background_color = \"white\",\n                      width = 3000,\n                      height = 2000\n                     ).generate(' '.join(words_in_titles))\nplt.figure(1, figsize = (18, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","919f056e":"data.groupby(['pub_title']).count().sort_values(by = 'Id', ascending = False)","fc75b5c1":"import json\n\n# read text\ntext = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith('.json'):\n            text.append(json.load(open(os.path.join(dirname, filename))))","ab946408":"# section length\nfrom collections import Counter\nsection_length = Counter([len(x) for x in text])\nsections = sorted(section_length.keys())\nplt.figure(figsize = (15,15))\nplt.bar(sections, [section_length[x] for x in sections])\nplt.show()","55e917a5":"# inspect first publication\ntext[0]","e0436984":"## Publication Title Analysis","30fe21de":"## Word Cloud of label","c6c66275":"An original dataset title may be re-written\/phrased in many ways\n\nFor example, **Aging Integrated Database (AGID)** is written as **aging integrated database agid** or **aging integrated database**","97bb5c45":"## Document analysis","c6b5d5f4":"# EDA","2e89c73e":"## Label analysis","96eb45d1":"Section example from text[0] \n\n```\n{'section_title': 'Results', 'text': ''}\n```\n\nSomehow, section_title could be the title itself and sub-title.","f85fafbb":"This competition challenges data scientists to show how publicly funded data and evidence are used to serve science and society. Data, evidence, and science are critical if government is address the many threats facing society: pandemics, climate change and coastal inundation, Alzheimer\u2019s disease, child hunger, and support science and innovation, increase food production, maintain biodiversity, and address many other challenges. Yet much of the information about data necessary to inform evidence and science is locked inside publications.\n\nCan natural language processing find the hidden-in-plain-sight data citations? Can machine learning find the link between the words used in research articles and the data referenced in the article?"}}