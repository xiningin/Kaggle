{"cell_type":{"6c28bd7d":"code","b24cd457":"code","5c77802c":"code","85670206":"code","50a607ea":"code","9970bffe":"code","c36e1582":"code","e25226a5":"code","03a14c86":"code","31b59d90":"code","60325bac":"code","ff7fc4d7":"code","9ac03abe":"code","be3e4ba8":"code","14d55d55":"code","489cb919":"code","a83f09cf":"code","6e75c518":"code","a3ea4468":"code","bbd0f584":"code","211aa5d0":"code","e6e1476b":"code","15295427":"code","1f2a08d9":"code","99a5cb4b":"code","d9ed671c":"code","eb128916":"code","d742588f":"code","c41faaf2":"code","353495bc":"code","421297b1":"code","2551c7c4":"code","f4767d07":"code","ebd95086":"code","e689dee5":"code","23638c59":"code","05e9837c":"code","77d0a7d5":"code","749703ad":"markdown","0f5732c5":"markdown","7c09f72f":"markdown","7c79b76f":"markdown","dd8284ee":"markdown","7381313a":"markdown","e84cc382":"markdown","f541203e":"markdown","399b1747":"markdown","933fa205":"markdown","bdb2a1ff":"markdown","d73a433e":"markdown","a102b71f":"markdown","9f810eeb":"markdown","63c2b70e":"markdown","b0a2272c":"markdown","ff2d5281":"markdown","633a6ec7":"markdown"},"source":{"6c28bd7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b24cd457":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport spacy\nfrom spacy import displacy\nfrom spacy.util import minibatch, compounding\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style(\"darkgrid\")\nplt.style.use(\"fivethirtyeight\")","5c77802c":"df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ndf.head(10)","85670206":"df.tail()","50a607ea":"# rows and columns\ndf.shape","9970bffe":"# info of dataset\ndf.info()","c36e1582":"df.isna().sum()","e25226a5":"import missingno as msno\nmsno.matrix(df)","03a14c86":"df.location.value_counts().head(30)","31b59d90":"df.columns","60325bac":"new_df = df[[\"text\",\"target\"]]\nnew_df.head(10)","ff7fc4d7":"sns.countplot(df[\"target\"],palette=\"BuPu\")","9ac03abe":"from sklearn.utils import resample\ntrain_majority = df[df.target==0]\ntrain_minority = df[df.target==1]\ntrain_minority_upsampled = resample(train_minority, \n                                 replace=True,    \n                                 n_samples=len(train_majority),   \n                                 random_state=123)\nnew_df = pd.concat([train_minority_upsampled,train_majority])","be3e4ba8":"sns.countplot(new_df.target, palette= \"BuPu\")","14d55d55":"# Tokenization\nspacy_tok = spacy.load(\"en_core_web_sm\")\nsample_tweet = new_df.text[105]\nsample_tweet","489cb919":"!wget https:\/\/raw.githubusercontent.com\/tylerneylon\/explacy\/master\/explacy.py","a83f09cf":"import explacy\nexplacy.print_parse_info(spacy_tok,\"Tornado is very severe in North part of US\")","6e75c518":"explacy.print_parse_info(spacy_tok,sample_tweet)","a3ea4468":"sentence_spans = list(parsed_tweet)\nsentence_spans","bbd0f584":"# parsed text representation which shows relation\ndisplacy.render(parsed_tweet,style=\"dep\",jupyter=True,  options={\"distance\":120})","211aa5d0":"!pip install scattertext\nimport scattertext as st\nnlp = spacy.load('en',disable_pipes=[\"tagger\",\"ner\"])","e6e1476b":"new_df.head()","15295427":"new_df[\"parsed\"] = new_df.text.apply(nlp)\n#corpus = st.CorpusFromParsedDocuments(new_df,category_col=\"target\",parsed_col=\"parsed\").build","1f2a08d9":"new_df.head()","99a5cb4b":"new_df[\"tuples\"] = new_df.apply(lambda row: (row[\"text\"],row[\"target\"]),axis=1)\ntrain = new_df.tuples.tolist()\ntrain[:5]","d9ed671c":"#functions from spaCy documentation\ndef load_data(limit=0, split=0.8):\n    train_data = train\n    np.random.shuffle(train_data)\n    train_data = train_data[-limit:]\n    texts, labels = zip(*train_data)\n    cats = [{'POSITIVE': bool(y)} for y in labels]\n    split = int(len(train_data) * split)\n    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n\ndef evaluate(tokenizer, textcat, texts, cats):\n    docs = (tokenizer(text) for text in texts)\n    tp = 1e-8  # True positives\n    fp = 1e-8  # False positives\n    fn = 1e-8  # False negatives\n    tn = 1e-8  # True negatives\n    for i, doc in enumerate(textcat.pipe(docs)):\n        gold = cats[i]\n        for label, score in doc.cats.items():\n            if label not in gold:\n                continue\n            if score >= 0.5 and gold[label] >= 0.5:\n                tp += 1.\n            elif score >= 0.5 and gold[label] < 0.5:\n                fp += 1.\n            elif score < 0.5 and gold[label] < 0.5:\n                tn += 1\n            elif score < 0.5 and gold[label] >= 0.5:\n                fn += 1\n    precision = tp \/ (tp + fp)\n    recall = tp \/ (tp + fn)\n    f_score = 2 * (precision * recall) \/ (precision + recall)\n    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}\n\n#(\"Number of texts to train from\",\"t\" , int)\nn_texts=30000\n#You can increase texts count if you have more computational power.\n\n#(\"Number of training iterations\", \"n\", int))\nn_iter=10","eb128916":"nlp = spacy.load('en_core_web_sm')","d742588f":"# add the text classifier to pipeline if it doesn't\n# nlp.create_pipe works for built-ins that are registered with spaCy\nif 'textcat' not in nlp.pipe_names:\n    textcat = nlp.create_pipe('textcat')\n    nlp.add_pipe(textcat,last=True)\nelse:\n    textcat = nlp.get_pipe('textcat')\n\n# add label to text classifier\ntextcat.add_label(\"POSITIVE\")\n\n# load the data\nprint(\"Loading the Disaster Tweets...\")\n(train_texts, train_cats),(dev_texts, dev_cats) = load_data(limit=n_texts)\nprint(\"Using {} examples ({} training {} evaluation)\".format(n_texts, len(train_texts),len(dev_texts)))\ntrain_data = list(zip(train_texts,[{'cats': cats} for cats in train_cats]))","c41faaf2":"# get names of other pipes to disable them during training\nother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\nwith nlp.disable_pipes(*other_pipes):  # only train textcat\n    optimizer = nlp.begin_training()\n    print(\"Training the model...\")\n    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n    for i in range(n_iter):\n        losses = {}\n        # batch up the examples using spaCy's minibatch\n        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n        for batch in batches:\n            texts, annotations = zip(*batch)\n            nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n                       losses=losses)\n        with textcat.model.use_params(optimizer.averages):\n            # evaluate on the dev data split off in load_data()\n            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n              .format(losses['textcat'], scores['textcat_p'],\n                      scores['textcat_r'], scores['textcat_f']))","353495bc":"test_text1 = \"Earthquake is affecting Japan since 1956\"\ntest_text2 = \"Coronavirus is not anymore in Delhi.\"\ndoc = nlp(test_text1)\ntest_text1, doc.cats","421297b1":"doc2 = nlp(test_text2)\ntest_text2, doc2.cats","2551c7c4":"test_text3 = new_df.text[96]\ntest_text3","f4767d07":"doc3 = nlp(test_text3)\ntest_text3, doc3.cats","ebd95086":"test_text4 = new_df.text[66]\ntest_text4","e689dee5":"doc4 = nlp(test_text4)\ntest_text4, doc4.cats","23638c59":"df_test = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\ndf_test.head(4)","05e9837c":"test_text5 = df_test.text[3]\ntest_text5","77d0a7d5":"doc5 = nlp(test_text5)\ntest_text5, doc5.cats","749703ad":"**Testing our model through random inputs:**","0f5732c5":"# SpaCy\n* spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.\n* spaCy is designed specifically for production use and helps you build applications that process and \u201cunderstand\u201d large volumes of text. \n* It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning.","7c09f72f":"# Model Training","7c79b76f":"------------------","dd8284ee":"# Resampling Data","7381313a":"### **Scattertext**\n* A tool for finding distinguishing terms in small-to-medium-sized corpora, and presenting them in a interactive scatter plot with non-overlapping term labels. Exploratory data analysis just got more fun.","e84cc382":"<div class=\"alert alert-box alert-warning\">\nSome functions are taken from spaCy documentation.\n<\/div>","f541203e":"**SpaCy Text Categorizer:**\n* We will train convolutional neural network text classifier on our Coronavirus Tweets using spaCy's new TextCategorizer component.\n* SpaCy provides classification model with multiple labels,non_mutually exclusive labels.The TextCategorizer uses its own CNN to balance weights and other pipeline components.","399b1747":"# Importing Modules","933fa205":"* Most tweets were from USA","bdb2a1ff":"<div class=\"alert alert-box alert-info\">\nOur SpaCy model is working fine. \n    \nWe can try predicting with test data also.\n<\/div>","d73a433e":"![sw.jpg](attachment:745a767e-aded-44d9-ab7d-9af781188488.jpg)","a102b71f":"* Checkout [this site](https:\/\/spacy.io\/usage\/spacy-101) for more applications of `spaCy`.","9f810eeb":"![460993-Darth_Vader-Star_Wars-Sith-lightsaber.jpg](attachment:fd1474fc-f009-4d89-b849-b35b41b8a273.jpg)","63c2b70e":"<div class=\"alert alert-box alert-warning\">\nUPVOTE if you find this kernel insighful! This helps me stay motivated\ud83d\ude0a.\n    \nSee ya!\n<\/div>","b0a2272c":"--------------------","ff2d5281":"### **Explacy**\n* A small tool that explains spaCy parse results","633a6ec7":"-------------------"}}