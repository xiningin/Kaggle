{"cell_type":{"47dd1d3e":"code","89c67527":"code","085f5292":"code","bfcba50d":"code","028b2f9b":"code","81d48870":"code","af9ddc33":"code","1377daca":"code","17646890":"code","475d046a":"code","f7addbff":"code","ef465db0":"code","442ada7d":"code","53a3a478":"markdown","4936e004":"markdown","6cfd1b07":"markdown","9b9785a7":"markdown","954cfd7a":"markdown","98524559":"markdown","1d9d6cc1":"markdown","828fab5d":"markdown","16b7ab90":"markdown","0717ba45":"markdown","490b2163":"markdown","d27bdc88":"markdown","ad89286a":"markdown","2cd9fe19":"markdown","dceaf079":"markdown","46dd1f6b":"markdown"},"source":{"47dd1d3e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools","89c67527":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","085f5292":"# divide training data into features and labels\nX_train = train.iloc[:,1:]\ny_train = train.iloc[:,0]","bfcba50d":"# Reshape and normalize image\nX_train = X_train.values.reshape(-1, 28, 28, 1)\/255.\ntest = test.values.reshape(-1, 28, 28, 1)\/255.\n# One Hot encoding the label\ny_train = to_categorical(y_train, 10)","028b2f9b":"random_seed = 0\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=random_seed)","81d48870":"datagen = ImageDataGenerator(\n            rotation_range=10,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            zoom_range=0.1\n            )","af9ddc33":"model = Sequential()\n\nmodel.add(Conv2D(32, (5,5), padding='same', input_shape=X_train.shape[1:], activation='relu'))\nmodel.add(Conv2D(32, (5,5), padding='same', activation='relu'))\nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","1377daca":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","17646890":"EPOCHS = 30\nBATCH_SIZE = 20\ncallback_list = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1),\n    EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=4)\n]\n\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n                   epochs=EPOCHS,\n                   callbacks=callback_list,\n                   validation_data=(X_val, y_val),\n                   steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE)","475d046a":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nfig, ax = plt.subplots(figsize=(12,4))\nax.plot(loss, 'b', label='Training loss')\nax.plot(val_loss, 'r', label='Validation loss')\nax.legend()","f7addbff":"def plot_confustion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Oranges):\n    plt.figure(figsize=(10,7))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i , cm[i,j],\n                horizontalalignment='center',\n                color='white' if cm[i, j] > thresh else 'black')\n    plt.tight_layout()\n    plt.xlabel('True label')\n    plt.ylabel('Predicted label')","ef465db0":"y_pred = model.predict(X_val)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_real_classes = np.argmax(y_val, axis=1)\ncm = confusion_matrix(y_pred_classes, y_real_classes)\nplot_confustion_matrix(cm, classes=range(10))","442ada7d":"results = model.predict(test)\nresults = np.argmax(results, axis=1)\nresults = pd.Series(results, name='Label')\nsubmission = pd.concat([pd.Series(range(1,28001), name='ImageID'), results], axis=1)\nsubmission.to_csv('submission.csv', index=False)","53a3a478":"<a id=\"2\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>2. Data preparation<\/center><\/h1>","4936e004":"<a id=\"6\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>6. Create submission<\/center><\/h1>","6cfd1b07":"### 2.2 Optimize the data","9b9785a7":"### 3.1 Define model","954cfd7a":"### 5.1 Training and validation curves","98524559":"<a id=\"3\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>3. Build CNN<\/center><\/h1>","1d9d6cc1":"### 3.2 Compile","828fab5d":"### 5.2 Confusion matrix","16b7ab90":"# Digit Recognizer with keras CNN","0717ba45":"### 2.3 split training and validation set","490b2163":"* [1. Import required libraries](#1)\n* [2. Data preparation](#2)\n* [3. Build CNN](#3)\n* [4. Training](#4)\n* [5. Evaluate the model](#5)\n* [6. Create submission](#6)","d27bdc88":"### 2.4 Data Augmentation","ad89286a":"<a id=\"1\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>1. Import required libraries<\/center><\/h1>","2cd9fe19":"### 2.1 load dataset","dceaf079":"<a id=\"5\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>5. Evaluate the model<\/center><\/h1>","46dd1f6b":"<a id=\"4\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>4. Training<\/center><\/h1>"}}