{"cell_type":{"f1e6d37f":"code","4fbe9b68":"code","67307600":"code","f15498b2":"code","ef3a38c6":"code","36e38ed3":"code","aac7ddbb":"code","612e2929":"code","80fa0662":"code","96c6348f":"code","e9db21b9":"code","1d369cf9":"code","bd59290b":"code","35e3088f":"code","41b754a0":"code","d3751ca6":"code","b4e536d1":"code","c7ee4a8a":"code","d6e701dc":"code","7522b332":"code","e5244180":"markdown","6933d4b0":"markdown","81709483":"markdown","9a80a197":"markdown","cf0f4f44":"markdown","cdea248e":"markdown","e9046b12":"markdown","0f5b7dca":"markdown","b3517985":"markdown","2cf8aab4":"markdown","d8764911":"markdown"},"source":{"f1e6d37f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4fbe9b68":"df=pd.read_csv('..\/input\/pulsar_stars.csv')","67307600":"# look first five data \ndf.head()","f15498b2":"df.info()","ef3a38c6":"# summary statistic data \ndf.describe()","36e38ed3":"df.target_class.value_counts()\nsns.countplot(df.target_class)\nplt.show()","aac7ddbb":"# pair plot \nsns.pairplot(data=df,\n             diag_kind=\"kde\", \n             markers=\".\",\n             plot_kws=dict(s=50, edgecolor=\"b\", linewidth=1),\n             hue=\"target_class\",\n             vars=[\" Mean of the integrated profile\",\n                   \" Excess kurtosis of the integrated profile\",\n                   \" Skewness of the integrated profile\",\n                   \" Mean of the DM-SNR curve\",\n                   \" Excess kurtosis of the DM-SNR curve\",\n                   \" Skewness of the DM-SNR curve\"],\n                   diag_kws=dict(shade=True))\n\nplt.tight_layout()\nplt.show() ","612e2929":"# heatmap \ndf.corr()\nsns.heatmap(df.corr(),cmap=\"YlGnBu\",linewidths=.5)\nplt.title('Corelation Heatmap')\nplt.show()","80fa0662":"f,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(df.corr(), annot=True, linewidths=.5, cmap=\"YlGnBu\",fmt= '.1f',ax=ax)\nplt.title('Corelation Map')\nplt.show()","96c6348f":"# violinplot\n# data normalization\ndf_nor=(df - np.min(df))\/(np.max(df)-np.min(df))\n\nsns.violinplot(data=df,y=\" Mean of the integrated profile\",x=\"target_class\")\nplt.show()\n\nsns.violinplot(data=df,y=\" Mean of the DM-SNR curve\",x=\"target_class\")\nplt.show()","e9db21b9":"#Set x and y values\ny=df.target_class.values\nx_df=df.drop(['target_class'],axis=1)\n#normalization\nx=(x_df-np.min(x_df))\/(np.max(x_df)-np.min(x_df))","1d369cf9":"# train\/test\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)","bd59290b":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(x_train,y_train)\nprint('lr accuracy :', lr.score(x_test,y_test))\n\n# confusion matrix\ny_pred = lr.predict(x_test)\ny_true = y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_lr = confusion_matrix(y_true,y_pred)","35e3088f":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=3)\nknn.fit(x_train,y_train)\nprint('knn accuracy :',knn.score(x_test,y_test))\n# confisioun matrix\ny_pred = knn.predict(x_test)\ny_true = y_test\n\n# confisuon matrix\nfrom sklearn.metrics import confusion_matrix\ncm_knn = confusion_matrix(y_true,y_pred)\n","41b754a0":"score_list=[]\nfor each in range(1,15):\n    knn2=KNeighborsClassifier(n_neighbors=each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n\nplt.plot(range(1,15),score_list)\nplt.xlabel('k values')\nplt.ylabel('accuracy')\nplt.show()","d3751ca6":"from sklearn.svm import SVC\nsvm=SVC(random_state=1)\nsvm.fit(x_train,y_train)\nprint('svm accuracy :', svm.score(x_test,y_test))\n\n# confisuon matrix\ny_pred = svm.predict(x_test)\ny_true = y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_svm = confusion_matrix(y_true,y_pred)","b4e536d1":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(x_train,y_train)\nprint('nb accuracy : ', nb.score(x_test,y_test))\n\n# confisuon matrix\ny_pred = nb.predict(x_test)\ny_true = y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_nb = confusion_matrix(y_true,y_pred)","c7ee4a8a":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\nprint('dt.accuracy : ', nb.score(x_test,y_test))\n\n# confisuon matrix\ny_pred = dt.predict(x_test)\ny_true = y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_dt = confusion_matrix(y_true,y_pred)\n","d6e701dc":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrf.fit(x_train,y_train)\nprint('rf accuracy : ', rf.score(x_test,y_test))\n\n# confision matrix\ny_pred = rf.predict(x_test)\ny_true = y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_rf = confusion_matrix(y_true,y_pred)","7522b332":"plt.figure(figsize=(20,15))\n\nplt.suptitle(\"Confusion Matrixes\",fontsize=20)\n\nplt.subplot(2,3,1)\nplt.title(\"Logistic Regression Confusion Matrix\")\nsns.heatmap(cm_lr,cbar=False,annot=True,cmap=\"Greens\",fmt=\"d\")\n\nplt.subplot(2,3,2)\nplt.title(\"K Nearest Neighbors Confusion Matrix\")\nsns.heatmap(cm_knn,cbar=False,annot=True,cmap=\"Greens\",fmt=\"d\")\n\nplt.subplot(2,3,3)\nplt.title(\"Support Vector Machine Confusion Matrix\")\nsns.heatmap(cm_svm,cbar=False,annot=True,cmap=\"Greens\",fmt=\"d\")\n\nplt.subplot(2,3,4)\nplt.title(\"Naive Bayes Confusion Matrix\")\nsns.heatmap(cm_nb,cbar=False,annot=True,cmap=\"Greens\",fmt=\"d\")\n\nplt.subplot(2,3,5)\nplt.title(\"Decision Tree Classifier Confusion Matrix\")\nsns.heatmap(cm_dt,cbar=False,annot=True,cmap=\"Greens\",fmt=\"d\")\n\nplt.subplot(2,3,6)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(cm_rf,cbar=False,annot=True,cmap=\"Greens\",fmt=\"d\")\n\nplt.show()","e5244180":"CONCLUS\u0130ON:\nin this data set, KNN algorithm has the highest accuracy for predicte.We can see that on the conclusion matrix\n","6933d4b0":"Visualization Confision Matrix","81709483":"SVM","9a80a197":"\u0130mport library","cf0f4f44":"Logistic Regression","cdea248e":"KNN","e9046b12":"Naive Bayes","0f5b7dca":"Exploratory Data Analysis","b3517985":"Random Forest","2cf8aab4":"Find best k value","d8764911":"Decision Tree"}}