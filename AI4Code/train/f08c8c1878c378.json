{"cell_type":{"1210d4a1":"code","20e1a844":"code","ef054f56":"code","611a4423":"code","80b1e18d":"code","b6e6460c":"code","01dcbc8a":"code","e79ae7ad":"code","3c5dc0d5":"code","0d54bf20":"code","c0e6f834":"code","c9da3ab4":"code","afc7cc9e":"code","a661cdf7":"code","35cd0450":"code","592eb1a5":"code","9d827159":"code","810d4210":"code","fe410bde":"code","5e686cb5":"code","ca89dd91":"code","844461b6":"code","e0957bf6":"code","d2081960":"code","51da9d27":"code","34071e28":"code","deed59fd":"code","de150a3d":"code","73b77e89":"code","5360c32d":"code","ebd063cd":"code","82796fc6":"code","7706091c":"code","718c8b99":"code","346a9875":"code","720274a6":"code","a2423741":"code","7fdf8825":"code","97537410":"code","957c443b":"code","437876a4":"markdown","e29cab05":"markdown","2d29a7c5":"markdown","324f624e":"markdown","865e247e":"markdown","e2239208":"markdown","db03b4ef":"markdown","5f513683":"markdown","0a8bbc53":"markdown","96f72ec4":"markdown","53df491d":"markdown","e4e7d753":"markdown","0f4d6858":"markdown","6bd0eb4b":"markdown","55471ef1":"markdown","56f6a589":"markdown"},"source":{"1210d4a1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as st\nimport math, gc, re, warnings\nfrom nltk.tokenize import sent_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom tqdm.auto import tqdm\nfrom os import listdir\nfrom os.path import isfile, join\nwarnings.filterwarnings(\"ignore\")","20e1a844":"df = pd.DataFrame(pd.read_csv('..\/input\/feedback-prize-2021\/train.csv'))\ndf","ef054f56":"df['sentence_num'] = df.groupby('id').cumcount() + 1\ndf['total_sentences'] = df.groupby('id')['sentence_num'].transform('max')\ndf['sentence_location'] = round(df.sentence_num\/df.total_sentences, 2) * 10\ndf['words_num'] = df['discourse_text'].str.split(' ').str.len()\ndf['char_num'] = df['discourse_text'].str.len()\n\ndf = df.rename(columns={'discourse_type':'class',\n                        'discourse_text':'text',\n                        'discourse_start':'start_loc',\n                        'discourse_end':'end_loc'})\n\ndf.head()","611a4423":"fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n# discourse type breakdown\ndf['class'].value_counts().plot.bar(title='class', ax=ax1)\ndf['discourse_type_num'].value_counts().plot.bar(title='discourse_type_num', ax=ax2)\nplt.tight_layout()","80b1e18d":"df.groupby('id')['total_sentences'].first().plot.hist(grid=True, title='Total sentences frequency')\nplt.tight_layout()","b6e6460c":"# discourse start\/end frequencies \nfig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,3))\ndf.start_loc.plot.hist(grid=True, bins=20, title='start location', ax=ax1)\ndf.end_loc.plot.hist(grid=True, bins=20, title='end location', ax=ax2)\nplt.tight_layout()","01dcbc8a":"# length of discourse text\nfig, ((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4,2, figsize=(15,10))\n\ntypes = df['class'].unique().tolist()\naxs = [ax1,ax2,ax3,ax4,ax5,ax6,ax7]\n\ndef plot_length(discourse):\n    df.loc[df['class']==discourse]['text'].str.split(' ').str.len()\\\n        .plot.hist(grid=True, bins=20, title=f'{discourse} text length frequency: number of words', ax=axs[types.index(discourse)])\n    \nfor x in types:\n    plot_length(x)\n\nplt.tight_layout()","e79ae7ad":"# length of discourse text\nfig, ((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4,2, figsize=(15,10))\n\naxs = [ax1,ax2,ax3,ax4,ax5,ax6,ax7]\n\ndef sentence_number(discourse):\n    df.loc[df['class']==discourse]['text'].str.len()\\\n        .plot.hist(grid=True, bins=20, title=f'{discourse} character number frequency', ax=axs[types.index(discourse)])\n    \nfor x in types:\n    sentence_number(x)\n\nplt.tight_layout()","3c5dc0d5":"# length of discourse text\nfig, ((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4,2, figsize=(15,10))\n\naxs = [ax1,ax2,ax3,ax4,ax5,ax6,ax7]\n\ndef plot_length(discourse):\n    df.loc[df['class']==discourse]['sentence_num']\\\n        .plot.hist(grid=True, bins=20, title=f'{discourse} sentence number frequency', ax=axs[types.index(discourse)])\n    \nfor x in types:\n    plot_length(x)\n\nplt.tight_layout()","0d54bf20":"# length of discourse text\nfig, ((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4,2, figsize=(15,10))\n\naxs = [ax1,ax2,ax3,ax4,ax5,ax6,ax7]\n\ndef sentence_number(discourse):\n    df.loc[df['class']==discourse]['sentence_location']\\\n        .plot.hist(grid=True, bins=20, title=f'{discourse} essay location frequency', ax=axs[types.index(discourse)])\n    \nfor x in types:\n    sentence_number(x)\n\nplt.tight_layout()","c0e6f834":"words = ''\nstopwords = set(STOPWORDS)\n\n# iterate through the df\nfor val in df['text']:\n\n    val = str(val)\n\n    tokens = val.split()\n\n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n\n    words += \" \".join(tokens)+\" \"\n\nwordcloud = WordCloud(width = 800, height = 800,\n                background_color ='white',\n                stopwords = stopwords,\n                min_font_size = 10).generate(words)\n\n# plot word cloud                       \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title(f'Text word cloud')\nplt.tight_layout(pad = 0)\n\nplt.show()","c9da3ab4":"# add stopwords based on word cloud\nstop_words = ['student','students','school','schools','people','teacher','teachers'] + list(STOPWORDS)","afc7cc9e":"def wc(discourse):\n    words = ''\n    stopwords = set(stop_words)\n\n    # iterate through the df\n    for val in df.loc[df['class']==discourse]['text']:\n\n        val = str(val)\n\n        tokens = val.split()\n\n        for i in range(len(tokens)):\n            tokens[i] = tokens[i].lower()\n\n        words += \" \".join(tokens)+\" \"\n\n    wordcloud = WordCloud(width = 800, height = 800,\n                    background_color ='white',\n                    stopwords = stopwords,\n                    min_font_size = 10).generate(words)\n\n    # plot word cloud                       \n    plt.figure(figsize = (8, 8), facecolor = None)\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.title(f'{discourse} word cloud')\n    plt.tight_layout(pad = 0)\n\n    plt.show()\n    \nwc('Claim')","a661cdf7":"wc('Evidence')","35cd0450":"wc('Position')","592eb1a5":"wc('Concluding Statement')","9d827159":"wc('Lead')","810d4210":"wc('Counterclaim')","fe410bde":"wc('Rebuttal')","5e686cb5":"# select features\/target and split data\nfeatures = df['text']\ntarget = df['class']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features, \n                                                    target, \n                                                    random_state=42)\n\n\nprint(X_train.shape,X_test.shape)","ca89dd91":"# create and test model\/pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n# from sklearn.linear_model import PassiveAggressiveClassifier\n# from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import f1_score\n\nvectorizer = CountVectorizer(ngram_range=(1,2))\nmodel = SGDClassifier()\n\npipe = Pipeline([\n    ('vectorizer', vectorizer),\n    ('model', model)\n])\n\npipe.fit(X_train, y_train)\n\ntest_score = pipe.score(X_test, y_test)\npred = pipe.predict(X_test)\nf1 = f1_score(y_test, pred, average='micro')\n\nprint('test score:', test_score)\nprint('F1 score:', f1)","844461b6":"# get list of file names\ntest_folder = '..\/input\/feedback-prize-2021\/test'\nfilenames = [f for f in listdir(test_folder) if isfile(join(test_folder, f))]\n\n# create dict for all data\nall_data = {'id':[], 'text':[], 'start_loc':[], 'end_loc':[], 'start_word':[], \n            'end_word':[], 'sentence_num':[], 'predictionstrings':[]}\n\n# loop through file names\nfor i in tqdm(range(len(filenames))):\n    \n    path = test_folder + '\/' + filenames[i] #assemble file path\n\n    with open(path, 'r') as f:\n        text = f.read() #read in text\n    f.close()\n\n#     split_text = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', text) #split text into sentence\n\n    split_text = sent_tokenize(text) #split text into sentence\n    \n    string_word = 0 #set predictionstring start\n    string_loc = 0 #set char start\n\n    # loop through sentences and append data to dict lists\n    for sentence in split_text:\n        all_data['id'].append(filenames[i][:-4])\n        all_data['text'].append(sentence)\n        all_data['start_word'].append(string_word)\n        \n        # calculate string end location and update new starting loc\n        word_split = sentence.split(' ')\n        all_data['end_word'].append(string_loc+len(word_split)) \n        string_word += len(word_split)\n        \n        all_data['start_loc'].append(string_loc)\n        string_loc += len(sentence) + 1\n        all_data['end_loc'].append(string_loc)\n        \n\n        \n# create testing DF\ntest_df = pd.DataFrame(data={'id':all_data['id'], \n                             'text':all_data['text'], \n                             'start_loc':all_data['start_loc'], \n                             'end_loc':all_data['end_loc'],\n                             'start_word':all_data['start_word'],\n                             'end_word':all_data['end_word']})\n\n\n# calcuate and add predictionstrings column\nfor index, row in test_df.iterrows():\n    all_data['predictionstrings'].append(' '.join([str(i) for i in range(row.start_word, row.end_word + 1)]))\n\ntest_df['predictionstring'] = all_data['predictionstrings']\n\ntest_df['sentence_num'] = test_df.groupby('id').cumcount() + 1\ntest_df['total_sentences'] = test_df.groupby('id')['sentence_num'].transform('max')\ntest_df['sentence_location'] = round(test_df.sentence_num\/test_df.total_sentences, 2) * 10\ntest_df['words_num'] = test_df['text'].str.split(' ').str.len()\ntest_df['char_num'] = test_df['text'].str.len()\n\ntest_df","e0957bf6":"# make test preds and save output\npreds = pipe.predict(test_df['text'])\ntest_df['class'] = preds\nsubmit_df = test_df[['id','class','predictionstring']]\n# submit_df.to_csv('submission.csv', index=False)\nsubmit_df","d2081960":"fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(18,4))\nsubmit_df['class'].value_counts().plot.bar(title='Sumbission prediction classes', ax=ax1)\npd.Series(pred).value_counts().plot.bar(title='Split-test prediction classes', ax=ax2)\ndf['class'].value_counts().plot.bar(title='Training classes', ax=ax3)\nplt.tight_layout()","51da9d27":"# # training words\n\n# stop_words.append('')\n# def bar_charter(classification, ax):\n#     all_text = ' '.join(df.loc[df.discourse_type==classification].discourse_text.str.lower().tolist())\n#     all_words = [word for word in all_text.split(' ') if word not in stop_words]\n#     pd.Series(all_words).value_counts().head(20).plot.bar(title=f'{classification} word frequency', ax=ax)\n    \n# fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,4))\n    \n# bar_charter('Claim', ax1)\n# bar_charter('Evidence', ax2)","34071e28":"# # submission words\n\n# stop_words.append('')\n# def bar_charter(classification, ax):\n#     all_test_text = ' '.join(test_df.loc[test_df['class']==classification].text.str.lower().tolist())\n#     all_test_words = [word for word in all_test_text.split(' ') if word not in stop_words]\n#     pd.Series(all_test_words).value_counts().head(20).plot.bar(title=f'{classification} word frequency', ax=ax)\n\n    \n# fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,4))\n    \n# bar_charter('Claim', ax1)\n# bar_charter('Evidence', ax2)","deed59fd":"# select features\/target and split data\nfeatures = df[[\n    'start_loc',\n    'end_loc',\n    'text',\n    'sentence_num',\n    'total_sentences',\n    'sentence_location',\n    'words_num',\n    'char_num'\n]]\n\ntarget = df['class']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=.2, random_state=42)\n\nprint(X_train.shape,y_train.shape)","de150a3d":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression, PassiveAggressiveClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\n\n# functions to select numeric and text data by column name\nget_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\nget_numeric_data = FunctionTransformer(lambda x: x[[\n    'start_loc',\n    'end_loc',\n    'sentence_num',\n    'total_sentences',\n    'sentence_location',\n    'words_num',\n    'char_num'\n]], validate=False)\n\nscaler = StandardScaler()\n\nvectorizer = CountVectorizer(ngram_range=(1,2))\ntransformer = TfidfTransformer()\nmodel = SGDClassifier()\n\n\n# create pipeline to process and join features\npipe = Pipeline([\n    ('features', FeatureUnion([\n            ('numeric_features', Pipeline([\n                ('selector', get_numeric_data),\n                ('scaler', scaler)\n            ])),\n             ('text_features', Pipeline([\n                ('selector', get_text_data),\n                ('vectorizer', vectorizer),\n            ]))\n         ])),\n    ('clf', model)\n])\n\n# train model\npipe.fit(X_train, y_train)\n\n# test model\npred = pipe.predict(X_test)\nf1 = f1_score(y_test, pred, average='micro')\n\nprint('F1 score:', f1)","73b77e89":"# make test preds and save output\ntest_features = test_df[[\n   'start_loc',\n   'end_loc',\n   'text',\n   'sentence_num',\n   'total_sentences',\n   'sentence_location',\n   'words_num',\n   'char_num'\n]]\n\npreds = pipe.predict(test_features)\n# probs = pipe.predict_proba(test_features)\ntest_df['class'] = preds\n# test_df['predict_prob'] = probs\n\nsubmit_df = test_df[['id','class','predictionstring']]\n\n# submit_df.to_csv('submission.csv', index=False)\nsubmit_df","5360c32d":"fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(18,4))\nsubmit_df['class'].value_counts().plot.bar(title='Sumbission prediction classes', ax=ax1)\npd.Series(pred).value_counts().plot.bar(title='Split-test prediction classes', ax=ax2)\ndf['class'].value_counts().plot.bar(title='Training classes', ax=ax3)\nplt.tight_layout()","ebd063cd":"(df.groupby('id')['end_loc'].last()-(df.groupby('id')['char_num'].sum())).head(25)","82796fc6":"# filenames = df['id'].unique().tolist()\n\n# train_path = '..\/input\/feedback-prize-2021\/train\/'\n\n# all_text = {}\n\n# for i in tqdm(range(len(filenames))):\n    \n#     path = train_path + filenames[i] + '.txt'\n    \n#     with open(path, 'r') as f:\n#         text = f.read()\n#     f.close()\n    \n#     all_text[filenames[i]] = text\n             \n# len(all_text)","7706091c":"# test_dict = all_text\n\n# unused_sentences = []\n# ids = []\n# for index, row in df.iterrows():\n#     text = test_dict[row['id']][int(row['start_loc']):int(row['end_loc'])]\n#     test_dict[row['id']] = test_dict[row['id']].replace(text, '*'*len(text))\n\n#     for x in filter(None, test_dict[row['id']].split('*')): \n#         if x not in unused_sentences:\n#             if len(x.split(' ')) > 5:\n#                 unused_sentences.append(x)\n#                 ids.append(row['id'])\n\n# unused_df = pd.DataFrame({'id':ids,'unused_sentences':unused_sentences})\n# unused_df","718c8b99":"# unused_df = pd.DataFrame({'id':ids, 'text':unused_sentences, 'class':'no_class'})\n# unused_df['text'] = unused_df['text'].replace('\\s+', ' ', regex=True)\n# unused_df = unused_df.loc[unused_df['text'] != ' ']\n# unused_df","346a9875":"unused_df = pd.DataFrame(pd.read_csv('..\/input\/text-with-no-class\/no_class.csv'))\nall_classes_df = df[['id','text','class']].append(unused_df)\n# all_classes_df.to_csv('no_class.csv')","720274a6":"# select features\/target and split data\nfeatures = all_classes_df['text']\ntarget = all_classes_df['class']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features, \n                                                    target, \n                                                    random_state=42)\n\n\n# create and test model\/pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\n# from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import f1_score\n\nvectorizer = TfidfVectorizer(ngram_range=(1,2))\nmodel = PassiveAggressiveClassifier()\n\npipe = Pipeline([\n    ('vectorizer', vectorizer),\n    ('model', model)\n])\n\npipe.fit(X_train, y_train)\n\ntest_score = pipe.score(X_test, y_test)\npred = pipe.predict(X_test)\nf1 = f1_score(y_test, pred, average='micro')\n\nprint('test score:', test_score)\nprint('F1 score:', f1)","a2423741":"# make test preds and save output\ntest_features = test_df['text']\n\npreds = pipe.predict(test_features)\n# probs = pipe.predict_proba(test_features)\ntest_df['class'] = preds\n# test_df['predict_prob'] = probs\n\nsubmit_df = test_df[['id','class','predictionstring']]\n\n# submit_df.to_csv('submission.csv', index=False)\nsubmit_df","7fdf8825":"fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(18,4))\nsubmit_df['class'].value_counts().plot.bar(title='Sumbission prediction classes', ax=ax1)\npd.Series(pred).value_counts().plot.bar(title='Split-test prediction classes', ax=ax2)\ndf['class'].value_counts().plot.bar(title='Training classes', ax=ax3)\nplt.tight_layout()","97537410":"# submit_df['class'] = np.where(submit_df['class']=='no_class', 'Evidence', submit_df['class'])\nsubmit_df = submit_df.loc[submit_df['class'] != 'no_class']\nfig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(18,4))\nsubmit_df['class'].value_counts().plot.bar(title='Sumbission prediction classes', ax=ax1)\npd.Series(pred).value_counts().plot.bar(title='Split-test prediction classes', ax=ax2)\ndf['class'].value_counts().plot.bar(title='Training classes', ax=ax3)\nplt.tight_layout()","957c443b":"submit_df.to_csv('submission.csv', index=False)","437876a4":"**This model scored 0.145**","e29cab05":"Much better! But how well will it work with the actual test data?","2d29a7c5":"Looks like there are some unaccounted for characters.","324f624e":"# Making predictions","865e247e":"# Retesting\nFrom the EDA earlier, it appears some classes appear more frequently in certain locations within a given essay. Let's add some features!","e2239208":"# Checking predictions ","db03b4ef":"# Training\/testing basic model","5f513683":"### Word clouds","0a8bbc53":"### Discourse by the numbers","96f72ec4":"# EDA","53df491d":"## Create test set","e4e7d753":"Okay, so too many \"claim\" predictions in the submission set. Let's look at the words again.","0f4d6858":"PassiveAggressiveClassifier: .59\n\n\nRandomForestClassifier: .64\n\n\nSGDClassifier: .69","6bd0eb4b":"# Unclassified text?\n\nCould there be segments of the training essays that are not classified? That might be throwing things off.\n\nLet's see if we can find out.","55471ef1":"There's a lot of overlap here. \"will\", \"one\", \"help\", and \"make\" are very present in both the \"Claim\" and \"Evidence\" classifications.","56f6a589":"Looks a little better, though the model is clearly classifying \"Position\" sentences as \"Rebuttal\".\n\n\n**This model with added features scored .08 (even worse)**\n\n\nSomething is still causing the test set trouble. "}}