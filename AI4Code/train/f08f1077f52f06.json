{"cell_type":{"aa786945":"code","715e5ee6":"code","bcee0bf9":"code","67f6006c":"code","af0b0a80":"code","af9614e6":"code","b12ee82b":"code","dcc85cb2":"code","c3bdbe93":"code","dd9816e7":"code","ca4adb09":"code","abcbdf91":"code","e7dbacde":"code","3de787fa":"code","a54af6cb":"markdown","8f3e8fdc":"markdown","f30c02cd":"markdown","1eab0e80":"markdown","474085f0":"markdown","2e4dcd65":"markdown","5f7af455":"markdown","65d1169e":"markdown","b8509a90":"markdown","82fa13fb":"markdown","e4321123":"markdown","870c3749":"markdown","3dec195c":"markdown"},"source":{"aa786945":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","715e5ee6":"import matplotlib.pyplot as plt \nimport sklearn.datasets as dt\nimport numpy as np\nimport pandas as pd","bcee0bf9":"nomes = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\"]\nscreen = pd.read_csv(\"\/kaggle\/input\/credit-screening.data\", sep=\",\", names=nomes, na_values=\"?\")\nscreen.head()","67f6006c":"screen.describe()","af0b0a80":"screen.isnull().sum()","af9614e6":"col=['A1', 'A4', 'A5', 'A7']\nfor i in col:\n    screen[i]=screen[i].fillna(screen[i].mode)","b12ee82b":"cols=['A2', 'A14']\nfor i in cols:\n    screen[i]=screen[i].fillna(screen[i].mean)","dcc85cb2":"colus = ['A1', 'A4', 'A5', 'A6', 'A7','A9' ,'A10','A12','A13']\nfor i in colus:\n    screen[i]=screen[i].astype('category')","c3bdbe93":"screen[\"A16\"] = screen[\"A16\"].astype('category')\nscreen[\"A16\"].cat.codes","dd9816e7":"screen = pd.get_dummies(screen, columns=['A1','A4','A5','A6','A7','A9','A10','A12','A13'])","ca4adb09":"x = screen.iloc[:,:]\ny = screen.iloc[:,:]\nx.shape","abcbdf91":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)","e7dbacde":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nmodelo= knn.fit(x_train,y_train)\ny_pred = modelo.predict(x_test)","3de787fa":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\ndtc = DecisionTreeClassifier()\nmodelo = dtc.fit(X_train, Y_train)\nY_pred = modelo.predict(X_test)\nY_core = modelo.score(X_test, Y_test)\nY_core","a54af6cb":"11 - Execute o algoritmo de \u00c1rvore de Decis\u00e3o, guarde o resultado da predi\u00e7\u00e3o em uma nova coluna predictAD","8f3e8fdc":"7 - Transforme a coluna objetivo  A16 primeiro para o tipo category e depois fa\u00e7a a codifica\u00e7\u00e3o num\u00e9rica utiliando a fun\u00e7ao df[\"A16\"].cat.codes","f30c02cd":"*  Colunas Categ\u00f3ricas: A1, A4, A5, A6, A7, A9, A10, A12, A13\n*  Colunas Categ\u00f3ricas com valores faltantes : A1, A4, A5, A6, A7 preencher com a moda (valor que mais aparece na coluna)\n*  Colunas com valores cont\u00ednuos: A2, A3, A8, A11, A14, A15\n*  Colunas com valores cont\u00ednuos com valores faltantes:  A2 e A14 preencher com m\u00e9dia","1eab0e80":"3 - utilize   df.isnull().sum() para saber em quais colunas h\u00e1 valores faltantes NaN\n","474085f0":"8 - utilize a fun\u00e7\u00e3o pd.get_dummies para transformar todas as colunas categ\u00f3ricas para indicadores de vari\u00e1veis. \n### df = pd.get_dummies( df, columns=['A1','A4','A5','A6','A7','A9','A10','A12','A13'])","2e4dcd65":"6 - transforme todas as colunas com valores categ\u00f3ricos para o tipo \"category\"  use a fun\u00e7\u00e3o astype\n        * Colunas Categ\u00f3ricas: A1, A4, A5, A6, A7, A9, A10, A12, A13","5f7af455":"9 - utilize train_test_split para criar bases de treino e teste","65d1169e":"10 - Execute o algoritmo dos K vizinhos mais pr\u00f3ximos com K=3, guarde o resultado da predi\u00e7\u00e3o em uma nova coluna do dataframe \"predictKNN\"","b8509a90":"5 - Preencha os campos faltantes das colunas com valores cont\u00ednuos com a m\u00e9dia\n        * Colunas com valores cont\u00ednuos com valores faltantes:  A2 e A14","82fa13fb":"4 - Preencha os campos das colunas com valores categ\u00f3ricos com a moda dos valores da coluna, para isso use a fun\u00e7\u00e3o fillna( ) e moda( )\n    * defina um vetor com as colunas a serem alteradas\n    * use um la\u00e7o para varrer o vetor   (for n in colunas: df.fillna...)","e4321123":"1 - Importar arquivo (credit-screening.data) procure o dataset no Kaggle, caso n\u00e3o encontre, importe o arquivo dispon\u00edvel no Google Classroom. Importe o arquivo substituindo valores faltantes \"?\" por NaN e inserir o nome das colunas utilizando o vetor abaixo.\n\n#### nomes = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\"]5 - ","870c3749":"2 - Execute a fun\u00e7\u00e3o describe para ver um resumo estat\u00edstico descritivo","3dec195c":"1. Title: Credit Approval\n2. Sources: \n    (confidential)\n    Submitted by quinlan@cs.su.oz.au\n3.  Past Usage:\n    See Quinlan,\n    * \"Simplifying decision trees\", Int J Man-Machine Studies 27, Dec 1987, pp. 221-234.\n    * \"C4.5: Programs for Machine Learning\", Morgan Kaufmann, Oct 1992\n4.  Relevant Information:\n    This file concerns credit card applications.  All attribute names\n    and values have been changed to meaningless symbols to protect\n    confidentiality of the data.\n    This dataset is interesting because there is a good mix of\n    attributes -- continuous, nominal with small numbers of\n    values, and nominal with larger numbers of values.  There\n    are also a few missing values.\n5.  Number of Instances: 690\n6.  Number of Attributes: 15 + class attribute\n7.  Attribute Information:\n    A1:\tb, a.\n    A2:\tcontinuous.\n    A3:\tcontinuous.\n    A4:\tu, y, l, t.\n    A5:\tg, p, gg.\n    A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n    A7:\tv, h, bb, j, n, z, dd, ff, o.\n    A8:\tcontinuous.\n    A9:\tt, f.\n    A10:\tt, f.\n    A11:\tcontinuous.\n    A12:\tt, f.\n    A13:\tg, p, s.\n    A14:\tcontinuous.\n    A15:\tcontinuous.\n    A16: +,-         (class attribute)\n8.  Missing Attribute Values:\n    37 cases (5%) have one or more missing values.  The missing\n    values from particular attributes are:\n    A1:  12 ; A2:  12; A4:   6;  A5:   6; A6:   9;   A7:   9;    A14: 13\n9.  Class Distribution\n      +: 307 (44.5%)    -: 383 (55.5%)"}}