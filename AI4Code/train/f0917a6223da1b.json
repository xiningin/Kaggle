{"cell_type":{"78e8952a":"code","d7100598":"code","101f98df":"code","cb501fff":"code","2ef564f0":"code","9a0709e5":"code","5d3e536c":"code","c050401c":"code","918e4e40":"code","de580bf9":"code","c632673b":"code","11af53ac":"code","577db4ba":"markdown","7d3a7386":"markdown","44b878ea":"markdown","e394ba08":"markdown","9a6d6716":"markdown"},"source":{"78e8952a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7100598":"training_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender_data = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","101f98df":"training_data.head()","cb501fff":"test_data.head()","2ef564f0":"gender_data.head()","9a0709e5":"y = training_data.Survived\nX = training_data.drop(['Survived'], axis=1)\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)","5d3e536c":"cols_w_missing_data = [col for col in X_train.columns if X_train[col].isnull().any()]\ncols_w_missing_data","c050401c":"def reformat_data(X_input: pd.DataFrame, ordinal_encoder: OrdinalEncoder, imputer: SimpleImputer, ord_encode_fit=False, imputer_fit=False) -> pd.DataFrame:\n    X_data = X_input.copy()\n    \n#     name_lengths = X_input.Name.notnull() & X_input.Name.str.len()\n#     name_lengths.rename(\"NameLength\", inplace=True).astype('int')\n\n    ticket_content = X_input.Name.notnull() & X_input.Ticket.str.isdigit().astype('int')\n    ticket_content.rename(\"TicketFormat\", inplace=True)\n    \n    X_data.loc[X_data.Cabin.isnull(), 'Cabin'] = '0'   \n    X_data.loc[X_data.Cabin.notnull() & X_data.Cabin.str.contains('A'), 'Cabin'] = '100'\n    X_data.loc[X_data.Cabin.notnull() & X_data.Cabin.str.contains('B'), 'Cabin'] = '90'\n    X_data.loc[X_data.Cabin.notnull() & X_data.Cabin.str.contains('C'), 'Cabin'] = '80'\n    X_data.loc[X_data.Cabin.notnull() & X_data.Cabin.str.contains('D'), 'Cabin'] = '70'\n    X_data.loc[X_data.Cabin.notnull() & X_data.Cabin.str.contains('E'), 'Cabin'] = '60'\n    X_data.loc[X_data.Cabin.notnull() & X_data.Cabin.str.contains('F'), 'Cabin'] = '30'\n    X_data.loc[X_data.Cabin.notnull() & X_data.Cabin.str.contains('G'), 'Cabin'] = '20'\n    X_data.loc[X_data.Cabin.notnull() & X_data.Cabin.str.contains('T'), 'Cabin'] = '10'\n\n    \n    X_data.loc[X_data.Embarked.isnull(), 'Embarked'] = \"X\"\n    X_data.loc[X_data.Sex == 'male', 'Sex'] = 0\n    X_data.loc[X_data.Sex == 'female', 'Sex'] = 1\n    \n    X_data.Cabin.astype('int')\n    X_data.Sex.astype('int')\n    \n    X_data = pd.concat([X_data.drop(['Name', 'Ticket', 'PassengerId'], axis=1), ticket_content], axis=1)\n    \n    encodable_cols = ['Embarked', 'Cabin']\n    \n    if not ord_encode_fit:\n        transformed = ordinal_encoder.fit_transform(X_data[encodable_cols])\n        X_data[encodable_cols] = transformed   \n    else:\n        X_data[encodable_cols] = ordinal_encoder.transform(X_data[encodable_cols])\n        \n    if not imputer_fit:\n        imputed_X = pd.DataFrame(imputer.fit_transform(X_data))\n        imputed_X.columns = X_data.columns\n        X_data = imputed_X\n    else:\n        imputed_X = pd.DataFrame(imputer.transform(X_data))\n        imputed_X.columns = X_data.columns\n        X_data = imputed_X\n        \n    return X_data\n\nencoder = OrdinalEncoder()\nimputer = SimpleImputer()\n\nX_train_edit = reformat_data(X_train, encoder, imputer)\nX_valid_edit = reformat_data(X_valid, encoder, imputer, True, True)\n\nprint(X_train_edit)\n\n# cols_w_missing_data = [col for col in X_train_edit.columns if X_train_edit[col].isnull().any()]\n# cols_w_missing_data","918e4e40":"model = RandomForestRegressor()\nmodel.fit(X_train_edit, y_train)","de580bf9":"preds = model.predict(X_valid_edit)\nmae = mean_absolute_error(preds, y_valid)\nprint('MAE:', mae)","c632673b":"X_test_edit = reformat_data(test_data, encoder, imputer)\npreds_final = model.predict(X_test_edit)\npreds_final[preds_final < 0.5] = 0\npreds_final[preds_final > 0] = 1\npreds_final = preds_final.astype('int')\nprint(preds_final)","11af53ac":"output = pd.DataFrame({'PassengerId': test_data.PassengerId,\n                       'Survived': preds_final})\noutput.to_csv('submission.csv', index=False)","577db4ba":"## Create testing & validation data","7d3a7386":"## Train it up","44b878ea":"### Load the datasets","e394ba08":"# Save final predictions to file","9a6d6716":"## Test against validation set"}}