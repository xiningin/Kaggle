{"cell_type":{"a5a07ff3":"code","f67a226a":"code","58984c24":"code","b8f7c2b5":"code","3be4854c":"code","922096fd":"code","638b709f":"code","53057ad9":"code","385fc611":"code","b8979e2f":"code","2bd33b62":"code","a54691af":"code","83b8db9b":"code","319af327":"code","343c0c16":"code","c63d5ae3":"code","fd269067":"code","3ab5916f":"code","9ca26269":"code","39969571":"code","90dba1b9":"code","eba5bca6":"code","ea0ef171":"code","66872244":"code","f9eb8a62":"code","65fd0a7e":"code","9636c315":"markdown","0775d485":"markdown","4a3ce9df":"markdown","41f0f99b":"markdown","f9aa601c":"markdown","ec6d5912":"markdown","f06d066e":"markdown","9620a35e":"markdown","5642073b":"markdown","a7d4ff17":"markdown","e422e714":"markdown","ce363680":"markdown","cc623a03":"markdown","06120466":"markdown","d2afec65":"markdown","c52f70e9":"markdown","b4beaa33":"markdown","51661084":"markdown","767a995c":"markdown","797b0e88":"markdown","f71160cb":"markdown","7470f105":"markdown","afb9e59e":"markdown"},"source":{"a5a07ff3":"!pip install \/kaggle\/input\/efficientnet-keras-source-code\/ -q --no-deps\n!pip install \/kaggle\/input\/keras-pretrained-imagenet-weights\/image_classifiers-1.0.0-py3-none-any.whl","f67a226a":"import os, numpy, random, pandas, seaborn\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                                        EarlyStopping, ReduceLROnPlateau, \n                                        TensorBoard, CSVLogger)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport efficientnet.tfkeras as efn\nfrom classification_models.tfkeras import Classifiers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","58984c24":"# root\ntrain_data_dir = '..\/input\/flowers-recognition\/flowers\/flowers'\n\n# hyper parameter\nSEED       = 1234\ndim        = 226, 226   # dimensions of our images.\nepochs     = 80         # epochs  \nbatch_size = 16         # batch size\n\ndef seed_all(SEED):\n    tf.random.set_seed(SEED)\n    random.seed(SEED)\n    numpy.random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    \nseed_all(SEED)","b8f7c2b5":"train_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    validation_split=0.20,\n    horizontal_flip=True)\n\n# flow_from_directory\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=dim,\n    batch_size=batch_size,\n    seed=42, \n    shuffle=True,\n    class_mode='categorical', subset='training')\n\n# flow_from_directory\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=dim,\n    batch_size=batch_size,\n    seed=42,\n    shuffle=False,\n    class_mode='categorical', subset='validation')","3be4854c":"# defining some callbacks\ndef Call_Back():\n    # model check point\n    checkpoint = ModelCheckpoint('flowertrainedwg\/seresnext.h5', \n                                 monitor = 'val_loss', \n                                 verbose = 0, save_best_only=True, \n                                 mode = 'min',\n                                 save_weights_only = True)\n    \n    csv_logger = CSVLogger('flowerhistory\/seresnext.csv')\n\n    # reduce learning rate plateau\n    rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n                            patience=5, verbose=1, \n                            mode='auto', \n                            epsilon=0.0001)\n    return [checkpoint, rlr, csv_logger]\n\n# calling all callbacks \ncallbacks = Call_Back()","922096fd":"# model arch\ndef create_model(input_dim, base_model):\n    inp = L.Input(input_dim)\n    \n    curr_output   = base_model(inp)\n    curr_output_1 = L.GlobalAveragePooling2D()(curr_output)\n    curr_output_2 = L.GlobalMaxPooling2D()(curr_output)\n    curr_output   = L.concatenate([curr_output_1, curr_output_2])\n\n    curr_output   = L.BatchNormalization()(curr_output)\n    curr_output   = L.Dense(512, activation='elu')(curr_output)\n    curr_output   = L.Dropout(0.5)(curr_output)\n    curr_output   = L.BatchNormalization()(curr_output)\n    curr_output   = L.Dense(252, activation='elu')(curr_output)\n    curr_output   = L.Dropout(0.5)(curr_output)\n    \n    out = L.Dense(5, activation='softmax') (curr_output)\n    model = Model(inp, out)\n    return model","638b709f":"class_wg_root = '\/kaggle\/input\/keras-pretrained-imagenet-weights\/'\n\n# backbone: \nSeResNeXT50, preprocess_input = Classifiers.get('seresnext50')\nSRNXT = SeResNeXT50(input_shape=(*dim, 3), include_top=False, weights=None)\nSRNXT.load_weights(class_wg_root + 'seresnext50_imagenet_1000_no_top.h5')\n\n# build model\nmodel = create_model(input_dim=(*dim, 3), base_model = SRNXT)\n\n# compile it.\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=0.0001),\n              metrics=['accuracy'])\n\n# plot the model structure\nplot_model(model, to_file='model.png')","53057ad9":"training = False\n\nif training:\n    # fit the model  \n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=len(train_generator) \/\/ batch_size,\n        epochs=epochs,\n        callbacks=callbacks,\n        validation_data=validation_generator,\n        validation_steps=len(validation_generator) \/\/ batch_size)\nelse:\n    model.load_weights('..\/input\/flowertrainedwg\/seresnext.h5')\n    history = pandas.read_csv('..\/input\/flowerhistory\/seresnext.csv')","385fc611":"plt.style.use(\"seaborn\")\n\ndef plot_log(filename, show=True):\n\n    data = filename\n\n    fig = plt.figure(figsize=(8,10))\n    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n    fig.add_subplot(211)\n    \n    for key in data.keys():\n        if key.find('loss') >= 0:  # loss\n            plt.plot(data['epoch'].values, data[key].values, label=key)\n    plt.legend()\n    plt.title('Training and Validtion Loss')\n\n    fig.add_subplot(212)\n    for key in data.keys():\n        if key.find('acc') >= 0:  # acc\n            plt.plot(data['epoch'].values, data[key].values, label=key)\n    plt.legend()\n    plt.title('Training and Validation Accuracy')\n\n    if show:\n        plt.show()\n        \n# plt\nplot_log(history)","b8979e2f":"validation_generator.reset()\nscores = model.evaluate_generator(validation_generator, \n                                  verbose = False,\n                                  steps=len(validation_generator)) \nprint(\"Accuracy = \", scores[1])","2bd33b62":"# set plot figure size for better view\nplt.figure(figsize=(10,7))\n\n# reset the generator\nvalidation_generator.reset()\ny_pred = model.predict_generator(validation_generator, \n                                 steps=len(validation_generator),\n                                 verbose = False)\ny_pred = numpy.argmax(y_pred, axis=1)\n\nconf_mat = confusion_matrix(validation_generator.classes, y_pred)\nseaborn.heatmap(conf_mat, annot=True, fmt=\"d\", cbar = False,  cmap = plt.cm.Blues)\n\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","a54691af":"target = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n\nprint('Classification Report')\nprint('Validation Acc: %2.2f%%' %(100*accuracy_score(validation_generator.classes, y_pred)))\nprint(classification_report(validation_generator.classes, y_pred, target_names = target))","83b8db9b":"# set plot figure size\nfig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n\n# function for scoring roc auc score for multi-class\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n\n    for (idx, c_label) in enumerate(target):\n        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('ROC AUC score:', multiclass_roc_auc_score(validation_generator.classes, y_pred))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nplt.show()","319af327":"efn_wg_root   = '\/kaggle\/input\/efficientnet-keras-noisystudent-weights-b0b7\/'\n\n# backbone: \nefnet =  efn.EfficientNetB3(include_top=False, input_shape=(*dim, 3), weights=None)\nefnet.load_weights(efn_wg_root + 'efficientnet-b3_noisy-student_notop.h5')\n\n# build model\nmodel = create_model(input_dim=(*dim, 3), base_model = efnet)\n\n# compile it.\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=0.0001),\n              metrics=['accuracy'])\nmodel.summary()\n\n# plot the model structure\nplot_model(model, to_file='model.png')","343c0c16":"if training:\n    # fit the model  \n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=len(train_generator) \/\/ batch_size,\n        epochs=epochs,\n        callbacks=callbacks,\n        validation_data=validation_generator,\n        validation_steps=len(validation_generator) \/\/ batch_size)\nelse:\n    model.load_weights('..\/input\/flowertrainedwg\/efficient.h5')\n    history = pandas.read_csv('..\/input\/flowerhistory\/efficient.csv')","c63d5ae3":"# plt\nplot_log(history)","fd269067":"validation_generator.reset()\nscores = model.evaluate_generator(validation_generator, \n                                  verbose = False,\n                                  steps=len(validation_generator)) \nprint(\"Accuracy = \", scores[1])","3ab5916f":"# set plot figure size for better view\nplt.figure(figsize=(10,7))\n\n# reset the generator\nvalidation_generator.reset()\ny_pred = model.predict_generator(validation_generator, \n                                 steps=len(validation_generator),\n                                 verbose = False)\ny_pred = numpy.argmax(y_pred, axis=1)\n\nconf_mat = confusion_matrix(validation_generator.classes, y_pred)\nseaborn.heatmap(conf_mat, annot=True, fmt=\"d\", cbar = False,  cmap = plt.cm.Blues)\n\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","9ca26269":"target = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n\nprint('Classification Report')\nprint('Validation Acc: %2.2f%%' %(100*accuracy_score(validation_generator.classes, y_pred)))\nprint(classification_report(validation_generator.classes, y_pred, target_names = target))","39969571":"# set plot figure size\nfig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n\n# function for scoring roc auc score for multi-class\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n\n    for (idx, c_label) in enumerate(target):\n        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('ROC AUC score:', multiclass_roc_auc_score(validation_generator.classes, y_pred))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nplt.show()","90dba1b9":"def ensemble(models, model_input):\n    \n    Models_output=[model(model_input) for model in models]\n    Avg = L.average(Models_output)\n    \n    modelEnsemble = Model(inputs=model_input, outputs=Avg, name='ensemble')\n    modelEnsemble.summary()\n    modelEnsemble.compile(optimizers.Adam(lr=0.0001),\n                          loss='categorical_crossentropy', \n                          metrics=['accuracy'])\n    return modelEnsemble","eba5bca6":"model_EF = create_model(input_dim=(*dim, 3), base_model = efnet)\nmodel_SE = create_model(input_dim=(*dim, 3), base_model = SRNXT)\n\nmodels = []\n\n# Load weights \nmodel_EF.load_weights('..\/input\/flowertrainedwg\/efficient.h5')\nmodels.append(model_EF)\n\nmodel_SE.load_weights('..\/input\/flowertrainedwg\/seresnext.h5')\nmodels.append(model_SE)\n\nmodel_input = L.Input(shape=models[0].input_shape[1:])\nensemble_model = ensemble(models, model_input)\n\n# plot the model structure\nplot_model(ensemble_model, to_file='model.png')","ea0ef171":"validation_generator.reset()\nscores = ensemble_model.evaluate_generator(validation_generator, \n                                  verbose = False,\n                                  steps=len(validation_generator)) \nprint(\"Accuracy = \", scores[1])","66872244":"# set plot figure size for better view\nplt.figure(figsize=(10,7))\n\n# reset the generator\nvalidation_generator.reset()\ny_pred = ensemble_model.predict_generator(validation_generator, \n                                 steps=len(validation_generator),\n                                 verbose = False)\ny_pred = numpy.argmax(y_pred, axis=1)\n\nconf_mat = confusion_matrix(validation_generator.classes, y_pred)\nseaborn.heatmap(conf_mat, annot=True, fmt=\"d\", cbar = False,  cmap = plt.cm.Blues)\n\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","f9eb8a62":"target = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n\nprint('Classification Report')\nprint('Validation Acc: %2.2f%%' %(100*accuracy_score(validation_generator.classes, y_pred)))\nprint(classification_report(validation_generator.classes, y_pred, target_names = target))","65fd0a7e":"# set plot figure size\nfig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n\n# function for scoring roc auc score for multi-class\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n\n    for (idx, c_label) in enumerate(target):\n        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('ROC AUC score:', multiclass_roc_auc_score(validation_generator.classes, y_pred))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nplt.show()","9636c315":"# Content\n\nIt's important to know the content of this notebook, otherwise it may not come helpful to you at the end and waste your time. **If you're new to deep learning and image classification in general, or want to brush up some old experience, you may stay. :)**\n\n- Multi-class Image Classification with `tf.keras` or `keras`\n- Usage of simple `flow_from_directory` data generator \n- Train 2 state-of-the-art models and compute \n    - loss curve, confusion matrix, classification report \n    - roc auc score \n- How to Ensemble these models for better performance. ","0775d485":"**Evaluate**","4a3ce9df":"## Model: SeResNeXT50","41f0f99b":"**ROC AUC**","f9aa601c":"**Note**, I'm doing some experiment on some more complex data set in my local. And I was making some note on **some fancy technique** during my experiment and thought to share few things here for [this data set](https:\/\/www.kaggle.com\/alxmamaev\/flowers-recognition). \n\n---\n\nI was making this notebook off line and so I imported my desire pre-trained weights. Please, check out the following to data set. It may come to you handy. :)\n\n- [Pretrained Model Weights (Keras)](https:\/\/www.kaggle.com\/ipythonx\/keras-pretrained-imagenet-weights)\n- [EfficientNet Keras Noisy-Student Weights B0-B7](https:\/\/www.kaggle.com\/ipythonx\/efficientnet-keras-noisystudent-weights-b0b7)\n\nThe [pre-trained model weights](https:\/\/www.kaggle.com\/ipythonx\/keras-pretrained-imagenet-weights) contains almost all the imagenet pre-trained weights. If you love to use it, please check this [starting notebook](https:\/\/www.kaggle.com\/ipythonx\/keras-all-models-weights-loader) too, you'll find it helpful. \n\n\n# Version Update\n\n- Version 1: Evaluate **SeResNeXT50 and EfficientNet B3**\nValidation scores are:\n```\n    - SeResNeXT50    : 0.9117305\n    - EfficientNetB3 : 0.9047619\n```\n- Version 2: Ensemble of **SeResNeXT50 and EfficientNet B3** \nValidation score increased\n```\n    - Ensemble :  0.93147504\n``` ","ec6d5912":"## Data Generator","f06d066e":"If you've time, expand the following cell to read some note. Thanks. ","9620a35e":"## Callbacks","5642073b":"**Confusion Matrix**","a7d4ff17":"## Imports","e422e714":"End for Now. ","ce363680":"**Classification Report**","cc623a03":"**Learning Curve**","06120466":"## Model: EfficientNet B3","d2afec65":"# Ensemble (EfficientNetB3 + SeResNeXT50)","c52f70e9":"**ROC AUC**","b4beaa33":"**Classification Report**","51661084":"**!Training, Inferencing**","767a995c":"## Set Param","797b0e88":"## Build Model\n\nI will try on `SeResNeXT50` and `EfficientNetB3` model. The following `create_model` method is same for both backbone model.","f71160cb":"**Evaluate**","7470f105":"## Ensemble of SeResNeXT50 and EfficientNetB3\n```\n- Confusion Metrix , \n- Classification Report , and \n- ROC AUC Graph\n```","afb9e59e":"**Confusion Matrix**"}}