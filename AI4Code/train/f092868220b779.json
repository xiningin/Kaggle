{"cell_type":{"7f2bd33f":"code","987d2a84":"code","ca3f9c2a":"code","c5607154":"code","0924be40":"code","afe8b03b":"code","c1e835ae":"code","3399bb5d":"code","d2c2f535":"code","057197c9":"code","9b094e3c":"code","f04c0bed":"code","7bd96282":"code","dbd50388":"code","cade2d21":"code","32b2dc21":"code","047ec6e0":"code","0f8fad03":"code","a518e7c5":"code","74d307da":"code","b0d6c84e":"code","27d8bb8f":"code","2c1d1afe":"code","09447ea8":"code","68e9815b":"code","bc81135b":"code","1db70b25":"code","1c2516d2":"code","fa47ab03":"code","36c92680":"code","3a9c842b":"code","79acfeb6":"code","2aad9a9c":"code","76559bf7":"code","9b037f6a":"code","652ae21c":"code","7efbfbb5":"code","960f63f5":"code","9618e28e":"code","8e6eb166":"code","91d0e708":"code","6f369bc5":"code","8c96266a":"code","ad9e9c20":"code","d49b0c2c":"code","e51a67f8":"code","0af785a2":"code","8299126e":"code","a817f773":"code","ca15ad03":"code","d84bf4be":"code","bf29e043":"code","48394c34":"code","69b8b257":"code","b17de42a":"code","35530825":"markdown","7aeb452b":"markdown","f73867d3":"markdown","3ed269df":"markdown","fafe22d7":"markdown","d0ec8139":"markdown","620f4f96":"markdown","8d3770e3":"markdown","3415f9f4":"markdown","23b2237f":"markdown","e3878f8c":"markdown","37708f81":"markdown","16e522bc":"markdown","6f9306c9":"markdown","4f30121b":"markdown","2536dd3a":"markdown","e75a85db":"markdown","4f5ae95d":"markdown","b06d5198":"markdown","e46146dc":"markdown","ce920c59":"markdown","51b23600":"markdown","48c60490":"markdown"},"source":{"7f2bd33f":"import numpy as np","987d2a84":"from keras.datasets import cifar10\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()","ca3f9c2a":"import matplotlib.pyplot as plt\nindex = 88\nplt.imshow(X_train[index]), y_train[index]","c5607154":"plt.imshow(X_train[10]), y_train[10]","0924be40":"labels = {0:  'airplane',   #back to the documntation\n          1:  'automobile',\n          2:  'bird', \n          3:  'cat', \n          4:  'deer', \n          5:  'dog', \n          6:  'frog', \n          7:  'horse', \n          8:  'ship', \n          9:  'truck'}\n","afe8b03b":"unique, counts = np.unique(y_train, return_counts=True) #all the classes equal to each other\ndict(zip(unique, counts))","c1e835ae":"labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]","3399bb5d":"def avg_pixels(data):\n  data_avg = data.copy()\n  for i in range(len(data)): #looping over the data\n    for x in range(len(data[0])): #looping over the x_coordinates\n      for y in range(len(data[0].T[0])): #looping over the y_coordinates\n        data_avg[i][x][y] = np.average(data[i][x][y])\n  return data_avg","d2c2f535":"X_train_avg = avg_pixels(X_train)","057197c9":"len(X_train_avg) #for debugging","9b094e3c":"f, axarr = plt.subplots(2,2)\naxarr[0,0].imshow(X_train[1])\naxarr[0,1].imshow(X_train_avg[1])\naxarr[1,0].imshow(X_train[100])\naxarr[1,1].imshow(X_train_avg[100])","f04c0bed":"X_train_avg[0][0][0]","7bd96282":"def convert(data):\n  X_train_avg = avg_pixels(data)\n  imgs = []\n  for i in range(len(data)):\n    img = []\n    for j in range(len(data[0])):\n      tmp = [int(np.unique(hold)[0]) for hold in X_train_avg[i][j]]\n      img.append(tmp)\n    imgs.append(img)\n  return np.asarray(imgs)","dbd50388":"X_train_conv = convert(X_train)","cade2d21":"len(X_train_conv)","32b2dc21":"max(X_train_conv[0].flatten()) * 29791","047ec6e0":"def c_momentum(data, c = 3):\n  m_data = []\n  mean_x = (len(data[0][0]) + 1) \/ 2\n  mean_y = (len(data[0][0].T) + 1) \/ 2\n  for img in data:\n    ms = []\n    for p in range(c+1):\n      for q in range(c+1):\n        if p + q <= c:\n          tmp = np.multiply((np.power(np.arange(len(data[0][0])) - mean_x, p) * np.power(np.arange(len(data[0].T[0] - mean_y)), q)) , img)\n          ms.append(tmp.sum().sum())\n    m_data.append(ms)\n  return np.asarray(m_data)","0f8fad03":"X_train_m = c_momentum(X_train_conv, c  = 3)","a518e7c5":"len(X_train_m[0])","74d307da":"len(X_train_m)","b0d6c84e":"X_train_m[0]","27d8bb8f":"from sklearn.model_selection import train_test_split\nX_trainn, X_val, y_trainn, y_val = train_test_split(X_train_m, y_train, test_size=0.1)","2c1d1afe":"len(X_trainn), len(X_val)","09447ea8":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score","68e9815b":"svc1 = SVC()\nsvc1.fit(X_trainn, y_trainn.ravel())\nsvc2 = SVC(kernel='poly', degree=3)\nsvc2.fit(X_trainn, y_trainn.ravel())\nsvc3 = SVC(kernel='sigmoid', gamma='auto')\nsvc3.fit(X_trainn, y_trainn.ravel())","bc81135b":"print(accuracy_score(svc1.predict(X_val), y_val))\nprint(accuracy_score(svc2.predict(X_val), y_val))\nprint(accuracy_score(svc2.predict(X_val), y_val))","1db70b25":"from sklearn.ensemble import RandomForestClassifier","1c2516d2":"forest1 = RandomForestClassifier(criterion='entropy', max_depth=50)\nforest1.fit(X_trainn, y_trainn.ravel())\nforest2 = RandomForestClassifier(criterion='gini', max_depth=70)\nforest2.fit(X_trainn, y_trainn.ravel())\nforest3 = RandomForestClassifier(criterion='entropy', max_depth=100)\nforest3.fit(X_trainn, y_trainn.ravel())","fa47ab03":"print(accuracy_score(forest1.predict(X_val), y_val))\nprint(accuracy_score(forest2.predict(X_val), y_val))\nprint(accuracy_score(forest3.predict(X_val), y_val))","36c92680":"from sklearn.tree import DecisionTreeClassifier","3a9c842b":"tree1 = DecisionTreeClassifier(criterion='entropy', max_depth=100)\ntree1.fit(X_trainn, y_trainn.ravel())\ntree2 = DecisionTreeClassifier(criterion='entropy', max_depth=150)\ntree2.fit(X_trainn, y_trainn.ravel())\ntree3 = DecisionTreeClassifier(criterion='gini', max_depth=200)\ntree3.fit(X_trainn, y_trainn.ravel())","79acfeb6":"print(accuracy_score(tree1.predict(X_val), y_val))\nprint(accuracy_score(tree2.predict(X_val), y_val))\nprint(accuracy_score(tree3.predict(X_val), y_val))","2aad9a9c":"from sklearn.neighbors import KNeighborsClassifier","76559bf7":"knn1 = KNeighborsClassifier(n_neighbors=4)\nknn1.fit(X_trainn, y_trainn.ravel())\nknn2 = KNeighborsClassifier(n_neighbors=6)\nknn2.fit(X_trainn, y_trainn.ravel())\nknn3 = KNeighborsClassifier(n_neighbors=8)\nknn3.fit(X_trainn, y_trainn.ravel())","9b037f6a":"print(accuracy_score(knn1.predict(X_val), y_val))\nprint(accuracy_score(knn2.predict(X_val), y_val))\nprint(accuracy_score(knn3.predict(X_val), y_val))","652ae21c":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import models, layers","7efbfbb5":"model = Sequential()\nmodel.add(Dense(5, activation='relu', input_shape=(len(X_trainn[0]),)))\nmodel.add(Dense(4, activation='relu'))\nmodel.add(Dense(3, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","960f63f5":"model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])","9618e28e":"model.summary()","8e6eb166":"history = model.fit(X_trainn, y_trainn, epochs=10, \n                    validation_data=(X_val, y_val))","91d0e708":"model2 = models.Sequential()\nmodel2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel2.add(layers.MaxPooling2D((2, 2)))\nmodel2.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D((2, 2)))\nmodel2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","6f369bc5":"model2.add(layers.Flatten())\nmodel2.add(layers.Dense(64, activation='relu'))\nmodel2.add(layers.Dense(10))","8c96266a":"model2.summary()","ad9e9c20":"model2.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model2.fit(X_train, y_train, epochs=10, \n                    validation_data=(X_test, y_test))\n","d49b0c2c":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model2.evaluate(X_test,  y_test, verbose=2)\n","e51a67f8":"from sklearn.metrics import confusion_matrix\nfrom sklearn import metrics","0af785a2":"def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(names))\n    plt.xticks(tick_marks, names, rotation=90)\n    plt.yticks(tick_marks, names)\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","8299126e":"cnn_pred = model2.predict(X_test)\ncnn_pred = np.argmax(cnn_pred,axis=1)\n\ncnn_f1 = metrics.f1_score(y_test, cnn_pred, average= \"weighted\")\ncnn_accuracy= metrics.accuracy_score(y_test, cnn_pred)\ncnn_cm = metrics.confusion_matrix(y_test, cnn_pred)\nprint(\"-----------------Convolutional Neural Network Report---------------\")\nprint(\"F1 score: {}\".format(cnn_f1))\nprint(\"Accuracy score: {}\".format(cnn_accuracy))\nprint(\"Confusion matrix: \\n\", cnn_cm)\nprint('Plotting confusion matrix')\n\nplt.figure()\nplot_confusion_matrix(cnn_cm, labelNames)\nplt.show()\n\nprint(metrics.classification_report(y_test, cnn_pred))","a817f773":"X_test_transformed = convert(X_test)\nX_test_m = c_momentum(X_test_transformed, c  = 3)\ny_test = y_test.ravel()","ca15ad03":"# SVM report and analysis\ny_pred_svc = svc1.predict(X_test_m)\nsvc_f1 = metrics.f1_score(y_test, y_pred_svc, average= \"weighted\")\nsvc_accuracy = metrics.accuracy_score(y_test, y_pred_svc)\nsvc_cm = metrics.confusion_matrix(y_test, y_pred_svc)\nprint(\"-----------------SVM Report---------------\")\nprint(\"F1 score: {}\".format(svc_f1))\nprint(\"Accuracy score: {}\".format(svc_accuracy))\nprint(\"Confusion matrix: \\n\", svc_cm)\nprint('Plotting confusion matrix')\n\nplt.figure()\nplot_confusion_matrix(svc_cm, labelNames)\nplt.show()\n\nprint(metrics.classification_report(y_test, y_pred_svc))","d84bf4be":"# RandomForest report and analysis\ny_pred_forest = forest1.predict(X_test_m)\nforest_f1 = metrics.f1_score(y_test, y_pred_forest, average= \"weighted\")\nforest_accuracy = metrics.accuracy_score(y_test, y_pred_forest)\nforest_cm = metrics.confusion_matrix(y_test, y_pred_forest)\nprint(\"-----------------RandomForest Report---------------\")\nprint(\"F1 score: {}\".format(forest_f1))\nprint(\"Accuracy score: {}\".format(forest_accuracy))\nprint(\"Confusion matrix: \\n\", forest_cm)\nprint('Plotting confusion matrix')\n\nplt.figure()\nplot_confusion_matrix(forest_cm, labelNames)\nplt.show()\n\nprint(metrics.classification_report(y_test, y_pred_forest))","bf29e043":"# KNN report and analysis\ny_pred_knn = knn3.predict(X_test_m)\nknn_f1 = metrics.f1_score(y_test, y_pred_knn, average= \"weighted\")\nknn_accuracy = metrics.accuracy_score(y_test, y_pred_knn)\nknn_cm = metrics.confusion_matrix(y_test, y_pred_knn)\nprint(\"-----------------KNN Report---------------\")\nprint(\"F1 score: {}\".format(knn_f1))\nprint(\"Accuracy score: {}\".format(knn_accuracy))\nprint(\"Confusion matrix: \\n\", knn_cm)\nprint('Plotting confusion matrix')\n\nplt.figure()\nplot_confusion_matrix(knn_cm, labelNames)\nplt.show()\n\nprint(metrics.classification_report(y_test, y_pred_knn))","48394c34":"# DecisionTree report and analysis\ny_pred_tree = tree3.predict(X_test_m)\ntree_f1 = metrics.f1_score(y_test, y_pred_tree, average= \"weighted\")\ntree_accuracy = metrics.accuracy_score(y_test, y_pred_tree)\ntree_cm = metrics.confusion_matrix(y_test, y_pred_tree)\nprint(\"-----------------DecisionTree Report---------------\")\nprint(\"F1 score: {}\".format(tree_f1))\nprint(\"Accuracy score: {}\".format(tree_accuracy))\nprint(\"Confusion matrix: \\n\", tree_cm)\nprint('Plotting confusion matrix')\n\nplt.figure()\nplot_confusion_matrix(tree_cm, labelNames)\nplt.show()\n\nprint(metrics.classification_report(y_test, y_pred_tree))","69b8b257":"scores = [cnn_accuracy, svc_accuracy, forest_accuracy, knn_accuracy, tree_accuracy]\nmodels = [\"CNN\", \"SVC\", \"RandomForest\", \"Knn\", \"DecisionTree\"]\nprint(scores)\nprint(models)","b17de42a":"plt.bar(models, scores)\nplt.show()","35530825":"# Loading the data\nUsing the keras datasets to load the data, the data is already splitted into train and test portions.\nWe are just going to take a portion of the train set and make it our validation set","7aeb452b":"# Error Analysis","f73867d3":"Since now all the RGB channels got the same value no need to keep them all, instead we are going to keep only a single chanel, converting each image into a 32x32 matrix, which will provide an efficient way in computation      \nex. the first pixel of the first image will get the values (61, 61, 61) so  we will make it one channel (61)","3ed269df":" looking at the first image at the first pixel (0, 0) coordinates,at each pixel we got three RGB values and we are going to replace them by a single value computed by their avreage.","fafe22d7":"## SVM","d0ec8139":"# Approaching CIFAR-10\n","620f4f96":"## This notebook made by: Mohammed El-Ammen & Youseef Mo'men","8d3770e3":"As we can see below many diffrient models with diffrient hyperparamters couldn't catch the complexity of the model even the SVMs with rbf and polynomial kernal. this might be due to many resons\n\n\n*   Quality of the data, data doesn't have enough information\n*   simplicity of the models, even tuning the hyper-parapmeters won't add that much\n*   increasing the number of the instances will not add to much, models are too simple \n\n\n*   CNN as we see below are a much more complex model enabling them to detect patterns, edges, ..etc, perform much better\n\n\n\n","3415f9f4":"From the previous graph, it is clear that the normal models fail to grasp the complexity of the data resulting in poor performance.\non the other hand a normal CNN performs well on the test data without a lot of fine tuning, maiking it a good place to start with.","23b2237f":"a sample for converted image into 32 * 32 ","e3878f8c":"## KNN\n","37708f81":"## Avg Pooling","16e522bc":"CNN on the normal data","6f9306c9":"# Building the Model\n","4f30121b":"## Applying the momentum ","2536dd3a":"## Spliting the train data into train and validation by 10%","e75a85db":"## Decision Tree\n","4f5ae95d":"some image are too bad even a human being can't recognize it given the following image which is suppose to be for a **Deer**","b06d5198":"## Random Forest\n","e46146dc":"# Data Preprocessing","ce920c59":"## ANN","51b23600":"After Averging the images there is no change, they are only converted into gray images like the following examples","48c60490":"# Exploring the Data"}}