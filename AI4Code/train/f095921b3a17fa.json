{"cell_type":{"9df9d520":"code","74c0bd3e":"code","ede4262c":"code","ea80acc3":"code","1fc18467":"code","a0433f6c":"code","5dde7b82":"code","a5bd5499":"code","e305ce42":"code","41024ac9":"code","ad74eb7b":"code","2c58adf6":"code","a72cec5f":"code","60265aea":"code","98e94dcf":"code","4b341257":"code","bc4452de":"code","0132989d":"code","4a75338e":"code","b5d4f478":"code","59e8ab3a":"code","87b63f91":"code","2789dc6a":"markdown","45f4e6b4":"markdown","2ae26170":"markdown","e3a7bae3":"markdown","70dc3791":"markdown"},"source":{"9df9d520":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","74c0bd3e":"data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\ndata.loc[data.Sex=='male','Sex'] = 0\ndata.loc[data.Sex=='female','Sex'] = 1\n","ede4262c":"#data[\"Age\"] = data[\"Age\"].fillna(-1)\ndata[\"Age\"].fillna(-1, inplace=True)","ea80acc3":"data","1fc18467":"data.isnull().sum(axis=0)\/len(data)","a0433f6c":"X = data[ [\"Fare\", \"Pclass\",\"Sex\",\"Age\"] ].values\ny = data.Survived.values","5dde7b82":"from sklearn.tree import DecisionTreeClassifier","a5bd5499":"X.shape","e305ce42":"Xtrain = X[0:700]\nYtrain = y[0:700]\n\nXtest  = X[700:]\nYtest  = y[700:]","41024ac9":"model = DecisionTreeClassifier()\n\nmodel.fit(Xtrain, Ytrain)","ad74eb7b":"Ptrain = model.predict(Xtrain)\nscoreTrain = np.sum(Ptrain==Ytrain) \/ len(Ytrain)\nprint('Train score : ', scoreTrain)","2c58adf6":"Ptest = model.predict(Xtest)\nscoreTest = np.sum(Ptest==Ytest) \/ len(Ytest)\nprint('Test score : ', scoreTest)","a72cec5f":"score_train = []\nscore_test  = []\n\nfor depth in range(1, 15):\n    \n    model = DecisionTreeClassifier(max_depth=depth)\n\n    model.fit(Xtrain, Ytrain)\n    \n    Ptrain = model.predict(Xtrain)\n    scoreTrain = np.sum(Ptrain==Ytrain) \/ len(Ytrain)\n    score_train.append( 1-scoreTrain )\n    \n    Ptest = model.predict(Xtest)\n    scoreTest = np.sum(Ptest==Ytest) \/ len(Ytest)\n    score_test.append(1-scoreTest)","60265aea":"plt.figure(figsize=(10,10))\nplt.plot(score_train)\nplt.plot(score_test)","98e94dcf":"from sklearn.model_selection import StratifiedKFold, KFold","4b341257":"y = np.array( [4,5,5,5,4,4,4,5,5,4] )\n#50% de valeur 4 et 50% de valeur 5","bc4452de":"cv = KFold( n_splits=5 )\n\nfor train_index, test_index in cv.split(y):\n    print('train : ',train_index, y[train_index])\n    print('test  : ',test_index,  y[test_index])\n    print('******************')","0132989d":"cv = StratifiedKFold( n_splits=5 )\n\nfor train_index, test_index in cv.split(y,y):\n    print('train : ',train_index, y[train_index])\n    print('test  : ',test_index,  y[test_index])\n    print('******************')","4a75338e":"X = data[ [\"Fare\", \"Pclass\",\"Sex\",\"Age\"] ].values\ny = data.Survived.values\n\ntrain_depth_score = []\ntest_depth_score = []\n\nfor depth in range(1, 15):\n    \n    cv = StratifiedKFold( n_splits=5 )\n\n    score_train_CV = []\n    score_test_CV  = []\n\n    for train_index, test_index in cv.split(y,y):\n            \n        Xtrain = X[train_index]\n        Ytrain = y[train_index]\n        \n        Xtest = X[test_index]\n        Ytest = y[test_index]\n    \n        model = DecisionTreeClassifier(max_depth=depth)\n\n        model.fit(Xtrain, Ytrain)\n\n        Ptrain = model.predict(Xtrain)\n        scoreTrain = np.sum(Ptrain==Ytrain) \/ len(Ytrain)\n        score_train_CV.append( 1-scoreTrain )\n\n        Ptest = model.predict(Xtest)\n        scoreTest = np.sum(Ptest==Ytest) \/ len(Ytest)\n        score_test_CV.append(1-scoreTest)\n        \n    train_depth_score.append( np.mean(score_train_CV) )\n    test_depth_score.append( np.mean(score_test_CV) )\n        \n        ","b5d4f478":"plt.figure(figsize=(10,10))\nplt.plot(train_depth_score)\nplt.plot(test_depth_score)","59e8ab3a":"test_depth_score","87b63f91":"from sklearn.model_selection import GridSearchCV","2789dc6a":"**Selection des param\u00e8tres optimaux de notre mod\u00e8le**","45f4e6b4":"**VALIDATION CROISEE**","2ae26170":"**On remarque qu'en utilisant la validation crois\u00e9e, la prodondeur optimale est 3 et non pas 5**","e3a7bae3":"0.8114285714285714\n0.7329842931937173\n\n0.9085714285714286  \n0.8481675392670157    \n\nTrain score :  0.9814285714285714  ERREUR = 1-0.9814285714285714 = 0.01857\nTest score :  0.7853403141361257   ERREUR = 1-0.7853403141361257 = 0.214","70dc3791":"**On remarque que la profondeur (complexit\u00e9) optimale est 5. Pour cette valeur (depth=5), nous obtenons la plus petite erreur sur le Test**"}}