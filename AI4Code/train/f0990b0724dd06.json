{"cell_type":{"a9aae8b3":"code","ccf70988":"code","408c3ea9":"code","b75215f6":"code","4561479e":"code","cb962204":"code","bbc6cc8d":"code","6ee4b6e4":"code","3948c1b7":"code","b7260990":"code","10ace61c":"code","b28c6dce":"code","7f6ecdff":"code","1478fa29":"code","ab0ae7c4":"code","22dc858a":"code","bcd28b02":"code","c2f8f7f2":"code","d69ea4a7":"code","069d3817":"code","fc24c94b":"code","28e1c8b0":"code","b6004756":"code","fc262f42":"code","7e23e439":"code","d0647b01":"code","30048f4f":"markdown"},"source":{"a9aae8b3":"# saewon\ub2d8 kernel\uc744 \uc0ac\uc6a9\ud588\uc74c\uc744 \uc54c\ub824\ub4dc\ub9bd\ub2c8\ub2e4.\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))","ccf70988":"!pip install efficientnet_pytorch\n!pip install pretrainedmodels","408c3ea9":"TEST_IMAGE_PATH = Path('..\/input\/testdata\/test_crop')\ntest_csv = pd.read_csv('..\/input\/testdata\/test.csv')","b75215f6":"import os\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport glob\nfrom PIL import Image, ImageEnhance, ImageOps\n\nfrom tqdm import tqdm, tqdm_notebook\n\nimport torch\nfrom torch import nn, cuda\nfrom torch.autograd import Variable \nimport torch.nn.functional as F\nimport torchvision as vision\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.metrics import f1_score","4561479e":"# seed value fix\n# seed \uac12\uc744 \uace0\uc815\ud574\uc57c hyper parameter \ubc14\uafc0 \ub54c\ub9c8\ub2e4 \uacb0\uacfc\ub97c \ube44\uad50\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 2019\nseed_everything(SEED)","cb962204":"class TestDataset(Dataset):\n    def __init__(self, df, mode='test', transforms=None):\n        self.df = df\n        self.mode = mode\n        self.transform = transforms[self.mode]\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        \n        new_idx = idx % len(self.df)\n        image = Image.open(TEST_IMAGE_PATH \/ self.df[new_idx]).convert(\"RGB\")\n        \n        if self.transform:\n            image = self.transform(image)\n            \n        return image    ","bbc6cc8d":"target_size = (299, 299)\n\ndata_transforms = {\n    'test': vision.transforms.Compose([\n        vision.transforms.Resize(target_size),\n        vision.transforms.RandomRotation(5),\n        vision.transforms.RandomHorizontalFlip(),\n        vision.transforms.RandomResizedCrop(target_size, scale=(0.8,1.0)),\n        vision.transforms.ToTensor(),\n        vision.transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n}","6ee4b6e4":"x_test = test_csv['img_file'][:100]\nnum_classes = 196","3948c1b7":"weights_path = Path('..\/input\/careff7')\nweight_list = os.listdir(weights_path)","b7260990":"from efficientnet_pytorch import EfficientNet\ntta = 5","10ace61c":"from collections import OrderedDict\nbatch_size = 256\ntest_dataset = TestDataset(x_test, mode='test', transforms=data_transforms)\ntest_loader = DataLoader(test_dataset, \n                        batch_size=batch_size,\n                        num_workers=2,\n                        shuffle=False,\n                        pin_memory=True,\n                        )\n\n\ntotal_num_models = len(weight_list)*tta \n\nall_prediction1 = np.zeros((len(test_dataset), num_classes))\n\nfor i, weight in enumerate(weight_list):\n    print(\"fold {} prediction starts\".format(i+1))\n    \n    for _ in range(tta):\n        print(\"tta {}\".format(_+1))\n        \n        model = EfficientNet.from_pretrained('efficientnet-b7')\n        # Unfreeze model weights\n        for param in model.parameters():\n            param.requires_grad = True\n        model._fc = nn.Sequential(\n            nn.Dropout(p=0.4),\n            nn.Linear(in_features=2560, out_features=196, bias=True)\n        )\n        \n        # DataParallel \ud559\uc2b5\ub41c weight\ub97c \ubb38\uc81c \uc5c6\uc774 \ub2e8\uc77c gpu\ub85c \ubd88\ub7ec\uc624\ub294 code\uc785\ub2c8\ub2e4.\n        # https:\/\/discuss.pytorch.org\/t\/solved-keyerror-unexpected-key-module-encoder-embedding-weight-in-state-dict\/1686\n        state_dict = torch.load(weights_path \/ weight)\n        new_state_dict = OrderedDict()\n        for k, v in state_dict.items():\n            name = k[7:] # remove module.\n            new_state_dict[name] = v\n        model.load_state_dict(new_state_dict)\n        \n        # multi gpu\ub97c \uc0ac\uc6a9\ud558\ub294 code\uc785\ub2c8\ub2e4. kaggle\uc740 \ub2e8\uc77c gpu\uc5ec\uc11c \uc758\ubbf8\uac00 \uc5c6\ub294 \ucf54\ub4dc\uc785\ub2c8\ub2e4.\n        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        if torch.cuda.device_count() > 1:\n            model = nn.DataParallel(model)\n        model.to(device)\n        \n        model.eval()\n        \n        prediction = np.zeros((len(test_dataset), num_classes)) # num_classes=196\n        with torch.no_grad():\n            for i, images in enumerate(tqdm_notebook(test_loader)):\n                images = images.cuda()\n\n                preds = model(images).detach()\n                prediction[i * batch_size: (i+1) * batch_size] = preds.cpu().numpy()\n                all_prediction1 = all_prediction1 + prediction\n    \nall_prediction1 \/= total_num_models","b28c6dce":"weights_path = Path('..\/input\/carrb6') # careff6\uc5d0 \ub4e4\uc5b4\uc788\ub294 weight\uc778\ub370 \uc624\ud0c0\ub09c \ud30c\uc77c\uba85\uc744 \ubc14\uafb8\ub294\uac78 \uae5c\ubc15\ud588\ub124\uc694\nweight_list = os.listdir(weights_path)","7f6ecdff":"batch_size = 256\n\ntest_dataset = TestDataset(x_test, mode='test', transforms=data_transforms)\ntest_loader = DataLoader(test_dataset, \n                        batch_size=batch_size,\n                        num_workers=24,\n                        shuffle=False,\n                        pin_memory=True,\n                        )\n\n\ntotal_num_models = len(weight_list)*tta \n\nall_prediction2 = np.zeros((len(test_dataset), num_classes))\n\nfor i, weight in enumerate(weight_list):\n    print(\"fold {} prediction starts\".format(i+1))\n    \n    for _ in range(tta):\n        print(\"tta {}\".format(_+1))\n        \n        model = EfficientNet.from_pretrained('efficientnet-b6')\n        # Unfreeze model weights\n        for param in model.parameters():\n            param.requires_grad = True\n        model._fc = nn.Sequential(\n                    nn.Dropout(p=0.4),\n                    nn.Linear(in_features=2304, out_features=196, bias=True)\n                )\n        state_dict = torch.load(weights_path \/ weight)\n        new_state_dict = OrderedDict()\n        for k, v in state_dict.items():\n            name = k[7:] # remove module.\n            new_state_dict[name] = v\n        \n        model.load_state_dict(new_state_dict)\n        \n        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        if torch.cuda.device_count() > 1: \n            model = nn.DataParallel(model)\n        model.to(device)\n        \n        model.eval()\n        \n        prediction = np.zeros((len(test_dataset), num_classes)) # num_classes=196\n        with torch.no_grad():\n            for i, images in enumerate(tqdm_notebook(test_loader)):\n                images = images.cuda()\n\n                preds = model(images).detach()\n                prediction[i * batch_size: (i+1) * batch_size] = preds.cpu().numpy()\n                all_prediction2 = all_prediction2 + prediction\n    \nall_prediction2 \/= total_num_models","1478fa29":"weights_path = Path('..\/input\/careff5')\nweight_list = os.listdir(weights_path)","ab0ae7c4":"batch_size = 256\n\ntest_dataset = TestDataset(x_test, mode='test', transforms=data_transforms)\ntest_loader = DataLoader(test_dataset, \n                        batch_size=batch_size,\n                        num_workers=24,\n                        shuffle=False,\n                        pin_memory=True,\n                        )\n\n\ntotal_num_models = len(weight_list)*tta \n\nall_prediction3 = np.zeros((len(test_dataset), num_classes))\n\nfor i, weight in enumerate(weight_list):\n    print(\"fold {} prediction starts\".format(i+1))\n    \n    for _ in range(tta):\n        print(\"tta {}\".format(_+1))\n        \n        model = EfficientNet.from_pretrained('efficientnet-b5')\n        # Unfreeze model weights\n        for param in model.parameters():\n            param.requires_grad = True\n        model._fc = nn.Sequential(\n                    nn.Dropout(p=0.4),\n                    nn.Linear(in_features=2048, out_features=196, bias=True)\n                )\n        state_dict = torch.load(weights_path \/ weight)\n        new_state_dict = OrderedDict()\n        for k, v in state_dict.items():\n            name = k[7:] # remove module.\n            new_state_dict[name] = v\n        \n        model.load_state_dict(new_state_dict)\n        \n        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        if torch.cuda.device_count() > 1: \n            model = nn.DataParallel(model)\n        model.to(device)\n        \n        model.eval()\n        \n        prediction = np.zeros((len(test_dataset), num_classes)) # num_classes=196\n        with torch.no_grad():\n            for i, images in enumerate(tqdm_notebook(test_loader)):\n                images = images.cuda()\n\n                preds = model(images).detach()\n                prediction[i * batch_size: (i+1) * batch_size] = preds.cpu().numpy()\n                all_prediction3 = all_prediction3 + prediction\n    \nall_prediction3 \/= total_num_models","22dc858a":"torch.cuda.empty_cache()","bcd28b02":"target_size = (331, 331)\n\ndata_transforms = {\n    'test': vision.transforms.Compose([\n        vision.transforms.Resize(target_size),\n        vision.transforms.RandomRotation(5),\n        vision.transforms.RandomHorizontalFlip(),\n        vision.transforms.RandomResizedCrop(target_size, scale=(0.8,1.0)),\n        vision.transforms.ToTensor(),\n        vision.transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n}","c2f8f7f2":"weights_path = Path('..\/input\/carnas')\nweight_list = os.listdir(weights_path)","d69ea4a7":"from pretrainedmodels import nasnetalarge","069d3817":"batch_size = 128\n\ntotal_num_models = len(weight_list)*tta \nall_prediction4 = np.zeros((len(test_dataset), num_classes))\n\nfor i, weight in enumerate(weight_list):\n    print(\"fold {} prediction starts\".format(i+1))\n    \n    for _ in range(tta):\n        print(\"tta {}\".format(_+1))\n        test_dataset = TestDataset(x_test, mode='test', transforms=data_transforms)\n        test_loader = DataLoader(test_dataset, \n                                batch_size=batch_size,\n                                num_workers=24,\n                                shuffle=False,\n                                pin_memory=True,\n                                )\n\n        model = nasnetalarge(num_classes=1000, pretrained='imagenet')\n        model.last_linear = nn.Sequential(\n                    nn.Dropout(p=0.4),\n                    nn.Linear(in_features=4032, out_features=196, bias=True)\n                )\n        state_dict = torch.load(weights_path \/ weight)\n        new_state_dict = OrderedDict()\n        for k, v in state_dict.items():\n            name = k[7:] # remove module.\n            new_state_dict[name] = v\n        \n        model.load_state_dict(new_state_dict)\n        \n        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        if torch.cuda.device_count() > 1: \n            model = nn.DataParallel(model)\n        model.to(device)\n        \n        model.eval()\n        \n        prediction = np.zeros((len(test_dataset), num_classes)) # num_classes=196\n        with torch.no_grad():\n            for i, images in enumerate(tqdm_notebook(test_loader)):\n                images = images.cuda()\n\n                preds = model(images).detach()\n                prediction[i * batch_size: (i+1) * batch_size] = preds.cpu().numpy()\n                all_prediction4 = all_prediction4 + prediction\n    \nall_prediction4 \/= total_num_models","fc24c94b":"weights_path = Path('..\/input\/carpnas')\nweight_list = os.listdir(weights_path)","28e1c8b0":"from pretrainedmodels import pnasnet5large","b6004756":"batch_size = 128\n\ntotal_num_models = len(weight_list)*tta \nall_prediction5 = np.zeros((len(test_dataset), num_classes))\n\nfor i, weight in enumerate(weight_list):\n    print(\"fold {} prediction starts\".format(i+1))\n    \n    for _ in range(tta):\n        print(\"tta {}\".format(_+1))\n        \n        test_dataset = TestDataset(x_test, mode='test', transforms=data_transforms)\n        test_loader = DataLoader(test_dataset, \n                                batch_size=batch_size,\n                                num_workers=24,\n                                shuffle=False,\n                                pin_memory=True,\n                                )\n\n        \n        model = pnasnet5large(num_classes=1000, pretrained='imagenet')\n        model.last_linear = nn.Sequential(\n                    nn.Dropout(p=0.4),\n                    nn.Linear(in_features=4320, out_features=196, bias=True)\n                )\n        state_dict = torch.load(weights_path \/ weight)\n        new_state_dict = OrderedDict()\n        for k, v in state_dict.items():\n            name = k[7:] # remove module.\n            new_state_dict[name] = v\n        \n        model.load_state_dict(new_state_dict)\n        \n        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        if torch.cuda.device_count() > 1: \n            model = nn.DataParallel(model)\n        model.to(device)\n        \n        model.eval()\n        \n        prediction = np.zeros((len(test_dataset), num_classes)) # num_classes=196\n        with torch.no_grad():\n            for i, images in enumerate(tqdm_notebook(test_loader)):\n                images = images.cuda()\n\n                preds = model(images).detach()\n                prediction[i * batch_size: (i+1) * batch_size] = preds.cpu().numpy()\n                all_prediction5 = all_prediction5 + prediction\n    \nall_prediction5 \/= total_num_models","fc262f42":"# https:\/\/stackoverflow.com\/questions\/34968722\/how-to-implement-the-softmax-function-in-python\n\ndef softmax(z):\n    assert len(z.shape) == 2\n    s = np.max(z, axis=1)\n    s = s[:, np.newaxis] # necessary step to do broadcasting\n    e_x = np.exp(z - s)\n    div = np.sum(e_x, axis=1)\n    div = div[:, np.newaxis] # dito\n    return e_x \/ div","7e23e439":"all_prediction1 = softmax(all_prediction1)\nall_prediction2 = softmax(all_prediction2)\nall_prediction3 = softmax(all_prediction3)\nall_prediction4 = softmax(all_prediction4)\nall_prediction5 = softmax(all_prediction5)\n\n# soft-voting\ntotal = (all_prediction1 + all_prediction2 + all_prediction3 + all_prediction4 + all_prediction5)\n\n# argmax\ub97c \ud1b5\ud558\uc5ec \uac00\uc7a5 \ub192\uc740 \ud655\ub960\uc758 class \ucd94\ucd9c\nresult = np.argmax(total, axis=1)","d0647b01":"# predict\ud558\ub294 \uc2dc\uac04\uc774 \ub108\ubb34 \uae38\uc5b4\uc11c csv \ud30c\uc77c\ub85c \ubcf5\uc6d0\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n# load result using local gpu\nsubmission = pd.read_csv('..\/input\/final-csv-for-car\/soft_voting-5-tta_plus_PNAS.csv')\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","30048f4f":"Inference kernel\uc785\ub2c8\ub2e4. weight\ub4e4\uc744 \uc62c\ub838\uc9c0\ub9cc, \ubaa8\ub4e0 test image\uc5d0 \ub300\ud574\uc11c predict\ub97c \ud558\uae30\uc5d0\ub294 \uc2dc\uac04\uc758 \ubb38\uc81c\uac00 \uc874\uc7ac\ud558\uc600\uc2b5\ub2c8\ub2e4. test image 100\uac1c\uc5d0 \ub300\ud574\uc11c\ub9cc \uc608\uce21\ud558\ub294 code\uc785\ub2c8\ub2e4.\n\nsolution\uc740 discussion\uc5d0 \uc62c\ub824\ub450\uc5c8\uc2b5\ub2c8\ub2e4."}}