{"cell_type":{"5103d71c":"code","435a7957":"code","71ea70fa":"code","ff7fb8a4":"code","a502c131":"code","efd6e2ff":"code","b13c87f4":"code","796b8bcc":"code","50b60da8":"code","46540fb9":"code","cf7fac7b":"code","72487c36":"code","bf51b606":"code","f2bfe355":"code","1b21ad6d":"code","ce7fcc05":"code","b6fa58fd":"code","fd4a7a7f":"code","cb4594f9":"code","7e022589":"code","6a55fc0a":"code","50d937ff":"code","7f23b0db":"code","29afe067":"code","d2f01071":"code","1a61dc24":"code","be9b6bbe":"code","b9773855":"code","bf827524":"code","af00d67b":"code","480ec80e":"code","b5516e80":"code","5882f33a":"code","9d149e0b":"code","36e48ae9":"code","16339aa7":"code","7dd8edfc":"code","ccf092b4":"code","d1533a12":"code","b1133198":"code","b3f185e5":"code","f35b9dfd":"markdown","e78e836b":"markdown","863db915":"markdown","9390d0bf":"markdown","b9ce3d14":"markdown","627d5933":"markdown","ee6c74de":"markdown","c1747bfb":"markdown","6a3b4586":"markdown","3cf21cca":"markdown","356fa37c":"markdown","14b56af6":"markdown","b84d8147":"markdown","655da62e":"markdown","9f1d22d5":"markdown","5c60f629":"markdown","2fc9c3f5":"markdown","96654ee5":"markdown"},"source":{"5103d71c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nfrom tqdm import tqdm\nimport gc","435a7957":"# Code from https:\/\/www.kaggle.com\/caesarlupum\/ashrae-start-here-a-gentle-introduction \n\n# Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","71ea70fa":"InputPath = \"..\/input\/ashrae-energy-prediction\"\ntrain_df = pd.read_csv(InputPath+'\/train.csv')\nbuilding_df = pd.read_csv(InputPath+'\/building_metadata.csv')\nweather_train_df = pd.read_csv(InputPath+'\/weather_train.csv')","ff7fb8a4":"train_df.head()","a502c131":"train_df.describe()","efd6e2ff":"building_df.head()","b13c87f4":"building_df.describe()","796b8bcc":"weather_train_df.head()","50b60da8":"weather_train_df.describe()","46540fb9":"#Reduce memory usage\ntrain_df = reduce_mem_usage(df=train_df)\nweather_train_df = reduce_mem_usage(df=weather_train_df)","cf7fac7b":"\ntrain = pd.merge(train_df,building_df,how = 'left')     \ntrain = pd.merge(train,weather_train_df, on = ['site_id','timestamp'], how = 'left')\nprint(train.shape)\n\ndel train_df\ndel weather_train_df","72487c36":"gc.collect()","bf51b606":"train['timestamp'] = pd.to_datetime(train.timestamp)","f2bfe355":"# Extracting date features from timestamp\ntrain['year'] = train['timestamp'].dt.year\ntrain['month'] = train['timestamp'].dt.month\ntrain['day'] = train['timestamp'].dt.day\ntrain['hour'] = train['timestamp'].dt.hour\ntrain['dayofweek'] = train['timestamp'].dt.dayofweek","1b21ad6d":"#Reduce memory usage\ntrain = reduce_mem_usage(df=train)","ce7fcc05":"train = train.drop('timestamp',axis=1)","b6fa58fd":"gc.collect()","fd4a7a7f":"le = LabelEncoder()\ntrain[\"primary_use\"] = le.fit_transform(train[\"primary_use\"])","cb4594f9":"# Convert to categorical datatype\ncat_cols = ['meter', 'primary_use', 'site_id', 'building_id', 'year', 'month', 'day', 'hour', 'dayofweek']\nfor col in cat_cols:\n    train[col] = train[col].astype('category')","7e022589":"target = np.log1p(train[\"meter_reading\"])\nfeatures = train.drop('meter_reading', axis = 1)","6a55fc0a":"del train","50d937ff":"gc.collect()","7f23b0db":"features = reduce_mem_usage(df=features)","29afe067":"no_splits = 3\nkf = KFold(no_splits)\nLGBM = []\nparams = {\n        \"objective\": \"regression\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 1280,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"rmse\",\n\n}\nfor train,test1 in kf.split(features):\n    train_features = features.loc[train]\n    train_target = target.loc[train]\n    \n    test_features = features.loc[test1]\n    test_target = target.loc[test1]\n    \n    training = lgb.Dataset(train_features, label=train_target,categorical_feature=cat_cols, free_raw_data=False)\n    testing = lgb.Dataset(test_features, label=test_target,categorical_feature=cat_cols, free_raw_data=False)\n    \n    del train_features, train_target, test_features, test_target\n    gc.collect()\n    \n    model = lgb.train(params, train_set=training, num_boost_round=1000, valid_sets=[training,testing], verbose_eval=25, early_stopping_rounds=50)\n    LGBM.append(model)\n    \n    del training, testing\n    gc.collect()\n\n","d2f01071":"#delete intermediate dataframes\ndel target\ndel features\ndel train\ndel test1\ngc.collect()","1a61dc24":"test_df = pd.read_csv(InputPath+'\/test.csv')\nbuilding_df = pd.read_csv(InputPath+'\/building_metadata.csv')\nweather_test_df = pd.read_csv(InputPath+'\/weather_test.csv')","be9b6bbe":"#drop row_id in test_df\n\ntest_df = test_df.drop(columns=['row_id'])\nimport gc\ngc.collect()","b9773855":"# Reduce memory usage\ntest_df = reduce_mem_usage(df=test_df)\nweather_test_df = reduce_mem_usage(df=weather_test_df)","bf827524":"test = pd.merge(test_df,building_df,how = 'left')           \ntest = pd.merge(test,weather_test_df, on = ['site_id','timestamp'], how = 'left')\nprint(test.shape)","af00d67b":"del test_df\ndel weather_test_df\ndel building_df","480ec80e":"gc.collect()","b5516e80":"test['timestamp'] = pd.to_datetime(test.timestamp)","5882f33a":"test['year'] = test['timestamp'].dt.year\ntest['month'] = test['timestamp'].dt.month\ntest['day'] = test['timestamp'].dt.day\ntest['hour'] = test['timestamp'].dt.hour\ntest['dayofweek'] = test['timestamp'].dt.dayofweek","9d149e0b":"#Reduce memory usage\ntest = reduce_mem_usage(df=test)","36e48ae9":"#Drop timestamp from test\ntest = test.drop('timestamp',axis=1)","16339aa7":"gc.collect()","7dd8edfc":"le = LabelEncoder()\ntest[\"primary_use\"] = le.fit_transform(test[\"primary_use\"])","ccf092b4":"# Convert to categorical datatype\ncat_cols = ['meter', 'primary_use', 'site_id', 'building_id', 'year', 'month', 'day', 'hour', 'dayofweek']\nfor col in cat_cols:\n    test[col] = test[col].astype('category')","d1533a12":"i=0\nresult=[]\nstep_size = 50000\nfor j in tqdm(range(int(np.ceil(test.shape[0]\/50000)))):\n    result.append(np.expm1(sum([model.predict(test.iloc[i:i+step_size]) for model in LGBM])\/no_splits))\n    i+=step_size\n    gc.collect()","b1133198":"result = np.concatenate(result)","b3f185e5":"submission = pd.read_csv(InputPath+'\/sample_submission.csv')\nsubmission['meter_reading'] = result\nsubmission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\nsubmission.to_csv('submission.csv', index=False)","f35b9dfd":"**Now we can drop timestamp**","e78e836b":"# Merge Datasets","863db915":"# Import Libraries","9390d0bf":"# **EDA**","b9ce3d14":"**timestamp update on test data**","627d5933":"# **KFOLD LIGHTGBM **","ee6c74de":"# Prediction on test data","c1747bfb":"# Read test data","6a3b4586":"# Read Input\nRead only training data to avoid RAM overhead","3cf21cca":"**Extract information from timestamp**","356fa37c":"**Change timestamp to type timestamp**","14b56af6":"**We dont need these dataframes anymore**","b84d8147":"**Merge datasets**","655da62e":"**Split train to target and features**","9f1d22d5":"**Now we can delete train dataframe**","5c60f629":"**Submit to csv**","2fc9c3f5":"**Encode primary_use using LabelEncoder **","96654ee5":"**Label Encoder and categorical variables in test dataframe**"}}