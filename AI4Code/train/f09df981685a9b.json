{"cell_type":{"fa32f742":"code","517867a9":"code","f1e45d11":"code","0387f0e3":"code","294830c8":"code","bc334e28":"code","10aa4fc6":"code","4455e724":"code","2c01c496":"code","b728b28d":"code","f9494f67":"markdown","199b0e0b":"markdown","37c5aa08":"markdown","3c95a563":"markdown"},"source":{"fa32f742":"import copy\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","517867a9":"def get_categories(df):\n    return df['category'].unique()","f1e45d11":"df = pd.read_csv('..\/input\/bbc-articles-cleaned\/tfidf_dataset.csv')\ndf.head()","0387f0e3":"X_data = df[['text']].to_numpy().reshape(-1)\nY_data = df[['category']].to_numpy().reshape(-1)","294830c8":"n_texts = len(X_data)\nprint('Texts in dataset: %d' % n_texts)\n\nn_categories = len(get_categories(df))\nprint('Number of categories: %d' % n_categories)\n\nprint('Loading train dataset...')\nX_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.3)\n\nprint('Done!')","bc334e28":"clf = Pipeline([('vect', CountVectorizer(strip_accents=None, lowercase=False)),\n                ('svm', SGDClassifier(alpha=0.001,\n                                      loss='log',\n                                      penalty='l2',\n                                      random_state=42,\n                                      tol=0.001))])\nclf.fit(X_train, Y_train)","10aa4fc6":"def plot_confusion_matrix(X_test, Y_test, model):\n    Y_pred = model.predict(X_test)\n\n    con_mat = confusion_matrix(Y_test, Y_pred)\n    con_mat_norm = np.around(con_mat.astype('float') \/ con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n\n    label_names = list(range(len(con_mat_norm)))\n    con_mat_df = pd.DataFrame(con_mat_norm,\n                              index=label_names, \n                              columns=label_names)\n\n    figure = plt.figure(figsize=(10, 10))\n    sns.heatmap(con_mat_df, cmap=plt.cm.Blues, annot=True)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","4455e724":"Y_pred = clf.predict(X_test)","2c01c496":"print('Accuracy: %.4f' % accuracy_score(Y_pred, Y_test))\n\nprint('Classification report:')\nprint(classification_report(Y_test, Y_pred))","b728b28d":"plot_confusion_matrix(X_test, Y_test, clf)","f9494f67":"## Create SVM model\n\nYou can see in my Github repository how to use `GridSearch` and cross-validation to find the best parameters: https:\/\/github.com\/DimasDMM\/text-classification. In this notebook version, I wrote the best parameter values that I found.","199b0e0b":"## Prepare dataset\n\nIn comparison to other models implemented in Tensorflow, you will notice that it is very simple to configure a SVM model as many functions are already implemented.","37c5aa08":"# Simple text classification with SVM\n\nIn this approach, I chose a **Support Vector Machine** (aka. SVM) model, which is already implemented in the library Scikit-Learn. Please, note that the data that I used in this notebook is already cleaned\/processed to be used as input of the model.","3c95a563":"## Evaluation\n\nIt took very few time to train the model and the results are pretty good. This approach got a global accuracy of $96.26\\%$ and, in comparison to the LSTM model, SVM is much faster to train and make predictions."}}