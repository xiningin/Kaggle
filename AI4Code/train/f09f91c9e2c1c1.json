{"cell_type":{"bf1be667":"code","10a193f5":"code","0b6fc50f":"code","4b5127da":"code","9144cc36":"code","51159103":"code","0d5c4970":"code","324a2e5b":"code","11165b6c":"code","2960f000":"code","8702a4c4":"code","210debd7":"code","26384979":"code","8c4ad6ca":"code","70fcc23b":"code","949f9694":"code","16f6c51f":"code","ae5b6530":"code","8b6b84cc":"markdown","669f81a8":"markdown","2c748e78":"markdown","efac8cd2":"markdown","367afa84":"markdown","f2762cd1":"markdown","b918a6d9":"markdown","9b1b6e10":"markdown"},"source":{"bf1be667":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","10a193f5":"df = pd.read_csv('..\/input\/wine-reviews\/winemag-data-130k-v2.csv')","0b6fc50f":"df.head()","4b5127da":"df.isna().any()","9144cc36":"df.dropna(subset = [\"country\",\"designation\",\"price\",\"province\",\"region_1\",\"region_2\",\"taster_name\",\"taster_twitter_handle\",\"variety\"])","51159103":"df.dropna(inplace = True)","0d5c4970":"df.isna().any()","324a2e5b":"df.info()","11165b6c":"df['price'] = df['price'].astype(np.int64)","2960f000":"df.info()","8702a4c4":"df.describe()","210debd7":"q1, q3 = np.percentile(df.price,[25,75])","26384979":"iqr = q3 - q1","8c4ad6ca":"lower_bound = q1 -(1.5 * iqr) \nupper_bound = q3 +(1.5 * iqr) ","70fcc23b":"print(lower_bound)\nprint(upper_bound)","949f9694":"data_clean = df.price[~((df.price < lower_bound) | (df.price > upper_bound))]","16f6c51f":"data_clean.shape","ae5b6530":"df.duplicated()","8b6b84cc":"The datatype of the price column is in float64 type which need to be converted into the int64 for data to be consistent. ","669f81a8":"As we can see there are null or NaN values in the columns of the table. Let us check the NaN values one by one.","2c748e78":"Now, that we have consistent datatypes for all the columns we will check for the statics and the maximum and the minimum values to check if there are any outliers in the dataset. ","efac8cd2":"As we can see there are not any duplicates in the dataset. Now we can use the dataset for the exploration and visualization.","367afa84":"As we can see there are NaN values in the columns country, designation, price, province, region_1,region_2, taster_name, taster_tweeter_handle, Variety. We need to drop the NaN values from these caolumns. ","f2762cd1":"Now, that we have cleanned the outliers. We will look for any duplicates present so that we can finally remove them and make use of it for exploration.","b918a6d9":"Now, that we have got the lower bound and upper bound values. Values exceeding the upper bound are the outliers. ","9b1b6e10":"So that now we have dropped all the null values from the table. We will check for the datatypes of the columns in the dataset. "}}