{"cell_type":{"3e761c0a":"code","3e917ee3":"code","820a0bab":"code","aff1fb4a":"code","12dcc3b2":"code","626debfb":"code","f2bea3f4":"code","1bd461b9":"code","6973b5a8":"code","bab8825d":"code","d667b7cc":"code","92956c57":"code","c008b07c":"code","fc147707":"code","27aecd18":"code","5e12cbd2":"code","6c73df54":"code","44d5bc41":"code","5844c90e":"code","1a6e980f":"code","4c91133d":"code","7511689a":"code","d13186c1":"code","715f8d4f":"code","f8c0a87c":"code","61f765b5":"code","aa083ab6":"code","e7717ea3":"code","5bf2c715":"code","024fdf6d":"code","8e08d93e":"code","159f76f5":"code","971d708e":"code","2e89b7bc":"code","40cdf404":"code","593159a8":"code","e9aad785":"code","7f7f7616":"code","9b93ac92":"code","c143bd32":"code","9ec9144f":"code","5eca5edc":"markdown","6eb9dd05":"markdown","046cc72f":"markdown","a297512b":"markdown","37f30c79":"markdown","9c60747a":"markdown","1f050740":"markdown","5f3d74f6":"markdown","c9b8b585":"markdown","45240ac1":"markdown","1dd47857":"markdown","4b9a0433":"markdown","ec2240f7":"markdown","38437665":"markdown","b5f39a73":"markdown","6d799772":"markdown","e624be90":"markdown","b60df1db":"markdown","47266017":"markdown","fcf9e992":"markdown","4cf216de":"markdown","bee9647a":"markdown","fb9d4c6b":"markdown"},"source":{"3e761c0a":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nfrom timm import create_model","3e917ee3":"from fastai.vision.all import *","820a0bab":"set_seed(999, reproducible=True)\nBATCH_SIZE = 32","aff1fb4a":"dataset_path = Path('..\/input\/petfinder-pawpularity-score\/')\ndataset_path.ls()","12dcc3b2":"train_df = pd.read_csv(dataset_path\/'train.csv')\ntrain_df.head()","626debfb":"train_df['path'] = train_df['Id'].map(lambda x:str(dataset_path\/'train'\/x)+'.jpg')\ntrain_df = train_df.drop(columns=['Id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head()","f2bea3f4":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")","1bd461b9":"train_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")","6973b5a8":"print(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")","bab8825d":"train_df['norm_score'] = train_df['Pawpularity']\/100\ntrain_df['norm_score']","d667b7cc":"im = Image.open(train_df['path'][1])\nwidth, height = im.size\nprint(width,height)","92956c57":"im","c008b07c":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'\n","fc147707":"seed=999\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True","27aecd18":"#Sturges' rule\nnum_bins = int(np.floor(1+np.log2(len(train_df))))\nnum_bins","5e12cbd2":"train_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()","6c73df54":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\n\nN_FOLDS = 10\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","44d5bc41":"train_df[train_df['fold']==0].head()","5844c90e":"train_df[train_df['fold']==0]['bins'].value_counts()","1a6e980f":"train_df[train_df['fold']==1]['bins'].value_counts()","4c91133d":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))","7511689a":"def get_data(fold):\n#     train_df_no_val = train_df.query(f'fold != {fold}')\n#     train_df_val = train_df.query(f'fold == {fold}')\n    \n#     train_df_bal = pd.concat([train_df_no_val,train_df_val.sample(frac=1).reset_index(drop=True)])\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    dls = ImageDataLoaders.from_df(train_df_f, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n                               valid_col='is_valid', #\n                               seed=999, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) #pass in batch_tfms\n    \n    return dls\n","d13186c1":"#Valid Kfolder size\nthe_data = get_data(0)\nassert (len(the_data.train) + len(the_data.valid)) == (len(train_df)\/\/BATCH_SIZE)","715f8d4f":"def get_learner(fold_num):\n    data = get_data(fold_num)\n    \n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), metrics=petfinder_rmse).to_fp16()\n    \n    return learn","f8c0a87c":"test_df = pd.read_csv(dataset_path\/'test.csv')\ntest_df.head()","61f765b5":"test_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path\/'test'\/x)+'.jpg')\ntest_df = test_df.drop(columns=['Id'])\ntrain_df['norm_score'] = train_df['Pawpularity']\/100","aa083ab6":"get_learner(fold_num=0).lr_find(end_lr=3e-2)","e7717ea3":"import gc","5bf2c715":"all_preds = []\n\nfor i in range(N_FOLDS):\n\n    print(f'Fold {i} results')\n    \n    learn = get_learner(fold_num=i)\n\n    learn.fit_one_cycle(5, 2e-5, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)]) \n    \n    learn.recorder.plot_loss()\n\n    #learn = learn.to_fp32()\n    \n    #learn.export(f'model_fold_{i}.pkl')\n    #learn.save(f'model_fold_{i}.pkl')\n    \n    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               fn_col='path', #filename\/path is in the second column of the DataFrame\n                               label_col='norm_score', #label is in the first column of the DataFrame\n                               y_block=RegressionBlock, #The type of target\n                               bs=BATCH_SIZE, #pass in batch size\n                               num_workers=8,\n                               item_tfms=Resize(224), #pass in item_tfms\n                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n    \n    test_dl = dls.test_dl(test_df)\n    \n    preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n    \n    all_preds.append(preds)\n    \n    del learn\n\n    torch.cuda.empty_cache()\n\n    gc.collect()","024fdf6d":"all_preds","8e08d93e":"np.mean(np.stack(all_preds*100))","159f76f5":"sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\npreds = np.mean(np.stack(all_preds), axis=0)\nsample_df['Pawpularity'] = preds*100\nsample_df.to_csv('submission.csv',index=False)","971d708e":"pd.read_csv('submission.csv').head()","2e89b7bc":"#path = '.\/models'\n#learn1 = load_learner('model_fold_2.pkl')","40cdf404":"# test_df = pd.read_csv(dataset_path\/'test.csv')\n# test_df.head()","593159a8":"# test_df['Pawpularity'] = [1]*len(test_df)\n# test_df['path'] = test_df['Id'].map(lambda x:str(dataset_path\/'test'\/x)+'.jpg')\n# test_df = test_df.drop(columns=['Id'])\n# train_df['norm_score'] = train_df['Pawpularity']\/100","e9aad785":"# dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n#                                valid_pct=0.2, #80-20 train-validation random split\n#                                seed=999, #seed\n#                                fn_col='path', #filename\/path is in the second column of the DataFrame\n#                                label_col='norm_score', #label is in the first column of the DataFrame\n#                                y_block=RegressionBlock, #The type of target\n#                                bs=32, #pass in batch size\n#                                num_workers=8,\n#                                item_tfms=Resize(224), #pass in item_tfms\n#                                batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n# test_dl = dls.test_dl(test_df)","7f7f7616":"# test_dl.show_batch()","9b93ac92":"#preds, _ = learn1.tta(dl=test_dl, n=5, beta=0)","c143bd32":"# sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\n# sample_df['Pawpularity'] = preds.float().numpy()*100\n# sample_df.to_csv('submission.csv',index=False)","9ec9144f":"#pd.read_csv('submission.csv').head()","5eca5edc":"lr\u306f\u4e0a\u8a18\u306e\u30b3\u30fc\u30c9\u304b\u3089\u63d0\u6848\u3055\u308c\u305f\u5024\u306b\u5909\u66f4\u3059\u308b\n\nLet's now fine-tune the model with the desired learning rate of 2e-5. We'll save the best model and use the early stopping callback.","6eb9dd05":"## Data loading\nAfter my quick 'n dirty EDA, let's load the data into fastai as DataLoaders objects. We're using the normalized score as the label. I use some fairly basic augmentations here.","046cc72f":"In fastai, the trainer class is the `Learner`, which takes in the data, model, optimizer, loss function, etc. and allows you to train models, make predictions, etc. Let's define the `Learner` for this task, and also use mixed precision. Note that we use `BCEWithLogitsLoss` to treat this as a classification problem.","a297512b":"Let's check what data is available to us:","37f30c79":"We plotted the loss, put the model back to fp32, and now we can export the model if we want to use later (i.e. for an inference kernel):","9c60747a":"Let's check an example image to see what it looks like:","1f050740":"We are now provided with a Learner object. In order to train a model, we need to find the most optimal learning rate, which can be done with fastai's learning rate finder:","5f3d74f6":"We can easily confirm that the test_dl is correct (the example test images provided are just noise so this is expected):","c9b8b585":"## A look at the data\nLet's start out by setting up our environment by importing the required modules and setting a random seed:","45240ac1":"We can see that we have our train csv file with the train image names, metadata and labels, the test csv file with test image names and metadata, the sample submission csv with the test image names, and the train and test image folders.\n\nLet's check the train csv file:","1dd47857":"Note that the Pawpularity score is an integer, so in addition to being a regression problem, it could also be treated as a 100-class classification problem. Alternatively, it can be treated as a binary classification problem if the Pawpularity Score is normalized between 0 and 1:","4b9a0433":"Let's do some quick processing of the image filenames to make it easier to access:","ec2240f7":"Now, **WE ARE DONE!**\n\nIf you enjoyed this notebook, please give it an upvote. \n\nStay tuned for improvements to this notebook, potentially including a version that uses the metadata as well.\n\nIf you have any questions or suggestions, please leave a comment!","38437665":"Now let's pass the dataloader to the model and get predictions. Here I am using 5x test-time augmentation which further improves model performance.","b5f39a73":"Let's check the distribution of the Pawpularity Score:","6d799772":"The metadata provided includes information about key visual quality and composition parameters of the photos. The Pawpularity Score is derived from the profile's page view statistics. This is the target we are aiming to predict.","e624be90":"Let's make a submission with these predictions!","b60df1db":"Okay, let's check how many images are available in the training dataset:","47266017":"**It's based on tanlikesmath's starter notebook at https:\/\/www.kaggle.com\/tanlikesmath\/petfinder-pawpularity-eda-fastai-starter. My teammate Stefano did the most work.**\n\n# Petfinder.my - Pawpularity Contest: Simple EDA and fastai starter\n\nIn this competition, we will use machine learning to predict the \"pawpularity\" of a pet using images and metadata. If successful, solutions will be adapted into AI tools that will guide shelters and rescuers around the world to improve the appeal of their pet profiles, automatically enhancing photo quality and recommending composition improvements. As a result, stray dogs and cats can find families much faster, and these tools will help improve animal welfare.\n\nIn this notebook, I will present a quick 'n dirty EDA and a (image-only, for now) fastai starter. \n\n**As of 10\/26, it's currently the best-scoring notebook for the competition, beating 10-fold ensemble models that are bigger while only using a single and smaller model.**\n\nV1: Change get_data(fold) to correct K-Fold, use is_valid for validation data","fcf9e992":"Let's also define the metric we will use. Note that we multiply by 100 to get a relevant RMSE for Pawpularity Score prediction, not prediction of the normalized score.","4cf216de":"Let's now define the model.","bee9647a":"# Model training\n\nLet's train a Swin Transformer model as a baseline. We will use the wonderful timm package by Ross Wightman to define the model. Since this competition doesn't allow internet access, I have added the pretrained weights from timm as a dataset, and the below code cell will allow timm to find the file:","fb9d4c6b":"## Inference\n\nIt's very simple to perform inference with fastai. We preprocess the test CSV in the same way as the train CSV, and the `dls.test_dl` function allows you to create test dataloader using the same pipeline we defined earlier."}}