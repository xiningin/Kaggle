{"cell_type":{"cd6cab16":"code","6cfaf051":"code","05b03e3b":"code","7c4fc1eb":"code","6b5f13e5":"code","6e22a343":"code","a409e69c":"code","ed9da4b9":"code","3901addb":"markdown","87603091":"markdown","979ed9bf":"markdown"},"source":{"cd6cab16":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport cv2\nimport glob\nfrom PIL import Image","6cfaf051":"# installing icrawler\n!pip install icrawler","05b03e3b":"from icrawler.builtin import  (BingImageCrawler,GoogleImageCrawler)\nimport logging","7c4fc1eb":"# downloading images of the car\n# pass no. of maximum images in max_num arguement\ndirectory_bing_car = '.\/data\/car'\nsearch_filters_bing = dict()\nbing_crawler = BingImageCrawler(downloader_threads=4,storage={'root_dir': directory_bing_car},log_level=logging.INFO)\nbing_crawler.crawl(keyword='car', filters=search_filters_bing, max_num=100)\n\n# downloading images of the car\n# pass no. of maximum images in max_num arguement\ndirectory_bing_bike = '.\/data\/bike'\nsearch_filters_bing = dict()\nbing_crawler = BingImageCrawler(downloader_threads=4,storage={'root_dir': directory_bing_bike},log_level=logging.INFO)\nbing_crawler.crawl(keyword='bike', filters=search_filters_bing, max_num=100)","6b5f13e5":"# you can see the images has been downloaded.\n!ls '.\/data\/car'\n!ls '.\/data\/bike'\n","6e22a343":"# funtion for checking corrupted images.\ndef check_corrupted_images(image_folder_path):\n    counter = 0\n    for image in os.listdir(image_folder_path):\n        try:\n            img = cv2.imread(image)\n        except:\n            counter+=1\n    return counter\n            ","a409e69c":"print(\"Total number of corrupted images are: {}\".format(check_corrupted_images(directory_bing_car)))\nprint(\"Total number of corrupted images are: {}\".format(check_corrupted_images(directory_bing_bike)))\n#If there are corrupted images use the below function to delete those images","ed9da4b9":"#use this function to remove the corrupted files\ndef del_corrupted_images(image_folder_path):\n    counter = 0\n    for image in os.listdir(image_folder_path):\n        try:\n            img = cv2.imread(image)\n        except:\n            os.remove(image)\n            print(\"File Removed!\")\n            counter+=1\n    return counter","3901addb":"You may wish to make a image classifier for car and bike.\nSo, let's use icrawler and download 100 images for both the classes.\\\nNote: you can download maximum 1000 images because of search engine api restriction.","87603091":"<span style=\"color:red\"> If you like the kernel then please upvote <\/span>","979ed9bf":"There are plenty of datasets present over the internet.\nBut there might be a situation where you may not find dataset of \nyour desired classes. So you may wish to make your own dataset. \\\n<span style=\"color:red\">*Presenting \"custom image dataset using icrawler\" to cop with the above problem.*<\/span> \\\nYou can use this kernel as a script to download images of your\ndesired classes from the famous search engines.\n\nI crawler is a mini framework of web crawlers.\nIt also provides built-in crawlers for popular image sites like Flickr and search engines such as Google, Bing and Baidu. \\\nFor all the use cases refer the documentation https:\/\/icrawler.readthedocs.io\/en\/latest\/index.html"}}