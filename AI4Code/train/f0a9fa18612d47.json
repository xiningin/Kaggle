{"cell_type":{"e4eaead0":"code","41c72d1a":"code","ee053d46":"code","af0bbcbf":"code","91a4fe6d":"code","18524cd5":"code","17d79495":"code","793ccda9":"code","49c282e7":"code","d54a9eb3":"code","1c3aa4b0":"code","5e76f5ad":"code","bfa89175":"code","7cc0a94a":"code","990a4502":"code","8bd59c15":"markdown"},"source":{"e4eaead0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","41c72d1a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt       # matplotlib.pyplot plots data\n%matplotlib inline \nimport seaborn as sns","ee053d46":"df = pd.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndf.rename(columns={'DiabetesPedigreeFunction': 'DiabPed', 'BloodPressure': 'BP','SkinThickness': 'SkinThick',\n          'Pregnancies': 'Preg'}, inplace=True)\ndf.head(10)","af0bbcbf":"X = df.drop('Outcome',axis=1)   # split prediction features\nY = df['Outcome'] ","91a4fe6d":"Y.value_counts() ","18524cd5":"sns.heatmap(df.isnull(), yticklabels = False, cmap=\"YlGnBu\") ","17d79495":"X.describe()","793ccda9":"X = X.replace(0, np.NaN)","49c282e7":"X.describe()","d54a9eb3":"X.hist(stacked=False, bins=40, figsize=(12,40), layout=(14,2), color='blue'); ","1c3aa4b0":"from sklearn.impute import SimpleImputer\nreplace_0 = SimpleImputer(missing_values=np.NaN, strategy=\"mean\")\ncols=X.columns\nX = pd.DataFrame(replace_0.fit_transform(X))\nX.columns = cols\nl=X.head(10)","5e76f5ad":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\nx_train.shape","bfa89175":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\n\n# Fit the model on train\nmodel = LogisticRegression(solver=\"liblinear\")\nmodel.fit(x_train, y_train)\n#predict on test\ny_predict = model.predict(x_test)\n\ncoef_df = pd.DataFrame(model.coef_)\ncoef_df['intercept'] = model.intercept_\nprint(coef_df)","7cc0a94a":"model_score = model.score(x_test, y_test)\nprint(model_score)","990a4502":"cm=metrics.confusion_matrix(y_test, y_predict, labels=[1, 0])\n\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm, annot=True)","8bd59c15":"Split"}}