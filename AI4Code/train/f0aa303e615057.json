{"cell_type":{"bf1a82a0":"code","60786cdc":"code","62705d80":"code","29151484":"code","2a62a48e":"code","d9ca9f30":"code","4363c803":"code","c2d332f1":"code","f027d228":"code","9a0b6420":"code","bbc8d890":"code","85ef90e8":"code","83e4c32d":"code","e38fc151":"code","4502a263":"code","2b3a34f5":"code","0078c1d1":"markdown","f1ced3fe":"markdown","55bc9ddd":"markdown","4db30521":"markdown","fa636f72":"markdown","a4ab423a":"markdown","c98f2d5d":"markdown","5f217a7b":"markdown","36588f91":"markdown","2b7fbead":"markdown","6379608b":"markdown","ccd2095b":"markdown","7c2e7c3d":"markdown","1ea8cd66":"markdown"},"source":{"bf1a82a0":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.classify import ClassifierI\nfrom nltk.classify.scikitlearn import SklearnClassifier\nfrom statistics import mode\nfrom sklearn.naive_bayes import BernoulliNB,MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import NuSVC\nimport random\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport re\nimport string\nfrom string import punctuation,ascii_letters\nfrom nltk.corpus import stopwords\nimport plotly\nimport plotly.graph_objs as go\nfrom plotly.offline import plot","60786cdc":"traintwitts = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntesttwitts = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\ntraintwitts.isna().sum()","62705d80":"twts = traintwitts.drop(columns=['id' ,'keyword',\t'location'])\ntwts.head()","29151484":"text = []\nfor t in twts['text']:\n    if t.isalpha:\n        text.append(t)\ndoncuments = []\nfor r,t in zip(twts['text'],twts['target']):\n    doncuments.append((r,t))\nprint('length of Document:',len(doncuments))","2a62a48e":"stop_words = set(stopwords.words('english'))\nall_words = []\nfor i in text:\n    for s in word_tokenize(i):\n        url = re.findall(r'\/\/\\S+|www\\.\\S+|',s)\n        if s not in stop_words and s not in punctuation and s not in url:\n            all_words.append(s.lower())","d9ca9f30":"all_words = nltk.FreqDist(all_words)\nwords_keys = list(all_words.keys())","4363c803":"dic = {}\nfor k,v in all_words.items():\n    dic[k] = v\ndf = pd.DataFrame.from_dict(dic,orient='index')\n","c2d332f1":"colors = [plotly.colors.DEFAULT_PLOTLY_COLORS[random.randrange(1, 10)] for i in range(55)]\n\ndata = go.Scatter(x=[random.random() for i in range(55)],\n                 y=[random.random() for i in range(55)],\n                 mode='text',\n                 text=df.index,\n                 marker={'opacity': 0.3},\n                 textfont={'size': df[0:55],\n                           'color': colors})\nlayout = go.Layout({'xaxis': {'showgrid': True, 'showticklabels': False, 'zeroline': True},\n                    'yaxis': {'showgrid': True, 'showticklabels': False, 'zeroline': True}})\n\n\n\n\nfig = go.Figure(data=[data], layout=layout)\n\nfig.show()","f027d228":"def f_feature(document):\n    words = word_tokenize(document)\n    features = {}\n    for w in words_keys:\n        features[w] = (w in words)\n    return features","9a0b6420":"featuresets = [(f_feature(rev),category) for (rev,category) in doncuments]\nrandom.shuffle(featuresets)\ntrain_set = featuresets[:6500]\ntest_set = featuresets[6500:] ","bbc8d890":"onb = nltk.NaiveBayesClassifier.train(train_set)\nprint(\"Original Naive Bayes Classifier accuracy:\", (nltk.classify.accuracy(onb, test_set))*100,'%')\nonb.show_most_informative_features(15)","85ef90e8":"MNB_classifier = SklearnClassifier(MultinomialNB())\nMNB_classifier.train(train_set)\nprint(\"MNB_classifier accuracy:\", (nltk.classify.accuracy(MNB_classifier, test_set))*100,'%')\n","83e4c32d":"BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\nBernoulliNB_classifier.train(train_set)\nprint(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, test_set))*100,'%')\n","e38fc151":"LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\nLogisticRegression_classifier.train(train_set)\nprint(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, test_set))*100)\n","4502a263":"NuSVC_classifier = SklearnClassifier(NuSVC())\nNuSVC_classifier.train(train_set)\nprint(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, test_set))*100)\n","2b3a34f5":"sample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\n\npred = []\nfor i in range(len(testtwitts['text'])):\n    pred.append(MNB_classifier.classify(f_feature(testtwitts['text'][i])))\nsample_submission['target'] = pred  \nsample_submission.head()","0078c1d1":"2. Importing train and test data ","f1ced3fe":"4. Classifiers\n> a- Naive Bays","55bc9ddd":"> d-Logistic Regression","4db30521":"c- Word Frequancy","fa636f72":"**In this kernel we are going to classify Real or Not? NLP with Disaster Tweets dataset using five algorithm **\n\n1. importing libraries ","a4ab423a":"5. Predicting and Submission","c98f2d5d":"> e-Nu SVM","5f217a7b":"b- Remove punctuation urls, stopwords and lowercase all words ","36588f91":"> b- Multinomial Naive Bays","2b7fbead":"> c- Bernoulli Naive Bays","6379608b":"d- 55 worlds cloud","ccd2095b":"3. Preprocessing \n\na- Documents for texts and labels ","7c2e7c3d":"We will focus on the text column","1ea8cd66":"e- Find features and split the data into train validation set"}}