{"cell_type":{"2236576b":"code","36acde77":"code","3b8e6a1a":"code","5856a3b0":"code","382687c3":"code","15885486":"code","a5204992":"code","cea26869":"code","bc270de7":"code","a75e053f":"code","eb291830":"code","1e11e6de":"code","a48fc5f7":"code","50fc4dfb":"code","10129877":"code","46d877f2":"code","cee8066d":"code","37dd5108":"code","6c4d0e64":"code","430928e4":"code","13a9df1a":"code","14de4149":"code","69fdefa8":"code","551b0cf9":"markdown","dc1157eb":"markdown","7bfe05b4":"markdown","c1c55a60":"markdown","67af3a8e":"markdown","8ff21e9b":"markdown","2fbf55c1":"markdown","48fb3f1e":"markdown","983b64a5":"markdown","06b03dbe":"markdown","1542d77e":"markdown","28c08a2e":"markdown","c58cdb5b":"markdown","9797d2b0":"markdown","aa9590b5":"markdown","14ec510c":"markdown","89da2b6c":"markdown","3fb1a510":"markdown","5d62dbd3":"markdown","5aea21ca":"markdown","c019518d":"markdown","be1eb345":"markdown","3ec8caa3":"markdown","c8ba2688":"markdown","aee79b6c":"markdown","459f54f8":"markdown","e893ee30":"markdown","2d8ce534":"markdown","27dd243f":"markdown"},"source":{"2236576b":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\nfrom sklearn.metrics import precision_recall_fscore_support as score\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","36acde77":"df = pd.read_csv('\/kaggle\/input\/hr-analytics-and-job-prediction\/HR_comma_sep.csv')\ndf.head()","3b8e6a1a":"df.isnull().sum()","5856a3b0":"plt.figure(figsize=(9, 9)) \nplt.subplot(3, 3, 1)\ndf.boxplot(column=['promotion_last_5years'], color=dict(boxes='b', medians='r', caps='g'))\nplt.subplot(3, 3, 2, )\ndf.boxplot(column=['left'], color=dict(boxes='b', medians='r', caps='g'))\nplt.subplot(3, 3, 3, )\ndf.boxplot(column=['Work_accident'], color=dict(boxes='b', medians='r', caps='g'))\nplt.subplot(3, 3, 4, )\ndf.boxplot(column=['time_spend_company'], color=dict(boxes='b', medians='r', caps='g'))\nplt.subplot(3, 3, 5, )\ndf.boxplot(column=['average_montly_hours'], color=dict(boxes='b', medians='r', caps='g'))\nplt.subplot(3, 3, 6)\ndf.boxplot(column=['number_project'], color=dict(boxes='b', medians='r', caps='g'))\nplt.subplot(3, 3, 7, )\ndf.boxplot(column=['last_evaluation'], color=dict(boxes='b', medians='r', caps='g'))\nplt.subplot(3, 3, 8, )\ndf.boxplot(column=['satisfaction_level'], color=dict(boxes='b', medians='r', caps='g'))\nplt.show()","382687c3":"df['left'].value_counts()","15885486":"df['Work_accident'].value_counts()","a5204992":"df['promotion_last_5years'].value_counts()","cea26869":"corr = df.corr()\nplt.figure(figsize=(8, 6))\nsns.heatmap(df.corr(), annot=True, cmap=\"crest\")\nplt.show()","bc270de7":"plt.figure(figsize=(15, 6))\nplt.plot(abs(corr['left']).sort_values()[:-1].index, abs(corr['left']).sort_values()[:-1], color='green')\nplt.grid()\nplt.show()","a75e053f":"df = df.drop(columns=['last_evaluation'])  # cause of low corrolation","eb291830":"df = df.replace({'salary': {'low': 1, 'medium': 2, 'high': 3}})\ndf = pd.get_dummies(df,columns = ['Department'])","1e11e6de":"df_class = df.copy()\nx = df_class.iloc[:, :-1].values\ny = df_class.iloc[:, -1].values","a48fc5f7":"scaler = StandardScaler()\nx = scaler.fit_transform(x)\n","50fc4dfb":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)","10129877":"def compute(ytest, ypred):  # Copied\n\n    cm = confusion_matrix(ytest, ypred)\n    class_label = [\"true\", \"false\"]\n    class_label_2 = [\"positive\", \"negetive\"]\n    df_cm = pd.DataFrame(cm, index=class_label, columns=class_label_2)\n    sns.heatmap(df_cm, annot=True, cmap='coolwarm', linewidths=2, fmt='d')\n    plt.title(\"Confusion Matrix\", fontsize=15)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n\n    # Calculate Metrics\n    acc = accuracy_score(ytest, ypred)\n    mse = mean_squared_error(ytest, ypred)\n    precision, recall, fscore, train_support = score(ytest, ypred, pos_label=1, average='binary')\n    print('Precision: {} \\nRecall: {} \\nF1-Score: {} \\nAccuracy: {} %\\nMean Square Error: {}'.format(\n        round(precision, 3), round(recall, 3), round(fscore, 3), round((acc * 100), 3), round((mse), 3)))\n","46d877f2":"knn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_test)\nclassify_eval = compute(y_test, knn.predict(x_test))\nprint(classify_eval)","cee8066d":"df_clust = df.copy()\ndf_clust = df_clust.drop(columns=['left']) ","37dd5108":"scaler = StandardScaler()\ndata = scaler.fit_transform(df_clust)\ndf_clust = pd.DataFrame(data, columns=df_clust.columns)","6c4d0e64":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nsse = []\nfor i in range(1, 20):\n    model = KMeans(n_clusters=i, random_state=48)\n    model.fit(df_clust)\n    sse.append(model.inertia_ \/ 1000)\nplt.plot(range(1, 20), sse, color='r')\nplt.scatter(range(1, 20), sse, color='b')\nplt.title('Different SSE with different k with KMeans'), plt.grid(), plt.show()\n","430928e4":"model = KMeans(n_clusters=2, random_state=48)\ncluster_labels = model.fit_predict(df_clust)\nscore = silhouette_score(df_clust, cluster_labels, metric='euclidean')\nprint('Silhouette Score: %.3f' % score)","13a9df1a":"predict = model.predict(df_clust)\ndf_clust['new_left'] = pd.Series(predict, index=df_clust.index)","14de4149":"plt.subplot(1, 2, 1)\ndf_clust['new_left'].value_counts().sort_values().plot(kind = 'bar',color = '#A56CE0')\nplt.subplot(1, 2, 2)\ndf_class['left'].value_counts().sort_values().plot(kind = 'bar' ,color = '#95D91B')\nprint(df_class['left'].value_counts())\nprint(df_clust['new_left'].value_counts())\nplt.show()","69fdefa8":"x_clus = df_clust.iloc[:, :-1].values\ny_clus = df_clust.iloc[:,-1].values\n\n# ========================= Normalization =====================================\nscaler = StandardScaler()\nx_clus = scaler.fit_transform(x_clus)\n\n# # ========================= hold out data =====================================\nx_train, x_test, y_train, y_test = train_test_split(x_clus, y_clus, test_size=0.3, random_state=42)\n# ========================= KNeighborsClassifier  ================================\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_test)\n# cluster_eval = compute(y_test, knn.predict(x_test))\nprint(accuracy_score(y_test,y_pred))","551b0cf9":"It seems it's great model with 99% accuracy.","dc1157eb":"As we were supposed to classify our dataset ,let's go to predict emploee behaviour with classification models.\nwe choose knn to this project","7bfe05b4":"let's check out we have null values or not","c1c55a60":"now it's time to compare these 2 dataset.one with default lable and the other one with new target leble ('new_left')","67af3a8e":"As we see with value_counts , these datas are not outliers, but they are real data in their feature . In fact, it has a large data ratio, so the box diagram shows them as outlier data. for example in promotion_last_5years number of '0' is 46 times that of '1'.","8ff21e9b":"As we can see the elbow point is 11","2fbf55c1":"For clustring we should normalize our data","48fb3f1e":"Now let's check corrolation of our dataset","983b64a5":"# Compare new dataset with orginal dataset","06b03dbe":"It's time to do our mission. We want to cluster our dataset and again classify our datas. So at first we should drop our target feature and then guess it with Kmeans","1542d77e":"# Classify our dataset with knn","28c08a2e":"As you see in the charts,there is good similarity with new lables and old ones. with the difference that the place of zero and one has changed, which does not matter.","c58cdb5b":"In this notebook we are going to predict employees who leave their job with **neighbors classifier** and then we want to omit target feature ('left') and clustr our dataset with **kmeans**, Then predict it with classifications model again.\n\nwe do this clustring because sometimes clustring is just a step of classification.","9797d2b0":"# Observing our dataset","aa9590b5":"let's prepare our x and y data","14ec510c":"As we see in the corrolation plot chart with 'left' feature, which is our target, we can drop 'last_evaluation' beacuase of little of corrolation","89da2b6c":"As we see there is no null value !","3fb1a510":"![](https:\/\/blog.bonus.ly\/hubfs\/employee-turnover.png)","5d62dbd3":"Now we should encode two features beacuase their type is object : salary and department ","5aea21ca":"Now it's better to standard our x values with StandardScaler. Remember we shouldn't normalize y.","c019518d":"Let's add k-means predicted clusters in a column to our dataframe ","be1eb345":"# Clustring with Kmeans","3ec8caa3":"As we can see there is some starnge outliers in first three coulmn, let's check their value : ","c8ba2688":"Now is time to check out outliers values ","aee79b6c":"In this level we are making are model with Keans:","459f54f8":"And now it's the time of making our model with knn, but befor that I want to make compute function to evaluate my model :","e893ee30":"First of all let's look at our dataset","2d8ce534":"KNN model :","27dd243f":"At last we can see these results :\n* we have good clustring with high accuracy model\n* we have good classification model to predict our targat"}}