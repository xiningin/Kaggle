{"cell_type":{"c16cea8c":"code","cd9ef2f5":"code","b860f09d":"code","6509c86d":"code","a2f6e874":"code","aa83618f":"code","7456acb1":"code","2534b2d7":"code","931d71af":"code","14f7b38b":"code","97e824f0":"code","8b53cfb4":"code","fb7c62f4":"code","0bb59728":"code","199535b1":"code","7e9a575b":"code","4bc7fca2":"code","7e309aa2":"markdown","a3c34b83":"markdown","9afb8f66":"markdown","c1b26907":"markdown","56b0fc60":"markdown","29726095":"markdown","aae801db":"markdown","c6073df9":"markdown","050d160e":"markdown","e61dda71":"markdown","642b851b":"markdown","e195f6c1":"markdown","399ee4c7":"markdown","1d9b9d8d":"markdown","f6c02ead":"markdown","cbced53e":"markdown"},"source":{"c16cea8c":"import pandas as pd\nimport numpy as np\nimport re \nimport nltk \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\n\n\nfrom io import StringIO\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import chi2\nfrom IPython.display import display\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\n\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.style.use('ggplot')\nimport matplotlib.patches as mpatches","cd9ef2f5":"train=pd.read_csv(\"\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv\",encoding='latin1')\ntest=pd.read_csv(\"\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv\",encoding='latin1')","b860f09d":"train['text'] = train.OriginalTweet\ntrain[\"text\"] = train[\"text\"].astype(str)\n\ntest['text'] = test.OriginalTweet\ntest[\"text\"] = test[\"text\"].astype(str)\n\n# Data has 5 classes, let's convert them to 3\n\ndef classes_def(x):\n    if x ==  \"Extremely Positive\":\n        return \"2\"\n    elif x == \"Extremely Negative\":\n        return \"0\"\n    elif x == \"Negative\":\n        return \"0\"\n    elif x ==  \"Positive\":\n        return \"2\"\n    else:\n        return \"1\"\n    \n\ntrain['label']=train['Sentiment'].apply(lambda x:classes_def(x))\ntest['label']=test['Sentiment'].apply(lambda x:classes_def(x))\n\n\ntrain.label.value_counts(normalize= True)","6509c86d":"#Remove Urls and HTML links\ndef remove_urls(text):\n    url_remove = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url_remove.sub(r'', text)\ntrain['text_new']=train['text'].apply(lambda x:remove_urls(x))\ntest['text_new']=test['text'].apply(lambda x:remove_urls(x))\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\ntrain['text']=train['text_new'].apply(lambda x:remove_html(x))\ntest['text']=test['text_new'].apply(lambda x:remove_html(x))","a2f6e874":"# Lower casing\ndef lower(text):\n    low_text= text.lower()\n    return low_text\ntrain['text_new']=train['text'].apply(lambda x:lower(x))\ntest['text_new']=test['text'].apply(lambda x:lower(x))\n\n\n# Number removal\ndef remove_num(text):\n    remove= re.sub(r'\\d+', '', text)\n    return remove\ntrain['text']=train['text_new'].apply(lambda x:remove_num(x))\ntest['text']=test['text_new'].apply(lambda x:remove_num(x))","aa83618f":"#Remove stopwords & Punctuations\nfrom nltk.corpus import stopwords\n\", \".join(stopwords.words('english'))\nSTOPWORDS = set(stopwords.words('english'))\n\ndef punct_remove(text):\n    punct = re.sub(r\"[^\\w\\s\\d]\",\"\", text)\n    return punct\ntrain['text_new']=train['text'].apply(lambda x:punct_remove(x))\ntest['text_new']=test['text'].apply(lambda x:punct_remove(x))\n\n\ndef remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\ntrain['text']=train['text_new'].apply(lambda x:remove_stopwords(x))\ntest['text']=test['text_new'].apply(lambda x:remove_stopwords(x))","7456acb1":"#Remove mentions and hashtags\ndef remove_mention(x):\n    text=re.sub(r'@\\w+','',x)\n    return text\ntrain['text_new']=train['text'].apply(lambda x:remove_mention(x))\ntest['text_new']=test['text'].apply(lambda x:remove_mention(x))\n\ndef remove_hash(x):\n    text=re.sub(r'#\\w+','',x)\n    return text\ntrain['text']=train['text_new'].apply(lambda x:remove_hash(x))\ntest['text']=test['text_new'].apply(lambda x:remove_hash(x))\n\n#Remove extra white space left while removing stuff\ndef remove_space(text):\n    space_remove = re.sub(r\"\\s+\",\" \",text).strip()\n    return space_remove\ntrain['text_new']=train['text'].apply(lambda x:remove_space(x))\ntest['text_new']=test['text'].apply(lambda x:remove_space(x))\ntest = test.drop(columns=['text_new'])\ntrain = train.drop(columns=['text_new'])","2534b2d7":"stop_words = ['a', 'an', 'the']\n\n# Basic cleansing\ndef cleansing(text):\n    # Tokenize\n    tokens = text.split(' ')\n    # Lower case\n    tokens = [w.lower() for w in tokens]\n    # Remove stop words\n    tokens = [w for w in tokens if w not in stop_words]\n    return ' '.join(tokens)\n\n# All-in-one preproce\ndef preprocess_x(x):\n    processed_x = [cleansing(text) for text in x]\n    \n    return processed_x\n\ntrain['text_new']=train['text'].apply(lambda x:preprocess_x(x))\ntest['text_new']=test['text'].apply(lambda x:preprocess_x(x))","931d71af":"X = train[\"text\"].tolist()\ny = train[\"label\"].tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.10,\n                                                    random_state = 0)","14f7b38b":"tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n                    \n                        stop_words='english')\n\n# We transform each text into a vector\nfeatures = tfidf.fit_transform(train.text).toarray()\n\nlabels = train.label\n\nprint(\"Each of the %d tweets is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))","97e824f0":"models = [\n    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n    LinearSVC(),\n    MultinomialNB(),\n]\n\n# 5 Cross-validation\nCV = 5\ncv_df = pd.DataFrame(index=range(CV * len(models)))\n\nentries = []\nfor model in models:\n  model_name = model.__class__.__name__\n  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n  for fold_idx, accuracy in enumerate(accuracies):\n    entries.append((model_name, fold_idx, accuracy))\n    \ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])","8b53cfb4":"mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\nstd_accuracy = cv_df.groupby('model_name').accuracy.std()\n\nacc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n          ignore_index=True)\nacc.columns = ['Mean Accuracy', 'Standard deviation']\nacc","fb7c62f4":"plt.figure(figsize=(8,5))\nsns.boxplot(x='model_name', y='accuracy', \n            data=cv_df, \n            color='lightblue', \n            showmeans=True)\nplt.title(\"MEAN ACCURACY (cv = 5)\\n\", size=14);","0bb59728":"X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(features, \n                                                               labels, \n                                                               train.index, test_size=0.10, \n                                                               random_state=1)\nmodel =   LinearSVC()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n","199535b1":"# Classification report\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\n\nprint('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\nprint(metrics.classification_report(y_test, y_pred, \n                                    target_names= train['label'].unique()))","7e9a575b":"# Create a new column 'category_id' with encoded categories \n\ndef classes_def(x):\n    if x ==  \"Extremely Positive\":\n        return \"Positive\"\n    elif x == \"Extremely Negative\":\n        return \"Negative\"\n    elif x == \"Negative\":\n        return \"Negative\"\n    elif x ==  \"Positive\":\n        return \"Positive\"\n    else:\n        return \"Neutral\"\n    \n\ntrain['sentiment']=train['Sentiment'].apply(lambda x:classes_def(x))\n\n\nsentiment_id_df= train[[\"sentiment\",'label']].drop_duplicates()\n\n# Dictionaries for future use\n\n\nsentiment_to_id = dict(sentiment_id_df.values)\nid_to_sentiment = dict(sentiment_id_df[[\"sentiment\",'label']].values)\n\n\nsentiment_id_df\n","4bc7fca2":"conf_mat = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n            xticklabels=sentiment_id_df.label.values, \n            yticklabels=sentiment_id_df.label.values)\ntrain = train.drop(columns=['sentiment'])\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.title(\"CONFUSION MATRIX - LinearSVC\\n\", size=16);","7e309aa2":"<font size=+4 color=\"Black\"><center><b>Text Classification<\/b><\/center><\/font>\n<font size=-1 color=\"Black\"><center><b>*Series: All about NLP by Data Tattle <\/b><\/right><\/font>","a3c34b83":"<a id=\"3\"><\/a>\n    \n<font size=\"+2\" color=\"indigo\"><b>3. TF-IDF<\/b><\/font><br>","9afb8f66":"    Precison = True Positive \/ (True Positive + False Positive) = True Positive \/ All Predicted Positive\nPrecision talks about how precise\/accurate your model is out of those predicted positive, how many of them are actual positive. Precision is a good measure to determine, when the costs of False Positive is high. For instance, email spam detection.\n\n    Recall = True Positive \/ (True Positive + False Negative) = True Positive \/ All Actual Positive\nRecall actually calculates how many of the Actual Positives our model capture through labeling it as Positive (True Positive). Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative. For instance, in fraud detection or sick patient detection. \n\n    F1 =  2 * (Precision * Recall) \/ (Precision + Recall)\nF1 Score might be a better measure to use if we need to seek a balance between Precision and Recall AND there is an uneven class distribution (large number of Actual Negatives).","c1b26907":"#### Let's encode Neutral as 0, Negative as 1, and Positive as 2","56b0fc60":"### We see low F1 scores for Positive (2) tweets as compared to Negative (0) and Neutral (1)","29726095":"### About this notebook\n\n## This notebook is a part of Series \"[All about NLP](https:\/\/www.kaggle.com\/datatattle\/all-about-nlp)\" and will cover traditional ML Models\n\n\n![](https:\/\/cdn.dribbble.com\/users\/113062\/screenshots\/2812589\/bots.gif)\n![](https:\/\/miro.medium.com\/proxy\/1*_JW1JaMpK_fVGld8pd1_JQ.gif)","aae801db":"<a id=\"2\"><\/a>\n    \n<font size=\"+2\" color=\"indigo\"><b>2. Text Cleaning<\/b><\/font><br>","c6073df9":"<font size=\"+2\" color=\"Green\"><b>Please Upvote if you like the work<\/b><\/font>\n\n### It gives motivation to a working professional (like me) to contribute more.","050d160e":"<a id=\"1\"><\/a>\n    \n<font size=\"+2\" color=\"indigo\"><b>1. Libraries<\/b><\/font><br>","e61dda71":"#### So there are 10813 features produced using Tf-idf\nTo make vector denser use \\\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n                        ngram_range=(1, 2),\n                        stop_words='english')\n ","642b851b":"Contents:\n\n* [1. Libraries](#1)\n* [2. Text Cleaning](#2)\n* [3. TF-IDF](#3)\n* [4. Models](#4)","e195f6c1":"<font size=\"+3\" color=\"Green\"><b>Related Work:<\/b><\/font>\n\n### Predictions need more attention. Glad up next is Word Embeddings\n\n### Links: Click [here](https:\/\/www.kaggle.com\/datatattle\/all-about-nlp) for related notebooks","399ee4c7":"<font size=\"+3\" color=\"Green\"><b>Please Upvote if you liked the work<\/b><\/font>","1d9b9d8d":"<a id=\"4\"><\/a>\n    \n<font size=\"+2\" color=\"indigo\"><b>4. Models<\/b><\/font><br>","f6c02ead":"\n![#Precious](https:\/\/i.imgur.com\/5YSC6pg.gif)","cbced53e":"### As we can see Linear SVM has the highest accuracy of 79%, followed by Naive Bayes. It's shocking to see Random Forest with the least accuracy"}}