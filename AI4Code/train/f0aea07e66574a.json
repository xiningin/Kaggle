{"cell_type":{"0f041cdd":"code","4b5fa68b":"code","0141ea4f":"code","9734e025":"code","28c1387b":"code","7b36e45c":"code","7367312c":"code","0fc99092":"code","d66f1c91":"code","9a2af30c":"code","85834861":"code","435fd25c":"code","0685fcbe":"code","4306495c":"code","0d339256":"code","afdaa587":"code","81d346f6":"code","bfbbe76a":"code","2c66957d":"code","7e057476":"code","1205a17d":"code","7e21360f":"code","29c4a303":"code","980c7fb1":"markdown","0f2c2771":"markdown","d24ada55":"markdown"},"source":{"0f041cdd":"import numpy as np\nimport pandas as pd\nimport re\nimport warnings \nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.colors import n_colors\nfrom plotly.subplots import make_subplots\ninit_notebook_mode(connected= True)\nimport cufflinks as cf\ncf.go_offline()\nfrom wordcloud import WordCloud, ImageColorGenerator \nimport nltk\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob","4b5fa68b":"df= pd.read_csv('\/kaggle\/input\/indian-products-on-amazon\/amazon_vfl_reviews.csv')\ndf.head()","0141ea4f":"df.isnull().sum()\ndf.shape","9734e025":"df.dropna(inplace= True)\ndf = df.reset_index()\ndf.drop(['index'], axis = 1, inplace= True) \ndf.shape","28c1387b":"def get_brand(x):\n    return x.split('-')[0]\n\ndf['brand']= df['name'].apply(get_brand)\ndf['brand'].unique()","7b36e45c":"df['brand'] = df['brand'].str.replace('PATANJALI', 'Patanjali')\ndf['brand'] = df['brand'].str.replace('MYSORE', 'Mysore')\n\n#number of unique brands\nlen(df['brand'].unique())","7367312c":"df1= pd.DataFrame(df.groupby('brand')['asin'].count().reset_index())\ndf1.columns= ['brand', 'count']\n\nsort_df= df1.sort_values(['count'], ascending= True)\n\nfig= px.bar(sort_df.iloc[:5, :], y= 'brand', x= 'count', orientation= 'h', color= 'count')\nfig.update_layout(title_text= 'Top 5 brands with least number of reviews', title_x= .5, template= 'plotly_dark')\nfig.show()","0fc99092":"import seaborn as sns\nsns.set(rc={'figure.figsize':(15,7)})\nsns.set_theme(style=\"darkgrid\")\nplt.style.use(\"dark_background\")\nplt.title('Top 10 brands with most reviews')\nsns.barplot(x= sort_df['count'].tail(10) , y= sort_df['brand'].tail(10), palette= 'tab10' ).grid(False)","d66f1c91":"brand= sort_df.iloc[-10: , :]['brand'].to_list()\ncount= sort_df.iloc[-10: , :]['count'].to_list()\n\nfig= go.Figure(data= [go.Table(header= dict(values= ['Brand', 'Number of reviews'], fill_color= 'lightblue', height= 40 ),\n                              cells= dict(values=[brand, count], height= 20))])\nfig.update_layout(title_text='Top 5 Names of brands with most number of reviews',title_x=0.5,\n                  template='plotly_dark')\n\nfig.show()","9a2af30c":"stop_words = stopwords.words('english')\n\ncorpus = []\nfor i in range(0,len(df)):\n    text= re.sub('[^a-zA-Z]', ' ', df['review'][i])\n    text= text.lower()\n    text= text.split()\n    text= [word for word in text if not word in stop_words]\n    text= ' '.join(text)\n    corpus.append(text)\n    \nword_cloud = WordCloud(width = 800,\n                       height = 600,\n                       colormap = 'RdYlGn', \n                       margin = 0,\n                       max_words = 200,  \n                       min_word_length = 4,\n                       max_font_size = 120, \n                       background_color = 'black').generate(' '.join(corpus))\n\n\nplt.figure(figsize = (10, 10))\nplt.imshow(word_cloud, interpolation = 'gaussian')\nplt.axis('off')\nplt.show()","85834861":"rating= pd.DataFrame(df['rating'].value_counts().reset_index())\nrating.columns= ['rating', 'count']\n\nrating.sort_values('rating', ascending= False, inplace= True)\nrating","435fd25c":"fig= px.bar(rating, x= 'rating', y= 'count')\nfig.update_layout(title_text= 'Distribution of ratings', title_x= 0.5, template= 'plotly_dark')\nfig.show()","0685fcbe":"def polarity(text):\n    return TextBlob(text).sentiment.polarity\n\ndf['polarity_score']= df['review'].apply(lambda x : polarity(x))\n\ndef sentiment(x):\n    if x<0:\n        return 'negative'\n    elif x==0:\n        return 'neutral'\n    else:\n        return 'positive'\n    \ndf['polarity'] = df['polarity_score'].\\\n   map(lambda x: sentiment(x))","4306495c":"values = df['polarity'].value_counts()\nlabels= df['polarity'].value_counts().index\nplt.pie(values , labels= labels ,explode= (.05,.05,0),\n          colors=['#006400','#8B0000','#add8e6'],startangle= 90)\nplt.axis('equal')\nplt.show()","0d339256":"from nltk.corpus import stopwords\nfrom nltk.cluster.util import cosine_distance\nimport numpy as np\nimport networkx as nx","afdaa587":"def sentence_similarity(sent1, sent2, stopwords=None):\n    if stopwords is None:\n        stopwords = []\n \n    sent1 = [w.lower() for w in sent1]\n    sent2 = [w.lower() for w in sent2]\n \n    all_words = list(set(sent1 + sent2))\n \n    vector1 = [0] * len(all_words)\n    vector2 = [0] * len(all_words)\n \n    # build the vector for the first sentence\n    for w in sent1:\n        if w in stopwords:\n            continue\n        vector1[all_words.index(w)] += 1\n \n    # build the vector for the second sentence\n    for w in sent2:\n        if w in stopwords:\n            continue\n        vector2[all_words.index(w)] += 1\n \n    return 1 - cosine_distance(vector1, vector2)\n \ndef build_similarity_matrix(sentences, stop_words):\n    # Create an empty similarity matrix\n    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n \n    for idx1 in range(len(sentences)):\n        for idx2 in range(len(sentences)):\n            if idx1 == idx2: #ignore if both are same sentences\n                continue \n            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n\n    return similarity_matrix\n\n\ndef generate_summary(rawtext, top_n=2):\n    stop_words = stopwords.words('english')\n    summarize_text = []\n\n    article = rawtext.split(\". \")\n    sentences = []\n\n    for sentence in article:\n        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n\n    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n\n    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n    scores = nx.pagerank(sentence_similarity_graph)\n\n    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n\n    for i in range(top_n):\n        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n\n    return \". \".join(summarize_text)","81d346f6":"generate_summary(df['review'][5], 1)","bfbbe76a":"extract_summary= []\nfor i in range(0,10):\n    summary= generate_summary(df['review'][i], 1)\n    extract_summary.append(summary)","2c66957d":"for i in range(0,10):\n    print(\"rating:\", df['rating'][i], \" Summary:\" , extract_summary[i],'\\n' )","7e057476":"from transformers import pipeline\nsummarizer  = pipeline('summarization')","1205a17d":"summary= summarizer(df['review'][220], max_length= 30, min_length=5, do_sample=False)[0]\n\nprint(summary['summary_text'])","7e21360f":"review_summary= []\nfor i in range(0, 10):\n    summary= summarizer(df['review'][i], max_length= 30, min_length=5, do_sample=False)[0]\n    review_summary.append(summary['summary_text'])","29c4a303":"for i in range(0,10):\n    print(\"rating:\", df['rating'][i], \" Summary:\" , review_summary[i],'\\n' )","980c7fb1":"Summarizing first ten reviews","0f2c2771":"# Abstractive summarization using HuggingFace Transformers","d24ada55":"# Text summarization Extractive method"}}