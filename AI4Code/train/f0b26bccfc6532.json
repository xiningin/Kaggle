{"cell_type":{"48db57b3":"code","5e858c3a":"code","bda4e281":"code","02e8c048":"code","113aae08":"code","239fe19f":"code","bdbc488c":"code","26f3686a":"code","0bf2080c":"code","cec82082":"code","4ea98747":"code","ad612248":"code","59388012":"code","72238cbf":"code","32cec7cb":"code","972512a4":"code","11224a3e":"code","97cae8d1":"code","adee791a":"code","d300743e":"code","5b6c23a1":"code","a31037b7":"code","bb67ca3a":"code","f9b7c2fe":"code","af8e4cd8":"code","bbd08b9e":"code","e5d27074":"code","9c7e05d3":"code","576607fd":"code","2b99cc0e":"code","9214e759":"code","5c589fd0":"code","ba91cf18":"code","121b594b":"code","1e8fa7a4":"code","d9418c36":"code","7650f4db":"code","ef766453":"code","da916750":"code","9a5ebfe9":"code","6bc2ac03":"code","f6501492":"code","d2fb30fa":"code","42bd1aaf":"code","77a96d5a":"code","93bf4ff1":"code","8188c658":"code","f064e0be":"code","bffd2742":"code","50a8829e":"markdown","33f01478":"markdown","65220953":"markdown","06057a95":"markdown","136c1e7b":"markdown","924cfcec":"markdown","29d9f072":"markdown","ac46e7e7":"markdown","ae947ed9":"markdown"},"source":{"48db57b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5e858c3a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings; warnings.simplefilter('ignore')\n%matplotlib inline\n\n# importar pacotes usados na sele\u00e7\u00e3o do modelo e na medi\u00e7\u00e3o da precis\u00e3o\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import mean_squared_error\n\n# importar os pacotes necess\u00e1rios para os algoritmos de classifica\u00e7\u00e3o\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier","bda4e281":"data = pd.read_csv('..\/input\/abalone-train.csv', index_col='id')\ntest = pd.read_csv('..\/input\/abalone-test.csv', index_col='id')","02e8c048":"print(data.shape)\ndata.head()","113aae08":"print(test.shape)\ntest.head()","239fe19f":"data['sex_I'] = data['sex'].map({'I': 1, 'F': 0, 'M':0}).astype(int)\ndata['sex_F'] = data['sex'].map({'I': 0, 'F': 1, 'M':0}).astype(int)\ndata['sex_M'] = data['sex'].map({'I': 0, 'F': 0, 'M':1}).astype(int)\ndata['is_outlier'] = 'normal'\ndata = data[['sex', 'sex_I', 'sex_F', 'sex_M', 'length', 'diameter', \n               'height', 'whole_weight', 'shucked_weight', 'viscera_weight', 'shell_weight', 'rings', 'is_outlier']]\ndata.head()","bdbc488c":"test['sex_I'] = test['sex'].map({'I': 1, 'F': 0, 'M':0}).astype(int)\ntest['sex_F'] = test['sex'].map({'I': 0, 'F': 1, 'M':0}).astype(int)\ntest['sex_M'] = test['sex'].map({'I': 0, 'F': 0, 'M':1}).astype(int)\ntest = test[['sex', 'sex_I', 'sex_F', 'sex_M', 'length', 'diameter', \n               'height', 'whole_weight', 'shucked_weight', 'viscera_weight', 'shell_weight']]\ntest.head()","26f3686a":"data.describe()","0bf2080c":"numerical_features = data.columns\nnumerical_features = numerical_features.drop(['sex', 'sex_I', 'sex_F', 'sex_M', 'is_outlier'])\nsns.pairplot(data[numerical_features])","cec82082":"outliers_anteriores = data['is_outlier'][data['is_outlier'] == 'outlier'].count()\n\nfor col in numerical_features:\n    if col != 'is_outlier':\n        data['is_outlier'][data[col] >= data[col].quantile(0.999)] = 'outlier'\n        data['is_outlier'][data[col] <= data[col].quantile(0.001)] = 'outlier'\n        data['is_outlier'][data[col] == np.nan] = 'outlier'\n\noutliers_atuais = data['is_outlier'][data['is_outlier'] == 'outlier'].count()\nprint(\"O loop acrescentou \" + str(outliers_atuais - outliers_anteriores) + \" outlier(s).\")\nsns.pairplot(data, hue='is_outlier')","4ea98747":"data[data['is_outlier'] != 'outlier'].describe()","ad612248":"data[data['is_outlier'] != 'normal']","59388012":"data[numerical_features].head()","72238cbf":"#from sklearn.preprocessing import MinMaxScaler\n#\n#scaler = MinMaxScaler()\n#data_copy = pd.DataFrame(data, columns = data.columns)\n#test_copy = pd.DataFrame(test, columns = test.columns)\n#data = pd.DataFrame(scaler.fit_transform(data[numerical_features[:-1]]), columns=numerical_features[:-1])\n#data['rings'] = data_copy['rings']\n#test = pd.DataFrame(scaler.fit_transform(test[numerical_features[:-1]]), columns=numerical_features[:-1])","32cec7cb":"data.head()","972512a4":"outliers_anteriores = data['is_outlier'][data['is_outlier'] == 'outlier'].count()\n\nfrom sklearn.cluster import DBSCAN\nfor x in numerical_features:\n    for y in numerical_features:\n        db = DBSCAN(eps = data[y].max() * 0.2, min_samples = data[y].count() * 0.01).fit(data[[x,y]])\n        data['is_outlier'][db.labels_ == -1] = 'outlier'\n        \noutliers_atuais = data['is_outlier'][data['is_outlier'] == 'outlier'].count()\nprint(\"O DBSCAN acrescentou \" + str(outliers_atuais - outliers_anteriores) + \" outlier(s).\")\nsns.pairplot(data, hue='is_outlier')","11224a3e":"def manual_outliers():\n    descricao = 'outlier'\n    \n    outliers_anteriores = data['is_outlier'][data['is_outlier'] == descricao].count()\n    \n    var_x = 'length'\n    var_y = 'rings'\n    data['is_outlier'][(data[var_x] <= 0.1) & (data[var_y] >= 0)] = descricao\n    var_x = 'diameter'\n    var_y = 'rings'\n    data['is_outlier'][(data[var_x] <= 0.1) & (data[var_y] >= 0)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.6) & (data[var_y] >= 25)] = descricao\n    data['is_outlier'][(data[var_x] >= 0.6) & (data[var_y] <= 25)] = descricao\n    var_x = 'height'\n    var_y = 'rings'\n    data['is_outlier'][(data[var_x] >= 0.4) & (data[var_y] <= 15)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.4) & (data[var_y] >= 25)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.01) & (data[var_y] >= 5)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.05) & (data[var_y] >= 7.5)] = descricao\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] >= 25)] = descricao\n    var_x = 'whole_weight'\n    var_y = 'rings'\n    data['is_outlier'][(data[var_x] >= 2) & (data[var_y] >= 0)] = descricao\n    data['is_outlier'][(data[var_x] >= 0) & (data[var_y] >= 20)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.01) & (data[var_y] >= 0)] = descricao\n    var_x = 'shucked_weight'\n    var_y = 'rings'\n    data['is_outlier'][(data[var_x] >= 1) & (data[var_y] >= 0)] = descricao\n    data['is_outlier'][(data[var_x] >= 0) & (data[var_y] >= 20)] = descricao\n    var_x = 'viscera_weight'\n    var_y = 'rings'\n    data['is_outlier'][(data[var_x] >= 0.55) & (data[var_y] >= 0)] = descricao\n    data['is_outlier'][(data[var_x] >= 0) & (data[var_y] >= 22.5)] = descricao\n    var_x = 'shell_weight'\n    var_y = 'rings'\n    data['is_outlier'][(data[var_x] >= 0.6) & (data[var_y] >= 0)] = descricao\n    data['is_outlier'][(data[var_x] >= 0) & (data[var_y] >= 20)] = descricao\n    var_x = 'length'\n    var_y = 'shell_weight'\n    data['is_outlier'][(data[var_x] <= 0.2) & (data[var_y] >= 0.1)] = descricao\n    var_x = 'diameter'\n    var_y = 'shell_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] >= 0.6)] = descricao\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0)] = descricao\n    var_x = 'height'\n    var_y = 'shell_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0)] = descricao\n    var_x = 'whole_weight'\n    var_y = 'shell_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.0) & (data[var_y] >= 0)] = descricao\n    var_x = 'shucked_weight'\n    var_y = 'shell_weight'\n    data['is_outlier'][(data[var_x] >= 0.4) & (data[var_y] <= 0.05)] = descricao\n    var_x = 'viscera_weight'\n    var_y = 'shell_weight'\n    data['is_outlier'][(data[var_x] >= 0.4) & (data[var_y] <= 0.3)] = descricao\n    data['is_outlier'][(data[var_x] >= 0.5) & (data[var_y] >= 0.5)] = descricao\n    var_x = 'rings'\n    var_y = 'shell_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0)] = descricao\n    var_x = 'length'\n    var_y = 'viscera_weight'\n    data['is_outlier'][(data[var_x] >= 0.7) & (data[var_y] <= 0.2)] = descricao\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0.0)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.45) & (data[var_y] >= 0.2)] = descricao\n    var_x = 'diameter'\n    var_y = 'viscera_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0)] = descricao\n    var_x = 'height'\n    var_y = 'viscera_weight'\n    data['is_outlier'][(data[var_x] <= 0.1) & (data[var_y] >= 0.25)] = descricao\n    data['is_outlier'][(data[var_x] >= 0.225) & (data[var_y] >= 0)] = descricao\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0.0)] = descricao\n    var_x = 'whole_weight'\n    var_y = 'viscera_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.0) & (data[var_y] >= 0)] = descricao\n    var_x = 'shucked_weight'\n    var_y = 'viscera_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] >= 0.49)] = descricao\n    var_x = 'shell_weight'\n    var_y = 'viscera_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.0) & (data[var_y] >= 0)] = descricao\n    var_x = 'rings'\n    var_y = 'viscera_weight'\n    data['is_outlier'][(data[var_x] >= 0.0) & (data[var_y] <= 0)] = descricao\n    data['is_outlier'][(data[var_x] <= 0.0) & (data[var_y] >= 0)] = descricao\n    \n    outliers_atuais = data['is_outlier'][data['is_outlier'] == descricao].count()\n    \n    return \"A fun\u00e7\u00e3o marcou \" + str(outliers_atuais - outliers_anteriores) + \" outlier(s).\"\n#    \nprint(manual_outliers())","97cae8d1":"sns.pairplot(data, hue='is_outlier')","adee791a":"print(\"Dados normais: \", data['is_outlier'][data['is_outlier'] != 'outlier'].count())\nprint(\"Dados ruidosos: \", data['is_outlier'][data['is_outlier'] == 'outlier'].count())","d300743e":"data.drop(data.index[data['is_outlier'] == 'outlier'], inplace = True)\nprint(\"Dados normais: \", data['is_outlier'][data['is_outlier'] != 'outlier'].count())\nprint(\"Dados ruidosos: \", data['is_outlier'][data['is_outlier'] == 'outlier'].count())","5b6c23a1":"sns.pairplot(data, hue='is_outlier')","a31037b7":"plt.figure(figsize=(20,7))\nsns.heatmap(data[numerical_features].corr(), annot=True)","bb67ca3a":"data.drop('is_outlier', axis = 1, inplace = True)\ndata.head()","f9b7c2fe":"#selectkBest = SelectKBest()\n#X_new = selectkBest.fit_transform(X, y)","af8e4cd8":"columns = ['diameter', 'whole_weight', 'sex', 'sex_I', 'sex_F', 'sex_M']\nX_train = data.drop(columns, axis = 1)\nX_train.drop('rings', axis = 1, inplace = True)\nX_train.head()","bbd08b9e":"y_train = pd.DataFrame(data['rings'])\ny_train.head()","e5d27074":"X_test = test.drop(columns, axis = 1)\n#standardScale.fit_transform(X_test)\nX_test.head()","9c7e05d3":"# exibindo as caracter\u00edsticas dos dados\n\nprint(\"X_train.shape: \", X_train.shape, type(X_train))\nprint(\"y_train.shape: \", y_train.shape, type(y_train))\nprint(\"X_test.shape: \", X_test.shape, type(X_test))","576607fd":"# criando lista de modelos preditivos a serem comparados\n# mapeando os nomes dos par\u00e2metros dos modelos aos valores a serem verificados\n\nmodels = []\n\nfrom sklearn.linear_model import LinearRegression\nparam_grid = {'fit_intercept':[True]}\nmodels.append(('LinearRegression', LinearRegression(), param_grid))\n\nfrom sklearn.linear_model import Ridge\nparam_grid = {'alpha':[0.01, 0.1, 1, 10, 100, 1000], 'copy_X':[True], 'fit_intercept':[True], 'max_iter':[None], 'normalize':[False], 'random_state':[None], 'solver':['auto'], 'tol':[0.001]}\nmodels.append(('Ridge', Ridge(), param_grid))\n\nfrom sklearn.svm import SVR\nparam_grid = {'kernel': ['rbf'], 'gamma': [0.2, 0.4, 0.6, 0.8, 1.0],'C': range(500, 2001, 100), 'epsilon': [x\/100 for x in range(100,201,5)]}\nmodels.append(('SVR', SVR(), param_grid))\n\nfrom sklearn.ensemble import RandomForestRegressor\nparam_grid = {'max_depth':range(1,4), 'random_state':[None, 0], 'n_estimators':range(50,151,50)}\nmodels.append(('RandomForestRegressor', RandomForestRegressor(), param_grid))\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nparam_grid = {'n_estimators':range(60,201,20), 'max_depth':range(1,5), 'learning_rate':[x\/100 for x in range(10,101,10)]} #'loss':['ls', 'lad', 'huber', 'quantile'], 'random_state':[None, 0, 1, 2], \nmodels.append(('GradientBoostingRegressor', GradientBoostingRegressor(), param_grid))\n\nfrom sklearn.neighbors import KNeighborsRegressor\nparam_grid = {'n_neighbors':[4, 5, 1, 2, 3, 6, 7, 8, 9, 10]}\nmodels.append(('KNeighborsRegressor', KNeighborsRegressor(), param_grid))\n\nfrom sklearn.tree import DecisionTreeRegressor\nparam_grid = {'max_depth':[None, 1, 2, 3, 4, 5, 6]}\nmodels.append(('DecisionTreeRegressor', DecisionTreeRegressor(), param_grid))\n\nprint(models)","2b99cc0e":"# Definindo fun\u00e7\u00e3o score de regress\u00e3o: Raiz do Erro Quadr\u00e1tico M\u00e9dio - RMSE (Root Mean Square Error)\n\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n#    return np.sqrt(mean_squared_error(y_true, y_pred))*(-1)\n\nrmse_scorer = make_scorer(rmse, greater_is_better=False)\n#rmse_scorer = make_scorer(rmse, greater_is_better=True)","9214e759":"# Comparando os modelos selecionados, com score RMSE\n\nnames = []\nbest_scores = []\nbest_params = []\nbest_estimator = []\n\ncross_validator = KFold(5)\n\nfor name, model, par_grid in models:\n    grid = GridSearchCV(estimator = model, param_grid = par_grid, cv = cross_validator, \n                        scoring = rmse_scorer)\n    grid.fit(X_train, np.ravel(y_train,order='C'))  \n    names.append(name)\n    best_scores.append(grid.best_score_)\n    best_params.append(grid.best_params_)\n    best_estimator.append(grid.best_estimator_)\n    \nresults_prev = pd.DataFrame({'Model': names, 'Score': best_scores, 'best_params':best_params, 'best_estimator':best_estimator})  ","5c589fd0":"results_prev.sort_values(by=['Score'], ascending=False, inplace=True)","ba91cf18":"results_prev[['Model', 'Score', 'best_params']]","121b594b":"results_prev[['Model', 'Score', 'best_estimator']]","1e8fa7a4":"# gerando o arquivo CSV dos melhores modelos\nresults_prev.to_csv('.\/best_models.csv')\n\n# lendo o arquivo CSV dos melhores modelos\nresults_prev = pd.read_csv('.\/best_models.csv')","d9418c36":"results_prev[['Model', 'Score', 'best_params']]","7650f4db":"results_prev[['Model', 'Score', 'best_estimator']]","ef766453":"# otimizando o modelo e verificando as novas configura\u00e7\u00f5es\n\nmodel_prev = eval(results_prev['best_estimator'][0])\nprint(model_prev)","da916750":"# treinando o modelo e avaliando o score\n\nmodel_prev.fit(X_train, np.ravel(y_train,order='C'))\nprint(rmse(y_train, model_prev.predict(X_train)))","9a5ebfe9":"# executando mais uma rodada para ajuste fino do melhor modelo computado\n\nmodels = []\n\nparam_grid = {'kernel': ['rbf'], 'gamma': [x\/10 for x in range(8,19)],'C': range(1400,2500,100), 'epsilon': [x\/100 for x in range(100,201,5)]}\nmodels.append(('SVR_1', SVR(), param_grid))\n\n#param_grid = {'kernel': ['rbf'], 'gamma': [0.8, 0.9, 1.0],'C': [900, 1000, 1100], 'epsilon': [0.05, 0.1, 0.2]}\n#models.append(('SVR_1', SVR(), param_grid))\n\n#param_grid = {'kernel': ['rbf'], 'gamma': [x\/10 for x in range(6,17)],'C': range(500,1501,100), 'epsilon': [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]}\n#models.append(('SVR_1', SVR(), param_grid))\n\n#param_grid = {'kernel': ['rbf'], 'gamma': [x\/10 for x in range(1,21)],'C': range(1000,10001, 1000)}\n#models.append(('SVR_2', SVR(), param_grid))\n\nprint(models)\n\nnames = []\nbest_scores = []\nbest_params = []\nbest_estimator = []\n\ncross_validator = KFold(5)\n\nfor name, model, par_grid in models:\n    grid = GridSearchCV(estimator = model, param_grid = par_grid, cv = cross_validator, \n                        scoring = rmse_scorer)\n    grid.fit(X_train, np.ravel(y_train,order='C'))  \n    names.append(name)\n    best_scores.append(grid.best_score_)\n    best_params.append(grid.best_params_)\n    best_estimator.append(grid.best_estimator_)\n    \nresults = pd.DataFrame({'Model': names, 'Score': best_scores, 'best_params':best_params, 'best_estimator':best_estimator})  \nprint(results)","6bc2ac03":"# gerando o arquivo CSV dos melhores modelos\nresults.to_csv('.\/best_models_opt.csv')\n\n# lendo o arquivo CSV dos melhores modelos\nresults = pd.read_csv('.\/best_models_opt.csv')","f6501492":"results.sort_values(by=['Score'], ascending=False, inplace=True)\nresults[['Model', 'Score', 'best_params']]","d2fb30fa":"model = eval(results['best_estimator'][0])\nprint(model)","42bd1aaf":"# treinando o modelo e avaliando o score\n\nmodel.fit(X_train, np.ravel(y_train,order='C'))\nprint(rmse(y_train, model.predict(X_train)))","77a96d5a":"# Gerando a predi\u00e7\u00e3o dos dados de teste\n\ny_test = model.predict(X_test)","93bf4ff1":"# Analisando os resultados\nprint('y_test: ', type(y_test), y_test.shape)\nprint(y_test)\nprint(y_test.flatten())","8188c658":"# Gerando o conjunto de dados de sa\u00edda\n\nsubmission = pd.DataFrame({'id': X_test.index, 'rings': y_test.flatten()})\nsubmission.set_index('id', inplace=True)\n\n# Exibindo os dados de sa\u00edda\n\nsubmission.head(10)","f064e0be":"# gerando o arquivo CSV de sa\u00edda\nsubmission.to_csv('.\/abalone-submission.csv')\n\n# verificando o conte\u00fado do arquivo gerado\nsubmission = pd.read_csv('.\/abalone-submission.csv', index_col='id')","bffd2742":"submission","50a8829e":"Importando bibliotecas","33f01478":"Adquirindo os dados","65220953":"Gerando dados de treino e teste","06057a95":"Reduzindo a dimensionalidade","136c1e7b":"Lidando com outliers e afins","924cfcec":"modelando","29d9f072":"Gerando sa\u00edda de dados","ac46e7e7":"Transformando os dados","ae947ed9":"Inspecionando os dados"}}