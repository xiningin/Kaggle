{"cell_type":{"4fc6b374":"code","36fdd021":"code","c02c5b36":"code","86faf8f5":"code","81e5c91e":"code","804ebd11":"code","6897eb9e":"code","47775b0d":"code","0dc9ec1e":"code","7450060a":"code","e4142f4f":"code","da0f5816":"code","123dda5e":"code","9814f50f":"code","b6511a7d":"code","4795fc4c":"code","3ca0ecb7":"code","f6d09cca":"code","0987fbac":"code","e98487f4":"code","c32e1217":"code","0288bdfe":"code","d42bd975":"code","ba82da8a":"code","7fbb67e0":"code","e4bcd880":"code","f2bf6b5c":"code","c090d3ef":"code","a8483ca7":"code","169cd75a":"code","0955cff6":"code","a6e25299":"code","b8ad59ca":"code","d2e4b118":"code","a28dfa13":"code","61ceec7a":"code","a7b477d1":"markdown","58ac0408":"markdown","2368ec5e":"markdown","4048cdbd":"markdown","3d3f407b":"markdown","52c48e69":"markdown","c83dde46":"markdown","40b94507":"markdown","89937222":"markdown"},"source":{"4fc6b374":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks.hooks import *\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import auc,roc_curve\n\nimport os\nprint(os.listdir(\"..\/input\"))","36fdd021":"# Paths and roots to the important files\npath='..\/input\/'\ncsv_file='..\/input\/HAM10000_metadata.csv'","c02c5b36":"df=pd.read_csv(csv_file).set_index('image_id')\ndf.head()","86faf8f5":"# Categories of the diferent diseases\nlesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}","81e5c91e":"df.dx=df.dx.astype('category',copy=True)\ndf['labels']=df.dx.cat.codes # Convert the labels to numbers\ndf['lesion']= df.dx.map(lesion_type_dict)\ndf.head()","804ebd11":"print(df.lesion.value_counts())\n","6897eb9e":"df.loc['ISIC_0027419','lesion']","47775b0d":"fig, ax1 = plt.subplots(1, 1, figsize = (10, 5))\nsns.countplot(y='lesion',data=df, hue=\"lesion\",ax=ax1)","0dc9ec1e":"class CustomImageItemList(ImageItemList):\n    def custom_label(self,df, **kwargs)->'LabelList':\n        \"\"\"Custom Labels from path\"\"\"\n        file_names=np.vectorize(lambda files: str(files).split('\/')[-1][:-4])\n        get_labels=lambda x: df.loc[x,'lesion']\n        #self.items is an np array of PosixPath objects with each image path\n        labels= get_labels(file_names(self.items))\n        y = CategoryList(items=labels)\n        res = self._label_list(x=self,y=y)\n        return res","7450060a":"def get_data(bs, size):\n    train_ds = (CustomImageItemList.from_folder('..\/input', extensions='.jpg')\n                    .random_split_by_pct(0.15)\n                    .custom_label(df)\n                    .transform(tfms=get_transforms(flip_vert=True),size=size)\n                    .databunch(num_workers=2, bs=bs)\n                    .normalize(imagenet_stats))\n    return train_ds","e4142f4f":"data=get_data(16,224)","da0f5816":"data.classes=list(np.unique(df.lesion))  \ndata.c= len(np.unique(df.lesion))  ","123dda5e":"data.show_batch(rows=3)","9814f50f":"learner=create_cnn(data,models.resnet50,metrics=[accuracy], model_dir=\"\/tmp\/model\/\")","b6511a7d":"learner.loss_func=nn.CrossEntropyLoss()","4795fc4c":"learner.lr_find()\nlearner.recorder.plot()","3ca0ecb7":"learner.fit_one_cycle(10, 3e-3)","f6d09cca":"learner.unfreeze()","0987fbac":"learner.lr_find()\nlearner.recorder.plot()","e98487f4":"lr=1e-6\nlearner.fit_one_cycle(3, slice(3*lr,10*lr))","c32e1217":"learner.save('stage-1')","0288bdfe":"interp = ClassificationInterpretation.from_learner(learner)","d42bd975":"interp.plot_confusion_matrix(figsize=(10,8))","ba82da8a":"interp.most_confused()","7fbb67e0":"pred_data=get_data(16,224)","e4bcd880":"pred_data.classes=list(np.unique(df.lesion))  \npred_data.c= len(np.unique(df.lesion)) ","f2bf6b5c":"pred_data.single_from_classes(path, pred_data.classes)","c090d3ef":"predictor = create_cnn(pred_data, models.resnet50, model_dir=\"\/tmp\/model\/\").load('stage-1')","a8483ca7":"img = open_image('..\/input\/ham10000_images_part_2\/ISIC_0029886.jpg')\nimg","169cd75a":"pred_class,pred_idx,outputs = predictor.predict(img)\npred_class","0955cff6":"# Predictions of the validation data\npreds_val, y_val=learner.get_preds()","a6e25299":"#  ROC curve\nfpr, tpr, thresholds = roc_curve(y_val.numpy(), preds_val.numpy()[:,1], pos_label=1)\n\n#  ROC area\npred_score = auc(fpr, tpr)\nprint(f'ROC area is {pred_score}')","b8ad59ca":"plt.figure()\nplt.plot(fpr, tpr, color='orange', label='ROC curve (area = %0.2f)' % pred_score)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.01])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")","d2e4b118":"x,y = data.valid_ds[2]\nx.show()\ndata.valid_ds.y[2]","a28dfa13":"def heatMap(x,y,data, learner, size=(0,224,224,0)):\n    \"\"\"HeatMap\"\"\"\n    \n    # Evaluation mode\n    m=learner.model.eval()\n    \n    # Denormalize the image\n    xb,_ = data.one_item(x)\n    xb_im = Image(data.denorm(xb)[0])\n    xb = xb.cuda()\n    \n    # hook the activations\n    with hook_output(m[0]) as hook_a: \n        with hook_output(m[0], grad=True) as hook_g:\n            preds = m(xb)\n            preds[0,int(y)].backward()\n\n    # Activations    \n    acts=hook_a.stored[0].cpu()\n    \n    # Avg of the activations\n    avg_acts=acts.mean(0)\n    \n    # Show HeatMap\n    _,ax = plt.subplots()\n    xb_im.show(ax)\n    ax.imshow(avg_acts, alpha=0.6, extent=size,\n              interpolation='bilinear', cmap='magma')\n    ","61ceec7a":"heatMap(x,y,pred_data,learner)","a7b477d1":"## Countplot\nHere we notice tha we have data imbalance ","58ac0408":"# Skin Cancer Detencion\n\n\nTraining of neural networks for automated diagnosis of pigmented skin lesions is hampered by the small size and lack of diversity of available dataset of dermatoscopic images. We tackle this problem by releasing the HAM10000 (\"Human Against Machine with 10000 training images\") dataset. We collected dermatoscopic images from different populations, acquired and stored by different modalities. The final dataset consists of 10015 dermatoscopic images which can serve as a training set for academic machine learning purposes. Cases include a representative collection of all important diagnostic categories in the realm of pigmented lesions: Actinic keratoses and intraepithelial carcinoma \/ Bowen's disease (akiec), basal cell carcinoma (bcc), benign keratosis-like lesions (solar lentigines \/ seborrheic keratoses and lichen-planus like keratoses, bkl), dermatofibroma (df), melanoma (mel), melanocytic nevi (nv) and vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).\n\nMore than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal). The dataset includes lesions with multiple images, which can be tracked by the lesion_id-column within the HAM10000_metadata file.\n\n![skin cancer](http:\/\/www.justscience.in\/wp-content\/uploads\/2017\/12\/what-causes-skin-cancer.jpg)\n\n\n\n","2368ec5e":"## Exploratory Data Analysis","4048cdbd":"## Dataset","3d3f407b":"### Roc Curve\nWith the ROC curve we will mesuare how good it's our model","52c48e69":"## Predictions","c83dde46":"## Inference","40b94507":"## Model ResNet50 ","89937222":"## Heatmap"}}