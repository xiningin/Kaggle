{"cell_type":{"c498a7dd":"code","a810e2c3":"code","220f4d8f":"code","aa170650":"code","44edeec0":"code","c2fcb455":"code","ab75c711":"code","260cae09":"code","da89f6dd":"code","80d04a53":"code","fcff5837":"code","c13a2627":"code","31e78dd2":"code","20560260":"code","f76f8720":"code","ee834df1":"code","5f7f602f":"code","fc320f2d":"code","d80b4dbf":"markdown","706c8953":"markdown","20f2997d":"markdown","30a3e292":"markdown"},"source":{"c498a7dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a810e2c3":"# import libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\ntf.__version__","220f4d8f":"data_train = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ndata_test = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","aa170650":"data_train.head()","44edeec0":"data_test.head()","c2fcb455":"from keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nimg_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\nX = np.array(data_train.iloc[:, 1:])\ny = to_categorical(np.array(data_train.iloc[:, 0]))\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n\n#Test data\nX_test = np.array(data_test.iloc[:, 1:])\ny_test = to_categorical(np.array(data_test.iloc[:, 0]))","ab75c711":"from keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nX = np.array(data_train.iloc[:, 1:])     \ny = to_categorical(np.array(data_train.iloc[:, 0]))","260cae09":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n\n#Test data\nX_test = np.array(data_test.iloc[:, 1:])\ny_test = to_categorical(np.array(data_test.iloc[:, 0]))","da89f6dd":"img_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\nX_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_val = X_val.astype('float32')\nX_train \/= 255\nX_test \/= 255\nX_val \/= 255","80d04a53":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nnum_classes = 10\n\n#input image dimensions\nimg_rows, img_cols = 28, 28\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])\nmodel.summary()","fcff5837":"batch_size = 256\nepochs = 50\n\nhistory = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_val, y_val))","c13a2627":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)","31e78dd2":"test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\nprint('\\nTest accuracy:', test_acc)","20560260":"probability_model = tf.keras.Sequential([model, \n                                         tf.keras.layers.Softmax()])","f76f8720":"predictions = probability_model.predict(X_test)","ee834df1":"preds = pd.Series(np.argmax(model.predict(X_test), axis=1).tolist())","5f7f602f":"out_df = pd.DataFrame({\n    'ImageId': pd.Series(range(1,28001)),\n    'Label': preds\n})\nout_df","fc320f2d":"out_df.to_csv('my_submission.csv', index=False)","d80b4dbf":"## Build the CNN model ","706c8953":"## Making Predictions","20f2997d":"## Convert the dataframes into numpy arrays","30a3e292":"## Training the CNN\n"}}