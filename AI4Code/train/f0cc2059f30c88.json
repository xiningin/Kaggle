{"cell_type":{"45013564":"code","e9101ea3":"code","a22fb9b9":"code","50ee6540":"code","5577e835":"code","308e6f51":"code","eb70ef3d":"code","65801907":"code","56df9fe6":"code","9802b349":"code","1a420969":"code","c5d2dfcf":"code","212625ff":"code","f6079e65":"code","293f56e1":"code","3b284171":"code","d62ddd38":"code","346a0e04":"code","6a08807a":"code","72d13762":"code","8e1e3db3":"code","73c29859":"code","ba27350e":"code","f266c94b":"code","84462541":"code","5c29e5ab":"code","cc134625":"code","bd79f9f6":"code","c33aa2b7":"markdown","99265cb7":"markdown","5897d00a":"markdown","81cf3e70":"markdown","ff5bfdb1":"markdown","b854745a":"markdown","6d57ede0":"markdown","cace2507":"markdown","c7f5ca28":"markdown","d4ad6515":"markdown","18cc72b2":"markdown","cbd2a8ec":"markdown"},"source":{"45013564":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport itertools\nimport tensorflow as tf\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dropout, Dense, Input, Conv1D, MaxPooling1D, Flatten\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn ","e9101ea3":"df = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\ndf.head()","a22fb9b9":"df.info()","50ee6540":"df.describe()","5577e835":"df.isnull().sum()","308e6f51":"sns.countplot(df.target)\nplt.show()\ndf.target.value_counts(normalize=True)","eb70ef3d":"pd.crosstab(df.sex, df.target).plot(kind='bar')","65801907":"plt.figure(figsize = (12, 6), dpi = 100)\nsns.heatmap(df.corr(), annot = True)","56df9fe6":"X = df.drop('target', axis = 1).values\ny = df['target'].values\n\n# 80-20 Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n\nscaler = StandardScaler()\nX_train= scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","9802b349":"X_train.shape","1a420969":"i = Input(shape=(None, 242, 13))\n\nx = Dense(16, activation='relu')(i)\n# x = Dropout(0.2)(x)\n\nx = Dense(32, activation='relu')(i)\n# x = Dropout(0.2)(x)\n\nx = Dense(16, activation='relu')(x)\n# x = Dropout(0.2)(x)\n\ny = Dense(1, activation='sigmoid')(x)\n\nmodel_dnn = Model(inputs=i, outputs=y)","c5d2dfcf":"model_dnn.compile(optimizer='adam', \n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])\n\ntf.keras.utils.plot_model(model_dnn, show_shapes=True)","212625ff":"model_dnn.summary()","f6079e65":"early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\nhistory_dnn = model_dnn.fit(x=X_train, y=y_train,\n                            validation_data=(X_test, y_test),\n                            epochs=50,\n                            callbacks=[early_stopping])","293f56e1":"acc = history_dnn.history['accuracy']\nval_acc = history_dnn.history['val_accuracy']\n\nloss = history_dnn.history['loss']\nval_loss = history_dnn.history['val_loss']\n\nplt.figure(figsize=(12, 10))\nplt.subplot(2, 1, 1)\n\nplt.plot(acc, label='Training Accuracy', color='r')\nplt.plot(val_acc, label='Validation Accuracy', color='b')\n\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='lower right', fontsize=13)\nplt.ylabel('Accuracy', fontsize=16, weight='bold')\nplt.title('Heart Disease (DNN) - Training & Validation Acc.', fontsize=16, weight='bold')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss', color='r')\nplt.plot(val_loss, label='Validation Loss', color='b')\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='upper right', fontsize=13)\nplt.ylabel('Cross Entropy', fontsize=16, weight='bold')\nplt.title('Heart Disease (DNN) - Training & Validation Loss', fontsize=16, weight='bold')\nplt.xlabel('Epoch', fontsize=15, weight='bold')\nplt.show()","3b284171":"Y_pred = model_dnn.predict(X_test)\ny_pred = np.round(Y_pred).astype(int)\n\nprint(classification_report(y_test, y_pred))","d62ddd38":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(10, 10))\nplot_confusion_matrix(cnf_matrix, classes=['0', '1'], normalize=True, title='Normalized Confusion Matrix - DNN')\nplt.show()","346a0e04":"i_c = Input(shape=(X_train.shape[1],1))\n\nx_c = Conv1D(16, 2, strides=1, activation='relu')(i_c)\nx_c = MaxPooling1D(1)(x_c)\n\nx_c = Conv1D(32, 2, strides=1, activation='relu')(i_c)\nx_c = MaxPooling1D(1)(x_c)\n\nx_c = Conv1D(16, 2, strides=1, activation='relu')(x_c)\nx_c = MaxPooling1D(1)(x_c)\n\nx_c = Flatten()(x_c)\n# x_c = Dropout(0.3)(x_c)\n\ny_c = Dense(1, activation='sigmoid')(x_c)\n\nmodel_cnn = Model(inputs=i_c, outputs=y_c)\n\nmodel_cnn.summary()","6a08807a":"model_cnn.compile(optimizer='adam', \n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])\n\ntf.keras.utils.plot_model(model_cnn, show_shapes=True)","72d13762":"history_cnn = model_cnn.fit(x=X_train, y=y_train,\n                            validation_data = (X_test, y_test),\n                            epochs = 50,\n                            callbacks = [early_stopping])","8e1e3db3":"acc = history_cnn.history['accuracy']\nval_acc = history_cnn.history['val_accuracy']\n\nloss = history_cnn.history['loss']\nval_loss = history_cnn.history['val_loss']\n\nplt.figure(figsize=(12, 10))\nplt.subplot(2, 1, 1)\n\nplt.plot(acc, label='Training Accuracy', color='cyan')\nplt.plot(val_acc, label='Validation Accuracy', color='purple')\n\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='lower right', fontsize=13)\nplt.ylabel('Accuracy', fontsize=16, weight='bold')\nplt.title('Heart Disease (CNN) - Training & Validation Acc.', fontsize=16, weight='bold')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss', color='cyan')\nplt.plot(val_loss, label='Validation Loss', color='purple')\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='upper right', fontsize=13)\nplt.ylabel('Cross Entropy', fontsize=16, weight='bold')\nplt.title('Heart Disease (CNN) - Training & Validation Loss', fontsize=16, weight='bold')\nplt.xlabel('Epoch', fontsize=15, weight='bold')\nplt.show()","73c29859":"from sklearn.metrics import classification_report\n\nY_pred_c = model_cnn.predict(X_test)\ny_pred_c = np.round(Y_pred_c).astype(int)\n\nprint(classification_report(y_test, y_pred_c))","ba27350e":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred_c)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(10, 10))\nplot_confusion_matrix(cnf_matrix, classes=['0', '1'], normalize=True, title='Normalized Confusion Matrix - CNN')\nplt.show()","f266c94b":"model_svc = SVC(random_state=42) \nmodel_svc.fit(X_train, y_train)\nscore_svc = model_svc.score(X_test, y_test)\nprint(\"SVC Score: %.4f\" % score_svc)","84462541":"model_lr = LogisticRegression(solver='liblinear', random_state=42) \nmodel_lr.fit(X_train, y_train)\nscore_lr = model_lr.score(X_test, y_test)\nprint(\"LR Score: %.4f\" % score_lr)","5c29e5ab":"model_dt = DecisionTreeClassifier(random_state=42) \nmodel_dt.fit(X_train, y_train)\nscore_dt = model_dt.score(X_test, y_test)\nprint(\"DT Score: %.4f\" % score_dt)","cc134625":"model_rf = RandomForestClassifier(n_estimators=150, random_state=42) \nmodel_rf.fit(X_train, y_train)\nscore_rf = model_rf.score(X_test, y_test)\nprint(\"RF Score: %.4f\" % score_rf)","bd79f9f6":"cnn_dnn = 0.85\n\nx = np.array(['DNN', 'CNN', 'SVC', 'LR', 'DT', 'RF'])\ny = np.array([cnn_dnn, cnn_dnn, score_svc, score_lr ,score_dt, score_rf])\n\nplt.scatter(x, y)\nplt.show()","c33aa2b7":"## **SVC**","99265cb7":"## **DNN**\n* **Hidden Layers: Dense --> (8-16-8)**\n* **Activated by the ReLU function**\n* **Dropout rate of 20%**\n","5897d00a":"## **CNN Classification Report & Conf. Matrix**","81cf3e70":"## **Decision Tree**","ff5bfdb1":"## **DNN Classification Report & Conf. Matrix**","b854745a":"## **Random Forest**","6d57ede0":"# **Conclusion**\n### **Given the performances, we can conclude that ALL models perform the same.**\n### **HOWEVER, I FEEL SOMETHING IS OFF AND I MIGHT EXPLORE A BIT MORE LATER**\n","cace2507":"## **Logistic Regression**","c7f5ca28":"# **Model Building**\n**Here, We will build two architectures:**\n* **DNN**\n* **CNN (Conv1D)**\n---\n**Hyperparameter for both models:**  \n* **Adam Optimizer**\n* ***'binary_crossentropy'* loss function**\n* **Final layer activated by Sigmoid**\n* **Metrics: Accuracy -- Feel free to add *'AUC'* if you want**\n* ***'binary_crossentropy'* loss function**\n* **Early Stopping on *'val_loss'* with a patience of 3**","d4ad6515":"# **Imports**","18cc72b2":"# **Data Preparation & Basic EDA**","cbd2a8ec":"## **CNN**\n* **Conv1D --> 16-32-16**\n* **Activated by the ReLU function**\n* **MaxPooling1D, Pool size of 1**\n* **A *Flatten* layer followd by a Dropout rate of 30%**"}}