{"cell_type":{"1bb025b8":"code","e0bf9a30":"code","8eae29ca":"code","38d88694":"code","0be2d17b":"code","aa6a2e57":"code","5654f378":"code","9ee6e2d0":"code","781daefc":"code","b49ce407":"code","78473441":"code","c7a17d4d":"code","054ac983":"code","30a606c9":"code","f715cfd5":"code","4dcf3453":"code","d4649ed3":"code","628c6343":"code","4e1d4cc1":"code","43dc4f46":"code","f3088d6d":"code","6340bec7":"code","53642cf3":"code","426a1daf":"code","417735a7":"code","029c4355":"code","d0227595":"code","9f5f972c":"code","682210d2":"code","4c32bdd7":"code","c553593e":"code","4bb39b36":"code","c9563f25":"markdown","2f90e07d":"markdown","cc8e47c3":"markdown","05f3d8c0":"markdown","f5b4803e":"markdown","9b567ddb":"markdown","48943bfd":"markdown","31453648":"markdown","0e923646":"markdown","777fd2aa":"markdown","cfdd6548":"markdown","30feb842":"markdown","525cc8b0":"markdown","32b228fa":"markdown","aa918820":"markdown","7410aaa5":"markdown","7e408ea2":"markdown","d047e76a":"markdown","03e4d216":"markdown","e3eb1a53":"markdown","0f05c3bd":"markdown","beb5bc07":"markdown","9aadec6f":"markdown","d5d48bc1":"markdown","4139985b":"markdown","8f9b5a7b":"markdown","960b2963":"markdown","946998a1":"markdown","7c639f08":"markdown","46c9dcf6":"markdown","135c7404":"markdown","dc1406bb":"markdown","02c562f8":"markdown","7f3959e6":"markdown","2aa2a1d4":"markdown","63292447":"markdown","919d765b":"markdown"},"source":{"1bb025b8":"# workspace prep \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline","e0bf9a30":"# import data & look at data\nplay = pd.read_csv('..\/input\/NFL-Punt-Analytics-Competition\/play_information.csv')\nplayer_role =pd.read_csv(\"..\/input\/NFL-Punt-Analytics-Competition\/play_player_role_data.csv\") \nplayer = pd.read_csv('..\/input\/NFL-Punt-Analytics-Competition\/player_punt_data.csv')","8eae29ca":"# data quality check\ndfs = ([play, player_role, player])\n\nfor df in dfs:\n    \n    print(\"dataframe information\")\n    nan_count = df.apply(lambda x: x.count(), axis=0)\n    if sum(nan_count) == len(df)*len(df.columns):\n        print('No Missing Values')\n    elif nan_count != len(df):\n        print(nan_count)\n    \n    print(df.shape)\n    print(df.info())\n    print(df.head())","38d88694":"# join on proper keys - no missing data\n# first two on GSISID\n# then on GameKey and PlayID to get the full data set for each player    \nfull_players = player.merge(player_role, left_on='GSISID',right_on='GSISID',how = 'left')\nfull_set = full_players.merge(play, left_on=['GameKey','PlayID'],\n                              right_on = ['GameKey','PlayID'],\n                              how = 'left')\nprint(full_set.info())\nprint(full_set.isna().sum())\nfull_set.head()","0be2d17b":"#drop the null values\ndf=full_set.dropna()","aa6a2e57":"# need to split the score column and also the home and away column into 4 \n# diff columns \ndf['Home_Team_Visit_Team'] = df['Home_Team_Visit_Team'].astype(str)\ndf['Score_Home_Visiting'] = df['Score_Home_Visiting'].astype(str)","5654f378":"# splits\ndf=df.join(df['Home_Team_Visit_Team'].str.split('-', 1, expand=True).rename(columns={0:'Home',1:'Away'}))\ndf=df.join(df['Score_Home_Visiting'].str.split(' - ', 1, expand=True).rename(columns={0:'Home_score',1:'Away_score'}))\n\n# Date\ndf[\"Game_Date\"] = pd.to_datetime(df[\"Game_Date\"], format = '%m\/%d\/%Y')\n\n# drop columns that were split\ndf = df.drop(['Home_Team_Visit_Team'], axis = 1)\ndf = df.drop(['Score_Home_Visiting'], axis = 1)","9ee6e2d0":"df.head()","781daefc":"# Extract key information from the Play Description string variable using re\ndf['PlayDescription'] = df['PlayDescription'].astype(str)\n\n# punt length \nimport re \npunt_length = []\nfor row in df['PlayDescription']:\n    match = re.search('punts (\\d+)', row)\n    if match:\n        punt_length.append(match.group(1))\n    elif match is None:\n        punt_length.append(0)\n        \n# return length\nreturn_length = []\nfor row in df['PlayDescription']:\n    match = re.search('for (\\d+)', row)\n    if match:\n        return_length.append(match.group(1))\n    elif match is None:\n        return_length.append(0)\n            \n# fair catch\nfair_catch = []\nfor row in df['PlayDescription']:\n    match = re.search('fair catch', row)\n    if match:\n        fair_catch.append(1)\n    elif match is None:\n        fair_catch.append(0)\n\n# injury\ninjury = []\nfor row in df['PlayDescription']:\n    match = re.search('injured', row)\n    if match:\n        injury.append(1)\n    elif match is None:\n            injury.append(0)\n\n# penalty         \npenalty = []\nfor row in df['PlayDescription']:\n    if 'Penalty' in row.split():\n        penalty.append(1)\n    elif 'PENALTY' in row.split():\n        penalty.append(1)\n    elif 'Penalty' not in row.split():\n        penalty.append(0)\n    elif 'PENALTY' not in row.split():\n        penalty.append(0)\n        \n\n# downed\ndowned = []\nfor row in df['PlayDescription']:\n    match = re.search('downed', row)\n    if match:\n        downed.append(1)\n    elif match is None:\n        downed.append(0)\n\n# fumble\nfumble = []\nfor row in df['PlayDescription']:\n    match = re.search('FUMBLES', row)\n    if match:\n        fumble.append(1)\n    elif match is None:\n        fumble.append(0)\n\n# muff\nmuff = []\nfor row in df['PlayDescription']:\n    match = re.search('MUFFS', row)\n    if match:\n        muff.append(1)\n    elif match is None:\n        muff.append(0)\n\n# Touchback\ntouchback = []\nfor row in df['PlayDescription']:\n    match = re.search('Touchback', row)\n    if match:\n        touchback.append(1)\n    elif match is None:\n        touchback.append(0)\n\n# Touchdown\ntouchdown = []\nfor row in df['PlayDescription']:\n    match = re.search('TOUCHDOWN', row)\n    if match:\n        touchdown.append(1)\n    elif match is None:\n        touchdown.append(0)\n\n# add new columns to the df \ndf[\"punt_length\"] = punt_length\ndf[\"return_length\"] = return_length\ndf[\"fair_catch\"] = fair_catch\ndf[\"injury\"] = injury\ndf[\"penalty\"] = penalty\ndf[\"downed\"] = downed\ndf[\"fumble\"] = fumble\ndf['muff'] = muff\ndf['touchback'] = touchback\ndf['touchdown'] = touchdown","b49ce407":"df.head()","78473441":"import feather\ndf_final = feather.read_dataframe('..\/input\/feathered-ngs\/ngs.feather')","c7a17d4d":"print(df_final.shape)\ndf_final.head()","054ac983":"new_df = df.merge(df_final.drop_duplicates(subset=['GSISID','GameKey','PlayID']), how='left',\n                  left_on=['GSISID','GameKey','PlayID','Season_Year_x'], right_on = ['GSISID','GameKey','PlayID','Season_Year'])\ndel df_final","30a606c9":"new_df.head()","f715cfd5":"# game data\ngame = pd.read_csv('..\/input\/NFL-Punt-Analytics-Competition\/game_data.csv')\n\ngame_with_new = new_df.merge(game, how = 'left', left_on = \"GameKey\", \n                             right_on = \"GameKey\")\n# columns to keep \nkeep = ['GSISID', 'Number', 'Position','Season_Year_x', 'GameKey', 'PlayID',\n       'Role', 'Game_Date_x', 'Week_x',\n       'Game_Clock', 'YardLine', 'Quarter', 'Play_Type', 'Poss_Team',\n       'Home', 'Away', 'Home_score', 'Away_score',\n       'punt_length', 'return_length', 'fair_catch', 'injury', 'penalty',\n       'downed', 'fumble', 'muff', 'touchback','touchdown','x',\n       'y', 'dis', 'o', 'dir', 'Event', 'Season_Type_y',\n       'Game_Day', 'Game_Site', 'Start_Time',\n       'Home_Team', 'Visit_Team', 'Stadium',\n       'StadiumType', 'Turf', 'GameWeather', 'Temperature', 'OutdoorWeather'\n       ]\ndf_clean = game_with_new[keep]\ndel game_with_new\n\n# rename columns\nheaders = ['GSISID', 'Number', 'Position', 'Season_Year','Season_Year_x', 'GameKey', 'PlayID',\n       'Role', 'Game_Date', 'Week',\n       'Game_Clock', 'YardLine', 'Quarter', 'Play_Type', 'Poss_Team',\n       'Home', 'Away', 'Home_score', 'Away_score',\n       'punt_length', 'return_length', 'fair_catch', 'injury', 'penalty',\n       'downed', 'fumble', 'muff', 'touchback','touchdown','x',\n       'y', 'dis', 'o', 'dir', 'Event', 'Season_Type',\n       'Game_Day', 'Game_Site', 'Start_Time',\n       'Home_Team', 'Visit_Team', 'Stadium',\n       'StadiumType', 'Turf', 'GameWeather', 'Temperature', 'OutdoorWeather'\n       ]\ndf_clean.columns = headers","4dcf3453":"print(df_clean.dtypes)\ndf_clean[[\"punt_length\", \"return_length\"]] = df_clean[[\"punt_length\", \"return_length\"]].apply(pd.to_numeric)\ndf_clean = df_clean.drop(columns='Season_Year_x')\ndf_clean.head()","d4649ed3":"# lets look at how many games and punts there are \ngames = len(df_clean['GameKey'].unique().tolist())\nprint('There are ' + str(games) + ' games in the dataset.')\npunts = len(df_clean['PlayID'].unique().tolist())\nprint('There are ' + str(punts) + ' punts in the dataset.')\nprint('On average, there are ' + str(punts\/games) + ' punts per game.')","628c6343":"# let's start with the injury field\nno_injuries = df_clean.loc[df_clean['injury'] == 0]\ninjuries = df_clean.loc[df_clean['injury'] == 1]","4e1d4cc1":"# average function \ndef avg(lst):\n    return sum(lst)\/len(lst)\n\n# Number of injuries\nprint('There are ' + str(len(injuries['PlayID'].unique().tolist())) + ' injuries in the dataset.')\n\n# lets look at the average punt length and return lenth for both new dfs\nprint('The average punt length for a play with an injury is ' + str(avg(injuries['punt_length'].unique().tolist())))\nprint('The average punt length for a play without an injury is ' + str(avg(no_injuries['punt_length'].unique().tolist())))\nprint('The average punt return for a play with an injury is ' + str(avg(injuries['return_length'].unique().tolist())))\nprint('The average punt return for a play without an injury is ' + str(avg(no_injuries['return_length'].unique().tolist())))","43dc4f46":"#injuries by gameday\ntotal_injuries = injuries.groupby('Game_Day')['PlayID'].nunique()\ntotal_no_injuries = no_injuries.groupby('Game_Day')['PlayID'].nunique()\nprint('On Fridays, injuires occured on ' + str(3\/203) + ' percent of punt plays.')\nprint('On Mondays, injuires occured on ' + str(4\/312) + ' percent of punt plays.')\nprint('On Saturdays, injuires occured on ' + str(7\/602) + ' percent of punt plays.')\nprint('On Sundays, injuires occured on ' + str(56\/2648) + ' percent of punt plays.')\nprint('On Thursdays, injuires occured on ' + str(16\/871) + ' percent of punt plays.')","f3088d6d":"# injuries by game site\ninjuries.groupby('Game_Site')['PlayID'].nunique().plot(kind='bar',figsize=(18, 16))\nplt.xlabel('Week')\nplt.ylabel('Injuries')\nplt.title('Injuries per Location')\nplt.show()","6340bec7":"# injuries by season year\ninjuries.groupby('Season_Year')['PlayID'].nunique().plot(kind='bar',figsize=(12, 10))\nplt.xlabel('Year')\nplt.ylabel('Injuries')\nplt.title('Injuries (2016-2017)')\nplt.show()","53642cf3":"# injuries by muff\ndata = injuries.groupby('muff')['PlayID'].nunique().plot(kind='bar', figsize=(12, 10))\nplt.xlabel('muff')\nplt.ylabel('Injuries')\nplt.title('Injuries on Muffs')\nplt.show()","426a1daf":"# injuries by fumble\ndata = injuries.groupby('fumble')['PlayID'].nunique().plot(kind='bar', figsize=(12, 10))\nplt.xlabel('Fumble')\nplt.ylabel('Injuries')\nplt.title('Injuries on Fumbles')\nplt.show()","417735a7":"# injuries by touchdown\ndata = injuries.groupby('touchdown')['PlayID'].nunique().plot(kind='bar',figsize=(12, 10))\nplt.xlabel('Touchdowns')\nplt.ylabel('Injuries')\nplt.title('Injuries on Touchdowns')\nplt.show()\n","029c4355":"# injuries by week\ndata = injuries.groupby('Week')['PlayID'].nunique().plot(kind='bar',figsize=(18, 16))\nplt.xlabel('Week')\nplt.ylabel('Injuries')\nplt.title('Injuries per Week')\nplt.show()","d0227595":"# injuries by quarter\ninjuries.groupby('Quarter')['PlayID'].nunique().plot(kind='bar',figsize=(12, 10))\nplt.xlabel('Week')\nplt.ylabel('Injuries')\nplt.title('Injuries per Quarter')\nplt.show()","9f5f972c":"# injuries per season type\ninjuries.groupby('Season_Type')['PlayID'].nunique().plot(kind='bar', figsize=(12, 10))\nplt.xlabel('Season Type')\nplt.ylabel('Injuries')\nplt.title('Injuries in Pre, Post, and Regular Season Games')\nplt.show()","682210d2":"# lets look at teams who have the most injuries\nfig, axes = plt.subplots(nrows=1, ncols=2, sharey = True)\n\ninjuries.groupby('Home')['PlayID'].nunique().plot(figsize=(18, 16),ax=axes[0],kind='bar')\nplt.ylabel('Injuries')\nplt.suptitle('Frequency of Injuries by Home (Left) and Away (Right)')\ninjuries.groupby('Away')['PlayID'].nunique().plot(figsize=(18, 16),ax=axes[1],kind='bar')\nplt.show()","4c32bdd7":"# lets look at punt length\ncols = ['GameKey', 'PlayID','punt_length','injury']\npunt_length = df_clean[cols]\npunt_length = punt_length.drop_duplicates()\n\n# histogram for punt length on injuires\nfig, axes = plt.subplots(nrows=1, ncols=2)\n\npunt_length['punt_length'].loc[punt_length['injury']==1].plot(ax=axes[0],kind='hist', bins = 10, color = 'red', edgecolor = 'black', figsize=(18, 16))\npunt_length['punt_length'].loc[punt_length['injury']==0].plot(ax=axes[1],kind='hist', bins = 10, edgecolor = 'black', figsize=(18, 16))\nplt.suptitle('Frequency of Injuries (Red) and Non-Injuries (Blue) by Return length')\nplt.show()","c553593e":"# same process for return length\ncols = ['GameKey', 'PlayID','return_length','injury']\nreturn_length= df_clean[cols]\nreturn_length= return_length.drop_duplicates()\n\n# histogram for return length on injuires\nfig, axes = plt.subplots(nrows=1, ncols=2)\n\nreturn_length['return_length'].loc[return_length['injury']==1].plot(ax=axes[0],kind='hist', bins = 15, color = 'red', edgecolor='black',figsize=(18, 16))\nreturn_length['return_length'].loc[return_length['injury']==0].plot(ax=axes[1],kind='hist', bins = 15, edgecolor='black',figsize=(18, 16))\nplt.suptitle('Frequency of Injuries (Red) and Non-Injuries (Blue) by Return length')\nplt.show()","4bb39b36":"# injuries by fair catch\ninjuries.groupby('fair_catch')['PlayID'].nunique().plot(kind='bar', figsize=(12, 10))\nplt.xlabel('Fair Catch')\nplt.ylabel('Injuries')\nplt.title('Injuries on Fair Catches')\nplt.show()","c9563f25":"## Conclusion ","2f90e07d":"With those few lines of code, we now have more data than we did before that we can isolate and begin working with. Let's do the same for Play Description to get dummy variables and numerical variables for punt length, return length, fair catch, injury, penatly, a downed punt, fumbles, muffed punts, touchdowns, and touchbacks. This will allow for us to have the most amount of data possible for analysis later on. We can do this using a combination of for loops, regular expression, and basic string selection in Python. ","cc8e47c3":"It seems we were corrent, most injures are happening directly after the returner begins the return process.","05f3d8c0":"Next, we need to check our data quality. Missing values and other data imperfections can prove to be quite the pain.","f5b4803e":"Let's now do some quick but fun bar charts and histograms to wrap up.","9b567ddb":"We now have a data set that gives us in depth looks at every play a player was out for a punt for the last two years. We can now begin to subset this data based on injuries and begin to gain some insights to injuries on punt plays in the NFL.","48943bfd":"The difference between the average punt return lengths for plays with and without injuries is jarring. This is likely due to the returner being stopped abruptly by the coverage team with a bone-crushing tackle.","31453648":"Week 5 has more injuries than any other week during both seasons. This deserves further analysis.","0e923646":"6 points don't seem to be a cause for injury.","777fd2aa":"We now have two differnt data set that contain injury plays and none injury plays and the data for each player on the field. We will need to be careful when doing aggregation to use unique vales when appropriate. We can need to quickly define an avergae function for lists since .nunique() will be returning lists.","cfdd6548":"Now we can drop the null values to ensure data quality.","30feb842":"As we saw earlier Miami Gardens has a high number of injuries and we now see that most of those injuries are suffered by the home team, the Dolphins :\/","525cc8b0":"I wanted to try and make the biggest and most informational dataset using the NGS and play information provided in this competition. Using pandas, matplotlib, and some regular expressions, I attempted to extract as much data form the PlayDescription field as I could and join this new table with more data provided through NGS analysis tables. Hopefully it proves to be helpful. Enjoy.","32b228fa":"First, let's get our data in here.","aa918820":"## Injury Exploration","7410aaa5":"We are beginning to see the power of proper joining, giving us a very insightful data set. We are not done yet though. Let do some final touches and trim down the columns.","7e408ea2":"As the game carries on, injuries begin to happen more. This can be attributed to several different factors. As the game wears on player's become tired, fatigued and often crucial plays are made by these world class athletes on coverage teams resulting big hits.","d047e76a":"## Working with Play Description","03e4d216":"There are more regular season games through the year, therefore seeing most injuires occuring in the regular season makes sense. That pregame number looks high and probably deserves further analysis.","e3eb1a53":"On fumble plays, the focus shifts from the player to the ball on the ground, therefore decreasing injuries dramatically.","0f05c3bd":"We can now split the comlums we turned into strings into seperate variables using string split, and we can also quickly change the date format.","beb5bc07":"I wanted to make this new dataset as robust and informational as possible so it seemed right to add the corresponding NGS data as well. Due to the sheer size of all the data, I used this amazing and helpful [kernal](http:\/\/www.kaggle.com\/kmader\/convert-to-feather-for-use-in-other-kernels\/) by the great [Kevin Mader](http:\/\/www.kaggle.com\/kmader). Using Apache Feather by the Pandas Father Wes McKinney, the NGS data file is cut nearly into a quarter of its original size, reducing its impact on the disk when read in by pandas, allowing for the kernal to survive the import. The NGS file contains all the NGS data as the serperate files share column names, making the concat process seamless.","9aadec6f":"Further analysis is needed but it seems that most of the injuries that are taking place on punt plays are happening during the regular season, late in the game, on punts of rougly 50-55 yards, immedately after the returner catches the ball and starts the return process. I will post another kernal if time permits of my analysis of the video data provided as well. I hope you enjoyed this analysis.","d5d48bc1":"Miami Garden seems to be a pretty rough place to play or the Dolphins are getting it doen on special teams. This probably deserves more analysis.","4139985b":"Let's take a peak at the data we just loaded in.","8f9b5a7b":"Lots of data there but we will soon trim it down. Let's do some joining with pandas again.","960b2963":"## More Joining using the feathered data file","946998a1":"Great! Seems we were provided with some high quality data. Let's move on. Next, we will conduct some simple joins using the all powerful pandas package. Using the unique fields og GSISID, GameKey, and PlayID, we can create a very imformative data set from which we can gain some insights on the injuries during punt plays.  ","7c639f08":"## Cheers!","46c9dcf6":"Muffs do not seem to be a cause of injury.","135c7404":"Even with increased awareness of player safety, there were more injuries in 2017 than 2016.","dc1406bb":"# **Data Exploration, Extraction, and Visualization using Pandas, RE, and Matplotlib**","02c562f8":"We see that most of the innjuries happen right around the 50-55 yard range. This is likely due to the fact that punts of this length give sufficent time for theplayers on the coverage team to cover the play properly, and deliver blows to the punt returner almost immediately. Punts of this length also allow for the returner to sometimes return the ball if blocked correctly, leading to blindside hits and more opportunites for coverage players to deliver blows as well.","7f3959e6":"Concurrent with our prior analysis of punt length, it seems that most of the injuries take place almost immedately after the return process begins. Let's double check with a quick bar graph of fair catches just to be certain.","2aa2a1d4":"While Sunday is the most represented day in the data set, it still seems the odds of being hurt on a punt play on Sunday are still the highest. Keep your head on a swivel!","63292447":"Take a look at your new and imporved dataframe, ready to tell the full story about each player for every punt play provided in the data.","919d765b":"Since I wanted to work with the text in the certain columns, some coloumns need to become strings to do so."}}