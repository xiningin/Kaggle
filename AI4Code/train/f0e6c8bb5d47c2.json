{"cell_type":{"e047c414":"code","87b53925":"code","5adcf63a":"code","42f36d82":"code","df9cc8a5":"markdown","89f10c07":"markdown","6355c1a2":"markdown","a46e75e2":"markdown","30a37143":"markdown","e5e5d5f7":"markdown","637787c9":"markdown"},"source":{"e047c414":"import cv2\n\n#Init Camera\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    ret,frame = cap.read()\n        gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n    if ret==False:\n        continue \n\n        cv2.imshow(\"Video Frame\",frame)\n        cv2.imshow(\"Gray Frame\" ,gray_frame)\n\n    key_pressed = cv2.waitKey(1) & 0xFF\n    if key_pressed == ord('q'):\n        break\n\n\ncap.release()\ncv2.destroyAllWindows()","87b53925":"import cv2\n#Init Camera\ncap = cv2.VideoCapture(0)\n\n# Face Detection\nface_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n\nwhile True:\n    ret,frame = cap.read()\n    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n    if ret==False:\n        continue\n    faces = face_cascade.detectMultiScale(frame,1.3,5)\n    print(faces)\n    for (x,y,w,h) in faces:\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n        cv2.rectangle(gray_frame,(x,y),(x+w,y+h),(0,255,255),2)\n\n    cv2.imshow(\"Video Frame\",frame)\n    cv2.imshow(\"Gray Frame\" ,gray_frame)\n\n    key_pressed = cv2.waitKey(1) & 0xFF\n    if key_pressed == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n","5adcf63a":"import cv2\nimport numpy as np\n\n#Init Camera\ncap = cv2.VideoCapture(0)\n\n# Face Detection\nface_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n\nskip = 0\nface_data = []\ndataset_path = '.\/image_data\/'\nfile_name = input(\"Enter the name of the person : \")\nwhile True:\n    ret,frame = cap.read()\n\n    if ret==False:\n        continue\n\n\n    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n\n\n    faces = face_cascade.detectMultiScale(frame,1.3,5)\n    if len(faces)==0:\n        continue\n\n    faces = sorted(faces,key=lambda f:f[2]*f[3])\n\n    # Pick the last face (because it is the largest face acc to area(f[2]*f[3]))\n    for face in faces[-1:]:\n        x,y,w,h = face\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n\n\n\n    #Extract (Crop out the required face) : Region of Interest\n    offset = 10\n    face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n    face_section = cv2.resize(face_section,(100,100))\n\n    skip += 1\n    if skip%10==0:\n        face_data.append(face_section)\n        print(len(face_data))\n\n\n    cv2.imshow(\"Frame\",frame)\n    cv2.imshow(\"Face Section\",face_section)\n\n    key_pressed = cv2.waitKey(1) & 0xFF\n    if key_pressed == ord('q'):\n        break\n\n# Convert our face list array into a numpy array\nface_data = np.asarray(face_data)\nface_data = face_data.reshape((face_data.shape[0],-1))\nprint(face_data.shape)\n\n# Save this data into file system\nnp.save(dataset_path+file_name+'.npy',face_data)\nprint(\"Data Successfully save at \"+dataset_path+file_name+'.npy')\n\ncap.release()\ncv2.destroyAllWindows()","42f36d82":"import cv2\nimport numpy as np \nimport os \n\ndef distance(v1, v2):\n    # Eucledian \n    return np.sqrt(((v1-v2)**2).sum())\n\ndef knn(train, test, k=5):\n    dist = []\n\n    for i in range(train.shape[0]):\n        # Get the vector and label\n        ix = train[i, :-1]\n        iy = train[i, -1]\n        # Compute the distance from test point\n        d = distance(test, ix)\n        dist.append([d, iy])\n    # Sort based on distance and get top k\n    dk = sorted(dist, key=lambda x: x[0])[:k]\n    # Retrieve only the labels\n    labels = np.array(dk)[:, -1]\n\n    # Get frequencies of each label\n    output = np.unique(labels, return_counts=True)\n    # Find max frequency and corresponding label\n    index = np.argmax(output[1])\n    return output[0][index]\n\n\n#Init Camera\ncap = cv2.VideoCapture(0)\n\n# Face Detection\nface_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n\nskip = 0\ndataset_path = '.\/image_data\/'\n\nface_data = [] \nlabels = []\n\nclass_id = 0 # Labels for the given file\nnames = {} #Mapping btw id - name\n\n\n# Data Preparation\nfor fx in os.listdir(dataset_path):\n    if fx.endswith('.npy'):\n       #Create a mapping btw class_id and name\n        names[class_id] = fx[:-4]\n        print(\"Loaded \"+fx)\n        data_item = np.load(dataset_path+fx)\n        face_data.append(data_item)\n\n        #Create Labels for the class\n        target = class_id*np.ones((data_item.shape[0],))\n        class_id += 1\n        labels.append(target)\n\nface_dataset = np.concatenate(face_data,axis=0)\nface_labels = np.concatenate(labels,axis=0).reshape((-1,1))\n\nprint(face_dataset.shape)\nprint(face_labels.shape)\n\ntrainset = np.concatenate((face_dataset,face_labels),axis=1)\nprint(trainset.shape)\n\n# Testing \n\nwhile True:\n    ret,frame = cap.read()\n    if ret == False:\n        continue\n\n    faces = face_cascade.detectMultiScale(frame,1.3,5)\n    if(len(faces)==0):\n        continue\n\n    for face in faces:\n        x,y,w,h = face\n\n        #Get the face ROI\n        offset = 10\n        face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n        face_section = cv2.resize(face_section,(100,100))\n\n        #Predicted Label (out)\n        out = knn(trainset,face_section.flatten())\n\n        #Display on the screen the name and rectangle around it\n        pred_name = names[int(out)]\n        cv2.putText(frame,pred_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n\n    cv2.imshow(\"Faces\",frame)\n\n    key = cv2.waitKey(1) & 0xFF\n    if key==ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()","df9cc8a5":"# Face Recognition using KNN\nWe are using KNN to work upon the dataset,that we have generated using webcam images. So the first step was reading video stream and extracting faces out of it.These faces will be used for testing purposes for which we want to predict the label.We have the test data, we will also load training data.Goal of the algorithm would be that when a new image is given, we want to extract the face and we want to see with whose face it resembles the most. ","89f10c07":"# **Face recognition using k-Nearest Neighbours Algorithm, Haarcascades Classifier & openCV for python**\n* Face recognition is all about those meaningful features from an image ,putting them into a useful representation and performing some classifications on them.\n* This is a very basic form of face recognition,because nowadays we have more improved and accurate algo like pca,hmm and deep learning algorithms.","6355c1a2":"# OpenCV-Read a video stream from webcam frame by frame\nOpencv is a library useful while we want to work with images. It is shipped as cv2.Basically we\u2019ll be using this library to read and write images and to input a video stream also.When opencv reads an image,it is an RGB image.Therefore,each image has 3 channels.So,when we read an image using opencv,opencv by default reads these channels as BGR.\n","a46e75e2":"***Detect Faces and show box over the detected faces using Haarcascade Classifier***","30a37143":"#  Haar Cascades \nIt is a pretained model used to detect faces.This is basically a machine learning based approach where a cascade function is trained from a lot of images both positive and negative. Based on the training it is then used to detect the objects in the other images.Haar Cascades uses the Ada-boost learning algorithm which selects a small number of important features from a large set to give an efficient result of classifiers then use cascading techniques to detect the face in an image.","e5e5d5f7":"**Generate Training data using webcam**\n* Read and show video stream,capture images\n* Detect faces and show bounding box \n* Flatten the largest face image(gray scale image) and save in a numpy array(storing every 10th frame)","637787c9":"# Steps\n* First we'll prepare a good database of faces with multiple images for each individual.\n* Then import the faces in the database images and use them to train the face recognizer model,which is KNN in our case.\n* Test the face recognizer to recognize faces it was trained for."}}