{"cell_type":{"b3bf1e8a":"code","18f4c8eb":"code","d5885541":"code","4e32ded1":"code","b52583bb":"code","ca130854":"code","026d45f4":"code","07ca4faf":"code","9358ac0a":"code","97f401ca":"code","2de2c2c4":"code","6428294e":"code","cb27e9db":"code","5d11b380":"code","0496aa29":"code","69a318a8":"markdown"},"source":{"b3bf1e8a":"!pip uninstall spacy -y","18f4c8eb":"!pip install -U spacy==3.1.0","d5885541":"!pip install -U allennlp\n!python -m spacy download en_core_web_sm","4e32ded1":"!python -m spacy download en_core_web_lg","b52583bb":"import json\nimport os\nimport random\nimport logging\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\n# from spacy.gold import GoldParse\n# from spacy.scorer import Scorer\nfrom sklearn.metrics import accuracy_score\nimport spacy\nprint(spacy.__version__)\nimport re\nimport random\n\nspacy.prefer_gpu()","ca130854":"def trim_entity_spans(data: list) -> list:\n    \"\"\"Removes leading and trailing white spaces from entity spans.\n\n    Args:\n        data (list): The data to be cleaned in spaCy JSON format.\n\n    Returns:\n        list: The cleaned data.\n    \"\"\"\n    invalid_span_tokens = re.compile(r'\\s')\n\n    cleaned_data = []\n    for text, annotations in data:\n        entities = annotations['entities']\n        valid_entities = []\n        for start, end, label in entities:\n            valid_start = start\n            valid_end = end\n            while valid_start < len(text) and invalid_span_tokens.match(\n                    text[valid_start]):\n                valid_start += 1\n            while valid_end > 1 and invalid_span_tokens.match(\n                    text[valid_end - 1]):\n                valid_end -= 1\n            valid_entities.append([valid_start, valid_end, label])\n        cleaned_data.append([text, {'entities': valid_entities}])\n\n    return cleaned_data\n\ndef validate_overlap(ALL_DATA):\n    for ix,x in enumerate(ALL_DATA):\n        startCK=[]\n        for iy,y in enumerate(x[-1]['entities']):\n            if iy == 0:\n                startCK.append([y[0],y[1]])\n            else:\n                pop = False \n                for z in startCK:\n                    if z[0] <= y[0] < z[1]:\n                        print(y,z)\n                        ALL_DATA[ix][-1]['entities'].pop(iy)\n                        print(ALL_DATA[ix][-1]['entities'].pop(iy))\n                        pop = True\n                        break\n                if pop == False:\n                    startCK.append([y[0],y[1]])\n    return ALL_DATA","026d45f4":"def convert_doccano_to_spacy(doccano_JSON_FilePath):\n    try:\n        training_data = []\n        lines=[]\n        with open(doccano_JSON_FilePath, 'r') as f:\n            lines = f.readlines()\n\n        for line in lines:\n            data = json.loads(line)\n            text = data['text']\n            entities = data['labels']\n            if len(entities)>0:\n                training_data.append((text, {\"entities\" : entities}))\n        return training_data\n    except Exception as e:\n        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n        return None","07ca4faf":"DATA_FILE_PATH = \"..\/input\/doccano-dummy-data\/data.json\"\nALL_DATA = convert_doccano_to_spacy(DATA_FILE_PATH)\nALL_DATA=trim_entity_spans(ALL_DATA)\nALL_DATA = validate_overlap(ALL_DATA)\nrandom.shuffle(ALL_DATA)\nprint(len(ALL_DATA))","9358ac0a":"import pandas as pd\nfrom tqdm import tqdm\nimport spacy\nfrom spacy.tokens import DocBin\n\nnlp = spacy.blank(\"en\") # load a new spacy model\ndb = DocBin() # create a DocBin object\n\nc = 0\nfor text, annot in tqdm(ALL_DATA): # data in previous format\n    doc = nlp.make_doc(text) # create doc object from text\n    ents = []\n    for start, end, label in annot[\"entities\"]: # add character indexes\n        span = doc.char_span(start, end, label=label, alignment_mode=\"strict\")\n        if span is None:\n#             print(\"======================================================Skipping entity Start===================================================\")\n#             print(start, end, label, span)\n#             print(doc.text[0:end-1],doc.text[start],doc.text[end],'kh',sep='|')\n#             print(\"======================================================Skipping entity End===================================================\")\n            s = doc.text\n            sub_E = s[end:]\n            sub_S = s[:start]\n            end = end+ (0 if len(sub_E.split(\" \", 1)[0]) <= 0 else len(sub_E.split(\" \", 1)[0]))\n            start = start - (0 if len(sub_S.rsplit(\" \", 1)[-1]) <= 0 else len(sub_S.rsplit(\" \", 1)[-1]))\n#             print(s[start:end])\n            span = doc.char_span(start, end, label=label, alignment_mode=\"strict\")\n            if span is None:\n                print(\"++++++++++++++++++++++++++++Skipping entity Start++++++++++++++++++++++++++++\")\n                print(start, end, label, span)\n                print(doc.text[start:end],doc.text[start],doc.text[end-1],'kh',sep='|')\n                print(\"++++++++++++++++++++++++++++Skipping entity End++++++++++++++++++++++++++++++\")\n                c+=1\n        else:\n            ents.append(span)\n    doc.ents = ents # label the text with the ents\n    spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n    db.add(doc)\n\ndb.to_disk(\".\/train.spacy\") # save the docbin object\nprint(c)","97f401ca":"!python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency","2de2c2c4":"%%bash\n#!\/bin\/bash\necho start: $(date \"+%y%m%d.%H%M%S.%3N\")\npython -m spacy train config.cfg --output .\/output_ --paths.train .\/train.spacy --paths.dev .\/train.spacy\necho stop:  $(date \"+%y%m%d.%H%M%S.%3N\")","6428294e":"!mkdir base_model","cb27e9db":"!python -m spacy package output_\/model-best\/ base_model\/","5d11b380":"!pip install base_model\/en_pipeline-0.0.0\/dist\/en_pipeline-0.0.0.tar.gz","0496aa29":"text = \"\"\"139 1st Street Extn,Mookambigai Nagar,M.K Kottai,Trichy-620011.\"\"\"\nnlp = spacy.load(\"en_pipeline\")\ndoc = nlp(text)\nspacy.displacy.render(doc, style=\"ent\")","69a318a8":"* This is just to demonstrate the Pipeline Workflow\n* Do not consider the Accuracy.\n* You can update the input Data\n* And based on your input data(Doccano format) follow the Transformation and packaging script."}}