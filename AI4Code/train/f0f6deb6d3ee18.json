{"cell_type":{"0f742c8d":"code","aca21fb7":"code","47791b41":"code","d6e175cd":"code","594910f9":"code","13ccc75e":"code","3b4d5d11":"code","9efcc783":"code","414dd598":"markdown","608d826e":"markdown","60cf35bf":"markdown","1963304f":"markdown","5b84ec92":"markdown","63b1d19b":"markdown","c653a868":"markdown","9d41c590":"markdown","a5caa428":"markdown"},"source":{"0f742c8d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.simplefilter('ignore')","aca21fb7":"DF = pd.read_csv(\"..\/input\/heart.csv\")\nDF_Shape = {\"Total Rows\": [len(DF.index)], \"Total Columns\": [len(DF.columns)]}\nDF_Shape = pd.DataFrame(DF_Shape,index=[\"Values\"])\nDF_Shape.transpose()","47791b41":"index = list(DF.columns)\nnew_df = pd.DataFrame(index=index)\nfor col in DF.columns:\n    new_df.at[col,'data_type'] = DF[col].dtypes\n    new_df.at[col,'null_count'] = DF[col].isnull().sum()\n    new_df.at[col,'unique_value'] = DF[col].nunique()\n    new_df.at[col,'min_value'] = DF[col].min()\n    new_df.at[col,'mean_value'] = round(DF[col].mean(),0)\n    new_df.at[col,'max_value'] = DF[col].max()\nnew_df","d6e175cd":"DF['Count'] = 1\ntarget = pd.pivot_table(DF, values='Count', index=['target'], aggfunc = np.sum).fillna(0).reset_index()\nDF.drop(['Count'], axis=1, inplace=True)\nplt.pie(target['Count'], labels=target['target'], autopct='%1.0F%%', startangle=90, explode=(0.025,0.025))\nplt.show()","594910f9":"df,Y,T,F = DF,'target',1,0\nDF4 = pd.DataFrame()\nfor col in df.columns:\n    if col != Y:\n        X = str(col)\n        data = df[[Y,X]]\n        Z = X + '_grp'\n        data[Z] = data[X]\n        data['Count'] = 1\n        table = pd.pivot_table(data, values='Count', index=[Z], columns=[Y], aggfunc=np.sum).fillna(0).reset_index()\n        table['True%'] = (table[T] \/ (table[T] + table[F]))\n        table['False%'] = (table[F] \/ (table[T] + table[F]))\n        A = Z + '_Weightage'\n        table[A] = round((table['True%']) - (table['False%']),2)\n        table2 = table.set_index(Z)\n        table2 = table2[[A]]\n        data2 = data[Z]\n        DF2 = DF.join(data2)\n        DF3 = pd.merge(DF2, table2, left_on=Z, right_index=True)\n        DF4[A] = DF3[A]\nDF4['Total_Weightage'] = 0\nDF4['Total_Weightage'] = DF4.sum(axis = 1, skipna = True)\nA_DF = DF.iloc[:,-1]\nDF5 = DF4.join(A_DF)","13ccc75e":"BenMar = DF5['Total_Weightage'].quantile(0.46)\nround(BenMar,2)","3b4d5d11":"for ix in DF5.index:\n    if DF5.at[ix,'Total_Weightage'] <= BenMar:\n        DF5.at[ix,'Pred'] = F\n    else:\n        DF5.at[ix,'Pred'] = T\nround(accuracy_score(DF5['target'],DF5['Pred']),2)","9efcc783":"x = DF.iloc[:,0:13]\ny = DF.iloc[:,len(DF.columns)-1]\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=0)\nlogreg = LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred = logreg.predict(x_test)\nround(accuracy_score(y_pred,y_test),2)","414dd598":"**Predicting the Output and checking the Accuracy Score**","608d826e":"**Reading \u201cHeart Disease UCI\u201d Data**","60cf35bf":"**Setting up a Benchmark for Prediction**","1963304f":"**Graphical representation of 1 (True or Yes) and 0 (False or No) in Target column**","5b84ec92":"**Clearly the Weighted Model has better Accuracy Score**","63b1d19b":"**Applying Logistic Regression to compare Accuracy Score**","c653a868":"**Weighted Model for Prediction**","9d41c590":"**Evaluating Data Texture and Spread**","a5caa428":"**Importing required Python Libraries**"}}