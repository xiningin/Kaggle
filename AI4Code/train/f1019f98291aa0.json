{"cell_type":{"68a703d3":"code","3110efc8":"code","aa716bdc":"code","62cf2892":"code","ceed9814":"code","33903180":"code","20d32174":"code","065f1250":"code","ecf278cc":"code","eefb4bf3":"code","ad57b9bb":"code","e6152a10":"code","4ab3a12d":"code","1a344c9b":"code","de7b2ef3":"code","167a46a5":"code","61dc52a7":"markdown","7ba126ef":"markdown","142dad59":"markdown","a8e0b0d5":"markdown"},"source":{"68a703d3":"import IPython.display as ipd \nimport librosa\nimport librosa.display\nimport pandas as pd\nimport os\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import LabelEncoder\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense , Activation , Dropout\nfrom keras.utils import np_utils\nfrom sklearn.metrics import accuracy_score","3110efc8":"# Audio files and CSV file containing metadata\nfile_path = '..\/input\/urbansound8k'\ndf = pd.read_csv('..\/input\/urbansound8k\/UrbanSound8K.csv')","aa716bdc":"#pd.set_option('display.max_rows', None)\ndf.head()","62cf2892":"# Checking class distribution of each fold\n\nappended = []\nfor i in range(1,11):\n    appended.append(df[df.fold == i]['class'].value_counts())\n\nclass_distribution = pd.DataFrame(appended)\nclass_distribution = class_distribution.reset_index()\nclass_distribution['index'] = [\"fold\"+str(x) for x in range(1,11)]\nclass_distribution","ceed9814":"# Dog Barking audio\nfname1 = '..\/input\/urbansound8k\/fold10\/30344-3-0-4.wav'  \ndata, sampling_rate = librosa.load(fname1)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Play the audio file.\nipd.Audio(fname1)","33903180":"# Children playing audio\nfname2 = '..\/input\/urbansound8k\/fold5\/100263-2-0-117.wav'  \ndata, sampling_rate = librosa.load(fname2)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Play the audio file.\nipd.Audio(fname2)","20d32174":"fold = df['fold'].to_numpy()\nfname = df['slice_file_name'].to_numpy()\ncname = df['class'].to_numpy()\ni = 300\npath1 = '..\/input\/urbansound8k\/fold' + str(fold[i]) + '\/' + fname[i]\nj = 150\npath2 = '..\/input\/urbansound8k\/fold' + str(fold[j]) + '\/' + fname[j]\ndat1, sampling_rate1 = librosa.load(path1)\ndat2, sampling_rate2 = librosa.load(path2)","065f1250":"plt.figure(figsize=(10, 4))\n# why abs ?\nD = np.abs(librosa.stft(dat1))\n# what is np.max ?\nS_db = librosa.amplitude_to_db(D, ref=np.max) \nlibrosa.display.specshow(S_db, x_axis='time', y_axis='log')\nplt.colorbar(format='%+2.0f dB')\nplt.title(f'Power spectrogram: {cname[i]}')","ecf278cc":"plt.figure(figsize=(10, 4))\nD = np.abs(librosa.stft(dat2))\nS_db = librosa.amplitude_to_db(D, ref=np.max) \nlibrosa.display.specshow(S_db, x_axis='time', y_axis='log')\nplt.colorbar(format='%+2.0f dB')\nplt.title(f'Power spectrogram: {cname[j]}')","eefb4bf3":"# Feature extraction using librosa\n\ndef features_extract(file):\n    # load the audio file\n    audio,sample_rate = librosa.load(file_name,res_type='kaiser_fast')\n    \n    # extract the features\n    feature = librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n    feature_norm = (feature - feature.mean())\/feature.std()\n    \n    # feature scaling\n    scaled_feature = np.mean(feature_norm.T,axis=0)\n    \n    # return the scaled features\n    return scaled_feature\n\n# list containg all the features\nextracted = []\n\n# for each row in the csv\nfor index_num,row in tqdm(df.iterrows()):\n    \n    # get the file \n    file_name = os.path.join(os.path.abspath(file_path),'fold'+str(row[\"fold\"])+'\/',str(row['slice_file_name']))\n    \n    # get file label\n    final_class_labels = row['class']\n    \n    # extract feature\n    data= features_extract(file_name)\n    \n    # store it in a list\n    extracted.append([data,final_class_labels])","ad57b9bb":"# Creating DataFrame from the extracted features:\ndf_extracted = pd.DataFrame(extracted,columns=['feature','label'])\n\n# Adding 'fold' column to new DataFrame which contains extracted feature and label\ndf_extracted['fold'] = df['fold']\ndf_extracted.head()","e6152a10":"le = LabelEncoder()\ny = np.array(df_extracted.label.tolist())\n\nfilter_size = 3\ny = np_utils.to_categorical(le.fit_transform(y))\n\nnum_labels = y.shape[1]\n\n# build model\nmodel = Sequential()\nmodel.add(Dense(512, input_shape=(40,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128))\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=['accuracy'],\n)\nmodel.summary()","4ab3a12d":"predicted = []\nactual = []\n\n# Taking 1 fold for Validation and rest 9 folds for train sets.\n# Using for loop so that each fold becomes validation set once and rest 9 as train set.\n\nfor i in range(1,11):\n    validation_data = df_extracted[df_extracted['fold'] == i]\n    train_data = df_extracted[df_extracted['fold'] != i]\n    \n    x = np.array(train_data.feature.tolist())\n    y = np.array(train_data.label.tolist())\n    \n    x_val = np.array(validation_data.feature.tolist())\n    y_val = np.array(validation_data.label.tolist())\n    \n    y = np_utils.to_categorical(le.fit_transform(y))\n    y_val = np_utils.to_categorical(le.fit_transform(y_val))\n    \n    fitting = model.fit(x, y, batch_size=64, epochs=10, validation_data=(x_val, y_val), shuffle=False)\n    pred = model.predict(x_val)\n    \n    predicted.append(pred)\n    actual.append(y_val)","1a344c9b":"acc = []\nfor i in range(0,10):\n    predict_conv = np.argmax(predicted[i],axis=1)\n    actual_conv = np.argmax(actual[i],axis=1)\n    acc.append(accuracy_score(actual_conv,predict_conv))\nprint(\"Accuracy for 10 fold cross validation:\",np.mean(acc))","de7b2ef3":"# Plotting ANN Loss\n\nmetrics = fitting.history\nplt.plot(fitting.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['train_loss', 'test_loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","167a46a5":"# Plotting ANN Accuracy\n\nplt.plot(fitting.history['accuracy'], label='train_accuracy')\nplt.plot(fitting.history['val_accuracy'], label='test_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)","61dc52a7":"### Constructing ANN model:","7ba126ef":"### Pre-processing & Fitting the model:","142dad59":"### Please read 'Project Report.pdf' for detailed explanations -> https:\/\/github.com\/SanketSonu\/UrbanSound8K\/blob\/main\/Project%20Report.pdf","a8e0b0d5":"### Extracting features using Librosa"}}