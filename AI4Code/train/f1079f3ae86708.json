{"cell_type":{"7fcc8d18":"code","19930cd3":"code","8dd0a4f2":"code","a7a861bf":"code","38cea55f":"code","177f3718":"code","61e2c64c":"code","0472f8c0":"code","4afbb863":"code","a86f1052":"code","c9850d72":"code","663bccf9":"code","ff90516d":"code","b2e2ffa0":"code","ac26046c":"code","5dec3c1d":"code","3ea51b21":"markdown","2a9d89b3":"markdown","846cf9fe":"markdown","9efde3f9":"markdown","02bdd7e9":"markdown","e2bc2563":"markdown","5b1f8b11":"markdown","ee19738f":"markdown","c6704f83":"markdown"},"source":{"7fcc8d18":"import numpy as np \nimport pandas as pd\nimport os\nimport glob\nimport re\n\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut","19930cd3":"def tryint(s):\n    try:\n        return int(s)\n    except ValueError:\n        return s\n    \ndef alphanum_key(s):\n    \"\"\" Turn a string into a list of string and number chunks.\n        \"z23a\" -> [\"z\", 23, \"a\"]\n    \"\"\"\n    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n\ndef sort_nicely(l):\n    \"\"\" Sort the given list in the way that humans expect.\n    \"\"\"\n    l.sort(key=alphanum_key)\n#source: https:\/\/nedbatchelder.com\/blog\/200712\/human_sorting.html","8dd0a4f2":"# flair_zero = sorted(glob_values, key= (lambda x:  alphanum_key(glob_values[x])))","a7a861bf":"glob_values = glob.glob(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/00001\/FLAIR\/*\")","38cea55f":"glob_values[0]","177f3718":"dicom = pydicom.read_file(glob_values[0])\ndata = dicom.pixel_array\ndata = cv2.resize(data, (256,256,)) #should edit this to be correct dimensions for dft shift","61e2c64c":"plt.imshow(data)","0472f8c0":"y = np.expand_dims(data, axis=-1)\nplt.imshow(y)\ny.shape","4afbb863":"from PIL import Image\nim = Image.fromarray(data)\nim.save(\"image.png\")\nimg = cv2.imread('image.png',0)","a86f1052":"crop_img = img[40:160, 60:200]\nplt.imshow(crop_img)","c9850d72":"# im = Image.fromarray(crop_img)\n# im.save(\"image.png\")\n# img = cv2.imread('image.png',0)\n# dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)\n# dft","663bccf9":"dft = cv2.dft(np.float32(crop_img), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft.shape #comparing sizes","ff90516d":"dft_shift = np.fft.fftshift(dft)\nmagnitude_spectrum = 20 * np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))\ndft_shift.shape #comparing sizes","b2e2ffa0":"img = cv2.resize(data, (140,120,))","ac26046c":"rows, cols = img.shape\ncrow, ccol = int(rows \/ 2), int(cols \/ 2)\n\nmask = np.ones((rows, cols, 2), np.uint8)\n# r = 80\n# center = [crow, ccol]\n# x, y = np.ogrid[:rows, :cols]\n# mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r\n# mask[mask_area] = 0\n\n\n# Circular LPF mask, center circle is 1, remaining all zeros\n# Only allows low frequency components - smooth regions\n#Can smooth out noise but blurs edges.\n#\n\"\"\"\nrows, cols = img.shape\ncrow, ccol = int(rows \/ 2), int(cols \/ 2)\nmask = np.zeros((rows, cols, 2), np.uint8)\nr = 100\ncenter = [crow, ccol]\nx, y = np.ogrid[:rows, :cols]\nmask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r\nmask[mask_area] = 1\n# Band Pass Filter - Concentric circle mask, only the points living in concentric circle are ones\nrows, cols = img.shape\ncrow, ccol = int(rows \/ 2), int(cols \/ 2)\nmask = np.zeros((rows, cols, 2), np.uint8)\nr_out = 80\nr_in = 10\ncenter = [crow, ccol]\nx, y = np.ogrid[:rows, :cols]\nmask_area = np.logical_and(((x - center[0]) ** 2 + (y - center[1]) ** 2 >= r_in ** 2),\n                           ((x - center[0]) ** 2 + (y - center[1]) ** 2 <= r_out ** 2))\nmask[mask_area] = 1\n\"\"\"\n\n\n# apply mask and inverse DFT: Multiply fourier transformed image (values)\n#with the mask values. \nfshift = dft_shift * mask #dft_shift\n\n#Get the magnitude spectrum (only for plotting purposes)\nfshift_mask_mag = 20 * np.log(cv2.magnitude(fshift[:, :, 0], fshift[:, :, 1]))\n\n#Inverse shift to shift origin back to top left.\nf_ishift = np.fft.ifftshift(fshift)\n\n#Inverse DFT to convert back to image domain from the frequency domain. \n#Will be complex numbers\nimg_back = cv2.idft(f_ishift)\n\n#Magnitude spectrum of the image domain\nimg_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])","5dec3c1d":"fig = plt.figure(figsize=(12, 12))\nax1 = fig.add_subplot(2,2,1)\nax1.imshow(img, cmap='gray')\nax1.title.set_text('Input Image')\nax2 = fig.add_subplot(2,2,2)\nax2.imshow(magnitude_spectrum, cmap='gray')\nax2.title.set_text('FFT of image')\nax3 = fig.add_subplot(2,2,3)\nax3.imshow(fshift_mask_mag, cmap='gray')\nax3.title.set_text('FFT + Mask')\nax4 = fig.add_subplot(2,2,4)\nax4.imshow(img_back, cmap='gray')\nax4.title.set_text('After inverse FFT')\nplt.show()","3ea51b21":"### This notebook acts as three things:\n* a follow along as to how to apply a fourier transform to an image(video in sources)\n* proof of concept that the principle works just fine on an mri image\n* base for moving to next notebook which will aim to glean more value from the data using the transform more explicitly in our context","2a9d89b3":"## FFT Processing Step (needs more customization for quality usage; acts as a proof of concept for now)","846cf9fe":"<center><h1>Learning and Applying the Fourier transform to the BraTS21' dataset<\/h1><\/center>\n\n## Source of Learning:\n * [Prof. Sreeni Video](https:\/\/www.youtube.com\/watch?v=9mLeVn8xzMw&ab_channel=Apeer_micro)\n * [Sreeni github](https:\/\/github.com\/bnsreenu\/python_for_image_processing_APEER\/blob\/master\/tutorial41_image_filters_using_fourier_transform_DFT.py)","9efde3f9":"hidden cell below for testing the array values with different loading method","02bdd7e9":"### resize image to work with script","e2bc2563":"hidden cell for initial attempts at more graceful sorting(need to come back to)","5b1f8b11":"## load image, resize, crop","ee19738f":"## for filtering out low frequency","c6704f83":"## plotting step"}}