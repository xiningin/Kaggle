{"cell_type":{"595d6161":"code","a4e91179":"code","0e54b20a":"code","59b5d4e0":"code","c2951782":"code","0ef6b0bd":"code","fbf84471":"code","532e724e":"code","b3a14f18":"code","755da5ed":"code","36bfc243":"code","11f66942":"code","1a17fc3f":"code","fa3fc676":"code","4e2faec8":"code","47b830be":"code","bc1af35c":"code","b8f74def":"code","2aed56cb":"code","6851d704":"code","ae0be40f":"code","063b197f":"code","a5877318":"code","e759f47a":"code","e6f33a97":"code","397a5577":"code","7e6e5653":"code","44943938":"code","b49e6ea2":"code","6c22edec":"code","e888f2bf":"code","63c1e6c5":"code","481853a1":"code","12c0e2b9":"code","d16bbc64":"code","77ce9aff":"code","74f69802":"code","36773d30":"code","8114e45e":"code","a9ac3896":"code","1f0c21a5":"code","54739489":"code","5db5d27a":"code","9c4887fc":"code","ebbc046c":"code","e2abc2e6":"code","7e09d5dc":"code","a0a6c33f":"code","36c99be6":"code","dfb94abb":"code","24726086":"code","c7a4ff63":"code","192d12ce":"code","fc43cbe4":"code","4a81b470":"code","d8f4cdb3":"code","e327622d":"code","6346770e":"code","4f559c2d":"code","440c106c":"code","f1b0c140":"code","2287f670":"code","f73d08d6":"code","79e0a57f":"code","b708d5d4":"code","154a2caa":"code","817bc3ec":"code","19b80947":"code","125e60a8":"code","26d4ef20":"code","fe81702d":"code","3dc6e964":"code","0fd00a79":"code","1017654f":"code","187b8fdd":"code","8f143383":"code","8f2d4970":"code","4db01ecb":"code","ac863798":"code","e4ca3d1d":"code","7d2954c4":"code","4e2de731":"code","35ef83a7":"code","f535561f":"code","0cf7d2b7":"code","5d4ae563":"code","4e6916d2":"code","eb368619":"code","f01b2f9c":"code","8a93234e":"code","4ebcbb06":"code","57439047":"code","42c94205":"markdown","658f61e1":"markdown","829eb7e2":"markdown","1a3399ba":"markdown","9433e09d":"markdown","46d735e6":"markdown","5f284a4d":"markdown","7ffef451":"markdown","407618b9":"markdown","c73a35b2":"markdown","e0aceac2":"markdown","d7185ecb":"markdown","1b43c52a":"markdown","97ba41c6":"markdown","fc592a3d":"markdown","6d8e6e14":"markdown","82e97e54":"markdown","4bf40775":"markdown","925f8b02":"markdown","50933109":"markdown","e0fcbcb1":"markdown","f5516e48":"markdown","b655210f":"markdown","18261d65":"markdown","4dd0146c":"markdown","9f8e9e7c":"markdown","ea6e8b80":"markdown","4b491e1c":"markdown","db36f754":"markdown","8836aa52":"markdown","4030b400":"markdown","bd4c47cc":"markdown","17b70d52":"markdown","b8f24190":"markdown","059fdd7b":"markdown","cd4a44ee":"markdown","19a0ae40":"markdown","bf7dff50":"markdown","7b882478":"markdown","5fc026fa":"markdown","55ff587f":"markdown","176a6e5b":"markdown","e67b35a0":"markdown","b3690c82":"markdown","9d8acc5a":"markdown","2da229a5":"markdown","319874d2":"markdown","4e0b4b44":"markdown","36d19ac4":"markdown","6f0aac98":"markdown","baa8b0c5":"markdown","39e7b807":"markdown","65e9b48a":"markdown"},"source":{"595d6161":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook as tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom glob import glob","a4e91179":"!ls \/kaggle\/input\/land-cover-class\/","0e54b20a":"!ls \/kaggle\/input\/land-cover-class\/train","59b5d4e0":"test_images = sorted([fn.split('\/')[-1] for fn in glob('\/kaggle\/input\/land-cover-class\/test\/*.jpg')])","c2951782":"test_images[:5]","0ef6b0bd":"len(test_images)","fbf84471":"train_df = pd.read_csv('\/kaggle\/input\/land-cover-class\/train.csv')","532e724e":"train_df.head()","b3a14f18":"train_dir = '\/kaggle\/input\/land-cover-class\/train\/'\ntest_dir = '\/kaggle\/input\/land-cover-class\/test\/'\nimg = plt.imread(f'{train_dir}1.jpg')","755da5ed":"img.shape","36bfc243":"img","11f66942":"plt.imshow(img); train_df['class'][0]","1a17fc3f":"classes = sorted(train_df['class'].unique())\nclasses","fa3fc676":"fig, axs = plt.subplots(3, 4, figsize=(15, 12))\nrand_idxs = np.random.randint(1, len(train_df)+1, 9)\nfor c, ax in zip(classes, axs.flat):\n    fn = train_df[train_df['class'] == c].sample().iloc[0]['fn']\n    img = plt.imread(f'{train_dir}\/{fn}')\n    ax.imshow(img)\n    ax.set_title(c)\nfor ax in axs.flat:\n    ax.set_axis_off()\nplt.tight_layout()","4e2faec8":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, rescale=1.\/255)\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)","47b830be":"train_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    directory=train_dir,\n    batch_size=32,\n    x_col='fn',\n    y_col='class',\n    target_size=(64, 64), \n    subset='training'\n)\n\nvalid_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    directory=train_dir,\n    batch_size=32,\n    x_col='fn',\n    y_col='class',\n    target_size=(64, 64), \n    subset='validation'\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory='\/kaggle\/input\/land-cover-class\/',\n    classes=['test'],\n    batch_size=32,\n    target_size=(64, 64), \n    shuffle=False\n)","bc1af35c":"X, y = train_generator[0]","b8f74def":"X.shape, y.shape","2aed56cb":"train_generator.class_indices","6851d704":"y[:3]","ae0be40f":"p = np.random.rand(10) * 10\nplt.bar(np.arange(10), p);","063b197f":"p.sum()","a5877318":"pp = p \/ p.sum()","e759f47a":"pp","e6f33a97":"pp.sum()","397a5577":"pexp = np.exp(p)\nplt.bar(np.arange(10), pexp);","7e6e5653":"def softmax(a):\n    return np.exp(a) \/ np.exp(a).sum()","44943938":"p = softmax(p)\np.sum()","b49e6ea2":"plt.bar(np.arange(10), p);","6c22edec":"y[0], p","e888f2bf":"plt.bar(np.arange(10), p)\nplt.bar(np.arange(10), y[0], zorder=0.5);","63c1e6c5":"a = np.linspace(0, 1, 100)\ntrue = 1","481853a1":"loss = - true * np.log(a)","12c0e2b9":"plt.plot(a, loss);","d16bbc64":"(- y[0] * np.log(p)).sum()","77ce9aff":"model = tf.keras.Sequential([\n    Input(shape=(64, 64, 3)),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(256, activation='relu'),\n    Dense(128, activation='relu'),\n    Dense(10, activation='softmax'),\n])","74f69802":"model.summary()","36773d30":"model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])","8114e45e":"model.fit(train_generator, epochs=3, validation_data=valid_generator)","a9ac3896":"model.fit(train_generator, epochs=3, validation_data=valid_generator)","1f0c21a5":"preds = model.predict(X)","54739489":"i=2\nplt.bar(np.arange(10), preds[i], alpha=0.5)\nplt.bar(np.arange(10), y[i], alpha=0.5);","5db5d27a":"(X, _), _ = tf.keras.datasets.mnist.load_data()","9c4887fc":"X.shape","ebbc046c":"a = X[0]","e2abc2e6":"import matplotlib.patches as patches\nplt.figure(figsize=(10, 10))\nplt.imshow(a, cmap='Greys')\nrect = patches.Rectangle((7-0.5, 7-0.5),3, 3,linewidth=2,edgecolor='r',facecolor='none')\nplt.gca().add_patch(rect);","7e09d5dc":"a[7:10, 7:10]","a0a6c33f":"k = np.array([\n    [-1, 0, 1],\n    [-2, 0, 2],\n    [-1, 0, 1]\n])\nk = np.array([\n    [-1, -2, -1],\n    [0, 0, 0],\n    [1, 2, 1]\n])\nk","36c99be6":"a[7:10, 7:10] * k","dfb94abb":"(a[7:10, 7:10] * k).sum()","24726086":"b = np.zeros((28-2, 28-2))\nfor i in range(0, 28-2):\n    for j in range(0, 28-2):\n        patch = a[i: i+3, j:j+3]\n        b[i, j] = (patch * k).sum()","c7a4ff63":"plt.imshow(a, cmap='Greys');","192d12ce":"plt.imshow(b, cmap='Greys')\nplt.colorbar();","fc43cbe4":"model = tf.keras.Sequential([\n    Input(shape=(64, 64, 3)),\n    Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(10, activation=\"softmax\"),\n])","4a81b470":"model.summary()","d8f4cdb3":"model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])","e327622d":"model.fit(train_generator, epochs=3, validation_data=valid_generator)","6346770e":"model = tf.keras.Sequential([\n    Input(shape=(64, 64, 3)),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n\n    Flatten(),\n    Dense(64, activation='relu'),\n    Dense(10, activation=\"softmax\"),\n])","4f559c2d":"model.summary()","440c106c":"model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])","f1b0c140":"h = model.fit(train_generator, epochs=10, validation_data=valid_generator)","2287f670":"plt.plot(h.history['accuracy'][1:])\nplt.plot(h.history['val_accuracy'][1:])","f73d08d6":"model.optimizer.lr = 1e-4","79e0a57f":"h = model.fit(train_generator, epochs=10, validation_data=valid_generator)","b708d5d4":"plt.plot(h.history['accuracy'][1:])\nplt.plot(h.history['val_accuracy'][1:])","154a2caa":"l2 = 2e-5\nmodel = tf.keras.Sequential([\n    Input(shape=(64, 64, 3)),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2)),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2)),\n    MaxPooling2D(),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2)),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2)),\n    MaxPooling2D(),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2)),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(l2)),\n    MaxPooling2D(),\n\n    Flatten(),\n    Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-5)),\n    Dense(10, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(1e-5)),\n])","817bc3ec":"model.summary()","19b80947":"model.compile(tf.keras.optimizers.Adam(1e-3), 'categorical_crossentropy', metrics=['accuracy'])","125e60a8":"h = model.fit(train_generator, epochs=10, validation_data=valid_generator)","26d4ef20":"plt.plot(h.history['accuracy'][1:])\nplt.plot(h.history['val_accuracy'][1:])","fe81702d":"model.optimizer.lr = 1e-4","3dc6e964":"h = model.fit(train_generator, epochs=10, validation_data=valid_generator)","0fd00a79":"plt.plot(h.history['accuracy'][1:])\nplt.plot(h.history['val_accuracy'][1:])","1017654f":"model = tf.keras.Sequential([\n    Input(shape=(64, 64, 3)),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Dropout(0.25),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Dropout(0.25),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n    MaxPooling2D(),\n    Flatten(),\n    Dropout(0.25),\n    Dense(64, activation='relu'),\n    Dense(10, activation=\"softmax\"),\n])","187b8fdd":"model.summary()","8f143383":"model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])","8f2d4970":"h = model.fit(train_generator, epochs=10, validation_data=valid_generator)","4db01ecb":"plt.plot(h.history['accuracy'][1:])\nplt.plot(h.history['val_accuracy'][1:])","ac863798":"model.optimizer.lr=1e-4","e4ca3d1d":"h = model.fit(train_generator, epochs=10, validation_data=valid_generator)","7d2954c4":"plt.plot(h.history['accuracy'][1:])\nplt.plot(h.history['val_accuracy'][1:])","4e2de731":"probs = model.predict(test_generator)","35ef83a7":"probs.shape","f535561f":"probs[0]","0cf7d2b7":"preds = np.argmax(probs, 1)\npreds.shape","5d4ae563":"preds[:3]","4e6916d2":"pred_classes = [classes[i] for i in preds]","eb368619":"pred_classes[:3]","f01b2f9c":"len(test_images)","8a93234e":"def create_submission(model, test_generator, classes, test_images):\n    probs = model.predict(test_generator)\n    preds = np.argmax(probs, 1)\n    pred_classes = [classes[i] for i in preds]\n    sub =  pd.DataFrame({'fn': test_images, 'class': pred_classes})\n    return sub","4ebcbb06":"sub = create_submission(model, test_generator, classes, test_images)\nsub.to_csv('submission1.csv', index=False)","57439047":"sub.head()","42c94205":"Next, we need to convert the numbers to the actual class.","658f61e1":"## Look at images\n\nLet's take a look at some images to get a feel for the data.\n\nTo do so we can use pyplot's imread function.","829eb7e2":"The images are split into a train and test directory.","1a3399ba":"## Regularization #1: L2\n\nL2 regularization or weight decay (not technically the same but close enough) is a way to force the network to not focus too much on a few parameters. This helps distribute the weights more evenly and thereby reduces overfitting.\n\nWe need to add L2 separately to all layers with a lambda parameter. This is another hyper-parameter that we need to tune.\n","9433e09d":"## Convolutions\n\nTo understand what convolutions are, let's load some grayscale images of hand-writen numbers, a.k.a. the famous MNIST dataset.","46d735e6":"The result is actually kind of interesting. It seems to highlight horizontal edges. Let's look at the kernel again in detail and see why this is the case. We can also change the kernel to create a vertical edge detector. This is called a Sobel kernel. \n\nThese kernels are really useful. With only a handful of parameters they detect features in images. These features we can then combine to classify the image.\n\nHowever, hand-coding the kernels is really cumbersome. So why don't we learn them in a neural network. This is what a convolutional neural network is. So let's do it in Keras.","5f284a4d":"Finally we need to put the image name and the classes in a Pandas dataframe.","7ffef451":"## A bigger network\n\nSo let's train a bigger network by increasing the number of channels, the number of convolutions between each max-pooling and another fully-connected layer at the end.","407618b9":"We can see that the network get some of the probabilities right.\n\nBut the accuracy is not great for a model with 6M parameters. In fact, our approach of flattening the image and doing a brute force fully-connected apprach is kind of dumb and doesn't include any of the structures that we know images possess. \n\nTo do so, we want to use convolutions. So what are they?","c73a35b2":"Probabilities need to sum to one. Our dumb NN prediction does not do so.","e0aceac2":"## Lern the kernels\n\nTo build a CNN we simply need to replace our `Dense` layers with `Conv2D` layers. For these we have to specify the number of channels (instead of neurons) and the kernel size.\n\nAfter a few convolution\/max-pooling layers we can flatten the image again and add a final fully-connected layer with a softmax.","d7185ecb":"What we can do now is to do an elementwise product of the 3x3 area of the image and the kernel and then take the sum.","1b43c52a":"So now we have a prediction given by our softmax layer and an one-hot encoded target vector.","97ba41c6":"Now let's train the bigger model. Now is probably a good time to talk about GPUs.","fc592a3d":"### Softmax + Categorical Crossentropy\n\nWhy do we need a one-hot encoded vector? To crease a loss function for classification. \n\nThis is also time to think about why accuracy is not a suitable loss function.\n\nFirst though we need to make sure we are predicting something reasonable with our ML model. We want to predict the probability of a given sample belonging to each of our 10 classes. A standard neural network doesn't know anything about probability, so it will just predict some random numbers. Let's simulate this.","6d8e6e14":"You will notice that this network has a lot fewer parameters compared to our fully-connected network above. This is because we imposed structure on our problem by using convolutions.","82e97e54":"Combining these two is what is called a softmax layer. This layer is typically the last layer in a classification network.","4bf40775":"These are the probabilities for each test image. Now we need to pick the maximum prediction for each sample.","925f8b02":"## Classification\n\nNow we need to understand the difference between regression and classification. \n\nFirst, let's start to look at the different classes we have. We have 10 in total.","50933109":"# Convolutional neural networks - Classifying land cover\n\nOur task now is to classify which type of land use we can see from satellite images. Two things will be different now: 1) We are dealing with images, i.e. data on a 2D grid; 2) We are doing classification instead of regression. Before we tackle these two things however, we need to take a look at our new dataset.","e0fcbcb1":"So we get a much better validation score because we are overfitting less.","f5516e48":"Looks like we are getting some overfitting again. But one thing to always check is whether our learning rate is too high. Let's see what happens if we reduce our learning rate by an order of magnitude.","b655210f":"To train a neural network we need a loss function that tells us how good our prediction is. For this we will use the log-loss or the cross-entropy. Let's illustrate this for a single class for a true label.","18261d65":"Next we create two generators, one for training, one for validation.","4dd0146c":"What we have here is a one-hot-encoded vector. ","9f8e9e7c":"Se even after a few epochs we are already doing a lot better than before.","ea6e8b80":"So we definitely do better than random guessing which would give around 10% accuracy.","4b491e1c":"For X we see what we would expect: an array with shape [batch_size, img_size1, img_size2, channels]. But what about y? ","db36f754":"The cell below plots a random image from each class.","8836aa52":"Inside the train directory we have a randomly ordered list of images.","4030b400":"The dataset contains 60,000 28x28 images. Let's just pick the first one and plot it.","bd4c47cc":"So an image is nothing else but a 2D array of numbers, specifically three 2D arrays, one for each color, RGB.","17b70d52":"## Fully connected model\n\nFor starters let's just treat each images as one really long array. We can do so by flattening the image dimensions and channels. Then we can build a neural network just like we did in the prevous lesson.\n\nThe only difference is that we add a final layer with the number of classes and a softmax activation.","b8f24190":"For a convolution we need to define a kernel. This is another matrix, in this case a 3x3 matrix.","059fdd7b":"# Your turn\n\nAs always, the first task is to reproduce the key steps from this notebook: \n\n1. Open some images and look at them\n2. Create train\/valid and test generators\n3. Train a simple CNN \n4. Train a bigger CNN and try out regularization with L2 and dropout\n\nIf you are done with that, here are some further challenges. \n\n1. Try to visualize the images for which the networks gets wrong predictions. Would humans also have made this mistake?\n2. Try to get a better score. Play around with the hyper-parameters or change the network architecture. Why not use Google to find modern CNN architectures and try those out.","cd4a44ee":"Here is a handy little function to copy-paste to your notebooks.","19a0ae40":"## Regularization #2: Dropout\n\nAnother very popular way to prevent overfitting is using dropout. This is usually only done for fully connected layers but also works for convolutional layers. In dropout we need to set a ratio of neurons to be randomly dropped for each batch. Let's just add one layer with a 25% dropout.","bf7dff50":"The number typically go from 0 to 255. Let's plot one on the images and pront the land use class.","7b882478":"So immediately we jump to a higher accuracy. At the beginning of training high learning rates are good to get close to the minima but after that lower learning rates might be required to get into the minima. Eventually we don't want to change our learning rate manually, but rather use a learning rate schedule. \n\n**Always check if your learning rate is too high!**\n\n\nStill we have encountered our old enemy again: overfitting. We already know how to use early stopping to prevent overfitting. But there are some additional techniques that are sometimes helpful: L2 regularization (weight decay) and Dropout.","5fc026fa":"Now we can do this for every 3x3 patch of the image. To do so (in a dumb way) we just need two loops. We end up with another image with almost the same size than the original image.","55ff587f":"The `train.csv` file assigns a land use class to each training image.","176a6e5b":"Dropout also works :) ","e67b35a0":"Then let's see what we get in our y vector.","b3690c82":"Now we have a loss function that is differentiable. Which means we can use it to train a neural network. So let's do some classification.","9d8acc5a":"Then we use `categorical_crossentropy` as our loss function. But the cross-entropy is hard to interpret, so in addition we will preint out the accuracy during training.","2da229a5":"So for a true label, the best prediction (lowest error) is predicting 1. Predicting zero gives the largest error. For a zero label the error would always be zero.\n\nFor several classes we can just sum up the loss over all classes. But of course, the only non-zero values come from the classes where the target is True.","319874d2":"## Read the data\n\nTo use the images in a neural network, we will use Keras' `ImageDataGenerator` class. This has several advantages over just reading all the images and putting them into a Numpy array. \n\nWe will randomly split our data into training (80%) and validation (20%) and rescale the images by dividing by 255.","4e0b4b44":"A Python generator can be called similar to a list by just indexing into it. Let's pick the first batch of data.","36d19ac4":"So the first thing we need to do is normalize our predictions to sum to one.","6f0aac98":"## Create submission\n\nNow let's submit out results to Kaggle. ","baa8b0c5":"Next, we know that in our target only one value will be one, while all the others will be zero. So let's find a way to make larger predictions large and small predictions smaller. One way to do so is taking exp of all values.","39e7b807":"The images are pretty low resolution (64x64), so it's actually quite hard to so what's going on sometimes :D\n\nTo get a better feel for the data, let's plot a bunch of images.","65e9b48a":"I already highlighted a 3x3 are of the image which as we know is nothing else than a 3x3 matrix of numbers."}}