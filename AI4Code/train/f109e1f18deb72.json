{"cell_type":{"e1b1e816":"code","26e0eda3":"code","2cd7387c":"code","cf03d1f4":"code","2d25cd17":"code","471d4c2a":"code","a16c64aa":"code","588bf37d":"code","63ac8e6c":"code","cc13a78f":"code","96e3fbd2":"code","01ea9f76":"code","bb605c2b":"code","82abe878":"code","82ecd0da":"code","fdce7a71":"code","3ad821c9":"code","f298ce5d":"code","0a29ce82":"code","52524cc9":"code","93d24bda":"code","3b4973d6":"code","c0d746b2":"code","3651f8aa":"code","e1202e9a":"code","25e20891":"code","c6581f7c":"code","ace37b4a":"code","68b6510c":"code","1281ce3e":"code","99ce5455":"code","a0e081a6":"code","17a326b9":"code","c44278ef":"code","b6930320":"code","8e7d9b2d":"code","87ff7177":"markdown","2c9509d0":"markdown","a3af2fbb":"markdown"},"source":{"e1b1e816":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport time\nimport glob\nfrom PIL import Image\n\nimport torchvision\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nimport torch.optim as optim\n\nfrom sklearn.model_selection import train_test_split\n\nprint(os.listdir(\"..\/input\"))","26e0eda3":"random.seed( 42 )","2cd7387c":"use_gpu = torch.cuda.device_count() > 0\nprint(\"{} GPU's available:\".format(torch.cuda.device_count()) )","cf03d1f4":"base_dir = '..\/input'\ntrain_image_dir = os.path.join(base_dir, 'train')\ntest_image_dir = os.path.join(base_dir, 'test')","2d25cd17":"df_train = pd.read_csv(base_dir + '\/train.csv')\ndf_test = pd.DataFrame()","471d4c2a":"test_image_dir","a16c64aa":"df_train['path'] = df_train['Id'].map(lambda x: os.path.join(train_image_dir, '{}_green.png'.format(x)))\ndf_train['target_list'] = df_train['Target'].map(lambda x: [int(a) for a in x.split(' ')])\n\ndf_test['path'] = glob.glob(os.path.join(test_image_dir, '*.png'))","588bf37d":"df_train.head()","63ac8e6c":"X = df_train['path'].values\ny = df_train['target_list'].values\n\nX_test = df_test['path'].values","cc13a78f":"class CellsDataset(Dataset):\n\n    def __init__(self, X, y=None, transforms=None, nb_organelle=28):\n        \n        self.nb_organelle = nb_organelle\n        self.transform = transforms \n        self.X = X\n        self.y = y\n            \n    def open_rgby(self, path2data): #a function that reads RGBY image\n        \n        Id = path2data.split('\/')[-1].split('_')[0]\n        basedir = '\/'.join(path2data.split('\/')[:-1])\n        \n        images = np.zeros(shape=(512,512,3))\n        colors = ['red','green','blue']\n        for i, c in enumerate(colors):\n            images[:,:,i] = np.asarray(Image.open(basedir + '\/' + Id + '_' + c + \".png\"))\n        \n            yellow_ch = np.asarray(Image.open(basedir + '\/' + Id + '_yellow.png'))\n            images[:,:,0] += (yellow_ch\/2).astype(np.uint8) \n            images[:,:,1] += (yellow_ch\/2).astype(np.uint8)\n\n        \n        return images.astype(np.uint8)\n    \n    def __getitem__(self, index):\n        \n        path2img = self.X[index]\n        image = self.open_rgby(path2img)\n\n        if self.y is None:\n            labels =np.zeros(self.nb_organelle,dtype=np.int)\n        else:\n            label = np.eye(self.nb_organelle,dtype=np.float)[self.y[index]].sum(axis=0)\n        \n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n    def __len__(self):\n        return len(self.X)","96e3fbd2":"class AdjustGamma(object):\n    def __call__(self, img):\n        return transforms.functional.adjust_gamma(img, 0.8, gain=1)","01ea9f76":"class AdjustContrast(object):\n    def __call__(self, img):\n        return transforms.functional.adjust_contrast(img, 2)","bb605c2b":"class AdjustBrightness(object):\n    def __call__(self, img):\n        return transforms.functional.adjust_brightness(img, 2)","82abe878":"imagenet_mean = np.array([0.485, 0.456, 0.406])\nimagenet_std  = np.array([0.229, 0.224, 0.225])\n\ndef denormalize(image, mean=imagenet_mean, std=imagenet_std):\n    inp = image.transpose((1, 2, 0))\n    img = std * inp + mean\n    return img","82ecd0da":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.ToPILImage(), # because the input dtype is numpy.ndarray\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        AdjustGamma(),\n        AdjustContrast(),\n        ##AdjustBrightness(),\n        transforms.ToTensor(),\n        transforms.Normalize(imagenet_mean, imagenet_std),\n    ]),\n    'test': transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(imagenet_mean, imagenet_std),\n    ]),\n}","fdce7a71":"X_train, X_valid, y_train, y_valid = train_test_split(\n     X, y, test_size=0.2, random_state=42)","3ad821c9":"dsets = {\n    'train': CellsDataset(X_train, y_train, transforms=data_transforms['train']),\n    'valid': CellsDataset(X_valid, y_valid, transforms=data_transforms['test']),\n    'test':  CellsDataset(X_test, None,  transforms=data_transforms['test']),\n}","f298ce5d":"batch_size = 32\nrandom_seed = 3\nvalid_size = 0.2\nshuffle = True","0a29ce82":"def create_dataLoader(dsets, batch_size, shuffle=False, pin_memory=False):\n    \n    dset_loaders = {} \n    for key in dsets.keys():\n        if key == 'test':\n            dset_loaders[key] = DataLoader(dsets[key], batch_size=batch_size, pin_memory=pin_memory, shuffle=False)\n        else:\n            dset_loaders[key] = DataLoader(dsets[key], batch_size=batch_size, pin_memory=pin_memory, shuffle=True)\n    return dset_loaders","52524cc9":"dset_loaders = create_dataLoader(dsets, batch_size, shuffle, pin_memory=False)","93d24bda":"dset_loaders.keys()","3b4973d6":"def plot_organelles(dset_loaders, is_train = True, preds_test = [], preds_train = []):\n    \n    X, y = next(iter(dset_loaders))\n    X, y = X.numpy(), y.numpy()\n    \n    plt.figure(figsize=(20,10))\n    for i in range(0, 4):\n        plt.subplot(1,4,i+1)\n        rand_img = random.randrange(0, X.shape[0])\n        img = denormalize(X[rand_img,:,:,:])\n        img = np.clip(img, 0, 1.0)    \n        plt.imshow(img)\n        plt.axis('off')","c0d746b2":"image, label = next(iter(dset_loaders['train']))\nprint(image.size(), label.size())","3651f8aa":"plot_organelles(dset_loaders['train'])","e1202e9a":"class MyDenseNetConv(torch.nn.Module):\n    def __init__(self, fixed_extractor = True):\n        super(MyDenseNetConv,self).__init__()\n        original_model = torchvision.models.densenet161(pretrained=True)\n        self.features = torch.nn.Sequential(*list(original_model.children())[:-1])\n        \n        if fixed_extractor:\n            for param in self.parameters():\n                param.requires_grad = False\n\n    def forward(self, x):\n        x = self.features(x)\n        x = F.relu(x, inplace=True)\n        x = F.avg_pool2d(x, kernel_size=7).view(x.size(0), -1)\n        return x\n\nclass MyDenseNetDens(torch.nn.Module):\n    def __init__(self, nb_out=28):\n        super().__init__()\n        self.dens1 = torch.nn.Linear(in_features=2208, out_features=512)\n        self.dens2 = torch.nn.Linear(in_features=512, out_features=128)\n        self.dens3 = torch.nn.Linear(in_features=128, out_features=nb_out)\n        \n    def forward(self, x):\n        x = self.dens1(x)\n        x = torch.nn.functional.selu(x)\n        x = F.dropout(x, p=0.25, training=self.training)\n        x = self.dens2(x)\n        x = torch.nn.functional.selu(x)\n        x = F.dropout(x, p=0.25, training=self.training)\n        x = self.dens3(x)\n        return x\n\nclass MyDenseNet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mrnc = MyDenseNetConv()\n        self.mrnd = MyDenseNetDens()\n    def forward(self, x):\n        x = self.mrnc(x)\n        x = self.mrnd(x)\n        return x ","25e20891":"model = MyDenseNet()","c6581f7c":"if use_gpu:\n    print(\"Using all GPU's \")\n    model = torch.nn.DataParallel(model)\n    model.cuda()\n    convnet = model.module.mrnc\nelse:\n    convnet = model.mrnc\n    print(\"Using CPU's\")","ace37b4a":"def predict(dset_loaders, model,use_gpu=False):\n    \n    predictions = []\n    labels_lst = []\n\n    ii_n = len(dset_loaders)\n    start_time = time.time()\n\n    for i, (inputs, labels) in enumerate(dset_loaders):\n                   \n        if use_gpu:\n          inputs = inputs.cuda()\n          labels = labels.cuda()\n\n        inputs = Variable(inputs)\n        labels = Variable(labels)\n\n        predictions.append(model(inputs).data)\n        labels_lst.append(labels)\n        \n        print('\\rpredict: {}\/{}'.format(i, ii_n - 1), end='')\n    print(' ok')\n    print('Execution time {0:.2f} s'.format(round(time.time()- start_time), 2))\n    if len(predictions) > 0:\n        return {'pred': torch.cat(predictions, 0), 'true': torch.cat(labels_lst, 0) }","68b6510c":"#extract features from images\n#convOutput_train = predict(dset_loaders['train'], convnet,use_gpu=use_gpu)\nconvOutput_valid = predict(dset_loaders['valid'], convnet,use_gpu=use_gpu)\n#convOutput_test = predict(dset_loaders['test'], convnet,use_gpu=use_gpu)","1281ce3e":"#print(convOutput_train['true'].size(), convOutput_train['pred'].size())\nprint(convOutput_valid['true'].size(), convOutput_valid['pred'].size())\n#print(convOutput_test['true'].size(), convOutput_test['pred'].size())","99ce5455":"print(convOutput_valid['true'].type(), convOutput_valid['pred'].type())","a0e081a6":"model_name = 'MyDenseNet'","17a326b9":"sav_feats= {\n    #'train': (convOutput_train['pred'], convOutput_train['true'], model_name),\n    'valid': (convOutput_valid['pred'], convOutput_valid['true'], model_name),\n    #'test': (convOutput_test['pred'], convOutput_test['true'], model_name)\n}","c44278ef":"def save_prediction(path2data,convOutput):\n    \n    for key in convOutput.keys():\n        if convOutput[key][0].is_cuda: \n            data ={'true':convOutput[key][0].cpu().numpy(),\n                   'pred':convOutput[key][1].cpu().numpy()}\n        else:\n            data ={'true':convOutput[key][0].numpy(),\n                   'pred':convOutput[key][1].numpy()}\n        if not os.path.exists(path2data + key):\n            os.makedirs(path2data + key)\n        \n        print('\\nSaving '+convOutput[key][2]+' '+ key) \n        np.savez(path2data+key+\"\/\"+convOutput[key][2]+\".npz\",**data)\n        print('Saved in:'+path2data+key+\"\/\"+convOutput[key][2]+\".npz\")","b6930320":"save_prediction('..\/results\/', sav_feats)","8e7d9b2d":"!cd ..\/results\/ && ls .","87ff7177":" - Now it is possible to use any other kind of model to perform the multilabel classification","2c9509d0":"**Saving features**","a3af2fbb":"**Extracting the features**"}}