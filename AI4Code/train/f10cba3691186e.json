{"cell_type":{"fa7e9e0d":"code","b6a7b0dc":"code","a419cc29":"code","bff9fe64":"code","d7473440":"code","f6888a42":"code","9dd0847b":"code","0b992fef":"code","c8b68d05":"code","7bb51df7":"code","4a83e0f7":"code","4ef80f24":"code","9fb13245":"code","d11c93eb":"code","c8dbc141":"code","c0d64915":"code","a3a8ed82":"code","3dac08ca":"code","8100b04f":"code","0e0bf9ef":"code","cb23f9a7":"code","b475b8cb":"code","efc98b1e":"markdown","4e63ad32":"markdown","46ce24a6":"markdown","a185e785":"markdown","0af80a96":"markdown","ff44c42d":"markdown","30890959":"markdown","ad35a316":"markdown","f8026dbf":"markdown","b81e59f9":"markdown","fc2114cc":"markdown","ae1e6c90":"markdown","925cbe02":"markdown","f5195f01":"markdown","361bb6b8":"markdown","ec89e3e6":"markdown","b61424c8":"markdown","2003cb6b":"markdown","8ce10839":"markdown","d0113c5d":"markdown"},"source":{"fa7e9e0d":"!pip install pulp","b6a7b0dc":"import os\nimport urllib.request as ur\nimport zipfile\nimport math\nimport numpy as np\nimport pandas as pd\nimport geopandas as gp\nimport shapely\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport contextily\nimport pulp","a419cc29":"df = pd.read_csv(\"\/kaggle\/input\/montcoalert\/911.csv\")\ndf.info()","bff9fe64":"df.head(3)","d7473440":"df_clean = df.copy() # copy df\ndf_clean = df_clean.loc[:,[\"lat\",\"lng\", \"title\", \"timeStamp\"]]\n\n# convert to datetime\ndf_clean.timeStamp = pd.to_datetime(df_clean.timeStamp)\n\n# parse the title\ndf_title = df_clean.title.str.extract(r'(?P<eventType>.+):\\s*(?P<eventDetail>.+)')\ndf_title = df_title.apply(lambda x: x.astype('category'), axis=0)\n\n# append new cols and drop title\ndf_clean = pd.concat([df_clean.loc[:,[\"lat\",\"lng\", \"timeStamp\"]], df_title],axis=1)\ndf_clean.info()","f6888a42":"# check number of NAs per column\nprint(\"NAs per column\")\ndisplay(df_clean.apply(lambda x: x.isna().sum(), axis=0))\n\n# check number of distinct values per column\nprint(\"nunique per column\")\ndisplay(df_clean.apply(lambda x: len(x.unique()), axis=0))","9dd0847b":"# filter out irrelevant eventType\ndf_ems = df_clean[df_clean.eventType=='EMS']\ndf_ems.info()","0b992fef":"plt.figure(figsize=(10, 5))\n_ = df_ems.eventDetail.value_counts().head(10).plot.barh()\n_.set_xlabel(\"n\")\n_.invert_yaxis();","c8b68d05":"plt.figure(figsize=(10, 5))\n_ = df_ems.timeStamp.dt.date.value_counts().sort_index().plot()\n_.set_xlabel(\"time\")\n_.set_ylabel(\"n\");","7bb51df7":"# geospatial data\nworld = gp.read_file(gp.datasets.get_path('naturalearth_lowres'))\ngdf = gp.GeoDataFrame(df_ems.loc[:,[\"timeStamp\",\"eventDetail\"]],\n        geometry=[shapely.geometry.Point(x, y) for x, y in zip(df_ems.lng, df_ems.lat)])\ngdf.crs = {'init': 'epsg:4326'}\n#world.crs\n\n# spatial outliers?\nax = world.plot(color='white', edgecolor='black', figsize=(15, 10))\ngdf.plot(ax=ax, color='red', markersize=7.5);","4a83e0f7":"# get county shapes\nif not os.path.exists('shape\/'):\n    sh_file = ur.URLopener()\n    u = \"https:\/\/www2.census.gov\/geo\/tiger\/TIGER2016\/COUNTY\/tl_2016_us_county.zip\"\n    sh_file.retrieve(u, \"shape.zip\")\n    shz_file = zipfile.ZipFile(\"shape.zip\")\n    shz_file.extractall(path=\"shape\")\n    shz_file.close()\n    os.remove(\"shape.zip\")\n\nfilenames = [y for y in sorted(os.listdir(\"shape\/\"))\n                 for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)] \ndbf, prj, shp, shx = [filename for filename in filenames]\ncounty = gp.read_file(\"shape\/\"+shp)\n#county.crs\n\n# build montco polygon\nmontco = county[county.NAMELSAD==\"Montgomery County\"].unary_union","4ef80f24":"# aggregate the observations\ndf = gdf.copy()\ndf['x'] = np.round(df.geometry.x\/0.025)*0.025\ndf['y'] = np.round(df.geometry.y\/0.025)*0.025\ndf = df.groupby(['x', 'y'], as_index=False).\\\n        geometry.count().rename({'geometry':'weight'}, axis=1)\n\ndf = gp.GeoDataFrame(df,\n        geometry=[shapely.geometry.Point(x, y) for x, y in zip(df.x, df.y)])\n\ndf.crs = {'init': 'epsg:4326'}\ndf.info()","9fb13245":"# get montco points\nwithin_vec = df.geometry.within(montco)\ndf = df.loc[np.logical_and(within_vec,df.x>-80),:]\ntot_inc_served = df.weight.sum()\ndf.shape","d11c93eb":"point_1 = gdf.geometry[0]\npoint_2 = gdf.geometry[1]\n\ndef get_manhattan(p1, p2):\n    \"\"\"calculate manhattan from point lat+lng \n    args>\n    p1, p2 - shapely.geometry.Point objects    \n    returns>\n    distance, scalar\"\"\"\n    \n    e_circ = 40075  \n    distance = e_circ*(math.fabs(p1.x-p2.x) +\n                       math.fabs(p1.y-p2.y))\/360 \n    return distance\n\nget_manhattan(point_1, point_2)","c8dbc141":"# remap vars\nincidents = df.geometry\nweights = df.weight\nfacilities = df.geometry\ninc_i = incidents.index\nfac_i = facilities.index\n\n# initialize object\nos.chdir(\"\/\")\nmodel = pulp.LpProblem(\"CFLModel\", pulp.LpMinimize)\n\n# initialize facility vector\nf_vec = pulp.LpVariable.dict(\"f_vec\",\n            [j for j in fac_i], cat=\"Binary\")\n\n# initialize binary variable for incident-facility mapping\nif_mat = pulp.LpVariable.dicts(\"if_mat\",\n            [(i,j) for i in inc_i for j in fac_i], cat=\"Binary\")\n\n# objective function - weighted manhattan sum\nmodel += (pulp.lpSum([get_manhattan(incidents.loc[i],\n            facilities.loc[j]) * weights[i] * if_mat[(i,j)] \n            for i in inc_i for j in fac_i]))\n\n# every incident must be served\nfor i in inc_i:\n    model += pulp.lpSum(if_mat[(i, j)] for j in fac_i)==1\n    \n# every incident mapped to facility, given facility must exists\nfor i in inc_i:\n    for j in fac_i:\n        model += if_mat[(i, j)] <= f_vec[j]\n\n# we are limited to 5 facilities\nmodel += pulp.lpSum(f_vec[j] for j in fac_i)==5\n\n# facilities can serve incidents within limited capacity\nfor j in fac_i:\n    model += pulp.lpSum(if_mat[(i, j)] * weights[i] for i in inc_i)\\\n        <=np.round(1.05*tot_inc_served\/5,0)","c0d64915":"# try to solve it\nmodel.solve()\n\nprint(\"Solving the model results in **{}** status and objective function of {}.\".\\\n    format(pulp.LpStatus[model.status].lower(), np.round(pulp.value(model.objective),2)))","a3a8ed82":"fac_loc = pd.DataFrame(index=[j for j in fac_i if f_vec[j].varValue==1])\ncust_loc = pd.DataFrame([{'fac_id':j } for i in inc_i\n                for j in fac_i if if_mat[(i,j)].varValue==1], index=inc_i)\n\nfor i in range(fac_loc.shape[0]):\n    print(\"Suitable coordinates for facility {} are lat: {}, lng: {}.\".\\\n        format(i,facilities[fac_loc.index[i]].y, facilities[fac_loc.index[i]].x))","3dac08ca":"cols = ['#f032e6', '#000075', '#ffe119', '#e6194B', '#3cb44b']\ndict_cols = dict(zip(fac_loc.index, cols))\ninc_cols = cust_loc.fac_id.map(dict_cols)\nfac_cols = fac_loc.index.map(dict_cols)\n\n# plot out incidents\nax = incidents.to_crs(epsg=3857).plot(\n    color=inc_cols, markersize=weights\/75,\n    alpha=.5,figsize=(15, 10))\n\n# plot out facilities\nfacilities[fac_loc.index].to_crs(epsg=3857).plot(\n    color=fac_cols, markersize=200, marker=\"D\", ax=ax)\n\n# add contextily tiles\ncontextily.add_basemap(ax, zoom=11,\n    source=contextily.providers.Stamen.TonerLite)\nax.set_axis_off()","8100b04f":"# get data about shadow prices and slack\nconst_df = pd.DataFrame([{'con_name':name,\n                          'shadow_price':c.pi,\n                          'slack_value':c.slack}\n                         for name, c in model.constraints.items()])\n\nconst_df.shadow_price.value_counts().sort_index()","0e0bf9ef":"const_df.slack_value.value_counts().sort_index()","cb23f9a7":"const_df.sort_values('slack_value', ascending=False).head(3)","b475b8cb":"str(model.constraints['_C44944'])[-285:]","efc98b1e":"There are ~ 660k rows & 9 columns.\n\nThe coordinates of distress events are in `lat` and `lng` cols, loaded as `float64`; required precision might be discussed later. The `desc` col denotes details - responding crew?, township, responding station, and timestamp, the values are loaded as `object` and require parsing. The  `zip` is loaded as `float64`, even though discrete. Approx 10 % of its values are missing. The `title` col encodes the type of response and nature of the call; it is loaded as an `object` and needs parsing. The `timeStamp` col describes the date and time of the call, loaded as an object, and needs to be coerced to a proper data type. The `twp` stands for the township; it is loaded as an `object` and might be transformed into the `cat` type. The `addr` col represents the address, and it is introduced as an `object`. The last feature `e` is loaded as `int64` and is 1 for all observations; hence will be omitted.","4e63ad32":"The most common incidents are `FALL VICTIM`, `RESPIRATORY EMERGENCY`, and `CARDIAC EMERGENCY`.","46ce24a6":"# Housekeepin'","a185e785":"From the printout above, we understand that most of the conditions are bounded (slack is equal to 0); hence change in these conditions leads to a different solution. Let us take a look at one of the conditions with the highest slack.","0af80a96":"# What's Next?\n\nAs presented in the previous section, we find a suitable solution for the capacitated facility location problem. However, the solution is somewhat limited. In this section, we describe some of the difficulties & further steps.\n\n**Problem definition** - we might align the solution with the real-world a bit more. Different objective functions can be applied to reflect on that (average time to location\/maximum distance traveled\/...). Moreover, the feasibility region can be narrowed with further details (time\/capacity\/location constraints).\n\n**Data** - we build the model on the raster representation (not precise) & use every incident location as a potential facility location (not necessarily good). Both choices might be improved with prior information. Moreover, boundary problems are expected (e.g., there are calls and hospitals adjacent to Montgomery County, which are not acknowledged).\n\n**Sensitivity analysis** - at the end of the CFL, we examine selected components of the model, one at a time; this part of the study can be more thorough. To further challenge our solution, we can do simulations while adding noise to the data\/constraints and analyzing the results, leading to better insights.\n\n> Martin Fridrich 08\/2019","ff44c42d":"## Solution","30890959":"## Data Transformation\n\nFirstly, we aggregate observations on rounded coordinates to improve the optimization speed, resulting in a significantly smaller dataset while not losing the precision (~ 5 km). Geometries are then reconstructed to be combined with `montco` polygon.","ad35a316":"# Exploratory Data Analysis\n\nOver the next code chunks, we focus on a brief examination of EMS calls, specifically on frequent incident types, trends, and geospatial properties.","f8026dbf":"## Further Analysis","b81e59f9":"> Martin Fridrich 08\/2019\n\n**The task:** Evil zombies have destroyed all central rescue stations in the city. The state has statistics where emergency problems occurred in last year (data above) and they are not sure whether the emergency stations were placed efficiently. Note that ambulances were sent only to EMS problems. Therefore, they asked us to find places where they should build 5 (of the same size) emergency stations. What will their position be?\n\nThus, we aim to find suitable locations for five emergency facilities based on historical data with linear programming. The notebook is organized as follows:\n\n* Housekeepin',\n* Data Processing,\n* Exploratory Data Analysis,\n* Capacitated Facility Location Problem,\n* What's Next?","fc2114cc":"This is the constraint (4), describing facility location index 401. Slack identified here is not entirely useful, as this particular location is not amongst the selected ones.","ae1e6c90":"# Capacitated Facility Location Problem","925cbe02":"The figure presents the optimization results and serves as a sanity check. We depict the facilities as large diamond markers; serviced areas share the color; the size of the incident\/location points depends on the incident frequency. \n\nWe can see that there is a larger, probably rural, region with a lower density of events in the upper-left part of the figure. Other areas appear to be more compact, serving areas with a higher density of the events.","f5195f01":"There is somewhat linear trend, with the significant drop in 2020 caused by the pandemic. With different level of aggregation, we might see some other interesting pattern. However, it is not the goal of the endevour.","361bb6b8":"\n## Problem Formulation\n\nNow, it is time to formulate the CFLP. Let us have a binary variable $x_{ij}$, for all $i = 1, ..., m$ and for all $j = 1, ..., n$ , where $m$ stands for a number of incident locations and $n$ represents a number of facilities. If $x_{ij} = 1$, than incident $i$ is served from facility $j$, otherwise $x_{ij} = 0 $. Let us have another binary variable $y_{j}$ , for all $j = 1, ..., n$, where $n$ represents the number of facilities. If $y_{j} = 1$, than the facility is open, otherwise $y_{j} = 0$. Now we define cost variables, $d_{ij}$ presents manhattan distance between incident $i$ and facility $j$, $w_{i}$ then shows a number of incidents in location $i$.\n\nWe introduce the problem in the following manner.\n\n**Objective function:** \n\n$min \\sum_{i=1}^{m} \\sum_{j=1}^{n} d_{ij} w_{i} x_{ij}$\n\n**Constraints:** \n\n$(1)\\space\\space\\sum_{i=1}^{m} x_{ij} = 1, \\forall i = 1, ..., m$  \n$(2)\\space\\space\\sum_{i=1}^{m} x_{ij} = 1, \\forall i = 1, ..., m$  \n$(3)\\space\\space\\space x_{ij} \\leq y_{j}, \\forall i = 1, ..., m, j = 1, ..., n$  \n$(4)\\space\\space\\sum_{j=1}^{n} y_{j} = facility\\_limit$  \n$(5)\\space\\space\\sum_{i=1}^{m} x_{ij} w_{i} \\leq capacity\\_limit,\\forall j = 1, ..., n$  \n\nThe objective function minimizes the sum of the weighted distance between incidents and facilities. Constraint (1) ensure that every incident location is served; constraint (2) ensures that if incident $x_{ij}$ is served from facility $y_{j}$, that facility exists; constraint (3) limits the number of facilities that can be opened; the constraint (4) limits capacities, we arbitrarily chose the limit.","ec89e3e6":"There does not appear to be a possibility of improving the objective function.","b61424c8":"# Data Processing\n\nWe identify the most critical columns and ensure features are in proper data types. The resulting dataset will contain only EMS distress calls and the variables: `lat`, `lng`, `timeStamp`, `eventType`, `eventDetail`.","2003cb6b":"The status suggests that the solution is found and all constraints are satisfied.","8ce10839":"There are multiple outlying points. To resolve that, we leverage US shapefile with borders of Montgomery County.","d0113c5d":"## Distance Function\n\nHere, we define a distance func based on the Manhattan (L1)."}}