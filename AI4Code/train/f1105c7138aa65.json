{"cell_type":{"465d5a36":"code","44bea898":"code","737f0a46":"code","ceae4b4d":"code","1d7c8fc7":"code","26d931e3":"code","5b83c329":"code","65f56f49":"code","597537c8":"code","7b1ec9dd":"code","ca0c4497":"code","0a840796":"code","665a91d9":"code","499a538d":"code","6560f3ff":"code","c3b3f26c":"code","c544a7ac":"code","1f5f02b1":"code","cb691d3f":"code","46ccf7fe":"code","9afa16f3":"code","d687fc0b":"code","cdc90da5":"code","549c9c00":"code","5c673c1f":"code","305cd17e":"code","6d9716a3":"code","4c9dc638":"code","d649751c":"code","8bbbb2dc":"code","21e0e736":"code","4b930631":"code","2602a0f3":"code","5acad947":"code","414f3461":"code","4c61efd7":"code","5f78964b":"code","6f8a41ed":"code","36243189":"markdown","30fc8719":"markdown","df582190":"markdown"},"source":{"465d5a36":"import numpy as np\nimport pandas as pd \nimport xgboost as xgb\nimport sklearn\n\nimport matplotlib.pyplot as plt\n\nfor p in [np, pd, xgb, sklearn]:\n    print (p.__name__, p.__version__)","44bea898":"from sklearn.base import TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import PredefinedSplit, cross_val_score, GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, make_scorer","737f0a46":"RANDOM_STATE = 71","ceae4b4d":"# Evaluation criterion\ndef smape(pred, actual):\n    \"\"\"\n    pred: a numpy array of predictions\n    actual: a numpy array of actual values\n    \n    for a perfectly predicted zero observation, the smape is defined to be 0. \n    \n    \"\"\"\n    \n    selector = ~((pred == 0) & (actual == 0))\n    numerator = np.abs(pred-actual)\n    denom = (np.abs(pred) + np.abs(actual)) \/ 2\n    return 100*np.sum((numerator[selector] \/ denom[selector])) \/ pred.shape[0]\n\nsmape_scorer = make_scorer(smape, greater_is_better=False)","1d7c8fc7":"# Test cases\nfor actual, pred in zip([np.array([1,4,0,5])]*3, \n                        [np.array([1,3,0,5]), np.array([0.5,4,1,6]), np.array([2,7,-1,4])]):\n    print(smape(pred, actual))","26d931e3":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/sample_submission.csv\")","5b83c329":"sample_submission.info()","65f56f49":"train.info()","597537c8":"# Convert the date field\ntrain.loc[:,'date'] = pd.to_datetime(train.date)\ntest.loc[:,'date'] = pd.to_datetime(test.date)","7b1ec9dd":"data = pd.concat([train, test], sort=False).fillna(0)   # test data has id column","ca0c4497":"def downcast_dtypes(df):\n    '''\n        Changes column types in the dataframe: \n                \n                `float64` type to `float32`\n                `int64`   type to `int32`\n    '''\n    \n    # Select columns to downcast\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n    \n    # Downcast\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols]   = df[int_cols].astype(np.int32)\n    \n    return df","0a840796":"data = downcast_dtypes(data)","665a91d9":"# Lag featurizer\nclass Lag_Featurizer(TransformerMixin):\n    def __init__(self, index_col, time_col, value_col, output_col, output_time_index=False, shift=0, freq='1D'):\n        self.index_col = index_col\n        self.time_col = time_col\n        self.value_col = value_col\n        self.output_col = output_col\n        self.output_time_index=output_time_index\n        self.shift = shift\n        self.freq = freq\n        \n    def fit(self, X):                \n        pass\n    \n    def transform(self, X):\n        assert isinstance(self.index_col, list)\n        \n        time_key = pd.Grouper(freq=self.freq)      \n        time_index = self.index_col + [time_key]\n        resampled = X.groupby(time_index)[self.value_col].sum().reset_index().set_index(self.time_col)\n        shifted= resampled.groupby(self.index_col).shift(self.shift, freq=self.freq).drop(self.index_col, axis=1).reset_index().rename(columns={self.value_col:self.output_col})\n        merged = pd.merge(X, shifted, how='left',left_on=self.index_col + [self.time_col], right_on=self.index_col + [self.time_col])\n        if self.output_time_index:\n            return merged.set_index(self.time_col)\n        else:\n            return merged","499a538d":"data = data.set_index('date')","6560f3ff":"lag_feature_pipeline = Pipeline(\n[\n    # lag store, item sales\n    ('store_item_lag_1d', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_1d', output_time_index=True, shift=1 )),\n    ('store_item_lag_2d', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_2d', output_time_index=True, shift=2 )),\n    ('store_item_lag_3d', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3d', output_time_index=True, shift=3 )),\n    ('store_item_lag_4d', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_4d', output_time_index=True, shift=4 )),\n    ('store_item_lag_1w', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_1w', output_time_index=True, shift=7 )),\n    ('store_item_lag_2w', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_2w', output_time_index=True, shift=14)),\n    ('store_item_lag_4w', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_4w', output_time_index=True, shift=28)),\n    ('store_item_lag_3m', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3m', output_time_index=True, shift=84)),\n    ('store_item_lag_6m', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_6m', output_time_index=True, shift=168)),\n    ('store_item_lag_1y', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_1y', output_time_index=True, shift=336)),\n    \n    #lag store sales\n    ('store_lag_1d', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_1d', output_time_index=True, shift=1 )),\n    ('store_lag_2d', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_2d', output_time_index=True, shift=2 )),\n    ('store_lag_3d', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3d', output_time_index=True, shift=3 )),\n    ('store_lag_4d', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_4d', output_time_index=True, shift=4 )),\n    ('store_lag_1w', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_1w', output_time_index=True, shift=7 )),\n    ('store_lag_2w', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_2w', output_time_index=True, shift=14)),\n    ('store_lag_4w', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_4w', output_time_index=True, shift=28)),\n    ('store_lag_3m', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3m', output_time_index=True, shift=84)),\n    ('store_lag_6m', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_6m', output_time_index=True, shift=168)),\n    ('store_lag_1y', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_1y', output_time_index=True, shift=336)),\n    \n    # lag item sales\n    ('item_lag_1d', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_1d', output_time_index=True, shift=1 )),\n    ('item_lag_2d', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_2d', output_time_index=True, shift=2 )),\n    ('item_lag_3d', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3d', output_time_index=True, shift=3 )),\n    ('item_lag_4d', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_4d', output_time_index=True, shift=4 )),\n    ('item_lag_1w', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_1w', output_time_index=True, shift=7 )),\n    ('item_lag_2w', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_2w', output_time_index=True, shift=14)),\n    ('item_lag_4w', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_4w', output_time_index=True, shift=28)),\n    ('item_lag_3m', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3m', output_time_index=True, shift=84)),\n    ('item_lag_6m', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_6m', output_time_index=True, shift=168)),\n    ('item_lag_1y', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_1y', output_time_index=True,shift=336))\n    \n]\n)","c3b3f26c":"data = lag_feature_pipeline.transform(data)","c544a7ac":"# drop all rows with nulls. Part of 2013 data is kept since the maximum lag is 336 days. \ndata.dropna(inplace=True)\ndata.loc[:,'weekend'] = ((data.index.weekday == 5) |  (data.index.weekday == 6)) + 0","1f5f02b1":"cols = [\n    \n    'sales',\n    \n    'sales_1d',\n    'sales_2d',\n    'sales_3d',\n    'sales_4d',\n    'sales_1w',\n    'sales_2w',\n    'sales_4w',\n    'sales_3m',\n    'sales_6m',\n    'sales_1y',\n    \n    'store_sales_1d',\n    'store_sales_2d',\n    'store_sales_3d',\n    'store_sales_4d',\n    'store_sales_1w',\n    'store_sales_2w',\n    'store_sales_4w',\n    'store_sales_3m',\n    'store_sales_6m',\n    'store_sales_1y',\n    \n    'item_sales_1d',\n    'item_sales_2d',\n    'item_sales_3d',\n    'item_sales_4d',\n    'item_sales_1w',\n    'item_sales_2w',\n    'item_sales_4w',\n    'item_sales_3m',\n    'item_sales_6m',\n    'item_sales_1y',\n    \n    'weekend'\n]","cb691d3f":"training = data.loc[:'2017-03',cols]\nvalidation_split = np.where((training.index >= pd.Timestamp(2017,1,1)) & (training.index <= pd.Timestamp(2017,3,31)), 0, -1)","46ccf7fe":"X_validation = training.loc[validation_split == 0, cols[1:]]\ny_validation = training.loc[validation_split == 0, 'sales']","9afa16f3":"# training matrices\nX_training = training.loc[:,cols[1:]]\ny_training = training.loc[:,'sales']\nprint('Number of training instances = {0:d}'.format(X_training.shape[0]))\nprint('Number of features           = {0:d}'.format(X_training.shape[1]))\nprint('Date range = {0} to {1}'.format(training.index[0].strftime('%Y-%m-%d'), training.index[-1].strftime('%Y-%m-%d')))","d687fc0b":"testing = data.loc['2018-01':,cols]\nX_testing = testing.loc[:,cols[1:]]\ny_testing = testing.loc[:,'sales']\nprint('Number of test instances = {0:d}'.format(X_testing.shape[0]))\nprint('Number of features       = {0:d}'.format(X_testing.shape[1]))\nprint('Date range = {0} to {1}'.format(testing.index[0].strftime('%Y-%m-%d'), testing.index[-1].strftime('%Y-%m-%d')))","cdc90da5":"# Lasso\nlasso = Lasso(random_state=RANDOM_STATE, max_iter=2000)\nlasso_params = {'alpha': np.logspace(-3,3,7)}","549c9c00":"reg = GridSearchCV(lasso, lasso_params, scoring=smape_scorer, n_jobs=1, cv=PredefinedSplit(validation_split), verbose=1)","5c673c1f":"reg.fit(X_training,y_training)","305cd17e":"print('Best score = {0:.4f}; Best Parameter = {1}'.format(-reg.best_score_, reg.best_params_)) # Score is the negative because large score indicates better fit","6d9716a3":"pred_validation = reg.predict(X_validation)\nprint(smape(pred_validation, y_validation.values))","4c9dc638":"fig, ax = plt.subplots(figsize=(12,12))\nax.scatter(y_validation.values, pred_validation)","d649751c":"# Refit on the entire training data\ntraining_full = data.loc[:'2017-12',cols]\nX_training_full = training_full.loc[:,cols[1:]]\ny_training_full = training_full.loc[:,'sales']\nprint('Number of training instances = {0:d}'.format(X_training_full.shape[0]))\nprint('Number of features           = {0:d}'.format(X_training_full.shape[1]))\nprint('Date range = {0} to {1}'.format(training_full.index[0].strftime('%Y-%m-%d'), training_full.index[-1].strftime('%Y-%m-%d')))","8bbbb2dc":"reg_best = reg.best_estimator_\nreg_best.fit(X_training_full, y_training_full)","21e0e736":"pred_reg_best = reg_best.predict(X_testing)","4b930631":"# Make predictions and a submission: 141.87\nsubmission_lasso = pd.DataFrame({'Id': sample_submission.id, 'sales': pred_reg_best})\nsubmission_lasso.to_csv('submission_lasso.csv', index=False)","2602a0f3":"rf = RandomForestRegressor(random_state=RANDOM_STATE, criterion='mae')","5acad947":"rf_params = {\"n_estimators\": np.arange(100, 1100, 100),\n              \"max_depth\": np.arange(3, 10, 1),\n              \"min_samples_split\": np.arange(10,150,1),\n              \"min_samples_leaf\": np.arange(5,10,1),\n              \"max_leaf_nodes\": np.arange(5,15,1)}","414f3461":"rf = GridSearchCV(rf, rf_params, scoring=smape_scorer, n_jobs=1, cv=PredefinedSplit(validation_split), verbose=10)","4c61efd7":"# rf.fit(X_training,y_training)","5f78964b":"# print('Best score = {0:.4f}; Best Parameter = {1}'.format(-rf.best_score_, rf.best_params_))","6f8a41ed":"# rf_best = rf.best_estimator_\n# rf_best.fit(X_training_full, y_training_full)\n# pred_rf_best = rf_best.predict(X_testing)\n# submission_rf = pd.DataFrame({'Id': sample_submission.id, 'sales': pred_rf_best})\n# submission_rf.to_csv('submission_rf.csv', index=False)","36243189":"#### Random Forest Model","30fc8719":"#### Add lag features\nStore-item lag sales\n\nstore lag sales\n\nitem lag sales\n\nlag periods (days): 1, 2, 3, 4, 7, 14, 21, 28,  84, 168, 336","df582190":"#### Add lag features"}}