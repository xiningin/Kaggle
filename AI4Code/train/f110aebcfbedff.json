{"cell_type":{"9d44d1b7":"code","fae00483":"code","a0ff7c33":"code","a5f1d1b0":"code","a7ec7ee3":"code","cda47357":"code","46a1d986":"code","4c95594e":"code","b655a31c":"code","740f74c4":"code","b3fa8b4c":"code","2321db5a":"code","a2b24c33":"code","e39a5d52":"code","625a5be2":"code","98d23357":"code","60810628":"code","649262b7":"code","33169072":"code","351f948c":"code","d75ae3f4":"code","635582a5":"code","8f6a1760":"code","9c762963":"code","d24e1c31":"code","83c37dc6":"code","a623fb2d":"code","429a38d7":"code","37d2e9a8":"code","57236ba5":"code","f1c16fb8":"code","e019f379":"code","75084f4c":"code","5ce6e2de":"code","54de6c16":"code","82565695":"code","924b9160":"code","cbd48f56":"code","26942f60":"code","e3b94df1":"code","68e1370f":"code","5b2b5005":"code","2ecfe171":"code","cbe8e2d5":"code","6472f4d9":"code","657ccc23":"code","e9cd9faa":"code","e2b129c6":"code","1d00976a":"code","9309eba5":"code","8c0941c2":"code","0cdcf382":"code","001aded8":"code","db30f996":"code","c24f8399":"code","c729910f":"code","46e2e3eb":"code","56c4120c":"code","2aae6a39":"code","a2e401dc":"code","5d42deb1":"code","dee4f18a":"code","ee559a46":"code","301e76e2":"code","f5bc8f18":"code","ff3f1898":"code","2a9213a3":"code","92f1d5f7":"code","2f36bcc0":"code","fbaecdba":"code","c258d0ae":"code","da059a45":"code","3cbf011a":"code","d0a90572":"markdown","437fb613":"markdown","b58af3ba":"markdown","9e6866e6":"markdown","dd20017e":"markdown","9ca7f515":"markdown","96dc3265":"markdown","4ae34ffb":"markdown","33c66163":"markdown","d1692b38":"markdown","80158e85":"markdown","831e4b60":"markdown","e11a4603":"markdown","9624dac2":"markdown","1d1863ee":"markdown","0047366d":"markdown","a4b7a66d":"markdown","e7ff7975":"markdown","c7bebcec":"markdown","6717da77":"markdown"},"source":{"9d44d1b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fae00483":"import warnings\nwarnings.filterwarnings('ignore')","a0ff7c33":"titanic = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntitanic.head()\n## checking the head of our data set","a5f1d1b0":"titanic.info()\n## checking info of all columns","a7ec7ee3":"titanic.shape\n## checking shape of data set","cda47357":"titanic.describe()\n## statistical information about numerical variable","46a1d986":"round(100*(titanic.isnull().sum()\/len(titanic)),2)\n## checking missing value percentage in all columns","4c95594e":"titanic.drop('Cabin',axis=1,inplace=True)\n## cabin almost have 77% of missing values hence remove this column from data set","b655a31c":"age_median = titanic['Age'].median(skipna=True)\ntitanic['Age'].fillna(age_median,inplace=True)\n## as there is 19% of missing values in age column hence it is not a good idea to remove this row wise or column wise hence impute those missing values with the median of age \n","740f74c4":"titanic = titanic[titanic['Embarked'].isnull()!=True]\n## as embarked has a very small amount of missing values hence remove those rows which have missing values in embarked column \n","b3fa8b4c":"titanic.shape\n## checking shape after removing null values","2321db5a":"titanic_dub = titanic.copy()\n## creating copy of the data frame to check duplicate values","a2b24c33":"titanic_dub.shape\n## comparing shapes of two data frames","e39a5d52":"titanic.shape\n## shape of original data frame","625a5be2":"import seaborn as sns\nimport matplotlib.pyplot as plt\n## importing libraries for data visualitation","98d23357":"plt.figure(figsize=(15,5), dpi=80)\nplt.subplot(1,4,1)\nsns.boxplot(y=titanic['Age'])\nplt.title(\"Outliers in 'Age'\")\n\nplt.subplot(1,4,2)\nax = sns.boxplot(y=titanic['Fare'])\nax.set_yscale('log')\nplt.title(\"Outliers in 'Fare'\")\n\nplt.subplot(1,4,3)\nsns.boxplot(y=titanic['SibSp'])\nplt.title(\"Outliers in 'SibSp'\")\n\n\nplt.subplot(1,4,4)\nsns.boxplot(y=titanic['Parch'])\nplt.title(\"Outliers in 'Parch'\")\n#ax.set_yscale('log')\nplt.tight_layout()\nplt.show()\n\n## plotting all four variables to check for outliers\n## it clearly shows that all four variables has some outliers","60810628":"\n\nsns.catplot(x=\"SibSp\", col = 'Survived', data=titanic, kind = 'count', palette='pastel')\nsns.catplot(x=\"Parch\", col = 'Survived', data=titanic, kind = 'count', palette='pastel')\nplt.tight_layout()\nplt.show()\n\n## plotting of sibsp and parch in basis of survived and not survived","649262b7":"def alone(x):\n    if (x['SibSp']+x['Parch']>0):\n        return (1)\n    else:\n        return (0)\ntitanic['Alone'] = titanic.apply(alone,axis=1)\n## creating a function to make one variable which tells us whether a person is single or accompanied by some on the ship","33169072":"sns.catplot(x=\"Alone\", col = 'Survived', data=titanic, kind = 'count', palette='pastel')\nplt.show()","351f948c":"## drop parch and sibsp\ntitanic = titanic.drop(['Parch','SibSp'],axis=1)\ntitanic.head()\n","d75ae3f4":"sns.distplot(titanic['Fare'])\nplt.show()","635582a5":"titanic['Fare'] = titanic['Fare'].map(lambda x: np.log(x) if x>0 else 0)\n## converting fare into a logarithmic scale","8f6a1760":"sns.distplot(titanic['Fare'])\nplt.show()\n## again check the distribution of fare ","9c762963":"sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\", data=titanic, saturation=.5, kind=\"bar\", ci=None, aspect=0.8, palette='deep')\nsns.catplot(x=\"Sex\", y=\"Survived\", col=\"Embarked\", data=titanic, saturation=.5, kind=\"bar\", ci=None, aspect=0.8, palette='deep')\nplt.show()\n\n## plotting of survive on basis of pclass","d24e1c31":"survived_0 = titanic[titanic['Survived']==0]\nsurvived_1 = titanic[titanic['Survived']==1]\n## divided our dataset into survived or not survived to check the distribution of age in both the cases ","83c37dc6":"survived_0.shape\n## checking shape of the data set that contains the data of passengers who not survived","a623fb2d":"survived_1.shape\n## checking shape of the data set that contains the data of passengers who survived","429a38d7":"sns.distplot(survived_0['Age'])\nplt.show()\n## checking distribution of age in not survived data set","37d2e9a8":"sns.distplot(survived_1['Age'])\nplt.show()\n## checking distribution of age in survived dataset","57236ba5":"sns.boxplot(x='Survived',y='Fare',data=titanic)\nplt.show()\n## checking survival rate on basis of fare","f1c16fb8":"Pclass_dummy = pd.get_dummies(titanic['Pclass'],prefix='Pclass',drop_first=True)\nPclass_dummy.head()\n## creating dummy variables for pclass\n\n","e019f379":"## joing dummy variables\ntitanic = pd.concat([titanic,Pclass_dummy],axis=1)\ntitanic.head()","75084f4c":"titanic.drop('Pclass',axis=1,inplace=True)\n## as there is no use of pclass after joining the columns that contains dummy variables  for pclass","5ce6e2de":"Embarked_dummy = pd.get_dummies(titanic['Embarked'],drop_first=True)\nEmbarked_dummy.head()\n## creating dummy variables for embarked and dropping first column","54de6c16":"titanic = pd.concat([titanic,Embarked_dummy],axis=1)\ntitanic.drop('Embarked',axis=1,inplace=True)\n## joining dummy variables","82565695":"titanic.head()\n## checking head of the data set after joining dummy variables","924b9160":"def sex_map(x):\n    if x == 'male':\n        return (1)\n    elif x == 'female':\n        return (0)\ntitanic['Sex'] = titanic['Sex'].apply(lambda x:sex_map(x))\n\n## creating function for convert sex into binary values","cbd48f56":"titanic = titanic[['Survived','Sex','Age','Fare','Alone','Pclass_2','Pclass_3','Q','S']]","26942f60":"## First, let's calculate the Inter Quantile Range for our dataset,\nIQR = titanic.Age.quantile(0.75) - titanic.Age.quantile(0.25)\n## Using the IQR, we calculate the upper boundary using the formulas mentioned above for age\nupper_limit = titanic.Age.quantile(0.75) + (IQR * 1.5)\nupper_limit_extreme = titanic.Age.quantile(0.75) + (IQR * 3)\nupper_limit, upper_limit_extreme\n","e3b94df1":"## Now, let\u2019s see the ratio of data points above the upper limit & extreme upper limit. ie, the outliers.\ntotal = np.float(titanic.shape[0])\nprint('Total Passenger: {}'.format(titanic.Age.shape[0]\/total))\nprint('Passenger those age > 54.5: {}'.format(titanic[titanic.Age>54.5].shape[0]\/total))\nprint('passenger those age > 74.0: {}'.format(titanic[titanic.Age>74.0].shape[0]\/total))","68e1370f":"## hence replace more than 54.5 age values with age_median\n\ntitanic['Age'] = titanic['Age'].apply(lambda x:age_median if x>54.5 else x)","5b2b5005":"## let's define lower boundary of age\n\nlower_limit = titanic.Age.quantile(0.25) - (IQR * 1.5)\nlower_limit_extreme = titanic.Age.quantile(0.25) - (IQR * 3)\nlower_limit, lower_limit_extreme","2ecfe171":"## Now, let\u2019s see the ratio of data points above the upper limit & extreme upper limit. ie, the outliers.\ntotal = np.float(titanic.shape[0])\nprint('Total Passenger: {}'.format(titanic.Age.shape[0]\/total))\nprint('Passenger those age < 2.5: {}'.format(titanic[titanic.Age<2.5].shape[0]\/total))\nprint('passenger those age < -17.0: {}'.format(titanic[titanic.Age<-17.0].shape[0]\/total))","cbe8e2d5":"## hence replace less than 2.5 age values with age_median\n\ntitanic['Age'] = titanic['Age'].apply(lambda x:age_median if x<2.5 else x)","6472f4d9":"sns.boxplot(titanic['Age'])\nplt.show()\n## check distribution of Age after replacing outliers","657ccc23":"## First, let's calculate the Inter Quantile Range for our dataset,\nIQR_fare = titanic.Fare.quantile(0.75) - titanic.Fare.quantile(0.25)\n## Using the IQR, we calculate the upper boundary using the formulas mentioned above for age\nupper_limit_fare = titanic.Fare.quantile(0.75) + (IQR_fare * 1.5)\nupper_limit_extreme_fare = titanic.Fare.quantile(0.75) + (IQR_fare * 3)\nupper_limit_fare, upper_limit_extreme_fare\n","e9cd9faa":"## Now, let\u2019s see the ratio of data points above the upper limit & extreme upper limit. ie, the outliers.\ntotal = np.float(titanic.shape[0])\nprint('Total Passenger: {}'.format(titanic.Fare.shape[0]\/total))\nprint('Passenger those fare > 6.213966625918822: {}'.format(titanic[titanic.Fare>6.213966625918822].shape[0]\/total))\nprint('passenger those fare > 8.700333209612108: {}'.format(titanic[titanic.Fare>8.700333209612108].shape[0]\/total))","e2b129c6":"fare_median = titanic['Fare'].median()\ntitanic['Fare'] = titanic['Fare'].apply(lambda x:fare_median if x>6.213966625918822 else x)","1d00976a":"## let's define lower boundary of Fare\n\nlower_limit_fare = titanic.Fare.quantile(0.25) - (IQR_fare * 1.5)\nlower_limit_extreme_fare = titanic.Fare.quantile(0.25) - (IQR_fare * 3)\nlower_limit_fare, lower_limit_extreme_fare","9309eba5":"## Now, let\u2019s see the ratio of data points above the upper limit & extreme upper limit. ie, the outliers.\ntotal = np.float(titanic.shape[0])\nprint('Total Passenger: {}'.format(titanic.Fare.shape[0]\/total))\nprint('Passenger those fare < -0.4163442639299415: {}'.format(titanic[titanic.Fare<-0.4163442639299415].shape[0]\/total))\nprint('passenger those fare < -2.9027108476232275: {}'.format(titanic[titanic.Fare<-2.9027108476232275].shape[0]\/total))","8c0941c2":"sns.boxplot(titanic['Fare'])\nplt.show()\n## check distribution of fare after replacing outliers ","0cdcf382":"y_train = titanic.pop('Survived')\nX_train = titanic","001aded8":"import sklearn\nfrom sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(max_depth=2,random_state=10).fit(X_train,y_train)","db30f996":"## check accuracy score with default decision tree\nfrom sklearn.metrics import accuracy_score\nscore_default = accuracy_score(y_train,dt.predict(X_train))\nscore_default","c24f8399":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nestm = list(range(1,500,3))\nacc_score = []\nfor i in estm:\n    ada = AdaBoostClassifier(base_estimator=dt,n_estimators=i,random_state=50).fit(X_train,y_train)\n    pred = ada.predict(X_train)\n    scores = accuracy_score(y_train,pred)\n    acc_score.append(scores)\n    \n    \n## created different estimators of ensembles and produce different accuracy score for each ensemble .","c729910f":"plt.plot(estm,acc_score)\nplt.xlabel('n_estimators')\nplt.ylabel('accuracy')\nplt.ylim([0.85, 1])\nplt.show()\n## plotted number of estimators and accuracy score ","46e2e3eb":"## let's make one final model \n\nada_final = AdaBoostClassifier(base_estimator=dt,n_estimators=50,random_state=100).fit(X_train,y_train)","56c4120c":"from sklearn.metrics import classification_report\nprint(classification_report(y_train,ada_final.predict(X_train)))","2aae6a39":"titanic_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","a2e401dc":"titanic_test.isnull().sum() ## check for null values","5d42deb1":"## impute Age using age_median\n\ntitanic_test['Age'].fillna(age_median,inplace=True)\n\n## log transformation of fare \n\ntitanic_test['Fare'] = titanic_test['Fare'].map(lambda x: np.log(x) if x>0 else 0)","dee4f18a":"## convert sex into numerical value\n\ntitanic_test['Sex'] = titanic_test['Sex'].apply(lambda x:sex_map(x))\n\n## outliers treatment \n\ntitanic_test['Age'] = titanic_test['Age'].apply(lambda x:age_median if x>54.5 else x)","ee559a46":"## outlier treatment\n\ntitanic_test['Age'] = titanic_test['Age'].apply(lambda x:age_median if x<2.5 else x)\n\ntitanic_test['Fare'] = titanic_test['Fare'].apply(lambda x:fare_median if x>6.213966625918822 else x)","301e76e2":"## creating alone column \n\ntitanic_test['Alone'] = titanic_test.apply(alone,axis=1)","f5bc8f18":"Embarked_dummy_test = pd.get_dummies(titanic_test['Embarked'],drop_first=True) ## creating dummy for test\n","ff3f1898":"titanic_test = pd.concat([titanic_test,Embarked_dummy_test],axis=1) ## joining dummy set","2a9213a3":"## creating dummy for pclass\n\nPclass_dummy_test = pd.get_dummies(titanic_test['Pclass'],prefix='Pclass',drop_first=True)","92f1d5f7":"titanic_test = pd.concat([titanic_test,Pclass_dummy_test],axis=1) ## joining dummy set","2f36bcc0":"test_cols = list(X_train.columns) ## required columns for fitting model","fbaecdba":"X_test = titanic_test[test_cols]","c258d0ae":"titanic_test['Survived'] = ada_final.predict(X_test) ## predicted survival using our model on test data ","da059a45":"titanic_res = titanic_test[['PassengerId','Survived']]\n","3cbf011a":"titanic_res.to_csv(\"Submission_titanic.csv\",index=False) ## final submission file","d0a90572":"Divide data into x train and y train","437fb613":"# creating dummy variables","b58af3ba":"**Ada Boost**\n\nAdaBoost is one of the first boosting algorithms to be adapted in solving practices. Adaboost helps you combine multiple \u201cweak classifiers\u201d into a single \u201cstrong classifier\u201d.\n\nFor more information on boosting technique and ada boost : [https:\/\/towardsdatascience.com\/understanding-adaboost-2f94f22d5bfe](http:\/\/)","9e6866e6":"# Outliers Treatment","dd20017e":"Let's prepare test data by removing outliers and imputing missing values for fit our model and do predict.","9ca7f515":"# **Data Quality Check**\n\nhandling missing values as well\n","96dc3265":"Select variables needed for creating model.","4ae34ffb":"it clearly shows that those person who are not alone survived more","33c66163":"# duplicate check","d1692b38":"The most basic form of outlier detection is Extreme Value analysis. The key of this method is to determine the statistical tails of the underlying distribution of the variable and find the values at the extreme end of the tails.\nIf the variable is not normally distributed (not a Gaussian distribution), a general approach is to calculate the quantiles and then the inter-quartile range.\nIQR (Inter quantiles range)= 75th quantile \u2014 25th quantile\nAn outlier will be in the following upper and lower boundaries:\n\nUpper Boundary = 75th quantile +(IQR * 1.5)\nLower Boundary = 25th quantile \u2014 (IQR * 1.5)\nOr for extreme cases:\nUpper Boundary = 75th quantile +(IQR * 3)\nLower Boundary = 25th quantile \u2014 (IQR * 3)\nIf the data point is above the upper boundary or below the lower boundary, it can be considered as an outlier.\n\nFor more information on outliers treatment and detection check the following link : [https:\/\/medium.com\/@swethalakshmanan14\/outlier-detection-and-treatment-a-beginners-guide-c44af0699754](http:\/\/)","80158e85":"* No outliers spotted in lower range of Fare.","831e4b60":"If we keep increasing the number of estimators total error will become 0 and model will became overfit.","e11a4603":"those who are survived paid more fares","9624dac2":"sibsp and parch basically tells us that whether a person is accompanied by someone else or not \nso we can make two category by merging them to find whether a single person is acompanied by some one else or not ","1d1863ee":"young persons are survived more (age group between 20-40)","0047366d":"# EDA","a4b7a66d":"# Model Build","e7ff7975":"there is some skewness in the fare column \nhence removing the skewness using log function","c7bebcec":"females are more likely to be survived","6717da77":"Fit one default decision tree and interpret the accuracy."}}