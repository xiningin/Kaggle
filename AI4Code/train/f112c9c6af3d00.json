{"cell_type":{"12e1be86":"code","33e8c84d":"code","66d90860":"code","80d0244f":"code","c1637fde":"code","b3991033":"code","42b412b7":"code","eaeafb17":"code","9dedcfb5":"code","710bed9f":"code","8619f283":"code","184f9ff5":"code","11ed5bb6":"code","389c4053":"code","7204f703":"code","b39ff6af":"code","31bc92bb":"code","7d233ecf":"code","db5fd4dc":"code","11f17008":"code","c06ca3c9":"code","5a921247":"code","5d28fe11":"code","afd2575d":"code","f12047fe":"code","3c5c37c6":"code","d865f715":"code","10d95913":"code","efc86732":"code","059cdf50":"code","beeed0f4":"code","b97fc7c4":"code","09fd7ab9":"code","926b5beb":"code","52fc16f7":"code","65249d96":"code","810920b0":"code","d8cfe247":"code","944975b7":"code","ecdbf975":"code","a3ce978c":"code","ca36403e":"code","8f84c447":"code","1443d8da":"code","b816188c":"code","5e867559":"code","2034d71a":"code","20e6c3d5":"code","e0e57726":"code","09807ebb":"code","3f93663b":"code","76942090":"code","cd1d9ce0":"code","742731cd":"code","63f4c739":"code","3504397c":"code","20059591":"code","61af950f":"code","f2568d84":"code","b4fe4aca":"code","bae0e3a3":"code","5e1438f4":"code","ec47044e":"code","7122e7b1":"code","bffd72fd":"code","c0f4f0f6":"code","e6edbf75":"code","11394612":"code","60412519":"code","12429154":"code","ec6682d6":"code","0a777003":"code","ed07352d":"code","5cc65cd6":"code","3fbb8cc5":"code","b86d2a16":"code","e4e29cc4":"code","d968c602":"code","72d774bb":"code","f58ad6c9":"code","9749cc8f":"code","d6c56db8":"code","721be323":"code","ae1ea3a4":"code","c3798692":"code","e76c770a":"code","3f728718":"code","7000dffa":"code","2e53cc6f":"code","ff0c19d9":"code","5aab8a40":"code","0d3c1dbb":"code","5b411a6b":"markdown","c67ee117":"markdown","69a272be":"markdown","aff77a81":"markdown","7bb1c7d7":"markdown","dc035675":"markdown","aeeb1838":"markdown","76ae7dad":"markdown"},"source":{"12e1be86":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","33e8c84d":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n\nimport xgboost as xgb","66d90860":"data = pd.read_csv('..\/input\/glass\/glass.csv')","80d0244f":"data.info()","c1637fde":"data['Type'].value_counts()","b3991033":"data.isnull().sum()","42b412b7":"# so we have a data set that's clean already and we want to build a model that predicts the glass type\nX, y = data.drop(columns = 'Type'), data['Type']","eaeafb17":"label_cnts = y.value_counts().to_dict()\nlabel_cnts","9dedcfb5":"new_y_label_for_xgb = {label: idx for idx, label in enumerate(label_cnts.keys())}\nnew_y_label_for_xgb","710bed9f":"y_2 = y.copy()\ny_2 = y_2.map(new_y_label_for_xgb)","8619f283":"X_train, X_test, y_train, y_test = train_test_split(X, y_2, \n                                                    train_size=0.7, \n                                                    stratify = y,\n                                                    shuffle=True, \n                                                    random_state=1)","184f9ff5":"y_train.value_counts() \/ len(y_train)","11ed5bb6":"y_test.value_counts() \/ len(y_test)","389c4053":"# now because the data set is soo soo tiny it's worth using xgb cross validation to do this","7204f703":"train_d_matrix = xgb.DMatrix(X_train, label = y_train)\ntest_d_matrix = xgb.DMatrix(X_test, label = y_test)","b39ff6af":"xgb_params = {'nfolds' : 5, 'num_boost_round' : 100,'early_stopping_rounds' : 5,}\nxgb_gen_params = {'objective' : 'multi:softprob',\n                  'num_class' : 6,\n                  'eval_metric' : 'mlogloss'}","31bc92bb":"def carry_out_training(train_d_matrix):\n    cvresult = xgb.cv(xgb_gen_params, \n                      train_d_matrix, \n                      num_boost_round=xgb_params['num_boost_round'],\n                      nfold=xgb_params['nfolds'],\n                      verbose_eval = True, \n                      early_stopping_rounds=xgb_params['early_stopping_rounds'])\n\n    num_boost_round = cvresult.shape[0]\n    \n    model = xgb.train(dtrain  = train_d_matrix, \n                      params = xgb_gen_params,\n                      num_boost_round  = num_boost_round,\n                      verbose_eval = True)\n    return model","7d233ecf":"model = carry_out_training(train_d_matrix)","db5fd4dc":"def get_performance_metrics(model, test_d_matrix, y_train):\n    dep_vars = [0, 1, 2, 3, 4, 5]\n    preds = pd.DataFrame(model.predict(test_d_matrix), columns = dep_vars)\n    preds['TARGET'] = test_d_matrix.get_label()\n    # now get the max score and max kpi assciated with it\n    preds['pred_max_score'] = preds.loc[:, dep_vars].max(axis = 1)\n    preds['PRED'] = preds.loc[:, dep_vars].idxmax(axis = 1)\n\n    \n    model_f1 = f1_score(preds['TARGET'], preds['PRED'], average = 'macro')\n    model_acc = accuracy_score(preds['TARGET'], preds['PRED'])\n    conf_matrix = pd.DataFrame(confusion_matrix(preds['TARGET'], preds['PRED']), columns = [0, 1, 2, 3, 4, 5])\n\n    for idx in range(6):\n        conf_matrix.loc[idx, 'recall'] = conf_matrix.loc[idx, idx] \/ conf_matrix.loc[idx, ].sum()\n    conf_matrix['recall'] = conf_matrix['recall'].round(4)\n\n    perf = {'f1' : model_f1, 'acc' : model_acc, 'conf' : conf_matrix}\n    \n    # now consider the predicted class vs the logit\n    unconditional_probs = y_train.value_counts() \/ len(y_train)\n    unconditional_odds = unconditional_probs \/ (1-unconditional_probs)\n    unconditional_logits = np.log(unconditional_odds)\n\n    \n    for y_targ in range(6):\n        preds[f'logit__{y_targ}'] = preds[y_targ] \/ (1-preds[y_targ])\n        preds[f'logit__{y_targ}'] = np.log(preds[f'logit__{y_targ}'])\n        preds[f'logit_vs_uncond__{y_targ}'] = preds[f'logit__{y_targ}'] - unconditional_logits.loc[y_targ]\n\n    new_dep_preds = [f'logit_vs_uncond__{y_targ}' for y_targ in range(6)]\n    preds['PRED_2'] = np.argmax(preds[new_dep_preds].to_numpy(), axis=1)\n\n\n    model_f1 = f1_score(preds['TARGET'], preds['PRED_2'], average = 'macro')\n    model_acc = accuracy_score(preds['TARGET'], preds['PRED_2'])\n    conf_matrix = pd.DataFrame(confusion_matrix(preds['TARGET'], preds['PRED_2']), columns = [0, 1, 2, 3, 4, 5])\n\n    for idx in range(6):\n        conf_matrix.loc[idx, 'recall'] = conf_matrix.loc[idx, idx] \/ conf_matrix.loc[idx, ].sum()\n    conf_matrix['recall'] = conf_matrix['recall'].round(4)\n    \n    perf_logit_class = {'f1' : model_f1, 'acc' : model_acc, 'conf' : conf_matrix}\n\n    return perf, perf_logit_class","11f17008":"perf, perf_logit_class = get_performance_metrics(model, test_d_matrix, y_train)","c06ca3c9":"perf","5a921247":"results = {}\nresults['baseline'] = perf\nresults['baseline-logit-approach'] = perf_logit_class\nresults","5d28fe11":"class_labels = y_train.value_counts().reset_index().rename(columns = {'index': 'target', 'Type':'n'})\nclass_labels","afd2575d":"class_labels = class_labels.sort_values('n',ascending = False).reset_index(drop=True)\nclass_labels","f12047fe":"(target_max, n_max) = class_labels.loc[0,['target', 'n']]\nclass_labels['samples_to_add'] = n_max - class_labels['n'] \nclass_labels","3c5c37c6":"X_train_new_data = []\ny_train_new_data = []\n\nfor target, samples_to_add in zip(class_labels['target'], class_labels['samples_to_add']):\n    existing = y_train[y_train == target].index.to_list()\n    if samples_to_add > 0 :\n        to_add = y_train[y_train == target].sample(samples_to_add, replace=True, random_state = 10).index.to_list()\n        y_train_to_add = y_train.loc[existing + to_add].copy()\n        X_train_to_add = X_train.loc[existing + to_add].copy()\n        X_train_new_data.append(X_train_to_add)\n        y_train_new_data.append(y_train_to_add)\n    else:\n        y_train_to_add = y_train.loc[existing].copy()\n        X_train_to_add = X_train.loc[existing].copy()\n        X_train_new_data.append(X_train_to_add)\n        y_train_new_data.append(y_train_to_add)","d865f715":"list(map(lambda x: (x.shape[0], x.shape[1]), X_train_new_data))","10d95913":"list(map(len, y_train_new_data))","efc86732":"X_train_new_data = pd.concat(X_train_new_data, axis = 0)\nprint(X_train_new_data.shape)","059cdf50":"y_train_new_data = pd.concat(y_train_new_data, axis = 0)\ny_train_new_data.value_counts()","beeed0f4":"print(len(y_train_new_data))\nprint(len(X_train_new_data))","b97fc7c4":"X_train_new_data.shape","09fd7ab9":"y_train_new_data.shape","926b5beb":"train_d_matrix = xgb.DMatrix(X_train_new_data, label = y_train_new_data)","52fc16f7":"model = carry_out_training(train_d_matrix)","65249d96":"perf, perf_logit_class = get_performance_metrics(model, test_d_matrix, y_train_new_data)","810920b0":"perf","d8cfe247":"perf_logit_class","944975b7":"results['upsampling'] = perf\nresults['upsampling-logit-approach'] = perf_logit_class\nresults","ecdbf975":"# interesting how now the unsampling logit approach matches the unsampling approach","a3ce978c":"class_labels = class_labels.sort_values('n',ascending = True).reset_index(drop=True)\nclass_labels","ca36403e":"(target_min, n_min) = class_labels.loc[0,['target', 'n']]\nclass_labels","8f84c447":"X_train_new_data = []\ny_train_new_data = []\n\nfor target in class_labels['target']:\n    to_select = y_train[y_train == target].sample(n_min, replace=False, random_state = 10).index.to_list()\n    y_train_selected = y_train.loc[to_select].copy()\n    X_train_selected = X_train.loc[to_select].copy()\n    X_train_new_data.append(X_train_selected)\n    y_train_new_data.append(y_train_selected)","1443d8da":"list(map(lambda x: (x.shape[0], x.shape[1]), X_train_new_data))","b816188c":"list(map(len, y_train_new_data))","5e867559":"X_train_new_data = pd.concat(X_train_new_data, axis = 0)\nprint(X_train_new_data.shape)\ny_train_new_data = pd.concat(y_train_new_data, axis = 0)\nprint(y_train_new_data.value_counts())\n\ntrain_d_matrix = xgb.DMatrix(X_train_new_data, label = y_train_new_data)","2034d71a":"model = carry_out_training(train_d_matrix)\nperf, perf_logit_class = get_performance_metrics(model, test_d_matrix, y_train_new_data)\nresults['downsampling'] = perf\nresults['downsampling-logit-approach'] = perf_logit_class\nresults","20e6c3d5":"class_labels = class_labels.sort_values('n',ascending = False).reset_index(drop=True)\nclass_labels","e0e57726":"differences = {}\nfor i in range(1, 6):\n        differences[i] = np.floor((class_labels.loc[0, 'n'] -  class_labels.loc[i, 'n']) \/ 2)","09807ebb":"differences","3f93663b":"to_dec_big_target = int(np.min([val for targ, val in differences.items()]))\nto_dec_big_target","76942090":"target_biggest, target_big_n = class_labels.loc[0, ['target', 'n']]","cd1d9ce0":"target_big_n","742731cd":"# i.e. increase everything by 16 and decrease the major class by 16 only once!","63f4c739":"X_train_new_data = []\ny_train_new_data = []\n\nfor target in range(1, 6):\n    to_inc = int(differences[target])\n    target_existing = y_train[y_train == target].index.to_list()\n    target_to_add = y_train[y_train == target].sample(to_inc, replace=True, random_state = 10).index.to_list()\n        \n    y_train_selected = y_train.loc[target_existing + target_to_add].copy()\n    X_train_selected = X_train.loc[target_existing + target_to_add].copy()\n    X_train_new_data.append(X_train_selected)\n    y_train_new_data.append(y_train_selected)","3504397c":"target_to_keep = y_train[y_train == target_biggest].sample(target_big_n - to_dec_big_target, replace=False, random_state = 10).index.to_list()\nlen(target_to_keep)","20059591":"y_train_selected = y_train.loc[target_to_keep].copy()\nX_train_selected = X_train.loc[target_to_keep].copy()\nX_train_new_data.append(X_train_selected)\ny_train_new_data.append(y_train_selected)","61af950f":"list(map(lambda x: (x.shape[0], x.shape[1]), X_train_new_data))","f2568d84":"X_train_new_data = pd.concat(X_train_new_data, axis = 0)\nprint(X_train_new_data.shape)\ny_train_new_data = pd.concat(y_train_new_data, axis = 0)\nprint(y_train_new_data.value_counts())","b4fe4aca":"train_d_matrix = xgb.DMatrix(X_train_new_data, label = y_train_new_data)","bae0e3a3":"model = carry_out_training(train_d_matrix)\nperf, perf_logit_class = get_performance_metrics(model, test_d_matrix, y_train_new_data)\nresults['both'] = perf\nresults['both-logit-approach'] = perf_logit_class\nresults","5e1438f4":"class_labels = y_train.value_counts().reset_index().rename(columns = {'index': 'target', 'Type':'n'})\nclass_labels = class_labels.sort_values('n',ascending = False).reset_index(drop=True)\nclass_labels","ec47044e":"target_biggest, target_big_n = class_labels.loc[0, ['target', 'n']]\nrount_nbr = 0\nfor target in class_labels.loc[1:]['target'].tolist():\n    class_labels.loc[target, f'round__{rount_nbr}__inc'] = int((target_big_n - class_labels.loc[target, 'n'])\/2)\n    \nclass_labels.loc[0, f'round__{rount_nbr}__inc'] = -class_labels.loc[1, f'round__{rount_nbr}__inc']\nclass_labels[f'round__{rount_nbr}'] = class_labels['n'] + class_labels[f'round__{rount_nbr}__inc']\nclass_labels","7122e7b1":"class_labels_round__0 = class_labels.groupby(['round__0'])['target'].apply(list).reset_index().sort_values('round__0', ascending=False).reset_index(drop=True)\nclass_labels_round__0 = class_labels_round__0[['target', 'round__0']]\nclass_labels_round__0","bffd72fd":"def do_both_get_numbers(df, current_nbr, rount_nbr):\n    target_biggest, target_big_n = df.loc[0, ['target', current_nbr]]\n    for target in range(1, len(df)):\n        df.loc[target, f'round__{rount_nbr}__inc'] = int((target_big_n - df.loc[target, current_nbr])\/2)\n\n    df.loc[0, f'round__{rount_nbr}__inc'] = -df.loc[1, f'round__{rount_nbr}__inc']\n    df[f'round__{rount_nbr}'] = df[current_nbr] + df[f'round__{rount_nbr}__inc']\n    return df","c0f4f0f6":"round_1 = do_both_get_numbers(class_labels_round__0, current_nbr='round__0', rount_nbr=1)\nround_1","e6edbf75":"class_labels_round__1 = round_1.groupby(['round__1'])['target'].apply(list).reset_index().sort_values('round__1', ascending=False).reset_index(drop=True)\nclass_labels_round__1 = class_labels_round__0[['target', 'round__1']]\nclass_labels_round__1","11394612":"class_labels_round__1 = pd.DataFrame()\n# it's so so tricky because \nfor group, df in round_1.groupby(['round__1'])['target']:\n    round__1 = [var for vars2 in df.to_list() for var in vars2]\n    print(round__1)\n    round__1_df = pd.DataFrame({'round__1' : [group]})\n    round__1_df['target'] = [round__1]\n\n    class_labels_round__1 = class_labels_round__1.append(round__1_df)","60412519":"class_labels_round__1\nclass_labels_round__1 = class_labels_round__1.sort_values('round__1', ascending=False).reset_index(drop=True)\nclass_labels_round__1 = class_labels_round__1[['target', 'round__1']]\nclass_labels_round__1\n","12429154":"# the above you repeat - this is quite a lot of work and doesn't achieve much I don't think!\nround_2 = do_both_get_numbers(class_labels_round__1, current_nbr='round__1', rount_nbr=2)\nround_2","ec6682d6":"class_labels_round__2 = pd.DataFrame()\n# it's so so tricky because \nfor group, df in round_2.groupby(['round__2'])['target']:\n    round__2 = [var for vars2 in df.to_list() for var in vars2]\n    round__2_df = pd.DataFrame({'round__2' : [group]})\n    round__2_df['target'] = [round__2]\n\n    class_labels_round__2 = class_labels_round__2.append(round__2_df)\n    \n    \nclass_labels_round__2\nclass_labels_round__2 = class_labels_round__2.sort_values('round__2', ascending=False).reset_index(drop=True)\nclass_labels_round__2 = class_labels_round__2[['target', 'round__2']]\nclass_labels_round__2\n    ","0a777003":"# the above you repeat - this is quite a lot of work and doesn't achieve much I don't think!\nround_3 = do_both_get_numbers(class_labels_round__2, current_nbr='round__2', rount_nbr=3)\nround_3","ed07352d":"# so I don't like the approach that I've set it up as! I think this is too complicated!","5cc65cd6":"\ndef up_plus_down_sampling_herlper(df):\n    class_labels = df['TARGET'].value_counts().reset_index().rename(columns = {'index': 'target', 'TARGET':'n'})\n    class_labels = class_labels.sort_values('n',ascending = False).reset_index(drop=True)\n\n    differences = {}\n    for i in range(len(class_labels)):\n        target = class_labels.loc[i, 'target']\n        differences[target] = int(np.floor((class_labels.loc[0, 'n'] -  class_labels.loc[i, 'n']) \/ 2))\n\n    print(differences)\n\n    target_biggest, target_big_n = class_labels.loc[0, ['target', 'n']]\n    to_dec_big_target = int(np.min([val for targ, val in differences.items() if val >0]))\n\n    \n    df_mod_new = []\n    for target in class_labels['target'].tolist():\n        to_inc = differences[target]\n        n = class_labels.query(f'target == \"{target}\"')['n'].tolist()[0]\n        if to_inc == 0:\n            # then to this group we're going to downsample!\n            to_select = df['TARGET'][df['TARGET'] == target].sample(n - to_dec_big_target, \n                                                                    replace=False, \n                                                                    random_state = 10).index.to_list() \n            df_mod_new_selection = df.loc[to_select].copy()\n            df_mod_new.append(df_mod_new_selection)\n            print(f'target = {target} downsampled')\n        else:\n            # then to this group we're going to downsample!\n            base_to_select = df['TARGET'][df['TARGET'] == target].index.to_list() \n            to_add = df['TARGET'][df['TARGET'] == target].sample(to_inc, \n                                                                 replace=True, \n                                                                 random_state = 10).index.to_list() \n            df_mod_new_selection = df.loc[base_to_select+to_add].copy()\n            df_mod_new.append(df_mod_new_selection)\n            print(f'target = {target} upsampled')\n            \n    print(list(map(lambda x: (x.shape[0], x.shape[1]), df_mod_new)))\n    df_mod_new = pd.concat(df_mod_new, axis = 0).reset_index(drop=True)\n    return df_mod_new\n\n#df_mod_pass_1 = up_plus_down_sampling_herlper(df_mod_2)\n#df_mod_pass_2 = up_plus_down_sampling_herlper(df_mod_pass_1)\n","3fbb8cc5":"class Weight_Binary_Cross_Entropy:\n    '''\n    The class of binary cross entropy loss, allows the users to change the weight parameter\n    '''\n\n    def __init__(self, imbalance_alpha):\n        '''\n        :param imbalance_alpha: the imbalanced \\alpha value for the minority class (label as '1')\n        '''\n        self.imbalance_alpha = imbalance_alpha\n\n    def weighted_binary_cross_entropy(self, pred, dtrain):\n        # assign the value of imbalanced alpha\n        imbalance_alpha = self.imbalance_alpha\n        # retrieve data from dtrain matrix\n        label = dtrain.get_label()\n        # compute the prediction with sigmoid\n        sigmoid_pred = 1.0 \/ (1.0 + np.exp(-pred))\n        # gradient\n        grad = -(imbalance_alpha ** label) * (label - sigmoid_pred)\n        hess = (imbalance_alpha ** label) * sigmoid_pred * (1.0 - sigmoid_pred)\n\n        return grad, hess\n\n    \ndef evalerror(preds, dtrain):\n    labels = dtrain.get_label()\n    # return a pair metric_name, result\n    # since preds are margin(before logistic transformation, cutoff at 0)\n\n    return 'error', float(sum(labels != (preds > 0.0))) \/ len(labels)","b86d2a16":"[y_train == 1] * 1\n    ","e4e29cc4":"y_train_2 = y_train.copy()\ny_train_2 = np.where([y_train == 0], 1, 0)[0]\ny_train_2","d968c602":"train_d_matrix = xgb.DMatrix(X_train, label = y_train_2)\n\nweighted_loss_obj = Weight_Binary_Cross_Entropy(imbalance_alpha=1)\n    \n    \nxgb_params = {'nfolds' : 5, \n              'num_boost_round' : 100,\n              'early_stopping_rounds' : 5}\n\nxgb_gen_params = {'eval_metric' : 'logloss',\n                  'objective': 'binary:logitraw'}\n","72d774bb":"cvresult = xgb.cv(xgb_gen_params, \n                      train_d_matrix, \n                      num_boost_round=xgb_params['num_boost_round'],\n                      nfold=xgb_params['nfolds'],\n                      obj = weighted_loss_obj.weighted_binary_cross_entropy,\n                      feval=evalerror,\n                      verbose_eval = True, \n                      early_stopping_rounds=xgb_params['early_stopping_rounds'])\n","f58ad6c9":"def carry_out_training_vers2(X_train, y_train, predicted_class, imbalance_alpha):\n    \n    \n    y_train_2 = y_train.copy()\n    y_train_2 = np.where([y_train == predicted_class], 1, 0)[0]\n    print(y_train_2.sum())\n    train_d_matrix = xgb.DMatrix(X_train, label = y_train_2)\n\n    \n    weighted_loss_obj = Weight_Binary_Cross_Entropy(imbalance_alpha=imbalance_alpha)\n    \n\n    xgb_params = {'nfolds' : 5, \n                  'num_boost_round' : 100,\n                  'early_stopping_rounds' : 5}\n\n    xgb_gen_params = {'eval_metric' : 'logloss',\n                      'objective': 'binary:logitraw'}\n\n\n\n    cvresult = xgb.cv(xgb_gen_params, \n                      train_d_matrix, \n                      num_boost_round=xgb_params['num_boost_round'],\n                      nfold=xgb_params['nfolds'],\n                      obj = weighted_loss_obj.weighted_binary_cross_entropy,\n                      feval=evalerror,\n                      verbose_eval = True, \n                      early_stopping_rounds=xgb_params['early_stopping_rounds'])\n\n    num_boost_round = cvresult.shape[0]\n    \n    model = xgb.train(dtrain  = train_d_matrix, \n                      params = xgb_gen_params,\n                      num_boost_round  = num_boost_round,\n                      obj = weighted_loss_obj.weighted_binary_cross_entropy,\n                      feval=evalerror,\n                      verbose_eval = True)\n    return model","9749cc8f":"all_models = {}\nimbalance_alpha = 1\nfor predicted_class in range(6):\n    \n    all_models[f'model__{predicted_class}'] = carry_out_training_vers2(X_train, \n                                                                       y_train, \n                                                                       predicted_class=predicted_class, \n                                                                       imbalance_alpha=1)","d6c56db8":"pred_probs = []\n\nfor predicted_class in range(6):\n    pred = all_models[f'model__{predicted_class}'].predict(test_d_matrix)\n    pred = 1. \/ (1. + np.exp(-pred))\n    pred_probs.append(pd.Series(pred))","721be323":"pred_probs_df = pd.concat(pred_probs, axis=1)","ae1ea3a4":"pred_probs_df","c3798692":"pred_probs_df[list(range(6))].to_numpy().shape","e76c770a":"pred_probs_df['PRED'] = np.argmax(pred_probs_df[list(range(6))].to_numpy(), axis=1)\npred_probs_df['PRED'].value_counts()","3f728718":"model_f1 = f1_score(y_test, pred_probs_df['PRED'], average = 'macro')\nmodel_f1","7000dffa":"model_acc = accuracy_score(y_test, pred_probs_df['PRED'])\nmodel_acc","2e53cc6f":"conf_matrix = pd.DataFrame(confusion_matrix(y_test, pred_probs_df['PRED']), columns = [0, 1, 2, 3, 4, 5])\nconf_matrix","ff0c19d9":"for idx in range(6):\n    conf_matrix.loc[idx, 'recall'] = conf_matrix.loc[idx, idx] \/ conf_matrix.loc[idx, ].sum()\nconf_matrix['recall'] = conf_matrix['recall'].round(4)\n\n{'f1' : model_f1, 'acc' : model_acc, 'conf' : conf_matrix}\n","5aab8a40":"import lightgbm","0d3c1dbb":"# https:\/\/maxhalford.github.io\/blog\/lightgbm-focal-loss\/#first-order-derivative","5b411a6b":"### focal loss using lightgbm","c67ee117":"### using weighting on the objective function","69a272be":"### so now do both but do it repeatedly until all classes have the same observations\n\ni.e. round one find class with the highest number of records -> now that class find mid point between all other classes for it - that represents observations to add for those minority classes\n\nfor the majority class reduce only once by it's midpoint between it and the 2nd most majority class\n\n\nthen repeat the above until all classes have the same number of observations","aff77a81":"## now for both find median between the all cases","7bb1c7d7":"## now for downsampling all to have the clas with the lowest number! this will be bad","dc035675":"## now for upsampling all to have the same number of records as the class with the highest obs","aeeb1838":"###\u00a0approaches that I will be testing\n\n#### multi-classification approaches\n- simple model\n- upsampling all observations to the class with the highest number of observations\n- downsampling all observations to the class with the lower number of observations\n- both approahces and basing it of the median difference of observations between all combinations -> so some classes will be downsampled others upsamplied\n- using a loss function that accounts for the error -> is it possible to use the loss function? try and see!\n\n#### OVR\n- simple model for each class -> prediction with the highest prob is the class to predict\n- upsampling -> each model -> and then see predictive accuracy\n- downsampling -> each model -> and then see predictive accuracy\n- both upsampling and downsampling -> and then seeing predictive accuracy\n- using a loss function ","76ae7dad":"### approach find class with the lowest number"}}