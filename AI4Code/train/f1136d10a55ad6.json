{"cell_type":{"b9de52e3":"code","584df88e":"code","1a21c415":"code","165d554c":"code","b1bcfbdd":"code","775f1c5e":"code","1adea9b3":"code","ca3ed909":"code","cd25c563":"code","6506f22b":"markdown","adbf3a29":"markdown","ac5df21d":"markdown","5c6e196e":"markdown"},"source":{"b9de52e3":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","584df88e":"df1 = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\", sep = \",\" , encoding=\"utf-8\")","1a21c415":"df2 = df1.copy()\n# Copying original df into another one to edit and compare them","165d554c":"df1.info()\n# We can see that there are many features\n# and there might be some unneeded features","b1bcfbdd":"df1.head()\n# Getting a general idea of how the data looks","775f1c5e":"df1.isnull().sum()\n# The number of null values of each feature","1adea9b3":"df1.isnull().sum().sum()\n# The Total number of null values is\n# big compared to the dataset, so we can't simply\n# drop them, we need to fill them with reasonable values","ca3ed909":"plt.figure(figsize=(20,23))\nsns.heatmap(df1.isnull(), cbar = False)\n# It is clear that dropping nulls will\n# have a great effect on the accuracy of the data","cd25c563":"# Will be continued later on, isA","6506f22b":"# Data preprocessing","adbf3a29":"# EDA","ac5df21d":"# Importing necessary libraries","5c6e196e":"# Reading input data"}}