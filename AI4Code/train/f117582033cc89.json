{"cell_type":{"b936853b":"code","85ecc7a9":"code","0411951f":"code","0f4a8c77":"code","1f43115e":"code","f5de0898":"code","ed9c2892":"code","65169937":"code","7b3129a6":"code","20d8d1d1":"code","77ff6c8a":"code","1b5eee65":"code","9b805a95":"code","2db16d75":"code","8b9c7aa3":"code","2e75ed5b":"code","c7478067":"markdown"},"source":{"b936853b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import confusion_matrix,auc,roc_auc_score\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","85ecc7a9":"# https:\/\/www.kaggle.com\/lovedeepsaini\/fraud-detection-with-naive-bayes-classifier\/notebook","0411951f":"df = pd.read_csv(\"..\/input\/creditcard.csv\")\ndf.describe()","0f4a8c77":"print(\"Class as pie chart:\")\nfig, ax = plt.subplots(1, 1)\nprint(df.Class.value_counts())\nax.pie(df.Class.value_counts(),autopct='%1.1f%%', labels=['Genuine','Fraud'], colors=['yellowgreen','r'])","1f43115e":"print('Time variable')\ndf['Time_Hr'] = df[\"Time\"]\/3600\nprint(df[\"Time_Hr\"].tail(5))\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex = True, figsize=(6,3))\nax1.hist(df.Time_Hr[df.Class==0],bins=48,color='g',alpha=0.5)\nax1.set_title('Genuine')\nax2.hist(df.Time_Hr[df.Class==1],bins=48,color='r',alpha=0.5)\nax2.set_title('Fraud')\nplt.xlabel('Time (hrs)')\nplt.ylabel('# transactions')","f5de0898":"fig, (ax3,ax4) = plt.subplots(2,1, figsize = (6,3), sharex = True)\nax3.hist(df.Amount[df.Class==0],bins=50,color='g',alpha=0.5)\nax4.hist(df.Amount[df.Class==1],bins=50,color='r',alpha=0.5)\nax3.set_yscale('log') # to see the tails\nax3.set_title('Genuine') # to see the tails\nax3.set_ylabel('# transactions')\nax4.set_yscale('log') # to see the tails\nax4.set_title('Fraud') # to see the tails\nax4.set_xlabel('Amount ($)')\nax4.set_ylabel('# transactions') ","ed9c2892":"from sklearn.preprocessing import StandardScaler\ndf['scaled_Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\ndf = df.drop(['Amount'],axis=1)\ndf.head(10)","65169937":"#let us check correlations and shapes of those 25 principal components.\n# Features V1, V2, ... V28 are the principal components obtained with PCA.\nimport seaborn as sns\nimport matplotlib.gridspec as gridspec\ngs = gridspec.GridSpec(28, 1)\nplt.figure(figsize=(6,28*4))\nfor i, col in enumerate(df[df.iloc[:,0:28].columns]):\n    ax5 = plt.subplot(gs[i])\n    sns.distplot(df[col][df.Class == 1], bins=50, color='r')\n    sns.distplot(df[col][df.Class == 0], bins=50, color='g')\n    ax5.set_xlabel('')\n    ax5.set_title('feature: ' + str(col))\nplt.show()","7b3129a6":"def split_data(df, drop_list):\n    df = df.drop(drop_list,axis=1)\n    print(df.columns)\n    #test train split time\n    from sklearn.model_selection import train_test_split\n    y = df['Class'].values #target\n    X = df.drop(['Class'],axis=1).values #features\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n                                                    random_state=42, stratify=y)\n\n    print(\"train-set size: \", len(y_train),\n      \"\\ntest-set size: \", len(y_test))\n    print(\"fraud cases in test-set: \", sum(y_test))\n    return X_train, X_test, y_train, y_test","20d8d1d1":"def get_predictions(clf, X_train, y_train, X_test):\n    # create classifier\n    clf = clf\n    # fit it to training data\n    clf.fit(X_train,y_train)\n    # predict using test data\n    y_pred = clf.predict(X_test)\n    # Compute predicted probabilities: y_pred_prob\n    y_pred_prob = clf.predict_proba(X_test)\n    #for fun: train-set predictions\n    train_pred = clf.predict(X_train)\n    print('train-set confusion matrix:\\n', confusion_matrix(y_train,train_pred)) \n    return y_pred, y_pred_prob","77ff6c8a":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression","1b5eee65":"def print_scores(y_test,y_pred,y_pred_prob):\n    print('test-set confusion matrix:\\n', confusion_matrix(y_test,y_pred)) \n    print(\"recall score: \", recall_score(y_test,y_pred))\n    print(\"precision score: \", precision_score(y_test,y_pred))\n    print(\"f1 score: \", f1_score(y_test,y_pred))\n    print(\"accuracy score: \", accuracy_score(y_test,y_pred))\n    print(\"ROC AUC: {}\".format(roc_auc_score(y_test, y_pred_prob[:,1])))","9b805a95":"drop_list = []\nX_train, X_test, y_train, y_test = split_data(df, drop_list)\ny_pred, y_pred_prob = get_predictions(GaussianNB(), X_train, y_train, X_test)\nprint_scores(y_test,y_pred,y_pred_prob)","2db16d75":"drop_list = ['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8']\nX_train, X_test, y_train, y_test = split_data(df, drop_list)\ny_pred, y_pred_prob = get_predictions(GaussianNB(), X_train, y_train, X_test)\nprint_scores(y_test,y_pred,y_pred_prob)","8b9c7aa3":"drop_list = ['Time_Hr','V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8']\nX_train, X_test, y_train, y_test = split_data(df, drop_list)\ny_pred, y_pred_prob = get_predictions(GaussianNB(), X_train, y_train, X_test)\nprint_scores(y_test,y_pred,y_pred_prob)","2e75ed5b":"df = df.drop(drop_list,axis=1)\nprint(df.columns)","c7478067":"    > Trends about amount"}}