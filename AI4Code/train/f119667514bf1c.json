{"cell_type":{"8ea78928":"code","cd830098":"code","81564ed7":"code","43abc7cb":"code","29953bb1":"code","ceb5e936":"code","e36a88f5":"code","78d0cb85":"code","ea00c4e3":"code","d2a46c85":"code","b63f81a5":"code","86a2c843":"code","a711bbd4":"code","ef9ecf64":"code","0efc1b63":"code","2616ef57":"code","429d78d0":"code","b707ca12":"code","51ec52b3":"code","6aa4a4a1":"code","6953be0d":"code","f91a8ca2":"code","2750f9a5":"code","9fcdbcef":"code","277a78de":"code","95526e96":"code","68086b62":"code","b6967810":"code","89127446":"code","51df59b7":"code","cf96ff23":"code","fc940148":"markdown","5ca6a082":"markdown","77bd546f":"markdown","822f0741":"markdown","d9da78e8":"markdown","e1d2431a":"markdown","81b094d0":"markdown","e7b1ed1b":"markdown","0084b116":"markdown","d35a1bd0":"markdown","9ffc1feb":"markdown","9e75f2e0":"markdown","12324498":"markdown","6f11b64e":"markdown","e5c2c102":"markdown","7fbe60c5":"markdown","79693e28":"markdown","50c2fef0":"markdown","4569bc28":"markdown"},"source":{"8ea78928":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #data visualization\n\nimport warnings            \nwarnings.filterwarnings(\"ignore\") \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","cd830098":"#Load dataset\ndata=pd.read_csv('..\/input\/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2015.csv')\n#data includes how many rows and columns\ndata.shape\nprint(\"Our data has {} rows and {} columns\".format(data.shape[0],data.shape[1]))\n#Features name in data\ndata.columns","81564ed7":"#diplay first 5 rows\ndata.head()","43abc7cb":"#display last 5 rows\ndata.tail()","29953bb1":"print(\"Data Type:\")\ndata.dtypes","ceb5e936":"#column name change\ndata.columns=[each.replace(\" \",\"_\") for each in data.columns]\n\n#remove dollar sign\ndata.Total_Charges=[each.replace(\"$\",\"\") for each in data.Total_Charges]\ndata.Total_Costs=[each.replace(\"$\",\"\") for each in data.Total_Costs]\n\n#lets convert object to float\ndata[\"Total_Charges\"]=data[\"Total_Charges\"].astype('float')\ndata[\"Total_Costs\"]=data[\"Total_Costs\"].astype('float')\n\n#Delete the + sign\ndata.Length_of_Stay=[each.replace(\"+\",\"\") if(each==\"120 +\") else each for each in data.Length_of_Stay]\n#lets convert object to int\ndata[\"Length_of_Stay\"]=data[\"Length_of_Stay\"].astype('int')","e36a88f5":"#Let's look again\ndata.dtypes","78d0cb85":"data.loc[:,[\"Total_Costs\",\"Total_Charges\",\"Birth_Weight\",\"Length_of_Stay\"]].describe()","ea00c4e3":"#checking for missing values\nprint(\"Are there missing values? {}\".format(data.isnull().any().any()))\n#missing value control in features\ndata.isnull().sum()","d2a46c85":"assert data[\"Hospital_County\"].notnull().all()","b63f81a5":"#we found out how many Type of Admission\nprint(\"Type of Admission in Dataset:\\n\")\nprint(data.Type_of_Admission.unique())\n#we found out how many Age group\nprint(\"\\n\\nAge Group in Dataset:\\n\")\nprint(data.Age_Group.unique())\n#we found out how many ARP Risk of Mortality\nprint(\"\\n\\nARP Risk of Mortality:\\n\")\nprint(data.APR_Risk_of_Mortality.unique())\n#we found out how many hospital country in our data\nprint(\"\\n\\nHospital Country in Dataset:\\n\")\nprint(\"There are {} different values\\n\".format(len(data.Hospital_County.unique())))\nprint(data.Hospital_County.unique())\n#we found out how many ARP MDC Description\nprint(\"\\n\\nARP MDC Description(disease diagnosis) in Dataset:\\n\")\nprint(\"There are {} different values\\n\".format(len(data.APR_MDC_Description.unique())))\nprint(data.APR_MDC_Description.unique())","86a2c843":"#We group features by data numbers\n#show it if missing value(dropna=False)\ndata[\"Type_of_Admission\"].value_counts(dropna=False)","a711bbd4":"#number of patients by age groups\n#show it if missing value(dropna=False)\ndata[\"Age_Group\"].value_counts(dropna=False)","ef9ecf64":"#show it if missing value(dropna=False)\nprint(\"Patients with or without abortion:\\n\")\nprint(data[\"Abortion_Edit_Indicator\"].value_counts(dropna=False))","0efc1b63":"#filtering\ndata_newborn=data['Type_of_Admission']=='Newborn'\nprint(\"Total Newborns:\",data_newborn.count())\ndata[data_newborn].head()","2616ef57":"#grouping of mortality risk values\n#show it if missing value(dropna=False)\ndata[\"APR_Severity_of_Illness_Description\"].value_counts(dropna=False)","429d78d0":"\ndata_new = data.head()\nmelted = pd.melt(frame = data_new, id_vars = 'APR_MDC_Description', value_vars = ['Age_Group','Type_of_Admission'])\nmelted","b707ca12":"#firstly lets create 2 data frame\ndata1=data['APR_MDC_Description'].tail()\ndata2=data['Age_Group'].tail()\n\nconc_data_col=pd.concat([data1,data2],axis=1)\nconc_data_col","51ec52b3":"#data frames from dictionary\nHospital=list(data[\"Hospital_County\"].head())\nFacility=list(data[\"Facility_Name\"].head())\nYear=list(data[\"Discharge_Year\"].head())\nCosts=list(data[\"Total_Costs\"].head())\n\nlist_label=[\"hospital_country\",\"facility_name\",\"discharge_year\",\"total_costs\"]\nlist_col=[Hospital,Facility,Year,Costs]\nzipped=list(zip(list_label,list_col))\ndata_dict=dict(zipped)\n\ndf=pd.DataFrame(data_dict)\ndf","6aa4a4a1":"#add new column\ndata[\"Entry_Year\"]=0\ndata.head()","6953be0d":"#ploting\ndata1=data.loc[:,[\"Total_Costs\",\"Total_Charges\",\"Birth_Weight\",\"Length_of_Stay\"]]\ndata1.plot()\nplt.show()\n#this is complete","f91a8ca2":"#To solve the above complexity\n#subplot\ndata1.plot(subplots=True)\nplt.show()","2750f9a5":"#histogram\ndata1.plot(kind=\"hist\",y=\"Total_Costs\",bins=50,range=(0,250),normed=True)\nplt.show()","9fcdbcef":"#histogram subplot with non cumulative an cumulative\nfig,axes=plt.subplots(nrows=2,ncols=1)\n\ndata1.plot(kind=\"hist\",y=\"Total_Costs\",bins=50,range=(0,250),normed=True,ax=axes[0])\ndata1.plot(kind=\"hist\",y=\"Total_Costs\",bins=50,range=(0,250),normed=True,ax=axes[1],cumulative=True)\n\nplt.savefig(\"Graph.png\")\nplt.show()","277a78de":"print(df[\"discharge_year\"])\ndf.discharge_year=pd.to_datetime(df[\"discharge_year\"])\n#lets make discharge_year as index\ndf=df.set_index(\"discharge_year\")\ndf","95526e96":"df.resample(\"A\").mean()\n#lets resample with month\n#df.resample(\"M\").mean()","68086b62":"#indexing data frame\n#using loc accessor\nprint(data.loc[85,['APR_DRG_Description']])\n#selecting only some columns\ndata[[\"APR_DRG_Description\",\"Age_Group\",\"Length_of_Stay\"]].head(20)","b6967810":"#silincing and indexing data series\nprint(data.loc[1:10,\"Race\":\"Length_of_Stay\"])\n#from something to end\ndata.loc[1:10,\"Gender\":]","89127446":"first_filter=data.Gender==\"F\"\nsecond_filter=data.Abortion_Edit_Indicator==\"Y\"\ndata[first_filter & second_filter].head()\n#filtering columns based others\n#data.Gender[data.Race==\"Black\/African American\"]","51df59b7":"#Defining column using other columns\ndata[\"Average_Costs\"]=data.Total_Costs.mean()\ndata.head()\n\n#print(data.Total_Costs.apply(lambda n:n\/2))","cf96ff23":"print(\"Total hospitalization times for patients admitted to the hospital as Urgent:\",\n      data['Length_of_Stay'][data['Type_of_Admission']=='Urgent'].sum())\n\n#The first value of unique races of patients coming to the hospital\ndata.groupby(\"Race\").first()\n","fc940148":"* Missing data control with Assert method.\n<br>We use the Assert method to check for missing data in the Hospital_Country property. We are planning to get an error because we have missing data.<\/br>","5ca6a082":"<a id=12><\/a>\n**<h3>Grouping Data<\/h3>**","77bd546f":"* Let's look at the frequency of total costs with histogram","822f0741":"<a id=5><\/a>\n**<h3>Building Data Frames From Scratch<\/h3>**","d9da78e8":"<a id=11><\/a>\n**<h3>Transforming Data<\/h3>**","e1d2431a":" We group the Type of Admission property into values and we see that there are many patients who are accepted emergency.Also we again understand that there is no missing data in the Type of Admission feature.","81b094d0":"**<h3>INTRODUCTION<\/h3>**\n* In this tutorial,I will describe it from my data analysis as a beginner on the 2015 de-identified NY inpatient discharge dataset.\n\nContent:\n* [Summarize the Dataset](#1)\n* [Missing Data Capture](#2)\n* [Tidy Data](#3)\n* [Concatenating Data](#4)\n* [Building Data Frames From Scratch](#5)\n* [Visual Exploratory Data Analysis](#6)\n* [Indexing Pandas Time Series](#7)\n* [Resampling Pandas Time Series](#8)\n* [Indexing and Silicing Data Frames](#9)\n* [Filtering Data Frames](#10)\n* [Transforming Data](#11)\n* [Grouping Data](#12)","e7b1ed1b":"<a id=7><\/a>\n**<h3>Indexing Pandas Time Series<\/h3>**\n* First we print the Discharge_Year property in our data queue. We convert the type of our feature to datetime with the to_datetime() method.","0084b116":"<a id=8><\/a>\n**<h3>Resampling Pandas Time Series<\/h3>**\n* Let's take the average of all years in our data. Since our data is a single year, a single-line result is output.","d35a1bd0":"* When we group the Abortion_Edit_Indicator feature, Type_of_Admission does not contain only newborns. So we found newborns with filtering.","9ffc1feb":"<a id=6><\/a>\n**<h3>Visual Exploratory Data Analysis<\/h3>**\n* plot\n* subplot\n* histogram","9e75f2e0":"<p>When we look at the data types of our data set, we have the Total Charges and Total Costs property type object and the dollar sign in their content.  We can not convert it to a float type when there is a  dollar sign in those features. we need to remove this sign. But first we need to organize the space between the names of our data columns.<\/p>\n<p>I want to see the Length of Stay feature in the statistical summary, and I need to convert the object type to int first. But I get an error because of the '120 +' record in the conversion. I am clearing the '+' sign in this record.<\/p>\n<br>Then we can change the types to float so we can see these features statistically.<\/br>","12324498":"**<h3>Broadcasting<\/h3>**\n* Create new column and assign a value to entire column\n    <br>There is no special feature about patients' entry into the hospital, so let's add it and get zero by default.<\/br>","6f11b64e":"<a id=10><\/a>\n**<h3>Filtering Data Frames<\/h3>**","e5c2c102":"<a id=3><\/a>\n**<h3>Tidy Data(Melting)<\/h3>**\n* We have transformed into a different structure with the melt () method to find out the features of the first five elements in our dataset ['Age_Group', 'Length_of_Stay', 'Type_of_Admission'].","7fbe60c5":"**<h3> Summarize the Dataset <\/h3>**\nNow it is time to take a look at the data.\n<br>In this step we are going to take a look at the data a few different ways:<\/br>\n  * Dimensions of the dataset.\n        We can get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the shape property.\n  * Features name in dataset.\n  * Peek at the data itself.\n  * Statistical summary of all attributes.\n        This includes the count, mean, the min and max values as well as some percentiles.","79693e28":"<a id=9><\/a>\n**<h3>Indexing and Silicing Data Frames<\/h3>**\n","50c2fef0":"<a id=4><\/a>\n**<h3>Concatenating Data<\/h3>**\n* age group of the diagnosis and the patient","4569bc28":"<a id=2><\/a>\n**<h3>Missing Data Capture<\/h3>**\n* Let's check if there is missing data in the features of our data."}}