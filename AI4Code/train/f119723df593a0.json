{"cell_type":{"4521548d":"code","70047bb9":"code","f58b23de":"code","2064795f":"code","92f64120":"code","27bf7e9e":"code","cc931422":"code","261d2dc3":"code","7319c8f8":"code","7d67ec1b":"code","de5fc6f1":"code","26461e97":"code","20522aae":"code","ec9e6063":"code","4a84313c":"code","0c43d2c2":"code","e54dce0d":"code","f0df0374":"markdown","aff55b54":"markdown","727ff290":"markdown","31da3bd3":"markdown"},"source":{"4521548d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","70047bb9":"train=pd.read_csv('\/kaggle\/input\/random-linear-regression\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/random-linear-regression\/test.csv')","f58b23de":"train.head()","2064795f":"test.head()","92f64120":"train_data = train.sample(frac=0.7, random_state=10)\nval_data = train.drop(train_data.index)","27bf7e9e":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\ntrain_data[['x','y']]=scaler.fit_transform(train_data[['x','y']])\n#X_tr=X_train.to_numpy()\nval_data[['x','y']]=scaler.transform(val_data[['x','y']]) \ntest[['x','y']]=scaler.transform(test[['x','y']])","cc931422":"train_data.head()","261d2dc3":"test.head()","7319c8f8":"from tensorflow import keras \nfrom tensorflow.keras import layers","7d67ec1b":"model=keras.Sequential([\n                     layers.Dense(64,activation='relu',input_shape=[1]),\n                     layers.Dense(1,input_shape=[1])])","de5fc6f1":"model.weights","26461e97":"model.compile(optimizer='adam',\n             loss='mae',\n              \n              )","20522aae":"X=train_data['x']\ny=train_data['y']","ec9e6063":"X","4a84313c":"history = model.fit(X,y,\n                   batch_size=50,\n                   epochs=30\n                   )","0c43d2c2":"history_df = pd.DataFrame(history.history)\n# Start the plot at epoch 5. You can change this to get a different view.\nhistory_df.loc[5:, ['loss']].plot();","e54dce0d":"# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test['x'], test['y'], batch_size=50)\nprint(\"test loss\", results)","f0df0374":"check the 1st 5 values ","aff55b54":"lets read the data","727ff290":"lets scale it","31da3bd3":"we got loss which is around 0.08."}}