{"cell_type":{"b85d5c74":"code","317eeb80":"code","e838d9a9":"code","7e2fb9c4":"code","69f1754c":"code","157bc4f7":"code","5fe9bc77":"code","0db0e48c":"code","2f1f1115":"code","9d7b46c2":"code","039afcd1":"code","a6c5fdb7":"code","aafa54f1":"code","b853da76":"code","3cf30cb8":"code","71c0ae3e":"code","cc12122b":"code","2bf49ae3":"code","75d1eb64":"code","45f01113":"code","6de676f0":"code","f0da86ef":"code","118d62c1":"code","2626c3e8":"code","d5039da8":"code","8f688b61":"code","d839c868":"code","c98260dd":"code","f717d788":"code","9442ed12":"code","f6d3232a":"code","6b0abba3":"code","16292cd6":"code","4107ac8e":"code","91be29eb":"code","2eb3034a":"code","37de5e69":"code","683b79a9":"code","4cad2926":"code","d087dc5d":"code","11927990":"code","4ab3691c":"code","3cb08b21":"code","6ee4e55d":"code","b9905853":"code","317604bb":"code","9e0668cd":"markdown","40eaa47d":"markdown","0eb629b4":"markdown","56798d79":"markdown","86c2229a":"markdown","7e11a486":"markdown","2c6493e0":"markdown","aebe4fe8":"markdown","72f907e9":"markdown","34944ca5":"markdown","4931417a":"markdown","f4f7e1d2":"markdown","5445f888":"markdown","6100a816":"markdown","0b69a668":"markdown"},"source":{"b85d5c74":"import re,string,nltk\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer \nimport numpy as np\nimport pandas as pd\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nimport csv\nimport string\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer  # https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.TfidfVectorizer.html\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom collections import Counter\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score\nimport math\nfrom sklearn.naive_bayes import MultinomialNB","317eeb80":"data = pd.read_csv('..\/input\/mediaeval2015\/mediaeval-2015-trainingset.txt', sep = '\\t')\ndata.head()","e838d9a9":"data.info()","7e2fb9c4":"data.columns = [\"tweetId\", \"tweetText\", \"userId\", \"imageId(s)\",\"username\",\"timestamp\",\"label\"]\ndata['label'].value_counts()","69f1754c":"data=data.drop_duplicates(subset=['tweetText'])\ndata['label'].value_counts()","157bc4f7":"data.info()","5fe9bc77":"#you may want to change it later so that no . or , are left at the end\ndef get_hashtags(text):\n    words = text.split(\" \")\n    hashtags = [word for word in words if (word != \"\" and word[0]=='#')]\n    return hashtags\n    \ndef get_tags(text):\n    words = text.split(\" \")\n    tags = [word for word in words if (word != \"\" and word[0]=='@')]\n    return tags\n\ndef get_uppercase_ratio(text):\n    upper = 0\n    lower = 0\n    for character in text:\n        if character.islower():\n            lower = lower + 1\n        elif character.isupper():\n            upper = upper + 1\n    if upper == 0 and lower == 0:\n        return 0\n    else:\n        return math.floor((upper\/lower)*100)","0db0e48c":"#data['hashtags'] = data['tweetText'].apply(get_hashtags)\n# data['tags'] = data['tweetText'].apply(get_tags)\ndata['newFeature'] = data['tweetText'].apply(get_uppercase_ratio)\ndata.head()","2f1f1115":"def process_text(text): #should probably get rid of all the remaining hashtags ..or not \n    #text = translator.translate(text).text #changing all the strings to english, I can add a column for language later\n    text = text.translate(str.maketrans('', '', string.punctuation)) #getting rid of the punctuation\n    text_tokens = nlp(text)\n    text_tokens = [token.lemma_ for token in text_tokens if not token.is_stop] #getting rid of hashtags and tags , and token != \"\" and token[0] not in ['@', '#'])\n    return \" \".join(text_tokens)","9d7b46c2":"def preprocess_text(text):\n    text = text.lower()\n    new_text = []\n    for t in text.split(\" \"):\n        t = '' if (t.startswith('http')) else t #t = '' if (t.startswith('@') or t.startswith('#') or  t.startswith('http')) else t\n        if t != '':\n            new_text.append(t)\n    return \" \".join(new_text)","039afcd1":"def labels_to_numbers(label):\n    if label[0] == 'r':\n        return 0\n    else:\n        return 1","a6c5fdb7":"data['tweetText'] = data['tweetText'].apply(preprocess_text)\ndata['label'] = data['label'].apply(labels_to_numbers)\ndata=data.dropna()\ndata.head()","aafa54f1":"data['tweetTextTokens'] = data['tweetText'].apply(process_text)\ndata=data.dropna()\ndata.head()\ndata = data.drop(columns=['timestamp', 'username', 'userId', 'tweetText'])","b853da76":"test_data = pd.read_csv('..\/input\/mediaeval2015\/mediaeval-2015-testset.txt', sep = '\\t')\ntest_data.head()\n#test_data['hashtags'] = test_data['tweetText'].apply(get_hashtags)\n# test_data['tags'] = test_data['tweetText'].apply(get_tags)\ntest_data['newFeature'] = test_data['tweetText'].apply(get_uppercase_ratio)\ntest_data['tweetText'] = test_data['tweetText'].apply(preprocess_text)\ntest_data=test_data.dropna()\ntest_data['tweetTextTokens'] = test_data['tweetText'].apply(process_text)\ntest_data=test_data.dropna()\ntest_data['label'] = test_data['label'].apply(labels_to_numbers)\ntest_target = test_data['label']\ntest_data = test_data.drop(columns=['label', 'timestamp', 'username', 'userId', 'tweetText'])","3cf30cb8":"test_data.head()","71c0ae3e":"test_target.head()","cc12122b":"def evaluate(prediction, target):\n    compare = []\n    for i in range(0, len(prediction)):\n        if prediction[i] == target[i]:\n            if target[i]==0:\n                tmp ='TN'\n            else:\n                tmp = 'TP'\n        else:\n            if target[i]==0:\n                tmp ='FN'\n            else:\n                tmp = 'FP'\n        compare.append(tmp)\n        r = Counter(compare)\n    return r","2bf49ae3":"# train_data = data['tweetTextTokens']\ntrain_target = data['label']\ntrain_data = data.drop(columns=['label'])","75d1eb64":"tfid_vectorizer = TfidfVectorizer()\nvectorized_train = tfid_vectorizer.fit_transform(train_data['tweetTextTokens'])\nvectorized_test = tfid_vectorizer.transform(test_data['tweetTextTokens'])","45f01113":"count_vectorizer = CountVectorizer()\nvectorized_train2 = count_vectorizer.fit_transform(train_data['tweetTextTokens'])\nvectorized_test2 = count_vectorizer.transform(test_data['tweetTextTokens'])","6de676f0":"dtree_clf = DecisionTreeClassifier(random_state=42)\ndtree_clf.fit(vectorized_train, train_target)\ndtree_pred = dtree_clf.predict(vectorized_test)\nprint (f1_score(test_target, dtree_pred, average='micro'))\nprint(classification_report(test_target, dtree_pred))","f0da86ef":"dtree_clf2 = DecisionTreeClassifier(random_state=42)\ndtree_clf2.fit(vectorized_train2, train_target)\ndtree_pred2 = dtree_clf2.predict(vectorized_test2)\nprint (f1_score(test_target, dtree_pred2, average='micro'))\nprint(classification_report(test_target, dtree_pred2))","118d62c1":"from sklearn.ensemble import RandomForestClassifier\nforest_clf = RandomForestClassifier(random_state=42)\nforest_clf.fit(vectorized_train, train_target)\nforest_pred = forest_clf.predict(vectorized_test)\nprint (f1_score(test_target, forest_pred, average='micro'))\nprint(classification_report(test_target, forest_pred))","2626c3e8":"forest_clf2 = RandomForestClassifier(random_state=42)\nforest_clf2.fit(vectorized_train2, train_target)\nforest_pred2 = forest_clf2.predict(vectorized_test2)\nprint (f1_score(test_target, forest_pred2, average='micro'))\nprint(classification_report(test_target, forest_pred2))","d5039da8":"from sklearn.svm import SVC\nsvc_clf = SVC(random_state=42, probability = True)\nsvc_clf.fit(vectorized_train, train_target)\nsvc_pred = svc_clf.predict(vectorized_test)\nprint (f1_score(test_target, svc_pred, average='micro'))\nprint(classification_report(test_target, svc_pred))","8f688b61":"svc_clf2 = SVC(random_state=42, probability = True)\nsvc_clf2.fit(vectorized_train2, train_target)\nsvc_pred2 = svc_clf2.predict(vectorized_test2)\nprint (f1_score(test_target, svc_pred2, average='micro'))\nprint(classification_report(test_target, svc_pred2))","d839c868":"from sklearn.linear_model import LogisticRegression\nlog_clf = LogisticRegression(random_state=42)\nlog_clf.fit(vectorized_train, train_target)\nlog_pred = log_clf.predict(vectorized_test)\nprint (f1_score(test_target, log_pred, average='micro'))\nprint(classification_report(test_target, log_pred))","c98260dd":"log_clf2 = LogisticRegression(random_state=42)\nlog_clf2.fit(vectorized_train2, train_target)\nlog_pred2 = log_clf2.predict(vectorized_test2)\nprint (f1_score(test_target, log_pred2, average='micro'))\nprint(classification_report(test_target, log_pred2))","f717d788":"nb_clf = MultinomialNB()\nnb_clf.fit(vectorized_train, train_target)\nnb_pred = nb_clf.predict(vectorized_test)\nprint (f1_score(test_target, nb_pred, average='micro'))\nprint(classification_report(test_target, nb_pred))","9442ed12":"nb_clf2 = MultinomialNB()\nnb_clf2.fit(vectorized_train2, train_target)\nnb_pred2 = nb_clf2.predict(vectorized_test2)\nprint (f1_score(test_target, nb_pred2, average='micro'))\nprint(classification_report(test_target, nb_pred2))","f6d3232a":"from sklearn.ensemble import VotingClassifier\nvoting_clf = VotingClassifier(estimators = [('log', log_clf),\n                                            ('svc', svc_clf),\n                                            ('nb', nb_clf),\n                                            ('dt', dtree_clf)],\n                             voting = 'soft')\nvoting_clf.fit(vectorized_train, train_target)\nvoting_pred = voting_clf.predict(vectorized_test)\nprint (f1_score(test_target, voting_pred, average='micro'))\nprint (classification_report(test_target, voting_pred))","6b0abba3":"voting_clf2 = VotingClassifier(estimators = [('dt', dtree_clf),\n                                            ('log', log_clf),\n                                            ('svc', svc_clf),\n                                            ('nb', nb_clf)],\n                             voting = 'hard')\nvoting_clf2.fit(vectorized_train, train_target)\nvoting_pred2 = voting_clf2.predict(vectorized_test)\nprint (f1_score(test_target, voting_pred2, average='micro'))\nprint (classification_report(test_target, voting_pred2))","16292cd6":"voting_clf3 = VotingClassifier(estimators = [('log', log_clf),\n                                            ('svc', svc_clf),\n                                            ('dt', dtree_clf)],\n                             voting = 'hard')\nvoting_clf3.fit(vectorized_train2, train_target)\nvoting_pred3 = voting_clf3.predict(vectorized_test2)\nprint (f1_score(test_target, voting_pred3, average='micro'))\nprint (classification_report(test_target, voting_pred3))","4107ac8e":"voting_clf4 = VotingClassifier(estimators = [('log', log_clf),\n                                            ('svc', svc_clf),\n                                            ('dt', dtree_clf)],\n                             voting = 'soft')\nvoting_clf4.fit(vectorized_train2, train_target)\nvoting_pred4 = voting_clf4.predict(vectorized_test2)\nprint (f1_score(test_target, voting_pred4, average='micro'))\nprint (classification_report(test_target, voting_pred4))","91be29eb":"from sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import Normalizer\n\ndt_pipeline = Pipeline([('union', ColumnTransformer([('tfidf',  TfidfVectorizer(), 'tweetTextTokens'),\n                                                  (\"norm1\", Normalizer(), ['newFeature'])])),   \n                     ('dt_clf', DecisionTreeClassifier(random_state = 42))])\ndt_pipeline.fit(train_data, train_target)\ndt_predictions = dt_pipeline.predict(test_data)\nprint (f1_score(test_target, dt_predictions, average='micro'))","2eb3034a":"dt_pipeline2 = Pipeline([('union', ColumnTransformer([('cv',  CountVectorizer(), 'tweetTextTokens'),\n                                                  (\"norm1\", Normalizer(), ['newFeature'])])),   \n                     ('dt_clf', DecisionTreeClassifier(random_state = 42))])\ndt_pipeline2.fit(train_data, train_target)\ndt_predictions2 = dt_pipeline2.predict(test_data)\nprint (f1_score(test_target, dt_predictions2, average='micro'))","37de5e69":"rf_pipeline = Pipeline([('union', ColumnTransformer([('tfidf',  TfidfVectorizer(), 'tweetTextTokens'),\n                                                     (\"norm1\", Normalizer(), ['newFeature'])])),   \n                     ('rf_clf', RandomForestClassifier(random_state = 42))])\nrf_pipeline.fit(train_data, train_target)\nrf_predictions = rf_pipeline.predict(test_data)\nprint (f1_score(test_target, rf_predictions, average='micro'))","683b79a9":"rf_pipeline2 = Pipeline([('union', ColumnTransformer([('tfidf',  CountVectorizer(), 'tweetTextTokens'),\n                                                     (\"norm1\", Normalizer(), ['newFeature'])])),   \n                     ('rf_clf', RandomForestClassifier(random_state = 42))])\nrf_pipeline2.fit(train_data, train_target)\nrf_predictions2 = rf_pipeline2.predict(test_data)\nprint (f1_score(test_target, rf_predictions2, average='micro'))","4cad2926":"sv_pipeline = Pipeline([('union', ColumnTransformer([('tfidf',  TfidfVectorizer(), 'tweetTextTokens'),\n                                                   (\"norm1\", Normalizer(), ['newFeature'])])),   \n                     ('svc_clf', SVC(random_state=17, probability = True))])\nsv_pipeline.fit(train_data, train_target)\nsv_predictions = sv_pipeline.predict(test_data)\nprint (f1_score(test_target, sv_predictions, average='micro'))","d087dc5d":"sv_pipeline2 = Pipeline([('union', ColumnTransformer([('tfidf',  CountVectorizer(), 'tweetTextTokens'),\n                                                   (\"norm1\", Normalizer(), ['newFeature'])])),   \n                     ('svc_clf', SVC(random_state=17, probability = True))])\nsv_pipeline2.fit(train_data, train_target)\nsv_predictions2 = sv_pipeline2.predict(test_data)\nprint (f1_score(test_target, sv_predictions2, average='micro'))","11927990":"lr_pipeline = Pipeline([('union', ColumnTransformer([('tfidf',  TfidfVectorizer(), 'tweetTextTokens'),\n                                                     (\"norm1\", Normalizer(), ['newFeature'])])),   \n                        ('lr_clf', LogisticRegression(random_state=17))])\nlr_pipeline.fit(train_data, train_target)\nlr_predictions = lr_pipeline.predict(test_data)\nprint (f1_score(test_target, lr_predictions, average='micro'))","4ab3691c":"lr_pipeline2 = Pipeline([('union', ColumnTransformer([('tfidf',  CountVectorizer(), 'tweetTextTokens'),\n                                                     (\"norm1\", Normalizer(), ['newFeature'])])),   \n                        ('lr_clf', LogisticRegression(random_state=17))])\nlr_pipeline2.fit(train_data, train_target)\nlr_predictions2 = lr_pipeline2.predict(test_data)\nprint (f1_score(test_target, lr_predictions2, average='micro'))","3cb08b21":"nb_pipeline = Pipeline([('union', ColumnTransformer([('tfidf',  TfidfVectorizer(), 'tweetTextTokens'),\n                                                     (\"norm1\", Normalizer(), ['newFeature'])])),   \n                        ('nb_clf', MultinomialNB())])\nnb_pipeline.fit(train_data, train_target)\nnb_predictions = nb_pipeline.predict(test_data)\nprint (f1_score(test_target, nb_predictions, average='micro'))\nprint (classification_report(test_target, nb_predictions))","6ee4e55d":"nb_pipeline2 = Pipeline([('union', ColumnTransformer([('tfidf',  CountVectorizer(), 'tweetTextTokens'),\n                                                     (\"norm1\", Normalizer(), ['newFeature'])])),   \n                        ('nb_clf', MultinomialNB())])\nnb_pipeline2.fit(train_data, train_target)\nnb_predictions2 = nb_pipeline2.predict(test_data)\nprint (f1_score(test_target, nb_predictions2, average='micro'))\nprint (classification_report(test_target, nb_predictions2))","b9905853":"voting_pipeline1 = Pipeline([('union', ColumnTransformer([('tfidf',  TfidfVectorizer(), 'tweetTextTokens'),\n                                                         (\"norm1\", Normalizer(norm='l1'), ['newFeature'])])),   \n                            ('voting_clf',VotingClassifier(estimators = [('log', log_clf),\n                                            ('nb', nb_clf),\n                                            ('dtr', dtree_clf)],\n                             voting = 'hard'))])\nvoting_pipeline1.fit(train_data, train_target)\nvoting_predictions1 = voting_pipeline1.predict(test_data)\nprint (f1_score(test_target, voting_predictions1, average='micro'))\nprint (classification_report(test_target, voting_predictions1))","317604bb":"voting_pipeline2 = Pipeline([('union', ColumnTransformer([('tfidf',  TfidfVectorizer(), 'tweetTextTokens'),\n                                                         (\"norm1\", Normalizer(norm='l1'), ['newFeature'])])),   \n                            ('voting_clf2', VotingClassifier(estimators = [('log', log_clf),\n                                            ('nb', nb_clf),\n                                            ('dtr', dtree_clf)],\n                             voting = 'soft'))])\nvoting_pipeline2.fit(train_data, train_target)\nvoting_predictions2 = voting_pipeline2.predict(test_data)\nprint (f1_score(test_target, voting_predictions2, average='micro'))","9e0668cd":"Decision tree classifier:","40eaa47d":"Adding another feature for capital letters ratio","0eb629b4":"NB","56798d79":"New Voting classifier(s):","86c2229a":"Voting classifier(s)","7e11a486":"Logistic Regresssion","2c6493e0":"New random forrest classifier","aebe4fe8":"Vectorizing train and test set","72f907e9":"New decision tree classifier","34944ca5":"Putting the test data in an usable format","4931417a":"Evaluation","f4f7e1d2":"SVC","5445f888":"New logistic regression","6100a816":"Random Forrest Classifier","0b69a668":"New SVC classifier"}}