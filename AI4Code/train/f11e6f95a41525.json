{"cell_type":{"8f2d06a7":"code","cae198d7":"code","0d1565c2":"code","6133da66":"code","35e95991":"code","4fc3ad4c":"code","c2a68639":"code","0467b9f2":"code","83dd5a86":"code","adf8cb2b":"code","02aff5d8":"code","55bcda85":"code","d69983b3":"code","b0576d23":"code","9d608e90":"code","275587c4":"code","f5276c65":"code","b6f5c360":"code","3e1ba275":"code","f8e628d8":"code","07943257":"code","cb5f6d54":"markdown","04efddeb":"markdown","96fd021f":"markdown","98201629":"markdown","54d19bd7":"markdown","91181b2f":"markdown","7a964899":"markdown","a4c65604":"markdown","8ab4ef1f":"markdown","a1a020aa":"markdown","e7df1702":"markdown","6fbaa9ea":"markdown","1929b717":"markdown","e619aa70":"markdown","7a1cb3b6":"markdown"},"source":{"8f2d06a7":"import re\nimport spacy\nfrom collections import Counter\nimport networkx as nx\nfrom networkx import centrality as cent\nfrom IPython.display import Image","cae198d7":"def _entity_normalizer(entity):\n    \"\"\"Returns a clean entity.\"\"\"\n    \n    ent = entity.text.lower()\n    ent = ent.replace('_','').replace('-','').replace('\\'s','').replace('\\n',' ').strip()\n    if 'sid' in ent: return 'Sid Sawyer'\n    if 'garrick' in ent: return 'David Garrick the younger'\n    if 'emmeline' in ent: return 'Emmeline Grangerford'\n    if 'huck' in ent or 'finn' in ent or 'huckleberry' in ent: return 'Huckleberry Finn'\n    if ent == 'tom' or ent == 'sawyer'  or ent == 'tom sawyer': return 'Tom Sawyer'\n    if 'orleans' in ent: return 'New Orleans'\n    return ent.capitalize()","0d1565c2":"def get_entites_dict_from_paragraph(paragraph, nlp):\n    \"\"\"Returns a dictionary with entities from input paragraph.\"\"\"\n    \n    # instantiate output dictionary\n    output = {'GPE': set(), 'PERSON': set()}\n    \n    # process paragraph\n    doc = nlp(paragraph)\n    \n    # extract places and people entities\n    for entity in doc.ents:\n        if entity.label_ == 'GPE' or entity.label_ == 'PERSON':\n            output[entity.label_].add(_entity_normalizer(entity))  # clean the entity\n            \n    # return the dictionary if contains at least 2 entities\n    return output if len(output['GPE']) + len(output['PERSON']) >= 2 else None","6133da66":"def get_edges_from_entities(entities):\n    \"\"\"\n    Returns a list of edges between entities.\n    \n    An edge is created if 2 entities appear on the same paragraph.\n    \"\"\"\n    \n    edges = set()\n    \n    # links of person and place\n    for loc in entities['GPE']:\n        for person in entities['PERSON']:\n            if loc==person:  # in case spacy identified a person as a location (happens to Jim)\n                continue\n            edges.add(((loc, 'loc'), (person, 'prs')))\n    \n    # links of people\n    for person_1 in entities['PERSON']:\n        for person_2 in entities['PERSON']:\n            # skip same person links\n            if person_1==person_2:\n                continue\n            if person_1 > person_2:\n                person_1, person_2 = person_2, person_1  # switch order to avoid 2-way edges\n            edges.add(((person_1, 'prs'), (person_2, 'prs')))\n            \n    return list(edges)","35e95991":"# open the file\npath = '..\/input\/data\/Huckleberry_Finn.txt'\nwith open(path, 'r') as file:\n    finn = file.read()","4fc3ad4c":"# remove text which is not part of the story\nbegin_ind = re.search(r'CHAPTER I', finn).start()\nend_ind = re.search(r'THE END', finn).end()\nfinn = finn[begin_ind : end_ind]\n\n# lowercase\nfinn = finn.lower()\n\n# replace \"t'word\" with \"the word\"\nfinn = re.sub(r\"[t]\\'(.*)(?=\\s)\", r'the \\1', finn)\n\n# replace \"bekase\" with \"because\"\nfinn = re.sub(r'bekase', 'because', finn)\n\nfinn = re.sub(r\"de bes'\", 'the best', finn)\n\n# split the book to paragraphs\nparagraphs = finn.split(\"\\n\\n\")","c2a68639":"# load english NLP module\nnlp_processor = spacy.load('en_core_web_lg')","0467b9f2":"edges_list = []\n\n# iterate through paragraphs and extract links between places and people or people and people\nfor para in paragraphs:\n    \n    # get entities from paragraph\n    entities = get_entites_dict_from_paragraph(paragraph=para, nlp=nlp_processor)\n    \n    # create edges\n    if entities is not None:\n        edges_list += get_edges_from_entities(entities=entities)\n\n# count occurrences of each edge (number of paragraphs each edge appears)\ncounted_edges = dict(Counter(edges_list))","83dd5a86":"def add_edges(g, attribute, min_occurrences):\n    \"\"\"Add to graph g nodes and edges with corresponding attributes.\"\"\"\n    \n    for edge, occurrences in counted_edges.items():\n        if edge[0][1] == attribute and occurrences >= min_occurrences:\n            g.add_node(edge[0][0], typ = attribute)\n            g.add_node(edge[1][0], typ = 'prs')\n            g.add_edge(edge[0][0], edge[1][0], weight = occurrences)","adf8cb2b":"G = nx.Graph()\n\nadd_edges(g=G, attribute='loc', min_occurrences=1)  # add edge if location-person appears at least once\nadd_edges(g=G, attribute='prs', min_occurrences=2)  # add edge if person-person appears at least twice","02aff5d8":"# export the graph as .gml file, to use Cytoscape\nnx.write_gml(G, \"Huckleberry_Finn_graph.gml\")","55bcda85":"Image(filename='..\/input\/data\/Huckleberry_Finn_Zoom_Out.png')","d69983b3":"Image(filename='..\/input\/data\/Huckleberry_Finn_Zoom_In.png')","b0576d23":"def top_central(graph, centrality_measure, k=10):\n    \"\"\"Returns a list of tuples, which are the top k scored people and the scores according to input centrality measure.\"\"\"\n    \n    # a map of centrality measures to be determined by an input string\n    func = {\n        'closeness': cent.closeness_centrality,\n        'degree': cent.degree_centrality,\n        'betweeness': cent.betweenness_centrality\n    }\n    \n    # create a list of tuples (person, centrality measure score) of input centrality measure\n    output = [(person, score) for person, score in func[centrality_measure](graph).items()]\n    \n    # sort the list by score, top to bottom\n    output.sort(key=lambda tup: tup[1], reverse=True)\n    \n    # return k-top\n    return output[:k]","9d608e90":"PG = nx.Graph()\n\n# add edge if person-person appears at least once\nadd_edges(g=PG, attribute='prs', min_occurrences=1)\n\n# create a subgraph from greatest connected component\ngcc_nodes = max(nx.connected_components(PG), key=len)\nPG = PG.subgraph(gcc_nodes)","275587c4":"# determine number of top scores\nk=6","f5276c65":"# create 3 lists of scores by different centrality measures\ntop_k_closeness_scores = top_central(graph=PG, centrality_measure='closeness', k=k)\ntop_k_betweeness_scores = top_central(graph=PG, centrality_measure='betweeness', k=k)\ntop_k_degree_scores = top_central(graph=PG, centrality_measure='degree', k=k)","b6f5c360":"# an example\ntop_k_betweeness_scores","3e1ba275":"# extract only names from above lists\ntop_k_closeness_names = list(zip(*top_k_closeness_scores))[0]\ntop_k_betweeness_names = list(zip(*top_k_betweeness_scores))[0]\ntop_k_degree_names = list(zip(*top_k_degree_scores))[0]","f8e628d8":"# find names with high closeness-centrality score and low degree-cetrality score\nhigh_closeness_low_degree = [name for name in top_k_closeness_names if name not in top_k_degree_names]\nhigh_closeness_low_degree","07943257":"# find names with high betweenes-centrality score and low degree-cetrality score\nhigh_betweeness_low_degree = [name for name in top_k_betweeness_names if name not in top_k_degree_names]\nhigh_betweeness_low_degree","cb5f6d54":"# Create the network graph","04efddeb":"Depends on the NLP task different pre-processing is needed. <br>\nFor this toy example, not much is needed...","96fd021f":"People nodes are colored green. <br>\nPlaces nodes are colored orange. <br>\nNode size denotes how many distinct people were mentioned with that person or place. <br>\nEdge width denotes how many times (in how many paragraphs) two entities were mentioned together.\n\n** This image was created after using Spacy version 2.1.3 and networkX version 2.2, thus, some inconsistency might be present.","98201629":"# Imports","54d19bd7":"# Extract the data","91181b2f":"# Centrality measures","7a964899":"# Get familiar with a book without reading it\nThis is a short and simple notebook which demonstrates gaining insights by creation of a graph which visualizes the connections network between the main places and people in a book, and by using centrality measures.\n\nI use the following tools:<br>\n1. spaCy - An NLP (natural language processing) package, to perform NER (named entity recognition).\n2. NetwrokX - A package for the creation and manipulation of complex networks.\n3. [Cytoscape](https:\/\/cytoscape.org\/) - An external software, used to visualize the graph.\n\nI create the graph of the book [\"The Adventures of Huckleberry Finn\"](http:\/\/www.gutenberg.org\/files\/76\/76-0.txt), by Mark Twain.","a4c65604":"Centraly measures come to reveal the central nodes, by different aspects.<br>\nWe can reveal a lot without the need for visualization (and when visualziation does not help).<br>","8ab4ef1f":"### Visualization insights","a1a020aa":"Centrality measures tend to be highly correlated.<br>\nHowever, valuable insights could be gained when comparing the results, and looking at the uncorrelated ones.<br>","e7df1702":"### Centrality measures insights:","6fbaa9ea":"- A node with high closeness-centrality score (how close a node is to all other nodes) and a low degree-centrality score (based on the degree of a node), is a node with a central position in the network, because it succeeded in gaining a central position while not creating a lot of edges with other nodes. <br>\nWe can observe that Ben, Phelps and Watson are in central positions in the story.\n\n- High betweenness-centrality nodes are bottlenecks of the network; i.e., most of the paths between communities in the network go through them.<br>\nWe can observe that Mary Jane is such a bottleneck, while not having an high degree-centrality score.","1929b717":"# Visualize the network using Cytoscape:","e619aa70":"Without ever reading \"The Adventures of Huckleberry Finn\", and only by looking at the graph, we can come to the following conclusions: \n- Huckleberry Finn, Tom Sawyer, and Jim are the main characters of the book.\n- The story takes place in different parts of the world, including Middle east, Europe and the USA.\n- Jim and Tom Sawyer had a lot of time together, while Huckleberry Finn never met William the Conqueror.","7a1cb3b6":"This time, the network is composed of people only, to gain some insights about their centrality.<br>\nAs opposed to the people and places network, this time an edge exist if 2 people appear at least once togeher (and not twice).<br>\nIn addition, to avoid high centrality scores in small connected components, I analyze only the greatest connected component.<br>"}}