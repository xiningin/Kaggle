{"cell_type":{"f5c6c9bd":"code","0221dcc2":"code","7e7adfd9":"code","3bf8ce54":"code","97d17473":"code","d1d0b276":"code","84244db9":"code","dbee96a1":"code","2eb33e31":"code","1ede1012":"code","d969bb55":"code","84c5a998":"code","176cfe18":"code","93d38a54":"code","e43d4c18":"code","da1c0b74":"code","aa7df650":"code","5cbc0479":"code","305d8f49":"code","8f09fa70":"code","d6e5fb8e":"code","2ef924e8":"code","afe0e0ab":"code","99f0e2b8":"markdown","ba6a48a6":"markdown","256a2ff8":"markdown","e11038aa":"markdown","2425f784":"markdown","b5260eaa":"markdown"},"source":{"f5c6c9bd":"# !pip install git+https:\/\/github.com\/qubvel\/segmentation_models.pytorch","0221dcc2":"import os\nimport copy\nimport cv2\nimport random\nimport pydicom\nimport torch\nimport time\nimport math\nimport shutil\nimport rasterio\n\nimport pandas as pd\nimport numpy as np\nimport PIL as pil\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport pytorch_lightning as pl\nimport albumentations as A\nfrom pytorch_lightning import loggers as pl_loggers\nfrom scipy.ndimage.interpolation import zoom\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate \n)","7e7adfd9":"# def seed_everything(seed):\n#     random.seed(seed)\n#     os.environ['PYTHONHASHSEED'] = str(seed)\n#     np.random.seed(seed)\n#     torch.manual_seed(seed)\n#     torch.cuda.manual_seed(seed)\n#     torch.backends.cudnn.deterministic = True\n#     torch.backends.cudnn.benchmark = True\n\n# seed_everything(cfg['seed'])","3bf8ce54":"input_dir = '..\/input\/hubmap-kidney-segmentation'\nerrors_dir = '..\/input\/errors'\nerrors_csv = f'{errors_dir}\/errors.csv'\n\nimg_size = 1024","97d17473":"df = pd.read_csv(errors_csv)\ndf.head()","d1d0b276":"eps = 1e-7\ndf['filename'] = df.apply( lambda row: f'{row.id}-{row.i}-{row.j}.jpeg', axis=1)\ndf['precision'] = (df.tp + eps) \/ (df.tp + df.fp + eps)\ndf['recall'] = (df.tp + eps) \/ (df.tp + df.fn + eps)\ndf['dice'] = (2 * df.tp + eps) \/ (2 * df.tp + df.fp + df.fn + eps)\ndf.sample(5)","84244db9":"def plot_imgs(imgs_df, columns = 4):\n    imgs = imgs_df.filename.tolist()\n    \n    rows = len(imgs) \/\/ columns\n    \n    fig, axs = plt.subplots(rows, columns, figsize=(20,rows*5))\n    \n    for ax, img, im,  in zip(axs.flatten(), imgs, imgs_df.id.tolist()):\n        ax.imshow(pil.Image.open(f'{errors_dir}\/imgs\/{img}'))\n        ax.text(500,500,img, color='blue')\n\n    plt.show()","dbee96a1":"count = 32\nworst = [df.nsmallest(count, typ) for typ in ['precision', 'recall', 'dice']]","2eb33e31":"plot_imgs(worst[0])","1ede1012":"plot_imgs(worst[1], columns=3)","d969bb55":"plot_imgs(worst[2])","84c5a998":"worst_fn = df.nlargest(32, 'fn')\nworst_fn.head()","176cfe18":"plot_imgs(worst_fn)","93d38a54":"df.nlargest(32, 'fp')","e43d4c18":"print('worst recall; worst fn')\nworst[1].id.value_counts(), worst_fn.id.value_counts()","da1c0b74":"df.fp.sum(), df.fn.sum(), ","aa7df650":"df.groupby(['id']).fn.sum().sort_values(ascending=False), df.groupby(['id']).fp.sum().sort_values(ascending=False),","5cbc0479":"thresh = 0.4\ndf[df.recall < thresh].shape, df[df.precision < thresh].shape","305d8f49":"identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n\ndef reconstruct_img(tiff_id, tiffs, scale=10, typ='imgs'):\n    tif = rasterio.open(os.path.join(input_dir, 'train', f'{tiff_id}.tiff'), transform=identity)\n    shape = tif.shape\n\n    shape = (shape[0] \/\/ scale, shape[1] \/\/ scale, 3)\n\n    gray = 122\n    patched = np.ones(shape, dtype=np.uint8)*gray\n    print(tiff_id, shape, patched.shape)\n\n    for f in tiffs:\n        file = f.split('.')[0]\n\n        row = int(file.split('-')[1])\n        column = int(file.split('-')[2])\n        file = file.split('-')[0]\n\n        sz = img_size\/\/scale\n\n        xstart = row*sz\n        xstop = xstart+sz\n\n        ystart = column*sz\n        ystop = ystart+sz\n\n        pt = os.path.join(errors_dir, typ, f)\n\n        patch = np.array(pil.Image.open(pt))\n        patch = cv2.resize(patch,(sz,sz))\n\n        patched[xstart:xstop, ystart:ystop] = patch\n        \n    return patched\n\ndef reconstruct_imgs(df, scale=10, typ='imgs'):\n    imgs = {}\n    for tiff_id in df.id.unique().tolist():\n        tiffs = df[df.id == tiff_id].filename.tolist()\n        \n        patch = reconstruct_img(tiff_id, tiffs, scale=scale, typ=typ)        \n        imgs[tiff_id] = patch\n\n    return imgs","8f09fa70":"imgs = reconstruct_imgs(df,scale=5)","d6e5fb8e":"def save_result(imgs, dr='results'):\n    os.mkdir(dr)\n    \n    for k, v in imgs.items():\n        pl = pil.Image.fromarray(v)\n\n        pl.save(f'{dr}\/{k}.jpeg')\n\n    shutil.make_archive(dr, 'zip', dr)\n    shutil.rmtree(dr)","2ef924e8":"save_result(imgs)","afe0e0ab":"for k, v in imgs.items():\n    plt.figure(figsize = (20,20))\n    plt.imshow(v)\n    plt.title(k)\n    \nplt.show()","99f0e2b8":"# Plot worst predictions","ba6a48a6":"# Plot tiffs","256a2ff8":"**2.Recall**","e11038aa":"**1. Precision**","2425f784":"**4. FN**","b5260eaa":"**3.Dice**"}}