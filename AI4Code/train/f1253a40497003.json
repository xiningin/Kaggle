{"cell_type":{"717b28e0":"code","6537fed9":"code","857bdfbc":"code","e6f14b03":"code","38bb8b1d":"code","3c1e8d21":"code","5b8168db":"code","e68236d8":"code","e77bca91":"code","b03061ea":"code","4c8b4255":"code","6b950d20":"code","0e4e366b":"code","02e7bd08":"code","0a1444bf":"code","7a351c10":"code","d0d34af4":"markdown","f533c992":"markdown","93d6b8a6":"markdown"},"source":{"717b28e0":"import numpy as np\nimport pandas\nimport matplotlib.pyplot as plt\n","6537fed9":"dataset = pandas.read_csv('..\/input\/airlinepassengers\/airline-passengers.csv', usecols=[1])#Return a subset of the columns. If list-like)\n","857bdfbc":"plt.plot(dataset)\nplt.show()","e6f14b03":"dataset.info()","38bb8b1d":"dataset.head()","3c1e8d21":"import numpy\nimport matplotlib.pyplot as plt\nimport pandas\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","5b8168db":"# fix random seed for reproducibility\nnumpy.random.seed(7)","e68236d8":"# load the dataset\ndataframe = pandas.read_csv('..\/input\/airlinepassengers\/airline-passengers.csv', usecols=[1])\ndataset = dataframe.values\ndataset = dataset.astype('float32')","e77bca91":"# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","b03061ea":"# split into train and test sets\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(len(train), len(test))","4c8b4255":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-look_back-1):\n\t\ta = dataset[i:(i+look_back), 0]\n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + look_back, 0])\n\treturn numpy.array(dataX), numpy.array(dataY)","6b950d20":"# reshape into X=t and Y=t+1\nlook_back = 1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)","0e4e366b":"# reshape input to be [samples, time steps, features]\ntrainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","02e7bd08":"# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=100, batch_size=1,verbose=2)","0a1444bf":"# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","7a351c10":"# shift train predictions for plotting\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n# shift test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","d0d34af4":"The network has a visible layer with 1 input, a hidden layer with 4 LSTM blocks or neurons, and an output layer that makes a single value prediction. The default sigmoid activation function is used for the LSTM blocks. The network is trained for 100 epochs and a batch size of 1 is used.\n\n","f533c992":"We can load this dataset easily using the Pandas library. We are not interested in the date, given that each observation is separated by the same interval of one month. Therefore, when we load the dataset we can exclude the first column.\n\nOnce loaded we can easily plot the whole dataset. The code to load and plot the dataset is listed below.\n\n","93d6b8a6":"The problem we are going to look at in this post is theInternational Airline Passengers prediction problem.\n\nThis is a problem where, given a year and a month, the task is to predict the number of international airline passengers in units of 1,000. The data ranges from January 1949 to December 1960, or 12 years, with 144 observations."}}