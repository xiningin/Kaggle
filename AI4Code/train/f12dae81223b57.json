{"cell_type":{"c81bc39e":"code","36569270":"code","742d7dbf":"code","05f274f9":"code","20d1407e":"code","6c5b0d99":"code","9b7645c0":"code","e7335144":"code","118aa920":"markdown","20f65a42":"markdown","87bb39b0":"markdown","170a2720":"markdown","a74ae974":"markdown","062d7e9c":"markdown"},"source":{"c81bc39e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\ndf = pd.read_csv(\"..\/input\/creditcard.csv\",encoding=\"utf-8\")\n\n# Fill NA\/NaN values with 0\ndf = df.fillna(0)\ndf.head(5)\n","36569270":"print(\"N\u00famero de amostras da classe 0 (transa\u00e7\u00e3o normal):\")\nprint(sum(df.Class==0))\n\nprint(\"N\u00famero de amostras da classe 1 (transa\u00e7\u00e3o fraudulenta):\")\nprint(sum(df.Class==1))","742d7dbf":"from sklearn.model_selection import train_test_split\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Separando os dados em X, com os dados\/features e y com os labels\nX = df.iloc[:, df.columns != \"Class\"]\ny = df.iloc[:, df.columns == \"Class\"]\n\n# Separando os dados em test e train\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n\n# Undersampling data\nrus = RandomUnderSampler(random_state=0)\nX_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n\nprint(\"N\u00famero de amostras na base de treino da classe 0 (transa\u00e7\u00e3o normal):\")\nprint(sum(y_resampled==0))\n\nprint(\"N\u00famero de amostras na base de treino da classe 1 (transa\u00e7\u00e3o fraudulenta):\")\nprint(sum(y_resampled==1))","05f274f9":"from sklearn.metrics import confusion_matrix, classification_report\ndef evaluates_model(model, X, y, probability):\n    '''\n    Reveices a model, and prints report and confusion matrix\n    for a given dataset and a defined probability.\n    '''\n\n    predicted = model.predict_proba(X)\n    predicted = [0 if x[0]>probability else 1 for x in predicted]\n    target_names = ['Normal', 'Fraude']\n    print(classification_report(y, predicted, target_names=target_names))\n    print(\"Confusion matrix:\")\n    print(confusion_matrix(y, predicted))\n    return predicted\n\nfrom sklearn.metrics import recall_score, precision_score, f1_score\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plotRecallPrecision(mdl, X_test, y_test, space):\n    recall_axis = []\n    prec_axis = []\n    f1_axis = []\n    x_axis = np.linspace(space[0],space[1], 20)\n    for prob in x_axis:\n        predicted = mdl.predict_proba(X_test)\n        predicted = [0 if x[0]>prob else 1 for x in predicted]\n        # Calculating the recall \n        recall_axis.append(np.trunc(recall_score(y_test, predicted, average='binary')*100))\n        # Calculating the precision \n        prec_axis.append(np.trunc(precision_score(y_test, predicted, average='binary')*100))\n        # Calculating the precision \n        f1_axis.append(np.trunc(f1_score(y_test, predicted, average='binary')*100))\n    # Plot Grid search scores\n    _, ax = plt.subplots(1,1)\n    ax.set_title(\"Detec\u00e7\u00e3o de Fraudes\", fontsize=20, fontweight='bold')\n    ax.set_ylabel(\"%\", fontsize=16)\n    ax.set_xlabel(\"Probabilidade de corte\", fontsize=16)\n    ax.plot(x_axis, prec_axis, label='Precision')\n    ax.plot(x_axis, recall_axis, label='Recall')\n    ax.plot(x_axis, f1_axis, label='f1 score')\n    ax.legend()\n    ax.grid('on')","20d1407e":"from xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nmdl = ExtraTreesClassifier(n_estimators=25, max_depth=10, bootstrap=True, n_jobs = 1,\n                            max_leaf_nodes=40, min_samples_leaf = 2, \n                            min_samples_split=5, random_state=10)\nmdl.fit(X_resampled, y_resampled.ravel())\n\nplotRecallPrecision(mdl, X_test, y_test,[0.1,0.7])\n\nprint(\"_____________________________________________________________\")\nprint(\"\\nModelo: ExtraTreesClassifier   Probabilidade de corte: 0.3\\n\")\n_ = evaluates_model(mdl, X_test, y_test, .3)","6c5b0d99":"mdl = RandomForestClassifier(n_estimators=25, max_depth=10, bootstrap=True, n_jobs = 1,\n                            max_leaf_nodes=40, min_samples_leaf = 2, \n                            min_samples_split=5, random_state=10)\nmdl.fit(X_resampled, y_resampled.ravel())\n\nplotRecallPrecision(mdl, X_test, y_test,[0.1,0.7])\n\nprint(\"_____________________________________________________________\")\nprint(\"\\nModelo: RandomForest   Probabilidade de corte: 0.4\\n\")\n_ = evaluates_model(mdl, X_test, y_test, .4)","9b7645c0":"mdl = XGBClassifier()\nmdl.fit(X_train, y_train)\n\n#X_test = X_test[X_train.columns]\n# Todo, solve problem with \n\nplotRecallPrecision(mdl, X_test, y_test, [0.4,0.98])","e7335144":"print(\"_____________________________________________________________\")\nprint(\"\\nModelo:  XGBClassifier   Probabilidade de corte: 0.8\\n\")\n_ = evaluates_model(mdl, X_test, y_test, .8)\n\n\nprint(\"_____________________________________________________________\")\nprint(\"\\nModelo:  XGBClassifier   Probabilidade de corte: 0.95\\n\")\n_ = evaluates_model(mdl, X_test, y_test, .95)","118aa920":"Em seguida, vamos treinar alguns modelos e avali\u00e1-los.","20f65a42":"## Detec\u00e7\u00e3o de fraude em transa\u00e7\u00f5es de cart\u00f5es de cr\u00e9dito\n\nEsta base de dados traz uma s\u00e9rie transa\u00e7\u00f5es de cart\u00e3o de cr\u00e9dito e features em PCA que n\u00e3o sabemos quais s\u00e3o as suas descri\u00e7\u00f5es, o que limita nossa capacidade de feature engineering. A princ\u00edpio, iremos utilizar todas a features.\n\nAs \u00fanicas features conhecidas s\u00e3o: \n- Amount -> valor da transa\u00e7\u00e3o\n- Time -> tempo em rela\u00e7\u00e3o a primeira transa\u00e7\u00e3o da base de dados\n\nA primeira coisa a ser feita \u00e9 carregar algumas bibliotecas b\u00e1sicas, carregar a base de dados que est\u00e1 em formato CSV, completar com 0 caso haja algum NA valor, e imprimir as primeiras 5 linhas.","87bb39b0":"Devido ao grande desbalanceamento de dados \u00e9 necess\u00e1rio que seja aplicado alguma estrat\u00e9gia para equilibrar o n\u00famero de amostras de cada classe. \n\nEntre as estrat\u00e9gias mais comuns est\u00e3o:\n- Oversampling -> Aumentar o n\u00famero da classe com menor n\u00famero de representantes.\n        * RandomOverSampler -> Consiste em duplicar algumas amostras selecionadas aleatoriamente da classe minorit\u00e1ria.\n        * SMOTE -> Cria novas amostras baseado na interpola\u00e7\u00e3o de amostras da classe minorit\u00e1ria.\n        * ADASYN -> Cria novas amostras para a classe minorit\u00e1ria de acordo com as amostras que s\u00e3o pouco separ\u00e1veis desta mesma classe. \n\n- Undersampling -> Diminuir o n\u00famero de amostras da classe com maior n\u00famero de representantes.\n        * RandomUnderSamples -> Seleciona aleatoriamente algumas amostras da classe minorit\u00e1ria para serem retiradas.\n        * NearMiss -> Retira algumas amostras da classe minorit\u00e1ria de acordo com alguma heuristica, como vizinhos mais pr\u00f3ximos.\n      \nAs t\u00e9cnicas acima devem ser testadas para encontrar a que apresente melhor resultado. \u00c9 importante lembrar que estas ferramentas devem ser aplicadas apenas na base de treinamento, j\u00e1 que a base de teste deve manter sua integridade para representar as condi\u00e7\u00f5es reais de aplica\u00e7\u00e3o.\n\nVamos ent\u00e3o separar a base de dados para treino e teste em 70\/30 e aplicar RandomUnderSamples","170a2720":"Por se tratar de um problema de detec\u00e7\u00e3o de fraude, \u00e9 esperado que uma das classes apresente mais ocorr\u00eancias que a outra. O que pode ser confirmado a seguir:","a74ae974":"## Conclus\u00f5es\n\nForam avaliados os algoritmos de ExtraTreesClassifier, RandomForestclassifier e XGBClassifier. Sendo utilizada os dados com undersampling aleat\u00f3rio para ExtraTreesClassifier e RandomForestclassifier e completos para XGBClassifier.\n\nOs gr\u00e1ficos apresentados nos fornecem informa\u00e7\u00f5es importantes e permitem uma avalia\u00e7\u00e3o de qual modelo se comporta melhor de acordo com a m\u00e9trica mais importante para a aplica\u00e7\u00e3o.\n\nO resultado dos algoritmos \u00e9 praticamente similar e o XGBoost apresentou o melhor f1 de 0.84.\n\nEstes foram os primeiros passos para desenvolvimento de um modelo para detec\u00e7\u00e3o de fraude em cart\u00e3o de cr\u00e9dito. Existe uma s\u00e9rie de coisas que podem ser feitas buscando aperfei\u00e7oar o modelo, tais quais:\n    - Feature selection -> estamos usando todas as features dispon\u00edveis, mas algumas delas podem n\u00e3o ser interessantes para o modelo. Retirar features de pouca import\u00e2ncia pode melhorar o modelo.\n    - Features engineering -> apesar de n\u00e3o termos informa\u00e7\u00f5es sobre a features, estam poderiam ser avaliadas por sua correla\u00e7\u00e3o ou outros m\u00e9todos para aplicar alguma t\u00e9cnica de feature engineering. (Ex. criar features baseadas na faixa hor\u00e1ria, faixa de gastos ou features fortemente relacionadas)\n    - Otimiza\u00e7\u00e3o de hyperparameters -> foram utilizados hiper par\u00e2metros escolhidos manualmente. Seria interessante fazer uma busca pelos melhores hiper par\u00e2metros. (Ex. GridCV)\n    - Testar outras t\u00e9cnicas de downsampling e oversampling.\n    \nDevido a base de dados ser relativamente pequena, considerada a quantidade de informa\u00e7\u00f5es que podem ser fornecidas por uma instui\u00e7\u00e3o banc\u00e1ria (pode-se f\u00e1cilmente levantar transa\u00e7\u00f5es de um ano completo), o ideal para avaliar de forma efetiva os modelos seria levantar uma base de dados maior. No caso de uma base de dados mais representativa, as t\u00e9cnicas acima deveriam ser experimentadas em um esquema de cross validation. Os melhores modelos deveriam ter seu tempo de execu\u00e7\u00e3o medidos, e o que apresentasse o tempo de execu\u00e7\u00e3o abaixo do m\u00ednimo para esse tipo de opera\u00e7\u00e3o (abaixo de <20ms provavelmente) deve ser escalado a n\u00edvel do banco.","062d7e9c":"Uma vez que j\u00e1 temos nossa base de dados balanceada e dividida para treinamento e teste, podemos escolher alguns modelos para avaliar.\n\nAlguns dos algoritmos que podem ser avaliados por mostrarem bons resultados em base de dados semelhantes s\u00e3o:\n    - LogisticRegression\n    - RandomForest\n    - ExtraTreesClassifier\n    - XGBoost\n    - SVM\n    \n Devido ao desbalanceamento da base de teste \u00e9 necess\u00e1rio recorrer a uma m\u00e9trica de avalia\u00e7\u00e3o diferente de acur\u00e1cia. J\u00e1 que mesmo que o modelo erre a classifica\u00e7\u00e3o de todos as fraudes, este ainda apresentar\u00e1 uma alta acur\u00e1cia. \n \n As m\u00e9tricas que podem ser calculadas a partir da matriz de confus\u00e3o s\u00e3o:\n* Accuracy = (TP+TN)\/total -> Calcula a taxa de acertos geral\n* Precision = TP\/(TP+FP) -> Calcula a taxa de relev\u00e2ncia entre os classificados. Para o nosso caso indicar\u00e1 entre os classificados como fraude quais s\u00e3o realmente fraude.\n* Recall = TP\/(TP+FN) -> Calcula a taxa de classifica\u00e7\u00e3o entre os relevantes. Para o nosso problema ir\u00e1 mostrar a taxa de fraudes que estamos detectando entre todas as fraudes existentes. \n\nOutras m\u00e9tricas podem ser calculadas a partir dessas, como \u00e9 o caso de F1. A m\u00e9trica F1 calcula uma m\u00e9dia ponderada entre Precision e Recall. \n\nA m\u00e9trica a ser utilizada depende do problema a ser tratado, e muitas vezes ir\u00e1 depender de uma an\u00e1lise feita em conjunto com o especialista do problema. Vamos considerar que o importante \u00e9 n\u00e3o perder muitas fraudes, j\u00e1 que estas geram preju\u00edzo, para isso \u00e9 necess\u00e1rio obtermos um alto recall. Por outro lado, um aumento do recall leva a uma diminu\u00ed\u00e7\u00e3o da precision, o que poderia acarretar em muitos usu\u00e1rios tendo compras barradas devido a estas serem consideradas fraude. Temos ent\u00e3o um trade-off entre recall e precision que representa a rela\u00e7\u00e3o entre preju\u00edzos do banco e clientes insatisfeitos por compras barradas. Para avaliar o os modelos de acordo com esse trade-off iremos utilizar o F1 para a classe de fraudes como a nossa m\u00e9trica principal.\n\nPara apresentar uma op\u00e7\u00e3o para a \u00e1rea de neg\u00f3cios do banco, uma solu\u00e7\u00e3o interessante \u00e9 o c\u00e1lculo da probabilidade de uma transa\u00e7\u00e3o ser fraudulenta ao inv\u00e9s da classifica\u00e7\u00e3o bin\u00e1ria. Dessa forma, o banco pode decidir qual a taxa de corte que utilizar\u00e1 para definir uma transa\u00e7\u00e3o fraudulenta. Um caso de uso seria analisar a fraude de cart\u00f5es black com maior taxa de corte, j\u00e1 que os usu\u00e1rios pagam altas anuidades e ficariam muito insatisfeitos por terem compras barradas; por outro lado, o banco poderia ser mais restrito com compras de cart\u00f5es gratuitos, j\u00e1 que estes clientes possuem maior aceita\u00e7\u00e3o a erros banc\u00e1rios.\n\nOs algoritmos baseados em conjuntos de \u00e1rvores calculam a probabilidade da amostra ser de uma classe ou outra, utilizando a m\u00e9dia entre as classifica\u00e7\u00f5es das diferentes \u00e1rvores. Devido a este comportamento podemos utilizar esse tipo de algoritmo para fazer um modelo como proposto acima. Os algoritmos utilizados, ent\u00e3o, ser\u00e3o: RandomForest, ExtraTreesClassifier e XGBoost.\n\nVamos criar uma fun\u00e7\u00e3o que avalie um modelo de acordo com uma probablidade de corte e apresenta os resultados desse modelo, e outra fun\u00e7\u00e3o que mostra as curvas de precision, recall e f1 de acordo com a probabibilidade de corte."}}