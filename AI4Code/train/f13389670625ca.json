{"cell_type":{"ac90ae3f":"code","7afde4da":"code","7141d366":"code","cfd2f819":"code","eea30a67":"code","8d1690d4":"code","2d69fdb8":"code","4d956323":"code","476fdf67":"code","af7ba216":"code","8a5e3c7d":"code","723ad407":"code","beffee8c":"code","62e4c872":"code","87916db3":"code","594983a4":"code","4120cb4a":"code","a1f3b7b9":"code","5b2967a8":"code","39932c75":"code","18334261":"code","54e13444":"code","e9b53fa8":"code","d9654a45":"code","a8c6ce0e":"code","34e95e4f":"code","3db25187":"code","9ee6faed":"code","e2ddff82":"code","562e0f95":"code","dce69013":"code","4045cabc":"markdown","7d12e8fa":"markdown","79fb6fb5":"markdown","411bcca4":"markdown","841a9c13":"markdown","0d3bfe7e":"markdown","591d85bb":"markdown","98f0ecc3":"markdown","497aae58":"markdown","56a3d727":"markdown","b6d6ee01":"markdown","ae45d651":"markdown","1af37f40":"markdown"},"source":{"ac90ae3f":"# importing python packages\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7afde4da":"#Users\nu_cols = ['user_id', 'location', 'age']\nusers = pd.read_csv('..\/input\/bookcrossing-dataset\/Book reviews\/BX-Users.csv', sep=';', names=u_cols, encoding='latin-1',low_memory=False)\n\n#Books\ni_cols = ['isbn', 'book_title' ,'book_author','year_of_publication', 'publisher', 'img_s', 'img_m', 'img_l']\nitems = pd.read_csv('..\/input\/bookcrossing-dataset\/Book reviews\/BX-Books.csv', sep=';', names=i_cols, encoding='latin-1',low_memory=False)\n\n#Ratings\nr_cols = ['user_id', 'isbn', 'rating']\nratings = pd.read_csv('..\/input\/bookcrossing-dataset\/Book reviews\/BX-Book-Ratings.csv', sep=';', names=r_cols, encoding='latin-1',low_memory=False)","7141d366":"users.head()","cfd2f819":"items.head()","eea30a67":"ratings.head()","8d1690d4":"# merging\n\ndf = pd.merge(users, ratings, on = 'user_id')\ndf = pd.merge(df, items, on = 'isbn')\ndf.head()","2d69fdb8":"df.info()","4d956323":"# dropping irrelevant columns\n\ndf = df.drop(columns = ['img_s', 'img_m', 'img_l'])\ndf = df.drop(df.index[0])\ndf.head()","476fdf67":"# detecting missing values\n\ndf.isnull().sum()","af7ba216":"# dropping missing values\n\ndf = df.dropna()","8a5e3c7d":"# dropping duplicates\n\ndf.drop_duplicates(inplace = True)","723ad407":"# location\n\ndf['location'].value_counts().to_frame()","beffee8c":"# publisher\n\ndf['publisher'].value_counts().to_frame()","62e4c872":"# checking value counts in column 'year_of_publication'\n\ndf['year_of_publication'].value_counts()","87916db3":"# some wierd things have been found, therefore checking the list of values is needed \n\ndf.year_of_publication.unique()","594983a4":"# deleting rows with wrong values in column 'year_of_publication'\n\nwrong_values = df[df['year_of_publication'].isin(['\\\\\"Freedom Song\\\\\"\"', 'John Peterman', '2030', 'Frank Muir', 'Isadora Duncan', '2050', 'Karen T. Whittenburg', \n                                                  'ROBERT A. WILSON', '2038', 'George H. Scherr', 'Stan Berenstain', '2026', 'Francine Pascal', '2021', 'Gallimard',\n                                                  'DK Publishing Inc', '2037', 'Luella Hill', 'Salvador de Madariaga', 'K.C. Constantine', 'Bart Rulon', 'Alan Rich',\n                                                  'Jules Janin', '2024'])].index\ndf.drop(wrong_values, inplace = True)","4120cb4a":"# converting the columns below to the proper type (integer)\n\ndf['user_id'] = df['user_id'].astype('int')\ndf['age'] = df['age'].astype('int')\ndf['rating'] = df['rating'].astype('int')\ndf['year_of_publication'] = df['year_of_publication'].astype('int')\n\ndf.dtypes","a1f3b7b9":"df['book_author'].value_counts().to_frame()","5b2967a8":"df['book_title'].value_counts().to_frame()","39932c75":"df.describe()","18334261":"df.corr()","54e13444":"sns.pairplot(df)","e9b53fa8":"df_best_authors = df.groupby(by = ['book_author', 'book_title']).mean().sort_values(by = ['rating'], ascending = False)\ndf_best_authors.head(20)","d9654a45":"df_best_books = df.groupby(by = ['book_title']).mean().sort_values(by = ['rating'], ascending = False)\ndf_best_books.head(20)","a8c6ce0e":"# normalizing over the standard deviation\n\nfrom sklearn.preprocessing import StandardScaler\n\nclus_df = df[['age', 'rating', 'year_of_publication']]\n\nX = clus_df.values[:,1:]\nX = np.nan_to_num(X)\nclus_df = StandardScaler().fit_transform(X)\nclus_df","34e95e4f":"# searching for the right K with the elbow method\n\nfrom sklearn.cluster import KMeans\n\nwcss = []\n\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 1)\n    kmeans.fit(clus_df)\n    \n    wcss.append(kmeans.inertia_)","3db25187":"# depicting\n\nplt.figure(figsize = (12, 8))\nsns.lineplot(range(1, 11), wcss, marker = 'o', color = 'darkorchid')\n\nplt.xticks(fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.title('The Elbow Method', fontsize = 18)\nplt.xlabel('Number of clusters', fontsize = 16)\nplt.ylabel('Within Cluster Sum of Squares', fontsize = 16)\n\nplt.show()","9ee6faed":"# fitting and predicting\n\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 1)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)","e2ddff82":"#assign labels to each row\n\nlabels = kmeans.labels_\ndf['group'] = labels\ndf.head()","562e0f95":"df.groupby('group').mean()","dce69013":"# depicting clusters\n\nplt.figure(figsize = (12, 8))\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], c = 'deepskyblue', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], c = 'midnightblue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], c = 'slategray', label = 'Cluster 3')\n\nplt.title('Clusters of ratings', fontsize = 16)\n\nplt.xticks(fontsize = 12)\nplt.yticks(fontsize = 12)\nplt.xlabel('Rating', fontsize = 14)\nplt.ylabel('Year of publication', fontsize = 14)\nplt.legend()\nplt.show()","4045cabc":"* Acknowledgemnts\n* Importing packages, loading datasets\n* Data cleaning\n* Exploratory data analysis\n* Normalizing data for clustering\n* K-means clustering","7d12e8fa":"# Contents","79fb6fb5":"# Importing packages, loading dataset","411bcca4":"![Wallpaper-Kemra-Bookshelf-1-1100x1318.jpg](attachment:Wallpaper-Kemra-Bookshelf-1-1100x1318.jpg)","841a9c13":"# Acknowledgements","0d3bfe7e":"We can conclude that the optimal number of clusters is 3.","591d85bb":" # Exploratory data analysis","98f0ecc3":"# Data cleaning","497aae58":"# Book ratings","56a3d727":"Thanks Ruchi Bhatia for uploading this dataset, furthermore Vijay Choudhary and Shruti_Iyyer for inspiration.","b6d6ee01":"# K-means clustering","ae45d651":"*\u201cA reader lives a thousand lives before he dies, said Jojen. <br> The man who never reads lives only one.\u201d <br> <br>\n\u2015 George R.R. Martin, A Dance with Dragons*","1af37f40":"# Normalizing data for clustering"}}