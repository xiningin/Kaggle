{"cell_type":{"64a5eb04":"code","a2333b52":"code","39a0a82d":"code","35e2aa53":"code","7a116af3":"code","2bf27842":"code","24f9cce4":"code","918b56b3":"code","c960697c":"code","9c77f6f4":"code","4b898d30":"code","89441b75":"code","0a079eec":"code","28576e49":"code","0b52c2fd":"code","68b1326e":"code","293701a1":"code","9662b541":"code","ebf96776":"code","f00903bb":"code","c2c83896":"code","0641c06b":"code","6454b82b":"code","3f5fe7ab":"code","fa9505b1":"code","4563de80":"code","3a2294a5":"code","7453ab23":"code","db9abb88":"code","10b7b2ae":"code","fdc2558d":"code","993575c9":"code","3308eb82":"code","d523550c":"code","f4c0b334":"code","8bb3f0aa":"code","7e9ea8af":"code","28ad4136":"code","17ac20af":"code","2537d254":"code","a3d91115":"code","6e74bc30":"code","5bb47810":"code","6601e0d9":"markdown","745c3224":"markdown","4cf89f3d":"markdown","0e955187":"markdown","7033f3dd":"markdown","f125fac3":"markdown","c0f7481a":"markdown","610ccae7":"markdown","22e79af7":"markdown","75b59e0e":"markdown","930f9766":"markdown","d5b36c20":"markdown","0f17cc25":"markdown","ce6e8ddc":"markdown"},"source":{"64a5eb04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a2333b52":"!pip install pandas==0.25.3\n!pip install scikit-learn==0.22\n!pip install numpy==1.18.0\n!pip install ppscore","39a0a82d":"import numpy as np \nimport pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport ppscore as pps\nfrom sklearn.preprocessing import OneHotEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import f1_score\nfrom sklearn.externals import joblib\n\nseed = 2020","35e2aa53":"print('numpy version: '+ np.__version__)\nprint('pandas version: '+ pd.__version__)\nprint('sklearn version: '+ sklearn.__version__)","7a116af3":"pwd","2bf27842":"path ='\/kaggle\/input\/titanic\/'\ntrain = pd.read_csv(os.path.join(path,'train.csv'))\ntest = pd.read_csv(os.path.join(path,'test.csv'))\nsample_sub = pd.read_csv(os.path.join(path,'gender_submission.csv'))","24f9cce4":"train.head()","918b56b3":"test.head()","c960697c":"train.describe()","9c77f6f4":"train.info()","4b898d30":"# checking for missing values \nfig, ax = plt.subplots(figsize=(10,5))\nsns.heatmap(train.isnull(), cbar=False)\nplt.show()","89441b75":"sns.countplot(train.Survived)","0a079eec":"sns.barplot(x='Sex', y='Survived', data=train)\nplt.ylabel(\"Rate of Surviving\")\nplt.title(\"Plot of Survival as function of Sex\", fontsize=16)\nplt.show()\ntrain[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","28576e49":"sns.barplot(x='Pclass', y='Survived', data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Plot of Survival as function of Pclass\", fontsize=16)\nplt.show()\ntrain[[\"Pclass\", \"Survived\"]].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","0b52c2fd":"plt.figure(figsize=(10,5))\nsns.heatmap(train.corr(),annot=True)","68b1326e":"plt.figure(figsize=(10,5))\nax = train.corr()['Survived'].plot(kind='bar',title='correlation of target variable to features')\nax.set_ylabel('correlation')","293701a1":"# Predictive Power Score Plot\nplt.figure(figsize=(20,10))\nsns.heatmap(pps.matrix(train),annot=True)","9662b541":"train_copy = train.copy()\ntrain_copy.dropna(inplace = True)\nsns.distplot(train_copy.Age)","ebf96776":"sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_copy)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\")","f00903bb":"sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=train_copy)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\")","c2c83896":"train_null = train.isnull().sum()\ntest_null = test.isnull().sum()\nprint(train_null[train_null !=0])\nprint('-'*40)\nprint(test_null[test_null !=0])","0641c06b":"from sklearn.impute import SimpleImputer\nage_imp = SimpleImputer(strategy= 'median')\nage_imp.fit(np.array(train.Age).reshape(-1,1))\n\ntrain.Age = age_imp.transform(np.array(train.Age).reshape(-1,1))\ntest.Age = age_imp.transform(np.array(test.Age).reshape(-1,1))\ntrain.head()","6454b82b":"#save age imputer \nwith open('age_imputer.joblib', 'wb') as f:\n  joblib.dump(age_imp,f)","3f5fe7ab":"emb_imp = SimpleImputer(strategy= 'most_frequent' )\nemb_imp.fit(np.array(train.Embarked).reshape(-1,1))\n\ntrain.Embarked = emb_imp.transform(np.array(train.Embarked).reshape(-1,1))\ntest.Embarked = emb_imp.transform(np.array(test.Embarked).reshape(-1,1))\ntrain.head()","fa9505b1":"#save embark imputer \nwith open('embark_imputer.joblib', 'wb') as f:\n  joblib.dump(emb_imp,f)","4563de80":"train.isnull().sum() \nprint('-'*40)\ntest.isnull().sum()","3a2294a5":"drop_cols = ['PassengerId','Ticket','Cabin','Name']\ntrain.drop(columns=drop_cols,axis=1,inplace = True)\ntest_passenger_id = test.PassengerId\ntest.drop(columns=drop_cols,axis=1,inplace = True)","7453ab23":"test.fillna(value = test.mean(),inplace=True)","db9abb88":"train.isnull().sum().any() , test.isnull().sum().any()","10b7b2ae":"train['Number_of_relatives'] = train.Parch + train.SibSp\ntest['Number_of_relatives'] = test.Parch + test.SibSp\n\ntrain.drop(columns=['Parch','SibSp'],axis=1,inplace=True)\ntest.drop(columns=['Parch','SibSp'],axis=1,inplace=True)","fdc2558d":"train.head()","993575c9":"gender_dic = {'male':1,'female':0}\ntrain.Sex = train.Sex.map(gender_dic)\ntest.Sex = test.Sex.map(gender_dic)\ntrain.head()","3308eb82":"cat_col = ['Embarked', 'Pclass']\nOne_hot_enc = OneHotEncoder(sparse=False,drop='first',dtype=np.int)","d523550c":"encoded_train = pd.DataFrame(data=One_hot_enc.fit_transform(train[cat_col]), columns=['emb_2','emb_3','Pclass_2','Pclass_3'])\nencoded_test = pd.DataFrame(data=One_hot_enc.transform(test[cat_col]),columns=['emb_2','emb_3','Pclass_2','Pclass_3'])","f4c0b334":"#save One_hot_enc \nwith open('One_hot_enc.joblib', 'wb') as f:\n  joblib.dump(One_hot_enc,f)","8bb3f0aa":"train.drop(columns=cat_col,axis=1,inplace=True)\ntest.drop(columns=cat_col,axis=1,inplace=True)\n\ntrain = pd.concat([train,encoded_train],axis=1)\ntest = pd.concat([test,encoded_test],axis=1)\ntrain.head()","7e9ea8af":"features = test.columns\nX = train[features]\ny = train.Survived","28ad4136":"scaler = StandardScaler()\nX = scaler.fit_transform(X)\ntest = scaler.transform(test)","17ac20af":"#save scaler \nwith open('scaler.joblib', 'wb') as f:\n  joblib.dump(scaler,f)","2537d254":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)","a3d91115":"logistic_model  = LogisticRegression()\nlogistic_model.fit(X_train,y_train)","6e74bc30":"print('f1_score on training set: {}'.format(f1_score(logistic_model.predict(X_train),y_train)))\nprint('f1_score on test set: {}'.format(f1_score(logistic_model.predict(X_test),y_test)))","5bb47810":"logistic_model.fit(X,y)\n#save model \nwith open('model-v1.joblib', 'wb') as f:\n  joblib.dump(logistic_model,f)","6601e0d9":"* of the whole features, PassengerID and Name have lowest 0 PPS\n* Sex, Pclass and fare have have a good PPS \n* The Ticket feature can greatly improve model performance with enough feature engineering \n* Pclass can be predicted using the Fare feature with 90% accuracy\n* The missing values in Cabin can be worked on using the Pclass feature","745c3224":"### There are much more survivals in female than male","4cf89f3d":"From the graphs above,Female survival rate in the all the Pclasses is higher than male survival rate respectively","0e955187":"# Handling missing values ","7033f3dd":"Looks like the distribution of ages is slightly skewed right. Because of this, we can fill in the null values with the median for the most accuracy.","f125fac3":"Some features are highly correlated with one another, creating new features will be helpful. e.g Pclass and SibSp are highly correlated, a new feature will be created to reduce the Collinearity","c0f7481a":"# Short Exploratory Data Analysis  ","610ccae7":"### Passengers in Pclass 1 and 2 have higher chances of surviving ","22e79af7":"# This notebook was created for a quick experiment on the deployment of machine learning model using the titanic dataset.\n\nThe model performance can greatly be improved on but I will be sticking to basic modelling in other to remian within standard available packages during the deployment without need for the creation of custom packages. \n### The focus here is just to get a simple model serialized so as to have it deployed on google app engine. \n\nBelow is a link to medium article explaining the deployment in stages for further clarification on why this kernel was created:\nhttps:\/\/heartbeat.fritz.ai\/deploying-machine-learning-models-on-google-cloud-platform-gcp-7b1ff8140144\n","75b59e0e":"### Imbalance dataset... resampling techniques will be useful so as to have better performance evaluation","930f9766":"### Note that we saved all the objects used during data tranformation and trained model.\n### All these saved objects can be found and downloaded in the output directory under the Data section at the top right corner of the notebook. these will be needed for test data transformation and inference at the deployment stage.","d5b36c20":"There were more female survivals than male in all the 3 Pclass categories","0f17cc25":"The passengerId feature will be dropped as this is unique across all samples. Pclass and Fare have the highest absolute correletion with the target variable","ce6e8ddc":"### There are missing values in age and Cabin features "}}