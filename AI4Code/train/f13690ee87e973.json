{"cell_type":{"f505de2b":"code","68389125":"code","b8f4b612":"code","89443378":"code","04ae4307":"code","1b686087":"code","19bd0ca7":"code","445b090a":"markdown","3871ac8d":"markdown","910ab8a6":"markdown","02166d02":"markdown","f4dc04fa":"markdown","3289dd3b":"markdown","4b935e81":"markdown","f91065c8":"markdown"},"source":{"f505de2b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix , classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","68389125":"df = pd.read_csv('\/kaggle\/input\/heart-disease-health-indicators-dataset\/heart_disease_health_indicators_BRFSS2015.csv')\nprint(df.shape)\ndf.head()","b8f4b612":"X = df.iloc[:,1:].copy().astype('int64')\nY = df.iloc[:,0].copy().astype('int64')","89443378":"scaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_train,X_test,Y_train,Y_test = train_test_split(X_scaled,Y,test_size=0.05)","04ae4307":"model = LogisticRegression()\nmodel.fit(X_train,Y_train)\npredictions = model.predict(X_test)\n\nprint(classification_report(Y_test,predictions))\ncmatrix = confusion_matrix(Y_test,predictions)\nprint(f'TN: {cmatrix[0][0]}' )\nprint(f'FP: {cmatrix[0][1]}' )\nprint(f'FN: {cmatrix[1][0]}' )\nprint(f'TP: {cmatrix[1][1]}' )","1b686087":"X = df.iloc[:,1:].copy()\nX = X.drop(columns={'NoDocbcCost','Income','CholCheck','AnyHealthcare'})\nX_scaled = scaler.fit_transform(X)\nX_train,X_test,Y_train,Y_test = train_test_split(X_scaled,Y,test_size=0.05)\nmodel = LogisticRegression()\nmodel.fit(X_train,Y_train)\npredictions = model.predict(X_test)\n\nprint(classification_report(Y_test,predictions))\ncmatrix = confusion_matrix(Y_test,predictions)\nprint(f'TN: {cmatrix[0][0]}' )\nprint(f'FP: {cmatrix[0][1]}' )\nprint(f'FN: {cmatrix[1][0]}' )\nprint(f'TP: {cmatrix[1][1]}' )","19bd0ca7":"pd.value_counts(df.HeartDiseaseorAttack).plot.bar()","445b090a":"### Scaling the features and splitting data","3871ac8d":"### As you can see the dataset is imbalanced as negative class is much much higher than positive class thus Logistic model will not work perfectly.","910ab8a6":"### Making  Logistic Regression Model","02166d02":"#### Still the problem remains same for Logistic Regression Classifier","f4dc04fa":"## Taking ALL Features and target\n#### Right Now I am taking all the features that are given in dataset","3289dd3b":"### Now i will be discarding the following features as they dont seem to be important towards health \n#### 'NoDocbcCost','Education','Income','CholCheck','AnyHealthcare'","4b935e81":"## Report\n#### As we can see out model can easily predict the negative classes but is bad at predicting positive classes. This is bad as we can't tell a patient who is having heart attack risk a false report. Thus we need to train the model using different features","f91065c8":"## Loading Dataframe"}}