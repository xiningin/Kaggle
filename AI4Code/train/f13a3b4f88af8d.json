{"cell_type":{"8a0b97d0":"code","dc6907d6":"code","e2b0c6c9":"code","c1d2cc36":"code","40dc3d3c":"code","afa82b66":"code","a1826622":"code","598ccd5a":"code","70bcd86b":"code","88125916":"code","4c918378":"code","9ad7f2cf":"code","713c899d":"code","ede9287b":"code","df671de1":"markdown","7cd49e48":"markdown","111c6315":"markdown","ca5db941":"markdown"},"source":{"8a0b97d0":"from tensorflow.keras.models import Model , load_model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Dropout\nfrom tensorflow.keras.utils import normalize , to_categorical\nfrom tensorflow.keras.metrics import MeanIoU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.math import confusion_matrix\nfrom tqdm.notebook import tqdm\n\nimport os\nimport glob\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport time\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nprint(1)","dc6907d6":"# def unet(pretrained_weights=None , num_classes=7, img_height=256 , img_width=256 , channels=3):\n\n#     inputs = Input((img_height,img_width,channels))\n#     conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n#     conv1 = BatchNormalization()(conv1)\n#     conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n#     conv1 = BatchNormalization()(conv1)\n#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n#     conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n#     conv2 = BatchNormalization()(conv2)\n#     conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n#     conv2 = BatchNormalization()(conv2)\n#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n#     conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n#     conv3 = BatchNormalization()(conv3)\n#     conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n#     conv3 = BatchNormalization()(conv3)\n#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n#     conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n#     conv4 = BatchNormalization()(conv4)\n#     conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n#     conv4 = BatchNormalization()(conv4)\n#     drop4 = Dropout(0.5)(conv4, training=True)\n#     pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n#     conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n#     conv5 = BatchNormalization()(conv5)\n#     conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n#     conv5 = BatchNormalization()(conv5)\n#     drop5 = Dropout(0.5)(conv5, training=True)\n#     #\u4e0a\u91c7\u6837\n#     up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n#         UpSampling2D(size=(2, 2))(drop5))\n#     merge6 = concatenate([drop4, up6], axis=3)\n#     conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n#     conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n\n#     up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n#         UpSampling2D(size=(2, 2))(conv6))\n#     merge7 = concatenate([conv3, up7], axis=3)\n#     conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n#     conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n\n#     up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n#         UpSampling2D(size=(2, 2))(conv7))\n#     merge8 = concatenate([conv2, up8], axis=3)\n#     conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n#     conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n\n#     up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n#         UpSampling2D(size=(2, 2))(conv8))\n#     merge9 = concatenate([conv1, up9], axis=3)\n#     conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n#     conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n#     # conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n\n#     conv10 = Conv2D(num_classes, (1,1), activation='sigmoid')(conv9)\n\n#     model = Model(inputs=inputs, outputs=conv10)\n\n\n#     if (pretrained_weights):\n#         model = load_model(pretrained_weights)\n\n#     return model\n# \u5b9a\u4e49u-Net\u7f51\u7edc\u6a21\u578b\ndef Unet():\n    # contraction path \n    # \u8f93\u5165\u5c42\u6570\u636e\u4e3a256*256\u7684\u4e09\u901a\u9053\u56fe\u50cf\n    inputs = Input(shape=[256, 256, 3])\n    # \u7b2c\u4e00\u4e2ablock(\u542b\u4e24\u4e2a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\u7684\u6709\u6548\u5377\u79ef\u5c42 \uff0c\u548c\u4e00\u4e2a\u5377\u79ef\u6700\u5927\u6c60\u5316(\u4e0b\u91c7\u6837)\u64cd\u4f5c)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n    # \u6700\u5927\u6c60\u5316\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    # \u7b2c\u4e8c\u4e2ablock(\u542b\u4e24\u4e2a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\u7684\u6709\u6548\u5377\u79ef\u5c42 \uff0c\u548c\u4e00\u4e2a\u5377\u79ef\u6700\u5927\u6c60\u5316(\u4e0b\u91c7\u6837)\u64cd\u4f5c)\n    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    # \u7b2c\u4e09\u4e2ablock(\u542b\u4e24\u4e2a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\u7684\u6709\u6548\u5377\u79ef\u5c42 \uff0c\u548c\u4e00\u4e2a\u5377\u79ef\u6700\u5927\u6c60\u5316(\u4e0b\u91c7\u6837)\u64cd\u4f5c)\n    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    # \u7b2c\u56db\u4e2ablock(\u542b\u4e24\u4e2a\u6fc0\u6d3b\u51fd\u6570\u4e3arelu\u7684\u6709\u6548\u5377\u79ef\u5c42 \uff0c\u548c\u4e00\u4e2a\u5377\u79ef\u6700\u5927\u6c60\u5316(\u4e0b\u91c7\u6837)\u64cd\u4f5c)\n    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n    # \u5c06\u90e8\u5206\u9690\u85cf\u5c42\u795e\u7ecf\u5143\u4e22\u5f03\uff0c\u9632\u6b62\u8fc7\u4e8e\u7ec6\u5316\u800c\u5f15\u8d77\u7684\u8fc7\u62df\u5408\u60c5\u51b5\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n    # \u5c06\u90e8\u5206\u9690\u85cf\u5c42\u795e\u7ecf\u5143\u4e22\u5f03\uff0c\u9632\u6b62\u8fc7\u4e8e\u7ec6\u5316\u800c\u5f15\u8d77\u7684\u8fc7\u62df\u5408\u60c5\u51b5\n    drop5 = Dropout(0.5)(conv5)\n\n    # expansive path\n    # \u4e0a\u91c7\u6837\n    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n        UpSampling2D(size=(2, 2))(drop5))\n    # copy and crop(\u548ccontraction path \u7684feature map\u5408\u5e76\u62fc\u63a5)\n    merge6 = concatenate([drop4, up6], axis=3)\n    \n    # \u4e24\u4e2a\u6709\u6548\u5377\u79ef\u5c42\n    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n    \n    # \u4e0a\u91c7\u6837\n    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n        UpSampling2D(size=(2, 2))(conv6))\n    merge7 = concatenate([conv3, up7], axis=3)\n    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n\n    # \u4e0a\u91c7\u6837\n    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n        UpSampling2D(size=(2, 2))(conv7))\n    merge8 = concatenate([conv2, up8], axis=3)\n    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n\n    # \u4e0a\u91c7\u6837\n    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n        UpSampling2D(size=(2, 2))(conv8))\n    merge9 = concatenate([conv1, up9], axis=3)\n    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n#     conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n    conv10 = Conv2D(7, (1,1), activation='sigmoid')(conv9)\n    model = Model(inputs=inputs, outputs=conv10)\n    \n#     merge9 = concatenate([conv1, up9], axis=3)\n#     conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n#     conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n#     # conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n#     conv10 = Conv2D(num_classes, (1,1), activation='sigmoid')(conv9)\n    \n#     # \u4f18\u5316\u5668\u4e3a Adam,\u635f\u5931\u51fd\u6570\u4e3a binary_crossentropy\uff0c\u8bc4\u4ef7\u51fd\u6570\u4e3a accuracy\n#     model.compile(\n#                  loss='binary_crossentropy',\n#                  metrics=['accuracy'])\n    return model","e2b0c6c9":"# # loading the images and label ids to arrays\nimg_height = 256\nimg_width = 256\nchannels = 3\n# def load_images(PATH, h=img_height, w=img_width):\n#     images_list = []\n#     for img_path in tqdm(glob.glob(PATH+'\/*png')):\n#         img = cv2.imread(img_path)\n#         img = cv2.resize(img, (h , w))\n#         images_list.append(img)\n    \n#     return np.array(images_list)\n\n# def load_labels(PATH, h=img_height, w=img_width):\n#     images_list = []\n#     for img_path in tqdm(glob.glob(PATH+'\/*png')):\n#         img = cv2.imread(img_path, 0)\n#         img = cv2.resize(img, (h , w),interpolation = cv2.INTER_NEAREST)\n#         images_list.append(img)\n    \n#     return np.array(images_list)\n\n\n# train = load_images('..\/input\/tas500\/tas500v1.1\/train') \n# train_labels = load_labels('..\/input\/tas500\/tas500v1.1\/train_labels_ids')\n# val = load_images('..\/input\/tas500\/tas500v1.1\/val')\n# val_labels = load_labels('..\/input\/tas500\/tas500v1.1\/val_labels_ids')","c1d2cc36":"def case0():                           \n    return 0\ndef case1():                           \n    return 1\ndef case2():                            \n    return 2\ndef case3():                            \n    return 3\ndef case4():                            \n    return 4\ndef case5():                            \n    return 5\ndef case6():                            \n    return 6\ndef default(): \n    print('Error')                        \n    return 255\nswitch = {38: case1,                \n          75: case2,\n          113: case3,\n          14: case4,\n          52: case5,\n          89: case6,\n          0: case0\n          }\ndef labelconvert(img):\n    x,y,channel = np.shape(img)\n    for i in range (x):\n        for j in range (y):\n            img[i][j] = switch.get(int(img[i][j]), default)() \n    return img\n","40dc3d3c":"h = 256\nw = 256\nmask_dir = '..\/input\/iono2630\/Iono2630\/label\/'\ninput_dir = '..\/input\/iono2630\/Iono2630\/img\/'\n\ntic1 = time.perf_counter()\n# \u5bfc\u5165input\u6570\u636e\ntrain_list = []\nfor filename in os.listdir(input_dir):\n    img = cv2.imread(input_dir + \"\/\" + filename) #\u8bfb\u5165\u4e09\u901a\u9053\n    img = img[104:360,0:256]\n#     img = cv2.resize(img, (128, 128))\n    img = img_to_array(img)\n    train_list.append(img)\ntrain_list = np.array(train_list)\ntic2 = time.perf_counter()\nprint('train_list is ready, cost', tic2-tic1, 's')\n\nmask_list = []\nfor filename in os.listdir(mask_dir):\n    img = cv2.imread(mask_dir + \"\/\" + filename, cv2.IMREAD_GRAYSCALE)   #\u5bfc\u5165\u7070\u5ea6\u56fe\n    img = img[104:360,0:256]\n    img = img_to_array(img)\n    mask_list.append(img)\nmask_list = np.array(mask_list)\ntic3 = time.perf_counter()\nprint('mask_list is ready, cost', tic3-tic2, 's')\n# \u5bfc\u5165mask\u6570\u636e 255s\n# mask_list = []\n# for filename in os.listdir(mask_dir):\n#     img = cv2.imread(mask_dir + \"\/\" + filename, cv2.IMREAD_GRAYSCALE)   #\u5bfc\u5165\u7070\u5ea6\u56fe\n#     img = img[104:360,0:256]\n# #     img = cv2.resize(img, (128, 128),interpolation = cv2.INTER_NEAREST)\n    \n#     img = img_to_array(img)\n    \n#     img = labelconvert(img)    # \u66ff\u6362\n#     Fspread = (img == 6).any() # \u66ff\u6362\n# #     Fspread = (img == 89).any() # \u4e0d\u505a\u6807\u7b7e\u8f6c\u6362\n#     mask_list.append(img)\n# mask_list = np.array(mask_list)\n\nprint(np.shape(train_list))\nprint(np.shape(mask_list))","afa82b66":"mask_list = np.reshape(mask_list,(2630,h,w))\n\ntrain = train_list[0:2104]\ntrain_labels = mask_list[0:2104]\nval = train_list[2104:1949]\nval_labels = mask_list[2104:1949]\nprint(np.shape(train))\nprint(type(val_labels))\nprint(np.shape(train_labels))\n\nprint('the classes are:',np.unique(train_labels))\nnum_classes = len(np.unique(train_labels))\nprint('the number of classes is:', num_classes)\n\n# changing the labels to categorical for classification\ny_train = to_categorical(train_labels, num_classes)\ny_test = to_categorical(val_labels, num_classes)","a1826622":"# model = unet(pretrained_weights=None , num_classes=num_classes , img_height=256 , img_width=258 , channels=channels)\nmodel = Unet()\nmodel.compile(optimizer=Adam(lr=0.00004), loss='categorical_crossentropy', metrics=[MeanIoU(num_classes)])\nmodel.summary()","598ccd5a":"# training the model\nhistory = model.fit(train, y_train,\n                    batch_size=2,\n                    verbose=1,\n                    epochs=10,\n                    validation_data=(val, y_test),\n                    shuffle=False)","70bcd86b":"# evaluate the model with IoU\n_, meanIOU = model.evaluate(val, y_test)\n\nprint(f'mean IOU is: {meanIOU}')","88125916":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Validation loss')\nplt.plot(epochs, val_loss, 'r', label='Training  loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('loss.png')\nplt.show()\n","4c918378":"Mean_IoU = history.history['mean_io_u']\nval_Mean_IoU = history.history['val_mean_io_u']\n\nplt.plot(epochs, Mean_IoU, 'y', label='Training Mean IoU')\nplt.plot(epochs, val_Mean_IoU, 'r', label='Validation Mean IoU')\nplt.title('Training and validation Mean IoU')\nplt.xlabel('Epochs')\nplt.ylabel('Mean IoU')\nplt.legend()\nplt.savefig('iou.png')\nplt.show()","9ad7f2cf":"# getting the confusion matrix\ntest_predictions = model.predict(val)\npredicted_labels = np.argmax(test_predictions , axis=3)\ncm = confusion_matrix(val_labels.flatten(), predicted_labels.flatten())\nprint(cm)","713c899d":"def create_visual_anno(anno):\n    \"\"\"\"\"\"\n    assert np.max(anno) <= 7, \"only 7 classes are supported, add new color in label2color_dict\"\n    label2color_dict = {\n        0: [0, 0, 0],\n        1: [255, 248, 220],  # cornsilk\n        2: [100, 149, 237],  # cornflowerblue\n        3: [102, 205, 170],  # mediumAquamarine\n        4: [205, 133, 63],  # peru\n        5: [160, 32, 240],  # purple\n        6: [255, 64, 64],  # brown1\n        7: [139, 69, 19],  # Chocolate4\n    }\n    # visualize\n    visual_anno = np.zeros((anno.shape[0], anno.shape[1], 3), dtype=np.uint8)\n    for i in range(visual_anno.shape[0]):  # i for h\n        for j in range(visual_anno.shape[1]):\n            color = label2color_dict[anno[i, j]]\n            visual_anno[i, j, 0] = color[0]\n            visual_anno[i, j, 1] = color[1]\n            visual_anno[i, j, 2] = color[2]\n\n    return visual_anno","ede9287b":"import random\ntest_img_number = random.randint(0, len(val))\ntest_img_number = 226\nprint(test_img_number)\ntest_img = val[test_img_number]\nground_truth = val_labels[test_img_number]\nground_truth = create_visual_anno(ground_truth)\ntest_img_input = np.expand_dims(test_img, 0)\nprediction = (model.predict(test_img_input))\npredicted_img = np.argmax(prediction, axis=3)[0, :, :]\nprint(np.unique(predicted_img))\npredicted_img = create_visual_anno(predicted_img)\nplt.figure(figsize=(12, 8))\nplt.subplot(131)\nplt.title('Testing Image')\nplt.imshow(test_img[:, :, 0], cmap='gray')\nplt.subplot(132)\nplt.title('Testing Label')\nplt.imshow(ground_truth, cmap='hot')\nplt.subplot(133)\nplt.title('Prediction on test image')\nplt.imshow(predicted_img, cmap='hot')\nplt.savefig('res.png')\nplt.show()","df671de1":"### \u5bfc\u5165\u6570\u636e","7cd49e48":"### label\u8f6c\u6362\u51fd\u6570","111c6315":"# \u52a0\u8f7d\u539f\u6570\u636e","ca5db941":"### \u5212\u5206\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6"}}