{"cell_type":{"5b044b22":"code","46c9ad8d":"code","6a95a744":"code","129ce8ca":"code","560bcec3":"code","f264b932":"code","c5883234":"code","32309cd1":"code","7206e346":"code","68274f4a":"code","a037c2ea":"code","7e9fe74a":"code","fe7111d5":"code","2a11c135":"code","333dc9c0":"code","a873fa79":"code","3203ca92":"code","e295b8f4":"code","25b2b2e5":"code","43755996":"code","60df5212":"code","f7d21c7a":"code","7eca8cd3":"code","799dcdd1":"code","45a189f1":"code","0aaaa926":"code","bcae66fc":"code","3f249148":"code","56086d41":"code","14e93005":"code","ed7bf4be":"code","5b5b27f0":"code","84ced48d":"code","9cec5e85":"code","ace9301f":"code","3a92ce35":"code","6b03abe5":"code","621b9fbc":"code","ce55dc5a":"markdown","e8595c58":"markdown","f1ad5a8b":"markdown","9f8b34f8":"markdown","ce645f3b":"markdown","aaad1144":"markdown","939fc520":"markdown","f80c8d12":"markdown","10564a5d":"markdown","8b00dfd5":"markdown","52c97656":"markdown","5466e273":"markdown","39894fdf":"markdown","764d24b4":"markdown","176c2483":"markdown","ec980eaa":"markdown","16040d14":"markdown","8f92a8bb":"markdown","1ac71038":"markdown","b1ccf6d1":"markdown","484eb04e":"markdown","e1292373":"markdown","1083f677":"markdown","a9675ba9":"markdown","f58fa5af":"markdown","bdc77b6b":"markdown","0fe43c41":"markdown","45eb2f79":"markdown","f7ff03f4":"markdown","3a2fa17d":"markdown","cd1d2eb2":"markdown","9b2d10bb":"markdown","7daa6cc2":"markdown","6c004971":"markdown"},"source":{"5b044b22":"!pip install dabl\n!pip install datatable","46c9ad8d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\ncolorMap = sns.light_palette(\"blue\", as_cmap=True)\n\n\nimport dabl\nimport warnings\nwarnings.filterwarnings('ignore')\n\ncolorMap = sns.light_palette(\"blue\", as_cmap=True)\n\nimport missingno as msno","6a95a744":"!wc -l ..\/input\/jane-street-market-prediction\/train.csv","129ce8ca":"%%time\n\ntrain_data = dt.fread('..\/input\/jane-street-market-prediction\/train.csv').to_pandas()","560bcec3":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","f264b932":"train_data = reduce_mem_usage(train_data)","c5883234":"train_data.head()","32309cd1":"print(\" Total days avaiallbe in dataset:- \",len(train_data['date'].unique()))","7206e346":"days_txn = train_data.groupby(['date']).agg({'ts_id':'count'}).reset_index()\ndays_txn.rename(columns={'ts_id':'txn_count'},inplace=True)","68274f4a":"fig, ax = plt.subplots(figsize=(25, 10))\nsns.lineplot(days_txn['date'],days_txn['txn_count'])\nax.set_xlabel (\"Days\", fontsize=18)\nax.set_ylabel (\"Transaction count\", fontsize=18);","a037c2ea":"days_txn_wght = train_data.groupby(['date']).agg({'weight':'sum'}).reset_index()\nfig, ax = plt.subplots(figsize=(25, 10))\nsns.lineplot(days_txn_wght['date'],days_txn_wght['weight'])\nax.set_xlabel (\"Days\", fontsize=18)\nax.set_ylabel (\"Sum of weight\", fontsize=18)","7e9fe74a":"days_txn_wght = train_data.groupby(['date']).agg({'weight':'mean'}).reset_index()\nfig, ax = plt.subplots(figsize=(25, 10))\nsns.lineplot(days_txn_wght['date'],days_txn_wght['weight'])\nax.set_xlabel (\"Days\", fontsize=18)\nax.set_ylabel (\"Mean of weight\", fontsize=18)","fe7111d5":"percent_zeros = (100\/train_data.shape[0])*((train_data.weight.values == 0).sum())\nprint('Percentage of zero weights is: %i' % percent_zeros +\"%\")","2a11c135":"max_weight = train_data['weight'].max()\nprint('The maximum weight was: %.2f' % max_weight)","333dc9c0":"train_data[train_data['weight']==(max_weight)]","a873fa79":"train_data['feature_0'].value_counts()","3203ca92":"fig, ax = plt.subplots(figsize=(8, 3))\nfeature_0 = pd.Series(train_data['feature_0']).cumsum()\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_ylabel (\"feature_0 (cumulative)\", fontsize=18);\nfeature_0.plot(lw=3);","e295b8f4":"train_data['action'] = ((train_data['resp'])>0)*1","25b2b2e5":"def plot_txn_day_cumsum(day):\n    fig, ax = plt.subplots(figsize=(25, 10))\n    balance= pd.Series(day['resp']).cumsum()\n    resp_1= pd.Series(day['resp_1']).cumsum()\n    resp_2= pd.Series(day['resp_2']).cumsum()\n    resp_3= pd.Series(day['resp_3']).cumsum()\n    resp_4= pd.Series(day['resp_4']).cumsum()\n    ax.set_xlabel (\"Trade\", fontsize=18)\n    ax.set_title (\"Cumulative return for resp and time horizons 1, 2, 3, and 4\", fontsize=18)\n    balance.plot(lw=3)\n    resp_1.plot(lw=3)\n    resp_2.plot(lw=3)\n    resp_3.plot(lw=3)\n    resp_4.plot(lw=3)\n    plt.legend(loc=\"upper left\");","43755996":"plot_txn_day_cumsum(train_data.loc[train_data['date'] == 5])","60df5212":"plot_txn_day_cumsum(train_data.loc[train_data['date'] == 0])","f7d21c7a":"plot_txn_day_cumsum(train_data.loc[train_data['date'] == 1])","7eca8cd3":"plot_txn_day_cumsum(train_data.loc[train_data['date'] == 499])","799dcdd1":"msno.matrix(train_data.loc[train_data['date'] == 1])","45a189f1":"msno.matrix(train_data.loc[train_data['date'] == 100])","0aaaa926":"plt.figure(figsize=(20,20))\nsns.heatmap(train_data.corr())","bcae66fc":"# Taken from this notebook: https:\/\/www.kaggle.com\/blurredmachine\/jane-street-market-eda-viz-prediction\n\ndate = 0\nn_features = 130\n\ncols = [f'feature_{i}' for i in range(1, n_features)]\nhist = px.histogram(\n    train_data[train_data[\"date\"] == date], \n    x=cols, \n    animation_frame='variable', \n    range_y=[0, 600], \n    range_x=[-7, 7]\n)\n\nhist.show()","3f249148":"dabl.plot(train_data.loc[train_data['date'] == 5], target_col=\"resp\")","56086d41":"fig_1 = px.scatter(train_data.loc[train_data['date'] == 5], x=train_data.loc[train_data['date'] == 5]['ts_id'], y=train_data.loc[train_data['date'] == 5]['resp'], \n                   trendline=\"ols\", marginal_y=\"violin\",\n                   title=(\"Scatter plot of resp with respect to ts_id for day 5\"))\nfig_1.show()","14e93005":"fig_1 = px.scatter(train_data.loc[train_data['date'] == 446], x=train_data.loc[train_data['date'] == 446]['ts_id'], y=train_data.loc[train_data['date'] == 446]['resp'], \n                   trendline=\"ols\", marginal_y=\"violin\",\n                   title=(\"Scatter plot of resp with respect to ts_id for day 446\"))\nfig_1.show()","ed7bf4be":"X_train = train_data.loc[train_data['date'] == 5].loc[:, train_data.columns.str.contains('feature')]\nX_train = X_train.fillna(X_train.mean())\n# our target is the action\ny_train = train_data.loc[train_data['date'] == 5]['resp']","5b5b27f0":"from sklearn.ensemble import RandomForestRegressor","84ced48d":"regressor = RandomForestRegressor(max_features='auto')\nregressor.fit(X_train, y_train)","9cec5e85":"import eli5\nfrom eli5.sklearn import PermutationImportance","ace9301f":"perm_import = PermutationImportance(regressor, random_state=1).fit(X_train, y_train)","3a92ce35":"eli5.show_weights(perm_import, top=20, feature_names = X_train.columns.tolist())","6b03abe5":"import shap \n\n# load JS visualization code to notebook\nshap.initjs()\n\nexplainer = shap.TreeExplainer(regressor)\nshap_values = explainer.shap_values(X_train)\n\n#use matplotlib=True\n\n\n# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\nshap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])","621b9fbc":"# sort the features indexes by their importance in the model\n# (sum of SHAP value magnitudes over the train dataset)\n\n\nexplainer = shap.TreeExplainer(regressor)\nshap_values = explainer.shap_values(X_train)\n\n\ntop_inds = np.argsort(-np.sum(np.abs(shap_values), 0))\n\n# make SHAP plots of the three most important features\nfor i in range(len(top_inds)):\n    shap.dependence_plot(top_inds[i], shap_values, X_train)","ce55dc5a":"# EDA starts ","e8595c58":"### Trade Day - 5","f1ad5a8b":"## Features\n> \"*This dataset contains an anonymized set of features, `feature_{0...129}`, representing real stock market data.*\"\n\nHowever, `feature_0` seems to me to be a little unusual, as it is composed solely of the integers `+1` or `-1`:","9f8b34f8":"# Let see How distribution looks like ","ce645f3b":"# Future work\n\n1. Feature Analysis \n2. Dimentionality reduction\n3. Data Imputation","aaad1144":"## Observation :- \n\n* Features 80-117 have high correlation with each other \n* Feature 17-25 & Feature 29-33 have high correlation\n","939fc520":"####  Observation - Trade reponse is above zero for Day-446 compared to Day 0 ","f80c8d12":"# Pearson Correlation between features","10564a5d":"### visualize the results - Show top 20 features","8b00dfd5":"# Automatic Data Vizualisation with Dabl ","52c97656":"## Model Explainability with SHAP","5466e273":"### There is Huge trend and seasonality in the trade data ","39894fdf":"<font color=\"red\" size=5>Please upvote this kernel if you like it. It motivates me to create kernal with great content  :) <\/font>","764d24b4":"## Import necessary libraries","176c2483":"## Lets see how the trade transactions in Day 5 ","ec980eaa":"# Feature interation with model output ","16040d14":"### Trade Day - 1","8f92a8bb":"### Tade of maximum weightage happends in Day-446 ","1ac71038":"## Weight\n\n> *Each trade has an associated `weight` and `resp`, which together represents a return on the trade.\nTrades with `weight = 0` were intentionally included in the dataset for completeness, although such trades will not contribute towards the scoring evaluation. So we ignore 17% data while doing modeling*","b1ccf6d1":"# Conclustion :- \n\nThis notebook covers detail trend analysis of response and weights at day level , Interaction of target variable with independent variables****","484eb04e":"\n# Jane Street Market Prediction: A Commplete EDA\n\nThis is a simple exploratory data analysis (EDA) of the files provided for the [Jane Street Market Prediction](https:\/\/www.kaggle.com\/c\/jane-street-market-prediction) time series competition.","e1292373":"# Day - 5 Trade Txn Scatter Plot ","1083f677":"## Subset data preperation for Feature importance and model explainability","a9675ba9":"# Save memory !!! \ud83d\ude80\ud83d\ude80\ud83d\ude80 Compure faster \ud83d\ude80\ud83d\ude80\ud83d\ude80","f58fa5af":"### Its has been oberved that Cummulative sum of trade response varies over days","bdc77b6b":"# Mean of Weights accross dates","0fe43c41":"### Observation :- \n\n Bunch of fields have missing elements , Panoramically missing value pattern looks even accross trading days","45eb2f79":"## Trade Action\n\n`action`: 1 to make the trade and 0 to pass on it.In view of this let us add a new 'binary' column to our test dataset called `action` such that if `resp` is positive then `action=1` else `action=0`","f7ff03f4":"# Sum of Weights accross dates","3a2fa17d":"## Curious nature of feature 1 ","cd1d2eb2":"## Observation :- For Day 5 important features for Feature 43,6,35,45,64 etc","9b2d10bb":"### Trade Day - 0","7daa6cc2":"For Model explainability you can visit another kernel for more details \n\nhttps:\/\/www.kaggle.com\/praveengovi\/jane-street-model-interpretability-shap\n","6c004971":"## Feature Importance by PermutationImportance"}}