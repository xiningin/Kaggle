{"cell_type":{"cda72fd2":"code","6d0e5375":"code","92dd5232":"code","c7eacad6":"code","7fdee130":"code","1842cfa7":"code","fb03b73d":"code","d936c66c":"code","f7131dae":"code","4f62ae43":"code","d8261f74":"code","92307dae":"code","2af41d90":"code","6e14326c":"code","cbf41ce5":"code","89f0964d":"code","7178e643":"code","f053838a":"code","d8de0652":"code","ca38016c":"code","b281d18f":"code","69a10e75":"code","e00ffb20":"code","7b3cc25f":"code","e63a3eb3":"code","2d104d85":"code","3cccde7e":"code","037af2ce":"code","54219fbd":"code","9e741758":"code","9f09c4f8":"code","a32870ca":"code","0c0efe48":"code","e5cb2c8f":"code","152110f2":"code","e8b69baf":"code","8ccaabd1":"code","abd7d44a":"code","09857c78":"code","777a2bd1":"code","33af4d86":"code","cfdfc5f0":"code","6dbaf58a":"code","68831a69":"code","84f6bb38":"code","bf591c8b":"code","2eae10f6":"code","9a4d51ba":"markdown","e18027ed":"markdown","2fcbeb48":"markdown","40c8fad1":"markdown","5c83457e":"markdown","74eaaf2f":"markdown","4afe57dc":"markdown"},"source":{"cda72fd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d0e5375":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_theme(style=\"darkgrid\")\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, MinMaxScaler\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error","92dd5232":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","c7eacad6":"train.describe()","7fdee130":"train.head()","1842cfa7":"train.info()","fb03b73d":"train.shape, test.shape","d936c66c":"test.columns","f7131dae":"plt.figure(figsize=(10,7))\nsns.heatmap(train.corr(),annot=True)","4f62ae43":"plt.figure(figsize=(10,7))\nsns.countplot(data=train, x='Survived', hue='Sex')","d8261f74":"train.groupby(['Survived', 'Sex'])['Sex'].count()","92307dae":"rate_male = train.loc[train['Sex'] == 'male']['Survived'].sum()\/train.loc[train['Sex'] == 'male']['Survived'].count()\nrate_female = train.loc[train['Sex'] == 'female']['Survived'].sum()\/train.loc[train['Sex'] == 'female']['Survived'].count()\nprint(f'Rate for male survive: {rate_male}')\nprint(f'Rate for female survive: {rate_female}')","2af41d90":"plt.figure(figsize=(10,7))\nsns.histplot(train['Age'], kde=True)","6e14326c":"plt.figure(figsize=(10,7))\nsns.violinplot(data=train, x='Survived', y='Age', hue='Sex', split=True, inner='quartile')","cbf41ce5":"plt.figure(figsize=(10, 7))\nsns.barplot(x='Pclass', y='Survived', hue='Sex', data=train)","89f0964d":"plt.figure(figsize=(10, 7))\nsns.scatterplot(x='Age', y='Fare', hue='Sex', data=train)","7178e643":"plt.figure(figsize=(10, 7))\nsns.pairplot(data=train, hue='Sex')","f053838a":"train.isnull().sum()","d8de0652":"test.isnull().sum()","ca38016c":"train.drop(['PassengerId', 'Cabin', 'Name', 'Ticket'], axis=1, inplace=True)\ntest.drop(['PassengerId', 'Cabin', 'Name', 'Ticket'], axis=1, inplace=True)","b281d18f":"train['Age'] = train['Age'].fillna(train['Age'].median(),axis=0)\ntest['Age'] = train['Age'].fillna(train['Age'].median(),axis=0)","69a10e75":"train['Embarked'] = train['Embarked'].fillna(method='bfill')\ntest['Fare'] = test['Fare'].fillna(method='bfill')","e00ffb20":"train","7b3cc25f":"def feat_split (df):\n    categ_feat = []\n    num_feat = []\n\n    for col in list(df.columns):\n        if (df[col].dtype == 'float64') | (df[col].dtype == 'int64'):\n            num_feat.append(col)\n    \n        else:\n            categ_feat.append(col)\n            \n    return categ_feat, num_feat","e63a3eb3":"def encoder (X, categ_feat):\n    X_encoded = pd.get_dummies(X[categ_feat], drop_first=True)\n    return X_encoded","2d104d85":"def scaler (df):\n    scaler = RobustScaler()\n    X_scaled = scaler.fit_transform(df)\n    X_scaled = pd.DataFrame(X_scaled, columns=df.columns)\n    return X_scaled","3cccde7e":"categ_feat, num_feat = feat_split(train)","037af2ce":"categ_feat","54219fbd":"X_encoded = encoder(train, categ_feat)","9e741758":"X_encoded","9f09c4f8":"X = pd.concat([train[num_feat],X_encoded],axis=1)\ny = X['Survived']\nX = X.drop('Survived', axis='columns')","a32870ca":"X_scaled = scaler(X)","0c0efe48":"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state=0)","e5cb2c8f":"model_params = {\n    'logistic_regression' : {        \n        'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n        'params': {\n             'C': [1, 5, 10, 15, 20],\n        }\n    },\n    'random_forest' : {\n        'model': RandomForestClassifier(),\n        'params': {\n            'n_estimators': np.arange(50, 550, 50),\n            'max_depth': np.arange(1, 6, 1)\n        }\n    },\n  #  'knn': {\n  #      'model': KNeighborsClassifier(),\n  #      'params' : {\n #           'n_neighbors' : [3, 4, 5, 7, 9, 10, 11]\n #       }\n #       \n #   },\n  #  'svm' : {\n  #      'model': SVC(),\n #       'params': {\n #          'gamma': ['auto', 'scale'],\n #           'C': [1, 5, 10, 15, 20],\n #           'kernel': ['rbf', 'linear', 'poly']\n   #     }\n  #  },\n    'xgb':{\n        'model': XGBClassifier(n_estimators=1000, learning_rate=0.05),\n        'params':{}\n    }\n}","152110f2":"scores = []\n\nfor model_name, mp in model_params.items():\n    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n    clf.fit(X, y)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })","e8b69baf":"scores = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\nscores","8ccaabd1":"model = RandomForestClassifier(max_depth=4, n_estimators=100)","abd7d44a":"model.fit(X_train, y_train)","09857c78":"y_pred = model.predict(X_test)","777a2bd1":"model.score(X_test, y_test)","33af4d86":"cm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True)","cfdfc5f0":"def score_predictions(y_test, y_pred):\n    print(\n        f\"\"\"\n        MSE: {mean_squared_error(y_test, y_pred)}\n        RMSE: {mean_squared_error(y_test, y_pred)}\n        MAE: {mean_absolute_error(y_test, y_pred)}\n        R_SQR: {r2_score(y_test, y_pred)}\n        RMSLE: {mean_squared_log_error(y_test, y_pred)}\n        \"\"\"\n    )\n    \nscore_predictions(y_test, model.predict(X_test))","6dbaf58a":"print(classification_report(y_test, y_pred))","68831a69":"categ_feat_test, num_feat_test = feat_split(test)\nX_test_encoded = encoder(test, categ_feat_test)\nX_test_sub = pd.concat([test[num_feat_test],X_test_encoded],axis=1)","84f6bb38":"model.fit(X, y)","bf591c8b":"y_test_pred = model.predict(X_test_sub)\ny_test_pred","2eae10f6":"output = pd.DataFrame({'PassengerId': pd.read_csv('..\/input\/titanic\/test.csv').PassengerId, 'Survived': y_test_pred})\noutput.to_csv('submission.csv', index=False)","9a4d51ba":"## EDA","e18027ed":"## Prepering Data","2fcbeb48":"## Submit Test","40c8fad1":"## Data Overview","5c83457e":"## Modeling","74eaaf2f":"## Import Dataset","4afe57dc":"## Import Libraries"}}