{"cell_type":{"b0a5da16":"code","76829b81":"code","0d121bac":"code","72f0d6c7":"code","e1c7d984":"code","00ce24c1":"code","33411638":"code","7935a70e":"code","b387279c":"code","0c7309de":"code","e0024580":"code","67708cf7":"code","5e383fab":"code","f3dd0114":"code","aca58ac3":"code","395709e1":"code","f935eb07":"code","d802d4ad":"code","11cf80b6":"code","7ae360ff":"code","044a7494":"code","c13188ff":"code","edd12d1f":"code","578def4c":"code","5234069d":"code","c38bbf87":"code","a59a81a3":"code","8d7c2a61":"code","9c37e9db":"code","0cb596ab":"code","85aab632":"code","1382799e":"code","7a480d81":"code","81f9cc3b":"code","ff298678":"code","44b6c311":"code","6748a634":"code","52937866":"code","0fc062bc":"code","98cdfd91":"code","2fea4429":"code","3df900d7":"code","f5ded730":"code","38fe73ef":"code","2d2a96b2":"code","b57bb07f":"code","4539c063":"code","e873f8f5":"code","99b11e9b":"code","42380f59":"code","19fb444d":"code","fac91c03":"code","f7b52710":"code","c5a56891":"code","95162951":"code","b1af9ba2":"code","63b88ffe":"code","2273b434":"code","8f778f2c":"code","2d3bb882":"code","adb3fa8d":"code","ffb6df5f":"code","31b008df":"code","d5f03554":"code","ffe5cfc8":"code","a9729afa":"code","83f6ab38":"code","4cd84590":"markdown","fdc8d492":"markdown","e072e941":"markdown","32436a30":"markdown","89947a0a":"markdown","1e37cd80":"markdown","b9a4afcf":"markdown","0edd5224":"markdown","b4a6fa0f":"markdown","23d59733":"markdown","8881e2d2":"markdown","ca21633b":"markdown","ff51bcfe":"markdown","3f52a875":"markdown","dd82ef5e":"markdown","e623ccf6":"markdown","a838a180":"markdown","fd91b87d":"markdown","21c520a5":"markdown","9f76483d":"markdown","31748a52":"markdown","e3af328d":"markdown","ce11c216":"markdown","b726047f":"markdown","9a53f25f":"markdown","4445feb2":"markdown","8d12782d":"markdown","62a38df2":"markdown","7de5ba82":"markdown","5bf37227":"markdown","8436d688":"markdown","50f6f0f2":"markdown","0548dbd0":"markdown"},"source":{"b0a5da16":"# for numerical analysis\nimport numpy as np # linear algebra\n\n# to store and process in a dataframe\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Visualizations, for ploting graphs\nimport matplotlib.pyplot as plt\n\n# image processing\nimport matplotlib.image as mpimg\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# advanced ploting\nimport seaborn as sns","76829b81":"import warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\n# Image manipulations\nfrom PIL import Image\n\n# Timing utility\nfrom timeit import default_timer as timer\n\nfrom IPython.core.interactiveshell import InteractiveShell\n\n# Printing out all outputs\nInteractiveShell.ast_node_interactivity = 'all'","0d121bac":"# PyTorch\nimport torchvision\nfrom torchvision import transforms, datasets, models\n\nimport torch\nfrom torch import optim, cuda\nfrom torch.utils.data import DataLoader, sampler\nfrom torch.autograd import Variable\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d\nfrom torch.nn import Module, Softmax, BatchNorm2d, Dropout\n\nimport gc","72f0d6c7":"# file operations\n\nimport shutil\nimport os\nfrom os import walk\n\n# to list files\nimport glob\n\nprint(os.listdir(\"..\/input\"))","e1c7d984":"# current working directory\nos.getcwd()","00ce24c1":"# no. of files\n\ndef list_files(startpath):\n    \n    for root, dirs, files in os.walk(startpath):\n        \n        level = root.replace(startpath, '').count(os.sep)\n        \n        indent = ' ' * 4 * (level)\n        \n        print('{}{}'.format(indent, os.path.basename(root)), '-', len(os.listdir(root)))\n        \nfolder = '\/kaggle\/input'\nlist_files(folder)","33411638":"folder = '\/kaggle\/working'\nlist_files(folder)","7935a70e":"# list of files in the dataset \/input\/ecg-images\/MITBIH_img\n\nos.listdir('..\/input\/ecg-images\/MITBIH_img')","b387279c":"# Classes in the data\n\nECG_list = os.listdir('..\/input\/ecg-images\/MITBIH_img')\n\nn_classes = len(ECG_list)\n\nprint(f'There are {n_classes} different classes.')","0c7309de":"ECG_list","e0024580":"classes = ('S', 'V', 'Q', 'N', 'F')","67708cf7":"N_imgs = os.listdir('..\/input\/ecg-images\/MITBIH_img\/N')\nprint('# of Normal beats: ',len(N_imgs))\n\nF_imgs = os.listdir('..\/input\/ecg-images\/MITBIH_img\/F')\nprint('# of Fusion beats: ',len(F_imgs))\n\nQ_imgs = os.listdir('..\/input\/ecg-images\/MITBIH_img\/Q')\nprint('# of Unknown beats: ',len(Q_imgs))\n\nV_imgs = os.listdir('..\/input\/ecg-images\/MITBIH_img\/V')\nprint('# of Ventricular ectopic beats: ',len(V_imgs))\n\nS_imgs = os.listdir('..\/input\/ecg-images\/MITBIH_img\/S')\nprint('# of Supraventricular ectopic beats: ',len(S_imgs))","5e383fab":"#print(N_dir)\nprint(N_imgs[0])","f3dd0114":"def imshow(image):\n    \"\"\"Display image\"\"\"\n    plt.figure(figsize=(6, 6))\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()","aca58ac3":"image = mpimg.imread(os.path.join('..\/input\/ecg-images\/MITBIH_img\/N', N_imgs[0]))\n\nimshow(image)","395709e1":"print(image.shape)\nprint(type(image))","f935eb07":"# Define a function which will plot several images\n\ndef image_shows(folder, number_of_images):\n    \n    n=number_of_images;\n    \n    folder_list = os.listdir(folder)\n    \n    fig, axes = plt.subplots(nrows = 1, ncols=n, figsize=(20, 10))\n    \n    for i in range(n):\n        \n        print(os.path.join(folder, folder_list[i]))\n        \n        image = mpimg.imread(os.path.join(folder, folder_list[i]));\n        \n        axes[i].imshow(image);","d802d4ad":"# Examples of N\n\nimage_shows(folder = '..\/input\/ecg-images\/MITBIH_img\/N', number_of_images = 6)","11cf80b6":"# Examples of S\n\nimage_shows(folder = '..\/input\/ecg-images\/MITBIH_img\/S', number_of_images = 6)","7ae360ff":"# Examples of Q\n\nimage_shows(folder = '..\/input\/ecg-images\/MITBIH_img\/Q', number_of_images = 6)","044a7494":"# Examples of V\n\nimage_shows(folder = '..\/input\/ecg-images\/MITBIH_img\/V', number_of_images = 6)","c13188ff":"# Examples of F\n\nimage_shows(folder = '..\/input\/ecg-images\/MITBIH_img\/F', number_of_images = 6)","edd12d1f":"import cv2","578def4c":"imgcv = cv2.imread(os.path.join('..\/input\/ecg-images\/MITBIH_img\/N', N_imgs[0]))\nplt.imshow(imgcv)\nplt.show();","5234069d":"imgcv.shape","c38bbf87":"b = imgcv.copy()\n# set green and red channels to 0\nb[:, :, 1] = 0\nb[:, :, 2] = 0\n\n\ng = imgcv.copy()\n# set blue and red channels to 0\ng[:, :, 0] = 0\ng[:, :, 2] = 0\n\nr = imgcv.copy()\n# set blue and green channels to 0\nr[:, :, 0] = 0\nr[:, :, 1] = 0","a59a81a3":"# plot data\n\nfig = plt.figure(figsize=(15,15))\n\nplot_1 = plt.subplot(131)\nplot_1.imshow(r);\n\n#plt.subplot(131).imshow(b);\n\nplot_2 = plt.subplot(132, sharex=plot_1, sharey=plot_1)\nplt.setp(plot_2.get_yticklabels(), visible=False);\nplot_2.imshow(b);\n\nplot_3 = plt.subplot(133, sharex=plot_1, sharey=plot_1)\nplt.setp(plot_3.get_yticklabels(), visible=False);\nplot_3.imshow(g);\n\nplt.show();","8d7c2a61":"for root, dirs, files in os.walk('\/kaggle\/'):\n    print(root)","9c37e9db":"os.makedirs('..\/working\/train\/N', exist_ok = True)\nos.makedirs('..\/working\/train\/F', exist_ok = True)\nos.makedirs('..\/working\/train\/Q', exist_ok = True)\nos.makedirs('..\/working\/train\/V', exist_ok = True)\nos.makedirs('..\/working\/train\/S', exist_ok = True)\n\n\nos.makedirs('..\/working\/test\/N', exist_ok = True)\nos.makedirs('..\/working\/test\/F', exist_ok = True)\nos.makedirs('..\/working\/test\/Q', exist_ok = True)\nos.makedirs('..\/working\/test\/V', exist_ok = True)\nos.makedirs('..\/working\/test\/S', exist_ok = True)","0cb596ab":"for root, dirs, files in os.walk('\/kaggle\/'):\n    print(root)","85aab632":"for file_name in F_imgs[0:round(len(F_imgs)\/5)]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/F', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/test\/F');\n        \n        \nfor file_name in F_imgs[round(len(F_imgs)\/5):]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/F', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/train\/F');\n\nprint(\"done\")","1382799e":"# N_imgs = os.listdir('..\/input\/ecg-images\/MITBIH_img\/N')\n\nfor file_name in N_imgs[0:round(len(N_imgs)\/5)]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/N', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/test\/N');\n        \nfor file_name in N_imgs[round(len(N_imgs)\/5):]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/N', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/train\/N');\n\nprint(\"done\") ","7a480d81":"for file_name in V_imgs[0:round(len(V_imgs)\/5)]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/V', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/test\/V');\n        \n        \nfor file_name in V_imgs[round(len(V_imgs)\/5):]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/V', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/train\/V');\n\nprint(\"done\")","81f9cc3b":"for file_name in Q_imgs[0:round(len(Q_imgs)\/5)]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/Q', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/test\/Q');\n        \n        \nfor file_name in Q_imgs[round(len(Q_imgs)\/5):]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/Q', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/train\/Q');\n\nprint(\"done\")","ff298678":"S_imgs = os.listdir('..\/input\/ecg-images\/MITBIH_img\/S')\n\nfor file_name in S_imgs[0:round(len(S_imgs)\/5)]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/S', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/test\/S');\n        \n        \nfor file_name in S_imgs[round(len(S_imgs)\/5):]:\n    \n    full_file_name = os.path.join('..\/input\/ecg-images\/MITBIH_img\/S', file_name);\n    \n    if os.path.isfile(full_file_name):\n        \n        a = shutil.copy(full_file_name, '..\/working\/train\/S');\n\nprint(\"done\")","44b6c311":"folder = '\/kaggle\/working'\nlist_files(folder)","6748a634":"N_imgs       = len(os.listdir('..\/input\/ecg-images\/MITBIH_img\/N'))\nN_train_imgs = len(os.listdir('..\/working\/train\/N'))\nN_test_imgs  = len(os.listdir('..\/working\/test\/N'))\nprint('number of N images at the original file: ', N_imgs)\nprint('total number of train and test picts:    ', N_train_imgs + N_test_imgs)","52937866":"S_imgs       = len(os.listdir('..\/input\/ecg-images\/MITBIH_img\/S'))\nS_train_imgs = len(os.listdir('..\/working\/train\/S'))\nS_test_imgs  = len(os.listdir('..\/working\/test\/S'))\nprint('number of S images at the original file: ', S_imgs)\nprint('total number of train and test picts:    ', S_train_imgs + S_test_imgs)","0fc062bc":"F_imgs       = len(os.listdir('..\/input\/ecg-images\/MITBIH_img\/F'))\nF_train_imgs = len(os.listdir('..\/working\/train\/F'))\nF_test_imgs  = len(os.listdir('..\/working\/test\/F'))\nprint('number of F images at the original file: ', F_imgs)\nprint('total number of train and test picts:    ', F_train_imgs + F_test_imgs)","98cdfd91":"V_imgs       = len(os.listdir('..\/input\/ecg-images\/MITBIH_img\/V'))\nV_train_imgs = len(os.listdir('..\/working\/train\/V'))\nV_test_imgs  = len(os.listdir('..\/working\/test\/V'))\nprint('number of V images at the original file: ', V_imgs)\nprint('total number of train and test picts:    ', V_train_imgs + V_test_imgs)","2fea4429":"Q_imgs       = len(os.listdir('..\/input\/ecg-images\/MITBIH_img\/Q'))\nQ_train_imgs = len(os.listdir('..\/working\/train\/Q'))\nQ_test_imgs  = len(os.listdir('..\/working\/test\/Q'))\nprint('number of Q images at the original file: ', Q_imgs)\nprint('total number of train and test picts:    ', Q_train_imgs + Q_test_imgs)","3df900d7":"# Define default PATH\n\nTRAIN_PATH        = '..\/working\/train'\n\ntransform         = transforms.Compose(\n                                       [transforms.Resize([120,120]),\n                                        transforms.Grayscale(), \n                                        transforms.ToTensor(),\n                                        transforms.Normalize((0.5), (0.5))\n                                       ])\n  \ntrain_data_set    = datasets.ImageFolder(root=TRAIN_PATH, transform=transform)\n\nbatch_size=32\n\ntrain_data_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=True)","f5ded730":"TEST_PATH        = '..\/working\/test'\n  \ntest_data_set    = datasets.ImageFolder(root=TEST_PATH, transform=transform)\n\ntest_data_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=True)","38fe73ef":"# Run this to test your data loader\n\nimages, labels = next(iter(train_data_loader))","2d2a96b2":"print(type(images))\n\nprint(images.size())\n\nprint(\"\")\nprint(\"Batch Size:   \",images.size()[0])\nprint(\"Channel Size: \",images.size()[1])\nprint(\"Image Height: \",images.size()[2])\nprint(\"Image Width:  \",images.size()[3])","b57bb07f":"def imshow_tensor(image, ax=None, title=None, normalize=True):\n    \n    \"\"\"Imshow for Tensor.\"\"\"\n    \n    if ax is None:\n        fig, ax = plt.subplots()\n        \n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.5])\n        std = np.array([0.5])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    \n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax","4539c063":"# show images\n\nncol = 8;\n\nimshow_tensor(torchvision.utils.make_grid(images,nrow = ncol));","e873f8f5":"# print labels\n\nclasses = ('N', 'Q', 'F', 'S', 'V')\n\nnrow = batch_size\/ncol;\n\nfor row in range(int(nrow)):\n    \n    print(' '.join('%5s' % classes[labels[(row*ncol)+j]] for j in range(ncol))) ","99b11e9b":"# CNN Architect\n\nclass ConvNet_1(nn.Module):\n    \n    def __init__(self):\n        \n        super(ConvNet_1, self).__init__()\n\n        self.layer_1  = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1)\n        \n        self.relu1    = nn.ReLU(inplace=True)\n        \n        self.maxpool1 = MaxPool2d(kernel_size=2)\n        \n\n        self.layer_2  = nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=1, padding=1)\n        \n        self.relu2    = nn.ReLU(inplace=True)\n        \n        self.maxpool2 = MaxPool2d(kernel_size=2)\n        \n        self.drop_out = nn.Dropout()\n        \n        \n        # out_channels = 4, number of classes = 5\n        \n        # image width = 120, image height = 120 after two maxpooling 120 -> 60 -> 30\n        \n        self.fc1 = nn.Linear(4 * 30 * 30, 5)\n        \n    # Defining the forward pass\n\n    def forward(self, x):\n        \n        out = self.layer_1(x)\n        \n        out = self.relu1(out)\n        \n        out = self.maxpool1(out)\n        \n        \n        out = self.layer_2(out)\n        \n        out = self.relu2(out)\n        \n        out = self.maxpool2(out)\n        \n        \n        out = out.reshape(out.size(0), -1)\n        \n        out = self.drop_out(out)\n        \n        out = self.fc1(out)\n        \n        return out\n    \n# Define Model\n\nmodel_1 = ConvNet_1()\n\nprint(model_1)","42380f59":"# Define Criterion\n\ncriterion = nn.CrossEntropyLoss()\n\n# Define Optimizer\n\noptimizer = optim.SGD(model_1.parameters(), lr=0.001, momentum=0.9)","19fb444d":"# Whether to train on a gpu and Number of gpus\n\nif cuda.is_available(): \n    \n    print(f'{cuda.device_count()} number of gpus are detected and available.')\n    \nelse:\n        \n    print(f'Train on gpu is not available')\n        \n        ","fac91c03":"# This part is working\n\n# Train the model\n\nif torch.cuda.is_available():\n    \n    MODEL = model_1.cuda()\n    CRITERION = criterion.cuda()\n    print(f'Model is started training on {cuda.device_count()} number of gpus.')\n    print(\"Devise is cuda\")\n    \nelse:\n    \n    MODEL = model_1\n    CRITERION = criterion\n    print(\"Devise is cpu and model is started training.\")\n\ntotal_step = len(train_data_loader)\nloss_list = []\nacc_list = []\n\nnum_epochs = 1\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nall_con_mat = torch.zeros([num_epochs, 5, 5], dtype=torch.int32, device=device)\n\nfor epoch in range(num_epochs):\n    \n    # define empty tensor 5*5 beginning of every epoch\n    # tensor [row,column]\n    con_mat = torch.zeros([5, 5], dtype=torch.int32, device=device)\n    \n    for i, data in enumerate(train_data_loader):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # optimization\n        optimizer.zero_grad()\n        \n        # Forward to get output\n        outputs = MODEL(inputs)\n        # Calculate Loss\n        loss = CRITERION(outputs, labels)\n        # Backward propagation\n        loss.backward()\n        # Updating parameters\n        optimizer.step()\n        \n        # Store loss\n        loss_list.append(loss.item())\n    \n        # Calculate labels size\n        total = labels.size(0)\n        \n        # Outputs.data has dimension batch size * 5\n        # torch.max returns the max value of elements(_) and their indices(predicted) in the tensor array\n        _, predicted = torch.max(outputs.data, 1)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        # Store accuracy\n        acc_list.append(correct \/ total)\n        \n        \n        # Build Confusion Matrix\n        for element in range(total):\n            \n            # con_mat[row,column]\n            # con_mat[predictions, actual]\n            \n            con_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n        if (i + 1) % 300 == 0:                             # every 300 mini-batches...\n            \n            print('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  \n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct \/ total) * 100))\n    print(con_mat)\n            \n    all_con_mat[epoch] = con_mat            \n            \nprint('Finished Training')\n\nplt.plot(loss_list);\nplt.show();\n\nplt.plot(acc_list);\nplt.show();","f7b52710":"# SUM FOR EACH COLUMN\n\n# N Q S V F\n\nprint(torch.sum(con_mat, dim=0))","c5a56891":"folder = '\/kaggle\/working'\nlist_files(folder)","95162951":"# RECALL\n\n# PRECISION\n\n# F1-score = 2 \u00d7 (precision \u00d7 recall)\/(precision + recall)\n\nclass_list = ['N', 'Q', 'S', 'V', 'F']\n\nf1_score_list=[0,0,0,0,0]\n\nprecision_list=[0,0,0,0,0]\n\nrecall_list=[0,0,0,0,0]\n\ndelta = 0.0000000000001\n\nfor i in range(torch.sum(con_mat, dim=0).size(0)): \n    \n    recall_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=0)[i].item()+delta)\n    \n    precision_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=1)[i].item()+delta)\n    \n    f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n    \n    print('class: {:<2},total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(con_mat, dim=0)[i].item(),\n                          con_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))","b1af9ba2":"# This part is working\n\nif torch.cuda.is_available():\n    \n    MODEL = model_1.cuda()\n    CRITERION = criterion.cuda()\n    print(\"cuda\")\n    \nelse:\n    \n    MODEL = model_1\n    CRITERION = criterion\n    print(\"cpu\")\n\n# Train the model\n\ntotal_step = len(train_data_loader)\nloss_list = []\nacc_list = []\n\nnum_epochs = 5\n\nclass_list = ['N', 'Q', 'S', 'V', 'F']\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nall_con_mat = torch.zeros([num_epochs, 5, 5], dtype=torch.int32, device=device)\n\nfor epoch in range(num_epochs):\n    \n    f1_score_list=[0,0,0,0,0]\n\n    precision_list=[0,0,0,0,0]\n\n    recall_list=[0,0,0,0,0]\n    \n    delta = 0.0000000000001 \n    \n    # define empty tensor 5*5 beginning of every epoch\n    # tensor [row,column]\n    con_mat = torch.zeros([5, 5], dtype=torch.int32, device=device)\n    \n    for i, data in enumerate(train_data_loader):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # optimization\n        optimizer.zero_grad()\n        \n        # Forward to get output\n        outputs = MODEL(inputs)\n        # Calculate Loss\n        loss = CRITERION(outputs, labels)\n        # Backward propagation\n        loss.backward()\n        # Updating parameters\n        optimizer.step()\n        \n        # Store loss\n        loss_list.append(loss.item())\n    \n        # Calculate labels size\n        total = labels.size(0)\n        \n        # Outputs.data has dimension batch size * 5\n        # torch.max returns the max value of elements(_) and their indices(predicted) in the tensor array\n        _, predicted = torch.max(outputs.data, 1)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        # Store accuracy\n        acc_list.append(correct \/ total)\n        \n        for element in range(total):\n            \n            # con_mat[row,column]\n            # con_mat[predictions, actual]\n            con_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n        if (i + 1) % 300 == 0:                             # every 300 mini-batches...\n            \n            print('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  \n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct \/ total) * 100))\n    print(con_mat)\n            \n    all_con_mat[epoch] = con_mat\n    \n    # Print Confusion Matrix\n    \n    for i in range(torch.sum(con_mat, dim=0).size(0)): \n    \n        recall_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=0)[i].item()+delta)\n    \n        precision_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=1)[i].item()+delta)\n    \n        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n        \n    \n        print('class name: {}, total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(con_mat, dim=0)[i].item(),\n                          con_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))\n    \n            \nprint('Finished Training')\n\nplt.plot(loss_list);\nplt.show();\n\nplt.plot(acc_list);\nplt.show();","63b88ffe":"all_con_mat","2273b434":"confusion_mat = torch.zeros([5, 5], dtype=torch.int32, device=device)\n\nwith torch.no_grad():\n    \n    for data in test_data_loader:\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        outputs = MODEL(inputs)\n        \n        _, predicted = torch.max(outputs.data, 1)\n        \n        total = labels.size(0)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        for element in range(total):\n            \n            # confusion_mat[row,column]\n            # confusion_mat[predictions, actual]\n            confusion_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n    print(confusion_mat)","8f778f2c":"class_list = ['N', 'Q', 'S', 'V', 'F']\n\nf1_score_list=[0,0,0,0,0]\n\nprecision_list=[0,0,0,0,0]\n\nrecall_list=[0,0,0,0,0]\n    \ndelta = 0.0000000000001 \n\n\nfor i in range(torch.sum(confusion_mat, dim=0).size(0)): \n    \n        recall_list[i] = confusion_mat[i][i].item()\/(torch.sum(confusion_mat, dim=0)[i].item()+delta)\n    \n        precision_list[i] = confusion_mat[i][i].item()\/(torch.sum(confusion_mat, dim=1)[i].item()+delta)\n    \n        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n        \n    \n        print('class name: {}, total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(confusion_mat, dim=0)[i].item(),\n                          confusion_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))\n    ","2d3bb882":"# CNN Architect\n\nclass ConvNet_2(nn.Module):\n    \n    def __init__(self):\n        \n        super(ConvNet_2, self).__init__()\n\n        self.layer_1  = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1)\n        \n        self.relu1    = nn.ReLU(inplace=True)\n        \n        self.maxpool1 = MaxPool2d(kernel_size=2)\n        \n\n        self.layer_2  = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1)\n        \n        self.relu2    = nn.ReLU(inplace=True)\n        \n        self.maxpool2 = MaxPool2d(kernel_size=2)\n        \n        self.drop_out = nn.Dropout()\n        \n        \n        # out_channels = 8, number of classes = 5\n        \n        # image width = 120, image height = 120 after two maxpooling 120 -> 60 -> 30\n        \n        self.fc1 = nn.Linear(8 * 30 * 30, 5)\n        \n    # Defining the forward pass\n\n    def forward(self, x):\n        \n        out = self.layer_1(x)\n        \n        out = self.relu1(out)\n        \n        out = self.maxpool1(out)\n        \n        \n        out = self.layer_2(out)\n        \n        out = self.relu2(out)\n        \n        out = self.maxpool2(out)\n        \n        \n        out = out.reshape(out.size(0), -1)\n        \n        out = self.drop_out(out)\n        \n        out = self.fc1(out)\n        \n        return out\n    \n# Define Model\n\nmodel_2 = ConvNet_2()\n\nprint(model_2)","adb3fa8d":"if torch.cuda.is_available():\n    \n    MODEL = model_2.cuda()\n    CRITERION = criterion.cuda()\n    print(\"cuda\")\n    \nelse:\n    \n    MODEL = model_2\n    CRITERION = criterion\n    print(\"cpu\")\n\n# Train the model\n\ntotal_step = len(train_data_loader)\nloss_list = []\nacc_list = []\n\nnum_epochs = 5\n\nclass_list = ['N', 'Q', 'S', 'V', 'F']\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nall_con_mat = torch.zeros([num_epochs, 5, 5], dtype=torch.int32, device=device)\n\nfor epoch in range(num_epochs):\n    \n    f1_score_list=[0,0,0,0,0]\n\n    precision_list=[0,0,0,0,0]\n\n    recall_list=[0,0,0,0,0]\n    \n    delta = 0.0000000000001 \n    \n    # define empty tensor 5*5 beginning of every epoch\n    # tensor [row,column]\n    con_mat = torch.zeros([5, 5], dtype=torch.int32, device=device)\n    \n    for i, data in enumerate(train_data_loader):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # optimization\n        optimizer.zero_grad()\n        \n        # Forward to get output\n        outputs = MODEL(inputs)\n        # Calculate Loss\n        loss = CRITERION(outputs, labels)\n        # Backward propagation\n        loss.backward()\n        # Updating parameters\n        optimizer.step()\n        \n        # Store loss\n        loss_list.append(loss.item())\n    \n        # Calculate labels size\n        total = labels.size(0)\n        \n        # Outputs.data has dimension batch size * 5\n        # torch.max returns the max value of elements(_) and their indices(predicted) in the tensor array\n        _, predicted = torch.max(outputs.data, 1)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        # Store accuracy\n        acc_list.append(correct \/ total)\n        \n        for element in range(total):\n            \n            # con_mat[row,column]\n            # con_mat[predictions, actual]\n            con_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n        if (i + 1) % 300 == 0:                             # every 300 mini-batches...\n            \n            print('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  \n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct \/ total) * 100))\n    print(con_mat)\n            \n    all_con_mat[epoch] = con_mat\n    \n    # Print Confusion Matrix\n    \n    for i in range(torch.sum(con_mat, dim=0).size(0)): \n    \n        recall_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=0)[i].item()+delta)\n    \n        precision_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=1)[i].item()+delta)\n    \n        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n        \n    \n        print('class name: {}, total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(con_mat, dim=0)[i].item(),\n                          con_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))\n    \n            \nprint('Finished Training')\n\nplt.plot(loss_list);\nplt.show();\n\nplt.plot(acc_list);\nplt.show();","ffb6df5f":"# CNN Architect\n\nclass ConvNet_3(nn.Module):\n    \n    def __init__(self):\n        \n        super(ConvNet_3, self).__init__()\n\n        self.conv1    = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1)\n        \n        self.relu1    = nn.ReLU(inplace=True)\n        \n        self.pool1    = MaxPool2d(kernel_size=2)\n        \n\n        self.conv2    = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1)\n        \n        self.lrelu2   = nn.LeakyReLU(0.1)\n        \n        self.bn2      = nn.BatchNorm2d(8)\n        \n        self.pool2    = MaxPool2d(kernel_size=2)\n        \n        self.dropout2 = nn.Dropout(p=0.25)\n        \n        \n        # out_channels = 8, number of classes = 5\n        \n        # image width = 120, image height = 120 after two maxpooling 120 -> 60 -> 30\n        \n        self.fc3      = nn.Linear(8 * 30 * 30, 100)\n        \n        self.relu3    = nn.ReLU(inplace=True)\n        \n        self.dropout3 = nn.Dropout(p=0.5)\n        \n        self.fc4 = nn.Linear(100, 5)\n        \n    # Defining the forward pass\n\n    def forward(self, x):\n        \n        out = self.conv1(x)\n        \n        out = self.relu1(out)\n        \n        out = self.pool1(out)\n        \n        \n        \n        out = self.conv2(out)\n        \n        out = self.lrelu2(out)\n        \n        out = self.bn2(out)\n        \n        out = self.pool2(out)\n        \n        out = self.dropout2(out)\n        \n        \n        out = out.reshape(out.size(0), -1)\n        \n        \n        out = self.fc3(out)\n        \n        out = self.relu3(out)\n        \n        out = self.dropout3(out)\n        \n        out = self.fc4(out)\n        \n        return out\n    \n# Define Model\n\nmodel_3 = ConvNet_3()\n\nprint(model_3)","31b008df":"if torch.cuda.is_available():\n    \n    MODEL = model_3.cuda()\n    CRITERION = criterion.cuda()\n    print(\"cuda\")\n    \nelse:\n    \n    MODEL = model_3\n    CRITERION = criterion\n    print(\"cpu\")\n\n# Train the model\n\ntotal_step = len(train_data_loader)\nloss_list = []\nacc_list = []\n\nnum_epochs = 5\n\nclass_list = ['N', 'Q', 'S', 'V', 'F']\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nall_con_mat = torch.zeros([num_epochs, 5, 5], dtype=torch.int32, device=device)\n\nfor epoch in range(num_epochs):\n    \n    f1_score_list=[0,0,0,0,0]\n\n    precision_list=[0,0,0,0,0]\n\n    recall_list=[0,0,0,0,0]\n    \n    delta = 0.0000000000001 \n    \n    # define empty tensor 5*5 beginning of every epoch\n    # tensor [row,column]\n    con_mat = torch.zeros([5, 5], dtype=torch.int32, device=device)\n    \n    for i, data in enumerate(train_data_loader):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # optimization\n        optimizer.zero_grad()\n        \n        # Forward to get output\n        outputs = MODEL(inputs)\n        # Calculate Loss\n        loss = CRITERION(outputs, labels)\n        # Backward propagation\n        loss.backward()\n        # Updating parameters\n        optimizer.step()\n        \n        # Store loss\n        loss_list.append(loss.item())\n    \n        # Calculate labels size\n        total = labels.size(0)\n        \n        # Outputs.data has dimension batch size * 5\n        # torch.max returns the max value of elements(_) and their indices(predicted) in the tensor array\n        _, predicted = torch.max(outputs.data, 1)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        # Store accuracy\n        acc_list.append(correct \/ total)\n        \n        for element in range(total):\n            \n            # con_mat[row,column]\n            # con_mat[predictions, actual]\n            con_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n        if (i + 1) % 300 == 0:                             # every 300 mini-batches...\n            \n            print('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  \n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct \/ total) * 100))\n    print(con_mat)\n            \n    all_con_mat[epoch] = con_mat\n    \n    # Print Confusion Matrix\n    \n    for i in range(torch.sum(con_mat, dim=0).size(0)): \n    \n        recall_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=0)[i].item()+delta)\n    \n        precision_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=1)[i].item()+delta)\n    \n        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n        \n    \n        print('class name: {}, total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(confusion_mat, dim=0)[i].item(),\n                          confusion_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))\n    \n            \nprint('Finished Training')\n\nplt.plot(loss_list);\nplt.show();\n\nplt.plot(acc_list);\nplt.show();","d5f03554":"# CNN Architect\n\nclass ConvNet_4(nn.Module):\n    \n    def __init__(self):\n        \n        super(ConvNet_4, self).__init__()\n\n        self.layer_1  = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1)\n        \n        self.relu1    = nn.ReLU(inplace=True)\n        \n        self.maxpool1 = MaxPool2d(kernel_size=2)\n        \n\n        self.layer_2  = nn.Conv2d(in_channels=4, out_channels=4, kernel_size=5, stride=1, padding=2)\n        \n        self.relu2    = nn.ReLU(inplace=True)\n        \n        self.maxpool2 = MaxPool2d(kernel_size=2)\n        \n        self.drop_out = nn.Dropout()\n        \n        \n        # out_channels = 4, number of classes = 5\n        \n        # image width = 120, image height = 120 after two maxpooling 120 -> 60 -> 30\n        \n        self.fc1 = nn.Linear(4 * 30 * 30, 5)\n        \n    # Defining the forward pass\n\n    def forward(self, x):\n        \n        out = self.layer_1(x)\n        \n        out = self.relu1(out)\n        \n        out = self.maxpool1(out)\n        \n        \n        out = self.layer_2(out)\n        \n        out = self.relu2(out)\n        \n        out = self.maxpool2(out)\n        \n        out = self.drop_out(out)\n        \n        \n        out = out.reshape(out.size(0), -1)\n        \n        out = self.fc1(out)\n        \n        return out\n\n# Define Model\n\nmodel_4 = ConvNet_4()\n\nprint(model_4)","ffe5cfc8":"if torch.cuda.is_available():\n    \n    MODEL = model_4.cuda()\n    CRITERION = criterion.cuda()\n    print(\"cuda\")\n    \nelse:\n    \n    MODEL = model_4\n    CRITERION = criterion\n    print(\"cpu\")\n\n# Train the model\n\ntotal_step = len(train_data_loader)\nloss_list = []\nacc_list = []\n\nnum_epochs = 5\n\nclass_list = ['N', 'Q', 'S', 'V', 'F']\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nall_con_mat = torch.zeros([num_epochs, 5, 5], dtype=torch.int32, device=device)\n\nfor epoch in range(num_epochs):\n    \n    f1_score_list=[0,0,0,0,0]\n\n    precision_list=[0,0,0,0,0]\n\n    recall_list=[0,0,0,0,0]\n    \n    delta = 0.0000000000001 \n    \n    # define empty tensor 5*5 beginning of every epoch\n    # tensor [row,column]\n    con_mat = torch.zeros([5, 5], dtype=torch.int32, device=device)\n    \n    for i, data in enumerate(train_data_loader):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # optimization\n        optimizer.zero_grad()\n        \n        # Forward to get output\n        outputs = MODEL(inputs)\n        # Calculate Loss\n        loss = CRITERION(outputs, labels)\n        # Backward propagation\n        loss.backward()\n        # Updating parameters\n        optimizer.step()\n        \n        # Store loss\n        loss_list.append(loss.item())\n    \n        # Calculate labels size\n        total = labels.size(0)\n        \n        # Outputs.data has dimension batch size * 5\n        # torch.max returns the max value of elements(_) and their indices(predicted) in the tensor array\n        _, predicted = torch.max(outputs.data, 1)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        # Store accuracy\n        acc_list.append(correct \/ total)\n        \n        for element in range(total):\n            \n            # con_mat[row,column]\n            # con_mat[predictions, actual]\n            con_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n        if (i + 1) % 300 == 0:                             # every 300 mini-batches...\n            \n            print('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n                  \n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct \/ total) * 100))\n    print(con_mat)\n            \n    all_con_mat[epoch] = con_mat\n    \n    # Print Confusion Matrix\n    \n    for i in range(torch.sum(con_mat, dim=0).size(0)): \n    \n        recall_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=0)[i].item()+delta)\n    \n        precision_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=1)[i].item()+delta)\n    \n        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n        \n    \n        print('class name: {}, total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(confusion_mat, dim=0)[i].item(),\n                          confusion_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))\n    \n            \nprint('Finished Training')\n\nplt.plot(loss_list);\nplt.show();\n\nplt.plot(acc_list);\nplt.show();","a9729afa":"confusion_mat = torch.zeros([5, 5], dtype=torch.int32, device=device)\n\nwith torch.no_grad():\n    \n    for data in test_data_loader:\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        outputs = MODEL(inputs)\n        \n        _, predicted = torch.max(outputs.data, 1)\n        \n        total = labels.size(0)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        for element in range(total):\n            \n            # confusion_mat[row,column]\n            # confusion_mat[predictions, actual]\n            confusion_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n    print(confusion_mat)","83f6ab38":"class_list = ['N', 'Q', 'S', 'V', 'F']\n\nf1_score_list=[0,0,0,0,0]\n\nprecision_list=[0,0,0,0,0]\n\nrecall_list=[0,0,0,0,0]\n    \ndelta = 0.0000000000001 \n\n\nfor i in range(torch.sum(confusion_mat, dim=0).size(0)): \n    \n        recall_list[i] = confusion_mat[i][i].item()\/(torch.sum(confusion_mat, dim=0)[i].item()+delta)\n    \n        precision_list[i] = confusion_mat[i][i].item()\/(torch.sum(confusion_mat, dim=1)[i].item()+delta)\n    \n        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n        \n    \n        print('class name: {}, total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.2f}%, Precision: {:.2f}%, F1-Score: {:.2f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(confusion_mat, dim=0)[i].item(),\n                          confusion_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))","4cd84590":"## I want to make %20 test set. For this reason I will copy first %20 percent of each class to test folders","fdc8d492":"## <span style=\"color:blue\">Copy Files<\/span>","e072e941":"## <span style=\"color:red\">Check Trained 1. Model on the Test Data<\/span>","32436a30":"## <span style=\"color:red\">Built and Train Third CNN Model<\/span>","89947a0a":"## <span style=\"color:red\">Built and Train Forth CNN Model<\/span>","1e37cd80":"## <span style=\"color:red\">Built and Train Second CNN Model<\/span>","b9a4afcf":"The batch size is 32, image size is reduced to 120*120 and we need only one channel(Gray Scale).","0edd5224":"## <span style=\"color:red\">Train Our First Model<\/span>","b4a6fa0f":"## <span style=\"color:blue\">Plot one Batch of Files from Dataloader<\/span>","23d59733":"# <span style=\"color:blue\">Building Convolutional Neural Networks<\/span> ","8881e2d2":"## <span style=\"color:red\">Check Trained Forth Model on the Test Data<\/span>","ca21633b":"## <span style=\"color:red\">Copy N files<\/span>","ff51bcfe":"## <span style=\"color:blue\">Set Data Loader<\/span>","3f52a875":"## <span style=\"color:blue\">Check Total File Numbers in each Train and Test Folders <\/span>","dd82ef5e":"## <span style=\"color:red\">First CNN Model<\/span>","e623ccf6":"## <span style=\"color:red\">Copy F files<\/span>","a838a180":"## <span style=\"color:blue\">Create Test and Train Folders<\/span>","fd91b87d":"## <span style=\"color:red\">Copy Q files<\/span>","21c520a5":"# <span style=\"color:blue\">Check Files in the MITBIH_img Folder<\/span>","9f76483d":"# <span style=\"color:blue\">EDA<\/span>","31748a52":"## <span style=\"color:red\">Train Our First Model epoch=5<\/span>","e3af328d":"## <span style=\"color:red\">Chech and run GPU<\/span>","ce11c216":"## To see 3 channels I plot figures with cv 2 package","b726047f":"# <span style=\"color:blue\">Show Images From Each Folder<\/span>","9a53f25f":"# <span style=\"color:blue\">Split Data in to Test and Train Folders<\/span>","4445feb2":"# <span style=\"color:blue\">Import Packages<\/span>","8d12782d":"## <span style=\"color:red\">Recall, Precision, and F1 Score for each Class<\/span>","62a38df2":"Lets load images with datasets.ImageFolder function and than read and plot","7de5ba82":"* F (Fusion beat) - 801 images\n* N (Normal beat) - 90,589 images\n* Q (Unknown beat) - 8,038 images\n* S (Supraventricular ectopic beat) - 2,779 images\n* V (Ventricular ectopic beat) - 7,236 images","5bf37227":"# <span style=\"color:blue\">Plot RGB<\/span>","8436d688":"# <span style=\"color:blue\">Count Number of Files in the MITBIH_img Folder<\/span>","50f6f0f2":"## <span style=\"color:red\">Copy S files<\/span>","0548dbd0":"## <span style=\"color:red\">Copy V files<\/span>"}}