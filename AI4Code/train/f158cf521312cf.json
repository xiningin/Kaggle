{"cell_type":{"afadbc2c":"code","9a88324f":"code","9caf7de1":"code","b08b01bc":"code","d001f2a5":"code","fed0793a":"code","0f13c05a":"code","db886393":"code","489d04e2":"code","cad7a7a6":"code","2d071354":"code","1fda5679":"code","828a18ed":"code","fb5d5445":"code","7742ddcf":"code","f27149b6":"code","37e68e44":"code","87aff99d":"code","9e7ca3e0":"code","fb4bb144":"code","81514667":"code","098d5ba8":"code","b2603563":"code","49523eda":"code","b68c5b0d":"code","02f4448c":"code","990a4730":"code","7ccd248f":"code","afa8783d":"code","9241e301":"code","3b650210":"code","c28ccafd":"code","bfc30e24":"code","562154df":"code","2a5237a0":"code","0b3b5f26":"code","e49679dc":"markdown","6c33ff2b":"markdown","16cadaf9":"markdown"},"source":{"afadbc2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a88324f":"data=pd.read_csv('\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')","9caf7de1":"data.head()","b08b01bc":"data.shape","d001f2a5":"data[\"Department\"].unique()","fed0793a":"count1=0\ncount2=0\ncount3=0\ncount4=0\ncount5=0\ncount6=0","0f13c05a":"for i in data.index:\n    if(data[\"Department\"][i]=='Sales' and data['Attrition'][i]=='Yes'):\n        count1=count1+1;\n    if(data[\"Department\"][i]=='Sales' and data['Attrition'][i]=='No'):\n        count2=count2+1;\n    if(data[\"Department\"][i]=='Research & Development' and data['Attrition'][i]=='Yes'):\n        count3=count3+1;\n    if(data[\"Department\"][i]=='Research & Development' and data['Attrition'][i]=='No'):\n        count4=count4+1;\n    if(data[\"Department\"][i]=='Human Resources' and data['Attrition'][i]=='Yes'):\n        count5=count5+1;\n    if(data[\"Department\"][i]=='Human Resources' and data['Attrition'][i]=='No'):\n        count6=count6+1;","db886393":"print(count1)\nprint(count2)\nprint(count3)\nprint(count4)\nprint(count5)\nprint(count6)","489d04e2":"import matplotlib.pyplot as plt\nx=0\nx_=('Sales','Research and development','Human Resources')\nax = plt.subplot(111)\nax.bar(x-0.2, count1, width=0.2, color='g', align='center',label='yes')\nax.bar(x, count2, width=0.2, color='r', align='center',label='no')\nax.bar(x+0.4, count3, width=0.2, color='g', align='center')\nax.bar(x+0.6, count4, width=0.2, color='r', align='center')\nax.bar(x+1.0, count5, width=0.2, color='g', align='center')\nax.bar(x+1.2, count6, width=0.2, color='r', align='center')\nplt.xticks([-0.1,0.5,1.1],('Sales','R&D','Human Resources'))\nplt.xlabel(\"Department\")\nplt.legend();\nplt.show()","cad7a7a6":"data[\"BusinessTravel\"].unique()","2d071354":"count1=0\ncount2=0\ncount3=0\ncount4=0\ncount5=0\ncount6=0","1fda5679":"for i in data.index:\n    if(data[\"BusinessTravel\"][i]=='Travel_Rarely' and data['Attrition'][i]=='Yes'):\n        count1=count1+1;\n    if(data[\"BusinessTravel\"][i]=='Travel_Rarely' and data['Attrition'][i]=='No'):\n        count2=count2+1;\n    if(data[\"BusinessTravel\"][i]=='Travel_Frequently' and data['Attrition'][i]=='Yes'):\n        count3=count3+1;\n    if(data[\"BusinessTravel\"][i]=='Travel_Frequently' and data['Attrition'][i]=='No'):\n        count4=count4+1;\n    if(data[\"BusinessTravel\"][i]=='Non-Travel' and data['Attrition'][i]=='Yes'):\n        count5=count5+1;\n    if(data[\"BusinessTravel\"][i]=='Non-Travel' and data['Attrition'][i]=='No'):\n        count6=count6+1;","828a18ed":"print(count1)\nprint(count2)\nprint(count3)\nprint(count4)\nprint(count5)\nprint(count6)","fb5d5445":"x=0\nx_=('Travel_Rarely','Travel_Frequently','Non-Travel')\nax = plt.subplot(111)\nax.bar(x-0.2, count1, width=0.2, color='y', align='center',label='yes')\nax.bar(x, count2, width=0.2, color='c', align='center',label='no')\nax.bar(x+0.4, count3, width=0.2, color='y', align='center')\nax.bar(x+0.6, count4, width=0.2, color='c', align='center')\nax.bar(x+1.0, count5, width=0.2, color='y', align='center')\nax.bar(x+1.2, count6, width=0.2, color='c', align='center')\nplt.xticks([-0.1,0.5,1.1],('Travel_Rarely','Travel_Frequently','Non-Travel'))\nplt.xlabel(\"BusinessTravel\")\nplt.legend();\nplt.show()","7742ddcf":"!pip install wordcloud","f27149b6":"import os\n\nfrom os import path\nfrom wordcloud import WordCloud\n\n# get data directory (using getcwd() is needed to support running example in generated IPython notebook)\nd = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n\n# Read the whole text.\ntext = open(path.join(r\"\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv\")).read()\n\n# Generate a word cloud image\nwordcloud = WordCloud().generate(text)\n\n# Display the generated image:\n# the matplotlib way:\nimport matplotlib.pyplot as plt\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","37e68e44":"# lower max_font_size\nwordcloud = WordCloud(max_font_size=40).generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\n# The pil way (if you don't have matplotlib)\n# image = wordcloud.to_image()\n# image.show()","87aff99d":"data.isnull().any()","9e7ca3e0":"data.corr()","fb4bb144":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndata['BusinessTravel']=le.fit_transform(data['BusinessTravel'])\ndata['Department']=le.fit_transform(data['Department'])\ndata['Gender']=le.fit_transform(data['Gender'])\ndata['MaritalStatus']=le.fit_transform(data['MaritalStatus'])\ndata['OverTime']=le.fit_transform(data['OverTime'])\ndata['Attrition']=le.fit_transform(data['Attrition'])\ndata['PerformanceRating']=le.fit_transform(data['PerformanceRating'])","81514667":"data.head()","098d5ba8":"x=data.iloc[:,[0,2,4,5,10,11,16,17,18,22,23,24,25,28,31,33]].values\n#0:age 1:Businesstravel 2:Department 3:Distance from home 4:EnvironmentSatisfaction 5:Gender 6:JobSatisfaction \n#7:MaritalStatus  8:MonthlyIncome 9:OverTime 10:PercentSalaryHike 11:PerformanceRating 12:RelationshipSatisfaction\n#13:TotalWorkingYears 14:YearsAtCompany 15:YearsSinceLastPromotion \ny=data.iloc[:,1:2].values","b2603563":"\nfrom sklearn.preprocessing import OneHotEncoder\none=OneHotEncoder()\nz=one.fit_transform(x[:,1:2]).toarray()#2 more columns\nt=one.fit_transform(x[:,2:3]).toarray()#2 more columns\nr=one.fit_transform(x[:,4:5]).toarray()#3 more columns\ns=one.fit_transform(x[:,6:7]).toarray()#3 more columns\nm=one.fit_transform(x[:,7:8]).toarray()#2 more columns\nq=one.fit_transform(x[:,12:13]).toarray()#3 more columns\nx=np.delete(x,[1,2,4,6,7,12],axis=1)\nx=np.concatenate((q,m,s,r,t,z,x),axis=1)","49523eda":"x.shape#(16+2+2+3+3+2+3)","b68c5b0d":"from sklearn.model_selection import train_test_split#then we divided the data into train set and test set so that we can send it for further processing\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=23)","02f4448c":"x_train.shape","990a4730":"x_test.shape","7ccd248f":"#we scaled the data so that we can avoid outliers and we classify the data accurately\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)","afa8783d":"from sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier(random_state=23,criterion='entropy')\ndtc.fit(x_train,y_train)","9241e301":"dtcpred=dtc.predict(x_test)","3b650210":"dtcpred","c28ccafd":"y_test","bfc30e24":"from sklearn.metrics import accuracy_score\ndtcacc=accuracy_score(y_test,dtcpred)","562154df":"dtcacc","2a5237a0":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,dtcpred)\ncm","0b3b5f26":"import sklearn.metrics as metrics\nfpr,tpr,threshold=metrics.roc_curve(y_test,dtcpred)\nroc_auc=metrics.auc(fpr,tpr)#false positive rate fpr and true positive rate tpr","e49679dc":"## **Label Encoding the data**","6c33ff2b":"## **OneHot Encoding**","16cadaf9":"## **Decision Tree Classifier**"}}