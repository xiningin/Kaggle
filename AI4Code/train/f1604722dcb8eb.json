{"cell_type":{"26ab6f98":"code","d1b9a60c":"code","6e56d8f2":"code","5b4492a5":"code","d6b17ddc":"code","b1fb674e":"code","6c942db3":"code","8a0d117b":"code","0000df82":"code","15ac6ebb":"code","691455d1":"code","1e793677":"code","eda1dc63":"code","00b3b71d":"code","666ce749":"code","af236911":"code","5225c127":"code","d56a7f03":"code","628f47eb":"code","b3e43c51":"code","daab0f23":"code","a0eaece7":"code","9846c488":"code","cbd0ad30":"code","d92ca672":"code","47e52ea8":"code","fab100ec":"code","7e7c64ad":"code","b39abc2b":"code","b8741d2b":"code","9f8ef695":"code","0cf38444":"code","abf0dc67":"code","9fe658b5":"code","9c1d2c25":"code","55c0ca5c":"code","33b27386":"code","8c0dc43f":"code","5f3fd919":"code","dbcba554":"code","528fd749":"code","1e864ae1":"code","ec9c7059":"markdown","75c6a1d5":"markdown","469fd862":"markdown","2463c997":"markdown","70f53a58":"markdown","439f8654":"markdown","5c24acf2":"markdown","ec08b65b":"markdown","9414795f":"markdown","fdc78c4a":"markdown","8fe7ffa6":"markdown","0b06d9df":"markdown","1a49b91f":"markdown","01415174":"markdown","7d30deb1":"markdown","85a39e9d":"markdown","6cf129a9":"markdown","b8b251c5":"markdown","d69e528e":"markdown","22afcff5":"markdown","467a398b":"markdown","d61d584a":"markdown","7b514215":"markdown","fc84ccc9":"markdown","79600525":"markdown","19d87001":"markdown","91ca0c5b":"markdown","047bb8e3":"markdown","d3b2c987":"markdown","147d44df":"markdown","388bfd3d":"markdown","27132970":"markdown","4d15afda":"markdown","e1f6499e":"markdown","605ea1b5":"markdown","ded3e01e":"markdown","78a915a7":"markdown","16f6aab6":"markdown","11e2426f":"markdown","e037ffa8":"markdown","502dcd01":"markdown"},"source":{"26ab6f98":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport statsmodels.api as sm\nimport warnings\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom fbprophet import Prophet\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nnp.random.seed(666)","d1b9a60c":"df = pd.read_csv(\"..\/input\/online-retail-final\/online_retail_final.csv\")\ndisplay(df.head())\n\nprint(df.shape)","6e56d8f2":"df.info()","5b4492a5":"df = df[df.Country == \"United Kingdom\"]","d6b17ddc":"df.loc[:, \"InvoiceDate\"] = pd.to_datetime(df.loc[:, \"InvoiceDate\"])\n\nprint(f\"First observation on data is {df.InvoiceDate.min()}\")\nprint(f\"Last observation on data is {df.InvoiceDate.max()}\")\n\nprint(f\"We have {(df.InvoiceDate.max() - df.InvoiceDate.min()).days} days.\")","b1fb674e":"df.set_index(\"InvoiceDate\", inplace = True)\ndf.head()","6c942db3":"prices_df = pd.DataFrame(df.groupby(\"InvoiceDate\").TotalPrice.sum())\nprices_df = prices_df.iloc[:-1]\nprices_df","8a0d117b":"weekly_prices = prices_df.resample(\"W\").sum()\nweekly_prices.head()","0000df82":"fig, ax = plt.subplots(figsize = (12, 5), facecolor = \"#e5e5e5\")\nax.set_facecolor(\"#101820\")\n\nweekly_prices.plot(ax = ax).set_title(\"Weekly Revenue for United Kingdom\")\nax.legend(facecolor = \"#101820\", labelcolor = \"#e5e5e5\")\n\nsns.despine()\nplt.show()","15ac6ebb":"daily_sales = pd.DataFrame(df.groupby(\"InvoiceDate\").sum().resample(\"D\").sum()[\"TotalPrice\"])\ndaily_sales","691455d1":"daily_sales.loc[\"2010-12-23\" : \"2011-1-4\"]","1e793677":"daily_sales.reset_index(inplace = True)\ndaily_sales[\"Closed\"] = np.where((daily_sales.TotalPrice == 0), 1, 0)\ndaily_sales.set_index(\"InvoiceDate\", inplace = True)","eda1dc63":"daily_sales[\"weekday\"] = daily_sales.index.day_name()\ndaily_sales","00b3b71d":"daily_sales[daily_sales.TotalPrice == 0].weekday.value_counts()","666ce749":"daily_sales.groupby(\"weekday\").TotalPrice.sum()","af236911":"daily_sales_workdays = daily_sales[daily_sales.TotalPrice > 0].copy()\ndaily_sales.drop(\"weekday\", axis = 1, inplace = True)\ndaily_sales_workdays.drop(\"weekday\", axis = 1, inplace = True)","5225c127":"fig, axes = plt.subplots(2, 1, sharex = True, figsize = (14, 10), facecolor = \"#e5e5e5\")\n\nfor ax in axes: ax.set_facecolor(\"#101820\")\n\ndaily_sales.TotalPrice.plot(ax = axes[0]).set_title(\"Daily Revenue\")\ndaily_sales_workdays.TotalPrice.plot(ax = axes[1]).set_title(\"Daily Revenue for Work Days\")\n\nsns.despine()\nplt.show()","d56a7f03":"fig, axes = plt.subplots(2, 1, sharex = True, figsize = (14, 10), facecolor = \"#e5e5e5\")\n\nfor ax in axes: ax.set_facecolor(\"#101820\")\n    \nsns.lineplot(x = daily_sales.index, y = daily_sales.TotalPrice, \n             ax = axes[0], label = \"Daily Sales\").set_title(\"For Daily Sales \\nIncludes Vacation Days\")\n\nsns.lineplot(x = daily_sales.index, y = daily_sales.TotalPrice.rolling(7).mean(), \n             ax = axes[0], label = \"Rolling Mean for 7 Days\")\nsns.lineplot(x = daily_sales.index, y = daily_sales.TotalPrice.rolling(35).mean(), \n             ax = axes[0], label = \"Rolling Mean for 35 Days\")\nsns.lineplot(x = daily_sales.index, y = daily_sales.TotalPrice.rolling(70).mean(), \n             ax = axes[0], label = \"Rolling Mean for 70 Days\")\nsns.lineplot(x = daily_sales.index, y = daily_sales.TotalPrice.rolling(140).mean(), \n             ax = axes[0], label = \"Rolling Mean for 140 Days\")\n\n\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice, \n             ax = axes[1], label = \"Daily Sales\").set_title(\"Daily Sales \\nJust Work Days\")\n\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice.rolling(6).mean(), \n             ax = axes[1], label = \"Rolling Mean for 7 Days\")\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice.rolling(30).mean(),\n             ax = axes[1], label = \"Rolling Mean for 30 Days\")\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice.rolling(60).mean(), \n             ax = axes[1], label = \"Rolling Mean for 60 Days\")\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice.rolling(120).mean(), \n             ax = axes[1], label = \"Rolling Mean for 120 Days\")\n\nfor ax in axes: ax.legend(facecolor = \"#101820\", labelcolor = \"#e5e5e5\")\n    \nsns.despine()\nplt.tight_layout()\nplt.show()","628f47eb":"def check_adf(series, check = 0.05):\n    \n    adf = adfuller(series, autolag = \"AIC\")\n    \n    print(f\"H0: {series.name} is non-stationary.\")\n    print(f\"H1: {series.name} is stationary.\\n\")\n    \n    test_stat = adf[0]; print(f\"ADF test statistic: {adf[0]}\")\n    pvalue = adf[1]; print(f\"p-value: {adf[1]}\")\n    print(f\"Number of lags: {adf[2]}\")    \n    print(\"\\nCritical Values : \\n\")\n    for key, item in adf[4].items(): print(\"\\t\", key, \"\\t\", item)\n    \n    print(f\"\\nFor {check} significance level: \\n\")\n    if pvalue < check:\n        print(\"We can reject null hypothesis. This series is stationary.\")\n    else:\n        print(\"We can not reject null hypothesis. This series is non-stationary.\")","b3e43c51":"print(\"Performing Augmented Dickey-Fuller test for Total Price \\n\")\n\ncheck_adf(daily_sales.TotalPrice)\n\nprint(\"\\nPerforming Augmented Dickey-Fuller test for Total Price (for workdays)\\n\")\n\ncheck_adf(daily_sales_workdays.TotalPrice)","daab0f23":"fig, axes = plt.subplots(2, 1, figsize = (14, 10), facecolor = \"#e5e5e5\")\n\nfor ax in axes: ax.set_facecolor(\"#101820\")\n\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice, \n             ax = axes[0], label = \"Daily Sales\").set_title(\"Daily Sales for Work Days\")\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice.rolling(60).mean(), \n             ax = axes[0], label = \"Rolling Mean - 60 Days\")\n\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice.diff(7), \n             ax = axes[1], label = \"Daily Sales - First Difference\").set_title(\"1st Difference of Work Days Daily Sales\")\nsns.lineplot(x = daily_sales_workdays.index, y = daily_sales_workdays.TotalPrice.diff(7).rolling(60).mean(), \n             ax = axes[1], label = \"Rolling Mean - 60 Days\")\n\nfor ax in axes: ax.legend(facecolor = \"#101820\", labelcolor = \"#e5e5e5\")\n\nsns.despine()\nplt.tight_layout()\nplt.show()","a0eaece7":"print(\"Performing Augmented Dickey-Fuller test for 1st Difference Revenue (All Days)\")\ncheck_adf(daily_sales[\"TotalPrice\"].diff(7).dropna())\n\nprint(\"\\nPerforming Augmented Dickey-Fuller test for 1st Difference of Work Days Sales\")\ncheck_adf(daily_sales_workdays[\"TotalPrice\"].diff(6).dropna())","9846c488":"decompose = seasonal_decompose(daily_sales[\"TotalPrice\"], period = 7)","cbd0ad30":"fig, axes = plt.subplots(4, 1, sharex = True, figsize = (15, 10), facecolor = \"#e5e5e5\")\n\nfor ax in axes: ax.set_facecolor(\"#101820\")\n\ndecompose.observed.plot(ax = axes[0]).set_title(\"Observed\")\ndecompose.trend.plot(ax = axes[1]).set_title(\"Trend\")\ndecompose.seasonal.plot(ax = axes[2]).set_title(\"Seasonal\")\ndecompose.resid.plot(ax = axes[3]).set_title(\"Residual\")\n\nsns.despine()\nplt.tight_layout()\nplt.show()","d92ca672":"fig, axes = plt.subplots(1, 2, figsize = (14, 4), facecolor = \"#e5e5e5\")\n\nfor ax in axes: ax.set_facecolor(\"#e5e5e5\")\n    \nsns.kdeplot(decompose.resid, ax = axes[0]).set_title(\"Density for Residual\")\n\nwith warnings.catch_warnings(): \n    warnings.simplefilter(\"ignore\")\n    \n    sm.qqplot(decompose.resid.dropna(), ax = axes[1], marker = \"x\", line = \"45\", fit = True)\n    axes[1].set_title(\"QQ Plot for Residual\")\n    \nplt.show()","47e52ea8":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nfig, axes = plt.subplots(2, 1, sharex = True, figsize = (15, 10), facecolor = \"#e5e5e5\")\n\nfor ax in axes: ax.set_facecolor(\"#e5e5e5\")\n    \nplot_acf(daily_sales[\"TotalPrice\"].diff(7).dropna(), lags = 60, ax = axes[0])\nplot_pacf(daily_sales[\"TotalPrice\"].diff(7).dropna(), lags = 60, ax = axes[1])\n\nsns.despine()\nplt.show()","fab100ec":"daily_data = daily_sales[[\"TotalPrice\"]].dropna().reset_index()\n\ndaily_data.columns = [\"ds\", \"y\"]\n\ntrain_size = int(0.85 * len(daily_data))\n\ntrain = daily_data.iloc[:train_size]\nval = pd.DataFrame(daily_data.iloc[train_size:])\n\nprint(f\"Training Days:\\t\\t{len(train)} \\nValidation Days:\\t {len(val)}\")","7e7c64ad":"def scores(y_true, y_pred):\n    print(f\"R2: {r2_score(y_true, y_pred)}\")\n    print(f\"MSE: {mean_squared_error(y_true, y_pred)}\")\n    print(f\"Correlation: {np.corrcoef(y_true, y_pred)[0][1]}\")","b39abc2b":"from fbprophet import Prophet\n\nmodel = Prophet()\n\nmodel.fit(train)\n\nval_pred = model.predict(val)\ntrain_pred = model.predict(train)","b8741d2b":"print(\"For Training set: \\n\")\nscores(train.y, train_pred.yhat)\n\nprint(\"\\nFor Validation set: \\n\")\nscores(val.y, val_pred.yhat)","9f8ef695":"fig, ax = plt.subplots(figsize = (14, 5), facecolor = \"#e5e5e5\")\nax.set_facecolor(\"#101820\")\n\nsns.lineplot(x = daily_data.ds, y = daily_data.y, ax = ax)\nsns.lineplot(x = val_pred.ds, y = val_pred.yhat, ax = ax)\n\nsns.despine()\nplt.show()","0cf38444":"black_friday = pd.DataFrame(\n    {\n        \"holiday\": \"black friday\",\n        \"ds\": pd.to_datetime([\"2011-11-24\", \"2012-11-23\", \"2013-11-22\"]),\n        \"lower_window\": 0,\n        \"upper_window\": 1\n    }\n)","abf0dc67":"def is_saturday(ds):\n    date = pd.to_datetime(ds)\n    return date.day_name() == \"Saturday\"\n\ndaily_data[\"is_saturday\"] = daily_data[\"ds\"].apply(is_saturday)\n\ntrain = daily_data.iloc[:train_size]\nval = pd.DataFrame(daily_data.iloc[train_size:])","9fe658b5":"model = Prophet(\n    holidays = black_friday,\n    daily_seasonality = True, \n    weekly_seasonality = True,\n    holidays_prior_scale = 1,\n    seasonality_prior_scale = 5,\n    changepoint_prior_scale = 1,\n)\n\nmodel.add_country_holidays(country_name = \"UK\")\n\nmodel.add_regressor(\"is_saturday\")\n\nmodel.fit(train)\n\nval_pred = model.predict(val)\ntrain_pred = model.predict(train)","9c1d2c25":"print(\"For Training set: \\n\")\nscores(train.y, train_pred.yhat)\n\nprint(\"\\nFor Validation set: \\n\")\nscores(val.y, val_pred.yhat)","55c0ca5c":"fig, ax = plt.subplots(figsize = (14, 5), facecolor = \"#e5e5e5\")\nax.set_facecolor(\"#101820\")\n\nsns.lineplot(x = daily_data.ds, y = daily_data.y, ax = ax, label = \"Original Data\")\nsns.lineplot(x = train_pred.ds, y = train_pred.yhat, alpha = 0.8, ax = ax, label = \"Train Predictions\")\nsns.lineplot(x = val_pred.ds, y = val_pred.yhat, ax = ax, alpha = 0.8, label = \"Validation Predictions\")\n\nax.legend(labelcolor = \"#e5e5e5\", facecolor = \"#101820\")\nsns.despine()\nplt.show()","33b27386":"train_pred[\"yhat\"] = np.where((train_pred.is_saturday == 0), train_pred.yhat, 0)\nval_pred[\"yhat\"] = np.where((val_pred.is_saturday == 0), val_pred.yhat, 0)\n\nprint(\"For Training set: \\n\")\nscores(train.y, train_pred.yhat)\n\nprint(\"\\nFor Validation set: \\n\")\nscores(val.y, val_pred.yhat)","8c0dc43f":"fig, ax = plt.subplots(figsize = (14, 5), facecolor = \"#e5e5e5\")\nax.set_facecolor(\"#101820\")\n\nsns.lineplot(x = daily_data.ds, y = daily_data.y, ax = ax, label = \"Original Data\")\nsns.lineplot(x = train_pred.ds, y = train_pred.yhat, alpha = 0.8, ax = ax, label = \"Train Predictions\")\nsns.lineplot(x = val_pred.ds, y = val_pred.yhat, ax = ax, alpha = 0.8, label = \"Validation Predictions\")\n\nax.legend(labelcolor = \"#e5e5e5\", facecolor = \"#101820\")\nsns.despine()\nplt.show()","5f3fd919":"model = Prophet(\n    holidays = black_friday,\n    daily_seasonality = True, \n    weekly_seasonality = True,\n    yearly_seasonality = True,\n    holidays_prior_scale = 1,\n    seasonality_prior_scale = 5,\n    changepoint_prior_scale = 1,\n)\n\nmodel.add_country_holidays(country_name = \"UK\")\n\nmodel.add_regressor(\"is_saturday\")\n\nmodel.fit(daily_data)","dbcba554":"future = model.make_future_dataframe(periods = 365)\n\nfuture[\"is_saturday\"] = future[\"ds\"].apply(is_saturday)\nfuture.tail()","528fd749":"forecast = model.predict(future)\nforecast[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]].tail()","1e864ae1":"forecast[\"yhat\"] = np.where((forecast.is_saturday == 0), forecast.yhat, 0)\nforecast[\"yhat_lower\"] = np.where((forecast.is_saturday == 0), forecast.yhat_lower, 0)\nforecast[\"yhat_upper\"] = np.where((forecast.is_saturday == 0), forecast.yhat_upper, 0)\n\nfig, ax = plt.subplots(figsize = (9, 3), facecolor = \"#e5e5e5\", dpi = 300)\n\nmodel.plot(forecast, ax = ax)\n\nax.set_title(\"Daily Revenue Forecast\")\nax.grid(False)\nax.set_facecolor(\"#e5e5e5\")\nax.set_ylim(0, 70000)\n\nsns.despine()\nplt.show()","ec9c7059":"We have a problem, we get negative valued forecasts. Actually, using \"floor\" and \"cap\" didn't work for me. http:\/\/facebook.github.io\/prophet\/docs\/saturating_forecasts.html#saturating-minimum\n\nTo get rid of this, I will manually set them zero.","75c6a1d5":"# Prophet's parameters","469fd862":"For ADF test, this series is not stationary. To make it stationary, we have two main option.\n\n1- Take difference until it become stationary.\n\n2- Apply transformations: Log, square root, etc.","2463c997":"I will use daily sales data for model training. We have 0 values on saturdays, it is fixed. We can get rid of these records with subsetting the data, just like stock prices. \n\nFor training set, I just get first 85% records of all days, and remaining part is validation set.\n\nFirst of all, I want to say again, my main goal is getting more detailed project about this dataset. As we talk theoretical part, I think this dataset is not fully convenient for forecasting. We have one year data and after then major peak, we don't have a lot observations to predicting the behaivor of data.\n\nThis part would be a simple introduction of Facebook's Prophet, and I probably prepare more detailed notebooks about these concepts.","70f53a58":"As we can see kde plot and QQ plot, residual has normal distribution.","439f8654":"We can add holidays to prophet model with below format.\n\nI just add \"Black Friday\" as a holiday for three years.","5c24acf2":"Now, I will perform time series analysis on daily data for online retail dataset.\n\nBefore I start, I just want to point out, my goal is not create a best model for this dataset. I aim to basic introduction to Prophet, and diversify the context of my work on Online Retail dataset. I hope you'll enjoy.","ec08b65b":"We can saw trend, seasonal component and residual. We know we have weekly seasonality. \n\nWe need normal distributed residual. Let's look at it.","9414795f":"# Simple Model","fdc78c4a":"Also you can use add_country_holidays(country) method for adding all holidays for a country.","8fe7ffa6":"We make the series stationary. Let's decompose and examine its components.","0b06d9df":"# Modelling","1a49b91f":"We have 373 days sales record. Daily data can be more suitable.","01415174":"First model is simple prophet model with default parameters. We don't have good results, we have 53% R2 for training and 48% R2 for validation set.","7d30deb1":"Here, we have revenue per week graph. Let's interpret it.\n\nEarlier January, this retailer was closed. Revenue is 0.\n\nWe see first peak in the middle of May.\n\nSecond peak is in the beginning of October.\n\nThen the revenue top out in the middle of November.","85a39e9d":"I just convert data to daily form with using resample method. Let's dive in.","6cf129a9":"# Weekly","b8b251c5":"I will use only UK sales for this analysis.","d69e528e":"Now, I will build a new model for forecasting next year. I just add yearly seasonality to last model that we used.","22afcff5":"# Data Preparation for Time Series","467a398b":"# Stationarity","d61d584a":"This is fifth part of https:\/\/www.kaggle.com\/mustafacicek\/detailed-marketing-cohort-pareto-rfm-forecast\/\n\nYou can reach this data from here. https:\/\/www.kaggle.com\/mustafacicek\/online-retail-final","7b514215":"We get 48% R2 for validation. Let's plot that results.","fc84ccc9":"We can take difference with using .diff() method.\n\nIn this problem, our series has seasonal behaivor. Our revenue is increasing from saturday to thursday, then it decrease. For taking difference of seasonal series, we need set period in diff method.","79600525":"Yeap, this retailer closed on saturdays.","19d87001":"Nice, we have a constant mean over time. Let's look at ADF test results of 1st differenced series.","91ca0c5b":"For this problem our metrics are R2, mean squared error and correlation. Actually, I don't like to use infinite intervaled metrics like MSE, but I just add it for variety.","047bb8e3":"# Seasonality, Decomposition","d3b2c987":"Our model can not capture sudden trends well. Actually, we have to investigate the reasons underlying this peaks. Is it yearly seasonal, or not? We can not detect it since we have only one year data.","147d44df":"As we can see above daily revenue graphs, we have an increasing trend for end of the year.","388bfd3d":"We saw that there is a zero revenue week in earlier January.","27132970":"# Augmented Dickey-Fuller Test","4d15afda":"68% R2 for validation set, good increasing.","e1f6499e":"It seems, the model does not capture huge peaks.\n\nLet's add some parameters.","605ea1b5":"Okey, we don't have any record at 69 days. 53 of 69 is saturday. This retailer could be closed on saturdays. Let's look at total revenues per weekday.","ded3e01e":"# Daily Data","78a915a7":"In saturdays, we don't have any sale record. I will simply add \"is_saturday\" column as an extra regressor.","16f6aab6":"Here is the results of this year's predictions and next year's forecast. Black dots represent actual revenue, and blue lines represent forecasts.\n\nIn the last months of the year, our predictions on the border of upper confidence interval, or sometimes outside of it. \n\nIf we look at next year's forecast, we can see minor peaks in the middle of the year, and also we have positive trend late of the year.","11e2426f":"Prophet gives lots of options in model building step.\n\nholidays: You can use this for adding special days to model.\n\nseasonality: If the data has seasonality, you can set daily_seasonality, weekly_seasonality, and yearly_seasonality parameters to True.\n\n\n_prior_scale: This parameter controls the flexibility of components' affects. \n\n\nIn this model, I just set them with simple numbers. You can turn them with [0.01-10] range.","e037ffa8":"Let's check stationarity. Stationarity simply means that, our series has constant mean, variance on different times.\n\nIn above rolling mean plots, we saw that our mean values increase over time.\n\nBut, let's check it with Augmented Dickey Fuller test.","502dcd01":"# Forecasting Future"}}