{"cell_type":{"d1eddc41":"code","1416ff2b":"code","1c0ef28c":"code","c0cf4d6c":"code","09d3ee0e":"code","c7bb32a5":"code","8f240a7e":"code","0e9c75e2":"code","ae57ed91":"code","f88d3b0e":"code","c9736028":"code","93d53bd8":"code","5a289415":"code","1e66af44":"code","84d5fb89":"code","aa3af1c8":"code","902d2440":"code","aa3423c4":"code","c2d1d84e":"code","64f7c24f":"code","b4aaf7b9":"code","9169e758":"code","4e6293d4":"markdown","c6580186":"markdown","c2b26c49":"markdown","fb9876ca":"markdown","4fce324b":"markdown","1c47a9d5":"markdown","4657142a":"markdown","d4931b2f":"markdown","15f2f3ee":"markdown","1ed92acf":"markdown","bf0f80d4":"markdown","3187b9e1":"markdown","5029ccfa":"markdown","f07d840f":"markdown","9154befc":"markdown"},"source":{"d1eddc41":"\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt,matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n#%matplotlib is a magic function in IPython\n#%matplotlib inline sets the backend of \n#matplotlib to the 'inline' backend: \n#With this backend, the output of plotting commands\n#is displayed inline within frontends like the Jupyter notebook, \n#directly below the code cell that produced it.\n%matplotlib inline\n\n#constants\nNUMBER_OF_TRAINING_IMGS=5000\nIMG_HEIGHT=28\nIMG_WIDTH=28\n#list all the contents of the ..\/input directory\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1416ff2b":"labeled_images=pd.read_csv('..\/input\/train.csv')\nprint('shape of the dataframe ',labeled_images.shape)\nlabeled_images.head(n=3)","1c0ef28c":"images=labeled_images.iloc[0:NUMBER_OF_TRAINING_IMGS,1:] # first NUMBER_OF_TRAINING_IMGS rows,column 2 onwards.\nlabels=labeled_images.iloc[0:NUMBER_OF_TRAINING_IMGS,:1] #first NUMBER_OF_TRAINING_IMGS rows, first column. \n                                                        #I could have used .iloc[0:NUMBER_OF_TRAINING_IMGS,0 ] \n                                                        #instead of        .iloc[0:NUMBER_OF_TRAINING_IMGS,:1] but the first case returns a Series and the second one a DataFrame.\n                                                        #prefer the latter.\ntrain_images,test_images,train_labels,test_labels=train_test_split(images,labels,test_size=0.2,random_state=13)","c0cf4d6c":"type(train_images)","09d3ee0e":"ii=13\nimg=train_images.iloc[ii].values\nprint('shape of numpy array',img.shape,'reshaping to 28x28')\nimg=img.reshape(IMG_HEIGHT,IMG_WIDTH)\nplt.imshow(img,cmap='gray')\nplt.title(train_labels.iloc[ii,0])\n","c7bb32a5":"plt.hist(train_images.iloc[ii].values)","8f240a7e":"train_images.describe()","0e9c75e2":"max=train_images.max()\nmin=train_images.min()\ntrain_images_std=(train_images-min)\/(max-min)\ntest_images_std=(test_images-min)\/(max-min)\ntrain_images_std.head(n=2)","ae57ed91":"train_images_std=train_images_std.replace([-np.inf,np.inf],np.nan)\ntest_images_std=test_images_std.replace([-np.inf,np.inf],np.nan)\ntrain_images_std=train_images_std.fillna(0)\ntest_images_std=test_images_std.fillna(0)\ntrain_images_std.head(n=2)","f88d3b0e":"plt.hist(train_images_std.iloc[13])","c9736028":"test_images_std.describe()","93d53bd8":"clf=SVC(kernel='rbf',C=1.0,random_state=1,gamma=0.1)   # radial basis function K(a,b) = exp(-gamma * ||a-b||^2 ) where gamma=1\/(2*stddev)^2\nclf.fit(train_images_std,train_labels.values.ravel())\nclf.score(test_images_std,\n          test_labels.values.ravel())\n","5a289415":"## Will not be using this classifier. This  is to test the need for scaling in SVM\n\nclf_without_std=SVC(kernel='rbf',C=1.0,random_state=1,gamma=0.1)   # radial basis function K(a,b) = exp(-gamma * ||a-b||^2 ) where gamma=1\/(2*stddev)^2\nclf_without_std.fit(train_images,train_labels.values.ravel())      # unscaled original  data.\nclf_without_std.score(test_images,\n          test_labels.values.ravel())","1e66af44":"#use the clf model. (trained on scaled data)\nraw_data=pd.read_csv('..\/input\/test.csv')\nprint('shape of dataframe ',raw_data.shape)\nraw_data.head(n=3)","84d5fb89":"raw_data_scaled=(raw_data-min)\/(max-min)\nraw_data_scaled=raw_data_scaled.replace([-np.inf,np.inf],np.nan)\nraw_data_scaled=raw_data_scaled.fillna(0)\nraw_data_scaled.describe()","aa3af1c8":"from random import randint\n\njj=13\n\nfor i in range(1,3):\n    jx=randint(0,raw_data_scaled.shape[0])\n    smp=raw_data_scaled.iloc[[jx]]\n    img=smp.values        #get a random image\n    img=img.reshape(IMG_HEIGHT,IMG_WIDTH)\n    for j in range(1,3):\n        for k in range(1,2):\n            print('plt',i,j,k)\n            plt.subplot(i,j,k)\n            plt.imshow(img)\n            y=clf.predict(smp)\n            plt.title('predicted : '+str(y[0]))\n            \n\n'''\nimg=raw_data_scaled.iloc[[jj]].values\nimg=img.reshape(IMG_HEIGHT,IMG_WIDTH)\nimg1=raw_data_scaled.iloc[jj+1].values\nimg1=img1.reshape(IMG_HEIGHT,IMG_WIDTH)\nplt.subplot(121)\nplt.imshow(img)\nplt.title('predicted: ')\nplt.subplot(122)\nplt.imshow(img1)\nplt.title('predicted: ')\n'''","902d2440":"jjthSample=raw_data_scaled.iloc[[jj]]     # iloc[j] returns a Series. We need a dataframe to pass to predict. which is returned by iloc[[jj]]  .i.e. a list of rows\ntype(jjthSample)\ny_pred_jj=clf.predict(jjthSample)\ny_pred_jj","aa3423c4":"y_pred=clf.predict(raw_data_scaled)","c2d1d84e":"y_pred.shape","64f7c24f":"submissions=pd.DataFrame({\"ImageId\":list(range(1,len(y_pred)+1)), \"Label\":y_pred})\nsubmissions.head()","b4aaf7b9":"submissions.to_csv(\"mnist_svm_submit.csv\",index=False,header=True)","9169e758":"!ls","4e6293d4":"**Using [Support Vector Machines](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html)**  \n\n","c6580186":"Load the training data in and create a dataframe from the csv. \nThe first column in the ground truth label. The remaining are pixel values\nThe images are 28X28 pixels and these pixels are unrolled. See the data section to see more details.\n\nThe data is of the format: \nLabel, pixel0, pixel1, pixel2,..., pixel783\n\nLoading the data is done as follows:\n1. Read the csv using pandas read_csv to read into a dataframe\n2. separate into images ( design matrix X) and labels (Y)\n3. Split into training and test sets\n","c2b26c49":"I am trying to  go about with the MNIST data classification task using Python.\n\nAlthough I could have forked existing kernels for this task, I really wanted to build a kernel ground up and this seemed the easiest data to work off. Also I am using [this great kernel as my source](https:\/\/www.kaggle.com\/archaeocharlie\/a-beginner-s-approach-to-classification). \nI started with creating a new kernel and then adding the data under 'Draft Environment' and selecting the Digit Recognizer data. \n\n\n","fb9876ca":"what does the distribution look like now? ","4fce324b":"Spot check to see if the clf predicts correctly on new data.  \nView an image from the raw data and see if the prediction matches expected value","1c47a9d5":"**81%** accuracy with scaled data.   \nNow compare this with the case below where the data is used as is. (no scaling)","4657142a":"The output type from  [train_test_split](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html) is the same as the input type.  ","d4931b2f":"[How to standardize a dataframe while keeping the header information](https:\/\/stackoverflow.com\/questions\/26414913\/normalize-columns-of-pandas-data-frame)  \nThe training set is assumed variable enough to be that all data (test and new) comes from a distribution similar to the training set distribution.  \nTherefore I am saving  the max  and the min values  from the training data distribution.  \nmax and min will then be used to perform the standardization of all the data.","15f2f3ee":"**Statistics**  \nhow are the pixel values distributed?   \n","1ed92acf":"\n**Submission**  \n\nload the data in test.csv  \nscale it using the min and max values derived from the training set.  \nremove Nans and infinities as before.  \n","bf0f80d4":"\n**Now to viewing an image**[](http:\/\/).  \nThe image is unrolled into a single row that represents an image. Convert the single data point (row) to a 28X28 matrix (to view the original image)\nAnd then use matplotlib to plot this matrix.","3187b9e1":"More darker pixel values (close to 0 ) as compared to lighter( closer to 256).  \nEach of the pixels is a feature, so the data point is a 784-Dimensional vector.  \nWe need to standardize the features .   \n\n","5029ccfa":"*pandas loc is used to subset rows by labels while iloc is used to subset rows by row numbers.  \nBy default(?) the dataframe rows are assigned labels set to the row numbers.   \nLabels need not always be equal to the row numbers in all cases.   \n(row_number->label   0->A,1->B,2->C  or 0->Z,1->Y,2->X and so on).   \nloc => labels  \niloc => row numbers*","f07d840f":"> division by 0  causes  [NaNs](https:\/\/stackoverflow.com\/questions\/13295735\/how-can-i-replace-all-the-nan-values-with-zeros-in-a-column-of-a-pandas-datafra).  and [infinities](https:\/\/stackoverflow.com\/questions\/17477979\/dropping-infinite-values-from-dataframes-in-pandas) that need to be replaced\n","9154befc":"**10%** accuracy  \nThis is because the radial basis function kernel aka the gaussian kernel is of the the form K(a,b) = exp(-gamma * ||a-b||^2 ) i.e the L2 norm is used between data points to determine similarity.   \nAnd when the L2 norm is been used, it's best to keep the scaling similar between features vectors ."}}