{"cell_type":{"b72b60b9":"code","8b3c36a0":"code","2bcfe033":"code","2504f872":"code","06ca94b8":"code","29431b43":"code","c01ffaaa":"code","8f60f14a":"code","b31bab09":"code","29701adf":"code","2fba4ffc":"code","86a96981":"code","e2dc7e82":"code","76c40ed3":"markdown","2bb82735":"markdown","764a858c":"markdown","e60d2105":"markdown","7bce358b":"markdown","721d344c":"markdown","730dbc90":"markdown","0d9651d7":"markdown"},"source":{"b72b60b9":"import pandas as pd\n\ndf = pd.read_csv('\/kaggle\/input\/autompg-dataset\/auto-mpg.csv', na_values='?')\nprint(df.info())\ndf.head()","8b3c36a0":"df[['model year', 'origin', 'car name']].nunique()","2bcfe033":"df.drop(['model year', 'car name'], axis=1, inplace=True)","2504f872":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(abs(df.corr()))\nplt.show()","06ca94b8":"df.drop(['weight', 'cylinders'], axis=1, inplace=True)\n\nsns.heatmap(abs(df.corr()))\nplt.show()","29431b43":"from sklearn.model_selection import train_test_split\n\n# Get training set and test set\ny = df['mpg']\nX = df.drop('mpg', axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","c01ffaaa":"from sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\n\nnumerical_col_names = X.select_dtypes(include=['int', 'float']).columns\n\n# Preprocessing numerical columns\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer())\n])\n\n# Preprocessing categorical columns\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\n# Bundle preprocessing for numerical and categorical columns\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, numerical_col_names),\n    ('cat', categorical_transformer, ['origin'])\n])","8f60f14a":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\n\nmodel = RandomForestRegressor(random_state=1)\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\ncv_score = cross_val_score(pipeline, X_train, y_train\n                           , scoring='neg_root_mean_squared_error')\nprint('RandomForestRegressor RMSE: {:.3f}'.format(abs(np.mean(cv_score))))","b31bab09":"from xgboost import XGBRegressor\n\nmodel = XGBRegressor(random_state=1)\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\ncv_score = cross_val_score(pipeline, X_train, y_train\n                           , scoring='neg_root_mean_squared_error')\nprint('XGBRegressor RMSE: {:.3f}'.format(abs(np.mean(cv_score))))","29701adf":"from sklearn.linear_model import Ridge\n\nmodel = Ridge(random_state=1)\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\ncv_score = cross_val_score(pipeline, X_train, y_train\n                           , scoring='neg_root_mean_squared_error')\nprint('Ridge RMSE: {:.3f}'.format(abs(np.mean(cv_score))))","2fba4ffc":"from sklearn.linear_model import Lasso\n\nmodel = Lasso(random_state=1)\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\ncv_score = cross_val_score(pipeline, X_train, y_train\n                           , scoring='neg_root_mean_squared_error')\nprint('Lasso RMSE: {:.3f}'.format(abs(np.mean(cv_score))))","86a96981":"from sklearn.model_selection import GridSearchCV\n\nmodel = RandomForestRegressor(random_state=1)\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\n# Tune hyperparameter\nparam_grid = {'model__n_estimators': [30, 40, 50, 100]\n              , 'model__min_samples_leaf' : [1, 2, 3]}\nsearcher = GridSearchCV(pipeline, param_grid, cv=5\n                        , scoring='neg_root_mean_squared_error')\nsearcher.fit(X_train, y_train)\n\nprint('Best parameter: {}'.format(searcher.best_params_))\nprint('Best RMSE: {:.3f}'.format(abs(searcher.best_score_)))\n    \n# Get best estimator\nbest_estimator = searcher.best_estimator_","e2dc7e82":"from sklearn.metrics import mean_squared_error\n\n# Predict on the hold-out set and compute metrics\ny_pred = best_estimator.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mse ** (1\/2)\n\nprint('RMSE: {:.3f}'.format(rmse))","76c40ed3":"Selected RandomForestRegressor as it has the lowest RMSE.\n\n# Hyperparameter Tuning","2bb82735":"# Predict Fuel Consumption In Miles Per Gallon\n\nI will create model to predict fuel consumption in miles per gallon based on car technical specification.","764a858c":"# Drop High Cardinality Columns","e60d2105":"# Preprocessing","7bce358b":"# Select Model","721d344c":"# Drop Feature Columns That Are Correlated With Other Feature Columns","730dbc90":"# Get Training Set And Hold-out Set","0d9651d7":"# Evaluate Model On Hold-Out Set"}}