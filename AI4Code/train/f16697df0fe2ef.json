{"cell_type":{"54d3bc2d":"code","de2e1c82":"code","c53d5153":"code","540b4d55":"code","e2efa71b":"code","5900fd23":"code","60a98c54":"code","f3554c36":"code","18846847":"code","db02ab68":"code","1528c82e":"code","7d57c824":"code","715ac804":"code","69a31ca3":"code","197184bd":"code","e5ccc5bc":"code","4d8b6880":"code","35fca95b":"code","59d772e1":"code","2f74267c":"code","bc69741d":"code","745ac329":"code","753632c9":"code","311b658a":"code","06a105b0":"code","a605ccc4":"code","95f9a0ac":"code","7f481efa":"markdown","03bb0649":"markdown","1dc127be":"markdown","ff80d434":"markdown","79d21de5":"markdown","62366d07":"markdown","7a8c1c4f":"markdown","e1203127":"markdown","bc4a8cc6":"markdown","6a8a94bb":"markdown","967fe677":"markdown","1fd70389":"markdown","248d08cf":"markdown","54220bb6":"markdown","bc3b3947":"markdown","b5be9a6f":"markdown","f0172b96":"markdown","b2bcfe36":"markdown"},"source":{"54d3bc2d":"!pip install -q --upgrade wandb","de2e1c82":"import string\nimport random\ndef id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n\nHASH_NAME = id_generator(size=12)\nprint(HASH_NAME)","c53d5153":"import os\n# Close TF debug logs\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport gc\nimport sys\nimport time\nimport json\nimport wandb\nprint(\"W&B version: \", wandb.__version__)\n\nimport signal\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom wandb.keras import WandbCallback\n\n# For deep learning\nimport tensorflow as tf\nprint(\"TF version: \", tf.__version__)\nimport tensorflow_hub as hub\nprint('Hub version:', hub.__version__)\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import regularizers\nimport tensorflow_addons as tfa\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\n\n# Sklearn for spliting the dataset\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Imports for augmentations. \nfrom albumentations import Compose, RandomResizedCrop, Cutout, Rotate, HorizontalFlip, VerticalFlip, RandomBrightnessContrast, ShiftScaleRotate, CenterCrop, Resize, Normalize","540b4d55":"def wandbKeyboardInterruptHandler(signal, frame):\n    print(\"KeyboardInterrupt (ID: {}) has been caught. Cleaning up...\".format(signal))\n    wandb.finish()\n    sys.exit()","e2efa71b":"# For efficientnet class of models\ndef get_hub_url_and_isize(model_name, ckpt_type, hub_type):\n  if ckpt_type == '1k':\n    ckpt_type = ''  # json doesn't support empty string\n  else:\n    ckpt_type = '-' + ckpt_type  # add '-' as prefix\n  \n  hub_url_map = {\n    'efficientnetv2-b0': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b0\/{hub_type}',\n    'efficientnetv2-b1': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b1\/{hub_type}',\n    'efficientnetv2-b2': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b2\/{hub_type}',\n    'efficientnetv2-b3': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b3\/{hub_type}',\n    'efficientnetv2-s':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-s\/{hub_type}',\n    'efficientnetv2-m':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-m\/{hub_type}',\n    'efficientnetv2-l':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-l\/{hub_type}',\n\n    'efficientnetv2-b0-21k': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b0-21k\/{hub_type}',\n    'efficientnetv2-b1-21k': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b1-21k\/{hub_type}',\n    'efficientnetv2-b2-21k': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b2-21k\/{hub_type}',\n    'efficientnetv2-b3-21k': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b3-21k\/{hub_type}',\n    'efficientnetv2-s-21k':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-s-21k\/{hub_type}',\n    'efficientnetv2-m-21k':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-m-21k\/{hub_type}',\n    'efficientnetv2-l-21k':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-l-21k\/{hub_type}',\n    'efficientnetv2-xl-21k':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-xl-21k\/{hub_type}',\n\n    'efficientnetv2-b0-21k-ft1k': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b0-21k-ft1k\/{hub_type}',\n    'efficientnetv2-b1-21k-ft1k': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b1-21k-ft1k\/{hub_type}',\n    'efficientnetv2-b2-21k-ft1k': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b2-21k-ft1k\/{hub_type}',\n    'efficientnetv2-b3-21k-ft1k': f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-b3-21k-ft1k\/{hub_type}',\n    'efficientnetv2-s-21k-ft1k':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-s-21k-ft1k\/{hub_type}',\n    'efficientnetv2-m-21k-ft1k':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-m-21k-ft1k\/{hub_type}',\n    'efficientnetv2-l-21k-ft1k':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-l-21k-ft1k\/{hub_type}',\n    'efficientnetv2-xl-21k-ft1k':  f'gs:\/\/cloud-tpu-checkpoints\/efficientnet\/v2\/hub\/efficientnetv2-xl-21k-ft1k\/{hub_type}',\n      \n    # efficientnetv1\n    'efficientnet_b0': f'https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b0\/{hub_type}\/1',\n    'efficientnet_b1': f'https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b1\/{hub_type}\/1',\n    'efficientnet_b2': f'https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b2\/{hub_type}\/1',\n    'efficientnet_b3': f'https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b3\/{hub_type}\/1',\n    'efficientnet_b4': f'https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b4\/{hub_type}\/1',\n    'efficientnet_b5': f'https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b5\/{hub_type}\/1',\n    'efficientnet_b6': f'https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b6\/{hub_type}\/1',\n    'efficientnet_b7': f'https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b7\/{hub_type}\/1',\n  }\n  \n  image_size_map = {\n    'efficientnetv2-b0': 224,\n    'efficientnetv2-b1': 240,\n    'efficientnetv2-b2': 260,\n    'efficientnetv2-b3': 300,\n    'efficientnetv2-s':  384,\n    'efficientnetv2-m':  480,\n    'efficientnetv2-l':  480,\n    'efficientnetv2-xl':  512,\n  \n    'efficientnet_b0': 224,\n    'efficientnet_b1': 240,\n    'efficientnet_b2': 260,\n    'efficientnet_b3': 300,\n    'efficientnet_b4': 380,\n    'efficientnet_b5': 456,\n    'efficientnet_b6': 528,\n    'efficientnet_b7': 600,\n  }\n  \n  hub_url = hub_url_map.get(model_name + ckpt_type)\n  image_size = image_size_map.get(model_name, 224)\n  return hub_url, image_size","5900fd23":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","60a98c54":"try:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=secret_value_0)\n    anony=None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https:\/\/wandb.ai\/authorize')","f3554c36":"TRAIN_PATH = '..\/input\/petfinder-pawpularity-score\/train\/'\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nCONFIG = dict (\n    seed = 42,\n    loss = 'mse', # binary_crossentropy\n    num_labels = 1,\n    num_folds = 5,\n    train_val_split = 0.2,\n    img_width = 224,\n    img_height = 224,\n    batch_size = 16,\n    epochs = 1, # FOR FULL TRAINING INCREASE EPOCHS TO ATLEAST 20.\n    learning_rate = 1e-5,\n    hash_name = HASH_NAME\n)\n\n# Model configs\nCONFIG['model_type'] = 'efficientnetv2-b0'\nCONFIG['ckpt_type'] = '1k'   # '21k', '21k-ft1k', '1k'\nCONFIG['hub_type'] = 'feature-vector' # \nhub_url, image_size = get_hub_url_and_isize(CONFIG['model_type'], CONFIG['ckpt_type'], CONFIG['hub_type'])\nprint(hub_url)\n\nCONFIG['group'] = f'{HASH_NAME}-Regression'\nCONFIG['model_name'] = f'{HASH_NAME}-model'\nCONFIG['img_width'] = image_size\nCONFIG['img_height'] = image_size\nCONFIG['do_fine_tuning'] = True\n\n# Set the random seeds\ndef seed_everything(SEED):\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n    np.random.seed(SEED)\n    tf.random.set_seed(SEED)\n    \nseed_everything(CONFIG['seed'])","18846847":"df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\nprint(f'Number of train images: {len(df)}')\n\n# Add path\ndf['img_path'] = df['Id'].apply(lambda x: f'{TRAIN_PATH}{x}.jpg')\n\n# Min-max scaling (For regression)\ncolumn = 'Pawpularity'\ndf[column] = (df[column] - df[column].min()) \/ (df[column].max() - df[column].min())   \n\ndf.head()","db02ab68":"FEATURES = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']","1528c82e":"def create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n\n    data.loc[:, \"bins\"] = pd.cut(data[\"Pawpularity\"], bins=num_bins, labels=False)\n\n    kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n    \n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'kfold'] = f\n    \n    data = data.drop(\"bins\", axis=1)\n\n    return data\n\ndf = create_folds(df, num_splits=CONFIG['num_folds'])\ndf.to_csv('five_fold_classification.csv', index=False)","7d57c824":"# Apply training augmentation\ntrain_transforms = Compose([\n            Resize(CONFIG['img_height'], CONFIG['img_width'], p=1),\n            Rotate(limit=20),\n            Cutout(num_holes=8, max_h_size=30, max_w_size=30, p=1.0),\n            HorizontalFlip(p=0.7),\n            VerticalFlip(p=0.4),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p=1.0,\n            ),\n        ])\n\n# Apply validation augmentation\nvalid_transforms = Compose([\n            Resize(CONFIG['img_height'], CONFIG['img_width'], p=1),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p=1.0,\n            ),\n        ])\n\ndef aug_train_fn(image):\n    data = {\"image\":image}\n    aug_data = train_transforms(**data)\n    aug_img = aug_data[\"image\"]\n\n    return aug_img.astype(np.float32) \n\ndef aug_valid_fn(image):\n    data = {\"image\":image}\n    aug_data = valid_transforms(**data)\n    aug_img = aug_data[\"image\"]\n\n    return aug_img.astype(np.float32) \n\ndef train_augmentations(inputs, label):\n    image = inputs['image']\n    aug_img = tf.numpy_function(func=aug_train_fn, inp=[image], Tout=tf.float32)\n    aug_img.set_shape((CONFIG['img_height'], CONFIG['img_width'], 3))\n\n    return {'image': aug_img, 'features': inputs['features']}, label\n\ndef valid_augmentations(inputs, label):\n    image = inputs['image']\n    aug_img = tf.numpy_function(func=aug_valid_fn, inp=[image], Tout=tf.float32)\n    aug_img.set_shape((CONFIG['img_height'], CONFIG['img_width'], 3))\n\n    return {'image': aug_img, 'features': inputs['features']}, label","715ac804":"@tf.function\ndef load_resize(df_dict):\n    # Load image\n    img = tf.io.read_file(df_dict['img_path'])\n    img = tf.image.decode_jpeg(img, channels=3)\n    \n    # Parse features\n    features = {key: df_dict[key] for key in FEATURES}\n    features = features.values()\n    \n    # Parse label\n    label = df_dict['Pawpularity']\n    label = tf.cast(label, tf.float32)\n    \n    return {'image': img, 'features': features}, label","69a31ca3":"AUTOTUNE = tf.data.AUTOTUNE\n\ndef get_dataloaders(train_df, valid_df):\n    # Train Loader\n    trainloader = tf.data.Dataset.from_tensor_slices(dict(train_df))\n    # Valid Loader\n    validloader = tf.data.Dataset.from_tensor_slices(dict(valid_df))\n\n    trainloader = (\n        trainloader\n        .shuffle(1024)\n        .map(load_resize, num_parallel_calls=AUTOTUNE)\n        .map(train_augmentations, num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n\n    validloader = (\n        validloader\n        .map(load_resize, num_parallel_calls=AUTOTUNE)\n        .map(valid_augmentations, num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n    \n    return trainloader, validloader","197184bd":"def show_batch(image_batch):\n  plt.figure(figsize=(20,20))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.axis('off')\n\n#sanity check\n# Prepare dataloaders\ntrain_df = df.loc[df.kfold != 0].reset_index(drop=True)\nvalid_df = df.loc[df.kfold == 0].reset_index(drop=True)\n\ntrainloader, validloader = get_dataloaders(train_df, valid_df)\ninputs, labels = next(iter(validloader))\n\n# show_batch(imgs)","e5ccc5bc":"def get_model():\n    # Setup backbone model\n    base_model = hub.KerasLayer(hub_url, trainable=CONFIG['do_fine_tuning'])\n\n    # Inputs\n    image_inputs = layers.Input((CONFIG['img_height'], CONFIG['img_width'], 3), name='image')\n    feature_inputs = layers.Input((len(FEATURES)), name='features')\n    \n    # Get image features\n    img_features = base_model(image_inputs)\n    img_features = layers.Dense(64, activation='selu', \n                               kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n                               bias_regularizer=regularizers.l2(1e-4), \n                               activity_regularizer=regularizers.l2(1e-5))(img_features)\n    \n    # Get metadata features\n    features = layers.Dense(64, activation='selu',\n                            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n                            bias_regularizer=regularizers.l2(1e-4),\n                            activity_regularizer=regularizers.l2(1e-5))(feature_inputs)\n    \n    # Concat features\n    concat_features = layers.concatenate([img_features, features])\n    \n    x = layers.Dropout(0.5)(concat_features)\n    x = layers.Dense(64, activation='selu', \n                     kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n                     bias_regularizer=regularizers.l2(1e-4),\n                     activity_regularizer=regularizers.l2(1e-5))(x)\n    \n    outputs = layers.Dense(1, activation='sigmoid', \n                           kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n                           bias_regularizer=regularizers.l2(1e-4),\n                           activity_regularizer=regularizers.l2(1e-5))(x)\n    \n    return models.Model([image_inputs, feature_inputs], outputs)\n\ntf.keras.backend.clear_session()\nmodel = get_model()\nmodel.summary()","4d8b6880":"# Callbacks\nearlystopper = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=2, verbose=0, mode='min',\n    restore_best_weights=True\n)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=1, min_lr=CONFIG['learning_rate'])","35fca95b":"def get_predictions(model, validloader, valid_df):\n    y_pred = []\n    for image_batch, label_batch in validloader:\n        preds = model.predict(image_batch)\n        y_pred.extend(preds)\n        \n    valid_df['preds'] = y_pred\n    \n    return valid_df ","59d772e1":"oof_df = pd.DataFrame()","2f74267c":"# In case we interrupt the kernel\nsignal.signal(signal.SIGINT, wandbKeyboardInterruptHandler)\n\nfor fold in range(CONFIG['num_folds']):\n    print('FOLD: ', fold)\n    # Prepare train and valid df\n    train_df = df.loc[df.kfold != fold].reset_index(drop=True)\n    valid_df = df.loc[df.kfold == fold].reset_index(drop=True)\n\n    # Prepare dataloaders\n    trainloader, validloader = get_dataloaders(train_df, valid_df)\n\n    # Initialize model\n    tf.keras.backend.clear_session()\n    model = get_model()\n\n    # Compile model\n    optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['learning_rate'])\n    model.compile(optimizer, \n                  loss='binary_crossentropy', \n                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\n    # Update CONFIG dict with the name of the model.\n    print('Training configuration: ', CONFIG)\n\n    # Initialize W&B run\n    run = wandb.init(project='petfinder-train', \n                     config=CONFIG,\n                     group=CONFIG['group'], \n                     job_type='train',\n                     tags=['effnetv2', f'{HASH_NAME}'],\n                     name=f'{HASH_NAME}-fold-{fold}')\n\n    # Train\n    _ = model.fit(trainloader, \n                  epochs=CONFIG['epochs'],\n                  validation_data=validloader,\n                  callbacks=[WandbCallback(),\n                             earlystopper,\n                             reduce_lr])\n\n\n    # Evaluate\n    loss, rsme = model.evaluate(validloader)\n    wandb.log({'Val RSME': rsme})\n\n    # Save model\n    model_name = CONFIG['model_name']\n    MODEL_PATH = f'models\/{model_name}'\n    os.makedirs(MODEL_PATH, exist_ok=True)\n    count_models = len(os.listdir(MODEL_PATH))\n\n    model.save(f'{MODEL_PATH}\/{model_name}_{count_models}')\n\n    # Get Prediction on validation set\n    _oof_df = get_predictions(model, validloader, valid_df)\n    oof_df = pd.concat([oof_df, _oof_df])\n\n    # Close W&B run\n    run.finish()\n\n    del model, trainloader, validloader, _oof_df\n    _ = gc.collect()\n\n# Save oof as csv file\noof_df.to_csv('oof_preds.csv', index=False)","bc69741d":"# Initialize W&B run\nrun = wandb.init(project='petfinder-train', \n                 config=CONFIG,\n                 group=CONFIG['group'], \n                 job_type='eval',\n                 name=f'{HASH_NAME}-eval')\n\n# Compute CV score\noof_df_copy = oof_df.copy()\ndef correct_preds(row):\n    return row.preds[0]\n\noof_df_copy['preds'] = oof_df_copy.apply(lambda row: correct_preds(row), axis=1)\n\nmetric = tf.keras.metrics.RootMeanSquaredError()\nmetric.update_state(oof_df_copy.Pawpularity.values, oof_df_copy.preds.values)\nprint(f'CV Score: {metric.result().numpy()}')\n\nwandb.log({\"CV Score\": metric.result().numpy()})\n\n# Log oof.csv as artifacts\nmodel_artifacts = wandb.Artifact(f'{HASH_NAME}', type='model', metadata={'hash_name': HASH_NAME})\n# Add oof_preds.csv\nmodel_artifacts.add_file('oof_preds.csv')\n# Add trained models\nmodel_artifacts.add_dir('models\/')\nwandb.log_artifact(model_artifacts)\n\nwandb.finish()","745ac329":"# Copy Kaggle API token to ~\/.kaggle\n! mkdir -p \/root\/.kaggle\/\n! cp ..\/input\/apitoken\/kaggle.json \/root\/.kaggle\/kaggle.json\n\n# Initialize dataset creation\n! kaggle datasets init -p models\/\n\n!ls models\/\n\n%cat models\/dataset-metadata.json","753632c9":"import json\n  \n# Opening JSON file\nwith open('models\/dataset-metadata.json', 'r') as openfile:\n    # Reading from json file\n    json_object = json.load(openfile)\n\n    json_object['title'] = f'Petfinder {HASH_NAME}'\n    json_object['id'] = f'petfinder-{HASH_NAME}'\n\nwith open(\"models\/dataset-metadata.json\", \"w\") as outfile:\n    json.dump(json_object, outfile, indent=2)","311b658a":"!kaggle datasets create -p models\/ --dir-mode zip\n# ! kaggle datasets version -p \/kaggle\/tmp\/hpa_512x512_dataset -m \"add rgb images\"  --dir-mode tar","06a105b0":"DESP = \"efficientnetv2-b0_trained_with_metadata\"\n!kaggle datasets version -p models -m {DESP} --dir-mode zip","a605ccc4":"import seaborn as sns\nsns.set(style='dark')\n\nplt.figure(figsize=(10*2,6*2))\n\n# Prediction Plot\nplt.subplot(2, 2, 1)\nsns.kdeplot(x=oof_df_copy.Pawpularity.values, color='b',shade=True);\nsns.kdeplot(x=oof_df_copy.preds.values, color='r',shade=True);\nplt.grid('ON')\nplt.xlabel(oof_df_copy.Pawpularity.values);plt.ylabel('freq');plt.title('KDE')\nplt.legend(['train', 'oof'])\n\nplt.tight_layout()\nplt.show()","95f9a0ac":"import wandb\napi = wandb.Api()\n\nrun = api.run(\"ayut\/petfinder-train\/3sopqxw1\")\nrun.summary[\"LB Score\"] = 0.22954 # This is just representative number.\nrun.summary.update()","7f481efa":"# \ud83d\udc15 Analysis of Model Performance","03bb0649":"# \ud83d\udc08 Dataloader","1dc127be":"#### Utils for EfficientNetV2","ff80d434":"#### Login to Weights and Biases\n\nIf you are using Kaggle kernel to train your model and commit the kernel, it's best to use Kaggle User Secrets. Put in your W&B Access token with the label `wandb_api`. \n\nIf you Quick Save your kernel you can simply use `wandb.login()`.\n\nIf you are using a local system (where the runtime is not volatile) you just need to call `wandb.login()` once. ","79d21de5":"### \u2753 Why is this useful?\n\n\ud83d\ude4b In Kaggle we usually train model using K-fold strategy. If you are using W&B for experiment tracking you can see aggregated training metrics for each fold if you pass in `group=some-name` argument to `wandb.init()`. In the context of Kaggle, where we keep trying new experiments, tweak hyperparameters, change model definition, etc. regularly, deciding on this `some-name` can be tricky and prone to human error (usual error is to forget renaming for a new experiment). \n\nBy using a randomly generated hash-value you can group one experiment under one group-name and name the model as well as any generated file with that name. This is an unique identifier about your experiment. \n\n\u26a0\ufe0f Run this cell at the start of the notebook.","62366d07":"# \ud83d\udc36 Callbacks","7a8c1c4f":"# \ud83d\udc15 Model","e1203127":"## Update LB Score\n\nUse the trained model to run inference using a different kernel. Once you get the LB score, use the cell code below to log the LB score to the <HASH_NAME>-eval W&B run name. \n\n![img](https:\/\/i.imgur.com\/c7CAlBH.gif)","bc4a8cc6":"# \ud83d\udc31 Build Input Pipeline","6a8a94bb":"Each experiments are grouped together using the hash-value. \n\n![img](https:\/\/i.imgur.com\/a7atecz.png)","967fe677":"This way you can track which experiment trained which model and the corresponding `oof_preds.csv` file. \n\n![img](https:\/\/i.imgur.com\/gOz1LNj.png)","1fd70389":"#  \ud83d\udc15\u200d\ud83e\uddbaHyperparameters\n\nSave your hyperparameters as a dictionary so that you can log the same to W&B. ","248d08cf":"# \ud83d\udc31 Save the model as Kaggle dataset\n\n","54220bb6":"# \ud83d\udc08 Compute CV Score and Save Model and OOF File as W&B Artifacts","bc3b3947":"# \ud83d\udc36 Introduction\n\nIn this competition, the task is to predict the \"Pawpularity Score\" given an input image. The score range from 0-100 and thus can be formulated as classification problem or regression problem. \n\n# \ud83d\udc15 About this kernel\n\nThis kernel fine-tunes an EfficientNetv2 model using TensorFlow and uses Weights and Biases (W&B) for efficient experiment tracking. Meta-data is also used for training. \n\nIn the past, I have created multiple training kernels that use Weights and Biases but this kernel introduces some useful W&B best-practices (framework agnostic) that you can easily incorporate in your own pipeline with slight to no modification. \n\nIn particular, this kernel introduces:\n\n1. Use of hash value (random string) for efficient grouping of experiments in the W&B UI. \u2714\ufe0f \n2. Fine-tuning of EfficientNetv2 hosted on TensorFlow Hub. \n3. Use of Albumentations with TensorFlow for data augmentation. \n4. Track metrics using W&B Experiment Tracking. \u2714\ufe0f \n4. Keep track of the model and `oof.csv` file using W&B Artifacts.\u2714\ufe0f \n5. Save the trained model as Kaggle dataset to be used for inference.\n6. Visualize model perforance using W&B Tables. \u2714\ufe0f \n7. Manually log LB Score to Weights and Biases. \u2714\ufe0f \n\nThe bullet points marked with \u2714\ufe0f are specific to Weights and Biases and can be incorporated in your own workflow. ","b5be9a6f":"# \ud83d\udc15\u200d\ud83e\uddba Train\n\n\u26a0\ufe0f For demonstration purposes I am training the model for 1 epochs. ","f0172b96":"### \u2753 Why is this useful?\n\n\ud83d\ude4b In case a cell with initialized W&B run is KeyboardInterrupted, this function will close the W&B run. If you use a Python script to train your model, W&B will close automatically if you interrupt the training process. ","b2bcfe36":"# \ud83e\uddae Imports and Setups\n\n* Install the latest version of W&B. \n* Generate random string as hash value.\n* Import important libraries.\n* Loging to W&B using your W&B API access token."}}