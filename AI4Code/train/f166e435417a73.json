{"cell_type":{"335c5220":"code","f8440919":"code","d9e82161":"code","0d64ca7d":"code","4e44195a":"code","2b36b4b8":"code","dcce2cc9":"code","aaaef584":"code","420b6645":"code","34e3fd56":"code","3398f4e8":"code","0805554c":"code","2dd53546":"code","c87bd9f7":"code","2a2319d8":"code","6389bf92":"code","d74616b8":"code","4391cd7b":"code","02cfbd33":"code","e7f2509e":"code","d380c01d":"code","a2ddd5df":"code","b26e497f":"code","0d90de5e":"code","70455135":"code","e72ffba6":"code","a0344379":"code","296f6576":"code","70fc68ee":"code","369423a5":"code","f4250c0a":"code","2db36a90":"code","d69260c3":"code","1aa27f2b":"code","bf92ff57":"code","cdbad7c6":"code","38e1a842":"code","d9351a29":"code","6233a85c":"code","c03fa7e3":"code","5bd2af8e":"code","c0f6839e":"code","6600d3f3":"code","c71ddad5":"code","c6f0e2b6":"code","8ad5f548":"code","feade05e":"code","910c4f9f":"code","9bdd7121":"code","164e5de8":"code","3cb3a1a5":"code","a16030d5":"code","19019698":"code","336a92ca":"code","116c491a":"code","dfc14a5b":"code","a7086f6b":"code","c3a66132":"code","f5ff0e4a":"code","1ac1fb60":"code","615b769b":"code","0cc6acfa":"code","96dbd03c":"code","1ff51db4":"code","fa4229ac":"code","8fa43527":"code","54da004b":"markdown","79a89cc8":"markdown","985f5186":"markdown","10f6094b":"markdown","f55d630d":"markdown","24d602d8":"markdown","044128f6":"markdown","45a03167":"markdown","452d7f08":"markdown","28840ec9":"markdown","c2dc9261":"markdown","9233822e":"markdown","fdd1d4dc":"markdown","6097bb48":"markdown","d2d5b110":"markdown","d08798bd":"markdown","5d0d3206":"markdown","976101a8":"markdown","fd3b4874":"markdown","538632ad":"markdown","3bd2b20c":"markdown","4d183e9c":"markdown","a521a9c1":"markdown","5501e9b7":"markdown","7a9fd5cb":"markdown","46c9f2eb":"markdown","194ed077":"markdown","f1428d9d":"markdown"},"source":{"335c5220":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8440919":"from scipy.stats import norm\nfrom datetime import datetime\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.feature_selection import SelectKBest, f_regression\n\nimport xgboost as xgb\nimport calendar\nimport seaborn as sns\nimport matplotlib.pyplot as plt","d9e82161":"train_data = pd.read_excel('..\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')\ntest_data = pd.read_excel('..\/input\/flight-fare-prediction-mh\/Test_set.xlsx')","0d64ca7d":"train_data.info()","4e44195a":"train_data.head()","2b36b4b8":"sns.distplot(train_data.Price, fit=norm)","dcce2cc9":"log_price = np.log(train_data.Price)\nsns.distplot(log_price, fit=norm, kde=False)","aaaef584":"rt_price = np.sqrt(train_data.Price)\nsns.distplot(rt_price, fit=norm, kde=False)","420b6645":"train_data.Price = log_price","34e3fd56":"print(\"Number of unique airlines: \", train_data['Airline'].nunique())","3398f4e8":"train_data['Airline'].value_counts()","0805554c":"def plot_price(feature, df=train_data, target='Price', width=10, height=10):\n    fig = plt.figure(figsize=(width, height))\n    plt.title('Price of fare by %s' %(feature))\n    price_order = df.groupby(feature)[target].mean()\\\n                    .sort_values(ascending=False).index.values\n    sns.boxplot(data=df, y=feature, x=target, order=price_order)\n    \nplot_price('Airline')","2dd53546":"print(\"Number of unique Dates: \", train_data['Date_of_Journey'].nunique())\nplot_price('Date_of_Journey')","c87bd9f7":"date = pd.DatetimeIndex(train_data['Date_of_Journey'])\ntrain_data['Date_of_Journey'] = date.date\ntrain_data['Weekday'] = train_data['Date_of_Journey']\\\n                        .apply(lambda x: calendar.day_name[x.weekday()])\ntrain_data['Month'] = date.month\ntrain_data['Month'] = train_data['Month'].apply(lambda x: calendar.month_abbr[x])\ntrain_data['Day'] = date.day\ntrain_data['Year'] = date.year\ntrain_data.head()","2a2319d8":"sns.boxplot(data=train_data, y='Price', x='Month')\nplt.title('Price of fare by %s' %('Month'))","6389bf92":"sns.boxplot(data=train_data, y='Price', x='Weekday')\nplt.title('Price of fare by %s' %('Weekday'))","d74616b8":"sns.boxplot(data=train_data, y='Price', x='Day')\nplt.title('Price of fare by %s' %('Day'))","4391cd7b":"sns.boxplot(data=train_data, y='Price', x='Source')\nplt.title('Price of fare by %s' %('Source'))","02cfbd33":"sns.boxplot(data=train_data, y='Price', x='Destination')\nplt.title('Price of fare by %s' %('Destination'))","e7f2509e":"train_data['Source_Dest'] = train_data[['Source','Destination']].apply(lambda x: '_'.join(x), axis=1)\ntrain_data['Source_Dest'].unique()","d380c01d":"plot_price('Source_Dest', height=4, width=8)","a2ddd5df":"test = train_data['Duration'].str.split(' ', expand=True)\ntrain_data['Duration_Hour'] = pd.to_numeric(test[0].str.extract('(\\d+)', expand=False))\ntrain_data['Duration_Minutes'] = pd.to_numeric(test[1].str.extract('(\\d+)', expand=False))\ntrain_data.fillna(0, inplace=True)\ntrain_data['Duration_Total'] = train_data['Duration_Hour']*60 + train_data['Duration_Minutes']\ntrain_data.head()","b26e497f":"sns.lmplot(data=train_data, x='Duration_Total', y='Price')","0d90de5e":"sns.distplot(train_data['Duration_Total'])","70455135":"sns.distplot(np.sqrt(train_data['Duration_Total']), fit=norm, kde=False)","e72ffba6":"# temp = train_data.copy()\ntrain_data['Duration_Total_Sqrt'] = np.sqrt(train_data['Duration_Total'])\nsns.lmplot(data=train_data, x='Duration_Total_Sqrt', y='Price')","a0344379":"idx = train_data[train_data['Total_Stops']==0].index\ntrain_data.loc[idx,'Total_Stops'] = train_data['Total_Stops'].mode()[0]\ntrain_data.loc[idx]","296f6576":"plot_price('Total_Stops', height=5)","70fc68ee":"train_data['Additional_Info'] = train_data['Additional_Info']\\\n                                    .replace({'No Info': 'No info',\n                                              '1 Short layover': 'Has Layover',\n                                              '1 Long layover': 'Has Layover',\n                                              '2 Long layover': 'Has Layover'})\nplot_price('Additional_Info', height=5)","369423a5":"train_data.info()","f4250c0a":"train_data['Total_Stops'] = train_data['Total_Stops']\\\n                                    .replace({'non-stop': 0,\n                                              '1 stop': 1,\n                                              '2 stops': 2,\n                                              '3 stops': 3,\n                                              '4 stops': 4})","2db36a90":"train_data['Avg_Duration'] = train_data['Duration_Total'] \/ (train_data['Total_Stops'] + 1)\ntrain_data.head()","d69260c3":"print(train_data['Avg_Duration'].nunique())\nsns.lmplot(data=train_data, x='Avg_Duration', y='Price')","1aa27f2b":"test_data.info()","bf92ff57":"date = pd.DatetimeIndex(test_data['Date_of_Journey'])\ntest_data['Date_of_Journey'] = date.date\ntest_data['Weekday'] = test_data['Date_of_Journey']\\\n                        .apply(lambda x: calendar.day_name[x.weekday()])\ntest_data['Month'] = date.month\ntest_data['Month'] = test_data['Month'].apply(lambda x: calendar.month_abbr[x])\ntest_data['Day'] = date.day\ntest_data['Year'] = date.year\ntest = test_data['Duration'].str.split(' ', expand=True)\ntest_data['Duration_Hour'] = pd.to_numeric(test[0].str.extract('(\\d+)', expand=False))\ntest_data['Duration_Minutes'] = pd.to_numeric(test[1].str.extract('(\\d+)', expand=False))\ntest_data.fillna(0, inplace=True)\ntest_data['Duration_Total'] = test_data['Duration_Hour']*60 + test_data['Duration_Minutes']\ntest_data['Duration_Total_Sqrt'] = np.sqrt(test_data['Duration_Total'])\ntest_data['Source_Dest'] = test_data[['Source','Destination']].apply(lambda x: '_'.join(x), axis=1)\ntest_data['Additional_Info'] = test_data['Additional_Info']\\\n                                    .replace({'No Info': 'No info',\n                                              '1 Short layover': 'Has Layover',\n                                              '1 Long layover': 'Has Layover',\n                                              '2 Long layover': 'Has Layover'})\ntest_data['Additional_Info'].value_counts()\ntest_data['Total_Stops'] = test_data['Total_Stops']\\\n                                    .replace({'non-stop': 0,\n                                              '1 stop': 1,\n                                              '2 stops': 2,\n                                              '3 stops': 3,\n                                              '4 stops': 4})\ntest_data['Avg_Duration'] = test_data['Duration_Total'] \/ (test_data['Total_Stops'] + 1)\ntest_data.head()","cdbad7c6":"diff_sd = list(set(test_data['Route']) - set(train_data['Route']))\ndiff_sd","38e1a842":"diff = list(set(test_data['Airline']) - set(train_data['Airline']))\ndiff","d9351a29":"diff_layover = list(set(test_data['Additional_Info']) - set(train_data['Additional_Info']))\ndiff_layover","6233a85c":"diff_sd = list(set(test_data['Source_Dest']) - set(train_data['Source_Dest']))\ndiff_sd","c03fa7e3":"test_data.info()","5bd2af8e":"test_clean = test_data.copy()\ntrain_clean = train_data.copy()\ntemp = pd.concat([train_clean, test_clean])","c0f6839e":"drop_col = ['Date_of_Journey', 'Route', 'Dep_Time', 'Arrival_Time', \n            'Duration', 'Duration_Hour', 'Duration_Minutes']\ntemp = temp.drop(columns=drop_col, axis=1)\ntemp.info()","6600d3f3":"to_one_hot = ['Airline', 'Source', 'Destination',\n              'Weekday', 'Month', 'Source_Dest']\n\ntemp = pd.concat([temp, pd.get_dummies(temp[to_one_hot])], axis=1)\ntemp.drop(to_one_hot, axis=1, inplace=True)\ntemp.info()","c71ddad5":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(temp['Additional_Info'])\ntemp['Additional_Info'] = le.fit_transform(temp['Additional_Info'])\ntemp.head()","c6f0e2b6":"train_clean = temp[temp['Price'].notnull()]\ntest_clean = temp[temp['Price'].isnull()]\ntest_clean = test_clean.drop(columns='Price')\n(train_clean.shape, test_clean.shape)","8ad5f548":"y = train_clean.Price\nX = train_clean.drop(columns='Price', axis=1)\nX.head(10)","feade05e":"pd.DataFrame(np.exp(y)).head(10).T","910c4f9f":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1)\n\ndef validation_predictions(model, name):\n    new_model = model.fit(X_train, y_train)\n    pred = np.exp(new_model.predict(X_valid))\n    print(\"============= %s and Shuffle Split =============\" %name)\n    print(\"Accuracy: %f\" %(r2_score(np.exp(y_valid), pred)))\n    print(\"MSE: %f\" %(mean_squared_error(np.exp(y_valid), pred)))\n    print(\"MAE: %f\" %(mean_absolute_error(np.exp(y_valid), pred)))\n    \n    new_model = model.fit(X, y)\n    cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n    cvs = cross_val_score(new_model, X, y, cv=cv)\n    print('Shuffle and cross validate: %s \\nAverage: %.2f' %(cvs, cvs.mean()))","9bdd7121":"lr_model = LinearRegression()\nvalidation_predictions(lr_model, 'Linear Regression')","164e5de8":"rf_model = RandomForestRegressor(random_state=0)\n# rf_model.fit(X_train, y_train)\nvalidation_predictions(rf_model, 'Random Forest Regressor')\n# print('Training accuracy: %.2f \\nTesting accuracy: %.2f' %(rf_model.score(X_train, y_train), rf_model.score(X_valid,y_valid)))","3cb3a1a5":"dt_model = DecisionTreeRegressor(random_state=0)\nvalidation_predictions(dt_model, 'Decision Tree Regressor')","a16030d5":"xgb_model = xgb.XGBRegressor()\nvalidation_predictions(xgb_model, 'XGBoost Regressor')","19019698":"# from sklearn.model_selection import RandomizedSearchCV\n\n# # Randomized Search CV\n# # Number of trees in random forest\n# n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# # Number of features to consider at every split\n# max_features = ['auto', 'sqrt']\n# # Maximum number of levels in tree\n# max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# # Minimum number of samples required to split a node\n# min_samples_split = [2, 5, 10, 15, 100]\n# # Minimum number of samples required at each leaf node\n# min_samples_leaf = [1, 2, 5, 10]\n\n# # create random grid\n# random_grid = {'n_estimators': n_estimators,\n#                'max_features': max_features,\n#                'max_depth': max_depth,\n#                'min_samples_split': min_samples_split,\n#                'min_samples_leaf': min_samples_leaf}\n\n# # Random search of parameters, using 5 fold cross validation, \n# # search across 100 different combinations\n# rf_random = RandomizedSearchCV(estimator = rf_model, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n\n# rf_random.fit(X_train, y_train)","336a92ca":"# looking at best parameters\n# rf_random.best_params_","116c491a":"best_rf_model = RandomForestRegressor(n_estimators=700, min_samples_split=15, \n                                      min_samples_leaf=1, max_features='auto', \n                                      max_depth=20, random_state=0)\n\nvalidation_predictions(best_rf_model, 'Random Forest Regressor Tuned')","dfc14a5b":"def accuracy_score(results):\n    key_min = min(results.keys(), key=(lambda k: results[k]))\n    key_max = max(results.keys(), key=(lambda k: results[k]))\n    \n    print('Highest accuracy score at %d features of %.4f' %(key_max, results[key_max]))\n    print('Lowest accuracy score at %d features of %.4f' %(key_min, results[key_min]))\n    return key_max, key_min","a7086f6b":"results = {}\n\nfor i in range(2, X.columns.size):\n    selector = SelectKBest(f_regression, k=i)\n    X_new = selector.fit_transform(X_train, y_train)\n#     rf_model = RandomForestRegressor(random_state=0)\n    new_model = best_rf_model.fit(X_new, y_train)\n    selected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                     index=X_train.index, \n                                     columns=X_train.columns)\n    selected_cols = selected_features.columns[selected_features.var() != 0]\n    pred = np.exp(new_model.predict(X_valid[selected_cols]))\n    results[i] = r2_score(np.exp(y_valid), pred)","c3a66132":"plt.plot(list(results.keys()), list(results.values()))\nplt.xlabel('# of features')\nplt.ylabel('Score (average MAE)')\nplt.title('Random Forest SelectKBest')\nplt.show()","f5ff0e4a":"high, low = accuracy_score(results)","1ac1fb60":"selector = SelectKBest(f_regression, k=high)\nX_new = selector.fit_transform(X_train, y_train)\nrf_model = best_rf_model.fit(X_new, y_train)\n\nselected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                 index=X_train.index, \n                                 columns=X_train.columns)\n\nselected_cols_rf = selected_features.columns[selected_features.var() != 0]\npred = np.exp(rf_model.predict(X_valid[selected_cols_rf]))","615b769b":"print(\"Accuracy: %f\" %(r2_score(np.exp(y_valid), pred)))\nprint(\"MSE: %f\" %(mean_squared_error(np.exp(y_valid), pred)))\nprint(\"MAE: %f\" %(mean_absolute_error(np.exp(y_valid), pred)))","0cc6acfa":"results1 = {}\n\nfor i in range(2, X.columns.size):\n    selector = SelectKBest(f_regression, k=i)\n    X_new = selector.fit_transform(X_train, y_train)\n    xgb_model = xgb.XGBRegressor(random_state=0)\n    new_model = xgb_model.fit(X_new, y_train)\n    selected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                     index=X_train.index, \n                                     columns=X_train.columns)\n    selected_cols = selected_features.columns[selected_features.var() != 0]\n    pred = np.exp(new_model.predict(X_valid[selected_cols].values))\n    results1[i] = r2_score(np.exp(y_valid), pred)","96dbd03c":"plt.plot(list(results1.keys()), list(results1.values()))\nplt.xlabel('# of features')\nplt.ylabel('Score (average MAE)')\nplt.title('XGBRegressor SelectKBest')\nplt.show()","1ff51db4":"high1, low1 = accuracy_score(results1)","fa4229ac":"selector = SelectKBest(f_regression, k=high1)\nX_new = selector.fit_transform(X_train, y_train)\nxgb_model = xgb.XGBRegressor().fit(X_new, y_train)\n\nselected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                 index=X_train.index, \n                                 columns=X_train.columns)\n\nselected_cols_xgb = selected_features.columns[selected_features.var() != 0]\npred = np.exp(xgb_model.predict(X_valid[selected_cols_xgb].values))","8fa43527":"print(\"Accuracy: %f\" %(r2_score(np.exp(y_valid), pred)))\nprint(\"MSE: %f\" %(mean_squared_error(np.exp(y_valid), pred)))\nprint(\"MAE: %f\" %(mean_absolute_error(np.exp(y_valid), pred)))","54da004b":"**Separate Date**\n\nWe can separate the date by weekday, month, day and year. Since the flights are all in 2019, we can look at how the price changes per month or weekday, instead.","79a89cc8":"There is a row that has 0 stops. That does not make sense, so we can drop the row, or replace it with the most frequent number of stops.","985f5186":"**Drop certain features**","10f6094b":"best params for random forest regressor\n> {'n_estimators': 700,\n>  'min_samples_split': 15,\n>  'min_samples_leaf': 1,\n>  'max_features': 'auto',\n>  'max_depth': 20}","f55d630d":"# Feature Engineering","24d602d8":"**Label Encoding**","044128f6":"Creating a feature called average duration which is the duration of flights between stops.","45a03167":"**Hyperparameter Tuning for Random Forest Regressor**","452d7f08":"**Split them up again into train and test**","28840ec9":"**Predictions using validation data**","c2dc9261":"# Encoding\n\n**Combine**\n\nThe train and test data are combined for easy one-hot and label encoding","9233822e":"**Combine Duration into minutes**\n\nFirst separate the Duration column into its hours and minutes, then combine to get total duration in minutes.","fdd1d4dc":"There are four different routes in the test data that aren't in the training data. Since they are never trained on, the 'Route' feature should be dropped.","6097bb48":"# Train and Predict","d2d5b110":"# Preliminary Analysis","d08798bd":"### Dates","5d0d3206":"### Source and Destination","976101a8":"**Feature Selection**","fd3b4874":"**Read File**","538632ad":"# Exploratory Data Analysis\n\nEverything but the response variable is a categorical feature. To choose whether to one-hot encode or label encode the categorical features, we need to analyze each feature.\n\n### Airlines","3bd2b20c":"**Check Price Distribution**","4d183e9c":"**Imports**","a521a9c1":"### Duration","5501e9b7":"### Additional Info","7a9fd5cb":"# Test Data set\n\nWhatever was done to the training data set will also be done to the test data set so that they have the exact same features.","46c9f2eb":"**Combine Source and Destination to make a new feature**","194ed077":"### Stops","f1428d9d":"**Quick one-hot encoding**"}}