{"cell_type":{"2e1085e0":"code","93d8b66a":"code","8ac72590":"code","865378f6":"code","fbc8c16f":"code","def4cb71":"code","da156d2e":"code","b2017aa1":"code","6fb5fa50":"code","ff51299c":"code","d2d2fd42":"code","785c6e4a":"code","a0647c5b":"code","ea80b326":"code","3e1c489d":"code","7ac233ad":"code","2d9012fa":"code","49b7b90c":"code","d8ce3353":"code","53fcad4a":"code","8ec2f5ed":"code","336130be":"code","5b62a099":"code","17b47725":"code","d96af64d":"code","a0f7c64e":"code","7d93e25c":"code","97ffc9d2":"code","ef70fa38":"code","37a51959":"code","9f2b6c18":"code","f522df2b":"code","24e32ccb":"markdown","fcaa3e5c":"markdown","f9727e5c":"markdown","6a9a86e3":"markdown","1770c94f":"markdown","cbdd2f6b":"markdown","bdb34073":"markdown","f6f51b28":"markdown","87f7b29b":"markdown","5c8c21fc":"markdown","2075d3fa":"markdown","aafe4476":"markdown","7a8d5885":"markdown","240b8e50":"markdown","7111dbb3":"markdown","b2c721a1":"markdown","b215360a":"markdown","d2ecc21d":"markdown","da8f93d5":"markdown"},"source":{"2e1085e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93d8b66a":"#importing Libraries\nimport pandas as pd\nimport numpy as np","8ac72590":"df= pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()\nX=df.iloc[:,0:8]\ny=df.iloc[:,-1]\nX","865378f6":"df.describe()","fbc8c16f":"#libraries for plotting data\nimport matplotlib.pyplot as plt\nimport seaborn as sns","def4cb71":"matrix = np.triu(df.corr())\nsns.heatmap(df.corr(),annot=True,fmt='.1g',vmin=-1, vmax=1, center= 0,cmap='YlOrRd',mask=matrix)\n","da156d2e":"feature=X.columns\ndfzero=(X[feature]==0).sum()\ndfzero","b2017aa1":"X[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI']]=X[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)","6fb5fa50":"X.isnull().sum()","ff51299c":"X['Glucose'].fillna(X['Glucose'].mean(),inplace=True)\n#inplace=True is necessary\nX['BMI'].fillna(X['BMI'].mean(),inplace=True)\nX['Pregnancies'].fillna(X['Pregnancies'].mean(),inplace=True)\nX['BloodPressure'].fillna(X['BloodPressure'].mean(),inplace=True)\nX['SkinThickness'].fillna(X['SkinThickness'].mean(),inplace=True)\nX['Insulin'].fillna(X['Insulin'].mean(),inplace=True)\n","d2d2fd42":"X.describe() # there is minimum value across every feature, no more error values.","785c6e4a":"X.isnull().sum() #there are no more null values","a0647c5b":"# Age Bracket based on the input values of Age Vs Glucose\nX1=X['Glucose']\nY1=X['Age']\n\nplt.scatter(X1,Y1)\nplt.xlabel('Glucose Level')\nplt.ylabel('Age')\nplt.title(label='Age Vs Glucose Chart')\nplt.show()","ea80b326":"#Derive new columns\nX['HighRisk']= np.where(X['SkinThickness']>23,1,0) # derived column based on the input values\n\nX['AgeBracket'] = np.select([\n    (X.Age >= 50),\n    (X.Age >= 30) & (X.Age <50),\n    (X.Age <30)\n], [3, 2, 1])\n","3e1c489d":"X.head()\nX=X.drop(columns=['Age','SkinThickness'])","7ac233ad":"X.head()","2d9012fa":"from sklearn.model_selection import train_test_split \nXtrain,Xtest,ytrain,ytest= train_test_split(X,y,test_size=0.2,random_state=0)","49b7b90c":"Xtrain.shape #training data has 614 rows and 8 columns\n","d8ce3353":"Xtest.shape #test dataset has 154 rows and 8 columns","53fcad4a":"Xtrain.head()","8ec2f5ed":"from sklearn.preprocessing import StandardScaler\nSc= StandardScaler()\nXtrain.iloc[:,:6]=Sc.fit_transform(Xtrain.iloc[:,:6])\nXtest.iloc[:,:6]=Sc.transform(Xtest.iloc[:,:6])","336130be":"Xtrain # all the values have been converted in the range of -3 to +3 ","5b62a099":"from sklearn.svm import SVC\nSVC_Classifier=SVC()\nSVC_Classifier.fit(Xtrain,ytrain)","17b47725":"ypred=SVC_Classifier.predict(Xtest) # Predicting Data Values","d96af64d":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,roc_auc_score\ncm=confusion_matrix(ytest,ypred)\ncm\n","a0f7c64e":"score=accuracy_score(ytest,ypred)\nprint('Accuracy Score',score)","7d93e25c":"from sklearn.metrics import roc_curve\nfpr,tpr,_=roc_curve(ytest,ypred)\nplt.plot(fpr,tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')","97ffc9d2":"from sklearn.ensemble import RandomForestClassifier\nRF_Classifier=RandomForestClassifier()\nRF_Classifier.fit(Xtrain,ytrain)","ef70fa38":"ypred_RF= RF_Classifier.predict(Xtest)","37a51959":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,roc_auc_score\ncm_rf=confusion_matrix(ytest,ypred_RF)\ncm_rf\n","9f2b6c18":"score_rf=accuracy_score(ytest,ypred_RF)\nprint('Score based on RandomForest model',score_rf)","f522df2b":"from sklearn.metrics import roc_curve\nfpr,tpr,_=roc_curve(ytest,ypred_RF)\nplt.plot(fpr,tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')","24e32ccb":"# New Facts based on the Field details.\n\nSkin Thickness >23mm leads to higher chances of diabetes. \n\nWith this information we can derive a new feature \"High Risk\".\nIf Skin Thickness>23 then HR= 1 else HR=0\n","fcaa3e5c":"# Notebook is about Predicting whether a female is diabetic or not based on the features provided.\n\n\n\nThere are few general steps always performed in ML predictions. Let's go step by step.\n\n\n","f9727e5c":"**Data Preprocessing**\n\nit involves \nTreating missing values\n  1. Remove them simply if values are not critical or doesnt form a major part of your data.\n  2. Replace them with average or median values. Depends on the business decision.\n\nDealing with outliers \nStandardize your data","6a9a86e3":"Lets Check Score..!!","1770c94f":"What do you get from this \n\n1. Outcome :- \n    Glucose and BMI are highly correlated \n2. Age and Pregnancy are positively corelated i.e. greater the age , more will be the number of pregnancies.\n3. SkinThickness has high relevance to BMI and Insulin.\n\nThere is not a single feature that doesnot have direct or indirect impact over outcome. \n","cbdd2f6b":" **Evaluating RF Classifier**\n","bdb34073":"\n**Please give a upvote if you liked my efforts. #MLBeginner**","f6f51b28":"# Trying Random Forest Classifier now","87f7b29b":"Data Standardization is the best method to remove outliers and set your data in range.\n\n* First Fit your data on the training dataset and based on that transform your testdataset. \n\nP.S:- **do not fit on test dataset.**","5c8c21fc":"#Data Analysis\n1. Describe function , this provides a very clear picture of all the fields in your data.","2075d3fa":" 1. There is no missing values in the data.\n 2. Min value =0 in Pregnancy , Glucose, BP, SkinThickness, Insulin, BMI which is practically not possible so we will handle it by replacing it with NaN\n 3. There is extreme variation(std,mean) across the fields hence we will require to Standardize the data so that they fall in the same range.\n *with Standardization data values gets converted to (-3 to 3 )range","aafe4476":"**Fill Na with Average of the data values\nNA values can be treated with Mean, Median and Mode depending on the type of data and the no. of values missing.**","7a8d5885":"# Evaluating Result\n1. CONFUSION MATRIX\n2. ACCURACY SCORE\n3. ROC CURVE","240b8e50":"# Build Data Model","7111dbb3":"Deriving AgeBracket based on the data pattern which shows \nwith increase in Age, Glucose Level increases leading to Higher risk of Diabetics\n\nAgeBracket :- \n\n>50 patients are at high risk so I have given AgeBracket=3\n\n>30 and <50 are at med risk so AgeBracket=2\n\n<30 are at low risk so AgeBracket=1\n\n\n\n\n\n\n","b2c721a1":"**Dataset Description**\n\n1. Pregnancies: No. of times pregnant\n2.  Glucose: Plasma Glucose Concentration (mg\/dl)\n3. Blood Pressure: Diastolic Blood Pressure(mmHg)\n4. Skin Thickness:A value used to estimate body fat. Normal Triceps SkinFold Thickness in women is 23mm. Higher thickness leads to obesity and chances of diabetes increases.\n5. Insulin: 2-Hour Serum Insulin (mu U\/ml)\n6. BMI: Body Mass Index (weight in kg\/ height in m2)\n7. Diabetes Pedigree Function: It provides information about diabetes history in relatives and genetic relationship of those relatives with patients. Higher Pedigree Function means patient is more likely to have diabetes.\n8. Age:Age (years)\n9. Outcome: Class Variable (0 or 1) where \u20180\u2019 denotes patient is not having diabetes and \u20181\u2019 denotes patient having diabetes.\n","b215360a":"Yay..!! 78 % but it can  be improved ","d2ecc21d":"95 :- True Postive i.e. out of 154 values 94 values (1) are correctly predicted as 1\n\n26 :- True Negative i.e. 27 values (0) are correctly predicted as 0 \n\n12 :- False Positive i.e 13 values (1) are incorrectly predicted as 0\n\n21 :- False Negative i.e. 20 values (0) are incorrectly predicted as 1\n\nP.S **Model outcome looks really appreciative.**\n","da8f93d5":"SPLIT DATASET INTO TRAINING AND TEST DATASET\n\n---\n\n"}}