{"cell_type":{"05ea9be9":"code","d5d6455a":"code","369de338":"code","79e81ca4":"code","9693f776":"code","5d7c3f44":"code","b8fbabbf":"code","0f72418e":"code","ac404f78":"code","08082db3":"code","1b647f5a":"code","524b4a97":"code","d4afef0d":"code","6c9a9b86":"code","9bda68f7":"code","6c99ffe6":"code","4cb59161":"code","aa2f4463":"code","0ec7bb4c":"code","bd1de65e":"code","d9aa52c1":"code","1a93ebdf":"code","9e9f0cd8":"code","bcbce1a4":"code","458e683d":"code","bed86c52":"code","cdf80517":"code","ffb4f65f":"code","e55324e8":"code","bb1c2f73":"markdown","b2afc199":"markdown","36a626f0":"markdown","c0249527":"markdown","12c24652":"markdown","f9f4dd76":"markdown","f561125d":"markdown","8e81c451":"markdown","8a5408fc":"markdown","6271825e":"markdown","338bfb6a":"markdown","25098ffe":"markdown","ce7932ba":"markdown","b869a911":"markdown","1d03c887":"markdown","ef34e647":"markdown","dec9342a":"markdown","0c1c9eec":"markdown","6bd49b9f":"markdown","fddec3d7":"markdown","3ad81af4":"markdown","a905290f":"markdown","2544f759":"markdown","460e2448":"markdown","6c2e8a47":"markdown","06dbca3f":"markdown","ea4728c6":"markdown"},"source":{"05ea9be9":"import pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport squarify\nfrom datetime import datetime","d5d6455a":"file_repos = \"..\/input\/github-repositories.csv\"\ndf_repos = pd.read_csv(file_repos, index_col = False)\ndf_repos.head(5)","369de338":"df_repos['id'].count()","79e81ca4":"df_repos_by_stars = df_repos.sort_values(by='stars', ascending=False).reset_index()\ndf_repos_by_stars[['full_name', 'stars']].head(10)","9693f776":"df_repos_by_lang = df_repos.groupby(['language'])['id'].agg(['count'])\ndf_repos_by_lang = df_repos_by_lang.sort_values(by = 'count', ascending = False).reset_index()\ndf_repos_by_lang.head(10)","5d7c3f44":"df_repos_by_lang.sort_values(by = 'count', ascending = True).head(10)","b8fbabbf":"total_repos = df_repos['id'].count()\n\ndf_repos_by_lang['percentage'] = df_repos_by_lang['count'].apply(lambda count: count \/ total_repos * 100)\ndf_repos_by_lang['new_language'] = df_repos_by_lang.apply(lambda row: 'Other' if row['percentage'] < 1 else row['language'], axis = 1)\n\ndf_repos_by_lang.head(5)","0f72418e":"df_repos_by_lang_transformed = df_repos_by_lang.groupby(['new_language'])['count'].agg(['sum'])\ndf_repos_by_lang_transformed = df_repos_by_lang_transformed.sort_values(by='sum', ascending=False).reset_index()\ndf_repos_by_lang_transformed","ac404f78":"labels = df_repos_by_lang_transformed['new_language']\nvalues = df_repos_by_lang_transformed['sum']\n\nfig, ax =  plt.subplots(figsize=(16, 9))\n\nsquarify.plot(sizes = values, label = labels, alpha=.8, ax = ax)\n\nplt.axis('off')\nplt.show()","08082db3":"df_repos['created_at_datetime'] = pd.to_datetime(df_repos['created_at'], format = \"%Y-%m-%dT%H:%M:%SZ\")","1b647f5a":"df_repos['created_at_year'] = df_repos['created_at_datetime'].apply(lambda created_at_datetime: created_at_datetime.strftime(\"%Y\") if pd.notnull(created_at_datetime) else created_at_datetime)","524b4a97":"df_repos_by_year = df_repos.groupby(['created_at_year'])['id'].agg(['count']).reset_index()\ndf_repos_by_year","d4afef0d":"x = df_repos_by_year['created_at_year']\ny = df_repos_by_year['count']\n\nfig, ax =  plt.subplots(figsize=(16, 9))\n\nax.bar(x, y, color = 'green')\nax.set_title('Repos created by year')\nax.set_xlabel('Year')\nax.set_ylabel('# of repos created')\n\nplt.xticks(rotation = 90)\nplt.plot()","6c9a9b86":"df_repos['created_at_month'] = df_repos['created_at_datetime'].apply(lambda created_at_datetime: created_at_datetime.strftime(\"%Y-%m\") if pd.notnull(created_at_datetime) else created_at_datetime)\ndf_repos_by_month = df_repos.groupby(['created_at_month'])['id'].agg(['count']).reset_index()\ndf_repos_by_month.head(12)","9bda68f7":"x = df_repos_by_month['created_at_month']\ny = df_repos_by_month['count']\n\nfig, ax =  plt.subplots(figsize=(16, 9))\n\nax.bar(x, y, color = 'green')\nax.set_title('Repos created by month')\nax.set_xlabel('Month')\nax.set_ylabel('# of repos created')\n\nplt.xticks(rotation = 90)\nplt.plot()","6c99ffe6":"df_repos_forked = df_repos.groupby(['is_fork'])['id'].agg(['count']).reset_index()\ndf_repos_forked['label'] = df_repos_forked['is_fork'].apply(lambda is_fork: 'Fork' if is_fork else 'No Fork')\ndf_repos_forked","4cb59161":"labels = df_repos_forked['label']\ncount = df_repos_forked['count']\n\nfig, ax = plt.subplots(figsize = (8, 8))\n\nax.pie(count, labels = labels, autopct = '%1.1f%%')\nax.set_title('Fork repos')\n\nplt.plot()","aa2f4463":"df_creators = df_repos.groupby(['owner_id', 'owner_name'])['owner_id'].agg(['count'])\ndf_creators_top_25 = df_creators.sort_values(by = 'count', ascending = False).head(25).reset_index()\ndf_creators_top_25.head(5)","0ec7bb4c":"df_repos_of_creators_top_25 = pd.merge(df_creators_top_25, df_repos, how = 'inner', on = ['owner_id'])","bd1de65e":"df_repos_by_creator = df_repos_of_creators_top_25.groupby(['owner_name_x', 'is_fork'])['owner_id'].agg(['count']).sort_values(by = ['owner_name_x', 'is_fork'], ascending = True).reset_index()\ndf_repos_by_creator.head(5)","d9aa52c1":"df_repos_by_creator_transformed = df_repos_by_creator.pivot(index = 'owner_name_x', columns = 'is_fork', values = 'count').reset_index()\ndf_repos_by_creator_transformed[True].fillna(0, inplace = True)\ndf_repos_by_creator_transformed[False].fillna(0, inplace = True)\ndf_repos_by_creator_transformed.head(5)","1a93ebdf":"N = df_creators_top_25['owner_id'].count()\n\nfig, ax =  plt.subplots(figsize = (16, 9))\n\noriginal_repos = np.array(df_repos_by_creator_transformed[False])\nforked_repos = np.array(df_repos_by_creator_transformed[True])\ntotal_repos = np.array(original_repos + forked_repos)\n\nind = np.arange(N) # the x locations for the groups\nwidth = 0.25       # the width of the bars\n\ns1 = ax.bar(ind - width, total_repos, width, color='green')\ns2 = ax.bar(ind, original_repos, width, color = 'blue')\ns3 = ax.bar(ind + width, forked_repos, width, color='red')\n\nax.set_title('Repos created by top 25 creators')\nax.set_xticks(ind + width \/ 3)\nax.set_xticklabels(np.array(df_repos_by_creator_transformed['owner_name_x']))\nax.legend((s1[0], s2[0], s3[0]), ('Total', 'No Fork', 'Fork'))\n\nplt.xticks(rotation = 90)\nplt.plot()","9e9f0cd8":"df_language_evolution = df_repos.groupby(['language', 'created_at_month'])['id'].agg(['count']).reset_index()\ndf_language_evolution.head(5)","bcbce1a4":"df_language_evolution_filtered = df_language_evolution[df_language_evolution['language'].isin(df_repos_by_lang_transformed['new_language'])]","458e683d":"df_language_evolution_filtered = df_language_evolution_filtered.sort_values(by = ['language', 'created_at_month'], ascending = True)\ndf_language_evolution_filtered.head(5)","bed86c52":"df_language_evolution_transformed = df_language_evolution_filtered.pivot(index = 'created_at_month', columns = 'language', values = 'count')\ndf_language_evolution_transformed.head(5)","cdf80517":"df_language_evolution_transformed.fillna(0, inplace = True)\ndf_language_evolution_transformed.head(5)","ffb4f65f":"df_language_evolution_transformed = df_language_evolution_transformed.cumsum().reset_index()\ndf_language_evolution_transformed.head(5)","e55324e8":"N = df_language_evolution_transformed['created_at_month'].count()\n\nfig, ax =  plt.subplots(figsize=(16, 9))\n\nind = np.arange(N)\n\nlegend_values = list()\nlegend_titles = list()\n\nfor column in df_language_evolution_transformed:\n    if column != 'created_at_month':\n        sn = ax.plot(np.array(df_language_evolution_transformed[column]))\n        \n        legend_values.append(sn[0])\n        legend_titles.append(column)\n\nax.set_title('Evoluci\u00f3n de los lenguajes')\nax.set_xlabel('Tiempo')\nax.set_xticks(ind)\nax.set_xticklabels(np.array(df_language_evolution_transformed['created_at_month']))\nax.set_ylabel('Repositorios creados')\nax.grid(True)\nax.legend(legend_values, legend_titles)\n\nplt.xticks(rotation = 90)\nplt.plot()","bb1c2f73":"S\u00f3lo queda agrupar por esta nueva columna (`created_at_year`) y hacer un conteo.","b2afc199":"Por \u00faltimo se representan los datos con un gr\u00e1fico de l\u00edneas.\n\nPara realizar este gr\u00e1fico se itera sobre las columnas del _dataframe_ y se crea una serie para cada columna.","36a626f0":"## 3 - Uso de lenguajes\n\nEn este punto se va a mostrar gr\u00e1ficamente, mediante un _TreeMap_, el uso de cada uno de los lenguajes.\n\nAntes de hacer esta representaci\u00f3n se va a hacer una transformaci\u00f3n de los datos para que la representaci\u00f3n sea m\u00e1s legible. El problema reside en que hay muchos lenguajes con muy pocos repositorios, lo que provoca que haya demasiados elementos representados. Para subsanar esto, se crear un nuevo lenguaje ficticio llamado __other__, que funciona a modo de _\"caj\u00f3n desastre\"_, donde se aglutinar\u00e1n los lenguajes que tengan un n\u00famero de repositorios inferior al 1% del total.\n\nA continuaci\u00f3n se muestran algunos de estos lenguajes con pocos repositorios creados:","c0249527":"Se pivota los datos anteriores de tal forma que en vertical tengamos los nombres de los creadores y en las columnas el n\u00famero de repositorios originales creados (columna `False`) y el n\u00famero de repositorios _fork_ creados (columns `True`).\n\nEste paso es una preparaci\u00f3n de los datos para facilitar la generaci\u00f3n del gr\u00e1fico final.","12c24652":"## 2 - Top 10 de lenguajes\n\nEn este caso se van a obtener los 10 lenguajes con m\u00e1s repositorios, para ello, se hace una agrupaci\u00f3n de los repositorios por la columna `language`. A continuaci\u00f3n se ordena la agregaci\u00f3n por la columna `count` descendientemente y se obtienen los 10 primeras elementos del _dataframe_.","f9f4dd76":"Se calcula el acumulado de cada columna.","f561125d":"## 4 - Repositorios creados por a\u00f1o\n\nEn este caso se va a mostrar gr\u00e1ficamente el n\u00famero de repositorios creados en cada a\u00f1o.\n\nPara mostrar los repositorios creados por a\u00f1o hay que parsear la columna `created_at` que est\u00e1 en formato `String` y convertirla a formato `DateTime`.\n\nSe utiliza la funci\u00f3n `to_datetime` de _Pandas_ para realizar la conversi\u00f3n y se crea una nueva columna en el dataset con el resultado de esta conversi\u00f3n (`created_at_datetime`).","8e81c451":"Esta evoluci\u00f3n se hace para los lenguajes con m\u00e1s repositorios (con un n\u00famero de repositorios superior al 1% del total). Para conseguir esto se filtran los lenguajes que se encuentran en el _dataframe_ calculado previamente en el caso 3 (`df_repos_by_lang_transformed`).","8a5408fc":"# An\u00e1lisis de repositorios de GitHub\n\nSe disponde de un dataset con datos de repositorios de [GitHub](https:\/\/github.com\/) que incluye la siguiente informaci\u00f3n:\n    \n| Columna | Descripci\u00f3n |\n| ------- | ----------- |\n| id | Identificador del repositorio |\n| owner_id | Identificador del creador del repositorio |\n| owner_name | Nickname del creador del repositorio |\n| full_name | Nombre del repositorio |\n| repo_detail_url | URL con informaci\u00f3n detallada del repositorio |\n| is_fork | Indica si el repositorio es un fork (copia) de otro |\n| repo_commits_url | URL para recuperar los commits de un repositorio |\n| language | Lenguage del c\u00f3digo del repositorio |\n| license | Licencia del repositorio |\n| size | Tama\u00f1o en bytes del repositorio |\n| stars | N\u00famero de estrellas concedidas al repositorio |\n| forks | N\u00famero de forks (copias) que se han creado del repositorio |\n| open_issues | N\u00famero de issues (bugs, peticiones de mejora, preguntas, etc.) abiertos |\n| created_at | Fecha de creaci\u00f3n del repositorio |\n\n#### Sobre el scraping\n\nLos datos han sido obtenidos utilizando el API que proporciona GitHub. Para ello se ha desarrollado unos scripts en python. Este API tiene las siguientes limitaciones:\n\n- 60 peticiones\/hora (uso an\u00f3nimo)\n- 5.000 peticiones\/hora (autenticado)\n\nEn un principio las 5.000 peticiones\/hora parec\u00eda un l\u00edmite bastante bajo por lo que la primera versi\u00f3n de los scripts de scraping se realizaron utilizando la red Tor, para poder cambiar de ip, y haciendo las llamadas de manera an\u00f3nima. Tras unas primeras pruebas se ha observado que el ratio de peticiones\/hora obtenido es muy bajo (tras 20 horas hab\u00eda realizado 24.900 peticiones, un ratio de 1.245 peticiones\/hora). Es por esto que se ha desarrollado una segunda versi\u00f3n de los scripts de scraping sin utilizar la red Tor y haciendo peticiones autenticadas. De esta forma el ratio alcanza el m\u00e1ximo permitido de 5.000 peticiones\/hora.\n\n#### Librer\u00edas utilizadas\n\nSe van a utilizar las siguientes librer\u00edas para hacer el an\u00e1lisis:\n\n- pandas\n- matplotlib\n- numpy\n- squarify","6271825e":"## 7 - Top 25 de creadores de repositorios\n\nEn esta caso se va a hacer una representaci\u00f3n de las 25 personas que m\u00e1s repositorios han creado, distinguiendo entre repositorios originales y _forks_.\n\nEn primer lugar se crea un nuevo _dataframe_ con los identificadores y nombres de los creadores de repositorios. Para ello se realiza una agregaci\u00f3n por las columnas `owner_id` y `owner_name`, se ordenan los resultados y se filtran los 25 primeros.","338bfb6a":"Para crear este nuevo lenguaje ficticio __other__, se van a a\u00f1adir 2 nuevas columnas al _dataframe_:\n\n- percentage\n- new_language\n\nLa columna `percentage` tiene el porcentaje de repositorios creados en ese lenguage con respecto al total.\n\nLa columna `new_language` contiene bien el valor __other__, si el porcentaje es inferior al 1%, o bien el valor original, en caso contrario.","25098ffe":"Se completan las columnas con `NaN` con valor `0`","ce7932ba":"El \u00faltimo paso es hacer la representaci\u00f3n gr\u00e1fica mediante un diagrama de barras.","b869a911":"A continuaci\u00f3n se crea otro _dataframe_ con todos los repositorios de estos 25 creadores obtenidos en el paso anterior.","1d03c887":"A partir de la columna que se acaba de crear con la fecha en formato `DateTime` (`created_at_datetime`), se crea la columna `created_at_year` que contiene el a\u00f1o de la fecha de creaci\u00f3n del repositorio.","ef34e647":"A continuaci\u00f3n se agrega el _dataframe_ anterior por la nueva columna `new_language` y se realiza la __suma__ de la columna `count`. Esto es para sumar los repositorios de todos los lenguajes que se han transformado en el nuevo lenguaje ficticio __other__.","dec9342a":"Con el resultado anterior se crea un _TreeMap_","0c1c9eec":"## 6 - Porcentaje de forks\n\nEn este caso se va a representar la relaci\u00f3n entre los repositorios originales y los repositorios creados a partir de otros (denominados _forks_).\n\nPara ello se agrupan los datos por la columna `is_fork` y se cuenta los resultados.","6bd49b9f":"A continuaci\u00f3n se pivota el _dataframe_ anterior de tal forma que se tenga la vertical las fechas y en las columnas los lenguajes.","fddec3d7":"## 5 - Repositorios creados por mes\n\nComo los repositorios se van recuperando de manera secuencial, y los respositorios que se han recuperado hasta la fecha son de pocos a\u00f1os, he realizado tambi\u00e9n la representaci\u00f3n de los repositorios creados por mes.\n\nLa mec\u00e1nica es la misma que en el caso anterior:\n\n1. Crear colunma nueva (`created_at_month`) con el mes de creaci\u00f3n (formato _a\u00f1o-mes_)\n1. Agrupar por la nueva columna\n1. Conteo","3ad81af4":"Una vez filtrados se ordenan por las columnas lenguaje (`lenguage`) y fecha (`created_at_month`).","a905290f":"En esta ocasi\u00f3n los resultados se muestran en un gr\u00e1fico de sectores:","2544f759":"## 8 - Evoluci\u00f3n de los lenguajes\n\nEn este caso se trata de ver como evoluciona a lo largo del tiempo la creaci\u00f3n de repositorios por cada lenguaje.\n\nPara ello se hace una agregaci\u00f3n por las columnas `language` y `created_at_month`.","460e2448":"Los resultados se representan en un diagrama de barras en el que por cada creador de repositorios se muestra:\n\n- el total de repositorios creados\n- los repositorios originales (No Fork)\n- los repositorios _fork_ (Fork)","6c2e8a47":"Estos repositorios se agrupan por su creador (`owner_name`) y por la columna `is_fork`.","06dbca3f":"### Carga del dataset\n\nEn primer lugar se crea un _dataframe_ a partir de un fichero csv que contiene los datos:","ea4728c6":"## 1 - Top 10 de repositorios m\u00e1s votados\n\nEn este caso se van a obtener los 10 repositorios m\u00e1s votados, para ello, simplemente se ordenan los repositorios por la columna `stars` descendientemente y se obtienen los 10 primeros elementos del _dataframe_."}}