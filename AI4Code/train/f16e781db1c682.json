{"cell_type":{"61791508":"code","64b2cadc":"code","0590eb93":"code","4120e639":"code","8d526df1":"code","ca817833":"code","074a2f7c":"code","a8f7b073":"code","98e6a4a5":"code","cf3be664":"code","5f16ce71":"code","91cafe3a":"code","12e25e52":"markdown","f92b0fa1":"markdown","aff58293":"markdown","34a40033":"markdown","4d70a0b6":"markdown","3f8634ec":"markdown","c52b39b3":"markdown","99641b4e":"markdown","713bca08":"markdown","7b4bd7b4":"markdown","215fec45":"markdown"},"source":{"61791508":"import math\nimport pandas as pd\nfrom datetime import datetime\nfrom vowpalwabbit import pyvw","64b2cadc":"with open('..\/input\/test.csv') as f:\n    # skip header\n    feature_names = f.readline().strip().split(',')","0590eb93":"too_many_unique_vals = ['MachineIdentifier',\n                        'Census_FirmwareVersionIdentifier',\n                        'Census_OEMModelIdentifier',\n                        'CityIdentifier'\n                       ]\ntoo_many_nas = ['PuaMode',\n                'Census_ProcessorClass',\n                'DefaultBrowsersIdentifier',\n                'Census_IsFlightingInternal',\n                'Census_InternalBatteryType',\n                'Census_ThresholdOptIn',\n                'Census_IsWIMBootEnabled'\n               ]\n\ntoo_imbalanced = ['Census_IsFlightsDisabled',\n                  'Census_IsAlwaysOnAlwaysConnectedCapable',\n                  'AVProductsEnabled',\n                  'IsProtected',\n                  'RtpStateBitfield',\n                  'Census_IsVirtualDevice',\n                  'Census_IsPortableOperatingSystem',\n                  'Census_IsPenCapable',\n                  'Census_FlightRing',\n                  'OsVer',\n                  'IsBeta',\n                  'Platform',\n                  'AutoSampleOptIn',\n                  'Census_DeviceFamily',\n                  'ProductName'\n                 ]","4120e639":"numeric_column_ids = [\n    38,  # Census_ProcessorCoreCount\n    42,  # Census_PrimaryDiskTotalCapacity\n    44,  # Census_SystemVolumeTotalCapacity\n    46,  # Census_TotalPhysicalRAM\n    48,  # Census_InternalPrimaryDiagonalDisplaySizeInInches\n    49,  # Census_InternalPrimaryDisplayResolutionHorizontal\n    50,  # Census_InternalPrimaryDisplayResolutionVertical\n    53   # Census_InternalBatteryNumberOfCharges  \n]","8d526df1":"categorical_column_ids = [i for i, feat_name in zip(range(len(feature_names)), feature_names) \n                          if (feat_name not in too_many_unique_vals + too_many_nas + too_imbalanced\n                          and i not in numeric_column_ids)]","ca817833":"len(categorical_column_ids), len(numeric_column_ids)","074a2f7c":"def to_vw(line, categ_column_ids, num_column_ids, column_names, train=True):\n    \"\"\"\n    Converts a string to VW format.\n    \n    :param line: a string with comma-separated feature values, str\n    :param categ_column_ids: ids of categorical features, list\n    :param num_column_ids: ids of numeric features, list\n    :param column_names: column (or feature) names to use (both categorical and numeric), list\n    :param train: whether the line belongs to a training set\n    :return: processed line, str\n    \"\"\"\n    values = line.strip().split(',')\n    # VW treats '|' and ':' as special symbols, so jnust in case we'll replace them\n    for i in range(len(values)):\n        values[i] = values[i].replace('|', '').replace(':', '')\n    label = '-1'\n    if train:\n        label, values = values[-1], values[:-1] \n        # in case of binary classification, VW eats labels 1 and -1, so 1 -> 1, 0 -> -1\n        label = str(2 * int(label) - 1)\n    \n    # for categorical features, we fill in missing values with 'unk'\n    for i in categ_column_ids:\n        if not values[i]:\n            values[i] = 'unk'\n            \n    # for numeric features, we fill in missing values with '-1'\n    for i in num_column_ids:\n        if values[i] == '':\n            values[i] = '-1'\n    \n    categ_vw = ' '.join(['{}={}'.format(column_names[i], values[i])\n                           for i in categ_column_ids])\n    # we apply log1p transformation to numeric features\n    numeric_vw = ' '.join(['{}:{}'.format(column_names[i],round(math.log(1 + float(values[i]) + 1e-10)))\n                           for i in num_column_ids])\n    \n    new_line = label + ' |num ' + numeric_vw + ' |cat ' + categ_vw\n    return new_line","a8f7b073":"line = '0000010489e3af074adeac69c53e555e,win8defender,1.1.15400.5,4.18.1810.5,1.281.501.0,0,7,0,,53447,1,1,1,43,58552,18,53,42,windows10,x64,10.0.0.0,15063,768,rs2,15063.0.amd64fre.rs2_release.170317-1834,Home,1,0,,,108,,1,1,Notebook,Windows.Desktop,2689,30661,4,5,3063,,488386,SSD,123179,0,8192,Notebook,15.5,1920,1080,Mobile,,8,10.0.15063.1387,amd64,rs2_release,15063,1387,Core,CORE,Reset,37,158,AutoInstallAndRebootAtMaintenanceTime,0,IS_GENUINE,OEM:DM,,0,Retail,,807,8554,1,,0,0,0,0,0,7'","98e6a4a5":"to_vw(line, categorical_column_ids, numeric_column_ids, feature_names, train=False)","cf3be664":"vw = pyvw.vw(b=28, random_seed=17, loss_function='logistic', passes=3, learning_rate=0.7, k=True, c=True, \n             link='logistic', quiet=True)\nwith open('..\/input\/train.csv') as f:\n    # skip header\n    f.readline()\n    start_time = datetime.now()\n    for i, line in enumerate(f):\n        # print when the next 1 mln examples is processed\n        if i % 1e5 == 0: print(\"{}\\t{} passed.\".format(i, datetime.now() - start_time))\n        # training Vowpal Wabbit with current example\n        vw.learn(to_vw(line, categorical_column_ids, numeric_column_ids, feature_names, train=True))","5f16ce71":"predictions = []\nwith open('..\/input\/test.csv') as f:\n    # skip header\n    f.readline()\n    start_time = datetime.now()\n    for i, line in enumerate(f):\n        # print when the next 1 mln examples is processed\n        if i % 1e5 == 0: print(\"{}\\t{} passed.\".format(i, datetime.now() - start_time))\n        # add Vowpal Wabbit prediction for the current example\n        predictions.append(vw.predict(to_vw(line, categorical_column_ids, numeric_column_ids, feature_names, train=False)))","91cafe3a":"subm_df = pd.read_csv('..\/input\/sample_submission.csv', index_col='MachineIdentifier')\nsubm_df['HasDetections'] = predictions\nsubm_df.to_csv('submission.csv', header=True)","12e25e52":"**Let's see how this function processes the first line from the test set.** ","f92b0fa1":"**Reading test data and making predictions on the fly.**","aff58293":"**What was skipped here and what can be improved**\n* train\/test split: local validation gave showed ROC AUC 0.70838 for 30% holdout set\n* hyperparam tuning: this was done with [vw-hyperopt](https:\/\/github.com\/VowpalWabbit\/vowpal_wabbit\/blob\/master\/utl\/vw-hyperopt.py), take a look at [this Hyperopt tutorial](https:\/\/www.kaggle.com\/ilialar\/hyperparameters-tunning-with-hyperopt)\n* feature engineering: explore other kernels, come up with good features, add them, and see your AUC rise! \n* blending: well, this solutions doesn;t result in a high AUC but try to blend this model predictions with some others","34a40033":"The following function converts a string to Vowpal Wabbit format. Take a look at [this tutorial](https:\/\/www.kaggle.com\/kashnitsky\/vowpal-wabbit-tutorial-blazingly-fast-learning) on VW to understand the format. ","4d70a0b6":"**We'll drop features with too many unique values, too many missing values, and too imbalanced value distribution. Motivated by [this EDA](https:\/\/www.kaggle.com\/artgor\/is-this-malware-eda-fe-and-lgb-updated) by Andrew Lukyanenko.**","3f8634ec":"**Reading training data and training Vowpal Wabbit on the fly.**","c52b39b3":"Thus we have 48 categorical features and 8 numeric ones.","99641b4e":"Let's figure out ids of numeric and categorical features that we'll used for prediction. Inspired by [this post](https:\/\/www.kaggle.com\/c\/microsoft-malware-prediction\/discussion\/75396) by Aditya Soni.","713bca08":"# <center> Vowpal Wabbit starter\n## <center> Training while reading \n    \n![](https:\/\/habrastorage.org\/webt\/je\/do\/29\/jedo293npvm0uytxuwx-4goid2e.jpeg)\n\n\nIn this kernel, we train a model just on the fly while reading data. If you are in doubt how it's even possible - take a look at [this tutorial](https:\/\/www.kaggle.com\/kashnitsky\/vowpal-wabbit-tutorial-blazingly-fast-learning) on Vowpal Wabbit. We'll skip basic EDA and feature engineering (for that you can pick any kernel, ex. [this one]([this EDA](https:\/\/www.kaggle.com\/artgor\/is-this-malware-eda-fe-and-lgb-updated)). We are not going to beat cool baselines with this model, but it's a nice and fast starter.  ","7b4bd7b4":"**Read feature names from the header of the test set.**","215fec45":"**Form the submission file**"}}