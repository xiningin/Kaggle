{"cell_type":{"4598bfa5":"code","5048a6f5":"code","0840d322":"code","aca75a7c":"code","1473033c":"markdown","86cb1628":"markdown","c3615d49":"markdown","840f885c":"markdown"},"source":{"4598bfa5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,KFold\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error,mean_squared_log_error\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder,RobustScaler,StandardScaler,Imputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LassoCV\nfrom scipy.stats import skew\nfrom mlxtend.regressor import StackingRegressor\nfrom sklearn.ensemble import BaggingRegressor\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the currentd directory are saved as output.","5048a6f5":"def rmsle_cv(model, x, y):\n    kf = KFold(10, shuffle=True, random_state=1).get_n_splits(x)\n    rmse = np.sqrt(-cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=kf, verbose=0))\n    return (rmse)\n\ndef get_cat_cols(df):\n    return  [col for col in df.columns if df[col].dtype == 'object']\n\ntrain_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')\n\ny = np.log1p(train_data.SalePrice)\n# test is meant for predictions and doesn't contain any price data. I need to provide it.\ncand_train_predictors = train_data.drop(['Id', 'SalePrice'], axis=1)\ncand_test_predictors = test_data.drop(['Id'], axis=1)\n\ncat_cols = get_cat_cols(cand_train_predictors)\n\ncand_train_predictors[cat_cols] = cand_train_predictors[cat_cols].fillna('NotAvailable')\ncand_test_predictors[cat_cols] = cand_test_predictors[cat_cols].fillna('NotAvailable')\n\nencoders = {}\n\nfor col in cat_cols:\n    encoders[col] = LabelEncoder()\n    val = cand_train_predictors[col].tolist()\n    val.extend(cand_test_predictors[col].tolist())\n    encoders[col].fit(val)\n    cand_train_predictors[col] = encoders[col].transform(cand_train_predictors[col])\n    cand_test_predictors[col] = encoders[col].transform(cand_test_predictors[col])\n\n    \ncorr_matrix = cand_train_predictors.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\ncols_to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\nprint('Highly correlated features(will be droped):',cols_to_drop)\n\ncand_train_predictors = cand_train_predictors.drop(cols_to_drop, axis=1)\ncand_test_predictors = cand_test_predictors.drop(cols_to_drop, axis=1)\n\nprint(cand_train_predictors.shape)\nprint(cand_test_predictors.shape)\n\ncand_train_predictors.fillna(cand_train_predictors.mean(), inplace=True)\ncand_test_predictors.fillna(cand_test_predictors.mean(), inplace=True)\n\nskewed_feats = cand_train_predictors.apply(lambda x: skew(x))  # compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nprint('Skewed features:', skewed_feats)\n\ncand_train_predictors[skewed_feats] = np.log1p(cand_train_predictors[skewed_feats])\ncand_test_predictors[skewed_feats] = np.log1p(cand_test_predictors[skewed_feats])\n\ntrain_set, test_set = cand_train_predictors.align(cand_test_predictors,join='left', axis=1)","0840d322":"gdr = BaggingRegressor(base_estimator=GradientBoostingRegressor(n_estimators=1000))\ngdr_model = gdr\nprint(gdr_model)\ngdr_model.fit(train_set, y)\n\nprint('score gradient boost:', gdr_model.score(train_set, y))\n\ntrain_pred = gdr_model.predict(train_set)\n\nprint('rmse from log: ', np.sqrt(mean_squared_error(y, train_pred)))\nprint('mse from log: ', mean_squared_error(y, train_pred))\nprint('rmsle: ', np.sqrt(mean_squared_log_error(y, train_pred)))\nprint('rmse: ', np.sqrt(mean_squared_error(train_data.SalePrice, np.expm1(train_pred))))\nprint('mse: ', mean_squared_error(train_data.SalePrice, np.expm1(train_pred)))\nprint('mae: ', mean_absolute_error(train_data.SalePrice, np.expm1(train_pred)))\n\n","aca75a7c":"test_pred = gdr_model.predict(test_set)\npredicted_prices = np.expm1(test_pred)\nprint(predicted_prices[:5])\n\n# print(len(predicted_prices))\n# print(len(test_data.Id))\n\nmy_submission = pd.DataFrame({'Id': test_data.Id, 'SalePrice': predicted_prices})\nmy_submission.Id = my_submission.Id.astype(int)\n# print(my_submission.Id)\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","1473033c":"# Predicting and submitting\n\nNow it's time to predict from test.","86cb1628":"# Loading data\n\nLoading data from train and test file. Test file provides only input data and I'll predict the prices via using a model.","c3615d49":"# Links\n\nI got inspired by these kernels:\n\n* https:\/\/www.kaggle.com\/apapiu\/regularized-linear-models\n* https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\n* https:\/\/www.kaggle.com\/learn\/machine-learning\n\nFor stacking I use :\nhttps:\/\/rasbt.github.io\/mlxtend\/user_guide\/regressor\/StackingRegressor\/\n\nBagging:\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.BaggingRegressor.html\n\n","840f885c":"# Model\n"}}