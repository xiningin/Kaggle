{"cell_type":{"a1b7ed25":"code","f92cf735":"code","5f5b1d0c":"code","70801b45":"code","4d8cd1ff":"code","f1c84de9":"code","0115d493":"code","1f9f17f5":"code","0b311429":"code","ed3734fa":"code","1e53927e":"code","aee018dd":"code","ac3e2613":"code","7ba509c7":"code","c1777805":"markdown","e47a9cef":"markdown","f5f86088":"markdown","08e37b25":"markdown","efeb6544":"markdown","07ab88f8":"markdown","e2819c04":"markdown","17c44299":"markdown","1e54a12b":"markdown","9528d947":"markdown","e2c9bd57":"markdown","7473ed3f":"markdown"},"source":{"a1b7ed25":"!pip install --quiet tensorflow-datasets","f92cf735":"import os, time\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom kaggle_datasets import KaggleDatasets\nimport visiontools","5f5b1d0c":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","70801b45":"if tpu:\n    DATA_DIR = KaggleDatasets().get_gcs_path('cars196')\nelse:\n    DATA_DIR = '\/kaggle\/input\/cars196'\n\nds, ds_info = tfds.load('cars196',\n                        split='train',\n                        with_info=True,\n                        download=False,\n                        data_dir=DATA_DIR)\n\nfig = tfds.show_examples(ds_info=ds_info, ds=ds)","4d8cd1ff":"from visiontools import make_preprocessor, make_augmentor\n\npreprocessor = make_preprocessor(size=[192, 192])\n\naugmentor = make_augmentor(hue_delta=0.25,\n                           saturation_range=[0.1, 3.0],\n                           horizontal_flip=True)\n\nrows = 4; cols = 4\nds = tfds.load('cars196', split='train',\n               download=False, data_dir=DATA_DIR,\n               as_supervised=True)\nexamples = list(tfds.as_numpy(ds.take(rows * cols)))\n\nplt.figure(figsize=(15, (15 * rows) \/\/ cols))\nfor i, (image, label) in enumerate(examples):\n    image, _ = preprocessor(image, label)\n    image, _ = augmentor(image, label)\n    plt.subplot(rows, cols, i+1)\n    plt.axis('off')\n    plt.imshow(image)\nplt.show()","f1c84de9":"(ds_train, ds_validation), ds_info = tfds.load('cars196',\n                                               download=False,\n                                               data_dir=DATA_DIR,\n                                               split=['train', 'test'],\n                                               as_supervised=True,\n                                               shuffle_files=True,\n                                               with_info=True)","0115d493":"NUM_LABELS = 196\nNUM_TRAINING_IMAGES = ds_info.splits['train'].num_examples\nSHUFFLE_BUFFER =  NUM_TRAINING_IMAGES \/\/ 4\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nSIZE = [512, 512]\nAUTO = tf.data.experimental.AUTOTUNE\n\npreprocess = make_preprocessor(size=SIZE)\naugment = make_augmentor(horizontal_flip=True,\n                        hue_delta=0.2,\n                        saturation_range=[0, 2],\n                        contrast_range=[0.5, 2])\n\n# Training Pipeline\nds_train = (\n    ds_train.map(preprocess, AUTO) # preprocess before caching\n    .cache() # cache before augmenting\n    .repeat() # why is this needed?\n    .shuffle(SHUFFLE_BUFFER) # shuffle before batching\n    .batch(BATCH_SIZE) # batch before augmenting\n    .map(augment, AUTO)\n    .prefetch(AUTO) # prefetch last\n)\n\n# Validation Pipeline\n# since the training set is shuffled, we can cache the batches for the\n# validation set\nds_validation = (\n    ds_validation.map(preprocess, AUTO)\n    .batch(BATCH_SIZE)\n    .cache() \n    .prefetch(AUTO)\n)\n\n# TODO - Tune and profile these. Customize jpeg decoding and bbox\n# crop\/resize.","1f9f17f5":"with strategy.scope():\n    pretrained_model = tf.keras.applications.Xception(weights='imagenet',\n                                                      include_top=False,\n                                                      input_shape=[*SIZE, 3])\n    pretrained_model.trainable = True\n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(NUM_LABELS,\n                              activation='softmax',\n                              dtype=tf.float32),\n    ])\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\n\nmodel.summary()","0b311429":"from visiontools import exponential_lr\n\n# Fine tuning is sensitive to learning rate\nlr_callback = (\n    tf.keras\n    .callbacks\n    .LearningRateScheduler(lambda epoch: exponential_lr(epoch),\n                           verbose=True)\n)\n\nes_callback = (\n    tf.keras\n    .callbacks\n    .EarlyStopping(monitor='val_loss',\n                   min_delta=1e-4,\n                   patience=3,\n                   restore_best_weights=True)\n)","ed3734fa":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE\nEPOCHS = 80\n\nstart_time = time.time()\nhistory = model.fit(ds_train,\n                    validation_data=ds_validation,\n                    epochs=EPOCHS,\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    callbacks=[lr_callback,\n                               es_callback])\nfinal_accuracy = history.history[\"val_sparse_categorical_accuracy\"][-5:]\nprint(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))\nprint (\"TRAINING TIME: \", time.time() - start_time, \" sec\")\nmodel.save('\/kaggle\/working\/densenet.h5')","1e53927e":"# TODO - training visualizations","aee018dd":"# TODO - predictions","ac3e2613":"# TODO - confusion matrix","7ba509c7":"# TODO - examine misclassified images","c1777805":"# Examine the Model's Predictions","e47a9cef":"Let's take a look at what these functions can do. Feel free to change the arguments to the augmentation constructor to get different kinds of augmentations.","f5f86088":"Data augmentation, which includes a random component, should be done separately from the preprocessing. The procedure, however, is the same.","08e37b25":"# Prepare the Dataset","efeb6544":"# Setup\n\nWe'll use the Tensorflow library `tensorflow-datasets`. It offers a convenient interface to the TFRecords format ingestible by TPUs.","07ab88f8":"Now we'll load the data. To train with TPUs, we need to put the data in a GCS bucket. Having dones that, we'll point the `tfds` data loader at it and take a look at our data.","e2819c04":"# Prepare Data Pipelines for Training\n\nTo use the data to train a model, we'll load it in \"supervised\" format. For each data split, this will create a generator of tuples `(image, label)` that the model will consume.","17c44299":"# Define Preprocessing and Augmentation\n\nWe need to do some preprocessing to prepare the data for training. The `make_preprocessor` function will construct a preprocessing function that we will map over the dataset as part of the data pipeline.","1e54a12b":"# Define the Model\n\nNow let's try a model.","9528d947":"# Define Callbacks","e2c9bd57":"# Train the Model\n\nAnd now we can train the model!","7473ed3f":"Now let's create pipelines for the training and validation datasets."}}