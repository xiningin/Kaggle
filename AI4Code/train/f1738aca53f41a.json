{"cell_type":{"4148fa0b":"code","c4c4a3a7":"code","589923a8":"code","7a6ae846":"code","fe3423bd":"code","a4a9d7d0":"code","fc8f99f8":"code","c58ddbd9":"code","532889bb":"code","b0e13311":"code","e1cf9938":"code","314c833f":"code","fce9d084":"code","16c87251":"code","eeb1d17b":"code","0613910e":"markdown","6fb70a8e":"markdown","dfdf2d37":"markdown","7193911c":"markdown","1828e108":"markdown","ffa38758":"markdown","cf327cd9":"markdown"},"source":{"4148fa0b":"# Importing libraries\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score,confusion_matrix, recall_score, precision_score, classification_report\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\n","c4c4a3a7":"# Load The Dataset\ndf = pd.read_csv(\"\/kaggle\/input\/heart-failure-prediction\/heart.csv\")\ndf.head() # Display first 5 lines","589923a8":"df.shape\n# Our data set contain 918 pation with 12 seperate dimentions (columns)","7a6ae846":"# The folowig dispaly information about the dimentinos (type)\ndf.info()\n","fe3423bd":"# Let have few statistique about our data set to have a global overview\ndf.describe().T\n# note: std mean Standard deviation of the observations. It is a summary measure of the differences of each observation from the mean","a4a9d7d0":"# To better judge the quality of our data set let count how many mission value it contains\ndf.isnull().sum()","fc8f99f8":"# Let's compaire how many patient has Heart Disease with the ones who donesn't\nsns.countplot(x = \"HeartDisease\", data = df)","c58ddbd9":"# In order to display some graph for statistic sake we will seperate the dimention into numeric (numeric_feature) and string (categorical_feature)\n# numpy create a reference for string in the array unstead of putting the full string because it do not have fixed size\ncategorical_feature = df.columns[df.dtypes==object].tolist()\nnumeric_feature = [i for i in df.columns.tolist() if i not in categorical_feature and i != 'HeartDisease']\nprint(numeric_feature)","532889bb":"# We will use the dencity plot to observe the distribution of data for each numeric dimention\ndf[numeric_feature].plot(kind='density', subplots=True, layout=(2,3), sharex=False, figsize= (16,8))\nplt.show()","b0e13311":"# For the categorical_feature (string) we will use the bar plot\nfor i in range(len(categorical_feature)):\n    df[categorical_feature[i]].value_counts().plot(kind='bar')\n    plt.xticks(rotation='vertical')\n    plt.ylabel(categorical_feature[i])\n    plt.show()\n","e1cf9938":"le = LabelEncoder() \ndf[categorical_feature] = df[categorical_feature].apply(lambda col: le.fit_transform(col)) \ndf.head(5)","314c833f":"# Heatmap of the correlation matrix between the numerica attributes and the target, HeartDisease.\n# We can observe that the stronger correlations with HeartDisease are MaxHR(negatively) and Oldpeak(positively). ExerciseAngina((positively)) ST_Slope(negatively)\nmask = np.triu(np.ones_like(df.corr()))\nfig, ax = plt.subplots(figsize=(20,20),dpi=80, facecolor='w', edgecolor='k')\nsns.heatmap(df.corr(), mask= mask, cmap=\"RdYlGn\", vmax=.4, annot = True, center = 0,annot_kws={\"fontsize\":15})","fce9d084":"x = df.drop(\"HeartDisease\", axis = 1)\ny = df['HeartDisease']","16c87251":"# Let's split the data into train data and test data\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state =100 ,stratify=y, test_size = 0.3)\nprint(y_train.value_counts())","eeb1d17b":"RF = RandomForestClassifier(criterion='entropy', min_samples_leaf=2, n_estimators=25,\n                       random_state=0)\n\nRF.fit(x_train, y_train)\n\ny_test_pred_RF = RF.predict(x_test)\ny_train_pred_RF = RF.predict(x_train)\n\ntest_acc_RF = accuracy_score(y_test, y_test_pred_RF)\ntrain_acc_RF = accuracy_score(y_train, y_train_pred_RF)\nscores_RF= cross_val_score(RF, x_train , y_train , cv = 10, scoring = 'accuracy' )\n\nprecision_score_RF = precision_score(y_test, y_test_pred_RF)\nrecall_score_RF = recall_score(y_test, y_test_pred_RF)\nf1_score_RF = f1_score(y_test, y_test_pred_RF)\nconf_RF = confusion_matrix(y_test, y_test_pred_RF)\n\n\nprint(\"Tain set Accuracy: \", train_acc_RF)\nprint(\"Test set Accuracy: \", test_acc_RF)\nprint(\"cv:  %s\\n\"% scores_RF.mean())\nprint(\"************************************************\")\nprint(\"precision_score: \", precision_score_RF)\nprint(\"recall_score: \", recall_score_RF)\nprint(\"f1_score: \", f1_score_RF)\nprint(\"************************************************\")\nprint(\"\\nReport:\\n%s\\n\"%classification_report(y_test, y_test_pred_RF))\nprint(\"\\nConfision Tree:\\n%s\\n\"%conf_RF)","0613910e":"### Convert categorical data to numeric","6fb70a8e":"Thankd for your attensions. \nBy Ahmed. Benyahia. Oussema Jaziri,  Hana Derwish ","dfdf2d37":"For our model, we are going to work with random forest algo.\n\nThe random forest classifier is a model that fits a number of decision tree sorting into several sub-samples, countered by the number of estimators, of the data set and uses the mean to improve prediction accuracy and to control over-fitting. . The number of estimators in our case is a sequence of numbers to see which gives the best result.","7193911c":"# Exploring Data","1828e108":"# Preprocessing","ffa38758":"# Training the model","cf327cd9":"# Hear Failure Prediction ML Model With Random Forest Algorithem (Groupe 6)\n### By Ahmed.Benyahia, Oussema. Jaziri, Hana. Derwish "}}