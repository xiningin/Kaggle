{"cell_type":{"e7f2b358":"code","0937af23":"code","589a4458":"code","49dff133":"code","44ffc496":"code","b07d02e4":"code","bebd2266":"code","78ee9f2b":"code","ee7323f3":"code","298b5166":"code","90c4a5fa":"code","0f197770":"code","6f1d5957":"code","8557d090":"code","c3f7d764":"code","d105faf5":"code","481b6384":"markdown","7e2cc201":"markdown","713690b8":"markdown","d52dc0d3":"markdown","2932e7fc":"markdown","261d3cc7":"markdown","2cc8164e":"markdown","aa9664f8":"markdown","9e6e10c5":"markdown","a5e0f356":"markdown","3cc01444":"markdown","de84779d":"markdown","bbe6bca6":"markdown","590e89c7":"markdown","4a536e7c":"markdown","79733ac9":"markdown","2c241c66":"markdown","bacfe52e":"markdown"},"source":{"e7f2b358":"import pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.preprocessing import StandardScaler\n\ndata_dir = '..\/input\/creditcardfraud'\nmodel_dir = '..\/input\/credit-card-fraud-detection-models'\n\n# Load the data and define its feature columns.\ntxns = pd.read_csv(os.path.join(data_dir, 'creditcard.csv'))\nfeat_cols = [i for i in txns.columns if i[0] == 'V']\nfeat_cols.extend(['Amount', 'Time'])\nprint('The feature columns are: {}'.format(feat_cols))\n\n# Normalize the features.\ntxns[feat_cols] = StandardScaler().fit_transform(txns[feat_cols])\n\n# Build and count the number of records in Fraud and Non-Fraud classes.\nnon_frauds = txns[txns.Class == 0]\nfrauds = txns[txns.Class == 1]\nprint('Total of {} frauds and {} non-frauds'.format(len(frauds), len(non_frauds)))\n\n# For asynchronous training we can use multiple processes, but then the results vary depending\n# on the order of completion. \npool_size = 16","0937af23":"from sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Draw random samples for visualization.\nnon_fraud_samples = 15 * len(frauds)\nvis_subset = pd.concat([\n    frauds, non_frauds.sample(n=non_fraud_samples, random_state=361932)],axis=0)[feat_cols]\n\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\ntsne_results = tsne.fit_transform(vis_subset)\ntsne_frame = pd.DataFrame({'X': tsne_results[:, 0], 'Y': tsne_results[:, 1]})\ntsne_frame['Fraud'] = [ int(x < len(frauds)) for x in range(0, len(tsne_results)) ]\n\nplt.figure(figsize=(16,10))\npal = [(0,1,0), (1,0,0)]\nsns.scatterplot(\n    data=tsne_frame,\n    palette=pal,\n    x = 'X', y = 'Y',hue='Fraud',\n    style='Fraud')","589a4458":"import torch\n\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset\n\nclass CreditCardDataset(Dataset):\n    def __init__(self, name, X, y):\n        assert(len(X) == len(y))\n        self.name = name\n        if isinstance(X, pd.DataFrame):    \n            self.X = torch.tensor(X.values, dtype=torch.float32)\n        else:\n            self.X = X.clone()\n        if isinstance(y, pd.Series):\n            self.y = torch.tensor(y.values, dtype=torch.float32)\n        else:\n            self.y = y.clone()\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return (self.X[idx], self.y[idx])\n    \n    def __str__(self):\n        return 'CreditCardDataset \"{}\" has {} items and {} frauds'.format(self.name, len(self.y), int(self.y.sum()))\n    \nX, y = txns[feat_cols], txns['Class']\n# Reserve 30% for dev and training\nX_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3, random_state=3161)\n# Split the reserved 30% in half for 15% dev and 15% test\nX_dev, X_test, y_dev, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=1494)\n\ntrain_set = CreditCardDataset('train', X_train, y_train)\ndev_set = CreditCardDataset('dev', X_dev, y_dev)\ntest_set = CreditCardDataset('test', X_test, y_test)\nprint(train_set)\nprint(dev_set)\nprint(test_set)","49dff133":"from os import path\n\nfrom torch.multiprocessing import Pool\n\ndef init_weights(m):\n    if type(m) == torch.nn.Linear:\n        torch.nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.1)\n\ndef train_model_epoch(model, loader, optimizer):\n    loss_fn = torch.nn.BCELoss()\n    total_loss = 0\n    for i, data in enumerate(loader, 0):\n        X, y = data\n        y_pred = model(X)\n        loss = loss_fn(y_pred.reshape(-1), y)\n        total_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    return total_loss\n        \ndef train_model(model, loader, optimizer, state_name, max_epochs=50, checkpoints=5, silent=False):\n    state_file = '{}\/{}.pt'.format(model_dir, state_name)\n    if path.exists(state_file):\n        model.load_state_dict(torch.load(state_file))\n        return\n    # torch.manual_seed(3621099)\n    model.train()\n    model.apply(init_weights)\n    checks, check_at, total_loss = 0, 0, 0\n    pool = Pool(processes=pool_size)\n    pool_args = [(model, loader, optimizer) for _ in range(max_epochs)]\n    for epoch, result in enumerate(pool.starmap_async(train_model_epoch, pool_args).get()):\n        total_loss = result\n        if not silent and epoch >= check_at:\n            print('At epoch {}, loss={}'.format(epoch, total_loss))\n            checks += 1\n            check_at = int(max_epochs * checks \/ checkpoints)    \n    if not silent:\n        print('Final loss={}'.format(total_loss))\n    pool.close()\n    torch.save(model.state_dict(), state_file)\n    return","44ffc496":"import matplotlib.pyplot as plt\n\nfrom sklearn.metrics import average_precision_score, precision_recall_curve\n    \n%matplotlib inline\n\ndef eval_model(model, name, eval_set, batch_size, silent=False):\n    model.eval()\n    full_loader = torch.utils.data.DataLoader(eval_set, batch_size)\n    loss_fn = torch.nn.BCELoss()\n    total_loss = 0\n    device = next(model.parameters()).device\n    y_data_all, y_pred_all = None, None\n    for i, data in enumerate(full_loader, 0):\n        X, y = data\n        y_pred = model(X)\n        if i == 0:\n            y_data_all = y\n            y_pred_all = y_pred\n        else:\n            y_data_all = torch.cat((y_data_all, y), 0)\n            y_pred_all = torch.cat((y_pred_all, y_pred), 0)\n        total_loss += loss_fn(y_pred.reshape(-1), y)\n    y_data_all = y_data_all.detach().numpy()\n    y_pred_all = y_pred_all.detach().numpy()\n    avg_precision = average_precision_score(y_data_all, y_pred_all)\n    if not silent:\n        print('y_data_all sum={}'.format(y_data_all.sum()))\n        print('y_pred_all sum={}'.format(y_pred_all.sum()))\n        precision, recall, _ = precision_recall_curve(y_data_all, y_pred_all)\n        plt.step(recall, precision, alpha=0.3, color='b')\n        plt.fill_between(recall, precision, alpha=0.3, color='b')\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.title('{} Precision-Recall, AP={:0.3f}'.format(name, avg_precision))\n        plt.show()\n        print('Loss of {}={}'.format(name, total_loss.item()))\n    return avg_precision","b07d02e4":"batch_size, d_in, d_out = 300, len(feat_cols), 1\nlogistic_model = torch.nn.Sequential(\n    torch.nn.Linear(d_in, d_out),\n    torch.nn.Sigmoid(),\n)\n\nif __name__ == '__main__':\n    learning_rate = 0.002\n    loader = torch.utils.data.DataLoader(train_set, batch_size)\n    optimizer = torch.optim.Adam(logistic_model.parameters(), lr=learning_rate, weight_decay=0)\n    train_model(model=logistic_model, loader=loader, optimizer=optimizer, state_name='logistic-0', max_epochs=200)\n    eval_model(model=logistic_model, name='Logistic model (WD=0)', eval_set=dev_set, batch_size=batch_size)","bebd2266":"import numpy as np\nfrom multiprocessing import Pool, cpu_count\n\ndef eval_model_for_datasets(model, train_set, eval_sets, batch_size, learning_rate, weight_decay, model_name,\n                            max_epochs=200):\n    loader = torch.utils.data.DataLoader(train_set, batch_size)\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    state_name = '{}-{:0.6f}'.format(model_name, weight_decay)\n    train_model(model=model, loader=loader, optimizer=optimizer, state_name=state_name, \n                max_epochs=max_epochs, silent=True)\n    avg_precisions = []\n    for i, eval_set in enumerate(eval_sets):\n        avg_precisions.append(eval_model(model=model,\n                                         name='Dataset #{} (WD={:0.6f})'.format(i + 1, weight_decay),\n                                         eval_set=eval_set, batch_size=batch_size, silent=True))\n    return tuple([float(weight_decay)]) + tuple(avg_precisions)\n\ndef eval_model_over_weight_decays(model, train_set, eval_sets,\n                                  batch_size, learning, weight_decays, model_name, max_epochs=200, pool_size=32):\n    wd_precisions = dict()\n    for wd in weight_decays:\n        result = eval_model_for_datasets(model=logistic_model, train_set=train_set,\n                                         eval_sets=eval_sets, batch_size=batch_size,\n                                         learning_rate=learning_rate, weight_decay=wd,\n                                         model_name=model_name, max_epochs=max_epochs)\n        wd_precisions[result[0]] = result[1:]\n\n    wd_and_precisions_len = 1 + len(eval_sets)\n    wd_and_precisions = [list() for _ in range(wd_and_precisions_len)]\n    for wd in sorted(wd_precisions.keys()):\n        wl = list()\n        wd_and_precisions[0].append(wd)\n        for i, prec in enumerate(wd_precisions[wd]):\n            wd_and_precisions[i + 1].append(prec)\n    plt.xlabel('Weight Decay')\n    plt.ylabel('Average Precision')\n    for i, dataset in enumerate(eval_sets):\n        plt.plot(wd_and_precisions[0], wd_and_precisions[i+1], color='C{}'.format(i), \n                 label='{} set'.format(dataset.name))\n    plt.legend(loc='best')\n    plt.show()","78ee9f2b":"import numpy as np\n\n%matplotlib inline\n\nif __name__ == '__main__':\n    batch_size, learning_rate = 300, 0.002\n    eval_model_over_weight_decays(logistic_model, train_set, [train_set, dev_set], batch_size, learning_rate,\n                                  np.geomspace(0.00001, 0.8, 20), 'logistic')","ee7323f3":"batch_size, d_in, d_h1, d_h2, d_out = 60, len(feat_cols), len(feat_cols), len(feat_cols), 1\nnn_model = torch.nn.Sequential(\n    torch.nn.Linear(d_in, d_h1),\n    torch.nn.ReLU(),\n    torch.nn.Linear(d_h1, d_h2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(d_h2, d_out),  \n    torch.nn.Sigmoid(),\n)\n\nif __name__ == '__main__':\n    learning_rate = 0.002   \n    loader = torch.utils.data.DataLoader(train_set, batch_size)\n    optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate, weight_decay=0)\n    train_model(model=nn_model, loader=loader, optimizer=optimizer, state_name='nn-0', max_epochs=200)\n    eval_model(model=nn_model, name='3 Layer model (WD=0)', eval_set=dev_set, batch_size=batch_size)\n   ","298b5166":"import numpy as np\n\n%matplotlib inline\n\nif __name__ == '__main__':\n    batch_size, learning_rate = 300, 0.002\n    eval_model_over_weight_decays(nn_model, train_set, [train_set, dev_set], batch_size, learning_rate,\n                                  np.geomspace(0.00001, 0.8, 20), 'nn')","90c4a5fa":"import lzma\nimport pickle\nimport resource\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import precision_recall_fscore_support\n\ndef model_file(model_name):\n    return '{}\/{}.lzma.pkl'.format(model_dir, model_name)\n    \ndef load_model(model_name):\n    file = model_file(model_name)\n    if not path.exists(model_file(model_name)):\n        return None\n    with lzma.open(file, 'rb') as file:\n        return pickle.load(file)\n        \ndef save_model(model_name, model):\n    with lzma.open(model_file(model_name), 'wb') as fh:\n        pickle.dump(model, fh)\n\ndef eval_pred(name, y_data, y_pred, fscore=True):\n    precision, recall, _ = precision_recall_curve(y_data, y_pred) \n    avg_precision = average_precision_score(y_data, y_pred)\n    plt.step(recall, precision, alpha=0.3, color='b')\n    plt.fill_between(recall, precision, alpha=0.3, color='b')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('{}, AP={:0.3f}, '.format(name, avg_precision))\n    plt.show()\n    if fscore:\n        precision, recall, f1_score, _ = precision_recall_fscore_support(y_data, y_pred, beta=1.0, average='binary')\n        print('{} Precision={:0.4f}, Recall={:0.4f}, F1={:0.4f}'.format(name, precision, recall, f1_score)) \n    \ndef eval_knn(model, name, eval_set):\n    y_pred = model.predict(eval_set.X)\n    eval_pred(name, eval_set.y, y_pred)","0f197770":"for n in [1,3,4,5,10]:\n    model_name = 'knn-{}'.format(n)\n    knn = load_model(model_name)\n    if not knn:\n        knn = KNeighborsClassifier(n_neighbors=n, algorithm='kd_tree', leaf_size=50)\n        # On a machine with low memory I found I needed to train on a subset of the full data.\n        # knn.fit(train_set.X[0:5000, :], train_set.y[0:5000])\n        knn.fit(train_set.X, train_set.y)\n        save_model(model_name, knn)\n    eval_knn(knn, 'k-NN dev (N={})'.format(n), dev_set)","6f1d5957":"\n\ndef cluster_probs(clusterer):\n    p, q, cluster_prob = dict(), dict(), dict()\n    for i, k in enumerate(clusterer.labels_):\n        if k not in p:\n            p[k] = 0\n            q[k] = 0\n        q[k] += 1\n        if train_set.y[i] == 1:\n            p[k] += 1\n    for k in p:\n        cluster_prob[k] = float(p[k] \/ q[k])\n    return cluster_prob\n\ndef eval_hdbscan(name, clusterer, eval_set):\n    test_labels, _ = hdbscan.approximate_predict(clusterer, eval_set.X)\n    probs = cluster_probs(clusterer)\n    y_pred = list()\n    ks = 0\n    for label in test_labels:\n        kp = probs[label]\n        ks += kp\n        y_pred.append(kp)\n    eval_pred(name, eval_set.y, y_pred, fscore=False)","8557d090":"!pip install hdbscan\nimport hdbscan\n\nclusterer = load_model('hdbscan-2-1')\nif not clusterer:\n    clusterer = hdbscan.HDBSCAN(min_cluster_size=2, min_samples=1, prediction_data=True)\n    clusterer.fit_predict(train_set.X)\n    save_model('hdbscan-2-1', clusterer)\neval_hdbscan('HDBSCAN min_cluster_size=2, min_samples=1', clusterer, dev_set)","c3f7d764":"train_model(model=logistic_model, loader=None, optimizer=None, state_name='logistic-0')\neval_model(model=logistic_model, name='Logistic model (WD=0)', eval_set=test_set, batch_size=batch_size)\n    \ntrain_model(model=nn_model, loader=None, optimizer=None, state_name='nn-0')\neval_model(model=nn_model, name='2 Hidden Layer model (WD=0)', eval_set=test_set, batch_size=batch_size)\n\nknn = load_model('knn-4')\neval_knn(knn, 'k-NN dev (N=4)', test_set)","d105faf5":"from torch.utils.data import Sampler\nfrom itertools import chain\n\nimport random\n\nclass FraudSampler(Sampler):\n    def __init__(self, cc_dataset, batch_size=50, frauds=20):\n        self.fraud_count, self.non_fraud_count = frauds, batch_size - frauds\n        self.non_fraud_idx = (cc_dataset.y == 0).nonzero().squeeze().tolist()\n        self.fraud_idx = (cc_dataset.y > 0).nonzero().squeeze().tolist()\n        self.block_size = (self.fraud_count + self.non_fraud_count)\n        self.blocks = int(len(self.non_fraud_idx) \/ self.non_fraud_count)\n\n    def __iter__(self):\n        iters = list()\n        for i in range(self.blocks):\n            block = list()\n            block.extend(self.non_fraud_idx[i * self.non_fraud_count: (i+1) * self.non_fraud_count])\n            block.extend(random.sample(self.fraud_idx, self.fraud_count))\n            iters.append(iter(block))\n        return chain(*iters)\n            \n    def __len__(self):\n        return self.blocks * self.block_size\n    \n    \nbatch_size = 5000\nfraud_sampler = FraudSampler(dev_set, batch_size=batch_size, frauds=60)\nloader = torch.utils.data.DataLoader(dev_set, batch_size, sampler=fraud_sampler)\nfor i, data in enumerate(loader, 0):\n    X, y = data\n    print('Batch {} has {} examples with {} frauds'.format(i, len(y), int(y.sum())))","481b6384":"<a name=\"fc-two-hidden\"><\/a>\n## Fully-Connected Network With Two Hidden Layers \n\nWe'll explore a more complicated network structure, while being sure to use regularization to prevent overfitting.\n\n","7e2cc201":"<a name=\"conclusion\"><\/a>\n## Conclusion\n\nBased on the performance against the dev dataset, the **3-Layer NN wins** by a narrow margin.","713690b8":"<a name=\"loading\"><\/a>\n## Loading the Data\n1. Load the data from a CSV\n2. Define the feature columns\n3. Reset the feature values to a normal distribution.\n4. Count the number of examples in each class.","d52dc0d3":"This result shows there's definitely a zone where fraud examples are concentrated, but there are also false negatives and false positives mixed in.\n\nWe'll try a few different approaches, but we may find the classes difficult to separate.","2932e7fc":"Having chosen a technique, we can examine the test dataset performance, and see that again 3-Layer NN again wins again, though again by a narrow margin.\n\n| Method                | Params           | Dev AUPRC | Test AUPRC |\n| --------------------- | ---------------- | --------- | ---------- |\n| *3-Layer NN*          | weight_decay = 0 | 0.783     | 0.778      |\n| *Logistic Regression* | weight_decay = 0 | 0.768     | 0.757      |\n| *k-NN*                | N=4              | 0.748     | 0.740      |\n| *HDBSCAN*             |                  | 0.384     | skipped    |","261d3cc7":"<a name=\"logistic-wd\"><\/a>\n### Weight Decay Search\n\nThis looks like a reasonable result, an average precision of close to 0.80.\n\nIt's possible, though, that we're overfitting, and can do better with a simpler model.\n\nI ran a search over various weight decays to find one that performed reasonably well.\n\n`np.geomspace(0.0001, 0.3, 20)` gives 20 values of weight decay spaced between 0.0001 and 0.3, with the ratio between consecutive values being equal.  \n","2cc8164e":"<a name=\"hdbscan\"><\/a>\n## HDBSCAN\n\nTo use hdbscan you need to install the package.\n\nIn Anaconda: `conda install hdbscan`.\nOn Kaggle: Run `!pip install hdbscan`, after enabling Internet.\n\nI was interested in trying HDBSCAN as an alternative method for clustering.  I wasn't able to find any built-in methods for binary classification in HDBSCAN, so I used the following approach:\n\n1. Assign points to clusters.\n2. The cluster's probability of fraud is equal to the proportion of fraud cases in the cluster.\n\nThe results overall were disappointing.\n\nWhen using HDBSCAN, I noticed that roughly half the points were not assigned to any cluster.\n\nI tried varying the `min_cluster_size` and `min_samples` because they seemed to be the parameters that most affected cluster assignment.\n\n| min_cluster_size | min_samples | unassigned | labels |\n| ---------------- | ----------- | ---------- | ------ |\n| 2                | 1           | 32%        | 46655  |\n| 5                | 1           | 43%        | 8931   |\n| 8                | 4           | 54%        | 2337   |\n| 10               | 1           | 45%        | 3285   |\n| 15               | 4           | 52%        | 1389   |\n| 20               | 1           | 45%        | 1587   |\n| 30               | 1           | 44%        | 1090   |\n| 30               | 4           | 51%        | 821    |\n| 30               | 10          | 59%        | 558    |\n| 40               | 1           | 43%        | 828    |\n| 60               | 1           | 43%        | 578    |\n| 60               | 15          | 60%        | 291    |\n| 60               | 30          | 64%        | 203    |\n| 250              | 1           | 40%        | 157    |\n| 500              | 1           | 33%        | 76     |\n| 1000             | 1           | 29%        | 41     |\n\nSummarizing these results:\n*  Increasing `min_cluster_size` reduces the total number of `labels` and `% unassigned`, but we probably don't want a high `min_cluster_size` because we have so few fraud examples.\n*  Increasing `min_samples` seems to increase the `% unassigned` strongly, while weakly decreasing the number of `labels`.","aa9664f8":"<a name=\"appendix-balanced\"><\/a>\n## Appendix: Balanced Sampling\n\nEarly in the development of this notebook I made some coding mistakes.  The models I trained tended to predict `y = 0` in all cases.\n\nI wondered if this was a side-effect of having so few fraud examples.\n\nI thought that balancing the number of frauds and non-frauds in my mini-batches might help.  \n\nI'm leaving this in case anyone else is curious of one way to do it in PyTorch.\n\nThis Sampler creates blocks until the non-frauds are exhausted, and it adds a random shuffle of fraud cases in each block.","9e6e10c5":"<a name=\"tsne\"><\/a>\n## Visualizing with t-SNE\nNow we will use T-distributed Stochastic Neighbor Embedding \n([t-SNE](https:\/\/en.wikipedia.org\/wiki\/T-distributed_stochastic_neighbor_embedding)) to show this high-dimensional data in a 2D plot.\n\nThe idea of t-SNE is to visualize our 30-dimensional data points in 2-D.  \n\nIf there is strong visual separation, it implies that we could get good results with [k-Nearest Neighbors](https:\/\/en.wikipedia.org\/wiki\/K-nearest_neighbors_algorithm) (KNN) or simple linear or logistic models.\n\nThe converse is not necessarily true, though; a data set with no obvious difference between the classes in t-SNE could still be classified accurately by a model.","a5e0f356":"<a name=\"knn\"><\/a>\n## K-Nearest Neighbor Classifier\n\nUnfortunately, training k-NN on the full training set takes more memory than I've got.  I could try using PCA, etc. to reduce the dimensionalit.\n\nHowever, the 3000-element training set gives decent results, so I decided to include them here.","3cc01444":"<a name=\"split\"><\/a>\n## Creating Training, Dev and Test Datasets\nFirst, define a pytorch Dataset build from pandas DataFrames, and then split our data into training, dev and test sets.\n\nThe split train\/dev\/test split is 70\/15\/15.  \n\n*  training_set: 70% of the data is used to train the model.\n*  dev_set: 15% of the data is used to explore and evaluate different approaches.\n*  test_set: 15% of the data is reserved for final performance evaluation.","de84779d":"<a name=\"eval\"><\/a>\n## Evaluating Model Performance\nAs suggested in the dataset description, we'll use Area Under the Precision-Recall Curve (AUPRC) as the metric.\n\nOur evaluation function will display the Precision-Recall Curve.  We will also display the average precision in the graph title using <code>AP=<i>value<\/i><\/code>.\n\nThe average precision is equal to the AUPRC.","bbe6bca6":"<a name=\"train\"><\/a>\n## Training a Model\nHere we provide a generic function that we can use to train a model, given a data loader and an optimizer.\n\nOur models run a strong risk of overfitting, given how few frauds there are in the training set.  Because of this, we should use some form of regularization.\n\nRather than training for a fixed number of epochs, we'll train until the loss reaches a specific `max_loss` threshold, or we've trained for `max_epochs`.","590e89c7":"Here we see performance that's slightly improved over the logistic regression model, though again we see the best result with a weight decay of 0.","4a536e7c":"This is a basic exploration of the Credit Card Fraud dataset.\n\nMy intent is to gain some practice analyzing datasets with [PyTorch](https:\/\/pytorch.org\/) and [scikit-learn](https:\/\/scikit-learn.org\/stable\/index.html).\n\nI want to obtain a reasonable result with a simple model, and am not aiming for a best-in-class result.\n\n1. [Loading the Data](#loading)\n2. [Visualizing with t-SNE](#tsne)\n3. [Creating Training, Dev and Test Datasets](#split)\n4. [Training a Model](#train)\n5. [Evaluating Model Performance](#eval)\n6. [Logistic Regression Model](#logistic)\n   * [Weight Decay Search](#logistic-wd)\n7. [Fully-Connected Network With Two Hidden Layers](#fc-two-hidden)\n   * [Weight Decay Search](#nn-wd)\n8. [K-Nearest Neighbor Classifier](#knn)\n9. [HDBSCAN](#hdbscan)\n10. [Conclusion](#conclusion)\n11. [Appendix: Balanced Sampling](#appendix-balanced)","79733ac9":"<a name=\"logistic\"><\/a>\n## Logistic Regression Model\nTo start with, we'll use a simple logistic model with no regularization.","2c241c66":"I was not expecting this, but it does appear that the best performance occurs with a weight decay of 0.","bacfe52e":"The best result is with N=4, giving an AUPRC of 0.748, but this is a worse result than previous models."}}