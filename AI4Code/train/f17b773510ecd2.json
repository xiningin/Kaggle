{"cell_type":{"42304cee":"code","d03071c7":"code","6e0901dc":"code","a22eca56":"code","90b96be4":"code","7ec25723":"code","f85df405":"code","95ab0107":"code","cab55aa2":"code","11bee9f2":"code","fd73941e":"code","e48679a4":"code","0a16635a":"code","9ce24636":"code","42b71014":"code","1182ad8f":"code","fdf58782":"code","6eb802a6":"code","36d1a616":"code","57cb81ce":"code","5066ab49":"code","3276d3de":"code","ab1dc2fd":"code","4679f05e":"code","649123a7":"code","8483fbf2":"code","6f295a6c":"code","d59c31e6":"code","deae4ab2":"code","990d3ec9":"code","65d6cd0f":"code","c0f771e5":"code","e676b358":"code","6a81514b":"code","543cda27":"code","7ba26236":"code","f0baecd8":"code","09fa46e0":"code","58b95036":"code","8d5e32b6":"code","d0ed08ea":"code","c0477889":"code","96c3610d":"code","ed5adf36":"code","1f6d3f4b":"code","3db4c763":"code","64da51fa":"code","f11fca7c":"code","2ccb78fb":"code","b3488777":"code","f73eaf02":"code","68a41f31":"code","3ac3c8b4":"code","d94a1bb0":"code","3148e9d8":"code","21ecf7f5":"code","57dcb713":"code","5352f371":"code","b382859c":"code","71142420":"code","037afd44":"code","f91b3c56":"code","249ec639":"code","1bbd4457":"code","113ecb9d":"code","3138651e":"code","17124174":"code","df4297e1":"code","affb5ec8":"code","803f68ce":"code","d7e023eb":"code","5ad16356":"code","6e1c09af":"code","bde8d7bb":"markdown","7e0bfc34":"markdown","c98fb38b":"markdown","4b1d5da7":"markdown","f0ca311e":"markdown","739a8ba0":"markdown","a938a69d":"markdown","72a7ea43":"markdown","5b1fea39":"markdown","b904306d":"markdown","c3485e16":"markdown","9786ffee":"markdown","8a5e8bc1":"markdown","f9e94e79":"markdown","c69b6bbe":"markdown","ceb5d4af":"markdown","1bf14d12":"markdown","b301fe7a":"markdown","9fa0b2cf":"markdown","2beb1714":"markdown","caaf9d78":"markdown","9fcedf04":"markdown","4bd3b764":"markdown","2588546f":"markdown","b304de62":"markdown","3ea13007":"markdown","9e5249ae":"markdown","1eb5371b":"markdown","08700d84":"markdown","8a772de4":"markdown"},"source":{"42304cee":"\nimport pandas as pd\nimport numpy as np\nfrom statsmodels.tsa.api import VAR\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tools.eval_measures import rmse, aic\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.tsa.stattools import acf\nfrom math import sqrt\nfrom warnings import catch_warnings\nfrom warnings import filterwarnings\nfrom sklearn.metrics import mean_squared_error\nfrom pandas import read_csv\nimport io\nimport matplotlib.pyplot as plt\nfrom numpy import array\nfrom datetime import datetime\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","d03071c7":"df1 = pd.read_csv('\/kaggle\/input\/dengueai\/dengue_features_train.csv', index_col=['city','year','weekofyear'])\ndf2 = pd.read_csv('\/kaggle\/input\/dengueai\/dengue_labels_train.csv', index_col=['city','year','weekofyear'])","6e0901dc":"df = df1.join(df2)","a22eca56":"df.head()","90b96be4":"dfsj = df.iloc[ :936]\ndfiq = df.iloc[936: ]","7ec25723":"dfsj.set_index('week_start_date', inplace=True)\ndfiq.set_index('week_start_date', inplace=True)","f85df405":"fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\nfig.suptitle('Cases in San Joun & Iquitos')\nfig.set_size_inches(16,5)\nax = dfsj['total_cases'].plot(ax=ax1);\nax1.set_title('San Joun cases')\nax = dfiq['total_cases'].plot(ax=ax2);\nax2.set_title('Iquitos cases')","95ab0107":"dfsj.head()","cab55aa2":"dfiq.head()","11bee9f2":"fig, axes = plt.subplots(nrows=21, ncols=1, dpi=120, figsize=(12,30))\nfor i, ax in enumerate(axes.flatten()):\n    data = dfsj[dfsj.columns[i]]\n    ax.plot(data, color='red', linewidth=1)\n    # Decorations\n    ax.set_title(dfsj.columns[i])\n    ax.xaxis.set_ticks_position('none')\n    ax.yaxis.set_ticks_position('none')\n    ax.spines[\"top\"].set_alpha(0)\n    ax.tick_params(labelsize=6)\n\nplt.tight_layout();","fd73941e":"dfsj.isnull().sum()","e48679a4":"dfsj = dfsj.interpolate()\ndfsj.isnull().sum()","0a16635a":"fig, axes = plt.subplots(nrows=21, ncols=1, dpi=120, figsize=(12,30))\nfor i, ax in enumerate(axes.flatten()):\n    data = dfiq[dfiq.columns[i]]\n    ax.plot(data, color='red', linewidth=1)\n    # Decorations\n    ax.set_title(dfsj.columns[i])\n    ax.xaxis.set_ticks_position('none')\n    ax.yaxis.set_ticks_position('none')\n    ax.spines[\"top\"].set_alpha(0)\n    ax.tick_params(labelsize=6)\n\nplt.tight_layout();","9ce24636":"dfiq.isnull().sum()","42b71014":"dfiq = dfiq.interpolate()\ndfiq.isnull().sum()","1182ad8f":"sj_correlations = dfsj.corr()","fdf58782":"import seaborn as sns\nfig, ax = plt.subplots(figsize=(20,10))\nsns.set(style=\"ticks\", palette=\"colorblind\")\n(sj_correlations\n     .total_cases\n     .drop('total_cases') # don't compare with myself\n     .sort_values(ascending=False)\n     .plot\n     .barh()\n)","6eb802a6":"dfsj.shape","36d1a616":"dfsj.columns","57cb81ce":"iq_correlations = dfiq.corr()","5066ab49":"# iq\nimport seaborn as sns\nfig, ax = plt.subplots(figsize=(20,10))\nsns.set(style=\"ticks\", palette=\"colorblind\")\n(iq_correlations\n     .total_cases\n     .drop('total_cases') # don't compare with myself\n     .sort_values(ascending=False)\n     .plot\n     .barh()\n)","3276d3de":"dfiq.shape","ab1dc2fd":"dfiq.columns","4679f05e":"maxlag=8\ntest = 'ssr_chi2test'\nvariables = dfsj.columns\n\ndef grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n    \n    \"\"\"\n    data      : pandas dataframe containing the time series variables\n    variables : list containing names of the time series variables.\n    \"\"\"\n    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [var + '_x' for var in variables]\n    df.index = [var + '_y' for var in variables]\n    return df\n\ngrangers_causation_matrix(dfsj, variables)","649123a7":"dffsj = dfsj[['reanalysis_air_temp_k', 'reanalysis_avg_temp_k', 'reanalysis_max_air_temp_k','reanalysis_min_air_temp_k', 'reanalysis_specific_humidity_g_per_kg', 'station_avg_temp_c', 'reanalysis_dew_point_temp_k','station_min_temp_c', 'total_cases']]","8483fbf2":"dffsj.head()","6f295a6c":"from statsmodels.tsa.stattools import grangercausalitytests\nmaxlag=8\ntest = 'ssr_chi2test'\nvariables = dfiq.columns\n\ndef grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n    \n    \"\"\"\n    data      : pandas dataframe containing the time series variables\n    variables : list containing names of the time series variables.\n    \"\"\"\n    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [var + '_x' for var in variables]\n    df.index = [var + '_y' for var in variables]\n    return df\n\ngrangers_causation_matrix(dfiq, variables)","d59c31e6":"dffiq = dfiq[['reanalysis_relative_humidity_percent', 'station_avg_temp_c', 'station_min_temp_c','reanalysis_min_air_temp_k', 'reanalysis_dew_point_temp_k', 'reanalysis_specific_humidity_g_per_kg', 'total_cases']]","deae4ab2":"dffiq.head()","990d3ec9":"from statsmodels.tsa.vector_ar.vecm import coint_johansen\n\ndef cointegration_test(df, alpha=0.05): \n    \"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\n    out = coint_johansen(df,-1,5)\n    d = {'0.90':0, '0.95':1, '0.99':2}\n    traces = out.lr1\n    cvts = out.cvt[:, d[str(1-alpha)]]\n    def adjust(val, length= 6): return str(val).ljust(length)\n\n    # Summary\n    print('Name   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n    for col, trace, cvt in zip(df.columns, traces, cvts):\n        print(adjust(col), ':: ', adjust(round(trace,2), 9), \">\", adjust(cvt, 8), ' =>  ' , trace > cvt)","65d6cd0f":"cointegration_test(dffsj)","c0f771e5":"cointegration_test(dffiq)","e676b358":"nobs = int(len(dffsj)*.3)\n\ndffsj_train = dffsj[:-nobs]\ndffsj_test = dffsj[-nobs:]\n\nprint('30%  = ',nobs )\nprint('Rows , Cols for training : ', dffsj_train.shape)  \nprint('Rows , Cols for testing  : ', dffsj_test.shape)  ","6a81514b":"def adfuller_test(series, signif=0.05, name='', verbose=False):\n    \"\"\"Perform ADFuller to test for Stationarity of given series and print report\"\"\"\n    r = adfuller(series, autolag='AIC')\n    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n    p_value = output['pvalue'] \n    def adjust(val, length= 6): return str(val).ljust(length)\n\n    # Print Summary\n    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n    print(f' Significance Level    = {signif}')\n    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n\n    for key,val in r[4].items():\n        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n\n    if p_value <= signif:\n        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n        print(f\" => Series is Stationary.\")\n    else:\n        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n        print(f\" => Series is Non-Stationary.\") ","543cda27":"nobs = int(len(dffiq)*.3)\n\ndffiq_train = dffiq[:-nobs]\ndffiq_test = dffiq[-nobs:]\n\nprint('30%  = ', nobs )\nprint('Rows , Cols for training : ', dffiq_train.shape)  \nprint('Rows , Cols for testing  : ', dffiq_test.shape)","7ba26236":"# ADF Test on each series (as column value)\nfor name, column in dffsj_train.iteritems():\n    adfuller_test(column, name=column.name)\n    print('\\n')","f0baecd8":"for name, column in dffiq_train.iteritems():\n    adfuller_test(column, name=column.name)\n    print('\\n')","09fa46e0":"model_sj = VAR(dffsj)\nfor i in range(1,12):\n    result = model_sj.fit(i)\n    print('Lag Order =', i)\n    print('AIC : ', result.aic)\n    print('BIC : ', result.bic)\n    print('FPE : ', result.fpe)\n    print('HQIC: ', result.hqic, '\\n')","58b95036":"x = model_sj.select_order(maxlags=3)\nx.summary()","8d5e32b6":"model_sj_fitted = model_sj.fit(3)\nmodel_sj_fitted.summary()","d0ed08ea":"from statsmodels.stats.stattools import durbin_watson\nout = durbin_watson(model_sj_fitted.resid)\n\nfor col, val in zip(dffsj.columns, out):\n    print((col), ':', round(val, 2))","c0477889":"# Get the lag order\nlag_order = model_sj_fitted.k_ar\nprint(lag_order) \n\n# Input data for forecasting\nforecastsj_input = dffsj.values[-lag_order:]\nprint(forecastsj_input.shape)","96c3610d":"fc = model_sj_fitted.forecast(y = forecastsj_input, steps=280)\ncols = dffsj.columns\ndffsj_forecast = pd.DataFrame(fc, index=dffsj_test.index, columns=cols + '_2d')\ndffsj_forecast","ed5adf36":"model_iq = VAR(dffiq)\nfor i in range(1,12):\n    result = model_iq.fit(i)\n    print('Lag Order =', i)\n    print('AIC : ', result.aic)\n    print('BIC : ', result.bic)\n    print('FPE : ', result.fpe)\n    print('HQIC: ', result.hqic, '\\n')","1f6d3f4b":"x = model_iq.select_order(maxlags=3)\nx.summary()","3db4c763":"model_iq_fitted = model_iq.fit(3)\nmodel_iq_fitted.summary()","64da51fa":"out = durbin_watson(model_iq_fitted.resid)\n\nfor col, val in zip(dffiq.columns, out):\n    print((col), ':', round(val, 2))","f11fca7c":"# Get the lag order\nlag_order = model_iq_fitted.k_ar\nprint(lag_order)\n\n# Input data for forecasting\nforecastiq_input = dffiq.values[-lag_order:]\nprint(forecastiq_input)","2ccb78fb":"fc = model_iq_fitted.forecast(y = forecastiq_input, steps=156)\ncols = dffiq.columns\ndffiq_forecast = pd.DataFrame(fc, index=dffiq_test.index, columns=cols + '_2d')\ndffiq_forecast","b3488777":"from statsmodels.tsa.stattools import acf\ndef forecast_accuracy(forecast, actual):\n    mape = np.mean(np.abs(forecast - actual)\/np.abs(actual))  # MAPE\n    me = np.mean(forecast - actual)             # ME\n    mae = np.mean(np.abs(forecast - actual))    # MAE\n    mpe = np.mean((forecast - actual)\/actual)   # MPE\n    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n    mins = np.amin(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    maxs = np.amax(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    minmax = 1 - np.mean(mins\/maxs)             # minmax\n    return({'mape':mape, 'me':me, 'mae': mae, \n            'mpe': mpe, 'rmse':rmse, 'corr':corr, 'minmax':minmax})","f73eaf02":"print('Forecast Accuracy of: Total Cases in sj')\naccuracy_prod = forecast_accuracy(dffsj_forecast['total_cases_2d'].values, dffsj_test['total_cases'])\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\nprint('Forecast Accuracy of: Total Cases in iq')\naccuracy_prod = forecast_accuracy(dffiq_forecast['total_cases_2d'].values, dffiq_test['total_cases'])\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))","68a41f31":"dfsj.shape","3ac3c8b4":"dfsj.isnull().sum()","d94a1bb0":"dffsj.shape","3148e9d8":"model_sj_entire = VAR(dffsj)\nfor i in range(1,12):\n    result = model_sj_entire.fit(i)\n    print('Lag Order =', i)\n    print('AIC : ', result.aic)\n    print('BIC : ', result.bic)\n    print('FPE : ', result.fpe)\n    print('HQIC: ', result.hqic, '\\n')","21ecf7f5":"x = model_sj_entire.select_order(maxlags=12)\nx.summary()","57dcb713":"model_sj_entire_fitted = model_sj_entire.fit(3)\nmodel_sj_entire_fitted.summary()","5352f371":"dffsj.shape","b382859c":"# Get the lag order\nlag_order = model_sj_entire_fitted.k_ar\nprint(lag_order)  #> 4\n\n# Input data for forecasting\nforecast_sj_entire_input = dffsj.values[-lag_order:]\nforecast_sj_entire_input","71142420":"model_iq_entire = VAR(dffiq)\nfor i in range(1,12):\n    result = model_iq_entire.fit(i)\n    print('Lag Order =', i)\n    print('AIC : ', result.aic)\n    print('BIC : ', result.bic)\n    print('FPE : ', result.fpe)\n    print('HQIC: ', result.hqic, '\\n')","037afd44":"x = model_iq_entire.select_order(maxlags=12)\nx.summary()","f91b3c56":"model_iq_entire_fitted = model_iq_entire.fit(3)\nmodel_iq_entire_fitted.summary()","249ec639":"lag_order = model_iq_entire_fitted.k_ar\nprint(lag_order)  \n\nforecast_iq_entire_input = dffiq.values[-lag_order:]\nforecast_iq_entire_input","1bbd4457":"fc = model_iq_entire_fitted.forecast(y=forecast_iq_entire_input, steps=156)\nfc.shape","113ecb9d":"dff_test.shape","3138651e":"dff_iq_entire_test = dff_test[260:]","17124174":"dff_iq_entire_test.set_index('week_start_date', inplace=True)\ndff_iq_entire_test.sample()","df4297e1":"cols = dffiq.columns","affb5ec8":"df_iq_entire_forecast = pd.DataFrame(fc, index=dff_iq_entire_test.index, columns=cols + '_2d')\ndf_iq_entire_forecast","803f68ce":"def forecast_accuracy(forecast, actual):\n    mape = np.mean(np.abs(forecast - actual)\/np.abs(actual))  # MAPE\n    me = np.mean(forecast - actual)             # ME\n    mae = np.mean(np.abs(forecast - actual))    # MAE\n    mpe = np.mean((forecast - actual)\/actual)   # MPE\n    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n    mins = np.amin(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    maxs = np.amax(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    minmax = 1 - np.mean(mins\/maxs)             # minmax\n    return({'mae': mae, 'corr':corr})","d7e023eb":"print('Forecast Accuracy of features\\n')\n\naccuracy_prod = forecast_accuracy(df_sj_entire_forecast['reanalysis_air_temp_k_2d'].values, dff_sj_test['reanalysis_air_temp_k'])\nprint('\\n reanalysis_air_temp_k_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_sj_entire_forecast['reanalysis_avg_temp_k_2d'].values, dff_sj_test['reanalysis_avg_temp_k'])\nprint('\\n reanalysis_avg_temp_k_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_sj_entire_forecast['reanalysis_max_air_temp_k_2d'].values, dff_sj_test['reanalysis_max_air_temp_k'])\nprint('\\n reanalysis_max_air_temp_k_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_sj_entire_forecast['reanalysis_min_air_temp_k_2d'].values, dff_sj_test['reanalysis_min_air_temp_k'])\nprint('\\n reanalysis_min_air_temp_k_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_sj_entire_forecast['reanalysis_specific_humidity_g_per_kg_2d'].values, dff_sj_test['reanalysis_specific_humidity_g_per_kg'])\nprint('\\n reanalysis_specific_humidity_g_per_kg_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_sj_entire_forecast['station_avg_temp_c_2d'].values, dff_sj_test['station_avg_temp_c'])\nprint('\\n station_avg_temp_c_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_sj_entire_forecast['reanalysis_dew_point_temp_k_2d'].values, dff_sj_test['reanalysis_dew_point_temp_k'])\nprint('\\n reanalysis_dew_point_temp_k_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_sj_entire_forecast['station_min_temp_c_2d'].values, dff_sj_test['station_min_temp_c'])\nprint('\\n station_min_temp_c_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))","5ad16356":"df_iq_entire_forecast.columns","6e1c09af":"print('Forecast Accuracy of features\\n')\n\naccuracy_prod = forecast_accuracy(df_iq_entire_forecast['reanalysis_relative_humidity_percent_2d'].values, dff_iq_entire_test['reanalysis_relative_humidity_percent'])\nprint('\\n reanalysis_relative_humidity_percent_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_iq_entire_forecast['station_avg_temp_c_2d'].values, dff_iq_entire_test['station_avg_temp_c'])\nprint('\\n station_avg_temp_c_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_iq_entire_forecast['station_min_temp_c_2d'].values, dff_iq_entire_test['station_min_temp_c'])\nprint('\\n station_min_temp_c_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_iq_entire_forecast['reanalysis_min_air_temp_k_2d'].values, dff_iq_entire_test['reanalysis_min_air_temp_k'])\nprint('\\n reanalysis_min_air_temp_k_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))  \n\naccuracy_prod = forecast_accuracy(df_iq_entire_forecast['reanalysis_dew_point_temp_k_2d'].values, dff_iq_entire_test['reanalysis_dew_point_temp_k'])\nprint('\\n reanalysis_dew_point_temp_k_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))\n\naccuracy_prod = forecast_accuracy(df_iq_entire_forecast['reanalysis_specific_humidity_g_per_kg_2d'].values, dff_iq_entire_test['reanalysis_specific_humidity_g_per_kg'])\nprint('\\n reanalysis_specific_humidity_g_per_kg_2d')\nfor k, v in accuracy_prod.items():\n    print((k), ': ', round(v,4))","bde8d7bb":"## Data Preprocessing:\n\n**There are two cities in datasets, I will explore both cities saperately**\n\nComparing the cases of two cities:","7e0bfc34":"## Accuracy Iq","c98fb38b":"## VAR\nVector autoregression. ... Vector autoregression (VAR) is a stochastic process model used to capture the linear interdependencies among multiple time series. VAR models generalize the univariate autoregressive model (AR model) by allowing for more than one evolving variable","4b1d5da7":"## Evaluate the Forecasts\n**To evaluate the forecasts, let\u2019s compute a comprehensive set of metrics, namely, the MAE & corr and minmax**","f0ca311e":"## ADFuller for Iq","739a8ba0":"## ADFuller for San Juan","a938a69d":"# DangAI Prediction : A Time Series Approach\n**A Time Series Analysis approach to model DangAI Data**","72a7ea43":"from statsmodels.tsa.vector_ar.vecm import coint_johansen\n\ndef cointegration_test(df, alpha=0.05): \n    \"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\n    out = coint_johansen(df,-1,5)\n    d = {'0.90':0, '0.95':1, '0.99':2}\n    traces = out.lr1\n    cvts = out.cvt[:, d[str(1-alpha)]]\n    def adjust(val, length= 6): return str(val).ljust(length)\n\n    # Summary\n    print('Name   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n    for col, trace, cvt in zip(df.columns, traces, cvts):\n        print(adjust(col), ':: ', adjust(round(trace,2), 9), \">\", adjust(cvt, 8), ' =>  ' , trace > cvt)","5b1fea39":"## Training for Iquitos entire data using VAR","b904306d":"**All features of iq on Total Cases**","c3485e16":"## San Juan : Training & Testing","9786ffee":"## Co-integration Test\n**Cointegration test helps to establish the presence of a statistically significant connection between two or more time series.**","8a5e8bc1":"## Adfuller Test","f9e94e79":"## Training on entire dataset","c69b6bbe":"## Forecasting total cases for sj","ceb5d4af":"## Forecasting\n**Here forecasting the prediction for city sj on training data for next 280 values**","1bf14d12":"**1st Splitted the Features + labels into \"Training & Testing on city basis\".**","b301fe7a":"**Interpolate Method used to fill missing values**","9fa0b2cf":"## Traning data contains following features:\n\n* ndvi_sw \u2013 Pixel southwest of city centroid\n* ndvi_sw \u2013 Pixel southwest of city centroid\n* ndvi_ne \u2013 Pixel northeast of city centroid\n* ndvi_nw \u2013 Pixel northwest of city centroid\n* City and date indicators\n* \n* city \u2013 City abbreviations: sj for San Juan and iq for Iquitos\n\n* week_start_date \u2013 Date given in yyyy-mm-dd format NOAA's GHCN daily climate data weather station measurements\n\n* station_max_temp_c \u2013 Maximum temperatur\n* station_min_temp_c \u2013 Minimum temperature\n* station_avg_temp_c \u2013 Average temperature\n* station_precip_mm \u2013 Total precipitation\n* station_diur_temp_rng_c \u2013 Diurnal temperature range PERSIANN satellite precipitation measurements (0.25x0.25 degree scale)\n\n* precipitation_amt_mm \u2013 Total precipitation NOAA's NCEP Climate Forecast System Reanalysis measurements (0.5x0.5 degree scale)\n\n* reanalysis_sat_precip_amt_mm \u2013 Total precipitation\n* reanalysis_dew_point_temp_k \u2013 Mean dew point temperature\n* reanalysis_air_temp_k \u2013 Mean air temperature\n* reanalysis_relative_humidity_percent \u2013 Mean relative humidity\n* reanalysis_specific_humidity_g_per_kg \u2013 Mean specific humidity\n* reanalysis_precip_amt_kg_per_m2 \u2013 Total precipitation\n* reanalysis_max_air_temp_k \u2013 Maximum air temperature\n* reanalysis_min_air_temp_k \u2013 Minimum air temperature\n* reanalysis_avg_temp_k \u2013 Average air temperature\n* reanalysis_tdtr_k \u2013 Diurnal temperature range\n* ndvi_se \u2013 Pixel southeast of city centroid","2beb1714":" ## Durbin Watson\n**The Durbin Watson (DW) statistic is a test for autocorrelation in the residuals from a statistical regression analysis. The Durbin-Watson statistic will always have a value between 0 and 4. A value of 2.0 means that there is no autocorrelation detected in the sample.**","caaf9d78":"**P-Value of less that the significance level of 0.05 represents that the null hypothesis and conclude x-axis causes y-axis.\n\n**Looking at the P-Values in the above table, you can pretty much observe that all the variables (time series) in the system are interchangeably causing each other.**\n\n**This makes this system of multi time series a good candidate for using VAR models to forecast.**","9fcedf04":"<hr>","4bd3b764":"## Accuracy Sj","2588546f":"## Importing Libraries \/ Packages","b304de62":"## Correlation\n\n**All features of San Jaun on Total Cases**","3ea13007":"## Granger\u2019s Causality Test\n\n**Using Granger\u2019s Causality Test to test this relationship before building the model.**","9e5249ae":"**Traning data contains following features: Separate on City basis. San Joun & Iquitos**","1eb5371b":"## Forecasting\n**Here forecasting the prediction for city iq on training data for next 156 values**","08700d84":"**Checking Null & Missing Values**","8a772de4":"## Uplaoding Datasets\n**Data Files\n\n1. Training Features\n1. Training labels\n1. Test Labels**"}}