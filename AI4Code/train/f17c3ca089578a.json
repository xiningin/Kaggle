{"cell_type":{"0ecd9161":"code","1ac220f1":"code","9314aefa":"code","11a0db2c":"code","c21f5e61":"code","4a28b947":"code","887c487c":"code","f1128f37":"code","026f3a67":"code","1aefdeb1":"code","624cc66b":"code","e635ab8b":"code","574eb606":"code","88fcea06":"code","f3b735d2":"code","20ddf784":"code","8f8e6f61":"code","b1325125":"code","59dec5ef":"code","6bcab110":"code","0e5e8edd":"markdown","6cc950c5":"markdown","8829154c":"markdown","914f6b78":"markdown","7aec3fcd":"markdown","d2ae5064":"markdown","34088b58":"markdown","24bcc1cd":"markdown","1d88379f":"markdown","9280542e":"markdown","5256c614":"markdown","aff15f70":"markdown"},"source":{"0ecd9161":"# Basic import of libraries to support our analysis\nimport numpy as np \nimport pandas as pd\n\n# Visualization Libs\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport tensorflow as tf\n","1ac220f1":"# Check which version of TF is hosted \nprint(tf.__version__)","9314aefa":"train=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nprint(\"Train Shape: {}\".format(train.shape))\nprint(\"Test Shape: {}\".format(test.shape))","11a0db2c":"train.head()","c21f5e61":"test.head()","4a28b947":"print(\"Train Nulls: {}\".format(train.isna().any().sum()))\nprint(\"Test Nulls: {}\".format(test.isna().any().sum()))","887c487c":"# Training set\nfig, axs = plt.subplots(2, 5, figsize=(16,6))\nfor i, ax  in zip(range(0,10), axs.flat):\n    ax.imshow(train[train['label'] == i].drop(columns=['label']).iloc[0].values.reshape(28, 28), cmap='gray')","f1128f37":"fig, axs = plt.subplots(2, 5, figsize=(16,6))\nfor i, ax  in zip(range(0,10), axs.flat):\n    ax.imshow(test.iloc[i].values.reshape(28, 28), cmap='gray')","026f3a67":"# Plot the distribution of each label\nplt.figure(figsize=(24, 7))\nplt.hist(train['label'], color='c', rwidth=0.5, align='mid')\nplt.xlabel('Digits')\nplt.ylabel('Frequency')\nplt.title('Distribution of Labels')\nplt.show()","1aefdeb1":"# Downcasting all the values to save memory\ny = train['label'].astype('int8')\n\n# Downcast to float16 for every column except label\nX = train.drop(columns=['label']).astype('float16').values\n\n# Reshape the arrays so they are easier to visualize and input to NN\nX = X.reshape(42000, 28,28, 1)","624cc66b":"from sklearn.model_selection import train_test_split\n\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)","e635ab8b":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Create our image generator\ntrain_image_generator = ImageDataGenerator(\n    rescale=1.\/255\n)\n\nvalidation_image_generator = ImageDataGenerator(\n    rescale=1.\/255\n)\n\n# Create instance of image generator attach to the dataset\ntrain_image_gen = train_image_generator.flow(\n    x=X_train, \n    y=y_train,\n)\n\nvalidation_image_gen = validation_image_generator.flow(\n    x=X_validation, \n    y=y_validation,\n)","574eb606":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu',padding='same', input_shape=(28, 28, 1)),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    tf.keras.layers.Dropout(0.1),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    tf.keras.layers.Dropout(0.1),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(10, activation='softmax')\n])","88fcea06":"tf.keras.backend.clear_session()  # For easy reset of notebook state.\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(\n    train_image_gen,\n    epochs=5,\n    validation_data=validation_image_gen\n)","f3b735d2":"# Plot the loss and accuracy of the validation and training set\nfig, axs = plt.subplots(1,2, figsize=(20,5))\naxs[0].plot(history.history['loss'], label='Train')\naxs[0].plot(history.history['val_loss'], label='Validation')\naxs[0].set_title(\"Loss of Validation and Train\")\naxs[0].legend()\n\naxs[1].plot(history.history['accuracy'], label='Train')\naxs[1].plot(history.history['val_accuracy'], label='Validation')\naxs[1].set_title(\"Accuracy of Validation and Train\")\naxs[1].legend()\n\nfig.show()","20ddf784":"# Lets predict the values on the validation set\nvalidation_predict = model.predict(X_validation)\n\n# Create a dataframe to store the label and the confidence in their predictions\nlow_predictions = pd.DataFrame()\nlow_predictions['label'] = np.argmax(validation_predict, axis=1)\nlow_predictions['Confidence'] = np.max(validation_predict, axis=1)\n\nlow_index = low_predictions.sort_values(by=['Confidence'])[:10].index\nlow_labels = low_predictions.sort_values(by=['Confidence'])['label']\n\nfig, axs = plt.subplots(2, 5, figsize=(24,9.5))\nfor i, low_label, ax  in zip(low_index,low_labels, axs.flat):\n    image = X_validation[i].astype('float32').reshape(28, 28)\n    ax.imshow(image, cmap='gray')\n    ax.set_xlabel(\"True: {}\".format(y_validation.iloc[i]))\n    ax.set_title(\"Guessed:{} \".format(low_label))\n","8f8e6f61":"# Create our image generator\ntrain_image_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=25,\n    width_shift_range=.1,\n    height_shift_range=.1,\n    zoom_range=0.1\n)\n\nvalidation_image_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=25,\n    width_shift_range=.1,\n    height_shift_range=.1,\n    zoom_range=0.1\n)\n\n# Create the dataset\ntrain_image_gen = train_image_generator.flow(\n    x=X_train, \n    y=y_train,\n)\n\nvalidation_image_gen = validation_image_generator.flow(\n    x=X_validation, \n    y=y_validation,\n)\n\nlr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n    initial_learning_rate=0.001,\n    decay_steps=250,\n    decay_rate=1,\n    staircase=False\n)\n\ndef get_optimizer():\n    return tf.keras.optimizers.Adam(lr_schedule)\n\ntf.keras.backend.clear_session()  # For easy reset of notebook state.\n\nmodel.compile(optimizer=get_optimizer(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(\n    train_image_gen,\n    epochs=20,\n    validation_data=validation_image_gen\n)","b1325125":"# Plot the loss and accuracy of validation and train\nfig, axs = plt.subplots(1,2, figsize=(20,5))\naxs[0].plot(history.history['loss'], label='Train')\naxs[0].plot(history.history['val_loss'], label='Validation')\naxs[0].set_title(\"Loss of Validation and Train\")\naxs[0].legend()\n\naxs[1].plot(history.history['accuracy'], label='Train')\naxs[1].plot(history.history['val_accuracy'], label='Validation')\naxs[1].set_title(\"Accuracy of Validation and Train\")\naxs[1].legend()\n\nfig.show()","59dec5ef":"X_test = test.astype('float16').values\nX_test = X_test \/ 255.0\nX_test = X_test.reshape(len(X_test), 28, 28, 1)","6bcab110":"label_pred = model.predict_classes(X_test, verbose=0)\n\nsubmission = pd.DataFrame()\nsubmission['Label'] = label_pred\nsubmission['ImageId'] = submission.index + 1\nsubmission.to_csv('..\/working\/output.csv', index=False)","0e5e8edd":"Looking at the predictions the model was not very confident in that aren't drawn that well. Images are not drawn well, or drawn at a slant are difficult for the model to classify since it most likely does not encounter these kind of images that often.\n\nIn order to improve our model lets recreate the ImageDataGenerator this time lets add rotations and some horizontal and vertical shift to stimulate the distortions. We will then retrain the network and evaluate the accuracy. Lets also run it for 20 epochs since we want to see if more training time leads to better results.","6cc950c5":"We are going to use a combination of Conv2D nets and MaxPooling2D to help determine what the most important features are.\nWe are then going to feed the features to a Flatten() layer and then to a large dense layer. A dropout rate of 0.1 is used to lower the chances of overfitting. BatchNorm is also used to help the NN train more efficently. ","8829154c":"We will train for 5 epochs and plot the loss and accuracy between the two datasets. ","914f6b78":"There doesn't seem to be any class over\/under represented in the train set.\n\n## Data Preprocessing\n\nLets begin to setup the data so we can feed it into a neural network. We need to reshape X from 42000x28x28 to 42000x28x28x1. The extra dimension represents the black and white colour channel. If this was a coloured picture dataset then we would have 3 channels to work with. We are also going to downcast the dataset to variable types that take up less memory. This makes it easier to train larger Neural Networks (NN) since we are using up less memory.","7aec3fcd":"Juding by the loss and accuracy we can see that there doesnt seem to be much bias or variance between the two datasets. This is good meaning out NN does not over or underfit and in theory perform well in predicting the test set. Before we actually make predictions on our test set, lets visualize the results of the worst predictions and see which pictures the model has trouble predicting.","d2ae5064":"We are going to use the ImageDataGenerator class to load all out data. This class provides us the flexibility to apply many builtin data augmentation technqiues. But for now we are just going to divide all the pixels by 255 to normalize the values between 0 and 1.0 and see how the NN performs. Normalized values makes it easier for our NN to converge.","34088b58":"### Exploring the Dataset\nBefore we begin to visualize the dataset lets see the shape and size of the data we are working with.","24bcc1cd":"We will create a new training and a validation set. The size of the validation set will be 20% of the training set which is the standard.","1d88379f":"## Data Visualization\n\nLets explore what our data looks like. Lets see what each number.","9280542e":"Looks there is not much overfitting or underfitting. Lets make predictions on the test set and see the score.","5256c614":"We can see that there are 10 classes of numbers, from 0 to 9. They all look handwritten with varying density and curves. There does not seem to be any difference between the test set and train set.\n\nThe next step is to see the distribution of labels. We need to pay attention to any labels that are over represented or underrepresented in out dataset. A model predictions power decreases when it encounters any label that was underrepresented in train set","aff15f70":"Looks like we are working wth 42000 images in the training set and 28000 images in the test set. The test set is missing the label column. Interesting thing to note is the images should be 28 px x 28 x 1 channel (black and white) but the pixels were unrolled into 784 columns. We need to reshape the columns to 28x28x1 in order to visualize the image and also feed it into the neural network we will build. "}}