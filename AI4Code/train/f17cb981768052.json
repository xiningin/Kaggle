{"cell_type":{"2180c3aa":"code","0d588462":"code","99c713a6":"code","9ba1ae51":"code","639142b1":"code","de782ca1":"code","644598a5":"code","51f3e9c0":"code","a73de3fd":"code","b471cc28":"code","220b8d09":"code","0e2a8616":"code","f637e651":"code","e6e12e25":"code","320d1fca":"markdown","e65c9c9d":"markdown","c2bfd231":"markdown","a993b6e1":"markdown","f1694fc2":"markdown","e46caa7c":"markdown","47234738":"markdown","0f48e0a6":"markdown","73d0a945":"markdown","23ca7e7b":"markdown","a6341bbc":"markdown"},"source":{"2180c3aa":"# Libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\n\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nimport torch\nimport torchvision.models as models\nimport torch.nn as nn\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import models\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nfrom skimage.io import imshow, imread, imsave\nfrom skimage.transform import rotate, AffineTransform, warp,rescale, resize, downscale_local_mean\nfrom skimage import color,data\nfrom skimage.exposure import adjust_gamma\nfrom skimage.util import random_noise","0d588462":"data_dir = '..\/input\/seti-breakthrough-listen'\ntrain_merger = os.path.join(data_dir,'train_labels.csv')\ntrain_labels = pd.read_csv(train_merger)\nprint('train_label_csv : ' +str(train_labels.shape[0]))\n#adding the path for each id for easier processing\ntrain_labels['path'] = train_labels['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')\ntrain_labels.head()","99c713a6":"import albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom typing import *\n\nclass Transform:\n    def __init__(self, aug_kwargs: Dict):\n        albumentations_aug = [getattr(A, name)(**kwargs)\n                            for name, kwargs in aug_kwargs.items()]\n        albumentations_aug.append(ToTensorV2(p=1))\n        self.transform = A.Compose(albumentations_aug)\n    \n    def __call__(self, image):\n        image = self.transform(image = image)['image']\n        return image","9ba1ae51":"class ModeTransform():\n    def __init__(self, df_frame, config, channel_mode,mode,target,transform):\n        self.df_frame = df_frame\n        self.channel_mode = channel_mode\n        self.config = config\n        self.target = target\n        self.file_names = df_frame['path'].values\n        self.labels = df_frame['target'].values\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.df_frame)\n\n    def __getitem__(self, idx):\n        image = np.load(self.file_names[idx])\n        # print(image.shape) -> (6, 273, 256)\n        if self.channel_mode == 'spatial_6ch':\n            image = image.astype(np.float32)\n            image = np.vstack(image) # no transpose here (1638, 256) \n            #image = np.vstack(image).transpose((1, 0))\n            # print(image.shape) -> (256, 1638)\n\n        elif self.channel_mode == 'spatial_3ch':\n            image = image[::2].astype(np.float32)\n            image = np.vstack(image).transpose((1, 0))\n        elif self.channel_mode == '6_channel':\n            image = image.astype(np.float32)\n            image = np.transpose(image, (1,2,0))\n        elif self.channel_mode == '3_channel':\n            image = image[::2].astype(np.float32)\n            image = np.transpose(image, (1,2,0))\n        \n        if self.transform:\n            image = self.transform(image)\n  \n        else:\n            image = torch.from_numpy(image).float()\n\n        if self.mode == 'test':\n            return image    \n        else:\n            label = torch.tensor(self.labels[idx]).float()\n            return image, label","639142b1":"import albumentations as A\nCONFIG = { \n    \"TRAIN_TRANSFORMS\": {        \n        \"VerticalFlip\": {\"p\": 0.5},\n        \"HorizontalFlip\": {\"p\": 0.5},\n        \"Resize\": {\"height\": 640, \"width\": 640, \"p\": 1},\n    }}\nconfig = CONFIG\n\n# Parameters\nparams_train  = {'mode'            :  'train',\n                 'channel_mode'    : 'spatial_6ch',\n                 'target'          : True}\n\ntrain_dset = ModeTransform(train_labels,config,\n                           **params_train,\n                           transform=Transform(config[\"TRAIN_TRANSFORMS\"]))\n\nfor i in range(2):\n    image, label = train_dset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show()\nimage.shape","de782ca1":"class SETIDataset(tf.keras.utils.Sequence):\n    def __init__(self,df, directory, batch_size, random_state, shuffle, target):\n        np.random.seed(random_state)\n        self.directory = directory\n        self.df = df\n        self.target = target\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.ext = '.npy'\n        self.on_epoch_end()\n        \n    def __len__(self):  \n        len_ = np.ceil(self.df.shape[0] \/ self.batch_size).astype(int)\n        return len_\n    \n    def __getitem__(self, idx):\n        start_idx = idx * self.batch_size\n        batch = self.df[start_idx: start_idx + self.batch_size]\n        \n        signals = []\n\n        for fname in batch.id:\n            path = os.path.join(self.directory, fname[0], fname + self.ext)\n            data = np.load(path)\n            signals.append(data)\n        \n        signals = np.transpose(np.stack(signals), (0, 1, 3, 2)).astype('float32')\n        \n        if self.target:\n            return signals, batch.target.values\n        else:\n            return signals\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)","644598a5":"train = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\nsub = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')","51f3e9c0":"sample_df = train.sample(frac=1).reset_index(drop=True)\n\nsplit = int(sample_df.shape[0] * 0.8)\ntrain_df = sample_df[:split]\nvalid_df = sample_df[split:]","a73de3fd":"# Parameters\nparams_train  = {'batch_size'   : 64,\n                'shuffle'       : True,\n                'random_state'  : 42,\n                'target'        : True}\n\nparams_valid  = {'batch_size'   : 64,\n                 'shuffle'      : False,\n                 'random_state' : 42,\n                 'target'       : True}\n\nparams_test   = {'batch_size'   : 64,\n                'shuffle'       : False,\n                'random_state'  : 42,\n                'target'        : False}\n\ntrain_dset = SETIDataset(\n    train_df, \"..\/input\/seti-breakthrough-listen\/train\", **params_train )\n\nvalid_dset = SETIDataset(\n    valid_df, \"..\/input\/seti-breakthrough-listen\/train\", **params_valid)\n\ntest_dset = SETIDataset(\n    sub, \"..\/input\/seti-breakthrough-listen\/test\", **params_test)","b471cc28":"def build_model(unit):\n    inputs = layers.Input(shape=(6, 256, 273))\n\n    gru1 = layers.Bidirectional(layers.GRU(unit, return_sequences = True))\n    gru2 = layers.Bidirectional(layers.GRU(unit, return_sequences = True))\n    pool = layers.GlobalAveragePooling1D()\n\n    model = layers.TimeDistributed(gru1, name=\"bi_gru_1\")(inputs)\n    model = layers.TimeDistributed(gru2, name=\"bi_gru_2\")(model)\n    model = layers.TimeDistributed(pool, name=\"pool\")(model)\n    \n    model = layers.Flatten()(model)\n    model = layers.Dense(128, activation=\"relu\")(model)\n    model = layers.Dense(1, activation=\"sigmoid\", name=\"sigmoid\")(model)\n\n    model = models.Model(inputs = inputs, outputs = model)\n    \n    model.compile(\"adam\", \n              loss=\"binary_crossentropy\",\n              metrics=[tf.keras.metrics.AUC()])\n    model.summary()\n    \n    return model","220b8d09":"model = build_model(unit = 128)\nmodel_save = ModelCheckpoint(\"model_weights.h5\", \n                             save_best_only=True, \n                             save_weights_only=True)\n\nhistory = model.fit(train_dset, \n                    use_multiprocessing=True, \n                    workers=4, \n                    epochs=10,\n                    validation_data=valid_dset,\n                    callbacks=[model_save])","0e2a8616":"acc = history.history['auc']\nval_acc = history.history['val_auc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.set_style(\"white\")\nplt.suptitle('Train history', size = 15)\n\nax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\nax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\nax1.set_title(\"Training and validation acc\")\nax1.legend()\n\nax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\nax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\nax2.set_title(\"Training and validation loss\")\nax2.legend()\n\nplt.show()","f637e651":"model.load_weights('model_weights.h5')\ny_pred = model.predict(\n    test_dset, \n    use_multiprocessing=True, \n    workers=4, \n    verbose=1)","e6e12e25":"sub['target'] = y_pred\nsub.to_csv('submission.csv', index=False)\nsub.head()","320d1fca":"# \ud83c\udf9b<span style=\"font-family:cursive;\"> Custom Dataset<\/span>","e65c9c9d":"# \ud83c\udfc1<span style=\"font-family:cursive;\"> Final Submission<\/span>","c2bfd231":"# \ud83d\udcd7<span style=\"font-family:cursive;\"> Albumentations<\/span>","a993b6e1":"## <span style=\"font-family:cursive;\"> If it's useful for you, come on upvote and thank you for your attention\ud83d\ude42<\/span>","f1694fc2":"# \ud83d\udcdd<span style=\"font-family:cursive;\"> Data Preparation<\/span>\n","e46caa7c":"## <span style=\"font-family:cursive;\"> Reference :<\/span>","47234738":"# \ud83d\udccd<span style=\"font-family:cursive;\"> Overview<\/span>\n* In this notebook,we build best model using Gated Recurrent Unit (GRU) keras with some refrences\n* Using albumentations \n* Custom Dataset Function\n* This notebook using GPU","0f48e0a6":"# \ud83d\udcc8<span style=\"font-family:cursive;\"> Visualizations<\/span>","73d0a945":"# \ud83e\uddea<span style=\"font-family:cursive;\"> Build Model<\/span>","23ca7e7b":"# \ud83d\udcda<span style=\"font-family:cursive;\"> Libraries <\/span>","a6341bbc":"Some references that have been used in this book :\n* [https:\/\/keras.io\/api\/layers\/recurrent_layers\/gru\/](http:\/\/https:\/\/keras.io\/api\/layers\/recurrent_layers\/gru\/)\n* [https:\/\/www.programcreek.com\/python\/example\/97114\/keras.layers.recurrent.GRU](http:\/\/https:\/\/www.programcreek.com\/python\/example\/97114\/keras.layers.recurrent.GRU)\n* [https:\/\/towardsdatascience.com\/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21](http:\/\/https:\/\/towardsdatascience.com\/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n* [https:\/\/www.kaggle.com\/xhlulu\/openvaccine-gru-with-keras-tuner](http:\/\/https:\/\/www.kaggle.com\/xhlulu\/openvaccine-gru-with-keras-tuner)\n* [https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/239339](http:\/\/https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/239339)"}}