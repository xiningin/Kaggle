{"cell_type":{"75cf92a6":"code","0edf012f":"code","5249e2c9":"code","d52deeaf":"code","96e60ab3":"code","d497ec23":"code","b7cc746a":"code","b479b057":"code","6f3565af":"code","b6261619":"code","5b253251":"code","4cdc0e69":"code","4cad202b":"code","72324ab3":"code","90fc0f1a":"code","bfeba2d0":"code","f7b372c7":"code","0f929389":"code","c9a7cc2d":"code","4fe1ba65":"code","2fe83ed1":"code","d91c86da":"code","7c9ca2c0":"code","1c568a3f":"code","b7e87ef7":"code","b2e46abd":"code","451c9437":"code","d992eba7":"code","4ac47e6f":"code","7d546425":"code","523e889a":"markdown","a91a9c6c":"markdown","00097879":"markdown","7f704c0f":"markdown","fdcba697":"markdown","bd58dc64":"markdown","afe911be":"markdown","54ffa6c3":"markdown","282b3459":"markdown","a071b442":"markdown","1fd16956":"markdown","353c166c":"markdown","5f43d2e0":"markdown"},"source":{"75cf92a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0edf012f":"df= pd.read_csv('\/kaggle\/input\/telecom-users-dataset\/telecom_users.csv')\ndf.head()","5249e2c9":"df.info()","d52deeaf":"df.describe()","96e60ab3":"df.duplicated().sum()","d497ec23":"df.nunique()","b7cc746a":"df= df.drop(df.columns[0], axis=1)\ndf.head()","b479b057":"categorical_cols= ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\nnum_cols= ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']","6f3565af":"df['Churn']= pd.get_dummies(df['Churn'], drop_first=True)\ndf.head()","b6261619":"plt.figure(figsize= (20,40))\n\ni=1\nfor col in categorical_cols:\n    plt.subplot(8,2,i)\n    sns.countplot(x= 'Churn', hue=col, data=df)\n    plt.title(col + 'Variation')\n    i=i+1\n        ","5b253251":"plt.figure(figsize=(15,15))\nn= 1\nfor col in ['tenure', 'MonthlyCharges']:\n    plt.subplot(4,2,n)\n    sns.boxplot(x='Churn', y= col, data=df)\n    plt.title(col + 'Variation')\n    n=n+1","4cdc0e69":"df[num_cols].hist()","4cad202b":"df_new= pd.get_dummies(df[categorical_cols],drop_first= True, prefix= 'dum_')","72324ab3":"df_new.head()","90fc0f1a":"df_new[num_cols]= df[num_cols]\ndf_new['Churn']= df['Churn']","bfeba2d0":"df_new.head()","f7b372c7":"df_new.info()","0f929389":"df_new['TotalCharges']= pd.to_numeric(df_new['TotalCharges'], errors='coerce')","c9a7cc2d":"df_new.isna().sum()","4fe1ba65":"df_new['TotalCharges']= df_new['TotalCharges'].fillna(method= 'ffill')","2fe83ed1":"df_new.info()","d91c86da":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","7c9ca2c0":"X= df_new.drop('Churn', axis=1)\ny= df_new['Churn']\n\nX_train, X_test, y_train,  y_test= train_test_split(X,y,test_size= 0.2, stratify=y, random_state=100)\n\nss= StandardScaler()\nss.fit_transform(X_train[num_cols])\nss.transform(X_test[num_cols])\n\nacc= []","1c568a3f":"from sklearn.linear_model import LogisticRegression\n\nlr= LogisticRegression()\nlr.fit(X_train, y_train)\n\ny_pred= lr.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n\nacc.append(accuracy_score(y_test, y_pred))","b7e87ef7":"from sklearn.ensemble import RandomForestClassifier\n\nrfc= RandomForestClassifier(random_state= 100)\nrfc.fit(X_train, y_train)\ny_pred= rfc.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n\nacc.append(accuracy_score(y_test, y_pred))","b2e46abd":"from sklearn.neighbors import KNeighborsClassifier\n\ndt= KNeighborsClassifier()\ndt.fit(X_train, y_train)\ny_pred= dt.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n\nacc.append(accuracy_score(y_test, y_pred))","451c9437":"from sklearn.naive_bayes import GaussianNB\n\ngnb= GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred= gnb.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n\nacc.append(accuracy_score(y_test, y_pred))","d992eba7":"from sklearn.tree import DecisionTreeClassifier\n\ndt= DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred= dt.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n\nacc.append(accuracy_score(y_test, y_pred))","4ac47e6f":"acc","7d546425":"plt.figure(figsize= (5,6))\nsns.barplot(x= ['LogReg', 'RandomForest', 'KNeighbors', 'NaiveBayes', 'DecisionTree'], y= acc)\nplt.title('Accuracy of Models')\nplt.xlabel('Training Models')\nplt.ylabel('Accuracy')\nplt.show()","523e889a":"# Building our Model","a91a9c6c":"# Decision Tree Classifier","00097879":"**We use get_dummies function of Pandas to get dummy variables for categorical data.**\n\n**Drop first columns to prevent overfitting**","7f704c0f":"**Scaling the Numerical Columns**","fdcba697":"**The Best Classifier for this model is Logistic Regression with accuracy and f1 score of 80%**","bd58dc64":"# Naive Bayes Classifier","afe911be":"# KNeighbors Classifier","54ffa6c3":"# Random Forest Classifier","282b3459":"# Exploratory Data Analysis","a071b442":"# Reading Data","1fd16956":"**Adding the Numerical Columns to our New Dataset**\n\n(I created this new dataframe beacuse I didn't want to spoil original dataframe with dummy variables)","353c166c":"# Creating Dummy Variables for Categorical Data","5f43d2e0":"# Logistic Regression"}}