{"cell_type":{"59bf6373":"code","58aff139":"code","274077f0":"code","3279465b":"code","74374c0c":"code","a9b8d329":"code","1853e387":"code","a225c037":"code","a04c0303":"code","f29bd174":"code","37515729":"code","398cf2b2":"code","2903a6bd":"code","86f0a619":"code","f86b55e2":"code","81c3d8d7":"code","77cfbbd9":"code","a772cac5":"code","aaa34f52":"code","46a13f44":"code","05795abe":"code","3b18280c":"code","63286581":"code","662dd7e7":"code","74d49b7f":"code","574d3821":"code","efb1b1f0":"code","f68d033a":"code","ce855a4b":"code","8eba6cd8":"code","fc7de27b":"code","4fc0a6c7":"code","b0794d50":"code","78e27fa5":"code","e4694f1f":"code","beead940":"code","a148f2f3":"code","e2594bd4":"code","a36e4513":"code","40ad856d":"code","590b5be6":"code","5f228c8f":"code","37f3ed1b":"code","271b72a4":"code","bcd7ba5a":"code","ceb7a162":"code","cd38f748":"code","1e238a29":"markdown","a816602d":"markdown","a9e6906e":"markdown","b6dc378b":"markdown","3689db24":"markdown","48890292":"markdown","2ac3a651":"markdown","aaac57ae":"markdown","740e1e3b":"markdown","dca00e0b":"markdown","93db8cb6":"markdown","f5c470ba":"markdown","a714bc73":"markdown","a40e1577":"markdown","5edc8e59":"markdown","b3682025":"markdown","1455f43b":"markdown","24f310a2":"markdown","9e0edbb4":"markdown","ef2daecf":"markdown","ba125a65":"markdown","4f2efa66":"markdown","9194a296":"markdown","a9a8fce1":"markdown","0d30c929":"markdown","c46d0725":"markdown","97f12f5f":"markdown","7604482d":"markdown","a63a3471":"markdown","2349d0a9":"markdown","7ba65e6e":"markdown","6b7e2b22":"markdown","6f5ef1ed":"markdown","7d764307":"markdown","adcfca36":"markdown","1857ac98":"markdown","9cbded9e":"markdown","1c3c8183":"markdown","68e4e53f":"markdown","bfb06d4b":"markdown","66701dff":"markdown","1ef79897":"markdown","68119e79":"markdown","bc2919c8":"markdown","22b7224e":"markdown","2e00909e":"markdown"},"source":{"59bf6373":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections\n\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix , precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport warnings\nwarnings.filterwarnings('ignore')","58aff139":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","274077f0":"sns.countplot('Class', data=df)","3279465b":"df_train, df_test = train_test_split(df, test_size=0.2,random_state=123,stratify=df[\"Class\"])\ndf_train, df_val = train_test_split(df_train, test_size=0.25,random_state=123,stratify=df_train[\"Class\"])","74374c0c":"plt.figure(figsize = (10,10))\nplt.title('Credit Card Transactions features correlation plot (Pearson)')\ncorr = df_train.corr()\nsns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"Reds\")\nplt.show()","a9b8d329":"# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n\n# RobustScaler is less prone to outliers.\n\nstd_scaler = StandardScaler()\nrob_scaler = RobustScaler()\n\ndf_train['scaled_amount'] = rob_scaler.fit_transform(df_train['Amount'].values.reshape(-1,1))\ndf_train['scaled_time'] = rob_scaler.fit_transform(df_train['Time'].values.reshape(-1,1))\n\ndf_train.drop(['Time','Amount'], axis=1, inplace=True)","1853e387":"X_train = df_train.drop([\"Class\"], axis = 1)\ny_train = df_train[\"Class\"]","a225c037":"df_val['scaled_amount'] = rob_scaler.fit_transform(df_val['Amount'].values.reshape(-1,1))\ndf_val['scaled_time'] = rob_scaler.fit_transform(df_val['Time'].values.reshape(-1,1))\ndf_val.drop(['Time','Amount'], axis=1, inplace=True)","a04c0303":"X_val = df_val.drop([\"Class\"], axis = 1)\ny_val = df_val[\"Class\"]","f29bd174":"log_cfl = LogisticRegression(C=0.95, random_state=0,solver='liblinear')\n\nlog_cfl.fit(X_train, y_train)\n\ny_predict = log_cfl.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","37515729":"log_cfl = LogisticRegression(C=0.95, random_state=0,solver='liblinear')\n\nlog_cfl.fit(X_train, y_train)\n\ny_predict = log_cfl.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","398cf2b2":"KNN = KNeighborsClassifier(n_neighbors=5)\n\nKNN.fit(X_train, y_train)\n\ny_predict = KNN.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","2903a6bd":"KNN = KNeighborsClassifier(n_neighbors=5)\n\nKNN.fit(X_train, y_train)\n\ny_predict = KNN.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","86f0a619":"import xgboost as xgb","f86b55e2":"from sklearn.ensemble import VotingClassifier\n","81c3d8d7":"xgb_cfl = xgb.XGBClassifier(n_jobs = -1, n_estimators = 100 ,max_depth=1)\nDT_clf = DecisionTreeClassifier(max_depth=2)\nrf_cfl =  RandomForestClassifier(n_estimators = 200,random_state = 42 , max_depth=2)","77cfbbd9":"vot = VotingClassifier (estimators = [('xgb', xgb_cfl), ('dt', DT_clf), ('rf', rf_cfl)], voting='soft')\nvot.fit(X_train, y_train)\n\ny_predict = vot.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","a772cac5":"vot = VotingClassifier (estimators = [('xgb', xgb_cfl), ('dt', DT_clf), ('rf', rf_cfl)], voting='soft')\nvot.fit(X_train, y_train)\n\ny_predict = vot.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","aaa34f52":"xgb_cfl = xgb.XGBClassifier(n_jobs = -1, n_estimators = 100 ,max_depth=1)\nlog_cfl = LogisticRegression(C=0.95, random_state=0,solver='liblinear')","46a13f44":"vot = VotingClassifier (estimators = [('xgb', xgb_cfl), ('log', log_cfl), ('knn', KNN)], voting='soft')\nvot.fit(X_train, y_train)\n\ny_predict = vot.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","05795abe":"vot = VotingClassifier(estimators = [('xgb', xgb_cfl), ('dt', log_cfl), ('rf', KNN)] ,voting='soft')\nvot.fit(X_train, y_train)\n\ny_predict = vot.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","3b18280c":"rf_cfl = RandomForestClassifier(n_estimators = 200,random_state = 42 , max_depth=2)\n\nrf_cfl.fit(X_train, y_train)\n\ny_predict = rf_cfl.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","63286581":"rf_cfl = RandomForestClassifier(n_estimators = 200,random_state = 42 , max_depth=2)\n\nrf_cfl.fit(X_train, y_train)\n\ny_predict = rf_cfl.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","662dd7e7":"from sklearn.ensemble import BaggingClassifier","74d49b7f":"from sklearn.ensemble import BaggingClassifier","574d3821":"DT_clf = DecisionTreeClassifier(max_depth=2)","efb1b1f0":"bag_clf = BaggingClassifier(DT_clf, n_estimators=200 , n_jobs=-1)\n\nbag_clf.fit(X_train, y_train)\n\ny_predict = bag_clf.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","f68d033a":"bag_clf = BaggingClassifier(DT_clf, n_estimators=200 , n_jobs=-1)\n\nbag_clf.fit(X_train, y_train)\n\ny_predict = bag_clf.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","ce855a4b":"from sklearn.ensemble import StackingClassifier","8eba6cd8":"xgb_cfl = xgb.XGBClassifier(n_jobs = -1, n_estimators = 100 ,max_depth=1)\nDT_clf = DecisionTreeClassifier(max_depth=2)\nrf_cfl =  RandomForestClassifier(n_estimators = 200,random_state = 42 , max_depth=2)","fc7de27b":"STC = StackingClassifier([('xgb', xgb_cfl), ('lt', log_cfl), ('rf', rf_cfl)])\n\nSTC.fit(X_train, y_train)\ny_predict = STC.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","4fc0a6c7":"STC = StackingClassifier([('xgb', xgb_cfl), ('lt', log_cfl), ('rf', rf_cfl)])\nSTC.fit(X_train, y_train)\n\ny_predict = STC.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","b0794d50":"STC = StackingClassifier([('xgb', xgb_cfl), ('log', log_cfl), ('knn', KNN)])\n\nSTC.fit(X_train, y_train)\ny_predict = STC.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","78e27fa5":"STC = StackingClassifier([('xgb', xgb_cfl), ('log', log_cfl), ('knn', KNN)])\n\nSTC.fit(X_train, y_train)\ny_predict = STC.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","e4694f1f":"from sklearn import svm","beead940":"svm = svm.SVC(kernel='linear')\n\nsvm.fit(X_train, y_train)\n\ny_predict = svm.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","a148f2f3":"from sklearn import svm","e2594bd4":"svm = svm.SVC(kernel='linear')\n\nsvm.fit(X_train, y_train)\n\ny_predict = svm.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","a36e4513":"dtc_cfl = DecisionTreeClassifier(random_state=1,max_depth=2)\n\ndtc_cfl.fit(X_train, y_train)\n\ny_predict = dtc_cfl.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","40ad856d":"dtc_cfl = DecisionTreeClassifier(random_state=1,max_depth=2)\n\ndtc_cfl.fit(X_train, y_train)\n\ny_predict = dtc_cfl.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","590b5be6":"xgb_cfl = xgb.XGBClassifier(n_jobs = -1, n_estimators = 100,max_depth=1)\nxgb_cfl.fit(X_train, y_train)\n\ny_predict = xgb_cfl.predict(X_train)\n\n# evaluate the model\nprint(classification_report(y_train, y_predict))\nprint(confusion_matrix(y_train, y_predict))","5f228c8f":"xgb_cfl = xgb.XGBClassifier(n_jobs = -1, n_estimators = 100 ,max_depth=1)\nxgb_cfl.fit(X_train, y_train)\n\ny_predict = xgb_cfl.predict(X_val)\n\n# evaluate the model\nprint(classification_report(y_val, y_predict))\nprint(confusion_matrix(y_val, y_predict))","37f3ed1b":"df_test['scaled_amount'] = rob_scaler.fit_transform(df_test['Amount'].values.reshape(-1,1))\ndf_test['scaled_time'] = rob_scaler.fit_transform(df_test['Time'].values.reshape(-1,1))\n\ndf_test.drop(['Time','Amount'], axis=1, inplace=True)","271b72a4":"X_test= df_test.drop([\"Class\"], axis = 1)\ny_test = df_test[\"Class\"]","bcd7ba5a":"from sklearn import svm","ceb7a162":"svm = svm.SVC(kernel='linear')\n\nsvm.fit(X_train, y_train)\n\ny_predict = svm.predict(X_test)\n\n# evaluate the model\nprint(classification_report(y_test, y_predict))\nprint(confusion_matrix(y_test, y_predict))","cd38f748":"LABELS = ['Normal', 'Fraud'] \nplt.figure(figsize =(8,8)) \nsns.heatmap(confusion_matrix(y_test, y_predict), xticklabels = LABELS, yticklabels = LABELS, annot = True, fmt =\"d\",  cmap=\"Blues\",annot_kws={\"size\": 20}); \nplt.title(\"Confusion matrix\",fontsize = 25) \nplt.ylabel('True class') \nplt.xlabel('Predicted class') \nplt.show()","1e238a29":"# XGBClassifier","a816602d":"### Val","a9e6906e":"### Train","b6dc378b":"* 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset.\n\n* 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning.\n\n* 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwis.","3689db24":"### val","48890292":"### Train","2ac3a651":"### Train","aaac57ae":"### val","740e1e3b":"# Stacking (xgb , log , rf)","dca00e0b":"# Stacking (xgb , log , knn)","93db8cb6":"### val","f5c470ba":"### val","a714bc73":"### Train","a40e1577":"# Credit Card Fraud Detection","5edc8e59":"### val ","b3682025":"### Train","1455f43b":"### After trying more than one model, it became clear that the best prediction model is the SVM model because we are interested in ( recall ).","24f310a2":"# RandomForestClassifier","9e0edbb4":"### StackingClassifier","ef2daecf":"# DecisionTreeClassifier","ba125a65":"### Headers","4f2efa66":"# KNeighborsClassifier","9194a296":"# Test","a9a8fce1":"### Train","0d30c929":"### val","c46d0725":"# Voting Classifier","97f12f5f":"### SVM ","7604482d":"### val","a63a3471":"The dataset contains transactions made by credit cards in September 2013 by European cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, \u2026 V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'.\n","2349d0a9":"### Fetchr engineering","7ba65e6e":"# Voting (xgb , log , knn)","6b7e2b22":"### val","6f5ef1ed":"# Models","7d764307":"### val","adcfca36":"### Train","1857ac98":"The main technical challenge it poses to predicting fraud is the highly imbalanced distribution between positive and negative classes in 284,807  thousand rows of data.","9cbded9e":"# ","1c3c8183":"# LogisticRegression","68e4e53f":"# ","bfb06d4b":"# Voting (xgb , dt , rf)","66701dff":"# BaggingClassifier","1ef79897":"### Problem statement","68119e79":"### Train - test splet","bc2919c8":"### Datasets : An Overview","22b7224e":"### Train","2e00909e":"### Train"}}