{"cell_type":{"27d9b5bb":"code","cd5b382e":"code","824e2763":"code","13f1758a":"code","1e01b520":"code","a866954e":"code","8a8ec49d":"code","726a4dc1":"code","76918120":"code","07f2129b":"code","3a366099":"code","178a8062":"code","ba9a7b22":"code","4a986de7":"code","e75638c3":"code","81bfbafd":"code","7da402f2":"code","80bc56d6":"code","3dd74748":"code","a2b0bc8e":"code","4c3417bd":"code","e8313ac5":"code","9d2ca5a3":"code","241e102a":"code","59133977":"code","08ec9297":"code","a35f9011":"code","75f87147":"code","375402dc":"code","06a91dc8":"code","5e705ea7":"code","19a2e4be":"code","2bad7d3e":"code","c01220cd":"code","8a8161f9":"code","c464166a":"code","c21e8663":"code","24c5679b":"code","edfc39ab":"code","5b1f514e":"code","56e2d7d2":"code","8605523a":"code","41ead98a":"code","8de93ecd":"code","df057e76":"code","b24ad300":"code","5f55195a":"code","b0301fec":"code","96b8ba89":"code","5361c361":"code","ef1868b2":"code","316c2d4e":"code","2611a42b":"code","9ee79bc0":"code","f5309e7d":"code","d007ee11":"code","e8589ffa":"code","ff4b8d42":"code","b6dff1bf":"code","8b42bfb1":"code","3737285a":"code","c482ac0b":"code","76471ff2":"code","cb29d576":"code","c880ab98":"code","7bb2c56f":"code","8a3c9ff9":"code","9c7ccf79":"code","3475850e":"code","d6db532b":"code","a005e3ed":"code","8e70a917":"code","1b627783":"code","67eed0e5":"code","fa6c7c68":"code","6394701e":"code","99a9e5d2":"code","a5dac41e":"code","5e53647f":"code","ec3a29d8":"code","5994d395":"code","29df5acb":"code","c5106965":"code","4e5c0d63":"code","0b437269":"code","691c918b":"code","bc73702f":"code","b006b6f1":"code","918ce505":"code","0fd4a204":"code","611ee758":"code","49c14296":"code","c10795ce":"code","ce47c1ee":"code","8d2c66f5":"code","ed08be6b":"code","5420ee17":"code","eca2af97":"code","e211495f":"code","89ee066a":"code","e5eca0ab":"code","90c90048":"code","8e7418e7":"code","bee46e17":"code","761e5bb6":"code","3a63ff30":"code","f50c2ba6":"code","ca520f48":"code","d5fb91dd":"code","fea4b6fb":"code","b7f04a1e":"code","55362706":"code","d2b6e0e4":"code","6ed4a329":"markdown","6b634f5b":"markdown","f57d6260":"markdown","c4260706":"markdown","1a2310b1":"markdown","4d42b642":"markdown","cad31799":"markdown","b1805a87":"markdown","e7073213":"markdown","e49f25b6":"markdown","6afc3cec":"markdown","87bc9daa":"markdown","27dc4e69":"markdown","4c913964":"markdown","c9b54d9d":"markdown","616effb8":"markdown","23c55878":"markdown","b0ca7d87":"markdown","637d37fc":"markdown","e81ce23f":"markdown"},"source":{"27d9b5bb":"import pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.preprocessing import LabelEncoder\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsRegressor\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import f1_score,plot_roc_curve,accuracy_score,roc_curve,roc_auc_score,recall_score\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.feature_selection import SelectFwe, f_regression","cd5b382e":"train= pd.read_csv('..\/input\/hr-analysis\/train.csv', sep= ',' , encoding= ' utf-8')\ntest= pd.read_csv('..\/input\/hr-analysis\/test.csv', sep= ',' , encoding= ' utf-8')\nsample=pd.read_csv('..\/input\/hr-analysis\/sample_submission.csv', sep=',' , encoding= ' utf-8')","824e2763":"train","13f1758a":"train.isna().sum()","1e01b520":"test.isna().sum()","a866954e":"train.apply(lambda x:len(x.unique()))\n## Apllying a lambda function on the dataset to return the lenght of every unique column.","8a8ec49d":"test.apply(lambda x:len(x.unique()))\n## Apllying a lambda function on the dataset to return the lenght of every unique column.","726a4dc1":"print('gender ',train['gender'].unique())\nprint('relevent_experience ',train['relevent_experience'].unique())\nprint('enrolled_university ',train['enrolled_university'].unique())\nprint('education_level ',train['education_level'].unique())\nprint('major_discipline ',train['major_discipline'].unique())\nprint('experience ',train['experience'].unique())\nprint('company_size ',train['company_size'].unique())\nprint('company_type ',train['company_type'].unique())","76918120":"\n\nround(train[\"gender\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))\n","07f2129b":"round(train[\"company_size\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1))\n\n","3a366099":"round(train[\"relevent_experience\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1))\n\n","178a8062":"round(test[\"gender\"].value_counts()\/test.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))","ba9a7b22":"round(test[\"company_size\"].value_counts()\/test.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1))","4a986de7":"round(test[\"relevent_experience\"].value_counts()\/test.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1))","e75638c3":"df = train.append(test)\n# Merging the train and test data on one Data Frame\ndf.apply(lambda x:len(x.unique()))\n## Apllying a lambda function on the dataset to return the lenght of every unique column.","81bfbafd":"round(df[\"gender\"].value_counts()\/df.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))\n\n","7da402f2":"round(df[\"company_size\"].value_counts()\/df.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1))\nplt.savefig(\"size.png\") # save as png\n","80bc56d6":"round(df[\"relevent_experience\"].value_counts()\/df.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1))","3dd74748":"df1=df.drop('target',axis=1)\ndf1.fillna(method=\"pad\", inplace=True)\ndf1.head()","a2b0bc8e":"round(df1[\"gender\"].value_counts()\/df1.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))\nplt.savefig(\"gender.png\") # save as png","4c3417bd":"sns.catplot(data=train, kind=\"count\", x=\"gender\",hue='target')\n","e8313ac5":"round(df1[\"company_size\"].value_counts()\/df1.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1))\nplt.savefig(\"size.png\") # save as png","9d2ca5a3":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"company_size\",height=6\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","241e102a":"round(df1[\"enrolled_university\"].value_counts()\/df1.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))\nplt.savefig(\"enrolled.png\") # save as png","59133977":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"enrolled_university\",height=4\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","08ec9297":"round(train[\"education_level\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1))\nplt.savefig(\"level.png\") # save as png","a35f9011":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"education_level\",height=5\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","75f87147":"round(train[\"major_discipline\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1))\nplt.savefig(\"dis.png\") # save as png","375402dc":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"major_discipline\",height=5\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","06a91dc8":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"experience\",height=5\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","5e705ea7":"sns.set_theme(style=\"darkgrid\")\n\nround(df1[\"relevent_experience\"].value_counts()\/df1.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1))\nplt.savefig(\"rel.png\") # save as png","19a2e4be":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"relevent_experience\",hue='target',height=6\n    ,aspect=2,)\n","2bad7d3e":"round(train[\"company_type\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1))\nplt.savefig(\"type.png\") # save as png","c01220cd":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"company_type\",height=5\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","8a8161f9":"train.fillna(method=\"pad\", inplace=True)\ntest.fillna(method=\"pad\", inplace=True)","c464166a":"train.isnull().sum()\n","c21e8663":"test.isnull().sum()","24c5679b":"test['gender'].fillna(test['gender'].mode()[0], inplace=True)\ntest['last_new_job'].fillna(test['last_new_job'].mode()[0], inplace=True)","edfc39ab":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"gender\",hue='target',height=5\n    ,aspect=1,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"gender1.png\") # save as png","5b1f514e":"train.replace('no_enrollment',0, inplace= True)\ntrain.replace('Full time course',1, inplace= True)\ntrain.replace('Part time course',0.5, inplace= True)","56e2d7d2":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"enrolled_university\",hue='target',height=5\n    ,aspect=1,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"enrolled1.png\") # save as png","8605523a":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"company_type\",hue='target',height=6\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"type1.png\") # save as png","41ead98a":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"experience\",hue='target',height=6\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"ex1.png\") # save as png","8de93ecd":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"relevent_experience\",hue='target',height=4\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"rel1.png\") # save as png","df057e76":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"education_level\",hue='target',height=4\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"level1.png\") # save as png","b24ad300":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"company_size\",hue='target',height=7\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n\nplt.savefig(\"size1.png\") # save as png","5f55195a":"sns.catplot(data=train, kind=\"count\", x=\"major_discipline\",hue='target',height=4\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"dis1.png\") # save as png","b0301fec":"from sklearn import preprocessing\n\n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder()\n\n# Encode labels in column 'housing','loan'. \nles = {}\nfor col in ['gender','company_size','city', 'relevent_experience','education_level','major_discipline','company_type','experience','last_new_job']:\n    les[col] = label_encoder\n    train[col]  = les[col].fit_transform(train[col])\ntrain.head()","96b8ba89":"from sklearn import preprocessing\n\n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder()\n\nles = {}\nfor col in ['gender','company_size','city', 'relevent_experience','education_level','major_discipline','company_type','enrolled_university',\n            'experience','last_new_job']:\n    les[col] = label_encoder\n    test[col]  = les[col].fit_transform(test[col])\ntest.head()","5361c361":"def normalize_col(col_name):\n    return (train[col_name] - train[col_name].min())\/(train[col_name].max()-train[col_name].min())\ntrain['company_size']=normalize_col('company_size')\ntrain['company_type']=normalize_col('company_type')\ntrain['training_hours']=normalize_col('training_hours')\ntrain['major_discipline']=normalize_col('major_discipline')\ntrain.head()\n","ef1868b2":"def normalize_col(col_name):\n    return (train[col_name] - train[col_name].min())\/(train[col_name].max()-train[col_name].min())\ntest['company_size']=normalize_col('company_size')\ntest['company_type']=normalize_col('company_type')\ntest['training_hours']=normalize_col('training_hours')\ntest['major_discipline']=normalize_col('major_discipline')\ntest.head()\n","316c2d4e":"train.drop(['enrollee_id','city', 'city_development_index'], axis=1,inplace=True)","2611a42b":"# linear crr\n\nplt.figure(figsize=(15,10))\nsns.heatmap(train.corr(),cbar = True, annot =True,cmap='twilight_shifted_r')\nplt.savefig(\"crr.png\") # save as png","9ee79bc0":"train.columns","f5309e7d":"train.head()","d007ee11":"print('relevent_experience ',train['relevent_experience'].unique())\nprint('enrolled_university ',train['enrolled_university'].unique())\n","e8589ffa":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x=\"gender\", y=\"experience\", hue=\"target\",\n                 data=train, palette=\"Set3\")\nplt.savefig(\"box.png\") # save as png","ff4b8d42":"train.shape\n","b6dff1bf":"train.columns","8b42bfb1":"X = train.drop('target',axis=1).values\nY = train['target'].values","3737285a":"# Split the dataset into training and testing.\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=1234)","c482ac0b":"print(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","76471ff2":"# Train and predict.\nLL = LogisticRegression(solver='liblinear')\nLL.fit(X_train,Y_train)\nY_pred_test = LL.predict(X_test)                            # Out-of-sample prediction. ","cb29d576":"# Confusion matrix.\nconf_mat = metrics.confusion_matrix(Y_test,Y_pred_test)\nprint(conf_mat)","c880ab98":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","7bb2c56f":"confusion_matrix(Y_test,LL.predict(X_test))","8a3c9ff9":"kclf = KNeighborsClassifier(n_neighbors=5,)\n#the distance metric to use for the tree. The default metric is minkowski, \n#and with p=2 is equivalent to the standard Euclidean metric","9c7ccf79":"kclf.fit(X_train,Y_train)","3475850e":"Y_pred_test = kclf.predict(X_test)                            # Out-of-sample prediction. ","d6db532b":"kclf.score(X_train,Y_train)","a005e3ed":"kclf.score(X_test,Y_test)","8e70a917":"confusion_matrix(Y_test,kclf.predict(X_test))","1b627783":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","67eed0e5":"svm = SVC()\nsvm.fit(X_train,Y_train)\nY_pred_test = svm.predict(X_test)                            # Out-of-sample prediction. ","fa6c7c68":"svm.score(X_test,Y_test)","6394701e":"svm.score(X_train,Y_train)","99a9e5d2":"confusion_matrix(Y_test,svm.predict(X_test))","a5dac41e":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","5e53647f":"gnb = GaussianNB()\ngnb.fit(X_train,Y_train)\ngnb.predict(X_test)\nY_pred_test = gnb.predict(X_test)                            # Out-of-sample prediction. ","ec3a29d8":"gnb.score(X_train,Y_train)","5994d395":"gnb.score(X_test,Y_test)","29df5acb":"confusion_matrix(Y_test,gnb.predict(X_test))","c5106965":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","4e5c0d63":"clf = RandomForestClassifier(max_depth=5000,max_features='auto')\nclf.fit(X_train,Y_train)\nY_pred_test=clf.predict(X_test)\nconfusion_matrix(Y_test,clf.predict(X_test))","0b437269":"print(\"random forest F1-score\",f1_score(Y_test,Y_pred_test))\nprint(\"random forest Recall: \",recall_score(Y_test,Y_pred_test))","691c918b":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","bc73702f":"param_grid ={\n    'max_depth': [10, 20, 30, 40],\n 'max_features': ['auto', 'sqrt'],\n 'n_estimators': [20, 40 ]\n}\n","b006b6f1":"clf = RandomForestClassifier(max_depth=10, n_estimators=20)\ngrid = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, n_jobs=-1,verbose=1)\ngrid_result = grid.fit(X_train, Y_train)\n# Summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","918ce505":"model=grid_result.best_estimator_","0fd4a204":"model","611ee758":"model_pre=model.predict(X_test)","49c14296":"accuracy_score(Y_test,model_pre)","c10795ce":"conf_mat=confusion_matrix(Y_test,model_pre)","ce47c1ee":"plot_confusion_matrix(conf_mat,class_names=[\"not suitable(0 or negative)\",\"suitable(1 or positive)\"],figsize=(12,5)); #fn","8d2c66f5":"plot_roc_curve(model, X_test, Y_test)","ed08be6b":"xgb= XGBClassifier(loss='exponential', learning_rate=0.05, n_estimators=1000, subsample=1.0, criterion='friedman_mse', \n                                  min_samples_split=2, \n                                  min_samples_leaf=5, min_weight_fraction_leaf=0.0, max_depth=10, min_impurity_decrease=0.0, \n                                  min_impurity_split=None, \n                                  init=None, random_state=None, max_features=None, verbose=1, max_leaf_nodes=None, warm_start=False, \n                                  presort='deprecated', \n                                  validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n                              \nxgb.fit(X_train, Y_train)","5420ee17":"Y_pred_test=xgb.predict(X_test)","eca2af97":"xgb.score(X_train,Y_train)","e211495f":"xgb.score(X_test,Y_test)","89ee066a":"xgb.score(X_train,Y_train)","e5eca0ab":"xgb.score(X_test,Y_test)","90c90048":"conf_mat=confusion_matrix(Y_test,xgb.predict(X_test))","8e7418e7":"plot_confusion_matrix(conf_mat,class_names=[\"not suitable(0 or negative)\",\"suitable(1 or positive)\"],figsize=(12,5)); #fn","bee46e17":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","761e5bb6":"cols=train.columns\ncols","3a63ff30":"X_train=train[cols[:len(cols)-1]]\nY_train=train['target']\nX_test=test[cols[:len(cols)-1]]","f50c2ba6":"target = 'target'\nscoring_parameter = 'balanced-accuracy'","ca520f48":"#pip install autoviml","d5fb91dd":"\ndef Xg_boost(Xtrain,Ytrain,Xtest):\n    xg = XGBClassifier(loss='exponential', learning_rate=0.05, n_estimators=1000, subsample=1.0, criterion='friedman_mse', \n                                  min_samples_split=2, \n                                  min_samples_leaf=5, min_weight_fraction_leaf=0.0, max_depth=10, min_impurity_decrease=0.0, \n                                  min_impurity_split=None, \n                                  init=None, random_state=None, max_features=None, verbose=1, max_leaf_nodes=None, warm_start=False, \n                                  presort='deprecated', \n                                  validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n    xg.fit(Xtrain, Ytrain) \n    xg_prediction = xg.predict(Xtest)\n    return xg_prediction\n","fea4b6fb":"pred_xg = Xg_boost(X_train,Y_train,X_test)\n","b7f04a1e":"pred_xg = Xg_boost(X_train,Y_train,X_test)\n","55362706":"sample['target'] = pred_xg\nprint(sample['target'].unique())\nsample.to_csv('XG.csv',index = False)","d2b6e0e4":"dict(sample['target'])","6ed4a329":"**` Getting The train and test data again after Filling for Encoding and Modelling `**","6b634f5b":"------------------------\n**`-2-  - KNN CLF`**\n----------------------","f57d6260":"## SO >>>> The most qualified applicant for the data analysis Internship :\n\n- Gender : Male ( There is gender equality despite of the number of male applicants is morevthan females but the targetting is nearly equvalent). This is shown in the boxplot above.\n\n- More than 20 years experience.\n\n- Has relevent experience.\n\n- Last job was at PVT LTD Company.\n\n- Not currently enrolled at University.\n\n- Major is STEM.\n\n- Graduated","c4260706":"- Finding The relation between Features and target after Filling","1a2310b1":"# Data Preprocessing","4d42b642":"-----------------------\n**`-4-  Navie Bayes`**\n--------------------","cad31799":"## Data Visaulization\n\n- Trainning data Visualization before Filling","b1805a87":"------------------------\n**` 1-LogisticRegression`**\n----------------------","e7073213":"## SO >>>> After Modelling I See that the XGBoost classifier gets the best results.","e49f25b6":"-----------------------\n**`-3-  SVM`**\n--------------------","6afc3cec":"-----------------------\n**`-7- XGBoost `**\n--------------------","87bc9daa":"**`Filling missing data by getting values from forward cells`**","27dc4e69":"## So >>> Trainning data, testing data and DataFrame have all the same visualization result , so we will copy the data frame and visualize all the features of the data at once.","4c913964":"## Encoding Data","c9b54d9d":"-----------------------\n**`-6- RandomForestClassifier with grid`**\n--------------------","616effb8":"- Data Frame Visualization before Filling","23c55878":"#pip install lightgbm\n","b0ca7d87":"#### There is only one Missing Data in both (gender and last new job) on test data so I will fill them with the mode. ","637d37fc":"-----------------------\n**`-5- Random Forest`**\n--------------------","e81ce23f":"- Testing data Visualization before Filling"}}