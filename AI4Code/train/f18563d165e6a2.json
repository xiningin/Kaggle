{"cell_type":{"766a4aad":"code","36f364c2":"code","053ae58a":"code","00778d21":"code","53bb0151":"code","a33ea4d1":"code","937019d3":"code","31d90dd7":"code","3f89965b":"code","e8df1f93":"code","addff470":"code","6112bc9d":"code","1e5eeb95":"code","1ec894ea":"code","f6d604f9":"code","818860d1":"code","3fa31232":"code","85cf8e09":"code","99cadbb0":"code","c6ef17af":"code","a0e1c1e6":"code","ea542291":"code","542fea67":"markdown","734b4ddc":"markdown","c8be990d":"markdown","b4eed08b":"markdown","c3cb9100":"markdown","23e239ef":"markdown","a8c0f048":"markdown","6179f354":"markdown","d7ad1aeb":"markdown","7760c3c7":"markdown","4ea270c0":"markdown","c8bf463c":"markdown","1067921f":"markdown","1d5eac87":"markdown","96942f1c":"markdown","848259cd":"markdown","47d128cb":"markdown"},"source":{"766a4aad":"import cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom random import shuffle\nfrom keras.regularizers import l1, l2\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Sequential, Model\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions, VGG16\nfrom keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, Input, SeparableConv2D","36f364c2":"data = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray')\ntrain_path = data \/ 'train'\ntest_path = data \/ 'test'\nval_path = data \/ 'val'","053ae58a":"train, test, val = [], [], []\nX_train, y_train, X_test, y_test, X_val, y_val = [], [], [], [], [], []","00778d21":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20, 20))\nsubplots = [ax1, ax2, ax3, ax4, ax5]\n\nj = 0\nfor i in (train_path \/ 'NORMAL').glob('*.jpeg'):\n    if j < 5:\n        subplots[j].imshow(cv2.imread(str(i), 0))\n        subplots[j].axhline(y=0.5, color='r')\n    j += 1\n\nplt.show()","53bb0151":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20, 20))\nsubplots = [ax1, ax2, ax3, ax4, ax5]\n\nj = 0\nfor i in (train_path \/ 'PNEUMONIA').glob('*.jpeg'):\n    if j < 5:\n        subplots[j].imshow(cv2.imread(str(i), 0))\n        subplots[j].axhline(y=0.5, color='r')\n    j += 1\n\nplt.show()","a33ea4d1":"i = 0\n\nfor h in [(train_path \/ 'NORMAL').glob('*.jpeg'), (train_path \/ 'PNEUMONIA').glob('*.jpeg')]:\n    for j in h:\n        i += 1\n        \n        img = cv2.imread(str(j), 0)\n        train.append(cv2.resize(img, (59536, 1))[0])\n        train.append(str(j))","937019d3":"train = np.array(train).reshape(-1, 2)\ntrain = np.array(pd.DataFrame(train).sample(frac=1).reset_index(drop=True))","31d90dd7":"for k in train:\n    if k[1][58] == 'N':\n        y_train.append(0)\n    else:\n        y_train.append(1)\n    X_train.append(k[0])\n    \nX_train = pd.DataFrame(np.array(X_train).T)","3f89965b":"i = 0\n\nfor h in [(test_path \/ 'NORMAL').glob('*.jpeg'), (test_path \/ 'PNEUMONIA').glob('*.jpeg')]:\n    for j in h:\n        i += 1\n        \n        img = cv2.imread(str(j), 0)\n        test.append(cv2.resize(img, (59536, 1))[0])\n        test.append(str(j))","e8df1f93":"test = np.array(test).reshape(-1, 2)\ntest = np.array(pd.DataFrame(test).sample(frac=1).reset_index(drop=True))","addff470":"for k in test:\n    if k[1].split('\/')[6] == 'NORMAL':\n        y_test.append(0)\n    else:\n        y_test.append(1)\n    X_test.append(k[0])\n    \nX_test = pd.DataFrame(np.array(X_test).T)","6112bc9d":"i = 0\n\nfor h in [(val_path \/ 'NORMAL').glob('*.jpeg'), (val_path \/ 'PNEUMONIA').glob('*.jpeg')]:\n    for j in h:\n        i += 1\n        \n        img = cv2.imread(str(j), 0)\n        val.append(cv2.resize(img, (59536, 1))[0])\n        val.append(str(j))","1e5eeb95":"val = np.array(val).reshape(-1, 2)\nval = np.array(pd.DataFrame(val).sample(frac=1).reset_index(drop=True))","1ec894ea":"for k in val:\n    if k[1].split('\/')[6] == 'NORMAL':\n        y_val.append(0)\n    else:\n        y_val.append(1)\n    X_val.append(k[0])\n    \nX_val = pd.DataFrame(np.array(X_val).T)","f6d604f9":"X_train","818860d1":"X_test","3fa31232":"X_val","85cf8e09":"X_train = X_train \/ 255.\nX_test = X_test \/ 255.\nX_val = X_val \/ 255.","99cadbb0":"X_train, y_train = np.array(X_train.T).reshape(5216, 244, 244, 1), np.array(y_train)\nX_test, y_test = np.array(X_test.T).reshape(624, 244, 244, 1), np.array(y_test)","c6ef17af":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","a0e1c1e6":"idg = ImageDataGenerator()\nidg.fit(X_train)\ntrain = idg.flow(X_train, y_train)\n\nidg1 = ImageDataGenerator()\nidg1.fit(X_test)\ntest = idg1.flow(X_test, y_test)","ea542291":"model = Sequential()\n    \nmodel.add(Conv2D(16, activation='relu', kernel_size=(2, 2), input_shape=(244, 244, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(16, activation='relu', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n    \nmodel.add(Conv2D(32, activation='relu', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, activation='relu', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n        \nmodel.add(Conv2D(64, activation='relu', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, activation='relu', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n    \nmodel.add(Conv2D(128, activation='relu', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, activation='relu', kernel_size=(2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n    \nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(2, activation='sigmoid'))\n\n    \ncheckpoint = ModelCheckpoint('vgg16_1.h5', monitor='val_acc')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.001)\n    \nmodel.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=SGD(lr=0.01))\nhistory = model.fit_generator(generator=train, validation_data=test, callbacks=[checkpoint, reduce_lr], epochs=10)\n    \nfor j in history.history:\n    plt.plot(history.history[j])\n    plt.title(str(j) + ' over epochs')\n    plt.ylabel(j)\n    plt.xlabel('epochs')\n    plt.show()","542fea67":"Subsequently, we'll augment the data by feeding it to an ImageDataGenerator. This is useful as the generator will provide more samples which are changed in random ways, eg. the images are flipped or cropped. This will stop the model from learning irrelavent pattern in our data.","734b4ddc":"The final thing we will do in this notebook is create a Convolutional Neural Network (CNN) which will be able to predict whether an X-Ray of a chest has pneumonia or not.\n* The **architecture** of the neural net is one with four hidden layers, all with an activation function of relu.\n* There are four **dropouts** with a value of 0.25 dropout rate.\n* The **output activation** function is sigmoid with the loss and metrics of the model being binary_crossentropy and accuracy. They are like this so that they can efficiently output the score of our neural network.\n* We also use the **callbacks** of ModelCheckpoint, which has a VGG16 transfer learning algorithm which monitors the validation accuracy and we have a ReduceLROnPlateau which monitors the validation loss and reduces the learning rate as it falls. These callbacks help stop overfitting within our model.","c8be990d":"# Collecting Validation data","b4eed08b":"# **Pneumonia prediction**\nGood day everyone! As I'm sure you are all aware, AI is a huge area which can massively benefit humankind. Therefore, we must put our minds together and create technologies which will help people. Technologies such as pneumonia prediction!","c3cb9100":"The first thing we will do is visualising the X-Ray scans of normal and pneumonic chests.","23e239ef":"# Collecting Train Data","a8c0f048":"# Collecting Test Data","6179f354":"# Predicting with our model","d7ad1aeb":"## Pneumonia\nHere are five images with pneumonia:","7760c3c7":"Then, the X's are rehaped into a size which are suitable to be given to our neural network, followed by the y's being converted to a binary class matrix through to_categorical.","4ea270c0":"### If you enjoyed this notebook and found it useful, please give it an upvote as it will help me make more of these in the future.","c8bf463c":"Now we will get started with assembling the train, test and validation data. We do this by looping over all the images provided for us in the folders and using the imread function from the cv2 library in order to convert the images to an array of numbers. Afterwards, the data is then shuffled as to make it seem more natural.","1067921f":"# Visualising images","1d5eac87":"Now the train, test and validation sets are normalized by diving them by 255. This is an essential piece of feature engineering when working with computer vision tasks.","96942f1c":"# Augmenting the data","848259cd":"Today we will be creating an AI which can predict whether a chest scanned by an X-Ray has pneumonia or not. This is important as it can help doctors around the world with their job of diagnosing patients with pneumonia so that they can get the help they need.","47d128cb":"## Normal\nHere are five images of chests without pneumonia:"}}