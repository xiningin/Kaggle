{"cell_type":{"fa40da5d":"code","df8df73c":"code","7298fc22":"code","3b123378":"code","56970f09":"code","f43b129d":"code","13af602b":"code","8fe696a6":"code","4527c36f":"code","614c8aa7":"code","b04a8b80":"code","32177d2b":"code","273e07cc":"code","fbcd1b99":"code","fb1f29df":"code","c4f65c19":"code","2423c491":"code","495b373a":"code","93e12265":"code","b659092b":"code","ae8fd04f":"code","8601608b":"code","65552689":"code","0cd39d5d":"code","5f81fbea":"code","61444db3":"code","535dd3b6":"code","b8779324":"code","b30a3788":"code","c5e3ce0a":"code","87f613c4":"markdown","8de8fdbd":"markdown","fc717c5d":"markdown","b0bcf77c":"markdown","770c632b":"markdown","9abf3aec":"markdown","9e938db6":"markdown","1e4e238f":"markdown","6f53355d":"markdown","97421d75":"markdown","746dee26":"markdown","974db218":"markdown","76b80549":"markdown","7a3b12e4":"markdown","89151c71":"markdown","599b6690":"markdown","b9187b71":"markdown","1aafa756":"markdown","41799a32":"markdown","95cba3ef":"markdown","6f3ee6ed":"markdown","29a4513f":"markdown","e0374676":"markdown","a6b9c463":"markdown","0f3d261b":"markdown"},"source":{"fa40da5d":"# Load necessary library\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport statsmodels.api as sm\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn')\n\nfrom wordcloud import WordCloud\n\n%matplotlib inline\n\n# set default plot size\nplt.rcParams[\"figure.figsize\"] = (15,8)","df8df73c":"# Load and preview data \nab_nyc = pd.read_csv(\"..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv\")\n\n\nab_nyc.head()","7298fc22":"# drop id and name columns\nab_nyc.drop(['id','name','host_id','host_name'],axis=1,inplace = True)\nab_nyc.describe()","3b123378":"# Check each column for nas\nab_nyc.isnull().sum()","56970f09":"# data cleanning\n# remove outliers for price and minimun nights column\n\nfrom scipy import stats\n\nab_nyc['z_price'] = np.abs(stats.zscore(ab_nyc['price']))\nab_nyc['z_min_nights'] = np.abs(stats.zscore(ab_nyc['minimum_nights']))\n\n# remove z scroe that are greater than 3\n\nab_nyc_final = ab_nyc[(ab_nyc['z_price'] < 3)]\nab_nyc_final = ab_nyc_final[(ab_nyc_final['price'] > 3)]\nab_nyc_final = ab_nyc_final[(ab_nyc['z_min_nights'] < 3)]\n\n# convert numneric variables into categorical variables\n\nab_nyc_final['minimum_nights_group'] = 'Others'\nab_nyc_final['minimum_nights_group'][ab_nyc_final['minimum_nights'] == 1] = 'one night'\nab_nyc_final['minimum_nights_group'][ab_nyc_final['minimum_nights'] == 2] = 'two nights'\nab_nyc_final['minimum_nights_group'][ab_nyc_final['minimum_nights'] == 3] = 'three nights'\nab_nyc_final['minimum_nights_group'][ab_nyc_final['minimum_nights'] == 4] = 'four nights'\nab_nyc_final['minimum_nights_group'][ab_nyc_final['minimum_nights'] > 4] = 'five nights or more'\n# ab_nyc_final.groupby('minimum_nights_group').size()\n\nab_nyc_final['calculated_host_listings_count_group'] = 'Others'\nab_nyc_final['calculated_host_listings_count_group'][ab_nyc_final['calculated_host_listings_count'] == 1] = 'one listing'\nab_nyc_final['calculated_host_listings_count_group'][ab_nyc_final['calculated_host_listings_count'] == 2] = 'two listings'\nab_nyc_final['calculated_host_listings_count_group'][ab_nyc_final['calculated_host_listings_count'] > 2] = 'more than two listings'\n\n\n# ab_nyc_final.groupby('calculated_host_listings_count_group').size()\n","f43b129d":"# remove unused columns\nab_nyc_final.drop(['z_price','z_min_nights','minimum_nights','last_review','neighbourhood',\n                   'calculated_host_listings_count','reviews_per_month'],\n                  axis = 1,inplace = True)\nab_nyc_final.head()","13af602b":"ab_nyc_final.describe()","8fe696a6":"ab_nyc_cor = ab_nyc_final.drop(['latitude','longitude'],axis=1).corr()\nab_nyc_cor","4527c36f":"# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(ab_nyc_cor, dtype=np.bool))\n\n# Set up the matplotlib figure\nfig, ax = plt.subplots(figsize=(15, 8))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(ab_nyc_cor, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot = True)","614c8aa7":"import plotly.express as px\n\nlat = np.mean(ab_nyc_final['latitude'])\nlon = np.mean(ab_nyc_final['longitude'])\n\n\nfig = px.density_mapbox(ab_nyc_final, lat='latitude', lon='longitude', z='price', radius=2,\n                        center=dict(lat = lat, lon = lon), zoom=10,\n                        mapbox_style=\"carto-positron\")\nfig.show()","b04a8b80":"ab_nyc_final.groupby(['neighbourhood_group'])['price','number_of_reviews','availability_365'].agg(['count', 'mean','median'])\n\n# ab_nyc_final.groupby(['neighbourhood_group']).agg({\n#     'price': ['mean', 'count', 'median'], \n#     'number_of_reviews': ['mean', 'count', 'median'],\n#     'availability_365': ['mean', 'count', 'median']\n# })","32177d2b":"# boxplot of neighbourhood group and price\n# entire home\/apt have the highest median price over other room types\n# manhattan entire home\/apt have the highest median price\nsns.boxplot(x=\"neighbourhood_group\", y=\"price\",hue = \"room_type\",data=ab_nyc_final)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","273e07cc":"# manhattan and brooklyn private room have the lowest availability\/highest demand overall\nsns.boxplot(x=\"neighbourhood_group\", y=\"availability_365\",hue = \"room_type\",data=ab_nyc_final)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","fbcd1b99":"# four nights minimum are the most popular\nsns.boxplot(x=\"minimum_nights_group\", y=\"availability_365\",data=ab_nyc_final,\n            order = ['one night','two nights','three nights','four nights','five nights or more'])","fb1f29df":"sns.boxplot(x=\"minimum_nights_group\", y=\"price\",data=ab_nyc_final,\n            order = ['one night','two nights','three nights','four nights','five nights or more'])","c4f65c19":"sns.pairplot(ab_nyc_final.drop(['latitude','longitude'],axis=1))","2423c491":"ab_nyc_model = ab_nyc_final.drop(['latitude','longitude'],axis = 1)\nab_nyc_model.head()","495b373a":"# Building the model\n# first convert categorical variables to dummy variables using one hot encoding\n\ncategorical_var = ['neighbourhood_group','room_type','minimum_nights_group','calculated_host_listings_count_group']\n\n# create dummy variables for all the other categorical variables\n\nfor variable in categorical_var:\n# #     fill missing data\n#     recruit[variable].fillna('Missing',inplace=True)\n#     create dummy variables for given columns\n    dummies = pd.get_dummies(ab_nyc_model[variable],prefix=variable)\n#     update data and drop original columns\n    ab_nyc_model = pd.concat([ab_nyc_model,dummies],axis=1)\n    ab_nyc_model.drop([variable],axis=1,inplace=True)\n\nab_nyc_model.head()","93e12265":"x = ab_nyc_model.drop(['availability_365'], axis=1)\ny = ab_nyc_model['availability_365'].astype(float)\n\n# split train and test dataset\ntrain_x, test_x, train_y, test_y = train_test_split(x,y , test_size=0.3, random_state=42)\n\nprint(train_x.shape)\nprint(train_y.shape)\n\nprint(test_x.shape)\nprint(test_y.shape)","b659092b":"# training using statmodel\n\nlinear_model_sm = sm.OLS(train_y,sm.tools.add_constant(train_x).astype(float))\nresults_sm = linear_model_sm.fit()\nprint(results_sm.summary())","ae8fd04f":"# using sklearn\n\nlinear_model_sk = LinearRegression()  \nlinear_model_sk.fit(train_x, train_y)\nlinear_model_sk.score(test_x, test_y)","8601608b":"pred_y = linear_model_sk.predict(test_x)\ndf = pd.DataFrame({'Actual': test_y, 'Predicted': pred_y})\ndf.head(30)","65552689":"# random forest regressor for non-linear regression\n\nrf_regressor = RandomForestRegressor(n_estimators=100,random_state=0)\nrf_regressor.fit(train_x,train_y)","0cd39d5d":"rf_regressor.score(train_x,train_y)","5f81fbea":"feature_importance = pd.Series(rf_regressor.feature_importances_,index=x.columns)\nfeature_importance = feature_importance.sort_values()\nfeature_importance.plot(kind='barh')","61444db3":"# parameter tunning\n# # of trees trained parameter tunning\n\nresults_rf = []\nn_estimator_options = [30,50,100,200,500,1000,2000]\n\nfor trees in n_estimator_options:\n    model = RandomForestRegressor(trees,oob_score=True,n_jobs=-1,random_state=42)\n    model.fit(train_x,train_y)\n    print(trees,\" trees\")\n    score = model.score(train_x,train_y)\n    print(score)\n    results_rf.append(score)\n    print(\"\")\n\npd.Series(results_rf,n_estimator_options).plot()\n\n# use 500 trees","535dd3b6":"# max number of features parameter tunning\nresults_rf = []\nmax_features_options = ['auto',None,'sqrt','log2',0.9,0.2]\n\nfor max_features in max_features_options:\n    model = RandomForestRegressor(n_estimators=500,oob_score=True,n_jobs=-1,\n                                  random_state=42,max_features=max_features)\n    model.fit(train_x,train_y)\n    print(max_features,\" option\")\n    score = model.score(train_x,train_y)\n    print(score)\n    results_rf.append(score)\n    print(\"\")\n\npd.Series(results_rf,max_features_options).plot(kind='barh')\n\n# use auto option","b8779324":"# final model using the parameter tuning\nrf_regressor = RandomForestRegressor(n_estimators=500,oob_score=True,n_jobs=-1,\n                                  random_state=42,max_features='auto')\nrf_regressor.fit(train_x,train_y)\nrf_regressor.score(train_x,train_y)","b30a3788":"pred_y = rf_regressor.predict(test_x)\ndf = pd.DataFrame({'Actual': test_y, 'Predicted': pred_y})\ndf.head(30)","c5e3ce0a":"fig, ax = plt.subplots()\nax.scatter(test_y, pred_y)\nax.plot([test_y.min(), test_y.max()], [test_y.min(), test_y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","87f613c4":"Then we check na for each column, most of the columns doesn't have na other than the **last_review** and **reviews_per_month** for those listing properties doesn't have any reviews.","8de8fdbd":"*Boxplot of minimum nights group with availability*\n\nFour nights minimum are the most popular overall.","fc717c5d":"This will be our final dataset to fit the model.\n\nThen we split the dataset into training and testing dataset with 70\/30 split. We'll use the regression module in both `statsmodels` and `sklearn`","b0bcf77c":"#### Parameter Tuning\n\nWe want to tune the parameter for the random forest regressor to optimize the results.\n\n##### n_estimator_options tunning\n\nWe will choose 500 trees based on the plot because after 500 trees, the model score increase is flattened.","770c632b":"![](https:\/\/d1.awsstatic.com\/product-marketing\/rds\/airbnb_horizontal_lockup_web.bd87ed2c8e964eb35463744e07a1a0670177bda2.png)\n\n# 2019 Airbnb NYC Availability Prediction\n\n## Introduction\n\nThe data from this analysis is from [Kaggle New York City Airbnb Open Data](https:\/\/www.kaggle.com\/dgomonov\/new-york-city-airbnb-open-data). The dataset describes the listing activity and metrics in NYC, NY for 2019. It includes information such as the location of the listing properties, the neighbourhood of the properties, room type, price, minimum nights required, customer reviews and availability of the listing.\n\nThe purpose of this analysis is to perform exploratory data analysis as well as data visualization to understand how different factors influence the demand of the listing properties on Airbnb and ultimately using machine learning techniques to make predictions on the availability of the listing properties.\n\nThe following questions will be answered in the course of this analysis:\n\n- Where are most of the properties listed and where is the busiest areas?\n- What type of rooms are most popular?\n- How are different area\/neighbourhood affect the listing property price and demands?\n- What are the most important factors when customer choose an airbnb property?\n    - Price\n    - Location\n    - Room Type\n    - Customer Review\n\n## Data Loading and preprocessing\n\nWe start the analysis by importing necesssary libraries and loading the data.\nThe libraries used in this analysis are:\n\n- pandas\n- numpy\n- matplotlib\n- seaborn\n- sklearn\n- statsmodels","9abf3aec":"To see which feature have the most influence, the bar plot below plots each features from the most significant to the least.\n\nWe can see that the **price** and **number_of_review** have the most influence on availability of the listing.","9e938db6":"Clean the dataset by removing intermediate columns, we get the final data for exploratory data analysis and visualization.","1e4e238f":"## Data Visualization\n\nFor data visualization, we start with plotting a correlation matrix to explore the correlation between each numeric variable using `corr()` function. then we plot it using seaborn heatmap.","6f53355d":"The last visualization we will use `pairplot` in seaborn to explore the distribution and correlation of all numeric variables. As we seen earlier, there's no strong linear correlation between each individual variable. However, we can see that there might be some non-linear correlation between price\/number of review.","97421d75":"Then we want to remove the outliers for **price** and **minimum_nights** column. we calculate z score for both column and remove all records that have a z score greater than 3.\n\nFor the columns that are highly skewed, for example **number_of_reviews** and **calculated_host_listings_count**, we transfer them into categorical variable. Based on the summary statistics, we can see that the first 25 percentile of **minimum_nights** are 1, the median is 3 and the 75% percentile is 5, an reasonable categorization would be one night, two nights, three nights, four nights and five nights or more. Then we check we have enough and evenly distributed values in each of the group using `groupby()` and `size()`.\n\nWe'll do the same for **calculated_host_listings_count** and transfer the column into one listing, two listing and more than two listing.","746dee26":"To further explore how location affect listing properties, the following code calculate the mean and median for **price**, **number_of_reviews** and **availability_365**.\n\nWe can see that Manhattan has the most listing and the highest median price, followed by Brooklyn. However, Brooklyn have a higher demand than Manhattan as the **availability_365** mean and median is the lowest.","974db218":"### Random Forest Regressor\n\nRandom forest is a popular machine learning techniques that can not only be used in classification problems, but also be used in regression problems. To make random forest uniques is that it can also be used to fit non-linear relationship.\n\n#### Initial Model\n\nWe first start an instance of the model with a randomly chosen parameters. These prameters will later be tuned to yield optimized results.","76b80549":"##### max_features_options tunning\n\nWe will choose auto option.","7a3b12e4":"The random forest has a score of 0.77, which is significantly higher than linear regression.","89151c71":"Then we will use `boxplot` to visualize the median by different categorical variables to explore how the price and availabilty differ between groups\n\n*Boxplot of neighbourhood group and room type with price*\n\n- Entire home\/apt have the highest median price over other room types, followed by Private room and shared room, as expected\n- Manhattan entire home\/apt have the highest median price, followed by Brooklyn\n","599b6690":"After we load in the data, we used `describe` to get a summary statistics of the numeric data. We can see that the data need some cleanning. There are some outliers for **price** and **minimum_nights**. Other columns such as **number_of_reviews** and **calculated_host_listings_count** are highly right skewed, so that we might need to transfer them into categorical variables.\n\nFirst we need to drop a few columns from the dataset that are not useful.","b9187b71":"#### Multiple Linear Regression using Sklearn\n\nThen we fit the regression using Sklearn, the result is similar with a low model score of 0.23. this suggest that maybe the data doesn't fit a linear relationship because the prediction have a high variance from the actual value. We may need to try to use other non-linear regression techniques.","1aafa756":"#### Model Prediction\n\nThe following output shows the actual and the predicted value.","41799a32":"## Conclusion\n\nThrough this analysis, we have a better idea on the key factors that influences the demand of an airbnb listing property. Tourists\/customers prefer location close to downtown, lower price and entire room which offers them more privacy when touring the city. These can all be taken into consideration for airbnb hosts when posting their properties online.\n","95cba3ef":"#### Multiple Linear Regression using Statsmodels\n\nAfter fitting the model, we can see that the R square is 0.23, which is not very high, given that all of the variables are significant with a p value less than 0.05.\n\nLooking at the coefficients, we can see that both price and number_of_review is positive, which means the higher both these two are, the least demand for the listing property will be. Manhattan and Brooklyn have a negative coefficient, which means properties in these two locations have a higher demand. Additionally, entire roo,\/apt is the most popular room type.","6f3ee6ed":"## Model Building\n\nThe ultimate goal of this analysis is to predict the availability of a listing property based on its location, price and other metrics. We will try different regression to fit the data and find out which model best fit the data and make the most accurate prediction.\n\n### Multiple Linear Regression\n\nThe first regression method used is multiple linear regression.\n\nBefore fitting the model, we need to transfer the categorical variables into binary using **one hot encoding**.","29a4513f":"*Boxplot of minimum nights group with price*\n\nOne nights minimum is the most cheapest overall.","e0374676":"From the plot, we can see that there's no strong correlation between each numeric variables. No correlation coefficient greater than 0.7.\n\nThen we want to plot all the listing properties on the map to see where the most properties located and how their price differs.\n\nFor this task, we used `plotly` and `density_mapbox` by passing latitude, longitude and price.\n\nFrom the plot, we can see that as expected, most properties are in Manhattan, on the south side of the Central Park, and also on the north side of Brooklyn around Willamsburg Bridge. These location offers the most convenient transportation for the tourists in that they are either in Manhattan or near it. By looking at the price, these locations also have the highest prices.","a6b9c463":"#### Final Model\n\nBased on the parameter tunning, we will use `n_estimators=500` and `max_features='auto'` to fit the random forest regressor. The final model has a score of 0.78 ","0f3d261b":"*Boxplot of neighbourhood group and room type with availability*\n\n- Brooklyn entire home\/apt have the lowest availability\/highest demand, followed by Manhattan's entire home\/apt\n- Staten Island properties have the lowest demand\n- The most popular\/high demand room type is private room and entire home\/apt in most locations other than Staten Island and Bronx"}}