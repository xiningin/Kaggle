{"cell_type":{"d6a7be54":"code","fd22f07b":"code","0e623281":"code","4f773a1e":"code","77938224":"code","80cbf060":"code","cd444c6d":"code","96b431b9":"code","41b28901":"code","3070b469":"code","ff533d89":"code","004228e9":"code","9d63c910":"code","b561b650":"code","d6d8dd91":"code","f7eec719":"code","2beb828e":"code","50f00aad":"code","926aa078":"code","4e968c72":"code","95099d7f":"code","120b6b0d":"code","4193a028":"code","10a77522":"code","be27aa64":"code","6a2c190a":"code","75cca63a":"code","6ad54ba5":"code","8bc907ac":"code","8a837ef8":"markdown","d0d6b542":"markdown","f24251b7":"markdown","4aa0d37d":"markdown","afa3d328":"markdown","144d3189":"markdown","4abcef27":"markdown","06ed855c":"markdown","eea7e9fa":"markdown","b13ef850":"markdown","12c6a614":"markdown","51556700":"markdown","dd2fcd09":"markdown","f58b5b1f":"markdown","ef252cbb":"markdown","b62de26b":"markdown","06a7c4eb":"markdown","5083502f":"markdown","ae093d9a":"markdown","b081df48":"markdown","74e2ccfa":"markdown","b617baff":"markdown","09c2278f":"markdown","9fcf31dc":"markdown","a9bf184f":"markdown","421faa06":"markdown","278bd6fe":"markdown"},"source":{"d6a7be54":"import time\nfrom time import perf_counter as timer\nstart = timer()","fd22f07b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow as imshow\nimport seaborn as sns\nimport warnings\nfrom sklearn.preprocessing import LabelBinarizer\nfrom skimage import exposure","0e623281":"train = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ntest = pd.read_csv('..\/input\/fashion-mnist_test.csv')\ntrain.head(8)","4f773a1e":"train.shape","77938224":"labels = train['label'].values\nlabels[0:10]","80cbf060":"unique_val = np.array(labels)\nnp.unique(unique_val)","cd444c6d":"plt.figure(figsize = (18,8))\nsns.countplot(x =labels)","96b431b9":"label_binrizer = LabelBinarizer()\nlabels = label_binrizer.fit_transform(labels)\nlabels","41b28901":"train.drop('label', axis = 1, inplace = True)","3070b469":"images = train.values\nprint(images.dtype, np.round(images.min(), 4), np.round(images.max(), 4), images.shape)","ff533d89":"def plot_10(imgs):\n    plt.style.use('grayscale')\n    fig, axs = plt.subplots(2, 5, figsize=(15, 6), sharey=True)\n    for i in range(2): \n        for j in range(5):\n            axs[i,j].imshow((225-images[5*i+j]).reshape(28,28))\n    fig.suptitle('Grayscale images:\\n a Pullover,   an Ankle boot,   a Shirt,   a T-shirt\/top,   a Dress,\\n' +\n            'a Coat,   a Coat,    a Sandal,    a Coat,   a Bag')\n\nplot_10(images)","004228e9":"images = images\/255","9d63c910":"new_images = np.zeros((10, 784))\nfor i in range(10):\n        new_images[i,:]= exposure.rescale_intensity(images[i, :], in_range=(0.045, 0.955))\n        \nplot_10(new_images)","b561b650":"warnings.simplefilter('once')\nfor i in range(10):\n        new_images[i,:]= exposure.equalize_hist(images[i, :].reshape(28, 28), nbins=100).flatten() #, clip_limit=0.03, nbins=200\n\nplot_10(new_images)","d6d8dd91":"new_images = np.zeros((10, 784))\nfor i in range(10):\n        new_images[i,:]= exposure.adjust_gamma(images[i, :])\n        \nplot_10(new_images)","f7eec719":"def my_prep(x):\n    x = exposure.adjust_gamma(x)\n    return x\n\nimages = np.apply_along_axis(my_prep, 1, images)\nimages.shape","2beb828e":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(images, labels, stratify = labels, test_size = 0.2)","50f00aad":"x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","926aa078":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator","4e968c72":"num_classes = 10\nbatch_size = 500\nepochs = 100","95099d7f":"img_rows, img_cols = 28, 28\n\nmodel = Sequential()\nmodel.add(Conv2D(160, kernel_size=(6, 6),\n                 padding = \"same\",\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 input_shape=(img_rows, img_cols ,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (4, 4), padding = \"same\", activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(128, (3,3), padding = \"same\", activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adamax(),#keras.optimizers.Nadam()\n              metrics=['accuracy'])","120b6b0d":"train_datagen = ImageDataGenerator(shear_range = 0.1,\n                                   zoom_range = [.95, 1.0],\n                                   rotation_range = 10,\n                                   horizontal_flip = True,\n                                   fill_mode = 'constant', cval = 0,\n                                   brightness_range = [.6, 1],\n                                   width_shift_range = [ -2, -1, 0, +1, +2],\n                                   height_shift_range = [-1, 0, +1])\ntest_datagen = ImageDataGenerator()","4193a028":"history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, verbose=2, batch_size=batch_size)","10a77522":"plt.style.use('tableau-colorblind10')\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.ylim(0.85, 0.98)\nplt.title(\"Accuracy\")\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['train','test'])\nplt.show()","be27aa64":"fig = plt.hist(history.history['val_acc'][60:], bins=8)\n# when you want to run this code quickly with fewer epochs\n#plt.hist(history.history['val_acc'], bins=8)\nfig = plt.figure()\nfig.savefig('plot.png')","6a2c190a":"test_labels = test.iloc[:, 0]\ntest.drop('label', axis = 1, inplace = True)\ntest_images = test.values\/255\ntest_images = np.apply_along_axis(my_prep, 1, test_images)\nlabels_as_array = label_binrizer.fit_transform(test_labels)\ntest_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\ntest_images.shape","75cca63a":"y_pred = model.predict(test_images).round()\nfrom sklearn.metrics import accuracy_score\naccuracy_score(labels_as_array, y_pred)","6ad54ba5":"from sklearn.metrics import confusion_matrix\nclass_names = ['T-shirt\/top',  'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\ncm = pd.DataFrame(confusion_matrix(test_labels.values, label_binrizer.inverse_transform(y_pred)))\ncm.assign(Classes = class_names)","8bc907ac":"end = timer()\nelapsed_time = time.gmtime(end - start)\nprint(\"Elapsed time:\")\nprint(\"{0} minutes {1} seconds.\".format(elapsed_time.tm_min, elapsed_time.tm_sec))","8a837ef8":"The the functions do not help much, although do not spoil our results as well. I will apply the first one just to show how it is done. Using numpy method to apply a function to each row is much more efficient than a loop.","d0d6b542":"Let's validate with the test data. At first it must be brought to the same format so I apply the same preprocessing as I did with our data for model fitting. It means that its label column must be removed and rows must be reshaped as square arrays, and applying the same image modification (I mean my_prep function).","f24251b7":"Setting a number of classes,  a batch size and a number of epochs.","4aa0d37d":"Now I drop the label column from the 'train' set and will work with the rest of data.","afa3d328":"As we see a shirt and a t-shirt are the most confused items.\n\n### My time count","144d3189":"Here goes the CNN in all its glory!","4abcef27":"As you can see all output numbers are about the same.\n\nFor our CNN network  I'm to create an output array with Label Binarizer from the labels.","06ed855c":"See it running!","eea7e9fa":"This part is for image augmentation during model fitting.","b13ef850":"At this point we can transform our data as numpy array, look at its data type, range and dimensions.","12c6a614":"A coat and a shirt do not differ much.  The only difference I see is that a coat has more or less horisontal straight hem, and a shirt has a rounded one. This means that a difference is an outline.  \n\nI wanted to see if you can preprosses images in some way to enchance recognition, and I found the `skimage` package which is supposed to do this.  For it our numbers must be in [0, 1] range, so I'm scaling them now. I need to do it for CNN anyway. I will try 3 kind of preprocessing. ","51556700":"Is our data balanced?","dd2fcd09":"For validation during a model fitting we need to divide our train set in two parts. I did not set a random state parameter because there are a lot of randomly generated values in CNN anyway, and I wanted to see how my results will change with each run.","f58b5b1f":"## Content\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\nFor more detail look here: [https:\/\/www.kaggle.com\/zalando-research\/fashionmnist](https:\/\/www.kaggle.com\/zalando-research\/fashionmnist)","ef252cbb":"Let us look in more detail.","b62de26b":"Our 'train' set is reworked to reduce a data size. In particular all images are in grayscale and their sizes are 28 * 28 pixels. I will show pictures  in a few steps.","06a7c4eb":"This type of computations may be long, so I start with timer setting to know how much time the script will take.","5083502f":"Importing necessary modules:","ae093d9a":"## Convolutional Neural Network Model, or CNN\nFor CNN I am using keras library here.","b081df48":"# Convolutional Neural Networks with Additional Preprocessing and Image Augmentation","74e2ccfa":" ## Data Load and Check","b617baff":"I would like to see a historgram of computed validated accuracies.","09c2278f":"And for a moment of truth: checking predictions on a test set. Here are predictions and an accuracy on our provided test set. An accuracy for another run of the provided script may fluctuate due to randomness of applyed methods. The above histogram is likely to reflect possible changes.","9fcf31dc":"Let us see provided images using first 10 rows. ","a9bf184f":"Now I need to reshape our rows as square tables because I want to use a Convolution Neural Network method.","421faa06":"You can see below how accuracy values improve with each epoch.","278bd6fe":"## Data Object Preparation and Outcome Balance Check\nLet us create arrays for keras from our data. At first I take a look at labels."}}