{"cell_type":{"5fd7eb97":"code","6099827c":"code","979dc9d3":"code","13b129f0":"code","80e0464c":"code","c619783d":"code","b72747b9":"code","1e35430b":"code","f122fb86":"code","dffa091a":"code","33122488":"code","48752ae2":"code","22ac5682":"code","221ba4be":"code","e8e6797e":"code","eac020af":"code","8fe6e807":"code","c4dfe535":"code","4ed767b8":"code","73d222ff":"code","6d9cf278":"code","54632c88":"code","ba292abd":"code","73569f9a":"code","f9ebf914":"code","acb16a84":"code","aa1e654e":"code","a975771d":"code","029a56f9":"code","f932206a":"code","bfc56589":"code","7eb5e5ac":"code","a615ab6d":"code","2ec3e282":"code","d99ae53e":"code","33e12474":"code","08bf6f03":"markdown","989a3441":"markdown","d446bbcc":"markdown","c8f38bdb":"markdown"},"source":{"5fd7eb97":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMClassifier\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score","6099827c":"train = pd.read_csv('..\/input\/jantahack-cross-sell-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/jantahack-cross-sell-prediction\/test.csv')","979dc9d3":"train.head()","13b129f0":"test.head()","80e0464c":"train.info()","c619783d":"train[\"Region_Code\"].nunique()","b72747b9":"train[\"Vehicle_Age\"].value_counts()","1e35430b":"sns.distplot(train[\"Annual_Premium\"],bins=40)","f122fb86":"train[\"Annual_Premium\"] = np.log(train[\"Annual_Premium\"])\ntest[\"Annual_Premium\"] = np.log(test[\"Annual_Premium\"])\nsns.distplot(train[\"Annual_Premium\"])","dffa091a":"sns.heatmap(train.drop('id',axis=1).corr(),cmap='coolwarm')","33122488":"print(train[\"Response\"].value_counts())\nsns.countplot(train[\"Response\"])","48752ae2":"concat_df = pd.concat([train,test],axis=0)","22ac5682":"sns.pairplot(concat_df.drop(\"id\",axis=1))","221ba4be":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler","e8e6797e":"#label encoding for Gender\nen = LabelEncoder()\nconcat_df[\"Gender\"] = en.fit_transform(concat_df[\"Gender\"])\n#label encoding for Vehicle_Damage\nen = LabelEncoder()\nconcat_df[\"Vehicle_Damage\"] = en.fit_transform(concat_df[\"Vehicle_Damage\"])\n# Frequency encoding for Vehicle Age\nf = concat_df.groupby(concat_df[\"Vehicle_Age\"]).size()\/len(concat_df)\nconcat_df[\"Vehicle_Age\"] = concat_df[\"Vehicle_Age\"].apply(lambda x: f[x])","eac020af":"concat_df.head()","8fe6e807":"train_feat = concat_df[pd.isnull(concat_df[\"Response\"])==False].drop(\"Response\",axis=1)\ntrain_targets = concat_df[pd.isnull(concat_df[\"Response\"])==False][\"Response\"]\ntest_feat = concat_df[pd.isnull(concat_df[\"Response\"])==True]","c4dfe535":"train_feat.drop(\"id\",axis=1,inplace=True)\ntest_feat.drop([\"id\",\"Response\"],axis=1,inplace=True)","4ed767b8":"from sklearn.model_selection import train_test_split","73d222ff":"train_feat[\"Region_Code\"]=train_feat[\"Region_Code\"].astype(int)\ntrain_feat[\"Policy_Sales_Channel\"]=train_feat[\"Policy_Sales_Channel\"].astype(int)\ntest_feat[\"Region_Code\"]=test_feat[\"Region_Code\"].astype(int)\ntest_feat[\"Policy_Sales_Channel\"]=test_feat[\"Policy_Sales_Channel\"].astype(int)","6d9cf278":"X_train,X_val,Y_train,Y_val = train_test_split(train_feat,train_targets,test_size=0.3,random_state=101)","54632c88":"lgb = LGBMClassifier(boosting_type='gbdt',n_estimators=500,max_depth=7,learning_rate=0.04,objective='binary',metric='auc',is_unbalance=True,\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=101,n_jobs=-1)","ba292abd":"lgb.fit(X_train,Y_train)","73569f9a":"print(roc_auc_score(Y_val,lgb.predict_proba(X_val)[:,1]))","f9ebf914":"pred2 = lgb.predict_proba(test_feat)[:,1]","acb16a84":"from xgboost import XGBClassifier","aa1e654e":"xgb = XGBClassifier(objective='binary:logistic',boosting_type = 'gbdt',n_estimators=400,max_depth=8,learning_rate=0.04,metric='auc',\n                   colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=101,n_jobs=-1)","a975771d":"xgb.fit(X_train,Y_train)","029a56f9":"print(roc_auc_score(Y_val,xgb.predict_proba(X_val)[:,1]))","f932206a":"pred1 = xgb.predict_proba(test_feat)[:,1]","bfc56589":"from catboost import CatBoostClassifier","7eb5e5ac":"cat = [\"Gender\",\"Driving_License\",\"Region_Code\",\"Previously_Insured\",\"Vehicle_Damage\",\"Policy_Sales_Channel\"]","a615ab6d":"cbc = CatBoostClassifier(n_estimators=1000,l2_leaf_reg=2,custom_metric=['AUC','Logloss'],learning_rate = 0.04,cat_features=cat,max_depth=8,eval_metric=\"AUC\")","2ec3e282":"cbc.fit(X_train,Y_train,eval_set=(X_val,Y_val),early_stopping_rounds=20)","d99ae53e":"pred = cbc.predict_proba(test_feat)[:,1]","33e12474":"n_pred = (5*pred+pred1+pred2)\/7\ndf = pd.DataFrame({'id':test[\"id\"],'Response':n_pred})\ndf.to_csv('result2.csv',index=False)","08bf6f03":"The model building approach is as follows. We apply lgbm, xgboost and catboost classifiers and then take a weighted average of their predicted probability. This approach gives a public leaderboard score of 84.85","989a3441":"We observe a skewness in the data. Therefore we apply log transformation.","d446bbcc":"# Data Preparation","c8f38bdb":"# EDA"}}