{"cell_type":{"401bd334":"code","082eec3a":"code","ef1698a9":"code","1d34adad":"code","a2f326c3":"code","9f9c582a":"code","41fb1a2d":"code","5117babe":"code","d6696893":"code","34a7b41d":"code","01d4b2d8":"code","1a2bdc08":"code","ead20fa1":"code","f64067f8":"code","e979feb8":"code","02b36005":"code","c18c2ca3":"code","65ac4596":"code","977fb6b4":"code","0d6597c9":"code","532035b4":"code","8e03188e":"code","765d232f":"code","c95e3269":"code","5919ceeb":"code","f19fb4f1":"code","e5bc9bd2":"code","b329c059":"code","bfe53d28":"code","8a85b9f7":"code","75f1dbf7":"code","215bf1ce":"code","3695c45b":"code","9e601201":"code","52eaee82":"code","467547b7":"code","001a85d9":"code","485afa64":"code","7be77f3e":"code","c017500d":"code","8b2d61d8":"code","2240828d":"code","1a14dc95":"code","d74967fa":"code","55824509":"code","063c29b1":"code","a4d54eeb":"code","ae4eac6b":"code","a6ee039c":"code","9e6b8b45":"markdown","aa6e9f7f":"markdown","88a21339":"markdown","cf492c81":"markdown","bb63c16f":"markdown","2a592526":"markdown","1a6c3470":"markdown","bd8b5057":"markdown","67acca0e":"markdown","4356bbbc":"markdown","4b646b29":"markdown","eac3f855":"markdown","a9d6923f":"markdown"},"source":{"401bd334":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport statsmodels.api as sm","082eec3a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ef1698a9":"# df = pd.read_csv('train.csv')\ndf = pd.read_csv('\/kaggle\/input\/iba-ml2-mid-project\/train.csv')","1d34adad":"df['credit_line_utilization'] = df['credit_line_utilization'].str.replace(',', '.').astype('float')","a2f326c3":"# removing duplicate rows\n\ndf = df.drop('Id', axis=1).drop_duplicates()","9f9c582a":"# filling nan values using KNN imputer\n\nfrom sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=5)\ndf2 = imputer.fit_transform(df)","41fb1a2d":"df2 = pd.DataFrame(df2, columns=df.columns)","5117babe":"df2.number_dependent_family_members = round(df2.number_dependent_family_members)","d6696893":"# shortening the column names for convenience\n\ndf2 = df2.rename(columns=\n                 {\n                     'number_dependent_family_members': 'fam_mem', \n                     'monthly_income': 'income',\n                     'number_of_credit_lines': 'ncl',\n                     'credit_line_utilization': 'clu', \n                     'number_of_previous_late_payments_up_to_59_days': 'late59',\n                     'number_of_previous_late_payments_up_to_89_days': 'late89',\n                     'number_of_previous_late_payments_90_days_or_more': 'late90',\n                     'real_estate_loans': 'loans',\n                     'ratio_debt_payment_to_income': 'ratio',\n                     'defaulted_on_loan': 'default'\n                 }\n                )\n\ndf2.head(5)","34a7b41d":"from imblearn.under_sampling import NearMiss\n\nX = df2.drop('default', axis=1)\ny = df2['default']\n\nundersample = NearMiss(version=3, n_neighbors_ver3=3)\n\nX, y = undersample.fit_resample(X, y)","01d4b2d8":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB","1a2bdc08":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score as ras\nfrom sklearn.metrics import confusion_matrix as cm\nfrom sklearn.model_selection import cross_val_score","ead20fa1":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","f64067f8":"model = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)","e979feb8":"print('Report for Train set: \\n')\nprint(classification_report(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Report for Test set: \\n')\nprint(classification_report(y_test, model.predict(X_test)))\n\nprint('\\n')\nprint('ROC\/AUC score for Train: ')\nprint(ras(y_train, model.predict_proba(X_train)[:, 1]))\n\nprint('\\n')\nprint('ROC\/AUC score for Test: ')\nprint(ras(y_test, model.predict_proba(X_test)[:, 1]))\n\nprint('\\n')\nprint('Confusion Matrix for Train: ')\nprint(cm(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Confusion Matrix for Test: ')\nprint(cm(y_test, model.predict(X_test)))","02b36005":"m = DecisionTreeClassifier()\n\n# cross validation score tells us how good is model for the data - higher, better\nscores = cross_val_score(m, X, y, scoring='accuracy', n_jobs=-1)\n\nprint('\\n')\n# report performance\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n\nprint('\\n')\nprint('Report for whole data: \\n')\nprint(classification_report(df2['default'], model.predict(df2.drop('default', axis=1))))\n\nprint('\\n')\nprint('ROC\/AUC score: ')\nprint(ras(df2['default'], model.predict_proba(df2.drop('default', axis=1))[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix: ')\nprint(cm(df2['default'], model.predict(df2.drop('default', axis=1))))","c18c2ca3":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)","65ac4596":"print('Report for Train set: \\n')\nprint(classification_report(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Report for Test set: \\n')\nprint(classification_report(y_test, model.predict(X_test)))\n\nprint('\\n')\nprint('ROC\/AUC score for Train: ')\nprint(ras(y_train, model.predict_proba(X_train)[:, 1]))\n\nprint('\\n')\nprint('ROC\/AUC score for Test: ')\nprint(ras(y_test, model.predict_proba(X_test)[:, 1]))\n\nprint('\\n')\nprint('Confusion Matrix for Train: ')\nprint(cm(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Confusion Matrix for Test: ')\nprint(cm(y_test, model.predict(X_test)))","977fb6b4":"m = RandomForestClassifier()\n\nscores = cross_val_score(m, X, y, scoring='accuracy', n_jobs=-1)\n\n# report performance\nprint('\\n')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n\nprint('\\n')\nprint('Report for whole data: \\n')\nprint(classification_report(df2['default'], model.predict(df2.drop('default', axis=1))))\n\nprint('\\n')\nprint('ROC\/AUC score: ')\nprint(ras(df2['default'], model.predict_proba(df2.drop('default', axis=1))[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix: ')\nprint(cm(df2['default'], model.predict(df2.drop('default', axis=1))))","0d6597c9":"model = AdaBoostClassifier(random_state = 42)\nmodel.fit(X_train, y_train)","532035b4":"print('Report for Train set: \\n')\nprint(classification_report(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Report for Test set: \\n')\nprint(classification_report(y_test, model.predict(X_test)))\n\nprint('\\n')\nprint('ROC\/AUC score for Train: ')\nprint(ras(y_train, model.predict_proba(X_train)[:,1]))\n\nprint('\\n')\nprint('ROC\/AUC score for Test: ')\nprint(ras(y_test, model.predict_proba(X_test)[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix for Train: ')\nprint(cm(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Confusion Matrix for Test: ')\nprint(cm(y_test, model.predict(X_test)))","8e03188e":"m = AdaBoostClassifier(random_state = 42)\nscores = cross_val_score(m, X, y, scoring='accuracy', n_jobs=-1)\n\n# report performance\nprint('\\n')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n\nprint('\\n')\nprint('\\n\\n Report for whole data: \\n')\nprint(classification_report(df2['default'], model.predict(df2.drop('default', axis=1))))\n\nprint('\\n')\nprint('ROC\/AUC score: ')\nprint(ras(df2['default'], model.predict_proba(df2.drop('default', axis=1))[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix: ')\nprint(cm(df2['default'], model.predict(df2.drop('default', axis=1))))","765d232f":"model = XGBClassifier()\nmodel.fit(X_train, y_train)","c95e3269":"print('Report for Train set: n')\nprint(classification_report(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Report for Test set: \\n')\nprint(classification_report(y_test, model.predict(X_test)))\n\nprint('\\n')\nprint('ROC\/AUC score for Train: ')\nprint(ras(y_train, model.predict_proba(X_train)[:,1]))\n\nprint('\\n')\nprint('ROC\/AUC score for Test: ')\nprint(ras(y_test, model.predict_proba(X_test)[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix for Train: ')\nprint(cm(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Confusion Matrix for Test: ')\nprint(cm(y_test, model.predict(X_test)))","5919ceeb":"m = XGBClassifier()\nscores = cross_val_score(m, X, y, scoring='accuracy', n_jobs=-1)\n\n# report performance\nprint('\\n')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n\nprint('\\n')\nprint('Report for whole data: \\n')\nprint(classification_report(df2['default'], model.predict(df2.drop('default', axis=1))))\n\nprint('\\n')\nprint('ROC\/AUC score: ')\nprint(ras(df2['default'], model.predict_proba(df2.drop('default', axis=1))[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix: ')\nprint(cm(df2['default'], model.predict(df2.drop('default', axis=1))))","f19fb4f1":"model = CatBoostClassifier()\nmodel.fit(X_train, y_train, verbose = False)","e5bc9bd2":"print('Report for Train set: \\n')\nprint(classification_report(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Report for Test set: \\n')\nprint(classification_report(y_test, model.predict(X_test)))\n\nprint('\\n')\nprint('ROC\/AUC score for Train: ')\nprint(ras(y_train, model.predict_proba(X_train)[:,1]))\n\nprint('\\n')\nprint('ROC\/AUC score for Test: ')\nprint(ras(y_test, model.predict_proba(X_test)[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix for Train: ')\nprint(cm(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Confusion Matrix for Test: ')\nprint(cm(y_test, model.predict(X_test)))","b329c059":"m = CatBoostClassifier()\nscores = cross_val_score(m, X, y, scoring='accuracy', n_jobs=-1)\n\n# report performance\nprint('\\n')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n\nprint('\\n')\nprint('Report for whole data: \\n')\nprint(classification_report(df2['default'], model.predict(df2.drop('default', axis=1))))\n\nprint('\\n')\nprint('ROC\/AUC score: ')\nprint(ras(df2['default'], model.predict_proba(df2.drop('default', axis=1))[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix: ')\nprint(cm(df2['default'], model.predict(df2.drop('default', axis=1))))","bfe53d28":"model = GaussianNB()\nmodel.fit(X_train, y_train)","8a85b9f7":"print('Report for Train set: \\n')\nprint(classification_report(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Report for test set: \\n')\nprint(classification_report(y_test, model.predict(X_test)))\n\nprint('\\n')\nprint('ROC\/AUC score for Train: ')\nprint(ras(y_train, model.predict_proba(X_train)[:, 1]))\n\nprint('\\n')\nprint('ROC\/AUC score for Test: ')\nprint(ras(y_test, model.predict_proba(X_test)[:, 1]))\n\nprint('\\n')\nprint('Confusion Matrix for Train: ')\nprint(cm(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Confusion Matrix for Test: ')\nprint(cm(y_test, model.predict(X_test)))","75f1dbf7":"m = GaussianNB()\nscores = cross_val_score(m, X, y, scoring='accuracy', n_jobs=-1)\n\n# report performance\nprint('\\n')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n\nprint('\\n')\nprint('Report for whole data: \\n')\nprint(classification_report(df2['default'], model.predict(df2.drop('default', axis=1))))\n\nprint('\\n')\nprint('ROC\/AUC score: ')\nprint(ras(df2['default'], model.predict_proba(df2.drop('default', axis=1))[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix: ')\nprint(cm(df2['default'], model.predict(df2.drop('default', axis=1))))","215bf1ce":"from sklearn.model_selection import GridSearchCV as gs","3695c45b":"model = AdaBoostClassifier(random_state=42)\n# model = XGBClassifier()","9e601201":"parameters = {'algorithm': ('SAMME', 'SAMME.R'), 'n_estimators': [20, 30, 40, 50, 70, 80], 'learning_rate': [0.1, 1, 0.01]}\n\n'''\nparameters = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n              'n_estimators': [20,30,40,50,65,80,100,115,130,150]}\n'''\n\nclf = gs(model, parameters, cv=5)","52eaee82":"# we fit and expect it to find best parameter combination\n\nclf.fit(X, y)","467547b7":"clf.best_estimator_","001a85d9":"model = clf.best_estimator_\n\n# model = XGBClassifier(learning_rate=0.01, n_estimators=100, max_depth=3, subsample=0.8, gamma=1, colsample_bytree=1)\n\nmodel.fit(X_train, y_train)","485afa64":"print('Report for Train set: \\n')\nprint(classification_report(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Report for Test set: \\n')\nprint(classification_report(y_test, model.predict(X_test)))\n\nprint('\\n')\nprint('ROC\/AUC score for Train: ')\nprint(ras(y_train, model.predict_proba(X_train)[:,1]))\n\nprint('\\n')\nprint('ROC\/AUC score for Test: ')\nprint(ras(y_test, model.predict_proba(X_test)[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix for Train: ')\nprint(cm(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Confusion Matrix for Test: ')\nprint(cm(y_test, model.predict(X_test)))","7be77f3e":"m = clf.best_estimator_\nscores = cross_val_score(m, X, y, scoring='accuracy', n_jobs=-1)\n\n# report performance\nprint('\\n')\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n\nprint('\\n')\nprint('Report for whole data: \\n')\nprint(classification_report(df2['default'], model.predict(df2.drop('default', axis = 1))))\n\nprint('\\n')\nprint('ROC\/AUC score: ')\nprint(ras(df2['default'], model.predict_proba(df2.drop('default', axis=1))[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix: ')\nprint(cm(df2['default'], model.predict(df2.drop('default', axis=1))))","c017500d":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nimport matplotlib.pyplot as plt\n\nprobs = model.predict_proba(df2.drop('default', axis = 1))\npreds = probs[:,1]\n\nfpr, tpr, threshold = roc_curve(df2['default'], preds)\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic of best model - AdaBoost')\nplt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","8b2d61d8":"# test = pd.read_csv('test.csv')\ntest = pd.read_csv('\/kaggle\/input\/iba-ml2-mid-project\/test.csv')","2240828d":"test","1a14dc95":"test['credit_line_utilization'] = test['credit_line_utilization'].str.replace(',', '.').astype('float')","d74967fa":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=5)\ntest2 = imputer.fit_transform(test.drop(\"Id\", axis=1))","55824509":"test2 = pd.DataFrame(test2, columns=test.drop(\"Id\", axis=1).columns)","063c29b1":"test2.number_dependent_family_members = round(test2.number_dependent_family_members)","a4d54eeb":"test2 = test2.rename(columns=\n                     {\n                         'number_dependent_family_members': 'fam_mem',\n                         'monthly_income': 'income',\n                         'number_of_credit_lines': 'ncl',\n                         'credit_line_utilization': 'clu',\n                         'number_of_previous_late_payments_up_to_59_days': 'late59',\n                         'number_of_previous_late_payments_up_to_89_days': 'late89',\n                         'number_of_previous_late_payments_90_days_or_more': 'late90',\n                         'real_estate_loans': 'loans',\n                         'ratio_debt_payment_to_income': 'ratio',\n                         'defaulted_on_loan': 'default'\n                     }\n                    )\n\ntest2.head(5)","ae4eac6b":"pd.DataFrame({'Id': pd.read_csv('\/kaggle\/input\/iba-ml2-mid-project\/test.csv')['Id'], 'Predicted': model.predict_proba(test2)[:,1]}).to_csv('submission.csv', index=False)","a6ee039c":"pd.read_csv('submission.csv')","9e6b8b45":"### Decision Tree","aa6e9f7f":"### Naive Bayes","88a21339":"#### Among above models, AdaBoost and XGBoost performed relatively better","cf492c81":"Naive Bayes performed poorly","bb63c16f":"### AdaBoost","2a592526":"##### Visualizing ROC curve","1a6c3470":"### ABB Tech Academy - Machine Learning\n\n#### Step Project: Model analysis, interpretation, and explanation notebook\n-------------------------------\nDate: 07.01.2022","bd8b5057":"### XGBoost","67acca0e":"### Random Forest","4356bbbc":"Let's tune hyperparameters","4b646b29":"#### Prediction Submission","eac3f855":"### CatBoost","a9d6923f":"Undersampling the data for building better model:\n<br>\n* less than 10% of data is defaulted, most algorithms just easily give all the value of 0 and gets higher (more than ~90%) accuracy\n<br>\n* by this method, we select relevant data points in majority class (default=0) and keep all the minority class (default=1) "}}