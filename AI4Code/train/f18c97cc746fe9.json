{"cell_type":{"7d65127e":"code","10fc3069":"code","026be920":"code","f659154a":"code","02697491":"code","1f4975b7":"code","8ab1609f":"code","11b1a06c":"code","266fe6b2":"code","2f99581f":"code","29790333":"code","6e0249fe":"code","77488448":"code","205965f7":"markdown","19a935bb":"markdown","ebee2935":"markdown","fa9e8d02":"markdown"},"source":{"7d65127e":"import sys\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nwarnings.filterwarnings(\"ignore\")\n","10fc3069":"import plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))","026be920":"pd.set_option('mode.chained_assignment', None)\ntest = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv\")\ntrain['Province_State'].fillna('', inplace=True)\ntest['Province_State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country_Region','Province_State','Date'])\ntest = test.sort_values(['Country_Region','Province_State','Date'])","f659154a":"train.head()","02697491":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nfor country in train['Country_Region'].unique():\n#for country in ['Vietnam']:\n    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n        y_train_fatalities = df_train['Fatalities'].ravel()\n        X_pred = CreateInput(df_test)\n        \n        # Only train above 50 cases\n        for day in sorted(feature_day,reverse = True):\n            feature_use = 'Number day from ' + str(day) + ' case'\n            idx = X_train[X_train[feature_use] == 0].shape[0]     \n            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n                break\n                                           \n        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n        idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n        \n        pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n        min_test_date = pred_data['Date'].min()\n        #The number of day forcast\n        #pred_data[pred_data['Date'] > max_train_date].shape[0]\n        #model = SimpleExpSmoothing(adjusted_y_train_confirmed).fit()\n        #model = Holt(adjusted_y_train_confirmed).fit()\n        #model = Holt(adjusted_y_train_confirmed, exponential=True).fit()\n        #model = Holt(adjusted_y_train_confirmed, exponential=True, damped=True).fit()\n        model = ExponentialSmoothing(adjusted_y_train_confirmed, trend = 'additive').fit()\n        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n               \n        #model = Holt(adjusted_y_train_fatalities).fit()\n        model = ExponentialSmoothing(adjusted_y_train_fatalities, trend = 'additive').fit()\n        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n        \n        \n        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n        pred_data['Fatalities_hat'] = y_hat_fatalities\n        pred_data_all = pred_data_all.append(pred_data)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val_1 = df_val.copy()","1f4975b7":"country = \"Ukraine\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0])\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","8ab1609f":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","11b1a06c":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.arima_model import ARIMA\n\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\npred_data_all = pd.DataFrame()\nfor country in train['Country_Region'].unique():\n    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n        y_train_fatalities = df_train['Fatalities'].ravel()\n        X_pred = CreateInput(df_test)\n        \n        # Only train above 50 cases\n        for day in sorted(feature_day,reverse = True):\n            feature_use = 'Number day from ' + str(day) + ' case'\n            idx = X_train[X_train[feature_use] == 0].shape[0]     \n            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n                break\n                                           \n        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n        idx = X_pred[X_pred[feature_use] == 0].shape[0]    \n        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n        \n        pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n        min_test_date = pred_data['Date'].min()\n        model = SARIMAX(adjusted_y_train_confirmed, order=(1,1,0), \n                        #seasonal_order=(1,1,0,12),\n                        measurement_error=True).fit(disp=False)\n        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n               \n        model = SARIMAX(adjusted_y_train_fatalities, order=(1,1,0), \n                        #seasonal_order=(1,1,0,12),\n                        measurement_error=True).fit(disp=False)\n        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n        y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n        \n        \n        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n        pred_data['Fatalities_hat'] = y_hat_fatalities\n        pred_data_all = pred_data_all.append(pred_data)\n\ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf_val_2 = df_val.copy()","266fe6b2":"country = \"US\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","2f99581f":"country = \"Russia\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nidx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_country, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_country, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of ' + df_country['Country_Region'].values[0] + ' (SARIMA)')\nfig.add_scatter(x=df_country['Date'][0:idx], y=df_country['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","29790333":"df_total = df_val.groupby(['Date']).sum().reset_index()\n\nidx = df_total[((df_total['ConfirmedCases'].isnull() == False) & (df_total['ConfirmedCases'] > 0))].shape[0]\nfig = px.line(df_total, x=\"Date\", y=\"ConfirmedCases_hat\", title='Total Cases of World - SARIMA')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['ConfirmedCases'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()\n\nfig = px.line(df_total, x=\"Date\", y=\"Fatalities_hat\", title='Total Fatalities of World - SARIMA')\nfig.add_scatter(x=df_total['Date'][0:idx], y=df_total['Fatalities'][0:idx], mode='lines', name=\"Actual\", showlegend=False)\nfig.show()","6e0249fe":"method_list = ['Exponential Smoothing','SARIMA']\nmethod_val = [df_val_1,df_val_2]\nfor i in range(0,2):\n    df_val = method_val[i]\n    method_score = [method_list[i]] + [RMSLE(df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases'].values,df_val[(df_val['ConfirmedCases'].isnull() == False)]['ConfirmedCases_hat'].values)] + [RMSLE(df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities'].values,df_val[(df_val['Fatalities'].isnull() == False)]['Fatalities_hat'].values)]\n    print (method_score)","77488448":"df_val = df_val_2\nsubmission = df_val[['ForecastId','ConfirmedCases_hat','Fatalities_hat']]\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission.to_csv('submission.csv', index=False)\nsubmission","205965f7":"Today is the last day of the competition.\n\nOther solutions in Week 3:\n\n* https:\/\/www.kaggle.com\/mrmorj\/covid19-svc\n* https:\/\/www.kaggle.com\/mrmorj\/covid-19-adv-eda-lstm\n* https:\/\/www.kaggle.com\/mrmorj\/covid-19-eda-xgboost\n* https:\/\/www.kaggle.com\/mrmorj\/covid-19-linreg\n* https:\/\/www.kaggle.com\/mrmorj\/covid-19-sarima\n\nPlease support the efforts!","19a935bb":"# Holt and Exponential Smoothening","ebee2935":"# Submission","fa9e8d02":"# SARIMA Model"}}