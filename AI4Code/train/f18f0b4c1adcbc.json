{"cell_type":{"b98a3019":"code","c7161778":"code","0ac91919":"code","af9dee44":"code","f7c894f3":"code","39a9bce6":"code","bcf72100":"code","5da69b0d":"code","4a867e2c":"code","be91453b":"code","9f6fc06e":"code","e7a9f835":"code","b760ec6c":"code","b6217dc1":"code","075f3542":"code","34d6a4ab":"code","86d6fa30":"code","538dad69":"code","2885073b":"code","b45bb7a4":"code","dfbecb91":"code","7d82a2d2":"code","6d86c952":"code","641d8ed7":"code","856adef6":"code","be1564f9":"code","2420fd0a":"code","6a87fa5d":"code","0aa13e4d":"code","30601ec0":"code","093505e4":"code","0a701b6a":"code","b3dc783a":"markdown","d440be82":"markdown","ab26f4b8":"markdown","bb8eb847":"markdown","b6d274e0":"markdown","4597e284":"markdown","c8117e7f":"markdown","b9d61183":"markdown","cf92b127":"markdown","25f70592":"markdown","11e566b7":"markdown","8625f9a7":"markdown","1a0a4eac":"markdown","c739273c":"markdown","5028d949":"markdown","f6a47536":"markdown","8a736d80":"markdown"},"source":{"b98a3019":"#Load libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","c7161778":"df=pd.read_csv('..\/input\/iris\/Iris.csv')\ndf.head()","0ac91919":"print(df.describe())","af9dee44":"print(df.groupby('Species').size())","f7c894f3":"df.info()","39a9bce6":"df.isnull().sum()","bcf72100":"df=df.drop(['Id'],axis=1)\ndf.head()","5da69b0d":"sns.set(font_scale=1.5)\nplt.figure(figsize=(8,5))\ncorr = (df.corr())\nsns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values,cmap=\"YlGnBu\",annot=True,linewidths=.5, fmt=\".2f\")\nplt.title(\"Pearson Correlation of all Elements\")","4a867e2c":"f,ax=plt.subplots(1,1,figsize=(25,6))\nsns.boxplot(data=df, palette=\"muted\")","be91453b":"df.hist (bins=10,figsize=(20,20))\nplt.show ()","9f6fc06e":"sns.set(style=\"ticks\", color_codes=True)\ng = sns.pairplot(df)","e7a9f835":"g = sns.pairplot(df, hue=\"Species\",palette=\"husl\", markers=[\"o\", \"s\", \"D\"])","b760ec6c":"f,ax=plt.subplots(1,1,figsize=(25,6))\nax = sns.scatterplot(x=\"SepalLengthCm\", y=\"Species\",color = \"orange\",data=df)\nax = sns.scatterplot(x=\"SepalWidthCm\", y=\"Species\",color = \"red\",data=df)\nax = sns.scatterplot(x=\"PetalLengthCm\", y=\"Species\",color = \"green\",data=df)\nax = sns.scatterplot(x=\"PetalWidthCm\", y=\"Species\",color = \"blue\",data=df)","b6217dc1":"f,ax=plt.subplots(1,1,figsize=(25,6))\ndf['Species'].replace([0], 'Iris_Setosa', inplace=True) \ndf['Species'].replace([1], 'Iris_Vercicolor', inplace=True) \ndf['Species'].replace([2], 'Iris_Virginica', inplace=True)   \nsns.kdeplot(df.loc[(df['Species']=='Iris-virginica'), 'SepalLengthCm'], color='b', shade=True, Label='Iris_Virginica')\nsns.kdeplot(df.loc[(df['Species']=='Iris-setosa'), 'SepalLengthCm'], color='g', shade=True, Label='Iris_Setosa')\nsns.kdeplot(df.loc[(df['Species']=='Iris-versicolor'), 'SepalLengthCm'], color='r', shade=True, Label='Iris_Vercicolor')\nplt.xlabel('Sepal Length') \nplt.ylabel('Probability Density') ","075f3542":"f,axes = plt.subplots(1,1,figsize=(3,5),sharex = True,sharey =True)\ns=np.linspace(0,3,10)\ncmap = sns.cubehelix_palette(start=0.0, light=1, as_cmap=True)\nx = df['PetalWidthCm'].values\ny = df['PetalLengthCm'].values\nsns.kdeplot(x,y,cmap=cmap,shade=True,cut = 5)","34d6a4ab":"f,ax=plt.subplots(2,2,figsize=(25,15))\nsns.violinplot(x=\"Species\", y=\"SepalLengthCm\",ax=ax[0][0],data=df, palette=\"muted\")\nsns.violinplot(x=\"Species\", y=\"PetalWidthCm\",data=df,ax=ax[0][1], palette=\"muted\")\nsns.violinplot(x=\"Species\", y=\"PetalLengthCm\",ax=ax[1][0],data=df, palette=\"muted\")\nsns.violinplot(x=\"Species\", y=\"SepalWidthCm\",ax=ax[1][1],data=df, palette=\"muted\")","86d6fa30":"f,axes=plt.subplots (1,1,figsize=(15,4))\nsns.distplot(df['SepalLengthCm'],kde=True,hist=True,color=\"g\")\nsns.distplot(df['SepalWidthCm'],kde=True,hist=True,color=\"r\")\nsns.distplot(df['PetalLengthCm'],kde=True,hist=True,color=\"b\")\nsns.distplot(df['PetalWidthCm'],kde=True,hist=True,color=\"yellow\")\nplt.xlabel('Quantity') \n#plt.ylabel('Probability Density') ","538dad69":"X = df.drop(['Species'],axis=1)\nY = df['Species']\nx_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=7)","2885073b":"from sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\nclf.fit(x_train,y_train)\ny_pred=clf.predict(x_test)","b45bb7a4":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","dfbecb91":"from sklearn.metrics import classification_report, confusion_matrix\nmodel = KNeighborsClassifier()\nmodel.fit(x_train,y_train)\ny_pred= model.predict(x_test)\nprint(classification_report(y_test,y_pred))\naccuracy1=model.score(x_test,y_test)\nprint (accuracy1*100,'%')\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot= True)","7d82a2d2":"model = SVC()\nmodel.fit(x_train,y_train)\ny_pred= model.predict(x_test)\nprint(classification_report(y_test,y_pred))\naccuracy1=model.score(x_test,y_test)\nprint (accuracy1*100,'%')\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot= True)","6d86c952":"model = RandomForestClassifier(n_estimators=5)\nmodel.fit(x_train,y_train)\ny_pred= model.predict(x_test)\nprint(classification_report(y_test,y_pred))\naccuracy1=model.score(x_test,y_test)\nprint (accuracy1*100,'%')\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot= True)","641d8ed7":"model = LogisticRegression()\nmodel.fit(x_train,y_train)\ny_pred= model.predict(x_test)\nprint(classification_report(y_test,y_pred))\naccuracy1=model.score(x_test,y_test)\nprint (accuracy1*100,'%')\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot= True)","856adef6":"x = df.iloc[:, [0, 1, 2, 3]].values\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', \n                    max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\n    \n# Plotting the results onto a line graph, \n# `allowing us to observe 'The elbow'\nplt.plot(range(1, 11), wcss)\nplt.title('The elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS') # Within cluster sum of squares\nplt.show()","be1564f9":"kmeans = KMeans(n_clusters = 3, init = 'k-means++',\n                max_iter = 300, n_init = 10, random_state = 0)\ny_kmeans = kmeans.fit_predict(x)\n","2420fd0a":"# Visualising the clusters - On the first two columns\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], \n            s = 100, c = 'red', label = 'Iris-setosa')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], \n            s = 100, c = 'blue', label = 'Iris-versicolour')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1],\n            s = 100, c = 'green', label = 'Iris-virginica')\n\n# Plotting the centroids of the clusters\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], \n            s = 100, c = 'yellow', label = 'Centroids')\n\nplt.legend()","6a87fa5d":"y=df['Species']","0aa13e4d":"# Defining the decision tree algorithm\nfrom sklearn.tree import DecisionTreeClassifier\ndtree=DecisionTreeClassifier()\ndtree.fit(x,y)\n\nprint('Decision Tree Classifer Created')\n","30601ec0":"# Install required libraries\n!pip install pydotplus\n!apt-get install graphviz -y","093505e4":"!pip install pydotplus","0a701b6a":"# Import necessary libraries for graph viz\n!pip install --upgrade scikit-learn==0.20.3\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\n\n# Visualize the graph\ndot_data = StringIO()\nexport_graphviz(dtree, out_file=dot_data, feature_names=X.columns,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","b3dc783a":"**Logistic Regression**","d440be82":"**Box plot**","ab26f4b8":"**Heatmap**","bb8eb847":"**KDE plot**","b6d274e0":"**Histogram**","4597e284":"**Violinplot**","c8117e7f":"**Train Test Split**","b9d61183":"**Importing CSV file**","cf92b127":"**Decision Tree Classifier**","25f70592":"**Checking Missing Values**","11e566b7":"**SVM**","8625f9a7":"**Distplot**","1a0a4eac":"**Clustering**","c739273c":"**The dataset contains:**\n\n3 classes (different Iris species) with 50 samples each, and then four numeric properties about those classes:\n\n1)Sepal Length\n\n2)Sepal Width\n\n3)Petal Length\n\n4)Petal Width\n\nOne species, Iris Setosa, is \"linearly separable\" from the other two. This means that we can draw a line (or a hyperplane in higher-dimensional spaces) between Iris Setosa samples and samples corresponding to the other two species.\n\n**Predicted Attribute:** Different Species of Iris plant.\n\n**Purpose :-** The purpose of this project was to gain introductory exposure to Machine Learning Classification concepts along with data visualization. The project makes heavy use of Scikit-Learn, Pandas and Data Visualization Libraries.\n\nTable of content\n\n1. Importing dataset\n\n2. Data Visualization\n   \n   1.Heatmap\n   \n   2.Boxplot\n   \n   3.Violinplot\n   \n   4.Pairplot\n   \n   5.Scatterplot\n   \n   6.KDE plot\n\n3. Machine learning Techniques\n\n   1.KNN\n   \n   2.Logistic Regression\n   \n   3.Random Forest Classifier\n   \n   4.SVM\n   \n   5.Decision Tree Classifier","5028d949":"**Random Forest Classifier**","f6a47536":"**Pairplot**","8a736d80":"**Scatterplot**"}}