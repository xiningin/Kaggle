{"cell_type":{"6d3717bf":"code","612ae575":"code","62014a92":"code","8a79db2b":"code","c48732cd":"code","d4655974":"code","efe19779":"code","b9eb61c3":"code","30ad5fa5":"code","15542035":"code","81475b50":"code","e2ee9343":"code","82fcf794":"code","9d0b305d":"code","6cbb1df0":"code","d5c6cf4f":"code","11154351":"code","8bdb7ff1":"code","34a13f51":"code","7d9775c2":"code","b533c214":"code","ea13b57d":"code","767dd73c":"code","271baa75":"code","1b17a655":"code","3bc506f8":"code","858086bb":"code","b62cf33e":"code","809a0b1f":"code","56562878":"code","9426da72":"code","ae2a5743":"code","c784d2a8":"code","c04898f0":"code","18f60bd2":"code","87638b97":"code","60cc164c":"code","50cb53f9":"code","abc628f1":"code","190de600":"code","64c417e5":"markdown","302e2873":"markdown","3ee10f9a":"markdown","be031dc6":"markdown","ea7c8a6b":"markdown"},"source":{"6d3717bf":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\nfrom IPython.display import Image, display\nimport matplotlib.cm as cm\n\nimport os\nfrom distutils.dir_util import copy_tree, remove_tree\n\nfrom PIL import Image\nfrom random import randint\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow_addons as tfa\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","612ae575":"base_dir = \"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/\"\nroot_dir = \".\/\"\ntest_dir = base_dir + \"test\/\"\ntrain_dir = base_dir + \"train\/\"\nwork_dir = root_dir + \"dataset\/\"\n\nif os.path.exists(work_dir):\n    remove_tree(work_dir)\n    \n\nos.mkdir(work_dir)\ncopy_tree(train_dir, work_dir)\ncopy_tree(test_dir, work_dir)\nprint(\"Working Directory Contents:\", os.listdir(work_dir))","62014a92":"WORK_DIR = '.\/dataset\/'\n\nCLASSES = [ 'NonDemented',\n            'VeryMildDemented',\n            'MildDemented',\n            'ModerateDemented']\n\nIMG_SIZE = 100\nIMAGE_SIZE = [IMG_SIZE, IMG_SIZE]\nDIM = (IMG_SIZE, IMG_SIZE)","8a79db2b":"#Performing Image Augmentation to have more data samples\n\nZOOM = [.99, 1.01]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\n\nwork_dr = IDG(rescale = 1.\/255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n\ntrain_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=True)","c48732cd":"def show_images(generator,y_pred=None, nn=6400):\n    \"\"\"\n    Input: An image generator,predicted labels (optional)\n    Output: Displays a grid of 9 images with lables\n    \"\"\"\n    \n    # get image lables\n    labels =dict(zip([0,1,2,3], CLASSES))\n    \n    # get a batch of images\n    x,y = generator.next()\n    \n    # display a grid of 9 images\n    plt.figure(figsize=(10, 10))\n    if y_pred is None:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            idx = randint(0, nn)\n            plt.imshow(x[idx])\n            plt.axis(\"off\")\n            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n                                                     \n    else:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(x[i])\n            plt.axis(\"off\")\n            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n    \n# Display Train Images\nshow_images(train_data_gen,nn=6400)","d4655974":"#Retrieving the data from the ImageDataGenerator iterator\n\ntrain_data, train_labels = train_data_gen.next()","efe19779":"#Getting to know the dimensions of our dataset\n\nprint(train_data.shape, train_labels.shape)","b9eb61c3":"#Splitting the data into train, test, and validation sets\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)","30ad5fa5":"# OVER SAMPLING\n# - train data\nsm = SMOTE(random_state=42)\n\ntrain_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n\ntrain_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(train_data.shape, train_labels.shape)\n\n","15542035":"# OVER SAMPLING\n# - validation data\nval_data, val_labels = sm.fit_resample(val_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), val_labels)\n\nval_data = val_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(val_data.shape, val_labels.shape)","81475b50":"# OVER SAMPLING\n# - test data\ntest_data, test_labels = sm.fit_resample(test_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), test_labels)\n\ntest_data = test_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(test_data.shape, test_labels.shape)","e2ee9343":"def conv_block(filters, act='relu',i=0):\n    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Conv2D(filters, 3, activation=act, padding='same', name=f'conv2d_p{i}'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same', name=f'conv2d_pp{i}'))\n    block.add(BatchNormalization())\n    block.add(MaxPool2D())\n    \n    return block","82fcf794":"def dense_block(units, dropout_rate, act='relu'):\n    \"\"\"Defining a Dense NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Dense(units, activation=act))\n    block.add(BatchNormalization())\n    block.add(Dropout(dropout_rate))\n    \n    return block","9d0b305d":"def construct_model(act='relu'):\n    \"\"\"Constructing a Sequential CNN architecture for performing the classification task. \"\"\"\n    \n    model = Sequential([\n        Input(shape=(*IMAGE_SIZE, 3)),\n        Conv2D(16, 3, activation=act, padding='same'),\n        Conv2D(16, 3, activation=act, padding='same'),     \n        MaxPool2D(), \n#         conv_block(32,i=1),\n        Conv2D(32, 3, activation='relu', padding='same', name=f'conv2d_p1'),\n        Conv2D(32, 3, activation='relu', padding='same', name=f'conv2d_pp1'),\n        BatchNormalization(),\n        MaxPool2D(),\n        \n#         conv_block(64,i=2),\n        Conv2D(64, 3, activation='relu', padding='same', name=f'conv2d_p2'),\n        Conv2D(64, 3, activation='relu', padding='same', name=f'conv2d_pp2'),\n        BatchNormalization(),\n        MaxPool2D(), \n        \n#         conv_block(128,i=3),\n        Conv2D(128, 3, activation='relu', padding='same', name=f'conv2d_p3'),\n        Conv2D(128, 3, activation='relu', padding='same', name=f'conv2d_pp3'),\n        BatchNormalization(),\n        MaxPool2D(),\n        \n        Dropout(0.2),\n#         conv_block(256,i=4),\n        Conv2D(256, 3, activation='relu', padding='same', name=f'conv2d_p4'),\n        Conv2D(256, 3, activation='relu', padding='same', name=f'conv2d_pp4'),\n        BatchNormalization(),\n        MaxPool2D(),\n        \n        Dropout(0.2),\n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","6cbb1df0":"#Defining a custom callback function to stop training our model when accuracy goes above 99%\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            \nmy_callback = MyCallback()\n\n#EarlyStopping callback to make sure model is always learning\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)","d5c6cf4f":"#Defining other parameters for our CNN model\n\nmodel = construct_model()\n\nMETRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc'), \n           tfa.metrics.F1Score(num_classes=4)]\n\nCALLBACKS = [my_callback]\n\n\nmodel.compile(optimizer='adam',\n              loss=tf.losses.CategoricalCrossentropy(),\n              metrics=METRICS)\n\nmodel.summary()","11154351":"#Fit the training data to the model and validate it using the validation data\nEPOCHS = 150\n\nhistory = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)","8bdb7ff1":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","34a13f51":"#Evaluating the model on the data\n\n#train_scores = model.evaluate(train_data, train_labels)\n#val_scores = model.evaluate(val_data, val_labels)\ntest_scores = model.evaluate(test_data, test_labels)\n\n#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n#print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","7d9775c2":"#Predicting the test data\n\npred_labels = model.predict(test_data)","b533c214":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","ea13b57d":"#Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Alzheimer\\'s Disease Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","767dd73c":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","271baa75":"#Saving the model for future use\n\nmodel_dir = work_dir + \"alzheimer_cnn_model\"\nmodel.save(model_dir, save_format='h5')\nos.listdir(work_dir)","1b17a655":"pretrained_model = tf.keras.models.load_model(model_dir)\n\n#Check its architecture\nplot_model(pretrained_model, to_file=work_dir + \"model_plot.png\", show_shapes=True, show_layer_names=True)","3bc506f8":"model.summary()","858086bb":"for layer in model.layers:\n    print(layer.get_output_at(0).get_shape().as_list())","b62cf33e":"# model_builder = model\nimg_size = (100, 100)\npreprocess_input = keras.applications.xception.preprocess_input\ndecode_predictions = keras.applications.mobilenet.decode_predictions\n\nlast_conv_layer_name = 'conv2d_pp4'\n\n# The local path to our target image\n# img_path = '..\/input\/rsna-cq500-abnormal-data\/CQ500_Images\/CQ500CT1 CQ500CT1\/CT 2.55mm_1.2.276.0.7230010.3.1.3.296485376.1.1521714567.2079631\/1.2.276.0.7230010.3.1.4.296485376.1.1521714568.2079634.png'\n# display(Image(img_path))","809a0b1f":"def get_img_array(img, size):\n    # `img` is a PIL image of size 299x299\n#     img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (100, 100, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 100, 100, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) \/ tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","56562878":"work_dr = IDG()\ntest_data_gen = work_dr.flow(test_data, test_labels,  batch_size=500, shuffle=True)","9426da72":"# Prepare image\nimg_array = preprocess_input(get_img_array(test_data_gen[3][0][0], size=img_size))\n\n\n\n# Remove last layer's softmax\nmodel.layers[-1].activation = None\n\n# Print what the top predicted class is\npreds = model.predict(img_array)\n# print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n\n# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.show()","ae2a5743":"import matplotlib.image as mpimg\ndef save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n    # Load the original image\n#     img = keras.preprocessing.image.load_img(img_path)\n    img = keras.preprocessing.image.img_to_array(img)\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n#     display(Image(cam_path))\n    img = mpimg.imread(cam_path)\n    imgplot = plt.imshow(img)\n    plt.show()\n    \n\n    \n# img_path=\"..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train\/NonDemented\/nonDem1.jpg\"\nsave_and_display_gradcam(test_data_gen[3][0][0], heatmap)","c784d2a8":"!rm -r .\/0\n!rm -r .\/1\n!rm -r .\/2\n!rm -r .\/3\n","c04898f0":"!mkdir .\/0\n!mkdir .\/1\n!mkdir .\/2\n!mkdir .\/3","18f60bd2":"np.argmax(test_data_gen[1][1][1])","87638b97":"import os\nh=0\nlabels =dict(zip([0,1,2,3], CLASSES))\nfor i in range(0,4):\n    for j in range (0,500):\n        x = test_data_gen[i][0][j]\n        y = test_data_gen[i][1][j]\n        x = x.reshape(1,100,100,3)\n#         np.shape(x)\n        \n        h+=1\n        preds = model.predict(x)\n        heatmap = make_gradcam_heatmap(x*255, model, last_conv_layer_name)\n        p=os.path.join(\".\/\", str(np.argmax(preds)))\n        if len(os.listdir(p)) < 20: \n            save_and_display_gradcam(x[0]*255, heatmap, cam_path= str(np.argmax(preds))+\"\/\"+f\"cam_{labels[np.argmax(y)]}_\"+str(len(os.listdir(p)))+\".jpg\")\n            print(\"--- \"+str(np.argmax(preds))+\" :  \"+ str(len(os.listdir(p))))\n        if len(os.listdir(\".\/0\")) == 20 and len(os.listdir(\".\/1\")) == 20 and len(os.listdir(\".\/2\")) == 20 and len(os.listdir(\".\/3\")) == 20:\n            break\n    if len(os.listdir(\".\/0\")) == 20 and len(os.listdir(\".\/1\")) == 20 and len(os.listdir(\".\/2\")) == 20 and len(os.listdir(\".\/3\")) == 20:\n        break","60cc164c":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 100\nh = 100\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(5, 10*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"0\",)\ni=-1\n# for i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n#     img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\nfor n in os.listdir('.\/0'):\n    i+=1\n#     img = cv2.imread(n)\n    img = mpimg.imread('.\/0\/'+n)\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(f'p:{labels[0][0:4]} ,t:{n[4:-14]}')  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 10*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","50cb53f9":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 100\nh = 100\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(5, 10*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"1\",)\ni=-1\n# for i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n#     img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\nfor n in os.listdir('.\/1'):\n    i+=1\n#     img = cv2.imread(n)\n    img = mpimg.imread('.\/1\/'+n)\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(f'p:{labels[1][0:6]} ,t:{n[4:-14]}')  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 10*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","abc628f1":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 100\nh = 100\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(5, 10*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"2\",)\ni=-1\n# for i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n#     img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\nfor n in os.listdir('.\/2'):\n    i+=1\n#     img = cv2.imread(n)\n    img = mpimg.imread('.\/2\/'+n)\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(f'p:{labels[2][0:6]} ,t:{n[4:-14]}')  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 10*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","190de600":"import matplotlib.pyplot as plt\nimport numpy as np\nw = 100\nh = 100\nfig = plt.figure(figsize=(9, 13))\ncolumns = 4\nrows = 5\n\n# prep (x,y) for extra plotting\nxs = np.linspace(5, 10*np.pi, 60)  # from 0 to 2pi\nys = np.abs(np.sin(xs))           # absolute of sine\n\n# ax enables access to manipulate each of subplots\nax = []\np=os.path.join(\".\/\",\"3\",)\ni=-1\n# for i in range(columns*rows):\n\n#     img = np.random.randint(10, size=(h,w))\n#     img = cv2.imread(p+'\/'+'cam_'+str(i)+'.jpg')\nfor n in os.listdir('.\/3'):\n    i+=1\n#     img = cv2.imread(n)\n    img = mpimg.imread('.\/3\/'+n)\n    \n    # create subplot and append to ax\n    ax.append( fig.add_subplot(rows, columns, i+1) )\n    ax[-1].set_title(f'p:{labels[3][0:6]} ,t:{n[4:-14]}')  # set title\n    plt.imshow(img, )\n\n# do extra plots on selected axes\/subplots\n# note: index starts with 0\nax[2].plot(xs, 10*ys)\nax[19].plot(ys**2, xs)\n\nplt.show()  # finally, render the plot","64c417e5":"# GradCam","302e2873":"Constructing a Convolutional Neural Network Architecture","3ee10f9a":"Training & Testing the Model","be031dc6":"# over sampling","ea7c8a6b":"# Data Preprocessing"}}