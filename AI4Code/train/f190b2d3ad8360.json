{"cell_type":{"64fee76c":"code","7fb6726d":"code","337e90b4":"code","d426709e":"code","52227eb7":"code","8220f32c":"code","a37bf77b":"code","d19d2f9c":"code","86799a95":"code","3c9a0b6f":"code","d24fb572":"code","0f9bcd1f":"code","519677f3":"code","79bd573b":"code","3bcd704b":"code","6ac36e04":"code","cfb43996":"code","eb2f06e1":"code","4312a286":"code","cfba90c6":"code","74f25d88":"code","8ed225da":"code","10c28d7e":"code","a7796801":"code","90c8b53e":"code","a5d73710":"code","c832bcaf":"code","f0c923ef":"code","bc2557a3":"code","3f9234cd":"code","df45ee5c":"code","0914453f":"code","e17bc590":"code","f90ea3d8":"code","785ea6dd":"code","8399903f":"code","242a0a05":"code","c5b2edf2":"code","5c385178":"code","b6878b61":"code","b02e608f":"code","f1829f2c":"code","f3c90b0b":"markdown","11b02a30":"markdown","a703791c":"markdown","3a78df7f":"markdown","72b9de94":"markdown","26fb33b3":"markdown","78e19031":"markdown","0b313951":"markdown","55d1051b":"markdown","018d7dc3":"markdown","453320e3":"markdown","085bdbc7":"markdown","a3382774":"markdown","ff5326ce":"markdown","4b66ffda":"markdown","661ac2b8":"markdown","c16a0467":"markdown","cd946f98":"markdown","73669efa":"markdown","613c46db":"markdown","d3b37166":"markdown","b1102181":"markdown","ef92337e":"markdown","2436f73f":"markdown","adf22505":"markdown","e5fd89bf":"markdown","f918d079":"markdown","e2c734a4":"markdown","66f03e0e":"markdown","e6238fe9":"markdown","10d3a1ee":"markdown","35313000":"markdown"},"source":{"64fee76c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7fb6726d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\npd.pandas.set_option('display.max_columns',None)\n\nfrom scipy import stats\nfrom scipy.stats import norm,skew\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\n\n\n# for warnings\nimport warnings\nwarnings.filterwarnings('ignore')","337e90b4":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\n# Remove unnecessary column from the dataset.\n\ndf_train.drop('Id',axis=1,inplace=True)\ndf_train.head()","d426709e":"df_test.drop('Id',axis=1,inplace=True)\ndf_test.head()","52227eb7":"print(\"Train Shape: \",df_train.shape)\nprint(\"Test Shape: \",df_test.shape)","8220f32c":"missing_percentage = (df_train.isnull().sum()\/len(df_train))*100\nmissing_percentage = missing_percentage[missing_percentage > 0].sort_values(ascending = False)\nmissing_percentage","a37bf77b":"df_train.drop(['PoolQC','MiscFeature','Alley','Fence','3SsnPorch'],axis=1,inplace=True)","d19d2f9c":"missing_percentage_test = (df_test.isnull().sum()\/len(df_test))*100\nmissing_percentage_test = missing_percentage_test[missing_percentage_test > 0].sort_values(ascending = False)\nmissing_percentage_test","86799a95":"df_test.drop(['PoolQC','MiscFeature','Alley','Fence','3SsnPorch'],axis=1,inplace=True)","3c9a0b6f":"df_train.skew()","d24fb572":"df_test.skew()","0f9bcd1f":"plt.figure(figsize = (15,5))\nplt.subplot(1,2,1)\nfig1 = sns.distplot(df_train['SalePrice'],color = 'b',fit=norm)\n(mu, sigma) = norm.fit(df_train['SalePrice'])\nplt.title(\"Before Transformation\",color = 'r',size=15)\nplt.xlabel(\"SalePrice\",size=15,color='r')\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)])\n\nplt.subplot(1,2,2)\ntarget = np.log(df_train['SalePrice'])\nfig2 = sns.distplot(target,color = 'b',fit=norm,label = \"After Transformation\")\n(mu, sigma) = norm.fit(target)\nplt.title(\"After Transformation\",color = 'r',size=15)\nplt.xlabel(\"SalePrice\",size=15,color='r')\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)])\n\nplt.tight_layout()\nplt.show()","519677f3":"num_feat = list(col for col in df_train.columns if df_train[col].dtypes != 'object')\nprint('Numerical Features are: {}'.format(len(num_feat)))\n\ncat_feat = list(col for col in df_train.columns if df_train[col].dtypes == 'object')\nprint('Categorical Features are: {}'.format(len(cat_feat)))","79bd573b":"plt.figure(figsize=[20,15])\ncorr = df_train[num_feat].corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr,annot=True,cmap='coolwarm',mask = mask,linewidths=0.4,fmt='.1f',vmin=-1,vmax=1,center=0,\n            cbar_kws={'orientation':'horizontal'})\nplt.show()","3bcd704b":"df_train[num_feat].corr()['SalePrice'].sort_values(ascending=False).nlargest(20)","6ac36e04":"plt.figure(figsize=[15,8])\nplt.subplot(2,1,1)\nfig = sns.countplot(df_train['MoSold'])\nplt.title(\"\\nIn Which Month House Selling High?\\n\",color='r',size=25)\nplt.xlabel(\"\\nMonth\",color='magenta',size=15)\nplt.subplot(2,1,2)\nfig1 = sns.countplot(df_train['YrSold'])\nplt.title(\"\\nIn Which Year house Selling High?\\n\",color='r',size=25)\nplt.xlabel(\"\\nYear\",color='magenta',size=15)\nplt.tight_layout()\nplt.show()","cfb43996":"plt.figure(figsize = [15,8])\nsns.lineplot(df_train['YrSold'],df_train['SalePrice'],color='tomato')\nplt.title(\"\\nFluctuation of House Price over the Years\",size = 20,color = 'red')\nplt.xlabel('\\nYr Selling',color='blue',size=15)\nplt.ylabel('Selling Price',color='blue',size=15)\nplt.show()","eb2f06e1":"plt.figure(figsize=[15,12])\ngrp_order = df_train.groupby(['Neighborhood'])['SalePrice'].mean().sort_values(ascending=False).index\nsns.barplot(y = df_train['Neighborhood'], x = df_train['SalePrice'],order = grp_order,ci=None,orient='h')\nplt.title(\"\\nWhich Neighborhood Is Popular?\\n\",size=25,color='r')\nplt.xlabel(\"\\nHouse Selling Price\",color='magenta',size=15)\nplt.ylabel(\"Neighborhood\",color = 'magenta',size=25)\nplt.yticks(fontsize=15)\nplt.show()","4312a286":"df_train['MSSubClass'] = df_train['MSSubClass'].apply(str)\ndf_train['OverallCond'] = df_train['OverallCond'].astype(str)\ndf_train['YrSold'] = df_train['YrSold'].astype(str)\ndf_train['MoSold'] = df_train['MoSold'].astype(str)","cfba90c6":"cat_feat = list(col for col in df_train.columns if df_train[col].dtypes == 'O')\nprint('Categorical Features now becomes: {}'.format(len(cat_feat)))","74f25d88":"# Plotting for the Category Features\n\nf = pd.melt(df_train, value_vars = sorted(cat_feat))\ng = sns.FacetGrid(f,col = 'variable',col_wrap=4,sharex=False,sharey=False)\nplt.xticks(rotation = 90)\ng = g.map(sns.countplot,'value') \n[plt.setp(ax.get_xticklabels(),rotation = 90) for ax in g.axes.flat]\ng.fig.tight_layout()\nplt.show()","8ed225da":"# checking outliers for the Numerical Features\n\nfig,ax=plt.subplots(18,2,figsize=(15,60))\ndef graph(x,y,r,c,title):\n    sns.scatterplot(df_train[num_feat][x],y,ax=ax[r][c])\n    ax[r][c].set_xlabel(x)\n    fig.tight_layout(pad=5.0)\n\nfor r,col in enumerate(num_feat):\n    c=r%2\n    graph(col,df_train['SalePrice'],r\/\/2,c,col)","10c28d7e":"def outlier(df_train):\n    for col in df_train.columns:\n        if (((df_train[col].dtype)=='float64') | ((df_train[col].dtype)=='int64')):\n            percentiles = df_train[col].quantile([0.25,0.75]).values\n            df_train[col][df_train[col] <= percentiles[0]] = percentiles[0]\n            df_train[col][df_train[col] >= percentiles[1]] = percentiles[1]\n        else:\n            df_train[col]=df_train[col]\n    return df_train\n\ndf_train = outlier(df_train)","a7796801":"for col in df_train.columns:\n    if df_train[col].isnull().sum() > 50:\n        df_train[col].fillna(0,inplace=True)\n    elif df_train[col].dtypes == 'O':\n        df_train[col].fillna(df_train[col].mode()[0],inplace=True)\n    else:\n        df_train[col].fillna(df_train[col].mean(),inplace = True)","90c8b53e":"df_train.isnull().values.any()","a5d73710":"for col in df_test.columns:\n    if df_test[col].isnull().sum() > 50:\n        df_test[col].fillna(0,inplace=True)\n    elif df_test[col].dtypes == 'O':\n        df_test[col].fillna(df_test[col].mode()[0],inplace=True)\n    else:\n        df_test[col].fillna(df_test[col].mean(),inplace = True)","c832bcaf":"df_test.isnull().values.any()","f0c923ef":"encoder = LabelEncoder()\n\nfor col in cat_feat:\n    df_train[col] = encoder.fit_transform(df_train[col].astype(str))","bc2557a3":"print(df_train.shape)\ndf_train.head()","3f9234cd":"cat_feat_test = list(col for col in df_test.columns if df_test[col].dtypes == 'object')\nprint(\"Category Features of Test data are: \",len(cat_feat_test))\n\nfor col in cat_feat_test:\n    df_test[col] = encoder.fit_transform(df_test[col].astype(str))","df45ee5c":"print(df_test.shape)\ndf_test.head()","0914453f":"X = df_train.drop('SalePrice',axis=1)\ny = df_train['SalePrice']","e17bc590":"print(X.shape)\nX.head()","f90ea3d8":"y.head().to_frame()","785ea6dd":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 10)\n\nprint(\"X_train Shape:\",X_train.shape)\nprint(\"X_test Shape:\",X_test.shape)\nprint(\"y_train Shape:\",y_train.shape)\nprint(\"y_test Shape:\",y_test.shape)","8399903f":"plt.figure(figsize = [15,25])\nfrom sklearn.ensemble import ExtraTreesRegressor\nextra_reg = ExtraTreesRegressor()\nextra_reg.fit(X_train,y_train)\n\nfeatures = pd.Series(extra_reg.feature_importances_,index= X_train.columns).plot(kind = 'barh')\nplt.title(\"\\nBest Features\",size = 20,color = 'crimson')\nplt.ylabel('Features',size=20,color='purple')\nplt.yticks(fontsize = 10)\nplt.show()","242a0a05":"lightgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=8,\n                                       learning_rate=0.0385, \n                                       n_estimators=3500,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose= 0,\n                                       )","c5b2edf2":"lightgbm.fit(X_train,y_train)","5c385178":"lightgbm.score(X_test,y_test)","b6878b61":"prediction = lightgbm.predict(df_test)\nprint(prediction)","b02e608f":"submission = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","f1829f2c":"final_output = pd.DataFrame({'Id':submission['Id'],'SalePrice' : prediction})\nfinal_output.to_csv('Submission_lightgbm.csv',index = False)\nfinal_output.head()","f3c90b0b":"# **Exploratory Data Analysis (EDA):-**","11b02a30":">**Train Data:**","a703791c":"**So,as we know in terms of house selling most people look the Overall Quality first, the second thing they need to see is that Ground Living area how many sqft and how it looks based on these factors the price of houses would be decided.**","3a78df7f":"**We can divide the features into Numerical and Category features inorder to make a good Analysis.**","72b9de94":"# **House Prices with Advance Regression Techniques**","26fb33b3":">**Test Data:-**","78e19031":"**Same for Test as well, we can drop some columns as they are not relevant for prediction.**","0b313951":"**As there are not many informations availabel in some columns of missing % so we can simply drop some of them.**","55d1051b":"# **Outliers:**","018d7dc3":"# **Feature Importance:-**","453320e3":"# **Handling Missing Values:-**","085bdbc7":"**Here,we removed outliers by having lower bound 0.25% and upper bound 0.75%.So,the values which are less than 0.25 and greater than 0.75 will be removed.**","a3382774":"# **If You like my work then Please upvote it.**\n\n# **I would love to get Suggestions which will help me to become a Good DataScientist :)** ","ff5326ce":">**Train Data:**","4b66ffda":"# **Split The Data:-**","661ac2b8":"**Now, We will handling missing values of the both data.So, whichever features has more Nan values we can fill it with 0 and other features we can fill it by taking mean() or mode() depending upon the type.**\n\n>**Train Data:-**","c16a0467":">**Test Data:**","cd946f98":"# **Correlation via Heatmap**","73669efa":"# **Model Building:-**","613c46db":">**Test Data:**","d3b37166":"**Let's first visualise the distribution of Target variable(\"SalePrice\") and if it is a skewed then we can changed it by taking log transformation of it**","b1102181":"# **Missing Values:-**","ef92337e":"**Load Data:**","2436f73f":"# **Let's load submission data and make prediction on it.**","adf22505":">**Test Data:**","e5fd89bf":"**Let see the distributions of Categorical Features. But,before that change some numerical features into Category,as they have discrete distributions.**","f918d079":">**Train Data:**","e2c734a4":"# **Importing Required Libraries:**","66f03e0e":"**Removing Outliers:-**","e6238fe9":"# **Preparing Data to feed into ML models:-**","10d3a1ee":"# **Skewness:-**","35313000":"# **Data Conversion using LabelEncoder:-**"}}