{"cell_type":{"325e2959":"code","b26c9da2":"code","cec416e6":"code","7ba3f63b":"code","7d9c1d71":"code","6464984e":"code","d94c5fbe":"code","a87b9900":"code","ebc25459":"code","af382ab5":"code","7c9704a3":"code","d8a2cf8f":"code","8a8c65d4":"code","7da595c7":"code","d29f02dd":"code","2760a0e7":"markdown"},"source":{"325e2959":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b26c9da2":"# lets create a text\ntext = \"No woman no tears\"\n\n# length of text ( includes spaces)\nprint(\"length of text: \",len(text))\n\n# split the text\nsplitted_text = text.split() # default split methods splits text according to spaces\nprint(\"Splitted text: \",splitted_text)    # splitted_text is a list that includes words of text sentence\n# each word is called token in text mining world.","cec416e6":"\n# capitalized words with istitle() method that finds capitalized words\ncapital_words = [ word for word in splitted_text if word.istitle()]\nprint(\"Capitalized words: \",capital_words)\n\n# words which end with \"o\": endswith() method finds last letter of word\nwords_end_with_o =  [word for word in splitted_text if word.endswith(\"o\")]\nprint(\"words end with o: \",words_end_with_o) \n\n# words which starts with \"w\": startswith() method\nwords_start_with_w = [word for word in splitted_text if word.startswith(\"w\")]\nprint(\"words start with w: \",words_start_with_w) \n\n# unique with set() method\nprint(\"unique words: \",set(splitted_text))  # actually the word \"no\" is occured twice bc one word is \"no\" and others \"No\" there is a capital letter at first letter\n\n# make all letters lowercase with lower() method\nlowercase_text = [word.lower() for word in splitted_text]\n\n# then find uniques again with set() method\nprint(\"unique words: \",set(lowercase_text))","7ba3f63b":"# chech words includes or not includes particular substring or letter\nprint(\"Is w letter in woman word:\", \"w\" in \"woman\")\n\n# check words are upper case or lower case\nprint(\"Is word uppercase:\", \"WOMAN\".isupper())\nprint(\"Is word lowercase:\", \"tears\".islower())\n\n# check words are made of by digits or not\nprint(\"Is word made of by digits: \",\"12345\".isdigit())\n\n# get rid of from white space characters like spaces and tabs or from unwanted letters with strip() method\nprint(\"00000000No tears: \",\"00000000No tears\".strip(\"0\"))\n\n# find particular letter from front \nprint(\"Find particular letter from back: \",\"No tears no\".find(\"o\"))  # at index 1\n\n# find particular letter from back  rfind = reverse find\nprint(\"Find particular letter from back: \",\"No tears no\".rfind(\"o\"))  # at index 8\n\n# replace letter with letter\nprint(\"Replace o with 3 \", \"No tears no\".replace(\"o\",\"3\"))\n\n# find each letter and store them in list\nprint(\"Each letter: \",list(\"No tears\"))","7d9c1d71":"\n# Cleaning text\ntext1 = \"    Blessed and focussed    \"\nprint(\"Split text: \",text1.split(\" \"))   # as you can see there are unnecessary white space in list\n\n# get rid of from these unnecassary white spaces with strip() method then split\nprint(\"Cleaned text: \",text1.strip().split(\" \"))","6464984e":"# reading files line by line\nf = open(\"..\/input\/religious-and-philosophical-texts\/35895-0.txt\",\"r\")\n\n# read first line\nprint(f.readline())\n\n# length of text\ntext3=f.read()\nprint(\"Length of text: \",len(text3))\n\n# Number of lines with splitlines() method\nlines = text3.splitlines()\nprint(\"Number of lines: \",len(lines))","d94c5fbe":"# read data\ndata = pd.read_csv(r\"..\/input\/ben-hamners-tweets\/benhamner.csv\", encoding='latin-1')\ndata.head()","a87b9900":"# find which entries contain the word 'appointment'\nprint(\"In his tweets, the rate of occuring kaggle word is: \",sum(data.text.str.contains('kaggle'))\/len(data))\n# text\ntext = data.text[1]\nprint(text)","ebc25459":"# find regular expression on text\n# import regular expression package\nimport re\n# find callouts that starts with @\ncallouts = [word for word in text.split(\" \") if re.search(\"@[A-Za-z0-9_]+\",word)]\nprint(\"callouts: \",callouts)","af382ab5":"# continue finding regular expressions\n# [A-Za-z0-9_] =\\w\n# We will use \"\\w\" to find callouts and our result will be same because \\w matches with [A-Za-z0-9_] \ncallouts1 = [word for word in text.split(\" \") if re.search(\"@\\w+\",word)]\nprint(\"callouts: \",callouts1)\n# find specific characters like \"w\"\nprint(re.findall(r\"[w]\",text))\n# \"w\"ith, \"w\"indo\"w\", sho\"w\"ing, s\"w\"itches \n\n# do not find specific character like \"w\". We will use \"^\" symbol\nprint(re.findall(r\"[^w]\",text))","7c9704a3":"# Regular expressions for Dates\ndate = \"15-10-2000\\n09\/10\/2005\\n15-05-1999\\n05\/05\/99\\n\\n05\/05\/199\\n\\n05\/05\/9\"\nre.findall(r\"\\d{1,2}[\/-]\\d{1,2}[\/-]\\d{1,4}\",date)","d8a2cf8f":"# import natural language tool kit\nimport nltk as nlp\n\n# counting vocabulary of words\ntext = data.text[1]\nsplitted = text.split(\" \")\nprint(\"number of words: \",len(splitted))\n\n# counting unique vocabulary of words\ntext = data.text[1]\nprint(\"number of unique words: \",len(set(splitted)))\n\n# print first five unique words\nprint(\"first 5 unique words: \",list(set(splitted))[:5])\n\n# frequency of words \ndist = nlp.FreqDist(splitted)\nprint(\"frequency of words: \",dist)\n\n# look at keys in dist\nprint(\"words in text: \",dist.keys())\n\n# count how many time a particalar value occurs. Lets look at \"box\"\nprint(\"the word box is occured how many times:\",dist[\"box\"])","8a8c65d4":"# normalization\nwords = \"task Tasked tasks tasking\"\nwords_list = words.lower().split(\" \")\nprint(\"normalized words: \",words_list)\n\n# stemming\nporter_stemmer = nlp.PorterStemmer()\nroots = [porter_stemmer.stem(each) for each in words_list]\nprint(\"roots of task Tasked tasks tasking: \",roots)","7da595c7":"# stemming\nstemming_word_list = [\"Universal\",\"recognition\",\"Become\",\"being\",\"happened\"]\nporter_stemmer = nlp.PorterStemmer()\nroots = [porter_stemmer.stem(each) for each in stemming_word_list]\nprint(\"result of stemming: \",roots)\n\n# lemmatization\nlemma = nlp.WordNetLemmatizer()\nlemma_roots = [lemma.lemmatize(each) for each in stemming_word_list]\nprint(\"result of lemmatization: \",lemma_roots)","d29f02dd":"text_t = \"You\u2019re in the right place!\"\nprint(\"split the sentece: \", text_t.split(\" \"))  # 5 words\n\n# tokenization with nltk\nprint(\"tokenize with nltk: \",nlp.word_tokenize(text_t))","2760a0e7":"# \nBasic Text Mining Methods\u00b6\nText can be sentences, strings, words, characters and large documents\nNow lets create a sentence to understand basics of text mining methods.\nOur sentece is \"no woman no cry\" from Bob Marley."}}