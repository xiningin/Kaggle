{"cell_type":{"b89114f6":"code","0625e6a1":"code","bbd67673":"code","7ba86aaf":"code","0c6d6baf":"code","ed73e669":"code","4373bcc2":"code","501828bf":"code","19a0e98e":"code","b89cb44e":"code","84db2c94":"code","2203ecc7":"code","6b858153":"code","6111f553":"code","f752ec22":"code","4e6df6eb":"code","68ddc389":"code","2245f813":"code","d3db1096":"code","9bb03480":"code","6191fec1":"code","92e40496":"code","31994289":"code","778efbb0":"markdown","baf27669":"markdown","483d4674":"markdown","fefee65d":"markdown"},"source":{"b89114f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport nltk\nfrom nltk import tokenize\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nlyrics_path = '..\/input\/eminem-dataset-show\/eminem.csv'\nGLOVE_DIR = '..\/input\/glove6b\/glove.6B.100d.txt'\n\n# Any results you write to the current directory are saved as output.\nuse_gpu = torch.cuda.is_available()","0625e6a1":"lyrics = pd.read_csv(lyrics_path)","bbd67673":"lyrics.head()","7ba86aaf":"#lyrics = lyrics[:300]","0c6d6baf":"import re\ndef clean_str(string):\n    \"\"\"\n    Tokenization\/string cleaning for dataset\n    Every dataset is lower cased except\n    \"\"\"\n    string = re.sub(r\"\\n\", \" \\n \", string)\n    string = re.sub(r\"\\\\\", \"\", string) \n    string = re.sub(r\"\\'\", \"\", string)    \n    string = re.sub(r\"\\\"\", \"\", string)\n    if string.rfind('<\/p>') != -1:\n        string = string[: string.rfind('<\/p>') + len('<\/p>')]\n    return string.strip().lower()","ed73e669":"rap_lyrics = lyrics['text'].apply(clean_str)","4373bcc2":"rap_lyrics = rap_lyrics.apply(lambda s : tokenize.word_tokenize(s, preserve_line=True)).tolist()","501828bf":"word_index = {}\nrev_dict = {}\nword_count = -1\nfor rap in rap_lyrics:\n    for word in rap:\n        if word not in word_index:\n            word_count += 1\n            word_index[word] = word_count\n            rev_dict[word_count] = word\nprint(len(word_index))","19a0e98e":"embed_size=100\nnum_stacks = 3\nnum_inputs = 15\nbatch_size = 2048\ntraining_iters = 500\ndisplay_step = 100\nlearning_rate = 1e-3","b89cb44e":"embeddings_index = {}\nf = open(GLOVE_DIR)\nfor line in f:\n    try:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n    except:\n        print(word)\n        pass\nf.close()\nprint('Total %s word vectors.' % len(embeddings_index))","84db2c94":"embedding_matrix = np.random.randn(len(word_index) + 1, embed_size)\nabsent_words = 0\nabsent_index = {}\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be randomly initialized.\n        embedding_matrix[i] = embedding_vector\n    else:\n        absent_words += 1\nprint('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 \/ len(word_index)), '% of total words')","2203ecc7":"vocab_size = len(word_index)","6b858153":"## Convert words too their corresponding index\ntotal_raps = len(rap_lyrics)\nfor i in range(total_raps):\n    rap_len = len(rap_lyrics[i])\n    for j in range(rap_len):\n        rap_lyrics[i][j] = word_index[rap_lyrics[i][j]]","6111f553":"## Create training data\ntrain_x = []\ntrain_y = []\nfor rap  in rap_lyrics:\n        m = len(rap)\n        window = m - num_inputs\n        for i in range(window):\n            train_x.append(rap[i: i + num_inputs])\n            train_y.append(rap[i + num_inputs])","f752ec22":"train_x = np.array(train_x)\ntrain_y = np.array(train_y)","4e6df6eb":"print(train_x.shape, train_y.shape)","68ddc389":"def get_accuracy(outputs, labels):\n    total = float(labels.size()[0])\n    _, predicted = torch.max(outputs, 1)\n    correct_pred = (predicted == labels).float()\n    accuracy = correct_pred.sum() \/ total * 100\n    return accuracy","2245f813":"# Testing\nget_accuracy(torch.Tensor([[1, 0, 0], [0,1,0], [0,1,0], [0,0,1], [1,0,0]]), torch.LongTensor([1,1,1,1,2]))","d3db1096":"def train_step(inputs, labels, optimizer, criterion):\n    optimizer.zero_grad()\n    # forward + backward + optimize\n    outputs = emnet(inputs)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\n    acc_batch = get_accuracy(outputs, labels)\n    return loss, acc_batch","9bb03480":"class EmNet(nn.Module):\n    def __init__(self, num_stacks, num_inputs, weights_matrix):\n        super(EmNet, self).__init__()\n        self.vocab_size, self.embed_size = weights_matrix.shape\n        self.create_emb_layer(weights_matrix)\n        self.num_stacks = num_stacks\n        self.num_inputs = num_inputs\n        self.Wfh = nn.ParameterList([nn.Parameter(torch.randn((embed_size, embed_size)), requires_grad =True) for i in range(num_stacks)])\n        self.Wfx = nn.ParameterList([nn.Parameter(torch.randn((embed_size, embed_size)), requires_grad =True) for i in range(num_stacks)])\n        self.Wih = nn.ParameterList([nn.Parameter(torch.randn((embed_size, embed_size)), requires_grad =True) for i in range(num_stacks)])\n        self.Wix = nn.ParameterList([nn.Parameter(torch.randn((embed_size, embed_size)), requires_grad =True) for i in range(num_stacks)])\n        self.Wch = nn.ParameterList([nn.Parameter(torch.randn((embed_size, embed_size)), requires_grad =True) for i in range(num_stacks)])\n        self.Wcx = nn.ParameterList([nn.Parameter(torch.randn((embed_size, embed_size)), requires_grad =True) for i in range(num_stacks)])\n        self.Woh = nn.ParameterList([nn.Parameter(torch.randn((embed_size, embed_size)), requires_grad =True) for i in range(num_stacks)])\n        self.Wox = nn.ParameterList([nn.Parameter(torch.randn((embed_size, embed_size)), requires_grad =True) for i in range(num_stacks)])\n        self.bf = nn.ParameterList([nn.Parameter(torch.zeros(1, embed_size), requires_grad =True) for i in range(num_stacks)])\n        self.bi = nn.ParameterList([nn.Parameter(torch.zeros(1, embed_size), requires_grad =True) for i in range(num_stacks)])\n        self.bc = nn.ParameterList([nn.Parameter(torch.zeros(1, embed_size), requires_grad =True) for i in range(num_stacks)])\n        self.bo = nn.ParameterList([nn.Parameter(torch.zeros(1, embed_size), requires_grad =True) for i in range(num_stacks)])\n        self.Wfinal = nn.Parameter(torch.randn(embed_size,  vocab_size), requires_grad =True)\n        self.bfinal = nn.Parameter(torch.zeros(1, vocab_size), requires_grad =True)\n        self.cin = Variable(torch.zeros(1, embed_size).cuda())\n        self.hin = Variable(torch.zeros(1, embed_size).cuda())\n        return\n        \n    def create_emb_layer(self, weights_matrix, non_trainable=False):\n        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n        self.embedding.weight.data.copy_(torch.from_numpy(weights_matrix).cuda())\n        if non_trainable:\n            emb_layer.weight.requires_grad = False\n        return\n        \n    def lstm_cell(self, layer_num, prev_c, prev_h, curr_x):\n        ft = F.sigmoid(prev_h.mm(self.Wfh[layer_num]) + curr_x.mm(self.Wfx[layer_num]) + self.bf[layer_num])\n        it = F.sigmoid(prev_h.mm(self.Wih[layer_num]) + curr_x.mm(self.Wix[layer_num]) + self.bi[layer_num])\n        Ct = F.tanh(prev_h.mm(self.Wch[layer_num]) + curr_x.mm(self.Wcx[layer_num]) + self.bc[layer_num])\n        ot = F.sigmoid(prev_h.mm(self.Woh[layer_num]) + curr_x.mm(self.Wox[layer_num]) + self.bo[layer_num])\n        ct = ft * prev_c + it * Ct\n        ht = ot * F.tanh(ct)\n        return ct, ht\n    \n    def lstm_layer(self, xin, cin, hin, layer_num):\n        num_inp = self.num_inputs\n        h = hin\n        c  = cin\n        next_inp = None\n        for i in range(num_inp):\n            curr = xin[:, i, :]\n            c, h = self.lstm_cell(layer_num, c, h, curr)\n            hfit = h.unsqueeze(1)\n            if next_inp is None:\n                next_inp = hfit\n            else:\n                next_inp = torch.cat((next_inp, hfit), 1)\n        return next_inp\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        for layer_num in range(self.num_stacks):\n            x = self.lstm_layer(x, self.cin, self.hin, layer_num)\n        x = x[:, -1, :]\n        x = x.mm(self.Wfinal) + self.bfinal\n        return x","6191fec1":"emnet = EmNet(num_stacks, num_inputs, embedding_matrix)\nif use_gpu:\n    emnet = emnet.cuda()","92e40496":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(emnet.parameters(), learning_rate)","31994289":"m = train_x.shape[0]\nfor epoch in range(training_iters):\n    cst_total = 0\n    acc_total = 0\n    total_batches = int(np.ceil(m \/ batch_size))\n    for i in range(total_batches):\n        df_x = Variable(torch.LongTensor(train_x[i * batch_size : (i + 1) * batch_size]).cuda())\n        df_y = Variable(torch.LongTensor(train_y[i * batch_size : (i + 1) * batch_size]).cuda())\n        batch_loss, acc_batch = train_step(df_x, df_y, optimizer, criterion)\n        cst_total += batch_loss\n        acc_total += acc_batch\n    if (epoch + 1) % display_step == 0:\n        print('After ', (epoch + 1), 'iterations: Cost = %.2f' % (cst_total.data.cpu().numpy()[0] \/ total_batches), 'and Accuracy = ', acc_total.data.cpu().numpy()[0] \/ total_batches, '%' )\nprint('Optimiation finished!!!')\nprint(\"Let's test\")\ntext_inp = \"I reckon you ain't familiar with these here parts You know, there's a story behind\"\ntokens = tokenize.word_tokenize(clean_str(text_inp))[:num_inputs]\ninp_vecs = Variable(torch.LongTensor([word_index[i] for i in tokens])).cuda().view(1,-1)\nlen_rap = 128\nrap = inp_vecs\nwhile rap.size()[1] < len_rap:\n    out_vec = emnet(inp_vecs)\n    out_vec = F.softmax(out_vec, 1)\n    _, next_word = torch.max(out_vec, 1)\n    rap = torch.cat((rap, next_word.unsqueeze(1)), 1)\n    inp_vecs = torch.cat((inp_vecs[:, 1:], next_word.unsqueeze(1)), 1)\nrap_string = ''\nfor i in range(len_rap):\n    rap_string += rev_dict[rap[0, i].data.cpu().numpy()[0]] + ' '\nprint(rap_string)","778efbb0":"## Data Preprocessing","baf27669":"## Embedding Matrix","483d4674":"## Model Implementation","fefee65d":"## Lyrics Analysis"}}