{"cell_type":{"38af046c":"code","be138216":"code","2c3d2bc5":"code","023b20f6":"code","272c58c1":"code","71a0cc13":"code","5c2dc54b":"code","3a388022":"code","e309c481":"code","cef80317":"code","57dc3adb":"code","839a0a5f":"code","99275bcb":"code","e9c23af9":"code","8c25fa1b":"code","d9296301":"code","f05ef5fc":"code","03508c62":"code","83986365":"code","41d8a256":"code","82104482":"code","060c054d":"code","8c9a9c65":"code","659a449c":"code","ad0be9a9":"code","5afee9bb":"code","86a9a8cf":"code","d09bd16d":"code","69676cda":"code","5a40530d":"code","53fdb279":"code","cc8a7537":"code","5bc94222":"code","9b9cea93":"code","c7ed8004":"code","e99ffb98":"code","8f9b7f94":"code","ba9aa6b2":"code","8dd6c080":"code","72a7f4cc":"markdown","27f44fb5":"markdown","2ad88bc9":"markdown","26689bb1":"markdown","08f012d8":"markdown","e18b80b5":"markdown","6717449b":"markdown","45734760":"markdown","35f0b0dc":"markdown","25c4869e":"markdown","983bf058":"markdown","5572afb4":"markdown","d0049e5b":"markdown","e6b98e59":"markdown","e74e5f4a":"markdown","328491c0":"markdown","225b50b4":"markdown","7f93f563":"markdown","378bac6a":"markdown","80f67e8e":"markdown","ceded50b":"markdown"},"source":{"38af046c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","be138216":"\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","2c3d2bc5":"train = pd.read_csv('..\/input\/Train.csv')\ntest = pd.read_csv('..\/input\/Test.csv')","023b20f6":"train.shape, test.shape","272c58c1":"train.columns","71a0cc13":"test.columns","5c2dc54b":"train['source'] = 'train'\ntest['source'] = 'test'\ntest['Item_Outlet_Sales'] = 0\ndata = pd.concat([train, test], sort = False)\nprint(train.shape, test.shape, data.shape)","3a388022":"data['Item_Outlet_Sales'].describe()","e309c481":"sns.distplot(data['Item_Outlet_Sales'])","cef80317":"print('Skewness: %f' % data['Item_Outlet_Sales'].skew())\nprint('Kurtsis: %f' %data['Item_Outlet_Sales'].kurt())","57dc3adb":"data.dtypes","839a0a5f":"categorial_features = data.select_dtypes(include=[np.object])\ncategorial_features.head(2)","99275bcb":"numerical_features = data.select_dtypes(include=[np.number])\nnumerical_features.head(2)","e9c23af9":"data['Outlet_Establishment_Year'].value_counts()","8c25fa1b":"data.apply(lambda x: sum(x.isnull()))","d9296301":"data.apply(lambda x : len(x.unique()))","f05ef5fc":"#frequency of categories\nfor col in categorial_features:\n    print('\\n%s column: '%col)\n    print(data[col].value_counts())","03508c62":"plt.figure(figsize = (10,9))\n\nplt.subplot(311)\nsns.boxplot(x='Outlet_Size', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\n\nplt.subplot(312)\nsns.boxplot(x='Outlet_Location_Type', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\n\nplt.subplot(313)\nsns.boxplot(x='Outlet_Type', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 1.5)\n\nplt.show()","83986365":"plt.figure(figsize = (14,9))\n\nplt.subplot(211)\nax = sns.boxplot(x='Outlet_Identifier', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\nax.set_title(\"Outlet_Identifier vs. Item_Outlet_Sales\", fontsize=15)\nax.set_xlabel(\"\", fontsize=12)\nax.set_ylabel(\"Item_Outlet_Sales\", fontsize=12)\n\nplt.subplot(212)\nax = sns.boxplot(x='Item_Type', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\nax.set_title(\"Item_Type vs. Item_Outlet_Sales\", fontsize=15)\nax.set_xlabel(\"\", fontsize=12)\nax.set_ylabel(\"Item_Outlet_Sales\", fontsize=12)\n\nplt.subplots_adjust(hspace = 0.9, top = 0.9)\nplt.setp(ax.get_xticklabels(), rotation=45)\n\nplt.show()\n\n","41d8a256":"item_avg_weight = data.pivot_table(values='Item_Weight', index='Item_Identifier')\n\nmissing_values = data['Item_Weight'].isnull()\nprint('Missing values: %d' %sum(missing_values))\n\ndata.loc[missing_values,'Item_Weight']  = data.loc[missing_values,'Item_Identifier'].apply(lambda x: item_avg_weight.at[x,'Item_Weight'])\nprint('Missing values after immputation %d' %sum(data['Item_Weight'].isnull()))","82104482":"#Import mode function:\nfrom scipy.stats import mode\n\n#Determing the mode for each\noutlet_size_mode = data.pivot_table(values='Outlet_Size', columns='Outlet_Type',aggfunc=(lambda x:mode(x.astype('str')).mode[0]))\nprint ('Mode for each Outlet_Type:')\nprint (outlet_size_mode)\n\n#Get a boolean variable specifying missing Item_Weight values\nmissing_values = data['Outlet_Size'].isnull() \n\n#Impute data and check #missing values before and after imputation to confirm\nprint ('\\nOrignal #missing: %d'% sum(missing_values))\ndata.loc[missing_values,'Outlet_Size'] = data.loc[missing_values,'Outlet_Type'].apply(lambda x: outlet_size_mode[x])\nprint (sum(data['Outlet_Size'].isnull()))","060c054d":"#Determine average visibility of a product\nvisibility_avg = data.pivot_table(values='Item_Visibility', index='Item_Identifier')\n\n#Impute 0 values with mean visibility of that product:\nmissing_values = (data['Item_Visibility'] == 0)\n\nprint ('Number of 0 values initially: %d'%sum(missing_values))\ndata.loc[missing_values,'Item_Visibility'] = data.loc[missing_values,'Item_Identifier'].apply(lambda x: visibility_avg.at[x, 'Item_Visibility'])\nprint ('Number of 0 values after modification: %d'%sum(data['Item_Visibility'] == 0))","8c9a9c65":"#Get the first two characters of ID:\ndata['Item_Type_Combined'] = data['Item_Identifier'].apply(lambda x: x[0:2])\n#Rename them to more intuitive categories:\ndata['Item_Type_Combined'] = data['Item_Type_Combined'].map({'FD':'Food',\n                                                             'NC':'Non-Consumable',\n                                                             'DR':'Drinks'})\ndata['Item_Type_Combined'].value_counts()","659a449c":"#Change categories of low fat:\nprint('Original Categories:')\nprint(data['Item_Fat_Content'].value_counts())\n\nprint('\\nModified Categories:')\ndata['Item_Fat_Content'] = data['Item_Fat_Content'].replace({'LF':'Low Fat',\n                                                             'reg':'Regular',\n                                                             'low fat':'Low Fat'})\nprint(data['Item_Fat_Content'].value_counts())","ad0be9a9":"plt.figure(figsize = (10,9))\n\nplt.subplot(211)\nsns.boxplot(x='Item_Type_Combined', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\n\nplt.subplot(212)\nsns.boxplot(x='Item_Fat_Content', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 1.5)\n\nplt.show()","5afee9bb":"plt.figure(figsize = (14,9))\n\nplt.subplot(211)\nax = sns.boxplot(x='Outlet_Identifier', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\nax.set_title(\"Outlet_Identifier vs. Item_Outlet_Sales\", fontsize=15)\nax.set_xlabel(\"\", fontsize=12)\nax.set_ylabel(\"Item_Outlet_Sales\", fontsize=12)\n\nplt.subplot(212)\nax = sns.boxplot(x='Item_Type', y='Item_Outlet_Sales', data=data, palette=\"Set1\")\nax.set_title(\"Item_Type vs. Item_Outlet_Sales\", fontsize=15)\nax.set_xlabel(\"\", fontsize=12)\nax.set_ylabel(\"Item_Outlet_Sales\", fontsize=12)\n\nplt.subplots_adjust(hspace = 0.9, top = 0.9)\nplt.setp(ax.get_xticklabels(), rotation=45)\n\nplt.show()","86a9a8cf":"data.index = data['Outlet_Establishment_Year']\ndata.index","d09bd16d":"df = data.loc[:,['Item_Outlet_Sales']]\ndf.head(2)","69676cda":"data.groupby('Outlet_Establishment_Year')['Item_Outlet_Sales'].mean().plot.bar()","5a40530d":"data['Outlet_Years'] = 2009 - data['Outlet_Establishment_Year']\ndata['Outlet_Years'].describe()","53fdb279":"data.index = data['Outlet_Establishment_Year']\ndf = data.loc[:,['Item_Outlet_Sales']]\nts = df['Item_Outlet_Sales']\nplt.figure(figsize=(12,8))\nplt.plot(ts, label='Item_Outlet_Sales')\nplt.title('Outlet Establishment Year')\nplt.xlabel('Time(year-month)')\nplt.ylabel('Item_Outlet_Sales')\nplt.legend(loc = 'best')\nplt.show()","cc8a7537":"plt.figure(figsize = (12,6))\nax = sns.boxplot(x = 'Outlet_Years', y = 'Item_Outlet_Sales', data = data)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 45)\nax.set_title('Outlet years vs Item_Outlet_Sales')\nax.set_xlabel('', fontsize = 15)\nax.set_ylabel('Item_Outlet_Sales', fontsize = 15)\n\nplt.show()","5bc94222":"temp_data = data.loc[data['Outlet_Establishment_Year'] == 1998]","9b9cea93":"temp_data['Outlet_Type'].value_counts()","c7ed8004":"test_temp_data = test.loc[test['Outlet_Establishment_Year'] == 1998]\ntest_temp_data['Outlet_Type'].value_counts()","e99ffb98":"#Import library:\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n#New variable for outlet\ndata['Outlet'] = le.fit_transform(data['Outlet_Identifier'])\nvar_mod = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet']\nle = LabelEncoder()\nfor i in var_mod:\n    data[i] = le.fit_transform(data[i])","8f9b7f94":"#One Hot Coding:\ndata = pd.get_dummies(data, columns=['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Outlet_Type',\n                              'Item_Type_Combined','Outlet'])","ba9aa6b2":"data.dtypes","8dd6c080":"#Drop the columns which have been converted to different types:\ndata.drop(['Item_Type','Outlet_Establishment_Year'],axis=1,inplace=True)\n\n#Divide into test and train:\ntrain = data.loc[data['source']==\"train\"]\ntest = data.loc[data['source']==\"test\"]\n\n#Drop unnecessary columns:\ntest.drop(['Item_Outlet_Sales','source'],axis=1,inplace=True)\ntrain.drop(['source'],axis=1,inplace=True)\n\n#Export files as modified versions:\ntrain.to_csv(\"train_modified.csv\",index=False)\ntest.to_csv(\"test_modified.csv\",index=False)","72a7f4cc":"**Numerical and One-Hot Coding of Categorical variables**","27f44fb5":"We need to predict Item_Outlet_Sales for given test data\n\nlets first merge the train and test data for Exploratory Data Analysis\n","2ad88bc9":"**Create a broad category of Type of Item**\n\nEarlier we saw that the Item_Type variable has 16 categories which might prove to be very useful in analysis. So its a good idea to combine them. One way could be to manually assign a new category to each. But there\u2019s a catch here. If you look at the Item_Identifier, i.e. the unique ID of each item, it starts with either FD, DR or NC. If you see the categories, these look like being Food, Drinks and Non-Consumables. So I\u2019ve used the Item_Identifier variable to create a new column:","26689bb1":"**Lets start looking Outlet_Size, Outlet_Location_Type, and\tOutlet_Type distribution in Item_Outlet_Sale**","08f012d8":"**Determine the years of operation of a store**\nWe wanted to make a new column depicting the years of operation of a store. This can be done as:","e18b80b5":"1. Deviate from the normal distribution.\n1. Have appreciable positive skewness.\n1. Show peakedness.","6717449b":"**Finding Missing values**","45734760":"Based on the observation from 1998 data, we can see there is only Grocery Store Type as Outlet_Type\nthus Item_Outlet_Sale is minimum.\n\nThought to remove those data as part of data cleaning for more accurate model, however we need to check first it's posibilities in test data as well. ","35f0b0dc":"**BigMart Sales Prediction practice problem**\n\nWe have train (8523) and test (5681) data set, train data set has both input and output variable(s). We need to predict the sales for test data set.\n\n\n* Item_Identifier: Unique product ID\n\n* Item_Weight: Weight of product\n\n* Item_Fat_Content: Whether the product is low fat or not\n\n* Item_Visibility: The % of total display area of all products in a store allocated to the particular product\n\n* Item_Type: The category to which the product belongs\n\n* Item_MRP: Maximum Retail Price (list price) of the product\n\n* Outlet_Identifier: Unique store ID\n\n* Outlet_Establishment_Year: The year in which store was established\n\n* Outlet_Size: The size of the store in terms of ground area covered\n\n* Outlet_Location_Type: The type of city in which the store is located\n\n* Outlet_Type: Whether the outlet is just a grocery store or some sort of supermarket\n\n* Item_Outlet_Sales: Sales of the product in the particulat store. This is the outcome variable to be predicted.","25c4869e":"**Modify Item_Visibility**\n\nWe noticed that the minimum value here is 0, which makes no practical sense. Lets consider it like missing information and impute it with mean visibility of that product.","983bf058":"**Data Cleaning and Imputing Missing Values**\n\nWe found two variables with missing values \u2013 Item_Weight and Outlet_Size. Lets impute the former by the average weight of the particular item. This can be done as:","5572afb4":"**Data Mining**","d0049e5b":"This confirms that the column has no missing values now. Lets impute Outlet_Size with the mode of the Outlet_Size for the particular type of outlet.","e6b98e59":"**Load Libraries**","e74e5f4a":"Lets look at numerical and categorial variables","328491c0":"This tells us that there are 1559 products and 10 outlets\/stores (which was also mentioned in problem statement). Another thing that should catch attention is that Item_Type has 16 unique values. Let\u2019s explore further using the frequency of different categories in each nominal variable.","225b50b4":"**Some observations:**\n\n*  **Item_Visibility** has a min value of zero. This makes no practical sense because when a product is being sold in a store, the visibility cannot be 0.\n\n* **Outlet_Establishment_Years** vary from 1985 to 2009. The values might not be apt in this form. Rather, if we can convert them to how old the particular store is, it should have a better impact on sales.\n\n* The lower \u2018count\u2019 of **Item_Weight** and **Outlet_Size** confirms the findings from the missing value check.","7f93f563":"**Exploratory Data Analysis**","378bac6a":"Which shows resonably very low data however we can not remove it. so lets keep it as it is.","80f67e8e":"**Modify categories of Item_Fat_Content**\n\nWe found typos and difference in representation in categories of Item_Fat_Content variable. This can be corrected as:","ceded50b":"Now our data is ready for model building"}}