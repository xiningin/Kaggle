{"cell_type":{"d832e6d9":"code","22da8d93":"code","0bf3e9e0":"code","935559a1":"code","fcb6e574":"code","1615af17":"code","75306642":"code","bb6dc705":"code","79f31fda":"code","22503efe":"code","9047ff6b":"code","cf525b6d":"code","7cd9a5ed":"code","a6b50747":"code","39e3c6ba":"code","0e999aa8":"code","8ea938d8":"code","cf643057":"code","8ce45221":"code","2374d67d":"code","78bdcd10":"code","c2cf1cd2":"code","925b7042":"code","408817ec":"code","bd49f580":"code","eb8fac79":"code","224faa1c":"code","ef9dbd1c":"markdown","b9536b6c":"markdown","22e43495":"markdown","6a6219da":"markdown","3d381c0d":"markdown","8ef28dca":"markdown","4b192c7c":"markdown","fd84e21f":"markdown","df67ff15":"markdown","076f5ef6":"markdown","56c0572e":"markdown","0fd56d3f":"markdown"},"source":{"d832e6d9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nfrom sklearn.ensemble import VotingClassifier\nimport time\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections\n\n\n# Other Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndf = pd.read_csv('..\/input\/creditcard.csv')\ndf.head()","22da8d93":"df.describe()","0bf3e9e0":"# We don't have any Null Values present\ndf.isnull().sum()","935559a1":"df['Class'].value_counts(normalize=True)*100","fcb6e574":"print('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')","1615af17":"df.head(2)","75306642":"# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n\n# RobustScaler is less prone to outliers.\n\nrob_scaler = RobustScaler()\n\ndf['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n\ndf.drop(['Time','Amount'], axis=1, inplace=True)","bb6dc705":"scaled_amount = df['scaled_amount']\nscaled_time = df['scaled_time']\n\ndf.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\ndf.insert(0, 'scaled_amount', scaled_amount)\ndf.insert(1, 'scaled_time', scaled_time)\n\n# Amount and Time are Scaled!\n\ndf.head()","79f31fda":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')\n\nX = df.drop('Class', axis=1)\ny = df['Class']\n\nsss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n\nfor train_index, test_index in sss.split(X, y):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n\n# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Check the Distribution of the labels\n\n\n# Turn into an array\noriginal_Xtrain = original_Xtrain.values\noriginal_Xtest = original_Xtest.values\noriginal_ytrain = original_ytrain.values\noriginal_ytest = original_ytest.values\n\n# See if both the train and test label distribution are similarly distributed\ntrain_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\nprint('-' * 100)\n\nprint('Label Distributions: \\n')\nprint(train_counts_label\/ len(original_ytrain))\nprint(test_counts_label\/ len(original_ytest))","22503efe":"# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n\n# Lets shuffle the data before creating the subsamples\n\ndf = df.sample(frac=1)\n\n# amount of fraud classes 492 rows.\nfraud_df = df.loc[df['Class'] == 1]\nnon_fraud_df = df.loc[df['Class'] == 0][:492]\n\nnormal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n\n# Shuffle dataframe rows\nnew_df = normal_distributed_df.sample(frac=1, random_state=42)\n\nnew_df.head()","9047ff6b":"new_df['Class'].value_counts()","cf525b6d":"print('Distribution of the Classes in the subsample dataset')\nprint(new_df['Class'].value_counts()\/len(new_df))\n\nsns.countplot('Class', data=new_df)\nplt.title('Equally Distributed Classes', fontsize=14)\nplt.show()","7cd9a5ed":"# Make sure we use the subsample in our correlation\n\nplt.subplots(figsize=(24,20))\nsub_sample_corr = new_df.corr()\nsns.heatmap(sub_sample_corr, cmap='coolwarm_r',annot=True)\nplt.show()","a6b50747":"f, axes = plt.subplots(ncols=4, figsize=(20,4))\n\n# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\nsns.boxplot(x=\"Class\", y=\"V17\", data=new_df, ax=axes[0])\naxes[0].set_title('V17 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V14\", data=new_df, ax=axes[1])\naxes[1].set_title('V14 vs Class Negative Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V12\", data=new_df,  ax=axes[2])\naxes[2].set_title('V12 vs Class Negative Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V10\", data=new_df,ax=axes[3])\naxes[3].set_title('V10 vs Class Negative Correlation')\n\nplt.show()","39e3c6ba":"f, axes = plt.subplots(ncols=4, figsize=(20,4))\n\n# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\nsns.boxplot(x=\"Class\", y=\"V11\", data=new_df,ax=axes[0])\naxes[0].set_title('V11 vs Class Positive Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V4\", data=new_df,  ax=axes[1])\naxes[1].set_title('V4 vs Class Positive Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V2\", data=new_df, ax=axes[2])\naxes[2].set_title('V2 vs Class Positive Correlation')\n\n\nsns.boxplot(x=\"Class\", y=\"V19\", data=new_df,ax=axes[3])\naxes[3].set_title('V19 vs Class Positive Correlation')\n\nplt.show()","0e999aa8":"# # -----> V14 Removing Outliers (Highest Negative Correlated with Labels)\nv14_fraud = new_df['V14'].loc[new_df['Class'] == 1].values\nq25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\nprint('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\nv14_iqr = q75 - q25\nprint('iqr: {}'.format(v14_iqr))\n\nv14_cut_off = v14_iqr * 1.5\nv14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\nprint('Cut Off: {}'.format(v14_cut_off))\nprint('V14 Lower: {}'.format(v14_lower))\nprint('V14 Upper: {}'.format(v14_upper))\n\noutliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\nprint('Feature V14 Outliers for Fraud Cases: {}'.format(len(outliers)))\nprint('V10 outliers:{}'.format(outliers))\n\nnew_df = new_df.drop(new_df[(new_df['V14'] > v14_upper) | (new_df['V14'] < v14_lower)].index)\nprint('----' * 25)\n\n# -----> V12 removing outliers from fraud transactions\nv12_fraud = new_df['V12'].loc[new_df['Class'] == 1].values\nq25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)\nv12_iqr = q75 - q25\n\nv12_cut_off = v12_iqr * 1.5\nv12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\nprint('V12 Lower: {}'.format(v12_lower))\nprint('V12 Upper: {}'.format(v12_upper))\noutliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\nprint('V12 outliers: {}'.format(outliers))\nprint('Feature V12 Outliers for Fraud Cases: {}'.format(len(outliers)))\nnew_df = new_df.drop(new_df[(new_df['V12'] > v12_upper) | (new_df['V12'] < v12_lower)].index)\nprint('Number of Instances after outliers removal: {}'.format(len(new_df)))\nprint('----' * 25)\n\n\n# Removing outliers V10 Feature\nv10_fraud = new_df['V10'].loc[new_df['Class'] == 1].values\nq25, q75 = np.percentile(v10_fraud, 25), np.percentile(v10_fraud, 75)\nv10_iqr = q75 - q25\n\nv10_cut_off = v10_iqr * 1.5\nv10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off\nprint('V10 Lower: {}'.format(v10_lower))\nprint('V10 Upper: {}'.format(v10_upper))\noutliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]\nprint('V10 outliers: {}'.format(outliers))\nprint('Feature V10 Outliers for Fraud Cases: {}'.format(len(outliers)))\nnew_df = new_df.drop(new_df[(new_df['V10'] > v10_upper) | (new_df['V10'] < v10_lower)].index)\nprint('Number of Instances after outliers removal: {}'.format(len(new_df)))","8ea938d8":"f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,6))\n\n# Boxplots with outliers removed\n# Feature V14\nsns.boxplot(x=\"Class\", y=\"V14\", data=new_df,ax=ax1)\nax1.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\n\n# Feature 12\nsns.boxplot(x=\"Class\", y=\"V12\", data=new_df, ax=ax2)\nax2.set_title(\"V12 Feature \\n Reduction of outliers\", fontsize=14)\n\n# Feature V10\nsns.boxplot(x=\"Class\", y=\"V10\", data=new_df, ax=ax3)\nax3.set_title(\"V10 Feature \\n Reduction of outliers\", fontsize=14)\n\n\nplt.show()","cf643057":"X = new_df.drop('Class', axis=1)\ny = new_df['Class']\n\n\n# T-SNE Implementation\nt0 = time.time()\nX_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)\nt1 = time.time()\nprint(\"T-SNE took {:.2} s\".format(t1 - t0))","8ce45221":"f, (ax1) = plt.subplots(1, 1, figsize=(24,6))\n# labels = ['No Fraud', 'Fraud']\nf.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n\n\nblue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\nred_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n\n\n# t-SNE scatter plot\nax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\nax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\nax1.set_title('t-SNE', fontsize=14)\n\nax1.grid(True)\n\nax1.legend(handles=[blue_patch, red_patch])\n\nplt.show()","2374d67d":"# Undersampling before cross validating (prone to overfit)\nX = new_df.drop('Class', axis=1)\ny = new_df['Class']","78bdcd10":"# Our data is already scaled we should split our training and test sets\nfrom sklearn.model_selection import train_test_split\n\n# This is explicitly used for undersampling.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values","c2cf1cd2":"# Let's implement simple classifiers\n\nclassifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n    \"RandomForestClassifier\": RandomForestClassifier()\n}","925b7042":"from sklearn.model_selection import cross_val_score\n\n\nfor key, classifier in classifiers.items():\n    classifier.fit(X_train, y_train)\n    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")","408817ec":"from sklearn.model_selection import GridSearchCV\n\n# Logistic Regression \nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\ngrid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\ngrid_log_reg.fit(X_train, y_train)\n# We automatically get the logistic regression with the best parameters.\nlog_reg = grid_log_reg.best_estimator_\n\ntree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n              \"min_samples_leaf\": list(range(5,7,1))}\ngrid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\ngrid_tree.fit(X_train, y_train)\n\n# tree best estimator\ntree_clf = grid_tree.best_estimator_\n\n## Random Forest\n\nparam_grid = { \n    'n_estimators': [200, 700],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nrandom_gs = GridSearchCV(RandomForestClassifier(),param_grid)\nrandom_gs.fit(X_train, y_train)\n#forest best estimator\nrandom_clf = random_gs.best_estimator_","bd49f580":"voting_clf = VotingClassifier(estimators=[('lr',log_reg),('rf',random_clf),('dt',tree_clf)],voting='hard')\nvoting_clf.fit(X_train, y_train)","eb8fac79":"from sklearn.metrics import roc_curve\nfrom sklearn.model_selection import cross_val_predict\n# Create a DataFrame with all the scores and the classifiers names.\n\nlog_reg_pred = cross_val_predict(log_reg, X_train, y_train, cv=5,\n                             method=\"decision_function\")\n\n\ntree_pred = cross_val_predict(tree_clf, X_train, y_train, cv=5)\n\nrandom_pred = cross_val_predict(random_clf, X_train, y_train, cv=5)\nvoting_pred = cross_val_predict(voting_clf, X_train, y_train, cv=5)\nfrom sklearn.metrics import roc_auc_score\n\nprint('Logistic Regression: ROC_AUC_SCORE ', round(roc_auc_score(y_train, log_reg_pred),2)*100)\nprint('Decision Tree Classifier: ROC_AUC_SCORE', round(roc_auc_score(y_train, tree_pred),2)*100)\nprint('Random Forest Classifier: ROC_AUC_SCORE', round(roc_auc_score(y_train, random_pred),2)*100)\nprint('Voting Classifier: ROC_AUC_SCORE', round(roc_auc_score(y_train, voting_pred),2)*100)","224faa1c":"log_fpr, log_tpr, log_thresold = roc_curve(y_train, log_reg_pred)\ntree_fpr, tree_tpr, tree_threshold = roc_curve(y_train, tree_pred)\n\n\ndef graph_roc_curve_multiple(log_fpr, log_tpr, tree_fpr, tree_tpr):\n    plt.figure(figsize=(16,8))\n    plt.title('ROC Curve \\n Top 2 Classifiers', fontsize=18)\n    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_train, log_reg_pred)))\n    plt.plot(tree_fpr, tree_tpr, label='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_train, tree_pred)))\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([-0.01, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.legend()\n    \ngraph_roc_curve_multiple(log_fpr, log_tpr,tree_fpr, tree_tpr)\nplt.show()","ef9dbd1c":"## Random Under-Sampling:\nIn this phase of the project we will implement *\"Random Under Sampling\"* which basically consists of removing data in order to have a more <b> balanced dataset <\/b> and thus avoiding our models to overfitting.","b9536b6c":"* Our Dataset is highly Imbalanced and hence we need to use either Oversampling\/Undersampling to Tackle the problem","22e43495":"<h1 align=\"center\"> Credit Fraud Detector <\/h1>\n","6a6219da":"<h2> Classification Algorithm (UnderSampling):  <\/h2>\n<a id=\"classifiers\"><\/a>\nIn this section we will train 2 types of classifiers and decide which classifier will be more effective in detecting <b>fraud transactions<\/b>.  Before we have to split our data into training and testing sets and separate the features from the labels.","3d381c0d":"<h3> Correlation Matrices <\/h3>\n - Correlation matrices are the essence of understanding our data. We want to know if there are features that influence heavily in whether a specific transaction is a fraud. ","8ef28dca":"## Summary\n - Negative Correlations: V17, V14, V12 and V10 are negatively correlated.\n - Positive Correlations: V2, V4, V11, and V19 are positively correlated. ","4b192c7c":"### Splitting the Data (Original DataFrame)\nWe need to Split our Data, because we need to make sure to test the data on the original Dataset and not on the Undersampled\/OverSampled Dataset.","fd84e21f":"## Summary:\n\n- Using Undersampling Technique, I was able to handle the issue of Skewness in the dataset.\n- Used Logistic Regression method to classify the classes properly.\n- GridSearch CV was able to help us with better results because of hyperparameter tuning.","df67ff15":"##  Equally Distributing and Correlating: \n","076f5ef6":"# Scaling and Distributing\n\n- We can clearly see that our Dataset contains Time and Amount, which needs to be scaled as the other columns.\n- Also we need to create subsample of the dataframe in order to have an equal amount of Fraud and Non-Fraud Cases.","56c0572e":"## t-SNE Clustering Results","0fd56d3f":"## Anomaly Detection:\n\nOur main aim in this section is to remove \"extreme outliers\" from features that have a high correlation with our classes. This will have a positive impact on the accuracy of our models.  <br><br>\n\n\n### Interquartile Range Method:\n<ul>\n<li> <b>Interquartile Range (IQR): <\/b> We calculate this by the difference between the 75th percentile and 25th percentile. Our aim is to create a threshold beyond the 75th and 25th percentile that in case some instance pass this threshold the instance will be deleted.  <\/li>\n<li> <b>Boxplots: <\/b> Besides easily seeing the 25th and 75th percentiles (both end of the squares) it is also easy to see extreme outliers (points beyond the lower and higher extreme). <\/li>\n<\/ul>"}}