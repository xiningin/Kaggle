{"cell_type":{"17a93f0b":"code","115cf4cc":"code","c62550e8":"code","56222fdd":"code","97ff15ce":"code","298677ea":"code","422383ff":"code","dfe748d3":"code","217bbe09":"code","78c6c2a8":"code","ad9c3a34":"code","dc3261f0":"markdown","908c6e88":"markdown","67058a0a":"markdown","013ea64d":"markdown","ab0f3373":"markdown","8450cdd5":"markdown","92508784":"markdown","75b1a5d4":"markdown"},"source":{"17a93f0b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","115cf4cc":"train_ds = pd.read_csv('\/kaggle\/input\/tabular-playground-series-dec-2021\/train.csv', index_col='Id')\ntrain_ds.head(10)","c62550e8":"train_ds.drop([\"Soil_Type7\", \"Soil_Type15\"], axis=1, inplace=True)\ntrain_ds = train_ds.where(train_ds['Cover_Type'] != 5)\nprint('Before removing null: ', train_ds.isnull().sum().sum())\ntrain_ds.dropna(inplace=True)","56222fdd":"labels = train_ds['Cover_Type'].copy()\ntrain_ds = train_ds.drop('Cover_Type', axis=1) ","97ff15ce":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline, FeatureUnion\n\n\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, hill_feat, soil_feat, wild_feat):\n        self.hill_feat = hill_feat\n        self.soil_feat = soil_feat\n        self.wild_feat = wild_feat\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):        \n        X['Aspect'][X['Aspect'] < 0] += 360\n        X[\"Aspect\"][X[\"Aspect\"] > 359] -= 360\n\n        X[\"Mnhttn_Dist_Hydrlgy\"] = np.abs(X[\"Horizontal_Distance_To_Hydrology\"]) + np.abs(X[\"Vertical_Distance_To_Hydrology\"])\n        X[\"Ecldn_Dist_Hydrlgy\"] = (X[\"Horizontal_Distance_To_Hydrology\"]**2 + X[\"Vertical_Distance_To_Hydrology\"]**2)**0.5\n        \n        for hill in self.hill_feat:\n            X.loc[X[hill] < 0, hill] = 0\n            X.loc[X[hill] > 255, hill] = 255\n\n        X[\"Soil_Count\"] = X[self.soil_feat].apply(sum, axis=1)\n        X[\"Wild_Area_Count\"] = X[self.wild_feat].apply(sum, axis=1)\n        X[\"Hillshade_Mean\"] = X[self.hill_feat].mean(axis=1)\n        X['Amp_Hillshade'] = X[self.hill_feat].max(axis=1) - X[self.hill_feat].min(axis=1)\n\n        return X\n","298677ea":"hill_feat = [x for x in train_ds.columns if x.startswith(\"Hillshade\")]\nsoil_feat = [x for x in train_ds.columns if x.startswith(\"Soil_Type\")]\nwild_feat = [x for x in train_ds.columns if x.startswith(\"Wilderness_Area\")]\n\nfeature_engineer = FeatureEngineer(hill_feat=hill_feat, soil_feat=soil_feat, wild_feat=wild_feat)\ntrain_ds = feature_engineer.fit_transform(train_ds)\ntrain_ds.head(10)","422383ff":"class DataSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attributes):\n        self.attributes = attributes\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        return X[self.attributes].values.astype(np.float16)\n\n\nbool_cols = [i for i in train_ds.columns if i.startswith('Soil_Type') or i.startswith('Wilderness')]\nnum_cols = [i for i in train_ds.columns if not i.startswith('Soil_Type') and not i.startswith('Wilderness')]\n\nnum_pipeline = Pipeline([\n    ('num_selector', DataSelector(num_cols)),\n    ('scaler', StandardScaler())\n])\n\nint_pipeline = Pipeline([\n    ('int_selector', DataSelector(bool_cols))\n])\n\npreprocessor = FeatureUnion([\n    ('num_pipeline', num_pipeline),\n    ('int_pipeline', int_pipeline)\n])","dfe748d3":"train_ds = preprocessor.fit_transform(train_ds)\nlabels = labels.values","217bbe09":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=25, random_state=42, verbose=2, n_jobs=-1).fit(train_ds, labels)","78c6c2a8":"test_ds = pd.read_csv('\/kaggle\/input\/tabular-playground-series-dec-2021\/test.csv', index_col='Id')\n\nadded_features = FeatureEngineer(hill_feat=hill_feat, soil_feat=soil_feat, wild_feat=wild_feat).fit_transform(test_ds)\ntest_data = preprocessor.transform(added_features)\ntest_labels = clf.predict(test_data)","ad9c3a34":"predictions = test_labels.astype(np.uint8)\n\nsub_df = pd.DataFrame({'Id': test_ds.index, 'Cover_Type': predictions})\n\nsub_df.to_csv(\"submission.csv\", index=False)","dc3261f0":"If you found it useful - plz UV ;)","908c6e88":"This is an example of using tranfromers and pipelines in Sklearn. Feature engineering transformer is based on this research: https:\/\/www.kaggle.com\/balamurugan1603\/tps-dec-21-nn-feature-engg-tf","67058a0a":"I didn't reduce memory usage for this task, so *n_estimators=25*. Sorry) This is all for demonstrational purpose.","013ea64d":"Removing empty columns and NaN rows","ab0f3373":"Here we add data selector. It will seperate dataset based on column types. Also we define pipelines to preprocess dataset.","8450cdd5":"Our pipeline in action for test dataset.","92508784":"Prepare dataset with pipelines","75b1a5d4":"Here we define a feature engineering tranformer, it will addjust and add features."}}