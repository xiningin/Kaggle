{"cell_type":{"8c7bbc5b":"code","a81ba674":"code","a198306c":"code","7170ee39":"code","41f9a12c":"code","40e0539c":"code","74169fd6":"code","56bfdd39":"code","c1473fcc":"code","d0422430":"code","436778b2":"code","9a38a552":"code","cd50b631":"code","78be1f76":"code","ac213fd2":"code","35395170":"code","5deb4dcb":"code","53098ed5":"code","cd70910b":"code","b0f7c8cd":"code","0562370a":"code","557ee8e3":"code","16fa3775":"code","ac7389d2":"code","f5c74d02":"code","a870dbcb":"code","267337f0":"code","a92a2a17":"code","39817491":"code","76cc45a3":"code","eb5d7134":"code","55c7c5a3":"code","bfc89e6b":"code","0f3ff9f3":"code","af10978a":"code","b16bf1d9":"code","c5cf3c61":"code","81297c17":"code","6f7edc71":"code","30b4254e":"code","f574438e":"code","84cc8fd6":"code","a5c1e5fd":"code","be7a7885":"code","824bc056":"markdown","c67d556f":"markdown","28b71d9b":"markdown","025dfdae":"markdown"},"source":{"8c7bbc5b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (15,5)\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, TimeDistributed, LSTM, ConvLSTM2D\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, MaxPooling1D\nfrom keras.datasets import mnist\nfrom keras.utils import np_utils\nfrom keras import regularizers\nimport sys\nimport warnings\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a81ba674":"# importing data\nFDM = pd.read_csv('\/kaggle\/input\/nyse\/fundamentals.csv')\nPRS = pd.read_csv('\/kaggle\/input\/nyse\/prices.csv')\nSCR = pd.read_csv('\/kaggle\/input\/nyse\/securities.csv')\nPSA = pd.read_csv('\/kaggle\/input\/nyse\/prices-split-adjusted.csv')","a198306c":"FDM.columns","7170ee39":"FDM = FDM.drop(['For Year'], axis = 1)\nFDM = FDM.drop(['Earnings Per Share'], axis = 1)\nFDM = FDM.drop(['Estimated Shares Outstanding'], axis = 1)\nprint(FDM.isnull().sum())\nprint(FDM.shape)","41f9a12c":"#correlation_matrix = FDM.corr()\n#fig = plt.figure(figsize=(12,9))\n#sns.heatmap(correlation_matrix,vmax=0.3, vmin=-0.3,linewidths=1)\n#plt.show()","40e0539c":"PRS","74169fd6":"#FDM.head()\nPRS_12 = PRS[PRS['date'] == '2012-12-31']\nPRS_12 = PRS_12.drop(['open', 'low', 'high', 'volume'], axis = 1)\nPRS_13 = PRS[PRS['date'] == '2013-12-31']\nPRS_13 = PRS_13.drop(['open', 'low', 'high', 'volume'], axis = 1)\nPRS_14 = PRS[PRS['date'] == '2014-12-31']\nPRS_14 = PRS_14.drop(['open', 'low', 'high', 'volume'], axis = 1)\nPRS_15 = PRS[PRS['date'] == '2015-12-31']\nPRS_15 = PRS_15.drop(['open', 'low', 'high', 'volume'], axis = 1)\nPRS_16 = PRS[PRS['date'] == '2016-12-30']\nPRS_16 = PRS_16.drop(['open', 'low', 'high', 'volume'], axis = 1)\nPRS_16['date'] = '2016-12-31'\n","56bfdd39":"PRS_last = pd.concat((PRS_12, PRS_13, PRS_14, PRS_15, PRS_16, ), axis = 0)","c1473fcc":"#https:\/\/en.wikipedia.org\/wiki\/List_of_S%26P_500_companies\n#SCR.head()","d0422430":"PRS_X = PRS_12['symbol'].values\nall_L = PRS_16['symbol'].values\n\n#NewStock = np.setdiff1d(all_L, PRS_X)\na = np.setdiff1d(PRS_X, all_L)","436778b2":"#plt.plot(PRS[PRS['symbol'] == 'TRIP']['close'])\nPRS[PRS['symbol'] == 'TRIP'].head(10)","9a38a552":"#FDM.head()\n#FDM_all = FDM[FDM['Period Ending'] != '2016-12-31']\n#FDM_liv = FDM[FDM['Period Ending'] == '2016-12-31']","cd50b631":"FDM_all = FDM\nFDM_all.rename(columns = {'Period Ending' : 'date'}, inplace = True)\nFDM_all.rename(columns = {'Ticker Symbol' : 'symbol'}, inplace = True)","78be1f76":"#FDM_all = FDM_all[FDM_all['symbol'] == 'AAL']\nFDM_Merge = FDM_all.merge(PRS_last)\nFDM_Merge = FDM_Merge.fillna(0)\nFDM_Merge.head(4)","ac213fd2":"Symbol = FDM_Merge['symbol']\ndf_list = Symbol.unique()","35395170":"def df_Normal(df, df_list):\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    newData = np.zeros((1, df.shape[1]-3))\n    for i in range(0, len(df_list)):\n        x_df = df[df['symbol'] == df_list[i]]\n        x = x_df.iloc[:, 3:].values\n        x_ = sc.fit_transform(x)\n        newData = np.concatenate((newData, x_), axis = 0)\n    newData = np.delete(newData, (0), axis=0)\n    newData_DF = pd.DataFrame(newData)\n    newData_DF.columns = df.columns[3:]\n    return newData_DF\nFDM_Norm = df_Normal(FDM_Merge, df_list)","5deb4dcb":"FDM_Norm","53098ed5":"#FDM_Norm.corr().sort_values(by=['close'], axis=0, ascending=False).head(20)\n#FDM_Norm.corr().sort_values(by=['close'], axis=0, ascending=True).head(20)","cd70910b":"#+\n#Net Income, Earnings Before Tax Operating Income, Gross Profit, Retained Earnings, Net Cash Flow-Operating, Total Assets, Total Liabilities, Profit Margin\n#\ub2f9\uae30 \uc21c\uc774\uc775, \uc138\uc804 \uc601\uc5c5 \uc774\uc775, \uc21c\uc774\uc775, \uc774\uc775 \uc789\uc5ec\uae08, \uc21c \ud604\uae08 \ud750\ub984 \uc6b4\uc601, \ucd1d\uc790\uc0b0, \ubd80\ucc44, \uc774\uc724\n#-\n#Accounts Receivable, Capital Expenditures, Effect of Exchange Rate\n#\ucc44\uad8c, \uc790\ubcf8 \uc9c0\ucd9c, \ud658\uc728\uc758 \uc601\ud5a5","b0f7c8cd":"FDM_Norm_mod = FDM_Norm[['Net Income', 'Earnings Before Tax', 'Operating Income', 'Gross Profit', 'Retained Earnings', 'Net Cash Flow-Operating', 'Total Assets', 'Total Liabilities', 'Profit Margin', 'Accounts Receivable', 'Capital Expenditures', 'Effect of Exchange Rate', 'close']]","0562370a":"correlation_matrix = FDM_Norm_mod.corr()\nfig = plt.figure(figsize=(12,9))\nsns.heatmap(correlation_matrix,vmax=0.4, vmin=-0.4,linewidths=1, annot=True)\nplt.show()","557ee8e3":"#sns.pairplot(FDM_Norm_mod,kind=\"reg\")\n#plt.show()","16fa3775":"SCR","ac7389d2":"SCR_sym = SCR[['Ticker symbol']]\nSCR_sym.rename(columns = {'Ticker symbol' : 'symbol'}, inplace = True)\nSCR_sym","f5c74d02":"SCR_new = SCR['GICS Sub Industry']\n#SCR_new = SCR['GICS Sector']\nSCR_new\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nOH = OneHotEncoder()\nLE = LabelEncoder()\nSCR_new = LE.fit_transform(SCR_new)\nSCR_new = SCR_new.reshape(len(SCR_new), 1)\nOH.fit(SCR_new)\nSCR_new = OH.transform(SCR_new).toarray()\nSCR_new = pd.DataFrame(SCR_new)\n\nSCR_new.columns = LE.classes_\nSCR_new = pd.concat((SCR_sym, SCR_new), axis=1)\nSCR_new","a870dbcb":"FDM_Close = FDM_Merge[['symbol', 'date', 'close']]\nFDM_Close = FDM_Close.merge(SCR_new)\nFDM_Close","267337f0":"print(FDM_Close.corr().sort_values(by=['close'], axis=0, ascending=False).iloc[0:8, 0:1])\nprint(FDM_Close.corr().sort_values(by=['close'], axis=0, ascending=True).iloc[0:8, 0:1])","a92a2a17":"FDM_Close_mod = FDM_Close[['Internet & Direct Marketing Retail', 'Restaurants', 'Biotechnology', 'Life Sciences Tools & Services', 'Banks', 'MultiUtilities', 'Integrated Telecommunications Services', 'Electric Utilities', 'Oil & Gas Exploration & Production', 'close']]","39817491":"P_Stock_1 = FDM_Close[FDM_Close[['Internet & Direct Marketing Retail', 'Restaurants', 'Biotechnology', 'Life Sciences Tools & Services']].sum(axis=1) == 1]['symbol'].unique()\nM_Stock_1 = FDM_Close[FDM_Close[['Banks', 'MultiUtilities', 'Integrated Telecommunications Services', 'Electric Utilities', 'Oil & Gas Exploration & Production', 'Life Sciences Tools & Services']].sum(axis=1) == 1]['symbol'].unique()\nprint(P_Stock_1)\nprint(M_Stock_1)","76cc45a3":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\nN1 = P_Stock_1[:]\nwarnings.filterwarnings(action='ignore')\nfor i in range(0, len(N1)):\n    new_gs = PRS[PRS['symbol'] == N1[i]][['date', 'close']]\n    new_gs.time = pd.to_datetime(new_gs['date'])\n    new_gs.set_index(['date'],inplace=True)\n    new_gs['close'] = new_gs[['close']].rolling(window=20).mean()\n    new_gs['close'] = new_gs['close'].fillna(0)\n    #new_gs['close'] = sc.fit_transform(new_gs[['close']])\n    plt.plot(new_gs.time, new_gs['close'], label = N1[i])\n    plt.legend()\n    plt.grid(True)\n    if i % 4 == 3:\n        plt.show()\nwarnings.filterwarnings(action='default')","eb5d7134":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\nN1 = M_Stock_1[0:]\nwarnings.filterwarnings(action='ignore')\nfor i in range(0, len(N1)):\n    new_gs = PRS[PRS['symbol'] == N1[i]][['date', 'close']]\n    new_gs.time = pd.to_datetime(new_gs['date'])\n    new_gs.set_index(['date'],inplace=True)\n    new_gs['close'] = new_gs[['close']].rolling(window=20).mean()\n    new_gs['close'] = new_gs['close'].fillna(0)\n    #new_gs['close'] = sc.fit_transform(new_gs[['close']])\n    plt.plot(new_gs.time, new_gs['close'], label = N1[i])\n    plt.legend()\n    plt.grid(True)\n    if i % 3 == 2:\n        plt.show()","55c7c5a3":"PRS_list = PRS['symbol'].unique()\n#print(PRS_list)\nPRS_list = PRS_list[30:50]\nprint(PRS_list)\n#PRS_list = ['CL']","bfc89e6b":"seq_length = 31\nseq_length_div = int(seq_length \/ 2)\ndata_dim = 5\n\ndef build_dataset(time_series, seq_length):\n    \n    dataX = []\n    dataY = []\n    for i in range(0, (len(time_series) - seq_length)):\n        _x = time_series[i:i + seq_length-1, :data_dim]\n        _y = time_series[i + seq_length, [-1]]\n        \n        from sklearn.preprocessing import MinMaxScaler\n        sc = MinMaxScaler()\n        _x = sc.fit_transform(_x)\n\n        dataX.append(_x)\n        dataY.append(_y)\n        \n    return np.array(dataX), np.array(dataY)","0f3ff9f3":"def build_Stockset(Stocklist, seq_length, data_dim):\n    trainX = np.zeros((1,(seq_length-1)*data_dim))\n    trainY = np.zeros((1,1))\n    for i in range(0, len(Stocklist)):\n        PRS_rand = Stocklist[i]\n        PRS_symbol_close = PRS[PRS['symbol'] == PRS_rand]\n        PRS_symbol_close['close+1'] = PRS_symbol_close['close'].shift(-5)\n        PRS_symbol_close = PRS_symbol_close.iloc[:-1]\n        PRS_symbol_close['Fluctuation'] = (PRS_symbol_close['close+1']\/PRS_symbol_close['close'] -1)*100\n        ## lamda   elseif \ud558\ub294\ubc95 = True if() false,  (false\uc5d0\uc11c \ub2e4\uc2dc True if false)\uc5d0\uc11c \ub2e4\uc2dc True if false\n        PRS_symbol_close['target'] = PRS_symbol_close['Fluctuation'].apply(lambda x : 2 if x > 5 else (0 if x < -5 else 1)) \n        PRS_symbol_close = PRS_symbol_close.drop(['close+1', 'symbol', 'date'], axis = 1)\n        Case0 = PRS_symbol_close.iloc[:-5].values\n\n        Case0X, Case0Y = build_dataset(Case0, seq_length)\n        Case0X = np.reshape(Case0X, [Case0X.shape[0], -1])\n        Case0X.resize(Case0X.shape[0], data_dim*(seq_length-1))\n        \n        trainX = np.concatenate([trainX, Case0X], axis=0)\n        trainY = np.concatenate([trainY, Case0Y], axis=0)\n    return trainX, trainY\ntrainX, trainY = build_Stockset(PRS_list, seq_length, data_dim)\ntrainX = np.delete(trainX, (0), axis=0)\ntrainY = np.delete(trainY, (0), axis=0)\ntrainY = np_utils.to_categorical(trainY)","af10978a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(trainX,trainY,test_size=0.3, random_state = 42)","b16bf1d9":"import keras\n# NN\uc758 \uc815\uc758\n# SGD \ubcf4\ub2e4 \uc544\ub2f4\uc774 \uc798\ub428\nNNinput = X_train.shape[1]\nact = 'relu'\nopt = 'Adam'\nlos = 'categorical_crossentropy'\n\nmodel = Sequential()\nmodel.add(Dense(300, activation = act, input_shape = [NNinput,]))\nmodel.add(Dense(400, activation = act))\nmodel.add(Dense(200, activation = act))\nmodel.add(Dense(3, activation = 'softmax'))\nmodel.compile(optimizer = opt, loss = los, metrics = ['accuracy'])\n#model.summary()","c5cf3c61":"batch_size = 486\nepoch = 100\nhistory = model.fit(X_train, y_train, epochs = epoch, batch_size = batch_size, verbose = 1, validation_data = [X_test, y_test])","81297c17":"a = (y_test[:, :1] == 1).sum()\nb = (y_test[:, :2] == 1).sum()\nc = (y_test[:, :3] == 1).sum()\nprint(a, b, c)","6f7edc71":"(a + c) \/ b","30b4254e":"########### test\nPRS_list = PRS['symbol'].unique()\nPRS_list = PRS_list[206:207]\nprint(PRS_list)","f574438e":"testX, testY = build_Stockset(PRS_list, seq_length, data_dim)\ntestX = np.delete(testX, (0), axis=0)\ntestY1 = np.delete(testY, (0), axis=0)\ntestY1 = np_utils.to_categorical(testY1)","84cc8fd6":"pred = model.predict(testX)\n#pred[50:100]","a5c1e5fd":"pred1 = pred[:, 0]\npred1 = np.where(pred1 > 0.4, pred1, 0)\npred1 = pred1.reshape(len(pred1),1)\npred2 = pred[:, 2]\npred2 = np.where(pred2 > 0.4, pred2, 0)\npred2 = pred2.reshape(len(pred2),1)\ntestY = np.argmax(testY1,axis=1)\ntestY = testY.reshape(len(testY),1)","be7a7885":"Scale = 30\nShift = 45\nL1 = 1500\nL2 = 1700\nPRS_rand = PRS_list[0]\ntest_PRS = PRS[PRS['symbol'] == PRS_rand][['date', 'close']].iloc[30:].values\ntest_PRS = test_PRS[L1:L2]\npred1_ = pred1[L1:L2]*Scale + Shift\npred2_ = pred2[L1:L2]*Scale + Shift + 10\ntestY_ = testY[L1:L2]*Scale\/4 + Shift+20\n\ntest_PRS = np.concatenate((test_PRS, pred1_, pred2_, testY_), axis=1)\n\ntest_PRS = pd.DataFrame(test_PRS)\ntest_PRS.columns = ['date', 'close', 'Sell', 'Buy', 'test']\n\ntest_PRS.time = pd.to_datetime(test_PRS['date'])\ntest_PRS.set_index(['date'],inplace=True)\nplt.plot(test_PRS.time, test_PRS['close'],'o-', label = \"close\")\nplt.plot(test_PRS.time, test_PRS['Sell'],'-', label = \"Sell\")\nplt.plot(test_PRS.time, test_PRS['Buy'],'-', label = \"Buy\")\nplt.plot(test_PRS.time, test_PRS['test'],'-', label = \"Real\")\nplt.legend()\n#plt.plot(testY*Scale)\n#plt.plot(pred1[L1:L2]*Scale)\n#plt.plot(pred2[L1:L2]*Scale + Shift)\n\n## \ud314\uba74 40\ubd09\ub3d9\uc548 \uc0ac\uc9c0\uc54a\uace0  \ub2e4\uc2dc \ub9e4\uc218\ubd09\uc774\ub098\uc624\uba74 \uc0ac\uba74\ub428.","824bc056":"\ub2e4\uc74c\uc740\uc774 \ub370\uc774\ud130\ub85c \uc2dc\ub3c4 \ud560 \uc218\uc788\ub294 \uba87 \uac00\uc9c0 \uc0ac\ud56d\uc785\ub2c8\ub2e4.\n\n\ud558\ub8e8 \uc608\uce21 : \ub864\ub9c1 \uc120\ud615 \ud68c\uadc0, ARIMA, \uc2e0\uacbd\ub9dd, LSTM\n\n\ubaa8\uba58\ud140 \/ \ud3c9\uade0 \ubcf5\uadc0 \uc804\ub7b5\n\n\ubcf4\uc548 \ud074\ub7ec\uc2a4\ud130\ub9c1, \ud3ec\ud2b8\ud3f4\ub9ac\uc624 \uad6c\uc131 \/ \ud5e4\uc9c0\n\n1. \ud30c\uc0b0 \uac00\ub2a5\uc131\uc774 \uac00\uc7a5 \ud070 \ud68c\uc0ac\ub294 \uc5b4\ub290 \uac83\uc785\ub2c8\uae4c?\n2. \uc5b4\ub290 \uac83\uc774 \uc800\ud3c9\uac00 \ub418\uc5c8\ub294\uac00 (\ud6c4\uc5d0 \uac00\uaca9\uc774 \uc5b4\ub5bb\uac8c \ud589\ub3d9 \ud558\ub294\uac00) \ud22c\uc790\ud574\uc57c\ud560 \uc885\ubaa9\uc740?\n3. \ud22c\uc790 \uc218\uc775 (ROI)\uc774\ub780 \ubb34\uc5c7\uc785\ub2c8\uae4c?? <<?\n","c67d556f":"fundamentals.csv : \uc5f0\ub840 SEC 10K \ucda9\uc804 (2012-2016)\uc5d0\uc11c \ucd94\ucd9c\ud55c \uc9c0\ud45c\ub294 \ub300\ubd80\ubd84\uc758 \uc778\uae30\uc788\ub294 \uae30\ubcf8 \uc9c0\ud45c\ub97c \ub3c4\ucd9c\ud558\uae30\uc5d0 \ucda9\ubd84\ud574\uc57c\ud569\ub2c8\ub2e4.\n\nprices.csv : \ub0a0\uac83 \uadf8\ub300\ub85c\uc758 \uc77c\uc77c \uac00\uaca9\uc785\ub2c8\ub2e4. \ub300\ubd80\ubd84\uc758 \ub370\uc774\ud130\ub294 2010 \ub144\ubd80\ud130 2016 \ub144 \ub9d0\uae4c\uc9c0\uc774\uba70, \uc8fc\uc2dd \uc2dc\uc7a5 \ub0a0\uc9dc \ubc94\uc704\uc5d0 \uc0c8\ub85c\uc6b4 \ud68c\uc0ac\ub294 \ub354 \uc9e7\uc2b5\ub2c8\ub2e4..\n\n\ub2f9\uc2dc 140 \uac1c\uc758 \uc8fc\uc2dd\uc774 \ubd84\ud560\ub418\uc5c8\uc73c\ubbc0\ub85c\uc774 \uc138\ud2b8\ub294\uc774\ub97c \uc124\uba85\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n    \nsecurities.csv : \ubd80\ubb38\ubcc4\ub85c \ubd80\uc11c\uac00\uc788\ub294 \uac01 \ud68c\uc0ac\uc758 \uc77c\ubc18 \uc124\uba85\n\nprices-split-adjusted.csv : \uac00\uaca9\uacfc \ub3d9\uc77c\ud558\uc9c0\ub9cc \ubd84\ud560\uc5d0 \ub300\ud55c \uc870\uc815\uc774 \ucd94\uac00\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n","28b71d9b":"+\uc778\ud130\ub137 \ubc0f \ub2e4\uc774\ub809\ud2b8 \ub9c8\ucf00\ud305 \uc18c\ub9e4\n+\uc74c\uc2dd\uc810\n+\uc0dd\uba85 \uacf5\ud559\n+\uc0dd\uba85 \uacfc\ud559 \ub3c4\uad6c \ubc0f \uc11c\ube44\uc2a4\n+\uac74\uac15 \uad00\ub9ac \uc7a5\ube44\n+\uc0b0\uc5c5 \uc790\uc7ac\n+\ub370\uc774\ud130 \ucc98\ub9ac \ubc0f \uc544\uc6c3\uc18c\uc2f1 \uc11c\ube44\uc2a4\n\n-\uc740\ud589\n-\ub2e4\uc911 \uc720\ud2f8\ub9ac\ud2f0\n-\ud1b5\ud569 \ud1b5\uc2e0 \uc11c\ube44\uc2a4\n-\uc804\uae30 \uc2dc\uc124\n-\uc11d\uc720 \ubc0f \uac00\uc2a4 \ud0d0\uc0ac \ubc0f \uc0dd\uc0b0\n-\ud22c\uc790 \uc740\ud589 \ubc0f \uc911\uac1c\n-\ud56d\uacf5\n-\uc790\ub3d9\ucc28 \uc81c\uc870\uc5c5\uccb4","025dfdae":"'\ud2f0\ucee4 \uc2ec\ubcfc', '\uae30\uac04 \uc885\ub8cc', '\ucc44\ubb34 \ud68c\uacc4',\n'\ucc44\uad8c \uacc4\uc815', '\uc18c\ub4dd \/ \ube44\uc6a9 \ud56d\ubaa9 \ucd94\uac00', '\uc138\ud6c4 ROE',\n'\uc790\ubcf8 \uc9c0\ucd9c', '\uc790\ubcf8 \uc789\uc5ec\uae08', '\ud604\uae08 \ube44\uc728',\n'\ud604\uae08 \ubc0f \ud604\uae08\uc131 \uc790\uc0b0', '\uc7ac\uace0 \ubcc0\ub3d9 \uc0ac\ud56d', '\ubcf4\ud1b5\uc8fc',\n'\uc218\uc775 \ube44\uc6a9', '\ud604\uc7ac \ube44\uc728', '\uc774\uc5f0 \uc790\uc0b0 \ube44\uc6a9',\n'\uc9c0\uc5f0\ub41c \ucc45\uc784 \uccad\uad6c', '\uac10\uac00 \uc0c1\uac01',\n'\uc774\uc790 \ubc0f \uc138\uae08 \uc804 \uc18c\ub4dd', '\uc138\uae08 \uc804\uc5d0 \uc18c\ub4dd',\n'\ud658\uc728 \ud6a8\uacfc',\n'\uc790\ubcf8 \uc774\uc775 \/ \uc190\uc2e4 \uc5f0\uacb0 \uc790\ud68c\uc0ac', '\uace0\uc815 \uc790\uc0b0',\n'\uc601\uc5c5\uad8c', '\ucd1d \uc774\uc775', '\ucd1d \uc774\uc775', '\uc18c\ub4dd\uc138',\n'\ubb34\ud615 \uc790\uc0b0', '\uc774\uc790 \ube44\uc6a9', '\uc778\ubca4\ud1a0\ub9ac', '\ud22c\uc790',\n'\ubd80\ucc44', '\uc7a5\uae30 \ubd80\ucc44', '\uc7a5\uae30 \ud22c\uc790',\n'\uc18c\uc218\ubbfc \uad00\uc2ec\uc0ac', '\uae30\ud0c0 \uc8fc\uc2dd ','\uc21c \ucc28\uc785\uae08 ','\uc21c \ud604\uae08 \ud750\ub984 ',\n'\uc21c \ud604\uae08 \ud750\ub984 \uc6b4\uc601', '\uc21c \ud604\uae08 \ud750\ub984 \uae08\uc735',\n'\uc21c \ud604\uae08 \ud750\ub984 \ud22c\uc790', '\uc21c\uc774\uc775', '\uc21c\uc774\uc775 \uc870\uc815',\n'\ubcf4\ud1b5 \uc8fc\uc8fc\uc5d0\uac8c \uc801\uc6a9\ub418\ub294 \uc21c\uc774\uc775',\n'\uc21c\uc774\uc775-\uacc4\uc18d. \uc6b4\uc601 ','\uc21c \ucc44\uad8c ','\ubc18\ubcf5\ub418\uc9c0 \uc54a\uc740 \ud488\ubaa9 ',\n'\uc601\uc5c5 \uc774\uc775', '\uc601\uc5c5 \uc774\uc775', '\uae30\ud0c0 \uc790\uc0b0',\n'\uae30\ud0c0 \uc720\ub3d9 \uc790\uc0b0', '\uae30\ud0c0 \uc720\ub3d9 \ubd80\ucc44', '\uae30\ud0c0 \uc790\ubcf8',\n'\uae30\ud0c0 \uae08\uc735 \ud65c\ub3d9', '\uae30\ud0c0 \ud22c\uc790 \ud65c\ub3d9',\n'\uae30\ud0c0 \ubd80\ucc44', '\uae30\ud0c0 \uc6b4\uc601 \ud65c\ub3d9',\n'\uae30\ud0c0 \uc6b4\uc601 \ud488\ubaa9', '\uc138\uc804 \uc774\uc775', '\uc138\uc804 ROE',\n'\uc774\uc775 \ub9c8\uc9c4', '\ube60\ub978 \ube44\uc728', '\uc5f0\uad6c \ubc0f \uac1c\ubc1c',\n'\uc774\uc775 \uc789\uc5ec\uae08', '\uc8fc\uc2dd \ud310\ub9e4 \ubc0f \uad6c\ub9e4',\n'\uc601\uc5c5, \uc77c\ubc18 \ubc0f \uad00\ub9ac\uc790',\n'\ub2e8\uae30 \ubd80\ucc44 \/ \uc7a5\uae30 \ubd80\ucc44\uc758 \ud604\uc7ac \ubd80\ubd84',\n'\ub2e8\uae30 \ud22c\uc790', '\ucd1d \uc790\uc0b0', '\ucd1d \uc720\ub3d9 \uc790\uc0b0',\n'\ucd1d \uc720\ub3d9 \ubd80\ucc44', '\ucd1d \uc790\ubcf8', '\ucd1d \ubd80\ucc44',\n'\ucd1d \ubd80\ucc44 \ubc0f \uc790\ubcf8', '\ucd1d \uc218\uc775', '\uc7ac\uace0',\n'\uc5f0\ub3c4 \ubcc4', '\uc8fc\ub2f9 \uc21c\uc774\uc775', '\uc608\uc0c1 \uc8fc\uac00 \uc6b0\uc218'\n\n\n"}}