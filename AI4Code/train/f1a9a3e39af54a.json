{"cell_type":{"70a4f396":"code","d42baa42":"code","655ef70c":"code","231ae745":"code","bcd50e9a":"code","d908c21c":"code","5479fb96":"code","f4e7d73d":"code","c01b514d":"code","6599238d":"code","a310049c":"code","11f96a1b":"code","0a378a5b":"code","f9ba6a73":"code","b517d33d":"code","1c971c3b":"code","17257319":"code","d7778ec1":"code","09fc57ee":"code","0dad7454":"code","af3114ba":"code","d9c430b0":"code","333130ad":"code","606dc282":"code","c711c764":"code","585307c6":"code","7e477efc":"code","077139c2":"code","607db14c":"code","e7f26a64":"code","cd77b164":"code","53fc4db2":"code","d6b0c6dd":"code","db11b4b5":"code","218ac845":"code","86cdd652":"code","de496885":"code","3844442f":"markdown"},"source":{"70a4f396":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d42baa42":"!pip install pyspark","655ef70c":"from pyspark import SparkContext, SparkConf\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Window, SparkSession\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import DoubleType, StringType, ArrayType, LongType, FloatType, DateType\nfrom sklearn.model_selection import train_test_split\nimport sys\nimport xgboost as xgb\nimport numpy as np\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import label_binarize\nimport lightgbm as lgb","231ae745":"spark = (SparkSession.builder\n                  .appName('Toxic Comment Classification')\n                  .enableHiveSupport()\n                  .config(\"spark.executor.memory\", \"10G\")\n                  .config(\"spark.driver.memory\",\"5G\")\n                  .config(\"spark.executor.cores\",\"7\")\n                  .config(\"spark.python.worker.memory\",\"4G\")\n                  .config(\"spark.driver.maxResultSize\",\"0\")\n                  .config(\"spark.sql.crossJoin.enabled\", \"true\")\n                  .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n                  .config(\"spark.default.parallelism\",\"2\")\n                  .config(\"spark.kryoserializer.buffer.max.mb\", \"2047\").getOrCreate()\n        )","bcd50e9a":"df = spark.read.csv('\/kaggle\/input\/liverpool-ion-switching\/train.csv', header=True)","d908c21c":"df.show()","5479fb96":"description = df.describe().collect()\ndescription","f4e7d73d":"signal_stddev = float(description[2]['signal'])\nopen_channels_stddev = float(description[2]['open_channels'])\n\nsignal_mean = float(description[1]['signal'])\nopen_channels_mean = float(description[1]['open_channels'])","c01b514d":"df1 = df.filter(col('time') <= 50)\ndf2 = df.filter(col('time') > 50)","6599238d":"last_2 = Window().orderBy('time').rowsBetween(-2, -1)\nlast_4 = Window().orderBy('time').rowsBetween(-4, -1)\nlast_8 = Window().orderBy('time').rowsBetween(-8, -1)\nlast_16 = Window().orderBy('time').rowsBetween(-16, -1)\nlast_32 = Window().orderBy('time').rowsBetween(-32, -1)\n\nlead_2 = Window().orderBy('time').rowsBetween(1, 2)\nlead_4 = Window().orderBy('time').rowsBetween(1, 4)\nlead_8 = Window().orderBy('time').rowsBetween(1, 8)\nlead_16 = Window().orderBy('time').rowsBetween(1, 16)\nlead_32 = Window().orderBy('time').rowsBetween(1, 32)","a310049c":"df1 = df1.withColumn('last_2_sig_mean', F.mean('signal').over(last_2))\ndf1 = df1.withColumn('last_4_sig_mean', F.mean('signal').over(last_4))\ndf1 = df1.withColumn('last_8_sig_mean', F.mean('signal').over(last_8))\ndf1 = df1.withColumn('last_16_sig_mean', F.mean('signal').over(last_16))\ndf1 = df1.withColumn('last_32_sig_mean', F.mean('signal').over(last_32))\ndf1 = df1.withColumn('last_64_sig_mean', F.mean('signal').over(last_64))\ndf1 = df1.withColumn('last_128_sig_mean', F.mean('signal').over(last_128))\n\ndf1 = df1.withColumn('lead_2_sig_mean', F.mean('signal').over(lead_2))\ndf1 = df1.withColumn('lead_4_sig_mean', F.mean('signal').over(lead_4))\ndf1 = df1.withColumn('lead_8_sig_mean', F.mean('signal').over(lead_8))\ndf1 = df1.withColumn('lead_16_sig_mean', F.mean('signal').over(lead_16))\ndf1 = df1.withColumn('lead_32_sig_mean', F.mean('signal').over(lead_32))\ndf1 = df1.withColumn('lead_64_sig_mean', F.mean('signal').over(lead_64))\ndf1 = df1.withColumn('lead_128_sig_mean', F.mean('signal').over(lead_128))\n\ndf2 = df2.withColumn('last_2_sig_mean', F.mean('signal').over(last_2))\ndf2 = df2.withColumn('last_4_sig_mean', F.mean('signal').over(last_4))\ndf2 = df2.withColumn('last_8_sig_mean', F.mean('signal').over(last_8))\ndf2 = df2.withColumn('last_16_sig_mean', F.mean('signal').over(last_16))\ndf2 = df2.withColumn('last_32_sig_mean', F.mean('signal').over(last_32))\ndf2 = df2.withColumn('last_64_sig_mean', F.mean('signal').over(last_64))\ndf2 = df2.withColumn('last_128_sig_mean', F.mean('signal').over(last_128))\n\ndf2 = df2.withColumn('lead_2_sig_mean', F.mean('signal').over(lead_2))\ndf2 = df2.withColumn('lead_4_sig_mean', F.mean('signal').over(lead_4))\ndf2 = df2.withColumn('lead_8_sig_mean', F.mean('signal').over(lead_8))\ndf2 = df2.withColumn('lead_16_sig_mean', F.mean('signal').over(lead_16))\ndf2 = df2.withColumn('lead_32_sig_mean', F.mean('signal').over(lead_32))\ndf2 = df2.withColumn('lead_64_sig_mean', F.mean('signal').over(lead_64))\ndf2 = df2.withColumn('lead_128_sig_mean', F.mean('signal').over(lead_128))\n\n\n","11f96a1b":"df1 = df1.toPandas()","0a378a5b":"df2 = df2.toPandas()","f9ba6a73":"df = pd.concat([df1, df2], sort=False)","b517d33d":"df['signal'] = df['signal'].astype(np.float64)","1c971c3b":"df = df.fillna(0)","17257319":"df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)","d7778ec1":"clf = xgb.XGBClassifier(\n    n_estimators=5,\n    max_depth=9,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    missing=-999,\n    random_state=2000\n)","09fc57ee":"all_but_open_channels = list(df.columns)\nall_but_open_channels.remove('open_channels')\nall_but_open_channels.remove('time')","0dad7454":"%time clf.fit(df_train[all_but_open_channels], df_train['open_channels'])","af3114ba":"probs = clf.predict_proba(df_test[all_but_open_channels])","d9c430b0":"df_test['open_channels']","333130ad":"y_test = label_binarize(df_test['open_channels'], classes=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\ny_score = probs\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(11):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nprint(roc_auc)\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nauc = roc_auc['micro']\n\nprint('AUC performance', auc)","606dc282":"auc","c711c764":"y_score.shape","585307c6":"df = spark.read.csv('\/kaggle\/input\/liverpool-ion-switching\/test.csv', header=True)","7e477efc":"df = df.withColumn('last_2_sig_mean', F.mean('signal').over(last_2))\ndf = df.withColumn('last_4_sig_mean', F.mean('signal').over(last_4))\ndf = df.withColumn('last_8_sig_mean', F.mean('signal').over(last_8))\ndf = df.withColumn('last_16_sig_mean', F.mean('signal').over(last_16))\ndf = df.withColumn('history_mean', F.mean('signal').over(history))","077139c2":"df = df.toPandas()","607db14c":"df['signal'] = df['signal'].astype(np.float64)","e7f26a64":"df = df.fillna(0)","cd77b164":"preds = clf.predict(df[all_but_open_channels])","53fc4db2":"submission = pd.read_csv('\/kaggle\/input\/liverpool-ion-switching\/sample_submission.csv')","d6b0c6dd":"submission","db11b4b5":"submission['open_channels'] = preds","218ac845":"submission['time'] = submission['time'].map(lambda x: '%.4f' % x)","86cdd652":"submission.to_csv('submission.csv', index=False)","de496885":"submission[submission['time'] == 500.0010]","3844442f":"Let us describe the dataset."}}