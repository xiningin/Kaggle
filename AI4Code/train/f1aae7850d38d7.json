{"cell_type":{"3e519d0f":"code","08d3caf2":"code","da52bb39":"code","958b0168":"code","fc846b3a":"code","f57c7390":"markdown"},"source":{"3e519d0f":"!pip install -U pandas\nimport re\nimport pandas as pd","08d3caf2":"#Creamos el primer Dataframe con el primer Dataset\n\n#Est\u00e1 separado en 2 archivos (El path es el default de Kaggle, recomiendo correr ahi o tendran q modificar esto)\nqs_df1 = pd.read_csv(\"..\/input\/askreddit-questions-and-answers\/reddit_questions.csv\", delimiter=';')\nans_df1 = pd.read_csv(\"..\/input\/askreddit-questions-and-answers\/reddit_answers.csv\", delimiter=';')\n\n#Merge y lo limpiamos un poquito\ndf1 = qs_df1.merge(ans_df1, left_on=\"id\", right_on=\"q_id\").drop(columns=[\"datetime\", \"q_id\", \"timestamp\"]).rename(columns={\"text_x\": \"Q\", \"text_y\": \"ANS\", \"votes_x\": \"Qscore\", \"votes_y\": \"ANSscore\"}).drop(columns=[\"Unnamed: 0\"])\n\n#Temporal: solo dejamos los comentarios con m\u00e1s upvotes\ndf1 = df1.groupby(\"id\", as_index=False).agg(lambda x: max(x))\n\ndf1","da52bb39":"#Creamos el segundo dataframe para el otro dataset\n\n#Est\u00e1 separado en 2 archivos\nans_df2 = pd.read_csv(\"..\/input\/a-month-of-askreddit\/askreddit_comments.csv\", dtype=str).drop(columns=[ \"permalink\", \"timestamp\", \"author\"])\nqs_df2 = pd.read_csv(\"..\/input\/a-month-of-askreddit\/askreddit_posts.csv\", dtype=str).drop(columns=[\"author\", \"timestamp\", \"num_comments\", \"selftext\", \"permalink\"]).rename({\"title\": \"text\"})\n\n#filtramos los comentarios que sean directos al post.\nans_df2 = ans_df2[ans_df2[\"post_id\"] == ans_df2[\"parent_id\"]]\n\n#Normalizamos el id\nans_df2[\"post_id\"] = ans_df2[\"post_id\"].str.replace(\"t3_\", \"\")\n\nans_df2 = ans_df2.drop(columns=[ \"parent_id\"]).rename(columns={\"body\": \"ANS\", \"score\": \"ANSscore\", \"post_id\": \"id\"})\n\n#Ajustamos los nombres para que coincidan\nqs_df2 = qs_df2.rename(columns={\"post_id\": \"id\", \"title\": \"Q\", \"score\": \"Qscore\"})\n\ndf2 = qs_df2.merge(ans_df2, left_on=\"id\", right_on=\"id\")\n\n\ndf2 = df2.groupby(\"id\", as_index=False).first()\n\ndf2","958b0168":"# Los concatenamos, Y Ya tenemos un lindo corpus de AskReddit para multiple uso\ndf = pd.concat([df1, df2], ignore_index=True)\n\n#lo guardamos depaso\ndf.to_csv(\"ask-reddit-corpus.csv\")\ndf.to_pickle(\"ask-reddit-corpus.pkl\")\ndf","fc846b3a":"\n\n#qs1_df[qs1_df[\"text\"].str.contains(r\"deworm\", flags=re.IGNORECASE)]\n\n#qs1_df[qs1_df[\"text\"].str.contains(r\"conspiracy|hoax|tested|pfizer|covid|vax|Sputnik|Moderna|Jab|vacc|corona|virus|Dosis|Cases|Face\\W?Mask|pandemic|quarantine|social distanc\", flags=re.IGNORECASE)]","f57c7390":"# Creating an AskReddit QA Corpus\n\n**I'm using this 2 datasets from kaggle where they collected a good number of Askreddit Posts.  \nIt could be easily expanded if given a little time**\n"}}