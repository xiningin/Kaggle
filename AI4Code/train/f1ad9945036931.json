{"cell_type":{"78270ec2":"code","25f0ff7a":"code","ad8bd71b":"code","e3ce32f6":"code","1a679235":"code","121a606e":"code","cea88d81":"code","4a8cf079":"code","6145cefd":"code","f5394dcf":"code","aa589955":"code","766d758a":"code","96c3d964":"code","75220d59":"code","14f978bf":"code","8f62cc89":"code","f5a4c22c":"code","eb34bce8":"code","3cce97ed":"markdown","13d88927":"markdown","e6a0cd5d":"markdown","cf08978d":"markdown","363dfaa5":"markdown","b1115e3c":"markdown","d30b9693":"markdown","083feca7":"markdown","9edceace":"markdown","3e480809":"markdown","004b01a6":"markdown","3e386b3b":"markdown","42c2a72c":"markdown","024d9be8":"markdown","4bcca9ea":"markdown","c4461d72":"markdown"},"source":{"78270ec2":"!pip install chart_studio\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom wordcloud import WordCloud, STOPWORDS\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom spacy.lang.en import English\nimport re\nimport string\n\nimport matplotlib.pyplot as plt\nfrom plotly import tools\nimport chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","25f0ff7a":"train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","ad8bd71b":"train['text'] = train['text'].str.replace('[{}]'.format(string.punctuation), '')\ntest['text'] = test['text'].str.replace('[{}]'.format(string.punctuation), '')","e3ce32f6":"train.head(3)","1a679235":"test.head(3)","121a606e":"print(train.size)\nprint(train.shape)\nprint(test.shape)\nprint(test.size)","cea88d81":"train.describe()","4a8cf079":"sns.countplot(train['sentiment'])","6145cefd":"# Thanks : https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(10.0,10.0), color = 'white',\n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color=color,\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=600, \n                    height=300,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train.loc[train['sentiment'] == 'neutral', 'text'].append(test.loc[test['sentiment'] == 'neutral', 'text']), title=\"Word Cloud of Neutral tweets\",color = 'white')","f5394dcf":"plot_wordcloud(train.loc[train['sentiment'] == 'positive', 'text'].append(test.loc[test['sentiment'] == 'positive', 'text']), title=\"Word Cloud of Positive tweets\",color = 'green')","aa589955":"plot_wordcloud(train.loc[train['sentiment'] == 'negative', 'text'].append(test.loc[test['sentiment'] == 'negative', 'text']), title=\"Word Cloud of negative tweets\",color = 'red')","766d758a":"from collections import defaultdict\ntrain0_df = train[train[\"sentiment\"]=='positive'].dropna().append(test[test[\"sentiment\"]=='positive'].dropna())\ntrain1_df = train[train[\"sentiment\"]=='neutral'].dropna().append(test[test[\"sentiment\"]=='neutral'].dropna())\ntrain2_df = train[train[\"sentiment\"]=='negative'].dropna().append(test[test[\"sentiment\"]=='neutral'].dropna())\n\n## custom function for ngram generation ##\ndef generate_ngrams(text, n_gram=1):\n    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n    ngrams = zip(*[token[i:] for i in range(n_gram)])\n    return [\" \".join(ngram) for ngram in ngrams]\n\n## custom function for horizontal bar chart ##\ndef horizontal_bar_chart(df, color):\n    trace = go.Bar(\n        y=df[\"word\"].values[::-1],\n        x=df[\"wordcount\"].values[::-1],\n        showlegend=False,\n        orientation = 'h',\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\n## Get the bar chart from sincere questions ##\nfreq_dict = defaultdict(int)\nfor sent in train0_df[\"text\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'red')\n\n## Get the bar chart from insincere questions ##\nfreq_dict = defaultdict(int)\nfor sent in train1_df[\"text\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'green')\n\n## Get the bar chart from sincere questions ##\nfreq_dict = defaultdict(int)\nfor sent in train2_df[\"text\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'orange')\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04,\n                          subplot_titles=[\"Frequent words of positive tweets\", \"Frequent words of neutral tweets\",\n                                          \"Frequent words of negative tweets\"])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\nfig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\niplot(fig, filename='word-plots')\n","96c3d964":"freq_dict = defaultdict(int)\nfor sent in train0_df[\"text\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'gray')\n\n\nfreq_dict = defaultdict(int)\nfor sent in train1_df[\"text\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'orange')\n\nfreq_dict = defaultdict(int)\nfor sent in train2_df[\"text\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'brown')\n\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04,horizontal_spacing=0.25,\n                          subplot_titles=[\"Bigram plots of Positive tweets\", \n                                          \"Bigram plots of Neutral tweets\",\n                                          \"Bigram plots of Negative tweets\"\n                                          ])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\n\n\nfig['layout'].update(height=1000, width=800, paper_bgcolor='rgb(233,233,233)', title=\"Bigram Plots\")\niplot(fig, filename='word-plots')","75220d59":"for sent in train0_df[\"text\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'blue')\n\n\nfreq_dict = defaultdict(int)\nfor sent in train1_df[\"text\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'green')\n\nfreq_dict = defaultdict(int)\nfor sent in train2_df[\"text\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'violet')\n\n\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04, horizontal_spacing=0.05,\n                          subplot_titles=[\"Tri-gram plots of Positive tweets\", \n                                          \"Tri-gram plots of Neutral tweets\",\n                                          \"Tri-gram plots of Negative tweets\"])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\nfig['layout'].update(height=1200, width=1200, paper_bgcolor='rgb(233,233,233)', title=\"Trigram Count Plots\")\niplot(fig, filename='word-plots')","14f978bf":"train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\ntest[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\ntrain['select_num_words'] = train[\"selected_text\"].apply(lambda x: len(str(x).split()))\n\n## Number of unique words in the text ##\ntrain[\"num_unique_words\"] = train[\"text\"].apply(lambda x: len(set(str(x).split())))\ntest[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\ntrain['select_num_unique_words'] = train[\"selected_text\"].apply(lambda x: len(set(str(x).split())))\n\n## Number of characters in the text ##\ntrain[\"num_chars\"] = train[\"text\"].apply(lambda x: len(str(x)))\ntest[\"num_chars\"] = test[\"text\"].apply(lambda x: len(str(x)))\ntrain['select_num_chars'] = train[\"selected_text\"].apply(lambda x: len(str(x)))","8f62cc89":"fig = go.Figure()\nfig.add_trace(go.Histogram(x=train['num_words'],name = 'Number of words in text of train data'))\nfig.add_trace(go.Histogram(x=test['num_words'],name = 'Number of words in text of test data'))\nfig.add_trace(go.Histogram(x=train['select_num_words'],name = 'Number of words in selected text'))\n\n# Overlay both histograms\nfig.update_layout(barmode='stack')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.75)\nfig.show()","f5a4c22c":"fig_ = go.Figure()\nfig_.add_trace(go.Histogram(x=train['num_chars'],name = 'Number of characters in text of train data',marker = dict(color = 'rgba(222, 111, 33, 0.8)')))\nfig_.add_trace(go.Histogram(x=test['num_chars'],name = 'Number of characters in text of test data',marker = dict(color = 'rgba(33, 1, 222, 0.8)')))\nfig_.add_trace(go.Histogram(x=train['select_num_chars'],name = 'Number of characters in selected text',marker = dict(color = 'rgba(108, 25, 7, 0.8)')))\n\n# Overlay both histograms\nfig_.update_layout(barmode='stack')\n# Reduce opacity to see both histograms\nfig_.update_traces(opacity=0.75)\nfig_.show()","eb34bce8":"fig_ = go.Figure()\nfig_.add_trace(go.Histogram(x=train['num_unique_words'],name = 'Number of unique words in text of train data',marker = dict(color = 'rgba(222, 1, 3, 0.8)')))\nfig_.add_trace(go.Histogram(x=test['num_unique_words'],name = 'Number of unique words in text of test data',marker = dict(color = 'rgba(3, 221, 2, 0.8)')))\nfig_.add_trace(go.Histogram(x=train['select_num_unique_words'],name = 'Number of unique words in selected text',marker = dict(color = 'rgba(1, 2, 237, 0.8)')))\n\n# Overlay both histograms\nfig_.update_layout(barmode='stack')\n# Reduce opacity to see both histograms\nfig_.update_traces(opacity=0.75)\nfig_.show()","3cce97ed":"# NOW START BUILDING THE MODEL","13d88927":"From above Ngaram analysis we can observe that neutral tweets and negative tweets had more amount of repeteted words than positive tweets.","e6a0cd5d":"## 4.Histogram plot of Number of words","cf08978d":"# Histogram plots of Number of characters","363dfaa5":"# Text Data Preprocessing","b1115e3c":"**stay tuned** I will update the model of having high accuracy soon. ","d30b9693":"From above plot we can see that number of characters in test and train set was in same range.In selected text the range flows from 3 to 138 Characters.","083feca7":"## 3.Tri-gram Plots:","9edceace":"We can see that number of unique words in train and test sets range from 1 to 26. In selected text most number  ","3e480809":"## 1.Ngram Analysis:","004b01a6":"**NOW BASIC EDA, TEXT PREPROCESSING IS COMPLETED **","3e386b3b":"We can observe from above histogram plot that the number of words in train text and test text ranges from 1 to 30.Selected text words mostly fall in range of 1-10. ","42c2a72c":"**Please upvote if you like it and keep me motivated**","024d9be8":"# Reading the data","4bcca9ea":"# Word clouds of Text:","c4461d72":"## 2.Bi-gram Plots:"}}