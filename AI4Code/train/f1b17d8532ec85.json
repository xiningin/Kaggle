{"cell_type":{"2823bea4":"code","7b2a1c7b":"code","602d7c16":"code","61dd3587":"code","5c89e5ae":"code","96276f6f":"code","9237db22":"code","2997d7e1":"code","a2ca2705":"code","b0e968bf":"code","c8816767":"code","75bf9d25":"code","26278e1d":"code","912afb36":"code","abb2d8a0":"code","a551137a":"code","c26cf546":"code","a45da7e7":"code","b237d6da":"code","3b1605f3":"markdown","30c3cfa4":"markdown","f65091a5":"markdown","192a9ec6":"markdown","8e1c7c9e":"markdown","df593a17":"markdown","fdc89143":"markdown"},"source":{"2823bea4":"import os \nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom pathlib import Path\nfrom matplotlib.image import imread\nimport plotly.express as px ","7b2a1c7b":"tf.config.list_physical_devices()  # APU device is visible to TensorFlow.","602d7c16":"base_dir = '..\/input\/yoga-pose-image-classification-dataset\/dataset\/'\nprint('Number of post to be predicted: ',len(os.listdir(base_dir)))","61dd3587":"class_dir = '..\/input\/yoga-pose-image-classification-dataset\/dataset\/janu sirsasana'\n","5c89e5ae":"fig, axes = plt.subplots(nrows=2, ncols=3,figsize=(10,5), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(os.path.join(class_dir,os.listdir(class_dir)[i])))\n    ax.set_title(os.listdir(base_dir)[1])\nplt.tight_layout()\nplt.show()\n","96276f6f":"## count number of images in each class\nDF = pd.DataFrame(columns=['class','count'])\nDF['class']=pd.Series([os.listdir(base_dir)[x] for x in range(0,107)])\nDF['count']=pd.Series([len(os.listdir(os.path.join(base_dir,os.listdir(base_dir)[x]))) for x in range(0,107)])\n","9237db22":"import seaborn as sns\nplt.figure(figsize=(14,10))\ng=sns.barplot(x='class', y='count',data=DF)\ng.set_xticklabels(g.get_xticklabels(), rotation=90)\nplt.tight_layout()","2997d7e1":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                  width_shift_range = 0.1,\n                                  height_shift_range = 0.1,\n                                  shear_range = 0.1,\n                                  zoom_range= 0.1,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest',\n                                  validation_split=0.2)\n","a2ca2705":"train_data = train_datagen.flow_from_directory(\n    base_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training')\n\nvalidation_data = train_datagen.flow_from_directory(\n    base_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation')","b0e968bf":"from tensorflow.keras.layers import MaxPool2D, Flatten, Dense, Conv2D\n# covnet\nmodel = tf.keras.models.Sequential([Conv2D(128,(3,3),input_shape=(224,224,3),activation='relu'),\n                                   Conv2D(128,(3,3)),\n                                   MaxPool2D(2,2),\n                                   Conv2D(64,(3,3)),\n                                   Conv2D(64,(3,3)),\n                                   MaxPool2D(2,2),\n                                   Conv2D(32,(3,3)),\n                                   Conv2D(32,(3,3)),\n                                   MaxPool2D(2,2),\n                                   Flatten(),\n                                   Dense(1024,activation='relu'),\n                                   Dense(512,activation='relu'),\n                                   Dense(107,activation='softmax')])\n","c8816767":"#compile\nmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])","75bf9d25":"with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index='0')):\n    history = model.fit(train_data, steps_per_epoch=120,validation_data=validation_data, validation_steps=35, epochs=25,verbose=1,\n                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.01,patience=3,restore_best_weights=True)])","26278e1d":"model.evaluate(validation_data)","912afb36":"from tensorflow.keras.applications.resnet50 import ResNet50\n\ndef resnet_feature_extractor(inputs):\n\n  feature_extractor =ResNet50(input_shape=(224, 224, 3),include_top=False, weights='imagenet')(inputs)\n  return feature_extractor","abb2d8a0":"\ndef classifier(inputs):\n    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n    x = tf.keras.layers.Dense(107, activation=\"softmax\", name=\"classification\")(x)\n    return x\n\n\ninputs = tf.keras.layers.Input(shape=(224,224,3))\nfeature_extractor = resnet_feature_extractor(inputs)\nclassification_output = classifier(feature_extractor)\nresnet = tf.keras.Model(inputs=inputs, outputs = classification_output)\nresnet.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n#resnet.compile(optimizer='SGD', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\nresnet.summary()","a551137a":"with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index='0')):\n    resnet_history = resnet.fit(train_data, steps_per_epoch=120,validation_data=validation_data, validation_steps=35, epochs=25,verbose=1,\n                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001,patience=3,restore_best_weights=True)])","c26cf546":"from tensorflow.keras.applications.vgg16 import VGG16\n\ndef vgg_feature_extractor(inputs):\n\n  feature_extractor = VGG16(input_shape=(224, 224, 3),include_top=False,\n                            weights='imagenet')(inputs)\n  return feature_extractor","a45da7e7":"inputs = tf.keras.layers.Input(shape=(224,224,3))\nfeature_extractor = vgg_feature_extractor(inputs)\nclassification_output = classifier(feature_extractor)\nvgg = tf.keras.Model(inputs=inputs, outputs = classification_output)\nvgg.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=_rate=0.01), metrics=['accuracy'])\n#vgg.compile(optimizer='SGD', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n","b237d6da":"with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index='0')):\n    vgg_history = vgg.fit(train_data, steps_per_epoch=120,validation_data=validation_data, validation_steps=35, epochs=25,verbose=1,\n                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001,patience=3,restore_best_weights=True)])","3b1605f3":"Data Preprocessing","30c3cfa4":"# **Classification of Yoga posts**","f65091a5":"# Resnet","192a9ec6":"# First Try: Simple CNN Model","8e1c7c9e":"# VGG","df593a17":"Viualize some of the Data","fdc89143":"Import Libraries"}}