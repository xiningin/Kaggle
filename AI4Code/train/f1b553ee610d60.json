{"cell_type":{"e832052a":"code","1b514406":"code","c5db42ae":"code","7d0bd018":"code","c70b468a":"code","9efacf64":"code","6ee37a11":"code","1c985866":"code","db5721a6":"code","1b7d724d":"code","df5c1d1c":"code","ba2d3395":"code","fa44a3b8":"code","1aa4467c":"code","299e9a9f":"code","1904b747":"code","c22a36d3":"markdown","0316d265":"markdown","4c38a188":"markdown","6ccc0db3":"markdown"},"source":{"e832052a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b514406":"from bs4 import BeautifulSoup # this module helps in web scraping.\n\n!pip install geocoder\nimport geocoder\n\nimport requests  # this module helps us to download a web page\n\nprint(\"Setup completed\")","c5db42ae":"#use beautiful soup to scrape the webpage\n\nurl = 'https:\/\/en.wikipedia.org\/wiki\/Category:Localities_in_Mangalore'\n\ndata = requests.get(url).text\n\nsoup = BeautifulSoup(data, 'html5lib')","7d0bd018":"#create an empty list to store the data\nneighborhoodlist = []","c70b468a":"#append the data into list\n\nfor row in soup.find_all('div', class_='mw-category')[0].find_all('li'):\n    neighborhoodlist.append(row.text)","9efacf64":"neighborhoodlist","6ee37a11":"#create a dataframe from the list\nmlr_data = pd.DataFrame({'Neighborhood' : neighborhoodlist})\nmlr_data","1c985866":"mlr_data.isnull().sum()","db5721a6":"#function to get the coordinates for all neighborhood in Mangalore\n\ndef get_cord(neighborhood):\n    lat_lon_cord = None\n    #looping until we get coordinates\n    while(lat_lon_cord is None):\n        g = geocoder.arcgis('{}, Mangalore, India'.format(neighborhood))\n        lat_lon_cord = g.latlng\n    return lat_lon_cord","1b7d724d":"coords = [ get_cord(neighborhood) for neighborhood in mlr_data[\"Neighborhood\"].tolist() ]","df5c1d1c":"coords","ba2d3395":"#now create a temporary dataframe to store the coords values\n\ncoord_df = pd.DataFrame(coords , columns=['Latitude', 'Longitude'])","fa44a3b8":"coord_df","1aa4467c":"#now combine 2 df to form as one\n\nmlr_data['Latitude']=coord_df['Latitude']\nmlr_data['Longitude']=coord_df['Longitude']","299e9a9f":"mlr_data","1904b747":"#now save this dataframe as a csv\n\nmlr_data.to_csv('mangalore_neighborhood_coords.csv', index=False)","c22a36d3":"#### Here, to extract the data from the webpage, Beautiful Soup is used as Web Scraping tool and to get corresponding coordinates geocoder module is used. ","0316d265":"## This notebook is used to extract data from a wiki page of Mangalore city,India neighborhood and its coordinates.\n","4c38a188":"### Libraries","6ccc0db3":"### Now we gather the coordinates of each neighborhood using geocoder"}}