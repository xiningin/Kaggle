{"cell_type":{"85c4c82c":"code","f317a645":"code","854be25b":"code","9cf0f570":"code","89f86e53":"code","dd721d79":"code","b3201f95":"code","e6f66921":"code","96a288e1":"code","db6a300a":"code","632b610e":"code","3bbea8b0":"code","b578e891":"code","a35aaa1f":"code","3353631b":"code","33d06302":"code","2307c181":"code","9a3e7f8a":"code","c1bad3d7":"code","6a581e86":"code","f3adce95":"code","85189c91":"code","424e50b0":"code","71d9de74":"code","d7e7a039":"code","013e4ccf":"code","8c5bc054":"code","a82890a9":"code","ed55385b":"code","76724c42":"code","f50aac7c":"code","a5138624":"code","a4cbf2a2":"code","2996adae":"code","f3a42dc4":"code","8c97c1ca":"code","f63744b0":"code","a22c32e1":"code","7b56ce78":"code","da3956ef":"code","cf523cb9":"code","d284da3e":"markdown","a9969ffe":"markdown","8d7f1b4b":"markdown","4af40d99":"markdown","5a4f1a52":"markdown","7053609d":"markdown","e50c0edf":"markdown","7dff9c1f":"markdown","f525b23c":"markdown","c73afb34":"markdown","f96f0ee0":"markdown","750262a7":"markdown","dc64b3eb":"markdown","b32a3df5":"markdown","baef1acb":"markdown","69c4871c":"markdown","c514e7fc":"markdown","11338e51":"markdown","5b667a8e":"markdown"},"source":{"85c4c82c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f317a645":"Datos=pd.DataFrame(pd.read_csv(os.path.join(dirname, filename)))","854be25b":"Datos","9cf0f570":"Datos.isna().sum() #Verificar valores incompletos","89f86e53":"Datos.dtypes # ver los tipos de datos en el dataframe","dd721d79":"Datos['Attrition'].replace({'Yes':'1', 'No':'0'}, inplace=True)\nDatos['Attrition'] = pd.to_numeric(Datos['Attrition']) ","b3201f95":"Datos","e6f66921":"sns.countplot(x='BusinessTravel',data=Datos)\nplt.title('Empleados por frecuencia de viajes', weight='bold', size=25, y=1)\n#plt.gcf().set_size_inches(10, 5)\nplt.xticks(rotation=30)","96a288e1":"sns.histplot(x='Age', kde=True, data=Datos, bins=int(np.sqrt(Datos['Age'].count())))\nplt.title('Distribuci\u00f3n edad empleados', weight='bold', size=25, y=1)\nplt.gcf().set_size_inches(10, 5)\nplt.xticks(rotation=30)","db6a300a":"data_pie= Datos.groupby(\"Department\")['Department'].count()\ndata_pie\ndata_pie.plot.pie(autopct=\"%.1f%%\");\nplt.title('% Empleados por Departamnto', weight='bold', size=25, y=1)","632b610e":"sns.countplot(x='EducationField',data=Datos)\nplt.title('Empleados por \u00e1rea de formacion', weight='bold', size=25, y=1)\nplt.gcf().set_size_inches(10, 5)\nplt.xticks(rotation=30)","3bbea8b0":"sns.histplot(x='TotalWorkingYears', kde=True, data=Datos, bins=int(np.sqrt(Datos['TotalWorkingYears'].count())))\nplt.title('Distribuci\u00f3n a\u00f1os de experiencia empleados', weight='bold', size=25, y=1)\nplt.gcf().set_size_inches(10, 5)\nplt.xticks(rotation=30)","b578e891":"Numeric_data=pd.DataFrame(Datos.select_dtypes(include=['int64']))\nNumeric_data #visualizacion de variables num\u00e9ricas","a35aaa1f":"Numeric_data.corr().dtypes\n","3353631b":"sns.heatmap(Numeric_data.corr(), annot=True, annot_kws={\"size\":8})\nplt.title('Correlaci\u00f3 entre variables num\u00e9ricas', weight='bold', size=25, y=1)\nplt.gcf().set_size_inches(15, 8)\nplt.xticks(rotation=90)","33d06302":"corelation=Numeric_data.corr()\ncorr_pairs = corelation.unstack()\nprint(corr_pairs)","2307c181":"sorted_pairs = corr_pairs.sort_values(kind=\"quicksort\")\nprint(sorted_pairs)","9a3e7f8a":"strong_pairs = sorted_pairs[abs(sorted_pairs) > 0.6]\nprint(strong_pairs[[0,2,4,6,8,10,12,14,16,18]])","c1bad3d7":"Datos_para_analisis=Numeric_data[['YearsAtCompany', 'TotalWorkingYears', \n                                  'YearsInCurrentRole', 'YearsAtCompany', 'YearsWithCurrManager', \n                                 'MonthlyIncome', 'PercentSalaryHike', 'JobLevel', 'PerformanceRating',\n                                 'YearsSinceLastPromotion', 'Age']]","6a581e86":"Datos_para_analisis","f3adce95":"Datos_para_analisis= Datos_para_analisis.assign(Attrition=Numeric_data['Attrition'].values)","85189c91":"Datos_para_analisis","424e50b0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix","71d9de74":"X = np.array(Datos_para_analisis.drop(['Attrition'],1))\ny = np.array(Datos_para_analisis['Attrition'])","d7e7a039":"print(X.shape)\nprint(y.shape)\ny","013e4ccf":"classifier = LogisticRegression()\nclassifier.fit(X, y)\npredictions = classifier.predict(X)\n\nprint('N\u00famero de instancias a predecir: {}'.format(y.shape[0]))\nprint('Valores de verdad: {}'.format(y))\nprint('Valores predichos: {}'.format(predictions))\n","8c5bc054":"print(\"Score para la regresi\u00f3n log\u00edstica:\",classifier.score(X, y))","a82890a9":"prediction = classifier.predict(X)\ncnf_matrix = confusion_matrix(y, prediction)\nprint(\"Matriz de confusi\u00f3n\")\nprint(cnf_matrix)\n","ed55385b":"from sklearn.naive_bayes import GaussianNB\nclassifier2 = GaussianNB()\nclassifier2.fit(X, y);\n\nprediction2 = classifier2.predict(X)\ncnf_matrix2 = confusion_matrix(y, prediction2)\n\nprint(\"Score para Naive Bayes:\",classifier2.score(X, y))\nprint(\"Matriz de confusi\u00f3n\")\nprint(cnf_matrix2)","76724c42":"from sklearn.datasets import make_blobs, make_moons\nfrom sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, DBSCAN\nfrom IPython.display import HTML\nfrom sklearn.metrics import silhouette_score","f50aac7c":"n_clusters = 3","a5138624":"km = KMeans( n_clusters = n_clusters)\nkm.fit(X)\ny = km.predict(X)","a4cbf2a2":"def experiment_number_of_clusters(X, clustering, show_metric=True,\n                                  plot_data=True, plot_centers=True, plot_boundaries=False):\n    plt.figure(figsize=(15,6))\n    for n_clusters in range(2,10):\n        clustering.n_clusters = n_clusters\n        y = clustering.fit_predict(X)\n\n        cm = plt.cm.plasma\n        plt.subplot(2,4,n_clusters-1)\n\n        plot_cluster_predictions(clustering, X, n_clusters, cm, \n                                 plot_data, plot_centers, show_metric)\n        \n\ndef plot_cluster_predictions(clustering, X, n_clusters = None, cmap = plt.cm.plasma,\n                             plot_data=True, plot_centers=True, show_metric=False,\n                             title_str=\"\"):\n\n    assert not hasattr(clustering, \"n_clusters\") or \\\n           (hasattr(clustering, \"n_clusters\") and n_clusters is not None), \"must specify `n_clusters` for \"+str(clustering)\n\n    if n_clusters is not None:\n        clustering.n_clusters = n_clusters\n\n    y = clustering.fit_predict(X)\n    # remove elements tagged as noise (cluster nb<0)\n    X = X[y>=0]\n    y = y[y>=0]\n\n    if n_clusters is None:\n        n_clusters = len(np.unique(y))\n\n    if plot_data:        \n        plt.scatter(X[:,0], X[:,1], color=cmap((y*255.\/(n_clusters-1)).astype(int)), alpha=.5)\n    if plot_centers and hasattr(clustering, \"cluster_centers_\"):\n        plt.scatter(clustering.cluster_centers_[:,0], clustering.cluster_centers_[:,1], s=150,  lw=3,\n                    facecolor=cmap((np.arange(n_clusters)*255.\/(n_clusters-1)).astype(int)),\n                    edgecolor=\"black\")   \n\n    if show_metric:\n        if hasattr(clustering, 'inertia_'):\n          inertia = clustering.inertia_\n        else:\n          inertia = 0\n        sc = silhouette_score(X, y) if len(np.unique(y))>1 else 0\n        plt.title(\"n_clusters %d, inertia=%.0f sc=%.3f\"%(n_clusters, inertia, sc)+title_str)\n    else:\n        plt.title(\"n_clusters %d\"%n_clusters+title_str)\n\n    plt.axis(\"off\")\n    return","2996adae":"experiment_number_of_clusters(X, KMeans(), show_metric=False)","f3a42dc4":"Sum_of_squared_distances = []\nK = range(2,15)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(X)\n    Sum_of_squared_distances.append(km.inertia_)\n    \nplt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Inertia')\nplt.show()","8c97c1ca":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix\n","f63744b0":"X = np.array(Datos_para_analisis.drop(['Attrition'],1))\ny = np.array(Datos_para_analisis['Attrition'])","a22c32e1":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\nprint(X_train.shape)\nprint(y_train.shape)\ny","7b56ce78":"model_rf = RandomForestClassifier()\nmodel_rf.fit(X_train, y_train)\nrfc_pred = model_rf.predict(X_test)\nrfc_pred\nmodel_rf.score(X_test, y_test)","da3956ef":"y_pred_rf = model_rf.predict(X_test)\nfalse_positive_rate_rf, true_positive_rate_rf, thresholds = roc_curve(y_test, y_pred_rf)\nroc_auc_rf = auc(false_positive_rate_rf, true_positive_rate_rf)\nroc_auc_rf","cf523cb9":"cm_rf = confusion_matrix(y_test,y_pred_rf)\nprint('Confusion Matrix : \\n', cm_rf)\n\ntotal1=sum(sum(cm_rf))\n#####from confusion matrix calculate accuracy\naccuracy1=(cm_rf[0,0]+cm_rf[1,1])\/total1\nprint ('Accuracy RF : ', accuracy1)\n\nsensitivity1 = cm_rf[0,0]\/(cm_rf[0,0]+cm_rf[0,1])\nprint('Sensitivity RF: ', sensitivity1 )\n\nspecificity1 = cm_rf[1,1]\/(cm_rf[1,0]+cm_rf[1,1])\nprint('Specificity RF: ', specificity1)","d284da3e":"### Random Forest","a9969ffe":"### Crear una matriz con las columnas que poseen las correlaciones mas fuertes","8d7f1b4b":"### \u00bfQue edad tienen los empleados?","4af40d99":"### A\u00f1adir la variable a predecir a nuestra matriz (En este caso \"Attrition\")","5a4f1a52":"### \u00bfQue tanto viajan los empleados?","7053609d":"### Por \u00e1reas \u00bfComo estan distribuidos los empleados? ","e50c0edf":"### Custering por K- Means","7dff9c1f":"### Crear un listado de todas las correlaciones","f525b23c":"## ALGUNAS GRAFICAS PARA ENTENDER EL NEGOCIO","c73afb34":"### \u00bfQue formaci\u00f3n tienen los empleados?","f96f0ee0":"### Naive Bayes","750262a7":"# Probaremos diferentes modelos de predicci\u00f3n","dc64b3eb":"# # Los mejores resultado se obtienen con los modelos de regresi\u00f3n log\u00edstica y randdom forest con scores de 0.83 y 0.82 respectivamente","b32a3df5":"### \u00bfCuantos a\u00f1os llevan trabajando los empleados?","baef1acb":"### Convertir nuestra variable a predercir a una de tipo num\u00e9rico","69c4871c":"### Regresi\u00f3n log\u00edstica","c514e7fc":"## Separamos varialbes numericas para hacer analisis de correlaciones","11338e51":"### Seleccionar las correlaciones m\u00e1s fuertes (Mayores a 60%)","5b667a8e":"### Ordenar los valores de correlaciones"}}