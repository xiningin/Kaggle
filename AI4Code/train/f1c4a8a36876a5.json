{"cell_type":{"7172d4d6":"code","806e74e6":"code","15eb69b5":"code","11881d84":"code","5815c7ff":"code","c316db6a":"code","7cbe3c36":"code","7115cb48":"code","acac35b1":"code","86b3b621":"code","6af5cb5e":"code","a80fc373":"code","5b5bda4d":"code","265bf44e":"code","7e153254":"code","691fa2b3":"code","e2ef15a2":"code","057c1e96":"code","6d8ae169":"code","fc7a3e92":"code","1c33317c":"code","9250f2d7":"code","e8b04f6d":"code","ce27ab7e":"code","d979cbd1":"code","13957f31":"code","c4e4e2c1":"code","c7ddc420":"markdown","c217062a":"markdown","2b754f11":"markdown","194fc15e":"markdown","0a3beec7":"markdown","33c2d857":"markdown","6150eb84":"markdown","d3930768":"markdown"},"source":{"7172d4d6":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","806e74e6":"from fastai.vision import *\nfrom fastai.metrics import error_rate","15eb69b5":"import fastai\nprint('fastai version :', fastai.__version__)","11881d84":"# Batch Size (adequate size for GPU of 11GB or more)\nbs = 64","5815c7ff":"path = Path('..\/input\/planesnet\/planesnet\/planesnet')\n# path.ls()","c316db6a":"fnames = get_image_files(path)\nfnames[:5]","7cbe3c36":"# regex to extract category\npat = r'^\\D*(\\d+)'","7115cb48":"np.random.seed(23)","acac35b1":"# Setup the transformations to apply to the training data\ntfms = get_transforms(flip_vert=True)\n\n# Add the images to the Image Data Bunch\ndata = ImageDataBunch.from_name_re(path, fnames, pat, ds_tfms=tfms, size=21, bs=bs).normalize(imagenet_stats)","86b3b621":"data.show_batch(rows=3, figsize=(7,6))","6af5cb5e":"print(data.classes)\nlen(data.classes),data.c","a80fc373":"learn = cnn_learner(data, models.resnet50, metrics=error_rate, model_dir=\"\/output\/kaggle\/working\/model\")","5b5bda4d":"learn.model","265bf44e":"learn.fit_one_cycle(4)","7e153254":"learn.save('stage-1', return_path=True)","691fa2b3":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses, idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","e2ef15a2":"interp.plot_top_losses(9, figsize=(15,11))","057c1e96":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","6d8ae169":"interp.most_confused(min_val=2)","fc7a3e92":"learn.unfreeze()","1c33317c":"lr_find(learn)\nlearn.recorder.plot()","9250f2d7":"learn.fit_one_cycle(6, slice(1e-5,1e-3))","e8b04f6d":"learn.save('stage-2', return_path=True)","ce27ab7e":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses, idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","d979cbd1":"interp.plot_top_losses(9, figsize=(15,11))","13957f31":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","c4e4e2c1":"interp.most_confused(min_val=2)","c7ddc420":"## Setup","c217062a":"## Model Update - Retraining of all the layer of the ResNet50","2b754f11":"Import necessary packages","194fc15e":"## Data Bunch creation","0a3beec7":"For reproducibility","33c2d857":"Ensure that:\n* any edits to libraries are reloaded automatically\n* any charts or images displayed are shown in this notebook","6150eb84":"# Introduction\nThis notebook applies fast.ai course v3 [lesson1](https:\/\/course.fast.ai\/videos\/?lesson=1) to the [Planes in Satellite Imagery dataset](https:\/\/www.kaggle.com\/rhammell\/planesnet).\nWe will use a ResNet50 architecture with some transfer learning first, and then update the weight of the whole architecture.\nThe model will have 2 outputs, planes (1) or no-planes (0).\n\nThis achieved an accuracy of 98.71.\n\nAlso, if you look at the final plot of the top losses, you will find out that even for a human it is very difficult (impossible) to say if there is a plane or not.\nKnowing that the data has been manually labelled let me think that those might even have been mislabeled...","d3930768":"## Model Creation - Transfer Learning with ResNet50"}}