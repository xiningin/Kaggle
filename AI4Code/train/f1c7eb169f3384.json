{"cell_type":{"547c86bc":"code","51205399":"code","1657b160":"code","389ce412":"code","d8e5d645":"code","67faa0a0":"code","568a094b":"code","15c58c70":"code","0283ec6a":"code","3f9719c5":"code","53f5e15c":"code","acb0dbb1":"code","4df37332":"code","03001d41":"code","31f54206":"code","73e6f87c":"code","082d877b":"code","45b46ce8":"code","61dc77b0":"code","2292fff9":"code","bdd0fbe4":"code","dacd04cb":"code","5f3b646d":"code","eff1d96d":"code","0ce0c3b6":"code","9f165281":"code","b90933a8":"code","344c41e9":"code","a74651f4":"code","5f154e7d":"code","192e6ce3":"code","676b9a2d":"markdown","f4daea3a":"markdown","0cb6aa85":"markdown","2d4c6524":"markdown","3a3e468f":"markdown","112fb64e":"markdown","7eed6c96":"markdown","e01d0054":"markdown","3fcfe4e9":"markdown","f2bb8a0a":"markdown","3311862b":"markdown","b175178b":"markdown","b08d1ab0":"markdown","121b1937":"markdown","34f8ca7a":"markdown","7d469fa0":"markdown","ee3d9c75":"markdown","b1409001":"markdown","9e04b989":"markdown","b1947119":"markdown","25d83e2b":"markdown","95514afa":"markdown"},"source":{"547c86bc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nimport os\nprint(os.listdir(\"..\/input\/dogs-vs-cats\"))","51205399":"# Unzipping the files\n\nimport zipfile\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\",\"r\") as z:\n    z.extractall(\".\")  ","1657b160":"# Retrieving a list of directories in each folder\n\nDIR_TRAIN = \"\/kaggle\/working\/train\/\"\nDIR_TEST = \"\/kaggle\/working\/test1\"\n\ntrain_imgs = os.listdir(DIR_TRAIN)\ntest_imgs = os.listdir(DIR_TEST)","389ce412":"train_imgs[:5]","d8e5d645":"sample = random.choice(train_imgs)\nimage = load_img(\"\/kaggle\/working\/train\/\"+sample)\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()","67faa0a0":"# Creating a DataFrame for our train set\n\ncategory = [x.split(\".\")[0] for x in train_imgs]\ndf = pd.DataFrame({\"Filename\":train_imgs, \"Category\":category})\ndf.head()","568a094b":"# Visualizing the constituents of our train set\n\nplt.figure(figsize=(6,6))\nplt.pie(df['Category'].value_counts(), explode=[0.01,0.02], \n       autopct=\"%.2f%%\", textprops={'color':'white', 'size':12,\n                                   'weight':'bold'},\n       startangle=45, colors = ['#947867', '#D49034'])\nplt.legend([\"Dogs\",\"Cats\"])\nplt.show()","15c58c70":"# Splitting the train set, into a train & validation set with equal categories\n\ndf_train, df_valid = train_test_split(df, test_size = 5000, \n                                     stratify=df['Category'],\n                                     random_state=42)","0283ec6a":"# Checking if categories are equal\n\ndf_train['Category'].value_counts()","3f9719c5":"df_train.reset_index(drop=True, inplace=True)\ndf_valid.reset_index(drop=True, inplace=True)","53f5e15c":"# Creating an Augmentation generator for the train set\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range = 15,\n    rescale = 1.0\/255.0,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(df_train, \n                                  directory = \"\/kaggle\/working\/train\/\",\n                                  x_col = 'Filename',\n                                  y_col = 'Category',\n                                  target_size = (224, 224),\n                                  class_mode = 'categorical',\n                                  batch_size = 32\n                                 )","acb0dbb1":"# Creating the Augmentation generator for the valid set\n\nvalid_datagen = ImageDataGenerator(rescale = 1.0\/255.0)\n\nvalid_generator = valid_datagen.flow_from_dataframe(df_valid, \n                                  directory = \"\/kaggle\/working\/train\/\",\n                                  x_col = 'Filename',\n                                  y_col = 'Category',\n                                  target_size = (224, 224),\n                                  class_mode = 'categorical',\n                                  batch_size = 32\n                                 )","4df37332":"df_example = df_train.sample(1)\n\nexample_generator = train_datagen.flow_from_dataframe(df_example,\n                                  directory = \"\/kaggle\/working\/train\/\",\n                                  x_col = 'Filename',\n                                  y_col = 'Category',\n                                  target_size = (224, 224),\n                                  class_mode = 'categorical')","03001d41":"plt.figure(figsize=(12,12))\n\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        plt.axis(\"off\")\n        break\nplt.tight_layout()\nplt.show()","31f54206":"from functools import partial\n\nkeras.backend.clear_session()\n\n\nDefaultConv = partial(keras.layers.Conv2D, kernel_size = 3, strides = 1,\n                     padding = 'same', activation = 'relu')\n\nmodel = keras.models.Sequential([\n    DefaultConv(filters = 32, kernel_size = 7, strides=2, input_shape=[224,224,3]),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=2),\n\n    DefaultConv(filters = 64),\n    DefaultConv(filters = 64),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.25),\n    keras.layers.MaxPool2D(pool_size=2),\n    \n    DefaultConv(filters = 128),\n    DefaultConv(filters = 128),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.25),\n    keras.layers.MaxPool2D(pool_size=2),\n    \n    DefaultConv(filters = 256),\n    DefaultConv(filters = 256),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.25),\n    keras.layers.MaxPool2D(pool_size=2),\n    \n    DefaultConv(filters = 512),\n    DefaultConv(filters = 512),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.4),\n    keras.layers.MaxPool2D(pool_size=2),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(300, activation = 'relu', use_bias = False),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(2, activation = 'sigmoid')\n])\n\nmodel.compile(loss = \"binary_crossentropy\", optimizer = 'nadam',\n             metrics = ['accuracy'])","73e6f87c":"model.summary()","082d877b":"Checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model.h5\", save_best_only=True)\nEarlystopping_cb = keras.callbacks.EarlyStopping(patience=10)\n\ncallback = [Checkpoint_cb, Earlystopping_cb]","45b46ce8":"history = model.fit(\n    train_generator,\n    epochs = 50,\n    validation_data = valid_generator,\n    validation_steps = len(df_valid)\/32,\n    steps_per_epoch = len(df_train)\/32,\n    callbacks=callback\n)","61dc77b0":"# Train and Validation Loss\n\nplt.figure(figsize=(12,6))\nplt.plot(history.history['loss'][1:], \"ro-\", label = \"Train Loss\")\nplt.plot(history.history['val_loss'][1:], \"b--\", lw=3, label = \"Validation Loss\")\nplt.legend(loc=\"upper right\", fontsize=12)\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Train & Validation Loss (50 epochs)\", fontsize=16)\nplt.show()","2292fff9":"# Train and Validation Accuracy\n\nplt.figure(figsize=(12,6))\nplt.plot(history.history['accuracy'], \"ro-\", label = \"Train Accuracy\")\nplt.plot(history.history['val_accuracy'], \"b--\", lw=3, label = \"Validation Accuracy\")\nplt.legend(loc=\"lower right\", fontsize=12)\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Train & Validation Accuracy (50 epochs)\", fontsize=16)\nplt.show()","bdd0fbe4":"df_test = pd.DataFrame({'Filename':test_imgs})\ndf_test.head()","dacd04cb":"test_datagen = ImageDataGenerator(rescale=1.0\/255.0)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    df_test,\n    directory = \"\/kaggle\/working\/test1\/\",\n    x_col = 'Filename',\n    y_col = None,\n    class_mode = None,\n    target_size = (224, 224),\n    batch_size = 32,\n    shuffle = False\n)","5f3b646d":"# loading the best model\n\nmodel = keras.models.load_model(\"model.h5\")","eff1d96d":"model.summary()","0ce0c3b6":"pred = model.predict(test_generator, \n                     steps = np.ceil(df_test.shape[0]\/32))","9f165281":"np.set_printoptions(suppress=True)\n\npred[:5]","b90933a8":"category = []\nfor x in pred[:,0]:\n    category.append(\"cat\" if x > 0.5 else \"dog\")\n    \ndf_test['Category'] = category\n\ndf_test.head()","344c41e9":"plt.figure(figsize=(6,6))\nplt.pie(df_test['Category'].value_counts(), explode=[0.01,0.02], \n       autopct=\"%.2f%%\", textprops={'color':'white', 'size':12,\n                                   'weight':'bold'},\n       startangle=45, colors = ['#947867', '#D49034'])\nplt.legend([\"Dogs\",\"Cats\"])\nplt.show()","a74651f4":"df_example = df_test.sample(50).reset_index(drop=True)\n\nplt.figure(figsize=(18,12))\n\nfor i in range(50):\n    plt.subplot(5,10,i+1)\n    filename = df_example['Filename'][i]\n    category = df_example['Category'][i]\n    image = load_img('\/kaggle\/working\/test1\/'+filename)\n    plt.imshow(image)\n    plt.title(f\"Prediction: {category}\")\n    plt.axis(\"off\")\nplt.tight_layout()\nplt.show()","5f154e7d":"df_submission = df_test.copy()\ndf_submission['Category'] = pred[:,1]\ndf_submission['id'] = df_submission['Filename'].str.split('.').str[0]\ndf_submission['label'] = df_submission['Category']\ndf_submission.drop(['Filename', 'Category'], axis = 1, inplace = True)\ndf_submission.to_csv('submission.csv', index=False)","192e6ce3":"df_submission","676b9a2d":"## PROCESSING THE TEST DATA","f4daea3a":"## Visualizing the Training","0cb6aa85":"### callbacks","2d4c6524":"## Importing Libraries","3a3e468f":"### Creating the sequential vanilla model","112fb64e":"Works as we had hoped !!","7eed6c96":"We will add a category to our dataframe based on our predictions. If the first probabilty on each row is greater than 0.5, we assign it as `cat`, else `dog`.","e01d0054":"## Loading a sample image","3fcfe4e9":"For the submission, we are to provide the probabilty that an image is a dog. Therefore, i will be extracting the second column of our `pred` variable for this purpose.","f2bb8a0a":"## Visualizing our predictions","3311862b":"We can see from our chart that during training, we experienced some cases of overfitting. In general, the model performed well due to the addition of regularization and sensitivity techniques like `DataAugmentaion`, `BatchNormalization` and `DropOut`.","b175178b":"### Fitting the model","b08d1ab0":"The model returns the probability an instace belongs to each category.","121b1937":"The aim of this notebook is to create a decent vanilla Convolutional Neural Network that is capable of distinguishing between a Dog and Cat.\n\nPlease note that it is advisable to use pre-trained models for image classification tasks, but i'll be creating my own model to solidify my understanding of DNNs and CNNs.\n","34f8ca7a":"### Splitting the data into train & validation","7d469fa0":"### Data Augmentation","ee3d9c75":"## Creating the Generator","b1409001":"## 2.0 PROCESSING THE DATA","9e04b989":"# $The$ $End!$","b1947119":"### Let's see how well our Generator works","25d83e2b":"# 3.0 CREATING THE MODEL","95514afa":"## Prediction"}}