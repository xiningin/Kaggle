{"cell_type":{"2d375a78":"code","0e648eae":"code","c3ed6ae8":"code","af9c7931":"code","cafc024a":"code","3ef8e4b6":"code","e32ffddc":"code","301743c5":"code","dd8c481f":"code","00ca2582":"code","f4964c3f":"code","286012de":"code","fc46a7b6":"code","edcc63ef":"code","fe9d0b45":"code","a8d7c7b3":"code","d5be9eb5":"code","8dcb2336":"code","b6c657ba":"code","70ed732f":"code","8964790b":"code","a4df346b":"code","9d6cce4b":"code","35e0831c":"code","af986c11":"code","1ce6d411":"code","f394a804":"code","de9f4c2f":"code","d770cdea":"code","4155c688":"code","80dfc234":"code","d8839e79":"code","ee943f81":"code","c2880879":"code","0524a105":"code","0efd6178":"code","273e5970":"markdown","11a8ac68":"markdown","84f9fc8c":"markdown","d3b723ec":"markdown","f1f66af9":"markdown","c0b209b5":"markdown","68a00c99":"markdown","ef6f5272":"markdown","afcf1b9a":"markdown","f9ca4b14":"markdown","f5520d4f":"markdown","78685811":"markdown","7ee44d97":"markdown"},"source":{"2d375a78":"import pandas as pd\nimport numpy as np\n\n#for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n#for data splitting\nfrom sklearn.model_selection import train_test_split\n\n#for the model prediction\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression","0e648eae":"# We are reading our data\ndf = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\n\n# First 5 rows of our data\ndf.head()","c3ed6ae8":"#Change the column names for better understanding\ndf.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']\n","af9c7931":"#Finding the shape of the dataframe\ndf.shape","cafc024a":"# Describing the Dataframe\ndf.describe()","3ef8e4b6":"#Finding information of dataframe\ndf.info()","e32ffddc":"#Finding the missing values. In this dataframe there is no missing value.\ndf.isnull().sum()","301743c5":"#Finding the percentage of patients with heart disease and the one without heart disease\n\ncountNoDisease = len(df[df.target == 0])\ncountHaveDisease = len(df[df.target == 1])\nprint(\"Percentage of Patients Haven't Heart Disease: {:.2f}%\".format((countNoDisease \/ (len(df.target))*100)))\nprint(\"Percentage of Patients Have Heart Disease: {:.2f}%\".format((countHaveDisease \/ (len(df.target))*100)))\n","dd8c481f":"#Finding heart disease frequency with the age parameter\n\npd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize=(20,6))\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.savefig('heartDiseaseAndAges.png')\nplt.show()","00ca2582":"#Finding all the unique value of 'cheat_pain_type' parameter\ndf.chest_pain_type.unique()","f4964c3f":"#Finding the count of all the type of 'chest_pain_type' \nc = df[\"chest_pain_type\"].value_counts()\nlabels = c.index\nfig = px.bar(c, title = \"Chest pain type\", text = c)\nfig.show()","286012de":"#Relation of heart disease with chest_pain_type. Here the chest_pain_type 2 has highest chance to have heart disease\npd.crosstab(df.chest_pain_type,df.target).plot(kind=\"bar\",figsize=(15,6))\nplt.title('Heart Disease Frequency for chest_pain_type')\nplt.xlabel('Chest_pain_type (0, 1, 2, 3)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","fc46a7b6":"#Relation of heart disease with sex\npd.crosstab(df.sex,df.target).plot(kind=\"bar\",figsize=(15,6))\nplt.title('Heart Disease Frequency for Sex')\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","edcc63ef":"#Using scatter plot to find relation of max_heart_rate achieved with age. Here yellow color is used for target = 1 and purple for target = 0\nfig = px.scatter(df, x=\"age\", y=\"max_heart_rate_achieved\", color = \"target\") \nfig.update_traces(marker=dict(size=12,\n                              line=dict(width=2,\n                                        color='MediumPurple')),\n                  selector=dict(mode='markers'))\nfig.show()","fe9d0b45":"#Finding frequency of heart disease with Fasting blood sugar. \npd.crosstab(df.fasting_blood_sugar \t,df.target).plot(kind=\"bar\",figsize=(15,8))\nplt.title('Heart Disease Frequency According To Fasting Blood Sugar')\nplt.xlabel('FBS - (Fasting Blood Sugar < 120 mg\/dl) (1 = true; 0 = false)')\nplt.xticks(rotation = 0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency of Disease or Not')\nplt.show()","a8d7c7b3":"#Finding number of fasting blood sugar in patients\nfb = df[\"fasting_blood_sugar\"].value_counts()\nlabels = fb.index\nfig = px.bar(fb, title = \"fasting blood sugar\", text = fb)\nfig.show()\n\n","d5be9eb5":"#Using scatter plot to find relation between Cholesterol and Age with yellow being target = 0 and blue being target = 1\nfig = px.scatter(df, x=\"age\", y=\"cholesterol\", color = \"target\") \nfig.update_traces(marker=dict(size=12,\n                              line=dict(width=2,\n                                        color= 'DarkSlateGrey')),\n                  selector=dict(mode='markers'))\nfig.show()","8dcb2336":"#Relation between cholestrol and maximum heart rate achieved with chances of target either 0 or 1\nplt.figure(figsize=(8,6))\nsns.scatterplot(x='cholesterol',y='max_heart_rate_achieved',data=df,hue='target')\nplt.show()\n","b6c657ba":"#Faceting is used for splitting the plot into multiple subplots based on the values of a particular row\/column. Here we are using facet_col and thus, we end up with 2 subplots each representing 'sex'\nfig = px.scatter(df, x = 'resting_blood_pressure', y = 'cholesterol', title='Cholestrol vs Blood Pressure', \n                 facet_col = 'sex', # the name of the column in the dataframe whose values are used for creating subplots\n                 color = 'target')\nfig.show()\n","70ed732f":"#Relation of major_vessels with target = 1\nfig = px.bar(df, x = \"num_major_vessels\", y = \"target\")\nfig.show()","8964790b":"#'chest_pain_type', 'thalassemia' and 'st_slope' are categorical variables we'll turn them into dummy variables.\na = pd.get_dummies(df['chest_pain_type'], prefix = \"chest_pain_type\")\nb = pd.get_dummies(df['thalassemia'], prefix = \"thalassemia\")\nc = pd.get_dummies(df['st_slope'], prefix = \"st_slope\")\nframes = [df, a, b, c]\ndf = pd.concat(frames, axis = 1)\ndf.head()","a4df346b":"#Dropping the categorical variable\ndf = df.drop(columns = ['chest_pain_type', 'thalassemia', 'st_slope'])\ndf.head()","9d6cce4b":"#Alloting target as 'y'\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\ny = df.target.values\nx_data = df.drop(['target'], axis = 1)\n\n#Normalize the data\n# scaler_norm = MinMaxScaler().fit(x_data)\n# x_normalized = scaler_norm.transform(x_data)\n# x_normalized = (x_data - np.min(x_data)) \/ (np.max(x_data) - np.min(x_data)).values\n\n\nscaler = MinMaxScaler()\nnames = x_data.columns\nd = scaler.fit_transform(x_data)\nx_normalized = pd.DataFrame(d, columns=names)\n\n#numerical features \nnum_cols = ['resting_blood_pressure','cholesterol','max_heart_rate_achieved','age']\n\n# standardrization only be done in the numerical features \n\n# Standardrization of data \n\n\n\nx_std = x_data.copy()\n\nfor i in num_cols:\n    \n    #fit on training data column\n    scaler_std = StandardScaler().fit(x_std[[i]])\n    #transform\n    x_std[i] = scaler_std.transform(x_std[[i]])\n#Finding the shape of 'x'\n\n","35e0831c":"\nx_normalized","af986c11":"#We will split our data. 80% of our data will be train data and 20% of it will be test data\nx_train, x_test, y_train, y_test = train_test_split(x_data,y,test_size = 0.2,random_state=0)\nx_train_norm, x_test_norm, y_train_norm, y_test_norm = train_test_split(x_normalized,y,test_size = 0.2,random_state=42)\nx_train_std, x_test_std, y_train_std, y_test_std= train_test_split(x_std,y,test_size = 0.2,random_state=27)\n","1ce6d411":"# x_train_norm.shape\n# y_train_norm.shape\nx_test_norm.shape,\ny_test_norm.shape","f394a804":"#transpose matrices\nx_train = x_train.T\ny_train = y_train.T\nx_test = x_test.T\ny_test = y_test.T\n\n#Using decision tree algorithm for prediction\n# Since stardardization and normalization have zero impact on decision tree hence we don't use that data here\ndtc = DecisionTreeClassifier()\ndtc.fit(x_train.T, y_train.T)\n\nacc = dtc.score(x_test.T, y_test.T)*100\nprint(\"Decision Tree Test Accuracy {:.2f}%\".format(acc))\n\n","de9f4c2f":"data_train_list = [[x_train.T,y_train.T],[x_train_norm,y_train_norm],[x_train_std,y_train_std]]\ndata_test_list  =[[x_test.T,y_test.T],[x_test_norm,y_test_norm],[x_test_std,y_test_std]]\n\n\n\n\n# for (i , j) in zip(data_train_list,data_test_list):\n#     rf = RandomForestClassifier(n_estimators = 1000, random_state = 1)\n#     rf.fit(i[0], i[1])\n#     acc = rf.score(j[0],j[1])*100\n#     print(\"Random Forest Algorithm Accuracy Score : {:.2f}%\".format(acc))\n\nrf = RandomForestClassifier(n_estimators = 100, random_state = 0,)\nrf.fit(x_train.T, y_train.T)\n\nacc = rf.score(x_test.T,y_test.T)*100\n\nprint(\"Random Forest Algorithm Accuracy Score : {:.2f}%\".format(acc))","d770cdea":"for (i , j) in zip(data_train_list,data_test_list):\n    rf = LogisticRegression(max_iter=1500)\n    rf.fit(i[0], i[1])\n    acc = rf.score(j[0],j[1])*100\n    print(\"Logistic Regression Algorithm Accuracy Score : {:.2f}%\".format(acc))","4155c688":"for (i , j) in zip(data_train_list,data_test_list):\n    rf = SVC(kernel = 'rbf', C = 0.7, gamma = 0.1)\n    rf.fit(i[0], i[1])\n    acc = rf.score(j[0],j[1])*100\n    print(\"SVC Algorithm Accuracy Score : {:.2f}%\".format(acc))","80dfc234":"from sklearn.model_selection import GridSearchCV\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.1, 0.01,0.001],\n                     'C': [0.5,0.7, 1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\nclf = GridSearchCV(SVC(gamma='auto'),tuned_parameters)\nclf.fit(x_train_norm, y_train_norm)\nclf.cv_results_","d8839e79":"clf.best_params_\n","ee943f81":"# 'C': 100, 'gamma': 0.001, 'kernel': 'rbf'\n# C= 100, gamma= 0.001, kernel= 'rbf'            \nrf = SVC(kernel = 'rbf', C = 0.7, gamma = 0.1)\nrf.fit(x_train_norm, y_train_norm)\nacc = rf.score(x_test_norm, y_test_norm)*100\nprint(\"SVC Algorithm Accuracy Score : {:.2f}%\".format(acc))","c2880879":"clf.best_score_","0524a105":"rf = LogisticRegression(max_iter=1500)\nrf.fit(x_train_std, y_train_std)\ny_pred = rf.predict(x_test_std)\nprint(y_pred)\nacc = rf.score(x_test_std, y_test_std)*100\nprint(\"Logistic Regression Algorithm Accuracy Score : {:.2f}%\".format(acc))\n\n    ","0efd6178":"from sklearn.metrics import confusion_matrix,precision_recall_curve\ncm = confusion_matrix(y_test_std,y_pred)\nprint(cm)","273e5970":"**HEART DISEASE**\n\n\nHeart disease is a class of diseases that involve the heart or blood vessels. Cardiovascular diseases are the leading cause of death globally. This is true in all areas of the world except few. Deaths, at a given age, from CVD are more common and have been increasing in much of the developing world, while rates have declined in most of the developed world since the 1970s. This heart disease classifier uses historical dataset of patients to classify heart disease. Various features available in the dataset are used for prediction of heart disease.\n\n\n\nAbout the Dataset\n\nThis database contains 76 attributes, but all published experiments refer to using a subset of 13 of them.The \"target\" field refers to the presence of heart disease in the patient. It is integer valued 0 which means presence of no hear disease and 1 means presence of disease. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence i.e value 1 from absence (value 0).\n\nThe data includes 303 patient level features including if they have heart disease at the end or not. Features are like; Age: Obvious one.\n\n    Sex:\n\n    0: Female\n    1: Male\n\n    Chest Pain Type:\n\n    0: Typical Angina\n    1: Atypical Angina\n    2: Non-Anginal Pain\n    3: Asymptomatic\n\n    Resting Blood Pressure: Person's resting blood pressure.\n    Cholesterol: Serum Cholesterol in mg\/dl\n    Fasting Blood Sugar:\n\n    0:Less Than 120mg\/ml\n    1: Greater Than 120mg\/ml\n\n    Resting Electrocardiographic Measurement:\n\n    0: Normal\n    1: ST-T Wave Abnormality\n    2: Left Ventricular Hypertrophy\n\n    Max Heart Rate Achieved: Maximum Heart Rate Achieved\n    Exercise Induced Angina:\n\n    1: Yes\n    0: No\n\n    ST Depression: ST depression induced by exercise relative to rest.\n    Slope: Slope of the peak exercise ST segment:\n\n    0: Upsloping\n    1: Flat\n    2: Downsloping\n\n    Thalassemia: A blood disorder called 'Thalassemia':\n\n    0: Normal\n    1: Fixed Defect\n    2: Reversable Defect\n\n    Number of Major Vessels: Number of major vessels colored by fluoroscopy.\n","11a8ac68":"Now in the graph below matplotlib is used and when you move the cursor over the plot the properties won't be shown as in the plotly.","84f9fc8c":"Now we will use plotly to check the count of 'chest_pain_type'. There are more advantage of plotly over seaborn or matplotlib. Just move the cursor over the plot below.","d3b723ec":"As we can see the cholestrol value is mostly confined between 200-400 with maximum heart rate value is 200. And maximum patients with heart disease have heart rate between 140-180.","f1f66af9":"Logistic Regression giving the best accuracy 91.80%","c0b209b5":"Take the cursor over the plot to see the exact properties like age and cholestrol for target.  ","68a00c99":"The plot below is split for both male and female to draw the plot between cholestrol and resting blood pressure and also using target parameter.","ef6f5272":"As target = 1 means the patient has a heart disease so we will use age parameter to check the frequency of heart disease using matplotlib.","afcf1b9a":"Let's improve our test accuracy by using random forest classifier","f9ca4b14":"Here we can see normalized data has shown good accuracy in SVC.","f5520d4f":"Here the scatter plot of plotly is used to find relation between max_heart_rate and the age parameter. As we can see high heart rate is achieved by younger people with heart disease and with older people the heart rate is not that high with heart disease.","78685811":"standardize data with logistic regression is giving great accuracy on test data.","7ee44d97":"Let's see the percentage of patients who really have heart disease and the one without any heart disease. "}}