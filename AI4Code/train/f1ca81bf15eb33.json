{"cell_type":{"8bf2151a":"code","37bd3b58":"code","8ed5539f":"code","78b30278":"code","7007ee6f":"code","8abd25f5":"code","168e1e26":"code","b1a8b9ff":"code","8cc71cd0":"code","6b8b767f":"code","5ffe4419":"code","1b4b4648":"code","2b3e3fc4":"code","6bfff41e":"markdown","e7b964c0":"markdown","7eca2e22":"markdown","80671730":"markdown"},"source":{"8bf2151a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","37bd3b58":"df=pd.read_csv('..\/input\/inventario-de-ganado-bovino-boyac\/data.csv', encoding='utf8')\npd.set_option('display.max_columns', None)\ndf.head()","8ed5539f":"df.isnull().sum()","78b30278":"sns.countplot(data = df, x = 'A\u00d1O')\nplt.title('A\u00d1O')","7007ee6f":"# Lets first handle numerical features with nan value\nnumerical_nan = [feature for feature in df.columns if df[feature].isna().sum()>1 and df[feature].dtypes!='O']\nnumerical_nan","8abd25f5":"df[numerical_nan].isna().sum()","168e1e26":"## Replacing the numerical Missing Values\n\nfor feature in numerical_nan:\n    ## We will replace by using median since there are outliers\n    median_value=df[feature].median()\n    \n    df[feature].fillna(median_value,inplace=True)\n    \ndf[numerical_nan].isnull().sum()","b1a8b9ff":"df = pd.get_dummies(df)","8cc71cd0":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_curve\nfrom sklearn.linear_model import LogisticRegression","6b8b767f":"y = df[\"A\u00d1O\"]\nX = df.drop('A\u00d1O',axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)","5ffe4419":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","1b4b4648":"m1 = 'Logistic Regression'\nlr = LogisticRegression()\nmodel = lr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)\nlr_conf_matrix = confusion_matrix(y_test, lr_predict)\nlr_acc_score = accuracy_score(y_test, lr_predict)\nprint(\"confussion matrix\")\nprint(lr_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Logistic Regression:\",lr_acc_score*100)","2b3e3fc4":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, @mpwolke was Here.' )","6bfff41e":"![](https:\/\/http2.mlstatic.com\/D_NQ_NP_896457-MLB29396693664_022019-O.jpg)produto.mercadolivre.com","e7b964c0":"#S\u00f3 isso!!!  Only this of Accuracy??","7eca2e22":"#Code by Steven George https:\/\/www.kaggle.com\/smith123\/logistic-regression\/comments","80671730":"I used utf8 since 1st column is in spanish A\u00d1O."}}