{"cell_type":{"94cd9502":"code","9d9ebc00":"code","c5a44107":"code","79584539":"code","f4a465c1":"code","49fb650f":"code","5d31dec3":"code","62b07721":"code","8f55de66":"code","aaf3a3bf":"code","bb2f770b":"code","0505986a":"code","1ca4182f":"code","b91ec052":"code","ed21a81d":"code","386604a3":"markdown","fe917068":"markdown","0e349203":"markdown","5312522d":"markdown","58ec76f1":"markdown","2b872811":"markdown","e85c2dba":"markdown","48c28cec":"markdown","086bf175":"markdown","318e44c4":"markdown","5ebb37ff":"markdown","66ea46bf":"markdown","1d8fcd5f":"markdown"},"source":{"94cd9502":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\nimport re\nimport math\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom random import shuffle\nfrom sklearn import model_selection as sk_model_selection\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf","9d9ebc00":"data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\npytorch3dpath = \"..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D\"\n \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nIMAGE_SIZE = 256\nNUM_IMAGES = 64","c5a44107":"sample_submission = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')\ntest=sample_submission\ntest['BraTS21ID5'] = [format(x, '05d') for x in test.BraTS21ID]\ntest.head(3)","79584539":"def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n        \n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=IMAGE_SIZE, mri_type=\"FLAIR\", split=\"test\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    middle = len(files)\/\/2\n    num_imgs2 = num_imgs\/\/2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d \/ np.max(img3d)\n            \n    return np.expand_dims(img3d,0)\n\na = load_dicom_images_3d(\"00001\")\nprint(a.shape)\nprint(np.min(a), np.max(a), np.mean(a), np.median(a))\nimage = a[0]\nprint(\"Dimension of the CT scan is:\", image.shape)\nplt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")","f4a465c1":"def plot_slices(num_rows, num_columns, width, height, data):\n    \"\"\"Plot a montage of 20 CT slices\"\"\"\n    data = np.rot90(np.array(data))  \n    data = np.transpose(data)\n    data = np.reshape(data, (num_rows, num_columns, width, height))\n    rows_data, columns_data = data.shape[0], data.shape[1]\n    heights = [slc[0].shape[0] for slc in data]\n    widths = [slc.shape[1] for slc in data[0]]\n    fig_width = 12.0\n    fig_height = fig_width * sum(heights) \/ sum(widths)\n    f, axarr = plt.subplots(\n        rows_data,\n        columns_data,\n        figsize=(fig_width, fig_height),\n        gridspec_kw={\"height_ratios\": heights},\n    )\n    for i in range(rows_data):\n        for j in range(columns_data):\n            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n            axarr[i, j].axis(\"off\")\n    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n    plt.show()\n# Visualize montage of slices.\n# 5 rows and 10 columns for 100 slices of the CT scan.\nplot_slices(5, 10, 256, 256, image[:, :, :50])","49fb650f":"from keras.utils import Sequence\nclass Dataset(Sequence):\n    def __init__(self,df,is_train=True,batch_size=1,shuffle=True):\n        self.idx = df[\"BraTS21ID\"].values\n        self.paths = df[\"BraTS21ID5\"].values\n        self.y =  df[\"MGMT_value\"].values\n        self.is_train = is_train\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n   \n    def __getitem__(self,ids):\n        id_path= self.paths[ids]\n        batch_paths = self.paths[ids * self.batch_size:(ids + 1) * self.batch_size]\n        \n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n        list_x =  load_dicom_images_3d(id_path)#str(scan_id).zfill(5)\n        #list_x =  [load_dicom_images_3d(x) for x in batch_paths]\n        batch_X = np.stack(list_x)\n        if self.is_train:\n            return batch_X,batch_y\n        else:\n            return batch_X\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","5d31dec3":"#train_dataset = Dataset(df_train)\n#valid_dataset = Dataset(df_valid)\ntest_dataset = Dataset(test,is_train=False)","62b07721":"for i in range(1):\n    image = test_dataset[i]\n    print(\"Dimension of the CT scan is:\", image.shape)\n    plt.imshow(image[0,:,:, 32], cmap=\"gray\")\n    plt.show()","8f55de66":"ans=[]\nfor x in test_dataset:\n    if (np.mean(x) * np.std(x)) < 0.0104726682251054525:\n        ans.append(1)\n    else:\n        ans.append(0)","aaf3a3bf":"preds = ans","bb2f770b":"sum(ans)","0505986a":"submission = pd.DataFrame({'BraTS21ID':sample_submission['BraTS21ID'],'MGMT_value':preds})","1ca4182f":"submission","b91ec052":"submission.to_csv('submission.csv',index=False)","ed21a81d":"plt.figure(figsize=(5, 5))\nplt.hist(submission[\"MGMT_value\"]);","386604a3":"# Model","fe917068":"# Loading Data","0e349203":"# Make predictions","5312522d":"1. https:\/\/keras.io\/examples\/vision\/3D_image_classification\/\n1. https:\/\/www.kaggle.com\/rluethy\/efficientnet3d-with-one-mri-type\n","58ec76f1":"# Functions to load images\n","2b872811":"**Very stupid predicting model**","e85c2dba":"Mainly from this notebook : https:\/\/www.kaggle.com\/ammarnassanalhajali\/brain-tumor-3d-inference","48c28cec":"### Hi kagglers, This is `Inference` notebook using `Keras`.\n\n> \n>  [Brain Tumor 3D [Training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/brain-tumor-3d-training) \n\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","086bf175":"# This is our Model","318e44c4":"![download.jpg](attachment:bcd79dfb-f7c2-459e-bc2c-d2da9813d10d.jpg)","5ebb37ff":"## \u2600\ufe0f Importing Libraries","66ea46bf":"#  Custom Data Generator","1d8fcd5f":"# References"}}