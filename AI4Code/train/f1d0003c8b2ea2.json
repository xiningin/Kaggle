{"cell_type":{"b5081a57":"code","d66cee9a":"code","e00b6b48":"code","d7913611":"code","58a20b58":"code","5d13d1c0":"code","5b311e1f":"code","93454ae2":"code","9d79b0b7":"code","56476ef2":"code","254ab7de":"code","8785e5ee":"code","ea86ecbf":"code","639079c0":"code","289f87b3":"code","33056f83":"code","a62f9430":"code","3f808e30":"code","831cb5c9":"code","b69e7778":"code","f87e9e66":"code","2ac685c8":"code","5c118cdc":"code","e68bb883":"markdown","005ef674":"markdown","1c514f5a":"markdown","376f1eea":"markdown","2beb354b":"markdown","4019caeb":"markdown","69749f52":"markdown","c769d3e9":"markdown","0f793f14":"markdown","b917dc1b":"markdown"},"source":{"b5081a57":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport xgboost\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler,RobustScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier,AdaBoostClassifier,StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score, LeaveOneOut, cross_val_predict\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nimport time","d66cee9a":"trainp = \"\/kaggle\/input\/ml-club-nits\/train.csv\"\ntestp = \"\/kaggle\/input\/ml-club-nits\/test.csv\"\nnaVal = [None,\"None\",\"?\",\"\",np.nan,np.inf]\ndf = pd.read_csv(trainp,na_values=naVal)","e00b6b48":"df.head()","d7913611":"df.isna().sum()","58a20b58":"df[df.isnull().any(axis=1)]","5d13d1c0":"df.Albumin_and_Globulin_Ratio.fillna(value=df.Albumin_and_Globulin_Ratio.median(),inplace=True)\ndf.Albumin_and_Globulin_Ratio.isna().sum()","5b311e1f":"Xtrain = df.iloc[:,1:-1]\nytrain = df[\"Dataset\"]\nXtrain_dummy=pd.get_dummies(columns=[\"Gender\"],data=Xtrain)\nXtrain_dummy","93454ae2":"for col in Xtrain_dummy.select_dtypes([\"float64\",\"uint8\"]).columns:\n    Xtrain_dummy[col] = Xtrain_dummy[col].astype(int)","9d79b0b7":"sc = StandardScaler()\n#sc = MinMaxScaler()\nsc.fit(Xtrain_dummy)\nX_sc = sc.transform(Xtrain_dummy.values)\nX_trainsc , X_testsc, y_train, y_test = train_test_split(X_sc,ytrain,stratify=ytrain,test_size=.25,random_state=42)\n","56476ef2":"len(Xtrain_dummy.columns)","254ab7de":"dtest = pd.read_csv(testp,na_values=naVal)\ndtestSel = dtest[Xtrain.columns]\ndtestcat = pd.get_dummies(data=dtest)\ndtestcat.drop([\"ID\"],inplace=True,axis=1)\noriginal_Xtest = sc.transform(dtestcat.values)\n","8785e5ee":"startT = int(time.time())\nmodels=[(\"LogisticReg\",LogisticRegression()),\n    (\"SVC\", SVC()),\n        (\"GradBoostC\",GradientBoostingClassifier(n_estimators=20, learning_rate=0.001, max_depth=1, random_state=0)),\n        (\"AdaBoost\",AdaBoostClassifier(n_estimators=50)),\n   #  (\"xgboost\",xgboost()),\n        (\"RandomForest\", RandomForestClassifier(n_estimators=8,max_depth=4)),\n        (\"KNN\",KNeighborsClassifier(n_neighbors=6)),\n        (\"GNB\",GaussianNB())\n       ]\npreds = []\ncv=LeaveOneOut()\nfor name,model in models:\n    results = cross_val_score(model,X_sc,ytrain,cv=cv,scoring='accuracy')\n    #preds = cross_val_predict\n    print(f\"{name}(Accuracy)\\t{results.mean():.6f}: \u00b1 {results.std():.4f}\")\n    \nstopT=int(time.time())\n\nprint(f\"------> Finished in {stopT-startT} seconds <------------\")","ea86ecbf":"resultz={}\nsvc = models[1][1]\ngdb = models[2][1]\nadb = models[3][1]\nsvc.fit(X_sc,ytrain)\ngdb.fit(X_sc,ytrain)\nadb.fit(X_sc,ytrain)\nresultz[models[1][0]]=svc.predict(original_Xtest)\nresultz[models[2][0]]=gdb.predict(original_Xtest)\nresultz[models[3][0]]=adb.predict(original_Xtest)","639079c0":"resultz","289f87b3":"outputs1 = {'ID':dtest.ID ,\n           'Dataset':resultz[models[1][0]]\n          }\noutputs2 = {'ID':dtest.ID ,\n           'Dataset':resultz[models[2][0]]\n          }\noutputs3 = {'ID':dtest.ID ,\n           'Dataset':resultz[models[3][0]]\n          }\n\nresFile1 = pd.DataFrame(outputs1)\nresFile1.to_csv(\"my_submis_svc.csv\",index=None)\nresFile2 = pd.DataFrame(outputs2)\nresFile2.to_csv(\"my_submis_gdb.csv\",index=None)\nresFile3 = pd.DataFrame(outputs3)\nresFile3.to_csv(\"my_submis_adb.csv\",index=None)","33056f83":"startT = int(time.time())    \n\nclf = StackingClassifier(estimators=models, final_estimator=LogisticRegression())\nX_trainsc , X_testsc, y_train, y_test = train_test_split(X_sc,ytrain,stratify=ytrain,test_size=.25,random_state=42)\nclf_res = clf.fit(X_trainsc, y_train).score(X_testsc, y_test)\nprint(clf_res)\nstopT=int(time.time())\n\nprint(f\"------> Finished in {stopT-startT} seconds <------------\")","a62f9430":"startT = int(time.time())    \ncross_results = cross_val_score(clf,X_sc,ytrain,cv=3,)\nprint(cross_results)\nstopT=int(time.time())\n\nprint(f\"------> Finished in {stopT-startT} seconds <------------\")","3f808e30":"resTack={}\nresTack[\"pred\"]=clf.predict(original_Xtest)\nresTack\noutputs = {'ID':dtest.ID ,\n           'Dataset':resTack[\"pred\"]\n          }\nresFile = pd.DataFrame(outputs)\nresFile.to_csv(\"my_submisTack.csv\",index=None)","831cb5c9":"from sklearn.model_selection import RandomizedSearchCV\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)","b69e7778":"startT = int(time.time())    \n# Fit the random search model\nrf_random.fit(X_trainsc, y_train)\nstopT=int(time.time())\n\nprint(f\"------> Finished in {stopT-startT} seconds <------------\")","f87e9e66":"best_random = rf_random.best_estimator_\ndef evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors \/ test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy\nevaluate(best_random, X_testsc, y_test)\n","2ac685c8":"result={}\npredictions = best_random.predict(original_Xtest)\nresult[\"rfGrid\"]=predictions","5c118cdc":"outputs = {'ID':dtest.ID ,\n           'Dataset':result['rfGrid']\n          }\nresFile = pd.DataFrame(outputs)\nresFile.to_csv(\"my_submission.csv\",index=None)","e68bb883":"# resTackPred","005ef674":"# Attempt 3,4,5","1c514f5a":"# Scaling","376f1eea":"# ===========","2beb354b":"# Stacking above models","4019caeb":"# We can search for best parameters required for classifier automatically","69749f52":"# NULLS:-","c769d3e9":"# Predict...","0f793f14":"# Filled with median ","b917dc1b":"# Columns with null-"}}