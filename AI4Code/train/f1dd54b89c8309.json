{"cell_type":{"c066ca9b":"code","11e1604c":"code","a55015cb":"code","5b98ca8e":"code","319222c6":"code","7e671236":"code","b066e382":"code","2ca9a205":"code","76eef8c7":"code","0db7506c":"code","ac991723":"code","614c341f":"code","c3f59c2c":"code","1b945f1b":"code","fe3c5e81":"code","6892e970":"code","41a52827":"code","a1914c0a":"code","0df13931":"code","9867d380":"code","a559a656":"code","d8d87263":"code","c15caf86":"code","6310ee33":"code","1c745dda":"code","f92146a1":"code","1524ac1e":"code","0bcef97d":"code","2f56b54c":"code","895fbf2f":"code","0e63b3f4":"code","987fb8bb":"code","b055bdd3":"code","cfb98b1f":"code","708d8260":"code","25040fe3":"code","ad68698e":"code","56f0e916":"code","b088bd5a":"code","ad862242":"code","e1e892ee":"code","a6a1fc0f":"code","3bd67b39":"code","c369a1ca":"code","ce417375":"code","f3460e57":"code","75860e38":"code","50fbf478":"code","83d3c504":"code","c66d5190":"code","1e59d92e":"code","a720b44d":"code","3d87a2d5":"code","8b37bf92":"code","78ea3977":"code","6e4e4d8c":"code","c021d3c4":"code","0f81ad25":"code","1ae4b27e":"code","8b33fcba":"code","002c8a19":"code","1e04eada":"markdown","7d971315":"markdown","30b69ec0":"markdown","595b3ab0":"markdown","6751274a":"markdown","bd140659":"markdown"},"source":{"c066ca9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/bmw.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11e1604c":"# Importing the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm","a55015cb":"data = pd.read_csv('..\/input\/used-car-dataset-ford-and-mercedes\/audi.csv')","5b98ca8e":"data.head()","319222c6":"data.info()","7e671236":"# There no null values and missing values in the data\ndata.isna().sum()","b066e382":"# Pairplotting to view the insights\nsns.pairplot(data)\nplt.show()","2ca9a205":"# The correlation between the features\nf, ax = plt.subplots(figsize=(18,18))\nsns.heatmap(data.corr(), annot=True, linewidth=.5, fmt='.1f', ax=ax)","76eef8c7":"# Count plot on fuel type\nax = sns.countplot(data.fuelType, label = \"Count\")","0db7506c":"# Count plot on the transmission\nax = sns.countplot(data.transmission, label = \"Count\")","ac991723":"# Count plot on model\nplt.subplots(figsize=(18,18))\nax = sns.countplot(data.model, label = \"Count\")","614c341f":"# Checking the price of car by transimission type\nplt.subplots(figsize=(12,12))\nprice_by_transmission = data.groupby(\"transmission\")['price'].mean().reset_index()\nplt.title(\"Average Price of vechicle\")\nsns.set()\nsns.barplot(x=\"transmission\", y =\"price\", data = price_by_transmission)\nplt.show()","c3f59c2c":"# Checking the price by fueltype\nplt.subplots(figsize=(12,12))\nprice_by_fuel = data.groupby(\"fuelType\")['price'].mean().reset_index()\nplt.title(\"Average Price of vechicle\")\nsns.set()\nsns.barplot(x=\"fuelType\", y =\"price\", data = price_by_fuel)\nplt.show()","1b945f1b":"# Checking the price by model\nplt.subplots(figsize=(18,18))\nprice_by_model = data.groupby(\"model\")['price'].mean().reset_index()\nplt.title(\"Average Price of vechicle\")\nsns.set()\nsns.barplot(x=\"model\", y =\"price\", data = price_by_model)\nplt.show()","fe3c5e81":"# Feature engineering\nfinal_data = pd.concat([data,pd.get_dummies(data.fuelType), pd.get_dummies(data.transmission)], axis =1)","6892e970":"final_data.head()","41a52827":"final_data = final_data.drop([\"transmission\", \"fuelType\", \"model\"], axis = 1)","a1914c0a":"# Fitting Regression Model\nX = final_data.drop(\"price\", axis = 1)\ny = final_data[\"price\"]","0df13931":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=100)","9867d380":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)","a559a656":"X_train_new = X_train\nX_train_new = sm.add_constant(X_train_new)","d8d87263":"lr_1 = sm.OLS(y_train,X_train_new).fit()\nprint(lr_1.summary())","c15caf86":"# The summary helps to view the p-value and decide on the variables to stay on the data","6310ee33":"from sklearn import preprocessing\ndef normalize(x):\n    return ((x-np.min(x))\/(max(x)-min(x)))\n\nfinal_data = final_data.apply(normalize)","1c745dda":"# After Normalizing\nfinal_data.head()","f92146a1":"X = final_data.drop('price',axis=1)\ny =  final_data['price']","1524ac1e":"# Splitting the data\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=100)\nforest_X_train = X_train.copy()\nforest_X_test = X_test.copy()\nforest_y_train = y_train.copy()\nforest_y_test = y_test.copy()","0bcef97d":"lr = LinearRegression()\nlr.fit(X_train,y_train)","2f56b54c":"X_train_new = X_train\nX_train_new = sm.add_constant(X_train_new)\nlr_2 = sm.OLS(y_train,X_train_new).fit()\nprint(lr_2.summary())","895fbf2f":"plt.figure(figsize=(12,6))\nsns.heatmap(final_data.corr(),annot=True)\nplt.show()","0e63b3f4":"# UDF for calculating vif value\ndef vif_cal(input_data, dependent_col):\n    vif_df = pd.DataFrame( columns = ['Var', 'Vif'])\n    x_vars=input_data.drop([dependent_col], axis=1)\n    xvar_names=x_vars.columns\n    for i in range(0,xvar_names.shape[0]):\n        y=x_vars[xvar_names[i]] \n        x=x_vars[xvar_names.drop(xvar_names[i])]\n        rsq=sm.OLS(y,x).fit().rsquared  \n        vif=round(1\/(1-rsq),2)\n        vif_df.loc[i] = [xvar_names[i], vif]\n    return vif_df.sort_values(by = 'Vif', axis=0, ascending=False, inplace=False)","987fb8bb":"vif_cal(input_data=final_data,dependent_col='price')","b055bdd3":"# dropping automatic column because p-value is high and also VIF is high too\nX_train = X_train.drop('Automatic',axis=1)\nlr_3 = sm.OLS(y_train,X_train).fit()\nprint(lr_3.summary())","cfb98b1f":"vif_cal(input_data=final_data.drop(['Automatic'],axis=1),dependent_col='price')","708d8260":"# dropping Diesel because p-value is high and also VIF is high too\nX_train = X_train.drop('Diesel',1)\nlr_4 = sm.OLS(y_train,X_train).fit()\n\nprint(lr_4.summary())","25040fe3":"vif_cal(input_data=final_data.drop(['Automatic','Diesel'],axis=1),dependent_col='price')","ad68698e":"# Making predictions\nX_test_m4 = sm.add_constant(X_test)","56f0e916":"X_test_m4 = X_test.drop(['Automatic', 'Diesel'],axis=1)\ny_pred_m4 = lr_4.predict(X_test_m4)","b088bd5a":"from sklearn.metrics import r2_score,mean_squared_error\nprint('R square:',r2_score(y_test,y_pred_m4))\nprint(\"RMSE:\",np.sqrt(mean_squared_error(y_test,y_pred_m4)))","ad862242":"plt.figure(figsize=(12,6))\nc = [i for i in range(1,len(X_test_m4)+1,1)]\nplt.plot(c,y_test,linestyle='-',color='b')\nplt.plot(c,y_pred_m4,linestyle='-',color='r')\nplt.title('Actual Vs Prediction')\nplt.xlabel('Index')\nplt.ylabel('Price')\nplt.show()","e1e892ee":"# Error\nplt.figure(figsize=(12,6))\nc = [i for i in range(1,len(X_test_m4)+1,1)]\nplt.plot(c,y_test-y_pred_m4,linestyle='-',color='b')\n#plt.plot(c,y_pred_m6,linestyle='-',color='r')\nplt.title('Actual Vs Prediction')\nplt.xlabel('Index')\nplt.ylabel('Error')\nplt.show()","a6a1fc0f":"# Error Distribution\nplt.figure(figsize=(12,6))\nsns.distplot(y_test-y_pred_m4,bins=50)\nplt.xlabel('y_test - y_pred')\nplt.ylabel('Index')\nplt.title('Error distribution')\nplt.show()","3bd67b39":"# Random forest regressor\n","c369a1ca":"from sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor()\nforest.fit(forest_X_train,forest_y_train)","ce417375":"forest_y_pred = forest.predict(forest_X_test)","f3460e57":"# Calculating RMSE\nforest_rmse = np.sqrt(mean_squared_error(forest_y_test,forest_y_pred))\nforest_r2score = r2_score(forest_y_test,forest_y_pred)\nprint(\"R2 score is \", forest_r2score)\nprint(\"rmse is \", forest_rmse )","75860e38":"# Model evaluation\nplt.figure(figsize=(12,6))\nc = [i for i in range(1,len(forest_X_test)+1,1)]\nplt.plot(c,forest_y_test,linestyle='-',color='b')\nplt.plot(c,forest_y_pred,linestyle='-',color='r')\nplt.title('Actual Vs Prediction')\nplt.xlabel('Index')\nplt.ylabel('Price')\nplt.show()","50fbf478":"# Error\nplt.figure(figsize=(12,6))\nc = [i for i in range(1,len(forest_X_test)+1,1)]\nplt.plot(c,forest_y_test-forest_y_pred,linestyle='-',color='b')\n#plt.plot(c,y_pred_m6,linestyle='-',color='r')\nplt.title('Actual Vs Prediction')\nplt.xlabel('Index')\nplt.ylabel('Error')\nplt.show()","83d3c504":"# Decision tree regressor","c66d5190":"from sklearn.tree import DecisionTreeRegressor\ntree=DecisionTreeRegressor()\ntree.fit(forest_X_train.drop(['Automatic','Diesel'], axis=1),forest_y_train)","1e59d92e":"tree_y_pred = tree.predict(forest_X_test.drop(['Automatic', 'Diesel'], axis = 1))","a720b44d":"# Calculating RMSE\nforest_rmse = np.sqrt(mean_squared_error(forest_y_test,tree_y_pred))\nforest_r2score = r2_score(forest_y_test,tree_y_pred)\nprint(\"R2 score is \", forest_r2score)\nprint(\"rmse is \", forest_rmse )","3d87a2d5":"# XGboost model","8b37bf92":"import xgboost as xgb\nregressor = xgb.XGBRegressor(\n    n_estimators=200,\n    reg_lambda=2,\n    gamma=0,\n    max_depth=5\n)","78ea3977":"regressor.fit(forest_X_train, forest_y_train)","6e4e4d8c":"boost_y_pred = regressor.predict(forest_X_test)","c021d3c4":"# Calculating RMSE\nforest_rmse = np.sqrt(mean_squared_error(forest_y_test,boost_y_pred))\nforest_r2score = r2_score(forest_y_test,boost_y_pred)\nprint(\"R2 score is \", forest_r2score)\nprint(\"rmse is \", forest_rmse )","0f81ad25":"# Model evaluation\nplt.figure(figsize=(12,6))\nc = [i for i in range(1,len(forest_X_test)+1,1)]\nplt.plot(c,forest_y_test,linestyle='-',color='b')\nplt.plot(c,boost_y_pred,linestyle='-',color='r')\nplt.title('Actual Vs Prediction')\nplt.xlabel('Index')\nplt.ylabel('Price')\nplt.show()","1ae4b27e":"# Error\nplt.figure(figsize=(12,6))\nc = [i for i in range(1,len(forest_X_test)+1,1)]\nplt.plot(c,forest_y_test-boost_y_pred,linestyle='-',color='b')\n#plt.plot(c,y_pred_m6,linestyle='-',color='r')\nplt.title('Actual Vs Prediction')\nplt.xlabel('Index')\nplt.ylabel('Error')\nplt.show()","8b33fcba":"# Error distribution\nplt.figure(figsize=(12,6))\nsns.distplot(forest_y_test-boost_y_pred,bins=50)\nplt.xlabel('y_test - y_pred')\nplt.ylabel('Index')\nplt.title('Error distribution')\nplt.show()","002c8a19":"# The prediction\nprint('The original price'+str(forest_y_test.head())+'\\nThe predicted values'+str(boost_y_pred[0:5]))","1e04eada":"# Please Upvote to motivate me & for my contribution on kaggle :)\n# THANK YOU","7d971315":"# Model Evaluation\n","30b69ec0":"# Error","595b3ab0":"# Comapritively the XGboost performs well on both train and the test data.\nAnd the error distributed is minimum as possible","6751274a":"# Normalizing the data","bd140659":"# EDA on the data\n"}}