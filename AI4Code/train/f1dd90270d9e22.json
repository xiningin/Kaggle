{"cell_type":{"cb88d4d4":"code","2cfb79f5":"code","e3a892e0":"code","29e68b1a":"code","eb98d108":"code","cc5aa90e":"code","6fc2760f":"code","bed9d18d":"code","a92672e5":"code","a7318c06":"code","6f3d638c":"code","56189372":"code","37e7bd12":"code","2e54053b":"code","84360d3e":"code","434e7a3a":"code","d3d4f87d":"code","1d6592cd":"code","d406841a":"code","ac0a217f":"code","72417b5b":"code","085a33ab":"code","78d63149":"code","a87f1383":"code","4439712c":"code","897438c4":"code","c6408d0f":"code","67363c2e":"code","a1352ca4":"code","9dca4936":"code","2e4b2416":"code","e4d4461e":"code","da01fa02":"code","2b9ac046":"code","c57fcfa9":"code","baa2a71f":"code","80a4e616":"code","a9de0879":"code","3742b6b7":"code","9a45c578":"code","25ba80d4":"code","bb82bdf9":"code","880be931":"code","76c02b52":"code","4de070f1":"code","9a8506ee":"markdown","1ffba44f":"markdown","08334962":"markdown","62d24a32":"markdown","f8188cd3":"markdown","b8778dd3":"markdown","d31a43df":"markdown","88f4647f":"markdown","8691d65e":"markdown","297f5fd3":"markdown","ca4a3f7b":"markdown","889e79c3":"markdown","c7a547ca":"markdown","df321930":"markdown","e6492b23":"markdown","3badcaf2":"markdown","847722d7":"markdown","096ea893":"markdown","85726455":"markdown","c882cae5":"markdown","05a58bec":"markdown","2f2e9fa6":"markdown","1fad4fcb":"markdown","3250b379":"markdown","8e34eda1":"markdown","0420eeb4":"markdown","66a902b7":"markdown","e41c3956":"markdown","95e0d88f":"markdown","f7faaae5":"markdown"},"source":{"cb88d4d4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","2cfb79f5":"df = pd.read_csv('..\/input\/data-analyst-jobs\/DataAnalyst.csv')","e3a892e0":"df.head(2)","29e68b1a":"df.drop(['Unnamed: 0'], axis=1,inplace=True)","eb98d108":"df.isna().sum()","cc5aa90e":"df[df.isnull().any(axis=1)]","6fc2760f":"df.dropna(axis=0 , subset=['Company Name'], inplace=True)","bed9d18d":"missing_val_dict = {\n    -1 : np.nan,\n    -1.0 : np.nan,\n    '-1' : np.nan\n}","a92672e5":"df.replace(missing_val_dict, inplace=True)","a7318c06":"df['Easy Apply'].replace(np.nan, False, inplace=True)","6f3d638c":"df.isna().sum()","56189372":"df['Job Title'], df['Department'] = df['Job Title'].str.split(',', 1).str","37e7bd12":"df['Job Title'].value_counts()[:20]","2e54053b":"df['Job Title'] = df['Job Title'].replace(['Sr. Data Analyst', 'Sr Data Analyst'], 'Senior Data Analyst')","84360d3e":"df['Job Title'].value_counts()[:20]","434e7a3a":"df['Salary Estimate']","d3d4f87d":"df['Salary Estimate'],_ = df['Salary Estimate'].str.split('(', 1).str\ndf['Min Salary'], df['Max Salary'] = df['Salary Estimate'].str.split('-').str\ndf.dropna(axis=0 , subset=['Max Salary'], inplace=True)","1d6592cd":"df['Max Salary'] = df['Max Salary'].str.extract('(\\d+)')\ndf['Min Salary'] = df['Min Salary'].str.extract('(\\d+)')\n\ndf['Min Salary'] = df['Min Salary'].astype(str).astype(int)\ndf['Max Salary'] = df['Max Salary'].astype(str).astype(int)","d406841a":"del df['Salary Estimate']","ac0a217f":"df['Company Name'], temp = df['Company Name'].str.split('\\n', 1).str","72417b5b":"df['Location'].value_counts()[:20]","085a33ab":"df['City'], df['State'] = df['Location'].str.split(',', 1).str","78d63149":"df['State'] = df['State'].replace([' Arapahoe, CO'], ' CO')","a87f1383":"df['State'] = df['State'].str.strip()\ndf['City'] = df['City'].str.strip()","4439712c":"df['State'].value_counts()","897438c4":"df['Industry'] = df['Industry'].fillna('Others')","c6408d0f":"df['Sector'] = df['Sector'].fillna('Others')","67363c2e":"df['Rating'] = df['Rating'].fillna(round(df['Rating'].mean(), 1))","a1352ca4":"def filter_revenue(x):\n    revenue=0\n    if(x== 'Unknown \/ Non-Applicable' or type(x)==float):\n        revenue=0\n    elif(('million' in x) and ('billion' not in x)):\n        maxRev = x.replace('(USD)','').replace(\"million\",'').replace('$','').strip().split('to')\n        if('Less than' in maxRev[0]):\n            revenue = float(maxRev[0].replace('Less than','').strip())\n        else:\n            if(len(maxRev)==2):\n                revenue = float(maxRev[1])\n            elif(len(maxRev)<2):\n                revenue = float(maxRev[0])\n    elif(('billion'in x)):\n        maxRev = x.replace('(USD)','').replace(\"billion\",'').replace('$','').strip().split('to')\n        if('+' in maxRev[0]):\n            revenue = float(maxRev[0].replace('+','').strip())*1000\n        else:\n            if(len(maxRev)==2):\n                revenue = float(maxRev[1])*1000\n            elif(len(maxRev)<2):\n                revenue = float(maxRev[0])*1000\n    return revenue","9dca4936":"df['Revenue'] = df['Revenue'].apply(lambda x: filter_revenue(x))","2e4b2416":"important_column = ['Job Title', 'Rating', 'Company Name', 'State', 'City','Size', 'Industry', 'Sector', 'Min Salary', 'Max Salary', 'Revenue']","e4d4461e":"df[important_column].head()","da01fa02":"top_20_job = pd.DataFrame(df['Job Title'].value_counts()[:20]).reset_index()\ntop_20_job.rename(columns={'index': 'Job Title', 'Job Title': 'No. of Openings'}, inplace=True)","2b9ac046":"fig = go.Figure(go.Bar(\n    x=top_20_job['Job Title'],\n    y=top_20_job['No. of Openings'],\n))\nfig.update_layout(title_text='Current openings in different Roles',xaxis_title=\"Job Title\",yaxis_title=\"Number of openings\")\nfig.show()","c57fcfa9":"top_20_industry = pd.DataFrame(df['Industry'].value_counts()[1:21]).reset_index()\ntop_20_industry.rename(columns={'index': 'Industry', 'Industry': 'No. of Openings'}, inplace=True)","baa2a71f":"fig = go.Figure(go.Bar(\n    x=top_20_industry['Industry'],\n    y=top_20_industry['No. of Openings'],\n))\nfig.update_layout(title_text='Current openings in different Industry',xaxis_title=\"Industry\",yaxis_title=\"Number of openings\")\nfig.show()","80a4e616":"top_20_city = pd.DataFrame(df['City'].value_counts()[:20]).reset_index()\ntop_20_city.rename(columns={'index':'City', 'City':'No. of Openings'}, inplace=True)","a9de0879":"fig = go.Figure(go.Bar(\n    x=top_20_city['City'],\n    y=top_20_city['No. of Openings'],\n))\nfig.update_layout(title_text='Current openings in different City',xaxis_title=\"City\",yaxis_title=\"Number of openings\")\nfig.show()","3742b6b7":"top_20_company = pd.DataFrame(df['Company Name'].value_counts()[:20]).reset_index()\ntop_20_company.rename(columns={'index':'Company Name' , 'Company Name':'No. of Openings'},inplace=True)","9a45c578":"companies = top_20_company['Company Name'].values\nrevenue_rating = df[df['Company Name'].isin(companies)][['Company Name','Rating', 'Revenue']]\nrevenue_rating = revenue_rating.groupby('Company Name').mean()","25ba80d4":"fig = go.Figure(go.Bar(\n    x=top_20_company['Company Name'],\n    y=top_20_company['No. of Openings'],\n))\nfig.update_layout(title_text='Current openings in different City',xaxis_title=\"Company\",yaxis_title=\"Number of openings\")\nfig.show()","bb82bdf9":"df.dropna(axis=0 , subset=['Max Salary','Min Salary'], inplace=True)","880be931":"grp_job_title = df[['Job Title','Min Salary', 'Max Salary']].groupby('Job Title').mean().reset_index()\ngrp_job_title = grp_job_title[grp_job_title['Job Title'].isin(top_20_job['Job Title'].values)].reset_index()\ndel grp_job_title['index']","76c02b52":"grp_job_title['Min Salary'] = grp_job_title['Min Salary'].round(2)\ngrp_job_title['Max Salary'] = grp_job_title['Max Salary'].round(2)","4de070f1":"fig = go.Figure(data=[\n    go.Bar(name='Min Salary', x=grp_job_title['Job Title'], y=grp_job_title['Min Salary'],marker_color='indianred'),\n    go.Bar(name='Max Salary', x=grp_job_title['Job Title'], y=grp_job_title['Max Salary'],marker_color='lightsalmon'),\n])\n# Change the bar mode\nfig.update_layout(barmode='group', title='Min and Max salary of top 20 Job openings',\n                 yaxis=dict(\n                    title='USD (_K)',\n                    titlefont_size=16,\n                    tickfont_size=14,\n                ),\n                xaxis=dict(\n                    title='Job Title',\n                    titlefont_size=16,\n                    tickfont_size=14,\n                ))\n\nfig.show()","9a8506ee":"* we are spliting the states and cities from 'Location' column","1ffba44f":"* ### From the above output we can see that there are many missing values in the dataset. But we have only work with some columns like :\n    1. Job Title.\n    2. Salary Estimate.\n    3. Company Name.\n    4. Location.\n    5. Industry.\n    6. Sector.\n    7. Rating\n    8. Size.\n    9. Revenue\n    \n    \n    \n* ### So let's view the details of this cloumns to make this ready for visualization purpose","08334962":"## Now it's time to visualize.","62d24a32":"* Ratings and Revenue","f8188cd3":"* ## Creating a dictionary having keys as missing values","b8778dd3":"# Data Analyst jobs visualization\n\n## About Dataset\n\nThis dataset was created by picklesueat and contains more than 2000 job listing for data analyst positions, with features such as:\n\n* Job Title.\n* Salary Estimate.\n* Company Name.\n* Location.\n* Industry.\n* Sector.\n* Rating\n* Size.\n* Revenue","d31a43df":"## Now our working dataset is ready","88f4647f":"# If you like my work do UPVOTE","8691d65e":"### Cleaning 'Sector' column","297f5fd3":"## Data Cleaning","ca4a3f7b":"* As we can see that it's very hard to predict the null values because it has many missing values present in the entire row. So it's better to remove the row.","889e79c3":"* Top 20 most Openings in different Roles","c7a547ca":"### filter revenue Function","df321930":"* ### Removing 'Unnamed' column","e6492b23":"* Top 20 Companies providing most Jobs","3badcaf2":"### Cleaning Salary Estimate column","847722d7":"### Cleaning 'Company Name' column","096ea893":"* Top 20 Industries offering most number of Jobs","85726455":"* Jobs offering in different city","c882cae5":"### Cleaning 'Revenue' column","05a58bec":"* ### checking for null values in the dataset","2f2e9fa6":"### Cleaning 'Location' column","1fad4fcb":"## Importing necessary Libraries","3250b379":"### Cleaning 'Rating' column","8e34eda1":">  As we can see 'Salary Estimate' column need some cleaning by removing the glassdoor est. and spliting salary into 2 col( min and max ) columns","0420eeb4":"## starting with 'Job Title' column","66a902b7":"> we can see that only 'Company Name' column has a null value.Displaying the row","e41c3956":"### Cleaning 'Industry' column**","95e0d88f":"* Replacing the values having missing or incorrect data in the dataframe","f7faaae5":"* Jobs having min and max salary"}}