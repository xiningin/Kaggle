{"cell_type":{"30eb36ce":"code","0e144447":"code","3a00c8dc":"code","c8cb35f6":"code","1386ca11":"code","713e7351":"code","8fd93504":"code","2cc4e2c4":"code","643dad9e":"code","e53028db":"code","af800bad":"code","129eaa71":"code","758d5e55":"code","938c6132":"code","af668d65":"code","65349920":"code","2fa5d95b":"code","44f2d6b9":"code","91cdfbbe":"markdown","d2172cdd":"markdown","2a20befb":"markdown","1ba5d0e0":"markdown","d2aa63a5":"markdown","23d4148e":"markdown","4f8b8a5a":"markdown","480e6a7b":"markdown","94b40759":"markdown","5b70e8df":"markdown","525bc278":"markdown","897d7802":"markdown","df88d502":"markdown","37185d38":"markdown","eaa69728":"markdown"},"source":{"30eb36ce":"!nvidia-smi","0e144447":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","3a00c8dc":"!python -m pip install detectron2 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu110\/torch1.7\/index.html","c8cb35f6":"!python -m detectron2.utils.collect_env","1386ca11":"# import some common libraries\nimport numpy as np\nimport os, json, cv2, random\nimport skimage.io as io\nimport pylab\nimport sys\nimport copy\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import colors\nfrom tensorboard.backend.event_processing import event_accumulator as ea\nfrom PIL import Image\n\n\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\n# Set base params\n#plt.rcParams[\"figure.figsize\"] = [16,9]","713e7351":"dataset_dir = \"..\/input\/bccd-coco\"\ntrain_dir = \"train\/\"\nval_dir = \"valid\/\"\ntest_dir = \"test\/\"","8fd93504":"from detectron2.data.datasets import register_coco_instances\nregister_coco_instances(\"bccd_train\", {}, os.path.join(dataset_dir,train_dir,\"_annotations.coco.json\"), os.path.join(dataset_dir,train_dir))\nregister_coco_instances(\"bccd_val\", {}, os.path.join(dataset_dir,val_dir,\"_annotations.coco.json\"), os.path.join(dataset_dir,val_dir))\nregister_coco_instances(\"bccd_test\", {}, os.path.join(dataset_dir,test_dir,\"_annotations.coco.json\"), os.path.join(dataset_dir,test_dir))","2cc4e2c4":"dataset_dicts = DatasetCatalog.get(\"bccd_train\")\nmetadata_dicts = MetadataCatalog.get(\"bccd_train\")","643dad9e":"fig, ax = plt.subplots(2, 2, figsize =(20,14))\nindices=[ax[0][0],ax[1][0],ax[0][1],ax[1][1] ]\ni=-1\nfor d in random.sample(dataset_dicts, 4):\n    i=i+1    \n    img = cv2.imread(d[\"file_name\"])\n    v = Visualizer(img[:, :, ::-1],\n                   metadata=metadata_dicts, \n                   scale=0.4, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n    )\n    out = v.draw_dataset_dict(d)\n    indices[i].grid(False)\n    indices[i].axis('off')\n    indices[i].imshow(out.get_image()[:, :, ::-1])\n    ","e53028db":"from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\nimport detectron2.data.transforms as T\n\ndef custom_mapper(dataset_dict):\n    \n    dataset_dict = copy.deepcopy(dataset_dict)\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n    transform_list = [T.Resize((640,640)),\n                      T.RandomBrightness(0.9, 1.1),\n                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n                      T.RandomCrop(\"absolute\", (640, 640))\n                      ]\n    image, transforms = T.apply_transform_gens(transform_list, image)\n    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n\n    annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n        if obj.get(\"iscrowd\", 0) == 0\n    ]\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n    return dataset_dict\nclass AugTrainer(DefaultTrainer):\n    \n    @classmethod\n    def build_train_loader(cls, cfg):\n        return build_detection_train_loader(cfg, mapper=custom_mapper)","af800bad":"\ncfg = get_cfg()\nconfig_name = \"COCO-Detection\/faster_rcnn_R_50_FPN_3x.yaml\" \n#config_name = \"COCO-Detection\/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"\ncfg.merge_from_file(model_zoo.get_config_file(config_name))\n\ncfg.DATASETS.TRAIN = (\"bccd_train\",)\ncfg.DATASETS.TEST = (\"bccd_val\",)\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\n\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR = 0.00025\n\ncfg.SOLVER.WARMUP_ITERS = 1000\ncfg.SOLVER.MAX_ITER = 3500 #adjust up if val mAP is still rising, adjust down if overfit\n#cfg.SOLVER.STEPS = (100, 500) # must be less than  MAX_ITER \n#cfg.SOLVER.GAMMA = 0.05\n\n\ncfg.SOLVER.CHECKPOINT_PERIOD = 100000  # Small value=Frequent save need a lot of storage.\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n\n\n#Training using custom trainer defined above\n#trainer = AugTrainer(cfg) \ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()\n","129eaa71":"evaluator = COCOEvaluator(\"bccd_val\", cfg, False, output_dir=\".\/output\/\")\nval_loader = build_detection_test_loader(cfg, \"bccd_val\")\ninference_on_dataset(trainer.model, val_loader, evaluator)","758d5e55":"import pandas as pd\nmetrics_df = pd.read_json(\".\/output\/metrics.json\", orient=\"records\", lines=True)\nmdf = metrics_df.sort_values(\"iteration\")\nmdf.T","938c6132":"# 1. Loss curve\nfig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"total_loss\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\nif \"validation_loss\" in mdf.columns:\n    mdf2 = mdf[~mdf[\"validation_loss\"].isna()]\n    ax.plot(mdf2[\"iteration\"], mdf2[\"validation_loss\"], c=\"C1\", label=\"validation\")\n\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"Loss curve\")\nplt.show()\n","af668d65":"# 1. Loss curve\nfig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"fast_rcnn\/cls_accuracy\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"fast_rcnn\/cls_accuracy\"], c=\"C0\", label=\"train\")\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"cls_accuracy\")\nplt.show()\n","65349920":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\ncfg.DATASETS.TEST = (\"bccd_test\", )\npredictor = DefaultPredictor(cfg)","2fa5d95b":"test_dataset_dicts = DatasetCatalog.get(\"bccd_test\")\ntest_metadata_dicts = MetadataCatalog.get(\"bccd_test\")","44f2d6b9":"fig, ax = plt.subplots(2, 2, figsize =(20,14))\nindices=[ax[0][0],ax[1][0],ax[0][1],ax[1][1] ]\ni=-1\nfor d in random.sample(test_dataset_dicts, 4):\n    i=i+1    \n    im = io.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=test_metadata_dicts, \n                   scale=0.4, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n    )\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    indices[i].grid(False)\n    indices[i].imshow(out.get_image()[:, :, ::-1])","91cdfbbe":"* It seems CUDA=11.0 and torch==1.7.0 is used in this kaggle docker image.\n* See installation for details.\nhttps:\/\/detectron2.readthedocs.io\/en\/latest\/tutorials\/install.html","d2172cdd":"##  If this kernel helps you, please upvote to keep me motivated \ud83d\ude01 Thanks!","2a20befb":"# References","1ba5d0e0":"# predictor\nA predictor is defined with 0.5 threshold score which gives bounding box and label for the test images","d2aa63a5":"# Installation\n* detectron2 is not pre-installed in this kaggle docker, so let's install it.\n* we need to know CUDA and pytorch version to install correct detectron2.","23d4148e":"# Data visualisation","4f8b8a5a":"# Import Libraries","480e6a7b":"# Data Augmentation\nThe dataset is transformed by changing the brighness and flipping the image with 50% probability.","94b40759":"* https:\/\/www.kaggle.com\/corochann\/vinbigdata-detectron2-train\n* https:\/\/www.aicrowd.com\/showcase\/maskrcnn-augmentation\n* https:\/\/blog.roboflow.com\/how-to-train-detectron2\/\n\n","5b70e8df":"# evaluator","525bc278":"Detectron2 keeps track of a list of available datasets in a registry, so we must register our custom data with Detectron2 so it can be invoked for training.\n\nIf you want to use a custom dataset while also reusing detectron2\u2019s data loaders, you will need to\n*  Register your dataset (i.e., tell detectron2 how to obtain your dataset).\n* Optionally, register metadata for your dataset.","897d7802":"# Training\n","df88d502":"# Training Detectron2 for blood cells detection\ncategory_dict = {\"cells\":0, \"Platelets\":1, \"RBC\":2, \"WBC\":3}\n","37185d38":"# Register Dataset","eaa69728":"# Install Pre-Built Detectron2"}}