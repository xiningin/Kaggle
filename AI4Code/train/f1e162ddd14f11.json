{"cell_type":{"5ba95a78":"code","9e2d3d5f":"code","c0735328":"code","820f3b5e":"code","9f9885ca":"code","e07a8ee7":"code","61b46d4c":"code","b49da0bb":"code","82096285":"code","0a01d1b5":"code","113e446a":"code","09d9acfc":"code","0d261f2e":"code","e8f95d8c":"code","a2814e51":"code","e48bbd94":"code","713424dc":"code","917f938c":"code","204e317d":"code","a0597777":"code","81f1a0a3":"code","13f9bc60":"code","897afd2c":"code","7ef9da79":"code","c7795f7c":"code","2c56493c":"code","9178f62b":"code","84e3fd1c":"code","574450ef":"code","a5b06c84":"code","92bc53f8":"code","0e5211f8":"code","0499341f":"code","8130056b":"markdown","d848a1ed":"markdown","d71e21f5":"markdown","f40ccd1e":"markdown","7d9220df":"markdown","66e90569":"markdown","b1c51413":"markdown","d99a2ed3":"markdown","b9c0b05d":"markdown","945ed96e":"markdown","3f537cf0":"markdown","1a2bbabc":"markdown","8628e1ee":"markdown","c7262d2c":"markdown","1e43b1cc":"markdown","f1ea7c72":"markdown"},"source":{"5ba95a78":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e2d3d5f":"import pandas as pd\nimport seaborn as sns","c0735328":"car_data = pd.read_csv(\"\/kaggle\/input\/vehicle-dataset-from-cardekho\/car data.csv\")\ncar_data.head()","820f3b5e":"car_data.shape","9f9885ca":"print(car_data[\"Fuel_Type\"].value_counts(),car_data[\"Seller_Type\"].value_counts(),car_data[\"Transmission\"].value_counts(),car_data[\"Owner\"].value_counts(), sep='\\n\\n')","e07a8ee7":"car_data.isnull().sum()","61b46d4c":"car_data.describe(include=\"all\")","b49da0bb":"col = car_data.columns.to_list()\ncol.remove('Car_Name')\n\ncar_dup = car_data[col]\ncar_dup.head()","82096285":"current_year = 2021\ncar_dup[\"Num_Years\"] = current_year-car_dup[\"Year\"] \ncar_dup.head()","0a01d1b5":"car_dup.drop('Year', axis=1, inplace=True)\ncar_dup.head()","113e446a":"final_data = car_dup.copy()\nfinal_data = pd.get_dummies(final_data, drop_first=True)\nfinal_data.head()","09d9acfc":"final_data.corr()","0d261f2e":"sns.pairplot(final_data.corr())","e8f95d8c":"import matplotlib.pyplot as plt\n%matplotlib inline","a2814e51":"corrmat = final_data.corr()\ntop_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heatmap\ngraph = sns.heatmap(final_data[top_features].corr(),annot = True, cmap='RdYlGn')","e48bbd94":"final_data.head()","713424dc":"X = final_data.iloc[:,1:]\ny = final_data.iloc[:,0]","917f938c":"print(X.head(), y.head(), sep='\\n\\n')","204e317d":"## Feature importance\nfrom sklearn.ensemble import ExtraTreesRegressor\nmodel = ExtraTreesRegressor()\nmodel.fit(X,y)","a0597777":"print(model.feature_importances_)","81f1a0a3":"feat_importance = pd.Series(model.feature_importances_, index = X.columns)\nfeat_importance.nlargest(5).plot(kind='barh')\nplt.show()","13f9bc60":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)","897afd2c":"print(X_train.shape)\nprint(X_test.shape)","7ef9da79":"from sklearn.ensemble import RandomForestRegressor\nrf_random = RandomForestRegressor()","c7795f7c":"import numpy as np\nn_estimators = [int(x) for x in np.linspace(start  = 100, stop = 1200, num = 12)]\nn_estimators","2c56493c":"#Randomized Serach CV\n\nmax_features = ['auto','sqrt']\n#max number of levels in a tree\nmax_depth = [int(x) for x in np.linspace(5,30,num=6)]\n#min number of samples required to split a node\nmin_samples_split = [2,5,10,15,100]\n#Min number of samples required at each leaf node\nmin_samples_leaf = [1,2,5,10]","9178f62b":"from sklearn.model_selection import RandomizedSearchCV","84e3fd1c":"random_grid = {'n_estimators' : n_estimators,\n               'max_features' : max_features,\n               'max_depth' : max_depth,\n               'min_samples_split' : min_samples_split,\n               'min_samples_leaf' : min_samples_leaf\n}\nprint(random_grid)","574450ef":"rf = RandomForestRegressor()\nrf_random = RandomizedSearchCV(estimator= rf, param_distributions= random_grid, scoring='neg_mean_squared_error',n_iter=10, cv = 5, verbose=2, random_state=42, n_jobs=1)\n#verbose displays the results","a5b06c84":"rf_random.fit(X_train, y_train)","92bc53f8":"y_pred = rf_random.predict(X_test)\ny_pred","0e5211f8":"sns.distplot(y_test - y_pred)","0499341f":"plt.scatter(y_test, y_pred)","8130056b":"this RandomizedSearchCV takes input as the parameters that we have specified and will automatically select the best parameters for us.","d848a1ed":"Since by looking at the data we can see that the selling price is our dependent value and fuel_type, seller_type, transmission are our categorical values","d71e21f5":"linear line shows that our results are good","f40ccd1e":"the array shows the number of different decision trees that will be used in RandomForestRegressor","7d9220df":"RandomizedSearchCV helps us to find the best parameters for our data. It's also faster then gridsearchCV","66e90569":"## One Hot Encoding to convert categorical data to numeric data","b1c51413":"now check for missing values if any","d99a2ed3":"let's separate the dependent and independent variable now","b9c0b05d":"we can see that the year is of no used except for deriving a new column of number of years since manufacturing","945ed96e":"to compare the results, we will use displot","3f537cf0":"let's see this by visualization","1a2bbabc":"let's work with the hyperparamters and some other parameters of RandomForestRegressor","8628e1ee":"since the graph shows the normal distribution, it means the model is giving great results.","c7262d2c":"we can see that the first feature and fifth feature (present price and fuel_type_diesel) has the most importance","1e43b1cc":"the pairplot visualizes the correlation table in a form and shows how strongly two variables are related, we'll use heatmap next to make it more visualizing.","f1ea7c72":"240 out of 301 of our data is for training, and 61 records are for testing"}}