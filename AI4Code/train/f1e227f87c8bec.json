{"cell_type":{"f035afc5":"code","5187240e":"code","2c04c1a7":"code","4b198bda":"code","d347c722":"code","d5e50df1":"code","92800523":"code","9210cdd7":"code","3d022b45":"markdown"},"source":{"f035afc5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nfrom tqdm import tqdm\nimport sys\n\nsys.path.append('..\/input\/tensorflow-great-barrier-reef')","5187240e":"!mkdir -p \/root\/.config\/Ultralytics\n!cp \/kaggle\/input\/yolov5-font\/Arial.ttf \/root\/.config\/Ultralytics\/","2c04c1a7":"import greatbarrierreef\nenv = greatbarrierreef.make_env()# initialize the environment\niter_test = env.iter_test()      # an iterator which loops over the test set and sample submission","4b198bda":"model = torch.hub.load('..\/input\/yolov5-lib-ds', \n                       'custom', \n                       path='..\/input\/reef-baseline-fold12\/l6_3600_uflip_vm5_f12_up\/f1\/best.pt',\n                       source='local',\n                       force_reload=True)  # local repo\nmodel.conf = 0.20","d347c722":"# norfair dependencies\n%cd \/kaggle\/input\/norfair031py3\/\n!pip install commonmark-0.9.1-py2.py3-none-any.whl -f .\/ --no-index\n!pip install rich-9.13.0-py3-none-any.whl\n\n!mkdir \/kaggle\/working\/tmp\n!cp -r \/kaggle\/input\/norfair031py3\/filterpy-1.4.5\/filterpy-1.4.5\/ \/kaggle\/working\/tmp\/\n%cd \/kaggle\/working\/tmp\/filterpy-1.4.5\/\n!pip install .\n!rm -rf \/kaggle\/working\/tmp\n\n# norfair\n%cd \/kaggle\/input\/norfair031py3\/\n!pip install norfair-0.3.1-py3-none-any.whl -f .\/ --no-index\n%cd \/kaggle\/working\/","d5e50df1":"##############################################################\n#                      Tracking helpers                      #\n##############################################################\n\nimport numpy as np\nfrom norfair import Detection, Tracker\n\n# Helper to convert bbox in format [x_min, y_min, x_max, y_max, score] to norfair.Detection class\ndef to_norfair(detects, frame_id):\n    result = []\n    for x_min, y_min, x_max, y_max, score in detects:\n        xc, yc = (x_min + x_max) \/ 2, (y_min + y_max) \/ 2\n        w, h = x_max - x_min, y_max - y_min\n        result.append(Detection(points=np.array([xc, yc]), scores=np.array([score]), data=np.array([w, h, frame_id])))\n        \n    return result\n\n# Euclidean distance function to match detections on this frame with tracked_objects from previous frames\ndef euclidean_distance(detection, tracked_object):\n    return np.linalg.norm(detection.points - tracked_object.estimate)","92800523":"tracker = Tracker(\n    distance_function=euclidean_distance, \n    distance_threshold=30,\n    hit_inertia_min=3,\n    hit_inertia_max=6,\n    initialization_delay=1,\n)\nframe_id = 0","9210cdd7":"for idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n    detects = []\n    anno = ''\n    r = model(img, size=10000, augment=True)\n    if r.pandas().xyxy[0].shape[0] == 0:\n        anno = ''\n    else:\n        for idx, row in r.pandas().xyxy[0].iterrows():\n            if row.confidence > 0.28:      \n                anno += '{} {} {} {} {} '.format(row.confidence, int(row.xmin), int(row.ymin), int(row.xmax-row.xmin), int(row.ymax-row.ymin))\n                detects.append([int(row.xmin), int(row.ymin), int(row.xmin)+int(row.xmax-row.xmin), int(row.ymin)+int(row.ymax-row.ymin), row.confidence])\n\n    tracked_objects = tracker.update(detections=to_norfair(detects, frame_id))\n    for tobj in tracked_objects:\n        bbox_width, bbox_height, last_detected_frame_id = tobj.last_detection.data\n        if last_detected_frame_id == frame_id:  # Skip objects that were detected on current frame\n            continue\n            \n        # Add objects that have no detections on current frame to predictions\n        xc, yc = tobj.estimate[0]\n        x_min, y_min = int(round(xc - bbox_width \/ 2)), int(round(yc - bbox_height \/ 2))\n        score = tobj.last_detection.scores[0]\n        anno += '{} {} {} {} {} '.format(score, x_min, y_min, bbox_width, bbox_height)\n        \n    pred_df['annotations'] = anno.strip(' ')\n    env.predict(pred_df)\n    frame_id += 1","3d022b45":"# YOLOv5 detections + TRACKING submission made on COTS dataset\n\nTracking is a Great idea\uff01 We got it from Aleksandr Snorkin's notebook. Thanks [Aleksandr Snorkin](https:\/\/www.kaggle.com\/parapapapam)! \n\nLB:0.642\n\nIf you like this work, please upvote !\n\nReferences for this notebook are listed below:\n\n[1][YoloX inference + Tracking on COTS [LB 0.539]](https:\/\/www.kaggle.com\/parapapapam\/yolox-inference-tracking-on-cots-lb-0-539)\n\n[2][higher resolution and confidence](https:\/\/www.kaggle.com\/macxiao\/higher-resolution-and-confidence)\n\n[3][Yolov5 is all you need](https:\/\/www.kaggle.com\/steamedsheep\/yolov5-is-all-you-need),\n\nplease upvote them also! "}}