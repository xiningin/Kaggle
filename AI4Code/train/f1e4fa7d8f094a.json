{"cell_type":{"87142e64":"code","aaf2a5bc":"code","b911ea92":"code","81d2231b":"code","8b290694":"code","22c8cd54":"code","6e23d37d":"code","c5f2cc7d":"code","12a9500b":"code","a5e8a8c0":"code","53ea1bd4":"code","2f95775a":"code","ce852f30":"code","2d7101b8":"code","8a16653b":"code","27ee5839":"code","8f094fd0":"code","fd045d28":"code","7aba2654":"code","96677a2d":"code","83804de3":"code","96474309":"code","9afac061":"markdown","a0c7d8f9":"markdown","3f13188b":"markdown","77fa1633":"markdown","b9e8e0d8":"markdown","7b0db305":"markdown","0273df37":"markdown","c4cdc133":"markdown","0a28ad2f":"markdown","735e36db":"markdown","5281f8a5":"markdown","d1d3be8c":"markdown","a35e484e":"markdown","0021a9a3":"markdown","1f558f5b":"markdown","ad6ea16d":"markdown","2b77005d":"markdown","cd3de93e":"markdown","d3b6ad75":"markdown","23ab9b9e":"markdown","5a6f3ca2":"markdown","e27d3c7d":"markdown","0373ef5a":"markdown"},"source":{"87142e64":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","aaf2a5bc":"data=pd.read_csv('..\/input\/zomato.csv')\ndata.head()\n# data.shape","b911ea92":"print(\"Percentage null or na values in df\")\n((data.isnull() | data.isna()).sum() * 100 \/ data.index.size).round(2)","81d2231b":"data.rate = data.rate.replace(\"NEW\", np.nan)\ndata.dropna(how ='any', inplace = True)","8b290694":"# data.url.unique()\n# data.address.unique()\n# data.phone.unique()\n# data[['location','listed_in(city)']]","22c8cd54":"del data['url']\ndel data['address']\ndel data['phone']\ndel data['location']\ndata.rename(columns={'approx_cost(for two people)': 'average_cost', 'listed_in(city)': 'locality','listed_in(type)': 'restaurant_type'}, inplace=True)\ndata.head()","6e23d37d":"X = data\nX.rate = X.rate.astype(str)\nX.rate = X.rate.apply(lambda x: x.replace('\/5',''))\nX.rate = X.rate.apply(lambda x: float(x))\nX.head()","c5f2cc7d":"rcParams['figure.figsize'] = 15,7\ng = sns.countplot(x=\"locality\",data=data, palette = \"Set1\")\ng.set_xticklabels(g.get_xticklabels(), rotation=90, ha=\"right\")\ng \nplt.title('locality',size = 20)","12a9500b":"rcParams['figure.figsize'] = 15,7\ng = sns.countplot(x=\"rest_type\",data=data, palette = \"Set1\")\ng.set_xticklabels(g.get_xticklabels(), rotation=90, ha=\"right\")\ng \nplt.title('rest_type',size = 20)","a5e8a8c0":"plt.rcParams['figure.figsize'] = (3, 4)\nplt.style.use('_classic_test')\n\nX['online_order'].value_counts().plot.bar(color = 'cyan')\nplt.title('Online orders', fontsize = 20)\nplt.ylabel('Number of orders', fontsize = 15)\nplt.show()","53ea1bd4":"# X[['online_order','rate']].groupby(['rate']).sum(axis=0)\nplt.rcParams['figure.figsize'] = (15, 9)\nx = pd.crosstab(X['rate'], X['online_order'])\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True,color=['red','yellow'])\nplt.title('online order vs rate', fontweight = 30, fontsize = 20)\nplt.legend(loc=\"upper right\")\nplt.show()","2f95775a":"plt.rcParams['figure.figsize'] = (7, 9)\nplt.style.use('_classic_test')\n\nX['book_table'].value_counts().plot.bar(color = 'cyan')\nplt.title('Table booking', fontsize = 20)\nplt.ylabel('Number of bookings', fontsize = 15)\nplt.show()","ce852f30":"plt.rcParams['figure.figsize'] = (15, 9)\nx = pd.crosstab(X['rate'], X['book_table'])\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True,color=['red','yellow'])\nplt.title('table booking vs rate', fontweight = 30, fontsize = 20)\nplt.legend(loc=\"upper right\")\nplt.show()","2d7101b8":"X.head()\nX.average_cost = X.average_cost.apply(lambda x: x.replace(',',''))\nX.average_cost = X.average_cost.astype(int)\nfig, ax = plt.subplots(figsize=[16,4])\nsns.distplot(X['average_cost'],ax=ax)\nax.set_title('Cost Distrubution for all restaurants')","8a16653b":"restaurantTypeCount=data['restaurant_type'].value_counts().sort_values(ascending=True)\nslices=[restaurantTypeCount[0],\n        restaurantTypeCount[1],\n        restaurantTypeCount[2],\n        restaurantTypeCount[3],\n        restaurantTypeCount[4],\n        restaurantTypeCount[5],\n        restaurantTypeCount[6]]\nlabels=['Pubs and bars','Buffet','Drinks & nightlife','Cafes','Desserts','Dine-out','Delivery ']\ncolors = ['#3333cc','#ffff1a','#ff3333','#c2c2d6','#6699ff','#c4ff4d','#339933']\nplt.pie(slices,colors=colors, labels=labels, autopct='%1.0f%%', pctdistance=.5, labeldistance=1.2,shadow=True)\nfig = plt.gcf()\nplt.title(\"Percentage of Restaurants according to their Type\", bbox={'facecolor':'2', 'pad':5})\n\nfig.set_size_inches(12,12)\nplt.show()","27ee5839":"# X.average_cost.describe()\n# maxi=X.average_cost.max()\n# mean=X.rate.mean()\n# print(mean)\nX= X.drop_duplicates(subset='name',keep='first')\n# dups_name = X1.pivot_table(index=['name'],aggfunc='size')\nnewdf=X[['name','average_cost','locality','rest_type','cuisines']].groupby(['average_cost'], sort = True)\nnewdf=newdf.filter(lambda x: x.mean() <= 1500)\nnewdf=newdf.sort_values(by=['average_cost'])\n\nnewdf_expensive=X[['name','average_cost','locality','rest_type','cuisines']].groupby(['average_cost'], sort = True)\nnewdf_expensive=newdf_expensive.filter(lambda x: x.mean() >= 3000)\nnewdf_expensive=newdf_expensive.sort_values(by=['average_cost'])\n# newdf","8f094fd0":"newdf_rate=X[['name','rate']].groupby(['rate'], sort = True)\nnewdf_rate=newdf_rate.filter(lambda x: x.mean() >= 4.5)\nnewdf_rate=newdf_rate.sort_values(by=['rate'])\nX.rate.value_counts()\nX.rate.unique()\nX.nunique()\n# newdf_rate","fd045d28":"s1 = pd.merge(newdf, newdf_rate, how='inner', on=['name'])\n\ns2= pd.merge(newdf_expensive, newdf_rate, how='inner', on=['name'])\n\nprint(\"Cheap restaurants with low cost,high rating \\n\")\ns1","7aba2654":"print(\"Expensive restaurants with high cost,high rating \\n\")\ns2","96677a2d":"# X1.votes.describe()\nnewdf_votes=X[['name','votes']].groupby(['votes'], sort = True)\nnewdf_votes=newdf_votes.filter(lambda x: x.mean() >= 175)\nnewdf_votes=newdf_votes.sort_values(by=['votes'])\n# newdf_votes","83804de3":"s = pd.merge(s1, newdf_votes, how='inner', on=['name'])\ns=s.sort_values(by=['average_cost'])\nprint(\"Cheap restaurants,high rating,high votes\")\ns","96474309":"s = pd.merge(s2, newdf_votes, how='inner', on=['name'])\ns=s.sort_values(by=['average_cost'])\ns","9afac061":"* Also, observe that these cheaper options (cost<500) are all either **Quick Bites, Cafe or Dessert Parlour**.\n* **Casual Dining restaurants** start above 600\n* 6 out of 10 of the cheapest restaurants serve **South Indian Cuisine**\n* As for the **location**, these cheap restaurant option are **scattered and not localised** to any specific location of the city.","a0c7d8f9":"### Restaurant type distribution plot","3f13188b":"#### First step will be to find the restaurants with average cost 1\/4th the average cost of most expensive restaurant in our dataframe.\n\n\n*Let me explain:-*\nThe most **expensive** restaurant has an average meal cost= **6000**. We'll try to stay economical and only pick the restaurants that are** 1\/4th of 6000.**\n*Uncomment the comments in code below to get a clearer idea !*","77fa1633":"*You are more likely to receive a higher rating if your restaurant offers* **online order** *option.*","b9e8e0d8":"* If you look closely at each column of the dataframe closely you will notice that there are some columns that won't contribute to the ratings and reviews. The **url** or the full **address** of the restaurant or their **phone number** can't justify their ratings or reviews.\n* Note that only the address column is omitted from the dataframe and not the listed_in(city) column,because location details in listed_in(city) column can be very useful in extracting the information about the restaurants.\n* Also,location and listed_in(city) are the same columns.So, we **drop the location column**.\n* The names of columns are a bit non descriptive and confusing so its better to **rename** some of these columns.","7b0db305":"\n\n*You can say that you have the table booking option for Highly rated restaurants.*\n\n\n","0273df37":"#### Best restaurant options under 500 Rupees (average cost):-\n* **Brahmin's Coffee Bar** with average cost=100 and rating=4.8 and votes=2679\n* **CTR**  with average cost=150 and rating=4.7 and votes=4408\n* **Veena Stores** with average cost=150 and rating=4.5 and votes=2407\n* **O.G. Variar & Sons** with average cost=200 and rating=4.8 and votes=1156\n* **Mavalli Tiffin Room (MTR)** with average cost=250 and rating=4.5 and votes=2896\n* **Belgian Waffle Factory** with average cost=400 and rating=4.9 and votes=1746\n","c4cdc133":"## Breakdown of this notebook:\n1. **Loading the dataset**: Load the data and import the libraries.\n1. **Data Cleaning**: \n     * Deleting redundant columns.\n     * Renaming the columns.\n     * Dropping duplicates.\n     * Cleaning individual columns.\n1. **Data Visualization:** Using plots to find relations between the features.\n1. **Finding the best cheap restaurants:** \n      * **Cheapest, Highest rated and largely voted**.\n      * Is there a **relation** between **cuisine,location and the cost**?\n1. **Exploring the best expensive restaurants.**\n      * Restaurants that are **expensive, Highest rated and largely voted**.\n      * Is there a **relation** between **restaurant type,location and the cost**?\n","0a28ad2f":"### Data Visualization","735e36db":"## We can also explore the expensive options :-\n\nHere, we are only picking up the restaurants that **cost more than** **3000**(half of most expensive restaurant) and are highest rated , have large votes.","5281f8a5":"## Please upvote and feel free to give any feedback\/comment below!!","d1d3be8c":"### Find the most reliable restaurants: \n**Voted more the mean number of votes:- 175**  \n*Uncomment the last line in code below to get a clearer idea*","a35e484e":"**Now, we'll merge both the dataframes obtained above to get the intersection of both  i.e the highest rated and cheapest restaurants !!**","0021a9a3":"## Finding the best restaurants:-\n### The criteria for best restaurants would be  \n* **cheapest**,  \n* **highly rated**, \n* **reliable**(large number of votes) options.","1f558f5b":"## These are the most reliable, highest rated and economical restaurants:- \n\nWe obtain this dataframe by simply taking the intersection of all the dataframes obtained above.\n\n\nThis dataframe obtained below shows the restaurants whose:\n* Cost is below **1500**\n* Rating is above **4.5**\n* Votes are above **175**","ad6ea16d":"#### Other findings:-","2b77005d":"### Cost distribution of all the restaurants in City","cd3de93e":"### Is there a relation between online order option and rating of the restaurant?","d3b6ad75":"\n\n*No surprises there!!*\n\n**The Oberoi Hotel, Karavalli and JW Marriott** make this high profile list\n\nInterestingly, all these restaurants have the **same location**- **Brigade Road**  and **same restaurant type**- **Fine dining**","23ab9b9e":"**Now lets find the highest rated restaurants i.e rating above 4.5**\n*Uncomment the last line in code below to get a clearer idea*","5a6f3ca2":"As you can see the rate column is string type with an extra \/5 with all the ratings. This should be cleaned.It is important to convert the string back to float !!","e27d3c7d":"#### Are the locations of restaurants localised to specific parts of city?","0373ef5a":"### Is there a relation between table booking option and rating of the restaurant?"}}