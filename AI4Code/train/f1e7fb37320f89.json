{"cell_type":{"94cd16d5":"code","aa10822e":"code","db6f8e30":"code","e0266891":"code","b9c88bc7":"code","0fda2e32":"code","310a302c":"code","a3e89e31":"code","b7b3bca4":"code","e988b8a4":"code","7e81c4ea":"code","04726328":"code","da88adc5":"code","1d42ab59":"code","a0972263":"code","4b977e00":"code","b2fe6459":"code","21c8b270":"code","3a9904e2":"code","d5af721b":"code","53511a06":"code","5d79cf93":"code","6c9f64fe":"code","899156dc":"code","40e6e8a6":"code","8256f8b6":"code","06e7769f":"code","c8302cf6":"code","09146f4f":"code","9a24bbae":"code","363cf46c":"code","a83f34ef":"code","34d325eb":"code","b66bd558":"code","c98c4b00":"code","7516e809":"code","0fd990ee":"code","859fb1a3":"code","1caba633":"code","d6ff7aa6":"code","362362fc":"code","f2fc94a2":"code","b4b98669":"code","6af9752f":"code","b65bba1a":"code","56b19d6c":"code","059dddfa":"code","fb1c84a3":"code","e5ee9ac0":"code","88e1d193":"code","1133b814":"code","1f3d7a38":"code","7900cb7d":"code","0d1e0ccb":"code","fe911b51":"code","d758d11e":"code","c47d5e87":"code","7067fd2a":"code","22f2b563":"code","08a51bc9":"markdown","0594672c":"markdown","25ef302e":"markdown","1dd62e97":"markdown","04d8a736":"markdown","97049b66":"markdown","5c98c914":"markdown","32cf1865":"markdown","dff5c4d9":"markdown","78c67217":"markdown","a0511e8b":"markdown","4d8e55ec":"markdown","8f450d55":"markdown","07a44326":"markdown","bf94182c":"markdown","46ef0611":"markdown","dad97f82":"markdown","95c28e46":"markdown","2e117e75":"markdown","5270a459":"markdown","129cefa3":"markdown","c681cb4a":"markdown","20263662":"markdown","5f2b2d84":"markdown","c1c82681":"markdown","3487ac6e":"markdown","9182aafd":"markdown","6104d4d1":"markdown","982e9d13":"markdown","442dbfe8":"markdown","da68b518":"markdown","bb6997f0":"markdown","9f1d9f99":"markdown"},"source":{"94cd16d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.\n\n# Python libraries\n# Classic,data manipulation and linear algebra\nimport pandas as pd\nimport numpy as np\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\nimport squarify\n\n# Data processing, metrics and modeling\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix,  roc_curve, precision_recall_curve, accuracy_score, roc_auc_score\nimport lightgbm as lgbm\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_predict\nfrom yellowbrick.classifier import DiscriminationThreshold\n\n# Stats\nimport scipy.stats as ss\nfrom scipy import interp\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\n\n# Time\nfrom contextlib import contextmanager\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') \n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa10822e":"data = pd.read_csv(\"..\/input\/superheroes-nlp-dataset\/superheroes_nlp_dataset.csv\")\ndata.head(2)","db6f8e30":"display(data.info(),data.head())","e0266891":"data['name'] = data['name'].astype(str)\ndata['real_name'] = data['real_name'].astype(str)\ndata['full_name'] = data['full_name'].astype(str)\ndata['history_text'] = data['history_text'].astype(str)\ndata['powers_text'] = data['powers_text'].astype(str)","b9c88bc7":"# 2 datasets\nD = data[(data['creator'] == \"DC Comics\")]\nM = data[(data['creator'] == \"Marvel Comics\")]\ndata['creator'].loc[(data['creator']!=\"DC Comics\") & (data['creator']!=\"Marvel Comics\")]  = \"Others\"\n\n\n#------------COUNT-----------------------\ndef creator_count():\n    trace = go.Bar( x = data['creator'].value_counts().values.tolist(), \n                    y = ['Marvel Comics','DC Comics', 'Others'],\n                    orientation = 'h', \n                    text=data['creator'].value_counts().values.tolist(), \n                    textfont=dict(size=15),\n                    textposition = 'auto',\n                    opacity = 0.8,marker=dict(\n                    color=['red', 'blue','orchid'],\n                    line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  'Count of Creator of Superheroes')\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)\n\ndef creator_percent():\n    trace = go.Pie(labels = ['Marvel Comics','DC Comics', 'Others'], values = data['creator'].value_counts(), \n                   textfont=dict(size=15), opacity = 0.8,\n                   marker=dict(colors=['red', 'blue','orchid'], \n                               line=dict(color='#000000', width=1.5)))\n\n\n    layout = dict(title =  'Distribution of Creator of Superheroes')\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)","0fda2e32":"creator_count()\ncreator_percent()","310a302c":"# 2 datasets\nM = data[(data['gender'] == \"Male\")]\nW = data[(data['gender'] == \"Female\")]\n\n#------------COUNT-----------------------\ndef gender_count():\n    trace = go.Bar( x = data['gender'].value_counts().values.tolist(), \n                    y = ['Male','Female' ], \n                    orientation = 'h', \n                    text=data['gender'].value_counts().values.tolist(), \n                    textfont=dict(size=15),\n                    textposition = 'auto',\n                    opacity = 0.8,marker=dict(\n                    color=['gold', 'deeppink'],\n                    line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  'Count of Gender of Superheroes')\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)\n\n#------------PERCENTAGE-------------------\ndef gender_percent():\n    trace = go.Pie(labels = ['Male','Female'], values = data['gender'].value_counts(), \n                   textfont=dict(size=15), opacity = 0.8,\n                   marker=dict(colors=['gold', 'deeppink'], \n                               line=dict(color='#000000', width=1.5)))\n\n\n    layout = dict(title =  'Distribution of Gender of Superheroes')\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)","a3e89e31":"gender_count()\ngender_percent()","b7b3bca4":"W.sort_values('overall_score',ascending=False).head(10)","e988b8a4":"superpowers = data.loc[:, data.columns.str.startswith('has')].dropna()\nsuperpowers.columns = superpowers.columns.str.replace(r'has_', '')\nsuperpowers = superpowers.T.reset_index()\nsuperpowers['Total'] = superpowers.sum(axis=1)\nsuperpowers = superpowers.sort_values('Total',ascending=False)\nsuperpowers.head(1)","7e81c4ea":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.barplot(x=superpowers['index'], y=superpowers['Total'], data=superpowers)\nf.set_xlabel(\"Name of Superpower\",fontsize=18)\nf.set_ylabel(\"No. of Superheroes with Superpower\",fontsize=18)\nf.set_title('Superpowers')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","04726328":"data_x = data[['intelligence_score','strength_score','speed_score','durability_score','power_score','combat_score']]","da88adc5":"plt.style.use('ggplot') # Using ggplot2 style visuals \n\nf, ax = plt.subplots(figsize=(11, 15))\n\nax.set_facecolor('#fafafa')\nax.set(xlim=(-.05, 200))\nplt.ylabel('Variables')\nplt.title(\"Overview  of the Power Scores\")\nax = sns.boxplot(data = data_x, \n  orient = 'h', \n  palette = 'Set2')","1d42ab59":"def correlation_plot():\n    #correlation\n    correlation = data_x.corr()\n    #tick labels\n    matrix_cols = correlation.columns.tolist()\n    #convert to array\n    corr_array  = np.array(correlation)\n    trace = go.Heatmap(z = corr_array,\n                       x = matrix_cols,\n                       y = matrix_cols,\n                       colorscale='Viridis',\n                       colorbar   = dict() ,\n                      )\n    layout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                            #autosize = False,\n                            #height  = 1400,\n                            #width   = 1600,\n                            margin  = dict(r = 0 ,l = 100,\n                                           t = 0,b = 100,\n                                         ),\n                            yaxis   = dict(tickfont = dict(size = 9)),\n                            xaxis   = dict(tickfont = dict(size = 9)),\n                           )\n                      )\n    fig = go.Figure(data = [trace],layout = layout)\n    py.iplot(fig)","a0972263":"correlation_plot()","4b977e00":"data_y = data.drop(['overall_score','intelligence_score','strength_score','speed_score','durability_score','power_score','combat_score'],axis=1)\ndata.loc[:, 'total_superpowers'] = data_y.iloc[:, 1:].sum(axis=1)","b2fe6459":"data_powers_alignment=data[['name','total_superpowers','alignment','creator']].sort_values('total_superpowers',ascending=False)\ndata_powers_alignment.head(1)","21c8b270":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.barplot(x=data_powers_alignment[\"name\"].head(30), y=data_powers_alignment['total_superpowers'].head(30), data=data_powers_alignment)\nf.set_xlabel(\"Name of Superhero\",fontsize=18)\nf.set_ylabel(\"No. of Superpowers\",fontsize=18)\nf.set_title('Top 30 Superheroes having highest no. powers')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","3a9904e2":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.swarmplot(x=data_powers_alignment[\"creator\"], y=data_powers_alignment['total_superpowers'],hue=data_powers_alignment[\"alignment\"],data=data_powers_alignment)\nf.set_xlabel(\"Comics\",fontsize=18)\nf.set_ylabel(\"No. of Superpowers\",fontsize=18)\nf.set_title('Distirbution of Good\/Bad Superheroes, their creators and their Superpower')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","d5af721b":"data_powers_marvel = data_powers_alignment.loc[data_powers_alignment['creator'] == \"Marvel Comics\"]\n\n\nplt.style.use('ggplot') # Using ggplot2 style visuals\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.barplot(x=data_powers_marvel[\"name\"].head(30), y=data_powers_marvel['total_superpowers'].head(30), data=data_powers_marvel)\nf.set_xlabel(\"Name of Superhero\",fontsize=18)\nf.set_ylabel(\"No. of Superpowers\",fontsize=18)\nf.set_title('Top 30 Superheroes from Marvel Comics having highest no. powers')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","53511a06":"data_powers_dc = data_powers_alignment.loc[data_powers_alignment['creator'] == \"DC Comics\"]\n\n\nplt.style.use('ggplot') # Using ggplot2 style visuals\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.barplot(x=data_powers_dc[\"name\"].head(30), y=data_powers_dc['total_superpowers'].head(30), data=data_powers_dc)\nf.set_xlabel(\"Name of Superhero\",fontsize=18)\nf.set_ylabel(\"No. of Superpowers\",fontsize=18)\nf.set_title('Top 30 Superheroes from DC Comics having highest no. powers')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","5d79cf93":"data['total_score'] = data['intelligence_score'] + data['strength_score'] + data['speed_score'] + data['durability_score'] + data['power_score']+data['combat_score']","6c9f64fe":"data.sort_values(['overall_score','total_score','total_superpowers'], ascending=[False,False, False]).head(1)","899156dc":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.swarmplot(x=data[\"creator\"], y=data['total_score'],hue=data[\"alignment\"],data=data)\nf.set_xlabel(\"Comics\",fontsize=18)\nf.set_ylabel(\"Total Power Score\",fontsize=18)\nf.set_title('Distirbution of Good\/Bad Superheroes, their creators and their Superpower Score')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","40e6e8a6":"data_good = data.sort_values(['overall_score', 'total_superpowers'], ascending=[False, False])\ndata_good.loc[data_good['alignment'] == 'Good'].head(1)","8256f8b6":"data_good[(data_good['alignment'] == 'Good')&(data_good['creator'] == 'Marvel Comics')].dropna().head(1)","06e7769f":"data_good[(data_good['alignment'] == 'Good')&(data_good['creator'] == 'DC Comics')].dropna().head(1)","c8302cf6":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf = sns.countplot(x=data[\"type_race\"], data=data, order=data.type_race.value_counts().index)\nf.set_xlabel(\"Race of Superhero\",fontsize=18)\nf.set_ylabel(\"No. of Superheroes\",fontsize=18)\nf.set_title('Race of the Superheroes')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","09146f4f":"top_race = data.type_race.value_counts().head(15)\nprint(top_race)","9a24bbae":"top_race_names = ['Human','Mutant','God \/ Eternal','Metahuman','Alien','Animal','Demon','Android','Human \/ Radiation','Cyborg','Asgardian','Inhuman','Kryptonian','Demi-God','New God']\ndata_race = data[data['type_race'].isin(top_race_names)]","363cf46c":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.barplot(x=data_race[\"type_race\"],y=data_race[\"total_superpowers\"],data=data_race,order=data_race.type_race.value_counts().index )\nf.set_xlabel(\"Race of Superhero\",fontsize=18)\nf.set_ylabel(\"No. of Superpowers\",fontsize=18)\nf.set_title('Most Common Races v\/s Number of Powers of a Superhero')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","a83f34ef":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.barplot(x=data_race[\"type_race\"],y=data_race[\"total_score\"],data=data_race,order=data_race.type_race.value_counts().index )\nf.set_xlabel(\"Race of Superhero\",fontsize=18)\nf.set_ylabel(\"Total Power Score\",fontsize=18)\nf.set_title('Most Common Races v\/s Total Power Score of a Superhero')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","34d325eb":"data_race = data.groupby(['type_race'])['total_score'].mean().to_frame(name = 'mean_power_score').reset_index()\ndata_race = data_race.sort_values(by='mean_power_score', ascending=False)\ndata_race.head(5)","b66bd558":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.barplot(x=data_race[\"type_race\"],y=data_race[\"mean_power_score\"],data=data_race )\nf.set_xlabel(\"Race of Superhero\",fontsize=18)\nf.set_ylabel(\"Average Power Score\",fontsize=18)\nf.set_title('Most Powerful Races of Superheroes (based on powerscores)')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","c98c4b00":"data_race = data.groupby(['type_race'])['total_superpowers'].mean().to_frame(name = 'mean_power_list').reset_index()\ndata_race = data_race.sort_values(by='mean_power_list', ascending=False)\ndata_race.head(5)","7516e809":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\n\nsns.set_context(\"paper\", font_scale=1.5)\nf=sns.barplot(x=data_race[\"type_race\"],y=data_race[\"mean_power_list\"],data=data_race )\nf.set_xlabel(\"Race of Superhero\",fontsize=18)\nf.set_ylabel(\"Average Number of Powers\",fontsize=18)\nf.set_title('Most Powerful Races of Superheroes (based on number of superpowers)')\nfor item in f.get_xticklabels():\n    item.set_rotation(90)","0fd990ee":"import spacy\nfrom collections import Counter\n\ndef history_text_processing(history_text):\n    frequency = {}\n    list_of_entities = []\n    listofmax = []\n    most_common_key = \" \"\n    max_key = \"null\"\n    nlp = spacy.load(\"en_core_web_sm\")\n    doc = nlp(history_text)\n\n    for ent in doc.ents:\n        list_of_entities.append(str(ent.text))\n    \n    list = list_of_entities\n    \n    \n    \n    for item in list:\n       if (item in frequency):\n          frequency[item] += 1\n       else:\n          frequency[item] = 1\n\n    if len(frequency) != 0:\n        max_value = max(frequency.values())  # maximum value\n        max_key = max(frequency, key=frequency.get) # getting key containing the `maximum`\n    \n    k = Counter(frequency)\n    # Finding 3 highest values\n    high = k.most_common(3)\n    empty = []\n    \n    for i in high:\n        empty.append(i[0])\n    \n    most_common = \" \".join(empty)\n    \n    return str(most_common)","859fb1a3":"from tqdm.auto import tqdm\ntqdm.pandas()\n\ndata['name_entity'] = data['history_text'].progress_apply(lambda x:history_text_processing(str(x)) if x != None else x )\n    ","1caba633":"data.head(1)","d6ff7aa6":"from difflib import SequenceMatcher\ndef similiarity_ratio(row,col1,col2):\n    return SequenceMatcher(None, row[col1].lower(), row[col2].lower()).ratio() \n","362362fc":"data['name_match'] = data.apply(lambda x:similiarity_ratio(x,col1='name_entity',col2='name'),axis=1)","f2fc94a2":"print(\"Mean of the name_match :\" + str(data['name_match'].mean()))\nsum_of_name_match = (data['name_match'] > 0).values.sum()\npercentage_matched = (sum_of_name_match\/len(data))*100\nprint(\"Number of of name entites which has a match is in names  :\" + str(sum_of_name_match))\nprint(\"Percentage of name entites which has a match is in names :\" + str(percentage_matched))","b4b98669":"plt.style.use('ggplot') # Using ggplot2 style visuals\n\nfig, ax = plt.subplots()\n\nfig.set_size_inches(20, 10)\ncolors = ['#FFD700', '#7EC0EE']\n\nsns.set_context(\"paper\", font_scale=1.5)\nf = sns.distplot(data['name_match'], kde=True);\nf.set_xlabel(\"Similarity Score\",fontsize=18)\nf.set_title('Distribution of Similarity Scores based Superhero name and Prediction')","6af9752f":"data_text = data[['history_text', 'creator']]\n#we will only select comics by Marvel or DC as there's too many comic creators\ndata_text = data_text.loc[data_text['creator'].isin(['Marvel Comics','DC Comics'])]\ndata_text.head(1)","b65bba1a":"# Importing necessary libraries\nimport string,re\nimport nltk\nimport gc\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nlemmatiser = WordNetLemmatizer()\n# Defining modules for Text Processing\n\nfrom nltk.corpus import stopwords\n\", \".join(stopwords.words('english'))\nstopwords_list = set(stopwords.words('english'))\n\n\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '\/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '\u2022',  '~', '@', '\u00a3', \n '\u00b7', '_', '{', '}', '\u00a9', '^', '\u00ae', '`',  '<', '\u2192', '\u00b0', '\u20ac', '\u2122', '\u203a',  '\u2665', '\u2190', '\u00d7', '\u00a7', '\u2033', '\u2032', '\u00c2', '\u2588', '\u00bd', '\u00e0', '\u2026', \n '\u201c', '\u2605', '\u201d', '\u2013', '\u25cf', '\u00e2', '\u25ba', '\u2212', '\u00a2', '\u00b2', '\u00ac', '\u2591', '\u00b6', '\u2191', '\u00b1', '\u00bf', '\u25be', '\u2550', '\u00a6', '\u2551', '\u2015', '\u00a5', '\u2593', '\u2014', '\u2039', '\u2500', \n '\u2592', '\uff1a', '\u00bc', '\u2295', '\u25bc', '\u25aa', '\u2020', '\u25a0', '\u2019', '\u2580', '\u00a8', '\u2584', '\u266b', '\u2606', '\u00e9', '\u00af', '\u2666', '\u00a4', '\u25b2', '\u00e8', '\u00b8', '\u00be', '\u00c3', '\u22c5', '\u2018', '\u221e', \n '\u2219', '\uff09', '\u2193', '\u3001', '\u2502', '\uff08', '\u00bb', '\uff0c', '\u266a', '\u2569', '\u255a', '\u00b3', '\u30fb', '\u2566', '\u2563', '\u2554', '\u2557', '\u25ac', '\u2764', '\u00ef', '\u00d8', '\u00b9', '\u2264', '\u2021', '\u221a', ]\n\ndef clean_text(x):\n    x = str(x)\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x\n\ndef remove_stopwords(text):\n    return \" \".join([word for word in str(text).split() if word not in stopwords_list])\n\ndef stem_text(text):    \n    lemma = nltk.wordnet.WordNetLemmatizer()\n    class FasterStemmer(object):\n        def __init__(self):\n            self.words = {}\n\n        def stem(self, x):\n            if x in self.words:\n                return self.words[x]\n            t = lemma.lemmatize(x)\n            self.words[x] = t\n            return t\n    faster_stemmer = FasterStemmer()\n    text = text.split()\n    stemmed_words = [faster_stemmer.stem(word) for word in text]\n    text = \" \".join(stemmed_words)\n    del faster_stemmer\n    gc.collect\n    return text","56b19d6c":"data_text['history_text'] = data_text['history_text'].progress_apply(lambda x: x.lower())\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: clean_text(x))\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: clean_numbers(x))\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: remove_stopwords(x))\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: stem_text(x))   ","059dddfa":"data_text.head(1)","fb1c84a3":"# Importing necessary libraries\nfrom sklearn.preprocessing import LabelEncoder\ny = data_text['creator']\nlabelencoder = LabelEncoder()\ny = labelencoder.fit_transform(y)\nX = data_text['history_text']","e5ee9ac0":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n# 80-20 splitting the dataset \nX_train, X_test, y_train, y_test = train_test_split(X, y\n                                  ,test_size=0.35, random_state=1234)\n# defining the bag-of-words transformer on the text-processed corpus \nbow_transformer=CountVectorizer(analyzer='word').fit(X_train)\n# transforming into Bag-of-Words and hence textual data to numeric..\ntext_bow_train=bow_transformer.transform(X_train)\n# transforming into Bag-of-Words and hence textual data to numeric..\ntext_bow_test=bow_transformer.transform(X_test)","88e1d193":"from sklearn.linear_model import LogisticRegression\n# instantiating the model with simple Logistic Regression..\nmodel = LogisticRegression()\n# training the model...\nmodel = model.fit(text_bow_train, y_train)","1133b814":"model.score(text_bow_train, y_train)","1f3d7a38":"model.score(text_bow_test, y_test)","7900cb7d":"target_names = ['Marvel', 'DC']\n\nfrom sklearn.metrics import classification_report\n \n# getting the predictions of the Validation Set...\npredictions = model.predict(text_bow_test)\n# getting the Precision, Recall, F1-Score\nprint(classification_report(y_test,predictions,target_names=target_names))","0d1e0ccb":"data_text = data[['history_text', 'creator']]\n#we will only select comics by Marvel or DC as there's too many comic creators\ndata_text = data_text.loc[data_text['creator'].isin(['Marvel Comics','DC Comics'])]\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: x.lower())\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: clean_text(x))\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: clean_numbers(x))\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: remove_stopwords(x))\ndata_text['history_text'] = data_text['history_text'].progress_apply(lambda x: stem_text(x))   \n","fe911b51":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(stop_words='english', analyzer='word', strip_accents='unicode', sublinear_tf=True,\n                           token_pattern=r'\\w{1,}', max_features=10000, ngram_range=(1,2))\ntfidf.fit(data_text.history_text);","d758d11e":"features = tfidf.transform(data_text.history_text)","c47d5e87":"from sklearn import model_selection, preprocessing\n# split the dataset into training and validation datasets\ntrain_x, valid_x, train_y, valid_y = model_selection.train_test_split(data_text.history_text, data_text.creator, test_size=0.30, random_state=1)\n\n# label encode the target variable\nencoder = preprocessing.LabelEncoder()\ntrain_y = encoder.fit_transform(train_y)\nvalid_y = encoder.fit_transform(valid_y)","7067fd2a":"xtrain_tfidf =  tfidf.transform(train_x)\nxvalid_tfidf =  tfidf.transform(valid_x)","22f2b563":"from sklearn import metrics, linear_model, naive_bayes, metrics, svm, ensemble\ndef train_model(classifier, trains, t_labels, valids, v_labels):\n    # fit the training dataset on the classifier\n    classifier.fit(trains, t_labels)\n\n    # predict the labels on validation dataset\n    predictions = classifier.predict(valids)\n    target_names = ['Marvel', 'DC']\n    print(metrics.classification_report(v_labels, predictions,target_names=target_names))\n    return metrics.accuracy_score(predictions, v_labels)\n# Naive Bayes\nprint (\"Naive Bayes\")\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y);\nprint (\"Accuracy: \", accuracy)\n# Logistic Regression\nprint (\"Logistic Regression\")\naccuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y);\nprint (\"Accuracy: \", accuracy)\n# SVM\nprint (\"SVM\")\naccuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y);\nprint (\"Accuracy: \", accuracy)\n# Random Forest\nprint (\"Random Forest\")\naccuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y)\nprint (\"Accuracy: \", accuracy )","08a51bc9":"In this problem, we will use Bag-of-Words Technique of Feature Engineering.(BoW works well for small datasets)","0594672c":"#### **Creators of Superheroes**\n\n* **615 (42.4%)** of the superheroes are from **Marvel Comics**\n* **444 (30.6%)** of the superheroes are from **DC Comics** \n* **391 (27%)** of the superheroes are from other comics.\n","25ef302e":"## Who is the strongest superhero of all time ? ##\n\nIt's bit tricky, but let's try to find it based on overall score, number of powers and total score.","1dd62e97":"**Black Alice** is the strongest Good Superhero.","04d8a736":"Finding similarity between the top name entities obtained from each history_text and superhero name.","97049b66":"## Who are the top 10 Woman Superheroes? ##","5c98c914":"**God\/Eternal**, **Demon**, **Cosmic Entity** are the ones with highest total power scores.\nWhen it comes to **Humans** v\/s **Mutants**, it's a close call.\n\n\n\n## Most powerful Races ##\n\n#### Based on Total Power Score ####","32cf1865":"* Mean of the name_match = **Mean of similarity scores of the predictions.**\n* Number of of name entites which has a match is in names = **Number of predictions which matched with Superhero's name.**\n* Percentage of name entites which has a match is in names = **Percentage of predictions which matched with Superhero's name.**","dff5c4d9":"#### Surprise !!! The Golden Master is the superhero with most number of powers ####\n\nThe Golden Master is an ancient figure of evil linked to a Serpentine prophecy; it is said that the Golden Master will obtain all of the powers of the First Spinjitzu Master and will try to bring about a new dawn of the world, enslaving every man, woman, and Serpentine for all eternity.\n\nDuring the Nindroid conflict, the Ninja initially believed Lloyd was to become the Golden Master, but they eventually discovered The Overlord wanted to earn the title with the help of Pythor. The Overlord would steal Lloyd's Golden Power and forge a massive suit of armor and mech using the Golden Weapons, thus becoming the Golden Master. [SuperheroDB](https:\/\/www.superherodb.com\/the-golden-master\/10-16461\/)","78c67217":"**Bag of Words** model performs extremely well.","a0511e8b":"Another Surprise, \"**The Golden Master**\" is the strongest superhero of all time.\n\nLet's find out who is the strongest \"Good\" superhero,","4d8e55ec":"1. Man of Miracles\n2. Death Of The Endless\t\n3. Melinda May\n4. Gamora\n5. Rogue\n6. Bloodaxe\n7. Mercy Graves\n8. Batgirl\n9. Catwoman\n10. Harumi\n\n**The Man of Miracles** (Mother of Existence or M.O.M. for short) leads the list, is a fictional, ageless, mysterious, gender-less, super-being, featured in the Spawn comic book series. It's wrongly classified as \"Female\" as it is genderless. ","8f450d55":"**Abin Sur** is the strongest Good Superhero from DC.","07a44326":"**Eternal**,**God\/Eternal** and **Demon** are the races with most number of superpowers. None of the human superheroes has more than 10 superpowers.\n\n","bf94182c":"Cool ! The scores are excellent for such a small dataset.","46ef0611":"As this is a classification problem, here classes are the 3 creators as mentioned. But in the dataset, it can be seen that labels are non-numeric (MC and DC). These are label encoded to make them numeric, starting from 0 depicting each label in the alphabetic order i.e., (0 \u2192 MC, 1 \u2192 DC)","dad97f82":"## Most Common Superpowers ##\n\nMost Common Superpower is **Agility**","95c28e46":"## Can we predict Comics Creator using history text ? ##\n\nWe will use NLTK (Natural Language Took Kit) and Scikit-Learn.","2e117e75":"#### Based on total number of super powers ####","5270a459":"**Gamora** is the strongest Good Superhero from Marvel.","129cefa3":"### Creators of Superhero - Marvel v\/s DC ###","c681cb4a":"**Gods and Extra Terrestial Superheroes** are the ones with most number of powers or more power scores.","20263662":"The process we are following here is using Name Entity Recognition we are trying the determine the most used entity in the history text, and later try to match it with the name \/ real name \/ fullname of the superhero. For, the name entity recognition we are using the pre-built feature of Spacy.","5f2b2d84":"## Can we predict the name of Superhero from the history text ?##\n\nHere, we will attempt to predict the name of the superhero by performing NLP on the history texts.","c1c82681":"We can see, by using the NER technique we were able to detect the name of almost 92% of the superheroes. ","3487ac6e":"#### Most Common Races of Superheroes ####","9182aafd":"## Who has the Most Number of Powers ? ##\n\nHere, we determine the number of powers assigned to each superhero.","6104d4d1":"We will experiment with **TF-IDF**\n\nThe tfidf process produces a list of distinct vocabulary words. These words have the value that identifies the relevancy of words in the document. Here we use unigram and bigram,","982e9d13":"#### 10 Most Common Superpowers ####\n\n1. agility\n2. stamina\n3. super strength\n4. durability\n5. intelligence\n6. reflexes\n7. weapons_master\n8. super_speed\n9. marksmanship\n10. stealth","442dbfe8":"## Race and Power of the Superheroes ##","da68b518":"### Superheroes by Gender ###","bb6997f0":"* Removal of Punctuation \u2192 All the punctuation marks are removed from all the text-snippets (instances or documents) from the dataset (corpus).\n* Lemmatisation \u2192 Inflected forms of a word are known as lemma. For example, (studying, studied) are inflected forms or lemma of the word study which is the root word. So, the lemma of a word are grouped under the single root word. This is done to make the vocabulary of words in the corpus contain distinct words only.\n* Removal of Stopwords \u2192 Stop-words are usually articles (a, an, the), prepositions (in, on, under, \u2026) and other frequently occurring words that do not provide any key or necessary information. They are removed from all the text-snippets present in the dataset (corpus).","9f1d9f99":"Correlation between the powerscores"}}