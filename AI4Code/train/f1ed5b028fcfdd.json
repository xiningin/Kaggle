{"cell_type":{"d7e78ec6":"code","7e3edf18":"code","1fd880c6":"code","6998d27f":"code","5a04a5b4":"code","4fd3a72a":"code","f2bdebb6":"code","234659d4":"code","71f8cccb":"code","7efc32ca":"code","4b12f2ab":"code","9a7058a7":"code","14dd1c2a":"code","8425ba47":"code","ea9c2a0c":"code","20750c31":"code","ac09120b":"code","fcf80ed2":"code","7ab08c90":"code","285e9481":"code","5d72b9fc":"code","696e065d":"code","389c2551":"code","6e0bae1e":"code","55d421d0":"code","3aec22c3":"markdown","b43e0efa":"markdown","65551ca7":"markdown","283c803b":"markdown","35f7588a":"markdown","f55d32db":"markdown","ad6979c5":"markdown","3d85fb45":"markdown"},"source":{"d7e78ec6":"!pip install -U torchvision\n!pip install timm","7e3edf18":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1fd880c6":"import torch\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models","6998d27f":"torchvision.__version__, torch.__version__ # ('0.11.2+cu102', '1.10.1+cu102') or higher","5a04a5b4":"import matplotlib.pyplot as plt\nimport os\nimport sys\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","4fd3a72a":"from tqdm import tqdm\nimport time\nimport copy","f2bdebb6":"dataset_path = \"\/kaggle\/input\/fruits\/fruits-360_dataset\/fruits-360\/\"","234659d4":"def get_data_loaders(data_dir, batch_size=64, train = False):\n    if train:\n        transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomVerticalFlip(p=0.5),\n            transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(), \n                                                        transforms.GaussianBlur(3)]), p=0.1),\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n            transforms.RandomErasing(p=0.14, value='random')\n        ])\n        train_set = datasets.ImageFolder(os.path.join(data_dir, \"Training\/\"), transform=transform)\n        print(f\"Found {len(train_set)} images for training with {len(train_set.classes)} classes\")\n        train_data_len = int(len(train_set)*0.78)\n        valid_data_len = int((len(train_set) - train_data_len))\n        train_data, val_data = random_split(train_set, [train_data_len, valid_data_len])\n        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        return train_loader, val_loader, len(train_data), len(val_data)\n    \n    else:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n        test_data = datasets.ImageFolder(os.path.join(data_dir, \"Test\/\"), transform=transform)\n        print(f\"Found {len(test_data)} images for testing with {len(test_data.classes)} classes\")\n        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        return test_loader, len(test_data)","71f8cccb":"def get_classes(data_dir):\n    all_data = datasets.ImageFolder(data_dir)\n    return all_data.classes","7efc32ca":"classes = get_classes(os.path.join(dataset_path, \"Training\/\"))\nlen(classes)","4b12f2ab":"(train_loader, val_loader, train_data_len, valid_data_len) = get_data_loaders(dataset_path, 256, train=True)\n(test_loader, test_data_len) = get_data_loaders(dataset_path, 64, train=False)","9a7058a7":"dataloaders = {\n    \"train\":train_loader,\n    \"val\": val_loader\n}\ndataset_sizes = {\n    \"train\":train_data_len,\n    \"val\": valid_data_len\n}","14dd1c2a":"print(len(train_loader))\nprint(len(val_loader))\nprint(len(test_loader))","8425ba47":"print(train_data_len, test_data_len, valid_data_len)","ea9c2a0c":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, int(20\/2), idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(classes[labels[idx]])","20750c31":"import timm\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","ac09120b":"torch.backends.cudnn.benchmark = True # This will speed up training\nmodel = models.efficientnet_b0(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\nn_inputs = model.classifier[1].in_features\nmodel.classifier = nn.Sequential(\n    nn.Linear(n_inputs,2048),\n    nn.SiLU(),\n    nn.Dropout(0.2),\n    nn.Linear(2048, len(classes))\n)\n\nmodel = model.to(device)\nprint(model.classifier)","fcf80ed2":"criterion = nn.CrossEntropyLoss(label_smoothing=0.11)\ncriterion = criterion.to(device)\noptimizer = optim.AdamW(model.classifier.parameters(), lr=0.001)","7ab08c90":"exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)","285e9481":"training_history = {'accuracy':[],'loss':[]}\nvalidation_history = {'accuracy':[],'loss':[]}","5d72b9fc":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            \n            if phase == 'train':\n                training_history['accuracy'].append(epoch_acc)\n                training_history['loss'].append(epoch_loss)\n            elif phase == 'val':\n                validation_history['accuracy'].append(epoch_acc)\n                validation_history['loss'].append(epoch_loss)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","696e065d":"model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,\n                       num_epochs=2)","389c2551":"def test(model):\n  test_loss = 0.0\n  class_correct = list(0. for i in range(len(classes)))\n  class_total = list(0. for i in range(len(classes)))\n\n  model.eval()\n\n  for data, target in tqdm(test_loader):\n      if torch.cuda.is_available(): \n          data, target = data.cuda(), target.cuda()\n      with torch.no_grad():\n        output = model(data)\n        loss = criterion(output, target)\n      test_loss += loss.item()*data.size(0)\n      _, pred = torch.max(output, 1)    \n      correct_tensor = pred.eq(target.data.view_as(pred))\n      correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n      if len(target) == 64:\n        for i in range(64):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\n  test_loss = test_loss\/len(test_loader.dataset)\n  print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n  for i in range(len(classes)):\n      if class_total[i] > 0:\n          print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n              classes[i], 100 * class_correct[i] \/ class_total[i],\n              np.sum(class_correct[i]), np.sum(class_total[i])))\n      else:\n          print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\n  print('\\nTest Accuracy (Overall): {:.4f} ({}\/{})'.format(\n      100. * np.sum(class_correct) \/ np.sum(class_total),\n      np.sum(class_correct), np.sum(class_total)))","6e0bae1e":"test(model_ft)","55d421d0":"example = torch.rand(1, 3, 224, 224)\ntraced_script_module = torch.jit.trace(model_ft.cpu(), example)\ntraced_script_module.save(\"fruits-360-efficientnet_b0.zip\")","3aec22c3":"# Train EfficientNet on Fruits 360","b43e0efa":"We want to use the latest version of `torchvision`, Kaggle's current version of torchvision doesn't include EfficientNet, it was added in a later release","65551ca7":"## Save as torchscript model","283c803b":"## Model\n\nLoad `efficientnet_b0` from torchvision Models","35f7588a":"## Evaluation","f55d32db":"## Imports\n\nImport all necesssary libraries for this project","ad6979c5":"## Dataset","3d85fb45":"## Training"}}