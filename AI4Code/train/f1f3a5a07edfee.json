{"cell_type":{"c9a35691":"code","7b0e4c16":"code","ac05f0fb":"code","fd0c80a3":"code","11cec7b1":"code","f257ba42":"code","17b242a2":"code","da6293b9":"code","09670e46":"code","14258f5e":"code","eb8fca86":"code","b69f70ee":"code","4eebec63":"code","2f8d74f1":"code","33261af9":"code","30ad81a3":"code","8f556909":"code","fab8ada5":"markdown","f5d48759":"markdown","cb5c29b3":"markdown","0c0c5ed8":"markdown","756c5721":"markdown","a87ec118":"markdown","d92d4128":"markdown","0014c249":"markdown","747a9275":"markdown","f50ac022":"markdown","2be79b02":"markdown","5933836f":"markdown","2022cf5a":"markdown","875a1b25":"markdown","d0b0f4f6":"markdown"},"source":{"c9a35691":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","7b0e4c16":"# Read the data\nX_train_full = pd.read_csv('..\/input\/titanic\/train.csv', index_col='PassengerId')\nX_test_full = pd.read_csv('..\/input\/titanic\/test.csv', index_col='PassengerId')\n\n# Number of rows and columns\nprint(X_train_full.shape)\nprint(X_test_full.shape)\n\n# First 5 entries\nX_train_full.head()","ac05f0fb":"# Count null values\nprint(X_train_full.isnull().sum())\nprint('')\nprint(X_test_full.isnull().sum())","fd0c80a3":"# Labels\ny = X_train_full.Survived\n\n# Features\nX_train_full.drop(['Survived'], axis=1, inplace=True)","11cec7b1":"# Extract titles from 'Name' column\nX_train_full['Title']=0\nX_train_full['Title']=X_train_full.Name.str.extract('([A-Za-z]+)\\.')\n\n# Cross tabulation\npd.crosstab(X_train_full.Title,X_train_full.Sex).T","f257ba42":"# Raplace rare titles by 'Rare'\nX_train_full['Title'].replace(['Capt','Col','Countess','Don','Dr','Jonkheer','Lady','Major',\n                           'Master','Miss','Mlle','Mme','Mr','Mrs','Ms','Rev','Sir'],\n                           ['Rare','Rare','Rare','Rare','Rare','Rare','Rare',\n                            'Rare','Master','Miss','Rare','Rare','Mr','Mrs','Rare',\n                            'Rare','Rare'],inplace=True)\n\n# Median age in each group\nX_train_full.groupby('Title')['Age'].median()","17b242a2":"# Countplot\nsns.countplot(x=\"Title\",\n                   hue=\"Survived\", \n                   data=pd.concat([X_train_full,y],axis=1),\n                   palette = 'Blues_d')","da6293b9":"# Assign missing age values to be median within each group\nX_train_full.loc[(X_train_full.Age.isnull())&(X_train_full.Title=='Master'),'Age']=3.5\nX_train_full.loc[(X_train_full.Age.isnull())&(X_train_full.Title=='Miss'),'Age']=21\nX_train_full.loc[(X_train_full.Age.isnull())&(X_train_full.Title=='Mr'),'Age']=30\nX_train_full.loc[(X_train_full.Age.isnull())&(X_train_full.Title=='Mrs'),'Age']=34.5\nX_train_full.loc[(X_train_full.Age.isnull())&(X_train_full.Title=='Rare'),'Age']=44.5\n\n# Check there are not missing values\nX_train_full.Age.isnull().sum()","09670e46":"# Repeat feature engineering for test data\nX_test_full['Title']=0\nX_test_full['Title']=X_test_full.Name.str.extract('([A-Za-z]+)\\.') # extract titles\n\n# Raplace rare titles by 'Rare'\nX_test_full['Title'].replace(['Capt','Col','Countess','Don','Dr','Jonkheer','Lady','Major',\n                           'Master','Miss','Mlle','Mme','Mr','Mrs','Ms','Rev','Sir','Dona'],\n                           ['Rare','Rare','Rare','Rare','Rare','Rare','Rare',\n                            'Rare','Master','Miss','Rare','Rare','Mr','Mrs','Rare',\n                            'Rare','Rare','Rare'],inplace=True)\n\n# Assign missing age values to be median within each group\nX_test_full.loc[(X_test_full.Age.isnull())&(X_test_full.Title=='Master'),'Age']=3.5\nX_test_full.loc[(X_test_full.Age.isnull())&(X_test_full.Title=='Miss'),'Age']=21\nX_test_full.loc[(X_test_full.Age.isnull())&(X_test_full.Title=='Mr'),'Age']=30\nX_test_full.loc[(X_test_full.Age.isnull())&(X_test_full.Title=='Mrs'),'Age']=34.5\nX_test_full.loc[(X_test_full.Age.isnull())&(X_test_full.Title=='Rare'),'Age']=44.5\n\n# Check there are not missing values\nX_test_full.Age.isnull().sum()","14258f5e":"# Identify passangers with a recorded Cabin\nX_train_full['HasCabin']=X_train_full['Cabin'].notnull()\n\n# Repeat for test data\nX_test_full['HasCabin']=X_test_full['Cabin'].notnull()","eb8fca86":"# Countplot\nsns.countplot(x=\"HasCabin\",\n                   hue=\"Survived\", \n                   data=pd.concat([X_train_full,y],axis=1),\n                   palette = 'Blues_d')","b69f70ee":"# Select categorical columns to include in model\ncategorical_cols = ['Pclass', 'Sex', 'Embarked', 'HasCabin'] # Including 'Title' makes model worse\n\n# Select numerical columns to include in model\nnumerical_cols = ['Age', 'Fare', 'SibSp', 'Parch']\n\n# Keep selected columns only\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()","4eebec63":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='median')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Data preprocessing pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n\n# Transform the data\nX_train = my_pipeline.fit_transform(X_train)","2f8d74f1":"# Parameters grid\ngrid = {'n_estimators': [100, 125, 150, 175, 200, 225, 250], \n        'max_depth': [4, 6, 8, 10, 12]}\n\n# Random Forest Classifier\nclf=RandomForestClassifier(random_state=0)\n\n# Grid Search with 4-fold cross validation\ngrid_model = GridSearchCV(clf,grid,cv=4)\n\n# Train classifier with optimal parameters\ngrid_model.fit(X_train,y)","33261af9":"print(\"\\n The best parameters across ALL searched params:\\n\",grid_model.best_params_)\nprint(\"\\n The best score across ALL searched params:\\n\",grid_model.best_score_)","30ad81a3":"# Preprocess test data and fit model\nX_test_preprocessed=my_pipeline.transform(X_test)\npreds_test = grid_model.predict(X_test_preprocessed)\n\n# Save predictions to file\noutput = pd.DataFrame({'PassengerId': X_test.index,\n                       'Survived': preds_test})\n\n# Check format\noutput.head()","8f556909":"output.to_csv('submission.csv', index=False)","fab8ada5":"# Feature selection","f5d48759":"# Data","cb5c29b3":"# Libraries","0c0c5ed8":"**Repeat for test data**","756c5721":"**Check for missing values**","a87ec118":"**Title feature**","d92d4128":"# Grid Search","0014c249":"# Preprocessing data","747a9275":"# Background","f50ac022":"*The task is to predict which passangers survived the 1912 Titanic shipwreck given passanger information such as Age, Sex, Class etc.*","2be79b02":"**Labels and features**","5933836f":"**Results from Grid Search**","2022cf5a":"# Predictions","875a1b25":"# Feature engineering","d0b0f4f6":"**HasCabin feature**"}}