{"cell_type":{"638d35da":"code","f1905a3e":"code","9568ff24":"code","35a24694":"code","9d9f9e4e":"code","ea349179":"code","ddec34d5":"code","56191577":"code","4ec06d14":"code","e2e1a252":"code","c20884b4":"code","2497f1f1":"code","688a00a6":"code","150ccab1":"markdown","0ea86d60":"markdown","9973f085":"markdown","051527aa":"markdown","ddffb2b7":"markdown"},"source":{"638d35da":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport gc\nimport pickle\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import StratifiedKFold","f1905a3e":"with open(\"..\/input\/tps-sep-cooking-data\/TPS_Sep_Dataset.txt\", 'rb') as handle: \n    data = handle.read()\n\nprocessed_data = pickle.loads(data)\ntrain_df = processed_data['train_df']\ntest_df = processed_data['test_df']\n\ndel processed_data\ngc.collect()","9568ff24":"Xtrain = train_df.loc[:, train_df.columns != 'claim'].copy()\nYtrain = train_df['claim'].copy()\nXtest = test_df.copy()\n\nprint(f\"Xtrain: {Xtrain.shape} \\nYtrain: {Ytrain.shape} \\nXtest: {Xtest.shape}\")\n\ndel train_df, test_df\ngc.collect()","35a24694":"cat_cols = ['f5_bin','f29_bin','f40_bin','f42_bin','f50_bin','f65_bin',\n            'f70_bin','f74_bin','f75_bin','f91_bin','clusters_k']\n\nXtrain[cat_cols] = Xtrain[cat_cols].astype(int)\nXtest[cat_cols] = Xtest[cat_cols].astype(int)\n\ncat_cols_indices = [Xtrain.columns.get_loc(col) for col in cat_cols]\nprint(cat_cols_indices)","9d9f9e4e":"def plot_confusion_matrix(cm, classes):\n\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion matrix', fontweight='bold', pad=15)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], 'd'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontweight='bold')\n    plt.xlabel('Predicted label', fontweight='bold')\n    plt.tight_layout()","ea349179":"def lgb_train_predict(params, train, test, true_label, FOLD=5, SEEDS=[42]):\n\n    counter = 0\n    oof_score = 0\n    y_pred_final_lgb = np.zeros((test.shape[0], len(SEEDS)))\n    y_pred_meta_lgb = np.zeros((train.shape[0], len(SEEDS)))\n\n\n    for sidx, seed in enumerate(SEEDS):\n        seed_score = 0\n\n        kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n\n        for idx, (train_idx, val_idx) in enumerate(kfold.split(train, true_label)):\n            counter += 1\n\n            train_x, train_y = train.iloc[train_idx], true_label.iloc[train_idx]\n            val_x, val_y = train.iloc[val_idx], true_label.iloc[val_idx]\n\n            lgtrain = lgb.Dataset(train_x, label=train_y.ravel(), free_raw_data=False)\n            lgvalidation = lgb.Dataset(val_x, label=val_y.ravel(), free_raw_data=False)\n\n            params['learning_rate'] = 0.15\n\n            model = lgb.train(params, lgtrain, valid_sets=[lgtrain, lgvalidation], \n                              categorical_feature=cat_cols_indices,\n                              early_stopping_rounds=200, verbose_eval=300)\n\n            params['learning_rate'] = 0.07\n\n            model = lgb.train(params, lgtrain, valid_sets=[lgtrain, lgvalidation], \n                              categorical_feature=cat_cols_indices, init_model=model, \n                              early_stopping_rounds=100, verbose_eval=100)\n\n            y_pred = model.predict(val_x, num_iteration=model.best_iteration)\n            y_pred_meta_lgb[val_idx, sidx] += y_pred\n            y_pred_final_lgb[:, sidx] += model.predict(test, num_iteration=model.best_iteration)\n\n            score = roc_auc_score(val_y, y_pred)\n            oof_score += score\n            seed_score += score\n            print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n\n        print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score \/ FOLD)))\n\n\n    y_pred_final_lgb = y_pred_final_lgb \/ float(FOLD)\n    oof_score \/= float(counter)\n    print(\"Aggregate OOF Score: {}\".format(oof_score))\n    \n    return y_pred_meta_lgb, y_pred_final_lgb, oof_score","ddec34d5":"params1 = {\n    'objective': 'binary',\n    'metric': 'AUC',\n    'boosting': 'gbdt',\n    'n_jobs': -1,\n    'n_estimators': 8000,\n    'reg_alpha': 25.0,\n    'reg_lambda': 76.7,\n    'num_leaves': 6,\n    'max_depth': 2,\n    'colsample_bytree': 0.69,\n    'subsample': 0.98,\n    'subsample_freq': 1,\n    'feature_fraction_seed': 42,\n    'bagging_seed': 42,\n    'random_state': 42,\n    'min_child_samples': 54,\n    'min_child_weight': 256,\n    'verbosity': -1\n}\n\ny_pred_meta_lgb1, y_pred_final_lgb1, oof_score1 = lgb_train_predict(params1, Xtrain, Xtest, Ytrain)","56191577":"params2 = {\n    'objective': 'binary',\n    'metric': 'AUC',\n    'boosting': 'gbdt',\n    'n_jobs': -1,\n    'n_estimators': 8000,\n    'reg_alpha': 18.0,\n    'reg_lambda': 17.0,\n    'num_leaves': 7,\n    'max_depth': 3,\n    'colsample_bytree': 0.5,\n    'subsample': 0.85,\n    'subsample_freq': 1,\n    'feature_fraction_seed': 42,\n    'bagging_seed': 42,\n    'random_state': 42,\n    'min_child_samples': 20,\n    'min_child_weight': 256,\n    'verbosity': -1\n}\n\ny_pred_meta_lgb2, y_pred_final_lgb2, oof_score2 = lgb_train_predict(params2, Xtrain, Xtest, Ytrain)","4ec06d14":"y_pred_meta_lgb = np.concatenate((y_pred_meta_lgb1, y_pred_meta_lgb2), axis=1)\ny_pred_final_lgb = np.concatenate((y_pred_final_lgb1, y_pred_final_lgb2), axis=1)\nprint(f\"y_pred_meta_lgb: {y_pred_meta_lgb.shape} \\ny_pred_final_lgb: {y_pred_final_lgb.shape}\")","e2e1a252":"y_pred_meta = np.mean(y_pred_meta_lgb, axis=1)\ny_pred = (y_pred_meta>0.5).astype(int)\nprint(classification_report(Ytrain, y_pred))","c20884b4":"cnf_matrix = confusion_matrix(Ytrain, y_pred, labels=[0, 1])\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(12, 5))\nplot_confusion_matrix(cnf_matrix, classes=[0, 1])","2497f1f1":"np.savez_compressed('.\/LGB_Meta_Features.npz',\n                    y_pred_meta_lgb=y_pred_meta_lgb, \n                    oof_score1=oof_score1,\n                    oof_score2=oof_score2,\n                    y_pred_final_lgb=y_pred_final_lgb)","688a00a6":"y_pred_final = np.mean(y_pred_final_lgb, axis=1)\nsubmit_df = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\nsubmit_df['claim'] = y_pred_final\nsubmit_df.to_csv(\"LGB_Submission.csv\", index=False)\nsubmit_df.head(10)","150ccab1":"## Load processed datasets","0ea86d60":"## Helper Function","9973f085":"## Create submission file","051527aa":"## Import libraries","ddffb2b7":"## LightGBM Model"}}