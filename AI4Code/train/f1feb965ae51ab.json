{"cell_type":{"5ce2fb71":"code","562c38e8":"code","98c62cd2":"code","68aa56f6":"code","fb2cd70e":"code","243b9fc1":"code","92085c43":"code","018c91a6":"code","e467c06f":"code","114e22ba":"code","500e32e8":"code","f8a68bf1":"code","e5032bb5":"code","de96e0e3":"code","3ff45b50":"code","b8530760":"markdown","7e78739c":"markdown","08b1a56f":"markdown","37e30d90":"markdown","1c2c3b15":"markdown","3ecfc38e":"markdown","06ab8614":"markdown","0ea2af23":"markdown","3af7c532":"markdown","8d1361b8":"markdown"},"source":{"5ce2fb71":"import warnings\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import CatBoostClassifier","562c38e8":" PATH_TO_DATA = Path('..\/input\/mini-flight-delay-prediction\/')\n# PATH_TO_DATA = Path('..\/input\/flight-delays-fall-2018\/')\n# PATH_TO_DATA = Path('.\/data\/')","98c62cd2":"train_df = pd.read_csv(PATH_TO_DATA \/ 'flight_delays_train.csv')\ntest_df = pd.read_csv(PATH_TO_DATA \/ 'flight_delays_test.csv')\n\ntrain_df['DepHour'] = train_df['DepTime']\/\/100\ntrain_df['DepHour'].replace(to_replace=[24,25], value=0, inplace=True)\ntest_df['DepHour'] = test_df['DepTime']\/\/100\ntest_df['DepHour'].replace(to_replace=[24,25], value=0, inplace=True)\n\ntrain_df['DepMinute'] = train_df['DepTime']%100\ntest_df['DepMinute'] = test_df['DepTime']%100\n\ntrain_df['CarrierOriginDepHour'] = train_df['UniqueCarrier'] + ': ' + train_df['Origin'] + ': ' + train_df['DepHour'].astype('str')\ntest_df['CarrierOriginDepHour'] = test_df['UniqueCarrier'] + ': ' + test_df['Origin'] + ': ' + test_df['DepHour'].astype('str')\n","68aa56f6":"categ_feat_idx = np.where(train_df.drop('dep_delayed_15min', axis=1).dtypes == 'object')[0]\ncateg_feat_idx","fb2cd70e":"train_df.drop('dep_delayed_15min', axis=1).columns[categ_feat_idx]","243b9fc1":"X_train = train_df.drop('dep_delayed_15min', axis=1).values\ny_train = train_df['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\nX_test = test_df.values","92085c43":"X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, \n                                                                test_size=0.3, \n                                                                random_state=17)","018c91a6":"ctb = CatBoostClassifier(random_seed=17,\n                         silent=True,\n                         task_type=\"GPU\",\n                         border_count=254)\n\n# You can use GPU to speed up the process\n# border_count is necessary to go along with CPU precision. By default GPU sets border_count to 128.","e467c06f":"%%time\nctb.fit(X_train_part, y_train_part,\n        cat_features=categ_feat_idx);","114e22ba":"ctb_valid_pred = ctb.predict_proba(X_valid)[:, 1]","500e32e8":"roc_auc_score(y_valid, ctb_valid_pred)","f8a68bf1":"df = pd.DataFrame({'feature_name': train_df.drop('dep_delayed_15min', axis=1).columns,\n                   'importance': ctb.feature_importances_})\n\ndf.sort_values(by='importance', ascending=False)","e5032bb5":"%%time\nctb.fit(X_train, y_train,\n        cat_features=categ_feat_idx);","de96e0e3":"ctb_test_pred = ctb.predict_proba(X_test)[:, 1]","3ff45b50":"with warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\n    sample_sub = pd.read_csv('..\/input\/sample-data\/sample_submission.csv', \n                             index_col='id')\n    sample_sub['dep_delayed_15min'] = ctb_test_pred\n    sample_sub.to_csv('ctb_pred.csv')","b8530760":"**Lets take a look at the importance of the features**","7e78739c":"**Remember indexes of categorical features (to be passed to CatBoost)**","08b1a56f":"**Train Catboost with default arguments, passing only the indexes of categorical features.**","37e30d90":"**Create only three features**","1c2c3b15":" We got ~0.762 in the competition! That's well above the baseline!\n\n<img src='https:\/\/habrastorage.org\/webt\/fs\/42\/ms\/fs42ms0r7qsoj-da4x7yfntwrbq.jpeg' width=50%>\n*from the [\"Nerd Laughing Loud\"](https:\/\/www.kaggle.com\/general\/76963) thread.*","3ecfc38e":"**Train on the whole train set, make prediction on the test set.**","06ab8614":"In this assignment we are to beat the baseline of 0.75914 ROC AUC score.\nTo do this we need to aggregate some features from the initial data.\nMy approach is to create as few features as possible.\n\nMost of the code below is taken from public kernel https:\/\/www.kaggle.com\/kashnitsky\/mlcourse-ai-fall-2019-catboost-starter\n","0ea2af23":"**Allocate a hold-out set (a.k.a. a validation set) to validate the model**","3af7c532":"**We got some ~0.8 ROC AUC on the hold-out set.**","8d1361b8":"**Read the data**"}}