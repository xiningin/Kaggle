{"cell_type":{"7ba8f025":"code","ab70602b":"code","cc3d0cfa":"code","ae8f1df6":"code","6bf58245":"code","d9b77801":"code","3d136d08":"code","1f5d580c":"code","d888da24":"code","6e57e813":"code","b54cdf46":"code","d75f90ae":"code","a9069b51":"code","ec7b5708":"code","46de7d69":"code","fcd17165":"code","6728a90e":"code","9048b3a8":"code","b1f9ec4c":"code","5461bd4a":"code","1522018a":"code","b4fdcc93":"code","2b341295":"code","e7b35999":"code","5f1679c7":"code","40870847":"code","abc6c010":"code","ef9bfd25":"code","e384b962":"code","a04d4292":"code","52528ea7":"code","50d0aa5f":"code","5b86f043":"code","ac7c3bdf":"code","60725493":"code","51fad5f2":"code","e367cc30":"code","b1ab0b40":"code","e586cffc":"code","2e7db182":"code","57139505":"code","38882d8a":"markdown","34b6eea0":"markdown","40f6367e":"markdown","3d946872":"markdown","2bd385f5":"markdown","bb70d04f":"markdown","f2e3cb49":"markdown","dfcd8a19":"markdown","9bae1cf0":"markdown","a68ef4a7":"markdown","06bb0bcb":"markdown","91bfb905":"markdown","a6bef500":"markdown","916699b8":"markdown","639d6b58":"markdown","2c20c572":"markdown","c1ba7630":"markdown","414be62a":"markdown","d4df2200":"markdown","eb716e3e":"markdown"},"source":{"7ba8f025":"# !pip install ipywidgets matplotlib pandas spacy tqdm\n!pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_ner_bc5cdr_md-0.2.4.tar.gz","ab70602b":"%%bash -e\nif ! [[ -f .\/xyz2mol.py ]]; then\n  wget https:\/\/raw.githubusercontent.com\/jensengroup\/xyz2mol\/master\/xyz2mol.py\nfi","cc3d0cfa":"!pip install py3Dmol\n!pip install -U chembl_webresource_client\nimport sys\n!conda install --yes --prefix {sys.prefix} -c rdkit rdkit","ae8f1df6":"import glob\nimport json\nimport pandas as pd\nimport pickle\nimport spacy\nfrom spacy import displacy\nfrom spacy.matcher import Matcher\nfrom tqdm import tqdm\nimport en_ner_bc5cdr_md\nimport os\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom chembl_webresource_client.new_client import new_client\nimport rdkit\nfrom rdkit import Chem\nfrom rdkit.Chem import Draw\nimport py3Dmol # Amazing library for 3D visualization\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom ipywidgets import interact, interactive, fixed\nfrom IPython.display import Image\nimport cv2\nimport numpy as np\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn import decomposition\nfrom sklearn import datasets\nfrom sklearn.cluster import KMeans\nimport gc","6bf58245":"def doi_to_url(doi):\n    if isinstance(doi, float):\n        return None\n    elif doi.startswith('http'):\n        return str(doi)\n    elif doi.startswith('doi'):\n        return 'https:\/\/' + str(doi)\n    else:\n        return 'https:\/\/doi.org\/' + str(doi)","d9b77801":"df_meta = pd.read_csv('..\/input\/CORD-19-research-challenge\/metadata.csv')\ndf_meta['url'] = df_meta.doi.apply(doi_to_url)\ndf_meta.head(3)","3d136d08":"data_path = '..\/input\/CORD-19-research-challenge'\njson_files = glob.glob(f'{data_path}\/**\/**\/*.json', recursive=True)\nlen(json_files)","1f5d580c":"def to_covid_json(json_files):\n    jsonl = []\n    for file_name in tqdm(json_files):\n        row = {\"doc_id\": None, \"title\": None, \"abstract\": None, \"body\": None}\n\n        with open(file_name) as json_data:\n            data = json.load(json_data)\n\n            row['doc_id'] = data['paper_id']\n            row['title'] = data['metadata']['title']\n            \n            abstract_list = [abst['text'] for abst in data['abstract']]\n            abstract = \"\\n\".join(abstract_list)\n            row['abstract'] = abstract\n\n            # And lastly the body of the text. \n            body_list = [bt['text'] for bt in data['body_text']]\n            body = \"\\n\".join(body_list)\n            row['body'] = body\n            \n        jsonl.append(row)\n    \n    return jsonl\n    \n\ndef get_data():\n    try:\n        with open('df_cache.pickle', 'rb') as f:\n            df = pickle.load(f)\n    except FileNotFoundError:\n        df = pd.DataFrame(to_covid_json(json_files))\n        with open('df_cache.pickle', 'wb') as f:\n            pickle.dump(df, f)\n    return df\n\ndf = get_data()\nprint(df.shape)\ndf.head(3)","d888da24":"df.describe()","6e57e813":"def no_title(row):\n    return not row.title.strip()\n\ndef no_abstract(row):\n    return not row.abstract.strip()\n\ndef no_body(row):\n    return not row.body.strip()\n\ndef no_title_abstract_body(row):\n    return no_title(row) and no_abstract(row) and no_body(row)\n\nmask = df.apply(no_title_abstract_body, axis=1)\nprint('Number of articles that have no text data at all:', df.loc[mask].shape[0])","b54cdf46":"# insert missing values for empty strings\ndf.loc[df.apply(no_title, axis=1), 'title'] = None\ndf.loc[df.apply(no_abstract, axis=1), 'abstract'] = None\ndf.loc[df.apply(no_body, axis=1), 'body'] = None\ndf.head(3)","d75f90ae":"print('Missing value counts by column')\nlen(df) - df.count()","a9069b51":"# Gabarge collector\nimport gc\ngc.collect()","ec7b5708":"df = df.dropna(subset=['abstract'])\nprint('DataFrame shape:', df.shape)\nlen(df) - df.count()","46de7d69":"covid19_names = {\n    'COVID19',\n    'COVID-19',\n    '2019-nCoV',\n    '2019-nCoV.',\n#     'novel coronavirus',  # too ambiguous, may mean SARS-CoV\n    'coronavirus disease 2019',\n    'Corona Virus Disease 2019',\n    '2019-novel Coronavirus',\n    'SARS-CoV-2',\n}\n\ndef has_covid19(text):\n    for name in covid19_names:\n        if text and name.lower() in text.lower():\n            return True\n    return False\n\ndf['title_has_covid19'] = df.title.apply(has_covid19)\ndf['abstract_has_covid19'] = df.abstract.apply(has_covid19)\n# df['body_has_covid19'] = df.body.apply(has_covid19)\ndf_covid19 = df[df.title_has_covid19 | df.abstract_has_covid19]\nprint(df_covid19.shape)","fcd17165":"example_text = \"\"\"\nUnfortunately, no drug or vaccine has yet been approved to treat human coronaviruses. Several options can be envisaged to control or prevent emerging infections of 2019-nCoV, including vaccines, monoclonal antibodies, oligonucleotide-based therapies, peptides, interferon therapies and small-molecule drugs. However, new interventions are likely to require months to years to develop. Given the urgency of the 2019-nCoV outbreak, we focus here on the potential to repurpose existing antiviral agents approved or in development for treating infections caused by HIV, hepatitis B virus (HBV), hepatitis C virus (HCV) and influenza1, based on therapeutic experience with two other infections caused by human coronaviruses: severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS).\nVirally targeted agents. Approved nucleoside analogues (favipiravir and ribavirin) and experimental nucleoside analogues (remdesivir and galidesivir) may have potential against 2019-nCoV. Nucleoside analogues in the form of adenine or guanine derivatives target the RNA-dependent RNA polymerase and block viral RNA synthesis in a broad spectrum of RNA viruses, including human coronaviruses4. Favipiravir (T-705), a guanine analogue approved for influenza treatment, can effectively inhibit the RNA-dependent RNA polymerase of RNA viruses such as influenza, Ebola, yellow fever, chikungunya, norovirus and enterovirus4, and a recent study reported its activity against 2019-nCoV (EC50\u2009=\u200961.88\u2009\u03bcM in Vero E6 cells)5. Patients with 2019-nCoV are being recruited in randomized trials to evaluate the efficacy of favipiravir plus interferon-\u03b1 (ChiCTR2000029600) and favipiravir plus baloxavir marboxil (an approved influenza inhibitor targeting the cap-dependent endonuclease) (ChiCTR2000029544). Ribavirin is a guanine derivative approved for treating HCV and respiratory syncytial virus (RSV) that has been evaluated in patients with SARS and MERS, but its side effects such as anaemia may be severe at high doses2 and whether it offers sufficient potency against 2019-nCoV is uncertain. Remdesivir (GS-5734) is a phosphoramidate prodrug of an adenine derivative with a chemical structure similar to that of tenofovir alafenamide, an approved HIV reverse transcriptase inhibitor. Remdesivir has broad-spectrum activities against RNA viruses such as MERS and SARS in cell cultures and animal models, and has been tested in a clinical trial for Ebola. A recent study reported that remdesivir inhibited 2019-nCoV (EC50\u2009=\u20090.77\u2009\u03bcM in Vero E6 cells)5, and a US patient with 2019-nCoV recovered after receiving intravenous remdesivir in January6. Two phase III trials were initiated in early February to evaluate intravenous remdesivir (200\u2009mg on day 1 and 100\u2009mg once daily for 9 days) in patients with 2019-nCoV (NCT04252664 and NCT04257656), with estimated completion dates in April 2020. Galidesivir (BCX4430), an adenosine analogue that was originally developed for HCV, is currently in early-stage clinical studies evaluating its safety in healthy subjects and its efficacy against yellow fever, and has shown antiviral activities in preclinical studies against many RNA viruses, including SARS and MERS2.\n\"\"\"","6728a90e":"nlp = en_ner_bc5cdr_md.load()\n# nlp = spacy.load('..\/input\/scispacy-model\/en_ner_bc5cdr_md-0.2.4\/en_ner_bc5cdr_md\/en_ner_bc5cdr_md-0.2.4')","9048b3a8":"doc = nlp(example_text)","b1f9ec4c":"colors = {\n    'CHEMICAL': 'lightpink',\n    'DISEASE': 'lightorange',\n}\ndisplacy.render(doc, style='ent', options={\n    'colors': colors\n})","5461bd4a":"def apply_spacy(texts, nlp):\n    docs = []\n    for t in texts:\n        if t:\n            docs.append(nlp(t))\n        else:\n            docs.append(None)\n    return docs","1522018a":"def annotate_with_spacy(df):\n    df['title_doc'] = apply_spacy(df.title, nlp)\n    df['abstract_doc'] = apply_spacy(df.abstract, nlp)\n    return df\n\ndef get_spacy_df(df):\n    try:\n        with open('df_spacy_cache.pickle', 'rb') as f:\n            df_spacy = pickle.load(f)\n    except FileNotFoundError:\n        df_spacy = annotate_with_spacy(df)\n        with open('df_spacy_cache.pickle', 'wb') as f:\n            pickle.dump(df_spacy, f)\n    return df_spacy","b4fdcc93":"df_spacy = get_spacy_df(df_covid19)\ndf_spacy.iloc[0].abstract_doc.ents","2b341295":"trial_indicators = {\n    'trial',\n    'study',\n    'experiment',\n    'evaluate',\n    'evaluation',\n    're-evaluate',\n    'report',\n    'test',\n    'testing',\n    'target',\n    'data',\n    'show',\n    'outcome',\n    'evaluation',\n    'find',\n    'agent',\n    \n}\n\nusage_indicators = {\n    'approve',\n    'approval',\n    'therapeutic',\n    'therapy',\n    'inhibitory',\n    'effect',\n    'administer',\n    'achieve',\n    'improve'\n    'alleviate',\n    'reduce',\n    'antiviral',\n    'against',\n    'suppress',\n    'beneficial',\n    'evidence',\n    'take',\n\t'prescribe',\n\t'treatment',\n\t'receive',\n\t'treat',\n\t'regimen',\n\t'therapy',\n\t'use',\n\t'efficacy',\n\t'course',\n\t'drug',\n}\n\nidea_indicators = {\n    'promising',\n    'promise',\n    'speculate',\n    'believe',\n    'would',\n    'could',\n    'may',\n    'possibly',\n    'might',\n    'should',\n    'hypothesize',\n    'appear',\n    'lack',\n    'unclear',\n    'need',\n} \n\nmatcher = Matcher(nlp.vocab)\nfor n in trial_indicators:\n    matcher.add(\"trial\", None, [{'LEMMA': w.lemma_} for w in nlp(n)])\nfor n in usage_indicators:\n    matcher.add(\"usage\", None, [{'LEMMA': w.lemma_} for w in nlp(n)])\nfor n in idea_indicators:\n    matcher.add(\"idea\", None, [{'LEMMA': w.lemma_} for w in nlp(n)])\n\nexample_sent = \"Clinical trials (for example, ChiCTR2000029539) have been initiated to test HIV protease inhibitors such as lopinavir and ritonavir in patients infected with 2019-nCoV.\"\ndoc = nlp(example_sent)\nmatches = matcher(doc)\nfor match_name, start, end in matches:\n    print(nlp.vocab.strings[match_name], ':', doc[start:end])","e7b35999":"def doc_to_matches(doc):\n    match_results = {\n        'trial': [],\n        'usage': [],\n        'idea': []\n    }\n    if not doc:\n        return match_results\n\n    matches = matcher(doc)\n    for match_id, start, end in matches:\n        match_name = nlp.vocab.strings[match_id]\n        match_results[match_name].append((start, end))\n    return match_results\n\ndef get_matches_df(docs):\n    matches = []\n    for doc in docs:\n        matches.append(doc_to_matches(doc))\n    df = pd.DataFrame(matches)\n    return df\n        \ndf_matches = get_matches_df(df_spacy.abstract_doc)\ndf_matches.columns = ['abstract_trial_matches', 'abstract_usage_matches', 'abstract_idea_matches']\ndf_with_matches = pd.concat([df_spacy.reset_index(drop=True), df_matches], axis=1)\ndf_with_matches.head(3)","5f1679c7":"# df_covid19 = df_with_matches[df_with_matches.abstract_has_covid19]\nprint('Example abstracts', df_with_matches.shape)\nfor i, row in list(df_with_matches.iterrows())[:5]:\n    print('TITLE:', row.title)\n    print('\\n')\n    print(row.abstract)\n    print('\\n', '-' * 50, '\\n')","40870847":"BLACKLIST = {\n 'ACE2s',\n '2019-nCoV',\n '95%CI',\n 'ACE2-Fc',\n 'AMB',\n 'AMI',\n 'AMK',\n 'AOM',\n 'AST-045',\n 'AST-N041',\n 'ATP',\n 'BPO3-P',\n 'Betacoronavirus',\n 'CAP',\n 'CAZ',\n 'CC',\n 'CIP',\n 'CP',\n 'CLAVE',\n 'COVID-2019',\n 'CR3022',\n 'creatinine', \n 'CTX',\n 'CTX-M',\n 'CoV-2',\n 'DES',\n 'DHPG',\n 'DIP',\n 'E2',\n 'ESBL',\n 'Enterobacteriaceae',\n 'FASTA',\n 'FCA',\n 'FCS',\n 'FOS',\n 'GEN',\n 'GM',\n 'HK',\n 'HPDI',\n 'IFR',\n 'IM',\n 'IVA',\n 'JA',\n 'KLK13',\n 'LA',\n 'LPV\/r',\n 'LYM%',\n 'La',\n 'LcS',\n 'Li',\n 'MERS-CoV.',\n 'MICs',\n 'Metapneumovirus',\n 'M\u00e9decine',\n 'NAL',\n 'NCP',\n 'NG',\n 'NLR',\n 'NO',\n 'NOR',\n 'NP',\n 'NS7b',\n 'OC',\n 'OFL',\n 'OP',\n 'Prefixes',\n 'R\u00e9sum\u00e9',\n 'S.',\n 'SARS-CoV-2',\n 'SARS-COV-2',\n 'SARS-Cov2',\n 'SARS-CoV2',\n 'SARS-CoV-2 infection',\n 'SARS-CoV-2 infections',\n 'SARS-CoV-2 pneumonia',\n 'SARS-CoV.',\n 'SARS-Cov-2',\n 'SARS-related',\n 'SGC7901',\n 'SHV',\n 'SP',\n 'Sarbecovirus',\n 'Se',\n 'TCM',\n 'TCR',\n 'TCB',\n 'TGEV',\n 'TOB',\n 'TSL-EO',\n 'Texte',\n 'VME',\n 'VP',\n 'WeChat',\n 'ZJ01',\n '[ST]A',\n 'alcohol',\n 'amino acid',\n 'amino acids',\n 'aminoglycosides',\n 'bat-SL-CoVZXC21',\n 'betacoronavirus',\n 'cholesterol',\n 'coronavirus',\n 'des cas',\n 'https:\/\/doi.org\/10',\n 'infector-infectee',\n \"l'origine\",\n 'lactate',\n 'lockdowns',\n 'na',\n 'nucleic acid',\n 'nucleic acids',\n 'nucleotide',\n 'NBCZone',\n 'oxygen',\n 'quinolones',\n 'rinitis',\n 'self-imposed',\n 'sodium',\n 'smoking',\n '\u03b2-coronavirus',\n '\u2103'}\n\n\ndef count_chemical_ents(df):\n    ent_str = []\n    for i, row in df.iterrows():\n        if row.abstract_doc:            \n            for ent in row.abstract_doc.ents:\n                if ent.label_ == 'CHEMICAL':\n                    ent_str.append(row.abstract_doc[ent.start:ent.end].text)\n            \n    filtered = [e for e in Counter(ent_str).most_common() if e[1] > 8 and e[0] not in BLACKLIST]\n    return dict(filtered)\n\ncounts = count_chemical_ents(df_with_matches)\nprint('Count Frequencies\\n')\nprint(counts)\n\nplt.figure(figsize=(20,20))\nplt.rc('xtick', labelsize=20) \nplt.rc('ytick', labelsize=20) \nplt.xticks(rotation=90)\nplt.title('Frequency of CHEMICAL-type Strings in Abstracts', fontsize=20)\nplt.bar(counts.keys(), counts.values())","abc6c010":"import ipywidgets as widgets\nfrom ipywidgets import interact, interact_manual\nfrom IPython.core.display import HTML\n\nHTML_WRAPPER = \"\"\"<div style=\"overflow-x: auto; border: 1px solid #e6e9ef; border-radius: 0.25rem; padding: 1rem; margin-bottom: 2.5rem\">{}<\/div>\"\"\"\nBEGIN_ENTITY = \"\"\"<mark class=\"entity\" style=\"background: lightpink; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\"\"\"\nEND_ENTITY = \"\"\"<\/mark>\"\"\"\n\ndef match_to_concordance_html(match, doc, window_size=15):\n    _, start, end = match\n    concordance_start = max(start - window_size, 0)\n    concordance_end = min(end + window_size, len(doc))\n    return doc[concordance_start:start].text + BEGIN_ENTITY + doc[start:end].text + END_ENTITY + doc[end:concordance_end].text + '<\/br><\/br>'\n\n@interact_manual\ndef show_articles_more_than(column='abstract_doc', query='darunavir'):\n    matcher = Matcher(nlp.vocab)\n    matcher.add(\"query\", None, [{'LEMMA': w.lemma_} for w in nlp(query)])\n    result = []\n    html_str = ''\n    for doc in df_with_matches[column]:\n        if not doc:\n            continue\n        matches = matcher(doc)\n        for match in matches:\n            html_str += match_to_concordance_html(match, doc)\n    return display(HTML(HTML_WRAPPER.format(html_str + ''))) ##","ef9bfd25":"def doc_id_to_link(doc_id, df_meta, df_data):\n    rows = df_meta[df_meta.sha == doc_id]\n    if rows.empty:\n        return 'UNKNOWN URL AND TITLE'\n    url = rows.iloc[0].url\n    title = rows.iloc[0].title\n    if url and title:\n        return '<a href=\"{}\">'.format(url) + title + '<\/a>'\n    elif title:\n        return title\n    elif url:\n        return '<a href=\"{}\">'.format(url) + 'UNKNOWN TITLE' + '<\/a>'\n    else:\n        return 'UNKNOWN URL AND TITLE'\n\ndef chemical_df(chemicals, df_data, df_meta):\n    rows = []    \n    for chem in chemicals:\n        chem_row = {\n            'chemical_name': chem,\n            'chemical': [],\n            'trials': [],\n            'usages': [],\n            'ideas': []\n        }\n        matcher = Matcher(nlp.vocab)\n        matcher.add(\"query\", None, [{'LEMMA': w.lemma_} for w in nlp(chem)])\n        for i, row in df_data.iterrows():\n            chem_matches = matcher(row.abstract_doc)\n            for chem_match in chem_matches:\n                chem_row['chemical'].append((row.doc_id, chem_match[1], chem_match[2]))\n                for trial_match in row.abstract_trial_matches:\n                    if abs(trial_match[1] - chem_match[1]) < 15:\n                        chem_row['trials'].append((row.doc_id, trial_match[0], trial_match[1]))\n                for usage_match in row.abstract_usage_matches:\n                    if abs(usage_match[1] - chem_match[1]) < 15:\n                        chem_row['usages'].append((row.doc_id, usage_match[0], usage_match[1]))\n                for idea_match in row.abstract_idea_matches:\n                    if abs(idea_match[1] - chem_match[1]) < 15:\n                        chem_row['ideas'].append((row.doc_id, idea_match[0], idea_match[1]))\n        rows.append(chem_row)\n    return pd.DataFrame(rows)\n        \n    \ndf_chemical = chemical_df(list(counts.keys()), df_with_matches, df_meta)\ndf_chemical.head(3)","e384b962":"LABEL_TO_COLOUR = {\n    'chemical': 'lightorange',\n    'trials': 'lightpink',\n    'usages': 'lightgreen',\n    'ideas': 'lightblue'\n}\nBEGIN_ENTITY = \"\"\"<mark class=\"entity\" style=\"background: {}; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\"\"\"\nEND_ENTITY_WITH_SUBSCRIPT = \"\"\"<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">{}<\/span>\\n<\/mark>\"\"\"\n\ndef get_ents_by_doc_id(row):\n    contexts={'chemical', 'trials', 'usages', 'ideas'}\n    ents_by_doc_id = {}\n    for c in contexts:\n        for doc_id, start, end in row[c]:\n            entry = (start, end, c)\n            if doc_id not in ents_by_doc_id:\n                ents_by_doc_id[doc_id] = [entry]\n            else:\n                ents_by_doc_id[doc_id].append(entry)\n    return ents_by_doc_id\n\n@interact\ndef show_articles_for_chemical(chemical=list(counts.keys())):\n    row = df_chemical[df_chemical['chemical_name'] == chemical].iloc[0]\n    ents_by_doc_id = get_ents_by_doc_id(row)\n    html = ''\n    for doc_id, ents in ents_by_doc_id.items():\n        doc = df_with_matches[df_with_matches.doc_id == doc_id].iloc[0].abstract_doc\n        sorted_ents = sorted(set(ents))\n        doc_html = doc_id_to_link(doc_id, df_meta, df_covid19) + '<\/br><\/br>' \n        prev_end = 0\n        for start, end, label in sorted_ents:\n            doc_html += doc[prev_end:start].text\n            doc_html += ' ' + BEGIN_ENTITY.format(LABEL_TO_COLOUR[label]) + doc[start:end].text + END_ENTITY_WITH_SUBSCRIPT.format(label) + ' '\n            prev_end = end\n        doc_html += doc[end:].text + '<\/br><\/br>'\n        html+=doc_html\n        \n\n    return display(HTML(html))","a04d4292":"# function to draw the molecule\ndef drawit(m,p,confId=-1):\n    mb = Chem.MolToMolBlock(m,confId=confId)\n    p.removeAllModels()\n    p.addModel(mb,'sdf')\n    p.setStyle({'stick':{}})\n    p.setBackgroundColor('0xeeeeee')\n    p.zoomTo()\n    return p.show()\np = py3Dmol.view(width=400,height=400)","52528ea7":"# get the top drugs most mencioned\nlistchemicals = df_chemical.chemical_name.replace('lopinavir\/ritonavir', 'lopinavir').head(25)\nlistchemicals","50d0aa5f":"# Create clusters\nlistMols2 = []\nlistValids = []\n\nfor i in range(len(listchemicals)):\n    try:\n        productName = listchemicals[i]\n        \n        # Initiate Chembl database client\n        molecule = new_client.molecule\n        # get the moelcule id\n        molecule_chembl_id = molecule.search(productName)[0]['molecule_chembl_id']\n        res = molecule.get(molecule_chembl_id)\n        # return smile format molecular structure\n        smileStruct = res['molecule_structures']['canonical_smiles']\n        # converto to mol format\n        m = Chem.MolFromSmiles(smileStruct)\n        m = Chem.AddHs(m)\n        listMols2.append(m)\n        listValids.append(productName)\n      \n    except Exception as e:\n        print(f'\\nSorry, impossible to create structure for {productName}.')\n        \n        \n# generate fingeprints: Morgan fingerprint with radius 2\nn_dimensions = 300\nfps = [AllChem.GetMorganFingerprintAsBitVect(m, 2, n_dimensions) for m in listMols2]\n# Convert to numpy array\nnp_fps = np.asarray(fps)\n\n############# PCA decomposition (n=3)  #######################\ncenters = [[1, 1], [-1, -1], [1, -1]]\nX = np_fps\npca = decomposition.PCA(n_components=3)\npca.fit(X)\nX = pca.transform(X)\ndf2 = pd.DataFrame(X ,columns=['principal_component_1','principal_component_2','principal_component_3'])\ndf2['names'] = pd.DataFrame(listValids)\n\n############# Kmeans clusters  #######################\nkmeansmodel = KMeans(n_clusters=8).fit(df2[df2.columns[0:3]])\nlabelKmeans = kmeansmodel.labels_.astype(float)\ndf2['cluster'] = labelKmeans","5b86f043":"# Remove duplicated compounds\ndf2 = df2.drop_duplicates(subset=['principal_component_1','principal_component_2','principal_component_3'])\ndf2.sort_values(by=['cluster'])","ac7c3bdf":"# Gabarge collector to liberate memory\ngc.collect()","60725493":"############# Scatter plot  #######################\nimport matplotlib.patches as mpatches\n\ncentroids  = kmeansmodel.cluster_centers_\n\ndef randrange(n, vmin, vmax):\n    return (vmax - vmin)*np.random.rand(n) + vmin\n\nfig = plt.figure(figsize=(12, 12))\nax = fig.add_subplot(111)\n\nxs = df2.principal_component_1\nys = df2.principal_component_2\nnames = df2.names\ncluster = df2.cluster\nax.scatter(xs, ys)\nradius = 1.1\n\nfor x,y,names,cluster in zip(xs,ys,names,cluster):\n    label = names\n    if cluster == 0:\n        ax.text(x, y, label, fontsize=12, color='red')\n        art = mpatches.Circle(centroids[0],radius, edgecolor='r',fill=False)\n        ax.add_patch(art)\n    if cluster == 1:\n        ax.text(x, y, label,fontsize=12, color='blue')\n        art = mpatches.Circle(centroids[1],radius, edgecolor='blue',fill=False)\n        ax.add_patch(art)        \n    if cluster == 2:\n        ax.text(x, y, label, fontsize=12, color='green')\n        art = mpatches.Circle(centroids[2],radius, edgecolor='green',fill=False)\n        ax.add_patch(art)        \n    if cluster == 3:\n        ax.text(x, y, label, fontsize=12, color='black') \n        art = mpatches.Circle(centroids[3],radius, edgecolor='black',fill=False)\n        ax.add_patch(art)        \n    if cluster == 4:\n        ax.text(x, y, label, fontsize=12, color='purple')\n        art = mpatches.Circle(centroids[4],radius, edgecolor='purple',fill=False)\n        ax.add_patch(art)        \n    if cluster == 5:\n        ax.text(x, y, label, fontsize=12, color='blueviolet') \n        art = mpatches.Circle(centroids[5],radius, edgecolor='blueviolet',fill=False)\n        ax.add_patch(art)        \n    if cluster == 6:\n        ax.text(x, y, label, fontsize=12, color='brown') \n        art = mpatches.Circle(centroids[6],radius, edgecolor='brown',fill=False)\n        ax.add_patch(art)        \n    if cluster == 7:\n        ax.text(x, y, label, fontsize=12, color='magenta')  \n        art = mpatches.Circle(centroids[7],radius, edgecolor='magenta',fill=False)\n        ax.add_patch(art)        \n    \n      \n\nax.set_xlabel('principal component 1')\nax.set_ylabel('principal component 2')\nplt.title('Clusters of the most cited compounds according to their molecular structure.', loc='center', pad=None, fontSize=16)\nplt.show()","51fad5f2":"# get the top drugs most mencioned\nlistchemicals = listchemicals.head(6)\nlistchemicals","e367cc30":"percentSimilarity = 85\n\ndef print_structures(productName):\n    try:\n\n        print('\\n..................................................................................')\n        print(f'\\nStructure of {productName}\\n')\n\n        ################## Find the molecular structure in Chembl database ###########################\n\n        # Initiate Chembl database client\n        molecule = new_client.molecule\n        # get the moelcule id\n        molecule_chembl_id = molecule.search(productName)[0]['molecule_chembl_id']\n        res = molecule.get(molecule_chembl_id)\n        # return smile format molecular structure\n        smileStruct = res['molecule_structures']['canonical_smiles']\n        # converto to mol format using RDKIT library\n        m = Chem.MolFromSmiles(smileStruct)\n        m = Chem.AddHs(m)\n        # create the molecule image\n        AllChem.EmbedMultipleConfs(m,randomSeed=0xf00d,useExpTorsionAnglePrefs=True, useBasicKnowledge=True)\n        interact(drawit, m=fixed(m),p=fixed(p));\n\n        ############ Find similar molecules in Chembl database ###################################### \n        print(f'\\nMolecules that have at least {percentSimilarity}% similarity with {productName}\\n')\n\n        similarity = new_client.similarity\n        similar = similarity.filter(chembl_id=molecule_chembl_id, similarity=percentSimilarity)\n\n        list_mols=[]\n        list_ref_name = []\n\n        for i in range(len(similar)):\n\n            ref_name = (similar[i]['pref_name'])\n            if ref_name is None:\n                ref_name = similar[i]['molecule_chembl_id']\n    #             print(ref_name)\n            smileStruct = Chem.MolFromSmiles(similar[i]['molecule_structures']['canonical_smiles'])\n            list_mols.append(smileStruct)\n            list_ref_name.append(ref_name)\n\n        ms = [x for x in list_mols if x is not None]\n\n        for m in ms: tmp=AllChem.Compute2DCoords(m)\n\n        img=Draw.MolsToGridImage(ms, molsPerRow=3,subImgSize=(200,200),legends=[x for x in list_ref_name])\n        \n        fileName = 'related_' + productName + '.png'\n        img.save(fileName)\n        image = cv2.imread(fileName)        \n\n        plt.figure(figsize=(20, 80))\n        plt.ticklabel_format(style = 'plain')\n        plt.axis('off')\n        plt.imshow(image)\n        plt.show()\n\n    except Exception as e:\n        print('\\nSorry, structure not found in Chembl database.')\n\n","b1ab0b40":"print(listchemicals[0])\nprint_structures(listchemicals[0])","e586cffc":"print(listchemicals[2])\nprint_structures(listchemicals[2])","2e7db182":"print(listchemicals[3])\nprint_structures(listchemicals[3])","57139505":"print(listchemicals[4])\nprint_structures(listchemicals[4])","38882d8a":"As a result we have a group of molecules structurally related to the researched compound.   \nSuch a result may be useful in further research in the search for potential new drugs.","34b6eea0":"## Printing and comparing molecular structures\n\nNow we will print and compare those mentioned with other drugs with similar molecular structures in the public ChEMBL database. \nYou can find more information about the database on [https:\/\/www.ebi.ac.uk\/chembl\/](http:\/\/)\n\nNote: If you want to zoom in, or rotate de molecule, just click, scroll and move the mouse inside the molecule picture.\nNote 2: We will select only few compounds.","40f6367e":"# Extract all drugs and therapeutics from abstracts\nDrop all chemicals that appear less than N times in the whole dataset.\nIn the remaining, blacklist all false positives after manual inspection. Plot the remaining chemicals by occurrence frequency.","3d946872":"# TOPIC: Effectiveness of drugs being developed and tried to treat COVID-19 patients.\n\n![image.png](attachment:image.png)\n\n# TEAM:\n### This notebook was developed by the team formed by [Maria](https:\/\/www.kaggle.com\/maria17) and [Gtteixeira](https:\/\/www.kaggle.com\/gtteixeira) \n\n# Introduction\n\nIn response to the COVID-19 pandemic, the White House and a coalition of leading research groups have prepared the COVID-19 Open Research Dataset (CORD-19). CORD-19 is a resource of over 29,000 scholarly articles, including over 13,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses. This freely available dataset is provided to the global research community to apply recent advances in natural language processing and other AI techniques to generate new insights in support of the ongoing fight against this infectious disease. There is a growing urgency for these approaches because of the rapid acceleration in new coronavirus literature, making it difficult for the medical research community to keep up.\n\n## Dataset Description\n\nThe CORD-19 dataset represents the most extensive machine-readable coronavirus literature collection available for data mining to date. This allows the worldwide AI research community the opportunity to apply text and data mining approaches to find answers to questions within, and connect insights across, this content in support of the ongoing COVID-19 response efforts worldwide. There is a growing urgency for these approaches because of the rapid increase in coronavirus literature, making it difficult for the medical community to keep up.\n\n*References:   \n[https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge](http:\/\/)   \nCOVID-19 Open Research Dataset (CORD-19). 2020. Version 2020-03-13. Retrieved from https:\/\/pages.semanticscholar.org\/coronavirus-research. doi:10.5281\/zenodo.3715506*\n\n## Objective\n\nThe aim of this notebook is to provide resources and insights, through data science, to answer the following questions raised by the challenge proposed by Kaggle:  \n\n*What do we know about vaccines and therapeutics? What has been published concerning research and development and evaluation efforts of vaccines and therapeutics? *\n\nSpecifically, we want to show what the literature reports about:\n\nEffectiveness of drugs being developed and tried to treat COVID-19 patients.\nClinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocyclinethat that may exert effects on viral replication.\n\n## Strategy adopted\n\nIn this work we will make use of NLP, text mining, dataframe processing and visualization resources.","2bd385f5":"We will be working with abstracts. They provide an appropriate level of detail for the question at hand. Thus, we will drop all documents that do not have an abstract.","bb70d04f":"## Code for highlight  the text","f2e3cb49":"# Simple Concordance Visualiser\nHelps to compile the above blacklist as well as see contexts in which the above drug names appear.","dfcd8a19":"# Organise matches by Drugs\/Therapeutics\nAbove, we compiled a list of drugs\/therapeutics that are relevant in the context of COVID-19. Now, we can dive deeper into the contexts these drugs appear in.\n\nTo this end, we match words that indicate the context of the drug mention:\n* drug is in an **idea stage** (e.g. 'darunavir could be useful against COVID-19')\n* drug is in a **trial stage** (e.g. 'lopinavir is currently being trialled')\n* drug is in **usage stage** (e.g. 'patients are being treated with ritonavir')\n\nThese 'indicator' words are marked as additional entities in context.","9bae1cf0":"# Code development for insights\nFirst, let's import the necessary libraries.  ","a68ef4a7":"# Conclusion\n\nIn this notebook we present a technique to analyse the documents provided in search of relevant information about drugs being developed or tested.   \n\nA method was developed to find the relevant files among those provided in the challenge.\n\nSubsequently, a routine was developed whose objective is to find the words of interest as well as highlight them in the text and evaluate the context in which they are found. \n\nAll of this allows the user to quickly and efficiently search various files of interest.\n\nIt was also evaluated the correlation of the molecular structure of the most mentioned compounds among themselves, through clustering.\n\nFinally, the algorithm also searches the public CHEMBL database to find the chemical structure of the studied compound, as well as finding similar structures available in the database for further research by the user.\n\n\nWith the work it was possible to reach the following conclusions:\n\n* Several articles cite therapeutics with the use of drugs from different classes, such as antiretroviral protease inhibitors, corticosteroids, polyene antibiotics, glycosaminoglycans heparan sulfate, proteases and aminoquinoline derivatives.\n* There are 23 ongoing clinical trialsTRIALS in China. Chloroquine seems to be effective in limiting the replication of SARS-CoV-2 (virus causing COVID-19) in vitro.(https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0883944120303907?via%3Dihub)\n* Chloroquine was a highly effective treatment for falciparum malaria in The Gambia. High-grade resistance will soon preclude the use of chloroquine in severe malaria.(https:\/\/www.thelancet.com\/journals\/lancet\/article\/PII0140-6736(92)91645-O\/fulltext) \n* (Chymo)trypsin-like serine fold proteases belong to the serine\/cysteine proteases found in eukaryotes, prokaryotes, and viruses. For that reason, their catalytic activity is carried out using a triad of amino acids, a nucleophile, a base, and an acid. For this superfamily of proteases, they propose the existence of a universal 3D structure comprising 11 amino acids near the catalytic nucleophile and base -Nucleophile-Base Catalytic Zone (NBCZone).(https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0141813019386854?via%3Dihub)\n* The structure models of two severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) proteases, coronavirus endopeptidase C30 (CEP_C30) and papain like viral protease (PLVP), were built by homology modeling. Ritonavir, lopinavir and darunavir were then docked to the models, respectively, followed by energy minimization of the protease-drug complexes. In the simulations, ritonavir can bind to coronavirus endopeptidase C30 (CEP_C30)  most suitably, and induce significant conformation changes of CEP_C30; lopinavir can also bind to CEP_C30 suitably, and induce significant conformation changes of CEP_C30; darunavir can bind to PLVP suitably with slight conformation changes of PLVP. It is suggested that the therapeutic effect of ritonavir and lopinavir on COVID-19 may be mainly due to their inhibitory effect on CEP_C30, while ritonavirL may have stronger efficacy ; the inhibitory effect of darunavir on SARS-CoV-2 and its potential therapeutic effect may be mainly due to its inhibitory effect on PLVP. (https:\/\/www.biorxiv.org\/content\/10.1101\/2020.01.31.929695v2)\n* A total of 26 patients received intravenous administration of methylprednisolone with a dosage of 1-2mg\/kg\/d for 5-7 days, while the remaining patients not. The average number of days for body temperature back to the normal range was significantly shorter in patients with administration of methylprednisolone when compared to those without administration of methylprednisolone (2.06\u00b10.28 vs. 5.29\u00b10.70, P=0.010). The patients with administration of methylprednisolone had a faster improvement of SpO2, while patients without administration of methylprednisolone had a significantly longer interval of usingUSAGES supplemental oxygen therapy (8.2days[IQR 7.0-10.3] vs. 13.5days(IQR 10.3-16); P<0.001). In terms of chest CT, the absorption degree of the focus was significantly better in patients with administration of methylprednisolone. Our dataTRIALS indicate that in patients with severe COVID-19 pneumonia, early, lowdose and short-term application of corticosteroid was associated with a faster improvement of clinical symptoms and absorption of lung focus. (https:\/\/www.medrxiv.org\/content\/10.1101\/2020.03.06.20032342v1)\n*  It was studied the interaction between the SARS-CoV-2 Spike S1 protein receptor binding domain (SARS-CoV-2 S1 RBD) and heparin. The data demonstrate an interaction between the recombinant surface receptor binding domain and the polysaccharide. This has implications for the rapid development of a first-line therapeutic by repurposing heparin and for next-generation, tailor-made, GAG-based antivirals.(https:\/\/www.biorxiv.org\/content\/10.1101\/2020.02.29.971093v1)\n\n\n\nThe results show that the technique can be used to gain important insights into the about drugs and therapeutics related to coronavirus pandemic, in an agile way and without having to read thousands of full papers.   \n\n*Note: Some interactive features are not operational in the html file shown here; however, when running the notebook, all features are enabled and working.   *\n \n## Pros and cons\n\nAbout the technique used, we can highlight the ease and speed of obtaining the required information. \n\nAs cons, we emphasize that depending on the number of files to be evaluated, the execution of the algorithm can take a while.","06bb0bcb":"All document IDs are unique, nothing to tidy up. But there seem to be missing titles, abstracts and possibly missing bodies.","91bfb905":"## Load Metadata","a6bef500":"# Pre-filter by COVID-19\nIn order to analyze the papers related to COVID-19, we will create specific filters.","916699b8":"# Match relevant tokens, e.g. COVID-19, trial and usage indicators\nWe will now perform the necessary processing to make it possible to carry out the analyzes of interest.\n","639d6b58":"# Example Articles that talk about COVID-19","2c20c572":"# Load and Clean Data\nIn this step we will load the data and perform the necessary processing.","c1ba7630":"We can clearly see the separation of compounds groups.\nThe most important of which are: antiretroviral protease inhibitors, corticosteroids, polyene antibiotics, glycosaminoglycans heparan sulfate, proteases and aminoquinoline derivatives.\nNote: It was checked on Pubchem database.\n\nPublic References:  (In case of doubt to which chemical class a certain compound belongs, you can consult the public database PubChem )   \nhttps:\/\/pubchem.ncbi.nlm.nih.gov  \nhttps:\/\/pubchem.ncbi.nlm.nih.gov\/compound\/392622  \nhttps:\/\/pubchem.ncbi.nlm.nih.gov\/compound\/5755  \nhttps:\/\/pubchem.ncbi.nlm.nih.gov\/compound\/213039  \nhttps:\/\/pubchem.ncbi.nlm.nih.gov\/compound\/70678539  \nhttps:\/\/pubchem.ncbi.nlm.nih.gov\/compound\/5479537   \nhttps:\/\/pubchem.ncbi.nlm.nih.gov\/compound\/Amphotericin%20B","414be62a":"# Apply Scispacy Model\n\nWe use Scispacy's `en_ner_bc5cdr_md`. It provides only two NER classes: `DISEASE` and `CHEMICAL`. We are mostly interested in the latter because this class will likely carry drugs and therapeutics.","d4df2200":"## Load JSON Data","eb716e3e":"# Molecular Structure\n## Clustering the cited compounds \nIn this routine we will group the top cited compounds in clusters according to their molecular structure.\nHere we use PCA to reduce dimensionality and create a cluster with kmeans algorithm."}}