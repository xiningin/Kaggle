{"cell_type":{"cf12671d":"code","8d1bf24a":"code","6558de3a":"code","2f0c84db":"code","226269f4":"code","e3858872":"code","0e43a401":"code","7073aafc":"code","1ebc4e6a":"code","18ca8d70":"code","2cd30a97":"code","58929c21":"code","7110a11b":"code","1abe32ee":"code","77513e35":"code","da127e35":"code","b38d7e84":"code","7c89598b":"code","8a4030a2":"code","5b91fde0":"code","3fff158e":"code","08899c53":"code","66e034ef":"code","e8a71bac":"code","0db03086":"code","d52a7319":"code","341a1bb6":"code","246dbdac":"code","91f0318e":"code","00d3cc8e":"code","8638d26c":"code","2c49a709":"code","a129dcb5":"code","89422fd5":"markdown","df2e587c":"markdown","f4ca89cf":"markdown","05952bdb":"markdown","aa821c98":"markdown","f4b75f81":"markdown","193baa6f":"markdown","b21e72da":"markdown","6f225abc":"markdown","cb4d7340":"markdown","258a007c":"markdown","449382b2":"markdown","ed20ccc9":"markdown","344a5dd9":"markdown","c1947e0f":"markdown"},"source":{"cf12671d":"# setting up the libraries that we will need \nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8d1bf24a":"# loading the data\ntrain = pd.read_csv(\"..\/input\/new-york-city-taxi-fare-prediction\/train.csv\", nrows= 2000000)\ntest = pd.read_csv(\"..\/input\/new-york-city-taxi-fare-prediction\/test.csv\")\ntrain.name = \"Train\"\ntest.name = \"Test\"","6558de3a":"def corr(df):\n    corr_matrix = df.corr()\n    print(corr_matrix[\"fare_amount\"].sort_values(ascending=False))","2f0c84db":"#data exploration\ntrain.head()","226269f4":"train.info()","e3858872":"train.describe()","0e43a401":"corr(train)","7073aafc":"test.describe()","1ebc4e6a":"coordinates_columns = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\ndata_set = [train, test]\nfor coord in coordinates_columns:\n    for data in data_set:\n        maxi = data[coord].max()\n        mini = data[coord].min()\n        print (\"Range of {} in {} data is : ({:.3f}, {:.3f})\".format(coord, data.name, maxi, mini))\ndel data_set","18ca8d70":"test.passenger_count.value_counts()","2cd30a97":"train.passenger_count.value_counts()","58929c21":"#Negative fare amount\ntrain.loc[train['fare_amount']<0].shape","7110a11b":"# create a an fare amount category attribute with five bins to understand better this attribute\ntrain[\"fare_amount_1\"]=pd.cut(train[\"fare_amount\"],\n                            bins=[0., 6.0,12.,48.,150., np.inf],\n                                  labels = [1,2,3,4,5])","1abe32ee":"train[\"fare_amount_1\"].hist()","77513e35":"train.fare_amount_1.value_counts()","da127e35":"#a dictionary with NYC coordinates from test data that will be used in deleting outliers\ncoordinates = {'min_long': min(test.pickup_longitude.min(), test.dropoff_longitude.min()),\n              'max_long': max(test.pickup_longitude.max(), test.dropoff_longitude.max()),\n              'min_lat': min(test.pickup_latitude.min(), test.dropoff_latitude.min()),\n              'max_lat' : min(test.pickup_latitude.max(), test.dropoff_latitude.max()),}","b38d7e84":"# we will use plt.xlim to limit the axes while plotting , to get a better observation of the data\ncity_long_border = (-74.03, -73.75)\ncity_lat_border = (40.63, 40.85)","7c89598b":"train[(train.pickup_longitude >= coordinates['min_long']) & \n      (train.pickup_longitude <= coordinates['max_long']) & \n      (train.pickup_latitude >= coordinates['min_lat']) & \n      (train.pickup_latitude <= coordinates['max_lat']) &\n      (train.dropoff_longitude >= coordinates['min_long']) &\n      (train.dropoff_longitude <= coordinates['max_long']) &\n      (train.dropoff_latitude >= coordinates['min_lat']) & \n      (train.dropoff_latitude<= coordinates['max_lat'])].plot(\n        kind ='scatter', x='pickup_longitude', y='pickup_latitude',s=.02, alpha =0.4)\n\nplt.ylim(city_lat_border)\nplt.xlim(city_long_border)","8a4030a2":"class DataCleaning (BaseEstimator, TransformerMixin):\n    def __init__ (self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        l=len(X)\n        if X.name == 'Train':\n            X = X[(X.fare_amount>0) & (X.fare_amount<150)]\n            X = X.drop(\"fare_amount_1\", axis=1) # we don't need this feature anymore\n            X = X[(X.passenger_count>=0) &(X.passenger_count<=8)]\n            X = X[(X.pickup_longitude>=coordinates['min_long']) & (X.pickup_longitude<=coordinates['max_long'])]\n            X = X[(X.pickup_latitude>=coordinates['min_lat']) & (X.pickup_latitude<=coordinates['max_lat'])]\n            X = X[(X.dropoff_longitude>=coordinates['min_long']) & (X.dropoff_longitude<=coordinates['max_long'])]\n            X = X[(X.dropoff_latitude>=coordinates['min_lat']) & (X.dropoff_latitude<=coordinates['max_lat'])]\n        X.pickup_longitude = X.pickup_longitude.apply(lambda x: round(x,3))\n        X.pickup_latitude = X.pickup_latitude.apply(lambda x: round(x,3))\n        X.dropoff_longitude = X.dropoff_longitude.apply(lambda x: round(x,3))\n        X.dropoff_latitude = X.dropoff_latitude.apply(lambda x: round(x,3))\n        print(l - len(X), \" row has been deleted\" )\n        return X","5b91fde0":"class date_time_extraction (BaseEstimator, TransformerMixin):\n    def __init__ (self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X['key'] = pd.to_datetime(X.key, format=\"%Y-%m-%d %H:%M:%S\")\n        X['year'] = X.key.dt.year\n        X['month'] = X.key.dt.month\n        X['day'] = X.key.dt.month\n        X['dayOftheWeek'] = X.key.dt.dayofweek\n        X[\"hour\"]=X.key.dt.hour\n        X.drop(\"pickup_datetime\", axis=1, inplace=True)\n        return X           ","3fff158e":"#nyc_airports coordinates\nnyc_airports={'JFK':{'min_lng':-73.835,\n                     'min_lat':40.619,\n                     'max_lng':-73.740, \n                     'max_lat':40.665},\n              \n              'EWR':{'min_lng':-74.192,\n                     'min_lat':40.670, \n                     'max_lng':-74.153, \n                     'max_lat':40.708},\n              \n        'LaGuardia':{'min_lng':-73.889, \n                     'min_lat':40.766, \n                     'max_lng':-73.855, \n                     'max_lat':40.793}\n                }","08899c53":"# a function to assign 1 if we have a pick up or drop off from an airport\ndef Airport(latitude, longitude, airport_name):\n    if (latitude>=nyc_airports[airport_name]['min_lat'] and\n      latitude<=nyc_airports[airport_name]['max_lat'] and\n      longitude>=nyc_airports[airport_name]['min_lng'] and\n      longitude<=nyc_airports[airport_name]['max_lng']):\n        return 1\n    else:\n        return 0\n        ","66e034ef":"class Airport_data (BaseEstimator, TransformerMixin):\n    def __init__ (self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X['pick_up_JFK']=X.apply(lambda row:Airport(row['pickup_latitude'],row['pickup_longitude'],'JFK'),axis=1)\n        X['dropoff_JFK']=X.apply(lambda row:Airport(row['dropoff_latitude'],row['dropoff_longitude'],'JFK'),axis=1)\n        X['pickup_EWR']=X.apply(lambda row:Airport(row['pickup_latitude'],row['pickup_longitude'],'EWR'),axis=1)\n        X['dropoff_EWR']=X.apply(lambda row:Airport(row['dropoff_latitude'],row['dropoff_longitude'],'EWR'),axis=1)\n        X['pickup_la_guardia']=X.apply(lambda row:Airport(row['pickup_latitude'],row['pickup_longitude'],'LaGuardia'),axis=1)\n        X['dropoff_la_guardia']=X.apply(lambda row:Airport(row['dropoff_latitude'],row['dropoff_longitude'],'LaGuardia'),axis=1)\n        return X    \n        \n        ","e8a71bac":"# This forumla is availabe on the internet to understand it better\ndef trip_distance(lat1, lat2, lon1,lon2):\n    p = 0.017453292519943295 # Pi\/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)\/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) \/ 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))","0db03086":"class distance (BaseEstimator, TransformerMixin):\n    def __init__ (self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X['trip_distance']=X.apply(lambda row:trip_distance(row['pickup_latitude'],row['dropoff_latitude'],row['pickup_longitude'],row['dropoff_longitude']),axis=1)\n        X[\"diff_lat\"]=abs(X.pickup_latitude-X.dropoff_latitude)\n        X[\"diff_long\"]=abs(X.pickup_longitude-X.dropoff_longitude)\n        return X","d52a7319":"class Normalization (BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X.year = (X.year - 2009)\n        max_year = X.year.max()\n        X.month = X.month + X.year*12\n        X.year = X.year\/max_year\n        max_month = X.month.max()\n        X.month = X.month\/max_month\n        max_day = X.day.max()\n        X.day = X.day\/max_day\n        max_hour = X.hour.max()\n        X.hour = X.hour \/ max_hour\n        X.pickup_latitude = coordinates['max_lat'] - X.pickup_latitude\n        X.dropoff_latitude = coordinates['max_lat'] - X.dropoff_latitude\n        X.pickup_longitude = coordinates['max_long'] - X.pickup_longitude\n        X.dropoff_longitude = coordinates['max_long'] - X.dropoff_longitude\n        return X","341a1bb6":"Data_processing_pipeline = Pipeline([\n    ('cleaning', DataCleaning()),\n    ('Date and time extraction', date_time_extraction()),\n    ('Pick up or drop off in an airport', Airport_data()),\n    ('usefull distances', distance()),\n    ('Normalization', Normalization())   \n])","246dbdac":"X_train= Data_processing_pipeline.fit_transform(train)\nlabels = X_train[\"fare_amount\"].copy()\nX_train = X_train.drop(\"fare_amount\", axis=1) # drop labels for training set\nX_train = X_train.drop(\"key\", axis=1) \nX_test = Data_processing_pipeline.fit_transform(test)\nX_test = X_test.drop(\"key\", axis=1) \ndel train, test","91f0318e":"param_grid = [\n    {'n_estimators': [3, 10, 30, 40, 50], 'max_features': [2, 6, 8]},\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}\n]\n","00d3cc8e":"#loading model\nforest_reg = RandomForestRegressor()\n# grid search to determine the best set of HP using grid search and 5 folders for cross validation\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                          scoring = 'neg_mean_squared_error',\n                          return_train_score=True)","8638d26c":"#fitting and selecting best set of parameters\ngrid_search.fit(X_train, labels)\nbest_model = grid_search.best_estimator_\ngrid_search.best_params_","2c49a709":"final_predictions = best_model.predict(X_test)","a129dcb5":"SS = pd.read_csv(\"..\/input\/new-york-city-taxi-fare-prediction\/sample_submission.csv\")\nSS['fare_amount']= final_predictions\nSS.to_csv('SS.csv',index=False)","89422fd5":"### 2.3 Normalization:\nNow that all our features are ready we will reduce the size of our data so our model train faster","df2e587c":"#### 2.2.2 Airport pickup and dropoff\nAs mentionned earlier, NYC has 3 airports. We all now that taxis pick and drop passangers frequently from these kind of locations. So for each airport we will add 2 columnes: pick_up and drop_off.","f4ca89cf":"#### 3.2 Predictions","05952bdb":"### 2.4 Data Processing pipeline:\n","aa821c98":"### 2.2 Feature Engineering:\nAll we have is 5 features but this number is small to train a decent model so we will add a few attributes:\n#### 2.2.1 Extracting date and time\nUsing the date attribute which is not useful in this format we will generate 5 more attributes which are: Year, Month, Day, Day of The week, and hour.","f4b75f81":"## **1. Loading data and EDA:**\n\nThe New york city fare prediction dataset have 55M line, we will work only with the first 2M lines due to memory contraints.","193baa6f":"## **2. Data Processing**\n### 2.1 Data Cleaning: Dealing with outliers\nWe did notice in the previous section that our data has too much outliers (not realistic data) which will affect our model negatively. So here we will deal with this remove them.\n* Delete rows with negative or superior to 150 USD fare amount \n* Delete rows with unrealistic coordinates\n* Round coordinates to 3 round number to 3 decimal places (gain computing power)","b21e72da":"#### 3.3 Submitting results\n","6f225abc":"The longitude of NYC is from 71\u00b0 47' 25\" W to 79\u00b0 45' 54\" W and the Latitude is from  40\u00b0 29' 40\" N to 45\u00b0 0' 42\" N. However in this dataset we find some noise values: for ex longitude ~ 3457 and latitude ~ 3344. Whereas in test data the boundary is more compatible with NYC longitude and latitude. The same goes for passenger_count ~ 280   or = 0, and negative fare.\nIn Data processing section we will delete those outliers.","cb4d7340":"# **Introduction**\nHello, \nIn this notebook we will deal with a simple regression task, predicting the fare amount for taxi trips in new york city. The notebook focues on dealing with outliers, cleaning data, engineering some features, and then training a random forest regressor model. ","258a007c":"The plot of the pickup data from train shows that we have a map simular to NYC, we can note that there are 3 particular places with high pickup density:\n* JFK airport\n* LA Gurdia airport\n\nNYC has another airpot which is Erward airport. \nThese informations could help us to generate more feature: pick up and drop off from each airport.","449382b2":"#### 2.2.3 Distance\nAnother important feature that we can add is trip distance. We can also add latitude distance as difference between pickup and dropoff latitude. The same for longitude distance.","ed20ccc9":"Most of the values are from 6 to 12 USD then an equal distribution of values for the range 0 to 6 USD and 12 to 48 USD. The values that are supperior to 150 USD are unreal, despite being around 200 values they might affect our model so we will delete them in the data processing section.","344a5dd9":"# **Table of contents:** \n\n1. Loading data and EDA\n\n2. Data Processing\n\n    2.1 Data cleaning: Dealing with outliers\n\n    2.2 Feature Engineering\n    \n    2.3 Normalization\n\n3. Training, predictions and submitting results\n\n    3.1 Training\n\n    3.2 Predictions\n    \n    3.3 Submitting results\n\n","c1947e0f":"## **3. Training, predictions and submitting results**\n#### 3.1 Training\nI have tried several different models and decided to work with RandomForestRegrosser as it is a basic model and give acceptable results. Due to the big number of training 1 model will consume a lot of time while training. "}}