{"cell_type":{"f522adfa":"code","9f34ad4d":"code","07162084":"code","f04ae417":"code","5052d0ee":"code","5c1927e6":"code","f5a8b9f7":"code","85de8259":"code","0f036850":"code","8ffd159e":"code","d42e6a47":"code","5fb0f04e":"code","e1387f22":"code","6b0f3e4f":"code","43a82868":"code","66a48ced":"code","9d64b916":"code","ab3f4268":"code","199be409":"code","3e9c2cab":"code","a59aa93d":"code","181f5401":"code","608bf3f5":"code","14ec0f36":"code","29a44d2a":"code","e0bd572f":"code","be52abab":"code","2cc78a4e":"code","fec512d2":"code","e6b48443":"code","244063d2":"code","cfb23b0b":"code","eed27609":"code","d4277b4e":"code","437209e8":"markdown","c8c63826":"markdown","676afae7":"markdown","43c6e9dd":"markdown","35e3f784":"markdown","7064f85a":"markdown","8706018a":"markdown","819b6875":"markdown","4d2c1614":"markdown","61a9a099":"markdown","23369419":"markdown","dfb7472c":"markdown","5457bed2":"markdown","1c2b1d7f":"markdown","2bc9abc1":"markdown","68119d83":"markdown","629e05c7":"markdown","e73678b7":"markdown","7e8ff820":"markdown","cf048878":"markdown","3750081d":"markdown","b004b284":"markdown","b3d0a897":"markdown","2de4191f":"markdown","faacff15":"markdown","75c2e73f":"markdown","dac433ed":"markdown","3834a94b":"markdown","735d2e47":"markdown","275f36e8":"markdown","4132770c":"markdown","8463896a":"markdown","b5fdf537":"markdown","a9a67ff7":"markdown","297211d8":"markdown","66113c07":"markdown","d6c5837f":"markdown","743d23b1":"markdown","3b979642":"markdown","725c82bf":"markdown","91e6fba8":"markdown","211505e9":"markdown"},"source":{"f522adfa":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","9f34ad4d":"df = pd.read_csv(\"..\/input\/PakistanDroneAttacksWithTemp Ver 10 (October 19, 2017).csv\", encoding='latin1')\n\n# Removing the last row as it contained junk values\ndf = df.drop(df.index[[403, 404]])\n\n# Dropiing the Axes that are not required\ndf=df.drop(['Special Mention (Site)', 'References','Time'], axis=1)\n\n# Printing the number of missing values in the data\nfor col in df:\n    print (col, \": \", df[col].isnull().sum())\n","07162084":"def filling_nan(data):\n    \n    # Initializing 'col' which stores the Column names of the columns whose null values need to be filled by 0\n    col = ['Al-Qaeda', 'Taliban', 'Civilians Min', 'Civilians Max', 'Foreigners Min', 'Foreigners Max', \n           'Total Died Min', 'Total Died Mix', 'Injured Min', 'Injured Max']\n    \n    data[col] = data[col].fillna(0)                                  # Filling the above columns with 0\n    data['Women\/Children  '] = data['Women\/Children  '].fillna('N')  # Filling the Women\/Children column's missing values with 'N'\n    data['Temperature(C)'] = data['Temperature(C)'].fillna(data['Temperature(C)'].mean())\n    data['Temperature(F)'] = data['Temperature(F)'].fillna(data['Temperature(F)'].mean())\n    \n    return data","f04ae417":"data = filling_nan(df)\n\n# Printing the number of missing values in the data\nfor col in df:\n    print (col, \": \", df[col].isnull().sum())","5052d0ee":"def dt(data):\n    data['DateTime'] = pd.Series()\n    for i in range(0, len(data.Date)):\n        \n        # Converting to date-time format\n        frame = data['Date'][i]\n        data['DateTime'][i] =  datetime.datetime.strptime(frame, '%A, %B %d, %Y')\n    \n    return data","5c1927e6":"data = dt(data)","f5a8b9f7":"data['Terrorists'] = data['Al-Qaeda'] + data['Taliban']                   # Adding Taliban and Al-Qaeda personnel killed\ndata['Civilians'] = (data['Civilians Min'] + data['Civilians Max'])\/2     # Taking average of Max and Min Civilians killed\ndata['Civilians'] = np.ceil(data['Civilians'])                            # Rounding up the average\ndata['Injured'] = (data['Injured Min'] + data['Injured Max'])\/2           # Taking average of Max and Min Civilians injured\ndata['Injured'] = np.ceil(data['Injured'])                                # Rounding up the average\ndata['Total Died'] = (data['Total Died Min'] + data['Total Died Mix'])\/2           # Taking average of Max and Min Civilians injured\ndata['Total Died'] = np.ceil(data['Total Died'])\ndata['Foreigners'] = (data['Foreigners Min'] + data['Foreigners Max'])\/2  # Taking average of Max and Min Foreigners killed\ndata['Foreigners'] = np.ceil(data['Foreigners'])                          # Rounding up the average\n\ndata['Innocents'] = data['Total Died'] - data['Terrorists']                # Marking all the non-terrorists killed\n\n\n\n# In some observations, the Total Died was not calculated accurately and there were negative values representing the \n# number of people killed. In those cases, we used different method to calculate the Civilian Casualties\nfor i in range(0, len(data.Innocents)):\n    if data['Innocents'][i] <0:\n        data['Innocents'][i] = data['Civilians'][i] + data['Foreigners'][i]\n        \n    # Changing the Labels in 'Women\/Children' column to Binary values\n    if data['Women\/Children  '][i] == 'N':\n        data['Women\/Children  '][i] = 0\n    elif data['Women\/Children  '][i] == 'Y':\n        data['Women\/Children  '][i] = 1\n\n# Accuracy is the ratio of terrorists killed to the total number of people killed in a drone strike\ndata['Accuracy'] = (data['Terrorists'])\/(data['Terrorists'] + data['Innocents'])\ndata['Accuracy'] = data['Accuracy'].fillna(0)\n\n# Removing the columns that are not required for further analysis, replacement have been made for some of these columns\ndata = data.drop(['Date', 'Province', 'Civilians Min', 'Civilians Max', 'Foreigners Min',\n                  'Foreigners Max', 'Total Died Min', 'Total Died Mix', 'Injured Min', 'Injured Max', \n                 'Temperature(C)', 'Temperature(F)'], axis=1)","85de8259":"data.head()","0f036850":"# Creating new columns for Year, Day of week and Month from the given Date-Time format\ndata['Year'] = np.nan\ndata['Weekday'] = np.nan\ndata['Month'] = np.nan\n\n# Extracting the Year of attack, Day of attack and the month of Attack\nfor i in range(0, len(data.Year)):\n    data.loc[:,'Year'][i]= data.loc[:,'DateTime'][i].year\n    data.loc[:,'Weekday'][i] = data['DateTime'][i].weekday()\n    data.loc[:,'Month'][i] = data['DateTime'][i].month\n\n# Converting Year and Weekday values from float to int\ndata['Year'] = data['Year'].astype(\"int\")\ndata['Weekday'] = data['Weekday'].astype(\"int\")\n    \n# Grouping the new column by the Year, Weekday & Month and corresponding Drone Attacks\nby_year = data.groupby(['Year'])['No of Strike'].sum()\nby_weekday = data.groupby(['Weekday'])['No of Strike'].sum()\nby_month = data.groupby(['Month'])['No of Strike'].sum()\n","8ffd159e":"data['City'] = data['City'].replace('South waziristan', 'South Waziristan')\ndata['City'] = data['City'].replace('south Waziristan', 'South Waziristan')\ndata['City'] = data['City'].replace('south waziristan', 'South Waziristan')\ndata['City'] = data['City'].replace('Lower Kurram Agency', 'Kurram')\ndata['City'] = data['City'].replace('Kurram Agency', 'Kurram')\ndata['City'] = data['City'].replace('Khyber Agency', 'Khyber')\ndata['City'] = data['City'].replace('Hungu', 'Hangu')","d42e6a47":"data['City'].unique()","5fb0f04e":"data_byyear = pd.DataFrame()\ndata_byyear['Terrorists'] = data.groupby(['Year'])['Terrorists'].sum()\ndata_byyear['Innocents'] = data.groupby(['Year'])['Innocents'].sum()\ndata_byyear['Injured'] = data.groupby(['Year'])['Injured'].sum()\ndata_byyear['No of strikes'] = data.groupby(['Year'])['No of Strike'].sum()\ndata_byyear['Accuracy'] = data.groupby(['Year'])['Accuracy'].mean()\ndata_byyear['Total Died'] = data.groupby(['Year'])['Total Died'].sum()\ndata_byyear['Avg Innocents Killed'] = data.groupby(['Year'])['Innocents'].mean()\ndata_byyear.head()","e1387f22":"# Initializing start-date and end-date\nstart_date = datetime.date(2004,1,1)\nend_date= datetime.date(2017,12,31)\n\n# Creating object containing all the dates from 2004 to 2017\ndays = pd.date_range(start_date, end_date)\n\n# Making the object the index of the new DataFrame\ndatadate = pd.DataFrame(index=days)\ndatadate.index.name='Date'\n\ndatadate['Terrorists']=np.nan\ndatadate['Civilians']=np.nan\ndatadate['Injured']=np.nan\ndatadate['Foreigners']=np.nan\ndatadate['Month']=np.nan\ndatadate['Year']=np.nan\ndatadate['Strikes']=np.nan\ndatadate['Deaths']=np.nan\n\n# Storing Month and Year values in new columns for future use\nfor i in range(len(datadate)):\n    datadate['Month']=days.strftime(\"%B\")\n    datadate['Year']=days.year\n\n# Filling the new DataFrame with values. These values come from the dates in which Drone Attack took place.\n# All remaining dates will contain nan\nfor i in range(len(data)):\n    if(data['DateTime'][i] in datadate.index):\n        \n        datadate['Deaths'][data['DateTime'][i]]=data['Total Died'][i]\n        datadate['Strikes'][data['DateTime'][i]]=data['No of Strike'][i]    \n        datadate['Terrorists'][data['DateTime'][i]]=data['Terrorists'][i]\n        datadate['Civilians'][data['DateTime'][i]]=data['Civilians'][i]\n        datadate['Injured'][data['DateTime'][i]]=data['Injured'][i]\n        datadate['Foreigners'][data['DateTime'][i]]=data['Foreigners'][i]\n\n# Replacing nan values with 0\ndatadate = datadate.fillna(0)\n","6b0f3e4f":"datadate.head()","43a82868":"fig1 = plt.figure(figsize=(14, 10))\nfig1 = plt.bar(left=list(by_year.keys()), height=by_year.values)\nplt.xlabel(\"Year\")\nplt.ylabel(\"No. of attacks\")\nplt.title(\"Drone attacks by Year\")\nplt.xticks(list(by_year.keys()))\nplt.grid()\nplt.show()","66a48ced":"fig2 = plt.figure(figsize=(14, 10))\nfig2 = plt.bar(left=list(by_weekday.keys()), height=by_weekday.values)\nplt.xlabel(\"Day of the Week\")\nplt.ylabel(\"No. of attacks\")\nplt.title(\"Drone attacks by Weekday\")\nplt.xticks(range(0,7), ('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))\nplt.show()","9d64b916":"fig3 = plt.figure(figsize=(14, 10))\nfig3 = plt.bar(left=list(by_month.keys()), height=by_month.values)\nplt.xlabel(\"Month\")\nplt.ylabel(\"No. of attacks\")\nplt.title(\"Drone attacks by Months\")\nplt.xticks(range(1,13), ('January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'))\nplt.show()","ab3f4268":"\"\"\"Precision is being calculated by taking the number of Terrorists killed and dividing it by the total number \n   of people killed (including 'Civilians' and 'Foreigners') \"\"\"\n\nfig = plt.figure(figsize=(14, 10))\nfig = plt.plot(data_byyear.Accuracy.keys(), data_byyear.Accuracy)\nplt.xlabel(\"YEAR\", fontsize=16)\nplt.ylabel(\"SCORE (0-1)\", fontsize=18)\nplt.title(\"Precision of Drone attacks over the Years\", fontsize=22)\nplt.xticks(range(2004, 2018))\nplt.ylim(0, 1)\nplt.grid()\nplt.show()","199be409":"fig = plt.figure(figsize=(14, 10))\nx = data_byyear.Accuracy.keys()\n\nplt.plot(x, data_byyear.Terrorists, color='r', label = 'Terrorists Killed')\nplt.plot(x, data_byyear.Innocents, color='g', label = 'Civilians Killed')\nplt.plot(x, data_byyear.Injured, color='b', label = 'People Injured')\nplt.xticks(range(2004, 2018))\nplt.xlabel(\"YEAR\", fontsize=16)\nplt.ylabel(\"Number of people\", fontsize=18)\nplt.title(\"Trend of Terrorists and Civilians killed along with Civilians Injured\", fontsize=22)\nplt.legend(fontsize = 16)\nplt.show()","3e9c2cab":"def timeperiodyearTA(data):\n    \n    a1=[]\n    data['Year'] = np.nan\n    data['Weekday'] = np.nan\n    data['Month'] = np.nan\n\n    for i in range(0, 403):\n        data.loc[:,'Year'][i]= data.loc[:,'DateTime'][i].year\n    \n# Grouping the new column by the Year\n    by_year = data.groupby('Year').size()\n    df7 = pd.DataFrame(by_year)\n    timeyear = [2004.0,2005.0,2006.0,2007.0,2008.0,2009.0,2010.0,2011.0,2012.0,2013.0,2014.0,2015.0,2016.0,2017.0]\n    df7['Taliban'] = 0\n    df7['Al-Qaeda'] = 0\n    for i in range(0, 403):\n            for x in range(len(timeyear)):\n                if (data.loc[:,'Year'][i] == timeyear[x]):\n\n#Calculating total no Taliban personnel killed\n                    df7['Taliban'][timeyear[x]] = df7['Taliban'][timeyear[x]] + data['Taliban'][i]\n\n#Calculating total no Taliban personnel killed\n                    df7['Al-Qaeda'][timeyear[x]] = df7['Al-Qaeda'][timeyear[x]] + data['Al-Qaeda'][i]\n    x = df7.index.values\n    y1= df7['Taliban']\n    y2= df7['Al-Qaeda']\n\n#plotting the graph for analysis of drone strike under Bush and Obama\n    fig1= plt.figure(figsize=(14, 10))\n    plt.plot(x,y1)\n    plt.plot(x,y2,color=\"red\")\n    plt.ylabel(\"No. of Terrorist killed\")\n    plt.title(\"BUSH VS OBAMA\", fontsize = 30)\n    plt.xlabel(\"YEAR\")\n    plt.legend()\n    plt.axvspan(2004, 2009, color='red', alpha=0.3)\n    plt.axvspan(2009, 2017, color='blue', alpha=0.3)\n    plt.show()\n    return df7\ntimeperiodyearTA(df)","a59aa93d":"def areaTA(data,z):\n# Filtering the areas belonging to Taliban and Al-Qaeda\n    b=[]\n    c=[]\n    d=[]\n\n# b[] is used to store the Locations of Taliban\n# c[] is used to store the Longitude of Taliban\n# d[] is used to store the Latitude of Taliban\n\n    for i in range(len(data.index)):\n        if (data['Taliban'][i].any() != 0.0):\n            b.append(data['Location'][i])\n            c.append(data['Longitude'][i])\n            d.append(data['Latitude'][i])\n    df2 = pd.DataFrame(b)\n    df2.columns=['Taliban']\n    df2['Longitude'] = pd.DataFrame(c)\n    df2['Latitude'] = pd.DataFrame(d)\n    df3 = df2.drop_duplicates()\n    e=[]\n    f=[]\n    g=[]\n\n# e[] is used to store the Locations of Taliban\n# f[] is used to store the Longitude of Taliban\n# g[] is used to store the Latitude of Taliban\n\n    for i in range(len(data.index)):\n        if (data['Al-Qaeda'][i].any() != 0.0):\n            e.append(data['Location'][i])\n            f.append(data['Longitude'][i])\n            g.append(data['Latitude'][i])\n    df4 = pd.DataFrame(e)\n    df4.columns=['Al-Qaeda']\n    \n    df4['Longitude'] = pd.DataFrame(f)\n    df4['Latitude'] = pd.DataFrame(g)\n    #df2.columns=['Al-Qaeda']\n    #df2.sort_values('Taliban').drop_duplicates('Taliban')\n    df5 = df4.drop_duplicates()\n# z is a flag variable and determines whether data frame for Taliban or Al-Qaeda is to be sent \n# z=1 returns the Taliban Data Frame\n# z=0 returns the Al-Qaeda Data Frame\n    if (z==1):\n        return df3\n    else:\n        return df4\nareaTA(df,1)\n    \n\ndef Mapping(df):\n    import folium\n    dfmap1=areaTA(df,1)\n    dfmap0=areaTA(df,0)\n\n# folium package is used for plotting on a world map\n# dfmap1 contains Taliban data\n# dfmap0 contains Al-Qaeda data\n    \n    subset1 = dfmap1[['Latitude', 'Longitude']]\n    tuples1 = [tuple(x) for x in subset1.values]\n\n    subset0 = dfmap0[['Latitude', 'Longitude']]\n    tuples0 = [tuple(x) for x in subset0.values]\n\n#tuples0 contains tuple of longitude and latitude of Al-Qaeda\n#tuples1 contains tuple of longitude and latitude of Taliban\n\n    c1 = [x for x in tuples1 if not any(isinstance(i, float) and np.isnan(i) for i in x)]\n    c0 = [x for x in tuples0 if not any(isinstance(i, float) and np.isnan(i) for i in x)]\n    mapit = folium.Map(location=[32.9,70.1],zoom_start = 8)\n    for coord in c1:\n        folium.Marker( location=[ coord[0], coord[1] ],icon=folium.Icon(color='red',icon='info-sign')).add_to( mapit )\n    for coord in c0:\n        folium.Marker( location=[ coord[0], coord[1] ],icon=folium.Icon(color='green')).add_to( mapit )\n\n    mapit.save( 'map.html')\n    return mapit\nMapping(df)","181f5401":"# Using Wordcloud library to visualize the high-frequency words (https:\/\/github.com\/amueller\/word_cloud)\nfrom wordcloud import WordCloud\na=[]\n\n# Ignoring the Null Values\nfor i in range(len(data)):\n    data['Comments'][i]=str(data['Comments'][i])\n    if (data['Comments'][i]!=np.nan):\n        a.append(data['Comments'][i])\n        \na = [x for x in a if str(x) != 'nan']\n        \n# Generating the picture using WordCloud \nwordcloud = WordCloud().generate(' '.join(a))\n\n# Plotting the image generated\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","608bf3f5":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nN_Strikes = data_byyear['No of strikes']\n\nfig = plt.figure(figsize=[24, 20])\nfig = plot_acf(N_Strikes)          # Plotting Auto-correlation function\nfig = plot_pacf(N_Strikes)         # Plotting Partial auto-correlation function\nplt.show()","14ec0f36":"from statsmodels.tsa import arima_model\n\ndata_byyear.index = pd.to_datetime(data_byyear.index, format='%Y')\n\n# Using p=3 and q=1, building the ARMA model\nnpdf = data_byyear['No of strikes'].astype(float)\nresults = arima_model.ARMA(npdf,(3, 1)).fit()\nprint (results)\n\n# Forecasting using the ARMA model defined above\ndata_byyear['forecast_N_Strikes'] = results.predict(start='2012-01-01', end='2017-01-01', dynamic= False) \n\n# Plotting the forecast along with the actual data\ndata_byyear[['No of strikes', 'forecast_N_Strikes']].plot(figsize=(14, 10))\nplt.xlabel('YEAR')\nplt.ylabel('Log of No of strikes')\nplt.show()","29a44d2a":"from sklearn.metrics import mean_absolute_error\n\n# Creating Series of Actual Values\nN_Strikes = data_byyear['No of strikes']\nN_Strikes_sub = N_Strikes.loc['2011-01-01': '2017-01-01']\n\nforecast = results.predict(start='2011-01-01', end='2017-01-01', dynamic= True)\n\n# Mean Absolute Error\nMAE = mean_absolute_error(N_Strikes_sub, forecast)\nprint (\"Mean Absolute Error (MAE): {}\".format(MAE))\n\n# Mean Forecast Error\nforecast_error = [N_Strikes_sub[i]-forecast[i] for i in range(len(N_Strikes_sub))]\nMFE = (sum(forecast_error))\/len(N_Strikes)\nprint (\"Mean Forecast Error (MFE): {}\".format(MFE))","e0bd572f":"plt.figure(figsize=(14, 10))\n\n# Plotting Time-series\nplt.plot(data_byyear['No of strikes'], label= 'Time-series data')\n\n# Plotting Rolling Mean\nrollmean = pd.Series(data_byyear['No of strikes']).rolling(window=2).mean()\nplt.plot(rollmean, label = 'Rolling Mean')\n\n# Plotting Standard Deviation\nstd_dev = pd.Series(data_byyear['No of strikes']).rolling(window=2).std()\nplt.plot(std_dev, label = 'Rolling Standard Deviation')\n\n# Plotting Log( ) function of Time-Series\ndata_byyear['Log_No of strikes'] = np.log(data_byyear['No of strikes'])\nplt.plot(data_byyear['Log_No of strikes'], label = 'Log of No. of Strikes')\n\nplt.legend()","be52abab":"### Plotting Log of the 'No. of Strikes'\n\nmov_mean = pd.Series(data_byyear['Log_No of strikes']).rolling(window=2).mean()\nplt.figure(figsize=(14, 10))\nplt.plot(data_byyear['Log_No of strikes'], label = 'Log of time-series')\nplt.plot(mov_mean, label = 'Rolling Mean of Log')\nplt.legend()","2cc78a4e":"# Storing the Log of Time-series in a new variable\nts_log = data_byyear['Log_No of strikes']\n\nts_log_diff1 = ts_log - ts_log.shift()\ndata_byyear['First Difference'] = ts_log_diff1\nts_log_diff2 = ts_log_diff1 - ts_log_diff1.shift()\ndata_byyear['Second Difference'] = ts_log_diff2\ndata_byyear['Second Difference'].dropna(inplace=True)\nplt.figure(figsize=(12, 8))\nplt.ylabel('Log of Time-Series (No. of Strikes)')\nplt.xlabel('YEAR')\nplt.title('Log of No. of Strikes')\nplt.plot(ts_log_diff2, label = 'Second Difference of the Log function')\nplt.legend()","fec512d2":"from statsmodels.tsa.stattools import adfuller\n\n#Perform Dickey-Fuller test:\nprint ('Results of Dickey-Fuller Test:')\ndftest = adfuller(data_byyear['Second Difference'], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\nprint (dfoutput)","e6b48443":"from statsmodels.stats.stattools import durbin_watson\nprint (\"Durbin-Watson statistic of stationary time-series \", durbin_watson(data_byyear['Second Difference']))\n\n# The Durbin-Watson statistic implies a strong auto-correlation in the errors","244063d2":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nfig = plt.figure(figsize=[24, 20])\nfig = plot_acf(data_byyear['Second Difference'])          # Plotting Auto-correlation function\nfig = plot_pacf(data_byyear['Second Difference'])         # Plotting Partial auto-correlation function\nplt.show()","cfb23b0b":"# Using p = 1 and q = 0, building the ARMA model\n\nnpdf = data_byyear['Second Difference'].astype(float)\nresults = arima_model.ARMA(npdf,(1, 0)).fit()\n\n# Creating Series of Actual Values\nN_Strikes = data_byyear['Second Difference']\nN_Strikes_sub = N_Strikes.loc['2012-01-01': '2017-01-01']\n\nforecast = results.predict(start='2012-01-01', end='2017-01-01', dynamic= False) \n\n# Plotting the forecast along with the actual data\nplt.figure(figsize=(14, 10))\nplt.plot(data_byyear['Second Difference'], label = 'Second Difference of Log')\nplt.plot(forecast, label = 'Forecast')\nplt.xlabel('YEAR')\nplt.ylabel('Second Difference of Log of No of strikes')\nplt.title('ARMA Model of Stationary Time-Series')\nplt.legend()\nplt.show()","eed27609":"# Using p = 1 and q = 0, building the ARMA model\nnpdf = data_byyear['Second Difference'].astype(float)\nresults = arima_model.ARMA(npdf,(1, 0)).fit()\n\n# Creating Series of Actual Values\nN_Strikes = data_byyear['Second Difference']\nN_Strikes_sub = N_Strikes.loc['2012-01-01': '2017-01-01']\n\nforecast = results.predict(start='2012-01-01', end='2017-01-01', dynamic= False) \n\n# Mean Absolute Error\nMAE = mean_absolute_error(N_Strikes_sub, forecast)\nprint (\"Mean Absolute Error (MAE): {}\".format(MAE))\n\n# Mean Forecast Error\nforecast_error = [N_Strikes_sub[i]-forecast[i] for i in range(len(N_Strikes_sub))]\nMFE = (sum(forecast_error))\/len(N_Strikes)\nprint (\"Mean Forecast Error (MFE): {}\".format(MFE))","d4277b4e":"from scipy import stats\nfrom statsmodels.graphics.api import qqplot\n\n# Printing the Normal Test results to check whether residuals come from a normal distribution\nresid = results.resid\nprint (stats.normaltest(resid))\n\n# Contructing qq-plot of residuals \nfig = plt.figure(figsize=(12,8))\nqqplot(resid, line='s', fit=True)","437209e8":"## 2.3 Visualizing the important words commented on every Drone Strike","c8c63826":"### 1.6 Creating new DataFrame day-wise","676afae7":"### 2.1.5 Trend of Civilians and Terrorists killed along with people Injured","43c6e9dd":"### 3.1.2 Fitting the ARMA model","35e3f784":"### 2.1.6 Al-Qaeda vs Taliban and Bush vs Obama","7064f85a":"### 1.5 Creating Year-wise dataset\nHere, we are taking the important features, grouping them by year and creating a new DataFrame","8706018a":"### 3.2.3 Visualizing the Second Difference of the Log function","819b6875":"### Importing required libraries and reading the Data","4d2c1614":"## 2.2 Plotting the Drone Attacks on the Map","61a9a099":"## 3.2 Making the Time-Series Stationary","23369419":"### 2.1.1 Number of Drone Attacks over the Years","dfb7472c":"In the above map, the Green labels indicate the Drone Strikes in which Al-Qaeda personnels were killed and the Red labels indicate the Drone Strikes in which Talibani got killed. The region in which the Drone Strikes happened were very close to each other and therefore there is a lot of overlap in the labels. Due to inconsistencies in data, some labels were shown in Europe. ","5457bed2":"In the dataset, there are separate columns for no. of Al-Qaeda personnel killed, no. of Talibani killed, minimum no. of civilians killed etc. We want to add a new column marking the count of a terrorist killed (Al-Qaeda or Taliban) and marking the counts of civilians killed (civilians, foreigners etc.)","1c2b1d7f":"### 3.2.5 Fitting the ARMA model by taking p=1 and q-0","2bc9abc1":"The Mean Absolute Error and Mean Forecast Error seem to be quite low given the size of the Time-Series. We try to improve the score by making the Time-series stationary and then fitting the model.","68119d83":"### 1.3 Marking terrorists and civilians","629e05c7":"### 1.1. Missing Values","e73678b7":"### 2.1.3 Number of Drone Attacks by Month","7e8ff820":"### 3.2.7 Visualizing the distribution of Residuals","cf048878":"### 2.1.4 Precision of Drone Strikes over the Years\n","3750081d":"### 3.2.2 Visualizing the Log( ) function and its rolling mean","b004b284":"### 3.2.6 Calculating the MAE and MFE of new Time-Series","b3d0a897":"### 3.2.1 Visualizing the Time-Series and plotting mean, std and Log( )","2de4191f":"### 3.1.3 Calculating Mean Absolute Error and Mean Forecast Error","faacff15":"### 3.1.1 Autocorrelation and Partial Autocorrelation plot of Time-Series","75c2e73f":"### 2.1.2 Number of Drone Attacks by Day of a week\n","dac433ed":"## Here we are investigating the data on Drone attacks that have happened in Pakistan since 2004.","3834a94b":"### 3.2.4 Plotting the Autocorrelation and Partial Autocorrelation plots","735d2e47":"### 1.4 Cleaning the 'City' column by removing inconsistent values","275f36e8":"From ACF and PACF plot, we are inclined towards using AR (p) = 3 and MA (q) = 1 ","4132770c":"## 3.1 ARMA Model","8463896a":"Durbin-Watson statistic close to 2 implies that the One-Dimensional Time-Series has no evidence of serial correlation","b5fdf537":"# 2. Exploratory Data Analysis\n","a9a67ff7":"# Pakistan Drone Attacks\n# 1. Cleaning Data\n","297211d8":"## 2.1 Visualizing the Data\n","66113c07":"The plot of the changed Time-Series along with the results of ADF Test indicate that the Time-Series is now stationary","d6c5837f":"Merging the Date and Time columns and saving the data in date-time format for ease of use","743d23b1":"# 3.  Time-Series Forecasting of Number of Drone Strikes","3b979642":"In the above figure, the size of each figure depends on the frequency by which that word occurs in the Comments. Each word that is big enough to be read tells an interesting story about it. Words like Taliban and Al-Qaeda are big enough to be read whereas words like 'Haqqani-Network' is quite small. This is also true in the region which is dominated by Taliban followed by Al-Qaeda group members but there are also some members of the 'Haqqani-Network' operating in that region who have declared their fight against the US-led NATO Forces. ","725c82bf":"Removing NaN values from columns and replacing it with appropriate values:\n1. Time: NaN -> 00:00 (Setting un-recorded time to 12 AM)\n2. Al-Qaeda TO Injured_Min: NaN -> 0 (Setting un-recorded deaths to 0)\n3. Women\/Children: NaN -> N (Setting un-recorded Women\/Children involvement to No)\n4. Location (City Name) NaN -> when location not recorded (Lattitude and longitude still present)\n\nWe will deal with the null values of 'Comments' column later on","91e6fba8":"### 1.2 Changing to Date-Time format","211505e9":"Here we are creating new Data frame 'datadate' where each row will represent one day. The days on which drone strikes took place will have values in the corresponding columns (Terrorists, Civilians, Injured etc.). All the other rows will be filled with 0"}}