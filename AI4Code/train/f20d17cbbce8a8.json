{"cell_type":{"240d25a9":"code","3c6b947f":"code","a589efd5":"code","91dbd770":"code","1e54559e":"code","73201b0c":"code","63ef11b7":"code","887f7f44":"code","bb12f85f":"code","bee2b05b":"code","cdde78be":"code","2661eba4":"code","b2dc2023":"code","56055f46":"code","5acfb116":"markdown","32ebd773":"markdown","783692d2":"markdown","1421e981":"markdown","c780bc40":"markdown","383bc9ee":"markdown","b8233baa":"markdown","cb4ff553":"markdown","2d19f757":"markdown","1a8dfc1f":"markdown","2e54b83f":"markdown","66d02356":"markdown"},"source":{"240d25a9":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport pandas as pd\nimport time\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport cv2\nimport shutil","3c6b947f":"base_path = '..\/input\/american-sign-language-09az\/American\/'\nclasses = os.listdir(base_path)\nfilepaths = []\nlabels = []\nfor d in classes:\n    flist = os.listdir(base_path + d)\n    for f in flist:\n        fpath = os.path.join(base_path + d + '\/' + f)\n        filepaths.append(fpath)\n        labels.append(d)\nprint ('filepaths: ', len(filepaths), '   labels: ', len(labels))","a589efd5":"Fseries=pd.Series(filepaths, name='file_paths')\nLseries=pd.Series(labels, name='labels')\ndf=pd.concat([Fseries,Lseries], axis=1)\ndf=pd.DataFrame(np.array(df).reshape(142261,2), columns = ['file_paths', 'labels'])\nprint(df['labels'].value_counts())","91dbd770":"file_count = 1570\nsamples = []\nfor category in df['labels'].unique():    \n    category_slice = df.query(\"labels == @category\")    \n    samples.append(category_slice.sample(file_count, replace=False,random_state=1))\ndf = pd.concat(samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\nprint (df['labels'].value_counts())\nprint (len(df))","1e54559e":"plt.figure(figsize=(14,10))\nfor i in range(20):\n    random = np.random.randint(1,len(df))\n    plt.subplot(4,5,i+1)\n    plt.imshow(cv2.imread(df.loc[random,\"file_paths\"]))\n    plt.title(df.loc[random, \"labels\"], size = 10, color = \"black\") \n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","73201b0c":"train_df, test_df = train_test_split(df, train_size=0.95, random_state=0)\ntrain_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)\nprint(train_df.labels.value_counts())\nprint(valid_df.labels.value_counts())\nprint(test_df.labels.value_counts())","63ef11b7":"target_size=(299,299)\nbatch_size=64","887f7f44":"train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input, zoom_range=0.15, rotation_range=30, height_shift_range=0.1, width_shift_range=0.1)\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)\ntrain_gen = train_datagen.flow_from_dataframe(train_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='categorical')\nvalid_gen = test_datagen.flow_from_dataframe(valid_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='categorical')\ntest_gen = test_datagen.flow_from_dataframe(test_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='categorical')","bb12f85f":"base_model = tf.keras.applications.InceptionResNetV2(include_top=False, input_shape=(299,299,3))","bee2b05b":"model = tf.keras.Sequential([\n    base_model, \n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.Dropout(0.2), \n    tf.keras.layers.Dense(36, activation='softmax')\n])","cdde78be":"lr=0.001\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])","2661eba4":"patience = 1\nstop_patience = 3\nfactor = 0.5\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"classify_model.h5\", save_best_only=True, verbose = 0),\n    tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, verbose=1)\n]","b2dc2023":"epochs = 30\nhistory = model.fit(train_gen, validation_data=valid_gen, epochs=epochs, callbacks=callbacks, verbose=1)","56055f46":"best_model = model\nbest_model.load_weights('.\/classify_model.h5')\nbest_model.evaluate(test_gen)","5acfb116":"# **Image Data Generator**","32ebd773":"Dataset is severely inbalanced so we will take 1570 of each image for training and testing our model. ","783692d2":"# **Create Dataframe from Images**","1421e981":"# **Model Training**","c780bc40":"# **Import Libraries**","383bc9ee":"Looks like we should do some zooming, rotation, and some height and width shifting with Image Data Generator. ","b8233baa":"# **Building CNN Model**","cb4ff553":"# **Custom Callbacks to Improve Training**","2d19f757":"# **Balancing Dataset**","1a8dfc1f":"# **Visualize Images**","2e54b83f":"# **Create Train, Test, Valid Dataframes**","66d02356":"# **Predictions on Test Set**"}}