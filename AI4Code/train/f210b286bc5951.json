{"cell_type":{"34c81084":"code","2f10cf06":"code","1669b8a9":"code","9726a0fe":"code","01024c90":"code","299477af":"code","99522aed":"code","b7f07492":"code","1b292d1b":"code","14476912":"code","269e7a63":"code","21e15fb9":"code","8781e697":"code","6d58f138":"code","3bd06f33":"code","5ea384e9":"code","edae82b5":"code","4ce88bed":"code","a9c50500":"code","27fe9cd2":"code","24baa6ee":"code","ac7d6985":"code","27722f0d":"code","88e3938b":"code","53f28faf":"code","d3ed582b":"code","275d4421":"code","10d85aaa":"code","57ba9f81":"code","d6598688":"code","d5d1acfc":"code","fa0e6058":"code","371ec10a":"code","bff5c924":"code","4c9454cb":"code","4e1bbf0f":"code","0d0d69c8":"code","a7a0d1d8":"code","04b4e2c8":"markdown","9534315d":"markdown","9adde213":"markdown","4b40ca28":"markdown","047c1632":"markdown","8bb43264":"markdown","23d295a5":"markdown","8175ee13":"markdown","d40b48ed":"markdown","bea185e2":"markdown","6d1a6784":"markdown","4e5e01a9":"markdown","b8e8451c":"markdown","6e099920":"markdown","2648f272":"markdown","11f36398":"markdown","6fdb350a":"markdown","4d57672e":"markdown"},"source":{"34c81084":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2f10cf06":"import nltk\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","1669b8a9":"df = [line.strip() for line in open('..\/input\/SMSSpamCollection')]\n\nprint(len(df))","9726a0fe":"for message_no, df in enumerate(df[:5]):\n    print(message_no, df)\n    print('\\n')","01024c90":"import pandas as pd","299477af":"messages = pd.read_csv('..\/input\/SMSSpamCollection', sep='\\t', names=[\"label\", \"message\"])\n\nmessages.head()","99522aed":"messages.describe()","b7f07492":"messages.groupby('label').describe()","1b292d1b":"messages['length'] = messages['message'].apply(len)\nmessages.head()","14476912":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","269e7a63":"messages['length'].plot(bins=100, kind='hist')","21e15fb9":"messages.length.describe()","8781e697":"messages[messages['length'] == 910]['message'].iloc[0]","6d58f138":"messages.hist(column='length', by='label', bins=100, figsize=(12,4))","3bd06f33":"import string\nfrom nltk.corpus import stopwords","5ea384e9":"def text_process(mess):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    #Cek apakah karakternya berupa tanda baca (punctuation)\n    nopunc = [char for char in mess if char not in string.punctuation]\n    \n    #Menggabungkan karakter-karakternya lagi untuk membentuk data string\n    nopunc = ''.join(nopunc)\n    \n    #Menghilangkan stopwords\n    clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n    \n    return clean_mess","edae82b5":"messages['message'].head(5).apply(text_process)[3]","4ce88bed":"messages.head()","a9c50500":"from sklearn.feature_extraction.text import CountVectorizer","27fe9cd2":"bow_transformer = CountVectorizer(analyzer=text_process).fit(messages['message'])","24baa6ee":"print(len(bow_transformer.vocabulary_))","ac7d6985":"bow_transformer.vocabulary_","27722f0d":"message4 = messages['message'][3]\nprint(message4)","88e3938b":"bow4 = bow_transformer.transform([message4])\nprint(bow4)","53f28faf":"print(bow_transformer.get_feature_names()[4068])\nprint(bow_transformer.get_feature_names()[9554])","d3ed582b":"messages_bow = bow_transformer.transform(messages['message'])","275d4421":"print('Shape of Sparse matrix: ', messages_bow.shape)\nprint('Amount of Non-Zero occurences: ', messages_bow.nnz)","10d85aaa":"sparsity = (100.0 * messages_bow.nnz \/ (messages_bow.shape[0] * messages_bow.shape[1]))\nprint('sparsity: {}'.format(round(sparsity)))","57ba9f81":"from sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf_transformer = TfidfTransformer().fit(messages_bow)\ntfidf4 = tfidf_transformer.transform(bow4)\nprint(tfidf4)","d6598688":"print(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])\nprint(tfidf_transformer.idf_[bow_transformer.vocabulary_['university']])","d5d1acfc":"messages_tfidf = tfidf_transformer.transform(messages_bow)\nprint(messages_tfidf.shape)","fa0e6058":"messages_tfidf","371ec10a":"messages.label.head()","bff5c924":"from sklearn.naive_bayes import MultinomialNB\n\nspam_detect_model = MultinomialNB()\nspam_detect_model.fit(messages_tfidf, messages['label'])","4c9454cb":"print('predicted: ', spam_detect_model.predict(tfidf4)[0])\nprint('expected: ', messages.label[3])","4e1bbf0f":"all_predictions = spam_detect_model.predict(messages_tfidf)\nprint(all_predictions)","0d0d69c8":"from sklearn.metrics import classification_report,confusion_matrix\nprint (classification_report(messages['label'], all_predictions))","a7a0d1d8":"print(confusion_matrix(messages['label'], all_predictions))","04b4e2c8":"**Evalusai model**","9534315d":"Text Pre-Processing\nModel ML hanya bisa menggunakan data berupa numerik. Sedangkan data SMS ini merupakan data kumpulan teks atau strings. Jadi kita akan melakukan langkah-langkah berikut:\n1. Menghilangkan tanda baca (punctuation) dengan menggunakan string library.\n2. Menghilangkan common words atau stopwords seperti \"the\", \"a\", dan lain-lain. Untuk melakukan ini kita menggunakan NLTK library.\n3. Pendekatan bag-of-words untuk mengkonversi data teks (corpus) menjadi format vektor (kumpulan angka-angka).\n\nUntuk langkah 1 dan 2 dapat dilakukan dengan membuat fungsi di bawah ini. Nama fungsinya yaitu text_process.","9adde213":"Sebuah model bernama Natural Language Processing (NLP) adalah sub area dari artificial intelegence (AI) yang berfokus untuk membuat komputer mengerti dan memproses bahasa manusia seperti halnya manusia itu sendiri. Salah satu contoh pengaplikasian NLP yaitu untuk mengidentifikasi pesan masuk sebagai spam atau bukan. \nDi bawah ini adalah query python untuk membuat model NLP dalam identifikasi pesan sebagai spam atau bukan.","4b40ca28":"Setelah membuat fungsi di atas, kita masukan kolom message di data messages ke dalam fungsi tsb seperti query di bawah ini. Dan hasilnya kita coba tampilkan 5 teratasnya. Langkah ini juga disebut proses tokenize.","047c1632":"Dari visualisasi di atas dapat diketahui kalau pesan spam cenderung lebih panjang. Selanjutnya ","8bb43264":"Dari grafik di atas diketahui bahwa ada pesan dengan panjang sampai lebuh dari 400 atau bahkan sampai mendekati 600 panjangnya. Untuk mengetahui lebih lanjut, maka selanjutnya akan dilakukan anaisa deskriptif.","23d295a5":"Semakin banyak feature yang dimasukan ke model, maka akan membuat model tersebut semakin bagus. Jadi, kali ini kita akan menambah feature baru yaitu data seberapa panjang pesan tsb.","8175ee13":"Hanya untuk cek fungsi dari query di atas, kita akan cek kata \"u\" dan \"university\"","d40b48ed":"Sampai tahap ini, kita mendapatkan data berupa list. Jadi selanjutnya kita akan transform objek yang ada di Bag-of-Words.","bea185e2":"Langkah 3. Pendekatan bag-of-words untuk mengkonversi data teks (corpus) menjadi format vektor (kumpulan angka-angka).\nSampai dengan tahap ini, kita sudah mempunyai data messaes sebagai list dari token atau disebut juga sebagai lemmas.","6d1a6784":"Selanjutnya, untuk mengetahui secara visual tentang data, maka perlu dilakukan data visualization. ","4e5e01a9":"Atau bahkan ada yang mempunyai panjang 910 berdasarkan analisa deskriptif di atas. Apakah isi dari isi pesan panjang tsb?","b8e8451c":"**Membuat Model** \nMenggunakan algoritma Naive Bayes classifier.","6e099920":"Dari tampilan di atas dapat diketahui kalau ada dua kata (word) yang muncul dua kali, yaitu \"4068\" dan \"9554\".","2648f272":"Dapat terlihat kalau datanya berupa TSV (tab separated values), dengan pengertian datanya menggunakan spasi untuk memisahkan antar data. \nKolom pertama adalah kolom label untuk pesan yang ada di kolom kedua. Di kolom pertama dapat dilihat apakah pesan yang ada di kolom kedua sebuah spam atau bukan (ham).\nDengan menggunakan data dengan dua kolom tersebut, kita akan membangun model yang akan membedakan antara pesan spam atau bukan. ","11f36398":"Langkah selanjutnya yaitu melakukan weight untuk masing-masing kata yang nanti akhirnya masing-masing kata akan mempunyai nilai weight yang berbeda-beda. Untuk melakukan weight ini digunakan TF-IDF (term frequency-inverse document frequency).","6fdb350a":"Sedangkan untuk mentransformasi semua bagian bag-of-words ke TF-IDF, maka query-nya sebagai berikut:","4d57672e":"Di atas message ke 4 dari data yg sebelum di vectorization, sedangkan di bawah ini setelah dilakukan vectorization."}}