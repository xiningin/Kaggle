{"cell_type":{"b0fcdad9":"code","108d20e1":"code","b5dc7fa9":"code","00b7542a":"code","6739d764":"code","f81e02cc":"code","da2792a9":"code","6e94e907":"code","98a5ab7b":"code","46f99534":"code","4482c0ac":"code","a45fcc06":"code","521d70e3":"code","64fb24aa":"code","43a362a7":"code","13c3d992":"code","ec7b16ac":"code","f8b2c5f3":"code","7fe36f49":"code","8e245102":"code","17b39deb":"code","9089d9b3":"code","72032fdf":"code","4cc4195b":"code","23676df7":"code","03154f23":"code","c25b5362":"code","68c24941":"code","07eea45a":"code","8d3d063f":"code","2d3548d7":"code","2a614e6f":"code","b3676dd2":"code","6cd518cd":"code","56071436":"code","894188ca":"code","79d15234":"code","0588e73b":"code","37da1ede":"code","a07c0a08":"code","d368eeac":"code","fdddb8bc":"code","cef1a9be":"code","02705533":"code","54c67dce":"code","31032fce":"code","0f7cd3f7":"code","767d727b":"code","161be8e3":"markdown","40b7345f":"markdown","c58f4aec":"markdown","560adff8":"markdown","1a268458":"markdown","e9db7ac4":"markdown","79f31995":"markdown","31790377":"markdown","21832846":"markdown","6cd27268":"markdown","2792c37e":"markdown","bf24e213":"markdown","518f4dc8":"markdown","a026167a":"markdown","2f8ad7db":"markdown","82a44c8a":"markdown","3056957f":"markdown","c304a214":"markdown","d9adc4b1":"markdown","81c4dc4f":"markdown","c69f84f6":"markdown","751b9ff0":"markdown","dcd4be30":"markdown","e0717e0b":"markdown","97910288":"markdown"},"source":{"b0fcdad9":"#importing necissary libraries\n\nfrom numpy.random import seed\nseed(101)\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nimport os\nfrom os import listdir\nimport cv2\n\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","108d20e1":"# Removing duplicate folders to save space before running the notebook\n\nshutil.rmtree('\/kaggle\/working\/all_images_dir', ignore_errors=True)\nshutil.rmtree('\/kaggle\/working\/base_dir', ignore_errors=True)","b5dc7fa9":"files = listdir(\"..\/input\/breast-histopathology-images\/\")\nprint(len(files))","00b7542a":"#looking at first 10 folders\nfiles[0:10]","6739d764":"base_path = \"..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\/\"\nfolder = listdir(base_path)\nprint(\"No. of Patients:\",len(folder))","f81e02cc":"total_images = 0\nfor n in range(len(folder)):\n    patient_id = folder[n]\n    for c in [0, 1]:\n        patient_path = base_path + patient_id\n        class_path = patient_path + '\/' + str(c) + '\/'\n        subfiles = listdir(class_path)\n        total_images += len(subfiles)\n        \nprint(\"Total Images in dataset: \", total_images )","da2792a9":"data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n\nk = 0\nfor n in range(len(folder)):\n    patient_id = folder[n]\n    patient_path = base_path + patient_id \n    for c in [0,1]:\n        class_path = patient_path + \"\/\" + str(c) + \"\/\"\n        subfiles = listdir(class_path)\n        for m in range(len(subfiles)):\n            image_path = subfiles[m]\n            data.iloc[k][\"path\"] = class_path + image_path\n            data.iloc[k][\"target\"] = c\n            data.iloc[k][\"patient_id\"] = patient_id\n            k += 1  \n\ndata.head()","6e94e907":"data.shape","98a5ab7b":"cancer_perc = data.groupby(\"patient_id\").target.value_counts() \/ data.groupby(\"patient_id\").target.size()\ncanxer_perc = cancer_perc.unstack()\n\nfig, ax = plt.subplots(1, 3,figsize = (20,5))\nsns.distplot(data.groupby('patient_id').size(), ax=ax[0], color='Orange', kde=False, bins=30)\nax[0].set_xlabel('Number of patches')\nax[0].set_ylabel('Frequency')\nax[0].set_title('how may patches do we have per patient?')\nsns.distplot(cancer_perc.loc[:, 1]*100, ax=ax[1], color=\"Tomato\", kde=False, bins=30)\nax[1].set_title(\"How much percentage of an image is covered by IDC?\")\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"% of patches with IDC\");\nsns.countplot(data.target, palette=\"Set2\", ax=ax[2]);\nax[2].set_xlabel(\"no(0) versus yes(1)\")\nax[2].set_title(\"How many patches show IDC?\");\n","46f99534":"# coverting target to int\ndata.target = data.target.astype(np.int)","4482c0ac":"cancer_selection = np.random.choice(data[data.target == 1].index.values, size=50, replace=False)\n\nfig, ax = plt.subplots(5, 10, figsize=(20, 10))\n\nfor n in range(5):\n    for m in range(10):\n        idx = cancer_selection[m + 10*n]\n        image = imread(data.loc[idx, \"path\"])\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)\n","a45fcc06":"non_cancer_selection = np.random.choice(data[data.target == 0].index.values, size=50, replace=False)\n\nfig, ax = plt.subplots(5, 10, figsize=(20, 10))\n\nfor n in range(5):\n    for m in range(10):\n        idx = non_cancer_selection[m + 10*n]\n        image = imread(data.loc[idx, \"path\"])\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","521d70e3":"# Creating diresctory to store all images\nall_images_dir = 'all_images_dir'\n\nif os.path.isdir(all_images_dir):\n    pass\nelse:\n    os.mkdir(all_images_dir)\n    \n","64fb24aa":"# This code copies all images from their seperate folders into the same \n# folder called all_images_dir.\n\n'''\nThe directory structure is like:\n    patient_id:\n                0\n                1\n'''\n\npatient_list = folder\n\nfor patient in patient_list:\n    \n    path_0 = \"..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\/\" + str(patient) + '\/0'\n    path_1 = \"..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\/\" + str(patient) + '\/1'\n    \n    # create list of all files in folder 0\n    file_list_0 = listdir(path_0)\n    \n    #create a list of all files in folder 1\n    file_list_1 = listdir(path_1)\n    \n    # moving the 0 class images to all_images_dir\n    for fname in file_list_0:\n        \n        src = os.path.join(path_0, fname)\n        dst = os.path.join(all_images_dir, fname)\n        shutil.copyfile(src, dst)\n        \n    # moving the 1 class images to all_images_dir\n    for fname in file_list_1:\n        \n        src = os.path.join(path_1, fname)\n        dst = os.path.join(all_images_dir, fname)\n        shutil.copyfile(src, dst)\n        \n    \n        ","43a362a7":"# Total number of images\nlen(listdir(all_images_dir))","13c3d992":"image_list = os.listdir('all_images_dir')\ndf_data = pd.DataFrame(image_list, columns=['image_id'])\n\ndf_data.head()","ec7b16ac":"# Defining helper functions\n\ndef extract_patient_id(x):\n    \n    a = x.split('_')\n    patient_id = a[0]\n    \n    return patient_id\n\ndef extract_target(x):\n    \n    a = x.split('_')\n    b = a[4]\n    target = b[5]\n    \n    return target\n\n# creating new column named patient_id\ndf_data['patient_id'] = df_data['image_id'].apply(extract_patient_id)\n\n#creating new column named target\ndf_data['target'] = df_data['image_id'].apply(extract_target)\n\ndf_data.head(10)\n\n    ","f8b2c5f3":"# class distribution of the images\n\ndf_data['target'].value_counts()","7fe36f49":"SAMPLE_SIZE = 78786\n\n# take a sample of the majority class 0 (total = 198738)\ndf_0 = df_data[df_data['target'] == '0'].sample(SAMPLE_SIZE, random_state=101)\n# take a sample of class 1 (total = 78786)\ndf_1 = df_data[df_data['target'] == '1'].sample(SAMPLE_SIZE, random_state=101)\n\n# concat the two dataframes\ndf_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n\n# Check the new class distribution\ndf_data['target'].value_counts()","8e245102":"y = df_data['target']\n\ndf_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","17b39deb":"# Creating new base directory\nbase_dir ='base_dir'\nos.mkdir(base_dir)\n\n# Creating train directory inside base directory\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\n# Creating validation directory inside base directory\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\n# create new folders inside train_dir\na_no_idc = os.path.join(train_dir, 'a_no_idc')\nos.mkdir(a_no_idc)\nb_has_idc = os.path.join(train_dir, 'b_has_idc')\nos.mkdir(b_has_idc)\n\n\n# create new folders inside val_dir\na_no_idc = os.path.join(val_dir, 'a_no_idc')\nos.mkdir(a_no_idc)\nb_has_idc = os.path.join(val_dir, 'b_has_idc')\nos.mkdir(b_has_idc)\n\n\n","9089d9b3":"# check that the folders have been created\nos.listdir('base_dir\/train_dir')","72032fdf":"# Set the id as the index in df_data\ndf_data.set_index('image_id', inplace=True)","4cc4195b":"train_list = list(df_train['image_id'])\nval_list = list(df_val['image_id'])\n\n# Transfering the train images\nfor image in train_list:\n\n    try: \n        fname = image\n        target = df_data.loc[image, 'target']\n\n        if target == '0':\n            label = 'a_no_idc'\n        if target == '1':\n            label = 'b_has_idc'\n\n        # source path to image\n        src = os.path.join(all_images_dir, fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # move the image from the source to the destination\n        shutil.move(src, dst)\n    except: \n        continue\n\nfor image in val_list:\n\n    try: \n        fname = image\n        target = df_data.loc[image,'target']\n\n        if target == '0':\n            label = 'a_no_idc'\n        if target == '1':\n            label = 'b_has_idc'\n\n\n        # source path to image\n        src = os.path.join(all_images_dir, fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # move the image from the source to the destination\n        shutil.move(src, dst)\n\n    except:\n        continue\n\n        ","23676df7":"# check how many val images we have in each folder\nprint(len(os.listdir('base_dir\/train_dir\/a_no_idc')))\nprint(len(os.listdir('base_dir\/train_dir\/b_has_idc')))","03154f23":"train_path = 'base_dir\/train_dir'\nvalid_path = 'base_dir\/val_dir'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\n\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\nval_steps = np.ceil(num_val_samples \/ val_batch_size)","c25b5362":"IMAGE_SIZE = 50","68c24941":"\ndatagen = ImageDataGenerator(rescale = 1.0 \/ 255,\n                             rotation_range = 90,\n                             zoom_range = 0.2,\n                             horizontal_flip=True,\n                             vertical_flip=True)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)","07eea45a":"# Building the model\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', \n                 input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()","8d3d063f":"model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n              metrics=['accuracy'])","2d3548d7":"filepath = \"model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=50, verbose=1,\n                   callbacks=callbacks_list)\n\ntry:\n    model.save('\/kaggle\/working\/model.h5')\nexcept:\n    pass\n\ntry:\n    model.save('model.h5')\nexcept:\n    pass","2a614e6f":"model.save('model.h5')","b3676dd2":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","6cd518cd":"# Here the best epoch will be used.\n\nmodel.load_weights('model.h5')\n\nval_loss, val_acc = \\\nmodel.evaluate_generator(test_gen, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","56071436":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()","894188ca":"# make a prediction\npredictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)","79d15234":"predictions.shape","0588e73b":"# This is how to check what index keras has internally assigned to each class. \ntest_gen.class_indices","37da1ede":"# Put the predictions into a dataframe.\n# The columns need to be oredered to match the output of the previous cell\n\ndf_preds = pd.DataFrame(predictions, columns=['no_idc', 'has_idc'])\n\ndf_preds.head()","a07c0a08":"# Get the true labels\ny_true = test_gen.classes\n\n# Get the predicted labels as probabilities\ny_pred = df_preds['has_idc']","d368eeac":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_true, y_pred)","fdddb8bc":"def plot_confusion_matrix(cm, classes,\n                         normalize=False,\n                         title='Confusion Matrix',\n                         cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n        \n    print(cm)\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n        ","cef1a9be":"# Get the labels of the test images.\n\ntest_labels = test_gen.classes","02705533":"test_labels.shape","54c67dce":"# argmax returns the index of the max value in a row\ncm = confusion_matrix(test_labels, predictions.argmax(axis=1))","31032fce":"# Print the label associated with each class\ntest_gen.class_indices","0f7cd3f7":"# Define the labels of the class indices. These need to match the \n# order shown above.\ncm_plot_labels = ['a_no_idc', 'b_has_idc']\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","767d727b":"from sklearn.metrics import classification_report\n\n# Generate a classification report\n\n# For this to work we need y_pred as binary labels not as probabilities\ny_pred_binary = predictions.argmax(axis=1)\n\nreport = classification_report(y_true, y_pred_binary, target_names=cm_plot_labels)\n\nprint(report)","161be8e3":"### Balance the class distribution\n\n* We can see that the class 1 images are higher in number that of class 0\n\n* So to prevent this we balance the dataset\n\n* We do this so that the Neural Network dose not lean on favouring only one class ","40b7345f":"### Displaying Cnacer Tissue Samples","c58f4aec":"### Creating dataframe of all images","560adff8":"### Creating train and test sets","1a268458":"### Setting up image generators","e9db7ac4":"#### In each folder there are several images and each folder name is the id of the patient","79f31995":"### Insights\n\n* The numbe rof image patches per patient varie's a lot.\n\n* Some patients have more than 80 % patches that show IDC! Consequently the tissue is full of cancer or only a part of the breast was covered by the tissue slice that is focused on the IDC cancer. \n\n* The classes of IDC versus no IDC are imbalanced.","31790377":"## Preparing the dataset","21832846":"**Recall** = Given a class, will the classifier be able to detect it?<br>\n**Precision** = Given a class prediction from a classifier, how likely is it to be correct?<br>\n**F1 Score** = The harmonic mean of the recall and precision. Essentially, it punishes extreme values.","6cd27268":"### Calculating the AUC Score","2792c37e":"### Make a prediction on the val set\nWe need these predictions to calculate the AUC score, print the Confusion Matrix and calculate the F1 score.","bf24e213":"### Evaluating the model","518f4dc8":"## Exploring the Data Structure","a026167a":"### Creating Directory Structure","2f8ad7db":"#### We have to find the number of total images in the dataset","82a44c8a":"#### Shape of data frame[](http:\/\/)","3056957f":"### Training the model","c304a214":"### Conclusion\n\n* From the above report we can see that the model gives us admirable results.\n\n* The model can be improved.\n\n* The recall for each class should be ideally be above 0.90\n\n* This model can help pathologists detect cancer on tissue faster\n\n* The manual examining of tissue slides would not be required","d9adc4b1":"### Insights\n\n* Cancer Tissur appears to be more viloet.\n\n* But some non-caner tissue is also violet.\n","81c4dc4f":"### Plotting the training curves","c69f84f6":"### Displaying Non-Cnacer Tissue Samples","751b9ff0":"## Exploring the data","dcd4be30":"### Creating the confusion matrix","e0717e0b":"#### Organizing the data into pandas data frame","97910288":"### Creating a classfifcation Report"}}