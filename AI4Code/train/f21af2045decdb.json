{"cell_type":{"ad276352":"code","246b6547":"code","e87b42e1":"code","132f7972":"code","5766455c":"code","29e2b913":"code","e8364ff1":"code","c71a7c05":"code","bfc1fa2f":"code","f70c8947":"code","e404c5c0":"code","bcf66990":"code","6039af65":"code","15765140":"code","a1db62da":"code","36217911":"code","75bb9887":"code","e9d06f7e":"code","c7f06166":"code","c833f062":"code","7df57223":"code","b90b132f":"code","4319cc6e":"code","2e4547e4":"code","31fa3f0a":"code","7921d93a":"code","0b2d0f86":"code","48f84817":"code","2c020e4a":"code","e9db0383":"code","db27c789":"markdown","b41dae40":"markdown","bc91bdf2":"markdown","bebdf4bb":"markdown","00cc1d62":"markdown","0478dbaf":"markdown","06b41c9d":"markdown","9e42e31d":"markdown","5f340f99":"markdown","4b56bf67":"markdown","2163e4e6":"markdown","c9f470e6":"markdown","02f9817d":"markdown","f0525bf8":"markdown","92f422d2":"markdown","8be0fe2a":"markdown","249dc3b8":"markdown","9b4dcc3d":"markdown","a7faaef1":"markdown"},"source":{"ad276352":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\n#from bokeh.plotting import figure, show, output_notebook\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\n\nplt.style.use(\"ggplot\") # Set plot style\n%matplotlib inline","246b6547":"df = pd.read_csv(r\"..\/input\/hourly-energy-consumption\/PJME_hourly.csv\")","e87b42e1":"df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"])\n\n#Date features\ndf[\"Hour\"] = df[\"Datetime\"].dt.hour\ndf[\"Day\"] = df[\"Datetime\"].dt.dayofweek\ndf[\"Month\"] = df[\"Datetime\"].dt.month\ndf[\"Year\"] = df[\"Datetime\"].dt.year\ndf[\"Q\"] = df[\"Datetime\"].dt.quarter\ndf[\"Dayofyear\"] = df[\"Datetime\"].dt.dayofyear\ndf[\"Dayofmonth\"] = df[\"Datetime\"].dt.day\ndf[\"Weekofyear\"] = df[\"Datetime\"].dt.weekofyear\n\ndf[\"Drop_me\"] = df[\"Datetime\"].dt.strftime(\"%m-%d\")\n\ndf.index = df[\"Datetime\"]\ndf = df.drop([\"Datetime\"],axis=1)","132f7972":"df.head()","5766455c":"ax, fig = plt.subplots(figsize=(10,5))\n\nplt.hist(df[\"PJME_MW\"])\n\nplt.yticks(alpha=0.75, weight=\"bold\")\n\nplt.xlabel(\"\",alpha=0.75, weight=\"bold\")\nplt.ylabel(\"\",alpha=0.75, weight=\"bold\")\n\nplt.title(\"Consumption distribution\", alpha=0.60, weight=\"bold\", fontsize=15, loc=\"left\", pad=10)","29e2b913":"#Data prep\nQ1 = df[df[\"Q\"]==1]\nQ2 = df[df[\"Q\"]==2]\nQ3 = df[df[\"Q\"]==3]\nQ4 = df[df[\"Q\"]==4]\n\n#Plot\nfig,axes = plt.subplots(2,2,figsize=(17,7),sharex=True,sharey=True)\n\nsns.distplot(Q1[\"PJME_MW\"],color=\"skyblue\", ax=axes[0,0]).set_title(\"Q1 - Consumption\")\nsns.distplot(Q2[\"PJME_MW\"],color=\"red\", ax=axes[0,1]).set_title(\"Q2 - Consumption\")\nsns.distplot(Q3[\"PJME_MW\"],color=\"green\", ax=axes[1,0]).set_title(\"Q3 - Consumption\")\nsns.distplot(Q4[\"PJME_MW\"],color=\"gray\", ax=axes[1,1]).set_title(\"Q4 - Consumption\")\n\ndel Q1, Q2, Q3, Q4","e8364ff1":"#Data prep\nmean_per_day = df.groupby(\"Day\")[\"PJME_MW\"].agg([\"mean\"])\n\n#Plot\nfig, ax = plt.subplots(figsize=(10,5))\n\n\nplt.plot(mean_per_day.index,mean_per_day[\"mean\"])\n\nplt.xticks(mean_per_day.index, [\"Monday\",\"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\",\"Sunday\"], alpha=0.75, weight=\"bold\")\nplt.yticks(alpha=0.75, weight=\"bold\")\n\nplt.xlabel(\"Day of the week\",alpha=0.75, weight=\"bold\")\nplt.ylabel(\"Mean consumption\",alpha=0.75, weight=\"bold\")\n\nplt.title(\"Mean daily consumption\", alpha=0.60, weight=\"bold\", fontsize=15, loc=\"left\", pad=10)\n\n#del mean_per_day","c71a7c05":"#Data\nmean_per_hour = df.groupby(\"Hour\")[\"PJME_MW\"].agg([\"mean\"])\n\n#Plot\nfig, ax = plt.subplots(figsize=(10,5))\n\nplt.bar(mean_per_hour.index, mean_per_hour[\"mean\"])\n\nplt.xticks(range(24),alpha=0.75, weight=\"bold\")\nplt.yticks(alpha=0.75, weight=\"bold\")\n\nplt.xlabel(\"Hour\",alpha=0.75, weight=\"bold\")\nplt.ylabel(\"Mean consumption\",alpha=0.75, weight=\"bold\")\n\nplt.title(\"Mean hourly consumption\", alpha=0.60, weight=\"bold\", fontsize=15, loc=\"left\", pad=10)\n\ndel mean_per_hour","bfc1fa2f":"fig,ax = plt.subplots(figsize=(15,5))\n\nplt.plot(df.index,df[\"PJME_MW\"])\n\nplt.xlabel(\"Date\", alpha=0.75, weight=\"bold\")\nplt.ylabel(\"Consumption\", alpha=0.75, weight=\"bold\")\n\nplt.xticks(alpha=0.75,weight=\"bold\", fontsize=11)\nplt.yticks(alpha=0.75,weight=\"bold\", fontsize=11)\n\nplt.title(\"Consumption over time\", alpha=0.75, weight=\"bold\", fontsize=15, pad=10, loc=\"left\")","f70c8947":"#Be ready for some bruteforce if functions\ndef feature_holidays(row):\n\n    if row[\"Drop_me\"] == \"01-01\":\n        return \"New Year\"\n    if row[\"Drop_me\"] == \"04-07\":\n        return \"Ind Day\"\n    if row[\"Drop_me\"] == \"11-28\":\n        return \"Thanksgiving\"\n    if row[\"Drop_me\"] == \"12-25\":\n        return \"Christmas\"\n    return 'Other'\ndef feature_worktime(row):\n    if row[\"Hour\"] > 7 & row[\"Hour\"] <= 17:\n        return \"Worktime\"\n    return \"NonWorkTime\"\ndef feature_peak(row):\n    if row[\"Hour\"] > 7 & row[\"Hour\"] <= 22:\n        return \"Peak\"\n    return \"NonPeak\"\ndef feature_weekend(row):\n    if row[\"Day\"] == 5 or row[\"Day\"] == 6:\n        return \"Weekend\"\n    return \"NonWeekend\"","e404c5c0":"df[\"Holiday\"] = df.apply (lambda row : feature_holidays(row), axis=1)\ndf[\"Work\"] = df.apply(lambda row: feature_worktime(row), axis=1)\ndf[\"Peak\"] = df.apply(lambda row: feature_peak(row), axis=1)\ndf[\"Weekend\"] = df.apply(lambda row: feature_weekend(row), axis=1)","bcf66990":"df = df.drop([\"Drop_me\"],axis=1)","6039af65":"dummies = pd.get_dummies(df[[\"Holiday\",\"Peak\",\"Work\",\"Weekend\"]],prefix=\"Dummy\")\ndf = df.join(dummies,lsuffix=\"_left\")\ndf = df.drop(df[[\"Holiday\",\"Peak\",\"Work\",\"Weekend\"]], axis=1)","15765140":"train_test_date = \"01-01-2015\"\nconsum_test = df[df.index > train_test_date].copy()\nconsum_train = df[df.index <= train_test_date].copy()","a1db62da":"def lag_features(lag_dataset,period_list):\n\n    temp_data = lag_dataset[\"PJME_MW\"]\n\n    for period in period_list:\n\n        lag_dataset[\"lag_consumption_{}\".format(period)] = temp_data.shift(period)\n        lag_dataset[\"mean_rolling_{}\".format(period)] = temp_data.rolling(period).mean()\n        lag_dataset[\"max_rolling_{}\".format(period)] = temp_data.rolling(period).max()\n        lag_dataset[\"min_rolling_{}\".format(period)] = temp_data.rolling(period).min()\n\n    for column in lag_dataset.columns[20:]:\n\n        lag_dataset[column] = lag_dataset[column].fillna(lag_dataset.groupby(\"Hour\")[\"PJME_MW\"].transform(\"mean\"))\n    \n    return lag_dataset","36217911":"consum_train = lag_features(consum_train,[7,14,30])\n\nconsum_test = lag_features(consum_test,[7,14,30])","75bb9887":"fig,ax = plt.subplots(figsize=(15,5))\n\ncoloring = 70000\n\nplt.plot(consum_train.index,consum_train[\"PJME_MW\"],color=\"blue\", alpha=0.75)\nplt.fill_between(consum_train.index,coloring, facecolor=\"blue\", alpha=0.2)\n\nplt.plot(consum_test.index,consum_test[\"PJME_MW\"], color = \"red\", alpha=0.60)\nplt.fill_between(consum_test.index,coloring, facecolor=\"red\", alpha=0.2)\n\nplt.xlabel(\"Date\", alpha=0.75, weight=\"bold\")\nplt.ylabel(\"Consumption\", alpha=0.75, weight=\"bold\")\n\nplt.xticks(alpha=0.75,weight=\"bold\", fontsize=11)\nplt.yticks(alpha=0.75,weight=\"bold\", fontsize=11)\n\nplt.title(\"Train - Test Split\", alpha=0.75, weight=\"bold\", fontsize=15, pad=10, loc=\"left\")","e9d06f7e":"#Train - Test\nX_train = consum_train.drop(\"PJME_MW\", axis=1) \ny_train = consum_train[\"PJME_MW\"]\nX_test = consum_test.drop(\"PJME_MW\", axis=1)\ny_test = consum_test[\"PJME_MW\"]","c7f06166":"#XGBoost\n\nxgd_reg = xgb.XGBRegressor(n_estimators=1000)\n\nxgd_reg.fit(X_train,y_train,\n           eval_set=[(X_train,y_train),(X_test,y_test)],\n           early_stopping_rounds=50,\n           verbose=False)","c833f062":"plot_importance(xgd_reg)","7df57223":"consum_test[\"Prediction\"] = xgd_reg.predict(X_test)","b90b132f":"fig,ax = plt.subplots(figsize=(15,5))\n\nplt.plot(consum_train.index,consum_train[\"PJME_MW\"],alpha=.3)\nplt.plot(consum_test.index,consum_test[\"Prediction\"])\nplt.plot(consum_test.index,consum_test[\"PJME_MW\"],alpha=.3)\n\nplt.xlabel(\"Date\", alpha=0.75, weight=\"bold\")\nplt.ylabel(\"Consumption\", alpha=0.75, weight=\"bold\")\n\nplt.xticks(alpha=0.75,weight=\"bold\", fontsize=11)\nplt.yticks(alpha=0.75,weight=\"bold\", fontsize=11)\n\nplt.title(\"Predicted consumption\", alpha=0.75, weight=\"bold\", fontsize=15, pad=10, loc=\"left\")","4319cc6e":"fig,(ax1,ax2) = plt.subplots(2,1,figsize=(15,10),sharey=True)\n\nax1.plot(consum_test.index,consum_test[\"PJME_MW\"],alpha=0.75)\nax2.plot(consum_test.index,consum_test[\"Prediction\"],color=\"blue\",alpha=0.50)\n\nax1.set_xlabel(\"Date\", alpha=0.75, weight=\"bold\")\nax1.set_ylabel(\"Consumption\", alpha=0.75, weight=\"bold\")\nax2.set_xlabel(\"Date\", alpha=0.75, weight=\"bold\")\nax2.set_ylabel(\"Consumption\", alpha=0.75, weight=\"bold\")\n\nax1.set_title(\"Actual consumption\", alpha=0.75, weight=\"bold\", fontsize=15, pad=10, loc=\"left\")\nax2.set_title(\"Predicted consumption\", alpha=0.75, weight=\"bold\", fontsize=15, pad=10, loc=\"left\")","2e4547e4":"mean_sq = mean_squared_error(y_test,xgd_reg.predict(X_test))\nrmse = np.sqrt(mean_sq)\n\nmean_abs_sq = mean_absolute_error(y_test,xgd_reg.predict(X_test))\n\nprint(\"Root Mean Squared Error : {}\".format(rmse))\nprint(\"Mean Absolute Error : {}\".format(mean_abs_sq))","31fa3f0a":"# Worst Hour Prediction\nconsum_test[\"Difference\"] = np.abs(consum_test[\"PJME_MW\"] - consum_test[\"Prediction\"])\nconsum_test[\"Difference\"].sort_values(ascending=False)[:10]","7921d93a":"fig,ax= plt.subplots(figsize=(15,5))\n\n\nax.plot(consum_test.index,consum_test[\"PJME_MW\"],label=\"Actual\")\nax.plot(consum_test.index,consum_test[\"Prediction\"],alpha=.5,zorder=10,label=\"Predicted\")\n\nconsum = consum_test[\"PJME_MW\"]\npred = consum_test[\"Prediction\"]\n\nplt.fill_between(consum_test.index, consum,pred, facecolor=\"green\", alpha=.2,label=\"Difference\")\n\nax.set_ylim(25000, 45000)\nax.set_xbound(lower=\"2017-03-12 00:00:00\", upper=\"2017-03-12 23:30:00\")\n\nplt.xlabel(\"Date\", alpha=0.75, weight=\"bold\")\nplt.ylabel(\"Consumption\", alpha=0.75, weight=\"bold\")\n\nplt.xticks(alpha=0.75,weight=\"bold\", fontsize=11)\nplt.yticks(alpha=0.75,weight=\"bold\", fontsize=11)\n\nplt.title(\"Period with the worst hourly prediction\", alpha=0.75, weight=\"bold\", fontsize=15, pad=10, loc=\"left\")\nplt.legend()","0b2d0f86":"#Worst Days\nworst_days = consum_test.groupby(['Year','Month','Dayofmonth']).mean()[['PJME_MW','Prediction','Difference']]\nworst_days.sort_values(by=\"Difference\",ascending=False)[:10]","48f84817":"fig,ax= plt.subplots(figsize=(15,5))\n\n\nax.plot(consum_test.index,consum_test[\"PJME_MW\"],label=\"Actual\")\nax.plot(consum_test.index,consum_test[\"Prediction\"],color=\"red\",alpha=.5,zorder=10,label=\"Predicted\")\n\nconsum = consum_test[\"PJME_MW\"]\npred = consum_test[\"Prediction\"]\n\nplt.fill_between(consum_test.index, consum,pred, facecolor=\"green\", alpha=.2,label=\"Difference\")\n\nax.set_ylim(20000, 40000)\nax.set_xbound(lower=\"2016-02-20\", upper=\"2016-02-25\")\n\nplt.xlabel(\"Date\", alpha=0.75, weight=\"bold\")\nplt.ylabel(\"Consumption\", alpha=0.75, weight=\"bold\")\n\nplt.xticks(alpha=0.75,weight=\"bold\", fontsize=11)\nplt.yticks(alpha=0.75,weight=\"bold\", fontsize=11)\n\nplt.title(\"Period with the worst daily prediction\", alpha=0.75, weight=\"bold\", fontsize=15, pad=10, loc=\"left\")\n\nplt.legend()","2c020e4a":"#Best Days\nworst_days.sort_values(by=\"Difference\",ascending=True)[:10]","e9db0383":"fig,ax= plt.subplots(figsize=(15,5))\n\nax.plot(consum_test.index,consum_test[\"PJME_MW\"], label=\"Actual\")\nax.plot(consum_test.index,consum_test[\"Prediction\"], label=\"Predicted\")\nconsum = consum_test[\"PJME_MW\"]\npred = consum_test[\"Prediction\"]\n\nplt.fill_between(consum_test.index, consum,pred, facecolor=\"green\", alpha=.2,label=\"Difference\")\n\nax.set_ylim(20000, 35000)\nax.set_xbound(lower=\"2015-10-28\", upper=\"2015-10-30\")\n\nplt.xlabel(\"Date\", alpha=0.75, weight=\"bold\")\nplt.ylabel(\"Consumption\", alpha=0.75, weight=\"bold\")\n\nplt.xticks(alpha=0.75,weight=\"bold\", fontsize=11)\nplt.yticks(alpha=0.75,weight=\"bold\", fontsize=11)\n\nplt.title(\"Period with the best daily prediction\", alpha=0.75, weight=\"bold\", fontsize=15, pad=10, loc=\"left\")\n\n\nplt.legend()","db27c789":"**Feature engineering - Part I**","b41dae40":"The actual consumption is again covered by the predicted consumption. We have to resort to evaluation metrics.","bc91bdf2":"# ** Conslusion **  \n\n\nThe energy prediction model with XGBoost turned out rather good. It was a fun little project and I am more or less content with the results. However, future iterations of this model need to take into account the information we gained with the feature importance plot. Additionally, it might also be a good idea to try different encoding methods for categorical variables to boost performance.\n\n","bebdf4bb":"There are some major differences in the consumption distribution per quarter. This might be due to several factors, the most obvious being seasonal demand changes. Another major factor is the general temperature in the area. Higher temperatures encourage more electricity usage as office buildings and homes require cooling.","00cc1d62":"Looking at hourly consumption we can clearly see the peak and off-peak  hours of the area.","0478dbaf":"The distribution plot is slightly left-skewed, with the majority of the consumption moving around the 30-35k range.","06b41c9d":"During the second part, we will add columns that will help train the model and help it predict future consumption.\n\nThe categorical features added are:\n\n1.\tHolidays - I included some more famous American holidays.\n2.\tWorktime - If the half-hourly consumption demand happened during the usual worktime of most companies.\n3. \tPeak\/Off-Peak - I diverted this feature from the EDA above.\n4.\tWeekend\/NonWeekend - If the day is a working day or not. I am aware that this might be duplicating information as we have other columns that that indicate the exact day, but I would nonetheless like to cover all my bases.\n\nThe numerical features:\n\n1. Lag Variables - a shift in the data. I will explain more about this when we reach the cell.\n2. Temperature data (not included) - I initially wanted to include the average temperature for each day. Unfortunately,  this is an RTO and as the name implies it covers multiple regions\/states so getting and implementing good data was too difficult for now.\n\n","9e42e31d":"# **Introduction**\n\nThis dataset was acquired from an RTO (regional transmission organization) called PJM Interconnection LLC. Regional transmission organizations control and coordinate multi-state grids that span across state borders. They were created to promote energy efficiency, reliability, and non-discriminatory practices. The introduction of RTOs largely changed the economic landscape of some states as before their creation individual states had a monopoly on the generation and distribution of electricity within their state. \n\nPJM Interconnection LLC is responsible for the eastern states like Delaware, Illinois, Indiana, Kentucky, etc. The consumption data is displayed in MW.\n\nIn the notebook below I will perform an exploratory data analysis and build a time series prediction model using the XGBoost machine learning algorithm. My main goal is to find some interesting insights and correlations between the time and consumption data.","5f340f99":"The predicted value covers most of the actual value on the plot. This can either be very good or very bad. We need to inquire further.","4b56bf67":"\n\nThe feature engineering part was split into two for practical purposes. Part one contains features that were diverted from the DateTime column without too much data manipulation.","2163e4e6":"We are going to take a closer look at the dataset and highlight some interesting patterns in the consumption data.","c9f470e6":"Below we are separating the dataset based on a date.","02f9817d":"# **Initial look**","f0525bf8":"# **Importing the dataset**","92f422d2":"Looking at the consumption data as a whole we can very clearly see a pattern with peaks and valleys. While the baseline consumption stayed pretty much the sam on around 20.000. ","8be0fe2a":"Lag variables are a classic approach to solving supervised regression problems on a time series dataset. The logic behind it is very simple, it uses the last variable to predict the next one. This adds additional features to the dataset and is usually very helpful.\n\nThere is, unfortunately, a downside to using Lag variables. They produce some NA values in the columns where the data is not available forcing us to drop them. This can severely reduce the number of rows we have for the training and testing of the algorithm. ","249dc3b8":"The plot importance option of XGBoost allows us to evaluate what features are good if we would like to use this algorithm in an automated pipeline or for any future use. In this instance, the F-score represents a simple metric that measures how many times the feature was used during the tree splitting.","9b4dcc3d":"# **Importing libraries**","a7faaef1":"The plot above showcases the cumulative consumption per day. We can very clearly see that days matter when it comes to consumption. The lowest usage is usually marked on the weekends as most commercial and industrial areas stay closed reducing the overall consumption of the area."}}