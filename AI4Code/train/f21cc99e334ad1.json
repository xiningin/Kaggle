{"cell_type":{"c1ce3d49":"code","c741cdf1":"code","8e1652b3":"code","f5f028af":"code","ecb92394":"code","e9d87c11":"code","744b0aee":"code","cd311b91":"code","20362a98":"code","759ff6db":"code","47b64041":"code","982a749e":"code","8acf88c1":"code","80e36037":"code","3f1440bd":"code","16943ec6":"code","1a78c56d":"code","832979a1":"code","bd30623f":"code","f75be158":"code","55cb05a4":"code","d12331d8":"code","be9071a0":"code","701a7b78":"code","a5714bfa":"code","e16c2b5f":"code","58a50b3a":"code","0c3718f3":"code","dbc14281":"code","56ab336d":"code","5bd35993":"code","11d52baf":"code","a9a9224c":"code","decc386b":"code","d8e202a6":"code","89051315":"code","d378c40d":"markdown","1b90175e":"markdown","c92aedf7":"markdown","6984d0ad":"markdown","8260f94b":"markdown","943f6589":"markdown","23428258":"markdown","8981ddd4":"markdown"},"source":{"c1ce3d49":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn.model_selection import train_test_split\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","c741cdf1":"cardata=pd.read_csv('..\/input\/mtcars\/mtcars.csv')","8e1652b3":"cardata.head()","f5f028af":"cardata.rename(columns = {'Unnamed: 0':'model'}, inplace = True) ","ecb92394":"cardata.head()","e9d87c11":"cardata.info()","744b0aee":"cardata.isnull().sum()","cd311b91":"cardata.describe()","20362a98":"cardata.columns","759ff6db":"sns.pairplot(cardata)","47b64041":"plt.figure(figsize=(10,8))\nsns.heatmap(cardata.corr(),annot=True)","982a749e":"cardata.corr()","8acf88c1":"# Mileage has strong negative correlation with cyl,displacemnet,horsepower\ncardata.head()","80e36037":"# Find feature and target variable\ncardata.drop(columns=['model'],axis=1,inplace=True)","3f1440bd":"cardata.describe()","16943ec6":"# Treating outliers for the target variable\n\nupper_limit= 22.8 + (1.5* (22.8-15.4))\nlower_limit= 15.4 - (1.5* (22.8-15.4))\nupper_limit,lower_limit","1a78c56d":"cardata=cardata[cardata.mpg<33.9]\ncardata=cardata[cardata.mpg>4.3]\ncardata.shape","832979a1":"cardata.head()","bd30623f":"X=cardata.drop(columns=['mpg'],axis=1)\nX.head()","f75be158":"y=cardata['mpg']","55cb05a4":"from sklearn.model_selection import train_test_split\n\nX_train, X_test , y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","d12331d8":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nmodel = lin_reg.fit(X_train,y_train)\nprint(f'R^2 score for train: {lin_reg.score(X_train, y_train)}')\nprint(f'R^2 score for test: {lin_reg.score(X_test, y_test)}')","be9071a0":"# Raw OLS model.\nimport warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","701a7b78":"\nimport statsmodels.tsa.api as smt\n\nacf = smt.graphics.plot_acf(lin_reg.resid, lags=10 , alpha=0.05)\nacf.show()","a5714bfa":"from scipy import stats\nprint(stats.jarque_bera(lin_reg.resid))","e16c2b5f":"import seaborn as sns\n\nsns.distplot(lin_reg.resid)","58a50b3a":"import statsmodels.api as sm\nsm.stats.diagnostic.linear_rainbow(res=lin_reg, frac=0.5)\nimport scipy.stats as stats\nimport pylab\nfrom statsmodels.graphics.gofplots import ProbPlot\nst_residual = lin_reg.get_influence().resid_studentized_internal\nstats.probplot(st_residual, dist=\"norm\", plot = pylab)\nplt.show()","0c3718f3":"%matplotlib inline\n%config InlineBackend.figure_format ='retina'\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport statsmodels.stats.api as sms\nsns.set_style('darkgrid')\nsns.mpl.rcParams['figure.figsize'] = (15.0, 9.0)\n\ndef linearity_test(model, y):\n    '''\n    Function for visually inspecting the assumption of linearity in a linear regression model.\n    It plots observed vs. predicted values and residuals vs. predicted values.\n    \n    Args:\n    * model - fitted OLS model from statsmodels\n    * y - observed values\n    '''\n    fitted_vals = model.predict()\n    resids = model.resid\n\n    fig, ax = plt.subplots(1,2)\n    \n    sns.regplot(x=fitted_vals, y=y, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n    ax[0].set_title('Observed vs. Predicted Values', fontsize=16)\n    ax[0].set(xlabel='Predicted', ylabel='Observed')\n\n    sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[1], line_kws={'color': 'red'})\n    ax[1].set_title('Residuals vs. Predicted Values', fontsize=16)\n    ax[1].set(xlabel='Predicted', ylabel='Residuals')\n    \nlinearity_test(lin_reg, y)  ","dbc14281":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index=X.columns).T","56ab336d":"cardata.columns","5bd35993":"\nX=cardata[['cyl', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear',\n       'carb']]\ny=cardata['mpg']","11d52baf":"X_train, X_test , y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","a9a9224c":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'Intercept: {lin_reg.intercept_}')\nprint(f'R^2 score: {lin_reg.score(X, y)}')","decc386b":"X_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","d8e202a6":"from sklearn.model_selection import train_test_split\nX_train, X_test , y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","89051315":"lin_reg = LinearRegression()\nmodel = lin_reg.fit(X_train,y_train)\nprint(f'R^2 score for train: {lin_reg.score(X_train, y_train)}')\nprint(f'R^2 score for test: {lin_reg.score(X_test, y_test)}')","d378c40d":"# Check assumptions for linear regression","1b90175e":"## No Auto-correlation","c92aedf7":"## Multi Correlation","6984d0ad":"## Leanearity in Residuals","8260f94b":"## Normality in Residuals","943f6589":"## Linearity","23428258":"## Removing Correlated Features","8981ddd4":"# Upvote if you like my work."}}