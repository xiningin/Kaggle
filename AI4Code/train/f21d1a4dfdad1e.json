{"cell_type":{"ea49ab44":"code","dd844c73":"code","b89795f0":"code","b7237835":"code","dd89c924":"code","8ca6202f":"code","8e8dce20":"code","34486d44":"code","46d78ca3":"code","3b8f832f":"code","7ff52273":"code","85790d29":"code","cd25e3cf":"code","ab7a45dd":"code","9d99c319":"code","af585d48":"code","abf5b3d3":"code","c7d75b38":"code","b9718146":"code","462e00b0":"code","035ad113":"code","e5030b1d":"code","3ab55dd4":"code","f4c25cfc":"code","3ad451f9":"markdown"},"source":{"ea49ab44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd844c73":"# Imports required for this project\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\ntf.random.set_seed(4)","b89795f0":"# Creating the Pathlib PATH objects\ntrain_path = Path(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\")\nvalidation_path = Path(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\")\ntest_path = Path(\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\")","b7237835":"# Collecting all the Paths Inside \"Normal\" and \"Pneumonia\" folders of the above paths\ntrain_image_paths = train_path.glob(\"*\/*\")\nval_image_paths = validation_path.glob(\"*\/*\")\n\n# Output is a Generator object\nprint(train_image_paths)","dd89c924":"# Convert Generator Object to List of elements \ntrain_image_paths = list(train_image_paths)\nval_image_paths = list(val_image_paths)\n\n# Now the outputs are \"PosixPath\" objects\nprint(train_image_paths[:3])","8ca6202f":"# Convert Posix paths to normal strings\ntrain_image_paths = list(map(lambda x : str(x) , train_image_paths))\nval_image_paths = list(map(lambda x : str(x) , val_image_paths)) \n\nprint(train_image_paths[:3])","8e8dce20":"# Collect Length for Training and Validation Datasets\ntrain_dataset_length = len(train_image_paths)\nval_dataset_length = len(val_image_paths)","34486d44":"# Every Image has Label in its path , so lets slice it \nLABELS = {'NORMAL' : 0 , 'PNEUMONIA' : 1}\nINV_LABELS = {0 : 'NORMAL', 1 : 'PNEUMONIA'}\n\ndef get_label(path : str) -> int:\n    return LABELS[path.split(\"\/\")[-2]]\n\ntrain_labels = list(map(lambda x : get_label(x) , train_image_paths))\nval_labels = list(map(lambda x : get_label(x) , val_image_paths))\n\nprint(train_labels[:3])","46d78ca3":"# Now we have all training, validation image paths and their respective labels \n\nBATCH_SIZE = 32\n\n# Function used for Transformation\ndef load_and_transform(image , label , train = True):\n    image = tf.io.read_file(image)\n    image = tf.io.decode_jpeg(image , channels = 3)\n    image = tf.image.resize(image , [224 , 224] , method=\"nearest\")\n    if train:\n        image = tf.image.random_flip_left_right(image)\n    return image , label\n\n# Function used to Create a Tensorflow Data Object\ndef get_dataset(paths , labels , train = True):\n    image_paths = tf.convert_to_tensor(paths)\n    labels = tf.convert_to_tensor(labels)\n\n    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n\n    dataset = tf.data.Dataset.zip((image_dataset , label_dataset)).shuffle(1000)\n\n    dataset = dataset.map(lambda image , label : load_and_transform(image , label , train))\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n\n    return dataset","3b8f832f":"# Creating Train Dataset object and Verifying it\n%time train_dataset = get_dataset(train_image_paths , train_labels)\n\nimage , label = next(iter(train_dataset))\nprint(image.shape)\nprint(label.shape)","7ff52273":"# View a sample Train Image\nprint(INV_LABELS[label[0].numpy()])\nplt.imshow(image[0].numpy().reshape(224 , 224 , 3))","85790d29":"%time val_dataset = get_dataset(val_image_paths , val_labels , train = False)\n\nimage , label = next(iter(val_dataset))\nprint(image.shape)\nprint(label.shape)","cd25e3cf":"# View a sample Validation Image\nprint(INV_LABELS[label[0].numpy()])\nplt.imshow(image[0].numpy().reshape(224 , 224 , 3))","ab7a45dd":"# Building ResNet50 model\nfrom tensorflow.keras.applications import ResNet50V2\n\nbackbone = ResNet50V2(\n    input_shape=(224, 224, 3),\n    include_top=False\n)\n\nmodel = tf.keras.Sequential([\n    backbone,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","9d99c319":"# Compiling your model by providing the Optimizer , Loss and Metrics\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    loss = 'binary_crossentropy',\n    metrics=['accuracy' , tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')]\n)","af585d48":"# Defining our callbacks \ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"best_weights.h5\",verbose=1,save_best_only=True,save_weights_only = True)\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=4)","abf5b3d3":"# Train the model\nhistory = model.fit(\n    train_dataset,\n    steps_per_epoch=train_dataset_length\/\/BATCH_SIZE,\n    epochs=8,\n    callbacks=[checkpoint , early_stop],\n    validation_data=val_dataset,\n    validation_steps = val_dataset_length\/\/BATCH_SIZE,\n)","c7d75b38":"# Interpreting the Metrics \nfig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","b9718146":"# Saving the best Model\n\n# Load the best weights\nmodel.load_weights(\"best_weights.h5\")\n# Save the whole model (weigths + architecture)\nmodel.save(\"model.h5\")","462e00b0":"# Loading the whole model\nloaded_model = tf.keras.models.load_model(\"model.h5\")","035ad113":"# Create a Dataset Object for 'Testing' Set just the way we did for Training and Validation\ntest_image_paths = list(test_path.glob(\"*\/*\"))\ntest_image_paths = list(map(lambda x : str(x) , test_image_paths))\ntest_labels = list(map(lambda x : get_label(x) , test_image_paths))\n\ntest_image_paths = tf.convert_to_tensor(test_image_paths)\ntest_labels = tf.convert_to_tensor(test_labels)\n\ndef decode_image(image , label):\n    image = tf.io.read_file(image)\n    image = tf.io.decode_jpeg(image , channels = 3)\n    image = tf.image.resize(image , [224 , 224] , method=\"nearest\")\n    return image , label\n\ntest_dataset = (\n     tf.data.Dataset\n    .from_tensor_slices((test_image_paths, test_labels))\n    .map(decode_image)\n    .batch(BATCH_SIZE)\n)","e5030b1d":"# Verify Test Dataset Object\nimage , label = next(iter(test_dataset))\nprint(image.shape)\nprint(label.shape)","3ab55dd4":"# View a sample Validation Image\nprint(INV_LABELS[label[0].numpy()])\nplt.imshow(image[0].numpy().reshape(224 , 224 , 3))","f4c25cfc":"# Evaluating the loaded model\nloss, acc, prec, rec = loaded_model.evaluate(test_dataset)\n\nprint(\" Testing Acc : \" , acc)\nprint(\" Testing Precision \" , prec)\nprint(\" Testing Recall \" , rec)","3ad451f9":"Create a Testing Dataset"}}