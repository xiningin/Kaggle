{"cell_type":{"40031b28":"code","5523e8cb":"code","4ba4e927":"code","60c47f9d":"code","8b57fa7c":"code","63d67fcc":"code","da538a4d":"code","ad58bd9f":"code","9a9d2b44":"code","56b4ccfc":"code","7e411afa":"code","d12e4ce8":"code","ab5204f4":"code","afdbbc03":"code","b242c6f9":"code","b134b4be":"code","2cf5143b":"code","f77f687b":"code","bfcf3aa7":"code","674dccd5":"code","0471c4ef":"code","57f61af8":"code","53448e2c":"code","1d516ec8":"code","e8f56d2b":"code","9b3cf66b":"code","fe964b67":"code","a3aa90e4":"code","709a7600":"code","c53f8494":"code","352f3379":"code","75b6bb54":"code","48802768":"code","7ac2af8c":"code","b8778562":"code","da5d0383":"code","2bc2807c":"code","e56df342":"code","8512d10c":"code","e68a31fd":"code","6b3911d9":"code","f354e0b9":"code","6a36f4aa":"code","71022072":"code","525eea50":"code","c6b267ff":"code","f6d3d236":"code","914fe98e":"code","406da747":"code","8c0761ff":"code","211e0261":"code","7b8fae12":"code","691c7276":"code","1a127b11":"code","66445bbb":"code","112c52e5":"code","e4fbfbf4":"code","d52f68db":"code","166f0b95":"code","990e3878":"code","765266fa":"code","bd8a141c":"code","28079372":"code","74e6245a":"code","0be667ad":"code","243cdc8e":"code","a16edd17":"markdown","8dd3cb36":"markdown","ee7d8623":"markdown","b3f35743":"markdown","64cf2935":"markdown","6bee37f2":"markdown","bf24882d":"markdown","857c81d3":"markdown","ac86af67":"markdown"},"source":{"40031b28":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5523e8cb":"import numpy as np \nimport pandas as pd \nimport math\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom ml_metrics import rmse","4ba4e927":"#Normalizing the font sizes for the plots throughout the notebook\nsmall = 14\nmeduim = 16\nlarge = 18\nplt.rc('font', size=small)          # controls default text sizes\nplt.rc('axes', titlesize=small)     # fontsize of the axes title\nplt.rc('axes', labelsize=meduim)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=small)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=small)    # fontsize of the tick labels\nplt.rc('legend', fontsize=small)    # legend fontsize\nplt.rc('figure', titlesize=large)   # fontsize of the figure title\ncolor = 'white' \n#Change the color of text in the plot according to your prefrence, \n#I had a dark theme on my notebook, so I set it to 'white'","60c47f9d":"df_train_full = pd.read_csv('..\/input\/neolen-house-price-prediction\/train.csv', index_col='Id')\ndf_test_full = pd.read_csv('..\/input\/neolen-house-price-prediction\/test.csv', index_col='Id')","8b57fa7c":"print('Our training dataset has {} rows and {} columns.'.format(df_train_full.shape[0], df_train_full.shape[1]))\nprint('Our test dataset has {} rows and {} columns.'.format(df_test_full.shape[0], df_test_full.shape[1]))","63d67fcc":"print(\"Train dataset: \\n\")\ndf_train_full.head()","da538a4d":"print(\"Test dataset: \\n\")\ndf_test_full.head()","ad58bd9f":"df_train_full.info()","9a9d2b44":"print(\"The cheapest house sold for ${:,.0f} and the most expensive house sold for ${:,.0f}\".format(df_train_full.SalePrice.min(),df_train_full.SalePrice.max()))\nprint(\"The Average Sales Price is ${:,.0f}, while median is ${:,.0f}\".format(df_train_full.SalePrice.mean(),df_train_full.SalePrice.median()))","56b4ccfc":"df_train_full.SalePrice.hist(bins=75,rwidth = .8,figsize=(28,8))\nplt.title('House Prices', color=color)\nplt.xlabel('Price in USD', color=color)\nplt.ylabel('Number of Houses', color=color)\nplt.xticks(color=color)\nplt.yticks(color=color)\nplt.show()","7e411afa":"print('Oldest house built in the Year {} and Newest house built in the Year {}.'.format(df_train_full.YearBuilt.min(),df_train_full.YearBuilt.max()))","d12e4ce8":"df_train_full.YearBuilt.hist(bins=14,rwidth=.9,figsize=(24,8))\nplt.title('When were the Houses built?', color=color)\nplt.xlabel('Year', color=color)\nplt.ylabel('Number of Houses', color=color)\nplt.xticks(color=color)\nplt.yticks(color=color)\nplt.show()","ab5204f4":"numerical_columns = []\ncategorical_columns = []\nlow_cardinality_catrgorical_columns = []\nfor col in df_train_full.columns:\n    if df_train_full[col].dtype in ['int64', 'float64']:\n        numerical_columns.append(col)\n    elif df_train_full[col].dtype == \"object\":\n        categorical_columns.append(col)\n        if df_train_full[col].nunique() < 10:\n            low_cardinality_catrgorical_columns.append(col)\nprint(f\"Numerical Columns({len(numerical_columns)} Columns): \\n{numerical_columns}\\n\")\nprint(f\"Categorical Columns({len(categorical_columns)} Columns): \\n{categorical_columns}\\n\")\nprint(f\"Low Cardinality Categorical Columns(<10 categories)({len(low_cardinality_catrgorical_columns)} Columns): \\n{low_cardinality_catrgorical_columns}\\n\")","afdbbc03":"# df_train_numerical = df_train_full.select_dtypes(exclude=['object'])\n# df_train_numerical.head()","b242c6f9":"print(f'There are {len(df_train_full.isnull().sum()[df_train_full.isnull().sum() != 0])} features that contains null values.')","b134b4be":"print(f'Features containing null values:\\n')\ndisplay((df_train_full.isnull().sum()[df_train_full.isnull().sum() != 0]))","2cf5143b":"print(f'Features containing null values:\\n')\ndisplay((df_test_full.isnull().sum()[df_test_full.isnull().sum() != 0]))","f77f687b":"print(f'LotFrontage: Linear feet of street connected to property, type = {df_train_full.LotFrontage.dtype}, Number of null value = {df_train_full[\"LotFrontage\"].isnull().sum()}.\\n')\n\ndf_train_full.LotFrontage.hist(bins=14,rwidth=.9,figsize=(18,6))\nplt.title('LotFrontage Histogram', color=color)\nplt.xlabel('Linear feet of street connected to property', color=color)\nplt.ylabel('Number of Houses', color=color)\nplt.xticks(color=color)\nplt.yticks(color=color)\nplt.show()\n\ndf_train_full.boxplot(column = ['LotFrontage'], figsize=(8,6))\nplt.title('LotFrontage Boxplot', color=color)\nplt.show()\n\nprint(f'\\nLotFrontage feature has outliers, so we will fill the null values using the median approach.\\n')\n\ndf_train_full['LotFrontage'].fillna(df_train_full['LotFrontage'].median(), inplace=True)\ndf_test_full['LotFrontage'].fillna(df_test_full['LotFrontage'].median(), inplace=True)\nprint(df_train_full['LotFrontage'].isnull().sum(), df_test_full['LotFrontage'].isnull().sum())","bfcf3aa7":"print(f'Alley: Type of alley access, type = {df_train_full.Alley.dtype}, Number of null value = {df_train_full[\"Alley\"].isnull().sum()}.\\n')\n\nprint(f'Alley Categories: {df_train_full[\"Alley\"].unique()}, with value counts:\\n')\n\ndisplay(df_train_full[\"Alley\"].value_counts())\n\nprint('\\nWe will fill the null values with a third category called NoAlley')\n\ndf_train_full['Alley'].fillna('NoAlley', inplace=True)\ndf_test_full['Alley'].fillna('NoAlley', inplace=True)\nprint(df_train_full['Alley'].isnull().sum(), df_test_full['Alley'].isnull().sum())","674dccd5":"print(f'MasVnrType: Masonry veneer type, type = {df_train_full.MasVnrType.dtype}, Number of null value = {df_train_full[\"MasVnrType\"].isnull().sum()}.\\n')\n\nprint(f'MasVnrType Categories: {df_train_full[\"MasVnrType\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"MasVnrType\"].value_counts())\n\nprint('\\nSince the null values are only 7, we will fill it with the most occuring category which is \"None\".\\n')\n\ndf_train_full['MasVnrType'].fillna('None', inplace=True)\ndf_test_full['MasVnrType'].fillna('None', inplace=True)\nprint(df_train_full['MasVnrType'].isnull().sum(), df_test_full['MasVnrType'].isnull().sum())","0471c4ef":"print(f'MasVnrArea: Masonry veneer area in square feet, type = {df_train_full.MasVnrArea.dtype}, Number of null value = {df_train_full[\"MasVnrArea\"].isnull().sum()}.\\n')\n\ndf_train_full.MasVnrArea.hist(bins=14,rwidth=.9,figsize=(18,6))\nplt.title('MasVnrArea Histogram', color=color)\nplt.xlabel('Masonry veneer area in square feet', color=color)\nplt.ylabel('Number of Houses', color=color)\nplt.xticks(color=color)\nplt.yticks(color=color)\nplt.show()\n\ndf_train_full.boxplot(column = ['MasVnrArea'], figsize=(8,6))\nplt.title('MasVnrArea Boxplot', color=color)\nplt.show()\n\nprint(f'\\nMasVnrArea feature has outliers, so we will fill the null values using the median approach.\\n')\n\ndf_train_full['MasVnrArea'].fillna(df_train_full['MasVnrArea'].median(), inplace=True)\ndf_test_full['MasVnrArea'].fillna(df_test_full['MasVnrArea'].median(), inplace=True)\nprint(df_train_full['MasVnrArea'].isnull().sum(), df_test_full['MasVnrArea'].isnull().sum())","57f61af8":"print(f'BsmtQual: Height of the basement, type = {df_train_full.BsmtQual.dtype}, Number of null value = {df_train_full[\"BsmtQual\"].isnull().sum()}.\\n')\n\nprint(f'BsmtQual Categories: {df_train_full[\"BsmtQual\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"BsmtQual\"].value_counts())\n\nprint('\\nSince the null values are only 35, we will fill it with a new category which is \"NoBas\".\\n')\n\ndf_train_full['BsmtQual'].fillna('NoBas', inplace=True)\ndf_test_full['BsmtQual'].fillna('NoBas', inplace=True)\nprint(df_train_full['BsmtQual'].isnull().sum(), df_test_full['BsmtQual'].isnull().sum())","53448e2c":"print(f'BsmtCond: General condition of the basement, type = {df_train_full.BsmtQual.dtype}, Number of null value = {df_train_full[\"BsmtCond\"].isnull().sum()}.\\n')\n\nprint(f'BsmtCond Categories: {df_train_full[\"BsmtCond\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"BsmtCond\"].value_counts())\n\nprint(f'\\nSince the null values are only {df_train_full[\"BsmtCond\"].isnull().sum()}, we will fill it with a new category which is \"NoBas\".\\n')\n\ndf_train_full['BsmtCond'].fillna('NoBas', inplace=True)\ndf_test_full['BsmtCond'].fillna('NoBas', inplace=True)\nprint(df_train_full['BsmtCond'].isnull().sum(), df_test_full['BsmtCond'].isnull().sum())","1d516ec8":"print(f'BsmtExposure: Walkout or garden level basement walls, type = {df_train_full.BsmtExposure.dtype}, Number of null value = {df_train_full[\"BsmtExposure\"].isnull().sum()}.\\n')\n\nprint(f'BsmtExposure Categories: {df_train_full[\"BsmtExposure\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"BsmtExposure\"].value_counts())\n\nprint(f'\\nSince the null values are only {df_train_full[\"BsmtExposure\"].isnull().sum()}, we will fill it with a new category which is \"NoBas\".\\n')\n\ndf_train_full['BsmtExposure'].fillna('NoBas', inplace=True)\ndf_test_full['BsmtExposure'].fillna('NoBas', inplace=True)\nprint(df_train_full['BsmtExposure'].isnull().sum(), df_test_full['BsmtExposure'].isnull().sum())","e8f56d2b":"print(f'BsmtFinType1: Quality of basement finished area, type = {df_train_full.BsmtFinType1.dtype}, Number of null value = {df_train_full[\"BsmtFinType1\"].isnull().sum()}.\\n')\n\nprint(f'BsmtFinType1 Categories: {df_train_full[\"BsmtFinType1\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"BsmtFinType1\"].value_counts())\n\nprint(f'\\nSince the null values are only {df_train_full[\"BsmtFinType1\"].isnull().sum()}, we will fill it with a new category which is \"NoBas\".\\n')\n\ndf_train_full['BsmtFinType1'].fillna('NoBas', inplace=True)\ndf_test_full['BsmtFinType1'].fillna('NoBas', inplace=True)\nprint(df_train_full['BsmtFinType1'].isnull().sum(), df_test_full['BsmtFinType1'].isnull().sum())","9b3cf66b":"print(f'BsmtFinType2: Quality of second finished area (if present), type = {df_train_full.BsmtFinType2.dtype}, Number of null value = {df_train_full[\"BsmtFinType2\"].isnull().sum()}.\\n')\n\nprint(f'BsmtFinType2 Categories: {df_train_full[\"BsmtFinType2\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"BsmtFinType2\"].value_counts())\n\nprint(f'\\nSince the null values are only {df_train_full[\"BsmtFinType2\"].isnull().sum()}, we will fill it with a new category which is \"NoBas\".\\n')\n\ndf_train_full['BsmtFinType2'].fillna('NoBas', inplace=True)\ndf_test_full['BsmtFinType2'].fillna('NoBas', inplace=True)\nprint(df_train_full['BsmtFinType2'].isnull().sum(), df_test_full['BsmtFinType2'].isnull().sum())","fe964b67":"print(f'FireplaceQu: Fireplace quality, type = {df_train_full.FireplaceQu.dtype}, Number of null value = {df_train_full[\"FireplaceQu\"].isnull().sum()}.\\n')\n\nprint(f'FireplaceQu Categories: {df_train_full[\"FireplaceQu\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"FireplaceQu\"].value_counts())\n\nprint(f'\\nSince the null values are only {df_train_full[\"FireplaceQu\"].isnull().sum()}, we will fill it with a new category which is \"NoFP\".\\n')\n\ndf_train_full['FireplaceQu'].fillna('NoFP', inplace=True)\ndf_test_full['FireplaceQu'].fillna('NoFP', inplace=True)\nprint(df_train_full['FireplaceQu'].isnull().sum(), df_test_full['FireplaceQu'].isnull().sum())","a3aa90e4":"df_train_full['GarageType'].fillna('NoGarage', inplace=True)\ndf_test_full['GarageType'].fillna('NoGarage', inplace=True)\n\ndf_train_full['GarageFinish'].fillna('NoGarage', inplace=True)\ndf_test_full['GarageFinish'].fillna('NoGarage', inplace=True)\n\ndf_train_full['GarageQual'].fillna('NoGarage', inplace=True)\ndf_test_full['GarageQual'].fillna('NoGarage', inplace=True)\n\ndf_train_full['GarageCond'].fillna('NoGarage', inplace=True)\ndf_test_full['GarageCond'].fillna('NoGarage', inplace=True)\n\ndf_train_full['GarageYrBlt'].fillna(0, inplace=True)\ndf_test_full['GarageYrBlt'].fillna(0, inplace=True)\n\nprint(df_train_full['GarageType'].isnull().sum())\nprint(df_train_full['GarageYrBlt'].isnull().sum())\nprint(df_train_full['GarageFinish'].isnull().sum())\nprint(df_train_full['GarageQual'].isnull().sum())\nprint(df_train_full['GarageCond'].isnull().sum())","709a7600":"print(f'PoolQC: Pool quality, type = {df_train_full.PoolQC.dtype}, Number of null value = {df_train_full[\"PoolQC\"].isnull().sum()}.\\n')\n\nprint(f'PoolQC Categories: {df_train_full[\"PoolQC\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"PoolQC\"].value_counts())\n\nprint(f'\\nSince the null values are {df_train_full[\"PoolQC\"].isnull().sum()}, we will fill it with a new category which is \"NoPool\".\\n')\n\ndf_train_full['PoolQC'].fillna('NoPool', inplace=True)\ndf_test_full['PoolQC'].fillna('NoPool', inplace=True)\nprint(df_train_full['PoolQC'].isnull().sum(), df_test_full['PoolQC'].isnull().sum())","c53f8494":"print(f'Fence: Fence quality, type = {df_train_full.Fence.dtype}, Number of null value = {df_train_full[\"Fence\"].isnull().sum()}.\\n')\n\nprint(f'Fence Categories: {df_train_full[\"Fence\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"Fence\"].value_counts())\n\nprint(f'\\nSince the null values are {df_train_full[\"Fence\"].isnull().sum()}, we will fill it with a new category which is \"NoFence\".\\n')\n\ndf_train_full['Fence'].fillna('NoFence', inplace=True)\ndf_test_full['Fence'].fillna('NoFence', inplace=True)\nprint(df_train_full['Fence'].isnull().sum(), df_test_full['Fence'].isnull().sum())","352f3379":"print(f'MiscFeature: Miscellaneous feature not covered in other categories, type = {df_train_full.MiscFeature.dtype}, Number of null value = {df_train_full[\"MiscFeature\"].isnull().sum()}.\\n')\n\nprint(f'MiscFeature Categories: {df_train_full[\"MiscFeature\"].unique()}, with value counts: \\n')\n\ndisplay(df_train_full[\"MiscFeature\"].value_counts())\n\nprint('\\nWe will drop this feature.')\n\ndf_train_clean = df_train_full.drop('MiscFeature', axis = 1)\ndf_test_clean = df_test_full.drop('MiscFeature', axis = 1)","75b6bb54":"df_train_clean.isnull().sum().sum()","48802768":"df_train_clean.duplicated().sum()","7ac2af8c":"df_test_clean.isnull().sum().sum()","b8778562":"df_test_clean['Electrical'].fillna('SBrkr', inplace=True)","da5d0383":"df_test_clean.isnull().sum().sum()","2bc2807c":"df_test_clean.duplicated().sum()","e56df342":"df_train_clean.info()","8512d10c":"categorical_columns2 = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'SaleType', 'SaleCondition']\nfor cat in categorical_columns2:\n    df_train_clean[cat] = pd.factorize(df_train_clean[cat])[0].reshape(-1, 1)\n    df_test_clean[cat] = pd.factorize(df_test_clean[cat])[0].reshape(-1, 1)","e68a31fd":"df_train = df_train_clean.copy()\ndf_test = df_test_clean.copy()","6b3911d9":"df_train.shape","f354e0b9":"df_test.shape","6a36f4aa":"Y_train = df_train['SalePrice']\nX_train = df_train.drop('SalePrice', axis=1)","71022072":"X_train.shape","525eea50":"X_train_0, X_valid_0, Y_train_0, Y_valid_0 = train_test_split(X_train, Y_train, train_size=0.8, test_size=0.2, random_state=0)","c6b267ff":"LR_model_1 = LinearRegression()\nLR_model_1.fit(X_train_0, Y_train_0)","f6d3d236":"Y_pred_App1 = LR_model_1.predict(X_valid_0)","914fe98e":"r_sq_1 = LR_model_1.score(X_valid_0, Y_valid_0)\nprint('Coefficient of Determination:', r_sq_1)","406da747":"print(\"RMSE (Appraoch 1):\")\nprint(np.sqrt(mean_squared_error(Y_pred_App1, Y_valid_0)))","8c0761ff":"Y_valid_log = pd.DataFrame(np.log(Y_valid_0))\nY_pred_log = pd.DataFrame(np.log(Y_pred_App1))\nY_log = pd.concat([Y_valid_log, Y_pred_log], axis=1)\nY_log.columns = ['Valid', 'Pred']\nY_log.dropna(inplace=True)","211e0261":"print(\"Log RMSE (Appraoch 1):\")\nprint(np.sqrt(mean_squared_error(Y_log.Pred, Y_log.Valid)))","7b8fae12":"X_train_0_intercept = X_train_0.copy()\nX_train_0_intercept['intercept'] = 1","691c7276":"X_valid_0_intercept = X_valid_0.copy()\nX_valid_0_intercept['intercept'] = 1","1a127b11":"LR_model_sm = sm.OLS(Y_train_0, X_train_0_intercept)","66445bbb":"LR_model_sm_res = LR_model_sm.fit()","112c52e5":"print('Coefficient of Determination:', LR_model_sm_res.rsquared)","e4fbfbf4":"# print(results.summary())\n","d52f68db":"Y_pred_App2 = LR_model_sm_res.predict(X_valid_0_intercept)","166f0b95":"print(\"RMSE (Appraoch 2):\")\nprint(np.sqrt(mean_squared_error(Y_pred_App2, Y_valid_0)))","990e3878":"Y_valid_log2 = pd.DataFrame(np.log(Y_valid_0))\nY_pred_log2 = pd.DataFrame(np.log(Y_pred_App2))\nY_log2 = pd.concat([Y_valid_log2, Y_pred_log2], axis=1)\nY_log2.columns = ['Valid', 'Pred']\nY_log2.dropna(inplace=True)","765266fa":"print(\"Log RMSE (Appraoch 2):\")\nprint(np.sqrt(mean_squared_error(Y_log2.Pred, Y_log2.Valid)))","bd8a141c":"df_test.isnull().sum().sum()","28079372":"df_test.duplicated().sum()","74e6245a":"df_test_intercept = df_test.copy()\ndf_test_intercept['intercept'] = 1\ndf_test_intercept.shape","0be667ad":"final_pred = LR_model_sm_res.predict(df_test_intercept)","243cdc8e":"output = pd.DataFrame({'Id': df_test_clean.index,\n                       'SalePrice': final_pred})\noutput.to_csv('submission.csv', index=False)\nprint('done')","a16edd17":"### Data Preprocessing ###","8dd3cb36":"#### Approach 3 ####","ee7d8623":"### Final Submission ###","b3f35743":"### Reading Data files ###","64cf2935":"### Exploring Data Files ###","6bee37f2":"#### Approach 1","bf24882d":"### Data Analysis ###","857c81d3":"#### Approach 2","ac86af67":"### Modeling ###"}}