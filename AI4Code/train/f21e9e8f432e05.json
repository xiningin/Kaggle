{"cell_type":{"ffe58884":"code","45819f0e":"code","e6c5f4d9":"code","5df65e0b":"code","f7aa5885":"code","1ec17c3e":"code","62e51350":"code","95ae92c1":"code","9b1275d5":"code","6e0c46a9":"code","6b27d828":"markdown"},"source":{"ffe58884":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm","45819f0e":"# make tfrecords\n\ndef image_feature(value):\n    \"\"\"Returns a bytes_list from a jpeg\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()]))\n\n\ndef bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n\n\ndef float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n\ndef int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef float_feature_list(value):\n    \"\"\"Returns a list of float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n\n\ndef preprocess_img(file_path, img_size=512):\n    image = tf.io.read_file(file_path)\n    image = tf.image.decode_image(image, channels = 3)\n    image = tf.image.resize(image, [img_size, img_size])\n    image = tf.cast(image, tf.uint8)\n    return image\n\ndef create_example(image, label, label_name):\n    feature = {\n        \"image\": image_feature(image),\n        \"label\": int64_feature(label),\n        \"label_name\": int64_feature(label_name)\n    }\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\ndef parse_tfrecord_fn(example):\n    feature_description = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label_name\": tf.io.FixedLenFeature([], tf.int64),\n        \"label\": tf.io.FixedLenFeature([], tf.int64)\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n    return example\n\n\ndef validation_split(df):\n    x_train, x_val, y_train, y_val = train_test_split(df[['image']], df['label_group'], shuffle = True, random_state = 2021, test_size = 0.5)\n    return (\n        x_train.squeeze().values, \n        x_val.squeeze().values, \n        y_train.values, \n        y_val.values\n    )\n\ndef preprocess_train(df):\n    tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n    df['matches'] = df['label_group'].map(tmp)\n    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n    encoder = LabelEncoder()\n    df['label_group'] = encoder.fit_transform(df['label_group'])\n    return df[['posting_id', 'image', 'label_group']], encoder\n\n","e6c5f4d9":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntrain, label_encoder = preprocess_train(train)\nx_train, x_val, y_train, y_val = validation_split(train)","5df65e0b":"!mkdir tfrec_512x512\n!mkdir tfrec_512x512\/train\n!mkdir tfrec_512x512\/valid\n\n!mkdir tfrec_300x300\n!mkdir tfrec_300x300\/train\n!mkdir tfrec_300x300\/valid","f7aa5885":"def write_tfrecords(x, y, label_encoder, sample_size, path, img_size):\n    n_shardes = int(np.ceil(len(x_train) \/ sample_size))\n    for i in tqdm(range(n_shardes)):\n        images = x[i*sample_size:(i+1)*sample_size]\n        labels = y[i*sample_size:(i+1)*sample_size]\n        source_labels = label_encoder.inverse_transform(labels)\n        with tf.io.TFRecordWriter(f\"{path}\/{i}.tfrec\") as writer:\n            for im, lb, sl in zip(images, labels, source_labels):\n                image_path = f\"..\/input\/shopee-product-matching\/train_images\/{im}\"\n                image = preprocess_img(image_path, img_size)\n                example = create_example(image, lb, sl)\n                writer.write(example.SerializeToString())\n                \nwrite_tfrecords(x_train, y_train, label_encoder, 1024, \"tfrec_300x300\/train\", 300)\nwrite_tfrecords(x_val, y_val, label_encoder, 1024, \"tfrec_300x300\/valid\", 300)\n\nwrite_tfrecords(x_train, y_train, label_encoder, 1024, \"tfrec_512x512\/train\", 512)\nwrite_tfrecords(x_val, y_val, label_encoder, 1024, \"tfrec_512x512\/valid\", 512)\n","1ec17c3e":"!ls -l --block-size=MB tfrec_300x300\/train\/","62e51350":"!ls -l --block-size=MB tfrec_300x300\/valid\/","95ae92c1":"!ls -l --block-size=MB tfrec_512x512\/train\/","9b1275d5":"!ls -l --block-size=MB tfrec_512x512\/valid\/","6e0c46a9":"# read tfrecords example \n\n# import matplotlib.pyplot as plt\n\n# dataset = tf.data.TFRecordDataset(sorted(tf.io.gfile.glob('tfrec\/train\/*.tfrec')))\n# dataset = dataset.map(parse_tfrecord_fn)\n\n# for features in dataset.take(1):\n#     for key in features.keys():\n#         if key != \"image\":\n#             print(f\"{key}: {features[key]}\")\n#     print(f\"Image shape: {features['image'].shape}\")\n#     plt.figure(figsize=(7, 7))\n#     plt.imshow(features[\"image\"].numpy())\n#     plt.show()\n","6b27d828":"Hi!\n<br>It's not a secret that using of tfrecords provide better efficienty with tf.data.* API\n<br>I've made an attempt to write as compact code as possible for Shopee matching competition tfrecords generation \n<br>Sure, datast splitting is not mandatory\n<br>You could find resulting dataset here: https:\/\/www.kaggle.com\/alturutin\/shopee-product-match-tfrecords\n<br>Hope it will help someone"}}