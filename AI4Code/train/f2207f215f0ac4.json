{"cell_type":{"b9d1e822":"code","7d3edf53":"code","19d9da7f":"code","137928ae":"code","c9ad59aa":"code","3af42a0a":"code","e06b3125":"code","fa1787f7":"code","498fbcd4":"code","6b4abbe8":"code","12c80dc9":"code","22ee3dec":"code","a38a1edf":"code","2f3c63bb":"code","fa7339fc":"code","19d5024f":"code","09e0c993":"code","16eda819":"code","fb5fa3b8":"code","a7ff6314":"code","fd13a00d":"markdown","6bf7b5e6":"markdown","14674f65":"markdown","a42fdf37":"markdown","2c61b3e8":"markdown","f6260339":"markdown","918f52ef":"markdown","562af0ff":"markdown"},"source":{"b9d1e822":"!pip install -q \"monai-weekly[gdown, nibabel, tqdm, itk]\"","7d3edf53":"import os\nimport shutil\nimport tempfile\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nimport cv2\nfrom sklearn.metrics import classification_report\n\nimport torch\n\nfrom monai.apps import download_and_extract\nfrom monai.config import print_config\nfrom monai.metrics import ROCAUCMetric\nfrom monai.networks.nets import DenseNet121\nfrom monai.transforms import *\nfrom monai.data import Dataset, DataLoader\nfrom monai.utils import set_determinism\n\n#print_config()","19d9da7f":"train_dir='..\/input\/pneumonia-xray-images\/train'\nval_dir='..\/input\/pneumonia-xray-images\/val'\ntest_dir='..\/input\/pneumonia-xray-images\/test'","137928ae":"#train\nclass_names0 = os.listdir(train_dir)\nclass_names = sorted(class_names0)\nprint(class_names)\nnum_class = len(class_names)\nimage_files = [[os.path.join(train_dir, class_name, x) \n               for x in os.listdir(os.path.join(train_dir, class_name))] \n               for class_name in class_names]\n\nimage_file_list = []\nimage_label_list = []\nfor i, class_name in enumerate(class_names):\n    image_file_list.extend(image_files[i])\n    image_label_list.extend([i] * len(image_files[i]))","c9ad59aa":"#valid\nv_class_names0 = os.listdir(val_dir)\nv_class_names = sorted(v_class_names0)\nprint(v_class_names)\nv_num_class = len(v_class_names)\nv_image_files = [[os.path.join(val_dir, v_class_name, x) \n               for x in os.listdir(os.path.join(val_dir, v_class_name))] \n               for v_class_name in v_class_names]\n\nv_image_file_list = []\nv_image_label_list = []\nfor i, class_name in enumerate(v_class_names):\n    v_image_file_list.extend(v_image_files[i])\n    v_image_label_list.extend([i]*len(v_image_files[i]))\n","3af42a0a":"#test\nt_class_names0 = os.listdir(test_dir)\nt_class_names = sorted(t_class_names0)\nprint(t_class_names)\nt_num_class = len(t_class_names)\nt_image_files = [[os.path.join(test_dir, t_class_name, x) \n               for x in os.listdir(os.path.join(test_dir, t_class_name))] \n               for t_class_name in t_class_names]\n\nt_image_file_list = []\nt_image_label_list = []\nfor i, class_name in enumerate(t_class_names):\n    t_image_file_list.extend(t_image_files[i])\n    t_image_label_list.extend([i] * len(t_image_files[i]))","e06b3125":"num_total=len(image_file_list)\nplt.subplots(3,3, figsize=(12,12))\nfor i,k in enumerate(np.random.randint(num_total, size=9)):\n    im = Image.open(image_file_list[k])\n    arr = np.array(im)\n    print(arr.shape)\n    plt.subplot(3,3, i+1)\n    plt.xlabel(class_names[image_label_list[k]])\n    plt.imshow(arr, cmap='gray', vmin=0, vmax=255)\nplt.tight_layout()\nplt.show()\n# image size and number of channels differ each other","fa1787f7":"trainX=np.array(image_file_list)\ntrainY=np.array(image_label_list)\nvalX=np.array(v_image_file_list)\nvalY=np.array(v_image_label_list)\ntestX=np.array(t_image_file_list)\ntestY=np.array(t_image_label_list)","498fbcd4":"class SumDimension(Transform):\n    def __init__(self, dim=1):\n        self.dim = dim\n\n    def __call__(self, inputs):\n        return inputs.sum(self.dim)","6b4abbe8":"class MyResize(Transform):\n    def __init__(self, size=(100,150)):\n        self.size = size\n    def __call__(self, inputs):\n        image2=cv2.resize(inputs,dsize=(self.size[1],self.size[0]),interpolation=cv2.INTER_CUBIC)\n        return image2","12c80dc9":"class Astype(Transform):\n    def __init__(self, type='uint8'):\n        self.type = type\n    def __call__(self, inputs):\n        return inputs.astype(self.type)","22ee3dec":"train_transforms = Compose([\n    LoadImage(image_only=True),\n    Resize((-1,1)),\n    Astype(),\n    SumDimension(2),\n    Astype(),\n    MyResize(),\n    AddChannel(),    \n    ToTensor(),\n])\n\nval_transforms = Compose([\n    LoadImage(image_only=True),\n    Resize((-1,1)),\n    Astype(),\n    SumDimension(2),\n    Astype(),\n    MyResize(),\n    AddChannel(),    \n    ToTensor(),\n])\n\nact = Activations(softmax=True)\nto_onehot = AsDiscrete(to_onehot=True, n_classes=num_class)","a38a1edf":"class MedNISTDataset(Dataset):\n\n    def __init__(self, image_files, labels, transforms):\n        self.image_files = image_files\n        self.labels = labels\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, index):\n        return self.transforms(self.image_files[index]), self.labels[index]","2f3c63bb":"train_ds = MedNISTDataset(trainX, trainY, train_transforms)\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2)\n\nval_ds = MedNISTDataset(valX, valY, val_transforms)\nval_loader = DataLoader(val_ds, batch_size=64, num_workers=2)\n\ntest_ds = MedNISTDataset(testX, testY, val_transforms)\ntest_loader = DataLoader(test_ds, batch_size=64, num_workers=2)","fa7339fc":"device = torch.device(\"cuda:0\")   #\"cuda:0\"\nmodel = DenseNet121(\n    spatial_dims=2,            \n    in_channels=1,\n    out_channels=num_class,\n).to(device)\n\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), 1e-5)\nepoch_num = 10\nval_interval = 1","19d5024f":"best_metric = -1\nbest_metric_epoch = -1\nepoch_loss_values = list()\nauc_metric = ROCAUCMetric()\nmetric_values = list()\n\nfor epoch in range(epoch_num):\n    print('-' * 10)\n    print(f\"epoch {epoch + 1}\/{epoch_num}\")\n    model.train()\n    epoch_loss = 0\n    step = 0\n\n    for batch_data in train_loader:\n        step += 1\n        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs.float())     ##### \n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        print(f\"{step}\/{len(train_ds) \/\/ train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n        epoch_len = len(train_ds) \/\/ train_loader.batch_size\n\n    epoch_loss \/= step\n    epoch_loss_values.append(epoch_loss)\n    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n\n    if (epoch + 1) % val_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n            y = torch.tensor([], dtype=torch.long, device=device)\n            for val_data in val_loader:\n                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n                y = torch.cat([y, val_labels], dim=0)\n                \n            y_onehot = [to_onehot(i) for i in y]\n            y_pred_act = [act(i) for i in y_pred]\n            auc_metric(y_pred_act, y_onehot)\n            auc_result = auc_metric.aggregate()\n            auc_metric.reset()\n            del y_pred_act, y_onehot\n            metric_values.append(auc_result)\n            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n            acc_metric = acc_value.sum().item() \/ len(acc_value)\n            \n            if acc_metric > best_metric:\n                best_metric = acc_metric\n                best_metric_epoch = epoch + 1\n                torch.save(model.state_dict(), 'best_metric_model.pth')\n                print('saved new best metric model')\n                \n            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n                  f\" at epoch: {best_metric_epoch}\")\n            \nprint(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n","09e0c993":"plt.figure('train', (12,6))\nplt.subplot(1,2,1)\nplt.title(\"Epoch Average Loss\")\nx = [i+1 for i in range(len(epoch_loss_values))]\ny = epoch_loss_values\nplt.xlabel('epoch')\nplt.plot(x, y)\nplt.subplot(1,2,2)\nplt.title(\"Validation: Area under the ROC curve\")\nx = [val_interval * (i+1) for i in range(len(metric_values))]\ny = metric_values\nplt.xlabel('epoch')\nplt.plot(x,y)\nplt.show()","16eda819":"model.load_state_dict(torch.load('best_metric_model.pth'))\nmodel.eval()\ny_true = list()\ny_pred = list()\n\nwith torch.no_grad():\n    for test_data in test_loader:\n        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n        pred = model(test_images.float()).argmax(dim=1)\n        for i in range(len(pred)):\n            y_true.append(test_labels[i].item())\n            y_pred.append(pred[i].item())","fb5fa3b8":"print(y_true[0:5])\nprint(y_pred[0:5])","a7ff6314":"print(classification_report(y_true, y_pred, target_names=t_class_names, digits=4))","fd13a00d":"## Prepare training, validation and test data lists","6bf7b5e6":"## Visualise some examples","14674f65":"## Plot the loss and metric","a42fdf37":"## Install MONAI","2c61b3e8":"## Define MONAI transforms, Dataset and Dataloader to pre-process data","f6260339":"![Upvote!](https:\/\/img.shields.io\/badge\/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)","918f52ef":"# Pneumonia X-Ray Image Classify MONAI Pytorch\nThis notebook referred to MONAI's Image Classification Tutorial with the MedNIST Dataset<br\/>\nhttps:\/\/colab.research.google.com\/drive\/1wy8XUSnNWlhDNazFdvGBHLfdkGvOHBKe","562af0ff":"## Read image filenames from the dataset folders"}}