{"cell_type":{"9f56cdb5":"code","a9b7c6f6":"code","ac3ea685":"code","d518bada":"code","536f169d":"code","29940d7a":"code","45879954":"code","e7e20ca9":"code","827d120a":"code","874f02d1":"code","9e15af6b":"code","ae1a4819":"code","da9fecb9":"code","65270ca9":"code","285f1932":"code","501a3ad7":"code","107e68ff":"code","e87ae7a2":"code","cae2b055":"code","62ada29d":"code","ad3d24a7":"code","6740c8c6":"code","864bb9f3":"code","eef40a96":"code","d186750d":"code","4605029d":"code","9e60c456":"code","064dbcd2":"code","1867738a":"code","31125c7e":"code","33951622":"code","0a8f9c52":"code","2c2b8fa2":"code","c724d334":"code","60039cab":"code","6e5c11f3":"code","a87b9303":"code","a37b70d0":"code","3e6b904b":"code","7c144603":"markdown","a5a5e817":"markdown","477a8b86":"markdown","2a1a16fe":"markdown","9b421e8b":"markdown","9d93a2d7":"markdown","6e40820b":"markdown","b108deeb":"markdown","2f3b4e95":"markdown","08f16fb0":"markdown","51645bf2":"markdown","bd4c0450":"markdown","2be528ea":"markdown","34289506":"markdown","ea198bb1":"markdown","f5a7e365":"markdown","512c5a69":"markdown","f4b4bd7d":"markdown","00c9fe6e":"markdown","c31b4469":"markdown","319a3383":"markdown","a9da3ef1":"markdown","c151052e":"markdown","2efe1242":"markdown","f3e13ae5":"markdown","f2208ef9":"markdown","e818a14c":"markdown","f368d7ce":"markdown","554cd829":"markdown","46e56df1":"markdown","405b7e15":"markdown","1a56b0a9":"markdown","c5738323":"markdown","aa028887":"markdown","2c5e77a7":"markdown","8f90611f":"markdown","9da4124c":"markdown","c74ec7fd":"markdown","17fffbe1":"markdown","a0fbf345":"markdown","db962ba5":"markdown","6fab4d03":"markdown","390ad2d7":"markdown","a459c631":"markdown"},"source":{"9f56cdb5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import metrics\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","a9b7c6f6":"score = pd.read_csv('..\/input\/student_scores.csv')","ac3ea685":"score.shape","d518bada":"score.head()","536f169d":"score.describe()","29940d7a":"score.plot(x='Hours', y='Scores', style='o')  \nplt.title('Hours vs Percentage')  \nplt.xlabel('Hours Studied')  \nplt.ylabel('Percentage Score')  \nplt.show() ","45879954":"X = score.iloc[:, :-1].values  \ny = score.iloc[:, 1].values  ","e7e20ca9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) ","827d120a":"model = LinearRegression()  \nmodel.fit(X_train, y_train) ","874f02d1":"print(model.intercept_)  ","9e15af6b":"print(model.coef_)  ","ae1a4819":"# y_pred contains all the predicted values for the X_test data\ny_pred = model.predict(X_test)  ","da9fecb9":"# Creating a dataframe to show how the prediction and actual data looks like\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \nprint(df)","65270ca9":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  ","285f1932":"dataset = pd.read_csv(\"..\/input\/petrol_consumption.csv\")","501a3ad7":"dataset.head()","107e68ff":"dataset.describe()","e87ae7a2":"dataset.plot(kind='box',layout=(2,2), sharex=False, sharey=False, figsize=(10,8))\nplt.show()","cae2b055":"dataset.hist(figsize=(12,10))\nplt.show()","62ada29d":"X = dataset[['Petrol_tax', 'Average_income', 'Paved_Highways',  \n       'Population_Driver_licence(%)']]\ny = dataset['Petrol_Consumption']  ","ad3d24a7":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) ","6740c8c6":"regressor = LinearRegression()  \nregressor.fit(X_train, y_train)  ","864bb9f3":"coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])  \ncoeff_df","eef40a96":"y_pred = regressor.predict(X_test) ","d186750d":"df_regressor = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \nprint(df_regressor)","4605029d":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  ","9e60c456":"model_gnb = GaussianNB()  \nmodel_gnb.fit(X_train, y_train)\ny_pred = model_gnb.predict(X_test) ","064dbcd2":"df_gnb = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \nprint(df_gnb)","1867738a":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  ","31125c7e":"model_dtc = DecisionTreeClassifier() \nmodel_dtc.fit(X_train, y_train)\ny_pred = model_dtc.predict(X_test) ","33951622":"df_dtc = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \nprint(df_dtc)","0a8f9c52":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  ","2c2b8fa2":"model_sgd = SGDClassifier()\nmodel_sgd.fit(X_train, y_train)\ny_pred = model_sgd.predict(X_test) ","c724d334":"df_sgd = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \nprint(df_sgd)","60039cab":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  ","6e5c11f3":"model_knn = KNeighborsClassifier()\nmodel_knn.fit(X_train, y_train)\ny_pred = model_knn.predict(X_test) ","a87b9303":"df_knn = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \nprint(df_knn)","a37b70d0":"model_svm = SVC(kernel=\"linear\", C=0.025)\nmodel_svm.fit(X_train, y_train)\ny_pred = model_svm.predict(X_test) ","3e6b904b":"df_svm = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \nprint(df_svm)","7c144603":"- We have a simple dataset where we have two variables: hours and scores. We have hours as independent variable and scores as dependent variable. ","a5a5e817":"- Question: What is the correation between number of hours studied and the expected score of the student?","477a8b86":"In case of multivariable linear regression, the regression model has to find the most optimal coefficients for all the attributes. To see what coefficients our regression model has chosen, execute the following script:","2a1a16fe":"Visualize the data using various plots: \n1. Box Plot\n2. Histogram","9b421e8b":"Import all the required packages","9d93a2d7":"- Create histograms and describe the results","6e40820b":"- The dataset includes four features: \"Petrol Tax\", \"Average Income\", \"Paved Highways\" and \"Population Driver License Percent\", which gives the the average \"Petrol_Consumption\" \n- Goal: To find out consumption of petrol when provided 4 different featurs.","b108deeb":"Exploring the dataset:","2f3b4e95":"Another Algorithm we use here is \"Decision Tree Classifier\" which is a linear classifier so we can use it here.","08f16fb0":"Get the statistical details of the score dataset:","51645bf2":"Final step is to make prediction using the regressor model we created","bd4c0450":"- What is the question and what are we trying to solve\/find out?\n- What are the generation intentions behind doing this project and how is it going to be helpful?","2be528ea":"Plot the dataset into a scatter plot diagram\n- Scatter plot gives us an idea about how two variabled corelate to each other. Since, we have only two variables in our dataset and one influences the other, scatter plot representation makes the most sense","34289506":"We compare the accuracy of the different models","ea198bb1":"- We will import all the packages we need for our program to run in an end to end basis\n- Train different models and find out the best one\n- Get statistical Measures to evaluate our algorithm","f5a7e365":"- From the figure above we can conclude more the number of hours studied, higher the score","512c5a69":"# Multiple Linear Regression","f4b4bd7d":"To see statistical details of the dataset, we'll use the describe() command:","00c9fe6e":"- Look at the description of the dataset\n- Explore the dataset (what information can we gain from it and how can we use it to solve the defined problem)\n- Visualize our data to get more understanding on our dataset","c31b4469":"Splitting the data into training and test set:\n80% training set and 20% test set","319a3383":"Use only one attribute to predict the outcome of the result\n- Predict the percentage of marks that a student is expected to score based upon number of hours studied","a9da3ef1":"# 1. Define the Problem\/Outcome","c151052e":"The coefficient is 9.91%. This means if a student studies one hour more than they previously studied for an exam, they can expect to achieve an increase of 9.91% in the score achieved by the student previously.","2efe1242":"## Description of project:","f3e13ae5":"# 3. Data Exploration","f2208ef9":"Dividing the data into attributes and labels:\n- First column (Hours) is the attribute, which are independent variables \n- Second column (Percentage) is the label, which are dependent variables","e818a14c":"# 4. Evaluate our algorithms","f368d7ce":"Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see, e.g., Vowpal Wabbit) and graphical models.","554cd829":"- Split the dataset into the Training and Test Set (80\/20)","46e56df1":"Evaluate the Algorithm. We do this by using following methods:\n1. Mean Absolute Error  \n2. Mean Squared Error \n3. Root Mean Squared Error ","405b7e15":"Prepare the Data:\nUse the first 4 columns as attributes and the final column as the label","1a56b0a9":"# Single Linear Regression: ","c5738323":"- We use Linear Regression Method to train and fit the data","aa028887":"# Description of project","2c5e77a7":"Choosing the Model:\n- We use linear regression to train a model because a single independent variable is used to predict the value of a dependent variable","8f90611f":"# Models","9da4124c":"Since linear regression is basically:\n- y = mx + c, where m is slope and c is the intercept, we try to find the best possible values for the intercept (which is the goal)\n- Also, get the slope value","c74ec7fd":"We create different models to see which works the best for the type of dataset we have:\n- Linear Regression\n- Gaussian Naive Bayes\n- Decision Tree Classifier\n- Stochastic Gradient Descent\n- K-Nearest Neighbor\n- Linear SVM","17fffbe1":"- One of the major issues with working with datasets is that they are not always formatted and in a way, we want. We need to clean up the data in various ways. We need to make sure that the data we have is properly formatted and without any issues. We might need to add some data and remove some data, which can be done by viewing the data. In the example provided, we have a clean dataset, but that might not be always the case.","a0fbf345":"# General Steps to be followed for an end-to-end Machine Learning Project","db962ba5":"Since, we have trained our model with the algorithm, the next step is to make predictions based upon the model on some input values","6fab4d03":"- The data was acquired from the web \"https:\/\/drive.google.com\/file\/d\/1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_\/view\"\n- Check some of the data and how the dataset looks like","390ad2d7":"# 2. Prepare the dataset","a459c631":"Another Algorithm we use here is \"Gaussian Naive Bayes\" which is a linear classifier so we can use it here."}}