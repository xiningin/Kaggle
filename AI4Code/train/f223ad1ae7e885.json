{"cell_type":{"e64a7301":"code","c871f8d7":"code","173e1dc1":"code","1558b52b":"code","ee4985cd":"code","0c5b5b52":"code","2fc356e7":"code","633c4a15":"code","5d99c45e":"code","fe667aed":"code","f785aefc":"code","bbe9a242":"code","b991f41b":"code","cee1e69f":"code","138ba6bd":"code","9537389f":"code","5977cee0":"code","424ce55d":"code","f636cbe4":"code","d4e4027c":"markdown","0e1273ee":"markdown","90423fb5":"markdown","31ceb922":"markdown","413b7bbc":"markdown","84487363":"markdown","43dc6b4d":"markdown","84ac4ae0":"markdown","0683ed33":"markdown","1e4882ef":"markdown","eda79273":"markdown","ad0b2dd7":"markdown","f1f6dd0a":"markdown","8be27b84":"markdown","12d011a9":"markdown","e8436109":"markdown","7e2f282b":"markdown","7357764f":"markdown"},"source":{"e64a7301":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c871f8d7":"data=pd.read_csv(\"..\/input\/diabetes.csv\")","173e1dc1":"data.sample(5)","1558b52b":"data.info()","ee4985cd":"sns.countplot(data.Outcome)\nplt.title(\"Diabates Status\",color=\"black\",fontsize=15)","0c5b5b52":"data.Outcome.value_counts()","2fc356e7":"f,ax=plt.subplots(figsize=(15,15))\nsns.heatmap(data.corr(),annot=True,linecolor=\"blue\",fmt=\".2f\",ax=ax)\nplt.show()","633c4a15":"g = sns.pairplot(data, hue=\"Outcome\",palette=\"Set2\",diag_kind = \"kde\",kind = \"scatter\")","5d99c45e":"x=data.drop([\"Outcome\"],axis=1)\ny=data.Outcome.values.reshape(-1,1)","fe667aed":"#Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx = sc.fit_transform(x)","f785aefc":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=0)","bbe9a242":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nlr_prediction= lr.predict(x_test)\n\nlr_cm = confusion_matrix(y_test,lr_prediction)\nprint(\"Logistic Regression Accuracy :\",lr.score(x_test, y_test))","b991f41b":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 16)\nknn.fit(x_train,y_train)\nknn_prediction= knn.predict(x_test)\n\nknn_cm = confusion_matrix(y_test,knn_prediction)\nprint(\"KNN Classification Accuracy :\",knn.score(x_test,y_test))","cee1e69f":"score_list = []\nfor each in range(1,25):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,25),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\nprint(\"Best accuracy is {} with K = {}\".format(np.max(score_list),1+score_list.index(np.max(score_list))))","138ba6bd":"from sklearn.svm import SVC\n\nsvm=SVC(random_state=1)\nsvm.fit(x_train,y_train)\nsvm_prediction= svm.predict(x_test)\n\nsvm_cm = confusion_matrix(y_test,svm_prediction)\nprint(\"Support Vector Classification Accuracy :\",svm.score(x_test,y_test))","9537389f":"from sklearn.naive_bayes import GaussianNB\n\nnb=GaussianNB()\nnb.fit(x_train,y_train)\nnb_prediction= nb.predict(x_test)\n\nnb_cm = confusion_matrix(y_test,nb_prediction)\nprint(\"Naive Bayes Classification Accuracy :\",nb.score(x_test,y_test))","5977cee0":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\ndt_prediction= dt.predict(x_test)\n\ndt_cm = confusion_matrix(y_test,dt_prediction)\nprint(\"Decision Tree Classification Accuracy :\",dt.score(x_test,y_test))","424ce55d":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrf.fit(x_train,y_train)\nrf_prediction= rf.predict(x_test)\n\nrf_cm = confusion_matrix(y_test,rf_prediction)\nprint(\"Random Forest Classification Accuracy :\",rf.score(x_test,y_test))","f636cbe4":"fig = plt.figure(figsize=(15,15))\n\nax1 = fig.add_subplot(3, 3, 1) # row, column, position\nax1.set_title('Logistic Regression Classification')\n\nax2 = fig.add_subplot(3, 3, 2)\nax2.set_title('KNN Classification')\n\nax3 = fig.add_subplot(3, 3, 3)\nax3.set_title('SVM Classification')\n\nax4 = fig.add_subplot(3, 3, 4)\nax4.set_title('Naive Bayes Classification')\n\nax5 = fig.add_subplot(3, 3, 5)\nax5.set_title('Decision Tree Classification')\n\nax6 = fig.add_subplot(3, 3, 6)\nax6.set_title('Random Forest Classification')\n\n\nsns.heatmap(data=lr_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax1, cmap='RdGy')\nsns.heatmap(data=knn_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax2, cmap='RdGy')   \nsns.heatmap(data=svm_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax3, cmap='RdGy')\nsns.heatmap(data=nb_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax4, cmap='RdGy')\nsns.heatmap(data=dt_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax5, cmap='RdGy')\nsns.heatmap(data=rf_cm, annot=True, linewidth=0.5, linecolor='mintcream', fmt='.0f', ax=ax6, cmap='RdGy')\nplt.show()","d4e4027c":"## 6. Conclusion\n* Our data is not balanced.\n* we need more diabetic patient information (outcome=1)\n* Classfication methods have low accuracy between %82 and %75.\n* Logistic Regression gave the best accuracy to us","0e1273ee":"### Random Forest Classification","90423fb5":"### Pupose\n\nI will examine Pima Indians Diabetes Database with supervised learning algorithms and than evaluate classification methods. ","31ceb922":"## 5. Checking Classification Results with Confusion Matrix","413b7bbc":"## 1. Introduction","84487363":"![](https:\/\/healthnavigator.blob.core.windows.net\/cache\/f\/b\/e\/b\/8\/f\/fbeb8f908aefb57046466d208d4e4444c4ee8f2e.jpg)","43dc6b4d":"### Naive Bayes Classification","84ac4ae0":"## Contents\n1. Introduction\n2. Data Analysis\n3. Preparing Data for Machine Learning\n4. Classification Methods\n    * Logistic Regression Classification\n    * KNN Classification\n    * SVM Classification\n    * Naive Bayes Classification\n    * Decision Tree Classification\n    * Random Forest Classification\n5. Checking Classification Results with Confusion Matrix\n6. Conclusion","0683ed33":"## 2. Data Analysis","1e4882ef":"## 3. Preparing Data for Machine Learning","eda79273":"### Logistic Regression Classification","ad0b2dd7":"### What is Diabetes?\n\nDiabetes is a disease that occurs when your blood glucose, also called blood sugar, is too high. Blood glucose is your main source of energy and comes from the food you eat. Insulin, a hormone made by the pancreas, helps glucose from food get into your cells to be used for energy. Sometimes your body doesn\u2019t make enough\u2014or any\u2014insulin or doesn\u2019t use insulin well. Glucose then stays in your blood and doesn\u2019t reach your cells.\n\nOver time, having too much glucose in your blood can cause health problems. Although diabetes has no cure, you can take steps to manage your diabetes and stay healthy.","f1f6dd0a":"## 4. Classification Methods","8be27b84":"### KNN Classification","12d011a9":"### Data\n\n\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n\n* **Pregnancies**: Number of times pregnant\n* **Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n* **BloodPressure**: Diastolic blood pressure (mm Hg)\n* **SkinThickness**: Triceps skin fold thickness (mm)\n* **Insulin**: 2-Hour serum insulin (mu U\/ml)\n* **BMI**: Body mass index (weight in kg\/(height in m)^2)\n* **DiabetesPedigreeFunction**: Diabetes pedigree function\n* **Age**: Age (years)\n* **Outcome**: Class variable (0 or 1)\n","e8436109":"### Decision Tree Classification","7e2f282b":"# Evaluation of Classification Methods","7357764f":"### SVM Classification"}}