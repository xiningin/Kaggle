{"cell_type":{"85b76e3f":"code","a757d708":"code","98c50f5f":"code","ada042e7":"code","e5dd50a0":"code","d4f55aa5":"code","89101e67":"code","b084c1dc":"code","3f1155d9":"code","8ce255fe":"code","34608356":"code","18581b63":"code","dbba6429":"code","902cc058":"markdown","5a841581":"markdown","15727d27":"markdown","5c4a0d36":"markdown","25ec8d82":"markdown","1702de11":"markdown","208c94c5":"markdown","4682f887":"markdown","b86ad248":"markdown","a46302be":"markdown","547ac69f":"markdown","bfc05d01":"markdown","a639a28d":"markdown","bd217b23":"markdown","b83cd856":"markdown","5caa6854":"markdown","2f2f7aea":"markdown","fae9ce89":"markdown","8fcc869c":"markdown","12e8c547":"markdown","6b1c4f7c":"markdown","a5b28ae6":"markdown","7d30004e":"markdown","45352741":"markdown"},"source":{"85b76e3f":"import warnings\nwarnings.filterwarnings('ignore')\n\n#Basic data manipulation libraries\nimport pandas as pd, numpy as np\nimport math, json, gc, random, os, sys\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\n#Deep Learning Libraries\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\n\n#Library for model evaluation\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold","a757d708":"SEED = 731\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\nseed_everything(SEED)","98c50f5f":"FOLDS = 6\nepoch = 200\nVERBOSE = 0","ada042e7":"train = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntest = pd.read_json('\/kaggle\/input\/stanford-covid-vaccine\/test.json', lines=True)\nsample_sub = pd.read_csv('\/kaggle\/input\/stanford-covid-vaccine\/sample_submission.csv')\n\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n\ntoken2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(df[cols].applymap(lambda seq: [token2int[x] for x in seq]).values.tolist()),\n        (0, 2, 1))\n\ntrain_inputs = preprocess_inputs(train[train.signal_to_noise > 1])\ntrain_labels = np.array(train[train.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))","e5dd50a0":"train.head()","d4f55aa5":"REG=0","89101e67":"def MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","b084c1dc":"def gru_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.GRU(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef lstm_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.LSTM(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n    \n\ndef build_model(gru=1,seq_len=107, pred_len=68, dropout=0.5,\n                embed_dim=160, hidden_dim=384):\n    \n    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n\n    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    \n    reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n    \n    \n    if gru==0:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==1:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==2:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==3:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==4:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n    elif gru==5:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n    \n    elif gru==6:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n    elif gru==7:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n    \n    #only making predictions on the first part of each sequence\n    truncated = hidden[:, :pred_len]\n    \n    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n\n    model = tf.keras.Model(inputs=inputs, outputs=out)\n\n    #some optimizers\n    adam = tf.optimizers.Adam()\n    radam = tfa.optimizers.RectifiedAdam()\n    lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n    ranger = tfa.optimizers.Lookahead(radam, sync_period=6)\n    \n    #model.compile(optimizer=adam, loss='mse')\n    model.compile(optimizer=adam, loss=MCRMSE)\n    \n    return model","3f1155d9":"#train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs, train_labels, test_size=.1, random_state=34)","8ce255fe":"es =tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto',\n    baseline=None, restore_best_weights=False)\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(verbose=0)","34608356":"kf = KFold(n_splits=FOLDS, shuffle=True,random_state=SEED)\nrskf = RepeatedStratifiedKFold(FOLDS, n_repeats = 1, random_state = SEED)\ntrain_inputs_ = train_inputs\ntrain_labels_ = train_labels\nprint(train_inputs_.shape,train_labels_.shape)\nfor fold, (train_index, val_index) in enumerate(kf.split(train_inputs_,train_labels_)):\n#for fold, (train_index, val_index) in enumerate(rskf.split(train_inputs, train['SN_filter'][:2096])):\n    print(f\"fold {fold} has train:{len(train_index)}, val:{len(val_index)}\")\n    train_inputs=train_inputs_[train_index]\n    train_labels=train_labels_[train_index]\n    val_inputs=train_inputs_[val_index]\n    val_labels=train_labels_[val_index]\n    \n    tf.keras.backend.clear_session()\n    \"\"\"\n    for e in [96,128,160,192]:\n        for h in [128,192,256,384]:\n            gru = build_model(gru=2,embed_dim=e, hidden_dim=h)\n            sv_gru = tf.keras.callbacks.ModelCheckpoint('model_gru.h5', save_best_only=True)\n\n            history_gru = gru.fit(\n                train_inputs, train_labels, \n                validation_data=(val_inputs,val_labels),\n                batch_size=64,\n                epochs=epoch,\n                callbacks=[lr_callback,sv_gru,es],\n                verbose = VERBOSE\n            )\n            print(f\"in emb_dim={e}, hid_dim={h}, Min training loss={min(history_gru.history['loss'])}, min validation loss={min(history_gru.history['val_loss'])}\")\n            \n    break\n    \"\"\"\n    gru = build_model(gru=0)\n    sv_gru = tf.keras.callbacks.ModelCheckpoint('model_gru.h5', save_best_only=True)\n    \n    history_gru = gru.fit(\n        train_inputs, train_labels, \n        validation_data=(val_inputs,val_labels),\n        batch_size=64,\n        epochs=epoch,\n        callbacks=[lr_callback,sv_gru,es],\n        verbose = VERBOSE\n    )\n    \n    print(f\"Min training loss={min(history_gru.history['loss'])}, min validation loss={min(history_gru.history['val_loss'])}\")\n\n    lstm = build_model(gru=7)\n    sv_lstm = tf.keras.callbacks.ModelCheckpoint('model_lstm.h5', save_best_only=True)\n\n    history_lstm = lstm.fit(\n        train_inputs, train_labels, \n        validation_data=(val_inputs,val_labels),\n        batch_size=64,\n        epochs=epoch,\n        callbacks=[lr_callback,sv_lstm,es],\n        verbose = VERBOSE\n    )\n\n    print(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")\n\n    lstm = build_model(gru=1)\n    sv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb1.h5', save_best_only=True)\n\n    history_lstm = lstm.fit(\n        train_inputs, train_labels, \n        validation_data=(val_inputs,val_labels),\n        batch_size=64,\n        epochs=epoch,\n        callbacks=[lr_callback,sv_lstm,es],\n        verbose = VERBOSE\n    )\n\n    print(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")\n\n    lstm = build_model(gru=2)\n    sv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb2.h5', save_best_only=True)\n\n    history_lstm = lstm.fit(\n        train_inputs, train_labels, \n        validation_data=(val_inputs,val_labels),\n        batch_size=64,\n        epochs=epoch,\n        callbacks=[lr_callback,sv_lstm,es],\n        verbose = VERBOSE\n    )\n\n    print(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")\n\n    lstm = build_model(gru=3)\n    sv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb3.h5', save_best_only=True)\n\n    history_lstm = lstm.fit(\n        train_inputs, train_labels, \n        validation_data=(val_inputs,val_labels),\n        batch_size=64,\n        epochs=epoch,\n        callbacks=[lr_callback,sv_lstm,es],\n        verbose = VERBOSE\n    )\n\n    print(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")\n\n    lstm = build_model(gru=4)\n    sv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb4.h5', save_best_only=True)\n\n    history_lstm = lstm.fit(\n        train_inputs, train_labels, \n        validation_data=(val_inputs,val_labels),\n        batch_size=64,\n        epochs=epoch,\n        callbacks=[lr_callback,sv_lstm,es],\n        verbose = VERBOSE\n    )\n\n    print(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")\n\n    lstm = build_model(gru=5)\n    sv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb5.h5', save_best_only=True)\n\n    history_lstm = lstm.fit(\n        train_inputs, train_labels, \n        validation_data=(val_inputs,val_labels),\n        batch_size=64,\n        epochs=epoch,\n        callbacks=[lr_callback,sv_lstm,es],\n        verbose = VERBOSE\n    )\n\n    print(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")\n\n    lstm = build_model(gru=6)\n    sv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb6.h5', save_best_only=True)\n\n    history_lstm = lstm.fit(\n        train_inputs, train_labels, \n        validation_data=(val_inputs,val_labels),\n        batch_size=64,\n        epochs=epoch,\n        callbacks=[lr_callback,sv_lstm,es],\n        verbose = VERBOSE\n    )\n\n    print(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")\n\n    public_df = test.query(\"seq_length == 107\").copy()\n    private_df = test.query(\"seq_length == 130\").copy()\n\n    public_inputs = preprocess_inputs(public_df)\n    private_inputs = preprocess_inputs(private_df)\n\n    # build all models\n    gru_short = build_model(gru=0, seq_len=107, pred_len=107)\n    gru_long = build_model(gru=0, seq_len=130, pred_len=130)\n    lstm_short = build_model(gru=7, seq_len=107, pred_len=107)\n    lstm_long = build_model(gru=7, seq_len=130, pred_len=130)\n    hyb1_short = build_model(gru=1, seq_len=107, pred_len=107)\n    hyb1_long = build_model(gru=1, seq_len=130, pred_len=130)\n    hyb2_short = build_model(gru=2, seq_len=107, pred_len=107)\n    hyb2_long = build_model(gru=2, seq_len=130, pred_len=130)\n    hyb3_short = build_model(gru=3, seq_len=107, pred_len=107)\n    hyb3_long = build_model(gru=3, seq_len=130, pred_len=130)\n    hyb4_short = build_model(gru=4, seq_len=107, pred_len=107)\n    hyb4_long = build_model(gru=4, seq_len=130, pred_len=130)\n    hyb5_short = build_model(gru=5, seq_len=107, pred_len=107)\n    hyb5_long = build_model(gru=5, seq_len=130, pred_len=130)\n    hyb6_short = build_model(gru=6, seq_len=107, pred_len=107)\n    hyb6_long = build_model(gru=6, seq_len=130, pred_len=130)\n\n\n    # load pre-trained model weights\n    gru_short.load_weights('model_gru.h5')\n    gru_long.load_weights('model_gru.h5')\n    lstm_short.load_weights('model_lstm.h5')\n    lstm_long.load_weights('model_lstm.h5')\n    hyb1_short.load_weights('model_hyb1.h5')\n    hyb1_long.load_weights('model_hyb1.h5')\n    hyb2_short.load_weights('model_hyb2.h5')\n    hyb2_long.load_weights('model_hyb2.h5')\n    hyb3_short.load_weights('model_hyb3.h5')\n    hyb3_long.load_weights('model_hyb3.h5')\n    hyb4_short.load_weights('model_hyb4.h5')\n    hyb4_long.load_weights('model_hyb4.h5')\n    hyb5_short.load_weights('model_hyb5.h5')\n    hyb5_long.load_weights('model_hyb5.h5')\n    hyb6_short.load_weights('model_hyb6.h5')\n    hyb6_long.load_weights('model_hyb6.h5')\n\n\n    # and predict\n    gru_public_preds = gru_short.predict(public_inputs)\n    gru_private_preds = gru_long.predict(private_inputs)\n    lstm_public_preds = lstm_short.predict(public_inputs)\n    lstm_private_preds = lstm_long.predict(private_inputs)\n    hyb1_public_preds = hyb1_short.predict(public_inputs)\n    hyb1_private_preds = hyb1_long.predict(private_inputs)\n    hyb2_public_preds = hyb2_short.predict(public_inputs)\n    hyb2_private_preds = hyb2_long.predict(private_inputs)\n    hyb3_public_preds = hyb3_short.predict(public_inputs)\n    hyb3_private_preds = hyb3_long.predict(private_inputs)\n    hyb4_public_preds = hyb4_short.predict(public_inputs)\n    hyb4_private_preds = hyb4_long.predict(private_inputs)\n    hyb5_public_preds = hyb5_short.predict(public_inputs)\n    hyb5_private_preds = hyb5_long.predict(private_inputs)\n    hyb6_public_preds = hyb6_short.predict(public_inputs)\n    hyb6_private_preds = hyb6_long.predict(private_inputs)\n\n    preds_gru = []\n\n    for df, preds in [(public_df, gru_public_preds), (private_df, gru_private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds_gru.append(single_df)\n\n    preds_gru_df = pd.concat(preds_gru)\n\n    preds_lstm = []\n\n    for df, preds in [(public_df, lstm_public_preds), (private_df, lstm_private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds_lstm.append(single_df)\n\n    preds_lstm_df = pd.concat(preds_lstm)\n\n\n    preds_hyb1 = []\n\n    for df, preds in [(public_df, hyb1_public_preds), (private_df, hyb1_private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds_hyb1.append(single_df)\n\n    preds_hyb1_df = pd.concat(preds_hyb1)\n\n\n    preds_hyb2 = []\n\n    for df, preds in [(public_df, hyb2_public_preds), (private_df, hyb2_private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds_hyb2.append(single_df)\n\n    preds_hyb2_df = pd.concat(preds_hyb2)\n\n    preds_hyb3 = []\n\n    for df, preds in [(public_df, hyb3_public_preds), (private_df, hyb3_private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds_hyb3.append(single_df)\n\n    preds_hyb3_df = pd.concat(preds_hyb3)\n\n    preds_hyb4 = []\n\n    for df, preds in [(public_df, hyb4_public_preds), (private_df, hyb4_private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds_hyb4.append(single_df)\n\n    preds_hyb4_df = pd.concat(preds_hyb4)\n\n    preds_hyb5 = []\n\n    for df, preds in [(public_df, hyb5_public_preds), (private_df, hyb5_private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds_hyb5.append(single_df)\n\n    preds_hyb5_df = pd.concat(preds_hyb5)\n\n    preds_hyb6 = []\n\n    for df, preds in [(public_df, hyb6_public_preds), (private_df, hyb6_private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds_hyb6.append(single_df)\n\n    preds_hyb6_df = pd.concat(preds_hyb6)\n\n\n\n    blend_preds_df = pd.DataFrame()\n    blend_preds_df['id_seqpos'] = preds_gru_df['id_seqpos']\n    blend_preds_df['reactivity'] = 0.2*preds_gru_df['reactivity'] + 0.2*preds_lstm_df['reactivity'] + 0.2*preds_hyb1_df['reactivity'] + 0.2*preds_hyb2_df['reactivity'] + 0.2*preds_hyb3_df['reactivity']+ 0.2*preds_hyb4_df['reactivity'] + 0.2*preds_hyb5_df['reactivity'] + 0.2*preds_hyb6_df['reactivity']\n    blend_preds_df['deg_Mg_pH10'] = 0.2*preds_gru_df['deg_Mg_pH10'] + 0.2*preds_lstm_df['deg_Mg_pH10'] + 0.2*preds_hyb1_df['deg_Mg_pH10'] + 0.2*preds_hyb2_df['deg_Mg_pH10'] + 0.2*preds_hyb3_df['deg_Mg_pH10']+ 0.2*preds_hyb4_df['deg_Mg_pH10'] + 0.2*preds_hyb5_df['deg_Mg_pH10'] + 0.2*preds_hyb6_df['deg_Mg_pH10']\n    blend_preds_df['deg_pH10'] = 0.2*preds_gru_df['deg_pH10'] + 0.2*preds_lstm_df['deg_pH10'] + 0.2*preds_hyb1_df['deg_pH10'] + 0.2*preds_hyb2_df['deg_pH10'] + 0.2*preds_hyb3_df['deg_pH10']+ 0.2*preds_hyb4_df['deg_pH10'] + 0.2*preds_hyb5_df['deg_pH10'] + 0.2*preds_hyb6_df['deg_pH10']\n    blend_preds_df['deg_Mg_50C'] = 0.2*preds_gru_df['deg_Mg_50C'] + 0.2*preds_lstm_df['deg_Mg_50C'] + 0.2*preds_hyb1_df['deg_Mg_50C'] + 0.2*preds_hyb2_df['deg_Mg_50C'] + 0.2*preds_hyb3_df['deg_Mg_50C']+ 0.2*preds_hyb4_df['deg_Mg_50C'] + 0.2*preds_hyb5_df['deg_Mg_50C'] + 0.2*preds_hyb6_df['deg_Mg_50C']\n    blend_preds_df['deg_50C'] = 0.2*preds_gru_df['deg_50C'] + 0.2*preds_lstm_df['deg_50C'] + 0.2*preds_hyb1_df['deg_50C'] + 0.2*preds_hyb2_df['deg_Mg_50C'] + 0.2*preds_hyb3_df['deg_Mg_50C']+ 0.2*preds_hyb4_df['deg_50C'] + 0.2*preds_hyb5_df['deg_Mg_50C'] + 0.2*preds_hyb6_df['deg_Mg_50C']\n\n    blend_preds_df['reactivity'] \/=1.6\n    blend_preds_df['deg_Mg_pH10'] \/=1.6\n    blend_preds_df['deg_pH10'] \/=1.6\n    blend_preds_df['deg_Mg_50C']\/=1.6\n    blend_preds_df['deg_50C'] \/=1.6\n\n    sample_sub = pd.read_csv('\/kaggle\/input\/stanford-covid-vaccine\/sample_submission.csv')\n    submission = sample_sub[['id_seqpos']].merge(blend_preds_df, on=['id_seqpos'])\n\n    submission.head()\n\n    #Saving the final output file\n    submission.to_csv(f\"submission_{fold}.csv\", index=False)\n    ","18581b63":"files = []\nfor i in range(FOLDS):\n    csv = pd.read_csv(f'.\/submission_{i}.csv')\n    files.append(csv)\n\ntotal = pd.concat(files, axis=1)\ntotal.head()\ncol = list(submission.columns)[1:]\nprint(col)\nsubmission1 = submission\nfor c in col:\n    submission1[c] = total[c].mean(axis=1)\nsubmission1.to_csv('submission.csv', index=False)\nsubmission1.head()\n","dbba6429":"submission.head()","902cc058":"<a href=\"https:\/\/ibb.co\/55WvtCS\"><img src=\"https:\/\/i.ibb.co\/19fKhBP\/6.jpg\" alt=\"6\" border=\"0\"><\/a>","5a841581":"# * this notebook is based [Aman Kumar's](https:\/\/www.kaggle.com\/aestheteaman01) [notebook.](https:\/\/www.kaggle.com\/aestheteaman01\/mvan-covid-mrna-vaccine-analysis-notebook-268)","15727d27":"<h3> Notebook Detail Study <\/h3>\n\nWinning the fight against the COVID-19 pandemic will require an effective vaccine that can be equitably and widely distributed. Building upon decades of research has allowed scientists to accelerate the search for a vaccine against COVID-19, but every day that goes by without a vaccine has enormous costs for the world nonetheless\n\nThis notebook speaks about the Stanford University : mRNA Vaccine Degradation Predication Challenge. Apart from this an attempt is made by me to analyze why we should contribute globally to accelerate this research of mRNA Vaccine Stability, how COVID-19 has impacted the world in many ways. Also, a descriptive study has been highlighted in this notebook regarding the urgency of a COVID vaccine as excess deaths have been recorded across all age groups. ","5c4a0d36":"# Had there been any mRNA Vaccine research for diseases?\n\n\n<h3> mRNA-based active cancer immunotherapy, combined with local radiation treatment in patients with stage IV non-small cell lung cancer<\/h3>  \n\nSources : https:\/\/jitc.biomedcentral.com\/articles\/10.1186\/s40425-019-0520-5  \n\n\n\n<h3> About mRNA Association with Small Cell Lung Cancer <\/h3>\n\nPreviously research has been carried out regarding the usasge of mRNA based immunotherapy for treatment of small cell Lung Cancer.\nPreclinical studies demonstrate synergism between cancer immunotherapy and local radiation, enhancing anti-tumor effects and promoting immune responses. BI1361849 (CV9202) is an active cancer immunotherapeutic comprising protamine-formulated, sequence-optimized mRNA encoding six non-small cell lung cancer (NSCLC)-associated antigens (NY-ESO-1, MAGE-C1, MAGE-C2, survivin, 5T4, and MUC-1), intended to induce targeted immune responses.\n\n<h3> Okay, but why we are discussing this? <\/h3>\n\nAs per multiple reports the figures of deviation of the medical parameters and blood factors is prominent in lung cancer as well. i.e. Similar symptoms are observed in Lung Cancer as seen in Covid-19 cases. (Research undergoing)\n\nMuch detail on the section of comorbidities and on this is available at one of my notebooks:  \nhttps:\/\/www.kaggle.com\/aestheteaman01\/covid19-analysis-notebook-on-comorbidities-cance","25ec8d82":"<H3> Analysis of Electrolyte Abnormalities <\/h3>\n\n\n<img src=\"https:\/\/i.ibb.co\/gTjCb0X\/4.png\" alt=\"4\" border=\"0\">\n\nPatients diagnosed with lung cancer show a wide distribution of ferritin levels, however, it peaks around +0.5 standard deviation unites which is similar to the peak of ferritin levels of patients tested positive for COVID-19. These levels are higher than what is observed for patients tested negative in the COVID-19 test (mean equivalent to -0.5 standard deviation units).\n\nWe can conclude from these observations that patients who retracted COVID-19 have similar electrolyte abnormalities as patients with lung cancer. **Hence a positive research on the mRNA Vaccine can be the game changing move to develop a successful vaccine for COVID-19.**","1702de11":"# The mRNA Vaccine : Would this be a saver?\n\n<h3> Understanding the working of mRNA Vaccine and what are the problems associated with the same: <\/h3>\nSources : https:\/\/www.nature.com\/articles\/nrd.2017.243","208c94c5":"<h1> mVAN - COVID-19 mRNA Vaccine Analysis Notebook <\/h1>\n\n<h2> Understanding the COVID-19 mRNA Vaccine : Usage, Challenges and Reactivity <\/h2>","4682f887":"<h3> Training the GRU Model <\/h3>","b86ad248":"<h3> How are the above average deaths due to COVID-19 distributed globally? <\/h3>\n\n<img src=\"https:\/\/i.ibb.co\/pxk72r2\/Annotation-2020-06-27-011905.jpg\" alt=\"Annotation-2020-06-27-011905\" border=\"0\" align='left' width=\"800\" height=\"800\">","a46302be":"<h3> Importing the Libraries <\/h3>","547ac69f":"<h3> How the data looks? <\/h3>","bfc05d01":"<h3> Analyses from the Graphs for deaths due to COVID-19 <\/h3>\n\nOften the cause of death takes several days to establish and report, which creates a lag in the data. And even the most complete covid-19 records will not count people who were killed by conditions that might normally have been treated, had hospitals not been overwhelmed by a surge of patients needing intensive care. - Economist  [(See Here)](https:\/\/www.economist.com\/graphic-detail\/2020\/04\/16\/tracking-covid-19-excess-deaths-across-countries)\n\nA better way to measure the damage caused by such a medical crisis is to look at \u201cexcess mortality\u201d: the gap between the total number of people who died from any cause, and the historical average for the same place and time of year.","a639a28d":"<h3> Getting the data with some basic EDA <\/h3>","bd217b23":"<h3> About the mRNA Vaccine <\/h3>\n\nmRNA vaccines represent a promising alternative to conventional vaccine approaches because of their high potency, capacity for rapid development and potential for low-cost manufacture and safe administration. However, their application has until recently been restricted by the instability and inefficient in vivo delivery of mRNA. Recent technological advances have now largely overcome these issues, and multiple mRNA vaccine platforms against infectious diseases and several types of cancer have demonstrated encouraging results in both animal models and humans. This Review provides a detailed overview of mRNA vaccines and considers future directions and challenges in advancing this promising vaccine platform to widespread therapeutic use.\n\n<h3> mRNA Vaccine - The considerable points <\/h3>\n\n\n* Recent improvements in mRNA vaccines act to increase protein translation, modulate innate and adaptive immunogenicity and improve delivery.\n\n* mRNA vaccines have elicited potent immunity against infectious disease targets in animal models of influenza virus, Zika virus, rabies virus and others, especially in recent years, using lipid-encapsulated or naked forms of sequence-optimized mRNA.\n\n* Diverse approaches to mRNA cancer vaccines, including dendritic cell vaccines and various types of directly injectable mRNA, have been employed in numerous cancer clinical trials, with some promising results showing antigen-specific T cell responses and prolonged disease-free survival in some cases.\n\n* Therapeutic considerations and challenges include scaling up good manufacturing practice (GMP) production, establishing regulations, further documenting safety and increasing efficacy.\n\n<h3> The issues with mRNA Vaccine <\/h3>\n\n* Designing super stable messenger RNA molecules (mRNA).\n* RNA molecules have the tendency to spontaneously degrade. This is a serious limitation--a single cut can render the mRNA vaccine useless. \n\nCurrently, little is known on the details of where in the backbone of a given RNA is most prone to being affected. Without this knowledge, current mRNA vaccines against COVID-19 must be prepared and shipped under intense refrigeration, and are unlikely to reach more than a tiny fraction of human beings on the planet unless they can be stabilized.","b83cd856":"<h3> Defining the Neural Network Layers <\/h3>","5caa6854":"# mRNA Small Cell Lung Cancer IV vs. COVID-19 Associations \n\n\n<H3> 1. The count of blood components <\/H3>\n\nPatients tested positive for COVID-19 show significantly lower levels of platelets, leukocytes and eosinophils. We can also observe lower levels of calcium and magnesium, but significantly higher concentrations of ferritin, in comparison to patients tested negative for COVID-19.\n\nThe decrease in white blood cells (leukocytes) can either be a direct result of the COVID-19 infection or other pre-existing conditions. This decrease lowers patient immunity against COVID-19 and other infections in general. Additionally, electrolytes and minerals such as potassium, magnesium and zinc play a critical role in maintaining vitality, repairing cell damage, as well as immunity.\n\n<H3> 2. The Associations <\/H3>\n\nBy extracting clinical data from the literature, we can examine the abnormalities in blood tests in patients diagnosed with cancer and patients testing positive for COVID-19. Blood test results for multiple minerals were extracted for patients with lung cancer and compared with levels seen in COVID-19 patients. [1,2]\n\nBecause the clinical data available for patients tested for COVID-19 is normalised, measurements retrieved for cancer patients were also normalised using blood concentration in control groups as the mean. The published data has reported the mean and standard deviation of the measurements instead of individual readings, we use these metrics to simulate mineral concentrations in cancer patients assuming a normal distribution. The measurements retrieved from studies were for Magnesium, Ferritin and Zinc in both cancer patients as well as control groups.\n\n<img src=\"https:\/\/i.ibb.co\/3WgqNGV\/2.png\" alt=\"2\" border=\"0\">","2f2f7aea":"I hope that this notebook can act as a good starter code, giving light on both the current condition of the situation and the importance of the mRNA Vaccine and the associated research with the same. This notebook would be updated by me to check for much newer and diverse data to analyze more trends. I'll try to see around Kaggle contributions and try to modify the codes accordingly and publish them.\n\nContact LinkedIn - https:\/\/www.linkedin.com\/in\/amankumar01\/\n\nFeel free to edit this notebook as per your will. **Do upvote and comment if you like or wish to suggest something.\nSpecial thanks to all the contributors, for making their work public, which help me to write this notebook.**","fae9ce89":"<H3> Understanding Excess Deaths due to COVID-19 <\/H3>\n\n<img src=\"https:\/\/i.ibb.co\/Tg5Kjn9\/4.jpg\" alt=\"4\" border=\"0\" align='left' width=\"800\" height=\"800\">","8fcc869c":"<h3> Understandings from the Graphs Above <\/h3>\n\n1. The deaths due to COVID-19 has exceeded the average range of deaths for the past years.\n2. The death trends are variable w.r.t Age. For the lower age groups less death due to COVID-19 was recorded.\n\nWe see the urgency of a vaccine since the deaths exceed the normal average figures for death.","12e8c547":"# The unwanted COVID-19 Deaths - The Vaccine Need\n\n<h3> Understanding Above Average COVID-19 Deaths across geogrpahies and age groups <\/h3>","6b1c4f7c":"# Stanford mRNA Degradation Predictor\n\n\n<H3> Solving the task challenge of mRNA Vaccine Degradation Predictor the RNA Base Pairs <\/H3>  \n\nSpecial thanks to Tucker Arrants. The set of codes were collected from his notebook mentioned below.  \nhttps:\/\/www.kaggle.com\/tuckerarrants\/openvaccine-gru-lstm\n\n","a5b28ae6":"<h3> Train-Test Split of the dataset <\/h3>","7d30004e":"\n# The next big steps\n\nI hope that this notebook can act as a good starter code, giving light on both the current condition of the situation and the importance of the mRNA Vaccine and the associated research with the same. This notebook would be updated by me to check for much newer and diverse data to analyze more trends. I'll try to see around Kaggle contributions and try to modify the codes accordingly and publish them.\n\nContact LinkedIn - https:\/\/www.linkedin.com\/in\/amankumar01\/\n\nFeel free to edit this notebook as per your will. Do upvote and comment if you like or wish to suggest something.\nSpecial thanks to all the contributors, for making their work public, which help me to write this notebook.","45352741":"The charts use data from EuroMOMO, a network of epidemiologists who collect weekly reports on deaths from all causes in 24 European countries, covering 350m people. Compared to the baseline average of deaths from 2009-19, the flu seasons of 2017, 2018 and 2019 were all unusually lethal. But the covid-19 pandemic, which arrived much later in the year, has already reached a higher peak\u2014and would have been far more damaging without social-distancing measures. EuroMOMO\u2019s figures suggest that there were about 170,000 excess deaths between March 16th and May 31st.\n\n<h3> How are Excess Deaths of COVID-19 related to Age? <\/h3>\n\nDoes deaths due to COVID-19 above average across all age group? Or do the older ones need to be immunized first and later the younger ones?\n\n<img src=\"https:\/\/i.ibb.co\/x6zmw9K\/5.jpg\" alt=\"5\" border=\"0\" align='left' width=\"1000\" height=\"1000\"><\/a>"}}