{"cell_type":{"6226f14c":"code","50f228b7":"code","409cbc01":"code","05ee44b6":"code","4e1cf1dc":"code","49e98927":"code","3e8ed695":"code","5367b6ff":"code","9551e967":"code","6952a34e":"code","b6e6b60f":"code","491905ee":"code","7503450b":"code","a800972e":"code","6baec0f8":"code","78a79d82":"code","233db151":"code","f56f2aad":"code","218fc6fc":"code","f69e9090":"code","4768e61c":"code","13addb82":"code","3513d8dc":"code","6e6a4702":"markdown","c89ce7d4":"markdown","ac86916c":"markdown"},"source":{"6226f14c":"import pandas as pd\ntrain = pd.read_csv(\"..\/input\/ranzcr-clip-catheter-line-classification\/train.csv\")","50f228b7":"import plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport cv2","409cbc01":"cols = [\n    'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', \n    'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', \n    'NGT - Normal', 'CVC - Abnormal', 'CVC - Borderline', \n    'CVC - Normal', 'Swan Ganz Catheter Present'\n]\n\nfig = make_subplots(rows=4, cols=3)\n\ntraces = [\n    go.Bar(\n        x=[0, 1], \n        y=[\n            len(train[train[col]==0]),\n            len(train[train[col]==1])\n        ], \n        name=col,\n        text = [\n            str(round(100 * len(train[train[col]==0]) \/ len(train), 2)) + '%',\n            str(round(100 * len(train[train[col]==1]) \/ len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ) for col in cols\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i \/\/ 3) + 1, (i % 3)  +1)\n\nfig.update_layout(\n    title_text='Train columns',\n    height=1200,\n    width=1000\n)\n\nfig.show()","05ee44b6":"import os\nf, plots = plt.subplots(1, 5, sharex='col', sharey='row', figsize=(17, 17))\nsamples = train.sample(n=5, random_state=666)['StudyInstanceUID'].values\n\nfor i in range(5):\n    image = cv2.imread(os.path.join(\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/\", f\"{samples[i]}.jpg\"))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plots[i].imshow(image)","4e1cf1dc":"train.iloc[:, 1:-1].sum()","49e98927":"plt.hist(train.iloc[:, 1:-1].sum())","3e8ed695":"import random, os\nimport numpy as np\nimport torch\nfrom fastai.vision.all import *\nfrom fastai.callback import mixup\npath = Path('..\/input\/ranzcr-clip-catheter-line-classification\/')\npath.ls()","5367b6ff":"train['path'] = train.StudyInstanceUID.map(lambda x:str(path \/ 'train' \/ x)+'.jpg')","9551e967":"labels = list(train.columns[1:12].values)\nlabels","6952a34e":"def get_y(fname):\n    return fname[1:12].values.astype(np.float32)\n\ndef get_x(fname):\n    return fname[-1]","b6e6b60f":"item_tfms = RandomResizedCrop(256, min_scale=0.75, ratio=(1.,1.))\n\ndls = DataBlock(blocks=(ImageBlock, MultiCategoryBlock(encoded=True, vocab=labels)),\n                        get_x = get_x,get_y = get_y,  \n                        item_tfms = item_tfms)","491905ee":"dls = dls.dataloaders(train)\ndls.show_batch()","7503450b":"learn = cnn_learner(dls, resnet152, metrics = [accuracy_multi], cbs=[mixup.MixUp()], model_dir=\"\/tmp\/model\/\").to_native_fp16()","a800972e":"learn = cnn_learner(dls, resnet50, metrics = [accuracy_multi], cbs=[mixup.MixUp()], model_dir=\"\/tmp\/model\/\").to_native_fp16()","6baec0f8":"learn.lr_find()","78a79d82":"learn.fine_tune(3, 2e-2)","233db151":"learn = learn.to_native_fp32()","f56f2aad":"path = Path('..\/input\/ranzcr-clip-catheter-line-classification')","218fc6fc":"submission_df = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')\nsubmission_df.iloc[:,1:] = submission_df.iloc[:,1:].astype(float)","f69e9090":"test_data_path = submission_df['StudyInstanceUID'].apply(lambda x: path\/'test'\/(x+'.jpg'))\ntst_dl = learn.dls.test_dl(test_data_path)\npreds,targs = learn.tta(dl = tst_dl)","4768e61c":"columns = list(train.columns[1:12])","13addb82":"submission_df[columns] = pd.DataFrame(preds,columns=columns)\n# submission_df","3513d8dc":"submission_df.to_csv('submission.csv',index=False)  ","6e6a4702":"## What are we predicting?\n\nIn this competition, you\u2019ll detect the presence and position of catheters and lines on chest x-rays. Use machine learning to train and test your model on 40,000 images to categorize a tube that is poorly placed.\n\n## Evaluation criteria?\n\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\nTo calculate the final score, AUC is calculated for each of the 11 labels, then averaged. The score is then the average of the individual AUCs of each predicted column.\n\n## Train vs Test?\n\nA code-only competition so there is a hidden test set (approximately 4x larger, with ~14k images) as well.\n\ntrain.csv contains image IDs, binary labels, and patient IDs.\n\nTFRecords are available for both train and test. (They are also available for the hidden test set.)\n\ntrain_annotations.csv includes segmentation annotations for training samples that have them as solely additional information.\n\n## Similar Dataset & Competitions?\n\n[RSNA Pneumonia Detection Challenge](\"https:\/\/www.kaggle.com\/c\/rsna-pneumonia-detection-challenge\/notebooks\")\n\n[SIIM-ACR Pneumothorax Segmentation](\"https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\")\n\n[XRay Lung Segmentation](\"https:\/\/www.kaggle.com\/c\/xray-lung-segmentation\/data\")\n\n[RSNA Pneumonia Detection Challenge](\"https:\/\/www.kaggle.com\/c\/rsna-pneumonia-detection-challenge\/notebooks\")\n\nHave more?","c89ce7d4":"## Read","ac86916c":"[Creds](\"https:\/\/www.kaggle.com\/isaienkov\/ranzcr-clip-data-understanding\")"}}