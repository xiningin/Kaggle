{"cell_type":{"87f4f133":"code","f5fd11e4":"code","f4666561":"code","1bfac87f":"code","b41f8230":"code","eddcc147":"code","19de43d7":"code","372975da":"code","84aaf38f":"code","c01ab518":"code","31507544":"code","432dfa9b":"code","6ab4e61a":"code","f3dd902a":"code","dea721d8":"markdown"},"source":{"87f4f133":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport os\nfrom scipy.interpolate import interp1d\nimport gc\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GroupKFold\nimport lightgbm as lgb\nfrom joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\n\nimport soundfile as sf\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import roc_auc_score, label_ranking_average_precision_score","f5fd11e4":"trainfiles = glob.glob( '..\/input\/rfcx-species-audio-detection\/train\/*.flac' )\ntestfiles = glob.glob( '..\/input\/rfcx-species-audio-detection\/test\/*.flac' )\nlen(trainfiles), len(testfiles), trainfiles[0]","f4666561":"traint = pd.read_csv( '..\/input\/rfcx-species-audio-detection\/train_tp.csv' )\ntrainf = pd.read_csv( '..\/input\/rfcx-species-audio-detection\/train_fp.csv' )\ntraint.shape, trainf.shape","1bfac87f":"traint.head()","b41f8230":"trainf.head()","eddcc147":"def extract_features(fn):\n    data, samplerate = sf.read(fn)\n\n    varfft = np.abs( np.fft.fft(data)[:(len(data)\/\/2)] )\n    x = np.linspace(0, len(varfft), num=len(varfft), endpoint=True)\n    f1 = interp1d(x, varfft, kind='cubic')\n    x = np.linspace(0, len(varfft), num=1000, endpoint=True)\n    varfft = f1(x)\n    \n    return varfft","19de43d7":"FT = Parallel(n_jobs=4)(delayed(extract_features)( '..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac' ) for fn in tqdm(traint.recording_id.values))\nFT = np.stack(FT)\ngc.collect()\n\nFT.shape","372975da":"FF = Parallel(n_jobs=4)(delayed(extract_features)( '..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac' ) for fn in tqdm(trainf.recording_id.values))\nFF = np.stack(FF)\ngc.collect()\n\nFF.shape","84aaf38f":"#Combine True Positives and False Positives\n\nTRAIN = np.vstack( (FT, FF) )\nTRAIN.shape","c01ab518":"TEST = Parallel(n_jobs=4)(delayed(extract_features)(fn) for fn in tqdm(testfiles))\nTEST = np.stack(TEST)\ngc.collect()\n\nTEST.shape","31507544":"tt = traint[['recording_id','species_id']].copy()\ntf = trainf[['recording_id','species_id']].copy()\ntf['species_id'] = -1\n\nTRAIN_TAB = pd.concat( (tt, tf) )\n\nfor i in range(24):\n    TRAIN_TAB['s'+str(i)] = 0\n    TRAIN_TAB.loc[TRAIN_TAB.species_id==i,'s'+str(i)] = 1\n\nTRAIN_TAB.head()","432dfa9b":"TRAIN_TAB.head()","6ab4e61a":"np.save('TRAIN', TRAIN)\nnp.save('TEST', TEST)","f3dd902a":"TRAIN_TAB.to_csv('TRAIN_TAB.csv', index=False)","dea721d8":"This is a stand-alone notebook that generates FFT features. It is based on this Giba's notebook: https:\/\/www.kaggle.com\/titericz\/0-309-baseline-logisticregression-using-fft"}}