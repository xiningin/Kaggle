{"cell_type":{"843212ce":"code","14c4c645":"code","5fc61b01":"code","55660b29":"code","dceb0be4":"code","f58111b2":"code","50929b5f":"code","0d599e51":"code","1055c51a":"code","b7d9d26e":"code","f6e73858":"code","291e289a":"code","1b2c8140":"code","a952069a":"code","d9aff211":"code","5e1c2d53":"code","5e0a638d":"code","3be3447f":"code","23edbcff":"markdown","7c255ce0":"markdown","79baf605":"markdown","24c6caa0":"markdown","085dc1bc":"markdown","5936f332":"markdown","4abaac1f":"markdown","239ab45f":"markdown","449d1f68":"markdown"},"source":{"843212ce":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt\nimport PIL.Image as Image\nimport os\nimport tensorflow_addons as tfa","14c4c645":"!unzip \/kaggle\/input\/cassava-disease\/extraimages.zip -d  \/kaggle\/working\/ \n!unzip \/kaggle\/input\/cassava-disease\/test.zip -d \/kaggle\/working\/\n!unzip \/kaggle\/input\/cassava-disease\/train.zip -d \/kaggle\/working\/","5fc61b01":"!ls \/kaggle\/working\/train\/","55660b29":"!ls \/kaggle\/working\/test\/0\/ | wc -l","dceb0be4":"def display_image(image):\n    plt.imshow(image)\n    plt.show()","f58111b2":"def load_and_display_image(path):\n    image = tf.keras.preprocessing.image.load_img(path)\n    display_image(image)","50929b5f":"load_and_display_image('\/kaggle\/working\/train\/cbb\/train-cbb-351.jpg')","0d599e51":"!ls \/kaggle\/working\/train\/cbb\/ | wc -l\n!ls \/kaggle\/working\/train\/cbsd\/ | wc -l\n!ls \/kaggle\/working\/train\/cgm\/ | wc -l\n!ls \/kaggle\/working\/train\/cmd\/ | wc -l\n!ls \/kaggle\/working\/train\/healthy\/ | wc -l","1055c51a":"IMAGE_SHAPE = 96\nBATCH_SIZE = 70\nBUFFER_SIZE = 200\nPREFETCH = tf.data.experimental.AUTOTUNE","b7d9d26e":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=8,\n                                                                zoom_range=[0.9, 1.25],\n                                                                horizontal_flip=True,\n                                                                vertical_flip=True,\n                                                                rescale=1\/255,\n                                                                dtype='tf.float32',\n                                                                validation_split=0.2,\n                                                               )\n\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255,\n                                                               dtype='tf.float32',\n                                                                validation_split=0.2,\n                                                               )\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255,\n                                                              dtype='tf.float32'\n                                                              )\ntrain_datagen = train_datagen.flow_from_directory('\/kaggle\/working\/train\/',\n                                                 target_size=(IMAGE_SHAPE,IMAGE_SHAPE),\n                                                 batch_size=BATCH_SIZE,\n                                                 class_mode='categorical',\n                                                 shuffle=True,\n                                                 seed=42,\n                                                 subset='training')\n\nvalid_datagen = valid_datagen.flow_from_directory('\/kaggle\/working\/train\/',\n                                                 target_size=(IMAGE_SHAPE,IMAGE_SHAPE),\n                                                 batch_size=BATCH_SIZE,\n                                                 class_mode='categorical',\n                                                 shuffle=True,\n                                                 seed=42,\n                                                 subset='validation')\n\ntest_datagen = test_datagen.flow_from_directory('\/kaggle\/working\/',\n                                               target_size=(IMAGE_SHAPE,IMAGE_SHAPE),\n                                               batch_size=BATCH_SIZE,\n                                               classes=['test']\n                                               )","f6e73858":"train_datagen.next()[1].shape","291e289a":"base_model = tf.keras.applications.MobileNetV2(include_top=False,weights='imagenet',input_shape=(IMAGE_SHAPE,IMAGE_SHAPE,3))","1b2c8140":"base_model.trainable = False","a952069a":"reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7,patience=3, verbose=2, mode='auto',min_lr=1e-6)\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=6, verbose=2, mode='auto',baseline=None, restore_best_weights=True)","d9aff211":"try:\n    with tf.device('\/device:GPU:0'):\n        inputs = tf.keras.layers.Input(shape=(IMAGE_SHAPE,IMAGE_SHAPE,3))\n        x = base_model(inputs)\n        x = keras.layers.GaussianNoise(0.2)(x)\n        x = keras.layers.GlobalAveragePooling2D()(x)\n        outputs = tf.keras.layers.Dense(5,activation=\"softmax\")(x)\n\n        model = tf.keras.Model(inputs=[inputs],outputs=[outputs])\n\n        model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n                      loss=tf.keras.losses.CategoricalCrossentropy(),\n                      #loss=tfa.losses.SigmoidFocalCrossEntropy(),\n                      metrics=['accuracy'])\n\n        model.fit(train_datagen,epochs=30,validation_data=valid_datagen,callbacks = [reduce_lr,early_stop])\nexcept RuntimeError as e:\n    print(e)    ","5e1c2d53":"tf.config.experimental.list_physical_devices()","5e0a638d":"strategy = tf.distribute.experimental_set_strategy('')","3be3447f":"strategy.num_replicas_in_sync","23edbcff":"## Checking the Distributions for Training Images","7c255ce0":"# See what we have","79baf605":"## Using this place as Helper Functions","24c6caa0":"## Download Pretrained Model","085dc1bc":"## Some Fixed Variables","5936f332":"## Creating Data Augmentations and flow from directory","4abaac1f":"try:\n    with tf.device('\/device:GPU:0'):\n        inputs = tf.keras.layers.Input(shape=(IMAGE_SHAPE,IMAGE_SHAPE,3))\n        x = base_model(inputs)\n        x = tf.keras.layers.Flatten()(x)\n        x = tf.keras.layers.Dense(512,activation='relu')(x)\n        outputs = tf.keras.layers.Dense(5,activation=\"softmax\")(x)\n\n        model = tf.keras.Model(inputs=[inputs],outputs=[outputs])\n\n        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n                      #loss=tf.keras.losses.CategoricalCrossentropy(),\n                      loss=tfa.losses.SigmoidFocalCrossEntropy(),\n                      metrics=[tf.keras.metrics.Accuracy()])\n\n        model.fit(train_datagen,epochs=10,validation_data=valid_datagen,callbacks = [reduce_lr,early_stop])\nexcept RuntimeError as e:\n    print(e)    ","239ab45f":"# Imports Here","449d1f68":"# Unzip and Sort out the data"}}