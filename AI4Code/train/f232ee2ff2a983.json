{"cell_type":{"476e8b5d":"code","b8db5725":"code","4061f179":"code","7dd13a57":"code","b8aae58f":"code","a93c9404":"code","0dbef13e":"code","8811fe18":"code","3ad6a465":"code","9e3111cb":"code","0d1170f8":"code","c61c1221":"code","c6df9d67":"code","5ae0e959":"code","984f1f87":"code","50a912f2":"code","bffa74f7":"code","9b7ab326":"code","1694fb24":"code","88c93cf5":"code","09a761d3":"code","b5c5140d":"markdown","68c3b3f0":"markdown","76204213":"markdown","727f002b":"markdown","0e4b7217":"markdown","1b13c4c5":"markdown","14ada652":"markdown","b2bc6d61":"markdown"},"source":{"476e8b5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b8db5725":"df=pd.read_csv(\"\/kaggle\/input\/mobile-price-classification\/train.csv\")\ndf.head()","4061f179":"y=df['price_range']\nX=df.drop(labels=\"price_range\",axis=1)\nX.head()","7dd13a57":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","b8aae58f":"#select best features\nbest_features=SelectKBest(score_func=chi2,k=10)\nfit=best_features.fit(X,y)\ndf_scores=pd.DataFrame(fit.scores_)\ndf_specs=pd.DataFrame(X.columns)\n\ndf_combined=pd.concat([df_scores,df_specs],axis=1)\ndf_combined.columns=['Score','Spec']\nprint(df_combined.nlargest(10,'Score'))","a93c9404":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n#correlation matrix\ncorr_mat=df.corr()\ntop_corr_features=corr_mat.index\nplt.figure(figsize=(20,20))\nsns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","0dbef13e":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n","8811fe18":"best_feat=df_combined.nlargest(10,'Score')\nfeat_names=best_feat['Spec']\nfeat_names=feat_names.to_numpy()","3ad6a465":"feat_names=feat_names.tolist()\nX=df[feat_names]\nX.head()","9e3111cb":"from sklearn.preprocessing  import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nC=[0.01,0.03,0.1,0.3,1,3,10,30,100,300,1000]\ngamma=[0.01,0.03,0.1,0.3,1,3,10,30,100]\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.2)\n#feature normalization\nscaler=StandardScaler()\ncols=X.columns\nX_train=pd.DataFrame(scaler.fit_transform(X_train),columns=cols)\nX_train.head()","0d1170f8":"X_train.describe().apply(lambda s:s.apply('{0:.5f}'.format))\n","c61c1221":"# params={'C':C,'gamma':gamma,'kernel':['poly','rbf']}\n# grid_s=GridSearchCV(SVC(),params,refit=True,verbose=3)\n# grid_s.fit(X_train,y_train)","c6df9d67":"# print(grid_s.best_estimator_)\n# print(grid_s.best_params_)","5ae0e959":"model=SVC(C=3,gamma=0.01,kernel='rbf')\nmodel.fit(X_train,y_train)","984f1f87":"from sklearn.metrics import confusion_matrix,classification_report,roc_curve,roc_auc_score,auc,accuracy_score","50a912f2":"cols=X_test.columns\nscaler=StandardScaler()\nX_test=pd.DataFrame(scaler.fit_transform(X_test),columns=cols)\nX_test.head()","bffa74f7":"predictions=model.predict(X_test)","9b7ab326":"def score(y_test,predictions):\n    print(classification_report(y_test,predictions))\n    print(pd.DataFrame(predictions).value_counts())\n    print(\"Accuracy score ={score}\".format(score=accuracy_score(y_test,predictions)))\n\ndef plot_matrix(y_test,predictions):\n    matrix=confusion_matrix(y_test,predictions)\n    matrix=matrix.transpose()\n    cm_df=pd.DataFrame(matrix,index=[\"0\",\"1\",\"2\",\"3\"],columns=[\"0\",\"1\",\"2\",\"3\"])\n    sns.heatmap(cm_df,annot_kws={\"size\":16},annot=True,fmt=\"d\")\n    \ndef plot_roc(y_test,predictions):\n    actual_vals=pd.DataFrame(pd.get_dummies(y_test))\n    predictions=pd.DataFrame(pd.get_dummies(predictions))\n    print('0: {}'.format(predictions[predictions[0]==1][0].sum()))\n    print('1 :{}'.format(predictions[predictions[1]==1][1].sum()))\n    print('2 :{}'.format(predictions[predictions[2]==1][2].sum()))\n    predictions.head()\n    #compute roc curve and roc area for each curve\n    fpr=dict()\n    tpr=dict()\n    roc_auc=dict()\n    n_classes=4\n\n    #loop for each class\n    for i in range(n_classes):\n        fpr[i],tpr[i],_=roc_curve(actual_vals.iloc[:,i],predictions.iloc[:,i])\n        roc_auc[i]=auc(fpr[i],tpr[i])\n    #micro-average roc curve\n    fpr[\"micro\"],tpr[\"micro\"],_=roc_curve(actual_vals.to_numpy().ravel(),predictions.to_numpy().ravel())\n    roc_auc[\"micro\"]=auc(fpr[\"micro\"],tpr[\"micro\"])\n    \n    colors = ['aqua', 'darkorange', 'cornflowerblue','darkred']\n    #main plotter\n    lw=2\n    plt.figure(figsize=(10,8))\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='micro-average ROC curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"micro\"]),\n             color='deeppink', linestyle=':', linewidth=4)\n    labels=['0','1','2','3']\n    for i,color in zip(range(n_classes),colors):\n         plt.plot(fpr[i], tpr[i], color=color,lw=lw,label='ROC curve of class {0} {name} (area = {area:0.2f})'\n                 ''.format(i, name=labels[i],area=roc_auc[i]))\n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    ","1694fb24":"score(y_test,predictions)","88c93cf5":"plot_matrix(y_test,predictions)","09a761d3":"plot_roc(y_test,predictions)","b5c5140d":"<h2>Make Predictions<\/h2>","68c3b3f0":"<h2>Confusion Matrix<\/h2>","76204213":"<h2>Now, we will train a support vector classifier<\/h2>","727f002b":"<h2>Accuracy Score<\/h2>","0e4b7217":"<h2>Make a heatmap<\/h2>","1b13c4c5":"<h2>Feature Analysis<\/h2>","14ada652":"<h2>Hyperparameter tuning<\/h2>","b2bc6d61":"<h2>ROC Curve<\/h2>"}}