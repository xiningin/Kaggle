{"cell_type":{"4e61938b":"code","4d7b5a11":"code","54e72390":"code","0d04353e":"code","0f750b81":"code","d558c6c7":"code","036427dd":"code","154a0d5b":"code","173c86bf":"code","3a915c8a":"code","2f331315":"code","15fe2de0":"code","9fe13356":"code","c9d9f70d":"code","1c38917e":"code","a6b4f96e":"code","6ebf7dd4":"code","2ebbc294":"code","6dff57ee":"code","fcde30bd":"code","575b732d":"code","be3d5613":"code","bd7ec3c5":"code","22445bfd":"code","23ca80e2":"code","4aa4ead4":"code","14837e10":"code","c6a44729":"code","84e28641":"code","b3d8a568":"code","7d6bbbec":"code","bf935752":"code","1ab7f971":"code","7cc1e708":"code","97f3782a":"code","a12a48de":"code","7e55be8d":"code","6f0b3676":"code","699021f4":"code","6be481c3":"code","fe7e1684":"code","61139f77":"code","5eccd93d":"code","8a1e8d03":"code","d463443e":"code","795b4df6":"code","5573db0d":"code","134921a8":"code","d247f49c":"code","4b2e2517":"code","7d36727e":"code","cd0814ed":"markdown","ca3369f1":"markdown","416a3e55":"markdown","d980a844":"markdown","3c44ada5":"markdown","847bc48e":"markdown","ec3828e4":"markdown","af741eb7":"markdown","9064c4db":"markdown","2dbea15c":"markdown","1658c686":"markdown","2d5353e9":"markdown","fe3d3069":"markdown","3b4325b3":"markdown","0058560d":"markdown","b689b6ef":"markdown","9caaf860":"markdown","cd83755f":"markdown","b5ab19da":"markdown","629c26bd":"markdown","46129e40":"markdown","a0749098":"markdown"},"source":{"4e61938b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas import Series, DataFrame\nimport matplotlib.pyplot as plt  # for plots\n%matplotlib inline\nimport seaborn as sns # For advance plots and graphs\n\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# to view all columns\nfrom IPython.display import display\npd.options.display.max_columns = None\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4d7b5a11":"# Read data\ntrain = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n# combine train and test data set\ndata = pd.concat([train, test],ignore_index=True, sort=False)","54e72390":"print('the shape of  train dataset', train.shape)\nprint('the shape of  test dataset', test.shape)\nprint('the shape of data', data.shape)","0d04353e":"train.head()","0f750b81":"train.tail()","d558c6c7":"data.info()","036427dd":"data.describe().T","154a0d5b":"train.drop(['Id'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)","173c86bf":"sns.distplot(train['SalePrice'])\nplt.show()","3a915c8a":"print(\"Skewness in SalePrice :\", train['SalePrice'].skew())\nprint(\"Kurtosis in SalePrice :\", train['SalePrice'].kurt())","2f331315":"sns.boxplot(train['SalePrice'])\nplt.show()","15fe2de0":"train['SalePrice'] = np.log(train[\"SalePrice\"]+1)\n#check distribution after log transform.\nsns.distplot(train['SalePrice'])\nplt.show()","9fe13356":"#check correlation in features\ncor = train.corr()\nplt.figure(figsize=(15,10))\nsns.heatmap(cor,cmap=\"Blues\", vmax=0.9)\nplt.show()","c9d9f70d":"# checking high correlatinal features to 'SalePrice'\ncor[abs(cor['SalePrice'].values) >= 0.5]['SalePrice'].sort_values(ascending=False)[1:]","1c38917e":"# OverllQual is catagorical feature so draw boxplot\nfig = plt.figure(constrained_layout=True, figsize=(8,5))\nsns.boxplot(train['OverallQual'], train['SalePrice'])\nplt.show()","a6b4f96e":"fig = plt.figure(constrained_layout=True, figsize=(8,5))\nsns.scatterplot(train['GrLivArea'], train['SalePrice'])\nplt.show()","6ebf7dd4":"#Deleting outliers\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<12.5)].index)\n\ntrain.reset_index(drop = True, inplace = True)","2ebbc294":"# sctter plot after removing outliers.\nfig = plt.figure(constrained_layout=True, figsize=(8,5))\nsns.scatterplot(train['GrLivArea'], train['SalePrice'])\nplt.show()","6dff57ee":"fig = plt.figure(constrained_layout=True, figsize=(8,5))\nsns.boxplot(train['GarageCars'], train['SalePrice'])\nplt.show()","fcde30bd":"sns.scatterplot(train['GarageArea'], train['SalePrice'])\nplt.show()","575b732d":"sns.scatterplot(train['TotalBsmtSF'], train['SalePrice'])\nplt.show()","be3d5613":"fig = plt.figure(constrained_layout=True, figsize=(8,5))\nsns.boxplot(train['FullBath'], train['SalePrice'])\nplt.show()","bd7ec3c5":"## Plot fig sizing. \nimport matplotlib.style as style\nstyle.use('ggplot')\nsns.set_style('whitegrid')\nplt.subplots(figsize = (30,20))\n## Plotting heatmap. \n\n# Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(train.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nsns.heatmap(train.corr(), cmap=sns.diverging_palette(20, 220, n=200), mask = mask, annot=True, center = 0, );\n## Give title. \nplt.title(\"Heatmap of all the Features\", fontsize = 30);","22445bfd":"# again concat train and test cause we have done changes in train dataset. \ndata = pd.concat((train, test)).reset_index(drop=True)","23ca80e2":"columns = data.columns\n\nfor col in columns:\n    print(data[col].value_counts())\n    print('\\n')","4aa4ead4":"missing_tot = data.isnull().sum().sort_values(ascending = False)\nmissing_per = ((data.isnull().sum()\/data.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([missing_tot, missing_per] , axis=1, keys=['Total', 'Percent'])","14837e10":"missing_data.head(40)","c6a44729":"data_cat = data.select_dtypes('object')\ndata_int =  data.select_dtypes(['int64','float64'])","84e28641":"data_cat.columns","b3d8a568":"data_cat.isnull().sum().sort_values(ascending =False)","7d6bbbec":"d = data_cat.isnull().sum().sort_values(ascending =False)\nd.index","bf935752":"# fill null values by none cause this null represpents they are not avaliable on site so fill by 'None'\ncolumns1 = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageCond',\n       'GarageQual', 'GarageFinish', 'GarageType', 'BsmtCond', 'BsmtExposure',\n       'BsmtQual', 'BsmtFinType2', 'BsmtFinType1', 'MasVnrType']\n\n# fill by mode\ncolumns2 = ['MSZoning','Functional', 'Utilities', 'Electrical', 'KitchenQual', 'SaleType',\n       'Exterior2nd', 'Exterior1st']","1ab7f971":"for col in columns1:\n    data_cat[col].fillna('None',inplace =True)","7cc1e708":"for col  in columns2:\n    data_cat[col].fillna(data[col].mode()[0],inplace = True)","97f3782a":"d2 = data_int.isnull().sum().sort_values(ascending=False)\nd2.index","a12a48de":"columns3 = ['LotFrontage', 'GarageYrBlt', 'MasVnrArea', 'BsmtFullBath',\n       'BsmtHalfBath', 'TotalBsmtSF', 'BsmtUnfSF', 'GarageArea', 'GarageCars',\n       'BsmtFinSF2', 'BsmtFinSF1']","7e55be8d":"for col in columns3:\n    data_int[col].fillna(0,inplace=True)","6f0b3676":"df = pd.concat([data_cat,data_int],axis=1)","699021f4":"# Since these column are actually a category , using a numerical number will lead the model to assume\n# that it is numerical , so we convert to string .\ndf['MSSubClass'] = df['MSSubClass'].apply(str)\ndf['YrSold'] = df['YrSold'].astype(str)\ndf['MoSold'] = df['MoSold'].astype(str)\ndf.drop('SalePrice', axis=1, inplace = True)","6be481c3":"missing_tot = df.isnull().sum().sort_values(ascending = False)\nmissing_per = ((df.isnull().sum()\/df.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([missing_tot, missing_per] , axis=1, keys=['Total', 'Percent'])\nmissing_data.head()","fe7e1684":"numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n\nskewed_feats = df[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\nskewed_feats","61139f77":"from scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nhigh_skew = skewed_feats[skewed_feats > 0.5]\nskew_index = high_skew.index\n\n# Normalise skewed features\nfor i in skew_index:\n    df[i] = boxcox1p(df[i], boxcox_normmax(df[i] + 1))\n    ","5eccd93d":"final_features = pd.get_dummies(df).reset_index(drop=True)\nprint('Features size:', df.shape)\nfinal_features.head()","8a1e8d03":"final_features.shape","d463443e":"nrow_train = train.shape[0]\n\nX_train = final_features[:nrow_train]\nX_test = final_features[nrow_train:]\nY = train['SalePrice']","795b4df6":"from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\n\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n\nkfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n\n# Kernel Ridge Regression : made robust to outliers\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n\n# LASSO Regression : made robust to outliers\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, \n                    alphas=alphas2,random_state=42, cv=kfolds))\n\n# Elastic Net Regression : made robust to outliers\nelasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, \n                         alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\n\n","5573db0d":"#Fit the training data X_train,Y \nprint('Elasticnet')\nelastic_model = elasticnet.fit(X_train, Y)\nprint('Lasso')\nlasso_model = lasso.fit(X_train, Y)\nprint('Ridge')\nridge_model = ridge.fit(X_train, Y)","134921a8":"# model blending function using fitted models to make predictions\ndef blend_models(X):\n    return ((elastic_model.predict(X)) + (lasso_model.predict(X)) + (ridge_model.predict(X)))\/3\n","d247f49c":"submission = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsubmission.iloc[:,1] = np.expm1(blend_models(X_test))","4b2e2517":"# Fix outleir predictions\nq1 = submission['SalePrice'].quantile(0.0045)\nq2 = submission['SalePrice'].quantile(0.99)\nsubmission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\nsubmission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\nsubmission.to_csv(\"submission_regression1.csv\", index=False)","7d36727e":"submission","cd0814ed":"- So this features have good correlation with target variable\n- so check this their now realtion","ca3369f1":"**This competition is all about predict house price based on 79 columns.**\n\nThis notebook is just simple approach to solve this dataset.\n\nAnd there is brief explnation about filling null values.","416a3e55":"- Looking at Skewed Features","d980a844":"- Box Cox Transformation on Skewed Features","3c44ada5":"- Check values in each column","847bc48e":" **Now we are done with most of the Feature Analysis, Let's Beging with the Feature Engineering!**","ec3828e4":"- Check now is there ant missing value remain","af741eb7":"- **Now start EDA..**\n\n- First check target column.. target column is 'Sale price'\n","9064c4db":"- Form above plots we can see 'GrLivArea' and 'SalePrice' have good relation.\n- There are few outliers.\n- For now we will keep outliers, we will figure out it later.","2dbea15c":"- 'Id' has no relation with sale price.  \n- So drop 'Id' column ","1658c686":"- Encoding the finalized features","2d5353e9":"- Now move on toward the predictors.","fe3d3069":"- Split data into two parts for training and testing","3b4325b3":"- Now separate the catgorical freatues and numerical features ","0058560d":"- Target column is right skwed. So log transformation is requried.","b689b6ef":"- Now check missing values.","9caaf860":"This above thing I have done by taking refrence to other kernals.","cd83755f":"- To decide about null values I have done old type analysis by using paper and pen\n- For example, Like in 'PoolQc' column 2908 null values, but in as per data description\n  PoolQC: Pool quality\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       NA\tNo Pool\n- Means null values are reprsenting No pool so fill them by 'None'\n- One more example, if 'GarageType' is null and as per data description\n\n       2Types\tMore than one type of garage\n       Attchd\tAttached to home\n       Basment\tBasement Garage\n       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n       CarPort\tCar Port\n       Detchd\tDetached from home\n       NA\tNo Garage\n- Means null values neans no Garage so  fill them by 'None'\n- And the features related to Garage like 'GarageYrBlt', 'GarageFinish', 'GarageCars','GarageArea','GarageQual','GarageCond' will follow same lead.\n- Like in ('GarageCars':  Size of garage in car capacity) if there is now Garage means 'GarageCars' null represnts '0'.\n- As we can see 'GarageCars' column in above  value count code. \n      2.0    1593\n      1.0     776\n      3.0     373\n      0.0     157\n      4.0      16\n      5.0       1\n \n- Use data desciption for fill null values\n","b5ab19da":"- We can see there is multicollinearity between some features.\n- This can figure it later.","629c26bd":"- Import models","46129e40":"**This is my first approach with taking help some kernals.**\n\n**For more accurate results we can use multiple alogrithums.**\n\n**We can also do some feature engineering.**\n\n**If you like anything in this kernal then please don't forget to upvote.**","a0749098":"As we can see this two points may be outliers cause as GrLivArea is increase price also increase.\n\nBut this two points behave abnormal."}}