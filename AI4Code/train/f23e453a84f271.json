{"cell_type":{"03a543fa":"code","f6448fc5":"code","b1ee1b19":"code","0f3594a5":"code","6db61e3e":"code","7e653525":"code","cdd5bf8a":"code","41300996":"code","ac312046":"code","18840733":"code","10112561":"code","8e518487":"code","b73b0001":"code","09771d73":"code","4b2cb36c":"code","246008f7":"code","8e1cdce8":"code","3bab7931":"code","04926c64":"code","2b4623e4":"code","d476ac8d":"code","b76687d0":"code","a544ba19":"code","c020b598":"code","4d0c809d":"code","30dbc1cc":"code","451ffcef":"code","6e24da68":"code","bbaaeceb":"code","9f5567b6":"code","d62b72c5":"code","98c77a58":"code","c696e36e":"code","95f16b9c":"code","d0cffc2f":"code","4b7a6de6":"code","c9a2b576":"code","190653cc":"code","738a3bc4":"code","22085105":"code","2c06df70":"code","5c12e721":"code","087596ae":"code","805b064e":"code","c1c2e6a4":"code","244819fd":"code","05e7e954":"code","7bbdd49f":"code","e1e3cf19":"code","86579141":"code","690d1dfb":"code","b519ef64":"code","3ddcef4f":"code","0d049481":"code","35f4d824":"code","2436f298":"code","af3881f8":"code","c23e4aa5":"code","5a564f56":"code","d0ff31c4":"code","3731aea2":"code","c3c35ef8":"code","8b7d6a71":"code","115ab7b4":"code","e19bc5ce":"markdown","857a6c41":"markdown","f8f3ca24":"markdown","a39b512f":"markdown","dada3cfd":"markdown","5b6d849a":"markdown","e77109bc":"markdown","33dbdc07":"markdown","69a2445a":"markdown","274fe213":"markdown","ca7de7c5":"markdown","1bbddc3a":"markdown","1d0684c5":"markdown","9f366ed8":"markdown","834f9d76":"markdown","ecf0770a":"markdown","73fd152d":"markdown","f1f40c51":"markdown","38f19375":"markdown","6e04bf0d":"markdown","1d10ccaf":"markdown","26d634f9":"markdown","75a5b04d":"markdown","1a4568e0":"markdown","705d6f09":"markdown","c064bddf":"markdown","979c156e":"markdown","aa8da803":"markdown","10be6d80":"markdown","f27cb902":"markdown","f7e507f0":"markdown","fb9bf725":"markdown","f9d72c03":"markdown","1afa3bda":"markdown","90f9e490":"markdown","fdc99940":"markdown","840cc990":"markdown","ff44516e":"markdown","7606a5ed":"markdown","589c8fe8":"markdown","41e39100":"markdown","710a99fb":"markdown","c897b59b":"markdown","d2a7e4ea":"markdown","cc006c56":"markdown","9f68d541":"markdown","a394b6b6":"markdown","e560d5d2":"markdown","609a872d":"markdown","5d3a471d":"markdown","23f8ed1a":"markdown","d7423793":"markdown","c0450d25":"markdown","7c7cf471":"markdown","72f47e92":"markdown","2cb4a47b":"markdown"},"source":{"03a543fa":"!pip install -q pyicu\n!pip install -q pycld2\n!pip install -q polyglot\n!pip install -q textstat\n!pip install -q googletrans","f6448fc5":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as plty\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\nfrom colorama import Fore, Back, Style, init\n\nimport spacy\nfrom wordcloud import WordCloud\n\nfrom polyglot.detect import Detector\nimport pycountry\n\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nfrom googletrans import Translator\nimport textstat\n\nimport re\n\nfrom tqdm import tqdm, tqdm_notebook\ntqdm_notebook().pandas()\n\nfrom kaggle_datasets import KaggleDatasets\nimport transformers\nimport tensorflow as tf\nfrom tokenizers import BertWordPieceTokenizer\n\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Embedding\nfrom tensorflow.keras.layers import LSTM, GRU, Conv1D, SpatialDropout1D\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import activations\nfrom tensorflow.keras import constraints\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras import regularizers\n\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.constraints import *\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.regularizers import *\n\n# to set a style to all graphs\nplt.style.use('fivethirtyeight')\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\")","b1ee1b19":"INPUT_DIR = '..\/input\/jigsaw-multilingual-toxic-comment-classification\/'\n\nTRAIN_PATH = INPUT_DIR + 'jigsaw-toxic-comment-train.csv'\nTEST_PATH = INPUT_DIR + 'test.csv'\nVAL_PATH = INPUT_DIR + 'validation.csv'\n\ntrain_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\nval_df = pd.read_csv(VAL_PATH)\n\ndisplay('TRAINING DATA')\ndisplay(train_df.head(5))\n\ndisplay('TEST DATA')\ndisplay(test_df.head(5))\n\ndisplay('VALIDATION DATA')\ndisplay(val_df.head(5))","0f3594a5":"nlp = spacy.load('en_core_web_sm')\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\n\n'''\ndef preprocess_text(text):\n    doc = nlp(text, disable=['ner','parser'])\n    lemmas = [token.lemma_ for token in doc]\n    a_lemmas = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stop_words]\n    return ' '.join(a_lemmas)\n\ntrain_comments = train_df['comment_text'].progress_apply(preprocess_text)\n'''\n#Create an o\/p file for reading directly if session expires or new session\n#train_comments.to_csv('comments.csv')","6db61e3e":"train_comments = pd.read_csv('..\/input\/comments\/comments.csv')\ntrain_comments.drop(train_comments.columns[0], axis=1, inplace=True)","7e653525":"string = ' '.join(train_comments['comment_text'].dropna())\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(string.lower())\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Common words in comments')","cdd5bf8a":"# This will return language code, eg: 'en' for English\ndef detect_language(text):\n    return Detector(\"\".join(x for x in text if x.isprintable()), quiet=True).languages[0].name\n\n\n#This function will Fetch Full Language Name by passing Language code\ndef get_full_name(lang_code):\n    try:\n        Name = pycountry.languages.get(alpha_2=lang_code).name\n    except:\n        Name = None\n    return Name\n\n\ntrain_df['lang_code'] = train_df['comment_text'].progress_apply(detect_language)\ntrain_df['lang'] = train_df['lang_code'].progress_apply(get_full_name)","41300996":"def get_country(language):\n    if language == \"German\":\n        return \"Germany\"\n    if language == \"Scots\":\n        return \"Scotland\"\n    if language == \"Danish\":\n        return \"Denmark\"\n    if language == \"Arabic\":\n        return \"Saudi Arabia\"\n    if language == \"Spanish\":\n        return \"Spain\"\n    if language == \"Persian\":\n        return \"Iran\"\n    if language == \"Greek\":\n        return \"Greece\"\n    if language == \"Portuguese\":\n        return \"Portugal\"\n    if language == \"English\":\n        return \"United Kingdom\"\n    if language == \"Hindi\":\n        return \"India\"\n    if language == \"Albanian\":\n        return \"Albania\"\n    if language == \"Bosnian\":\n        return \"Bosnia and Herzegovina\"\n    if language == \"Croatian\":\n        return \"Croatia\"\n    if language == \"Dutch\":\n        return \"Netherlands\"\n    if language == \"Russian\":\n        return \"Russia\"\n    if language == \"Vietnamese\":\n        return \"Vietnam\"\n    if language == \"Somali\":\n        return \"Somalia\"\n    if language == \"Turkish\":\n        return \"Turkey\"\n    if language == \"Serbian\":\n        return \"Serbia\"\n    if language == \"Indonesian\":\n        return \"Indonesia\"\n    if language == \"Manx\":\n        return \"Ireland\"\n    if language == \"Scots\":\n        return \"Scotland\"\n    if language == \"Latin\":\n        return \"Holy See (Vatican City State)\"\n    if language == \"Afrikaans\":\n        return \"South Africa\"\n    return \"None\"","ac312046":"train_df['lang'].value_counts()[:10]","18840733":"total_comments = train_df['lang_code'].count()\nenglish_comments = train_df['lang_code'].value_counts().loc['en']\nlanguages = ['English','Non-English']\ncount = [english_comments, total_comments-english_comments]\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\nfig.add_trace(go.Bar(x=languages,y=count,text=count, marker_color=['#64D9D1','#D9636B']),\n             row=1, col=1)\nfig.add_trace(go.Pie(labels=languages, values=count, domain=dict(x=[0.5, 1.0]), marker_colors=['#64D9D1','#D9636B']), \n              row=1, col=2)\n\nfig.update_layout(height=600, width=800, title_text=\"English vs Non-English\", template='plotly_white')\n\nfig.show()","10112561":"df = train_df['lang'].value_counts()[1:6].reset_index()\ndf.columns = ['Language','Count']\n\nfig = px.bar(df,\n             y=\"Language\", x=\"Count\", title=\"Non-English comments\", template=\"plotly_white\", \n             color=\"Language\", text=\"Count\", orientation=\"h\")\nfig.update_traces(marker=dict(line=dict(width=0.75,\n                                        color='black')),  textposition=\"outside\")\nfig.update_layout(showlegend=False)\nfig","8e518487":"df = train_df['lang'].value_counts().reset_index()\ndf.columns = ['Language','Count']\ndf[\"country\"] = df[\"Language\"].progress_apply(get_country)\n \n\nfig = px.choropleth(df.query(\"Language != 'English' and Language != 'un' and country != 'None'\").query(\"Count >= 5\"), locations=\"country\", hover_name=\"country\",\n                     projection=\"natural earth\", locationmode=\"country names\", title=\"Countries of non-English languages\", color=\"Count\",\n                     template=\"plotly\", color_continuous_scale=\"agsunset\")\n# fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n# fig.data[0].marker.line.width = 0.2\nfig.show()","b73b0001":"fig = px.choropleth(df.query(\"Language != 'English' and Language != 'un' and country != 'None'\"), locations=\"country\", hover_name=\"country\",\n                     projection=\"natural earth\", locationmode=\"country names\", title=\"Non-English European countries\", color=\"Count\",\n                     template=\"plotly\", color_continuous_scale=\"aggrnyl\", scope=\"europe\")\n# fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n# fig.data[0].marker.line.width = 0.2\nfig.show()","09771d73":"fig = px.choropleth(df.query(\"Language != 'English' and Language != 'un' and country != 'None'\"), locations=\"country\", hover_name=\"country\",\n                     projection=\"natural earth\", locationmode=\"country names\", title=\"Asian countries\", color=\"Count\",\n                     template=\"plotly\", color_continuous_scale=\"spectral\", scope=\"asia\")\n# fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n# fig.data[0].marker.line.width = 0.2\nfig.show()","4b2cb36c":"fig = px.choropleth(df.query(\"Language != 'English' and Language != 'un' and country != 'None'\").query(\"Count >= 5\"), locations=\"country\", hover_name=\"country\",\n                     projection=\"natural earth\", locationmode=\"country names\", title=\"African countries\", color=\"Count\",\n                     template=\"plotly\", color_continuous_scale=\"agsunset\", scope=\"africa\")\n# fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n# fig.data[0].marker.line.width = 0.2\nfig.show()","246008f7":"# Counting no of words in each comment\ntrain_df['word_count'] = train_df['comment_text'].progress_apply(lambda x : len([word for word in x.split() if type(word) is str]))","8e1cdce8":"train_df.sort_values(by='word_count', ascending=False)[['comment_text','word_count']].head(3)","3bab7931":"fig = plt.figure(figsize=(20,10))\nplt.suptitle('Distribuition of Word count', fontsize=30)\n\nax1 = fig.add_subplot(121)\n_ = sns.distplot(train_df['word_count'], bins=200,color='#e56b6f', ax=ax1)\n_ = ax1.set_ylabel('Distribution', fontsize=20)\n_ = ax1.set_xlabel('Word count', fontsize=20)\n\n\nax2 = fig.add_subplot(122)\n_ = plt.scatter(range(train_df.shape[0]), np.sort(train_df['word_count'].values), color='#2a9d8f')\n_ = ax2.set_ylabel('Word count', fontsize=20)\n_ = ax2.set_xlabel('Comments', fontsize=20)","04926c64":"top_15 = train_df.groupby('lang')['word_count'].mean().rename('Mean').reset_index().\\\n                                    sort_values(by='Mean', ascending=False)[:15]\nbottom_15 = train_df.groupby('lang')['word_count'].mean().rename('Mean').reset_index().\\\n                                    sort_values(by='Mean')[:15]","2b4623e4":"fig = make_subplots(rows=2, cols=1,subplot_titles=['Top 15', 'Bottom 15'])\n\nfig.add_trace(go.Bar(x=top_15['lang'], y=top_15['Mean']), row=1, col=1)\n\nfig.add_trace(go.Bar(x=bottom_15['lang'], y=bottom_15['Mean']), row=2, col=1)\n\nfig.update_layout(height=900, width=800,yaxis_title=\"Average comment words\", title_text=\"Average comment words vs. language\", template=\"plotly_white\")\nfig.show()","d476ac8d":"translator = Translator()\n\ndef translate_text(comment_lang):\n    comment, lang = comment_lang[0], comment_lang[1]\n    try:\n        if (lang == 'English' or lang == None):\n            return comment\n        else:\n            return translator.translate(comment).text\n    except:\n        return None\n\ntrain_df['translated_comment'] = train_df[['comment_text','lang']].progress_apply(lambda x: translate_text(x), axis=1)","b76687d0":"def polarity(text):\n    if type(text) == str:\n        return SIA.polarity_scores(text)\n    else:\n        return 1000\n    \nSIA = SentimentIntensityAnalyzer()\ntrain_df[\"polarity\"] = train_df[\"translated_comment\"].progress_apply(polarity)","a544ba19":"neg_pol = [pols['neg'] for pols in train_df[\"polarity\"] if type(pols) is dict]\nneg_pol = list(filter((0.0).__ne__, neg_pol))\n\nfig = go.Figure(go.Histogram(x=neg_pol, marker=dict(\n            color='seagreen')\n    ))\n\nfig.update_layout(xaxis_title=\"Negativity sentiment\", title_text=\"Negativity sentiment\", template=\"simple_white\")\nfig.show()","c020b598":"toxic = [x['neg'] for x in train_df.sample(frac=0.1).query(\"toxic == 1\")['polarity'] if type(x) == dict]\nnon_toxic = [x['neg'] for x in train_df.sample(frac=0.1).query(\"toxic == 0\")['polarity'] if type(x) == dict]\n\nfig = ff.create_distplot(hist_data=[toxic, non_toxic],\n                         group_labels=[\"Toxic\", \"Non-toxic\"],\n                         colors=[\"darkorange\", \"dodgerblue\"], show_hist=False)\n\nfig.update_layout(title_text=\"Negativity of Toxic vs Non-toxic\", xaxis_title=\"Negativity\", template=\"simple_white\")\nfig.show()","4d0c809d":"pos_pol = [pols['pos'] for pols in train_df[\"polarity\"] if type(pols) is dict]\npos_pol = list(filter((0.0).__ne__, pos_pol))\n\nfig = go.Figure(go.Histogram(x=pos_pol, marker=dict(\n            color='seagreen')\n    ))\n\nfig.update_layout(xaxis_title=\"Positive sentiment\", title_text=\"Positive sentiment\", template=\"simple_white\")\nfig.show()","30dbc1cc":"neu_pol = [pols['neu'] for pols in train_df[\"polarity\"] if type(pols) is dict]\nneu_pol = list(filter((1.0).__ne__, neu_pol))\n\nfig = go.Figure(go.Histogram(x=neu_pol, marker=dict(\n            color='seagreen')\n    ))\n\nfig.update_layout(xaxis_title=\"Neutral sentiment\", title_text=\"Neutral sentiment\", template=\"simple_white\")\nfig.show()","451ffcef":"neu_pol = [pols['compound'] for pols in train_df[\"polarity\"] if type(pols) is dict]\nneu_pol = list(filter((0.0).__ne__, neu_pol))\n\nfig = go.Figure(go.Histogram(x=neu_pol, marker=dict(\n            color='seagreen')\n    ))\n\nfig.update_layout(xaxis_title=\"Compound sentiment\", title_text=\"Compund sentiment\", template=\"simple_white\")\nfig.show()","6e24da68":"toxic = [x['compound'] for x in train_df.sample(frac=0.1).query(\"toxic == 1\")['polarity'] if type(x) == dict]\nnon_toxic = [x['compound'] for x in train_df.sample(frac=0.1).query(\"toxic == 0\")['polarity'] if type(x) == dict]\n\nfig = ff.create_distplot(hist_data=[toxic, non_toxic],\n                         group_labels=[\"Toxic\", \"Non-toxic\"],\n                         colors=[\"darkorange\", \"dodgerblue\"], show_hist=False)\n\nfig.update_layout(title_text=\"Compoundedness of Toxic vs Non-toxic\", xaxis_title=\"Compound\", template=\"simple_white\")\nfig.show()","bbaaeceb":"train_df[\"flesch_reading_ease\"] = train_df[\"comment_text\"].progress_apply(textstat.flesch_reading_ease)\ntrain_df[\"automated_readability\"] = train_df[\"comment_text\"].progress_apply(textstat.automated_readability_index)\ntrain_df[\"dale_chall_readability\"] = train_df[\"comment_text\"].progress_apply(textstat.dale_chall_readability_score)","9f5567b6":"fig = go.Figure(go.Histogram(x=train_df.query(\"flesch_reading_ease > 0\")[\"flesch_reading_ease\"], marker=dict(\n            color='darkorange')\n    ))\n\nfig.update_layout(xaxis_title=\"Flesch reading ease\", title_text=\"Flesch reading ease\", template=\"simple_white\")\nfig.show()","d62b72c5":"# Count of Different Negative categories of comments\ntrain_df[train_df.columns[2:8]].sum(axis=0).rename('Count').sort_values(ascending=False).reset_index()","98c77a58":"train_df.groupby(['lang'])[train_df.columns[2:8]].sum().sum(axis=1).rename('Toxic_count').sort_values(ascending=False)[:10].reset_index()","c696e36e":"string = ' '.join(train_df.query('toxic == 1')['translated_comment'])\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(string.lower())\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Toxic comments')","95f16b9c":"string = ' '.join(train_df.query('obscene == 1')['translated_comment'])\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(string.lower())\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Obscene comments')","d0cffc2f":"string = ' '.join(train_df.query('identity_hate == 1')['translated_comment'])\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(string.lower())\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Identity hate comments')","4b7a6de6":"string = ' '.join(train_df.query('threat == 1')['translated_comment'])\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(string.lower())\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Identity hate comments')","c9a2b576":"val = val_df\ntrain = train_df\n\ndef clean(text):\n    text = text.fillna(\"fillna\").str.lower()\n    text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n    text = text.map(lambda x: re.sub(\"\\(http:\/\/.*?\\s\\(http:\/\/.*\\)\",'',str(x)))\n    return text\n\ntrain['comment_text'] = clean(train['comment_text'])\ntest_df['content'] = clean(test_df['content'])\nval['comment_text'] = clean(val['comment_text'])","190653cc":"# Inheriting tf.keras.Callback\nclass RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))","738a3bc4":"def fast_encode(texts, tokenizer, chunk_size=240, maxlen=512):\n    tokenizer.enable_truncation(max_length=maxlen)\n    tokenizer.enable_padding(max_length=maxlen)\n    all_ids = []\n    \n    for i in range(0, len(texts), chunk_size):\n        text_chunk = texts[i:i+chunk_size].tolist()\n        encs = tokenizer.encode_batch(text_chunk)\n        all_ids.extend([enc.ids for enc in encs])\n    \n    return np.array(all_ids)","22085105":"AUTO = tf.data.experimental.AUTOTUNE\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('jigsaw-multilingual-toxic-comment-classification')\n\nEPOCHS = 2\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync","2c06df70":"tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n\nsave_path = '\/kaggle\/working\/distilbert_base_uncased\/'\nif not os.path.exists(save_path):\n    os.makedirs(save_path)\ntokenizer.save_pretrained(save_path)\n\nfast_tokenizer = BertWordPieceTokenizer('distilbert_base_uncased\/vocab.txt', \n                                        lowercase=True)","5c12e721":"x_train_token_ids = fast_encode(train.comment_text.astype(str), \n                      fast_tokenizer, maxlen=512)\nx_valid_token_ids = fast_encode(val.comment_text.astype(str).values, \n                      fast_tokenizer, maxlen=512)\nx_test_token_ids = fast_encode(test_df.content.astype(str).values, \n                     fast_tokenizer, maxlen=512)\n\ny_valid = val.toxic.values\ny_train = train.toxic.values","087596ae":"## Token Ids for 1st comment tokens padded with 0s (max len = 512)\nx_train_token_ids[0][:100]","805b064e":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train_token_ids, y_train))\n    .repeat()\n    .shuffle(2048)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_valid_token_ids, y_valid))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(x_test_token_ids)\n    .batch(BATCH_SIZE)\n)","c1c2e6a4":"def build_vnn_model(transformer, max_len):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    \n    embed = transformer.weights[0].numpy()\n    embedding = Embedding(np.shape(embed)[0], np.shape(embed)[1],\n                          input_length=max_len, weights=[embed],\n                          trainable=False)(input_word_ids)\n    \n    conc = K.sum(embedding, axis=2)\n    conc = Dense(128, activation='relu')(conc)\n    conc = Dense(1, activation='sigmoid')(conc)\n    \n    model = Model(inputs=input_word_ids, outputs=conc)\n    \n    model.compile(Adam(lr=0.01), \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    return model","244819fd":"with strategy.scope():\n    transformer_layer = transformers.TFDistilBertModel.\\\n    from_pretrained('distilbert-base-multilingual-cased')\n    model_vnn = build_vnn_model(transformer_layer, max_len=512)\n\nmodel_vnn.summary()","05e7e954":"## Callback #1 - Reduce LR on Plateau\ndef callback():\n    cb = []\n\n    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',  \n                                    factor=0.3, patience=3, \n                                    verbose=1, mode='auto', \n                                    epsilon=0.0001, cooldown=1, min_lr=0.000001)\n    cb.append(reduceLROnPlat)\n    log = CSVLogger('log.csv')\n    cb.append(log)\n\n    RocAuc = RocAucEvaluation(validation_data=(x_valid_token_ids, y_valid), interval=1)\n    cb.append(RocAuc)\n    \n    return cb\ncalls = callback()\n\n## Callback #2 - Simply decay learning rate after each step\n\"\"\"\ndef step_decay(epoch):\n    initial_lrate = 0.1\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)\/epochs_drop))\n    return lrate\n\"\"\"\n\n## Callback #3 - learning rate scheduler\n\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\ncallbacks_list = [lr_schedule]","7bbdd49f":"STEPS_PER_EPOCH = x_train_token_ids.shape[0] \/\/ BATCH_SIZE\n\ntrain_history = model_vnn.fit(\n    train_dataset,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset,\n    \n    ## Using learning rate scheduler, tried running with all three callback methods, \n    ## Learning rate sceduler was considerably slower than LRonPlateau but the results were \n    ## more accurate\n    \n    callbacks = callbacks_list,  \n    epochs=10\n)","e1e3cf19":"translator = Translator()\n\ndef visualize_model_preds(model, indices=[0, 17, 1, 24]):\n    comments = val_df.comment_text.loc[indices].values.tolist()\n    preds = model.predict(x_valid_token_ids[indices].reshape(len(indices), -1))\n\n    for idx, i in enumerate(indices):\n        if y_valid[i] == 0:\n            label = \"Non-toxic\"\n            color = f'{Fore.GREEN}'\n            symbol = '\\u2714'\n        else:\n            label = \"Toxic\"\n            color = f'{Fore.RED}'\n            symbol = '\\u2716'\n\n        print('{}{} {}'.format(color, str(idx+1) + \". \" + label, symbol))\n        print(f'{Style.RESET_ALL}')\n        print(\"ORIGINAL\")\n        print(comments[idx]); print(\"\")\n        print(\"TRANSLATED\")\n        print(translator.translate(comments[idx]).text)\n        fig = go.Figure()\n        if y_valid[i] == 1:\n            yl = [preds[idx][0], 1 - preds[idx][0]]\n        else:\n            yl = [1 - preds[idx][0], preds[idx][0]]\n        fig.add_trace(go.Bar(x=['Non-Toxic', 'Toxic'], y=yl, marker=dict(color=[\"seagreen\", \"indianred\"])))\n        fig.update_traces(name=comments[idx])\n        fig.update_layout(xaxis_title=\"Labels\", yaxis_title=\"Probability\", template=\"plotly_white\", title_text=\"Predictions for validation comment #{}\".format(idx+1))\n        fig.show()\n        \nvisualize_model_preds(model_vnn)","86579141":"def build_cnn_model(transformer, max_len):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    \n    embed = transformer.weights[0].numpy()\n    embedding = Embedding(np.shape(embed)[0], np.shape(embed)[1],\n                          input_length=max_len, weights=[embed],\n                          trainable=False)(input_word_ids)\n    \n    embedding = SpatialDropout1D(0.3)(embedding)\n    conv_1 = Conv1D(64, 2)(embedding)\n    conv_2 = Conv1D(64, 3)(embedding)\n    conv_3 = Conv1D(64, 4)(embedding)\n    conv_4 = Conv1D(64, 5)(embedding)\n    \n    maxpool_1 = GlobalAveragePooling1D()(conv_1)\n    maxpool_2 = GlobalAveragePooling1D()(conv_2)\n    maxpool_3 = GlobalAveragePooling1D()(conv_3)\n    maxpool_4 = GlobalAveragePooling1D()(conv_4)\n    conc = concatenate([maxpool_1, maxpool_2, maxpool_3, maxpool_4], axis=1)\n\n    conc = Dense(64, activation='relu')(conc)\n    conc = Dense(1, activation='sigmoid')(conc)\n    \n    model = Model(inputs=input_word_ids, outputs=conc)\n    \n    model.compile(Adam(lr=0.01), \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    return model","690d1dfb":"with strategy.scope():\n    model_cnn = build_cnn_model(transformer_layer, max_len=512)","b519ef64":"from PIL import Image\nfrom IPython.display import SVG\nfrom keras.utils import model_to_dot\nSVG(tf.keras.utils.model_to_dot(model_cnn, dpi=70).create(prog='dot', format='svg'))","3ddcef4f":"train_history = model_cnn.fit(\n    train_dataset,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset,\n    callbacks = callbacks_list,\n    epochs=10\n)","0d049481":"visualize_model_preds(model_cnn)","35f4d824":"class AttentionWeightedAverage(Layer):\n\n    def __init__(self, return_attention=False, **kwargs):\n        self.init = initializers.get('uniform')\n        self.supports_masking = True\n        self.return_attention = return_attention\n        super(AttentionWeightedAverage, self).__init__(** kwargs)\n\n    def build(self, input_shape):\n        self.input_spec = [InputSpec(ndim=3)]\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape=(input_shape[2], 1),\n                                 name='{}_W'.format(self.name),\n                                 initializer=self.init)\n        super(AttentionWeightedAverage, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        logits = K.dot(x, self.W)\n        x_shape = K.shape(x)\n        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n\n        if mask is not None:\n            mask = K.cast(mask, K.floatx())\n            ai = ai * mask\n        att_weights = ai \/ (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n        weighted_input = x * K.expand_dims(att_weights)\n        result = K.sum(weighted_input, axis=1)\n        if self.return_attention:\n            return [result, att_weights]\n        return result\n\n    def get_output_shape_for(self, input_shape):\n        return self.compute_output_shape(input_shape)\n\n    def compute_output_shape(self, input_shape):\n        output_len = input_shape[2]\n        if self.return_attention:\n            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n        return (input_shape[0], output_len)\n\n    def compute_mask(self, input, input_mask=None):\n        if isinstance(input_mask, list):\n            return [None] * len(input_mask)\n        else:\n            return None","2436f298":"def build_lstm_model(transformer, max_len):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    \n    embed = transformer.weights[0].numpy()\n    embedding = Embedding(np.shape(embed)[0], np.shape(embed)[1],\n                          input_length=max_len, weights=[embed],\n                          trainable=False)(input_word_ids)\n    \n    embedding = SpatialDropout1D(0.3)(embedding)\n    lstm_1 = LSTM(128, return_sequences=True)(embedding)\n    lstm_2 = LSTM(128, return_sequences=True)(lstm_1)\n    \n    attention = AttentionWeightedAverage()(lstm_2)\n    conc = Dense(64, activation='relu')(attention)\n    conc = Dense(1, activation='sigmoid')(conc)\n    \n    model = Model(inputs=input_word_ids, outputs=conc)\n    \n    model.compile(Adam(lr=0.01), \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    return model","af3881f8":"with strategy.scope():\n    model_lstm = build_lstm_model(transformer_layer, max_len=512)","c23e4aa5":"SVG(tf.keras.utils.model_to_dot(model_lstm, dpi=70).create(prog='dot', format='svg'))","5a564f56":"train_history = model_lstm.fit(\n    train_dataset,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset,\n    callbacks = callbacks_list,\n    epochs=10\n)","d0ff31c4":"visualize_model_preds(model_lstm)","3731aea2":"def build_distilbert_model(transformer, max_len=512):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    cls_token = Dense(500, activation=\"elu\")(cls_token)\n    cls_token = Dropout(0.1)(cls_token)\n    out = Dense(1, activation='sigmoid')(cls_token)\n    \n    model = Model(inputs=input_word_ids, outputs=out)\n    \n    model.compile(Adam(lr=1.5e-5), \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    return model","c3c35ef8":"with strategy.scope():\n    model_distilbert = build_distilbert_model(transformer_layer, max_len=512)","8b7d6a71":"train_history = model_distilbert.fit(\n    train_dataset,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid_dataset,\n    callbacks = callbacks_list,\n    epochs=2\n)","115ab7b4":"visualize_model_preds(model_distilbert)","e19bc5ce":"### Word cloud of Negative Comments","857a6c41":"### Cleaning Comments","f8f3ca24":"### Convolution Neural Networks","a39b512f":"### Train LSTM model","dada3cfd":"### Convolution Neural Network Summary-\nValidation Accuracy - 84.61\n\n4 out 4 above validation samples predicted correctly, however the probability of prediction for some samples are not extreme","5b6d849a":"## LSTM with Attention\n \n\n### LSTM\n\nLSTMs are a type of neural network specifically made for NLP (text-related) tasks. In fact, LSTMs are a specific type of RNN. An RNN is a type of neural network that has a sense of direction (sequence). Classic neural networks look at all inputs at the same level, but RNNs look at inputs in a sequential order, which works well for text, as it is a sequential form of input.\n\nBut, RNNs have a problem called \"vanishing gradients\", which makes it difficult for it to understand long-term dependencies in text. Below is a depiction of the LSTM architecture which solves the problem of long-term dependencies:\n\n<center><img src=\"https:\/\/i.imgur.com\/gmijcvr.png\" width=\"650px\"><\/center>\n\n### Attention\n\nAttention is a mathematical mechanism that allows a neural network to select its main areas of focus ina sequence. Understanding which part of the comment to focus on (based on mathematics and probabilities) can be crucial in predicting whether it is toxic or not. The Attention mechanism can be combined with LSTMs to produce excellent NLP models.\n\nThe approach can be summarized with flowchart below:\n\n\n<center><img src=\"https:\/\/i.imgur.com\/SbFlht3.png\" width=\"315px\"><\/center>","e77109bc":"### Define the model","33dbdc07":"## Vanilla neural network\n\nVanilla neural network refers to the classic neural network architecture.","69a2445a":"### Define LSTM model","274fe213":"<center><img src=\"https:\/\/i.imgur.com\/ReZ9Ppl.png\" width=\"500px\"><\/center>","ca7de7c5":"## Convolutional neural network \nConvolutional neural networks are a type of neural netork generally used for image recognition problems. But, the 1D version of CNNs can also be used for text-related problems (natural language processing). Convolution involves a process called convolution.\n\n**In text classification, a 1D variant of convolution is used where the kernel moves in only one dimension.**\n\nwe wil use the pretrained BERT embeddings as input, pass the embeddings through convolutional layers, and get the probability of the comment being toxic. The approach can be summarized using the flowchart below:\n\n<center><img src=\"https:\/\/i.imgur.com\/7hsdV9T.png\" width=\"315px\"><\/center>","1bbddc3a":"### Threat","1d0684c5":"<h2>Let's Detect Languages and Countries<\/h2>\n\n![image.png](attachment:image.png)\n<br>\nWe will be using pycountry to get Full Language names and also the Country names","9f366ed8":"#### Top 3 most verbose comments","834f9d76":"![image.png](attachment:image.png)","ecf0770a":"![image.png](attachment:image.png)","73fd152d":"## Modelling","f1f40c51":"### Encoding comments and generating token ids","38f19375":"Majority of the comments are having average number of words around 100.\nAlso from the scatter plot on the right we can see that more than 2 lakh comments have word count less than 100","6e04bf0d":"### Building Roc Auc evaluation metric","1d10ccaf":"## Sentiment Analysis\n![image.png](attachment:image.png)","26d634f9":"### Setting up function for Encoding comments","75a5b04d":"<b>\n    As of now we don't seen any toxic words in the above Word Cloud.<br> It seems those words have not been used frequently in the comments.<\/b>","1a4568e0":"### Train the model","705d6f09":"### Identity hate","c064bddf":"Vanilla neural networks consist of sequential layers that perform simple matrix multiplications and vector additions, until we reach the output layer. The propagation of values in a VNN can be represented with the following equation:\n\n<center><img src=\"https:\/\/i.imgur.com\/xbtn9ex.png\" width=\"200px\"><\/center>\n\nwhere *W* is the weight matrix and *b* is the bias vector in layer *n*.","979c156e":"### Most toxic comments used in a Language","aa8da803":"<center><h2>Import Libraries<\/h2><center>","10be6d80":"We can see that compound sentiment tends to be higher for non-toxic comments as compared to toxic comments. The non-toxic distribution has a leftward (negative) skew, while the toxic distribution has a positive (rightward) skew. This indicates that non-toxic comments tend to have a higher compound sentiment than toxic comments on average.","f27cb902":"### Readability \nReadability is an indication of how \"easy\" it is to read some text. There are several metrics that can be used to measure the readability of a piece of text, including Flesch reading ease, automated readability, and Dale-Chall readability.","f7e507f0":"From the above plot, we can see that negative sentiment has a strong rightward (positive) skew, indicating that negativity is usually on the lower side. This suggests that most comments are not toxic or negative. In fact, the most common negativity value is around 0.04. Virtually no comments have a negativity greater than 0.8.","fb9bf725":"### Setup TPU config","f9d72c03":"### Distribution of Comment Words","1afa3bda":"### Toxic","90f9e490":"### Callbacks","fdc99940":"## Translate comments","840cc990":"## Target Variables","ff44516e":"### Average Word count per Language","7606a5ed":"### Bert Tokenizer","589c8fe8":"### LSTM summary-\n\nPretty better results till now","41e39100":"From the above plot, we can see that the neutrality sentiment distribution has a strong leftward (negative) skew, which is in constrast to the negativity and positivity sentiment distributions. This indicates that the comments tend to be very neutral and unbiased in general. This also suggests that most comments are not highly opinionated and polarizing, meaning that most comments are non-toxic.","710a99fb":"### Compound sentiment\nCompoundness sentiment refers to the total level of sentiment in the sentence. It is a score between -1 and 1; the greater the score, the more emotional the abstract is.","c897b59b":"### Obscene","d2a7e4ea":"### Define training, validation, and testing datasets","cc006c56":"### Vanilla Network Summary-\nValidation Accuracy - 84.61\n\n4 out 4 above validation samples predicted coorectly","9f68d541":"### Positive Sentiment\nPositive sentiment refers to positive or optimistic emotions. It is a score between 0 and 1; the greater the score, the more positive the abstract is.","a394b6b6":"### Neutral Sentiment\nNeutrality sentiment refers to the level of bias or opinion in the text. It is a score between 0 and 1; the greater the score, the more neutral\/unbiased the abstract is.","e560d5d2":"<center><h2>Load Data<\/h2><\/center>","609a872d":"## DistilBERT\n\n### BERT\n\nBERT (Bidirectional Encoder Representations from Transformers) was a paper published by researchers at Google AI Language, which caused a great stir in the NLP community as it became the SOTA on several NLP tasks.\n\nBERT\u2019s key technical innovation is applying the bidirectional training of Transformer, a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training (such as LSTMs). \n\nThe paper\u2019s results show that a language model which is bidirectionally trained can have a deeper sense of language context and flow than single-direction language models. In the paper, the researchers detail a novel technique named Masked LM (MLM) which allows bidirectional training in models in which it was previously impossible.\n\n### DistilBERT\n\nDistilBERT is a lighter version of BERT (a very complex model) which uses fewer weights and achieves similar accuracies on several tasks with much lower training times. For this notebook, I will be using DistilBERT as it is easier to train in less time. The approach can be summarized with the flowchart below:\n\n<center><img src=\"https:\/\/i.imgur.com\/6AGu9a4.png\" width=\"315px\"><\/center>","5d3a471d":"We can clearly see that toxic comments have a significantly greater negative sentiment than toxic comments (on average). The probability density of negativity peaks at around 0 for non-toxic comments, while the negativity for toxic comments are minimum at this point. This suggests that a comment is very likely to be non-toxic if it has a negativity of 0.","23f8ed1a":"### Define the Attention Layer","d7423793":"It is clear that the comment section is mostly in English with more than 98% usage.","c0450d25":"<center><h2>Looking at the comments from Train data<\/h2><\/center>","7c7cf471":"We will be using the pretrained BERT embeddings as input, add the word vectors, and pass it through a VNN and get the probability of the comment being toxic. The approach can be summarized using the flowchart below:\n\n<center><img src=\"https:\/\/i.imgur.com\/ORDcivv.png\" width=\"315px\"><\/center>","72f47e92":"### Negativity of Toxic vs Non-Toxic Comments","2cb4a47b":"### Negative Sentiment\nNegative sentiment refers to negative or pessimistic emotions. It is a score between 0 and 1; the greater the score, the more negative the abstract is."}}