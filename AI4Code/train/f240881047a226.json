{"cell_type":{"9c6f07dd":"code","3f05514c":"code","2c8ad637":"code","21522868":"code","821ee652":"code","1f82f1a0":"code","994c9626":"code","228cd5cb":"code","dd8ba196":"code","a992d60e":"code","04f198b6":"code","1a609f54":"code","30f2740d":"code","f6ed23f5":"code","95c0f08f":"code","9089c7bd":"code","44375ae5":"code","4e625eca":"code","e043dc06":"code","a3ce4424":"code","bab2e9c4":"markdown","90344e70":"markdown","a61be5f3":"markdown","43daab7f":"markdown","f6e099f3":"markdown","7fd779cb":"markdown","953bc929":"markdown","a301c17b":"markdown","e2eeed5b":"markdown","37398572":"markdown","6a888f8c":"markdown","7b2f8e44":"markdown"},"source":{"9c6f07dd":"import warnings\nwarnings.filterwarnings(\"ignore\")\n#importing the packages needed\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk","3f05514c":"#reading the 12 dataset scraped from different websites\ndf1=pd.read_csv(\"..\/input\/travel\/d1.csv\")\ndf2=pd.read_csv(\"..\/input\/travel\/d2.csv\")\ndf3=pd.read_csv(\"..\/input\/travel\/d3.csv\")\ndf4=pd.read_csv(\"..\/input\/travel\/d4.csv\")\ndf5=pd.read_csv(\"..\/input\/travel\/d5.csv\")\ndf6=pd.read_csv(\"..\/input\/travel\/d6.csv\")\ndf7=pd.read_csv(\"..\/input\/travel\/d7.csv\")\ndf8=pd.read_csv(\"..\/input\/travel\/d8.csv\")\ndf9=pd.read_csv(\"..\/input\/travel\/d9.csv\")\ndf10=pd.read_csv(\"..\/input\/travel\/d10.csv\")\ndf11=pd.read_csv(\"..\/input\/travel\/d11.csv\")\ndf12=pd.read_csv(\"..\/input\/travel\/d12.csv\")","2c8ad637":"#concatenating all the dataframes to a single one\nframes = [df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12]\ndf = pd.concat(frames)\n#dropping all the row where the about section is empty\n#This is imp as we are analysing the cosine similarity of this section\ndata=df.dropna(axis = 0, how ='any')","21522868":"#Joining the columns to make a unique text column which defines a package --- The cosine similarity of this column is used to predict recommendations \nfeatures = ['place','package_name','about_trip']\ndef combine_features(row):\n return row['place']+\" \"+row['package_name']+\" \"+row['about_trip']\nfor feature in features:\n    data[feature] = data[feature].fillna('') #filling all NaNs with blank string\ndata[\"combined_features\"] = data.apply(combine_features,axis=1) #applying combined_features() method over each rows of dataframe and storing the combined string in \u201ccombined_features\u201d column\n#data.head(50) ---seeing the data","821ee652":"#downloading stopwords to remove the common words\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n","1f82f1a0":"#Function to do basic text cleaning\ndef clean(text):\n           \n    # Urls\n    text = re.sub(r\"https?:\\\/\\\/t.co\\\/[A-Za-z0-9]+\", \"\", text)\n        \n    # Words with punctuations and special characters\n    punctuations =['@','#','!','?','+','&','*','[',']','-','%','.',':','\/','(',')',';','$','=','>','<','|','{','}','^']\n    for p in punctuations:\n        text = text.replace(p, f' {p} ')\n\n    return text","994c9626":"data.iloc[6] = data.iloc[6].apply(lambda s : clean(s)) #cleaning the text using above function","228cd5cb":"#removing stopwords \nfrom nltk.corpus import stopwords\ndata[\"combined_features\"] = data[\"combined_features\"].str.lower().str.split()\nstop = stopwords.words('english')\ndata['combined_features']=data['combined_features'].apply(lambda x: [item for item in x if item not in stop])\ndata[\"combined_features\"]= data[\"combined_features\"].str.join(\" \") #rejoining the words to text","dd8ba196":"# defining a new column with no's and setting it as index\nind=[]\nfor i in range(1609):\n     ind.append(i)\n\ndata.insert (0,\"index\",ind)\ndata.set_index(['index'])","a992d60e":"data.describe()","04f198b6":"data.head()","1a609f54":"data.tail()","30f2740d":"data.info()","f6ed23f5":"#import modules\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity","95c0f08f":"#data.replace('', np.nan, inplace=True)\ncv = CountVectorizer() #creating new CountVectorizer() object\ncount_matrix = cv.fit_transform(data['combined_features'].values.astype('U'))  #fitting cv object to combine features column\ncosine_sim = cosine_similarity(count_matrix) #calculating cosine similarity","9089c7bd":"#creating new column to merge place and package_name which serves as user input identifier\ndata.head()\nfeatures2 = ['place','package_name']\ndef combine_features2(row):\n return row['place']+\" \"+row['package_name']\nfor feature in features2:\n    data[feature] = data[feature].fillna('') #filling all NaNs with blank string\ndata[\"place_names\"] = data.apply(combine_features,axis=1)\ndata[\"place_names\"] = data[\"place_names\"].str.lower()","44375ae5":"#function to search user input on the newly created column and return the index\nimport re\ndef get_index_from_title(place):\n    for ind in data.index:\n        mond=data.iloc[ind]['place_names']\n        if re.search(place,mond):\n            return(ind)\n","4e625eca":"#finding similar places using cosine similarity\nplace_selec = \"kochi\"\nplace_index = get_index_from_title(place_selec)\n#print(place_index)\n\nsimilar_places = list(enumerate(cosine_sim[place_index])) #accessing the row corresponding to given place name to find all the similarity scores for that place name and then enumerating over it","e043dc06":"#sorting those packages in descending order \nsorted_similar_places = sorted(similar_places,key=lambda x:x[1],reverse=True)[1:]\n#print(sorted_similar_places)","a3ce4424":"#printing the top 5 recommendations\ni=0\nprint(\"Top 5 similar travel packages like \"+place_selec+\" are:\\n\")\nfor element in sorted_similar_places:\n    print(\"Package name: {}\".format(data.loc[data['index'] == element[0], 'package_name'].values[0]))\n    print(\"Place: {}\".format(data.loc[data['index'] == element[0], 'place'].values[0]))\n    dur=data.loc[data['index'] == element[0], 'time'].values[0]\n    print(\"Duration:{}\".format(\" \".join(dur.split()))) #removing extra places in emi column.\n    print(\"Amount: Rs {} .\".format(data.loc[data['index'] == element[0], 'price'].values[0]))\n    print('Emi amount: Rs {}'.format(data.loc[data['index'] == element[0], 'emi'].values[0]))\n    i=i+1\n    if i>5:\n        break","bab2e9c4":"## Section 3: Applying Cosine Similarity","90344e70":"This marks the end of our preprocessing of data.","a61be5f3":"# Table of contents\n\ni) Introduction\n\nii) Dataset preparation.\n\niii) Preprocessing of data.\n\niv) Applying Cosine similarity.\n\nv) Recommending places.","43daab7f":"# ii Dataset preparation","f6e099f3":"## Section 4: Recommending places","7fd779cb":"![](http:\/\/www.travelguru.com\/holiday-packages\/images\/goa.jpg)","953bc929":"Sorry for the huge no of datasets,this happened because scraping data from different websites.","a301c17b":"An upvote will be helpfull if you liked from my notebook.","e2eeed5b":"#  i Introduction\n\nEver wondered how Amazon is suggesting your favourites shoes or how youtube is suggesting a video which you like to watch. Recommender systems are the reason for this. The recommender systems are divided into three as of now\n\n* Popularity based recommendation engine\n* Content based recommendation engine\n* Collaborative filtering based recommendation engine\n.\n\n### 1)Popularity based recommendation engine:\n\nThisis the simplest kind of recommendation engine. The trending list you see in YouTube or Netflix is based on this algorithm. It keeps a track of view counts for each movie\/video and then lists movies based on views in descending order(highest view count to lowest view count).\n\n### 2)Content based recommendation engine:\n\nLets see this with the help of an example.Consider someone likes a movie. The recommender system takes it. Then it analyzes the contents (storyline, genre, cast, director etc.) of the movie to find out other movies which have similar content. Then it ranks similar movies according to their similarity scores and recommends the most relevant movies to the user.\n\n### 3)Collaborative filtering based recommendation engine:\n\nThis algorithm at first tries to find similarity between users based on their activities and preferences (for example, both the users watch same type of movies or movies directed by the same director). Now, between these users(say, A and B) if user A has seen a movie that user B has not seen yet, then that movie gets recommended to user B and vice-versa. In other words, the recommendations get filtered based on the collaboration between similar user\u2019s preferences (thus, the name \u201cCollaborative Filtering\u201d).ex: Amazon e-commerce platform, where you get to see the \u201cCustomers who viewed this item also viewed\u201d.\n\n\n\nThis notebook is a content based recommender engine. It takes in different details of travel packages, analyses it and predicts new travel packages based on the itinery details.","37398572":"![](http:\/\/\/www.researchgate.net\/publication\/320914786\/figure\/fig2\/AS:558221849841664@1510101868614\/The-difference-between-Euclidean-distance-and-cosine-similarity.png)","6a888f8c":"# iii Section 2 -- Preprocessing of data","7b2f8e44":"As I said earlier we are going to make a content based recommender system. So we are using the combined_features column. We are calculating the cosine similarity on this column.\n\nCosine similarity is a metric used to determine how similar the documents are irrespective of their size.\nMathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space. In this context, the two vectors I am talking about are arrays containing the word counts of two documents\n\nWhen plotted on a multi-dimensional space, where each dimension corresponds to a word in the document, the cosine similarity captures the orientation (the angle) of the documents and not the magnitude. If you want the magnitude, compute the Euclidean distance instead."}}