{"cell_type":{"0e0c2151":"code","8f94ab73":"code","40b63057":"code","124d8902":"code","57c541bd":"code","eb338f7b":"code","0aed5e6a":"code","3146acc3":"code","576dad73":"markdown","c74aed72":"markdown","5197ace6":"markdown","410aea71":"markdown"},"source":{"0e0c2151":"import numpy as np # linear algebra\nimport matplotlib.pyplot as plt","8f94ab73":"# trying to find:\ngoal_intercept = 10\ngoal_coef = 4\n\nX = 2 * np.random.rand(100, 1)\ny = goal_intercept + goal_coef * X + np.random.randn(100, 1)","40b63057":"plt.plot(X, y, \"o\")\nplt.show()","124d8902":"X_b = np.c_[np.ones((100,1)), X]\ntheta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\nprint(theta_best)","57c541bd":"X_new = np.array([[0], [2]])\nX_new_b = np.c_[np.ones((2,1)), X_new]\ny_predict = X_new_b.dot(theta_best)\nprint(y_predict)","eb338f7b":"plt.plot(X_new, y_predict, \"r-\")\nplt.plot(X, y, \"b.\")\nplt.show()","0aed5e6a":"eta = 0.1\niterations = 1000\nm = 100\n\ntheta = np.random.randn(2,1)\nprint(theta)\n\nfor i in range(iterations):\n    grad = (2 \/ m) * X_b.T.dot(X_b.dot(theta) - y)\n    theta = theta - eta * grad\n    \nprint(theta)","3146acc3":"from sklearn.linear_model import SGDRegressor\nsgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\nsgd_reg.fit(X, y.ravel())\nprint(sgd_reg.intercept_)\nprint(sgd_reg.coef_)","576dad73":"## Batch Gradient Descent","c74aed72":"# Linear Regression Algorithms","5197ace6":"## Normal Equation","410aea71":"## Stochastic Gradient Descent"}}