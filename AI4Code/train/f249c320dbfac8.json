{"cell_type":{"4edcfbfc":"code","31b72488":"code","4baf384a":"code","85ddd81f":"code","846598f4":"code","771b25ee":"code","511d68b2":"code","2a2bc6c3":"code","c4d2af51":"code","79477559":"code","e086b8f4":"code","2a5ec2b9":"code","8ef5f2b0":"code","abd84bc0":"code","dbb0d047":"code","9e35b602":"code","8ff6ded9":"code","5396e460":"code","4b36f1c4":"code","80fc3119":"code","1f3aa426":"code","153bd10f":"code","1ae35196":"code","af918a67":"code","98955a3e":"code","17aacefe":"code","b376b000":"code","4bad06bb":"code","2f66797f":"code","34080a99":"code","0b3c4660":"code","2bf4e5b2":"code","f03ef593":"code","da06a20b":"code","b4826c2b":"code","288f6d30":"code","8c57a34c":"code","8780f31d":"code","9444d386":"code","ad65b9b3":"code","b91be461":"code","dd9189de":"code","1b558d4a":"code","27dba3fa":"code","83699272":"code","f3a96d6e":"markdown","feaa550e":"markdown","c63be0a5":"markdown","663b9dda":"markdown","389699d8":"markdown","dd3c05dd":"markdown","bb2a8e69":"markdown","f1a8070e":"markdown","ff1525ed":"markdown","07ca28cd":"markdown","c008cba7":"markdown","939b1c9c":"markdown","4dfc90e0":"markdown","2d92a39d":"markdown","dc846af9":"markdown","49fd878d":"markdown","d050d1cd":"markdown","c88aec1b":"markdown","67c659fb":"markdown","2bf76d70":"markdown"},"source":{"4edcfbfc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# First, look at everything.\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\nimport cv2\nimport os\nimport random\nimport matplotlib.pylab as plt\nfrom glob import glob\nimport pandas as pd\nimport numpy as np","31b72488":"# in order to import an image\nfrom IPython.display import Image\nim1 = Image(\"..\/input\/walk_or_run_train\/train\/run\/run_00061c18.png\")\nim1","4baf384a":"# TRAIN\n\n# ..\/input\/\nPATH = os.path.abspath(os.path.join('..', 'input'))\n\n# TRAIN_RUN\n\n# ..\/input\/walk_or_run_train\/train\/run\ntrain_run_images = os.path.join(PATH, \"walk_or_run_train\", \"train\", 'run')\n# ..\/input\/walk_or_run_train\/train\/run\/*.png\ntrain_run = glob(os.path.join(train_run_images, \"*.png\"))\n\n# TRAIN_WALK\n\n# ..\/input\/walk_or_run_train\/train\/walk\ntrain_walk_images = os.path.join(PATH, \"walk_or_run_train\", \"train\", 'walk')\n# ..\/input\/walk_or_run_train\/train\/walk\/*.png\ntrain_walk = glob(os.path.join(train_walk_images, \"*.png\"))\n\n# ADD TRAIN_WALK AND TRAIN_RUN INTO A DATAFRAME\n\ntrain = pd.DataFrame()\ntrain['file'] = train_run + train_walk\ntrain.head()","85ddd81f":"# TEST\n\n# ..\/input\/\nPATH = os.path.abspath(os.path.join('..', 'input'))\n\n# TEST_RUN\n\n# ..\/input\/walk_or_run_test\/test\/run\ntest_run_images = os.path.join(PATH, \"walk_or_run_test\", \"test\", 'run')\n# ..\/input\/walk_or_run_test\/test\/run\/*.png\ntest_run = glob(os.path.join(test_run_images, \"*.png\"))\n\n# TEST_WALK\n\n# ..\/input\/walk_or_run_test\/test\/walk\ntest_walk_images = os.path.join(PATH, \"walk_or_run_test\", \"test\", 'walk')\n# ..\/input\/walk_or_run_test\/test\/walk\/*.png\ntest_walk = glob(os.path.join(test_walk_images, \"*.png\"))\n\ntest = pd.DataFrame()\ntest['file'] = test_run + test_walk\ntest.shape","846598f4":"#TRAIN LABELS\n\ntrain['label'] = [1 if i in train_run else 0 for i in train['file']]\ntrain.head()","771b25ee":"#TEST LABELS\n\ntest['label'] = [1 if i in test_run else 0 for i in test['file']]\ntest.tail()","511d68b2":"# TRAIN RUN AND WALK IMAGES\nplt.figure(figsize=(16,16))\nplt.subplot(121)\nplt.imshow(cv2.imread(train_run[2]))\n\nplt.subplot(122)\nplt.imshow(cv2.imread(train_walk[0]))","2a2bc6c3":"# TEST RUN AND WALK IMAGES\nplt.figure(figsize=(16,16))\nplt.subplot(121)\nplt.imshow(cv2.imread(test_run[12]))\n\nplt.subplot(122)\nplt.imshow(cv2.imread(test_walk[5]))","c4d2af51":"train.shape # features: file and layer","79477559":"# Each image shape is (224,224,3) (lets consider here only the first image)\ncv2.imread(train.file[0]).shape","e086b8f4":"# convert the dimension of an image into (224x224,3) namely: (50176,3)\nimage1 = cv2.imread(train.file[0]).reshape(224*224,3)\nimage1.shape\n\n# here 3 represent three dimension of a color pixel\n# for example RGB(23,24,122)","2a5ec2b9":"# convert this 3 dimensioanal color into an integer color value = R + G*(256) + B*(256^2)\n# for this example, lets use first pixel RGB values\nr1 = image1[0][0] # Red value of the first pixel of the first image\ng1 = image1[0][1] # Green value of the first pixel of the first image\nb1 = image1[0][2] # Blue value of the first pixel of the first image\n\n# now convert this 3 dimensional color value into an integer color value (of the first pixel)\nfirst_pixel_integer_color_value = r1+(256*g1)+(256*256*b1)\nfirst_pixel_integer_color_value","8ef5f2b0":"# create x_train3D and reshape it (coverting images into array)\n\nx_train3D = []\nfor i in range(0,600):\n    x_train3D.append(cv2.imread(train.file[i]).reshape(224*224,3))\n    \nx_train3D = np.asarray(x_train3D) # to make it array\nx_train3D = x_train3D\/1000 # for scaling\n\n# create y_train\ny_train = train.label\ny_train = np.asarray(y_train) # to make it array","abd84bc0":"x_train3D.shape","dbb0d047":"# create x_train \n# integer color value = R + G*(256) + B*(256^2)\nx_train = np.zeros((600,50176))\nfor i in range(0,600):\n    for j in range(0,50176):\n        x_train[i,j] = ((x_train3D[i][j][0]+(256*x_train3D[i][j][1])+(256*256*x_train3D[i][j][2]))\/10000000)\n\nx_train = np.asarray(x_train) # to make it array","9e35b602":"x_train.shape","8ff6ded9":"y_train.shape","5396e460":"# ORIJINAL IMAGES\n# TRAIN RUN IMAGES\nplt.figure(figsize=(16,16))\nplt.subplot(121)\nplt.imshow(cv2.imread(train_run[0]))\n\nplt.subplot(122)\nplt.imshow(cv2.imread(train_run[1]))","4b36f1c4":"# MODIFIED ONES\n\nimg_size = 224\nplt.figure(figsize=(16,16))\nplt.subplot(1, 2, 1)\nplt.imshow(x_train[0].reshape(img_size, img_size))\nplt.subplot(1, 2, 2)\nplt.imshow(x_train[1].reshape(img_size, img_size))","80fc3119":"test.shape","1f3aa426":"# create x_test and reshape it (coverting images into array)\nx_test3D = []\nfor i in range(0,141):\n    x_test3D.append(cv2.imread(test.file[i]).reshape(224*224,3))\n\nx_test3D = np.asarray(x_test3D) # to make it array\n\n# create y_test\ny_test = test.label\ny_test = np.asarray(y_test) # to make it array","153bd10f":"x_test3D.shape","1ae35196":"# create x_test \n# integer color value = R + G*(256) + B*(256^2)\nx_test = np.zeros((141,50176))\nfor i in range(0,141):\n    for j in range(0,50176):\n        x_test[i,j] = ((x_test3D[i][j][0]+(256*x_test3D[i][j][1])+(256*256*x_test3D[i][j][2]))\/10000000)\n\nx_test = np.asarray(x_test) # to make it array","af918a67":"x_test.shape","98955a3e":"y_test.shape","17aacefe":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(random_state=42, max_iter = 150, C = 0.1)\nLR.fit(x_train,y_train)","b376b000":"print(\"test accuracy: {} \".format(LR.score(x_test, y_test)))\nprint(\"train accuracy: {} \".format(LR.score(x_train, y_train)))","4bad06bb":"from sklearn.linear_model import SGDClassifier\nSGDC = SGDClassifier(max_iter = 100)\nSGDC.fit(x_train, y_train)","2f66797f":"print(\"test accuracy: {} \".format(SGDC.score(x_test, y_test)))\nprint(\"train accuracy: {} \".format(SGDC.score(x_train, y_train)))","34080a99":"x_train = x_train.T # it means we have 600 images with 50176 pixels each\nx_train.shape","0b3c4660":"y_train = y_train.T\ny_train.shape","2bf4e5b2":"x_test = x_test.T\ny_test = y_test.T\nx_test.shape","f03ef593":"def initialize_weights_bias(x_train, nodes=3):\n    w1 = np.random.rand(nodes,x_train.shape[0])*0.1\n    b1 = np.zeros((nodes,1))\n    w2 = np.random.rand(1,nodes)*0.1\n    b2 = np.zeros((1,1))\n    return w1, b1, w2, b2","da06a20b":"def sigmoid(x):\n    y = 1\/(1+np.exp(-x))\n    return y","b4826c2b":"def forward_propogation(x_train,w1,b1,w2,b2):\n    Z1 = np.dot(w1,x_train)+b1\n    A1 = np.tanh(Z1)\n    Z2 = np.dot(w2,A1)+b2\n    A2 = sigmoid(Z2)\n    \n    return Z1,A1,Z2,A2","288f6d30":"def calculate_cost(A2, Y):\n    logprobs = np.multiply(np.log(A2),Y)\n    cost = -np.sum(logprobs)\/Y.shape[1]\n    return cost","8c57a34c":"# Backward Propagation\ndef backward_propagation(w1, b1, w2, b2, A1, A2, X, Y):\n\n    dZ2 = A2-Y\n    dW2 = np.dot(dZ2,A1.T)\/X.shape[1]\n    db2 = np.sum(dZ2,axis =1,keepdims=True)\/X.shape[1]\n    dZ1 = np.dot(w2.T,dZ2)*(1 - np.power(A1, 2))\n    dW1 = np.dot(dZ1,X.T)\/X.shape[1]\n    db1 = np.sum(dZ1,axis =1,keepdims=True)\/X.shape[1]\n    \n    return dW1, db1, dW2, db2 ","8780f31d":"def update_parameters(w1,b1,w2,b2,dW1,db1,dW2,db2,learning_rate=0.01):\n    w1 = w1-learning_rate*dW1\n    b1 = b1-learning_rate*db1\n    w2 = w2-learning_rate*dW2\n    b2 = b2-learning_rate*db2\n    return w1,b1,w2,b2    ","9444d386":"def two_layer_Neural_Netwok(x_train, x_test, y_train, y_test, max_iter = 150):\n    cost_list = []\n    index_list = []\n    \n    w1,b1,w2,b2 = initialize_weights_bias(x_train, nodes=3)\n    for i in range(0,max_iter):\n        Z1,A1,Z2,A2 = forward_propogation(x_train,w1,b1,w2,b2)\n        # cost = calculate_cost(A2, y_train.T)\n        dW1, db1, dW2, db2 = backward_propagation(w1, b1, w2, b2, A1, A2, x_train, y_train)\n        w1,b1,w2,b2 = update_parameters(w1,b1,w2,b2,dW1,db1,dW2,db2,learning_rate=0.01)\n    \n        #if i % 10 == 0:\n        #    cost_list.append(cost)\n        #    index_list.append(i)\n        #    print (\"Cost after iteration {0}: {1}\".format(i, cost))\n    #plt.plot(index_list,cost_list)\n    #plt.xticks(index_list,rotation='vertical')\n    #plt.xlabel(\"Number of Iterarion\")\n    #plt.ylabel(\"Cost\")\n    #plt.show()\n    \n    # Now, lets make prediciton using updated parameters\n    Z1,A1,Z2,A2 = forward_propogation(x_test,w1,b1,w2,b2)\n    y_prediction = np.zeros((1,x_test.shape[1]))\n    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n    for i in range(x_test.shape[1]):\n        if A2[0,i]<=0.5:\n            y_prediction[0,i] = 0\n        else:\n            y_prediction[0,i] = 1\n    \n    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction - y_test)) * 100))\n    return w1,b1","ad65b9b3":"two_layer_Neural_Netwok(x_train, x_test, y_train, y_test, max_iter = 150)","b91be461":"# reshaping\nx_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.T, y_test.T","dd9189de":"# Evaluating the ANN\n# 2 hidden layers we have (totally 3 layers, together with the output)\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\ndef build_classifier():\n    classifier = Sequential() # initialize neural network\n    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'tanh'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 200)\n# accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\nclassifier.fit(x_train, y_train, epochs = 200)","1b558d4a":"print('test score of 3-Layer ANN: ', classifier.score(x_test,y_test)) \nprint('train score of 3-Layer ANN: ', classifier.score(x_train,y_train)) ","27dba3fa":"# Evaluating the ANN\n# 3 hidden layer\n# each has 64, 30, 3 neurons (nodes) respectively\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\ndef build_classifier():\n    classifier = Sequential() # initialize neural network\n    classifier.add(Dense(units = 6, kernel_initializer = 'random_uniform', activation = 'tanh', input_dim = x_train.shape[1]))\n    classifier.add(Dense(units = 4, kernel_initializer = 'random_uniform', activation = 'tanh'))\n    classifier.add(Dense(units = 3, kernel_initializer = 'random_uniform', activation = 'tanh'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'random_uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 300)\n# accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\nclassifier.fit(x_train, y_train, epochs = 300)","83699272":"print('test score of 4-Layer ANN: ', classifier.score(x_test,y_test)) \nprint('train score of 4-Layer ANN: ', classifier.score(x_train,y_train)) ","f3a96d6e":"**TO LOAD IMAGES**\n\nIn the dataset we have png images\n\n1. TRAIN DATA SET\n    1. RUN\n    1. WALK\n    \n2. TEST DATA SET\n    1. RUN\n    2. WALK","feaa550e":"**READ TRAIN AND TEST DATA**","c63be0a5":"**TRAIN (RUN AND WALK) IMAGE EXAMPLES**","663b9dda":"**TEST (RUN AND WALK) IMAGE EXAMPLES**","389699d8":"**LETS COMAPE ORIGINAL IMAGE WITH THE MODIFIED ONE******","dd3c05dd":"we see that for the train data accuracy is very high. However, for the test data it is low. Actullay we understand that here we have overfitting. It just memorizes the train data.","bb2a8e69":"**ARTIFICIAL NEURAL NETWORK USING KERAS**","f1a8070e":"**3-LAYER ANN**","ff1525ed":"<a id=\"14\"><\/a> <br>\n## Loss function and Cost function\n* Loss and cost functions are the same with logistic regression\n* Cross entropy function\n<a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/image.ibb.co\/nyR9LU\/as.jpg\" alt=\"as\" border=\"0\"><\/a><br \/>","07ca28cd":"**4-LAYER ANN**","c008cba7":"**TRAIN DATA SET LABELS**","939b1c9c":"**TEST DATA SET**","4dfc90e0":"https:\/\/playground.tensorflow.org\/#activation=tanh&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=0&networkShape=8,4,4,3,3,2&seed=0.09399&showTestData=false&discretize=false&percTrainData=70&x=true&y=true&xTimesY=true&xSquared=true&ySquared=true&cosX=false&sinX=true&cosY=false&sinY=true&collectStats=false&problem=classification&initZero=false&hideText=false\n","2d92a39d":"**2-LAYER ARTIFICIAL NEURAL NETWORK **","dc846af9":"**TEST DATA**","49fd878d":"**LOGISTIC REGRESSION **","d050d1cd":"**TRAIN DATA SET**","c88aec1b":"**Now lets apply these for all images and pixels**","67c659fb":"- each row is a pixel \n- that is, here we have 50176 pixel for each image\n- each pixel has 3 dimensional color value\n- we will convert it into 1 dimensional color value","2bf76d70":"**TRAIN DATA**"}}