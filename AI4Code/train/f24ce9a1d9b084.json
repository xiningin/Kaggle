{"cell_type":{"165058d8":"code","39158398":"code","4289ac9c":"code","f2f3f1f4":"code","d063e8c4":"code","5a42f499":"code","211a7472":"code","2830c41d":"code","63682548":"code","f2ca7ef0":"code","9cb06430":"code","78060bdb":"code","8bf939da":"code","520e5ecd":"code","d423a893":"code","34219ba2":"code","39336906":"markdown","b7819263":"markdown","069a7f6e":"markdown","30cd02db":"markdown","b6a62199":"markdown","7e4db601":"markdown","36a361ae":"markdown","f702459c":"markdown","6b74723a":"markdown","910df930":"markdown"},"source":{"165058d8":"# import libraries\n\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","39158398":"# reduce memory usage function\n# credits : Guillaume Martin (https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\/notebook)\n\ndef reduce_memory_usage(df):\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != 'object':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            \n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    pass\n        else:\n            df[col] = df[col].astype('category')\n    \n    return df","4289ac9c":"# read data into dataframe\n\ntrain = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv')\nreduce_memory_usage(train)\n\ntest = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/test.csv')\nreduce_memory_usage(test);","f2f3f1f4":"# concise summary of dataset\ntrain.info()","d063e8c4":"# first five rows\ntrain.head()","5a42f499":"# shape of data\nprint(train.shape)\nprint(test.shape)","211a7472":"# descriptive statistics\ntrain.describe().T.sort_values(by='std' , ascending = False)","2830c41d":"# distribution of labels\n\nplt.figure(figsize=(10,8))\nsns.countplot(x='Cover_Type', data=train, palette='icefire_r');","63682548":"train['Cover_Type'].value_counts(ascending=False)","f2ca7ef0":"# predictor\nX = train.drop(columns=['Id','Cover_Type','Soil_Type7','Soil_Type15'])\n\n# target\ny = train['Cover_Type']\n\n# test data \ntest_df = test.drop(columns=['Id','Soil_Type7','Soil_Type15'])","9cb06430":"# train-test split\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=123, shuffle =True)","78060bdb":"from catboost import CatBoostClassifier\n\nmodel = CatBoostClassifier(task_type='GPU')\nmodel.fit(X_train,y_train)","8bf939da":"# validation predictionShrink model to first 8860 iterations.\ny_pred=model.predict(X_val)","520e5ecd":"# validation accuracy\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy Score : ',accuracy_score(y_val, y_pred))","d423a893":"# test prediction\ny_pred = model.predict(test_df)","34219ba2":"# submission\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')\nsubmission['Cover_Type'] = y_pred\nsubmission.to_csv(\"submission.csv\",index=False)\nsubmission.head()","39336906":"<h1 style=\"color:#ff5733\"><strong>Preprocessing<\/strong><\/h1>","b7819263":"<h1 style=\"color: #ff5733\"><strong>Setup<\/strong><\/h1>","069a7f6e":"<p style=\"font-size:120%\">\n<strong>Kaggle<\/strong> competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, Kaggle have launched many Playground competitions that are more approachable than Featured competition, and thus more beginner-friendly.\n<p> \n    \n<p style=\"font-size:120%\">\nThe dataset is used for this competition, <strong><a href=\"https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\">Tabular Playground Series - Dec 2021<\/a><\/strong>, is synthetic, but based on a real dataset and generated using a <a href=\"https:\/\/github.com\/sdv-dev\/CTGAN\">CTGAN<\/a>. For this competition, you will be predicting a categorical target based on a number of feature columns given in the data.  This dataset is based off of the original <a href=\"https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/overview\">Forest Cover Type Prediction competition<\/a>. Submissions are evaluated on <strong>multi-class classification accuracy<\/strong>.\n<p>","30cd02db":"<p style=\"font-size:120%\">\n<strong>Data description<\/strong> can be found <a href=\"https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/data\">here<\/a>.\n<\/p>","b6a62199":"<h1 style=\"color: #ff5733\"><strong>Introduction<\/strong><\/h1>","7e4db601":"<p style=\"font-size:120%\"><strong>Thank You<\/strong><p\/>","36a361ae":"<h1 style=\"color:#ff5733\"><strong>CatBoostClassifier<\/strong><\/h1>\n","f702459c":"<p style=\"font-size:120%\">The distribution of label is very unbalanced.","6b74723a":"<p style=\"font-size:120%\">\n    Columns <strong>Soil_Type7<\/strong> and <strong>Soil_Type15<\/strong> have only zero values. So it will be dropped later\n<\/p>","910df930":"<h1 style=\"color:#ff5733\"><strong>Exploratory Data Analysis<\/strong><\/h1>"}}