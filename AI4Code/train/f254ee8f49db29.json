{"cell_type":{"0789a7e3":"code","dcd21699":"code","57fcce60":"code","6b71489f":"code","e1f7868c":"code","1ae61f02":"code","3b2deadf":"code","3452543b":"code","5f4d0873":"code","6ada6479":"code","57083e40":"code","2954220e":"code","36a4eb62":"code","78d5342f":"code","ce2978df":"code","444a4a2a":"code","374b41f3":"code","b1b71fa6":"code","511c7b1d":"code","7f35aab4":"code","66023043":"code","07f27da1":"code","8666b2b8":"code","b4a5227b":"code","4302e30e":"code","99c3736e":"code","bf8d0509":"code","1d47957e":"markdown","f482f471":"markdown","4346fe5b":"markdown","7fa3bd5e":"markdown","dd33361e":"markdown","a41cf676":"markdown","57af8227":"markdown","2909e9c4":"markdown","a437dc8d":"markdown","fe8b9755":"markdown"},"source":{"0789a7e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport scipy.sparse\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport base64\nfrom pandas.plotting import scatter_matrix\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nfrom IPython.display import FileLink, FileLinks\n        \n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dcd21699":"#DEscomentar si es para subir\nROOT_FOLDER         = '\/kaggle\/input\/competitive-data-science-predict-future-sales\/'\ndf_items             =  pd.read_csv(os.path.join(ROOT_FOLDER, 'items.csv'))\ndf_item_categories   =  pd.read_csv(os.path.join(ROOT_FOLDER, 'item_categories.csv'))\ndf_sales_train       =  pd.read_csv(os.path.join(ROOT_FOLDER, 'sales_train.csv'))\ndf_shops             =  pd.read_csv(os.path.join(ROOT_FOLDER, 'shops.csv'))\ndf_test              =  pd.read_csv(os.path.join(ROOT_FOLDER, 'test.csv'))","57fcce60":"print(' Dataset Items ')\ndf_items.head(1)","6b71489f":"print(' Dataset item_categories ')\ndf_item_categories.head(1)","e1f7868c":"print(' Dataset sales_train ')\ndf_sales_train.head(1)","1ae61f02":"print(' Dataset test ')\ndf_test.head(1)","3b2deadf":"print(' Dataset shops ')\ndf_shops.head(1)","3452543b":"print ('Train min\/max date: %s \/ %s' % (df_sales_train.date_block_num.min(), df_sales_train.date_block_num.max()))\nprint('Sales Train shape: %d rows' % df_sales_train.shape[0])\nprint('Test: %d rows ' % df_test.shape[0])","5f4d0873":"# Number of NaNs for columns\ndf_sales_train.isnull().sum(axis=0).head(15)","6ada6479":"# Number of NaNs for row\ndf_sales_train.isnull().sum(axis=1).head(15)","57083e40":"index_cols = ['shop_id', 'item_id','item_price','date_block_num']\n\n#get aggregated values for (shop_id, item_id,  date_block_num)\ngb_train = df_sales_train.groupby(index_cols,as_index=False).agg({'item_cnt_day':'sum'}, dtype='int32')\ngb_train = gb_train.rename(columns={'item_cnt_day': 'item_cnt_month'})\ngb_train = gb_train[['shop_id', 'item_id','item_price','date_block_num','item_cnt_month']]\ngb_train.fillna(0, inplace=True)\ngb_train.head(2)","2954220e":"#Shops without sales per month 2826\ngb_train[(gb_train.item_cnt_month == 0)]","36a4eb62":"gb_train[((gb_train.shop_id == 2) & (gb_train.item_id == 835))]","78d5342f":"gb_train.count()","ce2978df":"figure, axe = plt.subplots(figsize = (12,12))\naxe.set_title(\" EDA Item Price VS  Sales Day\", weight=\"bold\")\n\nplot = plt.scatter(gb_train.item_price, gb_train.item_cnt_month, marker=\"o\", c=\"yellow\", edgecolor =\"black\", s=30, cmap='viridis', linewidth=0.5)\nplt.xlabel('Item Price')\nplt.ylabel('Sales Day')","444a4a2a":"PRICE_OUT = 300000\nSALES_OUT = 2000\ngb_train = gb_train[(gb_train.item_price < PRICE_OUT) & (gb_train.item_cnt_month < SALES_OUT)]","374b41f3":"gb_train = gb_train.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_month'],columns = ['date_block_num'],fill_value = 0)","b1b71fa6":"gb_train.head(1)","511c7b1d":"# Doing merge between train_data and test_df as to be suitable for prediction\ndf_all_data = pd.merge(df_test, gb_train,on = ['item_id','shop_id'],how = 'left')\n#Fill NAN's with 0\ndf_all_data.fillna(0, inplace=True)","7f35aab4":"df_all_data.drop(['ID','shop_id','item_id'],inplace = True, axis = 1)","66023043":"df_all_data.head(1)","07f27da1":"# X we will keep all columns execpt the last one \nX_train = np.expand_dims(df_all_data.values[:,:-1],axis = 2)\n# the last column is our label\ny_train = df_all_data.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(df_all_data.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)","8666b2b8":"model_one = Sequential()\nmodel_one.add(LSTM(units = 64,input_shape = (33,1)))\nmodel_one.add(Dropout(0.4))\nmodel_one.add(Dense(1))\n\nmodel_one.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nmodel_one.summary()","b4a5227b":"model_one.fit(X_train,y_train,batch_size = 4096,epochs = 10)","4302e30e":"# creating submission file \nsubmission_file = model_one.predict(X_test)\n# we will keep every value between 0 and 20\nsubmission_file = submission_file.clip(0,20)\n# creating dataframe with required columns \nsubmission = pd.DataFrame({'ID':df_test['ID'],'item_cnt_month':submission_file.ravel()})\nsubmission.to_csv(\"submission_xy.csv\",index=False)","99c3736e":"submission.head(1)","bf8d0509":"def download_csv( df, title = \"Download CSV file\", filename = \"submission_xy.csv\"):\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return FileLink(html)\n\ndf = pd.DataFrame(data = submission, columns=['ID', 'item_cnt_month'])\ndownload_csv(df)","1d47957e":"I can to see, that train has more than 14 times rows than test","f482f471":"Finally generated my csv with data:","4346fe5b":"Let's analize data ***sales_train***:","7fa3bd5e":"I can see outliers when the prices more than 300000, and when  sales per day over 2000, therefor, create a data set without this data","dd33361e":"Plot Item Prices versus Sales per day as markers, searching outliers:","a41cf676":"Getting Started\n\n\nI have learned that data science is not only aimed at systems engineers, it is for enthusiastic, creative people, and with a thirst for knowledge, data is currently a gold mine, you just have to learn how to exploit it. There are tools, tutorials, communities, so I'm very excited to start this my first project close to a real problem, so go ahead.\n\nMy plan scheduled in this notebook:\n\n* Understand the data delivered by competition, know data type\n* Do EDA\n* Pre-process given data set and generate new features from existing ones, new features that give courage to achieve the objective as required my challenge:\n    Numeric, categorical, datetime and coordinate features.\n* Make decisions about handling missing data or cleaning data\n* Find insights\n* See differents between test and train\n* Build models over dataset, make training and test\n* Use differents librarys for data plots, visualize the data\n* Create validations for models\n* Forecast the total amount of products sold in every shop for the test set\n* Create baseline and summit\n\nFirst, It is necesary import librarys, a few over of these:\n* *Numpy (linear algebra)*: It's to work with dimensional arrays, has useful routines and random number capabilities for linear algebra.\n* *Pandas*: It allows we to process data like to SQL. Your use is easy intuitive, flexible. \n* *Os*: It is a python's module, it provides functions for interacting with the operating system, and its file system.\n* *matplotlib*: It allows we to create a production-quality graphic, differents plots\n* *seaborn*: It allows we to create a differents plots. Built on top of matplotlib and designed for advanced statistical graphics.","57af8227":"I try to group by shop_id,item_id,month:","2909e9c4":"**Loading data provide of competition:**","a437dc8d":"Let's go to see missing values, NaN, null:","fe8b9755":"Let's knowledge of dataset:"}}