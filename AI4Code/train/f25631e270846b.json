{"cell_type":{"9eef7e44":"code","2d967b2e":"code","da482d4a":"code","c0eb67aa":"code","6ad9ffd2":"code","235fd546":"code","2b993ccc":"code","0e42a4b4":"code","26c55672":"code","0ab4b5c4":"code","d4a67a9c":"code","e80eed3a":"code","e4954b95":"code","6dd377fd":"code","076218dc":"code","89821696":"code","9efd374f":"code","84702cd3":"code","f3d3a6b5":"code","0a0f77fb":"code","68dabdcd":"code","e4266674":"code","e3666f97":"code","8c429ca2":"code","ee36557f":"code","38fb7dd3":"code","a64daa76":"code","656e2231":"code","fdbc33f5":"code","ec1601e6":"code","0620ddd6":"code","78b0bec8":"code","526a229a":"code","0e94558e":"code","7210b3a6":"code","08710f23":"code","909f47b5":"code","2200a871":"code","8a6480fd":"code","4cbd72c9":"code","72a4533b":"code","f33c9fba":"code","c1433119":"code","3e2f4a22":"code","adc5a74e":"code","54a6707b":"code","5244dce3":"code","81d5b3c5":"code","c0c93722":"code","0c0c8f4b":"code","6a46c6b1":"code","9246a5d2":"code","3c8dbffd":"code","7319af79":"code","31f53a2a":"code","33bc3ea6":"code","75de84e3":"code","1b08a37b":"code","398b599d":"code","0cba5763":"code","625c89cf":"code","99179740":"code","630e4c8a":"code","9ef1ce3a":"code","83b6613b":"code","358e24f4":"code","02ad32b2":"code","af526f52":"code","e972c26c":"code","ae56367a":"code","ab2f465d":"code","222cfc20":"code","278cd1f4":"code","4824ca75":"code","e3c10a7c":"code","7d4b9446":"code","c0ff32f2":"code","1dd56c28":"code","9e6bc8f5":"code","1fca8080":"code","7e14ccc1":"code","17102f01":"code","1a0f8fce":"code","412e12fd":"code","1cce2fa6":"code","47aa9da6":"code","4044ab41":"code","f31d910c":"code","f6d50ae2":"code","80e360cb":"code","cbbc484f":"code","b039e405":"code","d035f06a":"code","6c7be67b":"markdown","9a81b4ee":"markdown","ec41e642":"markdown","9106a0a6":"markdown","8a754d7f":"markdown","d8cd86b3":"markdown","bf7ca46e":"markdown","1b090ea5":"markdown","911b28db":"markdown","cfbde248":"markdown","ecd9291e":"markdown","77fc0231":"markdown","d47e4903":"markdown","492ebc63":"markdown","19dc1be0":"markdown","89e8978c":"markdown","79c49d41":"markdown","e2de9432":"markdown","058de0ea":"markdown","0c9859e7":"markdown","5b738459":"markdown","63ab0aba":"markdown","bc936d0c":"markdown","7354f4f5":"markdown","2343a458":"markdown","3691e84f":"markdown","b6f1aadc":"markdown","75517023":"markdown","68353c29":"markdown","2d9329d4":"markdown","c2d72361":"markdown","395da500":"markdown","56868e3d":"markdown","2e0220f0":"markdown","5b154d43":"markdown","37179336":"markdown","b8aeea38":"markdown","bdadbf0b":"markdown","4ee8400b":"markdown","b81a2240":"markdown","32292a3d":"markdown","52c302c2":"markdown","fd9df906":"markdown","53ab1068":"markdown","521cdb96":"markdown","1e76e343":"markdown","311724a4":"markdown","45f24f34":"markdown","f55fd4db":"markdown","294b3e78":"markdown","cccb8b65":"markdown","c99a7d2b":"markdown","c4607199":"markdown","c7d50523":"markdown","43a39618":"markdown","99847860":"markdown","b69fad3b":"markdown","57ff5b36":"markdown"},"source":{"9eef7e44":"#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","2d967b2e":"#All imports\nimport os\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport scipy\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn import metrics\n\nimport statsmodels.api as sm","da482d4a":"#list all the filenames\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c0eb67aa":"#Read the train data\ntrain_df = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain_df.head()","6ad9ffd2":"#Read the test data\ntest_df = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest_df.head()","235fd546":"#Store test Ids in a seperate column to be used for submission\ntrain_Ids = train_df.pop('Id')\ntest_Ids = test_df.pop('Id')\n\ntest_df['SalePrice'] = np.NaN","2b993ccc":"housing_all_df = pd.concat([train_df, test_df], axis = 0, ignore_index=True)\n\nprint (\"Train shape: \", train_df.shape)\nprint (\"Test shape: \", test_df.shape)\nprint (\"Combined shape: \", housing_all_df.shape)","0e42a4b4":"#Distribution of SalePrice column\nplt.figure(figsize=(10,4))\nsns.distplot(housing_all_df[~housing_all_df['SalePrice'].isnull()]['SalePrice'])\nplt.show()","26c55672":"#Visualization of Overall quality and SalePrice\nplt.figure(figsize=(6,4))\nsns.boxplot(x='OverallQual', y ='SalePrice', data=housing_all_df)\nplt.show()","0ab4b5c4":"#Visualization of SalePrice and AboveGradeLivingArea\nsns.scatterplot(x='GrLivArea', y= 'SalePrice', data = housing_all_df)\nplt.show()","d4a67a9c":"sns.scatterplot(x='GrLivArea', y= 'SalePrice', hue='OverallQual', data = housing_all_df)\nplt.show()","e80eed3a":"#As feature 'Utilities' has no variance,dropping column: Utilities\nhousing_all_df.drop(columns=['Utilities'], inplace = True)","e4954b95":"#checking the null count for each column\nnull_counts = housing_all_df.isnull().sum()\nnull_counts[null_counts.values > 0].index","6dd377fd":"#Impute MSZoning with mode values\nprint(\"Null count: \", housing_all_df['MSZoning'].isnull().sum())\nprint (housing_all_df['MSZoning'].value_counts())\n\nhousing_all_df['MSZoning'].fillna(housing_all_df['MSZoning'].mode().values[0], inplace = True)","076218dc":"#Impute PoolQC\nprint (\"Null count: \", housing_all_df['PoolQC'].isnull().sum())\nhousing_all_df['PoolQC'].value_counts()","89821696":"#Check if records have a valid PoolArea and still PoolQC is missing\nhousing_all_df[(housing_all_df['PoolQC'].isnull()) & (housing_all_df['PoolArea'] > 0)][['PoolArea','PoolQC','OverallQual']]","9efd374f":"#Check relation between PoolArea and PoolQC\nsns.boxplot(x='PoolQC', y='PoolArea', data=housing_all_df)\nplt.show()","84702cd3":"housing_all_df['PoolQC'].fillna(value='None', inplace=True)\nhousing_all_df['PoolQC'] = housing_all_df['PoolQC'].map({'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n\nhousing_all_df[housing_all_df.index == 2420]['PoolQC'] = 4\nhousing_all_df[housing_all_df.index == 2503]['PoolQC'] = 6\nhousing_all_df[housing_all_df.index == 2599]['PoolQC'] = 3","f3d3a6b5":"#Check impact of MiscFeature and MiscVal on SalePrice column\nsns.scatterplot(x='MiscVal',y='SalePrice',hue='MiscFeature',data=housing_all_df)\nplt.show()","0a0f77fb":"#As MiscFeature and MiscVal does not show any impact on SalePrice column, so dropping these features\nhousing_all_df.drop(columns=['MiscFeature','MiscVal'], inplace=True)","68dabdcd":"#Impute Alley with mode value\nprint (\"Null count: \", housing_all_df['Alley'].isnull().sum())\nprint (housing_all_df['Alley'].value_counts())\n\nhousing_all_df['Alley'].fillna(value='None', inplace = True)","e4266674":"#Impute Fence with mode value\nprint (\"Null count: \", housing_all_df['Fence'].isnull().sum())\nprint (housing_all_df['Fence'].value_counts())\n\nhousing_all_df['Fence'].fillna(value='None', inplace=True)","e3666f97":"#Impute FireplaceQu\nhousing_all_df['FireplaceQu'].fillna(value='None', inplace=True)","8c429ca2":"#Impute LotFrontage\ngrouped_by_neighborhood = housing_all_df.groupby('Neighborhood')\nlot_frontage_median = grouped_by_neighborhood['LotFrontage'].median()\nlot_frontage_substitute = housing_all_df['Neighborhood'].map(lot_frontage_median.to_dict())\nhousing_all_df['LotFrontage'] = lot_frontage_substitute.where(pd.isnull(housing_all_df['LotFrontage']), housing_all_df['LotFrontage'])","ee36557f":"housing_all_df['GarageYrBlt'] = housing_all_df['YearBuilt'].where(pd.isnull(housing_all_df['GarageYrBlt']), housing_all_df['GarageYrBlt'])\nhousing_all_df.loc[housing_all_df['GarageType'].isnull() & (housing_all_df['GarageArea'] == 0), 'GarageType'] = 'No Garage'\nhousing_all_df.loc[housing_all_df['GarageFinish'].isnull() & (housing_all_df['GarageArea'] == 0), 'GarageFinish'] = 'No Garage'\nhousing_all_df.loc[housing_all_df['GarageQual'].isnull() & (housing_all_df['GarageArea'] == 0), 'GarageQual'] = 'None'\nhousing_all_df.loc[housing_all_df['GarageCond'].isnull() & (housing_all_df['GarageArea'] == 0), 'GarageCond'] = 'None'","38fb7dd3":"#Check if any house with GarageQual and GarageCond missing\nhousing_all_df[(housing_all_df['GarageQual'].isnull()) | (housing_all_df['GarageCond'].isnull())][['GarageCars','GarageArea',\n                                'GarageType','GarageFinish','GarageQual','GarageCond']]","a64daa76":"#House with index 2576 indicates it does not have Garage and GarageType is Detchd because of erroneous data, \n#so fixing values to indicate there is no garage\nhousing_all_df.loc[housing_all_df.index==2576, 'GarageCars']= 0\nhousing_all_df.loc[housing_all_df.index==2576, 'GarageArea']= 0\nhousing_all_df.loc[housing_all_df.index==2576, 'GarageType']= 'No Garage'\nhousing_all_df.loc[housing_all_df.index==2576, 'GarageFinish']= 'No Garage'\nhousing_all_df.loc[housing_all_df.index==2576, 'GarageQual']= 'None'\nhousing_all_df.loc[housing_all_df.index==2576, 'GarageCond']= 'None'","656e2231":"#For rest of the cases, substituting mode values\nhousing_all_df.loc[housing_all_df['GarageFinish'].isnull(),'GarageFinish'] = housing_all_df['GarageFinish'].mode().values[0]\nhousing_all_df.loc[housing_all_df['GarageCond'].isnull(),'GarageCond'] = housing_all_df['GarageCond'].mode().values[0]\nhousing_all_df.loc[housing_all_df['GarageQual'].isnull(),'GarageQual'] = housing_all_df['GarageQual'].mode().values[0]","fdbc33f5":"#Impute Exterior1st\nprint(\"Null count: \", housing_all_df['Exterior1st'].isnull().sum())\nprint (housing_all_df['Exterior1st'].value_counts())\n\nhousing_all_df['Exterior1st'].fillna(value=housing_all_df['Exterior1st'].mode().values[0], inplace=True)","ec1601e6":"#Impute Exterior2nd\nprint(\"Null count: \",housing_all_df['Exterior2nd'].isnull().sum())\nprint (housing_all_df['Exterior2nd'].value_counts())\n\nhousing_all_df['Exterior2nd'].fillna(housing_all_df['Exterior2nd'].mode().values[0], inplace = True)","0620ddd6":"print (\"Null count: \", housing_all_df['MasVnrType'].isnull().sum())\nprint (housing_all_df['MasVnrType'].value_counts())\n\nhousing_all_df.loc[housing_all_df['MasVnrType'].isnull() & housing_all_df['MasVnrArea'].isnull(), 'MasVnrType'] = 'None'\nhousing_all_df.loc[housing_all_df['MasVnrType'].isnull() & housing_all_df['MasVnrArea'], 'MasVnrType'] = housing_all_df['MasVnrType'].mode().values[0]\n\nhousing_all_df['MasVnrArea'].fillna(value=0, inplace=True)","78b0bec8":"housing_all_df.loc[housing_all_df['TotalBsmtSF'].isnull(),'BsmtFinSF1'] = 0\nhousing_all_df.loc[housing_all_df['TotalBsmtSF'].isnull(),'BsmtFinSF2'] =0\nhousing_all_df.loc[housing_all_df['TotalBsmtSF'].isnull(),'BsmtUnfSF'] =0\nhousing_all_df.loc[housing_all_df['TotalBsmtSF'].isnull(),'BsmtFullBath'] =0\nhousing_all_df.loc[housing_all_df['TotalBsmtSF'].isnull(),'BsmtHalfBath'] =0\nhousing_all_df.loc[housing_all_df['TotalBsmtSF'].isnull(),'TotalBsmtSF'] =0","526a229a":"housing_all_df.loc[(housing_all_df['TotalBsmtSF'] == 0) & (housing_all_df['BsmtQual'].isnull()), 'BsmtQual'] = 'None'\nhousing_all_df.loc[(housing_all_df['TotalBsmtSF'] == 0) & (housing_all_df['BsmtCond'].isnull()), 'BsmtCond'] = 'None'\nhousing_all_df.loc[(housing_all_df['TotalBsmtSF'] == 0) & (housing_all_df['BsmtExposure'].isnull()), 'BsmtExposure'] = 'None'\nhousing_all_df.loc[(housing_all_df['TotalBsmtSF'] == 0) & (housing_all_df['BsmtFinType1'].isnull()), 'BsmtFinType1'] = 'None'\nhousing_all_df.loc[(housing_all_df['TotalBsmtSF'] == 0) & (housing_all_df['BsmtFinType2'].isnull()), 'BsmtFinType2'] = 'None'","0e94558e":"housing_all_df.loc[housing_all_df['BsmtQual'].isnull(), 'BsmtQual'] = housing_all_df['BsmtQual'].mode().values[0]\nhousing_all_df.loc[housing_all_df['BsmtCond'].isnull(), 'BsmtCond'] = housing_all_df['BsmtCond'].mode().values[0]\nhousing_all_df.loc[housing_all_df['BsmtExposure'].isnull(), 'BsmtExposure'] = housing_all_df['BsmtExposure'].mode().values[0]\nhousing_all_df.loc[housing_all_df['BsmtFinType2'].isnull(), 'BsmtFinType2'] = housing_all_df['BsmtFinType2'].mode().values[0]\nhousing_all_df.loc[housing_all_df['BsmtFullBath'].isnull(), 'BsmtFullBath'] = 0\nhousing_all_df.loc[housing_all_df['BsmtHalfBath'].isnull(), 'BsmtHalfBath'] = 0","7210b3a6":"#Impute Electrical\nprint(\"Null counts: \" , housing_all_df['Electrical'].isnull().sum())\nprint (housing_all_df['Electrical'].value_counts())\n\nhousing_all_df['Electrical'].fillna(housing_all_df['Electrical'].mode().values[0], inplace=True)","08710f23":"#Impute kitchenQual\nprint(\"Null count: \" , housing_all_df['KitchenQual'].isnull().sum())\nprint (housing_all_df['KitchenQual'].value_counts())\n\nhousing_all_df['KitchenQual'].fillna(housing_all_df['KitchenQual'].mode().values[0], inplace=True)","909f47b5":"#Impute Functional\nprint(\"Null count: \", housing_all_df['Functional'].isnull().sum())\nprint (housing_all_df['Functional'].value_counts())\n\nhousing_all_df['Functional'].fillna(housing_all_df['Functional'].mode().values[0], inplace = True)","2200a871":"#Impute SaleType\nprint(\"Null count: \", housing_all_df['SaleType'].isnull().sum())\nprint (housing_all_df['SaleType'].value_counts())\n\nhousing_all_df['SaleType'].fillna(housing_all_df['SaleType'].mode().values[0], inplace=True)","8a6480fd":"#Compute TotalBathroom from all types of bathrooms\nhousing_all_df['TotalBath'] = housing_all_df['FullBath'] + housing_all_df['HalfBath'] * 0.5 + housing_all_df['BsmtFullBath'] + housing_all_df['BsmtHalfBath']*0.5\n\nsns.boxplot(x='TotalBath', y ='SalePrice', data = housing_all_df[~housing_all_df['SalePrice'].isnull()])\nplt.show()","4cbd72c9":"housing_all_df['IsRemod'] = np.where(housing_all_df['YearBuilt'] == housing_all_df['YearRemodAdd'], 0,1)\nhousing_all_df['Age'] = housing_all_df['YrSold'] - housing_all_df['YearRemodAdd']\n                                                                  \nsns.scatterplot(x='Age', y='SalePrice', data = housing_all_df[~housing_all_df['SalePrice'].isnull()])\nplt.show()\n                                                                  \nsns.boxplot(x='IsRemod', y='SalePrice', data = housing_all_df[~housing_all_df['SalePrice'].isnull()])\nplt.show()\n                                                                  \nhousing_all_df['IsNew'] = np.where(housing_all_df['YearBuilt'] == housing_all_df['YrSold'], 0, 1)\n                                                                  \nsns.boxplot(x='IsNew', y='SalePrice', data = housing_all_df[~housing_all_df['SalePrice'].isnull()])\nplt.show()                                                             ","72a4533b":"#Relation of GrLivArea with SalePrice\nsns.scatterplot(x='GrLivArea', y='SalePrice', data=housing_all_df[~housing_all_df['SalePrice'].isnull()])\nplt.show()\n\nhousing_all_df[['GrLivArea','SalePrice']].corr()","f33c9fba":"#Relation of TotalBasementArea with SalePrice\nsns.scatterplot(x='TotalBsmtSF', y='SalePrice', data=housing_all_df[~housing_all_df['SalePrice'].isnull()])\nplt.show()\n\nhousing_all_df[['SalePrice','TotalBsmtSF']].corr()","c1433119":"housing_all_df['TotalArea'] = housing_all_df['GrLivArea'] + housing_all_df['TotalBsmtSF']\n\nsns.scatterplot(x='TotalArea', y='SalePrice', data=housing_all_df)\nplt.show()\n\nhousing_all_df[['TotalArea','SalePrice']].corr()","3e2f4a22":"#Compute TotalPorchArea by combining all the PorchArea and their relation with SalePrice\nhousing_all_df['TotalPorchArea'] = housing_all_df['OpenPorchSF'] + housing_all_df['EnclosedPorch'] + housing_all_df['3SsnPorch'] + housing_all_df['ScreenPorch']\n\nsns.scatterplot(x='TotalPorchArea', y='SalePrice',data=housing_all_df[~housing_all_df['SalePrice'].isnull()])\nplt.show()\n\nhousing_all_df[['TotalPorchArea', 'SalePrice']].corr()","adc5a74e":"numerical_cols = housing_all_df.select_dtypes(include='number').columns.tolist()\nnumerical_cols = [col for col in numerical_cols if col not in ['MSSubClass', 'OverallQual','OverallCond','PoolQC','MoSold']]\nhousing_corr = housing_all_df[numerical_cols].corr()","54a6707b":"high_corr_matrix = housing_corr[abs(housing_corr.loc[:,:]) >= 0.5]\nhigh_corr_matrix.to_csv('.\/correlations.csv')","5244dce3":"cols_to_drop = ['GarageYrBlt','YearRemodAdd','1stFlrSF','TotalBsmtSF','TotRmsAbvGrd','GrLivArea','GarageArea']\nhousing_all_df.drop(columns=cols_to_drop, inplace=True)","81d5b3c5":"#Houses with higher GrLivArea, lower SalePrice but higher Overall house quality\ntrain_df[train_df['OverallQual'] == 10][['GrLivArea', 'SalePrice']].sort_values('GrLivArea', ascending=False)","c0c93722":"#dropping the houses with index 1298 and 523\nhousing_all_df.drop(index=[523,1298], inplace=True)","0c0c8f4b":"numerical_cols = housing_all_df.select_dtypes(include='number').columns.tolist()\nnumerical_cols = [col for col in numerical_cols if col not in ['MSSubClass','OverallQual','OverallCond','PoolQC','MoSold','SalePrice','IsRemod','IsNew','YearBuilt','YrSold']]\n\n#treat skewness of numerical columns\nfor col in numerical_cols:\n    skew_val = scipy.stats.skew(housing_all_df[col])\n    if abs(skew_val) > 0.8:\n        housing_all_df[col] = np.log(housing_all_df[col] + 1)    ","6a46c6b1":"#For features with categories having implicit ordering, assigning them incremental numeric values\nfor col in ['FireplaceQu', 'ExterQual', 'ExterCond', 'BsmtQual','BsmtCond','KitchenQual','GarageQual','GarageCond','HeatingQC']:\n    housing_all_df[col] = housing_all_df[col].map({'None':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n    \nhousing_all_df['BsmtExposure'] = housing_all_df['BsmtExposure'].map({'None':0,'No':1,'Mn':2,'Av':3,'Gd':4})\n\nfor col in ['BsmtFinType1','BsmtFinType2']:\n    housing_all_df[col] = housing_all_df[col].map({'None':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6})\n    \nhousing_all_df['GarageFinish'] = housing_all_df['GarageFinish'].map({'No Garage':0,'Unf':1,'RFn':2,'Fin':3})","9246a5d2":"#Check if MasVnrType has any ranking by considering its impact on SalePrice\nsns.boxplot(x='MasVnrType', y = 'SalePrice', data=housing_all_df)\nplt.show()\n\nhousing_all_df['MasVnrType'] = housing_all_df['MasVnrType'].map({'None':0, 'BrkCmn':0, 'BrkFace':1, 'Stone':2}) ","3c8dbffd":"#Check if feature 'Functional' has any ranking by considering its impact on SalePrice\nsns.boxplot(x='Functional', y = 'SalePrice', data=housing_all_df)\nplt.show()\n\nhousing_all_df['Functional'] = housing_all_df['Functional'].map({'Sal':0,'Sev':1,'Maj2':2,'Maj1':3,'Mod':4,'Min2':5,\n                                                                 'Min1':6,'Typ':7}) ","7319af79":"#Determine the neighborhood categories that can be combined by checking their average and median sale prices\ngroupd_by_neighborhood = housing_all_df[~housing_all_df['SalePrice'].isnull()].groupby('Neighborhood')\nneighborhood_median_prices = groupd_by_neighborhood['SalePrice'].median()\nneighborhood_median_prices = neighborhood_median_prices.sort_values()\n\nneighborhood_mean_prices = groupd_by_neighborhood['SalePrice'].mean()\nneighborhood_mean_prices = neighborhood_mean_prices.sort_values()","31f53a2a":"#plot of neighboorhood median prices\nplt.figure(figsize=(12,6))\nsns.barplot(x=neighborhood_median_prices.index, y = neighborhood_median_prices.values)\nplt.xticks(rotation=45)\nplt.show()","33bc3ea6":"#plot of neighborhood average prices\nplt.figure(figsize=(12,6))\nsns.barplot(x=neighborhood_mean_prices.index, y = neighborhood_mean_prices.values)\nplt.xticks(rotation=45)\nplt.show()","75de84e3":"#Combining the categories and assigning them incremental values to indicate ordering\nhousing_all_df.loc[~housing_all_df['Neighborhood'].isin(['StoneBr','NridgHt','NoRidge','MeadowV','IDOTRR','BrDale']), 'Neighborhood'] = 1\nhousing_all_df.loc[housing_all_df['Neighborhood'].isin(['StoneBr','NridgHt','NoRidge']), 'Neighborhood'] = 2\nhousing_all_df.loc[housing_all_df['Neighborhood'].isin(['MeadowV','IDOTRR','BrDale']), 'Neighborhood'] = 0","1b08a37b":"housing_all_df['Neighborhood'] = housing_all_df['Neighborhood'].astype(int)","398b599d":"all_dummies = []\ncat_cols = housing_all_df.select_dtypes(include='object').columns.tolist()\ncat_cols.extend(['MSSubClass', 'MoSold','YrSold'])\nfor col in cat_cols:\n    dummies = pd.get_dummies(housing_all_df[col], prefix=col, prefix_sep='_', drop_first=True)\n    for dum_col in dummies.columns.tolist():\n        if dummies[dum_col].sum() < 10:\n            print (\"Dummy: {0} has less than 10 records\".format(dum_col))\n            dummies.drop(columns=[dum_col], inplace =True)\n    all_dummies.extend(dummies)\n    housing_all_df.drop(columns=col, inplace=True)\n    housing_all_df = pd.concat([housing_all_df, dummies], axis=1)","0cba5763":"housing_train_df = housing_all_df[~housing_all_df['SalePrice'].isnull()]\nhousing_test_df = housing_all_df[housing_all_df['SalePrice'].isnull()]\n\nprint (\"Train data: \", housing_train_df.shape)\nprint (\"Test data: \", housing_test_df.shape)","625c89cf":"housing_train_df['SalePrice_log'] = np.log(housing_train_df['SalePrice'])\n\nsns.distplot(housing_train_df['SalePrice_log'])\nplt.show()","99179740":"X = housing_train_df.drop(columns=['SalePrice', 'SalePrice_log'])\ny = housing_train_df['SalePrice_log']\n\n#split the training data into train and test set. This test set will be used as validation data\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state = 100)","630e4c8a":"#A custom function to be used for scoring\ndef root_mean_squared_error(actual, predicted):\n    return np.sqrt(metrics.mean_squared_error(actual,predicted))\n\ncustom_scorer = metrics.make_scorer(root_mean_squared_error, greater_is_better = False)","9ef1ce3a":"#Custom function to perform GridSearchCV with 5 folds and rmse scoring mechanism.\ndef grid_search_cv(params, model, X_train, y_train, X_test, y_test):\n    folds = 5\n    \n    #perform GridSearchCV\n    model_cv = GridSearchCV(estimator = model,\n                        param_grid = params,\n                        scoring = custom_scorer,                        \n                        cv = folds,\n                        verbose = True,\n                        return_train_score = True,\n                        n_jobs=-1)\n\n    model_cv.fit(X_train, y_train)    \n    print (\"Best score: \", model_cv.best_score_)\n    print (\"Best params: \", model_cv.best_params_)\n    y_test_pred = model_cv.best_estimator_.predict(X_test)\n    print (\"Test score: \", root_mean_squared_error(y_test, y_test_pred))","83b6613b":"#regularization coefficient alpha to tune\nparams = {'model__alpha' : [0.0001, 0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.5, 1, 2, \n                    5, 10, 50]}\n    \n#model to be used\nlasso = Pipeline([('scaler',RobustScaler()), ('model',Lasso(random_state = 100, normalize=True))])\n\n#Invoke GridSearchCV\ngrid_search_cv(params, lasso, X_train, y_train, X_test, y_test)","358e24f4":"lasso_final = Pipeline([('scaler', RobustScaler()), ('model', Lasso(random_state=100, alpha=0.0001, normalize=True))])\nlasso_final.fit(X, y)\n\ny_pred = lasso_final.predict(X)\nprint (\"Lasso rmse: \", root_mean_squared_error(y, y_pred))","02ad32b2":"#regularization coefficient alpha to tune\nparams = {'model__alpha' : [0.0001, 0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.5, 1, 2, \n                    5, 10, 50]}\n    \n#model to be used\nridge = Pipeline([('scaler',RobustScaler()), ('model',Ridge(random_state = 100, normalize=True))])\n\n#Invoke GridSearchCV\ngrid_search_cv(params, ridge, X_train, y_train, X_test, y_test)","af526f52":"ridge_final = Pipeline([('scaler',RobustScaler()), ('model',Ridge(random_state=100, alpha =0.04, normalize=True))])\nridge_final.fit(X, y)\n\ny_pred = ridge_final.predict(X)\nprint (\"Ridge rmse: \", root_mean_squared_error(y, y_pred))","e972c26c":"xgb = XGBRegressor(random_state=100, learning_rate=0.1,max_depth=5, min_child_weight=1,subsample=0.8,\n                  colsample_by_tree=0.8)\nhyper_params = {'n_estimators':[50,100,200]}\n\ngrid_search_cv(hyper_params, xgb, X_train, y_train, X_test, y_test)","ae56367a":"xgb = XGBRegressor(random_state=100, learning_rate=0.1,max_depth=5, min_child_weight=1,subsample=0.8,\n                  colsample_by_tree=0.8)\nhyper_params = {'n_estimators':[250,300,350]}\n\ngrid_search_cv(hyper_params, xgb, X_train, y_train, X_test, y_test)","ab2f465d":"xgb = XGBRegressor(random_state=100, learning_rate=0.1,n_estimators=200, subsample=0.8,\n                  colsample_by_tree=0.8)\nhyper_params = {'max_depth':range(3,10,2), 'min_child_weight':range(1,9,2)}\n\ngrid_search_cv(hyper_params, xgb, X_train, y_train, X_test, y_test)","222cfc20":"xgb = XGBRegressor(random_state=100, learning_rate=0.1,n_estimators=200, max_depth=3, min_child_weight=5,\n                   subsample=0.8,colsample_by_tree=0.8)\nhyper_params = {'gamma':[0,0.1,0.2,0.3,0.4,0.5]}\n\ngrid_search_cv(hyper_params, xgb, X_train, y_train, X_test, y_test)","278cd1f4":"xgb = XGBRegressor(random_state=100, learning_rate=0.1, n_estimators=200, max_depth=3, min_child_weight=5,\n                   gamma = 0)\nhyper_params = {'subsample':[0.6,0.7,0.8,0.9], 'colsample_by_tree':[0.6,0.7,0.8,0.9]}\n\ngrid_search_cv(hyper_params, xgb, X_train, y_train, X_test, y_test)","4824ca75":"xgb = XGBRegressor(random_state=100, learning_rate=0.1, n_estimators=200, max_depth=3, min_child_weight=5,\n                   gamma = 0, subsample=0.8, colsample_by_tree=0.6)\nhyper_params = {'reg_alpha':[0.0001,0.001,0.01,0.1,1,10]}\n\ngrid_search_cv(hyper_params, xgb, X_train, y_train, X_test, y_test)","e3c10a7c":"xgb = XGBRegressor(random_state=100, learning_rate=0.1, n_estimators=200, max_depth=3, min_child_weight=5,\n                   gamma = 0, subsample=0.8, colsample_by_tree=0.6,reg_alpha=0.001)\nhyper_params = {'reg_lambda':[0.0001,0.001,0.01,0.1,1,10]}\n\ngrid_search_cv(hyper_params, xgb, X_train, y_train, X_test, y_test)","7d4b9446":"xgb = XGBRegressor(random_state=100, learning_rate=0.1, n_estimators=200, max_depth=3, min_child_weight=5,\n                   gamma = 0, subsample=0.8, colsample_by_tree=0.6,reg_alpha=0.001, reg_lambda=1)\nxgb.fit(X,y)\n\ny_pred = xgb.predict(X)\nprint (\"Train error: \", root_mean_squared_error(y, y_pred))","c0ff32f2":"xgb = XGBRegressor(random_state=100, learning_rate=0.05, n_estimators=400, max_depth=3, min_child_weight=5,\n                   gamma = 0, subsample=0.8, colsample_by_tree=0.6,reg_alpha=0.001, reg_lambda=1)\nxgb.fit(X,y)\n\ny_pred = xgb.predict(X)\nprint (\"Train error: \", root_mean_squared_error(y, y_pred))","1dd56c28":"xgb = XGBRegressor(random_state=100, learning_rate=0.01, n_estimators=2000, max_depth=3, min_child_weight=5,\n                   gamma = 0, subsample=0.8, colsample_by_tree=0.6,reg_alpha=0.001, reg_lambda=1)\nxgb.fit(X,y)\n\ny_pred = xgb.predict(X)\nprint (\"Train error: \", root_mean_squared_error(y, y_pred))","9e6bc8f5":"xgb_final = XGBRegressor(random_state=100, learning_rate=0.01, n_estimators=2000, max_depth=3, min_child_weight=5,\n                   gamma = 0, subsample=0.8, colsample_by_tree=0.6,reg_alpha=0.001, reg_lambda=1)\nxgb_final.fit(X,y)\n\ny_pred = xgb_final.predict(X)\nprint (\"XGBRegressor rmse: \", root_mean_squared_error(y, y_pred))","1fca8080":"elastic_net = Pipeline([('scaler',RobustScaler()), ('model',ElasticNet(random_state=100, normalize=True))])\nhyper_params = [{'model__alpha':[0.0001, 0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.5, 1, 2, \n                    5, 10, 50], 'model__l1_ratio':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}]\n\ngrid_search_cv(hyper_params, elastic_net, X_train, y_train, X_test, y_test)","7e14ccc1":"elastic_net_final = Pipeline([('scaler',RobustScaler()), \n                              ('model',ElasticNet(random_state=100, normalize=True, alpha=0.0001, l1_ratio=0.9))])\nelastic_net_final.fit(X, y)\n\ny_pred = elastic_net_final.predict(X)\nprint (\"ElasticNet rmse: \", root_mean_squared_error(y, y_pred))","17102f01":"grb = GradientBoostingRegressor(random_state=100, learning_rate=0.1,subsample=0.8,min_samples_split=150,\n                               min_samples_leaf=50, max_depth=5,max_features='sqrt')\nhyper_params = {'n_estimators':[50,150,200,250,300,350,400]}\n\ngrid_search_cv(hyper_params, grb, X_train, y_train, X_test, y_test)","1a0f8fce":"grb = GradientBoostingRegressor(random_state=100, learning_rate=0.1, n_estimators=350, subsample=0.8,\n                                min_samples_leaf=50, max_features='sqrt')\nhyper_params = {'max_depth':range(3,16,2), 'min_samples_split':range(150,300,50)}\n\ngrid_search_cv(hyper_params, grb, X_train, y_train, X_test, y_test)","412e12fd":"grb = GradientBoostingRegressor(random_state=100, learning_rate=0.1, n_estimators=350, max_depth=5, \n                                min_samples_split=150, subsample=0.8, max_features='sqrt')\nhyper_params = {'min_samples_leaf': range(50,101,10)}\n\ngrid_search_cv(hyper_params, grb, X_train, y_train, X_test, y_test)","1cce2fa6":"grb = GradientBoostingRegressor(random_state=100, learning_rate=0.1, n_estimators=350, max_depth=5, \n                                min_samples_split=150, min_samples_leaf=50, max_features='sqrt')\n\nhyper_params = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\ngrid_search_cv(hyper_params, grb, X_train, y_train, X_test, y_test)","47aa9da6":"grb = GradientBoostingRegressor(random_state=100, learning_rate=0.1, n_estimators=350, max_depth=5, \n                                min_samples_split=150, min_samples_leaf=50, max_features='sqrt', subsample=0.75)\n\ngrb.fit(X, y)\ny_pred = grb.predict(X)\nprint (\"grb rmse: \", root_mean_squared_error(y, y_pred))","4044ab41":"grb = GradientBoostingRegressor(random_state=100, learning_rate=0.05, n_estimators=700, max_depth=5, \n                                min_samples_split=150, min_samples_leaf=50, max_features='sqrt', subsample=0.75)\n\ngrb.fit(X, y)\ny_pred = grb.predict(X)\nprint (\"grb rmse: \", root_mean_squared_error(y, y_pred))","f31d910c":"grb = GradientBoostingRegressor(random_state=100, learning_rate=0.01, n_estimators=3500, max_depth=5, \n                                min_samples_split=150, min_samples_leaf=50, max_features='sqrt', subsample=0.75)\n\ngrb.fit(X, y)\ny_pred = grb.predict(X)\nprint (\"grb rmse: \", root_mean_squared_error(y, y_pred))","f6d50ae2":"grb_final = GradientBoostingRegressor(random_state=100, learning_rate=0.01, n_estimators=3500, max_depth=5, \n                                min_samples_split=150, min_samples_leaf=50, max_features='sqrt', subsample=0.75)\n\ngrb_final.fit(X, y)\ny_pred = grb_final.predict(X)\nprint (\"grb rmse: \", root_mean_squared_error(y, y_pred))","80e360cb":"stacked = StackingCVRegressor(regressors=(lasso_final, ridge_final, elastic_net_final, grb_final), \n                              meta_regressor=xgb_final, use_features_in_secondary=True)\nstacked.fit(X, y)\ny_pred = stacked.predict(X)\nprint (\"StackingCVRegressor rmse: \", root_mean_squared_error(y, y_pred))","cbbc484f":"def get_blended_predictions(df):\n    return (\n                (0.05 * lasso_final.predict(df)) +                \n                (0.05 * ridge_final.predict(df)) +\n                (0.05 * elastic_net_final.predict(df)) +\n                (0.15 * grb_final.predict(df)) + \n                (0.25 * xgb_final.predict(df)) +                \n                (0.45 * stacked.predict(df)) \n           )","b039e405":"y_pred = get_blended_predictions(X)\nprint (\"Blended model rmse: \", root_mean_squared_error(y, y_pred))","d035f06a":"housing_test_df.pop('SalePrice')\nhousing_test_pred = get_blended_predictions(housing_test_df)\n\nhousing_test_submission = pd.DataFrame()\nhousing_test_submission['Id'] = test_Ids\nhousing_test_submission['SalePrice'] = np.exp(housing_test_pred)\nhousing_test_submission.to_csv('.\/submission.csv', index=False)","6c7be67b":"**Fix learning rate to 0.1 and other tree parameters to default values to determine n_estimators**","9a81b4ee":"**As PoolArea and PoolQC does not show a direct relation, so: <br>- Houses with PoolArea but missing PoolQC will be subtituted with OverallQuality rating of the house<br>- Rest of the houses with PoolQC mising are the ones with PoolArea as 0, so substituting 'None', indicating no Pool in the house**","ec41e642":"### Outlier treatment","9106a0a6":"### Step 5 - Predictions on test data set","8a754d7f":"**Making a final ridge final model with tuned parameters**","d8cd86b3":"**Impute MasVnrType and MasVnrArea: <br><br>- Houses where MasVnrArea is 0, substituting MasVnrType as None. <br>- Houses with valid MasVnrArea, substituting them with mode values.<br>- Houses with missing MasVnrArea, substituting them with 0 value**","bf7ca46e":"**Concatenate train and test dataset for data cleaning and preparation**","1b090ea5":"**Trying a learning rate of half 0.05 and doubling n_estimators proportionally to 700**","911b28db":"### Data Visualization","cfbde248":"### Model 3 - XGBoostRegressor","ecd9291e":"## Step 1 - Data Reading and Understanding","77fc0231":"**Making a final elastic net model**","d47e4903":"**YearBuilt and GarageYrBlt has correlation of 0.85<br>Age and YearRemodAdd has a correlation has -0.99<br>1stFlrSF and TotalBsmtSF has a correlation of 0.80<br>TotalArea and TotalBsmtSF has a correlation of 0.82<br>TotalRoomsAbvGrd and GrLivArea has a correlation of 0.80<br>TotalArea and GrLivArea has a correlation of 0.87<br>GarageCars and GarageArea has a correlation of 0.88**","492ebc63":"**SalePrice shows a direct relation with Overall quality of the house. Higher is the overall quality, appreciation of house prices can be seen**","19dc1be0":"**Fix SalePrice distribution - Perform log transformation to treat right skewed feature**","89e8978c":"**Compute TotalArea with above ground living area and basement area and correlation of SalePrice with TotalArea**","79c49d41":"**Tune subsample and colsample_by_tree**","e2de9432":"**Convert nominal categories into dummies using one-hot encoding**","058de0ea":"### Feature Engineering","0c9859e7":"### Model 7 - ensemble\/blending","5b738459":"**Compute:<br><br> IsRemod - Indicating if house is renovated.<br>Age - Indicating how many years house is with an owner after renovation\/built.<br> IsNew - Indicating house is not sold yet after construction or if its a new property**","63ab0aba":" ### Null value Imputation","bc936d0c":"**Combining neighborhood categories**","7354f4f5":"**Split data back to train and test for modelling**","2343a458":"### Model 4 - Elastic Net Regression","3691e84f":"**Making a model with above tuned parameters**","b6f1aadc":"**Considering the above parameters and make a final model**","75517023":"**Fix learning rate and tree parameters for tuning of n_estimators**","68353c29":"## Step 2 - Data Visualization and Cleaning","2d9329d4":"### Skewness treatment of numerical columns","c2d72361":"### Model 2 - Ridge Regression","395da500":"**General trend seems to be - higher the GrLivArea, higher is the SalePrice with a couple of outliers. These outliers have higher GrLivArea but SalePrice is low even though these houses have higher OverallQuality**","56868e3d":"**Higher the number of TotalBath in the house, better is the price appreciation**","2e0220f0":"## Problem Statement: House price prediction on a dataset using Sacked Regression and model ensemble","5b154d43":"**Tune min_samples_leaf**","37179336":"**Trying a learning rate of 0.01 and n_estimators to 3500**","b8aeea38":"**Keeping learning rate to 0.1 and n_estimators to 200, tune tree parameters**","bdadbf0b":"**Tune max_depth and min_samples_split**","4ee8400b":"**Check correlations amongst numerical columns and drop the ones with high correlation**","b81a2240":"### Data Cleaning","32292a3d":"**Trying a lower learning rate 0.05 and increasing the number of estimators to 400 proportionally**","52c302c2":"**Building a model with above tuned parameters**","fd9df906":"## Step 4 - Model building","53ab1068":"**Tune regularization parameter alpha**","521cdb96":"**Tuning subsample**","1e76e343":"**Making a final model of Gradient Boosting Regressor**","311724a4":"### Model 6 - StackingCVRegressor","45f24f34":"## Approach:\n**=> Data Reading and Understanding<br>\n=> Data Cleaning (Data Visualization, Null value treatment, Outlier treatment)<br>\n=> Data Preparation (Converting categorical variables to numeric variables, Scaling)<br>\n=> Model Building and Evaluation<br>\n=> Predictions on test set**","f55fd4db":"**Target column is certainly right skewed and will require transformation to fit linear regression**","294b3e78":"**Tune regularization parameter lambda**","cccb8b65":"**Tune gamma**","c99a7d2b":"### Model 5 - Gradient Boosting Regressor","c4607199":"## Step 3 - Data preparation","c7d50523":"**Houses have a pool but their PoolQC is missing. This is certainly a miss and missing values should be imputed.**","43a39618":"**Making a final lasso model with tuned parameters**","99847860":"**Impute GarageVariables<br>-Houses where GarageArea is 0 indicates NoGarage, so substituting 'No Garage' and 'None' for GarageQuality and GarageCondition**","b69fad3b":"### Model 1 - Lasso Regression","57ff5b36":"**Impute Basement variables:<br><br>- Houses with missing TotalBsmtSF or TotalBsmtSF as 0, substituting Basement related variables with None indicating there is no basement. <br> - For rest of the houses with Basement, substituting basement related variables with mode values**"}}