{"cell_type":{"4b3feefa":"code","78b6d237":"code","26d53891":"code","e8229651":"code","d23b8a2f":"code","fe7acdbe":"code","7b81e286":"code","c3d1b032":"code","baf8fd8a":"code","e710d4ad":"code","ec6f91a8":"code","ef053b97":"code","3c957dd0":"code","11f94879":"code","22865ccc":"code","5616b320":"code","1ee88deb":"code","a0c41383":"code","5ea1a23d":"code","5b44bc41":"code","44fa8779":"code","cb457e34":"code","aa569463":"code","e76436f0":"code","44687c51":"code","b0f604a3":"code","3b76bab3":"code","626de069":"code","35f19aae":"markdown","4f883818":"markdown"},"source":{"4b3feefa":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15,15\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import train_test_split,StratifiedShuffleSplit,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score,accuracy_score ,confusion_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.combine import SMOTETomek\nfrom imblearn.under_sampling import ClusterCentroids , NearMiss\n\nfrom tqdm.notebook import tqdm ,tnrange","78b6d237":"train_data = pd.read_csv('..\/input\/healthcareanalyticsii\/train.csv')\ntest_data = pd.read_csv('..\/input\/healthcareanalyticsii\/test.csv')","26d53891":"print(train_data.shape)\ntrain_data.head()","e8229651":"print(test_data.shape)\ntest_data.head()","d23b8a2f":"def nullColumns(train_data):\n    list_of_nullcolumns =[]\n    for column in train_data.columns:\n        total= train_data[column].isna().sum()\n        try:\n            if total !=0:\n                print('Total Na values is {0} for column {1}' .format(total, column))\n                list_of_nullcolumns.append(column)\n        except:\n            print(column,\"-----\",total)\n    print('\\n')\n    return list_of_nullcolumns\n\n\ndef percentMissingFeature(data):\n    data_na = (data.isnull().sum() \/ len(data)) * 100\n    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n    return data_na\n\n\ndef plotMissingFeature(data_na):\n    f, ax = plt.subplots(figsize=(15, 12))\n    plt.xticks(rotation='90')\n    if(data_na.empty ==False):\n        sns.barplot(x=data_na.index, y=data_na)\n        plt.xlabel('Features', fontsize=15)\n        plt.ylabel('Percent of missing values', fontsize=15)\n        plt.title('Percent missing data by feature', fontsize=15)","fe7acdbe":"print('train data')\nprint(nullColumns(train_data))\nprint(percentMissingFeature(train_data))\nprint('\\n')\nprint('test_data')\nprint(nullColumns(test_data))\nprint(percentMissingFeature(test_data))","7b81e286":"stay = train_data.loc[:,\"Stay\"].value_counts().rename('Count')\nplt.xlabel(\"Stay\")\nplt.ylabel('Count')\nsns.barplot(stay.index , stay.values).set_title('Stay')","c3d1b032":"sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n\nf, axes = plt.subplots(3, 2, figsize=(15, 15))\n\nradiotherapy = train_data[train_data.Department =='radiotherapy'][\"Stay\"].value_counts().rename('Count')\n\nanesthesia = train_data[train_data.Department =='anesthesia'][\"Stay\"].value_counts().rename('Count')\n\ngynecology = train_data[train_data.Department =='gynecology'][\"Stay\"].value_counts().rename('Count')\n\nsurgery = train_data[train_data.Department =='surgery'][\"Stay\"].value_counts().rename('Count')\n\ntb = train_data[train_data.Department =='TB & Chest disease'][\"Stay\"].value_counts().rename('Count')\n\nsns.barplot(radiotherapy.index,radiotherapy,  color=\"b\", ax=axes[0, 0]).set_title('Department : radiotherapy')\n\nsns.barplot(anesthesia.index,anesthesia,   color=\"r\", ax=axes[0, 1]).set_title('Department : anesthesia')\n\nsns.barplot(gynecology.index,gynecology,  color=\"g\", ax=axes[1, 0]).set_title('Department : gynecology')\n\nsns.barplot(surgery.index,surgery, color=\"m\", ax=axes[1, 1]).set_title('Department : surgery')\n\nsns.barplot(tb.index,tb, color=\"m\", ax=axes[2, 0]).set_title('Department : TB & Chest disease')\n\nsns.barplot(stay.index,stay, color=\"m\", ax=axes[2, 1]).set_title('Department : ALL')\n\nplt.xlabel(\"Stay\")\n\nplt.setp(axes,yticks = np.arange(0,50000,5000))\n\nfor ax in f.axes:\n    \n    plt.sca(ax)\n    \n    plt.xticks(rotation=45)\n\nplt.tight_layout()\n","baf8fd8a":"sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n\nf, axes = plt.subplots(6, 2, figsize=(15, 15))\n\nstay0 = train_data[train_data.Stay =='0-10'][\"Department\"].value_counts().rename('Count')\n\nstay1 = train_data[train_data.Stay =='11-20'][\"Department\"].value_counts().rename('Count')\n\nstay2 = train_data[train_data.Stay =='21-30'][\"Department\"].value_counts().rename('Count')\n\nstay3 = train_data[train_data.Stay =='31-40'][\"Department\"].value_counts().rename('Count')\n\nstay4 = train_data[train_data.Stay =='41-50'][\"Department\"].value_counts().rename('Count')\n\nstay5 = train_data[train_data.Stay =='51-60'][\"Department\"].value_counts().rename('Count')\n\nstay6 = train_data[train_data.Stay =='61-70'][\"Department\"].value_counts().rename('Count')\n\nstay7 = train_data[train_data.Stay =='71-80'][\"Department\"].value_counts().rename('Count')\n\nstay8 = train_data[train_data.Stay =='81-90'][\"Department\"].value_counts().rename('Count')\n\nstay9 = train_data[train_data.Stay =='91-100'][\"Department\"].value_counts().rename('Count')\n\nstay10 = train_data[train_data.Stay =='More than 100 Days'][\"Department\"].value_counts().rename('Count')\n\nsns.barplot(stay0.index,stay0,  color=\"b\", ax=axes[0, 0]).set_title('Stay : 0-10')\n                   \nsns.barplot(stay1.index,stay2,  color=\"r\", ax=axes[0, 1]).set_title('Stay : 11-20')\n\nsns.barplot(stay2.index,stay2,  color=\"b\", ax=axes[1, 0]).set_title('Stay : 21-30')\n\nsns.barplot(stay3.index,stay3,  color=\"g\", ax=axes[1, 1]).set_title('Stay : 31-40')\n\nsns.barplot(stay4.index,stay4,  color=\"b\", ax=axes[2, 0]).set_title('Stay : 41-50')\n\nsns.barplot(stay5.index,stay5,  color=\"b\", ax=axes[2, 1]).set_title('Stay : 51-60')\n\nsns.barplot(stay6.index,stay6,  color=\"m\", ax=axes[3, 0]).set_title('Stay : 61-70')\n\nsns.barplot(stay7.index,stay7, color=\"b\", ax=axes[3, 1]).set_title('Stay : 71-80')\n\nsns.barplot(stay8.index,stay8,  color=\"b\", ax=axes[4, 0]).set_title('Stay : 81-90')\n\nsns.barplot(stay9.index,stay9,  color=\"g\", ax=axes[4, 1]).set_title('Stay : 91-100')\n\nsns.barplot(stay10.index,stay10, color=\"r\", ax=axes[5, 0]).set_title('Stay : >100')\n\nplt.setp(axes, yticks = np.arange(0,20000,5000))\n\n\nfor ax in f.axes:\n    \n    plt.sca(ax)\n    \n    plt.xticks(rotation=45)\n\nplt.tight_layout()","e710d4ad":"sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n\nf, axes = plt.subplots(3, 1, figsize=(15, 15))\n\nemergency = train_data[train_data['Type of Admission'] =='Emergency'][\"Stay\"].value_counts().rename('Count')\n\ntrauma = train_data[train_data['Type of Admission'] =='Trauma'][\"Stay\"].value_counts().rename('Count')\n\nurgent = train_data[train_data['Type of Admission'] =='Urgent'][\"Stay\"].value_counts().rename('Count')\n\nsns.barplot(emergency.index,emergency,  color=\"b\", ax=axes[0]).set_title('Admn. Type : Emergency')\n\nsns.barplot(trauma.index,trauma,   color=\"r\", ax=axes[1]).set_title('Admn. Type : Trauma')\n\nsns.barplot(urgent.index,urgent,  color=\"g\", ax=axes[2]).set_title('Admn. Type : Urgent')\n\nplt.setp(axes, yticks = np.arange(0,50000,10000))\n\nfor ax in f.axes:\n    \n    plt.sca(ax)\n    \n    plt.xticks(rotation=45)\n\nplt.tight_layout()","ec6f91a8":"train_data['City_Code_Patient'] = train_data['City_Code_Patient'].fillna(-1)\ntrain_data['Bed Grade'] = train_data['Bed Grade'].fillna(-1)","ef053b97":"test_data['City_Code_Patient'] = test_data['City_Code_Patient'].fillna(-1)\ntest_data['Bed Grade'] = test_data['Bed Grade'].fillna(-1)","3c957dd0":"cat_cols = ['Hospital_code','Hospital_type_code','City_Code_Hospital','Hospital_region_code'\n            ,'Department','Ward_Type','Ward_Facility_Code','Bed Grade','City_Code_Patient',\n           # 'Type of Admission','Severity of Illness',\n            'Age']","11f94879":"label = 'Stay'","22865ccc":"def encode_cat_cols(train, test, cat_cols): #target\n\n    train_df = train_data.copy()\n    \n    test_df = test_data.copy()\n    \n    # Making a dictionary to store all the labelencoders for categroical columns to transform them later.\n    \n    le_dict = {}\n\n    for col in cat_cols:\n        \n        le = LabelEncoder()\n        \n        le.fit(train_df[col].unique().tolist() + test_df[col].unique().tolist())\n        \n        train_df[col] = le.transform(train_df[[col]])\n        \n        test_df[col] = le.transform(test_df[[col]])\n\n        le_dict[col] = le\n\n    le = LabelEncoder()\n    \n    train_df[label] = le.fit_transform(train_df[[label]])\n    \n    le_dict[label] = le\n    \n    train_df['Type of Admission'] = train_df['Type of Admission'].map({'Urgent':0,'Emergency':1,'Trauma':2})\n    \n    train_df['Severity of Illness'] = train_df['Severity of Illness'].map({'Minor':0,'Moderate':1,'Extreme':2})\n    \n    test_df['Type of Admission'] = test_df['Type of Admission'].map({'Urgent':0,'Emergency':1,'Trauma':2})\n    \n    test_df['Severity of Illness'] = test_df['Severity of Illness'].map({'Minor':0,'Moderate':1,'Extreme':2})\n    \n    return train_df, test_df, le_dict","5616b320":"def feature_importance(model, X_train):\n\n    print(model.feature_importances_)\n    \n    names = X_train.columns.values\n    \n    ticks = [i for i in range(len(names))]\n    \n    plt.bar(ticks, model.feature_importances_)\n    \n    plt.xticks(ticks, names,rotation = 90)\n    \n    plt.show()","1ee88deb":"train_df, test_df, le_dict = encode_cat_cols(train_data,test_data,cat_cols)","a0c41383":"#After Feature Engineering\n# https:\/\/www.kaggle.com\/gcspkmdr\/lets-get-rid-of-the-patients-feature-engineering\n\ncombined_data = pd.read_csv('\/kaggle\/input\/fork-of-lets-get-rid-of-the-patients\/combined.csv')","5ea1a23d":"train_df = combined_data[combined_data['train']==1]\n\ntest_df = combined_data[combined_data['train']==0]","5b44bc41":"train_df.drop(columns = ['case_id','train','patientid','Hospital_code',\n                         'Hospital_type_code','City_Code_Hospital','Ward_Facility_Code'],inplace = True)\n\ntarget = train_df.pop('Stay')\n\ntest_df.drop(columns = ['case_id','train','Stay','patientid','Hospital_code',\n                        'Hospital_type_code','City_Code_Hospital','Ward_Facility_Code'],inplace = True)","44fa8779":"cat_features = ['Hospital_region_code','Department','Ward_Type','Bed Grade','City_Code_Patient','Type of Admission','Severity of Illness','Age']","cb457e34":"%%time\n\n##CatBoost\n\nscores = []\n\navg_loss = []\n\nX_train_cv,y_train_cv = train_df.copy(), target.copy()\n\nsssf = StratifiedShuffleSplit(n_splits=5, test_size = 0.45 ,random_state=1)\n\nfor i, (idxT, idxV) in enumerate(sssf.split(X_train_cv, y_train_cv)):\n    \n    print('Fold',i)\n    \n    print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n    \n    clf = CatBoostClassifier(iterations=1000,\n                            learning_rate=0.1,\n                            random_strength=0.1,\n                            depth=8,\n                            loss_function='MultiClass',\n                            eval_metric='Accuracy',\n                            leaf_estimation_method='Newton',\n                            task_type = 'GPU',\n                            random_state = 1,\n                            cat_features =cat_features\n                            )    \n    \n    h = clf.fit(X_train_cv.iloc[idxT], y_train_cv.iloc[idxT],\n                eval_set=[(X_train_cv.iloc[idxV],y_train_cv.iloc[idxV])],\n               early_stopping_rounds=50,verbose = 100)\n    \n    acc = accuracy_score(y_train_cv.iloc[idxV],np.argmax(clf.predict_proba(X_train_cv.iloc[idxV]),axis =1))*100\n    \n    scores.append(acc)\n    \n    avg_loss.append(clf.best_score_['validation']['MultiClass'])\n    \n    print ('CatBoost Val CV=',acc)\n    \n    if i==0:\n        feature_importance(clf,X_train_cv)\n    \n    print('#'*100)\n\nprint(\"Multi Log Loss Stats {0:.5f},{1:.5f}\".format(np.array(avg_loss).mean(), np.array(avg_loss).std()))\n\nprint('%.3f (%.3f)' % (np.array(scores).mean(), np.array(scores).std()))","aa569463":"trees = 5\n\nseeds = [32,432,73]\n\nsubmission = pd.read_csv('..\/input\/healthcareanalyticsii\/sample_submission.csv')\n\nprobs = np.zeros(shape=(len(test_df),11))\n\nsubmission_probs = pd.DataFrame(columns = ['case_id'] + list(le_dict['Stay'].classes_))\n\nsubmission_probs.iloc[:,0] = submission.iloc[:,0]\n\nsubmission_probs.iloc[:,1:] = 0","e76436f0":"%%time\n\n##LightGBM\n\n#groups = train_df['patientid'].values\n\nscores = []\n\navg_loss = []\n\nsubmission_name = [] \n\nX_train_cv,y_train_cv = train_df.copy(), target.copy()\n\nfor seed in tnrange(len(seeds)):\n\n    sssf = StratifiedShuffleSplit(n_splits=5, test_size = 0.3 ,random_state=seeds[seed])\n\n    for j, (idxT, idxV) in tqdm(enumerate(sssf.split(X_train_cv, y_train_cv))):\n\n        print('Fold',j)\n\n        print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n\n        model_cat = [0] *trees\n\n        for i in tnrange(trees):\n\n            print('Tree',i)\n\n            model_cat[i] = CatBoostClassifier(iterations=1000,\n                                              learning_rate=0.1,\n                                              random_strength=0.1,\n                                              depth=8,\n                                              loss_function='MultiClass',\n                                              eval_metric='Accuracy',\n                                              leaf_estimation_method='Newton',\n                                              task_type = 'GPU',\n                                              random_state = i*27,\n                                              cat_features = cat_features\n                                            )    \n    \n            model_cat[i].fit(X_train_cv.iloc[idxT], y_train_cv.iloc[idxT],\n                eval_set=[(X_train_cv.iloc[idxV],y_train_cv.iloc[idxV])],\n               early_stopping_rounds=50,verbose = 100)\n\n            probs_file_name = 'probs_'+str(seeds[seed])+'_'+str(j)+'_'+str(i)+\".csv\"\n            \n            submisssion_file_name  = 'submission_'+str(seeds[seed])+'_'+str(j)+'_'+str(i)+\".csv\"\n            \n            model_cat_probs = model_cat[i].predict_proba(test_df)\n            \n            submission_probs.iloc[:,1:] = model_cat_probs\n            \n            # probablity file per seed per split per tree\n            submission_probs.to_csv(probs_file_name,index = False)\n            \n            submission['Stay'] = le_dict['Stay'].inverse_transform(np.argmax(model_cat_probs,axis =1))\n            \n            # submission file per seed per split per tree\n            submission.to_csv(submisssion_file_name,index =False)\n            \n            probs += model_cat_probs\n            \n            acc = accuracy_score(y_train_cv.iloc[idxV],np.argmax(model_cat[i].predict_proba(X_train_cv.iloc[idxV]),axis =1))*100\n            \n            scores.append(acc)\n            \n            submission_name.append(submisssion_file_name)\n            \n            avg_loss.append(model_cat[i].best_score_['validation']['MultiClass'])\n\n            print ('CatBoost Accuracy Split =',acc)\n            \n            print('#'*100)\n    \n\nprint('%.3f (%.3f)' % (np.array(scores).mean(), np.array(scores).std()))","44687c51":"submission_probs.iloc[:,1:] = probs\n\n# probablity combined\nsubmission_probs.to_csv('probs.csv',index =False)","b0f604a3":"submission['Stay'] = le_dict['Stay'].inverse_transform(np.argmax(probs,axis =1))\n\n# submission file combined            \nsubmission.to_csv('submission.csv',index =False)\n            ","3b76bab3":"model_stats = pd.DataFrame({'submission':submission_name,'accuracy':scores,'validation_loss':avg_loss})\nmodel_stats.head()","626de069":"model_stats.to_csv('model_stats.csv',index =False)","35f19aae":"# Model Building","4f883818":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Cross Validation\n![](https:\/\/4.bp.blogspot.com\/-wpr6O3EBAfU\/WbHyt6UCOVI\/AAAAAAAAjPw\/Y1DaO6qcV8oDYjJHzJ1PaPB2EXHmYtBBQCLcBGAs\/s1600\/%25E6%2593%25B7%25E5%258F%2596.JPG)\n\n* **The CV score generated using the methodology shown in the above figure is a better indicator of model performance than public LB**"}}