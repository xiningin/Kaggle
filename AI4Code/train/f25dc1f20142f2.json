{"cell_type":{"c2cf0866":"code","c36d6027":"code","dbfe66bd":"code","c1174bb2":"code","ae742233":"code","8cf38dd9":"code","feaadb30":"code","f947698c":"code","b4a5c1ea":"code","5a713c40":"markdown","31388829":"markdown","4b4d2870":"markdown"},"source":{"c2cf0866":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import load_img,img_to_array","c36d6027":"#pictrue size 48*48\npic_size = 48\nbase_path = \"..\/input\/face-expression-recognition-dataset\/images\/\"","dbfe66bd":"#plotting the images\n\nplt.figure(0,figsize=(20,20))\ncpt = 0\n\nfor expression in os.listdir(base_path+\"train\/\"):\n    for i in range(1,8):\n        cpt+=1\n        plt.subplot(7,8,cpt)\n        img = load_img(base_path+\"train\/\"+expression+\"\/\"+os.listdir(base_path + \"train\/\" + expression)[i], target_size=(pic_size, pic_size))\n        plt.imshow(img,cmap = \"gray\")\n        plt.xlabel(os.listdir(base_path + \"train\/\" + expression)[i])\nplt.tight_layout()\nplt.show()\n    ","c1174bb2":"#training images for each expression\nfor expression in os.listdir(base_path + \"train\"):\n    print(str(len(os.listdir(base_path + \"train\/\" + expression)))+\" \"+expression+\" images\")","ae742233":"from keras.preprocessing.image import ImageDataGenerator\n\nbatch_size  = 128\n\ndatagen_train  = ImageDataGenerator()\ndatagen_val = ImageDataGenerator()\n\ntrain_gen = datagen_train.flow_from_directory(base_path+\"train\",\n                                              target_size = (pic_size,pic_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)\n\n\nval_gen = datagen_val.flow_from_directory(base_path+\"validation\",\n                                              target_size = (pic_size,pic_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=False)\n","8cf38dd9":"from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\nfrom keras.models import Model,Sequential\nfrom keras.optimizers import Adam,SGD,RMSprop\n\n\nno_of_classes = 7\n\nmodel = Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n\n","feaadb30":"%%time\n\n# number of epochs to train the NN\nepochs = 48\n\nfrom keras.callbacks import ModelCheckpoint\n\n\ncheckpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit_generator(generator=train_gen,\n                                steps_per_epoch=train_gen.n\/\/train_gen.batch_size,\n                                epochs=epochs,\n                                validation_data = val_gen,\n                                validation_steps = val_gen.n\/\/val_gen.batch_size,\n                                callbacks=callbacks_list\n                                )","f947698c":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","b4a5c1ea":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n","5a713c40":"We define our CNN with the following global architecture:\n\n* 4 convolutional layers\n* 2 fully connected layers\nThe convolutional layers will extract relevant features from the images and the fully connected layers will focus on using these features to classify well our images. ","31388829":"### Setup our Convolutional Neural Network (CNN)","4b4d2870":"## Train the model"}}