{"cell_type":{"df581e35":"code","360125a6":"code","c2808bb0":"code","35ac1512":"code","08e5bfb0":"code","ecf735d9":"code","a2605994":"code","02cdf745":"code","bc427a74":"code","ccc86ab4":"code","a7a38118":"code","20563f56":"code","275f020c":"code","09ddd53d":"code","326104ec":"code","49de5683":"code","c04260db":"code","c6b4613d":"code","c1ab32bd":"code","b1937f99":"markdown","6d1349f4":"markdown","21d030d5":"markdown","c1b41328":"markdown","f4145f8e":"markdown","887c1c5d":"markdown","82a01ac3":"markdown","4d9cff18":"markdown","593bbe5d":"markdown","92906b10":"markdown","5cf69978":"markdown","983b7615":"markdown","2b9153ee":"markdown","d598ca65":"markdown","57f84312":"markdown","73b66a87":"markdown","822c6f87":"markdown","34cb191a":"markdown"},"source":{"df581e35":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","360125a6":"from PIL import Image\nimage = Image.open('..\/input\/pilimages\/opera_house.jpg')\nprint(image.format)\nprint(image.mode)\nprint(image.size)","c2808bb0":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimg_arr = np.asarray(image)\nprint(img_arr.dtype)\nprint(img_arr.shape)\nplt.imshow(img_arr)","35ac1512":"img = Image.fromarray(img_arr)\nprint(img.mode)\nprint(img.size) # Width and height\nprint(img.format)","08e5bfb0":"image.save('opera_house.png', format='PNG')","ecf735d9":"new_img = Image.open('.\/opera_house.png')\nprint(new_img.format)\nprint(new_img.size)\nprint(new_img.mode)","a2605994":"from PIL import ImageOps\ngray_img = ImageOps.grayscale(new_img)\n# gray_img = new_img.convert(model='L')\n\ngray_img_arr = np.asarray(gray_img)\nplt.imshow(gray_img_arr)","02cdf745":"'''\nCurrent image dim width x height (640,360). thumbnail will resize the bigger dim i.e 640 to 100\nand other dim will be rescaled to maintain aspect ratio.\n\nStandard resampling algorithms are used to invent or remove pixels when resizing, and you can specify\na technique, although default is a bicubic resampling algorithm that suits most general applications\n'''\n\nnew_img.thumbnail((100,100)) \n## new_img.resize((200,200)) in case we dont want to preserve the aspect ratio\n\nprint('old image dim {}  and new img dim  {}'.format(image.size,new_img.size))","bc427a74":"## imshow() function can plot the Image object directly without having to convert it to a NumPy array\n\nhoz_flip = image.transpose(Image.FLIP_LEFT_RIGHT)\nver_flip = image.transpose(Image.FLIP_TOP_BOTTOM)\nplt.subplot(3,1,1)\nplt.imshow(image)\nplt.subplot(3,1,2)\nplt.imshow(hoz_flip)\nplt.subplot(3,1,3)\nplt.imshow(ver_flip)","ccc86ab4":"'''\nIn both rotations, the pixels are clipped to the original dimensions of the image\nand the empty pixels are filled with black color.\n\n'''\n\nplt.subplot(3,1,1)\nplt.imshow(image)\nplt.subplot(3,1,2)\nplt.imshow(image.rotate(45))\nplt.subplot(3,1,3)\nplt.imshow(image.rotate(90))","a7a38118":"'''\nhere we created a cropped square image of 100 pixels starting at 100,100 and\nextending down and left to 200,200.\n'''\n\ncropped_img = image.crop((100,100,200,200))\nplt.imshow(cropped_img)","20563f56":"image = Image.open('..\/input\/bridge-image\/sydney_bridge.png')\nprint(image.format)\nprint(image.mode)\nprint(image.size)","275f020c":"plt.imshow(image)","09ddd53d":"img_arr = np.asarray(image)\nprint('Type %s' % (img_arr.dtype))\nprint('min pixel value %s and max pixel value %s' % (img_arr.min(), img_arr.max()))\nimg_arr = img_arr.astype('float32')\nprint('Type : %s' % (img_arr.dtype))\nimg_arr = img_arr \/ 255.\nprint('min pixel value %.3f and max pixel value %.3f' % (img_arr.min(), img_arr.max()))","326104ec":"image = Image.open('..\/input\/pilimages\/opera_house.jpg')\nimg_arr = np.asarray(image)\nimg_arr = img_arr.astype('float32')\nmean = img_arr.mean()\nprint('Mean : %.3f' % (mean))\nprint('Min : %.3f and Max: %.3f' % (img_arr.min(), img_arr.max()))\n\n## Applying global centering \nprint('\\nAfter applying global centering\\n')\nimg_arr = img_arr - mean\nmean = img_arr.mean()\nprint('Mean : %.3f' % (mean))\nprint('Min: %.3f and Max: %.3f' % (img_arr.min(), img_arr.max()))","49de5683":"img1 = np.asarray(image)\nimg1 = img1.astype('float32')\nmeans = img1.mean(axis=(0,1), dtype='float64') # returns means for all channels\nprint('Mean: %s' % (means))\nprint('Min: %s and Max: %s' % (img1.min(axis=(0,1)), img1.max(axis=(0,1))))\n\n# Local centering\nimg1 = img1 - means\nprint('Mean: %s' % (means))\nprint('Min: %s and Max: %s' % (img1.min(axis=(0,1)), img1.max(axis=(0,1))))","c04260db":"img2 = np.asarray(image)\nimg2 = img2.astype('float32')\nmean, std = img2.mean(), img2.std()\nprint('Mean %.3f and Std: %.3f' % (mean, std))\nimg2 = (img2 - mean)\/std\nmean, std = img2.mean(), img2.std()\nprint('Mean: %.3f and Std: %.3f' % (mean, std))","c6b4613d":"# clipping the pixel values\nimg2 = np.clip(img2, -1.0,1.0)\n\n# Rescale them to [0,1]\nimg2 = (img2 + 1.0)\/2.0\nmean, std = img2.mean(), img2.std()\nprint('Mean: %.3f and Std: %.3f' % (mean, std))\nprint('Min: %.3f and Max: %.3f' % (img2.min(), img2.max()))","c1ab32bd":"img3 = np.asarray(image)\nimg3 = img3.astype('float32')\nmeans, stds = img3.mean(axis=(0,1), dtype='float64'), img3.std(axis=(0,1), dtype='float64')\nprint('Means: %s and Std: %s' % (means, stds))\n\n# Local standardisation\nimg3 = (img3 - means)\/stds\n\nmeans, stds = img3.mean(axis=(0,1), dtype='float64'), img3.std(axis=(0,1), dtype='float64')\nprint('Means: %s and Std: %s' % (means, stds))","b1937f99":"## Resizing","6d1349f4":"## Local Standardisation","21d030d5":"## Flip Image","c1b41328":"## Positive Global Standardisation\n\n### Why need of positive global standardisation\n\nWe may need to maintain the pixel values in the positive domain, so the images\ncan be visualized or perhaps for the benefit of a chosen activation function in the model. A\npopular way of achieving this is to clip the standardized pixel values to the range [-1, 1] and then\nrescale the values from [-1,1] to [0,1]. ","f4145f8e":"## local Centering","887c1c5d":"## Convert image to grayscale","82a01ac3":"## Centering pixel values\n\n1. A popular data preparation technique for image data is to subtract the mean value from the pixel values. This approach is called centering, because the distribution of the pixel values is centered on the value of zero\n\n2. Centering the pixels then normalizing will mean that the pixel values will be centered close to 0.5. Centering after normalization will mean that the pixels will have positive and negative values, in which case images will not display correctly.\n\n3. The mean can be calculated for all pixels in the image, referred to as a global centering, or it can be calculated for each channel in the case of color images, referred to as local centering.\n\n4. For models trained on images centered using these means that may be used for transfer learning on new tasks, it can be beneficial or even required to normalize images for the new task using the same means.","4d9cff18":"## Convert image from array back to Image object","593bbe5d":"## Golbal Standardisation","92906b10":"## Preparing image data for modeling with deep learning neural networks. ","5cf69978":"## Normalizing pixel values\n\nNeural networks process inputs using small weight values, and inputs with large integer values can\ndisrupt or slow down the learning process","983b7615":"## Using PIL libray for images","2b9153ee":"## Rotate Image","d598ca65":"## Crop Image","57f84312":"## Global Centering","73b66a87":"## Standardising Pixel Values\n\n1. Here we transform the distribution of pixel values to be a standard Gaussian: that is both centering the pixel values on zero and normalizing the values by the standard deviation. We get a standard Gaussian of pixel values with a mean of 0.0 and a standard deviation of 1.0.\n\n2. Standardization may be preferred to normalization and centering alone and it results in both zero-centered values and small input values, roughly in the range -3 to 3, depending on the specifics of the dataset.","822c6f87":"## Saving Images","34cb191a":"## Using matplotlib for images"}}