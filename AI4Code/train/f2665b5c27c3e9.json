{"cell_type":{"958ab6b4":"code","3823063d":"code","7b2479cf":"code","65e8eb51":"code","b6513067":"code","fdafdc93":"code","4a7851d4":"code","78735ded":"code","e536c551":"code","d21eced7":"code","ac486316":"code","13e8cdd2":"code","d0d59264":"code","f488853f":"code","44a1bf42":"code","4e1257b5":"code","f77802b3":"code","19b9ec55":"markdown","31fc8fb8":"markdown","c9636470":"markdown","7df055ae":"markdown","0aec09d7":"markdown","9635e34b":"markdown","1b56f0f5":"markdown","316ed4cb":"markdown","77f96919":"markdown"},"source":{"958ab6b4":"!pip install tensorflow\nimport os","3823063d":"#base_dir = '..\/input\/mechanical-tools-dataset\/Mechanical Tools Image dataset'\n\ntrain_dir = os.path.join('..\/input\/mechanical-tools-dataset\/train_data_V2\/train_data_V2')\nvalidation_dir = os.path.join('..\/input\/mechanical-tools-dataset\/validation_data_V2\/validation_data_V2')\n\n# Diret\u00f3rio com as imagens de chave de fenda e chave para o treinamento\ntrain_screwdriver_dir = os.path.join('..\/input\/mechanical-tools-dataset\/train_data_V2\/train_data_V2\/screwdriver')\ntrain_wrench_dir = os.path.join('..\/input\/mechanical-tools-dataset\/train_data_V2\/train_data_V2\/wrench')\ntrain_hammer_dir = os.path.join('..\/input\/mechanical-tools-dataset\/train_data_V2\/train_data_V2\/hammer')\n\n# Diret\u00f3rio com as imagens de chave de fenda e chave para valida\u00e7\u00e3o\nvalidation_screwdriver_dir = os.path.join('..\/input\/mechanical-tools-dataset\/validation_data_V2\/validation_data_V2\/screwdriver')\nvalidation_wrench_dir = os.path.join('..\/input\/mechanical-tools-dataset\/validation_data_V2\/validation_data_V2\/wrench')\nvalidation_hammer_dir = os.path.join('..\/input\/mechanical-tools-dataset\/validation_data_V2\/validation_data_V2\/hammer')","7b2479cf":"train_screwdriver_fnames = os.listdir(train_screwdriver_dir )\ntrain_wrench_fnames = os.listdir( train_wrench_dir)\ntrain_hammer_fnames = os.listdir( train_hammer_dir )\n\nprint(train_screwdriver_fnames[:20])\nprint(train_wrench_fnames[:20])\nprint(train_hammer_fnames[:20])","65e8eb51":"print('total training screwdriver images :', len(os.listdir(train_screwdriver_dir)))\nprint('total training wrench images :', len(os.listdir(train_wrench_dir)))\nprint('total training hammer images :', len(os.listdir(train_hammer_dir)))\n\n\nprint('total validation screwdriver images :', len(os.listdir( validation_screwdriver_dir ) ))\nprint('total validation wrench images :', len(os.listdir( validation_wrench_dir) ))\nprint('total validation hammer images :', len(os.listdir( validation_hammer_dir) ))","b6513067":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Par\u00e2metros para o gr\u00e1fico; a configura\u00e7\u00e3o de sa\u00edda das imagens ser\u00e1 10x10\nnrows = 10\nncols = 10\n\n# Indice para itera\u00e7\u00e3o das imagens\npic_index = 0","fdafdc93":"# Configurando o matplotlib fig e dimensionando para caber em fotos 4x4\nfig = plt.gcf()\nfig.set_size_inches(ncols * 4, nrows * 4)\n\npic_index += 10\nnext_screwdriver_pix = [os.path.join(train_screwdriver_dir, fname) \n                for fname in train_screwdriver_fnames[pic_index-10:pic_index]]\nnext_wrench_pix = [os.path.join(train_wrench_dir, fname) \n                for fname in train_wrench_fnames[pic_index-10:pic_index]]\nnext_hammer_pix = [os.path.join(train_hammer_dir, fname) \n                for fname in train_hammer_fnames[pic_index-10:pic_index]]\n\nfor i, img_path in enumerate(next_screwdriver_pix+next_wrench_pix+next_hammer_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","4a7851d4":"import tensorflow as tf","78735ded":"import os\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\nlocal_weights_file = '..\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n\npre_trained_model = InceptionV3(input_shape = (300,300, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n  \n# pre_trained_model.summary()\n\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","e536c551":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Todas as imagens foram reescalonadas para 1.\/255.\ntest_datagen  = ImageDataGenerator( rescale = 1.0\/255. )\n\n# Adicionando os par\u00e2metros do data-augmentation no ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 20,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = train_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 20,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n# --------------------\n# Fluxo das imagens de treinamento em lotes de 20 usando train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=30,\n                                                    class_mode='categorical',\n                                                    target_size=(300,300))     \n# --------------------\n# Fluxo das imagens de valida\u00e7\u00e3o em lotes de 20 usando test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory(validation_dir,\n                                                         batch_size=30,\n                                                         class_mode  = 'categorical',\n                                                         target_size = (300,300))","d21eced7":"from tensorflow.keras.optimizers import Adam\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(150, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)  \n\n# Add a final sigmoid layer for classification\nx = layers.Dense(3, activation='softmax')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\n#RMSprop(lr=0.0001)\n\nmodel.compile(optimizer = Adam(), \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])","ac486316":"model.summary()","13e8cdd2":"history = model.fit(train_generator,\n                              validation_data=validation_generator,\n                              steps_per_epoch=5,\n                              epochs=80,\n                              validation_steps=5,\n                              verbose=2)","d0d59264":"#-----------------------------------------------------------\n# Recuperando uma lista de resultados da lista de dados de treinamento e teste\n# Conjuntos para cada \u00e9poca de treinamento\n#-----------------------------------------------------------\nacc      = history.history[     'accuracy' ]\nval_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # N\u00famero ode \u00e9pocas\n\n#------------------------------------------------\n# Plot de acur\u00e1cia de treinamento e valida\u00e7\u00e3o por \u00e9poca\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training e validation loss por \u00e9poca\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'  )","f488853f":"\nimport cv2\nimg = cv2.imread('..\/input\/mechanical-tools-dataset\/test_data\/test_data\/Screwdriver (1415).JPEG')\nplt.imshow(img)\nimg = cv2.resize(img,(300, 300))\nimg = np.reshape(img,[1,300, 300,3])\n\nclasses = model.predict(img)\nprint(classes)","44a1bf42":"img = cv2.imread('..\/input\/mechanical-tools-dataset\/test_data\/test_data\/Screwdriver (1401).JPEG')\nplt.imshow(img)\nimg = cv2.resize(img,(300, 300))\nimg = np.reshape(img,[1,300, 300,3])\n\nclasses = model.predict(img)\nprint(classes)","4e1257b5":"img = cv2.imread('..\/input\/mechanical-tools-dataset\/test_data\/test_data\/Screwdriver (1402).JPEG')\nplt.imshow(img)\nimg = cv2.resize(img,(300, 300))\nimg = np.reshape(img,[1,300, 300,3])\n\nclasses = model.predict(img)\nprint(classes)","f77802b3":"img = cv2.imread('..\/input\/mechanical-tools-dataset\/test_data\/test_data\/Wrench (286).JPEG')\nplt.imshow(img)\nimg = cv2.resize(img,(300, 300))\nimg = np.reshape(img,[1,300, 300,3])\n\nclasses = model.predict(img)\nprint(classes)","19b9ec55":"**Em seguida, adicionamos camadas convolucionais como no exemplo anterior e achatamos o resultado final para alimentar as camadas densamente conectadas. Observe que, por estarmos enfrentando um problema de classifica\u00e7\u00e3o de duas classes, ou seja, um problema de classifica\u00e7\u00e3o bin\u00e1ria, encerraremos nossa rede com uma ativa\u00e7\u00e3o sigm\u00f3ide, de modo que a sa\u00edda de nossa rede ser\u00e1 um \u00fanico escalar entre 0 e 1, codificando o probabilidade de que a imagem atual seja de classe 1 (em oposi\u00e7\u00e3o \u00e0 classe 0).**","31fc8fb8":"**Agora vejamos como s\u00e3o os nomes dos arquivos nos diret\u00f3rios de treinamento:**","c9636470":"**Agora, vamos dar uma olhada em algumas fotos para ter uma ideia melhor de como s\u00e3o as ferramentas. Primeiro, vamos configurar os par\u00e2metros do matplot:**","7df055ae":"# Pr\u00e9-processamento dos Dados","0aec09d7":"# Modelo Pr\u00e9-Treino","9635e34b":"**Agora, vamos exibir um lote de 50 fotos de chaves e 50 alicates. Podemos executar novamente a c\u00e9lula para ver um novo lote a cada vez:**","1b56f0f5":"# Definindo cada um dos diret\u00f3rios","316ed4cb":"**A coluna \"output shape\" mostra como o tamanho do mapa de features evolui em cada camada sucessiva. As camadas de convolu\u00e7\u00e3o reduzem um pouco o tamanho do mapa de features devido ao preenchimento, e cada camada de agrupamento divide as dimens\u00f5es pela metade.**","77f96919":"**Vamos descobrir o n\u00famero de imagens das ferramentas no diret\u00f3rio**"}}