{"cell_type":{"91b83557":"code","2e12c3d8":"code","330049ae":"code","62bbf8cb":"code","0e7d9aa7":"code","a151d5ca":"code","2f32f47f":"code","0317430a":"code","97d6eb4c":"markdown","0ffb2cbb":"markdown","23966b8e":"markdown","6599111c":"markdown","b1ff6028":"markdown","fe40c7ce":"markdown"},"source":{"91b83557":"# Basic Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\n# TensorFlow Libraries\nimport cv2\nfrom tensorflow.keras import models, layers, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import load_img\n\n# Transfer Learning Libraries\nfrom tensorflow.keras.applications import Xception\n\n# Other Libraries\nfrom io import BytesIO\nfrom PIL import Image\nimport requests","2e12c3d8":"example_images = [\"..\/input\/10-monkey-species\/training\/training\/n0\/\"\n, \"..\/input\/10-monkey-species\/training\/training\/n1\/\"\n,\"..\/input\/10-monkey-species\/training\/training\/n2\/\"\n, \"..\/input\/10-monkey-species\/training\/training\/n3\/\"\n, \"..\/input\/10-monkey-species\/training\/training\/n4\/\"\n,\"..\/input\/10-monkey-species\/training\/training\/n5\/\"\n,\"..\/input\/10-monkey-species\/training\/training\/n6\/\"\n,\"..\/input\/10-monkey-species\/training\/training\/n7\/\"\n,\"..\/input\/10-monkey-species\/training\/training\/n8\/\",\n\"..\/input\/10-monkey-species\/training\/training\/n9\/\"]\n\nfig = plt.figure(figsize=(24, 10))\n\nj=1\nfor i in example_images:   \n    filenames  = os.listdir(i)\n    sample = filenames[0]\n    img = load_img(i+sample)\n    plt.subplot(2,5,j)\n    plt.axis(\"equal\")\n    plt.imshow(img)\n    plt.xlabel(\"Monkey Species: n{}\".format(j))\n    j+=1\n    \n","330049ae":"train_dir = '..\/input\/10-monkey-species\/training\/training'\nvalidation_dir = '..\/input\/10-monkey-species\/validation\/validation'\n\nBATCH_SIZE = 8\nIMG_SIZE = (224,224)\n\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range = 30,\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size= BATCH_SIZE,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical')\n","62bbf8cb":"Xception_base = Xception(weights='imagenet', \n                         include_top=False)\n\nx = Xception_base.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(512, activation='relu')(x)\n\nsoftmax_output_len =int(len(train_generator.class_indices.keys()))\n\npredictions = layers.Dense(softmax_output_len, activation='softmax')(x)\nXception_transfer = models.Model(inputs=Xception_base.input, outputs=predictions)\n\nXception_transfer.summary()\n\nXception_transfer.compile(loss='categorical_crossentropy',\n                          optimizer=optimizers.SGD(learning_rate=1e-4, momentum=0.9), \n                          metrics=['accuracy'])\n\nhistory = Xception_transfer.fit(train_generator,\n                                          epochs=10,\n                                          shuffle = True, \n                                          verbose = 1, \n                                          validation_data = validation_generator)","0e7d9aa7":"def history_plot(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    plt.figure(figsize=(8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylabel('Accuracy')\n    plt.ylim([min(plt.ylim()),1])\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.ylabel('Cross Entropy')\n    plt.ylim([min(val_loss)-0.2,max(loss)+0.2])\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()","a151d5ca":"history_plot(history)","2f32f47f":"test_images = [\n    \"https:\/\/projectzerofootprint.com\/wp-content\/uploads\/2016\/08\/monkey-2-1080x768.jpg\",\n    \"https:\/\/i.ytimg.com\/vi\/Ptisy32iRRA\/hqdefault.jpg\",\n    \"https:\/\/images.pond5.com\/red-uakari-monkey-footage-064800523_iconl.jpeg\",\n    \"https:\/\/thejapanalps.com\/wp-content\/uploads\/2020\/03\/nihonsaru01.jpg\",\n    \"https:\/\/www.zoo-leipzig.de\/fileadmin\/_processed_\/e\/c\/csm_Weissbauch-Zwergseidenaeffchen_3_c46c37b6a1.jpg\",\n    \"https:\/\/cdn.britannica.com\/05\/181805-050-C9682415\/capuchin-monkey.jpg\",\n    \"https:\/\/www.neprimateconservancy.org\/uploads\/1\/5\/3\/8\/15380094\/silvery-marmoset-istock-153473655-resize_45.jpg\",\n    \"https:\/\/study.com\/cimages\/multimages\/16\/squirrel_monkeys.png\",\n    \"https:\/\/ars.els-cdn.com\/content\/image\/3-s2.0-B9780124095274000171-f17-04-9780124095274.jpg\",\n    \"https:\/\/media-cdn.tripadvisor.com\/media\/photo-s\/0a\/67\/93\/f5\/nilgiri-langur-karunkorangu.jpg\"\n]\n\ntest_labels = [\"n0\", \"n1\", \"n2\", \n               \"n3\", \"n4\", \"n5\", \n               \"n6\", \"n7\", \n               \"n8\", \"n9\"]\n\nmonkey_speciets_type = [\"Mantled Howler\",\"Patas Monkey\",\"Bald Uakari\",\n                        \"Japanese Macaque\",\"Pygmy Marmoset\",\"White Headed Capuchin\",\n                        \"Silvery Marmoset\",\"Ommon Squirrel Monkey\",\n                        \"Black Headed Night Monkey\",\"Nilgiri Langur\"]","0317430a":"\nfor (i,label) in enumerate(test_labels):\n    response = requests.get(test_images[i])\n    img = Image.open(BytesIO(response.content))\n    img = np.asarray(img)\/255.\n    img = cv2.resize(img, (224,224))\n    prediction=Xception_transfer.predict(img.reshape(1, 224,224,3))\n    output = np.argmax(prediction)\n     \n    plt.title(\"Real: {} \\n Predict: {}\".format(monkey_speciets_type[i], monkey_speciets_type[output]))\n    plt.imshow(img)\n    plt.show()","97d6eb4c":"# Data from each Monkey Species","0ffb2cbb":"# Preparing the Data for the Model\n\n","23966b8e":"# Visualization of the Accuracy and Loss of the model","6599111c":"# Importing","b1ff6028":"# Examining Test Data","fe40c7ce":"# Base (Transfer Learning) and Head layers"}}