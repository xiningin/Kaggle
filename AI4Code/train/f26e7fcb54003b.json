{"cell_type":{"1ddeae3c":"code","1678b40b":"code","b768c3ca":"code","b42751f8":"code","e3a37b72":"code","e232cdda":"code","1637a1c0":"code","35fbfd36":"code","32a76c25":"code","0ed7a60c":"code","49305801":"code","9fd4261e":"code","236355d6":"code","acf23f8d":"code","50dcec21":"code","5254c042":"code","238e1b6d":"code","89a4a497":"code","e327289d":"markdown","862ef4a1":"markdown","65b3d90a":"markdown","144474cb":"markdown","7ff5ed92":"markdown","883d6d62":"markdown","7bb22605":"markdown","92c8ed52":"markdown","d9665323":"markdown","18396a60":"markdown","409aa3cb":"markdown","8b27b590":"markdown","bb9cfe1a":"markdown","fcdbff50":"markdown","e3ce21a8":"markdown"},"source":{"1ddeae3c":"#!pip install catboost","1678b40b":"import warnings as wr\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.model_selection import train_test_split \nfrom catboost import CatBoostClassifier \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nwr.filterwarnings('ignore')","b768c3ca":"#filepath\nfile_path= \"..\/input\/mobile-price-classification\/train.csv\"","b42751f8":"df=pd.read_csv(file_path) #reading file\ndf.head()#displaying initial entries","e3a37b72":"print('Number of rows are :',df.shape[0], ',and number of columns are :',df.shape[1])","e232cdda":"df.columns.tolist()\n","1637a1c0":"def NullClearner(df):\n    if(isinstance(df, pd.Series) and (df.dtype in [\"float64\",\"int64\"])):\n        df.fillna(df.mean(),inplace=True)\n        return df\n    elif(isinstance(df, pd.Series)):\n        df.fillna(df.mode()[0],inplace=True)\n        return df\n    else:return df\ndef EncodeX(df):\n    return pd.get_dummies(df)\ndef EncodeY(df):\n    if len(df.unique())<=2:\n        return df\n    else:\n        un_EncodedT=np.sort(pd.unique(df), axis=-1, kind='mergesort')\n        df=LabelEncoder().fit_transform(df)\n        EncodedT=[xi for xi in range(len(un_EncodedT))]\n        print(\"Encoded Target: {} to {}\".format(un_EncodedT,EncodedT))\n        return df","35fbfd36":"plt.figure(figsize = (20, 12))\ncorr = df.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\nsns.heatmap(corr, mask = mask, linewidths = 1, annot = True, fmt = \".2f\")\nplt.show()","32a76c25":"#spliting data into X(features) and Y(Target)\n\nX=df.drop([\"price_range\"],axis=1)\nY=df[\"price_range\"]   ","0ed7a60c":"x=X.columns.to_list()\nfor i in x:\n    X[i]=NullClearner(X[i])  \nX=EncodeX(X)\nY=EncodeY(NullClearner(Y))\nX.head()","49305801":"plt.figure(figsize = (10,6))\nsns.countplot(Y,palette='pastel')","9fd4261e":"#we can choose randomstate and test_size as over requerment\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 13) #performing datasplitting","236355d6":"scaler=MaxAbsScaler()\nX_train=scaler.fit_transform(X_train)\nX_train=pd.DataFrame(data = X_train,columns = X.columns)\nX_test=scaler.transform(X_test)\nX_train.head()\n","acf23f8d":"# Build Model here\nmodel=CatBoostClassifier(verbose=False)\n\nmodel.fit(X_train,y_train)","50dcec21":"print(\"Accuracy score {:.2f} %\\n\".format(model.score(X_test,y_test)*100))","5254c042":"#prediction on testing set\nprediction=model.predict(X_test)","238e1b6d":"#ploting_confusion_matrix(model,X_test,y_test,cmap=plt.cm.Blues)\ncf_matrix=confusion_matrix(y_test,prediction)\nplt.figure(figsize=(7,6))\nsns.heatmap(cf_matrix,annot=True,fmt=\"d\")\n","89a4a497":"print(classification_report(y_test,model.predict(X_test)))","e327289d":"### Initialization\n\nFilepath of CSV file","862ef4a1":"#### Confusion Matrix\n\nA confusion matrix is utilized to understand the performance of the classification model or algorithm in machine learning for a given test set where results are known.","65b3d90a":"### Required Packages","144474cb":"#### Classification Report\n\nA Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are True, how many are False.\n\n* **where**:\n    - Precision:- Accuracy of positive predictions.\n    - Recall:- Fraction of positives that were correctly identified.\n    - f1-score:-  percent of positive predictions were correct\n    - support:- Support is the number of actual occurrences of the class in the specified dataset.","7ff5ed92":"#### Model Accuracy\nscore() method return the mean accuracy on the given test data and labels.\n\nIn multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.","883d6d62":"\n#### Distribution Of Target Variable","7bb22605":"### Feature Selections\n\nIt is the process of reducing the number of input variables when developing a predictive model. Used to reduce the number of input variables to both reduce the computational cost of modelling and, in some cases, to improve the performance of the model.\n\nWe will assign all the required input features to X and target\/outcome to Y.","92c8ed52":"### Data Preprocessing\n\nSince the majority of the machine learning models in the Sklearn library doesn't handle string category data and Null value, we have to explicitly remove or replace null values. The below snippet have functions, which removes the null value if any exists. And convert the string classes data in the datasets by encoding them to integer classes.\n","d9665323":"### Data Splitting\n\nThe train-test split is a procedure for evaluating the performance of an algorithm. The procedure involves taking a dataset and dividing it into two subsets. The first subset is utilized to fit\/train the model. The second subset is used for prediction. The main motive is to estimate the performance of the model on new data.","18396a60":"### Data Fetching\n\nPandas is an open-source, BSD-licensed library providing high-performance, easy-to-use data manipulation and data analysis tools.\n\nWe will use panda's library to read the CSV file using its storage path.And we use the head function to display the initial row or entry.","409aa3cb":"# CatBoostClassifier with MaxAbsScaler","8b27b590":"## Model\n\n#### CatBoostClassifier(verbose=False)\nCatBoost is an algorithm for gradient boosting on decision trees. Developed by Yandex researchers and engineers, it is the successor of the MatrixNet algorithm that is widely used within the company for ranking tasks, forecasting and making recommendations\n\n**Tuning parameters :**\n\nlearning_rate:, float, default = it is defined automatically for Logloss, MultiClass & RMSE loss functions depending on the number of iterations if none of these parameters is set\n\n* The learning rate. Used for reducing the gradient step.\n\n* l2_leaf_reg: float, default = 3.0\n\nCoefficient at the L2 regularization term of the cost function. Any positive value is allowed.\n\n* bootstrap_type: string, default = depends on the selected mode and processing unit\n\nBootstrap type. Defines the method for sampling the weights of objects.\n\n * Supported methods:\n * Bayesian\n * Bernoulli\n * MVS\n * Poisson (supported for GPU only)\n * No\n**subsample:** float, default = depends on the dataset size and the bootstrap type\nSample rate for bagging. This parameter can be used if one of the following bootstrap types is selected:\n\n * Poisson\n * Bernoulli\n * MVS","bb9cfe1a":"#### Please do a upvote if you like it","fcdbff50":"\n### Feature Rescaling\n**MaxAbsScaler**\n\nScale each feature by its maximum absolute value. This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift\/center the data, and thus does not destroy any sparsity.\n\nReference URL to MaxAbsScaler API :\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.MaxAbsScaler.html\n\n","e3ce21a8":"#### Correlation Map\n\nIn order to check the correlation between the features, we will plot a correlation matrix. It is effective in summarizing a large amount of data where the goal is to see patterns."}}