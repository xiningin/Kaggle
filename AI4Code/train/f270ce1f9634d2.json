{"cell_type":{"72e3c3b2":"code","81622212":"code","d4742cf4":"code","e07342d1":"code","df10d586":"code","475a563f":"code","e1e9bda8":"code","1357386f":"code","03916f11":"code","71b71e42":"code","669f561a":"code","805cf6c1":"code","8e20e1d7":"code","2d0786d3":"code","1332bf2d":"code","6e157f51":"code","d3f05011":"code","d6e15b90":"code","726eb378":"code","7253e8e9":"code","22fdecfd":"code","04f428a4":"code","7cdc7350":"code","1cda5221":"code","5d85f7ce":"markdown","d1cf7a15":"markdown","9bef2fa1":"markdown","9e63f811":"markdown","19ada159":"markdown","dea0de95":"markdown","e2a23724":"markdown","9d8cc03e":"markdown","0bd954d7":"markdown"},"source":{"72e3c3b2":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport glob\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Input, Activation, add, Add, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom keras.models import Sequential, Model\nfrom keras import optimizers\nfrom kaggle_datasets import KaggleDatasets\n\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint\n\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.applications.efficientnet import preprocess_input","81622212":"batch_size = 256\nIMG_WIDTH = 380\nIMG_HEIGHT = 380\nCHANNELS = 3\nCLASSES = 5\nSEED = 5\n\nprint(\"Tensorflow version \" + tf.__version__)","d4742cf4":"datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=90,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    fill_mode='nearest',\n    cval=0xCC,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split = 0.2\n    )","e07342d1":"df_train = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ndf_train.head()","df10d586":"df_train['path'] = '..\/input\/cassava-leaf-disease-classification\/train_images\/' + df_train['image_id']\ndf_train.head()","475a563f":"test_images = glob.glob('..\/input\/cassava-leaf-disease-classification\/test_images\/*.jpg')\ndf_test = pd.DataFrame(test_images, columns = ['path'])\ndf_test.head()","e1e9bda8":"# If class_mode=\"categorical\", y_col=\"label\" column values must be type string, list or tuple.\ndf_train['label'] = df_train['label'].astype('str') \n\ntrain_generator = datagen.flow_from_dataframe(\n    df_train,\n    x_col = 'path',\n    y_col = 'label',\n    target_size=(IMG_WIDTH,IMG_HEIGHT),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True,\n    seed = SEED,\n    subset = 'training'\n    )\n\nvalidation_generator = datagen.flow_from_dataframe(\n    df_train,\n    x_col = 'path',\n    y_col = 'label',\n    target_size=(IMG_WIDTH,IMG_HEIGHT),\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True,\n    seed = SEED,\n    subset = 'validation'\n    )","1357386f":"from tensorflow.keras import layers\ndef build_model():\n    inputs = layers.Input(shape=(IMG_WIDTH,IMG_HEIGHT,CHANNELS))\n    x = inputs\n    model = EfficientNetB4(include_top=False, input_tensor=x, \n                           weights='..\/input\/tfkerasefficientnetimagenetnotop\/efficientnetb4_notop.h5')\n    \n    # Freeze the pretrained weights\n    model.trainable = False\n    \n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n    x = layers.BatchNormalization()(x)\n    top_dropout_rate = 0.2\n    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n    outputs = layers.Dense(CLASSES, activation=\"softmax\", name=\"pred\")(x)\n    \n    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n    \n    return model\n    ","03916f11":"model = build_model()\nmodel.summary()","71b71e42":"loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False,\n                                               label_smoothing=0.0001,\n                                               name='categorical_crossentropy' )  \n\nmodel.compile(loss = loss,\n              optimizer = optimizers.Adam(learning_rate=1e-2),\n              metrics=['accuracy'])\n \nSTEP_SIZE_TRAIN=train_generator.n \/\/ train_generator.batch_size\nSTEP_SIZE_VALID=validation_generator.n  \/\/ validation_generator.batch_size\n\nmodelCheckpoint = ModelCheckpoint(filepath = 'cassava-efficientNetB4_bestParam_pre.h5',\n                                  monitor='val_loss',\n                                  verbose=1,\n                                  save_best_only=True,\n                                  save_weights_only=True,\n                                  mode='min',\n                                  period=1)\n\n\nepochs = 10\n\nhistory = model.fit_generator(train_generator,\n                             steps_per_epoch=STEP_SIZE_TRAIN,\n                             epochs=epochs,\n                             validation_data=validation_generator,\n                             validation_steps=STEP_SIZE_VALID,\n                             callbacks=[modelCheckpoint])","669f561a":"plt.style.use('fivethirtyeight')\nplt.title('Pre Model Accuracy')\nplt.plot(range(1, epochs+1), history.history['accuracy'], label=\"training\")\nplt.plot(range(1, epochs+1), history.history['val_accuracy'], label=\"validation\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","805cf6c1":"plt.style.use('fivethirtyeight')\nplt.title('Pre Model Loss')\nplt.plot(range(1, epochs+1), history.history['loss'], label=\"training\")\nplt.plot(range(1, epochs+1), history.history['val_loss'], label=\"validation\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","8e20e1d7":"# Load Pretrain-weights\nmodel.load_weights('cassava-efficientNetB4_bestParam_pre.h5', by_name=True)\nmodel.summary()","2d0786d3":"def unfreeze_model(model):\n    model.trainable = True\n    \n    for layer in model.layers:\n        layer.trainable = False\n\n    # unfreeze the top 20 layers while leaving BatchNorm layers frozen\n    for layer in model.layers[-20:]:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = True","1332bf2d":"#Unfreezing\nunfreeze_model(model)\nmodel.summary()","6e157f51":"# Fine Tuning\nmodel.compile(loss = loss,\n              optimizer = optimizers.Adam(learning_rate=1e-4),\n              metrics=['accuracy'])\n \nSTEP_SIZE_TRAIN=train_generator.n \/\/ train_generator.batch_size\nSTEP_SIZE_VALID=validation_generator.n  \/\/ validation_generator.batch_size\n\nmodelCheckpoint = ModelCheckpoint(filepath = 'cassava-efficientNetB4_bestParam.h5',\n                                  monitor='val_loss',\n                                  verbose=1,\n                                  save_best_only=True,\n                                  save_weights_only=False,\n                                  mode='min',\n                                  period=1)\n\nepochs = 10\n\nhistory = model.fit_generator(train_generator,\n                             steps_per_epoch=STEP_SIZE_TRAIN,\n                             epochs=epochs,\n                             validation_data=validation_generator,\n                             validation_steps=STEP_SIZE_VALID,\n                             callbacks=[modelCheckpoint])","d3f05011":"plt.style.use('fivethirtyeight')\nplt.title('Model Accuracy')\nplt.plot(range(1, epochs+1), history.history['accuracy'], label=\"training\")\nplt.plot(range(1, epochs+1), history.history['val_accuracy'], label=\"validation\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","d6e15b90":"plt.style.use('fivethirtyeight')\nplt.title('Model Loss')\nplt.plot(range(1, epochs+1), history.history['loss'], label=\"training\")\nplt.plot(range(1, epochs+1), history.history['val_loss'], label=\"validation\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","726eb378":"model.load_weights('cassava-efficientNetB4_bestParam.h5')","7253e8e9":"test_datagen = image.ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_generator = test_datagen.flow_from_dataframe(\n    df_test,\n    x_col = 'path',\n    y_col=None,\n    target_size=(IMG_WIDTH,IMG_HEIGHT),\n    batch_size=batch_size,\n    class_mode=None,\n    shuffle=False,\n    seed = SEED\n    )\n","22fdecfd":"pred = model.predict_generator(test_generator, verbose = True)\npred_labels = np.argmax(pred, axis = -1)","04f428a4":"df_test['path'].str.split('\/').str[-1]","7cdc7350":"df_sub = df_test\ndf_sub['image_id'] = df_test['path'].str.split('\/').str[-1]\ndf_sub['label'] = pred_labels\ndf_sub.head()","1cda5221":"df_sub.to_csv('submission.csv', index=False, columns=['image_id', 'label'])","5d85f7ce":"### Set Up Data Augmentation","d1cf7a15":"### Pre Training","9bef2fa1":"### Import Module","9e63f811":"### Create Submission File","19ada159":"### Set up variables","dea0de95":"* This Notebook is Simple fine-tuning Model for begginners.\n* I'm a beginner at Machine Learning, so I'm sorry if there are any mistakes.\n* I referred to the following documents for fine-tuning.\nhttps:\/\/keras.io\/examples\/vision\/image_classification_efficientnet_fine_tuning\/\n\n","e2a23724":"### Fine Tuning","9d8cc03e":"### Load Image","0bd954d7":"### Create Model"}}