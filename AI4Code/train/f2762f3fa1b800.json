{"cell_type":{"213a2e6f":"code","b7d2d43e":"code","775054ab":"code","c19d2add":"code","8a69ce93":"code","5fcca2b0":"code","69880bfa":"code","3bb034ea":"code","f83e3cde":"code","0f798408":"code","0272a9eb":"code","ff5e7670":"code","f614bf79":"code","00046e2b":"code","75042549":"code","59c3b605":"code","6b308287":"code","dc96f6ca":"markdown","e95368a0":"markdown","aaa2bcb4":"markdown","2ae5c8e8":"markdown","39fa0f3a":"markdown","47b17cff":"markdown","121751c6":"markdown","a78624a3":"markdown","b7b846e6":"markdown","63c8a4d4":"markdown","697b1063":"markdown","fe2c22df":"markdown","57eeb279":"markdown","ff17fa98":"markdown","78dfb212":"markdown"},"source":{"213a2e6f":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport seaborn as sns\n\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\npio.templates.default = \"none\"\n\nfrom umap import UMAP\nfrom sklearn.manifold import TSNE\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b7d2d43e":"train = pd.read_csv('\/kaggle\/input\/song-popularity-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/song-popularity-prediction\/test.csv')","775054ab":"display(train.shape)\ndisplay(test.shape)","c19d2add":"train.info()","8a69ce93":"train.head()","5fcca2b0":"train.describe().T.head(10).sort_values(by='std' , ascending = False)\\\n.style.background_gradient()","69880bfa":"def null_value_df(data):    \n    null_values_df = []    \n    for col in data.columns:\n        \n        if data[col].isna().sum() != 0:\n            pct_na = np.round((100 * (data[col].isna().sum())\/len(data)), 2) \n            \n            dict1 ={\n                'Features' : col,\n                'NA (count)': data[col].isna().sum(),\n                'NA (%)': (pct_na)\n            }\n            null_values_df.append(dict1)\n    return pd.DataFrame(null_values_df, index=None).sort_values(by='NA (count)',ascending=False)\n\n\nDF1 = null_value_df(train)\nDF2 = null_value_df(test)\n\nfig = go.Figure(data=[go.Bar(x=DF1['Features'],\n                             y=DF1[\"NA (%)\"],                              \n                             name='train', marker_color='lightseagreen'),\n                      go.Bar(x=DF2['Features'],\n                             y=DF2[\"NA (%)\"], \n                             name='test', marker_color='lightsalmon')])\nfig.update_traces(marker_line_color='black', marker_line_width=1.5, opacity=1)\nfig.update_layout(title_text='<b> Features with missing values: train & test data <b>',\n                  font_family=\"San Serif\",\n                  width=750, height=500,\n                  xaxis_title='Features', \n                  yaxis_title='missing (%)',\n                  titlefont={'color':'black', 'size': 24, 'family': 'San-Serif'})\n\nfig.show()","3bb034ea":"neg = train[train['song_popularity'] == 0]\npos = train[train['song_popularity'] == 1]\n\nlabel = ['Popular (=1)', 'Not-popular (=0)']\nvalue = [pos.shape[0], neg.shape[0]] \npct = [value[0]*100\/len(train), value[1]*100\/len(train)]\n\n\nfig = go.Figure(data=[go.Bar(\n            y=value, x=label,\n            text=(np.round(pct,2)),\n            textposition=['outside', 'inside'],\n            texttemplate = [\"<b style='color: #f'>%{text}%<\/b>\"]*2,\n            textfont=dict(  family=\"sans serif\",\n                            size=16,\n                            color=\"black\"),\n            orientation='v',\n            marker_color=['lightseagreen', 'lightgray'],\n            opacity=1.0,\n                    )])\nfig.update_layout(title='<b>Target: Song Popularity<b>', \n                  font_family=\"San Serif\",\n                  yaxis_linewidth=2.5,\n                  width=600, \n                  height=400,\n                  bargap=0.2,\n                  barmode='group',\n                  titlefont={'size': 24},\n                  )\nfig.update_xaxes(showgrid=False, showline=True)\nfig.update_yaxes(showgrid=False, showline=False, showticklabels=False)\nfig.show()","f83e3cde":"features = train.columns[1:-1]\nl = len(features)\nrow = int(np.ceil(l\/2))\n\nfig = make_subplots(rows=row, cols=2,\n                   subplot_titles=('song_duration_ms','loudness', 'acousticness', 'audio_mode','danceability', \n                                   'speechiness','energy','tempo','instrumentalness', 'time_signature','key',\n                                   'audio_valence','liveness', ))                              \n                  \n\nfor i, feat in enumerate(features[0:row]):\n    fig.add_trace(go.Histogram(x=train[feat],\n                  name='train', marker_color = 'salmon'),\n                 row=i+1, col=1)\n    fig.add_trace(go.Histogram(x=test[feat],\n                  name='test', marker_color = 'gray'),\n                 row=i+1, col=1)    \n    fig.update_layout(barmode='overlay')\n                           \nfor j, feat in enumerate(features[row:l+1]):\n    fig.add_trace(go.Histogram(x=train[feat],\n                  name='train', marker_color = 'salmon'),\n                 row=j+1, col=2)\n    fig.add_trace(go.Histogram(x=test[feat], \n                  name='test', marker_color = 'gray'),\n                 row=j+1, col=2)    \n    fig.update_layout(barmode='overlay')\n\nfig.update_layout(title=\"<b> Features distribution: train_test data <b>\",\n                      font_family=\"San Serif\",\n                      titlefont={'size': 24},\n                      width=900, height=1200,\n                      template='simple_white',\n                      showlegend=False,\n                      bargap=0.1, \n                      bargroupgap=0.1\n                     )\nfig.show()","0f798408":"pos = train[train['song_popularity'] == 1]\nneg = train[train['song_popularity'] == 0]\n\nfeatures = train.columns[1:-1]\n\nl = len(features)\nrow = int(np.ceil(l\/2))\n\n\nfig = make_subplots(rows=row, cols=2,\n                   subplot_titles=('song_duration_ms','loudness', 'acousticness', 'audio_mode','danceability', \n                                   'speechiness','energy','tempo','instrumentalness', 'time_signature','key',\n                                   'audio_valence','liveness', ))                              \n                  \n\nfor i, feat in enumerate(features[0:row]):\n    fig.add_trace(go.Histogram(x=pos[feat],histnorm='percent',\n                  name='Popular', marker_color = 'salmon'),\n                  row=i+1, col=1)\n    fig.add_trace(go.Histogram(x=neg[feat],histnorm='percent',\n                  name='Not-popular', marker_color = 'seagreen', opacity=0.85),\n                 row=i+1, col=1)    \n    fig.update_layout(barmode='overlay')\n                           \nfor j, feat in enumerate(features[row:l+1]):\n    fig.add_trace(go.Histogram(x=pos[feat],histnorm='percent',\n                  name='Popular', marker_color = 'salmon'),\n                 row=j+1, col=2)\n    fig.add_trace(go.Histogram(x=neg[feat],histnorm='percent',\n                  name='Not-popular', marker_color = 'seagreen', opacity=0.85),\n                 row=j+1, col=2)    \n    fig.update_layout(barmode='overlay')\n\nfig.update_layout(title=\" <b> Features distribution: train_test data <b>\",\n                      font_family=\"San Serif\",\n                      titlefont={'size': 24},\n                      width=900, height=1200,\n                      template='simple_white',\n                      showlegend=False,\n                      bargap=0.1, \n                      bargroupgap=0.1\n                     )\n\nfig.update_layout(barmode='group')\nfig.show()\n    ","0272a9eb":"train.drop('id', axis=1, inplace=True)\ntrain = train.sample(frac=0.25, replace=False, random_state=1)\n\ncorr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\ncorr = corr.mask(mask)\n\n\nfig = go.Figure(data= go.Heatmap(z=corr,\n                                 x=corr.index.values,\n                                 y=corr.columns.values,\n                                 colorscale='deep',                                  \n                                 )\n                )\nfig.update_layout(title_text='<b>Correlation Heatmap<b>',\n                  font_family=\"San Serif\",\n                  title_x=0.5,\n                  titlefont={'size': 24},\n                  width=750, height=750,\n                  xaxis_showgrid=False,\n                  xaxis={'side': 'bottom'},\n                  yaxis_showgrid=False,\n                  yaxis_autorange='reversed',                   \n                                    autosize=False,\n                  margin=dict(l=150,r=50,b=150,t=70,pad=0),\n                  )\nfig.show()","ff5e7670":"def plot_contour_scatter(x, y, x_t, y_t, text_title):\n\n    fig = go.Figure(go.Histogram2dContour(\n            x = x,\n            y = y,\n            \n            contours = dict(\n                showlabels = True,\n                labelfont = dict(\n                    family = 'Raleway',\n                    color = 'white'\n                )\n            ),\n                hoverlabel = dict(\n                bgcolor = 'white',\n                bordercolor = 'black',\n                font = dict(\n                    family = 'Raleway',\n                    color = 'black'\n                )\n            )\n\n    ))\n    fig.add_trace(go.Scatter(\n            x = x,\n            y = y,\n            xaxis = 'x',\n            yaxis = 'y',\n            mode = 'markers',\n            marker = dict(\n                color = 'rgba(0,0,0,0.3)',\n                size = 2\n            )\n        ))\n    fig.layout.update(width=650, height=600, \n                      xaxis_title=x_t, \n                      yaxis_title=y_t,\n                      title= text_title,\n                      font_family=\"San Serif\",\n                      titlefont={'size': 24},\n                     )\n    fig.show()\n    \ndef density_contour(df, x, y, title):   \n    fig = px.density_contour(train, \n                             x=x, \n                             y=y, \n                             color=\"song_popularity\",\n                             trendline=\"ols\",\n                             #marginal_x=\"histogram\", marginal_y=\"histogram\",                 \n                             width=600,height=500,\n                             template=\"simple_white\",\n                             title= title,\n                             )\n    fig.layout.update(font_family=\"San Serif\", titlefont={'size': 24},)\n    fig.show()","f614bf79":"title1 = '<b> Energy vs Acousticness <b>'\n\nplot_contour_scatter(train[\"energy\"],train[\"acousticness\"], \n                     \"energy\", \"acousticness\", text_title=title1)\n\ntitle2 = '<b> Loudness vs Acousticness <b> '\n\nplot_contour_scatter(train[\"loudness\"],train[\"acousticness\"], \n                     \"loudness\", \"acousticness\", text_title=title2)\n\ntitle3 = '<b> Loudness vs Energy <b>'\n\nplot_contour_scatter(train[\"loudness\"],train[\"energy\"], \n                     \"loudness\", \"energy\", text_title=title3)\n\ntitle4 = '<b> Audio Valence vs Energy <b>'\n\nplot_contour_scatter(train[\"audio_valence\"],train[\"tempo\"], \n                     \"audio_valence\", \"energy\", text_title=title4)\n\ntitle5 = '<b> Audio Valence vs Tempo <b>'\n\nplot_contour_scatter(train[\"audio_valence\"],train[\"tempo\"], \n                     \"audio_valence\", \"tempo\", text_title=title5)","00046e2b":"train.dropna(axis=0, inplace=True)\n\nfig = px.density_contour(train, x=\"time_signature\", y=\"audio_mode\",facet_col=\"song_popularity\", color='key',\n                        category_orders={\n                            \"key\": np.arange(12)},\n                        facet_col_spacing=0.075,)\n#fig.update_traces(contours_coloring=\"fill\", contours_showlabels = True)\nfig.update_layout(title_text='<b>Time Signature vs Audio Mode <b>',\n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  height=400,width=900,\n                  \n                 )\nfig.show()\n\n\nfig = px.density_contour(train, x=\"time_signature\", y=\"key\",facet_col=\"song_popularity\", color='audio_mode',\n                        facet_col_spacing=0.075,)\n#fig.update_traces(contours_coloring=\"fill\", contours_showlabels = True)\nfig.update_layout(title_text='<b>Time Signature vs Key <b>',\n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  height=400,width=900,\n                  \n                 )\nfig.show()\n\nfig = px.density_contour(train, x=\"audio_mode\", y=\"key\",facet_col=\"song_popularity\", color='time_signature',\n                        category_orders={\n                            \"time_signature\": [2, 3, 4, 5]},\n                        facet_col_spacing=0.075,)\n#fig.update_traces(contours_coloring=\"heatmap\", contours_showlabels =False )\nfig.update_layout(title_text='<b>Audio Mode vs Key <b>',\n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  height=400,width=900,                                   \n                 )\nfig.show()","75042549":"fig = px.density_contour(train, x=\"energy\", y=\"audio_valence\",facet_col=\"song_popularity\", color='time_signature',\n                         category_orders={\n                            \"time_signature\": [2, 3, 4, 5]\n                        },facet_col_spacing=0.075,\n                        )\n#fig.update_traces(contours_coloring=\"fill\", contours_showlabels = True,)\nfig.update_layout(title_text='<b>Energy vs Audio Valence <b>',\n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  height=400,width=900,\n                  \n                                                     \n                 )\nfig.show()\n\nfig = px.density_contour(train, x=\"energy\", y=\"danceability\",facet_col=\"song_popularity\", color='audio_mode', \n                         facet_col_spacing=0.075,)\n#fig.update_traces(contours_coloring=\"fill\", contours_showlabels = True,)\nfig.update_layout(title_text='<b>Energy vs Danceability <b>',\n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  height=400,width=900,\n                                                     \n                 )\nfig.show()","59c3b605":"fig = px.density_contour(train, x=\"energy\", y=\"liveness\",\n                         facet_row=\"time_signature\", \n                         facet_col='song_popularity', \n                         color ='audio_mode',\n                         facet_col_spacing=0.075\n                        )\n#fig.update_traces(contours_coloring=\"fill\", contours_showlabels = True,)\nfig.update_layout(title_text='<b>Energy vs Danceability <b>',\n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  height=1000,width= 800,\n                                                     \n                 )\nfig.show()","6b308287":"train = pd.read_csv('\/kaggle\/input\/song-popularity-prediction\/train.csv')\ntrain.dropna(axis=0, inplace=True) # data reduced to 17259 from 40k upon dropping the na's\n\nfeatures = train.iloc[:, 1:-1].columns.values\nsampled_train = train.sample(10000, random_state=42)\n\numap_2d = UMAP(random_state=42)\numap_3d = UMAP(n_components=3, random_state=42)\n\nproj_2d = umap_2d.fit_transform(sampled_train[features])\nproj_3d = umap_3d.fit_transform(sampled_train[features])\n\n## Plot 2D UMAP ##\n\nfig_2d = px.scatter(\n    proj_2d, x=0, y=1, \n    labels={'color': 'song_popularity'},\n    color = sampled_train.song_popularity,\n    color_discrete_map=['viridis'],\n\n)\nfig_2d.update_layout(title='<b>2D_UMAP: Song Populaity<b>',\n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  width=650,\n                  height=500,\n                  template=\"simple_white\",\n                  showlegend=True,\n                  xaxis_showgrid=False,\n                  yaxis_showgrid=False,   \n                  paper_bgcolor=\"#dbdbdb\",\n                  plot_bgcolor='#dbdbdb', \n                  font=dict(\n                      color ='black',\n                      )\n                  )\nfig_2d.update_layout(xaxis_title='dim-1',yaxis_title='dim-2')\nfig_2d.update_xaxes(showgrid=False, showline=False)\nfig_2d.update_yaxes(showgrid=False, showline=False)\nfig_2d.show()\n\n\n## Plot 3D UMAP ##\nfig_3d = px.scatter_3d(\n    proj_3d, x=0, y=1, z=2,\n    labels={'color': 'song_popularity'},\n    color=sampled_train.song_popularity,\n    color_discrete_map=['viridis'],\n)\nfig_3d.update_layout(title='<b>3D_UMAP: Song Populaity<b>',\n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  width=650,\n                  height=500,\n                  template=\"plotly_dark\",\n                  showlegend=True,\n                  font=dict(\n                      color ='white',\n                      )\n                  )\nfig_3d.update_traces(marker_size=2)\nfig_3d.show()\n","dc96f6ca":"### Data Overview\n- Train data has 40k rows and 15 columns including target column.\n- Test data has 10k rows and 14 columns. \n- All of the columns are of numerical type. Some are may be of categorical type. We will see later.  ","e95368a0":"### Three-way feature interaction (cont - cont -cat)\n\n- Here the `energy vs audio_valence` plot looks interesting. In the left top quadrant of the second facet (song_popularity =1), we notice :\n> `low_energy` + `high audio_valence` is empty. Where as that same region in the first facet (song_popularity=0) is occupied by`time_signature(==5)`.  This may indicate that `low_energy` + `high audio_valence` + `time_signature(==5)` is likely to be a not-so-popular song.\n- Similarly in the bottom contour plot (`energy vs danceability`) we notice:\n> `high_energy` + `high_danceability` + `audio_mode==0` could be a not-so-popular song recipe.\n* Room for new features derived from these three-way interaction or am I fishing in an empty pond? May be, but it could be worth trying. ","aaa2bcb4":"### Features distribution with target\n- We see from the distribution of the features that no features is a strong predictor of the target variable. The target classes are almost overlaid one on the top of the other.","2ae5c8e8":"<div>    \n<img src=\"https:\/\/assets-global.website-files.com\/6080d45b6168d4415fe5cbd7\/60877444fc5ec5f71be695d4_1589931445-music-metrics.png\" width=\"500\", align=\"center\"\/>    \n<\/div>\n\n[Image credit](https:\/\/www.software.com\/src\/explore-the-data-behind-your-most-productive-music-for-coding)\n\n### **Song Popularity Prediction**\n\nSong Popularity Prediction is one of the community competitions of this year. Started on 18-Jan and ends on 2-Feb, 2022.\n- The aim of this competition is to predict the popularity of a given song based of its features (audio feature) as predictor.\n- Target variable is binary (0=not popular, 1= popular).\n- The evaluation metric for this competition is [Area Under the ROC Curve](https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic) (AUC).\n\n**Note** : The competition data description page does not have the features dictionary. We can use the list below, which can be found from the Spotify web page. Let's see what that is. \n\n#### Definition of audio features according to [Spotify](https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/#\/operations\/get-audio-features)\n\n\n\n- **Danceability**: Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.\n- **Valence**: Describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n- **Energy**: Represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.\n- **Tempo**: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, and derives directly from the average beat duration.\n- **Loudness**: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n- **Speechiness**: This detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.\n- **Instrumentalness**: Predicts whether a track contains no vocals. \u201cOoh\u201d and \u201caah\u201d sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \u201cvocal\u201d.\n- **Liveness**: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n- **Acousticness**: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n- **Key**: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on.\n- **Mode**: Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n- **Duration**: The duration of the track in milliseconds.\n- **Time Signature**: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).","39fa0f3a":"<!-- # fig = go.Figure(data=[go.Scatter(x=train['energy'],\n#                              y=train[\"acousticness\"], mode='markers',                         \n#                              marker_color=train['song_popularity']),\n#                      ])\n                       \n\n# fig.update_layout(title_text='Energy vs Acousticness ', \n#                   width=750, height=500,\n#                   xaxis_title='Energy', \n#                   yaxis_title='Acousticness',\n#                   #showlegend=True,\n#                   titlefont={'color':'black', 'size': 24, 'family': 'San-Serif'})\n\n# fig.show()\n# fig = go.Figure(data=[go.Scatter(x=train['loudness'],\n#                              y=train[\"acousticness\"], mode='markers',                         \n#                              name='train', marker_color=train['song_popularity']),\n#                      ])\n                      \n# fig.update_layout(title_text='Loudness vs Acousticness', \n#                   width=750, height=500,\n#                   xaxis_title='Loudness', \n#                   yaxis_title='Acousticness',\n#                   titlefont={'color':'black', 'size': 24, 'family': 'San-Serif'})\n\n# fig.show()\n# fig = go.Figure(data=[go.Scatter(x=train['loudness'],\n#                              y=train[\"energy\"], mode='markers',                         \n#                              name='train', marker_color=train['song_popularity']),\n#                      ])\n                      \n# fig.update_layout(title_text='Loudness vs Energy ', \n#                   width=750, height=500,\n#                   yaxis_title='Energy', \n#                   xaxis_title='Loudness',\n#                   titlefont={'color':'black', 'size': 24, 'family': 'San-Serif'})\n\n# fig.show()\n# fig = go.Figure(data=[go.Scatter(x=train['audio_valence'],\n#                              y=train[\"danceability\"], mode='markers',                         \n#                              name='train', marker_color=train['song_popularity']),\n#                      ])\n                      \n# fig.update_layout(title_text='Audio Valence vs Danceability ', \n#                   width=750, height=500,\n#                   yaxis_title='Audio Valence vs Danceability', \n#                   xaxis_title='Loudness',\n#                   titlefont={'color':'black', 'size': 24, 'family': 'San-Serif'})\n\n# fig.show()\n\n# fig = px.density_contour(train, \n#                          x=\"loudness\", \n#                          y=\"energy\", \n#                          color=\"song_popularity\",\n#                          trendline=\"expanding\",\n#                          marginal_x=\"histogram\", marginal_y=\"histogram\",                 \n#                          width=750,height=600,\n#                          title= '<b> Loudness vs Energy <b>',\n#                          template=\"simple_white\",\n#                          )\n# fig.layout.update(titlefont={'color': 'black', 'size': 24})\n\n# fig.show()\n# fig = px.density_contour(train, \n#                          x=\"energy\", \n#                          y=\"acousticness\", \n#                          color=\"song_popularity\",\n#                          trendline=\"ols\",\n#                          marginal_x=\"histogram\", marginal_y=\"histogram\",                 \n#                          width=750,height=600,\n#                          title= '<b> Energy vs Acousticness<b>',\n#                          template=\"simple_white\",\n#                          )\n# fig.layout.update(titlefont={'color': 'black', 'size': 24})\n\n# fig.show()\n\n-->","47b17cff":"### Correlation heatmap\nHere we notice a couple of things:\n- No single features is highly correlated with `song_popularity` (the target)\n- From the feature-feature correlations, there about three pairs that stand out. `loudness-energy`, `loundness-acousticness`, `energy-accoustices`. We will plot and see these individual correlations in the section below.","121751c6":"### Missing values\n\n- 8 columns out of 14 in both test and train datasets have missing values in them.\n- The missing values in both datasets are around 10% of the column having missing values. \n- Although not a huge amount of data is missing, we might need imputation to fill the missing values than drop.","a78624a3":"### Reference\n1. [Plotly](https:\/\/plotly.com\/python\/)\n2. [Spotify](https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/#\/operations\/get-audio-features)\n3. [umap-learn](https:\/\/pypi.org\/project\/umap-learn\/)","b7b846e6":"### Some interesting features\n- From the above correlation heatmap, we can identify three pairs of features which are moderately correlated. Below we will plot and see their interactions.\n- The plots below confirm what we have observed above in the correlation heatmap. The three pairs we have outlied above (energy-acousticness, loudness-acousticness and loudness-energy) indeed show moderately strong correlations. \n- As a comparison, a random feature pair (audio_valence - tempo) with low correlation is plotted. We can draw a horizontal line between them (no correlation).","63c8a4d4":"### Target: Song popularity\n\n- The train dataset contains more data which are labelled \"popular\" than those \"not-popular\" with ratio of 64% to 36%. We need to be carefull when we split data for training and validation.","697b1063":"### UMAP plots (2D and 3D)\n- I do not claim to know a great deal of UMAP dimension reduction models but their out put looks beautiful and artistic (not this particular plot though. It look like a plate of spaghetti). \n- For now I can only say that the two target classed seem to be inseparable, just as we have seen in the preceding sections. ","fe2c22df":"### Short summary:\n\n- Missing values: 8\/14 features have around 10% of missing data. Consider imputation of missing values.\n- Distribution of of continuous variables: Most features seem to be multi-modal. Consider log-transformation for those features which are skewed.\n- Target variable is slightly imbalanced: Consider appropriate sampling techniques before model training.\n- Distribution of both train and test dataset looks very similar.  \n- Correlation: No feature seem to have a strong correlation with the target variable.\n- **Three-way feature interaction** could be useful to create new features that can best separate popular and non-popular songs.\n","57eeb279":"Note the following in the last to rows. Looks interesting. \n- `liveness > 0.5` + `audio_mode == 1` + `time_signature == 2` >> not popular song\n- `liveness > 0.5` + `audio_mode == 0` + `time_signature == 5` >> popular song","ff17fa98":"### Three-way feature interaction (cat - cat - cat)\n- Here we consider the threw-way interaction of the categorical features `audio_mode`, `key`, and `time_signature`.\n- It seems that there is not a clear three-way interaction perhaps except the last contour plot `audio_mode vs key` where\n> `higher_key` + `audio_mode==1` + `time_signature==5` tend to be a popular song.","78dfb212":"### Features distribution\n\nFew observations: \n- Both train and test datasets seem to have similar distribution. \n- We see that features `audio_mode`, `time_signature` and `key` are categorical features. The other are continuous variable.\n- Only `song_duration` looks normally distributed.\n- Except `speechiness` all the other continuous features seem be multi-modal.\n- `energy` and `loudness` are more skewed to the left, whereas `speechiness` and `acousticness` are skewed more to the right. Log transformation can be applied in the feature engineering part of modelling.\n- `instrumentalness` looks like all the data is centred around zero with other (small amount of data) streching to the right up to 1."}}