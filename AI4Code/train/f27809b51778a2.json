{"cell_type":{"320c3875":"code","7602811f":"code","bc864c62":"code","f2753283":"code","510e82a4":"code","8b8bcd55":"code","e649c151":"code","ec2fcd3a":"code","e1ed5313":"code","82d215eb":"code","7015a271":"code","d9d1198d":"code","b9f997bd":"code","0b808d25":"code","399ee7f9":"code","80f5cc2d":"code","975743fe":"code","7652f4ad":"code","99002203":"code","bc4dac04":"code","af533762":"code","5ea80724":"code","4f624e3a":"code","3f9411c6":"code","c0f7e02c":"code","de4aaae9":"code","310af439":"code","90f2a808":"code","99f8fc3e":"code","af82194b":"code","3e2bb257":"code","3d65d012":"markdown","8b5e9c17":"markdown","bc459463":"markdown","7b566bda":"markdown","15ac31a2":"markdown","600a56d6":"markdown","ec2a0cb5":"markdown","f3f87b9e":"markdown","0c763e61":"markdown","efed413f":"markdown"},"source":{"320c3875":"# importing important liberaries\nimport pandas as pd \nimport numpy as np \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nplt.style.use('seaborn-white')","7602811f":"pip install xlrd","bc864c62":"pip install openpyxl","f2753283":"# LOading the dataa\nccdef = pd.read_excel('\/kaggle\/input\/finance-dataset\/Default.xlsx')\nccdef","510e82a4":"ccdef.shape","8b8bcd55":"ccdef.info()","e649c151":"#checking NUll values\nccdef.isnull().sum()","ec2fcd3a":"# Summarizing data\nccdef.describe()","e1ed5313":"# Analysis of Zero Values in Predictors\n(ccdef.balance == 0).sum(axis=0)","82d215eb":"#Categorical Variable Analysis\nprint(ccdef.student.value_counts())\nsns.countplot(x=\"student\", data=ccdef, palette='magma');","7015a271":"#Response Variable Analysis\nprint(ccdef.default.value_counts())\nsns.countplot(x = 'default', data = ccdef);","d9d1198d":"ccdef['default2'] = ccdef.default.factorize()[0]   \nccdef['student2'] = ccdef.student.factorize()[0] \n\nccdef.head()","b9f997bd":"# training and testing data\nX_train = ccdef.balance.values.reshape(-1,1)    \n\ny = ccdef.default2\n\nX_test = np.arange(ccdef.balance.min(), ccdef.balance.max()).reshape(-1 ,1)","0b808d25":"#Calculate probability using logistic regression\nimport sklearn.linear_model as skl_lm\n\nclf = skl_lm.LogisticRegression(solver='newton-cg')\nclf.fit(X_train,y)                      \nprob = clf.predict_proba(X_test)\n\nfig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5)) \nsns.regplot(ccdef.balance, ccdef.default2, order=1, ci=None,scatter_kws={'color':'orange'},line_kws={'color':'lightblue', 'lw':2}, ax=ax1) \n\nax2.scatter(X_train, y, color='orange') \nax2.plot(X_test, prob[:,1], color='lightblue') \nfor ax in fig.axes: \n    ax.hlines(1, xmin=ax.xaxis.get_data_interval()[0],xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1) \n    ax.hlines(0, xmin=ax.xaxis.get_data_interval()[0],xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1) \n    ax.set_ylabel('Probability of default') \n    ax.set_xlabel('Balance') \n    ax.set_yticks([0, 0.25, 0.5, 0.75, 1.]) \n    ax.set_xlim(xmin=-100) ","399ee7f9":" # Printing Cofficient and array of diatinct class\n print(clf)\n print('classes: ',clf.classes_)\n print('coefficients: ',clf.coef_)\n print('intercept :', clf.intercept_) ","80f5cc2d":"import statsmodels.api as sm\nimport statsmodels.discrete.discrete_model as sms\n\npd.set_option('precision', 6)\n\nX_train = sm.add_constant(ccdef.balance)\n\nest = sm.Logit(y.ravel(), X_train).fit()","975743fe":"est.summary2().tables[1]","7652f4ad":"X_train = sm.add_constant(ccdef.student2)\n\ny = ccdef.default2\n\nest = sms.Logit(y, X_train).fit()","99002203":"print(est.summary().tables[1].as_text())","bc4dac04":" X_train = sm.add_constant(ccdef[['balance', 'income', 'student2']])\n\n est = sms.Logit(y, X_train).fit()                    ","af533762":"print(est.summary().tables[1])","5ea80724":"#Create balance and default vectors for students\n\nX_train = ccdef[ccdef.student == 'Yes'].balance.values.reshape(-1,1)\ny = ccdef[ccdef.student == 'Yes'].default2","4f624e3a":"#Create balance and default vectors for non- students\n\nX_train2 = ccdef[ccdef.student == 'No'].balance.values.reshape(-1,1)\n\ny2 = ccdef[ccdef.student == 'No'].default2","3f9411c6":"# Create test vector\nX_test = np.arange(ccdef.balance.min(), ccdef.balance.max()).reshape(-1,1) ","c0f7e02c":"# Fit both dataset to Logistic Regression\n\nclf = skl_lm.LogisticRegression(solver='newton-cg')\n\nclf2 = skl_lm.LogisticRegression(solver='newton-cg')\n\nclf.fit(X_train,y)  ","de4aaae9":"clf2.fit(X_train2,y2) ","310af439":"# Calculate Probabilities\n\nprob = clf.predict_proba(X_test)    \n\nprob2 = clf2.predict_proba(X_test)","90f2a808":"# Confusion Matrix\nccdef.groupby(['student','default']).size().unstack('default')","99f8fc3e":"# Graphical Representation\nfig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5)) \n \n# Left plot \nax1.plot(X_test, prob[:,1], color='orange', label='Student') \nax1.plot(X_test, prob2[:,1], color='lightblue', label='Non-student') \nax1.hlines(127\/2817, colors='orange', label='Overall Student',xmin=ax1.xaxis.get_data_interval()[0],xmax=ax1.xaxis.get_data_interval()[1], linestyles='dashed') \nax1.hlines(206\/6850, colors='lightblue', label='Overall Non-Student',xmin=ax1.xaxis.get_data_interval()[0],xmax=ax1.xaxis.get_data_interval()[1], linestyles='dashed') \nax1.set_ylabel('Default Rate') \nax1.set_xlabel('Credit Card Balance') \nax1.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.]) \nax1.set_xlim(450,2500) \nax1.legend(loc=2) \n\n# Right plot \nsns.boxplot('student', 'balance', data=ccdef, orient='v', ax=ax2);","af82194b":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nX = ccdef[['balance', 'income', 'student2']]\ny = ccdef.default2        \n\nlda = LinearDiscriminantAnalysis(solver='svd')\n\ny_pred = lda.fit(X, y).predict(X)\n\nccdef_df = pd.DataFrame({'True default status': y, 'Predicted default status': y_pred})\n\nccdef_df.replace(to_replace={0:'No', 1:'Yes'}, inplace=True)           \n\nccdef_df.groupby(['Predicted default status','True default status']).size().unstack('True default status')  ","3e2bb257":"decision_prob = 0.2                                                    \ny_prob = lda.fit(X, y).predict_proba(X)                                \n\nccdef_df = pd.DataFrame({'True default status': y,'Predicted default status': y_prob[:,1] > decision_prob})                                   \n\nccdef_df.replace(to_replace={0:'No', 1:'Yes', 'True':'Yes', 'False':'No'}, inplace=True) \n\nccdef_df.groupby(['Predicted default status','True default status']).size().unstack('True default status') ","3d65d012":"***Logistic Regression - Dummy Variable***","8b5e9c17":"***Logistic Regression Statsmodel***","bc459463":"***50% Threshold***","7b566bda":"***Cofunding***","15ac31a2":"***Multiple Logistic Regression***","600a56d6":"# Logistic Regression - Sklearn","ec2a0cb5":"# Linear Discriminant Analysis","f3f87b9e":"IF any flaws in this kernal please let me know!!! :)","0c763e61":"*** 20% Threshold ***","efed413f":"***Encode Categorical Variables***"}}