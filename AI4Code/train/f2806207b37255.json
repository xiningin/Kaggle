{"cell_type":{"c3dc14a7":"code","60ba85bc":"code","8b875311":"code","1b1f48ea":"code","87a8c0a4":"code","b352dab8":"code","3e52c761":"code","153a69f2":"code","a2987d65":"code","d84b8542":"code","7d82a280":"code","f3644b90":"code","ad24e001":"code","c2f8aba9":"code","8b7f937d":"code","68f95194":"code","aa166d58":"code","808cdf72":"code","43445c35":"code","4758d47e":"code","2d7f19fe":"code","771270f4":"markdown","4555a579":"markdown","5648ab5a":"markdown","4e5b9175":"markdown","ef77ba07":"markdown","1ea83fba":"markdown","87c77766":"markdown","9c037575":"markdown","26736517":"markdown","bafd31af":"markdown","1e52f287":"markdown","1a0d1581":"markdown"},"source":{"c3dc14a7":"# libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport numpy as np\nimport time\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn import metrics","60ba85bc":"path = '..\/input\/ventilator-pressure-prediction'\ntrain = pd.read_csv(os.path.join(path, 'train.csv'))\ntest = pd.read_csv(os.path.join(path, 'test.csv'))\nsub = pd.read_csv(os.path.join(path, 'sample_submission.csv'))","8b875311":"train.head()","1b1f48ea":"train.describe()","87a8c0a4":"print(set(test['breath_id'].unique()).intersection(set(train['breath_id'].unique())))\nprint(set(train['breath_id'].unique()).intersection(set(test['breath_id'].unique())))","b352dab8":"fig, ax = plt.subplots(figsize = (12, 8))\nplt.subplot(2, 2, 1)\nsns.countplot(x='R', data=train)\nplt.title('Counts of R in train');\nplt.subplot(2, 2, 2)\nsns.countplot(x='R', data=test)\nplt.title('Counts of R in test');\nplt.subplot(2, 2, 3)\nsns.countplot(x='C', data=train)\nplt.title('Counts of C in train');\nplt.subplot(2, 2, 4)\nsns.countplot(x='C', data=test)\nplt.title('Counts of C in test');","3e52c761":"fig, ax1 = plt.subplots(figsize = (12, 8))\n\nbreath_1 = train.loc[train['breath_id'] == 1]\nax2 = ax1.twinx()\n\nax1.plot(breath_1['time_step'], breath_1['pressure'], 'r-', label='pressure')\nax1.plot(breath_1['time_step'], breath_1['u_in'], 'g-', label='u_in')\nax2.plot(breath_1['time_step'], breath_1['u_out'], 'b-', label='u_out')\n\nax1.set_xlabel('Timestep')\n\nax1.legend(loc=(1.1, 0.8))\nax2.legend(loc=(1.1, 0.7))\nplt.show()","153a69f2":"# rewritten calculation of lag features from this notebook: https:\/\/www.kaggle.com\/patrick0302\/add-lag-u-in-as-new-feat\n# some of ideas from this notebook: https:\/\/www.kaggle.com\/mst8823\/google-brain-lightgbm-baseline\ntrain['last_value_u_in'] = train.groupby('breath_id')['u_in'].transform('last')\ntrain['u_in_lag1'] = train.groupby('breath_id')['u_in'].shift(1)\ntrain['u_out_lag1'] = train.groupby('breath_id')['u_out'].shift(1)\ntrain['u_in_lag_back1'] = train.groupby('breath_id')['u_in'].shift(-1)\ntrain['u_out_lag_back1'] = train.groupby('breath_id')['u_out'].shift(-1)\ntrain['u_in_lag2'] = train.groupby('breath_id')['u_in'].shift(2)\ntrain['u_out_lag2'] = train.groupby('breath_id')['u_out'].shift(2)\ntrain['u_in_lag_back2'] = train.groupby('breath_id')['u_in'].shift(-2)\ntrain['u_out_lag_back2'] = train.groupby('breath_id')['u_out'].shift(-2)\ntrain = train.fillna(0)\n\n\ntrain['R__C'] = train[\"R\"].astype(str) + '__' + train[\"C\"].astype(str)\n\n# max value of u_in and u_out for each breath\ntrain['breath_id__u_in__max'] = train.groupby(['breath_id'])['u_in'].transform('max')\ntrain['breath_id__u_out__max'] = train.groupby(['breath_id'])['u_out'].transform('max')\n\n# difference between consequitive values\ntrain['u_in_diff1'] = train['u_in'] - train['u_in_lag1']\ntrain['u_out_diff1'] = train['u_out'] - train['u_out_lag1']\ntrain['u_in_diff2'] = train['u_in'] - train['u_in_lag2']\ntrain['u_out_diff2'] = train['u_out'] - train['u_out_lag2']\n# from here: https:\/\/www.kaggle.com\/yasufuminakama\/ventilator-pressure-lstm-starter\ntrain.loc[train['time_step'] == 0, 'u_in_diff'] = 0\ntrain.loc[train['time_step'] == 0, 'u_out_diff'] = 0\n\n# difference between the current value of u_in and the max value within the breath\ntrain['breath_id__u_in__diffmax'] = train.groupby(['breath_id'])['u_in'].transform('max') - train['u_in']\ntrain['breath_id__u_in__diffmean'] = train.groupby(['breath_id'])['u_in'].transform('mean') - train['u_in']\n\n# OHE\ntrain = train.merge(pd.get_dummies(train['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\ntrain = train.merge(pd.get_dummies(train['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\ntrain = train.merge(pd.get_dummies(train['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\n# https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/273974\ntrain['u_in_cumsum'] = train.groupby(['breath_id'])['u_in'].cumsum()\ntrain['time_step_cumsum'] = train.groupby(['breath_id'])['time_step'].cumsum()","a2987d65":"# all the same for the test data\ntest['last_value_u_in'] = test.groupby('breath_id')['u_in'].transform('last')\ntest['u_in_lag1'] = test.groupby('breath_id')['u_in'].shift(1)\ntest['u_out_lag1'] = test.groupby('breath_id')['u_out'].shift(1)\ntest['u_in_lag_back1'] = test.groupby('breath_id')['u_in'].shift(-1)\ntest['u_out_lag_back1'] = test.groupby('breath_id')['u_out'].shift(-1)\ntest['u_in_lag2'] = test.groupby('breath_id')['u_in'].shift(2)\ntest['u_out_lag2'] = test.groupby('breath_id')['u_out'].shift(2)\ntest['u_in_lag_back2'] = test.groupby('breath_id')['u_in'].shift(-2)\ntest['u_out_lag_back2'] = test.groupby('breath_id')['u_out'].shift(-2)\ntest = test.fillna(0)\ntest['R__C'] = test[\"R\"].astype(str) + '__' + test[\"C\"].astype(str)\n\ntest['breath_id__u_in__max'] = test.groupby(['breath_id'])['u_in'].transform('max')\ntest['breath_id__u_out__max'] = test.groupby(['breath_id'])['u_out'].transform('max')\n\ntest['u_in_diff1'] = test['u_in'] - test['u_in_lag1']\ntest['u_out_diff1'] = test['u_out'] - test['u_out_lag1']\ntest['u_in_diff2'] = test['u_in'] - test['u_in_lag2']\ntest['u_out_diff2'] = test['u_out'] - test['u_out_lag2']\ntest.loc[test['time_step'] == 0, 'u_in_diff'] = 0\ntest.loc[test['time_step'] == 0, 'u_out_diff'] = 0\n\ntest['breath_id__u_in__diffmax'] = test.groupby(['breath_id'])['u_in'].transform('max') - test['u_in']\ntest['breath_id__u_in__diffmean'] = test.groupby(['breath_id'])['u_in'].transform('mean') - test['u_in']\n\ntest = test.merge(pd.get_dummies(test['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\ntest = test.merge(pd.get_dummies(test['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\ntest = test.merge(pd.get_dummies(test['R__C'], prefix='R__C'), left_index=True, right_index=True).drop(['R__C'], axis=1)\n\ntest['u_in_cumsum'] = test.groupby(['breath_id'])['u_in'].cumsum()\ntest['time_step_cumsum'] = test.groupby(['breath_id'])['time_step'].cumsum()","d84b8542":"scores = []\nfeature_importance = pd.DataFrame()\nmodels = []\ncolumns = [col for col in train.columns if col not in ['id', 'breath_id', 'pressure']]\nX = train[columns]\ny = train['pressure']","7d82a280":"lgb_params = {'objective': 'regression',\n          'learning_rate': 0.35,\n          \"boosting_type\": \"gbdt\",\n          'min_data_in_leaf':30,\n          'max_bin': 600,\n          'num_leaves':1000,\n          \"metric\": 'mae',\n          'n_jobs': -1\n         }","f3644b90":"params = {'objective': 'regression',\n          'reg_alpha': 0.3311501618830454, 'reg_lambda': 0.2069631986549054, 'num_leaves': 64, 'learning_rate': 0.028472581467083848, 'max_depth': 35, 'n_estimators': 4901, 'min_child_weight': 0.017975228459091965, 'subsample': 0.9011219723450895, 'colsample_bytree': 0.6576034072003352, 'min_child_samples': 80,\n          \"boosting_type\": \"gbdt\",\n          \"metric\": 'mae',\n          'n_jobs': -1\n         }","ad24e001":"'''folds = GroupKFold(n_splits=5)\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y, groups=train['breath_id'])):\n    print(f'Fold {fold_n} started at {time.ctime()}')\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    model = lgb.LGBMRegressor(**params)\n    model.fit(X_train, y_train, \n            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n            verbose=1000, early_stopping_rounds=10)\n    score = metrics.mean_absolute_error(y_valid, model.predict(X_valid))\n    \n    models.append(model)\n    scores.append(score)\n\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = columns\n    fold_importance[\"importance\"] = model.feature_importances_\n    fold_importance[\"fold\"] = fold_n + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)'''","c2f8aba9":"'''print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))'''","8b7f937d":"'''feature_importance[\"importance\"] \/= 5\ncols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n    by=\"importance\", ascending=False)[:50].index\n\nbest_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\nplt.figure(figsize=(16, 12));\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\nplt.title('LGB Features (avg over folds)');'''","68f95194":"xgb_params = {'tweedie_variance_power': 1.6, 'max_depth':5, 'n_estimators': 3200, 'eta': 0.010586132487923238, 'subsample': 0.8, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.9, 'min_child_weight': 0.0003123491275017405, 'reg_lambda': 0.010653307691727407, 'reg_alpha': 0.5037217811537977, 'gamma': 0.0007456156589630464, 'tree_method':'gpu_hist'}","aa166d58":"lgb = LGBMRegressor(**lgb_params)\nxgb = XGBRegressor(**xgb_params)","808cdf72":"from sklearn.ensemble import VotingRegressor\nfolds = GroupKFold(n_splits=5)\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y, groups=train['breath_id'])):\n    print(f'Fold {fold_n} started at {time.ctime()}')\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    model = VotingRegressor(\n            estimators = [\n                ('lgbm', lgb),\n                ('xgb', xgb)\n            ],\n            weights = [0.65, 0.15]\n        )\n    model.fit(X_train, y_train)\n    score = metrics.mean_absolute_error(y_valid, model.predict(X_valid))\n    \n    models.append(model)\n    scores.append(score)","43445c35":"print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","4758d47e":"for model in models:\n    sub['pressure'] += model.predict(test[columns])\nsub['pressure'] \/= 5","2d7f19fe":"sub.to_csv('first_sub.csv', index=False)","771270f4":"## Feature engineering","4555a579":"This is quite interesting: we can see that at first the `pressure` (our target) is rising and then, after the `u_out` becomes equal to 1, it has an abrupt drop. I think it would be useful to create new features based on the behavior of these features.","5648ab5a":"## General information\n\nIn this we work with the data from ventilators connected to a sedated patient's lung. Our goal is to similate the ventilator and correctly predict the airway pressure in the respiratory circuit during the breath.\n\nIt is important to understand that this isn't a usual time-series competition: in time-series tasks we need to predict the future values of the series based on the previous values. Here we use the values of different series to predict the values of other series. So this is a regression task.\n","4e5b9175":"## Data loading and overview","ef77ba07":"## Making predictions","1ea83fba":"**Upvote, if you find this helpful.**","87c77766":"**<h1> Upvote!!, If this notebook is helpful.<\/h1>**","9c037575":"The dataset is quite large - more than 6 mln rows. There are 2 categorical features (R and C), the id of a row, the id of a breath, timestamp and continuous variables.","26736517":"`R` and `C` categorical variables have a similar distribution in train and test data.","bafd31af":"## Model training","1e52f287":"Here is a very **important** point:\nThe breath ids in train and test don't overlap! This means we should use GroupKFold validation using this variable.","1a0d1581":"Now, let's have a look at one of the series in the data."}}