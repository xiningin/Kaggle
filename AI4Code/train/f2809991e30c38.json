{"cell_type":{"1b017ab3":"code","a76278f1":"code","8463c295":"code","bc98369d":"code","c4eae8c9":"code","c4cc024d":"code","d929bfcf":"code","99a2455a":"code","71129be9":"code","96667151":"code","28e85caf":"code","cf1c30cd":"code","dcebd3cc":"code","8331f28f":"code","d6a0c432":"code","068817f8":"code","4b62b8db":"code","1db32a8d":"code","2c8be257":"code","79a5b148":"code","7fa848af":"code","74557a95":"code","92185246":"code","2b45d8b7":"code","182af6ac":"code","8bff87f4":"code","a93c5817":"code","d4789de8":"code","907fca8c":"code","ff567afd":"code","86a46ddf":"code","4454c9a2":"code","214ec3b6":"code","1f008ce8":"code","46999397":"code","1d9bab41":"code","0703298e":"code","2e8d47a9":"code","e0d835fd":"code","c4465664":"code","c5a9a8d5":"code","744f43f1":"code","abc72e4a":"code","e793ebde":"code","cddc39af":"code","c2a5e0c7":"code","e6c02cd3":"markdown","0c54b436":"markdown","335c2bc0":"markdown","44add5b9":"markdown","390fe936":"markdown","a9e9ac55":"markdown","005b62aa":"markdown","caef3744":"markdown","8ceb9f96":"markdown","82cf0236":"markdown","f705273b":"markdown","50e0ef92":"markdown"},"source":{"1b017ab3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport nibabel as nib\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf","a76278f1":"data = pd.read_csv('..\/input\/covid19-ct-scans\/metadata.csv')\ndata.head()","8463c295":"def read_nii(filepath):\n    '''\n    Reads .nii file and returns pixel array\n    '''\n    ct_scan = nib.load(filepath)\n    array   = ct_scan.get_fdata()\n    array   = np.rot90(np.array(array))\n    return(array)","bc98369d":"# Read sample\nk = 19\nsample_ct   = read_nii(data.loc[k,'ct_scan'])\nsample_lung = read_nii(data.loc[k,'lung_mask'])\nsample_infe = read_nii(data.loc[k,'infection_mask'])\nsample_all  = read_nii(data.loc[k,'lung_and_infection_mask'])","c4eae8c9":"sample_all.shape","c4cc024d":"n =sample_all.shape[2] % 2\nn = 40\n\nfig = plt.figure(figsize = (18,15))\nplt.subplot(1,4,1)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.title('Original Image')\n\nplt.subplot(1,4,2)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.imshow(sample_lung[..., n],alpha = 0.5, cmap = 'nipy_spectral')\nplt.title('Lung Mask')\n\nplt.subplot(1,4,3)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.imshow(sample_infe[..., n], alpha = 0.5, cmap = 'nipy_spectral')\nplt.title('Infection Mask')\n\nplt.subplot(1,4,4)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.imshow(sample_all[..., n], alpha = 0.5, cmap = 'nipy_spectral')\nplt.title('Lung and Infection Mask')\n\nplt.show()\n\n\nfig = plt.figure(figsize = (18,15))\nplt.subplot(1,4,1)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.title('Original Image')\n\nplt.subplot(1,4,2)\n\nplt.imshow(sample_lung[..., n])\nplt.title('Lung Mask')\n\nplt.subplot(1,4,3)\n\nplt.imshow(sample_infe[..., n])\nplt.title('Infection Mask')\n\nplt.subplot(1,4,4)\nplt.imshow(sample_all[..., n])\nplt.title('Lung and Infection Mask')","d929bfcf":"im_size = sample_ct[:,:,1].shape","99a2455a":"dd = sample_all[:,:,:].sum(axis=2)\nplt.imshow(dd\/sample_all.shape[2])\nplt.show()\n\nd_size_interes = np.where(dd > 0)\nprint(np.min(d_size_interes,axis=1),np.max(d_size_interes,axis=1))\nprint(len(d_size_interes),d_size_interes[0].shape,d_size_interes[1].shape)","71129be9":"[np.min(d_size_interes,axis=1),np.max(d_size_interes,axis=1)]","96667151":"set(sample_all[:,:,n].reshape((im_size[0]*im_size[1])).tolist())","28e85caf":"set(sample_infe[:,:,n].reshape((im_size[0]*im_size[1])).tolist())","cf1c30cd":"import math","dcebd3cc":"from tensorflow.keras.utils import Sequence\n\nclass DataSequence(Sequence):\n    \"\"\"\n    Keras Sequence object to train a model on a list of csv files\n    data, - csv - data with file name information\n    batch_size=1, - batch size\n    out_chanel = 2, - chanel number\n    w_size = 256 - window size, if w_size = 1, full size\n    in_chanel - number of uf input image on sample\n    \n    \"\"\"\n    def __init__(self, data, batch_size=1, out_chanel = 1, in_chanel = 1, w_size = 256, mode='train'):\n        \"\"\"\n        df = dataframe with 4 columns: the labels and a list of filenames\n        \"\"\"\n        \n        self.bsz = batch_size\n        self.mode = mode\n        self.ind = np.arange(batch_size)\n        \n        # Take labels and a list of image locations in memory\n        self.data = data\n        self.x1 = 0\n        self.x2 = w_size\n        self.y1 = 0\n        self.y2 = w_size\n        self.w = w_size\n        self.chanel = out_chanel\n        self.seqenc = in_chanel \/\/ 2\n        \n\n    def __len__(self):\n        return int(math.ceil((self.data.shape[0]) ))\n\n    def on_epoch_end(self):\n        #print('epoch end:')\n        self.indexes = range(self.data.shape[0])\n        if self.mode == 'train':\n            # Shuffles indexes after each epoch if in training mode\n            self.indexes = np.random.choice(self.indexes, size=len(self.indexes))\n            #print('gen end:')\n            \n\n    def get_batch_labels(self, idx):\n        # Fetch a batch of labels\n        #idx * self.bsz: (idx + 1) * self.bsz\n        #print(idx)\n        imag = read_nii(data.loc[idx,'lung_and_infection_mask'])\n        batch =[]\n        #print(imag.shape)\n        if self.w >1:\n            # RoI\n            d_size_interes = np.where(imag.sum(axis=2) > 0)\n            # choice corner on new select RoI\n            xy_min = np.min(d_size_interes,axis=1)\n            xy_max = np.max(d_size_interes,axis=1)\n            # randon corner\n            conertb = np.random.choce(np.arange(2), size=1)\n            conerrl = np.random.choce(np.arange(2), size=1)\n            self.x1 = xy_min[1]+(xy_max[1]-xy_min[1]-self.w)*conerrl\n            self.x2 = self.w + self.x1\n            self.y1 = xy_min[0]+(xy_max[0]-xy_min[0]-self.w)*conertb\n            self.y2 = self.w + self.y1\n        else:\n            self.x1 = 0 # full size\n            self.x2 = imag.shape[1]\n            self.y1 = 0\n            self.y2 = imag.shape[0]\n            \n        # chanel on label\n        for i in range(imag.shape[2]):\n            \n            imag4 = np.zeros((imag.shape[0],imag.shape[1],self.chanel))\n            #print(imag4.shape,imag.shape)\n            if self.chanel == 1:\n                imag4[:,:,0] = imag[:,:,i]==3 # only infect\n            if self.chanel == 3:\n                imag4[:,:,0] = imag[:,:,i]==0 # all classes\n                imag4[:,:,1] = imag[:,:,i]==1 \n                imag4[:,:,1] = imag[:,:,i]==2 \n                imag4[:,:,2] = imag[:,:,i]==3               \n            if self.chanel == 2:\n                imag4[:,:,0] = imag[:,:,i]==1 # infect + lung\n                imag4[:,:,0] = imag[:,:,i]==2 \n                imag4[:,:,1] = imag[:,:,i]==3\n            # batch RoI\n            batch.append(imag4[self.y1:self.y2,self.x1:self.x2,:])\n        self.ind = np.random.choice(np.arange(1,len(batch)-1), size=self.bsz )\n        #print(type(self.ind))\n        # sampling labels to batch\n        self.segment = np.array(batch)[self.ind].astype(float)    \n        return self.segment\n\n    def get_batch_features(self, idx):\n        # Fetch a batch of inputs\n        imag = read_nii(data.loc[idx,'ct_scan'])\n        imag = imag.transpose([2,0,1])\n        imag = imag \/ np.max(imag)\n        # RoI on image + sampling\n        imag =imag.reshape(imag.shape[0],imag.shape[1],imag.shape[2],1)\n        return imag[self.ind,self.y1:self.y2,self.x1:self.x2,:]\n\n    def __getitem__(self, idx):\n        \n        batch_y = self.get_batch_labels(idx)\n        batch_x = self.get_batch_features(idx)\n        return batch_x, batch_y\n    \n    \n  ","8331f28f":"data_seq = DataSequence(data.iloc[:-2,:],50)\ndata_seq_test = DataSequence(data.iloc[-2:,:],10)\nfor i in range(2):\n    x,y = data_seq[i]\n    print(i,':',x.shape,y.shape)\n","d6a0c432":"n = 2\nfig = plt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\nplt.imshow(x[n,:,:,0])\nplt.subplot(1,3,2)\nplt.imshow(y[n,:,:,0])\nplt.subplot(1,3,3)\nplt.imshow(x[n,:,:,0], cmap = 'bone')\nplt.imshow(y[n,:,:,0], alpha = 0.5, cmap = 'nipy_spectral')\n\nplt.show()","068817f8":"np.max(x)","4b62b8db":"from sklearn.model_selection import train_test_split\n","1db32a8d":"import cv2\nimport skimage.color\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nfrom keras import backend as K\nfrom PIL import Image\nimport tensorflow\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n\n#\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\nfrom tensorflow.keras.layers  import concatenate, add\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","2c8be257":"from tensorflow.python.framework import ops\n\nfrom tensorflow.python.keras.utils import losses_utils\n\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops","79a5b148":"def dice_coef(y_true, y_pred):\n    return (2. * K.sum(y_true * y_pred) + 1.) \/ (K.sum(y_true) + K.sum(y_pred) + 1.)\n\n\ndef focal(y_true, y_pred):\n    alpha = 1\n    gamma = 2\n    \n    num = y_true.shape\n    print(y_true,y_pred)\n\n    \n    y_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)\n    y_true = math_ops.cast(y_true, y_pred.dtype)\n    BCE_loss = tensorflow.keras.losses.CategoricalCrossentropy()\n\n    return K.mean((y_pred - 1)** gamma * alpha * BCE_loss( y_true, y_pred), axis=-1)\n   \n\n\n\n","7fa848af":"\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint","74557a95":"mm = VGG16(input_shape=(256,256,3), include_top=False, weights=\"imagenet\")\nmm.summary()\n        ","92185246":"len(mm.layers)","2b45d8b7":"class Gray2VGGInput( tensorflow.keras.layers.Layer ) :\n    \"\"\"Custom conversion layer\n    \"\"\"\n    def build( self, x ) :\n        self.image_mean = K.variable(value=np.array([103.939, 116.779, 123.68]).reshape([1,1,1,3]).astype('float32'), \n                                     dtype='float32', \n                                     name='imageNet_mean' )\n        self.built = True\n        return\n    def call( self, x ) :\n        rgb_x = K.concatenate( [x,x,x], axis=-1 )\n        #norm_x = rgb_x - self.image_mean\n        return rgb_x\n    def compute_output_shape( self, input_shape ) :\n        return input_shape[:3] + (3,)","182af6ac":"from tensorflow.keras.models import Sequential","8bff87f4":"def unet_pre_train(use_pretrain = True, num_classes = 13, input_shape= (200, 200, 3),level = 3,neuron = 16, lr=0.0001,b1 = 0.9, b2=0.9999):  \n    img_input = Input(shape = input_shape)\n    if use_pretrain :\n        # \u0433\u0440\u0443\u0437\u0438\u043c   VGG16\n        x_in  = Gray2VGGInput( name='gray_to_rgb_norm')( img_input )\n        model_vgg16_3 = VGG16(input_tensor = x_in, input_shape = (input_shape[0],input_shape[1],3),include_top=False, weights=\"imagenet\")\n\n            \n            \n        \n        #y = pre_trained_model(x_in) \n        \n        # \u0437\u0430\u043c\u043e\u0440\u0430\u0436\u0438\u0432\u0430\u0435\u043c \u0432\u0441\u0435 \u0441\u043b\u043e\u0438\n        for layer in model_vgg16_3.layers:\n            layer.trainable = False\n            \n        print('x_in: ',model_vgg16_3.layers)\n        \n        #y_bloc = [y]\n        \n        \n         \n        #print(x_in)\n        #y = pre_trained_model.layers[0](x_in )\n        #print(y)\n        # \u0444\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u0441\u043a\u0438\u043f\u044b \u0434\u043b\u044f \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0430 \u0438\u0437 VGG16 (\u043d\u0430\u0434\u043e \u0435\u0449\u0435 \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0442\u044c)\n        #blocks_ = [ pre_trained_model.layers[2].output]\n        blocks_ =[ model_vgg16_3.layers[2].output]\n        for i in range(level):\n            #blocks_.append( pre_trained_model.layers[5+i*4].output)\n            blocks_.append( model_vgg16_3.layers[5+i*4].output)\n        #block_3_out = pre_trained_model.layers[6].output\n        #block_2_out = pre_trained_model.layers[3].output\n        \n        #  \u0444\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u0432\u0445\u043e\u0434 \u0441\u0435\u0442\u0438\n        \n        \n        \n        # \u0444\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u0440\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u043b\u043e\u0439 \u0434\u043b\u044f \u0441\u0432\u043e\u0435\u0433\u043e \u043f\u043e\u0442\u043e\u043a\u0430  \n        #x = pre_trained_model.layers[level*4+1].output\n        x =  model_vgg16_3.layers[1+level*4].output\n        #x = y_bloc[level*4+2]\n        #print('y:',y_bloc)\n        print('x:',x)\n        \n    else:\n        #x = Conv2D(3, (3, 3), padding='same')(img_input )\n        #pre_trained_model.layers[0].input = x                                      \n        #x = pre_trained_model.layers[0].output\n        x1 = img_input\n        print(x1)\n    \n        blocks_ = []\n        i = 0\n        for i in range(level):\n            x2 = Conv2D(neuron*(i+1), (3, 3), padding='same')(x1)\n            \n            x2 = BatchNormalization()(x2)\n            x2 = Activation('relu')(x2)\n\n            x2 = Conv2D(neuron*(i+1), (1, 1), padding='same')(x2)\n            x2 = BatchNormalization()(x2)\n            x2 = Activation('relu')(x2) \n            \n            x3 = Conv2D(neuron*(i+1), (1, 1), padding='same')(x1)\n            \n            x3 = BatchNormalization()(x3)\n            x3 = Activation('relu')(x3)\n\n            x3 = Conv2D(neuron*(i+1), (3, 3), padding='same')(x3)\n            x3 = BatchNormalization()(x3)\n            x3 = Activation('relu')(x3)\n            \n            x4 = Conv2D(neuron*(i+1), (5, 5), padding='same')(x1)\n            \n            x4 = BatchNormalization()(x4)\n            x4 = Activation('relu')(x4)\n\n            \n            x = concatenate([x2,x3,x4,x1], axis = 3 )\n        \n            blocks4 = x\n            \n            blocks_.append(x)\n            \n    \n            # down i\n            x = MaxPooling2D(padding='same')(x)\n            x1 = x\n            print('i: ',i,x)\n    \n     \n    print('x up:',x)\n    x = Conv2D(neuron*(level+1), (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(neuron*(level+1), (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # \u0437\u0430\u0434\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0441\u043a\u0438\u043f\u043e\u0432\n    print(blocks_)\n    print(x)\n\n    for i in range(level-1,0,-1):\n      # UP i\n      print(i,'x up:',x)\n      x = Conv2DTranspose(neuron*i, (2, 2), strides=(2, 2), padding='same')(x)\n      x = BatchNormalization()(x)\n      x = Activation('relu')(x)\n        \n      x = concatenate([x, blocks_[i]] ) # \u0434\u043e\u0431\u0430\u0432\u0438\u043b\u0438 \u043f\u0435\u0440\u0435\u043d\u043e\u0441 \u0438\u0437 \u043f\u043e\u043d\u0438\u0436\u0430\u044e\u0448\u0435\u0433\u043e \u043f\u043b\u0435\u0447\u0430 \n      x = Conv2D(neuron*i, (3, 3), padding='same')(x)\n      x = BatchNormalization()(x)\n      x = Activation('relu')(x)\n\n      x = Conv2D(neuron*i, (3, 3), padding='same')(x)\n      x = BatchNormalization()(x)\n      x = Activation('relu')(x)\n\n\n    print(x)\n    x = Conv2DTranspose(neuron*i, (2, 2), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    print(-1+i,'x up:',x)    \n    x = concatenate([x, blocks_[0]] ) # \u0434\u043e\u0431\u0430\u0432\u0438\u043b\u0438 \u043f\u0435\u0440\u0435\u043d\u043e\u0441 \u0438\u0437 \u043f\u043e\u043d\u0438\u0436\u0430\u044e\u0448\u0435\u0433\u043e \u043f\u043b\u0435\u0447\u0430 \n    # \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u0441\u043b\u043e\u0439 \u0441\u0432\u0435\u0440\u0442\u043e\u043a \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\n    x = Conv2D(neuron, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    if num_classes>1:\n      x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n      # \u0441\u043e\u0431\u0438\u0440\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \n      print('model:',img_input,x)  \n      model = Model(img_input, x)\n      model.compile(optimizer=Adam(),\n                    loss= 'categorical_crossentropy',#focal, #'\n                    metrics=[dice_coef])\n    else:\n      x = Conv2D(num_classes, (3, 3), activation='sigmoid', padding='same')(x)\n      # \u0441\u043e\u0431\u0438\u0440\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\n      print('model:',img_input,x) \n      model = Model(img_input, x)\n      model.compile(optimizer=Adam(learning_rate=lr, beta_1=b1, beta_2=b2),\n                    loss = 'mse',\n                    metrics=[dice_coef])\n\n    model.summary()\n    # \u0432\u0435\u0440\u043d\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\n    return model","a93c5817":"im_size","d4789de8":"K.clear_session()\nim_size=x[0,:,:,:].shape\nmodel= unet_pre_train(use_pretrain = False,num_classes = 1, input_shape= (im_size[0], im_size[1], im_size[2]), level = 4,neuron = 16)","907fca8c":"from tensorflow.keras.utils import plot_model\n","ff567afd":"plot_model(model,'model1.png')","86a46ddf":"es = EarlyStopping(monitor = ['val_loss'], patience = 3)\nmodch = ModelCheckpoint(monitor='val_loss',mode='min',save_best_only=True,save_weights_only=True,verbose=1,filepath='model.{epoch:02d}-{val_loss:.2f}.h5')","4454c9a2":"#model.load_weights('.\/model.hdf5')\n","214ec3b6":"history1 = model.fit_generator(data_seq, epochs=500, verbose=1,validation_data = data_seq_test) # , callbacks =[es,modch]","1f008ce8":"model.save_weights('model.h5')\n\nmodel.save_weights('model.HDF5')\nmodel.save_weights('model.hdf5')","46999397":"first = False #reset history . If I want long history first = False ","1d9bab41":"if first:\n    history = history1\nelse:\n    history.history['dice_coef'] = history.history['dice_coef']+history1.history['dice_coef']\n    history.history['val_dice_coef'] = history.history['val_dice_coef']+history1.history['val_dice_coef']\n    history.history['loss'] = history.history['loss']+history1.history['loss']\n    history.history['val_loss'] = history.history['val_loss']+history1.history['val_loss']","0703298e":"plt.plot(history.history['dice_coef'])\nplt.plot(history.history['val_dice_coef'])\nplt.title('dice vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('dice')\nplt.legend(['Train', 'Val'], loc = 'upper left')\nplt.show()","2e8d47a9":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Val'], loc = 'upper right')\nplt.show()","e0d835fd":"X,Y = data_seq[0]\nXt,Yt = data_seq_test[0]","c4465664":"predictedt = model.predict(Xt)\nn = 0\nchanel = 0\nfig = plt.figure(figsize = (18,15))\n\nplt.subplot(1,3,1)\nplt.imshow(Xt[n][...,0], cmap = 'bone')\nplt.title('original lung')\n\nplt.subplot(1,3,2)\n#plt.imshow(Xt[n][...,0], cmap = 'bone')\nplt.imshow(Yt[n][...,chanel],alpha = 0.9, cmap = \"nipy_spectral\")\nplt.title('original infection mask')\n\nplt.subplot(1,3,3)\n#plt.imshow(Xt[n][...,0], cmap = 'bone')\nplt.imshow((predictedt[n,:,:,chanel]>predictedt[n,:,:,chanel].mean()*5.0).astype(float),alpha = 0.9,cmap = \"nipy_spectral\")\nplt.title('predicted infection mask')\nplt.show()","c5a9a8d5":"predicted = model.predict(X)\nn = 10\nchanel = 0\nfig = plt.figure(figsize = (18,15))\n\nplt.subplot(1,3,1)\nplt.imshow(X[n][...,0], cmap = 'bone')\nplt.title('original lung')\n\nplt.subplot(1,3,2)\n#plt.imshow(X[n][...,0], cmap = 'bone')\nplt.imshow(Y[n][...,chanel],alpha = 0.9, cmap = \"nipy_spectral\")\nplt.title('original infection mask')\n\nplt.subplot(1,3,3)\n#plt.imshow(X[n][...,0], cmap = 'bone')\nplt.imshow((predicted[n,:,:,chanel]>predicted[n,:,:,chanel].mean()*5.).astype(float),alpha = 0.9,cmap = \"nipy_spectral\")\nplt.title('predicted infection mask')\nplt.show()","744f43f1":"# Read sample - \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a\ndata_seq_test_big_size = DataSequence(data.iloc[-2:,:],20,w_size = 1)\nfor i in range(2):\n    x,y = data_seq_test_big_size[i]\n    print(i,':',x.shape,y.shape)\n","abc72e4a":"# create big model\n\n\n\nim_size=x[0,:,:,:].shape\nmodel_big_size= unet_pre_train(use_pretrain = False,num_classes = 1, input_shape= (im_size[0], im_size[1], im_size[2]), level = 4,neuron = 16)\n","e793ebde":"# loaw weight from model\nmodel_big_size.load_weights('model.h5')","cddc39af":"#test\nXtb,Ytb = data_seq_test_big_size[0]\npredictedtb = model_big_size.predict(Xtb)\nfor i in range(10):\n    n = i\n    chanel = 0\n    fig = plt.figure(figsize = (18,15))\n\n    plt.subplot(1,3,1)\n    plt.imshow(Xtb[n][...,0], cmap = 'bone')\n    plt.title('original lung')\n\n    plt.subplot(1,3,2)\n    #plt.imshow(X[n][...,0], cmap = 'bone')\n    plt.imshow(Ytb[n][...,chanel],alpha = 0.9, cmap = \"nipy_spectral\")\n    plt.title('original infection mask')\n\n    plt.subplot(1,3,3)\n    #plt.imshow(X[n][...,0], cmap = 'bone')\n    plt.imshow((predictedtb[n,:,:,chanel]>predictedtb[n,:,:,chanel].mean()*5.).astype(float),alpha = 0.9,cmap = \"nipy_spectral\")\n    plt.title('predicted infection mask')\n    plt.show()","c2a5e0c7":"model_big_size.evaluate_generator(data_seq_test_big_size,verbose=1)\n","e6c02cd3":"test my generator","0c54b436":"predicted masks","335c2bc0":"Get class label","44add5b9":"\u043e\u0442\u043a\u0430\u043b\u0438\u0431\u0440\u0443\u0435\u043c \u043e\u0442\u0432\u0435\u0442 \u043f\u043e \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u043c\u0443 \u043d\u0430\u0431\u043e\u0440\u0443\n\n\u043f\u0440\u043e\u0441\u0442\u043e \u043f\u043e \u043d\u0435\u0441\u043c\u043a\u043e\u043b\u044c\u043a\u0438\u043c \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u043c \u043f\u043e\u0434\u0431\u0438\u0440\u0430\u044e \u043f\u043e\u0440\u043e\u0433 (\u043c\u043e\u0436\u043d\u043e \u0438 \u043f\u043e\u043b\u0443\u0447\u0448\u0435 \u0441\u0434\u0435\u0434\u0430\u0442\u044c) - predicted[n,:,:,chanel]>predicted[n,:,:,chanel].mean()*5.0","390fe936":"Buil UNet model","a9e9ac55":"\u041f\u043e\u043a\u0430 \u043d\u0435 \u043e\u0447\u0435\u043d\u044c - \u043d\u0443\u0436\u043d\u043e \u0443\u0447\u0438\u0442\u044c","005b62aa":"\u0421\u043e\u0437\u0434\u0430\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u043f\u043e\u043b\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432\u0416\n\n- \u0441\u0442\u0440\u043e\u0438\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043f\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0443 \u0438\u0437 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 (512\u0445512)\n- \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0441\u0435\u0442\u044c UNet+inception \u0434\u043b\u044f \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 512\u0445512\n- \u0433\u0440\u0443\u0437\u0438\u043c \u0432 \u043d\u0435\u0435 \u0432\u0435\u0441\u0430 \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u043e\u0439 \u0441\u0435\u0442\u0438 model\n- \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044e \u043e\u0442\u0432\u0435\u0442\u043e\u0432\n- \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043d\u0435 \u0431\u0435\u0437 \u043e\u0433\u0440\u0435\u0445, \u043d\u043e \u043f\u043e\u0439\u0434\u0435\u0442","caef3744":"\u041f\u043e\u043b\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440","8ceb9f96":"* 0 - background\n* 1 - left\n* 2 - right\n* 3 - infect","82cf0236":"Region of interest\n\n\n- get area with same label\n- set min-max coordinate","f705273b":"## Load Data","50e0ef92":"* 0 - background\n* 1 - infect"}}