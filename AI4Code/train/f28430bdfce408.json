{"cell_type":{"68fec448":"code","75e51c90":"code","32d63de7":"code","b733fd4e":"code","9bc1ef37":"code","250089e5":"code","e3d0cc04":"code","00a82ed7":"code","653585bb":"code","490ed643":"code","629ad74f":"code","40a47e37":"code","14555740":"code","d7804452":"code","8d156857":"code","45a6b7cc":"code","4325c657":"code","88d3146a":"code","63372b1c":"code","acee8214":"code","7f312e83":"code","e2ca1a5e":"code","f69eea75":"code","73524e2d":"code","2277a249":"code","3f33e41a":"code","111e4509":"code","f50eed64":"code","e526e772":"code","81e54808":"code","70699b0b":"code","60defc8f":"code","042c1153":"code","ea6ecd17":"code","15515522":"code","d15695a4":"code","6d0cfd10":"code","f892c1cc":"code","4b8cce1b":"code","4f515c8d":"code","7fa68e11":"code","b1868627":"code","f7dace92":"code","c250503c":"code","8ed80497":"code","cde92f6c":"code","209eaa34":"code","387191da":"code","c2e7e90e":"code","b3a3e3f1":"code","f646ffd6":"code","e1e5f0f2":"code","f46aae68":"code","93454792":"code","0856658b":"code","397c52a1":"code","da536fa8":"code","31f9066b":"code","a379da00":"code","d2d7f024":"code","0efca1fd":"code","3bfe1bcf":"code","adde35b0":"code","ff476aca":"code","0635ebfb":"code","f880e24c":"code","a75b38e1":"code","a7a7bf45":"code","8d27066d":"code","aa8a2e09":"code","8931bbe7":"code","5d4e29ca":"code","6730ca58":"code","10487bdb":"code","eb6b750c":"code","cf6c0b70":"code","71dc4223":"code","deb46c14":"code","c65ddbf1":"code","2d19e4ec":"code","ea7866b2":"code","049a00fa":"code","d1751d55":"code","9efa4877":"code","8c9f340a":"code","4679aa5f":"code","7f680d1b":"code","2313c138":"code","6a567e8c":"code","1568806c":"code","142876d3":"code","2048b6c0":"code","6fc53b71":"code","50a784ff":"code","82a0a83d":"code","282a2877":"code","7d4288d8":"code","6d46c6cb":"code","73911ff5":"code","c24ebfde":"code","15b8bcb0":"code","eef09ec0":"code","3ffe56c9":"code","03d7c471":"code","8433e2d6":"code","41ca3c06":"code","7de5b7dc":"code","5503f16c":"code","792259d8":"code","f13dc448":"code","f780301b":"code","5343a07b":"code","d521a8e8":"code","a51c8628":"code","7f8f41a0":"code","e63dc613":"code","8b8bb8ab":"code","39385b27":"code","0bb62ee9":"code","502d21b4":"code","db45682f":"code","4601a165":"code","b85df571":"code","1e82815d":"code","ee10c69d":"code","327e5fde":"code","8d9cd697":"code","0eec0aaa":"code","bd9f0d3d":"code","c9d70cf4":"code","32e3f3e2":"code","5acf1d70":"code","7bfcf7ac":"code","2e0ee56b":"code","7c1fcc09":"code","0e489737":"code","d8c592f6":"code","913357a1":"code","11af7d66":"code","e5c15619":"code","1c2a1e8f":"code","0c23ad5e":"code","bc5fa9a4":"code","4bee0369":"code","1a3c4612":"code","b35dc491":"code","c9bb9794":"code","06731fca":"code","f323d683":"code","9f240e3b":"code","dff35c62":"code","206ce185":"code","748fd48a":"code","6d5aa8cf":"code","4d8afb6d":"code","83139032":"code","b837300c":"code","a7159ae7":"code","4dbe9c95":"code","c28a7bab":"code","818868c8":"code","e100bf14":"code","3c7285f2":"code","2568ebcd":"code","8b3507ec":"code","2f6ffa25":"code","27dd0091":"code","2b8e9013":"code","2ed319d2":"code","90d02c30":"code","88e64f70":"code","99d621b9":"code","4c981cf0":"code","83e22fb6":"code","2c067444":"code","ffa43c29":"code","d44d041c":"code","9ab7f15d":"code","446219a9":"code","86300d61":"code","d057bcc8":"code","f2f4dd1b":"code","24b861ea":"code","f3b7bf7c":"code","f1e7844b":"code","1816e781":"code","38eec791":"code","4a1cd2c7":"code","2eb4d024":"code","a5d424ff":"code","1a864494":"code","fe7499b4":"code","991b53d5":"code","e23759c2":"markdown","bc2be7cc":"markdown","7b6b3972":"markdown","90035d4e":"markdown","8ddadbb7":"markdown","6f46c624":"markdown","b982fc90":"markdown","77e98ee2":"markdown","34a75e36":"markdown","6ac91ee9":"markdown","e5e5942e":"markdown","4f5ef384":"markdown","ed7392fb":"markdown","3766a083":"markdown","941d9562":"markdown","4029fa2f":"markdown","c6bd331f":"markdown","af324711":"markdown","804d83ec":"markdown","c64c15e3":"markdown","f6f8a8dc":"markdown","b27f9702":"markdown","4b443fe0":"markdown","7d9b0c65":"markdown","d28f7bdd":"markdown","6e5ca427":"markdown","2fda2ba3":"markdown","84fcbf4a":"markdown","854ba8aa":"markdown","6a067dd2":"markdown","32b320b6":"markdown","9bcc3558":"markdown","8b2f3452":"markdown","0bacb430":"markdown","74724644":"markdown"},"source":{"68fec448":"import pandas as pd\nad=pd.read_csv(\"..\/input\/d\/psycronos\/advertising\/Advertising.csv\",usecols=[1,2,3,4]) #usecols indeks problemini cozmek\n                                                                                     #icin kullandim\ndf=ad.copy()\ndf.head()","75e51c90":"len(df)","32d63de7":"#indeksi degisken olarak almis bunu cozucem s\u0131k s\u0131k karsilasilan bir problem\n#df= df.iloc[:,1:len(df)]\n#bunu boyle cozmenin yani sira usecols=[] ilede cozulebilir yukarida uyguladim","b733fd4e":"df.head()","9bc1ef37":"df.info()","250089e5":"df.describe().T           #transpoze unu almak tanimlamayi daha okunur hale getiriyor","e3d0cc04":"#Veri setinde hic null deger varmi onu gormek istiyorum o nedenle birkac yontem var bunu yapabilcegimiz\n#df.isnull().sum()\n#df.isnull().sum().sum()\n#df.isnull().any()\ndf.isnull().values.any()         #hic bos deger varmi varsa true yoksa false dondurur","00a82ed7":"df.corr()       #korelasyonlarini inceledik ","653585bb":"import seaborn as sns\nsns.pairplot(df,kind=\"reg\"); #burda kind=\"reg\" yapmamiz onemli bir tur belirtmeliyiz pairplot oldukca iyi bir grafik ","490ed643":"sns.jointplot(x=\"TV\", y=\"sales\", data=df, kind=\"reg\");","629ad74f":"import statsmodels.api as sm     #istatistiksel anlamli detayli verilere erismek istersek statsmodels kutuphanesi ile\n                                #gerceklestirebiliriz sklearn de erisemeyecegimiz degerlere erisebiliriz istatistik olarak","40a47e37":"X= df[[\"TV\"]]\nX[0:5]","14555740":"X=sm.add_constant(X) #matris islemi icin yapmamiz gerekiyor","d7804452":"X[0:5]","8d156857":"y=df[\"sales\"] #bagimli degiskeni aldik","45a6b7cc":"y[0:5]","4325c657":"lm =sm.OLS(y,X)","88d3146a":"model=lm.fit()","63372b1c":"model.summary() #modelleme ile ilgili tablo olustu bunu yorumlamak biraz istatistik bilgisi istiyor ama is hayatinda\n                #kullanilan ve yeri olan bir tablo","acee8214":"import statsmodels.formula.api as smf\nlm= smf.ols(\"sales~TV\",df)\nmodel=lm.fit()\nmodel.summary()                   #buda gene ayn\u0131 modeli kurar documentation dan ulasabilirsin fakat burdaki farklilik\n                                #degiskenleri boyle \"sales~TV\" isimlendirerek yazabiliriz bagimsiz degisken ilk yazilir","7f312e83":"#katsayilari alip tahmin yapmak icin\nmodel.params     #modelin parametrelerini getirir bunlar beta 0 ve beta 1 sayesinde ulastigimiz degerler","e2ca1a5e":"model.summary().tables[1]     #katsayilarla ilgili tablea ulastik","f69eea75":"model.conf_int()  #modelin guven araliklarina ulasmak ister isek","73524e2d":"model.f_pvalue #modelin anlamliligina iliskin pvalue degerine erisebiliyoruz","2277a249":"print(\"f_pvalue:\",\"%.50f\"%model.f_pvalue) #boyle kac basamaga erisebilecegimizi %.5f(5 basamak) ile secebiliriz \n                                            #ondan sonraki % isareti ise baglamak icin o kismi","3f33e41a":"print(\"fvalue:\",\"%.3f\"%model.fvalue) ","111e4509":"print(\"tvalue:\",\"%.3f\"%model.tvalues[0:1]) ","f50eed64":"#modelin basarisi icin ilk istatistik\nmodel.mse_model #modelin anlamliligna iliskin model degerlendirme istatistiklerine erismek icin\n                #hata cok yuksek cikti yani model cok kotu denebilir","e526e772":"model.rsquared #r^2 degeri aciklanabilirlik orani gercek hayat icin uygun","81e54808":" y[0:5]","70699b0b":"#MODELIN DENKLEMINI YAZDIK BU OLDUKCA ONEMLI BIRSEY\nprint(\"Sales= \"+str(\"%.2f\"% model.params[0])+\" + TV\"+ \"*\" +str(\"%.2f\"%model.params[1])) #model params katsayilariydi\n                                                                                        # a+bX gibi dusunebiliriz denklemi","60defc8f":"g=sns.regplot(df[\"TV\"],df[\"sales\"],ci=None,scatter_kws={\"color\":\"r\",\"s\":9})\ng.set_title(\"Model Denklemi: Sales= 7.03 + TV*0.05\")\ng.set_ylabel(\"Satis Sayisi\")\ng.set_xlabel(\"TV Harcamalari\")\n#plt.xlim(-10,310)\n#plt.ylim(bottom=0);","042c1153":"from sklearn.linear_model import LinearRegression","ea6ecd17":"X=df[[\"TV\"]]\ny=df[\"sales\"]\nreg=LinearRegression()\nmodel=reg.fit(X,y)\nmodel.intercept_\nmodel.coef_","15515522":"model.score(X,y) #bu score r^2 degeridir (basari falan degildir karistirma)","d15695a4":"model.predict(X)[0:10] #sklearn ile kurdugumuz model aracaligiyla tahmin edilen degerlere eristik","6d0cfd10":"7.03 +30*0.04 #ornek burda 8.23 birim satis olacagini tahmin ediyoruz modele 30 birim harcama icin","f892c1cc":"X=df[[\"TV\"]]\ny=df[\"sales\"]\nreg=LinearRegression()\nmodel=reg.fit(X,y)\n","4b8cce1b":"model.predict([[30]]) #burda tum sayilari aldigi icin yukardaki 8.23 den farkli cikti burda virgulden sonraki basamaklar\n                      #da isin icine dahil","4f515c8d":"yeni_veri= [[5],[90],[200]] #burda bir liste olusturduk tahmin islemini liste gondererek yapicaz","7fa68e11":"model.predict(yeni_veri) #boylece tahminlerimiz liste seklinde assagida cikmak oldu","b1868627":"from sklearn.metrics import mean_squared_error, r2_score","f7dace92":"lm=smf.ols(\"sales~TV\",df)\nmodel=lm.fit()        #sklearn icerisinden kurdugumuz modeli guncelledik\nmodel.summary()","c250503c":"mse=mean_squared_error(y,model.fittedvalues)","8ed80497":"mse","cde92f6c":"import numpy as np\nrmse=np.sqrt(mse)","209eaa34":"rmse","387191da":"reg.predict(X)[0:10] #tahmin islemini gerceklestirdik ","c2e7e90e":"y[0:10] #bunlarda gercek degerler simdi 2 sini karsilastiricam","b3a3e3f1":"k_t= pd.DataFrame({\"gercek_y\": y[0:10],\n                   \"tahmin_y\": reg.predict(X)[0:10]                })                    \n                                                  #dictionary yapilarini kullanip gercek ve tahmin degerlerini \n                                                  #karsilastirmak icin bir table olusturacagiz","f646ffd6":"k_t","e1e5f0f2":"k_t[\"hata\"] = k_t[\"gercek_y\"]-k_t[\"tahmin_y\"] #hata oranini gormek icin direkt olarak 2 sini birbirinden cikardim\n                                              #yeni bir sutun olusturdum","f46aae68":"k_t      #eksi degerleri istemiyoruz bu yuzden ya karesini yada mutlak degerini almamiz lazim","93454792":"k_t[\"hata_kare\"]=k_t[\"hata\"]**2","0856658b":"k_t","397c52a1":"np.sum(k_t[\"hata_kare\"]) #toplam hata kare","da536fa8":"np.mean(k_t[\"hata_kare\"]) #ortalama hata karesi","31f9066b":"np.sqrt(np.mean(k_t[\"hata_kare\"])) #hata kareler ortalamasinin karekoku","a379da00":"model.resid[0:10] #modelin artiklari","d2d7f024":"import matplotlib.pyplot as plt\nplt.plot(model.resid);    #burda dikkat etmemeiz gereken -8 e veya 6 7 8 gibi cok yukardaki degerler neden boyle diye\n                        #gidip oralari incelemek bu plot sayesinde aslinda nereye bakmamiz gerektigini kestirebiliriz\n                        #sorun cozme yontemlerinden biride budur","0efca1fd":"import pandas as pd\nad=pd.read_csv(\"..\/input\/d\/psycronos\/advertising\/Advertising.csv\",usecols=[1,2,3,4])\ndf=ad.copy()\ndf.head()","3bfe1bcf":"#X=df.iloc[:,0:3]     #bolme islemini boylede yapabiliriz istersek iloc ile yada assagidaki dropuda kullanabiliriz\n#X                    #iloc kullanmakta onemli documentationdan bakabilirsin","adde35b0":"from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict","ff476aca":"X=df.drop(\"sales\",axis=1) #bagimsiz degisken secmek istiyorum o nedenle sales sutununu dropladim\ny=df[\"sales\"] #bagimli degiskenimiz \n\n#bolme islemlerini gerceklestirecegiz train ve test islemlerimiz icin sklearn kullanarak\nX_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)","0635ebfb":"X_train.shape #X train set","f880e24c":"y_train.shape #y train set 2 side 160 gozlemden olusuyor","a75b38e1":"X_test.shape #testler ise 40 gozlemden olusuyor","a7a7bf45":"y_test.shape       #yani traine %80 teste %20 gibi bir dagilim yapmis olduk (160,40)","8d27066d":"training= df.copy() #veri seklinin bir kopyasini olusturuyoruz ihtiyaca bagli olarak kullanabilmek icin","aa8a2e09":"training.shape","8931bbe7":"lm=sm.OLS(y_train,X_train)","5d4e29ca":"model=lm.fit()\nmodel.summary()         #Gorulecegi uzere ilk modellememize gore R^2 degerimiz artmis\n                        #satis degiskeninin %98 ini acikliyoruz gercek hayat icin cok yuksek bir oran","6730ca58":"model.summary().tables[1]","10487bdb":"lm= LinearRegression()\nmodel=lm.fit(X_train,y_train)","eb6b750c":"model.intercept_ #sabit katsayimiz","cf6c0b70":"model.coef_ #diger katsayilara ulastik","71dc4223":"yeni_veri=[[30],[10],[40]] # 3 degisken icin 3 tane farkli katsayi gondermek lazim \nyeni_veri= pd.DataFrame(yeni_veri).T #dataframe formatina getirdik onemli\nyeni_veri","deb46c14":"model.predict(yeni_veri) #satislarimizin beklenen degeri","c65ddbf1":"rmse=np.sqrt(mean_squared_error(y_train,model.predict(X_train))) #egitim hatasina erisme islemi yapiyoruz","2d19e4ec":"rmse #gercek y degerleri= y_train  \/ gercek degerleri modelleyerek tahmin ettigimiz = X_train bunlar uzerinden bir rmse\n     #degeri elde ettik","ea7866b2":"rmse=np.sqrt(mean_squared_error(y_test,model.predict(X_test))) #test hatasi","049a00fa":"rmse #test seti hatamiza eristik","d1751d55":"df.head()","9efa4877":"X=df.drop(\"sales\",axis=1) \ny=df[\"sales\"] \nX_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)\n\nlm=LinearRegression()\nmodel=lm.fit(X_train,y_train)\nmodel=lm.fit(X_train,y_train)","8c9f340a":"np.sqrt(mean_squared_error(y_train,model.predict(X_train))) #egitim hatamiz","4679aa5f":"np.sqrt(mean_squared_error(y_test,model.predict(X_test))) #test hatamiz","7f680d1b":"model.score(X_train,y_train) ","2313c138":"cross_val_score(model,X_train,y_train,cv=10,scoring=\"r2\").mean() #calisma mantigi icin documentationlara bak","6a567e8c":"np.sqrt(-cross_val_score(model,X_train,y_train,cv=10,scoring=\"neg_mean_squared_error\")).mean() #gercek train hatamiz\n                                                                    #basina - koyma sebebi degerler eksili geliyor\n                                                                    #daha anlasilir hale getiriyoruz","1568806c":"np.sqrt(-cross_val_score(model,X_test,y_test,cv=10,scoring=\"neg_mean_squared_error\")).mean() #gercek test hatamiz","142876d3":"hit= pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\ndf=hit.copy() #ustteki veri setinin bir kopyasini aldik veri seti bozulmasin diye kopya ustunde yapicaz islemleri\ndf=df.dropna()#null degerleri dusurdum\ndf.head()","2048b6c0":"df.info()","6fc53b71":"df.describe().T","50a784ff":"dms=pd.get_dummies(df[[\"League\",\"Division\",\"NewLeague\"]])\ndms.head() #dummy degisken tuzagina dusmemek icin ikincil olarak tekrar eden degiskenleri cikaracagiz","82a0a83d":"y=df[\"Salary\"] #bagimsiz Degisken","282a2877":"X_= df.drop([\"Salary\",\"League\",\"Division\",\"NewLeague\"],axis=1).astype(\"float64\")","7d4288d8":"X_.head() #bagimli degiskeni ve kategorik degiskenlerin ilk hallerini cikarmis oldum","6d46c6cb":"X=pd.concat([X_,dms[[\"League_N\",\"Division_W\",\"NewLeague_N\"]]],axis=1)\nX.head() #bagimsiz degiskenleri dogru bir sekilde modellemeye hazir hale getirdik","73911ff5":"X_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size=0.25, \n                                                    random_state=42)\n\nprint(\"X_train\", X_train.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"X_test\",X_test.shape)\nprint(\"y_test\",y_test.shape)\n\ntraining = df.copy()\n\nprint(\"training\", training.shape)","c24ebfde":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\npca=PCA()","15b8bcb0":"X_reduced_train = pca.fit_transform(scale(X_train))","eef09ec0":"X_reduced_train[0:1,:]","3ffe56c9":"np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)[0:5] \n\n#bunlar 1. bilesenin veri setinde toplam degiskenligin(varyansin) %38 i acikladigi goruluyor\n#2. bilesenin 1. bilesen ile acikladigi varyans %59.88\n#varyans sayisi arttikca aciklama orani artiyor gorulecegi uzere\n#tum degiskenleri ele almaya gerek yok [0:5] 5. degiskene kadar baktigimizda zaten %85 ini aciklayacak duzeye gelmisiz\n\n#veri setini daha az sayida bilesene indirmek goruldugu uzere ise yariyor\n#19 bileseni 5 bilesene indirmis gibi dusunebiliriz","03d7c471":"lm = LinearRegression()","8433e2d6":"pcr_model = lm.fit(X_reduced_train, y_train)","41ca3c06":"pcr_model.intercept_ #sabit degerimiz","7de5b7dc":"pcr_model.coef_  # 19 tane katsayi degerlerimiz\n                 #tum degelere erismis olduz","5503f16c":"y_pred= pcr_model.predict(X_reduced_train)","792259d8":"y_pred[0:5]","f13dc448":"np.sqrt(mean_squared_error(y_train,y_pred)) #train hatamiz","f780301b":"df[\"Salary\"].mean()","5343a07b":"r2_score(y_train,y_pred) #r^2 fonksiyonu kullandik r2_score fonksiyonunu daha once import ettik","d521a8e8":"pca2=PCA()","a51c8628":"X_reduced_test=pca2.fit_transform(scale(X_test))","7f8f41a0":"y_pred= pcr_model.predict(X_reduced_test)","e63dc613":"np.sqrt(mean_squared_error(y_test,y_pred)) #test hatamiz","8b8bb8ab":"lm=LinearRegression()\npcr_model=lm.fit(X_reduced_train[:,0:2],y_train) #[:,0:2] ile 2 bileseni al demek istedik tahmin yaparken hata olmasin\ny_pred=pcr_model.predict(X_reduced_test[:,0:2]) #diye test setindede ayni islemi uyguladik bilesen sayisini degistirir\nprint(np.sqrt(mean_squared_error(y_test,y_pred))) #birbirinden farkli hatalar elde edebiliriz","39385b27":"from sklearn import model_selection","0bb62ee9":"cv_10=model_selection.KFold(n_splits=10,\n                           shuffle=True,\n                           random_state=1)","502d21b4":"lm = LinearRegression()","db45682f":"RMSE=[]","4601a165":"#sklearn de native PCR destegi yok dolayisiyla kendimiz hiber parametre optimizasyonu islemini dongu yazarak\n#rmseleri her olasi bilesende degerlendirip bu islemi kendimiz yapiyor olacagiz\nfor i in np.arange(1,X_reduced_train.shape[1]+1): #buraya cok takilmaya gerek yok cogu islemde fonksiyon hazir var\n    \n    score= np.sqrt( -1*model_selection.cross_val_score(lm,\n                                                        X_reduced_train[:,:i],\n                                                        y_train.ravel(),\n                                                        cv=cv_10,\n                                                        scoring=\"neg_mean_squared_error\"\n                                                       ).mean()\n                  )\n    RMSE.append(score)#bu hata degerlerini elde edip sonra hangi bilesen sayisinin daha az hata olusturdugunu bize sunacak","b85df571":"#yukada donguden elde ettigimiz hata degerlerini olusturdugumuz(RMSE) listeye ekledik simde plot ile gozlemleyecegiz \nplt.plot(RMSE,\"-v\")\nplt.xlabel(\"Bilesen Sayisi\")\nplt.ylabel(\"RMSE\")\nplt.title(\"Maas Tahmin Modeli icin PCR Model Tuning\");\n\n\n","1e82815d":"pcr_model= lm.fit(X_reduced_train[:,0:6],y_train) #pcr modelimizi kurmus olduk","ee10c69d":"y_pred= pcr_model.predict(X_reduced_train[:,0:6])","327e5fde":"print(np.sqrt(mean_squared_error(y_train,y_pred))) #train hata degerimiz 308 cikti","8d9cd697":"y_pred= pcr_model.predict(X_reduced_test[:,0:6])","0eec0aaa":"print(np.sqrt(mean_squared_error(y_test,y_pred))) #test hatamiz 393 cikti","bd9f0d3d":"hit=pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\ndf=hit.copy()\ndf=df.dropna()\nms=pd.get_dummies(df[[\"League\",\"Division\",\"NewLeague\"]])\ny=df[\"Salary\"]\nX_=df.drop([\"Salary\",\"League\",\"Division\",\"NewLeague\"],axis=1).astype(\"float64\")\nX=pd.concat([X_,dms[[\"League_N\",\"Division_W\",\"NewLeague_N\"]]],axis=1)\nX_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)","c9d70cf4":"from sklearn.cross_decomposition import PLSRegression, PLSSVD","32e3f3e2":"pls_model=PLSRegression().fit(X_train,y_train) #modeli olusturduk oldukca basit bir islem ile","5acf1d70":"pls_model.coef_ #katsayilara eristik","7bfcf7ac":"X_train.head()","2e0ee56b":"pls_model.predict(X_train)[0:10]","7c1fcc09":"y_pred=pls_model.predict(X_train)","0e489737":"np.sqrt(mean_squared_error(y_train,y_pred)) #train hatamiz 310 olarak hesaplandi","d8c592f6":"r2_score(y_train,y_pred) #r^2 degerimiz 51 civari cikti","913357a1":"y_pred = pls_model.predict(X_test)","11af7d66":"np.sqrt(mean_squared_error(y_test,y_pred)) #test hatamiz 398","e5c15619":"#CV Cross Validation yontemimizi kullaniyoruz assagida skorlari hesaplamak icin kullanacagiz\ncv_10 = model_selection.KFold(n_splits=10, shuffle=True, random_state=1)\n\n\n#Hata hesaplamak i\u00e7in d\u00f6ng\u00fc\nRMSE = []\n\nfor i in np.arange(1, X_train.shape[1] + 1):\n    pls = PLSRegression(n_components=i)\n    score = np.sqrt(-1*cross_val_score(pls, X_train, y_train, cv=cv_10, scoring='neg_mean_squared_error').mean())\n    RMSE.append(score)\n\n#Sonu\u00e7lar\u0131n G\u00f6rselle\u015ftirilmesi\nplt.plot(np.arange(1, X_train.shape[1] + 1), np.array(RMSE), '-v', c = \"r\")\nplt.xlabel('Bile\u015fen Say\u0131s\u0131')\nplt.ylabel('RMSE')\nplt.title('Salary');                                     #Gorulecegi uzere 2 olmasi gerekiyor bilesen sayisinin en dusuk RMSE (hata degeri) orda elde ediliyor","1c2a1e8f":"pls_model = PLSRegression(n_components = 2).fit(X_train, y_train) ","0c23ad5e":"y_pred = pls_model.predict(X_test)","bc5fa9a4":"np.sqrt(mean_squared_error(y_test, y_pred))","4bee0369":"hit = pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\nms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","1a3c4612":"from sklearn.linear_model import Ridge","b35dc491":"ridge_model = Ridge(alpha = 0.1).fit(X_train, y_train) #Ridge modelimizi kurduk","c9bb9794":"ridge_model","06731fca":"ridge_model.coef_ #alpha 1 oldugundaki katsayilarimiz","f323d683":"10**np.linspace(10,-2,100)*0.5 #cesitli lambda degerleri olusturduk\n\n                                #katsayilara ceza uygulama islemi yapacagiz. Bu cezanin siddetini lambda degeleri belirliyor\n                     #bu nedenle katsayilarda nasil degisikler geldigini gozlemlememiz gerekiyor lambda degerleri icin bu sayede lambdayi belirleyebilelim\n                                    ","9f240e3b":"lambdalar = 10**np.linspace(10,-2,100)*0.5 \n\nridge_model = Ridge()\nkatsayilar = []\n\nfor i in lambdalar:                  #sira sira tum lambda degerlerini alphaya atiyoruz i in lambdalar demek i sira sira tum lambda degelerine es oluyor demek\n    ridge_model.set_params(alpha = i) #bu sayede alpha degerlerini deneyebiliriz dongu icinde\n    ridge_model.fit(X_train, y_train) \n    katsayilar.append(ridge_model.coef_) \n    \n\n    \nax = plt.gca()\nax.plot(lambdalar, katsayilar) \nax.set_xscale('log') \n\nplt.xlabel('Lambda(Alpha) De\u011ferleri')\nplt.ylabel('Katsay\u0131lar\/A\u011f\u0131rl\u0131klar')\nplt.title('D\u00fczenlile\u015ftirmenin Bir Fonksiyonu Olarak Ridge Katsay\u0131lar\u0131');","dff35c62":"y_pred=ridge_model.predict(X_test)","206ce185":"np.sqrt(mean_squared_error(y_test,y_pred))","748fd48a":"r2_score(y_test,y_pred) #testin r^2 degeri\n\n#y_pred=ridge_model.predict(X_train)\n#r2_score(y_train,y_pred)                 #komutlariyla trainin r^2 degerinede bakabilirsin","6d5aa8cf":"lambdalar= 10**np.linspace(10,-2,100)*0.5","4d8afb6d":"lambdalar[0:5]","83139032":"from sklearn.linear_model import RidgeCV\nridge_cv= RidgeCV(alphas=lambdalar,scoring= \"neg_mean_squared_error\",normalize=True) #modelimizi olusturduk alttada fit edecegiz","b837300c":"ridge_cv.fit(X_train,y_train)","a7159ae7":"ridge_cv.alpha_ #optimum lambda degerimizi elde ettik yukaridaki fonksiyonlari(RidgeCV) kullanarak","4dbe9c95":"rige_tuned= Ridge(alpha=ridge_cv.alpha_,\n                 normalize=True).fit(X_train,y_train)       #tune edilmis, final modelimizi kurduk bu sefer fiti direkt burada cagirdim","c28a7bab":"np.sqrt(mean_squared_error(y_test,rige_tuned.predict(X_test))) #test hatamizi 386 olarak hesapladik","818868c8":"hit = pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\nms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","e100bf14":"from sklearn.linear_model import Lasso","3c7285f2":"lasso_model = Lasso(alpha = 0.1).fit(X_train, y_train) #modelimizi olusturduk","2568ebcd":"lasso_model.coef_ #modelin katsayilari","8b3507ec":"lasso = Lasso()\nlambdalar = 10**np.linspace(10,-2,100)*0.5 \nkatsayilar = []\n\nfor i in lambdalar:\n    lasso.set_params(alpha=i)\n    lasso.fit(X_train, y_train)\n    katsayilar.append(lasso.coef_)\n    \nax = plt.gca()\nax.plot(lambdalar*2, katsayilar)\nax.set_xscale('log')\nplt.axis('tight')\nplt.xlabel('alpha')\nplt.ylabel('weights')","2f6ffa25":"lasso_model.predict(X_test)","27dd0091":"y_pred = lasso_model.predict(X_test)       #test tahmin degerimiz simdi bunu y_test degerleriyle karsilastirip \n                                #diger modellerde oldugu gibi hatayi bulacagiz (biryerden sonra isleyis ayni ilerliyor)","2b8e9013":"np.sqrt(mean_squared_error(y_test, y_pred))      #test hatamiz 356 cikti tahmin sonucunda","2ed319d2":"from sklearn.linear_model import LassoCV","90d02c30":"lasso_cv_model= LassoCV(alphas=None,cv=10,\n                        max_iter=10000,\n                        normalize=True).fit(X_train,y_train)   #sonda fit ederek modeli olusturmayi tamamladik","88e64f70":"lasso_cv_model #fonksiyon icinde yaptigimiz default disi atamalar","99d621b9":"lasso_cv_model.alpha_ #optimum alpha degerimizi elde ettik","4c981cf0":"lasso_tuned = Lasso(alpha=lasso_cv_model.alpha_)","83e22fb6":"lasso_tuned.fit(X_train,y_train)","2c067444":"y_pred=lasso_tuned.predict(X_test)","ffa43c29":"np.sqrt(mean_squared_error(y_test,y_pred)) #356 degerine eristik ridge regresyonda 386 idi yani ridge regresyona gore\n                                           #lasso regresyon modelimiz biraz daha basarili diyebiliriz","d44d041c":"hit = pd.read_csv(\"..\/input\/hitters\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\nms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)\n\n\n","9ab7f15d":"from sklearn.linear_model import ElasticNet","446219a9":"enet_model = ElasticNet().fit(X_train, y_train)","86300d61":"enet_model.coef_","d057bcc8":"enet_model.intercept_","f2f4dd1b":"enet_model","24b861ea":"enet_model.predict(X_test)","f3b7bf7c":"y_pred = enet_model.predict(X_test)","f1e7844b":"np.sqrt(mean_squared_error(y_test, y_pred)) #test hatamiz","1816e781":"r2_score(y_test, y_pred) #aciklanabilirdik oranimiz 0.41 olarak geldi","38eec791":"from sklearn.linear_model import ElasticNetCV","4a1cd2c7":"enet_cv_model = ElasticNetCV(cv = 10, random_state = 0).fit(X_train, y_train)","2eb4d024":"enet_cv_model.alpha_","a5d424ff":"enet_cv_model","1a864494":"enet_tuned = ElasticNet(alpha = enet_cv_model.alpha_).fit(X_train,y_train)","fe7499b4":"y_pred = enet_tuned.predict(X_test)","991b53d5":"np.sqrt(mean_squared_error(y_test, y_pred))","e23759c2":"## Model Tuning","bc2be7cc":"# Ridge Regresyon","7b6b3972":"### Simdi diger modellerde oldugu gibi alpha degerimiz ile modeli tune edip final modeli olusturacagiz","90035d4e":"## Model Tuning","8ddadbb7":"## Statsmodels","6f46c624":"# Artiklar Ve Makine Ogrenmesindeki Onemi","b982fc90":"## Tahmin\nModel Denklemi:\n\nSales=7.03+TV*0.04\n\nOrnegin 30 birim TV harcamasi oldugunda satislarin tahmini degeri ne olur ?","77e98ee2":"## Tahmin","34a75e36":"# \u00c7oklu Do\u011frusal Regresyon","6ac91ee9":"**k\u0131saca yaptigimiz veri setini 19 degisken varken boyutu indirgedik. Indirgenmis boyut uzerinden,indirgenmis veri seti uzerine dogrusal regresyon fit ettik**","e5e5942e":"## Model","4f5ef384":"### optimum lambda degeriyle final degerini olusturucaz simdi","ed7392fb":"yapmak istedigimiz optimum bilesen sayisini elde etmek hata orani icin","3766a083":"## Statsmodels ile Modelleme","941d9562":"## Model Tuning","4029fa2f":"## Model Tuning","c6bd331f":"# Model Tuning\/ Model Do\u011frulama","af324711":"# SKLEARN ILE MODELLEME","804d83ec":"## Tahmin\nModel Denklemi:\n\nSales= 2.97 + TV*0.04+radio*0.18+newspaper*0.002\n\nOrnegin 30 birim TV harcamasi, 10 birim radio harcamasi, 40 birimde gazete harcamasi oldugunda satislarin tahmini degeri ne olur ?","c64c15e3":"### Final modeli olusturuyoruz suan optimum bilesen sayisi ile\n(NOT: Yukarida sansa on tanimli deger n_components i 2 olarak almis o yuzden altta hata degerinde bir degisiklik olmadi)","f6f8a8dc":"# Lasso Regresyon","b27f9702":"## Tahmin","4b443fe0":"# ElasticNet Regresyonu\nDiger regresyon modellerinde oldugu gibi ayni prosedurleri izleyip en sonda tuning islemini uyguladim","7d9b0c65":"## Tahmin","d28f7bdd":"### modelin tahmin basarisini ogrenmek istiyorsak:","6e5ca427":"## Tahmin","2fda2ba3":"## Tahmin","84fcbf4a":"## Model Tuning","854ba8aa":"# PLS\n\n## Model","6a067dd2":"## Scikit-Learn model","32b320b6":"## Stats Model Sonu","9bcc3558":"# PCR Model","8b2f3452":"# Simple Linear Regression","0bacb430":"### Amacimiz aslinda bu alttaki hata degerlerini optimize etmektir bunlari optimize etmekle ugrasmak onemli","74724644":"Optimum bilesen sayisiyla final modelini olusturmamiz gerekiyor 6 goruldugu uzere en az hataya sebep oluyor biz bu islemi **TRA\u0130N** seti uzerinden yaptik bu detay onemli"}}