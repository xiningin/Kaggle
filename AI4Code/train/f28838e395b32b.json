{"cell_type":{"109e852a":"code","7ed0b1ca":"code","dc8ce618":"code","5adfaa0d":"code","c87f426e":"code","f50ff5d6":"code","3350430d":"code","fd78fab1":"code","8e660b80":"code","778bcf93":"code","3bfa260a":"code","0bfb183c":"code","cfe23f53":"code","47336b8a":"code","f17c7c25":"code","202e607d":"code","65695509":"code","c22bf489":"code","b60b7e95":"markdown","86667346":"markdown","673650e9":"markdown"},"source":{"109e852a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/digit-recognizer\/train.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ed0b1ca":"df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')","dc8ce618":"df.head(10)","5adfaa0d":"# save the labels into l\nl = df['label']\n","c87f426e":"# store the pixel into d, except l\nd = df.drop(\"label\", axis=1)\n# d","f50ff5d6":"# check shape\nprint(l.shape)\nprint(d.shape)","3350430d":"import matplotlib.pyplot as plt\n\n# display number\nplt.figure(figsize=(7,7))\nidx=1\n\n# reshape pixel from 1d to 2d pixel array\ngrid = d.iloc[idx].to_numpy().reshape(28, 28)\nplt.imshow(grid, interpolation=\"none\", cmap=\"gray\")\nplt.show()\n\nprint(l[idx])","fd78fab1":"labels = l.head(42000)\ndata = d.head(42000)\n\nprint(\"shape of sample data =\" , data.shape)","8e660b80":"# Standardizing the data\nfrom sklearn.preprocessing import StandardScaler\nstandardized_data = StandardScaler().fit_transform(data)\nprint(standardized_data.shape)","778bcf93":"# Find Co-varience matrix A^T * A\n\nsample_data = standardized_data\n\ncovar_mat = np.matmul(sample_data.T, sample_data)\nprint('shape of varience matrix =', covar_mat.shape)","3bfa260a":"# finding the top two eigen-values and corresponding eigen-vectors \n# for projecting onto a 2-Dim space.\nfrom scipy.linalg import eigh\n\nvalues, vectors = eigh(covar_mat, eigvals=(782, 783))\nvectors = vectors.T\n\nprint('shape of eigen vectors = ', vectors.shape)\n","0bfb183c":"new_cor = np.matmul(vectors, sample_data.T)\nprint('resultant new data points shape', vectors.shape, \"X\", \n                             sample_data.T.shape, \" = \", new_cor.shape)","cfe23f53":"# appending label to 2D projected data\nnew_cor = np.vstack((new_cor, labels)).T\n\n# create new DF for plotting labelled points\ndataF = pd.DataFrame(data=new_cor, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\ndataF\n#print(dataF.head())","47336b8a":"import seaborn as sn\nsn.FacetGrid(dataF, hue=\"label\", size=6).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\nplt.show()","f17c7c25":"from sklearn import decomposition\npca = decomposition.PCA(n_components=2)","202e607d":"pca_data = pca.fit_transform(sample_data)\n\npca_data.shape","65695509":"# attach label for each 2-d dataPoints\npca_data = np.vstack((pca_data.T, labels)).T\n\npca_df = pd.DataFrame(data=pca_data, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\nsn.FacetGrid(pca_df, hue=\"label\", size=6).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\nplt.show()","c22bf489":"pca.n_components=784\npca_data = pca.fit_transform(sample_data)\n\nper_var_explained = pca.explained_variance_ \/ np.sum(pca.explained_variance_)\n\ncum_var_explained = np.cumsum(per_var_explained)\n\n# plot PCA spectrum\nplt.figure(1, figsize=(6, 4))\n\nplt.clf()\nplt.plot(cum_var_explained, linewidth=2)\nplt.axis('tight')\nplt.grid()\nplt.xlabel('n_components')\nplt.ylabel('Cumulative_explained_varience')\nplt.show()","b60b7e95":"# PCA for Dim. Reduction\n","86667346":"# PCA using Sklearn lib","673650e9":"# 2D Visualization using PCA (Taking first 10k data-points)\n\n"}}