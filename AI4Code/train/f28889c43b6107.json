{"cell_type":{"5e1fabbe":"code","ee75d0d9":"code","22dc1f07":"code","28a3e3f3":"code","0cc745e3":"code","553340a8":"code","89aa8d79":"code","85c9442a":"code","158f1ad8":"code","2534396f":"code","84e33669":"code","2dc31792":"code","82a1b7c7":"code","439f8933":"code","944801cb":"code","68ea87e1":"code","9cfdc51a":"code","6acb3d24":"code","62594da9":"markdown","77fcf387":"markdown"},"source":{"5e1fabbe":"!pip install pydotplus","ee75d0d9":"import pandas as pd\nimport seaborn as sb\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, accuracy_score\nfrom six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz, plot_tree\nimport pydotplus\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.metrics import silhouette_score\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\n\nfrom collections import Counter","22dc1f07":"import matplotlib.pyplot as plt\nimport pandas as pd\nfrom pandas import read_csv\nfrom pandas import set_option\nimport seaborn as sb\nimport numpy as np\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn import metrics\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline","28a3e3f3":"#CARGA DOS DADOS DE SOLICITACOES DE CREDITO\nurl = '\/kaggle\/input\/solicitacoes-credito\/solicitacoescredito.csv'\ndataset = pd.read_csv(url)\n\n#NOMENCLATURA DAS COLUNAS\ndataset.columns = [ 'numero_solicitacao', 'razaoSocial', 'nomeFantasia', 'cnpjSemTraco', 'maiorAtraso', 'margemBrutaAcumulada', 'percentualProtestos', 'primeiraCompra', 'prazoMedioRecebimentoVendas', 'titulosEmAberto', 'valorSolicitado', 'status', 'definicaoRisco', 'diferencaPercentualRisco', 'percentualRisco', 'dashboardCorrelacao', 'valorAprovado', 'dataAprovadoEmComite', 'periodoBalanco', 'ativoCirculante', 'passivoCirculante', 'totalAtivo', 'totalPatrimonioLiquido', 'endividamento', 'duplicatasAReceber', 'estoque', 'faturamentoBruto', 'margemBruta', 'periodoDemonstrativoEmMeses', 'custos', 'anoFundacao', 'intervaloFundacao', 'capitalSocial', 'restricoes', 'empresa_MeEppMei', 'scorePontualidade', 'limiteEmpresaAnaliseCredito', 'dataAprovadoNivelAnalista']\ndataframe = dataset.copy(deep = True)\n\n# VERIFICA INFORMACOES SOBRE O DATASET\ndataframe.info()\n\n\n#REMOCAO DE CAMPOS QUE N\u00c3O TEM RELEV\u00c2NCIA NA TOMADA DE DECIS\u00c3O\n\n# DROP avaliando os campos (Com foco na opera\u00e7\u00e3o e n\u00e3o no cliente)\ndataframe = dataframe.drop(['cnpjSemTraco', 'razaoSocial', 'nomeFantasia', 'diferencaPercentualRisco', 'status'], 1) \n\n# DROP depois de analise de correlacao\n# Voltar as informa\u00e7\u00f5es de 'maiorAtraso', 'scorePontualidade', 'margemBrutaAcumulada', pois a base est\u00e1 completa\ndataframe = dataframe.drop(['prazoMedioRecebimentoVendas', 'numero_solicitacao', \n                            'dashboardCorrelacao', 'valorSolicitado', 'percentualProtestos','valorAprovado', 'primeiraCompra',\n                            'empresa_MeEppMei'], 1)\n# DROP de valores OBJECT nao relevantes\ndataframe = dataframe.drop(['dataAprovadoEmComite','intervaloFundacao', 'dataAprovadoNivelAnalista', 'periodoBalanco'], 1)\n\n# DROP ap\u00f3s avalia\u00e7\u00e3o de outliers \/ correla\u00e7\u00e3o\ndataframe = dataframe.drop(['ativoCirculante','totalAtivo', 'passivoCirculante', 'estoque', 'totalPatrimonioLiquido', 'endividamento', 'duplicatasAReceber'], 1)\n\n# DROP para iniciar standard Scaler\ndataframe = dataframe.drop(['restricoes'], 1)\n\n\n\n#AUMENTAR O NUMERO DE COLUNAS APRESENTADAS \npd.set_option('max_columns', None)\n\n#VERIFICACAO DA VARIAVEL RELEVANTE (STATUS)\n# na nossa analise e importante avaliar se o pedido foi aprovado ou nao\n# nao ha status em branco (100% non-null)\n# a variavel status e um object, precisamos avaliar quantas sao as possibilidades \n#sb.set(rc={'figure.figsize':(20,3)})\n#sb.countplot(x='status',data=dataframe, palette='hls')\n\n\n\n#Replace das categorias\ndataframe.replace(to_replace='De 0 a 10 % - Muito Baixo', value = '1', inplace = True)\ndataframe.replace(to_replace='De 11 a 30 % - Baixo', value = '2', inplace = True)\ndataframe.replace(to_replace='De 31 a 50 % - M\u00e9dio', value = '3', inplace = True)\ndataframe.replace(to_replace='De 51 a 80 % - Alto', value = '4', inplace = True)\n\n#Exercicio 1 -  status n\u00e3o relevante na clusterizacao de clientes\n##ONE HOT ENCODING para STATUS - variavel n\u00e3o \u00e9 bin\u00e1ria\n#status_dmy = pd.get_dummies(dataframe['status'], prefix='STATUS')\n#dataframe = pd.concat([dataframe, status_dmy], axis = 1)\n\n#ONE HOT ENCODING para RISCO - variavel n\u00e3o \u00e9 bin\u00e1ria\nrisco_dmy = pd.get_dummies(dataframe['definicaoRisco'], prefix='RISCO')\ndataframe = pd.concat([dataframe, risco_dmy], axis = 1)\n\n\ndataframe = dataframe.drop(['definicaoRisco'], 1)\ndataframe.info()\n\n\n#VERIFICA QUAIS COLUNAS EST\u00c3O MISSING VALUES\ndataset.isnull().sum()\n\n#PREENCHIMENTO DE CAMPOS VAZIOS\n#dataset.fillna(method ='ffill', inplace = True) \n\ndataframe['faturamentoBruto'] = dataframe['faturamentoBruto'].fillna(dataframe['faturamentoBruto'].mean()).astype(np.int64, errors='ignore')\ndataframe['margemBruta'] = dataframe['margemBruta'].fillna(dataframe['margemBruta'].mean()).astype(np.int64, errors='ignore')\ndataframe['periodoDemonstrativoEmMeses'] = dataframe['periodoDemonstrativoEmMeses'].fillna(dataframe['periodoDemonstrativoEmMeses'].mean()).astype(np.int64, errors='ignore')\ndataframe['custos'] = dataframe['custos'].fillna(dataframe['custos'].mean()).astype(np.int64, errors='ignore')\ndataframe['capitalSocial'] = dataframe['capitalSocial'].fillna(dataframe['capitalSocial'].mean()).astype(np.int64, errors='ignore')\ndataframe['limiteEmpresaAnaliseCredito'] = dataframe['limiteEmpresaAnaliseCredito'].fillna(dataframe['limiteEmpresaAnaliseCredito'].mean()).astype(np.int64, errors='ignore')\ndataframe['anoFundacao'] = dataframe['anoFundacao'].fillna(dataframe['anoFundacao'].mean()).astype(np.int64, errors='ignore')\n\n# Removido ap\u00f3s an\u00e1lise de outliers\n#dataframe['ativoCirculante'] = dataframe['ativoCirculante'].fillna(dataframe['ativoCirculante'].mean()).astype(np.int64, errors='ignore')\n#dataframe['passivoCirculante'] = dataframe['passivoCirculante'].fillna(dataframe['passivoCirculante'].mean()).astype(np.int64, errors='ignore')\n#dataframe['totalAtivo'] = dataframe['totalAtivo'].fillna(dataframe['totalAtivo'].mean()).astype(np.int64, errors='ignore')\n\n#dataframe['estoque'] = dataframe['estoque'].fillna(dataframe['estoque'].mean()).astype(np.int64, errors='ignore')\n#dataframe['periodoBalanco'] = dataframe['periodoBalanco'].fillna(dataframe['periodoBalanco'].mean()).astype(np.int64, errors='ignore')\n#dataframe['totalPatrimonioLiquido'] = dataframe['totalPatrimonioLiquido'].fillna(dataframe['totalPatrimonioLiquido'].mean()).astype(np.int64, errors='ignore')\n#dataframe['endividamento'] = dataframe['endividamento'].fillna(dataframe['endividamento'].mean()).astype(np.int64, errors='ignore')\n#dataframe['duplicatasAReceber'] = dataframe['duplicatasAReceber'].fillna(dataframe['duplicatasAReceber'].mean()).astype(np.int64, errors='ignore')\n\n#dataframe['restricoes'] = dataframe['restricoes'].fillna(False)\n\n\n#VERIFICA QUAIS COLUNAS EST\u00c3O MISSING VALUES\ndataframe.isnull().sum()","0cc745e3":"sb.set(rc={'figure.figsize':(20,3)})\nsb.countplot(x='definicaoRisco',data=dataframe, palette='hls')\n\nsb.set(rc={'figure.figsize':(20,3)})\nsb.countplot(x='restricoes',data=dataframe, palette='hls')","553340a8":"# Descri\u00e7\u00e3o dos dados\nset_option('precision', 2)\ndataframe.describe()","89aa8d79":"# Outlier detection \n\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    df\n    features\n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5* IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n        \n    # select observations containing more than n outliers\n    outlier_indices = Counter(outlier_indices) \n    #print(outlier_indices)\n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n        \n\n    \n    \n    return multiple_outliers   \n\n\n#print(dataframe.maiorAtraso[5354])\ndataframe_2 = dataframe.copy(deep = True)\n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(dataframe_2,1,['maiorAtraso','titulosEmAberto','faturamentoBruto','margemBruta','periodoDemonstrativoEmMeses',\n                                                  'custos','anoFundacao','capitalSocial','scorePontualidade','limiteEmpresaAnaliseCredito'])\n\n\n\n#Outliers_to_drop\n#Outliers_to_drop\ndataframe_2 = dataframe_2.loc[Outliers_to_drop]\n\ndataframe_2 = dataframe_2.loc[dataframe_2['maiorAtraso'] < 500]\ndataframe_2 = dataframe_2.loc[dataframe_2['anoFundacao'] > 1800]\ndataframe_2 = dataframe_2.loc[dataframe_2['margemBruta'] > 0]\ndataframe_2 = dataframe_2.loc[dataframe_2['custos'] > 0]\n\ndataframe_2.describe()\n\n","85c9442a":"#scatterplot\nsb.set()\n\ncols = ['maiorAtraso', 'margemBrutaAcumulada', 'titulosEmAberto', 'percentualRisco', 'faturamentoBruto', 'margemBruta', 'periodoDemonstrativoEmMeses', 'custos', 'anoFundacao', 'capitalSocial', 'scorePontualidade', 'limiteEmpresaAnaliseCredito']\n\nsb.pairplot(dataframe_2[cols], height = 2.5)\nplt.show();","158f1ad8":"#box plot overallqual\/saleprice\nvar = 'RISCO_1'\ndata = pd.concat([dataframe_2['maiorAtraso'], dataframe_2[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y='maiorAtraso', data=data)\nfig.axis(ymin=0, ymax=200);\n\n","2534396f":"#Avalia\u00e7\u00e3o do histograma\ndataframe_2.hist(bins=20,figsize=(35,35),grid=False)","84e33669":"#Avalia\u00e7\u00e3o do histograma\ndataframe.hist(bins=20,figsize=(35,35),grid=False)","2dc31792":"# BUSCA VARIAVEIS OBJECT\ns = (dataframe.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Variaveis object:\")\nprint(object_cols)","82a1b7c7":"#Verifica a correla\u00e7\u00e3o entre as vari\u00e1veis da base de pedidos\n\ndataframe_2=dataframe.copy(deep=True)\nplt.figure(figsize=(20, 10))\ncorr = dataframe.corr(method='pearson')\nsb.heatmap(corr, annot=True)","439f8933":"#Normaliza os Dados:\nscaler_class = StandardScaler().fit(dataframe.values)\nprint(\"M\u00e9dia do DF n\u00e3o normalizado: {}\".format(np.mean(dataframe.values))) \nprint(\"Desvio padr\u00e3o do DF n\u00e3o normalizado: {}\".format(np.std(dataframe.values)))\nX_train_class = scaler_class.transform(dataframe.values)\n# Print the mean and standard deviation of the scaled features\nprint(\"M\u00e9dia do DF normalizado: {}\".format(np.mean(X_train_class))) \nprint(\"Desvio padr\u00e3o do DF normalizado: {}\".format(np.std(X_train_class)))\nX_train_class[1]\n\n ","944801cb":"dataframe.describe()\n    \n    ","68ea87e1":"\nprint(dataframe_2.shape)\nprint(dataframe_2.describe())\nplt.pyplot.show()\n","9cfdc51a":"X = StandardScaler().fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=25)\n\n\n\nclassificador = SVC(kernel=\"sigmoid\", gamma=2)\n#classificador = SVC(gamma=2, C=1)\nclassificador.fit(X_train, y_train)\ny_pred = classificador.predict(X_test)\n\n\nprint(classification_report(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nplot_confusion_matrix(classificador, X_test, y_test, normalize = 'true')\n\n\n\n\nAvalia\u00e7\u00e3o do histograma\ndataframe_2.hist(bins=20,figsize=(35,35),grid=False)","6acb3d24":"\n#Normaliza os Dados:\nscaler = StandardScaler() \ndataframe_2_norm = scaler.fit_transform(dataframe_2) \n\n\n#TODO - procurar o melhor valor de k para a fazer a Clusteriza\u00e7\u00e3o com o M\u00e9todo Elbow, execute para um k entre 1 e 25\nscores = []\ninertias =[]\nfor i in tqdm( range(2, 25)):\n    kmeans = KMeans(n_clusters = i, max_iter=100).fit(dataframe_2_norm)    \n    #soma dos quadrados intra-clusters de cada cluster\n    inertias.append(kmeans.inertia_)\n    scores.append( silhouette_score(dataframe_2.values, kmeans.labels_))\n\n\n    \nplt.figure(1)\nplt.plot(range(2, 25), inertias)\nplt.title('O Metodo Elbow')\nplt.xlabel('No de clusters')\nplt.ylabel('WSS - within cluster sum of squares')\nplt.show()\n\nplt.figure(2)\nplt.bar(range(2, 25), scores,  align='center', alpha=0.5)\nplt.title('O Metodo Silhouette Score')\nplt.xlabel('No de clusters')\nplt.ylabel('score')\nplt.show()\n\n\nbestKmeans = KMeans(n_clusters = 3, max_iter=100).fit(dataframe_2_norm)\nlabels = bestKmeans.labels_ \n\nclusters=pd.concat([dataframe_2, pd.dataframe_2({'cluster':labels})], axis=1)\nclusters.head()\n\n\n\nfor c in clusters:\n    grid= sns.FacetGrid(clusters, col='cluster')\n    grid.map(plt.hist, c)\n\n\nxtemp = dataframe_2.values\nscalerMinMax = MinMaxScaler()\nx_scaled = scalerMinMax.fit_transform(xtemp)\ndfMinMax = pd.dataframe_2( x_scaled, columns  = dataframe_2.columns)\ndfMinMax['cluster'] = labels\n\nqtdClusters = len(set(labels))\n\nfig, axes = plt.subplots(nrows=qtdClusters, ncols=1, figsize=(20,30))\n\nfor c in set(labels):\n        \n    medias =  dfMinMax[ dfMinMax.cluster== c].mean()\n    medias.drop(['cluster'], inplace = True)\n    medias.plot(ax = axes[c], kind='bar', fontsize=5, title = 'Cluster: ' + str(c), rot=0 )\n  \n\nfig.tight_layout()\n\n#Como plotar graficamentes estes Clusters?    \npca = PCA(n_components=2).fit_transform(dataframe_2_norm)\n\nplt.figure(3)\n#Faz a plotagem dos registros do primeiro cluster 0 (y_kmeans == 0) e utiliza as colunas de indice 0 e 1 (sepal_Length e sepal_width) para a plotagem dos pontos nas intru\u00e7\u00f5es x[y_kmeans == 0, 0] e x[y_kmeans == 0, 1]\nplt.scatter(pca[labels == 0, 0], pca[labels == 0, 1], s = 2, c = 'blue', label = 'Cluster 0')\nplt.scatter(pca[labels == 1, 0], pca[labels == 1, 1], s = 2, c = 'red', label = 'Cluster 1')\nplt.scatter(pca[labels == 2, 0], pca[labels == 2, 1], s = 2, c = 'green', label = 'Cluster 2')\n\n\nplt.legend()\nplt.title('Clusteriza\u00e7\u00e3o')\nplt.show()","62594da9":"# DESCRI\u00c7\u00c3O DAS VARIAVEIS\n* numero_solicitacao: N\u00famero da solicita\u00e7\u00e3o;\n* razaoSocial: Raz\u00e3o social anonimizada;\n* nomeFantasia: Nome Fantasia Anonimizado;\n* cnpjSemTraco: CNPJ anonimizado;\n* maiorAtrsaso: Maior atrasado de pagamento em dias;\n* margemBrutaAcumulada: Margem bruta acumulada;\n* percentualProtestos: percentual protestos;\n* primeiraCompra: Data da primeira compra na Wtec;\n* prazoMedioRecebimentoVendas: prazo m\u00e9dio do recebimento de vendas do cliente\n* titulosEmAberto: valor total de t\u00edtulos em aberto;\n* valorSolicitado: valor de cr\u00e9dito solicitado;\n* status: status da solicita\u00e7\u00e3o:\n> * AprovadoAnalista: aprovado por um analista;\n> * AprovadoComite: aprovado por um comit\u00ea, normalmente para valores mais expressivos;\n> * AguardandoAprovacao: aguardando aprova\u00e7\u00e3o;\n> * DocumentacaoReprovada: documentacao reprovada;\n> * EmAnaliseDocumentacao: em An\u00e1lise da documenta\u00e7\u00e3o;\n> * ReprovadoAnalista: reprovao por um analista;\n> * ReprovadoComite: reprovado por um comit\u00ea;\n> * definicaoRisco: categoriza\u00e7\u00e3o de risco;\n* percentualRisco: onde 0 \u00e9 baixo e 1 \u00e9 alto;\n* diferencaPercentualRisco: 1 - percentualRisco;\n* dashboardCorrelacao: uma correla\u00e7\u00e3o interna de risco, mas que os analistas n\u00e3o conseguiram explicar nas reuni\u00f5es realizadas\n* valorAprovado: valor que foi aprovado pelos analistas\n* dataAprovadoEmNivelAnalista: data em que a solicita\u00e7\u00e3o de cr\u00e9dito foi aprovada por um analista de cr\u00e9dito;\n* dataAprovadoEmComite: data em que a solicita\u00e7\u00e3o de cr\u00e9dito foi aprovada por um comit\u00ea\n* periodoBalanco: per\u00edodo do balan\u00e7o informado na documenta\u00e7\u00e3o da empresa:\n* ativoCirculante: Ativo circulante informado na documenta\u00e7\u00e3o da empresa;\n* passivoCirculante: passivo circulante informado na documenta\u00e7\u00e3o da empresa\n* totalAtivo: ativo informado na documenta\u00e7\u00e3o da empresa\n* totalPatrimonioLiquido: patrim\u00f4nio l\u00edquido informado na documenta\u00e7\u00e3o da empresa\n* endividamento: endividamento informado na documenta\u00e7\u00e3o da empresa\n* duplicatasAReceber: duplicatas a receber informado na documenta\u00e7\u00e3o da empresa\n* estoque: estoque informado na documenta\u00e7\u00e3o da empresa\n* faturamentoBruto: faturamento bruto inofrmado na documenta\u00e7\u00e3o da empresa\n* margemBruta: margembruta informada na documenta\u00e7\u00e3o da empresa\n* periodoDemonstrativoEmMeses: per\u00edodo do demonstrativo informado na documenta\u00e7\u00e3o da empresa\n* custos: custos informado na documenta\u00e7\u00e3o da empresa\n* limiteEmpresaAnaliseCredito: limite de cr\u00e9dito fornecido por uma empresa externa de an\u00e1lise de cr\u00e9dito;\n* anoFundacao: ano de funda\u00e7\u00e3o da empresa;\n* intervaloFunda\u00e7\u00e3o: categoria do ano de funda\u00e7\u00e3o;\n* capitalSocial: Capital social informado na documenta\u00e7\u00e3o da empresa\n* restricoes: flag informando se existem restri\u00e7\u00f5es relacionadas ao clinete;\n* empresa_MeEppMei: Flag informando se o cliente \u00e9 um pequeno neg\u00f3cio;\n* scorePontualidade: score de pontualidade entre 0 e 1, onde \u00e9 significa que o cliente \u00e9 pontual;","77fcf387":"* valorAprovado tem correla\u00e7\u00e3o com \n> * 0.53 - titulosEmAberto\n> * 0.36 - capitalSocial\n> * 0.24 - limiteEmpresaAnaliseCredito\n> * 0.20 - custos\n\n* percentualDeRisco tem correla\u00e7\u00e3o com a tomada de decis\u00e3o do analista\n* titulosEmAberto tem correla\u00e7\u00e3o com decis\u00e3o do Comit\u00ea"}}