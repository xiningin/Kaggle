{"cell_type":{"85999a75":"code","cc43fa0a":"code","31609d85":"code","b47c5afe":"code","7f4a3d54":"code","4a565a95":"code","ab70348f":"code","f560f500":"code","baeaaac0":"code","ca2de5a5":"code","3dd5f226":"code","aee81899":"code","f23f6d5a":"code","9e11cd02":"code","25bff095":"code","472ff6e2":"code","ed2d1f82":"code","6e7b7f92":"code","b7664cf2":"code","caaecaee":"code","cc3990f3":"code","38f40ad8":"code","d0d636cb":"code","82f4dc21":"code","a5ea0360":"code","73b88c5e":"code","abb714d5":"code","36f682ad":"code","14164f4c":"code","52339c2c":"code","cafcbc7e":"code","c32e8dde":"code","20ebe371":"code","5b8c4223":"code","eaa6053d":"code","5b4dac35":"code","e0dc97a4":"code","68da7acf":"code","30d2fe3b":"code","ae0f4299":"code","25219c43":"code","a6dcd13e":"markdown","4d09d90e":"markdown","79ad43fc":"markdown","ef142be7":"markdown","afda70b9":"markdown","e56b9aad":"markdown","e20a7259":"markdown","c52a776a":"markdown","c38b966d":"markdown","8ec85ba6":"markdown","150687a6":"markdown","fb0b5ebd":"markdown","137205bb":"markdown","121ba41d":"markdown","2d7f9943":"markdown","15a2f4b4":"markdown","b615676f":"markdown","5202217a":"markdown","57173a3f":"markdown","62a613c5":"markdown","a2074bb1":"markdown","41763fbd":"markdown","2331c6ec":"markdown","660c3032":"markdown","d5317e62":"markdown","cbeb2249":"markdown","00a42b34":"markdown","c0db2070":"markdown","cd90bed5":"markdown","7ad9bd6d":"markdown","8c8a2cea":"markdown","73375581":"markdown","c03f21ae":"markdown","3cee7c6b":"markdown","e83618be":"markdown","98aef6b7":"markdown","8befdaf4":"markdown","430f6c86":"markdown","aa6c3c8e":"markdown","c70fbb11":"markdown","1a480090":"markdown","a5e5e3c9":"markdown","935deb76":"markdown"},"source":{"85999a75":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings as wrn\n\nwrn.filterwarnings('ignore') # Filter unrelevant warnings\nsns.set_style(\"darkgrid\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cc43fa0a":"# Importing data\ndata = pd.read_csv('\/kaggle\/input\/students-performance-in-exams\/StudentsPerformance.csv')","31609d85":"data.head()","b47c5afe":"data.info()","7f4a3d54":"data[\"gender\"].value_counts()","4a565a95":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"gender\"])\nplt.show()","ab70348f":"data[\"race\/ethnicity\"].value_counts()","f560f500":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"race\/ethnicity\"])\nplt.show()","baeaaac0":"data[\"parental level of education\"].value_counts()","ca2de5a5":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"parental level of education\"])\nplt.xticks(rotation=60)\nplt.show()","3dd5f226":"data[\"lunch\"].value_counts()","aee81899":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"lunch\"])\nplt.show()","f23f6d5a":"data[\"test preparation course\"].value_counts()","9e11cd02":"fig,ax = plt.subplots(figsize=(8,6))\nsns.countplot(data[\"test preparation course\"])\nplt.show()","25bff095":"fig,ax = plt.subplots(figsize=(8,6))\nsns.distplot(data[\"math score\"])\nplt.show()","472ff6e2":"fig,ax = plt.subplots(figsize=(8,6))\nsns.distplot(data[\"writing score\"])\nplt.show()","ed2d1f82":"fig,ax = plt.subplots(figsize=(8,6))\nsns.distplot(data[\"reading score\"])\nplt.show()","6e7b7f92":"data.corr()","b7664cf2":"fig,ax = plt.subplots(figsize=(6,6))\nsns.heatmap(data.corr(),annot=True,fmt=\"0.2f\",linewidths=1.5)\nplt.show()","caaecaee":"gender_math = data.groupby(\"gender\")[\"math score\"].mean()\ngender_math","cc3990f3":"sns.barplot(gender_math.index,gender_math.values)\nplt.show()","38f40ad8":"gender_writing = data.groupby(\"gender\")[\"writing score\"].mean()\ngender_writing","d0d636cb":"sns.barplot(gender_writing.index,gender_writing.values)\nplt.show()\n","82f4dc21":"gender_reading = data.groupby(\"gender\")[\"reading score\"].mean()\ngender_reading","a5ea0360":"sns.barplot(gender_reading.index,gender_reading.values)\nplt.show()","73b88c5e":"race_math = data.groupby(\"race\/ethnicity\")[\"math score\"].mean()\nrace_math","abb714d5":"sns.barplot(race_math.index,race_math.values)\nplt.show()","36f682ad":"race_writing = data.groupby(\"race\/ethnicity\")[\"writing score\"].mean()\nrace_writing","14164f4c":"sns.barplot(race_writing.index,race_writing.values)\nplt.show()","52339c2c":"race_reading = data.groupby(\"race\/ethnicity\")[\"reading score\"].mean()\nrace_reading","cafcbc7e":"sns.barplot(race_reading.index,race_reading.values)\nplt.show()","c32e8dde":"print(data.values[0])\ndata[\"gender\"] = [1 if each == \"female\" else 0 for each in data[\"gender\"]]\ndata.head(1)","20ebe371":"x = data.drop(\"gender\",axis=1)\ny = data.gender\nx.head()","5b8c4223":"x_encoded = pd.get_dummies(x,columns=[\"race\/ethnicity\",\"parental level of education\",\"lunch\",\"test preparation course\"])\nx_encoded.head()","eaa6053d":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\n\nx_scaled = scaler.fit_transform(x_encoded)\nx_scaled[0]","5b4dac35":"x_scaled.shape","e0dc97a4":"x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.2,random_state=1)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","68da7acf":"class ANN(nn.Module):\n    \n    def __init__(self):\n        \n        super(ANN,self).__init__()\n        \n        # Linear function 1\n        self.linear1 = nn.Linear(18,10) # 18 to 10\n        self.tanh1 = nn.Tanh()\n        \n        # Linear function 2\n        self.linear2 = nn.Linear(10,6) # 10 to 6\n        self.tanh2 = nn.Tanh()\n        \n        # Linear function 3\n        self.linear3 = nn.Linear(6,2) # 6 to output\n        \n    \n    def forward(self,x):\n        \n        out = self.linear1(x)\n        out = self.tanh1(out)\n        \n        out = self.linear2(out)\n        out = self.tanh2(out)\n        \n        out = self.linear3(out)\n        return out\n    \n\nmodel = ANN()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.01)\nerror = nn.CrossEntropyLoss()","30d2fe3b":"# But before fitting, we must convert numpy arrays into torch tensors\n\nx_train = torch.Tensor(x_train)\nx_test = torch.Tensor(x_test)\ny_train = torch.Tensor(y_train).type(torch.LongTensor)","ae0f4299":"epochs = 200\nfor epoch in range(epochs):\n    \n    # Clearing gradients\n    optimizer.zero_grad()\n    \n    # Forward propagation\n    outs = model(x_train)\n    \n    # Computing loss\n    loss = error(outs,y_train)\n    \n    # Backward propagation\n    loss.backward()\n    \n    # Updating parameters\n    optimizer.step()\n    \n    if epoch%50 == 0:\n        print(f\"Cost after iteration {epoch} is {loss}\")","25219c43":"from sklearn.metrics import accuracy_score\n# Predicting \ny_head = model(x_test)\nprint(y_head[0])\n\n\n# Converting predictions into labels\ny_pred = torch.max(y_head,-1)[1]\nprint(y_pred[0])\n\nprint(\"Accuracy of model is \",accuracy_score(y_pred,y_test))","a6dcd13e":"### Lunch Countplot","4d09d90e":"## X Normalization","79ad43fc":"### Race Countplot","ef142be7":"* Like the math score, the sequence of groups is the same.","afda70b9":"## Countplots\/Histograms of Features\n\n### Gender Countplot","e56b9aad":"### Math Score Histogram","e20a7259":"# Building Model Using Pytorch\n\nOur data is ready, so in this section We are going to build a simple ANN model using pytorch. I know, I can use traditional machine learning algorithms for processing this data, but I will use pytorch for exercising. \n\nWe'll use a simple model like that:\n\n1. Input Layer\n1. Hidden Layer 1\n1. Output Layer\n\nAnd I will use Adam as optimizer and Cross Entropy as loss.","c52a776a":"## Relation Between Gender - Reading Score","c38b966d":"## Relation Between Race - Writing Score","8ec85ba6":"* Like the writing score, women are better in writing exam.","150687a6":"# Introduction\nHello people, welcome to this kernel! In this kernel I will predict genders of students according their exams. Before starting let's take a look at our content\n\n# Notebook Content\n1. Importing Data and Libraries \n1. Data Overview\n1. Simple Data Analyses \n    * Gender Countplot\n    * Race Countplot\n    * Parental Level Of Education Countplot\n    * Lunch Countplot\n    * Test Preparation Course Countplot\n    * Math Score\n    * Reading Score\n    * Writing Score\n1. Detailed Data Analyses\n    * Correlation Heatmap\n    * Relation Between Gender - Math Score\n    * Relation Between Gender - Writing Score\n    * Relation Between Gender - Reading Score\n    * Relation Between Race - Math Score\n    * Relation Between Race - Writing Score\n    * Relation Between Race - Reading Score\n1. Data Preprocessing\n1. Building Model Using Pytorch\n1. Fitting Model Using Pytorch\n1. Evaulating Results\n1. Conclusion\n\n","fb0b5ebd":"* We should convert this feature into categorical and then we should encode it.","137205bb":"### Writing Score Histogram","121ba41d":"# Data Preprocessing\n\nWe analysed the data and now we are ready for processing the data. In this section I will follow these steps:\n\n* Converting Label Into Int64\n* Creating X and Y\n* One Hot Encoding\n* X Normalization\n* Train Test Split","2d7f9943":"## Creating X and Y","15a2f4b4":"# Data Overview\nIn this section I am going to take look at the data.","b615676f":"### Test Preparation Course Countplot","5202217a":"* Unlike the previous feature, scores are far. \n* We can say that, women are better in writing exam","57173a3f":"# Detailed Data Analyses\n\nIn previous section we've examined the distrubiton of dataset, and now We are going to examine the relations between feautures, especially relations between gender and other features. Let's start with the heatmap","62a613c5":"# Simple Data Analyses\nIn this section I am going to do some simple EDA. ","a2074bb1":"* There are eight features in the dataset. 5 of them are categorical and 3 of them are numerical.","41763fbd":"### Parental Level Of Education Countplot","2331c6ec":"## Converting Label Into Int64","660c3032":"* All of the features are correlated with each others. ","d5317e62":"* Although scores are close, male's score is better.\n","cbeb2249":"# Importing Data and Libraries\n\nIn this section I am going to import libraries and the data that I wil use. ","00a42b34":"### Reading Score Histogram","c0db2070":"## Relation Between Race - Reading Score","cd90bed5":"* This plot is very similar with the previous plot.\n* I can't say anything new, everything is same with the math score.","7ad9bd6d":"* Bad to good teams:\n\n\n1. Group A\n1. Group B\n1. Group C\n1. Group D\n1. Group E","8c8a2cea":"## Relation Between Gender - Writing Score","73375581":"## One Hot Encoding","c03f21ae":"* Most of the students took score between 50 and 100.\n* Although there are scores between 0 and 40, they are so rare.\n* I am wondering the relation between math score and gender but it is not the subject of this section, we will examine that in Detailed Data Analyses.","3cee7c6b":"## Relation Between Gender - Math Score ","e83618be":"* Don't be confused because of the \"none\" label. It does not mean it is a missing value. \n* We should convert and encode this feature.","98aef6b7":"## Correlation Heatmap","8befdaf4":"## Relation Between Race - Math Score\n","430f6c86":"* Although female entries are a bit more, our data is balanced.\n* We should convert this feature into integer.","aa6c3c8e":"# Conclusion\n\nThanks for your attention, if you have any questions in your mind, please ask. ","c70fbb11":"* Most of the dataset's group is group D.\n* Entries of this feature is unbalanced. \n* We should convert this feature into categorical, and after that we should encode it.","1a480090":"# Fitting Model Using Pytorch\n\nOur frame of model is ready, and now let's train it.","a5e5e3c9":"# Evaulating Results\n\nWe trained our model in previous section. And now in this section we will predict x_test and after that we will evaulete the results.","935deb76":"* This feature is definetely unbalanced.\n* We should convert this feature into categorical and after that we should encode it."}}