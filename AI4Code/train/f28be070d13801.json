{"cell_type":{"cf42a62e":"code","34d9a725":"code","cf0adfd8":"code","a6f8a098":"code","c66b2057":"code","8b06722a":"code","2d3dfadf":"code","af1453e9":"code","537f3a2a":"code","9028b5f5":"code","15623371":"code","71f16745":"code","8491f6bf":"code","e7389587":"code","52edd1c9":"code","b9a91b2b":"code","13f842ae":"code","f1c6e0d2":"code","0cd55251":"code","3e4c72d8":"markdown","3545a980":"markdown","686ccf66":"markdown","acf41c36":"markdown","d451779b":"markdown"},"source":{"cf42a62e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","34d9a725":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport matplotlib.image as mpimg\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras import layers","cf0adfd8":"train_data = pd.read_csv('..\/input\/aerial-cactus-identification\/train.csv')\nsub_data = pd.read_csv('..\/input\/aerial-cactus-identification\/sample_submission.csv')","a6f8a098":"train_data.head()","c66b2057":"np.unique(train_data.has_cactus, return_counts=True)","8b06722a":"has_cactus = train_data[train_data['has_cactus'] == 1].id.values\nno_cactus = train_data[train_data['has_cactus'] == 0].id.values","2d3dfadf":"# zip\ud30c\uc77c \ud480\uae30\n!unzip ..\/input\/aerial-cactus-identification\/train.zip -d train\n!unzip ..\/input\/aerial-cactus-identification\/test.zip -d test","af1453e9":"print(os.listdir(\"..\/working\"))","537f3a2a":"TRAIN_IMG_PATH = \"..\/working\/train\/train\/\"\nTEST_IMG_PATH = \"..\/working\/test\/test\/\"","9028b5f5":"check_img = mpimg.imread(TRAIN_IMG_PATH + has_cactus[0])\nimgplot = plt.imshow(check_img)","15623371":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen=ImageDataGenerator(rescale=1.\/255)\nbatch_size=150\ntrain_data.has_cactus=train_data.has_cactus.astype(str)\n\ntrain_generator=datagen.flow_from_dataframe(dataframe=train_data[:15001],directory=TRAIN_IMG_PATH,x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                            target_size=(150,150))\n\n\nvalidation_generator=datagen.flow_from_dataframe(dataframe=train_data[15000:],directory=TRAIN_IMG_PATH,x_col='id',\n                                                y_col='has_cactus',class_mode='binary',batch_size=50,\n                                                target_size=(150,150))","71f16745":"model = tf.keras.models.Sequential()\nmodel.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512,activation='relu'))\nmodel.add(layers.Dense(1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","8491f6bf":"hist = model.fit_generator(train_generator,steps_per_epoch=50,epochs=5,validation_data=validation_generator,validation_steps=50)","e7389587":"plt.plot(hist.history['accuracy'],'r',label='accuracy')\nplt.plot(hist.history['val_accuracy'],'b',label='val_acc')\nplt.legend()\nplt.show()","52edd1c9":"plt.plot(hist.history['loss'],'r',label='loss')\nplt.plot(hist.history['val_loss'],'b',label='val_loss')\nplt.legend()\nplt.show()","b9a91b2b":"sub_data.has_cactus = sub_data.has_cactus.astype(str)\n\ntrain_generator = datagen.flow_from_dataframe(dataframe=sub_data,directory=TEST_IMG_PATH,x_col='id',\n                                              y_col='has_cactus',class_mode=None,batch_size=batch_size,target_size=(150,150))","13f842ae":"datagen=ImageDataGenerator(rescale=1.\/255)\nbatch_size=150\nsub_data.has_cactus=sub_data.has_cactus.astype(str)\n\ntest_generator=datagen.flow_from_dataframe(dataframe=sub_data,directory=TEST_IMG_PATH,x_col='id',\n                                            y_col='has_cactus',class_mode=None,batch_size=batch_size,\n                                            target_size=(150,150))","f1c6e0d2":"y_pred = model.predict(test_generator)\n\ndf=pd.DataFrame({'id':sub_data['id'] })\n\ndf['has_cactus']=y_pred\ndf.to_csv(\"\/kaggle\/working\/submission.csv\",index=False)","0cd55251":"df","3e4c72d8":"# Building Model & Fitting","3545a980":"# Display sample image","686ccf66":"## has_cactus=0 -> no cactus(num: 4364) , has_cactus=1 -> with cactus(num: 13136)","acf41c36":"# File Save","d451779b":"# ImageDataGenerator"}}