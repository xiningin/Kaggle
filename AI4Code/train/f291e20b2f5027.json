{"cell_type":{"a969d427":"code","91781d52":"code","71019530":"code","00ce5be5":"code","a256df7e":"code","268515d4":"code","e9a0caad":"code","f073f87e":"code","ecb3b308":"code","2c41aef6":"code","d12d0c22":"code","0b2bd317":"markdown","3c1c9f91":"markdown","f7947b10":"markdown","9cc85c2e":"markdown","9953aa95":"markdown","74bf19d6":"markdown","6db761a8":"markdown","b54691c2":"markdown","f2cf4499":"markdown","b179b92c":"markdown","8eb0f5a6":"markdown"},"source":{"a969d427":"import ubiquant_utils as uu","91781d52":"import gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm","71019530":"# thanks for the parquet file @robikscube. upvoted.\n# takes a minute or so to load.\ntrain_df = pd.read_parquet('..\/input\/ubiquant-parquet\/train.parquet')","00ce5be5":"test_df = train_df[train_df.time_id <= 250]","a256df7e":"del train_df\ngc.collect()","268515d4":"api = uu.API(test_df)","e9a0caad":"start_time = time.time()\n\nfor (data_df, pred_df) in tqdm(api):\n    \n    # dummy prediction - insert yours here.\n    pred_df['target'] = 0.\n    api.predict(pred_df)\n    \nfinish_time = time.time()\n\ntotal_time = finish_time - start_time\nmean_iter_speed = api.init_num_times\/total_time\n\nprint(f\"Iterations\/s = {mean_iter_speed:.2g}.\")\ntest_iters = 250\nprint(f\"Expected number of iterations in test set is approx. {test_iters}\",\n      f\"which will take {test_iters \/ (mean_iter_speed * 3600):.2g} hours\",\n      \"using this API emulator while making dummy predictions.\")","f073f87e":"score_df, score = api.score()","ecb3b308":"print(f\"Final LB score is {score:.4g}\")","2c41aef6":"score_df.head(5)","d12d0c22":"api = uu.API(test_df)\n\nfor i, (data_df, pred_df) in enumerate(api):\n    \n    # random prediction\n    pred_df['target'] = np.random.randn(len(pred_df), 1)\n    api.predict(pred_df)\n    \n    #regular scoring\n    if i % 10 == 0:\n        _, cum_score = api.score()\n        print(f\"LB score at {i:<3}: {cum_score:>10.4g}\")\n    \n    \nscore_df, score = api.score()\n\nprint(f\"Final LB score is {score:.4g}\")","0b2bd317":"Take slice of `train_df` which contains 250 time_ids for testing. Note that we have [around 200 - 250 time_ids](https:\/\/www.kaggle.com\/lucasmorin\/don-t-mind-me-just-probing-the-lb) in the public LB. upvoted.","3c1c9f91":"# end","f7947b10":"# demo #1\n### example loop with dummy predictions","9cc85c2e":"# data","9953aa95":"An example loop making dummy predictions of target=0:","74bf19d6":"Create an API instance:","6db761a8":"Delete `train_df` and take out the trash to free up enough RAM for a couple of examples.","b54691c2":"# demo #2\n### example loop with random predictions and regular scoring calls","f2cf4499":"# import\n\nTo use the module in your notebook you need to:\n1. In the notebook menu select File > Add Utility Script\n2. Search for \"ubiquant_utils\" and (double-) click Add.\n3. Import `ubiquant_utils` as you would any module. E.g:","b179b92c":"The API has a `score` method. This returns:\n+ a dataframe containing your predictions and the targets.\n+ the LB score: mean of the correlation between predictions and targets when they are grouped by time_id.","8eb0f5a6":"# introduction\n\nThis notebook gives a quick intro to using the `ubiquant_utils` module which emulates the Ubiquant timeseries API locally. It gives you the flexibility to:\n1. feed different slices of the train dataset into it\n2. create as many emulator instances as you want within one session\n3. call an LB score method at any point during the iteration\n\nIt enforces similar constraints to the real API and produces realistic error messages. \nThe code adapts my [Local API Emulator](https:\/\/www.kaggle.com\/jagofc\/local-api-emulator) from the G-Research Crypo Competition.\n\nFor a quick introduction to importing utility scripts see [this intro video](https:\/\/www.youtube.com\/watch?v=C4h88PfN5jA&ab_channel=Kaggle)."}}