{"cell_type":{"a97441e5":"code","0f4306a1":"code","c5f1f119":"code","afc2d3e8":"code","95e47928":"code","d4981991":"code","a51ad8b9":"code","95191b42":"code","57625f5a":"code","c850adcb":"code","e00682d9":"code","d65c3480":"code","035d9153":"code","9a695a3e":"code","497a3cae":"code","1211966f":"markdown","a83b5ea7":"markdown","c2e45273":"markdown","ed061067":"markdown","d84d4e48":"markdown","112c5d8a":"markdown","9830bab8":"markdown","6f00333c":"markdown","20067f7d":"markdown","d19543bd":"markdown","c373df2c":"markdown","6288d334":"markdown","37ee179f":"markdown","77a8ea51":"markdown"},"source":{"a97441e5":"import os\nimport numpy as np \nimport pandas as pd \nfrom subprocess import check_output\nimport seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\nprint(check_output([\"ls\", \"..\/input\/\"]).decode(\"utf8\"))","0f4306a1":"sub_path = \"..\/input\/champstacks\"\nall_files = os.listdir(sub_path)\nall_files","c5f1f119":"# Read and concatenate submissions\nouts = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\nconcat_sub = pd.concat(outs, axis=1)\ncols = list(map(lambda x: \"champ\" + str(x), range(len(concat_sub.columns))))\nconcat_sub.columns = cols\nconcat_sub.reset_index(inplace=True)\nconcat_sub.head()\nncol = concat_sub.shape[1]","afc2d3e8":"# check correlation\nconcat_sub.iloc[:,1:ncol].corr()","95e47928":"corr = concat_sub.iloc[:,1:7].corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","d4981991":"# get the data fields ready for stacking\nconcat_sub['champ_max'] = concat_sub.iloc[:, 1:ncol].max(axis=1)\nconcat_sub['champ_min'] = concat_sub.iloc[:, 1:ncol].min(axis=1)\nconcat_sub['champ_mean'] = concat_sub.iloc[:, 1:ncol].mean(axis=1)\nconcat_sub['champ_median'] = concat_sub.iloc[:, 1:ncol].median(axis=1)","a51ad8b9":"concat_sub.describe()","95191b42":"cutoff_lo = -37\ncutoff_hi = 205","57625f5a":"concat_sub['scalar_coupling_constant'] = concat_sub['champ_mean']\nconcat_sub[['id', 'scalar_coupling_constant']].to_csv('stack_mean.csv', \n                                        index=False, float_format='%.6f')","c850adcb":"concat_sub['scalar_coupling_constant'] = concat_sub['champ_median']\nconcat_sub[['id', 'scalar_coupling_constant']].to_csv('stack_median.csv', \n                                        index=False, float_format='%.6f')","e00682d9":"concat_sub['scalar_coupling_constant'] = np.where(np.all(concat_sub.iloc[:,1:ncol] > cutoff_lo, axis=1), 1, \n                                    np.where(np.all(concat_sub.iloc[:,1:ncol] < cutoff_hi, axis=1),\n                                             0, concat_sub['champ_median']))\nconcat_sub[['id', 'scalar_coupling_constant']].to_csv('stack_pushout_median.csv', \n                                        index=False, float_format='%.6f')","d65c3480":"concat_sub['scalar_coupling_constant'] = np.where(np.all(concat_sub.iloc[:,1:ncol] > cutoff_lo, axis=1), \n                                    concat_sub['champ_max'], \n                                    np.where(np.all(concat_sub.iloc[:,1:ncol] < cutoff_hi, axis=1),\n                                             concat_sub['champ_min'], \n                                             concat_sub['champ_mean']))\nconcat_sub[['id', 'scalar_coupling_constant']].to_csv('stack_minmax_mean.csv', \n                                        index=False, float_format='%.6f')","035d9153":"concat_sub['scalar_coupling_constant'] = np.where(np.all(concat_sub.iloc[:,1:ncol] > cutoff_lo, axis=1), \n                                    concat_sub['champ_max'], \n                                    np.where(np.all(concat_sub.iloc[:,1:ncol] < cutoff_hi, axis=1),\n                                             concat_sub['champ_min'], \n                                             concat_sub['champ_median']))\nconcat_sub[['id', 'scalar_coupling_constant']].to_csv('stack_minmax_median.csv', \n                                        index=False, float_format='%.6f')","9a695a3e":"# load the model with best base performance\nsub_base = pd.read_csv('..\/input\/champstacks\/submission-giba-1 (2).csv')","497a3cae":"concat_sub['champ_base'] = sub_base['scalar_coupling_constant']\nconcat_sub['scalar_coupling_constant'] = np.where(np.all(concat_sub.iloc[:,1:ncol] > cutoff_lo, axis=1), \n                                    concat_sub['champ_max'], \n                                    np.where(np.all(concat_sub.iloc[:,1:ncol] < cutoff_hi, axis=1),\n                                             concat_sub['champ_min'], \n                                             concat_sub['champ_base']))\nconcat_sub[['id', 'scalar_coupling_constant']].to_csv('stack_minmax_bestbase.csv', \n                                        index=False, float_format='%.6f')","1211966f":"# Data Load","a83b5ea7":"# MinMax + Median Stacking ","c2e45273":"**LB ----** -","ed061067":"# MinMax + Mean Stacking\n\nMinMax seems more gentle and it outperforms the previous one given its peformance score.","d84d4e48":"> **LB -----**","112c5d8a":"# Mean Stacking","9830bab8":"# MinMax + BestBase Stacking","6f00333c":"# Median Stacking","20067f7d":"> **LB----** -","d19543bd":"**LB----**","c373df2c":"Thanks @DSEverything for https:\/\/www.kaggle.com\/dongxu027\/explore-stacking-lb-0-1463","6288d334":"# PushOut + Median Stacking \n\nPushout strategy is a bit agressive given what it does...","37ee179f":"![](http:\/\/)**LB ----**","77a8ea51":"> **LB ----**\n\n"}}