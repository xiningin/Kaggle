{"cell_type":{"bf6bfede":"code","1935961c":"code","2bd26344":"code","40aee013":"code","0de13c49":"code","18f57194":"code","8a945cd4":"code","76a64765":"code","22a6e93f":"code","47608915":"code","c00398f0":"markdown","1cc5bf68":"markdown","401f8b3c":"markdown","f3c21b26":"markdown","c7ec3e7b":"markdown","5e17bff9":"markdown","9fc2e4e4":"markdown","3deabdce":"markdown","aff01b11":"markdown","2e333967":"markdown","87258989":"markdown"},"source":{"bf6bfede":"# -*- coding: utf-8 -*-\n\n# Created on Sun Apr 18 14:43:05 2021\n\n# @author: mbadal1996\n\n# =============================================\n# Lightweight CNN Classifier\n# =============================================\n#\n# This python code is a foundation for a \n# lightweight (e.g. embedded\/mobile) CNN image\n# classifier in PyTorch. It is a fully functioning\n# code and can be easily adapted for additional \n# classes. The CNN can be made more sophisticated \n# by adding more convolutions, kernels, batchnorm, \n# and\/or dropout. By default it is set up for two\n# classes and has performance of close to 80 \n# percent accuracy for validation data on the \n# Kaggle flowers data set. This may be improved \n# by cleaning and normalizing the dataset (which \n# is needed). The code runs on CPU or GPU as chosen \n# by user.\n#\n# IMPORTANT NOTE:\n# When organizing data in folders to be input to\n# dataloader, it is important to keep in mind the \n# following for correct loading:\n#\n# (1) The train and val data were separated into\n# their own folders by hand by class (rose and \n# tulip) called 'flowers_datasets\/training_sets' \n# and 'flowers_datasets\/val_set'. That means the\n# sub-folder 'training_set' contains two \n# folders: rose and tulip. The same is true for \n# validation data held in the folder \n# 'flowers_datasets\/val_set'. So the organization\n# looks like:\n#\n# flowers_datasets > training_set > rose, tulip\n# flowers_datasets > val_set > rose, tulip\n#\n# NOTE: Test data not included, but the code is.\n# (2) The test data is organized differently \n# since there are no labels for those images. \n# Instead, the test data are held in the folder \n# 'flowers_datasets\/test_sets' where the \n# sub-folder here 'test_sets' just contains one \n# folder called 'test'. This is instead of the \n# rose and tulip folders. So the organization \n# looks like:\n#\n# flowers_datasets > test_set > test\n#\n# ==========================================","1935961c":"# Python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n# Pytorch\nimport torch\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\n# Device\ndev = 'cuda'\n#dev = 'cpu'\n\n\n# ==========================================\n# Parameters\n\n# Input number of classes (chosen by user)\n# Needed for \nnum_class = 2\n\n# Image Parameters\nCH = 3  # number of channels\nratio = 1.5625  # wth\/ht ratio to resize images\nimagewidth = 157  # 157 for 100x100 images \nimageheight = int(np.floor(imagewidth\/ratio))\ncropsize = imageheight  # imageheight x imageheight\n\n# Neural Net Parameters\nlearn_rate = 5e-5  # smaller for stable convergence\nnum_epochs = 140  # 25-50 for 1e-4; 100-200 for 5e-5\nbatch_size_train = 500  # larger for smooth converge\nbatch_size_val = 320  # larger for smooth converge\n\n# Seed for reproducible results (weights,biases), but\n# e.g. shuffle=True will negate reproducible results\ntorch.manual_seed(1234)\n\n# Start Timing Code\ntic = time.perf_counter()","2bd26344":"# ==============================================\n\n# Create transforms for training data augmentation. \n# In each epoch, random transforms will be applied \n# according to the Compose function. They are random \n# since we are explicitly choosing \"Random\" versions \n# of the transforms. To \"increase the dataset\" one \n# should run more epochs, since each epoch has new \n# random data.\n# NOTE: Augment should only be applied to Train data.\n# NOTE: If using augment transforms, use larger batches.\n\ntransform_train = transforms.Compose([\n        transforms.Resize([imageheight, imagewidth]),\n        transforms.CenterCrop(cropsize),\n        transforms.RandomHorizontalFlip(p=0.5),\n        #transforms.RandomRotation(degrees = (-15,15)), \n        #transforms.RandomVerticalFlip(p=0.5),\n        transforms.ToTensor()])\n\ntransform_val = transforms.Compose([\n        transforms.Resize([imageheight, imagewidth]),\n        transforms.CenterCrop(cropsize),\n        transforms.ToTensor()])\n\ntransform_test = transforms.Compose([\n        transforms.Resize([imageheight, imagewidth]),\n        transforms.CenterCrop(cropsize),\n        transforms.ToTensor()])\n\n# --------------------------------------------------\n# Import train and validation data and set up data loader.\n# Note that ImageFolder will organize data according to \n# class labels of the folders \"roses, tulips, etc\" as \n# found in the train and val data folder. NOTE: When \n# calling a specific image (such as 135) from train data, \n# the first XXX images are class 0, then the next YYY \n# are class 1, and etc.\n\n\n# Training Data\nimages_train = \\\ndatasets.ImageFolder('..\/input\/flowers-subset\/flowers_datasets\/train_sets',\n                     transform=transform_train)\nloader_train = \\\ntorch.utils.data.DataLoader(images_train, shuffle=True,\n                            batch_size=batch_size_train)\n# Validation Data\nimages_val = \\\ndatasets.ImageFolder('..\/input\/flowers-subset\/flowers_datasets\/val_sets',\n                     transform=transform_val)\nloader_val = \\\ntorch.utils.data.DataLoader(images_val, shuffle=True,\n                            batch_size=batch_size_val)\n# Test Data\n#images_test = \\\n#datasets.ImageFolder('..\/input\/flowers-subset\/flowers_datasets\/test_sets',\n#                     transform=transform_test)\n#loader_test = \\\n#torch.utils.data.DataLoader(images_test, shuffle=False,\n#                            batch_size=len(images_test))","40aee013":"# Plot sample image from data obtained by ImageFolder class\nX_example,y_true_train = images_train[4]\nplt.imshow(X_example.permute(1, 2, 0))  #image to HxWxC (Ch) \nplt.title(\"Example of image with label \"+str(y_true_train))\nplt.show()\n\n# print(images_train.classes)  # Classes: 0,1,2,...\n\n# =======================================================","0de13c49":"# Define CNN Model\n\n# NOTE NOTE NOTE: CNN takes in images of size 100x100 pixels\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # Pooling\n        self.pool = torch.nn.MaxPool2d(kernel_size=(2, 2))\n        \n        # Dropout\n        self.do = torch.nn.Dropout(p=0.2)\n        \n        #Batchnorm\n        #self.conv4_bn = torch.nn.BatchNorm2d(num_features=128,\n        #                         eps=1e-04,momentum=0.2)\n        #self.fc2_bn = torch.nn.BatchNorm1d(num_features=50,\n        #                         eps=1e-05,momentum=0.1)\n        \n        # Convolution\n        self.conv1 = torch.nn.Conv2d(in_channels=3,\n                     out_channels=32,kernel_size=4)\n        self.conv2 = torch.nn.Conv2d(in_channels=32,\n                     out_channels=64,kernel_size=4)\n        self.conv3 = torch.nn.Conv2d(in_channels=64,\n                     out_channels=128,kernel_size=4)\n        self.conv4 = torch.nn.Conv2d(in_channels=128,\n                     out_channels=128,kernel_size=4)\n        \n        # Fully Connected\n        self.fc1 = torch.nn.Linear(128 * 3 * 3, 100)\n        self.fc2 = torch.nn.Linear(100, 50)\n        self.fc3 = torch.nn.Linear(50, 2)  # output\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.do(self.pool(F.relu(self.conv4(x))))\n        x = x.view(-1, 128 * 3 * 3)   \n        x = F.relu(self.fc1(x))  \n        x = self.do(F.relu(self.fc2(x)))  \n        x = self.fc3(x)       \n        return x\n\n\n# NOTE NOTE NOTE: This CNN takes inimages of size 100x100 pixels\n# This is a simpler CNN that user can try.\n#class Net(torch.nn.Module):\n#    def __init__(self):\n#        super().__init__()\n#        self.pool = torch.nn.MaxPool2d(kernel_size=(2, 2))\n#        self.conv1 = torch.nn.Conv2d(in_channels=3,\n#                     out_channels=15,kernel_size=5)\n#        self.conv2 = torch.nn.Conv2d(in_channels=15,\n#                     out_channels=10,kernel_size=5)\n#        #self.do = torch.nn.Dropout(p=0.5)\n#        self.fc1 = torch.nn.Linear(10 * 22 * 22, 100)\n#        self.fc2 = torch.nn.Linear(100, 50) \n#        self.fc3 = torch.nn.Linear(50, 2)  # output\n\n#    def forward(self, x):\n#        x = self.pool(F.relu(self.conv1(x)))\n#        x = self.pool(F.relu(self.conv2(x)))\n#        x = x.view(-1, 10 * 22 * 22) \n#        x = F.relu(self.fc1(x))  \n#        x = F.relu(self.fc2(x)) \n#        x = self.fc3(x)  # final output\n        \n#        return x\n\n\n# ==================================================","18f57194":"# Create instance of 'Net' class\nmodel = Net().to(dev)  # send model 'to device'\n\n# Choose the desired loss function.\nloss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n\n# Choose the desired optimizer to train parameters\noptimizer = torch.optim.Adam(model.parameters(), \n                             lr=learn_rate)\n\n\n# ==================================================","8a945cd4":"# Initialize tensor to store loss values\nresult_vals = torch.zeros(num_epochs,4)\ncount_train = 0  # Initialize Counter\ncount_val = 0  # Initialize Counter\ncount_test = 0  # Initialize Counter\n\nprint(' ')\nprint('epoch  | loss_train | loss_val | acc_train | acc_val')\nprint('-----------------------------------------------------')\n\nfor epoch in range(num_epochs):\n    # New epoch begins\n    \n    # Initialize values\n    running_loss_train = 0\n    running_loss_val = 0\n    num_batches_train = 0\n    num_batches_val = 0\n    count_train = 0\n    count_val = 0\n    \n    model.train() # Set torch into train mode\n    \n    for X_train,y_true_train in loader_train:\n        X_train,y_true_train = \\\n        X_train.to(dev),y_true_train.to(dev)\n        # (X,y) is a mini-batch:\n        # (N: batch-size, 3: num channels, H x W)\n        # X size N x 3 x cropsize x cropsize \n        # y size N\n        \n        # Reset gradients to zero for new batch\n        optimizer.zero_grad()\n        \n        # Run model and compute loss\n        N,C,nX,nY = X_train.size()  # Get batch parameters\n        # Evaluate model on batch\n        y_pred_train = model(X_train.view(N,C,nX,nY))\n        # Compute loss\n        loss_train = loss_fn(y_pred_train, y_true_train)  \n        \n        # Back propagation\n        loss_train.backward()   \n        \n        # Update the NN parameters\n        optimizer.step()\n        \n        # Update running loss after each batch\n        running_loss_train += loss_train.cpu().detach().numpy()\n        num_batches_train += 1 \n        \n        # Compute accuracy for train data per epoch\n        for i in range(0,len(y_true_train)):\n            # Compare y_pred_train to y_true_train\n            if torch.argmax(y_pred_train[i,:]).item() == \\\n            y_true_train[i].item():\n                count_train = count_train + 1\n    \n    model.eval()  # Set torch into eval mode\n    #with torch.no_grad():\n    for X_val,y_true_val in loader_val:\n        X_val,y_true_val = X_val.to(dev),y_true_val.to(dev)\n        # (X,y) is a mini-batch:\n        # (N: batch-size, 3: num channels, height x width)\n        # X size N x 3 x cropsize x cropsize \n        # y size N\n        \n        # Run model and compute loss\n        N,C,nX,nY = X_val.size()  # Get batch parameters\n        # Evaluate model on batch\n        y_pred_val = model(X_val.view(N,C,nX,nY))  \n        # Compute loss\n        loss_val = loss_fn(y_pred_val, y_true_val)  \n        \n        # Update running loss after each batch\n        running_loss_val += loss_val.cpu().detach().numpy()\n        num_batches_val += 1 \n        \n        # Compute accuracy for train data per epoch\n        for i in range(0,len(y_true_val)):\n            # Compare y_pred_val to y_true_val\n            if torch.argmax(y_pred_val[i,:]).item() == \\\n            y_true_val[i].item():\n                count_val = count_val + 1\n    \n    \n\n    ave_loss_train = running_loss_train\/num_batches_train\n    ave_loss_val = running_loss_val\/num_batches_val\n    ave_accuracy_train = count_train\/len(images_train)\n    ave_accuracy_val = count_val\/len(images_val)\n    \n    # Store loss and acc to \"loss_vals\" for plotting\n    result_vals[epoch, 0] = ave_loss_train  # per epoch\n    result_vals[epoch, 1] = ave_loss_val  # per epoch\n    result_vals[epoch, 2] = ave_accuracy_train  # per epoch\n    result_vals[epoch, 3] = ave_accuracy_val  # per epoch\n    \n    # Print loss every N epochs\n    if epoch % 5 == 4:\n        print(epoch, '      ', \n              round(ave_loss_train.item(),5), \n              '     ', round(ave_loss_val.item(),5),\n             '  ',round(ave_accuracy_train,5),\n             '   ',round(ave_accuracy_val,5))\n    \n\n# End Timing Code\ntoc = time.perf_counter()\n\n# Measure Time\nruntime = toc - tic\n\nprint(' ')\nprint('Computing Time')\nprint(runtime)","76a64765":"# ================================================\n# Plot Loss and Accuracy for train and val sets\n# ================================================\n\nxvals = torch.linspace(0, num_epochs, num_epochs+1)\n\nplt.clf()\nplt.plot(xvals[0:num_epochs].cpu().numpy(), \n         result_vals[:,0].cpu().numpy())\nplt.plot(xvals[0:num_epochs].cpu().numpy(), \n         result_vals[:,1].cpu().numpy())\nplt.legend(['loss_train', 'loss_val'], \n           loc='upper right')\n#plt.xticks(xvals[0:num_epochs])\nplt.title('Loss (NN Classifier)')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.tick_params(right=True, labelright=True)\n# plt.savefig('loss.pdf', bbox_inches='tight', \n#             dpi=2400)\nplt.show()\n\nplt.clf()\nplt.plot(xvals[0:num_epochs].cpu().numpy(), \n         result_vals[:,2].cpu().numpy())\nplt.plot(xvals[0:num_epochs].cpu().numpy(), \n         result_vals[:,3].cpu().numpy())\nplt.legend(['accuracy_train', 'accuracy_val'], \n           loc='lower right')\n#plt.xticks(xvals[0:num_epochs])\nplt.title('Accuracy (NN Classifier)')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.tick_params(right=True, labelright=True)\n# plt.ylim(-0.15, 1.0)\n# plt.savefig('accuracy.pdf', bbox_inches='tight', \n#             dpi=2400)\nplt.show()\n\n\n\n# =================================================\n\n# NOTE: If you have test data you can perform \n# inference on it using the trained model here.\n\n#count_test = 0\n#test_predict = torch.zeros(len(images_test)).long()\n\n#model.eval()\n#for X_test,y_test in loader_test:\n#    X_test,y_test = X_test.to(dev),y_test.to(dev)\n#    y_pred_test = model(X_test.view(len(images_test),\n#                        C,nX,nY))\n#    for i in range(0,len(images_test)):\n#        test_predict[i] = \\\n#             torch.argmax(y_pred_test[i,:]).item()\n        # Compare y_pred_test to y_true_test\n#        if torch.argmax(y_pred_test[i,:]).item() == \\\n#                        y_true_test[i].item():\n#            count_test = count_test + 1\n        \n#print(' ')\n#print('Predicted test data classes (Rose=0,Tulip=1): ')\n#print(test_predict)\n#print(' ')\n#print('Model accuracy in predicting test data:')\n#print(count_test\/len(y_true_test))\n#print(' ')\n\n\n\n# ======================================================","22a6e93f":"# Acquire Data from Batches for Confusion Matrices\n\ncount_train = 0\ncount_val = 0\n\npredict_train = []  # Initialize\ny_true_train_all = []  # Initialize\nfor X_train,y_true_train in loader_train:\n    X_train,y_true_train = \\\n    X_train.to(dev),y_true_train.to(dev)\n    N,C,nX,nY = X_train.size()\n    model.eval()\n    y_pred_train = model(X_train.view(N,C,nX,nY))\n    \n    for i in range(0,len(y_true_train)):\n        y_true_train_all.append(y_true_train[i])\n        predict_train.append(torch.argmax(y_pred_train[i,:]).item())\n        # Compare y_pred_train to y_true_train\n        if torch.argmax(y_pred_train[i,:]).item() == \\\n                        y_true_train[i].item():\n            count_train = count_train + 1\n\n\npredict_val = []  # Initialize \ny_true_val_all = []  # Initialize\nfor X_val,y_true_val in loader_val:\n    X_val,y_true_val = X_val.to(dev),y_true_val.to(dev)\n    N,C,nX,nY = X_val.size()\n    model.eval()\n    y_pred_val = model(X_val.view(N,C,nX,nY))\n    \n    for i in range(0,len(y_true_val)):\n        y_true_val_all.append(y_true_val[i])\n        predict_val.append(torch.argmax(y_pred_val[i,:]).item())\n        # Compare y_pred_val to y_true_val\n        if torch.argmax(y_pred_val[i,:]).item() == \\\n                        y_true_val[i].item():\n            count_val = count_val + 1\n\n# Compute accuracy for train and val using trained model\nprint(' ')\nprint('NN model accuracy in predicting training data:')\nprint(count_train\/len(y_true_train_all))\nprint(' ')\nprint('NN model accuracy in predicting val data:')\nprint(count_val\/len(y_true_val_all))\n\n\n# ---------------------------------------------","47608915":"# Initialize tensors to store confusion values\nZZ_train = torch.zeros(num_class,num_class).long()  \nZZ_val = torch.zeros(num_class,num_class).long()  \n\n# Step through \"True\" and \"Predicted\" values and \n# update confusion matrix\nfor j in range(0,len(y_true_train_all)):\n    # For each \"j\" add +1 to ZZ at coordinate called \n    # (predict_train[j],y_true_train[j])\n    ZZ_train[predict_train[j],y_true_train_all[j]] += 1\n\nfor j in range(0,len(y_true_val_all)):\n    # For each \"j\" add +1 to ZZ at coordinate called\n    # (predict_val[j],y_true_val[j])\n    ZZ_val[predict_val[j],y_true_val_all[j]] += 1 \n\n\n# -------------------------------------------------\n# Create plotting function for confusion matrices\n\ndef confplot_func(input_data):\n\n    # Create list of axis tick marks based on num classes\n    axes = []  # initialize list\n    for i in range(0,num_class):\n        axes.append(i)\n        \n    # Plot confusion matrix ZZ for Train and Val\n    plt.imshow(input_data,extent=(-0.5,num_class-0.5,\n                                  num_class-0.5,-0.5),\n               interpolation='none',cmap='coolwarm')\n    plt.xlabel('True Classes', fontsize = 12)\n    plt.ylabel('Predicted Classes', fontsize = 12)\n    plt.colorbar(fraction=0.145, pad=0.055, aspect=5.5)\n    plt.xticks(axes, fontsize = 11)\n    plt.yticks(axes, fontsize = 11)\n\n    # Insert count text for each box in confusion matrix\n    for i in range(0,num_class):\n        for j in range(0,num_class):\n            plt.text(j, i, format(input_data[i,j], 'd'), \n            horizontalalignment=\"center\", \n            verticalalignment=\"center\", color=\"white\",\n            fontsize = 16, fontweight = 'bold')\n\n# ---------------------------------------------------\n\n# Call function to plot confusion matrix ZZ \nplt.clf()\nplt.figure(figsize=(9,9))  # figures as subplots with size\n\nplt.subplot(1,2,1)\nconfplot_func(ZZ_train)  # pass train data to function\nplt.title('Confusion Matrix Train')\n\nplt.subplot(1,2,2)\nconfplot_func(ZZ_val)  # pass val data to plotting function\nplt.title('Confusion Matrix Val')\n\nplt.tight_layout(pad=1.5, w_pad=2.5, h_pad=1.0)\nplt.savefig('conf_mat.pdf', bbox_inches='tight', dpi=2400)\n\nplt.show()","c00398f0":"### **Training Loop and Validation**\n\nHere we train, compute loss and accuracy, and store the results for later plotting. The computing time is also obtained. Note that this is only approximate since CPU and GPU timing estimates will differ.","1cc5bf68":"### **Trained Model Accuracy**\n\nFollowing training, here we perform inference on the training and validation data and store it for confusion matrix plotting. Furthermore we obtain the final accuracy for for data sets. The prediction results for train and val are as much as about 81+ and 79+ percent respectively.","401f8b3c":"### **CNN Model Architecture**\n\nThis architecture takes 100x100 pixel, 3 channel images as input. It uses 4 conv layers, max pooling, modest dropout on two layers (one conv and one fc layer), and ReLU. It was found that BN made convergence unstable, so dropout was used instead. Since both DO and BN can behave as regularizers, they are not necessarily used together. A smaller CNN sample is also supplied if the user wants experiment. The larger CNN was able to push accuracy from 75 to almost 80 percent.","f3c21b26":"## **Lightweight CNN Classifier in PyTorch**\n\n### **Introduction**\nThe purpose of this project is to create and try several simple and small CNN architectures in PyTorch that are still capable of good prediction accuracy using two flower classes from the original 'flowers_recognition' data set. Simply by random choice, the rose and tulip data were employed here. This is an ongoing project and the present architecture used in the code is the result of various expriments with conv layers (not more than 4), dropout, and batch-norm. More sophisticated searches can be made (e.g. with neural search methods) in the future. \n\nWith the data as described, an accuracy of 79+ percent is achieved with only about 20 minutes of training on GPU, and given the very small architecture, is an encouraging result. Obviously far more sophisticated CNNs are available and can be used with transfer learning, as well as in an ensemble with other CNNs. However, the purpose here is to extract as much performance as possible with a very modest CNN.","c7ec3e7b":"### **Imports and Parameters**\n\nThe most notable parameters here that need some mention are the learning rate, epochs, and batch size. Due to the relatively small data set, as well as small CNN, the step size must be set very conservatively and epochs relatively large. Fortunately, the small CNN (and small images, 100x100 pixels) allow very large batches (300-500 images), which help improve the gradient search. GPU memory usage is well within hardware limits (about 8GBs). This obviously helps to smooth out the loss and accuracy curves. ","5e17bff9":"### **Loss and Optimizer**\n\nWe chose cross entropy loss (for classification) and Adam optimizer, both being so common and among the best performers. ","9fc2e4e4":"### **Plotting Loss and Accuracy**\n\nHere we plot average loss and accuracy per epoch. We recognize that the results exhibit some choppyness, but it is under control and both plots demonstrate clearly demonstrate convergence and learning.","3deabdce":"### **Code Intro and Data Organization**","aff01b11":"### **Sample Image from Data Set**\n\nLet us pull and visualize one sample image from the set to demonstrate the 100x100 pixel size and correct function of imagefolder class.","2e333967":"### **Transforms and Data Loaders**\n\nThe primary transforms used are resize and crop since the images may not all be of equal size. Following this, the train data are also subjected to a random horizontal flip for some augmentation. Note that normalization of the images is not employed, but may lead to improved results. Since the data set is small, only train and validation sets were created. Different batch sizes were employed to maximize performance.","87258989":"### **Confusion Matrices for Train and Validation** \n\nFinally, we organize the inference results above to obtain confusion matrices, sotred in ZZ. The plotting function confplot_func below, yields a decent looking output. We notice that, despite a nontrivial imbalance in the training\/val data (more tulips than roses), the model demonstrates an approximately equal performance in predicting roses and tulips."}}