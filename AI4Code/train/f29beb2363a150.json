{"cell_type":{"ea033cf2":"code","6c8337f3":"code","34c23c93":"code","88c70a8e":"code","f8420535":"code","93969068":"code","a79d9ec6":"code","46ebbf36":"code","6213ebf1":"code","94823ea1":"code","6c8ee9ea":"code","a0830ce5":"code","06f448eb":"code","09ac37bd":"markdown","63be8143":"markdown","46a5d386":"markdown","39391e51":"markdown","12561700":"markdown","0750c15b":"markdown","ce5d19be":"markdown","f1633c1f":"markdown","bebb5dd1":"markdown","3690457d":"markdown","0f15ea49":"markdown"},"source":{"ea033cf2":"#import lib\nimport numpy as np\nfrom tabulate import tabulate\nfrom matplotlib import pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.optimizers import Adam\n\n# install TF similarity if not there\ntry:\n    import tensorflow_similarity as tfsim  # main package\nexcept:\n    !pip install tensorflow_similarity\n    import tensorflow_similarity as tfsim\nfrom tensorflow_similarity.utils import tf_cap_memory\nfrom tensorflow_similarity.layers import MetricEmbedding # row wise L2 norm\nfrom tensorflow_similarity.losses import MultiSimilarityLoss  # specialized similarity loss\nfrom tensorflow_similarity.models import SimilarityModel # TF model with additional features\nfrom tensorflow_similarity.samplers import MultiShotMemorySampler  # sample data \nfrom tensorflow_similarity.samplers import select_examples  # select n example per class\nfrom tensorflow_similarity.visualization import viz_neigbors_imgs  # neigboors vizualisation\nfrom tensorflow_similarity.visualization import confusion_matrix  # matching performance","6c8337f3":"!pip install tensorflow_similarity","34c23c93":"tfsim.utils.tf_cap_memory()\nprint('TensorFlow:', tf.__version__)\nprint('TensorFlow Similarity', tfsim.__version__)","88c70a8e":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()","f8420535":"CLASSES = [2, 3, 1, 7, 9, 6, 8, 5, 0, 4]\nNUM_CLASSES = 6  #@param {type: \"slider\", min: 1, max: 10}\nCLASS_PER_BATCH = NUM_CLASSES\nEXAMPLE_PER_CLASS = 6 #@param {type:\"integer\"}\nSTEPS_PER_EPOCH = 1000 #@param {type:\"integer\"}\n\nsampler = MultiShotMemorySampler(x_train, y_train, \n                                 classes_per_batch=CLASS_PER_BATCH, \n                                 examples_per_class_per_batch=EXAMPLE_PER_CLASS,\n                                 class_list=CLASSES[:NUM_CLASSES], # Only use the first 6 classes for training.\n                                 steps_per_epoch=STEPS_PER_EPOCH)","93969068":"def get_model():\n    inputs = layers.Input(shape=(28, 28, 1))\n    x = layers.experimental.preprocessing.Rescaling(1\/255)(inputs)\n    x = layers.Conv2D(32, 7, activation='relu')(x)\n    x = layers.Conv2D(32, 3, activation='relu')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Conv2D(64, 7, activation='relu')(x)\n    x = layers.Conv2D(64, 3, activation='relu')(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(64, activation='relu')(x)\n    # smaller embeddings will have faster lookup times while a larger embedding will improve the accuracy up to a point.\n    outputs = MetricEmbedding(64)(x)\n    return SimilarityModel(inputs, outputs)\nmodel = get_model()\nmodel.summary()","a79d9ec6":"distance = 'cosine' #@param [\"cosine\", \"L2\", \"L1\"]{allow-input: false}\nloss = MultiSimilarityLoss(distance=distance)","46ebbf36":"LR = 0.0001  #@param {type:\"number\"}\nmodel = get_model()\nmodel.compile(optimizer=Adam(LR), loss=loss)","6213ebf1":"EPOCHS = 10 #@param {type:\"integer\"}\nhistory = model.fit(sampler, epochs=EPOCHS, validation_data=(x_test, y_test))","94823ea1":"# expect loss: 0.1853 \/ val_loss: 1.4360\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.title(f'Loss: {loss.name} - LR: {LR}')\nplt.show()","6c8ee9ea":"x_index, y_index = select_examples(x_train, y_train, CLASSES, 20)\nmodel.reset_index()\nmodel.index(x_index, y_index, data=x_index)","a0830ce5":"# used to label in images in the viz_neighbors_imgs plots\n# note we added a 11th classes for unknown\nlabels = [\"0\", \"1\",  \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"Unknown\"]\n\n# re-run to test on other examples\nnum_neighboors = 5\n\n# select\nx_display, y_display = select_examples(x_test, y_test, CLASSES, 1)\n\n# lookup nearest neighbors in the index\nnns = model.lookup(x_display, k=num_neighboors)\n\n# display\nfor idx in np.argsort(y_display):\n    viz_neigbors_imgs(x_display[idx], y_display[idx], nns[idx], \n                      class_mapping=labels, fig_size=(16, 2), cmap='Greys')","06f448eb":"num_calibration_samples = 1000 #@param {type:\"integer\"}\ncalibration = model.calibrate(\n    x_train[:num_calibration_samples], \n    y_train[:num_calibration_samples], \n    extra_metrics=['precision', 'recall', 'binary_accuracy'], \n    verbose=1\n)","09ac37bd":"# Indexing \/ Inference\nIndexing is where things get different from traditional classification models. Because the model learned to output an embedding that represent the example position within the learned metric space, we need a way to find which known example(s) are the closest to determine the class of the query example (aka nearest neighboors classication).\n\nTo do so, we are creating an index of known examples from all the classes present in the dataset. We do this by taking a total of 200 examples from the train dataset which amount to 20 examples per class and we use the index() method of the model to build the index.\n\nwe store the images (x_index) as data in the index (data=x_index) so that we can display them later. Here the images are small so its not an issue but in general, be careful while storing a lot of data in the index to avoid blewing up your memory. You might consider using a different Store() backend if you have to store and serve very large indexes.\n\nIndexing more examples per class will help increase the accuracy\/generalization, as having more variations improves the classifier \"knowledge\" of what variations to expect.\n\nReseting the index is not needed for the fist run; however we always calling it to ensure we start the evaluation with a clean index in case of a partial re-run.","63be8143":"# Model setup\n**Model definition**\nSimilarityModel() models extend tensorflow.keras.model.Model with additional features and functionality that allow you to index and search for similar looking examples.\n\nAs visible in the model definition below, similarity models output a 64 dimensional float embedding using the MetricEmbedding() layers. This layer is a Dense layer with L2 normalization. Thanks to the loss, the model learns to minimize the distance between similar examples and maximize the distance between dissimilar examples. As a result, the distance between examples in the embedding space is meaningful; the smaller the distance the more similar the examples are.\n\nBeing able to use a distance as a meaningful proxy for how similar two examples are, is what enables the fast ANN (aproximate nearest neighbor) search. Using a sub-linear ANN search instead of a standard quadratic NN search is what allows deep similarity search to scale to millions of items. The built in memory index used in this notebook scales to a million indexed examples very easily... if you have enough RAM :)","46a5d386":"# Compilation\nTensorflow similarity use an extended compile() method that allows you to optionally specify distance_metrics (metrics that are computed over the distance between the embeddings), and the distance to use for the indexer.\n\nBy default the compile() method tries to infer what type of distance you are using by looking at the fist loss specified. If you use multiple losses, and the distance loss is not the first one, then you need to specify the distance function used as distance= parameter in the compile function.","39391e51":"This notebook demonstrates the use of Tensorflow Similarity Learning library to solve, on a fraction of the MNIST classes, the problem of indexing and retrieving similar looking images for all MNIST classes.\n\n\n# You are going to learn about the main features offered by the SimilarityModel() and will:\n\n*  train() a similarity model on a sub-set of the 10 MNIST classes that will learn how to project digits within a cosine space\n\n*  index() a few examples of each of the 10 classes present in the train dataset (e.g 10 images per classes) to make them searchable\n\n*  lookup() a few test images to check that the trained model, despite having only a few examples of seen and unseen classes in it's index, is able to efficiently retrieve similar looking examples for all classes.\n\n*  calibrate() the model to estimate what is the best distance theshold to separate matching elements from elements belonging to other classes.\n\n*  match() the test dataset to evaluate how well the calibrated model works for classification purpose.\n\n![image.png](attachment:1b7b0ac6-85ab-4397-9d48-aea78a744cc8.png)","12561700":"# Loss definition\nOverall what makes Metric losses different from tradional losses is that:\n\nThey expect different inputs. Instead of having the prediction equal the true values, they expect embeddings as y_preds and the id (as an int32) of the class as y_true.\nThey require a distance. You need to specify which distance function to use to compute the distance between embeddings. cosine is usually a great starting point and the default.\nIn this example we are using the MultiSimilarityLoss(). This loss takes a weighted combination of all valid positive and negative pairs, making it one of the best loss that you can use for similarity training.","0750c15b":"# Matching\nTo be able to tell if an example matches a given class, we first need to calibrate() the model to find the optimal cut point. This cut point is the maximum distance below which returned neighbors are of the same class. Increasing the threshold improves the recall at the expense of the precision.\n\nBy default, the calibration uses the F1Score classification metric to optimally balance out the precsion and recalll; however, you can speficy your own target and change the calibration metric to better suite your usecase.","ce5d19be":"# Training\nSimilarity models are trained like normal models.\n\nNOTE: don't expect the validation loss to decrease too much here because we only use a subset of the classes within the train data but include all classes in the validation data.","f1633c1f":"# Data preparation\nWe are going to load the MNIST dataset and restrict our training data to only N of the 10 classes (6 by default) to showcase how the model is able to find similar examples from classes unseen during training. The model's ability to generalize the matching to unseen classes, without retraining, is one of the main reason you would want to use metric learning.\n\nWARNING: Tensorflow similarity expects y_train to be an IntTensor containing the class ids for each example instead of the standard categorical encoding traditionally used for multi-class classification.","bebb5dd1":"\n# Querying\nTo \"classify\" examples, we need to lookup their k nearest neighbors in the index.\n\nHere we going to query a single random example for each class from the test dataset using select_examples() and then find their nearest neighboors using the lookup() function.\n\nNOTE By default the classes 8, 5, 0, and 4 were not seen during training, but we still get reasonable matches as visible in the image below.\n\n","3690457d":"# Enjoy your learning :) !!!","0f15ea49":"For a similarity model to learn efficiently, each batch must contains at least 2 examples of each class.\n\nTo make this easy, tf_similarity offers Samplers() that enable you to set both the number of classes and the minimum number of examples of each class per batch. Here we are creating a MultiShotMemorySampler() which allows you to sample an in-memory dataset and provides multiple examples per class.\n\nTensorFlow Similarity provides various samplers to accomodate different requirements, including a SingleShotMemorySampler() for single-shot learning, a TFDatasetMultiShotMemorySampler() that integrate directly with the TensorFlow datasets catalogue, and a TFRecordDatasetSampler() that allows you to sample from very large datasets stored on disk as TFRecords shards."}}