{"cell_type":{"2038fb34":"code","28ef805d":"code","2fc8822b":"code","170b57f3":"code","73c17b6d":"code","b7e76175":"code","a1b961a9":"code","b6ab7018":"code","99426151":"code","6e28bd55":"code","47c939f9":"code","0685b06d":"code","3271016e":"code","452238ad":"code","3de94976":"code","7171338d":"code","a8b16c73":"code","cc380f22":"code","06347dd7":"code","7195a00e":"code","2c0058b9":"code","e9b2d203":"code","5830e2da":"code","f3c89f0f":"code","cbf0b401":"code","f7b3dee2":"code","dbc75675":"markdown","ec2f80c9":"markdown","8335d07a":"markdown","09bb1381":"markdown","24d7f405":"markdown","f4bd49e1":"markdown","aaafa7d7":"markdown"},"source":{"2038fb34":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow.keras.layers as L\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport os\n\ndata_dir = '..\/input\/vehicle-data\/'","28ef805d":"# Reading Data\nvehicle = pd.read_csv(os.path.join(data_dir, 'Train_Vehicletravellingdata.csv'))\nweather = pd.read_csv(os.path.join(data_dir, 'Train_WeatherData.csv'))\ntrain = pd.read_csv(os.path.join(data_dir, 'Train.csv'))","2fc8822b":"# Concat vehicle and weather data\ncons_df = pd.concat([vehicle, weather.drop(columns=['ID', 'Date time'])], axis=1)\n# Merge with train data\ncons_df = cons_df.merge(train, on=['ID'])","170b57f3":"# Sample Data\ncons_df.head()","73c17b6d":"# About columns\ncons_df.info()","b7e76175":"# Let's see the count of target variable\n# driving_style_df = cons_df['DrivingStyle'].value_counts().to_frame()\n# driving_style_df.columns = ['count']\n# driving_style_df['Labels'] = driving_style_df.index\n\n# fig = px.bar(driving_style_df, x='Labels', y='count')\n# fig.show()","a1b961a9":"# Count of missing values in columns\n# missing_values = cons_df.isnull().sum()\n# missing_values = missing_values[missing_values > 0].sort_values()\n\n# missing_values = missing_values.to_frame()\n# missing_values.columns = ['count']\n# missing_values.index.names = ['Name']\n# missing_values['Name'] = missing_values.index\n\n# fig = px.bar(missing_values, x='Name', y='count')\n# fig.show()","b6ab7018":"# Checking distribution of Speed\n# df = px.data.tips()\n# fig = px.box(cons_df, y=\"Speed of the vehicle (kph)\", points=\"all\")\n# fig.show()","99426151":"cons_df['Road Condition'].value_counts()","6e28bd55":"# Removing outliers\ncons_df = cons_df.loc[\n    (cons_df['Speed of the vehicle (kph)']> 20) & \n    (cons_df['Speed of the vehicle (kph)']<140)\n]","47c939f9":"label_encoding_columns = [\n    'Road Condition', 'Precipitation', 'Precipitation intensity', 'Day time'\n]","0685b06d":"cons_df[label_encoding_columns]","3271016e":"cons_df[label_encoding_columns] = cons_df[label_encoding_columns].apply(LabelEncoder().fit_transform)","452238ad":"train_df = cons_df.drop(columns=['ID of the preceding vehicle','Date time', 'DrivingStyle'])","3de94976":"missing_values_columns = list(missing_values['Name'])\n\nfor col in missing_values_columns:\n    train_df[col] = train_df[col].fillna(train_df[col].mean())","7171338d":"train_df.head()","a8b16c73":"# Let's make some features\ncons_df['speed_ratio'] = cons_df['Speed of the vehicle (kph)']\/cons_df['Speed of the preceding vehicle']\ncons_df['time_ratio1'] = cons_df['Time gap with the preceeding vehicle in seconds']\/cons_df['Speed of the vehicle (kph)']\ncons_df['time_ratio2'] = cons_df['Time gap with the preceeding vehicle in seconds']\/cons_df['Speed of the preceding vehicle']","cc380f22":"scaling_columns = [\n    'Speed of the vehicle (kph)', 'Speed of the preceding vehicle', 'Length of preceding vehicle',\n    'Time gap with the preceeding vehicle in seconds', 'Weather details-Air temperature', 'Weight of the preceding vehicle',\n    'Relative humidity', 'Wind direction', 'Wind speed in m\/s', 'Length of vehicle in cm', 'weight of vehicle in kg',\n    'Number of axles', 'Number of axles'\n]\nscaler = StandardScaler()\ntrain_df[scaling_columns] = scaler.fit_transform(train_df[scaling_columns])","06347dd7":"train_df","7195a00e":"sequences = list()\n\nfor name, group in tqdm(train_df.groupby(['ID'])):\n    sequences.append(group.drop(columns=['ID']).values)\n    \n# train_values = np.asarray(train_values)","2c0058b9":"len_sequences = []\nfor one_seq in sequences:\n    len_sequences.append(len(one_seq))\npd.Series(len_sequences).describe()","e9b2d203":"#Padding the sequence with the values in last row to max length\nto_pad = 112\nnew_seq = []\nfor one_seq in sequences:\n    len_one_seq = len(one_seq)\n    last_val = one_seq[-1]\n    n = to_pad - len_one_seq\n   \n    to_concat = np.repeat(one_seq[-1], n).reshape(17, n).transpose()\n    new_one_seq = np.concatenate([one_seq, to_concat])\n    new_seq.append(new_one_seq)\nfinal_seq = np.stack(new_seq)\n\n#truncate the sequence to length 60\n# from tf.keras.preprocessing import sequence\nseq_len = 60\nfinal_seq=tf.keras.preprocessing.sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float', truncating='post')","5830e2da":"# from keras.utils.np.utils import to_categorical\n# y_train = to_categorical(y_train)\n\ntarget = pd.get_dummies(train['DrivingStyle'])\ntarget = np.asarray(target)","f3c89f0f":"X_train, X_test, y_train, y_test = train_test_split(final_seq, target, test_size=0.20, random_state=34)","cbf0b401":"model = tf.keras.models.Sequential()\nmodel.add(L.LSTM(128, dropout=0.2, input_shape=(seq_len, 17), return_sequences=True))\nmodel.add(L.LSTM(64, dropout=0.2, input_shape=(seq_len, 17), return_sequences=True))\nmodel.add(L.LSTM(64, dropout=0.2))\nmodel.add(L.Dense(3, activation='softmax'))","f7b3dee2":"# adam = tf.optimizers.Adam(lr=0.1, clipvalue=0.5)\nadam = tf.keras.optimizers.Adam(lr=0.001)\n# sgd = tf.keras.optimizers.SGD(lr=1)\nsgd = tf.keras.optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n\n# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\nmodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n\nmodel.fit(\n    X_train,\n    y_train,\n    epochs=100,\n    batch_size=84,\n    validation_data=(X_test, y_test),\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n    ]\n)\n","dbc75675":"## EDA","ec2f80c9":"## Imports and inits","8335d07a":"### Imputing missing values with mean","09bb1381":"### Dropping redundant columns","24d7f405":"## Merging data\nSince vehicle and weather have same number of rows with same sequence of vehicle Id and time we directly concat the dataframes and merge train data on **ID** column.","f4bd49e1":"### Label encoding columns","aaafa7d7":"## Preprocessing\n\nLabel encoding columns like \n> ['Road Condition', 'Precipitation', 'Precipitation intensity', 'Day time', 'ID of the preceding vehicle']"}}