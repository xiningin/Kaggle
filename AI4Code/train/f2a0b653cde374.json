{"cell_type":{"072ebbc9":"code","7cb91232":"code","fe458513":"code","97670d42":"code","614d2a96":"code","35636392":"code","c62dba75":"code","dd39137b":"code","dd12ede6":"code","8573c200":"code","e4cb59af":"code","6e9f555b":"code","fe546375":"code","55e358b5":"code","cfc18b79":"code","97daaf34":"code","fcf97aaf":"code","573e2327":"code","35da4234":"code","9712e085":"code","8edb88ee":"code","2a0dabc7":"code","d9a75300":"code","71f6118c":"code","dc4a3aea":"code","ad70f53b":"code","642a8dcd":"code","491e0586":"code","75de64b1":"code","591408c9":"code","07c457b0":"code","8da2d2a5":"code","ebdf98eb":"code","29bea377":"code","4e1baaa9":"code","027b4106":"code","dbffc4cb":"code","24e4005d":"code","538066ed":"code","a365114d":"code","35ff13ac":"code","50145b95":"code","9b518a19":"code","1c60ed97":"code","0ca6381e":"code","8114968f":"code","71ad2d6c":"code","fa2f76bd":"code","8267eea2":"code","c26f8415":"code","2378f318":"code","a0a35e1e":"code","54ad1dad":"code","ec692219":"code","4d880542":"code","cae5631f":"code","350ef85c":"code","8dde38d5":"code","30ef1402":"code","cf264c39":"code","a2aa035d":"code","62c05313":"code","57e04e77":"code","96b9c573":"code","bf86aba2":"code","45a048bd":"code","72cce24d":"code","186d747f":"code","eec750bd":"code","c33cec8e":"code","c0c610df":"code","b66d1ffd":"code","1906c7ee":"code","2fe06b33":"markdown","02bf6e24":"markdown","35f3c235":"markdown","508c3d32":"markdown","45d60c5f":"markdown","078092a1":"markdown","d715e0fc":"markdown","1129ca79":"markdown","c81fff3f":"markdown","8f268d76":"markdown","702ce1f5":"markdown","0b9f08fc":"markdown","ea6c4b2e":"markdown","046b5893":"markdown","fc94387e":"markdown","fd4f7bb2":"markdown","920b5580":"markdown","5f1ab179":"markdown","4ed1fe42":"markdown","a2235ad4":"markdown","1e9a4d20":"markdown","c07af300":"markdown","a66aa499":"markdown","51fb45e9":"markdown","5e99d793":"markdown","7465089b":"markdown","74d46723":"markdown","52645587":"markdown","7ff130b8":"markdown","d1f974ed":"markdown","dca4381f":"markdown","f8a9015c":"markdown","864ef322":"markdown","53549af5":"markdown","2240d220":"markdown","ea6083f0":"markdown","3b5e2bbd":"markdown","b4b008ea":"markdown","1c243baf":"markdown","da3024aa":"markdown","76314d20":"markdown","bbd250eb":"markdown","8592d24a":"markdown","a0b62878":"markdown","c3550c12":"markdown","30e04f31":"markdown"},"source":{"072ebbc9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7cb91232":"import pandas as pd\n\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","fe458513":"train.head(5)","97670d42":"train.info()","614d2a96":"test.info()","35636392":"train.isnull().sum()","c62dba75":"test.isnull().sum()","dd39137b":"import matplotlib.pyplot as plt\nimport seaborn as sns","dd12ede6":"sns.countplot(train['Survived'])","8573c200":"sns.countplot(x=train['Survived'],hue=train['Sex'])","e4cb59af":"train_test_data = [train, test] # combining train and test dataset","6e9f555b":"for dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.', expand=False) # any letter followed by dot in any place\n    ","fe546375":"train['Title'].value_counts()","55e358b5":"test['Title'].value_counts()","cfc18b79":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","97daaf34":"train.head()","fcf97aaf":"test.head()","573e2327":"sns.countplot(train['Title'])","35da4234":"train.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","9712e085":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","8edb88ee":"sns.countplot(train['Sex'])","2a0dabc7":"train.groupby(\"Title\")[\"Age\"].median()","d9a75300":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","71f6118c":"train.info()","dc4a3aea":"survived = train[train[\"Survived\"] == 1]\ndied = train[train[\"Survived\"] == 0]\nsurvived[\"Age\"].plot.hist(alpha=0.5,color='red',bins=12)\ndied[\"Age\"].plot.hist(alpha=0.5,color='blue',bins=12)\nplt.legend(['Survived','Died'])\nplt.show()","ad70f53b":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","642a8dcd":"sns.countplot(train['Age'], hue = train[\"Survived\"])","491e0586":"# Embarked\ntrain[\"Embarked\"].value_counts()","75de64b1":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","591408c9":"train.head()","07c457b0":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","8da2d2a5":"train.groupby(\"Pclass\")[\"Fare\"].median()","ebdf98eb":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head()","29bea377":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True) # estimated distribution\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n\n#plt.xlim(0, 20)\nplt.show()  ","4e1baaa9":"for dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","027b4106":"train.head()","dbffc4cb":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","24e4005d":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","538066ed":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","a365114d":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","35ff13ac":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1 # plus one means plus the person\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","50145b95":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","9b518a19":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","1c60ed97":"train.head()","0ca6381e":"test.head()","8114968f":"features_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","71ad2d6c":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","fa2f76bd":"train_data.head(10)","8267eea2":"# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport numpy as np","c26f8415":"train.info()","2378f318":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","a0a35e1e":"k_fold = KFold(n_splits=10, shuffle=True, random_state=0)","54ad1dad":"clf = KNeighborsClassifier(n_neighbors = 13)\n\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring='accuracy')\nprint(score)","ec692219":"# kNN Score\nround(np.mean(score)*100, 2)","4d880542":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","cae5631f":"# decision tree Score\nround(np.mean(score)*100, 2)","350ef85c":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","8dde38d5":"# Random Forest Score\nround(np.mean(score)*100, 2)","30ef1402":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","cf264c39":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","a2aa035d":"train_data.shape , target.shape","62c05313":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score","57e04e77":"def create_network():\n    # create the model sequential\n    model = Sequential( )\n    model.add(Dense(units = 64,input_dim = 8 , activation='relu'))\n    model.add(Dense(units = 128, activation='relu'))\n    model.add(Dense(units = 32, activation='relu'))\n    # we need to pass sigmoid function here for binary classification\n    model.add(Dense(units = 1, activation='sigmoid'))\n    model.compile(Adam(lr=0.05),loss='binary_crossentropy',metrics=['accuracy'])\n    \n    return model\n\n\n# Wrap Keras model so it can be used by scikit-learn\nneural_network = KerasClassifier(build_fn=create_network, \n                                 epochs=10, \n                                 \n                                 verbose=0)\n# Evaluate neural network using three-fold cross-validation\nscore = cross_val_score(neural_network, train_data, target, cv=10)","96b9c573":"round(np.mean(score)*100, 2)","bf86aba2":"# one more test\nX_train, X_test, y_train, y_test = train_test_split(train_data, target)","45a048bd":"neural_network.fit(X_train, y_train)","72cce24d":"result = neural_network.predict_proba(X_test)","186d747f":"np.argmax(result[10])","eec750bd":"neural_network.score(X_test, y_test)","c33cec8e":"clf = KNeighborsClassifier(n_neighbors = 13)\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","c0c610df":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","b66d1ffd":"submission = pd.read_csv('submission.csv')\nsubmission.head()","1906c7ee":"submission.to_csv(\"Titanic_Submission.csv\",index=False)","2fe06b33":"# Titanic: \n\n","02bf6e24":"## 1. Defining the problem statement\n+ Complete the analysis of what sorts of people were likely to survive.  \n\n+ apply the tools of machine learning to predict which passengers survived the Titanic tragedy.","35f3c235":"### 4.7 Cabin","508c3d32":"### Bar Chart for Categorical Features\n- Pclass\n- Sex\n- SibSp ( # of siblings and spouse)\n- Parch ( # of parents and children)\n- Embarked\n- Cabin","45d60c5f":"The Chart confirms **Women** more likely survivied than **Men**","078092a1":"#### Title map\n\n* manually mapping all the titles\n* use the .map() function on both dataset using a for loop\n* pass to the map function the dictionary of our custom map\n\nMr : 0  \nMiss : 1  \nMrs: 2  \nOthers: 3\n","d715e0fc":"### 4.1 how titanic sank?\nsank from the bow of the ship where third class rooms located  \nconclusion, Pclass is key feature for classifier","1129ca79":"### 4.4 Age","c81fff3f":"* delete unnecessary feature from dataset using drop()","8f268d76":"* binnning again","702ce1f5":"* good to map in order and max is 11","0b9f08fc":"## 3. Exploratory data analysis\nPrinting first 5 rows of the train dataset.","ea6c4b2e":"### 4.6 Fare","046b5893":"**Total rows and columns**\n\nUsing info() We can see that there are 891 rows and 12 columns in our training dataset.","fc94387e":"### 4.5 Embarked","fd4f7bb2":"* https:\/\/seaborn.pydata.org\/generated\/seaborn.FacetGrid.html","920b5580":"### 4.3 Sex\n\nmale: 0\nfemale: 1\n\n* use the same mapping techinques for sex_mapping = {\"male\": 0, \"female\": 1}","5f1ab179":"## 4. Feature engineering\n\nFeature engineering is the process of using domain knowledge of the data  \nto create features (**feature vectors**) that make machine learning algorithms work.  \n","4ed1fe42":"## 7. Testing","a2235ad4":"* sns.countplot(train['Title'])","1e9a4d20":"* use mapping again","c07af300":"### 4.8 FamilySize","a66aa499":"### 6.2.2 Decision Tree","51fb45e9":"* the probability of survive changes depending on the bin , which means that we added some useful information","5e99d793":"https:\/\/www.computerhope.com\/unix\/regex-quickref.htm\n\n* regular expression use:\n* or dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n* so now we have a new column called \"Title\" in both dataset\n\n","7465089b":"#### 4.5.1 filling missing values","74d46723":"## 2. Collecting the data\n\n\n### load train, test dataset using Pandas","52645587":"* this plot shows that the letters correspond to the Pclass so that binning them in order would be good","7ff130b8":"### 6.2.4 Naive Bayes","d1f974ed":"* check the _value_counts() on the title column\n* do on the train and test","dca4381f":"### 6.2.1 kNN","f8a9015c":"* take only the first letter of the column","864ef322":"### 6.2 Cross Validation (K-fold)","53549af5":"### 6.2.5 Neural Network","2240d220":"## 5. Modelling","ea6083f0":"### 6.2.3 Ramdom Forest","3b5e2bbd":"#### 4.4.2 Binning\nBinning\/Converting Numerical Age to Categorical Variable  \n\nfeature vector map:  \nchild: 0  \nyoung: 1  \nadult: 2  \nmid-age: 3  \nsenior: 4","b4b008ea":"* we are going to bin the age into 5 values","1c243baf":"### Data Dictionary\n- Survived: \t0 = No, 1 = Yes  \n- pclass: \tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd  \t\n- sibsp:\t# of siblings \/ spouses aboard the Titanic  \t\n- parch:\t# of parents \/ children aboard the Titanic  \t\n- ticket:\tTicket number\t\n- cabin:\tCabin number\t\n- embarked:\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton  ","da3024aa":"* check the head of both train and test","76314d20":"### import python lib for visualization\n\n+ import matplotlib.pyplot as plt\n+ import seaborn as sns","bbd250eb":"#### 4.4.1 some age is missing\nLet's use Title's median age for missing Age\n* https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.transform.html","8592d24a":"We can see that *Age* value is missing for many rows. \n\nOut of 891 rows, the *Age* value is present only in 714 rows.\n\nSimilarly, *Cabin* values are also missing in many rows. Only 204 out of 891 rows have *Cabin* values.\n\n+ use isnull().sum()","a0b62878":"### 4.2 Name\n\n+ we need to work on train and test to do feature engeeniring on the entire data we have\n+ a simple way to performe the same operation on two objects is to group the 2 into a list and then use for loop ","c3550c12":"* in day five we plotted this graph","30e04f31":"There are 177 rows with missing *Age*, 687 rows with missing *Cabin* and 2 rows with missing *Embarked* information."}}