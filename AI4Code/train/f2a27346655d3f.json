{"cell_type":{"a5420efd":"code","35224f8c":"code","b9e28b14":"code","5ab703dc":"code","b85d6688":"code","a6ab71ff":"code","ba171126":"code","2b973b01":"code","90e4a6f9":"code","0f848c07":"code","b7fc4ec2":"code","31c938db":"code","4d70995c":"code","13de8c25":"code","4e14a22a":"code","e04d7a37":"code","e767b9c9":"code","1b66f267":"code","80855676":"code","d0247e1f":"code","916a18c1":"code","37390b13":"code","2ebaf2e2":"markdown","d31f368c":"markdown","ebe4b393":"markdown","e8d308a9":"markdown","a1b6693d":"markdown","8bb97bd5":"markdown","b30c2a6a":"markdown","dfcf56be":"markdown","8cd2c899":"markdown","a95c631b":"markdown","87d5019f":"markdown","622f8c1a":"markdown","dff370e6":"markdown","8cf778c5":"markdown"},"source":{"a5420efd":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm\nprint(\"Dependecies imported successfully.\")\nprint(\"Version of OpenCV used = \", cv2.__version__)\nprint(\"Version Of Tensorflow used = \", tf.__version__)","35224f8c":"train = pd.DataFrame(pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\"))\n\ntrain.head()","b9e28b14":"train_image_statistics = pd.DataFrame(pd.read_csv(\"..\/input\/cassavaimagestatistics\/train_image_statistics.csv\"))\n\ntrain_image_statistics.head()","5ab703dc":"def non_local_means_denoising(image) : \n    denoised_image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n    return denoised_image","b85d6688":"def histogram_equalization(image) : \n    image_ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCR_CB)\n    y_channel = image_ycrcb[:,:,0] # apply local histogram processing on this channel\n    cr_channel = image_ycrcb[:,:,1]\n    cb_channel = image_ycrcb[:,:,2]\n    \n    # Local histogram equalization\n    clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize=(8,8))\n    equalized = clahe.apply(y_channel)\n    equalized_image = cv2.merge([equalized, cr_channel, cb_channel])\n    equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_YCR_CB2RGB)\n    return equalized_image","a6ab71ff":"SIZE = 2100 # these many images I am clipping in one .tfrec file.\n\nnum_of_images = len(os.listdir(\"..\/input\/cassava-leaf-disease-classification\/train_images\"))\nimage_names = os.listdir(\"..\/input\/cassava-leaf-disease-classification\/train_images\")\n\nprint(\"Number Of Training Images =\",  num_of_images)","ba171126":"split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15, random_state = 42)\nfor train_index, val_index in split.split(train, train[\"label\"]) : \n    stratified_train_set = train.loc[train_index]\n    stratified_val_set = train.loc[val_index]","2b973b01":"def analyze_label_distibution(dataframe) : # The training and validation dataframe created post stratified splitting are passed to this function.\n    label_count = dict()\n    for label in tqdm(dataframe[\"label\"].values) : \n        if label not in label_count : \n            label_count[label] = 1\n        else:\n            label_count[label] += 1\n    \n    labels = [\"Cassava Bacterial Blight (CBB)\", \"Cassava Brown Streak Disease (CBSD)\", \"Cassava Green Mottle (CGM)\", \n          \"Cassava Mosaic Disease (CMD)\", \"Healthy\"]\n    counts = [label_count[0], label_count[1], label_count[2], label_count[3], label_count[4]]\n\n    explode = (0.05, 0.05, 0.05, 0.05, 0.05)\n    #fig, ax = plt.subplots(figsize = (15, 12))\n    plt.figure(figsize = (20, 12))\n    plt.pie(counts, explode = explode, labels = labels, shadow = True, startangle = 90)\n    plt.axis(\"equal\")\n    \n    count_bacterial_blight = label_count[0]\n    count_brown_streak = label_count[1]\n    count_green_mottle = label_count[2]\n    count_mosaic = label_count[3]\n    count_healthy = label_count[4]\n\n    print(\"Bacterial Blight count = \", count_bacterial_blight)\n    print(\"Brown Steak Count = \", count_brown_streak)\n    print(\"Green Mottle count = \", count_green_mottle)\n    print(\"Mosaic count = \", count_mosaic)\n    print(\"Healthy count = \", count_healthy)","90e4a6f9":"analyze_label_distibution(stratified_train_set)","0f848c07":"analyze_label_distibution(stratified_val_set)","b7fc4ec2":"training_image_ids = stratified_train_set[\"image_id\"].values\nvalidation_image_ids = stratified_val_set[\"image_id\"].values\n\nprint(\"Number Of Training Images = \", len(training_image_ids))\nprint(\"Number of Validation Images = \", len(validation_image_ids))","31c938db":"PATH_TRAIN = \"..\/input\/cassava-leaf-disease-classification\/train_images\/\"\nPATH_VAL = \"..\/input\/cassava-leaf-disease-classification\/train_images\/\"\nPATH_TEST = \"..\/input\/cassava-leaf-disease-classification\/test_images\/\"","4d70995c":"def bytes_features(value) : \n    \"\"\"\n    Returns a bytes_list from a string\/byte. \n    \n    isinstance() function : Returns True if the specified object is of the specified type, otherwise False. \n    Here, say in the first function tf.constant(0) is tensorflow.python.framework.ops.EagerTensor. \n    If passed value happens to be of this type, then True will be retured.\n    \"\"\"\n    if isinstance(value, type(tf.constant(0))) : \n        value = value.numpy() # # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n\ndef float_features(value) : \n    \"\"\"\n    Returns float_list from float\/double.\n    \"\"\"\n    return tf.train.Feature(float_list = tf.train.FloatList(value = [value]))\n\ndef int64_features(value) : \n    \"\"\"\n    Returns int64_list from a boolean\/enum\/int\/uint.\n    \"\"\"\n    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))","13de8c25":"def serialize_example(feature_list) : \n    #feature_list = [image, image_name, label]\n    feature = {\n        \"image\" : bytes_features(feature_list[0]),\n        \"image_name\" : bytes_features(feature_list[1]),\n        \"label\" : int64_features(feature_list[2])\n    }\n    example_proto = tf.train.Example(features = tf.train.Features(feature = feature))\n    return example_proto.SerializeToString()","4e14a22a":"total_chunks = len(training_image_ids)\/\/SIZE + int(len(training_image_ids) %SIZE != 0)\n\nprint(\"Total training TFRecord chunks to be prepared = \", total_chunks)","e04d7a37":"for j in tqdm(range(total_chunks)) : \n    print(\"Writing TFRecord %i of %i\"%(j, total_chunks))\n    count = min(SIZE, len(training_image_ids) - (j * SIZE))\n    with tf.io.TFRecordWriter(\"train%.2i-%i.tfrec\"%(j, count)) as writer : \n        \"\"\"\n        This will be saved as train00-2071.tfrec (for illustration) where the numeral before hyphen is simply \n        a part of name whereas post hyphen denotes number of entries in this record. Here, 2071 entries are in\n        the record. \n        \"\"\"\n        for k in range(count) : \n            image = cv2.imread(PATH_TRAIN + training_image_ids[(SIZE * j) + k])\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # openCV reads images in BGR format\n            image = cv2.resize(image, (256, 256), interpolation = cv2.INTER_NEAREST)\n            #image = non_local_means_denoising(image)\n            #image = histogram_equalization(image)\n            \"\"\"\n            some more IP modules can be appended.\n            \n            \"\"\"\n            image = cv2.imencode(\".jpg\", image, (cv2.IMWRITE_JPEG_QUALITY, 95))[1].tostring()\n            name_with_extension = training_image_ids[SIZE * j + k]\n            name_without_extension = name_with_extension.split(\".\")[0]\n            row = train.loc[train.image_id == name_with_extension]\n            \n            feature_list = [image, str.encode(name_without_extension), row.label.values[0]]\n            \n            example = serialize_example(feature_list)\n            writer.write(example)\n            \n            if k%100 == 0 :\n                print(k, \",\", end = \" \")\n\nprint(\"Training TFRecords Creation Successful! \\n\")","e767b9c9":"total_chunks = len(validation_image_ids)\/\/SIZE + int(len(validation_image_ids) %SIZE != 0)\n\nprint(\"Total training TFRecord chunks to be prepared = \", total_chunks)","1b66f267":"for j in tqdm(range(total_chunks)) : \n    print(\"Writing TFRecord %i of %i\"%(j, total_chunks))\n    count = min(SIZE, len(validation_image_ids) - (j * SIZE))\n    with tf.io.TFRecordWriter(\"val%.2i-%i.tfrec\"%(j, count)) as writer : \n        \"\"\"\n        This will be saved as val00-2071.tfrec (for illustration) where the numeral before hyphen is simply \n        a part of name whereas post hyphen denotes number of entries in this record. Here, 2071 entries are in\n        the record. \n        \"\"\"\n        for k in range(count) : \n            image = cv2.imread(PATH_TRAIN + validation_image_ids[(SIZE * j) + k])\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # openCV reads images in BGR format\n            image = cv2.resize(image, (256, 256), interpolation = cv2.INTER_NEAREST)\n            #image = non_local_means_denoising(image)\n            #image = histogram_equalization(image)\n            \"\"\"\n            some more IP modules can be appended.\n            \n            \"\"\"\n            image = cv2.imencode(\".jpg\", image, (cv2.IMWRITE_JPEG_QUALITY, 95))[1].tostring()\n            name_with_extension = training_image_ids[SIZE * j + k]\n            name_without_extension = name_with_extension.split(\".\")[0]\n            row = train.loc[train.image_id == name_with_extension]\n            \n            feature_list = [image, str.encode(name_without_extension), row.label.values[0]]\n            \n            example = serialize_example(feature_list)\n            writer.write(example)\n            \n            if k%100 == 0 :\n                print(k, \",\", end = \" \")\n\nprint(\"Validation TFRecords Creation Successful! \\n\")","80855676":"def serialize_example(feature_list) : \n    #feature_list = [image, image_name, label]\n    feature = {\n        \"image\" : bytes_features(feature_list[0]),\n        \"image_name\" : bytes_features(feature_list[1])\n    }\n    example_proto = tf.train.Example(features = tf.train.Features(feature = feature))\n    return example_proto.SerializeToString()","d0247e1f":"SIZE = 1\n\nnum_of_images = len(os.listdir(\"..\/input\/cassava-leaf-disease-classification\/test_images\"))\nprint(\"Number Of Testing Images =\",  num_of_images)","916a18c1":"total_chunks = num_of_images\/\/SIZE + int(num_of_images %SIZE != 0)\n\nprint(\"Total testing TFRecord chunks to be prepared = \", total_chunks)","37390b13":"test_image_names = [\"2216849948.jpg\"]\nfor j in tqdm(range(total_chunks)) : \n    print(\"Writing TFRecord %i of %i\"%(j, total_chunks))\n    count = min(SIZE, num_of_images - (j * SIZE))\n    with tf.io.TFRecordWriter(\"test%.2i-%i.tfrec\"%(j, count)) as writer : \n        for k in range(count) : \n            image = cv2.imread(PATH_TEST + test_image_names[(SIZE * j) + k])\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # openCV reads images in BGR format\n            image = cv2.resize(image, (256, 256), interpolation = cv2.INTER_NEAREST)\n            #image = non_local_means_denoising(image)\n            #image = histogram_equalization(image)\n            \"\"\"\n            some more IP modules can be appended.\n            \n            \"\"\"\n            image = cv2.imencode(\".jpg\", image, (cv2.IMWRITE_JPEG_QUALITY, 95))[1].tostring()\n            name_with_extension = test_image_names[SIZE * j + k]\n            name_without_extension = name_with_extension.split(\".\")[0]\n            \n            feature_list = [image, str.encode(name_without_extension)]\n            \n            example = serialize_example(feature_list)\n            writer.write(example)\n            \n            if k%100 == 0 :\n                print(k, \",\", end = \" \")\nprint(\"Test TFRecords Creation Successful! \\n\")","2ebaf2e2":"Similarily perform everything for testing set also.","d31f368c":"# Defining Path To Images :","ebe4b393":"As we can see, class distribution in training and validation sets are similar to each other. ","e8d308a9":"# Caasava- Create TFRecords\n\n![image.png](attachment:image.png)","a1b6693d":"Analysis of our stratified splitting.","8bb97bd5":"# An Insight Into TFRecord File Format :\n\n**It's Tensorflow's binary storage format for your data**.\n\n![image.png](attachment:image.png)\n\n**************************************************************************************************************\n\nOkay, so what's the endgame? Aren't JPEG, PNG also storage formats? What makes this one special ?\n\nBeing binary storage, data takes up relatively low space on your disk, and hence it takes less time to copy and can be read much more efficiently! Moreover, the tensorflow framework is optimized to handle tfrecords amazingly well.\n\nThe datasets that are too large to be stored fully in memory, **this is an advantage as only the data that is required at the time (e.g. a batch) is loaded from disk and then processed**.\n\nAnother major advantage of TFRecords is that **it is possible to store sequence data \u2014 for instance, a time series or word encodings \u2014 in a way that allows for very efficient and (from a coding perspective) convenient import of this type of data**.\n\n******************************************************************************************************************\n\n## TFRecord = Array of Examples :\n\nA TFRecord file contains an array of Examples. \n\n**Example is a data structure for representing a record**, like an observation in a training or test dataset. \n\n**A record is represented as a set of features**, each of which has a name and can be an array of bytes, floats, or 64-bit integers.\n\nFor serialization using TFExample, we have to make any data fit into either one of 3 types:\n\n* bytes_feature\n* float_feature\n* int_64_feature","b30c2a6a":"# Stratified Sampling\n\nStratified sampling refers to a type of sampling method . With stratified sampling, we divides the population into separate groups, called strata. Then, a simple random sample is drawn from each group.\n\nSo, to effectivey take a sample here, we will partition our training dataset into two : \n\n1. The actual training set.\n2. The validation set.\n\nSince the distribution of classes is not uniform, as we saw during EDA : **** , therefore **a stratified sampling ought to be preferred over simple random sampling of our data, for training and validation purposes**.\n\n**An advantage of stratified sampling is that our validation set will be a mirror(but obviously unseen by our model) of our training dataset**. In a way, we make sure that every class is present in same proportion in our training and validation set.\n\nFor illustration of concept : \n\n![image.png](attachment:image.png)","dfcf56be":"# Training TFRecords : ","8cd2c899":"*This is inspired from works of many folks I have had the pleasure to meet during the previous competitons. A detail insight into TFRecord file format is, and how such files are created is encapsulated in this book. I wish you all the very best and thank you for stopping by.*\n\n                                ~ Aditya Baurai (@fireheart7)","a95c631b":"# Testing TFRecords : ","87d5019f":"All this heavy lifting was done in order to convert the features into Tensorflow compatible features. This is what we are gonna do now. We define a set of features and encapsulate them in an Example data structure.\n\nRemember, to store or transfer an image, we often need to convert an image to a string in such a way that the string represents the image.","622f8c1a":"## Other Related Books : \n\n* **Nosedive-EDA cum Preprocessing** - EDA of Cassava Images. Link : **https:\/\/www.kaggle.com\/fireheart7\/nosedive-eda-cum-image-processing**\n* **Cassava Metadata preparation** - Link : **https:\/\/www.kaggle.com\/fireheart7\/cassava-metadata-preparation**\n\n## Thank You!","dff370e6":"# Image Processing :\n\nThese ideas have been taken from my previous notebook : **https:\/\/www.kaggle.com\/fireheart7\/nosedive-eda-cum-image-processing**. \n\nI am directly using the functions here. If you wish to know behind the curtain details, then do have a look at that book.","8cf778c5":"# Validation TFRecords"}}