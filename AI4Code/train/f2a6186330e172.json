{"cell_type":{"c9c545a9":"code","074a4a7a":"code","ff5e9251":"code","795f73ed":"code","d7fc826c":"code","2e82f555":"code","49e07489":"code","63af9fd5":"code","a2f12238":"code","1fb0ddd8":"code","98d9e512":"code","413ca91d":"code","ceb5720f":"code","e2c7e403":"code","88745612":"code","83d3192a":"code","ec2a72f9":"code","64edfdde":"code","cb5c2600":"code","86c7c828":"code","f2dca4bb":"code","40718d8b":"code","b02ca211":"code","3307f1e2":"markdown","20afe02e":"markdown","4473475d":"markdown","9cd1bb5c":"markdown","3b80dffc":"markdown","30a2aa26":"markdown","baf6d273":"markdown","0f50ec67":"markdown","ed4fc503":"markdown","b311ac7d":"markdown","73ad4297":"markdown","85618cd8":"markdown","d2e0e05b":"markdown","90c0a798":"markdown","2f94f919":"markdown","1dbe256d":"markdown","5df7a7a7":"markdown","e6312c01":"markdown","333313fe":"markdown","ae67284a":"markdown","1c44a03e":"markdown","0b01d89b":"markdown","218f800e":"markdown","ef83ff35":"markdown","9e903dde":"markdown","21e73cad":"markdown","36f70a6b":"markdown","ecec2db0":"markdown","1ef973ca":"markdown"},"source":{"c9c545a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","074a4a7a":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","ff5e9251":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","795f73ed":"train_data.head()","d7fc826c":"train_data.describe()","2e82f555":"test_data.head()","49e07489":"X_train = train_data.drop('label',axis = 1).values\ny_train = train_data['label'].values\n\nX_test = test_data.values","63af9fd5":"X_train.shape, y_train.shape, X_test.shape","a2f12238":"index = 0\nimage = X_train[index].reshape(28,28)\n# X_train[index]: (784,)\n# image: (28, 28)\nplt.imshow(image, 'gray')\nplt.title('label : {}'.format(y_train[index]))\nplt.show()","1fb0ddd8":"X_train = X_train.astype(np.float)\nX_test = X_test.astype(np.float)\nX_train \/= 255\nX_test \/= 255\n\nprint(X_train.max()) # 1.0\nprint(X_train.min()) # 0.0","98d9e512":"enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\ny_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n\nprint(y_train.shape)\nprint(y_train_one_hot.shape)\nprint(y_train_one_hot.dtype)","413ca91d":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)","ceb5720f":"class GetMiniBatch:\n    \"\"\"\n    \u30df\u30cb\u30d0\u30c3\u30c1\u3092\u53d6\u5f97\u3059\u308b\u30a4\u30c6\u30ec\u30fc\u30bf\n\n    Parameters\n    ----------\n    X : \u6b21\u306e\u5f62\u306endarray, shape (n_samples, n_features)\n      \u8a13\u7df4\u30c7\u30fc\u30bf\n    y : \u6b21\u306e\u5f62\u306endarray, shape (n_samples, 1)\n      \u6b63\u89e3\u5024\n    batch_size : int\n      \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\n    seed : int\n      NumPy\u306e\u4e71\u6570\u306e\u30b7\u30fc\u30c9\n    \"\"\"\n    def __init__(self, X, y, batch_size = 20, seed=0):\n        self.batch_size = batch_size\n        np.random.seed(seed)\n        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n        self._X = X[shuffle_index]\n        self._y = y[shuffle_index]\n        self._stop = np.ceil(X.shape[0]\/self.batch_size).astype(np.int)\n        \n    def __len__(self):\n        return self._stop\n    \n    def __getitem__(self,item):\n        p0 = item*self.batch_size\n        p1 = item*self.batch_size + self.batch_size\n        return self._X[p0:p1], self._y[p0:p1]     \n    \n    def __iter__(self):\n        self._counter = 0\n        return self\n    \n    def __next__(self):\n        if self._counter >= self._stop:\n            raise StopIteration()\n        p0 = self._counter*self.batch_size\n        p1 = self._counter*self.batch_size + self.batch_size\n        self._counter += 1\n        return self._X[p0:p1], self._y[p0:p1]","e2c7e403":"class ScratchSimpleNeuralNetrowkClassifier():\n    \"\"\"\n    \u30b7\u30f3\u30d7\u30eb\u306a\u4e09\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5206\u985e\u5668\n\n    Parameters\n    ----------\n    activation : str\n        \u6d3b\u6027\u5316\u95a2\u6570\uff1asigmoid(\u30b7\u30b0\u30e2\u30a4\u30c9\u95a2\u6570) or tanh(\u30cf\u30a4\u30d1\u30dc\u30ea\u30c3\u30af\u30bf\u30f3\u30b8\u30a7\u30f3\u30c8\u95a2\u6570)\n    n_nodes1 : int\n        1\u5c64\u76ee\u306e\u30ce\u30fc\u30c9\u6570\n    n_nodes2 : int\n        2\u5c64\u76ee\u306e\u30ce\u30fc\u30c9\u6570\n    n_output : int\n        \u51fa\u529b\u306e\u30af\u30e9\u30b9\u6570\n\n    Attributes\n    ----------\n    self.W1 : \u6b21\u306e\u5f62\u306endarray, shape (self.n_features, self.n_nodes1)\n        1\u5c64\u76ee\u306e\u91cd\u307f\n    self.B1 : \u6b21\u306e\u5f62\u306endarray, shape (self.n_nodes1)\n        1\u5c64\u76ee\u306e\u30d0\u30a4\u30a2\u30b9\n    self.W2 : \u6b21\u306e\u5f62\u306endarray, shape (self.n_nodes1, self.n_nodes2)\n        2\u5c64\u76ee\u306e\u91cd\u307f\n    self.B2 : \u6b21\u306e\u5f62\u306endarray, shape (self.n_nodes2)\n        2\u5c64\u76ee\u306e\u30d0\u30a4\u30a2\u30b9\n    self.W3 : \u6b21\u306e\u5f62\u306endarray, shape (self.n_nodes2, self.n_output)\n        3\u5c64\u76ee\u306e\u91cd\u307f\n    self.B3 : \u6b21\u306e\u5f62\u306endarray, shape (self.n_output)\n        3\u5c64\u76ee\u306e\u30d0\u30a4\u30a2\u30b9\n    self.A1 : \u6b21\u306e\u5f62\u306endarray, shape (self.batch_size, self.n_nodes1)\n        1\u5c64\u76ee\u306e\u7dda\u5f62\u7d50\u5408\u306e\u5024\n    self.Z1 : \u6b21\u306e\u5f62\u306endarray, shape (self.batch_size, self.n_nodes1)\n        1\u5c64\u76ee\u306e\u6d3b\u6027\u5316\u95a2\u6570\u306e\u7dda\u5f62\u5909\u63db\u306b\u3088\u308b\u5024\n    self.A2 : \u6b21\u306e\u5f62\u306endarray, shape (self.batch_size, self.n_nodes2)\n        2\u5c64\u76ee\u306e\u7dda\u5f62\u7d50\u5408\u306e\u5024\n    self.Z2 : \u6b21\u306e\u5f62\u306endarray, shape (self.batch_size, self.n_nodes2)\n        2\u5c64\u76ee\u306e\u6d3b\u6027\u5316\u95a2\u6570\u306e\u7dda\u5f62\u5909\u63db\u306b\u3088\u308b\u5024\n    self.epochs : int\n        \u30a8\u30dd\u30c3\u30af\u6570(\u521d\u671f\u5024\uff1a10)\n    self.batch_size : int\n        \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba(\u521d\u671f\u5024\uff1a20)\n    self.n_features : int\n        \u7279\u5fb4\u91cf\u306e\u6570\n    self.val_is_true : boolean\n        \u691c\u8a3c\u7528\u30c7\u30fc\u30bf\u306e\u6709\u7121    \n    self.loss : \u7a7a\u306endarray\n        \u8a13\u7df4\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u640d\u5931\u306e\u8a18\u9332\n    self.loss_val : \u7a7a\u306endarray\n        \u691c\u8a3c\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u640d\u5931\u306e\u8a18\u9332\n    \"\"\"\n    def __init__(self, activation, n_nodes1, n_nodes2, n_output):\n        self.activation = activation      # \u6d3b\u6027\u5316\u95a2\u6570     \n        self.n_nodes1 = n_nodes1      # 1\u5c64\u76ee\u306e\u30ce\u30fc\u30c9\u6570\n        self.n_nodes2 = n_nodes2      # 2\u5c64\u76ee\u306e\u30ce\u30fc\u30c9\u6570\n        self.n_output = n_output        # \u51fa\u529b\u306e\u30af\u30e9\u30b9\u6570\uff0810 : 3\u5c64\u76ee\u306e\u30ce\u30fc\u30c9\u6570\uff09        \n        \n    # \u554f\u984c 1\n    def __initialize_weights(self):\n        \"\"\"\n        \u91cd\u307f\u3092\u521d\u671f\u5316\u3059\u308b\u95a2\u6570\n        \"\"\"\n        sigma = 0.01 # \u30ac\u30a6\u30b9\u5206\u5e03\u306e\u6a19\u6e96\u504f\u5dee\n        \n        self.W1 = sigma * np.random.randn(self.n_features, self.n_nodes1)\n        self.B1 = sigma * np.random.randn(self.n_nodes1)\n        \n        self.W2 = sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n        self.B2 = sigma * np.random.randn(self.n_nodes2)\n        \n        self.W3 = sigma * np.random.randn(self.n_nodes2, self.n_output)\n        self.B3 = sigma * np.random.randn(self.n_output)\n    \n    def __forward_propagation(self, X):\n        \"\"\"\n        \u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d0\u30b2\u30fc\u30b7\u30e7\u30f3\n        \"\"\"\n        # 1\u5c64\u76ee\n        self.A1 = np.dot(X, self.W1) + self.B1        \n        self.Z1 = self.__activation_function(self.A1)\n        \n        # 2\u5c64\u76ee\n        self.A2 = np.dot(self.Z1, self.W2) + self.B2        \n        self.Z2 = self.__activation_function(self.A2)           \n        \n        # 3\u5c64\u76ee\n        A3 = np.dot(self.Z2, self.W3) + self.B3\n\n        return self.__softmax_function(A3)\n    \n    def __activation_function(self, A):\n        \"\"\"\n        \u6d3b\u6027\u5316\u95a2\u6570 :\n        \u30b7\u30b0\u30e2\u30a4\u30c9\u95a2\u6570    \n        \u30cf\u30a4\u30d1\u30dc\u30ea\u30c3\u30af\u30bf\u30f3\u30b8\u30a7\u30f3\u30c8\u95a2\u6570\n        \"\"\"\n        if self.activation == 'sigmoid':           \n            return 1 \/ (1 + np.exp(-A))\n        elif self.activation == 'tanh':            \n            return np.tanh(A)   \n        else:\n            raise NameError(\"name \\\"\" + str(self.activation) + \"\\\" is not defined. set either \\\"sigmoid\\\" or \\\"tanh\\\" .\") \n\n    def __softmax_function(self, A):\n        \"\"\"\n        \u30bd\u30d5\u30c8\u30de\u30c3\u30af\u30b9\u95a2\u6570\u306b\u3066\u5404\u30af\u30e9\u30b9\u306b\u5c5e\u3059\u308b\u78ba\u7387\u3092\u8a08\u7b97\n        \u5408\u8a08\u5024: 1.0\n        \"\"\"        \n        return np.exp(A) \/ np.sum(np.exp(A), axis=1, keepdims=True)\n    \n    # \u554f\u984c 3\n    def __cross_entropy_error(self, y, z):\n        \"\"\"\n        \u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u8aa4\u5dee\u3067\u76ee\u7684\u95a2\u6570\u3092\u8a08\u7b97\u3059\u308b\u95a2\u6570\n        \"\"\"\n        batch_size = y.shape[0]\n\n        return -np.sum(y * np.log(z)) \/ batch_size\n\n    def __backpropagation(self):\n        \"\"\"\n        \u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n        \"\"\"\n        # 3\u5c64\u76ee\n        partial_A3 = self.Z3 - self.y_\n\n        partial_B3 = np.sum(partial_A3, axis=0)     \n        partial_W3 = np.dot(self.Z2.T,  partial_A3)\n        partial_Z2 = np.dot(partial_A3, self.W3.T)         \n\n        self.W3, self.B3 = self.__stochastic_gradient_descent(self.W3, partial_W3, self.B3, partial_B3) # W3\u3068B3\u306e\u91cd\u307f\u306e\u66f4\u65b0\u5024        \n\n        # 2\u5c64\u76ee\n        partial_A2 = self.__derivative_function(self.A2, partial_Z2)\n\n        partial_B2 = np.sum(partial_A2, axis=0)\n        partial_W2 = np.dot(self.Z1.T,  partial_A2)    \n        partial_Z1 = np.dot(partial_A2, self.W2.T)         \n\n        self.W2, self.B2 = self.__stochastic_gradient_descent(self.W2, partial_W2, self.B2, partial_B2) # W2\u3068B2\u306e\u91cd\u307f\u306e\u66f4\u65b0\u5024\n\n        # 1\u5c64\u76ee\n        partial_A1 = self.__derivative_function(self.A1, partial_Z1)\n\n        partial_B1 = np.sum(partial_A1, axis=0)\n        partial_W1 = np.dot(self.X_.T,  partial_A1)\n        \n        self.W1, self.B1 = self.__stochastic_gradient_descent(self.W1, partial_W1, self.B1, partial_B1) # W1\u3068B1\u306e\u91cd\u307f\u306e\u66f4\u65b0\u5024\n \n    def __derivative_function(self, A, Z):\n        \"\"\"\n        \u5408\u6210\u95a2\u6570\u306e\u504f\u5fae\u5206\uff1a\n        \u30b7\u30b0\u30e2\u30a4\u30c9\u95a2\u6570\u306e\u5c0e\u95a2\u6570\n        \u30cf\u30a4\u30d1\u30dc\u30ea\u30c3\u30af\u30bf\u30f3\u30b8\u30a7\u30f3\u30c8\u95a2\u6570\u306e\u5c0e\u95a2\u6570\n        \"\"\"        \n        if self.activation == 'sigmoid':\n            return Z * np.multiply((1.0 - self.__sigmoid_function(A)), self.__sigmoid_function(A))\n        elif self.activation == 'tanh':                \n            return Z * (1.0 - (np.tanh(A) ** 2))\n            \n    def __stochastic_gradient_descent(self, W, partial_W, B, partial_B):\n        \"\"\"\n        \u78ba\u7387\u7684\u52fe\u914d\u964d\u4e0b\u6cd5\u306b\u3088\u308a\u91cd\u307f\u3092\u66f4\u65b0\u3059\u308b\u95a2\u6570\n        \"\"\"        \n        lr = 0.001 # \u5b66\u7fd2\u7387\n        W_prime = W - lr * partial_W\n        B_prime = B - lr * partial_B\n        \n        return W_prime, B_prime\n  \n    def fit(self, X, y, X_val=None, y_val=None, epochs=10, batch_size=20):\n        \"\"\"\n        \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5206\u985e\u5668\u3092\u5b66\u7fd2\u3059\u308b\u3002\n\n        Parameters\n        ----------\n        X : \u6b21\u306e\u5f62\u306endarray, shape (n_samples, n_features)\n            \u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\n        y : \u6b21\u306e\u5f62\u306endarray, shape (n_samples, )\n            \u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u5024\n        X_val : \u6b21\u306e\u5f62\u306endarray, shape (n_samples, n_features)\n            \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\n        y_val : \u6b21\u306e\u5f62\u306endarray, shape (n_samples, )\n            \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u5024\n        epochs : int\n            \u30a8\u30dd\u30c3\u30af\u6570(\u521d\u671f\u5024\uff1a10)\n        batch_size : int\n            \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba(\u521d\u671f\u5024\uff1a20)        \n        \"\"\"\n        self.epochs = epochs                            # \u30a8\u30dd\u30c3\u30af\u6570     \n        self.batch_size = batch_size               # \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\n        self.n_features = X.shape[1]               # \u7279\u5fb4\u91cf\u306e\u6570(784) \n        self.val_is_true = False                        # \u691c\u8a3c\u7528\u30c7\u30fc\u30bf\u306e\u6709\u7121(\u521d\u671f\u5024\uff1aFalse)\n        self.loss = np.zeros(self.epochs)        # \u5b66\u7fd2\u66f2\u7dda\u30fb\u76ee\u7684\u95a2\u6570\u306e\u51fa\u529b\u7528(\u8a13\u7df4\u30c7\u30fc\u30bf)\n        self.loss_val = np.zeros(self.epochs) # \u5b66\u7fd2\u66f2\u7dda\u30fb\u76ee\u7684\u95a2\u6570\u306e\u51fa\u529b\u7528(\u691c\u8a3c\u30c7\u30fc\u30bf)\n        \n        self.__initialize_weights() # \u91cd\u307f\u306e\u521d\u671f\u5316\n        \n        for epoch in range(self.epochs):\n            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n            for mini_X_train,  mini_y_train in get_mini_batch:\n                self.X_ = mini_X_train\n                self.y_ = mini_y_train\n\n                # \u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d0\u30b2\u30fc\u30b7\u30e7\u30f3\n                self.Z3 = self.__forward_propagation(self.X_)\n\n                # \u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u8aa4\u5dee\n                self.loss[epoch] = self.__cross_entropy_error(self.y_, self.Z3)\n\n                # \u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n                self.__backpropagation()\n\n            if not(X_val is None) and not(y_val is None):\n                self.val_is_true = True\n                \n                # \u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d0\u30b2\u30fc\u30b7\u30e7\u30f3\n                self.y_val_pred = self.__forward_propagation(X_val)\n\n                # \u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u8aa4\u5dee\n                self.loss_val[epoch] = self.__cross_entropy_error(y_val, self.y_val_pred)      \n\n    def predict(self, X):\n        \"\"\"\n        \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5206\u985e\u5668\u3092\u4f7f\u3044\u63a8\u5b9a\u3059\u308b\u3002\n\n        Parameters\n        ----------\n        X : \u6b21\u306e\u5f62\u306endarray, shape (n_samples, n_features)\n            \u30b5\u30f3\u30d7\u30eb\n\n        Returns\n        -------\n            \u6b21\u306e\u5f62\u306endarray, shape (n_samples, 1)\n            \u63a8\u5b9a\u7d50\u679c\n        \"\"\"\n        # \u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d0\u30b2\u30fc\u30b7\u30e7\u30f3\n        y_pred = self.__forward_propagation(X)    \n\n        return np.argmax(y_pred, axis=1)\n    \n    def plot_learning_curve(self):\n        \"\"\"\n        \u5b66\u7fd2\u66f2\u7dda\u3092\u30d7\u30ed\u30c3\u30c8\u3059\u308b\u3002    \n        \"\"\"\n        plt.plot(range(1, self.epochs + 1), self.loss, color=\"r\", marker=\"o\", label=\"train loss\")\n        if self.val_is_true:\n            plt.plot(range(1, self.epochs + 1), self.loss_val, color=\"g\", marker=\"o\", label=\"val loss\")\n            \n        plt.title(\"Learning Curve\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.grid()\n        plt.legend(loc=\"best\")\n        plt.show()","88745612":"model = ScratchSimpleNeuralNetrowkClassifier(activation='tanh', n_nodes1=400, n_nodes2=200, n_output=10)\nmodel.fit(X_train, y_train, X_val, y_val, epochs = 20, batch_size = 20)\ny_pred = model.predict(X_val)","83d3192a":"np.bincount(y_pred)","ec2a72f9":"np.sum(y_val, axis=0).astype('int')","64edfdde":"#\u76f4\u5217\u5316 \ny_val = np.argmax(y_val, axis=1)","cb5c2600":"print(\"accuracy : {}\".format(accuracy_score(y_val, y_pred)))","86c7c828":"model.plot_learning_curve()","f2dca4bb":"\"\"\"\n\u8a9e\u5206\u985e\u7d50\u679c\u3092\u4e26\u3079\u3066\u8868\u793a\u3059\u308b\u3002\u753b\u50cf\u306e\u4e0a\u306e\u8868\u793a\u306f\u300c\u63a8\u5b9a\u7d50\u679c\/\u6b63\u89e3\u300d\u3067\u3042\u308b\u3002\n\nParameters:\n----------\ny_pred : \u63a8\u5b9a\u5024\u306endarray (n_samples,)\ny_val : \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u6b63\u89e3\u30e9\u30d9\u30eb(n_samples,)\nX_val : \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\uff08n_samples, n_features)\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nnum = 36 # \u3044\u304f\u3064\u8868\u793a\u3059\u308b\u304b\ntrue_false = y_pred==y_val\nfalse_list = np.where(true_false==False)[0].astype(np.int)\nif false_list.shape[0] < num:\n    num = false_list.shape[0]\nfig = plt.figure(figsize=(6, 6))\nfig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\nfor i in range(num):\n    ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n    ax.set_title(\"{} \/ {}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n    ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')","40718d8b":"prediction = model.predict(X_test)","b02ca211":"submission = pd.DataFrame({'ImageId': np.array(range(1,28001)), 'Label': prediction})\nsubmission.to_csv(\"submission.csv\", index=False)","3307f1e2":"\u300c3\u5c64\u76ee\u300d\n\n$$\n\\frac{\\partial L}{\\partial A_3} = Z_3 - Y\n$$\n\n$$\n\\frac{\\partial L}{\\partial B_3} = \\displaystyle \\sum_{j}^{n_b} \\frac{\\partial L}{\\partial A_{3_j}} \n$$\n\n$$\n\\frac{\\partial L}{\\partial W_3} = Z_2^T  \\frac{\\partial L}{\\partial A_3} \n$$\n\n$$\n\\frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial A_3} \u22c5 W_3^T\n$$\n\n\n$\\frac{\\partial L}{\\partial A_3}$ : $A_3$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (batch_size, n_output)\u3000 \u21e8 __(20, 10)__\n\n\n$\\frac{\\partial L}{\\partial A_{3_j}}$ : j\u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e$A_3$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_nodes2,)\n\n\n$\\frac{\\partial L}{\\partial B_3}$ : $B_3$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_output,)\u3000 \u21e8 __(10,)__\n\n\n$\\frac{\\partial L}{\\partial W_3}$ : $W_3$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_nodes2, n_output)\u3000 \u21e8 __(200, 10)__\n\n\n$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (batch_size, n_nodes2)\u3000 \u21e8 __(20, 200)__\n\n\n$Z_{3}$ : \u30bd\u30d5\u30c8\u30de\u30c3\u30af\u30b9\u95a2\u6570\u306e\u51fa\u529b (batch_size, n_output)\n\n\n$Y$ : \u6b63\u89e3\u30e9\u30d9\u30eb (batch_size, n_output)\n\n\n$Z_{2}$ : 2\u5c64\u76ee\u306e\u6d3b\u6027\u5316\u95a2\u6570\u306e\u51fa\u529b (batch_size, n_nodes2)\n\n\n$W_3$ : 3\u5c64\u76ee\u306e\u91cd\u307f (n_nodes2, n_output)","20afe02e":"- \u30df\u30cb\u30d0\u30c3\u30c1\u51e6\u7406","4473475d":"3. train_test_split\u95a2\u6570","9cd1bb5c":"\u300a\u88dc\u8db3\u300b\n\n\n\u6d3b\u6027\u5316\u95a2\u6570\u306b\u30b7\u30b0\u30e2\u30a4\u30c9\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u5834\u5408\u306f\u3001\u6b21\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n$$\n\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \u2299 \\{1 - sigmoid(A_2)\\} sigmoid(A_2)\n$$\n\n$$\n\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \u2299 \\{1 - sigmoid(A_1)\\} sigmoid(A_1)\n$$","3b80dffc":"### \u3010\u554f\u984c2\u3011\u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u88c5\n\u4e09\u5c64\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e \u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3 \u3092\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u4ee5\u4e0b\u306e\u8aac\u660e\u3067\u306f\u30ce\u30fc\u30c9\u6570\u306f1\u5c64\u76ee\u306f400\u30012\u5c64\u76ee\u306f200\u3068\u3057\u307e\u3059\u304c\u3001\u5909\u66f4\u3057\u3066\u3082\u69cb\u3044\u307e\u305b\u3093\u3002\n\n\n\u5404\u5c64\u306e\u6570\u5f0f\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\u3002\u4eca\u56de\u306f\u305d\u308c\u305e\u308c\u306e\u8a18\u53f7\u304c\u8868\u3059\u914d\u5217\u304c\u3001\u5b9f\u88c5\u4e0a\u3069\u306e\u3088\u3046\u306andarray\u306eshape\u306b\u306a\u308b\u304b\u3092\u4f75\u8a18\u3057\u3066\u3042\u308a\u307e\u3059\u3002","30a2aa26":"$$\nW'_i= W_i - \\alpha \\frac{\\partial L}{\\partial W_i}\n$$\n\n$$\nB'_i= B_i - \\alpha \\frac{\\partial L}{\\partial B_i}\n$$\n\n\n$\\alpha$ : \u5b66\u7fd2\u7387\uff08\u5c64\u3054\u3068\u306b\u5909\u3048\u308b\u3053\u3068\u3082\u53ef\u80fd\u3060\u304c\u3001\u57fa\u672c\u7684\u306b\u306f\u5168\u3066\u540c\u3058\u3068\u3059\u308b\uff09\n\n\n$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d\n\n\n$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d\n\n\n\uff0a\u3053\u306e\u52fe\u914d\u306f\u30df\u30cb\u30d0\u30c3\u30c1\u306e\u30b5\u30f3\u30d7\u30eb\u6570\u5206\u306e\u5408\u8a08\u307e\u305f\u306f\u5e73\u5747\u3092\u8003\u3048\u307e\u3059\u3002\u3053\u3053\u3067\u306f\u5408\u8a08\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\n\n\u3053\u306e\u66f4\u65b0\u65b9\u6cd5\u306fSprint3\u7dda\u5f62\u56de\u5e30\u3084sprint4\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u306b\u304a\u3051\u308b\u6700\u6025\u964d\u4e0b\u6cd5\u3068\u540c\u69d8\u3067\u3059\u3002\u3088\u308a\u52b9\u679c\u7684\u306a\u66f4\u65b0\u65b9\u6cd5\u304c\u77e5\u3089\u308c\u3066\u304a\u308a\u3001\u305d\u308c\u306f\u6b21\u306eSprint\u3067\u6271\u3044\u307e\u3059\u3002\n\n\n\u52fe\u914d $\\frac{\\partial L}{\\partial W_i}$ \u3084 $\\frac{\\partial L}{\\partial B_i}$ \u3092\u6c42\u3081\u308b\u305f\u3081\u306b\u3001\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3044\u307e\u3059\u3002\u4ee5\u4e0b\u306e\u6570\u5f0f\u3067\u3059\u3002\u30cf\u30a4\u30d1\u30dc\u30ea\u30c3\u30af\u30bf\u30f3\u30b8\u30a7\u30f3\u30c8\u95a2\u6570\u3092\u4f7f\u7528\u3057\u305f\u4f8b\u3092\u8f09\u305b\u307e\u3057\u305f\u3002\u30b7\u30b0\u30e2\u30a4\u30c9\u95a2\u6570\u306e\u5834\u5408\u306e\u6570\u5f0f\u306f\u305d\u306e\u5f8c\u308d\u306b\u3042\u308a\u307e\u3059\u3002","baf6d273":"- \u524d\u51e6\u7406","0f50ec67":"- \u30b7\u30f3\u30d7\u30eb\u306a\u4e09\u5c64\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5206\u985e\u5668","ed4fc503":"### \u3010\u554f\u984c6\u3011\u5b66\u7fd2\u3068\u63a8\u5b9a\n\nMNIST\u306e\u30c7\u30fc\u30bf\u3092\u5b66\u7fd2\u30fb\u63a8\u5b9a\u3057\u3001Accuracy\u3092\u8a08\u7b97\u3057\u3066\u304f\u3060\u3055\u3044\u3002","b311ac7d":"\u300c1\u5c64\u76ee\u306e\u6d3b\u6027\u5316\u95a2\u6570\u300d\n\n$$\nZ_1=f(A_1)\n$$\n\n\n$f()$ : \u6d3b\u6027\u5316\u95a2\u6570\n\n\n$Z_1$ \u51fa\u529b (batch_size, n_nodes1)  \u21e8 __(20, 400)__","73ad4297":"\u300c2\u5c64\u76ee\u300d\n\n$$\n\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \u2299 \\{1 - tanh^2(A_2)\\}\n$$\n\n$$\n\\frac{\\partial L}{\\partial B_2} = \\displaystyle \\sum_{j}^{n_b} \\frac{\\partial L}{\\partial A_{2_j}} \n$$\n\n$$\n\\frac{\\partial L}{\\partial W_2} = Z_1^T  \\frac{\\partial L}{\\partial A_2} \n$$\n\n$$\n\\frac{\\partial L}{\\partial Z_1} = \\frac{\\partial L}{\\partial A_2} \u22c5 W_2^T\n$$\n\n\n$\\frac{\\partial L}{\\partial A_2}$ : $A_2$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (batch_size, n_nodes2)\u3000 \u21e8 __(20, 200)__\n\n\n$\\frac{\\partial L}{\\partial A_{2_j}}$ : j\u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e$A_2$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_nodes2,)\n\n\n$\\frac{\\partial L}{\\partial B_2}$ : $B_2$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_nodes2,)\u3000 \u21e8 __(200,)__\n\n\n$\\frac{\\partial L}{\\partial W_2}$ : $W_2$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_nodes1, n_nodes2)\u3000 \u21e8 __(400, 200)__\n\n\n$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (batch_size, n_nodes2)\u3000 \u21e8 __(20, 200)__\n\n\n$A_2$ : 2\u5c64\u76ee\u306e\u51fa\u529b (batch_size, n_nodes2)\n\n\n$Z_{1}$ : 1\u5c64\u76ee\u306e\u6d3b\u6027\u5316\u95a2\u6570\u306e\u51fa\u529b (batch_size, n_nodes1)\n\n\n$W_2$ : 2\u5c64\u76ee\u306e\u91cd\u307f (n_nodes1, n_nodes2)","85618cd8":"- \u753b\u50cf\u30c7\u30fc\u30bf\u306e\u53ef\u8996\u5316","d2e0e05b":"### \u3010\u554f\u984c8\u3011\uff08\u30a2\u30c9\u30d0\u30f3\u30b9\u8ab2\u984c\uff09\u8aa4\u5206\u985e\u306e\u78ba\u8a8d\n\n\n\u8aa4\u5206\u985e\u3057\u305f\u753b\u50cf\u306f\u3069\u306e\u3088\u3046\u306a\u3082\u306e\u3060\u3063\u305f\u304b\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u63a8\u5b9a\u5024\u3092\u7528\u610f\u3057\u3001\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002","90c0a798":"1. \u6b63\u898f\u5316","2f94f919":"### \u3010\u554f\u984c1\u3011\u91cd\u307f\u306e\u521d\u671f\u5024\u3092\u6c7a\u3081\u308b\u30b3\u30fc\u30c9\u306e\u4f5c\u6210\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u5c64\u306e\u91cd\u307f\u306e\u521d\u671f\u5024\u3092\u6c7a\u3081\u308b\u30b3\u30fc\u30c9\u3092\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\u91cd\u307f\u306e\u521d\u671f\u5024\u306f\u69d8\u3005\u306a\u65b9\u6cd5\u304c\u63d0\u6848\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u4eca\u56de\u306f\u30ac\u30a6\u30b9\u5206\u5e03\u306b\u3088\u308b\u5358\u7d14\u306a\u521d\u671f\u5316\u3092\u884c\u3044\u307e\u3059\u3002\u30d0\u30a4\u30a2\u30b9\u306b\u95a2\u3057\u3066\u3082\u540c\u69d8\u3067\u3059\u3002\n\n\n\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3092\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u6a19\u6e96\u504f\u5dee\u306e\u5024sigma\u306f\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u3059\u3002\u767a\u5c55\u7684\u306a\u91cd\u307f\u306e\u521d\u671f\u5316\u65b9\u6cd5\u306b\u3064\u3044\u3066\u306f\u6b21\u306eSprint\u3067\u6271\u3044\u307e\u3059\u3002","1dbe256d":"\u300c1\u5c64\u76ee\u300d\n\n$$\nA_1=X \u22c5 W_1 + B_1\n$$\n\n\n$X$ : \u7279\u5fb4\u91cf\u30d9\u30af\u30c8\u30eb (batch_size, n_features) \u21e8 __(20, 784)__\n\n\n$W_1$ : 1\u5c64\u76ee\u306e\u91cd\u307f (n_features, n_nodes1) \u21e8 __(784, 400)__\n\n\n$B_1$ : 1\u5c64\u76ee\u306e\u30d0\u30a4\u30a2\u30b9 (n_nodes1,) \u21e8 __(400,)__\n\n\n$A_1$ : \u51fa\u529b (batch_size, n_nodes1)  \u21e8 __(20, 400)__","5df7a7a7":"\u300c2\u5c64\u76ee\u306e\u6d3b\u6027\u5316\u95a2\u6570\u300d\n\n$$\nZ_2=f(A_2)\n$$\n\n\n$f()$ : \u6d3b\u6027\u5316\u95a2\u6570\n\n\n$Z_2$ \u51fa\u529b (batch_size, n_nodes2) \u21e8 __(20, 200)__","e6312c01":"- \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u63d0\u51fa","333313fe":"### \u3010\u554f\u984c4\u3011\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u88c5\n\u4e09\u5c64\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u3092\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u78ba\u7387\u7684\u52fe\u914d\u964d\u4e0b\u6cd5\u3092\u884c\u3046\u90e8\u5206\u3067\u3059\u3002\n\n\n\u6570\u5f0f\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059\u3002\n\n\n\u307e\u305a\u3001i\u5c64\u76ee\u306e\u91cd\u307f\u3068\u30d0\u30a4\u30a2\u30b9\u306e\u66f4\u65b0\u5f0f\u3067\u3059\u3002 $W_i$ \u3068 $B_i$ \u306b\u5bfe\u3057\u3001\u66f4\u65b0\u5f8c\u306e $W_i^{\\prime}$ \u3068 $B_i^{\\prime}$ \u306f\u6b21\u306e\u6570\u5f0f\u3067\u6c42\u3081\u3089\u308c\u307e\u3059\u3002","ae67284a":"- \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u78ba\u8a8d","1c44a03e":"2. one-hot\u8868\u73fe ","0b01d89b":"### \u3010\u554f\u984c3\u3011\u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u8aa4\u5dee\u306e\u5b9f\u88c5\n\u76ee\u7684\u95a2\u6570\uff08\u640d\u5931\u95a2\u6570\uff09\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\n\n\n\u591a\u30af\u30e9\u30b9\u5206\u985e\u306e\u76ee\u7684\u95a2\u6570\u3067\u3042\u308b\u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u8aa4\u5dee $L$ \u306f\u6b21\u306e\u6570\u5f0f\u3067\u3059\u3002\n\n\n$$\nL = - \\frac{1}{n_b} \\displaystyle \\sum_{j}^{n_b} \\displaystyle \\sum_{k}^{n_c}\ny_{jk}log(z_{3_jk})\n$$\n\n\n$y_{ij}$ : $j$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e $k$ \u756a\u76ee\u306e\u30af\u30e9\u30b9\u306e\u6b63\u89e3\u30e9\u30d9\u30eb\uff08one-hot\u8868\u73fe\u30670\u304b1\u306e\u30b9\u30ab\u30e9\u30fc\uff09\n\n\n$z_{3_ij}$ : $j$ \u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e $k$ \u756a\u76ee\u306e\u30af\u30e9\u30b9\u306e\u78ba\u7387\uff08\u30b9\u30ab\u30e9\u30fc\uff09\n\n\n$n_{b}$ : \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3001batch_size\n\n\n$n_{c}$ : \u30af\u30e9\u30b9\u306e\u6570\u3001n_output\uff08\u4eca\u56de\u306eMNIST\u3067\u306f10\uff09\n\n\n\u30b5\u30f3\u30d7\u30eb1\u3064\u3042\u305f\u308a\u306e\u8aa4\u5dee\u304c\u6c42\u307e\u308a\u307e\u3059\u3002","218f800e":"### \u3010\u554f\u984c5\u3011\u63a8\u5b9a\n\u63a8\u5b9a\u3092\u884c\u3046\u30e1\u30bd\u30c3\u30c9\u3092\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\u30d5\u30a9\u30ef\u30fc\u30c9\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3055\u308c\u305f10\u500b\u306e\u78ba\u7387\u306e\u4e2d\u3067\u3001\u6700\u3082\u9ad8\u3044\u3082\u306e\u306f\u3069\u308c\u304b\u3092\u5224\u5b9a\u3057\u307e\u3059\u3002","ef83ff35":"- \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","9e903dde":"\u300c3\u5c64\u76ee\uff08\u51fa\u529b\u5c64\uff09\u300d\n\n$$\nA_3=Z_2 \u22c5 W_3 + B_3\n$$\n\n\n$Z_2$ \u51fa\u529b (batch_size, n_nodes2) \u21e8 __(20, 200)__\n\n\n$W_3$ : 3\u5c64\u76ee\u306e\u91cd\u307f (n_nodes2, n_output) \u21e8 __(200, 10)__\n\n\n$B_3$ : 3\u5c64\u76ee\u306e\u30d0\u30a4\u30a2\u30b9 (n_output,) \u21e8 __(10,)__\n\n\n$A_3$ : \u51fa\u529b (batch_size, n_output) \u21e8 __(20, 10)__","21e73cad":"\u300c2\u5c64\u76ee\u300d\n\n$$\nA_2=Z_1 \u22c5 W_2 + B_2\n$$\n\n\n$Z_1$ \u51fa\u529b (batch_size, n_nodes1)  \u21e8 __(20, 400)__ \n\n\n$W_2$ : 2\u5c64\u76ee\u306e\u91cd\u307f (n_nodes1, n_nodes2) \u21e8 __(400, 200)__\n\n\n$B_2$ : 2\u5c64\u76ee\u306e\u30d0\u30a4\u30a2\u30b9 (n_nodes2,) \u21e8 __(200,)__\n\n\n$A_2$ : \u51fa\u529b (batch_size, n_nodes2) \u21e8 __(20, 200)__","36f70a6b":"\u300c1\u5c64\u76ee\u300d\n\n$$\n\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \u2299 \\{1 - tanh^2(A_1)\\}\n$$\n\n$$\n\\frac{\\partial L}{\\partial B_1} = \\displaystyle \\sum_{j}^{n_b} \\frac{\\partial L}{\\partial A_{1_j}} \n$$\n\n$$\n\\frac{\\partial L}{\\partial W_1} = X^T \\frac{\\partial L}{\\partial A_1} \n$$\n\n$\\frac{\\partial L}{\\partial A_1}$ : $A_1$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (batch_size, n_nodes1)\u3000 \u21e8 __(20, 400)__\n\n\n$\\frac{\\partial L}{\\partial A_{1_j}}$ : j\u756a\u76ee\u306e\u30b5\u30f3\u30d7\u30eb\u306e$A_1$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_nodes1,)\n\n\n$\\frac{\\partial L}{\\partial B_1}$ : $B_1$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_nodes1,)\u3000 \u21e8 __(400,)__\n\n\n$\\frac{\\partial L}{\\partial W_1}$ : $W_1$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (n_features, n_nodes1)\u3000 \u21e8 __(784, 400)__\n\n\n$\\frac{\\partial L}{\\partial Z_1}$ : $Z_1$ \u306b\u95a2\u3059\u308b\u640d\u5931 $L$ \u306e\u52fe\u914d (batch_size, n_nodes1)\u3000 \u21e8 __(20, 400)__\n\n\n$A_1$ : 1\u5c64\u76ee\u306e\u51fa\u529b (batch_size, n_nodes1)\n\n\n$X$ : \u7279\u5fb4\u91cf\u30d9\u30af\u30c8\u30eb (batch_size, n_features)\n\n\n$W_1$ : 1\u5c64\u76ee\u306e\u91cd\u307f (n_features, n_nodes1)","ecec2db0":"\u300c3\u5c64\u76ee\u306e\u6d3b\u6027\u5316\u95a2\u6570\u300d\n\n$$\nZ_3=softmax(A_3)\n$$\n\n\n$softmax()$ : \u30bd\u30d5\u30c8\u30de\u30c3\u30af\u30b9\u95a2\u6570\n\n\n$Z_3$ \u51fa\u529b (batch_size, n_output) \u21e8 __(20, 10)__\n\n\n$Z_3$ \u306f\u5404\u30e9\u30d9\u30eb\uff080\u301c9\uff09\u306b\u5bfe\u3059\u308b\u78ba\u7387\u306e\u914d\u5217\u3067\u3042\u308b\u3002","1ef973ca":"### \u3010\u554f\u984c7\u3011\u5b66\u7fd2\u66f2\u7dda\u306e\u30d7\u30ed\u30c3\u30c8\n\u5b66\u7fd2\u66f2\u7dda\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n\n\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306f\u904e\u5b66\u7fd2\u304c\u767a\u751f\u3057\u3084\u3059\u3044\u305f\u3081\u3001\u5b66\u7fd2\u66f2\u7dda\u306e\u78ba\u8a8d\u304c\u91cd\u8981\u3067\u3059\u3002\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u30a8\u30dd\u30c3\u30af\u3054\u3068\u306e\u640d\u5931\uff08\u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u8aa4\u5dee\uff09\u3092\u8a18\u9332\u3067\u304d\u308b\u3088\u3046\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002"}}