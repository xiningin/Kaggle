{"cell_type":{"fe636501":"code","071b451e":"code","7805cb63":"code","d97520ec":"code","3b7ebd43":"code","1c380d8a":"code","620060cf":"code","a632b2f8":"markdown"},"source":{"fe636501":"#!\/usr\/bin\/env python\n# -*- coding: utf-8 -*-\n\nimport lightgbm as lgb\nfrom sklearn import datasets\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, KFold\nimport numpy.random as rd","071b451e":"class ModelExtractionCallback(object):\n    \"\"\"Callback class for retrieving trained model from lightgbm.cv()\n    NOTE: This class depends on '_CVBooster' which is hidden class, so it might doesn't work if the specification is changed.\n    \"\"\"\n\n    def __init__(self):\n        self._model = None\n\n    def __call__(self, env):\n        # Saving _CVBooster object.\n        self._model = env.model\n\n    def _assert_called_cb(self):\n        if self._model is None:\n            # Throw exception if the callback class is not called.\n            raise RuntimeError('callback has not called yet')\n\n    @property\n    def boosters_proxy(self):\n        self._assert_called_cb()\n        # return Booster object\n        return self._model\n\n    @property\n    def raw_boosters(self):\n        self._assert_called_cb()\n        # return list of Booster\n        return self._model.boosters\n\n    @property\n    def best_iteration(self):\n        self._assert_called_cb()\n        # return boosting round when early stopping.\n        return self._model.best_iteration\n\ndef loading_dataset():\n    # Loading Iris Dataset\n    iris = datasets.load_iris()\n    X, y = iris.data, iris.target\n\n    # Split dataset for this demonstration.\n    train, test, y_train, y_test = train_test_split(X, y,\n                                                    shuffle=True,\n                                                    random_state=42)\n    return train, test, y_train, y_test","7805cb63":"rd.seed(123)\n\n# Loading Sample Dataset.\ntrain, test, y_train, y_test = loading_dataset()\n\n# one hot representation of y_train\nmax_class_num = y_train.max()+1\ny_train_ohe = np.identity(max_class_num)[y_train]\n    \n# Create LightGBM dataset for train.\nlgb_train = lgb.Dataset(train, y_train)\n\n# Create callback class for retrieving trained model.\nextraction_cb = ModelExtractionCallback()\ncallbacks = [\n    extraction_cb,\n]\n\n# LightGBM parameter\nlgbm_params = {\n    'objective': 'multiclass',\n    'num_class': 3,\n    'verbosity' : 1,\n}\n\n# Training settings\nFOLD_NUM = 5\nfold_seed = 71\nfolds = StratifiedKFold(n_splits=FOLD_NUM, shuffle=True, random_state=fold_seed)\n\n# Fitting\nret = lgb.cv(params=lgbm_params,\n               train_set=lgb_train,\n               folds=folds,\n               num_boost_round=1000,\n               verbose_eval = 10,\n               early_stopping_rounds=10,\n               callbacks=callbacks,\n               )\ndf_ret = pd.DataFrame(ret)\ndf_ret","d97520ec":"# Retrieving booster and training information.\nproxy = extraction_cb.boosters_proxy\nboosters = extraction_cb.raw_boosters\nbest_iteration = extraction_cb.best_iteration","3b7ebd43":"# Create oof prediction result\nfold_iter = folds.split(train, y_train)\noof_preds = np.zeros_like(y_train_ohe)\nfor n_fold, ((trn_idx, val_idx), booster) in enumerate(zip(fold_iter, boosters)):\n    print(val_idx)\n    valid = train[val_idx]\n    oof_preds[val_idx] = booster.predict(valid, num_iteration=best_iteration)\nprint(f\"accuracy on oof preds: {accuracy_score(y_train, np.argmax(oof_preds, axis=1))}\")","1c380d8a":"# Averaging prediction result for test data.\ny_pred_proba_list = proxy.predict(test, num_iteration=best_iteration)\ny_pred_proba_avg = np.array(y_pred_proba_list).mean(axis=0)\ny_pred = np.argmax(y_pred_proba_avg, axis=1)\naccuracy = accuracy_score(y_test, y_pred)\nprint('Averaging accuracy:', accuracy)\n","620060cf":"# Predicting with test data of each CV separately.\nfor i, booster in enumerate(boosters):\n    y_pred_proba = booster.predict(test,\n                                   num_iteration=best_iteration)\n    y_pred = np.argmax(y_pred_proba, axis=1)\n    accuracy = accuracy_score(y_test, y_pred)\n    print('Model {0} accuracy: {1}'.format(i, accuracy))","a632b2f8":"### Original auther : \n  - @momijiame [Twitter]  \n  - Blog page: https:\/\/blog.amedama.jp\/entry\/lightgbm-cv-model  (Sorry Japanese only)  \n  \n### Auther of this kernel : \n - @kenmatsu4 [Twitter]\n\nIn this kernel, it is introduced how to use booster information and oof prediction result from lightgbm.cv() with callback class."}}