{"cell_type":{"e5e6635a":"code","c44928e0":"code","604f8b10":"code","21f3127a":"code","67ce95ac":"code","56d60ccf":"code","3ed5edf4":"code","6d5d6784":"code","aebaf2d2":"code","8f38498f":"code","d3f94502":"code","d69ba16a":"code","e104575c":"code","8f7128ec":"code","edb6f4ad":"code","01a364ca":"markdown","a2a933b6":"markdown","bb739898":"markdown","a0685fb3":"markdown","6a8ac52e":"markdown","722982d2":"markdown","2a76afa0":"markdown","f5a10f6a":"markdown"},"source":{"e5e6635a":"import os\nimport pandas as pd\n\n#Garbage Collector\nimport gc","c44928e0":"#Read in the data\ntrain_id = pd.read_csv('..\/input\/train_identity.csv')\ntrain_tran = pd.read_csv('..\/input\/train_transaction.csv')","604f8b10":"#This is a function that downcast the integer columns\ndef downcast_df_int_columns(df):\n    list_of_columns = list(df.select_dtypes(include=[\"int32\", \"int64\"]).columns)\n        \n    if len(list_of_columns)>=1:\n        max_string_length = max([len(col) for col in list_of_columns]) # finds max string length for better status printing\n        print(\"downcasting integers for:\", list_of_columns, \"\\n\")\n        \n        for col in list_of_columns:\n            print(\"reduced memory usage for:  \", col.ljust(max_string_length+2)[:max_string_length+2],\n                  \"from\", str(round(df[col].memory_usage(deep=True)*1e-6,2)).rjust(8), \"to\", end=\" \")\n            df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n            print(str(round(df[col].memory_usage(deep=True)*1e-6,2)).rjust(8))\n    else:\n        print(\"no columns to downcast\")\n    \n    gc.collect()\n    \n    print(\"done\")","21f3127a":"#This is a function that downcast the float columns, if you have too many columns to adjust and do not want to see to many messages proceesing, you could comment our the print() columns\ndef downcast_df_float_columns(df):\n    list_of_columns = list(df.select_dtypes(include=[\"float64\"]).columns)\n        \n    if len(list_of_columns)>=1:\n        max_string_length = max([len(col) for col in list_of_columns]) # finds max string length for better status printing\n        print(\"downcasting float for:\", list_of_columns, \"\\n\")\n        \n        for col in list_of_columns:\n            print(\"reduced memory usage for:  \", col.ljust(max_string_length+2)[:max_string_length+2],\n                  \"from\", str(round(df[col].memory_usage(deep=True)*1e-6,2)).rjust(8), \"to\", end=\" \")\n            df[col] = pd.to_numeric(df[col], downcast=\"float\")\n            print(str(round(df[col].memory_usage(deep=True)*1e-6,2)).rjust(8))\n    else:\n        print(\"no columns to downcast\")\n    \n    gc.collect()\n    \n    print(\"done\")","67ce95ac":"train_id.info(memory_usage=\"deep\")","56d60ccf":"train_tran.info(memory_usage=\"deep\")","3ed5edf4":"#Reducing Size for the numeric columns for the train id part\ndowncast_df_int_columns(train_id)\ndowncast_df_float_columns(train_id)","6d5d6784":"#Reducing Size for the numeric columns for the train transaction part\ndowncast_df_int_columns(train_tran)\ndowncast_df_float_columns(train_tran)","aebaf2d2":"train_id.info(memory_usage=\"deep\")","8f38498f":"train_tran.info(memory_usage=\"deep\")","d3f94502":"pd.set_option('display.max_columns', None)\n\ntrain_id.head(10)","d69ba16a":"#This is a function that convert a list of columns from object to categorical\ndef convert_columns_to_catg(df, column_list):\n    for col in column_list:\n        print(\"converting\", col.ljust(30), \"size: \", round(df[col].memory_usage(deep=True)*1e-6,2), end=\"\\t\")\n        df[col] = df[col].astype(\"category\")\n        print(\"->\\t\", round(df[col].memory_usage(deep=True)*1e-6,2))","e104575c":"#Picking some columns that seems to be able to convert to categorical\nconvert_columns_to_catg(train_id, ['id_12', 'id_16', 'id_30', 'id_31', 'id_33', 'id_34', 'id_34', \n                                  'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo'])","8f7128ec":"train_id.info()","edb6f4ad":"train_id.to_pickle(\"train_id.pkl\")\n\nprint(\"train_identity.csv:\", os.stat('..\/input\/train_identity.csv').st_size * 1e-6)\nprint(\"train_id.pkl:\", os.stat('train_id.pkl').st_size * 1e-6)","01a364ca":"## 2.Downcasting the object column by converting them to categorical","a2a933b6":"This code refers to Kaggle kernal: https:\/\/www.kaggle.com\/frankherfert\/tips-tricks-for-working-with-large-datasets?source=post_page---------------------------","bb739898":"Saving memory size can greatly reduce the burden to your system memory while improve your analysis experience.\nHere there are 3 steps to do it. ","a0685fb3":"**Do not Forget to save your work. This way you can access the downcasted df everytime you load it!**","6a8ac52e":"## 3.Saving your dataframe as pickle file for fast read","722982d2":"## 1. Downcasting Numeric Columns","2a76afa0":"As you can see, the tran_id dataframe has been downcasted from 161.9MB to 148.7MB (8.1%), while the trin_tran dataframe has been downcasted from 2.1GB to 1.2GB (42.9%). Of course, the more int and float column you have, the chance that these functions can better improve your performaces will be.\n\nThe idea behind the scene is pandas automatically read in your dataframe using int 64 or float 64, most of the time you do not need it to be this big, here is a size chart from StackOverflow:\n**   Type      Capacity\n\n   Int16 -- (-32,768 to +32,767)\n\n   Int32 -- (-2,147,483,648 to +2,147,483,647)\n\n   Int64 -- (-9,223,372,036,854,775,808 to +9,223,372,036,854,775,807)**\n   \nSo most of the time, int16 or even int8 could do the job and thus save you the space. ","f5a10f6a":"The idea behind the this is based on the fact that most of the column only takes few values and pandas can limit those values only to the few categorical value to save the memory. \n\n\"Often in real-time, data includes the text columns, which are repetitive. Features like gender, country, and codes are always repetitive. These are the examples for categorical data.\n\nCategorical variables can take on only a limited, and usually fixed number of possible values. Besides the fixed length, categorical data might have an order but cannot perform numerical operation. Categorical are a Pandas data type.\n\nThe categorical data type is useful in the following cases \u2212\n\nA string variable consisting of only a few different values. Converting such a string variable to a categorical variable will save some memory.\n\nThe lexical order of a variable is not the same as the logical order (\u201cone\u201d, \u201ctwo\u201d, \u201cthree\u201d). By converting to a categorical and specifying an order on the categories, sorting and min\/max will use the logical order instead of the lexical order.\n\nAs a signal to other python libraries that this column should be treated as a categorical variable (e.g. to use suitable statistical methods or plot types).\"\n(https:\/\/www.tutorialspoint.com\/python_pandas\/python_pandas_categorical_data)"}}