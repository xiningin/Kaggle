{"cell_type":{"74947257":"code","bd77504a":"code","92263af9":"code","534350cf":"code","bbc60bcc":"code","556d1017":"code","f5354717":"code","cc286da7":"code","7b1319c3":"code","e6424175":"code","3a792d5d":"code","5dbaafb9":"code","008868b8":"code","d07696e2":"code","1df6796e":"code","19b95b30":"code","385c24b0":"code","a6b521b1":"code","76aae60e":"code","8ee0db6b":"code","d25de993":"code","36a8e604":"code","0764443e":"code","d36d1477":"code","f1b4245e":"code","08b8635c":"code","f43a58fb":"code","60ae98b3":"code","cd7cb264":"code","d6c7e879":"code","4791ee2e":"code","2ebfb1ac":"code","b58a6a51":"code","f3fcd880":"code","47012d89":"code","fa84ea6c":"code","17e54945":"code","14f4dff4":"code","113dd035":"code","2ce492c6":"code","bf2b6a61":"code","d8f9a8f9":"code","1dd0166b":"code","2faf2ca8":"code","e60754c2":"code","f11ad5ad":"code","558d334f":"code","7179e5cc":"code","b80c7915":"markdown","dca8156e":"markdown","f0cb7a26":"markdown","8b2423f4":"markdown","a446a61b":"markdown","353520e5":"markdown","275f9504":"markdown","3278ef35":"markdown","3145fdaf":"markdown","2cd8bb24":"markdown","d631df6d":"markdown","c3964206":"markdown","618a777d":"markdown","e9ac2a43":"markdown","94f49525":"markdown","68563d5e":"markdown","c06f1a99":"markdown","6c746494":"markdown","c53214fb":"markdown"},"source":{"74947257":"import time","bd77504a":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input ,models\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers import Adagrad\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","92263af9":"    \n# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","534350cf":"# # Step 1: Get the credential from the Cloud SDK\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# user_credential = user_secrets.get_gcloud_credential()\n    \n#     # Step 2: Set the credentials\n# user_secrets.set_tensorflow_credential(user_credential)\n\n#     # Step 3: Use a familiar call to get the GCS path of the dataset\n# from kaggle_datasets import KaggleDatasets\n# GCS_DS_PATH = KaggleDatasets().get_gcs_path()\t\n    ","bbc60bcc":"# Set parameters\nIMAGE_SIZE = (256, 256)","556d1017":"train_files = []","f5354717":"mask_files = glob('..\/input\/lgg-mri-segmentation\/kaggle_3m\/*\/*_mask*')","cc286da7":"# mask_files","7b1319c3":"for i in mask_files:\n    train_files.append(i.replace('_mask', ''))","e6424175":"df = pd.DataFrame({\"image_path\": train_files, \"mask_path\":mask_files})\n","3a792d5d":"df\n","5dbaafb9":"def diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    if value:\n        return 1\n    else:\n        return 0\n\ndf['mask'] = df[\"mask_path\"].apply(lambda x: diagnosis(x))","008868b8":"df.head()","d07696e2":"df['mask'].value_counts()","1df6796e":"fig, ax = plt.subplots(10,3,figsize=(20,45))\nfor x in range(10):\n    i = random.randint(0, len(df))\n    img = cv2.imread(df['image_path'][i])\n    mask = cv2.imread(df['mask_path'][i])\n    ax[x][0].title.set_text(\"Brain MRI\")\n    ax[x][0].imshow(img)\n    ax[x][1].title.set_text(\"Mask - \" + str(df['mask'][i]))\n    ax[x][1].imshow(mask)\n    ax[x][2].title.set_text(\"Brain MRI with Mask\")\n    ax[x][2].imshow(img)\n    ax[x][2].imshow(mask, alpha=0.4)\nplt.tight_layout()","19b95b30":"df['mask'] = df['mask'].apply(lambda x: str(x))\ndf.info()","385c24b0":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.15)\ndf_train, df_val = train_test_split(df_train, test_size=0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","a6b521b1":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img \/ 255.\n    mask = mask \/ 255.\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","76aae60e":"smooth=100\n\ndef dice_coef(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    And=K.sum(y_truef* y_predf)\n    return((2* And + smooth) \/ (K.sum(y_truef) + K.sum(y_predf) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\ndef iou_loss(y_true, y_pred):\n    return -iou(y_true, y_pred)\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n\n    return - iou(y_true, y_pred)","8ee0db6b":"def unet(input_size=(256,256,3)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n    pool1=Dropout(0.3)(pool1)\n\n    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n    pool2=Dropout(0.3)(pool2)\n\n    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n    pool3=Dropout(0.3)(pool3)\n\n    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n    pool4=Dropout(0.3)(pool4)\n\n    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n\n    up6 = concatenate([Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n        \n\n\n    up9 = concatenate([Conv2DTranspose(64, (3,3), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","d25de993":" model = unet(input_size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\ntf.keras.utils.plot_model(\n    model, to_file='model3.png', show_shapes=, show_dtype=False,\n    show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96,\n    layer_range=None\n)","36a8e604":"# tf.keras.utils.plot_model(\n#     model, to_file='model3.png', show_shapes=False, show_dtype=False,\n#     show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96,\n#     layer_range=None\n# )","0764443e":"# Set parameters\nEPOCHS = 150\nBATCH_SIZE = 16\nlearning_rate = 5e-3","d36d1477":"learning_rate","f1b4245e":"train_generator_args = dict(rotation_range=0.2,\n#                             width_shift_range=0.05,\n#                             height_shift_range=0.05,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=IMAGE_SIZE)\n    \ntest_gener = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\n    ","08b8635c":"    \n# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","f43a58fb":"# model = unet(input_size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n# import tensorflow_addons as tfa\n# tfa.losses.SigmoidFocalCrossEntropy()","60ae98b3":"from keras import backend as K\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))\n","cd7cb264":"# model = unet(input_size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n# input_size=(256,256,3)\n# inputs = Input(input_size)\n# model=models.Sequential()\n# model.add(Conv2D(64, (3, 3), padding='same',input_shape= inputs))\ndecay_rate = learning_rate \/ EPOCHS\nopt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\nmodel.compile(optimizer=opt, loss=[dice_coef_loss,iou], metrics=[iou, dice_coef,\"binary_accuracy\"],steps_per_execution=32)\n","d6c7e879":"callbacks = [ModelCheckpoint('unet_brainMRI_seg.hdf5', verbose=0, save_best_only=True)]\n","4791ee2e":"import tensorflow_addons as tfa","2ebfb1ac":"tfa.losses.SigmoidFocalCrossEntropy()","b58a6a51":"history = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) \/\/ BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = test_gener,\n                    validation_steps=len(df_val) \/\/ BATCH_SIZE)","f3fcd880":"traindice = history.history['dice_coef']\ntestdice = history.history['val_dice_coef']\n\ntrainjaccard = history.history['iou']\ntestjaccard = history.history['val_iou']\n\ntrainloss = history.history['loss']\ntestloss = history.history['val_loss']\nplt.figure(1)\nplt.plot(testloss, 'b-')\nplt.plot(trainloss,'r-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(traindice, 'r-')\nplt.plot(testdice, 'b-')\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.title('accuracy graph', fontsize = 15)\nplt.show()","47012d89":"import json\n# Get the dictionary containing each metric and the loss for each epoch\nhistory_dict = history.history\n# Save it under the form of a json file\njson.dump(history_dict, open('history.json', 'w'))","fa84ea6c":"history_dict_loaded = json.load(open('history.json', 'r'))","17e54945":"history_dict_loaded_loss=history_dict_loaded['loss']","14f4dff4":"print(history_dict_loaded_loss)","113dd035":"plt.plot(history_dict_loaded_loss)","2ce492c6":"history_dict_loaded_loss","bf2b6a61":"print(len(traindice),len(testdice) ,len(trainjaccard) ,len(testjaccard) )","d8f9a8f9":"plt.plot()","1dd0166b":"test_gen = train_generator(df_test, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\nresults = model.evaluate(test_gen, steps=len(df_test) \/\/ BATCH_SIZE)\nprint(\"Test lost: \",results[0])\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","2faf2ca8":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['image_path'].iloc[index])\n    img = cv2.resize(img ,IMAGE_SIZE)\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","e60754c2":"model.save('.\/model_60.h5')","f11ad5ad":"type(history)","558d334f":"history.save('.\/history.h5')","7179e5cc":"import pickle\npickle.dump( history, open( \"history_60.p\", \"wb\" ) )","b80c7915":"### Training","dca8156e":"### Define Loss function and Metrics","f0cb7a26":"### Import necessary libraries","8b2423f4":"### Loading Image path and Mask path","a446a61b":"Visualize some random images with their tumor (if exist)","353520e5":"* Mask = 0 -> no tumor\n* Mask = 1 -> tumor","275f9504":"* Using UNet Model for Brain MRI Segmentation","3278ef35":"## Model 2: Segementaion Model to localize tumor","3145fdaf":"### This notebook includes 2 tasks: a Classifier to detect if tumor exist or not, and a Segmentation model to localize tumor\n\nIf you find this work useful, please upvote for me :))","2cd8bb24":"### Visualize MRI with Mask","d631df6d":"!['iou']('http:\/\/https:\/\/miro.medium.com\/max\/500\/1*Vsx1tBly1KnY7e8IKJvvQQ.jpeg')","c3964206":"### If you find this work useful, please don't forget upvoting","618a777d":"### Data Generator, Data Augmentation and Adjust Data","e9ac2a43":"### Split data into Train, Validation and Test Set","94f49525":"### Define UNet Modelbin","68563d5e":"### Create Data Frame","c06f1a99":"### Visualize the Result","6c746494":"### Evaluate the model","c53214fb":"### Visualize the model performance"}}