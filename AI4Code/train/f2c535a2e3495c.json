{"cell_type":{"1d407b49":"code","1541a786":"code","1c75098c":"code","4ce2e222":"code","baba77d7":"code","46b921c0":"code","771994e2":"code","72b27c92":"code","98c6c126":"code","1cdcc254":"code","2d65f5b7":"code","40cae2ae":"markdown","cb3af373":"markdown","e20a55a8":"markdown","ee66a2e6":"markdown","c7025b42":"markdown"},"source":{"1d407b49":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1541a786":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndefault_path = '\/kaggle\/input\/competitive-data-science-predict-future-sales\/'","1c75098c":"train_df = pd.read_csv(default_path+'sales_train.csv')\nitems_df = pd.read_csv(default_path+'items.csv')\nitem_categories_df = pd.read_csv(default_path+'item_categories.csv')\nshops_df = pd.read_csv(default_path+'shops.csv')\n\nsample_submission_df = pd.read_csv(default_path+'sample_submission.csv')\ntest_df = pd.read_csv(default_path+'test.csv')","4ce2e222":"print(train_df.shape, test_df.shape)","baba77d7":"train_df.head()","46b921c0":"train_df.info()","771994e2":"train_df.shape\nprint('Total records:', train_df.shape[0]\/(10**6))\nprint('Total columns:',train_df.shape[1])","72b27c92":"def exploring_stats(df_input):\n    total_rows = df_input.shape[0]\n    total_columns = df_input.shape[1]\n    # check data type\n    name = []\n    sub_type = []\n    for n, t in df_input.dtypes.iteritems():\n        name.append(n)\n        sub_type.append(t)\n\n    # check distinct\n    # cname is column name\n    check_ndist = []\n    for cname in df_input.columns:\n        ndist = df_input[cname].nunique()\n        pct_dist = ndist * 100.0 \/ total_rows\n        check_ndist.append(\"{} ({:0.2f}%)\".format(ndist, pct_dist))\n    # check missing\n    check_miss = []\n    for cname in df_input.columns:\n        nmiss = df_input[cname].isnull().sum()\n        pct_miss = nmiss * 100.0 \/ total_rows\n        check_miss.append(\"{} ({:0.2f}%)\".format(nmiss, pct_miss))\n    # check zeros\n    check_zeros = []\n    for cname in df_input.columns:\n        try:\n            nzeros = (df_input[cname] == 0).sum()\n            pct_zeros = nzeros * 100.0 \/ total_rows\n            check_zeros.append(\"{} ({:0.2f}%)\".format(nzeros, pct_zeros))\n        except:\n            check_zeros.append(\"{} ({:0.2f}%)\".format(0, 0))\n            continue\n    # check negative\n    check_negative = []\n    for cname in df_input.columns:\n        try:\n            nneg = (df_input[cname].astype(\"float\") < 0).sum()\n            pct_neg = nneg * 100.0 \/ total_rows\n            check_negative.append(\"{} ({:0.2f}%)\".format(nneg, pct_neg))\n        except:\n            check_negative.append(\"{} ({:0.2f}%)\".format(0, 0))\n            continue\n    data = {\"column_name\": name, \"data_type\": sub_type, \"n_distinct\": check_ndist, \"n_miss\": check_miss, \"n_zeros\": check_zeros,\n            \"n_negative\": check_negative, }\n    # check stats\n    df_stats = df_input.describe().transpose()\n    check_stats = []\n    for stat in df_stats.columns:\n        data[stat] = []\n        for cname in df_input.columns:\n            try:\n                data[stat].append(df_stats.loc[cname, stat])\n            except:\n                data[stat].append(0.0)\n    # col_ordered = [\"name\", \"sub_type\", \"n_distinct\", \"n_miss\", \"n_negative\", \"n_zeros\",\n    #                \"25%\", \"50%\", \"75%\", \"count\", \"max\", \"mean\", \"min\", \"std\"]  # + list(pdf_sample.columns)\n    df_data = pd.DataFrame(data)\n    # df_data = pd.concat([df_data, df_sample], axis=1)\n    # df_data = df_data[col_ordered]\n    return df_data","98c6c126":"exploring_stats(train_df)","1cdcc254":"train_df['date'] = pd.to_datetime(train_df['date'])","2d65f5b7":"train_df.head()","40cae2ae":"## 2. Construct Attribute description","cb3af373":"# I.Data Importing","e20a55a8":"## 1. Construct data set description","ee66a2e6":"This dataset has 3mil rows and 6 columns","c7025b42":"## Purpose: We are asking you to **predict total sales** for every **product** and **store** in the **next month**. By solving this competition you will be able to apply and enhance your data science skills"}}