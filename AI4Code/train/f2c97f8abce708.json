{"cell_type":{"e19e9937":"code","58511d23":"code","eff75986":"code","812d59d4":"code","d0b7de49":"code","667ba055":"code","b73feb3a":"code","15413fee":"code","8bb60a5e":"code","6e5a8ff7":"code","0ad82df9":"code","82e1001c":"code","19b24f88":"code","576f71e7":"code","6cc34fa9":"code","ac78b7f4":"code","ce5edb12":"code","82fe8190":"code","3c86b9c7":"code","38122857":"code","20e9ded0":"code","6450da94":"code","aff9cc29":"code","f4e09329":"code","7096962a":"markdown","127f572f":"markdown","62789ce1":"markdown","0eb177cd":"markdown","72daa08a":"markdown","5af0de04":"markdown","89936e85":"markdown","c07c17de":"markdown","97a52366":"markdown","2881c5a1":"markdown","30202cea":"markdown","6837de84":"markdown","ba5b24e5":"markdown","0a1cf338":"markdown"},"source":{"e19e9937":"#For loading and manipulating the data\nimport os\nimport random\nfrom kaggle_datasets import KaggleDatasets\n\n#For dealing with numbers and plotting\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n#Deep learning libraries\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense , Dropout, Activation\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomRotation, RandomZoom, RandomHeight, RandomWidth, RandomContrast\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n\n","58511d23":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept:\n    strategy = strategy = tf.distribute.MirroredStrategy() \nprint('Number of replicas:', strategy.num_replicas_in_sync)","eff75986":"# We can try using mixed precision or XLA accelerate to boost our training\nMIXED_PRECISION = True\nXLA_ACCELERATE = True\n\nif MIXED_PRECISION:\n    try: \n        if tpu: policy = tf.keras.mixed_precision.Policy('mixed_bfloat16')\n    except: \n        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n        mixed_precision.set_global_policy(policy)\n    print('Mixed precision enabled')\n\nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')","812d59d4":"#Let's set some parameters first for later use\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Configuration\nIMG_SIZE = (224, 224)\nSEED = 102\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nGCS_PATH = KaggleDatasets().get_gcs_path(\"covid19-radiography-database\")\n\n\n#Locate the file path of the images\nfile_path = \"..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\"","d0b7de49":"#Get the GCS path of the file\nfilenames = tf.io.gfile.glob(GCS_PATH + '\/COVID-19_Radiography_Dataset\/*\/*.png')\ntrain_filenames, test_filenames = train_test_split(filenames, test_size=0.2, random_state=SEED)","667ba055":"# Get a list of unique class names in the image dataset\nclass_names = [item for item in os.listdir(file_path) \n           if os.path.isdir(os.path.join(file_path, item)) ]\nprint(f'Classes: {class_names}')\n\n#print out the numbers of images\nfor class_name in class_names:\n    train_num_class = len([filename for filename in train_filenames if class_name in filename.split('\/')[-2]])\n    test_num_class = len([filename for filename in test_filenames if class_name in filename.split('\/')[-2]])\n    print(f\"{class_name} : {train_num_class} images in training set, {test_num_class} images in testing set\")","b73feb3a":"def make_dataset(filenames, buffer_size=1024,batch_size=BATCH_SIZE, num_parallel_calls=AUTOTUNE, augment=False, config=True):    \n\n    def get_label(file_path, class_names=class_names):\n        parts = tf.strings.split(file_path, os.path.sep)\n        one_hot = parts[-2] == class_names\n        return tf.cast(one_hot, tf.int32)\n\n    def decode_img(img):\n        img = tf.image.decode_png(img, channels=3)\n        img = tf.cast(img, tf.float32) \/ 255.0\n        img = tf.image.resize(img, IMG_SIZE)\n        return img\n\n    def process_path(file_path):\n        label = get_label(file_path)\n        img = tf.io.read_file(file_path)\n        img = decode_img(img)\n        return img, label\n\n    def configure_for_performance(ds,augment=False):\n        ds = ds.shuffle(buffer_size=1024)\n        ds = ds.batch(BATCH_SIZE)\n        \n        #If we want to do data augmentation to our images dataset\n        if augment:\n            ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n                num_parallel_calls=AUTOTUNE)\n\n        ds = ds.repeat()\n        ds = ds.prefetch(buffer_size=AUTOTUNE)\n        return ds\n    \n    \n    list_ds = tf.data.Dataset.from_tensor_slices(filenames)\n    ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n    \n    # here we set a config flag to prepare a test set without configuration for later analysis\n    if config:\n        ds = configure_for_performance(ds)\n    else:\n        ds = ds.batch(BATCH_SIZE)\n    \n    return ds","15413fee":"data_augmentation = Sequential([\n    RandomWidth(0.1),\n    RandomHeight(0.1),\n    RandomRotation(0.01),\n    RandomZoom(0.05),\n    RandomContrast(0.1)\n    \n],name=\"data_augmentation\")","8bb60a5e":"#make training and test datasets\ntrain_ds = make_dataset(train_filenames, augment=True)\ntest_ds = make_dataset(test_filenames)","6e5a8ff7":"#Let's count how many images there are in our training and testing datasets\nTRAIN_IMG_COUNT = tf.data.experimental.cardinality(tf.data.Dataset.from_tensor_slices(train_filenames)).numpy()\nprint(\"Training images: \" + str(TRAIN_IMG_COUNT))\n\nVAL_IMG_COUNT = tf.data.experimental.cardinality(tf.data.Dataset.from_tensor_slices(test_filenames)).numpy()\nprint(\"Testing images: \" + str(VAL_IMG_COUNT))","0ad82df9":"for image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label shape: \", label.numpy().shape)","82e1001c":"train_ds,test_ds","19b24f88":"image_batch, label_batch = next(iter(train_ds))","576f71e7":"def show_batch(image_batch, label_batch, class_names=class_names, data_aug=False):\n    image_batch = image_batch.numpy()\n    label_batch = label_batch.numpy()\n    plt.figure(figsize=(10,10))\n    for n in range(16):\n        ax = plt.subplot(4,4,n+1)\n        image = image_batch[n]\n        plt.imshow(image)\n        plt.title(class_names[np.argmax(label_batch[n])])\n        plt.axis(\"off\")","6cc34fa9":"show_batch(image_batch, label_batch)","ac78b7f4":"#Model Checkpoint for saving the best model during training\nmodel_checkpoint = ModelCheckpoint('model.h5',\n                                    montior='val_loss', \n                                    save_best_only=True, \n                                    verbose=0) \n\n\n# Reduce the learning rate on Plateau to minimun 1e-7\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',  \n                            factor=0.2, \n                             patience=2,\n                             verbose=1,\n                             min_lr=1e-7)\n\n#Early stopping when training hasn't improved for 2 epochs\nearly_stopping = EarlyStopping(\n    patience=2,\n    min_delta=0.001,\n    restore_best_weights=True,\n)","ce5edb12":"with strategy.scope():\n    \n    model = Sequential([\n        Conv2D(filters=16, kernel_size= (2,2), activation='relu', input_shape=(224, 224, 3)),\n        MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\"),\n        Conv2D(32, (3,3), activation='relu'),\n        MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\"),\n        Conv2D(64, (3,3), activation='relu'),\n        MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\"),\n        Flatten(),\n        Dense(32),\n        Dropout(0.2, input_shape=(32,)),\n        Dense(4),\n        Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")\n    ])\n    \n\n    \n    METRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n    \n    \n    model.compile(\n        optimizer= tf.keras.optimizers.Adam(1e-4),\n        loss=\"categorical_crossentropy\",\n        metrics=METRICS\n    )\n    \nprint(model.summary())","82fe8190":"# Comment out below lines to train the model\n# history = model.fit(\n#     train_ds,\n#     epochs=25,\n#     steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n#     validation_data=test_ds,\n#     validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n#     callbacks= [reduce_lr, early_stopping,model_checkpoint]\n\n# )\n\n\n# Save the training history and output as csv\n# hist_df = pd.DataFrame(history.history)\n# hist_csv_file = 'history.csv'\n# with open(hist_csv_file, mode='w') as f:\n#     hist_df.to_csv(f)","3c86b9c7":"# Load saved model\nmodel = tf.keras.models.load_model('..\/input\/covid19-xray-training-output\/model.h5')","38122857":"#Load training history\nhistory = pd.read_csv('..\/input\/covid19-xray-training-output\/history.csv', index_col=0)\nhistory","20e9ded0":"# Make a new test dataset without configuration for validation\ntest_ds = make_dataset(test_filenames,config=False)\n\n#get all y true labels from the dataset\ny_true = [class_names.index(name.split('\/')[-2]) for name in test_filenames]\n\n#using our model to predict and get y_predict\ny_prob = model.predict(test_ds, verbose=1) \ny_predict = y_prob.argmax(axis=-1)","6450da94":"#Let's see the classification report\nprint(classification_report(y_true, y_predict,target_names=class_names))","aff9cc29":"# Visualize confusion matrix\nplt.figure(figsize=(12,8))\ncm = confusion_matrix(y_true, y_predict)\nsns.heatmap(cm, annot=True, fmt='d',xticklabels=class_names, yticklabels=class_names)","f4e09329":"#plot learning history\nplt.figure(figsize=(20,8))\nplt.subplot(121)\nplt.plot(history['accuracy'])\nplt.plot(history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\n\nplt.subplot(122)\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n","7096962a":"# 5. Validation and Visualization","127f572f":"Here I used a few data augmentation parameters. Since the X-ray images tend to be in the regular in terms of the position and orientation, I don't choose to use great extent of data augmentation.","62789ce1":"Let's create a batch and visualize the images in the batch","0eb177cd":"To save the time to retrain the model once restarts, we will load the saved trained model and do subsequent analysis.\n","72daa08a":"# COVID-19 Chest X-ray Classification\n\nIn this notebook, we will use COVID-19 Chest X-ray images from COVID-19 RADIOGRAPHY DATABASE https:\/\/www.kaggle.com\/tawsifurrahman\/covid19-radiography-database. In the following, we will do a multiclass classification to classify whether an X-ray image is normal, lung opacity,pneumonia or COVID-19. For this notebook we will use TPU for more efficient model training.\n","5af0de04":"Let's have a look of a batch in our training dataset and check whether the image and the labels are in correct shape","89936e85":"# 4. Model training","c07c17de":"# 1. Import Libraries and Set-up\nLet's import all the libraries we need first","97a52366":"Now we will configure TPU in this Kaggle Kernel for our model training later","2881c5a1":"# 2. Get the files and Create dataset","30202cea":"# 3. Visualize the images in the training dataset","6837de84":"We will create a function to a tf.dataset in the next step.","ba5b24e5":"We'll have to check whether our dataset is in correct shape.","0a1cf338":"* Now we will set up some callbacks parameters right now"}}