{"cell_type":{"ab5c2764":"code","eb5913f9":"code","3cb389fd":"code","e53c71b8":"code","28efe0bb":"code","55dcd970":"code","96a9cb7b":"code","b6100981":"code","295d2761":"code","56d03a37":"code","23d4eab5":"code","200ac66f":"code","64fcc397":"code","55785b8b":"code","e1828ec5":"code","570f7fd0":"code","4ab1606f":"code","75685ba0":"code","ca718a31":"code","1befd93a":"code","f474820f":"code","db809ed3":"code","3ffd185d":"code","cdd9d75d":"code","2cab5c86":"code","4300b605":"code","eb31f2d8":"code","50b4b45c":"code","de890dff":"code","29e9a111":"code","ccdea1b8":"code","736eebe9":"code","2f215625":"code","6ccdaac5":"code","be89b284":"code","85704ae3":"code","0e7806b1":"code","9793baee":"code","f11e426a":"code","0e5ab753":"code","06094544":"code","224124f1":"code","97ce5a76":"code","b8cfbeea":"code","dc6db95f":"code","5c11be70":"code","b4903939":"code","730778b0":"code","1804554e":"code","992ecf42":"code","4cca1f52":"code","484f4f75":"code","a971b6fa":"code","f6f5cfa9":"code","cd6d7ef7":"code","3332c222":"code","0ce584fd":"markdown","fdd62ff4":"markdown","724b75bb":"markdown","ff9b4998":"markdown","0065d581":"markdown","146ddebb":"markdown","68c441d2":"markdown","c35e6584":"markdown","a337c62f":"markdown","13f84903":"markdown","072fe43f":"markdown","22c2edd4":"markdown","e844d75b":"markdown","2fc941d0":"markdown","d9a5908d":"markdown","fb7378dc":"markdown","73418757":"markdown","14d74e40":"markdown","18db82b4":"markdown","f1624f5d":"markdown","6a2d9e03":"markdown","fc0ec073":"markdown","bc1dd8bd":"markdown"},"source":{"ab5c2764":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\nfrom sklearn.model_selection import train_test_split\n\nimport random\nfrom random import randint\nimport re\n\nfrom keras.utils import to_categorical","eb5913f9":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical #convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\n","3cb389fd":"\n\n#%tensorflow_version 2.x\nimport tensorflow as tf\n\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))\n\nprint(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")","e53c71b8":"# creat data dirctories, we my use it later\n\nDATA_DIR = '..\/input\/dog-breed-identification'\n\n\nTRAIN_DIR = DATA_DIR + '\/train'                           \nTEST_DIR = DATA_DIR + '\/test'                             \n\nTRAIN_CSV = DATA_DIR + '\/labels.csv'                     \nTEST_CSV = DATA_DIR + '\/sample_submission.csv' ","28efe0bb":"# Checkout the labels of our data\nimport pandas as pd\nlabels_df= pd.read_csv(TRAIN_CSV)\nlabels_df.head()","55dcd970":"labels_df.describe()","96a9cb7b":"labels = labels_df[\"breed\"].to_numpy() # convert labels column to NumPy array\nlabels[:15] ","b6100981":"num_images = len(labels_df[\"id\"])\nprint('Number of images in Training file:', num_images)\nno_labels=len(labels)\nprint('Number of dog breeds in Training file:', no_labels)","295d2761":"# Make bar chart\n\nbar = labels_df[\"breed\"].value_counts(ascending=True).plot.barh(figsize = (30,120))\nplt.title(\"Distribution of the Dog Breeds\", fontsize = 20)\nbar.tick_params(labelsize=20)\nplt.show()","56d03a37":"# Create pathnames from image ID's\nfilenames = [TRAIN_DIR + \"\/\" + fname + \".jpg\" for fname in labels_df[\"id\"]]\nfilenames[:10]","23d4eab5":"# display some dogs with their labels\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(25, 25),\n                          subplot_kw={'xticks': [], 'yticks': []})\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(filenames[i]))\n    ax.set_title(labels_df.breed[i])\nplt.tight_layout()\nplt.show()\n","200ac66f":"# check image size\nfrom matplotlib.pyplot import imread\nimage = imread(filenames[42]) # read in an image\nimage.shape","64fcc397":"# See if number of labels matches the number of filenames\nif len(labels) == len(filenames):\n  print(\"Number of labels matches number of filenames!\")\nelse:\n  print(\"Number of labels does not match number of filenames, check data directories.\")","55785b8b":"# Find the unique label values\nunique_breeds = np.unique(labels)\nlen(unique_breeds)","e1828ec5":"one_hot_labels = [label == np.array(unique_breeds) for label in labels]\none_hot_labels[0] ","570f7fd0":"# Setup X & y variables\nX = filenames\ny = one_hot_labels","4ab1606f":"# Define image size\nIMAGE_SIZE = 331\n\n\n\ndef process_image(image_path):\n  \"\"\"\n  Takes an image file path and turns it into a Tensor.\n  \"\"\"\n  # Read in image file\n  image = tf.io.read_file(image_path)\n  \n  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n  image = tf.image.decode_jpeg(image, channels=3)\n  \n\n  # Convert the colour channel values from 0-225 values to 0-1 values\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  \n  # Resize the image to our desired size \n  image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n\n  return image\n","75685ba0":"#Display one dog\n#plt.imshow(process_image(filenames[0]))\n#plt.title(labels_df.breed[0])\n\none_image=process_image(filenames[0])\none_image\n#print(one_image.shape)","ca718a31":"#diplay dogs after processing\n\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(25, 25),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(process_image(filenames[i]))\n    ax.set_title(labels_df.breed[i])\nplt.tight_layout()\nplt.show()\n\n\n","1befd93a":"def data_agumentation(image=process_image):\n    image=tf.image.random_flip_up_down(image)\n    image=tf.image.random_flip_left_right(image)\n    return image\n\n\n\n\n#not used..low accuraccy","f474820f":"# Split them into training and validation using NUM_IMAGES \nX_train, X_val, y_train, y_val = train_test_split(X[:1000],\n                                                  y[:1000], \n                                                  test_size=0.15,\n                                                  random_state=42)\n\nlen(X_train), len(y_train), len(X_val), len(y_val)","db809ed3":"# Create a simple function to return a tuple (image, label)\ndef get_image_label(image_path, label):\n  \"\"\"\n  Takes an image file path name and the associated label,\n  processes the image and returns a tuple of (image, label).\n  \"\"\"\n  image = process_image(image_path)\n  return image, label","3ffd185d":"# Define the batch size, 32 is a good default\nBATCH_SIZE = 32\n\n# Create a function to turn data into batches\ndef create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n  \"\"\"\n  Creates batches of data out of image (x) and label (y) pairs.\n  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n  Also accepts test data as input (no labels).\n  \"\"\"\n  # If the data is a test dataset, we probably don't have labels\n  if test_data:\n    print(\"Creating test data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n    data_batch = data.map(process_image).batch(batch_size)\n    return data_batch\n  \n  # If the data if a valid dataset, we don't need to shuffle it\n  elif valid_data:\n    print(\"Creating validation data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                               tf.constant(y))) # labels\n    data_batch = data.map(get_image_label).batch(batch_size)\n    return data_batch\n\n  else:\n    # If the data is a training dataset, we shuffle it\n    print(\"Creating training data batches...\")\n    # Turn filepaths and labels into Tensors\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                              tf.constant(y))) # labels\n    \n    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n    #data = data.shuffle(buffer_size=len(x))\n\n    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n    data = data.map(get_image_label)\n\n    # Turn the data into batches\n    data_batch = data.batch(BATCH_SIZE)\n  return data_batch","cdd9d75d":"# Create training and validation data batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val, valid_data=True)","2cab5c86":"# Create a function for viewing images in a data batch\ndef show_25_images(images, labels):\n  \"\"\"\n  Displays 25 images from a data batch.\n  \"\"\"\n  # Setup the figure\n  plt.figure(figsize=(10, 10))\n  # Loop through 25 (for displaying 25 images)\n  for i in range(25):\n    # Create subplots (5 rows, 5 columns)\n    ax = plt.subplot(5, 5, i+1)\n    # Display an image\n    plt.imshow(images[i])\n    # Add the image label as the title\n    plt.title(unique_breeds[labels[i].argmax()])\n    # Turn gird lines off\n    plt.axis(\"off\")","4300b605":"# Visualize training images from the training data batch\ntrain_images, train_labels = next(train_data.as_numpy_iterator())\nshow_25_images(train_images, train_labels)","eb31f2d8":"# Visualize validation images from the validation data batch\nval_images, val_labels = next(val_data.as_numpy_iterator())\nshow_25_images(val_images, val_labels)","50b4b45c":"# Setup input shape to the model\nINPUT_SHAPE = [None, IMAGE_SIZE, IMAGE_SIZE, 3] # batch, height, width, colour channels\n\n# Setup output shape of the model\nOUTPUT_SHAPE = len(unique_breeds) # number of unique labels\n","de890dff":"#create model\n\ndef create_model():\n    pretrained_model = tf.keras.applications.InceptionV3(input_shape=(IMAGE_SIZE,IMAGE_SIZE, 3), include_top=False)\n    pretrained_model.trainable = True\n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(OUTPUT_SHAPE, activation='softmax')\n      ])\n    \n    #Define the optimizer\n    optimizer=RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n\n\n\n    model.compile(\n        optimizer=optimizer,\n        loss = tf.keras.losses.CategoricalCrossentropy(),\n        metrics=['accuracy']\n  )\n    \n  # Build the model\n    model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n    return model  \n  \n","29e9a111":"\n# Create a model and check its details\nmodel = create_model()\nmodel.summary() ","ccdea1b8":"# Create early stopping (once our model stops improving, stop training)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                                  patience=3) # stops after 3 rounds of no improvements","736eebe9":"# Set a learning rate annealer\nlearning_rate_redcuing=ReduceLROnPlateau(monitor='val_accuracy', \n                                         patience=3,\n                                         verbose=1,\n                                         factor=0.5,\n                                         min_lr=0.00001)","2f215625":"# How many rounds should we get the model to look through the data?\nNUM_EPOCHS = 100","6ccdaac5":"# Build a function to train and return a trained model\ndef train_model(NUM_EPOCHS, model):\n    \"\"\"\n    Trains a given model and returns the trained version.\n    \"\"\"\n\n    # Fit the model to the data passing it the callbacks we created\n    history=model.fit(x=train_data,\n                epochs=NUM_EPOCHS,\n                validation_data=val_data,\n                steps_per_epoch=len(X_train) \/\/ BATCH_SIZE,\n                validation_freq=1, # check validation metrics every epoch\n                callbacks=[learning_rate_redcuing, early_stopping])\n    return history\n  \n","be89b284":"# Fit the model to the data\nhistory = train_model(NUM_EPOCHS,model)\n\nfinal_accuracy = history.history[\"val_accuracy\"][-5:]\nprint(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))","85704ae3":"def display_training_curves(training, validation, title, subplot):\n  ax = plt.subplot(subplot)\n  ax.plot(training)\n  ax.plot(validation)\n  ax.set_title('Model '+ title)\n  ax.set_ylabel(title)\n  ax.set_xlabel('Epoch')\n  ax.legend(['Training', 'Validation'])\n\nplt.subplots(figsize=(10,10))\nplt.tight_layout()\ndisplay_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\ndisplay_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)","0e7806b1":"# Make predictions on the validation data (not used to train on)\npredictions = model.predict(val_data, verbose=1) # verbose shows us how long there is to go\npredictions\n","9793baee":"# Check the shape of predictions\npredictions.shape","f11e426a":"# First prediction\nprint(predictions[0])\nprint(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\nprint(f\"Sum: {np.sum(predictions[0])}\") # because we used softmax activation in our model, this will be close to 1\nprint(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {unique_breeds[np.argmax(predictions[0])]}\") # the predicted label","0e5ab753":"# Create a function to unbatch a batched dataset\ndef unbatchify(data):\n  \"\"\"\n  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n  of images and labels.\n  \"\"\"\n  images = []\n  labels = []\n  # Loop through unbatched data\n  for image, label in data.unbatch().as_numpy_iterator():\n    images.append(image)\n    labels.append(unique_breeds[np.argmax(label)])\n  return images, labels\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(val_data)\nval_images[0], val_labels[0]","06094544":"# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into a label.\n  \"\"\"\n  return unique_breeds[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(predictions[0])\npred_label","224124f1":"def plot_pred(prediction_probabilities, labels, images, n=1):\n  \"\"\"\n  View the prediction, ground truth label and image for sample n.\n  \"\"\"\n  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n  # Get the pred label\n  pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n  plt.imshow(image)\n  plt.xticks([])\n  plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n  if pred_label == true_label:\n    color = \"green\"\n  else:\n    color = \"red\"\n\n  plt.title(\"Predicted label :{} ({:2.0f}%) \\n True label :{}\".format(pred_label,\n                                      np.max(pred_prob)*100,\n                                      true_label),\n                                      color=color)","97ce5a76":"# View an example prediction, original image and truth label\nplot_pred(prediction_probabilities=predictions, n=0,\n          labels=val_labels,\n          images=val_images)","b8cfbeea":"def plot_pred_conf(prediction_probabilities, labels, n=1):\n    \"\"\"\n    Plots the top 10 highest prediction confidences along with\n    the truth label for sample n.\n    \"\"\"\n    pred_prob, true_label = prediction_probabilities[n], labels[n]\n\n    # Get the predicted label\n    pred_label = get_pred_label(pred_prob)\n\n    # Find the top 10 prediction confidence indexes\n    top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n    \n    # Find the top 10 prediction confidence values\n    top_10_pred_values = pred_prob[top_10_pred_indexes]\n    \n    # Find the top 10 prediction labels\n    top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n\n    # Setup plot\n    top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n                     top_10_pred_values, color=\"gray\")\n        \n    plt.xticks(np.arange(len(top_10_pred_labels)),\n             labels=top_10_pred_labels, rotation=\"vertical\")\n    \n     # Change color of true label\n    #if np.isin(true_label, top_10_pred_labels):\n    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n \n    \n\n\n","dc6db95f":"plot_pred_conf(prediction_probabilities=predictions,\n               labels=val_labels,\n               n=0)","5c11be70":"# Let's check a few predictions and their different values\ni_multiplier = 0\nnum_rows = 3\nnum_cols = 2\nnum_images = num_rows*num_cols\nplt.figure(figsize=(5*2*num_cols, 5*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_pred(prediction_probabilities=predictions,\n            labels=val_labels,\n            images=val_images,\n            n=i+i_multiplier)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_pred_conf(prediction_probabilities=predictions,\n                labels=val_labels,\n                n=i+i_multiplier)\nplt.tight_layout(h_pad=1.0)\nplt.show()","b4903939":"import datetime\nimport shutil\n\n#shutil.rmtree(\".\/models\")\n\n#Make directory\nshutil.os.mkdir(\".\/models\")\n\n\ndef save_model(model, suffix=None):\n    \"\"\"\n    Saves a given model in a models directory and appends a suffix (str)\n    for clarity and reuse.\n    \"\"\"\n    # Create model directory with current time\n    modeldir = os.path.join(\"models\",\n                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n    model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n    print(f\"Saving model to: {model_path}...\")\n    model.save(model_path)\n    return model_path","730778b0":"def load_model(model_path):\n  \"\"\"\n  Loads a saved model from a specified path.\n  \"\"\"\n  print(f\"Loading saved model from: {model_path}\")\n  model = tf.keras.models.load_model(model_path)\n                                     \n  return model","1804554e":"# Save our model trained on 1000 images\nsave_model(model, suffix=\"1000 images model\")","992ecf42":"# Load our model trained on 1000 images\n#model_1000_images = load_model('models\/20200815-22211597530072-1000 images model.h5')","4cca1f52":"# Evaluate the pre-saved model\nmodel.evaluate(val_data)","484f4f75":"# Evaluate the loaded model\n#model_1000_images.evaluate(val_data)","a971b6fa":"test_filenames = [TEST_DIR +\"\/\"+ fname for fname in os.listdir(TEST_DIR)]","f6f5cfa9":"# Create test data batch\ntest_data = create_data_batches(test_filenames, test_data=True)","cd6d7ef7":"#take one hour to complete\n\n# Make predictions on test data batch using the loaded full model\ntest_predictions = model.predict(test_data, verbose=1)","3332c222":"# Check out the test predictions\ntest_predictions[:10]","0ce584fd":"## Visualizing data batches","fdd62ff4":"## Image processing ","724b75bb":"labels.csv file contains all Images ID and labels. Every entry contains ID image and its assosciated dog breed","ff9b4998":"# Making predictions on the test dataset","0065d581":"## Saving and reloading a model","146ddebb":"# Input data and pre-processing ","68c441d2":"# Creating data batches","c35e6584":"# Exlporatory Data Analysis (EDA)","a337c62f":"## Creating callbacks","13f84903":"# Setup Workplace","072fe43f":"## Data agumentation","22c2edd4":"Since the output of our predictor for each input is a vector of probabilities for each class we must convert out label dataset to be the same format. That is for each input a row vector of length num_classes with a 1 at the index of the label and 0's everywhere else.","e844d75b":"To create data dirctories","2fc941d0":"# Create model","d9a5908d":"# Introduction","fb7378dc":"# Creating and training a model","73418757":"**We cansee that:**\n*   All images are of differnt sizes.\n*   The backgrounsd vary- some have humans, and other things.\n*   Some images are not vertical\n","14d74e40":"## Enabling and testing the GPU\n","18db82b4":"# Making and evaluating predictions using a trained model","f1624f5d":"## Training a model","6a2d9e03":"## Oen-hot encoding","fc0ec073":"In this project I going to be using deep learning to help us identify 120 breeds of dogs. \nI will load the data from Kaggle competition ( [Kaggle dog breed identification competition](https:\/\/www.kaggle.com\/c\/dog-breed-identification\/overview)). \nIn this project, a pre-trainded model form tensorflow hud used to predict a 120 differents breeds of dogs. This is call Multi-classs classification. For speed the training and validation processes I will use GPU as processor.\nEnabling a GPU to your Kernel results in a 12.5X speedup during training of a deep learning model.\n\n","bc1dd8bd":"## Spilt data for experimenting"}}