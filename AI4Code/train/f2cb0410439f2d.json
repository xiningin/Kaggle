{"cell_type":{"fef113b4":"code","0ad919db":"code","48842330":"code","79d53a6b":"code","60fe9110":"code","919fcad9":"code","78051ea4":"code","1f859f9b":"code","c1d96eb8":"code","361daa36":"code","005dfbbe":"code","3c68525e":"code","129064c6":"code","f9c95c97":"code","73735e70":"code","de39b485":"code","39bb484d":"code","f5811959":"code","f00310c9":"code","5e39917e":"code","ae346c2b":"code","9b366734":"code","75df6dd0":"code","2916faa1":"code","c2bf0191":"code","c349f1d6":"code","2804cf6f":"code","789ca253":"code","e9990e38":"code","ed44a6d9":"code","2bab73ed":"code","8eabc473":"code","b114df68":"code","2e2f4484":"code","b17eef94":"code","0d32bfd4":"code","5a1fe8eb":"code","e8507fe6":"markdown","3c1eb95b":"markdown"},"source":{"fef113b4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#json\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport string\nimport gc","0ad919db":"def create_text_from_json(dataInd,fileId):\n    filename = \"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/\" + dataInd + \"\/\" + fileId + \".json\"\n    \n    fd = open(filename, mode='r')\n    data = json.load(fd)\n    fd.close()\n    json_text = ''\n    for sections in data:\n        json_text = json_text + ' ' + sections.get('text')\n    \n    return json_text","48842330":"def text_cleaning(text):\n    text = ''.join([k if k not in string.punctuation else ' ' for k in text])\n    text = re.sub('[^A-Za-z0-9]+', ' ', str(text).lower()).strip()\n    \n    return text","79d53a6b":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()","60fe9110":"sample_submission_df = pd.read_csv(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv\")\ntrain_df = pd.read_csv(\"\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train.csv\")","919fcad9":"training_text = []\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u53d6\u308a\u8fbc\u307f\nfor Id in train_df[\"Id\"]:\n    training_text.append(create_text_from_json(\"train\", Id))\n\ntrain_df['text'] = training_text","78051ea4":"train_df['text'] = train_df['text'].apply(text_cleaning)","1f859f9b":"train_df.head()","c1d96eb8":"submit_text = []\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u53d6\u308a\u8fbc\u307f\nfor Id in sample_submission_df[\"Id\"]:\n    submit_text.append(create_text_from_json(\"test\", Id))\n\nsample_submission_df['text'] = submit_text","361daa36":"sample_submission_df.head()","005dfbbe":"temp_1 = [x.lower() for x in train_df['dataset_label'].unique()]\ntemp_2 = [x.lower() for x in train_df['dataset_title'].unique()]\ntemp_3 = [x.lower() for x in train_df['cleaned_label'].unique()]\nexisting_labels = set(temp_1 + temp_2 + temp_3)\n\nid_list = []\nlables_list = []\nfor index, row in sample_submission_df.iterrows():\n    sample_text = row['text']\n    row_id = row['Id']\n    temp_df = train_df[train_df['text'] == text_cleaning(sample_text)]\n    cleaned_labels = temp_df['cleaned_label'].to_list()\n    for known_label in existing_labels:\n        if known_label in sample_text.lower():\n            cleaned_labels.append(clean_text(known_label))\n    cleaned_labels = [clean_text(x) for x in cleaned_labels]\n    cleaned_labels = set(cleaned_labels)\n    lables_list.append('|'.join(cleaned_labels))\n    id_list.append(row_id)","3c68525e":"# \u63d0\u51fa\u7528\u30c7\u30fc\u30bf\u4f5c\u6210\nmy_submission = pd.DataFrame()\nmy_submission['Id'] = id_list\nmy_submission['PredictionString1'] = lables_list","129064c6":"my_submission.head()","f9c95c97":"del training_text\ndel submit_text\ndel id_list\ndel lables_list\ndel sample_text\ngc.collect()","73735e70":"!pip install '..\/input\/simpletransformers0272\/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '..\/input\/tokenizers-070\/tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl' -q\n!pip install '..\/input\/simpletransformers-0323-pypi\/transformers-2.11.0-py3-none-any.whl' -q\n!pip install '..\/input\/simpletransformers-0323-pypi\/simpletransformers-0.32.3-py3-none-any.whl' -q","de39b485":"from simpletransformers.classification import MultiLabelClassificationModel\nimport logging","39bb484d":"# \u30ed\u30b0\u306e\u8a2d\u5b9a\nlogging.basicConfig(level=logging.INFO)\ntransformers_logger = logging.getLogger(\"transformers\")\ntransformers_logger.setLevel(logging.WARNING)","f5811959":"work_df = pd.get_dummies(train_df['cleaned_label']) \nlabel_list = list(work_df.columns)","f00310c9":"del work_df\ngc.collect()","5e39917e":"distinct_train_df = pd.DataFrame()\ndistinct_train_df['Id'] = train_df['Id']\ndistinct_train_df['text'] = train_df['text']\ndistinct_train_df = distinct_train_df.drop_duplicates(subset=[\"Id\"])","ae346c2b":"work_label_df = pd.DataFrame()\nfor label in label_list:\n    match_list = []\n    for index, row in distinct_train_df.iterrows():\n        match_list.append(1 if label in row['text'] else 0)\n    work_label_df[label] = match_list\n\ndistinct_train_df['label'] = work_label_df.values.tolist()","9b366734":"del match_list\ndel work_label_df\ngc.collect()","75df6dd0":"from gensim.parsing.preprocessing import remove_stopwords","2916faa1":"stopword_list = list(set([stopword for stopword in clean_text(' '.join(existing_labels)).split()]))","c2bf0191":"def text_preprocessing(json_text):\n    json_text = remove_stopwords(json_text)\n    \n    for label in label_list:\n        json_text.replace(label,'')\n\n    for stopword in stopword_list:\n        json_text.replace(stopword,'')\n\n    return json_text","c349f1d6":"distinct_train_df['text'] = distinct_train_df['text'].apply(text_preprocessing)","2804cf6f":"distinct_train_df.head()","789ca253":"sample_submission_df['text'] = sample_submission_df['text'].apply(text_cleaning)\nsample_submission_df['text'] = sample_submission_df['text'].apply(text_preprocessing)","e9990e38":"sample_submission_df.head()","ed44a6d9":"gc.collect()","2bab73ed":"distinct_train_df = distinct_train_df.sample(frac=1)","8eabc473":"# \u30e2\u30c7\u30eb\u306e\u4f5c\u6210\nmodel = MultiLabelClassificationModel('albert', '..\/input\/pretrained-albert-pytorch\/albert-base-v2', \n                                      num_labels=len(label_list),\n                                      use_cuda=False, \n                                      args={'reprocess_input_data': False, \n                                            'overwrite_output_dir': True, \n                                            'train_batch_size': 8, \n                                            'num_train_epochs': 1})\n\nmodel.train_model(distinct_train_df.drop('Id',axis=1))","b114df68":"Prediction_list = []\nfor index, row in sample_submission_df.iterrows():\n    predictions, raw_outputs = model.predict([row['text']])\n    Prediction_list.append('|'.join(np.array(label_list)[predictions==1].tolist()))\n\nmy_submission['PredictionString2'] = Prediction_list","2e2f4484":"my_submission.head()","b17eef94":"#2\u3064\u306e\u30e2\u30c7\u30eb\u306e\u7d50\u679c\u3092\u30de\u30fc\u30b8\nmy_submission['PredictionString'] = np.where(my_submission['PredictionString1'] == '', \n                                             my_submission['PredictionString2'], \n                                             my_submission['PredictionString1'])\nmy_submission = my_submission.drop('PredictionString1', axis=1)\nmy_submission = my_submission.drop('PredictionString2', axis=1)","0d32bfd4":"my_submission.head()","5a1fe8eb":"# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","e8507fe6":"## literal matching","3c1eb95b":"## simple transformers"}}