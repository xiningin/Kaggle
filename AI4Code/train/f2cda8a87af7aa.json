{"cell_type":{"a9d83db9":"code","ead74e2f":"code","ad5f4b44":"code","755638c5":"code","668e3da1":"code","011a26d2":"code","6192bc5c":"code","d28362b4":"code","234213dc":"code","606abecf":"code","8c6b0b95":"code","454edbea":"code","49e34391":"markdown","d9eb3699":"markdown","3f81e831":"markdown","288c1df6":"markdown","8fc94e4c":"markdown","281d30db":"markdown","a9c7e36c":"markdown","9f303dd1":"markdown","70591fef":"markdown","bc942291":"markdown","4ef00e9b":"markdown","6f556996":"markdown","4fff9df7":"markdown","23a2b2bf":"markdown","f3a21241":"markdown","c030bcaf":"markdown","5be3cb63":"markdown","7c92f051":"markdown","fab8481c":"markdown","0977ae57":"markdown"},"source":{"a9d83db9":"from PIL import Image \nImage.open(\"..\/input\/ab-testing\/ab-testing.png\")","ead74e2f":"from PIL import Image \nImage.open(\"..\/input\/example-ab\/example.png\")","ad5f4b44":"# installlation required\n!pip install openpyxl\n\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.stats.api as sms\nfrom scipy.stats import ttest_1samp, shapiro, levene, ttest_ind, mannwhitneyu, pearsonr, spearmanr, kendalltau, \\\n    f_oneway, kruskal\nfrom statsmodels.stats.proportion import proportions_ztest\nimport plotly.graph_objs as go   \nimport plotly.offline as py \npy.init_notebook_mode(connected=True) \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n# Making the appearance settings of the printouts\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)","755638c5":"# Load data into pandas dataframe..\n\n# Maximum Bidding\ncontrol = pd.read_excel(\"..\/input\/ab-test\/ab_testing.xlsx\", sheet_name=\"Control Group\")\n\ndef check_df(dataframe):\n    print(f\"\"\"\n        ##################### Shape #####################\\n\\n\\t{dataframe.shape}\\n\\n\n        ##################### Types #####################\\n\\n{dataframe.dtypes}\\n\\n\n        ##################### Head #####################\\n\\n{dataframe.head(3)}\\n\\n\n        ##################### NA #####################\\n\\n{dataframe.isnull().sum()}\\n\\n\n        ##################### Quantiles #####################\\n\\n{dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T}\\n\\n\"\"\")\ncheck_df(control)","668e3da1":"# Average Bidding\ntest = pd.read_excel(\"..\/input\/ab-test\/ab_testing.xlsx\", sheet_name=\"Test Group\")\n\ndef check_df(dataframe):\n    print(f\"\"\"\n        ##################### Shape #####################\\n\\n\\t{dataframe.shape}\\n\\n\n        ##################### Types #####################\\n\\n{dataframe.dtypes}\\n\\n\n        ##################### Head #####################\\n\\n{dataframe.head(3)}\\n\\n\n        ##################### NA #####################\\n\\n{dataframe.isnull().sum()}\\n\\n\n        ##################### Quantiles #####################\\n\\n{dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T}\\n\\n\"\"\")\ncheck_df(test)","011a26d2":"# Numerical Variable Frequency of Test and Control Datasets\nnum_cols = [col for col in control.columns if control[col].dtypes != 'O' and col not in \"Id\"]\nprint('Number of Numerical Variable: ', len(num_cols))\n\ndef hist_for_nums(data, numeric_cols, color= True):\n    col_counter = 0\n    data = data.copy()\n    if color:\n        for col in numeric_cols:\n            data[col].plot.hist(alpha=0.5, color=\"b\")\n            plt.xlabel(col)\n            plt.title(col)\n            plt.show()\n            col_counter += 1\n    else:\n        for col in numeric_cols:\n            data[col].plot.hist(alpha=0.5, color=\"y\")\n            plt.xlabel(col)\n            plt.title(col)\n            plt.show()\n            col_counter += 1   \n    print(col_counter, \"variables have been plotted\")\n    \nhist_for_nums(control, num_cols) \nhist_for_nums(test, num_cols, color=False) ","6192bc5c":"trace0 = go.Box(\n    y=control[\"Purchase\"],\n    name='Control Purchase Da\u011f\u0131l\u0131m\u0131',\n    marker=dict(\n        color='LightSkyBlue'\n    )\n)\n\ntrace1 = go.Box(\n    y=test['Purchase'],\n    name='Test Purchase Da\u011f\u0131l\u0131m\u0131',\n    marker=dict(\n        color='DarkSlateGrey'\n    )\n)\n    \ndata = [trace0, trace1]\n\nlayout = go.Layout(\n    yaxis=dict(\n        title='Frequency',\n        zeroline=False\n    ),\n    xaxis=dict(\n        title='Purchase of Control and Test Group'\n    ),\n    boxmode='group'\n)\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='box-age-cat')","d28362b4":"test_stat, pvalue = shapiro(control[\"Purchase\"])\nprint('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))","234213dc":"test_stat, pvalue = shapiro(test[\"Purchase\"])\nprint('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))","606abecf":"test_stat, pvalue = levene(control[\"Purchase\"], test[\"Purchase\"])\nprint('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))","8c6b0b95":"test_stat, pvalue = ttest_ind(control[\"Purchase\"], test[\"Purchase\"], equal_var=True)\nprint('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))","454edbea":"from PIL import Image \nImage.open(\"..\/input\/pvalue\/win.png\")","49e34391":"* >  H0 hypothesis **could not be rejected** because pvalue = 0.5891 > 0.05.\n* >  We see that the data in the control group has a normal distribution.\n* >  Because 0.05 is not greater than p value.","d9eb3699":"# Conclusion","3f81e831":"# Visualization of Variables","288c1df6":"**Hypothesis Testing**\n\n*  **H0**: There is no statistically significant difference between Maximum Bidding and Average Bidding (**p-value < 0.05**)\n*  **H1**: There is a statistically significant difference between Maximum Bidding and Average Bidding (**not p-value < 0.05**)","8fc94e4c":"**Normality Assumption (Shapiro Test)**\n\n* >  **H0**: Normal distribution assumption is provided.(**p-value < 0.05**)\n* >  **H1**: Normal distribution assumption **not** provided. (**not p-value < 0.05**)\n","281d30db":"\n**1. Define the hypothesis of the A\/B test.**\n\nIs there any statistically significant difference between Maximum Bidding and Average Bidding ?\n>      **H0**: There is no statistically significant difference between Maximum Bidding and Average Bidding\n>      **H1**: There is a statistically significant difference between Maximum Bidding and Average Bidding\n\n**2. Statistically, the test results, it is statistically significant or not.**\n\nAfter calculating the normality and homogeneity of variance, I decided to perform the Parametric Independent Two-Sample T-Test. The pvalue is greater than 0.05 in the last test, I observed that there is no statistically significant difference between the purchases made with the Maximum Bidding and Average Bidding methods.\n\n**3. Which tests did you use? Specify your reasons.**\n\n- Independent Two-Sample T-Test\n>     - Parametric Comparison\n>     - Nonarametric Comparison\n- Two Sample Ratio Test\n- ANOVA (Mean Comparison of More than Two Groups)\n \nBased on the information above; Lastly, we could observed the results of the hypotheses regarding homogeneity of variance and normality assumptions. After that; the p value was greater than 0.05, h0 **could not be rejected** and an independent two-sample parametric t test was applied.\n\n\n**4. Based on your answer in question 2, what is your advice for customer?**\n\nConsidering the costs, they may abandon the relevant situation. As another suggestion,when the investment in development is taken into account, the outputs of the analysis can be checked by waiting for a certain period of time and thanks to the new data.    \n","a9c7e36c":"# A\/B Testing Methods\n-  **Independent Two-Sample T-Test** (Comparing Means of Two Group)\n\n>    - Parametric Comparison (if Normality Assumption and Variance Homogeneity Assumption are provided)\n>    - Nonarametric Comparison (if Normality Assumption or Variance Homogeneity Assumption are NOT provided)\n\n\n-  **Two Sample Ratio Test** (Comparing Ratio of Two Group)\n\n-  **Anova** (Mean Comparison of More than Two Groups)\n","9f303dd1":"* >  H0 hypothesis **could be rejected** because pvalue = 0.1083 > 0.05.\n* >  We see that the data in the test and control group have variances homogeneous.\n* >  Because 0.05 is not greater than p value.","70591fef":"> *  H0 hypothesis **could be rejected** because pvalue = 0.3493 > 0.05.\n> *  There is **no statistically significant difference** between Maximum Bidding and Average Bidding\n> *  Because 0.05 is not greater than p value.","bc942291":"* >  H0 hypothesis **could not be rejected** because pvalue = 0.1541 > 0.05.\n* >  We see that the data in the test group has a normal distribution.\n* >  Because 0.05 is not greater than p value.","4ef00e9b":"# **A\/B Testing with Python**","6f556996":"**Thank you for taking the time.**","4fff9df7":"# Parametric Independent Two-Sample T Test ()\n\nLastly, we could observed the results of the hypotheses regarding homogeneity of variance and normality assumptions. After that; the p value was greater than 0.05, h0 **could not be rejected** and an independent two-sample parametric t test was applied.","23a2b2bf":"# Business Problem\n\n*  ......... company recently made an offer called maximum bidding a new bid type, average bidding, as an alternative to the bidding type introduced. One of their customers, ....., is testing this new feature. Company decided to try and find that averagebidding is better than maximumbidding. Do an A\/B test to see if it converts too much wants.\n\n**Dataset Story**\n* In this dataset, which contains the website information of ........ ,information of user are number of ads they saw and clicked on, purchase frequency.\n* There are two separate data sets, the control and test groups.\n\n**Variables**\n* **Impression** \u2013 Ad views\n* **Click** \u2013 Clicks >> Indicates the number of clicks on the displayed ad.\n* **Purchase**  >> Indicates the number of products purchased after the ads clicked.\n* **Earning** \u2013 Earning  >> Earnings after purchased products\n","f3a21241":"A\/B testing (also known as bucket testing or split-run testing) is a user experience research methodology.A\/B tests consist of a randomized experiment with two variants, A and B. It includes application of statistical hypothesis testing or \"two-sample hypothesis testing\" as used in the field of statistics. A\/B testing is a way to compare two versions of a single variable, typically by testing a subject's response to variant A against variant B, and determining which of the two variants is more effective.\n\nThe purpose of A\/B testing is to enable you to make incremental improvements to your website or app. By comparing your existing website or app to one or more variations, you can continually iterate your design and validate it with real users.\nWith A\/B testing, each test generates new data about what works and what doesn't. Whenever something works, it can be incorporated into that website or app and now creates a new and improved design.\n\n\nIf there is a numerical or proportional difference between them, did this happen by chance or a significant difference? Based on this question; We have to decide which a\/b testing we should apply based on the circumstances.","c030bcaf":"# Hypothesis Testing\nHypothesis testing is a method used to determine the accuracy of a hypothesis within a statistical confidence interval.\n\nHypothesis tests are tests that determine whether the difference between a sample mean and the mean value thought to have been drawn from this sample is significant.\n\nIf the difference between the averages of the two populations is tested, it can be understood whether the difference is correct by performing hypothesis tests on the averages of the samples drawn from them.\n\ne.g; The colors of the buttons on the website have been changed. As a result of these changes, the click rate was calculated. Hypothesis testing; It allows us to calculate statistically whether there is a significant difference between these two ratios.","5be3cb63":"# What is A\/B Testing?","7c92f051":"# Assumption Control\n> 1. Normality Assumption\n> 2. Variance Homogeneity Assumption","fab8481c":"**Variance Homogeneity Assumption (Levene Test)**\n\n* >  **H0**: Variances are homogeneous. (**p-value < 0.05**)\n* >  **H1**: Variances are **not** homogeneous. (**not p-value < 0.05**)","0977ae57":"> # DON\u2019TS\n* When doing A\/B testing, never ever wait to test the variation until after you\u2019ve tested the control. \n* Don\u2019t conclude too early. There is a concept called \u201cstatistical confidence\u201d that determines whether your test results are significant (that is, whether you should take the results seriously)\n* Don\u2019t surprise regular visitors. If you are testing a core part of your website, include only new visitors in the test. You want to avoid shocking regular visitors, especially because the variations may not ultimately be implemented.\n* Don\u2019t let your gut feeling overrule test results.\n\n> # DO'S\n* Know how long to run a test before giving up. Giving up too early can cost you because you may have gotten meaningful results had you waited a little longer.\n* Show repeat visitors the same variations. Your tool should have a mechanism for remembering which variation a visitor has seen. \n* Make your A\/B test consistent across the whole website. \n* Do many A\/B tests. Let\u2019s face it: chances are, your first A\/B test will turn out a lemon. But don\u2019t despair. "}}