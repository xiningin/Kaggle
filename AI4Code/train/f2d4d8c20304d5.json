{"cell_type":{"98d4190f":"code","5a9fb28d":"code","baff9e7e":"code","31022034":"code","8814c98c":"code","6dba7990":"code","3c845b6d":"code","0f5386ff":"code","51cf9787":"code","7aa196cd":"code","05f8c4aa":"code","db2d18b7":"markdown","63296ad7":"markdown","45022ce3":"markdown","7842dfcb":"markdown","d95f888b":"markdown","ee46b8e7":"markdown","90a433dc":"markdown","1e2d365e":"markdown","11e91c6f":"markdown","ca6a73c0":"markdown","fb837bbc":"markdown","084f9a17":"markdown","aeb4a1d4":"markdown","7e78328a":"markdown"},"source":{"98d4190f":"import pandas as pd\nfrom pandas.plotting import register_matplotlib_converters\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport requests\nimport datetime\nimport ipywidgets as widgets\n\n#librerie per lo scatter plot animato\nfrom matplotlib.animation import FuncAnimation\nimport plotly           #(version 4.5.0)\nimport plotly.express as px\nimport plotly.io as pio","5a9fb28d":"header_len = 4 # numero di colonne nel file csv che contengono i dati sul paese (e non sul covid)\n\ncsv_name_confirmed = \"time_series_covid19_confirmed_global.csv\"\ncsv_name_deaths = \"time_series_covid19_deaths_global.csv\"\ncsv_name_recovered = \"time_series_covid19_recovered_global.csv\"\n\nlocal_storage_path = \"\/kaggle\/input\/time-series-covid19-updated\/\"\n\ndf_confirmed_biased = pd.read_csv(local_storage_path + csv_name_confirmed)\ndf_deaths_biased = pd.read_csv(local_storage_path + csv_name_deaths)\ndf_recovered_biased = pd.read_csv(local_storage_path + csv_name_recovered)\n    \ndf_confirmed_biased","baff9e7e":"def group_df(df):\n    n_rows = len(df)\n    n_cols = len(df.columns)\n    \n    # Creo un array di array, dove gli array interni corrispondono alle colonne del nuovo dataframe (cio\u00e8\n    # il dataframe che avr\u00e0 i dati aggregati)\n    # Questa lista verr\u00e0 utilizzata per realizzare il dizionario tramite il quale verr\u00e0 costruito il dataframe\n    list_of_column = []\n    for i in range(0, len(df.columns.values)):\n        list_of_column.append([])\n    \n    Country_region_previous = \"\"\n    \n    # leggo il dataframe riga per riga\n    for i in range(0, n_rows):\n\n        # Ottengo i dati sul paese puntato dalla riga attuale\n        Country_region = df.iat[i, 1]\n        \n        # Ho gi\u00e0 incontrato questo paese nella riga precedente\n        if Country_region == Country_region_previous:\n            \n            # Opera sulla stessa riga della precedente iterazione\n            # Non modifico la parte inerenti ai metadati poich\u00e9 \u00e8 la stessa della precedente iterazione\n            \n            # Sommo i dati della nuova riga a quelli della riga precedente per aggregarli\n            for j in range(header_len, n_cols):\n                list_of_column[j][-1] += df.iat[i, j]\n\n        # E' la prima volta che incontro questo paese\n        else:\n                \n            # Copio l'intera riga i\u00b0 del dataframe nella lista delle colonne\n            list_of_column[0].append(df.iat[i, 0])\n            list_of_column[1].append(Country_region)\n            list_of_column[2].append(df.iat[i, 2])\n            list_of_column[3].append(df.iat[i, 3])\n            \n            for j in range(header_len, n_cols):\n                list_of_column[j].append(df.iat[i, j])\n                    \n        Country_region_previous = Country_region\n\n    # costruisco il dataframe a partire dalla liste delle colonne\n    new_df = pd.DataFrame({ i : list_of_column[i] for i in range(0, len(list_of_column) ) })\n    new_df.columns = df.columns.values\n    \n    return new_df\n    \n            \ndf_confirmed_biased = group_df(df_confirmed_biased)\ndf_deaths_biased = group_df(df_deaths_biased)\ndf_recovered_biased = group_df(df_recovered_biased)\n\ndf_confirmed_biased","31022034":"def parse_date(str_date):\n    # Trasformo m\/d\/YY in un oggetto datetime con il formato YYYY-mm-gg\n    date_components = str_date.split(\"\/\")    \n    date_str = str(int(date_components[2]) + 2000)\n    string_to_parse = date_components[0] + \"\/\" + date_components[1] + \"\/\" + date_str\n    \n    return datetime.datetime.strptime(string_to_parse, '%m\/%d\/%Y')\n    \n    \ndef parse_df(df, value):\n    n_rows = len(df)\n    n_cols = len(df.columns)\n    \n    increment_value = \"New_\" + value\n    \n    # Ottengo la data (come datetime) da cui partono i dati del covid\n    # Per come \u00e8 realizzato il file csv, \u00e8 il nome della colonna (header_len+1)\u00b0\n    starting_date = parse_date(df.columns.values[header_len])\n    \n    # Dichiaro le liste che verranno riempite durante la lettura del dataframe\n    # Queste liste saranno usate come elementi del dizionario per la costruzione del nuovo dataframe\n    Date_list = []\n    Province_state_list = []\n    Country_region_list = []\n    Lat_list = []\n    Long_list = []\n    value_list = []\n    increment_value_list = []\n    \n    # Itero il dataframe iniziale riga per riga\n    for i in range(0, n_rows):\n        \n        Province_state = df.iat[i, 0] \n        Country_region = df.iat[i, 1]\n        Lat = df.iat[i, 2]\n        Long = df.iat[i, 3]\n\n        # Leggo la parte della riga che contiene i dati covid giorno per giorno\n        days_increment = 0\n        for j in range(header_len, n_cols):\n            Date_list.append(starting_date + datetime.timedelta(days=days_increment))\n            Province_state_list.append(Province_state)\n            Country_region_list.append(Country_region)\n            Lat_list.append(Lat)\n            Long_list.append(Long)\n            value_list.append(df.iat[i, j])\n            \n            # Calcolo l'incremento di \"value\" rispetto al giorno precedente\n            if j == header_len:\n                increment_value_list.append(0)\n            else:\n                if df.iat[i, j] > df.iat[i, j-1]:\n                    increment_value_list.append(df.iat[i, j] - df.iat[i, j-1])\n                else:\n                    increment_value_list.append(0)\n            \n            days_increment += 1\n    \n    # Costruisco il nuovo dataframe a partire dal dizionario realizzato sopra le liste precedentemente riempite        \n    new_df = pd.DataFrame({\"Date\":Date_list, \n                           \"Province\/State\":Province_state_list, \n                           \"Country\/Region\":Country_region_list,\n                           \"Lat\": Lat_list,\n                           \"Long\": Long_list,\n                           value: value_list,\n                           increment_value: increment_value_list\n                          })\n        \n    return new_df\n\ndf_confirmed = parse_df(df_confirmed_biased, \"Confirmed\")\ndf_deaths = parse_df(df_deaths_biased, \"Deaths\")\ndf_recovered = parse_df(df_recovered_biased, \"Recovered\")\n\ndf_confirmed","8814c98c":"# Faccio il merge in un nuovo dataframe\ndf_all = df_confirmed.copy()\ndf_all[\"Deaths\"] = df_deaths[\"Deaths\"]\ndf_all[\"New_Deaths\"] = df_deaths[\"New_Deaths\"]\ndf_all[\"Recovered\"] = df_recovered[\"Recovered\"]\ndf_all[\"New_Recovered\"] = df_recovered[\"New_Recovered\"]\n\n# Riorganizzo le colonne del dataframe\n# \"inplace = True\" = effettua la modifica sul posto, non ritornare un nuovo dataframe\ndf_all.drop(columns=['Province\/State'], inplace = True)\ndf_all.rename(columns={'Country\/Region': 'Country'}, inplace = True)\ndf_all = df_all[[\"Country\", \"Date\", \"Lat\", \"Long\", \n                 \"Confirmed\", \"Deaths\", \"Recovered\", \n                 \"New_Confirmed\", \"New_Deaths\", \"New_Recovered\"]]\ndf_all\n#df_all[(df_all[\"New_Confirmed\"] < 0) & (df_all[\"Country\"] == \"France\")]","6dba7990":"# la funzione che disegna il grafico per un singolo paese \ndef view_by_country(country):\n    \n    # Seleziono solo i records relativi al parametro paese\n    selected_country = df_all.loc[(df_all.Country == country)]\n    \n    # ordino i valori in base alla data\n    ordered_values = selected_country.sort_values(by=['Date']);\n\n    # La grandezza del grafico\n    fig, ax = plt.subplots(figsize = (16, 9)) \n    \n    # aggiungo titolo al grafico\n    ax.set_title('Evolution of cases in ' + country, loc ='left') \n\n    # aggiungo nome del nostro gruppo di lavoro \n    fig.text(0.9, 0.15, 'Fanta[stati]stici4 ', fontsize = 12, \n             color ='grey', ha ='right', va ='bottom', \n             alpha = 0.7)\n   \n    # visualizzo grafico\n    ax.plot(ordered_values[\"Date\"], ordered_values[\"New_Confirmed\"], label=\"New Confirmed\");\n    ax.plot(ordered_values[\"Date\"], ordered_values[\"New_Deaths\"], label=\"New Deaths\");\n    ax.plot(ordered_values[\"Date\"], ordered_values[\"New_Recovered\"], label=\"New Recovered\");\n    \n    # questa funzione fa vedere la legenda dei colori\n    ax.legend()\n        \n    # visualizzo il grafico \n    plt.show()\n    \n\n# richiamo la funzione per la visualizzazione del grafico. I paramteri sono: \n# il paese\nview_by_country(\"Italy\")","3c845b6d":"# funzione che rappresenta l'andamento globale delle nuove morti\ndef global_new_deaths(start_date, end_date):\n    \n    # creo una maschera per selezionare i valori entro le date passate come parametro, se presenti\n    apply_mask = 0\n    if ((start_date != None) & (end_date != None)):\n        mask = (df_all[\"Date\"] >= start_date) & (df_all[\"Date\"] <= end_date)\n        apply_mask = 1\n    elif (start_date != None):\n        mask = (df_all[\"Date\"] >= start_date)\n        apply_mask = 1\n    elif (end_date != None):\n        mask = (df_all[\"Date\"] <= end_date)\n        apply_mask = 1\n        \n    # riduco il DataFrame all'intervallo compreso tra le due date, se presenti\n    if (apply_mask == 1):\n        df_reduced = df_all.loc[mask]\n    else:\n        df_reduced = df_all\n    \n    # creo due nuove liste con i valori da plottare\n    n_rows = len(df_reduced)\n    daily_global_death = []\n    date = []\n    \n    for i in range(0, n_rows):\n        # se la data di riferimento non \u00e8 presente nella lista\n        # la aggiungo e aggiungo anche il corrispondente valore di nuove morti\n        if df_reduced[\"Date\"].iloc[i] not in date:\n            date.append(df_reduced[\"Date\"].iloc[i])\n            daily_global_death.append(df_reduced[\"New_Deaths\"].iloc[i])\n        # se la data \u00e8 gi\u00e0 presente nella lista\n        # incremento il corrispondente valore di nuove morti globali per quella data\n        else:\n            index = date.index(df_reduced[\"Date\"].iloc[i])\n            daily_global_death[index] = daily_global_death[index] + df_reduced[\"New_Deaths\"].iloc[i]\n            \n    # creo il nuovo DataFrame a partire dalle precedenti liste\n    new_deaths = pd.DataFrame({\n        \"Date\":date,\n        \"New_global_deaths\":daily_global_death  \n    })\n    new_deaths.columns = new_deaths.columns.values\n    \n    # La grandezza del grafico\n    fig, ax = plt.subplots(figsize = (16, 9)) \n    \n    # aggiungo titolo al grafico\n    if ((start_date != None) & (end_date != None)):\n        ax.set_title('Global new deaths from ' + start_date + ' to ' + end_date, loc ='left')\n    elif (start_date != None):\n        ax.set_title('Global new deaths from ' + start_date + ' to now', loc ='left')\n    elif (end_date != None):\n        ax.set_title('Global new deaths from the beginning to ' + end_date, loc ='left')\n    else:\n        ax.set_title('Global new deaths from the beginning to now', loc ='left')\n\n    \n    # aggiungo nome del nostro gruppo di lavoro \n    fig.text(0.9, 0.15, 'Fanta[stati]stici4 ', fontsize = 12, \n             color ='grey', ha ='right', va ='bottom', \n             alpha = 0.7)\n   \n    # visualizzo grafico\n    ax.plot(new_deaths[\"Date\"], new_deaths[\"New_global_deaths\"], label=\"New Deaths\");\n        \n    # visualizzo il grafico \n    plt.show()\n\n# richiamo la funzione per la visualizzazione del grafico. I paramteri sono: \n# la data di inizio del periodo di interesse\n# la data di fine del periodo di interesse\n# se lasciati a 'None' viene considerato come periodo di interesse l'intero intervallo coperto dai dati in nostro possesso\nglobal_new_deaths(None, None)\n#global_new_deaths('2020-07-10', '2020-12-15')\n#global_new_deaths('2020-07-10', None)\n#global_new_deaths(None, '2020-12-15')","0f5386ff":"#Chiama la funzione per generare lo scatter plot per ogni osservabile\ndef global_scatter(date, obs):\n\n    colours = [\"yellow\", \"orange\", \"red\"]\n    for i in range (0, len(obs)):\n        #sanity check per vedere se il nome della colonna \u00e8 corretto\n        if obs[i] not in df_all:\n            print(\"La colonna %s non \u00e8 non presente nel dataframe, verificare che sia stata scritta correttamente\\n\" % obs[i])\n        else:\n            #filtra le righe in base alla data\n            df_daily = df_all.loc[df_all[\"Date\"] == date] \n            \n            #imposta il titolo per il grafico\n            title = \"Situazione globale \\n\" + obs[i] + \" alla data \" + date.strftime('%d\/%m\/%Y')\n            draw_scatter_plot(df_daily, obs[i], True, title, colours[i])\n    \n\n#Genera uno scatter plot della situazione globale in una specifica data e per una specifica osservabile\ndef draw_scatter_plot(dataframe, obs, labels, title, colour):\n    \n    #imposta la taglia della figure e i limiti sugli assi\n    plt.figure(figsize=(16,9))\n    plt.xlim(-180, 180)\n    plt.ylim(-90, 90)\n    \n    #imposta titolo e label per gli assi cartesiani\n    plt.title(title)\n    plt.xlabel(\"Longitude\")\n    plt.ylabel(\"Latitude\")\n    \n    #prende i dati di latitudine e longitudine\n    x_axis = dataframe[\"Long\"]\n    y_axis = dataframe[\"Lat\"]\n    scale = 40\n    \n    if scale > 0:\n        size = dataframe[obs]\/scale #le dimensioni delle sfere sono date dall'osservabile presa in analisi\n        \n    plt.scatter(x_axis, y_axis, size, c=colour) #genera lo scatterplot\n    \n    if labels: #labels \u00e8 un booleano che indica se inserire o meno le label nello scatterplot\n        labels = [\"Italy\", \"Brazil\", \"Germany\", \"Canada\", \"US\", \"India\", \"China\"] #labels usate sui punti\n        coord = [] #matiene le coordinate per le labels\n        \n        #aggiunge le label al grafico\n        for label in labels:\n            coord = get_lat_long(label)\n            plt.annotate(label, coord)\n    \n    plt.show()\n    return 1\n\ndef animated_scatter_plot(df, year, obs):\n    \n    dataframe = df.copy()\n    \n    # Aggiungo una nuova colonna da utilizzare per l'operazione di group by\n    dataframe['YearMonth'] = dataframe[\"Date\"].dt.strftime('%m-%Y')\n    \n    # Evito che l'osservabile assuma valori negativi\n    for i in range(0, len(dataframe)):\n        if dataframe.iloc[i][obs] < 0:\n            dataframe.iloc[i, dataframe.columns.get_loc(obs)] = 0\n    \n    # Filtro per tutti i mesi dell'anno specificato\n    dataframe = dataframe.loc[dataframe[\"Date\"].dt.year == year]\n\n    dataframe = dataframe.groupby(['Country','YearMonth'])[obs].sum().reset_index(name=obs) \n    \n    fig = px.scatter_geo(dataframe, locationmode = 'country names', locations=\"Country\",\n                         hover_name=obs, size=obs,\n                         animation_frame=\"YearMonth\", projection=\"natural earth\")\n    fig.show()\n    \n\n#Restituisce la latitudine e la longitudine di una nazione, usate per mettere le label al grafico\ndef get_lat_long(country):\n    row = df_all.loc[df_all[\"Country\"] == country]\n    return (row.iloc[0][\"Long\"], row.iloc[0][\"Lat\"])","51cf9787":"#Calcola la media mobile a days_range giorni per una specifica country, data una specifica osservabile\ndef moving_avg(country, days_range, obs):\n    mov_avgs = []\n    valid_days = [7, 14, 21, 28]\n    #sanity check per verificare che l'osservabie corrisponda ad una colonna del dataframe\n    if not obs in df_all:\n        print(\"Colonna non presente nel dataframe non presente: verificare che sia stata scritta correttamente\\n\")\n        return mov_avgs\n    if days_range not in valid_days:\n        print(\"Non \u00e8 possibile calcolare la media mobile a %d giorni, insierire un valore fra quelli seguenti: %s\" % (days_range, str(valid_days)))\n        return mov_avgs\n    mov_avg = []\n    j = 0\n    \n    df = df_all.loc[df_all[\"Country\"] == country] #seleziona solo le righe della specifica country\n    \n    for i in range(0, days_range): #costruisco la prima media mobile a \"days_range\" giorni\n        mov_avg.append(df.iloc[i][obs])\n        j = (j+1)%(days_range)\n        \n    #calcola la media col metodo mean della libreria statistics, in quanto mov_avg \u00e8 un array\n    #e non pi\u00f9 un dataframe    \n    mov_avgs.append(np.mean(np.array(mov_avg)))\n    \n    for i in range(days_range, len(df)): #scorre le restanti date e computa le varie medie mobili\n        mov_avg[j] = df.iloc[i][obs]\n        mov_avgs.append(np.mean(np.array(mov_avg)))\n        j = (j+1)%(days_range) #scala l'indice del valore pi\u00f9 vecchio nel vettore mov_avg\n    return mov_avgs\n\n#Plotta la media mobile a x giorni per una specifica osservabile\n#Prende come parametri la nazione, il vettore che contiene i giorni su cui calcolare la media mobile\n#e l'osservabile per cui calcolare la media\ndef plot_mov_avg(country, days_arr, obs):\n    for days in days_arr:\n        avg = moving_avg(country, days, obs) #calcola le medie mobili\n        if len(avg) == 0:\n            return -1\n    \n        plt.figure(figsize=(16, 9))\n        x = range(len(avg)) #imposta come valori dell'asse x il numero di medie mobili calcolate prima\n    \n        title = \"Media mobile a \" + str(days) + \" giorni per la nazione \"+country+\"\\n\"+\"Osservabile: \"+obs\n        plt.title(title)\n        plt.xlabel(\"N\u00b0 di media mobile\")\n        plt.ylabel(\"Valore media mobile\")\n        \n        plt.plot(x, avg)\n    plt.show()","7aa196cd":"#Chiamata di funzioni\nanimated_scatter_plot(df_all, 2020, \"New_Deaths\")\n\ndate = datetime.datetime(2020, 6, 22) #data passata come input alla funzione, convertita in datetime\nglobal_scatter(date, [\"New_Confirmed\", \"New_Recovered\", \"New_Deaths\"])\n\nplot_mov_avg(\"Italy\", [7,14,21], \"New_Confirmed\")","05f8c4aa":"country_to_show = 10\norderby_maximum = True\n\n# definisco a widget DatePicker per selezionare la data\ndp = widgets.DatePicker(\n    description='Pick a Date',\n    disabled=False\n)\ndisplay(dp)\n\ndef on_value_change(change):\n    new_date = pd.to_datetime(change['new'])\n    global_bars_hor(df_all, new_date, country_to_show, orderby_maximum)\n\n#callback del widget per prendere valore data nuovo\ndp.observe(on_value_change, names='value')\n\n# la funzione che disegna il grafico a barre orizzontale \ndef global_bars_hor(datafr, date, country_numbers, orderby_maximum):\n    # Seleziono solo i records relativi al parametro data ed escludo i paesi che hanno tutti i valori nulli\n    all_countries = datafr.loc[(datafr.Date == date) & ((datafr.New_Confirmed > 0) | (datafr.New_Deaths > 0) | (datafr.New_Recovered > 0))]\n    \n    # ordino i dati in base di valori massimi\n    if orderby_maximum == True:\n        ordered_countries = all_countries.sort_values(by=['New_Confirmed', 'New_Deaths', 'New_Recovered'], ascending=False);\n    else:\n        ordered_countries = all_countries.sort_values(by=['Country']);\n    \n    #seleziono solo n numero di paesi\n    selected_countries = ordered_countries.head(n=country_numbers)\n    \n    # La grandezza del grafico\n    # l'altezza del grafico aumenta al base del numero dei paesi\n    fig = plt.figure(figsize = (16, country_numbers))\n\n    # aggiungo nuovo grafico\n    ax = fig.add_subplot()\n\n    # Rimuovo la cornice del grafico\n    for s in ['top', 'bottom', 'left', 'right']: \n        ax.spines[s].set_visible(False) \n\n    # Rimuovo x, y Ticks (sono delle piccole barrette sugli assi)\n    ax.xaxis.set_ticks_position('none') \n    ax.yaxis.set_ticks_position('none') \n\n    # aggiungo spazio tra assi e labels\n    ax.xaxis.set_tick_params(pad = 5) \n    ax.yaxis.set_tick_params(pad = 10) \n\n    # aggiungo griglia\n    ax.grid(b = True, color ='grey', \n            linestyle ='-.', linewidth = 0.5, \n            alpha = 0.2) \n\n    # Se giro il grafico i valori si invertono, allora li reinverto, per avere sopra la barra giusta (confirmed) \n    ax.invert_yaxis() \n\n    # aggiungo titolo al grafico\n    ax.set_title('Situazione globale pandemica in data di ' + date.strftime('%d\/%m\/%Y'), loc ='left') \n    \n    # aggiungo nome del nostro gruppo di lavoro \n    fig.text(0.9, 0.3, 'Fanta[stati]stici4', fontsize = 12, \n             color ='grey', ha ='right', va ='bottom', \n             alpha = 0.7)\n\n    # richiamo la funzione per disegnare le barre\n    subBarY(ax, selected_countries[\"Country\"], \n            [selected_countries[\"New_Confirmed\"],selected_countries[\"New_Deaths\"],selected_countries[\"New_Recovered\"]], \n            [\"Nuovi confermati\", \"Nuovi morti\", \"Nuovi ricoverati\"])\n    \n    # questa funzione fa vedere la legenda dei colori\n    ax.legend()\n\n    # Aggiungo le notazioni con valori ad ogni barra \n    for i in ax.patches: \n        plt.text(i.get_width()+0.5, i.get_y()+0.2,  \n                 str(round((i.get_width()), 2)), \n                 fontsize = 10, \n                 color ='grey') \n    \n    # Visualizzo il grafico   \n    plt.show()\n    \n# funzione per disegnare multibarre, per farlo si deve calcolare la coordinata Y per ogni barra\ndef subBarY(ax, Y, vals, labels, height=0.8):\n    # la lunghezza del set dei dati\n    n = len(vals)\n\n    # la coordinata Y iniziale\n    _Y = np.arange(len(Y))\n    \n    # faccio il ciclo per ogni valore per disegnare le barre\n    for i in range(n):\n        ax.barh(_Y - height\/2. + i\/float(n)*height, vals[i], \n                height=height\/float(n), align=\"edge\", label=labels[i])\n         \n    # assegno asse verticale\n    plt.yticks(_Y, Y)\n\n    \n# richiamo la funzione per la visualizzazione del grafico. I parametri sono:\n# il dataframe da utilizzare\n# la data \n# il numero dei paesi da visualizzare (visto che i paesi sono 191, visualizzarli tutti puo' sembrare un po' affollato)\n# se visualizzare i dati ordinati dai valori massimi o ordinati per paese (True - massimi, False - paese)\ndate = datetime.datetime(2020, 6, 22)\nglobal_bars_hor(df_all, date, country_to_show, orderby_maximum)","db2d18b7":"<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione parse_date<\/h4><\/b> <br>\n<b>Input<\/b>: data nel formato di stringa m\/d\/YY<br>\n<b>Output<\/b>: oggetto di tipo datetime che rappresenta la data in input\n<\/div>\n<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione parse_df<\/h4><\/b> <br>\n<b>Input<\/b>: dataframe realizzato in accordo alla struttura dei file csv offerti dalla John Hopkins University<br>\n<b>Output<\/b>: lo stesso dataframe dove i dati in merito al covid vengono organizzati per righe. <br>\nPer ogni riga del dataframe di input, si ripetono sulle righe del dataframe di output i dati in merito al paese (Province\/State, Country\/Region, Lat, Long) un numero di volte pari al numero di \"colonne giorni\" del dataset di input riportando, per ciascuna riga, il valore sottostante alla \"colonna giorni\" e la data stessa (che non \u00e8 altro che il nome della colonna)\n<\/div>","63296ad7":"<center><h1>COVID-3<\/h1><\/center>\n\n# Gruppo di lavoro\n\n> ### Nome del gruppo: \n>- Fanta-stati-stici4\n>\n>### Partecipanti\n>\n>- Alessandro Fato\n>- Gian Marco Falcone\n>- Pierciro Caliandro\n>- Polina Kalashnikova\n\n# Scopo del progetto\n\n>Il progetto ha l'obiettivo di analizzare, in funzione delle specifiche richieste, i dati in merito al covid riguardanti, a livello globale: casi confermati, numero di morti e ricoverati. Ci\u00f2 che viene richiesto \u00e8 di:<br>\n><ul>\n    <li>Graficare l\u2019andamento dei nuovi morti, nuovi confermati e nuovi ricoverati di un singolo paese dato<\/li>\n    <li>Graficare l\u2019andamento globale dei nuovi morti in un intervallo di date<\/li>\n    <li>Costruire uno scatter plot della situazione mondiale ad una data assegnata<\/li>\n    <li>Costruire e graficare le medie mobili a 7, 14, 21 e 28 giorni<\/li>\n    <li>Graficare a barre per tutti i paesi i dati dei nuovi morti, nuovi confermati e nuovi ricoverati di una data assegnata<\/li>\n<\/ul> \n\n\n# Dati\n\n><div>\nI dati analizzati sono raccolti dalla seguente <a href=\"https:\/\/github.com\/CSSEGISandData\/COVID-19\/tree\/master\/csse_covid_19_data\/csse_covid_19_time_series\">repository di github<\/a> del Center for Systems Science and Engineering della Johns Hopkins University. <br>\nIn particolare, siamo interessati ai file csv contenenti i dati globali in merito ai confermati, morti e ricoverati dovuti al Covid-19. I file sono organizzati per nazione e divisi per giorno, e sono rispettivamente:<br><br>\n<span style=\"margin-left:2em\">- time_series_covid19_confirmed_global.csv<\/span><br>\n<span style=\"margin-left:2em\">- time_series_covid19_deaths_global.csv<\/span><br>\n<span style=\"margin-left:2em\">- time_series_covid19_recovered_global.csv<\/span><br><br>\nQuesti sono dati di natura incrementale; ad esempio, i confermati in una data non corrispondono a quante persone sono realmente ammalate di Covid nella data specifica (quindi le infezioni in corso), bens\u00ec alla somma di tutte le persone che sono state confermate positive sin dall'inizio del Covid (chiamati anche contagiati totali). E' possibile fare un'analisi pi\u00f9 approfondita in merito al significato dei casi confermati poich\u00e8, per ciascuna nazione, questi dati possono assumere un senso leggermenti diverso a seconda della data. Per fare alcuni esempi:<br><br>\n    <div style=\"margin-left:2em\">- Dal 4 all'11 Aprile, in merito alla Francia, la Johns Hopkins University prende solo il valore 'casi confermati' dal database di terze parti che utilizza per riempire le colonne del csv; dal 12 Aprile in poi utilizza sia 'casi confermati' che 'casi probabili dell'ESMS'<\/div><br>\n    <div style=\"margin-left:2em\">- In Lituania, prima del 28 Aprile, i casi confermati corrispondono al numero di test positivi e non al numero di individui che sono stati confermati positivi almeno una volta<\/div><br>\n    Continuando a leggere il seguente <a href=\"https:\/\/github.com\/CSSEGISandData\/COVID-19\/blob\/master\/csse_covid_19_data\/README.md\">readme<\/a> potremmo sicuramente trovare altre situazioni analoghe. In aggiunta possiamo leggere, in merito ai casi confermati e alle morti, che: \"Counts include confirmed and probable (where reported)\" e, in merito ai ricoverati: \"Recovered cases are estimates based on local media reports, and state and local reporting when available, and therefore may be substantially lower than the true number[...]\".<br>\n    Con questi esempi si vuole mettere alla luce quanto il reale significato di questi dati non sia cos\u00ec banale, ed andrebbe esaminato nazione per nazione e per intervalli di date. Per ovvie ragioni di semplicit\u00e0, analizzeremo questi dati nella loro accezione pi\u00f9 semplice, cos\u00ec come indicato dalla Johns Hopkins University stessa:<br><br>\n    <span style=\"margin-left:2em\">\"[...]<\/span><br>\n<span style=\"margin-left:2em\"><b>Confirmed<\/b> - Aggregated case count for the state.<\/span><br>\n<span style=\"margin-left:2em\"><b>Deaths<\/b> - Aggregated death toll for the state.<\/span><br>\n<span style=\"margin-left:2em\"><b>Recovered<\/b> - Aggregated Recovered case count for the state.[...]\"<\/span><br><br>\nLe nazioni risultano organizzate per provincie secondo le colonne <b>Country\/Region<\/b> e <b>Province\/State<\/b>. Ad esempio, possiamo notare come la Francia compare 11 volte nella colonna <b>Country\/Region<\/b>, ogni volta con un valore di <b>Province\/State<\/b> diverso. L'analisi dei dati che seguir\u00e0 non tiene conto della suddivisione in provincie, bens\u00ec queste vengono eliminate e considerati i dati cumulativi per ogni <b>Country\/Region<\/b>. Di conseguenza, si conteranno un totale di 191 nazioni.<br><br>\nOgni coppia <b>Country\/Region<\/b>-<b>Province\/State<\/b> compare una volta per riga. I dati covid di tale coppia sono presenti sulla stessa riga e su colonne diverse, dove ogni colonna rappresenta un giorno a partire dal 22 Gennaio 2020 fino alla data attuale. Non viene mantenuto questo formato di rappresentazione dei dati per la successiva analisi, bens\u00ec vengono portate, per ogni nazione, le date sulle righe con i corrispettivi dati giornalieri. <br><br>\nPer una corretta analisi dei dati, \u00e8 inoltre fondamentale tenere conto delle imprecisioni contenute nel dataset di terze parti che si vuole utilizzare. Si pu\u00f2 notare come il csv dei ricoverati ha 15 righe in meno degli altri due (257 invece di 272). Questo \u00e8 giusitificato dal fatto che il Canada non \u00e8 organizzato in provincie nel csv pi\u00f9 piccolo. <br>\nInoltre, pu\u00f2 capitare che i dati, i quali sono di natura incrementale, abbiano una ricaduta verso il basso. Ad esempio, si possono considerare le date 2 e 3 Giugno 2020 riferite ai casi confermati della Francia, i quali sono 187265 nel primo giorno e 184015 nel successivo. Situazioni del genere accadono in pi\u00f9 nazioni ed in pi\u00f9 date diverse, anche in merito ai dati dei morti e dei ricoverati. Spesso sono dovute a ricalcoli effettuati dalla nazione stessa oppure da una nuova politica di raccolta dati applicati dall'ente che colleziona le statistiche della nazione in esame. In ogni caso, tali situazioni sono state giustificate dalla Johns Hopkins nel <a href=\"https:\/\/github.com\/CSSEGISandData\/COVID-19\/blob\/master\/csse_covid_19_data\/README.md\">readme<\/a> della repository. Infatti, in quel file possiamo leggere \"France | Reduction in confirmed cases due to a change in calculation method. Since June 2, patients who test positive are only counted once [...]\". Questo comporta che, nei grafici in cui si analizza l'andamento dei nuovi confermati (o morti o ricoverati) la curva possa toccare valori negativi.    \n<\/div>","45022ce3":"<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione plot_mov_avg<\/h4><\/b> <br>\n<b>Input<\/b>: \n    <ul>\n        <li>stringa che rappresenta la nazione per cui si vuole calcolare la media<\/li>\n        <li>vettore che contiene gli intervalli per cui calcolare la media (es: [7, 14, 21, 28])<\/li>\n        <li>stringa che rappresenta l'osservabile per cui si vuole calcolare e graficare la media mobile<\/li>\n    <\/ul>\n<br>\n<b>Output<\/b>: All'interno della funzione avviene, per ogni intervallo di giorni, \nla chiamata alla funzione <b><i>moving_avg<\/i><\/b>, che calcola la media mobile. Fatto questo, viene generato\nil corrispondente grafico\n<\/div>\n\n<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione moving_avg<\/h4><\/b> <br>\n<b>Input<\/b>: \n    <ul>\n        <li> stringa che rappresenta la nazione per cui si vuole calcolare la media<\/li>\n        <li>intero corrispondente al range di giorni per cui calcolare la media (es: 7, 14, ...)<\/li>\n        <li>stringa che rappresenta l'osservabile per cui calcolare la media mobile<\/li>\n    <\/ul>\n<br>\n<b>Output<\/b>: Un array che contiene tutte le medie mobili calcolate a partire dal primo gruppo di giorni fino \nall'ultimo\n<\/div>","7842dfcb":"## Media mobile a 7, 14, 21, 28 giorni\n>#### Viene calcolata la media mobile ad x giorni (dove x \u00e8 un parametro che pu\u00f2 essere 7, 14, 21 o 28), relativa ad una delle osservabili sui nuovi confermati, nuovi ricoveri e nuovi decessi e filtrate in base ad una specifica nazione.<br>I valori calcolati per le medie mobili vengono poi graficati","d95f888b":"## Grafico dell'andamento di New Confirmed, New Deaths, New Recovered di un singolo paese","ee46b8e7":"# Organizzazione lavoro di gruppo\n\n>Il lavoro \u00e8 stato svolto sfruttando le potenziali\u00e0 del Jupyter Notebook.<br>\nJupyter Notebook \u00e8 un\u2019applicazione web open source che consente di includere testo, video, audio e immagini e offre la possibilit\u00e0 di eseguire codice in diversi linguaggi di programmazione.<br>\nDi default, fornisce il kernel Python incluso. Tuttavia, supporta altri kernel come Julia, R, Haskell, ecc.<br>\nLa sua architettura \u00e8 il principale vantaggio di questa applicazione: ci consente di ospitare l\u2019intera installazione di kernel, librerie e strumenti necessari in un server. Questo pu\u00f2 anche essere integrato con docker, impedendo cos\u00ec, per esempio, che ogni membro del gruppo debba configurare l'ambiente di lavoro localmente nel proprio computer. In questo modo, ci si potrebbe collegare direttamente dal proprio computer all\u2019ambiente server tramite browser, disponendo gi\u00e0 di tutte le configurazioni di base necessarie per lavorare.<br>\nNoi, purtroppo, essendo semplici studenti, non abbiamo modo di installare un nostro server Jupiter. Quindi, per organizzare il lavoro del nostro gruppo, abbiamo scelto degli strumenti gratuiti: Github, Teams, Whatsapp, JupiterLab, Kaggle. In particolare, Kaggle \u00e8 una buona soluzione per lavorare su un software equivalente a JupiterLab ma con i vantaggi di: essere online e permettere la modifica dello stesso file da pi\u00f9 utenti, permettere una buona orchestrazione del lavoro di gruppo con la possibili\u00e0 di gestire i commit con numeri di versione, avere l'ambiente di sviluppo python installato su container nel cloud, avere il file sempre disponibile alla lettura sotto il nome di url. Inizialmente, abbiamo lavorato con JupiterLab e usato Github per produrre il file .ipynb. Purtroppo, lavorare sullo stesso file comporta un numero non banale di operazioni di risoluzione dei conflitti nei commit e, inoltre, il file .ipynb contiene una serie di metadati locali alla macchina che lo esegue, ragione per cui risulta ancora pi\u00f9 complicata la condivisione di questo.<br>\nTeams \u00e8 stato usato per le riunioni pi\u00f9 lunghe mentre Whatsapp per i messaggi brevi di tutti i giorni.\n<br>Il lavoro \u00e8 stato organizzato in diverse fasi. Inizialmente, abbiamo analizzato la traccia e suddiviso i compiti da svolgere tra i 4 componenti. Successivamente, il lavoro \u00e8 stato per lo pi\u00f9 indipendente. Vi sono state comunque molte occasioni di discussioni (utilizzando i mezzi di sopra mostrati) per chiarire dubbi sulla traccia o sul codice e per proporre idee. Una volta terminate le parti individuali, sono seguite delle riunioni su Teams per proporre il proprio codice agli altri membri del gruppo e, eventualmente, migliorarlo.","90a433dc":"## Grafico dell\u2019andamento globale di New Deaths in un intervallo di date","1e2d365e":"## Grafico a barre per tutti i paesi in una certa data\n<div class=\"alert alert-block alert-info\">\n<b>Richiesta:<\/b> creare un grafico a barre per tutti i paesi di una data assegnata. <br>\n<b>Funzione:<\/b> global_bars_hor <br>\n <b>Parametri:<\/b><br>\n datafr - il dataframe da utilizzare <br>\n date - data <br>\n country_numbers - numero dei paesi da visualizzare <br>\n orderby_maximum - ordinamento dei valori<\/div>","11e91c6f":"<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione group_df<\/h4><\/b> <br>\n<b>Input<\/b>: dataframe realizzato in accordo alla struttura dei file csv offerti dalla John Hopkins University<br>\n<b>Output<\/b>: lo stesso dataframe raggruppato per la colonna <b>Country\/Region<\/b>. I dati in merito al covid vengono aggregati tramite la somma\n<\/div>","ca6a73c0":"## Scatter plot per la situazione globale\n>#### Gli scatter plot che abbaimo generato, usano come valori per l'asse x ed y rispettivamente latitudine e longitudine delle nazioni presenti nel dataset.<br>Nel grafico, si mostra l'andamento globale per una delle colonne relative ai nuovi confermati, nuovi ricoveri e nuovi decessi, i cui dati vengono filtrati in base ad una specifica data.","fb837bbc":"<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione global_new_deaths<\/h4><\/b> <br>\n<b>Input<\/b>: \n    <ul>\n        <li>data corrispondente all'inzio del periodo di interesse ('None' se si vuole partire dalla prima data presente nel dataset)<\/li>\n        <li>data corrispondente alla fine del periodo di interesse ('None' se si vuole terminare alla prima data presente nel dataset)<\/li>\n    <\/ul>\n<br>\n<b>Output<\/b>: il grafico rappresentante le nuove morti globali giornaliere nel periodo di interesse\n<\/div>","084f9a17":"<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione global_scatter<\/h4><\/b> <br>\n<b>Input<\/b>: \n    <ul>\n        <li>data nel formato di stringa m\/d\/YY<\/li>\n        <li>una lista di osservabili per cui generare lo scatter plot<\/li>\n    <\/ul>\n<br>\n<b>Output<\/b>: All'interno della funzione avviene, per ogni osservabile, la chiamata alla funzione <b><i>draw_scatter_plot<\/i><\/b>, che genera lo scatter plot\n<\/div>\n\n<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione draw_scatter_plot<\/h4><\/b> <br>\n<b>Input<\/b>: \n    <ul>\n        <li> dataframe che contiene i valori filtrati per una specifica data<\/li>\n        <li>stringa che corrisponde all'osservabile per cui fare lo scatter plot<\/li>\n        <li>booleano, che indica se inserire o meno le label relative ad alcune nazioni<\/li>\n        <li>stringa per il titolo dello scatter plot<\/li>\n        <li>stringa per il colore delle bolle del grafico<\/li>\n    <\/ul>\n<br>\n<b>Output<\/b>: Scatter plot, realizzato usando come valori sull'asse x ed y rispettivamente longitudine e latitudine delle nazioni\n<\/div>","aeb4a1d4":"<div class=\"alert alert-block alert-info\">\n<b><h4>Funzione view_by_country<\/h4><\/b> <br>\n<b>Input<\/b>: \n    <ul>\n        <li>stringa che corrisponde al nome della nazione ceh si vuole graficare<\/li>\n    <\/ul>\n<br>\n<b>Output<\/b>: il grafico rappresentante i nuovi confermati, le nuove morti e i nuovi ricoverati giornalieri per il paese dato\n<\/div>","7e78328a":"# Codice"}}