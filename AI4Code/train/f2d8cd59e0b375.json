{"cell_type":{"805e3fa9":"code","c50bbff0":"code","a54c0c67":"code","86b04ce3":"code","02d40191":"code","bbb26e18":"code","139e7f6b":"code","d047dc75":"code","665080dd":"code","6315763a":"code","25598cde":"code","1010076a":"code","7c336c61":"code","8120ce1e":"code","8d6ad2ae":"code","9e03d3d1":"code","0a0dfbe3":"code","8bef41b5":"code","9e9932f5":"code","9968dfb6":"code","9710ec35":"code","617e5585":"markdown","10933ff7":"markdown"},"source":{"805e3fa9":"import os\nimport json\nfrom operator import itemgetter\nfrom collections import defaultdict\nfrom functools import partial\nfrom math import isnan\n\nimport cv2\nimport dill\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import LabelEncoder","c50bbff0":"# https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction\/discussion\/76106\n\nos.mkdir(\".\/working\")\nos.environ['USER'] = 'root'\nos.system('pip install ..\/input\/xlearn\/xlearn\/xlearn-0.40a1\/')\n\nimport xlearn as xl\n","a54c0c67":"train_df = pd.read_csv(\"..\/input\/petfinder-adoption-prediction\/train\/train.csv\", encoding=\"utf-8\")\ntest_df = pd.read_csv(\"..\/input\/petfinder-adoption-prediction\/test\/test.csv\", encoding=\"utf-8\")\n\nsmpsb_df = pd.read_csv(\"..\/input\/petfinder-adoption-prediction\/test\/sample_submission.csv\")","86b04ce3":"train_df[\"group\"] = 0\npetid_map = {v: i for i, v in enumerate(pd.concat([train_df[\"PetID\"], test_df[\"PetID\"]]))}\nrescuerid_encoder = LabelEncoder().fit(pd.concat([train_df[\"RescuerID\"], test_df[\"RescuerID\"]]))\n\nfor group, (_, group_idx) in enumerate(GroupKFold(n_splits=10).split(train_df,\n                                                                     train_df[\"AdoptionSpeed\"],\n                                                                     rescuerid_encoder.transform(train_df[\"RescuerID\"]))):\n    train_df.loc[group_idx, \"group\"] = group","02d40191":"train_df.pivot_table(columns=\"AdoptionSpeed\",\n                     index=\"group\",\n                     values=\"Breed1\",\n                     aggfunc=\"count\")","bbb26e18":"class FFMformatter():\n    def __init__(self,\n                 numerical_field_max: int,\n                 key_column=\"PetID\"\n                 ):\n        \n        self.numerical_field_max = numerical_field_max\n        self.key_column = key_column\n\n        self.numerical_field_last = -1\n        self.numerical_field = defaultdict(lambda: self.new_numerical_field())\n        self.field_nan = defaultdict(lambda: np.NaN)\n        \n        self.categorical_field_last = numerical_field_max\n        self.categorical_feature_last = numerical_field_max\n        self.categorical_field = defaultdict(lambda: self.new_categorical_field())\n        self.categorical_feature = defaultdict(lambda: defaultdict(lambda: self.new_categorical_feature()))\n        self.result = {}\n        self.categorical_columns = set()\n\n\n    def add_dataframe(self, df: pd.DataFrame):\n        petids = df[self.key_column]\n        for field in df.columns:\n            if field == self.key_column:\n                continue\n            for petid, value in zip(petids, df[field]):\n                if self.field_nan[field] == value or ((type(value) == float) and isnan(value)):\n                    continue\n\n                if field in self.categorical_columns:\n                    field_id = self.categorical_field[field]\n                    self.result[petid] += \" {}:{}:1\".format(field_id,\n                                                            self.categorical_feature[field_id][value])\n                \n                else:\n                    field_id = self.numerical_field[field]\n                    self.result[petid] += \" {}:{}:{}\".format(field_id,\n                                                             field_id,\n                                                             value)\n\n    def add_field_dataframe(self, df, field_col, value_col):\n        field_id = self.categorical_field[field_col]\n        for _, row in tqdm(df.iterrows()):\n            petid = row[self.key_column]\n            self.result[petid] += \" {}:{}:{}\".format(field_id,\n                                                     self.categorical_feature[field_id][row[field_col]],\n                                                     row[value_col])\n        \n    def add_dataframe_as_samefield(self, df, basecol=None):\n        assert self.key_column in df.columns\n        cols = [col for col in df.columns if col != self.key_column]\n        if basecol is None:\n            basecol = cols[0]\n        field_id = self.categorical_field[basecol]\n        key_vals = df[self.key_column].values\n        for col in cols:\n            for key_val, value in zip(key_vals, df[col].values):\n                if self.field_nan[basecol] == value or ((type(value) == float) and isnan(value)):\n                    continue\n                self.result[key_val] += \" {}:{}:{}\".format(field_id,\n                                                           self.categorical_feature[field_id][col],\n                                                           value)\n\n\n    def set_categorical_columns(self, columns):\n        if type(columns) == str:\n            self.categorical_columns.add(columns)\n        else:\n            self.categorical_columns.update(columns)\n\n\n    def set_multicolumns_as_column(self, columns):\n        self.set_categorical_columns(columns)\n        base_field = self.categorical_field[columns[0]]\n        for col in columns:\n            self.categorical_field[col] = base_field\n\n\n    def add_Petids(self, keys, targets=None):\n        if targets is not None:\n            for key, target in zip(keys, targets):\n                self.result[key] = str(target)\n        else:\n            for key in keys:\n                self.result[key] = \"-1\"\n\n    def set_field_nanvalue(self, col, nanvalue=np.NaN):\n        self.field_nan[col] = nanvalue\n\n    def new_numerical_field(self):\n        self.numerical_field_last += 1\n        if self.numerical_field_last > self.numerical_field_max:\n            raise\n        return self.numerical_field_last * 1\n\n    def new_categorical_field(self):\n        self.categorical_field_last += 1\n        return self.categorical_field_last * 1\n    \n    def new_categorical_feature(self):\n        self.categorical_feature_last += 1\n        return self.categorical_feature_last * 1","139e7f6b":"df2ffm = FFMformatter(numerical_field_max=200)\n\ndf2ffm.add_Petids(train_df[\"PetID\"].values, train_df[\"AdoptionSpeed\"].values)\ndf2ffm.add_Petids(test_df[\"PetID\"].values)","d047dc75":"train_df[\"care_count\"] = (train_df[\"Vaccinated\"] == 1).astype(np.uint8) + (train_df[\"Dewormed\"] == 1) + (train_df[\"Sterilized\"] == 1)\ntest_df[\"care_count\"] = (test_df[\"Vaccinated\"] == 1).astype(np.uint8) + (test_df[\"Dewormed\"] == 1) + (test_df[\"Sterilized\"] == 1)\n\ntrain_df[\"care_uncertain_count\"] = ((train_df[\"Vaccinated\"] == 3).astype(np.uint8) +\n                                    (train_df[\"Dewormed\"] == 3) +\n                                    (train_df[\"Sterilized\"] == 3))\ntest_df[\"care_uncertain_count\"] = ((test_df[\"Vaccinated\"] == 3).astype(np.uint8) +\n                                   (test_df[\"Dewormed\"] == 3) +\n                                   (test_df[\"Sterilized\"] == 3))\n\ntrain_df[\"color_counts\"] = 3 - (train_df.filter(regex=\"^Color\") == 0).sum(axis=1)\ntest_df[\"color_counts\"] = 3 - (test_df.filter(regex=\"^Color\") == 0).sum(axis=1)\n\nrescuer_count_map = pd.concat([train_df[\"RescuerID\"], test_df[\"RescuerID\"]]).value_counts().to_dict()\ntrain_df[\"Rescuer_count\"] = np.log(train_df[\"RescuerID\"].map(rescuer_count_map))\ntest_df[\"Rescuer_count\"] = np.log(test_df[\"RescuerID\"].map(rescuer_count_map))\n\ntrain_df[\"Fee\"] = np.log1p(train_df[\"Fee\"])\ntest_df[\"Fee\"] = np.log1p(test_df[\"Fee\"])\n\ntrain_df[\"Age\"] = np.log1p(train_df[\"Age\"])\ntest_df[\"Age\"] = np.log1p(test_df[\"Age\"])\n\ntrain_df[\"description_len\"] = np.log1p(train_df[\"Description\"].fillna(\"\").str.len())\ntest_df[\"description_len\"] = np.log1p(test_df[\"Description\"].fillna(\"\").str.len())\n\ntrain_df[\"name_len\"] = np.log1p(train_df[\"Name\"].fillna(\"\").str.len())\ntest_df[\"name_len\"] = np.log1p(test_df[\"Name\"].fillna(\"\").str.len())\n\n# https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction\/discussion\/78040\n\n# state GDP: https:\/\/en.wikipedia.org\/wiki\/List_of_Malaysian_states_by_GDP\nstate_gdp = {\n    41336: 116.679,\n    41325: 40.596,\n    41367: 23.02,\n    41401: 190.075,\n    41415: 5.984,\n    41324: 37.274,\n    41332: 42.389,\n    41335: 52.452,\n    41330: 67.629,\n    41380: 5.642,\n    41327: 81.284,\n    41345: 80.167,\n    41342: 121.414,\n    41326: 280.698,\n    41361: 32.270\n}\n\n# state population: https:\/\/en.wikipedia.org\/wiki\/Malaysia\nstate_population = {\n    41336: 33.48283,\n    41325: 19.47651,\n    41367: 15.39601,\n    41401: 16.74621,\n    41415: 0.86908,\n    41324: 8.21110,\n    41332: 10.21064,\n    41335: 15.00817,\n    41330: 23.52743,\n    41380: 2.31541,\n    41327: 15.61383,\n    41345: 32.06742,\n    41342: 24.71140,\n    41326: 54.62141,\n    41361: 10.35977\n}\n\ntrain_df[\"state_gdp\"] = train_df.State.map(state_gdp)\ntest_df[\"state_gdp\"] = test_df.State.map(state_gdp)\n\ntrain_df[\"state_population\"] = train_df.State.map(state_population)\ntest_df[\"state_population\"] = test_df.State.map(state_population)\n\nfor col in [\"description_len\", \"name_len\", \"state_gdp\", \"state_population\", \"Rescuer_count\", \"Fee\", \"Age\"]:\n    mean, std = train_df[col].mean(), train_df[col].std()\n    train_df[col] = (train_df[col] - mean)\/std\n    test_df[col] = (test_df[col] - mean)\/std","665080dd":"train_df.head()","6315763a":"df2ffm.set_multicolumns_as_column([\"Color1\", \"Color2\", \"Color3\"])\ndf2ffm.set_multicolumns_as_column([\"Breed1\", \"Breed2\"])\ndf2ffm.set_categorical_columns([\"Gender\", \"State\"])\n\nfor col in [\"Color1\", \"Color2\", \"Color3\", \"Breed1\", \"Breed2\", \"FurLength\", \"MaturitySize\", \"Health\", \"State\"]:\n    df2ffm.set_field_nanvalue(col, 0)\n\nfor col in [\"Vacciated\", \"Dewormed\", \"Sterilized\"]:\n    df2ffm.set_field_nanvalue(col, 3)\n\ndrop_col = [\"Name\", \"Description\", \"RescuerID\"]\ndf2ffm.add_dataframe(train_df.drop(drop_col + [\"AdoptionSpeed\", \"group\"], axis=1))\ndf2ffm.add_dataframe(test_df.drop(drop_col, axis=1))","25598cde":"def load_metadata(path):\n    file = path.split(\"\/\")[-1]\n    pet_id = file[:-5].split(\"-\")[0]\n    file_id = file[:-5].split(\"-\")[1]\n    \n    with open(path, encoding=\"utf-8\") as f:\n        jfile = json.loads(f.read())\n    response = {\"labels\": [],\n                \"text\": {\"PetID\": pet_id,\n                         \"FileID\": file_id,\n                         \"description\": \"\"}}\n    \n    if \"labelAnnotations\" in jfile.keys():\n        for anot in jfile[\"labelAnnotations\"]:\n            response[\"labels\"].append({\"PetID\": pet_id,\n                                       \"FileID\": file_id,\n                                       \"description\": anot[\"description\"],\n                                       \"score\": anot[\"score\"]})\n\n    if \"imagePropertiesAnnotation\" in jfile.keys():\n        colors = np.zeros((10, 1, 3), dtype=np.uint8)\n        scores = np.zeros(10)\n        fractions = np.zeros(10)\n        getscore = itemgetter(\"score\")\n        for i, color in enumerate(sorted(jfile['imagePropertiesAnnotation'][\"dominantColors\"][\"colors\"],\n                                         key=getscore,\n                                         reverse=True)\n                                 ):\n\n            for j, c in enumerate([\"red\", \"green\", \"blue\"]):\n                if not color[\"color\"].get(c) is None:\n                    colors[i, 0, j] = color[\"color\"][c] \n                \n            scores[i] = color[\"score\"]\n            fractions[i] = color[\"pixelFraction\"]\n        hsv = cv2.cvtColor(colors, cv2.COLOR_RGB2HSV_FULL)\n        response[\"property\"] = {\"PetID\": pet_id,\n                                \"FileID\": file_id,\n                                \"top_red\": colors[0, 0, 0],\n                                \"top_green\": colors[0, 0, 1],\n                                \"top_blue\": colors[0, 0, 2],\n                                \"top_score\": scores[0],\n                                \"top_fraction\": fractions[0],\n                                \"top_hue\": hsv[0, 0, 0],\n                                \"top_saturation\": hsv[0, 0, 1],\n                                \"top_brightness\": hsv[0, 0, 2],\n                                \"top3_score\": scores[:3].sum(),\n                                \"top3_fraction\": fractions[:3].sum(),\n                                \"top3_area\": np.linalg.norm(np.cross((colors[1] - colors[0])[0], (colors[2] - colors[0])[0])),\n                                \"top10_fraction\": fractions.sum(),\n                                \"top10_score\": scores.sum()}\n\n    if 'cropHintsAnnotation' in jfile.keys():\n        tmp = jfile[\"cropHintsAnnotation\"][\"cropHints\"][0]\n        response[\"crop\"] = {\"PetID\": pet_id,\n                            \"FileID\": file_id,\n                            \"confidence\": tmp[\"confidence\"]}\n        if not tmp.get(\"importanceFraction\") is None:\n            response[\"crop\"][\"importanceFraction\"] = tmp[\"importanceFraction\"]\n    \n    if 'textAnnotations' in jfile.keys():\n        for anot in jfile[\"textAnnotations\"]:\n            response[\"text\"][\"description\"] += anot[\"description\"] + \" \"\n    \n    if \"faceAnnotations\" in jfile.keys():\n        faceanot = jfile[\"faceAnnotations\"][0]\n        response[\"face\"] = {\"PetID\": pet_id,\n                            \"FileID\": file_id,\n                            \"detectionConfidence\": faceanot['detectionConfidence'],\n                            'landmarkingConfidence': faceanot['landmarkingConfidence'],\n                            }\n    \n    return response","1010076a":"metadata_path = [dir_ + file for dir_ in [\"..\/input\/petfinder-adoption-prediction\/train_metadata\/\",\n                                          \"..\/input\/petfinder-adoption-prediction\/test_metadata\/\"]\n                                 for file in os.listdir(dir_)]\nresults = Parallel(n_jobs=-1, verbose=50)([delayed(load_metadata)(path) for path in metadata_path])\n\nlabels = []\nproperties = []\ncrops = []\nfaces = []\ntexts = []\nfor res in tqdm(results):\n    if not res.get(\"labels\") is None:\n        labels.extend(res[\"labels\"])\n    if not res.get(\"property\") is None:\n        properties.append(res[\"property\"])\n    if not res.get(\"crop\") is None:\n        crops.append(res[\"crop\"])\n    if not res.get(\"face\") is None:\n        faces.append(res[\"face\"])\n    if not res.get(\"text\") is None:\n        texts.append(res[\"text\"])\n\nlabels_df = pd.DataFrame(labels)\nproperties_df = pd.DataFrame(properties)\ncrops_df = pd.DataFrame(crops)\nfaces_df = pd.DataFrame(faces)\ntexts_df = pd.DataFrame(texts)","7c336c61":"labels_agg = labels_df.groupby([\"PetID\", \"description\"])[\"score\"].max().reset_index()\ndf2ffm.add_field_dataframe(labels_agg.rename(columns={\"description\": \"labels_description\"}).reset_index(), \"labels_description\", \"score\")","8120ce1e":"ffm_df = pd.Series(df2ffm.result).reset_index()\nffm_df.columns = [\"PetID\", \"ffm_text\"]\n\ntrain_ffm = train_df[[\"PetID\", \"AdoptionSpeed\", \"group\"]].merge(ffm_df,\n                                                                on=\"PetID\",\n                                                                how=\"left\")\n\ntest_ffm = test_df[[\"PetID\"]].merge(ffm_df,\n                                    on=\"PetID\",\n                                    how=\"left\")","8d6ad2ae":"with open(\".\/working\/test.txt\", \"w\") as f:\n    f.write(\"\\n\".join(test_ffm.loc[:, \"ffm_text\"].values.tolist()))\n","9e03d3d1":"train_oof = np.zeros(len(train_df))\ntest_pred = np.zeros(len(test_df))\n\nfor j in tqdm(range(50)):\n    i = j%10\n    with open(\".\/working\/dev.txt\", \"w\") as f:\n        f.write(\"\\n\".join(train_ffm.loc[train_ffm[\"group\"] != i, \"ffm_text\"].values.tolist()))\n    with open(\".\/working\/val.txt\", \"w\") as f:\n        f.write(\"\\n\".join(train_ffm.loc[train_ffm[\"group\"] == i, \"ffm_text\"].values.tolist()))\n    param = {\"task\": \"reg\",\n             \"lr\": .1,\n             \"epoch\": 200,\n             \"lambda\": .0001,\n             \"k\": 4,\n             \"nthread\": 4,\n             \"metric\": \"rmse\"}\n    ffm_model =xl.create_ffm()\n    ffm_model.setTrain(\".\/working\/dev.txt\")\n    ffm_model.setValidate(\".\/working\/val.txt\")\n    ffm_model.fit(param, \".\/working\/model.out\")\n\n    ffm_model.setTest(\".\/working\/val.txt\")\n    ffm_model.predict(\".\/working\/model.out\", \".\/working\/output.txt\")\n    output = pd.read_csv(\".\/working\/output.txt\", header=None)[0].values\n    train_oof[np.where(train_ffm[\"group\"] == i)] += output \/ 5\n\n    ffm_model.setTest(\".\/working\/test.txt\")\n    ffm_model.predict(\".\/working\/model.out\", \".\/working\/output.txt\")\n    output = pd.read_csv(\".\/working\/output.txt\", header=None)[0].values\n    test_pred += output \/ 50","0a0dfbe3":"from sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(train_df[\"AdoptionSpeed\"], train_oof))","8bef41b5":"from sklearn.metrics import cohen_kappa_score\n\n# https:\/\/www.kaggle.com\/naveenasaithambi\/optimizedrounder-improved\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return -cohen_kappa_score(y, preds, weights = 'quadratic')\n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = np.percentile(X, [2.73, 23.3, 50.3, 72]) # <= improved\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n    \n    def predict(self, X, coef):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return preds\n    \n    def coefficients(self):\n        return self.coef_['x']\n\n\n# https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction\/discussion\/76106\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              \/ num_scored_items)\n            d = pow(i - j, 2.0) \/ pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] \/ num_scored_items\n            denominator += d * expected_count \/ num_scored_items\n\n    return (1.0 - numerator \/ denominator)","9e9932f5":"y_train = train_df[\"AdoptionSpeed\"].values\ngroup = train_df[\"group\"].values\n\ncoef_mean = np.zeros(4)\nfor fold in range(10):\n    dev_idx = np.where(group != fold)[0]\n    val_idx = np.where(group == fold)[0]\n\n    pred_dev = train_oof[dev_idx]\n    y_dev = y_train[dev_idx]\n\n    pred_val = train_oof[val_idx]\n    y_val = y_train[val_idx]\n\n    optR = OptimizedRounder()\n    optR.fit(pred_dev, y_dev)\n    coefficients = optR.coefficients()\n    coef_mean += coefficients \/ 10\n    pred_val_k = optR.predict(pred_val, coefficients)","9968dfb6":"quadratic_weighted_kappa(y_train, optR.predict(train_oof, coef_mean))","9710ec35":"smpsb_df[\"AdoptionSpeed\"] = optR.predict(test_pred, coef_mean)\nsmpsb_df.to_csv(\"submission.csv\", index=None)","617e5585":"# tabular data","10933ff7":"# metadata"}}