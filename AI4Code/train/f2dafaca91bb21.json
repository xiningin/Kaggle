{"cell_type":{"d47b6720":"code","05be3295":"code","11833b07":"code","e5f4a9ca":"code","0c83c1cd":"code","9ac60cd8":"code","e5e57d69":"code","ce7000cc":"code","ce113b3d":"code","cca4daeb":"code","d124e6dd":"code","14c13e31":"code","3738d682":"code","50c66396":"code","b63e7751":"code","fb0dc20b":"code","e8086cbb":"code","d71c1485":"code","796b4c14":"code","4cf1053a":"code","9ed9f457":"code","f5aa6d85":"code","797c9f57":"code","3b3138ef":"code","0afb5db2":"code","a83b3134":"code","eb5af76f":"code","f561d52f":"code","b4423dff":"code","a87cd5e5":"code","b352a69e":"code","b860401a":"code","2c7b3e25":"markdown","34ad2541":"markdown"},"source":{"d47b6720":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","05be3295":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","11833b07":"train = pd.read_csv('..\/input\/twitter-sentiment-analysis-hatred-speech\/train.csv')","e5f4a9ca":"train.shape","0c83c1cd":"train.head()","9ac60cd8":"train['label'].value_counts()","e5e57d69":"plt.figure(figsize=(12,6))\nsns.countplot(x='label',data=train)","ce7000cc":"import nltk\nfrom nltk.stem import WordNetLemmatizer\nlemma = WordNetLemmatizer()\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords","ce113b3d":"def transform_text(text):\n    text = text.lower()\n    \n    r = re.findall('@[\\w]*', text)\n    \n    for w in r:\n        text = text.replace(w, ' ')\n    text = text.replace('[^a-zA-Z#]', '')\n    text = ' '.join([word for word in text.split() if len(word) > 3])\n    \n    text = re.sub(r'\\$%,.\\:\\?', ' ', text)\n    text = re.sub(r'\\s+', ' ', text)\n    \n    words = text.split(\" \")\n    words = [lemma.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n    text = ' '.join(words) \n    \n    return text","cca4daeb":"train['clean_text'] = train['tweet'].apply(lambda x : transform_text(x))","d124e6dd":"train.sample(5)","14c13e31":"# Visualizing all words\n\nall_words = \" \".join(sent for sent in train['clean_text'])\n\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(all_words)\n\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","3738d682":"# Frequency of Positive Words\n\npos_words = \" \".join(sent for sent in train['clean_text'][train['label'] == 0])\n\nwordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(pos_words)\n\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","50c66396":"# Frequency of Negative Words\n\nneg_words = \" \".join(sent for sent in train['clean_text'][train['label'] == 1])\n\nwordcloud = WordCloud(width=800, height=500, random_state=42, max_font_size=100).generate(neg_words)\n\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","b63e7751":"#Extract Hashtags\n\ndef extract_hashtag(texts):\n    hash = []\n    \n    for text in texts:\n        ht = re.findall(r\"#(\\w+)\", text)\n        hash.append(ht)\n        \n    return hash","fb0dc20b":"hash_pos = extract_hashtag(train['clean_text'][train['label'] == 0])","e8086cbb":"hash_neg = extract_hashtag(train['clean_text'][train['label'] == 1])","d71c1485":"hash_neg[:10]","796b4c14":"# unnest list\nhash_pos = sum(hash_pos, [])\nhash_neg = sum(hash_neg, [])","4cf1053a":"hash_pos[:10]","9ed9f457":"freq = nltk.FreqDist(hash_pos)\npos = pd.DataFrame({'Hashtag': list(freq.keys()),\n                 'Count': list(freq.values())})\npos.head()","f5aa6d85":"# select top 10 hashtags\npos = pos.nlargest(columns='Count', n=10)\nplt.figure(figsize=(15,8))\nsns.barplot(data=pos, x='Hashtag', y='Count')\nplt.show()","797c9f57":"freq = nltk.FreqDist(hash_neg)\nneg = pd.DataFrame({'Hashtag': list(freq.keys()),\n                 'Count': list(freq.values())})\nneg.head()","3b3138ef":"# select top 10 hashtags\nneg = neg.nlargest(columns='Count', n=10)\nplt.figure(figsize=(15,8))\nsns.barplot(data=neg, x='Hashtag', y='Count')\nplt.show()","0afb5db2":"# feature extraction\nfrom sklearn.feature_extraction.text import CountVectorizer\nbow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\nbow = bow_vectorizer.fit_transform(train['clean_text'])","a83b3134":"from sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(bow, train['label'], random_state=42, test_size=0.25)","eb5af76f":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, accuracy_score","f561d52f":"# training\nmodel = LogisticRegression()\nmodel.fit(xtrain, ytrain)","b4423dff":"# testing\npred = model.predict(xtest)\nf1_score(ytest, pred)","a87cd5e5":"accuracy_score(ytest,pred)","b352a69e":"# use probability to get output\npred_prob = model.predict_proba(xtest)\npred = pred_prob[:, 1] >= 0.3\npred = pred.astype(np.int)\n\nf1_score(ytest, pred)","b860401a":"accuracy_score(ytest,pred)","2c7b3e25":"Exploratory Data Analysis","34ad2541":"Below is a helper Function which generates random colors which can be used to give different colors to your plots.Feel free to use it"}}