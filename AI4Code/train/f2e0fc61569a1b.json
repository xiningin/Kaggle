{"cell_type":{"310369db":"code","25e553bc":"code","2271396a":"code","aaa43465":"code","da639ec8":"code","a4eb16c1":"code","b23b83a9":"code","9b6bd41d":"code","883620cc":"code","c9fe0bb4":"code","a65159e9":"code","e2b42a28":"code","febf7402":"code","af2d450c":"code","20d682a4":"code","4bc7e7e8":"code","fb702cf6":"code","03b6cd76":"code","df9526f4":"code","1f0f40a1":"code","963b8050":"code","9059cd5e":"code","9e57e2cf":"code","460020b0":"code","d403c278":"code","1a25c197":"code","e1b17046":"code","2be75c01":"code","501eda8e":"code","44aff52a":"code","446c8f93":"code","ce3945c1":"code","f30f20f1":"code","c19c8fa9":"code","1398db33":"code","ac0fc49e":"code","a1bfb858":"code","a9aefe58":"code","16189cb6":"markdown","e5c4b29c":"markdown","f66c51d1":"markdown","72231434":"markdown","c9d2a4cc":"markdown","eca25fc9":"markdown","b2f6cedc":"markdown","47fe9a2b":"markdown","f5e14e6d":"markdown","2464f0e5":"markdown","a8dcdc57":"markdown","56000549":"markdown","ebbc9934":"markdown","12b8d9ec":"markdown","2ee0e15c":"markdown","9d4df8ee":"markdown","58e35d33":"markdown","9b01e735":"markdown","7c23831e":"markdown","24e4c847":"markdown","964417b5":"markdown","5d7dc20b":"markdown","74ac2bfe":"markdown","7cbc4a6b":"markdown","7076621f":"markdown","72a82d70":"markdown","30560cfc":"markdown","693ab68b":"markdown","88305286":"markdown","5456491a":"markdown","21324b6c":"markdown","ca1b217e":"markdown","695c20aa":"markdown","dd3a7604":"markdown","7b2b4b2f":"markdown","97da8075":"markdown"},"source":{"310369db":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error","25e553bc":"# Read data\nconfirms_data = pd.read_csv(\"\/kaggle\/input\/time-series-data\/confirm.csv\")\ndeaths_data = pd.read_csv(\"\/kaggle\/input\/time-series-data\/death.csv\")\nrecovered_data = pd.read_csv(\"\/kaggle\/input\/time-series-data\/recovered.csv\")\n# Get columns name\ncolumn_comfirms_names= list(confirms_data.columns.values)\ncolumn_deaths_names= list(deaths_data.columns.values)\ncolumn_recovered_names= list(recovered_data.columns.values)\n# Total rows and columns each tabale\nprint('Confirms data has total:',len(confirms_data) ,'rows, and',len(column_comfirms_names),'columns.')\nprint('Deaths data has total:',len(deaths_data) ,'rows, and',len(column_deaths_names),'columns.')\nprint('Recovered data has total:',len(recovered_data) ,'rows, and',len(column_recovered_names),'columns.')\n\n# Number of countries in data\nprint(\"Number of Country\/Region: \", confirms_data['Country\/Region'].nunique())\nprint(\"From day\", column_deaths_names[4], \"to day\", column_deaths_names[-1], \":\", len(column_comfirms_names)-4, \"days\")","2271396a":"display(confirms_data)\ndisplay(deaths_data)\ndisplay(recovered_data)","aaa43465":"confirm_data_totals = confirms_data.sum(axis = 0, skipna = True)[3:]\ndeaths_data_totals = deaths_data.sum(axis = 0, skipna = True)[3:]\nrecovered_data_totals = recovered_data.sum(axis = 0, skipna = True)[3:]\ntotal = [confirm_data_totals,deaths_data_totals,recovered_data_totals]\ntotals = pd.concat(total,axis=1)\ntotals.columns = [ 'Confirmed','Deaths','Recovered']\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(17,7))\ntotals.plot(ax=ax1)\nax1.set_title(\"Global cases\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\n\ndeaths_data_totals.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deaths cases\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)\n\nrecovered_data_totals.plot(ax=ax3, color='green')\nax3.set_title(\"Global recovered cases\", size=13)\nax3.set_ylabel(\"Number of cases\", size=13)\nax3.set_xlabel(\"Date\", size=13)","da639ec8":"def showPLTByCountry(country,axs):\n    confirm_data_totals= confirms_data.loc[confirms_data[\"Country\/Region\"] == country].sum(axis = 0, skipna = True)[4:]\n    deaths_data_totals = deaths_data.loc[deaths_data[\"Country\/Region\"] == country].sum(axis = 0, skipna = True)[4:]\n    recovered_data_totals = recovered_data.loc[recovered_data[\"Country\/Region\"] == country].sum(axis = 0, skipna = True)[4:]\n    total_ = [confirm_data_totals,deaths_data_totals,recovered_data_totals]\n    total = pd.concat(total_,axis=1)\n    total.columns = [ 'Confirmed','Deaths','Recovered']\n    total.plot(ax=axs)\n    axs.set_title(country+\"'s cases\", size=13)\n    axs.set_ylabel(\"Number of cases\", size=13)\n#     axs.set_xlabel(\"Date\", size=13)\n","a4eb16c1":"fig1, (axs) = plt.subplots(2,3,figsize=(17,7))\nshowPLTByCountry(\"US\",axs[0][0])\nshowPLTByCountry(\"Brazil\",axs[0][1])\nshowPLTByCountry(\"India\",axs[0][2])\nshowPLTByCountry(\"Russia\",axs[1][0])\nshowPLTByCountry(\"South Africa\",axs[1][1])\nshowPLTByCountry(\"China\",axs[1][2])\n","b23b83a9":"# susceptible\ndef dS_dt(S, I, beta):\n    return -beta*S*I\n    \n# infected\ndef dI_dt(S, I, beta, gamma):\n    return beta*S*I - gamma*I\n\n# recovered\ndef dR_dt(I, gamma):\n    return gamma*I","9b6bd41d":"def runge_kutta(Sn, In, Rn, beta, gamma, h):\n    ks1 = dS_dt(Sn, In, beta)\n    ki1 = dI_dt(Sn, In, beta, gamma)\n    kr1 = dR_dt(In, gamma)\n    \n    ks2 = dS_dt(Sn + 0.5*h*ks1, In + 0.5*h*ki1, beta)\n    ki2 = dI_dt(Sn + 0.5*h*ks1, In + 0.5*h*ki1, beta, gamma)\n    kr2 = dR_dt(In + 0.5*h*ki1, gamma)\n    \n    ks3 = dS_dt(Sn + 0.5*h*ks2, In + 0.5*h*ki2, beta)\n    ki3 = dI_dt(Sn + 0.5*h*ks2, In + 0.5*h*ki2, beta, gamma)\n    kr3 = dR_dt(In + 0.5*h*ki2, gamma)\n    \n    ks4 = dS_dt(Sn + h*ks3, In + h*ki3, beta)\n    ki4 = dI_dt(Sn + h*ks3, In + h*ki3, beta, gamma)\n    kr4 = dR_dt(In + h*ki3, gamma)\n    \n    Sn_1 = Sn + (ks1 + 2*ks2 + 2*ks3 + ks4)*h\/6\n    In_1 = In + (ki1 + 2*ki2 + 2*ki3 + ki4)*h\/6\n    Rn_1 = Rn + (kr1 + 2*kr2 + 2*kr3 + kr4)*h\/6\n    \n    return Sn_1, In_1, Rn_1\n    ","883620cc":"def SIR_model(N, beta, gamma, h):\n    # N l\u00e0 d\u00e2n s\u1ed1 th\u1ebf gi\u1edbi hi\u1ec7n t\u1ea1i\n    # gi\u1ea3 s\u1eed ban \u0111\u1ea7u c\u00f3 1 ng\u01b0\u1eddi nhi\u1ec5m n\u00ean S0=N-1, I0=1, R0=0\n    # \u1edf \u0111\u00e2y ta s\u1ebd chu\u1ea9n h\u00f3a d\u1eef li\u1ec7u n\u1eb3m trong [0,1]\n    s = float(N-1)\/N\n    i = float(1)\/N\n    r = 0.\n    \n    susceptible, infected, recovered = [], [], []\n    #ta s\u1ebd l\u1eb7p 10000 l\u1ea7n (time-steps) \u0111\u1ec3 l\u1ea5y d\u1eef li\u1ec7u t\u01b0\u01a1ng \u1ee9ng\n    for k in range(10000):\n        susceptible.append(s)\n        infected.append(i)\n        recovered.append(r)\n        s, i, r = runge_kutta(s, i, r, beta, gamma, h)\n        \n    return susceptible, infected, recovered","c9fe0bb4":"N = 7800000000 # d\u00e2n s\u1ed1 th\u1ebf gi\u1edbi hi\u1ec7n t\u1ea1i\nbeta = 0.7\ngamma = 0.2\nh = 0.1\n\nsusceptible, infected, recovered = SIR_model(N, beta, gamma, h)\n\nf = plt.figure(figsize=(8,5)) \nplt.plot(susceptible, '#2ca02c', label='susceptible');\nplt.plot(infected, '#ff7f0e', label='infected');\nplt.plot(recovered, '#17becf', label='recovered\/deceased');\nplt.title(\"SIR model\")\nplt.xlabel(\"time\", fontsize=10);\nplt.ylabel(\"Normalized population\", fontsize=10);\nplt.legend(loc='best')\nplt.xlim(0,1000)\nplt.savefig('SIR_model.png')\nplt.show()","a65159e9":"t= confirms_data.loc[confirms_data[\"Country\/Region\"] == \"US\"]\ncolumn_day= list(t.columns.values)\ncolumn_day= column_day[4:]\nt = t.sum(axis = 0, skipna = True).to_frame()\nt = t.T\n\nx= t.loc[:,column_day[0]:column_day[-1]]\nx = x.diff(axis=1).fillna(0)\nx.values[0][0] = t[column_day[0]].values[0]\n\npopulation = float(330578810)\n# population = float(1439323776)\n\nday_count = list(range(1,len(column_day)+1))\nxdata = day_count\nydata = np.array(x.values[0], dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] \/ N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model for US confirmed cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])\n","e2b42a28":"t = confirms_data.sum(axis = 0, skipna = True).to_frame()\nt = t.T\ncolumn_day= list(t.columns.values)\ncolumn_day= column_day[4:]\n\nx= t.loc[:,column_day[0]:column_day[-1]]\nx = x.diff(axis=1).fillna(0)\nx.values[0][0] = t[column_day[0]].values[0]\n\npopulation = float(7800000000)\n# population = float(1439323776)\n\nday_count = list(range(1,len(column_day)+1))\nxdata = day_count\nydata = np.array(x.values[0], dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] \/ N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model for global confirmed cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])\n","febf7402":"test = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/train.csv\")\ntrain.Province_State.fillna(\"None\", inplace=True)","af2d450c":"# Do d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb cu\u1ed9c thi n\u00ean ta g\u1ed9p 2 b\u1ed9 d\u1eef li\u1ec7u train v\u00e0 test v\u1edbi nhau\ndates_overlap = ['2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08',\n                 '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14']\ntrain2 = train.loc[~train['Date'].isin(dates_overlap)]\nall_data = pd.concat([train2, test], axis = 0, sort=False)\n\n# Ch\u1eafc ch\u1eafn ch\u1ec9 c\u00f3 th\u00f4ng tin v\u1ec1 s\u1ed1 ca nhi\u1ec5m v\u00e0 s\u1ed1 ca t\u1eed vong tr\u01b0\u1edbc ng\u00e0y 11\/03\/2020\n# M\u1ee5c \u0111\u00edch: ta hu\u1ea5n luy\u1ec7n v\u1edbi b\u1ed9 d\u1eef li\u1ec7u tr\u01b0\u1edbc ng\u00e0y 11\/03\/2020 \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n \nall_data.loc[all_data['Date'] >= '2020-04-01', 'ConfirmedCases'] = 0\nall_data.loc[all_data['Date'] >= '2020-04-01', 'Fatalities'] = 0\nall_data['Date'] = pd.to_datetime(all_data['Date'])\n\n# T\u1ea1o c\u00e1c c\u1ed9t d\u1eef li\u1ec7u ch\u1ee9 th\u1eddi gian: ng\u00e0y, th\u00e1ng, n\u0103m\nle = preprocessing.LabelEncoder()\nall_data['Day_num'] = le.fit_transform(all_data.Date)\nall_data['Day'] = all_data['Date'].dt.day\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year\n\n# X\u1eed l\u00fd d\u1eef li\u1ec7u b\u1ecb m\u1ea5t trong d\u1eef li\u1ec7u b\u1eb1ng c\u00e1ch thay th\u1ebf\nall_data['Province_State'].fillna(\"None\", inplace=True)\nall_data['ConfirmedCases'].fillna(0, inplace=True)\nall_data['Fatalities'].fillna(0, inplace=True)\nall_data['Id'].fillna(-1, inplace=True)\nall_data['ForecastId'].fillna(-1, inplace=True)\n\ndisplay(all_data.head())","20d682a4":"all_data.info() # S\u1ed1 l\u01b0\u1ee3ng ph\u1ea7n t\u1eed non-null trong t\u1eebng c\u1ed9t \u0111\u1ec3u b\u1eb1ng s\u1ed1 l\u01b0\u1ee3ng ph\u1ea7n t\u1eed","4bc7e7e8":"# \u0110\u1ecbnh ngh\u0129a c\u00e1c h\u00e0m t\u00ednh lags v\u00e0 trends c\u1ee7a d\u1eef li\u1ec7u \n\ndef calculate_lag(dataframe, lag_list, column):\n    for lag in lag_list:\n        column_lag = f\"{column}_{lag}\"\n        dataframe[column_lag] = dataframe.groupby(['Country_Region', 'Province_State'])[column].shift(lag, fill_value=0)\n    return dataframe\n\ndef calculate_trend(dataframe, lag_list, column):\n    df_groupby = dataframe.groupby(['Country_Region', 'Province_State'])\n    for lag in lag_list:\n        trend_column_lag = f\"Trend_{column}_{lag}\"\n        dataframe[trend_column_lag] = (df_groupby[column].shift(0, fill_value=0) - \n                                df_groupby[column].shift(lag, fill_value=0))\/df_groupby[column].shift(lag, fill_value=0.001)\n    return dataframe","fb702cf6":"all_data = calculate_lag(all_data.reset_index(), range(1,7), 'ConfirmedCases')\nall_data = calculate_lag(all_data, range(1,7), 'Fatalities')\nall_data = calculate_trend(all_data, range(1,7), 'ConfirmedCases')\nall_data = calculate_trend(all_data, range(1,7), 'Fatalities')\nall_data.replace([np.inf, -np.inf], 0, inplace=True)\nall_data.fillna(0, inplace=True)","03b6cd76":"# \u0110\u1ecdc d\u1eef li\u1ec7u t\u1eeb data file\nworld_population = pd.read_csv(\"..\/input\/population-by-country-2020\/population_by_country_2020.csv\")\n\n# Ch\u1ecdn c\u00e1c c\u1ed9t mong mu\u1ed1n , v\u00e0 s\u1eeda \u0111\u1ed5i l\u1ea1i t\u00ean \nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P\/Km\u00b2)', 'Land Area (Km\u00b2)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country_Dependency', 'Population', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Thay t\u00ean \"United States\" th\u00e0nh \"US\"\nworld_population.loc[world_population['Country_Dependency']=='United States', 'Country_Dependency)'] = 'US'\n\n# X\u00f3a d\u1ea5u % \u1edf c\u1ed9t d\u1eef li\u1ec7u Urban Pop\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes\n# Thay th\u1ebf c\u00e1c gi\u00e1 tr\u1ecb \"N.A\" trong c\u1ed9t \"Urban Pop\" v\u00e0 c\u1ed9t \"Med Age\" b\u1eb1ng mode c\u1ee7a n\u00f3\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\n\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='Country_Region', right_on='Country_Dependency', how='left')\nall_data[['Population', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\ndisplay(all_data.head())\n\nprint(\"Encoded dataset\")\n# Label encode countries and provinces. Save dictionary for exploration purposes\nall_data.drop('Country_Dependency)', inplace=True, axis=1)\n\nall_data['Country_Region'] = le.fit_transform(all_data['Country_Region'])\nnumber_c = all_data['Country_Region']\ncountries = le.inverse_transform(all_data['Country_Region'])\ncountry_dict = dict(zip(countries, number_c)) \n\nall_data['Province_State'] = le.fit_transform(all_data['Province_State'])\nnumber_p = all_data['Province_State']\nprovince = le.inverse_transform(all_data['Province_State'])\nprovince_dict = dict(zip(province, number_p)) \ndisplay(all_data.head())","df9526f4":"# Tr\u1ef1c quan d\u1eef li\u1ec7u c\u1ea3 hai tr\u01b0\u1eddng h\u1ee3p \u0111\u1ed1i v\u1edbi T\u00e2y Ban Nha v\u1edbi d\u1eef li\u1ec7u 10 ng\u00e0y cu\u1ed1i m\u00e0 c\u00f3 th\u00f4ng tin, b\u1eaft \u0111\u1ea7u t\u1eeb 01\/03\/2020\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\ncondition = (all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)\n\n# Day_num = 38 is March 1st\ny1 = all_data[condition][['ConfirmedCases']]\nx1 = range(0, len(y1))\nax1.plot(x1, y1, 'bo--')\nax1.set_title(\"Spain ConfirmedCases between days 39 and 49\")\nax1.set_xlabel(\"Days\")\nax1.set_ylabel(\"ConfirmedCases\")\n\n\ny2 = all_data[condition][['ConfirmedCases']].apply(lambda x: np.log(x))\nx2 = range(0, len(y2))\nax2.plot(x2, y2, 'bo--')\nax2.set_title(\"Spain Log ConfirmedCases between days 39 and 49\")\nax2.set_xlabel(\"Days\")\nax2.set_ylabel(\"Log ConfirmedCases\")","1f0f40a1":"# Ch\u1ecdn l\u1ecdc c\u00e1c \u0111\u1eb7c tr\u01b0ng l\u00e0m \u0111\u1ea7u v\u00e0o m\u00f4 h\u00ecnh\ndata = all_data.copy()\nfeatures = ['Id', 'ForecastId', 'Country_Region', 'Province_State', 'ConfirmedCases', 'Fatalities', \n       'Day_num']\ndata = data[features]\n\n# \u00c1p d\u1ee5ng bi\u1ebfn \u0111\u1ed5i Logarithm cho ConfirmedCases v\u00e0 Fatalities c\u1ed9t\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].astype('float64')\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.log1p(x))\n\n# Replace infinites\ndata.replace([np.inf, -np.inf], 0, inplace=True)","963b8050":"# Chia th\u00e0nh t\u1eadp hu\u1ea5n luy\u1ec7n v\u00e0 t\u1eadp ki\u1ec3m th\u1eed\ndef split_data(df, train_lim, test_lim):\n    \n    df.loc[df['Day_num']<=train_lim , 'ForecastId'] = -1\n    df = df[df['Day_num']<=test_lim]\n    \n    # T\u1eadp hu\u1ea5n luy\u1ec7n\n    x_train = df[df.ForecastId == -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n    y_train_1 = df[df.ForecastId == -1]['ConfirmedCases']\n    y_train_2 = df[df.ForecastId == -1]['Fatalities']\n\n    # T\u1eadp ki\u1ec3m th\u1eed \n    x_test = df[df.ForecastId != -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n\n    # Lo\u1ea1i b\u1ecf hai c\u1ed9t Id v\u00e0 ForecastId\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test","9059cd5e":"# h\u00e0m m\u00f4 h\u00ecnh h\u1ed3i quy tuy\u1ebfn t\u00ednh\ndef lin_reg(X_train, Y_train, X_test):\n    regr = linear_model.LinearRegression()\n\n    # Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh d\u1ef1a tr\u00ean t\u1eadp hu\u1ea5n luy\u1ec7n\n    regr.fit(X_train, Y_train)\n\n    # D\u1ef1 \u0111o\u00e1n t\u1eadp ki\u1ec3m th\u1eed\n    y_pred = regr.predict(X_test)\n    \n    return regr, y_pred","9e57e2cf":"from datetime import timedelta, date\n\ndef daterange(start_date, end_date):\n    for n in range(int((end_date - start_date).days)):\n        yield start_date + timedelta(n)\n\nstart_date = date(2020, 3, 1)\nend_date = date(2020, 4, 15)\n\ndates_list = [single_date.strftime(\"%Y-%m-%d\") for single_date in daterange(start_date, end_date)]","460020b0":"def plot_linreg_basic_country(data, country_name, dates_list, day_start, shift, train_lim, test_lim):\n    \n    data_country = data[data['Country_Region']==country_dict[country_name]]\n    data_country = data_country.loc[data_country['Day_num']>day_start]\n    X_train, Y_train_1, Y_train_2, X_test = split_data(data_country, train_lim, test_lim)\n    model, pred = lin_reg(X_train, Y_train_1, X_test)\n\n    # Create a df with both real cases and predictions (predictions starting on March 12th)\n    X_train_check = X_train.copy()\n    X_train_check['Target'] = Y_train_1\n\n    X_test_check = X_test.copy()\n    X_test_check['Target'] = pred\n\n    X_final_check = pd.concat([X_train_check, X_test_check])\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n    ax1.plot(list(range(len(predicted_data))), np.expm1(predicted_data))\n    ax1.plot(list(range(len(real_data))), real_data)\n    ax1.axvline(30-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(f\"Day count (from March {1+shift})\")\n    ax1.set_ylabel(\"Confirmed Cases\")\n\n    ax2.plot(list(range(len(predicted_data))), predicted_data)\n    ax2.plot(list(range(len(real_data))), np.log1p(real_data))\n    ax2.axvline(30-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(f\"Day count (from March {str(1+shift)})\")\n    ax2.set_ylabel(\"Log Confirmed Cases\")\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))","d403c278":"train_lim, test_lim = 69, 112\n\noutput_lr = widgets.Output()\n\ndef linear_reg_country():\n    country_name = country_combobox.value\n    march_day = marchDay_text.value\n    if not (country_name and march_day):\n        return\n    march_day = int(march_day)\n    day_start = 39 + march_day # 39 l\u00e0 th\u1ee9 t\u1ef1 c\u1ee7a ng\u00e0y 01\/03\/2020\n    date_list_temp = dates_list[march_day:]\n    with output_lr:\n        output_lr.clear_output()\n        plot_linreg_basic_country(data, country_name, date_list_temp, day_start, march_day, train_lim, test_lim)\n        plt.show()\n        \ncountry_combobox = widgets.Combobox(\n    placeholder='Country',\n    options= tuple(country_dict.keys()),\n    description='Country: ',\n    ensure_option=True,\n    disabled=False\n)    \n\nmarchDay_text = widgets.Text(\n    placeholder='Enter number',\n    description=\"March day:\"\n)\n\nsubmit_lr_btn = widgets.Button(description=\"run\")\n\ndef run_linear_reg_country(b):\n    linear_reg_country()\n\ndisplay(country_combobox, marchDay_text, submit_lr_btn, output_lr)\n\nsubmit_lr_btn.on_click(run_linear_reg_country)","1a25c197":"# H\u00e0m chia t\u1eadp hu\u1ea5n luy\u1ec7n v\u00e0 t\u1eadp test cho d\u1ef1 \u0111o\u00e1n sau 1 ng\u00e0y\ndef split_data_one_day(df, d, train_lim, test_lim):\n    df.loc[df['Day_num']<=train_lim , 'ForecastId'] = -1\n    df = df[df['Day_num']<=test_lim]\n    \n    # T\u1eadp hu\u1ea5n luy\u1ec7n\n    x_train = df[df.Day_num<d]\n    y_train_1 = x_train.ConfirmedCases\n    y_train_2 = x_train.Fatalities\n    x_train.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n    # T\u1eadp ki\u1ec3m th\u1eed \n    x_test = df[df.Day_num==d]\n    x_test.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n    # Lo\u1ea1i b\u1ecf hai c\u1ed9t Id v\u00e0 ForcastId \n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test\n\n\n# H\u00e0m c\u1ea5u h\u00ecnh bi\u1ec3u \u0111\u1ed3 \ndef config_axis(axis, march_day, msg):\n    axis.axvline(30-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    axis.set_xlabel(\"Day count (starting on March \" + str(march_day) + \"))\")\n    axis.set_ylabel(msg)\n    return axis\n\n\n# H\u00e0m chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u \u0111\u1ec3 v\u1ebd\ndef prepare_data(data, train, country_name, day_start, dates_list, fatalities=False):\n    column = \"ConfirmedCases\"\n    if fatalities:\n        column = \"Fatalities\"\n    \n    predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))][column]\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))][column]\n    \n    dates_list_num = list(range(0,len(dates_list)))\n    \n    return predicted_data, real_data, dates_list_num\n\n\ndef plot_real_vs_prediction_country(data, train, country_name, day_start, dates_list, march_day):\n    predicted_data, real_data, dates_list_num = prepare_data(data, train, country_name, day_start, dates_list)\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n    \n    config_axis(ax1, march_day, \"Confirmed Cases\")\n    ax1.plot(list(range(len(predicted_data))), np.expm1(predicted_data))\n    ax1.plot(list(range(len(real_data))), real_data)\n    \n    config_axis(ax2, march_day, \"Log Confirmed Cases\")\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \ndef plot_real_vs_prediction_country_fatalities(data, train, country_name, day_start, dates_list, march_day):\n    predicted_data, real_data, dates_list_num = prepare_data(data, train, country_name, day_start, dates_list, True)\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n    \n    ax1 = config_axis(ax1, march_day, \"Fatalities Cases\")\n    ax1.plot(dates_list_num, np.expm1(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    \n    ax2 = config_axis(ax2, march_day, \"Log Fatalities Cases\")\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n    plt.suptitle((\"Fatalities predictions based on Log-Lineal Regression for \"+country_name))","e1b17046":"# H\u00e0m d\u1ef1 \u0111o\u00e1n s\u1eed d\u1ee5ng m\u00f4 h\u00ecnh H\u1ed3i quy tuy\u1ebfn t\u00ednh v\u1edbi th\u00eam \u0111\u1eb7c tr\u01b0ng lags cho m\u1ed9t qu\u1ed1c gia\ndef lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict, train_lim, test_lim):\n    data = all_data.copy()\n    features = ['Id', 'Province_State', 'Country_Region',\n           'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n    data = data[features]\n\n    # Select country an data start (all days)\n    data = data[data['Country_Region']==country_dict[country_name]]\n    data = data.loc[data['Day_num'] > day_start]\n\n    # Lags\n    data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n    data = calculate_lag(data, range(1,8), 'Fatalities')\n    \n    # Ch\u1ecdn ra c\u00e1c c\u1ed9t thu\u1ed9c t\u00ednh Confirmed\n    filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n    filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n    \n    # Apply log transformation\n    data[filter_col] = data[filter_col].apply(lambda x: np.log1p(x))\n    data.replace([np.inf, -np.inf], 0, inplace=True)\n    data.fillna(0, inplace=True)\n\n\n    # Start\/end of forecast\n    start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n    end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n    for d in list(range(start_fcst, end_fcst+1)):\n        X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d, train_lim, test_lim)\n        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) \n                 & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) \n                 & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n        # T\u00ednh to\u00e1n l\u1ea1i lags\n        data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n        data = calculate_lag(data, range(1,8), 'Fatalities')\n        data.replace([np.inf, -np.inf], 0, inplace=True)\n        data.fillna(0, inplace=True)\n   \n    return data","2be75c01":"train_lim, test_lim = 69, 112\n\noutput = widgets.Output()\n\ndef linear_reg_with_lag_country():\n    country_name = country_combobox_lag.value\n    march_day = marchDay_text_lag.value\n    lag_size = lagSize_text.value\n    \n    if not (country_name and march_day and lag_size):\n        return\n    march_day = int(march_day)\n    lag_size = int(lag_size)\n    day_start = 39 + march_day # 39 l\u00e0 th\u1ee9 t\u1ef1 c\u1ee7a ng\u00e0y 01\/03\/2020\n    date_list_temp = dates_list[march_day:]\n    data_c = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict, train_lim, test_lim)\n    with output:\n        output.clear_output()\n        print(country_name, march_day, lag_size)\n        plot_real_vs_prediction_country(data_c, train, country_name, day_start, date_list_temp, march_day)\n        plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, date_list_temp, march_day)\n        plt.show()\n\ncountry_combobox_lag = widgets.Combobox(\n    placeholder='Country',\n    options= tuple(country_dict.keys()),\n    description='Country: ',\n    ensure_option=True,\n    disabled=False\n)    \n\nmarchDay_text_lag = widgets.Text(\n    placeholder='Enter number',\n    description=\"March day:\"\n)\nlagSize_text = widgets.Text(\n    placeholder=\"Enter number\",\n    description=\"Lag size:\"\n)\n\nsubmit_btn = widgets.Button(description=\"run\")\n\ndef run_linear_reg_with_lag_country(button):\n    linear_reg_with_lag_country()\n    \ndisplay(country_combobox_lag, marchDay_text_lag, lagSize_text, submit_btn, output)\n\nsubmit_btn.on_click(run_linear_reg_with_lag_country)\n\n# Spain, Italy, Germany, Albania, Andora","501eda8e":"# \u0110\u1ecbnh ngh\u0129a h\u00e0m Logistic t\u1ed5ng qu\u00e1t\ndef logistic_function(x, a, b, c, d):\n    return a \/ (1. + np.exp(-c * (x - d))) + b\n\n# Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh t\u00ecm ra b\u1ed9 tham s\u1ed1 t\u1ed1i \u01b0u nh\u1ea5t\ndef fit_logistic(all_data, country_name, province_name, train_lim, target):\n    data_cp = all_data.loc[(all_data['Country_Region']==country_dict[country_name]) & (all_data['Province_State']==province_dict[province_name])]\n    y = data_cp.loc[(data_cp['Day_num'])<=train_lim, target].astype(np.int32)\n    x = list(range(0, len(y)))\n\n    # Kh\u1edfi t\u1ea1o b\u1ed9 tham s\u1ed1 \u0111\u1ea7u ti\u00ean\n    p0 = [0,1,1,0]\n\n    (a_, b_, c_, d_), cov = optimize.curve_fit(logistic_function, x, y, bounds=(0, [500000., 10., 1000., 1000., ]), p0=p0, maxfev=10**9)\n    y_fit = logistic_function(x, a_, b_, c_, d_)\n    return x, y, y_fit, (a_, b_, c_, d_), cov\n\n# V\u1ebd h\u00e0m logistic\ndef plot_logistic(x, y, y_fit, country_name, province_name, target):\n    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n    ax.plot(x, y, 'o')\n    ax.plot(x, y_fit, '-')\n    ax.set_xlabel(\"Day count (starting on January 22nd)\")\n    ax.set_ylabel(target)\n    ax.set_title(\"Fit to logistic regression for \"+ country_name+\"\/\"+province_name)\n    \n# V\u1ebd gi\u00e1 tr\u1ecb d\u1ef1 \u0111o\u00e1n cho m\u1ed9t qu\u1ed1c gia\ndef plot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, target, x, a_, b_, c_, d_):\n    forecast = logistic_function(list(range(len(x)+60)), a_, b_, c_, d_)\n    df_train = train.loc[(train['Country_Region']==country_name) & (train['Province_State']==province_name), target]\n    df_fcst = forecast[:len(df_train)]\n    dates = list(range(len(df_train)))\n    \n    # V\u1ebd k\u1ebft qu\u1ea3\n    fig, (ax1) = plt.subplots(1, 1, figsize=(6,4))\n    ax1.plot(dates, df_fcst)\n    ax1.plot(dates, df_train)\n    ax1.axvline(len(df_train)-valid_num-1, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.set_title(\"Actual ConfirmedCases vs predictions based on Logistic curve for \"+country_name + \"\/\"+province_name)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count starting on January 22nd\")\n    ax1.set_ylabel(\"ConfirmedCases\")\n\n\ntrain_lim = 69\nvalid_lim = 84 \ntest_lim = 112\nvalid_num=valid_lim-train_lim ","44aff52a":"country_name = 'Spain'\nprovince_name = 'None'\n\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","446c8f93":"country_name = 'Italy'\nprovince_name = 'None'\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","ce3945c1":"country_name = 'Germany'\nprovince_name = 'None'\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","f30f20f1":"country_name = 'Andorra'\nprovince_name = 'None'\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","c19c8fa9":"country_name = 'China'\nprovince_name = 'Hubei'\nx, y, y_fit, (a_, b_, c_, d_), cov = fit_logistic(all_data, country_name, province_name, train_lim, 'ConfirmedCases')\nplot_logistic(x, y, y_fit, country_name, province_name, 'ConfirmedCases')\nplot_logistic_country(all_data, train, dates_overlap, country_name, province_name, valid_num, 'ConfirmedCases', x, a_, b_, c_, d_)","1398db33":"#############\n# Daily report : from 22\/1\/2020\ndata_us = pd.read_csv(\"\/kaggle\/input\/datadeathbygroups\/us-states.csv\")\n# data_us.to_excel ('hle.xlsx', index = None, header=True)\n# Weekly report : from \ndata_by_group = pd.read_csv(\"\/kaggle\/input\/datadeathbygroups\/death_weekly.csv\")\n##############\n\n# Connecticut\n# Daily report in Connecticut : Chi dung duoc data nay\ndata_by_group_st_conn = pd.read_csv(\"\/kaggle\/input\/datadeathbygroups\/case_connecticut.csv\")\n# Sort the data frame by date updated\n# data_by_group_st_conn[\"DateUpdated\"] = pd.to_datetime(data_by_group_st_conn[\"DateUpdated\"])\nprint ('Total case infected in 08\/05\/2020 (mm\/dd\/yyyy):' ,sum(data_by_group_st_conn.loc[data_by_group_st_conn[\"DateUpdated\"] == \"08\/05\/2020\"]['Total cases'].tolist()))\ndisplay(data_by_group_st_conn)\n\nprint(data_by_group_st_conn['AgeGroups'].unique())","ac0fc49e":"# S\u1eafp x\u1ebfp l\u1ea1i d\u1eef li\u1ec7u theo ng\u00e0y th\u00e1ng\ndata_by_group_st_conn = data_by_group_st_conn.sort_values(by=\"DateUpdated\")\ndays= data_by_group_st_conn['DateUpdated'].unique().tolist()\nprint(\"From day\", days[0], \"to day\", days[-1], \":\",len(days) ,\"days\")\n# Thay \u0111\u1ed5i gi\u00e1 tr\u1ecb c\u1ee7a age groups\ncol_age = data_by_group_st_conn['AgeGroups'].tolist()\ncol_age = [i.replace(\" \", \"\").replace(\"andolder\",\"+\").replace('19-Oct','10-19') for i in col_age]\ndata_by_group_st_conn.loc[:,'AgeGroups'] = col_age\n\nprint(data_by_group_st_conn['AgeGroups'].unique())","a1bfb858":"import statistics \n","a9aefe58":"fig, (myax,myax2) = plt.subplots(1,2,figsize=(17,7))\ndate = data_by_group_st_conn['DateUpdated'].tolist();\ncase_by_age = []\ncol_age = data_by_group_st_conn['AgeGroups'].unique().tolist()\ncol_age.sort()\nfor i in col_age:\n    newlist= data_by_group_st_conn.loc[data_by_group_st_conn[\"AgeGroups\"] == i]['Total cases'].tolist()\n    case_by_age.append(newlist)\nidx =0\nfor lists in case_by_age:\n    myax.plot(lists, label= str(col_age[idx]))\n    idx+=1\n\n# Add legend\nmyax.legend(loc=2, ncol=2)\nstrTitle= '1: Total cases infected from ' +days[0]\nmyax.title.set_text(strTitle)\nmyax.set_ylabel(\"Number of cases\", size=13)\nmyax.set_xlabel(\"Days\", size=13)\n# fig, (myax) = plt.subplots(1,1,figsize=(17,7))\n# date = data_by_group_st_conn['DateUpdated'].tolist();\n# date.sort()\ncase_by_age = []\nfor i in col_age:\n    newlist= data_by_group_st_conn.loc[data_by_group_st_conn[\"AgeGroups\"] == i]['Total deaths'].tolist()\n    case_by_age.append(newlist)\nidx =0\nfor lists in case_by_age:\n    myax2.plot(lists, label= str(col_age[idx]))\n    idx+=1\n\n# Add legend\nplt.legend(loc=2, ncol=2)\nstrTitle= '2: Total deaths from ' +days[0]\nmyax2.title.set_text(strTitle)\nmyax2.set_ylabel(\"Number of cases\", size=13)\nmyax2.set_xlabel(\"Days\", size=13)\n## Ratio for deaths and infected\nfig, (ratio) = plt.subplots(1,1,figsize=(17,7))\ncase_by_age = []\nfor i in col_age:\n    newlistCase= data_by_group_st_conn.loc[data_by_group_st_conn[\"AgeGroups\"] == i]['Total cases'].tolist()\n    newlistDeaths= data_by_group_st_conn.loc[data_by_group_st_conn[\"AgeGroups\"] == i]['Total deaths'].tolist()\n    newlist =[newlistDeaths[i]\/newlistCase[i] for i in range(len(newlistCase))]\n    print(i ,' : ', statistics.mean(newlist))\n\n    case_by_age.append(newlist)\nidx =0\nfor lists in case_by_age:\n    ratio.plot(lists, label= str(col_age[idx]))\n    idx+=1\n\n# Add legend\nratio.legend(loc=2, ncol=2)\nstrTitle= '3: Ratio between deaths and infected case ' +days[0]\nratio.title.set_text(strTitle)\nratio.set_ylabel(\"Ratio\", size=13)\nratio.set_xlabel(\"Days\", size=13)","16189cb6":"Tri\u1ec3n khai c\u00f4ng th\u1ee9c l\u00fd thuy\u1ebft \u0111\u01b0\u1ee3c \u0111\u1ec1 c\u1eadp \u1edf ph\u1ea7n 2.1 ta c\u00f3 c\u00e1c h\u00e0m t\u01b0\u01a1ng \u1ee9ng","e5c4b29c":"## 5. D\u1ef1 \u0111o\u00e1n cho giai \u0111o\u1ea1n sau c\u1ee7a \u0111\u1ea1i d\u1ecbch<a id=\"section5\"><\/a>\n\nTrong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n c\u1ee7a \u0111\u1ea1i d\u1ecbch, m\u00f4 h\u00ecnh tuy\u1ebfn t\u00ednh b\u1eaft \u0111\u1ea7u cho m\u1ed9t s\u1ed1 k\u1ebft qu\u1ea3 t\u1ed9i t\u1ec7 h\u01a1n khi d\u1ef1 b\u00e1o. V\u00e0 vi\u1ec7c bi\u1ebft tr\u01b0\u1edbc \u0111\u01b0\u1ee3c h\u1ea1n ch\u1ebf c\u1ee7a m\u00f4 h\u00ecnh tuy\u1ebfn t\u00ednh th\u00ec ch\u00fang ta c\u1ea7n t\u00ecm ra c\u00e1c ph\u01b0\u01a1ng ph\u00e1p thay th\u1ebf cho m\u00f4 h\u00ecnh tr\u00ean. <br\/><br\/>\nM\u00f4 h\u00ecnh m\u00e0 ch\u00fang ta c\u00e2n nh\u1eafc \u0111\u1ebfn:\n- Logistic curve fit\n","f66c51d1":"## 2. SIR Model \n### 2.1 \u0110\u1ecbnh ngh\u0129a m\u00f4 h\u00ecnh d\u1ecbch b\u1ec7nh SIR\nL\u00e0 m\u1ed9t m\u00f4 h\u00ecnh to\u00e1n h\u1ecdc v\u1ec1 d\u1ecbch b\u1ec7nh, trong \u0111\u00f3, d\u00e2n s\u1ed1 s\u1ebd \u0111\u01b0\u1ee3c chia l\u00e0m 3 nh\u00f3m\n    - S: Susceptible (=All - Confirmed) : Nh\u1eefng ng\u01b0\u1eddi c\u00f3 kh\u1ea3n n\u0103ng nhi\u1ec5m b\u1ec7nh\n    - I: Infected (=Confirmed - Recovered - Deaths) : Nh\u1eefng ng\u01b0\u1eddi \u0111ang nhi\u1ec5m b\u1ec7nh\n    - R: Recovered or fatal (=Recovered + Deaths) : Nh\u1eefng ng\u01b0\u1eddi \u0111\u00e3 h\u1ed3i ph\u1ee5c ho\u1eb7c ch\u1ebft (kh\u00f4ng c\u00f2n kh\u1ea3 n\u0103ng nhi\u1ec5m).\n\u1ede d\u1ea1ng SIR chu\u1ea9n, th\u00ec ch\u1ec9 x\u00e9t s\u1ed1 ng\u01b0\u1eddi \u0111\u00e3 h\u1ed3i ph\u1ee5c, tuy nhi\u00ean v\u1edbi th\u1ef1c t\u1ebf, s\u1ed1 l\u01b0\u1ee3ng ng\u01b0\u1eddi ch\u1ebft l\u1edbn n\u00ean kh\u00f4ng th\u1ec3 b\u1ecf qua \u0111\u01b0\u1ee3c, cho n\u00ean, g\u1ed9p nh\u00f3m h\u1ed3i ph\u1ee5c v\u00e0 t\u1eed vong v\u00e0o nh\u00f3m R <br>\n\u1ede m\u00f4 h\u00ecnh n\u00e0y, ch\u1ec9 x\u00e9t tr\u01b0\u1eddng h\u1ee3p ng\u01b0\u1eddi c\u00f3 th\u1ec3 chuy\u1ec3n t\u1eeb tr\u1ea1ng th\u00e1i t\u1eeb $S$ sang $I$ v\u00e0 t\u1eeb $I$ sang $R$<br>\n![SIR_MODEL](https:\/\/www.lewuathe.com\/assets\/img\/posts\/2020-03-11-covid-19-dynamics-with-sir-model\/sir.png)\nTrong 1 th\u1eddi \u0111i\u1ec3m th\u00ec $S + I + R = N$, v\u1edbi N l\u00e0 t\u1ed5ng s\u1ed1 d\u00e2n. \u0110\u1ea1i l\u01b0\u1ee3ng c\u1ea7n \u0111\u01b0\u1ee3c quan t\u00e2m \u0111\u1ebfn ch\u00ednh l\u00e0 $I$ b\u1edfi n\u00f3 cho bi\u1ebft xu h\u01b0\u1edbng l\u00e2y lan v\u00e0 quy m\u00f4 c\u1ee7a d\u1ecbch b\u1ec7nh t\u1ea1i th\u1eddi \u0111i\u1ec3m \u0111ang x\u00e9t.<br>\nV\u00e0 v\u1edbi N l\u00e0 s\u1ed1 d\u00e2n (th\u00f4ng th\u01b0\u1eddng t\u1eeb v\u00e0i tri\u1ec7u \u0111\u1ebfn h\u00e0ng t\u1ec9), \u0111\u01b0\u1ee3c xem l\u00e0 1 \u0111\u1ea1i l\u01b0\u1ee3ng \u0111\u1ee7 l\u1edbn. Khi \u0111\u00f3, ta c\u00f3 h\u1ec7 sau: <br>\n\\begin{align*}\n& \\frac{\\mathrm{d}S}{\\mathrm{d}t}= -{\\beta S I}  \\\\\n& \\frac{\\mathrm{d}I}{\\mathrm{d}t}= {\\beta S I }- \\gamma I  \\\\\n& \\frac{\\mathrm{d}R}{\\mathrm{d}t}= \\gamma I  \\\\\n\\end{align*}\nTrong \u0111\u00f3 $\\beta$ l\u00e0 t\u1ec9 l\u1ec7 l\u00e2y nhi\u1ec5m, c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 x\u00e1c su\u1ea5t 1 ng\u01b0\u1eddi kh\u1ecfe m\u1ea1nh b\u1ecb nhi\u1ec5m. $\\gamma$ l\u00e0 t\u1ec9 l\u1ec7 h\u1ed3i ph\u1ee5c c\u1ee7a m\u1ed9t ng\u01b0\u1eddi\n","72231434":"### 4.2. H\u1ed3i quy tuy\u1ebfn t\u00ednh v\u1edbi \u0111\u1eb7c tr\u01b0ng lags <a id=\"section44\"><\/a>\nTa s\u1ebd s\u1eed d\u1ee5ng \u0111\u1eb7c tr\u01b0ng lags \u0111\u1ec3 th\u1ef1c hi\u1ec7n m\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n. Nh\u01b0ng m\u1ed9t v\u1ea5n \u0111\u1ec1 x\u1ea3y ra l\u00e0 ch\u00fang ta ch\u1ec9 bik \u0111\u01b0\u1ee3c th\u00f4ng tin v\u1ec1 ca nhi\u1ec5m c\u0169ng nh\u01b0 ca t\u1eed vong trong t\u1eadp hu\u1ea5n luy\u1ec7n n\u00ean c\u00f3 nhi\u1ec1u lags \u1edf nh\u1eefng ng\u00e0y sau mang gi\u00e1 tr\u1ecb 0. \u0110\u1ec3 gi\u1ea3i quy\u1ebft cho v\u1ea5n \u0111\u1ec1 n\u00e0y ta th\u1ef1c hi\u1ec7n ph\u01b0\u01a1ng ph\u00e1p sau:\n1. B\u1eaft \u0111\u1ea7u v\u1edbi t\u1eadp hu\u1ea5n luy\u1ec7n, khi m\u00e0 th\u00f4ng tin v\u1ec1 s\u1ed1 ca nhi\u1ec5m v\u00e0 \u0111\u1eb7c tr\u01b0ng lags c\u00f3 \u0111\u1ea7y \u0111\u1ee7\n2. D\u1ef1 \u0111o\u00e1n ng\u00e0y ti\u1ebfp theo v\u1edbi h\u1ed3i quy tuy\u1ebfn t\u00ednh\n3. G\u00e1n d\u1ef1 \u0111o\u00e1n v\u1eeba r\u1ed3i l\u00e0 gi\u00e1 tr\u1ecb ca nhi\u1ec5m c\u1ee7a ng\u00e0y h\u00f4m \u0111\u00f3\n4. T\u00ednh to\u00e1n l\u1ea1i lags\n5. L\u1eb7p \u0111i l\u1eb7p l\u1ea1i t\u1eeb b\u01b0\u1edbc 2 -> 4 cho c\u00e1c ng\u00e0y c\u00f2n l\u1ea1i.","c9d2a4cc":"**Gemany**","eca25fc9":"## 3.3 Nh\u1eadn x\u00e9t\nTrong kho\u1ea3ng th\u1eddi gian b\u1eaft \u0111\u1ea7u x\u00e9t l\u00e0 t\u1eeb ng\u00e0y 5 th\u00e1ng 4 n\u0103m 2020 \u0111\u1ebfn ng\u00e0y 5 th\u00e1ng 8 n\u0103m 2020. <br>\nNh\u00f3m tu\u1ed5i t\u1eeb 50-59 lu\u00f4n l\u00e0 nh\u00f3m c\u00f3 s\u1ed1 ca nhi\u1ec5m l\u1edbn nh\u1ea5t. Nh\u00f3m d\u01b0\u1edbi 19 tu\u1ed5i c\u00f3 s\u1ed1 ca nhi\u1ec5m \u00edt h\u01a1n c\u00e1c nh\u00f3m c\u00f2n l\u1ea1i (d\u01b0\u1edbi 1000 ca m\u1ed7i nh\u00f3m nh\u1ecf).  C\u00e1c nh\u00f3m tu\u1ed5i c\u00f2n l\u1ea1i c\u00f3 s\u1ed1 ca nhi\u1ec5m t\u1eeb kho\u1ea3ng 4000 \u0111\u1ebfn 7000 ca.  <br>\n\nTuy nhi\u00ean, v\u1edbi s\u1ed1 ca t\u1eed vong, ta th\u1ea5y r\u1eb1ng c\u00f3 s\u1ef1 ph\u00e2n h\u00f3a r\u1ea5t l\u1edbn. Nh\u00f3m t\u1eeb 60 tu\u1ed5i tr\u1edf l\u00ean c\u00f3 s\u1ed1 ca t\u1eed vong l\u1edbn h\u01a1n h\u1eb3n c\u00e1c nh\u00f3m c\u00f2n l\u1ea1i. <br>\n\nSau \u0111\u00e2y l\u00e0 t\u1ec9 l\u1ec7 t\u1eed vong trung b\u00ecnh c\u1ee7a t\u1eebng nh\u00f3m tu\u1ed5i\n                <pre><code>\n                0-9    :  0.0036805436389047916\n                10-19  :  0.0011339023561485675\n                20-29  :  0.0008836140413264112\n                30-39  :  0.003452531926642996\n                40-49  :  0.008284981036868547\n                50-59  :  0.019849466571340665\n                60-69  :  0.07255307531462857\n                70-79  :  0.19300914838215322\n                80+    :  0.3501340387535907\n<\/code><\/pre>\nV\u1eady v\u1edbi d\u1eef li\u1ec7u t\u1eeb bang Connecticut \u1edf M\u1ef9, ta c\u00f3 th\u1ec3 n\u00f3i r\u1eb1ng nh\u00f3m ng\u01b0\u1eddi **t\u1eeb 80 tu\u1ed5i tr\u1edf l\u00ean** khi nhi\u1ec5m COVID c\u00f3 kh\u1ea3 n\u0103ng ch\u1ebft cao h\u01a1n","b2f6cedc":"## 3.2 Bi\u1ec3u \u0111\u1ed3 th\u1ec3 hi\u1ec7n s\u1ed1 ca","47fe9a2b":"**Nh\u1eadn x\u00e9t**:\n* V\u1edbi m\u1ed9t m\u00f4 h\u00ecnh kh\u00e1 \u0111\u01a1n gi\u1ea3n th\u00ec qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n \u0111\u1ea1i d\u1ecbch \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n kh\u00e1 r\u00f5 r\u00e0ng.\n* Tuy nhi\u00ean, khi th\u1eddi gian c\u00e0ng v\u1ec1 sau m\u00f4 h\u00ecnh \u01b0\u1edbc t\u00ednh ng\u00e0y c\u00e0ng t\u1ec7, t\u1eeb \u0111\u00f3 cho th\u1ea5y m\u00f4 h\u00ecnh ch\u01b0a th\u1ef1c s\u1ef1 hi\u1ec7u qu\u1ea3 \u0111\u1ec3 \u01b0\u1edbc t\u00ednh c\u00e1c gi\u00e1 tr\u1ecb \u1edf t\u01b0\u1ee3ng l\u1ea1i.\n* C\u00e1c qu\u1ed1c gia g\u1ea7n \u0111\u00e2y \u0111\u00e3 x\u00e1c nh\u1eadn tr\u01b0\u1eddng h\u1ee3p l\u00e2y nhi\u1ec5m \u0111\u1ea7u ti\u00ean c\u1ee7a h\u1ecd r\u1ea5t kh\u00f3 d\u1ef1 \u0111o\u00e1n (\u00edt \u0111i\u1ec3m d\u1eef li\u1ec7u h\u01a1n)\n* C\u00e1c qu\u1ed1c gia c\u00f3 0 tr\u01b0\u1eddng h\u1ee3p trong to\u00e0n b\u1ed9 t\u1eadp d\u1eef li\u1ec7u hu\u1ea5n luy\u1ec7n \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n l\u00e0 kh\u00f4ng b\u1ecb nhi\u1ec5m (kh\u00f4ng c\u00f3 \u0111i\u1ec3m d\u1eef li\u1ec7u)","f5e14e6d":"### 1.2 Bi\u1ec3u \u0111\u1ed3 m\u00f4 ph\u1ecfng d\u1eef li\u1ec7u\n#### a. Bi\u1ec3u \u0111\u1ed3 tr\u00ean to\u00e0n b\u1ed9 c\u00e1c qu\u1ed1c gia","2464f0e5":"\u0110\u1ec3 gi\u1ea3i ph\u01b0\u01a1ng tr\u00ecnh vi ph\u00e2n v\u1edbi \u0111\u1ed9 ch\u00ednh x\u00e1c g\u1ea7n \u0111\u00fang, ta s\u1ebd s\u1eed d\u1ee5ng ph\u01b0\u01a1ng ph\u00e1p [Runge-Kutta](https:\/\/vi.wikipedia.org\/wiki\/Ph%C6%B0%C6%A1ng_ph%C3%A1p_Runge-Kutta). <br>\nPh\u01b0\u01a1ng ph\u00e1p n\u00e0y s\u1ebd gi\u00fap ch\u00fang ta t\u00ecm gi\u00e1 tr\u1ecb g\u1ea7n \u0111\u00fang c\u1ee7a Yn+1 khi \u0111\u00e3 bi\u1ebft \u0111\u01b0\u1ee3c gi\u00e1 tr\u1ecb c\u1ee7a Yn. \n    ","a8dcdc57":"### 1.3 \u0110\u00e1nh gi\u00e1\nTa nh\u1eadn th\u1ea5y r\u1eb1ng, h\u00ecnh d\u1ea1ng \u0111\u01b0\u1eddng cong trong bi\u1ec3u \u0111\u1ed3 tr\u00ean c\u00f3 s\u1ef1 t\u01b0\u01a1ng \u0111\u1ed3ng v\u1edbi m\u00f4 h\u00ecnh SIR<br>\nM\u00f4 h\u00ecnh SIR cho th\u1ea5y s\u1ef1 gia t\u0103ng l\u1edbn v\u1ec1 s\u1ed1 l\u01b0\u1ee3ng nhi\u1ec5m , m\u1ed9t khi n\u00f3 \u0111\u1ea1t \u0111\u1ebfn m\u1ee9c t\u1ed1i \u0111a c\u1ee7a b\u1ec7nh truy\u1ec1n nhi\u1ec5m, s\u1ebd gi\u1ea3m xu\u1ed1ng v\u1edbi \u0111\u1ed9 d\u1ed1c th\u1ea5p h\u01a1n. <br>\nCh\u1eb3ng h\u1ea1n nh\u01b0 \u0111\u1ed1i v\u1edbi Trung Qu\u1ed1c, s\u1ed1 l\u01b0\u1ee3ng ca nhi\u1ec5m d\u01b0\u1eddng nh\u01b0 \u0111\u1ea1t \u0111\u1ec9nh v\u00e0o th\u00e1ng gi\u1eefa th\u00e1ng 2, t\u1eeb \u0111\u00f3 s\u1ed1 ca nhi\u1ec5m b\u0103t \u0111\u1ea7u gi\u1ea3m xu\u1ed1ng<br>\nBi\u1ec3u \u0111\u1ed3 m\u00f4 h\u00ecnh SIR nh\u01b0 sau: <br>\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/2a\/Graph_SIR_model_without_vital_dynamics.svg\" alt=\"SIR MODEL\" title=\"Bi\u1ec3u \u0111\u1ed3 m\u00f4 h\u00ecnh SIR\">\nYellow=Susceptible, Maroon=Infectious, Teal=Recovered<br>\nSource: https:\/\/en.wikipedia.org\/wiki\/Compartmental_models_in_epidemiology \n","56000549":"**Nh\u1eadn x\u00e9t**:\n* **L\u01b0\u1ee3ng tham s\u1ed1:** 2 tu\u1ea7n \u0111\u1ea7y \u0111\u1ee7 t\u1eadp hu\u1ea5n luy\u1ec7n \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng (t\u1eeb 26\/02 to 11\/03), v\u1edbi s\u1ed1 l\u01b0\u1ee3ng tham s\u1ed1 lags l\u00e0 30\n* **D\u1eef li\u1ec7u \u0111\u1ea7y \u0111\u1ee7:**: (Spain, Italy, Germany). V\u1edbi nh\u1eefng qu\u1ed1c gia c\u00f3 d\u1eef li\u1ec7u \u0111\u1ea7y \u0111\u1ee7 v\u00e0 s\u1ed1 ca nhi\u1ec5m l\u1edbn h\u01a1n 0, vi\u1ec7c d\u1ef1 \u0111o\u00e1n c\u00f3 ph\u1ea7n ch\u00ednh x\u00e1c h\u01a1n v\u00e0 g\u1ea7n v\u1edbi d\u1eef li\u1ec7u th\u1ef1c t\u1ebf h\u01a1n\n* **D\u1eef li\u1ec7u thi\u1ebfu th\u1ed1n:** (Algeria, Andorra). V\u1edbi nh\u1eefng qu\u1ed1c gia d\u1eef li\u1ec7u nh\u1ecf th\u00ec kh\u00f4ng th\u1ec3 d\u1ef1 \u0111o\u00e1n t\u1ed1t. Vi\u1ec7c d\u1eef li\u1ec7u \u00edt d\u1eabn \u0111\u1ebfn vi\u1ec7c bi\u1ebfn \u0111\u1ed5i logarithm kh\u00f4ng n\u0103m \u0111\u01b0\u1ee3c \u0111\u1eb7c tr\u01b0ng c\u1ee7a di\u1ec5n bi\u1ebfn trong t\u01b0\u01a1ng lai.\n* **Kh\u00f4ng c\u00f3 d\u1eef li\u1ec7u:**. V\u1edbi c\u00e1c qu\u1ed1c gia kh\u00f4ng c\u00f3 d\u1eef li\u1ec7u, th\u00ec m\u00f4 h\u00ecnh lu\u00f4n \u0111o\u00e1n kh\u00f4ng b\u1ecb nhi\u1ec5m.","ebbc9934":"## Danh s\u00e1ch th\u00e0nh vi\u00ean\n    1. L\u00e2m \u0110\u1ee9c Anh - 1712273\n    2. Ho\u00e0ng \u0110\u1ee9c C\u00f4ng - 1712304\n    3. Tr\u01b0\u01a1ng Kh\u1eafc Tri\u1ec7u - 1712838\n","12b8d9ec":"### 2.2 Tri\u1ec3n khai m\u00f4 h\u00ecnh SIR","2ee0e15c":"#### b. Bi\u1ec3u \u0111\u1ed3 t\u1ea1i c\u00e1c qu\u1ed1c gia \u0111ang c\u00f3 s\u1ed1 ca nhi\u1ec5m \u0111\u1ee9ng \u0111\u1ea7u\nT\u00ednh \u0111\u1ebfn ng\u00e0y 4 th\u00e1ng 8 n\u0103m 2020, c\u00e1c n\u01b0\u1edbc c\u00f3 s\u1ed1 l\u01b0\u1ee3ng ca nhi\u1ec5m nhi\u1ec1u tr\u00ean 500000 ca g\u1ed3m: US, Brazil, India, Russia, South Africa<br>\nC\u00f3 quan t\u00e2m \u0111\u1ebfn m\u00f4 h\u00ecnh \u1edf Trung Qu\u1ed1c, n\u01a1i kh\u1edfi ph\u00e1t c\u1ee7a d\u1ecbch b\u1ec7nh","9d4df8ee":"### 3.3. Th\u00eam c\u00e1c th\u00f4ng tin v\u1ec1 qu\u1ed1c gia <a id=\"section33\"><\/a>\n\nC\u00e1c th\u00f4ng tin v\u1ec1: t\u1ed5ng d\u00e2n s\u1ed1 c\u1ee7a m\u1ed9t qu\u1ed1c gia, tu\u1ed5i trung b\u00ecnh c\u1ee7a d\u00e2n th\u00e0nh th\u1ecb ho\u1eb7c t\u1ec9 l\u1ec7 ng\u01b0\u1eddi s\u1ed1ng trong th\u00e0nh ph\u1ed1 c\u00f3 th\u1ec3 \u1ea3nh h\u01b0\u1edbng \u0111\u1ebfn kh\u1ea3 n\u0103ng l\u00e2y truy\u1ec1n c\u1ee7a Covid. T\u1eeb \u0111\u00f3, Ch\u00fang ta s\u1ebd th\u00eam d\u1eef li\u1ec7u v\u1ec1 c\u00e1c y\u1ebfu t\u1ed1 tr\u00ean b\u1ed9 d\u1eef li\u1ec7u ch\u00fang ta [Tanu's dataset](https:\/\/www.kaggle.com\/tanuprabhu\/population-by-country-2020).","58e35d33":"**Andorra**","9b01e735":"# \u0110\u1ed3 \u00e1n cu\u1ed1i k\u00ec m\u00f4n To\u00e1n \u1ee9ng d\u1ee5ng v\u00e0 th\u1ed1ng k\u00ea\n## X\u00e2y d\u1ef1ng m\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n: Nhi\u1ec5m, nhi\u1ec5m kh\u1ecfi, nhi\u1ec5m ch\u1ebft, kh\u00f4ng nhi\u1ec5m t\u1eeb d\u1eef li\u1ec7u COVID-19\n## Nh\u00f3m ng\u01b0\u1eddi d\u1ec5 ch\u1ebft khi nhi\u1ec5m COVID-19","7c23831e":"## 1. Ph\u00e2n t\u00edch d\u1eef li\u1ec7u\nDatasets l\u1ea5y t\u1eeb Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). <br>\nLink \u0111\u1ebfn repository ch\u1ee9a datasets: https:\/\/github.com\/CSSEGISandData\/COVID-19 <br>\nBao g\u1ed3m s\u1ed1 ca confirms, deaths, v\u00e0 recovered<br>\nM\u1ed7i file d\u1eef li\u1ec7u c\u00f3 c\u1ea5u tr\u00fac Province\/State, Country\/Region, Lat, Long, n c\u1ed9t ti\u1ebfp theo l\u00e0 c\u1eadp nh\u1eadt s\u1ed1 ca theo ng\u00e0y<br>\nNg\u00e0y update cu\u1ed1i l\u00e0 ng\u00e0y 05 th\u00e1ng 08 n\u0103m 2020","24e4c847":"# C\u00e2u 1: C\u00e1c m\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n","964417b5":"### 3.2. T\u00ednh hai \u0111\u1eb7c tr\u01b0ng m\u1edbi lags v\u00e0 trends <a id=\"section32\"><\/a>\n\n**Lag**: l\u00e0 gi\u00e1 tr\u1ecb \u1edf b\u01b0\u1edbc th\u1eddi gian tr\u01b0\u1edbc \u0111\u00f3 c\u1ee7a c\u1ed9t, ch\u1eb3ng h\u1ea1n gi\u00e1 tr\u1ecb c\u1ee7a $lag_1$ s\u1ed1 ca nhi\u1ec5m s\u1ebd b\u1eb1ng gi\u00e1 tr\u1ecb c\u1ee7a s\u1ed1 ca nhi\u1ec5m c\u1ee7a ng\u00e0y h\u00f4m tr\u01b0\u1edbc. V\u00e0 $lag_p$ c\u1ee7a thu\u1ed9c t\u00ednh X c\u00f3 d\u1ea1ng  \n$$X_{lag_p}(t) = X(t-p)$$\n\n\n**Trend**: T\u1ef7 l\u1ec7 t\u0103ng hay gi\u1ea3m c\u1ee7a thu\u1ed9c t\u00ednh \u0111\u00f3 \u1edf th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i so v\u1edbi p b\u01b0\u1edbc th\u1eddi \u0111i\u1ec3m tr\u01b0\u1edbc \u0111\u00f3. \u0110\u1ecbnh ngh\u0129a trend b\u1eadc p c\u1ee7a thu\u1ed9c t\u00ednh X nh\u01b0 sau: \n$$Trend_p(X(t)) = {X(t) - X(t-p) \\over X(t-p)}$$\n","5d7dc20b":"### 3.1. Ti\u1ec1n x\u1eed l\u00fd d\u1eef li\u1ec7u <a id=\"section31\"><\/a>\n\nC\u00e1c c\u00f4ng vi\u1ec7c trong ti\u1ec1n x\u1eed l\u00fd d\u1eef li\u1ec7u\n\n* **G\u1ed9p d\u1eef li\u1ec7u**: g\u1ed9p t\u1eadp hu\u1ea5n luy\u1ec7n v\u00e0 t\u1eadp ki\u1ec3m th\u1eed th\u00e0nh m\u1ed9t t\u1eadp d\u1eef li\u1ec7u m\u1edbi \u0111\u1ec3 bi\u1ebfn \u0111\u1ed5i.\n* **L\u1ecdc ng\u00e0y**: x\u00f3a ConfirmedCases v\u00e0 Fatalities sau 12\/03\/2020. t\u1ea1o c\u1ed9t thu\u1ed9c t\u00ednh \"date\".\n* **M\u1ea5t d\u1eef li\u1ec7u**: thay th\u1ebf c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u b\u1ecb m\u1ea5t.","74ac2bfe":"Ki\u1ec3m tra xem d\u1eef li\u1ec7u c\u00f2n thi\u1ebfu hay kh\u00f4ng ?","7cbc4a6b":"### Kh\u1edbp m\u00f4 h\u00ecnh SIR v\u1edbi to\u00e0n b\u1ed9 qu\u1ed1c gia","7076621f":"**Italy**","72a82d70":"## 3.1 Chu\u1ea9n h\u00f3a d\u1eef li\u1ec7u\nCh\u1ec9 s\u1eed d\u1ee5ng \u0111\u01b0\u1ee3c d\u1eef li\u1ec7u c\u1ee7a bang Connecticut \u1edf M\u1ef9. Tuy nhi\u00ean, s\u1ed1 l\u01b0\u1ee3ng ca nhi\u1ec5m t\u1ea1i ng\u00e0y cu\u1ed1i c\u00f9ng l\u1ea5y d\u1eef li\u1ec7u l\u00e0 50189 kh\u00e1 l\u1edbn. Cho n\u00ean d\u00f9ng d\u1eef li\u1ec7u n\u00e0y \u0111\u1ec3 ph\u00e2n t\u00edch nh\u00f3m em cho r\u1eb1ng c\u00f3 th\u1ec3 ch\u1ea5p nh\u1eadn \u0111\u01b0\u1ee3c. <br> \n\u1ede d\u1eef li\u1ec7u ban \u0111\u1ea7u, c\u00e1c gi\u00e1 tr\u1ecb trong age groups c\u00f3 s\u1ef1 kh\u00e1c nhau. Cho n\u00ean s\u1eeda l\u1ea1i c\u00e1c gi\u00e1 tr\u1ecb c\u1ee7a age group \u0111\u1ec3 d\u1ec5 d\u00e0ng x\u1eed l\u00fd h\u01a1n <br>\nNg\u00e0y th\u00e1ng \u1edf DateUpdated kh\u00f4ng theo th\u1ee9 t\u1ef1 \n","30560cfc":"### 2.3 Kh\u1edbp m\u00f4 h\u00ecnh v\u1edbi d\u1eef li\u1ec7u","693ab68b":"### 1.1 \u0110\u1ecdc v\u00e0 ph\u00e2n t\u00edch c\u1ea5u tr\u00fac d\u1eef li\u1ec7u ","88305286":"**Spain**","5456491a":"# C\u00e2u 3: \u0110\u1ed1i t\u01b0\u1ee3ng d\u1ec5 ch\u1ebft khi nhi\u1ec5m COVID-19\nDatasets \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb 3 ngu\u1ed3n: \n    - https:\/\/github.com\/nytimes\/covid-19-data\n    - https:\/\/data.cdc.gov\/NCHS\/Provisional-COVID-19-Death-Counts-by-Sex-Age-and-W\/vsak-wrfu\n    - https:\/\/catalog.data.gov\/dataset\/covid-19-confirmed-cases-and-deaths-by-age-group\/","21324b6c":"**China\/Hubei**\n","ca1b217e":"## 4. S\u1eed d\u1ee5ng m\u00f4 h\u00ecnh Linear Regression \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n giai \u0111o\u1ea1n \u0111\u1ea7u \u0111\u1ea1i d\u1ecbch <a id=\"section4\"><\/a>\n\nC\u00e1c m\u00f4 h\u00ecnh s\u1eed d\u1ee5ng\n1. Linear Regression cho m\u1ed9t qu\u1ed1c gia\n2. Linear Regression v\u1edbi \u0111\u1eb7c tr\u01b0ng lags","695c20aa":"### Kh\u1edbp m\u00f4 h\u00ecnh SIR v\u1edbi 1 n\u01b0\u1edbc. L\u1ea5y v\u00ed d\u1ee5 l\u00e0 US, \u0111ang c\u00f3 s\u1ed1 d\u00e2n l\u00e0 330578810.","dd3a7604":"## 3. T\u0103ng c\u01b0\u1eddng d\u1eef li\u1ec7u <a id=\"section3\"><\/a>\nVi\u1ec7c ph\u00e2n t\u00edch m\u00f4 h\u00ecnh SIR b\u00ean tr\u00ean nh\u1eb1m t\u00ecm hi\u1ec3u m\u00f4 h\u00ecnh g\u1ea7n gi\u1ed1ng v\u1edbi c\u01a1 ch\u1ebf lan truy\u1ec1n c\u1ee7a nhi\u1ec1u lo\u1ea1i virus, bao g\u1ed3m c\u1ea3 COVID-19. Ngo\u00e0i ra, ch\u00fang ta c\u00f3 nhi\u1ec1u ph\u01b0\u01a1ng ph\u00e1p kh\u00e1c h\u1eefu \u00edch t\u01b0\u01a1ng t\u1ef1 \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n v\u00e0 hi\u1ec3u h\u01a1n v\u1ec1 qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n \u0111\u1ea1i d\u1ecbch. C\u00e1c ph\u01b0\u01a1ng ph\u00e1p \u0111\u00f2i h\u1ecfi d\u1eef li\u1ec7u \u0111\u1ea7y \u0111\u1ee7 h\u01a1n \u0111\u1ec3 r\u00fat tr\u00edch ra c\u00e1c k\u1ebft lu\u1eadn v\u00e0 \u0111\u1ea3m b\u1ea3o thu\u1eadt to\u00e1n ph\u00e1t hi\u1ec7n \u0111\u01b0\u1ee3c c\u00e1c tri th\u1ee9c trong d\u1eef li\u1ec7u. \u0110\u00f3 c\u0169ng l\u00e0 m\u1ee5c \u0111\u00edch cho vi\u1ec7c m\u1edf r\u1ed9ng d\u1eef li\u1ec7u.  \n\n\nC\u00e1c c\u00f4ng vi\u1ec7c ch\u00ednh trong m\u1edf r\u1ed9ng d\u1eef li\u1ec7u\n1. Ti\u1ec1n x\u1eed l\u00fd d\u1eef li\u1ec7u (x\u1eed l\u00fd c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u b\u1ecb m\u1ea5t, ...)\n2. T\u00ednh to\u00e1n c\u00e1c \u0111\u1eb7c tr\u01b0ng m\u1edbi lags v\u00e0 trends\n3. Th\u00eam th\u00f4ng tin qu\u1ed1c gia\n","7b2b4b2f":"### 4.1. Linear Regression cho m\u1ed9t qu\u1ed1c gia <a id=\"section41\"><\/a>\n\nV\u00ec ch\u00fang ta quan t\u00e2m \u0111\u1ebfn vi\u1ec7c d\u1ef1 \u0111o\u00e1n di\u1ec5n bi\u1ebfn theo th\u1eddi gian trong t\u01b0\u01a1ng lai c\u1ee7a \u0111\u1ea1i d\u1ecbch, n\u00ean c\u00e1ch ti\u1ebfp c\u1eadn \u0111\u1ea7u ti\u00ean c\u1ee7a ch\u00fang ta bao g\u1ed3m m\u00f4 h\u00ecnh h\u1ed3i quy tuy\u1ebfn t\u00ednh \u0111\u01a1n gi\u1ea3n. Tuy nhi\u00ean, s\u1ef1 ph\u00e1t tri\u1ec3n \u0111\u1ea1i d\u1ecbch kh\u00f4ng ph\u1ea3i tuy\u1ebfn t\u00ednh m\u00e0 l\u00e0 theo c\u1ea5p s\u1ed1 nh\u00e2n (ch\u1ec9 trong giai \u0111o\u1ea1n \u0111\u1ea7u c\u1ee7a qu\u00e1 tr\u00ecnh l\u00e2y nhi\u1ec5m), do \u0111\u00f3 c\u1ea7n c\u00f3 m\u1ed9t ph\u00e9p bi\u1ebfn \u0111\u1ed5i logarithm.","97da8075":"### 5.1. Logistic curve fit <a id=\"section51\"><\/a>"}}