{"cell_type":{"fc41208e":"code","6d33d9be":"code","e6deb9b7":"code","ebac821e":"code","a305ae23":"code","c99185f8":"code","9c476679":"code","a7ca8f49":"code","ba03154d":"code","df222a1e":"code","bbd38292":"code","b51b501a":"code","6e286582":"code","1d684414":"code","202313e5":"code","9f837054":"code","5139e6af":"code","c766d8b1":"code","efad30ca":"code","3a8d72d7":"code","5164d7ff":"code","6b3296e0":"code","a3a6f334":"code","d66ca083":"code","0e08d0e2":"code","177a30d9":"code","3ed44bf3":"code","61721a57":"code","1ae1e6db":"code","f5727ee0":"code","643b5c50":"code","59a84ab1":"code","a11debc0":"code","d3271057":"code","67932e9b":"code","b62e36d8":"code","25ef3650":"code","ee646345":"code","2efff23a":"code","3a201746":"code","f0c9042a":"code","8d5ba1af":"code","434a140e":"code","cb7b0aa7":"markdown","33297125":"markdown","ab1d8ce9":"markdown","30851715":"markdown","6583d63b":"markdown","36d1b451":"markdown","cc7a8e7c":"markdown","5f043e0b":"markdown","29db1bcf":"markdown","e908c27d":"markdown","678fa7f3":"markdown","a0c596d5":"markdown","fad420eb":"markdown","43445b17":"markdown","dcef63ec":"markdown","211c1d3e":"markdown"},"source":{"fc41208e":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np","6d33d9be":"# loading the training dataset\ntrain_dataset = pd.read_csv('..\/input\/titanic\/train.csv')","e6deb9b7":"train_dataset.head()","ebac821e":"train_dataset.info()","a305ae23":"# creating a copy of training dataset to work with\nwork_dataset = train_dataset.copy()","c99185f8":"work_dataset = work_dataset.set_index('PassengerId')","9c476679":"work_dataset = work_dataset.drop(['Name', 'Ticket', 'Cabin'], axis = 1)","a7ca8f49":"work_dataset.head()","ba03154d":"# we can use label encoder for conversion of numeric data\nfrom sklearn.preprocessing import LabelEncoder\ndef encoding(feature):\n    if (feature.dtype == 'object'):\n        return LabelEncoder().fit_transform(feature)\n    else:\n        return feature","df222a1e":"# dropping missing values\nwork_dataset = work_dataset.dropna()","bbd38292":"work_dataset = work_dataset.apply(encoding)","b51b501a":"work_dataset.head()","6e286582":"import seaborn as sns\nsns.pairplot(work_dataset)","1d684414":"work_dataset = work_dataset[work_dataset['Fare'] < 200]\nsns.distplot(work_dataset['Fare'])","202313e5":"work_dataset.shape","9f837054":"# splitting the training and testing dataset.\nfrom sklearn.model_selection import train_test_split\nX = work_dataset.drop(['Survived'], axis = 1)\ny = work_dataset[['Survived']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 22)","5139e6af":"# Importing Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)\npredict = classifier.predict(X_test)","c766d8b1":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score","efad30ca":"print(confusion_matrix(predict, y_test))\nprint(classification_report(predict, y_test))\naccuracy_before = accuracy_score(predict, y_test)*100\nprint(accuracy_before)","3a8d72d7":"work_dataset.loc[:,['Age', 'Fare']].describe()","5164d7ff":"sns.distplot(work_dataset.loc[:,['Age']])","6b3296e0":"sns.distplot(work_dataset.loc[:,['Fare']])","a3a6f334":"work_dataset['Fare'] = pd.cut(x = work_dataset.Fare, bins = 17, labels = range(17))\nwork_dataset['Age'] = pd.cut(x = work_dataset.Age, bins = 8, labels = range(8))","d66ca083":"sns.distplot(work_dataset.Age, kde = False)","0e08d0e2":"sns.distplot(work_dataset.Fare, kde = False)","177a30d9":"X = work_dataset.drop(['Survived'], axis = 1)\ny = work_dataset[['Survived']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 22)","3ed44bf3":"classifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)\npredict = classifier.predict(X_test)","61721a57":"print(confusion_matrix(predict, y_test))\nprint(classification_report(predict, y_test))\naccuracy_after = accuracy_score(predict, y_test)*100\nprint(accuracy_after)","1ae1e6db":"print(accuracy_before)\nprint(accuracy_after)","f5727ee0":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nc = DecisionTreeClassifier()\nc.fit(X_train, y_train)\npredict = c.predict(X_test)\naccuracy = accuracy_score(predict, y_test)*100\nprint(accuracy)","643b5c50":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nc_knn = KNeighborsClassifier(n_neighbors = 11)\nc_knn.fit(X_train, y_train)\npredict = c_knn.predict(X_test)\naccuracy = accuracy_score(predict, y_test)*100\nprint(accuracy)","59a84ab1":"# MLP\nfrom sklearn.neural_network import MLPClassifier\nc = MLPClassifier(hidden_layer_sizes = (100,))\nc.fit(X_train, y_train)\npredict = c.predict(X_test)\naccuracy = accuracy_score(predict, y_test)*100\nprint(accuracy)","a11debc0":"# SVC\nfrom sklearn.svm import SVC\nc = SVC()\nc.fit(X_train, y_train)\npredict = c.predict(X_test)\naccuracy = accuracy_score(predict, y_test)*100\nprint(accuracy)","d3271057":"# importing the test dataset\ntest_dataset = pd.read_csv('..\/input\/titanic\/test.csv')","67932e9b":"test_dataset.head()","b62e36d8":"work_test_dataset = test_dataset.copy()\n# making the Id as index or we can drop this ID\nwork_test_dataset = work_test_dataset.set_index('PassengerId')\n# removing the columns that we removed from the training dataset\nwork_test_dataset = work_test_dataset.drop(['Name', 'Ticket', 'Cabin'], axis = 1)\n# converting the non numeric into numeric values\nwork_test_dataset = work_test_dataset.apply(encoding)","25ef3650":"work_test_dataset.head()","ee646345":"# checking for missing values\nwork_test_dataset.isnull().sum()","2efff23a":"# importing simple imputer\nfrom sklearn.impute import SimpleImputer\nimpute = SimpleImputer(strategy = 'mean')\nfinal_test_dataset = pd.DataFrame(impute.fit_transform(work_test_dataset), columns = work_test_dataset.columns)","3a201746":"final_test_dataset.isnull().sum()","f0c9042a":"# applying the trained KNN classifier\nsurvived = c_knn.predict(final_test_dataset)","8d5ba1af":"submission = pd.DataFrame({'PassengerId':test_dataset.PassengerId, 'Survived':survived})","434a140e":"submission.to_csv('submission.csv', index = False)","cb7b0aa7":"Age is normally distributed (approximately).","33297125":"Learning never ends for everyone. Your suggestions and other creative ideas are much appreciated. ","ab1d8ce9":"The column - Cabin contains only 204 rows. So the column can be removed.","30851715":"Now we shall apply the algorithm and check the accuracy","6583d63b":"KNN is the best classifier for the dataset","36d1b451":"Inferences: \n1. PassengerId is the Identity column and Survived is the target column. \n2. The columns Name and Ticket can be removed","cc7a8e7c":"There are some outlieres in the feature Fare. The skewness is positively skewed.","5f043e0b":"We need to convert Sex and Embarked into binary values. There are two missing values in Embarked. They can be dropped or replaced by mean.","29db1bcf":"The accuracy after binning is higher than accuracy before binning. Now we can apply to the unknown dataset and predict the results","e908c27d":"Now predicting the values with the model","678fa7f3":"We have to impute the missing values. We can use simple imputer to impute the missing values","a0c596d5":"We can bin the Age and Fare. First we will apply this dataset to classification algorithm and check the accuracy. Then we shall bin and see the accuracy again.","fad420eb":"Generating the CSV file","43445b17":"Let us try binning the Age and Fare features and see the accuracy","dcef63ec":"To all Fellow learners, Good Luck.","211c1d3e":"Let us try with different classification algorithms:"}}