{"cell_type":{"de2ec7eb":"code","383ad270":"code","7de90d9c":"code","9ceac583":"code","137ffab5":"code","de23849b":"code","9a6dcf6c":"code","2b56cc11":"code","cb191026":"code","15359e60":"code","4e2073d8":"code","d6b444e6":"code","c28854c4":"code","68744926":"code","52b6722d":"code","7c5cbb55":"code","4188fa6e":"code","1551361c":"code","36595f90":"code","393c15b7":"code","99b46ece":"code","5a21403e":"code","6e314fdd":"code","70d002fb":"code","4300e69d":"code","9321786d":"code","9500b40b":"code","f37a0d17":"code","989930af":"code","01bb9f04":"code","93f1ef67":"code","6aea911e":"code","bf7e000a":"code","acc39fd0":"code","7e8a6b63":"code","26236932":"code","69cf9b1b":"code","bc3cde05":"code","18884497":"code","eb18c773":"code","6cbe9897":"code","e2d11381":"code","f4f17db1":"code","e7fe0ce6":"code","660751cd":"code","60535f42":"code","6d472ef4":"code","caa12da6":"code","17a81403":"code","e73b9ac3":"code","c897b119":"code","f6514f1f":"code","8a84e9d2":"code","73a69980":"code","7f599e25":"code","29262312":"code","3fd6ff55":"code","50e38ac0":"code","7386d32b":"code","74bd4769":"code","4f5439fb":"code","22244294":"code","a68d6853":"code","1bcd1d90":"code","f12f9217":"code","dd70b031":"code","92682474":"code","22c135bf":"code","567f7f7f":"code","b0070025":"code","b9edeaff":"code","5ac52f10":"code","7052a67f":"code","aa09686c":"code","d0c52497":"code","f0c83feb":"code","5d36a8a0":"code","f2b7a3d6":"code","074da0ea":"code","363d8d6a":"markdown","d42fa504":"markdown","013e6581":"markdown","b5f2377c":"markdown","45fe9694":"markdown","2e21d5fc":"markdown","e282bd1f":"markdown","3dbd8cb0":"markdown","8eac5e66":"markdown","67d0a46b":"markdown","d1e129c2":"markdown","e47fe407":"markdown","23dc2e3b":"markdown","9b1be744":"markdown","5ab004b3":"markdown","ec8df2b7":"markdown","d3bbc3ba":"markdown","e0cef651":"markdown","04c25d87":"markdown","d4d3afa5":"markdown","5e883d33":"markdown","240ad547":"markdown","e67f13a4":"markdown","17052b07":"markdown","ad05cffa":"markdown","b904f8b9":"markdown","8bd6600f":"markdown","eae5a3d7":"markdown","ddbabc09":"markdown","1771184f":"markdown","f4576a32":"markdown","f9542472":"markdown","04566e8e":"markdown","2b709848":"markdown","6ed8fdd8":"markdown","dfc2131b":"markdown","2c67ebca":"markdown","5c14b80a":"markdown","251f93c9":"markdown","7fc5657a":"markdown","679fdbee":"markdown","92714f95":"markdown","e3876345":"markdown","894ecc26":"markdown","b880df05":"markdown","010288b0":"markdown","f1b770c3":"markdown","51841e6e":"markdown","19fb7b23":"markdown","b26efbb5":"markdown","f36b429f":"markdown","b507f988":"markdown","9d83a275":"markdown","d44fd61e":"markdown","ddb3a798":"markdown","8ccc2467":"markdown","d93ab6a9":"markdown","2ccd70e3":"markdown","8d50008a":"markdown","ceb464ec":"markdown","f8a00aaa":"markdown","0168a775":"markdown","967ab793":"markdown","88777772":"markdown","aef3ef1d":"markdown","67b02ae8":"markdown","dd59439a":"markdown","e56d90b8":"markdown","61b2e672":"markdown","4baf30ed":"markdown","b31dd1df":"markdown","43a7728f":"markdown"},"source":{"de2ec7eb":"import requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\n\n!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes}\nimport folium # plotting library\n\nprint('Folium installed')\nprint('Libraries imported.')","383ad270":"#import numpy as np # library to handle data in a vectorized manner\nimport time\n#import pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n#import folium # map rendering library\nimport folium # map rendering library\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nimport seaborn as sns\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\nprint('Libraries imported.')","7de90d9c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9ceac583":"# load data\ndf_s = pd.read_csv('\/kaggle\/input\/berlin-airbnb-data\/listings_summary.csv')\n","137ffab5":"df_s.head()","de23849b":"df_s.shape","9a6dcf6c":"df_s.columns","2b56cc11":"columns_to_keep = ['id','host_has_profile_pic','host_since',\n                   'latitude', 'longitude','property_type', 'room_type', 'accommodates', 'bathrooms',  \n                   'bedrooms', 'bed_type', 'amenities', 'price', 'cleaning_fee',\n                   'security_deposit', 'minimum_nights',  \n                   'instant_bookable', 'cancellation_policy','availability_365','neighbourhood_cleansed','neighbourhood_group_cleansed']\ndf_s= df_s[columns_to_keep].set_index('id')","cb191026":"df_s.shape","15359e60":"total = df_s.isnull().sum().sort_values(ascending = False)\npercent = (df_s.isnull().sum()\/df_s.isnull().count()*100).sort_values(ascending = False)\nmissing_df_s  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_df_s.head(3)","4e2073d8":"#Convert f,t to 0 or 1\ndf_s['instant_bookable'] = df_s['instant_bookable'].map({'f':0,'t':1})\n#fill f for N\/A in host_has_profile_pic column for further correct mapping\nset(df_s['host_has_profile_pic'])\ndf_s['host_has_profile_pic'].fillna('f',inplace=True)\n#Convert f,t to 0 or 1\ndf_s['host_has_profile_pic'] = df_s['host_has_profile_pic'].map({'f':0,'t':1})\n","d6b444e6":"#Remove $ from price, fee columns and convert to float\ndf_s['price'] = df_s['price'].str.replace('$', '').str.replace(',', '').astype(float)\ndf_s['cleaning_fee'] = df_s['cleaning_fee'].str.replace('$', '').str.replace(',', '').astype(float)\ndf_s['security_deposit'] = df_s['security_deposit'].str.replace('$', '').str.replace(',', '').astype(float)\n","c28854c4":"#cleaning_fee cleanup of N\/a replace with median value\ndf_s['cleaning_fee'].fillna(df_s['cleaning_fee'].median(), inplace=True)\n#security_deposit cleanup of N\/a replace with median value\ndf_s['security_deposit'].fillna(df_s['security_deposit'].median(), inplace=True)\n#cleanup bathroom , bedroom columns\ndf_s['bathrooms'].fillna(1,inplace=True)\ndf_s['bedrooms'].fillna(1,inplace=True)","68744926":"total = df_s.isnull().sum().sort_values(ascending = False)\npercent = (df_s.isnull().sum()\/df_s.isnull().count()*100).sort_values(ascending = False)\nmissing_df  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_df.head(3)","52b6722d":"#Check distribution of price column\ndf_s.describe()\n","7c5cbb55":"df_s['price'].describe()\n","4188fa6e":"df_s.drop(df_s[ (df_s.price > 180) | (df_s.price == 0) | (df_s.price == 1) ].index, axis=0, inplace=True)\n\ndf_s['price'].describe()","1551361c":"# boxplot of price column\nred_square = dict(markerfacecolor='r', markeredgecolor='r', marker='.')\ndf_s['price'].plot(kind='box', xlim=(0, 180), vert=False, flierprops=red_square, figsize=(15,3));\n","36595f90":"import seaborn as sns\nsns.distplot(df_s['price'],bins=15)","393c15b7":"sns.boxplot(x='room_type',y='price',data = df_s)\nplt.show()","99b46ece":"sns.boxplot(x='bedrooms', y= 'price', data=df_s)","5a21403e":"nh = df_s['neighbourhood_group_cleansed'].value_counts().reset_index()\nnh.columns = ['neighbourhood_group_cleansed' ,'Count']\nnh['Percent'] = nh['Count']\/nh['Count'].sum() * 100\nnh.head()","6e314fdd":"sns.set(rc={'figure.figsize':(11.7,8.27)})\nax = sns.countplot(x=\"neighbourhood_group_cleansed\", hue=\"neighbourhood_group_cleansed\", data=df_s,\n              order=df_s['neighbourhood_group_cleansed'].value_counts().iloc[:5].index)\nplt.title('Popular Neighborhoods')\nplt.ylabel('Count')\nplt.xlabel('neighbourhood_group_cleansed')\nplt.show()\n","70d002fb":"ax = sns.countplot(x=\"room_type\", data=df_s)\nplt.title('Room Type distribution')\nplt.xlabel('Room Type')\nplt.ylabel('Frequency')\nplt.show()","4300e69d":"plt.figure(figsize=(10,10))\nax = sns.countplot(x=\"room_type\", data=df_s,hue=\"neighbourhood_group_cleansed\")\n","9321786d":"#nominal_categorical bed_type and property_type\nfor i in [\"bed_type\",\"property_type\",\"cancellation_policy\"]:\n    x = df_s[[i]]\n    x.room_type = pd.Categorical(x[i])\n    del df_s[i]\n    dummies = pd.get_dummies(x, prefix = i)\n    df_s = pd.concat([df_s,dummies], axis=1)\n\n    df_s.head(3)","9500b40b":"df_s['Laptop_friendly_workspace'] = df_s['amenities'].str.contains('Laptop friendly workspace')\ndf_s['TV'] = df_s['amenities'].str.contains('TV')\ndf_s['Family_kid_friendly'] = df_s['amenities'].str.contains('Family\/kid friendly')\ndf_s['Host_greets_you'] = df_s['amenities'].str.contains('Host greets you')\ndf_s['Smoking_allowed'] = df_s['amenities'].str.contains('Smoking allowed')\ndf_s['Hot_water'] = df_s['amenities'].str.contains('Hot water')\ndf_s['Fridge'] = df_s['amenities'].str.contains('Refrigerator')","f37a0d17":"df_s['No_of_amentities'] = df_s['amenities'].apply(lambda x:len(x.split(',')))","989930af":"# dropping amenities as we have inferred above as different categories\ndropped = ['amenities']\ndf_s.drop(dropped,axis=1,inplace=True)","01bb9f04":"#Convert false,true to 0 or 1\ndf_s['Laptop_friendly_workspace'] = df_s['Laptop_friendly_workspace'].astype(int)\ndf_s['TV'] = df_s['TV'].astype(int)\ndf_s['Family_kid_friendly'] = df_s['Family_kid_friendly'].astype(int)\ndf_s['Host_greets_you'] = df_s['Host_greets_you'].astype(int)\ndf_s['Smoking_allowed'] = df_s['Smoking_allowed'].astype(int)\ndf_s['Hot_water'] = df_s['Hot_water'].astype(int)\ndf_s['Fridge'] = df_s['Fridge'].astype(int)","93f1ef67":"#Calculate distance from central berlin\ndef haversine_distance_central(row):\n    berlin_lat,berlin_long = radians(52.5200), radians(13.4050)\n    R = 6373.0\n    long = radians(row['longitude'])\n    lat = radians(row['latitude'])\n    \n    dlon = long - berlin_long\n    dlat = lat - berlin_lat\n    a = sin(dlat \/ 2)**2 + cos(lat) * cos(berlin_lat) * sin(dlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    return R * c","6aea911e":"#Calculate distance from airport\ndef haversine_distance_airport(row):\n    berlin_lat,berlin_long = radians(52.3733), radians(13.5064)\n    R = 6373.0\n    long = radians(row['longitude'])\n    lat = radians(row['latitude'])\n    \n    dlon = long - berlin_long\n    dlat = lat - berlin_lat\n    a = sin(dlat \/ 2)**2 + cos(lat) * cos(berlin_lat) * sin(dlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    return R * c","bf7e000a":"#Calculate distance from berlin railway station\ndef haversine_distance_rail(row):\n    berlin_lat,berlin_long = radians(52.5073), radians(13.3324)\n    R = 6373.0\n    long = radians(row['longitude'])\n    lat = radians(row['latitude'])\n    \n    dlon = long - berlin_long\n    dlat = lat - berlin_lat\n    a = sin(dlat \/ 2)**2 + cos(lat) * cos(berlin_lat) * sin(dlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    return R * c","acc39fd0":"from math import sin, cos, sqrt, atan2, radians","7e8a6b63":"df_s['distance_central'] = df_s.apply(haversine_distance_central,axis=1)\ndf_s['distance_airport'] = df_s.apply(haversine_distance_airport,axis=1)\ndf_s['distance_railways'] = df_s.apply(haversine_distance_rail,axis=1)\ndf_s['distance_avg'] = ( df_s['distance_central'] + df_s['distance_airport'] + df_s['distance_railways'] )\/3.0\n","26236932":"df_s.sort_values(by='price',ascending=False,axis=0,inplace=True) #sorting frame by price desc","69cf9b1b":"df_top10000 = df_s.head(10000)\ndf_top1000 = df_s.head(1000)","bc3cde05":"import seaborn as sns \nimport matplotlib.pyplot as plt","18884497":"sns.set(style=\"white\")\ncorr = df_s.corr()\n\n# generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# set up the matplotlib figure\nfig, ax = plt.subplots(figsize=(25, 15))\n\n# generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\":.5},cbar=True);","eb18c773":"# Setting a base map\nlat = 52.509\nlong = 13.381\nbase = folium.Map(location=[lat,long], zoom_start=12) #base map setting\nbase","6cbe9897":"neighbourhoods = folium.map.FeatureGroup()","e2d11381":"lat_long_list = [[52.520,13.405],[52.373,13.506],[52.507,13.332]] #locatioms of central berlin , railway stn, airport","f4f17db1":"for i in range(0,len(lat_long_list)):\n    neighbourhoods.add_child(\n        folium.CircleMarker(\n        lat_long_list[i],\n        radius = 16,\n        color='yellow',\n        fill=True,\n        fill_color='red',\n        fill_opacity=0.6\n        )\n    )\nbase.add_child(neighbourhoods)","e7fe0ce6":"for inc_lat,inc_long in zip(df_top1000.longitude,df_top1000.latitude):\n    neighbourhoods.add_child(\n    folium.CircleMarker(\n    [inc_long,inc_lat],\n    radius = 6,\n    color='red',\n    fill=True,\n    fill_color='yellow',\n    fill_opacity=0.6\n    )\n)\nbase.add_child(neighbourhoods)","660751cd":"fig = plt.figure(figsize=(10,6))\nax0 = fig.add_subplot(2, 2, 1)\nax1 = fig.add_subplot(2, 2, 2)\nax2 = fig.add_subplot(2, 2, 3)\n\nsns.distplot(df_top1000[\"distance_central\"], bins=10, kde=False,ax=ax0)\nax0.set_title('Distances central berlin to apartments')\nax0.set_xlabel('distance_central')\nax0.set_ylabel('#properties')\n\nsns.distplot(df_top1000[\"distance_railways\"], bins=10, kde=False,ax=ax1)\nax1.set_title('Distances railway station to apartments')\nax1.set_xlabel('distance_railways')\nax1.set_ylabel('#properties')\n\nsns.distplot(df_top1000[\"distance_airport\"], bins=10, kde=False,ax=ax2)\nax2.set_title('Distances airport to apartments')\nax2.set_xlabel('distance_airport')\nax2.set_ylabel('#properties')\n\nplt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.5, wspace=0.5)\nplt.show()","60535f42":"Berlin_data = df_s[['neighbourhood_cleansed','neighbourhood_group_cleansed', 'latitude', 'longitude','price']].reset_index(drop=True)\nBerlin_data.head()","6d472ef4":"print('The dataframe has {} neighbourhood_group_cleansed and {} neighborhoods.'.format(\n        len(Berlin_data['neighbourhood_group_cleansed'].unique()),\n        Berlin_data.shape[0]\n    )\n)\n","caa12da6":"Belin_c = df_s[df_s.neighbourhood_group_cleansed.isin(['Mitte','Friedrichshain-Kreuzberg','Pankow','Neuk\u00f6lln','Charlottenburg-Wilm.'])]\n    \nBelin_c.head()    \n    \n    ","17a81403":"Belin_c.shape","e73b9ac3":"address =  'Berlin, Germany'\n\ngeolocator = Nominatim(user_agent=\"my-application\", timeout=10)\nBerlin_location = geolocator.geocode(address)\n\nprint('The geograpical coordinate of Berlin are {}, {}.'.format(Berlin_location.latitude, Berlin_location.longitude))","c897b119":"\nBerlin_map=folium.Map(location=[Berlin_location.latitude,Berlin_location.longitude], zoom_start=12)\nBerlin_map\n","f6514f1f":"address = 'Berlin' \n\ngeolocator = Nominatim(user_agent=\"my-application\", timeout=10)\nparis_location = geolocator.geocode(address)\n\nprint('The geograpical coordinate of Berlin are {}, {}.'.format(Berlin_location.latitude, Berlin_location.longitude))","8a84e9d2":"CLIENT_ID = 'C50U5PW0KUQFAYG3VW3C3OTKWLKYAMDVDPEKKC3COOAML32M' # your Foursquare ID\nCLIENT_SECRET = 'FQW0AQA0PF52RSL5ZQ3YSHMI2O4QQWYDGVTC5HJ2WFCTO4VI' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)","73a69980":"LIMIT = 100 # limit of number of venues returned by Foursquare API\n\n\nradius = 500 # define radius\n\n# create URL\nurl = 'https:\/\/api.foursquare.com\/v2\/venues\/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    Berlin_location.latitude, \n    Berlin_location.longitude, \n    radius, \n    LIMIT)\nurl # display URL","7f599e25":"results = requests.get(url).json()\nresults","29262312":"# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']","3fd6ff55":"venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()","50e38ac0":"\nprint('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))","7386d32b":"def getNearbyVenues(results, names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https:\/\/api.foursquare.com\/v2\/venues\/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name'],\n            v['venue']['id']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category',\n                  'Venue id'         ]\n    \n    return(nearby_venues)","74bd4769":"results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n\nBerlin_venues = getNearbyVenues(results, names=Belin_c['neighbourhood_cleansed'],\n                                   latitudes=Belin_c['latitude'],\n                                   longitudes=Belin_c['longitude']\n                                  )\n           ","4f5439fb":"print(Berlin_venues.shape)\nBerlin_venues.head()","22244294":"Berlin_venues.groupby('Neighborhood').count().head()","a68d6853":"print('There are {} uniques categories.'.format(len(Berlin_venues['Venue Category'].unique())))\n","1bcd1d90":"# one hot encoding\nBerlin_onehot = pd.get_dummies(Berlin_venues, prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nBerlin_onehot['Neighborhood'] = Berlin_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [Berlin_onehot.columns[-1]] + list(Berlin_onehot.columns[:-1])\nBerlin_onehot = Berlin_onehot[fixed_columns]\n\nBerlin_onehot.head()","f12f9217":"Berlin_onehot.shape","dd70b031":"Berlin_grouped = Berlin_onehot.groupby('Neighborhood').mean().reset_index()\nBerlin_grouped.head()","92682474":"Berlin_grouped.shape","22c135bf":"num_top_venues = 5\n\nfor hood in Berlin_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = Berlin_grouped[Berlin_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')","567f7f7f":"def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]","b0070025":"num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = Berlin_grouped['Neighborhood']\n\nfor ind in np.arange(Berlin_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(Berlin_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()","b9edeaff":"df_no_top_venue = Berlin_venues[['Neighborhood','Venue Category','Venue']].groupby(['Neighborhood','Venue Category']).count()\ndf_no_top_venue.head()","5ac52f10":"# set number of clusters\nkclusters = 3\nBerliln_grouped_clustering = Berlin_grouped.drop('Neighborhood', 1)\nBerliln_grouped_clustering.head()\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(Berliln_grouped_clustering)\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ","7052a67f":"Berliln_grouped_clustering.head()","aa09686c":"kmeans.labels_","d0c52497":"# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\nBerlin_merged = df_s\n\n# merge Berlin_grouped with Berlin_data to add latitude\/longitude for each neighborhood\nBerlin_merged = Berlin_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='neighbourhood_cleansed')\nBerlin_merged.head() # check the last columns!","f0c83feb":"latitude=52.5170365\nlongitude=13.3888599\n# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(Berlin_merged['latitude'], Berlin_merged['longitude'], Berlin_merged['neighbourhood_cleansed'], Berlin_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n\n       \nmap_clusters","5d36a8a0":"cluster1 = Berlin_merged.loc[Berlin_merged['Cluster Labels'] == 0, Berlin_merged.columns[[0,1,2,3] + list(range(4, Berlin_merged.shape[1]))]]\nprint(cluster1.shape[0], \"neighborhood(s) in Cluster 1\")\ncluster1.head()","f2b7a3d6":"cluster2 = Berlin_merged.loc[Berlin_merged['Cluster Labels'] == 1, Berlin_merged.columns[[0,1,2,3] + list(range(4, Berlin_merged.shape[1]))]]\nprint(cluster2.shape[0], \"neighborhood(s) in Cluster 2\")\ncluster2.head()","074da0ea":"cluster3 = Berlin_merged.loc[Berlin_merged['Cluster Labels'] == 2, Berlin_merged.columns[[0,1,2,3] + list(range(3, Berlin_merged.shape[1]))]]\nprint(cluster3.shape[0], \"neighborhood(s) in Cluster 3\")\ncluster3.head()","363d8d6a":"### Airbnb has successfully disrupted the traditional hospitality industry as more and more travelers decide to use Airbnb as their primary accommodation provider. Since its beginning in 2008, Airbnb has seen an enormous growth, with the number of rentals listed on its website growing exponentially each year. In Germany, no city is more popular than Berlin. That implies that Berlin is one of the hottest markets for Airbnb in Europe, with over 22,552 listings as of November 2018.\n\n#### Although Airbnb listings provide enough information about the shared space, there is less information about the nearby location. For example, travelers might be interested in what kind of venues are close to the accommodation they book.In addition, travelers cannot filter Airbnb listings based on the nearby venues. In other words, each time travelers make a search for an accommodation using the Airbnb community, they may want to get direct information about the venues in the area and a list of similar Airbnb listings with same venue categories nearby.\n\n### The main objective of this project is to explore, segment and cluster Airbnb listings in Berlin, Germany. I will use the Foursquare API to explore the areas around the Airbnb listings in Berlin. I will use the explore function to get the most common venue categories for each Airbnb listing, and then use this feature together with the prices to group the listings into clusters. I will use the k-means clustering algorithm to complete this task. Finally, I will use the Folium library to visualize the listings in Berlin and their emerging clusters.","d42fa504":"## Now we are ready to clean the json and structure it into a pandas dataframe.","013e6581":"## let's have a look at number of Listingsin in each Neighbourhood group ","b5f2377c":"## First, let's create the GET request URL","45fe9694":"## Let's check how many venues were returned for each neighborhood","2e21d5fc":"#  Explore and Visualize Airbnb Berlin Data","e282bd1f":"### Get the Airbnb data of listings in Berlin","3dbd8cb0":"## Price range distribution among the bedrooms","8eac5e66":"## let's convert string true and false to numeric","67d0a46b":"# Let's explore the first neighborhood in our dataframe","d1e129c2":"## Let's print each neighborhood along with the top 5 most common venues","e47fe407":"## We notice here that the more rooms there are, the more price increases","23dc2e3b":"## let's extract the data about neighbourhood_cleansed,neighbourhood_group_cleansed, latitudes and longitudes","9b1be744":"## Data Science  Project\n\nMohamed Abdul Fatah\n\n","5ab004b3":"## let's have a look at the frist five popular neighborhoods among the listings?","ec8df2b7":"## Price range distribution among the room types","d3bbc3ba":"## let's have a look at the most occupied room types among the listings?","e0cef651":"##  Cluster 1","04c25d87":"## Convert false,true to 0 or 1","d4d3afa5":"## Get venues data of the neighbourhood_cleansed","5e883d33":"# Data\n\n## * Foursquare API: to get the most common venues of given Airbnb listing.\n\n## * Airbnb Data Collection : Here is the data provided for each Airbnb listing. Each link downloads a zip file of the data for a named city or region; in my case this is Berlin, Germany. The zip file holds one or more csv files. Each csv file represents a single \u201dsurvey\u201d or \u201dscrape\u201d of the Airbnb web site for that city. The data is collected from the public Airbnb web sit. Each csv file contains the attributes as follows:\n\n### * room_id: A unique number identifying an Airbnb listing\n\n### * host_id: A unique number identifying an Airbnb host.\n\n### * room_type: One of \u201dEntire home\/apt\u201d, \u201dPrivate room\u201d, or \u201dShared room\u201d borough: A sub-region of the city or search area for which the survey is carried out. The borough is taken from a shapefile of the city that is obtained independently of the Airbnb web site. For some cities, there is no borough information; for others the borough may be a number.\n\n### * neighborhood: As with borough: a sub-region of the city or search area for which the survey is carried out. For cities that have both, a neighborhood is smaller than a borough. For some cities there is no neighborhood information.\n\n### * reviews: The number of reviews that a listing has received. Airbnb has said that 70% of visits end up with a review, so the number of reviews can be used to estimate the number of visits. Note that such an estimate will not be reliable for an individual listing (especially as reviews occasionally vanish from the site), but over a city as a whole it should be a useful metric of traffic.\n\n### * overall_satisfaction: The average rating (out of five) that the listing has received from those visitors who left a review. accommodates: The number of guests a listing can accommodate. bedrooms: The number of bedrooms a listing offers. price: The price for a night stay. In early surveys, there may be some values that were recorded by month.\n\n### * minstay: The minimum stay for a visit, as posted by the host.\n\n### * latitude and longitude: The latitude and longitude of the listing as posted on the Airbnb site: this may be off by a few hundred meters.\n\n### * last_modified: the date and time that the values were read from the Airbnb web site\n\n## Airbnb data is used to get the coordinates (latitude and longitude), neighbourhood and price for each listing in Berlin, Germany. Having this information, I can leverage Foursquare API to explore the areas around the Airbnb listings and get the most common venue categories for each listing. Venue categories together with the price are used to segment the listings into similar clusters\n\n\n## If you don't want the details, just scroll to the end of the project, you'll see a map with average price range per night for each neighborhood and the cluster of quarters with the most common venues displayed \n\n","240ad547":"# Segmenting and Clustering Airbnb Listings in Berlin, Germany\u00b6\n","e67f13a4":"## Define function to get venues around the neighborhoods","17052b07":"## Let's confirm the new size","ad05cffa":" ## Cluster 2","b904f8b9":"## Now let's create the new dataframe and display the top 10 venues for each neighborhood.","8bd6600f":"****\n# Conclusion\n\n## I have combined Airbnb listings and Foursquare data to provide useful information to travelers in Berlin about the location and the most common venues they can visit in an area of 500 meters around their accommodation.\n\n## I have grouped the Airbnb listings around Berlin lake into 5 clusters based on similar venues and price levels. Travelers could leverage the clusters to filter listings according to their price preferences and the most common venues. In other words, travelers could search Airbnb listings according to location or venues they would like to visit, close to their accommodation.\n\nThe project is available on GitHub [5]","eae5a3d7":"## lets'have a look at the Room type distribution in the neighborhood groups","ddbabc09":"## cheak missing data ","1771184f":"## lets have a look at airbnb rent price statistics","f4576a32":"## And how many venues were returned by Foursquare?","f9542472":"## let's get important feature","04566e8e":"## Get the neighborhood's latitude and longitude values.\n","2b709848":"## let's cheak missing data ","6ed8fdd8":"# This is the end of project","dfc2131b":"## Let's find out how many unique categories can be curated from all the returned venues","2c67ebca":"# Methodology\n\n\n# 1- Airbnb Data Wrangling: Clean and Transform","5c14b80a":"****# Name the clusters\n## 1. Cluster 1 could be \"Restaurant & Bar\"\n\n## 2. Cluster 2 could be \" Lots of Hotel\"\n\n## 3. Cluster 3 could be \"Diverse Entertainment\"\n\n","251f93c9":"# * 75% of prices are near 70 $ so i will drop prices above 180 and also drop the min price like 0 & 1\n\n# * min prices is 0\n\n# * max prices is 9000 $\n\n","7fc5657a":"# Discussion and Recommendations\n## k-means partitioned the Airbnb listings into 5 groups since we specified the algorithm to generate 5 clusters. The Airbnb listings in each cluster are similar to each other in terms of the features included in the dataset.\n\n## I check the centroids values by averaging the features and get the top most common venues in each cluster.\n\n","679fdbee":"## let's extract the data about the 5 most popular neighborhood in berlin","92714f95":"## Now we are ready to see price is dependent on how many factors for top 1000 properties; so first I will sort by price descending and then generate a correlation matrix ","e3876345":"# I create also a map for the different Airbnb listing in Berlin. To do that, I work with Folium, a Python visualization library, solely developed for visualizing geospatial data. I use Folium library to visualize geographic details of Berlin and the Airbnb listings and I create a map of Berlin with Airbnb listings superimposed on top. I use latitude and longitude values to get the map below:","894ecc26":"# Get the Airbnb data of listings in Berlin  ","b880df05":"## Lets break up amenties that will help in drawing a correlation to price better as amenties might impact price\n","010288b0":"### Encode the Neighborhood","f1b770c3":"### from city center","51841e6e":"## Send the GET request and examine the resutls","19fb7b23":"### from airport","b26efbb5":"## And let's examine the new dataframe size","f36b429f":"## Airbnb rent price statistics shows The price ranges are between 25 to 75 $ ","b507f988":"## from berlin railway station","9d83a275":"## Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category","d44fd61e":"## Finally, let's visualize the resulting clusters","ddb3a798":"## We notice here that the most popular neighborhoods are each following in order from the first to the fifth:\n1 Friedrichshain-Kreuzberg\n\n2 Mitte\n\n3 Neuk\u00f6lln\n\n4 Pankow\t\n\n5 Charlottenburg-Wilm","8ccc2467":"## Let's put that into a pandas dataframe\nFirst, let's write a function to sort the venues in descending order.","d93ab6a9":"# Analyze Each Neighborhood","2ccd70e3":"## dropping amenities as we have inferred above as different categories","8d50008a":"## lets remove any outliers","ceb464ec":"# Examine Clusters\n## i will examine each cluster and determine the discriminating venue categories that distinguish each cluster. Based on the defining categories","f8a00aaa":"## let's Remove $ from price","0168a775":"## Friedrichshain-Kreuzberg Neighbourhood group seems to have more Listings in the dataset, with 24%","967ab793":"## let's plot all top 1000 properties and check where they are concentratedon a map [central berlin, railway station or airport]","88777772":"## price seems to depend largely on following factors\n\n## * No. of ameneties\n\n## * Is it family or kids friendly\n\n## * Cleaning fee\n\n## * how many guests it can accomodate\n\n## * price is not much dependent on distance","aef3ef1d":"## Cluster 3","67b02ae8":"## Lets also calculate distances from city center,airport and railway station that will again help in drawing a correlation to price","dd59439a":"## let's fill nan values with median","e56d90b8":"# 1 Introduction\/Business Problem","61b2e672":"## let's Count the number of venues for each venue category in the neighborhoods\n## top 5 most common venues","4baf30ed":"## Define Foursquare Credentials and Version","b31dd1df":"# Cluster Neighborhoods\n## Run k-means to cluster the neighborhood into 3 clusters.","43a7728f":"## the map plot indicates that the top 1000 properties are around central berlin railway station and very few near airports\n## This is also evident from below distribution plots where properties are mostly around central berlin & railway station"}}