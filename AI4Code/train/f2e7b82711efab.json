{"cell_type":{"bf7bc9b2":"code","88c6a81d":"code","f249e7c7":"code","05e08bdf":"code","0cfc13cd":"code","0a9bb467":"code","65d2e1e3":"code","81308c1d":"code","fcf38f5f":"code","045fb74a":"code","2d809926":"code","03466241":"code","eb4d79f8":"code","2a3a0231":"code","0a42f137":"code","47e7fcac":"code","ff719a72":"code","1754716d":"code","7923c14c":"code","c1107ec7":"code","315914fb":"markdown"},"source":{"bf7bc9b2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom nltk.tokenize import TweetTokenizer\nimport datetime\nimport lightgbm as lgb\nimport string\nimport re\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn import metrics\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom tqdm import tqdm\npd.set_option('max_colwidth',400)\npd.set_option('max_columns', 50)\nimport json\nimport gc\nimport os","88c6a81d":"train = pd.read_csv('..\/input\/jigsaw-train-preprocessed\/train_preprocessed_tfidf.csv').fillna('')","f249e7c7":"train.columns","05e08bdf":"fts = [\"raw_word_len\", \"raw_char_len\", \"nb_upper\", \"nb_fk\", \"nb_sk\", \"nb_dk\", \"nb_you\", \"nb_mother\", \"nb_ng\", \"start_with_columns\",\n       \"has_timestamp\", \"has_date_long\", \"has_date_short\", \"has_mail\", \"has_emphasize_equal\", \"has_emphasize_quotes\", \"clean_word_len\",\n       \"clean_char_len\", \"clean_chars\", \"clean_chars_ratio\"]","0cfc13cd":"annot_idx = train[train['identity_annotator_count'] > 0].sample(n=48660, random_state=13).index\nnot_annot_idx = train[train['identity_annotator_count'] == 0].sample(n=48660, random_state=13).index\nx_val_idx = list(set(annot_idx).union(set(not_annot_idx)))","0a9bb467":"val_df = train.loc[x_val_idx]\nprint(train.shape)\nprint(val_df.shape)","65d2e1e3":"X_train = train.loc[set(train.index) - set(x_val_idx)]","81308c1d":"train_text = X_train['clean_comment'].apply(lambda x: re.sub('#', '', x))","fcf38f5f":"word_vectorizer = TfidfVectorizer(\n        sublinear_tf=True,\n        strip_accents='unicode',\n        analyzer='word',\n        min_df=5,\n        ngram_range=(1, 2),\n        max_features=60000)\n\nword_vectorizer.fit(train_text)","045fb74a":"train_word_features = word_vectorizer.transform(train_text)","2d809926":"import pickle\n\nwith open('word_vectorizer.pickle', 'wb') as handle:\n    pickle.dump(word_vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","03466241":"train_word_features.shape","eb4d79f8":"X_train['rating'] = X_train['rating'].apply(lambda x: 0 if x == 'rejected' else 1)","2a3a0231":"train_features = hstack([X_train[fts], train_word_features]).tocsr()","0a42f137":"del X_train\ndel train_word_features","47e7fcac":"y_train = train.loc[set(train.index) - set(x_val_idx)]['target']\ny_train = (y_train >= 0.5).astype('int')","ff719a72":"lr = LogisticRegression(solver='lbfgs', random_state=13)\nlr.fit(train_features, y_train)","1754716d":"with open('lr_model.pickle', 'wb') as handle:\n    pickle.dump(lr, handle, protocol=pickle.HIGHEST_PROTOCOL)","7923c14c":"lgb_train = lgb.Dataset(train_features, y_train)\n\n# specify your configurations as a dict\nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective':'binary',\n    'metric': {'auc'},\n    'nthread': -1,\n    'feature_fraction': 0.4,\n    'num_leaves': 50,\n    'num_iterations': 200,\n    'verbose': 1,\n}\n\nprint('Start training...')\n# train\ngbm = lgb.train(params,\n                lgb_train)","c1107ec7":"with open('gbm_model.pickle', 'wb') as handle:\n    pickle.dump(gbm, handle, protocol=pickle.HIGHEST_PROTOCOL)","315914fb":"https:\/\/www.kaggle.com\/chernyshov\/logistic-regression-with-preprocessing"}}