{"cell_type":{"268f60b6":"code","c9fa6242":"code","537ed72a":"code","d5a72a18":"code","b9bb4642":"code","6b89471f":"code","f80d49be":"code","2e60ece1":"code","358e5948":"code","77ed120d":"code","0e56118e":"code","d3f2c8fd":"code","943655a5":"code","a57f2d98":"code","43aeb010":"code","4faca971":"code","d9333fc1":"code","9b9c5a10":"markdown","0be0f5b1":"markdown","bccbd64d":"markdown","8ab0b900":"markdown","fb08580b":"markdown","44e6a313":"markdown","a7420dbe":"markdown","d91f36cc":"markdown","add9c331":"markdown","b4a98f36":"markdown"},"source":{"268f60b6":"import pandas as pd\n\nds = pd.read_csv(\"..\/input\/catalog\/train.txt\",sep='\\t',names=['com','label'], header=None)\nds_out = pd.read_csv(\"..\/input\/catalog\/train.txt\",sep='\\t')\nds.head()","c9fa6242":"ds_out = pd.read_csv(\"..\/input\/catalog\/test.txt\",sep='\\t',names=['com'], header=None)\nds_out.head()","537ed72a":"dico,ocur = [],[]\nfor i in ds[\"com\"]:\n    for w in i.split(\" \"):\n        if not w in dico :\n            dico.append(w)\n            ocur.append(1)\n        else :\n            ocur[dico.index(w)] += 1\n\nlen(dico), len(ds)","d5a72a18":"ocur.index(max(ocur)), ocur[ocur.index(max(ocur))],dico[20]","b9bb4642":"def sort2(d,o):\n    dico,ocur = d[:],o[:]\n    s_dico,s_ocur = [],[]\n    for i in range(len(dico)):\n        i_max = ocur.index(max(ocur))\n        max_val = dico[i_max]\n        s_dico,s_ocur = s_dico+[max_val],s_ocur+[ocur[i_max]]\n        dico,ocur = dico[:i_max]+dico[i_max+1:],ocur[:i_max]+ocur[i_max+1:]\n    return s_dico,s_ocur\n","6b89471f":"s_dico,s_ocur = sort2(dico,ocur)","f80d49be":"dico = s_dico[:1000]","2e60ece1":"def gen_vect(com,dico):\n    vect = np.zeros(len(dico))\n    for i,w in enumerate(dico) :\n        if w in com :\n            vect[i] = 1\n    return vect        ","358e5948":"import numpy as np\n\ntab = np.zeros([len(ds[\"com\"]),len(dico)])\nfor i,com in enumerate(ds[\"com\"]):\n    tab[i] = gen_vect(com,dico)\n    ","77ed120d":"tab_out = np.zeros([len(ds_out[\"com\"]),len(dico)])\nfor i,com in enumerate(ds_out[\"com\"]):\n    tab[i] = gen_vect(com,dico)","0e56118e":"import sklearn as skl\nfrom sklearn.model_selection import train_test_split\nX,y = tab, ds[\"label\"].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=41)","d3f2c8fd":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nclf = RandomForestClassifier(n_estimators=100)\n#clf = skl.svm.SVC()\nmodel = clf.fit(X_train, y_train)\npredictions = model.predict(X_test)","943655a5":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix\n\nprint(skl.metrics.accuracy_score(y_test, predictions))","a57f2d98":"out_pred = model.predict(tab_out)","43aeb010":"ds_out[\"\u0413\u0440\u0443\u043f\u043f\u0430\"] = out_pred\nds_out.index.names = [\"index\"]\nds_out.head()","4faca971":"ds_out = ds_out.drop([\"com\"],axis=1)","d9333fc1":"ds_out.to_csv(\"submission.csv\")","9b9c5a10":"# **Submiting**","0be0f5b1":"convert a comment to the vector dim(len(dico)) of 0 and 1 if the word is in the comment","bccbd64d":"**Sort words by most frequent appearance**","8ab0b900":"SVM on dico = 10 => .32\n\nRFC on dico 50 d=> .42\n\ndico = 100 => .48\n\ndico = 1000 => .65","fb08580b":"**select only the top 1000 words**","44e6a313":"# **Read Data**","a7420dbe":"# **Make my model**","d91f36cc":"# **Split train \/ test**","add9c331":"# **Prepare my dictionary**","b4a98f36":"my idea is simple: retrieve the most frequent word to make a dictionary and classify on these words"}}