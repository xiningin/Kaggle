{"cell_type":{"901ed5c5":"code","be81611f":"code","1f7f684b":"code","59f1a9b4":"code","fcacfecd":"code","912af123":"code","e40a1e94":"code","e785ddf2":"code","4cbcad04":"code","39ad52d1":"code","625c81b9":"code","e2f15937":"code","471a0fe9":"code","5f3e19b9":"code","68b9c1f7":"code","1bf4023e":"code","ab0be721":"code","f33fd82a":"code","564e5d19":"markdown","29a8fe85":"markdown","21e1364e":"markdown","cb253617":"markdown","09e96a87":"markdown","44ec2705":"markdown","2b9a9129":"markdown","850dc844":"markdown","63cc6741":"markdown","b971ec92":"markdown","de3ac204":"markdown","d39e3fad":"markdown","e397d68f":"markdown","92b383cd":"markdown","1ef0859a":"markdown","1c81d7c4":"markdown","9c748f66":"markdown","b4e5c6c3":"markdown","455b6f56":"markdown","93ff93cc":"markdown","99fa38cd":"markdown","18011743":"markdown","e6c4129f":"markdown","eeb15e55":"markdown","2685d028":"markdown","43e6f872":"markdown","21db29d3":"markdown"},"source":{"901ed5c5":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import(\n    cross_validate,\n    train_test_split\n)\n\nimport altair as alt\nalt.renderers.enable('kaggle')\n\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score, cross_validate, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier","be81611f":"census_df = pd.read_csv('\/kaggle\/input\/adult-census-income\/adult.csv')\ncensus_df","1f7f684b":"train_df, test_df = train_test_split(census_df,\n                                     train_size=0.8,\n                                     random_state=2018)","59f1a9b4":"train_df.info()","fcacfecd":"train_df.sort_index()","912af123":"train_df_nan = train_df.replace(\"?\", np.nan)\ntest_df_nan = test_df.replace(\"?\", np.nan)","e40a1e94":"train_df.describe()","e785ddf2":"corr_df = train_df.corr('spearman').stack().reset_index(name='corr')\ncorr_df.loc[corr_df['corr'] == 1, 'corr'] = 0  # Remove diagonal\n# Use abs so that we can visualize the impact of negative correaltion  \ncorr_df['abs'] = corr_df['corr'].abs()\ncorr_df.sort_values('abs', ascending=False).head(n=5)","4cbcad04":"alt.Chart(corr_df).mark_circle().encode(\n    x='level_0',\n    y='level_1',\n    size='abs',\n    color=alt.Color('corr',\n                    scale=alt.Scale(scheme='blueorange',\n                                    domain=(-1, 1)))).properties(\n    height=150,\n    width=150)","39ad52d1":"numeric_features = ['age', 'fnlwgt', 'capital.gain', 'capital.loss', 'hours.per.week']\ncategorical_features = ['occupation', 'workclass', 'marital.status', 'relationship', 'native.country', 'education.num']\nordinal_features = ['education.num']\ndrop_features = ['education', 'race', 'sex']\npassthrough_features = []\ntarget = \"income\"","625c81b9":"preprocessor = make_column_transformer(\n    (\n        StandardScaler(),\n        numeric_features,\n    ),  # scaling on numeric features\n    (\n        make_pipeline(SimpleImputer(strategy=\"constant\",\n                                    fill_value=\"missing\"),\n                      OneHotEncoder(handle_unknown=\"ignore\",\n                                    sparse=False)),\n        categorical_features,\n    ),  # Imputation and OHE on categorical features\n    (\n        (\"drop\"),\n        drop_features\n    ),  # drop the drop features\n)","e2f15937":"results_dict = {}  # dictionary to store all the results\n\nX_train = train_df_nan.drop(columns=[\"income\"])\ny_train = train_df_nan[\"income\"]\n\nX_test = test_df_nan.drop(columns=[\"income\"])\ny_test = test_df_nan[\"income\"]","471a0fe9":"def mean_cross_val_scores(model, X_train, y_train, **kwargs):\n    \"\"\"\n    Returns mean scores of cross validation\n\n    Parameters\n    ----------\n    model :\n        scikit-learn model\n    X_train : numpy array or pandas DataFrame\n        X in the training data\n    y_train :\n        y in the training data\n\n    Returns\n    ----------\n        pandas Series with mean scores from cross_validation\n    \"\"\"\n\n    scores = cross_validate(model, X_train, y_train, **kwargs)\n\n    mean_scores = pd.DataFrame(scores).mean()\n    out_col = []\n\n    for i in range(len(mean_scores)):\n        out_col.append(round(mean_scores[i], 3))\n\n    return pd.Series(data=out_col, index=mean_scores.index)","5f3e19b9":"pipe = make_pipeline(preprocessor, DummyClassifier(strategy='prior')) \nresults_dict = mean_cross_val_scores(pipe, X_train, y_train, cv=5, return_train_score=True)\npd.DataFrame(results_dict, columns=['DummyClassifier'])","68b9c1f7":"models = {\n    \"decision tree\": DecisionTreeClassifier(random_state=2018),\n    \"kNN\": KNeighborsClassifier(),\n    \"RBF SVM\": SVC(random_state=2018),\n}\n\nmodels_short = {\n     \"decision tree\": 'DecisionTree',\n    \"kNN\": 'kNN',\n    'RBF SVM': 'SVC',\n}\n\nresults_dict = {}\nfor i in models:\n    pipe_temp = make_pipeline(preprocessor, models[i])\n    results_dict[models_short[i]] = mean_cross_val_scores(\n    pipe_temp, X_train, y_train, cv=5, return_train_score=True)\n    \npd.DataFrame(results_dict)","1bf4023e":"param_grid = {\"C\": np.logspace(-2, 2, 4)}\n\nresults_dict = {}\nfor i in param_grid[\"C\"]:\n    pipe_temp = make_pipeline(preprocessor, SVC(C=i, random_state=2018))\n    results_dict[i] = mean_cross_val_scores(\n    pipe_temp, X_train, y_train, cv=5, return_train_score=True)\n    \nhyper_C = pd.DataFrame(results_dict).T\nhyper_C.index.name='Hyperparameter: C'\nhyper_C","ab0be721":"round(hyper_C.index[hyper_C.test_score.argmax()], 3)","f33fd82a":"optimal_model = make_pipeline(preprocessor, SVC(random_state=2018))\noptimal_model.fit(X_train, y_train)\nprint(f\"Score on test set: { optimal_model.score(X_test, y_test):.3f}\")","564e5d19":"## 4.1 Relationships among the features.","29a8fe85":"- C = 4.642 gives the best validation accuracy of 0.856. It is the same as the default validation accuracy which was 0.856. \n- C = 4.642 is slightly worse than the default parameter since the gap between training and validation score is lesser.\n- So, we use the default parameters for the final model.","21e1364e":"# 3. Preliminary EDA","cb253617":"# 6. Preprocessing using sklearn's ColumnTransformer","09e96a87":"# 5. Transformations to be applied on features","44ec2705":"- The imputation are done on the categorical columns which have NaN values in them. \n- The numeric columns don't have NaN values. We scale the numeric columns. \n- We are doing OHE on categorical variables. For features having both imputation and OHE, first we impute the feature and then apply OHE.","2b9a9129":"- The Decision Tree overfits on the training data giving 100% accuracy on the training set. SVC has the lowest training set accuracy.  \n- On the other hand, SVC gives the best validation accuracy and due to overfitting on the training data. Decision Tree has the poorest performance on the validation set.  \n- All the above three models give better validation accuracies than the baseline model.   \n- RBF SVC has the best validation accuracy but it is too slow! Decision Tree Classifier is the fastest one, doing most of its work during fitting the model.","850dc844":"# 7.3 Hyperparameter Optimization for SVC","63cc6741":"# 2. Data splitting","b971ec92":"# 8. Evaluating on the test set","de3ac204":"# 7.2 Training multiple models","d39e3fad":"- There are very low correlation between the features. \n- But the above relations are only for numeric features.","e397d68f":"# 1. Reading the dataset","92b383cd":"- I'm grateful that you spent your time reading\/skimming all the way through. \n- Comments\/suggestions\/criticisms on the notebook would be highly appreciated.\n- Check out my other work on [Kaggle](https:\/\/www.kaggle.com\/rrrohit).","1ef0859a":"We are optimizing hyperparameters for only SVC which gave the best validation scores in the previous section. Ideally, we would want do this on all the models and then arrive at the best model.\n\nWe are using below a kind of GridSearch to do optimization. Another way to do so is to use RandomizedSearch.\n\nHyperparameter used: **C**\n- C is regularization parameter with squared L2 penalty. \n- The strength of the regularization is inversely proportional to C. Must be strictly positive.","1c81d7c4":"\nUsually .info() method would give you information on missing values. But here, it does not pick \"?\" as missing values as they are encoded as strings instead of an actual NaN in Python. So let's replace them with np.nan before we carry out EDA.","9c748f66":"Below we prepar the list of common features for each of the transformations we want to make. For ethical reasons, we would like to drop `race` and `sex` from our analysis. For some scenarios, it might be fine to include them for descriptive purposes.","b4e5c6c3":"Luckily, we do not have NANs values in the dataset. We still have to have to look whether some of the text columns have missing or empty strings in it.","455b6f56":"# 4. EDA","93ff93cc":"The stratgey for DummmyClassifier is `prior` which predicts the class that maximizes the most frequent class and predict_proba returns the class prior.\n\nBelow we train different parametric and non-parametric models on our preprocessed data using pipelines.","99fa38cd":"- A lot of the values in `captial.gain` and `capital.loss` are 0's. We can see that even 75% percentile of the value is 0.\n- `education.num` is an ordinal feature and the feature `education` becomes redundant.","18011743":"# 7. Building ML model","e6c4129f":"Yay! Our final score model is close to the validation score.","eeb15e55":"| Transformation | Features |\n| --- | ------ |\n| Scaling | age, fnlwgt, capital.gain, capital.loss |\n| Imputation | occupation, workclass, native.country |\n| OHE | occupation, workclass, education.num, marital.status, relationship, race, sex, native.country |\n| drop | education |\n","2685d028":"Below we have made the preprocessor we want to apply our training our model. Pipeline helps us to organize our data modifications\/transformations in a nicer, elegant fashion. Each step in pipeline passes its output to the next step as input. So, for categorical_features, first the imputation is done and then we apply OHE using a pipeline.","43e6f872":"## 7.1 Making a Baseline model","21db29d3":"We are basically checking for missing values, scaling issues in the dataframe."}}