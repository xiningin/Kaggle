{"cell_type":{"066a4b60":"code","0e3efb88":"code","10f581b8":"code","13a819c2":"code","36e8de72":"code","1b19b585":"code","ac3b2cbe":"code","b0ae558f":"code","96d62dbe":"code","587c9802":"code","9f653cfa":"code","e871e80e":"code","e24693ca":"code","4eab24fb":"code","fa4ee3c5":"code","3d805cd5":"markdown","89719283":"markdown","cbf4b324":"markdown","f4f62be7":"markdown","1dccdad0":"markdown","abadb30d":"markdown","f8b62d94":"markdown"},"source":{"066a4b60":"# First, import the important packages\nimport pandas as pd\nimport networkx as nx\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","0e3efb88":"# Next read in the edges and create a graph\ndf = pd.read_csv('..\/input\/group-edges.csv')\ng0 = nx.from_pandas_edgelist(df, \n                            source='group1', \n                            target='group2', \n                            edge_attr='weight')\n\nprint('The entire MeetUp group graph has {} nodes and {} edges.'.format(\n    len(g0.nodes),\n    len(g0.edges)))","10f581b8":"# Now, let's read in some member metadata and trim to Tech groups\ngroups = pd.read_csv('..\/input\/meta-groups.csv', index_col='group_id')\ntech = groups.loc[groups.category_name == 'Tech']\nprint('There are {} Tech groups with metadata.'.format(tech.shape[0]))\n\n# Let's trim the graph down to the largest connected Tech network\ngt = g0.subgraph(tech.index)\ng = [gt.subgraph(c) for c in nx.connected_components(gt)][0]\ntech = tech.loc[(n for n in g.nodes)]\nprint('After trimming, there are {} groups with metadata.\\nThese include...'.format(tech.shape[0]))\nprint(tech.sample(5).group_name.to_string())","13a819c2":"plt.figure(dpi=150)\n\npos = nx.spring_layout(g, k=2)\n# pos = nx.random_layout(g)\nnx.draw_networkx(g, pos, with_labels=False, node_size=10,\n                 width=0.05)\n\nax = plt.gca()\nax.set_aspect(1)\nax.axis('off')\nax.set_title('Graph Network of Nashville Tech MeetUps')\nplt.show()","36e8de72":"# Let's run some measures and populate our DataFrame\ntech['degree'] = pd.Series(dict(nx.degree(g)))\ntech['clustering'] = pd.Series(nx.clustering(g))\ntech['centrality'] = pd.Series(nx.betweenness_centrality(g))\n\n# Path length is a little trickier\navg_length_dict = {}\nfor node, path_lengths in nx.shortest_path_length(g):\n    path_lengths = [x for x in path_lengths.values()]\n    avg_length_dict[node] = np.mean(path_lengths)\ntech['path_length'] = pd.Series(avg_length_dict)","1b19b585":"# First, we plot a pairplot to get a sense of the overall relationships\n# between each of the measures we derived. On the diagonal is the \n# distribution of values within the variable; off the diagonal are \n# scatterplots showing the correlation between variables.\n\ngrid = sns.pairplot(tech[['clustering', 'centrality']], diag_kind='kde')\n\nplt.show()","ac3b2cbe":"# Now, let's look at clustering.\nfig, ax = plt.subplots(1,1, figsize=(5,10), dpi=100)\n\ngp_order = tech.loc[tech.clustering > 0].sort_values(by='clustering').group_name\nsns.barplot(data = tech, x='clustering', y='group_name',\n            order = gp_order)\n\nax.set_title('Average clustering coefficient by Category')\nax.set_yticks(ax.get_yticks()[::4])\nax.set_yticklabels(gp_order[::4], size=16)\n\nplt.show()","b0ae558f":"tech.sort_values(by='centrality', ascending=False)[['group_name', 'centrality', 'num_members']].head(10)","96d62dbe":"# Next, let's plot the Number of Members (not degree!) vs. centrality\nfig, ax = plt.subplots(1,1, figsize=(10,5))\n\nsns.regplot(data=tech, x='num_members', y='centrality', order=2)\nax.set_title('Centrality vs. Number of Group Members')\n\nplt.show()","587c9802":"print('The ten most \"central\" groups are...')\nprint(tech[['group_name', 'num_members', 'clustering', 'centrality']]\n          .sort_values(by='centrality', ascending=False)\n          .head(10).to_string())","9f653cfa":"# !pip install python-louvain\n\ndef community_layout(g, partition):\n    \"\"\"\n    Compute the layout for a modular graph.\n\n\n    Arguments:\n    ----------\n    g -- networkx.Graph or networkx.DiGraph instance\n        graph to plot\n\n    partition -- dict mapping int node -> int community\n        graph partitions\n\n\n    Returns:\n    --------\n    pos -- dict mapping int node -> (float x, float y)\n        node positions\n\n    \"\"\"\n\n    pos_communities = _position_communities(g, partition, scale=3.)\n\n    pos_nodes = _position_nodes(g, partition, scale=1.)\n\n    # combine positions\n    pos = dict()\n    for node in g.nodes():\n        pos[node] = pos_communities[node] + pos_nodes[node]\n\n    return pos\n\ndef _position_communities(g, partition, **kwargs):\n\n    # create a weighted graph, in which each node corresponds to a community,\n    # and each edge weight to the number of edges between communities\n    between_community_edges = _find_between_community_edges(g, partition)\n\n    communities = set(partition.values())\n    hypergraph = nx.DiGraph()\n    hypergraph.add_nodes_from(communities)\n    for (ci, cj), edges in between_community_edges.items():\n        hypergraph.add_edge(ci, cj, weight=len(edges))\n\n    # find layout for communities\n    pos_communities = nx.spring_layout(hypergraph, **kwargs)\n\n    # set node positions to position of community\n    pos = dict()\n    for node, community in partition.items():\n        pos[node] = pos_communities[community]\n\n    return pos\n\ndef _find_between_community_edges(g, partition):\n\n    edges = dict()\n\n    for (ni, nj) in g.edges():\n        ci = partition[ni]\n        cj = partition[nj]\n\n        if ci != cj:\n            try:\n                edges[(ci, cj)] += [(ni, nj)]\n            except KeyError:\n                edges[(ci, cj)] = [(ni, nj)]\n\n    return edges\n\ndef _position_nodes(g, partition, **kwargs):\n    \"\"\"\n    Positions nodes within communities.\n    \"\"\"\n\n    communities = dict()\n    for node, community in partition.items():\n        try:\n            communities[community] += [node]\n        except KeyError:\n            communities[community] = [node]\n\n    pos = dict()\n    for ci, nodes in communities.items():\n        subgraph = g.subgraph(nodes)\n        pos_subgraph = nx.spring_layout(subgraph, **kwargs)\n        pos.update(pos_subgraph)\n\n    return pos","e871e80e":"import community\n\npartition = community.community_louvain.best_partition(g)\ntech['community'] = pd.Series(partition)","e24693ca":"plt.figure(dpi=150)\n\npos = community_layout(g, partition)\n\ncdict = {ii: sns.color_palette()[ii] for ii in set(partition.values())}\nnx.draw_networkx(g, pos, node_size=60,\n                 node_color=[cdict[ii] for ii in partition.values()], \n                 with_labels=False, width=0.15,\n                 cmap='rainbow')\nplt.axis('off')\nplt.show()","4eab24fb":"for ii in tech.community.unique():\n    print('Most central groups in Community {}...'.format(ii))\n    tdf = tech.sort_values(by='centrality', ascending=False).loc[tech.community == ii]\n    for ix, gp in tdf.head(4).iterrows():\n        print('\\t{}'.format(gp.group_name, gp.num_members))","fa4ee3c5":"gps = ['Nashville PowerShell User Group (NashPUG)', 'Data Science Nashville', 'NashJS', 'Nashville Mobile Developers', 'WordPress Nashville']\ntech.loc[tech.group_name.isin(gps), ['group_name', 'num_members', 'clustering', 'centrality', 'community']]","3d805cd5":"## Centrality","89719283":"The question we want to ask in this analysis is: **If we wanted to inflitrate Nashville's \"tech\" networks, which MeetUp groups should we target?**\n\nWe first import the data and create a graph, then we read in some group metadata. Next, we derive measures of the graph and add them to our dataframe. Throughout, we visualize this information using `seaborn` and `matplotlib`.","cbf4b324":"## Investigate Clustering","f4f62be7":"## Investigating communities","1dccdad0":"# Plot and describe measures","abadb30d":"# Run NetworkX graph measures and add to DataFrame\n\nGetting the graph-based measures is typically a simple matter of running a function. To add them to a DataFrame, however, you should have a `df` that is indexed by the node ID (i.e. `group_id` here), and convert your `networkx` output to a Series. This will make it very simple to add data into your existing DataFrame.","f8b62d94":"# Import data and setup environment"}}