{"cell_type":{"0001bc7f":"code","b965fc97":"code","8e21aa8e":"code","06f5a416":"code","202a2f5d":"code","8057e76f":"code","019d60c6":"code","d76e4d1e":"code","0f3379b5":"code","67940cb3":"code","ccff24e0":"code","571ac8f7":"code","5c9dae91":"code","ec4a8d27":"code","48176229":"code","0252d1fc":"code","088c1db7":"code","d49a14e3":"code","4488c6a4":"code","71ce21f2":"code","49cc9fd1":"code","8c1d3672":"markdown","5082e8f0":"markdown","b472569d":"markdown","371227d4":"markdown","dee0bc81":"markdown","7ab35a66":"markdown","0221dd97":"markdown","9a1d7cb2":"markdown","59d2695d":"markdown","8bb4731a":"markdown","f853cc0d":"markdown","4e23417a":"markdown","5508fb37":"markdown","195d669a":"markdown","aac1997e":"markdown","201813fd":"markdown","5a4d18ad":"markdown","e73f1953":"markdown","e8b6b761":"markdown","003ceaf9":"markdown","29331a35":"markdown","33d93acd":"markdown"},"source":{"0001bc7f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nsns.set_theme(context='notebook')","b965fc97":"df = pd.read_csv('\/kaggle\/input\/amazon-fine-food-reviews\/Reviews.csv')\ndf['Time'] = pd.to_datetime(df['Time'], unit='s')\ndf.sort_values(by='Time')","8e21aa8e":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\n\nfig, axes = plt.subplots(1, 1, figsize=(8, 4))\naxes.yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:,.0f}\"))\nsns.countplot(data=df, x='Score', palette='flare')","06f5a416":"numUsers = len(df['UserId'].unique())\nnumProducts = len(df['ProductId'].unique())\n\nfig, axes = plt.subplots(1, 1, figsize=(8, 4))\naxes.xaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:,.0f}\"))\nsns.barplot(data=pd.DataFrame({\n    'data': ['reviews', 'users', 'products'],\n    'count': [len(df), numUsers, numProducts],\n}), x='count', y='data', ax=axes)","202a2f5d":"newUsersPerMonth = df[['UserId', 'Time']].sort_values(by='Time').drop_duplicates(subset=['UserId']).groupby(pd.Grouper(key='Time', freq='M')).count().reset_index()\nnewProductsPerMonth = df[['ProductId', 'Time']].sort_values(by='Time').drop_duplicates(subset=['ProductId']).groupby(pd.Grouper(key='Time', freq='M')).count().reset_index()\n\nplt.figure(figsize=(12, 4))\nplt.title('New Users \/ New Products Per Month, 1999 to 2012')\nsns.set_theme(context='notebook')\nsns.lineplot(data=newUsersPerMonth, x='Time', y='UserId', label='New Users Per Month')\nax = sns.lineplot(data=newProductsPerMonth, x='Time', y='ProductId', label='New Products Per Month')\nax.yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:,.0f}\"))","8057e76f":"reviewsPerMonth = df.groupby(pd.Grouper(key='Time',freq='M')).count().reset_index()\n\nfig, axes = plt.subplots(1, 1, figsize=(12, 4))\naxes.yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:,.0f}\"))\n\nsns.lineplot(data=reviewsPerMonth, x='Time', y='Id', label='Reviews Per Month')","019d60c6":"# Reviews per user over time\ndata = df[['Time', 'Id', 'UserId']].groupby(by=[\n    pd.Grouper(key='Time', freq='M'),\n    'UserId',\n]).count()\ndata['UserId_1'] = 1\ndata = data.reset_index().groupby(by=pd.Grouper(key='Time', freq='M')).sum()\ndata['Rewiews_Per_User'] = data['Id'] \/ data['UserId_1']\ndata = data.reset_index().dropna()\n\nplt.figure(figsize=(12, 4))\nplt.title('#Reviews per user in each month, 1999 - 2012')\nax = sns.lineplot(data=data, x='Time' , y='Rewiews_Per_User')\nax.set(ylabel='Rewiews Per User')\nplt.show()","d76e4d1e":"# Reviews per product over time\ndata = df[['Time', 'Id', 'ProductId']].groupby(by=[\n    pd.Grouper(key='Time', freq='M'),\n    'ProductId',\n]).count()\ndata['ProductId_1'] = 1\ndata = data.reset_index().groupby(by=pd.Grouper(key='Time', freq='M')).sum()\ndata['Rewiews_Per_Product'] = data['Id'] \/ data['ProductId_1']\ndata = data.reset_index().dropna()\n\nplt.figure(figsize=(12, 4))\nplt.title('#Reviews per product in each month, 1999 - 2012')\nax = sns.lineplot(data=data, x='Time' , y='Rewiews_Per_Product')\nax.set(ylabel='Rewiews Per Product')\nplt.show()","0f3379b5":"data = df.groupby(pd.Grouper(key='Time',freq='M')).mean().reset_index()\nfig, axes = plt.subplots(1, 1, figsize=(12, 4))\nsns.lineplot(data=data, x='Time', y='Score')","67940cb3":"df = df.sample(n=20000)\ndf.shape","ccff24e0":"%%time\nimport nltk\nfrom gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short, preprocess_string\n\nlemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n\ndf['Text_tokenized'] = df['Text'].apply(lambda text: preprocess_string(text, [\n    strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short, lemmatizer.lemmatize, lambda x: x.lower()\n]))","571ac8f7":"df['Text_tokenized'].sample(n=20)","5c9dae91":"df['Text_len'] = df['Text_tokenized'].apply(lambda text: len(text))","ec4a8d27":"plt.figure(figsize=(8, 4))\nsns.histplot(df[df['Text_len'] > 0]['Text_len'], log_scale=True)","48176229":"%%time \n# Around 8s\nfrom wordcloud import WordCloud\n\nlong_string = ','.join([' '.join(words) for words in df['Text_tokenized'].values])\nwordcloud = WordCloud()\nwordcloud.generate(long_string)\nwordcloud.to_image()","0252d1fc":"import gensim\n\ndictionary = gensim.corpora.Dictionary(df['Text_tokenized'].values)","088c1db7":"dictionary.filter_extremes(no_below=20, no_above=0.5)","d49a14e3":"corpus = [dictionary.doc2bow(doc) for doc in df['Text_tokenized'].values]","4488c6a4":"print('Number of unique tokens: %d' % len(dictionary))\nprint('Number of documents: %d' % len(corpus))","71ce21f2":"%%time \nimport logging\n\n# for handler in logging.root.handlers[:]:\n#     logging.root.removeHandler(handler)\n    \n# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n# logger = logging.getLogger()\n# logger.setLevel(logging.DEBUG)\n\nmodel = gensim.models.ldamulticore.LdaMulticore(corpus, id2word=dictionary, passes=10)\n\n# # Back to default\n# logger.setLevel(logging.WARNING)","49cc9fd1":"%%time\n# Around 30s for 100topics, 15s for 10 topics\nimport pyLDAvis\nimport pyLDAvis.gensim\n\nprep_display = pyLDAvis.gensim.prepare(model, corpus, dictionary)\npyLDAvis.display(prep_display)","8c1d3672":"<a id=\"top\"><\/a>\n# Topic Modelling on Amazon fine food reviews \ud83c\udf55\ud83d\udcac\ud83d\udc81\u200d\u2640\ufe0f\ud83d\udc81\u200d\u2642\ufe0f \n\n(Indeed, not much reviews talk about pizza. How do we know \ud83d\ude0e ?) <br>\nFor busy people, go straight to [the result \ud83d\ude80](#section-4d)<br>\n\nThis dataset consists of more than **500,000 rows of user reviews** on Amazon's fine food product over 13 years (1999 - 2012).<br>\nYou may check out the source [here](https:\/\/www.kaggle.com\/snap\/amazon-fine-food-reviews). <br>\n<br>\nIn this notebook, we will explore this dataset and discover some interesting findings within. <br>\nAlso, topc modelling will be conducted to gain a general idea on what the reviews are about\n\nTable Of Contents\n* [Environment Setup](#section-1)\n* [The Data](#section-2)\n  * [Score Count](#section-2a)\n  * [General description on the data](#section-2b)\n* [The Trend](#section-3)\n  * [Users\/Products Growth](#section-3a)\n  * [Reviews Per Month](#section-3b)\n  * [Reviews Per User](#section-3c)\n  * [Reviews Per Product](#section-3d)\n  * [Average Reviews Scores](#section-3e)\n* [What the reviews are about - Topic Modelling](#section-4)\n  * [Review lengths](#section-4a)\n  * [Word Cloud](#section-4b)\n  * [LDA Modelling](#section-4c)\n  * [Result Visualization](#section-4d)","5082e8f0":"<a id=\"section-1\"><\/a>\n# Environment Setup <a style=\"font-size: 12px\" href=\"#top\">[back to top]<\/a>","b472569d":"<a id=\"section-4c\"><\/a>\n## LDA topic modelling <a style=\"font-size: 12px\" href=\"#section-4\">[back to section top]<\/a>\nWe will go through several steps\n\n1. Create a \"dictionary\" which contains all the unique words appeared in the reviews\n2. Filter out \"extreme words\", say words that occur less than 20 documents, or more than 50% of the documents\n3. Apply LDA topc modelling to find \"groups\" of reviews","371227d4":"<a id=\"section-2a\"><\/a>\n## Score count <a style=\"font-size: 12px\" href=\"#section-2\">[back to section top]<\/a>\n\nSeems like the users are quite satified with their product bought.","dee0bc81":"<a id=\"section-4\"><\/a>\n# What the reviews are about - Topic Modelling <a style=\"font-size: 12px\" href=\"#top\">[back to top]<\/a>\n\n* [Review lengths](#section-4a)\n* [Word Cloud](#section-4b)\n* [LDA Modelling](#section-4c)\n* [Result Visualization](#section-4d)\n\nWe will go through the following steps.<br>\n\nFirstly we're going to tokenize each review so each will become someting like  <br>\n`[loved, tea, however, sure, brew, long, cup, i...`  <br>\nThen we will apply LDA model to \"group\" these tokenized reviews.\n<br>\n\nTo contain the modelling process under acceptable time range, <br>\nwe will randomly sample 20,000 reviews from ~500,000 availble ones","7ab35a66":"we are having 10 ~ 100 tokens for each review","0221dd97":"> product, taste, greate, good, love, coffee, tea, ...\n\nSeems quite positive, which matches our findings about the reivew scores in previous sections.","9a1d7cb2":"<a id=\"section-3e\"><\/a>\n## Average reivew scores <a style=\"font-size: 12px\" href=\"#section-3\">[back to section top]<\/a>\n\nThe monthly average is generally **stable at around 4**.","59d2695d":"<a id=\"section-3c\"><\/a>\n## Reviews per user <a style=\"font-size: 12px\" href=\"#section-3\">[back to section top]<\/a>\n\n#Reviews per user are converging to **around 1.75**","8bb4731a":"# Thank You For Reading <a style=\"font-size: 12px\" href=\"#top\">[back to top]<\/a>\nFeel free to let me know your throughts in the comments !","f853cc0d":"<a id=\"section-3\"><\/a>\n# The Trend <a style=\"font-size: 12px\" href=\"#top\">[back to top]<\/a>\n\nNext we are going to see changes in users, products, reviews, and review scores over time.\n\n* [Users\/Products Growth](#section-3a)\n* [Reviews Per Month](#section-3b)\n* [Reviews Per User](#section-3c)\n* [Reviews Per Product](#section-3d)\n* [Average Reviews Scores](#section-3e)","4e23417a":"<a id=\"section-4a\"><\/a>\n## Review lengths <a style=\"font-size: 12px\" href=\"#section-4\">[back to section top]<\/a>","5508fb37":"<a id=\"section-2\"><\/a>\n# The Data <a style=\"font-size: 12px\" href=\"#top\">[back to top]<\/a>\n\nIn this section we will have a general understanding on our data.\n* [Score Count](#section-2a)\n* [General description on the data](#section-2b)","195d669a":"<a id=\"section-4d\"><\/a>\n## Result Visualization <a style=\"font-size: 12px\" href=\"#top\">[back to top]<\/a>\n\nTo easily explore our \"review groups\", we will visualize our result using pyLDAvis","aac1997e":"Some interesting \"review groups\" found (not going to interpret all 100 groups though):\n\n### Pet\n* Dog\/cat food - 2, 4, \n* Dog bones - 6\n\n### Coffee\/tea\n* Coffee and its flavours - 5, 7, 14\n* Tea, chai - 8, 13\n* Aroma or Flavour strong\/mild\/bitter - 16\n\n### Ingredient focused\n* Calories, fiber, sodium - 9\n* Gluten free - 19\n\n### Snacks\n* Snack, protein, bar - 10\n* Sauce, hot, spicy, pepper, spice - 12\n* Chips, tortilla - 15\n\n### Breakfast, starch-based food\n* Peanut butter milk cocoa - 87, 53, 32\n* Rice, pasta - 99, 53\n\n### Gift\n* Chistmas gift - 60\n\nFeel free to play around with the above interactive plot and find out more!","201813fd":"Let have a look on some tokenized reviews","5a4d18ad":"<a id=\"section-3d\"><\/a>\n## Reviews per product <a style=\"font-size: 12px\" href=\"#section-3\">[back to section top]<\/a>\nWe are expecting around **2 new reviews** for each product in each month, <br>\nslightly dropping since 2012","e73f1953":"Successfully getting most document converged\n> 2021-03-14 07:57:19,533 : DEBUG : 1996\/2000 documents converged within 50 iterations\n","e8b6b761":"<a id=\"section-2b\"><\/a>\n## General description on the data <a style=\"font-size: 12px\" href=\"#section-2\">[back to section top]<\/a>","003ceaf9":"<a id=\"section-3b\"><\/a>\n## Reviews per month <a style=\"font-size: 12px\" href=\"#section-3\">[back to section top]<\/a>\n\nReviews per month is growing exponentially","29331a35":"<a id=\"section-3a\"><\/a>\n## Users \/ Products Growth <a style=\"font-size: 12px\" href=\"#section-3\">[back to section top]<\/a>\n\nAt 2012, in each month, we are having\n* more than 8,000 new joiners, and;\n* more than 2,000 new products\n\nin Amazon fine food section","33d93acd":"<a id=\"section-4b\"><\/a>\n## Word Cloud <a style=\"font-size: 12px\" href=\"#section-4\">[back to section top]<\/a>\n\nNext let's make a word cloud to see some popular words in the reviews"}}