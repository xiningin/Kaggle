{"cell_type":{"14800534":"code","25f9382d":"code","3845cbdb":"code","bc64864e":"code","bac1c225":"code","3fc527ce":"code","64cb4d4c":"code","2ce82b39":"code","bd266b14":"code","e0897db9":"code","1497ccdb":"code","f381ba81":"code","dbb9c3c4":"code","9069d1e5":"code","df648550":"code","fcbc0d51":"code","b880cbcc":"code","490f4e99":"code","f5f268f1":"code","9f06010f":"code","60248b93":"code","6a918e8a":"code","7614d8aa":"code","cf01d610":"code","75c2f260":"code","138a3e6c":"code","e259c53b":"code","631534e7":"code","acd86925":"code","fdd97149":"code","e5c28084":"code","2ae33858":"code","b2082779":"code","ad21fe35":"code","3c2bb05f":"code","7697e39c":"code","edae760a":"code","c8c5cc7e":"code","ebfac82b":"code","fb817721":"code","d2db1427":"code","a2d810ad":"code","2371c7a9":"code","d35fae67":"code","87acec87":"code","d6cc3d07":"code","fbd781bb":"code","3fed6d80":"code","77a754ef":"code","65e5042d":"code","d2d2dd46":"code","25cc3a12":"code","5fc736ea":"code","a89bc9b9":"code","e01e0c11":"code","0fc24936":"code","b543a6b8":"code","4b7e3b78":"code","49130a08":"code","4013142a":"code","58f75c94":"code","edd7e88d":"code","7ea0016f":"code","b98bc8f2":"code","2ae19266":"markdown","be480e8d":"markdown","8ec16eb2":"markdown","a534a18f":"markdown","fc8f4617":"markdown","8a1ebcbc":"markdown","08434cc4":"markdown","2590287e":"markdown","49e6754c":"markdown","7a4ecbbf":"markdown","ef343210":"markdown","9d08bb8d":"markdown","e5b7dba9":"markdown","0500470d":"markdown"},"source":{"14800534":"#Importing library\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn import metrics\n\n#importing datset\ndataset=pd.read_csv(\"www.kaggle.com\/karanchoudhary103\/nasa_as\/nasa.csv\")\n\n# import time for comparing Tuning methods\nfrom time import time\nstart=0\n#droping dataset coloumns\ndataset.drop( ['Close Approach Date'], axis = 1, inplace = True)\ndataset.drop( ['Orbiting Body'], axis = 1, inplace = True)\ndataset.drop( ['Orbit Determination Date'], axis = 1, inplace = True)\ndataset.drop( ['Equinox'], axis = 1, inplace = True)\n\ndataset.drop(dataset.iloc[:,[0,1,2,4,5,6,7,8,9,10,11,12,13,14,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34]],axis=1, inplace = True)\n\n\n#data conversion into dependent and target varible \nX = dataset.iloc[:,:-1]\nY = dataset.iloc[:,-1]\n\n\n\n\n","25f9382d":"#Label Encoding for enodig the raget varibles\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_Y = LabelEncoder()\nlabelencoder_Y.fit_transform(Y)\n#spiltting data into training and testing \nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,random_state=22)\n\n\n#standard scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n","3845cbdb":"#Loading and fitting data into Knn\nfrom sklearn.neighbors import KNeighborsClassifier\nneighbors = KNeighborsClassifier(n_neighbors=10)  \nneighbors.fit(X_train, Y_train)\nneighbors\n","bc64864e":"#Accuracy\nfrom sklearn.metrics import accuracy_score\n# Predict using 10-NN Classifier\ny_pred = neighbors.predict(X_test)\ny_pred[0:20]\naccuracy_score(Y_test,y_pred)*100\n","bac1c225":"#FEATURE SELECTION\n#the selction of k value method\n#Searching for the best K in the dataset\nK = 10\nmean_acc = np.zeros((K-1))\n#feature selection of k from 1 to 10 which has better accuracy\nfor n in range(1,K):     #range (start ,end)\n    \n    #Train Model and Predict \n    #constructing it  for k=1 to k=10 cross validation\n    neighbors = KNeighborsClassifier(n_neighbors = n)                 #Assigning value of n(1 to 10) in the loop\n    neighbors.fit(X_train,Y_train)       #fitting data\n    y_pred=neighbors.predict(X_test)    #predicting\n    mean_acc[n-1] = metrics.accuracy_score(Y_test, y_pred)    #Storing Accuracy of the each cross validation \n\n\n","3fc527ce":"mean_acc                                 #printing values of k\nprint(\"For the values k=1 to k=9: \\n\",mean_acc)","64cb4d4c":"mean_acc.mean()                       #mean of all rhe values of k (1 to10)\nprint(\"The value is mean of all values k=1 to k=9   : \",mean_acc.mean()*100)","2ce82b39":"#plotting the graph for the selection of the k th values\n#Bar plot for training data\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])#left,bootom ,width ,height                                                                                             #Add an axes to the figure.\n\nvalue_k = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]     #X AXIS\naccuracy = [0.81236674, 0.84434968, 0.8336887,  0.84648188 ,0.84221748, 0.86034115,\n 0.84861407, 0.85927505 ,0.85607676]                         #Y AXIS\nax.bar(value_k,accuracy,color='rgkyc')        #rgkyc-different color\nplt.title(\"Training Accuracy\",fontsize=25)    #title label\nplt.xlabel(\"Value of k\",fontsize=15)    #X label\nplt.ylabel(\"Rate in terms of percent\",fontsize=15)    #Y label\nplt.show()    #Display a figure\n","bd266b14":"#For cross validation\nfrom sklearn.model_selection import cross_val_score\nknn_scores = []\n#cross validation for the k value from 1 to 10\nfor k in range(1,10):\n    knn_classifier = KNeighborsClassifier(n_neighbors = k)         #Assigniing value of k form 1 to 10\n    score=cross_val_score(knn_classifier,X_train,Y_train,cv=10)      #cross validation forr va;lues 1 to 10 each time running cv=10\n    knn_scores.append(score.mean())","e0897db9":"score   #values of accuracy for the k=1 to k=10","1497ccdb":"score.mean()*100    #mean of cross validation","f381ba81":"#Plot y versus x as lines and\/or markers for the ten values in it\nplt.plot([k for k in range(1, 10)], knn_scores, color = 'blue')\nfor i in range(1,10):     #start,stop\n    plt.text(i, knn_scores[i-1], (i,'{:.2f}'.format(knn_scores[i-1]*100)) )     \n    #text for te  values accuracy in X-Y plot\nplt.xticks([i for i in range(1, 10)])      #Set the current  locations and labels of the x-axis.\nplt.xlabel('Number of Neighbors (K)',fontsize=15)   #assign labels for the X axis\nplt.ylabel('Scores',fontsize=15,color=\"RED\")        #assign labels for the Y axis\nplt.title('K Neighbors Classifier scores [1-9]',fontsize=15,color=\"BLUE\")    #assign labels for the Title of the graph","dbb9c3c4":"print(\"The best accuracy of k is 6    k=6 --> 86.482\")\n\nprint(\"Accuracy with K-NN with CROSS VALIDATION: %0.2f     STD--> (+\/- %f)\" % (score.mean()*100, score.std() *2*100))\n","9069d1e5":"\n#starting of the tuning methods\nfrom sklearn.model_selection import RandomizedSearchCV\n#RandomizedSearchCV tuning method which does tuning on sample\nfrom scipy.stats import randint    #for importing random values \n\nest = KNeighborsClassifier(n_jobs=-1)\n#assigning hyperameters for randomized search \nrf_p_dist={  'leaf_size' : randint(1,50),\n'n_neighbors' : randint(1,30),\n'p':[1,2]\n  }\n#combinations  50*30*2=3000\n#it will be working for limited sample randomly \ndef hypertuning_rscv(est, rf_p_distr, nbr_iter,X,y):\n    rdmsearch = RandomizedSearchCV(est, param_distributions=rf_p_distr,\n                                  n_jobs=-1, n_iter=nbr_iter, cv=5)\n    #CV = Cross-Validation (Stratified KFold CV)\n    rdmsearch.fit(X,y)               #fitting training data\n    ht_params = rdmsearch.best_params_            #best parameter\n    ht_score = rdmsearch.best_score_               #best accuracy\n    return ht_params, ht_score                       #returning values for the best paramterand its score\n\n\nrf_parameters, rf_ht_score = hypertuning_rscv(est, rf_p_dist, 5, X_train, Y_train)\n#classifier,iteartions,ttraining data\nprint(\"best aprmeters\",rf_parameters)\nprint(\"best score\",rf_ht_score)\n\n\n\n","df648550":"#evaluting for the best k=6 values from feature selection\nfrom sklearn.neighbors import KNeighborsClassifier\nneighbors = KNeighborsClassifier(n_neighbors=6)  #neighbours=6 \nneighbors.fit(X_train, Y_train) #fitting data\ny_pred=neighbors.predict(X_train)  #predciting training data\n","fcbc0d51":"from sklearn.metrics import classification_report\nreport = classification_report(Y_train,y_pred)\nprint(report)\n#for the training data","b880cbcc":"#PLOTTING AUC AND ROC FOR CLASSIFICATION PROBLEM \nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc, precision_recall_curve,f1_score\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\n\nns_probs = [0 for _ in range(len(Y_test))]\n# fit a model\n\n\n# predict probabilities\nlr_probs = neighbors.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# calculate scores\nns_auc = roc_auc_score(Y_test, ns_probs)\nlr_auc = roc_auc_score(Y_test, lr_probs)\n# summarize scores\nprint('AUC=%.3f' % (ns_auc))\nprint('ROC=%.3f' % (lr_auc))\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='AUC')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()\n","490f4e99":"#loading and fitting the dataset\nfrom sklearn.svm import SVC\nclf = SVC(kernel = 'linear')               #Assigning kernel(linear,rbf,ploy.) according to the dataset \nclf.fit(X_train, Y_train)                     #fitting in to training data\n#training\ny_pred=clf.predict(X_train)                     #fitting in to training data for prediction\n#testing\ny_pred1=clf.predict(X_test)                            #fitting in to testing data for prediction\nclf","f5f268f1":"from sklearn.metrics import accuracy_score\nprint(\"training accuracy for SVC  :\",accuracy_score(Y_train,y_pred)*100)    #Accuarcy for training\nprint(\"test accuracy  for SVC     :\",accuracy_score(Y_test,y_pred1)*100)    #Accuracy for testing","9f06010f":"#3D view of scattter plot for the independent varibales with target variable\nfrom mpl_toolkits.mplot3d import Axes3D   #tool kit of matplotlib for plotting 3d data into 2d\nfig = plt.figure()                 #for creating new figure\nax = fig.add_subplot(111, projection='3d')                   #*nrows*, *ncols*, and *index*\nx = dataset['Est Dia in KM(min)']                     \ny = dataset['Miss Dist.(Astronomical)']\nz= dataset['Hazardous']\nax.scatter(x, y, z)    #array like data positions for X,Y,Z\nax.set_xlabel('Est Dia in KM(min)')                     #Assigning labels for the dataset which we have computed in  x axis\nax.set_ylabel('Miss Dist.(Astronomical)')               #Assigning labels for the dataset which we have computed in  y axis\nax.set_zlabel('Hazardous')                               #similarly for z axis\nplt.title('3D plot of X1 ,X2 and Y ')                    #title label\nplt.show()                                              #plotiing the figure\n","60248b93":"#visulizing the plane which would seperate the the points\ntmp = np.linspace(-1,20,20)   #Return evenly spaced numbers over a specified interval.\n\nx,y = np.meshgrid(tmp,tmp)  #Return coordinate matrices from coordinate vectors\n#Lambda functions solve this problem. First, we create a lambda function, and assign it to a variable. \n#Then we show that variable is a function, and that we can call it with an argument.\nz = lambda x,y: (-clf.intercept_[0]-clf.coef_[0][0]*x-clf.coef_[0][1]*y) \/ clf.coef_[0][1]\n# The equation of the separating plane is given by all x so that np.dot(svc.coef_[0], x) + b = 0.\nfig = plt.figure()\nax  = fig.add_subplot(111, projection='3d')   #(111)-->row,col,index of particular\nax.plot_surface(x, y, z(x,y),cmap=\"hot\")            #For Creating a surface plot.\nax.set_xlabel('Est Dia in KM(min)')                   #Assigning labels for the x ,y ,z\nax.set_ylabel('Miss Dist.(Astronomical)')             #Assigning labels for the x ,y ,z\nax.set_zlabel(\"HAZARDOUS\")                            #Assigning labels for the x ,y ,z\nplt.title(\"3d plot for SVM\")                             #Assigning label ffor thr titls\nplt.show()","6a918e8a":"#cross validation value with accuracy and standard deviation\nfrom sklearn.model_selection import cross_val_score\n\npred_kfold = cross_val_score(clf, X_train, Y_train, cv=10)  #apllying on training data with cv=10 default \n \nprint(\"Accuracy with SVC and K-FOLD CROSS VALIDATION: %0.2f (+\/- %0.4f)\" % (pred_kfold.mean()*100, pred_kfold.std() * 2))\n\n","7614d8aa":"#starting of the tuning methods\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.svm import SVC\n\n#RandomizedSearchCV tuning method which does tuning on sample\nfrom scipy.stats import randint    #for importing random values \n\nest = SVC()\n#assigning hyperameters for randomized search \nrf_p_dist={  \n  'kernel':['linear',\"rbf\",\"sigmoid\"],\n          \"decision_function_shape\":[\"ovo\",\"ovr\"],\n'gamma':[\"scale\", \"auto\"]}\n#it will be working for limited sample randomly \ndef hypertuning_rscv(est, rf_p_distr, nbr_iter,X,y):\n    rdmsearch = RandomizedSearchCV(est, param_distributions=rf_p_distr,\n                                  n_jobs=-1, n_iter=nbr_iter, cv=5)\n    #CV = Cross-Validation (Stratified KFold CV)\n    rdmsearch.fit(X,y)               #fitting training data\n    ht_params = rdmsearch.best_params_            #best parameter\n    ht_score = rdmsearch.best_score_               #best accuracy\n    return ht_params, ht_score                       #returning values for the best paramterand its score\n\n\nrf_parameters, rf_ht_score = hypertuning_rscv(est, rf_p_dist, 5, X_train, Y_train)\n#classifier,iteartions,ttraining data\nprint(\"best aprmeters\",rf_parameters)\nprint(\"best score\",rf_ht_score)\n\n","cf01d610":"#cross validation value with accuracy and standard deviation\nfrom sklearn.metrics import classification_report\nreport = classification_report(Y_train,y_pred)    #Build a text report showing the main classification metrics\nprint(\"                  Classification report of training data \")\nprint(report)\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(Y_test,y_pred1)                           #Accuarcy\nprint(\"The accuracy of the SVM will be:\",accuracy_score(Y_train,y_pred))\n","75c2f260":"#INCREASING THE NUMBER OF TREES","138a3e6c":"\n# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')       #n_estimators-int value #entropy here defines criteria for info. gain and   \nclassifier.fit(X_train, Y_train)        #fitting dat into training\nprint(classifier)\n","e259c53b":"#starting of the tuning methods\nfrom sklearn.model_selection import RandomizedSearchCV\n#RandomizedSearchCV tuning method which does tuning on sample\nfrom scipy.stats import randint    #for importing random values \n\nest = RandomForestClassifier(n_jobs=-1)\n#assigning hyperameters for randomized search \nrf_p_dist={'max_depth':[3,5,10],                               #max_depth=depth of tree\n              'n_estimators':[10,100,200,300,400,500],          #NO. of tree\n              'max_features':randint(1,3),               #features\n               'criterion':['gini','entropy'],                #infoo gain,gini index, gain ratio\n               'bootstrap':[True,False],   #with replacement\n               'min_samples_leaf':randint(1,4),   #leafes\n              }\n\n#we have  3*6*3*2*2*4=864 combinations for the randomised search we will be using\n#it will be working for limited sample randomly \n","631534e7":"def hypertuning_rscv(est, rf_p_distr, nbr_iter,X,y):\n    rdmsearch = RandomizedSearchCV(est, param_distributions=rf_p_distr,\n                                  n_jobs=-1, n_iter=nbr_iter, cv=5)\n    #CV = Cross-Validation (Stratified KFold CV)\n    rdmsearch.fit(X,y)               #fitting training data\n    ht_params = rdmsearch.best_params_            #best parameter\n    ht_score = rdmsearch.best_score_               #best accuracy\n    return ht_params, ht_score                       #returning values for the best paramterand its score\n","acd86925":"\n\nrf_parameters, rf_ht_score = hypertuning_rscv(est, rf_p_dist, 5, X_train, Y_train)\n#classifier,iteartions,ttraining data\nrf_parameters\nrf_ht_score\n","fdd97149":"#Assigning best values for trainig data with hyperparmetrs\nclaasifier_tune=RandomForestClassifier(bootstrap= True,\n criterion= 'gini',\n max_depth= 5,\n max_features=2,\n min_samples_leaf= 2,\n n_estimators= 10)\n","e5c28084":"#fitting data\n#prediction for training data\n#prediction for testing data\nclaasifier_tune.fit(X_train, Y_train)\ny_pred=claasifier_tune.predict(X_train)\ny_pred1=claasifier_tune.predict(X_test)\nprint(\"The train accuracy of the random forest randizedtuned:\",accuracy_score(Y_train,y_pred)*100)\nprint(\"The test accuracy of the random forest randizedtuned:\",accuracy_score(Y_test,y_pred1)*100)\n\n","2ae33858":"\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\n\ncm = confusion_matrix(Y_train, y_pred)\n#precision values for false positive rate\n#recall values for false negative rate\ncross_val=cross_val_score(claasifier_tune,X_train,Y_train,cv=10,scoring='accuracy')\ncross_val1=cross_val_score(claasifier_tune,X_train,Y_train,cv=10,scoring='precision')\ncross_val2=cross_val_score(claasifier_tune,X_train,Y_train,cv=10,scoring='recall')\n","b2082779":"\nprint(\"The value of training data for 10 values:\")\nprint(cross_val)\nprint(\"  The value of training data mean for accuracy :\",cross_val.mean()*100)\nprint(\" \")\nprint(\" \")\nprint(\"The value of training data for 10 values of precsion:\")\nprint(cross_val1)\nprint(\"  The value of training data mean for precision:\",cross_val1.mean()*100)\nprint(\" \")\nprint(\" \")\nprint(\"The value of training data for 10 values of recall:\")\nprint(cross_val2)\nprint(\"  The value of training data meanfor recall:\",cross_val2.mean()*100)\n\n\n","ad21fe35":"print(\"Accuracy  of the training data through randomised tuning:\",rf_ht_score*100)\n\nprint(\"The value of  acuuracy training data through k-croos validation:\",cross_val.mean()*100)\n\nprint(\"The value of precision training data through k-croos validation :\",cross_val1.mean()*100)\n\nprint(\"The value of recall training data through k-croos validation :\",cross_val2.mean()*100)\n","3c2bb05f":"#PLOTTING AUC AND ROC FOR CLASSIFICATION PROBLEM \nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\n\nfrom matplotlib import pyplot\n\n# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')       #n_estimators-int value #entropy here defines criteria for info. gain and   \nclassifier.fit(X_train, Y_train)        #fitting dat into training\n\nns_probs = [0 for _ in range(len(Y_test))]\n# fit a model\n\n# predict probabilities\nlr_probs = classifier.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# calculate scores\nns_auc = roc_auc_score(Y_test, ns_probs)\nlr_auc = roc_auc_score(Y_test, lr_probs)\n# summarize scores\nprint('AUC=%.3f' % (ns_auc))\nprint('ROC=%.3f' % (lr_auc))\n\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='AOC')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.title(\"Random forest classifier\")\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()\n","7697e39c":"#Comparring of randomizedserachCV and gridsearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier()\nada.fit(X_train,Y_train)   #training data\nada","edae760a":"#prediction for ADA boost\ny_pred = ada.predict(X_train)                  #prediction for the training data\ny_pred[:20]                                     #predction for the first 20 values\n","c8c5cc7e":"#Tuning methods and comparing Them","ebfac82b":"\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.model_selection import RandomizedSearchCV\n#RandomizedSearchCV-\nfrom scipy.stats import randint  #for random integer values\n\nest = AdaBoostClassifier()\nrf_p_dist={\n 'n_estimators': [50, 100,200,300,90],\n 'learning_rate' : [0.01,0.05,0.1,0.3,1,0.8],\n              \n  'algorithm':['SAMME.R','SAMME']                        #algo here is for more data SAMME.R  for lower computaion\n  \n          }\ndef hypertuning_grid(est, rf_p_dist, nbr_iter,X_train,Y_train):\n    rdmsearch = RandomizedSearchCV(est, param_distributions=rf_p_dist,\n                                  n_jobs=-1, n_iter=nbr_iter, cv=5)\n    rdmsearch.fit(X_train,Y_train)                  #fitting data\n    ht_params = rdmsearch.best_params_             #best paramter\n    ht_score = rdmsearch.best_score_                     #best scorer\n    return ht_params, ht_score                      #returning values for the best accuracy and the best paprmeters\n\n","fb817721":"rf_parameters_ran, rf_ht_score_ran = hypertuning_grid(est, rf_p_dist, 1, X_train, Y_train)\nend=time()                         #starting time\ntrain_time_adatune=end-start                 #end time\nprint(\"train_time_ada_rand_tune  :\",train_time_adatune)\n","d2db1427":"print(\"accuracy of training data \",rf_ht_score_ran*100)                    #accuracy with traing data","a2d810ad":"#Now compute the time for Grid Search CV and campare\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nest=AdaBoostClassifier()\nfrom scipy.stats import randint\nparameters={\n 'n_estimators': [50, 100,200,300,90],           #no of trees\n 'learning_rate' : [0.01,0.05,0.1,0.3,1,0.8],             #rate of learning for assigning optimal local iinima.\n              \n  'algorithm':['SAMME.R','SAMME']\n  \n          }\n\ngrid_search = GridSearchCV(estimator = est,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv =5,\n                           n_jobs = -1)\ngrid_search = grid_search.fit(X_train, Y_train)                    #fitting data\nend=time()                                          #starting time\ntrain_aadagrid=end-start              #end time\nprint(\"train_aadagrid\",train_aadagrid)","2371c7a9":"\naccuracy = grid_search.best_score_\n\nprint(\"Accuracy of the training ada boost gridsearch \",accuracy*100)","d35fae67":"#taking the last 3 values\ntime_randomised=630.1231083    #158707630.123183 time for training\ntime_grid=904.1174705      #1587070904.1174705 time for training\n\ntime_diff=time_grid-time_randomised\nprint(\"time_randomised  :\",time_randomised)# in this we are making iterations 20\nprint(\"time_grid        :\",time_grid)# In this we are making iterations 5\nprint(\"time_diff        :\",time_diff)\nprint(\" \")","87acec87":"#Plotting the difference for these values","d6cc3d07":"model = [   \"adaboost_rand\" ,\"adaboost_grid\",\"adaboost_diff\"]   #X-axis\nTrain_Time = [\n    \n    time_randomised,\n    time_grid,\n    time_diff                #diff is small in terms of value\n]\nplt.bar(model, Train_Time,color=\"grb\")    #bar plotting\nplt.xlabel('Models', fontsize=15)    #  X-labels\nplt.ylabel('Training Time', fontsize=15)   #  Y-labels\nplt.title('Comparison of Training Time ',fontsize=25)   #title\nplt.show()                 #plot figure\n","fbd781bb":"#PLOTTING AUC AND ROC FOR CLASSIFICATION PROBLEM \nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\n\nfrom matplotlib import pyplot\nfrom sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier()\nada.fit(X_train,Y_train)   #training data\n\nns_probs = [0 for _ in range(len(Y_test))]\n# fit a model\n\n# predict probabilities\nlr_probs = ada.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# calculate scores\nns_auc = roc_auc_score(Y_test, ns_probs)\nlr_auc = roc_auc_score(Y_test, lr_probs)\n# summarize scores\nprint('AUC=%.3f' % (ns_auc))\nprint('ROC=%.3f' % (lr_auc))\n\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='AOC')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.title(\"ADA BOOST\")\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()\n","3fed6d80":"#ensemble learning works on boosting parallel learning from the errror from the \nfrom sklearn.ensemble import GradientBoostingClassifier\nGBC=GradientBoostingClassifier()\nGBC.fit(X_train,Y_train)   #fitting training data\n","77a754ef":"y_pred=GBC.predict(X_train)   #prediction for the x train\ny_pred[:10]        #prediction for the 10 values","65e5042d":"accuracy_score(Y_train,y_pred)*100                 #acuuracy","d2d2dd46":"\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nest=GradientBoostingClassifier()  \nfrom scipy.stats import randint\nparameters={\n    'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001],       #rate of learning for assigning optimal local iinima \n    \"max_depth\":[1,3,5,7,9],                                   #assigning depth for the trees\n    'n_estimators':[100,250,500,750,1000,1250,1500,1750]}             #assigning valies for theom of trees\n#combinations 6*5*8=240 combinantions\ngrid_search = GridSearchCV(estimator = est,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 5,\n                           n_jobs = -1)","25cc3a12":"grid_search = grid_search.fit(X_test, Y_test)    #fitting data\nprint(\"Accuracy for the training Gradient descent :\",accuracy_score(Y_train,y_pred)*100)\nprint(\"Accuracy for the testing Gradient descent :\",accuracy_score(Y_test,y_pred1)*100)","5fc736ea":"#PLOTTING AUC AND ROC FOR CLASSIFICATION PROBLEM \nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\n\nfrom matplotlib import pyplot\nfrom sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier()\nada.fit(X_train,Y_train)   #training data\n\nns_probs = [0 for _ in range(len(Y_test))]\n# fit a model\n#ensemble learning works on boosting parallel learning from the errror from the \nfrom sklearn.ensemble import GradientBoostingClassifier\nGBC=GradientBoostingClassifier()\nGBC.fit(X_train,Y_train)   #fitting training data\n\n# predict probabilities\nlr_probs = GBC.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# calculate scores\nns_auc = roc_auc_score(Y_test, ns_probs)\nlr_auc = roc_auc_score(Y_test, lr_probs)\n# summarize scores\nprint('AUC=%.3f' % (ns_auc))\nprint('ROC=%.3f' % (lr_auc))\n\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='AOC')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.title(\"GRADIENT BOOSTING\")\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()\n","a89bc9b9":"#XGBOOST  BEST MODEL","e01e0c11":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train,Y_train)\n","0fc24936":"#fitting data\n#prediction for training data\n#prediction for testing data\ny_pred=claasifier_tune.predict(X_train)\ny_pred1=claasifier_tune.predict(X_test)\nprint(\"The train accuracy of the random forest randizedtuned:\",accuracy_score(Y_train,y_pred)*100)\nprint(\"The test accuracy of the random forest randizedtuned:\",accuracy_score(Y_test,y_pred1)*100)\n\n","b543a6b8":"#prediction for XG boost\ny_pred = xgb.predict(X_train)                  #prediction for the training data\ny_pred[:20]                                     #predction for the first 20 values\n\nfrom xgb import XGBClassifier\n\nfrom sklearn.model_selection import RandomizedSearchCV\n#RandomizedSearchCV-tuning approach which works on sample of the dataset\nfrom scipy.stats import randint  #for random integer values\n\nest =XGBClassifier()\nrf_p_dist={\n    'subsample':[0.8,0.2,0.5,0.4,0.36],                        \n    'min_child_weight':[5,10,15,4,2],\n    'max_depth':[1,2,3,5,4],\n    'gamma':[0.1,0.2,0.5,0.60,0.8,0.91]\n}\ndef hypertuning_grid(est, rf_p_dist, nbr_iter,X_train,Y_train):\n    rdmsearch = RandomizedSearchCV(est, param_distributions=rf_p_dist,\n                                  n_jobs=-1, n_iter=nbr_iter, cv=15)\n    rdmsearch.fit(X_train,Y_train)                  #fitting data\n    ht_params = rdmsearch.best_params_             #best paramter\n    ht_score = rdmsearch.best_score_                     #best scorer\n    return ht_params, ht_score                      #returning values for the best accuracy and the best paprmeters\n\n","4b7e3b78":"\nrf_parameters, rf_ht_score = hypertuning_rscv(est, rf_p_dist, 15, X_train, Y_train)\n#classifier,iteartions,ttraining data\nrf_parameters\nprint(\"best parameters  :\",rf_parameters)\nprint(\"best scorer  :\",rf_ht_score*100)\n","49130a08":"#PLOTTING AUC AND ROC FOR CLASSIFICATION PROBLEM \nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\n\nfrom matplotlib import pyplot\nns_probs = [0 for _ in range(len(Y_test))]\n# fit a model\n#ensemble learning works on boosting parallel learning from the errror from the \nfrom xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train,Y_train)\n\n# predict probabilities\nlr_probs = xgb.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# calculate scores\nns_auc = roc_auc_score(Y_test, ns_probs)\nlr_auc = roc_auc_score(Y_test, lr_probs)\n# summarize scores\nprint('AUC=%.3f' % (ns_auc))\nprint('ROC=%.3f' % (lr_auc))\n\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='AOC')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.title(\"XG BOOST\")\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()\n","4013142a":"#Bagging Fot\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nbagging = BaggingClassifier(KNeighborsClassifier(n_neighbors=11),\n                            max_samples=0.9, max_features=2)\nbagging.fit(X_train, Y_train)\n\n\nfrom sklearn.metrics import accuracy_score\n# Predict using 10-NN Classifier\na=accuracy_score(Y_test,y_pred)*100\ny_pred = bagging.predict(X_test)\ny_pred[:20]\nprint(a)","58f75c94":"\n#Bar plot for training data\nfig = plt.figure()  #creating anew figure\nax = fig.add_axes([0,0,1,1])#width,height\nAlgorithms = ['logistic regression','naive bayes','decision tree','Svm','knn','ada boost','Random_tree_cv','Random_tree_tuning','GradientBoosting']\naccuracy = [84.2,82.5,84.648,85.382,82.3,87.409,85.463,86.567,87.803]\nax.barh(Algorithms,accuracy,color='rbgy')                  #horizontal bargraph with color\n\nplt.title(\"model vs accuracy\",fontsize=25)           #label of title\nplt.xlabel(\"Algorithms\",fontsize=20)                       #X label\nplt.ylabel(\"Accuracy\",fontsize=20)                             #Y label\nplt.show()                                                     #creating plot","edd7e88d":"#Saving all the images and then used in if andd else loop \nimport cv2\n#reading the images in the form of arrays\nimg = cv2.imread('knn1.png')\nimg1 = cv2.imread('knn2.png')\nimg2 = cv2.imread('svc1.png')\nimg3 = cv2.imread('svc2.png')\nimg4 = cv2.imread('ADA.png')\nimg5 = cv2.imread('Models.png')\nimg6 = cv2.imread('xgB.png')\n#plotting the images in the png format\nplt.imshow(img)\nplt.imshow(img1)\nplt.imshow(img2)\nplt.imshow(img3)\nplt.imshow(img4)\nplt.imshow(img5)\nplt.imshow(img6)\nprint(plt.imshow(img5))\n\nprint(plt.imshow(img4))\nprint(plt.imshow(img))\nprint(plt.imshow(img2))\nprint(plt.imshow(img1))\n\nprint(plt.imshow(img3))","7ea0016f":"#Enter the name of classifier and then check the value for it\nclassifier_search = int(input('PRESS KEY\\n1.KNN for featuere selection of K \\n2.KNN for CROSS VALIDATION \\n3.KNN CAMPARE CROSS VALIDATION VS ACCUARCY OF THE BEST K VALUE\\n4.SVC ACCURACY FOR TRANING AND TESTING ACCURACY\\n5.SVC CROSS VALIDATION AND HYPERPLANE:\\n6.Random forest randizedtuned\\n7.Random forest accuracy,precesion,recall\\n8.Time of random and grid searchCV and accuracy\\n9.Comparing the time of tuning methods and plotting graph\\n10.Models ACCUARCY\\n11.Xg boost acuuracy with tuning')) \n\nif classifier_search== 1: \n    print(\"KNN\")\n    print(\"For the values k=9 to k=1:\",mean_acc)\n\n    print(plt.imshow(img))\n\nelif classifier_search==2: \n    print(\"Croos validation score for Cv=10 for 10 values of k\",score)\n    print(\"Croos validation score for Cv=10 for 10 values of k mean\",score.mean())\n    print(plt.imshow(img1))\n\nelif classifier_search==3:\n    print(\"The best accuracy of k is 2    k=2 & its acuuracy value is 84.482\")\n    print(\"Accuracy with K-NN and K-FOLD CROSS VALIDATION: %0.2f     STD--> (+\/- %f)\" % (score.mean()*100, score.std() *2))\n    print(\"Switch to other model\")\n    \nelif classifier_search==4:\n\n    print(\"training accuracy for SVC:\",accuracy_score(Y_train,y_pred))\n    print(\"test accuracy  for SVC   :\",accuracy_score(Y_test,y_pred1))    \n    print(\"The 3d plot of the SVC  \",plt.imshow(img2))\nelif classifier_search==5:\n    print(\"The hyperplane of the points  SVC(3-D)  \",plt.imshow(img3))\n    print(report)\n    print(\"The accuracy of the SVM will be:\",accuracy_score(Y_train,y_pred))\n\nelif classifier_search==6:    \n    print(\" RANDOM FOREST TUNED \")\n    print(\"The train accuracy of the random forest randizedtuned:\",accuracy_score(Y_train,y_pred)*100)\n    print(\"The test accuracy of the random forest randizedtuned:\",accuracy_score(Y_test,y_pred1)*100)\n\nelif classifier_search==7:\n\n    print(\"The value of training data for 10 values:\")\n    print(cross_val)\n    print(\"  The value of training data mean:\",cross_val.mean()*100)\n    print(\" \")\n    print(\" \")\n    print(\"The value of training data for 10 values of precsion:\")\n    print(cross_val1)\n    print(\"  The value of training data mean:\",cross_val1.mean()*100)\n    print(\" \")\n    print(\" \")\n    print(\"The value of training data for 10 values of recall:\")\n    print(cross_val2)\n    print(\"  The value of training data mean:\",cross_val2.mean()*100)\n    \nelif classifier_search==8:\n    \n    print(\"train_time_ada_rand_tune  :\",train_time_adatune)\n    print(\"accuracy of training data \",rf_ht_score_ran*100)\n    print(\"train_ada_grid\",train_aadagrid)\n    print(\"Accuracy of the training ada boost gridsearch for each value\",accuracy*100)\n    \nelif classifier_search==9:\n    \n    print(\"Accuracy of the training ada boost gridsearch    : 86.70944251800479\")\n    print(\"accuracy of training data  for ada Ransearch_cv  :\"  ,rf_ht_score_ran*100)\n    print(\"Bar plot for the differnece in the time \")\n    print(plt.imshow(img4))\n        \n\nelif classifier_search==10:\n    print(\"HERE ARE THE DIFFERENT MODELS AND THERE ACCURACY \")\n    print(plt.imshow(img5))\nelif classifier_search==11:\n    print(\"Accuracy of the training xgboost random search : 88.36  \")\n    \nelse :\n    print(\"\\t                                            Wrong Input Value\")\n    print(\"                                          Enter value lies betwwen 1 to 10 \")\n    print(\"\")\n","b98bc8f2":"#USE ANN method For the dataset to compute more accuracy in terms of count\n#install library\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n#Initalizing the Ann\n\n#Making the prediction model test and results\nclassifier=Sequential()\n#adding the firstinput layer and the first hidden layers in the neural\nclassifier.add(Dense(output_dim=5,init=\"uniform\",Activation=\"relu\",input_dim=2))\n#As, deep learning is consist of  all the input,hidden,output layers where hidden layers are more for better acauuracy in terms\n#of actual nad predicted so we can end with this layer but more better undersatnding we keep adding of the layers\n\n#adding second hidden layer\nclassifier.add(Dense(output_dim=2,init=\"uniform\",Activation=\"relu\"))\n\n#making the final layer output layer where ewe use sigmoid function we will have prbability for the 0 or 1\n\nclassifier.add(Dense(output_dim=1,init=\"uniform\",Activation=\"sigmoid\"))\n# if we have more than 2 catequiers in the dependent function we will have tochnage sigmoid to shift-max and also out_deim\n\n#prediction from the actual ones.\nclassifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrices=['accuracy'])   #metrices we wnat fot precision of TP\n\n\n#to choose the epox at each round\n#A epoch here is process a complete visit of forward and backward propgation once.  \nclassifier.fit(X_train,Y_train,batch_size=10,nb_epoch=100)   \n\n#prediction of the classifier\ny_pred=classifier(X_test)\ny_pred= (y_pred>0.5)  # assigninhg threshold value to it genearlly we shold take value 0.65\n#confusion matricx,accuracy\nfrom sklearn.metrics import confusion_metrics\nfrom sklearn.metrics import accuracy_score\ncm=confusion_metrics(Y_train,y_pred)\naccuracy_score(Y_train, y_pred)\n","2ae19266":"#DEEP LEARNING \n","be480e8d":"NASA ASTEROID PREDICTION\nDATASET FROM  KAGGLE\nTOPICS TO BE COVERED:\n1.KNN\n2.SVC\n3.RANDOM FOREST CLASSIFIER\n4.ADA BOOST\n5.GRADIENT BOSSTING\n6.XG BOOST\n7.FEATURE SELECTION,CROSS VALIDATION ,HYPERPARAMETER TUNING,RUC AUC GRAPH FOR ALL THE MODELS\n8.ARTIFICAL NEURAL NETWORK (DEEP LEARNING)\n","8ec16eb2":"# Classification report of knn for the best knn value","a534a18f":"\nNow,then we go for the deep learning part  -->ANN(Artifical Neural Networks)\n\nHERE ARE THE STEPS:\nWeight are assigned at each layer of neural network\nForward propogation takes place by assigning weight and \nthen applying activation function from input values to the end of hidden layer and\nEvaluating the predicted dependent variable with the actual dependent variable\nEvaluating of output of input layer to hidden layer\nEvaluating of output of hidden layer to output layer\nEvaluating of Error\nThen reassigning the optimal weights for the same neural networks through Backpropgation\nUntil the cost function of it not be in Decreases further.                             '''","fc8f4617":"OVERVIEW\n1. Load the data and fit it \n2. Now the speration aprt which separte  the classes through a hyperplane\n3. For the maximum sepration we should have maximum seration between the classes we will assighn support vectors\n4. maximum sepertaion tell which data belongs to which class it classify.","8a1ebcbc":"# SVC","08434cc4":"# Ada boost and campare of tuning methods\n","2590287e":"# Prediction","49e6754c":"# KNN cv","7a4ecbbf":"#GRADIENT BOOSTING","ef343210":"# Random forest ","9d08bb8d":"# KNN","e5b7dba9":"# Time to check the better ones in terms of computation time ","0500470d":"BASIC IMPLEMENATION OF KNN\n1.Load the data\n2.Initialize K to your chosen number of neighbors\n3. For each example in the data\n3.1 Calculate the distance between the query example and the current example from the data.\n3.2 Add the distance and the index of the example to an ordered collection\n4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\n5. Pick the first K entries from the sorted collection\n6. Get the labels of the selected K entries\n7. If regression, return the mean of the K labels\n8. If classification, return the mode of the K labels\n"}}