{"cell_type":{"6541b45b":"code","1ded107c":"code","7d4e9b22":"code","bee70009":"code","57938683":"code","f60b90de":"code","710711ce":"code","78c29b5c":"code","77953de6":"code","7c39cfba":"code","503c6f88":"code","3bfebc24":"code","a64da819":"code","2816044b":"code","41b91bad":"code","5386fbb7":"code","dc472a8d":"code","55ea1820":"code","5302317c":"code","9f7c2cf2":"code","aa2be943":"markdown","0493ba0f":"markdown","f3b80444":"markdown","78733c9a":"markdown","130e782f":"markdown","c0184c67":"markdown","1a137890":"markdown","faf6b529":"markdown","01a4c331":"markdown","9b61507c":"markdown","1123f28b":"markdown","8843fc42":"markdown","b3c11d80":"markdown","c7814fef":"markdown","86f48a1f":"markdown","1c9a62db":"markdown","d586176c":"markdown","4a2269ea":"markdown","909de358":"markdown","38cf0851":"markdown","bed49d8f":"markdown","4c55dfb0":"markdown","c821f4f5":"markdown","ac1aea43":"markdown","b355d91c":"markdown","7db95df3":"markdown","60b66bdc":"markdown","36750fcb":"markdown","bb390357":"markdown","e2c0f3ac":"markdown","bf8c0225":"markdown","04a1791e":"markdown","7b3fb5dd":"markdown"},"source":{"6541b45b":"import numpy as np\nfrom numpy import linalg as LA\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import fetch_olivetti_faces\nfrom sklearn.preprocessing import StandardScaler\n\nfrom ipywidgets import interact, interactive, fixed, interact_manual, Layout\nimport ipywidgets as widgets\n\nfrom bokeh.plotting import ColumnDataSource\nfrom bokeh.io import push_notebook, show, output_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.layouts import widgetbox, row\noutput_notebook()","1ded107c":"def plot_gallery(title, images, n_col, n_row, titles=None,cmap=plt.cm.gray):\n    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n    plt.suptitle(title, size=16)\n    for i, comp in enumerate(images):\n        plt.subplot(n_row, n_col, i + 1)\n        vmax = max(comp.max(), -comp.min())\n        plt.imshow(comp.reshape(image_shape), cmap=cmap,\n                   interpolation='nearest',\n                   vmin=-vmax, vmax=vmax)\n        plt.xticks(())\n        plt.yticks(())\n        if titles:\n            plt.title(titles[i])\n    h_s = 0.2 if titles else 0\n    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, h_s)\n\n\nnormalize = lambda X: (X * 255\/X.max()).astype(int)    \n\n# Parameters\nimage_shape = (64, 64)\nrng = np.random.seed(0)","7d4e9b22":"# Load 1 face from olivetti dataset\ndataset = fetch_olivetti_faces(shuffle=True, random_state=rng).data #  we random extract one face\ndata = dataset[100].reshape(image_shape) # the 101th face\n\nprint(\"Image (dataset) shape: %s\" % str(data.shape))","bee70009":"pic = data.reshape(image_shape)\nplt.imshow(pic)\nplt.title('Original image');","57938683":"scaler = StandardScaler()      # \nX = normalize(data)#scaler.fit_transform(data) # 1. standardize data\nU, S_vec, Vt = LA.svd(X)       # 2. apply svd","f60b90de":"###\u00a0Visualize\nprint('U:',U.shape, ', S vector: ', S_vec.shape, ', V*:', Vt.shape)\n# Build the singular values matrix since numpy has returned a vector \nS = np.zeros( X.shape, dtype=complex)\nS[:len(S), :len(S)] = np.diag(S_vec)\n# Reconstruct the image normalizing values on 256 levels\nX_r = normalize( np.dot(U, np.dot(S, Vt)) )\nX_r","710711ce":"plt.imshow( X_r )\nplt.title('Reconstructed image');","78c29b5c":"X.max()","77953de6":"plt.figure(figsize=(15,15))\nplt.subplot(1,3,1)\nplt.imshow( pic )\nplt.title('Original image')\nplt.subplot(1,3,2)\nplt.imshow( X )\nplt.title('Original Standardized')\nplt.subplot(1,3,3)\nplt.imshow( X_r )\nplt.title('Reconstructed image');\nprint( 'MAE: ',  np.sum(np.abs(X - X_r)) \/ np.prod(X.shape) )","7c39cfba":"# Now truncate the matrices\nupto = 9 # number of singular values to consider, previously:image_shape[0]\nS_tr = S.copy()\nS_tr[upto:,upto:] = 0  # set to zero all singular values over the 'upto'th\nX_r = np.dot(U, np.dot(S_tr, Vt))\nX_r = X_r * 255\/X_r.max()\n\nplt.imshow( X_r.astype(int) )\nplt.title('Reconstructed image');","503c6f88":"plt.figure(figsize=(15,15))\nplt.subplot(1,3,1)\nplt.imshow( U )\nplt.title('U, left vectors')\nplt.subplot(1,3,2)\nplt.imshow( S.astype(int), cmap='Greys' )\nplt.title('S, singular values')\nplt.subplot(1,3,3)\nplt.imshow( Vt )\nplt.title('Vt, conj transpose of right vectors');","3bfebc24":"#\u00a0Increasing number of non zero singular values\nprojs  = [] \nproj_t = []\nupto = 9 # number of singular values to consider, previously:image_shape[0]\nfor c in range(upto):\n    #c = 1\n    S_tr = S.copy()\n    S_tr[c:, c:] = 0\n    X_n_x = np.dot(U, np.dot(S_tr, Vt))\n    X_n_x = (X_n_x * 255\/X_n_x.max()).astype(int)\n    projs.append(X_n_x)\n    proj_t.append(c)\n\nn_col, n_row = 3, 3 \nplot_gallery('', projs, n_col, n_row, titles=proj_t)\nfig = plt.gcf()\nfig.suptitle(\"Increasing number of non zero singular values representations\", fontsize=14, y=1);","a64da819":"upto = 6\nU_tr = U[:, :upto]\nS_tr = S[:upto, :upto]\nVt_tr = Vt[:upto, :]\nX_tr_n = normalize( np.dot(U_tr, np.dot( S_tr, Vt_tr )) )\nplt.imshow(X_tr_n);\n\n\n\nprint(\n'Dimension comparison\\n',\n    'U: ',U.shape, '=', np.prod(U.shape) , '; U_tr: ',U_tr.shape, '=', np.prod(U_tr.shape) , '\\n',\n    'S: ',S.shape, '=', np.prod(S.shape) , '; S_tr: ',S_tr.shape, '=', np.prod(S_tr.shape) , '\\n',\n    'V: ',Vt.shape, '=', np.prod(Vt.shape) , '; V_tr: ',Vt_tr.shape, '=', np.prod(Vt_tr.shape) , '\\n',\n    'X: ',X.shape, '=', np.prod(X.shape) , '; X_tr: ',X_tr_n.shape, '=', np.prod(X_tr_n.shape) , '\\n',    \n    '________________', '\\n',\n    'U+S+V = ', str(np.prod(U.shape)+np.prod(S.shape)+np.prod(Vt.shape)), '\\n',\n    'U_tr+S_tr+V_tr = ', str(np.prod(U_tr.shape)+np.prod(S_tr.shape)+np.prod(Vt_tr.shape)),'\\n',\n    'Compressed to', str(\n        (np.prod(U_tr.shape)+np.prod(S_tr.shape)+np.prod(Vt_tr.shape))*100 \/ (np.prod(U.shape)+np.prod(S.shape)+np.prod(Vt.shape))\n        \n        ),'%'\n    )","2816044b":"#\u00a0first nine singular values single combination\nprojs  = [] \nproj_t = []\nn_comp = 9\nfor c in range(n_comp):\n    #c = 1\n    S_x = np.full_like(S, 0)\n    S_x[c, c] = S[c, c]\n    X_n_c = np.dot(U, np.dot(S_x, Vt))\n    X_n_c = (X_n_c * 255\/X_n_c.max()).astype(int)\n    projs.append(X_n_c)\n    proj_t.append(c)\n\nn_col, n_row = 3, 3 \nplot_gallery('', projs, n_col, n_row, titles=proj_t)\nfig = plt.gcf()\nfig.suptitle(\"Single first singular values combinations\", fontsize=14, y=1);","41b91bad":"a,b,c,d,e,f,g,h,i = projs # first 9 components","5386fbb7":"k = np.array([    # coefficients of the first 9 elements\n    1, 0.3, 0.8, 1,   \n    0, 0, 0, 0,\n    0,\n    ])\n#k = k\/k.sum()\n# todo: normalize X_n_c, proj = proj\/proj.sum\nsom = k[0]*a + k[1]*b + k[2]*c + k[3]*d + k[4]*e + k[5]*f + k[6]*g + k[7]*h + k[8]*i\nsomn = normalize(som)\nplt.imshow(somn)","dc472a8d":"plt.figure(figsize=(14,4))\nplt.subplot(2,4,1)\nplt.imshow(k[0]*a)\nplt.title( 'A = ' + str(round(k[0],2)) + 'a' )\n\nplt.subplot(2,4,2)\nplt.imshow(k[1]*b)\nplt.title( 'B = ' + str(round(k[0],2)) + 'b')\n\nplt.subplot(2,4,3)\nplt.imshow(k[2]*c)\nplt.title( 'C = ' + str(round(k[1],2)) + 'c')\n\nplt.subplot(2,4,4)\nplt.imshow(k[3]*d)\nplt.title( 'D = ' + str(round(k[2],2)) + 'd')\n\nplt.subplot(2,4,5)\nplt.imshow(k[4]*e)\nplt.title( 'E = ' + str(round(k[3],2)) + 'e')\n\nplt.imshow( normalize(k[0]*a + k[1]*b) )\nplt.title('A+B')\nplt.subplot(2,4,6)\nplt.imshow( normalize(k[0]*a + k[1]*b + k[2]*c ))\nplt.title('A+B+C')\nplt.subplot(2,4,7)\nplt.imshow( normalize(k[0]*a + k[1]*b + k[2]*c + k[3]*d ))\nplt.title('A+B+C+D');\nplt.subplot(2,4,8)\nplt.imshow( normalize(k[0]*a + k[1]*b + k[2]*c + k[3]*d + k[4]*e ))\nplt.title('A+B+C+D+E');\nplt.subplots_adjust(hspace=0.45)\nfig = plt.gcf()\nfig.suptitle(\"Single singular value contribution vs Cumulative result\", fontsize=14, y=1);","55ea1820":"sv = 3 # number of the singular value\nS_x = np.full_like(S, 0)\nS_x[sv, sv] = S[sv, sv]\nUS = np.dot(U, S_x)\nUSVt = np.dot(US, Vt)\n\n\n\nplt.figure(figsize=(14,14))\nplt.subplot(1,3,1)\nplt.imshow(normalize(US))\nplt.title('$US_c$')\nplt.subplot(1,3,2)\nplt.imshow(Vt)\nplt.title('$V\\ast$')\nplt.subplot(1,3,3)\nplt.imshow(normalize(USVt))\nplt.title('$US_c V^{\/ast}$');\n# plt.subplot(1,3,3)\n# plt.imshow(normalize(np.dot(U,np.dot(S_x, Vt))))\n# plt.title('$USV^{\/ast}$')","5302317c":"S_x = np.full_like(S, 0)\nS_x[sv, sv] = S[sv, sv]\n\nSVt   = np.dot(S_x, Vt)\nUSVt2 = np.dot(U, SVt)\n\nplt.figure(figsize=(14,14))\nplt.subplot(1,3,1)\nplt.imshow(normalize(SVt))\nplt.title('$S_c V^{*}$')\nplt.subplot(1,3,2)\nplt.imshow(normalize(USVt2))\nplt.title('$US_c V^{*}$');","9f7c2cf2":"S_zeros = np.full_like(S, 0)\ndef get_prods_by_c(c):\n    S_x = S_zeros.copy()\n    S_x[c, c] = S[c, c]\n    US_c = np.dot(U, S_x)\n    USVt_c = np.dot(US_c, Vt)\n    p1.image(image=[normalize(US_c)], x=0, y=0, dw=1, dh=1)\n    p2.image(image=[normalize(S_x)], x=0, y=0, dw=1, dh=1)\n    p3.image(image=[normalize(USVt_c)], x=0, y=0, dw=1, dh=1)\n    push_notebook()\n\n\nimport numpy as np\nfrom bokeh.plotting import figure, show\n\npw = 300\nph = 300\np1 = figure(x_range=(0, 1), y_range=(0, 1), plot_width=pw , plot_height=ph, title='US')\np2 = figure(x_range=(0, 1), y_range=(0, 1), plot_width=pw , plot_height=ph, title='S')\np3 = figure(x_range=(0, 1), y_range=(0, 1), plot_width=pw , plot_height=ph, title='USV*')\n# must give a vector of image data for image parameter\np1.image(image=[normalize(S)], x=0, y=0, dw=1, dh=1)\np2.image(image=[normalize(S)], x=0, y=0, dw=1, dh=1)\np3.image(image=[normalize(S)], x=0, y=0, dw=1, dh=1)\n# show(p)\n\nlayout = row([p2, p1, p3])\ninteract(get_prods_by_c, c=widgets.IntSlider(min=0, max=20, continous_update=False, layout=Layout(width='500px')))       \nshow(layout, notebook_handle=True);","aa2be943":"Let's say we want to truncate the image up to the first 9 singular values, and throw away the other 55 (64-9).","0493ba0f":"Hey! it's very similar to the original image!    \nThis tell us that the most important features are linked to the higher singular values, wehre *most important* = richer in information.\n","f3b80444":"### Truncated SVD: Compression","78733c9a":"Starting from a question:  \n*Given a dataset, how can I describe it as a linear combination?*.  \nAgain: How can I break it down in coefficients to multiply over features?\nSVD can do the work. Let's see how","130e782f":"Let's visualize","c0184c67":"### Combining components","1a137890":"So, you can perform the reconstruction either by:\n* $U \\cdot S_c V^{\\ast} $\n* $U S_c \\cdot V^{\\ast} $\n* $U_c \\cdot S_c V^{\\ast}_c $\n* $U_c S_c \\cdot V^{\\ast}_c $","faf6b529":"Now that we gained our feeling about what physically those matrices are, it can be interesting to understand the contribution that each singular value gives to the entire final representation.  \nWe will do this combining a single singular value a time and see what happens.","01a4c331":"Now it is more evident that, from this point of view, the image is a representation 64 x 64 of a combination of matrices.  \nSuch matrices can be even thinner, but the main point is that in the end **their combination** will be spread on a 64x64 ~space~ matrix.","9b61507c":"## SVD","1123f28b":"As you can see the reconstructed image is hard to distinguish from the original one and the mean absolute difference between the two is 0.83\/255 = 0.3%. This is a measure of the loss relative to this method to reconstruct the image.","8843fc42":"## Just a little bit more in depth..","b3c11d80":"###\u00a0Selecting components","c7814fef":"Below is a simple app made to see it live","86f48a1f":"which is the same as truncating Vt, as expected","1c9a62db":"Well, at this point we should have gained a feeling about what to expect from a SVD, namely a triad of generative matrices, able to reconstruct the original one. Further more, we know got the feeling about how the combination of the single singular values works, in order to contribute to the final result. But we're not satisfied yet.  \nWe also want to understand what happens a little bit before, when we combine the single singular value with U, before to obtain the contribution, namely $U_c S_c V^{\\ast}_c$, where c is referred to the extracted cth vector.","d586176c":"To get a feeling about the importance of the first singular values we now print the result of combinations from truncated SVD, starting from one singular value and progressively including more of them.","4a2269ea":"As you can see, using only 6 singular components we are able to recognize the original picture from the reconstructed one.  \nThis means you can truncate all the matrices (yes, throwing away waste) to only 6 as length.","909de358":"Let's compare the images","38cf0851":"Now that we know how to apply a SVD we may want to know more about what happens in it. So let's dive in a little more.  \nWe start taking a look into the resulting matrices, namely U, S, V*","bed49d8f":"SVD has a very important property: since it returns an ordered matrix of singular values, you can throw away the less important, alias the lower ones, expecting little or no changes at all.","4c55dfb0":"To furtherly understand the combination of this single contribution let's play a bit with the first 9 ones.  \nRemember, now you know that you can express your image as:  \n$X = k_1a + k_2b + k_3c + k_4d + k_5 e + k_6f + k_7g + k_8h + k_9i$  \nwhere ${a, b, ..., i}$ are the matrices resulting from the combination of a single singular value, as depicted in the images above.","c821f4f5":"##\u00a0SVD more in depth","ac1aea43":"To recap..\nGiven a matrix <b>X<\/b> as dataset, we want to *decompose* it as a set of \"primitive lines\" and \"numbers\" (coefficients), which can reconstruct <b>X<\/b> when combined (multiplied).  \nIn other words we aim to be able to write $X = U S V^{\\ast}$.  \nS is a *diagonal* matrix: its values are all zero, except along the diagonal, where singular values are.  \nCan you imagine that just combining (summing and multiplying) coefficients from $S$ with rows from $U$ and columns from $V^{\\ast}$, you'll be able to reconstruct a complex thing like our image, or even other datasetes?","b355d91c":"Now perform the SVD by numpy","7db95df3":"Let's take a look to the main characters of the SVD","60b66bdc":"Play with values of **k** to see how single contributions affect the final result. If you set all of them to 1, obviously, the original reconstruction image will appear.","36750fcb":"Data loading and retrieving.\nIn this experiment a image from famous \"Olivetti faces\" will be our dataset.  \nIf you think about it you can recognize that an image is a matrix of points, or a vertical array of horizontal arrays (exsamples), each one made by features cells.","bb390357":"Mh.. Nothing like the previous representations we saw. Actually each of those was the sum of its previous, whilst these are related to a **single** singular value each.","e2c0f3ac":"Going back to our starting question, we found that SVD it's a method to express a matrix **X** as a combination of coefficients (singular values) and two matrices of main features. Moreover we saw that we can truncate all these matrices to lower dimensions no affecting the result.","bf8c0225":"### Conclusion","04a1791e":"Pretty impressive! We can compress an image to the 6% of its size and still mantaining its appearence.","7b3fb5dd":"This notebook was made in order to better understand what a Singular Values Decomposition does to a matrix.  \nIts purpose is to get in touch with the effects of it, but not the math formalism behind it.  \nA little bit of knowledge about the topic can be helpful.  \nHope it will be useful.  \nIf you have any improvements\/corrections to suggest feel free to comment!"}}