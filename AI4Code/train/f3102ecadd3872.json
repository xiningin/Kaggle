{"cell_type":{"2509eb98":"code","68bd2252":"code","b1423999":"code","93946e7f":"code","652ec8c7":"code","159d7291":"code","c87a6bcf":"code","c489d5dc":"code","189c5e54":"code","f069ca3d":"code","78df22ed":"code","7f6535cd":"code","ce77355e":"code","870bb0e0":"code","f5877a23":"code","d0db5d95":"code","0e3abd9d":"code","5704b5c4":"code","40eeb1a0":"code","da6988e1":"code","b8e30ace":"code","86565054":"code","e8273694":"code","600a34fe":"code","8467f98f":"code","9b742e96":"code","5bfd1a2e":"code","16517e69":"code","de648c9b":"code","1d164577":"code","40494e8b":"code","30213571":"markdown","6e0a8e5d":"markdown","aad3975e":"markdown","5de43a50":"markdown","b01464e4":"markdown","05bdcaf8":"markdown","b4ac1120":"markdown","f226aed7":"markdown","98ba39fb":"markdown","385b926c":"markdown","1b0c5cbc":"markdown","c952d1eb":"markdown","7ba44d4e":"markdown","e6e88bbc":"markdown","d2f3769f":"markdown"},"source":{"2509eb98":"%matplotlib inline\n\n!pip install torchsummary\n\n# random seed\nrandom_seed = 1024\nimport numpy as np # linear algebra\nnp.random.seed(random_seed)\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import resample\nimport torch\nimport random\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchsummary import summary\n\n\nplt.style.use('seaborn-whitegrid')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/heartbeat'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","68bd2252":"# Data Exploration (MIT-BIH)\nmitbih_train_loc = \"\/kaggle\/input\/heartbeat\/mitbih_train.csv\"\nmitbih_test_loc = \"\/kaggle\/input\/heartbeat\/mitbih_test.csv\"\nmitbih_train_df = pd.read_csv(mitbih_train_loc, header=None)\nmitbih_test_df = pd.read_csv(mitbih_test_loc, header=None)\n\ndataset = pd.concat([mitbih_train_df, mitbih_test_df], axis=0, sort=True).reset_index(drop=True)","b1423999":"labels = dataset.iloc[:, -1].astype('category').map({\n    0: 'N - Normal Beat', \n    1: 'S - Supraventricular premature or ectopic beat',\n    2: 'V - Premature ventricular contraction', \n    3: 'F - Fusion of ventricular and normal beat', \n    4: 'Q - Unclassified beat'}) \n\n# since the last column is the category\nobs = np.array(dataset.iloc[:, :187]) ","93946e7f":"# get the indexes of all labels\nn_indexes = labels.index[labels == 'N - Normal Beat']\nq_indexes = labels.index[labels == 'Q - Unclassified beat']\nv_indexes = labels.index[labels == 'V - Premature ventricular contraction']\ns_indexes = labels.index[labels == 'S - Supraventricular premature or ectopic beat']\nf_indexes = labels.index[labels == 'F - Fusion of ventricular and normal beat']\n\n# sample one observation per class by indexing the train_labels\nn_index = n_indexes[0]\nq_index = q_indexes[0]\nv_index = v_indexes[0]\ns_index = s_indexes[0]\nf_index = f_indexes[0]\n\ndef generate_subplot(figure, obs, gridspec, row, col, title):\n    axis = figure.add_subplot(gridspec[row, col])\n    axis.plot(np.linspace(0, 1, 187), obs)\n    axis.set_title(title)\n\nfig = plt.figure(figsize=(12, 8))\nfig.subplots_adjust(hspace = .5, wspace=.001)\ngs = fig.add_gridspec(5,1)\n\n# for N - Normal Beat\ngenerate_subplot(fig, obs[n_index], gs, 0, 0, 'N - Normal Beat')\n\n# for Q - Unclassified beat\ngenerate_subplot(fig, obs[q_index], gs, 1, 0, 'Q - Unclassified beat')\n\n# for V - Premature ventricular contraction\ngenerate_subplot(fig, obs[v_index], gs, 2, 0, 'V - Premature ventricular contraction')\n\n# for S - Supraventricular premature or ectopic beat\ngenerate_subplot(fig, obs[s_index], gs, 3, 0, 'S - Supraventricular premature or ectopic beat')\n\n# F - Fusion of ventricular and normal beat\ngenerate_subplot(fig, obs[f_index], gs, 4, 0, 'F - Fusion of ventricular and normal beat')\n\nplt.show()","652ec8c7":"observation_counts = labels.value_counts()\nlabels_descending = np.array(observation_counts.keys())\n\nfig1, ax1 = plt.subplots()\nax1.pie(observation_counts, labels=labels_descending, autopct='%1.1f%%', startangle=0, shadow=True)\nax1.axis('equal')\nfig1.set_size_inches(12,8)\nax1.set_title(\"Percentage Distribution of Heartbeat Classes\", fontsize=20)\nplt.show()","159d7291":"print(observation_counts)","c87a6bcf":"from sklearn.utils import resample\n\n# resample indexes of each class\nn_indexes_resampled = resample(n_indexes, replace=True,n_samples=10000,random_state=random_seed)\nq_indexes_resampled = resample(q_indexes, replace=True,n_samples=10000,random_state=random_seed)\nv_indexes_resampled = resample(v_indexes, replace=True,n_samples=10000,random_state=random_seed)\ns_indexes_resampled = resample(s_indexes, replace=True,n_samples=10000,random_state=random_seed)\nf_indexes_resampled = resample(f_indexes, replace=True,n_samples=10000,random_state=random_seed)\n\n# initialize the labels_resampled to empty pandas series\nlabels_resampled = pd.Series([])\nobs_resampled = None\n\n# add all indexes_resampled for all classes to iterate\nlabel_indexes_list = [n_indexes_resampled, \n                      q_indexes_resampled, \n                      v_indexes_resampled, \n                      s_indexes_resampled, \n                      f_indexes_resampled]\n\nfor label_indexes in label_indexes_list:\n    # append labels for all resampled classes\n    labels_resampled = labels_resampled.append(labels[label_indexes], ignore_index=True)\n    \n    # append observations for all resampled classes\n    if obs_resampled is None:\n        obs_resampled = obs[label_indexes]\n    else:\n        obs_resampled = np.concatenate((obs_resampled, obs[label_indexes]))","c489d5dc":"observation_counts = labels_resampled.value_counts()\nlabels_descending = np.array(observation_counts.keys())\n\nfig1, ax1 = plt.subplots()\nax1.pie(observation_counts, labels=labels_descending, autopct='%1.1f%%', startangle=0, shadow=True)\nax1.axis('equal')\nfig1.set_size_inches(12,8)\nax1.set_title(\"Percentage Distribution of Heartbeat Classes (Resampled)\", fontsize=20)\nplt.show()","189c5e54":"print(observation_counts)","f069ca3d":"from scipy.signal import resample\n\n# first version of adding random noise (Gaussian Noise)\nmean = 0\nstd = 0.05\ndef add_gaussian_noise(signal):\n    noise=np.random.normal(mean, std, 187)\n    return (signal + noise)\n\nobs_resampled_with_noise_1 = np.array([add_gaussian_noise(obs) for obs in  obs_resampled])\n\n# second version of adding random noise (Amplify and Stretch)\ndef stretch(x):\n    l = int(187 * (1 + (random.random()-0.5)\/3))\n    y = resample(x, l)\n    if l < 187:\n        y_ = np.zeros(shape=(187, ))\n        y_[:l] = y\n    else:\n        y_ = y[:187]\n    return y_\n\ndef amplify(x):\n    alpha = (random.random()-0.5)\n    factor = -alpha*x + (1+alpha)\n    return x*factor\n\ndef add_amplify_and_stretch_noise(x):\n    result = np.zeros(shape=187)\n    if random.random() < 0.33:\n        new_y = stretch(x)\n    elif random.random() < 0.66:\n        new_y = amplify(x)\n    else:\n        new_y = stretch(x)\n        new_y = amplify(new_y)\n    return new_y\n\nobs_resampled_with_noise_2 = np.array([add_amplify_and_stretch_noise(obs) for obs in  obs_resampled])","78df22ed":"def generate_subplot(figure, obs, gridspec, row, col, title):\n    axis = figure.add_subplot(gridspec[row, col])\n    axis.plot(np.linspace(0, 1, 187), obs)\n    axis.set_title(title)\n\ndef generate_plots_for_a_specific_data_augmentation(obs_resampled, obs_resampled_with_noise_1, obs_resampled_with_noise_2):\n    # sample one observation per class by indexing the train_labels\n    n_index = 0\n    q_index = 10000\n    v_index = 20000\n    s_index = 30000\n    f_index = 40000\n    \n    fig = plt.figure(figsize=(15, 15))\n    fig.subplots_adjust(hspace = .5, wspace=.001)\n    gs = fig.add_gridspec(5, 3)\n\n    # for N - Normal Beat\n    generate_subplot(fig, obs_resampled[n_index], gs, 0, 0, 'N - Normal Beat \\n(Original)')\n    generate_subplot(fig, obs_resampled_with_noise_1[n_index], gs, 0, 1, 'N - Normal Beat \\n(with random noise v1)')\n    generate_subplot(fig, obs_resampled_with_noise_2[n_index], gs, 0, 2, 'N - Normal Beat \\n(with random noise v2)')\n\n    # for Q - Unclassified beat\n    generate_subplot(fig, obs_resampled[q_index], gs, 1, 0, 'Q - Unclassified beat \\n(Original)')\n    generate_subplot(fig, obs_resampled_with_noise_1[q_index], gs, 1, 1, 'Q - Unclassified beat \\n(with random noise v1)')\n    generate_subplot(fig, obs_resampled_with_noise_2[q_index], gs, 1, 2, 'Q - Unclassified beat \\n(with random noise v2)')\n\n    # for V - Premature ventricular contraction\n    generate_subplot(fig, obs_resampled[v_index], gs, 2, 0, 'V - Premature ventricular contraction \\n(Original)')\n    generate_subplot(fig, obs_resampled_with_noise_1[v_index], gs, 2, 1, 'V - Premature ventricular contraction \\n(with random noise v1)')\n    generate_subplot(fig, obs_resampled_with_noise_2[v_index], gs, 2, 2, 'V - Premature ventricular contraction \\n(with random noise v2)')\n\n    # for S - Supraventricular premature or ectopic beat\n    generate_subplot(fig, obs_resampled[s_index], gs, 3, 0, 'S - Supraventricular premature or ectopic beat \\n(Original)')\n    generate_subplot(fig, obs_resampled_with_noise_1[s_index], gs, 3, 1, 'S - Supraventricular premature or ectopic beat \\n(with random noise v1)')\n    generate_subplot(fig, obs_resampled_with_noise_2[s_index], gs, 3, 2, 'S - Supraventricular premature or ectopic beat \\n(with random noise v2)')\n\n    # F - Fusion of ventricular and normal beat\n    generate_subplot(fig, obs_resampled[f_index], gs, 4, 0, 'F - Fusion of ventricular and normal beat \\n(Original)')\n    generate_subplot(fig, obs_resampled_with_noise_1[f_index], gs, 4, 1, 'F - Fusion of ventricular and normal beat \\n(with random noise v1)')\n    generate_subplot(fig, obs_resampled_with_noise_2[f_index], gs, 4, 2, 'F - Fusion of ventricular and normal beat \\n(with random noise v2)')\n\n    plt.suptitle('Side-by-side Comparison of Original and Two Data Augmentation Versions of Beat Observations Per Class')\n    plt.show()\n    \ngenerate_plots_for_a_specific_data_augmentation(obs_resampled, obs_resampled_with_noise_1, obs_resampled_with_noise_2)","7f6535cd":"# number of subprocesses to use for data loading\nnum_workers = 0\n# percentage of training set to use for testing and validation\ntest_valid_size = 0.2\n# percentage of test\/valid set to use for testing and validation from the test_valid_idx (to be called test_size)\ntest_size = 0.5\n\n\n# obtain training indices that will be used for validation\nnum_train = len(obs_resampled)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(test_valid_size * num_train))\ntrain_idx, test_valid_idx = indices[split:], indices[:split]\n\n# split test_valid_idx to test_idx and valid_idx\nnum_test_valid = len(test_valid_idx)\ntest_valid_split = int(num_test_valid * test_size)\ntest_idx, valid_idx = test_valid_idx[:test_valid_split], test_valid_idx[test_valid_split:]","ce77355e":"from IPython.display import Image \nImage(\"..\/input\/images\/network.png\")","870bb0e0":"# Batch Size of 32\nbatch_size = 32\n\ndef convert_to_loader(X, y, batch_size):\n    data = []\n    for i in range(len(X)):\n        data.append([X[i], y[i]])\n    \n    # drop last since it causes problems on the validation dataset\n    loader = torch.utils.data.DataLoader(data, shuffle=True, batch_size=batch_size, num_workers=0, drop_last=True)\n    \n    return loader\n    \n# convert labels_resampled to its integer encoding of the following listing:\n#     0: 'N - Normal Beat'\n#     1: 'S - Supraventricular premature or ectopic beat'\n#     2: 'V - Premature ventricular contraction'\n#     3: 'F - Fusion of ventricular and normal beat' \n#     4: 'Q - Unclassified beat\nlabels_resampled_factorized = pd.factorize(labels_resampled.astype('category'))[0]\n\n\n# now we create separate data loaders for both datasets with different data augmentation. Models will be trained for each\n\n# for data augmentation v1 (Add Gaussian Noise)\ntrain_loader_1 = convert_to_loader(obs_resampled_with_noise_1[train_idx], \n                                 labels_resampled_factorized[train_idx],\n                                 batch_size)\nvalid_loader_1 = convert_to_loader(obs_resampled_with_noise_1[valid_idx], \n                                 labels_resampled_factorized[valid_idx],\n                                 batch_size)\ntest_loader_1 = convert_to_loader(obs_resampled_with_noise_1[test_idx], \n                                 labels_resampled_factorized[test_idx],\n                                 batch_size)\n\n# for data augmentation v2 (Amplify and Stretch)\ntrain_loader_2 = convert_to_loader(obs_resampled_with_noise_2[train_idx], \n                                 labels_resampled_factorized[train_idx],\n                                 batch_size)\nvalid_loader_2 = convert_to_loader(obs_resampled_with_noise_2[valid_idx], \n                                 labels_resampled_factorized[valid_idx],\n                                 batch_size)\ntest_loader_2 = convert_to_loader(obs_resampled_with_noise_2[test_idx], \n                                 labels_resampled_factorized[test_idx],\n                                 batch_size)","f5877a23":"# define the 1st architecture\nclass Net1(nn.Module):\n    def __init__(self, input_features, output_dim):\n        super(Net1, self).__init__()\n        # 1-dimensional convolutional layer\n        self.conv0 = nn.Conv1d(input_features, 32, output_dim, stride=1, padding=0)\n        self.conv1 = nn.Conv1d(32, 32, output_dim, stride=1, padding=2)\n        self.conv2 = nn.Conv1d(32, 128, output_dim, stride=1, padding=2)\n        \n        # max pooling layer\n        self.pool1 = nn.MaxPool1d(5, 2)\n        \n        # fully-connected layer\n        self.fc1 = nn.Linear(256, 32)\n        self.fc2 = nn.Linear(32, 32)\n        self.fc3 = nn.Linear(32, output_dim)\n        \n        self.softmax = nn.LogSoftmax(dim=1)\n    \n    def forward(self, x):\n        # add sequence of convolutional and max pooling layers\n        \n        inp = x.view(32, -1, 187)\n        C = self.conv0(inp)\n        \n        # first conv layer\n        C11 = self.conv0(inp)\n        A11 = F.relu(C11)\n        C12 = self.conv1(A11)\n        S11 = torch.add(C12, C)\n        A12 = F.relu(S11)\n        M11 = self.pool1(A12)\n        \n        # second conv layer\n        C21 = self.conv1(M11)\n        A21 = F.relu(C21)\n        C22 = self.conv1(A21)\n        S21 = torch.add(C22, M11)\n        A22 = F.relu(S21)\n        M21 = self.pool1(A22)\n        \n        # third conv layer\n        C31 = self.conv1(M21)\n        A31 = F.relu(C31)\n        C32 = self.conv1(A31)\n        S31 = torch.add(C32, M21)\n        A32 = F.relu(S31)\n        M31 = self.pool1(A32)\n        \n        # fourth conv layer\n        C41 = self.conv1(M31)\n        A41 = F.relu(C41)\n        C42 = self.conv1(A41)\n        S41 = torch.add(C42, M31)\n        A42 = F.relu(S41)\n        M41 = self.pool1(A42)\n        \n        # flatten the output of the last layer\n        F1 = M41.view(32, -1)\n        \n        D1 = self.fc1(F1)\n        A6 = F.relu(D1)\n        D2 = self.fc2(A6)\n        D3 = self.fc3(A6)\n        \n#         return D3\n        return self.softmax(D3)","d0db5d95":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel1 = Net1(input_features=2, output_dim=5).to(device)\n\n# check keras-like model summary using torchsummary\n\nsummary(model1, (32, 187))","0e3abd9d":"# define the 1st architecture (from the paper)\nclass Net2(nn.Module):\n    def __init__(self, input_features, output_dim):\n        super(Net2, self).__init__()\n        # 1-dimensional convolutional layer\n        self.conv0 = nn.Conv1d(input_features, 128, output_dim, stride=1, padding=0)\n        self.conv1 = nn.Conv1d(128, 128, output_dim, stride=1, padding=2)\n        \n        # max pooling layer\n        self.pool1 = nn.MaxPool1d(5, 2)\n        \n        # fully-connected layer\n        self.fc1 = nn.Linear(256, 32)\n        self.fc2 = nn.Linear(32, output_dim)\n        \n        # softmax output\n        self.softmax = nn.LogSoftmax(dim=1)\n    \n    def forward(self, x):\n        # add sequence of convolutional and max pooling layers\n        \n        inp = x.view(32, -1, 187)\n        C = self.conv0(inp)\n        \n        # first conv layer\n        C11 = self.conv0(inp)\n        A11 = F.relu(C11)\n        C12 = self.conv1(A11)\n        S11 = torch.add(C12, C)\n        M11 = self.pool1(S11)\n        \n        # second conv layer\n        C21 = self.conv1(M11)\n        A21 = F.relu(C21)\n        C22 = self.conv1(A21)\n        S21 = torch.add(C22, M11)\n        M21 = self.pool1(S21)\n        \n        # third conv layer\n        C31 = self.conv1(M21)\n        A31 = F.relu(C31)\n        C32 = self.conv1(A31)\n        S31 = torch.add(C32, M21)\n        M31 = self.pool1(S31)\n        \n        # fourth conv layer\n        C41 = self.conv1(M31)\n        A41 = F.relu(C41)\n        C42 = self.conv1(A41)\n        S41 = torch.add(C42, M31)\n        M41 = self.pool1(S41)\n        \n        # last layer\n        C51 = self.conv1(M41)\n        A51 = F.relu(C51)\n        C52 = self.conv1(A51)\n        S51 = torch.add(C52, M41)\n        M51 = self.pool1(S51)\n        \n        # flatten the output of the last layer\n        F1 = M51.view(32, -1)\n        \n        D1 = self.fc1(F1)\n        A6 = F.relu(D1)\n        D2 = self.fc2(A6)\n        \n        return self.softmax(D2)","5704b5c4":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel2 = Net2(input_features=2, output_dim=5).to(device)\n\n# check keras-like model summary using torchsummary\nfrom torchsummary import summary\nsummary(model2, (32, 187))","40eeb1a0":"def train_by_model_and_custom_loader(model, train_loader, valid_loader, criterion, optimizer, best_model_name, n_epochs, train_on_gpu):\n    model = model.float()\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        model.cuda()\n    valid_loss_min = np.Inf # track change in validation loss\n    valid_losses = []\n\n    for epoch in range(1, n_epochs+1):\n\n        # keep track of training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for data, target in train_loader:\n            # move tensors to GPU if CUDA is available\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data.float())\n\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # update training loss\n            train_loss += loss.item()*data.size(0)\n\n        ######################    \n        # validate the model #\n        ######################\n        model.eval()\n        for data, target in valid_loader:\n            # move tensors to GPU if CUDA is available\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data.float())\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # update average validation loss \n            valid_loss += loss.item()*data.size(0)\n\n        # calculate average losses\n        train_loss = train_loss\/len(train_loader.dataset)\n        valid_loss = valid_loss\/len(valid_loader.dataset)\n        \n        valid_losses.append(valid_loss)\n\n        # print training\/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, train_loss, valid_loss))\n\n        # save model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model.state_dict(), best_model_name)\n            valid_loss_min = valid_loss\n            \n    return valid_losses","da6988e1":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')\n    \n# number of epochs\nnum_epochs = 50","b8e30ace":"def train_by_model_and_custom_loader(model, train_loader, valid_loader, criterion, optimizer, best_model_name, n_epochs, train_on_gpu):\n    model = model.float()\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        model.cuda()\n    valid_loss_min = np.Inf # track change in validation loss\n    valid_losses = []\n\n    for epoch in range(1, n_epochs+1):\n\n        # keep track of training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for data, target in train_loader:\n            # move tensors to GPU if CUDA is available\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data.float())\n\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # update training loss\n            train_loss += loss.item()*data.size(0)\n\n        ######################    \n        # validate the model #\n        ######################\n        model.eval()\n        for data, target in valid_loader:\n            # move tensors to GPU if CUDA is available\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data.float())\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # update average validation loss \n            valid_loss += loss.item()*data.size(0)\n\n        # calculate average losses\n        train_loss = train_loss\/len(train_loader.dataset)\n        valid_loss = valid_loss\/len(valid_loader.dataset)\n        \n        valid_losses.append(valid_loss)\n\n        # print training\/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, train_loss, valid_loss))\n\n        # save model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model.state_dict(), best_model_name)\n            valid_loss_min = valid_loss\n            \n    return valid_losses","86565054":"# create a complete CNN\nmodel_1 = Net1(input_features=1, output_dim=5)\n# specify loss function\ncriterion = nn.NLLLoss()\n\n# specify optimizer\noptimizer = optim.Adam(model_1.parameters(), lr=0.001)\nmodel_1_validation_losses = train_by_model_and_custom_loader(model_1, train_loader_1, valid_loader_1, criterion, optimizer, 'model_ecg_heartbeat_categorization_1.pt', num_epochs, train_on_gpu)","e8273694":"# create a complete CNN\nmodel_2 = Net1(input_features=1, output_dim=5)\n# specify loss function\ncriterion = nn.NLLLoss()\n\n# specify optimizer\noptimizer = optim.Adam(model_2.parameters(), lr=0.001)\nmodel_2_validation_losses = train_by_model_and_custom_loader(model_2, train_loader_2, valid_loader_2, criterion, optimizer, 'model_ecg_heartbeat_categorization_2.pt', num_epochs, train_on_gpu)","600a34fe":"# create a complete CNN\nmodel_3 = Net2(input_features=1, output_dim=5)\n# specify loss function\ncriterion = nn.NLLLoss()\n\n# specify optimizer\noptimizer = optim.Adam(model_3.parameters(), lr=0.001)\nmodel_3_validation_losses = train_by_model_and_custom_loader(model_3, train_loader_1, valid_loader_1, criterion, optimizer, 'model_ecg_heartbeat_categorization_3.pt', num_epochs, train_on_gpu)","8467f98f":"# create a complete CNN\nmodel_4 = Net2(input_features=1, output_dim=5)\n# specify loss function\ncriterion = nn.NLLLoss()\n\n# specify optimizer\noptimizer = optim.Adam(model_4.parameters(), lr=0.001)\nmodel_4_validation_losses = train_by_model_and_custom_loader(model_4, train_loader_2, valid_loader_2, criterion, optimizer, 'model_ecg_heartbeat_categorization_4.pt', num_epochs, train_on_gpu)","9b742e96":"def evaluate_model(model, test_loader, criterion, best_model_name):\n    model.load_state_dict(torch.load(best_model_name))\n    \n    # Specify the heartbeat classes from above\n    classes = {\n        0: 'N - Normal Beat', \n        1: 'S - Supraventricular premature or ectopic beat',\n        2: 'V - Premature ventricular contraction', \n        3: 'F - Fusion of ventricular and normal beat', \n        4: 'Q - Unclassified beat'}\n\n    # track test loss\n    test_loss = 0.0\n    class_correct = list(0. for i in range(5))\n    class_total = list(0. for i in range(5))\n\n    model.eval()\n    # iterate over test data\n    for data, target in test_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data.float())\n        # calculate the batch loss\n        loss = criterion(output, target.long())\n        # update test loss \n        test_loss += loss.item()*data.size(0)\n        # convert output probabilities to predicted class\n        _, pred = torch.max(output, 1)\n        # compare predictions to true label\n        correct_tensor = pred.eq(target.data.view_as(pred))\n        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n        # calculate test accuracy for each object class\n        for i in range(batch_size):\n            label = target.data[i].int()\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\n    # average test loss\n    test_loss = test_loss\/len(test_loader.dataset)\n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    for i in range(5):\n        if class_total[i] > 0:\n            print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n                classes[i], 100 * class_correct[i] \/ class_total[i],\n                np.sum(class_correct[i]), np.sum(class_total[i])))\n        else:\n            print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\n    print('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n        100. * np.sum(class_correct) \/ np.sum(class_total),\n        np.sum(class_correct), np.sum(class_total)))","5bfd1a2e":"evaluate_model(model_1, test_loader_1, criterion, 'model_ecg_heartbeat_categorization_1.pt')","16517e69":"evaluate_model(model_2, test_loader_2, criterion, 'model_ecg_heartbeat_categorization_2.pt')","de648c9b":"evaluate_model(model_3, test_loader_1, criterion, 'model_ecg_heartbeat_categorization_3.pt')","1d164577":"evaluate_model(model_4, test_loader_2, criterion, 'model_ecg_heartbeat_categorization_4.pt')","40494e8b":"validation_losses = {\n    \"model_1\": model_1_validation_losses,\n    \"model_2\": model_2_validation_losses,\n    \"model_3\": model_3_validation_losses,\n    \"model_4\": model_4_validation_losses\n}\n# plt.plot(model_1_validation_losses)\n\nplt.plot('model_1', data=validation_losses)\nplt.plot('model_2', data=validation_losses)\nplt.plot('model_3', data=validation_losses)\nplt.plot('model_4', data=validation_losses)\nplt.title(\"Validation Losses of All Models\")\nplt.legend(validation_losses.keys())","30213571":"For the MIT-BIH Arrhythmia Dataset, all the samples are cropped, downsampled and padded with zeroes if necessary to the fixed dimension of 188 as per the [Kaggle dataset remark](https:\/\/www.kaggle.com\/shayanfazeli\/heartbeat).\n\nWe have five classes, \\['N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4\\]. Please refer to the corresponding paper entitled [ECG Heartbeat Classification: A Deep Transferable\nRepresentation](https:\/\/arxiv.org\/pdf\/1805.00794.pdf) by Mohammad Kachuee, Shayan Fazeli, and Majid Sarrafzadeh. \nprint(mitbih_train_df.iloc[:, -1].unique())\nSpecifically, classes above refer to the beat annotations enumerated below:\n1. N - Normal beat\n2. S - Supraventricular premature or ectopic beat (atrial or nodal)\n3. V - Premature ventricular contraction\n4. F - Fusion of ventricular and normal beat\n5. Q - Unclassifiable beat\n\nThese classes can be found on the [PhysioBank Annotations](https:\/\/archive.physionet.org\/physiobank\/annotations.shtml) under the Beat Annotations section.\n\nAdditionally, each observation in this particular dataset are actual recorded heartbeats of 47 different subjects at a sampling rate of 360Hz annotated by at least two cardiologists under five classes mentioned above in accordance with the Association for the Advancement of Medical Instrumentation (AAMI) standard. The last column indicates how each heartbeat is classified. \n\nIn the following code, we separate labels to their actual observations. Each class are labeled with the ones mentioned above.","6e0a8e5d":"Noow that we generated a significant amount of observations for the project let us now split the dataset to train, test and validation. The following divides the dataset 80\/20 where the former is for training and the latter is for the test and validation equally splitted.","aad3975e":"Now we add a little bit of noise to all observations per class with mean 0 and standard deviation of 0.05. This is necessary especially when we are dealing with repeated cases for classes which originally have too few observations before resampling. Then let us see how each of them respond to the noise through line chart comparison.","5de43a50":"After executing the above code that creates two versions of data augmentation now we proceed to visualizing side-by-side the comparison between the original and both versions of augmented datasets.","b01464e4":"Previously, I resampled all the classes to 10000 observations each. Let us now verify if that is really the case.","05bdcaf8":"As you can see, dataset is highly imbalanced. So we need to upsample each classes. This may overfit class F (fusion of ventricular and normal beat b) but its influence to the model will be the same as other classes.","b4ac1120":"Now we load the model with lowest validation score.","f226aed7":"The inspiration for this project is from the paper ECG Heartbeat Classification: A Deep Transferable Representation by Mohammad Kachuee, Shayan Fazeli, Majid Sarrafzadeh. Shayan Fazeli compiled the dataset that is used in this project. \n\nThe proposed network that worked in this project is displayed in the following section:","98ba39fb":"As you can see, a slight random noise is added to each of the observations selected per class. This will ensure that the neural network will generalize in training. Now we proceed to model building.","385b926c":"Now that we already prepared the data suitable for training (i.e. build the train, validation and test loaders, let us now proceed with creating the model architecture. You can see from the above code that the loaders are done with PyTorch helper functions. That is the framework that we will use all throughout the training process.","1b0c5cbc":"Now that all of the models are created, let us now train each of them using two versions of train and validation loaders.\n\nBelow is the function that generalizes the training job for a combination of custom model to be trained as well as the dataset to train","c952d1eb":"After we separate actual observation and their labels, we will visualize each of the beat classes mentioned above using line graphs.","7ba44d4e":"Since the dataset has already been downsampled and preprocessed, we will proceed to visualizing the distribution per classification.","e6e88bbc":"Since we have limited number of observations in some of the classes, we merge the train and test CSVs. In this case, we are only interested in the MIT-BIH dataset which are for the multiclass classification. ","d2f3769f":"Now let us proceed to model preparation and building"}}