{"cell_type":{"e97b6edd":"code","ecb7edae":"code","3651d823":"code","a6a97cee":"code","0e5bb0c0":"code","68c40ee0":"code","4ffbcc41":"code","934abe15":"code","38785b37":"code","b33e1056":"code","d38f9bfd":"code","7e71eeb0":"code","d0bd0a1e":"code","ee8a2c87":"code","700f21c5":"code","b8892387":"code","f0eed56c":"code","9090fb6b":"code","93c6b3c2":"code","ce6e569f":"code","9f2961ad":"markdown","4f804b63":"markdown","95a27eb4":"markdown","5b46f9fb":"markdown","c7b935c2":"markdown"},"source":{"e97b6edd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n #   for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ecb7edae":"import os\nimport glob\nimport cv2\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.layers import Dropout, Flatten, Input, Dense\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as keras\nfrom sklearn.metrics import accuracy_score","3651d823":"image_path = os.path.join(\"\/kaggle\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\")\nmask_path = os.path.join(\"\/kaggle\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/masks\")\nimages = os.listdir(image_path)\nmask = os.listdir(mask_path)\nprint(len(images), len(mask))","a6a97cee":"mask2 = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask2]\nprint(len(image_file_name), len(mask))","0e5bb0c0":"check = [i for i in mask if \"mask\" in i]\nprint(len(check))","68c40ee0":"dsize = (256, 256)\ndef image_resize(img):\n    return cv2.resize(img,dsize )","4ffbcc41":"#print(mask)\nx = np.array([np.array(np.stack(( image_resize(cv2.imread(os.path.join(image_path,filename.split(\"_mask\")[0]+\".png\"),  0)),), axis=-1)) for filename in image_file_name])\ny= np.array([np.array(np.stack(( image_resize(cv2.imread(os.path.join(mask_path,filename),  0)),), axis=-1)) for filename in mask])\n","934abe15":"print(x.shape, y.shape)","38785b37":"def show_random_examples(x, y, p):\n    indices = np.random.choice(range(x.shape[0]), 10, replace=False)\n    x = x[indices]\n    y = y[indices]\n    p = p[indices]\n    dsize2 =(400,400)\n    plt.figure(figsize=(10, 5))\n    for i in range(10):\n        plt.subplot(2, 5, i + 1)\n        xi = cv2.resize(x[i], dsize2)\n        plt.imshow(xi)\n        plt.xticks([])\n        plt.yticks([])\n#        col = 'green' if np.argmax(y[i]) == np.argmax(p[i]) else 'red'\n#        plt.xlabel(class_names[np.argmax(p[i])], color=col)\n    plt.show()    \n    for i in range(10):\n        plt.subplot(2, 5, i + 1)\n        xi = cv2.resize(y[i], dsize2)\n        plt.imshow(xi)\n        plt.xticks([])\n        plt.yticks([])\n#        col = 'green' if np.argmax(y[i]) == np.argmax(p[i]) else 'red'\n#        plt.xlabel(class_names[np.argmax(p[i])], color=col)\n    plt.show()    \n    for i in range(10):\n        plt.subplot(2, 5, i + 1)\n        xi = cv2.resize(p[i], dsize2)\n        plt.imshow(xi)\n        plt.xticks([])\n        plt.yticks([])\n#        col = 'green' if np.argmax(y[i]) == np.argmax(p[i]) else 'red'\n#        plt.xlabel(class_names[np.argmax(p[i])], color=col)\n    plt.show()   ","b33e1056":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train_m, y_test_m = train_test_split(x, y, test_size=0.2, random_state=123)\nx2 = np.flip(X_train , axis = 2)\ny2 = np.flip(y_train_m , axis = 2)\nX_train= np.append(X_train, x2,axis=0)\ny_train_m = np.append(y_train_m, y2,axis=0)\nprint(X_train.shape,y_train_m.shape )\nshow_random_examples(X_train, y_train_m, y_train_m)","d38f9bfd":"def unet(pretrained_weights = None,input_size = (256,256,1)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\n    model = Model(inputs, conv10)\n\n    model.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    #model.summary()\n\n   # if(pretrained_weights):\n    #    model.load_weights(pretrained_weights)\n\n    return model","7e71eeb0":"model_1 = unet()\nmodel_1.summary()","d0bd0a1e":"y_test_m2 = (y_test_m\/255.> .5).astype(int)","ee8a2c87":"y_train_m2 = (y_train_m\/255.> .5).astype(int)\nmodel_checkpoint = ModelCheckpoint('\/kaggle\/working\/unet_membrane_a6.hdf5', monitor='loss',verbose=2, save_best_only=True)\n\nh = model_1.fit(\n    X_train\/255., y_train_m2,   \n    callbacks=[model_checkpoint],\n    validation_data=(X_test\/255., y_test_m2),\n    epochs=15, batch_size=20,\n    #validation_split=0.2,\n    #shuffle=True,\n)","700f21c5":"plt.plot(h.history['accuracy'])\nplt.plot(h.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(h.history['loss'])\nplt.plot(h.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n\nlosses = h.history['loss']\naccs = h.history['accuracy']\nval_losses = h.history['val_loss']\nval_accs = h.history['val_accuracy']\nepochs = len(losses)\n\npreds = model_1.predict(X_test\/255.)*255\n\nshow_random_examples(X_test, y_test_m, preds)","b8892387":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_decay = ReduceLROnPlateau(monitor='loss', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","f0eed56c":"h2 = model_1.fit(\n    X_train\/255., y_train_m2,\n    validation_data=(X_test\/255., y_test_m2),\n    epochs=30, batch_size=16,\n    shuffle=True,\n    verbose=2,\n    callbacks=[learning_rate_decay]\n)\n","9090fb6b":"plt.plot(h2.history['accuracy'])\nplt.plot(h2.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(h2.history['loss'])\nplt.plot(h2.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n\nlosses = h2.history['loss']\naccs = h2.history['accuracy']\nval_losses = h2.history['val_loss']\nval_accs = h2.history['val_accuracy']\nepochs = len(losses)\n\npreds2 = model_1.predict(X_test\/255.)*255\n\nshow_random_examples(X_test, y_test_m, preds2)","93c6b3c2":"test_path = os.path.join(\"\/kaggle\/input\/chest-xray-masks-and-labels\/data\/Lung Segmentation\/test\")\ntest = os.listdir(test_path)\n#print(test)\ny= np.array([np.array(np.stack(( image_resize(cv2.imread(os.path.join(test_path,filename),  0)),), axis=-1)) for filename in test])\n\npreds3 = model_1.predict(y\/255.)*255\n","ce6e569f":"show_random_examples(y, y, preds3)","9f2961ad":"I am asuming the all the Mask have a file.\n","4f804b63":"AS from above images are 800 images (CXR_PNG) and 704(Mask).\nSo i have to map those. ","95a27eb4":"TEST DATA Result","5b46f9fb":"Below program is to run the with decaying learning rate","c7b935c2":"Input and Output both are images.\nIn This Python code I have writen logic to Get the mask from Chest X-ray.\nI have used only one type of augmentation 180 degree rotation or horizontal flip.\nIn valation data I am getting Around 98.17 % accuracy. "}}