{"cell_type":{"1e3ae8dc":"code","1fca0cfd":"code","d6830777":"code","3c031145":"code","7894294a":"code","8ca4fb3e":"code","1440902c":"code","903abf6a":"code","5da4689a":"code","5a48a131":"code","ee0e6272":"markdown","1c28f55a":"markdown","7d4ee50e":"markdown","dd00f939":"markdown","ebd0230b":"markdown"},"source":{"1e3ae8dc":"import os \nimport re \nfrom scipy import ndimage, misc \nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\nfrom skimage.transform import resize, rescale\nimport matplotlib.pyplot as plt\nimport numpy as np\nnp. random. seed(0)\nimport cv2 as cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense ,Conv2D,MaxPooling2D ,Dropout, Activation,concatenate\nfrom tensorflow.keras.layers import Conv2DTranspose, UpSampling2D, add , BatchNormalization \nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.utils import plot_model\nimport tensorflow as tf\n\nprint(tf.__version__)","1fca0cfd":"def Upsample_block(x,ch=256, k_s=3, st=1):\n    x = tf.keras.layers.Conv2D(ch,k_s, strides=(st,st), padding='same')(x)\n    x = tf.nn.depth_to_space(x, 2)      # Subpixel pixelshuffler\n    x = tf.keras.layers.LeakyReLU()(x)\n    return x","d6830777":"batch_size = 1\nkernel_size = 3\ndropout = 0.4\nn_filters = 64\n#CNN \ninput_img=Input(shape=(52,52,3))\nl1=tf.keras.layers.Conv2D(64,9,padding='same',activation='relu') (input_img)\nl2=tf.keras.layers.Conv2D(64,1,padding='same',activation='relu') (l1)\nl3=tf.keras.layers.Conv2D(3,5,padding='same',activation='relu') (l2)\n#model=Model(input_img,l3)\n\n#residual block \nfilter_size=64\nfor i in range(3):\n    l4=tf.keras.layers.Conv2D(filter_size,1,padding='same',activation='relu') (l3)\n    l4=BatchNormalization(axis=3)(l4)\n    l4=Activation('relu')(l4)\n    filter_size*=2\n    l4=tf.keras.layers.Conv2D(3,9,padding='same',activation='relu')(l4)\n    l5= add([l3,l4])  \n\nmodel=Model(input_img,l5)\n\n\n\n'''\nleft_inputs = Input(shape=(52,52,3))\nx = left_inputs\nfilters = n_filters\n# 3 layers of Conv2D-Dropout-MaxPooling2D\n# number of filters doubles after each layer (32-64-128)\nfor i in range(1):\n    x = Conv2D(filters=filters,\n                  kernel_size=kernel_size,\n                  padding='same',\n                  activation='relu')(l4)\n    x = Dropout(dropout)(x)\n    x = MaxPooling2D()(x)\n    filters *= 2\n    \n# left branch of Y network\nright_inputs = Input(shape=(52,52,3))\ny = right_inputs\nfilters = n_filters\n# 3 layers of Conv2D-Dropout-MaxPooling2D\n# number of filters doubles after each layer (32-64-128)\nfor i in range(1):\n    y = Conv2D(filters=filters,\n                  kernel_size=kernel_size,\n                  padding='same',\n                  activation='relu')(l4)\n    y = Dropout(dropout)(y)\n    y = MaxPooling2D()(y)\n    filters *= 2\n\ny = concatenate([x, y])\ny=Upsample_block(y)\noutputs=Conv2D (3,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(y)\n\nl5=Conv2D (64,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(outputs)\nl6=Conv2D (64,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l5)\nl7=MaxPooling2D(padding='same')(l6)\nl8=Conv2D (128,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l7)\nl9=Conv2D (128,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l8)\nl10=MaxPooling2D(padding='same')(l9)\n\nl11=Conv2D (256,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l10)\n\n\nl12=UpSampling2D()(l11)\nl13=Conv2D (128,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l12)\nl14=Conv2D (128,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l13)\nl15=add([l9,l14])\nl16=UpSampling2D()(l15)\nl17=Conv2D (64,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l16)\nl18=Conv2D (64,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l17)\nl19=add([l18,l6])\n\ndecoder=Conv2D (3,(3,3) , padding='same' ,activation='relu',activity_regularizer=regularizers.l1(10e-10))(l19)\n''''''\nmodel=Model(input_img,decoder)\n'''\n\n\nmodel.summary()\nplot_model(model, to_file ='My_super_res.png',show_shapes=True)\n\n\n\n\n\n\n","3c031145":"def sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)\n# defining the size of the image\nSIZE = 52\nhigh_img = []\npath = '..\/input\/cell-data\/DATA OF CELL\/HR_1_imgs'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):    \n    if i == '250.jpg':\n        break\n    else:    \n        img = cv2.imread(path + '\/'+i,1)\n        # open cv reads images in BGR format so we have to convert it to RGB\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') \/ 255.0\n        high_img.append(img_to_array(img))\n\n\nlow_img = []\npath = '..\/input\/cell-data\/DATA OF CELL\/SR_1_imgs'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):\n    if i == '250.jpg':\n        break\n    else: \n        img = cv2.imread(path + '\/'+i,1)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') \/ 255.0\n        low_img.append(img_to_array(img))","7894294a":"for i in range(4):\n    a = np.random.randint(20,50)\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,2,1)\n    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n    plt.imshow(high_img[a])\n    plt.axis('off')\n    plt.subplot(1,2,2)\n    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n    plt.imshow(low_img[a])\n    plt.axis('off')","8ca4fb3e":"train_high_image = high_img[:150]\ntrain_low_image = low_img[:150]\ntrain_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,3))\ntrain_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,3))\n\nvalidation_high_image = high_img[150:180]\nvalidation_low_image = low_img[150:180]\nvalidation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,3))\nvalidation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,3))\n\n\ntest_high_image = high_img[180:]\ntest_low_image = low_img[180:]\ntest_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,3))\ntest_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,3))\n\nprint(\"Shape of training images:\",train_high_image.shape)\nprint(\"Shape of test images:\",test_high_image.shape)\nprint(\"Shape of validation images:\",validation_high_image.shape)","1440902c":"def pixel_mse_loss(x,y):\n    return tf.reduce_mean( (x - y) ** 2 )\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=pixel_mse_loss)","903abf6a":"model.fit(train_low_image, train_high_image, epochs = 30, batch_size = 1,\n          validation_data = (validation_low_image,validation_high_image))","5da4689a":"def PSNR(y_true,y_pred):\n    mse=tf.reduce_mean( (y_true - y_pred) ** 2 )\n    return 20 * log10(1\/ (mse ** 0.5))\n\ndef log10(x):\n    numerator = tf.math.log(x)\n    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n    return numerator \/ denominator\n\ndef pixel_MSE(y_true,y_pred):\n    return tf.reduce_mean( (y_true - y_pred) ** 2 )","5a48a131":"def plot_images(high,low,predicted):\n    plt.figure(figsize=(15,15))\n    plt.subplot(1,3,1)\n    plt.title('High Image', color = 'green', fontsize = 20)\n    plt.imshow(high)\n    plt.subplot(1,3,2)\n    plt.title('Low Image ', color = 'black', fontsize = 20)\n    plt.imshow(low)\n    plt.subplot(1,3,3)\n    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n    plt.imshow(predicted)\n   \n    plt.show()\n\nfor i in range(1,3):\n    \n    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n    plot_images(test_high_image[i],test_low_image[i],predicted)\n    print('PSNR',PSNR(test_high_image[i],predicted),'dB')","ee0e6272":"![Screenshot 2021-11-27 at 4.04.31 PM.png](attachment:19bc8cfa-8bad-4888-9e31-cd9227e52cdc.png)","1c28f55a":"![Libraries.png](attachment:71702a5a-fdf8-44ff-8903-890b63a8a411.png)","7d4ee50e":"# Model Building ","dd00f939":"![DATA VISU.png](attachment:45296830-362f-4f39-8e95-eec32b97fee4.png)","ebd0230b":"![splitting data.png](attachment:12705256-e5e3-48cb-a91a-d429120ad6d9.png)"}}