{"cell_type":{"2413671f":"code","bde447cc":"code","145019c1":"code","60bbdce6":"code","e22b3ea5":"code","93fd921f":"code","6f7f1da4":"code","50a17484":"code","f466b58d":"code","25319134":"code","5f2e2938":"code","42b846fb":"code","b09fc6b9":"code","f25cbd4f":"code","86e5043c":"code","4e4ff7d6":"code","fb7d9c4e":"code","1a98faed":"code","e45faf9c":"code","e9f13ff7":"code","059657b3":"code","9375c074":"code","246019eb":"code","c7b06c42":"code","a4ec590d":"code","27f7f7bb":"code","aa7bb996":"code","f31dc0ec":"code","ba235e1a":"code","3c3f6832":"code","414b01fc":"code","12e51161":"code","14c1db5c":"code","b35ba697":"code","f2e7e0c3":"code","901a5b7d":"code","a6e1a6c5":"code","b2aa6b38":"code","a4eefff9":"code","9454ec6e":"code","b83257ab":"code","af1a1cce":"code","76258ca4":"code","af8b12f1":"code","cf6bcb43":"code","b2cfb2fd":"code","e9116ea2":"code","05dd61d7":"code","250874b0":"code","aad1393d":"code","cd0a054f":"code","01f48e17":"code","16274d18":"code","cf7d7a69":"code","9ddb592e":"code","42cc8752":"code","120c0ff5":"code","c758dc10":"code","d8d992f5":"code","30d38248":"code","62c9012d":"code","03409397":"code","00ba8bd9":"code","10576c98":"code","238a8889":"code","0e34826d":"code","535054cd":"code","b1d7cf73":"code","197336a0":"code","5625fac1":"code","f8620bcd":"code","bf1d4a2d":"code","3da2b3b5":"markdown","cc24c32c":"markdown","f5d4bb0f":"markdown","1767eebd":"markdown","9de6929f":"markdown","5b2dd6fd":"markdown","edfebf91":"markdown","c44765ed":"markdown","5ffeff3e":"markdown","7c2504b6":"markdown","fbf74396":"markdown","ec2e473d":"markdown","61c495d1":"markdown","c203c7c0":"markdown","f29cc9da":"markdown","1fd3b3ad":"markdown","7296b1e5":"markdown","3baee6c0":"markdown","08508443":"markdown","46074013":"markdown","2a8ce3b2":"markdown"},"source":{"2413671f":"import sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn \u22650.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\ntry:\n    # %tensorflow_version only exists in Colab.\n    %tensorflow_version 2.x\nexcept Exception:\n    pass\n\n# TensorFlow \u22652.0 is required\nimport tensorflow as tf\nassert tf.__version__ >= \"2.0\"\n\n# Common imports\nimport numpy as np\nimport os\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\nmpl.rc('ytick', labelsize=12)","bde447cc":"import tensorflow as tf\r\nfrom tensorflow import keras","145019c1":"# Loading Dataset\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()","60bbdce6":"X_train_full.shape, y_train_full.shape","e22b3ea5":"\r\nX_valid, X_train = X_train_full[:5000] \/ 255., X_train_full[5000:] \/ 255.\r\ny_valid, y_train = y_train_full[:5000], y_train_full[5000:]\r\nX_test = X_test \/ 255.","93fd921f":"\r\nplt.imshow(X_train[0], cmap=\"binary\")\r\nplt.axis('off')\r\nplt.show()","6f7f1da4":"class_names = [\"T-shirt\/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\r\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\r\nclass_names[y_train[0]]\r\n","50a17484":"# Plotting some images\r\n\r\nn_rows = 4\r\nn_cols = 10\r\nplt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\r\nfor row in range(n_rows):\r\n    for col in range(n_cols):\r\n        index = n_cols * row + col\r\n        plt.subplot(n_rows, n_cols, index + 1)\r\n        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\r\n        plt.axis('off')\r\n        plt.title(class_names[y_train[index]], fontsize=12)\r\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\r\nplt.show()","f466b58d":"model = keras.models.Sequential([\r\n keras.layers.Flatten(input_shape=[28, 28]), # if it receives input data X, it computes X.reshape(1, -1)\r\n keras.layers.Dense(300, activation=\"relu\"),\r\n keras.layers.Dense(100, activation=\"relu\"),\r\n keras.layers.Dense(10, activation=\"softmax\")\r\n])","25319134":"model.summary()","5f2e2938":"# hidden layer 1\r\nhidden1 = model.layers[1]\r\nhidden1.name","42b846fb":"# get weights and biases\r\nweights, biases = hidden1.get_weights()\r\nprint(weights,'\\n', biases)","b09fc6b9":"model.compile(loss=\"sparse_categorical_crossentropy\",\r\n              optimizer=\"sgd\",\r\n              metrics=[\"accuracy\"])","f25cbd4f":" history = model.fit(X_train, y_train, epochs=30,\r\n                     validation_data=(X_valid, y_valid))","86e5043c":"import pandas as pd\r\npd.DataFrame(history.history).plot(figsize=(8, 5))\r\nplt.grid(True)\r\nplt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\r\nplt.show()\r\n","4e4ff7d6":"model.evaluate(X_test, y_test, steps= 10000, verbose=2)","fb7d9c4e":"X_new = X_test[:3]\r\ny_proba = model.predict(X_new)\r\ny_proba.round(2)","1a98faed":"y_pred = np.argmax(model.predict(X_new), axis=-1)\r\ny_pred","e45faf9c":"# Predicting the classes\r\nnp.array(class_names)[y_pred]","e9f13ff7":"\r\nfrom sklearn.datasets import fetch_california_housing\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import StandardScaler\r\n\r\nhousing = fetch_california_housing()\r\n\r\nX_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\r\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\r\n\r\nscaler = StandardScaler()\r\nX_train = scaler.fit_transform(X_train)\r\nX_valid = scaler.transform(X_valid)\r\nX_test = scaler.transform(X_test)","059657b3":"# Set random\r\n\r\nnp.random.seed(42)\r\ntf.random.set_seed(42)","9375c074":"# network\r\nmodel = keras.models.Sequential([\r\n    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\r\n    keras.layers.Dense(1) # Only one neuron to give a linear output\r\n])\r\n# Compile \r\nmodel.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\r\n# Fit the model\r\nhistory = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\r\n# Test the model\r\nmse_test = model.evaluate(X_test, y_test)\r\nX_new = X_test[:3]\r\n# Predit with test data\r\ny_pred = model.predict(X_new)","246019eb":"pd.DataFrame(history.history).plot(figsize = (12, 6))\r\nplt.grid(True)\r\nplt.gca().set_ylim(0, 1)\r\nplt.show()","c7b06c42":"y_pred\r\n","a4ec590d":"np.random.seed(42)\r\ntf.random.set_seed(42)","27f7f7bb":"input_ = keras.layers.Input(shape=X_train.shape[1:])\r\nhidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\r\nhidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\r\nconcat = keras.layers.concatenate([input_, hidden2]) \r\noutput = keras.layers.Dense(1)(concat)\r\nmodel = keras.models.Model(inputs=[input_], outputs=[output])","aa7bb996":"model.summary()","f31dc0ec":"\r\nmodel.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\r\nhistory = model.fit(X_train, y_train, epochs=100,\r\n                    validation_data=(X_valid, y_valid))\r\nmse_test = model.evaluate(X_test, y_test)\r\ny_pred = model.predict(X_new)","ba235e1a":"input_A = keras.layers.Input(shape=[5])\r\ninput_B = keras.layers.Input(shape=[6])\r\nhidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\r\nhidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\r\nconcat = keras.layers.concatenate([input_A, hidden2])\r\noutput = keras.layers.Dense(1)(concat)\r\nmodel = keras.models.Model(inputs=[input_A, input_B], outputs=[output])","3c3f6832":"model.compile(loss='mse', optimizer=keras.optimizers.SGD(learning_rate=1e-3))","414b01fc":"X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\r\nX_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\r\nX_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\r\nX_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\r\n","12e51161":"history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\r\n                    validation_data=((X_valid_A, X_valid_B), y_valid))\r\nmse_test = model.evaluate((X_test_A, X_test_B), y_test)\r\ny_pred = model.predict((X_new_A, X_new_B))","14c1db5c":"np.random.seed(42)\r\ntf.random.set_seed(42)","b35ba697":"input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\r\ninput_B = keras.layers.Input(shape=[6], name=\"deep_input\")\r\nhidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\r\nhidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\r\nconcat = keras.layers.concatenate([input_A, hidden2])\r\noutput = keras.layers.Dense(1, name=\"main_output\")(concat)\r\naux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\r\nmodel = keras.models.Model(inputs=[input_A, input_B],\r\n                           outputs=[output, aux_output])","f2e7e0c3":"model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))","901a5b7d":"history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\r\n                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))","a6e1a6c5":"pd.DataFrame(history.history).plot(figsize=(8, 5))\r\nplt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\r\nplt.show()","b2aa6b38":"total_loss, main_loss, aux_loss = model.evaluate(\r\n    [X_test_A, X_test_B], [y_test, y_test])\r\ny_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])","a4eefff9":"print(total_loss, main_loss, aux_loss)","9454ec6e":"class WideAndDeepModel(keras.models.Model):\r\n  def __init__(self, units=30, activation=\"relu\", **kwargs):\r\n    super().__init__(**kwargs) # handles standard args (e.g., name)\r\n    self.hidden1 = keras.layers.Dense(units, activation=activation)\r\n    self.hidden2 = keras.layers.Dense(units, activation=activation)\r\n    self.main_output = keras.layers.Dense(1)\r\n    self.aux_output = keras.layers.Dense(1)\r\n  def call(self, inputs):\r\n    input_A, input_B = inputs\r\n    hidden1 = self.hidden1(input_B)\r\n    hidden2 = self.hidden2(hidden1)\r\n    concat = keras.layers.concatenate([input_A, hidden2])\r\n    main_output = self.main_output(concat)\r\n    aux_output = self.aux_output(hidden2)\r\n    return main_output, aux_output\r\nmodel = WideAndDeepModel()","b83257ab":"np.random.seed(42)\r\ntf.random.set_seed(42)","af1a1cce":"# Creating a small N-N Layer\r\nmodel = keras.models.Sequential([\r\n    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\r\n    keras.layers.Dense(30, activation=\"relu\"),\r\n    keras.layers.Dense(1)\r\n])","76258ca4":"model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\r\nhistory = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\r\nmse_test = model.evaluate(X_test, y_test)","af8b12f1":"# saving\r\nmodel.save(\"my_keras_model.h5\")\r\n\r\n# Restoring\r\nmodel = keras.models.load_model(\"my_keras_model.h5\")","cf6bcb43":"# Also you can just save and load weights\r\n\r\nmodel.save_weights(\"my_keras_weights.ckpt\")\r\n\r\nmodel.load_weights(\"my_keras_weights.ckpt\")\r\n","b2cfb2fd":"keras.backend.clear_session()\r\nnp.random.seed(42)\r\ntf.random.set_seed(42)","e9116ea2":"model = keras.models.Sequential([\r\n    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\r\n    keras.layers.Dense(30, activation=\"relu\"),\r\n    keras.layers.Dense(1)\r\n])","05dd61d7":"model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\r\n\r\n# Callback funnction initialization\r\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\r\n\r\n\r\nhistory = model.fit(X_train, y_train, epochs=10,\r\n                    validation_data=(X_valid, y_valid),\r\n                    callbacks=[checkpoint_cb])\r\n\r\n# Load the saved model\r\nmodel = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\r\n\r\nmse_test = model.evaluate(X_test, y_test)","250874b0":"mse_test","aad1393d":"model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\r\n\r\n# if no change for 10 epochs stop training and restore the best model\r\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\r\n                                                  restore_best_weights=True)\r\n\r\n# Combined both save checkpoints and earlystopping\r\nhistory = model.fit(X_train, y_train, epochs=100,\r\n                    validation_data=(X_valid, y_valid),\r\n                    callbacks=[checkpoint_cb, early_stopping_cb])\r\nmse_test = model.evaluate(X_test, y_test)","cd0a054f":"# Plotting\r\npd.DataFrame(history.history).plot(figsize = (12, 6))\r\nplt.grid(True)\r\nplt.gca().set_ylim(0, 1)\r\nplt.show()","01f48e17":"keras.backend.clear_session()\r\nnp.random.seed(42)\r\ntf.random.set_seed(42)","16274d18":"def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\r\n    model = keras.models.Sequential()\r\n    model.add(keras.layers.InputLayer(input_shape=input_shape))\r\n    for layer in range(n_hidden):\r\n        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\r\n    model.add(keras.layers.Dense(1))\r\n    optimizer = keras.optimizers.SGD(lr=learning_rate)\r\n    model.compile(loss=\"mse\", optimizer=optimizer)\r\n    return model","cf7d7a69":"# Wrap the model using keras wrapper \r\nkeras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)","9ddb592e":"keras_reg.fit(X_train, y_train, epochs=100,\r\n              validation_data=(X_valid, y_valid),\r\n              callbacks=[keras.callbacks.EarlyStopping(patience=10)])","42cc8752":"\r\nmse_test = keras_reg.score(X_test, y_test)","120c0ff5":"# Making predictions\r\ny_pred = keras_reg.predict(X_new)","c758dc10":"from scipy.stats import reciprocal\r\nfrom sklearn.model_selection import RandomizedSearchCV\r\nparam_distribs = {\r\n \"n_hidden\": [0, 1, 2, 3],\r\n \"n_neurons\": np.arange(1, 100).tolist(),\r\n \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\r\n}\r\nrnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\r\nrnd_search_cv.fit(X_train, y_train, epochs=100,\r\n validation_data=(X_valid, y_valid),\r\n callbacks=[keras.callbacks.EarlyStopping(patience=10)])  ","d8d992f5":"rnd_search_cv.best_params_","30d38248":"rnd_search_cv.best_score_","62c9012d":"rnd_search_cv.best_estimator_","03409397":"rnd_search_cv.score(X_test, y_test)","00ba8bd9":"model = rnd_search_cv.best_estimator_.model\r\nmodel","10576c98":"model.evaluate(X_test, y_test)","238a8889":"from tensorflow.keras import layers\r\n# When working with colab install keras tuner\r\n!pip install -q -U keras-tuner\r\nfrom kerastuner.tuners import RandomSearch","0e34826d":"def build_model(hp): # hp IS THE HYPERPARAMETER\r\n    model = keras.Sequential()\r\n    for i in range(hp.Int('num_layers', 2, 20)):\r\n        model.add(layers.Dense(units=hp.Int('units_' + str(i), # All parameter names should be unique (here, in the loop over i, \r\n                                                               #we name the inner parameters 'units_' + str(i)).\r\n                                            #hp.int an integer from a certain range\r\n                                            min_value=32,\r\n                                            max_value=512,\r\n                                            step=32),\r\n                               activation='relu'))\r\n    model.add(layers.Dense(1, activation='linear'))\r\n    model.compile(\r\n        optimizer=keras.optimizers.Adam(\r\n            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), # hp.Choice to choose between following learning rates\r\n        loss='mean_absolute_error',                 \r\n        metrics=['mean_absolute_error'])\r\n    return model","535054cd":"# Available tuners are RandomSearch and Hyperband.\r\ntuner = RandomSearch(\r\n    build_model,\r\n    objective='val_mean_absolute_error',\r\n    max_trials=5,\r\n    executions_per_trial=3, # Total 15 fits\r\n    directory='project',    # To save all the check points \r\n    project_name='Air Quality Index')","b1d7cf73":"# You can print a summary of the search space:\r\ntuner.search_space_summary()","197336a0":"# Start the search for the best hyperparameter configuration.\r\ntuner.search(X_train, y_train,\r\n             epochs=5,\r\n             validation_data=(X_valid, y_valid))","5625fac1":"#  you can retrieve the best model(s)\r\nmodels = tuner.get_best_models(num_models=2)","f8620bcd":"models[0].evaluate(X_test, y_test)","bf1d4a2d":"models[0]","3da2b3b5":"To send a subset of the features through the wide path, and a\r\ndifferent subset (possibly overlapping) through the deep path","cc24c32c":"### Building an Image Classifi\u0080er","f5d4bb0f":"<a href=\"https:\/\/colab.research.google.com\/github\/Rishav-hub\/Dl_practice_Notebooks\/blob\/main\/L10_Artifi%C2%80cial_Neural_Networks_with_Keras.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","1767eebd":"Instead of passing a single input matrix X_train, we must pass a\r\npair of matrices (X_train_A, X_train_B): one per input. The same is true for\r\nX_valid, and also for X_test and X_new ","9de6929f":"A dictionary (history.history) containing the loss and extra metrics it\r\nmeasured at the end of each epoch on the training set and on the validation set","5b2dd6fd":"In\r\nthis example, the main output and the auxiliary output should try to predict the same\r\nthing, so they should use the same labels [y_train, y_train]","edfebf91":"### Using Callbacks during Training\r\n[Link for other callbacks]( https:\/\/keras.io\/callbacks\/)\r\n\r\n#### ModelCheckpoint callback\r\n- Saves checkpoints of your model at regular intervals during\r\ntraining, by default at the end of each epoch\r\n- No need to worry about training for too long and overfitting the training\r\nset: simply restore the last model saved after training, and this will be the best model\r\non the validation set","c44765ed":"#### Compile the model\r\nrefer - https:\/\/keras.io\/losses\/,\r\nhttps:\/\/keras.io\/optimizers\/ and https:\/\/keras.io\/metrics\/.\r\n","5ffeff3e":"### Keras- Tuner (ANN)\r\n[Link](https:\/\/keras-team.github.io\/keras-tuner\/)","7c2504b6":"### Building Complex Models Using the Functional AP","fbf74396":"### Saving and Restoring a Model\r\nUsing the HDF5 format\r\n","ec2e473d":" (history.history) containing the loss and extra metrics it\r\nmeasured at the end of each epoch on the training set and on the validation set","61c495d1":"Evaluating in the test  data","c203c7c0":"### Building Dynamic Models Using the Subclassing API\r\nIt create the layers you need in the constructor, and use\r\nthem to perform the computations you want in the call() method.\r\n\r\nDisadvantage - Your model\u2019s architecture is hidden\r\nwithin the call() method, so Keras cannot easily inspect it, it cannot save or clone it,\r\nand when you call the summary() method, you only get a list of layers, without any\r\ninformation on how they are connected to each other. Moreover, Keras cannot check\r\ntypes and shapes ahead of time, and it is easier to make mistakes.","f29cc9da":"We do not actually want to train and evaluate a single model like this, we\r\nwant to train hundreds of variants and see which one performs best on the validation\r\nset.\r\n\r\nThe following code would train ","1fd3b3ad":"### EarlyStopping Callback\r\nIt will interrupt training when it measures no progress on the validation set for\r\na number of epochs (defined by the patience argument), and it will optionally roll\r\nback to the best model.","7296b1e5":"#### Evaluating the model","3baee6c0":"### Building a Regression MLP Using the Sequential API\r\n","08508443":"Using keras.wrappers and sklearn\r\nRefer this [Link](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/wrappers\/scikit_learn) for more wrapper.","46074013":"### Fine-Tuning Neural Network Hyperparameters\r\nWe need to wrap our Keras models\r\nin objects that mimic regular Scikit-Learn regressors.\r\n[Link to the video](https:\/\/youtu.be\/Lx16T9cl5ng)","2a8ce3b2":"#### Add some auxiliary outputs in a neural network architecture"}}