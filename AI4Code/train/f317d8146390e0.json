{"cell_type":{"170cea6a":"code","f1b475b3":"code","b8a9d0dd":"code","4d2aec65":"code","628a780e":"code","8cd183c1":"code","6f280b4b":"code","907b6137":"code","4cd9c2bd":"code","1161d622":"code","f04c068b":"code","e5ac6499":"code","63755451":"code","ad5085ad":"code","f76bd2ad":"code","d8562810":"code","2f473e01":"code","ea4986b8":"code","3f90e1d9":"code","6ec78aad":"code","32b56660":"code","fb1b5bb5":"code","87712c28":"code","3c3a37d9":"code","f6d48390":"code","a6cbc41a":"code","4eb2dc11":"code","ba085c67":"code","8c667d4f":"code","69cc57cd":"markdown","fde06858":"markdown","8dd3b9ce":"markdown","610a443a":"markdown"},"source":{"170cea6a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f1b475b3":"#Reading the csv file of traning set\ntrain_set = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntrain_set.head()","b8a9d0dd":"#Dividing the Training set into input data and its labels\nY = train_set.iloc[:,0].values\nX = train_set.iloc[:,1:].values","4d2aec65":"print(\"Shape of input data {} ,Shape of labels set {}\".format(X.shape,Y.shape))","628a780e":"count = np.zeros(10)\nlabels = [\"Zero\",\"One\",\"Two\",\"Three\",\"Four\",\"Five\",\"Six\",\"Seven\",\"Eight\",\"Nine\"]\nDict = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[]}\nfor i in range(42000):\n    count[Y[i]] +=1\n    Dict[Y[i]].append(X[i,:])\nprint(count)\nprint(labels)","8cd183c1":"import matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 5))\nplt.bar(labels,count,color = '#4BF904')\nplt.title(\"Input Data\")\nplt.xlabel(\"Labels\")\nplt.ylabel(\"Count\")\nplt.legend()\nplt.show()","6f280b4b":"plt.figure(figsize=(20, 10))\nplt.style.use('default')\nfor i in range(10):\n    plt.subplot(5,2,i+1)\n    plt.imshow(Dict[i][0].reshape(28,28),cmap=\"gray\")\n    plt.title(labels[i])\nplt.tight_layout()\nplt.show()","907b6137":"pip install torchsummary","4cd9c2bd":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchsummary import summary","1161d622":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')","f04c068b":"class ConvNet(nn.Module):\n    def __init__(self,classes):\n        super().__init__()\n\n        self.con1 = nn.Conv2d(1,64,3,padding=1)\n        self.bn1 = nn.BatchNorm2d(num_features=64)\n        self.pool1 = nn.AvgPool2d(kernel_size=(2,2))\n\n        self.con2 = nn.Conv2d(64,64,3,padding=1)\n        self.bn2 = nn.BatchNorm2d(num_features=64)\n        self.pool2 = nn.AvgPool2d(kernel_size=(2,2))\n        self.drop2d = nn.Dropout2d(p=0.35)\n\n        self.con3 = nn.Conv2d(64,64,3,padding=1)\n        self.bn3 = nn.BatchNorm2d(num_features=64)\n\n        self.fc1 = nn.Linear(64*7*7,256)\n        self.bn4 = nn.BatchNorm1d(num_features=256)\n        self.drop1 = nn.Dropout(p=0.3)\n\n        self.fc2 = nn.Linear(256,128)\n        self.bn5 = nn.BatchNorm1d(num_features=128)\n        self.drop2 = nn.Dropout(p=0.3)\n\n        self.fc3 = nn.Linear(128,classes)\n    def forward(self,x,training = True):\n        \n        out = F.relu(self.con1(x))\n        out = self.bn1(out)\n        out = self.pool1(out)\n      \n        out = F.relu(self.con2(out))\n        out = self.bn2(out)\n        out = self.pool2(out) \n        if training==True:\n            out = self.drop2d(out)       \n        \n        out = F.relu(self.con3(out))\n        out = self.bn3(out)\n        \n        out = out.view(-1,64*7*7)\n        out = F.relu(self.fc1(out))\n        out = self.bn4(out)\n        if training == True:\n            out = self.drop1(out)\n\n        \n        out = F.relu(self.fc2(out))\n        out = self.bn5(out)\n        if training == True:\n            out = self.drop2(out)      \n        \n        out = self.fc3(out)        \n        return out\n        \n            ","e5ac6499":"total_labels = 10","63755451":"#Spliting the train data into train and validation data\nX_train = X[:38000,:]\/255\nX_val = X[38000:,:]\/255\nY_train = Y[:38000]\nY_val = Y[38000:]","ad5085ad":"model = ConvNet(total_labels).to(device)","f76bd2ad":"summary(model,(1,28,28))","d8562810":"loss = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.00001,weight_decay = 0.00001)","2f473e01":"train_loss_cache = []\niterations = []\nt=0\nfor epoch in range(70):\n    for batch in range(100):\n        images = torch.from_numpy(X_train[batch*380:batch*380+380,:].reshape(-1,1,28,28)).to(device)\n        its_label = torch.from_numpy(Y_train[batch*380:batch*380+380]).to(device)\n        output = model(images.float(),training=True)\n        cost = loss(output,its_label)\n        if batch%100==0:\n            print(\"At epoch {}\/7 nad batch {}\/1000, Train loss = {}\".format(epoch,batch,cost))\n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n    train_loss_cache.append(cost)\n    t=t+1\n    iterations.append(t)","ea4986b8":"plt.figure(figsize = (10,5))\nplt.plot(train_loss_cache,iterations,label = 'Training Data')\nplt.show()","3f90e1d9":"torch.cuda.empty_cache()","6ec78aad":"with torch.no_grad():\n    correct = 0\n    samples = 0\n    for batch in range(100):\n        images = torch.from_numpy(X_train[batch*380:batch*380+380,:].reshape(-1,1,28,28)).to(device)\n        label = torch.from_numpy(Y_train[batch*380:batch*380+380]).to(device)\n        output = model(images.float(),training=False)\n        _,predictions = torch.max(output,1)\n        samples += label.shape[0]\n        correct += (predictions == label).sum().item()\n    print(\"Train Accuracy: {}\".format(correct\/samples))","32b56660":"with torch.no_grad():\n    correct = 0\n    samples = 0\n    images = torch.from_numpy(X_val.reshape(-1,1,28,28)).to(device)\n    label = torch.from_numpy(Y_val).to(device)\n    output = model(images.float(),training=False).to(device)\n    _,predictions = torch.max(output,1)\n    samples += label.shape[0]\n    correct += (predictions == label).sum().item()\n    print(\"Valid Accuracy: {}\".format(correct\/samples))","fb1b5bb5":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","87712c28":"X_test = test.iloc[:,:].values","3c3a37d9":"X_test = X_test\/255","f6d48390":"with torch.no_grad():\n    images = torch.from_numpy(X_test.reshape(-1,1,28,28)).to(device)\n    label = model(images.float(),training=False).to(device)\n    _,predictions = torch.max(label,1)","a6cbc41a":"labels = np.array(predictions.to('cpu'))","4eb2dc11":"imageid = []\nfor i in range(X_test.shape[0]):\n    imageid.append(i+1)\nid = np.array(imageid)","ba085c67":"submission = pd.DataFrame({\"ImageId\":imageid,\"Label\":labels})","8c667d4f":"submission.to_csv(\"submission_colab.csv\",index = False)","69cc57cd":"# Training the model","fde06858":"# Importing the PyTorch Module","8dd3b9ce":"# Structure of our model\n#### First Layer:  \n    Input- Image of shape 28X28 and 1 channel\n    Parameters- Shape 3X3 and 64 channels with padding = 1\n    Batch Normalization\n    Pooling layer- Average pooling with shape 2X2\n#### Second Layer:\n    Input- Shape 14X14 and 64 channels\n    Parameters- Shape 3X3 and 64 channels with padding = 1\n    Batch Normalization\n    Pooling layer- Average pooling with shape 2X2\n    Dropout- Probability 0.35\n#### Third Layer:\n    Input- Shape 7X7 and 64 channels\n    Parameters- Shape 3X3 and 64 channels with padding = 1\n    Batch Normalization\n#### Fully connected layer 1:\n    Input- 64X7X7(3136) features\n    Batch Normalization\n    Dropout- Probability 0.3\n#### Fully connected layer 2:\n    Input- 256 features\n    Batch Normalizaion\n    Dropout- Probability 0.3\n#### Fully connected layer 3:\n    Input- 128 features\n    Softmax layer(computed the loss function defined)\n#### Loss Function:\n    Cross Entropy Loss\n#### Optimizer:\n    Adam Optimization\n    Learning rate- 0.00001\n    Batch Size- 1000 training examples\n    Weight decay- 0.00001\n    Epochs- 180\n    \n","610a443a":"# Data\nImporting the trainind data from train.csv file  \nThis file contains pixel values of 42000 images with their respective label  \nImage size:- 28 * 28  \nPixel values:- 0-255"}}