{"cell_type":{"b2c490e1":"code","2ebf1b6f":"code","1a26be3f":"code","882e43c0":"code","e5b5b8d8":"code","0aa56a84":"code","f450662e":"code","7b6ec011":"code","c3b434d1":"code","fce7597b":"code","aa7e0822":"code","4545b10f":"code","5df9e05e":"code","a3b1f730":"code","11af53ab":"code","1c1ee901":"code","a8d02d4a":"code","03955304":"code","62ffddbb":"code","4b43abf5":"code","ed6dd92b":"markdown","ed0f9917":"markdown","06b24e7a":"markdown","ebc0adb5":"markdown","894cce71":"markdown","e072ef74":"markdown","e660c3f2":"markdown","924a1157":"markdown","83d05eb8":"markdown","2a6f7f04":"markdown","345d6967":"markdown","8ea25fce":"markdown","aaee2f70":"markdown","cae37916":"markdown","08d7fece":"markdown","c902be8e":"markdown","9d20aea5":"markdown","e2c71539":"markdown","b2416687":"markdown","9ce17465":"markdown","4ebfd61a":"markdown"},"source":{"b2c490e1":"import os\nfor dirname,_,_ in os.walk('\/kaggle\/input'):\n    print(dirname)","2ebf1b6f":"# File treatment\nimport shutil, os\nos.mkdir('\/kaggle\/working\/ship')\nos.mkdir('\/kaggle\/working\/other')\nfor file in os.listdir('\/kaggle\/input\/ships-in-satellite-imagery\/shipsnet\/shipsnet'):\n  if file.startswith('0'):\n    shutil.copy('\/kaggle\/input\/ships-in-satellite-imagery\/shipsnet\/shipsnet\/' + file, '\/kaggle\/working\/other\/')\n  else:\n    shutil.copy('\/kaggle\/input\/ships-in-satellite-imagery\/shipsnet\/shipsnet\/' + file, '\/kaggle\/working\/ship\/')\n\n#shutil.rmtree('\/kaggle\/input\/ships-in-satellite-imagery\/shipsnet\/shipsnet')\nprint(len(os.listdir('\/kaggle\/working\/other\/')),len(os.listdir('\/kaggle\/working\/ship\/')))","1a26be3f":"# Libraries\nfrom zipfile import ZipFile\nimport shutil, os\nimport re\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow_hub as hub\nfrom tensorflow.keras.layers import Dense,Activation,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard,LearningRateScheduler\nimport tensorflow as tf\nimport datetime","882e43c0":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 16 #16 * strategy.num_replicas_in_sync\nSHUFFLE_SIZE = 1000\nIMAGE_SIZE = [80, 80]\nEPOCHS = 30","e5b5b8d8":"# Load the data\nfilenames = tf.io.gfile.glob(str('\/kaggle\/working\/*\/*'))\n\ntrain_val_filenames, test_filenames = train_test_split(filenames, test_size=0.1)\ntrain_filenames, val_filenames = train_test_split(train_val_filenames, test_size=0.15)\nprint(len(train_filenames),len(val_filenames),len(test_filenames))","0aa56a84":"# Ship images count\nNB_SHIP = len([name for name in train_filenames if \"ship\" in name])\nprint(\"Ship images count in training set: \" + str(NB_SHIP))\n\n# Non ship images count\nNB_NO_SHIP = len([name for name in train_filenames if \"other\" in name])\nprint(\"No-ship images count in training set: \" + str(NB_NO_SHIP))","f450662e":"# Creating datasets\ntrain_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\nval_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\ntest_list_ds = tf.data.Dataset.from_tensor_slices(test_filenames)\n\nfor f in train_list_ds.take(5):\n    print(f.numpy())","7b6ec011":"# Training images count\nTRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\nprint(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n\n# Validation images count\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\nprint(\"Validating images count: \" + str(VAL_IMG_COUNT))","c3b434d1":"# Class names\nCLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n                        for item in tf.io.gfile.glob(str('\/kaggle\/working\/*')) if '__' not in item])\nCLASS_NAMES","fce7597b":"def get_label(file_path):\n    \n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    return parts[-2] == \"ship\"\n\ndef image_processing(file_path):\n    \n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    # convert the compressed string to a 3D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=3)\n    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # resize the image to the desired size\n    img = tf.image.resize(img, IMAGE_SIZE)\n    \n    return img, label","aa7e0822":"# Mapped trainset\ntrain_ds = train_list_ds.map(image_processing, num_parallel_calls=AUTOTUNE)\n\n# Mapped Validationset\nval_ds = val_list_ds.map(image_processing, num_parallel_calls=AUTOTUNE)\n\n# Shape and label for one image\nfor image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","4545b10f":"# Load and format testset\nTEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\ntest_ds = test_list_ds.map(image_processing, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\n\nprint(\"Testing images count: \" + str(TEST_IMAGE_COUNT))","5df9e05e":"# This is a small dataset, only load it once, and keep it in memory.\n# Shuffle it and repeat forever\n# Batch the dataset\n# `prefetch` lets the dataset fetch batches in the background while the model is training.\ntrain_ds = train_ds.cache().shuffle(SHUFFLE_SIZE).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\nval_ds = val_ds.cache().shuffle(SHUFFLE_SIZE).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\nimage_batch, label_batch = next(iter(train_ds))","a3b1f730":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(16):\n        ax = plt.subplot(4,4,n+1)\n        plt.imshow(image_batch[n])\n        if label_batch[n]:\n            plt.title(\"SHIP\")\n        else:\n            plt.title(\"OTHER\")\n        plt.axis(\"off\")\n\n# Visualize the first batch\nshow_batch(image_batch.numpy(), label_batch.numpy())","11af53ab":"initial_bias = np.log([NB_SHIP\/NB_NO_SHIP])\ninitial_bias","1c1ee901":"weight_for_0 = (1 \/ NB_NO_SHIP)*(TRAIN_IMG_COUNT)\/2.0 \nweight_for_1 = (1 \/ NB_SHIP)*(TRAIN_IMG_COUNT)\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","a8d02d4a":"# Modeling\nMODULE_HANDLE = \"https:\/\/tfhub.dev\/google\/imagenet\/resnet_v2_101\/feature_vector\/4\"\nfeature_extractor = hub.KerasLayer(MODULE_HANDLE, input_shape= (80,80) + (3,), output_shape=[1280], trainable=False)\nmodel = Sequential([feature_extractor, Dense(1,activation='sigmoid')])\n\n# Learning rate decay \/ scheduling\nadam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\nrmsprop = RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False, name=\"RMSprop\")\n\n# Metrics\nMETRICS = ['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n\n# Model Compile\nmodel.compile(optimizer=adam, loss='binary_crossentropy', metrics=METRICS)\n\n# Callbacks functions\nlogdir = \"logs\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nrLRop = ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.8, patience=3, verbose=1, mode=\"auto\", min_lr=0.000001)\ntensorboard = TensorBoard(log_dir=logdir, histogram_freq=1, write_graph=True, write_images=False, update_freq=\"batch\", profile_batch=0,\n                          embeddings_freq=0,embeddings_metadata=None)","03955304":"# Model fit function\nhistory = model.fit(\n    train_ds,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=val_ds,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=class_weight,\n)","62ffddbb":"# Visualize model's performance\nfig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","4b43abf5":"# Predictions\nloss, acc, prec, rec = model.evaluate(test_ds)","ed6dd92b":"Let's apply the preprocessing functions written above.","ed0f9917":"## II. Setting-Up Kaggle\nIf we work with kaggle, we need to use the lines of codes shown below and given by kaggle in order to locate the folder containing our data.","06b24e7a":"## I. Introduction\n\nThis notebook will explain the complete pipeline from loading data to predicting results, and it will explain how to build an ships recognizer from satellite imagery from scratch to predict whether an image shows presence of ships.\n","ebc0adb5":"We see that the accuracy for our model is around 98%.","894cce71":"Notice that the there are way more images that are classified as non-ship than ship. This shows that we have a imbalance in our data. We will correct for this imbalance later on in our notebook.\n\nWe will create the datasets for our project by using tf.data.Dataset.\n","e072ef74":"## VIII. Visualizing model performance\nLet's plot the model accuracy and loss for the training and the validating set. These plots show the accuracy and loss values of training. ","e660c3f2":"## X. Predict and evaluate results\nLet's evaluate the model on our test data!","924a1157":"## VI. Correct the data \n","83d05eb8":"The code in the following cell count the number of images we have in our training and validation dataset. We can then verify that the ratio of images is 80:10:10.","2a6f7f04":"The code below explain how we segmented the data into different folders containing files for training and testing.","345d6967":"From exploring the data and the model, I noticed that the training for the model has a slow start. However, after <b>EPOCHS<\/b> epochs, the model slowly starts to converge.","8ea25fce":"## III. Libraries and variables\n\nRun the following cell to load the necessary packages. We are going to instantiate constant variables such as the **BATCH_SIZE**, IMAGE_SIZE and the number of **EPOCHS**.\n","aaee2f70":"The code below count the number of ships and non-ships in the trainset","cae37916":" The code below will load the datasets only once and keep it in memory because it is small. Then, we will shuffle it, repeat the process in order to keep give data to the model for training. We will also batch it and use prefetch to add batches to the background while the model is training.\n","08d7fece":"Load and apply the same preprocessing functions on the test set.","c902be8e":"## VII. Train the model\nSince there are only two possible labels for the image, we will be using the binary_crossentropy loss. When we fit the model, identify the class weights. Because we are using a TPU, training will be relatively quick.\n\nFor our metrics, we want to include precision and recall as they will provide use with a more informed picture of how good our model is. Accuracy tells us what fractions are the labels are correct. Since our data is not balanced, accuracy might give a skewed sense of a good model (i.e. a model that always predicts other will be 74% accurate but is not a good model).\n\nPrecision is the number of true positives (TP) over the sum of TP and false positives (FP). It shows what fraction of labeled positives are actually correct.\n\nRecall is the number of TP over the sum of TP and false negatves (FN). It shows what fraction of actual positives are correct.","9d20aea5":"To get the numnber of classes in our datasets, please run the following cell.\n","e2c71539":"## IV. Load the data\n\nThe Ships data come with only one directory. You can find the datasets on this page by clicking on this <a href=\"https:\/\/www.kaggle.com\/rhammell\/ships-in-satellite-imagery?\">link<\/a>. We are going to use train_test_split from <b>sklearn.model_selection<\/b> in order to divide this dataset into 3 datasets (train, validation, test).  We are going to take into consideration this proportion <b>80:10:10<\/b> in the division process.\n","b2416687":"As demonstrated previously, the dataset is just a list of filenames which we want to map to tuple (image, label). The following function will first overwrite the labels by transforming <b>ship<\/b> to <b>1 (True)<\/b> and <b>other<\/b> to <b>0 (False)<\/b>. Then, we will preprocess the images by converting its type, resizing it and may be trying some data augmentation techniques. The below functions were inspired by the loading images techniques provided by tensorflow on this <a href=\"https:\/\/www.tensorflow.org\/tutorials\/load_data\/images\">link<\/a>.","9ce17465":"## V. Visualize the first batch\n\nThis function will show the first batch of images stored in the trainset.","4ebfd61a":"We saw earlier in this notebook that the data was imbalanced, with more images classified as other than normal. We will correct for that in this following section."}}