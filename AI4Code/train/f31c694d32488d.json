{"cell_type":{"a8521a03":"code","2442af4f":"code","0d81dc30":"code","dd92fa08":"code","7c10e09f":"code","b72a0ac8":"code","68612eef":"code","29d39ca1":"code","8b789206":"code","7e69618c":"code","c3bc19de":"code","414bd37e":"code","3db520ff":"code","40a73cae":"code","4a601d38":"code","a7768bf5":"code","b614963e":"code","da34d7d6":"code","1bb11907":"code","19268c3f":"code","e9e474ce":"code","45aafa7f":"code","d8fbd080":"code","28f5c243":"code","2d1c5d15":"code","c1ff24e0":"code","bcafb188":"code","3da03e9a":"code","926e9e64":"code","8e9f7f6f":"code","891678dd":"code","4a7bb4c9":"code","1898c4cb":"code","85de5df4":"code","7b2ded6b":"code","b7fbe962":"code","7962460c":"code","243d3906":"code","b5bcb2b1":"code","7d6370ea":"code","e9a89516":"code","2e030d7b":"code","b65e70d3":"code","ca10b4f4":"code","e8237628":"code","490b89a4":"code","e0c9589a":"code","35c20cb1":"code","d5b795da":"code","20decfdf":"code","213869aa":"code","0558ba6a":"code","da51e10b":"code","6c49119d":"code","362cd634":"code","c81b526a":"code","61059d68":"code","c4a60900":"code","a82fef3d":"markdown","0901fbd1":"markdown","de203855":"markdown","f7be10c5":"markdown","3632d6a6":"markdown","89ca9766":"markdown","736c040e":"markdown","63fc4bca":"markdown","255dd511":"markdown","39072c83":"markdown","5f15dd42":"markdown","aa91d081":"markdown","94dda56e":"markdown","1d4013b3":"markdown","37ab98c0":"markdown","09968ab0":"markdown","fd29dcf7":"markdown","db342a5b":"markdown","79d8b5e0":"markdown","7187cf44":"markdown","f1ed3d5e":"markdown","69c61369":"markdown","0e80cf69":"markdown","1cb331c9":"markdown","d9904682":"markdown"},"source":{"a8521a03":"#Importing required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","2442af4f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0d81dc30":"#reading source file\ndata=pd.read_csv(\"\/kaggle\/input\/Bank_Personal_Loan_Modelling.csv\")","dd92fa08":"#Checking the head of the data\ndata.head(10)","7c10e09f":"#Checking the data types of the columns\ndata.dtypes\n\n#All datda are of type integer except CCAvg which is of Float","b72a0ac8":"#Checking the information\ndata.info()","68612eef":"#checking the shape of the data-set\ndata.shape\n# We can infer there are 5000 data with 14 columns each","29d39ca1":"#To check if there are any null values present\nnulllvalues=data.isnull().sum()\nprint(nulllvalues)\n#There are no null values present in the data-set","8b789206":"#To check if there are any NaN values present\nNaNvalues=data.isna().sum()\nprint(NaNvalues)\n#There are no NaN values present in the data-set","7e69618c":"#To check the data\ndata.describe().T","c3bc19de":"#Droping ID column as it is not used for analysis\ndata.drop(['ID'],axis=1,inplace=True)","414bd37e":"#New data head\ndata.head(10)","3db520ff":"#Distribution of continous data\n\nplt.figure(figsize=(30,6))\n\n#Subplot 1\nplt.subplot(1,3,1)\nplt.title('Age')\nsns.distplot(data['Age'],color='red')\n\n#Subplot 2\nplt.subplot(1,3,2)\nplt.title('Experience')\nsns.distplot(data['Experience'],color='blue')\n\n#Subplot 3\nplt.subplot(1,3,3)\nplt.title('Income')\nsns.distplot(data['Income'],color='green')\n\n\n\nplt.figure(figsize=(30,6))\n\n#Subplot 1- Boxplot\nplt.subplot(1,3,1)\nplt.title('Age')\nsns.boxplot(data['Age'],orient='vertical',color='red')\n\n#Subplot 2\nplt.subplot(1,3,2)\nplt.title('Experience')\nsns.boxplot(data['Experience'],orient='vertical',color='blue')\n\n#Subplot 3\nplt.subplot(1,3,3)\nplt.title('Income')\nsns.boxplot(data['Income'],orient='vertical',color='green')\n","40a73cae":"#Histogram for CCAvg,Motage- Continous data\nplt.figure(figsize=(30,6))\n\n#Subplot 1\nplt.subplot(1,2,1)\nplt.title('CCAvg')\nsns.distplot(data['CCAvg'],color='red')\n\n#Subplot 2\nplt.subplot(1,2,2)\nplt.title('Mortgage')\nsns.distplot(data['Mortgage'],color='blue')\n\nplt.figure(figsize=(30,6))\n\n#Subplot 1- Boxplot\nplt.subplot(1,2,1)\nplt.title('CCAvg')\nsns.boxplot(data['CCAvg'],orient='vertical',color='red')\n\n#Subplot 2\nplt.subplot(1,2,2)\nplt.title('Mortgage')\nsns.boxplot(data['Mortgage'],orient='vertical',color='blue')\n","4a601d38":"# Distribution of Categorical data\n\nplt.figure(figsize=(30,6))\n\n#Subplot 1\nplt.subplot(1,3,1)\nplt.title('Family')\nsns.countplot(data['Family'],color='cyan')\n\n#Subplot 2\nplt.subplot(1,3,2)\nplt.title('Education')\nsns.countplot(data['Education'],color='violet')\n\n#Subplot 3\nplt.subplot(1,3,3)\nplt.title('Securities Account')\nsns.countplot(data['Securities Account'],color='green')\n\nplt.figure(figsize=(30,6))\n\n#Subplot 4\nplt.subplot(1,3,1)\nplt.title('CD Account')\nsns.countplot(data['CD Account'],color='red')\n\n#Subplot 5\nplt.subplot(1,3,2)\nplt.title('Online')\nsns.countplot(data['Online'],color='blue')\n\n#Subplot 6\nplt.subplot(1,3,3)\nplt.title('CreditCard')\nsns.countplot(data['CreditCard'],color='orange')","a7768bf5":"#To find the correlation between the continous variables\ncorrelation=data.corr()\ncorrelation.style.background_gradient(cmap='coolwarm')","b614963e":"sns.heatmap(correlation)","da34d7d6":"columns=['Age','Experience','Income','CCAvg','Mortgage','Personal Loan']","1bb11907":"sns.pairplot(data[columns])","19268c3f":"sns.countplot(data['Personal Loan'])","e9e474ce":"#Calculate baseline proportion - ratio of Yes to No to identify data imbalance\nValue_counts = data['Personal Loan'].value_counts(normalize=True)\nprint(Value_counts)","45aafa7f":"#Converting all categorical variable to categorical data type\ndata['Personal Loan']=data['Personal Loan'].astype('category')\ndata['Family']=data['Family'].astype('category')\ndata['Education']=data['Education'].astype('category')\ndata['Securities Account']=data['Securities Account'].astype('category')\ndata['CD Account']=data['CD Account'].astype('category')","d8fbd080":"data.dtypes","28f5c243":"#Dropping the non targeted columns\ndata.drop([\"ZIP Code\",\"Age\",\"Experience\",\"Online\",\"CreditCard\"],axis=1,inplace = True)\n","2d1c5d15":"data.head()","c1ff24e0":"#Normalzing the continous data Income,CCAvg,Mortgage\n#Removing other cols except continous data for calculating z score(Normalizing)\ncols = list(data.columns)\ncols.remove('Education')\ncols.remove('Personal Loan')\ncols.remove('CD Account')\ncols.remove('Family')\ncols.remove('Securities Account')\ncols","bcafb188":"for col in cols:\n    col_zscore = col + '_zscore'\n    data[col_zscore] = (data[col] - data[col].mean())\/data[col].std(ddof=0) \ndata.head()\n#Calculated Z scre for Income CCAVg and mortgage","3da03e9a":"#importing necessary libraries\nfrom sklearn.model_selection import train_test_split","926e9e64":"# Deternmining the indepedent and dependent variales (X and Y)\nX=data.drop([\"Personal Loan\",\"Income\",\"CCAvg\",\"Mortgage\"],axis=1)","8e9f7f6f":"Y=data['Personal Loan']","891678dd":"# Checking the shape of X and Y\nX.shape","4a7bb4c9":"Y.shape","1898c4cb":"Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.3,random_state=1)\nXtrain.head()","85de5df4":"#importing necessary libraries\nfrom sklearn.linear_model import LogisticRegression","7b2ded6b":"model_log_regression=LogisticRegression(solver=\"liblinear\")","b7fbe962":"model_log_regression.fit(Xtrain,Ytrain)\ncoef_df = pd.DataFrame(model_log_regression.coef_)\ncoef_df['intercept'] = model_log_regression.intercept_\nprint(coef_df)","7962460c":"#Checking the score for logistic regression\nlogistic_regression_Trainscore=model_log_regression.score(Xtrain,Ytrain)\nprint(\"The score for Logistic regression-Training Data is {0:.2f}%\".format(logistic_regression_Trainscore*100))\nlogistic_regression_Testscore=model_log_regression.score(Xtest,Ytest)\nprint(\"The score for Logistic regression-Test Data is {0:.2f}%\".format(logistic_regression_Testscore*100))","243d3906":"#Predicting the Y values\nYpred=model_log_regression.predict(Xtest)\n\n#Misclassification error\nLR_MSE=1-logistic_regression_Testscore\nprint(\"Misclassification error of Logistical Regression model is {0:.1f}%\".format(LR_MSE*100))","b5bcb2b1":"#Confusion Matrix\nfrom sklearn import metrics\ncm=metrics.confusion_matrix(Ytest, Ypred, labels=[1, 0])\n\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm, annot=True)","7d6370ea":"accuracy_score=metrics.accuracy_score(Ytest,Ypred)\npercision_score=metrics.precision_score(Ytest,Ypred)\nrecall_score=metrics.recall_score(Ytest,Ypred)\nprint(\"The Accuracy of this model is {0:.2f}%\".format(accuracy_score*100))\nprint(\"The Percission of this model is {0:.2f}%\".format(percision_score*100))\nprint(\"The Recall score of this model is {0:.2f}%\".format(recall_score*100))","e9a89516":"#AUC ROC curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\nlogit_roc_auc = roc_auc_score(Ytest, model_log_regression.predict(Xtest))\nfpr, tpr, thresholds = roc_curve(Ytest, model_log_regression.predict_proba(Xtest)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","2e030d7b":"auc_score = metrics.roc_auc_score(Ytest, model_log_regression.predict_proba(Xtest)[:,1])\nprint(\"The AUC score is {0:.2f}\".format(auc_score))","b65e70d3":"#Importing necessary Libraries and spliting data\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom scipy.stats import zscore\n\n#Spliting the data for K-Nearest Neighbors\nXTrain,XTest,YTrain,YTest=train_test_split(X,Y,test_size=0.3,random_state=1)","ca10b4f4":"#Finding the optimal value of k nearest neigbours, not considering 1 as just checking 1 nearest neighbor is not recomended.\nneighbours=np.arange(2,30,2)\nac_scores=[]\nfor k in neighbours:\n    knn=KNeighborsClassifier(n_neighbors=k)\n    knn.fit(XTrain,YTrain)\n    score=knn.score(XTest,YTest)\n    ac_scores.append(score)\nMax_score=max(ac_scores)#finding the max score\nneighbours[ac_scores.index(max(ac_scores))]\n","e8237628":"model_knn=KNeighborsClassifier(n_neighbors=6)","490b89a4":"#Fitting the model\nmodel_knn.fit(XTrain,YTrain)\nYPred=model_knn.predict(XTest)","e0c9589a":"#Checking the score for KNN\nKNN_score=model_knn.score(XTest,YTest)\nprint(\"The score for KNN is {0:.2f}%\".format(KNN_score*100))","35c20cb1":"MSE=1-KNN_score\nprint(\"The misclassification error is {0:.2f}%\".format(MSE*100))\n\n#Calculating the model score for accuracy\nfrom sklearn import metrics\nKNN_train_Score=model_knn.score(XTrain, YTrain)\nprint(\"KNN model Accuracy for training data is {0:.2f}%\".format(KNN_train_Score*100))\n\nKNN_test_Score=model_knn.score(XTest, YTest)\nprint(\"KNN model Accuracy for training data is {0:.2f}%\".format(KNN_test_Score*100))","d5b795da":"\n#Confusion Matrix\ncm1=metrics.confusion_matrix(YTest, YPred, labels=[1, 0])\n\ndf_cm1 = pd.DataFrame(cm1, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm1, annot=True)","20decfdf":"accuracy_score=metrics.accuracy_score(YTest,YPred)\npercision_score=metrics.precision_score(YTest,YPred)\nrecall_score=metrics.recall_score(YTest,YPred)\nprint(\"The Accuracy of this model is {0:.2f}%\".format(accuracy_score*100))\nprint(\"The Percission of this model is {0:.2f}%\".format(percision_score*100))\nprint(\"The Recall score of this model is {0:.2f}%\".format(recall_score*100))","213869aa":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 10)","0558ba6a":"#Import necessary Linraries\nfrom sklearn.naive_bayes import GaussianNB","da51e10b":"model_NB = GaussianNB()","6c49119d":"#Fitting the model\nmodel_NB.fit(X_train,Y_train)","362cd634":"#Predicting the Y value\nY_pred=model_NB.predict(X_test)","c81b526a":"#Checking the score for Naive Bayes\nNB_score_train=model_NB.score(X_train,Y_train)\nprint(\"Naive Bayes model Accuracy for training data is {0:.2f}%\".format(NB_score_train*100))\nNB_score_test=model_NB.score(X_test,Y_test)\nprint(\"Naive Bayes model Accuracy for test data is {0:.2f}%\".format(NB_score_test*100))\nNB_MSE=1-NB_score_test\nprint(\"The misclassification error of Naive Bayes model is {0:.2f}%\".format(NB_MSE*100))","61059d68":"#Confusion Matrix\ncm2=metrics.confusion_matrix(Y_test, Y_pred, labels=[1, 0])\n\ndf_cm2 = pd.DataFrame(cm2, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (7,5))\nsns.heatmap(df_cm2, annot=True)","c4a60900":"accuracy_score=metrics.accuracy_score(Y_test,Y_pred)\npercision_score=metrics.precision_score(Y_test,Y_pred)\nrecall_score=metrics.recall_score(Y_test,Y_pred)\nprint(\"The Accuracy of this model is {0:.2f}%\".format(accuracy_score*100))\nprint(\"The Percission of this model is {0:.2f}%\".format(percision_score*100))\nprint(\"The Recall score of this model is {0:.2f}%\".format(recall_score*100))","a82fef3d":"## Target Column Distribution\n#### Personal Loan here is our Target column","0901fbd1":"**6 is considered as Best K value for this Data set other than 1 which is not recomended**","de203855":"## Attribute Description\n##### \uf0b7 ID : Customer ID\n##### \uf0b7 Age : Customer's age in completed years\n##### \uf0b7 Experience : #years of professional experience\n##### \uf0b7 Income : Annual income of the customer\n##### \uf0b7 ZIP Code : Home Address ZIP code\n##### \uf0b7 Family : Family size of the customer\n##### \uf0b7 CCAvg : Avg. spending on credit cards per month\n##### \uf0b7 Education : Education Level. 1- Undergrad, 2- Graduate, 3- Advanced\/Professional\n##### \uf0b7 Mortgage : Value of house mortgage if any.\n##### \uf0b7 Personal Loan : Did this customer accept the personal loan offered in the last campaign?\n##### \uf0b7 Securities Account : Does the customer have a securities account with the bank?\n##### \uf0b7 CD Account : Does the customer have a certificate of deposit (CD) account with the bank?\n##### \uf0b7 Online : Does the customer use internet banking facilities?\n##### \uf0b7 Credit card : Does the customer use a credit card issued by","f7be10c5":"##### Mean of Income,CCAvg,Mortage are above the median which infers that we have outliers","3632d6a6":"##### Family and Education is more or less equally distributed\n##### Family with 1 member is large than others\n##### Education- Undergraduates are more than others\n##### Most customers donot have securities account and CD account\n##### Number of people having Online account is higher\n##### Number of people not having Credit card is higher","89ca9766":"# Data Tuning","736c040e":"## K-Nearest Neighbors","63fc4bca":"\n### Considering the correlation of different variables against Personal loans\n\n#### Income, Family, CCAvg, Education, Mortgage,Security Account, CD account are much likely co related to personal loan than others\n\n#### Thus independent variables considered areIncome, Family, CCAvg, Education, Mortgage, Security Account, CD account","255dd511":"#### Splitting the data to 70% training data and 30% test data for Logistic Regression","39072c83":"## c. Multi-variate Analysis","5f15dd42":"# Conclusion\n## Out of all 3 models (Logistic Regression, K-Nearest Neighbors, Naive Bayes), K-Nearest Neighbors seems to be the best model since the accuracy, percision and recall score is good.\n## KNN Model:\n#### The Accuracy of this model is 96.27%\n#### The Percission of this model is 97.94%\n#### The Recall score of this model is 63.76%","aa91d081":"##### Average age ranges from 30 to 60,\n##### Average Experience ranges from 10 to 30 years, \n##### Mostly income rages from 50K to 100K  but there are good number of outliers.","94dda56e":"# The confusion matrix\n\nTrue Positives (TP): we correctly predicted that they have taken Personal Loan 83\n\nTrue Negatives (TN): we correctly predicted that they have not taken Personal Loan 1200\n\nFalse Positives (FP): we incorrectly predicted that have taken Personal Loan (a \"Type I error\") 120 Falsely predict positive Type I error\n\nFalse Negatives (FN): we incorrectly predicted that they have not taken Personal Loan (a \"Type II error\") 57 Falsely predict negative Type II error","1d4013b3":"#### The confusion matrix\n\nTrue Positives (TP): we correctly predicted that they have taken Personal Loan 95\n\nTrue Negatives (TN): we correctly predicted that they have not taken Personal Loan 1300\n\nFalse Positives (FP): we incorrectly predicted that have taken Personal Loan (a \"Type I error\") 2 Falsely predict positive Type I error\n\nFalse Negatives (FN): we incorrectly predicted that they have not taken Personal Loan (a \"Type II error\") 54 Falsely predict negative Type II error","37ab98c0":"##### The correlation between the independent variables is low excpet for Age and Experience\n##### The correlation between Income and CCAvg is quite good","09968ab0":" ##### Mostly CreditCard Average ranges from 1-3 but there are huge number of outliers, \n ##### Mostly Mortgage average ranges from 0-100 but there are huge number of outliers","fd29dcf7":"## a.Univariate Analysis","db342a5b":"## Data Slicing","79d8b5e0":"## Logistic Regression","7187cf44":"# The confusion matrix\n\nTrue Positives (TP): we correctly predicted that they have taken Personal Loan 80\n\nTrue Negatives (TN): we correctly predicted that they have not taken Personal Loan 1300\n\nFalse Positives (FP): we incorrectly predicted that have taken Personal Loan (a \"Type I error\") 11 Falsely predict positive Type I error\n\nFalse Negatives (FN): we incorrectly predicted that they have not taken Personal Loan (a \"Type II error\") 69 Falsely predict negative Type II error","f1ed3d5e":"# 2.Exploratoray Data Analytics","69c61369":"# 1. Reading Data File and Checking Data","0e80cf69":"## b. Bivariate Analysis","1cb331c9":"# Naive Bayes","d9904682":"##### The number of people who availed personal loan is less(<10%)"}}