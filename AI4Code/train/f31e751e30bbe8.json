{"cell_type":{"2ff5e558":"code","e07c43a1":"code","4b4059c0":"code","e61a30bd":"code","61800b27":"code","1b4734f1":"code","22dd711c":"code","6a9868b2":"code","5d9a83fc":"code","90bd45d7":"code","22bab8b3":"code","d810b249":"code","34fddf0a":"code","fdbcd369":"code","1ce8b74b":"markdown","a0c4c0f4":"markdown","64e83836":"markdown","ef36367e":"markdown","f7721294":"markdown","5cd8fb9b":"markdown","72fb262b":"markdown","9acd516f":"markdown"},"source":{"2ff5e558":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.keras import utils\nimport os\ntf.logging.set_verbosity(tf.logging.INFO)\n\nprint(os.listdir(\"..\/input\/\"))\n\n% matplotlib inline\n","e07c43a1":"ls ..\/input\/signsv2\/signs\/SIGNS","4b4059c0":"train_dir='..\/input\/signsv2\/signs\/SIGNS\/train_signs'\ndev_dir='..\/input\/signsv2\/signs\/SIGNS\/dev_signs'\ntest_dir='..\/input\/signsv2\/signs\/SIGNS\/test_signs'","e61a30bd":"def load_imgs(image_dir):\n    \"\"\"Load images from multiple folders\"\"\"\n    sub_dirs = [os.path.join(image_dir, item)\n                for item in gfile.ListDirectory(image_dir)]\n\n    sub_dirs = sorted(item for item in sub_dirs\n                    if gfile.IsDirectory(item))\n\n    # load images from multiple folders\n    imgs = []\n    labels=[]\n    for folder in sub_dirs:\n        names = os.listdir(folder)\n        filenames = [os.path.join(folder, f) for f in names if f.endswith('.jpg')]\n        labels.append([int(filename.split('\/')[-1][0]) for filename in filenames])\n        for file in filenames:\n            im = plt.imread(file)\n            imgs.append(im)\n    \n    # Preprocessing\n    imgs = np.asarray(imgs).astype(np.float32, casting='safe')\n    imgs \/=255.0\n    \n    # labels\n    labels=np.hstack(labels)\n    \n    \n    return imgs, labels","61800b27":"train_data,y_train=load_imgs(train_dir)\ndev_data,y_dev=load_imgs(dev_dir)\ntest_data,y_test=load_imgs(test_dir)\n\nprint(\"Train shape: \", train_data.shape)\nprint(\"Dev shape: \", dev_data.shape)\nprint(\"Test shape: \", test_data.shape)","1b4734f1":"plt.imshow(test_data[0,:,:,:])","22dd711c":"def MobileNet_V2(features,labels, mode):\n    \"\"\"Transfer learning with MobileNetV2 as ConvBase  \n    Args:\n    features: feature vector of size [batch, last layer size]\n    labels: labels or categories \n    lr: learning rate\n    mode: 'infer', 'eval', 'train'\n    \"\"\"\n    # Preatrained model MobileNetV2\n    model=hub.Module('https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_140_224\/feature_vector\/2')\n    \n    # Feature Vector\n    outputs=model(features['x'])\n    \n    # Logits\n    logits= tf.layers.dense(inputs=outputs, units=6)\n    \n    # Predictions\n    predictions={\n    'classes':tf.argmax(logits,axis=1),\n    'probabilities':tf.nn.softmax(logits, name=\"softmax_tensor\")}\n    \n    # Predict Mode\n    if mode==tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n    \n    # loss function \n    loss=tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)\n    \n    # Train Mode\n    if mode==tf.estimator.ModeKeys.TRAIN:\n        optimizer=tf.train.AdamOptimizer(learning_rate=0.01)\n        train_op=optimizer.minimize(\n            loss=loss,\n            global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode,loss=loss,train_op=train_op)\n    \n    # Evaluation metrics\n    eval_metric_ops={\n        \"accuracy\":tf.metrics.accuracy(labels=labels,predictions=predictions['classes'])\n    }\n    return tf.estimator.EstimatorSpec(mode=mode,loss=loss, eval_metric_ops=eval_metric_ops)\n    ","6a9868b2":"# Create Estimator\nclassifier= tf.estimator.Estimator(model_fn=MobileNet_V2)\n\n# log the values in the softmax tensor with labels probabilities \ntensor_to_log={'probabilities':'softmax_tensor'}\n# Print every N iterations \nlogging_hook=tf.train.LoggingTensorHook(tensors=tensor_to_log, every_n_iter=50)\n","5d9a83fc":"with tf.Graph().as_default() as g:\n    # Input function\n    train_input_fn=tf.estimator.inputs.numpy_input_fn(x={'x':train_data},y=y_train, shuffle=True)\n    for epoch in range(10):\n    # Train\n        classifier.train(input_fn=train_input_fn, hooks=[logging_hook], steps=50000)\n    \n    # Evaluate model\n    eval_input_fn=tf.estimator.inputs.numpy_input_fn(x={'x':dev_data}, y=y_dev,shuffle=False)\n    \n    # Evaluate\n    eval_results=classifier.evaluate(input_fn=eval_input_fn)\n    print(eval_results)","90bd45d7":"def serving_input_receiver_fn():\n    inputs={\n        'x':tf.placeholder(tf.float32, [None,224,224,3]), \n    }\n    return tf.estimator.export.ServingInputReceiver(inputs,inputs)","22bab8b3":"classifier.export_savedmodel('model',serving_input_receiver_fn=serving_input_receiver_fn)","d810b249":"predict_fn=tf.contrib.predictor.from_estimator(classifier,serving_input_receiver_fn=serving_input_receiver_fn)","34fddf0a":"# Predict image from the first example\ny_pred=predict_fn({'x':np.expand_dims(test_data[0,:,:,:],axis=0)})","fdbcd369":"class_predicted=np.argmax(y_pred['probabilities'])\nprint(\"The class predicted was: \", class_predicted)","1ce8b74b":"## Transfer learning model","a0c4c0f4":"### Training the model ","64e83836":"## Model MobileNetV2 ","ef36367e":"### Estimator ","f7721294":"### Predict","5cd8fb9b":"### Save model ","72fb262b":"# Classifier of Hand Signs","9acd516f":"## Data preprocessing "}}