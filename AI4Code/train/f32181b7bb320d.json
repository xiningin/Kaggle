{"cell_type":{"a8b35748":"code","36ce6f99":"code","afeb2332":"code","ebbe5666":"code","eaf08006":"code","e84a77e9":"code","1f3c066c":"code","271eb8f6":"code","9818f066":"code","596ed102":"code","d5df4d22":"code","3519938a":"code","e30c28d4":"code","fdc4f7aa":"code","6d9a60c6":"code","10481dce":"code","d47d4255":"code","6ecf7976":"markdown","c2633448":"markdown","1e1ef6bb":"markdown","9cfb0fce":"markdown","201d0121":"markdown"},"source":{"a8b35748":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36ce6f99":"import pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('dark_background')\nimport seaborn as sns","afeb2332":"df = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head()","ebbe5666":"df.shape","eaf08006":"plt.figure(figsize = (12,6))\nsns.countplot(df['quality'])\nplt.show()","e84a77e9":"plt.figure(figsize = (12,6))\nsns.barplot(x='quality', y = 'alcohol', data = df, palette = 'inferno')\nplt.show()","1f3c066c":"plt.figure(figsize = (12,6))\nsns.scatterplot(x='citric acid', y = 'pH', data = df)\nplt.show()","271eb8f6":"plt.figure(figsize = (12,6))\nsns.pairplot(df)\nplt.show()","9818f066":"plt.figure(figsize = (12,6))\nsns.heatmap(df.corr())\nplt.show()","596ed102":"x=df.drop(['quality'], axis=1)\ny=df['quality']","d5df4d22":"## oversampling\nfrom imblearn.over_sampling import SMOTE\nos=SMOTE()\nx_res,y_res=os.fit_sample(x, y)","3519938a":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_res,y_res,test_size=0.2, random_state=0)","e30c28d4":"from sklearn.preprocessing import StandardScaler\n\nstdscale = StandardScaler().fit(x_train)\nx_train_std = stdscale.transform(x_train)\nx_test_std = stdscale.transform(x_test)","fdc4f7aa":"from sklearn.metrics import accuracy_score","6d9a60c6":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train_std, y_train)\npredictions = lr.predict(x_test_std)\naccuracy_score(y_test, predictions)","10481dce":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train_std, y_train)\naccuracy_score(y_test, dt.predict(x_test_std))","d47d4255":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state = 42)\nrf.fit(x_train_std, y_train)\naccuracy_score(y_test, rf.predict(x_test_std))","6ecf7976":"# # Data Preprocessing","c2633448":"# # Data Analysation and Visualisation","1e1ef6bb":"# # Random Forest Classifier","9cfb0fce":"# # Decision Tree Classifier","201d0121":"# # Logistic Regression"}}