{"cell_type":{"139d774d":"code","a0f2ae61":"code","c380afca":"code","0eb16d0b":"code","01b53b12":"code","0b2d29ef":"code","4a4fe24e":"code","dc716509":"code","47d36bc2":"code","3042551f":"code","4aef4661":"code","802e4693":"code","cd7fdf0a":"code","cdd02fa3":"code","e06d5532":"code","cd36a22c":"code","d05c260f":"code","967c943f":"code","f3d1a24a":"code","9779049c":"code","612baf01":"code","2286d364":"code","145787d8":"code","308eea38":"code","4ed6d819":"markdown","505966bc":"markdown","1e76ec78":"markdown","fd457690":"markdown","93d3339f":"markdown","f68d1f50":"markdown","ea82227a":"markdown","39097e57":"markdown","04972f45":"markdown","f5166902":"markdown","30366654":"markdown","e128eb9f":"markdown","c374634f":"markdown","08778246":"markdown","7342b81c":"markdown","2483e564":"markdown","ed7fcaa5":"markdown","5ea90fff":"markdown","08476654":"markdown","a2170bb4":"markdown","681dbbaf":"markdown","8816ae9b":"markdown","9d2cc274":"markdown","56b40074":"markdown","aa5bc52a":"markdown","91c6c79a":"markdown","96bc6be2":"markdown","7fb159c2":"markdown","3ac1bd84":"markdown"},"source":{"139d774d":"import matplotlib.pyplot as plt\n\nimport numpy as np\nimport struct\nimport pandas as pd\nimport os\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils","a0f2ae61":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# Noise shape for generator\nNOISE_SHAPE = 128\nBATCH_SIZE = 60\n# Image size and number of channels\nH, W, C = (28, 28, 1)\n\n# Its better then a number of images in dataset will be divided by batch size without remainder\n# So, algorithm below will print this numbers\n# By default batch size equal to 60 is okey\n\"\"\"\nfor i in range(3, 100):\n    if 60_000 % i == 0:\n        print(i)\n\"\"\"\n","c380afca":"df = pd.read_csv('..\/input\/mnist-in-csv\/mnist_train.csv')\n# Create np array from csv\ndf_as_np = np.asarray(df)\n# Wrap images and labels\nlabels_mnist, data = (\n    df_as_np[:, 0],                      # First row - labels\n    df_as_np[:, 1:].reshape(-1, H, W, C) # Other rows - images\n)","0eb16d0b":"# Define class with super-class Dataset\n# We must implement two methods: getitem__ and __len__, \n#     __getitem__ - gives possibility to apply indexing for the instance of class FashionDataset\n#     __len__ - gives possibility to take size of overall dataset\n# This methods need in order to use DataLoader\nclass FashionDataset(Dataset):\n\n    def __init__(self, data, transform = None, H = 28, W = 28, C = 1):\n        self._images = np.asarray(data, dtype=np.float32).reshape(-1, H, W, C)\n        self._transform = transform\n\n    def __getitem__(self, index):\n        image = self._images[index]\n        if self._transform is not None:\n            image = self._transform(image)\n        return image\n    \n    def __len__(self):\n        return len(self._images)\n\n# Create instaince of data loader in order to load and create batches of data\n# Also we can specify number of workers in loader which can speed up process of \n# preparing data. We leave it as it is, with default value.\n# For more info refer to original docs.\ntrain_set = FashionDataset(\n    data, transform=transforms.Compose(\n        # Transform data into Tensor that has values in a range from -1 to 1\n        [transforms.ToTensor(), transforms.Normalize(128, 128)]\n    ),\n    H=H, W=W, C=C\n)\n# Create data loader\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)","01b53b12":"# Test loader\nbatch_d = next(iter(train_loader))\ngrid = torchvision.utils.make_grid(batch_d, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)).numpy().astype(np.uint8))","0b2d29ef":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","4a4fe24e":"class GeneratorNN(nn.Module):\n\n    def __init__(self):\n        super(GeneratorNN, self).__init__()\n        \n        self._model = nn.Sequential(\n            nn.Linear(NOISE_SHAPE, 256),\n            nn.BatchNorm1d(256, momentum=0.8, track_running_stats=False),\n            nn.ReLU(inplace=False),\n\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512, momentum=0.8, track_running_stats=False),\n            nn.ReLU(inplace=False),\n\n            nn.Linear(512, 1024),\n            nn.BatchNorm1d(1024, momentum=0.8, track_running_stats=False),\n            nn.ReLU(inplace=False),\n            \n            nn.Linear(1024, 2048),\n            nn.BatchNorm1d(2048, momentum=0.8, track_running_stats=False),\n            nn.ReLU(inplace=False),\n            \n            nn.Linear(2048, H * W * C),\n            nn.Tanh()\n        )\n    \n    def forward(self, x):\n        x = self._model(x)\n        x = x.view(-1, C, H, W)\n        return x","dc716509":"# Generator\ngen_nn = GeneratorNN()\ngen_nn.to(device=device)\n# Init weights of the model with certain initialization\ngen_nn.apply(weights_init)\n# Turn on training mode\ngen_nn.train()","47d36bc2":"# Check generator\narr = np.random.randn(BATCH_SIZE, NOISE_SHAPE).astype(np.float32)\nres = gen_nn(torch.tensor(arr).to(device=device))\nprint(res.shape)\nplt.imshow( ((res + 1.0) \/ 2.0)[0].cpu().detach().numpy().transpose(1, 2, 0)[..., 0])","3042551f":"class DiscriminatorNN(nn.Module):\n\n    def __init__(self):\n        super(DiscriminatorNN, self).__init__()\n\n        self._net = nn.Sequential(\n            nn.Linear(H * W * C, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Linear(1024, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Linear(512, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Dropout(p=0.2),\n            nn.Linear(512, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Dropout(p=0.3),\n            nn.Linear(512, 1),\n            nn.Sigmoid(),\n        )\n    \n    def forward(self, x):\n        b = x.shape[0]\n        return self._net(x.view(b, -1))","4aef4661":"# Discriminator\ndisc_nn = DiscriminatorNN()\ndisc_nn.to(device=device)\n# Init weights of the model with certain initialization\ndisc_nn.apply(weights_init)\n# Turn on training mode\ndisc_nn.train()","802e4693":"# Check discriminator on noise data\narr = np.random.randn(BATCH_SIZE, C, H, W).astype(np.float32)\nprint(arr.shape)\nres = disc_nn(torch.tensor(arr, device=device))\nres.cpu().detach().numpy()[:5]","cd7fdf0a":"# Check discriminator on real data from loaded test batch above\nprint(batch_d.shape)\nres = disc_nn(torch.tensor(batch_d, device=device))\nres.cpu().detach().numpy()[:5]","cdd02fa3":"class TrainGANController:\n    \n    def __init__(self, disc_nn, gen_nn, batch_size, device = None):\n        self._disc_nn = disc_nn\n        self._gen_nn = gen_nn\n        self._batch_size = batch_size\n\n        self._is_compiled = False\n        self._opt_disc = None\n        self._opt_gen = None\n        self._loss = None\n        self._device = device\n    \n    def compile(\n            self, \n            lr_disc=2e-4, lr_gen=3e-4, \n            beta_params_disc=(0.5, 0.999), beta_params_gen=(0.5, 0.999)):\n        # Init opt\n        self._opt_disc = torch.optim.Adam(\n            self._disc_nn.parameters(), lr=lr_disc, betas=beta_params_disc\n        )\n        self._opt_gen = torch.optim.Adam(\n            self._gen_nn.parameters(), lr=lr_gen, betas=beta_params_gen\n        )\n        # Losses\n        self._loss = nn.BCELoss().to(device=self._device)\n        # Set flag, in order to start train\n        self._is_compiled = True\n    \n    def train_step_disc(self, real_data, real_label=0.9, fake_label=0.0):\n        # Set real label equal to 0.9 in order to use \"Label smoothing\"\n        # Discriminator can produce better gradients, then this technique is used\n        # For more detail\u044b about label smoothing you can find in the internet \n        \n        # For easy access\n        device = self._device\n        # Train step for discriminator\n        # Zero grads\n        self._disc_nn.zero_grad()\n        # Forward pass for real data\n        label = torch.full((self._batch_size,), real_label, dtype=torch.float, device=device)\n        fake = torch.full((self._batch_size,), fake_label, dtype=torch.float, device=device)\n        # Generate fake stuf\n        noise = torch.randn(self._batch_size, NOISE_SHAPE, device=device)\n        generated_imgs = self._gen_nn(noise)\n        # Forward pass real batch through D\n        errD_real = self._loss(self._disc_nn(real_data).view(-1), label)\n        # Forward pass fake batch through D\n        errD_fake = self._loss(self._disc_nn(generated_imgs.detach()).view(-1), fake)\n        errD = (errD_fake + errD_real) \/ 2.0\n        errD.backward()\n        self._opt_disc.step()\n        return errD.cpu().detach().numpy()\n\n    def train_step_gen(self, fake_label=1.0):\n        # For easy access\n        device = self._device\n        # Train step for generator\n        # Zero grads\n        self._gen_nn.zero_grad()\n        # fake labels are real for generator cost\n        label = torch.full((self._batch_size,), fake_label, dtype=torch.float, device=device)\n        # Since we just updated D, perform another forward pass of all-fake batch through D\n        # Generate batch of latent vectors\n        noise = torch.randn(self._batch_size, NOISE_SHAPE, device=device)\n        # Generate fake image batch with G\n        generated_imgs = self._gen_nn(noise)\n        # Calculate G's loss based on this output\n        errG = self._loss(self._disc_nn(generated_imgs).view(-1), label)\n        # Calculate gradients for G\n        errG.backward()\n        # Update G\n        self._opt_gen.step()\n        return errG.cpu().detach().numpy()\n\n    def fit(self, data_gen, epoch: int, print_it: int = 400):\n        for i_e in range(epoch):\n            for ii_it, single_data in enumerate(data_gen):\n                single_data = single_data.to(device=self._device)\n                # Train discriminator\n                err_d = self.train_step_disc(single_data)\n                # Train generator\n                err_g = self.train_step_gen()\n                if ii_it % print_it == 0:\n                    print(f'epoch: {i_e+1}\/{epoch}, it: {ii_it}\/{len(data_gen)}'\n                          f'|| Loss G: {err_g}, Loss D: {err_d}'\n                    )","e06d5532":"t_gan_c = TrainGANController(disc_nn, gen_nn, BATCH_SIZE, device=device)\nt_gan_c.compile()","cd36a22c":"t_gan_c.fit(train_loader, epoch=25)","d05c260f":"def visualise_sheets_of_images(\n    images, prefix_name, unique_index=0,\n    show_images=False, subplot_size=(10, 10),\n    figsize=(20, 20),use_BGR2RGB=False, use_grey=False):\n    \"\"\"\n    Plot sheets of images. Usually used for generated images from GANs.\n    Parameters\n    ----------\n    images : list or np.ndarray\n        List of images that should be plotted.\n    prefix_name : str\n        Prefix name for file with sheets of images.\n    unique_index : int\n        Unique number for name of file which consist of sheets of images,\n        usually this params used for showing at which epoch this result is.\n    show_images : bool\n        If true, sheets of images will be plotted.\n    subplot_size : tuple\n        Size of raw and columns. For more detail, see plt docs.\n    figsize : tuple\n        Size of figure. For more detail, see plt docs.\n    use_BGR2RGB : bool\n        If true, `images` will be converted into RGB format (if they have BGR format).\n    use_grey : bool\n        If true, `images` will be plotted as black-white images.\n    \n    \"\"\"\n    plt.figure(figsize=figsize)\n    for z in range(min(len(images), subplot_size[0] * subplot_size[1])):\n        plt.subplot(*subplot_size, z + 1)\n        if use_BGR2RGB:\n            plt.imshow(cv2.cvtColor(images[z], cv2.COLOR_BGR2RGB))\n        elif use_grey:\n            plt.imshow(images[z], cmap='gray')\n        else:\n            plt.imshow(images[z])\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.savefig(f'{prefix_name}_{unique_index}.png')\n    if show_images:\n        plt.show()\n\n    plt.close('all')","967c943f":"# Check generator\narr = np.random.randn(BATCH_SIZE, NOISE_SHAPE).astype(np.float32)\ngen_nn.eval()\nres = gen_nn(torch.tensor(arr).to(device=device))\n# Unnormed images and plot big figure\nres = ((res + 1.0) \/ 2.0).cpu().detach().numpy().transpose(0, 2, 3, 1)\nvisualise_sheets_of_images(res, \"generated_digits\", show_images=True, use_grey=True)","f3d1a24a":"from scipy.linalg import sqrtm\nfrom sklearn.utils import shuffle\nimport cv2\nfrom tqdm import tqdm\nfrom torchvision.models import inception_v3\n\n# Number of images taken and generated\n# In order to estimate generator with FID metric\nN_IMAGES = 10_000","9779049c":"def scale_images(images, new_shape):\n    \"\"\"\n    Scale an array of images to a new size\n    \n    Parameters\n    ----------\n    images : list\n        List of images. Each image have shape - (C, H_old, W_old)\n        Where:\n            C - color dimension of the image;\n            H_old - height of the image;\n            W_old - width of the image.\n    new_shape : list or tuple\n        (H, W), Height and Width of the result image\n    \n    Return\n    ------\n    list\n        List of images with shape equal to `new_shape`\n    \n    \"\"\"\n    images_list = list()\n    for image in images:\n        # resize with nearest neighbor interpolation\n        new_image = np.transpose(image, (1, 2, 0)) # (C, H, W) --> (H, W, C)\n        new_image = cv2.resize(new_image, new_shape, interpolation = cv2.INTER_NEAREST)\n        if len(new_image.shape) == 2 or new_image.shape[-1] == 1:\n            new_image = cv2.cvtColor(new_image, cv2.COLOR_GRAY2BGR)\n        new_image = np.transpose(new_image, (2, 0, 1)) # (H, W, C) --> (C, H, W)\n        # store\n        images_list.append(new_image)\n    return np.asarray(images_list)","612baf01":"def calculate_fid_batched(model_inception, images1, images2, batch_size=128):\n    assert len(images1) == len(images2)\n    n_batches = len(images1) \/\/ batch_size\n    preds1 = []\n    preds2 = []\n    for i in tqdm(range(n_batches)):\n        batch_img1 = images1[i*batch_size: (i+1)*batch_size]\n        batch_img2 = images2[i*batch_size: (i+1)*batch_size]\n        # Resize images\n        resized_b_img1 = scale_images(batch_img1, (299, 299))\n        resized_b_img2 = scale_images(batch_img2, (299, 299))\n        # Normalize images\n        resized_b_img1 -= np.array([0.485, 0.456, 0.406]).reshape(1, -1, 1, 1)\n        resized_b_img1 \/= np.array([0.229, 0.224, 0.225]).reshape(1, -1, 1, 1)\n        # Run though inception v3 and take prediction\n        act1 = model_inception(torch.tensor(resized_b_img1, device=device)).squeeze().cpu().detach().numpy()\n        act2 = model_inception(torch.tensor(resized_b_img2, device=device)).squeeze().cpu().detach().numpy()\n        preds1.append(act1)\n        preds2.append(act2)\n    act1 = np.concatenate(preds1, axis=0)\n    act2 = np.concatenate(preds2, axis=0)\n    \n    return act1, act2","2286d364":"def calculate_fid(act1, act2):\n    # calculate mean and covariance statistics\n    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n    # calculate sum squared difference between means\n    ssdiff = np.sum((mu1 - mu2)**2.0)\n    # calculate sqrt of product between cov\n    covmean = sqrtm(sigma1.dot(sigma2))\n    # check and correct imaginary numbers from sqrt\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n    # calculate score\n    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n    return fid","145787d8":"# prepare the inception v3 model\nmodel = inception_v3(pretrained=True)\nmodel.eval()\n# Remove certain layers from output\nlayer_names = []\nfor layer in list(model.children()):\n    if layer.__class__.__name__ not in ['InceptionAux', 'Linear', 'Dropout']:\n        layer_names.append(layer)\n# Create model without some layers\nmodel = nn.Sequential(*layer_names)\nmodel.eval()\nmodel.to(device=device)\n# Define two batches of images\n# First - real data\nimages1 = shuffle(data)[:N_IMAGES]\nimages1 = np.transpose(np.asarray(images1), (0, 3, 1, 2)).astype(np.float32)\n# Images1 in range [0, 255], normalize into [0, 1]\nimages1 \/= 255.0\nimages1 = torch.tensor(images1, device=device).cpu().detach().numpy()\n\nimages2_noise = torch.tensor(\n    np.random.randn(N_IMAGES, NOISE_SHAPE).astype(np.float32),\n    device=device\n)\ngen_nn.eval()\nimages2 = gen_nn(images2_noise).cpu().detach().numpy()\n# Generator generate images in range (-1, 1), normalize into [0, 1] range\nimages2 += 1.0\nimages2 \/= 2.0\nprint('Prepared', images1.shape, images2.shape)\n# Calculate FID with batch size\n# fid between images1 and images1\nact1, act2 = calculate_fid_batched(model, images1, images2)\nfid_same = calculate_fid(act1, act1)\nfid = calculate_fid(act1, act2)\n\n\nprint('FID (same): %.3f' % fid_same)\n# fid between images1 and images2\nprint('FID (different): %.3f' % fid)","308eea38":"torch.save(gen_nn.state_dict(), 'model.pth')","4ed6d819":"# Import libraries what we will use in this notebook","505966bc":"## Define Generator model","1e76ec78":"# Define image generator","fd457690":"## Start training","93d3339f":"<h1><a href=\"model.pth\"> Download trained generator <\/a><\/h1>","f68d1f50":"### Define some useful methods","ea82227a":"### We will map data into numpy array for better usage","39097e57":"In order to download final model - click link below.","04972f45":"# Training","f5166902":"### Create instance of discriminator model and test it with noise","30366654":"## Import libraries and define constants","e128eb9f":"## Define Discriminator model","c374634f":"#### Load InceptionV3 and calculate FID","08778246":"#### Collect predictions from InceptionV3\nCollect data using certain batch size in order to save memory","7342b81c":"### Create instance of generator model and test it with noise","2483e564":"# Calculate accuracy with FID metric","ed7fcaa5":"# Read data from CSV file","5ea90fff":"# Generate digits with trained model","08476654":"### Define class which control training of GAN. \n### Main method: `fit` function which start training of a GAN","a2170bb4":"# Define Models","681dbbaf":"### Create instance and compile controller","8816ae9b":"#### Scale list of images into certain shape","9d2cc274":"## Test train loader. Print batch of images","56b40074":"### Define class for DataLoader in order to create image generator","aa5bc52a":"# Save model","91c6c79a":"# Define global constants","96bc6be2":"### Define some utils for layers\/models","7fb159c2":"## In this notebook:\n- Training of the Vanilla GAN, for more details refer to paper: https:\/\/arxiv.org\/abs\/1406.2661\n- FID Metric. Calculate how good final generator with FID metric, for more details refer to paper: https:\/\/arxiv.org\/abs\/1706.08500","3ac1bd84":"#### Calculate FID with predictions from InceptioV3"}}