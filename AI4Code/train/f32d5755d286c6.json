{"cell_type":{"7ee8e0e9":"code","7fc184f4":"code","421261dc":"code","b28e438f":"code","027472bf":"code","6d56bc7c":"code","c722e7b7":"code","67f3ac04":"code","69910db6":"code","7a869de3":"code","e00c625a":"code","64571e4d":"code","b10c78a0":"code","67fdc18b":"code","56cc663b":"code","ec8ca128":"code","343f4fd1":"code","b11e0e10":"code","b32d18fd":"code","be7876c0":"code","b35398fc":"code","3aacedc1":"markdown","4483678e":"markdown","9ccf6b57":"markdown","fc8d1e0e":"markdown","cdd46344":"markdown","48f2c3e3":"markdown","f430a2a5":"markdown","1dfc13e1":"markdown","6cf21220":"markdown","b9b4f1e1":"markdown","3fa4032b":"markdown"},"source":{"7ee8e0e9":"import numpy as np\nimport pandas as pd \nimport plotly.express as px\nimport matplotlib.pyplot as plt\n","7fc184f4":"df = pd.read_csv('..\/input\/covid19-tweets\/covid19_tweets.csv')","421261dc":"df.head()","b28e438f":"df.info()","027472bf":"missed = round(df.isnull().sum() * 100\/ len(df), 2).sort_values()\nmissed = missed[missed > 0]\n\nmissed_df = pd.DataFrame()\nmissed_df['feature_name'] = missed.index\nmissed_df['precent'] = missed.values\n\nfig = px.bar(missed_df, \n             x=missed_df['precent'], \n             y=missed_df['feature_name'],\n             height=400, width=600,\n            title='Missed values percent for every column (percent > 0)'\n            )\n\n\nfig.show()","6d56bc7c":"ds = df['user_name'].value_counts().reset_index()\nds.columns = ['user_name', 'tweets_count']\nds = ds.sort_values(['tweets_count'])\n\nfig = px.bar(\n    ds.tail(30), \n    x='tweets_count', \n    y='user_name',\n    width=800, \n    height=800,\n    title='Top 30 users by number of tweets'\n    )\n\nfig.show()","c722e7b7":"df = pd.merge(df, ds, on='user_name', how='inner')","67f3ac04":"data = df.sort_values('user_followers', ascending=False)\ndata = data.drop_duplicates(subset='user_name', keep=\"first\")\ndata = data[['user_name', 'user_followers', 'tweets_count']]\ndata = data.sort_values('user_followers')\n\nfig = px.bar(\n    data.tail(40), \n    x='user_followers',\n    y='user_name', \n    color='tweets_count',\n    title='Top 40 users by number of followers', \n    width=800, \n    height=800\n)\nfig.show()","69910db6":"pd.to_datetime(df['user_created'])","7a869de3":"df['year_created'] = pd.to_datetime(df['user_created']).dt.year\ndata = df.drop_duplicates(subset='user_name', keep=\"first\")\ndata = data[data['year_created']>2006]\ndata = data['year_created'].value_counts().reset_index()\ndata.columns = ['year', 'number']\n\nfig = px.bar(\n    data, \n    x=\"year\", \n    y=\"number\", \n    orientation='v', \n    title='User created year by year', \n    width=800, \n    height=600\n)\n\nfig.show()","e00c625a":"ds = df['user_location'].value_counts().reset_index()\nds.columns = ['user_location', 'count']\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds.tail(40), \n    x=\"count\", \n    y=\"user_location\", \n    orientation='h', title='Top 40 user locations by number of tweets', \n    width=800, \n    height=800\n)\n\nfig.show()","64571e4d":"ds = df['source'].value_counts().reset_index()\nds.columns = ['source', 'count']\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds.tail(40), \n    x=\"count\", \n    y=\"source\", \n    orientation='h', \n    title='Top 40 user sources by number of tweets', \n    width=800, \n    height=800\n)\n\nfig.show()","b10c78a0":"df['date'] = pd.to_datetime(df['date']) \ndf = df.sort_values(['date'])\ndf['day'] = df['date'].astype(str).str.split(' ', expand=True)[0]\ndf['time'] = df['date'].astype(str).str.split(' ', expand=True)[1]\ndf.head()","67fdc18b":"ds = df['day'].value_counts().reset_index()\nds.columns = ['day', 'count']\nds = ds.sort_values('count')\nds['day'] = ds['day'].astype(str) + ':00:00:00'\n\nfig = px.bar(\n    ds, \n    x='count', \n    y=\"day\", \n    orientation='h',\n    title='Tweets distribution over days present in dataset', \n    width=800, \n    height=800\n)\nfig.show()","56cc663b":"df['hour'] = df['date'].dt.hour\nds = df['hour'].value_counts().reset_index()\nds.columns = ['hour', 'count']\nds['hour'] = 'Hour ' + ds['hour'].astype(str)\nfig = px.bar(\n    ds, \n    x=\"hour\", \n    y=\"count\", \n    orientation='v', \n    title='Tweets distribution over hours', \n    width=800\n)\nfig.show()","ec8ca128":"df['hashtags'] = df['hashtags'].fillna('[]')\ndf['hashtags_count'] = df['hashtags'].apply(lambda x: len(x.split(',')))\ndf.loc[df['hashtags'] == '[]', 'hashtags_count'] = 0\n\ndf.head(10)","343f4fd1":"df['hashtags_count'].describe()","b11e0e10":"df['tweet_length'] = df['text'].str.len()\n\nfig = px.histogram(\n    df, \n    x=\"tweet_length\", \n    nbins=80, \n    title='Tweet length distribution', \n    width=800,\n    height=700\n)\nfig.show()","b32d18fd":"def build_wordcloud(df, title):\n    wordcloud = WordCloud(\n        background_color='gray', \n        stopwords=set(STOPWORDS), \n        max_words=50, \n        max_font_size=40, \n        random_state=666\n    ).generate(str(df))\n\n    fig = plt.figure(1, figsize=(14,14))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=16)\n    fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n    \n    build_wordcloud(df['text'], 'Prevalent words in tweets for all dataset')","be7876c0":"vec = TfidfVectorizer(stop_words=\"english\")\nvec.fit(df['text'].values)\nfeatures = vec.transform(df['text'].values)","b35398fc":"features","3aacedc1":"Now we are going to check how many tweets were for every day in our dataset.","4483678e":"Let's see top 40 most popular locations by the number of tweets.","9ccf6b57":"Just split day and time into separate columns.","fc8d1e0e":"Now we are going to calculate the length for every tweet in dataset.","cdd46344":"Let's see most popular users.","48f2c3e3":"Lets create new feature - hashtags_count that will show us how many hashtags in the current tweet.","f430a2a5":"Lets do the same but for hours.","1dfc13e1":"Let's see how coronavirus affect to new users creation.","6cf21220":"And most friendly users.","b9b4f1e1":"Lets see general wordcloud for this column.","3fa4032b":"Now it's time to check last one categorical feature - source. Lets see top 40 sources by the number of tweets."}}