{"cell_type":{"902c85c5":"code","0ee2ad45":"code","ab85db27":"code","ab82d788":"code","7dcb3827":"code","7da0faea":"code","a21d1a30":"code","4628a9ab":"code","399b16d6":"code","cb50cd2d":"code","54e122c2":"code","2e3f43d1":"markdown","092b7083":"markdown","6a716bbb":"markdown","4d60b197":"markdown","42a533a1":"markdown"},"source":{"902c85c5":"import os\nimport time\n\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nfrom torch.autograd import Variable\nfrom torchvision import datasets, models, transforms\n\n%matplotlib inline","0ee2ad45":"data_dir = \"..\/input\/cat-and-dog\"\ndata_str = [\"test_set\", \"training_set\"]\ndata_transform = transforms.Compose([transforms.Resize([64, 64]), transforms.ToTensor()])\nimg_datasets = {\n    x: datasets.ImageFolder(root=data_dir+'\/{}\/{}'.format(x,x), transform=data_transform)\n    for x in data_str\n}\ndataloader = {\n    x: torch.utils.data.DataLoader(dataset=img_datasets[x], batch_size=16, shuffle=True)\n    for x in data_str\n}","ab85db27":"X_example, y_example = next(iter(dataloader[\"training_set\"]))\n\nprint(\"X_example's number:{}\".format(len(X_example)))\nprint(\"y_example's number:{}\".format(len(y_example)))\nindex_classes = img_datasets[\"training_set\"].class_to_idx\nprint(index_classes)\nexample_classes = img_datasets[\"training_set\"].classes\nprint(example_classes)","ab82d788":"img = torchvision.utils.make_grid(X_example)\nimg = img.numpy().transpose([1, 2, 0])\nprint([example_classes[i] for i in y_example])\nplt.imshow(img)\nplt.show()  #visualization ","7dcb3827":"model = models.vgg16(pretrained=True)\nfor parma in model.parameters():\n    parma.requires_grad = False\nmodel.classifier = torch.nn.Sequential(\n    torch.nn.Linear(in_features=25088, out_features=1024 * 4, bias=True),\n    torch.nn.ReLU(inplace=True),\n    torch.nn.Dropout(p=0.5, inplace=False),\n    torch.nn.Linear(in_features=1024 * 4, out_features=1024 * 4, bias=True),\n    torch.nn.ReLU(inplace=True),\n    torch.nn.Dropout(p=0.5, inplace=False),\n    torch.nn.Linear(in_features=1024 * 4, out_features=2, bias=True),\n)\nmodel = model.cuda()\nlf = torch.nn.CrossEntropyLoss()\nop = torch.optim.Adam(model.classifier.parameters(), lr=1e-5)\nprint(model)","7da0faea":"epoch_n = 5\ntime_open = time.time()\n\nfor epoch in range(epoch_n):\n    print('Epoch {}\/{}'.format(epoch+1,epoch_n))\n    print('-----------')\n\n    for phase in data_str:\n        if phase == 'training_set':\n            print('Training...')\n            model.train(True)\n        else:\n            print('Validing...')\n            model.train(False)\n        running_loss = 0.0\n        running_correct = 0\n\n        for batch,data in enumerate(dataloader[phase],1):\n            X,y = data\n            X,y = Variable(X.cuda()),Variable(y.cuda())\n            y_pred = model(X)\n\n            _,pred = torch.max(y_pred.data,1)\n\n            op.zero_grad()\n            loss = lf(y_pred,y)\n\n            if phase == 'training_set':\n                loss.backward()\n                op.step()\n\n            running_correct +=torch.sum(pred == y.data)\n            running_loss +=loss.data\n            if batch%500 ==0 and phase =='train':\n                print('Batch {},Train Loss:{:.4f},Train Acc:{:.4f}%'.format(\n                batch,running_loss\/batch,100*running_correct\/batch\/16))\n\n        epoch_loss = running_loss*16\/len(img_datasets[phase])\n        epoch_acc = running_correct*100\/len(img_datasets[phase])\n\n        print('{} Loss:{:.4f} Acc:{:.4f}%'.format(phase,epoch_loss,epoch_acc))\n\ntime_end = time.time() - time_open\nprint(time_end)","a21d1a30":"torch.save(model.state_dict(), 'model_params.pth')","4628a9ab":"print(\"Validing...\")\nmodel.train(False)\nrunning_loss = 0.0\nrunning_correct = 0\n\nfor batch, data in enumerate(dataloader[\"test_set\"], 1):\n    X, y = data\n    X, y = Variable(X.cuda()), Variable(y.cuda())\n    y_pred = model(X)\n\n    _, pred = torch.max(y_pred.data, 1)\n\n    op.zero_grad()\n    loss = lf(y_pred, y)\n\n    running_correct += torch.sum(pred == y.data)\n    running_loss += loss.data\n\nepoch_loss = running_loss * 16 \/ len(img_datasets[\"test_set\"])\nepoch_acc = running_correct * 100 \/ len(img_datasets[\"test_set\"])\n\nprint(\"{} Loss:{:.4f} Acc:{:.4f}%\".format(\"valid\", epoch_loss, epoch_acc))","399b16d6":"# model.load_state_dict(torch.load(\"model_params.pth\"))","cb50cd2d":"# print(\"Validing...\")\n# model.train(False)\n# running_loss = 0.0\n# running_correct = 0\n\n# for batch, data in enumerate(dataloader[\"test_set\"], 1):\n#     X, y = data\n#     X, y = Variable(X.cuda()), Variable(y.cuda())\n#     y_pred = model(X)\n\n#     _, pred = torch.max(y_pred.data, 1)\n\n#     op.zero_grad()\n#     loss = lf(y_pred, y)\n\n#     running_correct += torch.sum(pred == y.data)\n#     running_loss += loss.data\n\n# epoch_loss = running_loss * 16 \/ len(img_datasets[\"test_set\"])\n# epoch_acc = running_correct * 100 \/ len(img_datasets[\"test_set\"])\n\n# print(\"{} Loss:{:.4f} Acc:{:.4f}%\".format(\"valid\", epoch_loss, epoch_acc))","54e122c2":"dataloader_test = torch.utils.data.DataLoader(\n    dataset=img_datasets['test_set'], batch_size=4, shuffle=True\n)\nX_test, y_test = next(iter(dataloader_test))\ninputs = Variable(X_test)\ninputs = inputs.cuda()\npred = model(inputs)\n_, prd = torch.max(pred, 1)\nexample_classes1 = img_datasets['test_set'].classes\nprint(\"predicted\uff1a\", [example_classes1[i] for i in prd])\nprint(\"true\uff1a\", [example_classes1[i] for i in y_test])\nimg = torchvision.utils.make_grid(X_test)\nimg = img.numpy().transpose(1, 2, 0)\n\nplt.imshow(img)\nplt.show()","2e3f43d1":"use a pre_trained VGG16 network to do **transfer learing**\n\nfreeze all the paramters in model and adjust its dense layers in classifier","092b7083":"demo","6a716bbb":"save the model's paramters(you don't need to train it again)","4d60b197":"or use the parameters you saved before","42a533a1":"train the model"}}