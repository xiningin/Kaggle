{"cell_type":{"21b10707":"code","47d4baf7":"code","2d6ea706":"code","52a55874":"code","441de853":"code","de82fe9d":"code","d9eb8268":"code","46995c83":"code","393a9a7f":"code","9237109b":"code","43b43cce":"code","06983567":"code","945583a2":"code","9cfd2710":"code","455f58b9":"code","3bc647e6":"code","e4dfa36d":"code","f46a88fe":"code","74bdd0a4":"code","e1b30f7b":"code","a58c8052":"code","1b5bd45c":"code","df7b4dc3":"code","3a1b6e3a":"code","ec33352f":"markdown","e550869c":"markdown","f9f69890":"markdown","357a33d1":"markdown","e4b71eca":"markdown","710bc785":"markdown","7458f436":"markdown","802e7e70":"markdown","3ef20ad0":"markdown","b9674b6e":"markdown","adf2fe06":"markdown","d4402de2":"markdown","5a5828c5":"markdown","b0665fee":"markdown","0c95d754":"markdown","bc276d60":"markdown","cdd244eb":"markdown","824951b7":"markdown","3e4b8328":"markdown","fad926a8":"markdown","ecfdefa2":"markdown","025642c2":"markdown","4035f096":"markdown","3cac7853":"markdown","bc75bce1":"markdown","5ac5a98e":"markdown","56952b80":"markdown","0540bfe5":"markdown","2a646a03":"markdown","dd892586":"markdown","b46643a7":"markdown","6a6c90f4":"markdown","9761b9fb":"markdown","faaaf833":"markdown","b57333dd":"markdown","b4b4e7a7":"markdown","bca5237c":"markdown","f652c2fb":"markdown","54394bde":"markdown","2e821717":"markdown","fb7c634a":"markdown"},"source":{"21b10707":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\/\"))\n\n# Any results you write to the current directory are saved as output.","47d4baf7":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2","2d6ea706":"# Set Train and Test Directory Variables\nTRAIN_DATA_DIR = \"..\/input\/flower_data\/flower_data\/train\/\"\nVALID_DATA_DIR = \"..\/input\/flower_data\/flower_data\/valid\/\"","52a55874":"#Visualiza Some Images of any Random Directory-cum-Class\nFILE_DIR = str(np.random.randint(1,103))\nprint(\"Class Directory: \",FILE_DIR)\nfor file_name in os.listdir(os.path.join(TRAIN_DATA_DIR, FILE_DIR))[1:3]:\n    img_array = cv2.imread(os.path.join(TRAIN_DATA_DIR, FILE_DIR, file_name))\n    img_array = cv2.resize(img_array,(224, 224), interpolation = cv2.INTER_CUBIC)\n    plt.imshow(img_array)\n    plt.show()\n    print(img_array.shape)","441de853":"import torch\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\ntorch.__version__","de82fe9d":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","d9eb8268":"# I used os.listdir() to maintain the ordering \nclasses = os.listdir(VALID_DATA_DIR)","46995c83":"# Load and transform data using ImageFolder\n\n# VGG-16 Takes 224x224 images as input, so we resize all of them\ndata_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])])\n\ntrain_data = datasets.ImageFolder(TRAIN_DATA_DIR, transform=data_transform)\ntest_data = datasets.ImageFolder(VALID_DATA_DIR, transform=data_transform)\n\n# print out some data stats\nprint('Num training images: ', len(train_data))\nprint('Num test images: ', len(test_data))","393a9a7f":"# define dataloader parameters\nbatch_size = 32\nnum_workers=0\n\n# prepare data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n                                           num_workers=num_workers, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n                                          num_workers=num_workers, shuffle=True)","9237109b":"# Visualize some sample data\n\n# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(classes[labels[idx]])","43b43cce":"# Load the pretrained model from pytorch\nmodel = models.<ModelNameHere>(pretrained=True)  \nprint(model)","06983567":"print(model.classifier[6].in_features) \nprint(model.classifier[6].out_features)\n# The above lines work for vgg only. For other models refer to print(model) and look for last FC layer","945583a2":"# Freeze training for all \"features\" layers\nfor param in model.features.parameters():\n    param.requires_grad = False\n\n\n#For models like ResNet or Inception use the following,\n\n# Freeze training for all \"features\" layers\n#     for _, param in model.named_parameters():\n#         param.requires_grad = False","9cfd2710":"# VGG16  \nn_inputs = model.classifier[6].in_features\n\n#Others\n# n_inputs = model.fc.in_features\n\n# add last linear layer (n_inputs -> 102 flower classes)\n# new layers automatically have requires_grad = True\nlast_layer = nn.Linear(n_inputs, len(classes))\n\n# VGG16\nmodel.classifier[6] = last_layer\n\n# Others\n#model.fc = last_layer\n\n# if GPU is available, move the model to GPU\nif train_on_gpu:\n    model.cuda()\n\n# check to see that your last layer produces the expected number of outputs\n\n#VGG\nprint(model.classifier[6].out_features)\n#Others\n#print(model.fc.out_features)","455f58b9":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = #TODO\n\n# specify optimizer (stochastic gradient descent) and learning rate = 0.01 or 0.001\noptimizer = #TODO","3bc647e6":"# Define epochs (between 50-200)\nepochs = 20\n# initialize tracker for minimum validation loss\nvalid_loss_min = np.Inf # set initial \"min\" to infinity\n\n# Some lists to keep track of loss and accuracy during each epoch\nepoch_list = []\ntrain_loss_list = []\nval_loss_list = []\ntrain_acc_list = []\nval_acc_list = []\n# Start epochs\nfor epoch in range(epochs):\n    \n    #adjust_learning_rate(optimizer, epoch)\n    \n    # monitor training loss\n    train_loss = 0.0\n    val_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    # Set the training mode ON -> Activate Dropout Layers\n    model.train() # prepare model for training\n    # Calculate Accuracy         \n    correct = 0\n    total = 0\n    \n    # Load Train Images with Labels(Targets)\n    for data, target in train_loader:\n        \n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        \n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        \n        if type(output) == tuple:\n            output, _ = output\n        \n        # Calculate Training Accuracy \n        predicted = torch.max(output.data, 1)[1]        \n        # Total number of labels\n        total += len(target)\n        # Total correct predictions\n        correct += (predicted == target).sum()\n        \n        # calculate the loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item()*data.size(0)\n    \n    # calculate average training loss over an epoch\n    train_loss = train_loss\/len(train_loader.dataset)\n    \n    # Avg Accuracy\n    accuracy = 100 * correct \/ float(total)\n    \n    # Put them in their list\n    train_acc_list.append(accuracy)\n    train_loss_list.append(train_loss)\n    \n        \n    # Implement Validation like K-fold Cross-validation \n    \n    # Set Evaluation Mode ON -> Turn Off Dropout\n    model.eval() # Required for Evaluation\/Test\n\n    # Calculate Test\/Validation Accuracy         \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n\n\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n\n            # Predict Output\n            output = model(data)\n            if type(output) == tuple:\n                output, _ = output\n\n            # Calculate Loss\n            loss = criterion(output, target)\n            val_loss += loss.item()*data.size(0)\n            # Get predictions from the maximum value\n            predicted = torch.max(output.data, 1)[1]\n\n            # Total number of labels\n            total += len(target)\n\n            # Total correct predictions\n            correct += (predicted == target).sum()\n    \n    # calculate average training loss and accuracy over an epoch\n    val_loss = val_loss\/len(test_loader.dataset)\n    accuracy = 100 * correct\/ float(total)\n    \n    # Put them in their list\n    val_acc_list.append(accuracy)\n    val_loss_list.append(val_loss)\n    \n    # Print the Epoch and Training Loss Details with Validation Accuracy   \n    print('Epoch: {} \\tTraining Loss: {:.4f}\\t Val. acc: {:.2f}%'.format(\n        epoch+1, \n        train_loss,\n        accuracy\n        ))\n    # save model if validation loss has decreased\n    if val_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        val_loss))\n        # Save Model State on Checkpoint\n        torch.save(model.state_dict(), 'model.pt')\n        valid_loss_min = val_loss\n    # Move to next epoch\n    epoch_list.append(epoch + 1)","e4dfa36d":"model.load_state_dict(torch.load('model.pt'))","f46a88fe":"#Save\/Pickle the Model\ntorch.save(model, 'classifier.pth')","74bdd0a4":"# Training \/ Validation Loss\nplt.plot(epoch_list,train_loss_list)\nplt.plot(val_loss_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training\/Validation Loss vs Number of Epochs\")\nplt.legend(['Train', 'Valid'], loc='upper right')\nplt.show()","e1b30f7b":"# Train\/Valid Accuracy\nplt.plot(epoch_list,train_acc_list)\nplt.plot(val_acc_list)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Training\/Validation Accuracy\")\nplt.title(\"Accuracy vs Number of Epochs\")\nplt.legend(['Train', 'Valid'], loc='best')\nplt.show()","a58c8052":"val_acc = sum(val_acc_list[:]).item()\/len(val_acc_list)\nprint(\"Validation Accuracy of model = {} %\".format(val_acc))","1b5bd45c":"# obtain one batch of test images\ndataiter = iter(test_loader)\nimages, labels = dataiter.next()\nimg = images.numpy()\n\n# move model inputs to cuda, if GPU available\nif train_on_gpu:\n    images = images.cuda()\n\nmodel.eval() # Required for Evaluation\/Test\n# get sample outputs\noutput = model(images)\nif type(output) == tuple:\n            output, _ = output\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(20, 5))\nfor idx in np.arange(12):\n    ax = fig.add_subplot(3, 4, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(img[idx], (1, 2, 0)))\n    ax.set_title(\"Pr: {} Ac: {}\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","df7b4dc3":"# !git clone https:\/\/github.com\/GabrielePicco\/deep-learning-flower-identifier\n# !pip install airtable\n# import sys\n# sys.path.insert(0, 'deep-learning-flower-identifier')","3a1b6e3a":"# from test_model_pytorch_facebook_challenge import calc_accuracy\n# calc_accuracy(model, input_image_size=224, use_google_testset=False)","ec33352f":"## 3. Make a DataLoader","e550869c":"**By [Soumya Ranjan Behera](https:\/\/www.linkedin.com\/in\/soumya044)**","f9f69890":"## Save the whole Model (Pickling)","357a33d1":"**Visualize Sample Images**","e4b71eca":"# 7. Visualize Model Training and Validation","710bc785":"**We can see that the Correctly Classifies Results are Marked in \"Green\" and the misclassifies ones are \"Red\"**","7458f436":"## 8.1 Test our Model Performance with Gabriele Picco's Program","802e7e70":"## 4. Use a Pre-Trained Model (VGG16)   \nHere we used a VGG16. You can experiment with other models.  \nReferences: https:\/\/github.com\/udacity\/deep-learning-v2-pytorch\/blob\/master\/transfer-learning\/Transfer_Learning_Solution.ipynb","3ef20ad0":"**Special Instruction:**  \n1. **Uncomment the following two code cells while running the notebook.**\n2. Comment these two blocks while **Commit**, otherwise you will get an error \"Too many Output Files\" in Kaggle Only.\n3. If you find a solution to this then let me know.","b9674b6e":"**Note:** This tutorial is like a template or guide for newbies to overcome the fear of the final lab challenge. My intent is not to promote plagiarism or any means of cheating. Users are encourage to take this tutorial as a baseline and build their own better model. Cheers!","adf2fe06":"**Here plt.imshow() clips our data into [0,....,255] range to show the images. The Warning message is due to our Transform Function. We can Ignore it.**","d4402de2":"# 8. Test our Model Performance ","5a5828c5":"# **Proceed To Part 2: [Click Here](https:\/\/www.kaggle.com\/soumya044\/udacity-pytorch-final-lab-guide-part-2\/)**","b0665fee":"**Just Right-click on Below link and Copy the Link**  \n**And Proceed to [Part 2 Tutorial](https:\/\/www.kaggle.com\/soumya044\/udacity-pytorch-final-lab-guide-part-2\/)**","0c95d754":"From the above graphs we get some really impressive results","bc276d60":"# Part 1: Build and Train a Model","cdd244eb":"## Links Here:  \n**Model State Checkpoint File: [model.pt](.\/model.pt)**   (Preferred)  \n**Classifier Pickle File: [classifier.pth](.\/classifier.pth)**  \n(Right-click on model.pt and copy the link address)  \n\n* If the links don't work then just modify the (link) as .\/model.pt or .\/classifier.pth","824951b7":"**Fork this Notebook and Run it from Top-To-Bottom Step by Step**","3e4b8328":"**Credits: ** **Gabriele Picco** (https:\/\/github.com\/GabrielePicco\/deep-learning-flower-identifier)","fad926a8":"## Load Model State from Checkpoint","ecfdefa2":"### We can see from above output that the last ,i.e, 6th Layer is a Fully-connected Layer with in_features=4096, out_features=1000","025642c2":"# Udacity PyTorch Scholarship Final Lab Challenge Guide  \n**A hands-on guide to get 90% + accuracy and complete the challenge**","4035f096":"**Import PyTorch libraries**","3cac7853":"**Load and Transform (Image Augmentation)**  \nSoucre: https:\/\/github.com\/udacity\/deep-learning-v2-pytorch\/blob\/master\/convolutional-neural-networks\/cifar-cnn\/cifar10_cnn_augmentation.ipynb","bc75bce1":"# 9. Export our Model Checkpoint File or Model Pickle File","5ac5a98e":"# 5. Specify our Loss Function and Optimzer","56952b80":"**Try More Models: ** https:\/\/pytorch.org\/docs\/stable\/torchvision\/models.html","0540bfe5":"## **Congrats! We got almost 90% accuracy with just a simple configuration!**  \n(We will get almost 90% accuracy in Gabriele's Test Suite. Just Uncomment above two code cells and see.)","2a646a03":"**Note:** **Look carefully! Kaggle uses v1.0.0 while Udcaity workspace has v0.4.0 (Some issues may arise but we'll solve them)**","dd892586":"## Let's Add our own Last Layer which will have 102 out_features for 102 species","b46643a7":"## 1. Import Data set and visualiza some data","6a6c90f4":"**Import some visualization Libraries**","9761b9fb":"# Thank You  \n\nIf you liked this kernel please **Upvote**. Don't forget to drop a comment or suggestion.  \n\n### *Soumya Ranjan Behera*\nLet's stay Connected! [LinkedIn](https:\/\/www.linkedin.com\/in\/soumya044)  \n\n**Happy Coding !**","faaaf833":"## 2. Data Preprocessing (Image Augmentation)","b57333dd":"**Make a Class Variable i.e a list of Target Categories (List of 102 species) **","b4b4e7a7":"**Credits:** The dataset credit goes to [Lalu Erfandi Maula Yusnu](https:\/\/www.kaggle.com\/nunenuh)","bca5237c":"**Freeze Training for all 'Features Layers', Only Train Classifier Layers**","f652c2fb":"## This Tutorial will be divided into Two Parts,  \n### [1. Model Building and Training](https:\/\/www.kaggle.com\/soumya044\/udacity-pytorch-final-lab-guide-part-1\/)\n### [2. Submit in Udcaity's Workspace for evaluation](https:\/\/www.kaggle.com\/soumya044\/udacity-pytorch-final-lab-guide-part-2\/)","54394bde":"# 6. Train our Model and Save necessary checkpoints","2e821717":"**Overall Accuracy\n**","fb7c634a":"### Find more on Image Transforms using PyTorch Here (https:\/\/pytorch.org\/docs\/stable\/torchvision\/transforms.html)"}}