{"cell_type":{"99c8bd93":"code","39b714bc":"code","0acc90af":"code","d5828ceb":"code","ad6ec952":"code","11294cfc":"code","fbd724a0":"code","d213ed5d":"code","8b1daa45":"code","442bb823":"code","91e49529":"code","8441908c":"code","aa15ff93":"code","55765195":"code","a79f9d73":"code","7d2a3988":"code","df2fdfa9":"code","2869f167":"code","79987cb3":"code","b00467dc":"code","5952f879":"code","55881540":"code","c99e0162":"code","1467b056":"code","5e650eac":"code","90cb763c":"code","ebd5763f":"code","15cac349":"code","dfee3247":"code","8be22aaf":"code","c0c4d133":"code","f132257c":"code","b95590c4":"code","9db1739d":"code","1a7504e4":"code","6be5884e":"code","b9e36b37":"code","c4d33b7b":"code","97157f81":"code","36a542ac":"code","aefcd519":"code","3168fa81":"code","b5779583":"code","98c1202c":"code","e1d235ea":"code","675f4f69":"code","a89292dd":"code","3a7ae7e2":"code","3d58c3fc":"markdown","2ccd14b5":"markdown","fd452f5b":"markdown","55795443":"markdown","9f71e154":"markdown","b8231c37":"markdown","c215b626":"markdown","d8a22958":"markdown","5e93ceb7":"markdown"},"source":{"99c8bd93":"def warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport glob\nimport numpy as np\nfrom skimage import io, transform\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport cv2\nimport time\nfrom random import shuffle\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nimport math\nfrom datetime import timedelta\nimport tensorflow.contrib.slim as slim\n# Any results you write to the current directory are saved as output.","39b714bc":"ROWS = 150\nCOLS = 150\nCHANNELS = 3\n\nBATCH_SIZE = 64\nLR_BASE = 1e-3\nnum_classes = 2","0acc90af":"train = glob.glob('..\/input\/dogs-vs-cats-redux-kernels-edition\/train\/*.jpg')\nNUM_TRAINS = len(train)\nsplit_factor = 0.1\n\n# Shuffle training data\nshuffle(train)\n\nNUM_TRAININGS = int(NUM_TRAINS*(1 - split_factor))\n\nTRAINING_DATA = train[:NUM_TRAININGS]\n\nVALIDATION_DATA = train[NUM_TRAININGS:]\n\n(len(TRAINING_DATA), len(VALIDATION_DATA))","d5828ceb":"# Reshape color images\ndef reshaped_image(image):\n    return transform.resize(image,(ROWS, COLS, CHANNELS))","ad6ec952":"# One-hot Encoding for training data: cat [1 0], dog [0 1]\ndef process_Data(DIR_PATH):\n    path_Imgs = []\n    labels = []\n    for pathImg in DIR_PATH:\n        path_Imgs.append(pathImg)\n        imgName = pathImg.split('\/')[-1]\n        label = imgName.split('.')[0]\n        if label == 'cat':\n            label = [1., 0.]\n        else:\n            label = [0., 1.]\n        labels.append(label)\n    \n    return np.array(path_Imgs), np.array(labels)","11294cfc":"def loadBatchImages(BatchDataPath):\n    BatchImages = []\n    for path in BatchDataPath:\n        img = cv2.imread(path)\n\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img\/ 255.\n        BatchImages.append(reshaped_image(img))\n    return np.array(BatchImages)","fbd724a0":"TRAIN_PATH_DATAS, TRAIN_LABELS = process_Data(TRAINING_DATA)\nVAL_PATH_DATAS, VALID_LABELS = process_Data(VALIDATION_DATA)\nTRAIN_PATH_DATAS.shape, VAL_PATH_DATAS.shape","d213ed5d":"def loading_Data(DataPath, DataLabels, Num_Datas, current_index, batch_size=64):\n    begin_index = current_index*batch_size\n    end_index = -1\n    if begin_index + batch_size < Num_Datas:\n        end_index = begin_index + batch_size\n    else:\n        end_index = Num_Datas\n    Batch_Imgs = loadBatchImages(DataPath[begin_index : end_index])\n    Batch_Labels = DataLabels[begin_index : end_index]\n    \n    return Batch_Imgs, Batch_Labels","8b1daa45":"Batch_Imgs, Batch_Labels = loading_Data(TRAIN_PATH_DATAS, TRAIN_LABELS, NUM_TRAININGS, current_index = 0, batch_size=9)","442bb823":"Batch_Imgs.shape, Batch_Labels.shape","91e49529":"def plot_image(images, cls_true, cls_pred=None):\n    assert len(images) == len(cls_true) == 9\n    fig, axes = plt.subplots(3, 3)\n    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i])\n    \n        if cls_pred is None:\n            xlabel = \"True: {0}\".format(cls_true[i])\n        else:\n            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n    \n        ax.set_xlabel(xlabel)\n    \n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","8441908c":"Batch_Labels_cls = np.argmax(Batch_Labels, axis=1)","aa15ff93":"plot_image(Batch_Imgs, Batch_Labels_cls)","55765195":"VGG_Weights = np.load('..\/input\/vgg16-pretrained\/vgg16.npy', encoding='latin1').item()","a79f9d73":"x_image = tf.placeholder(tf.float32, shape=[None, ROWS, COLS, CHANNELS], name='x_image')\ny_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\ny_true_cls = tf.argmax(y_true, axis=1)","7d2a3988":"def conv2d(layer, name, n_filters, trainable, k_size=3):\n        return tf.layers.conv2d(layer, n_filters, kernel_size=(k_size, k_size),\n                                activation=tf.nn.relu, padding='SAME', name=name, trainable=trainable,\n                                kernel_initializer=tf.constant_initializer(VGG_Weights[name][0], dtype=tf.float32),\n                                bias_initializer=tf.constant_initializer(VGG_Weights[name][1], dtype=tf.float32),\n                                use_bias=True)","df2fdfa9":"net = x_image","2869f167":"# Block 1\nnet = conv2d(net, 'conv1_1', 64, trainable = False)\nlayer_conv1_1 = net\nnet = conv2d(net, 'conv1_2', 64, trainable = False)\nlayer_conv1_2 = net\nnet = tf.layers.max_pooling2d(net, (2, 2), (2, 2), padding='same')","79987cb3":"# Block 2\nnet = conv2d(net, 'conv2_1', 128, trainable = False)\nlayer_conv2_1 = net\nnet = conv2d(net, 'conv2_2', 128, trainable = False)\nlayer_conv2_2 = net\nnet = tf.layers.max_pooling2d(net, (2, 2), (2, 2), padding='same')","b00467dc":"# Block 3\nnet = conv2d(net, 'conv3_1', 256, trainable = False)\nlayer_conv3_1 = net\nnet = conv2d(net, 'conv3_2', 256, trainable = False)\nlayer_conv3_2 = net\nnet = conv2d(net, 'conv3_3', 256, trainable = False)\nlayer_conv3_3 = net\nnet = tf.layers.max_pooling2d(net, (2, 2), (2, 2), padding='same')","5952f879":"# Block 4\nnet = conv2d(net, 'conv4_1', 512, trainable = True)\nlayer_conv4_1 = net\nnet = conv2d(net, 'conv4_2', 512, trainable = True)\nlayer_conv4_2 = net\nnet = conv2d(net, 'conv4_3', 512, trainable = True)\nlayer_conv4_3 = net\nnet = tf.layers.max_pooling2d(net, (2, 2), (2, 2), padding='same')","55881540":"# Block 5\nnet = conv2d(net, 'conv5_1', 512, trainable = True)\nlayer_conv5_1 = net\nnet = conv2d(net, 'conv5_2', 512, trainable = True)\nlayer_conv5_2 = net\nnet = conv2d(net, 'conv5_3', 512, trainable = True)\nlayer_conv5_3 = net\nnet = tf.layers.max_pooling2d(net, (2, 2), (2, 2), padding='same')","c99e0162":"layer_conv5_3, net","1467b056":"net = tf.contrib.layers.flatten(net)\nnet","5e650eac":"net = tf.layers.dense(inputs=net, \n                      name='layer_fc1',\n                      units=512, \n                      activation=tf.nn.relu)","90cb763c":"net = tf.layers.dense(inputs=net, \n                      name='layer_fc2',\n                      units=64, \n                      activation=tf.nn.relu)","ebd5763f":"net = tf.layers.dense(inputs=net, \n                      name='layer_fc_out',\n                      units=num_classes, \n                      activation=None)","15cac349":"logits = net\ny_pred = tf.nn.softmax(logits=logits)\ny_pred_cls = tf.argmax(y_pred, axis=1)","dfee3247":"y_pred_cls","8be22aaf":"def model_summary():\n    model_vars = tf.global_variables()\n    slim.model_analyzer.analyze_vars(model_vars, print_info=True)","c0c4d133":"model_summary()","f132257c":"def model_trainable_summary():\n    model_vars = tf.trainable_variables()\n    slim.model_analyzer.analyze_vars(model_vars, print_info=True)","b95590c4":"# summary trainable weights\nmodel_trainable_summary()","9db1739d":"cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)","1a7504e4":"loss = tf.reduce_mean(cross_entropy)","6be5884e":"# Optimization Method\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)","b9e36b37":"# Classification Accuracy\ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls)\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))","c4d33b7b":"for var in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES):\n    print(var)","97157f81":"def get_weights_variable(layer_name):\n    with tf.variable_scope(layer_name, reuse=True):\n        variable = tf.get_variable('kernel')\n    return variable","36a542ac":"weights_conv1_1 = get_weights_variable(layer_name='conv1_1')\nweights_conv1_2 = get_weights_variable(layer_name='conv1_2')\n\nweights_conv2_1 = get_weights_variable(layer_name='conv2_1')\nweights_conv2_2 = get_weights_variable(layer_name='conv2_2')\n\nweights_conv3_1 = get_weights_variable(layer_name='conv3_1')\nweights_conv3_2 = get_weights_variable(layer_name='conv3_2')\nweights_conv3_3 = get_weights_variable(layer_name='conv3_3')\n\nweights_conv4_1 = get_weights_variable(layer_name='conv4_1')\nweights_conv4_2 = get_weights_variable(layer_name='conv4_2')\nweights_conv4_3 = get_weights_variable(layer_name='conv4_3')\n\nweights_conv5_1 = get_weights_variable(layer_name='conv5_1')\nweights_conv5_2 = get_weights_variable(layer_name='conv5_2')\nweights_conv5_3 = get_weights_variable(layer_name='conv5_3')","aefcd519":"session = tf.Session()\ninit = tf.global_variables_initializer()\nsession.run(init)","3168fa81":"test_batch_size = 128\n\ndef print_test_accuracy(show_example_error=False, show_confusion_matrix=False):\n    num_test = len(VALIDATION_DATA)\n    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n    i = 0\n    while i < num_test:\n        j = min(i + test_batch_size, num_test)\n\n        k = int(i \/\/ test_batch_size)\n\n        x_batch, y_true_batch = loading_Data(VAL_PATH_DATAS, \n                                           VALID_LABELS, \n                                           len(VALIDATION_DATA), \n                                           current_index = k, \n                                           batch_size=test_batch_size)\n\n        feed_dict = {x_image: x_batch, y_true: y_true_batch}\n\n        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n\n        i = j\n    cls_true = np.argmax(VALID_LABELS, axis=1)\n    correct = (cls_true == cls_pred)\n    correct_sum = correct.sum()\n    acc = float(correct_sum) \/ num_test\n    msg = \"Accuracy on Validation-Set: {0:.1%} ({1} \/ {2})\"\n    print(msg.format(acc, correct_sum, num_test))","b5779583":"train_batch_size = 128\ntotal_iterations = 0\n\ndef optimize(num_iterations):\n    global total_iterations\n    start_time = time.time()\n    num_batchs = math.ceil(NUM_TRAININGS \/ train_batch_size)\n    for epoch in range(total_iterations, num_iterations + total_iterations):\n    \n        for batch_step in range(num_batchs):\n            x_batch, y_true_batch = loading_Data(TRAIN_PATH_DATAS, \n                                               TRAIN_LABELS, \n                                               NUM_TRAININGS, \n                                               current_index = batch_step, \n                                               batch_size=train_batch_size)\n\n            feed_dict_train = {x_image: x_batch, y_true: y_true_batch}\n            session.run(optimizer, feed_dict = feed_dict_train)\n            if batch_step % 10 == 0:\n                train_acc = session.run(accuracy, feed_dict=feed_dict_train)\n                msg = \"Optimization Iteration: {0:>6}, Training Accuracy : {1:>6.1%}\"\n                print(msg.format(batch_step + 1, train_acc))\n        print('===============================')\n        print('Epoch : {}'.format(epoch))\n        print_test_accuracy()\n        print('===============================')\n    total_iterations += num_iterations\n    end_time = time.time()\n    time_dif = end_time - start_time\n    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))","98c1202c":"#print_test_accuracy()","e1d235ea":"optimize(num_iterations = 1)","675f4f69":"#optimize(num_iterations = 9)","a89292dd":"#print_test_accuracy()","3a7ae7e2":"#optimize(num_iterations = 10)","3d58c3fc":"## Placeholder variables","2ccd14b5":"# DATA PREPROCESSING","fd452f5b":"## Loss-Function to be Optimized","55795443":"# Model Summary","9f71e154":"# TensorFlow Run","b8231c37":"# Show Global Variables","c215b626":"## Layers Implementation","d8a22958":"# CONVOLUTION NEURAL NETWORK WITH TENSORFLOW","5e93ceb7":"## Load pre-trained VGG16 Model"}}