{"cell_type":{"460a9759":"code","c2389531":"code","6e06057d":"code","7580486a":"code","dec012b3":"code","170e2c34":"code","f7ff5d33":"code","481f4dd0":"code","5bf6ddb4":"code","572da97d":"code","64f0ee45":"code","495e8619":"code","3a8d7619":"code","fff308c4":"code","c689f937":"code","172182bf":"code","8985ec19":"code","31db95ae":"code","2cc63632":"code","10f0f360":"code","c75ebfab":"code","24390b0b":"code","de716933":"code","d2de37ae":"code","d4b0b91b":"code","b72dfaee":"code","b5808595":"code","a66ee415":"code","cb514cae":"code","30ec030f":"code","50d7af38":"code","faa81d03":"code","ac6d6e8e":"code","401668f9":"code","a9e85af3":"code","a217968c":"code","cb5fb65b":"code","f7e3b3e6":"code","64553129":"code","e4f89c1a":"code","b2a819a7":"code","bf2ea44e":"code","522b7aaa":"code","a29e9482":"code","23295f9e":"code","9a852ade":"code","368c5d1b":"code","d24a70a0":"code","b5bb2f89":"code","c9489555":"code","148471fb":"markdown","e82306bc":"markdown","4001d5f2":"markdown","f0616b80":"markdown","5f346f23":"markdown"},"source":{"460a9759":"import pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c2389531":"# Read the data\nstores = pd.read_csv('\/kaggle\/input\/sample-data\/stores.csv')","6e06057d":"stores.head(2)","7580486a":"stores.shape","dec012b3":"# Add new columns\nstores['NetProfit'] = stores.TotalSales - stores.OperatingCost","170e2c34":"stores.head(2)","f7ff5d33":"stores.shape","481f4dd0":"# '.assign' can be used to create new columns\nstores = stores.assign(NetProfit1 = stores.TotalSales - stores.OperatingCost, NetProfit2 = stores.TotalSales - (stores.OperatingCost + stores.AcqCostPercust))","5bf6ddb4":"stores = stores.assign(np1 = stores.TotalSales - stores.OperatingCost, np2 = stores.TotalSales - stores.OperatingCost)","572da97d":"stores.head(2)","64f0ee45":"# Delete columns\n# to drop the column, \"Inplace = True\" needs to be used\nstores.drop(columns = 'np2', axis = 1, inplace = True)","495e8619":"stores.drop(columns = 'np1', axis = 1, inplace = True)","3a8d7619":"# Columsn 'np1' and 'np2' were dropped from original data set.\nstores.head(1)","fff308c4":"# Re-arrange the columns\nstores[['TotalSales','StoreType', 'StoreName', 'Location']].head(3)","c689f937":"# Subsetting the columns ([], loc, iloc)\nstores['StoreCode'].head(2)","172182bf":"# syntax for using loc and iloc (rows , columns) = (:,:)\n# rows and columns given in range\nstores.iloc[:,0:3].head(3)","8985ec19":"stores.loc[:,['StoreCode', 'StoreName', 'StoreType']].head(3)","31db95ae":"# Rename the columns \n# (here also we need to use \"Inplace = True\" in order to change the column name in original datset)\nstores.rename\nstores.rename(columns = {'TotalSales': 'Sales'}).head(2)","2cc63632":"stores.head(1)","10f0f360":"# Read the data\nstores = pd.read_csv('\/kaggle\/input\/sample-data\/stores.csv')","c75ebfab":"stores.head(2)","24390b0b":"# Filter\n# Get records from stores where Location is Delhi\nstores[stores.Location == 'Delhi']","de716933":"# Sort\nstores.sort_values('TotalSales', ascending = True)\n# to sort values in descending, simple use 'ascending = False'","d2de37ae":"# Similarly we can sort based on more than one column\n# stores.sort_values(['Location', 'TotalSales'], ascending = [True, False])","d4b0b91b":"# Removal of duplicates\n# Read the data\nScore = pd.read_csv('\/kaggle\/input\/sample-data1\/Score.csv')","b72dfaee":"Score","b5808595":"# Duplicate values\nScore[Score.duplicated()]","a66ee415":"# pleas try below\n# score.loc[score.duplicated(),:] \n# score.loc[-score.Student.duplicated(),:] ","cb514cae":"# Data Imputation\n# Read the data\nstores = pd.read_csv('\/kaggle\/input\/sample-data\/stores.csv')","30ec030f":"stores.shape[0]","50d7af38":"# percentage of missing values from stores dataset\n1 - stores.count()\/stores.shape[0]","faa81d03":"# Column 'AcqCostPercust' has missing values\ndata = stores.AcqCostPercust\ndata","ac6d6e8e":"# fill the missing values\n# if null values are more, we can drop the column 'AcqCostPercust' using below\na = stores.dropna(axis = 1)","401668f9":"# we can fill the missing values using below\ndata.fillna(data.mean())","a9e85af3":"stores['New'] = stores.TotalSales.clip(lower = 100, upper = 400)","a217968c":"# Values are restricted to the range (100,400)\nstores[['TotalSales', 'New']]","cb5fb65b":"# Binning example\nstores['Bins'] = pd.cut(stores.TotalSales, 10)","f7e3b3e6":"stores[['Bins', 'TotalSales'] ]","64553129":"pd.cut(stores.TotalSales, range(50, 1000, 50))","e4f89c1a":"import numpy as np","b2a819a7":"stores[\"Region\"] = np.where((stores.Location == \"Delhi\"), \"North\",\n            np.where((stores.Location == \"Chennai\"), \"South\",\n                     np.where((stores.Location == \"Kolkata\"), \"East\",\n                              np.where((stores.Location == \"Mumbai\"), \"West\", \"\"))))","bf2ea44e":"stores[['Region', 'Location']]","522b7aaa":"# Groupby\nstores.groupby('Location').TotalSales.agg(['sum', 'mean']).reset_index()","a29e9482":"# \/kaggle\/input\/sample-data-2\/Transaction_Summary.csv\n# \/kaggle\/input\/sample-data-2\/Demographic_Data.csv","23295f9e":"# Merge\na = pd.read_csv('\/kaggle\/input\/sample-data-2\/Transaction_Summary.csv')\nb = pd.read_csv('\/kaggle\/input\/sample-data-2\/Demographic_Data.csv')","9a852ade":"a","368c5d1b":"b","d24a70a0":"# Inner join\npd.merge(left = a, right= b, right_on = 'CustName', left_on='CustomerName', how = 'inner')\n# Similarly other joins can be performed","b5bb2f89":"# Append\n# Read the data\nQ3 = pd.read_csv('\/kaggle\/input\/sample-data-3\/POS_Q3.csv')\nQ1 = pd.read_csv('\/kaggle\/input\/sample-data-3\/POS_Q1.csv')\nQ4 = pd.read_csv('\/kaggle\/input\/sample-data-3\/POS_Q4.csv')\nQ2 = pd.read_csv('\/kaggle\/input\/sample-data-3\/POS_Q2.csv')","c9489555":"Q1.append([Q2, Q3, Q4], ignore_index = True)","148471fb":"**This Notebook covers \"Pandas Data Manipulation\"**\n\n# Structural changes\n* Add new columns\n* Delete some columns\n* Rearrange the columns\n* Subsetting (Extracting some columns)\n* Rename the columns\n\n# Content Based changes\n* Filters\n* Sort\n* Removal of duplicates\n* Data imputation (Missing values\/Outliers)\n* Binning or Grouping of the data\n* Encoding\n* Grouping of the data\/ Summaries\n* Joins\/Merge\n* Appending\n","e82306bc":"# Content Based Changes","4001d5f2":"# Structural changes","f0616b80":"**Binning: pd.cut()**\n1. Automatic binning = pd.cut(pd.Series, int, labels=[])\n2. Manual binning using user defined ranges = pd.cut(pd.Series, range(min, max + 1, step), labels=[])\n    \n**Grouping** \n1. Using user defined ranges = pd.cut(pd.Series, [ordered list], labels=[])\n2. numpy.where()","5f346f23":"**Data imputation - Outliers**\n* clip_lower()\n* clip_upper()\n* clip()"}}