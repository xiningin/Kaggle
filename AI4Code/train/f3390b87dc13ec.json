{"cell_type":{"a27b1884":"code","e66f7672":"code","24f1851f":"code","56eb06a2":"code","bad45406":"code","8946ff0e":"code","60f03a11":"code","ddbf4717":"code","56e9197c":"code","0f9d8ca0":"code","3bc41cc2":"code","5783a14b":"code","72ad3e9b":"code","e8087922":"code","fbc46864":"code","e2630ed5":"code","0680de24":"code","93afd7c7":"code","33f3b417":"code","7d7f0dfd":"code","13b12713":"code","0681d852":"code","e7c96696":"markdown","a6539909":"markdown","eb04031e":"markdown","e31f60a0":"markdown","9fbdcba6":"markdown","7aca1d2d":"markdown","8dcb0917":"markdown","7869bf0f":"markdown","9405ae94":"markdown","872921e1":"markdown"},"source":{"a27b1884":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e66f7672":"valid = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","24f1851f":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_subm = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ntrain.drop(['Name', 'Ticket'],inplace=True, axis=1)\ntrain","56eb06a2":"train.drop([\"Cabin\"], inplace=True, axis=1)","bad45406":"train[\"Family\"] = train['SibSp'] + train['Parch']+1\ntrain['Fare_person'] = train['Fare']\/train['Family']\ntrain['Safety'] = train['Pclass']*10 + train['Age']\ntrain","8946ff0e":"valid.drop(['Name', 'Ticket', 'PassengerId', 'Cabin'],inplace=True, axis=1)","60f03a11":"valid[\"Family\"] = valid['SibSp'] + valid['Parch']+1\nvalid['Fare_person'] = valid['Fare']\/valid['Family']\nvalid['Safety'] = valid['Pclass']*10 + valid['Age']\n","ddbf4717":"sex = {'male': 1, 'female':0}\ntrain.replace({'Sex': sex}, inplace=True)\nvalid.replace({'Sex': sex}, inplace=True)","56e9197c":"e_map = {'S': 1, 'C':2,'S':3, 'Q':4}\ntrain.replace({'Embarked': e_map}, inplace=True)\nvalid.replace({'Embarked': e_map}, inplace=True)","0f9d8ca0":"train","3bc41cc2":"from sklearn import preprocessing\n\nfeats = train[['Pclass','Age','SibSp','Parch','Fare','Sex','Embarked', 'Family','Fare_person','Safety']]\n\nscaler = preprocessing.StandardScaler()\nall_features_scaled = scaler.fit_transform(feats)\nall_features_scaleddf = pd.DataFrame(all_features_scaled)","5783a14b":"from sklearn import preprocessing\n\nfeats2 = valid[['Pclass','Age','SibSp','Parch','Fare','Sex','Embarked', 'Family','Fare_person','Safety']]\n\nscaler = preprocessing.StandardScaler()\nall_features_scaled2 = scaler.fit_transform(feats2)\nall_features_scaleddf2 = pd.DataFrame(all_features_scaled2)","72ad3e9b":"data = train[['PassengerId','Survived']].join(all_features_scaleddf)\ndata.columns = ['PassengerId','Survived','Pclass','Age','SibSp','Parch','Fare','Sex','Embarked', 'Family','Fare_person','Safety']\n\ndata2 = all_features_scaleddf2\ndata2.columns = ['Pclass','Age','SibSp','Parch','Fare','Sex','Embarked', 'Family','Fare_person','Safety']","e8087922":"data = data.fillna(data.median())\ndata2 = data2.fillna(data2.median())","fbc46864":"data","e2630ed5":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\nX_train, X_test, y_train, y_test = train_test_split(data[['Pclass','Age','SibSp','Parch','Fare','Sex','Embarked', 'Family','Fare_person','Safety']], data[[\"Survived\"]], test_size=0.25, random_state=0)","0680de24":"from sklearn.ensemble import RandomForestClassifier\nRF= RandomForestClassifier(n_estimators=100,random_state=22)","93afd7c7":"RF.fit(X_train,y_train)","33f3b417":"y_pred = RF.predict(data2)","7d7f0dfd":"print(\"Train Score:\",RF.score(X_train, y_train))","13b12713":"test_subm.drop([\"Survived\"], inplace=True, axis = 1)\ntest_subm.insert(1, \"Survived\", y_pred)\ntest_subm","0681d852":"test_subm.to_csv('sub7.csv', index=False)","e7c96696":"This is my notebook for my Titanic submission. I learned alot; getting a good score is not just about running complex models. You can help yourself by understanding and manipulating the data. I tried using LGB, basic Bayesian inference and XG boost models. It seems like this data is modelled particularly well by Random forests for some reason. ","a6539909":"May add some visualizations later but this is the core code used in the submission. Check out other notebooks for other ideas!","eb04031e":"Submitting my score!","e31f60a0":"Encorporating random forests model","9fbdcba6":"Count encoding the sex and embarked features.","7aca1d2d":"Train-Test split of the training data","8dcb0917":"Filling the NAN values with median instead of mean (the median is less affected by outliers)","7869bf0f":"My score: 0.79665 - Top 6%","9405ae94":"Here I've created 3 new features: Family size, fare per person and 'Safety' - which tries to take in to account the age of a person and what class they are in on the boat. ","872921e1":"Scaling the data helps the model alot"}}