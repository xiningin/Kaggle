{"cell_type":{"1f65fbe3":"code","0a0e5d91":"code","fb2e6064":"code","685a58a2":"code","4473bb7b":"code","0a5cdfe7":"code","875ad4e3":"code","25570fe6":"code","f9425b07":"code","c113a95f":"code","a38a4391":"code","900c5513":"markdown","91e6b1a4":"markdown","a5f8be81":"markdown","558b1c0c":"markdown","2e9c540c":"markdown"},"source":{"1f65fbe3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a0e5d91":"df = pd.read_csv('..\/input\/acled-bangladesh\/2001-01-01-2021-11-01-South_Asia-Bangladesh.csv', encoding='utf8')\ndf.head(2)","fb2e6064":"from sklearn.preprocessing import RobustScaler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.feature_selection import mutual_info_classif, SelectPercentile\nfrom sklearn.model_selection import  cross_val_score,cross_validate, train_test_split, cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier","685a58a2":"!pip install pandas_flavor","4473bb7b":"#Code by IM_AMS  https:\/\/www.kaggle.com\/imams2000\/fraud-detection-under-oversample-87-recall\n\nfrom pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef get_missing(df):        \n    tmp =  sorted(\n                [(col , str(df[col].dtypes) ,df[col].isna().sum(), np.round( df[col].isna().sum() \/ len(df) * 100,2) ) for col in df.columns if df[col].isna().sum() !=0 ],\n                key = lambda x: x[2], reverse=True)\n    \n    return pd.DataFrame(tmp).rename({0:\"Feature\", 1:\"dtype\", 2:\"count\", 3:\"percent\"},axis=1)  \n\n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_cols(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef get_object_cols(df):\n    return list(df.select_dtypes(exclude = np.number).columns)\n\n@register_dataframe_method\ndef get_object_df(df):\n    return df.select_dtypes(exclude = np.number)\n\n@register_dataframe_method\ndef get_discrete_cols(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef get_discrete_df(df,thresold):\n#     thresold in number of unique values\n    return df[ get_discrete_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef describe_discrete_cols(df,thresold, ascending=True):\n    \n    values = pd.DataFrame()\n    \n    for col in df.get_discrete_cols(thresold=thresold):\n        values[col] = [df[col].unique(), df[col].nunique()]\n        \n    return values.transpose().sort_values(by = 1,ascending=ascending).rename({0:\"Values\",1:\"cardinality\"},axis=1)\n\n@register_dataframe_method\ndef get_continuous_cols(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef get_continuous_df(df,thresold):\n    #     thresold in number of unique values\n    return df[ get_continuous_cols(df=df,thresold=thresold) ]\n\n\n@register_dataframe_method\ndef describe_continuous_cols(df,thresold, ascending=True):\n    return df[df.get_continuous_cols(thresold=thresold)].describe().T\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n\n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n#             length - Number of NON outliers\n            length = len(df[i])\n            outlier_count = length - df[i].between(lower_range,upper_range).sum()\n            \n            percent = np.round( outlier_count \/length * 100, 2)\n            if outlier_count != 0:\n                features[i] = [percent, outlier_count]\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Outlier percent', 1:\"Count\"}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n\n@register_dataframe_method\ndef get_outlier_cols(df):\n    return df.IQR_percent().reset_index()[\"index\"].to_list()\n        \n@register_dataframe_method\ndef drop_row_outlier(df, cols, inplace=False):\n#     init empty index\n    indices = pd.Series(np.zeros(len(df), dtype=bool), index=df.index)\n\n    for col in cols:\n        low, top = df[col].IQR_range()\n        indices |= (df[col] > top) | (df[col] < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n\n@register_series_method\ndef drop_row_outlier(df, inplace=False):\n#     init empty index\n\n    low, top = df.IQR_range()\n    indices = (df > top) | (df < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n        \n@register_dataframe_method\ndef compare_cols(df,l_feat,r_feat, percent=False, percent_of_total=False):\n    \n#     [L_feat] {R_feat1: agg1, R_feat2: agg2}\n\n    \n    if percent or percent_of_total:\n        \n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})\n            \n            if percent: tmp[key +\" %\"] = tmp.groupby(level=0).apply(lambda x: np.round(100 * x \/ float(x.sum()),2))\n\n            if percent_of_total: tmp[key+\" % of total\"] = np.round(tmp[key + \" \" + val] \/ tmp[key + \" \" + val].sum() * 100 , 2)\n            \n            comp.append(tmp)\n            \n        return comp\n    \n    else:\n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})           \n            comp.append(tmp)\n            \n        return comp  \n    \n    \n\n@register_dataframe_method\ndef count_dtypes(df, ascending=False):\n    return pd.DataFrame(df.dtypes.value_counts(ascending=ascending)).rename({0:\"Count\"},axis=1)\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    display(pd.DataFrame(df.dtypes.value_counts(ascending=False) ).rename({0:\"count\"},axis=1))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = get_missing(df)\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())\n    \n    \nimport itertools\ndef display_multiple_tables(table_list):\n    table_list = list(itertools.chain(*table_list) )\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","0a5cdfe7":"df.about()","875ad4e3":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"source_scale\"].value_counts().plot.bar(color='red', title='ACLED Bangladesh Source Scale')\nplt.xticks(rotation=45);","25570fe6":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"sub_event_type\"].value_counts().plot.bar(color='green', title='ACLED Bangladesh Sub Event Type')\nplt.xticks(rotation=45);","f9425b07":"#Code by Lucas Abrah\u00e3o https:\/\/www.kaggle.com\/lucasabrahao\/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"event_type\"].value_counts().plot.bar(color='purple', title='ACLED Bangladesh Event Type')\nplt.xticks(rotation=45);","c113a95f":"#Code by Varshini PJ  user: varshinipj\n\n\nfig = px.scatter_mapbox(df,\n# Here, plotly gets, (x,y) coordinates\nlat=\"latitude\",\nlon=\"longitude\",\ntext='fatalities',\n\n                #Here, plotly detects color of series\n                size=\"time_precision\",\n                color = \"sub_event_type\",\n                labels=\"fatalities\",\n\n                zoom=14.5,\n                center={\"lat\":23.4096, \"lon\":89.1380},\n                height=600,\n                width=800)\nfig.update_layout(mapbox_style='stamen-terrain')\nfig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\nfig.update_layout(title_text=\"ACLED fatalities in Bangladesh\")\nfig.show()","a38a4391":"#Code by Varshini PJ  user: varshinipj\n\n\nfig = px.scatter_mapbox(df,\n# Here, plotly gets, (x,y) coordinates\nlat=\"latitude\",\nlon=\"longitude\",\ntext='actor1',\n\n                #Here, plotly detects color of series\n                size=\"time_precision\",\n                color = \"source_scale\",\n                labels=\"actor1\",\n\n                zoom=14.5,\n                center={\"lat\":22.3678, \"lon\":90.5291},\n                height=600,\n                width=800)\nfig.update_layout(mapbox_style='stamen-terrain')\nfig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\nfig.update_layout(title_text=\"ACLED fatalities in Bangladesh\")\nfig.show()","900c5513":"Acknowledgment:\n\nIm_Ams https:\/\/www.kaggle.com\/imams2000\/fraud-detection-under-oversample-87-recall\n\nVarshini PJ  user: varshinipj","91e6b1a4":"That's all for now. I hope another kaggler would make some public ACLED work.","a5f8be81":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #006400;\"><b style=\"color:#CD5C5C;\">ACLED Bangladesh<\/b><\/h1><\/center>\n\n\"Armed Conflict Location & Event Data Project\"\n\n\"The Armed Conflict Location & Event Data Project (ACLED) is a disaggregated data collection, analysis, and crisis mapping project. ... The ACLED team conducts analysis to describe, explore, and test conflict scenarios, and makes both data and analysis open for free use by the public.\"\n\nhttps:\/\/acleddata.com\/about-acled\/#:~:text=The%20Armed%20Conflict%20Location%20%26%20Event,analysis%2C%20and%20crisis%20mapping%20project.&text=The%20ACLED%20team%20conducts%20analysis,free%20use%20by%20the%20public.","558b1c0c":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQlBvhbUApOGSyoDcF0Yd6mNM_DmsR-PQVTHw&usqp=CAU)https:\/\/www.jstor.org\/stable\/resrep03812?seq=1#metadata_info_tab_contents","2e9c540c":"#Pandas Helper functions"}}