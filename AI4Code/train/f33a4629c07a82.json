{"cell_type":{"a56241e3":"code","aff0bffc":"code","9b290019":"code","86b0d799":"code","a5e359ee":"code","21117c3d":"code","dd239729":"code","f7c9be52":"code","a73ba513":"code","e588acc1":"code","03003dea":"code","575d1ca1":"code","86e72af0":"code","b95b3716":"code","b1aef508":"code","6db9b4f5":"code","30ac6ebe":"code","a19d2e32":"code","e522c987":"code","0fd60f71":"code","fc8304f3":"code","023865ad":"code","c6ab7c53":"code","5a31686b":"code","bf47df62":"code","c6f435a0":"code","eed471c9":"code","d234690a":"code","e212cbd0":"markdown","0cf2f218":"markdown","a10ad6ad":"markdown","896842b1":"markdown","5e601174":"markdown","a10fbb33":"markdown","ba36fcb4":"markdown","767bf086":"markdown","332fe803":"markdown","d7f4a4d1":"markdown","bdedf173":"markdown","48a56932":"markdown","7c94d242":"markdown","2e3f1a24":"markdown","cfc1c94d":"markdown","9c623f54":"markdown","ebffb305":"markdown","3bdb847a":"markdown","355f7357":"markdown","1d5cc9a8":"markdown","0d867e8c":"markdown"},"source":{"a56241e3":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\n\nimport string\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.probability import FreqDist\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import  TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report","aff0bffc":"yelp_df = pd.read_csv('..\/input\/yelp.csv')\nyelp_df.head()","9b290019":"yelp_df = yelp_df.drop(['business_id', 'date', 'review_id', 'type', 'user_id'], axis=1)\nyelp_df = yelp_df.rename(columns={'stars':'Stars', 'text':'Text', 'cool':'Cool'\n                                  , 'useful':'Useful', 'funny':'Funny'})\nyelp_df.head()","86b0d799":"yelp_df['Text Length'] = yelp_df['Text'].apply(len)\nyelp_df.head()","a5e359ee":"yelp_df.describe()","21117c3d":"warnings.filterwarnings(\"ignore\")\n\nfig = plt.figure(figsize=(12,8))\naxes1 = plt.subplot(2,2,1)\naxes1 = sns.countplot(x='Stars', data=yelp_df)\naxes1.set_title('Stars')\naxes1.set_ylabel('Count')\n\naxes2 = plt.subplot(2,2,2)\naxes2 = sns.countplot(x='Cool', data=yelp_df)\naxes2.set_title('Cool')\naxes2.set_ylabel('Count')\n\naxes3 = plt.subplot(2,2,3)\naxes3 = sns.countplot(x='Useful', data=yelp_df)\naxes3.set_title('Useful')\naxes3.set_ylabel('Count')\n\naxes4 = plt.subplot(2,2,4)\naxes4 = sns.countplot(x='Funny', data=yelp_df)\naxes4.set_title('Funny')\naxes4.set_ylabel('Count')\n\nplt.tight_layout()","dd239729":"# Text Length\nwarnings.filterwarnings(\"ignore\")\nfig = plt.figure(figsize=(12,8))\nsns.distplot(yelp_df['Text Length'], kde=True, bins=50)\nplt.title('Text Length Distribution')","f7c9be52":"yelp_cor = yelp_df[['Stars', 'Cool', 'Useful', 'Funny', 'Text Length']].corr()\n\nfig = plt.figure(figsize=(12,8))\naxes = sns.heatmap(yelp_cor, cmap='coolwarm', linewidth=1, linecolor='white', annot=True)\naxes.set_title('Heatmap of Variables', fontsize=30)","a73ba513":"sns.pairplot(yelp_df, hue='Stars', palette='coolwarm')","e588acc1":"warnings.filterwarnings(\"ignore\")\nsns.boxplot(x='Stars', y='Text Length', data=yelp_df, palette='rainbow')","03003dea":"yelp_text = yelp_df[['Stars', 'Text']]\nyelp_text.head()","575d1ca1":"def remove_punc_stopword(text):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    remove_punc = [word for word in text if word not in string.punctuation]\n    remove_punc = ''.join(remove_punc)\n    return [word.lower() for word in remove_punc.split() if word.lower() not in stopwords.words('english')]","86e72af0":"yelp_text_allstars = yelp_text.copy()\nyelp_text_allstars['Text'] = yelp_text_allstars['Text'].apply(remove_punc_stopword)\nyelp_text_allstars.count()","b95b3716":"yelp_text_allstars.head()","b1aef508":"words_split = []\nfor i in range(0,9999): \n    for word in yelp_text_allstars['Text'][i]:\n        words_split.append(word)\nFreqDist(words_split).plot(30, cumulative=False)","6db9b4f5":"yelp_allstars_text = yelp_text_allstars['Text'].values\n\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(yelp_allstars_text))\n\nfig = plt.figure(\n    figsize = (10, 7),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)","30ac6ebe":"warnings.filterwarnings(\"ignore\")\nyelp_text_stars1 = yelp_text[yelp_text['Stars']==1]\nyelp_text_stars1['Text'] = yelp_text_stars1['Text'].apply(remove_punc_stopword)\nyelp_text_stars1.count()","a19d2e32":"yelp_text_stars1 = yelp_text_stars1.reset_index(drop=True)\nwords_split = []\nfor i in range(0,749): \n    for word in yelp_text_stars1['Text'][i]:\n        words_split.append(word)\nFreqDist(words_split).plot(30, cumulative=False)","e522c987":"yelp_stars1_text = yelp_text_stars1['Text'].values\n\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(yelp_stars1_text))\n\nfig = plt.figure(\n    figsize = (10, 7),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)","0fd60f71":"warnings.filterwarnings(\"ignore\")\nyelp_text_stars5 = yelp_text[yelp_text['Stars']==5]\nyelp_text_stars5['Text'] = yelp_text_stars5['Text'].apply(remove_punc_stopword)\nyelp_text_stars5.count()","fc8304f3":"yelp_text_stars5 = yelp_text_stars5.reset_index(drop=True)\nwords_split = []\nfor i in range(0,3337): \n    for word in yelp_text_stars5['Text'][i]:\n        words_split.append(word)\nFreqDist(words_split).plot(30, cumulative=False)","023865ad":"yelp_stars5_text = yelp_text_stars5['Text'].values\n\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(yelp_stars5_text))\n\nfig = plt.figure(\n    figsize = (10, 7),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)","c6ab7c53":"X = yelp_df['Text']\ny = yelp_df['Stars']\ncv = CountVectorizer()\nX = cv.fit_transform(X)\n\ntest_size = np.linspace(0.1, 1, num=9, endpoint=False)\nrandom_state = np.arange(0, 43)\ngrid_results= []\nfor testsize in test_size:\n    for randomstate in random_state:\n        try:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize, random_state=randomstate)\n            mnb = MultinomialNB()\n            mnb.fit(X_train, y_train)\n            y_test_pred = mnb.predict(X_test)     \n            grid_results.append([testsize, randomstate, mean_squared_error(y_test, y_test_pred)])\n            grid_frame = pd.DataFrame(grid_results)\n            grid_frame.rename(columns={0:'Test Size', 1:'Random State', 2:'MSE of Test'}, inplace=True)\n        except Exception:\n            print(Exception.with_traceback())\n            print('error')\n            continue\n\nmin_test_mse = grid_frame[grid_frame['MSE of Test'] == grid_frame['MSE of Test'].min()]\nmin_test_mse","5a31686b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=21)\nmnb = MultinomialNB()\nmnb.fit(X_train, y_train)\ny_test_pred = mnb.predict(X_test)\nprint(classification_report(y_test,y_test_pred))","bf47df62":"tfidf_transformer = TfidfTransformer().fit(X)\nX = tfidf_transformer.transform(X)\n\ngrid_results= []\nfor testsize in test_size:\n    for randomstate in random_state:\n        try:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize, random_state=randomstate)\n            mnb = MultinomialNB()\n            mnb.fit(X_train, y_train)\n            y_test_pred = mnb.predict(X_test)     \n            grid_results.append([testsize, randomstate, mean_squared_error(y_test, y_test_pred)])\n            grid_frame = pd.DataFrame(grid_results)\n            grid_frame.rename(columns={0:'Test Size', 1:'Random State', 2:'MSE of Test'}, inplace=True)\n        except Exception:\n            print(Exception.with_traceback())\n            print('error')\n            continue\n\nmin_test_mse = grid_frame[grid_frame['MSE of Test'] == grid_frame['MSE of Test'].min()]\nmin_test_mse","c6f435a0":"warnings.filterwarnings(\"ignore\")\npipeline = Pipeline([('bow', CountVectorizer()), \n                     ('tfidf', TfidfTransformer()), \n                     ('classifier', MultinomialNB())])\n\nX = yelp_df['Text']\ny = yelp_df['Stars']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=31)\npipeline.fit(X_train, y_train)\ny_test_pred = pipeline.predict(X_test)\nprint(classification_report(y_test,y_test_pred))","eed471c9":"yelp_df12 = yelp_df[(yelp_df.Stars==1) | (yelp_df.Stars==5)]\nX = yelp_df12['Text']\ny = yelp_df12['Stars']\ncv = CountVectorizer()\nX = cv.fit_transform(X)\n\ntest_size = np.linspace(0.1, 1, num=9, endpoint=False)\nrandom_state = np.arange(0, 43)\ngrid_results= []\nfor testsize in test_size:\n    for randomstate in random_state:\n        try:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize, random_state=randomstate)\n            mnb = MultinomialNB()\n            mnb.fit(X_train, y_train)\n            y_test_pred = mnb.predict(X_test)     \n            grid_results.append([testsize, randomstate, mean_squared_error(y_test, y_test_pred)])\n            grid_frame = pd.DataFrame(grid_results)\n            grid_frame.rename(columns={0:'Test Size', 1:'Random State', 2:'MSE of Test'}, inplace=True)\n        except Exception:\n            print(Exception.with_traceback())\n            print('error')\n            continue\n\nmin_test_mse = grid_frame[grid_frame['MSE of Test'] == grid_frame['MSE of Test'].min()]\nmin_test_mse","d234690a":"pipeline = Pipeline([('bow', CountVectorizer()), \n                     ('classifier', MultinomialNB())])\n\nX = yelp_df12['Text']\ny = yelp_df12['Stars']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=36)\npipeline.fit(X_train, y_train)\ny_test_pred = pipeline.predict(X_test)\nprint(classification_report(y_test,y_test_pred))","e212cbd0":"#### Stars 1 and 5 Words Frequency and Word Cloud","0cf2f218":"### Data Vasulization - Feature Engineering\nIn this part, we will conduct descriptive analysis for all variables and then explore the relationship between 'Stars' and other variables.","a10ad6ad":"### Basic Operations for Data\nKeep meaningful columns and rename variables","896842b1":"Based on these two result, the more accurate results come from Stars5 and Stars1 - the highest star and lowest star. Let's check it by only predict Stars5 and Stars1. And we can not ignore the fact that TF-IDF actually does not improve the accuracy in this case. It may work for other cases. However, for Yelp Reviews, we have to remove it.","5e601174":"## Ingest","a10fbb33":"A complete data set, without null values. A very good beginning for data analysis","ba36fcb4":"## Exploratory Data Analysis","767bf086":"#### Descriptive Analysis","332fe803":"## Build up ML Model","d7f4a4d1":"### Text Analysis\nFor text analysis, we need to remove all punctuations and stopwords. Then we can get word frequency and make some preparations for further building up model.","bdedf173":"#### All Stars Word Frequency and Word Cloud","48a56932":"#### ML using TF-IDF\nTypically, the tf-idf weight is composed by two terms: the first computes the normalized Term Frequency (TF), aka. the number of times a word appears in a document, divided by the total number of words in that document, measuring how frequently a term occures in document; the second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears, measuring how important a term is.\n","7c94d242":"### ML for All Stars","2e3f1a24":"#### Correlation between Label and Other Variables","cfc1c94d":"#### ML without TF-IDF\nCurrently, what we have is 'text', which cannot be recoganized by machine learning model. We need to transfer those texts to vectors that can be used in machine learning model. What's more, let's first build up a machine learning model without using TF-IDF (term frequency-inverse document frequency. The tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus.","9c623f54":"## Conclusions\n1. For restaurants of Yelp, food and service mean everything. We can find that no matter what star one kinds of restaurants get, more frequent words are food, service and some other words (delicious, friendly, etc.) that are used to describe the quality of them. Therefore, for all restaurants, please leave other factors along and just focus on improving your food and service. This will definitely help you a lot\n2. For Yelp reviews, the machine learning model can predict highest and lowest levels using customers' reviews with best accuracy. And during the process of building up model, we must remove some other numerical variables and just keep texts as independent variable. Also, though TF-IDF is a very advanced method to increase the accuracy, please do not use TF-IDF (it will lower the accuracy) for Yelp reviews analysis.","ebffb305":"### ML for Stars 1 and 5","3bdb847a":"The heatmap, pairplot and boxplot verify that those other numerical variables cannot be used to predict 'Stars'. Therefore, we have to focus on text analysis.","355f7357":"# NLP for Yelp Reviews\nThis notebook aims at using NLP to help Yelp restaurants find their advantages and disadvantages and provide some suggestions about how to improve themselves. Also, the notebook realizes applying machine learning model of texts to predict stars.\n\n![Yelp](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/a\/ad\/Yelp_Logo.svg\/1200px-Yelp_Logo.svg.png)","1d5cc9a8":"The heatmap shows that there is no correlation between stars and other other variables(the coefficients approximate zero). Let use pairplot to check whether other variables can be used to distinguish 'Stars'","0d867e8c":"These precision results show that we can predict highest and lowest levels with very high accuracy, indicating that we can just focus on these two levels and summarize what yelp should keep when it gets highest star and what it should imporve when it gets lowest star. And these summarizations will come from words frequency analysis which has been conducted above."}}