{"cell_type":{"1f8bd7c7":"code","79f614b4":"code","019ca07c":"code","864e24fa":"code","1b8a22ee":"code","15b25b09":"code","852121b6":"code","63d1609d":"code","1521bd90":"code","97768c5e":"code","75aac267":"code","703e8415":"code","6188e7f3":"code","e370d725":"code","4c4d0125":"code","ffe93a57":"code","e25c23d4":"code","1b3443e6":"code","f8e1893a":"code","3ef5dfc9":"code","93d2de34":"code","bd470767":"code","bc3e5e55":"code","df706800":"code","d3624f9a":"code","a725a78a":"code","b36f5ad9":"code","96f4e709":"code","4af4f62f":"code","6e67c20c":"code","a237cfc3":"code","b43021dc":"code","bb216bb4":"code","0f736a50":"code","4523d97d":"code","54dcc652":"code","4385fba2":"code","1c004a4a":"code","65520d16":"code","d9323120":"code","18ef86ac":"code","5b56bb6b":"code","1e933c03":"code","dd0ee01f":"code","3ad30a39":"markdown","0aa617ca":"markdown","d660f97a":"markdown","0c84386f":"markdown","81d34012":"markdown","c8ab37f8":"markdown","ca4a83cf":"markdown","fb566026":"markdown","9f4fe62c":"markdown","4b876c6f":"markdown","7a837e4e":"markdown","d8c4abcf":"markdown","67394f78":"markdown","c6428832":"markdown","af3c75dd":"markdown","d5598166":"markdown","a97c7cf2":"markdown","cf59c7d4":"markdown","dfcd1c10":"markdown","349629b2":"markdown","76a08574":"markdown","c7e13d04":"markdown","2be8c2d6":"markdown","421c2d9d":"markdown","091ff553":"markdown"},"source":{"1f8bd7c7":"# Supressing the warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","79f614b4":"# Reading the dataset\nimport pandas as pd\nimport numpy as np\nBostonData=pd.read_csv(\"..\/input\/boston\/BostonHousingData.csv\", encoding='latin')\nprint('Shape before deleting duplicate values:', BostonData.shape)\n\n# Removing duplicate rows if any\nBostonData=BostonData.drop_duplicates()\nprint('Shape After deleting duplicate values:', BostonData.shape)\n\n# Printing sample data\n# Start observing the Quantitative\/Categorical\/Qualitative variables\nBostonData.head(10)","019ca07c":"%matplotlib inline\n# Creating Bar chart as the Target variable is Continuous\nBostonData['MEDV'].hist()","864e24fa":"BostonData.head()","1b8a22ee":"BostonData.info()","15b25b09":"BostonData.describe(include='all')","852121b6":"BostonData.nunique()","63d1609d":"def PlotBarCharts(inpData, colsToPlot):\n    %matplotlib inline\n    \n    import matplotlib.pyplot as plt\n    \n    # Generating multiple subplots\n    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))\n    fig.suptitle('Bar charts of: '+ str(colsToPlot))\n\n    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):\n        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])","1521bd90":"PlotBarCharts(inpData=BostonData, colsToPlot=['CHAS','RAD'])","97768c5e":"BostonData.hist(['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX',\n                 'PTRATIO', 'B', 'LSTAT'], figsize=(18,10))","75aac267":"BostonData['CRIM'][BostonData['CRIM']<60].sort_values(ascending=False)","703e8415":"# Replacing outliers with nearest possibe value\nBostonData['CRIM'][BostonData['CRIM']>60] =51.13","6188e7f3":"BostonData.hist(['CRIM'], figsize=(18,5))","e370d725":"# Finding how many missing values are there for each column\nBostonData.isnull().sum()","4c4d0125":"ContinuousCols=['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX',\n                 'PTRATIO', 'B', 'LSTAT']\n\n# Plotting scatter chart for each predictor vs the target variable\nfor predictor in ContinuousCols:\n    BostonData.plot.scatter(x=predictor, y='MEDV', figsize=(10,5), title=predictor+\" VS \"+ 'MEDV')","ffe93a57":"# Calculating correlation matrix\nContinuousCols=['MEDV','CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX',\n                 'PTRATIO', 'B', 'LSTAT']\n\n# Creating the correlation matrix\nCorrelationData=BostonData[ContinuousCols].corr()\nCorrelationData","e25c23d4":"CorrelationData['MEDV'][abs(CorrelationData['MEDV']) > 0.5 ]","1b3443e6":"CategoricalColsList=['RAD', 'ZN']\n\nimport matplotlib.pyplot as plt\nfig, PlotCanvas=plt.subplots(nrows=1, ncols=len(CategoricalColsList), figsize=(18,5))\n\n# Creating box plots for each continuous predictor against the Target Variable \"MEDV\"\nfor PredictorCol , i in zip(CategoricalColsList, range(len(CategoricalColsList))):\n    BostonData.boxplot(column='MEDV', by=PredictorCol, figsize=(5,5), vert=True, ax=PlotCanvas[i])","f8e1893a":"# Defining a function to find the statistical relationship with all the categorical variables\ndef FunctionAnova(inpData, TargetVariable, CategoricalPredictorList):\n    from scipy.stats import f_oneway\n\n    # Creating an empty list of final selected predictors\n    SelectedPredictors=[]\n    \n    print('##### ANOVA Results ##### \\n')\n    for predictor in CategoricalPredictorList:\n        CategoryGroupLists=inpData.groupby(predictor)[TargetVariable].apply(list)\n        AnovaResults = f_oneway(*CategoryGroupLists)\n        \n        # If the ANOVA P-Value is <0.05, that means we reject H0\n        if (AnovaResults[1] < 0.05):\n            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n            SelectedPredictors.append(predictor)\n        else:\n            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n    \n    return(SelectedPredictors)","3ef5dfc9":"# Calling the function to check which categorical variables are correlated with target\nCategoricalPredictorList=['RAD', 'ZN']\nFunctionAnova(inpData=BostonData, \n              TargetVariable='MEDV', \n              CategoricalPredictorList=CategoricalPredictorList)","93d2de34":"SelectedColumns=['RM', 'PTRATIO','LSTAT', 'RAD', 'ZN']\n\n# Selecting final columns\nDataForML=BostonData[SelectedColumns]\nDataForML.head()","bd470767":"DataForML.to_pickle('DataForML.pkl')","bc3e5e55":"# Treating all the nominal variables at once using dummy variables\nDataForML_Numeric=pd.get_dummies(DataForML)\n\n# Adding Target Variable to the data\nDataForML_Numeric['MEDV']=BostonData['MEDV']\n\n# Printing sample rows\nDataForML_Numeric.head()","df706800":"# Printing all the column names for our reference\nDataForML_Numeric.columns","d3624f9a":"# Separate Target Variable and Predictor Variables\nTargetVariable='MEDV'\nPredictors=['RM', 'PTRATIO', 'LSTAT', 'RAD', 'ZN']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)","a725a78a":"### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","b36f5ad9":"# Sanity check for the sampled data\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","96f4e709":"# Multiple Linear Regression\nfrom sklearn.linear_model import LinearRegression\nRegModel = LinearRegression()\n\n# Printing all the parameters of Linear regression\nprint(RegModel)\n\n# Creating the model on Training Data\nLREG=RegModel.fit(X_train,y_train)\nprediction=LREG.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, LREG.predict(X_train)))\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['MEDV']-TestingDataResults['PredictedMEDV']))\/TestingDataResults['MEDV'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","4af4f62f":"# Decision Trees (Multiple if-else statements!)\nfrom sklearn.tree import DecisionTreeRegressor\nRegModel = DecisionTreeRegressor(max_depth=4,criterion='mse')\n# Good Range of Max_depth = 2 to 20\n\n# Printing all the parameters of Decision Tree\nprint(RegModel)\n\n# Creating the model on Training Data\nDT=RegModel.fit(X_train,y_train)\nprediction=DT.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, DT.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DT.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['MEDV']-TestingDataResults['PredictedMEDV']))\/TestingDataResults['MEDV'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","6e67c20c":"# Random Forest (Bagging of multiple Decision Trees)\nfrom sklearn.ensemble import RandomForestRegressor\nRegModel = RandomForestRegressor(max_depth=4, n_estimators=400,criterion='mse')\n# Good range for max_depth: 2-10 and n_estimators: 100-1000\n\n# Printing all the parameters of Random Forest\nprint(RegModel)\n\n# Creating the model on Training Data\nRF=RegModel.fit(X_train,y_train)\nprediction=RF.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, RF.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['MEDV']-TestingDataResults['PredictedMEDV']))\/TestingDataResults['MEDV'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","a237cfc3":"# Adaboost (Boosting of multiple Decision Trees)\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Choosing Decision Tree with 1 level as the weak learner\nDTR=DecisionTreeRegressor(max_depth=5)\nRegModel = AdaBoostRegressor(n_estimators=200, base_estimator=DTR ,learning_rate=0.04)\n\n# Printing all the parameters of Adaboost\nprint(RegModel)\n\n# Creating the model on Training Data\nAB=RegModel.fit(X_train,y_train)\nprediction=AB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, AB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(AB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['MEDV']-TestingDataResults['PredictedMEDV']))\/TestingDataResults['MEDV'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","b43021dc":"# Xtreme Gradient Boosting (XGBoost)\nfrom xgboost import XGBRegressor\nRegModel=XGBRegressor(max_depth=2, \n                      learning_rate=0.1, \n                      n_estimators=1000, \n                      objective='reg:linear', \n                      booster='gbtree')\n\n# Printing all the parameters of XGBoost\nprint(RegModel)\n\n# Creating the model on Training Data\nXGB=RegModel.fit(X_train,y_train)\nprediction=XGB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, XGB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(XGB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['MEDV']-TestingDataResults['PredictedMEDV']))\/TestingDataResults['MEDV'])\n\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","bb216bb4":"# K-Nearest Neighbor(KNN)\nfrom sklearn.neighbors import KNeighborsRegressor\nRegModel = KNeighborsRegressor(n_neighbors=3)\n\n# Printing all the parameters of KNN\nprint(RegModel)\n\n# Creating the model on Training Data\nKNN=RegModel.fit(X_train,y_train)\nprediction=KNN.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, KNN.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n# The variable importance chart is not available for KNN\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['MEDV']-TestingDataResults['PredictedMEDV']))\/TestingDataResults['MEDV'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))# K-Nearest Neighbor(KNN)\nfrom sklearn.neighbors import KNeighborsRegressor\nRegModel = KNeighborsRegressor(n_neighbors=3)\n\n# Printing all the parameters of KNN\nprint(RegModel)\n\n# Creating the model on Training Data\nKNN=RegModel.fit(X_train,y_train)\nprediction=KNN.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, KNN.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n# The variable importance chart is not available for KNN\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['MEDV']-TestingDataResults['PredictedMEDV']))\/TestingDataResults['MEDV'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","0f736a50":"# Support Vector Machines(SVM)\nfrom sklearn import svm\nRegModel = svm.SVR(C=50, kernel='rbf', gamma=0.01)\n\n# Printing all the parameters\nprint(RegModel)\n\n# Creating the model on Training Data\nSVM=RegModel.fit(X_train,y_train)\nprediction=SVM.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, SVM.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n# The built in attribute SVM.coef_ works only for linear kernel\n%matplotlib inline\n#feature_importances = pd.Series(SVM.coef_[0], index=Predictors)\n#feature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['MEDV']-TestingDataResults['PredictedMEDV']))\/TestingDataResults['MEDV'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","4523d97d":"# Separate Target Variable and Predictor Variables\nTargetVariable='MEDV'\n\n# Selecting the final set of predictors for the deployment\n# Based on the variable importance charts of multiple algorithms above\nPredictors=['LSTAT', 'RM', 'PTRATIO']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\nprint(X.shape)\nprint(y.shape)","54dcc652":"# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# choose from different tunable hyper parameters\nfrom xgboost import XGBRegressor\nRegModel=XGBRegressor(max_depth=2, \n                      learning_rate=0.1, \n                      n_estimators=1000, \n                      objective='reg:linear', \n                      booster='gbtree')\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","4385fba2":"Final_XGB_Model=RegModel.fit(X,y)","1c004a4a":"import pickle\nimport os\n\n# Saving the Python objects as serialized files can be done using pickle library\n# Here let us save the Final model\nwith open('Final_XGB_Model.pkl', 'wb') as fileWriteStream:\n    pickle.dump(Final_XGB_Model, fileWriteStream)\n    # Don't forget to close the filestream!\n    fileWriteStream.close()\n    \nprint('pickle file of Predictive Model is saved at Location:',os.getcwd())","65520d16":"# This Function can be called from any from any front end tool\/website\ndef FunctionPredictResult(InputData):\n    import pandas as pd\n    Num_Inputs=InputData.shape[0]\n    \n    # Making sure the input data has same columns as it was used for training the model\n    # Also, if standardization\/normalization was done, then same must be done for new input\n    \n    # Appending the new data with the Training data\n    DataForML=pd.read_pickle('DataForML.pkl')\n    InputData=InputData.append(DataForML)\n    \n    # Generating dummy variables for rest of the nominal variables\n    InputData=pd.get_dummies(InputData)\n            \n    # Maintaining the same order of columns as it was during the model training\n    Predictors=['LSTAT', 'RM', 'PTRATIO']\n    \n    # Generating the input values to the model\n    X=InputData[Predictors].values[0:Num_Inputs]\n    \n    # Generating the standardized values of X since it was done while model training also\n    X=PredictorScalerFit.transform(X)\n    \n    # Loading the Function from pickle file\n    import pickle\n    with open('Final_XGB_Model.pkl', 'rb') as fileReadStream:\n        PredictionModel=pickle.load(fileReadStream)\n        # Don't forget to close the filestream!\n        fileReadStream.close()\n            \n    # Genrating Predictions\n    Prediction=PredictionModel.predict(X)\n    PredictionResult=pd.DataFrame(Prediction, columns=['Prediction'])\n    return(PredictionResult)","d9323120":"# Calling the function for some loan applications\nNewSampleData=pd.DataFrame(\ndata=[[4.98,6.575,15.3],\n     [4.98,3.2,10.3]],\ncolumns=['LSTAT', 'RM', 'PTRATIO'])\n\nprint(NewSampleData)\n\n# Calling the Function for prediction\nFunctionPredictResult(InputData= NewSampleData)","18ef86ac":"# Creating the function which can take inputs and return prediction\ndef FunctionGeneratePrediction(inp_LSTAT , inp_RM, inp_PTRATIO):\n    \n    # Creating a data frame for the model input\n    SampleInputData=pd.DataFrame(\n     data=[[inp_LSTAT , inp_RM, inp_PTRATIO]],\n     columns=['LSTAT', 'RM', 'PTRATIO'])\n\n    # Calling the function defined above using the input parameters\n    Predictions=FunctionPredictResult(InputData= SampleInputData)\n\n    # Returning the predictions\n    return(Predictions.to_json())\n\n# Function call\nFunctionGeneratePrediction( inp_LSTAT=4.98,\n                           inp_RM=6.5,\n                           inp_PTRATIO=15.3\n                             )","5b56bb6b":"from flask import Flask, request, jsonify\nimport pickle\nimport pandas as pd\nimport numpy","1e933c03":"app = Flask(__name__)\n\n@app.route('\/prediction_api', methods=[\"GET\"])\ndef prediction_api():\n    try:\n        # Getting the paramters from API call\n        LSTAT_value = float(request.args.get('LSTAT'))\n        RM_value=float(request.args.get('RM'))\n        PTRATIO_value=float(request.args.get('PTRATIO'))\n                \n        # Calling the funtion to get predictions\n        prediction_from_api=FunctionGeneratePrediction(\n                                                       inp_LSTAT=LSTAT_value,\n                                                       inp_RM=RM_value,\n                                                       inp_PTRATIO=PTRATIO_value\n                                                )\n\n        return (prediction_from_api)\n    \n    except Exception as e:\n        return('Something is not right!:'+str(e))","dd0ee01f":"import os\nif __name__ ==\"__main__\":\n    \n    # Hosting the API in localhost\n    app.run(host='127.0.0.1', port=8080, threaded=True, debug=True, use_reloader=False)\n    # Interrupt kernel to stop the API","3ad30a39":"# Machine Learning: Splitting the data into Training and Testing sample","0aa617ca":"# Function for predictions API","d660f97a":"# Looking at the distribution of Target variable\n","0c84386f":"# Decision Trees","81d34012":"Data description\nThe business meaning of each column in the data is as below\n\nCRIM - per capita crime rate by town\n\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n\nINDUS - proportion of non-retail business acres per town.\n\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n\nNOX - nitric oxides concentration (parts per 10 million)\n\nRM - average number of rooms per dwelling\n\nAGE - proportion of owner-occupied units built prior to 1940\n\nDIS - weighted distances to five Boston employment centres\n\nRAD - index of accessibility to radial highways\n\nTAX - full-value property-tax rate per 10,000 dollars\n\nPTRATIO - pupil\/teacher ratio by town\n\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n\nLSTAT - % lower status of the population\n\nMEDV - Median value of owner-occupied homes in $1000's\n","c8ab37f8":"# Creating Flask API","ca4a83cf":"# Basic Data Exploration","fb566026":"# Statistical Feature Selection (Categorical Vs Continuous) using ANOVA test","9f4fe62c":"# Statistical Feature Selection (Continuous Vs Continuous) using Correlation value","4b876c6f":"# Multiple Linear Regression","7a837e4e":"# Deployment of the Model","d8c4abcf":"# Relationship exploration: Continuous Vs Continuous -- Scatter Charts","67394f78":"# Relationship exploration: Categorical Vs Continuous -- Box Plots","c6428832":"# SVM","af3c75dd":"# Starting the API engine","d5598166":"# Visualizing distribution after outlier treatment","a97c7cf2":"Replacing outliers for 'CRIM'","cf59c7d4":"# XGBoost","dfcd1c10":"# Standardization\/Normalization of data","349629b2":"# Random Forest","76a08574":"# Converting the nominal variable to numeric using get_dummies()","c7e13d04":"# AdaBoost","2be8c2d6":"# Selecting final predictors for Machine Learning","421c2d9d":"# KNN","091ff553":"# Visualize distribution of all the Categorical Predictor variables in the data using bar plots"}}