{"cell_type":{"f26fca5d":"code","aba695dc":"code","043b0c7e":"code","ae4e669b":"code","60149fbb":"code","159c67d9":"code","5ecd07f9":"code","c98576f7":"code","b747e916":"code","75e5d33f":"code","3ba59e91":"code","6d54144d":"code","6514ec69":"code","53daa910":"code","b4a51ae9":"code","c0ed4d30":"code","05b0fc43":"code","0a952ff0":"code","a4de23cd":"code","44fd2ca1":"code","d84bc346":"code","e97b8dde":"code","33c7095c":"code","8c6cd9ea":"code","1155e42c":"code","a0a2acdd":"code","03c0bf3b":"code","fa1dc9df":"code","94c1a3a1":"code","e1c1866f":"code","491fa2c7":"code","e0460593":"code","c3b6bad5":"code","843dcc73":"code","5e5177f5":"code","4df26d51":"code","d5242f17":"code","95c74841":"code","b4bb5873":"markdown"},"source":{"f26fca5d":"from albumentations.pytorch import ToTensor\nfrom albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma, OneOf, Resize,\n    ToFloat, ShiftScaleRotate, GridDistortion, RandomRotate90, Cutout,\n    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise, CoarseDropout,\n    IAAAdditiveGaussianNoise, GaussNoise, OpticalDistortion, RandomSizedCrop, VerticalFlip, Normalize\n)\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom torch.utils.data import DataLoader\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as t\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom sklearn import metrics\n\n!pip install --upgrade efficientnet_pytorch\nfrom efficientnet_pytorch import EfficientNet\nfrom tqdm.notebook import tqdm\n","aba695dc":"import scipy\n\nfrom numpy import pi\nfrom numpy import sin\nfrom numpy import zeros\nfrom numpy import r_\nfrom scipy import signal\nfrom scipy import misc # pip install Pillow\nimport matplotlib.pylab as pylab\n\n%matplotlib inline\npylab.rcParams['figure.figsize'] = (20.0, 7.0)","043b0c7e":"import random\n\nseed = 42\nprint(f'setting everything to seed {seed}')\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","ae4e669b":"data_dir = '..\/input\/alaska2-image-steganalysis'\nfolder_names = ['JMiPOD\/', 'JUNIWARD\/', 'UERD\/']\nclass_names = ['Normal', 'JMiPOD_75', 'JMiPOD_90', 'JMiPOD_95', \n               'JUNIWARD_75', 'JUNIWARD_90', 'JUNIWARD_95',\n                'UERD_75', 'UERD_90', 'UERD_95']\nclass_labels = { name: i for i, name in enumerate(class_names)}\nnum_classes = len(class_labels)","60149fbb":"train_df = pd.read_csv('..\/input\/alaska2trainvalsplit\/alaska2_train_df.csv')\nval_df = pd.read_csv('..\/input\/alaska2trainvalsplit\/alaska2_val_df.csv')\n\nprint(train_df.head(10))\ntrain_df.Label.hist()\nplt.title('Distribution of Classes')","159c67d9":"#train_df = train_df.sample(1000)\n#val_df = val_df.sample(500)\n#train_df,val_df","5ecd07f9":"import scipy\nimport os\nimport numpy as np\nimport pandas as pd\nfrom numpy import pi\nfrom numpy import sin\nfrom numpy import zeros\nfrom numpy import r_\nfrom scipy import signal\nfrom scipy import misc #pip install Pillow\nfrom scipy import fftpack\nimport matplotlib.pylab as pylab\n\n%matplotlib inline\npylab.rcParams['figure.figsize'] = (20.0, 7.0)\n","c98576f7":"def dct2(a):\n    return scipy.fftpack.dct( scipy.fftpack.dct( a, axis=0, norm='ortho' ), axis=1, norm='ortho' )\n\ndef idct2(a):\n    return scipy.fftpack.idct( scipy.fftpack.idct( a, axis=0 , norm='ortho'), axis=1 , norm='ortho')","b747e916":"def dct_ext(img):\n    imsize = img.shape\n    dct = np.zeros(imsize)\n    for i in r_[:imsize[0]:8]:\n        for j in r_[:imsize[1]:8]:\n            dct[i:(i+8),j:(j+8)] = dct2( img[i:(i+8),j:(j+8)] )\n\n    thresh = 0.02\n    dct_thresh = dct * (abs(dct) > (thresh*np.max(dct)))\n    return dct_thresh","75e5d33f":"from torch.utils.data import Dataset\nimport cv2\n\nclass Alaska(Dataset):\n    \n    def __init__(self, dataframe, trans = None):\n        self.data = dataframe\n        self.transform = trans\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        fname, target = self.data.iloc[idx]\n        img = cv2.imread(fname)[:, :, ::-1]\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n        #img\/= 255\n        #img = dct_ext(img)\n        \n        if self.transform:\n            img = self.transform(image = img)\n        x = (img['image'], target)\n        \n        return x","3ba59e91":"augmentations_train = Compose([\n    #Resize(512, 512, p=1), \n    VerticalFlip(p=0.5),\n    HorizontalFlip(p=0.5),\n    ToFloat(max_value=255),\n    ToTensor()\n],p=1)\n\naugmentations_test = Compose([\n    #Resize(512, 512, p=1),\n    ToFloat(max_value=255),\n    ToTensor()\n])","6d54144d":"train_ds = Alaska(train_df, trans = augmentations_train)\nval_ds = Alaska(val_df, trans = augmentations_test)\ntrain_ds","6514ec69":"len(train_ds)","53daa910":"img, lab = train_ds[200]\nplt.imshow(img.permute(1,2,0))","b4a51ae9":"batch_size = 64\nnum_workers = 0\n\ntemp_dl = DataLoader(train_ds, batch_size = batch_size, num_workers = num_workers, shuffle=True)\n","c0ed4d30":"import gc\n\nimages, labels = next(iter(temp_dl))\nimages = images.permute(0, 2, 3, 1)\nmax_images = 64\ngrid_width = 16\ngrid_height = int(max_images \/ grid_width)\nfig, axs = plt.subplots(grid_height, grid_width,\n                        figsize=(grid_width+1, grid_height+1))\n\nfor i, (im, label) in enumerate(zip(images, labels)):\n    ax = axs[int(i \/ grid_width), i % grid_width]\n    ax.imshow(im.squeeze())\n    ax.set_title(str(label.item()))\n    ax.axis('off')\n\nplt.suptitle(\"0: No Hidden Message, 1: JMiPOD, 2: JUNIWARD, 3:UERD\")\nplt.show()\ndel images, temp_dl\ngc.collect()","05b0fc43":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndef to_device(data, device):\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking = True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n            \n    def __len__(self):\n        return len(self.dl)\n        ","0a952ff0":"device = get_default_device()","a4de23cd":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = EfficientNet.from_pretrained('efficientnet-b0')\n        # b0 => 1280\n        self.dense_output = nn.Linear(1280, num_classes)\n\n    def forward(self, x):\n        feat = self.model.extract_features(x)\n        feat = F.avg_pool2d(feat, feat.size()[2:]).reshape(-1, 1280)\n        return self.dense_output(feat)\n        ","44fd2ca1":"model = Net()","d84bc346":"# https:\/\/www.kaggle.com\/anokas\/weighted-auc-metric-updated\n\ndef alaska_weighted_auc(y_true, y_valid):\n    tpr_thresholds = [0.0, 0.4, 1.0]\n    weights = [2,   1]\n\n    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_valid, pos_label=1)\n\n    # size of subsets\n    areas = np.array(tpr_thresholds[1:]) - np.array(tpr_thresholds[:-1])\n\n    # The total area is normalized by the sum of weights such that the final weighted AUC is between 0 and 1.\n    normalization = np.dot(areas, weights)\n\n    competition_metric = 0\n    for idx, weight in enumerate(weights):\n        y_min = tpr_thresholds[idx]\n        y_max = tpr_thresholds[idx + 1]\n        mask = (y_min < tpr) & (tpr < y_max)\n        # pdb.set_trace()\n\n        x_padding = np.linspace(fpr[mask][-1], 1, 100)\n\n        x = np.concatenate([fpr[mask], x_padding])\n        y = np.concatenate([tpr[mask], [y_max] * len(x_padding)])\n        y = y - y_min  # normalize such that curve starts at y=0\n        score = metrics.auc(x, y)\n        submetric = score * weight\n        best_subscore = (y_max - y_min) * weight\n        competition_metric += submetric\n\n    return competition_metric \/ normalization","e97b8dde":"def loss_batch(model, loss_func, xb, yb, opt = None, metric = None):\n    preds = model(xb)\n    \n    loss = loss_func(preds, yb)\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        \n    metric_result = None\n    if metric is not None:\n        metric_result = metric(preds, yb)\n    return loss.item(), len(xb), metric_result","33c7095c":"def evaluate(model, loss_fn, valid_dl, metric = None):\n    labs, predictions = [], []\n    with torch.no_grad():\n        for imgs, labels in valid_dl:\n            imgs = imgs.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.long)\n            preds = model(imgs)\n            loss = loss_fn(preds, labels)\n            \n            labs.extend(labels.cpu().numpy().astype(int))\n            predictions.extend(F.softmax(preds, 1).cpu().numpy())\n                \n        results = [loss_batch(model, loss_fn, xb, yb, metric = metric) \n                          for xb, yb in valid_dl]\n        losses, nums, metrics = zip(*results)\n\n        predictions = np.array(predictions)\n        pred_labels = predictions.argmax(1)\n        \n        eval_accuracy = (pred_labels == labs).mean()\n        \n        new_preds = np.zeros(len(predictions))\n        temp = predictions[pred_labels != 0, 1:]\n\n        new_preds[pred_labels != 0] = temp.sum(1)\n        new_preds[pred_labels == 0] = 1 - predictions[pred_labels == 0, 0]\n        labs = np.array(labs)\n        labs[labs != 0] = 1\n        \n        auc_score = alaska_weighted_auc(labs, new_preds)\n        \n        total = np.sum(nums)\n    \n        avg_loss = np.sum(np.multiply(losses, nums))\/total\n    \n        avg_metric = None\n        if metric is not None:\n            avg_metric = np.sum(np.multiply(metrics, nums))\/total\n    return avg_loss, total, avg_metric, auc_score, eval_accuracy","8c6cd9ea":"def fit(epochs, model, loss_fn, train_dl, valid_dl, opt_fn = None, lr = None, metric = None):\n    train_losses, val_losses, val_metrics, auc_metrics, eval_metrics = [], [], [], [], []\n    \n    if opt_fn is None: opt_fn = torch.optim.SGD\n    opt = opt_fn(model.parameters(), lr = lr)\n    \n    for epoch in range (epochs):\n        model.train()\n        for xb, yb in train_dl:\n            train_loss, _, _ =loss_batch(model, loss_fn, xb, yb, opt)\n            \n        model.eval()\n        result = evaluate(model, loss_fn, valid_dl, metric)\n        val_loss, total, val_metric, auc_score, eval_accuracy = result\n        \n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_metrics.append(val_metric)\n        auc_metrics.append(auc_score)\n        eval_metrics.append(eval_accuracy)\n        \n        if metric is None:\n            print('Epoch [{}\/{}], train_loss: {:4f}, val_loss: {:.4f}'\n                  .format(epoch+1, epochs, train_loss, val_loss))\n        else:\n            print('Epoch [{}\/{}], train_loss: {:4f}, val_loss: {:.4f}, val_{}: {:.4f},auc_score: {:.4f}, eval_accuracy: {:.4f}'\n                 .format(epoch+1, epochs, train_loss, val_loss, metric.__name__, val_metric, auc_score, eval_accuracy))\n    return train_losses, val_losses, val_metrics, auc_metrics, eval_metrics","1155e42c":"def accuracy(outputs, labels):\n    _,preds = torch.max(outputs, dim = 1)\n    return torch.sum(preds == labels).item()\/len(preds)","a0a2acdd":"batch_size = 8\nnum_workers = 8\n\ntrain_dl = DataLoader(train_ds, batch_size = batch_size, num_workers = num_workers, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size = batch_size, num_workers = num_workers, shuffle=False)\n","03c0bf3b":"model = Net() \ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device)\n","fa1dc9df":"def load_cp(cp):\n    model.load_state_dict(cp['model_state'])\n    ","94c1a3a1":"for p in model.parameters():\n    print(p)","e1c1866f":"cp = torch.load('..\/input\/checkpoint\/checkpoint26102020.pth')\nload_cp(cp)","491fa2c7":"for p in model.parameters():\n    print(p)","e0460593":"num_epochs = 2\nopt_fn = torch.optim.AdamW\nlr = 1e-4","c3b6bad5":"x = fit(num_epochs, model, F.cross_entropy, train_dl, val_dl, opt_fn, lr, metric = accuracy)\ntrain_losses, val_losses, val_metrics, auc_metrics, eval_metrics = x","843dcc73":"import glob\nclass Alaska2TestDataset(Dataset):\n\n    def __init__(self, df, augmentations=None):\n\n        self.data = df\n        self.augment = augmentations\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        fn = self.data.loc[idx][0]\n        im = cv2.imread(fn)[:, :, ::-1]\n\n        if self.augment:\n            # Apply transformations\n            im = self.augment(image=im)\n\n        return im\n\n\ntest_filenames = sorted(glob.glob(f\"{data_dir}\/Test\/*.jpg\"))\ntest_df = pd.DataFrame({'ImageFileName': list(\n    test_filenames)}, columns=['ImageFileName'])\n\nbatch_size = 16\nnum_workers = 4\ntest_dataset = Alaska2TestDataset(test_df, augmentations=augmentations_test)\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=batch_size,\n                                          num_workers=num_workers,\n                                          shuffle=False,\n                                          drop_last=False)","5e5177f5":"model.eval()\n\npreds = []\ntk0 = tqdm(test_loader)\nwith torch.no_grad():\n    for i, im in enumerate(tk0):\n        inputs = im[\"image\"].to(device)\n        # flip vertical\n        im = inputs.flip(2)\n        outputs = model(im)\n        # fliplr\n        im = inputs.flip(3)\n        outputs = (0.25*outputs + 0.25*model(im))\n        outputs = (outputs + 0.5*model(inputs))\n        labels = labels.to(device, dtype=torch.long)\n        \n        preds.extend(F.softmax(outputs, 1).cpu().numpy())\n\npreds = np.array(preds)\nlabels = preds.argmax(1)\nnew_preds = np.zeros((len(preds),))\ntemp = preds[labels != 0, 1:]\nnew_preds[labels != 0] = [temp[i, val] for i, val in enumerate(temp.argmax(1))]\nnew_preds[labels == 0] = preds[labels == 0, 0]\n\ntest_df['Id'] = test_df['ImageFileName'].apply(lambda x: x.split(os.sep)[-1])\ntest_df['Label'] = new_preds\n\ntest_df = test_df.drop('ImageFileName', axis=1)\ntest_df.to_csv('submission.csv', index=False)\nprint(test_df.head())","4df26d51":"torch.save(model.state_dict(), 'alaska2-effnetb0-4eps.pth')","d5242f17":"checkpoint = {\n    'epochs': 4,\n    'model_state': model.state_dict(),\n    'optim_state': opt_fn.state_dict()\n}\ntorch.save(checkpoint, 'checkpoint07112020.pth')","95c74841":"#model = torch.load(PATH)\n#model.eval()","b4bb5873":"for p in model.parameters():\n    print(p)"}}