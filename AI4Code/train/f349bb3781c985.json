{"cell_type":{"d46357bc":"code","8614aeb4":"code","e9d49d65":"code","ab3362b8":"code","55935610":"code","60188c65":"code","cc270414":"code","f01a2374":"code","85922e9d":"code","477f170b":"code","76b2a4e6":"code","36dfe4a0":"code","84dcf6d6":"code","ebdac27f":"code","fc9774b9":"code","57ddc72f":"code","d83f6f83":"code","bc3b28dc":"markdown"},"source":{"d46357bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sys\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8614aeb4":"#!find \/opt\/conda\/lib\/python3.6 -name *.yaml","e9d49d65":"sys.version","ab3362b8":"np.version.version, pd.__version__","55935610":"!find \/opt\/conda\/lib\/python3.6\/site-packages\/opensolutionhomecredit*","60188c65":"!cp \/opt\/conda\/lib\/python3.6\/site-packages\/src\/kaggle.yaml neptune.yaml","cc270414":"#from src.pipeline_manager import PipelineManager\n\n#pipeline_manager = PipelineManager()\n\nfrom src.pipeline_manager import *","f01a2374":"dev_mode = True\nsubmit_predictions = True\npipeline_name = 'lightGBM'\nmodel_level = 'first'","85922e9d":"from src.utils import read_params\nfrom deepsense import neptune\nctx = neptune.Context()\nparams = read_params(ctx, fallback_file='neptune.yaml')","477f170b":"import src.pipeline_config as cfg","76b2a4e6":"cfg.DEV_SAMPLE_SIZE = 10000","36dfe4a0":"from src.pipeline_manager import _read_data\nfrom src.pipeline_manager import _get_fold_generator\nfrom src.pipeline_manager import _fold_fit_evaluate_predict_loop\nfrom src.pipeline_manager import _aggregate_test_prediction\n\ndef train_evaluate_predict_cv(pipeline_name, model_level, dev_mode, submit_predictions):\n    if bool(params.clean_experiment_directory_before_training) and os.path.isdir(params.experiment_directory):\n        logger.info('Cleaning experiment_directory...')\n        shutil.rmtree(params.experiment_directory)\n\n    tables = _read_data(dev_mode, read_train=True, read_test=True)\n\n    target_values = tables.application_train[cfg.TARGET_COLUMNS].values.reshape(-1)\n    fold_generator = _get_fold_generator(target_values)\n\n    fold_scores, out_of_fold_train_predictions, out_of_fold_test_predictions = [], [], []\n    for fold_id, (train_idx, valid_idx) in enumerate(fold_generator):\n        (train_data_split,valid_data_split) = tables.application_train.iloc[train_idx], tables.application_train.iloc[valid_idx]\n\n        logger.info('Started fold {}'.format(fold_id))\n        logger.info('Target mean in train: {}'.format(train_data_split[cfg.TARGET_COLUMNS].mean()))\n        logger.info('Target mean in valid: {}'.format(valid_data_split[cfg.TARGET_COLUMNS].mean()))\n        logger.info('Train shape: {}'.format(train_data_split.shape))\n        logger.info('Valid shape: {}'.format(valid_data_split.shape))\n\n        score, out_of_fold_prediction, test_prediction = _fold_fit_evaluate_predict_loop(train_data_split,valid_data_split,tables,fold_id, pipeline_name, model_level='first')\n\n        logger.info('Fold {} ROC_AUC {}'.format(fold_id, score))\n        ctx.channel_send('Fold {} ROC_AUC'.format(fold_id), 0, score)\n\n        out_of_fold_train_predictions.append(out_of_fold_prediction)\n        out_of_fold_test_predictions.append(test_prediction)\n        fold_scores.append(score)\n\n    out_of_fold_train_predictions = pd.concat(out_of_fold_train_predictions, axis=0)\n    out_of_fold_test_predictions = pd.concat(out_of_fold_test_predictions, axis=0)\n\n    test_prediction_aggregated = _aggregate_test_prediction(out_of_fold_test_predictions)\n    score_mean, score_std = np.mean(fold_scores), np.std(fold_scores)\n\n    logger.info('ROC_AUC mean {}, ROC_AUC std {}'.format(score_mean, score_std))\n    ctx.channel_send('ROC_AUC', 0, score_mean)\n    ctx.channel_send('ROC_AUC STD', 0, score_std)\n\n    logger.info('Saving predictions')\n    out_of_fold_train_predictions.to_csv(os.path.join(params.experiment_directory,'{}_out_of_fold_train_predictions.csv'.format(pipeline_name)),index=None)\n    out_of_fold_test_predictions.to_csv(os.path.join(params.experiment_directory,'{}_out_of_fold_test_predictions.csv'.format(pipeline_name)),index=None)\n    test_aggregated_file_path = os.path.join(params.experiment_directory,'{}_test_predictions_{}.csv'.format(pipeline_name,params.aggregation_method))\n    test_prediction_aggregated.to_csv(test_aggregated_file_path, index=None)\n\n    if not dev_mode:\n        logger.info('verifying submission...')\n        sample_submission = pd.read_csv(params.sample_submission_filepath)\n        verify_submission(test_prediction_aggregated, sample_submission)\n\n        if submit_predictions and params.kaggle_api:\n            make_submission(test_aggregated_file_path)","84dcf6d6":"import warnings\nwarnings.simplefilter(action = \"ignore\", category = RuntimeWarning)","ebdac27f":"#%prun \ntrain_evaluate_predict_cv(pipeline_name, model_level, dev_mode, submit_predictions)","fc9774b9":"!find \/kaggle\/working\/result -name *.csv","57ddc72f":"!cp \/kaggle\/working\/result\/lightGBM_test_predictions_rank_mean.csv .","d83f6f83":"!rm -rf \/kaggle\/working\/result\/","bc3b28dc":"settings > packages > github user\/repo > dromosys\/open-solution-home-credit "}}