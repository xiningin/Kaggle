{"cell_type":{"c3fe6d84":"code","3b72b47c":"code","d6d91e91":"code","7d5c1cc2":"code","3cc75c3a":"code","1e725786":"code","91b35aa8":"code","82d29c63":"code","04d454f3":"code","330534ef":"code","86696b18":"code","0dbc19ca":"code","777212a7":"code","9f86f683":"code","1d675134":"code","c11f1695":"code","1b8ce9d7":"code","5cc721a9":"code","47ebd0a8":"code","384525c5":"code","0574d0d5":"code","78a68b8f":"code","b2a57176":"code","ce283249":"code","5ed099de":"code","403f6cf0":"code","bfaf715f":"code","e317a9aa":"code","ff71e77f":"markdown","6b2f9198":"markdown","aa3d70ab":"markdown","ba74960b":"markdown","6affb5f9":"markdown","801a8342":"markdown","7fba18a4":"markdown","de8eef31":"markdown"},"source":{"c3fe6d84":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score\nfrom skimage.transform import resize\nimport tqdm\nfrom tqdm import tqdm_notebook,tnrange\nfrom keras.layers import Input,BatchNormalization,Dense,Dropout,Flatten,MaxPooling2D,GlobalAveragePooling2D,Conv2D,UpSampling2D,Conv2DTranspose,MaxPool2D\nfrom keras.models import Model,load_model,Sequential\nfrom keras.losses import binary_crossentropy,categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\nfrom keras.utils import to_categorical\nfrom keras.applications.densenet import DenseNet121,preprocess_input as densenet_preprocessing\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input as inception_preprocessing\nfrom keras.applications.resnet50 import ResNet50,preprocess_input as resnet_preprocessing\nfrom keras.applications.xception import Xception,preprocess_input as xception_preprocessing\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input as inceptionresnet_prepross\nfrom keras.preprocessing.image import ImageDataGenerator,array_to_img,load_img,img_to_array\nfrom keras.layers.merge import concatenate\nfrom keras.layers.core import Lambda\nfrom keras import backend as K\nimport tensorflow as tf\nimport os\nimport sys\nimport seaborn as sn\nfrom PIL import Image\npd.set_option('display.max_colwidth',100)\n%matplotlib inline\nimport gc\ngc.collect()","3b72b47c":"Train_Image_folder='..\/input\/train\/images\/'\nTrain_Mask_folder='..\/input\/train\/masks\/'\nTest_Image_folder='..\/input\/test\/images\/'\nTrain_Image_name=os.listdir(path=Train_Image_folder)\nTest_Image_name=os.listdir(path=Test_Image_folder)\nTrain_Image_path=[]\nTrain_Mask_path=[]\nTrain_id=[]\nfor i in Train_Image_name:\n    path1=Train_Image_folder+i\n    path2=Train_Mask_folder+i\n    id1=i.split(sep='.')[0]\n    Train_Image_path.append(path1)\n    Train_Mask_path.append(path2)\n    Train_id.append(id1)\n  \n\nTest_Image_path=[]\nTest_id=[]\nfor i in Test_Image_name:\n    path=Test_Image_folder+i\n    id2=i.split(sep='.')[0]\n    Test_Image_path.append(path)\n    Test_id.append(id2)\n    \ndf_Train_path=pd.DataFrame({'id':Train_id,'Train_Image_path':Train_Image_path,'Train_Mask_path':Train_Mask_path})\ndf_Test_path=pd.DataFrame({'id':Test_id,'Test_Image_path':Test_Image_path})\n\ndf_depths=pd.read_csv('..\/input\/depths.csv')\ndf_sub=pd.read_csv('..\/input\/sample_submission.csv')\ndf_Train_path=df_Train_path.merge(df_depths,on='id',how='left')\ndf_Test_path=df_Test_path.merge(df_depths,on='id',how='left')\ndf_Test_path=df_sub.merge(df_Test_path,on='id',how='left')\nprint(df_Train_path.shape,df_Test_path.shape)\ndf_Train_path.head()","d6d91e91":"df_Test_path.head()","7d5c1cc2":"def read_image(path,img_height,img_width,img_chan):\n    pixel=np.zeros((len(path), img_height, img_width, img_chan),dtype=np.float32)\n    for n, p in tqdm_notebook(enumerate(path), total=len(path)):\n        img = load_img(p)\n        x = img_to_array(img)[:,:,1]\n        x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n        x=x\/255\n        pixel[n]=x\n    return pixel\n\nimg_height=128\nimg_width=128\nimg_chan=1\nTrain_Image_pixel=read_image(df_Train_path.Train_Image_path,img_height,img_width,img_chan)\nTrain_Mask_pixel=read_image(df_Train_path.Train_Mask_path,img_height,img_width,img_chan)\n\nprint('Train Image shape: ',Train_Image_pixel.shape)\nprint('Train Mask shape: ',Train_Mask_pixel.shape)\n","3cc75c3a":"# Get and resize test images\ndef read_image2(path,img_height,img_width,img_chan):\n    pixel=np.zeros((len(path), img_height, img_width, img_chan),dtype=np.float32)\n    sizes_test = []\n    for n, p in tqdm_notebook(enumerate(path), total=len(path)):\n        img = load_img(p)\n        x = img_to_array(img)[:,:,1]\n        sizes_test.append([x.shape[0], x.shape[1]])\n        x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n        x=x\/255\n        pixel[n]=x\n    return pixel,sizes_test\n\nTest_Image_pixel,sizes_test=read_image2(df_Test_path.Test_Image_path,img_height,img_width,img_chan)\nprint('Test Image shape: ',Test_Image_pixel.shape)","1e725786":"array_to_img(Train_Image_pixel[0])","91b35aa8":"array_to_img(Train_Mask_pixel[0])","82d29c63":"array_to_img(Test_Image_pixel[0])","04d454f3":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","330534ef":"# Another method\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","86696b18":"X=Train_Image_pixel\nY=Train_Mask_pixel\ntest=Test_Image_pixel\nX_train,X_val,y_train,y_val=train_test_split(X,Y,test_size=0.20,random_state=42)\nprint(X_train.shape,y_train.shape)\nprint(X_val.shape,y_val.shape)\nprint(test.shape)","0dbc19ca":"# Build U-Net model\ninputs = Input((img_height, img_width, img_chan))\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=[mean_iou])\n#model.summary()","777212a7":"earlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\nresults = model.fit(X, Y,validation_split=0.1, batch_size=8, epochs=30,callbacks=[earlystopper, checkpointer])\n","9f86f683":"# Predict on train, val and test\nmodel = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\n#pred_train = model.predict(X_train, verbose=1)\n#pred_val = model.predict(X_val, verbose=1)\npreds_test = model.predict(test, verbose=1)","1d675134":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","c11f1695":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\n","1b8ce9d7":"pred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(df_Test_path.Test_Image_path))}","5cc721a9":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nrle=sub[0].values\ndf_sub.rle_mask=rle","47ebd0a8":"df_sub.head()","384525c5":"df_sub.to_csv('sub1.csv',index=False)","0574d0d5":"input_layer = Input((img_height, img_width, 1))\nc1 = Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same')(input_layer)\nl = MaxPool2D(strides=(2,2))(c1)\nc2 = Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(l)\nl = MaxPool2D(strides=(2,2))(c2)\nc3 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\nl = MaxPool2D(strides=(2,2))(c3)\nc4 = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(c4), c3], axis=-1)\nl = Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(l), c2], axis=-1)\nl = Conv2D(filters=24, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = concatenate([UpSampling2D(size=(2,2))(l), c1], axis=-1)\nl = Conv2D(filters=16, kernel_size=(2,2), activation='relu', padding='same')(l)\nl = Conv2D(filters=64, kernel_size=(1,1), activation='relu')(l)\nl = Dropout(0.5)(l)\noutput_layer = Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid')(l)\n                                                         \nmodel2 = Model(input_layer, output_layer)\nmodel2.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=[dice_coef])\n#model2.summary()","78a68b8f":"earlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-2.h5', verbose=1, save_best_only=True)\nresults = model2.fit(X, Y,validation_split=0.1, batch_size=8, epochs=30,callbacks=[earlystopper, checkpointer])\n","b2a57176":"model2 = load_model('model-tgs-salt-2.h5', custom_objects={'dice_coef': dice_coef})\npreds_test2 = model2.predict(test, verbose=1)","ce283249":"# Create list of upsampled test masks\npreds_test_upsampled2 = []\nfor i in tnrange(len(preds_test2)):\n    preds_test_upsampled2.append(resize(np.squeeze(preds_test2[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","5ed099de":"pred_dict2 = {fn[:-4]:RLenc(np.round(preds_test_upsampled2[i])) for i,fn in tqdm_notebook(enumerate(df_Test_path.Test_Image_path))}","403f6cf0":"sub2 = pd.DataFrame.from_dict(pred_dict2,orient='index')\nrle2=sub2[0].values\ndf_sub.rle_mask=rle2","bfaf715f":"df_sub.head()","e317a9aa":"df_sub.to_csv('sub2.csv',index=False)","ff71e77f":"## Loading Dataset","6b2f9198":"### Define IoU metric","aa3d70ab":"## Spliting training set","ba74960b":"## 1. Building U-Net Model","6affb5f9":"** Creating two Dataframe which contains path of the images in train and test folder**","801a8342":"** Loading the Train_Image, Train_Mask and Test_Image in pixel formate**","7fba18a4":"## Loading Library","de8eef31":"## 2. Model2"}}