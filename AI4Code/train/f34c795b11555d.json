{"cell_type":{"7b6d5e70":"code","1ced4240":"code","ce900fbf":"code","410c176e":"code","5b88ae28":"code","e5e247fd":"code","b6881832":"code","f2b82095":"code","115b9036":"code","1374c0cd":"code","3a4eb41b":"code","ad3e3479":"code","722bf12c":"code","a6dff68b":"code","48cf3bc1":"code","a84b9729":"code","ce737b61":"code","d5d660b8":"code","649acb64":"code","99a8eea2":"code","b83b2050":"code","6635479b":"markdown","11d40947":"markdown","0f5a9fdc":"markdown","2d133958":"markdown","0c23669f":"markdown","5bd95335":"markdown"},"source":{"7b6d5e70":"# basic libraries\nimport os\nimport random\nimport numpy as np \nimport pandas as pd \nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\n\n# keras functionalities\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","1ced4240":"print(os.listdir('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images'))","ce900fbf":"print(len(os.listdir('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/')))\nprint(len(os.listdir('\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/')))","410c176e":"os.listdir('\/kaggle\/working\/')","5b88ae28":"# Creating the custom training and testing directories with subdirectories having images of given categories\n\nmain_dir='\/kaggle\/working\/Cell_Images'\n    \ntrain_dir=os.path.join(main_dir,'training')\ntest_dir=os.path.join(main_dir,'testing')\n    \nparasitized_train=os.path.join(train_dir,'parasitized')\nuninfected_train=os.path.join(train_dir,'uninfected')\n    \nparasitized_test=os.path.join(test_dir,'parasitized')\nuninfected_test=os.path.join(test_dir,'uninfected')\n    \nos.mkdir(main_dir)\n    \nos.mkdir(train_dir)\nos.mkdir(test_dir)\n    \nos.mkdir(parasitized_train)\nos.mkdir(uninfected_train)\n    \nos.mkdir(parasitized_test)\nos.mkdir(uninfected_test)\n\n    ","e5e247fd":"os.listdir('\/kaggle\/working\/Cell_Images\/testing\/uninfected\/')","b6881832":"# helper function for splitting the source data so that images belonging to particular categories can be put into their \n# respective directories that we created above.\n\ndef split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n    \n    data=os.listdir(SOURCE)\n    data=random.sample(data,len(data))\n    for count, file in enumerate(data):\n        if(count<SPLIT_SIZE*len(data)):\n            copyfile(f\"{SOURCE}\/{file}\",f\"{TRAINING}\/{file}\")\n        elif(count>=SPLIT_SIZE*len(data)):\n            copyfile(f\"{SOURCE}\/{file}\",f\"{TESTING}\/{file}\")\n        \n    ","f2b82095":"PARASITIZED_SOURCE_DIR='\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/'\nPARASITIZED_TRAIN_DIR='\/kaggle\/working\/Cell_Images\/training\/parasitized\/'\nPARASITIZED_TEST_DIR='\/kaggle\/working\/Cell_Images\/testing\/parasitized\/'\nUNINFECTED_SOURCE_DIR='\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/'\nUNINFECTED_TRAIN_DIR='\/kaggle\/working\/Cell_Images\/training\/uninfected\/'\nUNINFECTED_TEST_DIR='\/kaggle\/working\/Cell_Images\/testing\/uninfected\/'\n\nsplit_size = .9\nsplit_data(PARASITIZED_SOURCE_DIR, PARASITIZED_TRAIN_DIR, PARASITIZED_TEST_DIR, split_size)\nsplit_data(UNINFECTED_SOURCE_DIR, UNINFECTED_TRAIN_DIR, UNINFECTED_TEST_DIR, split_size)","115b9036":"print(len(os.listdir('\/kaggle\/working\/Cell_Images\/training\/parasitized\/')))\nprint(len(os.listdir('\/kaggle\/working\/Cell_Images\/training\/uninfected\/')))\nprint(len(os.listdir('\/kaggle\/working\/Cell_Images\/testing\/parasitized\/')))\nprint(len(os.listdir('\/kaggle\/working\/Cell_Images\/testing\/uninfected\/')))","1374c0cd":"train_datagen=ImageDataGenerator(rescale=1.0\/255)\n\nTRAINING_DIR=train_dir\ntrain_generator = train_datagen.flow_from_directory(\n    TRAINING_DIR,\n    target_size=(112,112),\n    batch_size=32,\n    class_mode='binary'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.0\/255)\n\nVALIDATION_DIR = test_dir\nvalidation_generator = validation_datagen.flow_from_directory(\n    VALIDATION_DIR,\n    target_size=(112,112),\n    batch_size=32,\n    class_mode='binary'\n)\n","3a4eb41b":"len(train_generator)","ad3e3479":"sample_training_images, train_label = next(train_generator)","722bf12c":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout() \n    plt.show()","a6dff68b":"print('Displaying Some Cell images')\nplotImages(sample_training_images[:5])","48cf3bc1":"from tensorflow.keras.applications import ResNet50","a84b9729":"base_model = ResNet50(include_top=False, \n                      weights='imagenet', \n                      input_shape=(112, 112, 3))\nbase_model.trainable = True ","ce737b61":"model=Sequential()\n\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.25))  \nmodel.add(Dense(1,activation='sigmoid'))\nmodel.summary()","d5d660b8":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","649acb64":"mdl=model.fit(train_generator,\n          epochs=10,\n          steps_per_epoch=len(train_generator),\n          validation_data=validation_generator,\n          validation_steps=len(validation_generator),\n          verbose=2\n          )","99a8eea2":"def visualize_training(mdl, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(mdl.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(mdl.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(mdl.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(mdl.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(mdl)","b83b2050":"model_name = 'malaria_pred_model.h5'\nmodel.save_weights(model_name)","6635479b":"### Data Preprocessing","11d40947":"### Visualizing the accuracy and losses","0f5a9fdc":"### Saving the model","2d133958":"### Displaying the Images","0c23669f":"#### Labelling and normalization via ImageDataGenerator object","5bd95335":"### Transfer Learning with ResNet50"}}