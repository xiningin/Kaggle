{"cell_type":{"c3d90caa":"code","395e3181":"code","c6ee4080":"code","c1fbcf84":"code","13b18159":"code","b4c2da8b":"code","09623e9f":"code","62a4d570":"code","f3a83338":"code","ecfd9482":"code","5af6dbc2":"code","0f5afeee":"code","3d7e1733":"code","74b51173":"code","3456a9ef":"code","0ae88f1d":"code","33a36318":"code","58ca7a9a":"code","f232161f":"code","be85978e":"code","467b840d":"code","6eef1a8f":"code","23575531":"code","b9f174c2":"code","93f8c646":"code","000b6c0c":"code","f19e08b7":"code","a1be64d7":"code","9ff0c493":"code","59721a57":"code","d6043356":"code","a932d5ad":"code","47b82ab8":"code","f735f66f":"code","7d1cacda":"markdown","521a6aff":"markdown","548008ee":"markdown","0cbac559":"markdown","156197d8":"markdown","38eeb481":"markdown","4de37695":"markdown","24429ff7":"markdown","a18988f8":"markdown","5a588d3d":"markdown","720547fa":"markdown"},"source":{"c3d90caa":"import os # accessing directory structure\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt # plotting\n%matplotlib inline\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom  IPython.display import display\nimport plotly.express as px\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, experimental, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy, binary_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau \nfrom tensorflow.data import Dataset\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.random import set_seed\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow import test\nimport random\n\n# Set Seed\nnp.random.seed(11)\nset_seed(11)\nrandom.seed(11)","395e3181":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nage_gender_data = pd.read_csv(\"\/kaggle\/input\/age-gender-and-ethnicity-face-data-csv\/age_gender.csv\")\nage_gender_data.info()","c6ee4080":"age_gender_data.head()","c1fbcf84":"sns.countplot(x='age', data=age_gender_data) #age distribution","13b18159":"sns.countplot(x='gender', data=age_gender_data) #gender distribution","b4c2da8b":"# Select only person who has age more than 18 \nage_gender_data = age_gender_data[age_gender_data['age'] >= 18]\nsns.countplot(x='age', data=age_gender_data) #age distribution","09623e9f":"age_gender_data.reset_index(drop=True, inplace=True)\nage_gender_data","62a4d570":"age_gender_data.isnull().sum() # Check null data","f3a83338":"# Input image configuration\nnum_pixels = len(age_gender_data['pixels'][0].split(' '))\ndimension = int(np.sqrt(num_pixels))\nimg_width = dimension\nimg_height = dimension\n\nprint(\"Pixels: {}\".format(num_pixels))\nprint(\"Width: {0}, Height: {1}\".format(img_width, img_height))","ecfd9482":"# Splitting dataset into X and y\nX_img = age_gender_data.iloc[:,4].copy()\ny_age = age_gender_data.iloc[:,0].copy()\ny_ethnicity = age_gender_data.iloc[:,1].copy()\ny_gender = age_gender_data.iloc[:,2].copy()\n\n# splitting the data into train and te sets.\nX_train, X_te, y_train, y_te = train_test_split(X_img,y_gender,test_size=0.3,random_state=11)\n# splitting 'te' set into validation and test set\nX_val, X_test, y_val, y_test = train_test_split(X_te,y_te,test_size=0.15,random_state=11)\n\ndef str_to_npArr(x):\n    '''\n    Function to convert pixel data (string) into numpy_array of pixels\n    '''\n    x = x.reset_index(drop=True)\n    x = x.apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\n    return np.array([x[i].reshape(img_width, img_height, 1) for i in range(x.shape[0])])\n\n# Converting the string of pixels into image array for each of train, val and test set and normalization\nX_train = str_to_npArr(X_train)\nX_test = str_to_npArr(X_test)\nX_val = str_to_npArr(X_val)\n\nprint(\"Traget: shape = (16593, 48, 48, 1), type = <class 'numpy.ndarray'>\")\nprint(\"Current: shape = {}, type = {}\".format(X_train.shape, type(X_train)))","5af6dbc2":"target_columns = ['gender', 'ethnicity', 'age']\n\nage_gender_data_preprocess = age_gender_data.drop('img_name', axis=1)\ny = age_gender_data_preprocess[target_columns]\nX = age_gender_data_preprocess.drop(target_columns, axis=1)\n\nprint(X)\nprint(\"--------------------------------------------------------\")\nprint(y)","0f5afeee":"X = X['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\nX = np.array(X)\/255.0 # normalization\nX = np.array([ X[i].reshape(48,48,1) for i in range(X.shape[0]) ])\n\nprint(\"Traget: X Shape: {}\".format(X.shape))\nprint(\"Current: X Shape: {}\".format(X.shape))","3d7e1733":"y_gender = np.array(y['gender'])\ny_ethnicity = np.array(y['ethnicity'])\ny_age = np.array(y['age'])","74b51173":"rows = 20 # rows in subplots\ncols = 5 # columns in subplots\nsamp = random.sample(range(X.shape[0]),rows*cols) #selecting 100 random samples\nx_samp = X[samp,:,:,:]\ny_samp_gender = y_gender[samp]\ny_samp_age = y_age[samp]\n    \nfig,ax = plt.subplots(rows,cols,figsize=(16,60))\nr = 0\nc = 0   \n\nfor i in range(rows*cols):\n    aa = x_samp[i,:,:,:].reshape(48,48)\n    ax[r,c].axis(\"off\")\n    ax[r,c].imshow(aa,cmap=\"gray\")\n    ax[r,c].set_title(f\"Gender: {'Female' if y_samp_gender[i]==1 else 'Male'}, Age: {y_samp_age[i]}\")\n    c+=1\n    if c == cols:\n        c=0\n        r+=1\n        \nplt.show()","3456a9ef":"train_data_gen = ImageDataGenerator(rotation_range=30,\n                                   width_shift_range=1,\n                                    brightness_range=[0.8,1.2],\n                                    zoom_range=[0.8,1.2],\n                                    rescale=1\/255\n                                   )\nval_data_gen = ImageDataGenerator(rescale=1\/255)\n\ntest_data_gen = ImageDataGenerator(rescale=1\/255)","0ae88f1d":"set_seed(11)\nrandom.seed(11)\nnp.random.seed(11)\n\nval_data = val_data_gen.flow(X_val,y_val,\n                                   seed=11,shuffle=False)\n\ntest_data = test_data_gen.flow(X_test,y_test,\n                                   seed=11,shuffle=False)","33a36318":"fig,ax = plt.subplots(10,5,figsize=(15,25))\nfor n in range(10):    \n    r = random.sample(range(X.shape[0]),1)[0]\n    ax[n,0].imshow(X[r].reshape(48,48),cmap=\"gray\")\n    ax[n,0].set_title(\"Original\")\n    ax[n,0].axis(\"off\")\n    for i in range(1,5):\n        ax[n,i].imshow(train_data_gen.random_transform(X[r]).reshape(48,48),cmap=\"gray\")\n        ax[n,i].set_title(\"Augmented\")\n        ax[n,i].axis(\"off\")\nplt.show()","58ca7a9a":"# Model configuration\nbatch_size = 32\nimg_width, img_height, img_num_channels = 48, 48, 1\nloss_function = sparse_categorical_crossentropy\nno_classes = 2\nno_epochs = 50\noptimizer = Adam()\nverbosity = 1\nnum_folds = 10\nactivation='softmax'\n\n# Determine shape of the data\ninput_shape = (img_width, img_height, img_num_channels)\ninput_shape","f232161f":"# Set Seed\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)","be85978e":"# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nfor train, test in kfold.split(X, y_gender):\n    \n  # Set Seed\n  random.seed(11)\n  set_seed(11)\n  np.random.seed(11)\n  \n  # Define the model architecture\n  model = Sequential()\n  \n  model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.3))\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.3))\n  model.add(BatchNormalization())\n\n  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n  model.add(Dropout(0.5))\n  model.add(BatchNormalization())\n\n  model.add(Flatten())\n  model.add(Dense(128, activation='relu'))\n  model.add(Dense(128, activation='softmax'))\n\n  # Compile the model\n  model.compile(loss=loss_function,\n              optimizer=optimizer,\n              metrics=['accuracy'])\n  \n  # Generate a print\n  print('------------------------------------------------------------------------')\n  print(f'Training for fold {fold_no} ...')\n    \n  early_stop = EarlyStopping(monitor=\"val_loss\",patience=5,mode=\"min\") # Ensure the model doesn't overfit\n  \n  # Set Seed\n  random.seed(11)\n  set_seed(11)\n  np.random.seed(11)\n    \n  # Fit data to model\n  history = model.fit(train_data_gen.flow(X[train], y_gender[train], seed=11),\n            callbacks=early_stop,\n            batch_size=batch_size,\n            epochs=no_epochs,\n            verbose=verbosity,\n            validation_data=train_data_gen.flow(X[test], y_gender[test],\n                                   seed=11))\n  \n  # Generate generalization metrics\n  fig = px.line(\n  history.history, y=['loss', 'val_loss'],\n  labels={'index': 'epoch', 'value': 'loss'}, \n  title='Training History')\n  fig.show()\n    \n  scores = model.evaluate(train_data_gen.flow(X[test], y_gender[test],\n                                   seed=11), verbose=0)\n  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n  acc_per_fold.append(scores[1] * 100)\n  loss_per_fold.append(scores[0])\n  \n  # Increase fold number\n  fold_no = fold_no + 1","467b840d":"# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","6eef1a8f":"# Set Seed\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\n  \n# Define the model architecture\nmodel = Sequential()\n  \nmodel.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='softmax'))\n\n# Compile the model\nmodel.compile(loss=loss_function,\n              optimizer=optimizer,\n              metrics=['accuracy'])","23575531":"Final_train = np.append(X_train, X_val, axis=0)\nFinal_val = np.append(y_train, y_val, axis=0)\nfinal_training_data = train_data_gen.flow(Final_train, Final_val,\n                                   seed=11)\n\nrandom.seed(11)\nset_seed(11)\nnp.random.seed(11)\nfinal_model_history = model.fit(train_data_gen.flow(X, y_gender, seed=11),batch_size=32,epochs=20, validation_data=val_data)","b9f174c2":"# Generate generalization metrics\nfig = px.line(\nfinal_model_history.history, y=['loss', 'val_loss'],\nlabels={'index': 'epoch', 'value': 'val_loss'}, \ntitle='Training History')\nfig.show()\n\n\n# Generate generalization metrics\nfig = px.line(\nfinal_model_history.history, y=['accuracy', 'val_accuracy'],\nlabels={'index': 'epoch', 'value': 'accuracy'}, \ntitle='Training History')\nfig.show()","93f8c646":"pwd","000b6c0c":"model.save(\"backup\")","f19e08b7":"# Metrics\nmodel.evaluate(test_data)","a1be64d7":"y_pred = model.predict_classes(test_data)","9ff0c493":"print(classification_report(y_test, y_pred))","59721a57":"# Confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, cmap='Greens', cbar=False, annot=True, fmt='d');","d6043356":"error_index = (y_test != y_pred)#finding error indices\ny_test_error = y_test[error_index]\nX_test_error = X_test[error_index]\nprediction_error = y_pred[error_index]","a932d5ad":"rows=int(np.floor(sum(error_index)\/3)) #rows in subplots\ncols=3 #columns in subplots\nx_samp = X_test_error\ny_samp = y_test_error\n\nfig,ax = plt.subplots(rows,cols,figsize=(15,50))\nr = 0\nc = 0\nfor i in range((rows*cols)-1):\n    aa = x_samp[i].reshape(48,48)\n    ax[r,c].axis(\"off\")\n    ax[r,c].imshow(aa,cmap=\"gray\")\n    actual_lab = \"Female\" if y_samp.iloc[i]==1 else \"Male\"\n    pred_lab = \"Female\" if int(prediction_error[i])==1 else \"Male\"\n    ax[r,c].set_title(f'Actual: {actual_lab}\\nPred: {pred_lab}')\n    c+=1\n    if c == cols:\n        c=0\n        r+=1\nplt.show()","47b82ab8":"import cv2","f735f66f":"img = cv2.imread('..\/input\/testset\/mind-long.jpg',0)\nplt.imshow(img, cmap=\"gray\")\nimg = cv2.resize(img, (48,48))\nimg = np.reshape(img,[1,48,48,1])\nimg_pixels = img.astype(\"float32\") \/ 255.0\nclasses = model.predict_classes(img_pixels)\n\nmapper=['male','female']\nprint(mapper[classes[0]])","7d1cacda":"**Gender  Data Scope**\n* **Biology:**\n    * a boy is usually a fully physically developed man at the age of 18. \n    * a girl is usually a fully physically developed woman at the age of 16.","521a6aff":"**Data Overview**\n* *Age*: range from 1 to 116\n* *Ethnicity*: 0 - White, 1 - Black, 2 - Asian, 3 - Indian, 4 - Other\n* *Gender*: 0 - male, 1 - female","548008ee":"# **Training**","0cbac559":"# **Data Visualization**","156197d8":"# **Data Preparation**","38eeb481":"**Data augmentation**: a technique to increase the diversity of your training set by applying random (but realistic) transformations such as image rotation.\nThis code below shows 100 samples of Data augmentation.","4de37695":"   **Gender classification** plays a crucial role in many scenarios. As one of the demographic classification attributes, gender information belongs to soft biometrics that provides ancillary information of an individual\u2019s identity information. Moreover, it can improve the performance of face recognition. Thus, it is widely used in many applications to provide smart services in human-computer interaction, such as visual surveillance, intelligent interface, and intelligent advertising.\n\n**Reference**: https:\/\/www.hindawi.com\/journals\/mpe\/2018\/1924151\/","24429ff7":"# **Error Analysis**","a18988f8":"# **Data Preprocessing**","5a588d3d":"# **Getting Started**","720547fa":"# **Image Augmentation**"}}