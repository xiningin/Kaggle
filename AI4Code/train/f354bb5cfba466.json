{"cell_type":{"f8074427":"code","e82e2e54":"code","a9f0538a":"code","d742b356":"code","3a639ec6":"code","29d69c40":"code","2331e162":"markdown","eb1cecd2":"markdown"},"source":{"f8074427":"# Clone GFPGAN and enter the GFPGAN folder\n!rm -rf GFPGAN\n!git clone https:\/\/github.com\/TencentARC\/GFPGAN.git\n%cd GFPGAN\n\n# Set up the environment\n!pip install basicsr\n\n# Install other depencencies\n!pip install facexlib\n!pip install -r requirements.txt\n!python setup.py develop\n!pip install realesrgan\n\n# Download the pre-trained model\n!wget https:\/\/github.com\/TencentARC\/GFPGAN\/releases\/download\/v0.2.0\/GFPGANCleanv1-NoCE-C2.pth -P experiments\/pretrained_models","e82e2e54":"import shutil\nimport os\nfrom glob import glob\nimport itertools\n\nupload_folder = '..\/input\/old-film-restoration-dataset\/test_A'\nimage_files = glob(upload_folder + '\/*.jp*g')\nimage_files","a9f0538a":"\nimport shutil\nimport os\nupload_folder = 'inputs\/upload'\n\nif os.path.isdir(upload_folder):\n    shutil.rmtree(upload_folder)\nos.makedirs(upload_folder, exist_ok=True)\nshutil.move('inputs\/whole_imgs\/Blake_Lively.jpg', 'inputs\/upload\/Blake_Lively.jpg')","d742b356":"# train_images = train_data[\"image\"].progress_apply(load_image, args=((100,100),))","3a639ec6":"# Now we use the GFPGAN to restore the above low-quality images\n# We use [Real-ESRGAN](https:\/\/github.com\/xinntao\/Real-ESRGAN) for enhancing the background (non-face) regions\n!rm -rf results\n!python inference_gfpgan.py --upscale 2 --test_path inputs\/upload --save_root results --model_path experiments\/pretrained_models\/GFPGANCleanv1-NoCE-C2.pth --bg_upsampler realesrgan\n\n!ls results\/cmp","29d69c40":"# We first visualize the cropped faces\n# The left are the inputs images; the right are the results of GFPGAN\n\nimport cv2\nimport matplotlib.pyplot as plt\ndef display(img1, img2):\n  fig = plt.figure(figsize=(25, 10))\n  ax1 = fig.add_subplot(1, 2, 1) \n  plt.title('Input image', fontsize=16)\n  ax1.axis('off')\n  ax2 = fig.add_subplot(1, 2, 2)\n  plt.title('GFPGAN output', fontsize=16)\n  ax2.axis('off')\n  ax1.imshow(img1)\n  ax2.imshow(img2)\ndef imread(img_path):\n  img = cv2.imread(img_path)\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n  return img\n\n# display each image in the upload folder\nimport os\nimport glob\n\ninput_folder = 'results\/cropped_faces'\nresult_folder = 'results\/restored_faces'\ninput_list = sorted(glob.glob(os.path.join(input_folder, '*')))\noutput_list = sorted(glob.glob(os.path.join(result_folder, '*')))\nfor input_path, output_path in zip(input_list, output_list):\n  img_input = imread(input_path)\n  img_output = imread(output_path)\n  display(img_input, img_output)","2331e162":"# introduction","eb1cecd2":"\ud835\uddda\ud835\uddd9\ud835\udde3-\ud835\uddda\ud835\uddd4\ud835\udde1 is a blind face restoration algorithm towards real-world face images. It leverages the generative face prior in a pre-trained GAN to restore realistic faces while preserving fidelity.\n\nBlind face restoration aims at recovering high-quality faces from the low-quality counterparts suffering from unknown degradation, such as low-resolution, noise, blur, compression artifacts, etc.\n\nThis Generative Facial Prior (GFP) is incorporated into the face restoration process via channel-split spatial feature transform layers, which allow for a good balance between realness and fidelity\nIf you want to use the paper model, [please go to this Colab Demo](https:\/\/colab.research.google.com\/drive\/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing) for GFPGAN google colab logo.\n\n\ud83d\udcdd \ud835\udde3\ud835\uddee\ud835\uddfd\ud835\uddf2\ud835\uddff:\nhttps:\/\/lnkd.in\/gMRk226Z"}}