{"cell_type":{"a50f0d07":"code","de1fe8b8":"code","59de8f43":"code","95b4819b":"code","571189c1":"code","d9a8c2da":"code","2bc8c79c":"code","b52b2ae0":"code","f2f5de35":"code","1a894c39":"code","da4dd6a2":"code","7574aeda":"code","3aae6fd2":"code","f7f73ff7":"code","eb5a0d13":"code","5b0a4ce5":"markdown","d4e5338e":"markdown","3d7ec088":"markdown","4be7d5e1":"markdown","6ad43b95":"markdown","b322e520":"markdown","2ac526ef":"markdown","7bda95e4":"markdown","aae4b032":"markdown","72fc632a":"markdown","d889f9d8":"markdown","6502907b":"markdown","a91b8627":"markdown","ee412ab5":"markdown","736d0986":"markdown","6b561276":"markdown"},"source":{"a50f0d07":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","de1fe8b8":"images_path = \"\/kaggle\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\"\nmasks_path = \"\/kaggle\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/masks\"\n\nimage_names = os.listdir(images_path)\nmask_names = os.listdir(masks_path)","59de8f43":"mask_names = [mask_name.split(\".png\")[0] for mask_name in mask_names]\nmask_names = [mask_name.split(\"_mask\")[0]+'.png' for mask_name in mask_names]\n\nno_mask_images = list(set(image_names) - set(mask_names))\n\nimage_names = [image_name for image_name in image_names if image_name not in no_mask_images]","95b4819b":"def load_data(data, kind='images', dim=512):\n    \"\"\"\n    Parameters: file_names\n    Returns: loaded-resized images array\n    \"\"\"\n    if kind == 'masks':\n        path = masks_path\n    else:\n        path = images_path\n    \n    data_array = []\n    \n    for i in tqdm(data):\n        if not os.path.exists(os.path.join(path,i)):\n            # because some images have \"_mask\" in name\n            i = i.split('.png')[0]+'_mask.png'\n            \n        img = cv2.imread(os.path.join(path,i))\n        rsz_img = cv2.resize(img,(dim,dim))[:,:,0]\n\n        data_array.append(rsz_img)\n\n    return data_array","571189c1":"images = load_data(image_names)\nmasks = load_data(image_names, kind='masks')","d9a8c2da":"def plot_samples(images,masks):\n    \n    image_set = np.hstack((images[:6]))\n    mask_set = np.hstack((masks[:6]))\n    display_set = np.vstack((image_set,mask_set))\n    \n    plt.figure(figsize = (10,4))\n    plt.imshow(display_set)\n    plt.axis('off')\n    plt.show()","2bc8c79c":"print('Sample images and corresponding masks')\nplot_samples(images,masks)","b52b2ae0":"from keras import backend as keras\nfrom keras.models import Model\nfrom keras.models import Input\nfrom keras.models import load_model\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import concatenate\nfrom keras.layers import Conv2DTranspose\nfrom keras.optimizers import Adam\n\n\ndef make_conv_block(filters,inputs,ret_pool=True):\n    \"\"\"\n    Returns Convoutional layers block as CONV -> CONV -> POOL\n    \"\"\"\n    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(inputs)\n    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)\n    if ret_pool:\n        pool = MaxPooling2D(pool_size=(2, 2))(conv)\n        return conv,pool\n    else:\n        return conv\n    \ndef make_conc_block(filters,conv1,conv2):\n    \"\"\"\n    Returns Concatenated Convoutional layers block as CONCAT -> CONV -> CONV\n    \"\"\"\n    up = concatenate([Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(conv1), conv2], axis=3)\n    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(up)\n    conv = Conv2D(filters, (3, 3), activation='relu', padding='same')(conv)\n    return conv\n    \ndef build_model():\n    input_size=(512,512,1)\n    inputs = Input(input_size)\n    \n    conv1, pool1 = make_conv_block(32,inputs)\n    conv2, pool2 = make_conv_block(64,pool1)\n    conv3, pool3 = make_conv_block(128,pool2)\n    conv4, pool4 = make_conv_block(256,pool3)\n    conv5 = make_conv_block(512,pool4,ret_pool=False)\n    \n    conv6 = make_conc_block(256,conv5,conv4)\n    conv7 = make_conc_block(128,conv6,conv3)\n    conv8 = make_conc_block(64,conv7,conv2)\n    conv9 = make_conc_block(32,conv8,conv1)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","f2f5de35":"def dice_coef(y_true, y_pred):\n    y_true_f = keras.flatten(y_true)\n    y_pred_f = keras.flatten(y_pred)\n    intersection = keras.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","1a894c39":"model = build_model()\nmodel.compile(optimizer=Adam(lr=2e-4), loss=dice_coef_loss, metrics=[dice_coef, 'binary_accuracy'])\n# model.summary()","da4dd6a2":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nweight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, \n                                   mode='min', min_delta=0.0001, cooldown=2, min_lr=1e-6)\n\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\ncallbacks = [checkpoint, early, reduceLR]","7574aeda":"from sklearn.model_selection import train_test_split\n\ndim=512\nimages = np.array(images).reshape(len(images),dim,dim,1)\nmasks = np.array(masks).reshape(len(masks),dim,dim,1)\n\ntrain_images, validation_images, train_masks, validation_masks = train_test_split((images-127.0)\/127.0, \n                                                            (masks>127).astype(np.float32), \n                                                            test_size = 0.1,random_state = 2018)\n\ntrain_images, test_images, train_masks, test_masks = train_test_split(train_images,train_masks,\n                                                            test_size = 0.1, \n                                                            random_state = 2018)\n\nhistory = model.fit(x = train_images, y = train_masks, batch_size = 16,\n                          validation_data =(test_images,test_masks), epochs = 1,\n                          callbacks=callbacks)","3aae6fd2":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.plot(history.history['loss'], '-', label = 'Loss')\nax1.plot(history.history['val_loss'], '-', label = 'Validation Loss')\nax1.legend()\n\nax2.plot(100*np.array(history.history['binary_accuracy']), '-', label = 'Accuracy')\nax2.plot(100*np.array(history.history['val_binary_accuracy']), '-', label = 'Validation Accuracy')\nax2.legend()","f7f73ff7":"pred_random_set = np.random.randint(1,validation_images.shape[0],10)\npreds = model.predict(validation_images)\n\nplt.figure(figsize=(15,8))\n\nfor i in range(0,9,3):\n    plt.subplot(3,3,i+1)\n    \n    plt.imshow(np.squeeze(validation_images[pred_random_set[i]]))\n    plt.xlabel(\"Image\")\n    plt.axis('off')\n    \n    plt.subplot(3,3,i+2)\n    plt.imshow(np.squeeze(validation_masks[pred_random_set[i]]))\n    plt.xlabel(\"Mask\")\n    plt.axis('off')\n    \n    plt.subplot(3,3,i+3)\n    plt.imshow(np.squeeze(preds[pred_random_set[i]]))\n    plt.xlabel(\"Prediction\")\n    plt.axis('off')","eb5a0d13":"new_model = build_model()\nnew_model.compile(optimizer=Adam(lr=2e-4), loss=dice_coef_loss, metrics=[dice_coef, 'binary_accuracy'])\n\nnew_model.load_weights('cxr_reg_weights.best.hdf5')","5b0a4ce5":"**Import libraries**","d4e5338e":"**Function to load images and masks followed by resizing**","3d7ec088":"**Dice loss and Dice-coef function**","4be7d5e1":"**Split images and masks to train-test-val set and fit model**","6ad43b95":"# Model Evaluation\n> **Plot model metrics**","b322e520":"# Model predictions","2ac526ef":"# Model Developement","7bda95e4":"# Abstract\n> To create a model that can segment lungs fields from X-ray scan images\n\n> **Total Samples used for model training\/testing and validation:** - 704\n> **Dataset for model training: https:\/\/www.kaggle.com\/nikhilpandey360\/chest-xray-masks-and-labels**","aae4b032":"**Visualize few samples to check images and their masks**","72fc632a":"**Build Model - UNET:https:\/\/arxiv.org\/abs\/1505.04597**","d889f9d8":"**Choose images with masks(as some images don't have mask)**","6502907b":"# Data pre-processing","a91b8627":"> **Visualize prediction results on random samples from validation set**","ee412ab5":"**To reuse the model, define and load best model's weights stored using checkpoint callback**","736d0986":"**Path to images and their masks**","6b561276":"**Set callbacks for model's epochs**"}}