{"cell_type":{"9f04e6a0":"code","2ac47167":"code","d82954a2":"code","b5d3946b":"code","dda49be8":"code","70ff476f":"code","5bafca03":"code","82aab4d0":"code","8389e0fe":"code","e2706207":"code","2460e5e8":"code","43ede965":"code","5e8fb14b":"code","49e60831":"code","f1be3b94":"code","b260f736":"code","2759dc15":"code","dffefa13":"code","b2396229":"code","20185385":"code","4da59f8c":"code","0a5ed24a":"code","8ba45725":"code","e85e2135":"code","f505db03":"code","91fec86c":"code","a392d82a":"code","5a06d926":"code","76725c75":"code","da6bcf16":"code","59ec7172":"code","bd6dc8c8":"code","2fad8cb0":"code","3f668b36":"code","147168b9":"code","123547d7":"code","a7e1c787":"code","0cb8c8ee":"code","8f969238":"code","4a98ec9d":"code","c6da425b":"code","0066e1f8":"code","2623de94":"code","090f58d0":"code","3cb998ae":"code","f4510586":"code","f39485bb":"code","1d3d5932":"code","7f34d28f":"code","6952bbe2":"code","7bf59b60":"code","793ba25e":"code","d0ad1961":"code","4195a175":"code","ed217e8e":"code","70b4ebdc":"code","80068d3a":"code","1684d3c8":"code","cb3d9fd0":"code","9c0d0148":"code","44b7c4d2":"code","7e166fb4":"code","ff50bf55":"code","241c8057":"code","40e3063a":"code","a8e6878b":"code","2364bd59":"code","e310d4db":"code","281cedfe":"code","50c6c0e4":"code","d4af6530":"code","100a944f":"code","e29b25ca":"code","21df61ee":"code","869d3658":"code","8f52fd13":"code","800d78f4":"markdown","bebf0e23":"markdown","249b96fb":"markdown","87c68e64":"markdown","954e0958":"markdown","772e51c2":"markdown","fb35eeb3":"markdown","3aec8f4a":"markdown","a21198be":"markdown","2b9987a0":"markdown","cc428cf7":"markdown","eb3d53ea":"markdown","929ca6d3":"markdown","5bea0c4e":"markdown","10afa7ce":"markdown","3ba35764":"markdown","e741c663":"markdown","d8ddabe9":"markdown","02e13869":"markdown","44bab819":"markdown","0c9f91f7":"markdown","5dfdb831":"markdown","3987dda3":"markdown","59ee1235":"markdown","4504141a":"markdown","62412f7f":"markdown","75e5101b":"markdown","8f53e30a":"markdown"},"source":{"9f04e6a0":"import pandas\nimport numpy as np\n\nfrom sklearn import model_selection\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport os\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\n","2ac47167":"dataframe = pandas.read_csv(\"..\/input\/cardiovascular-disease-dataset\/cardio_train.csv\",sep=\";\")","d82954a2":"dataframe.head()\n","b5d3946b":"dataframe.info()","dda49be8":"dataframe.describe()","70ff476f":"print(\"There is {} duplicated values in data frame\".format(dataframe.duplicated().sum()))","5bafca03":"%matplotlib inline\nimport matplotlib.pyplot as plt\ndataframe.hist(bins=50, figsize=(20,15));\n","82aab4d0":"dataframe.plot(kind=\"scatter\", x=\"id\", y=\"age\")","8389e0fe":"dataframe.plot(kind=\"scatter\", x=\"id\", y=\"age\", alpha=0.1)","e2706207":"dataframe.plot(kind=\"scatter\", x=\"id\", y=\"age\", alpha=0.4,s=dataframe[\"age\"]\/365, label=\"age\", figsize=(10,7),c=\"cardio\", cmap=plt.get_cmap(\"jet\"), colorbar=True)\n","2460e5e8":"# check correlations\nplt.subplots(figsize=(20,15))\nsns.heatmap(dataframe.corr(), vmin = -0.5, vmax = 1, annot=True)\n","43ede965":"dataframe[\"age_per_alco\"] = dataframe[\"smoke\"]\/dataframe[\"alco\"]\ndataframe[\"years_per_cardio\"] = dataframe[\"age\"]\/dataframe[\"gender\"]\n\ndataframe[\"gender_per_weight\"]=dataframe[\"gender\"]\/dataframe[\"weight\"]","5e8fb14b":"corr_matrix = dataframe.corr()\ncorr_matrix[\"cholesterol\"].sort_values(ascending=False)","49e60831":"dataframe.describe()","f1be3b94":"X = dataframe.iloc[:, [0,1,2,3,4,5,6,7,9,10,11,12]]\ny = dataframe.iloc[:, 8]","b260f736":"X.iloc[:,11]=np.ceil(X.iloc[:,11])","2759dc15":"X.head()","dffefa13":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder_X = LabelEncoder()\nX.iloc[:, 8] = labelencoder_X.fit_transform(X.iloc[:, 8])","b2396229":"print(labelencoder_X.classes_)","20185385":"X.head()","4da59f8c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)","0a5ed24a":"dataframe_categorical = dataframe.loc[:,['cholesterol','gluc', 'smoke', 'alco', 'active']]\nsns.countplot(x=\"variable\", hue=\"value\",data= pandas.melt(dataframe_categorical));","8ba45725":"dataframe.isnull().values.any()","e85e2135":"sns.heatmap(X.isnull(),yticklabels=False,cbar=False,cmap='viridis')","f505db03":"median=X_test.iloc[:, 4].median()\nX_test.iloc[:, 4].fillna(median, inplace=True)","91fec86c":"median=X_test.iloc[:, 11].median()\nX_test.iloc[:, 11].fillna(median, inplace=True)","a392d82a":"median=X_train.iloc[:, 4].median()\nX_train.iloc[:, 4].fillna(median, inplace=True)","5a06d926":"median=X_train.iloc[:, 11].median()\nX_train.iloc[:, 11].fillna(median, inplace=True)","76725c75":"sns.heatmap(X_test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","da6bcf16":"sns.heatmap(X_test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","59ec7172":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)","bd6dc8c8":"X_train.head()","2fad8cb0":"y_pred = lin_reg.predict(X_test)","3f668b36":"from sklearn.metrics import mean_squared_error\nlin_mse = mean_squared_error(y_test, y_pred)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","147168b9":"from sklearn.metrics import mean_absolute_error\n\nlin_mae = mean_absolute_error(y_test, y_pred)\nlin_mae","123547d7":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor(random_state=42)\ntree_reg.fit(X_train, y_train)","a7e1c787":"y_pred = tree_reg.predict(X_test)\ntree_mse = mean_squared_error(y_test, y_pred)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","0cb8c8ee":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(tree_reg, X_train, y_train,\n                         scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)","8f969238":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\ndisplay_scores(tree_rmse_scores)","4a98ec9d":"lin_scores = cross_val_score(lin_reg, X_train, y_train,\n                             scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","c6da425b":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\nforest_reg.fit(X_train, y_train)","0066e1f8":"y_pred = forest_reg.predict(X_test)\nforest_mse = mean_squared_error(y_test, y_pred)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","2623de94":"from sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, X_train, y_train,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","090f58d0":"scores = cross_val_score(lin_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\npandas.Series(np.sqrt(-scores)).describe()","3cb998ae":"\ndec = DecisionTreeClassifier()","f4510586":"ran = RandomForestClassifier(n_estimators=100)","f39485bb":"knn = KNeighborsClassifier(n_neighbors=100)","1d3d5932":"svm = SVC(random_state=1)\nnaive = GaussianNB()\n","7f34d28f":"models = {\"Decision tree\" : dec,\n          \"Random forest\" : ran,\n          \"KNN\" : knn,\n          \"Naive bayes\" : naive}\nscores= { }\n","6952bbe2":"for key, value in models.items():    \n    model = value\n    model.fit(X_train, y_train)\n    scores[key] = model.score(X_test, y_test)","7bf59b60":"scores_frame = pandas.DataFrame(scores, index=[\"Accuracy Score\"]).T\nscores_frame.sort_values(by=[\"Accuracy Score\"], axis=0 ,ascending=False, inplace=True)\nscores_frame","793ba25e":"plt.figure(figsize=(5,5))\nsns.barplot(x=scores_frame.index,y=scores_frame[\"Accuracy Score\"])\nplt.xticks(rotation=45)","d0ad1961":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)","4195a175":"y_pred_rfc = rfc.predict(X_test)","ed217e8e":"# Random Forest Model Evaluation\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, y_pred_rfc))\nprint(classification_report(y_test, y_pred_rfc))","70b4ebdc":"rfc.score(X_test, y_test)","80068d3a":"#Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies_rfc = cross_val_score(estimator=rfc, X=X_train, y=y_train, cv=10)","1684d3c8":"accuracies_rfc","cb3d9fd0":"accuracies_rfc.mean()","9c0d0148":"accuracies_rfc.std()","44b7c4d2":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=100)\nknn.fit(X_train, y_train)","7e166fb4":"y_pred_knn = knn.predict(X_test)","ff50bf55":"# KNN Model Evaluation\nprint(confusion_matrix(y_test, y_pred_knn))\nprint(classification_report(y_test, y_pred_knn))","241c8057":"knn.score(X_test, y_test)\n","40e3063a":"#Applying k-Fold Cross Validation\naccuracies_knn = cross_val_score(estimator=knn, X=X_train, y=y_train, cv=10)","a8e6878b":"accuracies_knn","2364bd59":"accuracies_knn.mean()","e310d4db":"accuracies_knn.std()","281cedfe":"# Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nnbc = GaussianNB()\nnbc.fit(X_train, y_train)","50c6c0e4":"y_pred_nbc = nbc.predict(X_test)\n","d4af6530":"# Naive Bayes Model Evaluation\nprint(confusion_matrix(y_test, y_pred_nbc))\nprint(classification_report(y_test, y_pred_nbc))","100a944f":"nbc.score(X_test, y_test)","e29b25ca":"#Applying k-Fold Cross Validation\naccuracies_nbc = cross_val_score(estimator=nbc, X=X_train, y=y_train, cv=10)","21df61ee":"accuracies_nbc","869d3658":"accuracies_nbc.mean()","8f52fd13":"accuracies_nbc.std()\n","800d78f4":"# Handling Text and categorical values","bebf0e23":"Compare against the actual values:\n\n","249b96fb":" It can be observed that people over 55 of age are more exposed to CVD. From the table above, we can see that there are outliers in ap_hi, ap_lo, weight and height. We will deal with them late","87c68e64":"The naive bayes model was the best performer out of all models giving us a mean accuracy score of 81.7%. K-Fold cross validation was used to ensure no overfitting was done.","954e0958":"It can be observed that people over 55 of age are more exposed to CVD. ","772e51c2":"# Visualizing geographical data\n","fb35eeb3":"The dataset consists of 70 000 records of patients data in 12 features, such as age, gender, systolic blood pressure, diastolic blood pressure, and etc. The target class \"cardio\" equals to 1, when patient has cardiovascular desease, and it's 0, if patient is healthy.\n\nThe task is to predict the presence or absence of cardiovascular disease (CVD) using the patient examination results.\n\nData description\nThere are 3 types of input features:\n\nObjective: factual information;\nExamination: results of medical examination;\nSubjective: information given by the patient","3aec8f4a":"Correlation coeff ranges from -1 to 1. When it is close to 1, it means there is strong positive correlation, -1 is strong negative correlation 0 indicates no correlation.\n\n","a21198be":"We can see from correlation  cholesterol, blood pressure (ap_hi and ap_low both) and age have a powerful relationship with cardiovascular diseases.\nGlucogen and cholesterol have a strong relationship among them either.","2b9987a0":"# REGRESSION MODEL","cc428cf7":"Are there any NAs or missing values in a dataset?\n\n","eb3d53ea":"# Prepare the data for Machine Learning algorithms","929ca6d3":"K-Fold cross-valuidation of Random Forest Model","5bea0c4e":"we specify n_estimators=10 to avoid a warning about the fact that the default value is going to change to 100 in Scikit-Learn 0.22.","10afa7ce":"# Discover and visualize the data to gain insights","3ba35764":"# Cadiovascular disease data","e741c663":"Setting alpha=0.1 makes it easier to visualize places where there is a high risk of cardiovascular diesease of data points A better visualization highlighting high active roleof disease.\n\n","d8ddabe9":"WE get the higher accuracy of  cholesterol, blood pressure (ap_hi and ap_low both) and age have a powerful relationship with cardiovascular diseases.","02e13869":"# Fine-tune your model(MODEL COMPARISON)","44bab819":"# CLASSIFICATION","0c9f91f7":"# CORRELATION","5dfdb831":"Age is measured in days, height is in centimeters. Let's look ate the numerical variables and how are they spread among target class. For example, at what age does the number of people with CVD exceed the number of people without CVD?","3987dda3":"Test Set Accuracy Score Now we have selected our model with better hyper parameters than default ones. It is time to evaluate model with our test set\n\n","59ee1235":"All features are numerical, 12 integers and 1 decimal number (weight). The second column gives us an idea how big is the dataset and how many non-null values are there for each field. We can use describe() to display sample statistics such as min, max, mean,std for each attribute:","4504141a":"It seems that KNN and Random Forest algorithms are far ahead of the others.","62412f7f":"## by Aarzoo Kuhar","75e5101b":"# Experimenting with Attribute Combinations","8f53e30a":"# Data Cleaning"}}