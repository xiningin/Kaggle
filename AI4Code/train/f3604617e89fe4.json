{"cell_type":{"f566e7b2":"code","96a97dde":"code","7143dd22":"code","f93c324b":"code","6df10c54":"code","48b724fb":"code","0cb6470a":"code","1190a8d0":"code","8b7245a1":"code","3006f5d1":"code","da2d236b":"code","8a5df4f0":"code","e9afa84c":"code","b583548d":"markdown","46a01688":"markdown","8d476f19":"markdown","c47c994b":"markdown","2371b624":"markdown","da098bca":"markdown","5f7d3003":"markdown","5045f5f2":"markdown","bbd5fb90":"markdown","8cae9b16":"markdown","90039614":"markdown","05598a79":"markdown","544670e1":"markdown","081245f0":"markdown","73b10cc5":"markdown","d8193dd7":"markdown","a3cf315e":"markdown","81823765":"markdown","19013fc5":"markdown","1e50a614":"markdown","c26ede4c":"markdown","c62a07c0":"markdown","d7ed0bc7":"markdown","6cf576fa":"markdown"},"source":{"f566e7b2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.cm import rainbow\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import scale\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\n\n# Load train dataset\ndigits_train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\n\n# Load test dataset\ndigits_test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","96a97dde":"print(\"Training data:\")\nprint(\"Shape: {}\".format(digits_train.shape))\nprint(\"Total images: {}\".format(digits_train.shape[0]))\n\nprint(\"Testing data:\")\nprint(\"Shape: {}\".format(digits_test.shape))\nprint(\"Total images: {}\".format(digits_test.shape[0]))","7143dd22":"# Check for missing values in the train data\ndigits_train.isnull().sum().head(20)\n# There are no missing values in the train data set.|","f93c324b":"## Visualizing the number of class and counts in the datasets\nplt.plot(figure = (22,16))\ng = sns.countplot( digits_train[\"label\"])\nplt.title('Number of digit classes')\ndigits_train.label.astype('category').value_counts()","6df10c54":"digits_train_subset = digits_train.loc[:8400]","48b724fb":"## Visualizing the number of class and counts in the datasets\nplt.plot(figure = (22,16))\ng = sns.countplot( digits_train_subset[\"label\"])\nplt.title('Number of digit classes')\ndigits_train_subset.label.astype('category').value_counts()","0cb6470a":"X_tr = digits_train_subset.iloc[:,1:] # iloc ensures X_tr will be a dataframe\ny_tr = digits_train_subset.iloc[:, 0]","1190a8d0":"#Lets split the train and test data with standard 70% train data and 30% test data\nX_train, X_test, y_train, y_test = train_test_split(X_tr,y_tr,test_size=0.3, random_state=100, stratify=y_tr)","8b7245a1":"np.random.seed(0)\nplt.figure(figsize = (20, 8))\nfor i in range(20):\n    index = np.random.randint(X_train.shape[0])\n    image_matrix = X_train.iloc[index].values.reshape(28, 28)\n    plt.subplot(4, 5, i+1)\n    plt.imshow(image_matrix, cmap=plt.cm.gray)","3006f5d1":"from time import time\nrandom_forest_classifier = RandomForestClassifier()\nstart_time = time()\nrandom_forest_classifier.fit(X_train, y_train)\nprint('Fitting time: ', time() - start_time)\ny_pred = random_forest_classifier.predict(X_test)","da2d236b":"print(\"Accuracy: {}%\".format(accuracy_score(y_test, y_pred)*100))\nprint(\"Confusion Matrix:\")\nprint(\"{}\".format(confusion_matrix(y_test, y_pred)))","8a5df4f0":"param_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 50, 100],\n    'min_samples_split': [2, 4],\n    'max_features': ['sqrt', 'log2']\n}\n\nstart_time = time()\ngrid = GridSearchCV(random_forest_classifier, param_grid = param_grid, cv = 5, verbose = 5, n_jobs = -1)\ngrid.fit(X_train, y_train)\nprint('Fitting time: ', time() - start_time)\nbest_estimator = grid.best_estimator_","e9afa84c":"best_pred_y = best_estimator.predict(X_test)\nprint(\"Accuracy: {}%\".format(accuracy_score(y_test, best_pred_y)*100))\nprint(\"Confusion Matrix:\")\nprint(\"{}\".format(confusion_matrix(y_test, best_pred_y)))","b583548d":"##### To identify the best combination of parameter values for the model, I used GridSearchCV. It\u2019s a method provided by the sklearn library which allows us to define a set of possible values we wish to try for the given model and it trains on the data and identifies the best estimator from a combination of parameter values.","46a01688":"#####  Above plot shows distribution is little biased towards digit '1'(exact 4684) and least biased towards digit '5' (exact 3795), which is ~21% higher (number 1 is 21% higher than number '5') So moving on.","8d476f19":"### Building on SVM Model (Using RandonForestClassifier)","c47c994b":"#### 1. Import the required libraries and load the dataset.\n#### 2. Pre-Process Data (Understanding and Cleaning the data).\n#### 3. Data preparation for model building.\n#### 4. Building on SVM Model (RandomForectClassifier and XGBoostClassifier for time comparision).\n#### 5. Hyperparameter Tuning\n#### 6. Model Evaluation\n#### 7. Conclusion\n","2371b624":"##### Above plot on the subset data shows distribution is again little biased towards digit '1'(exact 926) and least biased towards digit '5' (exact 757), which is ~21% higher (number 1 is 21% higher than number '5') so we can work on the subset of the data for faster processing and accuracy should be almost equivalent to as we have worked on the whole set of data. In other words moving forward we can work on digits_train_subset data frame.","da098bca":"### Parameter Tuning:","5f7d3003":"#####  In this particular case, I decided to select a range of values for a few parameters. The numbers of estimators could be 100 or 200, maximum depth could be 10, 50 or 100, minimum samples split at 2 or 4 and maximum features can be based on sqrt or log2.The GridSearchCV expects the estimator which in our case is the random_forest_classifier. We pass the possible parameter values as param_grid, and keep the cross-validation set to 5. Setting verbose as 5 outputs a log to the console and njobs as -1 to use all cores of the machine. Then, I fit this grid and use it to find the best estimator.","5045f5f2":"#### So before tuning the parameters we got the accuracy of ~90% on the training data, which is fairly good, lets tune the parameters now.","bbd5fb90":"#### Viewing the training images: Let\u2019s also see how the images look in real. I randomly select 20 images from the training data and display it using plt.imshow().","8cae9b16":"### 1. Import Requisite Libraries and Load Data:","90039614":"## Approach:","05598a79":"##### Since we have 42000 rows (possible hand written digits, it would take time to process the data and build the model, while fitting the model, lets try to subset the data) Lets take 20% of the original train data and again plot the distribution plot and see how is the bias.","544670e1":"## Objective:","081245f0":"### 2. Pre-Process Data (Data understanding and Cleaning):","73b10cc5":"##### The model achieved an accuracy of ~95%. The confusion matrix shows that the model was able to predict a lot of images correctly.Taking a look at the accuracy above, we see that the accuracy improved to ~95% from ~90% just by changing the parameters of the model. The confusion matrix also shows that more images were classified correctly.Machine learning is not just reading the data and applying multiple algorithms till we get a good model to work with but it also involves fine tuning the models to make them work best for the data at hand.","d8193dd7":"##### Next, using the prediction, I calculated the accuracy and confusion matrix.","a3cf315e":"\n<font color='brown' size = 12>Handwritten Digits Recognition<\/font>\n<\/br>","81823765":"### Conclusion:","19013fc5":"#### Something we immediately see in the 20 random images is the difference between digits of any one type too. Take a look at all the 8 or 9 in the above 20 images. See the difference yourself.","1e50a614":"##### Since there are handwritten digits to identify which ranges from 0-9 and also as they are handwritten a single digit might be written in different ways, which depends upon personal flavour. Lets find out if the digits ranging from 0-9 are evenly distributed or biased towards a particual digit.","c26ede4c":"<font color='red'>NOTE : While solving this problem during the experiment I found that GridSearchCV was taking too much time while working on the whole training set. and with different classifiers, so I Decided to take 20% of the original training set and build model on that, an i found pretty good accuracy on that > 94%, Also I did tried with various classifiers to fit the model and I found that RandomForestClassifier works better than anyone else. Also note that to use the XGBoost(If we use XGBoost Classifier) we have to install it separately and I found lots of issues while installing it, and finally i settled with the guidelines given here: https:\/\/xgboost.readthedocs.io\/en\/latest\/build.html\n<\/font>","c62a07c0":"##### So there is no missing data","d7ed0bc7":"### 3. Data Preparation for model building:","6cf576fa":"### We will develop a model using Support Vector Machine which should correctly classify the handwritten digits from 0-9 based on the pixel values given as features. Thus, this is a 10-class classification problem. Since digits are handwritten hence, it is possible that a single digit for exmaple \"8\" is been written in different ways, so we got to develop a model which correctly identifies all the possible handwritten representations of '8' correctly."}}