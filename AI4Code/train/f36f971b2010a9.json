{"cell_type":{"a239c4c0":"code","765223c7":"code","f983aa3c":"code","38d49168":"code","e73ea69f":"code","9dde722d":"code","c9c17b10":"code","b6e7a2f0":"code","848d1dd6":"code","c6f730ca":"code","f1bb8191":"code","c21b977a":"code","d33e072c":"code","27776f93":"code","56772c27":"code","118ad75c":"code","7bef4bf6":"code","04a39b8f":"code","0146170c":"code","0e0855fa":"code","8f6b8b96":"code","fdb4269a":"code","2ef50247":"code","e75b3c13":"code","6dd0174f":"code","6de3a308":"code","422bb749":"code","0062d925":"code","8bd1f0d8":"code","dbe09239":"code","49424c7b":"code","1f025a11":"markdown","7465d15b":"markdown","65b7a48c":"markdown","21cece00":"markdown","a67e1d01":"markdown","0a00fadf":"markdown","3f163835":"markdown","aa052f86":"markdown","2db52ef1":"markdown","a6796e60":"markdown","c90a2e30":"markdown","5d12ba66":"markdown","4fc61232":"markdown","b637e6e3":"markdown","726d5f45":"markdown"},"source":{"a239c4c0":"import tensorflow as tf\nimport keras","765223c7":"# Import the dataset\nfrom keras.datasets import mnist\n\n# Import various componenets for model building\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.layers import LSTM, Input, TimeDistributed\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop\n\n# Import the backend\nfrom keras import backend as K\n\n# For Kaggle\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","f983aa3c":"# # Load Kaggle Data\nPATH = '..\/input\/'\ntest = pd.read_csv(PATH+\"test.csv\")              #  Sets testing object as a DataFrame\ndataset = pd.read_csv(PATH+\"train.csv\")             #  Set training object as a DataFrame\ntarget = dataset['label'].values.ravel()                #  Set target as the label values flattened to an ndarray(N-dimensional Array)                                            \ntrain = dataset.iloc[:,1:].values                   #  Set train as the pixel values\n\n# # convert to array, specify data type, and reshape\ntargets = target.astype(np.uint8)\ntrains = np.array(train).reshape((-1, 1, 28, 28)).astype(np.uint8)\ntests = np.array(test).reshape((-1, 1, 28, 28)).astype(np.uint8)\n\nplt.imshow(trains[1729][0], cmap=cm.binary) # draw the picture\n\nplt.show()\n\ny = target                 # Set y equal to label values, ravel strips extra dimensional array \nX = train                    # Set X equal to pixels\n\nprint(\"splitting...\")                          # distribute 4 sets\nX_train, X_test, Y_train, Y_test = train_test_split(X, \n                    y, test_size=0.5) ","38d49168":"(x_train, y_train), (x_test, y_test) = mnist.load_data()","e73ea69f":"%matplotlib inline\n# The function below plots the images with their labels above\n# Code sampled from ..\/03.%20Dimension%20Reduction.ipynb\n\nimport matplotlib.pyplot as plt    #import pylab library which is suited for plotting images\n\n# Set X and y to plot\nnames = np.sort(dataset.label.unique())     # Created sorted labels array to match titles with images\ndone = set()                                # Create and empty set of explored indices\n\n#  Create function to plot single digit of interest\ndef plot_now(images, h=28, w=28, cmap=plt.cm.binary, indx=True, r=0):    # Set default constructor values  \n    plt.imshow(images.reshape((h, w)), cmap=cmap)                        # Reshape images and set cmap color\n    if indx==True:\n        plt.xlabel('index: '+str(r), size=12)                  # Option to show index\n        plt.title(names[y][r], size=16)                                      # Sets title from sorted names [y] and index [r] \n    plt.xticks(())                              # Eliminate tick marks\n    plt.yticks(())\n\n#  Create function to plot a gallery of interest\ndef plot_gallery(images, titles,  h=28, w=28, n_row=3, x=1.7, y=2.3, n_col=6, \n                 cmap=plt.cm.binary, random=True, indx=True, r=0, size=16):  \n    # Optional row and size parameters will allow us to reuse code, set random to false and r to an index of your choice\n    # to see a continous gallery\n\n    plt.figure(figsize=(x * n_col, y * n_row))                          # Set figure size as a ratio of rows\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35) # Adjust spacing of subplots\n    for i in range(n_row * n_col):                                         # Adjust spacing of subplots\n        move=True                  # logical to move on if a random int is found not in the done set()                                       \n        while random and move:      \n            r=(np.random.randint(len(images)-(n_row*n_col)-1))          # Create a random integer no greater than the size of the set, and gallery\n            if r not in done:                                        # if integer has not been used \n                done.add(r+i)                                       # add to set\n            move=False          # Optional randomization to explore sets\n        plt.subplot(n_row, n_col, i + 1)                        # create subplot for each\n        plt.imshow(images[i+r].reshape((h, w)), cmap=cmap)      # plot images reshaped to 28*28\n        if indx==True:plt.xlabel('index: '+str(i+r), size=12)   # print index if True\n        plt.title(titles[i+r], size=size)                       # print label\n        plt.xticks(())\n        plt.yticks(())   # remove ticks","9dde722d":"plot_gallery(X, names[y], 28, 28, indx=True, random=True, cmap=plt.cm.gray)","c9c17b10":"N=17972\nplot_now(X[17972], cmap=plt.cm.inferno, indx=False)","b6e7a2f0":"# mask the black pixels\nblack = np.ma.masked_where(X <= 200, X)\n\n# black = black.compressed()\n# blacks = black.reshape(42000, 784).astype(np.uint8).ravel()","848d1dd6":"plot_now(X[N], cmap=plt.cm.gray, indx=False, r=N)","c6f730ca":"weird = set()  # empty set of strange images\nN=17972       #\nplot_now(black[N], cmap=plt.cm.binary, indx=False, r=N)","f1bb8191":"plot_gallery(black, names[y],  h=28, w=28, n_row=3, x=1.7, y=2.3, n_col=6, \n                 cmap=plt.cm.binary, random=True, indx=True, r=0, size=16)","c21b977a":"# Let's try reducing dimensionality with PCA to 50 components \n# as we have seen from the eigenvectors from lab 1, 50 should be sufficient\n# http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.fit_transform\n# sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False, \n# svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\nfrom scipy import stats, integrate\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes=True)\nfrom sklearn.decomposition import PCA\n\nprint(\"Fitting PCA...\")\nn_comp = 50\n\n# whitening was recommended, as well as arpack solver\n\npca = PCA(n_components=n_comp, whiten=True, svd_solver='arpack')  # Create PCA object\n\n# Set fitted PCA object\ntrainer = pca.fit_transform(X_train)  # fit and transform the pca model in one operation\ntester = pca.fit_transform(X_test)\n\nprint(\"Done!\")","d33e072c":"def pca_plot(X, n_comp, svd_solver='auto', cmap=plt.cm.viridis, scaler=1.0):   # create a plotter function for PCA\n\n    plot_gallery(eigendigits, eigendigit_titles, n_row=int(np.floor(np.sqrt(n_comp))),   # set gallery size to number of PCA to scaler\n                 n_col=int(np.ceil(np.sqrt(n_comp))), x=(1.7*scaler), y=(2.3*scaler), \n                 indx=False, random=False, cmap=cmap, size=(16*scaler))","27776f93":"try:\n    eigendigits = pca.components_.reshape((n_comp, 28, 28))    # set eigenvalues \n    eigendigit_titles = [\"eigendigit %d\" % i for i in range(eigendigits.shape[0])]  #create the labels\n    pca_plot(train, 20, scaler=0.5)\nexcept IndexError:\n    pass","56772c27":"evr = pca.explained_variance_ratio_         # call evr on the PCA object to get the variance explained by each PC\nprint( round(sum(evr)*100), \"Percent Variance Explained by\", n_comp, 'PCs')\n\n# Create cumulative series to plot\ncum = 0\nd = []\nevr = pca.explained_variance_ratio_\n\nfor i in range(n_comp):  \n    cum += evr[i]\n    d.append(cum)","118ad75c":"sns.set(style='darkgrid')\nplt.plot(d, color='orange', label=True)\nplt.title('Cumulative Distribution')\nplt.xlabel('PC')\nplt.ylabel('percent var explained')\nplt.show()","7bef4bf6":"# n_comp = 100\n# # whitening was recommended, as well as arpack solver\n# pca = PCA(n_components=n_comp, whiten=True, svd_solver='arpack')  # Create PCA object\n\n# print(\"fitting...\")\n# # Set fitted PCA object\n# x_train = pca.fit_transform(x_train)  # fit and transform the pca model in one operation\n# x_test = pca.fit_transform(x_test)\n# print('done!')\n","04a39b8f":"# Create confusion matrix function to plot errors in predictions\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","0146170c":"from sklearn.ensemble import RandomForestClassifier \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics as mt\nfrom datetime import datetime as dt\nimport itertools\n\nstart=dt.now()\nrf = RandomForestClassifier(n_estimators=100, n_jobs=-1)  # 100 estimators has seen the most success\nprint(\"Fitting...\")\nrf.fit(X_train, Y_train)\n\ny_hat = rf.predict(X_test)\nconf = mt.confusion_matrix(Y_test,y_hat)\nprint( 'Accuracy', mt.accuracy_score(Y_test,y_hat)*100, '%')\nplot_confusion_matrix(conf, [x for x in range(10)],\n                  normalize=False,\n                  title='Confusion matrix',\n                  cmap=plt.cm.Greens)","0e0855fa":"# Change shape \n# Note that our images are 28*28 pixels, so in reshaping to arrays we want\n# 60,000 arrays of length 784, one for each image\n\n\nx_train = x_train.reshape(x_train.shape[0], 784)\nx_test = x_test.reshape(x_test.shape[0], 784)\n\n# Convert to float32 for type consistency\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\n# Normalize values to 1 from 0 to 255 (256 values of pixels)\nx_train \/= 255\nx_test \/= 255\n\n# Print sample sizes\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# Convert class vectors to binary class matrices\n# So instead of one column with 10 values, create 10 binary columns\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)","8f6b8b96":"# # Start with a simple sequential model\n# model = Sequential()\n\n# # Add dense layers to create a fully connected MLP\n# # Note that we specify an input shape for the first layer, but only the first layer.\n# # Relu is the activation function used\n# model.add(Dense(64, activation='relu', input_shape=(784,)))\n# # Dropout layers remove features and fight overfitting\n# model.add(Dropout(0.1))\n# model.add(Dense(64, activation='relu'))\n# model.add(Dropout(0.1))\n# # End with a number of units equal to the number of classes we have for our outcome\n# model.add(Dense(10, activation='softmax'))\n\n# model.summary()\n\n# # Compile the model to put it all together.\n# model.compile(loss='categorical_crossentropy',\n#               optimizer=RMSprop(),\n#               metrics=['accuracy'])","fdb4269a":"# history = model.fit(x_train, y_train,\n#                     batch_size=128,\n#                     epochs=10,\n#                     verbose=1,\n#                     validation_data=(x_test, y_test))\n# score = model.evaluate(x_test, y_test, verbose=0)\n# print('Test loss:', score[0])\n# print('Test accuracy:', score[1])","2ef50247":"# # input image dimensions, from our data\n# img_rows, img_cols = 28, 28\n# num_classes = 10\n\n# # the data, shuffled and split between train and test sets\n# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# if K.image_data_format() == 'channels_first':\n#     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n#     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n#     input_shape = (1, img_rows, img_cols)\n# else:\n#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n#     input_shape = (img_rows, img_cols, 1)\n\n# x_train = x_train.astype('float32')\n# x_test = x_test.astype('float32')\n# x_train \/= 255\n# x_test \/= 255\n# print('x_train shape:', x_train.shape)\n# print(x_train.shape[0], 'train samples')\n# print(x_test.shape[0], 'test samples')\n\n# # convert class vectors to binary class matrices\n# y_train = keras.utils.to_categorical(y_train, num_classes)\n# y_test = keras.utils.to_categorical(y_test, num_classes)\n\n\n# # Building the Model\n# model = Sequential()\n# # First convolutional layer, note the specification of shape\n# model.add(Conv2D(32, kernel_size=(3, 3),\n#                  activation='relu',\n#                  input_shape=input_shape))\n# model.add(Conv2D(64, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n# model.add(Flatten())\n# model.add(Dense(128, activation='relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(num_classes, activation='softmax'))\n\n# model.compile(loss=keras.losses.categorical_crossentropy,\n#               optimizer=keras.optimizers.Adadelta(),\n#               metrics=['accuracy'])\n\n# model.fit(x_train, y_train,\n#           batch_size=128,\n#           epochs=10,\n#           verbose=1,\n#           validation_data=(x_test, y_test))\n# score = model.evaluate(x_test, y_test, verbose=0)\n# print('Test loss:', score[0])\n# print('Test accuracy:', score[1])","e75b3c13":"\n# # Training parameters.\n# batch_size = 64\n# num_classes = 10\n# epochs = 3\n\n# # Embedding dimensions.\n# row_hidden = 32\n# col_hidden = 32\n\n# # The data, shuffled and split between train and test sets.\n# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# # Reshapes data to 4D for Hierarchical RNN.\n# x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n# x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n# x_train = x_train.astype('float32')\n# x_test = x_test.astype('float32')\n# x_train \/= 255\n# x_test \/= 255\n# print('x_train shape:', x_train.shape)\n# print(x_train.shape[0], 'train samples')\n# print(x_test.shape[0], 'test samples')\n\n# # Converts class vectors to binary class matrices.\n# y_train = keras.utils.to_categorical(y_train, num_classes)\n# y_test = keras.utils.to_categorical(y_test, num_classes)\n\n# row, col, pixel = x_train.shape[1:]\n\n# # 4D input.\n# x = Input(shape=(row, col, pixel))\n\n# # Encodes a row of pixels using TimeDistributed Wrapper.\n# encoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n\n# # Encodes columns of encoded rows.\n# encoded_columns = LSTM(col_hidden)(encoded_rows)\n\n# # Final predictions and model.\n# prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n# model = Model(x, prediction)\n# model.compile(loss='categorical_crossentropy',\n#               optimizer='rmsprop',\n#               metrics=['accuracy'])\n\n# # Training.\n# model.fit(x_train, y_train,\n#           batch_size=batch_size,\n#           epochs=epochs,\n#           verbose=1,\n#           validation_data=(x_test, y_test))\n\n# # Evaluation.\n# scores = model.evaluate(x_test, y_test, verbose=0)\n# print('Test loss:', scores[0])\n# print('Test accuracy:', scores[1])","6dd0174f":"# Start with a simple sequential model\nmodel = Sequential()\n\n# Add dense layers to create a fully connected MLP\n# Note that we specify an input shape for the first layer, but only the first layer.\n# Relu is the activation function used\nmodel.add(Dense(256, activation='relu', input_shape=(784,)))\n# Dropout layers remove features and fight overfitting\nmodel.add(Dropout(0.1))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.1))\n# End with a number of units equal to the number of classes we have for our outcome\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()\n\n# Compile the model to put it all together.\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=RMSprop(),\n              metrics=['accuracy'])","6de3a308":"model.fit(x_train, y_train,\n                    batch_size=128,\n                    epochs=10,\n                    verbose=1,\n                    validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","422bb749":"# import test set from kaggle and test from trained MNIST data\nX_test.shape","0062d925":"X_test = test.values.reshape(28000, 28, 28, 1)","8bd1f0d8":"preds = model.predict_classes(test, verbose=0)","dbe09239":"# my_submission = pd.DataFrame(preds).copy()\n# my_submission.to_csv('submission_KerasMLP2.csv', index=False)","49424c7b":"np.savetxt('submission_KerasMLP2.csv', np.c_[range(1,len(test)+1),preds], \n           delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')","1f025a11":"You should now be comfortable building some neural networks, but let's see if you can improve them!\n\n# Drill: 99% MLP\n\nWe have the MLP above, which runs reasonably quickly. Copy that code down here and see if you can tune it to achieve 99% accuracy with a Multi-Layer Perceptron. Does it run faster than the recurrent or concolutional neural nets?","7465d15b":"## Pick out an image that looks weird and plot it below","65b7a48c":"Great. Now we can create our model. We'll do this using dense layers and dropouts. Dense layers are simply fully connected layers with a given number of perceptrons. Dropout drops a certain portion of our perceptrons in order to prevent overfitting. Our activation function, `relu` stands for Rectified Linear Unit, which is standard but can be read about more [here](https:\/\/en.wikipedia.org\/wiki\/Rectifier_(neural_networks).","21cece00":"## try random forest","a67e1d01":"## Above are random images recreated from the mask at levels of black above 230, as you can see the images have become very simplified, in some cases, over-lossy, but could help combat overfitting.","0a00fadf":"That did impressively well for such a simple neural network, with each epoch training in about 1 second on this machine and giving us an accuracy in the high 90's. But what else can we do? Let's let our model get much more complicated by introducting convolution.\n\n## Convolutional Neural Networks\n\nBefore we go any further, do you recall that we've talked about how complex neural networks can get, and the degree of computational complexity that entails? Well, here we're going to finally truly experience that complexity, so be careful about rerunning this code. It will take some serious time (potentially on the order of hours) to run.\n\nNow that that's out of the way, let's talk convolution. First, a simple definition. Convolution basically takes your data and creates overlapping subsegments testing for a given feature in a set of spaces and upon which it develops its model.\n\nLet's extend that definition since it's incredibly dense.\n\nFirst, you have to define a shape of your input data. This can theoretically be in any number of dimensions, though for our image example we will use 2d, since images are in two dimensions. This is also why you'll see 2D in some of our layer definitions (though more on that later). Our first chunk of code after loading the data does this reshaping (with a conditional on the data format).\n\nOver that shaped data, we then create our tiles, also called __kernels__. These kernels are like little windows, that will look over subsets of the data of a given size. In the example below we create 3x3 kernels, which run overlapping over the whole 28x28 input looking for features. That is the convolutional layer, a way of searching for a subpattern over the whole of the image. We can chain multiple of these convolutional layers together, with the below example having two.\n\nNext comes a pooling layer. This is a _downsampling_ technique, which effectively serves to reduce sample size and simplify later processes. For each value generated by our convolutional layers, it looks over the grid in _non_-overlapping segments and takes the maximum value of those outputs. It's not the feautres exact location then that matters, but its approximate or relative location. After pooling you will want to flatten the data back out, so that it can be put into dense layers as we did in MLP.","3f163835":"Now that is incredibly impressive accuracy. 99% is really exceptional, but it did take a long time to get there. Such are the costs of convolution.\n\nThere is one more classic construction of a neural network: Recurrent, which we'll give quick mention.\n\n## Hierarchical Recurrrent Neural Networks\n\nSo far when we've talked about neural networks we've talked about them as feedforward: data flows in one direction until it reaches the end. Recurrent neural networks do not obey that directional logic, instead letting the data cycle through the network.\n\nHowever, to do this we have to abandon the sequential model building we've done so far and things can get much more complicated. You have to use recurrent layers and often time distribution (which handles the extra dimension created through the LTSM layer, as a time dimension) to get these things running. You can find an example of a hierarchical recurrent network below (via the link [here](https:\/\/github.com\/fchollet\/keras\/blob\/master\/examples\/mnist_hierarchical_rnn.py)). When you get comfortable with networks as they exist in Keras for both convolution and MLP, start exploring recurrence. Note that this will take an even longer time than the previous ones should you choose to run it again.","aa052f86":"When you look at this data you'll notice its organization structure is not images. We don't actually see any pictures of digits here. Instead, what we have is values of pixels, a simple way of converting images into numeric data on which we can train a model.\n\nHowever, this still doesn't look like most of the data we've worked with previously. It's not a single table, but rather a different, higher dimensionality structure. It is often described as a set of clouds, each cloud representing an image. The cloud contains columns of values, representing the darkness of pixels. That's great, but not an easy or meaningful dataset on which to directly train a model. The darkness of the second pixel in the third column isn't likely linearly related to likelihood the cloud represents a certain digit. Instead, we need to find meaningful patterns within our clouds, creating models off of those patterns.\n\nThis is exactly what neural networks are good at. Multiple layers will allow us to transform this clouds full of values into meaningful vectors containing the information we need to be able to create a model, admittedly in an unlabeled and unsupervised fashion. Our output, however, will be labels for each of the clouds, giving us predictions as to what digit they are meant to represent.\n\nLet's get started.","2db52ef1":"## Using a mask we can reduce the dimensionality of the data","a6796e60":"## Compared with the original, this digit has become more recognizeable through the masking, at least in making its most distinguishing feature more pronounced.","c90a2e30":"# Keras for Neural Networks - Guided Example\n\nHere we're going to work through a classic Machine Learning problem - digit recognition. This data is referred to as the MNIST dataset, which stands for Modified National Institute of Standards and Technology, and represents probably the most used dataset in the world for advanced machine learning techniques (though the iris dataset would be a close second). Here we're forgoing a more business focussed dataset for a few reasons. Firstly, this dataset is the most written about dataset in these topics - you'll easily find other guides using pure TensorFlow or other tools like Theano to solve the same problem with the same class of models. Similarly, you can also easily find several different kinds of neural networks being used to solve this problem. This will be valuable as you try to expand your knowledge of different kinds of layers and combinations.\n\nWe'll be building our code off of the examples provided in the Keras documentation, and found in full on its [creator's github](https:\/\/github.com\/fchollet\/keras\/tree\/master\/examples). \n\nOur goal here will be simple but multifaceted. Overall we are going to use the MNIST dataset and neural networks to classify handwritten numbers as the proper digits. This will be thought of as a multi-class classification problem, specifically with 10 classes (one for each possible digit).\n\nHowever, we will use this to teach a few new kinds of neural network compositions, creating three different styles of network and discussing their relative advantages and disadvantages. Through this we will delve a little deeper into neural network theory.\n\nBut before we go too far, let's actually look at the data.\n\n## MNIST DATA","5d12ba66":"Now we have a model. This we can use to accomplish our wildest dreams of data modeling, or at least predict some digits from pixel data. To do that we will use epochs, effectively iterations of the model, improving based on what it learned previously. Batch size is the number of samples to use in each step improving the model and will affect speed, but also slightly negatively impact accuracy (learning in bigger steps will affect what your model learns).\n\nNote that we are going with 64 perceptron wide layers, this is relatively arbitrary, though units within the $2^x$ series will parallelize more efficiently. Also note that our number of parameters is the product of our input width plus one and our layer width. This reflects the number of weights we're creating in that layer.","4fc61232":"## save predictions for submission","b637e6e3":"## Multi Layer Perceptron\n\nLet's start with a kind of neural network we've seen before: a multi-layer perceptron. Recall from our previous neural networks sections that this is a set of perceptron models organized into layers, one layer feeding into the next.\n\nTo do this, we will first need to reshape our data into flat vectors for each digit. We'll also need to convert our outcome to a matrix of binary variables, rather than the digit.","726d5f45":"## The plot above shows the first 20 eigendigits\nThe first 10 eigendigits resemble the following digits: 0, 3, 8, 9 After digit 10 they begin to lose form. These will be the most important to train accurately."}}