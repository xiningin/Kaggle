{"cell_type":{"b3c1765b":"code","c9155caf":"code","bb9e8357":"code","03992175":"code","e35ef8f9":"code","49325d60":"code","011e7ab8":"code","fd051693":"code","45cc189b":"code","a77d3bf2":"code","4124e954":"code","4b1d0bbc":"code","5a524002":"code","a75df7c9":"code","f4e6036d":"code","3875c93a":"code","6d859592":"code","3aa2a1c8":"code","40bb1506":"code","aae58587":"code","1c7b5c9f":"code","426513f2":"code","5057ca36":"code","cbc72d76":"code","17c2f778":"code","45612c47":"code","39e5aeeb":"code","61a99118":"markdown","5d89a029":"markdown","d20eaed9":"markdown","87219123":"markdown","1109f0a6":"markdown","b0621de6":"markdown","1d21ee38":"markdown","108b76c3":"markdown","bd38bf61":"markdown","34993a81":"markdown","0796589b":"markdown"},"source":{"b3c1765b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nimport tensorflow as tf\nimport keras\n","c9155caf":"print('tf version', tf.__version__)\nprint('keras version', keras.__version__)\nprint('numpy version', np.__version__)","bb9e8357":"\nsolarpower = pd.read_csv(\"..\/input\/solarpanelspower\/PV_Elec_Gas3.csv\",header = None,skiprows=1 ,names = ['date','cum_power','Elec_kW', \n                                                                            'Gas_mxm'], sep=',',usecols = [0,1,2,3],\n                     \n                     parse_dates={'dt' : ['date']}, infer_datetime_format=True,index_col='dt')\nprint(solarpower.head(2))\n","03992175":"# make solar power stationary\n\nsolarpower2 = solarpower.shift(periods=1, freq='D', axis=0)\nsolarpower['cum_power_shift'] = solarpower2.loc[:,'cum_power']\nsolarpower['day_power'] = solarpower['cum_power'].values - solarpower['cum_power_shift']\nsolarpower.iloc[0:1].day_power.value = 0.\nA = solarpower.dropna()\ndel A['cum_power'], A['cum_power_shift']\nsolarpower = A","e35ef8f9":"solarpower.head(2), solarpower.tail(2)","49325d60":"X_train = solarpower[:'2018-10-28']\nX_valid = solarpower['2018-10-29':'2019-10-28'] # is 365 days\nX_train.shape, X_valid.shape","011e7ab8":"X_train.tail(2), X_valid.head(2)","fd051693":"X_valid_start_cum_power = solarpower2['2018-10-28':'2018-10-28'].cum_power.values\nX_valid_start_cum_power # we need this to predict cumulative power on validation","45cc189b":"# we devide the series into multiple input and output patterns\n\ndef my_split_window(series, window):\n    '''\n    the series is split in (len(series)-window)-blocks of window size, \n    y is the next value that comes after the block, \n    every block starts with the next value in the series.\n    The last block ends with the last-but-one value in the series.\n    '''\n    X = []\n    y = []\n    n_steps = len(series) - window\n    for step in range(n_steps):\n        X.append(series[step:window+step])\n        y.append(series[step + window])\n    X = np.array(X)\n    y = np.array(y)\n    return X, y","a77d3bf2":"# test my_split_window\nmy_series = np.array([10,20,30,40,50,60,70,80,90])\nX_, y_ = my_split_window(my_series, 3)\nX_, y_\n","4124e954":"# apply my_split_window on dayly solar power with a window of 365 days (we do not make account for leap years)\n# the input series is the daily solar power\ntrain_power_series = X_train.day_power.values\nwindow = 365\nX, y = my_split_window(train_power_series, window)\n# print a sample\nfor i in range(3):\n    print(X[i][-5:], y[i])","4b1d0bbc":"\n# we have an input shape = window size, number of features \n# we use only 1 feature (it is univariate) and we have a window size of one year (365 days) \n# we have to reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n# define model\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv1D(filters=32, kernel_size=4, activation='relu', \n                                 input_shape=(window, n_features)))\nmodel.add(tf.keras.layers.MaxPooling1D(pool_size=2))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(50, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\nmodel.compile(optimizer='adam', loss='mae')  # metrics=['mae'])\n# fit model\nhistory = model.fit(X, y, epochs=600, verbose=0)\n\n# graph of the loss shows convergence\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title('loss')\nplt.xlabel('epochs')\nplt.show()","5a524002":"# predicting next year\nx_input = np.array(X_train.day_power[-365:]) #  next value based on data of last year\nx_input = x_input.reshape((1, window, n_features)) # the model expects three dimensions as input (samples, window, features)\n\nfor i in range(365):\n    y_hat = model.predict(x_input, verbose=0)\n    new_x = y_hat.reshape((1,1,1))\n    x_input = np.concatenate((x_input[:, -364:], new_x), axis=1)\n\n","a75df7c9":"y_predicted = x_input.reshape((x_input.shape[1]))\nplt.plot(y_predicted, label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","f4e6036d":"first_r2_score = r2_score(y_true, y_predicted) # Best possible score is 1.0 \nfirst_mae = mean_absolute_error(y_true, y_predicted)\nprint('r2_score %.4f' % first_r2_score)\nprint('mae %.2f' % first_mae)","3875c93a":"predicted_data = X_valid.copy()","6d859592":"predicted_data['101_predicted_from_predicted'] = y_predicted\npredicted_data.to_hdf('..\/predicted_data.hdf5', key = 'predicted_data ', table='true', mode='a')","3aa2a1c8":"def cumulate(series, start=0):\n    '''\n    start is the starting cumulative power, the series is the daily solar power\n    a list with daily cumulative power is the result\n    '''\n    cum = [start]\n    for i in range(len(series)):\n        sum_plus = cum[i] + series[i]\n        cum.append(sum_plus)\n    return cum","40bb1506":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_predicted)\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","aae58587":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)\/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.2f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))","1c7b5c9f":"# predicting next year\nx_input = np.array(X_train.day_power[-365:]) #  next value based on data of last year\nx_input = x_input.reshape((1, window, n_features))\ny_hat = model.predict(x_input, verbose=0)\nfor i in range(365):\n    new_x = y_hat.reshape((1,))\n    train_power_series = np.concatenate((train_power_series, new_x), axis=0)\n    X, y = my_split_window(train_power_series, window)\n    X = X.reshape((X.shape[0], X.shape[1], n_features))\n    history = model.fit(X, y, epochs=3, verbose=0)\n    x_input = train_power_series[-365:]\n    x_input = x_input.reshape((1, window, n_features))\n    y_hat = model.predict(x_input, verbose=0)\n    if i % 40 ==0:\n        print('at i=', i, 'y_hat',y_hat)","426513f2":"y_predicted = x_input.reshape((x_input.shape[1]))\nplt.plot(y_predicted, label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","5057ca36":"r2_score(y_true, y_predicted) # Best possible score is 1.0 ","cbc72d76":"mae = mean_absolute_error(y_true, y_predicted)\nprint('mae %.2f' % mae)","17c2f778":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_predicted)\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","45612c47":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)\/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.2f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))\n","39e5aeeb":"predicted_data['101_predicted_from_retrained'] = y_predicted\npredicted_data.to_hdf('predicted_data.hdf5', key = 'predicted_data ', table='true', mode='a')","61a99118":"We need both r2 score and mae to evaluate the quality of the predictions","5d89a029":"test 101 : test prediction solarpower with Univariate series and CNN","d20eaed9":"# but the cumulative power is actually much more interesting.#\n# It tels us what the the total expected solar power of that year will be. #","87219123":"100 epochs : \nr2_score 0.2358\nmae 5.32","1109f0a6":"These notebooks are based on the excellent article by Jason Brownlee:\nHow to Develop Convolutional Neural Network Models for Time Series Forecasting.  \nhttps:\/\/machinelearningmastery.com\/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting\/\n\nThese are the notebook that follow:  \n102_Multivariate_multiple_input_series_CNN  \n103_Sol_Elec_Gas_2_1B_Multivariate_mulitple_input  \n104_Sol_Elec_Gas_2_C_Multivariate_parallel_series_CNN_Model  \n105_Sol_Elec_Gas_2_D_Multivariate_parallel_multi_output_CNN_Model  \n106_Sol_Elec_Gas_3_Univariate_Multi_Step_CNN_Model  \n107_Sol_Elec_Gas_4_Multivariate_Multi_Step_CNN_Model  \n108_Sol_Elec_Gas_1_Univariate_LSTM_and_CNN_Model  \n\n\n","b0621de6":"We now look at the cumulative power over one year","1d21ee38":"# But what if we use y_hat to train the model again for every day?","108b76c3":"This notebook uses: tf 2.0.0  \nkeras 2.2.4\nnumpy 1.16.4","bd38bf61":"We want to use a one-dimensional Convolutional Neural Network (1D CNN). Just like in a CNN for images,  \na 1D CNN extracts features. It is very usefull in timeseries. More info is on theze links:  \nhttps:\/\/missinglink.ai\/guides\/keras\/keras-conv1d-working-1d-convolutional-neural-networks-keras\/  \nhttps:\/\/machinelearningmastery.com\/cnn-models-for-human-activity-recognition-time-series-classification\/  \n","34993a81":"This is better than without retraining but it grows too fast at the end","0796589b":"The error increases after 4 months"}}