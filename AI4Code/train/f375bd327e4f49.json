{"cell_type":{"edc8c855":"code","33910bdb":"code","d8c42017":"code","5988991c":"code","d48de57c":"code","c28bcf67":"code","c7f02225":"code","1d1447b3":"code","5e5cf5a9":"code","695ea711":"code","fc9d1041":"code","cb9c6060":"code","2593f7a3":"code","36462fc5":"markdown","72f098d8":"markdown","0f2ae9e1":"markdown","b7a936f1":"markdown","5af1bac2":"markdown","1d122cfd":"markdown","1e3c72b1":"markdown","627168cb":"markdown","7eca0149":"markdown","0fd942d6":"markdown","694a5697":"markdown","ec84e76a":"markdown","25dca881":"markdown","c0f6cb37":"markdown","1bd297e7":"markdown","b82413a1":"markdown","6ba4ba92":"markdown","929e61bf":"markdown"},"source":{"edc8c855":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","33910bdb":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d8c42017":"df = pd.read_csv('\/kaggle\/input\/lgcovid19hotp\/lg-covid19-hotp-article-info.csv', encoding = \"ISO-8859-1\")\ndf.head()","5988991c":"df.describe()","d48de57c":"years = df['year']","c28bcf67":"fig = plt.figure(figsize=(10,8))\nplt.xlabel('year')\nplt.ylabel('#articles (logscale)')\nyears.hist(range=(1950, 2020), bins=70, log=True)\nplt.show()","c7f02225":"from scipy.io import mmread\nA = mmread('\/kaggle\/input\/lgcovid19hotp\/lg-covid19-hotp-literature-graph.mtx')","1d1447b3":"inCitations = np.asarray( A.sum(axis=1) ).squeeze()","5e5cf5a9":"sortedIndices = np.argsort(inCitations)\nsortedIndices = sortedIndices[::-1]   # Default sorting is ascending so convert it to descenting\ntop = df.iloc[sortedIndices[0:50]]\ntitles = top['title'].tolist()\ntopInCitations = inCitations[sortedIndices[0:50]].squeeze()","695ea711":"# Get unique elements and unique counts\nu, uniqueCounts = np.unique(topInCitations, return_counts=True)\nuniqueCounts = uniqueCounts[::-1]\nu = u[::-1]\n\n# 50x1 vector to hold each rank\nranks = np.zeros((len(topInCitations), 1)).squeeze()\n\ni = 0  # Loop iterator\nlast = 0  # Index to last position of ranks array\nrank = 1  # Current rank\nwhile i<len(u):\n    width = uniqueCounts[i]  # Number of articles with the same rank at each repetition\n    ranks[last:last+width] = rank\n    rank += 1\n    i += 1\n    last += width","fc9d1041":"# Bokeh Libraries\nfrom bokeh.io import output_notebook\nfrom bokeh.plotting import figure, show\nfrom bokeh.models import HoverTool\nfrom bokeh.models import ColumnDataSource\n\n# Output the visualization directly in the notebook\noutput_notebook()\n\n# Create a figure with no toolbar\nfig = figure(y_axis_label='#citations (logscale)', y_axis_type='log',\n             x_axis_label='rank',\n             plot_height=600, plot_width=800,\n             x_range=(0, 50), y_range=(250, 1000),\n             toolbar_location=None)\n\ndata={\n    'x': ranks,\n    'y': topInCitations,\n    'title': titles\n}\nsource = ColumnDataSource(data=data)\n\n# Draw the coordinates as circles\nfig.circle(x='x', y='y', source=source,\n           color='blue', size=10, alpha=0.5)\n\n# Format the tooltip\ntooltips = [\n            ('x', '@x'),\n            ('y', '@y'),\n            ('title', '@title')\n           ]\n\n\n# Add the HoverTool to the figure\nfig.add_tools(HoverTool(tooltips=tooltips))\n\n# Show plot\nshow(fig)","cb9c6060":"# Keep only generation 1\ngen1 = df[df['generation'] == 1]\ngen1Indices = gen1.index.tolist()\ngen1Citations = inCitations[gen1Indices].squeeze()\ngen1Citations.sort()\ngen1Citations = gen1Citations[::-1]\n\ngen1titles = df.iloc[gen1Indices]\ngen1titles = gen1titles['title'].tolist()\n\n# Get unique elements and unique counts\nu, uniqueCounts = np.unique(gen1Citations, return_counts=True)\nuniqueCounts = uniqueCounts[::-1]\nu = u[::-1]\n\n# vector to hold each rank\nranks = np.zeros((len(gen1Citations), 1)).squeeze()\n\ni = 0  # Loop iterator\nlast = 0  # Index to last position of ranks array\nrank = 1  # Current rank\nwhile i<len(u):\n    width = uniqueCounts[i]  # Number of articles with the same rank at each repetition\n    ranks[last:last+width] = rank\n    rank += 1\n    i += 1\n    last += width","2593f7a3":"# Output the visualization directly in the notebook\noutput_notebook()\n\n# Create a figure with no toolbar\nfig = figure(y_axis_type='log',\n             y_axis_label='#citations (log scale)', x_axis_label='rank',\n             plot_height=800, plot_width=1000,\n             x_range=(0, 150), y_range=(0, 1000),\n             toolbar_location=None)\n\ndata={\n    'x': ranks,\n    'y': gen1Citations,\n    'title': gen1titles\n}\nsource = ColumnDataSource(data=data)\n\n# Draw the coordinates as circles\nfig.circle(x='x', y='y', source=source,\n           color='blue', size=8, alpha=0.5)\n\ncustom_hover = HoverTool()\n\ncustom_hover.tooltips = \"\"\"\n    <style>\n        .bk-tooltip>div:not(:first-child) {display:none;}\n    <\/style>\n\n    <b>X: <\/b> @x <br>\n    <b>Y: <\/b> @y <br>\n    <b>Title: <\/b> @title \n\"\"\"\n\n# Add the HoverTool to the figure\nfig.add_tools(custom_hover)\n\n# Show plot\nshow(fig)","36462fc5":"---","72f098d8":"## So let's get started and explore the dataset","0f2ae9e1":"Now that we have the necessary data, let's do the plotting","b7a936f1":"## After viewing the basic metrics and statistics, we will procceed to some plotting to describe the data better","5af1bac2":"Next we need to calculate the rank of each article by taking into account that many articles could have the same number of citations and consequently the same rank. The following code will do the job.","1d122cfd":"The dataset comes with 2 files:\n * **lg-covid19-hotp-article-info.csv** which contains the 100.000+ article as rows and 6 columns including *DOI, title, publication year, inCitCrossref, outCitCrossref* and *generation*\n * **lg-covid19-hotp-literature-graph.mtx** which is a 103.861x103.861 sparse matrix with a non-zero entry at cell (i, j) indicating that article i was cited by article j(or article j referenced article i)","1e3c72b1":"Variable *inCitations* is a 103.861x1 vector containing the number of citations for each article. \n\nFollowing the same logic we could also calculate the number of referencecs of each article by simply summing the rows.\n\nLet's sort the vector and extract the top 50 along with the corresponding table rows from the csv.","627168cb":"The y axis will be in log10 scale for more clarity and we will use articles from 1950 to 2020 with 70 bins.","7eca0149":"---","0fd942d6":"Following the same procedure for the data from generation 1 yields yields the graph below","694a5697":"Now, calculating the number of citations for each article is as easy as summing the columns!","ec84e76a":"First of all import all related libraries","25dca881":"## First, lets take a look at the csv file using **pandas** library","c0f6cb37":"and list the dataset files","1bd297e7":"## Next, we are going to plot the **number of citations** for the top-50 ranked articles\nTo do this we will need to import our second file, **lg-covid19-hotp-literature-graph.mtx**. Since it is in the portable matrix format **.mtx** we will use the **mmread** function from **scipy** package. This will load the matrix into **COO format**, but conversion to other sparse matrix formats is very easy(details [here](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/sparse.html) )","b82413a1":"# Exploring COVID19 related publications in a structured way\n\nFollowing and in parallel to the recently released dataset [CORD-19](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge) of scholarly articles, we provide the literature graph [LG-covid19-HOTP (10.5281\/zenodo.3728215)](https:\/\/zenodo.org\/record\/3728216#.XoRsfKdfiV4) composed of not only articles (graph nodes) that are relevant to the study of coronavirus, but also citation links (graph edges) for facilitating navigation and search among the articles. The article records are related and connected, not isolated, in the same spirit of other existing literature graphs, and focused around the particular theme of covid-19 study.\n\nThe graph nodes include more than 800 hot-off-the-press (HOTP) articles since January 2020. The graph contains about one hundred thousand articles and nearly one million links. In addition to the dataset, we provide basic meta-data analysis and interactive visualization in terms of publication growth over time, ranking by citation, similarity in co-citation, and similarity in co-reference.","6ba4ba92":"We will start with a **histogram** of the **publication year** of the articles. For that we will need to extract the years column from the data","929e61bf":"---"}}