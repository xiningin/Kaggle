{"cell_type":{"ac5e5fc7":"code","1ac303e1":"code","c28009a1":"code","5c5fd7b3":"code","0428e6b6":"code","48f0b0e5":"code","208db5b2":"code","b1aa48f3":"code","03898d1d":"code","10a83c09":"code","d6d4c301":"code","7dd2ba2e":"code","12f03615":"code","6dd81e6b":"code","21e9d9cb":"code","9ee985b5":"code","b010c15f":"code","3bcaad5b":"code","e82c3904":"code","e5e6e0d4":"code","8827b19b":"code","63cfae3b":"code","1e18e1ad":"code","0efe65a4":"code","2e17daf5":"code","4b400d73":"code","6db6c74e":"code","d1f3e85c":"code","5ec0cd8a":"code","0cbec0d8":"code","1ce7e741":"code","5729b427":"code","82862783":"code","f8664189":"markdown","1f1dce5e":"markdown","92b38d37":"markdown","bcbb3b6b":"markdown","e0d1e608":"markdown","426c0313":"markdown","f7efba84":"markdown","781d1c3c":"markdown","8c26c128":"markdown","47604173":"markdown","cdca1fbb":"markdown","d450773d":"markdown","8c38a4c2":"markdown","c4f7ae23":"markdown","df8d673d":"markdown","39b7a717":"markdown","28a6e527":"markdown","c8919823":"markdown"},"source":{"ac5e5fc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ac303e1":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nimport seaborn as sns\nfrom colorama import Fore, Back, Style \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom plotly.offline import plot, iplot, init_notebook_mode\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nfrom statsmodels.formula.api import ols\nimport plotly.graph_objs as gobj\n\ninit_notebook_mode(connected=True)\nwarnings.filterwarnings(\"ignore\")\nimport plotly.figure_factory as ff\n%matplotlib inline\n\nimport xgboost\nimport lightgbm\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier","c28009a1":"heart_data = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\nheart_data.head()","5c5fd7b3":"heart_data.columns ","0428e6b6":"fig = go.Figure()\nfig.add_trace(go.Histogram(x=heart_data['age'],xbins=dict(start = 20,end=95,size=2),))\n\nfig.update_layout(\ntitle_text= 'Age distribution',\nxaxis_title_text = 'Age',\nyaxis_title_text= 'Count',\nbargap = 0.05,\ntemplate='plotly_dark')\n","48f0b0e5":"fig = px.histogram(heart_data, x='age', color = \"DEATH_EVENT\",hover_data=heart_data.columns, title=\"Distribution of death evevnt amongst the age groups\",labels={'age':\"AGE\"})\nfig.show()","208db5b2":"d1 = heart_data[(heart_data['DEATH_EVENT']==0) & (heart_data['sex']==1)]\nd2 = heart_data[(heart_data['DEATH_EVENT']==1) & (heart_data['sex']==1)]\nd3 = heart_data[(heart_data['DEATH_EVENT']==0) & (heart_data['sex']==0)]\nd4 = heart_data[(heart_data['DEATH_EVENT']==1) & (heart_data['sex']==0)]\n\ngender_labels = ['Male','Females']\ndeath_labels = ['Male-Survived','Male-decesed','Female-survived','Female-deceased']\ngender_value = [(len(d1)+len(d2)),(len(d3)+len(d4))]\ndeath_ratio_value = [len(d1),len(d2),len(d3),len(d4)]\n\nfig = make_subplots(rows=1,cols=2,specs = [[{'type':'domain'},{'type':'domain'}]])\nfig.add_trace(go.Pie(labels=gender_labels,values=gender_value,name='Gender ratio'),1,1)\nfig.add_trace(go.Pie(labels=death_labels,values=death_ratio_value,name='Gender and death ratio'),1,2)\n\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\nfig.update_layout(title_text=\"  GENDER DISTRIBUTION IN THE DATASET                           GENDER VS DEATH_EVENT\")\n\n","b1aa48f3":"d1 = heart_data[(heart_data['DEATH_EVENT']==0) & (heart_data['diabetes']==0)]\nd2 = heart_data[(heart_data['DEATH_EVENT']==1) & (heart_data['diabetes']==0)]\nd3 = heart_data[(heart_data['DEATH_EVENT']==0) & (heart_data['diabetes']==1)]\nd4 = heart_data[(heart_data['DEATH_EVENT']==1) & (heart_data['diabetes']==1)]\n\nlabels1 = ['No diabetes ','diabetes']\nlabels2 = ['Non-diabetic survivor','non-diabetic deceased','diabetic-survivor','diabetic decesaed']\nvalue1 = [(len(d1)+len(d2)),(len(d3)+len(d4))]\nvalue2 = [len(d1),len(d2),len(d3),len(d4)]\n\nfig = make_subplots(rows=1,cols=2,specs = [[{'type':'domain'},{'type':'domain'}]])\nfig.add_trace(go.Pie(labels=labels1,values=value1,name='diabetic ratio'),1,1)\nfig.add_trace(go.Pie(labels=labels2,values=value2,name='diabetic and death ratio'),1,2)\n\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\nfig.update_layout(title_text=\"  Diabetic ratio and Diabetic death ratio\")","03898d1d":"fig = px.violin(heart_data,x = 'smoking',y= 'age',color=\"DEATH_EVENT\",box=False, points = 'all',hover_data= heart_data.columns)\nfig.show()","10a83c09":"fig = px.histogram(heart_data, x='ejection_fraction', color = \"DEATH_EVENT\",hover_data=heart_data.columns, title=\"Ejection fraction vs Death Event\",labels={'ejection_fraction':\"Ejection Fraction\"})\nfig.show()","d6d4c301":"plt.rcParams['figure.figsize']=20,12\nsns.set_style(\"darkgrid\")\n\nx = heart_data.iloc[:, :-1]\ny = heart_data.iloc[:,-1]\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(x,y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(12).plot(kind='barh')\nplt.show()","7dd2ba2e":"Features = ['time','ejection_fraction','serum_creatinine','age']\nx = heart_data[Features]\ny = heart_data[\"DEATH_EVENT\"]\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=2)","12f03615":"accuracy_list = []","6dd81e6b":"#logistic regression\n\nlog_reg = LogisticRegression()\nlog_reg.fit(x_train,y_train)\nlog_reg_prediction = log_reg.predict(x_test)\nlog_reg_accuracy = accuracy_score(y_test,log_reg_prediction)\naccuracy_list.append(log_reg_accuracy)\nprint(Fore.BLACK + \"Accuracy of Logistic Regression is : \", \"{:.2f}%\".format(100* log_reg_accuracy))","21e9d9cb":"cm = confusion_matrix(y_test, log_reg_prediction)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Logistic Regression Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","9ee985b5":"sv_clf = SVC()\nsv_clf.fit(x_train,y_train)\nsv_preds = sv_clf.predict(x_test)\nsv_accuracy = accuracy_score(y_test,sv_preds)","b010c15f":"accuracy_list.append(sv_accuracy)\nprint(Fore.GREEN + \"Accuracy of SVC is : \", \"{:.2f}%\".format(100* sv_accuracy))","3bcaad5b":"cm = confusion_matrix(y_test,sv_preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Reds)\nplt.title('SVC Confusion Matrix')\nplt.xticks(range(2),['heart not failed','heart failed'],fontsize=16)\nplt.yticks(range(2),['heart not failed','heart failed'],fontsize=16)\nplt.show()\n","e82c3904":"xgb_clf = xgboost.XGBRFClassifier(max_depth=3, random_state=1)\nxgb_clf.fit(x_train,y_train)\nxgb_pred = xgb_clf.predict(x_test)\nxgb_acc = accuracy_score(y_test, xgb_pred)\naccuracy_list.append(xgb_acc)","e5e6e0d4":"print(Fore.GREEN + \"Accuracy of XGBRFClassifier is : \", \"{:.2f}%\".format(100* xgb_acc))","8827b19b":"cm = confusion_matrix(y_test,xgb_pred)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Reds)\nplt.title('SVC Confusion Matrix')\nplt.xticks(range(2),['heart not failed','heart failed'],fontsize=16)\nplt.yticks(range(2),['heart not failed','heart failed'],fontsize=16)\nplt.show()","63cfae3b":"lgb_clf = lightgbm.LGBMClassifier(max_depth=2, random_state=4)\nlgb_clf.fit(x_train,y_train)\nlgb_pred = lgb_clf.predict(x_test)\nlgb_acc = accuracy_score(y_test, lgb_pred)\naccuracy_list.append(lgb_acc)","1e18e1ad":"print(Fore.GREEN + \"Accuracy of LGBMClassifier is : \",\"{:.2f}%\".format(100* lgb_acc))","0efe65a4":"cm = confusion_matrix(y_test, lgb_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"LGBMClassifier Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","2e17daf5":"# K Neighbors Classifier\n\nkn_clf = KNeighborsClassifier(n_neighbors=6)\nkn_clf.fit(x_train, y_train)\nkn_pred = kn_clf.predict(x_test)\nkn_acc = accuracy_score(y_test, kn_pred)\naccuracy_list.append(kn_acc)","4b400d73":"print(Fore.GREEN + \"Accuracy of K Neighbors Classifier is : \", \"{:.2f}%\".format(100* kn_acc))","6db6c74e":"cm = confusion_matrix(y_test, kn_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"K Neighbors Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","d1f3e85c":"# GradientBoostingClassifier\n\ngradientboost_clf = GradientBoostingClassifier(max_depth=2, random_state=1)\ngradientboost_clf.fit(x_train,y_train)\ngradientboost_pred = gradientboost_clf.predict(x_test)\ngradientboost_acc = accuracy_score(y_test, gradientboost_pred)\naccuracy_list.append(gradientboost_acc)","5ec0cd8a":"print(Fore.GREEN + \"Accuracy of Gradient Boosting is : \", \"{:.2f}%\".format(100* gradientboost_acc))","0cbec0d8":"cm = confusion_matrix(y_test, gradientboost_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Gredient Boosting Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","1ce7e741":"print(accuracy_list)\n# accuracy_list = accuracy_list[:len(accuracy_list)-1]\n#Had an error when I re-run one of the models and a duplicate value was added in the array.","5729b427":"models_list = ['Logistic Regressor', 'svc','xgb','lightgum','K Neighbors','Gradient Boosting']","82862783":"plt.rcParams['figure.figsize']=10,6 \nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=models_list, y=accuracy_list, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Classifier Models\", fontsize = 20 )\nplt.ylabel(\"% of Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Classifier Models\", fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'medium')\nplt.show()","f8664189":"Diabetes has been one of the most sought after factor in relation to heart_failure, so lets analyse that. ","1f1dce5e":"The dataset of diabetic distribution gives us the following insights:\n* 41.8% of patients had diabetes out of which 13.4% succumbed to heart_failure. \n* 58.2% of patients from the dataset were non-diabetic out of which 18.7% succumbed to diabetes.","92b38d37":"Ejection fraction is the Percentage of blood leaving the heart at each contraction.\nThe data in the above graph shows that a lower ejection fraction could be linked to Death event. \n","bcbb3b6b":"The above graph shows us the distribution of age groups in our data. (hover over the graph for exact count)\nNow lets analyse the death rate in various age groups. ","e0d1e608":"To improve the accuracy of the prediction model, lets try to find the most important features to fit in the training data. ","426c0313":"We have fit the data for our predictions now lets try different methods to predict our data. ","f7efba84":"Lets try some more models..","781d1c3c":"There is a higher survival rate in the age group 58-62 as compared to other age groups. ","8c26c128":"From the above subplot we can conclude that in our dataset 65.3% are MALE (out of which 44.4% survived and 20.9% died) and 34.7% are FEMALE (out of which 23.6% survived and 11.1% died)","47604173":"Heart Failure related death event data analysis and prediction by Farhan khan. ","cdca1fbb":"To begin with, lets first take the simplest look at the age factor in the death event due to heart failure. ","d450773d":"Lets analyse the effect of smoking in various age groups and link that to heart attack ","8c38a4c2":"As we can see smoking affects the rate of survival, people who dont smoke had better chance of survival at age group 55 to 65.\nDeath rate of smokers is higher than non-smokers. ","c4f7ae23":"As we can see, a death due to heart failure is influenced by a number of factors.\n\n**Objectives**: \n* To look for numerous insights in the data in order to improve the accuracy of our prediction.\n* Use different models to predict death events and compare the most reliable model for this dataset.","df8d673d":"We calculated the feature importance for this data to predict the outcome, so based on this we only select the three most important, i.e Time, ejection_fraction and serum creatinine. ","39b7a717":"**About the Data**\n\nCardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worlwide.\n\nHeart failure is a common event caused by CVDs and this dataset contains 12 features that can be used to predict mortality by heart failure.","28a6e527":"Next, lets analyse and find out if the gender factor affects the death rate. \nTo do this:\n* Lets find the ratio of Men and Women in the dataset\n* Lets find the percentage ratio of survival and death event. ","c8919823":"Lets create a confusion matrix to better understand the accuracy"}}