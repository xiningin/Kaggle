{"cell_type":{"31c30eb9":"code","a69cccdf":"code","598a9aa9":"code","a93959ec":"code","0ce1be61":"code","5fa68607":"code","68019425":"code","ecda9086":"code","85036c92":"code","32a548f5":"code","242ac7b8":"code","bd23cf51":"code","2c1202b1":"code","d7d2976a":"code","99e25c5e":"code","9cdd154d":"code","0952a30e":"code","0849ae22":"code","1c71c25b":"code","d8b106cd":"code","a50d0bd6":"code","cc882154":"code","b133ed23":"code","15bf75b6":"code","30e0d4cb":"code","50fd41b4":"code","85e3de5d":"code","ccd8f5b5":"code","1ab18168":"code","86d157ec":"code","f4c05ed6":"code","d541ec8c":"code","dca0fc5e":"code","94331e85":"code","1fa9679f":"code","5ea8e3e5":"code","1a49d1c3":"code","d291d1c0":"code","d2f20ba0":"code","f09beb71":"code","02dbbcc6":"code","5a86575d":"code","b5e863ea":"code","958b3476":"code","2e21f684":"code","b1ef9975":"code","13283ae4":"markdown","ee639a82":"markdown","1f469fca":"markdown"},"source":{"31c30eb9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a69cccdf":"!pip install albumentations","598a9aa9":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport random\nimport math\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\nimport torch.nn as nn\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler, Adam, SGD\n\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n# for evaluating the model\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport time\nimport os\nimport copy\n\nimport random\n\nimport cv2\n\nimport albumentations as A\nfrom IPython.display import Image\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","a93959ec":"test_path = {}\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/Testing_Data\/'):\n    for filename in filenames:\n        test_path[str(os.path.join(filename))] = str(os.path.join(dirname, filename))\n        #test_path.append(str(os.path.join(dirname, filename)))\n        #test_name.append(int(os.path.join(filename)))\n        \ntrain_path = {}\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/Training_Data\/'):\n    for filename in filenames:\n        train_path[str(os.path.join(filename))] = str(os.path.join(dirname, filename))","0ce1be61":"len_test = len(test_path)\nlen_train = len(train_path)","5fa68607":"test = pd.DataFrame()\ntrain = pd.DataFrame()","68019425":"name = []\npath = []\n\nfor i in range(1,len_test+1):\n    name.append(i)\n    path.append(test_path[str(i)])\ntest['name'] = name\ntest['path'] = path","ecda9086":"name = []\npath = []\n\nfor i in range(1,len_train+1):\n    name.append(i)\n    path.append(train_path[str(i)])\ntrain['name'] = name\ntrain['path'] = path","85036c92":"train.head()","32a548f5":"l = train.loc[2,'path']\nl","242ac7b8":"train_images = []\nk = np.array(train['path'])\nfor i in k:\n    train_images.append(mpimg.imread(i).reshape(1,64,64))\ntrain_images = np.array(train_images)\n\ntest_images = []\nk = np.array(test['path'])\nfor i in k:\n    test_images.append(mpimg.imread(i).reshape(1,64,64))\ntest_images = np.array(test_images)","bd23cf51":"train_images.shape, test_images.shape","2c1202b1":"train_labels = np.array(pd.read_csv(\"..\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/train.csv\")[\"code\"])","d7d2976a":"count = []\nfor i in range(0,16):\n    count.append(sum(train_labels==i))","99e25c5e":"count","9cdd154d":"pd.DataFrame(train_labels).nunique()","0952a30e":"img = train_images[1].reshape(64,64)\nimgplot = plt.imshow(img)\nplt.show()\nprint(train_labels[1])\nimg = train_images[9997].reshape(64,64)\nimgplot = plt.imshow(img)\nplt.show()\nprint(train_labels[9997])","0849ae22":"for i in range(len(train_labels)):\n    if train_labels[i] == 15:\n        train_labels[i] = 0","1c71c25b":"train_labels[:20]","d8b106cd":"train_images.shape, train_labels.shape, test_images.shape","a50d0bd6":"\nX_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)","cc882154":"X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape","b133ed23":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\nprint(device)","15bf75b6":"class DigitDataset(Dataset):\n\n    def __init__(self,images,labels,transfrom):\n        # Initialize data, download, etc.\n        self.x_data = torch.from_numpy(images) # size [n_samples, n_features]\n        self.y_data = torch.from_numpy(labels) # size [n_samples, 1]\n        self.n_samples = images.shape[0]\n\n    # support indexing such that dataset[i] can be used to get i-th sample\n    def __getitem__(self, index):\n        return self.x_data[index], self.y_data[index]\n\n    # we can call len(dataset) to return the size\n    def __len__(self):\n        return self.n_samples","30e0d4cb":"\naug_transform = A.Compose([\n    A.RandomCrop(width=50, height=50),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n])","50fd41b4":"transform = transforms.Compose([transforms.ToTensor(),\n                              \n                              ])","85e3de5d":"train_dataset = DigitDataset(X_train,y_train,transforms.Compose([aug_transform,\n                                                                 transforms.Normalize(mean=(0.5,), std=(0.5,)),\n                             transform]))\nval_dataset = DigitDataset(X_val,y_val,transform)\ntest_dataset = DigitDataset(X_test,y_test,transform)","ccd8f5b5":"batch_size=128\n# defining trainloader, valloader and testloader\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)","1ab18168":"# shape of training data\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\nprint(images.shape)\nprint(labels.shape)\n\n# visualizing the training images\nplt.imshow(images[0].numpy().squeeze(), cmap='gray')","86d157ec":"# shape of validation data\ndataiter = iter(val_loader)\nimages, labels = dataiter.next()\n\nprint(images.shape)\nprint(labels.shape)\n\n# visualizing the training images\nplt.imshow(images[0].numpy().squeeze(), cmap='gray')\nprint(labels[0])","f4c05ed6":"64*64","d541ec8c":"class Net(nn.Module):    \n    def __init__(self):\n        super(Net, self).__init__()\n          \n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n          \n        self.classifier = nn.Sequential(\n            nn.Dropout(p = 0.5),\n            nn.Linear(64 * 16 * 16, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, 15),\n        )\n          \n\n                \n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        \n        return x   ","dca0fc5e":"\n# defining the model\nmodel = Net()\n# defining the optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.003)\n# defining the loss function\ncriterion = nn.CrossEntropyLoss()\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n# checking if GPU is available\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n    \nprint(model)","94331e85":"dataset_sizes = {}\ndataset_sizes['train'] = len(train_dataset)\ndataset_sizes['val'] = len(val_dataset)","1fa9679f":"X_test.shape","5ea8e3e5":"def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n    since = time.time() #Return the time in seconds since the epoch as a floating point number\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    dataloaders = {}\n    dataloaders['train'] = train_loader\n    dataloaders['val'] = val_loader\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                inputs = inputs.type(torch.cuda.FloatTensor)\n                labels = labels.to(device)\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","1a49d1c3":"model = model.to(device)\n\nmodel = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=20)","d291d1c0":"model.eval()","d2f20ba0":"# getting predictions on test set and measuring the performance\ncorrect_count, all_count = 0, 0\nfor images,labels in test_loader:\n  for i in range(len(labels)):\n    images = images.cuda()\n    images = images.type(torch.cuda.FloatTensor)\n    labels = labels.cuda()\n    img = images[i].view(1, 1, 64, 64)\n    with torch.no_grad():\n        logps = model(img)\n\n    \n    ps = torch.exp(logps)\n    probab = list(ps.cpu()[0])\n    pred_label = probab.index(max(probab))\n    true_label = labels.cpu()[i]\n    if(true_label == pred_label):\n      correct_count += 1\n    all_count += 1\n\nprint(\"Number Of Images Tested =\", all_count)\nprint(\"\\nModel Accuracy =\", (correct_count\/all_count))","f09beb71":"\ntest = test_images #Normalizing the data\ntest = torch.from_numpy(test)  # Converting into Tensors\ntest = test.type(torch.cuda.FloatTensor)","02dbbcc6":"with torch.no_grad():\n    outputs = model(test.cuda())","5a86575d":"ps = torch.exp(outputs)\n\n#max_value is the value of highest no. in each 10-dim vector \n#index is the index of that max value \nmax_value, index = torch.max(ps,axis=1) \n\nindex = index.cpu()\n#Converting Prediction to numpy for Submission\nprediction = index.numpy()\n\nprint(prediction.shape)\nprint(prediction[:10])","b5e863ea":"len(prediction)","958b3476":"for i in range(len(prediction)):\n    if prediction[i] == 0:\n        prediction[i]=15","2e21f684":"prediction[:10]","b1ef9975":"k = np.arange(1,len(prediction)+1)\nsubmission = pd.DataFrame({\n        \"id\":k ,\n        \"code\": prediction\n\n    })\n\nsubmission.to_csv('Digit_Recognition_submission.csv', index=False)","13283ae4":"# No changes below","ee639a82":"# Do changes below only","1f469fca":"# Experiments"}}