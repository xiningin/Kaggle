{"cell_type":{"4f907f5c":"code","87cbce50":"code","fc5bdaec":"code","f182c29d":"code","2c509748":"code","07fdb627":"code","ba307aed":"code","4143ad92":"code","6606b823":"code","be4387c4":"code","79d010a2":"code","c21da027":"code","e901b14c":"code","f84687bd":"code","9bde9f2f":"code","b21e1375":"code","73b16b61":"code","4cae71fe":"code","1663b64c":"code","448511c9":"code","138d96b9":"code","8e44c7e3":"code","7fe3597f":"code","45b9a9ec":"code","885b1270":"code","5532c3ff":"code","d719a0bf":"code","ac612fe2":"code","687e6b59":"code","6c4984ff":"code","526ed479":"code","bdd5644d":"code","a26319cb":"code","0ba0cfc6":"code","a36f77ce":"code","b8bef3c3":"code","be6a01fa":"code","9699f7b0":"code","ea111ccb":"code","6fc59497":"code","3d7f3e5b":"code","4785b14a":"code","70ba8f30":"code","1125fc3b":"code","d2dc6813":"code","fa41ffbb":"code","e98ab143":"code","328ec740":"code","1e16942c":"code","0cdf7b87":"code","adca8e15":"code","228d4883":"code","1c7037dd":"code","f3a53d06":"code","15df345a":"code","55098aaf":"code","dc48df1c":"code","5d0a2031":"code","f8be758b":"code","718c0b1b":"code","1b46b3df":"markdown","2b355536":"markdown","c665bed3":"markdown","ef8ba351":"markdown","7109fb81":"markdown","e274209f":"markdown","b9ea1a16":"markdown","8a9aaa4a":"markdown","a932e7c7":"markdown","a384c8da":"markdown","dfa6964b":"markdown","90585a22":"markdown","4ca01f07":"markdown","9b7c7ecc":"markdown","9c428cbf":"markdown","3052fad7":"markdown","74f29c33":"markdown","1094ddb2":"markdown","4d2e63ec":"markdown","1823bad5":"markdown","ebfd3d1f":"markdown","b22563cb":"markdown","9e8ed6ef":"markdown","936c09fe":"markdown","989787fd":"markdown","1ba1eed2":"markdown","5124c0cf":"markdown","3ad9a520":"markdown","4274f7c5":"markdown","a69cf917":"markdown","c8ae4e94":"markdown","763ff1b0":"markdown","53145fb2":"markdown","acfd6683":"markdown","c46d0a67":"markdown","afb0437b":"markdown","d1670d55":"markdown","860cefb7":"markdown","ed92a466":"markdown","5557872d":"markdown","fd926126":"markdown","efdde373":"markdown","06d918e1":"markdown","efe1dfc0":"markdown","20518587":"markdown","3c994428":"markdown"},"source":{"4f907f5c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87cbce50":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n\nfrom scipy import stats\nimport numpy as np\nimport pandas as pd\nimport pydot\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom graphviz import Source\nfrom sklearn import tree\n\n# display warnings only the first time\nimport warnings\nwarnings.filterwarnings('ignore')","fc5bdaec":"# traffic station characteristics\n\n# change the path name of the dataset according to the location of data on your device.\ntraffic_station_df = pd.read_csv(\"..\/input\/us-traffic-2015\/dot_traffic_stations_2015.txt.gz\",\n                                 header=0, sep=',', quotechar='\"')\n\n# traffic volume metrics associated to each traffic station\n\n# change the path name of the dataset according to the location of data on your device.\ntraffic_df = pd.read_csv(\"..\/input\/us-traffic-2015\/dot_traffic_2015.txt.gz\",\n                         header=0, sep=',', quotechar='\"')\n\n# rename long feature names\ntraffic_station_df.rename(columns = {\"number_of_lanes_in_direction_indicated\": \"lane_count\"}, inplace = True)","f182c29d":"print('Traffic data:')\ntraffic_df.head()","2c509748":"traffic_df.isnull().mean()","07fdb627":"# dropping restrictions column because it contains all values as null\ntraffic_df.dropna(how='all', axis=1, inplace=True)\ntraffic_df.reset_index(inplace=True, drop=True)","ba307aed":"traffic_df.dtypes","4143ad92":"# Changing the datatype of date column to datetime as the given datatype is not correct.\ntraffic_df['date']= pd.to_datetime(traffic_df['date'], format='%Y-%m-%d')","6606b823":"# view top of station dataframe\nprint('Traffic Station data:')\ntraffic_station_df.head()","be4387c4":"# we are dropping the columns with more than 60% NULL values as they will not be able to contribute in the dataset and will reduce the model accuracy\ntraffic_station_df.drop(['concurrent_signed_route_number', 'hpms_sample_identifier', \n                         'lrs_identification', 'lrs_location_point', \n                         'shrp_site_identification'], axis = 1, inplace=True)\n\n# here we are only dropping the rows which contains the null values in 'latitude', 'longitude', 'station_location' because they contain \n# significatly less null values and are useful columns.\ntraffic_station_df.dropna(subset=['latitude', 'longitude', 'station_location'], inplace=True)\ntraffic_station_df.reset_index(inplace=True, drop=True)","79d010a2":"print('Traffic_Station_Null_Mean: \\n')\nprint(traffic_station_df.isnull().mean(), end = '\\n\\n')\n\nprint('Traffic_Station_Shape: \\n')\nprint(traffic_station_df.shape, end = '\\n\\n')","c21da027":"variables = ['traffic_volume_counted_after_0000_to_0100', 'traffic_volume_counted_after_0100_to_0200', 'traffic_volume_counted_after_0200_to_0300',\n            'traffic_volume_counted_after_0300_to_0400', 'traffic_volume_counted_after_0400_to_0500', 'traffic_volume_counted_after_0500_to_0600',\n             'traffic_volume_counted_after_0600_to_0700', 'traffic_volume_counted_after_0700_to_0800', 'traffic_volume_counted_after_0800_to_0900',\n             'traffic_volume_counted_after_0900_to_1000', 'traffic_volume_counted_after_1000_to_1100', 'traffic_volume_counted_after_1100_to_1200',\n             'traffic_volume_counted_after_1200_to_1300', 'traffic_volume_counted_after_1300_to_1400', 'traffic_volume_counted_after_1400_to_1500',\n             'traffic_volume_counted_after_1500_to_1600', 'traffic_volume_counted_after_1600_to_1700', 'traffic_volume_counted_after_1700_to_1800',\n             'traffic_volume_counted_after_1800_to_1900', 'traffic_volume_counted_after_1900_to_2000', 'traffic_volume_counted_after_2000_to_2100',\n             'traffic_volume_counted_after_2100_to_2200', 'traffic_volume_counted_after_2200_to_2300', 'traffic_volume_counted_after_2300_to_2400']\n\n# we will be starting by correcting the datatype of all the time-slots that are given to us, so that we will be able to sum them up very easily.\ntraffic_df[variables] = traffic_df[variables].astype(float).astype(int)","e901b14c":"till_4 = ['traffic_volume_counted_after_0000_to_0100', 'traffic_volume_counted_after_0100_to_0200', 'traffic_volume_counted_after_0200_to_0300',\n         'traffic_volume_counted_after_0300_to_0400']\ntill_8 = ['traffic_volume_counted_after_0400_to_0500', 'traffic_volume_counted_after_0500_to_0600','traffic_volume_counted_after_0600_to_0700',\n         'traffic_volume_counted_after_0700_to_0800']\ntill_12 = ['traffic_volume_counted_after_0800_to_0900','traffic_volume_counted_after_0900_to_1000', 'traffic_volume_counted_after_1000_to_1100',\n          'traffic_volume_counted_after_1100_to_1200']\ntill_16 = ['traffic_volume_counted_after_1200_to_1300', 'traffic_volume_counted_after_1300_to_1400', 'traffic_volume_counted_after_1400_to_1500',\n            'traffic_volume_counted_after_1500_to_1600']\ntill_20 = ['traffic_volume_counted_after_1600_to_1700', 'traffic_volume_counted_after_1700_to_1800','traffic_volume_counted_after_1800_to_1900',\n           'traffic_volume_counted_after_1900_to_2000']\ntill_24 = ['traffic_volume_counted_after_2000_to_2100','traffic_volume_counted_after_2100_to_2200', 'traffic_volume_counted_after_2200_to_2300',\n           'traffic_volume_counted_after_2300_to_2400']\n\n# Here we are summing up the data of 4 hours and creating the new column with the new data that we have got after summing up.\ntraffic_df['1_to_4'] = traffic_df[till_4].sum(axis=1, numeric_only= True)\ntraffic_df['5_to_8'] = traffic_df[till_8].sum(axis=1, numeric_only= True)\ntraffic_df['9_to_12'] = traffic_df[till_12].sum(axis=1, numeric_only= True)\ntraffic_df['13_to_16'] = traffic_df[till_16].sum(axis=1, numeric_only= True)\ntraffic_df['17_to_20'] = traffic_df[till_20].sum(axis=1, numeric_only= True)\ntraffic_df['21_to_24'] = traffic_df[till_24].sum(axis=1, numeric_only= True)\n\n# here we are dropping the columns named 'year_of_data', 'record_type' because they have only one value throughout the data which will affect our model accuracy.\ntraffic_df.drop(variables, axis = 1, inplace=True)\ntraffic_df.drop(['year_of_data', 'record_type'], axis = 1, inplace=True)\ntraffic_df.head()","f84687bd":"traffic_df['1_to_4'] = traffic_df['1_to_4'].div(4)\ntraffic_df['5_to_8'] = traffic_df['5_to_8'].div(4)\ntraffic_df['9_to_12'] = traffic_df['9_to_12'].div(4)\ntraffic_df['13_to_16'] = traffic_df['13_to_16'].div(4)\ntraffic_df['17_to_20'] = traffic_df['17_to_20'].div(4)\ntraffic_df['21_to_24'] = traffic_df['21_to_24'].div(4)\ntraffic_df.head()","9bde9f2f":"timings=['1_to_4','5_to_8', '9_to_12', '13_to_16', '17_to_20', '21_to_24']\nplt.figure(figsize = (20,8))\nfor i in range(1, 7):\n    plt.subplot(2, 3, i)\n    sns.boxplot(x=traffic_df[timings[i-1]])","b21e1375":"# For more detailed look we can see that between hour 1 and 4 there exists many outliers and most of them are above 3000 range.\n\nfig, ax = plt.subplots(figsize=(20,8))\nax.scatter(traffic_df['1_to_4'], traffic_df['day_of_week'])\nax.set_xlabel('1 to 4')\nax.set_ylabel('day of week')\nplt.show()","73b16b61":"timings=['1_to_4','5_to_8', '9_to_12', '13_to_16', '17_to_20', '21_to_24']\nz = np.abs(stats.zscore(traffic_df[timings]))\nprint(z)\nthreshold = 3\nprint(np.where(z > 3))","4cae71fe":"traffic_df[timings] = traffic_df[timings][(z < 3).all(axis=1)]\ntraffic_df[timings] = traffic_df[timings][(-3 < z).all(axis=1)]\ntraffic_df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)","1663b64c":"timings=['1_to_4','5_to_8', '9_to_12', '13_to_16', '17_to_20', '21_to_24']\nplt.figure(figsize = (20,8))\nfor i in range(1, 7):\n    plt.subplot(2, 3, i)\n    sns.boxplot(x=traffic_df[timings[i-1]])","448511c9":"traffic_df.describe()","138d96b9":"timings=['1_to_4','5_to_8', '9_to_12', '13_to_16', '17_to_20', '21_to_24']\nWeek_Traffic = pd.DataFrame(traffic_df.groupby(['day_of_week'], axis=0, as_index=False)[timings].mean())\n\nlegends=['1 - 4','4 - 8', '8 - 12', '12 - 16', '16 - 20', '20 - 24']\nplt.style.use('fivethirtyeight')\n\nWeek_Traffic.plot(x='day_of_week', y=timings, kind=\"bar\", figsize=(25,10), xlabel = 'Day of week', ylabel = 'Traffic count')\nplt.legend(title='Timings', labels=legends)","8e44c7e3":"# We are renaming the very long direction name in this code cell\n\ntraffic_df[\"direction_of_travel_name\"].replace({\"North-South or Northeast-Southwest combined (ATR stations only)\": \"Northeast-Southwest\", \n                                                \"East-West or Southeast-Northwest combined (ATR stations only)\": \"Southeast-Northwest\"}, inplace=True)","7fe3597f":"print('functional classification:'.upper())\nprint(dict(traffic_df['functional_classification'].value_counts()), end = '\\n\\n')\n\nprint('functional classification name:'.upper())\nprint(dict(traffic_df['functional_classification_name'].value_counts()), end = '\\n\\n')\n\n\nprint('fips state code:'.upper())\nprint(dict(traffic_df['fips_state_code'].value_counts()), end = '\\n\\n')\n\n\nprint('direction of travel:'.upper())\nprint(dict(traffic_df['direction_of_travel'].value_counts()), end = '\\n\\n')\n\n\nprint('direction of travel name:'.upper())\nprint(dict(traffic_df['direction_of_travel_name'].value_counts()), end = '\\n\\n')","45b9a9ec":"def columnWithName(dict1, dict2):\n    ans = {}\n    for k, v in dict1.items():\n        for k1, v1 in dict2.items():\n            if v == v1:\n                ans[k] = k1\n    return ans","885b1270":"functional_classification1 = dict(traffic_df['functional_classification'].value_counts())\nfunctional_classification_name1 = dict(traffic_df['functional_classification_name'].value_counts())\nfunctional_classification_dict = columnWithName(functional_classification1, functional_classification_name1)\n\n\ndirection_of_travel1 = dict(traffic_df['direction_of_travel'].value_counts())\ndirection_of_travel_name1 = dict(traffic_df['direction_of_travel_name'].value_counts())\ndirection_of_travel_dict = columnWithName(direction_of_travel1, direction_of_travel_name1)","5532c3ff":"legends=['1 - 4','4 - 8', '8 - 12', '12 - 16', '16 - 20', '20 - 24']\ndirection_EDA = pd.pivot_table(data=traffic_df, index=['direction_of_travel_name'], values=timings)\ndirection_EDA.plot(kind='bar', figsize=(22,8), xlabel = 'Direction of Travel', ylabel = 'Traffic count')\nplt.style.use('fivethirtyeight')\nplt.legend(title='Timings', labels=legends)","d719a0bf":"plt.figure(figsize=(20,6))\nplt.figure(1)\n\nsns.distplot(traffic_df['direction_of_travel'],color='red')","ac612fe2":"legends=['1 - 4','4 - 8', '8 - 12', '12 - 16', '16 - 20', '20 - 24']\ndirection_EDA = pd.pivot_table(data=traffic_df, index=['lane_of_travel'], values=timings)\ndirection_EDA.plot(kind='line', figsize=(20,8), xlabel = 'Lane of Travel', ylabel = 'Traffic count')\nplt.style.use('fivethirtyeight')\nplt.legend(title='Timings', labels=legends)","687e6b59":"legends=['1 - 4','4 - 8', '8 - 12', '12 - 16', '16 - 20', '20 - 24']\ndirection_EDA = pd.pivot_table(data=traffic_df, index=['functional_classification_name'], values=timings)\ndirection_EDA.plot(kind='area', figsize=(45,15), xlabel = 'Functional Classification', ylabel = 'Traffic count')\nplt.style.use('fivethirtyeight')\nplt.legend(title='Timings', labels=legends)","6c4984ff":"traffic_df['station_id'].nunique()","526ed479":"# def integers(x):\n#     ref = dict(traffic_df['station_id'].value_counts())\n#     if ref.get(x):\n#         return ref[x]\n\n# traffic_df['station_id'] = traffic_df['station_id'].apply(integers)\n\n\n# I initially tried to to the task using the above mentioned function but it was extremely slow while running and therefore had to look for a better alternative.\n# For solving this issue i then used the map function and the proper for which i found the reference at the below mentioned link.\n# https:\/\/stackoverflow.com\/questions\/41985566\/pandas-replace-dictionary-slowness\n\n\nstation_id_element_count = dict(traffic_df['station_id'].value_counts())\ntraffic_df['station_id'] = traffic_df['station_id'].map(station_id_element_count.get)","bdd5644d":"plt.figure(figsize=(20,6))\nplt.figure(1)\nsns.distplot(traffic_df['station_id'],color='blue')","a26319cb":"# It is clear that '5U', '6R', '7U', '7R' functional_classification are very much less in number and therefore we can merge them all under one field.\n# In the functional_classification column we can see they are categorical ones, so we make new feature out of them.\n\ntraffic_df['functional_classification'] = traffic_df['functional_classification'].replace(['5U', '6R', '7U', '7R'], 'other_functional_classifications')\ntraffic_df['functional_classification_name'] = traffic_df['functional_classification_name'].replace(['Urban: Collector', \n                                                                                                     'Rural: Minor Collector', \n                                                                                                     'Urban: Local System', \n                                                                                                     'Rural: Local System'], 'other_functional_classification_name')\n\nfunctional_classification_dummy = pd.get_dummies(traffic_df['functional_classification'])\n\ntraffic_df = pd.concat([traffic_df, functional_classification_dummy], axis=1)\n\n\n# In the direction_of_travel_name column we can see they are categorical ones, so we make new feature out of them.\n\ndirection_of_travel_name_dummy = pd.get_dummies(traffic_df['direction_of_travel_name'])\n\ntraffic_df = pd.concat([traffic_df, direction_of_travel_name_dummy], axis=1)\n\ntraffic_df.head()","0ba0cfc6":"direc = ['North', 'South', 'East', 'West', 'Northeast-Southwest', 'Southeast', 'Northwest', 'Northeast', 'Southeast-Northwest', 'Southwest']\ntime_rural = pd.pivot_table(traffic_df, index=['Northeast-Southwest'], values =timings)\nplt.style.use('fivethirtyeight')\ntime_rural.plot(kind='bar', figsize=(20, 6));","a36f77ce":"timings=['1_to_4','5_to_8', '9_to_12', '13_to_16', '17_to_20', '21_to_24']\nlane_station = pd.pivot_table(traffic_df, index=['lane_of_travel'], values =['station_id'])\nplt.style.use('fivethirtyeight')\nlane_station.plot(kind='area', figsize=(20, 6));\n\nplt.legend(title='Station Id V\/S Lane of Travel', labels=['Station ID Count'])","b8bef3c3":"funtional_class = ['1U', '3R', '3U', '1R', '2U', '4R', '5R', '4U', 'other_functional_classifications']\nlane_functional = pd.pivot_table(traffic_df, index=['lane_of_travel'], values =funtional_class)\nplt.style.use('fivethirtyeight')\nlane_functional.plot(kind='bar', figsize=(20, 8));\nlegends=['Urban: Principal Arterial - Interstate', 'Rural: Principal Arterial - Other', 'Urban: Principal Arterial - Other',\n         'Rural: Principal Arterial - Interstate', 'Urban: Principal Arterial - Other Freeways or Expressways', \n         'Rural: Minor Arterial', 'Rural: Major Collector', 'Urban: Minor Arterial', 'Other Classifications']\nplt.legend(title='Functional Classification', labels=legends)","be6a01fa":"time_rural = pd.pivot_table(traffic_df, index=['1U'], values =timings)\nplt.style.use('fivethirtyeight')\ntime_rural.plot(kind='barh', figsize=(20, 8));","9699f7b0":"traffic_df.head()","ea111ccb":"traffic_df.describe()","6fc59497":"traffic_station_df.head()","3d7f3e5b":"print('calibration of weighing system:'.upper())\nprint(dict(traffic_station_df['calibration_of_weighing_system'].value_counts()), end = '\\n\\n')\nprint('calibration of weighing system name:'.upper())\nprint(dict(traffic_station_df['calibration_of_weighing_system_name'].value_counts()), end = '\\n\\n')\n\nprint('algorithm_of_vehicle_classification:'.upper())\nprint(dict(traffic_station_df['algorithm_of_vehicle_classification'].value_counts()), end = '\\n\\n')\nprint('algorithm_of_vehicle_classification_name:'.upper())\nprint(dict(traffic_station_df['algorithm_of_vehicle_classification_name'].value_counts()), end = '\\n\\n')","4785b14a":"# It is clear that 'D', 'P', 'B', '2', 'S' calibration_of_weighing_system are very much less in number and therefore we can merge them all under one field.\n# In the calibration_of_weighing_system column we can see they are categorical ones, so we make new feature out of them.\n\ntraffic_station_df['calibration_of_weighing_system'] = traffic_station_df['calibration_of_weighing_system'].replace(['D', 'P', 'B', '2', 'S'], 'other_calibration_of_weighing_system')\n\ncalibration_of_weighing_system_dummy = pd.get_dummies(traffic_station_df['calibration_of_weighing_system'])\n\ntraffic_station_df = pd.concat([traffic_station_df, calibration_of_weighing_system_dummy], axis=1)\n\n\n# It is clear that 'Z', 'M', 'N', 'H', 'C', 'A', '1', 'E' algorithm_of_vehicle_classification are very much less in number and therefore we can merge them all under one field.\n# In the algorithm_of_vehicle_classification column we can see they are categorical ones, so we make new feature out of them.\n\ntraffic_station_df['algorithm_of_vehicle_classification'] = traffic_station_df['algorithm_of_vehicle_classification'].replace(['Z', 'M', 'N', 'H', 'C', 'A', '1', 'E'], 'other_algorithm_of_vehicle_classification')\ntraffic_station_df['algorithm_of_vehicle_classification'] = traffic_station_df['algorithm_of_vehicle_classification'].replace(['0'], 'A_0')\n\nalgorithm_of_vehicle_classification_dummy = pd.get_dummies(traffic_station_df['algorithm_of_vehicle_classification'])\n\ntraffic_station_df = pd.concat([traffic_station_df, algorithm_of_vehicle_classification_dummy], axis=1)\n\n# Renaming the very long column name.\n\ntraffic_station_df[\"direction_of_travel_name\"].replace({\"North-South or Northeast-Southwest combined (ATR stations only)\": \"Northeast-Southwest\", \n                                                \"East-West or Southeast-Northwest combined (ATR stations only)\": \"Southeast-Northwest\"}, inplace=True)\n\n# In the direction_of_travel_name column we can see they are categorical ones, so we make new feature out of them.\n\ndirection_of_travel_name_dummy1 = pd.get_dummies(traffic_station_df['direction_of_travel_name'])\n\ntraffic_station_df = pd.concat([traffic_station_df, direction_of_travel_name_dummy1], axis=1)\n\n\n# It is clear that '5U', '6R', '7U', '7R' functional_classification are very much less in number and therefore we can merge them all under one field.\n# In the functional_classification column we can see they are categorical ones, so we make new feature out of them.\n\ntraffic_station_df['functional_classification'] = traffic_station_df['functional_classification'].replace(['5U', '6R', '7U', '7R'], 'other_functional_classifications')\ntraffic_station_df['functional_classification_name'] = traffic_station_df['functional_classification_name'].replace(['Urban: Collector', \n                                                                                                     'Rural: Minor Collector', \n                                                                                                     'Urban: Local System', \n                                                                                                     'Rural: Local System'], 'other_functional_classification_name')\n\nfunctional_classification_dummy1 = pd.get_dummies(traffic_station_df['functional_classification'])\n\ntraffic_station_df = pd.concat([traffic_station_df, functional_classification_dummy1], axis=1)\n\n\n# In the lane_of_travel_name column we can see they are categorical ones, so we make new feature out of them.\n\ntraffic_station_df['lane_of_travel_name'] = traffic_station_df['lane_of_travel_name'].replace(['Outside (rightmost) lane'], 'Outside_rightmost_lane')\ntraffic_station_df['lane_of_travel_name'] = traffic_station_df['lane_of_travel_name'].replace(['Data with lanes combined'], 'Data_with_lanes_combined')\ntraffic_station_df['lane_of_travel_name'] = traffic_station_df['lane_of_travel_name'].replace(['Other lanes'], 'Other_lanes')\n\nlane_of_travel_name_dummy = pd.get_dummies(traffic_station_df['lane_of_travel_name'])\n\ntraffic_station_df = pd.concat([traffic_station_df, lane_of_travel_name_dummy], axis=1)\n\n\n# In the method_of_traffic_volume_counting_name column we can see they are categorical ones, so we make new feature out of them.\n\n\ntraffic_station_df.replace({'method_of_traffic_volume_counting_name' : { 'Permanent automatic traffic recorder (ATR)' : 'TVC_Automatic', \n                                                               'Portable traffic recording device' : 'TVC_Portable',\n                                                                'Human observation (manual)': 'TVC_Manual'}}, inplace=True)\n\nmethod_of_traffic_volume_counting_name_dummy = pd.get_dummies(traffic_station_df['method_of_traffic_volume_counting_name'])\n\ntraffic_station_df = pd.concat([traffic_station_df, method_of_traffic_volume_counting_name_dummy], axis=1)\n\ntraffic_station_df.head()","70ba8f30":"traffic_station_df.replace({'sample_type_for_traffic_volume_name' : {'Station used for Traffic Volume Trends': 1, \n                                                                     'Station not used for Traffic Volume Trends': 0}}, inplace=True)\n\ntraffic_station_df.replace({'sample_type_for_vehicle_classification_name' : {'Station used for Heavy Vehicle Travel Information System': 1, \n                                                                             'Station not used for Heavy Vehicle Travel Information System': 0}}, inplace=True)\n\ntraffic_station_df.replace({'method_of_data_retrieval_name' : { 'Automated (telemetry)' : 1, 'Not automated (manual)' : 0}}, inplace=True)\n\ntraffic_station_df.replace({'hpms_sample_type' : { 'N' : 1, 'Y' : 0}}, inplace=True)\n\ntraffic_station_df.replace({'national_highway_system' : { 'N' : 0, 'Y' : 1}}, inplace=True)","1125fc3b":"year_station_established_count = dict(traffic_station_df['year_station_established'].value_counts())\ntraffic_station_df['year_station_established'] = traffic_station_df['year_station_established'].map(year_station_established_count.get)\n\nyear_station_discontinued_count = dict(traffic_station_df['year_station_discontinued'].value_counts())\ntraffic_station_df['year_station_discontinued'] = traffic_station_df['year_station_discontinued'].map(year_station_discontinued_count.get)\n\nstation_id_element_count1 = dict(traffic_station_df['station_id'].value_counts())\ntraffic_station_df['station_id'] = traffic_station_df['station_id'].map(station_id_element_count1.get)\n\nprevious_station_id_count = dict(traffic_station_df['previous_station_id'].value_counts())\ntraffic_station_df['previous_station_id'] = traffic_station_df['previous_station_id'].map(previous_station_id_count.get)\n\nposted_signed_route_number_count = dict(traffic_station_df['posted_signed_route_number'].value_counts())\ntraffic_station_df['posted_signed_route_number'] = traffic_station_df['posted_signed_route_number'].map(posted_signed_route_number_count.get)","d2dc6813":"traffic_station_df.drop(['calibration_of_weighing_system', 'calibration_of_weighing_system_name', \n                         'algorithm_of_vehicle_classification', 'algorithm_of_vehicle_classification_name',\n                        'direction_of_travel_name', 'functional_classification','functional_classification_name', 'lane_of_travel_name',\n                        'method_of_traffic_volume_counting_name', 'year_of_data', 'station_location', 'method_of_truck_weighing_name',\n                        'record_type', 'sample_type_for_traffic_volume', 'sample_type_for_truck_weight_name',\n                        'sample_type_for_truck_weight', 'sample_type_for_vehicle_classification', 'type_of_sensor_name',\n                        'type_of_sensor', 'second_type_of_sensor', 'primary_purpose', 'primary_purpose_name', \n                        'method_of_vehicle_classification_name'], axis = 1, inplace=True)\ntraffic_station_df.reset_index(inplace=True, drop=True)","fa41ffbb":"# Removing the unnecesary columns and the columns with non numerical values.\ntraffic_df_m = traffic_df.drop(['date', 'direction_of_travel_name', 'functional_classification_name', 'functional_classification', 'fips_state_code'], axis = 1)","e98ab143":"traffic_df_m.reset_index(inplace=True, drop=True)\ntraffic_df_m.head()","328ec740":"# Setting up our X and Y axis i.e. input(X axis) and output(Y axis) i.e. target value.\n# Splitting out training data into new Train data and Validation data.\n\ny = traffic_df_m['lane_of_travel']\nX_train = traffic_df_m.drop(['lane_of_travel'], axis = 1)\nXtrain ,Xtest, ytrain, ytest = train_test_split(X_train, y, test_size = 0.2, random_state=0)","1e16942c":"# Defining Lists to Store in the Results and Names of Algorithms\nMSE_Score = []\nR2_Score = []\nAlgorithm = []","0cdf7b87":"# Creating the RandomForest model with number of trees = 10 to get better performance.\n# The reason i took less number of estimarors is because the data is too large and it will take 17 to 20 hours to just create this model otherwise.\n# ALso if we take more estimators our model will Over-Fit which we want to avoid.\n\nAlgorithm.append('Random Forest Regressor')\nRF_model = RandomForestRegressor(n_estimators=10)\n\n# Fit the model with our training data.\nRF_model.fit(Xtrain, ytrain)","adca8e15":"# Predicting the output using our trained model\nOutput = RF_model.predict(Xtest)","228d4883":"accuracy_train = round(RF_model.score(Xtest, ytest)*100,2)\nprint(round(accuracy_train,2),'%')","1c7037dd":"# Appending the Scores For Visualisation at a Later Part\nMSE_Score.append(mean_squared_error(ytest, Output))\nR2_Score.append(r2_score(ytest, Output))","f3a53d06":"train_features = Xtrain\ncol = Xtrain.columns\nfeature_list = col.tolist()\ntrain_labels = ytrain","15df345a":"# Limit depth of tree to 3 levels\nrf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\nrf_small.fit(train_features, train_labels)","55098aaf":"# Extract the small tree\ntree_small = rf_small.estimators_[5]\n\n# Save the tree as a png image\ntree.export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\ngraph.write_png('small_tree.png');\nSource.from_file(\"small_tree.dot\")","dc48df1c":"# In the below function we are taking user input of the time slot in the they want to travel and then we are assigning it to the appropriate time slot so that we can\n# find the optimal route for them.\n\ntimings=['1_to_4','5_to_8', '9_to_12', '13_to_16', '17_to_20', '21_to_24']\ntime_ranges = [(0,4), (5,8), (9, 12), (13, 16), (17, 20), (21,24)]\nprint(\"Please input your desired travelling time in 24-Hours format (example: 11, 12, 13, 14) : \")\nuser_time  = int(input())\nusertime = 0\nfor i in range(len(time_ranges)):\n  start, end = time_ranges[i]\n  if start <= user_time <= end:\n    usertime = timings[i]\n    break","5d0a2031":"table = pd.pivot_table(traffic_df, values=[usertime], index=['lane_of_travel'],\n                    columns=['direction_of_travel_name'], aggfunc=np.sum, fill_value=0)\nplt.style.use('fivethirtyeight')\ntable.plot(kind='area', figsize=(20, 8), colormap='Paired');","f8be758b":"# Just Combining the Lists into a DataFrame for a Better Visualisation\nComparison = pd.DataFrame(list(zip(Algorithm, MSE_Score*100, R2_Score*100)), columns = ['Algorithm', 'MSE_Score', 'R2_Score'])\nComparison","718c0b1b":"# Exporting the model\n\nimport pickle\n\nPkl_Filename = \"Final_model.pkl\"\n\nwith open(Pkl_Filename, 'wb') as file:\n    pickle.dump(RF_model, file)","1b46b3df":"Importing both the datasets","2b355536":"In the below cell we are taking only the values which are between the range of **-3 to 3 in Z-Score**.\n\nAll other values are outliers.","c665bed3":"# **CLEANING DATA - TRAFFIC DATA**","ef8ba351":"We can further Solidify our above mentioned proof that the **maximum amount of traffic occurs in the Direction of Northeast-Southwest** and in time range of 13 to 16 and 17 to 20.\n\n**More Proof for Pattern 2**","7109fb81":"Here we are converting all the columns which contains many unique values into the counts of each value so that they all can be used as the feature and contribute into our model accuracy.","e274209f":"## **Pattern 1**\n\nOn the basis of below bar plot between **Traffic count and Days of weeks** across all time frames we can conclude that:\n\n- The **maximum amout of Traffic occurs on Day 6 i.e saturday around the hours of 12 to 16 i.e. Afternoon Hours**.\n- Also the traffic on other days is almost similar and the **minimum amount of traffic occurs during eary morning hours between 1 to 4**.","b9ea1a16":"Here we have used **Z-Score** to detect all the outliers present in the dataset.\n\nThe intuition behind Z-score is to describe any data point by finding their relationship with the Standard Deviation and Mean of the group of data points. Z-score is finding the distribution of data where mean is 0 and standard deviation is 1 i.e. normal distribution.\n\n**how does this help in identifying the outliers?**\n\n> While calculating the Z-score we re-scale and center the data and look for data points which are too far from zero. These data points which are way too far from zero will be treated as the outliers. In most of the cases a threshold of 3 or -3 is used i.e if the Z-score value is greater than or less than 3 or -3 respectively, that data point will be identified as outliers.\n\nWe will use Z-score function defined in scipy library to detect the outliers.\n\n1.   The **Z-score** is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured.\n\n*I have taken the reference from [this article](https:\/\/towardsdatascience.com\/ways-to-detect-and-remove-the-outliers-404d16608dba) while detecting the outliers and removing them using Z-Score method.*","8a9aaa4a":"In The below code cell i have created a function so that i can create a dictionary for the appropriate Feature to match with its Feature name.\n\nExample: Direction and Direction name can be matched, Functional Classification and Functional Classification name can be matched together.","a932e7c7":"Changing the datatype of date column to datetime as the given datatype is not correct.","a384c8da":"In this we are trying to convert station_id into the count of each station_id\nsince station_id is unique and we have **5048 unique station ID's** we had to perform this step so as to convert it into a feature.","dfa6964b":"In the below code cell we are converting the columns which contains only 2 values into vinary values on 1 and 0 so that they can be machine readable and can be used as a feature.","90585a22":"We can now see in the below density graph that the station Id has been converted into the feature and can contribute in the accuracy of the dataset.","4ca01f07":"## **Pattern 5**\n\nFrom the below mentioned Bar Chart between **Functional Classification and Lane numbers** we can Conclude that:\n\n- Most number of people from **Rural Areas travel mostly on Outer Lanes** (i.e. 5, 6, 7, 8, 9) instead of main Lanes. Infact we can clearly see that There are almost negligible people from Urban Areas travelling in outer lanes except of lane 8 as there as most number of stationes situated in that lane.","9b7c7ecc":"## **Pattern 3**\n\nIn the below Graph we have created the Graph between **Lane of travel and The traffic count** on Diferrent days **across all time frames**.\n\n1. With this we can Easily conclude that **Lane number 8 have the maximum amount of traffic specially on Hours 1 to 4 and 4 to 8 i.e Early Mornings**, and the **Least amount of traffic on Lane number 1**.\n\n2. We can also observe that on the **time range of 8 to 12 the traffic is very least irrespective of Lane number**.\n\n","9c428cbf":"In the below code cell we are performing **One Hot Encoding** to convert many useless columns into features.","3052fad7":"Splitting our data into training and testing data.\nOur target value of the model will be the lane of travel.","74f29c33":"From the below **boxplot**'s we can clearly see that there exists some **outliers in the dataset**. Therefore now we will be working on removing the outliers present in the data. \n\n> 1.   In statistics, an outlier is an observation point that is distant from other observations.\n> 2.   In descriptive statistics, a box plot is a method for graphically depicting groups of numerical data through their quartiles. Box plots may also have lines extending vertically from the boxes (whiskers) indicating variability outside the upper and lower quartiles, hence the terms box-and-whisker plot and box-and-whisker diagram. Outliers may be plotted as individual points.","1094ddb2":"Checking the accuracy of the model.\n\nAs we can see our model have the **accuracy of 95.24%**","4d2e63ec":"After creating bucket of 4 hours, here i am dividing the value of every **bucket by 4** so that out values does not explode and we only get the data of each hour relatively.","1823bad5":"With be help of below graph we can Clearly say that User should avoid taking Inner lanes and try to use outer lanes as much as possible and also take directions North, Northwest, Southeast-Northwest, Southeast, Northeast-southwest and Northeast.","ebfd3d1f":"Here we are merging the time-slots in the **bucket of 4 hours** so that instead of dealing with 24 hours we will only have to deal with more accurate and less data.","b22563cb":"**The reason we chose this particular model for solving the problem was because of the accuracy and depth this model provides to my output.**\n\n**The reason for choosing Lane of Travel as output of my model was because during Data Analysis phase, we observed a pattern in which most of the data had a similarity and good relation with Lane of Travel column and therefore it will provide us with high accuracy and consistency throughout the model.**","9e8ed6ef":"# **EDA - TRAFFIC DATA**    (Feature Engineering)\n","936c09fe":"With the below mentioned Area graph between **Station ID and Lane of Travel** We can conclude that:\n\n- The Reason for Maximum Traffic on the Lane number 7 and Lane number 8 was because **There are more number of stationed located on that path** and because of that people Travel more across those lanes.\n\n**More Proof for Pattern 3**","989787fd":"We can further solidify our above mentioned argument that **Most amount traffic occurs in Urban: Principal Arterial - Interstate Area in hours 13 to 16 and 17 to 20 i.e. in Evening time mostly**.\n\n**More Proof for Pattern 5**","1ba1eed2":"Here we are trying to observe the dataset so that we can clean it more efficiently","5124c0cf":"## **Exporting the Model**","3ad9a520":"# **CLEANING DATA - STATION DATA**","4274f7c5":"## **Score Card of the Models' Performances**","a69cf917":"We can also see from the below cell output that the** data consistency have been improved in all the time bucket sections** where we have appied the **Z-Score method** and there is nearly no visible difference between the **mean, 75%, and maximum** value of the dataset.","c8ae4e94":"## **DATA MODEL**","763ff1b0":"**In the below cell we can see the Data Model of the complete Project and the final model.**","53145fb2":"The below code cell helps us to observe the data more vividly and understand it better.","acfd6683":"In the below code cell i am making use of the above created function to match the Features with its namings.","c46d0a67":"Here we are dropping all the useless column and the columns we have already converted into the features.","afb0437b":"dropping **restrictions** column because it contains all values as null","d1670d55":"## **Pattern 4**\n\nIn the below Graph we have created the Graph between **Functional Classification and The traffic count** on Diferrent days **across all time frames**.\n\n1. With this we can Easily conclude that **Urban Principal Arterial: Interstate and Other Expressways have the maximum amount of traffic specially on Hours 1 to 4 and 4 to 8 i.e Early Mornings and Late night between hours 20 to 24**, also the **Least amount of traffic on Lane number 1**.\n\n2. We can also observe that on the **time range of 8 to 12 the traffic is very least irrespective of Functional Classification** and on the **Rural Local system we have the least Traffic**.","860cefb7":"## **Pattern 2**\n\nIn the below Bar plot we have created the Graph between **Direction of travel and The traffic count** on Diferrent days across all time Frames.\n\n1. With this we can Easily conclude that **Northeast-Southwest Direction have the maximum amount of traffic specially on Hours 1 to 4, 4 to 8 i.e. early mornings and at Late nights between hours 20 to 24**.\n\n2. We can also conclude that **The traffic on time range 8 to 12 is extremely less irrespective of Direction of travel**.","ed92a466":"We can see here that '**restrictions**' column is completely **empty** and therefore will be of no use to us.","5557872d":"Now when we are running the boxplot again we can clearly see that all the outliers that were present in the dataset have been removed.\n\nHence we have now obtained a consistent and good performing dataset.","fd926126":"In the below Code cell we have performed **One Hot Encoding** on the columns **direction_of_travel_name and functional_classification** so that we can convert their unique values into the feature and they can contribute to our final model.","efdde373":"For more detailed look we can see that **between hour 1 and 4** there exists many **outliers** and most of them are **above 3000 range**.","06d918e1":"# **EDA - STATION DATA**","efe1dfc0":"# **Training and Testing of Model**","20518587":"We can also conclude on the basis of the below density graph that **highest density of traffic is in Direction number 1 and 5 i.e. North and South across all the times included.**\n\n**More Proof for Pattern 2**","3c994428":"## **Random Forest Model**"}}