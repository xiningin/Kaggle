{"cell_type":{"51c67983":"code","e21c8d65":"code","6885ee34":"code","1182458f":"code","45072640":"code","bebf94ab":"code","ad00184e":"code","5792cfa6":"code","5b170ac9":"code","11091fcf":"code","31bc3cee":"code","bbb9d062":"code","f1f22059":"code","3ea96204":"code","9ffa0214":"code","d31bbc0c":"code","30074fe1":"code","25bafc60":"code","67a47f13":"code","34ea9d59":"code","c3bfca1d":"code","d5e637ca":"code","68e70c89":"code","f7e0276a":"code","2a5487ce":"code","de657235":"code","94790797":"code","a37b283f":"code","8385d059":"code","42e12f77":"code","1a9b4410":"code","16d25835":"code","2dff5620":"code","dd32eec1":"code","a4e676f3":"code","eb708a67":"code","6ae921ed":"code","17228f35":"code","85f52bea":"code","00888c48":"code","5faa7142":"code","6a552f51":"code","5d8b0073":"code","3073606c":"code","ee52fb06":"code","f8df98b4":"code","cd6fff77":"code","cfc42d13":"code","c1aa3847":"code","bd064216":"code","f470f95c":"code","d2e12055":"code","6c59f9b5":"markdown","dd0f4bda":"markdown","b9c58191":"markdown","920414b3":"markdown","6e575ae5":"markdown","7bfd8413":"markdown","b601efb6":"markdown","35453866":"markdown","a2b7dcd8":"markdown","a69aa733":"markdown","82bff33f":"markdown","5321b44e":"markdown","2d1e8c2d":"markdown","6d820b64":"markdown","6e06f71b":"markdown","8e05eeec":"markdown","ffccb227":"markdown","681dd634":"markdown","63d6c628":"markdown","8faef3b3":"markdown","d2a5d1ce":"markdown","d226c13d":"markdown","3785b2ef":"markdown","5a8b1b7d":"markdown"},"source":{"51c67983":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing, metrics\nimport lightgbm as lgb","e21c8d65":"!ls ..\/input\/","6885ee34":"train = pd.read_csv(\"..\/input\/train.csv\")","1182458f":"train.head()","45072640":"train[\"card_id\"].head()","bebf94ab":"card_id_groupby_count = train.groupby(\"card_id\")[\"target\",\"first_active_month\"].agg([\"count\",\"size\"]).reset_index()","ad00184e":"card_id_groupby_count.columns = pd.Index([\"_\".join(col) for col in card_id_groupby_count.columns.tolist()])","5792cfa6":"card_id_groupby_count.head()","5b170ac9":"card_id_groupby_count[card_id_groupby_count[\"target_count\"] > 1].count()","11091fcf":"card_id_groupby_count[card_id_groupby_count[\"target_size\"] > 1].count()","31bc3cee":"card_id_groupby_count[card_id_groupby_count[\"first_active_month_count\"] > 1].count()","bbb9d062":"card_id_groupby_count[card_id_groupby_count[\"first_active_month_size\"] > 1].count()","f1f22059":"test = pd.read_csv(\"..\/input\/test.csv\")","3ea96204":"test.head()","9ffa0214":"card_id_test_groupby_count = test.groupby(\"card_id\")[\"first_active_month\"].agg([\"count\",\"size\"]).reset_index()","d31bbc0c":"card_id_test_groupby_count[card_id_test_groupby_count[\"count\"] > 1].count()","30074fe1":"card_id_test_groupby_count[card_id_test_groupby_count[\"size\"] > 1].count()","25bafc60":"train[\"first_active_month\"] = pd.to_datetime(train[\"first_active_month\"])\ntest[\"first_active_month\"] = pd.to_datetime(test[\"first_active_month\"])","67a47f13":"cnt_srs = train['first_active_month'].dt.date.value_counts()\ncnt_srs = cnt_srs.sort_index()\nplt.figure(figsize=(14,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='green')\nplt.xticks(rotation='vertical')\nplt.xlabel('First active month', fontsize=12)\nplt.ylabel('Number of cards', fontsize=12)\nplt.title(\"First active month count in train set\")\nplt.show()\n\ncnt_srs = test['first_active_month'].dt.date.value_counts()\ncnt_srs = cnt_srs.sort_index()\nplt.figure(figsize=(14,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='green')\nplt.xticks(rotation='vertical')\nplt.xlabel('First active month', fontsize=12)\nplt.ylabel('Number of cards', fontsize=12)\nplt.title(\"First active month count in test set\")\nplt.show()\n\n","34ea9d59":"train[\"target\"].describe()","c3bfca1d":"plt.figure(figsize=(8,6))\nplt.scatter(range(train.shape[0]), np.sort(train[\"target\"].values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('Loyalty Score', fontsize=12)\nplt.show()","d5e637ca":"plt.figure(figsize=(12,8))\nsns.distplot(train[\"target\"],bins=50, kde=False, color=\"red\")\nplt.title(\"Histogram of Loyalty score\")\nplt.xlabel('Loyalty score', fontsize=12)\nplt.show()","68e70c89":"def plotViolin(feature):\n    plt.figure(figsize=(8,4))\n    sns.violinplot(x=feature, y=\"target\", data=train)\n    plt.xticks(rotation='vertical')\n    plt.xlabel('Feature 1', fontsize=12)\n    plt.ylabel('Loyalty score', fontsize=12)\n    plt.title(\"Feature 1 distribution\")\n    plt.show()\n\nplotViolin(\"feature_1\")\nplotViolin(\"feature_2\")\nplotViolin(\"feature_3\")","f7e0276a":"sns.distplot(train[\"feature_1\"],kde=False)","2a5487ce":"sns.distplot(train[\"feature_2\"],kde=False)","de657235":"sns.distplot(train[\"feature_3\"],kde=False)","94790797":"historical_transaction = pd.read_csv(\"..\/input\/historical_transactions.csv\")","a37b283f":"historical_transaction.describe(include=\"all\")","8385d059":"historical_transaction.columns","42e12f77":"historical_transaction.count()","1a9b4410":"columns_check = ['authorized_flag', 'category_1', 'installments',\\\n                 'category_3','month_lag','category_2','state_id','subsector_id']","16d25835":"def plot_distribution(column,df):\n    distribution  = df[column].value_counts()\n    plt.figure(figsize=(10,5))\n    sns.barplot(distribution.index, distribution.values, alpha=0.8)\n    plt.title('Distribution of ' + column)\n    plt.ylabel(\"distribution\", fontsize=12)\n    plt.xlabel(column, fontsize=12)\n    plt.show()","2dff5620":"for col in columns_check:\n    plot_distribution(col,historical_transaction)","dd32eec1":"merchants = pd.read_csv(\"..\/input\/merchants.csv\")","a4e676f3":"merchants.head(5)","eb708a67":"merchants.head()","6ae921ed":"columns_to_check_merchant = [\n       'subsector_id', 'category_1',\n       'most_recent_sales_range', 'most_recent_purchases_range',\n       'category_4', 'city_id', 'state_id', 'category_2']","17228f35":"['merchant_group_id', 'merchant_category_id',\n       'numerical_1', 'numerical_2', 'category_1',\n       'most_recent_sales_range', 'most_recent_purchases_range',       \n       'category_4', 'city_id', 'state_id', 'category_2']","85f52bea":"for col in columns_to_check_merchant:\n    plot_distribution(col,merchants)","00888c48":"merchants[\"numerical_1\"].value_counts()","5faa7142":"merchants[\"numerical_2\"].value_counts()","6a552f51":"merchants[[\"numerical_1\",\"numerical_2\"]].corr()","5d8b0073":"new_trans_df = pd.read_csv(\"..\/input\/new_merchant_transactions.csv\")\nnew_trans_df.head()","3073606c":"new_trans_df.columns == historical_transaction.columns","ee52fb06":"gdf = historical_transaction.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].size().reset_index()\ngdf.columns = [\"card_id\", \"num_hist_transactions\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","f8df98b4":"gdf = historical_transaction.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].agg(['sum', 'mean', 'std', 'min', 'max']).reset_index()\ngdf.columns = [\"card_id\", \"sum_hist_trans\", \"mean_hist_trans\", \"std_hist_trans\", \"min_hist_trans\", \"max_hist_trans\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","cd6fff77":"train.columns","cfc42d13":"gdf = new_trans_df.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].agg(['sum', 'mean', 'std', 'min', 'max']).reset_index()\ngdf.columns = [\"card_id\", \"sum_merch_trans\", \"mean_merch_trans\", \"std_merch_trans\", \"min_merch_trans\", \"max_merch_trans\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","c1aa3847":"gdf = new_trans_df.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].size().reset_index()\ngdf.columns = [\"card_id\", \"num_merch_transactions\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","bd064216":"target_col = \"target\"\ntrain[\"year\"] = train[\"first_active_month\"].dt.year\ntest[\"year\"] = test[\"first_active_month\"].dt.year\ntrain[\"month\"] = train[\"first_active_month\"].dt.month\ntest[\"month\"] = test[\"first_active_month\"].dt.month\n\ncols_to_use = [\"feature_1\", \"feature_2\", \"feature_3\", \"year\", \"month\", \n               \"num_hist_transactions\", \"sum_hist_trans\", \"mean_hist_trans\", \"std_hist_trans\", \n               \"min_hist_trans\", \"max_hist_trans\",\n               \"num_merch_transactions\", \"sum_merch_trans\", \"mean_merch_trans\", \"std_merch_trans\",\n               \"min_merch_trans\", \"max_merch_trans\",\n              ]\n\ndef run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        \"num_leaves\" : 30,\n        \"min_child_weight\" : 50,\n        \"learning_rate\" : 0.05,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.7,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2018,\n        \"verbosity\" : -1\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100, evals_result=evals_result)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result\n\ntrain_X = train[cols_to_use]\ntest_X = test[cols_to_use]\ntrain_y = train[target_col].values\n\npred_test = 0\nkf = model_selection.KFold(n_splits=5, random_state=2018, shuffle=True)\nfor dev_index, val_index in kf.split(train):\n    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    \n    pred_test_tmp, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)\n    pred_test += pred_test_tmp\npred_test \/= 5.\n    ","f470f95c":"fig, ax = plt.subplots(figsize=(12,10))\nlgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"LightGBM - Feature Importance\", fontsize=15)\nplt.show()\n","d2e12055":"sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\nsub_df[\"target\"] = pred_test\nsub_df.to_csv(\"baseline_lgb.csv\", index=False)\n","6c59f9b5":"### ^^ The distribution of test and train is similar\n\n### Lets look at the target variable distribution","dd0f4bda":"## The summary of the data present in historical transaction file is as follows , more digging needed\n###### authorized_flag               -  Looks like if the transaction was authorized or not , \n###### card_id                             - This is the unique card id  \n###### city_id                               - city in which the transaction was done\n###### category_1                        - some masked category , has only two values and one of them is dominating\n###### category_2                       - Some masked category, Take 5 values.\n###### category_3                       - Some masked category, Take 3 values\n###### merchant_category_id    - The category the merchant belongs to \n###### installments                    - My guess is that it is the installments at which the purchase was completed , most of installments were completed in 0 , some at 1 . Not quite sure what 0 means ....\n###### merchant_id                    - Unique Merchant Id \n###### month_lag                       - Month lag to reference date\n###### purchase_amount          - Amount of transaction \n###### purchase_date               - purchase date\n###### state_id                           - state in which the transaction was done\n###### subsector_id                   - something similar to merchant_category_id .\n\n","b9c58191":"#### ^^ Yes these two variables are highly co related","920414b3":"## Lets peek into each of files","6e575ae5":"Lets look at each of the columns to understand more \n\nStarting with card_id","7bfd8413":"## Dataset exploration","b601efb6":"### Adding few Simple features","35453866":"## ^^Card Id is the unique id representing each user \n## Lets check the sanity of this data","a2b7dcd8":"### Lets look at each of the above columns \n\nLets start to look at authorized_flag","a69aa733":"### ^^ The data looks more of discreate than continuous , And the distribution of target variable seems to same for different values which means we dont see yet if these features are significant or not ,  we need see how models see it ","82bff33f":"#### ^^ these columns looks similar to ones present in historical transactions file , let verify it ","5321b44e":"## Lets now shift our focus to merchants.csv file","2d1e8c2d":"### ^^ Looks good","6d820b64":"### Lets look at the historical transaction data","6e06f71b":"#### If you find this kernel usefull , pls do upvote. It really motivates","8e05eeec":"## ^^ most of values in column numerical_1 is less","ffccb227":"### Lets look into test and do similar sanity check","681dd634":"## ^^ There is small outlier values , but rest looks good\n\n### Lets look into three other features","63d6c628":"## The summary of the data present in historical transaction file is as follows , more digging needed\n#### merchant_id                                        : Unique Merchant Id \n#### merchant_group_id                          : Yet another group Id , needs to be investigated   \n#### merchant_category_id                     : This field looks similar to the one we say in historical transaction file   , we have to find how these two are related\n#### subsector_id                                       :  This field looks similar to the one we say in historical transaction file   , we have to find how these two are related\n#### numerical_1                                         : Highly correlated with numerical_2, \n#### numerical_2                                        :  \n#### category_1                                           :  This field looks similar to the one we say in historical transaction file   , we have to find how these two are related\n#### most_recent_sales_range              :  Yet another categorical data.       \n#### most_recent_purchases_range   :  Yet another categorical data.                       \n#### avg_sales_lag3                                  :  To look deeper\n#### avg_purchases_lag3                             :  To look deeper\n#### active_months_lag3                             :  To look deeper\n#### avg_sales_lag6                                 :  To look deeper\n#### avg_purchases_lag6                             :  To look deeper\n#### active_months_lag6                             :  To look deeper\n#### avg_sales_lag12                                :  To look deeper\n#### avg_purchases_lag12                            :  To look deeper\n#### active_months_lag12                            :  To look deeper\n#### category_4                                        : Yet another categorical data\n#### city_id                                                : city id of the merchant\n#### state_id                                             : state of the merchant \n#### category_2                                      : This field looks similar to the one we say in historical transaction file   , we have to find how these two are related","8faef3b3":"### ^^ All looks good here too\n\n####  Lests look at the distribution of first active month","d2a5d1ce":"Lets look at the distribution of city_id flag","d226c13d":"#### ^^ The distribution and range of both columns numerical_1 and numerical_2 very similar , are these two related ?","3785b2ef":"## Lets Quickly build a baseline model ","5a8b1b7d":"## Lets look at the last file New Merchant Transactions"}}