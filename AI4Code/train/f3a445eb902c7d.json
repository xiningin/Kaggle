{"cell_type":{"dfebb17a":"code","684d8420":"code","2c3f1cd3":"code","89a77331":"code","69946d4d":"code","db4c591e":"code","85b022c6":"code","04194026":"code","b0057ce0":"code","9d03685e":"code","19e5c132":"code","28e9ac4a":"code","b0bb4335":"code","6858d39d":"code","eae8501e":"code","0e2de4b9":"code","48974557":"code","188ec7f2":"code","ad7b9d93":"code","2582d425":"code","79f51eae":"code","267d1bd6":"code","496cb974":"code","ac07ff6f":"code","e574fe62":"code","b93d3eda":"code","c71a3dd1":"code","b214e17d":"code","1f9c6439":"code","e384b013":"code","4e5b0087":"code","f7c2935d":"code","6d4737fc":"markdown","a03836ab":"markdown","785c7c33":"markdown","6afdd13f":"markdown","cbbddf49":"markdown","02cb3a42":"markdown","b1930b24":"markdown","761914e7":"markdown","8ce7e987":"markdown","18692774":"markdown","bcb6e9e0":"markdown","c3c9cd91":"markdown","06fc3524":"markdown","b37b7628":"markdown","55f51cb9":"markdown","9b31f760":"markdown","d919e7e7":"markdown","33245ebb":"markdown","d134c4ff":"markdown","c3c99e4e":"markdown","a4067b12":"markdown","b9ff3562":"markdown","f8115dc5":"markdown","1b7d54e4":"markdown","4ad67697":"markdown","4879581a":"markdown","afa7587d":"markdown","3a29c290":"markdown","041776bc":"markdown","b16510ca":"markdown","60ae89cf":"markdown","94e63866":"markdown","a321e602":"markdown","a81321c7":"markdown","fc09be7d":"markdown","c65439a1":"markdown","b26fe50f":"markdown","34a46920":"markdown"},"source":{"dfebb17a":"import numpy as np                          \n# The numpy package can help us with the calculation of vector and matrix\nimport pandas as pd                        \n# The pandas package can offer us some new data structure like dataframe \nimport matplotlib.pyplot as plt              \n# The matplotlib package can realize the visualization of the process\n%matplotlib inline                           \n# This command is a magic function, \n# whcih can embed the chart into the jupyter notebook\nimport os ","684d8420":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","2c3f1cd3":"pdData=pd.read_csv(\"\/kaggle\/input\/diabetes-dataset\/diabetes2.csv\")  \n# read the csv file and trandfer it into a dataframe\npdData.info()   \n# The info() function can offer us the basic information of the dataset","89a77331":"pdData.columns","69946d4d":"positive=pdData[pdData[\"Outcome\"]==1]\nnegative=pdData[pdData[\"Outcome\"]==0]\nplt.figure(figsize=(24,7))\n\nplt.subplot(1,2,1)\nplt.scatter(positive[\"Glucose\"],positive[\"DiabetesPedigreeFunction\"],\n            marker=\"o\",label=\"Outcom=1\")\nplt.scatter(negative[\"Glucose\"],negative[\"DiabetesPedigreeFunction\"],\n            marker=\"x\",label=\"Outcom=0\")\nplt.legend()\nplt.xlabel(\"Glucose\")\nplt.ylabel(\"DiabetesPedigreeFunction\")\n\nplt.subplot(1,2,2)\nplt.scatter(positive[\"BloodPressure\"],positive[\"Insulin\"],\n            marker=\"o\",label=\"Outcom=1\")\nplt.scatter(negative[\"BloodPressure\"],negative[\"Insulin\"],\n            marker=\"x\",label=\"Outcom=0\")\nplt.legend()\nplt.xlabel(\"BloodPressure\")\nplt.ylabel(\"Insulin\")\n\n#plt.savefig(\"visual\")\nplt.show()\n\n","db4c591e":"from mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure(dpi=100)\n\nax = Axes3D(fig)\nax.scatter(positive[\"Glucose\"],positive[\"BloodPressure\"],\n           positive[\"SkinThickness\"],cmap=\"cool\",label=\"outcome=1\")\nax.scatter(negative[\"Glucose\"],negative[\"BloodPressure\"],\n           negative[\"SkinThickness\"],cmap=\"cool\",label=\"outcome=0\")\n\nax.set_xlabel(\"Glucose\")\nax.set_ylabel(\"BloodPressure\")\nax.set_zlabel(\"SkinThickness\")\nax.set_title(\"Visualization of the classification\")\nplt.legend()\nplt.savefig(\"3D\")\nplt.show()","85b022c6":"fig = plt.figure(dpi=100)\n\nax = Axes3D(fig)\nax.scatter(positive[\"BMI\"],positive[\"DiabetesPedigreeFunction\"],\n           positive[\"Age\"],cmap=\"cool\",label=\"outcome=1\")\nax.scatter(negative[\"BMI\"],negative[\"DiabetesPedigreeFunction\"],\n           negative[\"Age\"],cmap=\"cool\",label=\"outcome=0\")\nax.set_xlabel(\"BMI\")\nax.set_ylabel(\"DiabetesPredigreeFunction\")\nax.set_zlabel(\"Age\")\nax.set_title(\"Visualization of the classification\")\nplt.legend()\nplt.savefig(\"3D2\")\nplt.show()","04194026":"def sigmoid(z):\n    return 1\/(1+np.exp(-z))","b0057ce0":"def model(X,theta):\n    return sigmoid(np.dot(X,theta.T))\n# np.dot means do the inner product of two matrix","9d03685e":"def cost(X,y,theta):\n    left=np.multiply(-y,np.log(model(X,theta)))\n    right=np.multiply(1-y,np.log(1-model(X,theta)))\n    return np.sum(left-right)\/(len(X))\n# np.sum means do the matrix addition of two vector ","19e5c132":"def gradient(X,y,theta):\n    grad=np.zeros(theta.shape)\n    error=(model(X,theta)-y).ravel()\n    for j in range(len(theta.ravel())):\n        term=np.multiply(error,X[:,j])        \n        grad[0,j]=np.sum(term)\/len(X)\n    return grad","28e9ac4a":"import numpy.random\ndef shuffleData(data):\n    np.random.shuffle(data)\n    cols=data.shape[1]\n    X=data[:,0:cols-1]\n    y=data[:,cols-1:]\n    return X,y","b0bb4335":"#label the three stop conditions with three integers \nSTOP_ITER=0                         \nSTOP_COST=1\nSTOP_GRAD=2\ndef stopCriterion(type,value,threshold):             \n    # set the condition respectively \n    \n    if type==STOP_ITER:   return value>threshold\n# the first stop_iteraion condition means that \n# we need to set the number of the times of iteration, \n# if the times of iteration exceeds the value we set, \n# then stop the loop\n    \n    if type==STOP_COST:   return abs(value[-1]-value[-2])<threshold\n# the second stop_cost condition means that \n# if the difference between two costs is less than the threshold \n# we set, then stop the loop\n    \n    if type==STOP_GRAD:   return np.linalg.norm(value)<threshold \n# the third stop_gradient condition menas that \n# if the norm of the gradient vector is less than the value we \n# set, then stop the loop","6858d39d":"import time  \n# this package is used to calculate the time for running the program\ndef descent(data,theta,batchSize,stopType,thresh,alpha):\n    init_time=time.time()\n    i=0  # The time of iteration \n    k=0  # The number of the batch \n    X,y=shuffleData(data)         \n    # get the sample and target after doing the shuffle   \n    grad=np.zeros(theta.shape)    \n    # creata an array to store the gradient with the initial value of 0\n    costs=[cost(X,y,theta)]       \n    # creata a list object to store \n    # all the cost during the gradient descent \n    \n    while True:\n        grad=gradient(X[k:k+batchSize],y[k:k+batchSize],theta)     \n        # update the value of the gradient \n        k+=batchSize                                               \n        # update the value of k \n       \n        if k>=n:                        \n            k=0\n            X,y=shuffleData(data)       \n            # reshuffle the data if k>=n, \n            # this is only used for the mini-batch method\n        \n        theta=theta-alpha*grad          \n        # update the parameters \n        costs.append(cost(X,y,theta))         \n        # store the new cost and append it into the costs list \n        i+=1                                 \n        # update i\n        \n        if stopType==STOP_ITER:         \n            value=i                     \n            #set the time of iteration as value\n        elif stopType==STOP_COST:\n            value=costs                 \n            #set the costs list as value \n        elif stopType==STOP_GRAD:\n            value=grad                  \n            #set the gradience vector as value\n        if stopCriterion(stopType,value,thresh): break          \n            # set the stop condition\n    \n    return theta,i-1,costs,grad,time.time()-init_time","eae8501e":"def runExpe(data,theta,batchSize,stopType,thresh,alpha):\n    theta,iter,costs,grad,dur=descent(data,theta,batchSize,stopType,thresh,alpha)   \n    # call the gradient dexcent function\n    \n    \n    name=\"Scaled\"\n    name += \"data - learning rate :{} - \".format(alpha)   \n    # represent the learning rate of the model\n    \n    # represent the stop_condition we choose \n    if stopType==STOP_ITER:\n        strStop=\"{} iterations\".format(thresh)\n    elif stopType==STOP_COST:\n        strStop=\"costs change < {}\".format(thresh)\n    else:\n        strStop = \"gradient norm < {}\".format(thresh)\n    \n    name+=strStop\n    print(\"***{}\\nTheta:{} - Iter: {} - Last cost: {:03.2f} - Duration: {:03.2f}s\".format(name,theta,iter,costs[-1],dur))\n    # set the title \n    \n    fig,ax=plt.subplots(figsize=(12,4))           \n    # create a canvas with the ration of length and width 12:4\n    ax.plot(np.arange(len(costs)),costs,'r')      \n    # plot the chart \n    ax.set_xlabel(\"Iteration\")                    \n    # set the title of x-axis\n    ax.set_ylabel(\"Cost\")                        \n    # set the title of y-axis\n    ax.set_title(name.upper())                    \n    # set the title\n   \n    return theta ","0e2de4b9":"pdData.insert(0,'ones',1)           \n# add a column to the pdData for the update of b","48974557":"orig_data=pdData.values             \n# here in Python 3.8 and later versions, the _.values means \n# transfer the values of a dataframe object into a multi-dimensional \n# numpy array   \n#NOTE: \n#       if your python version is low, you can change the code into:  \n#                            to_matrix()     \n#       but the to_matrix function was deleted in the new version\n\ncols=orig_data.shape[1]             \n# get the number of columns and set it as a constant\n\nX=orig_data[:,0:cols-1]             \n# X means the attributes of the feature \ny=orig_data[:,cols-1:cols]          \n# y means the label of the samples\ntheta = np.zeros ([1,9])            \n# originate the theta ","188ec7f2":"X.shape,y.shape,theta.shape         \n# have a look of the shape of X, y and theta ","ad7b9d93":"from sklearn import preprocessing as pp                \n# call the prerocessing function in the sklearn package \nscaled_data=orig_data.copy()                           \n# get a copy from the orginal data\nscaled_data[:,1:9]=pp.scale(orig_data[:,1:9])         \n# do the normalization ","2582d425":"n=768\nrunExpe(scaled_data,theta,n,STOP_ITER,thresh=20000,alpha=0.001)","79f51eae":"n=768\nrunExpe(scaled_data,theta,n,STOP_COST,thresh=0.000004,alpha=0.001)","267d1bd6":"n=768\nrunExpe(scaled_data,theta,1,STOP_ITER,thresh=50000,alpha=0.01)","496cb974":"n=768\nrunExpe(scaled_data,theta,20,STOP_COST,thresh=0.0000000001,alpha=0.001)","ac07ff6f":"newtheta=np.array([-0.8265755 ,  0.37491152,  1.03329477, -0.21938382, -0.00491618,-0.08607098,  0.65185757,  0.2965955 ,  0.20040424])\n# store the theta with the best performance ","e574fe62":"def predict(X,theta):\n    return [1 if x>=0.5 else 0 for x in model(X,theta)]\n# return a function with the predicted result \n# The principle is that:\n#          if the predicted outcome is larger than 0.5 then label the outcome with 1\n#          if the predicted outcome is smaller than 0.5 then label the outcome with 0","b93d3eda":"scaled_X=scaled_data[:,0:cols-1]","c71a3dd1":"predictions=predict(scaled_X,newtheta)           \n# create a precitions list to store the predicted outcome \ncorrect = [1 if ((a==1 and b==1) or (a==0 and b==0)) \n           else 0 for (a,b) in zip(predictions,y)]\n# if the predicted outcome is in line with the target label, \n# then we set the value as 1, otherwise 0\n                                                \naccuracy= (sum(map(int,correct))\/len(correct))\n# calculate the ratio of correctness \nprint('accuracy={}'.format(accuracy))      # print the accuracy \n","b214e17d":"visual=pd.DataFrame(scaled_data)   \n# create a new dataframe for visualization \nvisual.columns=[\"zero\",'Pregnancies', 'Glucose', \n                'BloodPressure', 'SkinThickness', 'Insulin',\n                'BMI', 'DiabetesPedigreeFunction', \n                'Age', 'Outcome']\n                # change the name of the columns ","1f9c6439":"visual.head(10)  # have a brief view of the scaled data ","e384b013":"pos=visual[visual[\"Outcome\"]==1]\nneg=visual[visual[\"Outcome\"]==0]\n# create two dataframe to store the data","4e5b0087":"plt.figure()  # create the canvas \n\nplt.scatter(pos[\"Glucose\"],pos[\"BloodPressure\"],marker=\"o\",label=\"Outcome=1\")  \n# draw the scatter plot \nplt.scatter(neg[\"Glucose\"],neg[\"BloodPressure\"],marker=\"x\",label='Outcome=0') \n\nplt.legend()    \nplt.xlabel(\"Glucose\")       # set the title of x-axis \nplt.ylabel(\"BloodPressure\") # set the title of y-axis\n\nx= np.linspace(0,1.3,30)\ny= (0.97485299*x-0.78869174)\/(-0.19376083)\n                            # plot the function based on the final parameters \nplt.plot(x,y,lw=3,c='r')    # set the format of the line \nplt.show()","f7c2935d":"plt.figure()\n\nplt.scatter(pos[\"Glucose\"],pos[\"BMI\"],marker=\"o\",label=\"Outcome=1\")\nplt.scatter(neg[\"Glucose\"],neg[\"BMI\"],marker=\"x\",label='Outcome=0')\n\nplt.legend()\nplt.xlabel(\"Glucose\")\nplt.ylabel(\"BMI\")\n\nx= np.linspace(-1.3,2.2,30)\ny= (0.97485299*x-0.78869174)\/(-0.60651927)\nplt.plot(x,y,lw=3,c='r')\n\nplt.show()","6d4737fc":"According to the result we have deducted in the essay, we use the following code to calculate the gradient.","a03836ab":"We will choose the best result with the cost of 0.47","785c7c33":"# The sourece code of using python to realize logistic regression","6afdd13f":"### The loss function","cbbddf49":"## Test the result of different methods ","02cb3a42":"### The full gradient descent ","b1930b24":"## Process the data","761914e7":"### Sigmoid Function ","8ce7e987":"The following code will show the whole process of logistic regression without calling any exsiting package like the logistic regression library in scikit-learn or pytorch. The following are the packages we called in the programme.","18692774":"### Stochastic Gradient Descent ","bcb6e9e0":"### The gradient calculation function","c3c9cd91":"Here we set the batch size as n and do the gradient descent ","06fc3524":"### The Gradient descent function ","b37b7628":"### The  plotting function for visualization ","55f51cb9":"As different variables may have a large difference in their variance, so that we can do the scaling process to ensure that each variable could have the same mean of 0 and variance of 1 \n","9b31f760":"---END","d919e7e7":"## Prepare all the function we need during the logistic regression","33245ebb":"The model function is used to calculate the inner product of two matrix using the numpy package and then output the outcome of the sigmoid function over the result. ","d134c4ff":"### Mini-batch Gradient Descent ","c3c99e4e":"## Using the sklearn to scale the data ","a4067b12":"The next step is to have a brief view of the dataset, we could transfer the csv file into a dataframe ","b9ff3562":"### Using the stop_cost as the stop condition","f8115dc5":"### The criteria of stop the program","1b7d54e4":"## Viusalization of the result ","4ad67697":"Here we create three different stop conditions to pick out the best one.","4879581a":"## The preliminary preparation before data anslysis and machine learning","afa7587d":"As the dataframe has 768 rows and 0 columns, according to the information, there is no Null Value in the dataset, so we do not need to do the missing value processing.","3a29c290":"As is illustrated in the essay, the cross entropy was used to calculate the loss\n","041776bc":"The shuffling function is used to randomly arrange the data.","b16510ca":"### Model function","60ae89cf":"<div class=\"mark\">\n----------------------------------------------------------------------------------------------------------------<\/div><i class=\"fa fa-lightbulb-o \"><\/i>","94e63866":"Here we set the batch size as 1 and do the parameters update, the advantage of this method is that the speed of descent is very large so \nthat we can set the iteration times much larger ","a321e602":"The Sigmoid Function is a S-shape function which could output a probability.\n","a81321c7":"## Calculate the accuracy of the final result ","fc09be7d":"### The shuffling function","c65439a1":"## Visualization part\n","b26fe50f":"The scaled data is the data after the normalization, which could do help to the machine learning result ","34a46920":"<div class=\"mark\">\n------------------------------------------------------------------------------------------------------------------------<\/div><i class=\"fa fa-lightbulb-o \"><\/i>"}}