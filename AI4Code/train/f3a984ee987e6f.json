{"cell_type":{"0283454e":"code","67784964":"code","df1be08c":"code","1a080049":"code","dcae63d2":"code","95843bd0":"code","786de14a":"code","2929fa15":"code","11af035f":"code","8f9927a3":"code","3b63d4bb":"code","3fff5355":"code","646e7c3f":"code","ff3009c1":"code","4966176f":"code","7a962c9d":"code","beba2d38":"code","6c35cfb7":"code","1b444b12":"code","681918d5":"markdown","404a835f":"markdown","7a929c95":"markdown","6460ce25":"markdown","77d6a155":"markdown","c7c03715":"markdown"},"source":{"0283454e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","67784964":"df=pd.read_csv('..\/input\/sentiment140\/training.1600000.processed.noemoticon.csv',encoding='ISO-8859-1',header=None)\ndf.head()","df1be08c":"columns=df.columns\ncolumns","1a080049":"df.drop([1,2,3,4],axis=1,inplace=True)\ndf.head()","dcae63d2":"df.columns=['sentiment','data']\ndf.head()","95843bd0":"y=df['sentiment']","786de14a":"from sklearn.model_selection import train_test_split\ndf_train,df_test,y_train,y_test=train_test_split(df['data'],y,test_size=0.33,random_state=42)\nprint('DF Train Shape: ',df_train.shape)\nprint('DF Test Shape: ',df_test.shape)\nprint('Y Train Shape: ',y_train.shape)\nprint('Y Test Shape: ',y_test.shape)\n","2929fa15":"from tensorflow.keras.preprocessing.text import Tokenizer\nmax_words=10000\ntokenizer=Tokenizer(max_words)\ntokenizer.fit_on_texts(df_train)\nsequence_train=tokenizer.texts_to_sequences(df_train)\nsequence_test=tokenizer.texts_to_sequences(df_test)","11af035f":"word2vec=tokenizer.word_index\nV=len(word2vec)\nprint('dataset has %s number of independent tokens' %V)","8f9927a3":"from tensorflow.keras.preprocessing.sequence import pad_sequences\ndata_train=pad_sequences(sequence_train)\ndata_train.shape","3b63d4bb":"T=data_train.shape[1]\ndata_test=pad_sequences(sequence_test,maxlen=T)\ndata_test.shape","3fff5355":"from tensorflow.keras.layers import Input,Conv1D,MaxPooling1D,Dense,GlobalMaxPooling1D,Embedding\nfrom tensorflow.keras.models import Model","646e7c3f":"D=20\ni=Input((T,))\nx=Embedding(V+1,D)(i)\nx=Conv1D(32,3,activation='relu')(x)\nx=MaxPooling1D(3)(x)\nx=Conv1D(64,3,activation='relu')(x)\nx=MaxPooling1D(3)(x)\nx=Conv1D(128,3,activation='relu')(x)\nx=GlobalMaxPooling1D()(x)\nx=Dense(5,activation='softmax')(x)\nmodel=Model(i,x)\nmodel.summary()","ff3009c1":"model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\ncnn_senti=model.fit(data_train,y_train,validation_data=(data_test,y_test),epochs=5,batch_size=100)\n","4966176f":"y_pred=model.predict(data_test)\ny_pred","7a962c9d":"y_pred=np.argmax(y_pred,axis=1)\ny_pred","beba2d38":"from sklearn.metrics import confusion_matrix,classification_report\nimport seaborn as sns","6c35cfb7":"cm=confusion_matrix(y_test,y_pred)\nax=sns.heatmap(cm,annot=True,cmap='Blues',fmt=' ')\nax.set_title('Confusion Matrix')\nax.set_xlabel('y_test')\nax.set_ylabel('y_pred')\n","1b444b12":"print(classification_report(y_test,y_pred))","681918d5":"## Training the model","404a835f":"## Scoring ","7a929c95":"## Feature Engineering","6460ce25":"## Building deep learn model","77d6a155":"## Importing the dataset","c7c03715":"## Splitting the dataset in train and test split"}}