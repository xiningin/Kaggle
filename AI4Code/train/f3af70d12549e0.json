{"cell_type":{"edf32211":"code","a2ff5d31":"code","d1105840":"code","f58b2591":"code","17e94c1d":"code","b3b90cfc":"code","1e1193d2":"code","7efd82bb":"code","d057ebb6":"code","2913d0c0":"code","7a81b2a5":"code","41c20574":"code","5a9ca7c4":"code","6048580c":"code","10cd4723":"code","c890c26c":"code","395973d7":"code","fd2249e8":"markdown","9181efbf":"markdown","57c701cf":"markdown"},"source":{"edf32211":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a2ff5d31":"import warnings\nimport nltk\nimport spacy\nimport re\nfrom spacy import displacy\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport plotly.express as px\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nfrom tensorflow.keras.models import load_model\nfrom wordcloud import WordCloud\nwarnings.filterwarnings('ignore')","d1105840":"path_of_file = '..\/input\/feedback-prize-2021\/train\/00C819ADE423.txt'\ntext = open(path_of_file, 'r').read()","f58b2591":"text[:2000]","17e94c1d":"nlp = spacy.load('en_core_web_sm')\nstopword = nltk.corpus.stopwords.words('english')\ndef text_cleaning(text):\n    \n    text = re.sub(r'[^\\w\\s]', '',str(text))             #Punctuations\n    text=re.split(\"\\W+\",text)                           #Tokenizing\n    text=[word for word in text if word not in stopword]#Stop words\n    text = ' '.join(text)                              \n    return text\n\n\ndef frequent_of_words(string):\n    \n    clean_string = text_cleaning(string)\n    split_string = pd.DataFrame(clean_string.split(),columns=['Words'])\n    split_string = split_string.value_counts()[:1000].reset_index(drop=False)[:1000]\n    split_string.columns = ['Words','Count']\n    return split_string","b3b90cfc":"frequent_words = frequent_of_words(text)\nfrequent_words[:15].style.background_gradient(cmap='summer')","1e1193d2":"fig = px.funnel(frequent_words[:15], x='Count', y='Words')\nfig.show()","7efd82bb":"list_for_cloud = []\nfor i in frequent_words.Words:\n    list_for_cloud.append(str(i))","d057ebb6":"wordcloud = WordCloud(width = 300, height = 300,\n                background_color ='black',\n                colormap='Set3',      \n                stopwords = stopword,\n                min_font_size = 10).generate(' '.join(list_for_cloud))\n  \n# plot the WordCloud image                       \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\nplt.show()","2913d0c0":"name_list = ['Nasa','Venus','Earth','Solar','Mars','Planets']\nscripts = []\nsplit_string = text.split()\nfor name in name_list:\n    scripts.append((name,split_string.count(name)))","7a81b2a5":"colors = ['#2F86A6','#34BE82','#2FDD92','#F2F013','#F9975D','#F4E185']\nsections = [scripts[0][1],\n            scripts[1][1],\n            scripts[2][1],\n            scripts[3][1],\n           scripts[4][1],\n           scripts[5][1]]\nplt.figure(figsize=(14, 8), dpi=75)\nplt.pie(sections, labels=name_list,colors=colors, \n        wedgeprops=dict( alpha=1),\n        startangle=90,\n        #explode = (0,0,0,0),\n        autopct = '%0.1f%%',\n         textprops={\n                'fontsize': 15, \n                'fontweight': 'normal'}\n            )\n\nplt.axis('equal')\nplt.title('Script Count',fontsize=20)\nplt.show()","41c20574":"def target(text):\n    input_txt = text[:-1]\n    target = text[1:]\n    return input_txt, target\n\nvocab = sorted(set(text))\nchar_index = {u:i for i, u in enumerate(vocab)}\nindex_of_charachter = np.array(vocab)\nencoded_text = np.array([char_index[c] for c in text])\nchar_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\nsequence_lenght = 120\n#+1 because of zero indexing\nsequences = char_dataset.batch(sequence_lenght+1, drop_remainder=True)\ndataset = sequences.map(target)\nbatch_size = 128\nbuffer_size = 10000\ndataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)","5a9ca7c4":"class PlanetsTextGenerator:\n    '''\n    TextGeneratorModel writed for generate text for Planets.\n    Class Bulit with Tenserflow.\n    This class has multifunction. It can train and save alse test ability.\n    '''\n\n    def loss_func(self,true,pred):\n         return sparse_categorical_crossentropy(true, pred, from_logits=True) \n        \n    def base_model(self,size_of_vocab=94,embedding_dim = 64,neurons = 1026,batch_size = 128):\n      \n        model = Sequential()\n        model.add(Embedding(size_of_vocab, embedding_dim,batch_input_shape=[batch_size, None]))\n        model.add(GRU(neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n        model.add(Dense(size_of_vocab))\n        model.compile(optimizer='adam', loss=self.loss_func) \n      \n        return model\n    \n    def train_model(self,dataset,epoch=2,train_vb_size=94,em_dim = 64,rnn_nrs = 1026,batchs = 128):\n        '''\n        This funtion used for train model with defined params\n\n        '''\n    \n        model = self.base_model(size_of_vocab = train_vb_size,\n                                embedding_dim = em_dim,\n                                neurons = rnn_nrs,\n                                batch_size = batchs)\n        print('\\n    --Model Creat Succesfully--   ')\n        model.fit(dataset,epochs=epoch)\n        model.save('planets.h5') \n        print('\\n    --Model Saved Succesfully--   ')\n        return model\n    \n    def use_trained_model(self,path):\n        '''\n        Function takes only path of trained model and generated sentence afterwords\n\n        '''\n        saved_model = self.base_model(size_of_vocab=94,embedding_dim = 64,neurons = 1026,batch_size=1)\n        saved_model.load_weights(path)\n        saved_model.build(tf.TensorShape([1, None]))\n        print('\\n    --Model ReCreat Succesfully--   ')\n        return saved_model\n    \n    def generate_dialog(self,model, start_sentence,characters=100):\n        '''\n        Purpose of this function is generate senctence\n        model : trained sequential model\n        start_sentence : according to which word will be generate\n        characters : lenght of generated sentence\n        '''\n    \n        num_generate = characters\n        change_char = {'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6,'&': 7,\"'\": 8,'(': 9,')': 10, '*': 11,'+': 12,',': 13,'-': 14,'.': 15,'\/': 16,'0': 17,'1': 18,'2': 19,'3': 20,'4': 21,'5': 22,'6': 23,'7': 24,\n        '8': 25,'9': 26,':': 27,';': 28,'<': 29,'=': 30,'>': 31,'?': 32,'@': 33,'A': 34,'B': 35,'C': 36,'D': 37,'E': 38,'F': 39,'G': 40,'H': 41,'I': 42,'J': 43,'K': 44,'L': 45,'M': 46,'N': 47,'O': 48,'P': 49,\n        'Q': 50,'R': 51,'S': 52,'T': 53,'U': 54,'V': 55,'W': 56,'X': 57,'Y': 58,'Z': 59,'[': 60,']': 61,'^': 62,'_': 63,'`': 64,'a': 65,'b': 66,'c': 67,'d': 68,'e': 69,'f': 70,'g': 71,'h': 72, 'i': 73,'j': 74,\n        'k': 75,'l': 76,'m': 77,'n': 78,'o': 79,'p': 80,'q': 81,'r': 82,'s': 83,'t': 84,'u': 85,'v': 86,'w': 87,'x': 88,'y': 89,'z': 90,'{': 91,'|': 92, '}': 93}\n        vocab = ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '\/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n                 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n                 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}']\n        \n        index_of_charachter = np.array(vocab)\n        # Vecotrizing sentecnce\n        input_sentence = [change_char[chrr] for chrr in start_sentence]\n        input_sentence = tf.expand_dims(input_sentence, 0)\n        generated_txt = []\n        model.reset_states()\n        print('\\n    --Dialog Creating--   ')\n        for i in range(num_generate):\n            \n            predictions = model(input_sentence)\n            predictions = tf.squeeze(predictions, 0)\n            predictions = predictions \/ 1.0\n            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n            input_sentence = tf.expand_dims([predicted_id], 0)\n            generated_txt.append(index_of_charachter[predicted_id])\n       \n        return (start_sentence + ''.join(generated_txt))","6048580c":"generator = PlanetsTextGenerator()","10cd4723":"first_model = generator.train_model(dataset,epoch=35)","c890c26c":"first_model.summary()","395973d7":"path = '.\/planets.h5'\ntest_model = generator.use_trained_model(path)","fd2249e8":"#After here only errors.","9181efbf":"#Code by MAMMAD ABBASLI    https:\/\/www.kaggle.com\/mammadabbasli\/friends-text-generator","57c701cf":"#Function for Prepare Dataset for RNN Model"}}