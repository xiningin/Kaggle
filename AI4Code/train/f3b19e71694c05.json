{"cell_type":{"7b853823":"code","5c47ab00":"code","1be9358c":"code","c228e395":"code","0d15f6f5":"code","bd9145c8":"code","21f0ce16":"code","adfa9c3b":"code","25a29cf8":"code","74d3d097":"code","e58cc148":"code","1b2b179d":"code","80d1cb70":"code","4e719353":"code","2319b163":"code","fe3600ca":"code","665fc7af":"code","0b15a0d3":"code","bffdf48f":"code","ecde564b":"code","a15f2179":"code","08dbefa9":"code","7b64af1c":"code","a868e423":"code","aa0279ee":"code","c4f7504c":"code","4f36b9cc":"code","091870a5":"code","974f5e31":"code","fa07800f":"code","6b759495":"code","777dcf26":"code","7a6dfec2":"code","8d615c3f":"markdown","50d4d6e4":"markdown","bf29868e":"markdown","a5f97b39":"markdown","38ef43d8":"markdown","615b1570":"markdown","58347de7":"markdown","323956cc":"markdown","84c3ea53":"markdown","e9af5986":"markdown","23e37fd7":"markdown","57ceb2bf":"markdown","c58d78b2":"markdown","368f5c34":"markdown","9eeb875b":"markdown","961b1e1f":"markdown","004a6735":"markdown","9ae8bde9":"markdown","a5ef1c02":"markdown","a9abc4c8":"markdown","9875df67":"markdown","b4cb7afe":"markdown","b5e2ac1d":"markdown","60731a50":"markdown","e26a63a1":"markdown","e9375e60":"markdown","d59fe950":"markdown","e0510cd4":"markdown","dabd0e30":"markdown","52cc9bb2":"markdown","9d3dc8f4":"markdown","d8039049":"markdown","b5677024":"markdown","c7057e3a":"markdown","528d0eb1":"markdown","be9a84fa":"markdown","f972cad4":"markdown","a64a4a78":"markdown","0dee4ce0":"markdown"},"source":{"7b853823":"## Installation using pip\n### import NLP Profiler after installing from the GitHub repo (master branch)\n!pip uninstall -qy typing\n!pip install git+https:\/\/github.com\/neomatrix369\/nlp_profiler.git@master\n#    or \n# !pip install nlp_profiler -U\nimport nlp_profiler.core as NLPProfiler","5c47ab00":"## Installation using Utility function: only works on Kaggle\n### import the utility function (see https:\/\/www.kaggle.com\/neomatrix369\/nlp-profiler-class)\n# from nlp_profiler_class import NLPProfiler","1be9358c":"import sys\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# visualization tools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# prettify plots\nfigure_size = (20.0, 5.0)\n\nplt.rcParams['figure.figsize'] = list(figure_size)\n\nsns.set_palette(sns.color_palette(\"muted\"))\nsns.set_style(\"ticks\")\nsns.set(rc={'figure.figsize': figure_size})\nsns.set(style=\"whitegrid\")\nsns.set(font_scale=1.25)","c228e395":"repeated_symbols = '\u00a3\u00a3'\ntext_with_emojis = \"I love \u26bd very much \ud83d\ude01.\"\ntext_with_a_number = '2833047 people live in this area. It is not a good area.'\ntext_with_two_numbers = '2833047 and 1111 people live in this area.'\ntext_with_punctuations = \"This sentence does not seem to have too many commas, periods or semicolons (;).\"\ntext_with_a_date = \"The date today is 04\/28\/2020 for format mm\/dd\/yyyy, not 28\/04\/2020.\"\ntext_with_dates = \"The date today is 28\/04\/2020 and tomorrow's date is 29\/04\/2020.\"\ntext_with_duplicates = 'Everyone here works so hard. People work hard. ' \\\n                       'I think they have a good trait.'\ntext_with_repeated_letters = 'Harrington PPPPPPpppppeople work hard.' \\\n                             ' I think they have a goodd traittttt.'\ntext_with_repeated_digits = '283047 people live in this area3333 22224444'\ntext_with_repeated_punctuations = '283047 people live in this area[[[ ]]] :::;;;;' + repeated_symbols\ntext_with_repeated_spaces = '283047   people live in this  area'\ntext_with_whitespaces = '2833047 pe\\nople li\\tve i\\rn this area'\ntext_with_repeated_whitespaces = '2833047   \\r\\rpeople\\n\\n   live in   th\\nis are\\t\\ta'\ntext_with_english_chars = '\u00b1\u00a7\u00a3ABCDEabcdef0123456789\\nis are\\t\\n' + r\"\"\"!#$%&()*+-.\/:;<=>?@[\\]^_`{|}~\"\"\"\ntext_with_non_english_chars = '2833047 pe\\nople li\\tve i\\rn this area' \\\n                              '\u201a\u0192\u201e\u2026\u2020\u2021\u02c6\u2030\u0160\u2039\u0152\u008d\u017d\u2022\u2122\u0161\u203a\u0153\u009d\u017e\u0178\u00a1\u00a2\u00a4\u00a5\u00a6\u00a8\u00a9\u00aa\u00ab\u00ac\u00ad\u00ae\u00af\u00b0\u00b2\u00b3\u00b4\"' \\\n                              '\u00b5\u00b6\u00b7\u00b8\u00b9\u00ba\u00bb\u00bc\u00bd\u00be\u00bf\u00c0\u00c1\u00c2\u00c3\u00c4\u00c5\u00c6\u00c7\u00c8\u00c9\u00ca\u00cb\u00cc\u00cd\u00ce\u00cf\u00d0\u00d1\u00d2\u00d3\u00d4\u00d5\u00d6\u00d7\u00d8\u00d9\u00da\u00db\u00dc\u00dd\u00de\u00df' \\\n                              '\u00e0\u00e1\u00e2\u00e3\u00e4\u00e5\u00e6\u00e7\u00e8\u00e9\u00ea\u00eb\u00ec\u00ed\u00ee\u00ef\u00f0\u00f1\u00f2\u00f3\u00f4\u00f5\u00f6\u00f7\u00f8\u00f9\u00fa\u00fb\u00fc\u00fd\u00fe\u00ff' \\\n                              'This sentence is in japanese (kana) \u308d\u306c\u3075\u3046\u3048\u304a\u3084\u3086\u3086\u308f\u307b\u3078\u3078\u3066' \\\n                              'This sentence is in japanese (kana compact) \u304a\u3063\u3042\u3053\u304a\u304a\u304c\u304a\u3093\u308f\u304a' \\\n                              '\u0641\u0635\u0635\u0635\u0634\u0628\u0628\u0644\u0627\u0627\u062a\u0646\u062e\u0645\u0643\u0643\u0643 This sentence is in arabic'\n","0d15f6f5":"data =  [text_with_emojis, text_with_a_number, text_with_two_numbers, text_with_repeated_letters,\n            text_with_repeated_digits, text_with_punctuations, text_with_repeated_punctuations,\n            text_with_a_date, text_with_dates, text_with_duplicates, text_with_repeated_spaces,\n            text_with_whitespaces, text_with_repeated_whitespaces,\n            text_with_english_chars, text_with_non_english_chars]\ntext_dataframe = pd.DataFrame(data, columns=['text'])\ntext_dataframe","bd9145c8":"percentiles = [value\/100 for value in range(10, 100, 10)] + [0.05, 0.25, 0.75, 0.95]\npercentiles","21f0ce16":"text_dataframe.describe()","adfa9c3b":"text_dataframe.to_csv('raw_data.csv', index=False)","25a29cf8":"%%time\nprofiled_text_dataframe = NLPProfiler.apply_text_profiling(text_dataframe, 'text',\n                                                             params={'spelling_check': True,\n                                                                     'grammar_check': True,\n                                                                     'parallelisation_method': 'default'})","74d3d097":"profiled_text_dataframe.head()","e58cc148":"profiled_text_dataframe.to_csv('nlp_profiler_profiled_on_raw_data.csv', index=False)","1b2b179d":"profiled_text_dataframe['sentiment_polarity'].hist(xlabelsize=15, ylabelsize=15)","80d1cb70":"profiled_text_dataframe['sentiment_subjectivity'].hist(xlabelsize=15, ylabelsize=15)","4e719353":"profiled_text_dataframe['spelling_quality_score'].hist(xlabelsize=15, ylabelsize=15)","2319b163":"profiled_text_dataframe['spelling_quality'].hist(xlabelsize=15, ylabelsize=15)","fe3600ca":"profiled_text_dataframe['grammar_check_score'].hist(xlabelsize=15, ylabelsize=15)","665fc7af":"profiled_text_dataframe['grammar_check'].hist(xlabelsize=15, ylabelsize=15)","0b15a0d3":"profiled_text_dataframe['ease_of_reading_score'].hist(xlabelsize=15, ylabelsize=15)","bffdf48f":"profiled_text_dataframe['ease_of_reading_quality'].hist(xlabelsize=15, ylabelsize=15)","ecde564b":"profiled_text_dataframe['ease_of_reading_summarised'].hist(xlabelsize=15, ylabelsize=15)","a15f2179":"selected_repeat_columns = [\n    'repeated_letters_count', 'repeated_digits_count', 'repeated_spaces_count', 'repeated_whitespaces_count', \n    'repeated_punctuations_count', 'english_characters_count', 'non_english_characters_count'\n]","08dbefa9":"filter_columns = profiled_text_dataframe[selected_repeat_columns] > 0\nprofiled_text_dataframe[filter_columns][selected_repeat_columns].describe()","7b64af1c":"profiled_text_dataframe.describe(percentiles=percentiles)","a868e423":"profiled_text_dataframe.corr()","aa0279ee":"def most_correlated_pairs(dataframe, threshold=0.05):\n    corr_matrix = dataframe.corr()\n    indexes = corr_matrix.columns\n    pair_names = []\n    values = []\n    abs_values = []\n    for row_index in indexes:\n        for col_index in indexes:\n            if str(row_index) != str(col_index):\n                pair_name = f'{row_index} v\/s {col_index}'\n                alt_pair_name = f'{col_index} v\/s {row_index}'\n                if (pair_name not in pair_names) and (alt_pair_name not in pair_names):\n                    pair_names.append(pair_name)\n                    values.append(corr_matrix[row_index][col_index])\n                    abs_values.append(abs(corr_matrix[row_index][col_index]))\n\n    correlation_pairs = pd.DataFrame({\n        'pair_name': pair_names,\n        'value': values,\n        'abs_value': abs_values\n    }).sort_values(by='abs_value', ascending=False)\n    return correlation_pairs[correlation_pairs.abs_value >= threshold]","c4f7504c":"profiled_text_correalted_pairs_dataframe = most_correlated_pairs(profiled_text_dataframe, threshold=0.05)\nprofiled_text_correalted_pairs_dataframe","4f36b9cc":"profiled_text_correalted_pairs_dataframe.to_csv('profiled_text_correalted_pairs.csv', index=False)","091870a5":"def correlated_tree(dataframe, threshold=0.05):\n    corr_matrix = dataframe.corr()\n    indexes = corr_matrix.columns\n    nodes = {}\n    for row_index in indexes:\n        for col_index in indexes:\n            value = corr_matrix[row_index][col_index]\n            if (str(row_index) != str(col_index)) and (value > threshold):\n                value_as_str = f'{col_index} ({str(abs(round(value, 3)))})'\n                if row_index not in nodes:\n                    nodes[row_index] = []\n\n                nodes[row_index].append(value_as_str)\n    \n    return dict(sorted(nodes.items(), key=lambda item: item[0]))","974f5e31":"profiled_text_correalted_tree = correlated_tree(profiled_text_dataframe, threshold=0.07)\nfor each_node in profiled_text_correalted_tree:\n    print(each_node)\n    for each in profiled_text_correalted_tree[each_node]:\n        print(f'\u2514\u2500 {each }')\n    print()","fa07800f":"import pandas_profiling as pp","6b759495":"%%time\nprofiled_report = pp.ProfileReport(profiled_text_dataframe, 'Profile textual dataset using NLP Profiler')","777dcf26":"profiled_report","7a6dfec2":"profiled_report.to_file('NLP-Profiler-profiled-pandas-profiling-report.html')","8d615c3f":"### NLP Profiler is a program\/library that profiles text data and extracts NLP specific data innate in them, and produce statictical details about the text data. Think of pandas.describe() but on text data, you get a dataframe that you then can run the describe() to get descriptive statistics from it.\n\n\n### Like `pandas.describe()` function for categorical or continuous data, we DO NOT have one for text data (irrespective of it's quality). NLP Profiler can take a column of text data at a time from a dataset and extract underlying information in the text a row at a time. This can be as granular as number of characters, words, etc... all the way to high-level concepts like sentiment analysis, spell-check, etc...\n\n### It's very basic in functionality at the moment and I'm slowly testing it with small datasets and also improving the functionality little-by-little. There is a lot to do including handling data at scale or even larger datasets.\n\n### For e.g. 35 rows took 22 seconds on Kaggle, so you can do your calculations for your datasets of different sizes.\n\n### Note: the accuracy need to be checked and it's still not there, although we can use different underlying libraries to improve them. Also we don't cover all kinds of edge-cases, just now the happy path works well. So don't take the results on it's face-value. I suggest compare the results with other sources as well. Also it's a simple library at the moment and does not do a lot of things, for e.g. does not scale yet. _Recommendations to improvements are always welcome._","50d4d6e4":"<a id='describe'><\/a>\n\n----------\n\n## Simple illustraction of the Pandas `describe()` function","bf29868e":"<a id='correlation-matrix-nlp-profiler'><\/a>\n\n----------\n\n## Generating a correlation matrix on the new NLP Profiler generated dataframe\n\nJust to get a glimpse of the various relationship between the generated features: there may be false positives in the correlations - these would need filtering out.","a5f97b39":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","38ef43d8":"<a id='ToC'><\/a>\n\n----------\n\n# Table of contents\n\n- [NLP Profiler Demo](#demo)\n- [Purpose of NLP Profiler](#purpose)\n- [Installation and import libraries\/packages](#import-libraries)\n- [Creating dataset](#dataset)\n- [Simple illustraction of the Pandas `describe()` function](#describe)\n- [NLP profiler's equivalent to that](#equivalent)\n  - Generating features\n    - Granular features\n    - High-level features\n  - Sentiment Analysis\n  - Spelling Quality Check\n  - Grammar Check\n- [Running `describe()` on the new NLP Profiler generated dataframe](#describe-nlp-profiler)\n- [Generating a correlation matrix on the new NLP Profiler generated dataframe](#correlation-matrix-nlp-profiler)\n- [Finding the most and least correlated feature pairs](#finding-pairs)\n- [Correlated feature trees (groups)](#feature-trees)\n- [Applying Pandas Profiling on top of the generated features](#pandas-profiling)\n- [Notebooks\/Kernels: learn from existing implementations of NLP Profiler](#notebooks)\n- [Resources](#resources)\n- [Contribute to these](#contribute)","615b1570":"<a id='feature-trees'><\/a>\n\n----------\n\n### Correlated feature trees (groups)","58347de7":"<a id='import-libraries'><\/a>\n\n----------\n\n# Installation and import libraries\/packages","323956cc":"<a id='describe-nlp-profiler'><\/a>\n\n----------\n\n## Running `describe()` on the new NLP Profiler generated dataframe","84c3ea53":"<a id='contribute'><\/a>\n\n----------\n\n\n## Contribute to these\n\n- **NLP Profiler notebooks: [README](https:\/\/github.com\/neomatrix369\/nlp_profiler\/tree\/master\/notebooks#notebooks) | [Notebooks archive](https:\/\/github.com\/neomatrix369\/nlp_profiler\/releases\/download\/v0.0.3\/nlp_profiler_notebooks.zip)**\n- [NLP Profiler Library](https:\/\/github.com\/neomatrix369\/nlp_profiler\/) | [NLP Profiler on PyPi](https:\/\/pypi.org\/project\/nlp_profiler\/)\n- [Awesome AI-ML-DL: Better NLP library](https:\/\/bit.ly\/better-nlp-launch)\n- [Awesome AI-ML-DL Github](https:\/\/github.com\/neomatrix369\/awesome-ai-ml-dl\/blob\/)","e9af5986":"<a id='purpose'><\/a>\n\n----------\n\n## Purpose of NLP Profiler","23e37fd7":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","57ceb2bf":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","c58d78b2":"### Generating features","368f5c34":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","9eeb875b":"<a id='pandas-profiling'><\/a>\n\n----------\n\n## Applying Pandas Profiling on top of the generated features\n\nAs the `describe()` function only generates a small bit of information, and that we now have more metrics and features extracted out of our text, what better than applying Pandas Profiling on it. We are not doing an exhaustive analysis of the dataset, this one is just a basic analysis.","961b1e1f":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","004a6735":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","9ae8bde9":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","a5ef1c02":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","a9abc4c8":"### Grammar check\n\n#### The grammar check score and grammar check is supported by a third-party library.","9875df67":"<a id='demo'><\/a>\n\n----------\n\n## NLP Profiler Demo","b4cb7afe":"<a id='equivalent'><\/a>\n\n----------\n\n## NLP profiler's equivalent to that","b5e2ac1d":"### English and non-English characters, repeated letters, digits, spaces, whitespaces and punctuations counts","60731a50":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","e26a63a1":"<a id='resources'><\/a>\n\n----------\n\n## Resources\n\n- https:\/\/www.kaggle.com\/raenish\/cheatsheet-text-helper-functions\n- https:\/\/textblob.readthedocs.io\/en\/dev\/quickstart.html\n- [Words of estimative probability](https:\/\/en.wikipedia.org\/wiki\/Words_of_estimative_probability)\n- [Approaching (Almost) Any NLP Problem on Kaggle](https:\/\/www.kaggle.com\/abhishek\/approaching-almost-any-nlp-problem-on-kaggle)\n- **Jupyter Notebooks: [README](https:\/\/github.com\/neomatrix369\/nlp_profiler\/tree\/master\/notebooks#notebooks) | [Notebooks archive](https:\/\/github.com\/neomatrix369\/nlp_profiler\/releases\/download\/v0.0.3\/nlp_profiler_notebooks.zip)**\n- [Kaggle Utility script](https:\/\/www.kaggle.com\/neomatrix369\/nlp-profiler-class)\n- [NLP Profiler Library](https:\/\/github.com\/neomatrix369\/nlp_profiler\/) | [NLP Profiler on PyPi](https:\/\/pypi.org\/project\/nlp_profiler\/) | [Chat on gitter.im](https:\/\/gitter.im\/nlp_profiler\/community)\n- [Awesome AI-ML-DL: Better NLP library](https:\/\/bit.ly\/better-nlp-launch)\n- [Awesome AI-ML-DL: NLP Resources](https:\/\/github.com\/neomatrix369\/awesome-ai-ml-dl\/tree\/master\/natural-language-processing)\n- [Awesome AI-ML-DL Github](https:\/\/github.com\/neomatrix369\/awesome-ai-ml-dl\/blob\/)","e9375e60":"### I presented \"NLP Profiler\" at beginning of August 2020 at [#Abhishek](https:\/\/www.kaggle.com\/abhishek) Talks, see the [YouTube channel](https:\/\/www.youtube.com\/AbhishekThakurAbhi) and later on at NLP Zurich, see below for links to the video and the slides.\n\n### You can find my [talk here](https:\/\/www.youtube.com\/watch?v=sdPOyqMfK7M), where I also demo this nifty library I wrote in under 3 hours.\n\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https:\/\/youtu.be\/sdPOyqMfK7M?t=2274\"><img alt=\"Demo of the NLP Profiler library (Abhishek talks #6)\" src=https:\/\/user-images.githubusercontent.com\/1570917\/88474968-8fb48980-cf23-11ea-944d-0a1069174ede.png><\/a> or you find the rest of the <a href=https:\/\/www.youtube.com\/watch?v=sdPOyqMfK7M><b>talk here<\/b><\/a> or here for <a href=\"https:\/\/github.com\/neomatrix369\/awesome-ai-ml-dl\/blob\/master\/presentations\/awesome-ai-ml-dl\/02-abhishektalks-2020\/README.md\"><b>slides<\/b><\/a><\/td>\n<td>\n  <td align=\"center\"><a href=\"https:\/\/youtu.be\/wHIcQWeOugI?t=808\"><img alt=\"Demo of the NLP Profiler library (NLP Zurich talk)\" src=https:\/\/secure.meetupstatic.com\/photos\/event\/5\/7\/3\/highres_492541395.jpeg><\/a> or you find the rest of the <a href=https:\/\/www.youtube.com\/watch?v=wHIcQWeOugI><b>talk here<\/b><\/a> or here for <a href=\"https:\/\/github.com\/neomatrix369\/nlp_profiler\/blob\/master\/presentations\/01-nlp-zurich-2020\/README.md\"><b>slides<\/a><\/b><\/a><\/td>\n  \n  <\/tr>\n<\/table>\n\n","d59fe950":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","e0510cd4":"### Sentiment Analysis","dabd0e30":"<a id='dataset'><\/a>\n\n----------\n\n\n# Creating dataset","52cc9bb2":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","9d3dc8f4":"#### Text messages with Emojis, Numbers, Alphanumeric, None-alphanumeric, Punctuations, Dates and Duplicates","d8039049":"### Ease of Reading check\n\n#### The ease of reading check score and ease of reading  check is supported by a third-party library.","b5677024":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","c7057e3a":"<a href='#ToC'><span class=\"label label-info\" style=\"font-size: 125%\">Back to Table of Contents<\/span><\/a>","528d0eb1":"### Spelling quality check","be9a84fa":"<a id='finding-pairs'><\/a>\n\n----------\n\n## Finding the most and least correlated feature pairs\nHere we are trying to identify based on the statistical analysis of the features which pairs are most suitable to compare and go deeper into. As you can see from the correlation matrix above, it can get weildy and cumbersome to be able to separate the wheat from the chaff for an ever-growing list.","f972cad4":"### Go to these links to find the full source for the [Utility Script](https:\/\/www.kaggle.com\/neomatrix369\/nlp-profiler-class) and the [NLP profiler](https:\/\/github.com\/neomatrix369\/nlp_profiler\/).","a64a4a78":"#### The spelling score and spelling quality check is upto 70% accurate, it's using Peter Norvig\u2019s \u201cHow to Write a Spelling Corrector\".","0dee4ce0":"<a id='notebooks'><\/a>\n\n----------\n\n## Notebooks\/Kernels: learn from existing implementations of NLP Profiler\n\n- [CTDS: answering the \"what...\" question differently](https:\/\/www.kaggle.com\/neomatrix369\/ctds-answering-the-what-question-differently)\n- [ChaiEDA: Google Play Store Apps - review analysis](https:\/\/www.kaggle.com\/neomatrix369\/chaieda-google-play-store-apps-review-analysis\/)\n- [Approaching (Almost) Any NLP Problem on Kaggle](https:\/\/www.kaggle.com\/abhishek\/approaching-almost-any-nlp-problem-on-kaggle)\n- [Jupyter Notebook](https:\/\/github.com\/neomatrix369\/nlp_profiler\/blob\/master\/notebooks\/jupyter\/nlp_profiler.ipynb)\n- [Google colab](https:\/\/github.com\/neomatrix369\/nlp_profiler\/blob\/master\/notebooks\/google-colab\/nlp_profiler.ipynb)\n- [Jupyter Notebook (large dataset)](https:\/\/github.com\/neomatrix369\/nlp_profiler\/blob\/master\/notebooks\/jupyter\/nlp_profiler-large-dataset.ipynb)\n- [Notebook(s)\/Kernel(s) from supporters](https:\/\/github.com\/neomatrix369\/nlp_profiler\/blob\/master\/CREDITS_AND_SUPPORTERS.md#supporters-and-well-wishers)"}}