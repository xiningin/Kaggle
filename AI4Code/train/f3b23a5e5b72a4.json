{"cell_type":{"cabdf3eb":"code","3e267c0d":"code","e433a7c9":"code","54a892f3":"code","9709a926":"code","76d63fba":"code","22da91be":"code","fd07b62c":"code","0f8eaed4":"code","1ceb4083":"code","fec3d241":"code","c91bdfe6":"code","8477676a":"code","82ea5b4d":"code","4ddaf55f":"code","31d8905d":"code","38de3fd9":"code","6dbb5ff4":"code","4e772d1e":"code","841c29e2":"markdown","6f7bdd2d":"markdown","f833d444":"markdown","36e960ed":"markdown","4a38ed45":"markdown","fd7d95f0":"markdown","8bc30d0b":"markdown","0fb8b2be":"markdown","ac3be7b1":"markdown","5dc04b31":"markdown","86445a56":"markdown","639c3c09":"markdown","a8f9e3fd":"markdown"},"source":{"cabdf3eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3e267c0d":"pd.set_option('max.rows',900)\n\ndf=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf.set_index('PassengerId',inplace=True)\n\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest.set_index('PassengerId',inplace=True)","e433a7c9":"list_of_numerics=df.select_dtypes(include=['float','int']).columns\ntypes= df.dtypes\nmissing= round((df.isnull().sum()\/df.shape[0]),3)*100\noverview= df.apply(lambda x: [round(x.min()),round(x.max()),round(x.mean()),round(x.quantile(0.5))] if x.name in list_of_numerics else x.unique())\n\n\noutliers= df.apply(lambda x: sum(\n                                 (x<(x.quantile(0.25)-1.5*(x.quantile(0.75)-x.quantile(0.25))))|\n                                 (x>(x.quantile(0.75)+1.5*(x.quantile(0.75)-x.quantile(0.25))))\n                                 if x.name in list_of_numerics else ''))\n\n\nexplo = pd.DataFrame({'Types': types,\n                      'Missing%': missing,\n                      'Overview': overview,\n                      'Outliers': outliers}).sort_values(by=['Missing%','Types'],ascending=False)\nexplo.transpose()","54a892f3":"df.drop(['Cabin','Ticket'],axis=1,inplace=True)\ntest.drop(['Cabin','Ticket'],axis=1,inplace=True)","9709a926":"values=df.groupby(['Sex', 'Pclass'])['Age'].agg(['mean', 'median']).round(1)\nvalues","76d63fba":"filt=(df['Sex']=='female')&(df['Pclass']==1)&(df['Age'].isnull())\ndf.loc[filt,'Age']=35.0\n\nfilt=(df['Sex']=='female')&(df['Pclass']==2)&(df['Age'].isnull())\ndf.loc[filt,'Age']=28.0\n\nfilt=(df['Sex']=='female')&(df['Pclass']==3)&(df['Age'].isnull())\ndf.loc[filt,'Age']=22.0\n\nfilt=(df['Sex']=='male')&(df['Pclass']==1)&(df['Age'].isnull())\ndf.loc[filt,'Age']=40.0\n\nfilt=(df['Sex']=='male')&(df['Pclass']==2)&(df['Age'].isnull())\ndf.loc[filt,'Age']=30.0\n\nfilt=(df['Sex']=='male')&(df['Pclass']==3)&(df['Age'].isnull())\ndf.loc[filt,'Age']=25.0\n\ndf['Embarked'].replace({np.nan:'S'},inplace=True) ##(mode of df['Embarked'] comes out to be S, can be found out by df['Embarked'].mode())\n","22da91be":"values=test.groupby(['Sex', 'Pclass'])['Age'].agg(['mean', 'median']).round(1)\nvalues","fd07b62c":"filt=(test['Sex']=='female')&(test['Pclass']==1)&(test['Age'].isnull())\ntest.loc[filt,'Age']=41.0\n\nfilt=(test['Sex']=='female')&(test['Pclass']==2)&(test['Age'].isnull())\ntest.loc[filt,'Age']=24.0\n\nfilt=(test['Sex']=='female')&(test['Pclass']==3)&(test['Age'].isnull())\ntest.loc[filt,'Age']=22.0\n\nfilt=(test['Sex']=='male')&(test['Pclass']==1)&(test['Age'].isnull())\ntest.loc[filt,'Age']=42.0\n\nfilt=(test['Sex']=='male')&(test['Pclass']==2)&(test['Age'].isnull())\ntest.loc[filt,'Age']=28.0\n\nfilt=(test['Sex']=='male')&(test['Pclass']==3)&(test['Age'].isnull())\ntest.loc[filt,'Age']=24.0\n\ntest['Fare'].replace({np.nan:test['Fare'].median()},inplace=True)\n","0f8eaed4":"ticket_fare=test.groupby(['Pclass'])['Fare'].agg(['mean', 'median']).round(1)\nticket_fare","1ceb4083":"filt=(test['Pclass']==1)&(test['Fare'].isnull())\ntest.loc[filt,'Fare']=94.3\n\nfilt=(test['Pclass']==2)&(test['Fare'].isnull())\ntest.loc[filt,'Fare']=22.2\n\nfilt=(test['Pclass']==3)&(test['Fare'].isnull())\ntest.loc[filt,'Fare']=12.5","fec3d241":"fig, axarr = plt.subplots(1,2,figsize=(12,6))\na = sns.countplot(df['SibSp'], ax=axarr[0]).set_title('Passengers count by SibSp')\n\nb = sns.barplot(x='SibSp', y='Survived', data=df, ax=axarr[1]).set_ylabel('Survival rate')\naxarr[1].set_title('Survival rate by SibSp')","c91bdfe6":"fig, axarr = plt.subplots(1,2,figsize=(12,6))\na = sns.countplot(df['Parch'], ax=axarr[0]).set_title('Passengers count by Parch')\naxarr[1].set_title('Survival rate by Parch')\nb = sns.barplot(x='Parch', y='Survived', data=df, ax=axarr[1]).set_ylabel('Survival rate')","8477676a":"plt.figure(figsize=(20,20))\nsns.heatmap(data=df.corr(),xticklabels=True,yticklabels=True,cbar=True,linecolor='white',annot=True)","82ea5b4d":"df['Fam_size'] = df['SibSp'] + df['Parch'] + 1\ntest['Fam_size'] = test['SibSp'] + test['Parch'] + 1\n\ndf['Fam_type'] = pd.cut(df.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\ntest['Fam_type'] = pd.cut(test.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\n","4ddaf55f":"df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntest['Title'] = test['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n\ndf['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntest['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n\ndf['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\ntest['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\n\n##drop the features as we have created new features in place\ndf.drop(['SibSp','Parch','Fam_size','Name'],axis=1,inplace=True)\ntest.drop(['SibSp','Parch','Fam_size','Name'],axis=1,inplace=True)\n\ndf.head()","31d8905d":"df=pd.get_dummies(df)\ntest=pd.get_dummies(test)\n\n\"\"\"\nSeperating the train data into X and y\n\n\"\"\"\nX=df.drop('Survived',axis=1)\ny=df['Survived']","38de3fd9":"from sklearn.ensemble import GradientBoostingClassifier\n\nclf=GradientBoostingClassifier(random_state=0,max_features='auto')\n\n\nclf.fit(xtrain,ytrain)\nprobabilities=clf.predict_proba(X)\nimportance=list(zip(X.columns,clf.feature_importances_))\n\nprint('accuracy'+' '+'='+' '+str(clf.score(X,y)\n))\nprint()\nprint(\"Feature Importances:-\")\nprint()\nprint(importance)","6dbb5ff4":"from sklearn.metrics import roc_curve\n\nfpr1,tpr1,thresholds1=roc_curve(y,probabilities[:,1])\n\nplt.figure(figsize=(8,8))\nsns.lineplot(y=tpr1,x=fpr1,ci=None)","4e772d1e":"pred=clf1.predict(test)\nId=test.index\nfinal_sub=pd.Series(data=pred,index=Id,name='Survived')\nfinal_sub.to_csv('final_sub1.csv')\nfinal_sub.head()","841c29e2":"**Coming to the SibSp and Parch columns, SibSp is the number of siblings or spouses of a person aboard the Titanic**\n\n**We see that more than 90% of people traveled alone or with one sibling or spouse.\nThe survival rate between the different categories is a bit confusing but we see that the chances of surviving are lower for those who traveled alone or with more than 2 siblings.\nFurthermore, we notice that no one from a big family with 5 or 8 siblings was able to survive.**\n","6f7bdd2d":"# Feature Engineering","f833d444":"**Read the file in a dataframe**\n\n\n**Set the PassengerId as index**","36e960ed":"**From the above heatmap it seems that Pclass 1 people had a better chnace on survival due to the negative correlation**\n\n**SibSp and Parch columns dont have much effect on the expectation of survival and it would be good to combine these features to produce a new feature**","4a38ed45":"**To fill the missing values in the age column I have calculated the mean and median ages of male and female for each Pclass seperately as shown in the table above**\n\n**Pclass groups people on how much they paid for the ticket and hence it is obvious that the median and mean ages of people in these classes will be different as the earnings of people increases with age and is maximum at 40-50 years**\n\n**Pclass 1 people earn the lowest wages and hence it is evident that their age should be around 22-27 years old**\n\n**For embarked column we fill the missing value with the most frequent embarking place since I don't expect that a passenger's boarding point could change the chance of surviving**","fd7d95f0":"# Model Building","8bc30d0b":" **The column Cabin contains a lot of missing values hence its better to drop the column as a whole, furthermore we cannot fill these values by any statistically calculated value as it is different for each family**\n\n**Same goes for ticket each and every person will have a unique ticket and hence does not provide a good estimate as to whether a person survived or not**","0fb8b2be":" **The Name column contains useful information as for example we could identify family groups using surnames.\nIn this notebook, however, I extracted only the passengers' title from it, creating a new feature for both train and test data.**","ac3be7b1":"**Since PClass denotes the economic status of the person it is clear that their ticket prices will also be different**","5dc04b31":"# Feature preprocessing","86445a56":"**The below code section is just an analysis of the features in the dataset**\n**We have calculated the percentage of missing values in in each column**\n**Number of outliers in each column**\n\n**Note:- Outliers can be detected if they lie 1.5 times the interquartile range below the 25th percentile and 1.5 times the**                **interquartile range above the 75th percentile**","639c3c09":"**Since we have two seemingly weak predictors, one thing we can do is combine them to get a stronger one.**\n\n**In the case of SibSp and Parch, we can join the two variables to get a family size feature, which is the sum of SibSp, Parch and 1 (who is the passenger himself).**\n\n**We can also group these family sizes into different groups based on their size-{Solo,Small,Big,Very Big}","a8f9e3fd":"**Similar to the SibSp, the Parch feature contains the number of parents or children each passenger was traveling with.**\n\n**Here we draw the same conclusions as SibSp: we see again that small families had more chance to survive than bigger ones as well as from passengers who traveled alone.**"}}