{"cell_type":{"8696bdb9":"code","7599a91c":"code","ed15d18d":"code","4e28a7f1":"code","3090d575":"code","65ee2321":"code","8091257b":"code","477ae53e":"code","36a2263d":"code","e87a6684":"code","a863ff50":"code","3f89dbe9":"code","ea15d99d":"code","3822fb16":"code","07151fdf":"code","e85e3f8b":"code","75959bb2":"code","34019397":"code","00db0cc3":"code","f6869e0c":"code","2a786b29":"code","9f6cb2f6":"code","9711343b":"code","4e43aafd":"code","0f89fb81":"code","3e67860a":"code","c7997bdc":"code","04554132":"code","f817e203":"code","0e5f7946":"code","5f50d4f1":"code","02b4e0d8":"code","b4c5dd1c":"code","16f25a0c":"code","b6499c3c":"code","9bc648c4":"code","43ec5dbd":"code","77ca93bf":"code","af55e780":"code","5a208281":"code","2634f1e8":"code","4be3a184":"code","b4b181f9":"code","932012c2":"code","6ab2f14c":"code","8a8495d7":"code","d0a34010":"code","efa2d3f2":"code","5530e72d":"code","5d0def21":"code","76637916":"code","c1e95342":"code","1a4b7a54":"code","8b8946cb":"code","67239d17":"code","af40dd42":"code","82f4a526":"code","1314fe62":"code","d841fdf3":"code","3cfa8bf3":"code","33650f9e":"code","8aedb5e6":"code","e2e56d05":"code","4b21564a":"code","329af5a5":"code","d456c3d6":"code","3f532ef2":"code","0045f4f2":"code","fb343c60":"code","e3931c26":"code","55ad634e":"code","9d207fa4":"code","058a423b":"code","6dbde049":"code","a53d9b7c":"code","71ad7b78":"code","4a6e7d3d":"code","05c34b49":"code","acef3a79":"code","ba8fedb4":"code","4f9ab72f":"code","127b87a0":"code","ba68f6b8":"code","e20b82d3":"code","ea68b0b4":"code","afe7f19f":"code","841e4349":"code","4bb08ec2":"code","05fc020d":"code","e18c0798":"code","993c4efd":"code","fad45f21":"code","327e4e2a":"code","0cfc1d37":"code","5ef3ca12":"code","1329ab5e":"code","36f8b742":"code","4c07e501":"code","56db3f5a":"code","c1489f34":"code","79b51454":"code","b995a51e":"code","a73cd791":"code","f23a1c29":"code","5e5ca3d2":"code","4d263a70":"code","62cbb320":"markdown","d4225ba8":"markdown","ee261f92":"markdown","6f2affba":"markdown","34c3510f":"markdown","c25794ae":"markdown","6024dab1":"markdown","11027365":"markdown","b36ad529":"markdown","9d79ea75":"markdown","dcb64011":"markdown","dfb0a638":"markdown","3cee1215":"markdown","5ff95fef":"markdown","aa736a7a":"markdown","5dcd8949":"markdown","5aa59388":"markdown","f6abe634":"markdown","4136f6ec":"markdown","73152fd6":"markdown","dfcf7ddd":"markdown","00e3c4c4":"markdown","b6de7499":"markdown","47f9e7c7":"markdown","901666bc":"markdown","d8fc046c":"markdown","7b086485":"markdown","ca273dfb":"markdown","0fb0851d":"markdown","d939ca9a":"markdown","4d9eb13a":"markdown","f9686193":"markdown","2f3c1ac6":"markdown","a146ff50":"markdown","7bda817b":"markdown","a8e4c74a":"markdown","c0ef3f08":"markdown"},"source":{"8696bdb9":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n","7599a91c":"data = pd.read_csv(\"..\/input\/data.csv\")\ndata.info()","ed15d18d":"data.corr()","4e28a7f1":"f,ax = plt.subplots(figsize=(32, 32))\nsns.heatmap(data.corr(), annot = True, linewidths=1.5 , fmt = '.2f',ax=ax)\nplt.show()","3090d575":"data.head(20)","65ee2321":"data.fractal_dimension_mean.plot(kind=\"line\", color = \"r\", label=\"fractal_dimension_mean\", linewidth= 1, alpha = 0.5, grid = True,linestyle = \"-\")\ndata.radius_mean.plot(color =\"b\", label = \"radius_mean\",linewidth=1,alpha=0.5,grid=True,linestyle=\":\")\nplt.legend()\nplt.xlabel(\"fractal_dimension_mean\")\nplt.ylabel(\"radius_mean\")\nplt.title(\"Line Plot\")\nplt.show()","8091257b":"#Scatter Plot\n#x = smoothness_se\n#y = radius_se\ndata.plot(kind=\"scatter\", x = \"smoothness_se\", y = \"radius_se\",alpha=0.7,color=\"green\")\nplt.xlabel(\"smoothness_se\")\nplt.ylabel(\"radius_se\")\nplt.title(\"Smoothness Radius Scatter Plot\")\n","477ae53e":"#Histogram\n#bins = number of bar in figure\ndata.texture_worst.plot(kind =\"hist\",bins = 40,figsize=(13,13))\nplt.show()\n                        ","36a2263d":"#clf() = cleans it up again you can start a fresh\ndata.texture_worst.plot(kind=\"hist\",bins= 30)\nplt.clf()","e87a6684":"#create dictionary and look its keys and values\n\ndictionary = {'spain':'madrid','england':'london'}\nprint(dictionary.keys())\nprint(dictionary.values())","a863ff50":"#Keys have to be imutable object like string, boolean, float, integer or tubles\n#list is not immutable\n#keys are unique\ndictionary['spain'] = \"barcelona\" #update existing entry\nprint(dictionary)\ndictionary['german'] = \"berlin\" # add new entry\nprint(dictionary)\ndel dictionary['spain']     # remove entry with key 'spain'\nprint(dictionary)\nprint('german' in dictionary)  #check include or not\ndictionary.clear()            #remove all entries in dict\nprint(dictionary)","3f89dbe9":"#In order to run all code you need to take comment this line\n#del dictionary      # delete entire dictionary\nprint(dictionary)  #it gives error because dictionary is deleted\n","ea15d99d":"data = pd.read_csv('..\/input\/data.csv')","3822fb16":"series = data['perimeter_mean']  #data['perimeter_mean'] = series\nprint(type(series))\ndata_frame = data[['perimeter_mean']] #data[['perimeter_mean']] = data frame\nprint(type(data_frame))","07151fdf":"# Comparisonoperator\n\nprint(3>2)\nprint(3!=2)\n#boolean operators\nprint(True and False)\nprint( not False)\nprint(True or False)\n","e85e3f8b":"# 1 - Filtering Pandas data frame\nx = data['perimeter_mean']>150 # there are only 13 results who higher perimeter_mean value than 150\ndata[x]","75959bb2":"#2 - Filtering pandas with logical_and\n#there are only 5 results who have higher perimeter_mean value than 150 and higher radius_mean value than 25\n\ndata[np.logical_and(data['perimeter_mean']>150,data['radius_mean']>25)]","34019397":"# This is also same with previous code line. Therefore wecanalso use '&' for filtering\ndata[(data['perimeter_mean']> 150) & (data['radius_mean']> 25)]","00db0cc3":"#stay in loop if condition(i is not equal 5) is true\ni=0\nwhile i != 5:\n    print('i is: ', i)\n    i +=1\nprint(i,' is equal to 5')","f6869e0c":"#stay in loop if condition(i is not equal 5)is true\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ', i)\nprint('')\n\n#Enumerate indexand value of list\n#index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')\n\n#for dictionaries\n# we can use for loop to achive key and value of dictionary. We learn key and value at dictionary part.\n\ndictionary = {'spain':'madrid','france':'paris','turkey':'ankara'}\nfor key,value in dictionary.items():\n    print(key, \" : \",value)\nprint('')\n\n#for pandas we can achieve index and value\nfor index,value in data[['radius_mean']][0:3].iterrows():\n    print(index,\" : \",value)","2a786b29":"#example of what learn above\ndef tuble_ex():\n    \"\"\"return defined t tuble\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)","9f6cb2f6":"#guess print what\n\nx=2\ndef f():\n    x = 3\n    y=2*x  # there is no local scope\n    return y\nprint(x) # x= 2 global scope\nprint(f())   #it uses global scope x=3 local scope\n#First local scope searched , if two of them cannot be found lastly duilt in scope searched.","9711343b":"# how can we learn what is luilt in scope\nimport builtins\ndir(builtins)","4e43aafd":"def square():\n    \"\"\"return square of value\"\"\"\n    def add():\n        \"\"\"add two local variable\"\"\"\n        x=2\n        y=3\n        z = x + y\n        return z\n    return add()**2\nprint(square())","0f89fb81":"# default arguments\n\ndef f (a, b = 1, c = 2):\n    y = a + b + c\n    return y\n\nprint(f(5))# what if we want to change default arguments\nprint(f(5,4,3))","3e67860a":"# flexible arguments *arg\ndef f(*args):\n    for i in args:\n        print(i)\n        \nf(1)\nprint(\"\")\nprint(1,2,3,4,5,6,7,8)\n\n#flexible arguments **kwargs that is dictionary\n\ndef f(**kwargs):\n    \"\"\"print key and value of dictionary\"\"\"\n    for key,value in kwargs.items():\n        print(key,\" \",value)\n        \nf(country = \"spain\", capital = \"madrid\", population = 123765)","c7997bdc":"# lambda function\nsquare = lambda x: x**3 # where x is name of argument\nprint(square(5))\ntot = lambda x,y,z : x*y\/z # whre x,y,z are names of arguments\nprint(tot(4,5,8))","04554132":"number_list = [1,2,3,4,5,6,7]\ny = map(lambda x:x+x**2,number_list)\nprint(type(y))\nprint(list(y))","f817e203":"#iteration example\nname = \"Semih\"\nit = iter(name)\nprint(next(it)) # print next iteration\nprint(*it) # print remaining iteration","0e5f7946":"#zip example\nlist1 = [1,2,3,4,5,6,7]\nlist2 = [8,9,10,11,12,13,14]\nz = zip(list1,list2)\nprint(type(z))\nprint(z)\nz_list = list(z)\nprint(z_list)","5f50d4f1":"un_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip) # unzip returns tuble\nprint(un_list1)\nprint(un_list2)\nprint(un_zip)\nprint(type(un_list1))","02b4e0d8":"num1 = [1,2,3]\nnum2 = [i+1 for i in num1]\nprint(num2)","b4c5dd1c":"# Conditionals on iterable\nnum1 = [5,10,20]\nnum2 = [i**2 if i == 20 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)","16f25a0c":"#lets return our csv and make on more list comprehension example\nsum_radius_mean = sum(data.radius_mean)\/len(data.radius_mean)\nprint(sum_radius_mean)\ndata[\"radius_mean_level\"] = [\"high\" if i > sum_radius_mean else \"low\" for i in data.radius_mean]\ndata.loc[:20,[\"radius_mean_level\",\"radius_mean\"]] ","b6499c3c":"data = pd.read_csv('..\/input\/data.csv')\ndata.head() # head shows first 5 rows","9bc648c4":"data.tail() # tail shows last 5 rows","43ec5dbd":"data.columns # columns gives column names of features","77ca93bf":"data.shape #shape give number of rows and columns in a tuble","af55e780":"data.info() # info gives data type like dataframe, number of sample or row, number offeature or column, feature types and memory usage","5a208281":"print(data.diagnosis.value_counts(dropna=False)) # if there are nan values that also be counted\n#as it can be seen below there are 357 B feature and 212 M feature\n","2634f1e8":"data.describe()\n#For example max smoothness_mean is 0.1634 and average of texture_mean is 19.289649","4be3a184":"#Black line at top is max\n#Blue line at top is 75%\n#Red line is median(50%)\n#Blue line is bottom is 25%\n#Black line at bottom is min\n#there are no outliers\ndata.boxplot(column='perimeter_worst',by ='diagnosis')\n","b4b181f9":"#Firstly I create new data to explain melt more easily.\ndata_new = data.head()  # I only take 5 rows into new data\ndata_new","932012c2":"#lets melt\n#id_vars = what we do not wish to melt\n#value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars='id',value_vars=['compactness_mean','radius_se'])\nmelted","6ab2f14c":"#Index is name\n# I want to make that columns are variable\n#finally values in columns are value\nmelted.pivot(index='id',columns='variable',values='value')","8a8495d7":"#Firstly lets create 2 data frame\ndata1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis=0, ignore_index=True) # axis=0 : adds dataframes in row\nconc_data_row","d0a34010":"data1 = data.radius_mean.head()\ndata2 = data['area_mean'].head()\nconc_data_col = pd.concat([data1,data2],axis=1) # axis = 1 : adds dataframes in column\nconc_data_col","efa2d3f2":"data.dtypes\n","5530e72d":"#lets convert object(str) to categorical an int to float\ndata.diagnosis = data['diagnosis'].astype('category')\ndata['symmetry_worst'] = data.symmetry_worst.astype('int')","5d0def21":"data.dtypes","76637916":"# Lets look at does this data have nan value\n#As you can see there are 600 entries but we do not have nan value\ndata.info()","c1e95342":"data.diagnosis.value_counts(dropna=False)","1a4b7a54":"#lets drop nan values\n#for example area_worst column have nan values\n#data.area_worst.dropna(inplace = True) #incplace = True means we do not assing it to new variable.Changes automatically assigned to do","8b8946cb":"#lets check with assert statement\n#Assert statement:\nassert 1==1 #return nothing because it is true","67239d17":"assert 2==3 # return error because it is false","af40dd42":"assert data.diagnosis.notnull().all() # returns nothing because we do not have nan values","82f4a526":"#data.diagnosis.fillna('empty',inplace=True) # returns error because we do not have nan values","1314fe62":"# With assert statement we can check a lot of thing.For Example\n#assert data.columns[2] == 'Name'\n#assert data.area_se.dtypes == np.int","d841fdf3":"#data frame from dictionary\ncountry = [\"Germany\",\"France\",\"Turkey\"]\npopulation = [\"15\",\"17\",\"43\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","3cfa8bf3":"#Add new columns\ndf[\"capital\"] = [\"Berlin\",\"Paris\",\"Ankara\"]\ndf","33650f9e":"#Broadcasting\ndf[\"income\"] = 0 #broadcasting enrite column\ndf","8aedb5e6":"#plotting all data\ndata1 = data.loc[:,[\"texture_se\",\"compactness_se\",\"symmetry_se\"]]\ndata1.plot()\nplt.show() # it is confusing","e2e56d05":"#subplot\ndata1.plot(subplots= True)\nplt.show()","4b21564a":"#scatter plot\ndata1.plot(kind=\"scatter\",x='texture_se',y='symmetry_se')\nplt.show()","329af5a5":"#histogram plot\ndata1.plot(kind='hist',y='texture_se',bins=50,range=(0,300),normed= True) # do not work normed because it is already normed","d456c3d6":"#histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind='hist',y = 'texture_se',bins=50,range=(0,500),ax = axes[0])\ndata1.plot(kind='hist',y ='texture_se',bins=50,range=(0,500),ax=axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","3f532ef2":"data.describe()","0045f4f2":"time_list = ['1992-03-08','1992-06-15']\nprint(type(time_list[1])) #as you can see date is string\n#however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","fb343c60":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#In order to practice lets take head of data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2['date'] = datetime_object\ndata2 = data2.set_index(\"date\")\ndata2","e3931c26":"#Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","55ad634e":"#we will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","9d207fa4":"#lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","058a423b":"# In real life(data is real. Not created from us like data2) we can solve this problem with interpolete\n#we can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","6dbde049":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","a53d9b7c":"#read data\n\ndata = pd.read_csv(\"..\/input\/data.csv\")\ndata = data.set_index('id')\ndata.head()","71ad7b78":"#indexing using square brackets\ndata.radius_mean[842302] #841302 we use because we setted index id","4a6e7d3d":"data[\"radius_mean\"][842302]","05c34b49":"data.loc[842302,[\"radius_mean\"]]","acef3a79":"#selecting only some columns\ndata[[\"area_mean\",\"compactness_mean\"]]","ba8fedb4":"#Difference betwenn selecting columns: series and dataframes\nprint(type(data[\"compactness_mean\"]))\nprint(type(data[[\"compactness_mean\"]]))","4f9ab72f":"#Slicing and indexinfg series\n\ndata.loc[:846226,\"compactness_mean\":\"concave points_mean\"]","127b87a0":"#Reverse slicing\n\ndata.loc[846226:843786:-1,\"compactness_mean\":\"concave points_mean\"]","ba68f6b8":"#From something to end\n\ndata.loc[:846226,\"compactness_worst\":]","e20b82d3":"#Creating boolean series\n\nboolean = data.concavity_worst > 1\ndata[boolean]","ea68b0b4":"#Combining filters\nfirst_filter = data.concavity_worst > 1\nsecond_filter = data.area_worst > 500\ndata[first_filter & second_filter]","afe7f19f":"#Filtering column based others\ndata.area_worst[data.concavity_worst > 1]","841e4349":"# Plain python functions\n\ndef div(n):\n    return n\/2\ndata.radius_mean.apply(div)","4bb08ec2":"#or we can use lambda function\ndata.radius_mean.apply(lambda n: n\/2)","05fc020d":"#Defining column using other columns\ndata[\"total_radius_mean_and_radius_worst\"] = data.radius_mean+data.radius_worst\ndata.head()","e18c0798":"# our index name is this:\nprint(data.index.name)\n#lets change it\ndata.index.name =  \"index_name\"\ndata.head()","993c4efd":"#Overwrite index\n#if we want to modify index we need to change all of them\ndata.head()\n#first copy of our data to data3 then change index\ndata3 = data.copy()\n#lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,669,1)\ndata3.head()","fad45f21":"#lets read data frame one more time to start from beginning\ndata = pd.read_csv(\"..\/input\/data.csv\")\ndata.head()","327e4e2a":"#setting index : perimeter_mean is outer diagnosis is inner index\ndata1 = data.set_index([\"perimeter_mean\",\"diagnosis\"])\ndata1.head(50)","0cfc1d37":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","5ef3ca12":"#pivoting\ndf.pivot(index=\"treatment\",columns=\"gender\",values=\"response\")","1329ab5e":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n#lets unstack it","36f8b742":"#level determines indexing\ndf1.unstack(level=0)","4c07e501":"df1.unstack(level=1)","56db3f5a":"#change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","c1489f34":"df","79b51454":"#df.pivot(index=\"treatment\",columns=\"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","b995a51e":"#We will use df\ndf","a73cd791":"#according to treatment take means of other features\ndf.groupby(\"treatment\").mean() #mean is aggregation \/ reduction method\n#there are other methods like sum,std, max or min","f23a1c29":"#we can only choose one of the feature\ndf.groupby(\"treatment\").age.max()","5e5ca3d2":"#or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min()","4d263a70":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","62cbb320":"Before continue with pandas, we need to learn** logic, control flow and filtering**.\nComparison operator: ==,<,>,>=\nBoolean operators : and,or,not\nFiltering pandas\n","d4225ba8":"**HIERARCHICAL INDEXING**\n    setting indexing","ee261f92":"PANDAS\nwhat we need to know about pandas?\nCSV : comma - separated values(virg\u00fclle ayr\u0131lm\u0131\u015f de\u011ferler)\n","6f2affba":"**STATISTICAL EXPLORATORY DATA ANALYSIS**\n\ncount: number of entries\nmean: average of entries\nstd: standart deviation\nmin: minimum entry\n25%: first quantile\n50%: median or second quantile\n75%: third quantile\nmax: maximum entry","34c3510f":"**VISUAL EXPLORATORY DATA ANALYSIS**\nBoxplot : visualize basic statistics like outliner, min\/max or quantiles","c25794ae":"**PANDAS FOUNDATION**\n\n\n**BUILDING DATA FRAMES FROM SCRATCH**\n\n    We can build data frames from csv as we did earlier.\n    Also we can build dataframe from dictionaries\n         zip() method : This function returns a list of tuples, where the i-th tuple contains thei-th element from each of the argument sequences or iterables.\n    Adding new columns\n    Broadcasting : Create new column and assing a value to entire column","6024dab1":"**NESTED FUNCTION**\n\nfunction inside function.\n\nThere is a LEGB rule that is search local scope, enclosing function, global and built in scopes,respectively.","11027365":"**ANONYMOUS FUNCTION**\nLike lambda function but it can take more than one arguments.\n\n map(func,seq) : applies a function to all the items in a list","b36ad529":"**CATEGORICALS AND GROUPBY**","9d79ea75":"**INDEX OBJECTS AND LABELED DATA**\nindex : sequence of label","dcb64011":"**LIST COMPREHENSION**\n\nOne of the most important topic of this kernel\nwe use list comprehension for data analysis often\nlist comprehension : collapse for loop for building lists into a single line\nex: num1 = [1,2,3] and we want to make it num2  = [2,3,4]. This can be done with for loop. However it is unnecessarily long.\nWe can make it one line code that is list comprehension.","dfb0a638":"**INDEXING PANDAS TIME SERIES**\n\nDatetime = object\nparse_dates(boolean) : Transform date to ISO 8601(yyyy-mm-dd hh:mm:ss) format\n","3cee1215":"**USER DEFINED FUNCTION**\nwhat we need to know about functions:\ndocstring: documentation for function. Example:\nfor f():\n\"\"\"This is docstring for documention of function\"\"\"\ntuble: sequence of immutable python objects.\ncan't modify values\ntuble uses paranthesis like tuble = (1,2,3)\nunpack tuble into several varitables like a,b,c = tuble","5ff95fef":"**CLEANING DATA**\n\n**DIAGNOSE DATA and CLEANING**\n\nWe need to diagnose and clean data before exploring\nUnclean data:\n\nColumn name inconsistency like upper-lower case letter or space between words. Ex: \"Radius_mean\" and \"raduis mean\" \nMissing data \nDifferent language\n\nWe will use head, tail, columns, shape and info methods to diagnose data","aa736a7a":"Dictionary\n\nWhy we need dictinory?\n\nIt's has 'key'  and 'value'\nfaster than lists\ndictionary = {'spain':'madrid'}\nKey is spain\nvalue is madrid\n\n\n","5dcd8949":"**MELTING DATA FRAMES**\nReverse of pivoting","5aa59388":"In this part,we learn:\nhow to import csv file\nplotting line,scatter and histogram\nbasic dictionary features\nbasicpandas features like filtering that is  actually something always used and main for being data secientist\nwhile and for loops","f6abe634":"  **STACKING and UNSTACKING DATAFRAME**\n  deal with multi label indexing\n  level : position of unstacked index\n  swaplevel: change inner and outer level index position","4136f6ec":"**MANIPULATING DATA FRAMES WITH PANDAS**\n\n**INDEXING DATA FRAMES**\n\nIndexing using square brackets\nUsing column attribute and row label\nUsing loc accessor\nSelecting only some columns","73152fd6":"**RESAMPLING PANDAS TIME SERIES**\n\nResampling: statistical method over different time intervals\n        Needs string to specify frequency like \"M\" = month or \"A\" = year\nDownsampling: reduce date time rows to slower frequency like from daily to weekly\nUpsampling: increase date time rows to faster frequency like from daily to hourly\nInterpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019\n        https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html","dfcf7ddd":"**FILTERING DATA FRAMES**\nCreating boolean series Combining filters Filtering column based others\n","00e3c4c4":"**VISUAL EXPLORATORY DATA ANALYSIS**\nPlot\nsubplot\nhistogram:\n    bins: number of bins\n    range(tuble): min and max values of bins\n    normed(boolean): normalize or not\n    cumulative(boolean):compute cumulative distribution","b6de7499":"**EXPLORATORY DATA ANALYSIS(EDA)**\n\nvalue_counts():  Frequency  counts\noutliers : the value that is considerably higher or lower from rest of the data\n\nLets say value at 75% is Q3 and value at 25% is Q1\n    Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3+1.5(Q3-Q1)      (Q3-Q1) = IQR\nWe will use describe() method.Describe method includes:\ncount: number of entries\nmean: average of entries\nstd: standart deviation\nmin: minimum entry\n25%: first quantile\n50%: median or second quantile\n75%: thirdquantile\nmax: maximum entry\n\nWhat is quantile?\n\n1,4,5,6,8,9,11,12,13,14,15,16,17\nThe median is the number that is in middle of sequence. In this case it would be 11.\nThe lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11,which is 6.\nThe upper quartile , you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","47f9e7c7":"**ITERATORS**\n* iterable is an object that can return an iterator\n* iterable : an object with an associated iter() method \n  example : list, string and dictionaries\n* iterator: produces next value with next() method\n ","901666bc":"**CONCATENATING DATA**\nWe can concatenate two dataframe","d8fc046c":"**SLICING DATA FRAME**\n\nDifference between selecting columns\n        Series and data frame\nSlicing and indexing series\nReverse slicing\nFrom something to end","7b086485":"**PIVOTING DATA**\nReverse of melting\n","ca273dfb":"**DATA TYPES**\nThere are 5 basic data types : object(string),boolean,integer,float and categorical.\nWe can make conversion data types like from str to categorical or from int to float\nWhy is category important:\nmake dataframe smaller in memory\ncan be utilized for analysis especially for sklearn\n","0fb0851d":"**MISSING DATA AND TESTING WITH ASSERT**\nIf we encounter with missing data,what we can do:\nleave as is\ndrop them with dropna()\nfill missing value with fillna()\nfill missing values with test statistics like mean\n    Assert statement : check that you can turn on and turn off when you are done with your testing of the program","d939ca9a":"zip(): zip lists","4d9eb13a":"**DEFAULT and FLEXIBLE ARGUMENTS**\n\nDefault argument example:\ndef f(a,b=1):\n        \"\"\" b = 1 is default argument \"\"\"\n        \nFlexible argument example:\ndef f(*args):\n        \"\"\" *args can be one or more\"\"\"\n        \n def f(** kwargs)\n         \"\"\" **kwargs is a dictionary \"\"\"\n         \n         \nlets write some code to practice\n\n","f9686193":"**LAMBDA FUNCTION**\n\nFaster way of writing function","2f3c1ac6":"**TIDY DATA**\nWe tidy data with melt(). Describing melt is confusing. therefore let make example to understand it","a146ff50":"**WHILE and For LOOPS**\n\nWe will learn most bas\u0131c while and for loops","7bda817b":"**PIVOTING DATA FRAMES**\npivoting : reshape tool","a8e4c74a":"**SCOPE**\nWhat we need to know about scope:\nglobal : defined main body in script\nlocal : defined in a function\nbuilt in scope : names in predefined built in scope module such as print, len\n\nLets make some basic example","c0ef3f08":"**TRANSFORMATING DATA**\n\nPlain python functions\nLambda function : to apply arbitrary python function to every elemnt\nDefinin column using other columns"}}