{"cell_type":{"3da5d905":"code","e5ee0fc6":"code","4054feb9":"code","6f9ee545":"code","ea43b1ff":"code","029275a8":"code","81e0b731":"code","eaf4d357":"code","83f8cbb5":"code","af498c15":"code","6be45f05":"code","a769efec":"code","7f0bf42a":"code","0e6ad562":"code","f3c88372":"code","318b65a3":"code","b39d08cf":"code","fdd2d954":"code","ba7eaa08":"code","47863ec3":"code","97ab203c":"code","249bd33b":"code","0b01db5d":"code","8288a815":"code","60054aa3":"code","bb2a3e0f":"code","a431bb1b":"code","243630aa":"code","e0a9a988":"code","02d09259":"code","08f467cb":"code","2cd04c2b":"code","81dc4a16":"code","4316decf":"code","6e55e815":"code","f3eb1054":"code","8001c015":"code","b2438899":"code","518ac763":"code","c1c46d8f":"code","2c45b105":"code","6d16dbc8":"markdown","0316ea5b":"markdown","241613bc":"markdown","67f1d4bc":"markdown","c006b480":"markdown","83d26310":"markdown","ac93a6a2":"markdown","4dfb3481":"markdown","5a5de9e4":"markdown","9110175a":"markdown","af9c6271":"markdown","194da8f0":"markdown","de9bd56d":"markdown","a8d28021":"markdown","a3b285b7":"markdown","fcf1cf65":"markdown","6b6dbf60":"markdown","4994e6e5":"markdown","dac6e1d5":"markdown","c33810d4":"markdown","08782220":"markdown","4448d4b9":"markdown","7663983c":"markdown","91ac5a9a":"markdown","ed16348d":"markdown","079828b2":"markdown","5d763a52":"markdown","4011b20c":"markdown","6a0fccf7":"markdown","0e64d26f":"markdown","b84bde3f":"markdown","48a66c81":"markdown","463054da":"markdown","ab7a83cb":"markdown","42404106":"markdown","0db5cae5":"markdown","60d20f45":"markdown"},"source":{"3da5d905":"\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\ndata = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndata.head()\n","e5ee0fc6":"data.columns","4054feb9":"data.info()","6f9ee545":"count_null = 0\nindices = []\nfor i in range(len(data.TotalCharges)):\n    if data.TotalCharges[i]==\" \":\n        count_null+=1\n        indices.append(i)\n    \nprint(count_null)","ea43b1ff":"print(100*count_null\/len(data))","029275a8":"daa=data.drop(indices,axis=0)\ntest = daa.reset_index()\ndata = test.drop([\"index\"],axis=1)","81e0b731":"def changeService(data,original_var=\"No phone service\",feature_list=[\"MultipleLines\"]):\n    \n    for feature in feature_list:\n        ls = list(data[feature][data[feature]==original_var].index)\n        data[feature].iloc[ls]=\"No\"\n    return data","eaf4d357":"df = changeService(data)","83f8cbb5":"feature_list = [\"OnlineSecurity\",\"OnlineBackup\",\"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\"]\ndf = changeService(df,original_var=\"No internet service\",feature_list=feature_list)\ndf.head()","af498c15":"sns.countplot(df.StreamingTV.value_counts())","6be45f05":"## See distribution of target variable ###\nac = sns.countplot(df.Churn)\nfor p in ac.patches:\n    height = p.get_height()\n    ac.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/len(df)),\n            ha=\"center\")","a769efec":"### Countplots for categorical features ###\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfig,ax = plt.subplots(5,3,figsize=(20,20))\nsns.set_style(\"dark\")\ncategorical = [\"gender\",\"SeniorCitizen\",\"Partner\",\"Dependents\",\"MultipleLines\",\"InternetService\",\\\n               \"OnlineSecurity\",\"OnlineBackup\",\"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\\\n               \"Contract\",\"PaperlessBilling\",\"PaymentMethod\",\"PhoneService\",\"Churn\"]\nk = 0\nfor i in range(5):\n    for j in range(3):\n        ac = sns.countplot(df[categorical[k]],ax=ax[i][j])\n        for p in ac.patches:\n            height = p.get_height()\n            ac.text(p.get_x()+p.get_width()\/2.,\n                    height + 3,\n                    '{:1.2f}'.format(height\/len(df)),\n                    ha=\"center\") \n        k+=1","7f0bf42a":"##Visualize probability distribution of continuous variables\ncont = [\"tenure\",\"MonthlyCharges\",\"TotalCharges\"]\nfig,ax = plt.subplots(1,3,figsize=(20,10))\nsns.set_style(\"dark\")\nfor i in range(3):\n    sns.distplot(df[cont[i]],ax=ax[i])\n","0e6ad562":"### Visualize cdf ###\nkwargs = {'cumulative': True}\nfig,ax = plt.subplots(1,3,figsize=(20,10))\nsns.set_style(\"dark\")\nfor i in range(3):\n    x = df[cont[i]]\n    sns.distplot(x, hist_kws=kwargs, kde_kws=kwargs,ax = ax[i])\n\n\n","f3c88372":"## Visualize categorical variables per churn label ###\nfig,ax = plt.subplots(5,3,figsize=(20,20))\nsns.set_style(\"dark\")\nk = 0\nfor i in range(5):\n    for j in range(3):\n        sns.countplot(data = df,x=\"Churn\",hue=categorical[k],ax=ax[i][j])\n        k+=1\n","318b65a3":"### Visualize reverse of above plot ###\nfig,ax = plt.subplots(5,3,figsize=(20,20))\nsns.set_style(\"dark\")\nk = 0\nfor i in range(5):\n    for j in range(3):\n        ac = sns.countplot(data = df,x=categorical[k],hue=\"Churn\",ax=ax[i][j])\n         \n        k+=1\n","b39d08cf":"### Do the same for the continuous variable distributions ###\n\n\ndef Viz(df,feat = \"tenure\"):\n    df_yes = df[df.Churn == \"Yes\"]\n    df_no = df[df.Churn ==\"No\"]\n    #fig,ax = plt.subplots(1,2,figsize=(20,20))\n\n    tenure_yes = df_yes[feat]\n    tenure_no = df_no[feat]\n    \n    sns.kdeplot(tenure_yes,label=feat+\"_yes\")\n    sns.kdeplot(tenure_no,label=feat+\"_no\")\n    plt.xlabel(feat)\n    plt.show()\n\n","fdd2d954":"#fig,ax = plt.subplots(1,3,figsize=(20,20))\n    \nViz(df,feat=cont[0])\nViz(df,feat=cont[1])\nViz(df,feat=cont[2])\n\n","ba7eaa08":"## Comparative visualization of CDF for the following ###\ndef VizCDF(df,feat=\"tenure\"):\n    kwargs = {'cumulative': True}\n    df_yes = df[df.Churn == \"Yes\"]\n    df_no = df[df.Churn ==\"No\"]\n    tenure_yes = df_yes[feat]\n    tenure_no = df_no[feat]\n\n    #fig,ax = plt.subplots(1,3,figsize=(20,10))\n\n    sns.distplot(tenure_yes, hist_kws=kwargs, kde_kws=kwargs,hist=False,label=feat+\"_yes\")\n    sns.distplot(tenure_no, hist_kws=kwargs, kde_kws=kwargs,hist=False,label=feat+\"_no\")\n    plt.show()\n\nVizCDF(df,feat=cont[0])\nVizCDF(df,feat=cont[1])\nVizCDF(df,feat=cont[2])\n","47863ec3":"### Boxplot to find outliers###\n#sns.boxplot(df.tenure)\nfig,ax = plt.subplots(3,2,figsize=(10,10))\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].astype(\"float\")\nsns.violinplot(x=df.Churn,y=df.tenure,ax=ax[0][0])\nsns.violinplot(x=df.Churn,y=df.MonthlyCharges,ax=ax[1][0])\nsns.violinplot(x=df.Churn,y=df.TotalCharges,ax=ax[2][0])\n\n\nsns.boxplot(x=df.Churn,y=df.tenure,ax=ax[0][1])\nsns.boxplot(x=df.Churn,y=df.MonthlyCharges,ax=ax[1][1])\nsns.boxplot(x=df.Churn,y=df.TotalCharges,ax=ax[2][1])\n","97ab203c":"## Convert Outliers to mean ###\n\ndf[df.tenure>65].tenure = df.tenure.mean()\n","249bd33b":"charge_yes = df[df.Churn==\"Yes\"].TotalCharges\ncharge_yes[charge_yes>5000] = charge_yes.mean()\n","0b01db5d":"charge_no = df[df.Churn==\"No\"].TotalCharges\ndf[\"TotalCharges\"] = pd.concat([charge_yes,charge_no])","8288a815":"### Label encode to convert strings to integers###\nfrom sklearn.preprocessing import LabelEncoder\nlec = LabelEncoder()\ndct = {}\nclasses = []\nfor col in df.columns:\n    if col in categorical:\n        dct[col] = list(lec.fit_transform(df[col]))\n        #print(lec.classes_)\n        if len(lec.classes_)>2:\n        \n            classes.append(lec.classes_)\n    else:\n        dct[col] = list(df[col].values)\n\n","60054aa3":"## Visualize correlation heatmap ###\ntest = pd.DataFrame(dct)\nfig = plt.subplots(figsize=(15,15))\nsns.heatmap(test.corr(),annot=True)\nplt.show()","bb2a3e0f":"### One hot encode variables with more than 2 categories ###\nfrom sklearn.preprocessing import OneHotEncoder\nonehot = OneHotEncoder()\n\n## first column ###\nfeatures = [\"InternetService\",\"Contract\",\"PaymentMethod\"]\nd = onehot.fit_transform(test[features[0]].values.reshape(-1,1)) \nonehot_df = pd.DataFrame(d.todense())\nonehot_df.columns = [\"DSL\",\"Fibre Optic\",\"No Internet service\"]\n\n## other 3 columns ##\nfor i in range(1,len(features)):\n    d = onehot.fit_transform(test[features[i]].values.reshape(-1,1)) \n    temp = pd.DataFrame(d.todense())\n    cols = []\n\n    \n    for j in range(len(classes[i])):\n        cols.append(classes[i][j])\n    temp.columns = cols\n    onehot_df = pd.concat([onehot_df,temp],axis=1)\n    \nfor feat in features:\n    test = test.drop(feat,axis=1)\ntest = pd.concat([test,onehot_df],axis=1)\ntest.head()","a431bb1b":"## View Columns ##\ntest.columns","243630aa":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_selection import SelectKBest,chi2\nfrom imblearn.over_sampling import RandomOverSampler,SMOTE","e0a9a988":"## Separate data and labels ###\nY = test.Churn\nX = test.drop(\"Churn\",axis=1)\nX = X.drop(\"customerID\",axis=1)\n## Drop total charges since its a redundant feature ###\n#X = X.drop(\"TotalCharges\",axis=1)","02d09259":"## Split train and test data\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,random_state=42,test_size=0.43)","08f467cb":"## Set up machine learning models###\n\n## Logistic Regression ###\nclf_1 = LogisticRegression(random_state=42,max_iter=500)\nclf_1.fit(X_train,Y_train)\npred = clf_1.predict(X_test)\n\n## Random Forest ###\nclf_forest = RandomForestClassifier(n_estimators=590)\nclf_forest.fit(X_train,Y_train)\npred_forest = clf_forest.predict(X_test)\n\n## Decision Tree ###\nclf_tree = DecisionTreeClassifier(min_samples_split=5)\nclf_tree.fit(X_train,Y_train)\npred_tree = clf_tree.predict(X_test)\n\n## XGB Classifier ###\nclf_xgb = XGBClassifier()\nclf_xgb.fit(X_train,Y_train)\npred_xgb = clf_xgb.predict(X_test)\n\n\n## GradientBoosting Classifier ##\nclf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.65,\\\n                                 max_depth=1, random_state=0)\nclf_gb.fit(X_train, Y_train)\npred = clf_gb.predict(X_test)\n\n## Voting Classifier ##\nclf_vote = VotingClassifier(estimators=[('lr', clf_1), ('xgb', clf_xgb),(\"gb\",clf_gb)],\n                         voting='soft')\nclf_vote.fit(X_train,Y_train)\npred_vote = clf_vote.predict(X_test)","2cd04c2b":"## Set up neural network ###\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import Input\nfrom keras.optimizers import Adam\n\nmodel = Sequential()\nmodel.add(Dense(128,activation=\"relu\",input_shape=(26,),use_bias=True))\nmodel.add(Dense(128,activation=\"relu\",use_bias=True))\n\nmodel.add(Dense(32,activation=\"relu\",use_bias=True))\nmodel.add(Dense(32,activation=\"relu\",use_bias=True))\n\nmodel.add(Dense(1,activation=\"sigmoid\"))","81dc4a16":"## Set up opt and loss ###\nopt = Adam(learning_rate=1e-5)\nmodel.compile(optimizer=opt,metrics=[\"accuracy\"],loss=\"binary_crossentropy\")","4316decf":"model.summary()","6e55e815":"## Generate classification report ###\nprint(\"======== Logistic Regression ========\")\nprint(classification_report(Y_test,pred))\nprint(\"======= Random Forest ======\")\nprint(classification_report(Y_test,pred_forest))\nprint(\"==== Decision tree ======\")\nprint(classification_report(Y_test,pred_tree))\nprint(\"========= XGB =========\")\nprint(classification_report(Y_test,pred_xgb))\nprint(\"=========GradientBoosting======\")\nprint(classification_report(Y_test,pred))\nprint(\"=========Voting======\")\nprint(classification_report(Y_test,pred_vote))\n\n","f3eb1054":"### Training Loop ####\nhistory = model.fit(x=X_train,y=Y_train,batch_size=32,epochs=200,validation_data=(X_test,Y_test))","8001c015":"fig,ax = plt.subplots(figsize=(8,8))\nplt.plot(history.history[\"loss\"],label = \"Train Loss\")\nplt.plot(history.history[\"val_loss\"],label=\"Val Loss\")\nplt.legend(['train', 'val'], loc='upper left')\nplt.xlabel(\"epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training History\")\nplt.show()","b2438899":"## See the logistic regression weights ###\nclf_1.coef_[0]","518ac763":"## Plot feature weights of logistic regression ###\nimport plotly.express as px\nfig = px.bar(x=X.columns,y=clf_1.coef_[0],template=\"ggplot2\",title=\"Logistic Regression weight visualization\")\nfig.update_xaxes(title=\"Features\")\nfig.update_yaxes(title=\"Weight\")\nfig.show()\n## Please hover over the plot to get value","c1c46d8f":"## See the xgb weights ##\nclf_xgb.feature_importances_","2c45b105":"## Plot feature importances of XGB\nimport plotly.express as px\nfig = px.bar(x=X.columns,y=clf_xgb.feature_importances_,template=\"ggplot2\")\nfig.update_xaxes(title=\"Features\")\nfig.update_yaxes(title=\"Weight\")\nfig.show()\n","6d16dbc8":"Weight importance of Logistic Regression","0316ea5b":"### Data Visualization","241613bc":"### Model Evaluation","67f1d4bc":"We observe the importance of features for two of our best models xgboost and logistic regression","c006b480":"**Categorical**\nGender,SeniorCitizen,Partner,Dependents,MultipleLines,InternetService,OnlineSecurity,OnlineBackup,DeviceProtection<br>,TechSupport,StreamingTV,StreamingMovies,Contract,PaperlessBilling,PaymentMethod\n\n**Continuous**<br>\ntenure,MonthlyCharges,TotalCharges","83d26310":"## Conclusion\n1. We see clearly in the first plot that people in the early stages of the timeline tend to be churners while the distribution of non churners is not really clear\n2. The second plot is also not very clear but seems to suggest most churners are willing to pay high amount of monthly charges and non churners pay a low amount. This is suggestive of the fact that customers paying for additional services like maybe streaming tv or movies are happier \n3. The next plot does not give much information since both plots seem to suggest that churners and non churners pay less total charges.","ac93a6a2":"Weight Importance of XGBoost","4dfb3481":"## Insights\n1. Logistic regression pays most attention to the feature InternetService2, which is the other name for FibreOptics.We had seen in out countplot that most churners preferred fiber optic services. This might be suggestive of the fact that it is an important factor.\n2. Last feature which is Internet Service 3 which stands for no service signifies that probably people without internet services are more likely to be non churners due to the highly negative weight.\n3. Contract3 feature also has a highly negative weight which signifies a two year long contract which supports our original hypothesis of longer contracts == lesser churn, while month to month contracts have a greater weight.\n4. Weights for features like StreamingTv and streaming music are moderately high representing that those features somewhere do affect the churn\n5. As seen from the barplot a pretty high negative weight is assigned to phone service and online security which seem to be like good areas to improve.\n","5a5de9e4":"From the above feature description its pretty clear that \n**A.** The feature multiple lines depends on whether the customer has a phone service in place in the first place. Hence we the no phone service can be replaced by no\n**B.** Similarly features like OnlineSecurity,OnlineBackup,TechSupport,DeviceProtection,StreamingTV and StreamingMovies depend on Internet Service. In all these places no internet service can be replaced by No\n","9110175a":"Since the percentage of missing data is so low we can just eliminate it","af9c6271":"## Conclusion\n1.There exist potential outliers in both classes but when viewed as a whole, no outlier comes into existence<br>\n2. Also difference in distributions can be seen once again","194da8f0":"### Interpretation of results","de9bd56d":"## Conclusion\n1. Number of no's are more than the number of yes's in every category\n2. The number of people having no internet service have a very low number of churners suggesting that internet service is a major factor in retaning customers.\n3. Customers with a two year contract have a very low number of churners\n4. People who pay via electronic check like the service more.","a8d28021":"## Conclusion\nWe see alot of correlations, mainly:\na. correlation between tenure and totalcharges seems to be very high. This can clearly be intuitively viewed since the more months they are the customers for, the more they pay.<br>\nb. Streaming TV and movies features have moderately high correlation with totalcharges since they increase charges. Similarly they have an effect on monthly charges as well.<br>\nc. Monthly charges and total charges have a pretty high correlation since basically they are both the same thing.<br>\nd. Interestingly churn and tenure again have a negative correlation as confirmed by our previous analysis.<br>\ne. Dependencies and Churn seem to have a pretty moderate negative correlation. This suggests that more the dependents less the person wants to spend on telecom services.<br>\n","a3b285b7":"The XGB Classifier provides similar conclusions, the only difference being the most important feature is found to be the month to month contract and not the internet service.<br>\nSince both models perform similarly well and so does gradientboostingclassifier, our final classifier is an ensemble of the all three in order to combine the best of all the algorithms. That takes our final prediction accuracy to 0.83","fcf1cf65":"### Importing the data","6b6dbf60":"## Conclusions\n1. The distribution of tenure seems to be multimodal, so does that of MonthlyCharges\n2. As for Total charges, data points seem to gather around the mode which is near 0","4994e6e5":"## Conclusion\nAlmost 73% of the data consists of no -> dataset is imbalanced\nSoln. Tried oversampling methods like SMOTE, they seemed to disturb the accuracy hence didnt go ahead with it","dac6e1d5":"# Churn Prediction\n\nThis notebook performs EDA and tries to predict churn according to the data present","c33810d4":"### Implement Machine Learning Models","08782220":"#### Q1. How did we know which features to eliminate?<br>\na. Initially we removed any kind of redundancy by eliminating an extra categories in those features which were dependent on the Internet service being present.<br><br>\nb. Next we explored the data and through the heatmap found that totalcharges and monthly charges were highly collinear. This made sense since totalcharges divided by tenure would end up giving us the monthly charges. Hence we decided to eliminate the same.But on running the models in both cases it was found that the when totalcharges was used as a feature and outliers were replaced by the mean, the model performed better<br><br>\nc. After that an effore was made to select relevant features using statistical techniques, but turned out most features provided relevant information about the target<br><br>\nd. Using boxplots we found outliers present categorically in the TotalCharges and the tenure feature. By replacing either of the outliers with their respective means, we were able to increase the accuracy of the classifiers to 0.83 (Logistic Regression)","4448d4b9":"We have certain categorical features and certain continuous features. Let us view them separately","7663983c":"#### 5. Assuming these actions were implemented, how would you determine whether they had worked?\nKeep collecting data over a period of time and perform similar analysis on the data collected to understand the effects and suggest counter measures in case the analysis does not seem to be correct.","91ac5a9a":"### Understanding the data","ed16348d":"Viewing the columns","079828b2":"Check for NULL values","5d763a52":"## Conclusion\n1. If we study the first CDF, we can see where the x axis and y axis meet at a particular point say (x=60). For non churners, it meets the y axis at an intercept of about 0.6. For churners it meets the y axis at a point just about 0.8 about 0.82. This indicates that for non churners about 60% of the people have a tenure<60 months and for churners, more than 80% of people have a tenure less than 80 months clearly suggesting that long tenure= lesser churners supplementing the fact from the kde plots earlier.\n2. Similarly if we look at the middle of the second plot we come to know a similar difference is observed in and around the monthly charges of 80 units.\n3. Finally at the total charge CDF, we again look at the middle to find a similar difference. More percentage of people have paid less than the same value and are likely to be churners as compared to non churners.","4011b20c":"### Final Conclusions\nAnswering some questions here","6a0fccf7":"## Conclusions\n1. Around 70% of the people in the sample are customers who have been customers for less than 60 months\n2. Around 70% of the people pay less than 100 units monthly\n3. More than 80% people pay less than 6000 total charges","0e64d26f":"### Feature Description ####\ncustomerID: Customer ID<br>\ngenderCustomer: gender (female, male)<br>\nSeniorCitizen: Whether the customer is a senior citizen or not (1, 0)<br>\nPartnerWhether: the customer has a partner or not (Yes, No)<br>\nDependents: Whether the customer has dependents or not (Yes, No)<br>\ntenure: Number of months the customer has stayed with the company<br>\nPhoneService: Whether the customer has a phone service or not (Yes, No)<br>\nMultipleLines: Whether the customer has multiple lines or not (Yes, No, No phone service)<br>\nInternetService: Customer\u2019s internet service provider (DSL, Fiber optic, No)<br>\nOnlineSecurity: Whether the customer has online security or not (Yes, No, No internet service)<br>\nOnlineBackup: Whether the customer has online backup or not (Yes, No, No internet service)<br>\nDeviceProtection: Whether the customer has device protection or not (Yes, No, No internet service)<br>\nTechSupport: Whether the customer has tech support or not (Yes, No, No internet service)<br>\nStreamingTV: Whether the customer has streaming TV or not (Yes, No, No internet service)<br>\nStreamingMovies: Whether the customer has streaming movies or not (Yes, No, No internet service)<br>\nContract: The contract term of the customer (Month-to-month, One year, Two year)<br>\nPaperlessBilling: Whether the customer has paperless billing or not (Yes, No)<br>\nPaymentMethod: The customer\u2019s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))<br>\nMonthlyCharges: The amount charged to the customer monthly<br>\nTotalCharges: The total amount charged to the customer<br>\nChurn: Whether the customer churned or not (Yes or No)<br>","b84bde3f":"## Conclusions:\n1. Mostly the sample consists of young population since the number of senior citizens is in the sample is just 16%\n2. Most people in the sample do not have dependents\n3. Most people do not ask for tech support","48a66c81":"### Data Manipulation after viz","463054da":"After observing all models we can safely say that the best model for the problem is XGboost. It gives an accuracy equal to logistic regression, but in terms of the other metrics it does slightly better. It is great to see simpler algorithms performing better than neural networks","ab7a83cb":"### Data Manipulation","42404106":"#### Q3. What are the key factors in predicting Churn?<br>\nAs described from the analysis above, tenure, phoneService,internetService,contract,dependents\n","0db5cae5":"Some features have more than 2 categories hence should be one hot encoded","60d20f45":"#### Q4. What offers should be made to which customers to encourage them to remain with the company?<br>\na. The company should put focus on getting word out about their internet service since people who have fibre optics are more likely to churn as compared to people who have no internet services. The company should provide fibre optics services at lower costs to make people realize how good of a service it is.<br>\nb. Contract: The company should either give incentives to people to go after their monthly contracts rather than yearly subscriptions, or find ways to keep their users engaged who are on longer contracts. Offers like Netflix,Amazon subscriptions along with monthly contracts may help boost both, internet services as well as contract services.<br>\nc. PhoneService: The company must take steps to improve their phone service since the current one clearly doesnt work well with the customers.<br>\nd. PaymentOptions: The company can partner with e-payment gateways to provide incentives to people to pay online. Offers like Save 15% off by paying online may work.<br>\ne.Improve on services in key areas like Online security and tech support<br>"}}