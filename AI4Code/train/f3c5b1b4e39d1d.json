{"cell_type":{"04399cd1":"code","ab5a710b":"code","3ac95b09":"code","48b4cd6a":"code","35f53ab1":"code","c5f34629":"code","fae4f03c":"code","daabdc31":"code","41238ae9":"code","f740bc9b":"code","45af2b57":"code","721d7a2c":"code","44f277ac":"code","c3eaba1a":"code","4c51b722":"code","e6faae2e":"code","148852ce":"code","38c36485":"code","a6e19bc1":"code","cd97a2d9":"code","28a4af55":"code","36f455ac":"code","d97e3c25":"code","fe18ca56":"code","776d2f48":"code","b6a06d99":"code","6276b6c6":"code","e2a30b7c":"code","5d83ee91":"code","41bf1d78":"code","e78b9fa2":"code","832a6da5":"code","eb46825d":"code","15002d2c":"code","08f16205":"code","37e2c2ee":"code","d6eb98a4":"code","4162a296":"code","e820ba16":"code","f1742e11":"code","8d299b9e":"code","5d46b222":"code","b2348d02":"code","f8f586fc":"code","ff8f7617":"code","7f7a164e":"code","41b46ca3":"code","baafa66e":"code","55013df3":"code","a75c4e82":"code","80e411ab":"code","94d96a74":"code","c623effc":"code","f63906a4":"code","72024c4b":"code","111009a0":"code","94058966":"code","3015caa6":"code","68f91cd0":"code","60c2fa3e":"code","b792083c":"code","599312c2":"code","d91e5e4e":"code","e97c87c0":"code","dff70dce":"code","560e378c":"code","6eabfa74":"code","14420f98":"code","9073111e":"code","ba2ebe0d":"code","39fd42b0":"code","098171c7":"code","1f60ab22":"code","56aa21cc":"code","5266e8d8":"code","95311cb3":"code","95f8a6a0":"code","8237fc15":"code","5a0100fd":"code","66365e42":"code","9c94894a":"code","50ff6f49":"code","ccdfe1de":"code","1435161e":"code","e90fc0da":"code","d61abdf7":"code","2768560d":"code","7be35eaf":"code","dbf42dbc":"code","9a6b036d":"markdown","62fba2ee":"markdown","5fc2451e":"markdown","1d9b5db6":"markdown","eb54ae60":"markdown","08fc70c5":"markdown","82df1600":"markdown","a1e3110c":"markdown","bd7241e9":"markdown","430e1df7":"markdown","3420a162":"markdown","bccfbca2":"markdown","6c07ab61":"markdown","3875419a":"markdown","30148bba":"markdown","55b7dd55":"markdown","36f4b321":"markdown","1bf60f07":"markdown","296b3979":"markdown","a0f025a3":"markdown","29614ab8":"markdown","36ad4ae4":"markdown","b3da220c":"markdown","41f320d3":"markdown","740262dc":"markdown","e84ff7e5":"markdown","db690101":"markdown","83c1bec4":"markdown","a484428f":"markdown","d1925afa":"markdown","da23a5db":"markdown","82133025":"markdown","b94a75d1":"markdown","1d5e7024":"markdown","8f93d2f9":"markdown","6cf14287":"markdown","da7c6e68":"markdown","a82461e5":"markdown","788de0c1":"markdown","cf4d4f61":"markdown","67d2cce4":"markdown","1c2802cd":"markdown","c6ae96bb":"markdown","71cb223b":"markdown","c4f395f6":"markdown","cc260ac6":"markdown","d1f2a762":"markdown","03428951":"markdown","1c1f653f":"markdown","ded48974":"markdown","0303760d":"markdown","fca1a918":"markdown","de9def8a":"markdown","ac8f189c":"markdown","c3921e21":"markdown","2d668f3e":"markdown","516d8a7a":"markdown","baf76853":"markdown"},"source":{"04399cd1":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import tree\nimport math\n\npd.set_option(\"display.max_columns\", None)\nsns.set(font_scale=1)\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ab5a710b":"rawdf = pd.read_csv('..\/input\/spain-public-transportation\/public_transportation_data.csv')\n","3ac95b09":"rawdf.head()","48b4cd6a":"df = rawdf\ndf.head()","35f53ab1":"df = df.iloc[:,1:]\n","c5f34629":"df.info()\ndf.head()","fae4f03c":"for col in ['insert_date', 'start_date', 'end_date']:\n    date_col = pd.to_datetime(df[col])\n    df[col + '_hour'] = date_col.dt.hour\n    df[col + '_minute'] = date_col.dt.minute\n    df[col + '_second'] = date_col.dt.second\n    df[col + '_day'] = date_col.dt.day\n    df[col + '_weekday'] = date_col.dt.day_name()\n    df[col + '_month'] = date_col.dt.month\n    df[col + '_year'] = date_col.dt.year","daabdc31":"df.head()","41238ae9":"for i in ['insert_date','start_date','end_date']:\n    df[i] = pd.to_datetime(df[i])\n","f740bc9b":"df['is_journey_end_on_sameday'] = np.where(df['start_date'].dt.date==df['end_date'].dt.date, \n                                           1, 0)\ndf['travel_time_in_mins'] = df['end_date'] - df['start_date']\ndf['travel_time_in_mins']=df['travel_time_in_mins']\/np.timedelta64(1,'m')","45af2b57":"df.head()","721d7a2c":"df.info()","44f277ac":"def movecol(df, cols_to_move=[], ref_col='', place='After'):\n    \n    cols = df.columns.tolist()\n    if place == 'After':\n        seg1 = cols[:list(cols).index(ref_col) + 1]\n        seg2 = cols_to_move\n    if place == 'Before':\n        seg1 = cols[:list(cols).index(ref_col)]\n        seg2 = cols_to_move + [ref_col]\n    \n    seg1 = [i for i in seg1 if i not in seg2]\n    seg3 = [i for i in cols if i not in seg1 + seg2]\n    \n    return(df[seg1 + seg2 + seg3])\n","c3eaba1a":"df.info()\ndf.head()","4c51b722":"missingper = df.isnull().sum().sort_values(ascending=False)\/df.shape[0]","e6faae2e":"missingper = missingper.round(2)*100\nmissingper.head()","148852ce":"df['price'].describe().round(2)","38c36485":"df.head()","a6e19bc1":"df['price'].fillna(df['price'].mean(),inplace=True)","cd97a2d9":"missingper = df.isnull().sum().sort_values(ascending=False)\/df.shape[0] * 100\nmissingper.head()","28a4af55":"df.dropna(inplace=True)","36f455ac":"missingper = df.isnull().sum().sort_values(ascending=False)\/df.shape[0]\nmissingper.head()","d97e3c25":"df.head()","fe18ca56":"corr = df.corr().sort_values(by='price',ascending=False).round(2)","776d2f48":"corr['price'].head(25)","b6a06d99":"plt.subplots(figsize=(12,9))\nsns.heatmap(data=df.corr(),square=True)","6276b6c6":"df.drop(columns=['end_date_day','end_date_month'], inplace=True)","e2a30b7c":"corr = df.corr().sort_values(by='price',ascending=False).round(1)","5d83ee91":"top_corr = corr['price'].head(14).index\ncm = np.corrcoef(df[top_corr].values.T)","41bf1d78":"plt.subplots(figsize=(10,10))\nsns.set(font_scale=1)\nhm = sns.heatmap(cm,annot=True,yticklabels=top_corr.values, xticklabels=top_corr.values)\nplt.show()","e78b9fa2":"df['price'].value_counts().head(10)","832a6da5":"fig,ax = plt.subplots(figsize=(15,5))\nax = sns.countplot(df['origin'])\nplt.show()","eb46825d":"fig,ax = plt.subplots(figsize=(15,5))\nax = sns.countplot(df['destination'])\nplt.show()","15002d2c":"px.histogram(df, x=\"origin\", color=\"destination\")","08f16205":"fig,ax = plt.subplots(figsize=(15,5))\nax = sns.countplot(df['train_type'])\nplt.show()","37e2c2ee":"f,ax = plt.subplots(figsize=(15,6))\nax = sns.distplot(df['price'],rug=True,)\nplt.show()","d6eb98a4":"fig,ax = plt.subplots(figsize=(15,5))\nax = sns.countplot(df['train_class'])\nplt.show()","4162a296":"f,ax = plt.subplots(figsize=(15,6))\nax = sns.boxplot(x='train_class',y='price',data=df)\nplt.show()","e820ba16":"f,ax = plt.subplots(figsize=(15,6))\nax = sns.boxplot(x='train_type',y='price',data=df)\nplt.show()","f1742e11":"countpie = df['train_type'].value_counts()\n\nfig = {\n  \"data\": [\n    {\n      \"values\": countpie.values,\n      \"labels\": countpie.index,\n      \"domain\": {\"x\": [0, .5]},\n      \"name\": \"Train types\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .7,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Pie chart Train types\",\n    }\n}\niplot(fig)","8d299b9e":"fig,ax = plt.subplots(figsize=(15,5))\nax = sns.countplot(df['fare'])\nplt.show()","5d46b222":"count_  = df['end_date'].dt.date.value_counts()\ncount_ = count_[:50,]\ncount_.head()","b2348d02":"fig,ax = plt.subplots(figsize=(10,6))\nax = sns.scatterplot(x='start_date_hour',y=df['start_date_hour'].value_counts(),data=df)\nplt.xlabel(\"start_date_hour\")\nplt.ylabel(\"start_hour_counts\")","f8f586fc":"fig,ax = plt.subplots(figsize=(10,6))\nax = sns.scatterplot(x='end_date_hour',y=df['end_date_hour'].value_counts(),data=df)\nplt.xlabel(\"end_date_hour\")\nplt.ylabel(\"end_date_hour_counts\")","ff8f7617":"railnumber = df['start_date'].dt.date.value_counts()\nrailnumber = railnumber[:50,]\nplt.figure(figsize=(25,10))\nsns.barplot(railnumber.index, railnumber.values)\nplt.ylabel('Number of journeys start date', fontsize=15)\nplt.xlabel('Date', fontsize=15)\nplt.xticks(rotation='vertical')\nplt.show()","7f7a164e":"railnumber = df['end_date'].dt.date.value_counts()\nrailnumber = railnumber[:50,]\nplt.figure(figsize=(25,10))\nsns.barplot(railnumber.index, railnumber.values)\nplt.ylabel('Number of journeys end date', fontsize=12)\nplt.xlabel('Date', fontsize=15)\nplt.xticks(rotation='vertical')\nplt.show()","41b46ca3":"df.head()","baafa66e":"countpie = df['start_date_weekday'].value_counts()\ncountpie = countpie.sort_index() \nfig = {\n  \"data\": [\n    {\n      \"values\": countpie.values,\n      \"labels\": ['Friday','Monday','Saturday', 'Sunday' ,'Thursday', 'Tuesday','Wednesday'],\n      \"domain\": {\"x\": [0, .5]},\n      \"name\": \"Percentage of train departure day\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .3,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Percentage of train departure day\",\n    }\n}\niplot(fig)","55013df3":"df['insert_date_weekday'].value_counts().sum()","a75c4e82":"df['is_journey_end_on_sameday'].value_counts()","80e411ab":"countpie = df['is_journey_end_on_sameday'].value_counts()\ncountpie = countpie.sort_index() \nfig = {\n  \"data\": [\n    {\n      \"values\": countpie.values,\n      \"labels\": ['no','yes'],\n      \"domain\": {\"x\": [0, .5]},\n      \"name\": \"Percentage of journeys started and ended on same date\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .3,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Percentage of journeys started and ended on same date\",\n    }\n}\niplot(fig)","94d96a74":"df.head()","c623effc":"px.histogram(df, x=\"train_type\",y=\"travel_time_in_mins\" ,color=\"train_type\")","f63906a4":"df['route'] = df['origin']+' - '+df['destination']","72024c4b":"df = movecol(df, \n             cols_to_move=['route'], \n             ref_col='destination',\n             place='After')","111009a0":"df.head()","94058966":"countpie = df['route'].value_counts()\n\nfig = {\n  \"data\": [\n    {\n      \"values\": countpie.values,\n      \"labels\": countpie.index,\n      \"domain\": {\"x\": [0, .5]},\n      \"name\": \"Routes\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .5,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Pie chart of routes\",\n    }\n}\niplot(fig)","3015caa6":"train_travelmins = df.groupby(['train_type'])['travel_time_in_mins'].mean()\ntrain_travelmins","68f91cd0":"plotter = df.groupby('train_type')['travel_time_in_mins'].agg(['mean'])\nplotter.columns = [\"mean\"]\nplotter['train_type'] = plotter.index\n\ndata = [\n    {\n        'x': plotter['train_type'],\n        'y': plotter['mean'],\n        'mode': 'markers+text',\n        'text' : plotter['train_type'],\n        'textposition' : 'bottom center',\n        'marker': {  \n            'size': 20,\n        }\n    }\n]\n\nlayout = go.Layout(title=\"Average travel time in minutes by Train type\", \n                   xaxis=dict(title='Train type'),\n                   yaxis=dict(title='Travel time in minutes')\n                  )\nfig = go.Figure(data = data, layout = layout)\niplot(fig, filename='scatter0')","60c2fa3e":"plotter = df.groupby('route')['price'].agg(['mean'])\nplotter.columns = [\"mean\"]\nplotter['train_type'] = plotter.index\n\ndata = [\n    {\n        'x': plotter['train_type'],\n        'y': plotter['mean'],\n        'mode': 'markers+text',\n        'text' : plotter['train_type'],\n        'textposition' : 'bottom center',\n        'marker': {  \n            'size': 20,\n        }\n    }\n]\n\nlayout = go.Layout(title=\"Average fare prices by Route type\", \n                   xaxis=dict(title='Route'),\n                   yaxis=dict(title='Average price')\n                  )\nfig = go.Figure(data = data, layout = layout)\niplot(fig, filename='scatter0')","b792083c":"plotter = df.groupby('start_date_weekday')['price'].agg(['mean'])\nplotter.columns = [\"mean\"]\nplotter['start_date_weekday'] = plotter.index\n\ndata = [\n    {\n        'x': plotter['start_date_weekday'],\n        'y': plotter['mean'],\n        'mode': 'markers+text',\n        'text' : plotter['start_date_weekday'],\n        'textposition' : 'bottom center',\n        'marker': {  \n            'size': 20,\n        }\n    }\n]\n\nlayout = go.Layout(title=\"Average fare price by Day type\", \n                   xaxis=dict(title='Start Day'),\n                   yaxis=dict(title='Average Price')\n                  )\nfig = go.Figure(data = data, layout = layout)\niplot(fig, filename='scatter0')","599312c2":"plotter = df.groupby('train_type')['price'].agg(['mean'])\nplotter.columns = [\"mean\"]\nplotter['train_type'] = plotter.index\n\ndata = [\n    {\n        'x': plotter['train_type'],\n        'y': plotter['mean'],\n        'mode': 'markers+text',\n        'text' : plotter['train_type'],\n        'textposition' : 'bottom center',\n        'marker': {  \n            'size': 20,\n        }\n    }\n]\n\nlayout = go.Layout(title=\"Average fare prices by Train type\", \n                   xaxis=dict(title='Train type'),\n                   yaxis=dict(title='Average price')\n                  )\nfig = go.Figure(data = data, layout = layout)\niplot(fig, filename='scatter0')","d91e5e4e":"df.head()","e97c87c0":"plt.subplots(figsize=(12,9))\nsns.heatmap(data=df.corr(),square=True)","dff70dce":"corr = df.corr().sort_values(by='price',ascending=False).round(2)\ncorr","560e378c":"abscorr = corr[abs(corr['price'])>0.05].index # get the index of all correlation by absolute first that more than 0.3\nabscorr","6eabfa74":"cm = np.corrcoef(df[abscorr].values.T)","14420f98":"sns.set(font_scale=1)\nhm = sns.heatmap(cm,annot=True,yticklabels=abscorr.values, xticklabels=abscorr.values)\nplt.show()","9073111e":"predictdf = df.copy()\npredictdf.head()","ba2ebe0d":"predictdf.drop(columns=['insert_date','start_date','end_date','insert_date_hour','insert_date_minute','insert_date_second',\n                       'insert_date_day','insert_date_month','insert_date_year','start_date_second','start_date_minute','start_date_hour','start_date_month','start_date_day','start_date_year',\n                       'end_date_hour','end_date_minute','end_date_second','end_date_year','is_journey_end_on_sameday'], inplace=True)","39fd42b0":"predictdf.head()","098171c7":"lab_en = LabelEncoder()\npredictdf.iloc[:,0] = lab_en.fit_transform(predictdf.iloc[:,0])\npredictdf.iloc[:,1] = lab_en.fit_transform(predictdf.iloc[:,1])\npredictdf.iloc[:,2] = lab_en.fit_transform(predictdf.iloc[:,2])\npredictdf.iloc[:,3] = lab_en.fit_transform(predictdf.iloc[:,3])\npredictdf.iloc[:,5] = lab_en.fit_transform(predictdf.iloc[:,5])\npredictdf.iloc[:,6] = lab_en.fit_transform(predictdf.iloc[:,6])\npredictdf.iloc[:,7] = lab_en.fit_transform(predictdf.iloc[:,7])\npredictdf.iloc[:,8] = lab_en.fit_transform(predictdf.iloc[:,8])\npredictdf.iloc[:,9] = lab_en.fit_transform(predictdf.iloc[:,9])","1f60ab22":"predictdf.head()","56aa21cc":"corr = predictdf.corr().sort_values(by='price',ascending=False).round(2)\ncorr","5266e8d8":"abscorr = corr[abs(corr['price'])>0.1].index # get the index of all correlation by absolute first that more than 0.3\nabscorr","95311cb3":"cm = np.corrcoef(predictdf[abscorr].values.T)","95f8a6a0":"sns.set(font_scale=1)\nhm = sns.heatmap(cm,annot=True,yticklabels=abscorr.values, xticklabels=abscorr.values)\nplt.show()","8237fc15":"predictdf.head()","5a0100fd":"X = predictdf.iloc[:,[0,1,2,3,5,6,7,8,9,10]].values\nY = predictdf.iloc[:,4].values","66365e42":"Y","9c94894a":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=123)","50ff6f49":"LinearModel = LinearRegression()\nLinearModel.fit(X_train,Y_train)\nLinearModel.score(X_train,Y_train) #r-squared","ccdfe1de":"LinearPrediction = LinearModel.predict(X_train)","1435161e":"def compute_rmse(model, X, y_true, name):\n    y_pred = model.predict(X)\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = math.sqrt(mse)\n    print(f'Root Mean Squared Error for {name}: {rmse}')","e90fc0da":"compute_rmse(LinearModel, X_train, Y_train, 'training set')\ncompute_rmse(LinearModel, X_test, Y_test, 'test set')","d61abdf7":"from sklearn.ensemble import RandomForestRegressor\nRFR = RandomForestRegressor(n_estimators=100, random_state=0)","2768560d":"RFR.fit(X_train,Y_train)","7be35eaf":"RFR.score(X_train,Y_train)","dbf42dbc":"compute_rmse(RFR, X_train, Y_train, 'training set')\ncompute_rmse(RFR, X_test, Y_test, 'test set')","9a6b036d":"We could know that most people have \"Madrid\" as origin station","62fba2ee":"**Plotly is the library that I want to try for so long, thanks to this project so I could use**","5fc2451e":"predictdf is data set that use for prediction","1d9b5db6":"We can know that price is at 12% from 100% <br> which we could remove all of it or input with mean","eb54ae60":"We could know almost everyone people use AVE train type more than any other types","08fc70c5":"We could know that most people have \"Madrid\" as their destination station too","82df1600":"### Create new column \"route\"","a1e3110c":"Percentage of trip route by using pie chart","bd7241e9":"### Examining Price","430e1df7":"# Creating the model","3420a162":"Average time per trip seperate by using train type","bccfbca2":"From the correlation matrix, we can assume that most trip are travel in the same day because \"start_date_day\" and \"end_date_day\" are highly correlated to each other. Same with \"start_date_month\" and \"end_date_month\" too. We can drop some columns of it","6c07ab61":"### Start visualize with the route","3875419a":"## Correlation","30148bba":"We could drop the missing data both in train_class and fare because it contain only 0.3%","55b7dd55":"A lot of people use AVE as their transportation.","36f4b321":"People usually buy tickets with Promo","1bf60f07":"Price is categorical in normal one such as 63.385 but it's not good because it both has standard price or discounted price","296b3979":"If joureny end on sameday is correct will be 1 no will be 0","a0f025a3":"# Import Dataset, Handle Data and Basic Inspection","29614ab8":"Missing data check again","36ad4ae4":"# Summary","b3da220c":"People prefer to use \"Turista\" class more than others class","41f320d3":"# Project Overview : Spanish Train","740262dc":"I would prefer to do the algorithms in R because it's better and have better understanding in this section but I will give you some example in python.","e84ff7e5":"Try to split Insert_date, start_data, end_date into seperate year, month and date type for better understanding","db690101":"## Virtualization","83c1bec4":"Dataset we use for prediction","a484428f":"\"Turista con enlance\" has the lowest ticket price <br>\nbut \"Cama G Clase\" has the highest ticket price","d1925afa":"Number of the Start Date","da23a5db":"Count of hour of the end date","82133025":"### Percentage of missing data","b94a75d1":"Count of hour of the start date","1d5e7024":"## Prepare data for prediction","8f93d2f9":"# Exploratory Data Analysis","6cf14287":"### After clean and remove columns we don't use we can use inspect data easier","da7c6e68":"From the graph we can assume that people prefer AVE train type because it has the least average time in muntes per trip","a82461e5":"### function for moving numbers of columns","788de0c1":"Distribution of ticket price","cf4d4f61":"### Random Forest Regressor","67d2cce4":"### Label encoding","1c2802cd":"Calculate amount of time in minutes and others","c6ae96bb":"We could know that most people have \"Madrid\" as destination station and travel from \"Madrid\"","71cb223b":"Every variables seem not affect to the price so I want to use LabelEncoder to make most of the avaliable as a factor","c4f395f6":"### Splitting the data to train and test","cc260ac6":"We can assume that \"travel_time_in_mins\" \"start_date_minute\" and \"start_date_month\" has high correlation to price","d1f2a762":"Thanks for Ratan Rohith : https:\/\/www.kaggle.com\/ratan123\/a-very-extensive-renfe-analysis <br>\nand Saurbah : https:\/\/www.kaggle.com\/scsaurabh\/spanish-train-ticket-price-prediction-renfe for references to create this kernel\n\n- Create virtualization to have a better understanding of the data of the Spanish Train System\n- Engineered features from the original variable to create a better model.\n- They are optimized Linear Regression and Random Forest.","03428951":"In this case we use mean to fill in NA of the price","1c1f653f":"## Seperate the time to seperate coloumns\n","ded48974":"### Linear Regression","0303760d":"## Checking missing data section, fill NA or drop","fca1a918":"From the correlation analysis, we have noted that \"travel_time_in_mins\" \"start_date_minute\" and \"start_date_month\" has high correlation to price. <br> So we need to use it and other variable that important and drop that doesn't matter","de9def8a":"Random Forest seems to be the best prediction because it has RMSE at around 8-10.\n\nThis is all I've done with this project, you might interest to invest further more and calculate a better model .\n\nThanks for viewing and studying from this kernel. I hope you enjoy the virtualization part and please upvote for me, it means a lot for my portfolio and if you have a question leave it below!","ac8f189c":"The most time spends by sum all travel_time_in_mins is AVE and Regional train type","c3921e21":"I removed the first columns because it's irrelevant to any of the work","2d668f3e":"## Feature Engineering","516d8a7a":"Mostly the price of \"AVE\" and AVE-TGV are higher than other train type","baf76853":"Build the Linear Regression Model"}}