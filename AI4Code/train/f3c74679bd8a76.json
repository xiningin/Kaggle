{"cell_type":{"1b1a8f60":"code","f582098d":"code","0950bf95":"code","3f828ec3":"code","f8789efd":"code","1fdabdf2":"code","6422fde8":"code","e01f15fd":"code","dbbf3b3e":"code","9ba67622":"code","76d0a068":"code","8e30f289":"code","686dbcf1":"code","3727bc84":"code","013bb33b":"code","c2e389a2":"code","52a6df31":"code","ddbc9980":"code","448fb7fa":"code","082eb68e":"code","526ed674":"code","aabc52af":"code","7bb6ac5c":"code","35752e6f":"code","7fa642dd":"code","55f7bcfb":"code","dcb6e401":"code","a5737059":"code","2fc040bc":"code","66391384":"code","fa0d8dfc":"code","184d4a43":"markdown","3ff8a80a":"markdown","46f47d02":"markdown","bf17221d":"markdown","92c588b4":"markdown","4611e300":"markdown","025cae83":"markdown","7600c6ec":"markdown","5a9a5504":"markdown","dd2c5919":"markdown","5de73f90":"markdown","a8367ddf":"markdown","7ec4ce22":"markdown","2ae0924a":"markdown","96a0b1fd":"markdown","f9b6e0de":"markdown","c423c6b4":"markdown","9713d9d2":"markdown","6576a22c":"markdown","7d6e48d6":"markdown","d84bbca2":"markdown","eb2150a7":"markdown","a964b48b":"markdown","1c98b300":"markdown","70fc2dbc":"markdown","fff2accd":"markdown","49d919f6":"markdown","146e9deb":"markdown","18b660e5":"markdown"},"source":{"1b1a8f60":"%pylab inline --no-import-all\n\nfrom pathlib import Path","f582098d":"!rm -rf GLC\n!git clone https:\/\/github.com\/maximiliense\/GLC","0950bf95":"# Change this path to adapt to where you downloaded the data\nDATA_PATH = Path(\"..\/input\/geolifeclef-2021\/data\")","3f828ec3":"ls -L $DATA_PATH","f8789efd":"ls $DATA_PATH\/observations","1fdabdf2":"import pandas as pd","6422fde8":"df_fr = pd.read_csv(DATA_PATH \/ \"observations\" \/ \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\ndf_us = pd.read_csv(DATA_PATH \/ \"observations\" \/ \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n\ndf = pd.concat((df_fr, df_us))\n\nprint(\"Number of observations for training: {}\".format(len(df)))\n\ndf.head()","e01f15fd":"df_fr_test = pd.read_csv(DATA_PATH \/ \"observations\" \/ \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\ndf_us_test = pd.read_csv(DATA_PATH \/ \"observations\" \/ \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n\ndf_test = pd.concat((df_fr_test, df_us_test))\n\nprint(\"Number of observations for testing: {}\".format(len(df_test)))\n\ndf_test.head()","dbbf3b3e":"def plot_observations_distribution(ax, df, df_test=None, **kwargs):\n    default_kwargs = {\n        \"zorder\": 1,\n        \"alpha\": 0.1,\n        \"s\": 0.5\n    }\n    default_kwargs.update(kwargs)\n    kwargs = default_kwargs\n    \n    ax.scatter(df.longitude, df.latitude, color=\"blue\", **kwargs)\n    \n    if df_test is not None:\n        ax.scatter(df_test.longitude, df_test.latitude, color=\"red\", **kwargs)\n\n    ax.autoscale(enable=True, axis=\"both\", tight=True)\n    ax.axis(\"off\")\n\n\nfig = plt.figure(figsize=(9, 5.5))\nax = fig.gca()\nplot_observations_distribution(ax, df_us, df_us_test)\nax.set_title(\"Observations distribution (US)\")\n\nfig = plt.figure(figsize=(5.5, 5.5))\nax = fig.gca()\nplot_observations_distribution(ax, df_fr, df_fr_test)\nax.set_title(\"Observations distribution (France)\")","9ba67622":"def select_samples_around_point(df, lon_min, lon_max, lat_min, lat_max):\n    ind = (\n        (lon_min <= df.longitude) & (df.longitude <= lon_max)\n        & (lat_min <= df.latitude) & (df.latitude <= lat_max)\n    )\n    return df[ind]\n\n\nfig, ax = plt.subplots(figsize=(9.5, 7))\n\nkwargs = {\n    \"alpha\": 0.2,\n    \"s\": 5,\n}\ndf_zoom = select_samples_around_point(df_fr, 3, 4.5, 43.25, 44.25)\ndf_zoom_test = select_samples_around_point(df_fr_test, 3, 4.5, 43.25, 44.25)\n\nax = fig.gca()\nplot_observations_distribution(ax, df_zoom, df_zoom_test, **kwargs)\nax.set_title(\"Observations distribution around Montpellier, France\")","76d0a068":"df_species = pd.read_csv(DATA_PATH \/ \"metadata\" \/ \"species_details.csv\", sep=\";\")\n\nprint(\"Total number of species: {}\".format(len(df_species)))\n\ndf_species.head()","8e30f289":"df_env_vars = pd.read_csv(DATA_PATH \/ \"metadata\" \/ \"environmental_variables.csv\", sep=\";\")\ndf_env_vars.head()","686dbcf1":"df_landcover_labels = pd.read_csv(DATA_PATH \/ \"metadata\" \/ \"landcover_original_labels.csv\", sep=\";\")\ndf_landcover_labels.head()","3727bc84":"df_suggested_landcover_alignment = pd.read_csv(DATA_PATH \/ \"metadata\" \/ \"landcover_suggested_alignment.csv\", sep=\";\")\ndf_suggested_landcover_alignment.head()","013bb33b":"PATCHES_PATH = DATA_PATH \/ \"patches_sample\"","c2e389a2":"ls $PATCHES_PATH","52a6df31":"ls $PATCHES_PATH\/fr","ddbc9980":"ls $PATCHES_PATH\/fr\/00","448fb7fa":"ls $PATCHES_PATH\/fr\/00\/19\/10561900*","082eb68e":"ls $PATCHES_PATH\/us\/00\/81\/22068100*","526ed674":"from GLC.data_loading.common import load_patch\n\npatch = load_patch(10561900, PATCHES_PATH)\n\nprint(\"Number of data sources: {}\".format(len(patch)))\nprint(\"Arrays shape: {}\".format([p.shape for p in patch]))\nprint(\"Data types: {}\".format([p.dtype for p in patch]))","aabc52af":"landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values\npatch = load_patch(10561900, PATCHES_PATH, landcover_mapping)","7bb6ac5c":"from GLC.plotting import visualize_observation_patch\n\n# Extracts land cover labels\nlandcover_labels = df_suggested_landcover_alignment[[\"suggested_landcover_code\", \"suggested_landcover_label\"]].drop_duplicates().sort_values(\"suggested_landcover_code\")[\"suggested_landcover_label\"].values\n\nvisualize_observation_patch(patch, landcover_labels)","35752e6f":"patch = load_patch(22068100, PATCHES_PATH, landcover_mapping)\n\nvisualize_observation_patch(patch, landcover_labels)","7fa642dd":"df_env = pd.read_csv(DATA_PATH \/ \"pre-extracted\" \/ \"environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\ndf_env.head()","55f7bcfb":"print(\"Variables which can contain NaN values:\")\ndf_env.isna().any()","dcb6e401":"from GLC.data_loading.environmental_raster import PatchExtractor","a5737059":"extractor = PatchExtractor(DATA_PATH \/ \"rasters\", size=256)\nextractor.add_all_bioclimatic_rasters()\n\nprint(\"Number of rasters: {}\".format(len(extractor)))","2fc040bc":"patch = extractor[43.61, 3.88]\n\nprint(\"Patch shape: {}\".format(patch.shape))\nprint(\"Data type: {}\".format(patch.dtype))","66391384":"print(\"Contains NaN: {}\".format(np.isnan(patch).any()))","fa0d8dfc":"fig = plt.figure(figsize=(14, 10))\nextractor.plot((43.61, 3.88), fig=fig)","184d4a43":"It can also automatically perform the land cover alignment if necessary:","3ff8a80a":"## Patch extraction from rasters\n\nTo more easily extract patches from the rasters, we provide a `PatchExtractor` class which uses [rasterio](https:\/\/github.com\/mapbox\/rasterio).","46f47d02":"Then, we need to define the path to the data:","bf17221d":"and","92c588b4":"# Environmental rasters\n\nThe rasters contain low-resolution environmental data - bioclimatic and pedological data.\n\nThere are two ways to use this data:\n1. directly use the environmental vectors pre-extracted that can be found in the CSV file `pre-extracted\/environmental_vectors.csv`\n2. manually extract patches centered at each observation using the rasters located in the `rasters` subfolder","4611e300":"A helper function to plot the patches is also provided.\n\nThe following example displays the patches obtained around the region of Montpellier, France.","025cae83":"Note that it typically contains NaN values due to absence of data over the seas and oceans for both types of data as well as rivers and others for the pedologic data.","7600c6ec":"Note that it typically contains NaN values due to absence of data over the seas and oceans for both types of data as well as rivers and others for the pedologic data.","5a9a5504":"This folder is the path root where the data was downloaded and extracted:","dd2c5919":"We first need to clone our code:","5de73f90":"A patch can then easily to be extracted given the localization using:","a8367ddf":"Let's load these CSV files using [pandas](https:\/\/pandas.pydata.org\/):","7ec4ce22":"## Pre-extracted environmental vectors\n\nThese vectors are ready to be used - see the Random Forest training baseline in the corresponding notebook.\n\nThey are easy to load as they are provided as a CSV file.\n\nEach line of this file correspond to an observation and each column to one of the environmental variable.","2ae0924a":"# Metadata\n\nIn the `metadata` folder, some additional data is provided.\nThere are 4 files containing:\n1. GBIF species names associated with the species id provided in the observations in `species_details.csv`\n2. The description of the environmental (bioclimatic and pedological) variables in `environmental_variables.csv`\n3. The labels corresponding to the original land cover codes in `landcover_original_labels.csv`\n4. The suggested alignment of land cover codes between France and US in `landcover_suggested_alignment.csv`","96a0b1fd":"We also provide an visualization function for the patches:","f9b6e0de":"Similarly, for the observation `22068100`:","c423c6b4":"The observations are not uniformly sampled in the two countries as shown the following plots.\nThe training observations are shown in blue while the test ones are shown in red.","9713d9d2":"There are 4 files for each observation:\n- a color JPEG image containing an RGB image (`*_rgb.jpg`)\n- a grayscale JPEG image containing a near-infrared image (`*_near_ir.jpg`)\n- a TIFF with Deflate compression containing altitude data (`*_altitude.tif`)\n- a TIFF with Deflate compression containing land cover data (`*_landcover.tif`)\n\nWe provide a loading function which, given an observation id, loads all this data at once using [Pillow](https:\/\/pillow.readthedocs.io\/en\/stable\/) for the images and [tiffile](https:\/\/github.com\/cgohlke\/tifffile) for the TIFF files and returns them as a tuple `(rgb, near-ir, altitude, landcover)`:","6576a22c":"The following code loads the rasters for all the variables and prepares to extract patches of size 256x256.\n\nHere the patches are not of the same resolution as the provided ones as one pixel corresponds to 30arcsec (~1km) for the bioclimatic data and to 250m for the pedologic data.\n\nNote that this uses quite a lot of memory (~18Go) as all the rasters will be loaded in the RAM.\n\nTo avoid this issue, we will only load the bioclimatic rasters here.","7d6e48d6":"# Observations\n\nThe `observations` subfolder contains 4 CSV files:","d84bbca2":"and","eb2150a7":"The first digit of the observation id tells the country it belongs to:\n- `1` for France, thus to be found in subfolder `fr`\n- `2` for US, thus to be found in subfolder `us`\n\nFor instance, `10561949` is an observation made in France whereas `22068175` was observed in the US.\n\nInside those folders, there are two levels of hierarchy, corresponding to the last four digits of the observation id:","a964b48b":"A close-up view on the region around Montpellier, France, shows the train\/test splitting procedure.\n\nNote that there is no geographical overlap between training and test sets.","1c98b300":"To load all the rasters use:\n```python\nextractor.add_all_rasters()\n```\n\nTo load all the pedologic rasters use:\n```python\nextractor.add_all_pedologic_rasters()\n```","70fc2dbc":"We can now look into these subfolders and the data they contain.","fff2accd":"Each of line of those files corresponds to a single observation.\n\nIn the files corresponding to the training data, there are 5 columns:\n- `observation_id`: unique identifier of the observation\n- `latitude`: latitude coordinates of this observation\n- `longitude`: longitude coordinates of this observation\n- `species_id`: identifier of the species observed at that location\n- `subset`: proposed train\/val split using the same splitting procedure than for train and test (equal to either \"train\" or \"val\")\n\nIn the files corresponding to the test data, there are only 3 columns:\n- `observation_id`: unique identifier of the observation\n- `latitude`: latitude coordinates of this observation\n- `longitude`: longitude coordinates of this observation\n\nThe goal is then to predict the identifier of the species observed at that location.","49d919f6":"This notebook details the data structure and shows how to load the data.","146e9deb":"# Patches\n\nThe patches consist of images centered at each observation's location capturing three types of information in the 250m x 250m neighboring square:\n1. remote sensing imagery under the form of RGB-IR images\n2. land cover data\n3. altitude data\n\nThey are located in the `patches` subfolder contains 2 subfolders, one for each country:","18b660e5":"To find the files corresponding to an observation:\n1. the first subfolder corresponds to the last two digits,\n2. the second subfolder corresponds to the two digits right before them.\n\nFor instance, the patches corresponding to observation `10561900` can be found in `patches\/fr\/00\/19`, whereas `22068100` can be found in `patches\/us\/00\/81`:"}}