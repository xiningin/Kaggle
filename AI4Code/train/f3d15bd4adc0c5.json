{"cell_type":{"5ea05058":"code","79cef9f1":"code","9a402628":"code","cb3d992d":"code","dfec2b54":"code","f0ffd050":"code","18f1dada":"code","70827176":"code","ad500dc5":"code","ead8e392":"code","ac892f26":"code","a2b3e450":"code","e7382d48":"code","31dfb134":"code","4b0995dc":"code","3f96bb10":"code","9a727ad9":"code","3238669d":"code","0e8526fc":"code","c050986f":"code","19fefb40":"code","cd81fc39":"code","a00ab283":"code","b381366a":"code","3a87438c":"code","b0d73459":"code","613738fd":"code","09ba5dad":"code","29fffe9b":"code","d5ae7957":"code","e28a1b42":"code","eaac42bc":"code","e45e629b":"code","0ae24e20":"code","7b950517":"markdown","c66f4e75":"markdown","506db099":"markdown","9bed908a":"markdown","97efc61d":"markdown","1c7db570":"markdown","e1513740":"markdown","b32d0b2c":"markdown","fda6fec4":"markdown","9a9d9f76":"markdown","951c4999":"markdown","0aba9a4a":"markdown","a3666285":"markdown","572f112f":"markdown","dad2809f":"markdown","a2841217":"markdown","0c452e2d":"markdown","37155a25":"markdown","51eff28f":"markdown","a0ad4674":"markdown","793fdbf0":"markdown","99666f6b":"markdown","737dfbcd":"markdown","1ea425c3":"markdown","974f1e52":"markdown","a98511f8":"markdown"},"source":{"5ea05058":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nimport math\nimport tensorflow as tf\nfrom tensorflow import keras\nimport itertools","79cef9f1":"train = pd.read_csv('..\/input\/train.csv')\ntrain.head()","9a402628":"test = pd.read_csv('..\/input\/test.csv')\ntest.head()","cb3d992d":"all = pd.concat([train,test], sort=False, ignore_index=True)\nall.head()","dfec2b54":"all_cabin1 = all['Cabin'].apply(lambda x: str(x)[:1] if x == x else '')\nall_cabin1 = pd.get_dummies(all_cabin1);\nall_cabin1.head()","f0ffd050":"all_cabin2 = all['Cabin'].apply(lambda x: str(x).split(' ')[0][1:] if x == x else x)\nall_cabin2 = all_cabin2.apply(lambda x: int(x) if str(x).isdigit() else math.nan)\nall_cabin2.head()","18f1dada":"all_cabin3 = all['Cabin'].str.len()\nall_cabin3.head()","70827176":"all_ticket1 = all['Ticket'].apply(lambda x: (str(x).split(' ')[0] if len(str(x).split(' ')) > 1 else '') if x == x else '')\nall_ticket1 = pd.get_dummies(all_ticket1.str.replace('.','').str.replace('\/','').str.upper())\nall_ticket1.head()","ad500dc5":"all_ticket2 = all['Ticket'].apply(lambda x: str(x).split(' ')[len(str(x).split(' '))-1] if x == x else '')\nall_ticket2 = all_ticket2.apply(lambda x: int(x) if str(x).isdigit() else math.nan)\nall_ticket2.head()","ead8e392":"all_name1 = all['Name'].apply(lambda x: 1 if '(' in x else 0)\nall_name1.head()","ac892f26":"all_name2 = all['Name'].str.len()\nall_name2.head()","a2b3e450":"all_agefare = all.apply(lambda row: row['Fare'] \/ row['Age'], axis=1)\nall_agefare.head()","e7382d48":"all_sex = pd.Series(LabelEncoder().fit_transform(all[\"Sex\"]))\nall_sex.head()","31dfb134":"all_embarked = pd.get_dummies(all['Embarked'])\nall_embarked.head()","4b0995dc":"X = all.drop(columns=[\"PassengerId\",\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"])\nX[\"Sex\"] = all_sex\nfor c in all_embarked:\n    X[\"Embarked_\"+c] = all_embarked[c]\nfor c in all_ticket1:\n    X[\"Ticket1_\"+c] = all_ticket1[c]\nfor c in all_cabin1:\n    X[\"Cabin1_\"+c] = all_cabin1[c]\nX[\"Cabin2\"] = all_cabin2\nX[\"Cabin3\"] = all_cabin3\nX[\"Ticket2\"] = all_ticket2\nX[\"Name1\"] = all_name1\nX[\"Name2\"] = all_name2\nX['Fare_Age'] = all_agefare\n\nX.head()","3f96bb10":"for c in list(X.drop(columns=\"Survived\")):\n    X[c] = X[c].apply(lambda x: X[c].median() if x != x else x)\n\nX.head()","9a727ad9":"for c in list(X.drop(columns=\"Survived\")):\n    X[c] = pd.cut(X[c],100)\n\nX.head()","3238669d":"for c in list(X.drop(columns=\"Survived\")):\n    X[c] = X[c].apply(lambda x: x.right)\n    X[c] = pd.Series(LabelEncoder().fit_transform(X[c]))\n\nX.head()","0e8526fc":"trainX = X.loc[X[\"Survived\"] == X[\"Survived\"]]\ntrainY = trainX.pop(\"Survived\")\ntrainX.head()","c050986f":"trainY.head()","19fefb40":"testX = X.loc[X[\"Survived\"] != X[\"Survived\"]].drop(columns=\"Survived\")\ntestX.head()","cd81fc39":"sampleX = []\nsampleY = []\nsampleXtest = []\nsampleYtest = []\nall = pd.concat([trainX,trainY],axis=1)\n\nfor i in range(0, 9):\n    sampleX.append(all.sample(n=math.ceil(len(trainX)\/10), random_state=i))\n    sampleXtest.append(all.iloc[all.index.difference(sampleX[i].index)])\n    sampleX[i] = pd.DataFrame(sampleX[i].values, columns=sampleX[i].columns)\n    sampleXtest[i] = pd.DataFrame(sampleXtest[i].values, columns=sampleXtest[i].columns)\n    sampleY.append(sampleX[i].pop('Survived'))\n    sampleYtest.append(sampleXtest[i].pop('Survived'))\n    \nsampleY[0].head()","a00ab283":"def evaluate(Y_pred, testY):\n    err = sum(abs(y - Y_pred[i]) for i, y in testY.iteritems())\n    return 1-err\/testY.count()","b381366a":"model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), learning_rate=.9, algorithm='SAMME')","3a87438c":"score = []\nfor i in range(0, 9):\n    model.fit(sampleX[i],sampleY[i])\n    Y_pred = pd.Series(model.predict(sampleXtest[i])).astype(int)\n    score.append(evaluate(Y_pred=Y_pred,testY=sampleYtest[i]))\n    \n(np.mean(score) + np.min(score))\/2","b0d73459":"def train_input_fn(trainX, trainY, shuffle=0):\n    dataset = tf.data.Dataset.from_tensor_slices((dict(trainX), trainY.values))\n    for _ in itertools.repeat(None, shuffle):\n        dataset = dataset.shuffle(100).repeat()\n    dataset = dataset.batch(10)\n    return dataset","613738fd":"def test_input_fn(testX):\n    dataset = tf.data.Dataset.from_tensor_slices(dict(testX))\n    dataset = dataset.batch(10)\n    return dataset","09ba5dad":"feature_columns = [tf.feature_column.numeric_column(name) for name in trainX.columns]","29fffe9b":"score = []\nfor i in range(0, 9):\n    model = tf.estimator.BoostedTreesClassifier(feature_columns, n_batches_per_layer=20)\n    model.train(input_fn=(lambda:train_input_fn(trainX=sampleX[i],trainY=sampleY[i],shuffle=4)),max_steps=1000)\n    pred = model.predict(input_fn=lambda:test_input_fn(testX=sampleXtest[i]))\n    Y_pred = pd.Series([int(next(pred)['classes'][0]) for _ in itertools.repeat(None, len(sampleXtest[i]))])\n    score.append(evaluate(Y_pred=Y_pred,testY=sampleYtest[i]))\n\n(np.mean(score) + np.min(score))\/2","d5ae7957":"# model = tf.estimator.BoostedTreesClassifier(feature_columns, n_batches_per_layer=20)\n# model.train(input_fn=(lambda:train_input_fn(trainX, trainY)),max_steps=1000)\n# pred = model.predict(input_fn=lambda:test_input_fn(testX))\n# Y_pred = pd.Series([int(pred.next()['classes'][0]) for _ in itertools.repeat(None, len(testX))])","e28a1b42":"# model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), learning_rate=.9, algorithm='SAMME')\n# model.fit(trainX,trainY)\n# Y_pred = pd.Series(model.predict(trainX)).astype(int)","eaac42bc":"# Y_pred.head()","e45e629b":"# submission = pd.DataFrame({\n#     \"PassengerId\": test[\"PassengerId\"],\n#     \"Survived\": Y_pred\n# })\n\n# submission.head()","0ae24e20":"# submission.to_csv('submission.csv', index=False)","7b950517":"# Modify input data\n\nCabin1 will be the first letter of Cabin, changed into \"one hot\" vector.","c66f4e75":"Fare_Age will be Fare divided by Age","506db099":"Turning Embarked into \"one hot\" vector","9bed908a":"# Overview\n\nThis kernel compares sklearn AdaBoostClassifier applied on DecisionTreeClassifier, with tensorflow BoostedTreesClassifier. It's meant mostly to test some basic TF functionalities.","97efc61d":"Labelling buckets","1c7db570":"Both methods give prety much the same result, which makes sense. The commented code below creates the final models (only one should be uncommented), runs prediction for the test set, and writes it to submission file.","e1513740":"Cabin2 will be the number part of Cabin","b32d0b2c":"And the evaluation part","fda6fec4":"Cabin3 will be the length of the Cabin string","9a9d9f76":"Simple evaluation function","951c4999":"Putting all together","0aba9a4a":"Grouping values into buckets","a3666285":"Name1 will indicate if Name contains parenthesis","572f112f":"# Load data","dad2809f":"Creating sklearn classifiers is pretty straightforward","a2841217":"Labeling the Sex field","0c452e2d":"Ticket2 will be the number part of Ticket","37155a25":"# Building and validating models\n\nThe models have different interfaces, so I'm doing my own validation, starting with splitting training set into validation subsets.","51eff28f":"Splitting data set into train input, train output, test input.","a0ad4674":"Prediction result is given as a generator, but for some reason `list(pred)` hangs, so I'm running `next(pred)` in a loop.","793fdbf0":"Column definition needs to be provided using tf.feature_column","99666f6b":"Name2 will be the length of Name","737dfbcd":"Let's put both data sets in one DataFrame before messing with it. Note ignore_index=True, without it the indices are duplicated, which is an issue for LabelEncoder.","1ea425c3":"Replacing NaN's with median","974f1e52":"Ticket1 will be the first word in Ticket, changed into \"one hot\" vector.","a98511f8":"With Tensorflow it's a bit more complicated. The input data needs to be provided by functions."}}