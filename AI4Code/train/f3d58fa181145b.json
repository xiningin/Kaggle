{"cell_type":{"473790b9":"code","4719dc53":"code","92589853":"code","51471625":"code","8122c2f4":"code","f581f97e":"code","a2b84f0f":"code","6db3fdb6":"code","5a330522":"code","5d906c21":"code","f4b1ff48":"code","4dbd4bcb":"code","17a0cea1":"code","a69ad694":"code","1bedcc20":"code","f1496425":"code","48f677e7":"code","679165be":"code","a9ebb5f6":"markdown","df1bca28":"markdown","5313b831":"markdown","18eaeb9c":"markdown","8bede3cb":"markdown","966cf404":"markdown","45d895d9":"markdown","7919e713":"markdown"},"source":{"473790b9":"import os\nimport pandas as pd\n\nTRAIN_FILENAME = \"train.csv\"\nTEST_FILENAME = \"test.csv\"\nDATA_PATH = \"\/kaggle\/input\/titanic\"\nOUT_PATH = \"\/kaggle\/working\"\n\ndata = pd.read_csv(os.path.join(DATA_PATH, TRAIN_FILENAME))\ndata.describe()","4719dc53":"from sklearn.model_selection import StratifiedShuffleSplit\n\ndef train_test_split(X: pd.DataFrame, y: pd.Series)-> (\n    pd.DataFrame,\n    pd.DataFrame,\n    pd.Series,\n    pd.Series\n):\n    split = StratifiedShuffleSplit(\n        n_splits=1,\n        test_size=0.2,\n        random_state=42\n    )\n    \n    # Fill NaNs before categorising\n    X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n    age_cat = pd.cut(\n        X[\"Age\"],\n        bins=10,\n        labels=[i for i in range(1, 11)]\n    )\n    \n    for train_index, test_index in split.split(X, age_cat):\n        X_train = X.loc[train_index]\n        X_test = X.loc[test_index]\n        y_train = y.loc[train_index]\n        y_test = y.loc[test_index]\n    \n    return X_train, X_test, y_train, y_test","92589853":"X = data.drop(\"Survived\", axis=1)\ny = data[\"Survived\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)","51471625":"from sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom typing import List\n\ndef build_preprocessing_pipeline(\n    columns: List[str],\n    cat_cols: List[str],\n    cols_to_drop: List[str]\n) -> ColumnTransformer:\n    \n    num_attrs = [\n        item\n        for item in columns\n        if item not in cat_cols\n        and item not in cols_to_drop\n    ]\n    \n    num_pipeline = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"median\")),\n        (\"std_sacler\", StandardScaler()),\n    ])\n    \n    impute_encode = Pipeline([\n        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"encode\", OneHotEncoder()),\n    ])\n    \n    full_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attrs),\n        (\"drop_cats\", \"drop\", cols_to_drop),\n        (\"impute_encode_cats\", impute_encode, cat_cols),\n    ])\n    \n    return full_pipeline","8122c2f4":"cat_attrs = [\"Sex\", \"Embarked\"]\ncols_to_drop = [\"PassengerId\", \"Cabin\", \"Name\", \"Ticket\"]\n\npreprocessing_pipeline = build_preprocessing_pipeline(list(X_train), cat_attrs, cols_to_drop)\n\nX_train_prepared = preprocessing_pipeline.fit_transform(X_train)","f581f97e":"pd.DataFrame(X_train_prepared).head()","a2b84f0f":"from sklearn.svm import SVC\n\nsvc = SVC()\n\nsvc.fit(X_train_prepared, y_train)","6db3fdb6":"some_data = X_train[:5]\nsome_labels = y_train[:5]\nsome_data_prepared = preprocessing_pipeline.transform(some_data)\n\nprint(f\"Predictions: {svc.predict(some_data_prepared)}\")\nprint(f\"Labels: {list(some_labels)}\")","5a330522":"from sklearn.metrics import accuracy_score\n\nsvc_score = accuracy_score(svc.predict(X_train_prepared), y_train)\nsvc_score","5d906c21":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier()\ntree.fit(X_train_prepared, y_train)\n\ntree_score = accuracy_score(tree.predict(X_train_prepared), y_train)\ntree_score","f4b1ff48":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import make_scorer\nimport numpy as np\nfrom typing import Dict\n\ndef display_scores(estimator_name: str, scores: np.ndarray):\n    print(f\"Scores for {estimator_name}:\\n{scores}\")\n    print(f\"Mean: {scores.mean()}\")\n    print(f\"Standard deviation: {scores.std()} \\n\\n\")\n\ndef cross_validate(estimators_dict: Dict, X, y, cv=10, scoring=make_scorer(f1_score)):\n    for estimator_name, estimator in estimators_dict.items():\n        scores = cross_val_score(\n            estimator,\n            X,\n            y,\n            cv=cv,\n            scoring=scoring\n        )\n        display_scores(estimator_name, scores)\n\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nimport warnings\nwarnings.filterwarnings('ignore') \n\nestimators = {\n    \"Support Vector Classifier\": SVC(),\n    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n    \"Multiple Layer Perceptron Classifier\": MLPClassifier(),\n    \"Logistic Regression\": LogisticRegression(),\n    \"Random Forest Classifier\": RandomForestClassifier(),\n    **{\n        f\"K-Neigbors Classifier with k={k}\": KNeighborsClassifier(k)\n        for k in range(1, 10)\n    }\n}\ncross_validate(estimators, X_train_prepared, y_train)","4dbd4bcb":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.base import BaseEstimator\n\ndef get_tuned_model(\n    estimator: BaseEstimator,\n    param_grid: Dict,\n    X,\n    y,\n    cv=10,\n    scoring=make_scorer(f1_score),\n    n_iter=10,\n    random_state=42,\n    n_jobs=-1\n):\n    \n    randomized_search = RandomizedSearchCV(\n        estimator,\n        param_grid,\n        cv=cv,\n        n_iter=n_iter,\n        scoring=scoring,\n        return_train_score=True,\n        n_jobs=n_jobs,\n        random_state=random_state\n    )\n    randomized_search.fit(X, y)\n    \n    curves = randomized_search.cv_results_\n    \n    print(\"Scores:\")\n    for mean_score, params in zip(curves[\"mean_test_score\"], curves[\"params\"]):\n        print(f\"Params: {params}, mean score: {mean_score}\")\n    \n    print(f\"Best Score: {randomized_search.best_score_}\")\n    print(f\"Best Parameters: {randomized_search.best_params_}\")\n    \n    return randomized_search.best_estimator_","17a0cea1":"param_grid = {\n    \"C\": [0.001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n    \"gamma\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n}\ntuned_model = get_tuned_model(\n    SVC(),\n    param_grid,\n    X_train_prepared,\n    y_train,\n    n_iter=100\n)","a69ad694":"X_test_prepaired = preprocessing_pipeline.transform(X_test)\ny_predicted = tuned_model.predict(X_test_prepaired)\n\ntest_score = f1_score(y_test, y_predicted)\ntest_score","1bedcc20":"X_prepaired = preprocessing_pipeline.transform(X)\n\ntuned_model.fit(X_prepaired, y)","f1496425":"X_final_test = pd.read_csv(os.path.join(DATA_PATH, TEST_FILENAME))\nX_final_test.describe()","48f677e7":"X_final_test_prepaired = preprocessing_pipeline.transform(X_final_test)\ny_final_test_predicted = tuned_model.predict(X_final_test_prepaired)\n\nprediction_submission = pd.concat(\n    [X_final_test[\"PassengerId\"], pd.Series(y_final_test_predicted, name=\"Survived\")],\n    axis=1\n)\nprediction_submission.head()","679165be":"# Save\n\nprediction_submission.to_csv(os.path.join(OUT_PATH, \"titanic-submission.csv\"), index=False)","a9ebb5f6":"## Predicting final_test set","df1bca28":"## Model evaluation on the test set","5313b831":"## Fine tuining\n### Randomized Parameter Optimization & Cross Validation","18eaeb9c":"## Load data","8bede3cb":"## Data preprocessing and transformation","966cf404":"### Cross validation","45d895d9":"## Create test set","7919e713":"## Model selection"}}