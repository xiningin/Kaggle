{"cell_type":{"e1113fee":"code","2822b69a":"code","524a7d74":"code","1d4fc0c6":"code","8c454740":"code","29002285":"code","eaf468f5":"code","fefba92f":"code","100667ca":"code","e7f7a99e":"code","82df02ec":"code","26119dd5":"code","03d105f5":"code","9cc821db":"code","056f5337":"code","ebc5931f":"code","9b904634":"code","5d5d5294":"code","4e4db9b1":"code","e2bc97e6":"code","ca829533":"code","2a5f3d81":"code","41ba56dc":"code","0f3aa897":"code","3997387f":"code","58334807":"code","f583cf8e":"markdown","d337b19c":"markdown","92634dbe":"markdown","3001e814":"markdown","d81544d3":"markdown","b5bb7f5d":"markdown","5a0c5c52":"markdown","aeb51db4":"markdown","26121520":"markdown","26faf0d0":"markdown","2bce1da4":"markdown","9e74bec3":"markdown","389ca720":"markdown","2f4c3d80":"markdown","119b5440":"markdown","8276b6ac":"markdown","7c149bc2":"markdown","76134221":"markdown","37ae6048":"markdown","b6f492f4":"markdown","c647f863":"markdown","dab2340b":"markdown","c7a108d5":"markdown","78e5abde":"markdown"},"source":{"e1113fee":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport matplotlib.gridspec as gridspec\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report ","2822b69a":"data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndata.head()","524a7d74":"number_of_fraud = len(data[data.Class == 1])\nnumber_of_normal= len(data[data.Class == 0])\n\nprint (\"Fraude:\", number_of_fraud)\nprint (\"Normal:\",number_of_normal)","1d4fc0c6":"sns.countplot(\"Class\",data=data)","8c454740":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\nbins = 50\n\nax1.hist(data.Time[data.Class == 1], bins = bins)\nax1.set_title('Fraude')\n\nax2.hist(data.Time[data.Class == 0], bins = bins)\nax2.set_title('Normal')\n\nplt.xlabel('Tempo')\nplt.ylabel('Numero de transacoes')\nplt.show()","29002285":"print (\"Fraude\")\nprint (data.Amount[data.Class == 1].describe())\nprint ()\nprint (\"Normal\")\nprint (data.Amount[data.Class == 0].describe())","eaf468f5":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\nbins = 10\n\nax1.hist(data.Amount[data.Class == 1], bins = bins)\nax1.set_title('Fraude')\n\nax2.hist(data.Amount[data.Class == 0], bins = bins)\nax2.set_title('Normal')\n\nplt.xlabel('Montante')\nplt.ylabel('Numero de transacoes')\nplt.show()","fefba92f":"PCA_features = data.iloc[:,1:29].columns","100667ca":"plt.figure(figsize=(12,28*4))\ngs = gridspec.GridSpec(28, 1)\nfor i, cn in enumerate(data[PCA_features]):\n    ax = plt.subplot(gs[i])\n    sns.distplot(data[cn][data.Class == 1], bins=50)\n    sns.distplot(data[cn][data.Class == 0], bins=50)\n    ax.set_xlabel('')\n    ax.set_title('histograma de recurso: ' + str(cn))\nplt.show()","e7f7a99e":"data = data.drop(['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8'], axis =1)\ndata.head()","82df02ec":"data['Normalized_Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\ndata.head()","26119dd5":"data = data.drop(['Time','Amount'],axis=1)\ndata.head()","03d105f5":"#\u00edndices of normal class\nindices_of_normal = data[data.Class==0].index\n#escolha aleatoriamente a mesma quantidade de amostras que a fraude e retorne seus \u00edndices\nrandom_indices_of_normal = np.array(np.random.choice(indices_of_normal, number_of_fraud, replace=False))\n#indices of fraud class\nindices_of_fraud = np.array(data[data.Class == 1].index)\n#indices of undersampled dataset\nindices_of_undersampled = np.concatenate([random_indices_of_normal, indices_of_fraud])\n#conjunto de dados com pouca amostra\ndata_of_undersampled = data.iloc[indices_of_undersampled,:]\n\nprint(len(data_of_undersampled))","9cc821db":"#conjunto de dados inteiro\nX = data.loc[:,data.columns!='Class']\ny = data.loc[:,data.columns=='Class']\n\n#treinar e testar o conjunto de dados dividido em todo o conjunto de dados, com propor\u00e7\u00e3o 70\/30\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n\nprint(\"Numero de transacoes treinar conjunto de dados: \", len(X_train))\nprint(\"Conjunto de dados de teste de transacoes numericas: \", len(X_test))\nprint(\"Numero total de transacoes: \", len(X_train)+len(X_test))","056f5337":"#conjunto de dados com pouca amostra\nX_undersampled = data_of_undersampled.loc[:,data_of_undersampled.columns!='Class']\ny_undersampled = data_of_undersampled.loc[:,data_of_undersampled.columns=='Class']\n\n#conjunto de dados de trem e teste dividido a partir de um conjunto de dados com pouca amostra, com raz\u00e3o 70\/30\nX_train_undersampled, X_test_undersampled, y_train_undersampled, y_test_undersampled = train_test_split(X_undersampled,y_undersampled,test_size = 0.3, random_state = 0)\n\nprint(\"Numero de transacoes treinar conjunto de dados: \", len(X_train_undersampled))\nprint(\"Conjunto de dados de teste de transacoes numericas: \", len(X_test_undersampled))\nprint(\"Numero total de transacoes: \", len(X_train_undersampled)+len(X_test_undersampled))","ebc5931f":"def train(model,X,y):\n    \n    # Recordar para o modelo\n    clf = model\n    \n    # Diferentes par\u00e2metros C para regulariza\u00e7\u00e3o\n    C_param = [0.01,0.1,1,10,100]\n\n    # Valida\u00e7\u00e3o cruzada do K-Fold\n    kf = KFold(n_splits=5)\n    \n    # Inicializacao\n    scores     =[]\n    best_score = 0\n    best_C     = 0\n    \n    for C in C_param:\n        \n        clf.C = C\n\n        score = []\n        for train_index, test_index in kf.split(X): \n\n            # Use os dados de treinamento divididos para ajustar-se ao modelo.\n            clf.fit(X.iloc[train_index,:].values,y.iloc[train_index,:].values.ravel())\n\n            # Prever valores usando os dados de teste divididos\n            y_pred = clf.predict(X.iloc[test_index,:].values)\n            \n            # Calcular a pontua\u00e7\u00e3o de rechamada e anex\u00e1-la a uma lista de pontua\u00e7\u00f5es de rechamada representando o par\u00e2metro c_ atual\n            rec = recall_score(y.iloc[test_index,:].values.ravel(),y_pred)\n            \n            # Anexar pontua\u00e7\u00e3o de recordar de cada itera\u00e7\u00e3o \u00e0 pontua\u00e7\u00e3o\n            score.append(rec)\n\n        # Calcule a pontua\u00e7\u00e3o m\u00e9dia real para todas as itera\u00e7\u00f5es e compare-a com a melhor pontua\u00e7\u00e3o.\n        mean_score = np.mean(score)\n        if mean_score > best_score:\n            best_score = mean_score\n            best_C     = C\n        \n        # Anexar a pontua\u00e7\u00e3o m\u00e9dia de cada C \u00e0s pontua\u00e7\u00f5es\n        scores.append(np.mean(score))\n        \n    # Crie um quadro de dados para mostrar a pontua\u00e7\u00e3o m\u00e9dia para cada par\u00e2metro C    \n    lr_results = pd.DataFrame({'Pontuacao':scores, 'C':C_param}) \n    print(lr_results)\n    \n    print(\"A melhor pontuacao de recordacao eh: \", best_score)\n    print(\"O melhor parametro C eh: \", best_C)\n    \n    return best_score, best_C","9b904634":"def predict(model, X_train, y_train, X_test, y_test):\n    # Recordar para o modelo\n    clf = model\n    #clf = Regress\u00e3o log\u00edstica (C = C, penalidade = 'l1')\n    # Use todo o conjunto de dados de trem com pouca amostra para ajustar-se ao modelo.\n    clf.fit(X_train.values,y_train.values.ravel())\n    # Previs\u00e3o no conjunto de dados de teste com pouca amostra\n\n    y_pred = clf.predict(X_test.values)\n\n    # Matriz de confus\u00e3o\n    CM = confusion_matrix(y_test.values, y_pred)\n    # Obter verdadeiros positivos (tp), falsos positivos (fp), falsos negativos (fn)\n    tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n\n    # Prediction report\n    sns.heatmap(CM,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\n    plt.title(\"Matriz_de_confusao\")\n    plt.xlabel(\"Classe_prevista\")\n    plt.ylabel(\"Classe Real\")\n    plt.show()\n    print(\"\\n----------Relatorio de classificacao------------------------------------\")\n    print(classification_report(y_test.values, y_pred))","5d5d5294":"clf = LogisticRegression(penalty = 'l2', solver ='lbfgs')\nbest_score, best_C = train(clf, X_train_undersampled,y_train_undersampled)","4e4db9b1":"clf = LogisticRegression(C=best_C, penalty = 'l2', solver ='lbfgs')\npredict(clf, X_train_undersampled,y_train_undersampled,X_test_undersampled,y_test_undersampled)","e2bc97e6":"predict(clf,X_train_undersampled,y_train_undersampled,X_test,y_test)","ca829533":"clf = LogisticRegression(penalty = 'l2',solver ='lbfgs')\nbest_score_whole, best_C_whole = train(clf,X_train,y_train)","2a5f3d81":"clf = LogisticRegression(C=best_C_whole,penalty = 'l2',solver='lbfgs')\npredict(clf,X_train,y_train,X_test,y_test)","41ba56dc":"clf = SVC(gamma='auto')\nbest_score, best_C = train(clf, X_train_undersampled,y_train_undersampled)","0f3aa897":"clf = SVC(C=best_C,gamma='auto')\npredict(clf, X_train_undersampled,y_train_undersampled,X_test_undersampled,y_test_undersampled)","3997387f":"predict(clf,X_train_undersampled,y_train_undersampled,X_test,y_test)","58334807":"predict(clf,X_train,y_train,X_test,y_test)","f583cf8e":"\n# 4. Prepare o conjunto de dados de treinamento e teste","d337b19c":"# Detec\u00e7\u00e3o de fraude no cart\u00e3o de cr\u00e9dito.\n\nEste kernel \u00e9 minha tentativa de aprender o b\u00e1sico do Machine Learning. \n\nH\u00e1 grande importancia que \u00e1s empresas de cart\u00e3o de cr\u00e9dito possam reconhecer\ntransa\u00e7\u00f5es fraudulentas com cart\u00e3o de cr\u00e9dito, para que os clientes n\u00e3o sejam cobrados pelos\nitens que n\u00e3o compraram. A base cont\u00e9m transa\u00e7\u00f5es realizadas com cart\u00f5es de cr\u00e9dito em\nsetembro de 2013 por portadores de cart\u00f5es europeus, com intuito de analisar as transa\u00e7\u00f5es\nfraudulentas.\n\nAlunos: Elvis A. Barbosa \/ Vinicius R. Martins\n\n\n### Index \n1. Importando bibliotecas e dados\n2. Explorar dados\n3. Reamostrar dados\n4. Prepare o conjunto de dados de treinamento e teste\n5. Aplique diferentes classificadores","92634dbe":"\nClaramente, os dados est\u00e3o totalmente desequilibrados!\nAbordagens:\n1. reamostrar dados (subamostragem \/ superamostragem) e, em seguida, aplicar diferentes classificadores\n2. log\u00edstica de Regress\u00e3o\n3. SVM","3001e814":"\nSegundo, treine em todo o conjunto de dados de trem com pouca amostra e preveja no conjunto de dados de teste com pouca amostra","d81544d3":"Nesse caso, podemos ver que 58 das 147 fraudes n\u00e3o foram previstas corretamente. Portanto, \u00e9 \u00f3bvio que, ao subamostrar os dados, aprimoramos o recordar de 61% para 93%. A subamostragem com regress\u00e3o log\u00edstica funciona muito bem para esse problema. Ent\u00e3o, que tal outros classificadores? Como melhoramos ainda mais a precis\u00e3o da previs\u00e3o?","b5bb7f5d":"* Parece que para as v8, v13, v15, v20, v23, v24, v25, v26, v27, v28, elas t\u00eam distribui\u00e7\u00e3o semelhante entre os dois tipos de transa\u00e7\u00f5es. Para a sele\u00e7\u00e3o de recursos, podemos descartar esses recursos.","5a0c5c52":"Agora, vejamos os recursos gerados por PCA, como cada recurso se correlaciona com a classe.\n\nPCA(\u00e9 um procedimento matem\u00e1tico que utiliza uma transforma\u00e7\u00e3o ortogonal (ortogonaliza\u00e7\u00e3o de vetores) para converter um conjunto de observa\u00e7\u00f5es de vari\u00e1veis possivelmente correlacionadas num conjunto de valores de vari\u00e1veis linearmente n\u00e3o correlacionadas chamadas de componentes principais).","aeb51db4":"\n# 5. Aplique diferentes classificadores","26121520":"\n# 3. Reamostrando dados","26faf0d0":"# Explorar recursos","2bce1da4":"# log\u00edstica de Regress\u00e3o","9e74bec3":"SVM (Uma m\u00e1quina de vetores de suporte \u00e9 um conceito na ci\u00eancia da computa\u00e7\u00e3o para um conjunto de m\u00e9todos do aprendizado supervisionado que analisam os dados e reconhecem padr\u00f5es, usado para classifica\u00e7\u00e3o e an\u00e1lise de regress\u00e3o. O SVM padr\u00e3o toma como entrada um conjunto de dados e prediz, para cada entrada dada, qual de duas poss\u00edveis classes a entrada faz parte, o que faz do SVM um classificador linear bin\u00e1rio n\u00e3o probabil\u00edstico.","389ca720":"\n# 2. Explorar os dados","2f4c3d80":"## 1. Importando bibliotecas e dados","119b5440":"\nDefinir uma fun\u00e7\u00e3o para treinar dados com diferentes classificadores com valida\u00e7\u00e3o cruzada K-Fold para obter o melhor par\u00e2metro C.\n\n(O m\u00e9todo de valida\u00e7\u00e3o cruzada denominado k-fold consiste em dividir o conjunto total de dados em k subconjuntos mutuamente exclusivos do mesmo tamanho e, a partir da\u00ed, um subconjunto \u00e9 utilizado para teste e os k-1 restantes s\u00e3o utilizados para estima\u00e7\u00e3o dos par\u00e2metros, fazendo-se o c\u00e1lculo da acur\u00e1cia do modelo. Este processo \u00e9 realizado k vezes alternando de forma circular o subconjunto de teste).","8276b6ac":"\nSubamostragem: com base na propor\u00e7\u00e3o 50\/50, escolha aleatoriamente amostras da classe normal","7c149bc2":"\nParece que as transa\u00e7\u00f5es fraudulentas s\u00e3o distribu\u00eddas de maneira mais uniforme, enquanto as transa\u00e7\u00f5es normais t\u00eam uma distribui\u00e7\u00e3o c\u00edclica. Vamos olhar a quantidade.","76134221":"A partir da matriz de confus\u00e3o, podemos ver que apenas 12 das 149 amostras de fraude n\u00e3o foram previstas corretamente. E o modelo alcan\u00e7ou 93% de precis\u00e3o de recordar. Isso \u00e9 muito bom, vamos tentar o modelo para prever todo o conjunto de dados de teste em vez do conjunto de dados de teste com pouca amostra.","37ae6048":"Definir uma fun\u00e7\u00e3o para usar o melhor par\u00e2metro C para treinar em diferentes conjuntos de dados de treinamento e prever em diferentes conjuntos de dados de teste; Plote confusion_matrix (existe uma fun\u00e7\u00e3o oficial para plotar matriz de confus\u00e3o no sklearn: http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html) e imprima o relat\u00f3rio de classifica\u00e7\u00e3o.","b6f492f4":"Vamos tentar o mesmo processo que a regress\u00e3o log\u00edstica. Primeiro ajustar o modelo no conjunto de dados com pouca amostra, prever o conjunto de dados de teste com pouca amostra e o conjunto de dados de teste inteiro, depois ajustar o modelo no conjunto de dados inteiro e prever o conjunto de dados de teste inteiro.","c647f863":"Primeiro, treine dados com pouca amostragem com o modelo de regress\u00e3o log\u00edstica + valida\u00e7\u00e3o cruzada do K-Fold para obter o melhor par\u00e2metro C\n\n(O modelo de regress\u00e3o log\u00edstica \u00e9 semelhante ao modelo de regress\u00e3o linear. No entanto, no modelo log\u00edstico a vari\u00e1vel resposta Y_i \u00e9 bin\u00e1ria. Uma vari\u00e1vel bin\u00e1ria assume dois valores, como por exemplo, Y_i=0 e Y_i=1, denominados \"fracasso\" e \"sucesso\", respectivamente).","dab2340b":"\nEscala de recursos","c7a108d5":"A precis\u00e3o da rechamada \u00e9 quase a mesma (11 em 147) que a prevista no conjunto de dados de teste com pouca amostra. Portanto, parece que o modelo funciona bem com a subamostragem. Ent\u00e3o, que tal aplicar o mesmo modelo em todos os conjuntos de dados sem reamostrar?\nTreinaremos todo o conjunto de dados com o mesmo modelo de regress\u00e3o log\u00edstica com valida\u00e7\u00e3o cruzada e regulariza\u00e7\u00e3o K-Fold para obter o melhor par\u00e2metro C, depois usaremos esse par\u00e2metro para treinar e prever todo o conjunto de dados de trem e teste.","78e5abde":"# SVM"}}