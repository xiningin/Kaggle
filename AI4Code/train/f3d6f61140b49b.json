{"cell_type":{"6a854d85":"code","37f416cb":"code","0ffb328d":"code","657dbc59":"code","40039fb7":"code","0b0c0d4e":"code","c7c820c9":"code","8a41604a":"code","6b7adce2":"code","6aae0711":"code","5e2b4b95":"code","24178b59":"code","589ebe9e":"code","dc7e14f8":"code","353a4151":"code","30fd93b9":"code","5f828e02":"code","9def69da":"code","13f3c913":"code","89e347da":"code","ce344373":"code","9767b48f":"code","73542d0a":"code","c14c4d45":"code","1b468c5f":"code","002f605a":"code","12faa347":"code","62219d4e":"code","611e0fd7":"code","97f84d70":"code","167a4a9b":"code","635b8032":"code","1664fc3a":"code","4d2ff7ff":"code","c368b646":"code","b0485ede":"code","4744f1fa":"code","ec4a9a4a":"code","c3cdc7b7":"code","3f30baf4":"code","049da8dd":"code","652826d5":"code","1641ad85":"code","2a007fa3":"code","131508a1":"markdown","be767d1b":"markdown","adb00324":"markdown","e47c59a3":"markdown","22d18e2f":"markdown","53b20981":"markdown","420ddcc1":"markdown","b29bd199":"markdown","c1502136":"markdown","b23cd1a3":"markdown","6c04cc4b":"markdown","7bb2e600":"markdown","6f13d71b":"markdown","b4848c3d":"markdown","46bbe471":"markdown","080c6d52":"markdown","ddcfb7f6":"markdown","b1786fdb":"markdown","86a7a1e7":"markdown","1415cff1":"markdown","c08bf387":"markdown","2dd2d8d9":"markdown"},"source":{"6a854d85":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\nimport random\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport sklearn as sk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport ast\nimport warnings\nimport json\n\nimport itertools\nfrom collections import Counter\n\n\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport xgboost as xgb\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\n\n# Any results you write to the current directory are saved as output.\n%matplotlib inline\nwarnings.filterwarnings('ignore')","37f416cb":"sns.set(style ='darkgrid')\nsns.set(palette = 'muted')\ncol = sns.color_palette()\nsns.palplot(col)","0ffb328d":"def plot_2y(df,x,y1,y2):\n    fig,ax1 = plt.subplots(figsize = (15,10))\n    ax1.plot(df[x],df[y1],'ro-')\n    ax2 =ax1.twinx()\n    ax2.plot(df[x], df[y2],'bo-')\n    ax1.set_xlabel(x)\n    ax1.set_ylabel(y1)\n    ax2.set_ylabel(y2)\n    if x == 'Month ':\n        plt.title('Monthly delay incidents between '+ str(df['Month '].dt.year.min()) + ' and ' + str(df['Month '].dt.year.max()))\n    else:\n        plt.title(y1+' and '+ y2 +' vs '+ x)\n    ax1.legend()\n    ax2.legend(loc=1)\n    plt.xticks(rotation = 45)\n    plt.tight_layout()\n    plt.show()","657dbc59":"def plot_scatter(df,xdata,ydata1,ydata2=None,ydata3=None):\n    plt.figure(figsize = (15,10))\n    plt.scatter(df[xdata],df[ydata1],c='r')\n    if pd.notna(ydata2):\n        plt.scatter(df[xdata],df[ydata2],c='b')\n        if pd.notna(ydata3):\n            plt.scatter(df[xdata],df[ydata3],c='k')\n    else:\n        plt.ylabel(ydata1)\n    plt.xlabel(xdata)\n    plt.title(ydata1 + ' vs ' + xdata)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()","40039fb7":"def booleanBoxPlot(df, bool_feature, other_feature, lang):\n    \"\"\" Box plot of values of other_feature when bool_feature == True and \n    bool__feature == False\"\"\"\n    \n    fig = plt.figure(figsize=(15, 10))\n    \n    sns.boxplot(x = bool_feature, y = other_feature, data = df, whis=[10, 90], showfliers  = False)\n    plt.xlabel(bool_feature)\n    plt.ylabel(other_feature)\n    \n    title = other_feature + ' distributed by ' + bool_feature + ' for ' + lang\n    plt.suptitle(title)","0b0c0d4e":"def roundup(x):\n    return int(math.floor(x\/10.0)) * 10","c7c820c9":"def json_to_dict(df, field):\n     df.loc[df[field].notnull(), field] = df.loc[df[field].notnull(),field].apply(lambda x: x.lstrip('\\\"([').rstrip(']\\\")')).apply(eval) ","8a41604a":"def get_json_dict(s):\n    \"\"\" indirect way of converting json into python dictionary \"\"\"\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d","6b7adce2":"def get_director(df):\n    for index,row in df.iterrows():\n        allCrew = get_json_dict(row['crew'])\n        director = next((x['name'] for x in allCrew if ('name' in x) and ('job' in x) and (x['job'] == 'Director')),None)\n        df.loc[index,'Director'] = director","6aae0711":"def get_cast(df):\n    for index,row in df.iterrows():\n        allCast = get_json_dict(row['cast'])\n        lead = next((x['name'] for x in allCast if ('name' in x)),None)\n        df.loc[index,'Lead'] = lead","5e2b4b95":"def dict_to_list(df, field):\n    if field == 'genres':\n        findex = 1\n    else:\n        findex = 0\n    for index,row in df.loc[df[field].notna(),field].iteritems():\n        if type(row) is dict:\n            df.loc[index,field] = list(row.values())[findex]\n        elif type(row) is tuple:\n            field_list = []\n            for i in np.arange(len(row)):\n                field_list.append(list(row[i].values())[findex])\n            df.at[index,field] = field_list","24178b59":"def transform_ridge(df, top_languages = [], top_directors = [], top_cast = [], additional = 0, ohe_director = 0, ohe_cast = 0):\n\n    df_copy = df.copy()\n    df_copy['release_date'] = pd.to_datetime(df_copy['release_date'], infer_datetime_format = True)\n    df_copy['year'] = df_copy.loc[df_copy['release_date'].notna(),'release_date'].dt.year\n    df_copy['year'] = df_copy['year'].apply(lambda x: x-100 if x> 2019 else x)\n    df_copy['year'].fillna(df_copy['year'].median(), inplace = True)\n    df_copy['year'] = df_copy['year'].astype('int64')\n    \n    df_copy['dayofrelease'] = df_copy.loc[df_copy['release_date'].notna(),'release_date'].dt.dayofweek\n    df_copy['dayofrelease'].fillna(df_copy['dayofrelease'].median(),inplace = True)\n        \n    # No budget correction except changing all 0 values to 1\n    df_copy.loc[df_copy['budget'] == 0,'budget'] = 1\n    df_copy['log_budget'] = df_copy['budget'].apply(math.log)  \n    \n    # Run time of the movie\n    df_copy['runtime'].fillna(df_copy['runtime'].median(),inplace = True)\n    \n    # One hot encoding of collection and homepage\n    df_copy.loc[df_copy['belongs_to_collection'].notna(),'belongs_to_collection'] = 1\n    df_copy.loc[df_copy['belongs_to_collection'].isna(),'belongs_to_collection'] = 0\n    \n    df_copy.loc[df_copy['homepage'].notna(),'homepage'] = 1\n    df_copy.loc[df_copy['homepage'].isna(),'homepage'] = 0\n    \n    df_copy.loc[df_copy['tagline'].notna(),'has_tag'] = 1\n    df_copy.loc[df_copy['tagline'].isna(),'has_tag'] = 0\n    \n    df_copy.loc[df_copy['status'] == 'Released','released'] = 1\n    df_copy.loc[df_copy['status'] == 'Post Production','released'] = 0\n    df_copy.loc[df_copy['status'] == 'Rumored','released'] = 0\n    df_copy.loc[df_copy['status'].isna(),'released'] = 0\n    \n    # df_copy['popularity'] = np.log(df_copy['popularity'])\n    features = ['year','dayofrelease','log_budget','runtime','belongs_to_collection','homepage', 'has_tag', 'released','popularity']\n    \n    if 'revenue' in df.columns:\n        top_languages = list(train['original_language'].value_counts().index[0:10])\n        df_copy.loc[~df_copy['original_language'].isin(top_languages),'original_language'] = 'other lang'\n        # One hot encoding of top 10 original languages and the rest as others\n        ohe = OneHotEncoder(handle_unknown='ignore')\n        lang_ohe = ohe.fit_transform(np.array(df_copy['original_language']).reshape(-1,1))\n        df_copy_lang = pd.DataFrame(data = lang_ohe.toarray(), columns = ohe.categories_[0])\n        top_languages = ohe.categories_[0]\n\n    else:\n        df_copy.loc[~df_copy['original_language'].isin(top_languages), 'original_language'] ='other lang'\n        ohe = OneHotEncoder(handle_unknown='ignore')\n        lang_ohe = ohe.fit_transform(np.array(df_copy['original_language']).reshape(-1,1))\n        df_copy_lang = pd.DataFrame(data = lang_ohe.toarray(), columns = ohe.categories_[0])\n    \n    df_copy = df_copy.merge(df_copy_lang, left_index = True, right_index = True) \n    features.extend(top_languages)\n    \n    # If this flag is set, then we add the additional features like genre, production countries etc. \n    if additional == 1:\n        json_to_dict(df_copy,'production_countries')\n        dict_to_list(df_copy,'production_countries')\n        df_copy['US production'] = df.loc[df['production_countries'].notnull(),'production_countries'].apply(lambda x: 1 if 'US' in x else 0)\n        df_copy['US production'].fillna(0,inplace = True)\n        features.append('US production')\n\n        big_productions = ['Paramount Pictures','Universal Pictures','Metro-Goldwyn-Mayer (MGM)', 'Warner Bros.','Twentieth Century Fox Film Corporation']\n        json_to_dict(df_copy,'production_companies')\n        dict_to_list(df_copy,'production_companies')\n        df_copy['Big production'] = df_copy.loc[df_copy['production_companies'].notnull(),'production_companies'].apply(lambda x: 1 if any(comp in x for comp in big_productions) else 0)\n        df_copy['Big production'].fillna(0,inplace = True)\n        features.append('Big production')\n        \n        df_copy.loc[df_copy['production_companies'].notnull(),'production_companies'] = df_copy.loc[df_copy['production_companies'].notnull(),'production_companies'].apply(lambda x: [x] if type(x) is str else x)\n        df_copy['no_production_companies'] = df_copy.loc[df_copy['production_companies'].notnull(),'production_companies'].apply(len)\n        df_copy['no_production_companies'].fillna(0,inplace = True)\n        features.append('no_production_companies')\n        \n        top_genres = ['Drama','Comedy','Action','Thriller','Romance']\n        json_to_dict(df_copy,'genres')\n        dict_to_list(df_copy,'genres')\n        df_copy['Top genres'] = df_copy.loc[df_copy['genres'].notnull(),'genres'].apply(lambda x: 1 if any(genre in x for genre in top_genres) else 0)\n        df_copy['Top genres'].fillna(0, inplace = True)\n        features.append('Top genres')\n        \n        json_to_dict(df_copy,'spoken_languages')\n        dict_to_list(df_copy,'spoken_languages')\n        df_copy.loc[df_copy['spoken_languages'].notnull(),'spoken_languages'] = df_copy.loc[df_copy['spoken_languages'].notnull(),'spoken_languages'].apply(lambda x: [x] if type(x) is str else x)\n        df_copy['no_languages'] = df_copy.loc[df_copy['spoken_languages'].notnull(),'spoken_languages'].apply(len)\n        df_copy['no_languages'].fillna(0,inplace = True)\n        features.append('no_languages')\n        \n        df_copy.loc[df_copy['spoken_languages'].notnull(),'english_spoken'] = df_copy.loc[df_copy['spoken_languages'].notnull(),'spoken_languages'].apply(lambda x: 1 if 'en' in x else 0) \n        df_copy['english_spoken'].fillna(0, inplace = True)\n        features.append('english_spoken')\n        \n        get_director(df_copy)\n        if 'revenue' in df.columns:\n            # revenue_cutoff = df_copy['revenue'].min() + (0.75) * (df_copy['revenue'].max() - df_copy['revenue'].min())\n            revenue_cutoff = df_copy['revenue'].quantile(0.75)\n            top_movies    = df_copy.loc[df_copy['revenue'] >= revenue_cutoff]\n            top_directors = list(top_movies['Director'].value_counts().index[0:10])\n            \n        if ohe_director == 1:\n            df_copy.loc[~df_copy['Director'].isin(top_directors), 'Director'] = 'other dir'\n            direct_ohe = ohe.fit_transform(np.array(df_copy['Director']).reshape(-1,1))\n            df_copy_direct = pd.DataFrame(data = direct_ohe.toarray(), columns = ohe.categories_[0])\n            top_directors = ohe.categories_[0]\n            df_copy = df_copy.merge(df_copy_direct, left_index = True, right_index = True)\n            features.extend(top_directors)\n        else:\n            df_copy.loc[df_copy['Director'].notnull(),'top_directors'] = df_copy.loc[df_copy['Director'].notnull(),'Director'].apply(lambda x: 1 if x in top_directors else 0)\n            df_copy['top_directors'].fillna(0,inplace = True)\n            features.append('top_directors')\n        \n        get_cast(df_copy)\n        if 'revenue' in df.columns:\n            revenue_cutoff = df_copy['revenue'].quantile(0.75)\n            top_movies     = df_copy.loc[df_copy['revenue'] >= revenue_cutoff]\n            top_cast       = list(top_movies['Lead'].value_counts().index[0:10]) \n        if ohe_cast == 1:\n            df_copy.loc[~df_copy['Lead'].isin(top_cast), 'Lead'] = 'other actors'\n            cast_ohe = ohe.fit_transform(np.array(df_copy['Lead']).reshape(-1,1))\n            df_copy_cast = pd.DataFrame(data = cast_ohe.toarray(), columns = ohe.categories_[0])\n            top_cast = ohe.categories_[0]\n            df_copy = df_copy.merge(df_copy_cast, left_index = True, right_index = True)\n            features.extend(top_cast)\n        else:\n            df_copy.loc[df_copy['Lead'].notnull(),'top_cast'] = df_copy.loc[df_copy['Lead'].notnull(),'Lead'].apply(lambda x: 1 if x in top_cast else 0)\n            df_copy['top_cast'].fillna(0, inplace = True)\n            features.append('top_cast')\n        \n        if 'revenue' in df_copy.columns:\n            df_copy['log_revenue'] = df_copy['revenue'].apply(math.log)\n            features.append('log_revenue')\n        df_out = df_copy[features]\n        print(df_out.columns)\n    return df_out, top_languages, top_directors, top_cast","589ebe9e":" def cross_validation(train_df, k = 1):\n    # alpha_val  = [0.1, 0.5, 1, 2, 5, 10]\n    alpha_val = np.arange(0,2,0.01)\n    rmsle = {}\n    rmsle_alpha = {}\n    train_size = train_df.shape[0]\n    train_splits = {}\n    for fold in np.arange(k):\n        train_splits[fold] = train_df.loc[fold * train_size\/k : (fold+1) * (train_size\/k) -1,:]\n        \n    for i,alpha in enumerate(alpha_val):\n        rmsle[i] = []\n        rmsle_alpha[i] =[]\n        for fold in np.arange(k):\n            train_cv = train_splits[fold%k].iloc[:,:-1].append(train_splits[(fold+1)%k].iloc[:,:-1]).append(train_splits[(fold+2)%k].iloc[:,:-1])\n            train_label = train_splits[fold%k].loc[:,'log_revenue'].append(train_splits[(fold+1)%k].loc[:,'log_revenue']).append(train_splits[(fold+2)%k].loc[:,'log_revenue'])\n            test_cv = train_splits[(fold+3)%k].iloc[:,:-1]\n            test_label = train_splits[(fold+3)%k].loc[:,'log_revenue']\n        \n            clf = Ridge(alpha=alpha, normalize = True)\n            # Normalizing is not the same as standard scaling - Standard scaling is more appropriate for getting the features on the same range\n            clf.fit(train_cv,train_label)\n            rmsle[i].append(np.sqrt(mean_squared_error(test_label, clf.predict(test_cv))))\n        rmsle_alpha[i] = np.mean(rmsle[i])\n        \n\n    print('Lowest RMSLE value on cross-validation -', min(rmsle_alpha))\n    alpha_best = alpha_val[np.argmin(rmsle_alpha)]\n    \n    plt.figure()\n    plt.plot(alpha_val,rmsle_alpha.values(),'r-')\n    plt.xlabel('alpha')\n    plt.ylabel('RMSLE')\n    plt.title('Cross-validation for alpha')\n    plt.show()\n    \n    return alpha_best","dc7e14f8":"def ridge_regression_model(train_df, test_df , alpha_best, no_models = 2):\n    train_df = train_df.copy()\n    test_df = test_df.copy()\n    if no_models == 1:\n        clf_all = Ridge(alpha = alpha_best, normalize = False)\n        features = list(train_df.columns)\n        clf_all.fit(train_df.loc[:,features[:-1]], train_df.loc[:,'log_revenue'])\n        train_df.loc[:,'log_revenue_pred'] = clf_all.predict(train_df.loc[:,features[:-1]])\n\n        \n    elif no_models == 2:\n        # Two separate models, one for those with budget, others for those without budget\n        clf_budget = Ridge(alpha=alpha_best, normalize = False)\n        features = list(train_df.columns)\n        clf_budget.fit(train_df.loc[train_df['log_budget']<=np.log(10000),features[:-1]],\n                       train_df.loc[train_df['log_budget']<=np.log(10000),'log_revenue'])\n        train_df.loc[train_df['log_budget']<=np.log(10000),'log_revenue_pred'] =  clf_budget.predict(train_df.loc[train_df['log_budget']<=np.log(10000),features[:-1]])\n                                                                                                                  \n        clf_no_budget = Ridge(alpha = alpha_best, normalize = False)\n        features.remove('log_budget')\n        clf_no_budget.fit(train_df.loc[train_df['log_budget']>np.log(10000),features[:-1]], \n                          train_df.loc[train_df['log_budget']>np.log(10000),'log_revenue'])\n        train_df.loc[train_df['log_budget']>np.log(10000),'log_revenue_pred'] =  clf_no_budget.predict(train_df.loc[train_df['log_budget']>np.log(10000),features[:-2]])\n\n    print('RMSLE on training set', np.sqrt(mean_squared_error(train_df['log_revenue'],train_df['log_revenue_pred'])))\n    \n    # Testing\n    if 'log_revenue_pred' not in test_df.columns:\n        if no_models == 1:\n            test_df.loc[:,'log_revenue_pred'] = clf_all.predict(test_df)\n        elif no_models == 2:\n            test_df.loc[test_df['log_budget']<=np.log(10000),'log_revenue_pred'] = clf_budget.predict(test_df.loc[test_df['log_budget']<=np.log(10000)])\n            test_df.loc[test_df['log_budget']>np.log(10000),'log_revenue_pred'] = clf_no_budget.predict(test_df.loc[test_df['log_budget']>np.log(10000),features[:-1]])\n    return test_df","353a4151":"def file_for_submission(test_df):\n    test_df['id'] = np.arange(3001,7399)\n    test_df['revenue'] = test_df['log_revenue_pred'].apply(np.exp)\n    test_df[['id','revenue']].to_csv('submission.csv',index = False)","30fd93b9":"train = pd.read_csv('..\/input\/train.csv')\ntest  = pd.read_csv('..\/input\/test.csv')","5f828e02":"def ridge_test(df_train, df_test):\n    train_copy,top_lang,top_direct,top_cast = transform_ridge(df_train, additional =1, ohe_director = 1, ohe_cast = 1)\n    print(train_copy.head())\n    test_copy,_,_,_ = transform_ridge(df_test, top_lang, top_direct, top_cast, additional =1, ohe_director = 1, ohe_cast = 1)\n    print(test_copy.head())\n    alpha_best = cross_validation(train_copy)\n    df_test = ridge_regression_model(train_copy, test_copy, alpha_best, no_models = 1)\n    return df_test","9def69da":"test_filled_ridge = ridge_test(train,test)","13f3c913":"test_filled_ridge.head()","89e347da":"file_for_submission(test_filled_ridge)","ce344373":"def random_forest_test(df_train, df_test):\n    train_copy,top_lang,top_direct,top_cast = transform_ridge(df_train, additional =1,ohe_director = 1, ohe_cast=1)\n    test_copy,_,_,_ = transform_ridge(df_test, top_lang, top_direct, top_cast, additional =1, ohe_director = 1, ohe_cast = 1)\n    rf_reg = RandomForestRegressor(criterion = 'mse', max_depth = 10, n_estimators = 100)\n    rf_reg.fit(train_copy.iloc[:,:-1],train_copy.iloc[:,-1])\n    train_copy['log_revenue_pred'] = rf_reg.predict(train_copy.iloc[:,:-1])\n    print('RMSLE on training data', np.sqrt(mean_squared_error(train_copy['log_revenue'],train_copy['log_revenue_pred'])))\n    \n    test_copy['log_revenue_pred']  = rf_reg.predict(test_copy)\n    return test_copy","9767b48f":"test_filled_rf = random_forest_test(train, test)","73542d0a":"file_for_submission(test_filled_rf)","c14c4d45":"test_filled_rf.head()","1b468c5f":"def xgb_test(df_train,df_test):\n    train_copy,top_lang,top_direct,top_cast = transform_ridge(df_train, additional =1,ohe_director = 1, ohe_cast=1)\n    test_copy,_,_,_ = transform_ridge(df_test, top_lang, top_direct, top_cast, additional =1, ohe_director =1, ohe_cast = 1)\n    xgb_reg = xgb.XGBRegressor(max_depth = 5, learning_rate = 0.05, n_estimators= 500)\n    xgb_reg.fit(train_copy.iloc[:,:-1],train_copy.iloc[:,-1])\n    train_copy['log_revenue_pred'] = xgb_reg.predict(train_copy.iloc[:,:-1])\n    print('RMSLE on training data', np.sqrt(mean_squared_error(train_copy['log_revenue'],train_copy['log_revenue_pred'])))\n    \n    test_copy['log_revenue_pred'] = xgb_reg.predict(test_copy)\n    return test_copy","002f605a":"test_filled_xgb  = xgb_test(train, test)","12faa347":"file_for_submission(test_filled_xgb)","62219d4e":"test_filled_xgb.head()","611e0fd7":"test_filled_xgb[['id','revenue']].to_csv('submission.csv',index = False)","97f84d70":"plot_scatter(train_copy[train_copy['log_budget']!=0],'log_budget','log_revenue')","167a4a9b":"train_yearly = train_copy.groupby(train_copy['year']).aggregate({'log_revenue' : 'mean', 'log_budget':'mean', 'id':'count'}).reset_index()\ntrain_yearly.rename(columns ={'id':'Number','log_revenue':'mean_log_revenue','log_budget':'mean_log_budget'}, inplace = True)","635b8032":"plt.figure()\ntrain_yearly.plot(x = 'year', y= 'mean_log_revenue', kind = 'bar',figsize =(25,10))\nplt.tight_layout()\nplt.show()","1664fc3a":"plot_2y(train_yearly,'year','mean_log_revenue','Number')","4d2ff7ff":"plt.figure()\ntrain_yearly.plot(x = 'year', y=['mean_log_budget','mean_log_revenue'], kind = 'bar',figsize =(25,10))\nplt.tight_layout()\nplt.show()","c368b646":"train['decade'] = train['year'].apply(roundup)\ntrain_decade = train.groupby(train['decade']).aggregate({'log_budget':'mean','log_revenue':'mean', 'id':'count'}).reset_index()\ntrain_decade.rename(columns = {'log_budget':'mean_log_budget', 'log_revenue':'mean_log_revenue'}, inplace = True)","b0485ede":"plt.figure()\ntrain_decade.plot(x = 'decade', y=['mean_log_budget','mean_log_revenue'], kind = 'bar',figsize =(15,10))\nplt.tight_layout()\nplt.title('Decade-wise mean log budget v mean log revenue',fontsize = 15)\nplt.show()","4744f1fa":"train_lang_table = train['original_language'].value_counts().reset_index()\ntrain_lang_table.rename(columns={'index':'language', 'original_language':'Number'},inplace= True)","ec4a9a4a":"train_lang_table.loc[10,'language']='others'\ntrain_lang_table.loc[10,'Number'] = train_lang_table.loc[10:,'Number'].sum()","c3cdc7b7":"train_lang_table[0:11]","3f30baf4":"train_lang = {}\nno_lang = 9\ni = 0\nplt.figure(figsize = (15,10))\nfor lang in train['original_language'].unique()[0:no_lang]:\n    train_lang[lang] = train[train['original_language']== lang]\n    x = train_lang[lang][train_lang[lang]['log_budget']!=0]['log_budget']\n    y = train_lang[lang][train_lang[lang]['log_budget']!=0]['log_revenue']\n    A = np.vstack([np.array(x), np.ones(len(x))]).T\n    m, c = np.linalg.lstsq(A,np.array(y), rcond=None)[0]\n    plt.scatter(x,y,s=20, c = col[i])\n    plt.plot(x,m*x+c,c = col[i])\n\n    i = i + 1\nplt.title('Scatter plot of mean log revenue vs mean log budget for various languages')\nplt.legend(train['original_language'].unique()[0:no_lang])\nplt.xlabel('Mean log budget')\nplt.ylabel('Mean log revenue')\nplt.show()","049da8dd":"booleanBoxPlot(train_copy,'belongs_to_collection','log_revenue', 'en')","652826d5":"booleanBoxPlot(train_copy,'homepage','log_revenue','en')","1641ad85":"plt.figure(figsize=(15,10))\nsns.distplot(train.loc[train['popularity']<=100,'popularity'])\nplt.show()","2a007fa3":"plt.figure(figsize=(15,10))\nplt.scatter(train.loc[train['popularity']<=40,'popularity'],train.loc[train['popularity']<=40,'log_revenue'],c = 'r')\nx = train.loc[train['popularity']<=40,'popularity']\ny = train.loc[train['popularity']<=40,'log_revenue']\nA = np.vstack([np.array(x),np.ones(len(x))]).T\nm,c = np.linalg.lstsq(A,np.array(y),rcond = None)[0]\nplt.plot(x,m*x +c, 'r^-')\nplt.show()","131508a1":"### Plot boxplots for boolean features","be767d1b":"### Function to run ridge regression on training data, learn the model and test its performance on test datam","adb00324":"### Plot multiple scatter plots for the same independent variable","e47c59a3":"### XG Boost regressor","22d18e2f":"### Aggregating based on decade of release","53b20981":"## Random Forest regressor","420ddcc1":"## <font color = 'red'> Some useless analysis <\/font>","b29bd199":"### $$ RMSLE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N \\Bigl[\\log(\\hat{y_i}) -\\log(y_i)\\Bigr]^2} $$","c1502136":"### <font color = red> Need to look at error in the test set <\/font>","b23cd1a3":"### Function for cross-validation to estimate the best $\\alpha$ value","6c04cc4b":"### Reading the train and the test files","7bb2e600":"### Language-wise linear model","6f13d71b":"\n### Aggregating budget and revenue by year","b4848c3d":"### Function to convert JSON fields into dictionaries","46bbe471":"### Plotting the mean log revenue by year","080c6d52":"### Function to round up to the nearest integer that is larger than x","ddcfb7f6":"### Function to convert dictionary to a list of values in the dictionary","b1786fdb":"### Function to transform raw data - convert everything to log and perform one-hot encoding on selected features","86a7a1e7":"### Plot multiple Y axes for a common X axis","1415cff1":"### Comparison of mean log budget and mean log revenue by year","c08bf387":"1. ### Ridge regression","2dd2d8d9":"### TMDB revenue forecasting contest"}}