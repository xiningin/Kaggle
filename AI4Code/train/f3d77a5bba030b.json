{"cell_type":{"0a3a15f8":"code","447eebb7":"code","6c72b6a5":"code","376cf554":"code","c0993e99":"code","c6965b1c":"code","b3b7ad61":"code","7c0d99da":"code","6ca63cd5":"code","65f6ccb1":"code","f662d56d":"code","13e94f88":"code","2755d355":"code","6d6b809f":"code","9f089d3a":"code","517f8ee9":"code","9adf86ae":"code","dd6522d0":"code","354dcc52":"code","63232893":"code","a7e8212a":"code","7acf0d39":"code","c98cdd2a":"code","222e50f7":"code","2f0c938e":"code","40140186":"code","b4191982":"code","1b18fd1c":"code","1a36fead":"code","7888be96":"code","8ae0cd65":"code","b860ce52":"code","86989ade":"code","dc383adf":"code","9a181c1e":"code","f797f719":"code","ab0a4ae4":"code","d9452539":"code","704b9858":"code","bc83ccfb":"code","4beae90b":"code","3bdf482c":"code","b3725ed6":"code","078fa33e":"code","40b2d3f9":"code","b23202ef":"code","78626510":"code","9c57d724":"code","5dfd7555":"code","4b40e19f":"code","61d390f3":"code","9505d615":"code","2105d395":"code","e1be1651":"code","8d744839":"code","a6c1274e":"code","4ac42bb0":"code","3e632b52":"code","1e9e9dba":"code","5c1b4347":"code","dd6148d6":"code","7d5be1ae":"code","6c82cb14":"code","d49fa617":"code","73f1388f":"code","1c577d94":"code","c33bfff1":"code","98b70b71":"code","a0738040":"code","c6d9e7a6":"code","02af0f1a":"code","b132a969":"code","fd79dc1c":"code","e4a03caa":"code","aeb9d2c8":"code","9e938219":"code","d1663690":"code","437678fc":"code","d5ef59da":"code","a4b1caf6":"code","29ea7b06":"code","9f4006b5":"code","77742994":"code","89454de6":"code","9f2e42e6":"code","d4f6c70a":"code","10a088c8":"code","cdc46712":"code","128ed5e4":"code","69a3a406":"code","8c3e99f1":"code","94b03e28":"code","021025b0":"code","59f80f48":"code","05154a29":"code","7d6264cb":"code","2da22bc2":"code","751e750f":"code","e6ef741a":"code","c7e9e40e":"code","319c9030":"code","5136860e":"code","c547b620":"code","4ac956ca":"code","d7821fb1":"code","24353e44":"code","c687f8d2":"code","170569bd":"code","350328c3":"code","b69c86d9":"code","c16900ce":"code","d1fe1136":"code","efd22fad":"code","e44ec05c":"code","743c3d0a":"code","4d69de8e":"code","8944f0e8":"code","93f3a426":"code","d39f08de":"code","63a1becc":"code","ccadf3e1":"code","76d9be82":"code","6213e9ca":"code","f2c357cb":"code","62711ca0":"code","0056bdf9":"code","01861257":"code","9d8a7e66":"code","28f57341":"code","7b059b89":"code","a19904c0":"code","076d245c":"code","11bb93ef":"code","15c46d9a":"markdown","53c6ee51":"markdown","27d38e32":"markdown","c436a98a":"markdown","526ca9f8":"markdown","391bbf64":"markdown","be013940":"markdown","6e7b834c":"markdown","7f5e1aad":"markdown","469ed5e1":"markdown","d2d7eca5":"markdown","123c1b4d":"markdown","23b483d4":"markdown","ccc238e2":"markdown","45b959d7":"markdown","d7062c17":"markdown","bfd4e015":"markdown","cfe8e822":"markdown","ef927b75":"markdown","6d4f4a6d":"markdown","3cd212d1":"markdown","f52ae6d9":"markdown","250fce18":"markdown","1d2bf5de":"markdown","6024d40e":"markdown","726461c1":"markdown","4528191a":"markdown","06bc3c64":"markdown","618cdfb6":"markdown","a6196a29":"markdown","5c90d3d3":"markdown","35ac4839":"markdown","71930bf7":"markdown","8425c65f":"markdown","f2732e3d":"markdown"},"source":{"0a3a15f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","447eebb7":"train = pd.read_csv(\"..\/input\/train.csv\", nrows = 10000000)\ntest = pd.read_csv(\"..\/input\/test.csv\")","6c72b6a5":"train.shape","376cf554":"test.shape","c0993e99":"train.head(10)","c6965b1c":"train.describe()","b3b7ad61":"#check for missing values in train data\ntrain.isnull().sum().sort_values(ascending=False)","7c0d99da":"#check for missing values in test data\ntest.isnull().sum().sort_values(ascending=False)","6ca63cd5":"#drop the missing values\ntrain = train.drop(train[train.isnull().any(1)].index, axis = 0)","65f6ccb1":"train.shape","f662d56d":"#check the target column\ntrain['fare_amount'].describe()","13e94f88":"#38 fields have negative fare_amount values.\nfrom collections import Counter\nCounter(train['fare_amount']<0)","2755d355":"train = train.drop(train[train['fare_amount']<0].index, axis=0)\ntrain.shape","6d6b809f":"#no more negative values in the fare field\ntrain['fare_amount'].describe()","9f089d3a":"#highest fare is $500\ntrain['fare_amount'].sort_values(ascending=False)","517f8ee9":"train['passenger_count'].describe()","9adf86ae":"#max is 208 passengers. Assuming that a bus is a 'taxi' in NYC, I don't think a bus can carry 208 passengers! Let' see the distribution of this field\n#LOL! One field. this is DEFINITELY an outlier. Lets drop it \ntrain[train['passenger_count']>6]","dd6522d0":"train = train.drop(train[train['passenger_count']==208].index, axis = 0)","354dcc52":"#much neater now! Max number of passengers are 6. Which makes sense is the cab is an SUV :)\ntrain['passenger_count'].describe()","63232893":"#Next, let us explore the pickup latitude and longitudes\ntrain['pickup_latitude'].describe()","a7e8212a":"train[train['pickup_latitude']<-90]","7acf0d39":"train[train['pickup_latitude']>90]","c98cdd2a":"#We need to drop these outliers\ntrain = train.drop(((train[train['pickup_latitude']<-90])|(train[train['pickup_latitude']>90])).index, axis=0)","222e50f7":"#12 rows dropped\ntrain.shape","2f0c938e":"#similar operation for pickup longitude\ntrain['pickup_longitude'].describe()","40140186":"train[train['pickup_longitude']<-180]","b4191982":"train[train['pickup_longitude']>180]","1b18fd1c":"train = train.drop(((train[train['pickup_longitude']<-180])|(train[train['pickup_longitude']>180])).index, axis=0)","1a36fead":"#11 rows dropped\ntrain.shape","7888be96":"#similar operation for dropoff latitude and longitude\ntrain[train['dropoff_latitude']<-90]","8ae0cd65":"train[train['dropoff_latitude']>90]","b860ce52":"train = train.drop(((train[train['dropoff_latitude']<-90])|(train[train['dropoff_latitude']>90])).index, axis=0)","86989ade":"#8 rows dropped\ntrain.shape","dc383adf":"train[train['dropoff_latitude']<-180]|train[train['dropoff_latitude']>180]","9a181c1e":"train.dtypes","f797f719":"train['key'] = pd.to_datetime(train['key'])\ntrain['pickup_datetime']  = pd.to_datetime(train['pickup_datetime'])","ab0a4ae4":"#Convert for test data\ntest['key'] = pd.to_datetime(test['key'])\ntest['pickup_datetime']  = pd.to_datetime(test['pickup_datetime'])","d9452539":"#check the dtypes after conversion\ntrain.dtypes","704b9858":"test.dtypes","bc83ccfb":"#check the data\ntrain.head()","4beae90b":"test.head()","3bdf482c":"def haversine_distance(lat1, long1, lat2, long2):\n    data = [train, test]\n    for i in data:\n        R = 6371  #radius of earth in kilometers\n        #R = 3959 #radius of earth in miles\n        phi1 = np.radians(i[lat1])\n        phi2 = np.radians(i[lat2])\n    \n        delta_phi = np.radians(i[lat2]-i[lat1])\n        delta_lambda = np.radians(i[long2]-i[long1])\n    \n        #a = sin\u00b2((\u03c6B - \u03c6A)\/2) + cos \u03c6A . cos \u03c6B . sin\u00b2((\u03bbB - \u03bbA)\/2)\n        a = np.sin(delta_phi \/ 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda \/ 2.0) ** 2\n    \n        #c = 2 * atan2( \u221aa, \u221a(1\u2212a) )\n        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    \n        #d = R*c\n        d = (R * c) #in kilometers\n        i['H_Distance'] = d\n    return d","b3725ed6":"haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')","078fa33e":"train['H_Distance'].head(10)","40b2d3f9":"test['H_Distance'].head(10)","b23202ef":"train.head(10)","78626510":"test.head(10)","9c57d724":"data = [train,test]\nfor i in data:\n    i['Year'] = i['pickup_datetime'].dt.year\n    i['Month'] = i['pickup_datetime'].dt.month\n    i['Date'] = i['pickup_datetime'].dt.day\n    i['Day of Week'] = i['pickup_datetime'].dt.dayofweek\n    i['Hour'] = i['pickup_datetime'].dt.hour","5dfd7555":"train.head()","4b40e19f":"test.head()","61d390f3":"plt.figure(figsize=(15,7))\nplt.hist(train['passenger_count'], bins=15)\nplt.xlabel('No. of Passengers')\nplt.ylabel('Frequency')","9505d615":"plt.figure(figsize=(15,7))\nplt.scatter(x=train['passenger_count'], y=train['fare_amount'], s=1.5)\nplt.xlabel('No. of Passengers')\nplt.ylabel('Fare')","2105d395":"plt.figure(figsize=(15,7))\nplt.scatter(x=train['Date'], y=train['fare_amount'], s=1.5)\nplt.xlabel('Date')\nplt.ylabel('Fare')","e1be1651":"plt.figure(figsize=(15,7))\nplt.hist(train['Hour'], bins=100)\nplt.xlabel('Hour')\nplt.ylabel('Frequency')","8d744839":"plt.figure(figsize=(15,7))\nplt.scatter(x=train['Hour'], y=train['fare_amount'], s=1.5)\nplt.xlabel('Hour')\nplt.ylabel('Fare')","a6c1274e":"plt.figure(figsize=(15,7))\nplt.hist(train['Day of Week'], bins=100)\nplt.xlabel('Day of Week')\nplt.ylabel('Frequency')","4ac42bb0":"plt.figure(figsize=(15,7))\nplt.scatter(x=train['Day of Week'], y=train['fare_amount'], s=1.5)\nplt.xlabel('Day of Week')\nplt.ylabel('Fare')","3e632b52":"train.sort_values(['H_Distance','fare_amount'], ascending=False)","1e9e9dba":"len(train)","5c1b4347":"bins_0 = train.loc[(train['H_Distance'] == 0), ['H_Distance']]\nbins_1 = train.loc[(train['H_Distance'] > 0) & (train['H_Distance'] <= 10),['H_Distance']]\nbins_2 = train.loc[(train['H_Distance'] > 10) & (train['H_Distance'] <= 50),['H_Distance']]\nbins_3 = train.loc[(train['H_Distance'] > 50) & (train['H_Distance'] <= 100),['H_Distance']]\nbins_4 = train.loc[(train['H_Distance'] > 100) & (train['H_Distance'] <= 200),['H_Distance']]\nbins_5 = train.loc[(train['H_Distance'] > 200) & (train['H_Distance'] <= 300),['H_Distance']]\nbins_6 = train.loc[(train['H_Distance'] > 300),['H_Distance']]\nbins_0['bins'] = '0'\nbins_1['bins'] = '0-10'\nbins_2['bins'] = '11-50'\nbins_3['bins'] = '51-100'\nbins_4['bins'] = '100-200'\nbins_5['bins'] = '201-300'\nbins_6['bins'] = '>300'\ndist_bins =pd.concat([bins_0,bins_1,bins_2,bins_3,bins_4,bins_5,bins_6])\n#len(dist_bins)\ndist_bins.columns","dd6148d6":"plt.figure(figsize=(15,7))\nplt.hist(dist_bins['bins'], bins=75)\nplt.xlabel('Bins')\nplt.ylabel('Frequency')","7d5be1ae":"Counter(dist_bins['bins'])","6c82cb14":"#pickup latitude and longitude = 0\ntrain.loc[((train['pickup_latitude']==0) & (train['pickup_longitude']==0))&((train['dropoff_latitude']!=0) & (train['dropoff_longitude']!=0)) & (train['fare_amount']==0)]","d49fa617":"train = train.drop(train.loc[((train['pickup_latitude']==0) & (train['pickup_longitude']==0))&((train['dropoff_latitude']!=0) & (train['dropoff_longitude']!=0)) & (train['fare_amount']==0)].index, axis=0)","73f1388f":"#1 row dropped\ntrain.shape","1c577d94":"#Check in test data\ntest.loc[((test['pickup_latitude']==0) & (test['pickup_longitude']==0))&((test['dropoff_latitude']!=0) & (test['dropoff_longitude']!=0))]\n#No records! PHEW!","c33bfff1":"#dropoff latitude and longitude = 0\ntrain.loc[((train['pickup_latitude']!=0) & (train['pickup_longitude']!=0))&((train['dropoff_latitude']==0) & (train['dropoff_longitude']==0)) & (train['fare_amount']==0)]","98b70b71":"train = train.drop(train.loc[((train['pickup_latitude']!=0) & (train['pickup_longitude']!=0))&((train['dropoff_latitude']==0) & (train['dropoff_longitude']==0)) & (train['fare_amount']==0)].index, axis=0)","a0738040":"#3 rows dropped\ntrain.shape","c6d9e7a6":"#Checking test data\n#Again no records! AWESOME!\ntest.loc[((test['pickup_latitude']!=0) & (test['pickup_longitude']!=0))&((test['dropoff_latitude']==0) & (test['dropoff_longitude']==0))]","02af0f1a":"high_distance = train.loc[(train['H_Distance']>200)&(train['fare_amount']!=0)]","b132a969":"high_distance","fd79dc1c":"high_distance.shape","e4a03caa":"high_distance['H_Distance'] = high_distance.apply(\n    lambda row: (row['fare_amount'] - 2.50)\/1.56,\n    axis=1\n)","aeb9d2c8":"#The distance values have been replaced by the newly calculated ones according to the fare\nhigh_distance","9e938219":"#sync the train data with the newly computed distance values from high_distance dataframe\ntrain.update(high_distance)","d1663690":"train.shape","437678fc":"train[train['H_Distance']==0]","d5ef59da":"train[(train['H_Distance']==0)&(train['fare_amount']==0)]","a4b1caf6":"train = train.drop(train[(train['H_Distance']==0)&(train['fare_amount']==0)].index, axis = 0)","29ea7b06":"#4 rows dropped\ntrain[(train['H_Distance']==0)].shape","9f4006b5":"#Between 6AM and 8PM on Mon-Fri\nrush_hour = train.loc[(((train['Hour']>=6)&(train['Hour']<=20)) & ((train['Day of Week']>=1) & (train['Day of Week']<=5)) & (train['H_Distance']==0) & (train['fare_amount'] < 2.5))]\nrush_hour","77742994":"train=train.drop(rush_hour.index, axis=0)","89454de6":"train.shape","9f2e42e6":"#Between 8PM and 6AM on Mon-Fri\nnon_rush_hour = train.loc[(((train['Hour']<6)|(train['Hour']>20)) & ((train['Day of Week']>=1)&(train['Day of Week']<=5)) & (train['H_Distance']==0) & (train['fare_amount'] < 3.0))]\n#print(Counter(non_work_hours['Hour']))\n#print(Counter(non_work_hours['Day of Week']))\nnon_rush_hour\n#keep these. Since the fare_amount is not <2.5 (which is the base fare), these values seem legit to me.","d4f6c70a":"#Saturday and Sunday all hours\nweekends = train.loc[((train['Day of Week']==0) | (train['Day of Week']==6)) & (train['H_Distance']==0) & (train['fare_amount'] < 3.0)]\nweekends\n#Counter(weekends['Day of Week'])\n#keep these too. Since the fare_amount is not <2.5, these values seem legit to me.","10a088c8":"train.loc[(train['H_Distance']!=0) & (train['fare_amount']==0)]","cdc46712":"scenario_3 = train.loc[(train['H_Distance']!=0) & (train['fare_amount']==0)]","128ed5e4":"len(scenario_3)","69a3a406":"#We do not have any distance values that are outliers.\nscenario_3.sort_values('H_Distance', ascending=False)","8c3e99f1":"scenario_3['fare_amount'] = scenario_3.apply(\n    lambda row: ((row['H_Distance'] * 1.56) + 2.50), axis=1\n)","94b03e28":"scenario_3['fare_amount']","021025b0":"train.update(scenario_3)","59f80f48":"train.shape","05154a29":"train.loc[(train['H_Distance']==0) & (train['fare_amount']!=0)]","7d6264cb":"scenario_4 = train.loc[(train['H_Distance']==0) & (train['fare_amount']!=0)]","2da22bc2":"len(scenario_4)","751e750f":"#Using our prior knowledge about the base price during weekdays and weekends for the cabs.\n#I do not want to impute these 1502 values as they are legible ones.\nscenario_4.loc[(scenario_4['fare_amount']<=3.0)&(scenario_4['H_Distance']==0)]","e6ef741a":"scenario_4.loc[(scenario_4['fare_amount']>3.0)&(scenario_4['H_Distance']==0)]","c7e9e40e":"scenario_4_sub = scenario_4.loc[(scenario_4['fare_amount']>3.0)&(scenario_4['H_Distance']==0)]","319c9030":"len(scenario_4_sub)","5136860e":"scenario_4_sub['H_Distance'] = scenario_4_sub.apply(\nlambda row: ((row['fare_amount']-2.50)\/1.56), axis=1\n)","c547b620":"train.update(scenario_4_sub)","4ac956ca":"train.shape","d7821fb1":"train.columns","24353e44":"test.columns","c687f8d2":"#not including the pickup_datetime columns as datetime columns cannot be directly used while modelling. Features need to extracted from the \n#timestamp fields which will later be used as features for modelling.\ntrain = train.drop(['key','pickup_datetime'], axis = 1)\ntest = test.drop(['key','pickup_datetime'], axis = 1)","170569bd":"train.columns","350328c3":"test.columns","b69c86d9":"x_train = train.iloc[:,train.columns!='fare_amount']\ny_train = train['fare_amount'].values\nx_test = test","c16900ce":"x_train.shape","d1fe1136":"x_train.columns","efd22fad":"y_train.shape","e44ec05c":"x_test.shape","743c3d0a":"x_test.columns","4d69de8e":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor()\nrf.fit(x_train, y_train)\nrf_predict = rf.predict(x_test)\n#print(rf_predict)","8944f0e8":"submission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['fare_amount'] = rf_predict\nsubmission.to_csv('submission_1.csv', index=False)\nsubmission.head(20)","93f3a426":"import lightgbm as lgbm","d39f08de":"params = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'nthread': -1,\n        'verbose': 0,\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'subsample_freq': 1,\n        'colsample_bytree': 0.6,\n        'reg_aplha': 1,\n        'reg_lambda': 0.001,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1     \n    }","63a1becc":"pred_test_y = np.zeros(x_test.shape[0])\npred_test_y.shape","ccadf3e1":"train_set = lgbm.Dataset(x_train, y_train, silent=True)\ntrain_set","76d9be82":"model = lgbm.train(params, train_set = train_set, num_boost_round=300)","6213e9ca":"print(model)","f2c357cb":"pred_test_y = model.predict(x_test, num_iteration = model.best_iteration)","62711ca0":"print(pred_test_y)","0056bdf9":"submission['fare_amount'] = pred_test_y\nsubmission.to_csv('submission_LGB.csv', index=False)\nsubmission.head(20)","01861257":"import xgboost as xgb ","9d8a7e66":"dtrain = xgb.DMatrix(x_train, label=y_train)\ndtest = xgb.DMatrix(x_test)","28f57341":"dtrain","7b059b89":"#set parameters for xgboost\nparams = {'max_depth':7,\n          'eta':1,\n          'silent':1,\n          'objective':'reg:linear',\n          'eval_metric':'rmse',\n          'learning_rate':0.05\n         }\nnum_rounds = 50","a19904c0":"xb = xgb.train(params, dtrain, num_rounds)","076d245c":"y_pred_xgb = xb.predict(dtest)\nprint(y_pred_xgb)","11bb93ef":"submission['fare_amount'] = y_pred_xgb\nsubmission.to_csv('submission_XGB.csv', index=False)\nsubmission.head(20)","15c46d9a":"The highest fares seem to be on a Sunday and Monday, and the lowest on Wednesday and Friday. Maybe people travel far distances on Sunday and Monday (visiting family and returning back home), and hence, the high fares. And guess people just want to stay at home on a Friday after a hectic week at work, or grab a drink from close by. Hmmm..","53c6ee51":"Next check the passenger_count variable","27d38e32":"Interesting! The time of day definitely plays an important role. The frequency of cab rides seem to be the lowest at 5AM and the highest at 7PM.","c436a98a":"**SCENARIO 2**\n\nFare is not 0 and is less than the base amount, but Distance is 0.\n\nDelete these rows as the minimum is $2.50, and these fares are incorrect values.","526ca9f8":"These 27159 rows need to be imputed using the following formula - \n> *distance = (fare_amount - 2.5)\/1.56*","391bbf64":"**PART 1 --> DATA CLEANSING & EXPLORATORY DATA ANALYSIS (EDA)**\n\nWill perform the following activities\n* Shape of train and test sets\n* Check for NaNs and drop them (if any)\n* Check for outliers and drop them (if any)\n* Type conversion of relevant fields","be013940":"**SCENARIO 1**\n\nFare and Distance are both 0. According to the table above, we shall delete them as they do not provide us any info with regards to the data.","6e7b834c":"**BOOSTING USING LGBM**\n\nThis is my first attempt at using a boosting algorithm such as LGBM. Let's see if LGBM really lives up to its hype of improving scores. My intital score with just the RF was 3.39 and placed me in the top 20%.","7f5e1aad":"**SCENARIO 4**\n\nFare is  not 0, but Distance is 0. These values need to be imputed.","469ed5e1":"And that's a wrap! With the Random Forest code I, got a score of 3.39, which was in the top 20%, with LGBM I got a score of 3.37 (which wasn't a great improvement from my initial RF model but helped me jump a couple of places up the leaderboard), and with XGBoost I got a 3.61, which is the worst of all my submissions. Maybe parameter tuning would help further. :) ","d2d7eca5":"**PART 2 --> MODELLING AND PREDICTION**\n\nFINALLY! Data cleansing is done! Now to split the x and y variables and proceed to modelling. I shall use the random forest method for prediction","123c1b4d":"From scenario 2, I can understand that the distance is 0, but the fare is all the minimum fare of $2.5. This could be because the passenger booked the cab but ended up cancelling to pay the base fare (not sure how this works in NYC, but I'm assuming that's how it is)","23b483d4":"Check the data types of each column","ccc238e2":"**2. Does the date and time of pickup affect the fare?**","45b959d7":"Now, for **EDA**. The following are my considerations - \n1. Does the number of passengers affect the fare? \n2. Does the date and time of pickup affect the fare?\n3. Does the day of the week affect the fare?\n4. Does the distance travelled affect the fare?\n\nFirst, let's split the datetime field 'pickup_datetime' to the following - \n* year\n* month\n* date\n* hour\n* day of week\n\nUsing these we shall calculate the day of the week and come to our conclusions about how pickup_location affects the fare.\nAlso, create a new field 'distance' to fetch the distance between the pickup and the drop.","d7062c17":"key and pickup_datetime seem to be datetime columns which are in object format. Let's convert them to datetime","bfd4e015":"**BOOSTING USING XGBM**","cfe8e822":"**3. Does the day of the week affect the fare?**","ef927b75":"1938 rows! As you can see from the DF above, the abnormally high distances are due to either the pickup or dropoff co-ordinates being incorrect or 0. However, since all these values have fares, I do not wish to drop them as they contain crucial data. Instead, I will replace the initial distance values with distance values calculated using the fare using the following formula \n\n> *distance = (fare_amount - 2.5)\/1.56*","6d4f4a6d":"Now we shall check for rows where the distance values are 0","3cd212d1":"There are values which are greater than 100 kms! In NYC I am not sure why people would take cabs to travel more than a 100 kms. Since the number of bins for 100-200 kms is quite high, I will keep these. These outliers could be because of typos or missing values in the latitude or longitude. Remove fields of the following - \n1.  Pickup latitude and pickup longitude are 0 but dropoff latitude and longitude are not 0, but the fare is 0\n2. vice versa of point 1.\n3. Pickup latitude and pickup longitude are 0 but dropoff latitude and longitude are not 0, but the fare is NOT 0. Here I will have to impute the distance values in both the train and test data.","f52ae6d9":"There are 4 rows. There 4 rows do not help us in anyway as we do not know either the distance or the fare to impute the missing values. So we shall drop them ","250fce18":"We can calulate the distance in a sphere when latitudes and longitudes are given by [Haversine formula](https:\/\/en.wikipedia.org\/wiki\/Haversine_formula)\n\n**haversine(\u03b8) = sin\u00b2(\u03b8\/2)**\n\nEventually, the formual boils down to the following where \u03c6 is latitude, \u03bb is longitude, R is earth\u2019s radius (mean radius = 6,371km) to include latitude and longitude coordinates (A and B in this case).\n\n**a = sin\u00b2((\u03c6B - \u03c6A)\/2) + cos \u03c6A . cos \u03c6B . sin\u00b2((\u03bbB - \u03bbA)\/2)**\n\n**c = 2 * atan2( \u221aa, \u221a(1\u2212a) )**\n\n**d = R \u22c5 c**\n\n**d = Haversine distance**\n\n*Refer [this](https:\/\/community.esri.com\/groups\/coordinate-reference-systems\/blog\/2017\/10\/05\/haversine-formula) page for more info and examples on Haversine formula*","1d2bf5de":"The fares, however, seem to be high betweeb 5AM and 10AM, and 2PM to 4PM. Maybe people who live far away prefer to leave earlier to avoid rush hour traffic?  ","6024d40e":"**4. Does the distance affect the fare?**\n\nThis is a no-brainer. I am confident that the distance would affect the fare a great deal. But I will visualise it.\n\nFirstly, let's check the frequency of the distances that we calculated using Haversine formula. I will do so by creating bins (0-10 kms, 10-20 kms, and so on, and check for any outliers)","726461c1":"Now that we have calculated the distance, we shall create columns for the following - \n* year\n* month\n* date\n* hour\n* day of week","4528191a":"**1. Does the number of passengers affect the fare? **","06bc3c64":"Nah, day of the week doesn't seem to have that much of an influence on the number of cab rides","618cdfb6":"**SCENARIO 3**\n\nFare is 0, but Distance is not 0. These values need to be imputed.\n\nI can calculate the fare as I have the distance. I shall use the following formula\n> *fare = 2.5 + 1.56(H_Distance)*","a6196a29":"From the above 2 graphs we can see that single passengers are the most frequent travellers, and the highest fare also seems to come from cabs which carry just 1 passenger.","5c90d3d3":"Quick Googling gave me this info\n* Latitudes range from -90 to 90.\n* Longitudes range from -180 to 180.\n\nThe above describe clearly shows some outliers. Let's filter them","35ac4839":"Check the H_Distance fields which are greater than 200 kms cause there is no way that people would travel more than 200 kms at the most in NYC in a CAB!","71930bf7":"Fare amount has a negative value, which doesn't make sense. Remove these fields","8425c65f":"We can see a few rows with distance =0. This could be due to 2 reasons \n1. The cab waited the whole time and the passenger eventually cancelled. *That's why the pickup and drop co-ordinates are the same and maybe, the passenger was charged for the waiting time.*\n2. The pickup and drop co-ordinates were not entered. In other words, these are **missing values**!\n\n28667 rows are too many rows to be deleted. We need to impute these missing values. I have a plan. I intend to impute the missing distance values with the fare and average price per kilometer of NYC cabs.\n\nA quick Google search gave me the following prices  - \n\n* $$2.5 base-price  +  $1.56\/km --> 6AM to 8PM Mon-Fri\n\n* $$3.0 base-price  +  $1.56\/km --> 8PM to 6AM Mon-Fri and Sat&Sun\n\nHowever, before we proceed with the above steps, lets check for the following scenarios to impute the missing fare amount and the H_Distance in train data.\n\n![image.png](attachment:image.png)\n","f2732e3d":"The fares throught the month mostly seem uniform, with the maximum fare received on the 12th"}}