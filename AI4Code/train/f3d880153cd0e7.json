{"cell_type":{"abde1dd3":"code","7f91dc34":"code","fbe6c754":"code","9de76324":"code","a237810c":"code","52f3eec0":"code","3764e42c":"code","7bb77f4e":"code","5027d9c6":"code","622379ed":"code","44b16201":"code","1735f2fe":"code","5f828960":"code","84673458":"code","ef677b26":"code","a9f1ff75":"code","2809eb87":"code","51f6a703":"code","c57f882d":"code","909f930a":"code","7268415b":"markdown","962d3e98":"markdown","180349dc":"markdown","fa69e112":"markdown","1f561568":"markdown","ed647877":"markdown","8dde0bf8":"markdown","1c4e9503":"markdown","0b33c53e":"markdown","0bfe2176":"markdown","246c39d1":"markdown","90fb02d5":"markdown","f9068d2a":"markdown"},"source":{"abde1dd3":"# Cancer Detection project, By BEKKAR Abdellatif\n# Aim is to familiarity with the use of CNNs with tensorflow for image classification","7f91dc34":"# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom time import time\nimport seaborn as sns\nimport plotly.graph_objects as go\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\n# import the necessary packages\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau","fbe6c754":"#Total Samples Available\nprint('Train Images = ',len(os.listdir('..\/input\/histopathologic-cancer-detection\/train')))\nprint('Test Images = ',len(os.listdir('..\/input\/histopathologic-cancer-detection\/test')))","9de76324":"df = pd.read_csv('..\/input\/histopathologic-cancer-detection\/train_labels.csv',dtype=str)\nprint(df.head())","a237810c":"print('Number of image : ', len(df))\nimg = plt.imread(\"..\/input\/histopathologic-cancer-detection\/train\/\"+df.iloc[0]['id']+'.tif')\nprint('Images shape', img.shape)","52f3eec0":"for i in range(5):\n    img = plt.imread(\"..\/input\/histopathologic-cancer-detection\/train\/\"+df.iloc[i]['id']+'.tif')\n    print(df.iloc[i]['label'])\n    plt.imshow(img)\n    plt.show()","3764e42c":"# Descriptive Analytics for given Dataset\n\nprint(df.label.value_counts())","7bb77f4e":"fig = plt.figure(figsize = (6,6)) \nax = sns.countplot(df.label).set_title('Label Counts', fontsize = 18)\nplt.annotate(df.label.value_counts()[0],\n            xy = (0,df.label.value_counts()[0] + 2000),\n            va = 'bottom',\n            ha = 'center',\n            fontsize = 12)\nplt.annotate(df.label.value_counts()[1],\n            xy = (1,df.label.value_counts()[1] + 2000),\n            va = 'bottom',\n            ha = 'center',\n            fontsize = 12)\nplt.ylim(0,150000)\nplt.ylabel('Count', fontsize = 16)\nplt.xlabel('Labels', fontsize = 16)\nplt.show()","5027d9c6":"labels = [\"No Cancer - 0\", \"Cancer - 1\"]\nvalues = df.label.value_counts()\n\nd = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.5, marker_colors=[\"rgb(0, 76, 153)\",\"rgb(255, 158, 60)\"])])\nd.show()","622379ed":"#add .tif to ids in the dataframe to use flow_from_dataframe\ndf[\"id\"]=df[\"id\"].apply(lambda x : x +\".tif\")\ndf.head()","44b16201":"train_path = '..\/input\/histopathologic-cancer-detection\/train'\nvalid_path = '..\/input\/histopathologic-cancer-detection\/train'","1735f2fe":"train_datagen = ImageDataGenerator(validation_split=0.20,\n                          rescale=1\/255.0)","5f828960":"train_generator=train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_path,\n    x_col=\"id\",\n    y_col=\"label\",\n    subset=\"training\",\n    batch_size=64,\n    shuffle=True,\n    class_mode=\"binary\",\n    target_size=(96,96))","84673458":"valid_generator=train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=valid_path,\n    x_col=\"id\",\n    y_col=\"label\",\n    subset=\"validation\",\n    batch_size=64,\n    shuffle=True,\n    class_mode=\"binary\",\n    target_size=(96,96))\n","ef677b26":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","a9f1ff75":"model.compile(optimizer='adam' , loss='binary_crossentropy', metrics=['accuracy'])","2809eb87":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nEPOCHS=20","51f6a703":"\nearlystopper = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1, restore_best_weights=True)\nreducel = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.1)\n\n\nhistory = model.fit_generator(generator=train_generator, \n                    steps_per_epoch=STEP_SIZE_TRAIN, \n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=EPOCHS,\n                   callbacks=[reducel, earlystopper])\n","c57f882d":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('accuracy')\n    ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","909f930a":"show_final_history(history)\nprint(\"Validation Accuracy: \" + str(history.history['val_accuracy'][-1:]))","7268415b":"Here the Label-1 is 59,5% and Label-0 is 40,5% of the whole train images. There is a little imbalance here which we can rectify to get better performance.","962d3e98":"# CNN Model Evaluation","180349dc":"***Total Samples Available***","fa69e112":"# Feature Engineering\n\nSplit into Train and Validation Sets with Keras ImageGenerator","1f561568":"***Create a DataFrame of all Train Image Labels***","ed647877":"**By BEKKAR Abdellatif**","8dde0bf8":"# **Histopathologic Cancer Detection**","1c4e9503":"**About the Data Set**\n\nhe data for this kernel is a slightly modified version of the PatchCamelyon (PCam) benchmark dataset. The original PCam dataset contains duplicate images due to its probabilistic sampling, however, the version presented on Kaggle does not contain duplicates.\n\nThe PatchCamelyon benchmark is a new and challenging image classification dataset. It consists of 327.680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections. Each image is annoted with a binary label indicating presence of metastatic tissue. PCam provides a new benchmark for machine learning models: bigger than CIFAR10, smaller than imagenet, trainable on a single GPU.\n\nPCam packs the clinically-relevant task of metastasis detection into a straight-forward binary image classification task, akin to CIFAR-10 and MNIST. Models can easily be trained on a single GPU in a couple hours, and achieve competitive scores in the Camelyon16 tasks of tumor detection and whole-slide image diagnosis. Furthermore, the balance between task-difficulty and tractability makes it a prime suspect for fundamental machine learning research on topics as active learning, model uncertainty, and explainability.\n\n**The images are labeled as 0 or 1, where 0 = No Tumor Tissue and 1 = Has Tumor Tissue(s)**","0b33c53e":"**Model structure (optimizer: Adam):**\n* In\n* Conv2D(32)*3 -> Dropout (0.3) -> MaxPool2D (3)\n* Conv2D(64)*3 -> Dropout (0.3) -> MaxPool2D (3)\n* Conv2D(128)*3 -> Dropout (0.3) -> MaxPool2D (3)\n* Flatten\n* Dense (128)\n* Dropout\n* Out\n","0bfe2176":"***Visualize some Train Images***","246c39d1":"***See the distribution of Train Labels***","90fb02d5":"# Define the model","f9068d2a":"# Exploratory Data Analysis"}}