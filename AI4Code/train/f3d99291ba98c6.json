{"cell_type":{"bac3ad59":"code","c1c039b5":"code","1f969d95":"code","000e354c":"code","f4691f2c":"code","38869b4f":"code","f6f5f567":"code","2451205f":"code","d65bd2f5":"code","4f481990":"code","172becea":"code","b36fd1e7":"code","319c534f":"code","ddf9beb3":"code","aaeb0321":"code","5297daea":"code","9ead8f97":"code","08adbbb7":"code","3753907c":"code","f22f1871":"code","c8928423":"code","eef65129":"code","e5792539":"code","e9d1f649":"code","149c1267":"code","07654df3":"code","f9043a2c":"code","c826e7c1":"code","c00adb9e":"code","7b9884a3":"code","74b341ae":"code","e48be28d":"code","d0598204":"code","6768afcd":"code","7ad537c0":"code","1dde49f3":"code","bee5d76b":"code","edb3647a":"code","dadfb59e":"code","8a71fe36":"code","4a91081a":"code","b984b58d":"code","cd61e251":"code","b0c94d1f":"code","95bb2a9e":"code","0dc56bba":"code","cd6985c2":"code","1654e4e6":"code","bcd39e67":"code","727bf235":"code","1bede69d":"code","1e8f0f55":"code","c5aaaabd":"code","5eda86d5":"code","b315d3f9":"code","b26c0c86":"code","0fd13c6e":"code","17b663ce":"code","4877fb71":"code","ddb24ff1":"code","38143afa":"code","e2e9b5fc":"code","3d4c7f8c":"code","a6601ee7":"code","98fbc472":"code","e777a31c":"code","3ca26046":"code","ca04299f":"code","e298e6be":"code","c1f90e2e":"code","a4bb4038":"code","3b554d0f":"code","0a5449af":"code","1815fbf6":"code","a0c39ad6":"code","f00276b9":"code","1cfb4f00":"code","0dd3af13":"code","7bd8503b":"code","7b327798":"code","e8049374":"code","8145d4fc":"code","cf8ef65f":"code","583dc225":"code","aa516663":"code","36d10dee":"code","2cd4dcbb":"code","f89cec6a":"code","a28b2023":"code","b9806e77":"code","3e771878":"code","1844e38b":"code","47c95fdc":"code","e34b638a":"code","3a5f0a56":"code","3ccccb38":"code","42537c6c":"code","0b21fd53":"code","925ddb39":"code","25257fe0":"code","68174dc8":"code","d6dd27fc":"code","6a64cc2f":"code","6cd4e075":"code","bd66507a":"code","8e198e92":"code","5a1aa087":"markdown","a2deb06d":"markdown","e48a17ed":"markdown","dbd66bcc":"markdown","d13d5dc4":"markdown","b2b1a9ae":"markdown","9ce04af3":"markdown","5003af18":"markdown","81ce4e6e":"markdown","3b3b39b0":"markdown","f4d27677":"markdown","c2d4e095":"markdown","02925832":"markdown","f2f5ae04":"markdown","259bd17d":"markdown","0cd5207f":"markdown","9407e361":"markdown","8f5af70c":"markdown","4c51abfe":"markdown","81051c67":"markdown","eed12264":"markdown","652d5546":"markdown","4778d9a0":"markdown","659fbe7a":"markdown","f83a57ab":"markdown","d590c5ef":"markdown","26017a79":"markdown","fbedbe48":"markdown","f5be6fce":"markdown","cbf94476":"markdown","3a8fe533":"markdown","179249ff":"markdown","7450b3b2":"markdown","3eafc31f":"markdown","171d2388":"markdown","cf911286":"markdown","52810963":"markdown","246a382d":"markdown"},"source":{"bac3ad59":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt","c1c039b5":"df_full = pd.read_csv('\/kaggle\/input\/google-analytics-api-ecommerce-cleaned\/google-analyticsapi-ecommerce-data-cleaned.csv',index_col=0)","1f969d95":"df_organic = df_full[df_full['medium']=='Organic']\ndf_paidsearch = df_full[df_full['medium']=='Paid Search']\ndf_direct = df_full[df_full['medium']=='Direct']\ndf_social = df_full[df_full['medium']=='Social']","000e354c":"df_full.info()","f4691f2c":"drop_elements=['ga:itemQuantity','ga:transactionRevenue','medium'] ","38869b4f":"df_social = df_social.drop(drop_elements, axis = 1)\ndf_direct = df_direct.drop(drop_elements, axis = 1)\ndf_paidsearch = df_paidsearch.drop(drop_elements, axis = 1)\ndf_organic = df_organic.drop(drop_elements, axis = 1)","f6f5f567":"df_social.info()","2451205f":"df_direct.info()","d65bd2f5":"df_paidsearch.info()","4f481990":"df_organic.info()","172becea":"drop_elements = ['ga:itemQuantity','ga:transactionRevenue']","b36fd1e7":"df_full = df_full.drop(drop_elements, axis = 1)","319c534f":"df_full.info()","ddf9beb3":"social_df = pd.get_dummies(df_social)\ndirect_df = pd.get_dummies(df_direct)\npaidsearch_df = pd.get_dummies(df_paidsearch)\norganic_df = pd.get_dummies(df_organic)\nfull_df = pd.get_dummies(df_full)","aaeb0321":"from sklearn.model_selection import train_test_split","5297daea":"def Raw_Data(df):\n    \n    ## Raw split - that function will return the test df and will be used in all combinations.\n    X_1 = df.drop('ga:transactions', axis=1)\n    y_1 = df['ga:transactions']\n\n    X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1,\n                                                                y_1,\n                                                                random_state=1,\n                                                                test_size=0.3)\n    \n    return X_train_1, X_test_1, y_train_1, y_test_1 ","9ead8f97":"def Without_Zeros(df):\n    \n    ## Split without zeros\n    df = df[(df['minutesessionDuration']>0)&(df['ga:pageDepth']>0)]\n    \n    X_2 = df.drop('ga:transactions', axis=1)\n    y_2 = df['ga:transactions']\n\n    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2,\n                                                                y_2,\n                                                                random_state=1,\n                                                                test_size=0.3)\n    \n    return X_train_2, y_train_2","08adbbb7":"def Without_Outliers(df):\n    \n    ## Split without zeros\n    df_new = df.copy()\n    \n    # Behavior columns to find the higher outliers\n    \n    behavior=['minutesessionDuration','ga:pageDepth','ga:hits']\n    \n    #Calculating the Interquartile Range\n        \n    for count,i in enumerate(behavior):\n        Q1 = df[behavior[count]].quantile(0.25)\n        Q3 = df[behavior[count]].quantile(0.75)\n        IQR = Q3 - Q1\n        #Apling the 1.5 rule for higher outliers\n        df_new = df_new[~(df_new[behavior[count]] > (Q3 + 1.5 * IQR))]\n                \n    \n    X_3 = df_new.drop('ga:transactions', axis=1)\n    y_3 = df_new['ga:transactions']\n\n\n    X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3,\n                                                                y_3,\n                                                                random_state=1,\n                                                                test_size=0.3)\n    \n    return  X_train_3,  y_train_3","3753907c":"def Without_Zeros_Outliers(df):\n    \n    ## Split without zeros and outliers\n    df_new = df.copy()\n    \n    # Behavior columns to find the higher outliers\n    \n    quantitative=['minutesessionDuration','ga:pageDepth','ga:hits']\n    \n    #Calculating the Interquartile Range\n        \n    for count,i in enumerate(quantitative):\n        Q1 = df[quantitative[count]].quantile(0.25)\n        Q3 = df[quantitative[count]].quantile(0.75)\n        IQR = Q3 - Q1\n        #Apling the 1.5 rule for higher outliers\n        df_new = df_new[~(df_new[quantitative[count]] > (Q3 + 1.5 * IQR))]\n    #Dropping 'minutesessionDuration' and 'ga:pageDepth' < 0             \n    df_new = df_new[(df_new['minutesessionDuration']>0)&(df_new['ga:pageDepth']>0)]    \n    \n    X_4 = df_new.drop('ga:transactions', axis=1)\n    y_4 = df_new['ga:transactions']\n\n\n    X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_4,\n                                                                y_4,\n                                                                random_state=1,\n                                                                test_size=0.3)\n    \n    return  X_train_4,  y_train_4","f22f1871":"#Data Balance Method\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import TomekLinks\n","c8928423":"# Random UnderSampler\n\ndef Rus_Split(X_train, y_train): \n\n    rus = RandomUnderSampler()\n\n    X_rus, y_rus  = rus.fit_sample(X_train ,  y_train)\n\n\n    return X_rus, y_rus","eef65129":"# Random OverSampler\n\ndef Ros_Split(X_train, y_train):\n    \n    ros = RandomOverSampler()\n\n    X_ros, y_ros = ros.fit_sample(X_train, y_train)\n\n   \n    return X_ros, y_ros","e5792539":"# Under sampler TomekLinks\n\ndef Ustl_Split(X_train, y_train):\n    \n    tl = TomekLinks( sampling_strategy ='majority')\n\n    X_tl, y_tl= tl.fit_sample(X_train, y_train)\n\n\n    return X_tl, y_tl","e9d1f649":"from sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score","149c1267":"def Model_Score(model, y_test, X_test):\n\n    y_pred = model.predict(X_test)\n    \n    total_score = {'Recall':[recall_score(y_test, y_pred)],\n                   'Precision' : [precision_score(y_test, y_pred)],\n                   'F1_score' : [f1_score(y_test, y_pred)]}\n     \n    total_score = pd.DataFrame(total_score, columns = ['Recall','Precision','F1_score'])\n\n    \n    return total_score","07654df3":"# Classifiers\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb","f9043a2c":"def Models_Binary_Classification(df):\n    \n    # Data Formats splits \n    \n    ## raw df - 1 \n    \n    X_train_1, X_test_1 ,y_train_1, y_test_1 = Raw_Data(df)\n    \n    ## Data Without Zeros - 2\n    \n    X_train_2,  y_train_2,  = Without_Zeros(df) \n   \n    ## Without Outliers - 3\n    \n    X_train_3, y_train_3 = Without_Outliers(df)\n    \n    ##  Without Zero & Outliers - 4\n    \n    \n    X_train_4,  y_train_4  = Without_Zeros_Outliers(df)\n    \n\n     # 1 - Decision Tree Classifier (DTC) \n    \n    \n    # 1.1 Unbalanced\n\n    \n    ### 1.1.1 - DTC - Unbalanced DF - Raw DF\n\n    DTC_1_1 = DecisionTreeClassifier(random_state=0, max_depth=5)\n\n    DTC_1_1.fit(X_train_1, y_train_1)\n\n    DTC_score_1_1 = Model_Score(DTC_1_1, y_test_1, X_test_1)\n    \n    ### 1.1.2 - DTC - Unbalanced DF - Without Zeros\n\n    DTC_1_2 = DecisionTreeClassifier(random_state=0, max_depth=5)\n\n    DTC_1_2.fit(X_train_2, y_train_2)\n\n    DTC_score_1_2 = Model_Score(DTC_1_2, y_test_1, X_test_1)\n     \n    ## 1.1.3 - DTC - Unbalanced DF - Without Outliers  \n\n    DTC_1_3 = DecisionTreeClassifier(random_state=0, max_depth=5 )\n\n    DTC_1_3.fit(X_train_3, y_train_3)\n\n    DTC_score_1_3 = Model_Score(DTC_1_3, y_test_1, X_test_1)\n\n    ###  1.1.4- DTC - Unbalanced DF - Without Zeros and Outliers\n\n    DTC_1_4 = DecisionTreeClassifier(random_state=0, max_depth=5 )\n\n    DTC_1_4.fit(X_train_4, y_train_4)\n\n    DTC_score_1_4 = Model_Score(DTC_1_4, y_test_1, X_test_1)\n    \n    \n    ## 1.2 - Random Under Sampling (RUS)\n    \n   \n    ### 1.2.1 DTC - RUS - Raw DF\n\n    X_train_2_1, y_train_2_1, = Rus_Split(X_train_1, y_train_1)\n\n    DTC_2_1 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth = 5)\n\n    DTC_2_1.fit(X_train_2_1, y_train_2_1)\n\n    DTC_score_2_1 = Model_Score(DTC_2_1, y_test_1, X_test_1)\n\n    ### 1.2.2 - DTC - RUS - Without Zeros\n\n    X_train_2_2, y_train_2_2 = Rus_Split(X_train_2, y_train_2)\n\n    DTC_2_2 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth = 5)\n\n    DTC_2_2.fit(X_train_2_2, y_train_2_2)\n\n    DTC_score_2_2 = Model_Score(DTC_2_2, y_test_1, X_test_1)\n\n\n    ### 1.2.3 - DTC - RUS - Without Outliers \n\n    X_train_2_3, y_train_2_3 = Rus_Split(X_train_3, y_train_3)\n\n    DTC_2_3 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth = 5)\n\n    DTC_2_3.fit(X_train_2_3, y_train_2_3)\n\n    DTC_score_2_3 = Model_Score(DTC_2_3, y_test_1, X_test_1)\n\n\n    ### 1.2.4 - DTC - RUS - Without Zeros and Outliers\n\n    X_train_2_4, y_train_2_4, = Rus_Split(X_train_4, y_train_4)\n\n    DTC_2_4 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth = 5)\n\n    DTC_2_4.fit(X_train_2_4, y_train_2_4)\n\n    DTC_score_2_4 = Model_Score(DTC_2_4, y_test_1, X_test_1)\n\n    \n    ## 1.3 - Randon Over Sample (ROS)\n    \n    \n    ### 1.3.1 - DTC - ROS  - Raw DF\n\n    X_train_3_1, y_train_3_1 = Ros_Split(X_train_1, y_train_1)\n\n    DTC_3_1 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    DTC_3_1.fit(X_train_3_1, y_train_3_1)\n\n    DTC_score_3_1 = Model_Score(DTC_3_1, y_test_1, X_test_1)\n\n    ### 1.3.2 - DTC - ROS - Without Zeros\n\n    X_train_3_2, y_train_3_2 = Ros_Split(X_train_2, y_train_2)\n\n    DTC_3_2 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    DTC_3_2.fit(X_train_3_2, y_train_3_2)\n\n    DTC_score_3_2 = Model_Score(DTC_3_2, y_test_1, X_test_1)\n\n    ### 1.3.3 - DTC - ROS - Without Outliers \n\n    X_train_3_3, y_train_3_3 = Ros_Split(X_train_3, y_train_3)\n\n    DTC_3_3 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    DTC_3_3.fit(X_train_3_3, y_train_3_3)\n\n    DTC_score_3_3 = Model_Score(DTC_3_3, y_test_1, X_test_1)\n\n    ### 1.3.4 - DTC - ROS - Without Zeros and Outliers\n\n    X_train_3_4, y_train_3_4 = Ros_Split(X_train_4, y_train_4)\n\n    DTC_3_4 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    DTC_3_4.fit(X_train_3_4, y_train_3_4)\n\n    DTC_score_3_4 = Model_Score(DTC_3_4, y_test_1, X_test_1)\n\n    \n    ## 1.4 Under-sampling: Tomek Links (USTL)\n\n    \n    ### 1.4.1 - DTC - USTL - Raw DF\n\n    X_train_4_1, y_train_4_1 = Ustl_Split(X_train_1, y_train_1)\n\n    DTC_4_1 = DecisionTreeClassifier(class_weight='balanced',max_depth = 5)\n\n    DTC_4_1.fit(X_train_4_1, y_train_4_1)\n\n    DTC_score_4_1 = Model_Score(DTC_4_1, y_test_1, X_test_1)\n\n    ### 1.4.2 - DTC - USTL - Without Zeros\n\n    X_train_4_2, y_train_4_2= Ustl_Split(X_train_2, y_train_2)\n\n    DTC_4_2 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth = 5)\n\n    DTC_4_2.fit(X_train_4_2, y_train_4_2)\n\n    DTC_score_4_2 = Model_Score(DTC_4_2, y_test_1, X_test_1)\n\n    ### 1.4.3 - DTC - USTL - Without Outliers \n\n    X_train_4_3, y_train_4_3 = Ustl_Split(X_train_3, y_train_3)\n\n    DTC_4_3 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth = 5)\n\n    DTC_4_3.fit(X_train_4_3, y_train_4_3)\n\n    DTC_score_4_3 = Model_Score(DTC_4_3, y_test_1, X_test_1)\n\n    ### 1.4.4 - DTC - USTL - Without Zeros and Outliers\n\n    X_train_4_4, y_train_4_4 = Ustl_Split(X_train_4, y_train_4)\n\n    DTC_4_4 = DecisionTreeClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    DTC_4_4.fit(X_train_4_4, y_train_4_4)\n\n    DTC_score_4_4 = Model_Score(DTC_4_4, y_test_1, X_test_1)\n\n\n    \n    # 2 - Ramdon Forrest  Classifier (RFC) \n\n    \n    # 2.1 RFC - Unbalanced DF\n\n    \n    ### 2.1.1 - RFC - Unbalanced DF - Raw DF\n\n    RFC_1_1 = RandomForestClassifier(random_state=0, max_depth=5)\n\n    RFC_1_1.fit(X_train_1, y_train_1)\n\n    RFC_score_1_1 = Model_Score(RFC_1_1, y_test_1, X_test_1)\n\n    ### 2.1.2 - RFC - Unbalanced DF - Without Zeros\n\n    RFC_1_2 = RandomForestClassifier(random_state=0, max_depth=5)\n\n    RFC_1_2.fit(X_train_2, y_train_2)\n\n    RFC_score_1_2 = Model_Score(RFC_1_2, y_test_1, X_test_1)\n\n    ## 2.1.3 - RFC - Unbalanced DF - Without Outliers \n\n    RFC_1_3 =  RandomForestClassifier(random_state=0, max_depth=5)\n\n    RFC_1_3.fit(X_train_3, y_train_3.ravel())\n\n    RFC_score_1_3 = Model_Score(RFC_1_3, y_test_1, X_test_1)\n\n    ###  2.1.4 - RFC - Unbalanced DF - Without Zeros and Outliers\n\n    RFC_1_4 = RandomForestClassifier(random_state=0, max_depth=5 )\n\n    RFC_1_4.fit(X_train_4, y_train_4)\n\n    RFC_score_1_4 = Model_Score(RFC_1_4, y_test_1, X_test_1)\n\n   \n    ## 2.2 - RFC - Random Under Sampling (RUS)\n\n    \n    ### 2.2.1 RFC - RUS - Raw DF\n\n    RFC_2_1 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_2_1.fit(X_train_2_1, y_train_2_1)\n\n    RFC_score_2_1 = Model_Score(RFC_2_1, y_test_1, X_test_1)\n\n    RFC_score_2_1\n\n    ### 2.2.2 - RFC - RUS - Without Zeros\n\n    RFC_2_2 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_2_2.fit(X_train_2_2, y_train_2_2)\n\n    RFC_score_2_2 = Model_Score(RFC_2_2, y_test_1, X_test_1)\n\n    ### 2.2.3 - RFC - RUS - Without Outliers \n\n    RFC_2_3 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_2_3.fit(X_train_2_3, y_train_2_3.ravel())\n\n    RFC_score_2_3 = Model_Score(RFC_2_3, y_test_1, X_test_1)\n\n    ### 2.2.4 - RFC - RUS- Without Zeros and Outliers\n\n    RFC_2_4 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth = 5)\n\n    RFC_2_4.fit(X_train_2_4, y_train_2_4)\n\n    RFC_score_2_4 = Model_Score(RFC_2_4, y_test_1, X_test_1)\n\n    \n    ## 2.3 - RFC - Randon Over Sample (ROS)\n\n    \n    ### 2.3.1 -  RFC - ROS  - Raw DF\n\n    RFC_3_1 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_3_1.fit(X_train_3_1, y_train_3_1)\n\n    RFC_score_3_1 = Model_Score(RFC_3_1, y_test_1, X_test_1)\n\n    ### 2.3.2 -  RFC - ROS - Without Zeros\n\n    RFC_3_2 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_3_2.fit(X_train_3_2, y_train_3_2)\n\n    RFC_score_3_2 = Model_Score( RFC_3_2, y_test_1, X_test_1)\n\n    ### 2.3.3 - RFC - ROS - Without Outliers \n\n    RFC_3_3 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_3_3.fit(X_train_3_3, y_train_3_3)\n\n    RFC_score_3_3 = Model_Score(RFC_3_3, y_test_1, X_test_1)\n\n    ### 2.3.4 - RFC - ROS - Without Zeros and Outliers\n\n    RFC_3_4 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_3_4.fit(X_train_3_4, y_train_3_4)\n\n    RFC_score_3_4 = Model_Score(RFC_3_4, y_test_1, X_test_1)\n\n\n    ## 2.4 - RFC - Under-sampling: Tomek Links (USTL)\n\n    \n    ### 2.4.1 - RFC - USTL - Raw DF\n\n    RFC_4_1 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_4_1.fit(X_train_4_1, y_train_4_1)\n\n    RFC_score_4_1 = Model_Score(RFC_4_1, y_test_1, X_test_1)\n\n    ### 1.4.2 - RFC - USTL - Without Zeros\n\n    RFC_4_2 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth=5)\n\n    RFC_4_2.fit(X_train_4_2, y_train_4_2)\n\n    RFC_score_4_2 = Model_Score(RFC_4_2, y_test_1, X_test_1)\n\n    ### 2.4.3 - RFC - USTL - Without Outliers \n\n    RFC_4_3 = RandomForestClassifier(class_weight='balanced',max_depth = 5)\n\n    RFC_4_3.fit(X_train_4_3, y_train_4_3)\n\n    RFC_score_4_3 = Model_Score( RFC_4_3, y_test_1, X_test_1)\n\n    ### 1.4.4 - RFC - USTL - Without Zeros and Outliers\n\n    RFC_4_4 = RandomForestClassifier(class_weight='balanced', random_state=0, max_depth = 5)\n\n    RFC_4_4.fit(X_train_4_4, y_train_4_4)\n\n    RFC_score_4_4 = Model_Score(RFC_4_4, y_test_1, X_test_1)\n\n\n    ## 3 - XGBClassifier (XGBC)\n\n\n    # 3.1 XGBC - Unbalanced DF\n\n    \n    ### 3.1.1 - XGBC - Unbalanced DF - Raw DF\n\n    XGBC_1_1 = xgb.XGBClassifier(random_state=0,max_depth=5)\n\n    XGBC_1_1.fit(X_train_1, y_train_1)\n\n    XGBC_score_1_1 = Model_Score(XGBC_1_1, y_test_1, X_test_1)\n\n    ### 3.1.2 - XGBC - Unbalanced DF - Without Zeros\n\n    XGBC_1_2 = xgb.XGBClassifier(random_state=0,max_depth=5)\n\n    XGBC_1_2.fit(X_train_2, y_train_2.values.ravel())\n\n    XGBC_score_1_2 = Model_Score(XGBC_1_2, y_test_1, X_test_1)\n\n    ## 3.1.3 - XGBC - Unbalanced DF - Without Outliers \n\n    XGBC_1_3 = xgb.XGBClassifier(random_state=0,max_depth=5)\n\n    XGBC_1_3.fit(X_train_3, y_train_3)\n\n    XGBC_score_1_3 = Model_Score(XGBC_1_3, y_test_1, X_test_1)\n\n    ###  3.1.4 - XGBC - Unbalanced DF - Without Zeros and Outliers\n\n    XGBC_1_4 = xgb.XGBClassifier(random_state=0,max_depth=5)\n\n    XGBC_1_4.fit(X_train_4, y_train_4)\n\n    XGBC_score_1_4 = Model_Score(XGBC_1_4, y_test_1, X_test_1)\n\n\n    ## 3.2 - XGBC - Random Under Sampling (RUS)\n\n    \n    ### 3.2.1 - XGBC - RUS - Raw DF\n\n    XGBC_2_1 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_2_1.fit(X_train_2_1, y_train_2_1)\n\n    XGBC_score_2_1 = Model_Score(XGBC_2_1, y_test_1, X_test_1)\n\n    ### 3.2.2 - XGBC - RUS - Without Zeros\n\n    XGBC_2_2 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_2_2.fit(X_train_2_2, y_train_2_2)\n\n    XGBC_score_2_2 = Model_Score(XGBC_2_2, y_test_1, X_test_1)\n\n    ### 3.2.3 - XGBC - RUS - Without Outliers \n\n    XGBC_2_3 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_2_3.fit(X_train_2_3, y_train_2_3)\n\n    XGBC_score_2_3 = Model_Score(XGBC_2_3, y_test_1, X_test_1)\n\n\n    ### 3.2.4 - XGBC - RUS - Without Zeros and Outliers\n\n    XGBC_2_4 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_2_4.fit(X_train_2_4, y_train_2_4)\n\n    XGBC_score_2_4 = Model_Score(XGBC_2_4, y_test_1, X_test_1)\n\n\n    ## 3.3 - XGBC - Randon Over Sample (ROS)\n\n    \n    ### 3.3.1 -  XGBC - ROS  - Raw DF\n\n    XGBC_3_1 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_3_1.fit(X_train_3_1, y_train_3_1)\n\n    XGBC_score_3_1 = Model_Score(XGBC_3_1, y_test_1, X_test_1)\n\n    ### 3.3.2 -  XGBC - ROS - Without Zeros\n\n    XGBC_3_2 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_3_2.fit(X_train_3_2, y_train_3_2)\n\n    XGBC_score_3_2 = Model_Score(XGBC_3_2, y_test_1, X_test_1)\n\n    ### 3.3.3 - XGBC - ROS - Without Outliers \n\n    XGBC_3_3 = xgb.XGBClassifier(random_state=0, max_depth=5)\n    \n    XGBC_3_3.fit(X_train_3_3, y_train_3_3)\n\n    XGBC_score_3_3 = Model_Score(XGBC_3_3, y_test_1, X_test_1)\n\n    ### 3.3.4 - RFC - ROS - Without Zeros and Outliers\n\n    XGBC_3_4 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_3_4.fit(X_train_3_4, y_train_3_4)\n\n    XGBC_score_3_4 = Model_Score(XGBC_3_4, y_test_1, X_test_1)\n\n\n    ## 3.4 - XGBC - Under-sampling: Tomek Links (USTL)\n\n    \n    ### 3.4.1 - XGBC - USTL - Raw DF\n\n    XGBC_4_1 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_4_1.fit(X_train_4_1, y_train_4_1)\n\n    XGBC_score_4_1 = Model_Score(XGBC_4_1, y_test_1, X_test_1)\n\n    ### 3.4.2 - XGBC - UTL - Without Zeros\n\n    XGBC_4_2 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_4_2.fit(X_train_4_2, y_train_4_2)\n\n    XGBC_score_4_2 = Model_Score(XGBC_4_2, y_test_1, X_test_1)\n\n    ### 3.4.3 - XGBC - USTL - Without Outliers \n\n    XGBC_4_3 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_4_3.fit(X_train_4_3, y_train_4_3)\n\n    XGBC_score_4_3 = Model_Score( XGBC_4_3, y_test_1, X_test_1)\n\n    ### 3.4.4 - XGBC - USTL - Without Zeros and Outliers\n\n    XGBC_4_4 = xgb.XGBClassifier(random_state=0, max_depth=5)\n\n    XGBC_4_4.fit(X_train_4_4, y_train_4_4)\n\n    XGBC_score_4_4 = Model_Score( XGBC_4_4, y_test_1, X_test_1)\n\n\n    \n\n\n    # Best F1_Score\n\n    \n    Score = {'Methods': [ 'DTC - Unbalanced DF - Raw DF',\n                                    'DTC - Unbalanced DF - Without Zeros',\n                                    'DTC - Unbalanced DF - Without Outliers ',\n                                    'DTC - Unbalanced DF - Without Zeros and Outliers',\n                                    'DTC - RUS - Raw DF',\n                                    'DTC - RUS - Without Zeros',\n                                    'DTC - RUS - Without Outliers ',\n                                    'DTC - RUS - Without Zeros and Outliers',\n                                    'DTC - ROS - Raw DF',\n                                    'DTC - ROS - Without Zeros',\n                                    'DTC - ROS - Without Outliers ',\n                                    'DTC - ROS - Without Zeros and Outliers',\n                                    'DTC - USTL - Raw DF',\n                                    'DTC - USTL - Without Zeros',\n                                    'DTC - USTL - Without Outliers ',\n                                    'DTC - USTL - Without Zeros and Outliers',\n                                    'RFC - Unbalanced DF - Raw DF',\n                                    'RFC - Unbalanced DF - Without Zeros',\n                                    'RFC - Unbalanced DF - Without Outliers ',\n                                    'RFC - Unbalanced DF - Without Zeros and Outliers',\n                                    'RFC - RUS - Raw DF',\n                                    'RFC - RUS - Without Zeros',\n                                    'RFC - RUS - Without Outliers ',\n                                    'RFC - RUS - Without Zeros and Outliers',\n                                    'RFC - ROS - Raw DF',\n                                    'RFC - ROS - Without Zeros',\n                                    'RFC - ROS - Without Outliers ',\n                                    'RFC - ROS - Without Zeros and Outliers',\n                                    'RFC - USTL - Raw DF',\n                                    'RFC - USTL - Without Zeros',\n                                    'RFC - USTL - Without Outliers ',\n                                    'RFC - USTL - Without Zeros and Outliers',\n                                    'XGB - Unbalanced DF - Raw DF',\n                                    'XGB - Unbalanced DF - Without Zeros',\n                                    'XGB - Unbalanced DF - Without Outliers ',\n                                    'XGB - Unbalanced DF - Without Zeros and Outliers',\n                                    'XGB - RUS - Raw DF',\n                                    'XGB - RUS - Without Zeros',\n                                    'XGB - RUS - Without Outliers ',\n                                    'XGB - RUS - Without Zeros and Outliers',\n                                    'XGB - ROS - Raw DF',\n                                    'XGB - ROS - Without Zeros',\n                                    'XGB - ROS - Without Outliers ',\n                                    'XGB - ROS - Without Zeros and Outliers',\n                                    'XGB - USTL - Raw DF',\n                                    'XGB - USTL - Without Zeros',\n                                    'XGB - USTL - Without Outliers ',\n                                    'XGB - USTL - Without Zeros and Outliers'\n                                    \n                                   ],\n                            'Recall': [DTC_score_1_1[\"Recall\"][0],\n                                        DTC_score_1_2[\"Recall\"][0],\n                                        DTC_score_1_3[\"Recall\"][0],\n                                        DTC_score_1_4[\"Recall\"][0],\n                                        DTC_score_2_1[\"Recall\"][0],\n                                        DTC_score_2_2[\"Recall\"][0],\n                                        DTC_score_2_3[\"Recall\"][0],\n                                        DTC_score_2_4[\"Recall\"][0],\n                                        DTC_score_3_1[\"Recall\"][0],\n                                        DTC_score_3_2[\"Recall\"][0],\n                                        DTC_score_3_3[\"Recall\"][0],\n                                        DTC_score_3_4[\"Recall\"][0],\n                                        DTC_score_4_1[\"Recall\"][0],\n                                        DTC_score_4_2[\"Recall\"][0],\n                                        DTC_score_4_3[\"Recall\"][0],\n                                        DTC_score_4_4[\"Recall\"][0],\n                                        RFC_score_1_1[\"Recall\"][0],\n                                        RFC_score_1_2[\"Recall\"][0],\n                                        RFC_score_1_3[\"Recall\"][0],\n                                        RFC_score_1_4[\"Recall\"][0],\n                                        RFC_score_2_1[\"Recall\"][0],\n                                        RFC_score_2_2[\"Recall\"][0],\n                                        RFC_score_2_3[\"Recall\"][0],\n                                        RFC_score_2_4[\"Recall\"][0],\n                                        RFC_score_3_1[\"Recall\"][0],\n                                        RFC_score_3_2[\"Recall\"][0],\n                                        RFC_score_3_3[\"Recall\"][0],\n                                        RFC_score_3_4[\"Recall\"][0],\n                                        RFC_score_4_1[\"Recall\"][0],\n                                        RFC_score_4_2[\"Recall\"][0],\n                                        RFC_score_4_3[\"Recall\"][0],\n                                        RFC_score_4_4[\"Recall\"][0],\n                                        XGBC_score_1_1[\"Recall\"][0],\n                                        XGBC_score_1_2[\"Recall\"][0],\n                                        XGBC_score_1_3[\"Recall\"][0],\n                                        XGBC_score_1_4[\"Recall\"][0],\n                                        XGBC_score_2_1[\"Recall\"][0],\n                                        XGBC_score_2_2[\"Recall\"][0],\n                                        XGBC_score_2_3[\"Recall\"][0],\n                                        XGBC_score_2_4[\"Recall\"][0],\n                                        XGBC_score_3_1[\"Recall\"][0],\n                                        XGBC_score_3_2[\"Recall\"][0],\n                                        XGBC_score_3_3[\"Recall\"][0],\n                                        XGBC_score_3_4[\"Recall\"][0],\n                                        XGBC_score_4_1[\"Recall\"][0],\n                                        XGBC_score_4_2[\"Recall\"][0],\n                                        XGBC_score_4_3[\"Recall\"][0],\n                                        XGBC_score_4_4[\"Recall\"][0]\n                                    ],\n                'Precision': [DTC_score_1_1[\"Precision\"][0],\n                                        DTC_score_1_2[\"Precision\"][0],\n                                        DTC_score_1_3[\"Precision\"][0],\n                                        DTC_score_1_4[\"Precision\"][0],\n                                        DTC_score_2_1[\"Precision\"][0],\n                                        DTC_score_2_2[\"Precision\"][0],\n                                        DTC_score_2_3[\"Precision\"][0],\n                                        DTC_score_2_4[\"Precision\"][0],\n                                        DTC_score_3_1[\"Precision\"][0],\n                                        DTC_score_3_2[\"Precision\"][0],\n                                        DTC_score_3_3[\"Precision\"][0],\n                                        DTC_score_3_4[\"Precision\"][0],\n                                        DTC_score_4_1[\"Precision\"][0],\n                                        DTC_score_4_2[\"Precision\"][0],\n                                        DTC_score_4_3[\"Precision\"][0],\n                                        DTC_score_4_4[\"Precision\"][0],\n                                        RFC_score_1_1[\"Precision\"][0],\n                                        RFC_score_1_2[\"Precision\"][0],\n                                        RFC_score_1_3[\"Precision\"][0],\n                                        RFC_score_1_4[\"Precision\"][0],\n                                        RFC_score_2_1[\"Precision\"][0],\n                                        RFC_score_2_2[\"Precision\"][0],\n                                        RFC_score_2_3[\"Precision\"][0],\n                                        RFC_score_2_4[\"Precision\"][0],\n                                        RFC_score_3_1[\"Precision\"][0],\n                                        RFC_score_3_2[\"Precision\"][0],\n                                        RFC_score_3_3[\"Precision\"][0],\n                                        RFC_score_3_4[\"Precision\"][0],\n                                        RFC_score_4_1[\"Precision\"][0],\n                                        RFC_score_4_2[\"Precision\"][0],\n                                        RFC_score_4_3[\"Precision\"][0],\n                                        RFC_score_4_4[\"Precision\"][0],\n                                        XGBC_score_1_1[\"Precision\"][0],\n                                        XGBC_score_1_2[\"Precision\"][0],\n                                        XGBC_score_1_3[\"Precision\"][0],\n                                        XGBC_score_1_4[\"Precision\"][0],\n                                        XGBC_score_2_1[\"Precision\"][0],\n                                        XGBC_score_2_2[\"Precision\"][0],\n                                        XGBC_score_2_3[\"Precision\"][0],\n                                        XGBC_score_2_4[\"Precision\"][0],\n                                        XGBC_score_3_1[\"Precision\"][0],\n                                        XGBC_score_3_2[\"Precision\"][0],\n                                        XGBC_score_3_3[\"Precision\"][0],\n                                        XGBC_score_3_4[\"Precision\"][0],\n                                        XGBC_score_4_1[\"Precision\"][0],\n                                        XGBC_score_4_2[\"Precision\"][0],\n                                        XGBC_score_4_3[\"Precision\"][0],\n                                        XGBC_score_4_4[\"Precision\"][0]\n                                    ],\n                'F1_Score': [DTC_score_1_1[\"F1_score\"][0],\n                                        DTC_score_1_2[\"F1_score\"][0],\n                                        DTC_score_1_3[\"F1_score\"][0],\n                                        DTC_score_1_4[\"F1_score\"][0],\n                                        DTC_score_2_1[\"F1_score\"][0],\n                                        DTC_score_2_2[\"F1_score\"][0],\n                                        DTC_score_2_3[\"F1_score\"][0],\n                                        DTC_score_2_4[\"F1_score\"][0],\n                                        DTC_score_3_1[\"F1_score\"][0],\n                                        DTC_score_3_2[\"F1_score\"][0],\n                                        DTC_score_3_3[\"F1_score\"][0],\n                                        DTC_score_3_4[\"F1_score\"][0],\n                                        DTC_score_4_1[\"F1_score\"][0],\n                                        DTC_score_4_2[\"F1_score\"][0],\n                                        DTC_score_4_3[\"F1_score\"][0],\n                                        DTC_score_4_4[\"F1_score\"][0],\n                                        RFC_score_1_1[\"F1_score\"][0],\n                                        RFC_score_1_2[\"F1_score\"][0],\n                                        RFC_score_1_3[\"F1_score\"][0],\n                                        RFC_score_1_4[\"F1_score\"][0],\n                                        RFC_score_2_1[\"F1_score\"][0],\n                                        RFC_score_2_2[\"F1_score\"][0],\n                                        RFC_score_2_3[\"F1_score\"][0],\n                                        RFC_score_2_4[\"F1_score\"][0],\n                                        RFC_score_3_1[\"F1_score\"][0],\n                                        RFC_score_3_2[\"F1_score\"][0],\n                                        RFC_score_3_3[\"F1_score\"][0],\n                                        RFC_score_3_4[\"F1_score\"][0],\n                                        RFC_score_4_1[\"F1_score\"][0],\n                                        RFC_score_4_2[\"F1_score\"][0],\n                                        RFC_score_4_3[\"F1_score\"][0],\n                                        RFC_score_4_4[\"F1_score\"][0],\n                                        XGBC_score_1_1[\"F1_score\"][0],\n                                        XGBC_score_1_2[\"F1_score\"][0],\n                                        XGBC_score_1_3[\"F1_score\"][0],\n                                        XGBC_score_1_4[\"F1_score\"][0],\n                                        XGBC_score_2_1[\"F1_score\"][0],\n                                        XGBC_score_2_2[\"F1_score\"][0],\n                                        XGBC_score_2_3[\"F1_score\"][0],\n                                        XGBC_score_2_4[\"F1_score\"][0],\n                                        XGBC_score_3_1[\"F1_score\"][0],\n                                        XGBC_score_3_2[\"F1_score\"][0],\n                                        XGBC_score_3_3[\"F1_score\"][0],\n                                        XGBC_score_3_4[\"F1_score\"][0],\n                                        XGBC_score_4_1[\"F1_score\"][0],\n                                        XGBC_score_4_2[\"F1_score\"][0],\n                                        XGBC_score_4_3[\"F1_score\"][0],\n                                        XGBC_score_4_4[\"F1_score\"][0]\n                                    ]\n\n\n                           }\n    \n    score_results = pd.DataFrame(Score)\n\n    \n\n\n    return score_results\n\n\n\n","c826e7c1":"%time score_df_social = Models_Binary_Classification(social_df)","c00adb9e":"%time score_df_direct = Models_Binary_Classification(direct_df)","7b9884a3":"%time score_df_paidsearch = Models_Binary_Classification(paidsearch_df)","74b341ae":"%time score_df_organic = Models_Binary_Classification(organic_df)","e48be28d":"%time score_df_full = Models_Binary_Classification(full_df)","d0598204":"# Result social df\nsocial_top5_methods = score_df_social.sort_values(by=['F1_Score'],ascending=False).head().reset_index(drop=True)\nsocial_top5_methods","6768afcd":"# Result direct df\ndirect_top5_methods = score_df_direct.sort_values(by=['F1_Score'],ascending=False).head().reset_index(drop=True)\ndirect_top5_methods","7ad537c0":"# Result paid search df\npaidsearch_top5_methods = score_df_paidsearch.sort_values(by=['F1_Score'],ascending=False).head().reset_index(drop=True)\npaidsearch_top5_methods","1dde49f3":"# Result organic df \norganic_top5_methods = score_df_organic.sort_values(by=['F1_Score'],ascending=False).head().reset_index(drop=True)\norganic_top5_methods","bee5d76b":"# Result Full df\nfull_top5_methods = score_df_full.sort_values(by=['F1_Score'],ascending=False).head().reset_index(drop=True)\nfull_top5_methods","edb3647a":"# Table of the best methods and the shape size\n\nsizes_results={ 'Social DF ': [social_top5_methods['Methods'][0],\n                            social_top5_methods['Recall'][0],\n                            social_top5_methods['Precision'][0],\n                            social_top5_methods['F1_Score'][0],\n                                  ],\n               \n    'Direct DF ': [direct_top5_methods['Methods'][0],\n                             direct_top5_methods['Recall'][0],\n                            direct_top5_methods['Precision'][0],\n                            direct_top5_methods['F1_Score'][0],\n                              ],\n               \n    'Paid Search DF ': [paidsearch_top5_methods['Methods'][0],\n                            paidsearch_top5_methods['Recall'][0],\n                            paidsearch_top5_methods['Precision'][0],\n                            paidsearch_top5_methods['F1_Score'][0],\n                            ],\n               \n    'Organic DF ': [organic_top5_methods['Methods'][0],\n                                  organic_top5_methods['Recall'][0],\n                            organic_top5_methods['Precision'][0],\n                            organic_top5_methods['F1_Score'][0],\n                   ],\n                    \n    'Full DF ': [full_top5_methods['Methods'][0],\n                            full_top5_methods['Recall'][0],\n                            full_top5_methods['Precision'][0],\n                            full_top5_methods['F1_Score'][0],\n                      ]\n                    }\n\nsizes_results = pd.DataFrame.from_dict(sizes_results, orient='index')\nsizes_results.columns=['Best Method','Recall','Precision','F1-Score']","dadfb59e":"sizes_results = sizes_results.sort_values(by='F1-Score',ascending=False)\nsizes_results","8a71fe36":"from hyperopt import fmin, tpe, hp, anneal, Trials, STATUS_OK\n\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score","4a91081a":"def GB_hyperopt(gb_mse_cv, X_train, y_train, X_test, y_test ):\n    \n\n    space={'max_depth': hp.quniform('max_depth',5,10,1),\n            'learning_rate': hp.loguniform('learning_rate', -5, 0),\n            'n_estimators': hp.quniform('n_estimators', 500, 2000,1),\n\n    }\n\n   # trials will contain logging information\n    trials = Trials()\n\n    best=fmin(fn=gb_mse_cv, # function to optimize\n              space=space, # possible values of parameters\n              algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n              max_evals=5, # maximum number of iterations\n              trials=trials # logging\n             )\n   \n    model=xgb.XGBClassifier( n_estimators = int(best['n_estimators']),\n                            max_depth = int(best['max_depth']),\n                            learning_rate = best['learning_rate'],\n                            \n\n                           )\n                   \n    model.fit(X_train, y_train)\n\n    tpe_test_score=mean_squared_error(y_test, model.predict(X_test))\n    \n    return print(\"Best MSE {:.3f} params {}\".format( gb_mse_cv(best), best))","b984b58d":"X_train_2, y_train_2 = Without_Zeros(social_df)","cd61e251":"X_train_s, y_train_s = Ustl_Split(X_train_2, y_train_2)","b0c94d1f":"X_test_s, y_test_s = Raw_Data(social_df)[1:4:2]","95bb2a9e":"def gb_mse_cv( params, random_state=0, cv=4, X = X_train_s, y = y_train_s):\n\n    params = {'n_estimators': int(params['n_estimators']), \n              'max_depth': int(params['max_depth']), \n              'learning_rate': int(params['learning_rate']),\n             }\n\n    model = xgb.XGBClassifier(random_state=0, **params)\n    \n    score = -cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n\n    return score","0dc56bba":"#%time GB_hyperopt(gb_mse_cv, X_train_s, y_train_s, X_test_s, y_test_s.values.ravel())","cd6985c2":"clf_s_t = xgb.XGBClassifier(random_state = 0,\n                           learning_rate = 0.2359749458095008,\n                           max_depth = 6,\n                           n_estimators = 666)\n\nclf_s_t.fit(X_train_s,y_train_s)","1654e4e6":"plot_confusion_matrix(clf_s_t,\n                      X_test_s,\n                      y_test_s,\n                      display_labels=['Not transaction','Transaction'],\n                      normalize='pred')","bcd39e67":"score_s_t = Model_Score(clf_s_t, y_test_s, X_test_s)\n\nscore_s_t","727bf235":"X_train_2, y_train_2 = Without_Zeros(direct_df)","1bede69d":"X_train_d, y_train_d = Ustl_Split(X_train_2, y_train_2)","1e8f0f55":" X_test_d, y_test_d = Raw_Data(direct_df)[1:4:2]","c5aaaabd":"def gb_mse_cv( params, random_state=0, cv=4, X = X_train_d, y = y_train_d):\n\n    params = {'n_estimators': int(params['n_estimators']), \n              'max_depth': int(params['max_depth']), \n              'learning_rate': int(params['learning_rate']),\n             }\n\n    model = xgb.XGBClassifier(random_state=0, **params)\n    \n    score = -cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n\n    return score","5eda86d5":"#%time GB_hyperopt(gb_mse_cv, X_train_d, y_train_d, X_test_d, y_test_d.values.ravel())","b315d3f9":"clf_d_t = xgb.XGBClassifier(random_state = 0,\n                           learning_rate = 0.2563253209599783,\n                           max_depth = 6,\n                           n_estimators = 1581,\n                           )\n\nclf_d_t.fit(X_train_d,y_train_d)","b26c0c86":"plot_confusion_matrix(clf_d_t,\n                      X_test_d,\n                      y_test_d,\n                      display_labels=['Not transaction','Transaction'],\n                      normalize='pred')","0fd13c6e":"score_d_t = Model_Score(clf_d_t, y_test_d, X_test_d)\n\nscore_d_t","17b663ce":"X_train_2, y_train_2 = Without_Zeros(paidsearch_df)","4877fb71":"X_train_ps, y_train_ps = Ustl_Split(X_train_2, y_train_2)","ddb24ff1":"X_test_ps, y_test_ps = Raw_Data(paidsearch_df)[1:4:2]","38143afa":"def gb_mse_cv( params, random_state=0, cv=4, X=X_train_ps, y=y_train_ps):\n   \n\n    params = {'n_estimators': int(params['n_estimators']), \n              'max_depth': int(params['max_depth']), \n              'learning_rate': int(params['learning_rate']),\n             }\n\n    model = xgb.XGBClassifier(random_state=0, **params)\n    \n\n    score = -cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n    \n\n    return score","e2e9b5fc":"#%time GB_hyperopt(gb_mse_cv, X_train_ps, y_train_ps, X_test_ps, y_test_ps.values.ravel())","3d4c7f8c":"clf_ps_t = xgb.XGBClassifier(random_state = 0,\n                           learning_rate = 0.03823986877162998,\n                           max_depth = 6,\n                           n_estimators = 946)\n\nclf_ps_t.fit(X_train_ps,y_train_ps)","a6601ee7":"plot_confusion_matrix(clf_ps_t,\n                      X_test_ps,\n                      y_test_ps,\n                      display_labels=['Not transaction','Transaction'],\n                      normalize='pred')","98fbc472":"score_ps_t = Model_Score(clf_ps_t, y_test_ps, X_test_ps)\n\nscore_ps_t","e777a31c":"X_train_o, y_train_o = Without_Zeros(organic_df)","3ca26046":"X_test_o, y_test_o = Raw_Data(organic_df)[1:4:2]","ca04299f":"def gb_mse_cv( params,  cv=4, X = X_train_o, y = y_train_o):\n   \n\n    params = { \"n_estimators\" : int(params['n_estimators']),\n                  \"max_depth\" : int(params['max_depth']),\n                  \"learning_rate\": params['learning_rate'],\n              }\n              \n    model = xgb.XGBClassifier(random_state=0,**params)\n    \n    score = -cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n    \n    return score","e298e6be":"#%time GB_hyperopt(gb_mse_cv, X_train_o, y_train_o, X_test_o, y_test_o.values.ravel())","c1f90e2e":"clf_o_t = xgb.XGBClassifier(random_state = 0,\n                            max_depth= 9 ,\n                            n_estimators = 1169 ,\n                            learning_rate= 0.7445931836683217  ) \n\nclf_o_t.fit(X_train_o,y_train_o)","a4bb4038":"plot_confusion_matrix(clf_o_t,\n                      X_test_o,\n                      y_test_o,\n                      display_labels=['Not transaction','Transaction'],\n                      normalize='pred')","3b554d0f":"score_o_t = Model_Score(clf_o_t, y_test_o, X_test_o)\n\nscore_o_t","0a5449af":"X_train_2, y_train_2= Without_Zeros(full_df)","1815fbf6":"X_train_f, y_train_f = Ustl_Split(X_train_2, y_train_2)","a0c39ad6":"X_test_f, y_test_f = Raw_Data(full_df)[1:4:2]","f00276b9":"def gb_mse_cv( params, random_state=0, cv=4, X = X_train_f, y = y_train_f):\n   \n\n    params = {'n_estimators': int(params['n_estimators']), \n              'max_depth': int(params['max_depth']), \n              'learning_rate': int(params['learning_rate'])\n             }\n\n    model = xgb.XGBClassifier(random_state=0, **params)\n    \n\n    score = -cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n    \n\n    return score","1cfb4f00":"#%time GB_hyperopt(gb_mse_cv, X_train_f, y_train_f, X_test_f, y_test_f.values.ravel())","0dd3af13":"clf_f_t = xgb.XGBClassifier(random_state = 0,\n                           learning_rate = 0.03053044253030009,\n                           max_depth = 9,\n                           n_estimators = 994)\n\nclf_f_t.fit(X_train_f,y_train_f)","7bd8503b":"plot_confusion_matrix(clf_f_t,\n                      X_test_f,\n                      y_test_f,\n                      display_labels=['Not transaction','Transaction'],\n                      normalize='pred')","7b327798":"score_f_t = Model_Score(clf_f_t, y_test_f, X_test_f)\n\nscore_f_t","e8049374":"#F1_Score\n\nf1={'Social DF - XGB - USTL - Without Zeros': [social_top5_methods['F1_Score'][0],\n                                                                    score_s_t['F1_score'][0]\n                                                                  ],\n    'Direct DF - XGB - USTL - Without Zeros' : [direct_top5_methods['F1_Score'][0],\n                                                                    score_d_t['F1_score'][0]\n                                                                   ],\n               \n    'Paid Search DF - XGB - USTL - Without Zeros': [paidsearch_top5_methods['F1_Score'][0],\n                                                                score_ps_t['F1_score'][0] \n                                                            ],\n    'Organic DF - XGB - Unbalanced DF - Without Zeros': [organic_top5_methods['F1_Score'][0],\n                                                        score_o_t['F1_score'][0]\n                                                       ],\n    \n    'Full DF - XGB - USTL - Without Zeros':  [full_top5_methods['F1_Score'][0],\n                                                   score_f_t['F1_score'][0]\n                                                  ],\n            }\n\nf1_Score=pd.DataFrame.from_dict(f1, columns=['F1 Before Tunnig','F1-Score Tunned'],orient='index')\n                          \n\n#Precision\n\nprecision = {'Social DF - XGB - USTL - Without Zeros': [social_top5_methods['Precision'][0],\n                                                                    score_s_t['Precision'][0]\n                                                                  ],\n           'Direct DF - XGB - USTL - Without Zeros' : [direct_top5_methods['Precision'][0],\n                                                                    score_d_t['Precision'][0]\n                                                                   ],\n           'Paid Search DF - XGB - USTL - Without Zeros': [paidsearch_top5_methods['Precision'][0],\n                                                                score_ps_t['Precision'][0] \n                                                            ],\n           'Organic DF - XGB - Unbalanced DF - Without Zeros': [organic_top5_methods['Precision'][0],\n                                                        score_o_t['Precision'][0]\n                                                       ],\n           'Full DF - XGB - USTL - Without Zeros':  [full_top5_methods['Precision'][0],\n                                                   score_f_t['Precision'][0]\n                                                  ],\n           \n             }\n\nprecision = pd.DataFrame.from_dict(precision, columns=['Precision Before Tunnig','Precision Tunned'],orient='index')\n\n#Recall\n\nrecall = {'Social DF -  XGB - USTL - Without Zeros': [social_top5_methods['Recall'][0],\n                                                                    score_s_t['Recall'][0]\n                                                                  ],\n          \n        'Direct DF - XGB - XGB - USTL - Without Zeros' : [direct_top5_methods['Recall'][0],\n                                                                    score_d_t['Recall'][0]\n                                                                   ],\n          \n          'Paid Search DF - XGB - USTL - Without Zeros': [paidsearch_top5_methods['Recall'][0],\n                                                                score_ps_t['Recall'][0] \n                                                            ],\n          \n          'Organic DF - XGB - Unbalanced DF - Without Zeros': [organic_top5_methods['Recall'][0],\n                                                        score_o_t['Recall'][0]\n                                                       ],\n          \n          'Full DF - XGB - USTL - Without Zeros':  [full_top5_methods['Recall'][0],\n                                                   score_f_t['Recall'][0]\n                                                  ],\n\n             }\n\nrecall = pd.DataFrame.from_dict(recall, columns=['Recall Before Tunnig','Recall Tunned'],orient='index')\n                          ","8145d4fc":"precision.plot.bar(figsize=(15,5),color=['#4B0082','purple'])","cf8ef65f":"precision.sort_values(by='Precision Tunned',ascending=False)","583dc225":"recall.plot.bar(figsize=(15,5),color=['#4B0082','purple'])","aa516663":"recall.sort_values(by='Recall Tunned',ascending=False)","36d10dee":"f1_Score.plot.bar(figsize=(15,5),color=['#4B0082','purple'])","2cd4dcbb":"f1_Score.sort_values(by='F1-Score Tunned',ascending=False)","f89cec6a":"from xgboost import plot_tree","a28b2023":"def Feat_Importances(clf,X_train):\n    \n    feat_importances = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)[::-1]\n    \n    return feat_importances.nlargest(20).plot(kind='barh',color='#4B0082')","b9806e77":"clf_s_t.get_booster().best_iteration","3e771878":"fig, ax = plt.subplots(figsize=(25, 25))  # whatever size you want\nplot_tree(clf_s_t, ax=ax , num_trees=665)","1844e38b":"Feat_Importances(clf_s_t,X_train_s)","47c95fdc":"clf_d_t.get_booster().best_iteration","e34b638a":"fig, ax = plt.subplots(figsize=(25, 25))  # whatever size you want\nplot_tree(clf_d_t, ax=ax , num_trees=1580)","3a5f0a56":"Feat_Importances(clf_d_t,X_train_d)","3ccccb38":"clf_ps_t.get_booster().best_iteration","42537c6c":"fig, ax = plt.subplots(figsize=(25, 25))  # whatever size you want\nplot_tree(clf_ps_t, ax=ax , num_trees=945)","0b21fd53":"Feat_Importances(clf_ps_t,X_train_ps)","925ddb39":"clf_o_t.get_booster().best_iteration","25257fe0":"fig, ax = plt.subplots(figsize=(25, 25))  # whatever size you want\nplot_tree(clf_o_t, ax=ax , num_trees=1168)\n","68174dc8":"\nFeat_Importances(clf_o_t,X_train_o)","d6dd27fc":"clf_f_t.get_booster().best_iteration","6a64cc2f":"fig, ax = plt.subplots(figsize=(25, 50))  # whatever size you want\nplot_tree(clf_f_t, ax=ax , num_trees=993)","6cd4e075":"Feat_Importances(clf_f_t,X_train_f)","bd66507a":"import joblib","8e198e92":"joblib.dump(clf_s_t, 'social_model.sav')\njoblib.dump(clf_d_t, 'direct_model.sav')\njoblib.dump(clf_ps_t, 'paidsearch_model.sav')\njoblib.dump(clf_o_t, 'organic.sav')\njoblib.dump(clf_f_t,'full_df_model.sav')","5a1aa087":"## Organic  - Decision Tree and Feature Importance <a id='organictree'>","a2deb06d":"\n\nThe data that we will use was mining from Google Analytics API. To get the granular data with the GA API we need to query for multiple dimensions simultaneously, so then every row returned will represent one session. You can [see more at Alex Papageorgioy article](https:\/\/www.linkedin.com\/pulse\/5-steps-get-google-analytics-ready-data-science-papageorgiou\/). (Thank you Alex for the explanations)\n\n\n\n\n\nThe preparation of the data will be very simple, once we have already cleaned and organised at [Exploratory Analysis](https:\/\/www.kaggle.com\/erickvarela\/ga-api-e-commerce-part-i-exploratory-analysis\/). Here we just will drop the columns 'ga:transactionRevenue' and 'ga:itemQuantity' to avoid data leakage and the 'medium' of the DFs splitted per medium. The Full Df will keep the 'medium' column.\n\n\n\nAfter that, we will convert categorical variables into dummy\/indicator variables.\n\n\n","e48a17ed":"## PaidSearch - Decision Tree and Feature Importance <a id='paidsearchtree'>\n","dbd66bcc":"# Methodology <a id=\"methodology\"><\/a>\n\nPreviously, in [ GA API - E-commerce Data - Part I - Exploratory Analysis](https:\/\/www.kaggle.com\/erickvarela\/ga-api-e-commerce-parti-exploratory-analysis) we saw that each medium of traffic has particularities and that split the data based on the traffic sources can help us to get better analyses. Here we will check the premise that can improve the accuracy in machine learning problems building splitting the data. So, we will build a classification model per traffic and one classification model for the full DF and see what analysis has the higher accuracy.\n\n\nAs we saw at [Part I](https:\/\/www.kaggle.com\/erickvarela\/ga-api-e-commerce-part-i-exploratory-analysis\/) the DFs are very unbalanced with transactions as the minority class. Each DF has its outliers and a very high number of zeros in 'minutesessionDuration'. To build the best model we will test some hypotheses.\n\n- If we should train the model with outliers or without them.\n\n- If we should train the model with zeros or without them.\n\n- If we should balance the DF to get better results \n\nAlso we will see:\n\n- What is the best balance method per medium.\n\n- What are the best classification methods per medium.\n\nAs in [Part I](https:\/\/www.kaggle.com\/erickvarela\/ga-api-e-commerce-part-i-exploratory-analyse\/) we are going to build functions to make the process easy.\n","d13d5dc4":"# Introduction<a id=\"introduction\"><\/a>\n\n\n\nThis is the second part of my first project, here we are going to do a couple of tests to find the best classification model based on the F1-Score to predict transaction sessions. We will test the data preparation(with or without outliers), data balance methods and best machine learn classification techniques for the different datasets. After that we are going to plot the best decision tree interaction of the models. \n\n:)\n\n\n\nLet's get started.\n\n","b2b1a9ae":"## Classification Algorithms <a id='classification'>","9ce04af3":"# Tuning Best Mothods <a id='tbm'>\n","5003af18":"In that section will define a few functions that will be called later by the main function.","81ce4e6e":"##  Resampling Strategies Splitting\n\n\n\nDifferent types of resampling work best with different data sets.\nSince our intention is to extract decision rules generating a reliable decision tree, we must avoid methods which generate synthetic data such as SMOTE. \n\n\n\nWe are going to test three resampling strategies. \n\n\n\n* Random Under Sampler  - RUS - Under-sample the majority class by randomly picking samples with or without replacement.\n\n\n\n* Random Over Sampler - ROS - Over-sample the minority class by picking samples at random with replacement.\n\n\n\n* TomekLink Under Sampling - Under-sampling by removing the instances of the majority class, facilitating the classification process.\n\n\n\nI highly recommend the [Rafael's](https:\/\/www.kaggle.com\/rafjaa) [Notebook](https:\/\/www.kaggle.com\/rafjaa\/resampling-strategies-for-imbalanced-datasets) for more informations about resampling strategies.\n","3b3b39b0":"## Full DF - Decision Tree and Feature Importance <a name='fulldftree'>","f4d27677":"## Evaluate Metrics - Precision, Recall and F1-Score <a id='evaluate'>\n\nFor evaluating the binary classification models we will use Precision and Recall and F1-Score.\n\n* Precision - The number of positive predictions divided by the total number of positive class values predicted.\n\n* Recall - The number of True Positives divided by the number of True Positives and the number of False Negatives. \n\n* F1-score - The F1 Score is the 2*((precision*recall)\/(precision+recall)). Put another way, it is a balance between precision and recall and it will be the main evaluation.\n\n\n[See more](https:\/\/machinelearningmastery.com\/classification-accuracy-is-not-enough-more-performance-measures-you-can-use\/#:~:text=F1%20Score,the%20precision%20and%20the%20recall.) at Jason's article.\n","c2d4e095":"## Models Test <a id='mt'>","02925832":"## Tuning Results <a id='tr'>\n\nBuilding 3 tables with the precision, recall and F1-score before and after tuning.","f2f5ae04":"To plot a XGBoost Classification model with the features names we the plot_tree function.\n","259bd17d":"## F1-Score","0cd5207f":"## Table of Contents <a name=\"top\"><\/a>\n* [Introduction](#introduction)\n* [Data](#data)\n* [Methodology](#methodology)\n* [Function](#function)\n    * [Data Formats Split (Train and Test)](#dfs)\n    * [Resampling Strategies Splitting](#rss)\n    * [Evaluate Metrics - Precision, Recall and F1-Score](#evaluate)\n    * [Classification Algorithms](#classification)\n    * [Models Testing](#mt)\n    * [Result of Methods Evaluation](#rme)\n* [Tunig Best Models](#tbm)\n    * [Social](#social)\n    * [Direct](#direct)\n    * [Paid Search](#paidsearch)\n    * [Organic](#organic)\n    * [Full DF](#fulldf)\n    * [Tuning Results](#tr)\n* [Feature Importance and Decision Tree Plot  (Help!)](#helptree)\n    * [Social - Decision Tree and Feature Importance](#socialtree)\n    * [Direct - Decision Tree and Feature Importance](#directtree)\n    * [Paid Search - Decision Tree and Feature Importance](#paidsearchtree)\n    * [Organic - Decision Tree and Feature Importance](#organictree)\n    * [Full DF - Decision Tree and Feature Importance](#fulldftree)\n\n\n","9407e361":"## Recall","8f5af70c":"## Full DF - XGB - USTL - Without Zeros <a id='fulldf'>\n","4c51abfe":"## Social - Decision Tree and Feature Importance  <a id='socialtree'>","81051c67":"## Social DF - XGB - USTL - Without Zeros <a id='social'>","eed12264":"Also, below we defined a function to plot the feature importances.","652d5546":"## Organic - XGB - Unbalanced DF - Without Zeros <a id='organic'>","4778d9a0":"## Direct DF - XGB - USTL - Without Zeros <a id='direct'>\n","659fbe7a":"## Direct - Decision Tree and Feature Importance  <a id='directtree'>","f83a57ab":"## Data Cleaning  <a id=\"data\"><\/a>","d590c5ef":"# Feature Importance and Decision Tree Plot <a id='clfplot'>\n\n\n","26017a79":"[Back to the top](#top)","fbedbe48":"## Precision","f5be6fce":"The next function will test.\n\n* 4 Data preparations  \n    * Raw Data\n\n    * Without Zeros\n\n    * Without Outliers\n\n    * Without Zero and Outliers\n    \n\n* 3 Balancing strategy  \n    * Random Under Sampler\n\n    * Random Over Sampler\n\n    * TomekLinks Under Sampler\n    \n\n* 3 Different algorithms \n    * Decision Tree Classifier\n\n    * Random Forest Classifier\n\n    * Extreme Gradient Boosting\n\n\nIn the end will return a table with the recall precision and f1-score based on the test set Raw Data for the 48 different models.\n\n","cbf94476":"# Results of Methods Evaluation <a id='rme'>","3a8fe533":"To tune the best methods I will use hyperopt library to find the best parameters for max_depth, learning_ratte and n_esttimators. Next I train the model with the parameters, plot confusion_matrix for transactions and not transactions and define a new DF with the Precision Recall and F1-Score.\n","179249ff":"# Functions <a id='function'>","7450b3b2":"# Saving the Models <a id='saving'>","3eafc31f":"As the classifier winner in all data frames was the XGBoost, which works on the principle of ensemble. Our models are constituted by a lot of trees. To extract the decision rule we have to find the ordinal number of the best iteration booster to set as the \"num_tree\" parameter. \n\nTo do that we will use two functions that set  it for us .get_booster and .best_iteration. ","171d2388":"#  Google Analytics-API - Ecommerce - Binary Classification - Transactions","cf911286":"## Paid Search DF - XGB - USTL - Without Zeros <a id='paidsearch'>","52810963":"## Data Split Formats  (Train and Test) <a id='dfs'>\nThose functions will split the DFs in X_train and y_train and return them. The unique function that will return X_test and y_test will be the raw_data split. In this way, we will always test our model in the raw data set. The real world scenario.","246a382d":"We will test three classification algorithms\n\n* Decision Tree Classifier\n* Random Forest Classifier\n* Extreme Gradient Boosting\n"}}