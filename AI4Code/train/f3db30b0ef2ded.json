{"cell_type":{"932b03d1":"code","39b59d9b":"code","009005e2":"code","4cb008e7":"code","f15a12de":"code","192f2171":"code","ed46a55f":"code","9df9ec61":"code","81299163":"code","dd27b378":"code","da457cf0":"code","a07ec0d5":"code","896c6681":"code","fe41d0c8":"code","bd808e14":"code","441795ea":"code","e901a354":"code","3a00d2d7":"code","61621dc1":"code","f9b52ee1":"code","b10cf7c9":"code","efb646a7":"code","1d54bb42":"code","cc76fdd4":"code","0e01520e":"code","343c94b7":"code","279f1e8f":"code","2160f431":"code","943af375":"code","116e25a2":"code","b22f5312":"code","790eb9ea":"code","e42e5ab0":"code","4295c890":"code","af42cf4b":"code","8330f0c7":"code","3ce35e2c":"code","b2138321":"code","16fcacb8":"code","2b436a46":"code","218ce937":"code","e87fa455":"code","856756c6":"code","ded3673a":"code","864e9412":"code","db629c2b":"code","f292cc8d":"code","b81d9b5f":"code","c8e51230":"markdown","28880cc0":"markdown","c70d3d39":"markdown","30ee4135":"markdown","88b8af29":"markdown","0163d0d9":"markdown","5457ef48":"markdown","408012b1":"markdown","40de306f":"markdown","2af01ccc":"markdown","d8c9eed6":"markdown","5ca7bac5":"markdown","b593556e":"markdown"},"source":{"932b03d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","39b59d9b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport warnings\nwarnings.filterwarnings(\"ignore\")","009005e2":"df = pd.read_csv(\"\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","4cb008e7":"df.shape","f15a12de":"df.columns","192f2171":"df.head(20)","ed46a55f":"df.info()","9df9ec61":"df.isna().sum()","81299163":"df['TotalCharges'] = df['TotalCharges'].replace(\" \", 0).astype('float32')\ndf['SeniorCitizen']=pd.Categorical(df['SeniorCitizen'])","dd27b378":"df.describe().T","da457cf0":"df.corr()","a07ec0d5":"def kdeplot(feature):\n    plt.figure(figsize=(9, 4))\n    plt.title(\"KDE for {}\".format(feature))\n    ax0 = sns.kdeplot(df[df['Churn'] == 'No'][feature].dropna(), color= 'navy', label= 'Churn: No')\n    ax1 = sns.kdeplot(df[df['Churn'] == 'Yes'][feature].dropna(), color= 'orange', label= 'Churn: Yes')\nkdeplot('tenure')\nkdeplot('MonthlyCharges')\nkdeplot('TotalCharges')","896c6681":"def barplot_percentages(feature, orient='v', axis_name=\"percentage of customers\"):\n    ratios = pd.DataFrame()\n    g = df.groupby(feature)[\"Churn\"].value_counts().to_frame()\n    g = g.rename({\"Churn\": axis_name}, axis=1).reset_index()\n    g[axis_name] = g[axis_name]\/len(df)\n    if orient == 'v':\n        ax = sns.barplot(x=feature, y= axis_name, hue='Churn', data=g, orient=orient)\n        ax.set_yticklabels(['{:,.0%}'.format(y) for y in ax.get_yticks()])\n    else:\n        ax = sns.barplot(x= axis_name, y=feature, hue='Churn', data=g, orient=orient)\n        ax.set_xticklabels(['{:,.0%}'.format(x) for x in ax.get_xticks()])\n    ax.plot()\nplt.figure(figsize=(9, 4.5))\nbarplot_percentages(\"MultipleLines\", orient='h')","fe41d0c8":"ax = sns.catplot(x=\"MultipleLines\", y=\"MonthlyCharges\", hue=\"Churn\", kind=\"violin\",\n                 split=True, palette=\"pastel\", data=df, height=4.2, aspect=1.4)","bd808e14":"plt.figure(figsize=(9, 4.5))\nbarplot_percentages(\"InternetService\", orient=\"h\")","441795ea":"cols = [\"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"]\ndf1 = pd.melt(df[df[\"InternetService\"] != \"No\"][cols]).rename({'value': 'Has service'}, axis=1)\nplt.figure(figsize=(10, 4.5))\nax = sns.countplot(data=df1, x='variable', hue='Has service')\nax.set(xlabel='Additional service', ylabel='Num of customers')\nplt.show()","e901a354":"def display_bars_splitted(a,b=\"Churn\"):\n    df_g = df.groupby([a, b]).size().reset_index()\n    df_g['percentage'] = df.groupby([a, b]).size().groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).values\n    df_g.columns = [a, b, 'Counts', 'Percentage']\n\n    fig = px.bar(df_g, x=a, y=['Counts'], color=b, title = a, text=df_g['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)))\n    fig.show()\ndisplay_bars_splitted('PaperlessBilling')","3a00d2d7":"plt.figure(figsize=(9, 4.5))\nbarplot_percentages(\"PaymentMethod\", orient='h')","61621dc1":"ax = sns.catplot(y=\"Churn\", kind=\"count\", data=df, height=2.6, aspect=2.5, orient='h')","f9b52ee1":"yeni_df = df.iloc[:,[1,5,6,8,11,13,15,16,17,18,20]]","b10cf7c9":"yeni_df.head()","efb646a7":"yeni_df[\"gender\"] = yeni_df[\"gender\"].apply(lambda x: 1 if x=='Female' else 0)\nyeni_df[\"PhoneService\"] = yeni_df[\"PhoneService\"].apply(lambda x: 1 if x=='Yes' else 0)\nyeni_df[\"Churn\"] = yeni_df[\"Churn\"].apply(lambda x: 1 if x=='Yes' else 0)\nyeni_df[\"PaperlessBilling\"] = yeni_df[\"PaperlessBilling\"].apply(lambda x: 1 if x=='Yes' else 0)","1d54bb42":"yeni_df = pd.get_dummies(yeni_df,columns=['InternetService',\n       'DeviceProtection', \n       'StreamingTV',\n       'Contract',\n       'PaymentMethod',],drop_first=False)","cc76fdd4":"yeni_df.head(10)","0e01520e":"\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n","343c94b7":"y = yeni_df[\"Churn\"]\nX = yeni_df.drop(['Churn'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=2021)","279f1e8f":"from sklearn.linear_model import LogisticRegression\nloj = LogisticRegression(solver = \"liblinear\")\nloj_model = loj.fit(X_train,y_train)\nloj_model","2160f431":"loj_model.intercept_","943af375":"loj_model.coef_","116e25a2":"y_pred = loj_model.predict(X_test)","b22f5312":"print(confusion_matrix(y_test, y_pred))","790eb9ea":"accuracy_score(y_test, y_pred)","e42e5ab0":"print(classification_report(y_test, y_pred))","4295c890":"y = yeni_df[\"Churn\"]\nX = yeni_df.drop(['Churn'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=2021)","af42cf4b":"from sklearn.svm import SVC\nsvm_model = SVC(kernel = \"linear\").fit(X_train, y_train)","8330f0c7":"svm_model","3ce35e2c":"y_pred = svm_model.predict(X_test)","b2138321":"accuracy_score(y_test, y_pred)","16fcacb8":"y = yeni_df[\"Churn\"]\nX = yeni_df.drop(['Churn'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=2021)","2b436a46":"from xgboost import XGBClassifier\nxgb_model = XGBClassifier().fit(X_train, y_train)","218ce937":"xgb_model","e87fa455":"y_pred = xgb_model.predict(X_test)\naccuracy_score(y_test, y_pred)","856756c6":"from sklearn.ensemble import RandomForestClassifier","ded3673a":"rf_model = RandomForestClassifier().fit(X_train, y_train)","864e9412":"rf_model","db629c2b":"y_pred = rf_model.predict(X_test)\naccuracy_score(y_test, y_pred)","f292cc8d":"modeller = [\n    \n    loj_model,\n    svm_model,\n    xgb_model,\n    rf_model]\n\n\nfor model in modeller:\n    isimler = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    dogruluk = accuracy_score(y_test, y_pred)\n    print(\"-\"*28)\n    print(isimler + \":\" )\n    print(\"Accuracy: {:.4%}\".format(dogruluk))","b81d9b5f":"sonuc = []\n\nsonuclar = pd.DataFrame(columns= [\"Modeller\",\"Accuracy\"])\n\nfor model in modeller:\n    isimler = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    dogruluk = accuracy_score(y_test, y_pred)    \n    sonuc = pd.DataFrame([[isimler, dogruluk*100]], columns= [\"Modeller\",\"Accuracy\"])\n    sonuclar = sonuclar.append(sonuc)\n    \n    \nsns.barplot(x= 'Accuracy', y = 'Modeller', data=sonuclar, color=\"purple\")\nplt.xlabel('Accuracy %')\nplt.title('Accuracy of Models ');    ","c8e51230":"# Categorical Variable Encoding","28880cc0":"**Train Test Split**","c70d3d39":"# Feature Selection","30ee4135":"**Accuracy is the ratio of correct guesses to the total number of guesses.**\n\n **Precision is concerned with how many of what we predict will actually churn.** \n\n **We look at Recall because of false negatives in the denominator, people who are predicted not to churn and who churn.** \n\n **F1 - Score is the harmonic mean of precision and recall. If we are looking for balance between precision and recall, we look for cases where F1-Score is maximum.**\n\n<img src=\"https:\/\/i.ytimg.com\/vi\/RYFViaaJxE8\/hqdefault.jpg\" \/>\n<img src=\"https:\/\/miro.medium.com\/max\/564\/1*OYQpRezFugSZa4HSnBixVw@2x.jpeg\" \/>\n","88b8af29":"# SVM Model","0163d0d9":"# Exploratory Data Analysis","5457ef48":"# **What is Churn ?**\n\n\n**Customer Churn means that a customer (player, subscriber, user, etc.) has terminated its relationship with a company. Online businesses often treat a customer as if they have churned after a certain amount of time since the customer's last interaction with the site or service. The full cost of loss includes both the loss of revenue and the marketing costs associated with replacing these customers. Reducing user churn is a core business goal of every online business. In this project, a classification model is created with the data we have now to predict the customers who may churn in the future. By using this model, it may be possible to identify the customers who are likely to churn in the future, reach them and offer opportunities or advantageous offers to prevent them from churning.** ","408012b1":"# LogisticRegression Model","40de306f":"# Comparision of Classification Models","2af01ccc":"# Conclusion\n\n**Support Vector Machine Classifier Model has better accuracy amongst all classifer models that shown above. With this model we may able to reach a customer before he or she churns and we might be able to convice him\/her before he\/she churns.**","d8c9eed6":"# RandomForestClassifier ","5ca7bac5":"# XGBoost Model","b593556e":"# Data Visualisation "}}