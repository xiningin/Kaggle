{"cell_type":{"a2ef30dc":"code","b32f624e":"code","91b4a918":"code","a6711c89":"code","76d85862":"code","aa9700d9":"code","c5c75334":"code","270a06a4":"code","bdbc5af5":"code","dcf580b3":"code","4bfd04db":"code","05895cc5":"code","8d6ff3bb":"code","785a7e0d":"code","cfac8508":"markdown","6963e641":"markdown","51edeea9":"markdown","0058b5b6":"markdown","dae298ee":"markdown","edbbf7c9":"markdown","db9c4288":"markdown","817e0a46":"markdown","8e55c8ae":"markdown","1a004142":"markdown","4ff8f0eb":"markdown"},"source":{"a2ef30dc":"# Imports\n\nimport numpy as np\nimport pandas as pd \npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import impute\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import make_column_transformer\n\n#Files\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","b32f624e":"train_table = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_table = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\nprint(train_table.shape)\nprint(test_table.shape)\n\nplt.figure(figsize= (15,5))\nplt.title(\"Null Values\")\nsns.barplot(x = train_table.columns,y = train_table.isnull().sum())","91b4a918":"sns.barplot(x = test_table.columns,y = test_table.isnull().sum())","a6711c89":"test_table.describe()\ntest_table.dtypes\n\ntest_table.head(20)","76d85862":"train_table[\"Cabin\"].unique()\n#way too many. Goodbye cabin!\ntrain_table = train_table.drop(columns = [\"Cabin\",\"Ticket\",\"Name\"])\ntest_table = test_table.drop(columns = [\"Cabin\",\"Ticket\",\"Name\"])","aa9700d9":"X = train_table.drop(columns = [\"Survived\",\"PassengerId\"])\ny = train_table.Survived\nsex_converter = {\"male\":0,\"female\":1}\nprint(X)\nprint(test_table)","c5c75334":"X.Sex = X.Sex.map(sex_converter)\ntest_table.Sex =test_table.Sex.map(sex_converter)","270a06a4":"X = pd.concat([X.drop(columns = \"Embarked\"),pd.get_dummies(X[\"Embarked\"])],axis = 1)\nprint(X)\ntest_table = pd.concat([test_table.drop(columns = \"Embarked\"),pd.get_dummies(test_table[\"Embarked\"])],axis = 1)\n","bdbc5af5":"print(test_table)","dcf580b3":"si = SimpleImputer(strategy = \"mean\")\nX = si.fit_transform(X)\nX = pd.DataFrame(X)\nX.columns = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"C\",\"Q\",\"S\"]\nprint(X.head(20))\n#X.Age = pd.Series(si.fit_transform(X.Age))","4bfd04db":"test_table_X = test_table.drop(columns = \"PassengerId\")\ntest_table_X = si.fit_transform(test_table_X)\ntest_table_X = pd.DataFrame(test_table_X)\ntest_table_X.columns = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"C\",\"Q\",\"S\"]\nprint(test_table_X)","05895cc5":"rfg1 = RandomForestRegressor(n_estimators = 50)\nrfg2 = RandomForestRegressor(n_estimators = 25)\nrfg3 = RandomForestRegressor(n_estimators = 75)\nscores1 = -1*cross_val_score(rfg1,X,y,cv = 8, scoring = \"neg_mean_absolute_error\")\ntotal1 = 0 \nfor i in scores1:\n    total1 = total1 +i\nscores2 = -1*cross_val_score(rfg2,X,y,cv = 8, scoring = \"neg_mean_absolute_error\")\ntotal2 = 0 \nfor i in scores2:\n    total2 = total2 + i \nscores3 = -1*cross_val_score(rfg3,X,y,cv = 8, scoring = \"neg_mean_absolute_error\")\ntotal3 = 0 \nfor i in scores3:\n    total3 = total3 + i \nprint(total1\/len(scores1))\nprint(total2\/len(scores2))\nprint(total3\/len(scores3))","8d6ff3bb":"clf = tree.DecisionTreeClassifier(max_depth = 8)\nclf = clf.fit(X,y)\nscore_clf = -1*cross_val_score(clf,X,y,cv = 8, scoring = \"neg_mean_absolute_error\")\ntotal_clf = 0\nfor i in score_clf:\n    total_clf = total_clf + i\n    total_clf = total_clf \/ len(score_clf)\nprint(total_clf)\n#depth 20 is 1.759\n#0 is 1.75","785a7e0d":"#submission = open(\"submission_file.csv\",\"w\")\npredictions_final = pd.DataFrame() \npredictions_final = pd.concat([test_table.PassengerId, pd.Series(clf.predict(test_table_X))],axis = 1)\n#pd.Series(test_table.PassengerId) + pd.Series(clf.predict(test_table_X))\n\npredictions_final.columns = [\"PassengerId\",\"Survived\"]\npredictions_final.to_csv(\"submission_file.csv\",index=False)\n","cfac8508":"Each ticket and cabin is individual and are strings, and they have (probably) no bearing on survival. Since there are way too many unique values, I'll drop it. ","6963e641":"# Titanic\nHello! This is my submission for the Titanic. First, I'm going to import some libraries and files. ","51edeea9":"Preprocessing and imputing vals (getting rid of strings and missing vals) ","0058b5b6":"CLF is really good. I'm going to submit that, see how I do, and then if it's still bad I'll try XGBoost. I'll comment back how it goes, but under is my submission creation. ","dae298ee":"Let's split up X and y and do processing. (P.S. - I'm going to drop \"PassengerId\" in X because it has no bearing on survival. For example, if the later passengers listed in this list for some reason had higher rates of survival, the algorithms may accidentally associate higher passId nums with survival. Since I know they're not related, I'll drop it from X)","edbbf7c9":"Excellent! Let's load up our tables and get some basic information. ","db9c4288":"There's a ton of missing points in cabin, age, and embarked in the training data. Let's look at the testing data. ","817e0a46":"Cool! Simple Imputer next","8e55c8ae":"rfg2 has lowest error","1a004142":"It's missing age, fare, and cabin. Let's look more at the data. ","4ff8f0eb":"# Preprocessing is done!\nI'm going to try several algorithms and cross validation. "}}