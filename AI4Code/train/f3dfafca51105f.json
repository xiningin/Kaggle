{"cell_type":{"0e5b6a08":"code","800a17e3":"code","ea7b423b":"code","81af51c6":"code","9b6e55ee":"code","f53c15ca":"code","bfa13be0":"code","c9350f27":"code","c2e376ec":"code","19a717c9":"code","5a5ba68f":"code","b461aabd":"code","9c5b6c75":"code","0aa35149":"code","b8064d76":"markdown","4ccdf8e0":"markdown"},"source":{"0e5b6a08":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","800a17e3":"df = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\n# df_test = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv')","ea7b423b":"df = df.drop(columns = 'id')\n#df_test = df_test.drop(columns = 'id')","81af51c6":"x = df.drop(columns = 'target')\ny = df.target","9b6e55ee":"##create folds\nfrom sklearn import model_selection\ndf[\"kfold\"] = -1\n\ndf = df.sample(frac=1).reset_index(drop=True)\n\nkf = model_selection.StratifiedKFold(n_splits=5, shuffle=False, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X=df,y=df.target.values)):\n    print(len(train_idx), len(val_idx))\n    df.loc[val_idx, 'kfold'] = fold","f53c15ca":"# params ={'device':['gpu'],'learning_rate': 0.1508067112491576, 'lambda_l1': 2.4697757781805905, 'lambda_l2': 9.083741442132819e-08, 'num_leaves': 23, 'feature_fraction': 0.6677259987024685, 'bagging_fraction': 0.6000000000000001, 'subsample': 0.8, 'min_child_samples': 35}","bfa13be0":"params = {'tree_method':'gpu_hist','learning_rate': 0.016041989603833812, 'reg_lambda': 1.2450082944209884e-07, 'reg_alpha': 0.018872727796774496, 'subsample': 0.347006156357217, 'colsample_bytree': 0.8480272882395739, 'max_depth': 9, 'early_stopping_rounds': 487, 'n_estimators': 20000}","c9350f27":"import joblib\nimport lightgbm as lgb\nimport xgboost as xg\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn import tree\ndef run(fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    df_train = df_train.drop(columns = 'kfold')\n    df_valid = df_valid.drop(columns = 'kfold')\n    x_train = df_train.drop('target', axis=1).values\n    y_train = df_train.target.values\n    x_valid = df_valid.drop('target', axis=1).values\n    y_valid = df_valid.target.values\n    clf = xg.XGBClassifier(**params)\n    clf.fit(x_train, y_train)\n    y_pred = clf.predict_proba(x_valid)[:,1]\n    roc_auc_score = metrics.roc_auc_score(y_valid,y_pred)\n    print(f\"Fold={fold}, roc_auc_score={roc_auc_score}\")\n    File_name = 'model_lgb' + str(fold)\n    joblib.dump(\n    clf,File_name)\nfor i in range(5):\n    run(fold = i)","c2e376ec":"model_0_xgb= joblib.load('.\/model_lgb0')\nmodel_1_xgb =joblib.load('.\/model_lgb1')\nmodel_2_xgb= joblib.load('.\/model_lgb2')\nmodel_3_xgb= joblib.load('.\/model_lgb3')\nmodel_4_xgb= joblib.load('.\/model_lgb4')","19a717c9":"df_test = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\ndf_test = df_test.drop(columns = 'id')","5a5ba68f":"y_final_3 = model_3_xgb.predict_proba(df_test)[:,1]\ny_final_0 = model_0_xgb.predict_proba(df_test)[:,1]\ny_final_1 = model_1_xgb.predict_proba(df_test)[:,1]\ny_final_2 = model_2_xgb.predict_proba(df_test)[:,1]\ny_final_4 = model_4_xgb.predict_proba(df_test)[:,1]","b461aabd":"y_final_avg = (y_final_0 + y_final_1 +y_final_2 + y_final_3 + y_final_4)\/5","9c5b6c75":"submission['target'] = y_final_avg ","0aa35149":"submission.to_csv('submission.csv',index = False)","b8064d76":"## Ensemble","4ccdf8e0":"### Train.py"}}