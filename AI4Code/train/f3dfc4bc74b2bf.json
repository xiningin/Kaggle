{"cell_type":{"c77cdd95":"code","d637a90e":"code","1a56321e":"code","1d1a11a8":"code","50a49bb9":"code","0cf60f6f":"code","8ee79c5b":"code","4a0a9165":"code","a7e11850":"code","21044fab":"code","e5530fb5":"code","d51b005d":"code","7aca5bdd":"code","f04de6d9":"code","bb9b782d":"code","c597cb86":"code","0dd74750":"code","a4fc7ded":"code","2b288402":"code","0c2d9989":"code","8df89228":"code","ac0a5b0a":"code","7c32fb89":"code","757ad51a":"code","aeec8fee":"code","64274b38":"code","6c7fcebe":"code","c1cc2992":"code","3b0aec0d":"code","38efc671":"code","8562b349":"code","f5870ccc":"code","cf5aa759":"code","d247375f":"code","cb4c4f87":"code","a436f960":"code","c967ccf2":"code","10e9cc26":"code","a8a86763":"code","411c197d":"code","35fd132a":"code","4167b93b":"code","8a07d65e":"code","d9c16e89":"code","8cc9caaf":"code","11188185":"code","2bf41a34":"code","e8bd7ff2":"code","9243f4e9":"code","c99e515f":"code","ef8f7faf":"code","bcfc65a6":"code","6bffaee7":"code","d3d47cd3":"code","81371c72":"code","75b07af4":"code","a041c26d":"code","f6e95042":"markdown","90edde21":"markdown","1e863ae3":"markdown","5b786fc5":"markdown","4de92368":"markdown","569dfe73":"markdown","02a83d0a":"markdown","e4dae894":"markdown","5434ccfd":"markdown","d835721d":"markdown","46a0d7c9":"markdown","b86d725f":"markdown","92e23175":"markdown","856dac42":"markdown","aa2e7fb2":"markdown","81cf3b14":"markdown","c9638730":"markdown","323ffdaa":"markdown","5f010daf":"markdown","6176be8e":"markdown","4aa2bd1e":"markdown","75c34113":"markdown","8cecebfd":"markdown","6db37468":"markdown","dc373693":"markdown","32a90c3e":"markdown","2795c178":"markdown"},"source":{"c77cdd95":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom IPython.display import display\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\n%matplotlib inline","d637a90e":"data = pd.read_csv(r'..\/input\/winedataset\/02_WineDataset.csv')\npd.options.display.max_columns = None #Display all columns\npd.options.display.max_rows = None #Display all rows\ndata.head()","1a56321e":"data.describe()","1d1a11a8":"data.isnull().any().any() #Check is there is any NULL value in the data set","50a49bb9":"data.rename(columns={'fixed acidity': 'fixed_acidity',\n                     'citric acid':'citric_acid',\n                     'volatile acidity':'volatile_acidity',\n                     'residual sugar':'residual_sugar',\n                     'free sulfur dioxide':'free_sulfur_dioxide',\n                     'total sulfur dioxide':'total_sulfur_dioxide'},\n            inplace=True)","0cf60f6f":"data.head()","8ee79c5b":"data['quality'].unique()","4a0a9165":"data.quality.value_counts().sort_index()","a7e11850":"plt.figure(figsize=(10,15))\n\nfor pl,col in enumerate(list(data.columns.values)):\n    plt.subplot(4,3,pl+1)\n    sns.set()\n    sns.boxplot(col,data=data)\n    plt.tight_layout()\n","21044fab":"sns.catplot(x='quality', data=data, kind='count');\nplt.title('Distribution of the Quality');","e5530fb5":"data.corr()['quality'].sort_values()","d51b005d":"data_Cor = data.drop(['fixed_acidity', 'volatile_acidity', 'density', 'residual_sugar', 'chlorides','total_sulfur_dioxide'], axis=1)","7aca5bdd":"sns.pairplot(data_Cor,hue = 'quality');","f04de6d9":"plt.figure(figsize=(14,8))\nax = sns.heatmap(data_Cor.corr(), annot = True, cmap='RdPu')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.1, top - 0.1);","bb9b782d":"data['pH'].describe()","c597cb86":"data['sulphates'].describe()","0dd74750":"data['free_sulfur_dioxide'].describe()","a4fc7ded":"data['alcohol'].describe()","2b288402":"data.iloc[:,:11].head() #Removing the quality column","0c2d9989":"plt.figure(figsize=(10,15))\n\nfor pl,col in enumerate(list(data.iloc[:,:11].columns.values)):\n    plt.subplot(4,3,pl+1)\n    sns.violinplot(y= data[col],x='quality',data=data, scale='count')\n    plt.title(f'quality\/{col}')\n    plt.tight_layout()\n    \n    \n","8df89228":"#This plots a 2d scatter plot with a regression line. Easily showing the correlation, distribution, and outliers!\n\nfor col in (data.iloc[:,:11].columns.values):\n \n    sns.lmplot(x='quality',y=col,data=data, fit_reg=False)\n  \n    plt.title(f'quality\/{col}');\n    plt.ylabel(col);\n    plt.show();\n    plt.tight_layout();\n    plt.close() \n    \n    sns.lmplot(x='quality',y=col,data=data)\n  \n    plt.title(f'quality\/{col}');\n    plt.ylabel(col);\n    plt.show();\n    plt.tight_layout();\n    plt.close() \n    \n    print('   ')\n ","ac0a5b0a":"condition = [(data['quality']>6),(data['quality']<=4)]#Setting the condition for good and bad ratings\n\nrating = ['good','bad']\n","7c32fb89":"data['rating'] = np.select(condition,rating,default='average')\ndata.rating.value_counts()","757ad51a":"data.head(25)","aeec8fee":"#This cell takes roughly about 15mins to an hour+ to run \n#depending on the specifications of your workstation and the number\n#of columns you have! \n\nfor col in data.iloc[:,:11].columns.values:\n \n    \n    sns.set()\n    sns.violinplot(y= col ,x='rating',data=data, scale='count')\n    plt.title(f'rating\/{col}');\n    plt.ylabel(col);\n    plt.show();\n    plt.tight_layout();\n    plt.close() \n    \n    sns.set()\n    sns.swarmplot(x='rating',y=col,data=data)\n    plt.title(f'rating\/{col}');\n    plt.ylabel(col);\n    plt.show();\n    plt.tight_layout();\n    plt.close() \n    \n    print('   ')\n    ","64274b38":"data[[('rating'),('quality')]].head(25)","6c7fcebe":"data.groupby('rating')['quality'].value_counts()","c1cc2992":"#This changes the quality from numbers to ratings between good and bad\n\nbins = (2, 4, 9)\ngroup_names = ['bad', 'good']\ndata['quality'] = pd.cut(data['quality'], bins = bins, labels = group_names)\n\n","3b0aec0d":"data.head(25)","38efc671":"data[[('rating'),('quality')]].head(25)","8562b349":"#This basically maps all good values to 1 and all bad values to 0 in the quality column\n\ndfL = np.array(data['quality'])\n\ndfL = pd.DataFrame(dfL)\n\ndata['quality'] = dfL.apply(lambda x: x.map({'good':1,'bad':0})) \n\n\n","f5870ccc":"data.head(30)","cf5aa759":"data[[('rating'),('quality')]].head(25)","d247375f":"#Setting the values of X and Y\n\nX =  data[['alcohol','density','sulphates','pH','free_sulfur_dioxide','citric_acid']]\ny =  data['quality']\n","cb4c4f87":"X_tr,X_t,y_tr,y_t = train_test_split(X,y,random_state = 50)","a436f960":"X_tr.shape, X_t.shape","c967ccf2":"y_tr.shape, y_t.shape","10e9cc26":"stds= StandardScaler().fit(X_tr)\n\nX_tr= stds.transform(X_tr)\nX_t = stds.transform(X_t)\n","a8a86763":"#The functions below will be used to measure the accuracy of the model\n\ndef generateClassificationReport_Tr(y_true,y_pred):\n    '''Train data accuracy tester'''\n    print(classification_report(y_true,y_pred));\n    print(confusion_matrix(y_true,y_pred));\n    print('\\n\\nTrain Accuracy is: ',\n          round(100*accuracy_score(y_true,y_pred),3),'%\\n');\n    \ndef generateClassificationReport_T(y_true,y_pred):\n    '''Test data accuracy tester'''\n    print(classification_report(y_true,y_pred));\n    print(confusion_matrix(y_true,y_pred));\n    print('\\n\\nTest Accuracy is: ',\n          round(100*accuracy_score(y_true,y_pred),3),'%\\n');","411c197d":"#LOGISTIC REGRESSION\n\nlogr = LogisticRegression(max_iter=1000);\nlogr.fit(X_tr,y_tr);\n","35fd132a":"#TRAIN DATA\n\nytr_pred = logr.predict(X_tr)\ngenerateClassificationReport_Tr(y_tr,ytr_pred)\n","4167b93b":"#TEST DATA\n\nyt_pred = logr.predict(X_t)\ngenerateClassificationReport_T(y_t,yt_pred)","8a07d65e":"#RANDOM FOREST\n\nrfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(X_tr,y_tr);","d9c16e89":"#TRAIN DATA\n\nytr_pred = rfc.predict(X_tr)\ngenerateClassificationReport_Tr(y_tr,ytr_pred)","8cc9caaf":"#TEST DATA\n\nyt_pred = rfc.predict(X_t);\ngenerateClassificationReport_T(y_t,yt_pred);","11188185":"#GAUSSIAN NORMAL DISTRIBUTION \n\ngnd = GaussianNB()\ngnd.fit(X_tr,y_tr);","2bf41a34":"#TRAIN DATA\n\nytr_pred = gnd.predict(X_tr)\ngenerateClassificationReport_Tr(y_tr,ytr_pred)","e8bd7ff2":"#TEST DATA\n\nyt_pred = gnd.predict(X_t)\ngenerateClassificationReport_T(y_t,yt_pred)","9243f4e9":"#SUPPORT VECTOR CLASSIFIER\n\nsvc = SVC()\nsvc.fit(X_tr,y_tr);","c99e515f":"#TRAIN DATA\n\nytr_pred = svc.predict(X_tr)\ngenerateClassificationReport_Tr(y_tr,ytr_pred)","ef8f7faf":"#TEST DATA\n\nyt_pred = svc.predict(X_t)\ngenerateClassificationReport_T(y_t,yt_pred)","bcfc65a6":"#DESCISION TREE\n\ndtc = DecisionTreeClassifier()\ndtc.fit(X_tr,y_tr);","6bffaee7":"#TRAIN DATA\n\nytr_pred = dtc.predict(X_tr)\ngenerateClassificationReport_Tr(y_tr,ytr_pred)","d3d47cd3":"#TEST DATA\n\nyt_pred = dtc.predict(X_t)\ngenerateClassificationReport_T(y_t,yt_pred)","81371c72":"#STOCHASTIC GRADIENT DESCENT\n\nsgd = SGDClassifier()\nsgd.fit(X_tr, y_tr);","75b07af4":"#TRAIN DATA\n\nytr_pred = sgd.predict(X_tr)\ngenerateClassificationReport_Tr(y_tr,ytr_pred)","a041c26d":"#TEST DATA\n\nyt_pred = sgd.predict(X_t)\ngenerateClassificationReport_T(y_t,yt_pred)","f6e95042":"\n![wine.png](attachment:wine.png)","90edde21":"# 2. CHECKING FOR MISSING VALUES AND PROCESSING\/EXPLORING DATA \n<a class=\"anchor\" id=\"2-bullet\"><\/a>","1e863ae3":"*  X_tr is training data for x\n*  X_t is testing data for x\n*  y_tr is training data for y\n*  y_t is testing data for y","5b786fc5":"# 3. GRAPHICAL ANALYSIS \n<a class=\"anchor\" id=\"3-bullet\"><\/a>","4de92368":"# **CONCLUSION**\n\n\n## We see that alot of the models we used gave an accuracy really close to 100% but the Random Forest Classifier yielded the best results with an acuracy of 95.938%","569dfe73":"# From both the violin plot and the lm plot above we can easily see the correlation between the different attributes and the quality","02a83d0a":"# Focusing on the features in the data set that give a postive correlation we see both distribution of single variables on the diagonal with respect to the quality (denoted by the various colours) and relationships between two variables with respect to the quality(denoted by the various colours)","e4dae894":"# Both the train and test data will be passed to the models. This is done to check how accurate the models are. ","5434ccfd":"# **SUPPORT VECTOR CLASSIFIER**","d835721d":"# **THE PROCESSES INVOLVED IN THIS PROJECT ARE LISTED BELOW**\n\n<br> \n1. [IMPORTING THE DATA AND IMPORT MODULES USED IN THIS PROJECT](#1-bullet) <br><br>\n\n2. [CHECKING FOR MISSING VALUES AND PROCESSING\/EXPLORING DATA](#2-bullet)<br><br>\n\n3. [GRAPHICAL ANALYSIS ](#3-bullet) <br><br>\n\n4. [ CORRELATION ANALYSIS](#4-bullet) <br><br> \n   \n5. [DATA FITING AND TRANSFORMATION](#5-bullet) <br><br>\n    \n6. [DATA MODELLING: PREDICTING QUALITY](#6-bullet) <br><br>\n    \n<br>","46a0d7c9":"# 1. IMPORTING THE DATA AND IMPORT MODULES USED IN THIS PROJECT <a class=\"anchor\" id=\"1-bullet\"><\/a>","b86d725f":"# Based on the ratio of good,average, and bad wine samples in the data set and the total number of samples being 6,495; the percentage of these ratings are as follows:\n\n* good --- 20%\n* average --- 76%\n* bad --- 4%","92e23175":"# 5. DATA FITTING AND TRANSFORMATION\n<a class=\"anchor\" id=\"5-bullet\"><\/a>","856dac42":"# **Project Problem Description:**\n\n### A wine bottling company has a lab where they test wine quality.\n### The company wants to be able to predict the marketability of any new wine sample they get from a vineyard before they commit to marketing it.\n### Create a machine learning model to predict the quality score of a given wine sample\n ","aa2e7fb2":"\n#  Input Features\n*    fixed acidity\n*    volatile acidity\n*    citric acid\n*     residual sugar\n*     chlorides\n*    free sulfur dioxide\n*    total sulfur dioxide\n*  density\n*    pH\n*     sulphates\n*     alcohol\n   \nOutput variable:\n   Quality (score between 0 and 10)\n","81cf3b14":"# **DESCISION TREE**","c9638730":"# From the various box plots above we see that most of the data is right skewed. Focusing on Fixed Acidity we see that 50% of the data is roughly between 6.5 and 7.5. ","323ffdaa":"# From the correlation analysis done above we see that the attributes in the dataset that have a positive correlation with the quality are :\n\n*  pH  ---                    0.0195\n*  sulphates  ---                0.038485\n*  free_sulfur_dioxide  ---      0.055463\n*  citric_acid     ---           0.085532\n*  alcohol      ---              0.444319\n","5f010daf":"# **LOGISTIC REGRESSION**","6176be8e":"# We see in the graph above that the quality of wine that appears most in the data set is 6","4aa2bd1e":"# The swarm and violin plot shows how much of the data is distributed into the 'good', 'average', and 'bad' rating","75c34113":"# 6. **DATA MODELLING: PREDICTING QUALITY:**\n*  LOGISTIC REGRESSION\n*  RANDOM FOREST\n*  GAUSSIAN NORMAL DISTRIBUTION\n*  SUPPORT VECTOR CLASSIFIER\n*  DESCISION TREE\n*  STOCHASTIC GRADIENT DESCENT\n\n<a class=\"anchor\" id=\"6-bullet\"><\/a>","8cecebfd":"# **4. CORRELATION ANALYSIS:**\n\n*     PAIR PLOT\n*     BOX PLOTS,\n*     VIOLIN PLOTS\n*     SWARM LOTS \n*     LM PLOTS\n*     SCATTER DIAGRAMS \n*     DATA DISTRIBUTION PLOTS\n*    DATA ANALYSIS\n<a class=\"anchor\" id=\"4-bullet\"><\/a>","6db37468":" # **GAUSSIAN NORMAL DISTRIBUTION**","dc373693":"# Below we will analyse each attribute ","32a90c3e":"# **RANDOM FOREST**","2795c178":"# **STOCHASTIC GRADIENT DESCENT**"}}