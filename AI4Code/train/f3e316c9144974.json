{"cell_type":{"323be30a":"code","30122fab":"code","1756f4bb":"code","1de79d73":"code","20b49244":"code","3380b30f":"code","63437e95":"code","6d5148b4":"code","1a63b2b3":"code","c7358e6d":"code","4cdc969a":"code","3f0c3931":"code","3176bdbb":"code","72698245":"code","b31fdfea":"code","164ac647":"code","53a6aad7":"code","e684830f":"code","8dd505d7":"code","19c4401d":"code","6787a5b5":"code","85c7b9e3":"code","6990197d":"code","da17479e":"code","5c39de3a":"code","a39ac79b":"code","5ea54d57":"code","efceb4b4":"code","9db31a84":"code","11bbf278":"code","47b13214":"code","e1db0539":"code","e1161bc9":"code","1f2d5177":"code","661746c4":"code","e200cafd":"code","88944e55":"code","05760c3a":"code","cf4debbf":"code","14f05a23":"code","b0fd41bb":"code","c6bc80ed":"code","93f5dc4b":"code","291a86eb":"code","9e7fe9d7":"code","e2de24d6":"code","8e0bd3fd":"code","0e56afa7":"code","685149b7":"code","7da430a5":"code","60aa1fcc":"code","d476d63e":"code","3ea84acc":"code","655fb972":"code","f4abea9d":"code","ae9cda11":"code","ba3948e2":"code","d854a477":"code","a49bf2f7":"code","f363e8ab":"code","8061bd05":"code","6aa12d6e":"code","c87ff019":"code","1ff2a6f6":"code","b008a9a2":"code","488a2719":"code","168ee166":"code","2479f7db":"code","aa117c98":"code","4ff20d32":"code","97a023d8":"code","71ca4c9a":"code","7c2c5af8":"code","1f721d92":"code","093e4b96":"code","0825b649":"code","eaed0087":"code","778424b2":"code","9cb05b2e":"code","d96c9a45":"code","699bb999":"code","59dfc77d":"code","76c2430c":"code","d7bdd373":"code","26705f43":"code","01e3050a":"code","85198115":"code","f7591fcd":"code","62286d6f":"code","9e33f5bf":"code","b1408fc5":"code","475cc155":"code","2513f819":"code","ef7a394e":"code","68d6ac71":"code","58cba8bf":"code","649685d3":"code","36c4817d":"code","34bc033b":"code","3f202f86":"code","7c1187ea":"code","b6f0c205":"code","83f1f58a":"code","e19a23c4":"code","33536ac2":"code","1692366c":"code","a1aa1278":"code","844fcc99":"markdown","0454d145":"markdown","dd615d58":"markdown","dea84024":"markdown","6a7070d7":"markdown","bc37fd0b":"markdown","73d2bb93":"markdown","9f98c27a":"markdown","b06328d5":"markdown","840d09e3":"markdown","910aeab4":"markdown","742716a2":"markdown","5ea7a66e":"markdown","1c8d4ff8":"markdown","5cb0f1bf":"markdown","1dcc5e58":"markdown","5c0f5f46":"markdown","13e16ab9":"markdown","7df4764c":"markdown","aac8f4e1":"markdown","78e749d9":"markdown","a593c691":"markdown","5a96531b":"markdown","9e397457":"markdown","cc9277f8":"markdown","5a7fd76f":"markdown","fe59679e":"markdown","8b1b3703":"markdown","eb71f22a":"markdown","3599605f":"markdown","6fd7b41e":"markdown","81e102ae":"markdown","e672802a":"markdown","18c363cc":"markdown","6acfa37a":"markdown","26713a1f":"markdown","452ed8c4":"markdown"},"source":{"323be30a":"# Data manipulation\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set a few plotting defaults\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 18\nplt.rcParams['patch.edgecolor'] = 'k'","30122fab":"pd.options.display.max_columns = 150\n\n# Read in data\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntrain.head()","1756f4bb":"train.info()","1de79d73":"from collections import OrderedDict","20b49244":"plt.figure(figsize = (20, 12))\nplt.style.use('fivethirtyeight')\n\n# Color mapping\ncolors = OrderedDict({1: 'red', 2: 'orange', 3: 'blue', 4: 'green'})\npoverty_mapping = OrderedDict({1: 'extreme', 2: 'moderate', 3: 'vulnerable', 4: 'non vulnerable'})\n\nfor i,col in enumerate(train.select_dtypes('float')):\n    ax=plt.subplot(4,2,i+1)\n    for poverty_level,color in colors.items():\n        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(), \n                    ax = ax, color = color, label = poverty_mapping[poverty_level])\n        plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}'); plt.ylabel('Density')\n        \nplt.subplots_adjust(top = 2)","3380b30f":"train.select_dtypes('object').head()","63437e95":"map={'yes':1,\"no\":0}\nfor df in [train,test]:\n    df['dependency']=df['dependency'].replace(map).astype(np.float64)\n    df['edjefe']=df['edjefe'].replace(map).astype(np.float64)\n    df['edjefa']=df['edjefa'].replace(map).astype(np.float64)\ntrain[['dependency','edjefe','edjefa']].describe()","6d5148b4":"plt.figure(figsize = (20, 16))\nplt.style.use('ggplot')\n\n# Color mapping\ncolors = OrderedDict({1: 'red', 2: 'orange', 3: 'blue', 4: 'green'})\npoverty_mapping = OrderedDict({1: 'extreme', 2: 'moderate', 3: 'vulnerable', 4: 'non vulnerable'})\n\nfor i,col in enumerate(['dependency','edjefe','edjefa']):\n    ax=plt.subplot(3,1,i+1)\n    for poverty_level,color in colors.items():\n        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(), \n                    ax = ax, color = color, label = poverty_mapping[poverty_level])\n        plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}'); plt.ylabel('Density')\n        \n","1a63b2b3":"test['Target']=np.nan\ndata=train.append(test,ignore_index=True)","c7358e6d":"from sklearn.tree import DecisionTreeClassifier as DTC\n\nX = [[0],[1],[2]] # 3 simple training examples\nY = [ 1,  2,  1 ] # class labels\n#\u6700\u591a\u5206\u88c2\u4e00\u5c42\uff0c\u5373\u4e00\u4e2aroot\u8282\u70b9\uff0c\u4e24\u4e2aleaf\u8282\u70b9\ndtc = DTC(max_depth=1)","4cdc969a":"#\u4e0d\u5e26\u6743\u91cd\u62df\u5408\u51b3\u7b56\u6811\ndtc.fit(X,Y)\n#\u7ed3\u679c\uff1a0.5\u662f\u5de6leaf\u7684\u6807\u51c6, \u5373\u7b2c\u4e00\u4e2a\u6837\u672c[0]\u88ab\u5206\u5165\u5de6leaf\u8282\u70b9\nprint (dtc.tree_.threshold)\n# [0.5, -2, -2]\n#\u8ba1\u7b97\u4e0d\u7eaf\u5ea6\uff0croot+\u5de6\u53f3leaf,\u57fa\u5c3c\u6307\u6570\nprint ( dtc.tree_.impurity)\n# [0.44444444, 0, 0.5]","3f0c3931":"#\u7ed9\u4e09\u4e2a\u6837\u672c\u4e0d\u540c\u6743\u91cd\uff0c\u518d\u62df\u5408\u65b0\u7684\u51b3\u7b56\u6811\ndtc.fit(X,Y,sample_weight=[1,2,3])\n#\nprint (dtc.tree_.threshold)\n# [1.5, -2, -2]\nprint (dtc.tree_.impurity)\n# [0.44444444, 0.44444444, 0.]","3176bdbb":"data['Target'].value_counts()","72698245":"heads=data.loc[data['parentesco1'] == 1].copy()\ntrain_labels=data.loc[(data['Target'].notnull())&(data['parentesco1']==1),['Target','idhogar']]","b31fdfea":"len(train_labels)","164ac647":"type_counts=train_labels['Target'].value_counts()","53a6aad7":"type_counts=pd.DataFrame(type_counts)","e684830f":"type_counts['level']=type_counts.index","8dd505d7":"type_counts['level']=type_counts['level'].replace(poverty_mapping)\n","19c4401d":"type_counts['Count']=type_counts['Target']","6787a5b5":"ax = sns.barplot(x=\"level\", y=\"Count\", data=type_counts)","85c7b9e3":"all_equal=train.groupby('idhogar')['Target'].apply(lambda x: x.nunique()==1)","6990197d":"print(len(all_equal))\nall_equal.head()\ntype(all_equal)","da17479e":"not_equal= all_equal[all_equal!=True]","5c39de3a":"not_equal.head()","a39ac79b":"example=train.loc[train['idhogar']==not_equal.index[0],['idhogar', 'parentesco1', 'Target']]","5ea54d57":"example","efceb4b4":"households_leader=train.groupby('idhogar')['parentesco1'].sum()","9db31a84":"households_leader.head()","11bbf278":"households_leader_flase=train.loc[train['idhogar'].isin(households_leader\n                                                       [households_leader !=1].index),:]","47b13214":"households_leader_flase[['idhogar', 'parentesco1', 'Target']]","e1db0539":"for household in not_equal.index:\n    true_target= int(train[(train['idhogar']==household) & \n                          (train['parentesco1']==1.0)]['Target'])\n    train.loc[train['idhogar']==household, 'Target']=true_target","e1161bc9":"missing = pd.DataFrame(data.isnull().sum()).rename(columns={0:'total'})\nmissing['Percent']=missing['total']\/len(data)\nmissing.sort_values('Percent',ascending=False).head(10)","1f2d5177":"heads=data.loc[data['parentesco1']==1].copy()\nplt.figure(figsize=(8,6))\nheads['v18q1'].value_counts().sort_index().plot.bar()\nplt.show()","661746c4":"heads.groupby('v18q')['v18q1'].apply(lambda x:x.isnull().sum())","e200cafd":"data['v18q1']=data['v18q1'].fillna(0)","88944e55":"own_variables=[x for x in data if x.startswith('tipo')]","05760c3a":"own_variables","cf4debbf":"data.loc[data['v2a1'].isnull(),own_variables].sum().plot.bar()\nplt.xticks([0, 1, 2, 3, 4],\n           ['Owns and Paid Off', 'Owns and Paying', 'Rented', 'Precarious', 'Other'],\n          rotation = 60)","14f05a23":"owns=pd.DataFrame(data.loc[data['tipovivi3']==1,'Target'])","b0fd41bb":"owns['Target'].value_counts()","c6bc80ed":"# Fill in households that own the house with 0 rent payment\ndata.loc[(data['tipovivi1'] == 1), 'v2a1'] = 0\n","93f5dc4b":"\n# Create missing rent payment column\ndata['v2a1-missing'] = data['v2a1'].isnull()\n","291a86eb":"data['v2a1-missing'].value_counts()","9e7fe9d7":"data['v2a1'] = data['v2a1'].fillna(value=data['tipovivi3'])","e2de24d6":"data['v2a1'].head(20)","8e0bd3fd":"data.loc[((data['age']>19) | (data['age']<7)) & (data['rez_esc'].isnull()), 'rez_esc']=0","0e56afa7":"data['rez_esc-missing'] = data['rez_esc'].isnull()","685149b7":"data['rez_esc']=data['rez_esc'].fillna(0)","7da430a5":"data['rez_esc'].plot()","60aa1fcc":"data.loc[data['rez_esc'] > 5, 'rez_esc'] = 5","d476d63e":"id_ = ['Id', 'idhogar', 'Target']","3ea84acc":"ind_bool = ['v18q', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', \n            'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n            'parentesco1', 'parentesco2',  'parentesco3', 'parentesco4', 'parentesco5', \n            'parentesco6', 'parentesco7', 'parentesco8',  'parentesco9', 'parentesco10', \n            'parentesco11', 'parentesco12', 'instlevel1', 'instlevel2', 'instlevel3', \n            'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', \n            'instlevel9', 'mobilephone', 'rez_esc-missing']\n\nind_ordered = ['rez_esc', 'escolari', 'age']","655fb972":"hh_bool = ['hacdor', 'hacapo', 'v14a', 'refrig', 'paredblolad', 'paredzocalo', \n           'paredpreb','pisocemento', 'pareddes', 'paredmad',\n           'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisoother', \n           'pisonatur', 'pisonotiene', 'pisomadera',\n           'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', \n           'abastaguadentro', 'abastaguafuera', 'abastaguano',\n            'public', 'planpri', 'noelec', 'coopele', 'sanitario1', \n           'sanitario2', 'sanitario3', 'sanitario5',   'sanitario6',\n           'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', \n           'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', \n           'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3',\n           'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', \n           'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', \n           'computer', 'television', 'lugar1', 'lugar2', 'lugar3',\n           'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'v2a1-missing']\n\nhh_ordered = [ 'rooms', 'r4h1', 'r4h2', 'r4h3', 'r4m1','r4m2','r4m3', 'r4t1',  'r4t2', \n              'r4t3', 'v18q1', 'tamhog','tamviv','hhsize','hogar_nin',\n              'hogar_adul','hogar_mayor','hogar_total',  'bedrooms', 'qmobilephone']\n\nhh_cont = ['v2a1', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'overcrowding']","f4abea9d":"sqr_ = ['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', \n        'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq']","ae9cda11":"heads = data.loc[data['parentesco1'] == 1, :]\nheads = heads[id_ + hh_bool + hh_cont + hh_ordered]\nheads.shape","ba3948e2":"elec = []\n\n# Assign values\nfor i, row in heads.iterrows():\n    if row['noelec'] == 1:\n        elec.append(0)\n    elif row['coopele'] == 1:\n        elec.append(1)\n    elif row['public'] == 1:\n        elec.append(2)\n    elif row['planpri'] == 1:\n        elec.append(3)\n    else:\n        elec.append(np.nan)\n        \n# Record the new variable and missing flag\nheads['elec'] = elec\nheads['elec-missing'] = heads['elec'].isnull()\n","d854a477":"heads = heads.drop(columns = 'area2')\n\nheads.groupby('area1')['Target'].value_counts(normalize = True)","a49bf2f7":"# Wall ordinal variable\nheads['walls'] = np.argmax(np.array(heads[['epared1', 'epared2', 'epared3']]),\n                           axis = 1)\n\n# heads = heads.drop(columns = ['epared1', 'epared2', 'epared3'])\n#plot_categoricals('walls', 'Target', heads)","f363e8ab":"heads['epared2'].head()","8061bd05":"# Roof ordinal variable\nheads['roof'] = np.argmax(np.array(heads[['etecho1', 'etecho2', 'etecho3']]),\n                           axis = 1)\n#heads = heads.drop(columns = ['etecho1', 'etecho2', 'etecho3'])\n\n# Floor ordinal variable\nheads['floor'] = np.argmax(np.array(heads[['eviv1', 'eviv2', 'eviv3']]),\n                           axis = 1)\n# heads = heads.drop(columns = ['eviv1', 'eviv2', 'eviv3'])","6aa12d6e":"# Create new feature\nheads['walls+roof+floor'] = heads['walls'] + heads['roof'] + heads['floor']\n\n#plot_categoricals('walls+roof+floor', 'Target', heads, annotate=False)","c87ff019":"# No toilet, no electricity, no floor, no water service, no ceiling\nheads['warning'] = 1 * (heads['sanitario1'] + \n                         (heads['elec'] == 0) + \n                         heads['pisonotiene'] + \n                         heads['abastaguano'] + \n                         (heads['cielorazo'] == 0))","1ff2a6f6":"# Owns a refrigerator, computer, tablet, and television\nheads['bonus'] = 1 * (heads['refrig'] + \n                      heads['computer'] + \n                      (heads['v18q1'] > 0) + \n                      heads['television'])\n","b008a9a2":"heads['phones-per-capita'] = heads['qmobilephone'] \/ heads['tamviv']\nheads['tablets-per-capita'] = heads['v18q1'] \/ heads['tamviv']\nheads['rooms-per-capita'] = heads['rooms'] \/ heads['tamviv']\nheads['rent-per-capita'] = heads['v2a1'] \/ heads['tamviv']","488a2719":"#feature from other notebook\nheads.loc[(heads.v14a ==  1) & (heads.sanitario1 ==  1) & (heads.abastaguano == 0), \"v14a\"] = 0\nheads.loc[(heads.v14a ==  1) & (heads.sanitario1 ==  1) & (heads.abastaguano == 0), \"sanitario1\"] = 0","168ee166":"ind = data[id_ + ind_bool + ind_ordered]\nind.shape\nind['escolari\/age'] = ind['escolari'] \/ ind['age']\n\nplt.figure(figsize = (10, 8))\nsns.violinplot('Target', 'escolari\/age', data = ind);","2479f7db":"# Define custom function\nrange_ = lambda x: x.max() - x.min()\nrange_.__name__ = 'range_'\n\n# Group and aggregate\nind_agg = ind.drop(columns = 'Target').groupby('idhogar').agg(['min', 'max', 'sum', 'count', 'std', range_])\nind_agg.head()","aa117c98":"# Rename the columns\nnew_col = []\nfor c in ind_agg.columns.levels[0]:\n    for stat in ind_agg.columns.levels[1]:\n        new_col.append(f'{c}-{stat}')\n        \nind_agg.columns = new_col\nind_agg.head()","4ff20d32":"ind_feats = list(ind_agg.columns)\n\n# Merge on the household id\nfinal = heads.merge(ind_agg, on = 'idhogar', how = 'left')\n\nprint('Final features shape: ', final.shape)","97a023d8":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\n\n# Custom scorer for cross validation\nscorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')","71ca4c9a":"# Labels for training\ntrain_labels = np.array(list(final[final['Target'].notnull()]['Target'].astype(np.uint8)))\n\n# Extract the training data\ntrain_set = final[final['Target'].notnull()].drop(columns = ['Id', 'Target'])\ntest_set = final[final['Target'].isnull()].drop(columns = ['Id',  'Target'])\n\n# Submission base which is used for making submissions to the competition\nsubmission_base = test[['Id', 'idhogar']].copy()","7c2c5af8":"train_set['adult'] = train_set['hogar_adul'] - train_set['hogar_mayor']\ntrain_set['dependency_count'] = train_set['hogar_nin'] + train_set['hogar_mayor']\ntrain_set['dependency'] = train_set['dependency_count'] \/ train_set['adult']\ntrain_set['child_percent'] = train_set['hogar_nin']\/train_set['hogar_total']\ntrain_set['elder_percent'] = train_set['hogar_mayor']\/train_set['hogar_total']\ntrain_set['adult_percent'] = train_set['hogar_adul']\/train_set['hogar_total']\ntest_set['adult'] = test_set['hogar_adul'] - test_set['hogar_mayor']\ntest_set['dependency_count'] = test_set['hogar_nin'] + test_set['hogar_mayor']\ntest_set['dependency'] = test_set['dependency_count'] \/ test_set['adult']\ntest_set['child_percent'] = test_set['hogar_nin']\/test_set['hogar_total']\ntest_set['elder_percent'] = test_set['hogar_mayor']\/test_set['hogar_total']\ntest_set['adult_percent'] = test_set['hogar_adul']\/test_set['hogar_total']\n\ntrain_set['rent_per_adult'] = train_set['v2a1']\/train_set['hogar_adul']\ntrain_set['rent_per_person'] = train_set['v2a1']\/train_set['hhsize']\ntest_set['rent_per_adult'] = test_set['v2a1']\/test_set['hogar_adul']\ntest_set['rent_per_person'] = test_set['v2a1']\/test_set['hhsize']\n\ntrain_set['overcrowding_room_and_bedroom'] = (train_set['hacdor'] + train_set['hacapo'])\/2\ntest_set['overcrowding_room_and_bedroom'] = (test_set['hacdor'] + test_set['hacapo'])\/2","1f721d92":"train_set['r4h1_percent_in_male'] = train_set['r4h1'] \/ train_set['r4h3']\ntrain_set['r4m1_percent_in_female'] = train_set['r4m1'] \/ train_set['r4m3']\ntrain_set['r4h1_percent_in_total'] = train_set['r4h1'] \/ train_set['hhsize']\ntrain_set['r4m1_percent_in_total'] = train_set['r4m1'] \/ train_set['hhsize']\ntrain_set['r4t1_percent_in_total'] = train_set['r4t1'] \/ train_set['hhsize']\ntest_set['r4h1_percent_in_male'] = test_set['r4h1'] \/ test_set['r4h3']\ntest_set['r4m1_percent_in_female'] = test_set['r4m1'] \/ test_set['r4m3']\ntest_set['r4h1_percent_in_total'] = test_set['r4h1'] \/ test_set['hhsize']\ntest_set['r4m1_percent_in_total'] = test_set['r4m1'] \/ test_set['hhsize']\ntest_set['r4t1_percent_in_total'] = test_set['r4t1'] \/ test_set['hhsize']\n","093e4b96":"\ntrain_set['rent_per_room'] = train_set['v2a1']\/train_set['rooms']\ntrain_set['bedroom_per_room'] = train_set['bedrooms']\/train_set['rooms']\ntrain_set['elder_per_room'] = train_set['hogar_mayor']\/train_set['rooms']\ntrain_set['adults_per_room'] = train_set['adult']\/train_set['rooms']\ntrain_set['child_per_room'] = train_set['hogar_nin']\/train_set['rooms']\ntrain_set['male_per_room'] = train_set['r4h3']\/train_set['rooms']\ntrain_set['female_per_room'] = train_set['r4m3']\/train_set['rooms']\ntrain_set['room_per_person_household'] = train_set['hhsize']\/train_set['rooms']\n\ntest_set['rent_per_room'] = test_set['v2a1']\/test_set['rooms']\ntest_set['bedroom_per_room'] = test_set['bedrooms']\/test_set['rooms']\ntest_set['elder_per_room'] = test_set['hogar_mayor']\/test_set['rooms']\ntest_set['adults_per_room'] = test_set['adult']\/test_set['rooms']\ntest_set['child_per_room'] = test_set['hogar_nin']\/test_set['rooms']\ntest_set['male_per_room'] = test_set['r4h3']\/test_set['rooms']\ntest_set['female_per_room'] = test_set['r4m3']\/test_set['rooms']\ntest_set['room_per_person_household'] = test_set['hhsize']\/test_set['rooms']\n\ntrain_set['rent_per_bedroom'] = train_set['v2a1']\/train_set['bedrooms']\ntrain_set['edler_per_bedroom'] = train_set['hogar_mayor']\/train_set['bedrooms']\ntrain_set['adults_per_bedroom'] = train_set['adult']\/train_set['bedrooms']\ntrain_set['child_per_bedroom'] = train_set['hogar_nin']\/train_set['bedrooms']\ntrain_set['male_per_bedroom'] = train_set['r4h3']\/train_set['bedrooms']\ntrain_set['female_per_bedroom'] = train_set['r4m3']\/train_set['bedrooms']\ntrain_set['bedrooms_per_person_household'] = train_set['hhsize']\/train_set['bedrooms']\n\ntest_set['rent_per_bedroom'] = test_set['v2a1']\/test_set['bedrooms']\ntest_set['edler_per_bedroom'] = test_set['hogar_mayor']\/test_set['bedrooms']\ntest_set['adults_per_bedroom'] = test_set['adult']\/test_set['bedrooms']\ntest_set['child_per_bedroom'] = test_set['hogar_nin']\/test_set['bedrooms']\ntest_set['male_per_bedroom'] = test_set['r4h3']\/test_set['bedrooms']\ntest_set['female_per_bedroom'] = test_set['r4m3']\/test_set['bedrooms']\ntest_set['bedrooms_per_person_household'] = test_set['hhsize']\/test_set['bedrooms']\n\ntrain_set['tablet_per_person_household'] = train_set['v18q1']\/train_set['hhsize']\ntrain_set['phone_per_person_household'] = train_set['qmobilephone']\/train_set['hhsize']\ntest_set['tablet_per_person_household'] = test_set['v18q1']\/test_set['hhsize']\ntest_set['phone_per_person_household'] = test_set['qmobilephone']\/test_set['hhsize']\n\ntrain_set['age_12_19'] = train_set['hogar_nin'] - train_set['r4t1']\ntest_set['age_12_19'] = test_set['hogar_nin'] - test_set['r4t1']    \n\n","0825b649":"train_set['num_over_18'] = 0\ntrain_set['num_over_18'] = train_set[train.age >= 18].groupby('idhogar').transform(\"count\")\ntrain_set['num_over_18'] = train_set.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\ntrain_set['num_over_18'] = train_set['num_over_18'].fillna(0)\n\ntest_set['num_over_18'] = 0\ntest_set['num_over_18'] = test_set[test.age >= 18].groupby('idhogar').transform(\"count\")\ntest_set['num_over_18'] = test_set.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\ntest_set['num_over_18'] = test_set['num_over_18'].fillna(0)","eaed0087":"train_set=train_set.drop(columns='idhogar')\ntest_set=test_set.drop(columns='idhogar')","778424b2":"#deal with nan and inf\ntrain_set=train_set.replace([np.inf, -np.inf], np.nan)\ntest_set=test_set.replace([np.inf, -np.inf], np.nan)\ntrain_set.describe()","9cb05b2e":"train_set.columns","d96c9a45":"# drop duplicated columns\nneedless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v14a']\ntrain_set = train_set.drop(needless_cols, axis=1)\ntest_set = test_set.drop(needless_cols, axis=1)","699bb999":"features = list(train_set.columns)\n","59dfc77d":"train_set= train_set.fillna(0)\ntest_set= test_set.fillna(0)","76c2430c":"test_ids = list(final.loc[final['Target'].isnull(), 'idhogar'])","d7bdd373":"train_set = pd.DataFrame(train_set, columns = features)\n\n# Create correlation matrix\ncorr_matrix = train_set.corr()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(abs(upper[column]) > 1)]\n\nto_drop","26705f43":"train_set = train_set.drop(columns = to_drop)\ntrain_set.shape","01e3050a":"test_set = pd.DataFrame(test_set, columns = features)\ntrain_set, test_set = train_set.align(test_set, axis = 1, join = 'inner')\nfeatures = list(train_set.columns)","85198115":"from sklearn.feature_selection import RFECV\n\n# Create a model for feature selection\nestimator = RandomForestClassifier(random_state = 10, n_estimators = 100,  n_jobs = -1)\n\n# Create the object\nselector = RFECV(estimator, step = 1, cv = 3, scoring= scorer, n_jobs = -1)","f7591fcd":"selector.fit(train_set, train_labels)","62286d6f":"plt.plot(selector.grid_scores_);\n\nplt.xlabel('Number of Features'); plt.ylabel('Macro F1 Score'); plt.title('Feature Selection Scores');\nselector.n_features_","9e33f5bf":"train_selected = selector.transform(train_set)\ntest_selected = selector.transform(test_set)","b1408fc5":"# Convert back to dataframe\nselected_features = train_set.columns[np.where(selector.ranking_==1)]\ntrain_selected = pd.DataFrame(train_selected, columns = selected_features)\ntest_selected = pd.DataFrame(test_selected, columns = selected_features)","475cc155":"def macro_f1_score(labels, predictions):\n    # Reshape the predictions as needed\n    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n    \n    metric_value = f1_score(labels, predictions, average = 'macro')\n    \n    # Return is name, value, is_higher_better\n    return 'macro_f1', metric_value, True","2513f819":"\n\ndef learning_rate_power_0997(current_iter):\n    base_learning_rate = 0.1\n    min_learning_rate = 0.02\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return max(lr, min_learning_rate)\n","ef7a394e":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom IPython.display import display\n\ndef model_gbm(features, labels, test_features, test_ids, \n              nfolds = 5, return_preds = False, hyp = None,random_state_int=101,early_stopping=300):\n    \"\"\"Model using the GBM and cross validation.\n       Trains with early stopping on each fold.\n       Hyperparameters probably need to be tuned.\"\"\"\n    \n    feature_names = list(features.columns)\n\n    # Option for user specified hyperparameters\n    if hyp is not None:\n        # Using early stopping so do not need number of esimators\n        if 'n_estimators' in hyp:\n            del hyp['n_estimators']\n        params = hyp\n    \n    else:\n        # Model hyperparameters\n        params = {\n                  'colsample_bytree': 0.88, \n                  'learning_rate': 0.028, \n                   'min_child_samples': 10, \n                   'num_leaves': 36, \n                  \n                   'subsample': 0.54, \n                   'class_weight': 'balanced'}\n    \n    # Build the model\n    model = lgb.LGBMClassifier(**params, objective = 'multiclass', \n                               n_jobs = 4, n_estimators = 10000,\n                               random_state = 10)\n    \n    # Using stratified kfold cross validation\n    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True, random_state= random_state_int)\n    \n    # Hold all the predictions from each fold\n    predictions = pd.DataFrame()\n    importances = np.zeros(len(feature_names))\n    \n    # Convert to arrays for indexing\n    features = np.array(features)\n    test_features = np.array(test_features)\n    labels = np.array(labels).reshape((-1 ))\n    \n    valid_scores = []\n    \n    # Iterate through the folds\n    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n        \n        # Dataframe for fold predictions\n        fold_predictions = pd.DataFrame()\n        \n        # Training and validation data\n        X_train = features[train_indices]\n        X_valid = features[valid_indices]\n        y_train = labels[train_indices]\n        y_valid = labels[valid_indices]\n        \n        # Train with early stopping\n        model.fit(X_train, y_train, early_stopping_rounds =early_stopping, \n                  eval_metric = macro_f1_score,\n                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n                  eval_names = ['train', 'valid'],\n                  callbacks=[lgb.reset_parameter(learning_rate=learning_rate_power_0997)])\n        \n        # Record the validation fold score\n        valid_scores.append(model.best_score_['valid']['macro_f1'])\n        \n        # Make predictions from the fold as probabilities\n        fold_probabilitites = model.predict_proba(test_features)\n        \n        # Record each prediction for each class as a separate column\n        for j in range(4):\n            fold_predictions[(j + 1)] = fold_probabilitites[:, j]\n            \n        # Add needed information for predictions \n        fold_predictions['idhogar'] = test_ids\n        fold_predictions['fold'] = (i+1)\n        \n        # Add the predictions as new rows to the existing predictions\n        predictions = predictions.append(fold_predictions)\n        \n        # Feature importances\n        importances += model.feature_importances_ \/ nfolds   \n        \n        # Display fold information\n        display(f'Fold {i + 1}, Validation Score: {round(valid_scores[i], 5)}, Estimators Trained: {model.best_iteration_}')\n\n    # Feature importances dataframe\n    feature_importances = pd.DataFrame({'feature': feature_names,\n                                        'importance': importances})\n    \n    valid_scores = np.array(valid_scores)\n    display(f'{nfolds} cross validation score: {round(valid_scores.mean(), 5)} with std: {round(valid_scores.std(), 5)}.')\n    \n    # If we want to examine predictions don't average over folds\n    if return_preds:\n        predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n        predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n        return predictions, feature_importances\n    \n    # Average the predictions over folds\n    predictions = predictions.groupby('idhogar', as_index = False).mean()\n    \n    # Find the class and associated probability\n    predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n    predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n    predictions = predictions.drop(columns = ['fold'])\n    \n    # Merge with the base to have one prediction for each individual\n    submission = submission_base.merge(predictions[['idhogar', 'Target']], on = 'idhogar', how = 'left').drop(columns = ['idhogar'])\n        \n    # Fill in the individuals that do not have a head of household with 4 since these will not be scored\n    submission['Target'] = submission['Target'].fillna(4).astype(np.int8)\n    \n    # return the submission and feature importances along with validation scores\n    return submission, feature_importances, valid_scores","68d6ac71":"hyp1 = {\n                  'colsample_bytree': 0.88, \n                  'learning_rate': 0.08, \n                   'min_child_samples': 90, 'num_leaves': 34, 'subsample': 0.94, 'reg_lambda': 0.5, \n                   'class_weight': 'balanced'}\n\nhyp2 = {\n                  'colsample_bytree': 0.88, \n                  'learning_rate': 0.08, \n                   'min_child_samples': 90, 'num_leaves': 14, 'subsample': 0.94, 'reg_lambda': 0.5, \n                   'class_weight': 'balanced'}\n\nhyp3 = {\n                  'colsample_bytree': 0.78, \n                  'learning_rate': 0.08, \n                   'min_child_samples': 45, 'num_leaves': 14, 'subsample': 0.64, 'reg_lambda': 0.1, \n                   'class_weight': 'balanced'}\n\nhyp4 = {\n                  'colsample_bytree': 0.72, \n                  'learning_rate': 0.08, \n                   'min_child_samples': 30, 'num_leaves': 18, 'subsample': 0.64, 'reg_lambda': 0.1, \n                   'class_weight': 'balanced'}","58cba8bf":"%%capture --no-display\n\nsubmission1, gbm_fi_selected, valid_scores_selected = model_gbm(train_set, train_labels, test_set, test_ids,hyp = hyp1,random_state_int=103,early_stopping=300)\nsubmission2, gbm_fi_selected, valid_scores_selected = model_gbm(train_set, train_labels, test_set, test_ids,hyp = hyp1,random_state_int=103,early_stopping=300)\nsubmission3, gbm_fi_selected, valid_scores_selected = model_gbm(train_selected, train_labels, test_selected, test_ids)\n","649685d3":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom IPython.display import display\n\ndef model_gbm_2(features, labels, test_features, test_ids, \n              nfolds = 5, return_preds = False, hyp = None,random_state_int=101,early_stopping=300):\n    \"\"\"Model using the GBM and cross validation.\n       Trains with early stopping on each fold.\n       Hyperparameters probably need to be tuned.\"\"\"\n    \n    feature_names = list(features.columns)\n\n    # Option for user specified hyperparameters\n    if hyp is not None:\n        # Using early stopping so do not need number of esimators\n        if 'n_estimators' in hyp:\n            del hyp['n_estimators']\n        params = hyp\n    \n    else:\n        # Model hyperparameters\n        params = {\n                  'colsample_bytree': 0.88, \n                  'learning_rate': 0.028, \n                   'min_child_samples': 10, \n                   'num_leaves': 36, \n                  \n                   'subsample': 0.54, \n                   'class_weight': 'balanced'}\n    \n    # Build the model\n    model = lgb.LGBMClassifier(**params, objective = 'multiclass', \n                               n_jobs = 4, n_estimators = 10000,\n                               random_state = 10)\n    \n    # Using stratified kfold cross validation\n    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True, random_state= random_state_int)\n    \n    # Hold all the predictions from each fold\n    predictions = pd.DataFrame()\n    importances = np.zeros(len(feature_names))\n    \n    # Convert to arrays for indexing\n    features = np.array(features)\n    test_features = np.array(test_features)\n    labels = np.array(labels).reshape((-1 ))\n    \n    valid_scores = []\n    \n    # Iterate through the folds\n    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n        \n        # Dataframe for fold predictions\n        fold_predictions = pd.DataFrame()\n        \n        # Training and validation data\n        X_train = features[train_indices]\n        X_valid = features[valid_indices]\n        y_train = labels[train_indices]\n        y_valid = labels[valid_indices]\n        \n        # Train with early stopping\n        model.fit(X_train, y_train, early_stopping_rounds =early_stopping, \n                  eval_metric = macro_f1_score,\n                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n                  eval_names = ['train', 'valid'],\n                  verbose = 200)\n        \n        # Record the validation fold score\n        valid_scores.append(model.best_score_['valid']['macro_f1'])\n        \n        # Make predictions from the fold as probabilities\n        fold_probabilitites = model.predict_proba(test_features)\n        \n        # Record each prediction for each class as a separate column\n        for j in range(4):\n            fold_predictions[(j + 1)] = fold_probabilitites[:, j]\n            \n        # Add needed information for predictions \n        fold_predictions['idhogar'] = test_ids\n        fold_predictions['fold'] = (i+1)\n        \n        # Add the predictions as new rows to the existing predictions\n        predictions = predictions.append(fold_predictions)\n        \n        # Feature importances\n        importances += model.feature_importances_ \/ nfolds   \n        \n        # Display fold information\n        display(f'Fold {i + 1}, Validation Score: {round(valid_scores[i], 5)}, Estimators Trained: {model.best_iteration_}')\n\n    # Feature importances dataframe\n    feature_importances = pd.DataFrame({'feature': feature_names,\n                                        'importance': importances})\n    \n    valid_scores = np.array(valid_scores)\n    display(f'{nfolds} cross validation score: {round(valid_scores.mean(), 5)} with std: {round(valid_scores.std(), 5)}.')\n    \n    # If we want to examine predictions don't average over folds\n    if return_preds:\n        predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n        predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n        return predictions, feature_importances\n    \n    # Average the predictions over folds\n    predictions = predictions.groupby('idhogar', as_index = False).mean()\n    \n    # Find the class and associated probability\n    predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n    predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n    predictions = predictions.drop(columns = ['fold'])\n    \n    # Merge with the base to have one prediction for each individual\n    submission = submission_base.merge(predictions[['idhogar', 'Target']], on = 'idhogar', how = 'left').drop(columns = ['idhogar'])\n        \n    # Fill in the individuals that do not have a head of household with 4 since these will not be scored\n    submission['Target'] = submission['Target'].fillna(4).astype(np.int8)\n    \n    # return the submission and feature importances along with validation scores\n    return submission, feature_importances, valid_scores","36c4817d":"%%capture --no-display\nsubmission4, gbm_fi_selected, valid_scores_selected = model_gbm_2(train_set, train_labels, test_set, test_ids,hyp = hyp3,random_state_int=103,early_stopping=300)","34bc033b":"suball=submission1.merge(submission2, on='Id')\nsuball=suball.merge(submission4, on='Id')\nsuball=suball.merge(submission3, on='Id')\nsuball_2=suball.merge(submission4, on='Id')","3f202f86":"#\u52a0\u5165\u4e00\u4e2aindex\u5373\u5e8f\u53f7\uff0c\u4ee5\u65b9\u4fbfmerge\u7ed3\u679c\u5230\u539f\u6570\u636e\nsuball_2['index']=suball_2.index","7c1187ea":"modle_13= pd.DataFrame(suball_2.mode(axis=1)[0])","b6f0c205":"modle_13['index']=modle_13.index","83f1f58a":"modle_13.head()","e19a23c4":"final = suball_2.merge(modle_13, on ='index')","33536ac2":"final_res=final[['Id',0]]","1692366c":"final_res.columns=['Id','Target']","a1aa1278":"final_res.to_csv('4_model_vote.csv',index=False)","844fcc99":"\u9009\u51fa\u4e86105\u4e2a\u7279\u5f81\uff0c\u8fbe\u5230\u9a8c\u8bc1\u96c6\u6700\u5c0f\u8bef\u5dee\uff0c\u4f5c\u4e3atrain_selected\u7279\u5f81\u96c6\u7559\u4e0b\u540e\u9762\u7528\u3002\n\u5373\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u5019\uff0c\u901a\u8fc7train_selected\u4f5c\u4e3a\u5dee\u5f02\u5316\u7684\u8bad\u7ec3\u96c6\uff0c\u548c\u672a\u9009\u62e9\u7684\u7279\u5f81\u96c6\u5206\u522b\u8bad\u7ec3\u4e00\u4e24\u4e2a\u6a21\u578b\uff0c\u589e\u52a0\u8bad\u7ec3\u7684\u968f\u673a\u6027\uff0c\u518d\u878d\u5408\u3002","0454d145":"\u67e5\u770b\u6570\u636e\u96c6\u4e2d\u975e\u7eaf\u6570\u5b57\u7684\u5217\uff0c\u53d1\u73b0\u6570\u503c\u548c\u5206\u7c7b\u53d8\u91cf\u6df7\u6742\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u5904\u7406\uff0c\u5bf9\u4e8e\u51e0\u4e2a\u7279\u5f81\u7684\u89e3\u91ca\u5982\u4e0b\uff1a\n\ndependency\uff1a\u8ba1\u7b97\u629a\u517b\u7387=(19\u5c81\u4ee5\u4e0b\u621664\u5c81\u4ee5\u4e0a\u5bb6\u5ead\u6210\u5458\u6570)\/(19\u81f364\u5c81\u5bb6\u5ead\u6210\u5458\u6570)\n\nedjefe\uff1a\u7537\u6237\u4e3b\u53d7\u6559\u80b2\u5e74\u9650\uff0c\u57fa\u4e8eescolari \uff08\u53d7\u6559\u80b2\u5e74\u9650\uff09\u3001\u6237\u4e3b\u548c\u6027\u522b\uff0c\u662f=1\uff0c\u5426=0\n\nedjefa\uff1a\u5973\u6237\u4e3b\u53d7\u6559\u80b2\u5e74\u9650\uff0c\u57fa\u4e8eescolari \uff08\u53d7\u6559\u80b2\u5e74\u9650\uff09\u3001\u6237\u4e3b\u548c\u6027\u522b\uff0c\u662f=1\uff0c\u5426=0","dd615d58":"\u5982\u679c\u4e00\u4e2a\u5bb6\u5ead\u6709\u8d85\u8fc7\u4e00\u4e2a\u7684\u8d2b\u56f0\u7a0b\u5ea6\uff0c\u8ba4\u4e3a\u6237\u4e3b\u7684\u8d2b\u56f0\u7a0b\u5ea6\u662f\u51c6\u786e\u7684\uff0c\u5176\u4ed6\u4eba\u4f7f\u7528\u6237\u4e3b\u7684\u8d2b\u56f0\u7a0b\u5ea6\u4ee3\u66ff","dea84024":"\u8fd9\u91cc\u4f7f\u7528\u4e86\u4e00\u4e2a\u7279\u5f81\u9009\u62e9\u7684\u65b9\u6cd5Recursive Feature Elimination with Random Forest, \u5b83\u7684\u57fa\u7840\u662fRFE\uff0c RFE\u662f\u6839\u636e\u6811\u6a21\u578b\u8ba1\u7b97\u7684\u7279\u5f81\u7684\u91cd\u8981\u7a0b\u5ea6\uff0c\u540e\u5411\u9009\u62e9\uff0c\u7b2c\u4e00\u8f6e\u5148\u7528\u6240\u6709\u7279\u5f81\uff0c\u7b2c\u4e8c\u8f6e\u629b\u5f03\u8d21\u732e\u6700\u4f4e\u7684\u7279\u5f81\uff0c\u4ee5\u6b64\u5faa\u73af\u82e5\u5e72\u8f6e\u76f4\u5230\u6d4b\u6307\u5b9a\u7684\u7279\u5f81\u6570\u76ee\u8fbe\u5230\uff0c\u4e5f\u5c31\u662f\u6307\u5b9a\u4e00\u4e2a\u6570\u76ee\u6bd4\u598210\u4e2a\uff0c\u7136\u540eRFE\u4f1a\u9009\u62e9\u82e5\u5e72\u7279\u5f81\u4e2d\u2019\u53ef\u80fd\u6700\u597d\u2018\u768410\u4e2a\u3002Recursive Feature Elimination with Random Forest\u6211\u7684\u7406\u89e3\u662f\u904d\u5386\u4e86\u4ece1\u5230\u7279\u5f81\u603b\u6570, \u5bf9\u4e8e\u6bcf\u4e2a\u6570\u91cf\u505a\u4e00\u4e2aREF\uff0c\u4e00\u6b21\u6b21\u5e94\u7528REF,  \u901a\u8fc7\u9a8c\u8bc1\u96c6\u5224\u65ad\u51fa\u591a\u5c11\u4e2a\u7279\u5f81\u6700\u597d\uff0c\u6700\u597d\u7684\u7279\u5f81\u662f\u4ec0\u4e48\u3002\u8fd9\u91cc\u7684\u597d\u8868\u793a\u5728\u9a8c\u8bc1\u673a\u4e0a\u8bef\u5dee\u6700\u5c0f\u3002\u7136\u800c\u8fd9\u53ef\u80fd\u5e26\u6765\u4e00\u4e9b\u95ee\u9898\u3002\u540e\u9762\u53d1\u73b0\u9009\u62e9\u540e\u7684\u7279\u5f81\u96c6\u5728\u5176\u4ed6\u6761\u4ef6\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u6d4b\u8bd5\u96c6\u8868\u73b0\u4e0d\u5982\u672a\u9009\u62e9\u7684\u7279\u5f81\u3002\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u6d4b\u8bd5\u96c6\u8fdc\u5927\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u96c6\uff0c\u7279\u5f81\u9009\u62e9\u4f1a\u8fc7\u62df\u5408\u8bad\u7ec3\u9a8c\u8bc1\u96c6\u5408\uff0c\u5982\u679c\u4e0d\u662f\u8fd9\u6837\u8fd8\u8bf7\u591a\u6307\u6559~","6a7070d7":"**\u54e5\u65af\u8fbe\u9ece\u52a0\u5bb6\u5ead\u8d2b\u56f0\u6c34\u5e73\u9884\u6d4b**\n\n\u7f8e\u6d32\u5f00\u53d1\u94f6\u884c\u8bf7\u6c42Kaggle\u793e\u533a\u4e3a\u4e16\u754c\u4e0a\u4e00\u4e9b\u6700\u8d2b\u56f0\u7684\u5bb6\u5ead\u505a\u51fa\u5e2e\u52a9\u3002\n\u5b98\u7f51\uff1a https:\/\/www.kaggle.com\/c\/costa-rican-household-poverty-prediction \n\n\u80cc\u666f\u662f\uff1a\u94f6\u884c\u9700\u8981\u8bc4\u5b9a\u4eba\u4eec\u7684\u751f\u6d3b\u8d2b\u56f0\u72b6\u6001\u7b49\u7ea7\uff0c\u5728\u62c9\u4e01\u7f8e\u6d32\uff0c\u4e00\u79cd\u6d41\u884c\u7684\u65b9\u6cd5\u4f7f\u7528\u4e00\u79cd\u7b97\u6cd5\u6765\u9a8c\u8bc1\u6536\u5165\u8d44\u683c\u3002\u5b83\u88ab\u79f0\u4e3a\u4ee3\u7406\u6d4b\u8bd5\uff08PMT\uff09\u3002\u4e5f\u5c31\u662f\u6839\u636e\u4eba\u4eec\u7684\u5bb6\u5ead\u60c5\u51b5\uff0c\u4f8b\u5982\u5bb6\u91cc\u7684\u5899\u58c1\u548c\u5929\u82b1\u677f\u7684\u6750\u6599\uff0c\u751f\u5b58\u73af\u5883\u7b49\u4fe1\u606f\u8fdb\u884c\u8d2b\u56f0\u5ea6\u8bc4\u4f30\u3002\n\u6211\u4eec\u5e0c\u671b\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u63d0\u9ad8PMT\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002\n\n\u8fd9\u662f\u4e00\u4e2aKaggle\u5185\u6838\u7ade\u8d5b\uff0c\u5fc5\u987b\u901a\u8fc7\u5185\u6838\u63d0\u4ea4\u4ee3\u7801\uff0c\u800c\u4e0d\u662f\u4e0a\u4f20CSV\u9884\u6d4b\u7ed3\u679c\u3002\u5185\u6838\u7ade\u8d5b\u5c31\u662f\u6240\u6709\u64cd\u4f5c\u9700\u8981\u5728Kaggle\u63d0\u4f9b\u7684\u673a\u5668\u4e0a\u8ba1\u7b97\u5b8c\u6210\u3002\u5185\u6838\u7b97\u529b\u4e00\u822c\uff0c\u6211\u6ca1\u7528GPU\u7684\u60c5\u51b5\u4e0b4\u6838CPU\u7b97\u529b\u548cI3 \u5e94\u8be5\u5dee\u4e0d\u591a\u3002\n\n**\u76f8\u5bf9\u4e8e\u6392\u540d\uff0c\u6211\u66f4\u5e0c\u671b\u770b\u91cd\u5bf9\u4e8e\u6a21\u578b\u6709\u65b0\u7684\u5c1d\u8bd5\u548c\u7406\u89e3\u5176\u4e2d\u539f\u7406**\n\u5305\u62ec\n1. \u4e0d\u5e73\u8861\u6570\u636e\u91cf\u7684\u5904\u7406\u548c\u539f\u7406\uff0c\u5982\u4f55\u5f71\u54cd\u6811\u6a21\u578b\u751f\u957f\n2. \u8c03\u53c2\u5728\u6d4b\u8bd5\u96c6\u8fdc\u5927\u4e8e\u8bad\u7ec3\u96c6\u65f6\u662f\u5426\u6709\u8d1f\u9762\u4f5c\u7528\n3. \u5b66\u4e60\u7387\u9010\u6b65\u51cf\u5c11\u7684\u4f5c\u7528\uff0c\u5982\u4f55\u5f71\u54cdLightGBM\u8bad\u7ec3\n\n\u8fd9\u624d\u662f\u6bd4\u8d5b\u5e26\u6765\u7684\u771f\u7684\u4e1c\u897f\uff0c \u6392\u540d\u9760\u524d\u6216\u591a\u6216\u5c11\u5f97\u9760\u8fd0\u6c14\u548c\u6280\u5de7\u3002\n\n\u7531\u4e8e\u4ee5\u524d\u8be6\u7ec6\u8bb0\u5f55\u8fc7\u5176\u4ed6\u6bd4\u8d5b\u7684\u5168\u8fc7\u7a0b\uff0c\u8fd9\u4e00\u7bc7\u5bf9\u4e8e\u5f02\u5e38\u503c\u5904\u7406\u548c\u7279\u5f81\u7684\u8bf4\u660e\u8f83\u5c11\uff0c \u4f46\u662f\u5305\u542b\u4e86\u5b8c\u6574\u7684\u63d0\u4ea4\u6d41\u7a0b\uff1a\n\n1 \u6570\u636e\u63a2\u7d22\u4e0e\u6570\u636e\u9884\u5904\u7406\n1.1 \u8d5b\u9898\u56de\u987e\n1.2 \u6570\u636e\u63a2\u7d22\u6027\u5206\u6790\u4e0e\u5f02\u5e38\u503c\u5904\u7406\n\n2 \u7279\u5f81\u5de5\u7a0b\n2.1 \u65b0\u7279\u5f81\u6784\u5efa\n2.2 \u4e2a\u4eba\u7279\u5f81\u5411\u5bb6\u5ead\u7279\u5f81\u7684\u7efc\u5408\n\n3 \u6a21\u578b\u6784\u5efa\u4e0e\u8c03\u8bd5\n3.1 LightGBM\u7684\u4f7f\u7528\u548c\u878d\u5408\n\n\n\n\u6570\u636e\u8ba4\u77e5\u548c\u57fa\u672c\u6a21\u578b\u53c2\u7167https:\/\/www.kaggle.com\/willkoehrsen\/a-complete-introduction-and-walkthrough \n\u4f5c\u8005Will \u5199\u7684\u6587\u7ae0\u770b\u8d77\u6765\u4e00\u76f4\u4f1a\u53d7\u76ca\u532a\u6d45\u3002\n\n\u6700\u7ec8\u901a\u8fc75\u4e2a\u6709\u5dee\u5f02LightGBM\u6295\u7968\u6700\u4e3a\u6700\u7ec8\u7ed3\u679c\uff0c\u5355\u6a21\u578b\u53ef\u4ee5\u8fbe\u5230\u524d10\u7684\u6210\u7ee9\uff0c\u878d\u5408\u6a21\u578b\u53ef\u4ee5\u505a\u5230\u524d5\u3002\n\u5173\u4e8e\u4ee5\u4e0b\u4e09\u4e2a\u95ee\u9898\u8fd8\u8bf7\u591a\u6307\u70b9\u8ba8\u8bba\uff0c\u7f51\u4e0a\u80fd\u627e\u5230\u7684\u8ba8\u8bba\u5f88\u5c11\uff0c\u6211\u53c2\u8003\u4e86\u51e0\u7bc7\u539f\u8bba\u6587\u8bd5\u56fe\u66f4\u597d\u7684\u7406\u89e3\u3002\n1. \u4e0d\u5e73\u8861\u6570\u636e\u91cf\u7684\u5904\u7406\u548c\u539f\u7406\uff0c\u5982\u4f55\u5f71\u54cd\u6811\u6a21\u578b\u751f\u957f\n2. \u8c03\u53c2\u7684\u9650\u5236\uff0c\u5728\u6d4b\u8bd5\u96c6\u8fdc\u5927\u4e8e\u8bad\u7ec3\u96c6\u65f6\u7684\u8d1f\u9762\u4f5c\u7528\n3. \u5b66\u4e60\u7387\u9010\u6b65\u51cf\u5c11\u7684\u4f5c\u7528\uff0c\u5982\u4f55\u5f71\u54cdLightGBM\u8bad\u7ec3","bc37fd0b":"\u7531\u4e8e\u6d4b\u8bd5\u53ea\u770b\u6237\u4e3b \uff08['parentesco1'] == 1\uff09\u7684\u8d2b\u7a77\u7a0b\u5ea6\uff0c\u76f4\u63a5\u63d0\u53d6\u6240\u6709\u6237\u4e3b\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c\u67092973\u4e2a\u6237\u4e3b","73d2bb93":"\u53d1\u73b0\u6709\u51e0\u4e2a\u7279\u5f81\u6709\u8f83\u5927\u6bd4\u4f8b\u7684\u7a7a\u7f3a\u503c\uff0c\u5176\u4e2dv18q1\u662f\u5bb6\u91cc\u6709\u684c\u5b50\u7684\u6570\u91cf\uff0cgroupby v18q(\u662f\u5426\u5bb6\u5ead\u7528\u4e8e\u684c\u5b50\uff09 \u53ef\u4ee5\u53d1\u73b0v18q=1\uff0c\u5bb6\u5ead\u62e5\u6709\u684c\u5b50\u7684\u60c5\u51b5\u4e0b\uff0c\u6ca1\u6709\u7a7a\u7f3a\u503c\uff0c\u90a3\u4e48\u7a7a\u7f3a\u503c\uff0c\u5c31\u8868\u793a\u5bb6\u5ead\u6ca1\u6709\u684c\u5b50\uff0cv18q1\u7a7a\u7f3a\u503c\u4e5f\u5c31\u53ef\u4ee5\u586b\u8865\u4e3a0","9f98c27a":"\u6570\u636e\u8bf4\u660e\uff0c\u6bcf\u4e00\u4e2a\u5bb6\u5ead\u53ea\u80fd\u6709\u4e00\u4e2a\u8d2b\u56f0\u7a0b\u5ea6\uff0c\u6240\u4ee5\u9700\u8981\u628a\u4e00\u4e2a\u5bb6\u5ead\u591a\u4e8e\u4e00\u4e2a\u8d2b\u56f0\u7a0b\u5ea6\u7684\u9519\u8bef\u8fdb\u884c\u4fee\u6539","b06328d5":"\u8fd9\u91cc\u53c2\u8003\u6587\u6863\u4f5c\u8005WILL\u9009\u62e9\u5bf9\u4e8e\u6bcf\u4e00\u7ec4\u76f8\u5173\u6027\u5927\u4e8e0.95\u7684\u7279\u5f81\uff0c\u5f03\u7528\u4e00\u4e2a\uff0c\u6211\u8fd9\u91cc\u6ca1\u6709\u8fdb\u884c\u5f03\u7528\u7279\u5f81\uff08\u5373\u628a0.95\u8c03\u5230\u4e861\uff09","840d09e3":"\u53c2\u8003\u5176\u4ed6\u4eba\u7684\u8ba8\u8bba\uff0c\u8fd9\u91cc\u4f7f\u7528tipovivi3\uff0c\u5373\u662f\u5426\u79df\u623f\u53bb\u586b\u8865\u5269\u4f59\u7a7a\u7f3a\u503c","910aeab4":"\u6bd4\u5982\u7edf\u8ba1\u5bb6\u5ead\u4e2d\u7535\u5b50\u4ea7\u54c1\u7684\u6570\u91cf\uff0c\u591a\u7684\u5927\u6982\u7387\u4e0d\u4f1a\u592a\u8d2b\u7a77","742716a2":"\u4e0b\u9762\u7684\u6a21\u578b\u53d6\u6d88\u5b66\u4e60\u7387\u7684\u6539\u53d8\uff0c\u518d\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b","5ea7a66e":"\u4f7f\u7528\u4e86\u539f\u59cb\u7279\u5f81\u8bad\u7ec3\u4e24\u4e2a\u6a21\u578b\uff0c\u518d\u4f7f\u7528\u9009\u62e9\u540e\u7684\u7279\u5f81\u8bad\u7ec3\u4e00\u4e2a\u3002\u5e76\u4e14\u91c7\u7528\u4e0d\u540c\u53c2\u6570\u3002","1c8d4ff8":"\u7279\u5f81\u5de5\u7a0b\u4e4b\u540e\uff0c\u9664\u6cd5\u4f1a\u505a\u51fa\u4e00\u4e9binf\uff0c\u628a\u5b83\u53d8\u4e3a\u7a7a\u503c","5cb0f1bf":"\u5173\u4e8e\u6a21\u578b\u548c\u5b83\u7684\u53c2\u6570\uff1a\n\n\n\n\u8fd9\u4e2a\u6570\u636e\u96c6\u6d4b\u8bd5\u96c6\u6570\u91cf\u8fdc\u5927\u4e8e\u8bad\u7ec3\u96c6\n\u5176\u4ed6\u4eba\u5728\u8ba8\u8bba\u4e2d\u4f7f\u7528\u8fc7\u7f51\u683c\u641c\u7d22\uff0c\u8d1d\u53f6\u65af\u8c03\u53c2\u7b49\u65b9\u6cd5\uff0c\u6548\u679c\u5e76\u4e0d\u597d\uff0chttps:\/\/www.kaggle.com\/willkoehrsen\/a-complete-introduction-and-walkthrough \u4e2d\u76f4\u63a5\u653e\u5f03\u4e86\u4f7f\u7528\u8d1d\u53f6\u65af\u8c03\u53c2\u627e\u5230\u7684\u4e00\u7ec4\u53c2\u6570\uff0c\u800c\u662f\u91c7\u7528\u7684\u9ed8\u8ba4\u53c2\u6570\u3002\n\n\u8c03\u53c2\u4e00\u822c\u662f\u627e\u5230\u53c2\u6570\u4f7f\u5f97\u4ea4\u53c9\u9a8c\u8bc1\u7684\u7ed3\u679c\uff0c\u6216\u8005\u5355\u72ec\u9a8c\u8bc1\u96c6\u7684\u8bef\u5dee\u6700\u5c0f\uff0c\u8ba4\u4e3a\u662f\u62df\u5408\u6700\u597d\u7684\u53c2\u6570\u7ec4\u5408\u3002\u5728\u6d4b\u8bd5\u96c6\u8fdc\u591a\u4e8e\u8bad\u7ec3\u96c6\u7684\u60c5\u51b5\u4e0b\uff0c\u8c03\u53c2\u6709\u4e00\u70b9\u8fc7\u62df\u5408\u73b0\u6709\u6570\u636e\u7684\u8d8b\u52bf\uff0c\u5373\u4f7f\u8fd9\u4e00\u7ec4\u53c2\u6570\u53ef\u4ee5\u5bf9\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u673a\u8868\u73b0\u7531\u4e8e\u5176\u4ed6\u53c2\u6570\u7ec4\u5408\uff0c\u4f46\u662f\u6d4b\u8bd5\u96c6\u592a\u5927\u4e86\uff0c\u8fd9\u7ec4\u53c2\u6570\u6ca1\u6cd5\u4fdd\u8bc1\u6d4b\u8bd5\u96c6\u8868\u73b0\u4e00\u6837\u597d\u3002\n\n\u8fd9\u91cc\u91c7\u7528\u4e86\u9898\u76ee\u8ba8\u8bba\u4e2d\u5176\u4ed6\u4eba\u5728\u4e0d\u540c\u7279\u5f81\uff0c\u4f46\u662f\u540c\u6837\u662fLightGBM\u4f7f\u7528\u7684\u51e0\u7ec4\u53c2\u6570\uff0c\u4f46\u662f\u6ca1\u6709\u5bf9\u53c2\u6570\u8fdb\u884c\u8c03\u53c2\u4f18\u5316\u3002\n\n\u7136\u540e\u8bbe\u7f6e\u4e86\u56db\u7ec4\u53c2\u6570\uff0c\u51e0\u4e2aLightGBM\u6a21\u578b\u4f7f\u7528\u4e0d\u540c\u7684\u53c2\u6570\u548c\u6570\u636e\u5207\u5206\uff0c\u5f25\u8865\u5355\u4e00\u53c2\u6570\u548c\u8c03\u53c2\u6548\u679c\u5dee\u7684\u4e0d\u8db3\u3002\n\n\u7279\u70b9\u662f\u6bcf\u6b21\u4ea4\u53c9\u9a8c\u8bc1\u90fd\u7b97\u4e00\u4e2a\u5b50\u6a21\u578b\uff0c\u90fd\u505a\u4e00\u6b21\u9884\u6d4b\uff0c\u589e\u5927\u4e86\u968f\u673a\u6027\uff0c\u8fd9\u4e2a\u5728\u4e0a\u6b21\u6bd4\u8d5b\u4e2d\u4e5f\u6709\u8f83\u597d\u6548\u679c\u3002","1dcc5e58":"\u67e5\u770b\u8fd9\u51e0\u4e2a\u7279\u5f81\u7684KDE plot","5c0f5f46":"\u90a3\u4e48\u81ea\u7136\u7684\u4e00\u4e2a\u60f3\u6cd5\u662f\u5df2\u7ecf\u5168\u6b3e\u4e70\u623f\u7684\u5bb6\u5ead\uff0c\u4e0d\u7528\u652f\u4ed8\u623f\u79df\uff0c\u6309\u7167\u8fd9\u4e2a\u60f3\u6cd5\u4fee\u6539v2a1\u7684\u90e8\u5206\u7a7a\u7f3a\u503c","13e16ab9":"\u5bf9\u4e8e\u6bcf\u884c\u6d4b\u8bd5\u6570\u636e\u4e94\u4e2a\u6a21\u578b\u6295\u7968\uff0c\u5f97\u7968\u6700\u591a\u7684\u7ed3\u679c\u4f5c\u4e3a\u6700\u7ec8\u8d2b\u7a77\u7a0b\u5ea6","7df4764c":"**\u7b80\u5355\u6570\u636e\u63a2\u7d22**\n\u8fd9\u4e2a\u6570\u636e\u96c6\u6bd4\u8f83\u5b8c\u6574\uff0c\u753b\u56fe\u5206\u6790\u4e00\u4e9b\u7279\u5f81\u548c\u76ee\u6807\u7684\u5173\u7cfb\u3002\u7528\u7684\u662fKDE plot\uff0c\u6570\u636e\u5206\u5e03\u60c5\u51b5\uff0c\u90a3\u4e48\u597d\u7684\u7279\u5f81\uff0c\u56db\u79cd\u8d2b\u7a77\u7a0b\u5ea6\uff0c\u5373\u56db\u79cd\u989c\u8272\u7684\u5206\u5e03\u5e94\u8be5\u4ea4\u96c6\u8f83\u5c11\uff0c\u4ee3\u8868\u8be5\u7279\u5f81\u80fd\u8f83\u597d\u7684\u7528\u4e8e\u533a\u522b\u8d2b\u7a77\u7a0b\u5ea6\u3002\n\n\u7279\u5f81\u4e3e\u4f8b\u8bf4\u660e \nV2a1: \u6bcf\u6708\u623f\u79df\nV18q1: \u5bb6\u5ead\u62e5\u6709\u7684\u684c\u5b50\u7684\u6570\u91cf","aac8f4e1":"scorer \u662f\u6839\u636e\u9898\u76ee\u8981\u6c42 \u5355\u72ec\u5b9a\u4e49\u7684\u8bc4\u4ef7\u51c6\u5219","78e749d9":"\u4e0b\u9762\u4f7f\u7528\u5b66\u4e60\u7387\u9010\u6b65\u4e0b\u964d\u7684\u65b9\u6cd5\u3002\u67e5\u770bGBM\u539f\u6587[Stochastic Gradient Boosting Jerome H. Friedman* March 26, 1999 ...]\n\uff0c\u7406\u89e3\u5b66\u4e60\u7387\u5bf9boosting\u7684\u5f71\u54cd\uff1a\nBoosting\u6bcf\u6b21\u4f1a\u627e\u65b0\u7684\u4e00\u4e2a\u6811\uff0c\u4f7f\u5f97\u52a0\u5165\u8be5\u6811\u540e\uff0c\u6574\u4f53\u6a21\u578b\uff0c\u5373\u524d\u9762\u6240\u6709\u6811+\u65b0\u7684\u6811\u5e26\u6765\u7684\u6574\u4f53\u8bef\u5dee\u6700\u5c0f\u3002\n\n\u5b66\u4e60\u7387\u5373\u4e58\u5728\u65b0\u7684\u6811\u524d\u9762\u7684\u4e00\u4e2a\u6743\u91cd\uff0c\u57280\u52301\u4e4b\u95f4\u3002\n![image.png](attachment:image.png)\n\n\n\u53c2\u8003\u522b\u4eba\u7684\u5206\u4eab\uff0c\u4f7f\u7528learning rate decay\u5b66\u4e60\u7387\u9010\u6b65\u4e0b\u964d\uff0c\u53ef\u4ee5\u66f4\u5feb\u7684\u6536\u655b\uff0c\u4e00\u5f00\u59cb\u5b66\u4e60\u7387\u5927\uff0c\u540e\u9762\u5b66\u4e60\u7387\u5f88\u5c0f\uff0c\u907f\u514d\u65b0\u7684\u6811\u6709\u8fc7\u5927\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7ee7\u7eed\u589e\u52a0\u6811\u7684\u6570\u91cf\u624d\u80fd\u8fbe\u5230\u6536\u655b\n\u4e5f\u4f7f\u7528\u4e86\u65e9\u505c\uff0c\u5373\u65e0\u8bba\u8bad\u7ec3\u8fdb\u884c\u7684\u5982\u4f55\uff0c\u5728\u9a8c\u8bc1\u96c6\u4e0a\u6a21\u578b\u5728n\u68f5\u65b0\u7684\u6811\u52a0\u4e0a\u540e\uff0c\u4f9d\u7136\u4e0d\u80fd\u4f7f\u5f97\u6d4b\u8bd5\u8bef\u5dee\u51cf\u5c11\uff0c\u5219\u7acb\u523b\u505c\u6b62\u8bad\u7ec3\u3002\u53d6\u5f53\u524d\u6a21\u578b\u4e3a\u6700\u4f18\u6a21\u578b\u3002\n\u5bf9\u4e8eboosting\u7531\u4e8e\u5b83\u53ef\u4ee5\u786e\u5b9a\u6bcf\u4e00\u8f6e\u65b0\u52a0\u7684\u6811\u90fd\u4f1a\u4f7f\u6574\u4f53\u8bef\u5dee\u66f4\u5c0f\uff0c\u6309\u7406\u8bf4\u76f4\u63a5\u7528\u4e00\u4e2a\u5f88\u5c0f\u7684\u5b66\u4e60\u7387\u5c31\u53ef\u4ee5\u4e86\uff0c**\u4e3a\u4ec0\u4e48learning rate decay\u8fd8\u4f1a\u6bd4\u6052\u5b9a\u5f88\u5c0f\u7684\u5b66\u4e60\u7387\u6709\u66f4\u597d\u7684\u6548\u679c**\uff0c\u771f\u7684\u6ca1\u641e\u592a\u660e\u767d\uff0c\u8fd8\u8bf7\u591a\u591a\u6307\u6559\u4e86\u3002\n\n\u6709\u610f\u601d\u7684\u662flearning rate decay\uff0c17\u5e74\u521d\u5728\u521a\u63a5\u89e6\u6df1\u5ea6\u5b66\u4e60\u548cPython\u7684\u8bfe\u4e0a\u7b2c\u4e00\u6b21\u4e86\u89e3\uff0c\u8001\u5e08\u662f\u5927\u725b\uff0c\u4e0d\u592a\u6562\u63d0\u95ee\uff0c\u7b2c\u4e00\u6b21\u79c1\u4e0b\u95ee\u8001\u5e08\u7684\u95ee\u9898\u5c31\u662f\u5173\u4e8e\u5c40\u90e8\u6700\u4f18\u89e3\u548clearnign rate\u7684, \u90a3\u4e00\u5b66\u671f\u53ea\u542c\u61c2\u4e86\u4e00\u70b9CNN\u7684\u4e1c\u897f\uff0c\u4f46\u662f\u7531\u8877\u7684\u6b23\u8d4f\u8001\u5e08\u548cTA\u7684\u6c34\u5e73\u548c\u8bfe\u7a0b\u3002","a593c691":"\u5bf9\u4e8e\u4e00\u4e9b\u4e2a\u4eba\u5f80\u5bb6\u5ead\u7ea7\u522b\u7684\u7efc\u5408\uff0c\u53ef\u4ee5\u8ba1\u7b97\u4e00\u4e2a\u8303\u56f4\uff0c\u6bd4\u5982\u5bb6\u5ead\u5e74\u9f84\u8303\u56f4","5a96531b":"1. \u5bf9\u4e8ev2a1\u4f9d\u7136\u7a7a\u7f3a\u7684\u60c5\u51b5\uff0c\u6570\u636e\u96c6\u52a0\u4e0a\u4e00\u5217\u2019v2a1-missing\u2018\uff0c\u63d0\u662f\u6bcf\u884c\u662f\u5426v2a1\u7a7a\u7f3a","9e397457":"\u53ef\u4ee5\u53d1\u73b0\u5728\u56db\u4e2a\u8d2b\u7a77\u7a0b\u5ea6\u91cc\u9762\uff0c\u6781\u5ea6\u8d2b\u7a77\u7684\u4eba\u5f88\u5c11\uff0c\u56db\u4e2a\u7c7b\u522b\u6837\u672c\u6570\u91cf\u4e25\u91cd\u4e0d\u5747\u8861\uff0c\u8fd9\u6837\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f1a\u5f88\u5c11\u51e0\u7387\u5b66\u4e60\u6765\u81ea\u4e8e\u6781\u5ea6\u8d2b\u7a77\u7684\u6837\u672c\uff0c\u5bfc\u81f4\u9884\u6d4b\u4e0d\u51c6\u786e\u3002\u6837\u672c\u6570\u91cf\u4e0d\u5e73\u8861\u901a\u5e38\u6bd4\u8f83\u597d\u7684\u89e3\u51b3\u65b9\u5f0f\u662f\u5728\u6a21\u578b\u6837\u672c\u4e0a\u52a0\u6743\u91cd\uff0c\u5728\u672c\u9898\u4e2d\u53ea\u9700\u8981lightGBM \u8bbe\u7f6e class_weight \u53c2\u6570 \u4e3a \u2018balanced' \u3002\n\n\u5173\u4e8e\u8fd9\u6837\u505a\u7684\u5f71\u54cd\uff0csklearn \u5b98\u65b9\u6587\u6863\u53ea\u8bf4\u4e86\u8fd9\u6837\u7684\u60f3\u6cd5\u662f\u53d7\u5230\u201cLogistic Regression in Rare Events Data, King, Zen, 2001.\" \u542f\u53d1\uff0c\u53bb\u53c2\u8003\u539f\u6587\uff0c\u539f\u6587\u63d0\u51fa\u4e86\u4e0d\u5e73\u8861\u6837\u672c\u4e0b\u7684\u903b\u8f91\u56de\u5f52\u4fee\u6b63\uff0c\u4f5c\u8005\u901a\u8fc7\u540c\u65f6\u4f7f\u7528 1. Prior Correction 2. Weighting \u6539\u53d8\u4e86\u6700\u5927\u4f3c\u7136\u4f30\u8ba1 \u4f30\u8ba1\u53c2\u6570\u7684\u8fc7\u7a0b\u548c\u7ed3\u679c\uff0c\u6539\u53d8\u8fc7\u7a0b\u662f\u7528Weighting\u5bf9\u4e8e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u53d6\u6700\u5927\u503c\u7684\u8fc7\u7a0b\u52a0\u6743\uff0c\u5c31\u662f\u6837\u672c\u5c11\u7684\u7c7b\u522b\u6743\u91cd\u5927\uff0c\u76f8\u5bf9\u4e8e\u6ca1\u52a0\u6743\u7684\u60c5\u51b5\u6539\u53d8\u4e86\u53c2\u6570\u7684\u4f30\u8ba1\u503c\u3002Prior Correction\u5219\u662f\u76f4\u63a5\u4fee\u6b63\u53c2\u6570\u7684\u503c\u3002 Prior Correction \u4fee\u6b63\u5e45\u5ea6\u548cWeighting\u52a0\u6743\u7684\u6743\u7684\u503c\uff0c\u76f4\u63a5\u548c\u4e0d\u5e73\u8861\u6837\u672c\u6bcf\u7c7b\u6570\u91cf\u7684\u6bd4\u4f8b\u6709\u5173\u3002\nPrior Correction\n![image.png](attachment:image.png)\n Weighting \uff08Wi)\n ![image.png](attachment:image.png)\n\n\u5bf9\u4e8eLigthGBM\u6765\u8bf4\uff0c\u4ece\u6e90\u4ee3\u7801\u53ef\u4ee5\u53d1\u73b0\uff0cweighting\u5f71\u54cd\u4e86\u6811\u7684\u751f\u957f\u8fc7\u7a0b\uff0c\u4e3e\u7b80\u5355\u4f8b\u5b50\u548c\u4ee3\u7801\u8bf4\u660e\uff0c\u6765\u6e90\u53c2\u8003\nhttps:\/\/stackoverflow.com\/questions\/34389624\/what-does-sample-weight-do-to-the-way-a-decisiontreeclassifier-works-in-skle\n","cc9277f8":"**\u8bfb\u5165\u6570\u636e**\n\u8bad\u7ec3\u6570\u636etrain.csv, 9557\u884c\uff0c\u6bcf\u884c\u4e00\u4e2a\u4eba\uff0c143\u5217\uff0c\u4e5f\u5c31\u662f142\u4e2a\u7279\u5f81\uff0c\u52a0\u4e0a\u4e00\u4e2a\u76ee\u6807\u5217\uff0c\u4ece\u5bb6\u5ead\u4eba\u53e3\u72b6\u51b5\u76f4\u5230\u88c5\u4fee\u72b6\u51b5\uff0c\u5177\u4f53\u53ef\u53c2\u8003https:\/\/www.kaggle.com\/willkoehrsen\/a-complete-introduction-and-walkthrough\/data \u5bf9\u4e8e142\u4e2a\u7279\u5f81\u7684\u89e3\u91ca\u8bf4\u660e\u3002\n\n\u6d4b\u8bd5\u6570\u636etest.csv\uff0c 23856\u884c\u3002\n\n\u76ee\u6807\u5217\uff1a\u4e2a\u4eba\u8d2b\u7a77\u7a0b\u5ea6\u7684\u5206\u7c7b\uff0c\u67094\u4e2a\u7b49\u7ea7\n1 = \u6781\u5ea6\u8d2b\u7a77\n2 = \u6bd4\u8f83\u8d2b\u7a77\n3 = \u6709\u8d2b\u7a77\u7684\u53ef\u80fd\u6027\n4 = \u4e0d\u8d2b\u7a77\n\n\u51c6\u786e\u5ea6\u8bc4\u4ef7\u6307\u6807\u662fMacro F1=(F1 Class 1+F1 Class 2+F1 Class 3+F1 Class 4)\/4 ","5a7fd76f":"\u6df7\u5408test \u548c train","fe59679e":"\u53e6\u5916\u6709\u4e9b\u5bb6\u5ead\u6ca1\u6709\u6237\u4e3b\uff0c\u4e5f\u662f\u9519\u8bef\u6570\u636e","8b1b3703":"\u521d\u6b65\u4e86\u89e3\u6570\u636e\u548c\u5904\u7406\u4e86\u7a7a\u7f3a\u5f02\u5e38\u503c\u4e4b\u540e\uff0c\u53ef\u4ee5\u505a\u7279\u5f81\u5de5\u7a0b\u3002\n\u4ee5\u4e0b\u9996\u5148\u660e\u786e\u53d8\u91cf\u7684\u7c7b\u578b\u4ee5\u53ca\u7c7b\u522b\uff1a\n\n\u7c7b\u578b\uff1a\nbool(\u771f\/\u5047\uff09, ordered\uff08\u6709\u7b49\u7ea7\u5206\u7c7b\uff09, cout (\u8fde\u7eed\uff09\n\n\u7c7b\u522b:\nind(\u5bf9\u4e8e\u4e2a\u4eba\u7684\uff09\uff0c hh(\u5bf9\u4e8e\u5bb6\u5ead\u7684\uff09\n\n\u4e0b\u9762\u6309\u7167\u7c7b\u522b_\u7c7b\u578b\u4e3a\u7ec4\u5212\u5206\u6240\u6709\u53d8\u91cf\uff0c\u8fd9\u6837\u5212\u5206\u662f\u56e0\u4e3a\u5bf9\u4e8e\u4e2a\u4eba\u7684\u53d8\u91cf\uff0c\u53ef\u4ee5\u505a\u5bb6\u5ead\u7ea7\u522b\u7684\u7efc\u5408\uff0c\u6bd4\u5982\u8ba1\u7b97\u4e00\u4e2a\u5bb6\u5ead\u4e2d\u6240\u6709\u4eba\u7684\u5e73\u5747\u6536\u5165\uff0c\u6700\u9ad8\u5b66\u5386\uff0c\u5e74\u9f84\u8303\u56f4\u7b49\u7b49\u3002\n\n\u8fd8\u6709id\u548csqr\u662f\u5e8f\u53f7\u7c7b\u548c\u5df2\u77e5\u53d8\u91cf\u7684\u5e73\u65b9\u7c7b\uff0c\u4e0d\u9700\u592a\u591a\u5904\u7406\u3002\n\n\u7279\u5f81\u5de5\u7a0b\u53ef\u4ee5\n1. \u521b\u9020\u65b0\u53d8\u91cf\uff0c\u6bd4\u5982\u5bb6\u5ead\u4e2d \u623f\u5b50\u9762\u79ef\/\u603b\u4eba\u6570\uff0c\u53cd\u5e94\u62e5\u6324\u7a0b\u5ea6\n2. \u4e2a\u4eba\u7684\u53d8\u91cf\u505a\u5bb6\u5ead\u7ea7\u522b\u7684\u7efc\u5408\n\n\u7279\u5f81\u5177\u4f53\u7684\u542b\u4e49\u5b98\u7f51\u53ef\u67e5\uff0c\u8fd9\u91cc\u5f88\u591a\u65b0\u7684\u7279\u5f81\u90fd\u662f\u501f\u9274kaggle\u7684\u8ba8\u8bba\u548c\u5206\u4eab\u3002\n","eb71f22a":"\u5bf9\u4e8e\u5176\u4ed6\u4f9d\u7136\u7a7a\u7f3a\u7684\u503c\uff0c\u56e0\u4e3a\u6a21\u578b\u4e0d\u63a5\u53d7\u7a7a\u503c\uff0c\u8fd9\u91cc\u7b80\u5355\u7f6e\u96f6","3599605f":"\u5904\u7406\u7f3a\u5931\u503c\u548c\u5f02\u5e38\u503c","6fd7b41e":"\u7136\u540e\u5904\u7406rez_esc\u7a7a\u7f3a\u503c\uff0c\u8fd9\u4e2a\u7279\u5f81\u4ee3\u8868\u5728\u5b66\u6821\u843d\u540e\u51e0\u5e74\u7ea7\uff0c\u8fd9\u4e2a\u6570\u636e\u53ea\u5bf97-19\u5c81\u7684\u4eba\u6709\u610f\u4e49\uff0c\u90a3\u4e48\u8d85\u8fc7\u8fd9\u4e2a\u8303\u56f4\u7684\u4eba\uff0c\u53ef\u4ee5\u88650\uff0c\u6dfb\u52a0\u4e00\u5217rez_esc-missing\uff0c \u63d0\u793a\u662f\u5426\u4f9d\u7136\u7a7a\u7f3a\u3002","81e102ae":"\u8fd9\u51e0\u4e2a\u7279\u5f81\u7684\u610f\u4e49\u662f\uff1a\ntipovivi1 = 1\uff0c\u5b8c\u6210\u652f\u4ed8\u81ea\u5df1\u623f\u5b50\ntipovivi2 = 1\uff0c\u5728\u652f\u4ed8\u4e2d\ntipovivi3 = 1\uff0c\u79df\u7684\ntipovivi4 =1\uff0c \u4e0d\u7a33\u5b9a\u7684\ntipovivi5 = 1\uff0c\u5176\u4ed6\u5206\u914d\uff0c\u501f\u7684","e672802a":"\u53ef\u4ee5\u53d1\u73b0\uff0c\u52a0\u4e86\u6837\u672c\u6743\u91cd\u4e4b\u540e\uff0c\u6811\u7684\u5206\u88c2\u6807\u51c6\uff0c\u53f6\u5b50\u8282\u70b9\u4e0d\u7eaf\u5ea6\u90fd\u4f1a\u968f\u4e4b\u6539\u53d8\u3002\u8fd9\u6837\u4e5f\u5c31\u76f8\u5bf9\u4e8e\u6ca1\u6709\u52a0\u6837\u672c\u6743\u91cd\uff0c\u6a21\u578b\u7684\u53c2\u6570\u505a\u51fa\u4e86\u6539\u53d8\u3002\n\n","18c363cc":"\u770b\u4e2a\u9519\u8bef\u7684\u4f8b\u5b50","6acfa37a":"\u7f3a\u5931\u503cv2a1 \u7684\u5904\u7406\u5219\u53ef\u4ee5\u548c\u79df\u623f\/\u4e70\u623f\u72b6\u6001\uff08tipoxxxx)\u4e00\u8d77\u770b","26713a1f":"\u8fd9\u91cc\u8fd8\u6709\u4e2a\u5f02\u5e38\u70b9\uff0c\u5728\u5b66\u6821\u843d\u540e\u4e8697\u5e74\uff0c\u8fd9\u662f\u4e0d\u73b0\u5b9e\u7684\uff0c\u628a\u5b83\u4fee\u6539\u4e00\u4e0b","452ed8c4":"\u57fa\u4e8e\u7279\u5f81\u7684\u89e3\u91ca\u8bf4\u660e\uff0cdependency\u548cedjefe\t\uff0cedjefa\u66ff\u6362yes no \u4e3a 1 \u548c 0 "}}