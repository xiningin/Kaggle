{"cell_type":{"4daf7161":"code","e9f9b6f2":"code","e7ae1ea9":"code","fcf522a8":"code","bf273352":"code","2918b256":"code","7746d752":"code","e4f7de3e":"code","f630e2a5":"code","87289b7f":"code","089cd095":"code","82a2e13f":"code","8fbbdcee":"code","d8834414":"code","2e1ed218":"code","57c50798":"code","c32c6a2f":"code","f1811e86":"code","ee86c3a1":"code","bb25131f":"code","6456aa11":"code","66c8f8d8":"code","67c5928c":"code","e43692cf":"code","1986b309":"code","6996e8a3":"code","3ad9a746":"code","84fe7b30":"code","9dbc7b9d":"code","3516eb59":"code","05a6cc69":"code","69862db7":"code","35b06ccb":"code","8bd23a4f":"code","61492a81":"code","0339fc38":"code","2ccd7e8d":"code","f78fe82b":"code","54edbc5c":"code","c7185399":"code","c0f524d4":"markdown","fd5472a2":"markdown","baabc869":"markdown","94c9b77b":"markdown","1a8d27d8":"markdown","437ae222":"markdown","2f2a6544":"markdown","11d47a90":"markdown","73d0bad7":"markdown","0e706fd3":"markdown","22e81a0d":"markdown","5b408db9":"markdown","e4eff00c":"markdown","c20a7624":"markdown","a0d853a0":"markdown","ea58117f":"markdown","d17f7077":"markdown","96bc077b":"markdown","999d0c90":"markdown","655b49eb":"markdown","9abd1a3d":"markdown","b7c97c17":"markdown","21cc2fa8":"markdown","8d21be36":"markdown","b790a2bb":"markdown","14ef6b01":"markdown"},"source":{"4daf7161":"# packages to load in \nimport numpy as np                                   # linear algebra\nimport pandas as pd                                  # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math                                          # from math import cos, asin, sqrt\nimport warnings                                      #ignore warnings\nwarnings.filterwarnings('ignore')                    # supress the warning messages\nimport dask                                          # distributed parallel processing\nimport dask.dataframe as dd                          # data processing, CSV file I\/O (e.g. pd.read_csv), dask\nfrom dask.distributed import Client, progress        # task distribution\nclient = Client()\nimport seaborn as sns, matplotlib.pyplot as plt      # visualizations\n% matplotlib inline\n\nimport folium                                        # map visualizations\nfrom folium.plugins import HeatMap                  # map visualizations - heatmap \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# input file path \ndata_train_file_path =   \"..\/input\/train.csv\"\ndata_test_file_path = \"..\/input\/test.csv\"","e9f9b6f2":"client","e7ae1ea9":"%%time\ndb_rows_count = 55423857\nwith open(data_train_file_path) as f:\n    db_rows_count = len(f.readlines())   \nprint(\"no. of rows in the training data : {0}\\n\".format(db_rows_count))","fcf522a8":"# training data - Set columns to most suitable type to optimize for memory usage and speed-up the loading\ntrain_types = {'fare_amount'      : 'float32',\n               'pickup_datetime'  : 'str', \n               'pickup_longitude' : 'float32',\n               'pickup_latitude'  : 'float32',\n               'dropoff_longitude': 'float32',\n               'dropoff_latitude' : 'float32'}\n\n# test-data - Set columns to most suitable type to optimize for memory usage and speed-up the loading\ntest_types = { 'pickup_datetime'  : 'str',\n                'key'             : 'str',\n               'pickup_longitude' : 'float32',\n               'pickup_latitude'  : 'float32',\n               'dropoff_longitude': 'float32',\n               'dropoff_latitude' : 'float32'}\n\n\n# select the columns (names) that you truly need for analysis - training data\ntrain_cols = list(train_types.keys())    \n\n# select the columns (names) that you truly need for analysis - test data\ntest_cols = list(test_types.keys())  \n\n# NY city - defining the bounding box\nBB = (-74.5, -72.8, 40.5, 41.8)        \n\n# set the amount of data to load from db\nfrac = 0.00050                   # set the amount of data to load from db\n    \n# select within the bounding box\ndef select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n\n","bf273352":"def load_data(data_file_path, train_data='Y'):\n    \n    # training data load and filter inputs    \n    if (train_data=='Y'):\n        df = dd.read_csv(data_file_path,usecols=train_cols, dtype=train_types)  # data load, dask\n        \n        column_names = [\"fare_amount\",\n                        \"pickup_longitude\",\n                        \"pickup_latitude\", \n                        \"dropoff_longitude\",\n                        \"dropoff_latitude\"]                          # selecting the columns to check for empty values\n        df = df.sample(frac=0.04)                                    # percentage of rows to load.  loading 2 million rows\n        df = df.dropna(how=\"any\", subset = train_cols)               # remove rows with null values\n        df = df[(df[column_names] != 0).all(axis=1)]                 # remove the latitude and longitude rows with zeros\n        df = df.loc[(df.fare_amount > 0) & (df.fare_amount < 100) & \n            ~(((df.pickup_longitude - df.dropoff_longitude) == 0) & \n             ((df.pickup_latitude - df.dropoff_latitude) == 0))]     # remove the rows where fare amounts less than or greater than zero or with same coordinates\n        df = df[select_within_boundingbox(df, BB)]                   #remove the coordinates not within the newyork city\n    \n    if (train_data == 'N'):\n        df = dd.read_csv(data_file_path,usecols=test_cols, dtype=test_types)  # data load, dask\n    \n    df = dd.concat([\n        df,dd.to_datetime(df['pickup_datetime']).apply(\n        lambda x: pd.Series([x.year, x.month, x.day, x.weekday(), x.hour, x.minute],\n        index=['pickup_year', 'pickup_month', 'pickup_dd' ,'pickup_weekday', 'pickup_hour', 'pickup_minute']))], axis=1)   # extract year, month, weekday and hour from pickup datetime  \n\n    df = client.persist(df) \n    return df\n","2918b256":"#call the subroutine to load the data \ndf = load_data(data_train_file_path, 'Y')\nprogress(df)","7746d752":"# number of rows from db and after applying the filters\nafter = len(df)\nprint('# of rows in training data \\n\\t actual : {0}  \\n\\t after applying filters : {1}  \\n\\t dropped rows: {2} '.format(db_rows_count, after, db_rows_count-after))   # before and after filter rows count ","e4f7de3e":"#top 10 rows\ndf.head(10)","f630e2a5":"%%time\nprint(f'# of rows processing : {len(df)}')\nprint(\"\\033[4m\\nColumn Name\\tisnull_counts\\tdata_types\\033[0m\")\nfor columns in df.columns:\n    print(f'{columns.ljust(17)}\\t{(df[columns].isnull().map_partitions(sum).compute().sum()):>5}\\t{(df[columns].dtype)}')\nprint('\\t')","87289b7f":"# distance calculation in Kilometeres\nfrom math import cos, asin, sqrt\n\ndef distance_haversine(lon1, lat1, lon2, lat2):\n    p = 0.017453292519943295     #Pi\/180\n    a = 0.5 - cos((lat2 - lat1) * p)\/2 + cos(lat1 * p) * cos(lat2 * p) * (1 - cos((lon2 - lon1) * p)) \/ 2\n    return 12742 * asin(sqrt(a)) * 0.62137 #2*R*asin...","089cd095":"def distance_rows(p_lon, p_lat, d_lon, d_lat):\n    nyc_coord = (40.7141667, -74.0063889,)      # ny city center coordinates\n    jfk_coord = (40.639722, -73.778889)         #John F. Kennedy International Airport coordinates\n    ewr_coord = (40.6925, -74.168611)           #Newark Liberty International Airport coordinates\n    lga_coord = (40.77725, -73.872611)          #LaGuardia Airport coordinates\n\n    distance_between_pickup_dropoff = distance_haversine(p_lon, p_lat, d_lon, d_lat)                    # distance between pickup and dropff\n    distance_between_pickup_jfk     = distance_haversine(p_lon, p_lat, jfk_coord[1], jfk_coord[0])      # distance between pickup and jfk airport\n    distance_between_dropoff_jfk    = distance_haversine(jfk_coord[1], jfk_coord[0], d_lon, d_lat)      # distance between dropoff and jfk airport\n    distance_between_pickup_ewr     = distance_haversine(p_lon, p_lat, ewr_coord[1], ewr_coord[0])      # distance between pickup and ewr airport\n    distance_between_dropoff_ewr    = distance_haversine(ewr_coord[1], ewr_coord[0], d_lon, d_lat)      # distance between dropoff and ewr airport\n    distance_between_pickup_lga     = distance_haversine(p_lon, p_lat, lga_coord[1], lga_coord[0])      # distance between pickup and lga airport\n    distance_between_dropoff_lga    = distance_haversine(lga_coord[1], lga_coord[0], d_lon, d_lat)      # distance between dropoff and lga airport\n    distance_between_citycenter_pickup = distance_haversine(nyc_coord[0], nyc_coord[1],p_lon, p_lat)    # distance between pickup and city center\n    longitude_diff                     = p_lon - d_lon\n    latitude_diff                      = p_lat - d_lat\n    \n    return [distance_between_pickup_dropoff,\n            distance_between_pickup_jfk,\n            distance_between_dropoff_jfk, \n            distance_between_pickup_ewr, \n            distance_between_dropoff_ewr, \n            distance_between_pickup_lga, \n            distance_between_dropoff_lga,\n            distance_between_citycenter_pickup,\n            longitude_diff,\n            latitude_diff]\n\ndef calculate_coordinates_distance(df, train_data='Y'):\n    # distance columns to be added to the data frame\n    column_names  = ['distance_between_pickup_dropoff', \n                     'distance_between_pickup_jfk', \n                     'distance_between_dropoff_jfk', \n                     'distance_between_pickup_ewr', \n                     'distance_between_dropoff_ewr', \n                     'distance_between_pickup_lga', \n                     'distance_between_dropoff_lga',\n                     'distance_between_citycenter_pickup',\n                     'longitude_diff',\n                     'latitude_diff']\n\n    # pandas dataframes processing - utilizing dask\n    df = dd.concat([df,df[[\"pickup_longitude\",\"pickup_latitude\", \"dropoff_longitude\",\"dropoff_latitude\"]].apply(lambda x: pd.Series(distance_rows(*x),index=column_names), axis=1)], axis=1)\n\n    # calculate fare per mile\n    if (train_data == 'Y'):\n        # remove data points less than .05 miles\n        df = df.loc[df.distance_between_pickup_dropoff>0.05]\n        df['fare_per_mile'] = df.fare_amount\/df.distance_between_pickup_dropoff \n\n    #reset the index\n    df = df.reset_index(drop=True)  \n    df = client.persist(df)\n    return df\n","82a2e13f":"# calculate the distance between the coordinates\ndf = calculate_coordinates_distance(df, train_data='Y')\nprogress(df)","8fbbdcee":"df.compute().info()","d8834414":"#create a map\nthis_map = folium.Map(location=[40.741895, -73.989308],\n                      zoom_start=11\n)\n\ndef plotDot(point):\n    '''input: series that contains a numeric named latitude and a numeric named longitude\n    this function creates a CircleMarker and adds it to your this_map'''\n    folium.CircleMarker(location=[point.pickup_latitude, point.pickup_longitude],\n                        radius=2,color='#3186cc', fill=True,fill_color='#3186cc',\n                       weight=0).add_to(this_map)\n\ndf.compute().head(5000).apply(plotDot, axis = 1)\n\n#Set the zoom to the maximum possible \n#this_map.fit_bounds(this_map.get_bounds())\n    \nthis_map  ","2e1ed218":"#create a map\nthis_map = folium.Map(location=[40.741895, -73.989308])\n\n# List comprehension to make out list of lists\nheat_data = [[row['pickup_latitude'],row['pickup_longitude']] for index, row in df.compute().iterrows()]\n\n# Plot it on the map\nHeatMap(heat_data).add_to(this_map)\n\n#Set the zoom to the maximum possible\nthis_map.fit_bounds(this_map.get_bounds())\n    \nthis_map  ","57c50798":"@dask.delayed\ndef round_decimals(x, x_decimals=2):\n    return x.round(x_decimals)\n\n@dask.delayed\ndef math_sqrt(x):\n    return math.sqrt(x)","c32c6a2f":"fare_amount_mean = df[\"fare_amount\"].mean()\nfare_amount_standard_deviation = math_sqrt(((df[\"fare_amount\"] - fare_amount_mean) ** 2).mean())\n\nprint(\"average fair amount (mean) : ${0:.2f}\".format(fare_amount_mean.compute()))\nprint(\"fare amount standard deviation : ${0:.2f}\\n\".format(fare_amount_standard_deviation.compute()))","f1811e86":"# plot histogram of fare\nplt.figure(figsize=(25,10))\nsns.set(color_codes=True)\nax = sns.distplot(df.fare_amount, bins=15, kde=False)\nplt.xlabel('fare $USD', fontsize=20)\nplt.ylabel('frequency', fontsize=20)\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\n    \nplt.title('fare amount Histogram', fontsize=25)\nplt.show()","ee86c3a1":"sns.set(style=\"darkgrid\")\nplt.figure(figsize=(20,12))\n# Plot the responses for different events and regions\nsns.lineplot(x=\"pickup_hour\", y=\"fare_per_mile\",\n            hue=\"pickup_year\", style=\"pickup_year\",  dashes=False, \n             data=df.compute())\nplt.show()","bb25131f":"df_day              = df.loc[(df.pickup_hour >=6) & (df.pickup_hour <16)]\ndf_peak_hours       = df.loc[((df.pickup_hour >=16) & (df.pickup_hour <20))]\ndf_night            = df.loc[~((df.pickup_hour >=6) & (df.pickup_hour <20))]\ndf_between_airports = df.loc[(((df.distance_between_pickup_jfk < 2)  | (df.distance_between_pickup_ewr < 2)  | (df.distance_between_pickup_lga < 2))  &\n                              ((df.distance_between_dropoff_jfk < 2) | (df.distance_between_dropoff_lga < 2) | (df.distance_between_dropoff_ewr < 2))                      )] \ndf_airport_pickup   = df.loc[((df.distance_between_pickup_jfk < 2)  | (df.distance_between_pickup_ewr < 2)  | (df.distance_between_pickup_lga < 2))]   \ndf_airport_dropoff  = df.loc[((df.distance_between_dropoff_jfk < 2) | (df.distance_between_dropoff_lga < 2) | (df.distance_between_dropoff_ewr < 2))] \n\n#remove the coordinates not within the newyork city\nBB_manhattan = (-74.025, 40.7, -73.925, 40.8)\ndf_jfk_manhattan = df[(select_within_boundingbox(df, BB_manhattan) &\n                      ((df.distance_between_pickup_jfk < 2) | (df.distance_between_dropoff_jfk < 2)))]\n\n#reset the index\ndf = df.reset_index(drop=True)  ","6456aa11":"%%time\n\nfare_amount_per_mile                  = df.fare_per_mile.mean().compute().round(2)\n\nfare_amount_per_mile_day              = df_day.fare_per_mile.mean().compute().round(2)\nfare_amount_per_mile_peak_hours       = df_peak_hours.fare_per_mile.mean().compute().round(2)\nfare_amount_per_mile_night            = df_night.fare_per_mile.mean().compute().round(2)\n\nfare_amount_per_mile_between_airports = df_between_airports.fare_per_mile.mean().compute().round(2)\nfare_amount_per_mile_airport_pickup   = df_airport_pickup.fare_per_mile.mean().compute().round(2)\nfare_amount_per_mile_airport_dropoff  = df_airport_dropoff.fare_per_mile.mean().compute().round(2)\nfare_amount_per_mile_jfk_manhattan    = df_jfk_manhattan.fare_per_mile.mean().compute().round(2)\n\nfare_amount_per_mile_weekday          = df.loc[df.pickup_weekday<=4].fare_per_mile.mean().compute().round(2)\nfare_amount_per_mile_weekend          = df.loc[df.pickup_weekday>=5].fare_per_mile.mean().compute().round(2)\n\navg_data = pd.DataFrame({'fare':[\n                    fare_amount_per_mile_between_airports,  \n                    fare_amount_per_mile_jfk_manhattan,\n                    fare_amount_per_mile_airport_pickup,\n                    fare_amount_per_mile_airport_dropoff,\n                    \n                    fare_amount_per_mile_weekend,\n                    fare_amount_per_mile_weekday,\n                    \n                    fare_amount_per_mile_peak_hours,\n                    fare_amount_per_mile_night, \n                    fare_amount_per_mile_day,\n                    fare_amount_per_mile\n]}, index = [ \n             'between_airports', \n             'jfk_manhattan',      \n             'airport_pickup', \n             'airport_dropoff', \n             'week end',  \n             'week day', \n             'peak hours(4-8pm)',\n             'night_ride',\n             'day_ride',\n             'all_day']\n).dropna()","66c8f8d8":"# average fare\nsns.set_style(\"white\")\nplt.figure(figsize=(20,8))\nplt.barh(avg_data.index, avg_data.fare, height = .4, align='center',  color=\"b\")\nplt.title(\"fare per mile - trip average\", fontsize=20)\nplt.xlabel('fare $ USD', fontsize=12)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n\nfor i, v in enumerate(avg_data.fare):\n    plt.text(v,i-.1, '$' + str(v), fontsize=12)","67c5928c":"fare_per_mile_yr                  = df.groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_day_yr              = df_day.groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_peak_hours_yr       = df_peak_hours.groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_night_yr            = df_night.groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_weekday_yr          = df.loc[df.pickup_weekday<=4].groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_weekend_yr          = df.loc[df.pickup_weekday>=5].groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_airport_pickup_yr   = df_airport_pickup.groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_airport_dropoff_yr  = df_airport_dropoff.groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_between_airports_yr = df_between_airports.groupby('pickup_year')['fare_per_mile'].mean().compute() \nfare_per_mile_jfk_manhattan_yr    = df_jfk_manhattan.groupby('pickup_year')['fare_per_mile'].mean().compute() \n\nfare_mile = pd.concat([\n            pd.DataFrame({'year':fare_per_mile_yr.index, 'avg_fare':fare_per_mile_yr.values, 'type':'overall'}),\n            pd.DataFrame({'year':fare_per_mile_day_yr.index, 'avg_fare':fare_per_mile_day_yr.values, 'type':'day_time'}),\n            pd.DataFrame({'year':fare_per_mile_peak_hours_yr.index, 'avg_fare':fare_per_mile_peak_hours_yr.values, 'type':'peak_hours'}),\n            pd.DataFrame({'year':fare_per_mile_night_yr.index, 'avg_fare':fare_per_mile_night_yr.values, 'type':'night_time'}),\n            pd.DataFrame({'year':fare_per_mile_weekday_yr.index, 'avg_fare':fare_per_mile_weekday_yr.values, 'type':'weekend'}),\n            pd.DataFrame({'year':fare_per_mile_weekend_yr.index, 'avg_fare':fare_per_mile_weekend_yr.values, 'type':'weekday'}),\n            pd.DataFrame({'year':fare_per_mile_airport_pickup_yr.index, 'avg_fare':fare_per_mile_airport_pickup_yr.values, 'type':'airport_pickup'}),\n            pd.DataFrame({'year':fare_per_mile_airport_dropoff_yr.index, 'avg_fare':fare_per_mile_airport_dropoff_yr.values, 'type':'airport_dropoff'}),\n            pd.DataFrame({'year':fare_per_mile_jfk_manhattan_yr.index, 'avg_fare':fare_per_mile_jfk_manhattan_yr.values, 'type':'jfk_manhattan'}),\n            pd.DataFrame({'year':fare_per_mile_between_airports_yr.index, 'avg_fare':fare_per_mile_between_airports_yr.values, 'type':'between_airports'}),\n            ]).reset_index(drop = True)   \n","e43692cf":"plt.figure(figsize=(20,12)) \nax = sns.barplot(x=\"type\", y=\"avg_fare\", hue=\"year\", data=fare_mile, palette=\"Blues\")\nplt.title(\"fare per mile - trip average\", fontsize=16)\nplt.ylabel('fare $ USD', fontsize=11)\nplt.xlabel('')\nplt.xticks(fontsize=11, rotation =90)\nplt.yticks(fontsize=11)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height-1.5,\n            '${:1.2f}'.format(height),\n            ha=\"center\", rotation=90) ","1986b309":"df.compute().info()","6996e8a3":"df.head(10)","3ad9a746":"%%time\nimport xgboost as xgb\nimport dask_xgboost as dxgb\nfrom sklearn.metrics import mean_squared_error\n\nX =  df.drop(['fare_amount', 'fare_per_mile', 'pickup_datetime'], axis=1)\ny =  df.fare_amount   \n\nX_train, X_test = X.random_split([0.7, 0.3], random_state=0)\ny_train, y_test = y.random_split([0.7, 0.3], random_state=0)\n","84fe7b30":"def dxgb_evaluate() :\n    params = {'eval_metric'        : 'rmse' \n              ,'num_boost_round'   : 100\n              ,'max_depth'         : 7\n              ,'seed'              : 0\n              ,'subsample'         : 0.8 \n              ,'silent'            : True \n              ,'gamma'             : 1\n              ,'colsample_bytree'  : 0.9\n              ,'nfold'             : 3 \n              ,'boosting_type'     : 'gbdt'\n              , 'seed' : 0\n         }\n\n    bst = dxgb.train(client, params, X_train, y_train)\n    del(params)\n    return bst\n","9dbc7b9d":"# train the model\nbst = dxgb_evaluate()","3516eb59":"# train split predictions\nX_train_predictions = dxgb.predict(client, bst, X_train)\n\n# train test split predictions\nX_test_predictions = dxgb.predict(client, bst, X_test)","05a6cc69":"# Report testing and training RMSE\nprint(\"\\033[1;37;40m\\033[2;37:40mdata category \\t\\t\\trmse-score\\033[0m\")\nprint('train test split \\t\\t\\033[0;37;41m  {0:.2f}  \\033[0m'.format(np.sqrt(mean_squared_error(y_test, X_test_predictions))))\nprint('train split \\t\\t\\t\\033[0;37;41m  {0:.2f}  \\033[0m\\n'.format(np.sqrt(mean_squared_error(y_train, X_train_predictions))))","69862db7":"fig, ax = plt.subplots(figsize=(12, 8))\nax = xgb.plot_importance(bst, ax=ax, height=0.8, max_num_features=20, color='b')\nax.grid(\"off\", axis=\"y\")","35b06ccb":"#for i in range(100):\n#    print(s[i], y_pred[i].round(1))","8bd23a4f":"%%time\n#load the data \ndf_test = load_data(data_test_file_path, train_data='N')\ndf_test = calculate_coordinates_distance(df_test, train_data='N')\n\ndf_test_key = df_test.key\ndf_test     = df_test.drop(['key', 'pickup_datetime'], axis=1)","61492a81":"df_test.compute().info()","0339fc38":"df_test.head(5)","2ccd7e8d":"# train split predictions\ntest_predictions = dxgb.predict(client, bst, df_test)","f78fe82b":"submission_predictions  = pd.DataFrame({'key': df_test_key.compute(), 'fare_amount': test_predictions.compute()})\nsubmission_predictions.to_csv('submission.csv', index=False)","54edbc5c":"submission_predictions","c7185399":"print(os.listdir('.'))","c0f524d4":"**Data Analysis and Feature Engineering: **\n\n**Distance Calculation** <br>\nCompute the distance in Kilometers between pickup and dropoff utilizing Haversine equation and add to the data frame.\n\n* Distance between pickup and dropoff <br>\n* Distance between pickup and jfk       <br>\n* Distance between dropoff and jfk      <br>\n* Distance between pickup and ewr     <br>\n* Distance between dropoff and ewr    <br>\n* Distance between pickup and lga     <br>\n* Distance between dropoff and lga     <br>\n* Distance between citycenter and pickup <br>\n* Pickup and dropoff longitude difference  <br>\n* Pickup and dropoff latitude difference    <br>","fd5472a2":"**Model : XGBoost**\n\nThe features selected for model training.\n\npickup_longitude                      \npickup_latitude                        \ndropoff_longitude                   \ndropoff_latitude                       \npickup_year                            \npickup_month                         \npickup_dd                              \npickup_weekday                    \npickup_hour                            \npickup_minute                         \ndistance_between_pickup_dropoff       \ndistance_between_pickup_jfk            \ndistance_between_dropoff_jfk           \ndistance_between_pickup_ewr           \ndistance_between_dropoff_ewr           \ndistance_between_pickup_lga            \ndistance_between_dropoff_lga           \ndistance_between_citycenter_pickup     \nlongitude_diff                         \nlatitude_diff                          ","baabc869":"**NY City Taxi Fare Prediction Exploration using Dask and XGBoost ** <br>\n\nThis is a basic Kernel for the New York City Taxi Fare Prediction using Dask and XGBoost .\n","94c9b77b":"**Submit Predictions:**","1a8d27d8":"**Delayed and Decorators:**   \nThe Dask delayed function decorates your functions so that they operate lazily. Rather than executing your function immediately it will defer execution, placing the function and its arguments into a task graph.","437ae222":"Above plots shows,   \n1)\tTaxi charge is higher between airplane terminals voyages  \n2)\tDay ride charge is higher than nightly ride.  \n3) Week day charge is higher than end of the week","2f2a6544":"From the above plotting's,  it gives off an impression of being the greater part of the traffic are in certain zones like Brooklyn, Queens, Bronx, JFK and LaGuardia.","11d47a90":"**Fare analysis:**\n\nWe got the taxi now. How about we check the cabi\u2019s are charging us using Histogram.","73d0bad7":" **What is dask?**  \nA Dask DataFrame is a large parallel dataframe composed of many smaller Pandas dataframes, split along the index. \n\nThese pandas dataframes may live on disk for larger-than-memory computing on a single machine, or on many different machines in a cluster. One Dask dataframe operation triggers many operations on the constituent Pandas dataframes.\n\n With Dask and its dataframe construct, you set up the dataframe must like you would in pandas but rather than loading the data into pandas, this appraoch keeps the dataframe as a sort of \u2018pointer\u2019 to the data file and doesn\u2019t load anything until you specifically tell it to do so.\n","0e706fd3":"**Training data RMSE scrores:**","22e81a0d":"It shows up, greater part of taxi ride charges are between five to twenty dollars.","5b408db9":"**Heatmap Plotting** <br>\n\nPlotting all the data frame coordinates to recognize the high activity zones.","e4eff00c":"**Test data predictions:**","c20a7624":"**Fare amount mean and standard deviation:**","a0d853a0":"**Fare per mile year by year analysis:**","ea58117f":"**Row Count :** <br>\n\nWhat number of rows we have in the data table?  simpler approach to discover the count in limited time.","d17f7077":"**Pre-requisites**\n\nWe have massive amount of information to load and process.   Stacking every one of the information in the given format and every one of the sections is tedious and unncessary.\n\n1) To accelerate the loading process, i selected only required fields and reduced the decimals length for coordinates. <br>\n2) Our goal is to foresee the NY-city taxi fare. That infers, we require just ny-city information.   Keeping in mind the end goal, introduce the boundary box and avoids the cordinates which are not inside the boundary box. <br>\n3) Fraction is about how much level of information from accessible information, I need to stack for preparing and testing.\n\nNote:\nAdditionally, ignored the passenger count column based on NYC Taxi and Limousine Commission extra passenger rule. <br>\n(http:\/\/www.nyc.gov\/html\/tlc\/html\/passenger\/taxicab_rate.shtml)","96bc077b":"**What is in the data?  **\n\nWe completed the initial setup process. What is actually in the data?  Let\u2019s read and  utilizing the Dask.....   \n\nWhy we are having so many lines of code just to read?  Is it because of Dask? maybe.. here is the reason for you friend.\n\nOften dataframe workloads look like the following:\n\n1.     Load data from files\n2.     Filter data to a particular subset\n3.     Shuffle data to set an intelligent index\n4.     Several complex queries on top of this indexed data\n\nIt is often ideal to load, filter, and shuffle data once and keep this result in memory. Afterwards each of the several complex queries can be based off of this in-memory data rather than have to repeat the full load-filter-shuffle process each time. To do this, use the client.persist method.","999d0c90":"**Fare per mile analysis  on different timings:**","655b49eb":"**Training data Prediction:**","9abd1a3d":"**Feature Importance plotting:**","b7c97c17":"**Hourly Fare Analysis:**","21cc2fa8":"**Model definition and train the model:**","8d21be36":"**Row count, null check and data type:**","b790a2bb":"**Train\/Test data split:**","14ef6b01":" **Folium map plotting - with limited data:**\n \n Plotting only 50k lines because of memory and speed.\n\n\n"}}