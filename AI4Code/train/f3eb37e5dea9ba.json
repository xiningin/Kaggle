{"cell_type":{"b8a813b0":"code","d2155183":"code","471af6d8":"code","25a0ab8b":"code","99241672":"code","f130565c":"code","18abf97d":"code","519a2c46":"code","f1b0ee7c":"code","cd1fd275":"code","f45f8217":"code","9482a868":"code","2b1a96e3":"code","a1bbbc9b":"code","80becbe7":"code","c63a97cb":"code","51cb95f8":"code","f65859ea":"code","08eb8c77":"code","17153975":"code","98a6d5e3":"code","c0ff56c3":"code","bdac6473":"code","32864722":"code","3330bd82":"code","cb3e338d":"code","616a9efd":"code","a774b7c5":"code","49621d1f":"code","77f7e65f":"code","9d152f12":"code","4371b854":"code","db27e0c4":"code","2e794f77":"code","96a960f2":"code","ce347e26":"code","cabcb7b0":"code","0eb68720":"code","08418524":"code","e8f49eea":"code","a44933c9":"code","02cc23fc":"code","651c74e6":"code","2351a87f":"code","45d274ec":"markdown","4a238ea1":"markdown","f07b4cb7":"markdown","d0c3171e":"markdown","c6ab68e2":"markdown","17e6f0f7":"markdown","fbfb51f6":"markdown","87bba56f":"markdown","c49a4822":"markdown","050b7ab6":"markdown","0b3845de":"markdown","400ac541":"markdown","ea3b8314":"markdown","95a0e20f":"markdown","aefdc833":"markdown","e3b7332c":"markdown","f46aa06e":"markdown","0c94b647":"markdown","c918790c":"markdown","81d9933d":"markdown","398cfc3b":"markdown","b530f5cc":"markdown","ee306c0b":"markdown","470fe163":"markdown","d70febb9":"markdown","aab5799a":"markdown","980a5544":"markdown","a041cfe3":"markdown","5f354f33":"markdown","67fd74e6":"markdown","3d430e0c":"markdown","e98f90ad":"markdown","8440c22e":"markdown"},"source":{"b8a813b0":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","d2155183":"#Importing the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","471af6d8":"#Read the data by csv file\nhousing_data = pd.read_csv('..\/input\/housing-simple-regression\/Housing.csv')\nhousing_data.head()","25a0ab8b":"housing_data.tail()","99241672":"#Check the shape of the dataframe\nhousing_data.shape","f130565c":"#Check the information about the data\nhousing_data.info()","18abf97d":"#Let's check about null values\nhousing_data.isna().any()","519a2c46":"#statstical summary of the data\nhousing_data.describe()","f1b0ee7c":"housing_data.hist(figsize=(20,20))","cd1fd275":"#let's make pairplot of numerical data\nsns.pairplot(housing_data)\nplt.show()","f45f8217":"#Box plots\nplt.figure(figsize=(20,12))\nplt.subplot(2,3,1)\nsns.boxplot(x='mainroad', y='price', data=housing_data)\nplt.subplot(2,3,2)\nsns.boxplot(x='guestroom', y='price', data=housing_data)\nplt.subplot(2,3,3)\nsns.boxplot(x='basement', y='price', data=housing_data)\nplt.subplot(2,3,4)\nsns.boxplot(x='hotwaterheating', y='price', data=housing_data)\nplt.subplot(2,3,5)\nsns.boxplot(x='airconditioning', y='price', data=housing_data)\nplt.subplot(2,3,6)\nsns.boxplot(x='furnishingstatus', y='price', data=housing_data)\nplt.show()\n\n\n\n\n","9482a868":"#List of variables to map\nvarlist= ['mainroad','guestroom','basement','hotwaterheating','airconditioning','prefarea']\n#Defining the map function\ndef binary_map(x):\n    return x.map({'yes':1,'no':0})\nhousing_data[varlist]=housing_data[varlist].apply(binary_map)\n","2b1a96e3":"housing_data.head()","a1bbbc9b":"#Get the dummy variable for the attribute furnishingstatus and store it in a new dataframe\ndf=pd.get_dummies(housing_data['furnishingstatus'])","80becbe7":"#Check how new dataset df looks like\ndf.head()","c63a97cb":"#Let's drop first column\ndf=pd.get_dummies(housing_data['furnishingstatus'], drop_first=True)\ndf.head()","51cb95f8":"#Add the above dataframe df into original housing_data dataframe\nhousing_data=pd.concat([housing_data, df], axis=1)\nhousing_data.head()","f65859ea":"housing_data.drop(['furnishingstatus'], axis=1, inplace= True)\nhousing_data.head()","08eb8c77":"#Splitting of data into train and test set\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(housing_data,train_size=0.8,test_size=0.2,random_state=0)","17153975":"#Scaling the features\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()","98a6d5e3":"#Apply scaler everywhere except categorical data\nnum = ['area','bedrooms','bathrooms','stories','parking','price']\ntrain[num] = scaler.fit_transform(train[num])\ntrain.head()","c0ff56c3":"#Let's find outh the correlation matrix\ncorr=housing_data.corr()\ncorr","bdac6473":"#Let's check heatmap\nplt.figure(figsize=(16,10))\nsns.heatmap(corr,annot=True, cmap='YlGnBu')\nplt.show()","32864722":"from sklearn.linear_model import LinearRegression\nX_train= train\nY_train= train.pop('price')\n","3330bd82":"from sklearn.feature_selection import RFE\nlm = LinearRegression()\nlm.fit(X_train, Y_train)\nrfe = RFE(lm, 10)             \nrfe = rfe.fit(X_train, Y_train)","cb3e338d":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","616a9efd":"#Display the columns suuported by RFE\ncol = X_train.columns[rfe.support_]\ncol","a774b7c5":"#Display the columns not supported by RFE\nX_train.columns[~rfe.support_]","49621d1f":"# Creating training dataframe with RFE selected variables\nX_train_rfe = X_train[col]","77f7e65f":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","9d152f12":"# Running the linear model\nlm = sm.OLS(Y_train,X_train_rfe).fit()   ","4371b854":"#Let's see the summary of our linear model\nprint(lm.summary())","db27e0c4":"#Drooping the bedrooms column\nX_train_new = X_train_rfe.drop([\"bedrooms\"], axis = 1)","2e794f77":"#Rebuilding the model without bedrooms\n\nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new)\nlm = sm.OLS(Y_train,X_train_lm).fit() \n\n\n\n","96a960f2":"#Let's see the summary of our linear model\nprint(lm.summary())","ce347e26":"X_train_new.columns","cabcb7b0":"X_train_new = X_train_new.drop(['const'], axis=1)","0eb68720":"# Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","08418524":"#Predicted value of price\nY_train_price = lm.predict(X_train_lm)","e8f49eea":"# Displaying error terms\nfig = plt.figure()\nsns.distplot((Y_train - Y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                   \nplt.xlabel('Errors', fontsize = 18)                         ","a44933c9":"#Applying the scaling on the test sets\nnum = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price']\ntest[num] = scaler.transform(test[num])","02cc23fc":"Y_test = test.pop('price')\nX_test = test","651c74e6":"# Now let's use our model to make predictions.\n\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)\n# Making predictions\nY_pred = lm.predict(X_test_new)","2351a87f":"# Displaying available and predicted price values for the test data \nfig = plt.figure()\nplt.scatter(Y_test,Y_pred)\nfig.suptitle('Y_test vs Y_pred', fontsize=20)            \nplt.xlabel('Y_test', fontsize=18)                          \nplt.ylabel('Y_pred', fontsize=16)                          ","45d274ec":"# Step 7 Model evaluation on test data\n","4a238ea1":"# **Step 6 Residual Analysis on the training data**\nSo, now to check if the error terms are also normally distributed (which is infact, one of the major assumptions of linear regression), let us plot the histogram of the error terms and see what it looks like.\n\n\n\n\n\n\n","f07b4cb7":"As it is clearly visible that there are 3 levels; furnished, semi-furnished and unfurnished but type of furnishing can be determined by only two columns so first column can be dropped.","d0c3171e":"All those columns with ranking 1 and true are the most preferrable columns for RFE.","c6ab68e2":"Let's convert categorical data into numerical data","17e6f0f7":"Clearly there are no null values present in the dataset.\n\n","fbfb51f6":"Displaying the columns in order of preference that can be used for model building as suggested by RFE","87bba56f":"**DUMMY VARIABLES**","c49a4822":"This notebook aims to analyse the dataset of a real estate company and build a model to optimize sales prices of the houses and its dependency on different parameters.","050b7ab6":"# Step 3 Data Preparation","0b3845de":"**RECRUSIVE FEATURE ELIMINATION (RFE)**","400ac541":"Here cofficients for feature bedrooms are insignificant so it can be dropped","ea3b8314":"As it is clearly seen from the correlation matrix and heatmap that there is no case of multicollinearity since maximum correlation lies between price and area which is 0.54.","95a0e20f":"Except area all other attributes have very low integer values so MinMax Scaler will be used here. But first let's split the data into training and testing data","aefdc833":"Here in this concated dataframe previous attribute of furnishingstatus is still there so let's drop this.","e3b7332c":"A variance inflation factor under 5 is considered to be good and here all the attributes have value of VIF<5, hence our model is doing great soo far","f46aa06e":"Pairplots show there is a correlation between area and price. Now let's visualize categorical data as well.","0c94b647":"**VISUALIZING CATEGORICAL DATA**","c918790c":"# Step 4 Scaling the data","81d9933d":"# Step 5 Model Building","398cfc3b":"Let's use automated feature selection.","b530f5cc":"The attribute furnishingstatus has 3 levels. We need to convert this into numerical data as well.","ee306c0b":"Building model using statsmodel, for the detailed statistics","470fe163":"# Housing Case Study","d70febb9":"# Step-1 Reading and Understanding the data","aab5799a":"This dataframe represents count, mean,standard deviation, minimum, maximum and interquartile values for each column containing numerical data.","980a5544":"VISUALIZING NUMERICAL DATA","a041cfe3":"Above dataframe shows first 5 rows of dataset. This data set has both numerical and categorical data present in it. Let's check the last 5 rows of data set as well.","5f354f33":"Histogram shows that only area and price have continous data while other columns such as bathrooms, bedrooms, parking and stories have discrete data","67fd74e6":"# Step-2 Visualizing the data","3d430e0c":"This dataset contains 545 rows and 13 columns, out of which 6 columns contain numerical data while other 7 have categorical data.","e98f90ad":"Since errors are normally distributed so our model is doing good enough. Hence final equation will be\nprice=(0.314*area+0.193*bathrooms+0.112*stories+0.040*mainroad+0.051*guestroom+0.111*hotwaterheating+0.082*airconditioning+0.07*parking+0.069*prefera)","8440c22e":"It can be clearly seen from box plots that furnishing status has three levels so dummy encoding has to be performed here. Also categorical data needs to be converted into numerical data for modelling."}}