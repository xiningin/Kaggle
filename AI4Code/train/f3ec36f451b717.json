{"cell_type":{"f172ab64":"code","0122eac3":"code","892ad177":"code","5feef19a":"code","12341423":"code","e0456cdf":"code","b36ed550":"code","74aaa116":"code","a4a83997":"code","ffbb0fdd":"code","34e7dcb0":"code","d89c7745":"code","4e176c66":"code","d977bf06":"code","66be8cdd":"code","dbac1628":"code","d07c94a1":"code","b1e277d3":"code","a31087ef":"code","95d6347d":"code","e7318801":"code","b231c812":"code","a5ea7b08":"code","51b05013":"code","88e7f6a4":"code","955dc134":"code","cb5ec8b5":"code","a7e11e54":"code","875f954f":"code","f9deab47":"code","f2fca684":"code","8a045cb0":"code","9fd794e3":"code","4ef84e2a":"code","0c80bfda":"code","8633910d":"code","edb93f71":"code","77fa623d":"code","34461d6f":"code","06312fa6":"code","0fdff8b5":"code","194f5965":"code","2304a4a9":"code","a14e53ce":"code","b224e803":"code","f07382d0":"code","a9611c88":"code","3d21f95e":"code","ad665d44":"code","62a0b221":"code","ec48e886":"code","b40c2fc0":"code","8a69de6e":"code","beaad0e2":"code","ea970254":"code","c6274d69":"code","ecf6795e":"markdown","7ca95345":"markdown","c8b225c8":"markdown","09a765b6":"markdown","0b5cb2ae":"markdown","b8529c9c":"markdown","8bf52006":"markdown","ffd03636":"markdown","7510a230":"markdown","6a7c16e7":"markdown","e6424ce5":"markdown","9924a578":"markdown","38d444e4":"markdown","f460c448":"markdown","b7281561":"markdown","dd1e0258":"markdown","37c35bcc":"markdown","bbe60a23":"markdown","95cdce10":"markdown","b7d4cf5c":"markdown","9baf3fbb":"markdown","d3c50b80":"markdown","17ebd2f0":"markdown","d2a86560":"markdown","c55234cb":"markdown","26851cd4":"markdown","1cd2c955":"markdown","d2dc8707":"markdown","76150a7b":"markdown","79a99deb":"markdown","e7f7d7df":"markdown","f0c7d737":"markdown"},"source":{"f172ab64":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom datetime import date, datetime\nfrom sklearn.preprocessing import MinMaxScaler","0122eac3":"train_df = pd.read_csv('..\/input\/restaurant-revenue-prediction\/train.csv.zip',parse_dates=['Open Date'])\ntest_df = pd.read_csv('..\/input\/restaurant-revenue-prediction\/test.csv.zip',parse_dates=['Open Date'])","892ad177":"train_df.shape, test_df.shape","5feef19a":"train_df.describe()","12341423":"test_df.describe()","e0456cdf":"train_df.isnull().sum()","b36ed550":"test_df.isnull().sum()","74aaa116":"def print_cols():\n    print(train_df.columns)","a4a83997":"plt.figure(figsize=(20,20))\nsns.heatmap(train_df.corr(),annot=True, cbar=False, cmap='Reds')","ffbb0fdd":"print_cols()","34e7dcb0":"plt.figure(figsize=(20,4))\nsns.boxplot(x='revenue',data=train_df)","d89c7745":"from scipy.stats import iqr\n\nupper_limit = train_df.revenue.quantile(0.75) + (1.5* iqr(train_df.revenue))\nlower_limit = train_df.revenue.quantile(0.25)- (1.5* iqr(train_df.revenue))\n\ncondition = (train_df.revenue > upper_limit) | (train_df.revenue<lower_limit)\ntrain_df[condition]","4e176c66":"rev_filter = (train_df.revenue < 10000000)\ntrain_df = train_df[rev_filter]\n\ntrain_df.shape","d977bf06":"len(train_df.Id.unique()) == train_df.shape[0]","66be8cdd":"len(test_df.Id.unique()) == test_df.shape[0]","dbac1628":"# Drop the ID\ntrain_df.drop('Id',axis=1,inplace=True)\ntest_df.drop('Id', axis=1, inplace=True)","d07c94a1":"#check the shape\ntrain_df.shape, test_df.shape","b1e277d3":"train_df['Open Date'].value_counts()","a31087ef":"train_df['open_year'] = train_df['Open Date'].dt.year\n# Do it to the test data \ntest_df['open_year'] = test_df['Open Date'].dt.year","95d6347d":"\"\"\"\nVisualize the data on the graph according the open year\n\n\"\"\"\n\nfig = plt.figure(figsize=(12,10))\nax1=fig.add_subplot(2,1,1)\nax2=fig.add_subplot(2,1,2)\n\nsns.countplot(train_df.open_year,ax=ax1)\nax1.set_title('Number of restaurant open from 1996-2014')\nax1.set_ylabel('Number of restaurant')\n\ntrain_df.groupby(['open_year']).mean()['revenue'].plot.bar(ax=ax2, width=0.7)\nax2.set_title('Average revenue for the restaurant according to their open year')\nax2.set_ylabel('Average Revenue')\n\nplt.show()","e7318801":"plt.figure(figsize=(10,7))\nsns.boxplot(x='open_year',y='revenue', data=train_df)","b231c812":"train_df['City Group'].value_counts()","a5ea7b08":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,4))\ntrain_df.groupby(['City Group']).mean()['revenue'].plot.bar(ax=ax1)\nsns.boxplot(x='City Group',y='revenue', data=train_df,ax=ax2)","51b05013":"train_df.groupby(['City']).mean()['revenue'].plot.barh(figsize=(20,20))\nplt.yticks(fontsize=17)","88e7f6a4":"len(train_df.City.unique()) ,len(test_df.City.unique())","955dc134":"train_df.drop('City',axis=1,inplace=True)\ntest_df.drop('City',axis=1,inplace=True)","cb5ec8b5":"print_cols()","a7e11e54":"train_df.Type.value_counts()","875f954f":"train_df.loc[124,'Type'] = 'IL'","f9deab47":"test_df.Type.value_counts()","f2fca684":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,4))\ntrain_df.groupby(['Type']).mean()['revenue'].plot.bar(ax=ax1)\nsns.boxplot(train_df.Type, train_df.revenue,ax=ax2)\nplt.show()","8a045cb0":"train_df.P1.value_counts()","9fd794e3":"#plt.figure(figsize=(20,25))\n#stop = 37\n#for i in range(1,stop+1):\n    #col_name = 'P' + str(i)\n    #plt.subplot(8,5,i)\n    #train_df.groupby([col_name]).median()['revenue'].plot.bar(width=0.2)\n    #sns.boxplot(col_name, 'revenue',data=train_df, width=0.3)\n#plt.show()","4ef84e2a":"train_df.head()","0c80bfda":"test_df.head()","8633910d":"comp_df = pd.concat([train_df, test_df])\ncomp_df.reset_index(drop=True, inplace=True)","edb93f71":"comp_df.Type.value_counts(),comp_df['City Group'].value_counts()","77fa623d":"comp_df.Type = comp_df.Type.map({'MB':0,'DT':1, 'IL':2,'FC':3})\ncomp_df['City Group'] = comp_df['City Group'].map({'Big Cities':1, 'Other':0})","34461d6f":"comp_df.head(3)","06312fa6":"p_name = ['P'+str(i) for i in range(1,38)]\ncomp_df[p_name] = MinMaxScaler().fit_transform(comp_df[p_name])","0fdff8b5":"# DPCA to p-columns\nfrom sklearn.decomposition import PCA\npca = PCA().fit(comp_df[p_name])\nplt.figure(figsize=(7,5))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of Components')\nplt.ylabel('Explained variance')\nplt.yticks(np.arange(0.1,1.1,0.05))\nplt.xticks(np.arange(0,41,2))\nplt.grid(True)","194f5965":"pca_list = ['pca'+str(i) for i in range(1,30,1)]\ncomp_df[pca_list] = PCA(n_components=29).fit_transform(comp_df[p_name])\ncomp_df.drop(p_name,axis=1,inplace=True)","2304a4a9":"comp_df","a14e53ce":"import datetime\ncomp_df['launch_days'] = (datetime.datetime.now() - comp_df[['Open Date']])\ncomp_df['launch_days'] = comp_df['launch_days'].dt.days","b224e803":"comp_df.drop('Open Date',axis=1,inplace=True)","f07382d0":"comp_df['launch_days'] = MinMaxScaler().fit_transform(comp_df[['launch_days']])\ncomp_df['open_year'] = MinMaxScaler().fit_transform(comp_df[['open_year']])","a9611c88":"test_df = comp_df[comp_df['revenue'].isnull()]\ntrain_df = comp_df[comp_df['revenue'].notnull()]\ntest_df.drop('revenue',axis=1, inplace=True)","3d21f95e":"train_df.shape, test_df.shape","ad665d44":"x_train = train_df.drop('revenue',axis=1)\ny_train = train_df['revenue']","62a0b221":"from lightgbm import LGBMRegressor\nfrom sklearn.model_selection import GridSearchCV, cross_validate, RepeatedKFold","ec48e886":"cv = RepeatedKFold(n_splits=10, n_repeats=3)\nscores = cross_validate(LGBMRegressor(), x_train,y_train, scoring=['r2','neg_root_mean_squared_error'],cv=cv)","b40c2fc0":"r2 = scores['test_r2']\nrmse = scores['test_neg_root_mean_squared_error']\nprint(np.mean(r2),np.mean(rmse))","8a69de6e":"# random forest first\n#cv = RepeatedKFold(n_splits=10, n_repeats=3)\n#params = {\n    #'n_estimators':[20,50,100,200],\n    #'max_depth':[3,5,7],\n    #'learning_rate':[0.0001,0.001,0.01,0.1,1],\n    #'boosting_type':['gbdt','dart','goss'],\n    #'subsample':[0.3,0.5,0.7,1]\n#}\n\n#lgbm_grid = GridSearchCV(LGBMRegressor(random_state=42),params, cv=cv, verbose=1, n_jobs=-1,scoring='neg_root_mean_squared_error')\n#lgbm_grid.fit(x_train,y_train)","beaad0e2":"final_model = LGBMRegressor(boosting_type='dart',max_depth=3,n_estimators=20,random_state=42, subsample=0.3).fit(x_train,y_train)","ea970254":"test_file = pd.read_csv('..\/input\/restaurant-revenue-prediction\/test.csv.zip')\nanswer = pd.DataFrame(final_model.predict(test_df))\nanswer.columns = ['Prediction']\nanswer['Id'] = test_file.index.tolist()\nanswer.set_index('Id',inplace=True)","c6274d69":"answer.to_csv('result.csv')","ecf6795e":"### Combine training set and test set into complete set for formatting.","7ca95345":"### Normalize the date\n- Create new column 'launch days'\n- Normalize open_year, launch days","c8b225c8":"- There are eight rows of outlier, the training set is too small, I don't want to drop too many instances.\n- Set the threshold higher to 10,000,000.","09a765b6":"# Restaurant Revenue Prediction\n## Predict annual restaurant sales based on objective measurements\n\n### Data description:\n\n- TFI has provided a dataset with 137 restaurants in the training set, and a test set of 100000 restaurants. The data columns include the open date, location, city type, and three categories of obfuscated data: Demographic data, Real estate data, and Commercial data. The revenue column indicates a (transformed) revenue of the restaurant in a given year and is the target of predictive analysis. \n\n### File description:\n\n- train.csv - the training set. Use this dataset for training your model. \n- test.csv - the test set. To deter manual \"guess\" predictions, Kaggle has supplemented the test set with additional \"ignored\" data. These are not counted in the scoring.\n- sampleSubmission.csv - a sample submission file in the correct format\n\n### Data fields:\n- Id : Restaurant id. \n- Open Date : opening date for a restaurant\n- City : City that the restaurant is in. Note that there are unicode in the names. \n- City Group: Type of the city. Big cities, or Other. \n- Type: Type of the restaurant. FC: Food Court, IL: Inline, DT: Drive Thru, MB: Mobile\n- P1, P2 - P37: There are three categories of these obfuscated data. Demographic data are gathered from third party providers with GIS systems. These include population in any given area, age and gender distribution, development scales. Real estate data mainly relate to the m2 of the location, front facade of the location, car park availability. Commercial data mainly include the existence of points of interest including schools, banks, other QSR operators.\n- Revenue: The revenue column indicates a (transformed) revenue of the restaurant in a given year and is the target of predictive analysis. Please note that the values are transformed so they don't mean real dollar values. \n\n### Evaluations:\n\n#### Root Mean Squared Error (RMSE)\n- Submissions are scored on the root mean squared error. ","0b5cb2ae":"# Prediction on test data\n- And output the file","b8529c9c":"Divide the open_date column into year, month, day","8bf52006":"### LGBM regressor","ffd03636":"There are more cities appear in test set than in training set. It provides less information to our model, also, the data of cities appear on the P columns, so I drop the 'city' columns.","7510a230":"set n_components to 29.","6a7c16e7":"### EDA: Type","e6424ce5":"### Train without tuning","9924a578":"There is only 1 data in 'DT' group, group this data to 'IL'.","38d444e4":"# Data formatting","f460c448":"The test data set is so much larger than the training set.","b7281561":"### EDA : Open date","dd1e0258":"### Label encoding: City Group, Type","37c35bcc":"### Normalize the p-columns","bbe60a23":"# Start training model\n\n- LGBMRegressor()","95cdce10":"#### There is no MB type in training set","b7d4cf5c":"Plot the average revenue of different cities.\n","9baf3fbb":"Import the tools for data preprocessing and EDA.","d3c50b80":"### EDA: p1 , p2 - p37\n\n- There are three categories of these obfuscated data. \n    1. Demographic data, inlcude given area, age and gender.\n    2. Real estate data, car park, front facade, m2 of the location.\n    3. Commerical main include the existence of points of interest including schools, banks.","17ebd2f0":"# Data EDA","d2a86560":"### EDA : restaurant ID\n\n- The id is unique in both training set and testing set, it provide little information, so we will drop it.","c55234cb":"### Basic information of the dataset.","26851cd4":"### EDA: City & City Group\n- There are unicode in the names.","1cd2c955":"# Split to training set and test set","d2dc8707":"Read the train and test set","76150a7b":"### Filter out the outliers","79a99deb":"No missing data in both training and testing dataset.","e7f7d7df":"The range of all P columns are different.","f0c7d737":"# Hyperparameters tuning"}}