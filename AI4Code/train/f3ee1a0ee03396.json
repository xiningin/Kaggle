{"cell_type":{"e7d16e7b":"code","708591d4":"code","308aa5ca":"code","9a9d8ebc":"code","5fce2dd9":"code","10702120":"code","2b4bbd71":"code","32860da0":"code","7ea1583c":"code","09794c8d":"code","4f244b3d":"code","9fd291cf":"code","a3f39012":"code","9fb8dfea":"code","41f15059":"markdown","5923a6c4":"markdown","b6b54037":"markdown","327ab709":"markdown","e1a01df9":"markdown","bba4da38":"markdown","a3051bd9":"markdown","fb5caf7c":"markdown","7f6cc18e":"markdown","baecc267":"markdown","4e64b197":"markdown","0f4504ff":"markdown","9bdc8a56":"markdown"},"source":{"e7d16e7b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport random\nimport scipy.stats as stt\nimport warnings\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve,roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import r2_score\nfrom sklearn import linear_model\nfrom sklearn.model_selection import GridSearchCV\nwarnings.filterwarnings('ignore')\n%pylab inline","708591d4":"data = pd.read_csv('..\/input\/Admission_Predict.csv')\n#data2 = pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv')","308aa5ca":"data.drop(['Serial No.'],axis=1,inplace=True)\ndata.head(5)\nprint(data.shape)","9a9d8ebc":"sns.pairplot(data[['GRE Score', 'TOEFL Score','CGPA','Chance of Admit ']]);","5fce2dd9":"fig = plt.figure(figsize=(20,20))\nsns.set(style=\"white\",font_scale=2)\nsns.heatmap(data.corr(), fmt='.2f',annot=True,linewidth=2);","10702120":"fig = plt.figure(figsize=(20,20));\nsns.set(font_scale=1.5);\npd.crosstab(data['University Rating'],data.Research).plot(kind='barh');","2b4bbd71":"fig = plt.figure(figsize=(20,10))\nax1 = fig.add_subplot(2,2,1)\n#ax1.set_title('SOP')\ndata[\"Chance of Admit \"].groupby(data['SOP']).mean().plot();\nax1.legend()\nax2 = fig.add_subplot(2,2,2)\n#ax2.set_title(\"LOR\")\ndata[\"Chance of Admit \"].groupby(data['LOR ']).mean().plot(color='red');\nax2.legend();","32860da0":"fig = plt.figure(figsize=(7,7))\nsns.set(font_scale=1.5)\nsns.regplot(x=data['GRE Score'],y=data['TOEFL Score'],marker='+');\nlin1 = sklearn.linear_model.LinearRegression()\nx = np.transpose(np.atleast_2d(data['GRE Score']))\nlin1.fit(x,data['TOEFL Score'])\nprint('R_coeff = ',r2_score(data['TOEFL Score'],lin1.predict(x)))","7ea1583c":"fig = plt.figure(figsize=(7,7))\nsns.set(font_scale=1.5)\nsns.regplot(x=data['CGPA'],y=data['Chance of Admit '],color='green');\nlin1 = sklearn.linear_model.LinearRegression()\nx = np.transpose(np.atleast_2d(data['CGPA']))\nlin1.fit(x,data['Chance of Admit '])\nprint('R_coeff = ',r2_score(data['Chance of Admit '],lin1.predict(x)))","09794c8d":"lin_full = linear_model.LinearRegression()\nx = np.transpose(np.atleast_2d(data[['GRE Score', 'TOEFL Score', 'University Rating',\\\n                            'SOP', 'LOR ', 'CGPA','Research']]))\nxx = data[['GRE Score', 'TOEFL Score', 'University Rating',\\\n                            'SOP', 'LOR ', 'CGPA','Research']]\nlin_full.fit(xx,data['Chance of Admit '])\nprint('R_coeff = ',r2_score(data['Chance of Admit '],lin_full.predict(xx)))","4f244b3d":"ss = pd.DataFrame(np.hstack((np.array(list(data.drop(['Chance of Admit '],\\\n                                                     axis=1).columns)).reshape(7,1),lin_full.coef_.reshape(7,1))))\nfeatures = ss[0]\nimportances = lin_full.coef_\nindices = np.argsort(importances)\n\nplt.figure(figsize=(10,10))\nplt.title('Regression coefficients')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center');\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('\u0421oefficient value');","9fd291cf":"lin_full = linear_model.LinearRegression()\n#x = np.transpose(np.atleast_2d(data[['LOR ', 'CGPA','Research']]))\nxx = data[['LOR ', 'CGPA','Research']]\nlin_full.fit(xx,data['Chance of Admit '])\nprint('R_coeff = ',r2_score(data['Chance of Admit '],lin_full.predict(xx)))","a3f39012":"lin_reg = linear_model.ElasticNet(alpha=0.05, l1_ratio=0.05,)\nx = np.transpose(np.atleast_2d(data[['GRE Score', 'TOEFL Score', 'University Rating',\\\n                            'SOP', 'LOR ', 'CGPA','Research']]))\nxx = data[['GRE Score', 'TOEFL Score', 'University Rating',\\\n                            'SOP', 'LOR ', 'CGPA','Research']]\nlin_reg.fit(xx,data['Chance of Admit '])\nprint('R_coeff = ',r2_score(data['Chance of Admit '],lin_reg.predict(xx)))","9fb8dfea":"parameters = {'alpha':[0.001, 3],\"l1_ratio\":[0.001,3]}\nclf = GridSearchCV(lin_reg, parameters, cv=5)\nclf.fit(xx,data['Chance of Admit '])\nclf.best_params_","41f15059":"By this gridsearchCV we can see that  regularization isn't suitable for this model, best coefficients tend to normal linear regression.","5923a6c4":"Here consider categorical data - Statement of Purpose and Letter of Recommendation Strength. Dependence is also linear.","b6b54037":"Also look at the possible regularization with ElasticNet:","327ab709":"Determination coefficient is high, so look at feature values. Undergraduate GPA has the most value - this is an extremely important feature. Than - Research and Letter of Recommendation.","e1a01df9":"Thank you for reading! I hope this kernel was helpful for you.","bba4da38":"The conclusion is obvious - if you want to go to university with high rating, you need research experience.","a3051bd9":"Import dataset and let's take a closer look it's features:","fb5caf7c":"We can see high correlation and clearly linear dependence, so check correlation coefficients:","7f6cc18e":"Given the previous reasoning, we can assume that linear model can describe this model well.","baecc267":"We can see, that maximal correlations are 'GRE Score', 'Toefel Score' and 'CGPA'. <br>\nDescry possibility relation between Research and University Rating:\n","4e64b197":"Build a correlation model between 'GRE Score' and 'TOEFL Score', calculate the coefficient of determination. <br>\nSimilarly with 'CGPA' and 'Chance of Admit '.","0f4504ff":"Consider scatter plot for numerical features:","9bdc8a56":"Here we can see, that dimension reduction may be justified even in small models. I left only 3 main features - and R2 don't fall much."}}