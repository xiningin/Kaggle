{"cell_type":{"1a38cf1f":"code","6671db7e":"code","2a0ad756":"code","f0f8dd45":"code","33cc9674":"code","372be86d":"code","0bfbfde6":"code","3ed08ee7":"code","b9ec7c0a":"code","169d5d41":"code","7e141bff":"code","7a11b3fe":"code","35612f96":"markdown","2f10985e":"markdown","16e76e2d":"markdown","0461fc78":"markdown","c1b1d724":"markdown","35328e67":"markdown","713cae3d":"markdown","8f59d541":"markdown","c9fe149e":"markdown","4e186467":"markdown"},"source":{"1a38cf1f":"!pip install ..\/input\/detectron-05\/whls\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/fvcore-0.1.5.post20211019\/fvcore-0.1.5.post20211019 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/antlr4-python3-runtime-4.8\/antlr4-python3-runtime-4.8 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/detectron2-0.5\/detectron2 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/ensemble-boxes-104\/ensemble_boxes-1.0.4\/ -f .\/ --no-index","6671db7e":"import os\nimport cv2\nimport json\nimport time\nimport numpy as np\nimport pandas as pd\nimport torch\nimport detectron2\nfrom tqdm.auto import tqdm\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.evaluation import inference_on_dataset\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nfrom detectron2.data import DatasetCatalog, build_detection_test_loader\nimport pycocotools.mask as mask_util\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom fastcore.all import *\nfrom ensemble_boxes import *\nos.environ['CUDA_VISIBLE_DEVICES'] = '0' \nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\n    print('GPU is available')\nelse:\n    DEVICE = torch.device('cpu')\n    print('CPU is used')\nprint('detectron ver:', detectron2.__version__)","2a0ad756":"best_model=(\n    {'file': 'R50-306.pth','config_name':'COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml', 'LB score': 0.306,'ths':[.18, .38, .58]},\n    {'file': '50_FPN_3x_F3_R82_300.pth','config_name':'COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml', 'LB score': 0.300,'ths':[.18, .38, .58]},\n    {'file': '32x8d_FPN_3x_F3_R57_295.pth','config_name':'COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml', 'LB score': 0.295,'ths':[.18, .38, .58]},\n    {'file': '50_FPN_3x_F5_ATTT32_300.pth','config_name':'COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml', 'LB score': 0.300,'ths':[.19, .39, .57]}\n            )","f0f8dd45":"#config_name = \"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"\nmdl_path = \"..\/input\/dtectron2-models-5fold\"\nDATA_PATH = \"..\/input\/sartorius-cell-instance-segmentation\"\nMODELS = []\nBEST_MODELS =[]\nTHSS = []\nID_TEST = 0\nSUBM_PATH = f'{DATA_PATH}\/test'\nSINGLE_MODE = False\nNMS = True\nMIN_PIXELS = [75, 150, 75]\nIOU_TH = 0.3\nfor b_m in best_model:\n    model_name=b_m[\"file\"]\n    model_ths=b_m[\"ths\"]\n    config_name=b_m[\"config_name\"]\n    BEST_MODELS.append(model_name)\n    THSS.append(model_ths)\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(config_name))\n    cfg.INPUT.MASK_FORMAT = 'bitmask'\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n    cfg.MODEL.WEIGHTS = f'{mdl_path}\/{model_name}'  \n    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n    MODELS.append(DefaultPredictor(cfg))\nprint(f'all loaded:\\nthresholds: {THSS}\\nmodels: {BEST_MODELS}')","33cc9674":"MODELS","372be86d":"def rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) \n                       for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    \n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef pred_masks(file_name, path, model, ths, min_pixels):\n    img = cv2.imread(f'{path}\/{file_name}')\n    output = model(img)\n    pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n    pred_class = max(set(pred_classes), key=pred_classes.count)\n    take = output['instances'].scores >= ths[pred_class]\n    pred_masks = output['instances'].pred_masks[take]\n    pred_masks = pred_masks.cpu().numpy()\n    result = []\n    used = np.zeros(img.shape[:2], dtype=int) \n    for i, mask in enumerate(pred_masks):\n        mask = mask * (1 - used)\n        if mask.sum() >= min_pixels[pred_class]:\n            used += mask\n            result.append(rle_encode(mask))\n    return result\n\ndef ensemble_preds(file_name, path, models, ths):\n    img = cv2.imread(f'{path}\/{file_name}')\n    classes = []\n    scores = []\n    bboxes = []\n    masks = []\n    for i, model in enumerate(models):\n        output = model(img)\n        pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n        pred_class = max(set(pred_classes), key=pred_classes.count)\n        take = output['instances'].scores >= ths[i][pred_class]\n        classes.extend(output['instances'].pred_classes[take].cpu().numpy().tolist())\n        scores.extend(output['instances'].scores[take].cpu().numpy().tolist())\n        bboxes.extend(output['instances'].pred_boxes[take].tensor.cpu().numpy().tolist())\n        masks.extend(output['instances'].pred_masks[take].cpu().numpy())\n    assert len(classes) == len(masks) , 'ensemble lenght mismatch'\n    #scores, classes, bboxes, masks = zip(*sorted(zip(scores, classes, bboxes, masks),reverse=True))\n    return classes, scores, bboxes, masks\n\ndef nms_predictions(classes, scores, bboxes, masks, \n                    iou_th=.5, shape=(520, 704)):\n    he, wd = shape[0], shape[1]\n    boxes_list = [[[x[0] \/ wd, x[1] \/ he, x[2] \/ wd, x[3] \/ he] for x in bboxes]]\n    scores_list = [[x for x in scores]]\n    classes_list = [[x for x in classes]]\n    nms_bboxes, nms_scores, nms_classes = non_maximum_weighted(\n        boxes_list, \n        scores_list, \n        classes_list, \n        weights=None,\n        iou_thr=0.3,skip_box_thr=0.0001  \n    )\n    nms_masks = []\n    for s in nms_scores:\n        nms_masks.append(masks[scores.index(s)])\n    nms_scores, nms_classes, nms_masks = zip(*sorted(zip(nms_scores, nms_classes, nms_masks), reverse=True))\n    return nms_classes, nms_scores, nms_masks\n\ndef ensemble_pred_masks(masks, classes, min_pixels, shape=(520, 704)):\n    result = []\n    #pred_class = max(set(classes), key=classes.count)\n    pred_class = int(max(set(classes), key=classes.count).item())\n    used = np.zeros(shape, dtype=int) \n    for i, mask in enumerate(masks):\n        mask = mask * (1 - used)\n        if mask.sum() >= min_pixels[pred_class]:\n            used += mask\n            result.append(rle_encode(mask))\n    return result","0bfbfde6":"test_names = os.listdir(SUBM_PATH)\nprint('test images:', len(test_names))","3ed08ee7":"encoded_masks_single = pred_masks(\n    test_names[ID_TEST], \n    path=SUBM_PATH, \n    model=MODELS[0],\n    ths=THSS[0],\n    min_pixels=MIN_PIXELS\n)","b9ec7c0a":"classes, scores, bboxes, masks = ensemble_preds(\n    file_name=test_names[ID_TEST] , \n    path=SUBM_PATH, \n    models=MODELS, \n    ths=THSS\n)\nif NMS:\n    classes, scores, masks = nms_predictions(\n        classes, \n        scores, \n        bboxes,\n        masks, iou_th=IOU_TH\n    )\nencoded_masks = ensemble_pred_masks(masks, classes, min_pixels=MIN_PIXELS)","169d5d41":"_, axs = plt.subplots(2, 2, figsize=(14, 8))\naxs[0][0].imshow(cv2.imread(f'{SUBM_PATH}\/{test_names[ID_TEST]}'))\naxs[0][0].axis('off')\naxs[0][0].set_title(test_names[ID_TEST])\nfor en_mask in encoded_masks_single:\n    dec_mask = rle_decode(en_mask)\n    axs[0][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n    axs[0][1].axis('off')\n    axs[0][1].set_title('single model')\naxs[1][0].imshow(cv2.imread(f'{SUBM_PATH}\/{test_names[ID_TEST]}'))\naxs[1][0].axis('off')\naxs[1][0].set_title(test_names[ID_TEST])\nfor en_mask in encoded_masks:\n    dec_mask = rle_decode(en_mask)\n    axs[1][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n    axs[1][1].axis('off')\n    axs[1][1].set_title('ensemble models')\nplt.show()","7e141bff":"subm_ids, subm_masks = [], []\nfor test_name in tqdm(test_names):\n    if SINGLE_MODE:\n        encoded_masks = pred_masks(\n            test_name, \n            path=SUBM_PATH, \n            model=MODELS[0],\n            ths=THSS[0],\n            min_pixels=MIN_PIXELS\n        )\n    else:\n        classes, scores, bboxes, masks = ensemble_preds(\n            file_name=test_name, \n            path=SUBM_PATH, \n            models=MODELS, \n            ths=THSS\n        )\n        if NMS:\n            classes, scores, masks = nms_predictions(\n                classes, \n                scores, \n                bboxes, \n                masks, \n                iou_th=IOU_TH\n            )\n        encoded_masks = ensemble_pred_masks(\n            masks, \n            classes, \n            min_pixels=MIN_PIXELS\n        )\n    for enc_mask in encoded_masks:\n        subm_ids.append(test_name[:test_name.find('.')])\n        subm_masks.append(enc_mask)","7a11b3fe":"pd.DataFrame({\n    'id': subm_ids, \n    'predicted': subm_masks\n}).to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","35612f96":"## Install and import libraries","2f10985e":"## My Models","16e76e2d":"# Ensemble NMS - Detectron2 [Inference]","0461fc78":"## Inference","c1b1d724":"### Hi kagglers, This is `Ensemble NMW - Detectron2 [Inference]` notebook.\n* [Sartorius Segmentation - Detectron2 [training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-detectron2-training) \n* [Sartorius Segmentation - Detectron2 [Inference]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-detectron2-inference) \n* [K-fold CrossValidation COCO Dataset Generator](https:\/\/www.kaggle.com\/ammarnassanalhajali\/k-fold-crossvalidation-coco-dataset-generator) \n\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","35328e67":"# References\n1. https:\/\/www.kaggle.com\/vgarshin\/detectron2-inference-with-ensemble-and-nms","713cae3d":"## Demo inference","8f59d541":"## Utils","c9fe149e":"## Other notebooks in this competition \n- [Sartorius Segmentation - Keras U-Net[Training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-keras-u-net-training)\n- [Sartorius Segmentation - Keras U-Net[Inference]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-keras-u-net-inference\/edit)","4e186467":"# Intro\nEnsembling multiple weaker performing models can help to get the results that you want."}}