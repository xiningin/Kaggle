{"cell_type":{"8c08db6b":"code","c77c9d16":"code","2af6103a":"code","a9087104":"code","c24e6224":"code","5aee4cce":"code","a8911943":"code","9938a9a5":"code","667e8dc0":"code","9673149f":"code","77a71e76":"code","db7aea83":"code","a5437dfd":"code","15abe323":"code","0489c425":"code","6a678a9a":"code","b64bb20b":"code","6e0f1c2d":"code","5c5ce417":"code","05fd1a1d":"code","c4f2cbc9":"code","d5772567":"code","dfe96ddb":"code","f4b04f08":"code","5cbdc78c":"code","1db02675":"code","1b474a92":"code","2ba3f4f8":"code","9ec64b57":"code","b96de46b":"code","36a98143":"code","96f0f1a7":"code","b4954059":"code","eab654d3":"code","18c03b0a":"code","275f2667":"code","57be7c3b":"code","afb92923":"code","4f07a891":"code","dcd5ec32":"code","50931a36":"code","763bdc02":"code","61314c6f":"code","dbb695f1":"code","2866f1f2":"code","66453d5d":"code","39991aa5":"code","46c4838f":"code","7a6f3c70":"code","2649de00":"code","ba5fe3ef":"code","e9811f5a":"code","9eb29857":"code","86bfdb4c":"code","fceec606":"code","04f220d4":"code","18bfb46e":"code","881aadd1":"code","50df5ed7":"code","e7974c29":"code","d34224b8":"code","e8f58cc4":"code","e04bfe0d":"code","95472096":"code","c0d5abb3":"code","17b4e34a":"code","c32b31c9":"markdown","f827d553":"markdown","0cec6681":"markdown","b86ffa70":"markdown","23fb3319":"markdown","769a406d":"markdown","e8675686":"markdown","7ceb48b8":"markdown","1bbe88d8":"markdown","7f2da75d":"markdown","e412514c":"markdown","7ca9da6f":"markdown","dce71b61":"markdown","f2560c66":"markdown","e2b82d90":"markdown","7449e2cf":"markdown","e5c56d85":"markdown","42e08cc3":"markdown","516883c5":"markdown","165fb5f6":"markdown","f9438672":"markdown","81d20b1d":"markdown","9acebb16":"markdown"},"source":{"8c08db6b":"# This Python 3 environment comes with many helpful analytics libraries installed.\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n\n# Packages\nimport numpy as np # Number crunching\nimport pandas as pd # Data processing\nimport matplotlib.pyplot as plt #Visualisation\nimport seaborn as sns #Visualisation\nfrom scipy.stats import ttest_1samp # 1 Sample T-test\nfrom scipy.stats import ttest_ind # 2 Sample T-test\nfrom sklearn.linear_model import LinearRegression # Linear Regression\n","c77c9d16":"# File location\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2af6103a":"# I found this data by browsing the datasets on Kaggle.\n# Load the football data\ndata = pd.read_csv('\/kaggle\/input\/womens-international-football-results\/results.csv')","a9087104":"# Table\ndata.head()","c24e6224":"# Info\ndata.info()","5aee4cce":"# Columns\ndata.columns","a8911943":"# Rename Columns\ndata.rename(columns={'home_score':'home_goals','away_score':'away_goals', 'country':'host'}, inplace=True)","9938a9a5":"# I want to create two results columns which tells us whether a team won (W), drew (D) or lost (L)\n# First I will create a results function\ndef result(a,b):\n    if a > b:\n        r = 'W'\n    elif a < b:\n        r = 'L'\n    else:\n        r = 'D'\n    return r\n# Then create the results columns\ndata['home_result'] = [result(data['home_goals'][i], data['away_goals'][i]) for i in range(len(data))]\ndata['away_result'] = [result(data['away_goals'][i], data['home_goals'][i]) for i in range(len(data))]\n                ","667e8dc0":"# Check the updated dataframe\ndata.head()","9673149f":"# I want to change the neutral column to give a numeric value of either 0 (False) or 1 (True)\ndata['neutral'] = data['neutral'].apply(lambda x: 1 if x == True else 0)\ndata.head()","77a71e76":"# Check for null values\ndata.isnull().any()","db7aea83":"# Check for duplicates\ndata[data.duplicated()]","a5437dfd":"# Let's see if there's a correlation between the results and whether the game was on neutral ground\nsns.heatmap(data.corr(),annot=True, linewidths=0.5)","15abe323":"# Let's visualise the home goals\nplt.hist(data['home_goals'], bins=max(data['home_goals']))\nplt.axvline(np.median(data['home_goals']), color='Black')\nplt.axvline(np.mean(data['home_goals']), color='Yellow')\nplt.xlabel('Goals')\nplt.ylabel('Frequency')\nplt.title('Home Goals Histogram')\nplt.legend(['Median','Mean'])\nplt.show()","0489c425":"# Let's visualise the away goals\nplt.hist(data['away_goals'], bins=max(data['away_goals']), color='Red')\nplt.axvline(np.median(data['away_goals']), color='Black')\nplt.axvline(np.mean(data['away_goals']), color='Yellow')\nplt.xlabel('Goals')\nplt.ylabel('Frequency')\nplt.title('Away Goals Histogram')\nplt.legend(['Median','Mean'])\nplt.show()","6a678a9a":"# Let's create a separate dataframe with all the games that had a team playing at home\nhomeadv_data = data[data['neutral']==0]\nhomeadv_data = homeadv_data.reset_index()\nhomeadv_data.head()","b64bb20b":"# Let's create another dataframe for the games where neither team was playing at home\nneut_data = data[data['neutral']==1].reset_index()\nneut_data.head()","6e0f1c2d":"# Let's see the match results of the home team when they were playing at home\nplt.pie(homeadv_data['home_result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nplt.title('Match Results With Home Advantage')\nplt.legend(['W', 'L', 'D'])\nplt.show()","5c5ce417":"# Let's compare this to the match results of games where neither team was playing at home\nplt.pie(neut_data['home_result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nplt.title('Match Results Without Home Advantage')\nplt.legend(['W', 'L', 'D'])\nplt.show()","05fd1a1d":"# Let's see a comparison on a bar chart\nsns.countplot(x=data['neutral'], hue=data['home_result'])\nplt.title('Home Team Performance Comparison')","c4f2cbc9":"# To test this I'm going to randomly re-order most of the matches in the neutral data set to see if the proportions turn out as expected\nlength = neut_data['home_result'].count()\nlength = int(length)\nrandom_swaps = np.random.randint(length, size=round(length*0.7))\n\n# for loop to swap the rows\nrand_neut_data = neut_data[['index','date', 'tournament', 'city', 'host', 'neutral']]\nhome_team = []\naway_team = []\nhome_goals = []\naway_goals = []\nfor i in range(length):\n    if i in random_swaps:\n        row = [neut_data['away_team'][i],neut_data['home_team'][i],neut_data['away_goals'][i],neut_data['home_goals'][i]]\n    else:\n        row = [neut_data['home_team'][i],neut_data['away_team'][i],neut_data['home_goals'][i],neut_data['away_goals'][i]]\n    #Create the values in the columns\n    home_team.append(row[0])\n    away_team.append(row[1])\n    home_goals.append(row[2])\n    away_goals.append(row[3])\n                           \n# Create the new columns\nrand_neut_data['home_team'] = home_team \nrand_neut_data['away_team'] = away_team\nrand_neut_data['home_goals'] = home_goals\nrand_neut_data['away_goals'] = away_goals\nrand_neut_data.head(10)","d5772567":"# Let's add the home and away result columns again\nrand_neut_data['home_result'] = [result(rand_neut_data['home_goals'][i], rand_neut_data['away_goals'][i]) for i in range(len(rand_neut_data))]\nrand_neut_data['away_result'] = [result(rand_neut_data['away_goals'][i], rand_neut_data['home_goals'][i]) for i in range(len(rand_neut_data))]\n# Let's see the new dataframe\nrand_neut_data.head(10)","dfe96ddb":"# Let's see the proportions of wins and losses\nrand_neut_data['home_result'].value_counts() \/ len(rand_neut_data['home_result'])","f4b04f08":"# Create the cleaned dataframe\nclean_data = pd.merge(rand_neut_data, homeadv_data, how = 'outer')\nclean_data.head()","5cbdc78c":"# Check the cleaned data\nclean_data.info()","1db02675":"sns.heatmap(clean_data[['neutral', 'home_goals', 'away_goals']].corr(),annot=True, linewidths=0.5)\nplt.title('Correlations')","1b474a92":"# Let's visualise the home score\nplt.hist(clean_data['home_goals'], bins=max(clean_data['home_goals']))\nplt.axvline(np.median(clean_data['home_goals']), color='Black')\nplt.axvline(np.mean(clean_data['home_goals']), color='Yellow')\nplt.xlabel('Goals')\nplt.ylabel('Frequency')\nplt.title('Home Goals Histogram')\nplt.legend(['Median','Mean'])\nplt.show()","2ba3f4f8":"# Let's visualise the away score\nplt.hist(clean_data['away_goals'], bins=max(clean_data['away_goals']), color='Red')\nplt.axvline(np.median(clean_data['away_goals']), color='Black')\nplt.axvline(np.mean(clean_data['away_goals']), color='Yellow')\nplt.xlabel('Goals')\nplt.ylabel('Frequency')\nplt.title('Away Goals Histogram')\nplt.legend(['Median','Mean'])\nplt.show()","9ec64b57":"# Comparing the results of matches \nsns.countplot(x=clean_data['home_result'], hue=clean_data['neutral'])","b96de46b":"# Let's now run some 1 sample T-tests to see if our results are statistically significant\n# Null hypothesis: A team's performance is not affected by where they are playing\n\n# Win\nt, p_win = ttest_1samp(homeadv_data['home_result'].apply(lambda x: 1 if x == 'W' else 0), 0.4333875)\nprint('p_win is '+str(p_win))\n\n# Draw\nt, p_draw = ttest_1samp(homeadv_data['home_result'].apply(lambda x: 1 if x == 'D' else 0), 0.133225)\nprint('p_draw is '+str(p_draw))\n\n# Loss\nt, p_loss = ttest_1samp(homeadv_data['home_result'].apply(lambda x: 1 if x == 'L' else 0), 0.4333875)\nprint('p_loss is '+str(p_loss))","36a98143":"# Let's do a 1 sample t-test on the number of home goals to see if there a significant increase in the number of goals scored\n# Null hypothesis is that there is no significant change in the number of goals scored\nt, p_val = ttest_1samp(homeadv_data['home_goals'], np.mean(clean_data['home_goals']))\nprint('P value is '+str(p_val))","96f0f1a7":"\n# List of countries\ncountries_home = clean_data['home_team'].unique()\ncountries_away = clean_data['away_team'].unique()\ndont_add = []\nadd = []\nfor country in countries_away:\n    if country in countries_home:\n        dont_add.append(country)\n    else:\n        add.append(country)\nunsorted_countries = np.concatenate([countries_home,add])\n#Sort the countries alphabetically\ncountries = np.sort(unsorted_countries)\n# Create a separate dataframe for each country\ncountry_data = []\nfor i in range(len(countries)):\n    country = countries[i]\n    home_matches = clean_data[clean_data['home_team'] == country]\n    away_matches = clean_data[clean_data['away_team'] == country]\n    matches = pd.merge(home_matches, away_matches, how='outer')\n    country_data.append(matches)\n# United States dataframe\nUS_data = country_data[180]\nUS_data.head()","b4954059":"# Create the individual dataframes\nclean_country = []\nfor i in range(len(country_data)):\n    country_name = countries[i]\n    country = country_data[i]\n    home_country = country[country['home_team'] == country_name][['index', 'date', 'tournament', 'neutral', 'home_team', 'away_team', 'home_goals', 'away_goals','home_result']]\n    home_country.rename(columns = {'home_team':'country', 'away_team':'opponent', 'home_goals':'goals_for', 'away_goals':'goals_against', 'home_result':'result'}, inplace=True)\n    away_country =  country[country['away_team'] == country_name][['index', 'date', 'tournament', 'neutral', 'away_team', 'home_team','away_goals', 'home_goals','away_result']]\n    away_country.rename(columns = {'away_team':'country', 'home_team':'opponent', 'away_goals':'goals_for', 'home_goals':'goals_against', 'away_result':'result'}, inplace=True)\n    new_country = pd.merge(home_country, away_country, how = 'outer')\n    clean_country.append(new_country)\n\n# US cleaned data\nUS = clean_country[180]\nUS.head(10)","eab654d3":"# Now that the country data has been cleaned lets do some EDA\n# Let's create a list with the mean goals scored for and against each country\n\ncountry_goals_for = [clean_country[i]['goals_for'].mean() for i in range(len(clean_country))]\ncountry_goals_against = [clean_country[i]['goals_against'].mean() for i in range(len(clean_country))]\n\n# Now let's visualise this with a bar chart\nplt.bar(list(range(len(country_data))),country_goals_for)\nplt.axhline(np.mean(country_goals_for), color='Yellow')\nplt.xlabel('Country')\nplt.ylabel('Mean Goals')\nplt.title('Mean Goals Scored')\nplt.legend(['Mean'])\nplt.show()","18c03b0a":"# First let's get the dataframes for the USA, England and Brazil\nUSA = clean_country[180] \nEng = clean_country[54]\nBra = clean_country[25]\n\n#Let's visualise their match records\n# USA\nplt.pie(USA['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nplt.legend(['W', 'L', 'D'])\nplt.title('USA match record')\nplt.show()","275f2667":"USA.head(10)","57be7c3b":"# England\nplt.pie(Eng['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nplt.legend(['W', 'L', 'D'])\nplt.title('England match record')\nplt.show()","afb92923":"Eng.head(10)","4f07a891":"# Brazil\nplt.pie(Bra['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nplt.legend(['W', 'L', 'D'])\nplt.title('Brazil match record')\nplt.show()","dcd5ec32":"Bra.head(10)","50931a36":"# I now want to make a histogram for the frequency of goals scored for\/against\n# USA\nplt.hist(USA['goals_for'], bins=max(USA['goals_for']),color='blue')\nplt.hist(USA['goals_against'], bins=max(USA['goals_against']),color='lightblue', alpha=0.6)\nplt.xlabel('Number of Goals')\nplt.ylabel('Frequency')\nplt.title('USA Goals Histogram')\nplt.legend(['Goals for','Goals against'])\nplt.show()","763bdc02":"# England\nplt.hist(Eng['goals_for'], bins=max(Eng['goals_for']),color='red')\nplt.hist(Eng['goals_against'], bins=max(Eng['goals_against']),color='lightcoral', alpha=0.6)\nplt.xlabel('Number of Goals')\nplt.ylabel('Frequency')\nplt.title('England Goals Histogram')\nplt.legend(['Goals for','Goals against'])\nplt.show()","61314c6f":"# Brazil\nplt.hist(Bra['goals_for'], bins=max(Bra['goals_for']),color='green')\nplt.hist(Bra['goals_against'], bins=max(Bra['goals_against']),color='yellowgreen', alpha=0.6)\nplt.xlabel('Number of Goals')\nplt.ylabel('Frequency')\nplt.title('Brazil Goals Histogram')\nplt.legend(['Goals for','Goals against'])\nplt.show()","dbb695f1":"# If the goals_against histogram is distributed like: \u0393 ~ (\u03bc = 1\/a, \u03c3 = 1\/a), then the std = mean\nprint('mean: '+str(US['goals_against'].mean()))\nprint('std: '+str(US['goals_against'].std()))","2866f1f2":"# Now I want to look at the distribution of goals scored for each type of result\n#USA\nplt.hist(USA[USA['result']=='W']['goals_for'], bins=max(USA[USA['result']=='W']['goals_for']), color='darkblue')\nplt.hist(USA[USA['result']=='D']['goals_for'], bins=max(USA[USA['result']=='D']['goals_for']), color='yellow', alpha=0.8)\nplt.hist(USA[USA['result']=='L']['goals_for'], bins=max(USA[USA['result']=='L']['goals_for']), color='blue', alpha=0.6)\nplt.xlabel('Number of Goals')\nplt.ylabel('Frequency')\nplt.title('USA Goals Histogram')\nplt.legend(['Win', 'Draw', 'Loss'])\nplt.show()","66453d5d":"# England\nplt.hist(Eng[Eng['result']=='W']['goals_for'], bins=max(Eng[Eng['result']=='W']['goals_for']), color='darkred')\nplt.hist(Eng[Eng['result']=='D']['goals_for'], bins=max(Eng[Eng['result']=='D']['goals_for']), color='yellow', alpha=0.8)\nplt.hist(Eng[Eng['result']=='L']['goals_for'], bins=max(Eng[Eng['result']=='L']['goals_for']), color='lightcoral', alpha=0.6)\nplt.xlabel('Number of Goals')\nplt.ylabel('Frequency')\nplt.title('England Goals Histogram')\nplt.legend(['Win', 'Draw', 'Loss'])\nplt.show()","39991aa5":"# Brazil\nplt.hist(Bra[Bra['result']=='W']['goals_for'], bins=max(Bra[Bra['result']=='W']['goals_for']), color='darkgreen')\nplt.hist(Bra[Bra['result']=='D']['goals_for'], bins=max(Bra[Bra['result']=='D']['goals_for']), color='yellow', alpha=0.8)\nplt.hist(Bra[Bra['result']=='L']['goals_for'], bins=max(Bra[Bra['result']=='L']['goals_for']), color='yellowgreen', alpha=0.6)\nplt.xlabel('Number of Goals')\nplt.ylabel('Frequency')\nplt.title('Brazil Goals Histogram')\nplt.legend(['Win', 'Draw', 'Loss'])\nplt.show()","46c4838f":"# I want to compare how well these teams perform in qualifying compared to the actual World Cup\n# USA\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.pie(USA[USA['tournament'] == 'FIFA World Cup']['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nax1.set_title('World Cup')\nax1.legend(['W', 'L', 'D'])\n\nax2.pie(USA[USA['tournament'] != 'FIFA World Cup']['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nax2.set_title('Not World Cup')\nax2.legend(['W', 'L', 'D'])\nplt.show()","7a6f3c70":"# England\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.pie(Eng[Eng['tournament'] == 'FIFA World Cup']['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nax1.set_title('World Cup')\nax1.legend(['W', 'L', 'D'])\n\nax2.pie(Eng[Eng['tournament'] != 'FIFA World Cup']['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nax2.set_title('Not World Cup')\nax2.legend(['W', 'L', 'D'])\nplt.show()","2649de00":"# Brazil\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.pie(Bra[Bra['tournament'] == 'FIFA World Cup']['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nax1.set_title('World Cup')\nax1.legend(['W', 'L', 'D'])\n\nax2.pie(Bra[Bra['tournament'] != 'FIFA World Cup']['result'].value_counts(),autopct='%1.1f%%',colors=['lightblue', 'lightcoral', 'yellowgreen'])\nax2.set_title('Not World Cup')\nax2.legend(['W', 'L', 'D'])\nplt.show()","ba5fe3ef":" # For loop to create the columns\ncountry_games = []\ncountry_wins = []\ncountry_draws = []\ncountry_losses=[]\nfor i in range(len(countries)):\n    nation = clean_country[i]\n    nation_games= nation['result'].count()\n    country_games.append(nation_games)\n    nation_wins = nation[nation['result']=='W']['result'].count()\n    country_wins.append(nation_wins)\n    nation_draws = nation[nation['result']=='D']['result'].count()\n    country_draws.append(nation_draws)\n    nation_losses = nation[nation['result']=='L']['result'].count()\n    country_losses.append(nation_losses)\n\n# Create the table\nresults_table = pd.DataFrame({'Country': countries,'Games': country_games,'Wins': country_wins, 'Draws': country_draws, 'Losses': country_losses})\n\n# Score system\nresults_table['Score'] = round((results_table['Wins']*3 + results_table['Draws'])\/results_table['Games'],2)\n\nresults_table.head(10)","e9811f5a":"# Histogram of scores\nplt.hist(results_table['Score'],bins=20,color='blue')\nplt.axvline(x=np.mean(results_table['Score']),color='yellow')\nplt.title('Score Histogram')\nplt.xlabel('Score')\nplt.ylabel('Frequency')\nplt.legend(['Mean'])\nplt.show()","9eb29857":"# Looks like there are a lot of countries with a score of 0, let's see which countries these are\nno_score = results_table[results_table['Score']==0]['Country']\nno_score","86bfdb4c":"#Let's see the results table for our countries\nresults_table.loc[[180,25,54]]","fceec606":"# Sort the scores so they are in order\nsorted_scores = np.sort(results_table['Score'])\n# Create the columns\nsorted_games = []\nsorted_country = []\nsorted_wins = []\nsorted_draws = []\nsorted_losses = []\n# Find the country with these scores\nfor i in range(len(sorted_scores)):\n    score = sorted_scores[-1*(i+1)]\n    for j in range(len(sorted_scores)):\n        if results_table['Score'][j] == score and results_table['Games'][j] > 10 and results_table['Country'][j] not in sorted_country:\n            # Add the countries results in order to create the rows\n            sorted_country.append(results_table['Country'][j])\n            sorted_games.append(results_table['Games'][j])\n            sorted_wins.append(results_table['Wins'][j])\n            sorted_draws.append(results_table['Draws'][j])\n            sorted_losses.append(results_table['Losses'][j])\n\n# Create the table            \nranking_table = pd.DataFrame({'Country': sorted_country,'Games': sorted_games,'Wins': sorted_wins, 'Draws': sorted_draws, 'Losses': sorted_losses})\nranking_table['Score'] = round((ranking_table['Wins']*3 + ranking_table['Draws'])\/ranking_table['Games'],2)\n\nranking_table.head(10)","04f220d4":"# Histogram of scores\nplt.hist(ranking_table['Score'],bins=20,color='blue')\nplt.axvline(x=np.mean(ranking_table['Score']),color='yellow')\nplt.title('Score Histogram')\nplt.xlabel('Score')\nplt.ylabel('Frequency')\nplt.legend(['Mean'])\nplt.show()","18bfb46e":"# Heatmap to check for correlations\nsns.heatmap(ranking_table.corr(),annot=True,linewidths=0.5)\nplt.title('Rankings Heatmap')\nplt.show()","881aadd1":"# Games\nplt.scatter(y=ranking_table['Score'], x=ranking_table['Games'], color='black', alpha = 0.6)\nplt.xlabel('Games Played')\nplt.ylabel('Score')\nplt.title('Games Scatter Plot')\nplt.show()","50df5ed7":"# Wins\nplt.scatter(y=ranking_table['Wins']\/ranking_table['Games'], x=ranking_table['Games'], color='blue', alpha = 0.6)\nplt.xlabel('Games Played')\nplt.ylabel('Win Proportion')\nplt.title('Win Proportion vs. Games Played Scatter Plot')\nplt.show()","e7974c29":"# Portugal and Finland have played more than 150 games played but have a score less than 1\ntable = ranking_table[ranking_table['Games'] > 150]\ntable[table['Score'] < 1]\n\n# Norway, Sweden, China PR and Denmark have played more than 250 games but have a score less than 2\n# All the Scandanvian countries (apart from Iceland) are outliers\ntable = ranking_table[ranking_table['Games'] > 250]\ntable[table['Score'] < 2]\n\n# Northen Ireland have played more than 50 games but have a score less than 0.5\ntable = ranking_table[ranking_table['Games'] > 50]\ntable[table['Score'] < 0.5]\n\n#Estonia have played nearly 50 games and have a really low score of 0.10\ntable = ranking_table[ranking_table['Games'] < 50]\ntable[table['Score'] < 0.3]\n\n# Dominican Republic and Jordan have played less than 50 games but have a score of 1.86 and 1.85 respectively\ntable = ranking_table[ranking_table['Games'] < 50]\ntable[table['Score'] > 1.5]","d34224b8":"# Create a new table with the outliers removed\n# There's probably a much more efficent way of doing this but this method will suffice\ntable_a = ranking_table[ranking_table['Country'] != 'Portugal'] \ntable_b = table_a[table_a['Country'] != 'Finland'] \ntable_c = table_b[table_b['Country'] != 'Norway']\ntable_d = table_c[table_c['Country'] != 'Sweden']\ntable_e = table_d[table_d['Country'] != 'China PR']\ntable_f = table_e[table_e['Country'] != 'Denmark']\ntable_g = table_f[table_f['Country'] != 'Northen Ireland']\ntable_h = table_g[table_g['Country'] != 'Estonia']\ntable_i = table_h[table_h['Country'] != 'Dominican Republic']\ntable_j = table_i[table_i['Country'] != 'Jordan']","e8f58cc4":"# Linear Regression\nline = LinearRegression()\nGames = table_j['Games']\nGames = Games.values.reshape(-1,1)\nline.fit(Games,-np.log1p(-table_j['Wins']\/table_j['Games']))\nline_y = line.predict(ranking_table['Games'].values.reshape(-1,1))\n# Gradient\nk= line.coef_[0]\n# Intercept\nc= line.predict(np.array([0]).reshape(-1,1))[0]\n\n# Scatter Plot with re-arranged variables\nplt.scatter(x=ranking_table['Games'], y=-np.log1p(-ranking_table['Wins']\/ranking_table['Games']), color='blue', alpha = 0.6)\nplt.plot(ranking_table['Games'],line_y, color = 'black')\nplt.xlabel('Games Played')\nplt.ylabel('Modified Win Proportion')\nplt.title('Win Proportion Scatter Plot with Line of Best Fit')\nplt.legend(['Line of Best Fit', 'Gradient='+str(round(k,5))])\nplt.show()\n","e04bfe0d":"# Here's the original plot with the exponential curve\ny_val = np.arange(0,301,1)\nplt.scatter(y=ranking_table['Wins']\/ranking_table['Games'], x=ranking_table['Games'], color='blue', alpha = 0.6)\nplt.plot(1+(c-1)*np.exp(-k*y_val),color='Black')\nplt.xlabel('Games Played')\nplt.ylabel('Win Proportion')\nplt.title('Win Proportion vs. Games Played Scatter Plot')\nplt.legend(['Exponential Curve'])\nplt.show()","95472096":"# The exponential curve above doesn't start close to (0,0), (which would be ideal)\n# A gradient of 0.006 fits the plot and goes through (0,0)\nplt.scatter(y=ranking_table['Wins']\/ranking_table['Games'], x=ranking_table['Games'], color='blue', alpha = 0.6)\nplt.plot(1-np.exp(-0.006*y_val),color='Black')\nplt.xlabel('Games Played')\nplt.ylabel('Win Proportion')\nplt.title('Win Proportion vs. Games Played Scatter Plot')\nplt.legend(['Exponential Curve'])\nplt.show()","c0d5abb3":"# Draws\nplt.scatter(y=ranking_table['Draws']\/ranking_table['Games'], x=ranking_table['Games'], color='green', alpha = 0.6)\nplt.axhline(y=np.mean(ranking_table['Draws']\/ranking_table['Games']))\nplt.xlabel('Games Played')\nplt.ylabel('Draw Proportion')\nplt.title('Draw Proportion vs. Games Played Scatter Plot')\nplt.legend(['Mean'])\nplt.show()","17b4e34a":"# Losses\nplt.scatter(y=ranking_table['Losses']\/ranking_table['Games'], x=ranking_table['Games'], color='red', alpha = 0.6)\nplt.xlabel('Games Played')\nplt.ylabel('Loss Proportion')\nplt.title('Loss Proportion vs. Games Played Scatter Plot')\nplt.show()","c32b31c9":"# Countries\n\nI want to turn my attention to looking at the performances of different countries. First I want to create a separate dataframe for each country which containing the matches they have played. ","f827d553":"# Womens International Football EDA\n\nHello Kaggler, this is my first notebook so I'm putting this out here first and foremost for feedback and not for any new insights I think I've found. Football is the British name for this sport. For any American readers you would call this sport 'Soccer'. I should also probably mention now that I don't follow Women's football or any sport for that manner, so I'm going in somewhat blind. Here's a list of Kaggle notebooks I used to help me with some of the code:\nhttps:\/\/www.kaggle.com\/nikhileshkos\/titanic-disaster-prediction-80-acc;\nhttps:\/\/www.kaggle.com\/kanncaa1\/data-sciencetutorial-for-beginners\n","0cec6681":"Interestingly the proportion of draws seems to be converging to a specific value (slightly higher than the mean). Also the points seem to converge to this hypothetical line from two different directions depending on whether their y-coorindate is above or below the hypthetical value. My guess is that the plots follow a first order ODE: dy\/dx = r(k-y), r=rate of convergence, k=hypothetical value. I won't try and figure out what r and k are for this, although that would be something I might do in the near future, or maybe one of you reading it can.","b86ffa70":"Upon inspection, none of these rows are duplicates so I will keep all of them.","23fb3319":"Looks like the USA performs slightly better at World Cups than at other competitions.","769a406d":"Looks like Brazil performs slightly worse at World Cups than at other competitions. I want to now rank these countries in some way by giving them a score. The formula is quite simple: Score = (3xWins + 1xDraws)\/total games.\nNow I want to create a pivot table that for every country, contains the number of games, wins, draws and losses as well as score.","e8675686":"I suspect that this graph follows an exponential curve and has a general equation that looks like: y = 1 - exp(-kx)\nI will re-arrange this equation to get: -log(1-y) = kx so that I can estimate the value of k using linear regression. First I want to remove outliers from the data.","7ceb48b8":"I would like to modfiy this dataframe so that instead of having home_team and away_team, have country and opponents. Similarly with home goals and away goals. I would also like one results columnn just for the result of the country.","1bbe88d8":"# Cleaning the Data","7f2da75d":"There seems to be something odd about the neutral data set. We would expect there to be roughly equal numbers of wins and losses in this data set. If that were true the proportions would ideally look like this:\n* W: 0.4333875\n* L: 0.4333875\n* D: 0.1332250","e412514c":"North Korea is 5th! That's a surprise, the Dominican Republic and Jordan being in the top 10 seems a bit fishy though.","7ca9da6f":"Looks like there is a very small correlation between the number of home goals and whether the game was 'neutral' or not.","dce71b61":"# Inspecting the Data","f2560c66":"I now want to re-order the table so that the table is arranged by score with the highest score at the top. I also want to exclude countries who have played less than 10 games, as their results are often skewed. I may make further amendments to the table for other outliers.","e2b82d90":"Looks like England performs just as well at the World Cup as they do in other competitions.","7449e2cf":"Analysing data for all 191 countries simultaneously will be messy (as the graph above shows). So, I would now like to do some EDA on specific countries: USA, England and Brazil. There's no particularly good reason to pick these countries. I'm English, I'm aware that Brazil is a good team (at least in men's football) and a lot of Kaggler's seem yo be from the USA. ","e5c56d85":"Looks like playing at home does mean the home team is more likely to win and less likely to lose. However the location a team is playing at has no affect on the likelihood of drawing","42e08cc3":"# Home Advantage\n\nThe two plots above don't tell us very much. For example it doesn't make sense to label teams 'home' and 'away' if neither team is playing in their home country. So I wanted to see if playing at home has a significant difference on a teams performance. ","516883c5":"The std and mean are quite different so looks like the histogram does not have a Gamma distribution. I'm not aware of any other distributions that have both those shapes. Maybe the distribution of this data is a task for someone with more stats knowledge than me.","165fb5f6":"I want to make some scatter plots to look at how playing more games affects performance. The correlations on the heatmap look slightly higher than I would have expected,-maybe that's just my poor judgement due to lack of knowledge about the sport-. ","f9438672":"Interestingly the frequency of goals for and goals against look like they have different distributions. To explain this I want suggest that both histograms have a Gamma distribution: \u0393(t,a) = (a^t\/(t-1)!)*x^(t-1)e^(-ax), x>0; \u0393 ~ (\u03bc = t\/a, \u03c3^2 = t\/a^2); \u0393(1,a) = a*e^(-ax) looks like the distribution for goals_against, \u0393(t,a) w\/ t>1 looks like the distribution for goals_for.","81d20b1d":"# Conclusion\n\n\nTo sum up what I learned from doing this. First, using common sense checks when cleaning data. As good as the data cleaning tools in Python are, they wouldn't have been able to spot to biased ordering to home and away teams. Second, the importance of visualising data. I'm not a visual learner, but I found plotting simple graphs helped so much with spotting outliers are data trends. \nNext, I want so summarise the conclusions of my EDA: I showed that there is such a things as home advantage. One thing I notice but didn't comment on was that the away goals were less skewed than the home goals. If I were to add anything to this notebook, it would be some boxplots to look into that. I also looked at how experience (number of games played) affects performance, and found essentially what you would expect; That the more experienced a team is the better they do on average. It was also good to have a mathematical model for quantifying the relationship, even if I could have improved it, if I put a bit more effort into it.    \n\nAgain, this is my first Kaggle notebook, feedback is greatly appreciated. I essentially wanted to use this as an opportunity to get use to using the various libraries and tools in Python. I wasn't trying to find any new insights in this document, just put some numbers to things I already knew.\n\nThank you for reading this notebook :) ","9acebb16":"This data has a much better distribution, I think the uncleaned data had a bias towards wins for the home team because it's assumed that the home team is more likely to win.\n\nIf it's assumed that P(Win) & P(Loss) are independent and equal, and P(Draw) = P(Win)*P(Loss) (the intersection);\nThen P(Win) = 0.414 (sqrt(2)-1), P(Draw) = 0.172 (3-2*sqrt(2)), P(Loss) = 0.414 (sqrt(2)-1)\nIt's worth noting that these are very similar to the real values."}}