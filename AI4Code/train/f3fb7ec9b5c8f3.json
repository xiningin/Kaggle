{"cell_type":{"84cc25f0":"code","efb9add9":"code","fe8a9e88":"code","beda5492":"code","7d46e445":"code","a6946920":"code","ef453228":"code","65424a94":"code","143af000":"code","08719029":"code","61bc72f6":"code","70db3abe":"code","281eb1c0":"code","dcda0bb1":"code","a56c7c13":"code","832c9725":"code","dfa0eccb":"code","cee4d22e":"code","28d84b1f":"code","2bdf783b":"code","ac3e3cac":"code","428e3865":"code","0ab6b384":"code","2e394da9":"code","48798d12":"code","0539e788":"code","d85a5d68":"code","60c7c97f":"code","cfa3ffd1":"code","d364c7af":"code","14f0e8be":"code","3bbf0b31":"code","cc45f3ea":"code","b723dd62":"code","cbdf3a65":"code","146a8bbd":"code","2544ac84":"code","ff0174b0":"code","b7096410":"code","1b8a4156":"code","f6706e22":"code","3c8ad855":"code","4d42bb77":"code","1f64d59b":"code","93aa907f":"code","9b6d9cca":"code","ef94f34d":"code","ea7fff34":"code","e94d9042":"code","150fb16a":"code","ca9d7926":"code","278fa6dd":"code","1c654e3c":"code","6935199d":"code","4449560f":"code","1d1dc676":"code","70d357f5":"code","41f6f4fe":"code","a96e370b":"code","f896f9a4":"code","13f8e222":"code","3360d307":"code","d7d98776":"code","bc934ee9":"code","9fbea91c":"code","c6c5b138":"code","bb823fd8":"markdown","27cbd330":"markdown","0ed2724f":"markdown","9ea1fa82":"markdown","0e141665":"markdown","6ec92eb5":"markdown","0b6c69ae":"markdown","b848c97b":"markdown","500da459":"markdown","5ef988f7":"markdown","8df55222":"markdown","88793f30":"markdown","115f55ba":"markdown","4b70264c":"markdown","d31a182d":"markdown","428d3739":"markdown","9606f805":"markdown","8b37b5a8":"markdown","22965ae1":"markdown","2b93c949":"markdown","9bafc70c":"markdown","d60eeb5c":"markdown","ec658827":"markdown","7fbb40f4":"markdown","7ce9d4ba":"markdown","f4536d76":"markdown","e6afde70":"markdown","01f9b8d5":"markdown","9e60c13f":"markdown","0a9f6b9b":"markdown","ba0a7d68":"markdown","ad8f6430":"markdown","f7f86d1b":"markdown","0da6100e":"markdown","f379c612":"markdown","46a985c3":"markdown","9aa54a60":"markdown"},"source":{"84cc25f0":"#Import the required Libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","efb9add9":"#Read the data in pandas\ninp0= pd.read_csv(\"..\/input\/AttributeDataSet.csv\")\ninp1= pd.read_csv(\"..\/input\/DressSales.csv\")","fe8a9e88":"inp0.info()","beda5492":"inp0.head()","7d46e445":"# Print the information about the attributes of inp0 and inp1.\ninp0.info()","a6946920":"inp1.info()","ef453228":"# Column fixing, correcting size abbreviation. count the percentage of each size category in \"Size\" column.\npd.unique(inp0['Size'])","65424a94":"inp0['Size'].replace(['XL','L','M','S','s','small','free'], ['Extra Large','Large','Medium','Small','Small','Small','Free'], inplace=True)","143af000":"pd.unique(inp0['Size'])","08719029":"# Print the value counts of each category in \"Size\" column.\n# What is the value of the lowest percentage, the highest percentage and the percentage of Small size categories in the column named \u201cSize\u201d?\n\ninp0['Size'].value_counts(normalize=True)*100","61bc72f6":"# Print the null count of each variables of inp0 and inp1.\ninp0.isnull().sum()","70db3abe":"inp1.isnull().sum()","281eb1c0":"# Print the data types information of inp1 i.e. \"Dress Sales\" data.\ninp1.info()","dcda0bb1":"# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n#inp1['09-12-2013'] = pd.to_numeric(inp1['09-12-2013'])","a56c7c13":"# Do the required changes in the \"Dress Sales\" data set to get null values on string values.\ninp1.loc[inp1['09-12-2013']== 'Removed',\"09-12-2013\"] = np.NaN\ninp1.loc[inp1['14-09-2013']== 'removed',\"14-09-2013\"] = np.NaN\ninp1.loc[inp1['16-09-2013']== 'removed',\"16-09-2013\"] = np.NaN\ninp1.loc[inp1['18-09-2013']== 'removed',\"18-09-2013\"] = np.NaN\ninp1.loc[inp1['20-09-2013']== 'removed',\"20-09-2013\"] = np.NaN\ninp1.loc[inp1['22-09-2013']== 'Orders',\"22-09-2013\"] = np.NaN","832c9725":"# Convert the object type columns in \"Dress Sales\" into float type of data type.\ninp1['09-12-2013'] = pd.to_numeric(inp1['09-12-2013'], downcast='float')\ninp1['14-09-2013'] = pd.to_numeric(inp1['14-09-2013'], downcast='float')\ninp1['16-09-2013'] = pd.to_numeric(inp1['16-09-2013'], downcast='float')\ninp1['18-09-2013'] = pd.to_numeric(inp1['18-09-2013'], downcast='float')\ninp1['20-09-2013'] = pd.to_numeric(inp1['20-09-2013'], downcast='float')\ninp1['22-09-2013'] = pd.to_numeric(inp1['22-09-2013'], downcast='float')","dfa0eccb":"inp1.info()","cee4d22e":"# Print the null percetange of each column of inp1.\ninp1.isnull().sum()\/len(inp1.index)*100","28d84b1f":"# Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\ninp1 = inp1.drop(['26-09-2013','30-09-2013','10-02-2013','10-04-2013','10-08-2013','10-10-2013' ],axis=1)\ninp1.info()","2bdf783b":"inp1.isnull().sum()\/len(inp1.index)*100","ac3e3cac":"inp1.head()","428e3865":"# Create the four seasons columns in inp1, according to the above criteria.\ninp1['Summer'] = inp1['09-06-2013'] + inp1['10-06-2013'] + inp1['29-08-2013'] + inp1['31-08-2013'] + inp1['09-08-2013']\ninp1['Autumn'] = inp1['09-10-2013'] + inp1['14-09-2013'] + inp1['16-09-2013'] + inp1['18-09-2013'] + inp1['20-09-2013'] + inp1['22-09-2013'] + inp1['24-09-2013'] + inp1['28-09-2013']\ninp1['Winter'] = inp1['09-12-2013'] + inp1['10-12-2013'] + inp1['09-02-2013']\ninp1['Spring'] = inp1['09-04-2013']","0ab6b384":"# calculate the sum of sales in each seasons in inp1 i.e. \"Dress Sales\".\ninp1[['Summer','Autumn','Winter','Spring']].sum()","2e394da9":"# Merge inp0 with inp1 into inp0. this is also called left merge.\ninp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\ninp0.head()","48798d12":"# Now Drop the Date columns from inp0 as it is already combined into four seasons.\ninp0.drop(inp0.loc[:,'29-08-2013':'10-12-2013'].columns, axis= 1, inplace= True)","0539e788":"# Print the null count of each columns in inp0 dataframe i.e. combined data frame of inp0 and inp1 without date columns.\ninp0.isnull().sum()","d85a5d68":"#inp0.drop(inp0.loc[:,'29-08-2013_x':'Spring_y'].columns, axis= 1, inplace= True)\n#inp0.head()","60c7c97f":"inp0.isnull().sum()","cfa3ffd1":"# Deal with the missing values of Type-1 columns: Price, Season, NeckLine, SleeveLength, Winter and Autumn.\ninp0['Price'].fillna(inp0['Price'].mode(), inplace=True)\ninp0['Season'].fillna(inp0['Season'].mode(), inplace=True)\ninp0['NeckLine'].fillna(inp0['NeckLine'].mode(), inplace=True)\ninp0['SleeveLength'].fillna(inp0['SleeveLength'].mode(), inplace=True)\ninp0['Winter'].fillna(inp0['Winter'].mode(), inplace=True)\ninp0['Autumn'].fillna(inp0['Autumn'].mode(), inplace=True)","d364c7af":"# Deal with the missing values for Type-2 columns: Material, FabricType, Decoration and Pattern Type.\ninp0.dropna(axis=0, subset=['Material','FabricType','Decoration','Pattern Type'], inplace=True)\ninp0.isnull().sum()","14f0e8be":"#correcting the spellings.\ninp0['Season'].unique()","3bbf0b31":"inp0['Season'].replace(['Automn','winter'], ['Autumn','Winter'], inplace=True)\ninp0['Season'].unique()","cc45f3ea":"inp0['SleeveLength'].unique()","b723dd62":"inp0['SleeveLength'].replace(['thressqatar'], ['threequarter'], inplace=True)\ninp0['SleeveLength'].unique()","cbdf3a65":"inp0.head()","146a8bbd":"# Group \"Style\" categories into \"Others\" which have less than 50000 sales across all the seasons.\ninp0['total'] = inp0['Summer'] + inp0['Autumn'] + inp0['Winter'] + inp0['Spring']\nstyle_group = inp0['total'].groupby(inp0['Style']).sum().reset_index()\nres = style_group.loc[style_group['total']<50000]\nres","2544ac84":"inp0['Style'].replace(['Flare','Novelty','bohemian','party','party','sexy','vintage','work'], 'Others', inplace=True)\ninp0['Style'].unique()","ff0174b0":"# Calculate the percentage of each categories in the \"Style\" variable.\ninp0['Style'].value_counts(normalize=True)*100","b7096410":"# Group \"Neckline\" categories into \"Others\" which have less than 50000 sales across all the seasons.\nneck_group = inp0['total'].groupby(inp0['NeckLine']).sum().reset_index()\nres = neck_group.loc[neck_group['total']<50000]\nres","1b8a4156":"inp0['NeckLine'].replace(['Sweetheart','boart-neck','bowneck','open','peterpan-collor','slash-neck','turndowncollor'], 'Others', inplace=True)\ninp0['NeckLine'].unique()","f6706e22":"# Group \"Sleeve length\" categories into \"Others\" which have less than 50000 sales across all the seasons.\nsleeve_group = inp0['total'].groupby(inp0['SleeveLength']).sum().reset_index()\nres = sleeve_group.loc[sleeve_group['total']<50000]\nres","3c8ad855":"inp0['SleeveLength'].replace(['butterfly','threequarter'], 'Others', inplace=True)\ninp0['SleeveLength'].unique()","4d42bb77":"# Group \"material\" categories into \"Others\" which have less than 25000 sales across all the seasons.\nmat_group = inp0['total'].groupby(inp0['Material']).sum().reset_index()\nres = mat_group.loc[mat_group['total']<25000]\nres","1f64d59b":"inp0['Material'].replace(['linen','lycra','model','nylon','other','shiffon','spandex'], 'Others', inplace=True)\ninp0['Material'].unique()","93aa907f":"# Group \"fabric type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\nfab_group = inp0['total'].groupby(inp0['FabricType']).sum().reset_index()\nres = fab_group.loc[fab_group['total']<25000]\nres","9b6d9cca":"res['FabricType']","ef94f34d":"inp0['FabricType'].replace([res['FabricType']], 'Others', inplace=True)\ninp0['FabricType'].unique()","ea7fff34":"# Group \"patern type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\npat_group = inp0['total'].groupby(inp0['Pattern Type']).sum().reset_index()\nres = pat_group.loc[pat_group['total']<25000]\nres","e94d9042":"inp0['Pattern Type'].replace([res['Pattern Type']], 'Others', inplace=True)\ninp0['Pattern Type'].unique()","150fb16a":"# Group \"decoration\" categories into \"Others\" which have less than 25000 sales across all the seasons.\ndec_group = inp0['total'].groupby(inp0['Decoration']).sum().reset_index()\nres = dec_group.loc[dec_group['total']<25000]\nres","ca9d7926":"inp0['Decoration'].replace([res['Decoration']], 'Others', inplace=True)\ninp0['Decoration'].unique()","278fa6dd":"inp0.head()","1c654e3c":"x = inp0['Autumn'].max() - inp0['Autumn'].quantile(0.75)\nx","6935199d":"# Describe the numerical variale: \"Autumn\".\ninp0['Autumn'].describe()","4449560f":"# plot the boxplot of \"Autumn\" column.\nplt.boxplot(inp0['Summer'])\nplt.show()","1d1dc676":"# Find the maximum and 99th percentile of Winter season.\nprint(inp0['Winter'].max()) \nprint(inp0['Winter'].quantile(0.99))\n\nx = inp0['Winter'].max() - inp0['Winter'].quantile(0.99)\nx","70d357f5":"# Find the maximum and 99th percentile of Summer season.\nprint(inp0['Summer'].max()) \nprint(inp0['Summer'].quantile(0.99))\nx = inp0['Summer'].max() - inp0['Summer'].quantile(0.99)\nx","41f6f4fe":"# Find the maximum and 99th percentile of Spring season.\nprint(inp0['Spring'].max()) \nprint(inp0['Spring'].quantile(0.99))\nx = inp0['Spring'].max() - inp0['Spring'].quantile(0.99)\nx","a96e370b":"# Find the maximum and 99th percentile of Autumn season.\nprint(inp0['Autumn'].max()) \nprint(inp0['Autumn'].quantile(0.99))\n\nx = inp0['Autumn'].max() - inp0['Autumn'].quantile(0.99)\nx","f896f9a4":"# Find the Mean of Ratings for each Price category.\ninp0['Rating'].groupby(inp0['Price']).mean()","13f8e222":"# Find the median of Ratings for each Style category.\ninp0['Rating'].groupby(inp0['Style']).median()","3360d307":"inp0['Recommendation'].groupby(inp0['Season']).mean()","d7d98776":"# Size vs Recommendation.\ninp0.groupby('Size')['Recommendation'].sum()","bc934ee9":"# plot the heat map of Style, price and Recommendation.\nres = pd.pivot_table(data=inp0, index='Style', columns='Price', values='Recommendation')\nres","9fbea91c":"sns.heatmap(res, cmap='RdYlGn', annot=True)","c6c5b138":"# plot the heat map of Season, material and Recommendation.\nres = pd.pivot_table(data=inp0, index='Material', columns='Season', values='Recommendation')\nplt.figure(figsize=[10,10])\nsns.heatmap(res[['Summer','Winter']], cmap='RdYlGn', annot=True)","bb823fd8":"### Categorical Unordered Univariate Analysis\n ","27cbd330":"### Categorical categorical bivariate analysis\n","0ed2724f":"## Data Cleaning ","9ea1fa82":"### Numerical- Categorical analysis","0e141665":"In the given dataset, there are certain discrepancies with the categorical names such as irregular spellings. Choose the correct option of columns with irregular categories and update them.\n \n- Season, NeckLine\n- Price, Material\n- fabricType, Decoration\n- Season, SleeveLength\n","6ec92eb5":"Which of the following column do you think are of no use in \u201cAttribute DataSet\u201d.\n- Dress_ID\n- Price\n- Size and material\n- NeckLine\n- None of the above\n\nAns: None of the above","0b6c69ae":"### Caregorical Ordered Univariate Analysis","b848c97b":"Now let's merge inp1 with inp0 with left join manner, so that the information of inp0 should remain intact.","500da459":"You can see that there are two types of variables one with a large number of missing values and another is very less number of missing values. These two columns can be categorized as:\n\nType-1: Missing values are very less (around 2 or 3 missing values): Price, Season, NeckLine, SleeveLength, Winter and Autumn. \n\nType-2: Missing values are large in numbers (more than 15%): Material, FabricType, Decoration and Pattern Type.\n\n","5ef988f7":"## Bivariate Analysis ","8df55222":"### Data Reading & Data Types ","88793f30":"Which of the following season has the highest average value of sale for \u201cRecommendation\u201d value equals to 1.\n- Summer\n- Spring\n- Autumn\n- Winter\n\nAns: Spring","115f55ba":"Similarly Club Neckline, SLeeve length categories into \"Others\" which have less than 50000 sales across all the seasons.","4b70264c":"Club material, fabrictype, patterntype and decoration categories into \"Others\" which have less than 25000 sales across all the seasons","d31a182d":"### Impute\/Remove Missing values","428d3739":"What is the percentage of \u201ccute\u201d and \u201cOthers\u201d category in \u201cStyle\u201d column in \u201cAttribute DataSet\u201d respectively?\n- 46%, 5%\n- 9%, 2.1%\n- 2.1%, 5%\n- 13.8%, 9%\n","9606f805":"When you see the null counts in \u201cDress Sales\u201d dataset after performing all the operations that have been mentioned in jupyter notebook, you will find that there are some columns in \u201cDress Sales\u201d data where there are more than 40% of missing values. Based on your understanding of dealing with missing values do the following steps.","8b37b5a8":"Which of the following season has the highest difference between the maximum value and 99th quantile of sales?\n- Winter\n- Summer\n- Spring\n- Autumn\n\nAns: Autumn","22965ae1":"What is the approximate difference between the maximum value and 75th percentile in \u201cAutumn\u201d column.\n- Approx 54000\n- Approx 55000\n- Approx 52000\n- Approx 50000\n\nAns: 51625","2b93c949":"You are given another dataset named \u201cDress Sales\u201d. Now if you observe the datatypes of the columns using \u2018inp1.info()\u2019 command, you can identify that there are certain columns defined as object data type though they primarily consist of numeric data.\n\nNow if you try and convert these object data type columns into numeric data type(float), you will come across an error message. Try to correct this error.\n\n\n\n\n\n","9bafc70c":"You should categorise the dates into seasons in \u201cDress Sales\u201d data to simplify the analysis according to the following criteria:\n- June, July and August: Summer.\n- September, October and November: Autumn.\n- December, January and February: WInter.\n- March, April and May: Spring.\n\n\n","d60eeb5c":"### Multivariate analysis ","ec658827":"You have \u201cAttribute DataSet\u201d which contains a column named \u201cPrice\u201d. Choose the correct statement from the following about its data type and variable type.\n- Integer type and numerical variable\n- Object type and categorical ordinal variable\n- Object type and categorical nominal variable\n- Float type and categorical variable.\n\nAns: Object type and categorical ordinal variable","7fbb40f4":"As you can see, there is a column in \u201cAttribute Dataset\u201d named as \u2018Size\u2019. This column contains the values in abbreviation format. Write a code in Python to convert the followings:\n\n- M into  \u201cMedium\u201d\n- L into  \u201cLarge\u201d\n- XL into \u201cExtra large\u201d\n- free into \u201cFree\u201d\n- S, s & small into \u201cSmall\u201d.\n\nNow once you are done with changes in the dataset, what is the value of the lowest percentage, the highest percentage and the percentage of Small size categories in the column named \u201cSize\u201d?\n","7ce9d4ba":"### Numerical variable Univariate analysis:","f4536d76":"Which of the following \u201cPrice\u201d category has the lowest average value of rating?\n- very-high\n- Medium\n- Low\n- High\n\nAns: High","e6afde70":"### Standardise value ","01f9b8d5":"Which of the following is an unordered variable in \u201cAttribute DataSet\u201d.\n- Style\n- Price\n- Season\n- Size\n\nAns: Style","9e60c13f":"Which of the following pair of \u201cStyle\u201d and \u201cPrice\u201d category has the highest average of positive recommendations?\n- Price: medium and style: vintage\n- Price: medium and style: cute\n- Price: very high and style: party\n- Price: low and style: sexy\n","0a9f6b9b":"### Fixing the Rows and Columns ","ba0a7d68":"Which of the following size categories has the highest positive recommendations?\n- Medium and extra large\n- Extra large and small\n- Free and small\n- Free and medium\n\nAns: Free and Medium","ad8f6430":"Which of the following categories in \u2018Style\u2019 column can be grouped into \u2018Others\u2019 category? and perform the grouping operation in the notebook for further analysis.\n- Flare, fashion\n- Novelty, bohemian\n- OL, fashion, work\n- Novelty, fashion, Flare\n","f7f86d1b":"There is a column named \u2018Style\u2019 in \u2018Attribute Dataset\u2019 which consists of the different style categories of the women apparels. Certain categories whose total sale is less than 50000 across all the seasons is considered under one single category as \u2018Others\u2019.\n","0da6100e":"Print the null count of inp0 to get the idea about the missing values in data set.","f379c612":"Which of the following material type has no recommendation in summer and winter seasons?\n- Mix and Milksilk\n- Nylon and Rayon\n- Microfiber and Silk\n- Milksilk and Microfiber\n","46a985c3":"## Univariate Analysis ","9aa54a60":"What is the median of the rating of \u201cvintage\u201d category in Style column?\n- 4.6\n- 4.7\n- 4.55\n- 0.00\n"}}