{"cell_type":{"29677ba0":"code","4b931d53":"code","f8140cd7":"code","cc5c0a92":"code","c303a265":"code","de4c77f3":"code","8ca43156":"code","5bc11ed0":"code","f89816b5":"code","0ee5061e":"code","f10ff0b8":"code","87ee4a9d":"code","d7062f2f":"code","d0baa26b":"code","2524cb5c":"code","e814c8ff":"code","1949c420":"code","1efb3627":"code","f41f65a4":"code","27edcb73":"code","ca1c444a":"code","c991a821":"code","66c20b6d":"code","3c8bf3ff":"code","151956e8":"code","ee274bdb":"code","7d377518":"code","68e9601c":"code","12e88911":"code","1cc704a3":"code","2bcdb058":"code","455503c8":"code","3312a37a":"code","a9edffa0":"code","5181a967":"code","cc1bf880":"code","62cf9ff9":"code","2b6f1c5b":"code","cb511001":"code","00482500":"code","d18b073a":"code","06ba878c":"code","d0833b5c":"code","2a4f0d38":"code","b74540de":"code","d1b9d54c":"markdown","429577f7":"markdown"},"source":{"29677ba0":"import pandas as pd\nimport numpy as np\npd.options.mode.chained_assignment = None\npd.set_option('display.max_columns', 67)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale = 1)\n%matplotlib inline\nplt.style.use('ggplot')\n\nnp.random.seed(7)\nfrom prettytable import PrettyTable\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom IPython.core.pylabtools import figsize\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error as MSE\n\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.layers import LSTM,Dropout\nfrom keras.layers import Dense,Conv1D,MaxPooling1D\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences","4b931d53":"kickstarter = pd.read_csv('..\/input\/kickstarter-campaigns-dataset\/kickstarter_data_full.csv', index_col=0)","f8140cd7":"# The dataset have 20632 entries of 67 features.\nkickstarter.shape\nkickstarter.info()","cc5c0a92":"# looking here we can see that 'is_backing' and 'profile' contain missing values\nsns.heatmap(kickstarter.isnull())","c303a265":"# friends, is_starred, is_backing, and permissions are looking weird\nkickstarter['friends'].isnull().value_counts()\ncols_to_drop = ['friends', 'is_starred', 'is_backing', 'permissions']\nkickstarter.drop(labels=cols_to_drop, axis=1, inplace=True)\nkickstarter.drop(labels='profile', axis=1, inplace=True)","de4c77f3":"#there are a lot of unnecessary features\nsecond_col_drop = ['id', \n                   'photo', \n                   'slug', \n                   'currency_symbol',\n                   'currency_trailing_code', \n                   'creator', \n                   'location',\n                   'urls', \n                   'source_url', \n                   'name_len', \n                   'blurb_len',\n                   'create_to_launch', \n                   'launch_to_deadline', \n                   'launch_to_state_change',\n                   'USorGB', \n                   'TOPCOUNTRY', \n                   'LaunchedTuesday', \n                   'DeadlineWeekend',\n                   'deadline_month', 'deadline_day', 'deadline_yr', 'deadline_hr', \n                   'state_changed_at_month', 'state_changed_at_day', 'state_changed_at_yr', 'state_changed_at_hr',\n                   'created_at_month', 'created_at_day', 'created_at_yr', 'created_at_hr',\n                   'launched_at_month', 'launched_at_day', 'launched_at_yr', 'launched_at_hr']\n                   \nkickstarter.drop(labels=second_col_drop, axis=1, inplace=True)","8ca43156":"# we reduced dimensionality from 67 to 28\nkickstarter.shape","5bc11ed0":"kickstarter['disable_communication'] = kickstarter['disable_communication'] * 1 #converts type bool to 0 for false and 1 for true\nkickstarter['staff_pick'] = kickstarter['staff_pick'] * 1 #converts type bool to 0 for false and 1 for true\nkickstarter['spotlight'] = kickstarter['spotlight'] * 1 #converts type bool to 0 for false and 1 for true","f89816b5":"figsize(10, 5)\nsns.countplot(kickstarter['state']);\nplt.xlabel('Campaign States'); \nplt.ylabel('Count');","0ee5061e":"figsize(2, 5)\nsns.countplot(kickstarter['SuccessfulBool']);\nplt.xlabel('Campaign Only Success or Failure'); \nplt.ylabel('Count');","f10ff0b8":"print(\"Only \" \n      + str(np.round(kickstarter['SuccessfulBool'].value_counts()[1] \/ len(kickstarter) * 100, decimals=2)) \n      + \"% of campaigns were successful.\")","87ee4a9d":"# when we look at the general statistics, we see how each feature covers a very different range.\nkickstarter.describe().transpose()","d7062f2f":"# Let's take a quick look at the common distribution of a few pairs of columns.\nsns.pairplot(kickstarter[['goal','pledged','staff_pick', 'backers_count', 'spotlight','SuccessfulBool']], diag_kind='kde')","d0baa26b":"# It looks like the goal variable has a huge spread\nkickstarter['goal'].sort_values().tail()","2524cb5c":"# the pledged amount is more reasonable because this represents real money that people decided to give\nkickstarter['pledged'].sort_values().tail()","e814c8ff":"first_quartile = kickstarter['goal'].describe()['25%']\nthird_quartile = kickstarter['goal'].describe()['75%']\niqr = third_quartile - first_quartile\nkickstarter_goal_iqr = kickstarter[(kickstarter['goal'] > first_quartile) & (kickstarter['goal'] < third_quartile)]","1949c420":"kickstarter_goal_iqr.describe().transpose()","1efb3627":"figsize(5, 5)   \nplt.hist(kickstarter_goal_iqr['goal'], 10, \n                            density = 10, \n                            color ='red',\n                            edgecolor = 'black',\n                            alpha = 0.7)\n  \nplt.xlabel('Campaign Goal USD')\nplt.ylabel('Campaign Goal Distribution')  \nplt.show()","f41f65a4":"# trim backers_count, pledged and create_to_launch_days then create a new IQR dataframe with these truncated values\n\nkickstarter_iqr_trimmed = kickstarter_goal_iqr\n\nfirst_quartile = kickstarter['create_to_launch_days'].describe()['25%']\nthird_quartile = kickstarter['create_to_launch_days'].describe()['75%']\n\niqr = third_quartile - first_quartile\n\nkickstarter_iqr_trimmed = kickstarter[(kickstarter['create_to_launch_days'] > first_quartile) & (kickstarter['create_to_launch_days'] < third_quartile)]\n\nfirst_quartile = kickstarter['pledged'].describe()['25%']\nthird_quartile = kickstarter['pledged'].describe()['75%']\n\niqr = third_quartile - first_quartile\n\nkickstarter_iqr_trimmed = kickstarter[(kickstarter['pledged'] > first_quartile) & (kickstarter['pledged'] < third_quartile)]\n\nfirst_quartile = kickstarter['backers_count'].describe()['25%']\nthird_quartile = kickstarter['backers_count'].describe()['75%']\n\niqr = third_quartile - first_quartile\n\nkickstarter_iqr_trimmed = kickstarter[(kickstarter['backers_count'] > first_quartile) & (kickstarter['backers_count'] < third_quartile)]","27edcb73":"# This reduction resulted in a dataframe where there are 9308 instances,\n# with only the IQR for the variables in question remaining.\nlen(kickstarter_iqr_trimmed)","ca1c444a":"# correlations between each variable against SuccessfulBool, which remember, is a binary value where 0=failed and 1=succeeded.\nkickstarter_iqr_trimmed.corr()['SuccessfulBool'].sort_values()","c991a821":"# Looking at the correlations above we can see that nothing is too strongly correlated except spotlight, backers_count, pledged, and staff_pick\n# But really the only significant ones are backers_count and spotlight\n\nlen(kickstarter_iqr_trimmed[kickstarter_iqr_trimmed['spotlight'] == 1])","66c20b6d":"# taken together with the spotlight variable's correlation to SuccessfulBool,\n# we can conclude that all spotlighted campaigns were successful, at least in this dataset,\n# taking into account the fact that it is reduced to IQR values only\n\nlen(kickstarter_iqr_trimmed[kickstarter_iqr_trimmed['SuccessfulBool'] == 1])","3c8bf3ff":"# we are going to pool together these strongly correlated features for feature selection\nreduced_x_features = kickstarter_iqr_trimmed[['launch_to_deadline_days', 'staff_pick', 'pledged', 'backers_count', 'spotlight', 'goal']]\nreduced_y = kickstarter_iqr_trimmed[['SuccessfulBool']]","151956e8":"# # we are going to pool together these strongly correlated features for feature selection\n# reduced_x_features = kickstarter_iqr_trimmed[['launch_to_deadline_days', 'staff_pick', 'SuccessfulBool', 'backers_count', 'spotlight', 'goal']]\n# reduced_y = kickstarter_iqr_trimmed[['pledged']]","ee274bdb":"# Because of the original format of the variables, we need to take the log and sqrt transformations of them and \n# check correlation with those as well to account for non-linear relationships\n\nnumeric_subset = kickstarter_iqr_trimmed.select_dtypes('number')\n\nfor col in numeric_subset.columns:\n    if col == 'SuccessfulBool':\n        next\n    else:\n        numeric_subset['sqrt_' + col] = np.sqrt(numeric_subset[col])\n        numeric_subset['log_' + col] = np.log(numeric_subset[col])\n\ncategorical_subset = kickstarter_iqr_trimmed['category']\n\ncategorical_subset = pd.get_dummies(categorical_subset)\nfeatures = pd.concat([numeric_subset, categorical_subset], axis = 1)\nfeatures = features.dropna(subset = ['SuccessfulBool'])\n\ncorrelations = features.corr()['SuccessfulBool'].dropna().sort_values()\ncorrelations.head()","7d377518":"# we saw in the previous step that goal got a boost in correlation what you take its log,\n# so we will add log_goal into the reduced_x_features dataframe and \n# saw log_pledged show a significant boost as well, so that will be included\n\nreduced_x_features['log_goal'] = features['log_goal']\nreduced_x_features['log_pledged'] = features['log_pledged']\n#reduced_x_features.drop('pledged', axis=1, inplace=True)","68e9601c":"reduced_x_features","12e88911":"reduced_y","1cc704a3":"# Feature engineering is the process of creating new features from existing ones in a sense, \n# so when we transformed goal and pledged to log_goal and log_pledged, \n# we found that these had a stronger correlation than their original forms,\n# so these new features were added to reduced_x_feature\nfigsize(20,7)\nsns.heatmap(kickstarter_iqr_trimmed.corr(), annot=True, annot_kws={\"size\": 10}, cmap=\"Purples\")\n","2bcdb058":"kickstarter_X = []\nkickstarter_y = []\nfor i, j in reduced_x_features.iterrows():\n    tmp = str(reduced_x_features['launch_to_deadline_days'][i]) + \" \" + \\\n        str(reduced_x_features['staff_pick'][i]) + \" \" + \\\n        str(reduced_x_features['backers_count'][i]) + \" \" + \\\n        str(reduced_x_features['spotlight'][i]) + \" \" + \\\n        str(reduced_x_features['goal'][i]) + \" \" + \\\n        str(reduced_x_features['log_goal'][i]) + \" \" + \\\n        str(reduced_x_features['log_pledged'][i])  \n    kickstarter_X.append(tmp)\n    kickstarter_y.append(reduced_y['SuccessfulBool'][i])","455503c8":"# kickstarter_X = []\n# kickstarter_y = []\n# for i, j in reduced_x_features.iterrows():\n#     tmp = str(reduced_x_features['launch_to_deadline_days'][i]) + \" \" + \\\n#         str(reduced_x_features['staff_pick'][i]) + \" \" + \\\n#         str(reduced_x_features['backers_count'][i]) + \" \" + \\\n#         str(reduced_x_features['spotlight'][i]) + \" \" + \\\n#         str(reduced_x_features['goal'][i]) + \" \" + \\\n#         str(reduced_x_features['log_goal'][i]) + \" \" + \\\n#         str(reduced_x_features['log_pledged'][i])\n#     kickstarter_X.append(tmp)\n#     kickstarter_y.append(reduced_y['pledged'][i])","3312a37a":"# kickstarter_X","a9edffa0":"# kickstarter_y","5181a967":"print(len(kickstarter_X), len(kickstarter_y))","cc1bf880":"max_words = 2000\nmax_length = 30\nvector_length = 16\n\nencoded_docs = [one_hot(d, max_words) for d in kickstarter_X]\npadded_docs = pad_sequences(encoded_docs, maxlen=7, padding='post')\n\nX_train, X_test, y_train, y_test = train_test_split(padded_docs, np.array(kickstarter_y)[:, None].astype(int), test_size=0.20, random_state=1234)","62cf9ff9":"print(\"X_train\")\nX_train","2b6f1c5b":"print(\"X_test\")\nX_test","cb511001":"print(\"y_train\")\ny_train","00482500":"print(\"y_test\")\ny_test","d18b073a":"# Initialising the RNN\nmodel = Sequential()\nmodel.add(layers.Embedding(max_words+1, vector_length, input_length=max_length))\nmodel.add(Conv1D(filters=32, kernel_size=7, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\n\n# Adding the first CNN layer and Dropout layer\nmodel.add(Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)))\nmodel.add(Dropout(0.2))\n\n# Adding a second CNN layer and Dropout layer\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\n# Adding a third CNN layer and Dropout layer\nmodel.add(Dense(32, activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\n# Adding a fourth CNN layer and Dropout layer\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\n# For Full connection layer we use dense\n# As the output is 1D so we use unit=1\n# Adding the output layer\nmodel.add(Dense(1))\n# model.add(Dense(1, activation= 'linear'))\n\nprint(model.summary())\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['mse'])\n\nhistory = model.fit(X_train, y_train, \n          epochs=50, \n          verbose=1,\n          validation_data=(X_test, y_test),\n          batch_size=256)\n\nscores = model.evaluate(X_test, y_test,\n                        verbose=1,\n                        batch_size = 256)\n\ndt = RandomForestRegressor(criterion='mse',n_jobs=-1, n_estimators=10, max_depth=6, min_samples_leaf=1, random_state=3)\ndt.fit(X_train,y_train)\ny_predicted = dt.predict(X_test)\naccuracy = dt.score(X_test,y_test)\nMSE_score = MSE(y_test,y_predicted)\n\n# print the final results\nprint(\"Training Accuracy:\",(dt.score(X_train,y_train)))\nprint(\"Testing Accuracy:\",accuracy)\nprint(\"Mean Squared Error\",MSE_score.mean())","06ba878c":"table = PrettyTable(border=True, header=True, padding_width=1)\ntable.field_names = ['X', 'y (actual)', 'Predicted']\ntable.add_row([X_test[15], y_test[15], y_predicted[15]])\ntable.add_row([X_test[25], y_test[25], y_predicted[25]])\ntable.add_row([X_test[40], y_test[40], y_predicted[40]])\ntable.add_row([X_test[47], y_test[47], y_predicted[47]])\ntable.add_row([X_test[85], y_test[85], y_predicted[85]])\ntable.add_row([X_test[110], y_test[110], y_predicted[110]])\ntable.add_row([X_test[202], y_test[202], y_predicted[202]])\ntable.add_row([X_test[1848], y_test[1848], y_predicted[1848]])\ntable.add_row([X_test[1857], y_test[1857], y_predicted[1857]])\n\nprint(table)","d0833b5c":"# Initialising the RNN\nmodel = Sequential()\nmodel.add(layers.Embedding(max_words+1, vector_length, input_length=max_length))\n\n# Adding the first LSTM layer and Dropout layer\nmodel.add(LSTM(units = 128, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nmodel.add(Dropout(0.2))\n\n# Adding a second LSTM layer and Dropout layer\nmodel.add(LSTM(units = 64, return_sequences = True))\nmodel.add(Dropout(0.2))\n\n# Adding a third LSTM layer and Dropout layer\nmodel.add(LSTM(units = 32, return_sequences = True))\nmodel.add(Dropout(0.2))\n\n# Adding a fourth LSTM layer and Dropout layer\nmodel.add(LSTM(units = 16))\nmodel.add(Dropout(0.2))\n\n# For Full connection layer we use dense\n# As the output is 1D so we use unit=1\n# Adding the output layer\nmodel.add(Dense(1))\n# model.add(Dense(1, activation= 'linear'))\n\nprint(model.summary())\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['mse'])\n\nhistory = model.fit(X_train, y_train, \n          epochs=50, \n          verbose=1,\n          validation_data=(X_test, y_test),\n          batch_size=256)\n\nloss, accuracy = model.evaluate(X_train, y_train, verbose=1)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\nloss, accuracy = model.evaluate(X_test, y_test, verbose=1)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n\nscores = model.evaluate(X_test, y_test,\n                        verbose=1,\n                        batch_size = 256)\n\ndt = RandomForestRegressor(criterion='mse',n_jobs=-1, n_estimators=10,max_depth=6, min_samples_leaf=1, random_state=3)\ndt.fit(X_train,y_train)\ny_predicted = dt.predict(X_test)\naccuracy = dt.score(X_test,y_test)\nMSE_score = MSE(y_test,y_predicted)\n\n# print the final results\nprint(\"Training Accuracy:\",dt.score(X_train,y_train))\nprint(\"Testing Accuracy:\",accuracy)\nprint(\"Mean Squared Error\",MSE_score.mean())","2a4f0d38":"table = PrettyTable(border=True, header=True, padding_width=1)\ntable.field_names = ['X', 'y (actual)', 'Predicted']\ntable.add_row([X_test[15], y_test[15], y_predicted[15]])\ntable.add_row([X_test[25], y_test[25], y_predicted[25]])\ntable.add_row([X_test[40], y_test[40], y_predicted[40]])\ntable.add_row([X_test[47], y_test[47], y_predicted[47]])\ntable.add_row([X_test[85], y_test[85], y_predicted[85]])\ntable.add_row([X_test[110], y_test[110], y_predicted[110]])\ntable.add_row([X_test[202], y_test[202], y_predicted[202]])\ntable.add_row([X_test[1848], y_test[1848], y_predicted[1848]])\ntable.add_row([X_test[1857], y_test[1857], y_predicted[1857]])\n\nprint(table)","b74540de":"# table = PrettyTable(border=True, header=True, padding_width=1)\n# table.field_names = ['Model', 'Accuracy']\n# table.add_row(['CNN', '--%'])\n# table.add_row(['LSTM', \"--%\"])\n\n# print(table)","d1b9d54c":"#------------- LSTM -------------#\n","429577f7":"#------------- CNN -------------#"}}