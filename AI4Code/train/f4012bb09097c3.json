{"cell_type":{"1847e95e":"code","5b7173db":"code","426fc69b":"code","304b7996":"code","578fca77":"code","57e1b892":"code","6e2a5215":"code","a81fa7b5":"code","1d18befd":"code","4bc385d7":"code","84c4ed0f":"code","dd088198":"code","e90dd1e0":"code","df14afef":"code","d26622bc":"code","f739171b":"code","c0c7e405":"code","4a7e8b48":"code","bab03306":"code","9654fdaa":"code","8f9f248b":"code","e2f42e61":"code","c6220680":"code","4708f15c":"code","809a3041":"code","124dd618":"code","4fe8cc2b":"code","4c876a44":"code","0bdf94c2":"code","80f1bb91":"code","bb725bef":"code","d6b5d411":"code","6b50eab9":"code","48121705":"code","c58c2afb":"code","39885b2f":"markdown","53c36d04":"markdown","561d02d3":"markdown","09619179":"markdown","b4b7d8db":"markdown","d9babea3":"markdown","e61024c4":"markdown","9947b182":"markdown","23bb29b4":"markdown","ffceca89":"markdown","75040f18":"markdown","beb8c67c":"markdown","14b4bea8":"markdown","16b03cc8":"markdown","eb8733a1":"markdown","e8316c1f":"markdown","b4efd46e":"markdown","31a05e0d":"markdown","952d4a1d":"markdown","ce0d35b4":"markdown","d3f54acf":"markdown","b967b86d":"markdown","4c0d5ff0":"markdown","5ab7a243":"markdown","25df5be0":"markdown"},"source":{"1847e95e":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","5b7173db":"data = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")","426fc69b":"data.info()","304b7996":"# Drop unnecessary columns\ndata.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True)\ndata.head()","578fca77":"# Categorical data convert to numeric data\ndata[\"diagnosis\"] = [1 if item == \"M\" else 0  for item in data[\"diagnosis\"]]","57e1b892":"colors = ['#96db01','#eb81d6']\nplt.pie(data.diagnosis.value_counts(),startangle=90,explode=[0.05,0.05],autopct='%0.2f%%',\n        labels=['Benign', 'Malignant'], colors= colors,radius=2)\nplt.show()","6e2a5215":"import seaborn as sns\nf,ax = plt.subplots(figsize=(14,12))\nsns.heatmap(data.corr(), cmap=\"PiYG\", annot=True, linewidths=0.5, fmt= '.1f',ax=ax)\nplt.show()","a81fa7b5":"# Prepare Data for classification\nx = data.drop(['diagnosis'], axis = 1)\ny = data.loc[:,\"diagnosis\"].values","1d18befd":"# Columns name\ncol = x.columns","4bc385d7":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)\nx = scaler.transform(x)","84c4ed0f":"from sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import cross_val_score,cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix","dd088198":"r_forest = RandomForestClassifier(max_depth=100, random_state=0)\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nscores = cross_val_score(r_forest, x, y, scoring='accuracy', cv=cv)\nrf_score = np.mean(scores)\n\nprint('Accuracy : %.3f' % (rf_score))","e90dd1e0":"y_pred = cross_val_predict(r_forest, x, y, cv=10)\ncf_matrix = confusion_matrix(y, y_pred)","df14afef":"sns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap=\"Greens\")\nplt.show()","d26622bc":" for i in range(1,16):\n    neigh = KNeighborsClassifier(n_neighbors=i)\n    cv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\n    scores = cross_val_score(neigh, x, y, scoring='accuracy', cv=cv)\n    print('k=%d : %.3f' % (i, (np.mean(scores))))","f739171b":"neigh = KNeighborsClassifier(n_neighbors=9)\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nscores = cross_val_score(neigh, x, y, scoring='accuracy', cv=cv)\nknn_score = np.mean(scores)\n\nprint('Accuracy : %.3f' % (knn_score))","c0c7e405":"y_pred = cross_val_predict(neigh, x, y, cv=10)\ncf_matrix = confusion_matrix(y, y_pred)","4a7e8b48":"sns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap=\"PuRd\")\nplt.show()","bab03306":"from sklearn.decomposition import PCA\npca = PCA()\npca.fit(x)\npca_ = pca.transform(x)","9654fdaa":"fig, ax = plt.subplots(figsize=(14, 5))\nplt.plot(range(x.shape[1]), pca.explained_variance_ratio_.cumsum(), linestyle='--', drawstyle='steps-mid', color='#c4008f',\n         label='Cumulative Explained Variance')\nsns.barplot(np.arange(1,x.shape[1]+1), pca.explained_variance_ratio_, alpha=0.85, color='#96db01',\n            label='Individual Explained Variance')\n\nplt.ylabel('Explained Variance Ratio', fontsize = 14)\nplt.xlabel('Number of Principal Components', fontsize = 14)\nax.set_title('Explained Variance', fontsize = 20)\nplt.legend(loc='center right', fontsize = 13);","8f9f248b":"pca = PCA(2)\npca.fit(x)\npca_ = pca.transform(x)","e2f42e61":"r_forest = RandomForestClassifier(max_depth=100, random_state=0)\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nscores = cross_val_score(r_forest, pca_, y, scoring='accuracy', cv=cv)\nr_score = np.mean(scores)\n\nprint('Accuracy : %.3f' % (r_score))","c6220680":"y_pred = cross_val_predict(r_forest, pca_, y, cv=10)\ncf_matrix = confusion_matrix(y, y_pred)\nsns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap=\"Greens\")\nplt.show()","4708f15c":"neigh = KNeighborsClassifier(n_neighbors=9)\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nscores = cross_val_score(neigh, pca_, y, scoring='accuracy', cv=cv)\nknn_score = np.mean(scores)\n\nprint('Accuracy : %.3f' % (knn_score))","809a3041":"y_pred = cross_val_predict(neigh, pca_, y, cv=10)\ncf_matrix = confusion_matrix(y, y_pred)\nsns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap=\"PuRd\")\nplt.show()","124dd618":"pca = PCA(5)\npca.fit(x)\npca_ = pca.transform(x)","4fe8cc2b":"r_forest = RandomForestClassifier(max_depth=100, random_state=0)\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nscores = cross_val_score(r_forest, pca_, y, scoring='accuracy', cv=cv)\nr_score = np.mean(scores)\n\nprint('Accuracy : %.3f' % (r_score))","4c876a44":"y_pred = cross_val_predict(r_forest, pca_, y, cv=10)\ncf_matrix = confusion_matrix(y, y_pred)\nsns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap=\"Greens\")\nplt.show()","0bdf94c2":"neigh = KNeighborsClassifier(n_neighbors=9)\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nscores = cross_val_score(neigh, pca_, y, scoring='accuracy', cv=cv)\nknn_score = np.mean(scores)\n\nprint('Accuracy : %.3f' % (knn_score))","80f1bb91":"y_pred = cross_val_predict(neigh, pca_, y, cv=10)\ncf_matrix = confusion_matrix(y, y_pred)\nsns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap=\"PuRd\")\nplt.show()","bb725bef":"pca = PCA(10)\npca.fit(x)\npca_ = pca.transform(x)","d6b5d411":"r_forest = RandomForestClassifier(max_depth=100, random_state=0)\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nscores = cross_val_score(r_forest, pca_, y, scoring='accuracy', cv=cv)\nr_score = np.mean(scores)\n\nprint('Accuracy : %.3f' % (r_score))","6b50eab9":"y_pred = cross_val_predict(r_forest, pca_, y, cv=10)\ncf_matrix = confusion_matrix(y, y_pred)\nsns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap=\"Greens\")\nplt.show()","48121705":"neigh = KNeighborsClassifier(n_neighbors=9)\ncv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=1)\nscores = cross_val_score(neigh, pca_, y, scoring='accuracy', cv=cv)\nknn_score = np.mean(scores)\n\nprint('Accuracy : %.3f' % (knn_score))","c58c2afb":"y_pred = cross_val_predict(neigh, pca_, y, cv=10)\ncf_matrix = confusion_matrix(y, y_pred)\nsns.heatmap(cf_matrix, annot=True, fmt='.0f', cmap=\"PuRd\")\nplt.show()","39885b2f":"* When the classification results for rf and knn are examined, it is seen that the accuracy values are quite close.\n* When confusion matrix is examined, it is seen that Random Forest is more successful for class 1, while kNN is more successful for class 0.","53c36d04":"<a id='15'><\/a><br>\n### Classification using kNN with 10 PC","561d02d3":"<a id='12'><\/a><br>\n### Classification using Random Forest with 5 PC","09619179":"<a id='2'><\/a><br>\n### Correlation Matrix","b4b7d8db":"<a id='1'><\/a><br>\n# Load and Check Data","d9babea3":"* More successful results were obtained with kNN when the first 2 PC were used for classification. Although the results obtained with 2 components are lower than the results obtained for 30 features, they are successful for only 2 dimensions.","e61024c4":"**To validate machine learning models, 10-Fold Cross-Validation is repeated 10 times using Repeated K-Fold Cross-Validation.**\n\nRepeated k-Fold Cross-Validation: Repeated k-fold cross-validation provides a way to improve the estimated performance of a machine learning model. This involves simply repeating the cross-validation procedure multiple times and reporting the mean result across all folds from all runs.","9947b182":"<a id='7'><\/a><br>\n### Classification using kNN with Original 30 Features","23bb29b4":"Principal Component Analysis (PCA) is a multivariate technique for analyzing quantitative data. PCA turns a set of related variables into a set of unrelated variables. The purpose of PCA is to reduce dimensionality, noise and extract important information (features) from large amounts of data. PCA is one of the most widely used tools in exploratory data analysis and machine learning for predictive models.","ffceca89":"<a id='8'><\/a><br>\n# Principal Component Analysis (PCA)","75040f18":"<a id='3'><\/a><br>\n# Classifiers","beb8c67c":"<a id='14'><\/a><br>\n### Classification using Random Forest with 10 PC","14b4bea8":"* Variance should be explained in the range of %95-99 with PCA optimal number of principal components. For this dataset, the 10 principal components explain approximately %95 of the variance. kNN classifier achieved better results than Random Forest. Although more successful results are obtained with 10 components than with 2 and 5 components, the results are very close to the results obtained with 5 components.","16b03cc8":"* Results are higher than 2 components, as 5 principal components explain approximately %85 of the variance. Slightly higher results were obtained with kNN classifier than Random Forest. It can be seen that the confusion matrices obtained with 5 PCs are quite similar to the confusion matrices obtained with 30 features.","eb8733a1":"<a id='6'><\/a><br>\n### Classification using Random Forest with Original 30 Features ","e8316c1f":"# \ud83d\udccc Introduction\n\nIn this notebook, dimension reduction with Principal Component Analysis (PCA) will be performed on the breast cancer dataset consisting of 30 features. The original dataset and the reduced dimension dataset will be classified using Random Forest and k-Nearest Neighbors (kNN) algorithms. The results will be compared for a different number of components by looking at the variance ratios on the PCA.\n\n#### Content:\n    \n1. [Load and Check Data](#1)\n    * [Correlation Matrix](#2)\n    \n1. [Classifiers](#3)\n    * [Standardization](#4)\n    * [Import Libraries](#5)\n    * [Classification using Random Forest with Original 30 Features](#6)\n    * [Classification using kNN with Original 30 Features](#7)\n   \n1. [Principal Component Analysis (PCA)](#8)\n    * [PCA Components - Variance Relationship](#9)\n    * [Classification using Random Forest with 2 PC](#10)\n    * [Classification using kNN with 2 PC](#11)\n    * [Classification using Random Forest with 5 PC](#12)\n    * [Classification using kNN with 5 PC](#13)\n    * [Classification using Random Forest with 10 PC](#14)\n    * [Classification using kNN with 10 PC](#15)\n","b4efd46e":"#### **The best k parameter is 9**","31a05e0d":"<a id='11'><\/a><br>\n### Classification using kNN with 2 PC","952d4a1d":"<a id='4'><\/a><br>\n### Standardization","ce0d35b4":"* According to the graph, the first two principal components explain more than half of the variance, the five components explain approximately %85 of the variance, and the ten components explain approximately %95 of the variance.","d3f54acf":"<a id='5'><\/a><br>\n### Import Libraries","b967b86d":"<a id='9'><\/a><br>\n### PCA Components - Variance Relationship","4c0d5ff0":"### ","5ab7a243":"<a id='10'><\/a><br>\n### Classification using Random Forest with 2 PC","25df5be0":"<a id='13'><\/a><br>\n### Classification using kNN with 5 PC"}}