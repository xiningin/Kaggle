{"cell_type":{"de990dd2":"code","6138f793":"code","4eaa2f9f":"code","82720e06":"code","d8dc2b2a":"code","bee9ff59":"code","cecf4db6":"code","a5ad44c9":"code","5b739197":"code","9a2769e9":"code","f41a3b9a":"code","1941ee80":"code","0ced4615":"code","36f10cd2":"code","b23e141a":"code","05ac5814":"code","9c341e0b":"code","e7a5263f":"code","11a84349":"code","74f2f31f":"code","32634c73":"code","30fafe88":"code","5ea65b04":"code","f78c2d2d":"code","99dc431f":"code","80750089":"code","969e3ccd":"code","c93edd49":"code","c030befe":"code","daabdb98":"code","25acbf7d":"code","0ca3408c":"code","3f6343a0":"code","14e0ebc6":"code","7ad5a328":"code","14e52950":"code","d5e62b66":"code","219047dd":"code","5921d8cc":"code","cd98bd05":"code","4c4c39f9":"code","e7b4b919":"code","7b54a811":"code","3631b11f":"code","4d173f42":"code","a5841f8c":"code","c9817c24":"markdown","4b897fdd":"markdown","ef9e3e76":"markdown","0a0808aa":"markdown","7993cef6":"markdown","0e9ffa3d":"markdown","afd6ea22":"markdown"},"source":{"de990dd2":"import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","6138f793":"img_array = cv2.imread('..\/input\/mrl-dataset\/train\/Closed_Eyes\/s0001_00001_0_0_0_0_0_01.png', cv2.IMREAD_GRAYSCALE)","4eaa2f9f":"plt.imshow(img_array, cmap=\"gray\")","82720e06":"img_array.shape","d8dc2b2a":"import os","bee9ff59":"Datadirectory = '..\/input\/mrl-dataset\/train'\nClasses = ['Closed_Eyes', 'Open_Eyes']\n# Datadirectory = 'dataset_new\/train\/'\n# Classes = ['Closed', 'Open']\nfor category in Classes:\n  path = os.path.join(Datadirectory, category)\n  for img in os.listdir(path):\n    img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n    backtorgb = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)\n    plt.imshow(img_array, cmap=\"gray\")\n    plt.show()\n    break\n  break","cecf4db6":"img_size = 224\nnew_array = cv2.resize(backtorgb, (img_size,img_size))\nplt.imshow(new_array, cmap=\"gray\")\nplt.show()","a5ad44c9":"training_data = []\n\ndef create_training_data():\n  for category in Classes:\n      path = os.path.join(Datadirectory, category)\n      class_num = Classes.index(category)\n      for img in os.listdir(path):\n        try :\n           img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n           backtorgb = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)\n           new_array = cv2.resize(backtorgb, (img_size,img_size))\n           training_data.append([new_array, class_num])\n        except Exception as e:\n          pass\n   ","5b739197":"create_training_data()","9a2769e9":"print(len(training_data))","f41a3b9a":"import random\nrandom.shuffle(training_data)","1941ee80":"#here we reshape the image.\nX = []\ny = []\nfor features, label in training_data:\n  X.append(features)\n  y.append(label)\n\nX = np.array(X).reshape(-1, img_size, img_size, 3)","0ced4615":"X.shape","36f10cd2":"X = X\/255.0","b23e141a":"Y = np.array(y)","05ac5814":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","9c341e0b":"model = tf.keras.applications.mobilenet.MobileNet()","e7a5263f":"model.summary()","11a84349":"base_input = model.layers[0].input","74f2f31f":"base_output = model.layers[-4].output","32634c73":"Flat_layer = layers.Flatten()(base_output)\nfinal_output = layers.Dense(1)(Flat_layer)\nfinal_output = layers.Activation('sigmoid')(final_output)","30fafe88":"new_model = keras.Model(inputs = base_input, outputs = final_output)","5ea65b04":"new_model.summary()","f78c2d2d":"new_model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])","99dc431f":"new_model.fit(X,Y, epochs = 2, validation_split = 0.1)\n#Note: Increase the number of epoch to get more appropriate result, accuracy.","80750089":"new_model.save('my_model.h5')","969e3ccd":"new_model = tf.keras.models.load_model('my_model.h5')","c93edd49":"img_array = cv2.imread('..\/input\/mrl-dataset\/train\/Closed_Eyes\/s0001_00004_0_0_0_0_0_01.png',cv2.IMREAD_GRAYSCALE)\nbacktorgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)\nnew_array = cv2.resize(backtorgb, (img_size, img_size))","c030befe":"X_input = np.array(new_array).reshape(1, img_size, img_size, 3)","daabdb98":"X_input.shape","25acbf7d":"plt.imshow(new_array)","0ca3408c":"X_input = X_input\/255.0","3f6343a0":"prediction = new_model.predict(X_input)","14e0ebc6":"prediction","7ad5a328":"img = cv2.imread('..\/input\/test-eyes\/open men.jpg')","14e52950":"plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))","d5e62b66":"faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\neyeCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')","219047dd":"gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)","5921d8cc":"eyes = eyeCascade.detectMultiScale(gray, 1.1, 4)","cd98bd05":"for (x, y, w, h) in eyes:\n  cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 1)","4c4c39f9":"plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","e7b4b919":"eyeCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\neyes = eyeCascade.detectMultiScale(gray, 1.1, 4)\nfor x, y,w, h in eyes:\n  roi_gray = gray[y:y+h, x:x+w]\n  roi_color = img[y:y+h, x:x+w]\n  eyess = eyeCascade.detectMultiScale(roi_gray)\n  if len(eyess) == 0:\n    print(\"eyes not detected\")\n  else:\n    for ex, ey, ew, eh in eyess :\n      eyes_roi = roi_color[ey:ey+eh, ex:ex+ew]","7b54a811":"plt.imshow(cv2.cvtColor(eyes_roi, cv2.COLOR_BGR2RGB))","3631b11f":"eyes_roi.shape","4d173f42":"final_img = cv2.resize(eyes_roi, (224,224))\nfinal_img = np.expand_dims(final_img, axis=0)\nfinal_img = final_img\/255.0","a5841f8c":"new_model.predict(final_img)","c9817c24":"# Open or Close Eye Detection\n\nWe can use this code for predecting if the eye if closed or open and also it can be used for mainly Driver Drowsiness Detection.\n\n**Please Upvote if you like my work.**","4b897fdd":"# Test whether the eye is closed or open\n\nAs the value ranges from 0 to 1, we the eye is detected as closed, then  the value will be nearer to zero. \nAnd if the eye is detected as open then it will be near to 1.","ef9e3e76":"Read the images","0a0808aa":"Since the eye is closed, we got the prediction value nearer to 0, i.e. 0.0000000008970.","7993cef6":"# Download Mobilenet Model\n\nSince i am using transfer learning to get appropriate result, i download the pre-trained mobilenet model.","0e9ffa3d":"Since the eye is open, we got the prediction value as 1.","afd6ea22":"# Import Libs"}}