{"cell_type":{"dc458c8b":"code","7473a576":"code","e3f9ead7":"code","08d0b127":"code","0cc031c5":"code","a1fb3bb4":"code","9fc5cd52":"code","f2fbde0f":"code","a52501a5":"code","f777580d":"code","8bcd8a1a":"code","415a1faa":"code","79f2359b":"code","264bc8d5":"code","a7dd4b09":"code","f6386979":"code","6587972b":"code","3876f908":"code","3fa6f908":"code","6d19fca7":"code","b8059732":"code","4a5ff81d":"code","9e7325fb":"code","102d00c6":"code","945cd751":"code","7fbaf553":"code","2a950ea7":"code","a99e5496":"code","2f4293f4":"code","8c6cc034":"code","81edc9e8":"code","5f97a481":"code","5d506105":"code","25fa94cf":"code","6c11981f":"code","a5b78897":"code","80480f51":"code","4af850f6":"code","0e1e94b1":"code","aa03fbf9":"code","a6649f82":"code","a129d23b":"code","838d851c":"code","3999cc83":"code","c5c7cc8a":"code","0fd4e450":"code","4e2379d7":"markdown","c0f32278":"markdown","b4571241":"markdown","5ccb5f9e":"markdown","ac087a1f":"markdown","a0410356":"markdown","f587853a":"markdown","fa61b258":"markdown","475922ac":"markdown","786f1832":"markdown","ac7f86f9":"markdown","db138164":"markdown","06cafbb7":"markdown","0cc1d919":"markdown","6a24430e":"markdown","65ae7d5f":"markdown","247a74fa":"markdown","2de8322e":"markdown","1facb2ce":"markdown","6961c08c":"markdown","78977002":"markdown","64d3026a":"markdown","303ee8c3":"markdown","a26d264b":"markdown","eca83a12":"markdown","3260fcea":"markdown","211eb961":"markdown","814408f3":"markdown","e360c3f5":"markdown","98f36c66":"markdown","2e611a93":"markdown","53ab5089":"markdown","e2948e7f":"markdown","8e89ec33":"markdown","4a2bf0ab":"markdown","430b0a47":"markdown","d864609c":"markdown","a35704d2":"markdown","18be0d70":"markdown","e0468f82":"markdown"},"source":{"dc458c8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\nimport matplotlib.pyplot as plt\n#plt.style.use('ggplot')\nfrom matplotlib.pyplot import figure\nfrom scipy import stats\nimport glob\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7473a576":"districts = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\nproducts = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")","e3f9ead7":"# Checking number of rows and columns and the first five rows of both dataframes\nprint('DISTRICTS - Rows and Columns:',districts.shape)\ndisplay(districts.head(3))\nprint('\\nPRODUCTS - Rows and Columns:',products.shape)\ndisplay(products.head(3))","08d0b127":"# Putting all csv.files of the 'engagement-data' into one dataframe\n# Then checking the number of rows and columns and the first rows of the dataframe\npath = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nall_files = glob.glob(path + \"\/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\n    \nengagement = pd.concat(li)\nengagement = engagement.reset_index(drop=True)\nprint('ENGAGEMENT DATA - Rows and Columns:', engagement.shape)\nengagement.head(3)","0cc031c5":"# Looking at colum names, data types and first overview of missing data \nprint('DISTRICTS:\\n')\ndisplay(districts.info())\nprint('\\n\\nPRODUCTS:\\n')\ndisplay(products.info())\nprint('\\n\\nENGAGEMENT:\\n')\ndisplay(engagement.info())","a1fb3bb4":"print('DISTRICTS:')\ndisplay(districts.describe(include = 'all'))\nprint('PRODUCTS:')\ndisplay(products.describe(include = 'all'))\nprint('ENGAGEMENT:')\ndisplay(engagement.describe(include = 'all'))","9fc5cd52":"products.columns = products.columns.str.lower()\nlist(products)","f2fbde0f":"products.rename(columns={'lp id':'lp_id','product name':'product_name', 'provider\/company name':'company_name','sector(s)': 'sectors', 'primary essential function':'function'}, inplace=True)\nlist(products)","a52501a5":"districts.rename(columns={'pct_black\/hispanic':'pct_black_hispanic','pct_free\/reduced':'pct_free_reduced'}, inplace=True)\nlist(districts)","f777580d":"# Identifying duplicate values \nprint('DUPLICATES\\nDistricts:\\t',districts.duplicated().sum(),'\\nProducts:\\t', products.duplicated().sum(),'\\nEngagement:\\t', engagement.duplicated().sum())","8bcd8a1a":"# Finding the amount of missing values in each column\nprint('\\nMISSING VALUES IN PRODUCTS:')\nprint(products.isnull().sum().sort_values(ascending = False))\nprint('\\nMISSING VALUES IN DISTRICTS:')\nprint(districts.isnull().sum().sort_values(ascending = False))\nprint('\\nMISSING VALUES IN ENGAGEMENT:')\nprint(engagement.isnull().sum().sort_values(ascending = False))","415a1faa":"print('\\nPERCENTAGE OF MISSING VALUES IN PRODUCTS:')\nfor col in products.columns:\n    missing_products = np.mean(products[col].isnull())\n    print('{}:  {:.2f}%'.format(col, missing_products*100))\n\nprint('\\nPERCENTAGE OF MISSING VALUES IN DISTRICTS:')\nfor col in districts.columns:\n    missing_districts = np.mean(districts[col].isnull())\n    print('{}:  {:.2f}%'.format(col, missing_districts*100))\n\nprint('\\nPERCENTAGE OF MISSING VALUES IN ENGAGEMENT:')\nfor col in engagement.columns:\n    missing_engagement = np.mean(engagement[col].isnull())\n    print('{}:  {:.2f}%'.format(col, missing_engagement*100))","79f2359b":"# Deleting rows of missing values in 'products' dataframe, as these twoe cannot be reproduced\nproducts.dropna(subset=[\"function\", \"sectors\"], axis=0, inplace=True)\nproducts.reset_index(inplace=True, drop=True)\nproducts.isnull().sum()","264bc8d5":"# Deleting the column 'url'\nproducts.drop(\"url\", axis=1, inplace=True)\nlist(products)","a7dd4b09":"# Rows of missing values in 'state'\ndistricts[districts.state.isnull()][:10]","f6386979":"# Deleting rows of missing values in 'districts' dataframe, as missing values in 'state' are useless for the EDA\ndistricts.dropna(subset=[\"state\", \"pp_total_raw\", \"pct_free_reduced\"], axis=0, inplace=True)\ndistricts.reset_index(inplace=True, drop=True)\ndistricts.isnull().sum().sort_values(ascending=False)","6587972b":"# Checking the unique values of 'county_connections_ratio' in order to decide how to replace the missing values\ndistricts.groupby('county_connections_ratio').sum()","3876f908":"# Deleting the column\ndistricts.drop(\"county_connections_ratio\", axis=1, inplace=True)\ndistricts.head(3)","3fa6f908":"engagement.isnull().sum().sort_values(ascending=False)","6d19fca7":"# Rows of missing values in 'pct_acess'\nengagement[engagement.pct_access.isnull()][:10]","b8059732":"# Deleting rows of missing values in these columns\nengagement.dropna(subset=[\"engagement_index\", \"lp_id\"], axis=0, inplace=True)\nengagement.isnull().sum()","4a5ff81d":"# splitting the columns 'function' to separate the 'function_category' from the subcategory\n# in two separate coluns. \nnew = products[\"function\"].str.split(\"-\", n = 1, expand = True)\nproducts[\"function_cat\"]= new[0]\nproducts[\"function_sub\"]= new[1]\nproducts.drop(columns =[\"function\"], inplace = True)\nproducts.head(3)","9e7325fb":"products.sectors.value_counts()","102d00c6":"def myfunc(prek_12_sectors):\n    if prek_12_sectors == 'PreK-12':\n        prek_12_sectors = 1\n    elif prek_12_sectors ==  'PreK-12; Higher Ed; Corporate':\n        prek_12_sectors = 1\n    elif prek_12_sectors == 'PreK-12; Higher Ed':\n        prek_12_sectors = 1\n    else:\n        prek_12_sectors = 0\n    return prek_12_sectors\n\nproducts['prek_12'] = products.apply(lambda x: myfunc(x['sectors']), axis=1)\n\n\ndef myfunc(higher_ed):\n    if higher_ed == 'PreK-12; Higher Ed; Corporate':\n        higher_ed = 1\n    elif higher_ed == 'PreK-12; Higher Ed':\n        higher_ed = 1\n    elif higher_ed == 'Higher Ed; Corporate':\n        higher_ed = 1\n    else:\n        higher_ed = 0\n    return higher_ed\n\nproducts['higher_ed'] = products.apply(lambda x: myfunc(x['sectors']), axis=1)\n\n\ndef myfunc(corporate):\n    if corporate == 'PreK-12; Higher Ed; Corporate':\n        corporate = 1\n    elif corporate == 'Higher Ed; Corporate':\n        corporate = 1\n    elif corporate == 'Corporate':\n        corporate = 1\n    else:\n        corporate = 0\n    return corporate\n\nproducts['corporate'] = products.apply(lambda x: myfunc(x['sectors']), axis=1)\n\nproducts.head()","945cd751":"# Replacing the first and last character in cells of the column\ndistricts['pct_black_hispanic'] = districts['pct_black_hispanic'].map(lambda x: str(x)[1:-1])\ndistricts['pct_free_reduced'] = districts['pct_free_reduced'].map(lambda x: str(x)[1:-1])\ndistricts['pp_total_raw'] = districts['pp_total_raw'].map(lambda x: str(x)[1:-1])\n\n# new data frame with split value columns\ntotal_raw = districts[\"pp_total_raw\"].str.split(\",\", n = 1, expand = True)\nblack_hispanic = districts[\"pct_black_hispanic\"].str.split(\",\", n = 1, expand = True)\nfree_reduced = districts[\"pct_free_reduced\"].str.split(\",\", n = 1, expand = True)\n  \n# making columns\ndistricts[\"total_raw_min\"]= total_raw[0]\ndistricts[\"total_raw_max\"]= total_raw[1]\n# changing data types\ndistricts[\"total_raw_min\"] = pd.to_numeric(districts[\"total_raw_min\"])\ndistricts[\"total_raw_max\"] = pd.to_numeric(districts[\"total_raw_max\"])\n# Makin column with average\nsum_total_raw = districts.total_raw_min + districts.total_raw_max\ndistricts['avg_total_raw'] = (sum_total_raw \/ 2).astype(int)\n\n# making columns\ndistricts[\"black_hispanic_min\"] = black_hispanic[0]\ndistricts[\"black_hispanic_max\"] = black_hispanic[1]\n# changing data types\ndistricts[\"black_hispanic_min\"] = pd.to_numeric(districts[\"black_hispanic_min\"]) * 100\ndistricts[\"black_hispanic_max\"] = pd.to_numeric(districts[\"black_hispanic_max\"]) * 100\n# Makin column with average\nsum_black_hispanic = districts.black_hispanic_min + districts.black_hispanic_max\ndistricts['avg_black_hispanic'] = (sum_black_hispanic \/ 2) \n\n# making columns\ndistricts[\"free_reduced_min\"] = free_reduced[0]\ndistricts[\"free_reduced_max\"] = free_reduced[1]  \n# changing data types\ndistricts[\"free_reduced_min\"] = pd.to_numeric(districts[\"free_reduced_min\"]) * 100\ndistricts[\"free_reduced_max\"] = pd.to_numeric(districts[\"free_reduced_max\"]) * 100\n# Makin column with average\nsum_free_reduced = districts.free_reduced_min + districts.free_reduced_max\ndistricts['avg_free_reduced'] = (sum_free_reduced \/ 2)\n\ndistricts.drop(columns =[\"pp_total_raw\", \"pct_black_hispanic\", \"pct_free_reduced\"], inplace = True)\ndistricts.head(3)","7fbaf553":"# Changing data type from 'object' to 'int64'\nengagement[\"district_id\"] = pd.to_numeric(engagement[\"district_id\"])","2a950ea7":"# Merging dataframes 'district' and 'engagement' on 'district_id'\ndistricts_engagement = pd.merge(districts, engagement, on='district_id', how='left')\ndistricts_engagement.head(3)","a99e5496":"# Merging dataframe 'products' and 'districts_engagement' on 'lp_id' to the new dataframe\ndf = pd.merge(products, districts_engagement, on='lp_id', how='left')\ndf.head(10)","2f4293f4":"# Checking if there are any missing values\ndf.isnull().sum()","8c6cc034":"# Deleting the rows in which have no values for 'district_id'\ndf.dropna(subset=[\"district_id\"], axis=0, inplace=True)\ndf.reset_index(inplace=True, drop=True)\ndf.isnull().sum()","81edc9e8":"df.head()","5f97a481":"# Creating dataframe for correalation\ndf_corr = df[['prek_12', 'higher_ed', 'corporate', 'avg_total_raw', 'avg_black_hispanic', 'avg_free_reduced', 'pct_access', 'engagement_index']]\n# Visualisation of the corralation table\ncorrelation = df_corr.corr()\nplt.figure(figsize=(14,7))\nsns.heatmap(correlation, linecolor='white',linewidths=0.1, annot=True)\nplt.title('Correlation Matrix', pad=11, size=17)\nplt.xlabel('Digital Learning Data')\nplt.ylabel('Digital Learning Data')\nplt.show()","5d506105":"# Showing the highest correlations in descending order\ncorrelations = correlation\ncorr_pairs = correlations.unstack()\nsorted_pairs = corr_pairs.sort_values(kind=\"quicksort\", ascending=False).where(corr_pairs < 1.0)\npairs = sorted_pairs[abs(sorted_pairs) >= 0.1]\nprint(pairs)","25fa94cf":"plt.figure(figsize=(12,10))\nsns.countplot(y='state', data=df, order = df['state'].value_counts().index)\nplt.title('States and Frequency in Dataset', size=16)\nplt.show()","6c11981f":"plt.figure(figsize=(9,7))\nsns.countplot(x='locale', data=df, order = df['locale'].value_counts().index)\nplt.title('NCES Locale Classification Frequency in Dataset', size=16)\nplt.show()","a5b78897":"suburb = (df['locale'] == 'Suburb').sum()\nrural = (df['locale'] == 'Rural').sum()\ncity = (df['locale'] == 'City').sum()\ntown = (df['locale'] == 'Town').sum()\nproportions_locale = [suburb, rural, city, town]\n\n\nplt.figure(figsize=(8,8))\nplt.pie(proportions_locale, data=df, labels=['Suburb', 'Rural', 'City', 'Town'], startangle=90, autopct='%1.1f%%', shadow=False, explode=(0.03, 0.0, 0, 0))\nplt.axis('equal')\nplt.title(\"'NCES' Locale Classification Proportion\", size=17)\nplt.show()\n","80480f51":"plt.figure(figsize=(12,10))\nsns.countplot(y='avg_total_raw', data=df)\nplt.title('Expenditure per student and frequency in Dataset', size=17, pad=11)\nplt.show()","4af850f6":"plt.figure(figsize=(12,10))\nsns.countplot(x='avg_black_hispanic', data=df)\nplt.title('Frequency of mean Percentage of black\/hispanic pupils in Dataset', size=16)\nplt.xlabel('Average Percentage of black\/hispanic pupils')\nplt.show()","0e1e94b1":"plt.figure(figsize=(21,10))\nsns.countplot(x='avg_total_raw', hue='locale',data=df)\nplt.title('DISTRIBUTION OF TOTAL MEAN EXPENDITURE PER STUDENT AND AREA (%)', size=16)\nplt.xlabel('Total mean exendature per pupil')\nplt.legend(loc='upper right')\nplt.show()","aa03fbf9":"# Visualisation of the software's 'function_category' and it's amount of usage\nplt.figure(figsize=(9,7))\nsns.countplot(x='function_cat', data=df)\nplt.title('Main Software Functions and Frequency in Dataset', size=16)\nplt.xlabel('Software Function Category')\nplt.show()\n","a6649f82":"plt.figure(figsize=(12,10))\nsns.countplot(y='function_sub', data=df, order = df['function_sub'].value_counts().index[0:10])\nplt.title('Top 10 - Software sub-category and Frequency in Dataset', size=19, pad=13)\nplt.ylabel('Software function sub-category')\nplt.yticks(size=15)\nplt.xticks(size=13)\nplt.show()","a129d23b":"plt.figure(figsize=(9,7))\nsns.countplot(x='function_cat', hue='sectors', data=df, order = df['function_cat'].value_counts().index)\nplt.title('Software Function Category within the Sectors', size=16)\nplt.ylabel('count')\nplt.xlabel('sectors')\nplt.legend(loc='upper right')\nplt.show()","838d851c":"products_companies = df.groupby('company_name').count()[['product_name']].sort_values(by='product_name', ascending=False)\nproducts_companies.head(10)","3999cc83":"plt.figure(figsize=(12,10))\nsns.countplot(y='company_name', data=df, order = df['company_name'].value_counts().index[0:10])\nplt.title('Frequency of Company Name in Dataset - Top 10', size=17, pad=11)\nplt.show()","c5c7cc8a":"plt.figure(figsize=(20,10))\nsns.countplot(x='sectors', hue='avg_total_raw', data=df, order = df['sectors'].value_counts().index)\nplt.title('Total expenditure per pupil and Education Sector', size=19, pad=13)\nplt.ylabel('Count', size=15)\nplt.yticks(size=13)\nplt.xlabel('Sectors', size=15)\nplt.xticks(size=13)\nplt.legend(loc='upper right')\nplt.show()","0fd4e450":"fig, ax= plt.subplots(1, 2, figsize=(20,7))\n\nsns.countplot(y='state',hue='avg_black_hispanic', data=df, ax=ax[0])\nax[0].set_title('Percentages of black \/ hispanic pupils', size=17, pad=17)\nax[0].set_ylabel('', size=13, labelpad=11)\nax[0].set_xlabel('count', size=13)\nax[0].legend(loc='lower right', title='Percentages:')\n\n\nsns.countplot(y='state', hue='avg_free_reduced',data=df, ax=ax[1])\nax[1].set_title('Percentages of pupils with free \/ reduced lunch', size=17, pad=17)\nax[1].set_ylabel('', size=13, labelpad=11)\nax[1].set_xlabel('count', size=13)\nax[1].legend(loc='lower right', title='Percentages:')\n\nplt.xlim()\nplt.show()","4e2379d7":"***\n### PRODUCTS\n***","c0f32278":"# 4.2 Cleaning Data","b4571241":"## 5.1 Correlation","5ccb5f9e":"## 4.2.2 Missing Values","ac087a1f":"## 5.2 Analysing Patterns using Visualisations ","a0410356":"#### After cleaning the data, there is only one unique value for 'county_connections_ratio'. The missing data could be replaced by it. But as there are no other values in the corresponding column, there is no need to include this column to the analysis. That's why I decided to delete it.","f587853a":"### 4.2.2.1 Identifying Missing Values","fa61b258":"# 1. INTRODUCTION","475922ac":"#### There are still missing values in `url` - but this column ist not relevant for the analysis.","786f1832":"***\n#### PRODUCTS\n***\n\n","ac7f86f9":"#### In order to fully analyse the data I decideded to merge the dataframes on the unique identifiers `district_id` and `lp_id`. Before doing so the data types of these columns have to be changed if they are not identic.","db138164":"## 4.2.3 Simplification and Splitting columns","06cafbb7":"### TOTAL RAW","0cc1d919":"As the values in the `engagement_index` and in the unique identifier `lp_id` are important for the EDA I decided to delete the corresponding rows with missing values.","6a24430e":"### 4.2.2.2 Handling Missing Values","65ae7d5f":"Questions:\n   - What is the picture of digital connectivity and engagement in 2020?\n   - What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n   - How does student engagement with different types of education technology change over the course of the pandemic?\n   - How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n   - Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?","247a74fa":"### LOCALE","2de8322e":"# 2. IMPORTING LIBRARIES","1facb2ce":"***\n#### DISTRICTS\n***","6961c08c":"# 3. LOADING AND VIEWING DATA","78977002":"#### No duplicate values in the dataframes.","64d3026a":"### COMPANY NAME","303ee8c3":"#### Getting a rough overview of the data by visualizing individual columns and looking for correlations and causations.","a26d264b":"# 1.3 Data Description\n\n- **`engagement_data`** - 235 csv files based on LearnPlatform\u2019s Student Chrome Extension. The extension collects page load events of over 10K education technology products in our product library, including websites, apps, web apps, software programs, extensions, ebooks, hardwares, and services used in educational institutions. Each file represents data from one school district. The 4-digit file name represents `district_id`\n    - `time`: date in \"YYYY-MM-DD\"\n    - `lp_id`: The unique identifier of the product\n    - `pct_access`: Percentage of students in the district have at least one page-load event of a given product and on a given day\n    - `engagement_index`: Total page-load events per one thousand students of a given product and on a given day\n    \n    \n- **`districts_info.csv`** - information about the characteristics of school districts, including data from NCES and FCC\n    - `district_id`: unique identifier of the school district\n    - `state`: The state where the district resides in\n    - `locale`: NCES locale classification that categorizes U.S. territory into four types of areas: **City, Suburban, Town, and Rural**.\n    - `pct_black\/hispanic`: Percentage of students in the districts identified as Black or Hispanic\n    - `pct_free\/reduced`: Percentage of students in the districts eligible for free or reduced-price lunch \n    - `county_connections_ratio`: ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households)\n    - `pp_total_raw`: Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD) project. The expenditure data are school-by-school. The median value is used to represent the expenditure of a given school district.\n    \n\n- **`products_info.csv`** - information about the characteristics of the top 372 products with most users in 2020\n\n    - `LP ID`: The unique identifier of the product\n    - `URL`: Web Link to the specific product\n    - `Product Name`: Name of the specific product\n    - `Provider\/Company Name`: Name of the product provider\n    - `Sector(s)`: Sector of education where the product is used\n    - `Primary Essential Function`: The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories followed by sub-categories: \n        - LC = Learning & Curriculum\n        - CM = Classroom Management\n        - SDO = School & District Operations","eca83a12":"#### The majority of software category used can be found in the category 'Learning & Curriculum'","3260fcea":"***\n### DISTRICTS\n***","211eb961":"***\n#### ENGAGEMENT\n***","814408f3":"# 1.2 Challenge\n\n**(1) Exploring the state of digital learning in 2020**\n\n**(2) Exploring how the engagement of digital learning relates to factors such as district demographics, broadband access, and state\/national level policies and events**","e360c3f5":"### BLACK \/ HISPANIC","98f36c66":"# 5. Exploratory Data Analysis (EDA)","2e611a93":"# COVID-19 Impact on Digital Learning\n#### Analyzing the impact of COVID-19 on student learning\n---","53ab5089":"<img src = \"https:\/\/image.freepik.com\/vektoren-kostenlos\/online-bildungsinfografiken-mit-bearbeitbarer-textillustration_1284-57254.jpg\" width='100%'>","e2948e7f":"## 4.2.1 Duplicate Values","8e89ec33":"\n### STATE\n\n","4a2bf0ab":"#### As the data in the columns `pct_black_hispanic`, `pct_free_reduced` and `pp_total_raw` are not easily readable or self explaining I change the format.","430b0a47":"# 4.1 Standardization\n#### Unifying the column names by renaming them in order make all of them both lowercase and to work with shorter names.","d864609c":"# 4.3 Merging Dataframes","a35704d2":"#### Where does the data come from? Which state provided the most data?","18be0d70":"# 4. DATA WRANGLING","e0468f82":"# 1.1 Problem Statement\n\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow."}}