{"cell_type":{"ff952720":"code","077b7b7e":"code","c0392e96":"code","bbfa0879":"code","8b9a528e":"code","c0593755":"code","c8fc5d1c":"code","a90a98fc":"code","4ac83f10":"code","3ef1c752":"code","44bcf93e":"code","841671c4":"code","288be56a":"code","c57ad961":"code","d1759f24":"code","51f9f620":"code","f4b43c69":"code","3821c4bb":"code","57d581b4":"code","dc65acfb":"code","03bf8546":"code","9b7205c6":"code","dab7f3b0":"code","5221ce1d":"code","a772d967":"code","6f17b7a9":"code","27c65069":"code","a8f87d6a":"code","6fe36974":"code","92f7a3e2":"code","1368436d":"code","4d4c8aab":"code","3d5e124a":"code","917010a4":"code","8c1a2ecb":"code","af1743cb":"code","4a3fd044":"markdown","c920193a":"markdown","866c364c":"markdown","3409a2ed":"markdown","c908b70b":"markdown","4ade765b":"markdown","e162b895":"markdown","83358215":"markdown","f87f269a":"markdown","e662104c":"markdown","9decbb0b":"markdown","d9e77e06":"markdown","9ee69516":"markdown","6c4c4eea":"markdown","58a56903":"markdown","eed6f14d":"markdown","ea23805e":"markdown","9eedf646":"markdown"},"source":{"ff952720":"%matplotlib inline\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom torch import autograd\nimport torch.nn.functional as F\nfrom torchvision.datasets import ImageFolder\n\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nimport os\n\nimport matplotlib.pyplot as plt","077b7b7e":"DATA_DIR = '..\/input\/dogs-cats-images\/dataset'\nTRAIN_DIR = DATA_DIR + \"\/training_set\"\nTEST_DIR = DATA_DIR + \"\/test_set\"\n","c0392e96":"classes = os.listdir(TRAIN_DIR)\nprint(classes)","bbfa0879":"cats = os.listdir(TRAIN_DIR + \"\/cats\")\nprint('No. of training examples for cats:', len(cats))\nprint(cats[:5])","8b9a528e":"dogs = os.listdir(TRAIN_DIR + \"\/dogs\")\nprint('No. of training examples for dogs:', len(dogs))\nprint(dogs[:5])","c0593755":"cats = os.listdir(TEST_DIR + \"\/cats\")\nprint('No. of testing examples for cats:', len(cats))\nprint(cats[:5])","c8fc5d1c":"cats = os.listdir(TEST_DIR + \"\/dogs\")\nprint('No. of testing examples for dogs:', len(dogs))\nprint(dogs[:5])","a90a98fc":"from torchvision.datasets import ImageFolder","4ac83f10":"transform = transforms.Compose([transforms.Resize((100,100)),transforms.ToTensor()])\ndataset = ImageFolder(DATA_DIR+'\/training_set', transform=transform)\ntest_dataset = ImageFolder(DATA_DIR+'\/test_set', transform=transform)\n","3ef1c752":"img, label = dataset[0]\nprint(img.shape, label)\nimg","44bcf93e":"print(dataset.classes)","841671c4":"import matplotlib.pyplot as plt\n\ndef show_example(img, label):\n    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0))","288be56a":"show_example(*dataset[0])","c57ad961":"show_example(*dataset[4800])","d1759f24":"random_seed = 42\ntorch.manual_seed(random_seed);","51f9f620":"len(dataset)","f4b43c69":"val_size = 2000\ntrain_size = len(dataset) - val_size\n\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","3821c4bb":"batch_size=64\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)","57d581b4":"def show_batch(dl, invert=False):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        data = 1-images if invert else images\n        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n        break","dc65acfb":"show_batch(train_loader)","03bf8546":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","9b7205c6":"class ImageClassificationModelBase(nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                      \n        loss = F.cross_entropy(out, targets)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        loss = F.cross_entropy(out, targets)  # Calculate loss\n        acc = accuracy(out, targets)\n        return {'val_loss': loss.detach(), 'val_acc': acc }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_acc = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch,result['train_loss'], result['val_loss'], result['val_acc']))","dab7f3b0":"class ImageClassificationModel(ImageClassificationModelBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1), #output 32 X 100 X 100 | (Receptive Field (RF) -  3 X 3\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),   #output 64 X 100 X 100 | RF 5 X 5\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 50 x 50 | RF 10 X 10\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # output: 64 x 50 x 50 | RF 12 X 12\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 25 x 25  | RF 24 X 24\n            \n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  # output: 256 x 25 x 25  | RF 26 X 26\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 12 x 12 | RF 52 X 52\n            \n            nn.Conv2d(256, 512, kernel_size=3, stride=1), #512* 10* 10 | RF 54 X 54\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 512 x 5 x 5 | RF - 108X 108\n            \n#             nn.Conv2d(512, 1024, kernel_size=3, stride=1),#1024 X 3 X 3 | Rf - 110 X 110\n#             nn.ReLU(),\n#             nn.MaxPool2d(2, 2), # output: 1024 x 4 x 4\n            \n#             nn.Conv2d(1024, 2048, kernel_size=3, stride=1), # output: 2048 x 2 x 2\n\n\n            nn.Flatten(),\n            nn.Linear(512 * 5 * 5,10))\n#             nn.Linear(1024 * 3 * 3, 10))\n         \n    def forward(self, xb):\n        return self.network(xb)","5221ce1d":"#function to ensure that our code uses the GPU if available, and defaults to using the CPU if it isn't.\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \n# a function that can move data and model to a chosen device.    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n\n#Finally, we define a DeviceDataLoader class to wrap our existing data loaders and move data to the selected device, \n#as a batches are accessed. Interestingly, we don't need to extend an existing class to create a PyTorch dataloader. \n#All we need is an __iter__ method to retrieve batches of data, and an __len__ method to get the number of batches.\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","a772d967":"device = get_default_device()\ndevice","6f17b7a9":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)","27c65069":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","a8f87d6a":"model = to_device(ImageClassificationModel(), device)\n","6fe36974":"\n!pip install torchsummary","92f7a3e2":"from torchsummary import summary\n# print the summary of the model\nsummary(model, input_size=(3, 100, 100), batch_size=-1)","1368436d":"history = [evaluate(model, val_loader)]\nhistory","4d4c8aab":"num_epochs = 20\nopt_func = torch.optim.Adam\nlr = 0.001\nhistory = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)","3d5e124a":"def plot_scores(history):\n#     scores = [x['val_score'] for x in history]\n    acc = [x['val_acc'] for x in history]\n    plt.plot(acc, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('acc')\n    plt.title('acc vs. No. of epochs');","917010a4":"plot_scores(history)\n","8c1a2ecb":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","af1743cb":"plot_losses(history)\n","4a3fd044":"### Loss Function\nWhile the accuracy is a great way for us (humans) to evaluate the model, it can't be used as a loss function for optimizing our model using gradient descent, for the following reasons:\n\nIt's not a differentiable function. torch.max and == are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n\nIt doesn't take into account the actual probabilities predicted by the model, so it can't provide sufficient feedback for incremental improvements.\n\nDue to these reasons, accuracy is a great evaluation metric for classification, but not a good loss function. A commonly used loss function for classification problems is the cross entropy,\n\n### How Cross Entropy works\nFor each output row, pick the predicted probability for the correct label. E.g. if the predicted probabilities for an image are [0.1, 0.3, 0.2, ...] and the correct label is 1, we pick the corresponding element 0.3 and ignore the rest.\n\nThen, take the logarithm of the picked probability. If the probability is high i.e. close to 1, then its logarithm is a very small negative value, close to 0. And if the probability is low (close to 0), then the logarithm is a very large negative value. We also multiply the result by -1, which results is a large postive value of the loss for poor predictions.\n\nFinally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data.\n\nUnlike accuracy, cross-entropy is a continuous and differentiable function that also provides good feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). This makes it a good choice for the loss function.\n\nPyTorch provides an efficient and tensor-friendly implementation of cross entropy as part of the torch.nn.functional package. Moreover, it also performs softmax internally, so we can directly pass in the outputs of the model without converting them into probabilities.","c920193a":"We can look at batches of images from the dataset using the make_grid method from torchvision. Each time the following code is run, we get a different bach, since the sampler shuffles the indices before creating batches.","866c364c":"Here we are using torch.max() function, this function's default behaviour as you can guess by the name is to return maximum among the elements in the Tensor. However, this function also helps get the maximum along a particular dimension, as a Tensor, instead of a single element. To specify the dimension (axis \u2013 in numpy), there is another optional keyword argument, called dim. This represents the direction that we take for the maximum.\n\nmax_elements, max_indices = torch.max(input_tensor, dim)\n\n- dim=0, (maximum along columns).\n- dim=1 (maximum along rows).\n\nThis returns a tuple, max_elements and max_indices.\n\n- max_elements -> All the maximum elements of the Tensor.\n- max_indices -> Indices corresponding to the maximum elements.\n\nIn the above accuracy function, the == performs an element-wise comparison of two tensors with the same shape, and returns a tensor of the same shape, containing 0s for unequal elements, and 1s for equal elements. Passing the result to torch.sum returns the number of labels that were predicted correctly. Finally, we divide by the total number of images to get the accuracy.","3409a2ed":"As a internal functionality, the list of classes is stored in the .classes property of the dataset. The numeric label for each element corresponds to index of the element's label in the list of classes.","c908b70b":"We can now wrap our data loaders using DeviceDataLoader.","4ade765b":"### DataLoader\nWe can now created data loaders to help us load the data in batches. Large datasets requires loading them into memory all at once. This leads to memory outage and slowing down of programs. PyTorch offers a solution for parallelizing the data loading process with the support of automatic batching as well. This is the DataLoader class present within the torch.utils.data package.\n\nWe'll use a batch size of 64, we will load 64 samples at a time until all the 50000 images in the training set are loaded and trained to complete 1 epoch.\n\n### What is batch size?\nThe number of samples (data points) that would be passed through the network at a time.\n\n### What is epoch?\nAn epoch is one single pass of all the input data through the network.\n\n### Relation between batch_size and epoch?\nbatch_size is not equal to epoch, consider you have 1000 images. Processing all the 1000 images through the network once is considered as 1 epoch. If we set the batch size as 10, during training we will be passing 100 data points (=1000\/10) at a time until we eventually pass in all the training data to complete 1 single epoch.\n\nGenerally, larger the batch size faster the training. However, you need to have enough hardware to handle. Sometimes, even if our machine can handle heavy computation,by setting larger batch size quality of the model could degrade and could create difficulty in generalizing.","e162b895":"Let's look at a sample element from the training dataset. Each element is a tuple, containing a image tensor and a label. Since the data consists of color images with 3 channels (RGB)","83358215":"Since the data consists of color images with 3 channels (RGB), each image tensor has the shape of varying size.So we are resizing the image to have same shape (200,200)","f87f269a":"### Using a GPU\nAs the sizes of our models and datasets increase, we need to use GPUs to train our models within a reasonable amount of time. GPUs contain hundreds of cores that are optimized for performing expensive matrix operations on floating point numbers in a short time, which makes them ideal for training deep neural networks with many layers.\n","e662104c":"### Import Libraries","9decbb0b":"### Training the Model","d9e77e06":"We can view the image using matplotlib, but we need to change the tensor dimensions to (200,200,3). Notice, for matplotlib the channel should be specified in the third position. Let's create a helper function to display an image and its label.","9ee69516":"The above directory structure (one folder per class) is used by many computer vision datasets, and most deep learning libraries provide utilites for working with such datasets. We can use the ImageFolder class from torchvision to load the data as PyTorch tensors.","6c4c4eea":"Let's look inside folders, training set and from the test set. ","58a56903":"### Model","eed6f14d":"### Training and Validation Datasets\nWhile building real world machine learning models, it is quite common to split the dataset into 3 parts:\n\n- Training set - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n- Validation set - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n- Test set - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model. \nSince there's no predefined validation set, we can set aside a small portion of the training set to be used as the validation set. We'll use the random_split helper method from PyTorch to do this. To ensure that we always create the same validation set, we'll also set a seed for the random number generator","ea23805e":"### Evaluation Metric and Loss Function\nLet's first define out evaluation metric, we need a way to evaluate how well our model is performing. A natural way to do this would be to find the percentage of labels that were predicted correctly i.e. the accuracy of the prediction","9eedf646":"Before we train the model, we need to ensure that the data and the model's parameters (weights and biases) are on the same device (CPU or GPU). We can reuse the to_device function to move the model's parameters to the right device."}}