{"cell_type":{"f5c8b154":"code","64968bde":"code","b8c0023b":"code","83da2442":"code","ab8ea1f2":"code","1ef539b2":"code","9b5ec534":"code","5c85a7a4":"code","2b20b1fa":"code","73ae356b":"code","23a01785":"code","f50bf1f0":"code","f975d54f":"code","03822cf6":"code","08fe7490":"code","6b31a2a2":"code","d0829081":"code","f0ae3ec5":"code","b511e000":"code","20c2ff53":"code","e64681b7":"code","feab0212":"code","06ee8873":"code","292d12c2":"markdown","88959e4e":"markdown","a2d769b6":"markdown","cc4c5694":"markdown","c9edca94":"markdown","d3d7a9a1":"markdown","49371caf":"markdown","f371463e":"markdown","520ab39e":"markdown"},"source":{"f5c8b154":"import os\nGPU_id = 0\nos.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)","64968bde":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport time\nimport math\nfrom tqdm import tqdm\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom torch import nn,optim\nimport torch.nn.functional as F\n\n%matplotlib inline","b8c0023b":"USE_GPU = torch.cuda.is_available()\nif USE_GPU:\n    print('Use GPU')\nelse:\n    print('Use CPU')","83da2442":"def show_mnist_batch(sample_batched):\n    \"\"\"Show image for a batch of samples.\"\"\"\n    images_batch, labels_batch = \\\n            sample_batched['image'], sample_batched['label']\n\n    grid = utils.make_grid(images_batch)\n    plt.imshow(grid.numpy().transpose((1, 2, 0)))","ab8ea1f2":"def cross_entropy(y,yp):\n    # y is the ground truch\n    # yp is the prediction\n    yp[yp>0.99999] = 0.99999\n    yp[yp<1e-5] = 1e-5\n    return np.mean(-np.log(yp[range(yp.shape[0]),y.astype(int)]))\n\ndef accuracy(y,yp):\n    return (y==np.argmax(yp,axis=1)).mean()\n\ndef softmax(score):\n    score = np.asarray(score, dtype=float)\n    score = np.exp(score-np.max(score))\n    score = score\/(np.sum(score, axis=1).reshape([score.shape[0],1]))#[:,np.newaxis]\n    return score","1ef539b2":"class MnistDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, df, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.df = df\n        self.transform = transform\n        if 'label' in df.columns:\n            self.labels = df['label'].values\n            self.images = df.drop('label',axis=1).values\n        else:\n            self.labels = np.zeros(df.shape[0])\n            self.images = df.values\n        self.images = (self.images\/255.0).astype(np.float32).reshape(df.shape[0],28,28)\n        \n    \n    def head(self):\n        return self.df.head()\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        label = np.array(self.labels[idx])\n        image = self.images[idx]\n        sample = {'image': image, 'label': label}\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample","9b5ec534":"class ToTensor(object):\n    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n\n    def __call__(self, sample):\n        image, label = sample['image'], sample['label']\n        # torch image: [C, H, W]\n        return {'image': torch.from_numpy(image).unsqueeze(0),\n                'label': torch.from_numpy(label)}","5c85a7a4":"class Logistic_Model(nn.Module):\n    def __init__(self,num_fea,num_class):\n        super().__init__()\n        #nn.Linear(input_dim, output_dim)\n        self.lin = nn.Linear(num_fea,num_class)\n\n    def forward(self, xb):\n        B = xb.size()[0]\n        if len(xb.size())>2:\n            xb = xb.view(B,-1) # 4D tensor of B,C,H,W -> 2D tensor B,CxHxW\n        return self.lin(xb)","2b20b1fa":"class Learner(object):\n    \n    def __init__(self,model,**params): \n        self.model = model\n        if USE_GPU:\n            self.model.cuda()\n        self.params = params\n        \n    def predict(self,test_dl):\n        yps = []\n        for batch in tqdm(test_dl):\n            xb, yb = batch['image'],batch['label']\n            if USE_GPU:\n                xb, yb = xb.cuda(),yb.cuda()\n            pred = self.model(xb)\n            if USE_GPU:\n                yps.append(pred.cpu().detach().numpy())\n            else:\n                yps.append(pred.detach().numpy())\n        yps = np.vstack(yps)\n        yps = softmax(yps)\n        return yps\n        \n    def fit(self,train_dl,valid_dl=None,\n            epochs=10,lr=0.001,wd=0.1):\n        opt_type = self.params.get('opt','SGD')\n        if opt_type == 'SGD':\n            opt = optim.SGD(self.model.parameters(), lr=lr)\n        for epoch in range(epochs):\n            train_loss = 0\n            for batch in tqdm(train_dl):\n                xb, yb = batch['image'],batch['label']\n                if USE_GPU:\n                    xb, yb = xb.cuda(),yb.cuda()\n                pred = self.model(xb)\n                loss = F.cross_entropy(pred, yb)\n                if USE_GPU:\n                    train_loss += loss.cpu().detach().numpy()\n                else:\n                    train_loss += loss.detach().numpy()\n                loss.backward()\n                opt.step()\n                opt.zero_grad()\n            if valid_dl is None:\n                print('Epoch %d Training Loss:%.4f'%(epoch,\n                            train_loss\/len(train_dl)))\n                continue\n            yps = []\n            yrs = []\n            for batch in tqdm(valid_dl):\n                xb, yb = batch['image'],batch['label']\n                if USE_GPU:\n                    xb, yb = xb.cuda(),yb.cuda()\n                pred = self.model(xb)\n                if USE_GPU:\n                    yps.append(pred.cpu().detach().numpy())\n                    yrs.append(yb.cpu().detach().numpy())\n                else:\n                    yps.append(pred.detach().numpy())\n                    yrs.append(yb.detach().numpy())\n            yps = np.vstack(yps)\n            yps = softmax(yps)\n            yrs = np.concatenate(yrs)\n            ce = cross_entropy(yrs,yps)\n            acc = accuracy(yrs,yps)\n            print('Epoch %d Training Loss:%.4f Valid ACC: %.4f Cross Entropy:%4f'%(epoch,\n                            train_loss\/len(train_dl),acc,ce))","73ae356b":"%%time\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nprint(train_df.shape, test_df.shape)","23a01785":"train_df.head()","f50bf1f0":"%%time\n\nval_pct = 0.2 # use 20% train data as local validation\nis_valid = np.random.rand(train_df.shape[0])<val_pct\ntrain_df, valid_df = train_df.loc[~is_valid], train_df.loc[is_valid]\nprint(train_df.shape, valid_df.shape)","f975d54f":"%%time\ntrain_dataset = MnistDataset(df=train_df,\n                            transform=transforms.Compose([\n                                               ToTensor()\n                                           ]))\nvalid_dataset = MnistDataset(df=valid_df,\n                            transform=transforms.Compose([\n                                               ToTensor()\n                                           ]))\ntest_dataset = MnistDataset(df=test_df,\n                            transform=transforms.Compose([\n                                               ToTensor()\n                                           ]))","03822cf6":"fig = plt.figure(figsize=(20,8))\n\nfor i in range(len(train_dataset)):\n    sample = train_dataset[i]\n\n    print(i, sample['image'].shape)\n\n    ax = plt.subplot(1, 4, i + 1)\n    plt.tight_layout()\n    ax.set_title('Sample #{} Label {}'.format(i,sample['label']), fontsize=30)\n    ax.axis('off')\n    plt.imshow(sample['image'].numpy()[0],cmap='gray')\n\n    if i == 3:\n        plt.show()\n        break","08fe7490":"%%time\n\nbatch_size = 128\ncpu_workers = 8\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n                        shuffle=True, num_workers=cpu_workers,\n                        drop_last=True)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size,\n                        shuffle=False, num_workers=cpu_workers,\n                        drop_last=False)\n\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n                        shuffle=False, num_workers=cpu_workers,\n                        drop_last=False)","6b31a2a2":"for i_batch, sample_batched in enumerate(train_dataloader):\n    print(i_batch, sample_batched['image'].size(),\n          sample_batched['label'].size())\n\n    plt.figure(figsize=(10,10))\n    show_mnist_batch(sample_batched)\n    plt.axis('off')\n    plt.ioff()\n    plt.show()\n    break","d0829081":"model = Logistic_Model(num_fea=test_df.shape[1],num_class=10)\nlearn = Learner(model)","f0ae3ec5":"%%time\nlearn.fit(train_dl=train_dataloader,\n          valid_dl=valid_dataloader,\n          epochs=10)","b511e000":"%%time\nyp = learn.predict(valid_dataloader)","20c2ff53":"%%time\nacc = accuracy(valid_df.label.values,yp)\nce = cross_entropy(valid_df.label.values,yp)\nprint('Valid ACC: %.4f Cross Entropy:%4f'%(acc,ce))","e64681b7":"%%time\nyp = learn.predict(test_dataloader)","feab0212":"sub = pd.DataFrame()\nsub['ImageId'] = np.arange(yp.shape[0])+1\nsub['Label'] = np.argmax(yp,axis=1)\nsub.head()","06ee8873":"from datetime import datetime\nclock = \"{}\".format(datetime.now()).replace(' ','-').replace(':','-').split('.')[0]\nout = 'pytorch_%s_acc_%.4f_ce_%.4f.csv'%(clock,acc,ce)\nprint(out)\nsub.to_csv(out,index=False)","292d12c2":"### Illustrate the first batch","88959e4e":"## Function and class definitions","a2d769b6":"## Training","cc4c5694":"### Predict and write submission","c9edca94":"### A model is a subclass of nn.Module which defines a computing graph","d3d7a9a1":"### A learner has functions fit() and predict(), like the sklearn model","49371caf":"### Read csv","f371463e":"## Inspect datasets","520ab39e":"### Data loader generates batch of samples with multi-thread functions."}}