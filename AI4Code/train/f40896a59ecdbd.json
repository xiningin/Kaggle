{"cell_type":{"825a3171":"code","0bb6c214":"code","3487afd2":"code","2241f328":"code","f791da0a":"code","9ab553d3":"code","90a8dc44":"code","12768b74":"code","c01c28bd":"code","43fd39fc":"code","2e8a94de":"code","f5e276e4":"code","db342dd9":"code","035fa3cb":"code","02475d05":"code","e49306a6":"code","2acab355":"code","325ef570":"code","75ed022e":"code","88db90a4":"code","cdcedc3b":"code","3a0af4c4":"code","3b3d1ca8":"code","fa620ecd":"code","fd819eed":"code","64fd5a44":"code","1c6b6f46":"code","866e4816":"code","276a5a84":"code","a9a28a5c":"code","2540fe3b":"code","09eb46f8":"code","257e08dd":"code","9f1c4427":"code","fd1a7e94":"code","293c193c":"code","010cced3":"code","46a80d0b":"code","5be1e9f2":"code","83d5b45e":"code","893e4d5a":"code","66a4734b":"code","ff15368f":"code","4fc75f18":"code","8b44b09b":"code","59922f40":"code","79a3b685":"code","2297d8d4":"code","9450eafc":"code","9716b36a":"code","bd6202ef":"code","e7bba074":"code","2a606707":"code","5d911a47":"markdown","32a7c1d9":"markdown","d63c4bf8":"markdown","2e0b6765":"markdown","ba2cae52":"markdown","1d74685a":"markdown","01f3401f":"markdown","07191653":"markdown","7f767786":"markdown","2e97c973":"markdown","de060116":"markdown","1c58ae27":"markdown","3cfdc82d":"markdown","a0ace975":"markdown","7743961b":"markdown","1be38ba0":"markdown","cee5b413":"markdown","06dfb915":"markdown","0287e238":"markdown","d18714ea":"markdown","47028d22":"markdown","9d750471":"markdown","e9113866":"markdown","86b291fb":"markdown","4ca763ef":"markdown","091b92ec":"markdown","c7eae6db":"markdown","862d6f6c":"markdown","bf1ffd4f":"markdown","48491407":"markdown","ee9320cf":"markdown","b17a7216":"markdown","1d0188fc":"markdown","3f59bf92":"markdown","24b4f480":"markdown","ca5c8359":"markdown","5abab652":"markdown","e3afcc6a":"markdown","bd371ef4":"markdown","dfada380":"markdown","0a1c15b0":"markdown","4817f804":"markdown","5f2bbe3e":"markdown","8f5dea12":"markdown","34116351":"markdown","8cc401c8":"markdown","cd71d50c":"markdown","eae12483":"markdown","3ca1dcdc":"markdown","97608a00":"markdown","0890b010":"markdown","3dacaa2d":"markdown","ac971da6":"markdown","6b0286b7":"markdown","39cd150c":"markdown","d5490944":"markdown","c5bbd0ff":"markdown","0fec749e":"markdown","f23855c7":"markdown","e53b6821":"markdown","b6256391":"markdown","f1e171d2":"markdown","3b62febc":"markdown","621576c3":"markdown","82a03ed0":"markdown","6f175548":"markdown","acf59eb0":"markdown","bcf68adf":"markdown","9b5cee67":"markdown","d90f8a3b":"markdown","2b91a572":"markdown","a27c81d7":"markdown","7e56843b":"markdown","8674f518":"markdown","0798ab24":"markdown","20e58a82":"markdown","14e8a02f":"markdown"},"source":{"825a3171":"# Import Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm\n","0bb6c214":"# Load data\n\nlabels = \"..\/input\/gene-expression\/actual.csv\"\ntest_path = \"..\/input\/gene-expression\/data_set_ALL_AML_independent.csv\"\ntrain_path = \"..\/input\/gene-expression\/data_set_ALL_AML_train.csv\"\n\n# replace labels with numbers\nlabels_df = pd.read_csv(labels, index_col = 'patient')\n\nX_test = pd.read_csv(test_path)\nX_train = pd.read_csv(train_path)","3487afd2":"# extract only call columns, in order to process them and potentially use them as features\nds_test = [col for col in X_test.columns if 'call' in col]\nX_test_call = X_test[ds_test]\n\n# drop call columns from X_test\nX_test.drop(ds_test, axis = 1, inplace = True)\n\n# extract only call columns, in order to process them and potentially use them as features\nds_train = [col for col in X_train.columns if 'call' in col]\nX_train_call = X_train[ds_train]\n\n# drop call columns from X_test\nX_train.drop(ds_train, axis = 1, inplace = True)","2241f328":"# check whether the manipulation above did what was intended\nX_train_call.head()\nX_test_call.head()","f791da0a":"# transform the string categories into numbers\nX_train_call = X_train_call.replace(\"A\", 0)\nX_train_call = X_train_call.replace(\"P\", 1)\nX_train_call = X_train_call.replace(\"M\", 2)\n\nX_test_call = X_test_call.replace(\"A\", 0)\nX_test_call = X_test_call.replace(\"P\", 1)\nX_test_call = X_test_call.replace(\"M\", 2)","9ab553d3":"# add rownames which include the \"Gene Accession number\" + \"Call\"\nrownames = \"Call \" + X_train.iloc[:,1]\nX_train_call.index = rownames\nX_test_call.index = rownames\n\n# extract ids for patients\nids_train = list(X_train.columns[2:])\nids_test = list(X_test.columns[2:])\n\nX_train_call.columns = ids_train\nX_test_call.columns = ids_test","90a8dc44":"# transpose the \"call\" features matrices and prepare them for merging with the rest of the features\nX_train_call = X_train_call.T\nX_train_call.head()\n\nX_test_call = X_test_call.T\nX_test_call.head()","12768b74":"# turn ids from strings to integers\ntrain_ids = X_train_call.index\ntrain_ids = list(map(int, train_ids))\n\ntest_ids = X_test_call.index\ntest_ids = list(map(int, test_ids))\n\ntrain_labels = []\ntest_labels = []\n\nfor i in train_ids:\n  train_labels.append(labels_df.iloc[i-1,0])\n\nfor j in test_ids:\n  test_labels.append(labels_df.iloc[j-1,0])\n\n\ntrain_labels = pd.concat([pd.DataFrame(train_ids), pd.DataFrame(train_labels)], axis=1, ignore_index = False)\ntrain_labels.columns = [\"patient\", \"cancer\"]\n\ntest_labels = pd.concat([pd.DataFrame(test_ids), pd.DataFrame(test_labels)], axis=1, ignore_index = False)\ntest_labels.columns = [\"patient\", \"cancer\"]\n\n# extract only the labels in the y variables\n\ny_train = train_labels.iloc[:,1]\ny_test = test_labels.iloc[:,1]\n\n# replace ALL labels with 0 and AML labels with 1\n\ny_train = y_train.replace(\"ALL\", 0)\ny_train = y_train.replace(\"AML\", 1)\ny_train = list(y_train)\n\n\ny_test = y_test.replace(\"ALL\", 0)\ny_test = y_test.replace(\"AML\", 1)\ny_test = list(y_test)\n\n","c01c28bd":"# processing the numerical features of the train and test sets\ngene_names = X_train.iloc[:,1]\nX_train = X_train.iloc[:,2:]\nX_train = X_train.T\nX_train.columns = gene_names\nX_train.index = train_ids\n\nX_test = X_test.iloc[:,2:]\nX_test = X_test.T\nX_test.columns = gene_names\nX_test.index = test_ids\nX_test.head()\n","43fd39fc":"# check numbers of samples in both conditions (ALL and AML), to see if they are balanced\n#sns.set_theme(style=\"darkgrid\")\nax = sns.countplot(x=\"cancer\", data=train_labels, order = [\"ALL\", \"AML\"]).set_title(\"Train set Classes Count\")","2e8a94de":"#sns.set_theme(style=\"darkgrid\")\nax = sns.countplot(x=\"cancer\", data=test_labels, order = [\"ALL\", \"AML\"]).set_title(\"Test set Classes Count\")","f5e276e4":"# Normalize each feature\nscaler = MinMaxScaler()\n\n# scale only the numerical features\nscaler.fit(X_train)\nX_train= scaler.transform(X_train)\nX_train = pd.DataFrame(X_train)\nX_train.columns = gene_names\nX_train.index = train_ids\nX_train.head()","db342dd9":"n_components = 30\npca = PCA(n_components = n_components)\nX_train_pca = pca.fit_transform(X_train)\nX_train_pca = pd.DataFrame(X_train_pca)\nX_train_pca.head()","035fa3cb":"X_train_pca.reset_index(drop = True, inplace = True)\nX_train_pca.columns =['PC'+str(i) for i in range(1,n_components+1)]\nprint(\"Percent of explained variance with {n_components} Components : \", round(pca.explained_variance_ratio_.sum()*100,2))\n","02475d05":"# Normalize test set and reduce dimensions through PCA\n\n# Normalize\n\nscaler.fit(X_test)\nX_test = scaler.transform(X_test)\nX_test = pd.DataFrame(X_test)\nX_test.columns = gene_names\nX_test.index = test_ids\n\n# PCA Transform\nX_test_pca = pca.transform(X_test)\n\n# generate the matrix with BOTH numerical and categorical features\nX_test_pca = pd.DataFrame(X_test_pca)\nX_test_pca.reset_index(drop=True, inplace=True)\nX_test_pca.columns =['PC'+str(i) for i in range(1,n_components+1)]\nX_test_pca.head()","e49306a6":"# Set the parameters by cross-validation\ntuned_parameters = [{'kernel': ['linear'], 'C': [1e-1, 1, 10, 100, 1000]},\n                    {'kernel': ['poly'], 'C': [1e-1, 1, 10, 100, 1000]},\n                    {'kernel': ['sigmoid'], 'C': [1e-1, 1, 10, 100, 1000]},\n                    {'kernel': ['rbf'], 'gamma': [1e-4, 1e-2, 1, 5, 10],\n                     'C': [1e-1, 1, 10, 100, 1000]},]\n\nscoring = {'f1_macro': make_scorer(f1_score, average='macro')}\nclf = GridSearchCV(svm.SVC(), tuned_parameters, scoring = scoring, refit = 'f1_macro')\nclf.fit(X_train_pca, y_train)\nprint(\"Best parameters set through GridSearchCV\")\nprint()\nprint(clf.best_params_)\n","2acab355":"# Instantiating Best Model\nclf = svm.SVC(kernel='linear', C = 0.1)\nclf.fit(X_train_pca, y_train)","325ef570":"# Generate predictions for test samples\ny_pred = clf.predict(X_test_pca)\n","75ed022e":"# Calculate model performance metrics on test set\n\nprint(\"Macro F1-Score\")\nprint(f1_score(y_test, y_pred, average = \"macro\"))\nprint()\nprint(\"F1-score for each label:\")\nprint()\nprint(\" ALL       AML\")\n\nprint(f1_score(y_test, y_pred, average = None))\n","88db90a4":"# generate vectors will all 1s (i.e AML) or all 0s (i.e ALL)\naml = [1] * len(y_pred)\nall = [0] * len(y_pred)","cdcedc3b":"# macro score of only-ALL macro F1-score\nprint(\"Macro F1-Score of only-ALL predictions\")\nprint(f1_score(y_test, all, average = \"macro\"))\nprint()\nprint(\"F1-score for each label\")\nprint()\nprint(\" ALL       AML\")\nprint(f1_score(y_test, all, average = None))","3a0af4c4":"print(\"Macro F1-Score of only-ALL predictions\")\nprint(f1_score(y_test, aml, average = \"macro\"))\nprint()\nprint(\"F1-score for each label\")\nprint()\nprint(\" ALL       AML\")\nprint(f1_score(y_test, aml, average = None))","3b3d1ca8":"pip install scikit-optimize","fa620ecd":"import skopt \nfrom skopt import BayesSearchCV\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n\nparameters = {'n_estimators': skopt.space.Integer(0,100),\n        'min_num_child': skopt.space.Integer(0, 50,),\n        'max_depth': skopt.space.Integer(0, 10),\n        'subsample': skopt.space.Real(0.5, 1.0),\n        'colsample_bytree': skopt.space.Real(0.5, 1.0),\n        'reg_lambda': skopt.space.Real(1e-10,100,'log-uniform'),\n        'reg_alpha': skopt.space.Real(1e-10,100,'log-uniform'),\n        'learning-rate': skopt.space.Real(0.01,0.2,'log-uniform'),\n        }\n\nbayes = BayesSearchCV(xgb.XGBClassifier(), search_spaces= parameters, n_iter=10, scoring='f1_macro',cv=5,random_state=0)\nres = bayes.fit(X_train_pca, y_train)\nprint(res.best_params_)","fd819eed":"final_params={'objective': 'binary:logistic', 'n_estimators': 24, 'colsample_bytree': 0.7643458710377254, 'learning-rate': 0.011893969796789843,'max_depth': 3, 'min_num_child': 10, 'reg_alpha': 1.2750414511557992e-06, 'reg_lambda': 0.005068685293864641 , 'subsample': 0.7042865059246077,}\ndtrain = xgb.DMatrix(X_train_pca, y_train)\nmodel_xgb = xgb.train(final_params,dtrain=dtrain)","64fd5a44":"dtest = xgb.DMatrix(X_test_pca, y_test)\ny_pred = model_xgb.predict(dtest)\n# turn the probabilities into labels\ny_pred[y_pred >= 0.5] = 1\ny_pred[y_pred < 0.5] = 0","1c6b6f46":"print(\"Macro F1-Score\")\nprint(f1_score(y_test, y_pred, average = \"macro\"))\nprint()\nprint(\"F1-score for each label\")\nprint()\nprint(\" ALL       AML\")\nprint(f1_score(y_test, y_pred, average = None))\n","866e4816":"# extract the categorical variables, which correspond to the top 10 differentially expressed genes between the two classes\nX_train_de = X_train_call[[\"Call U50136_rna1_at\", \"Call X95735_at\", \"Call M55150_at\", \"Call M16038_at\", \"Call Y12670_at\", \"Call M23197_at\", \"Call X17042_at\", \"Call U82759_at\", \"Call D49950_at\", \"Call M84526_at\"]]\nX_test_de = X_test_call[[\"Call U50136_rna1_at\", \"Call X95735_at\", \"Call M55150_at\", \"Call M16038_at\", \"Call Y12670_at\", \"Call M23197_at\", \"Call X17042_at\", \"Call U82759_at\", \"Call D49950_at\", \"Call M84526_at\"]]\nX_train_de.reset_index(drop = True, inplace = True)\nX_test_de.reset_index(drop = True, inplace = True)\n","276a5a84":"# add the \"de\" categorical variables to the numerical variables \nX_train_all = pd.concat([X_train_pca, X_train_de], axis=1, sort=False)\nX_test_all = pd.concat([X_test_pca, X_test_de], axis=1, sort=False)\n","a9a28a5c":"X_train_all.head()","2540fe3b":"# Set the parameters by cross-validation\ntuned_parameters = [{'kernel': ['linear'], 'C': [1e-1, 1, 10, 100, 1000]},\n                    {'kernel': ['poly'], 'C': [1e-1, 1, 10, 100, 1000]},\n                    {'kernel': ['sigmoid'], 'C': [1e-1, 1, 10, 100, 1000]},\n                    {'kernel': ['rbf'], 'gamma': [1e-4, 1e-2, 1, 5, 10],\n                     'C': [1e-1, 1, 10, 100, 1000]},]\n\nscoring = {'f1_macro': make_scorer(f1_score, average='macro')}\nclf = GridSearchCV(svm.SVC(), tuned_parameters, scoring = scoring, refit = 'f1_macro')\nclf.fit(X_train_all, y_train)\nprint(\"Best parameters set through GridSearchCV\")\nprint()\nprint(clf.best_params_)","09eb46f8":"# Instantiating Best Model\nclf = svm.SVC(kernel='linear', C = 0.1)\nclf.fit(X_train_all, y_train)","257e08dd":"# Generate predictions for test samples\ny_pred = clf.predict(X_test_all)\n","9f1c4427":"# Calculate model performance metrics on test set\n\nprint(\"Macro F1-Score\")\nprint(f1_score(y_test, y_pred, average = \"macro\"))\nprint()\nprint(\"F1-score for each label\")\nprint()\nprint(\" ALL       AML\")\nprint(f1_score(y_test, y_pred, average = None))\n\n","fd1a7e94":"import skopt \nfrom skopt import BayesSearchCV\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n\nparameters = {'n_estimators': skopt.space.Integer(0,100),\n        'min_num_child': skopt.space.Integer(0, 50,),\n        'max_depth': skopt.space.Integer(0, 10),\n        'subsample': skopt.space.Real(0.5, 1.0),\n        'colsample_bytree': skopt.space.Real(0.5, 1.0),\n        'reg_lambda': skopt.space.Real(1e-10,100,'log-uniform'),\n        'reg_alpha': skopt.space.Real(1e-10,100,'log-uniform'),\n        'learning-rate': skopt.space.Real(0.01,0.2,'log-uniform'),\n        }\n\nbayes = BayesSearchCV(xgb.XGBClassifier(objective = 'binary:logistic'), search_spaces= parameters, n_iter=10, scoring='f1_macro',cv=5,random_state=0)\nres = bayes.fit(X_train_all,y_train)\nprint(res.best_params_)","293c193c":"final_params={'objective': 'binary:logistic', 'n_estimators': 18, 'colsample_bytree': 0.6162570141151325, 'learning-rate': 0.020729429554412183,'max_depth': 7, 'min_num_child': 14, 'reg_alpha': 1.1046982314481511e-07, 'reg_lambda': 1.551926920387429e-10 , 'subsample': 0.5148603857041089}\ndtrain = xgb.DMatrix(X_train_all, y_train)\nmodel_xgb_pca_num_cat_de = xgb.train(final_params, dtrain = dtrain)\n","010cced3":"dtest = xgb.DMatrix(X_test_all, y_test)\ny_pred = model_xgb_pca_num_cat_de.predict(dtest)\n# turn the probabilities into labels\ny_pred[y_pred >= 0.5] = 1\ny_pred[y_pred < 0.5] = 0","46a80d0b":"print(\"Macro F1-Score\")\nprint(f1_score(y_test, y_pred, average = \"macro\"))\nprint()\nprint(\"F1-score for each label\")\nprint()\nprint(\" ALL       AML\")\nprint(f1_score(y_test, y_pred, average = None))\n","5be1e9f2":"# extract the numerical variables, which correspond to the top 10 differentially expressed genes between the two classes\nX_train_num_de = X_train[[\"U50136_rna1_at\", \"X95735_at\", \"M55150_at\", \"M16038_at\", \"Y12670_at\", \"M23197_at\", \"X17042_at\", \"U82759_at\", \"D49950_at\", \"M84526_at\"]]\nX_test_num_de = X_test[[\"U50136_rna1_at\", \"X95735_at\", \"M55150_at\", \"M16038_at\", \"Y12670_at\", \"M23197_at\", \"X17042_at\", \"U82759_at\", \"D49950_at\", \"M84526_at\"]]\nX_train_num_de.reset_index(drop = True, inplace = True)\nX_test_num_de.reset_index(drop = True, inplace = True)\n\n","83d5b45e":"# add the \"de\" categorical variables to the numerical variables \nX_train_all_de = pd.concat([X_train_num_de, X_train_de], axis=1, sort=False)\nX_test_all_de = pd.concat([X_test_num_de, X_test_de], axis=1, sort=False)\n","893e4d5a":"import skopt \nfrom skopt import BayesSearchCV\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n\nparameters = {'n_estimators': skopt.space.Integer(0,100),\n        'min_num_child': skopt.space.Integer(0, 50,),\n        'max_depth': skopt.space.Integer(0, 10),\n        'subsample': skopt.space.Real(0.5, 1.0),\n        'colsample_bytree': skopt.space.Real(0.5, 1.0),\n        'reg_lambda': skopt.space.Real(1e-10,100,'log-uniform'),\n        'reg_alpha': skopt.space.Real(1e-10,100,'log-uniform'),\n        'learning-rate': skopt.space.Real(0.01,0.2,'log-uniform'),\n        }\n\nbayes = BayesSearchCV(xgb.XGBClassifier(objective = 'binary:logistic'), search_spaces= parameters, n_iter=10, scoring='f1_macro',cv=5,random_state=0)\nres = bayes.fit(X_train_all_de,y_train)\nprint(res.best_params_)","66a4734b":"# train the model with tuned hyperparameters\nfinal_params={'objective': 'binary:logistic', 'n_estimators': 18, 'colsample_bytree': 0.6162570141151325, 'learning-rate': 0.020729429554412183,'max_depth': 7, 'min_num_child': 14, 'reg_alpha': 1.1046982314481511e-07, 'reg_lambda': 1.551926920387429e-10 , 'subsample': 0.5148603857041089}\ndtrain = xgb.DMatrix(X_train_de, y_train)\nmodel_xgb_de_num_cat = xgb.train(final_params, dtrain = dtrain)\n","ff15368f":"# testing the trained classifier\ndtest = xgb.DMatrix(X_test_de, y_test)\ny_pred = model_xgb_de_num_cat.predict(dtest)\n# turn the probabilities into labels\ny_pred[y_pred >= 0.5] = 1\ny_pred[y_pred < 0.5] = 0","4fc75f18":"print(\"Macro F1-Score\")\nprint(f1_score(y_test, y_pred, average = \"macro\"))\nprint()\nprint(\"F1-score for each label\")\nprint()\nprint(\" ALL       AML\")\nprint(f1_score(y_test, y_pred, average = None))\n","8b44b09b":"import skopt \nfrom skopt import BayesSearchCV\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n\nparameters = {'n_estimators': skopt.space.Integer(0,100),\n        'min_num_child': skopt.space.Integer(0, 50,),\n        'max_depth': skopt.space.Integer(0, 10),\n        'subsample': skopt.space.Real(0.5, 1.0),\n        'colsample_bytree': skopt.space.Real(0.5, 1.0),\n        'reg_lambda': skopt.space.Real(1e-10,100,'log-uniform'),\n        'reg_alpha': skopt.space.Real(1e-10,100,'log-uniform'),\n        'learning-rate': skopt.space.Real(0.01,0.2,'log-uniform'),\n        }\n\nbayes = BayesSearchCV(xgb.XGBClassifier(objective = 'binary:logistic'), search_spaces= parameters, n_iter=10, scoring='f1_macro',cv=5,random_state=0)\nres = bayes.fit(X_train_num_de,y_train)\nprint(res.best_params_)","59922f40":"final_params={'objective': 'binary:logistic', 'n_estimators': 18, 'colsample_bytree': 0.6162570141151325, 'learning-rate': 0.020729429554412183,'max_depth': 7, 'min_num_child': 14, 'reg_alpha': 1.1046982314481511e-07, 'reg_lambda': 1.551926920387429e-10 , 'subsample': 0.5148603857041089}\ndtrain = xgb.DMatrix(X_train_num_de, y_train)\nmodel_xgb = xgb.train(final_params, dtrain = dtrain)\n","79a3b685":"dtest = xgb.DMatrix(X_test_num_de, y_test)\ny_pred = model_xgb.predict(dtest)\n# turn the probabilities into labels\ny_pred[y_pred >= 0.5] = 1\ny_pred[y_pred < 0.5] = 0","2297d8d4":"print(\"Macro F1-Score\")\nprint(f1_score(y_test, y_pred, average = \"macro\"))\nprint()\nprint(\"F1-score for each label\")\nprint()\nprint(\" ALL       AML\")\nprint(f1_score(y_test, y_pred, average = None))\n","9450eafc":"import skopt \nfrom skopt import BayesSearchCV\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')\n\nparameters = {'n_estimators': skopt.space.Integer(0,100),\n        'min_num_child': skopt.space.Integer(0, 50,),\n        'max_depth': skopt.space.Integer(0, 10),\n        'subsample': skopt.space.Real(0.5, 1.0),\n        'colsample_bytree': skopt.space.Real(0.5, 1.0),\n        'reg_lambda': skopt.space.Real(1e-10,100,'log-uniform'),\n        'reg_alpha': skopt.space.Real(1e-10,100,'log-uniform'),\n        'learning-rate': skopt.space.Real(0.01,0.2,'log-uniform'),\n        }\n\nbayes = BayesSearchCV(xgb.XGBClassifier(objective = 'binary:logistic'), search_spaces= parameters, n_iter=10, scoring='f1_macro',cv=5,random_state=0)\nres = bayes.fit(X_train_de,y_train)\nprint(res.best_params_)","9716b36a":"final_params={'objective': 'binary:logistic', 'n_estimators': 82, 'colsample_bytree': 0.5737099059755859, 'learning-rate': 0.10448475115917014,'max_depth': 5, 'min_num_child': 23, 'reg_alpha': 0.0139529144831671, 'reg_lambda': 1.4176986367221247 , 'subsample': 0.6597195969050774}\ndtrain = xgb.DMatrix(X_train_de, y_train)\nmodel_xgb_cat_de = xgb.train(final_params, dtrain = dtrain)\n","bd6202ef":"dtest = xgb.DMatrix(X_test_de, y_test)\ny_pred = model_xgb_cat_de.predict(dtest)\n# turn the probabilities into labels\ny_pred[y_pred >= 0.5] = 1\ny_pred[y_pred < 0.5] = 0","e7bba074":"print(\"Macro F1-Score\")\nprint(f1_score(y_test, y_pred, average = \"macro\"))\nprint()\nprint(\"F1-score for each label\")\nprint()\nprint(\" ALL       AML\")\nprint(f1_score(y_test, y_pred, average = None))\n","2a606707":"# save the best performing models\nimport pickle\n# saving the model with PCA numerical features and categorical features \n# correspoinding to top 10 DE genes of the train set\nfilename = 'xgboost_model_pca_num_cat_de.sav'\npickle.dump(model_xgb_pca_num_cat_de, open(filename, 'wb'))\n\n# saving the model with only categorical features of the top 10 DE genes in the train set\nfilename = 'xgboost_model_cat_de.sav'\npickle.dump(model_xgb_cat_de, open(filename, 'wb'))","5d911a47":"##### **Grid Search Hyperparameter Tuning**","32a7c1d9":"Looking at the table, one can see that the top two classifiers, in terms of macro F1-score calculated on the test set are Model 4 and Model 7.\\\nModel 4 is the XGBoost classifier, which was trained on the PCA numerical features and the categorical features, corresponding to the top 10 DE genes in the train set.\nModel 7 is the XGBoost classifier which was trained only using the categorical features corresponding to the top 10 DE genes of the train set.\\\nOf these two top models, Model 7 has slightly better macro F1-score. However, since we have only trained it on one test set, we are not sure if this difference is statistically significant, or simply due to chance.\\\nMoreover, it is usually practice to choose the simpler model, in case of two models which perform equally well on a test set. In this case, however, we do not have much information about the thresholds used by the microarray technology which determines whether a gene's expression is present (\"P\"),\nabsent (\"A\"), or marginal (\"M\"). Thus, it is not very clear how robust this categorization is, making it potentially unreasonable to drop all the numerical features and relying only on the categorical ones.\\\nThus, before choosing the simpler model with determination, it might be a good idea to consult an expert on the microarray categorization robustness first.\\\nNevertheless, a macro F1-score of 0.87 for both models is a very good result.\nAnd what is more, both models appear to be doing quite well in predicting ALL and AML samples, when looked at separately, which was one of the main objectives we defined for our model.\n\n","d63c4bf8":"##### **Model Evaluation**","2e0b6765":"##### **Grid Search Hyperparameter Tuning**","ba2cae52":"##### **Model Evaluation**","1d74685a":"| | Algorithm          | Features | Num Features | Macro F1-score |ALL F1-score | AML F1-Score |\n|--|--------------------|----------|----------|---------|----------|----------|\n|1|SVM                 | PCA Num  | 30       | **0.717**  | 0.833   | 0.600  |\n|2|XGBoost             | PCA Num  | 30       | **0.671**  | 0.816   | 0.526   |\n|3|SVM                 | PCA Num + DE Cat   | 40   | **0.717**  | 0.833   | 0.600|\n|4|XGBoost             | PCA Num + DE Cat   | 40   | **0.871**  | 0.909  | 0.833|\n|5|XGBoost             | DE Num + DE Cat   | 20   | **0.724**  | 0.780  | 0.667|\n|6|XGBoost             | DE Num | 10   | **0.798** | 0.870  | 0.727   |\n|7|XGBoost             | DE Cat| 10   | **0.875**  | 0.905   | 0.846 | ","01f3401f":"As one can see, this classifier is on a par with the classifier trained with both the PCA numerical and the categorical features corresponding to the DE genes.\nHowever, there is one thing that should be considered when thinking of only using the categorical variables. We are not very clear on what the threshold is for determining the expression of a gene as present (\"P\"), absent (\"A\"), or marginal (\"M\"). And it is not very clear how robust this categorization is.","07191653":"Since the test set was predetermined, it is also worth checking whether it is imbalanced, because this can later on affect the evaluation of the classifier fit.","7f767786":"We also need to check how it does against an only-AML-predictions dataset.","2e97c973":"As mentioned earlier, our dataset is imbalanced (there are more ALL than AML samples in both the train and test set. Hence it is very important to ensure that the splitof the train sample during the cross-validation used is stratified. Luckily, GridSearchCV does this by default. In addition, we used a 5-fold cross-validation, as our train set is not very big and we wanted to ensure that we still had several samples to tune our hyperparameters on. We used the macro f1-score, in order to evaluate our models.","de060116":"As one can see, the XGBoost Classifier performs almost as well in classifying the samples from the two classes, compared to the SVM Classifier. \n\nIt also does better than the only-ALL-predictions and only-AML-predictions, which have macro F1-scores of 0.37 and 0.29, respectively.","1c58ae27":"Since there are 7129 numerical features, a natural step would be to attempt dimensionality reduction, using principal component analysis. Now, note that dimensionality reduction would also make sense from biological point of view, as some of the genes might be linked. We decided to use 30 principal components, as this helps explain around 90 percent of the variance, which is very reasonable.","3cfdc82d":"It seems like adding the categorical features resulted in a significant improvement of the performance of the XGBoost classifier, making this also an overall well-performing classification model, at least based on our test data. As one can see, this model does reasonably well in classifying samples from both the ALL and AML classes, which is exactly what we set as a goal at the beginning of the project.","a0ace975":"We first check whether there is an imbalance in the train set.","7743961b":"We selected the 10 differentially expressed genes in the train set with the smallest p-value, after Benjamini-Hochberg adjustment. These were (in order of smallest to largest adj. p-value): *U50136_rna1_at, X95735_at, M55150_at, M16038_at, Y12670_at, M23197_at, X17042_at, U82759_at, D49950_at, M84526_at*. The categorical variables, corresponding to these variables were extracted and added to the numerical variables.","1be38ba0":"Unsurprisingly, our model does better, compared to an only-AML-predictions dataset.","cee5b413":"## **Model Fitting**","06dfb915":"Before fitting a machine learning model, it is important to get to know the data. Determining whether there is an imbalance is an important step of exploratory data analysis, as, if left unchecked, it could then affect the performance of the model.","0287e238":"#### **XGBoost Classifier**","d18714ea":"In this section we are going to fit an SVM classifier and an XGBoost classifier, using only the numerical features.","47028d22":"### **Data Description**\n","9d750471":"Now that we have selected and added the categorical variables to the set of numeric features, we proceed with training an SVM and XGBoost classifiers once again, in order to try and improve the results.","e9113866":"### **Fitting a Model Only with the Numerical Features Corresponding to DE Genes**","86b291fb":"As mentioned, the dataset used in this project contains microarray gene expression data of patients with acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL). The data used in the paper was originally split into two datasets of 38 and 34 samples, used respectively for training and testing. In addition, we had one more dataset with the labels (ALL or AML) for all samples.\nThe first two columns of the dataset contain gene descriptions.\nThe dataset contains microarray expression data from 7129 genes, where each gene is a row in the dataset.  Intensity values have been re-scaled such that overall intensities for each chip are equivalent. The samples are the columns of the dataset. Next to the column for each sample there was a column of a variable named \"Call\", which took three values - \"A\", \"P\", and \"M\". These stand for \"Absent\", \"Present\", and \"Marginal\". They are based on the signal in the microarray for a gene at hand and they determine a gene's expression in a sample. In order for XGBoost to handle these categorical variables, these were transformed into numbers - 0 for \"A\", 1 for \"P\", and 2 for \"M\". We first trained classifiers only with the numerical variables, but they did not perform very well, and thus we trained the classifiers with the numerical and some of the categorical features.","4ca763ef":"### **Data Processing**","091b92ec":"We decided, purely for the sake of exercise, to tune the hyperparameters of the SVM classifier trained, using GridSearchCV.\n","c7eae6db":"As one can see, adding the categorical variables does not change the performance of the SVM classifier.","862d6f6c":"Now, before proceeding to the model fitting part, first we need to pick a suitable performance metric.","bf1ffd4f":"## **Principal Component Analysis**","48491407":"## **Comparison of All Classifiers**","ee9320cf":"##### **Model Performance Comparison to One-Outcome-Only Predictions**","b17a7216":"As one can see, both test and train set are imbalanced. Luckily, both GridSearchCV and BayesSearchCV, which we use for parameter optimization of our models both use stratification by default in classification problems.","1d0188fc":"#### **SVM**","3f59bf92":"Having done the processing step, we now proceed with a brief exploratory data analysis.","24b4f480":"Since none of the classifiers perform to a satisfactory level, we will now experiment with adding some of the categorical features.","ca5c8359":"##### **Best Model Fitting**","5abab652":"We now proceed to loading the original data and importing the necessary libraries and we will then focus on the data processing steps that will be necessary in this case.\n","e3afcc6a":"#### **SVM**","bd371ef4":"## **Data Normalization**","dfada380":"For convenience, here is a table of the performance results of all classifiers trained in this project.","0a1c15b0":"Taking differentially expressed genes into account seems to add some extra information and improves the performance of the XGBoost classfier. Thus we are now going to train an XGBoost classifier, which uses the DE categorical variables, as well as the numerical variables, corresponding to the 10 differentially expressed genes mentioned above.","4817f804":"## **Data**","5f2bbe3e":"Data rescaling is an important step of the process in developing a good machine learning model. Features often have different units, which often means different scales and distributions of feature variables. These differences, if left unadressed, might result in poor performance of the model, hence the problem should be considered. \n\nThere are two rescaling techniques used in machine learning - normalization and standardization.\nNormalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\nStandardizing a dataset involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1. This can be thought of as subtracting the mean value or centering the data.\nStandardization assumes that observations fit a Gaussian distribution with a well behaved mean and standard deviation. [2] In this case, we decided to use normalization, as we didn't want to make a normality assumption about all 7129 genes.","8f5dea12":"##### **Bayesian Optimization Hyperparameter Tuning**","34116351":"### **Fitting a Model with Numerical and Categorical Features Corresponding to DE Genes**","8cc401c8":"##### **Best Model Fitting**","cd71d50c":"In this project we decided to compare the performance of XGBoost and SVM Classifiers. We decided also, purely for the sake of exercise, to do parameter optimization using grid search and Bayesian optimization for SVM and XGBoost, respectively. Since we have both a set of numerical and a large set of categorical variables, we decided to do some experimentation with the set of features we used to fit the classifiers. Thus, we would first fit models only with the numerical features and then experiment with adding some of the categorical variables, in order to try and improve the model performance. ","eae12483":"**REFERENCES:**\n\n[1] *Golub, T. et al, 1999. Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring. Science, 286(5439), pp.531-537.*\n\n[2] Brownlee, J., 2020. How To Use Data Scaling Improve Deep Learning Model Stability And Performance. [online] Machine Learning Mastery. Available at: <https:\/\/machinelearningmastery.com\/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling\/> [Accessed 10 November 2020].","3ca1dcdc":"# **Classifying Samples with Acute Myeloid Leukemia and Acute Lymphoblastic Leukemia: SVM vs XGBoost**","97608a00":"## **Choosing a Performance Metric**","0890b010":"##### **Best Model Fitting**","3dacaa2d":"##### **Bayesian Optimization Hyperparameter Tuning**","ac971da6":"Once this is done for the train set, we also normalize the test set (separately, as doing the normalization for both sets together could potentially lead to some data leakage). Then we reduce the dimensionality of the test set by projecting the test points into the space defined by the principal components extracted from the train set.","6b0286b7":"## **Exploratory Data Analysis**","39cd150c":"This is a reasonable performance result, although there is clearly room for improvement. As it can be expected, the F1-score for AML is lower, as we had almost 2:1 ratio of ALL to AML samples in the train set. In order to get a better idea of the performance of the trained classifier, it is worth investigating how well the model does, compared to a one-outcome-only prediction for all samples (only ALL or only AML.)","d5490944":"Now, considering that the differential expression features carry so much information about the classification, it is still interesting to check whether we could reduce the number of features even further - using either only the DE numerical features, or the DE categorical features, and still get reasonable results.","c5bbd0ff":"Now, one cannot help but ask how well a model with a reduced number of features would do. Thus, we are now going to train a classifier with only the categorical variables, corresponding to the top 10 differentially expressed genes, as well as a model with said categorical variables, as well as the numerical variables, corresponding to these 10 genes. We will also experiment with a classifier trained on both the numerical and categorical features that correspond to the DE genes.","0fec749e":"Choosing a suitable performance metric is a crucial part of every machine learning project. In order to select a good metric, we first need to clearly state the purpose of our model.\n\nIn the case of classifying patients with either ALL or AML diagnosis, the performance of the model in **classifying samples from each of the classes is equally important**. This is, we want a metric which places equal weight on classification performance for each class. We are also **interested in high precision and recall for each of the classes**.  Having these requirements in mind, we decided that a good choice in this case would be to use the **Macro F1-score**. The Macro F1-score is the unweighted average of the F1-score calculated for each of the classes. Using it would enable us to find the model which fits best our requirements. Moreover, this metric works well for our imbalanced dataset, as it would penalize the misclassification of samples from the minority class - in our case AML. This is useful, because it would prevent from obtaining an overly optimistic performance evaluation, in case a model is trained to do well on classifying samples from the majority class only.\nHaving chosen our evaluation metric, we now proceed to model fitting.\n","f23855c7":"##### **Best Model Fitting**","e53b6821":"### **Fitting Models with Both Numerical and Categorical Features**","b6256391":"### **Fitting a Model Only with the Categorical Features Corresponding to DE Genes**","f1e171d2":"### **Fitting Models Only with the Numerical Features**","3b62febc":"This classifier performs overall reasonably well on the test set, however there is a significant difference in the performance on the ALL and AML samples, when looked at separately. ","621576c3":"#### **Categorical Variables Selection**","82a03ed0":"As one can see, there is a significant imbalance of ALL to AML samples, which could potentially result into training a classifier which does well on classifying ALL, but not AML samples.","6f175548":"##### **Model Evaluation**","acf59eb0":"As one can see, the XGBoost classifier trained only with the numerical and categorical features corresponding to the top 10 differential features performs slightly better on the test set, compared to the XGBoost with only PCA numerical features, but worse than the XGBoost classifier with PCA numerical and DE categorical features. \\\nIt also performs on par with the both SVM classifiers that we trained.\n","bcf68adf":"### **Data Loading**","9b5cee67":"We then use the trained model to classify samples in the test set.","d90f8a3b":"Now, it is worth pointing out, that when considering an only-ALL-predictions set, the F1-score for AML samples predictions is not defined, as both Precision and Recall are 0, which means that AML F1-score is 0\/0. In this case, however, sklearn assigns AML F1-score = 0, thus still meaning in has no contribution to the macro F1 score, thus bringing its value down. Hence, we decided to stick to macro F1-score as an evaluation metric.\n\nAs one can see, our SVM classifier does significantly better in classifying samples, compared to an only-ALL-predictions dataset.","2b91a572":"There are 7129 categorical variables, whose values denote whether the signal from a gene is strong enough for it to be qualified as expressed (\"P\" - present), absent (\"A\"), or marginal (\"M\"). In order for the classifier to be able to process these categorical features, they were encoded with numbers - 1, 0, and 2, respectively. Now, since this is a very large number of features (considering that we only have 38 train samples), we needed to carefully select a small subset of the categorical variables to add to the set of numerical features.\n\nThe idea we tried out was to find differentially expressed genes between the two groups (ALL and AML) from the provided gene expression microarray data of the train set.\nThe categorical variables, corresponding to these  genes will be added to the numerical features. Since there is a well-established package for microarray expression data in R - limma, it was used. The data was already normalized, so this step was skipped.","a27c81d7":"##### **Model Evaluation**","7e56843b":"There are several data processing steps that need to be conducted.\nThe first one would be to exctract the \"call\" columns mentioned above and turn them into features.\n","8674f518":"## **Saving the Best Models**","0798ab24":"This project is based on a study published in 1999 by Golub et al - Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring. It demonstrated how new cases of cancer could be classified by gene expression monitoring (via DNA microarray) and thus provided a general approach for identifying new cancer classes and assigning tumors to known classes. [1]\n\nThe data used in this project, also used as a test case in the paper, is gene expression data from patients with acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL). The project's purpose is to train a classifier which would diagnose new patients with one of the two conditions.\n\n\n","20e58a82":"We then use the best hyperparameter values and instantiate the best model.","14e8a02f":"#### **XGBoost Classifier**"}}