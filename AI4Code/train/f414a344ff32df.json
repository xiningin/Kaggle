{"cell_type":{"6e12dfd0":"code","6f9b43e8":"code","fc843bb6":"code","65c3ed4d":"code","150b7f57":"code","5577b8b5":"code","f3006bfe":"code","d3012c76":"code","c51bbb9d":"code","14f171f7":"code","3404b790":"code","0130b962":"code","75b6fd8d":"code","4e5731a5":"code","0e683630":"code","71c49abe":"code","c0a9fd50":"code","d6f4922f":"code","883b5de0":"code","83533bd3":"code","ebce4026":"code","ce3e2962":"code","2ab40bb9":"code","0782d43b":"code","b7a351d4":"code","e36a8a92":"code","5c7123f6":"code","d961a3f8":"code","e0b361ef":"markdown","240a8816":"markdown","f2085a80":"markdown","76715768":"markdown"},"source":{"6e12dfd0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split , GridSearchCV , cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler , MinMaxScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report , confusion_matrix , roc_curve , roc_auc_score \nfrom sklearn import metrics","6f9b43e8":"diamonds = pd.read_csv('..\/input\/diamonds\/diamonds.csv' , index_col = 0)","fc843bb6":"diamonds.head()","65c3ed4d":"diamonds.info()","150b7f57":"clarity = pd.get_dummies(diamonds['clarity'])\ncolor = pd.get_dummies(diamonds['color'])","5577b8b5":"diamonds = pd.concat([diamonds , clarity , color] , axis = 1)","f3006bfe":"diamonds.drop(['color' , 'clarity'] , axis = 1 , inplace=True)","d3012c76":"diamonds.head()","c51bbb9d":"diamonds.info()","14f171f7":"plt.figure(figsize=(20, 20))\ndf_corr = diamonds.corr()\nsns.heatmap(df_corr, cmap=sns.diverging_palette(220, 20, n=12), annot=True)\nplt.title(\"Diamonds\")\nplt.show()","3404b790":"diamonds['cut'].value_counts()","0130b962":"for i in range(len(diamonds)):\n    if diamonds['cut'].iloc[i] == 'Ideal':\n        diamonds['cut'].iloc[i] = 1\n    if diamonds['cut'].iloc[i] == 'Premium':\n        diamonds['cut'].iloc[i] = 2\n    if diamonds['cut'].iloc[i] == 'Very Good':\n        diamonds['cut'].iloc[i] = 3\n    if diamonds['cut'].iloc[i] == 'Good':\n        diamonds['cut'].iloc[i] = 4\n    if diamonds['cut'].iloc[i] == 'Fair':\n        diamonds['cut'].iloc[i] = 5","75b6fd8d":"X = diamonds.drop(['cut'], axis = 1 ).values\ny = diamonds['cut'].values","4e5731a5":"scalar = StandardScaler()\nX = scalar.fit_transform(X)","0e683630":"X_train, X_test, y_train, y_test = train_test_split(X , y  , test_size = 0.2 , random_state = 42)","71c49abe":"y_train = y_train.astype('int')\ny_test = y_test.astype('int')","c0a9fd50":"def calculate_and_plot_k_neighbors(X_train, X_test, y_train, y_test):\n    \n    neighbors = np.arange(1, 10)\n    train_accuracy = np.empty(len(neighbors))\n    test_accuracy = np.empty(len(neighbors))\n    \n    for i, k in enumerate(neighbors):\n        knn = KNeighborsClassifier(n_neighbors= k)\n        knn.fit(X_train , y_train)\n        train_accuracy[i] = knn.score(X_train, y_train)    \n        test_accuracy[i] = knn.score(X_test, y_test)\n\n    plt.figure(figsize=(10, 8))   \n    plt.title('k in kNN analysis')\n    plt.plot( neighbors , test_accuracy , label = 'Testing Accuracy')\n    plt.plot(neighbors,train_accuracy ,label = 'Training Accuracy')\n    plt.legend()\n    plt.annotate('Best accuracy for this model with this k is {0:.2f} %'.format(max(test_accuracy) * 100), xy=(np.argmax(test_accuracy) + 1 , max(test_accuracy)), xytext=(5 , 0.80),\n            arrowprops=dict(arrowstyle=\"->\",\n                            connectionstyle=\"angle3,angleA=0,angleB=-90\"));\n    plt.xlabel('Number of Neighbors')\n    plt.ylabel('Accuracy')\n    plt.show()","d6f4922f":"def plot_confusion_matrix(cf_matrix , y_test , model_type , cf_size):\n    if cf_size == '2x2':\n        group_names = ['True Negative','False Positive','False Negative','True Positive']\n        group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n        labels = ['{}\\n{}'.format(v1 ,v2) for v1, v2 in zip(group_names,group_counts)]\n        labels = np.asarray(labels).reshape(2,2)\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(\n            cf_matrix,\n            annot = labels,\n            cmap=sns.cubehelix_palette(100, as_cmap=True, hue=1, dark=0.30),\n            fmt='',\n            linewidths=1.5,\n            vmin=0,\n            vmax=len(y_test),\n        )\n        plt.title(model_type)\n        plt.show()\n    else:\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(\n            cf_matrix \/ np.sum(cf_matrix) * 100,\n            annot = True,\n            cmap=sns.cubehelix_palette(100, as_cmap=True, hue=1, dark=0.30),\n            fmt='.2f',\n            linewidths=1.5,\n            vmin=0,\n            vmax=100,\n        )\n        plt.title(model_type)\n        plt.show()","883b5de0":"def kNN_algorithm(X_train , y_train , X_test , y_test , k):\n    \n    global y_pred_kNN\n    global kNN_pipeline\n    \n    steps = [('impute' , SimpleImputer(missing_values = 0, strategy='mean')),\n             ('sclaer', StandardScaler()),\n             ('kNN', KNeighborsClassifier(n_neighbors = k))]\n    \n    kNN_pipeline = Pipeline(steps)\n    \n    kNN_pipeline.fit(X_train , y_train)\n    \n    y_pred_kNN = kNN_pipeline.predict(X_test)\n    \n    print(classification_report(y_test , y_pred_kNN))\n    print('kNN algorithm acuracy is : {0:.2f} %'.format(kNN_pipeline.score(X_test , y_test) * 100))","83533bd3":"def SVM_algorithm(X_train, X_test, y_train, y_test):\n    \n    global y_pred_SVM\n    global SVM_pipeline\n    global y_prob_SVM\n    \n    steps = [('scaler', StandardScaler()),\n             ('SVM', SVC(probability=True))]\n    \n    SVM_pipeline = Pipeline(steps)\n    \n    parameters = {'SVM__C':[1, 10, 100 ],\n                  'SVM__gamma':[0.1, 0.01]}\n    \n    cv = GridSearchCV(SVM_pipeline , cv = 5 , param_grid = parameters)\n    \n    cv.fit(X_train , y_train)\n    \n    y_pred_SVM = cv.predict(X_test)\n    \n    y_prob_SVM = cv.predict_proba(X_test)\n    \n    print(\"Accuracy: {0:.2f} %\".format(cv.score(X_test, y_test) * 100))\n    print(classification_report(y_test, y_pred_SVM))\n    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))","ebce4026":"def LogisticRegression_algorithm(X_train, X_test, y_train, y_test):\n    \n    global y_pred_LG\n    global LG_pipeline\n    global y_prob_LG\n    \n    steps = [('scaler', StandardScaler()),\n             ('LogisticRegression', LogisticRegression(random_state = 0))]\n    \n    LG_pipeline = Pipeline(steps)\n\n    \n    LG_pipeline.fit(X_train , y_train)\n    \n    y_pred_LG = LG_pipeline.predict(X_test)\n    \n    y_prob_LG = LG_pipeline.predict_proba(X_test)\n    \n    print(\"Accuracy: {0:.2f} %\".format(LG_pipeline.score(X_test, y_test) * 100))\n    print(classification_report(y_test, y_pred_LG))","ce3e2962":"calculate_and_plot_k_neighbors(X_train, X_test, y_train, y_test)","2ab40bb9":"kNN_algorithm(X_train , y_train , X_test , y_test , 8)","0782d43b":"cf_matrix_knn = confusion_matrix(y_test, y_pred_kNN)\ncf_matrix_knn = pd.DataFrame(cf_matrix_knn  , index = ['Ideal' ,'Premium','Very Good','Good','Fair'] , columns =['Ideal','Premium','Very Good','Good','Fair'])\nplot_confusion_matrix(cf_matrix_knn , y_test , 'kNN Confusion Matrix in percent %' , '5x5')","b7a351d4":"SVM_algorithm(X_train, X_test, y_train, y_test)","e36a8a92":"cf_matrix_SVM = confusion_matrix(y_test, y_pred_SVM)\ncf_matrix_SVM = pd.DataFrame(cf_matrix_SVM  , index = ['Ideal' ,'Premium','Very Good','Good','Fair'] , columns =['Ideal','Premium','Very Good','Good','Fair'])\nplot_confusion_matrix(cf_matrix_SVM , y_test , 'SVM Confusion Matrix in percent' , '5x5')","5c7123f6":"LogisticRegression_algorithm(X_train, X_test, y_train, y_test)","d961a3f8":"cf_matrix_LG = confusion_matrix(y_test, y_pred_LG)\ncf_matrix_LG = pd.DataFrame(cf_matrix_LG  , index = ['Ideal' ,'Premium','Very Good','Good','Fair'] , columns =['Ideal','Premium','Very Good','Good','Fair'])\nplot_confusion_matrix(cf_matrix_LG , y_test , 'LogisticRegression Confusion Matrix in percent' , '5x5')","e0b361ef":"# kNN (k-nearest neighbors)","240a8816":"## Functions\nI run 3 algorithm on this dataset \n1. kNN ( k-nearest neighbors )\n2. SVM ( Sub vector machine )\n3. Logistic Regression","f2085a80":"# Logistic Regression","76715768":"# SVM (Sub vector machine)"}}