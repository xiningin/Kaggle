{"cell_type":{"9fd94032":"code","6f9191bd":"code","7b480c48":"code","d25e01e8":"code","98321a40":"code","a4c60ce4":"code","89ba3183":"code","8657d02f":"code","7173d75c":"code","eb00dd62":"code","bca621fe":"code","28c9c1b8":"code","3a5583e7":"code","d1fa34dc":"code","cf216fbc":"code","b4434066":"code","dae4bd6d":"code","9d5608fc":"code","30deb529":"code","d45b974c":"code","b9e32cb2":"code","66842266":"code","c5dc0903":"code","a2e06102":"code","48bf25f2":"markdown","25b278ad":"markdown","9ded6652":"markdown","80255cb2":"markdown"},"source":{"9fd94032":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f9191bd":"train_data=pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_data.head()","7b480c48":"test_data=pd.read_csv('..\/input\/titanic\/test.csv')\ntest_data.head()","d25e01e8":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\ny = train_data[\"Survived\"]\nX = pd.get_dummies(train_data[features]).fillna(-1)\nX_valid, X_train, y_valid, y_train = train_test_split(X,y,test_size=0.5)\n\n\n\n\n","98321a40":"from sklearn.ensemble import RandomForestClassifier\nv=[]\nfor n in range(100):\n    model = RandomForestClassifier(n_estimators=n+1*10, max_depth=5, random_state=1)\n    model.fit(X_train, y_train)\n\n    predictions = model.predict(X_valid)\n    score = mean_absolute_error(y_valid, predictions)\n    v.append(score)\n\nn_min = min(v)\nn_pos = v.index(n_min)\n\nprint(\"Menor valor: %s\" % n_min)\nprint(\"Posi\u00e7\u00e3o: %s\" % n_pos)","a4c60ce4":"from sklearn.ensemble import RandomForestRegressor\nv=[]\nfor n in range(100):\n    model = RandomForestRegressor(n_estimators=n+1*10, random_state=1)\n    model.fit(X_train, y_train)\n\n    predictions = model.predict(X_valid)\n    score = mean_absolute_error(y_valid, predictions)\n    v.append(score)\n\nn_min = min(v)\nn_pos = v.index(n_min)\nprint(\"Menor valor: %s\" % n_min)\nprint(\"Posi\u00e7\u00e3o: %s\" % n_pos)","89ba3183":"np.mean(predictions==y_valid)","8657d02f":"from xgboost import XGBRegressor\n\nv=[]\nfor n in range(100):\n    model = XGBRegressor(n_estimators=500)\n    model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n\n    predictions = model.predict(X_valid)\n    score = mean_absolute_error(y_valid, predictions)\n    v.append(score)\n\nn_min = min(v)\nn_pos = v.index(n_min)\nprint(\"Menor valor: %s\" % n_min)\nprint(\"Posi\u00e7\u00e3o: %s\" % n_pos)\n","7173d75c":"model = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=1)\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_valid)\nscore = mean_absolute_error(y_valid, predictions)\nscore","eb00dd62":"train_data['Embarked_S'] = (train_data['Embarked']=='S').astype(int)\ntrain_data['Embarked_C'] = (train_data['Embarked']=='C').astype(int)\ntrain_data['Embarked_Q'] = (train_data['Embarked']=='Q').astype(int)\n\ntrain_data['Cabine_nula'] = train_data['Cabin'].isnull().astype(int)\n\ntrain_data['Nome_contrem_Miss'] = train_data['Name'].str.contains(\"Miss\").astype(int)\ntrain_data['Nome_contrem_Mrs'] = train_data['Name'].str.contains(\"Mrs\").astype(int)\n\ntrain_data['Nome_contrem_Master'] = train_data['Name'].str.contains(\"Master\").astype(int)\ntrain_data['Nome_contrem_Col'] = train_data['Name'].str.contains(\"Col\").astype(int)\ntrain_data['Nome_contrem_Major'] = train_data['Name'].str.contains(\"Major\").astype(int)\ntrain_data['Nome_contrem_Mr'] = train_data['Name'].str.contains(\"Mr\").astype(int)","bca621fe":"features = ['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', \"Fare\",'Embarked_S', 'Embarked_C', \"Embarked_Q\", 'Cabine_nula', 'Nome_contrem_Miss', 'Nome_contrem_Mrs','Nome_contrem_Master','Nome_contrem_Col','Nome_contrem_Major','Nome_contrem_Mr']\nX = pd.get_dummies(train_data[features]).fillna(-1)\nX_valid, X_train, y_valid, y_train = train_test_split(X,y,test_size=0.5)","28c9c1b8":"from sklearn.ensemble import RandomForestClassifier\nv=[]\nfor n in range(100):\n    model = RandomForestClassifier(n_estimators=n+1*10, max_depth=5, random_state=1)\n    model.fit(X_train, y_train)\n\n    predictions = model.predict(X_valid)\n    score = mean_absolute_error(y_valid, predictions)\n    v.append(score)\n\nn_min = min(v)\nn_pos = v.index(n_min)\n\nprint(\"Menor valor: %s\" % n_min)\nprint(\"Posi\u00e7\u00e3o: %s\" % n_pos)","3a5583e7":"from sklearn.ensemble import RandomForestRegressor\nv=[]\nfor n in range(100):\n    model = RandomForestRegressor(n_estimators=n+1*10, random_state=1)\n    model.fit(X_train, y_train)\n\n    predictions = model.predict(X_valid)\n    score = mean_absolute_error(y_valid, predictions)\n    v.append(score)\n\nn_min = min(v)\nn_pos = v.index(n_min)\nprint(\"Menor valor: %s\" % n_min)\nprint(\"Posi\u00e7\u00e3o: %s\" % n_pos)","d1fa34dc":"from xgboost import XGBRegressor\n\nv=[]\nfor n in range(100):\n    model = XGBRegressor(n_estimators=500)\n    model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)], verbose=False)\n\n    predictions = model.predict(X_valid)\n    score = mean_absolute_error(y_valid, predictions)\n    v.append(score)\n\nn_min = min(v)\nn_pos = v.index(n_min)\nprint(\"Menor valor: %s\" % n_min)\nprint(\"Posi\u00e7\u00e3o: %s\" % n_pos)","cf216fbc":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder","b4434066":"train_data['Title'] = train_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntest_data['Title'] = test_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n\ntrain_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\ntest_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n\ntrain_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\ntest_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)","dae4bd6d":"train_data['Fam_size'] = train_data['SibSp'] + train_data['Parch'] + 1\ntest_data['Fam_size'] = test_data['SibSp'] + test_data['Parch'] + 1","9d5608fc":"numerical_cols = ['Fare']\ncategorical_cols = ['Pclass', 'Sex', 'Title', 'Embarked', 'Fam_type']\n\ntrain_data['Fam_type'] = pd.cut(train_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\ntest_data['Fam_type'] = pd.cut(test_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\ntrain_data.head()","30deb529":"numerical_transformer= SimpleImputer(strategy='median')\n\ncategorical_transformer=Pipeline(steps=[\n    ('Imputer', SimpleImputer(strategy='most_frequent')),\n    ('Onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","d45b974c":"y = train_data['Survived']\nfeatures = ['Pclass', 'Sex', 'Fare', 'Title', 'Embarked', 'Fam_type']\nX = train_data[features]\nX.head()","b9e32cb2":"titanic_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', RandomForestClassifier(random_state=0, \n                                                               n_estimators=500, max_depth=5))\n                             ])\n\ntitanic_pipeline.fit(X,y)\n\nprint('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, y, cv=10).mean()))","66842266":"test_data['Embarked_S'] = (test_data['Embarked']=='S').astype(int)\ntest_data['Embarked_C'] = (test_data['Embarked']=='C').astype(int)\ntest_data['Embarked_Q'] = (test_data['Embarked']=='Q').astype(int)\n\ntest_data['Cabine_nula'] = test_data['Cabin'].isnull().astype(int)\n\ntest_data['Nome_contrem_Miss'] = test_data['Name'].str.contains(\"Miss\").astype(int)\ntest_data['Nome_contrem_Mrs'] = test_data['Name'].str.contains(\"Mrs\").astype(int)\n\ntest_data['Nome_contrem_Master'] = test_data['Name'].str.contains(\"Master\").astype(int)\ntest_data['Nome_contrem_Col'] = test_data['Name'].str.contains(\"Col\").astype(int)\ntest_data['Nome_contrem_Major'] = test_data['Name'].str.contains(\"Major\").astype(int)\ntest_data['Nome_contrem_Mr'] = test_data['Name'].str.contains(\"Mr\").astype(int)","c5dc0903":"X_test = test_data[features]\nX_test.head()\npredictions = titanic_pipeline.predict(X_test)","a2e06102":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv_new', index=False)","48bf25f2":"# trying to use pipelines and onehot","25b278ad":"# Appending features","9ded6652":"# Creating the output's model","80255cb2":"# Testing the models with new features"}}