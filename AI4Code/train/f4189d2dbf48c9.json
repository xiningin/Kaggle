{"cell_type":{"0220871c":"code","f8a00cac":"code","55acad8f":"code","0780cc42":"code","c0bea0e7":"code","039106f0":"code","bcc5b2b9":"code","ea500bc3":"code","eb4c74c1":"code","e803fc24":"code","1d12c28c":"code","43da3f11":"code","0c962eee":"code","dee99a94":"code","c69c3934":"code","0f1a1452":"code","6d7cd30a":"code","491fe278":"code","2f027b53":"code","438d1589":"code","67eb58ab":"code","73152756":"code","cde31dd3":"code","f0ed3b25":"code","c04d8080":"code","b074a7c2":"code","2ce175a9":"code","2c448cc5":"code","6504048e":"code","0c198ff6":"code","f33bed35":"code","225d2ca3":"code","dee164d4":"code","4f33ad0f":"code","fb3503f2":"code","1fd3cb9a":"code","7d865404":"code","c63e1ca3":"code","92ca65aa":"code","1280a952":"code","300bb11b":"code","c80e18d5":"code","af42ca9d":"code","4f7b0a6f":"code","27ab5519":"code","8e6b5108":"code","9c8d9bbe":"code","dd0a3acd":"code","6d340e4d":"markdown","d073bd34":"markdown","8bffeb9a":"markdown","48d1c0b1":"markdown","df42b468":"markdown","548f8a73":"markdown","436dbd9d":"markdown","ff155461":"markdown","cf08e40c":"markdown","f723a05c":"markdown","6a80312d":"markdown","e6b09c4d":"markdown","bc0e3eee":"markdown","98b61588":"markdown","81bff430":"markdown","2d958e1a":"markdown","0836ce69":"markdown","42956dc2":"markdown","67713377":"markdown","dcd965eb":"markdown","43dc1933":"markdown","ae99e973":"markdown","4359c3ae":"markdown","53a501c9":"markdown","d73553e1":"markdown","d0a8fdc3":"markdown","b0a0ea00":"markdown","f7b67fa1":"markdown","ee56a692":"markdown","a53d2470":"markdown","082921b7":"markdown","db885b00":"markdown","430722ef":"markdown","0f787730":"markdown","25e9570f":"markdown","2c17ee03":"markdown","381798dc":"markdown","09ceed09":"markdown","1df1a620":"markdown","a6993263":"markdown","225706e2":"markdown","f8892cec":"markdown","5dfdd7a4":"markdown","8835456e":"markdown","ebffb7f6":"markdown","b214ef05":"markdown","12663e50":"markdown","ccaa2176":"markdown","59b92063":"markdown","19414746":"markdown","0a7d2c5a":"markdown","d75154f9":"markdown","2c147d00":"markdown","7b09842b":"markdown","cf518a26":"markdown","cc3684d3":"markdown","ea90ba1e":"markdown","bca243b8":"markdown","ea5cc069":"markdown","46356847":"markdown","cdaa1c6b":"markdown"},"source":{"0220871c":"import math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport numpy as np\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8a00cac":"baseline = {'Cookies': 40000, 'Clicks': 3200, 'Enrolled': 660, 'Click-trough probability': 0.08, \n      'Probability of enrolling, given click': 0.20625, \"Probability of payment, given enroll\" : 0.53,\n     \"Probability of payment, given click\": 0.1093125}\nbaseline","55acad8f":"factor = 5000\/baseline[\"Cookies\"]\nfactor","0780cc42":"baseline.update((key, value*0.125) for key, value in baseline.items() if key in ['Cookies', 'Clicks', 'Enrolled'])\nbaseline","c0bea0e7":"stddev = {'Gross conversion': 0, 'Retention': 0, 'Net conversion': 0}\n\ndef SE(p, n):\n    return math.sqrt(p*(1-p)\/n)\n\nstddev['Gross conversion'] = round(SE(baseline['Probability of enrolling, given click'], baseline['Clicks']), 4)\nstddev['Retention'] = round(SE(baseline['Probability of payment, given enroll'], baseline['Enrolled']), 4)\nstddev['Net conversion'] = round(SE(baseline['Probability of payment, given click'], baseline['Clicks']), 4)\nstddev","039106f0":"sample_size = {'size_GC': 25835, 'size_R': 39115, 'size_NC': 27413}","bcc5b2b9":"sample_size.update((key, round(value*2\/0.08)) for key, value in sample_size.items() if key in ['size_GC', 'size_NC'])\nsample_size.update((key, round(value*2\/0.0165)) for key, value in sample_size.items() if key in ['size_R'])\nsample_size","ea500bc3":"max(sample_size.values())","eb4c74c1":"round(max(sample_size.values())\/40000)","e803fc24":"del sample_size['size_R']","1d12c28c":"round(max(sample_size.values())\/40000)","43da3f11":"round(max(sample_size.values())\/(40000*0.4))","0c962eee":"round(max(sample_size.values())\/(40000*0.5))","dee99a94":"round(max(sample_size.values())\/(40000*0.6))","c69c3934":"contr = pd.read_csv(\"\/kaggle\/input\/ab-test\/ab_control.csv\") \nexper = pd.read_csv(\"\/kaggle\/input\/ab-test\/ab_experiment.csv\")\n\ncontr.head()","0f1a1452":"exper.head()","6d7cd30a":"total = {'Control':{ 'Pageviews': contr['Pageviews'].sum(), \n                    'Clicks': contr['Clicks'].sum()}, \n         'Experiment': { 'Pageviews': exper['Pageviews'].sum(), \n                        'Clicks': exper['Clicks'].sum()},\n        'Total C + E': { 'Pageviews': contr['Pageviews'].sum()+exper['Pageviews'].sum(), \n                        'Clicks': contr['Clicks'].sum()+exper['Clicks'].sum()},\n        'Difference between C and E': {'Pageviews': abs(contr['Pageviews'].sum()-exper['Pageviews'].sum()), \n                        'Clicks': abs(contr['Clicks'].sum()-exper['Clicks'].sum())}}","491fe278":"for key, value in total.items():\n    print(key, ':')\n    for k, v in value.items():\n        print('  ', k,':', v)","2f027b53":"p = round(total['Control']['Pageviews']\/total['Total C + E']['Pageviews'], 4)\np","438d1589":"total['Total C + E']['Pageviews']*0.5>=10","67eb58ab":"std_dev = round(math.sqrt(0.5*0.5\/total['Total C + E']['Pageviews']),6)\nstd_dev","73152756":"lower = 0.5 - round(1.96*std_dev, 4)\nupper = 0.5 + round(1.96*std_dev, 4)","cde31dd3":"plt.rcParams.update({'font.size': 16})\nx = [lower, 0.500, upper]\ny = [0,0,0]\n\nplt.plot(x, y, '-o')\nfor xx,yy in zip(x,y):\n    plt.annotate(xx, # this is the text\n                 (xx,yy), # this is the point to label\n                 textcoords=\"offset points\", # how to position the text\n                 xytext=(0,10), # distance from text to points (x,y)\n                 ha='center') # horizontal alignment can be left, right or center\n    \nplt.title('Confidence interval for $p = 0.5$')\n\nplt.axis('off')\nplt.show()","f0ed3b25":"p = round(total['Control']['Clicks']\/total['Total C + E']['Clicks'], 4)\np","c04d8080":"total['Total C + E']['Clicks']*0.5>=10","b074a7c2":"std_dev = round(math.sqrt(0.5*0.5\/total['Total C + E']['Clicks']),6)\nstd_dev","2ce175a9":"lower = 0.5 - round(1.96*std_dev, 4)\nupper = 0.5 + round(1.96*std_dev, 4)","2c448cc5":"plt.rcParams.update({'font.size': 16})\nx = [lower, 0.500, upper]\ny = [0,0,0]\n\nplt.plot(x, y, '-o')\nfor xx,yy in zip(x,y):\n    plt.annotate(xx, # this is the text\n                 (xx,yy), # this is the point to label\n                 textcoords=\"offset points\", # how to position the text\n                 xytext=(0,10), # distance from text to points (x,y)\n                 ha='center') # horizontal alignment can be left, right or center\n    \nplt.title('Confidence interval for $p = 0.5$')\n\nplt.axis('off')\nplt.show()","6504048e":"d = round(total['Experiment']['Clicks']\/total['Experiment']['Pageviews'] \n          - total['Control']['Clicks']\/total['Control']['Pageviews'], 4)\nd","0c198ff6":"d_theor = 0","f33bed35":"p_pool = round((total['Experiment']['Clicks']+total['Control']['Clicks'])\n          \/(total['Experiment']['Pageviews']+total['Control']['Pageviews']), 6)\np_pool","225d2ca3":"se_pool = round(math.sqrt(p_pool*(1-p_pool)*(1\/total['Control']['Pageviews']+1\/total['Experiment']['Pageviews'])), 6)\nse_pool","dee164d4":"upper = round(d_theor + 1.96*se_pool, 4)\nlower = round(d_theor- 1.96*se_pool, 4)","4f33ad0f":"plt.rcParams.update({'font.size': 16})\nx = [lower, d_theor, upper]\ny = [0,0,0]\n\nplt.plot(x, y, '-o')\nfor xx,yy in zip(x,y):\n    plt.annotate(xx, # this is the text\n                 (xx,yy), # this is the point to label\n                 textcoords=\"offset points\", # how to position the text\n                 xytext=(0,10), # distance from text to points (x,y)\n                 ha='center') # horizontal alignment can be left, right or center\n    \nplt.title('Confidence interval for $d = {} $'.format(d_theor))\n\nplt.axis('off')\nplt.show()\n\n","fb3503f2":"total_eval = {'Control':{ 'Enrollments': contr['Enrollments'].sum(), \n                    'Clicks': contr.iloc[:23]['Clicks'].sum(),\n                        'Payments': contr['Payments'].sum()},\n              'Experiment':{'Enrollments': exper['Enrollments'].sum(),\n                           'Clicks': exper.iloc[:23]['Clicks'].sum(),\n                           'Payments': exper['Payments'].sum()}}\n              ","1fd3cb9a":"for key, value in total_eval.items():\n    print(key, ':')\n    for k, v in value.items():\n        print('  ', k,':', v)","7d865404":"d_hat = round(total_eval['Experiment']['Enrollments']\/total_eval['Experiment']['Clicks'] - total_eval['Control']['Enrollments']\/total_eval['Control']['Clicks'], 5)\nd_hat","c63e1ca3":"gc_pool = round((total_eval['Experiment']['Enrollments']+total_eval['Control']['Enrollments'])\/(total_eval['Experiment']['Clicks']+total_eval['Control']['Clicks']), 6)\ngc_pool","92ca65aa":"se_pool = round(math.sqrt(gc_pool*(1-gc_pool)*(1\/total_eval['Control']['Clicks']+1\/total_eval['Experiment']['Clicks'])), 6)\nse_pool","1280a952":"upper = round(d_hat + 1.96*se_pool, 4)\nlower = round(d_hat- 1.96*se_pool, 4)","300bb11b":"plt.rcParams.update({'font.size': 16})\nx = [lower, d_hat, upper]\ny = [0,0,0]\n\nplt.plot(x, y, '-o')\nfor xx,yy in zip(x,y):\n    plt.annotate(xx, # this is the text\n                 (xx,yy), # this is the point to label\n                 textcoords=\"offset points\", # how to position the text\n                 xytext=(0,10), # distance from text to points (x,y)\n                 ha='center') # horizontal alignment can be left, right or center\n    \nplt.title('Confidence interval for $d = {} $'.format(d_hat))\n\nplt.axis('off')\nplt.show()","c80e18d5":"d_hat = round(total_eval['Experiment']['Payments']\/total_eval['Experiment']['Clicks'] - total_eval['Control']['Payments']\/total_eval['Control']['Clicks'], 5)\nd_hat","af42ca9d":"nc_pool = round((total_eval['Experiment']['Payments']+total_eval['Control']['Payments'])\/(total_eval['Experiment']['Clicks']+total_eval['Control']['Clicks']), 6)\nnc_pool","4f7b0a6f":"se_pool = round(math.sqrt(nc_pool*(1-nc_pool)*(1\/total_eval['Control']['Clicks']+1\/total_eval['Experiment']['Clicks'])), 6)\nse_pool","27ab5519":"upper = round(d_hat + 1.96*se_pool, 4)\nlower = round(d_hat- 1.96*se_pool, 4)","8e6b5108":"plt.rcParams.update({'font.size': 16})\nx = [lower, d_hat, upper]\ny = [0,0,0]\n\nplt.plot(x, y, '-o')\nfor xx,yy in zip(x,y):\n    plt.annotate(xx, # this is the text\n                 (xx,yy), # this is the point to label\n                 textcoords=\"offset points\", # how to position the text\n                 xytext=(0,10), # distance from text to points (x,y)\n                 ha='center') # horizontal alignment can be left, right or center\n    \nplt.title('Confidence interval for $d = {} $'.format(d_hat))\n\nplt.axis('off')\nplt.show()","9c8d9bbe":"round(stats.binom_test(4, n=23, p=0.5, alternative='two-sided'), 5)","dd0a3acd":"round(stats.binom_test(10, n=23, p=0.5, alternative='two-sided'), 5)","6d340e4d":"#### 6.2 Net conversion\nHypothesis formulation for net conversion: \n\n>$H_0$: $NC_\\text{exp} = NC_\\text{cont}$ <br>\n>$H_1$: $NC_\\text{exp} \u2260 NC_\\text{cont}$ <br><br>\n\nand the practical significant difference between $NC_{exp}$ and $NC_{cont}$ is $d_{min} = 0.0075$. The observed difference is:\n\n$\\hat{d} = NC_{exp} - NC_{cont}$ = $\\frac{N_{pay-exp}}{NCL_{exp}} - \\frac{N_{pay-cont}}{NCL_{cont}} $","d073bd34":"## 7. Conclusions\nWe evaluated the change on the e-learning website in form of adding additional question to the sign up process. As the evaluation metrics we have choosen gross conversion $\\text{GC = } \\frac{\\text{N of users enrolled in free trial}}{\\text{NCL}}$ and net conversion $\\text{NC = } \\frac{\\text{N of users payed}}{\\text{NCL}}$. The experiment led to a statistically significant reduction of gross conversion metric, and caused no statistically significant change in the net conversion metric. Based on that, the tested change to the sign up process on the e-learning webpage should not be launged. ","8bffeb9a":"## 2. Formulating the hypothesis\n\n*Null hypothesis* $H_0$: experiment group is NOT significantly different from the control group in a certain success metric.<br>\n*Alternative hypothesis* $H_1$: experiment group differs significantly from the control group in a certain success metric. \nNow let's formalize it for each evaluation metrics:\n>$H_0$: $GC_\\text{exp} = GC_\\text{cont}$ <br>\n>$H_1$: $GC_\\text{exp} \u2260 GC_\\text{cont}$ <br><br>\n>$H_0$: $R_\\text{exp} = R_\\text{cont}$ <br>\n>$H_1$: $R_\\text{exp} \u2260 R_\\text{cont}$ <br><br>\n>$H_0$: $NC_\\text{exp} = NC_\\text{cont}$ <br>\n>$H_1$: $NC_\\text{exp} \u2260 NC_\\text{cont}$ <br>\n\n","48d1c0b1":"Total (pooled) net convergence:\n\n$GC_{pool} = \\frac{N_{pay-exp}+N_{pay-cont}}{NCL_{exp}+NCL_{cont}}$","df42b468":"The practical significant difference between $GC_{exp}$ and $GC_{cont}$ is $d_{min} = 0.01$. The observed difference is:\n\n$\\hat{d} = GC_{exp} - GC_{cont}$ = $\\frac{N_{enr-exp}}{NCL_{exp}} - \\frac{N_{enr-cont}}{NCL_{cont}} $","548f8a73":"Then the standard deviation is:","436dbd9d":"We see that our observed difference $\\hat{d} = 0.0001$ lies within obtained confidence interval, therefore \n\n>*Sanity check 3:* $CTP_{exp} \\approx CTP_{cont}$ *passed*","ff155461":"Let's summarize metrics in a table:\n\n|Metric                   | Metric formula                                       | Practical significance level$d_{min}$|\n|------------------------ | -------------------------------------------------------------|-------------------------------|\n|Gross conversion         | $\\text{GC = } \\frac{\\text{N of users enrolled in free trial}}{\\text{NCL}}$ |      0.01   |\n|Net conversion           | $\\text{NC = }\\frac{\\text{N of users paid}}{\\text{NCL}}$        |  0.0075  |    \n|Retention               |  $\\text{R = }\\frac{\\text{N of users paid}}{\\text{N of users enrolled in free trial}}$ | 0.01   | \n|Number of cookies       |  $\\text{C = N of unique daily cookies that viewed course overview page}$ |3000|\n|Number of clicks        | $\\text{NCL = N of unique cookies to click the \"Start free trial button\"}  $| 240|\n|Click-through probability| $\\text{CTP = } \\frac{\\text{NCL}}{\\text{C}} $   | 0.01|","cf08e40c":"Audacity wouldn't want to spend that long time running the experiment, so we have to figure out how to reduce the number of days. At this point we see that retention metric requires unfeasible duration time of the experiment, therefore we might want to exclude the retention metric from our analysis.   ","f723a05c":"## 6. Hypothesis test\n\n#### 6.1 Gross conversion\nNow it is time to analyse the effect of the experiment by looking at our evaluation metrics - gross and net conversion. Recall our hypothesis formulation for gross conversion: \n\n>$H_0$: $GC_\\text{exp} = GC_\\text{cont}$ <br>\n>$H_1$: $GC_\\text{exp} \u2260 GC_\\text{cont}$ <br><br>\n\n","6a80312d":"We can see that probability of a click being assigned to the control group $p = 0.5005$, obtained from the data, lies within this confidence interval, therefore:<br>\n>*Sanity check 2:* $NCL_{exp} \\approx NCL_{cont}$ *passed*","e6b09c4d":">Our confidence interval includs zero, therefore our difference $NC_{exp} - NC_{cont}$ could be pottentially zero and therefore observed difference is *not statistically significant*. <br>\n>Our confidence interval does not include our practical significance level for net conversion $d_{min} = 0.0075$, hovewer, it includes zero and $\\hat{d}$ could be potentially zero, therefore the change in metric obesrved is *not practically significant*.<br>\n>Thus we accept the *Null Hypothesis*: experiment group is *not significantly different* from the control group in net conversion metric.\n\n","bc0e3eee":"Since the enrollments and the payments data is only till 2 Nov. , we will limit clicks data till that time inclusively, too.","98b61588":"Hovewer it makes sence to reduce the trafic exposure. We still might not roll out this questioning feature at the end, so we don't really want all users to be exposed to this feature. Let's find the compromise between number of days and the trafic percentage. We will consider range between 40 and 60 percent of the trafic. ","81bff430":"50% of the trafic gives 34 days:","2d958e1a":"Udacity askes us to find number cookies viewed the page that would give enough power to run the experiment, for both experiment and control group. The numbers we have found hovewer correspond to unit of analysis of our evaluation metrics: *click* for gross and net conversion, and *enrollment*, or *user-id* for retention. We need to convert the sample sizes we have got into the number of cookies, or unique pageviews. \n\nRelationship \"click-cookie\" we know from click-through probability: $\\text{CTP = } \\frac{\\text{NCL}}{\\text{C}} \\text{= 0.08} $. From here we can get the number of cookies as $\\text{C = } \\frac{\\text{NCL}}{\\text{0.08}} $. Then we need to multiply this by 2, since we have experimental and control groups. So the final fomula for the number of cookies requered to run the experiment is: <br>\n<center><i>$N_C = \\frac{NCL}{\\text{0.08}}*2 $<\/i><\/center><br>\n\nTo convert enrollments into cookies, we will use probability of enrolling given cookie visited the homepage: $p = \\frac{\\text{N of users enrolled}}{\\text{C}} = 0.0165$. Then number of cookies is $C = \\frac{\\text{N of users enrolled}}{0.0165}$. Finaly we need to multiply it by 2 since we have 2 groups: experiemt and control. The final formula for the number of cookies requiered to run the experiemnt is: <br>\n<center><i>$N_C = \\frac{\\text{N of users enrolled}}{0.0165}*2$<\/i><\/center><br>\n\nLet's update our dictionary according to the formulas we've just got: \n","0836ce69":"Note that the baseline values are provided for the number of cookies equal to 40000, and we are asked to estimate the variance for the sample size of 5000 cookies visiting the homepage, so we need to **skale** those baselines. ","42956dc2":"Pooled standard error: $SE_{pool} = \\sqrt{\\hat{GC}_{pool}(1-\\hat{GC}_{pool})(\\frac{1}{NCL_{cont}} + \\frac{1}{NCL_{exp}})}$","67713377":"Let's do the same for the net conversion. Hypothesis formulation for net conversion:\n>$H_0$: $NC_\\text{exp} = NC_\\text{cont}$ <br>\n>$H_1$: $NC_\\text{exp} \u2260 NC_\\text{cont}$ <br><br>\n\nOut of 23 days of experiment, the change $NC_{exp} - NC_{cont}$ is positive on 10 days, and negative on 13 days. Assuming the Null Hypethesis is true, there is 50% chance that NC will be higher in the experimental group, and 50% chance that it will be lower. \nThus we need to find probability that there will be > 10 successes, or < 13 successes in 23 trials. We will use two-sided binomial test from scipy, with number of successes = 10, number of trials = 23, and probability of success = 0.5. ","dcd965eb":"## 4. Choosing duration and exposure\n\nFrom baselines table we know that average number of unique visitors to the page is 40000. Then the number of days required to run the experiment will be:","43dc1933":"As a compromise we choose 60% of the trafic and 29 days exposure time. ","ae99e973":"Pooled standard error: $SE_{pool} = \\sqrt{\\hat{p}_{pool}(1-\\hat{p}_{pool})(\\frac{1}{C_{cont}} + \\frac{1}{C_{exp}})}$","4359c3ae":"Total (pooled) gross convergence - number of enrolled users divided by number of clicks for both experiment and control group:\n\n$GC_{pool} = \\frac{N_{enr-exp}+N_{enr-cont}}{NCL_{exp}+NCL_{cont}}$","53a501c9":"Margin of error: $ME = z*SE_{pool}$, and with $z=1.96$ for 95% confidence level we get the lower and the upper bound of confidence interval:","d73553e1":"60% of trafic results in 29 days:","d0a8fdc3":"#### 6.4 Sign Test\nAdditionally Udacity suggests to run Sign-test. We have 23 days of experiment. Out of this 23 days, the change $GC_{exp} - GC_{cont}$ is positive on 4 days, and negative on 19 days. \nHypothesis formulation for gross conversion: \n\n>$H_0$: $GC_\\text{exp} = GC_\\text{cont}$ <br>\n>$H_1$: $GC_\\text{exp} \u2260 GC_\\text{cont}$ <br><br>\n\nAssuming the Null Hypethesis is true, there is 50% chance that GC will be higher in the experimental group, and 50% chance that it will be lower. \nThus we need to find probability that there will be > 4 successes, or < 19 successes in 23 trials. We will use two-sided binomial test from scipy, with number of successes = 4, number of trials = 23, and probability of success = 0.5. We will set our threshold probability $\\alpha = 0.05$ - probability to falsly reject the Null Hypothesis when it is true. ","b0a0ea00":"## 5. Sanity checks\n\nPreviously we have chosen **number of cookies**, **number of clicks** and **click-through-probability** as *invariant metrics* that shouldn't change when we run our experiment, and should remain the same in both groups. Let's check whether they are equal for the experiment and control group. \nHere are csv tables with our results:","f7b67fa1":"Total (pooled) probability of a click:\n\n$\\hat{p}_{pool} = \\frac{NCL_{exp}+NCL_{cont}}{C_{exp}+C_{cont}}$","ee56a692":"Margin of error: $ME = z*std dev$, and with $z=1.96$ for 95% confidence level we get the lower and the upper bound of confidence interval:","a53d2470":"**Sanity check 3:** $CTP_{exp} \\approx CTP_{cont}$ <br>\n\nHere we cannot use the same method like for clicks and cookies, since the metric is more complex. We will compare actual difference between click-through probabilities for experimental and control group $\\frac{NCL_{exp}}{C_{exp}} $ and $\\frac{NCL_{cont}}{C_{cont}} $.\n\nOur observed difference in CTP between experiment and control group is:\n\n$\\hat{d} = \\hat{p}_{exp} - \\hat{p}_{cont}$ = $\\frac{NCL_{exp}}{C_{exp}} - \\frac{NCL_{cont}}{C_{cont}} $","082921b7":">Audacity - the online learning platform - currently have two options of sign-up:\"start free trial\", and \"access course materials\". If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first. If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.<br><br>\nIn the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead.<br><br>\nThe hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough time\u2014without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.","db885b00":"## 1. Choosing metrics for our experiment\n*Evaluation metrics* - those that will be affected by the change and thus will be used to measure the impact of the change: <br>\n>**Gross conversion** - number of user-ids to complete check-out and enroll in the free trial divided by of unique cookies to click the \"start free trial\" button. <br>\n>**Net conversion** - number of user-ids to remain enrolled past the 14-days boundary (thus make at least one payment) divided by the number of unique cookies that clicked \"start free trial button\" button.<br>\n>**Retention** - number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids enrolled in free trial.\n\n*Invariant metrics* - those that shouldn't be affected by the change und thus will be used for sanity checks: <br>\n>**Number of cookies** - number of unique cookies to view the course overview page.<br>\n>**Number of clicks** - number of unique cookies to click the \"Start free trial button\" (appears before queastion screen is triggered).<br>\n>**Click-through-probability** - number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page.","430722ef":">Our confidence interval does not include zero, therefore we can be sure that the difference $GC_{exp} - GC_{cont}$ is not zero and it is *statistically significant*. <br>\n>Our confidence interval does not include our practical significance level for gross conversion $d_{min} = 0.01$, so we can be sure that the difference $GC_{exp} - GC_{cont}$ cannot be smaller than $d_{min}$ and our experiment gave *practically significant* change in metric of interest. In fact, our change significantly *reduced* gross conversion. <br>\n>Thus we reject the *Null Hypothesis*, and accept the alternative one: there is a *statistically significant difference* between experiment and control group in the gross conversion metric. \n\n","0f787730":"Since we have not that many numbers, let's summarize them all in a dictionary:","25e9570f":"In order to estimate variability **analitically**, we need to make assumptions about the **distribution** of the data. For metrics like probabilities, we can assume that the data is **normally distributed**. We can also say that gross conversion is a probability of enrolling, given click; retention - probability of payment, given enroll; net conversion - probability of payment, given click. Thus, the analytically estimated variance will be expressed as following:<br><br>\n<center><i>$\\text{Var = }\\frac{\\text{p(1-p)}}{\\text{N}}$<\/i><\/center>\nAnd standard deviation is: <br>\n<center><i>$\\text{std dev = }\\sqrt{\\frac{\\text{p(1-p)}}{\\text{N}}}$<\/i><\/center>","2c17ee03":"Now the number of days for our experiment with 100% trafic exposure is:","381798dc":"Is this value within the expectation range for probabilities? Let's find out the confidence interval for the 95% confidence level. We can assume binomial distribution with probability of success = 0.5.\n\nNormality condition to assume Binomial distribution: $np\\geq 10$ and $n(1-p)\\geq10$","09ceed09":"Our theorethical d should be 0, as we expect CTP to be equal for both experimental and control group:","1df1a620":"**Sanity check 1:** $C_{exp} \\approx C_{cont}$ <br>\n\nWe found that the number of pageviews and clicks for the control and experimental group are similar but not exactly equal: the difference in pageviews is 883 and in clicks - 53. Ideally the probability that a cookie is assigned either to control or experiment group is 0.5. In our case probability of a cookie being assigned to control group is:","a6993263":"**Sanity check 2:** $NCL_{exp} \\approx NCL_{cont}$ <br>\n\nLet's do the same for number of clicks. Ideally the probability that a click is assigned either to control or experiment group is 0.5. In our case probability of a click being assigned to control group is:","225706e2":"![fig2cut.png](attachment:fig2cut.png)\n<center><i>Fig. 1: Chema of the experiment<\/i><\/center>","f8892cec":"Pooled standard error: $SE_{pool} = \\sqrt{\\hat{GC}_{pool}(1-\\hat{GC}_{pool})(\\frac{1}{NCL_{cont}} + \\frac{1}{NCL_{exp}})}$","5dfdd7a4":"## 3. Determining variability and calculating experiment sizing\n### 3.1 Variability of the metrics\nIn order to later find out how many pageviews are needed to get enough power per experiment and control group, we need to know how variable are the evaluation metrics, since variability has large effect on experiment sizing. Udacity askes us determine variance of evaluation metrics for the sample size of 5000 cookies visiting the cookies overview page, and provides us with these baseline values:\n\n| Metric | Baseline (provided by Udacity)  | \n|--------------------|----------------|\n|Unique cookies to view course overview page per day: |40000  |\n|  Unique cookies to click \"Start free trial\" per day: | 3200  |\n| Enrollments per day:  |  660 |\n| Click-through-probability on \"Start free trial\":  | 0.08  |\n|    Probability of enrolling, given click: |     0.20625       |\n| Probability of payment, given enroll: |       0.53        |\n| Probability of payment, given click:   |    0.1093125         |\n","8835456e":"Standard deviation: $std dev = \\sqrt{\\frac{p(1-p)}{N}}$","ebffb7f6":"Margin of error: $ME = z*SE_{pool}$, and with $z=1.96$ for 95% confidence level we get the lower and the upper bound of confidence interval:","b214ef05":">Our p-value is 0.0026, which is smaller than $\\alpha = 0.05$, therefore we reject the Null Hypothesis, and accept the alternative one: there is *a significant difference* between experimental and control group in gross conversion metric. ","12663e50":"Margin of error: $ME = z*std dev$, and with $z=1.96$ for 95% confidence level we get upper and lower bound of confidenece interval:","ccaa2176":"### 3.2 Determining experiment sample size\n\nLet's define:\n> $\\alpha$ - probability to falsly reject $H_0$, or Type I Error - as *0.05* <br>\n> $\\beta$ - probability to fail to reject $H_0$ when $H_0$ is false, or Type II Error - as *0.2*\n\nThe required sample size will depend on $\\alpha$, $\\beta$, our *practical significance value*, and baseline *conversion rate* for each evaluation metric. Let's use the online calculator from Evan Miller: https:\/\/www.evanmiller.org\/ab-testing\/sample-size.html \n\nHere is what we've got from the online calculator, given apha, beta, and baselines provided by Udacity for each metric - number of events, or subjects needed per group for each metric:","59b92063":">Our p-value is 0.67764, which is greater than $\\alpha = 0.05$, therefore we accept the Null Hypothesis: there is *no significant difference* between experimental and control group in net conversion metric. ","19414746":"Let's create a new dict for our estimated standard deviations, and calcualate them according to the formula above:","0a7d2c5a":"Margin of error: $ME = z*SE_{pool}$, and with $z=1.96$ for 95% confidence level we get the lower and the upper bound of confidence interval:","d75154f9":"Normality condition to assume Binomial distribution: $np\\geq 10$ and $n(1-p)\\geq10$","2c147d00":"# A\/B Test: Udacity course final project","7b09842b":"We can see that probability of a cookie being assigned to the control group $p = 0.5006$, obtained from the data, lies within this confidence interval, therefore:<br>\n>*Sanity check 1:* $C_{exp} \\approx C_{cont}$ *passed*","cf518a26":"## 1. Task description (provided by Udacity): ","cc3684d3":"Defining the scaling factor:","ea90ba1e":"In order to have better overview, let's organize a chema of the experiment (Fig. 1):","bca243b8":"Now let's update the count values with the scaling factor:","ea5cc069":"40% of the trafic results in 43 days:","46356847":"Let's organize a dict with baseline values for each metric:","cdaa1c6b":"Those are the sample sizes requered for each metric in order to get enough statistical power and get consistent results for our experiment. In order to be able to test all three metrics and their corresponding hypothesis, we would require a sample size of:"}}