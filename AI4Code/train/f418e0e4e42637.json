{"cell_type":{"698d0c27":"code","b06c915d":"code","60cca6aa":"code","ac20ed9b":"code","2ebbda69":"code","babbb954":"code","993473e6":"code","a7970b4d":"code","8ca11352":"code","8787ae33":"code","a9887acd":"code","5989d582":"code","ccd680c3":"code","e85977fd":"code","f00bd8e1":"code","2645688d":"code","a28e288e":"code","5a00916a":"code","21616ddc":"markdown","5d211183":"markdown","43bd8a06":"markdown","52cad67a":"markdown","e22a4e8d":"markdown","9d34d8ed":"markdown","5902d68f":"markdown","1568e88a":"markdown","7c4fb4ce":"markdown"},"source":{"698d0c27":"# Carregando os pacotes\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Statistic lib\nfrom scipy import stats\nfrom scipy.stats import skew, norm\n\n# Sklearn lib\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\n\n# Utils\nimport pandasql as ps\nimport re \nimport math, string, os\nimport datetime\n\n# Options\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_seq_items = 200\npd.options.display.max_rows = 200\npd.set_option('display.max_columns', None)\nimport gc\ngc.enable()\n\n# Variavel para controlar o treinamento no Kaggle\nTRAIN_OFFLINE = False","b06c915d":"def read_data():\n    \n    if TRAIN_OFFLINE:\n        print('Carregando arquivo dataset_treino.csv....')\n        train = pd.read_csv('..\/dataset\/dataset_treino.csv')\n        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n        \n        print('Carregando arquivo dataset_teste.csv....')\n        test = pd.read_csv('..\/dataset\/dataset_teste.csv')\n        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n        \n        \n        print('Carregando arquivo sample_submission.csv....')\n        sample_submission = pd.read_csv('..\/dataset\/sample_submission.csv')\n        print('sample_submission.csv tem {} linhas and {} colunas'.format(sample_submission.shape[0], sample_submission.shape[1]))\n    else:\n        print('Carregando arquivo dataset_treino.csv....')\n        train = pd.read_csv('\/kaggle\/input\/competicao-dsa-machine-learning-dec-2019\/dataset_treino.csv')\n        print('dataset_treino.csv tem {} linhas and {} colunas'.format(train.shape[0], train.shape[1]))\n        \n        print('Carregando arquivo dataset_treino.csv....')\n        test = pd.read_csv('\/kaggle\/input\/competicao-dsa-machine-learning-dec-2019\/dataset_teste.csv')\n        print('dataset_teste.csv tem {} linhas and {} colunas'.format(test.shape[0], test.shape[1]))\n\n        print('Carregando arquivo dataset_treino.csv....')\n        sample_submission = pd.read_csv('\/kaggle\/input\/competicao-dsa-machine-learning-dec-2019\/sample_submission.csv')\n        print('sample_submission.csv tem {} linhas and {} colunas'.format(sample_submission.shape[0], sample_submission.shape[1]))\n    \n    return train, test, sample_submission","60cca6aa":"# Leitura dos dados\ntrain, test, sample_submission = read_data()","ac20ed9b":"# Visualizando os primeiros registros do dataset\ntrain.head()","2ebbda69":"# Visualizando os tipos das features\ntrain.dtypes","babbb954":"# Visualizando dados estatisticos das variaveis numericas\ntrain.describe().T","993473e6":"def percent_missing(df):\n    data = pd.DataFrame(df)\n    df_cols = list(pd.DataFrame(data))\n    dict_x = {}\n    for i in range(0, len(df_cols)):\n        dict_x.update({df_cols[i]: round(data[df_cols[i]].isnull().mean()*100,2)})\n    \n    return dict_x","a7970b4d":"# Verificando as colunas com dados missing do dataset de treino\nmissing = percent_missing(train)\ndf_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\nprint('Percent of missing data')\ndf_miss[0:133]","8ca11352":"# Setup do plot\nsns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(18, 16))\nsns.set_color_codes(palette='deep')\n\n# Identificando os valores missing\nmissing = round(train.isnull().mean()*100,2)\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar(color=\"b\")\n\n# Visual presentation\nax.xaxis.grid(False)\nax.set(ylabel=\"Percent of missing values\")\nax.set(xlabel=\"Features\")\nax.set(title=\"Percent missing data by feature\")\nsns.despine(trim=True, left=True)","8787ae33":"# Funcao para tratar os dados missing de cada variavel\ndef fill_na(data):\n    data.fillna(data.mean(),inplace=True)","a9887acd":"# Funcao para criar um plot de distribuicao para cada feature\ndef plot_distribution(dataset, cols=5, width=20, height=25, hspace=0.4, wspace=0.5):\n\n    plt.style.use('fivethirtyeight')\n    fig = plt.figure(figsize=(width, height))\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n\n    rows = math.ceil(float(dataset.shape[1]) \/ cols)\n\n    for i, column in enumerate(dataset.columns):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.set_title(column)\n        if dataset.dtypes[column] == np.object:\n\n            g = sns.countplot(y=column, \n                              data=dataset,\n                              order=dataset[column].value_counts().index[:10])\n\n            substrings = [s.get_text()[:20] for s in g.get_yticklabels()]\n            g.set(yticklabels=substrings)\n            plt.xticks(rotation=25)\n        else:\n            g = sns.distplot(dataset[column])\n            plt.xticks(rotation=25)","5989d582":"# Primeiro, vou preencher os dados missing com a media (apenas para iniciar as analises)\nfill_na(train)","ccd680c3":"# Correla\u00e7\u00e3o de Pearson\ncor_mat = train.corr(method = 'pearson')\n\n# Visualizando o grafico de heatmap\nf, ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(cor_mat,linewidths=.1,fmt= '.3f',ax=ax,square=True,cbar=True,annot=False)","e85977fd":"# Descricao: \u00e9 igual a 1 para indeniza\u00e7\u00f5es que podem ser aprovadas rapidamente.\ntrain['target'].describe()","f00bd8e1":"# Analisando a variavel target\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(12, 6))\n\n# Fit da distribuicao normal\nmu, std = norm.fit(train[\"target\"])\n\n# Verificando a distribuicao de frequencia da variavel target\nsns.distplot(train[\"target\"], color=\"b\", fit = stats.norm)\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"Target\")\nax.set(title=\"Target distribution: mu = %.2f,  std = %.2f\" % (mu, std))\nsns.despine(trim=True, left=True)\n\n# Adicionando Skewness e Kurtosis\nax.text(x=1.1, y=1, transform=ax.transAxes, s=\"Skewness: %f\" % train[\"target\"].skew(),\\\n        fontweight='demibold', fontsize=10, verticalalignment='top', horizontalalignment='right',\\\n        backgroundcolor='white', color='xkcd:poo brown')\nax.text(x=1.1, y=0.95, transform=ax.transAxes, s=\"Kurtosis: %f\" % train[\"target\"].kurt(),\\\n        fontweight='demibold', fontsize=10, verticalalignment='top', horizontalalignment='right',\\\n        backgroundcolor='white', color='xkcd:dried blood')\n\nplt.show()","2645688d":"# Existe um problema de desbalanceamento de classes, ou seja, volume maior de um dos tipos de classe. \n# Podemos ver abaixo que existe uma clara despropor\u00e7\u00e3o \n# Apenas 23% sao indenizacoes que nao podem ser aprovadas rapidamente\n\n# Visualizando a distribui\u00e7\u00e3o das classes (variavel TARGET)\npd.value_counts(train['target']).plot.bar()\nplt.title('TARGET histogram')\nplt.xlabel('TARGET')\nplt.ylabel('Frequency')\n\n# Visualizando um df com quantidade e percentual da variavel TARGET\ndf = pd.DataFrame(train['target'].value_counts())\ndf['%'] = 100*df['target']\/train.shape[0]\ndf","a28e288e":"# Primeiro, vamos remover a coluna ID\ntrain.drop(['ID'], axis=1, inplace=True)","5a00916a":"# Visualizando o grafico de distribuicao para cada feature (sao 132, entao \u00e9 s\u00f3 uma amostra)\n# Cada linha contem 6 features\ncolumns_to_plot = []\n\nfor column in train:\n    columns_to_plot.append(column)\n\nplot_distribution(train[columns_to_plot], cols=6, width=100, height=100, hspace=1, wspace=1)","21616ddc":"# Criando as fun\u00e7\u00f5es auxiliares de limpeza e conversao","5d211183":"# 1. ANALISE GERAL","43bd8a06":"# Analisando Correlacoes","52cad67a":"# 2. DATA MISSING","e22a4e8d":"# Resolvendo missing values e realizando limpeza das features","9d34d8ed":"### Analisando a variavel target","5902d68f":"# 3. Analisando todas as features do dataset","1568e88a":"# Kaggle\n## Competi\u00e7\u00e3o DSA de Machine Learning - Dezembro 2019\n\n## EDA Notebook v.1.0.0\n\n#### Upvote se esse notebook for util","7c4fb4ce":"### Analisando as demais vari\u00e1veis"}}