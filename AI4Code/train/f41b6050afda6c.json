{"cell_type":{"87cd67b1":"code","51d927fd":"code","d1692b8d":"code","882bc21e":"code","0e29051a":"code","683b94d9":"code","d7c19e4a":"code","fc387e3f":"code","5a151dec":"code","30284c67":"code","3c833954":"code","8fc3e3f6":"code","07075859":"markdown","d6e9d169":"markdown","989a1078":"markdown","84aaecd9":"markdown","b2ae7c72":"markdown"},"source":{"87cd67b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51d927fd":"import warnings\nwarnings.filterwarnings(\"ignore\")","d1692b8d":"import numpy as np\nimport pandas as pd\n\n# -----------------------------------\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\n# -----------------------------------\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u7279\u5fb4\u91cf\u3068\u76ee\u7684\u5909\u6570\u306b\u5206\u3051\u308b\ntrain_x = train.drop(['Survived'], axis=1)\ntrain_y = train['Survived']\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306f\u7279\u5fb4\u91cf\u306e\u307f\u306a\u306e\u3067\u3001\u305d\u306e\u307e\u307e\u3067\u3088\u3044\ntest_x = test.copy()\n\n# -----------------------------------\n# \u7279\u5fb4\u91cf\u4f5c\u6210\n# -----------------------------------\nfrom sklearn.preprocessing import LabelEncoder\n\n# \u5909\u6570PassengerId\u3092\u9664\u5916\u3059\u308b\ntrain_x = train_x.drop(['PassengerId'], axis=1)\ntest_x = test_x.drop(['PassengerId'], axis=1)\n\n# \u5909\u6570Name, Ticket, Cabin\u3092\u9664\u5916\u3059\u308b\ntrain_x = train_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\ntest_x = test_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n\n# \u305d\u308c\u305e\u308c\u306e\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u306blabel encoding\u3092\u9069\u7528\u3059\u308b\nfor c in ['Sex', 'Embarked']:\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u57fa\u3065\u3044\u3066\u3069\u3046\u5909\u63db\u3059\u308b\u304b\u3092\u5b9a\u3081\u308b\n    le = LabelEncoder()\n    le.fit(train_x[c].fillna('NA'))\n\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u5909\u63db\u3059\u308b\n    train_x[c] = le.transform(train_x[c].fillna('NA'))\n    test_x[c] = le.transform(test_x[c].fillna('NA'))","882bc21e":"train_x","0e29051a":"train_y","683b94d9":"# -----------------------------------\n# \u30e2\u30c7\u30eb\u4f5c\u6210\n# -----------------------------------\nfrom xgboost import XGBClassifier\n\n# \u30e2\u30c7\u30eb\u306e\u4f5c\u6210\u304a\u3088\u3073\u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u4e0e\u3048\u3066\u306e\u5b66\u7fd2\nmodel = XGBClassifier(n_estimators=20, random_state=71)\nmodel.fit(train_x, train_y)\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u5024\u3092\u78ba\u7387\u3067\u51fa\u529b\u3059\u308b\npred = model.predict_proba(test_x)[:, 1]\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u5024\u3092\u4e8c\u5024\u306b\u5909\u63db\u3059\u308b\npred_label = np.where(pred > 0.5, 1, 0)\n\n# \u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\nsubmission.to_csv('submission_first.csv', index=False)","d7c19e4a":"#\u672a\u77e5\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u3059\u308b\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\u3002\n# -----------------------------------\n# \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\n# -----------------------------------\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import KFold\n\n# \u5404fold\u306e\u30b9\u30b3\u30a2\u3092\u4fdd\u5b58\u3059\u308b\u30ea\u30b9\u30c8\nscores_accuracy = []\nscores_logloss = []\n\n# \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3046\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u30924\u3064\u306b\u5206\u5272\u3057\u3001\u3046\u30611\u3064\u3092\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3068\u3059\u308b\u3053\u3068\u3092\u3001\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3092\u5909\u3048\u3066\u7e70\u308a\u8fd4\u3059\nkf = KFold(n_splits=4, shuffle=True, random_state=71)\nfor tr_idx, va_idx in kf.split(train_x):\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306b\u5206\u3051\u308b\n    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n    # \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u884c\u3046\n    model = XGBClassifier(n_estimators=20, random_state=71)\n    model.fit(tr_x, tr_y)\n\n    # \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c\u5024\u3092\u78ba\u7387\u3067\u51fa\u529b\u3059\u308b\n    va_pred = model.predict_proba(va_x)[:, 1]\n\n    # \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3067\u306e\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3059\u308b\n    logloss = log_loss(va_y, va_pred)\n    accuracy = accuracy_score(va_y, va_pred > 0.5)\n\n    # \u305d\u306efold\u306e\u30b9\u30b3\u30a2\u3092\u4fdd\u5b58\u3059\u308b\n    scores_logloss.append(logloss)\n    scores_accuracy.append(accuracy)\n\n# \u5404fold\u306e\u30b9\u30b3\u30a2\u306e\u5e73\u5747\u3092\u51fa\u529b\u3059\u308b\nlogloss = np.mean(scores_logloss)\naccuracy = np.mean(scores_accuracy)\nprint(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')","fc387e3f":"#accuracy\u304c0.8182\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308b","5a151dec":"# -----------------------------------\n# \u30e2\u30c7\u30eb\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\n# -----------------------------------\nimport itertools\n\n# \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u5019\u88dc\u3068\u3059\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6e96\u5099\u3059\u308b\nparam_space = {\n    'max_depth': [3, 5, 7],\n    'min_child_weight': [1.0, 2.0, 4.0]\n}\n\n# \u63a2\u7d22\u3059\u308b\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7d44\u307f\u5408\u308f\u305b\nparam_combinations = itertools.product(param_space['max_depth'], param_space['min_child_weight'])\n\n# \u5404\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7d44\u307f\u5408\u308f\u305b\u3001\u305d\u308c\u306b\u5bfe\u3059\u308b\u30b9\u30b3\u30a2\u3092\u4fdd\u5b58\u3059\u308b\u30ea\u30b9\u30c8\nparams = []\nscores = []\n\n# \u5404\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7d44\u307f\u5408\u308f\u305b\u3054\u3068\u306b\u3001\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3067\u8a55\u4fa1\u3092\u884c\u3046\nfor max_depth, min_child_weight in param_combinations:\n\n    score_folds = []\n    # \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3046\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u30924\u3064\u306b\u5206\u5272\u3057\u3001\u3046\u30611\u3064\u3092\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3068\u3059\u308b\u3053\u3068\u3092\u3001\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3092\u5909\u3048\u3066\u7e70\u308a\u8fd4\u3059\n    kf = KFold(n_splits=4, shuffle=True, random_state=123456)\n    for tr_idx, va_idx in kf.split(train_x):\n        # \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306b\u5206\u3051\u308b\n        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n\n        # \u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u884c\u3046\n        model = XGBClassifier(n_estimators=20, random_state=71,\n                              max_depth=max_depth, min_child_weight=min_child_weight)\n        model.fit(tr_x, tr_y)\n\n        # \u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u3067\u306e\u30b9\u30b3\u30a2\u3092\u8a08\u7b97\u3057\u3001\u4fdd\u5b58\u3059\u308b\n        va_pred = model.predict_proba(va_x)[:, 1]\n        logloss = log_loss(va_y, va_pred)\n        score_folds.append(logloss)\n\n    # \u5404fold\u306e\u30b9\u30b3\u30a2\u3092\u5e73\u5747\u3059\u308b\n    score_mean = np.mean(score_folds)\n\n    # \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u7d44\u307f\u5408\u308f\u305b\u3001\u305d\u308c\u306b\u5bfe\u3059\u308b\u30b9\u30b3\u30a2\u3092\u4fdd\u5b58\u3059\u308b\n    params.append((max_depth, min_child_weight))\n    scores.append(score_mean)\n\n# \u6700\u3082\u30b9\u30b3\u30a2\u304c\u826f\u3044\u3082\u306e\u3092\u30d9\u30b9\u30c8\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u3068\u3059\u308b\nbest_idx = np.argsort(scores)[0]\nbest_param = params[best_idx]\nprint(f'max_depth: {best_param[0]}, min_child_weight: {best_param[1]}')","30284c67":"# -----------------------------------\n# \u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u7528\u306e\u7279\u5fb4\u91cf\u306e\u4f5c\u6210\n# -----------------------------------\nfrom sklearn.preprocessing import OneHotEncoder\n\n# \u5143\u30c7\u30fc\u30bf\u3092\u30b3\u30d4\u30fc\u3059\u308b\ntrain_x2 = train.drop(['Survived'], axis=1)\ntest_x2 = test.copy()\n\n# \u5909\u6570PassengerId\u3092\u9664\u5916\u3059\u308b\ntrain_x2 = train_x2.drop(['PassengerId'], axis=1)\ntest_x2 = test_x2.drop(['PassengerId'], axis=1)\n\n# \u5909\u6570Name, Ticket, Cabin\u3092\u9664\u5916\u3059\u308b\ntrain_x2 = train_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\ntest_x2 = test_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n\n# one-hot encoding\u3092\u884c\u3046\ncat_cols = ['Sex', 'Embarked', 'Pclass']\nohe = OneHotEncoder(categories='auto', sparse=False)\nohe.fit(train_x2[cat_cols].fillna('NA'))\n\n# one-hot encoding\u306e\u30c0\u30df\u30fc\u5909\u6570\u306e\u5217\u540d\u3092\u4f5c\u6210\u3059\u308b\nohe_columns = []\nfor i, c in enumerate(cat_cols):\n    ohe_columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n\n# one-hot encoding\u306b\u3088\u308b\u5909\u63db\u3092\u884c\u3046\nohe_train_x2 = pd.DataFrame(ohe.transform(train_x2[cat_cols].fillna('NA')), columns=ohe_columns)\nohe_test_x2 = pd.DataFrame(ohe.transform(test_x2[cat_cols].fillna('NA')), columns=ohe_columns)\n\n# one-hot encoding\u6e08\u307f\u306e\u5909\u6570\u3092\u9664\u5916\u3059\u308b\ntrain_x2 = train_x2.drop(cat_cols, axis=1)\ntest_x2 = test_x2.drop(cat_cols, axis=1)\n\n# one-hot encoding\u3067\u5909\u63db\u3055\u308c\u305f\u5909\u6570\u3092\u7d50\u5408\u3059\u308b\ntrain_x2 = pd.concat([train_x2, ohe_train_x2], axis=1)\ntest_x2 = pd.concat([test_x2, ohe_test_x2], axis=1)\n\n# \u6570\u5024\u5909\u6570\u306e\u6b20\u640d\u5024\u3092\u5b66\u7fd2\u30c7\u30fc\u30bf\u306e\u5e73\u5747\u3067\u57cb\u3081\u308b\nnum_cols = ['Age', 'SibSp', 'Parch', 'Fare']\nfor col in num_cols:\n    train_x2[col].fillna(train_x2[col].mean(), inplace=True)\n    test_x2[col].fillna(train_x2[col].mean(), inplace=True)\n\n# \u5909\u6570Fare\u3092\u5bfe\u6570\u5909\u63db\u3059\u308b\ntrain_x2['Fare'] = np.log1p(train_x2['Fare'])\ntest_x2['Fare'] = np.log1p(test_x2['Fare'])","3c833954":"# -----------------------------------\n# \u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\n# -----------------------------------\nfrom sklearn.linear_model import LogisticRegression\n\n# xgboost\u30e2\u30c7\u30eb\nmodel_xgb = XGBClassifier(n_estimators=20, random_state=71)\nmodel_xgb.fit(train_x, train_y)\npred_xgb = model_xgb.predict_proba(test_x)[:, 1]\n\n# \u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\u30e2\u30c7\u30eb\n# xgboost\u30e2\u30c7\u30eb\u3068\u306f\u7570\u306a\u308b\u7279\u5fb4\u91cf\u3092\u5165\u308c\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u3067\u3001\u5225\u9014train_x2, test_x2\u3092\u4f5c\u6210\u3057\u305f\nmodel_lr = LogisticRegression(solver='lbfgs', max_iter=300)\nmodel_lr.fit(train_x2, train_y)\npred_lr = model_lr.predict_proba(test_x2)[:, 1]\n\n# \u4e88\u6e2c\u5024\u306e\u52a0\u91cd\u5e73\u5747\u3092\u3068\u308b\npred = pred_xgb * 0.8 + pred_lr * 0.2\npred_label = np.where(pred > 0.5, 1, 0)","8fc3e3f6":"submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\nsubmission.to_csv('submission_second.csv', index=False)","07075859":"# 3.\u3000Hyper Parameter Tuning","d6e9d169":"# 4. Ensemble Method","989a1078":"# 1. Create model","84aaecd9":"# 2. Cross Validation","b2ae7c72":"# 0. Preprocess Data"}}