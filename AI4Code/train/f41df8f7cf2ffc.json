{"cell_type":{"bdaa9644":"code","5feac825":"code","8961e870":"code","9284f1d3":"code","242d0182":"code","ac68e673":"code","4de07368":"code","1399ceea":"code","de99dabf":"code","1a5849b2":"code","05f658d9":"code","5d0dc255":"code","f74bb21c":"code","74c164f1":"code","1ff10f1e":"code","3d28e4b2":"code","cf43c0d3":"code","10e5c9cc":"code","ddc39d9e":"code","f885742c":"code","79808ee5":"code","07fb2cbf":"code","6bc0cdc4":"code","95ee137b":"code","70a4549d":"code","e7114b67":"code","827ea298":"code","fbdfecd0":"code","421d3a6c":"code","c2063efb":"code","6cc3ae3e":"code","10f915eb":"code","e4ee7aa5":"code","e6072683":"code","b54c928f":"code","3b1fe3b0":"code","f9944075":"code","3a16c464":"code","dde3a7ad":"code","11c9a152":"code","389c0467":"markdown","31e2d430":"markdown","7cf8da45":"markdown","574a24d3":"markdown","c3da67bf":"markdown","e8674cf0":"markdown","b9a96b48":"markdown","14acc6d7":"markdown"},"source":{"bdaa9644":"%config Completer.use_jedi = False","5feac825":"# Importing standard libraries\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pprint import pprint\nfrom glob import glob\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# Importing Libraries for Audio file reading\nimport soundfile as sf\nimport librosa\nimport librosa.display\nimport IPython.display as display\n\n# Importing Libraries to build the neural network\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence, plot_model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import *\n\n# For data preparation and model evaluation\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8961e870":"# Helper functions\ndef read_wav_file(path):\n    return sf.read(path)\n\ndef displayWaveform(data, sr):\n    plt.figure(figsize = (14, 5))\n    librosa.display.waveplot(data, sr = sr)\n    plt.grid()\n    plt.show()\n\ndef plot_spectrogram(data, sr):\n    spectrogram = librosa.feature.melspectrogram(data, sr)\n    log_spec = librosa.power_to_db(spectrogram, ref = np.max)\n    librosa.display.specshow(log_spectrogram, sr = sr, x_axis = 'time', y_axis = 'mel')\n    ","9284f1d3":"# CONFIG\nparams = {}\nparams['train_csv'] = '..\/input\/birdclef-2021\/train_soundscape_labels.csv'\nparams['test_csv'] = '..\/input\/birdclef-2021\/test.csv'\nparams['train_metadata'] = '..\/input\/birdclef-2021\/train_metadata.csv'\nparams['train_short_audio'] = '..\/input\/birdclef-2021\/train_short_audio'\nparams['train_soundscapes'] = '..\/input\/birdclef-2021\/train_soundscapes'\nparams['sample_csv'] = '..\/input\/birdclef-2021\/sample_submission.csv'\nparams['labels'] = '..\/input\/birdclef-2021\/train_soundscape_labels.csv'\nparams['test_soundscapes'] = \"..\/input\/birdclef-2021\/test_soundscapes\"\npprint(params)","242d0182":"# Reading csv files\ntrain_csv = pd.read_csv(params['train_csv'])\ntest_csv = pd.read_csv(params['test_csv'])\ntrain_meta = pd.read_csv(params['train_metadata'])\nsample_sub = pd.read_csv(params['sample_csv'])\ntrain_labels = pd.read_csv(params['labels'])","ac68e673":"train_csv.head(3)","4de07368":"train_labels.head(3)","1399ceea":"sample_sub.sample(3)","de99dabf":"train_meta.sample(3)","1a5849b2":"print(f\"Len of train data : {len(train_csv)}\")\nprint(f\"Len of test data : {len(test_csv)}\")\nprint(f\"Len of train meta : {len(train_meta)}\")\nprint(f\"Len of train labels : {len(train_labels)}\")","05f658d9":"# Lets hear some voices from soundscapes\nsoundscapes = glob(\"..\/input\/birdclef-2021\/train_soundscapes\/*.ogg\")\n\ndisplay.Audio(soundscapes[np.random.randint(len(soundscapes))])","5d0dc255":"# Lets hear some short sounds\nshort_sounds = glob(\"..\/input\/birdclef-2021\/train_short_audio\/*\/*.ogg\")\n\ndisplay.Audio(short_sounds[np.random.randint(len(short_sounds))])","f74bb21c":"# Distribution of labels\nfig = px.histogram(train_labels, x = 'birds', color = 'birds')\nfig.update_layout(\n    title = 'Distribution of Birds calls\/labels',\n    title_x = 0.5\n)\nfig.show()","74c164f1":"# Distribution of audio_ids\ntrain_labels.groupby(by=['audio_id']).count()['birds']","1ff10f1e":"train_labels","3d28e4b2":"# There are labels with multiplt birds list in them\n# Lets list down unique labels first and observe their count\n\nuniq_labels = []\nfor bs in train_labels['birds'].values:\n    uniq_labels += bs.split()\n\n# '-1' for \"no call\"\nprint(f\"Num of unique birds : {len(set(uniq_labels)) - 1}\")\nfig = px.histogram(uniq_labels, color = uniq_labels)\nfig.show();\n\n# Finally storing only unique values\nuniq_labels = list(set(uniq_labels))","cf43c0d3":"df_train_labels = pd.DataFrame(\n    index = train_labels.index,\n    columns = uniq_labels\n)\n\nfor row in train_labels.index:\n    birds = train_labels.loc[row, 'birds'].split()\n    for bird in birds:\n        df_train_labels.loc[row, bird] = 1\n        \ndf_train_labels.fillna(0, inplace = True)\n\ntest_csv['birds'] = 'nocall'\n\ndf_test_labels = pd.DataFrame(index = test_csv.index,\n                              columns = uniq_labels)\nfor row in test_csv.index:\n    birds = test_csv.loc[row, 'birds'].split()\n    for bird in birds:\n        df_test_labels.loc[row, bird] = 1\n\ndf_test_labels.fillna(0, inplace = True)","10e5c9cc":"# Merging the table with the original data\n\ntrain_labels = pd.concat([train_labels, df_train_labels], axis = 1)\ntest_csv = pd.concat([test_csv, df_test_labels], axis = 1)\n","ddc39d9e":"eg = \"..\/input\/birdclef-2021\/train_soundscapes\/10534_SSW_20170429.ogg\"\ndata, sr = read_wav_file(eg)\nprint(len(data))\nprint(data[:5]) # first 5 entries\nprint(sr)","f885742c":"audio_id, site, _ = eg.split(\"\/\")[-1].split(\"_\")\ntrain_labels[(train_labels['audio_id']==int(audio_id)) & (train_labels['site']==site) & (train_labels['birds']!='nocall')].head(5)","79808ee5":"# Lets hear this bird for index 1450\nsub_data = data[int(50\/5)*160000 : int(55\/5)*160000]\n\nplt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(sub_data, sr=sr)\nplt.grid()\nplt.show();\n\ndisplay.Audio(sub_data, rate=sr)","07fb2cbf":"params['data_len'] = 160000\nparams['audio_len'] = 5\nparams['num_labels'] = len(uniq_labels)\nparams['for_training'] = {\n    'bs' : 16,\n    'epochs' : 50,\n}\npprint(params)","6bc0cdc4":"train_ids, val_ids = train_test_split(\n                            list(train_labels.index),\n                            test_size = 0.3,\n                            random_state = 2021)\ntest_ids = list(sample_sub.index)","95ee137b":"class DataLoader(Sequence):\n    def __init__(self, path : str, list_ids : list, data : \"Dataframe\", batch_size : int) -> \"Data for Training\":\n        self.path = path\n        self.list_IDs = list_ids\n        self.data = data\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(self.list_IDs))\n    \n    def __len__(self):\n        len_ = int(len(self.list_IDs)\/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        X = X.reshape((self.batch_size, 100, 1600\/\/2))\n        return X, y\n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, params['data_len']\/\/2))\n        y = np.zeros((self.batch_size, params['num_labels']))\n        for i, ID in enumerate(list_IDs_temp):\n            prefix = str(self.data.loc[ID, 'audio_id']) + '_' + self.data.loc[ID, 'site']\n            file_list = [s for s in os.listdir(self.path) if prefix in s]\n            if len(file_list) == 0:\n                # Dummy for missing test audio files\n                audio_file_fft = np.zeros((params['data_len']\/\/2))\n            else:\n                file = file_list[0]\n                audio_file, audio_sr = read_wav_file(os.path.join(self.path, file))\n                audio_file = audio_file[int((self.data.loc[ID, 'seconds']-5)\/params['audio_len'])*params['data_len']:int(self.data.loc[ID, 'seconds']\/params['audio_len'])*params['data_len']]\n                audio_file_fft = np.abs(np.fft.fft(audio_file)[: len(audio_file)\/\/2])\n                # scale data\n                audio_file_fft = (audio_file_fft-audio_file_fft.mean())\/audio_file_fft.std()\n            X[i, ] = audio_file_fft\n            y[i, ] = self.data.loc[ID, self.data.columns[5:]].values\n        return X, y","70a4549d":"# Now we have our Data Loader ready lets build our train_gen, val_gen and test_gen\ntrain_gen = DataLoader(params['train_soundscapes'],\n                       train_ids,\n                       train_labels,\n                       params['for_training']['bs']\n                      )\n\nval_gen = DataLoader(params['train_soundscapes'],\n                     val_ids,\n                     train_labels,\n                     params['for_training']['bs']\n                      )\n\ntest_gen = DataLoader(params['test_soundscapes'],\n                      test_ids,\n                      test_csv,         \n                      params['for_training']['bs']\n                      )","e7114b67":"def build_model():\n    model = Sequential()\n    model.add(LSTM(128,input_shape=(100, 800)))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(params['num_labels'], activation='sigmoid'))\n    \n    return model","827ea298":"clf = build_model()\nclf.summary()","fbdfecd0":"tf.keras.utils.plot_model(clf, show_layer_names = True, show_shapes = True)","421d3a6c":"# Compiling model \nclf.compile(optimizer = 'adam',\n            loss = 'binary_crossentropy',\n            metrics = ['binary_accuracy', 'accuracy', 'AUC']\n           )","c2063efb":"train_hist = clf.fit_generator(generator = train_gen,\n                              validation_data = val_gen,\n                              epochs = 2,\n                              workers = 4)","6cc3ae3e":"train_hist.history.keys()","10f915eb":"fig, axs = plt.subplots(1, 2, figsize=(16, 4))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = train_hist.history['loss']\nloss_val = train_hist.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'b', label='loss_train')\naxs[0].plot(epochs, loss_val, 'r', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\nacc = train_hist.history['auc']\nacc_val = train_hist.history['val_auc']\naxs[1].plot(epochs, acc, 'b', label='AUC_train')\naxs[1].plot(epochs, acc_val, 'r', label='AUC_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","e4ee7aa5":"y_pred = clf.predict_generator(test_gen, verbose=1)","e6072683":"y_test = np.where(y_pred > 0.5, 1, 0)\nfor row in sample_sub.index:\n    string = ''\n    for col in range(len(y_test[row])):\n        if y_test[row][col] == 1:\n            if string == '':\n                string += uniq_labels[col]\n            else:\n                string += ' ' + uniq_labels[col]\n    if string == '':\n        string = 'nocall'\n    sample_sub.loc[row, 'birds'] = string","b54c928f":"# Saving submission\n\nres = sample_sub\nres.to_csv('submission.csv', index=False)","3b1fe3b0":"!mkdir .\/baseline\nclf.save(\".\/baseline\/baseline.h5\")","f9944075":"# !pip install kaggle","3a16c464":"# !cp ..\/input\/kaggle-token\/kaggle_token.json .\/\n# !mv .\/kaggle_token.json .\/kaggle.json\n\n# !ls -l ..\/..\/root\n# !cp .\/kaggle.json ..\/..\/root\/\n# !ls ..\/..\/root\n\n# !mkdir ..\/..\/root\/.kaggle\n# !mv ..\/..\/root\/kaggle.json ..\/..\/root\/.kaggle\/kaggle.json\n\n# !chmod 600 \/root\/.kaggle\/kaggle.json\n# !kaggle datasets init -p .\/baseline","dde3a7ad":"# !cat .\/baseline\/dataset-metadata.json\n\n# import json\n# with open(\".\/baseline\/dataset-metadata.json\", 'r+') as file_:\n#     meta_data = json.load(file_)\n#     meta_data['title'] = 'baseline_BirdCLEF'\n#     meta_data['id'] = 'hotsonhonet\/BirdCLEF'\n#     file_.seek(0)        \n#     json.dump(meta_data, file_, indent=4)\n#     file_.truncate()\n    \n# print(meta_data['title'], meta_data['id'])\n# print(\"\\nAfter editing\\n\")\n# !cat .\/baseline\/dataset-metadata.json","11c9a152":"# !kaggle datasets create -p .\/baseline","389c0467":"This voice sounds more like fighter plane crash landing \ud83d\ude02","31e2d430":"# Saving model weights","7cf8da45":"# Inference","574a24d3":"Creating a custom data loader using [sequence](http:\/\/https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/utils\/Sequence) class","c3da67bf":"* Input_shape : (16, 100, 800)\n* Output_shape : (16, 49)","e8674cf0":"# Building Model","b9a96b48":"# Preparing Dataset","14acc6d7":"# EDA"}}