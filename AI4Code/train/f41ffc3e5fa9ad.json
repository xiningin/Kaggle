{"cell_type":{"aff9340c":"code","b4af109c":"code","cf236da2":"code","a1a1e503":"code","dfd4872c":"code","4f82c042":"code","6e3ccef6":"code","7b44ffab":"code","4a309b8f":"code","83743fa3":"code","adf838f6":"code","c18b82af":"code","0d5e3cbe":"code","ec745fa2":"code","65c09127":"code","79a01e0f":"code","7e46a798":"code","9e7847f9":"code","77225820":"code","487669b6":"code","2aa8a4e9":"code","4bf8c4ca":"code","3f80eb3f":"code","12a184c1":"code","3857b70e":"code","fa640567":"code","01789f1b":"code","08c988d2":"code","dce7043f":"code","4f05e283":"code","ea93866d":"code","f06991f2":"code","3b6e3457":"code","034b592a":"code","16d06ff0":"code","fbfc76fe":"code","73f4747d":"code","82b0c1d5":"code","d38d7fc1":"code","2b15a343":"code","b6a801b9":"code","ea59a180":"code","4494082c":"code","48fb422f":"code","524004f7":"code","96460d54":"code","a5a9a276":"code","0d8c26e1":"code","900d4d21":"code","ce9ab79c":"markdown","a8acc84d":"markdown","313f1c39":"markdown","ae2363d7":"markdown","5d6b8b6c":"markdown","dbc0516c":"markdown","a62f5a8f":"markdown","6d0f85e8":"markdown","d7009c64":"markdown","328d6862":"markdown","21c93d8d":"markdown","7bcd0570":"markdown","0c119ed6":"markdown"},"source":{"aff9340c":"# Importing libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression","b4af109c":"# Importing the train data.\n\nhousing_train=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","cf236da2":"# Displaying data head.\n\nhousing_train.head()","a1a1e503":"# Displaying data shape.\n\nhousing_train.shape","dfd4872c":"# Describe my numeric data (Statistics)\n\nnumerical_columns = [col for col in housing_train.columns if (housing_train[col].dtype=='int64' or housing_train[col].dtype=='float64')]\nhousing_train[numerical_columns].describe().loc[['mean', 'std', 'min', '25%', '50%', '75%', 'max'], :]","4f82c042":"# Display correlation matrix to check if multicolinearity exist (correlation between idependent\n# and dependent variables.)\n\nplt.figure(figsize=(30,20))\ncorrMatrix = housing_train.corr()\nsns.heatmap(corrMatrix, annot=True, cmap='coolwarm')\n### There are some variables with high correlation(Multicolinearity issue), We will deal with this issue later","6e3ccef6":"# Visualizing the missing data (Heat map)\n\nsns.heatmap(housing_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","7b44ffab":"# Train data variables, values and type.\n\nhousing_train.info()","4a309b8f":"housing_train.drop(['Id'],axis=1,inplace=True)\nhousing_train.drop(['Alley'],axis=1,inplace=True)\nhousing_train.drop(['PoolQC','Fence','MiscFeature', 'GarageArea'],axis=1,inplace=True)\nhousing_train.drop(['GarageYrBlt'],axis=1,inplace=True)\nhousing_train.drop(['1stFlrSF'],axis=1,inplace=True)","83743fa3":"## Fill Missing Values for numeric variables.\nhousing_train['LotFrontage']=housing_train['LotFrontage'].fillna(housing_train['LotFrontage'].mean())","adf838f6":"# Fill Missing Values for categorical variables.\nhousing_train['BsmtCond']=housing_train['BsmtCond'].fillna(housing_train['BsmtCond'].mode()[0])\nhousing_train['BsmtQual']=housing_train['BsmtQual'].fillna(housing_train['BsmtQual'].mode()[0])\nhousing_train['FireplaceQu']=housing_train['FireplaceQu'].fillna(housing_train['FireplaceQu'].mode()[0])\nhousing_train['GarageType']=housing_train['GarageType'].fillna(housing_train['GarageType'].mode()[0])\nhousing_train['GarageFinish']=housing_train['GarageFinish'].fillna(housing_train['GarageFinish'].mode()[0])\nhousing_train['GarageQual']=housing_train['GarageQual'].fillna(housing_train['GarageQual'].mode()[0])\nhousing_train['GarageCond']=housing_train['GarageCond'].fillna(housing_train['GarageCond'].mode()[0])\nhousing_train['MasVnrType']=housing_train['MasVnrType'].fillna(housing_train['MasVnrType'].mode()[0])\nhousing_train['MasVnrArea']=housing_train['MasVnrArea'].fillna(housing_train['MasVnrArea'].mode()[0])\nhousing_train['BsmtFinType2']=housing_train['BsmtFinType2'].fillna(housing_train['BsmtFinType2'].mode()[0])\nhousing_train['BsmtExposure']=housing_train['BsmtExposure'].fillna(housing_train['BsmtExposure'].mode()[0])","c18b82af":"# Total missing values\n\nhousing_train.isnull().sum().sum()","0d5e3cbe":"# Only 38 missing variables remained, I will drop them.\n\nhousing_train.dropna(inplace=True)\nhousing_train.isna().sum().sum()","ec745fa2":"## Making sure there is no missing data (heatmap.)\n\nsns.heatmap(housing_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","65c09127":"# Importing my test data\n\nhousing_test= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","79a01e0f":"# Saving the Id variable for later.\n\nId= housing_test['Id']","7e46a798":"# Displaying first 5 rows of the test data.\n\nhousing_test.head(5)","9e7847f9":"# Test data shape.\n\nhousing_test.shape","77225820":"# Displaying test data information ( variables, value counts, variable type)\n\nhousing_test.info()","487669b6":"# Displaying the total missing data\n\nhousing_test.isna().sum().sum()","2aa8a4e9":"# Visualizing the missing data\n\nsns.heatmap(housing_test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","4bf8c4ca":"#These variables have more than 50% missing values that is why I have decided to drop them.\n\nhousing_test.drop(['Id', 'Alley', 'MiscFeature', 'Fence', 'PoolQC', 'GarageYrBlt', 'GarageArea','1stFlrSF'], axis=1, inplace=True)","3f80eb3f":"# Imputing the missing data in numeric variables( mean).\n\nhousing_test.LotFrontage.fillna(housing_test.LotFrontage.mean(), inplace=True)","12a184c1":"# Impute the missing data with the mode.\n\nhousing_test.MSZoning .fillna(housing_test.MSZoning.mode()[0], inplace= True)\nhousing_test.Utilities.fillna(housing_test.Utilities.mode()[0], inplace= True)\nhousing_test.MasVnrType.fillna(housing_test.MasVnrType.mode()[0], inplace= True)\nhousing_test.BsmtQual.fillna(housing_test.BsmtQual.mode()[0], inplace= True)\nhousing_test.BsmtCond.fillna(housing_test.BsmtCond.mode()[0], inplace= True)\nhousing_test.BsmtExposure.fillna(housing_test.BsmtExposure.mode()[0], inplace= True)\nhousing_test.BsmtFinType1.fillna(housing_test.BsmtFinType1.mode()[0], inplace= True)\nhousing_test.BsmtFinType2.fillna(housing_test.BsmtFinType2.mode()[0], inplace= True)\nhousing_test.FireplaceQu.fillna(housing_test.FireplaceQu.mode()[0], inplace= True)\nhousing_test.GarageType.fillna(housing_test.GarageType.mode()[0], inplace= True)\nhousing_test.GarageFinish.fillna(housing_test.GarageFinish.mode()[0], inplace= True) \nhousing_test.GarageQual.fillna(housing_test.GarageQual.mode()[0], inplace= True)\nhousing_test.GarageCond.fillna(housing_test.GarageCond.mode()[0], inplace= True)\nhousing_test['GarageCars'].fillna(housing_test['GarageCars'].mean())\nhousing_test['BsmtUnfSF'].fillna(housing_test['BsmtUnfSF'].mean())\nhousing_test['BsmtFinSF1'].fillna(housing_test['BsmtFinSF1'].mean())\nhousing_test['BsmtFinSF2'].fillna(housing_test['BsmtFinSF2'].mean())","3857b70e":"# Test data shape.\n\nhousing_test.shape","fa640567":"# Exporting the clean test data into CSV file.\n\nhousing_test.to_csv('housing_testclean.csv', index=False)","01789f1b":"# These are all the categorical variables.\n\ncolumns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n        'SaleCondition','ExterCond',\n         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n         'CentralAir',\n         'Electrical','KitchenQual','Functional',\n         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']","08c988d2":"# Defining a function that will be used to convert categorical data into dummies.\ndef category_onehot_multcols(multcolumns):\n    df_final=final_df\n    i=0\n    for fields in multcolumns:\n        \n        print(fields)\n        df1=pd.get_dummies(final_df[fields],drop_first=True)\n        \n        final_df.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:\n            \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n       \n        \n    df_final=pd.concat([final_df,df_final],axis=1)\n        \n    return df_final","dce7043f":"# Importing the clean test data.\n\ntest_df=pd.read_csv('housing_testclean.csv')","4f05e283":"# \"Clean\" Test data shape.\n\ntest_df.shape","ea93866d":"# Displaying first 5 rows from the test data\n\ntest_df.head()","f06991f2":"# Concating test and train data\n\nfinal_df=pd.concat([housing_train,test_df],axis=0, sort=False)","3b6e3457":"# Displaying the shape of the final data\n\nfinal_df.shape","034b592a":"# Using the function to convert categorical data into dummies\n\nfinal_df=category_onehot_multcols(columns)","16d06ff0":"# Final data shape\n\nfinal_df.shape","fbfc76fe":"# Eliminating the duplicates.\n\nfinal_df =final_df.loc[:,~final_df.columns.duplicated()]","73f4747d":"# Data shape after eliminating duplicates.\n\nfinal_df.shape","82b0c1d5":"final_df.head()","d38d7fc1":"# Train, test data split.\n\ndf_Train=final_df.iloc[:1422,:]\ndf_Test=final_df.iloc[1422:,:]","2b15a343":"# Dependent variable (Test data)\n\ny_test= df_Test['SalePrice']","b6a801b9":"df_Test.drop(['SalePrice'],axis=1,inplace=True)\n# You can ignore this warning. SettingWithCopyWarning happens when indexing a DataFrame returns a reference to the initial DataFrame.","ea59a180":"X_train=df_Train.drop(['SalePrice'],axis=1)\ny_train=df_Train['SalePrice']","4494082c":"X_train=df_Train.drop(['SalePrice'],axis=1)\ny_train=df_Train['SalePrice']","48fb422f":"# X_train, y_train, test shape.\nprint(X_train.shape)\nprint(y_train.shape)\nprint(df_Test.shape)","524004f7":"# Fill NAs with 0.\n\ndf_Test.fillna(0, inplace= True)","96460d54":"# RidgeCV\nfrom sklearn.linear_model import RidgeCV\nridge_model = RidgeCV(alphas=(0.01, 0.05, 0.1, 0.3, 1, 3, 5, 10))\nridge_model.fit(X_train, y_train)\nridge_model_preds = ridge_model.predict(df_Test)\nridge_model_preds","a5a9a276":"#xgboost model\nimport xgboost as xgb\nxgb_model = xgb.XGBRegressor(n_estimators=340, max_depth=2, learning_rate=0.2)\nxgb_model.fit(X_train, y_train)\nxgb_preds = xgb_model.predict(df_Test)\npredictions = ( ridge_model_preds + xgb_preds )\/2\npredictions","0d8c26e1":"# Final submission\nsubmission = {'Id': Id.values,'SalePrice': predictions}\nfinal_submission = pd.DataFrame(submission)\n# Exporting the final prediction into a csv\nfinal_submission.to_csv('submission_house_price.csv', index=False)\nfinal_submission.head()","900d4d21":"# Please if you find this notebook helpful up.vote. I appreciate it.","ce9ab79c":"#                 Statistical learning Project: \n\n\n","a8acc84d":"# Model building","313f1c39":"### Dropping few variables\n* Id: is not relevant.\n* \"Alley\", \"PoolQC\", \"Fence\", \"Miscfeature\" have more than 50% missing data, I decided to drop them.","ae2363d7":"## Fitting test and train data into a linear model","5d6b8b6c":"#### Imputing missing data: numeric using mean and categorical using mode.","dbc0516c":"# Converting categorical variables into dummies and # Concatinating train and test data","a62f5a8f":"# Splitting the data into train and test data","6d0f85e8":"#### We still have 38 missing values","d7009c64":"# Test data: cleaning and prep\n","328d6862":"## Fitting the data into xgboost model.","21c93d8d":"#### Avoidng multicolinearity\n* \"Garage area\" variable is highly correlated with GarageCars.That makes sense; as the area of the garage gets bigger, the number of cars that fit in gets bigger.\nwe will drop GarageArea(It has less correlation with the target variable.)\n*  \"Garage built\" and \"year built\" have high correlation. We will drop \"GarageYrBlt.\"\n* \"1stFlrSF\" has a high correlation with \"TotalBsmtSF\", and both have equal correlation with \n\"Price\". Therefore, dropping either one would be fine. I decided to drop  \"1stFlrSF\".\n* \"GarageYrBlt\" and \"YearBuilt\" are highly correlated, We will drop \"GarageYrBlt\" since it has less correlattion with the target variable.","7bcd0570":"# Train data cleaning and prep","0c119ed6":"# Submission :)"}}