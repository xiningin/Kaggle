{"cell_type":{"432d31f0":"code","42794263":"code","601845d8":"code","5ff07f28":"code","047feeab":"code","e03fe936":"code","e4c019e5":"markdown","a485c6cc":"markdown","28e1b40b":"markdown","57db27e4":"markdown","c54cbf1a":"markdown","4ccd549e":"markdown","684f1c11":"markdown","1109bff3":"markdown","547cbe72":"markdown","818d69bb":"markdown","e3bb3348":"markdown","1afdcf36":"markdown","ccc7a9d9":"markdown","aef9d896":"markdown"},"source":{"432d31f0":"from IPython.display import Image\nImage(filename='..\/input\/stratified-sampling\/Stratified_sampling.png')","42794263":"import pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit, KFold\n\n\ndata = pd.DataFrame(load_breast_cancer()['data'],columns=load_breast_cancer()['feature_names'])\ndata['target'] = load_breast_cancer()['target']\ndata.head()","601845d8":"train_df,test_df = train_test_split(data,test_size=0.2,random_state=11)\nprint(f'PROPORTION OF TARGET IN THE ORIGINAL DATA\\n{data[\"target\"].value_counts() \/ len(data)}\\n\\n'+\n      f'PROPORTION OF TARGET IN THE TRAINING SET\\n{train_df[\"target\"].value_counts() \/ len(train_df)}\\n\\n'+\n      f'PROPORTION OF TARGET IN THE TEST SET\\n{test_df[\"target\"].value_counts() \/ len(test_df)}')","5ff07f28":"train_df,test_df = train_test_split(data,test_size=0.2,stratify=data['target'],random_state=11)\nprint(f'PROPORTION OF TARGET IN THE ORIGINAL DATA\\n{data[\"target\"].value_counts() \/ len(data)}\\n\\n'+\n      f'PROPORTION OF TARGET IN THE TRAINING SET\\n{train_df[\"target\"].value_counts() \/ len(train_df)}\\n\\n'+\n      f'PROPORTION OF TARGET IN THE TEST SET\\n{test_df[\"target\"].value_counts() \/ len(test_df)}')","047feeab":"kfold = KFold(n_splits=3,random_state=11,shuffle=True)\nsplits = kfold.split(data,data['target']) # each split has a train indexes and test indexes pair\nprint(f'PROPORTION OF TARGET IN THE ORIGINAL DATA\\n{data[\"target\"].value_counts() \/ len(data)}\\n\\n')\nfor n,(train_index,test_index) in enumerate(splits):\n    print(f'SPLIT NO {n+1}\\nTRAINING SET SIZE: {np.round(len(train_index) \/ (len(train_index)+len(test_index)),2)}'+\n          f'\\tTEST SET SIZE: {np.round(len(test_index) \/ (len(train_index)+len(test_index)),2)}\\nPROPORTION OF TARGET IN THE TRAINING SET\\n'+\n          f'{data.iloc[test_index,-1].value_counts() \/ len(data.iloc[test_index,-1])}\\nPROPORTION OF TARGET IN THE TEST SET\\n'+\n          f'{data.iloc[train_index,-1].value_counts() \/ len(data.iloc[train_index,-1])}\\n\\n')","e03fe936":"kfold = StratifiedKFold(n_splits=3,shuffle=True,random_state=11)\n#data['target'] IS THE VARIABLE USED FOR STRATIFIED SAMPLING.\nsplits = kfold.split(data,data['target'])\nprint(f'PROPORTION OF TARGET IN THE ORIGINAL DATA\\n{data[\"target\"].value_counts() \/ len(data)}\\n\\n')\nfor n,(train_index,test_index) in enumerate(splits):\n    print(f'SPLIT NO {n+1}\\nTRAINING SET SIZE: {np.round(len(train_index) \/ (len(train_index)+len(test_index)),2)}'+\n          f'\\tTEST SET SIZE: {np.round(len(test_index) \/ (len(train_index)+len(test_index)),2)}\\nPROPORTION OF TARGET IN THE TRAINING SET\\n'+\n          f'{data.iloc[test_index,-1].value_counts() \/ len(data.iloc[test_index,-1])}\\nPROPORTION OF TARGET IN THE TEST SET\\n'+\n          f'{data.iloc[train_index,-1].value_counts() \/ len(data.iloc[train_index,-1])}\\n\\n')","e4c019e5":"<h2 style=\"font-family:arial;font-size:25px\">Implementing hold-out cross-validation with stratified sampling<\/h2>\n<p style=\"font-family:arial;font-size:18px;text-align:justify\">We\u2019ll implement hold-out cross-validation with stratified sampling such that the training and the test sets have same proportion of the target variable. This can be achieved by setting the \u2018stratify\u2019 argument of \u2018train_test_split\u2019 to the characteristic of interest (target variable, in this case). It need not necessarily be the target variable, it can even be an input variable which you want to have the same proportion in the training and test sets.<\/p>","a485c6cc":"<h2 style=\"font-family:arial;font-size:25px\">Implementing hold-out cross-validation without stratified sampling<\/h2>\n<p style=\"font-family:arial;font-size:18px;text-align:justify\">Hold-out cross validation is implemented using the \u2018train_test_split\u2019 function of Scikit-Learn. The implementation is shown below. The function returns training set and test set.<\/p>","28e1b40b":"<h2 style=\"font-family:arial;font-size:25px\">Implementing k-fold cross-validation with stratified sampling<\/h2>\n<p style=\"font-family:arial;font-size:18px;text-align:justify\">Stratified sampling can be implemented with k-fold cross-validation using the \u2018StratifiedKFold\u2019 function of Scikit-Learn. The implementation is shown below.<\/p>","57db27e4":"<p style=\"font-family:arial;font-size:18px;text-align:justify\">Using stratified sampling, the proportion of the target variable is pretty much the same across the original data, training set and test set.<\/p>","c54cbf1a":"<p style=\"font-family:arial;font-size:18px;text-align:justify\">We can see that the proportion of the target variable is inconsistent among the original data, training data and test data across splits.<\/p>","4ccd549e":"<h2 style=\"font-family:arial;font-size:25px\">What is stratified sampling?<\/h2>\n<p style=\"font-family:arial;font-size:18px;text-align:justify\">Before diving deep into stratified cross-validation, it is important to know about stratified sampling. Stratified sampling is a sampling technique where the samples are selected in the same proportion (by dividing the population into groups called \u2018strata\u2019 based on a characteristic) as they appear in the population. For example, if the population of interest has 30% male and 70% female subjects, then we divide the population into two (\u2018male\u2019 and \u2018female\u2019) groups and choose 30% of the sample from the \u2018male\u2019 group and \u201870%\u2019 of the sample from the \u2018female\u2019 group.<\/p>","684f1c11":"<h2 style=\"font-family:arial;font-size:25px\">How is stratified sampling related to cross-validation?<\/h2>\n<p style=\"font-family:arial;font-size:18px;text-align:justify\">Implementing the concept of stratified sampling in cross-validation ensures the training and test sets have the same proportion of the feature of interest as in the original dataset. Doing this with the target variable ensures that the cross-validation result is a close approximation of generalization error.\nBefore proceeding further, we\u2019ll load the breast cancer dataset from Scikit-Learn.<\/p>","1109bff3":"<h2 style=\"font-family:arial;font-size:25px\">Implementing k-fold cross-validation without stratified sampling<\/h2>\n<p style=\"font-family:arial;font-size:18px;text-align:justify\">K-fold cross-validation splits the data into \u2018k\u2019 portions. In each of \u2018k\u2019 iterations, one portion is used as the test set, while the remaining portions are used for training. Using the \u2018KFold\u2019 function of Scikit-Learn, we\u2019ll implement 3-fold cross-validation without stratified sampling.<\/p>","547cbe72":"<p style=\"font-family:arial;font-size:18px;text-align:justify\">In the above results, we can see that the proportion of the target variable is pretty much consistent across the original data, training set and test set in all the three splits.<\/p>","818d69bb":"<p style=\"font-family:arial;font-size:18px;text-align:justify\">Refer to my article in <a href=\"https:\/\/towardsdatascience.com\/what-is-stratified-cross-validation-in-machine-learning-8844f3e7ae8e\" target=\"_blank\">Toward's Data Science<\/a> for another example.<\/p>","e3bb3348":"<h1 style=\"font-family:arial;font-size:30px\">What is Stratified Cross-Validation?<\/h1>\n<h3 style=\"font-family:arial\">This notebook explains stratified cross-validation and it\u2019s implementation in Python using Scikit-Learn.<\/h3>","1afdcf36":"Stratified sampling (Image by Mathprofdk (Dan Kernler) on Wikipedia)","ccc7a9d9":"<p style=\"font-family:arial;font-size:18px;text-align:justify\">Since, we haven\u2019t used stratified sampling, we can see that the proportion of the target variable varies hugely among the original dataset, training set and test set.<\/p>","aef9d896":"<p style=\"font-family:arial;font-size:18px;text-align:justify\">Cross-validation implemented using stratified sampling ensures that the proportion of the feature of interest is the same across the original data, training set and the test set. This ensures that no value is over\/under-represented in the training and test sets, which gives a more accurate estimate of performance\/error.<\/p>"}}