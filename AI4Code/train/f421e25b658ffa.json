{"cell_type":{"4f739f7f":"code","28f7439c":"code","8d5f04fb":"code","988c0685":"code","75c275ef":"code","4b55d523":"code","1e55f4b9":"code","8ab50f7a":"code","b74e253d":"code","690d6d13":"code","fe26b790":"code","1beb7c5c":"code","1e5b3e20":"code","8c7aac5e":"markdown","f4648791":"markdown"},"source":{"4f739f7f":"import pandas as pd\nimport numpy as np\nimport keras\nimport time\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.optimizers import RMSprop,Adam\nimport numpy as np\nimport random\nimport os","28f7439c":"dataset = pd.read_csv(\"\/kaggle\/input\/Arabic_Names.csv\")","8d5f04fb":"names = dataset.loc[:,\"Arabic_Name\"]","988c0685":"step_length = 1   \nepochs = 50       \nbatch_size = 64    \nlatent_dim = 128   \ndropout_rate = 0.2 \nverbosity = 0     \ngen_amount = 10    ","75c275ef":"input_names = []\nfor name in names:\n    name = name.rstrip()\n    input_names.append(name)","4b55d523":"concat_names = '\\n'.join(input_names).lower()\n\nchars = sorted(list(set(concat_names)))\nnum_chars = len(chars)\n\nchar2idx = dict((c, i) for i, c in enumerate(chars))\nidx2char = dict((i, c) for i, c in enumerate(chars))\n\nmax_sequence_length = max([len(name) for name in input_names])\n\nprint('Total chars: {}'.format(num_chars))\nprint('Corpus length:', len(concat_names))\nprint('Number of names: ', len(input_names))\nprint('Longest name: ', max_sequence_length)","1e55f4b9":"max_sequence_length = 50","8ab50f7a":"sequences = []\nnext_chars = []\nfor i in range(0, len(concat_names) - max_sequence_length, step_length):\n    sequences.append(concat_names[i: i + max_sequence_length])\n    next_chars.append(concat_names[i + max_sequence_length])\n\nnum_sequences = len(sequences)\n\nfor i in range(20):\n    print('X=[{}]   y=[{}]'.replace('\\n', ' ').format(sequences[i], next_chars[i]).replace('\\n', ' '))","b74e253d":"X = np.zeros((num_sequences, max_sequence_length, num_chars), dtype=np.bool)\nY = np.zeros((num_sequences, num_chars), dtype=np.bool)\n\nfor i, sequence in enumerate(sequences):\n    for j, char in enumerate(sequence):\n        X[i, j, char2idx[char]] = 1\n    Y[i, char2idx[next_chars[i]]] = 1\n    \nprint('X shape: {}'.format(X.shape))\nprint('Y shape: {}'.format(Y.shape))\nprint(X[0])\nprint(Y[0])","690d6d13":"model = Sequential()\nmodel.add(LSTM(latent_dim, \n               input_shape=(max_sequence_length, num_chars),  \n               recurrent_dropout=dropout_rate))\nmodel.add(Dense(units=num_chars, activation='softmax'))\n\noptimizer = Adam(lr=0.01)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer)\n\nmodel.summary()","fe26b790":"start = time.time()\nprint('Start training for {} epochs'.format(epochs))\nhistory = model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=verbosity)\nend = time.time()\nprint('Finished training - time elapsed:', (end - start)\/60, 'min')","1beb7c5c":"def generate_names():\n    r = np.random.choice(len(concat_names)-1)\n    r2 = r-max_sequence_length\n\n    sequence = concat_names[r2:r-1] + '\\n'\n\n    new_names = []\n    #print(sequence)\n    while len(new_names) < 1:\n\n        x = np.zeros((1, max_sequence_length, num_chars))\n        for i, char in enumerate(sequence):\n            x[0, i, char2idx[char]] = 1\n\n        probs = model.predict(x, verbose=0)[0]\n        probs \/= probs.sum()\n        next_idx = np.random.choice(len(probs), p=probs)   \n        next_char = idx2char[next_idx]   \n        sequence = sequence[1:] + next_char\n\n        if next_char == '\\n':\n\n            gen_name = [name for name in sequence.split('\\n')][1]\n\n            if len(gen_name) > 4 and gen_name[0] == gen_name[1]:\n                gen_name = gen_name[1:]\n\n            if len(gen_name) > 4 and len(gen_name) <= 7:\n\n                if gen_name not in input_names + new_names:\n                    new_names.append(gen_name.capitalize())\n                    return gen_name.capitalize()\n","1e5b3e20":"for _ in range(20):\n    print(generate_names())\n","8c7aac5e":"# Arabic Name Generator with RNNs in Keras","f4648791":"This kernel is just for fun purposes i just wanted to try an idea i had in mind most of the code are extracted from those 2 repos \nhttps:\/\/github.com\/antonio-f\/Generating-names-with-RNN\/blob\/master\/Generating%20names%20with%20recurrent%20neural%20networks\/RNN-task.ipynb <br>\nhttps:\/\/github.com\/simon-larsson\/pokemon-name-generator"}}