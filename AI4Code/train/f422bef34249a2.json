{"cell_type":{"f7192c45":"code","7719c56c":"code","e59b4aa9":"code","bdadb2ff":"code","371385b8":"code","6158492b":"code","9032353a":"code","466feba8":"code","e7590584":"code","0bbb705f":"code","ce2b8c85":"code","4673cbb3":"code","c96c4911":"code","0d9801f8":"code","377bbcf2":"code","a3a1f115":"code","a06cd072":"code","8a7d0a54":"code","2be3595e":"markdown","f02b3391":"markdown","7ee1e691":"markdown","cfbbe9de":"markdown","d7b265ee":"markdown","aa7a9406":"markdown","fcbd7591":"markdown","1f980d54":"markdown"},"source":{"f7192c45":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata_dir = '..\/input\/'\ndf = pd.read_csv(data_dir + 'spam.csv', encoding='latin-1')","7719c56c":"df.head()","e59b4aa9":"df.dtypes","bdadb2ff":"df.describe()","371385b8":"df.info()","6158492b":"df.shape","9032353a":"from sklearn.model_selection import train_test_split\ndata_train, data_test, label_train, label_test = train_test_split(df.v2,\n                                                                 df.v1,\n                                                                 test_size=0.2,\n                                                                 random_state=0)\nprint('Content after spliting:')\nprint(data_train.head())\nprint(label_train.head())","466feba8":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\ndata_train_cnt = vectorizer.fit_transform(data_train)\ndata_test_cnt = vectorizer.transform(data_test)\n# print(data_train_cnt)\n# print(len(vectorizer.vocabulary_))\n# print(data_test_cnt)","e7590584":"wordFrequency = pd.DataFrame({'Term': vectorizer.get_feature_names(), 'Count': data_train_cnt.toarray().sum(axis=0)})","0bbb705f":"wordFrequency['Frequency'] = wordFrequency['Count'] \/ wordFrequency['Count'].sum()","ce2b8c85":"plt.plot(wordFrequency['Count'])\nplt.xlabel('Vocabulary_Index of Term')\nplt.ylabel('Count')\nplt.plot","4673cbb3":"plt.plot(wordFrequency['Frequency'])\nplt.xlabel('Vocabulary_Index of Term')\nplt.ylabel('Frequency')\nplt.plot","c96c4911":"wordFrequency_sort = wordFrequency.sort_values(by='Count', ascending=False)\nwordFrequency_sort.head()","0d9801f8":"print(data_train_cnt.shape, label_train.shape, data_test_cnt.shape)","377bbcf2":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(data_train_cnt, label_train)\npredictions = clf.predict(data_test_cnt)\nprint(predictions)","a3a1f115":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nprint('Accuracy: \\n', accuracy_score(label_test, predictions))\nprint('Confusion Matrix: \\n', confusion_matrix(label_test, predictions))\nprint('Classification Report: \\n', classification_report(label_test, predictions))","a06cd072":"from sklearn.model_selection import cross_val_score","8a7d0a54":"accuracy = cross_val_score(clf, data_train_cnt, label_train, cv=20, scoring='accuracy')\nprint(accuracy)\nprint(accuracy.mean())","2be3595e":"Count the number of words in training set.","f02b3391":"df.v1 is the label (spam & ham), df.v2 is the text in the email.\n\nSelect these two columns and split the dataset into training set and testing set.","7ee1e691":"## Sort the wordFrequency by count in Descending order","cfbbe9de":"## Use cross validation method to validate performance in training set and make a comparion","d7b265ee":"## Build classification model with Multinomial Naive Bayes in training set, and make predictions in testing set.","aa7a9406":"# Spam Email Classification","fcbd7591":"## Validate the performance of model in testing set","1f980d54":"Read data"}}