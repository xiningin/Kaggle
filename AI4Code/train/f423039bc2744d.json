{"cell_type":{"2590de7a":"code","49430fbe":"code","8325084a":"code","72db3853":"code","586237b8":"code","7ed756d1":"code","dab5d9c9":"code","78f8519d":"code","83df138d":"code","137b7def":"code","49e9f264":"code","a6ba9f35":"code","b585d3ff":"code","870ab440":"code","24969e21":"code","d1e7afad":"code","7d038d24":"code","0ad3eea0":"code","7a59455f":"code","b6628b3c":"code","b35a021d":"code","1fea2f5e":"code","545c2f18":"code","a79f93cf":"code","d8b23c8f":"code","f8f0e254":"code","340a290d":"code","67e0773f":"code","090dfe9d":"code","3fd23bb7":"code","7d988eda":"markdown"},"source":{"2590de7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","49430fbe":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.preprocessing.image import *\nfrom tensorflow.keras.utils import plot_model\n!pip install livelossplot\nfrom livelossplot import PlotLossesKeras\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\nimport os\nfrom PIL import Image\nimport cv2\nfrom collections import Counter\n!pip install imutils\nfrom imutils import *\nfrom scipy.spatial.distance import cosine, euclidean\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n!pip install plotly\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly as ply\nfrom sklearn.metrics import *\nply.offline.init_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","8325084a":"VAL_LOC = \"..\/input\/mias-classes-gdf\/MIAS_Data\/Val\"\nTRAIN_LOC = \"..\/input\/mias-classes-gdf\/MIAS_Data\/Train\"\nTEST_LOC = \"..\/input\/mias-classes-gdf\/MIAS_Data\/Test\"","72db3853":"train_data = TRAIN_LOC\nval_data = VAL_LOC\nmasked_data = TEST_LOC\ntrain_names = []; val_names = []; masked_names = []\ntrain_names_count = []; val_names_count = []; masked_names_count = []\n\nfor class_ in sorted(os.listdir(train_data)):\n    train_names.append(class_)\n    train_names_count.append(len(os.listdir(os.path.join(train_data, class_))))\n\nfor class_ in sorted(os.listdir(val_data)):\n    val_names.append(class_)\n    val_names_count.append(len(os.listdir(os.path.join(val_data, class_))))\n\nfor class_ in sorted(os.listdir(masked_data)):\n    masked_names.append(class_)\n    masked_names_count.append(len(os.listdir(os.path.join(masked_data, class_))))","586237b8":"fig = make_subplots(rows=1, cols=3)\nfig.add_trace(go.Bar(name='training', x=train_names, y=train_names_count), row = 1, col = 1)\nfig.add_trace(go.Bar(name='validation', x=val_names, y=val_names_count), row = 1, col = 2)\nfig.add_trace(go.Bar(name='testing', x=masked_names, y=masked_names_count), row = 1, col = 3)\n\nfig.update_layout(title_text=\"Data\", title_x = 0.5)\nfig.show()","7ed756d1":"num_classes=3\ndef list_of_shapes(img_location, name):\n    shapes = []\n    for img in os.listdir(os.path.join(img_location, name)):\n        img_arr = cv2.imread(os.path.join(img_location, name, img))\n        shapes.append(img_arr.shape)\n    \n    return shapes","dab5d9c9":"G_train_shapes = list_of_shapes(train_data, \"G\")\nD_train_shapes = list_of_shapes(train_data, \"D\")\nF_train_shapes = list_of_shapes(train_data, \"F\")\n\n\nG_val_shapes = list_of_shapes(val_data, \"G\")\nD_val_shapes = list_of_shapes(val_data, \"D\")\nF_val_shapes = list_of_shapes(val_data, \"F\")\n\n\nshapes = G_train_shapes + D_train_shapes + G_val_shapes + D_val_shapes + F_train_shapes + F_val_shapes \nwidths = [shape[1] for shape in shapes]\nheights = [shape[0] for shape in shapes]","78f8519d":"IMG_SHAPE = (224,224,3)\ndef euclidean_distance(vectors):\n\t# unpack the vectors into separate lists\n\t(featsA, featsB) = vectors\n\n\t# compute the sum of squared distances between the vectors\n\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,\n\t\tkeepdims=True)\n\n\t# return the euclidean distance between the vectors\n\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))","83df138d":"def make_pairs(images, labels):\n\t# initialize two empty lists to hold the (image, image) pairs and\n\t# labels to indicate if a pair is positive or negative\n\tpairImages = []\n\tpairLabels = []\n\n\t# calculate the total number of classes present in the dataset\n\t# and then build a list of indexes for each class label that\n\t# provides the indexes for all examples with a given label\n\tnumClasses = len(np.unique(labels))\n \n\tidx = [np.where(labels == i)[0] for i in range(0,3)]\n\n\t# loop over all images\n\tfor idxA in range(len(images)):\n\t\t# grab the current image and label belonging to the current\n\t\t# iteration\n\t\tcurrentImage = images[idxA]\n\t\tlabel = labels[idxA]\n\n\t\t# randomly pick an image that belongs to the *same* class\n\t\t# label\n\t\tidxB = np.random.choice(idx[label])\n\t\tposImage = images[idxB]\n\n\t\t# prepare a positive pair and update the images and labels\n\t\t# lists, respectively\n\t\tpairImages.append([currentImage, posImage])\n\t\tpairLabels.append([1])\n\n\t\t# grab the indices for each of the class labels *not* equal to\n\t\t# the current label and randomly pick an image corresponding\n\t\t# to a label *not* equal to the current label\n\t\tnegIdx = np.where(labels != label)[0]\n\t\tnegImage = images[np.random.choice(negIdx)]\n\n\t\t# prepare a negative pair of images and update our lists\n\t\tpairImages.append([currentImage, negImage])\n\t\tpairLabels.append([0])\n\n\t# return a 2-tuple of our image pairs and labels\n\treturn (np.array(pairImages), np.array(pairLabels))","137b7def":"def load_data(img_location, name):\n    imgs = []\n    labels = []\n    for img in os.listdir(os.path.join(img_location, name)):\n        img_arr = cv2.imread(os.path.join(img_location, name, img))\n        img_arr = cv2.resize(img_arr, (IMG_SHAPE[1], IMG_SHAPE[0]))\n        labels.append(name)\n        imgs.append(img_arr)\n    \n    return imgs, labels    ","49e9f264":"G_train_imgs, G_train_labels = load_data(train_data,\"G\")\nD_train_imgs, D_train_labels = load_data(train_data,\"D\")\nG_val_imgs, G_val_labels = load_data(val_data,\"G\")\nD_val_imgs, D_val_labels = load_data(val_data,\"D\")\nF_train_imgs, F_train_labels = load_data(train_data,\"F\")\nF_val_imgs, F_val_labels = load_data(val_data,\"F\")\n\ntrain_imgs = G_train_imgs + D_train_imgs + F_train_imgs \ntrain_labels = G_train_labels + D_train_labels + F_train_labels \n\nval_imgs = G_val_imgs + D_val_imgs +F_val_imgs \nval_labels = G_val_labels + D_val_labels +F_val_labels \ntrain_imgs = np.array(train_imgs)\nval_imgs = np.array(val_imgs)\n\ntrain_imgs.shape, val_imgs.shape","a6ba9f35":"fig=plt.figure(figsize=(15,15))\ncolumns = 2\nrows = 2\nfor i in range(1, columns*rows +1):\n    img = np.random.randint(10)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(train_imgs[i])\nplt.show()","b585d3ff":"fig=plt.figure(figsize=(15,15))\ncolumns = 2\nrows = 2\nfor i in range(1, columns*rows +1):\n    img = np.random.randint(10)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(val_imgs[i])\nplt.show()","870ab440":"from collections import Counter\nprint(Counter(train_labels))\nprint(Counter(val_labels))","24969e21":"train_enc_labels = []; val_enc_labels = []\n\nencoding = dict({\"G\" : 0, \"D\" : 1, \"F\" : 2 })\nfor label in train_labels:\n    train_enc_labels.append(encoding[label])\n\nfor label in val_labels:\n    val_enc_labels.append(encoding[label])\n\ntrain_enc_labels = np.array(train_enc_labels, \"int\")\nval_enc_labels = np.array(val_enc_labels, \"int\")","d1e7afad":"print(f\"train_imgs shape : {train_imgs.shape}\")\nprint(f\"val_imgs shape : {val_imgs.shape}\")\nprint(f\"train_enc_labels shape : {train_enc_labels.shape}\")\nprint(f\"val_enc_labels shape : {val_enc_labels.shape}\")","7d038d24":"train_pairs, train_pair_labels = make_pairs(train_imgs, train_enc_labels)\nval_pairs, val_pair_labels = make_pairs(val_imgs, val_enc_labels)","0ad3eea0":"print(f\"train_pairs shape : {train_pairs.shape}\")\nprint(f\"val_pairs shape : {val_pairs.shape}\")\nprint(f\"train_pair_labels shape : {train_pair_labels.shape}\")\nprint(f\"val_pair_labels shape : {val_pair_labels.shape}\")","7a59455f":"\nimages = []\nfor i in np.random.choice(np.arange(0, len(train_pairs)), size=(49,)):\n\t# grab the current image pair and label\n\timageA = train_pairs[i][0]\n\timageB = train_pairs[i][1]\n\tlabel = train_pair_labels[i]\n\t# to make it easier to visualize the pairs and their positive or\n\t# negative annotations, we're going to \"pad\" the pair with two\n\t# pixels along the top, bottom, and right borders, respectively\n\toutput = np.zeros((300, 600, 3), dtype=\"uint8\")\n\tpair = np.hstack([imageA, imageB])\n\toutput[2:226, 2:450,:] = pair\n\t# set the text label for the pair along with what color we are\n\t# going to draw the pair in (green for a \"positive\" pair and\n\t# red for a \"negative\" pair)\n\ttext = \"neg\" if label[0] == 0 else \"pos\"\n\tcolor = (225, 0, 0) if label[0] == 0 else (0, 255, 0)\n\t# create a 3-channel RGB image from the grayscale pair, resize\n\t# it from 60x36 to 96x51 (so we can better see it), and then\n\t# draw what type of pair it is on the image\n\tvis = cv2.merge([output])\n\tvis = cv2.resize(vis, (96, 51), interpolation=cv2.INTER_LINEAR)\n\tcv2.putText(vis, text, (20, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2)\n\t# add the pair visualization to our list of output images\n\timages.append(vis)\n# construct the montage for the images\nmontage = build_montages(images, (96, 51), (7, 7))[0]\n# show the output montage\nplt.figure(figsize=(20, 20))\nplt.xticks([])\nplt.yticks([])\nprint(\"The images pairs will not appear if we have normalized the image data\")\nplt.imshow(montage);\nplt.imsave(\"Montage.jpeg\", montage)","b6628b3c":"def build_siamese_model(inputShape, embeddingDim=48):\n\t# specify the inputs for the feature extractor network\n\tinputs = Input(inputShape)\n\n\t# define the first set of CONV => RELU => POOL => DROPOUT layers\n\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n\tx = MaxPooling2D(pool_size=(2, 2))(x)\n\tx = Dropout(0.3)(x)\n\n\t# second set of CONV => RELU => POOL => DROPOUT layers\n\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n\tx = MaxPooling2D(pool_size=2)(x)\n\tx = Dropout(0.3)(x)\n\n\t# prepare the final outputs\n\tpooledOutput = GlobalAveragePooling2D()(x)\n\toutputs = Dense(embeddingDim, name=\"Emdedding\")(pooledOutput)\n\n\t# build the model\n\tmodel = Model(inputs, outputs)\n\n\t# return the model to the calling function\n\treturn model","b35a021d":"# configure the siamese network\nimgA = Input(shape=IMG_SHAPE)\nimgB = Input(shape=IMG_SHAPE)\nfeatureExtractor = build_siamese_model(IMG_SHAPE, 128)\nfeatsA = featureExtractor(imgA)\nfeatsB = featureExtractor(imgB)\n\n# finally, construct the siamese network\ndistance = Lambda(euclidean_distance, name=\"Euclidean_distance\")([featsA, featsB])\noutputs = Dense(1, activation=\"sigmoid\", name=\"similarity\")(distance)\nmodel = Model(inputs=[imgA, imgB], outputs=outputs, name=\"SiameseNetwork\")\n\n\n# compile the model\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\tmetrics=[\"accuracy\"])","1fea2f5e":"plot_model(featureExtractor, to_file='featureExtractor.png', show_shapes=True, show_layer_names=True)","545c2f18":"plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)","a79f93cf":"featureExtractor.summary()","d8b23c8f":"model.summary()","f8f0e254":"EPOCHS = 100\nc1= PlotLossesKeras()\nc2=EarlyStopping(monitor=\"val_loss\",\n    min_delta=0,\n    patience=0,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=False)\n","340a290d":"print(train_pairs[:, 0].shape)\nprint(train_pair_labels[:].shape)","67e0773f":"x_train = np.array([train_pairs[:, 0], train_pairs[:, 1]])\ny_train = train_pair_labels[:]\nx_val = np.array([val_pairs[:, 0], val_pairs[:, 1]])\ny_val = val_pair_labels[:]\n\nprint(f\"x_train shape : {x_train.shape}\")\nprint(f\"y_train shape : {y_train.shape}\")\nprint(f\"x_val shape : {x_val.shape}\")\nprint(f\"y_val shape : {y_val.shape}\")","090dfe9d":"BATCH_SIZE = 32; EPOCHS = 100\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\ntrain_history = model.fit([train_pairs[:, 0], train_pairs[:, 1]], train_pair_labels[:],\n                          batch_size = BATCH_SIZE,callbacks=[c1],\n                          epochs = EPOCHS)","3fd23bb7":"model.evaluate( [val_pairs[:, 0], val_pairs[:, 1]], val_pair_labels[:])","7d988eda":"My colab Notebook\nhttps:\/\/colab.research.google.com\/drive\/1Jp1ODGrGIb6B-9OLGdBejzUGWMpMaeYT#scrollTo=xymXaSbHBFZ3"}}