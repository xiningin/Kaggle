{"cell_type":{"3df53638":"code","32938319":"code","4bf4cf6b":"code","0c3858cf":"code","6c284904":"code","fc62e4e5":"code","db4929fb":"markdown","7c4c3f10":"markdown","fea32f82":"markdown","5dea4bcc":"markdown","c7ecfeea":"markdown","7905de13":"markdown"},"source":{"3df53638":"import pandas as pd\nimport numpy as np\n\nsource = '\/kaggle\/input\/digit-recognizer\/{file}'\n\ntrain_df = pd.read_csv(source.format(file='train.csv'))\ntest_df = pd.read_csv(source.format(file='test.csv'))\n\noriginal_test_X = test_df.values\n\noriginal_train_X = train_df.iloc[:, 1:].values\noriginal_train_y = train_df.iloc[:, :1].values","32938319":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nX = np.concatenate([original_train_X, original_test_X])\n\n# Scale data\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X)\n\nX_train, X_test = np.split(X, [42000])\ny_train = to_categorical(original_train_y)\n\nX_train = np.reshape(X_train, (X_train.shape[0],) + (28,28, 1))\nprint(f\"Data size X: {X_train.shape}, y: {y_train.shape}\")\n\nX_test = np.reshape(X_test, (X_test.shape[0],) + (28,28, 1))\nprint(f\"Data size X: {X_test.shape}\")","4bf4cf6b":"# Prepare model architecture\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n\n# Prepare model architecture\nmodel = tf.keras.Sequential([\n    layers.Conv2D(32, kernel_size=3,padding='same',activation='relu', input_shape=(28,28,1)),\n    layers.BatchNormalization(),\n    layers.Conv2D(32, kernel_size=3,padding='same',activation='relu', input_shape=(28,28,1)),\n    layers.BatchNormalization(),\n    layers.MaxPool2D(),\n    layers.BatchNormalization(),\n    layers.Dropout(0.35),\n\n    layers.Conv2D(48, kernel_size=3,padding='same',activation='relu'),\n    layers.BatchNormalization(),\n    layers.Conv2D(48, kernel_size=3,padding='same',activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPool2D(),\n    layers.BatchNormalization(),\n    layers.Dropout(0.35),    \n\n    layers.Conv2D(64, kernel_size=3,padding='same',activation='relu'),\n    layers.BatchNormalization(),\n    layers.Conv2D(64, kernel_size=3,padding='same',activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPool2D(),\n    layers.BatchNormalization(),\n    layers.Dropout(0.35),\n\n    layers.Flatten(),\n    layers.Dense(units=128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.35),\n\n    layers.Dense(units=64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.35),\n\n    layers.Dense(10, activation='softmax')\n])\n\ncallbacks_reduce_learning_rate = [\n    ReduceLROnPlateau(monitor='loss', factor=0.6, verbose=1, patience=2, min_lr=0.000000001)\n]","0c3858cf":"from tensorflow.keras.models import clone_model\nfrom sklearn.model_selection import train_test_split\n\n\nX_cross_train, X_cross_test, y_cross_train, y_cross_test = train_test_split(X_train, y_train, train_size=30000)\nepochs = 1\nvalidation_model = clone_model(model)\nvalidation_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nvalidation_model.fit(X_cross_train, y_cross_train, epochs=epochs, validation_data=(X_cross_test, y_cross_test), callbacks=callbacks_reduce_learning_rate)","6c284904":"epochs = 50\ntrain_model = clone_model(model)\ntrain_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ntrain_model.fit(X_train, y_train, epochs=epochs, callbacks=callbacks_reduce_learning_rate)","fc62e4e5":"predict_matrix = train_model.predict(X_test)\npredict = np.argmax(predict_matrix,axis = 1)\npredict = pd.Series(predict, name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"), predict],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","db4929fb":"### <a id='22'>Train:<\/a>","7c4c3f10":"### <a id='11'>Loading data:<\/a>","fea32f82":"### <a id='21'>Cross Validation:<\/a>","5dea4bcc":"### <a id='12'>Future scaling:<\/a>","c7ecfeea":"### <a id='31'>Submission:<\/a>","7905de13":"# <a id='0'>Content<\/a>\n- <a href='#1'>Data<\/a>\n    - <a href='#11'>Loading data<\/a>\n    - <a href='#12'>Future scaling<\/a>\n- <a href='#2'>Model<\/a>\n    - <a href='#21'>CrossValidation<\/a>\n    - <a href='#22'>Train<\/a>\n- <a href='#3'>Submission<\/a>\n"}}