{"cell_type":{"ba929bb8":"code","847ce7e7":"code","cb200023":"code","23e465e3":"code","75fa3846":"code","8fed04d7":"code","4e367cf5":"code","874957f3":"code","69a001e7":"code","6cb5fd65":"code","21331e93":"code","3ab9c1a0":"code","263e4308":"code","a4bcdcf6":"code","0d727d81":"code","e60be3ca":"code","514c0936":"code","549f932d":"code","2c0a4ba7":"code","c11e0a79":"code","1cae6643":"code","1d5c9643":"code","c9e119ac":"code","d5dc3f83":"code","cd3050f7":"code","cd0a2b02":"code","dcd75ca1":"code","7eacc47d":"code","fc6f2a0b":"code","8e14da76":"code","567d7ec5":"code","5d9f7c9b":"markdown","40678ee4":"markdown","4bea2d1c":"markdown","5988ab3d":"markdown","ca959af2":"markdown","0a07dcb5":"markdown","afe204a9":"markdown","0b235474":"markdown"},"source":{"ba929bb8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, TimeDistributed, ConvLSTM2D, Reshape\nimport tensorflow as tf\nimport sklearn.metrics as sm\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","847ce7e7":"def mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\ndef metrics(pred, y_test):\n    evs = sm.explained_variance_score(y_test, pred)\n    me = sm.max_error(y_test, pred)\n    mae = sm.mean_absolute_error(y_test, pred)\n    mse = sm.mean_squared_error(y_test, pred)\n    rmse = np.sqrt(mse)\n    #msle = sm.mean_squared_log_error(y_test, pred)\n    m_ae = sm.median_absolute_error(y_test, pred)\n    r2 = sm.r2_score(y_test, pred)\n    #mpd = sm.mean_poisson_deviance(y_test, pred)\n    #mgd = sm.mean_gamma_deviance(y_test, pred)\n    mape = mean_absolute_percentage_error(pred, y_test)\n    return({'Explained Variance Score': evs,\n            'Max Error': me,\n            'Mean Absolute Error': mae,\n            'Mean Squared Error': mse,\n            'Root Mean Squared Error': rmse,\n            #'Mean Squared Log Error': msle,\n            'Median Absolute Error': m_ae,\n            'R\u00b2 Score': r2,\n            #'Mean Poisson Deviance': mpd,\n            #'Mean Gamma Deviance': mgd,\n            'Mean Absolute Percentage Error': mape\n            })","cb200023":"path = \"\/kaggle\/input\/competitive-data-science-predict-future-sales\/\"\n\nitems = pd.read_csv(path+'\/items.csv')\nitem_cats = pd.read_csv(path+'\/item_categories.csv')\nshops = pd.read_csv(path+'\/shops.csv')\nsales = pd.read_csv(path+'\/sales_train.csv')\ntest = pd.read_csv(path+'\/test.csv')\nsubmission = pd.read_csv(path+'\/sample_submission.csv')","23e465e3":"pre_df = sales.copy()\npre_df = pre_df.pivot_table(\n    index=['shop_id', 'item_id'],\n    values=['item_cnt_day'],\n    columns=['date_block_num'],\n    fill_value=0,\n    aggfunc='sum'\n).reset_index()\n\npre_df","75fa3846":"full_train_df = test.copy()\nfull_train_df = full_train_df.merge(pre_df, how='left', on=['shop_id', 'item_id']).fillna(0).drop(\n    ['ID', 'shop_id', 'item_id'], axis=1)\nfull_train_df","8fed04d7":"X_train, y_train = full_train_df.values[:,:-2], full_train_df.values[:, -2:-1].ravel()\nX_valid, y_valid = full_train_df.values[:,1:-1], full_train_df.values[:, -1:].ravel()\nX_test = full_train_df.values[:, 2:]","4e367cf5":"early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=3)","874957f3":"modelMLP = Sequential()\nmodelMLP.add(Dense(8, activation='relu', input_dim=X_train.shape[1]))\nmodelMLP.add(Dense(1))\nmodelMLP.compile(optimizer='adam', loss='mse')\nhistory = modelMLP.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, callbacks=[early_stop], validation_data = (X_valid, y_valid))","69a001e7":"MLPpred = modelMLP.predict(X_valid, verbose=0)\nMLPpred = MLPpred.reshape((MLPpred.shape[0]))\nMLPresults = metrics(MLPpred, y_valid)\nMLPresults","6cb5fd65":"MLPnovember = modelMLP.predict(X_test, verbose=0)\nMLPnovember = MLPnovember.reshape((MLPnovember.shape[0]))","21331e93":"X_train = X_train.reshape((X_test.shape[0], X_train.shape[1], 1))\nX_valid = X_valid.reshape((X_test.shape[0], X_valid.shape[1], 1))\nX_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))","3ab9c1a0":"modelCNN = Sequential()\nmodelCNN.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\nmodelCNN.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\nmodelCNN.add(Conv1D(filters=16, kernel_size=2, activation='relu'))\nmodelCNN.add(Conv1D(filters=8, kernel_size=2, activation='relu'))\nmodelCNN.add(MaxPooling1D(pool_size=2))\nmodelCNN.add(Flatten())\nmodelCNN.add(Dense(1))\nmodelCNN.compile(optimizer='adam', loss='mse')\nhistory = modelCNN.fit(X_train, y_train, batch_size=512, epochs=10, verbose=1, callbacks=[early_stop], validation_data = (X_valid, y_valid))","263e4308":"CNNpred = modelCNN.predict(X_valid, verbose=0)\nCNNpred = CNNpred.reshape((CNNpred.shape[0]))\nCNNresults = metrics(CNNpred, y_valid)\nCNNresults","a4bcdcf6":"CNNnovember = modelCNN.predict(X_test, verbose=0)\nCNNnovember = CNNnovember.reshape((CNNnovember.shape[0]))","0d727d81":"modelLSTM = Sequential()\nmodelLSTM.add(LSTM(16, activation='relu', input_shape=(X_train.shape[1], 1)))\nmodelLSTM.add(Dense(1))\nmodelLSTM.compile(optimizer='adam', loss='mse')\nhistory = modelLSTM.fit(X_train, y_train, batch_size=512, epochs=10, verbose=1, callbacks=[early_stop], validation_data = (X_valid, y_valid))","e60be3ca":"LSTMpred = modelLSTM.predict(X_valid, verbose=0)\nLSTMpred = LSTMpred.reshape((LSTMpred.shape[0]))\nLSTMresults = metrics(LSTMpred, y_valid)\nLSTMresults","514c0936":"LSTMnovember = modelLSTM.predict(X_test, verbose=0)\nLSTMnovember = LSTMnovember.reshape((LSTMnovember.shape[0]))","549f932d":"subsequences = 2\ntimesteps = X_train.shape[1]\/\/subsequences\nX_train = X_train.reshape((X_train.shape[0], subsequences, timesteps, 1))\nX_valid = X_train.reshape((X_train.shape[0], subsequences, timesteps, 1))\nX_test = X_train.reshape((X_train.shape[0], subsequences, timesteps, 1))","2c0a4ba7":"modelCNNLSTM = Sequential()\nmodelCNNLSTM.add(TimeDistributed(Conv1D(filters=64, kernel_size=8, activation='relu'), input_shape=(None, X_train.shape[2], X_train.shape[3])))\nmodelCNNLSTM.add(TimeDistributed(MaxPooling1D(pool_size=4)))\nmodelCNNLSTM.add(TimeDistributed(Flatten()))\nmodelCNNLSTM.add(LSTM(64, activation='relu'))\nmodelCNNLSTM.add(Dense(1))\nmodelCNNLSTM.compile(optimizer='adam', loss='mse')\nhistory = modelCNNLSTM.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, callbacks=[early_stop], validation_data = (X_valid, y_valid))","c11e0a79":"CNNLSTMpred = modelCNNLSTM.predict(X_valid, verbose=0)\nCNNLSTMpred = CNNLSTMpred.reshape((CNNLSTMpred.shape[0]))\nCNNLSTMresults = metrics(CNNLSTMpred, y_valid)\nCNNLSTMresults","1cae6643":"CNNLSTMnovember = modelCNNLSTM.predict(X_test, verbose=0)\nCNNLSTMnovember = CNNLSTMnovember.reshape((CNNLSTMnovember.shape[0]))","1d5c9643":"X_train = X_train.reshape((X_train.shape[0], subsequences, 1, timesteps, 1))\nX_valid = X_train.reshape((X_train.shape[0], subsequences, 1, timesteps, 1))\nX_test = X_train.reshape((X_train.shape[0], subsequences, 1, timesteps, 1))","c9e119ac":"modelConvLSTM = Sequential()\nmodelConvLSTM.add(ConvLSTM2D(filters=32, kernel_size=(1,2), activation='relu', return_sequences=True,input_shape=(X_train.shape[1], 1, X_train.shape[3], X_train.shape[4])))\nmodelConvLSTM.add(ConvLSTM2D(filters=16, kernel_size=(1,2), activation='relu'))\nmodelConvLSTM.add(Flatten())\nmodelConvLSTM.add(Dense(1))\nmodelConvLSTM.compile(optimizer='adam', loss='mse')\nhistory = modelConvLSTM.fit(X_train, y_train, batch_size=512, epochs=10, verbose=1, callbacks=[early_stop], validation_data = (X_valid, y_valid))","d5dc3f83":"ConvLSTMpred = modelConvLSTM.predict(X_valid, verbose=0)\nConvLSTMpred = ConvLSTMpred.reshape((ConvLSTMpred.shape[0]))\nConvLSTMresults = metrics(ConvLSTMpred, y_valid)\nConvLSTMresults","cd3050f7":"ConvLSTMnovember = modelConvLSTM.predict(X_test, verbose=0)\nConvLSTMnovember = ConvLSTMnovember.reshape((ConvLSTMnovember.shape[0]))","cd0a2b02":"names = ['MLP', 'CNN', 'LSTM', 'CNN-LSTM', 'ConvLSTM']\npd.DataFrame([MLPresults, \n              CNNresults,\n              LSTMresults,\n              CNNLSTMresults,\n              ConvLSTMresults],\n              index = names)","dcd75ca1":"results = {\n    'MLP':MLPnovember,\n    'CNN':CNNnovember,\n    'LSTM':LSTMnovember,\n    'CNNLSTM':CNNLSTMnovember,\n    'ConvLSTM':ConvLSTMnovember\n}","7eacc47d":"resultdf = pd.DataFrame.from_dict(results)\nresultdf = pd.concat([test, resultdf], axis = 1).drop(['ID', 'shop_id', 'item_id'],axis = 1)\nresultdf","fc6f2a0b":"meanresult = resultdf.mean(axis=1).rename(\"item_cnt_month\").reset_index().rename(columns={'index': 'ID'})\nmeanresult","8e14da76":"meanresult.to_csv('.\/output.csv', index=False)","567d7ec5":"modelMLP.save('.\/modelMLP.h5')\nmodelCNN.save('.\/modelCNN.h5')\nmodelLSTM.save('.\/modelLSTM.h5')\nmodelCNNLSTM.save('.\/modelCNNLSTM.h5')\nmodelConvLSTM.save('.\/modelConvLSTM.h5')","5d9f7c9b":"# **CNN-LSTM**","40678ee4":"# **MLP**","4bea2d1c":"# **Save Models & Results**","5988ab3d":"# **ConvLSTM**","ca959af2":"# **Predict November**","0a07dcb5":"# **LSTM**","afe204a9":"# **Results**","0b235474":"# **CNN**"}}