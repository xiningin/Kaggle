{"cell_type":{"4de5d66c":"code","c54fe128":"code","c15a152a":"code","7424f8c3":"code","ebea6cc4":"code","c3ddab29":"code","314bc773":"code","ddde98a6":"code","1e59953d":"code","202f9722":"code","1f7b421a":"code","74d84357":"code","191b2efb":"code","2cd51db8":"code","4f720282":"code","05507189":"code","04f1cbd1":"code","e0862b43":"code","0ccb918b":"code","786bd679":"code","9436d2b5":"markdown","ec4ce8bf":"markdown","b23878ed":"markdown","e2216837":"markdown","505660de":"markdown","d9a2225e":"markdown","2dc2146e":"markdown","23a310ce":"markdown","7138ca30":"markdown"},"source":{"4de5d66c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pickle\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","c54fe128":"train = pd.read_csv('\/kaggle\/input\/challenges-in-representation-learning-facial-expression-recognition-challenge\/train.csv')\nprint(train.shape)","c15a152a":"train.head()","7424f8c3":"emotion_prop = (train.emotion.value_counts() \/ len(train)).to_frame().sort_index(ascending=True)\n\nemotion_prop","ebea6cc4":"emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']","c3ddab29":"palette = ['orchid', 'lightcoral', 'orange', 'gold', 'lightgreen', 'deepskyblue', 'cornflowerblue']\n\nplt.figure(figsize=[12,6])\n\nplt.bar(x=emotions, height=emotion_prop['emotion'], color=palette, edgecolor='black')\n    \nplt.xlabel('Emotion')\nplt.ylabel('Proportion')\nplt.title('Proportion of Emotion Labels')\nplt.show()","314bc773":"def pixels_to_array(pixels):\n    array = np.array(pixels.split(),'float64')\n    return array\n\ndef image_reshape(data):\n    image = np.reshape(data['pixels'].to_list(),(data.shape[0],48,48,1))\n    return image","ddde98a6":"train['pixels'] = train['pixels'].apply(pixels_to_array)\nX = image_reshape(train)\ny = train['emotion']","1e59953d":"plt.figure(figsize=[12,12])\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.imshow(X[i],cmap=\"gray\")\n    plt.title(emotions[y[i]])\n    plt.axis(\"off\")\nplt.show()","202f9722":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)","1f7b421a":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_valid.shape)\nprint(y_valid.shape)","74d84357":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same', input_shape=(48,48,1)),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    BatchNormalization(),\n\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n    \n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.25),\n    BatchNormalization(),\n    Dense(7, activation='softmax')\n])\n\ncnn.summary()","191b2efb":"opt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","2cd51db8":"%%time \n\nh1 = cnn.fit(\n    X_train, y_train, \n    batch_size=256,\n    epochs = 20,\n    verbose = 1,\n    validation_data = (X_valid, y_valid)\n)","4f720282":"history = h1.history\nprint(history.keys())","05507189":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","04f1cbd1":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","e0862b43":"%%time \n\nh2 = cnn.fit(\n    X_train, y_train, \n    batch_size=256,\n    epochs = 20,\n    verbose = 1,\n    validation_data = (X_valid, y_valid)\n)","0ccb918b":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","786bd679":"cnn.save('fer_model_v01.h5')\npickle.dump(history, open(f'fer_v01.pkl', 'wb'))","9436d2b5":"## View Sample of Images","ec4ce8bf":"## Import Packages","b23878ed":"## Save Model and History","e2216837":"## Label Distribution","505660de":"# **Facial Expression Recognition Training Notebook**\n### Sara Manrriquez","d9a2225e":"## Split Data","2dc2146e":"## Load Training DataFrame","23a310ce":"## Train Network","7138ca30":"## Build Network"}}