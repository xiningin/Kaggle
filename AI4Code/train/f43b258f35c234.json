{"cell_type":{"111bfc35":"code","7fa30e5e":"code","456a544f":"code","6124f5c4":"code","a831aa4d":"code","9910fa90":"code","2491fae9":"code","f5b47955":"code","de3894a3":"code","51b93c88":"code","fbdfcece":"code","d7241a9b":"code","cc89d2af":"code","5fe01311":"markdown","84f185d1":"markdown","6a066748":"markdown"},"source":{"111bfc35":"import numpy as np \nimport pandas as pd \nimport os \nimport tensorflow as tf \nimport keras\nfrom tensorflow.keras import Input, Model \nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, AlphaDropout, MaxPooling2D, AveragePooling2D, BatchNormalization, Concatenate, Flatten, Reshape, Add, Activation\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom keras.utils.np_utils import to_categorical\nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler ","7fa30e5e":"train_features = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_targets = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\nss = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv') ","456a544f":"def preprocess(df):\n    df = df.copy()\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2}) \n    del df['sig_id']\n    return df\n","6124f5c4":"train_ftr = preprocess(train_features) \ntest_ftr = preprocess(test_features)  ","a831aa4d":"x_train = train_ftr.values \nx_test = test_ftr.values ","9910fa90":"# column-wise standardization \nscalers = [] \nfor i in range(3,x_train.shape[1]): \n    arr = x_train[:,i]\n    arr = arr.reshape(-1,1) \n    sc = StandardScaler() \n    sc.fit(arr) \n    arr = sc.transform(arr) \n    arr = arr.reshape(arr.shape[0]) \n    x_train[:,i] = arr  \n    scalers.append(sc)\n\nfor i in range(3, x_test.shape[1]): \n    sc = scalers[i-3] \n    arr = x_test[:,i] \n    arr = arr.reshape(-1,1)\n    arr = sc.transform(arr) \n    arr = arr.reshape(arr.shape[0])\n    x_test[:,i] = arr \n","2491fae9":"models = [] \nfiles = [x for x in os.listdir('..\/input\/simple-resnet-best-models\/')]\ncnt = 1 \nfor file in files: \n    print(\"loading model {} ...\".format(cnt))\n    model = load_model(os.path.join('..\/input\/simple-resnet-best-models\/',file))\n    models.append(model)\n    cnt += 1","f5b47955":"preds = [] \nfor model in models: \n    pred = model.predict(x_test)\n    preds.append(pred)","de3894a3":"pred_avg = (preds[0] + preds[1] + preds[2] + preds[3] + preds[4] + preds[5] + preds[6] + preds[7] + preds[8] + preds[9])","51b93c88":"pred_avg \/= 10 ","fbdfcece":"for i in range(ss.shape[0]):\n    ss.iloc[i,1:] = pred_avg[i] ","d7241a9b":"ss.head(5) ","cc89d2af":"ss.to_csv('submission.csv', index = False)","5fe01311":"I used the same resnet structure from [this notebook](https:\/\/www.kaggle.com\/sudokill\/moa-keras-simple-resnet-first-submission). \n\nThe difference is that this time, I used multi label straitifed 10-fold ensemble. ","84f185d1":"# Load model and make predictions","6a066748":"# Data Preprocessing Step"}}