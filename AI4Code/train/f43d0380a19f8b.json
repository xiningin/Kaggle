{"cell_type":{"2f745baf":"code","8390331c":"code","4f777857":"code","9ee4a30a":"code","00a9ad6a":"code","c297b32e":"code","03a1c34c":"code","ad36fe99":"code","1e5e67eb":"code","6b0985cd":"code","2f92f9ae":"code","d2310150":"code","a4dd2da9":"code","84d20164":"code","7d53c0cb":"code","b57c4d90":"code","48a35391":"code","deba116b":"code","2d107110":"code","bdd624a7":"code","b53e7afe":"code","eaeaf7f1":"code","293a7833":"code","5ed851a8":"markdown","18ab7a6c":"markdown","eee6b80a":"markdown","aaa8030a":"markdown","68c3faea":"markdown","ed95398a":"markdown","0c4ae2d8":"markdown","455effb7":"markdown","21aff141":"markdown","cfa79d11":"markdown","0f2222eb":"markdown","d8099cbb":"markdown","3ee3b27f":"markdown","8e6b5e4a":"markdown","7a9aea84":"markdown"},"source":{"2f745baf":"import re\nimport requests","8390331c":"url = 'https:\/\/www.gutenberg.org\/files\/2638\/2638-0.txt'\nraw = requests.get(url).text\nprint(raw[:500])","4f777857":"pattern = re.compile(r'Title:\\s(\\w+\\s\\w+)')\nprint(pattern.findall(raw))","9ee4a30a":"pattern = re.compile(r'Release Date:\\s(\\w+\\,\\s\\d{4})')\nprint(pattern.findall(raw))\n\npattern = re.compile(r'updated:\\s(\\w+\\s\\d{2},\\s\\d{4})')\nprint(pattern.findall(raw))","00a9ad6a":"pattern = re.compile(r'PART\\s.+\\b')\nTotal_Part = set(pattern.findall(raw)) # Converting to set\nprint(Total_Part)","c297b32e":"pattern = re.compile(r'PART I\\b|PART II\\b')\n\npart_1_2_list = [(i.group(0),i.start(),i.end()) for i in pattern.finditer(raw)][-2:]\nPART_1_data = raw[part_1_2_list[0][1]:part_1_2_list[1][1]]\nprint(PART_1_data[:500])","03a1c34c":"pattern = re.compile(r'\\bI\\.|\\bII\\.')\npart_1_subdata_list = [(i.group(0),i.start(),i.end())for i in pattern.finditer(PART_1_data)][:2]\npart_1_subdata = PART_1_data[part_1_subdata_list[0][1]:part_1_subdata_list[1][1]]\nprint(part_1_subdata[:500])","ad36fe99":"pattern = re.compile(r'[^\\x00-\\x7F]') # replacing non-ascii characters with ' \" '\npart_1_subdata = pattern.sub('\"',part_1_subdata) \npart_1_subdata = re.sub(r'\"\"\"',r'\"',part_1_subdata)","1e5e67eb":"pattern = re.compile(r'\".+\"')\npattern.findall(part_1_subdata)[:10]","6b0985cd":"pattern = re.compile(r'www\\.\\w+\\.\\w{2,3}[\/\\w+]*')\nset(pattern.findall(raw)) ","2f92f9ae":"pattern = re.compile(r'Section\\s\\d')\nset(pattern.findall(raw)) ","d2310150":"pattern = re.compile(r'\\d\\.[A-Z][\\.\\d]*')\nset(pattern.findall(raw)) ","a4dd2da9":"pattern = re.compile(r'\\d{4}')\nset(pattern.findall(raw))","84d20164":"raw[:500]\n\n# Below we can see that there are many junk characters and non-ascii characters that we need to remove","7d53c0cb":"raw_punc = re.sub(r'[^a-zA-Z\\s]|\\n|\\r|I|V',' ',raw)\nraw_punc = re.sub(r'\\s+',' ',raw_punc)\nraw_punc[:500]","b57c4d90":"raw_lower = raw_punc.lower()\nraw_lower[:500]","48a35391":"raw_stopwords = raw_lower.split()\nraw_stopwords[:10]\n\n# Creating a list of words","deba116b":"raw_stopwords = [x for x in raw_stopwords if len(x)>2]\nraw_stopwords[:10]\n\n# Creating a list of words with length greater than 2","2d107110":"!pip install stopwords # Inbuilt library that contains list of stop words","bdd624a7":"import nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\n\nstop = stopwords.words('english')\nstop[:10]","b53e7afe":"cleaned_words_data = [x for x in raw_stopwords if x not in stop]\ncleaned_words_data[:10]","eaeaf7f1":"freq_words = nltk.FreqDist(cleaned_words_data)\n\n# Calculating count of words","293a7833":"sorted(freq_words.items(),key= lambda x: x[1], reverse=True)[:20]\n\n# Sorting the data and fetching top 20 most used words","5ed851a8":"## Q.8 Extract all unique section's from the end of book","18ab7a6c":"## Q.9 Extract all unique sub section from section 1 of book\n\n\n","eee6b80a":"# Cleaning the data for processing\n\n### Here cleaning is referred to \n```\n1.   Removing Punctuations\n2.   Lowercasing\n3.   Removing stopwords\n```\n\n\n\n","aaa8030a":"## 3.   Removing stopwords","68c3faea":"## Q.2 Extract release and updated date","ed95398a":"## Q.6 Extract all the one line phrases from above data in variable 'part_1_subdata'","0c4ae2d8":"## Q.5 Extract text data from I. to II. of only PART I","455effb7":"## Q.1 Extract the title of the book","21aff141":"## Q.7 Extract all unique URL's from book","cfa79d11":"# REGEX\n\n\n<img src='https:\/\/drive.google.com\/uc?export=view&id=1yi9hiNOMdcG19eJh-t2p_rAz7zUrsIeq' height=400>\n\nWe will be extracting data from [url](https:\/\/www.gutenberg.org\/files\/2638\/2638-0.txt) and solving questions using REGEX\n","0f2222eb":"## Q.4 Extract text data of only PART I","d8099cbb":"## 2.   Lowercasing","3ee3b27f":"## Q.3 Extract unique PART of book","8e6b5e4a":"## 1.   Removing Punctuations","7a9aea84":"## Q.10 Extract number that has length of 4"}}