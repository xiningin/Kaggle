{"cell_type":{"f63c65fd":"code","b42daaf0":"code","a5904ddb":"code","a5e4132b":"code","3d3a3108":"code","5a12c48a":"code","9e7aff04":"code","ef2fd347":"code","6143c362":"code","ad15f67f":"code","ce28e6ac":"code","8d452def":"code","e8a519d4":"code","91c45a06":"code","911f8d14":"code","a07ed43a":"code","c1cb5129":"code","063f3dab":"code","97ab935e":"code","0b40c53d":"code","06d20c96":"code","851683ab":"code","cab382ae":"code","91847f68":"code","304f0206":"code","bef72f6d":"code","4adca359":"code","6f1dac6b":"code","7d74aa2f":"code","f2c9a0b5":"code","ede77660":"code","91e518b5":"code","eaeaf308":"code","a32e87e7":"code","ea51c939":"code","cabf4408":"code","90adb641":"code","7796bb19":"code","346e6007":"code","4d597fd9":"code","bd266f54":"code","2228e5a7":"code","d06a9f65":"code","50da85cc":"code","8ceb850b":"code","9e13ff53":"code","b47a4d22":"code","ee353970":"code","40b6a77b":"code","5e77f8be":"code","05dc6cf7":"code","3baec293":"code","0a429ffb":"code","91d07327":"code","c2e65d01":"code","f8869052":"code","00feaf9b":"code","ee086fb9":"code","e65f9072":"code","6d683643":"code","9e0e85db":"code","e7367ed1":"code","98c94973":"code","363d273f":"code","59ce567e":"code","0b1e545d":"code","ead749db":"code","6b55ab77":"code","6147cec4":"code","761c2e93":"code","ad285a73":"code","f96a03c8":"code","4f226d45":"code","7580f624":"code","2b35a9c2":"code","6295ceb9":"code","725ad6ea":"code","d01e2679":"code","f4fd3fac":"code","58000e82":"code","bad22f28":"code","6a221a43":"code","340171a4":"code","b97e10b7":"code","6e9ca21b":"code","f5e6a0a8":"code","c68df9d8":"code","bbdd7a93":"code","bc28c093":"code","4fe28f56":"code","fcf8b992":"code","a3622a80":"code","8aee0626":"code","9358a847":"code","b80fbe4f":"code","50fc13a2":"code","35f5e39a":"code","15caaff6":"code","17150a2d":"code","19445100":"code","a39ba0b1":"code","be461d24":"code","87e90f17":"code","ba74d526":"code","48b6f97f":"code","b5a6ecbb":"code","c26baad5":"code","c1d4c8a5":"code","76c58b9b":"markdown","8ac19a90":"markdown","06fe7c95":"markdown","2cf3685c":"markdown","b39acdc0":"markdown","e7da001e":"markdown","559e46b4":"markdown","6e0e0fd9":"markdown","e269faa7":"markdown","7db86fa7":"markdown","6134d982":"markdown","14403dbf":"markdown","5964dc95":"markdown","ef958f1f":"markdown","d163b65a":"markdown","062fd203":"markdown","7c232806":"markdown","77f0bab0":"markdown","433fc931":"markdown","23582a7f":"markdown","6bae24a1":"markdown","b0b32bd1":"markdown","f2b64fa6":"markdown","404ff83b":"markdown","32b0cad1":"markdown","2f3860f7":"markdown","baf83983":"markdown","10cd2aa6":"markdown","5628f55b":"markdown","06c3aa4e":"markdown","490211b7":"markdown","5e3f85b3":"markdown","42de5ad2":"markdown","d84f3174":"markdown","02fb0002":"markdown","ada21929":"markdown","27b6f963":"markdown","aa059f3d":"markdown","93c3cbb5":"markdown","df3a81aa":"markdown","3575dac3":"markdown","8ae8235b":"markdown","5bc66d19":"markdown","32156a69":"markdown","39f6af73":"markdown","343ca783":"markdown","42e2e1ad":"markdown","d2a4a02a":"markdown","9f1100b0":"markdown","51fe36a2":"markdown","6a689e25":"markdown","bd0839f0":"markdown","f24e7c68":"markdown","b2571e7a":"markdown","06e3dfe0":"markdown","db0921bc":"markdown","c68bf799":"markdown","71bba537":"markdown","3bfce67e":"markdown","d652c48e":"markdown","5cfa2322":"markdown","e14fe1a7":"markdown","ecea7538":"markdown","97018bf1":"markdown","13a968fc":"markdown","dc5f7048":"markdown","9c09af42":"markdown","f7f57cf5":"markdown","7a5f97f7":"markdown","3978c091":"markdown","7dd9589b":"markdown","8ed07f6d":"markdown","cc570ac5":"markdown","3aad44ac":"markdown","eaf827cd":"markdown","9fe0bfed":"markdown","ee912c12":"markdown","50fcafcc":"markdown","b78fa81a":"markdown","f2cf53b0":"markdown","5bf1ec54":"markdown"},"source":{"f63c65fd":"#importing the nesserssary libraries\n#! pip install xgboost\n#! pip install mlxtend\n#! pip install lightgbm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#ignoring warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#setting display options\npd.pandas.set_option('display.max_columns',None)\n","b42daaf0":"train_df=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_df=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n","a5904ddb":"train_df.head()","a5e4132b":"test_df.head()\n","3d3a3108":"train_df.shape","5a12c48a":"test_df.shape","9e7aff04":"#no. of missing values in training dataset\npd.Series(train_df.isnull().sum(),index=train_df.columns[train_df.isnull().sum()>1])\n","ef2fd347":"#no. of missing values in test dataset\npd.Series(test_df.isnull().sum(),index=test_df.columns[test_df.isnull().sum()>1])","6143c362":"combined_df= pd.concat([train_df,test_df],ignore_index=True)","ad15f67f":"combined_df\n\n","ce28e6ac":"for i in combined_df.columns:\n    print(i,\"---->\",combined_df[i].isnull().sum()*100\/len(combined_df[i]))\n","8d452def":"combined_df.drop(['Alley',\"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\"],axis=1,inplace=True)\ntrain_df.drop(['Alley',\"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\"],axis=1,inplace=True)\ntest_df.drop(['Alley',\"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\"],axis=1,inplace=True)","e8a519d4":"train_df.info()","91c45a06":"train_df.describe()","911f8d14":"cat_fea=[]\nnum_fea=[]\nfor i,j in zip(train_df.dtypes,train_df.columns):\n    if i=='object':\n        cat_fea.append(j)\n    else:\n        num_fea.append(j)","a07ed43a":"df=train_df.copy()\n\ndf=df[cat_fea+['SalePrice']]","c1cb5129":"\n#df=df[cat_fea].fillna('missing')\nfor i in df.columns[df.isnull().sum()>0]:\n    \n    df[i+'_missing']=np.where(df[i].isnull(),1,0)\n    df.groupby(i+'_missing')['SalePrice'].median().plot.bar()\n    plt.show()\n","063f3dab":"categories_to_null=[\"MasVnrType\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\"]\nfor i in categories_to_null:\n    combined_df[i+\"_missing\"]=np.where(combined_df[i].isnull(),1,0)","97ab935e":"df=train_df.copy()\n\ndf=df[cat_fea+['SalePrice']]\nfor i in cat_fea:\n    x=df[i].mode()[0]\n    df[i].fillna(x,inplace=True)","0b40c53d":"#replacing the missing categories with mode\nfor i in cat_fea:\n    combined_df[i]=combined_df[i].fillna(combined_df[i].mode()[0])\n\n    ","06d20c96":"print(combined_df[cat_fea].isnull().sum().to_list())","851683ab":"#plotting the categories with median of the category\nfor i in df.columns:\n    df.groupby(i)['SalePrice'].median().sort_values().plot.bar()\n    plt.show()","cab382ae":"# converting the categorical values\n\nfea_code=pd.Series([1,1,1,1,1,0,0,0,1,0,0,0,0,0,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,0]).map({1:True,0:False})\nfea_code=df.columns[fea_code]","91847f68":"#encoding values in combined_df \nfor i in fea_code:\n    x=df.groupby(i)['SalePrice'].median().sort_values().index.to_list()\n    for j in range(len(x)):\n        combined_df[i]=combined_df[i].replace(x[j],j)\n    combined_df[i]=combined_df[i].astype(int)","304f0206":"#encoding values in train_df\nfor i in fea_code:\n    x=df.groupby(i)['SalePrice'].median().sort_values().index.to_list()\n    for j in range(len(x)):\n        df[i]=df[i].replace(x[j],j)\n    df[i]=df[i].astype(int)\n    \n        ","bef72f6d":"df","4adca359":"##Transforming the columns of our choice with weights for training data\ndf['LotConfig']=df['LotConfig'].replace(df.groupby('LotConfig')['SalePrice'].median().sort_values().index.to_list(),[0,0,0,1,1])\n\ndf['LandSlope']=df['LandSlope'].replace(df.groupby('LandSlope')['SalePrice'].median().sort_values().index.to_list(),[0,1,1])\n\ndf['Neighborhood']=df['Neighborhood'].replace(df.groupby('Neighborhood')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,2,2,2,3,3,3,3,3,3,4,4,4,5,5,5,5,6,6,6,8,8,8])\n\ndf['Condition2']=df['Condition2'].replace(df.groupby('Condition2')['SalePrice'].median().sort_values().index.to_list(),[0,0,1,1,2,2,4,4])\n\ndf['BldgType']=df['BldgType'].replace(df.groupby('BldgType')['SalePrice'].median().sort_values().index.to_list(),[0,0,0,1,1])\n\ndf['HouseStyle']=df['HouseStyle'].replace(df.groupby('HouseStyle')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,2,2,3,3])\n\ndf['RoofStyle']=df['RoofStyle'].replace(df.groupby('RoofStyle')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,1,2])\n\ndf['RoofMatl']=df['RoofMatl'].replace(df.groupby('RoofMatl')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,1,1,2,4])\n\ndf['Exterior2nd']=df['Exterior2nd'].replace(df.groupby('Exterior2nd')['SalePrice'].median().sort_values().index.to_list(),[0,0,1,1,1,1,1,1,2,2,2,3,3,3,4,6])\n\ndf['Foundation']=df['Foundation'].replace(df.groupby('Foundation')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,2,3,4])\n\ndf['BsmtFinType1']=df['BsmtFinType1'].replace(df.groupby('BsmtFinType1')['SalePrice'].median().sort_values().index.to_list(),[0,0,0,1,1,3])\n\ndf['Electrical']=df['Electrical'].replace(df.groupby('Electrical')['SalePrice'].median().sort_values().index.to_list(),[0,1,2,3,5])\n\ndf['Functional']=df['Functional'].replace(df.groupby('Functional')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,1,1,2])\n\ndf['SaleType']=df['SaleType'].replace(df.groupby('SaleType')['SalePrice'].median().sort_values().index.to_list(),[0,0,1,1,1,2,3,4,5])\n\ndf['SaleCondition']=df['SaleCondition'].replace(df.groupby('SaleCondition')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,1,2])\n\n\n\n\n\n\n\n\n\n","6f1dac6b":"combined_df['LotConfig']=combined_df['LotConfig'].replace(combined_df.groupby('LotConfig')['SalePrice'].median().sort_values().index.to_list(),[0,0,0,1,1])\n\ncombined_df['LandSlope']=combined_df['LandSlope'].replace(combined_df.groupby('LandSlope')['SalePrice'].median().sort_values().index.to_list(),[0,1,1])\n\ncombined_df['Neighborhood']=combined_df['Neighborhood'].replace(combined_df.groupby('Neighborhood')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,2,2,2,3,3,3,3,3,3,4,4,4,5,5,5,5,6,6,6,8,8,8])\n\ncombined_df['Condition2']=combined_df['Condition2'].replace(combined_df.groupby('Condition2')['SalePrice'].median().sort_values().index.to_list(),[0,0,1,1,2,2,4,4])\n\ncombined_df['BldgType']=combined_df['BldgType'].replace(combined_df.groupby('BldgType')['SalePrice'].median().sort_values().index.to_list(),[0,0,0,1,1])\n\ncombined_df['HouseStyle']=combined_df['HouseStyle'].replace(combined_df.groupby('HouseStyle')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,2,2,3,3])\n\ncombined_df['RoofStyle']=combined_df['RoofStyle'].replace(combined_df.groupby('RoofStyle')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,1,2])\n\ncombined_df['RoofMatl']=combined_df['RoofMatl'].replace(combined_df.groupby('RoofMatl')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,1,1,2,4])\n\ncombined_df['Exterior2nd']=combined_df['Exterior2nd'].replace(combined_df.groupby('Exterior2nd')['SalePrice'].median().sort_values().index.to_list(),[0,0,1,1,1,1,1,1,2,2,2,3,3,3,4,6])\n\ncombined_df['Foundation']=combined_df['Foundation'].replace(combined_df.groupby('Foundation')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,2,3,4])\n\ncombined_df['BsmtFinType1']=combined_df['BsmtFinType1'].replace(combined_df.groupby('BsmtFinType1')['SalePrice'].median().sort_values().index.to_list(),[0,0,0,1,1,3])\n\ncombined_df['Electrical']=combined_df['Electrical'].replace(combined_df.groupby('Electrical')['SalePrice'].median().sort_values().index.to_list(),[0,1,2,3,5])\n\ncombined_df['Functional']=combined_df['Functional'].replace(combined_df.groupby('Functional')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,1,1,2])\n\ncombined_df['SaleType']=combined_df['SaleType'].replace(combined_df.groupby('SaleType')['SalePrice'].median().sort_values().index.to_list(),[0,0,1,1,1,2,3,4,5])\n\ncombined_df['SaleCondition']=combined_df['SaleCondition'].replace(combined_df.groupby('SaleCondition')['SalePrice'].median().sort_values().index.to_list(),[0,1,1,1,1,2])\n","7d74aa2f":"df","f2c9a0b5":"#changing the datatype of the columns to int\nfea_code_rev=pd.Series([1,1,1,1,1,0,0,0,1,0,0,0,0,0,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,0]).map({0:True,1:False})\nfea_code_rev=df.columns[fea_code_rev]\nfor i in fea_code_rev:\n    if i !='SalePrice':\n        df[i]=df[i].astype(int)\n        combined_df[i]=combined_df[i].astype(int)","ede77660":"#now the columns are converted to integers\ncombined_df.info()","91e518b5":"combined_df\n","eaeaf308":"# the numerical features are num_fea\ndf_num=train_df[num_fea]\ndf_num","a32e87e7":"df_num.corr()","ea51c939":"year_fea=['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold','SalePrice']\ndf_yr=df_num[year_fea].copy()","cabf4408":"for i in year_fea:\n    plt.scatter(df_num[i],df_num['SalePrice'])\n    plt.show()","90adb641":"for i in year_fea:\n    df_yr[i+'_age']= df_yr['YrSold'] - df_yr[i]\n","7796bb19":"df_yr.corr()","346e6007":"df_yr","4d597fd9":"df_num['GarageYrBlt'].isnull().sum()","bd266f54":"df_num[['GarageCars','GarageArea']][df_num['GarageYrBlt'].isnull()]","2228e5a7":"df_yr['garage']=np.where(df_yr['GarageYrBlt'].isnull(),1,0)","d06a9f65":"df_yr.groupby('garage')['SalePrice'].median().sort_values().plot.bar()","50da85cc":"#adding new feature to combined_df\ncombined_df['garage']=np.where(combined_df['GarageYrBlt'].isnull(),1,0)","8ceb850b":"#GarageYrBlt alone has null values\ncombined_df['GarageYrBlt'].fillna(combined_df['GarageYrBlt'].mean(),inplace=True)\n","9e13ff53":"for i in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n    combined_df[i+'_age']= combined_df['YrSold'] - combined_df[i]\ncombined_df['YearRemodAdd_age']=combined_df['YearRemodAdd_age'].replace(-1,0)","b47a4d22":"old_combined=combined_df\ncombined_df","ee353970":"df_num=df_num.drop(['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold'],axis=1)","40b6a77b":"for i in df_num.columns:\n    print(i,'----->',len(df_num[i].unique()))","5e77f8be":"#seperating out the features based on no of unique values they have\ndisc_fea=['MSSubClass','OverallQual','OverallCond','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars','MoSold']\nspl_fea=['LowQualFinSF','3SsnPorch','PoolArea']\ncont_fea=[i for i in df_num.columns if i not in disc_fea and i not in spl_fea]","05dc6cf7":"df_spl=df_num.copy()\nfor i in spl_fea:\n    df_spl[i+'_new']=np.where(df_spl[i]>0,1,0)\n    df_spl.groupby(i+'_new')['SalePrice'].median().sort_values().plot.bar()\n    plt.show()","3baec293":"combined_df[spl_fea].isnull().sum()\nfor i in spl_fea:\n    combined_df[i+'_new']=np.where(combined_df[i]>0,1,0)","0a429ffb":"for i in disc_fea:\n    df_num.groupby(i)['SalePrice'].median().sort_values().plot.bar()\n    plt.show()","91d07327":"#bathroom\nbath_fea=['FullBath','HalfBath']\ndf_spl['bathroom']=df_spl[bath_fea].sum(axis=1)\ndf_spl.groupby('bathroom')['SalePrice'].median().sort_values().plot.bar()","c2e65d01":"combined_df['bathroom']=combined_df[bath_fea].sum(axis=1)","f8869052":"df_num[disc_fea+['SalePrice']].corr()","00feaf9b":"fea_todrop=['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','MoSold']\nfea_toalter=['MSSubClass','bathroom','OverallCond']","ee086fb9":"df_disc=df_num[disc_fea+['SalePrice']]\ndf_disc","e65f9072":"#dropping the unwanted features\ndf_disc=df_disc.drop(fea_todrop,axis=1)\ncombined_df=combined_df.drop(fea_todrop,axis=1)","6d683643":"#features to change\ncombined_df['bathroom']=combined_df['bathroom'].replace({0:1,1:0})\n\ndf_disc['MSSubClass']=df_disc['MSSubClass'].replace(df_disc.groupby('MSSubClass')['SalePrice'].median().sort_values().index.to_list(),[0,1,2,3,4,5,6,6,7,8,9,10,11,12,13])\ndf_disc['OverallCond']=df_disc['OverallCond'].replace({8:5,9:8,5:9})\n","9e0e85db":"\ncombined_df['MSSubClass']=combined_df['MSSubClass'].replace(combined_df.groupby('MSSubClass')['SalePrice'].median().sort_values().index.to_list(),[0,1,2,3,4,5,6,6,7,8,9,10,11,12,13,0])\ncombined_df['OverallCond']=combined_df['OverallCond'].replace({8:5,9:8,5:9})\n\n\n\n","e7367ed1":"combined_df[df_disc.columns].isnull().sum()","98c94973":"combined_df['GarageCars']=combined_df['GarageCars'].fillna(combined_df['GarageCars'].mode()[0])","363d273f":"df_cont=train_df[cont_fea].copy()\ncont_fea","59ce567e":"df_cont.drop('Id',axis=1,inplace=True)\ncombined_df.drop('Id',axis=1,inplace=True)\ncont_fea=cont_fea[1:]","0b1e545d":"df_cont.corr()['SalePrice']","ead749db":"plt.figure(figsize=(15,10))\nsns.heatmap(df_cont.corr(),cmap=\"YlGnBu\")","6b55ab77":"df_cont.isnull().sum()","6147cec4":"df_cont['LotFrontage']=df_cont['LotFrontage'].fillna(df_cont['LotFrontage'].median())","761c2e93":"for i in cont_fea:\n    sns.boxplot(df_cont[i])\n    plt.show()","ad285a73":"cont_fea=[i for i in cont_fea if i not in ['MiscVal' ,'ScreenPorch','EnclosedPorch','BsmtFinSF2']]\ndf_cont.drop(['MiscVal' ,'ScreenPorch','EnclosedPorch','BsmtFinSF2'],axis=1,inplace=True)\ncombined_df.drop(['MiscVal' ,'ScreenPorch','EnclosedPorch','BsmtFinSF2'],axis=1,inplace=True)","f96a03c8":"for i in cont_fea:\n    \n    fig=plt.figure(figsize=(10,5))\n    ax0=fig.add_subplot(1,2,1)\n    ax1=fig.add_subplot(1,2,2)\n   \n    df_cont[i].plot(kind='hist',ax=ax0)\n    \n    df_cont[[i,'SalePrice']].plot(kind='scatter',x=i,y='SalePrice',ax=ax1)\n    plt.title(i)\n    ","4f226d45":"import scipy.stats as stat\nimport pylab\nfor i in cont_fea:\n    plt.figure()\n    stat.probplot(df_cont[i],dist=\"norm\",plot=pylab)\n    plt.title(i)\n    plt.show()\n","7580f624":"#checking which plot is better\nimport scipy.stats as stat\nfrom scipy.special import boxcox1p\nlam = 0.15\nimport pylab\nbox=[]\nfor i in cont_fea:\n    \n    \n    stat.probplot(boxcox1p(df_cont[i],lam),dist=\"norm\",plot=pylab)\n    plt.title(i)\n    plt.show()\n    stat.probplot(np.log1p(df_cont[i]),dist=\"norm\",plot=pylab)\n    \n    plt.show()\n    stat.probplot(df_cont[i],dist=\"norm\",plot=pylab)\n    plt.show()\n    box.append(i)\n  ","2b35a9c2":"for i in cont_fea:\n    if i not in ['BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','2ndFlrSF','GarageArea']:\n        df_cont[i]=np.log1p(df_cont[i])\n        combined_df[i]=np.log1p(combined_df[i])","6295ceb9":"df_cont.corr()['SalePrice']\n","725ad6ea":"combined_df","d01e2679":"combined_df.isnull().sum().to_frame()","f4fd3fac":"#Lot frontage is non-skewed data, but others are wkewed data so we use mean and mode respectively\ncombined_df['LotFrontage'].fillna(combined_df['LotFrontage'].mean(),inplace=True)\ncombined_df['MasVnrArea'].fillna(combined_df['MasVnrArea'].median(),inplace=True)\ncombined_df['BsmtFinSF1'].fillna(combined_df['BsmtFinSF1'].median(),inplace=True)\ncombined_df['BsmtUnfSF'].fillna(combined_df['BsmtUnfSF'].median(),inplace=True)\ncombined_df['TotalBsmtSF'].fillna(combined_df['TotalBsmtSF'].median(),inplace=True)\ncombined_df['GarageArea'].fillna(combined_df['GarageArea'].median(),inplace=True)","58000e82":"new_combined=combined_df","bad22f28":"#only the saleprice feature has null\ncombined_df.isnull().sum().sum()","6a221a43":"#creating dummy var\nfinalt_df=combined_df[:1460].copy()","340171a4":"#getting non continuous features\ncaty_cols=[]\nfor i in finalt_df.columns:\n    if finalt_df[i].nunique()<=25 and finalt_df[i].nunique()>2:\n        caty_cols.append(i)","b97e10b7":"for i in caty_cols:\n    finalt_df.groupby(i)['SalePrice'].median().sort_values().plot.bar()\n    plt.show()","6e9ca21b":"to_onehot=['Condition2','OverallCond','ExterCond','ExterQual','MasVnrType','Foundation','BsmtCond','BsmtFinType1',\n 'Electrical','LowQualFinSF','GarageCars','3SsnPorch','SaleCondition']","f5e6a0a8":"finalt_df=pd.get_dummies(finalt_df,columns=to_onehot)","c68df9d8":"combined_df=pd.get_dummies(combined_df,columns=to_onehot)","bbdd7a93":"combined_df","bc28c093":"X= combined_df.loc[:1459,combined_df.drop('SalePrice',axis=1).columns]\ny=np.expm1(combined_df.loc[:1459,'SalePrice'])\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\n\n\nfeature_sel_model = SelectFromModel(Lasso(alpha=60, random_state=0)) # remember to set the seed, the random state in this function\nfeature_sel_model.fit(X, y)\nfeature_sel_model.get_support()","4fe28f56":"X_new=X.loc[:,X.columns[feature_sel_model.get_support()]]\nX_new","fcf8b992":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score,mean_squared_error,mean_squared_log_error,mean_absolute_error\nX_train,X_test,y_train,y_test=train_test_split(X_new,combined_df.loc[:1459,'SalePrice']\n                                               ,random_state=1)","a3622a80":"from sklearn.linear_model import LinearRegression\n\n#X= combined_df.loc[:1459,combined_df.drop('SalePrice',axis=1).columns]\n#y=combined_df.loc[:1459,'SalePrice']\n#X_train,X_test,y_train,y_test=train_test_split(X_new,y,random_state=1)\n\nlr=LinearRegression()\nlr.fit(X_train,y_train)\nlr_pred=lr.predict(X_test)\nr2_score(np.expm1(lr_pred),np.expm1(y_test))\nprint(\"r2- \",r2_score(np.expm1(lr_pred),np.expm1(y_test)))\nprint(\"msle- \",mean_squared_log_error(np.expm1(lr_pred),np.expm1(y_test)))\nprint(\"mae- \",mean_absolute_error(np.expm1(lr_pred),np.expm1(y_test)))\nprint(\"mse- \",np.sqrt(mean_squared_error(np.expm1(lr_pred),np.expm1(y_test))))","8aee0626":"from sklearn.linear_model import Lasso\nls=Lasso(alpha=60)\n\nls.fit(X_train,y_train)\nls_pred=lr.predict(X_test)\nr2_score(np.expm1(ls_pred),np.expm1(y_test))\nprint(\"r2- \",r2_score(np.expm1(ls_pred),np.expm1(y_test)))\nprint(\"msle- \",mean_squared_log_error(np.expm1(ls_pred),np.expm1(y_test)))\nprint(\"mae- \",mean_absolute_error(np.expm1(ls_pred),np.expm1(y_test)))","9358a847":"from sklearn.model_selection import KFold \nfrom sklearn.linear_model import LassoCV\n\nkfolds = KFold(n_splits=10, shuffle=True, random_state=10)\nlcv=LassoCV(alphas=[0.0000000000005,0.00005,0.0005,0.005,0.05,0.5,5,50,60],cv=kfolds)\n\nlcv.fit(X_train,y_train)\nlcv_pred=lr.predict(X_test)\nr2_score(np.expm1(lcv_pred),np.expm1(y_test))\nprint(\"r2- \",r2_score(np.expm1(lcv_pred),np.expm1(y_test)))\nprint(\"msle- \",mean_squared_log_error(np.expm1(lcv_pred),np.expm1(y_test)))\nprint(\"mae- \",mean_absolute_error(np.expm1(lcv_pred),np.expm1(y_test)))","b80fbe4f":"from sklearn.svm import SVR\nsvr=SVR()\nsvr.fit(X_train,y_train)\nsvr_pred=svr.predict(X_test)\nprint(\"r2- \",r2_score(np.expm1(svr_pred),np.expm1(y_test)))\nprint(\"msle- \",mean_squared_log_error(np.expm1(svr_pred),np.expm1(y_test)))\nprint(\"mae- \",mean_absolute_error(np.expm1(svr_pred),np.expm1(y_test)))","50fc13a2":"from sklearn.tree import DecisionTreeRegressor\ndtr=DecisionTreeRegressor()\ndtr.fit(X_train,y_train)\ndtr_pred=dtr.predict(X_test)\nr2_score(np.expm1(dtr_pred),np.expm1(y_test))\nprint(\"r2- \",r2_score(np.expm1(dtr_pred),np.expm1(y_test)))\nprint(\"msle- \",mean_squared_log_error(np.expm1(dtr_pred),np.expm1(y_test)))\nprint(\"mae- \",mean_absolute_error(np.expm1(dtr_pred),np.expm1(y_test)))","35f5e39a":"from sklearn.ensemble import RandomForestRegressor\nrfr=RandomForestRegressor()\nrfr.fit(X_train,y_train)\nrfr_pred=rfr.predict(X_test)\nr2_score(np.expm1(rfr_pred),np.expm1(y_test))\nprint(\"r2- \",r2_score(np.expm1(rfr_pred),np.expm1(y_test)))\nprint(\"msle- \",mean_squared_log_error(np.expm1(rfr_pred),np.expm1(y_test)))\nprint(\"mae- \",mean_absolute_error(np.expm1(rfr_pred),np.expm1(y_test)))","15caaff6":"from sklearn.neighbors import KNeighborsRegressor\nknr = KNeighborsRegressor()\nknr.fit(X_train,y_train)\nknr_pred=knr.predict(X_test)\nr2_score(np.expm1(knr_pred),np.expm1(y_test))\nprint(\"r2- \",r2_score(np.expm1(knr_pred),np.expm1(y_test)))\nprint(\"msle- \",mean_squared_log_error(np.expm1(knr_pred),np.expm1(y_test)))\nprint(\"mae- \",mean_absolute_error(np.expm1(knr_pred),np.expm1(y_test)))","17150a2d":"import xgboost as xgb\nmodel_xgb = xgb.XGBRegressor()\nmodel_xgb.fit(X_train,y_train)\nxgb_pred=knr.predict(X_test)\nprint(\"r2- \",r2_score(np.expm1(xgb_pred),np.expm1(y_test)))\nprint(\"msle- \",mean_squared_log_error(np.expm1(xgb_pred),np.expm1(y_test)))\nprint(\"mae- \",mean_absolute_error(np.expm1(xgb_pred),np.expm1(y_test)))","19445100":"lr=LinearRegression()\nlr.fit(X_new,y)\nran_model=RandomForestRegressor()\nran_model.fit(X_new,y)","a39ba0b1":"#importing necessary libraries\nfrom sklearn.model_selection import KFold # for cross validation\nfrom sklearn.model_selection import cross_val_score # score evaluation\nfrom sklearn.model_selection import cross_val_predict # prediction\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nimport time\nSEED = 42","be461d24":"\nkfolds = KFold(n_splits=10, shuffle=True, random_state=SEED)\n\ndef rmse(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef evaluate_model_cv(model, X, y):\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n    return (rmse)\n","87e90f17":"# model construction\ndef construct_models():\n    alphas_ridge = [0.005, 0.01, 0.1, 1, 5, 10, 15]\n    alphas_lasso = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n    e_alphas_elas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n    e_l1ratio_elas = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n    \n    \n    models = dict()\n    models['ridge'] = RidgeCV(alphas=alphas_ridge, cv=kfolds)\n    models['lasso'] = LassoCV(alphas=alphas_lasso, random_state=SEED, cv=kfolds)\n    models['elasticnet'] = ElasticNetCV(alphas=e_alphas_elas, cv=kfolds, l1_ratio=e_l1ratio_elas)\n    models['svr'] = SVR()\n    models['gbr'] = GradientBoostingRegressor(random_state =SEED) \n    models['lgbm'] = LGBMRegressor()\n    models['xgboost'] = XGBRegressor()\n    return models\n\n\nmodels = construct_models()","ba74d526":"\nfor name, model in models.items():\n    start = time.perf_counter()\n    \n    model = model.fit(np.array(X_train), np.array(y_train))\n    rmse_result = rmse(y_train, model.predict(np.array(X_train)))\n    print(f'{name}\\'s rmse after training: {rmse_result}')\n    \n    run = time.perf_counter() - start\n    print(f'Computational runtime of this algo: {round(run, 2)} seconds\\n')","48b6f97f":"cv_rmse_result = dict()\ncv_rmse_mean = dict()\ncv_rmse_std = dict()\n\nfor name, model in models.items():\n    start = time.perf_counter()\n    \n    cv_rmse_result[name] = evaluate_model_cv(model, np.array(X_train), np.array(y_train))\n    cv_rmse_mean[name] = cv_rmse_result[name].mean()\n    cv_rmse_std[name] = cv_rmse_result[name].std()\n    print(f'Finish {name}\\'s model')\n    \n\n    run = time.perf_counter() - start\n    print(f'Computational runtime of this algo: {round(run, 2)} seconds\\n')\n\nML_cv = pd.DataFrame({'cv_rsme_mean' : cv_rmse_mean, 'cv_rmse_std' : cv_rmse_std})\nML_cv","b5a6ecbb":"stack_model = StackingCVRegressor(regressors=(models['ridge'], models['lasso'], models['xgboost'],\n                                              models['elasticnet'], models['gbr'], models['lgbm']),\n                                              meta_regressor=models['xgboost'], use_features_in_secondary=True)\n\nstart = time.perf_counter()\n\nstack_model = stack_model.fit(np.array(X_train), np.array(y_train))\nprint('Finish training')\n\n\nrmse_stack = rmse(y_train, stack_model.predict(np.array(X_train)))\nprint(f'stack_model\\'s rmse (using cv) after training: {rmse_stack}')\n\nrun = time.perf_counter() - start\nprint(f'Computational runtime of this algo: {round(run, 2)} seconds\\n')\n\n","c26baad5":"def blend_models_predict(X):\n    return ((0.2 * lr.predict(np.array(X))) + \\\n            (0.05 * models['ridge'].predict(np.array(X))) + \\\n            (0.05 * models['lasso'].predict(np.array(X))) + \\\n            (0.05 * models['elasticnet'].predict(np.array(X))) + \\\n            (0.05 * models['gbr'].predict(np.array(X))) + \\\n            (0.05 * models['lgbm'].predict(np.array(X))) + \\\n            (0.25 * models['xgboost'].predict(np.array(X))) + \\\n            (0.3 * stack_model.predict(np.array(X))))\n\nprint('RMSLE score on train data:')\nprint(rmse(y_train, blend_models_predict(np.array(X_train))))","c1d4c8a5":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX= combined_df.loc[:1459,X_new.columns]\ny=combined_df.loc[:1459,'SalePrice']\nx_test=combined_df.loc[1460:,X_new.columns]\n\n\nfinal=np.expm1(blend_models_predict(np.array(x_test)))\n\n\nsubmission=pd.DataFrame()\nsubmission['Id']=test_df['Id']\nsubmission['SalePrice']=final\nsubmission=submission.set_index('Id')\nsubmission.to_csv('submission.csv')","76c58b9b":"## Analyzing the categorical Features","8ac19a90":"Considering the batroom Feature","06fe7c95":"we have to choose which transformation is best among log transform, boxcox","2cf3685c":"From the above analysis we need ['Condition2','OverallCond','ExterCond','ExterQual','MasVnrType','Foundation','BsmtCond','BsmtFinType1',\n 'Electrical','LowQualFinSF','GarageCars','3SsnPorch','SaleCondition'] these to encode onehot","b39acdc0":"#### Working with Categorical Features","e7da001e":"So the Median value differs between missing datasets in features - \"MasVnrType\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\" <br>\nSo we can Use then in test data also","559e46b4":"we could visualize the categories and decide whether to implement one hot- encoding or not.","6e0e0fd9":"#### Histogram and scatterplot (with SalePrice) of each continuous Feature","e269faa7":"## Linear Regression","7db86fa7":"# Lasso CV","6134d982":"Filling the missing value with median","14403dbf":"### Considering the discrete Features","5964dc95":"Constructing the models and storing it in a Dictionary ","ef958f1f":"This Dataset Containing more than 80 Features is Downloaded from Kaggle - https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques\n","d163b65a":"#### Univariate Analysis of Contiuous variable","062fd203":"Combining - LinearRegression(20%) , Ridge(5%) , Lasso (5%) , Elasticnet (5%) , GBR (5%) ,  LGBM (5%) ,  XGboost (25%) , Stacked model (30%)\n","7c232806":"\nHere we observe that Training and test dataset are Deviated in terms of missing values. Features Like 'MSZoning' ,'Utilities' do not have missing values in training data but have missing values in test data. So while handling missing values and encoding we have to consider both the train and test data together to get a balanced dataset.","77f0bab0":"#### Percentage of null values in each feature","433fc931":"Now we found that except 'BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','2ndFlrSF','GarageArea' all others are skewed, and log transform plays better.","23582a7f":"#### Corelation of Each Feature with SalePrice","6bae24a1":"Replacing the missing values with mode\n","b0b32bd1":"We could Find that Newly created features are more corelated than old features","f2b64fa6":"Converting the Column type of encoded columns to int","404ff83b":"## DecisionTreeRegressor","32b0cad1":"Note that we have also transformed SalePrice which must be transformed back after prediction","2f3860f7":"## XGB","baf83983":"Selecting just the useful Features by SelectFromModel using Lasso Regression","10cd2aa6":"# Modeling","5628f55b":" Most of the data is skewed so we must make them to gaussian distribution","06c3aa4e":"This feature tells whether garage is present or not","490211b7":"training each model","5e3f85b3":"Filling the Null Values in combined_df","42de5ad2":"# SVM","d84f3174":"Checking whether missing values in feature contribute to predict the target","02fb0002":"#### Finding the age of the house and other properties\nCreating new features that tell us the no.of years between house built and sold.","ada21929":"['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'Condition1', 'Exterior1st', 'MasVnrType', 'ExterQual', 'ExterCond',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType2', 'Heating',\n       'HeatingQC', 'CentralAir', 'KitchenQual', 'GarageType', 'GarageFinish',\n       'GarageQual', 'GarageCond', 'PavedDrive']","27b6f963":"From the above analysis we drop\n- 'BsmtFullBath','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','MoSold'","aa059f3d":"Let us first find the missing values in both train and test datasets","93c3cbb5":"Calculating and visualizing the median of housePrice for each categories of a categorical Feature","df3a81aa":"# Combining Models in a specific ratio (Trial and Error)","3575dac3":"Considering the special categories <br>\nThese features have 90% same category but the remaining 10% is spread out in different categories<br>\nConverting them into categorical","8ae8235b":"## RandomForestRegressor","5bc66d19":"_____","32156a69":"We could clearly see the price of houses with garages is higher than those without\n","39f6af73":"#### Working with garages creating new feature","343ca783":"## KNeighborsRegressor","42e2e1ad":"On visualizing, we found These Features Contribute to the target<br>\n","d2a4a02a":"For This Notebook I have taken the\n  - train_df - Training dataset\n  - test_df - test dataset\n  - combined_df - train and test dataset merged (done for making changes to both train and test datasets at the same time.)<br>\n","9f1100b0":"Getting the shape of training and test data","51fe36a2":"For Cross Validation","6a689e25":"Using models - ridge, lasso, elasticnet, svr, grb, lgbm, xgboost","bd0839f0":"<i >This notebook was made by <br>Gopinath K S<br><br>\nLinkedin - https:\/\/www.linkedin.com\/in\/gopinath-k-s-98a48a1b3\/ <br>\nGithub - https:\/\/github.com\/Gopinath-123   <br>\nKaggle - https:\/\/www.kaggle.com\/gopinath15\n\n\n<\/i>\n","f24e7c68":"Here we have \"Alley\", \"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\" features with more than half of the data missing so we can skip these features","b2571e7a":"## Lasso \n","06e3dfe0":"#### Seperating out the categorical feature and numerical feature\nCat_fea contains categorical feature names<br>\nnum_fea contains numerical feature names","db0921bc":"predicting for each model\n","c68bf799":"So we could Encode them Directly","71bba537":"### Till now we have cleaned the object type features . Now lets get into Numerical Features","3bfce67e":"### Among the models only Linear Regression and Random Forest Regressors performs well","d652c48e":"So lets use them and other complex models","5cfa2322":"## Feature Selection","e14fe1a7":"\n#### let us Explore the Train and test datas seperately","ecea7538":"This Notebook is made as a part for the Kaggle Competition on Advanced Housing Price Prediction.","97018bf1":"# Submission\n","13a968fc":"Droping index as it has no use","dc5f7048":"This code just replaces the several categories in the Feature to minimum no. of Categories","9c09af42":"## One hot encoding of categorical features","f7f57cf5":"## Getting into Continuous numerical value","7a5f97f7":"#### Corelation ","3978c091":"#### we could see 4 features associated with years\nLets create new features with the features associated with years","7dd9589b":"## Stack model of all models","8ed07f6d":"### Final data\n","cc570ac5":"Now we have done with years lets remove it","3aad44ac":"Let us get the discrete and continuous variables","eaf827cd":"Discrete Features are numerical but have distinct values (not continuous)","9fe0bfed":"___\n\n","ee912c12":"Doing the same for combined_df","50fcafcc":"<h1 align='center'> Housing Price Prediction","b78fa81a":"From this we could drop the irrugular features such as 'MiscVal' ,'ScreenPorch','EnclosedPorch','BsmtFinSF2'\nTheir corelation is also almost zero","f2cf53b0":"<p>The Below features are kind of Special features that are encoded manually. Categories in a Feature having similar median for Target-SalePrice are grouped to a single categories ,so that we could reduce the number of categories in a feature.\nThis method was purely based on Trial and Error to Group Categories.\n<\/p>\n\n\n","5bf1ec54":"So we could take these two basic models and other complex models to blend"}}