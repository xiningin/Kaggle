{"cell_type":{"0f3d7825":"code","68b97a87":"code","952c0b20":"code","d1d2cb8b":"code","54c1226c":"code","e28fd4bf":"code","a0fbbed9":"code","2479f80f":"code","a229f2d4":"code","3f769b27":"code","36725528":"code","64c1d8be":"code","69547f66":"code","3ecfb0a1":"code","6c92460f":"code","2db34237":"code","ed2e6908":"code","2dfc0913":"code","ab97da74":"code","181e2c5c":"code","d12bd0b4":"code","df52a43f":"code","69493daa":"code","c044fcd9":"code","bb896260":"code","b1709dc7":"code","778e15c9":"code","79ce702b":"code","28fc4b72":"code","0dff7e16":"code","ceb8ec3e":"code","1a0b9a6d":"code","43b6ec99":"code","6989030c":"code","a87cee10":"code","511a7145":"code","85c301e7":"code","6884e027":"code","9eeb45e6":"code","19266393":"code","5877cd66":"code","fda8db99":"code","a6e6a4cb":"code","5df458de":"code","586a0776":"code","d213250a":"markdown","8f25af0c":"markdown","9d5b329e":"markdown","4e06d79e":"markdown","e0dabe79":"markdown","de221633":"markdown","301fc332":"markdown","032fbd51":"markdown","6bea8079":"markdown","0af428af":"markdown","ac30809b":"markdown","a36f7115":"markdown","2b17d4de":"markdown","3ac84f55":"markdown","19ec2785":"markdown","79cd11f6":"markdown","d2200916":"markdown","a532211c":"markdown","727d3fdf":"markdown","f70c72f1":"markdown","7a3181fa":"markdown","9dd4b790":"markdown","f838a353":"markdown","d5e247e2":"markdown","ae8fccc3":"markdown","0acd4934":"markdown","4a5c7dc4":"markdown","f547fbcf":"markdown","f1846212":"markdown","382af8ac":"markdown","4b18687d":"markdown","7716cf49":"markdown","971b8577":"markdown","3aaa71f8":"markdown","208f23bb":"markdown","556c8056":"markdown","951b951f":"markdown","e74b8425":"markdown","dd428491":"markdown","325789c3":"markdown","627fb625":"markdown","d64ff6d5":"markdown","7035ed21":"markdown","71a73070":"markdown","ead18a28":"markdown"},"source":{"0f3d7825":"!pip install dataprep","68b97a87":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn import svm, datasets\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom dataprep.eda import plot\n#create_report","952c0b20":"data = pd.read_csv('\/kaggle\/input\/heart-disease-dataset\/heart.csv')","d1d2cb8b":"data","54c1226c":"plot(data)","e28fd4bf":"y = data['target'].copy()\n#y = np.array(y, dtype='float32')\nx = data.drop('target', axis=1).copy()\nx = np.array(x, dtype='float32')","a0fbbed9":"std_scaler = StandardScaler()","2479f80f":"(trainX, testX, trainY, testY) = train_test_split(x,\n    y, test_size=0.3, random_state=101)\n\ntrainX=std_scaler.fit_transform(trainX)\ntestX=std_scaler.transform(testX)","a229f2d4":"parameters = {'kernel':('linear', 'rbf'), 'C':[1.0, 10.0, 100.0, 1000.0],\n              'gamma':[1,0.1,0.01]}","3f769b27":"model = svm.SVC()\nclf = GridSearchCV(model, parameters, verbose=2)","36725528":"clf.fit(trainX, trainY)","64c1d8be":"svc_best_param = clf.best_params_\nprint(\"Best params for SVM:\", svc_best_param)","69547f66":"predict = clf.predict(testX)\nprint(classification_report(testY,predict))\nprint(confusion_matrix(testY, predict))","3ecfb0a1":"svc_accuracy_score = accuracy_score(testY, predict)\nprint(\"Best accuracy for SVM:\", svc_accuracy_score)","6c92460f":"parameters = {'penalty':['l2'], 'C':[1.0, 10.0, 100.0, 1000.0]}","2db34237":"model = LogisticRegression()\nclf = GridSearchCV(model, parameters, verbose=2)","ed2e6908":"clf.fit(trainX, trainY)","2dfc0913":"logreg_best_param = clf.best_params_\nprint(\"Best params for LR:\", logreg_best_param)","ab97da74":"predict = clf.predict(testX)\nprint(classification_report(testY,predict))\nprint(confusion_matrix(testY, predict))","181e2c5c":"logreg_accuracy_score = accuracy_score(testY, predict)\nprint(\"Best accuracy for LR:\", logreg_accuracy_score)","d12bd0b4":"parameters = {\n    'n_estimators': [100],\n    'max_depth': [4,5,6,7],\n    'subsample': np.arange(0.05, 1.01, 0.05),\n    'n_jobs': [1],\n    'verbosity': [0]\n        }","df52a43f":"model = XGBClassifier()\nclf = GridSearchCV(model, parameters, verbose=2)","69493daa":"clf.fit(trainX, trainY)","c044fcd9":"XGB_best_param = clf.best_params_\nprint(\"Best params for XGB:\", XGB_best_param)","bb896260":"predict = clf.predict(testX)\nprint(classification_report(testY,predict))\nprint(confusion_matrix(testY, predict))","b1709dc7":"XGB_accuracy_score = accuracy_score(testY, predict)\nprint(\"Best accuracy for RFC:\", XGB_accuracy_score)","778e15c9":"parameters = {\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [4,5,6,7],\n    'criterion' :['gini']\n   }","79ce702b":"model = RandomForestClassifier()\nclf = GridSearchCV(model, parameters, verbose=2)","28fc4b72":"clf.fit(trainX, trainY)","0dff7e16":"RFC_best_param = clf.best_params_\nprint(\"Best params for RFC:\", RFC_best_param)","ceb8ec3e":"predict = clf.predict(testX)\nprint(classification_report(testY,predict))\nprint(confusion_matrix(testY, predict))","1a0b9a6d":"RFC_accuracy_score = accuracy_score(testY, predict)\nprint(\"Best accuracy for RFC:\", RFC_accuracy_score)","43b6ec99":"parameters = {\n    'max_depth' : [None,4,5,6,7],\n    'criterion' :['gini', 'entropy']\n   }","6989030c":"model = DecisionTreeClassifier()\nclf = GridSearchCV(model, parameters, verbose=2)","a87cee10":"clf.fit(trainX, trainY)","511a7145":"DTC_best_param = clf.best_params_\nprint(\"Best params for DTC:\", DTC_best_param)","85c301e7":"predict = clf.predict(testX)\nprint(classification_report(testY,predict))\nprint(confusion_matrix(testY, predict))","6884e027":"DTC_accuracy_score = accuracy_score(testY, predict)\nprint(\"Best accuracy for DTC:\", DTC_accuracy_score)","9eeb45e6":"parameters = {\n    'n_neighbors' : [3,5,11,17],\n    'weights' :['uniform', 'distance']\n   }","19266393":"model = KNeighborsClassifier()\nclf = GridSearchCV(model, parameters, verbose=2)","5877cd66":"clf.fit(trainX, trainY)","fda8db99":"KN_best_param = clf.best_params_\nprint(\"Best params for KN:\", KN_best_param)","a6e6a4cb":"predict = clf.predict(testX)\nprint(classification_report(testY,predict))\nprint(confusion_matrix(testY, predict))","5df458de":"KN_accuracy_score = accuracy_score(testY, predict)\nprint(\"Best accuracy for KN:\", KN_accuracy_score)","586a0776":"accuracy_frame = pd.DataFrame({'Model': ['Support Vector Machine',\n                                   'Logistic Regression',\n                                   'eXtreme Gradient Boosting Classifier',\n                                   'Random Forest Classifier',\n                                   'Decision Tree Classifier',\n                                   'K-Nearest Neighbour Classifier'], \n                         'Accuracy': [svc_accuracy_score*100,\n                                      logreg_accuracy_score*100,\n                                      XGB_accuracy_score*100,\n                                      RFC_accuracy_score*100,\n                                      DTC_accuracy_score*100,\n                                      KN_accuracy_score*100]})\naccuracy_frame","d213250a":"There aren't missing data,\nThere are almost the same count of objects labeled as \"have heart disease\" and \"have not heart disease\" and big difference in \"sex\" column and \"fbs\" column","8f25af0c":"Best parameters for Random Forest Classifier","9d5b329e":"Setting parameters","4e06d79e":"Best accuracy for SVM","e0dabe79":"Setting parameters","de221633":"## Best accuracy: 99%","301fc332":"## Random Forest Classifier ML model. Used Grid Seach for finding best parameters, best accuracy","032fbd51":"Best parameters for SVM","6bea8079":"Training the model","0af428af":"Setting model","ac30809b":"Importing libraries","a36f7115":"Setting model","2b17d4de":"Best accuracy for eXtreme Gradient Boosting Classifier","3ac84f55":"Loading the dataframe","19ec2785":"Best accuracy for Decision Tree Classifier","79cd11f6":"Best parameters for K Neighbors Classifier","d2200916":"Best parameters for eXtreme Gradient Boosting Classifier","a532211c":"Setting model","727d3fdf":"Setting model","f70c72f1":"Setting parameters","7a3181fa":"Best parameters for Decision Tree Classifier","9dd4b790":"Best accuracy for Random Forest Classifier","f838a353":"Training the model","d5e247e2":"Setting parameters","ae8fccc3":"## K Neighbors Classifier ML model. Used Grid Seach for finding best parameters, best accuracy","0acd4934":"Setting parameters","4a5c7dc4":"Best accuracy for Logistic Regression","f547fbcf":"Setting model","f1846212":"Training the model","382af8ac":"Training the model","4b18687d":"# Heart Disease Prediction using GridSearchCV(99%)","7716cf49":"## eXtreme Gradient Boosting Classifier ML model. Used Grid Seach for finding best parameters, best accuracy","971b8577":"Let's analyze the data using dataprep.eda tool","3aaa71f8":"Below is the project finding the best accuracy among different models: Support Vector Machine,\nLogistic Regression, eXtreme Gradient Boosting Classifier, Random Forest Classifier,\nDecision Tree Classifier, K-Nearest Neighbour Classifier using GridSeachCV.","208f23bb":"Best parameters for Logistic Regression","556c8056":"Splitting the data into train and test","951b951f":"## Accuracy Data Frame","e74b8425":"## Decision Tree Classifier ML model. Used Grid Seach for finding best parameters, best accuracy","dd428491":"Setting parameters","325789c3":"## Logistic Regression ML model. Using Grid Seach for finding best parameters, best accuracy","627fb625":"Best accuracy for K Neighbors Classifier","d64ff6d5":"Setting model","7035ed21":"Training the model","71a73070":"Training the model","ead18a28":"## Support Vector Machine ML model. Using Grid Seach for finding best parameters, best accuracy"}}