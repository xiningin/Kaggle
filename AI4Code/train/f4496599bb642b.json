{"cell_type":{"99dfe4e3":"code","5a38a12b":"code","0b50203b":"code","0102dc81":"code","03a1010c":"code","88315784":"code","f6d0f5a3":"code","9d830875":"code","83d8355b":"code","7535b88c":"code","6cc746df":"code","063bf615":"code","32042ea3":"code","0b14cc2f":"code","b8b507ff":"code","b28ad363":"code","329de2e3":"code","df36e2a8":"code","56d3c3be":"code","8690d083":"code","4fa2758b":"code","3d5066e1":"code","8015d2a6":"code","13b8dedf":"code","d2caba74":"code","ea080532":"code","b2793edb":"code","f56f6236":"code","bff5851d":"code","23bb7690":"code","4b6ac981":"code","252e33f7":"code","b1309d93":"code","b06cadda":"code","60c21bd9":"code","41ecb846":"code","bba4c7bb":"code","976cc708":"code","6203da5a":"markdown","7528abbc":"markdown","4e71c383":"markdown","50f02c76":"markdown","cc8d59ff":"markdown","4c70cfcf":"markdown","62e3eea1":"markdown","20714146":"markdown","1a98b8d8":"markdown","d2f40606":"markdown","407347a4":"markdown"},"source":{"99dfe4e3":"import re, string, collections, pickle, os  #any object in Python can be pickled so that it can be saved on disk, Pickling is a way to convert a python object (list, dict, etc.) into a character stream\n%matplotlib inline\nimport matplotlib.pyplot as plt\n#import mpld3\n#mpld3.enabled_notebook()\nimport pandas as pd\nimport numpy as np\nimport itertools #module is a collection of tools for handling iterators\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\n#from sklearn.naive_bayes import MultinomialNB\nfrom sklearn import datasets, linear_model\nfrom sklearn.decomposition import TruncatedSVD, PCA #performs linear dimensionality reduction by means of truncated singular value decomposition (SVD).Contrary to PCA,this estimator does not center the data before computing the singular value decomposition. This means it can work with scipy.sparse matrices efficiently.Principal Component Analysis (PCA) is used to explain the variance-covariance structure of a set of variables through linear combinations. It is often used as a dimensionality-reduction technique.\nfrom sklearn.metrics import confusion_matrix","5a38a12b":"df = pd.read_csv(\"..\/input\/clean.csv\",sep=\"|\")\ndf.head()","0b50203b":"# How many columns and rows\ndf.shape","0102dc81":"# How many pos and neg sentence\/comments in the clean.csv file\npos = df.loc[df[\"sentiment\"]==1].copy().reset_index(drop=True)\nneg = df.loc[df[\"sentiment\"]==0].copy().reset_index(drop=True)\n#neg.head()\n#pos.head()\nprint(len(pos))\nprint(len(neg))","03a1010c":"def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.figure(figsize=(8, 8))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","88315784":"x_train,x_test,y_train,y_test = train_test_split(df[\"comment\"].values,df[\"sentiment\"].values,test_size=0.2)\ndef tokenise(s):\n    return s.split(\" \")\nvect = CountVectorizer(tokenizer = tokenise)\ntf_train = vect.fit_transform(x_train)\ntf_test = vect.transform(x_test)","f6d0f5a3":"model = LogisticRegression(C=0.2, dual=True)\n#model = MultinomialNB()\nmodel.fit(tf_train, y_train)\npreds = model.predict(tf_test)\nacc = (preds==y_test).mean()\nprint(f'Accuracy: {acc}')\nplot_confusion_matrix(confusion_matrix(y_test, preds.T), classes=['Negative', 'Positive'], title='Confusion matrix')\nplt.show()","9d830875":"# Length of train data\nlen(pos), len(neg)","83d8355b":"df = pd.read_csv(\"..\/input\/data3.csv\")\ndf.head()","7535b88c":"#col = df[\"reviews.text\"]\n#col.head()\n\nimport re\nf = open(\"..\/input\/data3.csv\", encoding=\"utf8\")\ntext = f.read()\nf.close()\ntext = re.sub(r\",+\\n\",\"\\n\",text)\ntext = re.sub(r\",0\\n\",\"|0\\n\",text)\ntext = re.sub(r\",1\\n\",\"|1\\n\",text)\ntext = re.sub(r\"[.,\\\/#!$%\\^&\\*;:{}=\\-_'~()\\\"]\",\"\",text)\n#print(text)\nf = open(\"clean1.csv\",\"w\", encoding=\"utf8\")\nf.write(text)\nf.close()","6cc746df":"import csv\ndf = pd.read_csv(\"..\/input\/clean1.csv\", quoting=csv.QUOTE_NONE)\nprint(df.shape)","063bf615":"data = (df[\"reviewstext\"].values)\ntf_data = vect.transform(data)","32042ea3":"preds = model.predict(tf_data)\npreds[preds==0] = -1\npreds","0b14cc2f":"main_data = pd.read_csv(\"..\/input\/data2.csv\")\nmain_data[\"reviews.text\"][9705]\nmain_data = main_data.drop([3211,9705],axis=0)","b8b507ff":"main_data[\"sentiments\"] = preds\nmain_data.head()","b28ad363":"post = main_data.loc[main_data[\"sentiments\"]==1].copy().reset_index(drop=True)\nnegt = main_data.loc[main_data[\"sentiments\"]==-1].copy().reset_index(drop=True)\n#negt\n#post\nprint(len(post))\nprint(len(negt))","329de2e3":"# Both negative and positive sentiments\nrequired_data = main_data[[\"name\",\"sentiments\"]]\nrequired_data.head()","df36e2a8":"# Positive Sentiments\npost[[\"reviews.text\",\"sentiments\"]].head()","56d3c3be":"# Negative Sentiments \nnegt[[\"reviews.text\",\"sentiments\"]].head()","8690d083":"# grouping the data as groupbyname\ngroups = required_data.groupby(\"name\")\nfinal = pd.DataFrame()\nfor name,group in groups:\n    row = {}\n    row[\"name\"] =  name\n    row[\"sentiment\"] =  group[\"sentiments\"].sum()\n    final = final.append(row,ignore_index=True)\nfinal.to_csv(\"..\/input\/sentiments_final.csv\")\nfinal.head()","4fa2758b":"import matplotlib.pyplot as plt, seaborn as sns\nfrom matplotlib import pyplot as plt\n#plt.figure(figsize=(10,6))\n\nplt.rc('xtick', labelsize=14)\nplt.rc('ytick', labelsize=14)\nsns.set_style(style='whitegrid')","3d5066e1":"from matplotlib import pyplot as plt\nimport matplotlib\nmatplotlib.style.use('ggplot')\nplt.figure(figsize=(14,6))\nsample = final.loc[0:48]\nsample.plot.bar(x=\"name\",y=\"sentiment\", figsize=(24, 9))\nplt.ylabel(\"Number of Sentiments\")\nplt.title('Amazon Products')\nplt.legend()\n#plt.plot(x)\nplt.show()","8015d2a6":"import matplotlib\nmatplotlib.style.use('ggplot')\nfig = plt.figure(figsize = (15,6))\nsample = final.loc[0:5]\nsample.plot.bar(x=\"name\",y=\"sentiment\", figsize=(10, 6))\nplt.ylabel(\"Number of Sentiments\")\nplt.title('Amazon Products')\nplt.legend()\nplt.show()","13b8dedf":"import matplotlib\nmatplotlib.style.use('ggplot')\nfig = plt.figure(figsize = (15,6))\nsample = final.loc[6:12]\nsample.plot.bar(x=\"name\",y=\"sentiment\", figsize=(10, 6))\nplt.ylabel(\"Number of Sentiments\")\nplt.title('Amazon Products')\nplt.legend()\nplt.show()","d2caba74":"import matplotlib\nmatplotlib.style.use('ggplot')\nfig = plt.figure(figsize = (15,6))\nsample = final.loc[13:18]\nsample.plot.bar(x=\"name\",y=\"sentiment\", figsize=(10, 6))\nplt.ylabel(\"Number of Sentiments\")\nplt.xlabel(\"Name of Amazon Products\")\nplt.title('Amazon Products')\nplt.legend()\nplt.show()","ea080532":"import matplotlib\nmatplotlib.style.use('ggplot')\nfig = plt.figure(figsize = (15,6))\nsample = final.loc[19:25]\nsample.plot.bar(x=\"name\",y=\"sentiment\", figsize=(10, 6))\nplt.ylabel(\"Number of Sentiments\")\nplt.xlabel(\"Name of Amazon Produts\")\nplt.title('Amazon Products')\nplt.legend()\nplt.show()","b2793edb":"import matplotlib\nmatplotlib.style.use('ggplot')\nfig = plt.figure(figsize = (15,6))\nsample = final.loc[0:25]\nsample.plot.bar(x=\"name\",y=\"sentiment\", figsize=(20, 6))\nplt.ylabel(\"Number of Sentiments\")\nplt.xlabel(\"Name of Amazon Produts\")\nplt.title('Amazon Products')\nplt.legend()\nplt.show()","f56f6236":"sent = pd.read_csv(\"..\/input\/sentiments_final.csv\")\nsent.head()","bff5851d":"df = pd.read_csv(\"..\/input\/data2.csv\")\ndf.head()","23bb7690":"#ploting graph on the basis of review ratings\ndf[\"reviews.rating\"].value_counts().sort_values().plot.bar()\nplt.show()","4b6ac981":"vocab = vect.get_feature_names()\nlen(vocab)","252e33f7":"coef_df = pd.DataFrame({'vocab': vocab, 'coef':model.coef_.reshape(-1)})\npos_top10 = coef_df.sort_values('coef', ascending=False).reset_index(drop=True)[:10]\nneg_top10 = coef_df.sort_values('coef').reset_index(drop=True)[:10]","b1309d93":"fig, axs = plt.subplots(1, 2, figsize=(18, 10))\nfig.subplots_adjust(wspace=0.8)\npos_top10.sort_values('coef').plot.barh(legend=False, ax=axs[0])\naxs[0].set_yticklabels(pos_top10['vocab'].values.tolist()[::-1])\naxs[0].set_title('Positive Words');\nneg_top10.sort_values('coef', ascending=False).plot.barh(legend=False, ax=axs[1])\naxs[1].set_yticklabels(neg_top10['vocab'].values.tolist()[::-1])\naxs[1].set_title('Negative Words');","b06cadda":"#Filtering not null values\nperm = df[['reviews.rating' , 'reviews.text' , 'reviews.title' , 'reviews.username']]\nsenti= perm[perm[\"reviews.rating\"].notnull()]\nsenti.head()","60c21bd9":"#Classifying text as postive and negative\u00b6\nsenti[\"senti\"] = senti[\"reviews.rating\"]>=4\nsenti[\"senti\"] = senti[\"senti\"].replace([True , False] , [\"pos\" , \"neg\"])","41ecb846":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib as mpl\nstopwords = set(STOPWORDS)\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='lavender',\n        stopwords=stopwords,\n        max_words=300,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n        \n    ).generate(str(data))\n    \n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n    \nshow_wordcloud(senti[\"reviews.text\"])","bba4c7bb":"show_wordcloud(senti[\"reviews.text\"][senti.senti == \"pos\"] , title=\"Positive Words\")","976cc708":"show_wordcloud(senti[\"reviews.text\"][senti.senti == \"neg\"] , title=\"Negative words\")","6203da5a":"                                              WORDS CLOUD","7528abbc":"                                      Confusion Matrix","4e71c383":"Plot a graph as different numbers of Amazon products from 13 to 18","50f02c76":"Plot a graph as different numbers of Amazon products from 0 to 25","cc8d59ff":"Plot a graph as different numbers of Amazon products from 19 to 25","4c70cfcf":"Plot a graph as different numbers of Amazon products from 0 to 30","62e3eea1":"Plot a graph of Number of Amazon products & its Sentiments","20714146":"Above reviews shows maximum reviews are positive","1a98b8d8":"Plot a graph as different numbers of Amazon products from 6 to 12","d2f40606":"Plot a graph as different numbers of Amazon products from 1 to 5","407347a4":"Confusion matrix describe the performance of a classification model (or \"classifier\") on a set of train data for which the true values are known"}}