{"cell_type":{"5c3a6279":"code","b020d273":"code","ef05f650":"code","b328c2f3":"code","161e3b98":"code","ad133787":"code","bb80ce7a":"code","4716da2c":"code","700b293b":"code","27d0ecf0":"code","f5d4b199":"code","aeb5e6a9":"code","88be4c5e":"code","44af0b4b":"code","f7b6daeb":"code","569a7221":"code","c9475bf9":"code","75a27b53":"code","08e1e1a9":"markdown"},"source":{"5c3a6279":"import pandas as pd\nimport numpy as np\nimport pickle\nfrom tqdm import tqdm\nfrom gensim.models import Doc2Vec\nfrom sklearn import utils\nfrom sklearn.model_selection import train_test_split\nimport gensim\nfrom sklearn.linear_model import LogisticRegression\nfrom gensim.models.doc2vec import TaggedDocument\nimport re, nltk\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom gensim.models import Doc2Vec\nfrom yellowbrick.cluster import KElbowVisualizer\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n%matplotlib inline","b020d273":"df = pd.read_csv('\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')\ndf = df.drop('sentiment', axis=1)\ndf.head(5)","ef05f650":"df.info()","b328c2f3":"# Removing html tags from documents\ndef cleanText(text):\n    text = BeautifulSoup(text, \"lxml\").text\n    text = re.sub(r'\\|\\|\\|', r' ', text) \n    text = re.sub(r'http\\S+', r'<URL>', text)\n    return text\n\ndf['review'] = df['review'].apply(cleanText)","161e3b98":"# Converting text to lowercase\ndf['review'] = df['review'].apply(lambda x: x.lower()) ","ad133787":"# Removing stopwords\nenglish_stopwords = stopwords.words(\"english\")\ndf['review'] = df['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in english_stopwords))","bb80ce7a":"# Removing non english words and words with length less than 3\nwords = set(nltk.corpus.words.words())\ndf['review'] = df['review'].apply(lambda x: \" \".join(i for i in nltk.wordpunct_tokenize(x) if i in words and len(i) > 2))","4716da2c":"# Transforming words to its root form\nlm = WordNetLemmatizer() \ndf['review'] = df['review'].apply(lambda x: ' '.join(lm.lemmatize(i) for i in x.split()))","700b293b":"# Replacing everyting else than words and whitespaces with a space.\ndf['review'] = df['review'].str.replace('[^\\w\\s]',' ')","27d0ecf0":"# Preparing data fro doc2vec training\nLabeledSentence = gensim.models.doc2vec.TaggedDocument\nall_content_train = []\nj=0\nfor em in df['review'].values:\n    all_content_train.append(LabeledSentence(em,[j]))\n    j+=1\nprint('Number of texts processed: ', j)","f5d4b199":"# Training doc2vec model\nd2v_model = Doc2Vec(all_content_train, vector_size = 100, window = 10, min_count = 500, workers=7, dm = 1,alpha=0.025, min_alpha=0.001)\nd2v_model.train(all_content_train, total_examples=d2v_model.corpus_count, epochs=10, start_alpha=0.002, end_alpha=-0.016)","aeb5e6a9":"# Determining the number of clusters\nwcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=10,random_state=0)\n    kmeans.fit(d2v_model.docvecs.vectors_docs)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","88be4c5e":"# Training KMeans model \nkmeans_model = KMeans(n_clusters=3, init='k-means++', max_iter=100, n_init=10,random_state=0) \nX = kmeans_model.fit(d2v_model.docvecs.vectors_docs)","44af0b4b":"# Plotting the clusters\nlabels = kmeans_model.labels_.tolist()\nl = kmeans_model.fit_predict(d2v_model.docvecs.vectors_docs)\npca = PCA(n_components=2).fit(d2v_model.docvecs.vectors_docs)\ndatapoint = pca.transform(d2v_model.docvecs.vectors_docs)\n\nplt.figure\nlabel1 = ['#FFFF00', '#008000', '#0000FF', '#800080']\ncolor = [label1[i] for i in labels]\nplt.scatter(datapoint[:, 0], datapoint[:, 1], c=color)\ncentroids = kmeans_model.cluster_centers_\ncentroidpoint = pca.transform(centroids)\nplt.scatter(centroidpoint[:, 0], centroidpoint[:, 1], marker='^', s=150, c='#000000')\nplt.show()","f7b6daeb":"# Saving the model and loading\npickle.dump(kmeans_model, open('model_v1', 'wb'))\nloaded_model = pickle.load(open('model_v1', 'rb'))","569a7221":"df['label'] = loaded_model.labels_","c9475bf9":"# plotting the distribution\ndf['label'].value_counts().plot(kind='bar', figsize=(15,8))","75a27b53":"# Plotting one cluster\nlabel = df[df['label'] == 0]\nprint(label.shape)\ntext = ''\nfor i in label.index:\n    text += ' ' + label['review'][i]\n\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n\n# Display the generated image:\nplt.figure(figsize = (15,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","08e1e1a9":"I have taken only the `review` column from the dataset as I am trying to build a clustering model based on the reviews."}}