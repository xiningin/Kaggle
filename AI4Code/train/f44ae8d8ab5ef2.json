{"cell_type":{"e8076d52":"code","10d06fcf":"code","22de463e":"code","49645584":"code","d1e691d9":"code","9de8ba9a":"code","f96f4bac":"code","873a641f":"code","0319d9b6":"code","14f6e41e":"code","a8c1e704":"code","ce064ce4":"code","b999e8bf":"code","3203f0f6":"code","7f2345da":"code","d2aea102":"code","a19b0b02":"code","df8b1f59":"code","4548189a":"code","b9333c8b":"code","7504f4ab":"code","7c0ae896":"code","37394175":"markdown","c69983d1":"markdown","e828c188":"markdown","e6bb05ef":"markdown","253d847b":"markdown","de5049cf":"markdown","6e7857a1":"markdown","780b5c40":"markdown","ad06c792":"markdown","c0e9e809":"markdown","951cd25d":"markdown","dd242844":"markdown","a5acc7b4":"markdown","13b416c9":"markdown","01a8e276":"markdown","b2071040":"markdown","f783f8a6":"markdown","0908f5be":"markdown","37ba62ff":"markdown","0650fc4e":"markdown","513badc1":"markdown","72e4e7f4":"markdown","921b024c":"markdown","37408fa5":"markdown","e4836d45":"markdown","e116e3bf":"markdown","33b78af2":"markdown","069daaf1":"markdown"},"source":{"e8076d52":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","10d06fcf":"#Import Packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as mlib\nprint('Setup complete')","22de463e":"#import data\npath_train = '..\/input\/30-days-of-ml\/train.csv'\npath_test = '..\/input\/30-days-of-ml\/test.csv'\npath_submission = '..\/input\/30-days-of-ml\/sample_submission.csv'\ntrain_data = pd.read_csv(path_train)\ntest_data = pd.read_csv(path_test)\nsubmission = pd.read_csv(path_submission)\nprint('Import has been completed!')","49645584":"#check for nulls\n# kod n\u0259tic\u0259l\u0259rinin daha y\u0131\u011fcam g\u00f6r\u00fcnm\u0259si \u00fc\u00e7\u00fcn \".tolist()\"-d\u0259n istifad\u0259 olunub.\n# daha ayd\u0131n n\u0259tic\u0259 \u00fc\u00e7\u00fcn \".tolist()\"-i sil\u0259 bil\u0259rsiniz.\nprint(train_data.isna().sum().tolist())\nprint('=================================================')\nprint(test_data.isna().sum().tolist())\n# n\u0259tic\u0259d\u0259n d\u0259 g\u00f6r\u00fcnd\u00fcy\u00fc kimi datada \"null\" d\u0259y\u0259r yoxdur.","d1e691d9":"# train data info\ntrain_data.info()\n#print('==================================================================')\n#test data info\n#print(test_data.info())","9de8ba9a":"#train data describe\ntrain_data.describe()","f96f4bac":"# test data describe\n\ntest_data.describe()","873a641f":"# train data review\n\ntrain_data.head(3)","0319d9b6":"# test data review\n\ntest_data.head(3)","14f6e41e":"# columns review\n\nprint(train_data.columns.tolist())\nprint('========================================================================================================================')\nprint(test_data.columns.tolist())\n\n# column types\nprint(train_data.dtypes.tolist())\nprint('========================================================================================================================')\nprint(test_data.dtypes.tolist())\n# dtype('0') --> \"object type\" dem\u0259kdir.","a8c1e704":"#choose numeric variables\nnumeric_train = train_data[[column for column in train_data.columns.tolist()\n                      if train_data[column].dtypes == 'float64' and column != 'target']]\n\nnumeric_test = test_data[[column for column in test_data.columns.tolist()\n                      if test_data[column].dtypes == 'float64']]","ce064ce4":"#choose x and y for train data\nx_train = numeric_train\ny_train = train_data['target']\nprint(x_train.head(2))\nprint(y_train.head(2))\n\n#choose x for test data\nx_test = numeric_test\nprint(x_test.head(2))","b999e8bf":"#split train data\nfrom sklearn.model_selection import train_test_split as tts\nx_tr_train, x_tr_test, y_tr_train, y_tr_test = tts(x_train, y_train, test_size = 0.2, random_state = 33)\n","3203f0f6":"#import Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor","7f2345da":"# defining model\nregress = RandomForestRegressor(n_estimators = 10, max_depth = 5, random_state = 33)","d2aea102":"#fit\nregress.fit(x_tr_train, y_tr_train)","a19b0b02":"#predict\ny_tr_predict = regress.predict(x_tr_test)","df8b1f59":"y_tr_predict","4548189a":"#import package\nfrom sklearn.metrics import mean_squared_error\n\n#evaluate\n\nmean_squared_error(y_tr_predict, y_tr_test)","b9333c8b":"#prediction with regress model\ny_predict = regress.predict(x_test)","7504f4ab":"# add id column\nprediction = pd.concat([test_data['id'], pd.DataFrame(y_predict)], axis=1)\n# rename columns\nprediction.columns = ['id', 'target']\n# save as \".csv\"\nprediction.to_csv('ml_30_1st_try.csv', index = False)\n# print shape (optional)\nprediction.shape","7c0ae896":"print(\"U\u011furlar!\")\nprint('Good luck!')","37394175":"Once we have the data, we separate the categorical and numeric columns for use in the model.\n\nFor now, we'll just use numerical variables to make our job easier.\n\nTo do this, write the following code. The code may seem longer, and more effective methods are available. However, the following form is a way in which we can write basic coding knowledge.\n\n> numeric_train \n\nwe will assign the result to this variable;\n\n> if train_data[column].dtypes == 'float64'\n\nthis section checks whether the column is a **numeric variable** or not;\n\n> and column != 'target'\n\nIn this section, we will check the condition that the number **does not have** the dependent variable we are looking for. Because we are currently looking for \"X\"s (independent variables). **\"Target\"** ie **\"target variable\"** is the variable that the model will predict;\n\n>  column for column in train_data.columns.tolist()\n\nthis section provides a check for the condition we wrote **for each of the columns in \"train_data\"**;\n\n> = train_data[[]]\n\nFinally, we get the columns that meet the conditions for \"train_data\".\n\nThe same thing applies to \"test_data\". **However, since there is no \"target\" here, we do not use the second condition.**\n\n","c69983d1":"Finally, we convert the result to \".csv\" format.\n\nIn the model, **\"id\"** is removed because the identification number is not used as a variable.\n\nThe \"id\" variable was automatically removed because we chose only **\"float\"**, **\"numeric_train\"** and **\"numeric_test\"** above. but if we choose **\"int\"**, that is, in addition,\n\n> train_data[column] != \"id\";\n> test_data[column] != \"id\";\n\nwe should add the above-mentioned conditions, as well.\n\nThe **id column must be added to the result before sending the result**. Otherwise, an error will occur when you **submit** the result.\n\n**In the same way, we must make sure that the column names are correct.**","e828c188":"# **Modell\u0259\u015fdirm\u0259 - Modelling**","e6bb05ef":"The **Kaggle** platform itself is rich in various types of data. If you are building a model for a competition, then the competition organizers provide the data. You can also search for data on the Internet.\nTo upload data to **\"notebook\"**, you must specify the correct **\"path\"**.\n\nIf you use a notebook during the competition, you can easily get access to data in two ways.\n\n1. On the right side of the screen, under the heading **\"Data\"**, we can get the address of the file when we move the cursor to any data file in the **\"input\"** folder.\n![image.png](attachment:66910dd6-0838-4458-9508-97e3742fe19e.png)\n\n2. When we click on the file, a new window will open below. There is also a passage for \"path\" at the top of the window.\n\nYou can download the resulting transition by assigning **variable** ***(\"variable\")***.\n\nTo download data in **\".csv\"** format, use the **\"read_csv()\"** function from the **\"pandas\"** library.\n","253d847b":"# **\u018fsas kitabxanalar\u0131n y\u00fckl\u0259nm\u0259si - Importing main libraries**","de5049cf":"# **Data y\u00fckl\u0259nm\u0259si - Import data**","6e7857a1":"# **Qiym\u0259tl\u0259ndirm\u0259 - Evaluation**","780b5c40":"# **\"Test\" data \u00fcz\u0259rind\u0259 proqnozla\u015fd\u0131rma - Prediction for test data**","ad06c792":"The most popular libraries in \"Python\" are **\"pandas\", \"numpy\", \"seaborn\", \"matplot.pyplot\", \"sclearn\"**. **\"pandas\" and \"numpy\"** need to be used for initial analysis and processing of the data. Since these two libraries are suitable for many purposes, we download them first when starting the project. **\"Seaborn\" and \"Matplotlib.pyplot\"** libraries are mostly used for visualization.\n\nYou can rename the library using the **\"as\"** operator, and then call it by that name. For example, when we type **\"pandas as pd\"**, the functions in the \"pandas\" library are called \"pd.\" can call in the form.\n\n**\"Setup complete\"** at the end to indicate that the download is complete. Because after the libraries are loaded, there is no **\"output\" *(result, extract)***. You can do this by typing any text inside the **\"print ()\"** function. In particular, it helps visually during long downloads.\n","c0e9e809":"This time we will not talk much about the data analysis part to keep the topic as short as possible. But before building a model, we need to know some basic nuances in order to process the data correctly:\n    \n1. The absence of empty cells in the data that we call **\"null\"**, or **\"N\/A\"**, if any **\".Remove via fillna()\"**. For example,\n\n> train_data['column1'].fillna(train_data['column1'].mean()) ;\n\n2. Be sure that columns in the data belong to the correct **type**. For example, it is incorrect for a column of numbers to be of type **\"object\"**. the type of data in the columns can be found via **\".dtypes\"** and **.info()**. For example,\n\na)\n> train_data['column1'].dtype;\n\nb)\n> train_data.dtypes();\n\nc)\n> train_data.info();\n\n3. Elimination of **\"outlier\"**, (ie excessively large or small value relative to the total distribution). For example,\n\n> train_data = train_data[train_data.age > 100] ;\n\n4. You can use \".head()\", \".tail()\", \"columns\", \".info()\", \".describe()\" to get initial information about the data. You will see examples of this in the boxes below.\n    ","951cd25d":"Before using the model, we need to know how well it works, that is, how accurately it estimates the \"y\".\n\nIn the next step, we compare the result of the model with the actual values of \"y\". Since our model is a regression model (ie the target variable is a numerical variable), we use **\"mean squared error\"**. For classification models, this value can be **\"F1 score\"** or **\"accuracy\"**.\n\n**\"Mean squared error\" will give us the arithmetic mean of the squares of the difference between the actual and predicted values.**\n\nThe lower the price, the smaller the difference.","dd242844":"The following line is an informative and instructive line for the \"Kaggle\" notebook. The process of downloading data and libraries is carried out here. You can delete this line or start a new line without making any changes.\n\n**Note:** I removed the \"pandas\" and \"numpy\" libraries from the first line and added them to the second one so that all the libraries I downloaded were on the same line. This operation has no effect on the final result of my work.","a5acc7b4":"Then we check the results on **test data**.","13b416c9":"For more posts like this:\n\nhttps:\/\/challengersdeep.wixsite.com\/website\n\nhttps:\/\/www.instagram.com\/deep_education\/","01a8e276":"The concept of modeling can seem a bit complicated and miraculous. However, the coding part of the model is very simple.\nIf you have a basic knowledge of **Python**, you can also build your first model based on the following explanation and template.","b2071040":"We train our model with our **train data**.","f783f8a6":"# **Datan\u0131n b\u00f6l\u00fcnm\u0259si - Split train data**","0908f5be":"First, we download the model from the appropriate library. **\"Random Forest\"** is my first and favorite model, so I decided to use it. But you can apply any model you want.","37ba62ff":"To do this, first download the **\"train_test_split\"** function from \"sklearn.model_selection\".\n\nThe \"train data\" is then divided into two parts. By typing **\"test_size = 0.2\"** here, we indicate that we will use 20% of the data for testing (ie, checking the model result). Because, we can see the accuracy of the model with the original test data only after \"submitting\". We want to be sure of the performance of the model before sending our results.\n\nWe need to write **\"random_state = 33\"** to get the same result every time we \"run\" the code.\n\n**Note: You can give \"random_state\" any value.**\n\nWhen separating the data with the \"train_test_split\" function, keep in mind that the sequence will be **\"X train\", \"X test\", \"y train\", \"y test\"**.\n\nIn Python, we need to divide the data into \"train\" and \"test\" sections by assigning function result to several variables at the same time and providing this particular sequence.\n","0650fc4e":"# **Data Emal\u0131 - Data Preprocessing**","513badc1":"# **\u0130lk Ma\u015f\u0131n \u00d6yr\u0259nm\u0259si modelini nec\u0259 qurmal\u0131?**\n# **How to build your first ML model?**\n\n# *By Sitara Aghayeva*","72e4e7f4":"We have come to the easiest and most difficult part of the job !!!\n\nWe have very little work to do here. We simply define the model and parameters. The model does the rest. That is, we will not do much. But to improve the model, we need to understand how it works. This requires some experience. So far, this is our first model, so we will form it in the simplest way.","921b024c":"# **Veril\u0259nl\u0259rin t\u0259hlili - Data Analysis**","37408fa5":"As you remember, we divided our \"train\" data into two parts and used only part of it in the model. Once the result is satisfactory, sometimes the model is trained again on the whole trainset.\n\n> #fit\n> regress.fit(train_data, test_data)\n\nNevertheless, while doing so, it is better to build a new model with a different name with the same parameters so as not to teach the model twice on the same data.\n\nFor now, I use the model for test data without this step.","e4836d45":"We can get the \".csv\" file we created from the **\"output\"** folder under the **\"Data\"** heading on the right.\n\nIf the file does not appear in the folder, double-check to make sure you have runned the cell, and click the **\"refresh\"** icon next to the **\"kaggle \/ working\"** folder.\n\n![image.png](attachment:31d08b96-b598-4f88-a83c-60f5526f6a9f.png)\n\nYou can then download the result by clicking on the **three dots** that appear when you move the cursor closer to the file name.","e116e3bf":"We then label our numeric variables as \"X\" and the target variable as \"y\".\n\n**Note:** Instead of writing \"numeric_train\" and \"numeric_test\" in the above function, we could name them directly as \"x\" and \"y\". But we can change the list of the \"x\" variables. For this reason, dividing them into different groups (like categorical, numerical, etc.) and keeping them as separate variables makes it easier for us to find them and change the variables included in the \"x\" without writing long codes. Also, the code we write becomes more readable.","33b78af2":"Then we build a model.\n\n\"Random Forest\" is one of the **decision tree** models. Here **\"n_estimators\"** is the number of trees. **\"max_depth\"** is the depth of the branches of trees. In Random Forest, the branches of the tree continue until all data belongs to the same class. But we can determine the maximum number for it. In the following model, the tree will reach to 5 levels at maximum.\n\nAs in the data partition, there is **\"random_state\"**. If you do not specify it, the result of the model will change each time.\n\n**If you take part in the competition, or in a real work environment, the result should coincide, when you run the model again.**","069daaf1":"Congratulations!\n\nYour model and result are ready!\n\nNow you can submit your output and get your place on leaderboard!"}}