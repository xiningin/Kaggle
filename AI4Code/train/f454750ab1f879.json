{"cell_type":{"302245af":"code","aa456ce4":"code","90d89fb7":"code","69b52445":"code","7bfda993":"code","e002490e":"code","874db747":"code","7399369a":"code","f16065e5":"code","5b1e5438":"code","9688b52a":"code","4bc018c3":"code","9cb334a7":"code","3c51b66f":"code","d7b2eb94":"code","52666064":"code","5c4c61a8":"code","2a2d0d7b":"code","f8a90b81":"code","7b22ec7d":"code","04d18594":"code","136eb29c":"code","4a073d76":"code","b855f7cc":"code","67143932":"code","c9e43505":"code","bbe7a384":"code","88c05bf6":"code","6d62e71f":"code","8ad17072":"code","93d95f1d":"markdown","7fb5d112":"markdown","8e182f38":"markdown","65020901":"markdown"},"source":{"302245af":"\nimport numpy as np  \nimport pandas as pd\n\n#  visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\n\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff\n# for providing the path\nimport os\nprint(os.listdir('..\/input\/'))\n","aa456ce4":"#Importing dataset\ndata = pd.read_csv('..\/input\/amazon_alexa.tsv', delimiter = '\\t', quoting = 3)\n\n# getting the shape of the data\ndata.shape\ndata.head()\n","90d89fb7":"# describing the data set\n\ndata.describe()","69b52445":"# checking if there is any null data or not\n\ndata.isnull().any().any()","7bfda993":"# adding a length column for analyzing the length of the reviews\n\ndata['length'] = data['verified_reviews'].apply(len)\n\ndata.groupby('length').describe().sample(10)","e002490e":"#describing data according to ratings\ndata.groupby('rating').describe()","874db747":"##describing data according to ratings\ndata.groupby('feedback').describe()","7399369a":"# PIE PLOT SHOWING DISTRIBUTION OF RATINGS FOR ALEXA\nratings = data['rating'].value_counts()\n\nlabel_rating = ratings.index\nsize_rating = ratings.values\n\ncolors = ['cyan', 'brown', 'yellow', 'pink', 'green']\n\nrating_piechart = go.Pie(labels = label_rating,\n                         values = size_rating,\n                         marker = dict(colors = colors),\n                         name = 'Alexa', hole = 0.3)\n\ndf = [rating_piechart]\n\nlayout = go.Layout(\n           title = 'Distribution of Ratings for Alexa')\n\nfig = go.Figure(data = df,\n                 layout = layout)\n\npy.iplot(fig)","f16065e5":"#BAR PLOT\ncolor = plt.cm.winter(np.linspace(0, 1, 15))\ndata['variation'].value_counts().plot.bar(color = color, figsize = (15, 9))\nplt.title('Distribution of Variations in Alexa', fontsize = 20)\nplt.xlabel('variations')\nplt.ylabel('count')\nplt.show()","5b1e5438":"#pie plot based on feedback\nfeedbacks = data['feedback'].value_counts()\n\nlabel_feedback = feedbacks.index\nsize_feedback = feedbacks.values\n\ncolors = ['lightblue','red']\n\nfeedback_piechart = go.Pie(labels = label_feedback,\n                         values = size_feedback,\n                         marker = dict(colors = colors),\n                         name = 'Alexa', hole = 0.3)\n\ndf2 = [feedback_piechart]\n\nlayout = go.Layout(\n           title = 'Distribution of Feedbacks for Alexa')\n\nfig = go.Figure(data = df2,\n                 layout = layout)\n\npy.iplot(fig)","9688b52a":"#BAR PLOT FOR DISTRIBUTION OF LENGTH IN REVIEWS\n\ndata['length'].value_counts().plot.hist(color = 'yellow', figsize = (15, 5), bins = 50)\nplt.title('Distribution of Length in Reviews')\nplt.xlabel('lengths')\nplt.ylabel('count')\nplt.show()","4bc018c3":"plt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('fivethirtyeight')\n\nsns.boxenplot(data['variation'], data['rating'], palette = 'copper')\nplt.title(\"Variation vs Ratings\")\nplt.xticks(rotation = 90)\nplt.show()","9cb334a7":"#STRIP PLOT FOR VARIATION VS LENGTH OF RATING \nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('fivethirtyeight')\n\nsns.swarmplot(data['variation'], data['length'], palette = 'summer')\nplt.title(\"Variation vs Length of Ratings\")\nplt.xticks(rotation = 90)\nplt.show()","3c51b66f":"import warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams['figure.figsize'] = (12, 7)\nplt.style.use('fivethirtyeight')\n\nsns.violinplot(data['feedback'], data['rating'], palette = 'deep')\nplt.title(\"feedback wise Mean Ratings\")\nplt.show()","d7b2eb94":"#MOST FREQUENTLY OCCURRENCE WORD\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n\ncv = CountVectorizer(stop_words = 'english')\nwords = cv.fit_transform(data.verified_reviews)\nsum_words = words.sum(axis=0)\n\n\nwords_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\nfrequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n\nplt.style.use('fivethirtyeight')\ncolor = plt.cm.spring(np.linspace(0, 1, 20))\nfrequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(15, 6), color = color)\nplt.title(\"Most Frequently Occuring Words - Top 20\")\nplt.show()","52666064":"from wordcloud import WordCloud\n\nwordcloud = WordCloud(background_color = 'lightcyan', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\n\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 10))\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.title(\"Vocabulary from Reviews\", fontsize = 20)\nplt.show()","5c4c61a8":"import warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams['figure.figsize'] = (12, 7)\nplt.style.use('fivethirtyeight')\n\nsns.stripplot(data['feedback'], data['length'], palette = 'deep')\nplt.title(\"Feedback vs Length\")\nplt.show()","2a2d0d7b":"#RATING VS LENGTH VS VARIANCE\ntrace = go.Scatter3d(\n    x = data['length'],\n    y = data['rating'],\n    z = data['variation'],\n    name = 'Amazon Alexa',\n    mode='markers',\n    marker=dict(\n        size=10,\n        color = data['rating'],\n        colorscale = 'Viridis',\n    )\n)\ndf = [trace]\n\nlayout = go.Layout(\n    title = 'Length vs Variation vs Ratings',\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0  \n    )\n    \n)\nfig = go.Figure(data = df, layout = \n                layout)\niplot(fig)","f8a90b81":"import spacy\nnlp = spacy.load('en')\n\ndef explain_text_entities(text):\n    doc = nlp(text)\n    for ent in doc.ents:\n        print(f'Entity: {ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}')\n        \nfor i in range(15, 50):\n    one_sentence = data['verified_reviews'][i]\n    doc = nlp(one_sentence)\n    spacy.displacy.render(doc, style='ent',jupyter=True)","7b22ec7d":"# cleaning the texts\n# importing the libraries for Natural Language Processing\n\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","04d18594":"corpus = []\n\nfor i in range(0, 3150):\n    review = re.sub('[^a-zA-Z]', ' ', data['verified_reviews'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","136eb29c":"# creating bag of words\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ncv = CountVectorizer(max_features = 2500)\n\nx = cv.fit_transform(corpus).toarray()\ny = data.iloc[:, 4].values\n\nprint(x.shape)\nprint(y.shape)","4a073d76":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 15)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","b855f7cc":"from sklearn.preprocessing import MinMaxScaler\n\nmm = MinMaxScaler()\n\nx_train = mm.fit_transform(x_train)\nx_test = mm.transform(x_test)","67143932":"#RANDOM FOREST \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\n\nmodel = RandomForestClassifier()\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nprint(\"Training Accuracy :\", model.score(x_train, y_train))\nprint(\"Testing Accuracy :\", model.score(x_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","c9e43505":"# applying k fold cross validation\n\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 10)\n\nprint(\"Accuracy :\", accuracies.mean())\nprint(\"Standard Variance :\", accuracies.std())","bbe7a384":"params = {\n    'bootstrap': [True],\n    'max_depth': [80, 100],\n    'min_samples_split': [8, 12],\n    'n_estimators': [100, 300]\n}","88c05bf6":"# applying grid search with stratified folds\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\ncv_object = StratifiedKFold(n_splits = 2)\n\ngrid = GridSearchCV(estimator = model, param_grid = params, cv = cv_object, verbose = 0, return_train_score = True)\ngrid.fit(x_train, y_train.ravel())","6d62e71f":"print(\"Best Parameter Combination : {}\".format(grid.best_params_))","8ad17072":"print(\"Mean Cross Validation Accuracy - Train Set : {}\".format(grid.cv_results_['mean_train_score'].mean()*100))\nprint(\"Mean Cross Validation Accuracy - Validation Set : {}\".format(grid.cv_results_['mean_test_score'].mean()*100))\n\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy Score for Test Set :\", accuracy_score(y_test, y_pred))","93d95f1d":"This kernel notebook provides the insight of customer reviews on Alexa,  data visualisation and sentimental analysis using NLP techniques.\n\n\nAbout the Data\n\nThis dataset consists of a nearly 3000 Amazon customer reviews (input text), star ratings, date of review, variant and feedback of various amazon Alexa products like Alexa Echo, Echo dots, Alexa Firesticks etc. for learning how to train Machine for sentiment analysis.\n\n","7fb5d112":"DATA VISUALIZATION","8e182f38":"Here we start with loading the packages required for review anlysis","65020901":"Thank you for reading my kernel. please upvote if you like it."}}