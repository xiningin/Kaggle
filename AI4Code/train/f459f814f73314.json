{"cell_type":{"92b44293":"code","2825b1f5":"code","ada41c2f":"code","5d3d8b3c":"code","5e0ad08d":"code","5ddab1a4":"code","8168ab2a":"code","0e8c1113":"code","1b3dff73":"code","ff91f221":"code","b3c1db30":"code","106c3620":"code","991cfbeb":"code","095bde4e":"code","f8bd96f9":"code","04728447":"code","e3164380":"code","e2df42b2":"code","306ab8bf":"code","1b46fd75":"code","2a0b3fa8":"code","58b35842":"code","688d5d70":"code","bce416f3":"code","3fd334a9":"code","23f4c670":"code","dd8b6206":"code","4f413ec7":"code","f5949d31":"code","9d7c716e":"code","f31d9763":"code","f91b7c2e":"code","e770f92c":"code","b8792377":"code","8eb4a30f":"code","6303396b":"code","1ba8bd3b":"code","1002cf0f":"code","3cad7e41":"code","3272f168":"code","2a30c4ea":"code","2a4f3621":"code","ee97c090":"code","c566fec0":"code","2f85683f":"code","0ad1c1ef":"code","3165cf35":"code","beae6860":"code","0df4e240":"code","891ba8be":"markdown","44dffd46":"markdown","f70b76fc":"markdown","733fdda6":"markdown","bbfe8c35":"markdown","9c9d9567":"markdown"},"source":{"92b44293":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n\n# Any results you write to the current directory are saved as output.","2825b1f5":"data = pd.read_csv('..\/input\/kc_house_data.csv')","ada41c2f":"data.head()","5d3d8b3c":"data.describe()","5e0ad08d":"data.info()","5ddab1a4":"data.head()","8168ab2a":"data.isnull().values.any()","0e8c1113":"import datetime\ndef get_year(date):\n    date = str(date)\n    year = date[0:4]\n    month = date[4:6]\n    day = date[6:8]\n    date = year+'-'+month+'-'+day\n    date = datetime.datetime.strptime(date, '%Y-%m-%d')    \n    return date","1b3dff73":"data['date'] = data['date'].apply(get_year)","ff91f221":"data.head()","b3c1db30":"data['is_basement'] = data['sqft_basement'].apply(lambda x: 1 if x != 0 else 0)","106c3620":"#updating living room area and lot area based on the new values of 2015\ndata = data.drop(['sqft_living','sqft_lot','sqft_basement','sqft_above'],axis=1)","991cfbeb":"data.head()","095bde4e":"def update_yr_built(cols):\n    yr_built = cols[0]\n    yr_renovated = cols[1]\n    if yr_renovated != 0:\n        yr_built = yr_renovated\n        \n    return yr_built\ndata['yr_built'] = data[['yr_built','yr_renovated']].apply(update_yr_built,axis=1)","f8bd96f9":"data.head()","04728447":"data = data.drop('yr_renovated',axis=1)","e3164380":"data.head()","e2df42b2":"data = data.drop(['id','view','lat','long'],axis=1)\ndata.head()","306ab8bf":"sns.pairplot(data.drop(['date','condition','yr_built','zipcode','waterfront','is_basement'],axis=1))","1b46fd75":"data.groupby('waterfront').mean()","2a0b3fa8":"#percentage of households having a waterfront\n(data['waterfront'].sum()\/len(data))*100","58b35842":"data.groupby('is_basement').mean()","688d5d70":"#percentage of households having a basement\n(data['is_basement'].sum()\/len(data))*100","bce416f3":"data.head()","3fd334a9":"plt.figure(figsize=(10,6))\nsns.lineplot(x='date',y='price',data=data,ci=False)","23f4c670":"data = data.drop('date',axis=1)","dd8b6206":"from sklearn.model_selection import train_test_split","4f413ec7":"X = data.drop('price',axis=1)\ny = data['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","f5949d31":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","9d7c716e":"norm_X_train = scaler.fit_transform(X_train)","f31d9763":"norm_X_test = scaler.fit_transform(X_test)","f91b7c2e":"norm_X_train = pd.DataFrame(data=norm_X_train,columns=X_train.columns)","e770f92c":"norm_X_test = pd.DataFrame(data=norm_X_test,columns=X_test.columns)","b8792377":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers","8eb4a30f":"def build_model():\n    model = keras.Sequential([\n        layers.Dense(60, activation=tf.nn.relu, input_shape=[len(norm_X_train.keys())]),\n        layers.Dropout(0.5),\n        layers.Dense(60, activation=tf.nn.relu,kernel_regularizer=regularizers.l2(0.01),\n                activity_regularizer=regularizers.l1(0.01)),\n        layers.Dropout(0.5),\n        layers.Dense(60, activation=tf.nn.relu,kernel_regularizer=regularizers.l2(0.01),\n                activity_regularizer=regularizers.l1(0.01)),\n        layers.Dense(1)\n          ])\n\n    optimizer = tf.keras.optimizers.RMSprop(0.001)\n    \n    model.compile(loss='mean_squared_error',\n                optimizer=optimizer,\n                metrics=['mean_absolute_error', 'mean_squared_error'])\n    return model","6303396b":"model = build_model()","1ba8bd3b":"model.summary()","1002cf0f":"EPOCHS = 1500\n","3cad7e41":"def plot_history(history):\n    hist = pd.DataFrame(history.history)\n    hist['epoch'] = history.epoch\n  \n    plt.figure()\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Abs Error')\n    plt.plot(hist['epoch'], hist['mean_absolute_error'],\n           label='Train Error')\n    plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n           label = 'Val Error')\n    \n    plt.legend()\n  \n    plt.figure()\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Square Error')\n    plt.plot(hist['epoch'], hist['mean_squared_error'],\n           label='Train Error')\n    plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n           label = 'Val Error')\n    \n    plt.legend()\n    plt.show()\n\n#plot_history(history)","3272f168":"#hist = pd.DataFrame(history.history)\n#hist['epoch'] = history.epoch\n#hist.tail()","2a30c4ea":"model = build_model()\n\n# The patience parameter is the amount of epochs to check for improvement\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = model.fit(norm_X_train, y_train, epochs=EPOCHS,batch_size=100,\n                    validation_split = 0.2, verbose=0, callbacks=[early_stop])\n","2a4f3621":"plot_history(history)","ee97c090":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()","c566fec0":"loss, mae, mse = model.evaluate(norm_X_train, y_train, verbose=0)\n\nprint(\"Training set Mean Abs Error: {:5.2f}\".format(mae))","2f85683f":"data['price'].mean()","0ad1c1ef":"test_predictions = model.predict(norm_X_test).flatten()\nplt.figure(figsize=(10,6))\nplt.scatter(y_test, test_predictions)\nplt.xlabel('True prices')\nplt.ylabel('Predicted prices')\nplt.xlim(0,2000000)\nplt.ylim(0,2000000)","3165cf35":"loss, mae, mse = model.evaluate(norm_X_test, y_test, verbose=0)\n\nprint(\"Testing set Mean Abs Error: {:5.2f}\".format(mae))","beae6860":"#using linear regression - \nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nlm.fit(norm_X_train,y_train)\npredictions = lm.predict(norm_X_test)\nplt.figure(figsize=(10,6))\nax = plt.scatter(y_test,predictions)\nplt.xlim(0,2000000)\n","0df4e240":"from sklearn import metrics\nmetrics.mean_absolute_error(y_test,predictions)","891ba8be":"The prices have remained fairly consistent throughout both the years.","44dffd46":"Having a basement is a plus point. It increases the prices! (Area of living is almost the same)","f70b76fc":"Lets predict the prices ","733fdda6":"Not even 1% of the households that we have, have a waterfront.","bbfe8c35":"That's weird - An avg house having a waterfront is larger in size but way more cheaper. Maybe houses having a waterfront are in the outskirts where the prices are very low.","9c9d9567":"A point to notice is that square feet living = sq. feet above + sq. feet basement. What we can rather do is have a categorical column for if there is a basement of not and delete the sq. feet above and sq. feet basement columns altogether. Afterall what matters is the total living area and if there is a basement there or not. The area of the basement would not have a major affect of its own as such as it is already included in the total living area"}}