{"cell_type":{"f5648bd5":"code","931e097d":"code","b2cf8701":"code","25b85ea9":"code","f1d14292":"code","b001c27c":"code","953570d1":"code","6067c647":"code","1ebab07f":"code","9cd3b407":"code","57621241":"code","d4bd1f68":"code","b5ab04c4":"code","cc5fe678":"code","4ded8b90":"code","4e647d94":"code","f3144961":"code","676a80a6":"code","6a2995e3":"code","70bfeefe":"markdown","82d2e1a9":"markdown"},"source":{"f5648bd5":"import pandas as pd\nimport numpy as np","931e097d":"df = pd.read_csv('..\/input\/pokemon\/Pokemon.csv')\ndf.head()","b2cf8701":"df.drop(columns=['#','Name',\t'Type 1',\t'Type 2'],inplace=True)","25b85ea9":"df","f1d14292":"df.Legendary.value_counts()","b001c27c":"# Import label encoder\nfrom sklearn import preprocessing\n  \n# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n  \n# Encode labels in column 'species'.\ndf['Legendary']= label_encoder.fit_transform(df['Legendary'])\n  \ndf['Legendary'].unique()","953570d1":"df","6067c647":"df.Legendary.value_counts()","1ebab07f":"from sklearn.model_selection import train_test_split\n\npokemon_features = df.drop(\"Legendary\",axis=1)\ntarget = df[\"Legendary\"]\n\nX_train,X_test,Y_train,Y_test = train_test_split(pokemon_features,target,test_size=0.20,random_state=0)","9cd3b407":"from sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver='liblinear')\n\nlr.fit(X_train,Y_train)\n\nY_pred_lr = lr.predict(X_test)\nscore_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Logistic Regression is: \"+str(score_lr)+\" %\")","57621241":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\n\nnb.fit(X_train,Y_train)\n\nY_pred_nb = nb.predict(X_test)\nscore_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Naive Bayes is: \"+str(score_nb)+\" %\")","d4bd1f68":"from sklearn import svm\n\nsv = svm.SVC(kernel='linear')\n\nsv.fit(X_train, Y_train)\n\nY_pred_svm = sv.predict(X_test)\n\nscore_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Linear SVM is: \"+str(score_svm)+\" %\")","b5ab04c4":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train,Y_train)\nY_pred_knn=knn.predict(X_test)\nscore_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")","cc5fe678":"from sklearn.tree import DecisionTreeClassifier\n\nmax_accuracy = 0\n\n\nfor x in range(200):\n    dt = DecisionTreeClassifier(random_state=x)\n    dt.fit(X_train,Y_train)\n    Y_pred_dt = dt.predict(X_test)\n    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n    if(current_accuracy>max_accuracy):\n        max_accuracy = current_accuracy\n        best_x = x\n        \n#print(max_accuracy)\n#print(best_x)\n\n\ndt = DecisionTreeClassifier(random_state=best_x)\ndt.fit(X_train,Y_train)\nY_pred_dt = dt.predict(X_test)\n\nscore_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")","4ded8b90":"from sklearn.ensemble import RandomForestClassifier\n\nmax_accuracy = 0\n\n\nfor x in range(2000):\n    rf = RandomForestClassifier(random_state=x)\n    rf.fit(X_train,Y_train)\n    Y_pred_rf = rf.predict(X_test)\n    current_accuracy = round(accuracy_score(Y_pred_rf,Y_test)*100,2)\n    if(current_accuracy>max_accuracy):\n        max_accuracy = current_accuracy\n        best_x = x\n        \n#print(max_accuracy)\n#print(best_x)\n\nrf = RandomForestClassifier(random_state=best_x)\nrf.fit(X_train,Y_train)\nY_pred_rf = rf.predict(X_test)\n\nscore_rf = round(accuracy_score(Y_pred_rf,Y_test)*100,2)\n\nprint(\"The accuracy score achieved using Decision Tree is: \"+str(score_rf)+\" %\")","4e647d94":"import xgboost as xgb\nxgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\nxgb_model.fit(X_train, Y_train)\nY_pred_xgb = xgb_model.predict(X_test)\nscore_xgb = round(accuracy_score(Y_pred_xgb,Y_test)*100,2)\nprint(\"The accuracy score achieved using XGBoost is: \"+str(score_xgb)+\" %\")","f3144961":"from keras.models import Sequential\nfrom keras.layers import Dense\nimport tensorflow as tf\nmodel = Sequential()\nmodel.add(Dense(32,activation='relu',input_dim=8))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","676a80a6":"model.fit(X_train,Y_train,epochs=100, callbacks = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3))","6a2995e3":"Y_pred_nn = model.predict(X_test)\nrounded = [round(x[0]) for x in Y_pred_nn]\nY_pred_nn = rounded\nscore_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)\nprint(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")","70bfeefe":"Reference Code: https:\/\/www.kaggle.com\/jashsheth5\/binary-classification-with-sklearn-and-keras-95","82d2e1a9":"# Predict if a pokemon is legendary or not:\n\n### Target -> Legendary"}}