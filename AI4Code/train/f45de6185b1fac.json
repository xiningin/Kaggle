{"cell_type":{"03172091":"code","c55a37fb":"code","d5eb0985":"code","f37a8b3c":"code","47799429":"code","31011d94":"code","e1e990c9":"code","e9dc11d6":"code","63d34294":"code","3b4235d6":"code","1da29bae":"code","c6389a9e":"code","0271ce51":"code","7c06d448":"code","8793824c":"code","2c920afd":"markdown","203c9f8e":"markdown","7aae9f3a":"markdown","5e3ffd05":"markdown","88d7dd66":"markdown","aeb21475":"markdown","c3aac146":"markdown","3507b75d":"markdown","d020402e":"markdown","3d892926":"markdown","e5cc2cce":"markdown","3484cac5":"markdown"},"source":{"03172091":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c55a37fb":"\ucee4\ub110 \uacf5\uac1c\ud569\ub2c8\ub2e4.\n\n\uba3c\uc800 \uacf5\uc720\ud574\uc8fc\uc2e0 \ucee4\ub110 \ub355\ubd84\uc5d0 \ub9cc\ub4e4 \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.\n\ud2b9\ud788, Jang \ub2d8 \ucee4\ub110\uc744 \ub9ce\uc774 \ucc38\uc870\ud558\uc600\uc2b5\ub2c8\ub2e4. \uac10\uc0ac\ud569\ub2c8\ub2e4.\n\n\ub098\ub984 \uac00\ub3c5\uc131 \uc788\uac8c \ub9cc\ub4e4\ub824\uace0 \ud588\ub294\ub370 \uc624\ud788\ub824 \uac00\ub3c5\uc131\uc774 \uc548\uc88b\uc544\uc9c4 \uc810\uc740 \uac1c\uc120\uc810\uc778 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\n\n\uac10\uc0ac\ud569\ub2c8\ub2e4.","d5eb0985":"import warnings\nimport seaborn as sns\nimport matplotlib.pylab as plt\nimport PIL\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras import Input\nfrom keras import backend as K\nfrom keras import optimizers\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.applications import *\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nwarnings.filterwarnings('ignore')","f37a8b3c":"def crop_boxing_img(img_name, margin=16, size=(299, 299)):\n    '''\n    \uc774\ubbf8\uc9c0 \uc798\ub77c\ub0b4\uae30 \ud568\uc218 : \ucd94\ud6c4 \ub0b4\uc6a9 \ubcf4\uc644\n    \n    Keyword arguments:\n    img_name  -- \uc774\ubbf8\uc9c0 \ud30c\uc77c\uba85\n    margin    -- \uac04\uaca9\n    size      -- \ucd5c\uc885 \uc774\ubbf8\uc9c0 \uc0ac\uc774\uc988\n    '''\n    if img_name.split('_')[0] == 'train':\n        path = TRAIN_IMG_PATH\n        data = df_train\n    else:\n        path = TEST_IMG_PATH\n        data = df_test\n\n    img = PIL.Image.open(os.path.join(path, img_name))\n    pos = data.loc[data[\"img_file\"] == img_name, ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n\n    width, height = img.size\n    x1 = max(0, pos[0] - margin)\n    y1 = max(0, pos[1] - margin)\n    x2 = min(pos[2] + margin, width)\n    y2 = min(pos[3] + margin, height)\n\n    return img.crop((x1, y1, x2, y2)).resize(size)\n\n\ndef get_train_image_generator(dataframe, datagen, image_size, batch_size, path, seed_num=2019, shuffle_yn=False):\n    '''\n    \ud6c8\ub828\uc6a9 \uc774\ubbf8\uc9c0 \uc0dd\uc131\uae30\n    \n    Keyword arguments:\n    dataframe  -- \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc744 \uc704\ud55c DataFrame\n    datagen    -- \ub370\uc774\ud130 \uc99d\uc2dd\uc6a9 ImageGenerator \n    image_size -- \uc774\ubbf8\uc9c0 \uac00\ub85c\/\uc138\ub85c \ud06c\uae30\n    batch_size -- Batch \ud06c\uae30\n    path       -- \uc774\ubbf8\uc9c0 \ud30c\uc77c\uc758 \uc2dc\uc791 \uacbd\ub85c\n    seed_num   -- Random Seed \uac12\n    shuffle_yn -- Shuffle \uc5ec\ubd80 : True \/ False\n    '''\n    image_generator = datagen.flow_from_dataframe(\n        dataframe=dataframe,\n        directory=path,\n        x_col='img_file',\n        y_col='class',\n        target_size= (image_size, image_size),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=batch_size,\n        seed=seed_num,\n        shuffle=shuffle_yn\n    )\n    \n    return image_generator\n\ndef get_test_image_generator(dataframe, datagen, image_size, batch_size, path, seed_num=2019, shuffle_yn=False):\n    '''\n    \ud14c\uc2a4\ud2b8\uc6a9 \uc774\ubbf8\uc9c0 \uc0dd\uc131\uae30\n    \n    Keyword arguments:\n    dataframe  -- \uc774\ubbf8\uc9c0 \uc0dd\uc131\uc744 \uc704\ud55c DataFrame\n    datagen    -- \ub370\uc774\ud130 \uc99d\uc2dd\uc6a9 ImageGenerator \n    image_size -- \uc774\ubbf8\uc9c0 \uac00\ub85c\/\uc138\ub85c \ud06c\uae30\n    batch_size -- Batch \ud06c\uae30\n    path       -- \uc774\ubbf8\uc9c0 \ud30c\uc77c\uc758 \uc2dc\uc791 \uacbd\ub85c\n    seed_num   -- Random Seed \uac12\n    shuffle_yn -- Shuffle \uc5ec\ubd80 : True \/ False\n    '''\n    image_generator = datagen.flow_from_dataframe(\n        dataframe=dataframe,\n        directory=path,\n        x_col='img_file',\n        y_col=None,\n        target_size= (image_size, image_size),\n        color_mode='rgb',\n        class_mode=None,\n        batch_size=batch_size,\n        seed=seed_num,\n        shuffle=shuffle_yn\n    )\n    \n    return image_generator","47799429":"def build_model(application, image_size=299):\n    '''\n    \uc0ac\uc804\ud6c8\ub828 \ubaa8\ub378 \uc0dd\uc131\n    \n    Keyword arguments:\n    application  -- \uc0ac\uc804 \ud6c8\ub828 \ubaa8\ub378(ex:ResNet50, Xception, ...)\n    image_size   -- \uc774\ubbf8\uc9c0 \uac00\ub85c\/\uc138\ub85c \ud06c\uae30\n    '''\n    input_layer = Input(shape=(image_size, image_size, 3))\n    base_model = application(weights='imagenet', include_top=False)(input_layer)\n    \n    x = GlobalAveragePooling2D()(base_model)\n    x = Dense(1024, activation='relu',\n                     bias_initializer='zeros',\n                     kernel_initializer='glorot_normal',\n                     kernel_regularizer=regularizers.L1L2(l1=0.001, l2=0.001))(x)\n    \n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    \n    output_layer = Dense(196, activation='softmax')(x)    \n    model = Model(input_layer, output_layer)\n    model.summary()\n    \n    optimizer = optimizers.nadam(lr=0.00001)\n        \n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n\n    return model\n\n\ndef get_callback(model_path, patient=4):\n    '''\n    callback \uc815\uc758\uac12 \ubc18\ud658\n    \n    Keyword arguments:\n    model_path  -- Best weights \uc800\uc7a5 \uacbd\ub85c\n    patient     -- Early Stop \uc218, Learning Rate \uac1c\uc120 \uc218(patient \/ 2)\n    '''\n    \n    patient_count = patient \/ 2\n    patient_count = 1 if patient_count < 1 else patient_count\n    \n    callbacks = [\n        EarlyStopping(monitor='val_loss', patience=patient, mode='min', verbose=1),\n        ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = int(patient_count), min_lr=0.00001, verbose=1, mode='min'),\n        ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n    ]\n    \n    return callbacks\n\ndef get_steps(num_samples, batch_size):\n    '''\n    step\ub2f9 \uc0d8\ud50c\ub9c1\uac1c\uc218 \ubc18\ud658\n    \n    Keyword arguments:\n    num_samples  -- \uc804\uccb4 \uc0d8\ud50c\uac1c\uc218\n    batch_size   -- Batch \ud06c\uae30\n    '''\n    if (num_samples % batch_size) > 0:\n        return (num_samples \/\/ batch_size) + 1\n    else:\n        return num_samples \/\/ batch_size\n  \n\ndef create_k_fold_model_path(model_name, num):\n    '''\n    K Fold \ud6c8\ub828\ubcc4 Best weights \uc800\uc7a5\uacbd\ub85c \ubc18\ud658\n    \n    Keyword arguments:\n    model_name  -- \ud6c8\ub828\uc911\uc778 \ubaa8\ub378\uc774\ub984\n    num         -- \uc9c4\ud589\uc911 Fold \uc218\n    '''\n    model_path ='.\/'\n    final_model_path = model_path + str(num) + '_' + model_name + '.hdf5'\n    return final_model_path\n\n\ndef print_header(file_num, k_folds):\n    '''\n    K Fold\ubcc4 \uba38\ub9bf\ub9d0 \ucd9c\ub825\n    \n    Keyword arguments:\n    file_num  -- \uc9c4\ud589\uc911\uc778 Fold \uc218\n    k_folds   -- \uc804\uccb4 Fold \uc218\n    '''\n    print(\"=\" * 44)\n    print(\"====== K Fold Validation step => %d\/%d =======\" % (file_num, k_folds))\n    print(\"=\" * 44)\n    \n\ndef train_with_StratifiedKFold(model, model_name, image_size=299, k_folds=5, epoch_num=20, batch_size=16,\n                               train_augmentaion_size=1, seed=2019, saved_model_path=None):\n    '''\n    Stratified K Fold \ud6c8\ub828 \uc9c4\ud589\n    \ud6c8\ub828\ub41c \ubaa8\ub378\uacfc Fold\ubcc4 Best Weight \uacbd\ub85c \ub9ac\uc2a4\ud2b8 \ubc18\ud658\n    \n    Keyword arguments:\n    model                   -- \uc0ac\uc804\ud6c8\ub828 \ubaa8\ub378\n    model_name              -- \ud6c8\ub828\ubaa8\ub378 \uc774\ub984\n    image_size              -- \uc774\ubbf8\uc9c0 \uac00\ub85c\/\uc138\ub85c \ud06c\uae30\n    k_folds                 -- \uc804\uccb4 Fold \uc218\n    epoch_num               -- \ud6c8\ub828 \ud69f\uc218 \n    batch_size              -- Batch \ud06c\uae30\n    train_augmentaion_size  -- \ub370\uc774\ud130 \uc99d\uc2dd \ubc30\uc218\n    seed                    -- Random Seed \uc218\n    saved_model_path        -- \uc911\ubcf5(\uc5f0\uc7a5) \ud6c8\ub828\uc2dc \ucc38\uace0\ud560 \uae30\uc874 weights \ud30c\uc77c \uacbd\ub85c\n    '''\n    \n    skf = StratifiedKFold(n_splits=k_folds, shuffle=False, random_state=seed)\n    \n    file_num = 1\n    save_model_names = []\n    \n    # \ubaa8\ub378 \uc0dd\uc131\n    target_model = build_model(model, image_size)\n    \n    # \uc800\uc7a5\ub41c \ubaa8\ub378 \ubd88\ub7ec\uc624\uae30\n    if saved_model_path is not None:\n        target_model.load_weights(saved_model_path)\n    \n    # K-Fold \uac80\uc99d \uc2dc\uc791\n    for (train_index, valid_index) in skf.split(\n        df_train['img_file'], \n        df_train['class']):\n\n        # \ud6c8\ub828 \ub300\uc0c1 \ub370\uc774\ud130 \uc218\uc9d1\n        traindf = df_train.iloc[train_index, :].reset_index()\n        train_generator = get_train_image_generator(traindf, train_datagen, image_size, batch_size, TRAIN_CROPPED_PATH)\n        \n        # \uac80\uc99d \ub300\uc0c1 \ub370\uc774\ud130 \uc218\uc9d1\n        validdf = df_train.iloc[valid_index, :].reset_index()\n        valid_generator = get_train_image_generator(validdf, train_datagen, image_size, batch_size, TRAIN_CROPPED_PATH)\n\n        # \uba38\ub9bf\ub9d0 \ucd9c\ub825\n        print_header(file_num, k_folds)\n\n        # \uc800\uc7a5\ud560 \ubaa8\ub378 weight \uacbd\ub85c \uc0dd\uc131\ud558\uae30\n        model_path = create_k_fold_model_path(model_name, file_num)\n        save_model_names.append(model_path)\n\n        # \ud6c8\ub828 \uc2dc\uc791\n        history = target_model.fit_generator(\n            train_generator,\n            steps_per_epoch=get_steps(len(traindf.index), batch_size) * train_augmentaion_size,\n            epochs=epoch_num,\n            validation_data=valid_generator,\n            validation_steps=get_steps(len(validdf.index), batch_size),\n            verbose=1,\n            shuffle=False,\n            callbacks = get_callback(model_path, patient=4)\n            )\n        \n        # \uc2dc\uac01\ud654\n        show_history(history)\n        \n        # Fold \uc218 \uc99d\uac00\n        file_num += 1\n    \n    return (model, save_model_names)\n\n\ndef show_history(history):\n    '''\n    \ud6c8\ub828\uacb0\uacfc \uc2dc\uac01\ud654\n    \n    Keyword arguments:\n    history  -- \ud6c8\ub828\uacb0\uacfc history \n    '''\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1)\n\n    plt.plot(epochs, acc, 'bo', label='Training Acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.show()\n\n    plt.plot(epochs, loss, 'bo', label='Traing loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Trainging and validation loss')\n    plt.legend()\n    plt.show()","31011d94":"def get_prediction(model, image_generator, batch_size=16, tta_size=1):\n    '''\n    \ubaa8\ub378 \uc608\uce21 tta \uc801\uc6a9\ud558\uc5ec \uc2e4\ud589\n    \uc608\uce21\uac12\uc744 \ud569\uc0b0\ud558\uc5ec \ubc18\ud658\n    \n    Keyword arguments:\n    model            -- \uc608\uce21 \ub300\uc0c1 \ubaa8\ub378 \n    image_generator  -- \ud14c\uc2a4\ud2b8 \uc774\ubbf8\uc9c0 \uc0dd\uc131\uae30\n    batch_size       -- Batch \ud06c\uae30 \n    tta_size         -- TTA \ud69f\uc218 \n    '''\n    predictions = None\n    \n    for i in range(tta_size):\n        image_generator.reset()\n        prediction = model.predict_generator(\n            generator = image_generator,\n            steps = get_steps(len(df_test.index), batch_size),\n            verbose=1) \n        \n        if predictions is None:\n            predictions = prediction\n        else :\n            predictions += prediction\n    \n    return predictions\n\ndef get_total_prediction_scores(model, model_paths, image_generator, batch_size=16, tta_size=1):\n    '''\n    \ubaa8\ub378 \uc608\uce21 \uc2e4\ud589\n    \n    Keyword arguments:\n    model            -- \uc608\uce21 \ub300\uc0c1 \ubaa8\ub378 \n    model_paths      -- weight \ud30c\uc77c \uacbd\ub85c List\n    image_generator  -- \ud14c\uc2a4\ud2b8 \uc774\ubbf8\uc9c0 \uc0dd\uc131\uae30\n    batch_size       -- Batch \ud06c\uae30 \n    tta_size         -- TTA \ud69f\uc218 \n    '''\n    predictions = None\n    target_model = build_model(model)\n\n    for path in model_paths:\n        target_model.load_weights(path)\n        prediction = get_prediction(target_model, image_generator, batch_size, tta_size)\n\n        if predictions is None:\n            predictions = prediction\n        else :\n            predictions += prediction\n\n    predictions \/= (len(model_paths) * tta_size)\n    \n    return predictions","e1e990c9":"DATA_PATH = '..\/input\/2019-3rd-ml-month-with-kakr'\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n\nTRAIN_CROPPED_PATH = '..\/cropped_train'\nTEST_CROPPED_PATH = '..\/cropped_test'\n\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))\n\ndf_train['class'] = df_train['class'].astype('str')\n\nIMAGE_SIZE = 299\nBATCH_SIZE = 16","e9dc11d6":"if (os.path.isdir(TRAIN_CROPPED_PATH) == False):\n    os.mkdir(TRAIN_CROPPED_PATH)\n\nif (os.path.isdir(TEST_CROPPED_PATH) == False):\n    os.mkdir(TEST_CROPPED_PATH)\n\nfor i, row in df_train.iterrows():\n    cropped = crop_boxing_img(row['img_file'], size=(IMAGE_SIZE, IMAGE_SIZE))\n    cropped.save(os.path.join(TRAIN_CROPPED_PATH, row['img_file']))\n\nfor i, row in df_test.iterrows():\n    cropped = crop_boxing_img(row['img_file'], size=(IMAGE_SIZE, IMAGE_SIZE))\n    cropped.save(os.path.join(TEST_CROPPED_PATH, row['img_file']))","63d34294":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=20,\n    width_shift_range=0.5,\n    height_shift_range=0.5,\n    shear_range = 0.1,\n    horizontal_flip=True,\n    vertical_flip=False,\n    zoom_range=0.3,\n    #fill_mode='reflect'\n    )\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","3b4235d6":"train_generator = get_train_image_generator(df_train, train_datagen, IMAGE_SIZE, BATCH_SIZE, TRAIN_CROPPED_PATH)\ntest_generator = get_test_image_generator(df_test, test_datagen, IMAGE_SIZE, BATCH_SIZE * 4, TEST_CROPPED_PATH)\ntta_generator = get_test_image_generator(df_test, train_datagen, IMAGE_SIZE, BATCH_SIZE * 4, TEST_CROPPED_PATH)","1da29bae":"model_paths = []\nmodel_paths.append('..\/input\/3rd-ml-month-inceptionv3\/1_InceptionV3.hdf5')\nmodel_paths.append('..\/input\/3rd-ml-month-inceptionv3\/2_InceptionV3.hdf5')\nmodel_paths.append('..\/input\/3rd-ml-month-inceptionv3\/3_InceptionV3.hdf5')\nmodel_paths.append('..\/input\/3rd-ml-month-inceptionv3\/4_InceptionV3.hdf5')\nmodel_paths.append('..\/input\/3rd-ml-month-inceptionv3\/5_InceptionV3.hdf5')","c6389a9e":"predictions = get_total_prediction_scores(\n    model = InceptionV3,\n    model_paths = model_paths,\n    image_generator = test_generator,\n    batch_size = BATCH_SIZE*4,\n    tta_size = 10\n)","0271ce51":"model_paths = []\nmodel_paths.append('..\/input\/3rd-ml-month-densenet201\/1_DenseNet201.hdf5')\nmodel_paths.append('..\/input\/3rd-ml-month-densenet201\/2_DenseNet201.hdf5')\nmodel_paths.append('..\/input\/3rd-ml-month-densenet201\/3_DenseNet201.hdf5')\nmodel_paths.append('..\/input\/3rd-ml-month-densenet201\/4_DenseNet201.hdf5')\nmodel_paths.append('..\/input\/3rd-ml-month-densenet201\/5_DenseNet201.hdf5')","7c06d448":"predictions += get_total_prediction_scores(\n    model = DenseNet201,\n    model_paths = model_paths,\n    image_generator = test_generator,\n    batch_size = BATCH_SIZE*4,\n    tta_size = 10\n)","8793824c":"predicted_class_indices=np.argmax(predictions, axis=1)\n\n# Generator class dictionary mapping\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\n\nsubmission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\nsubmission[\"class\"] = predictions\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","2c920afd":"# \uc608\uce21\uc2e4\ud589 \ubc0f \uacb0\uacfc\uc0dd\uc131","203c9f8e":"# \ud6c8\ub828 \ucc98\ub9ac\ud568\uc218","7aae9f3a":"<a href='.\/submission_1.csv'>Download submission csv File<\/a>","5e3ffd05":"# \uacb0\uacfc\ud30c\uc77c\uc744 \ub85c\uceec\ub85c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uae30","88d7dd66":"# \uc774\ubbf8\uc9c0 \uc798\ub77c\ub0b4\uae30","aeb21475":"# \uc608\uce21 \ucc98\ub9ac\ud568\uc218","c3aac146":"# \uc774\ubbf8\uc9c0 \uc0dd\uc131\uae30 \uc900\ube44","3507b75d":"# \uc774\ubbf8\uc9c0 \uc0dd\uc131\uae30(TRAIN, TEST, TTA)","d020402e":"<a href='.\/1_DenseNet201.hdf5'>Download Model File<\/a>","3d892926":"# \uc804\uc5ed \ubcc0\uc218\uc120\uc5b8","e5cc2cce":"# \uc774\ubbf8\uc9c0 \ucc98\ub9ac\ud568\uc218","3484cac5":"# \ubaa8\ub378 \ud30c\uc77c\uc744 \ub85c\uceec\ub85c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uae30"}}