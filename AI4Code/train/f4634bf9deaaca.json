{"cell_type":{"3da79725":"code","e68d96fb":"code","07508fde":"code","2a73d6d3":"code","080b9161":"code","cd9e858f":"code","ae1afa81":"code","24f73cc7":"code","4f8f250e":"code","edce2f6f":"code","3fee419b":"code","d10dab25":"code","f432c89b":"code","b3de0637":"code","229588fd":"code","fd22b256":"code","00643f3e":"code","27f9e5c0":"code","af8dea01":"code","a70f56f5":"code","6ec92748":"code","55109454":"code","5f36061a":"code","5ba01f5c":"code","f71d75d2":"code","5f1cdba0":"code","44c2756e":"code","23800ba0":"code","6101e174":"code","c50dda8c":"code","72e287a4":"code","3680e9f3":"code","a3e1a867":"code","d7dc7a04":"code","40574c3d":"code","bba414b2":"code","37793bd7":"code","3843d11c":"code","09668bc0":"code","60fa992e":"code","a4551dc7":"code","15b6f9c2":"code","16512a7c":"code","0cc0f0f5":"code","9f425e1a":"code","72ffceff":"code","51a9f112":"code","262eb8e2":"code","3dee0eb1":"code","f329b3ae":"code","5beb0192":"code","384680ea":"code","9943172e":"code","c27acf1c":"code","3372a782":"code","10d936bb":"code","525af9c6":"code","5eefa88f":"code","8271fcad":"code","cbf0cc00":"markdown","2f966459":"markdown","635d7ba9":"markdown","b887a61c":"markdown","b68236db":"markdown","103cfadf":"markdown","141e653f":"markdown","16c70bbf":"markdown","79fb5375":"markdown","44ea464a":"markdown","68be6a8f":"markdown","4ad8bc48":"markdown","9bfdff98":"markdown","397db6c4":"markdown","a04e0e78":"markdown","6b4d4f7b":"markdown","074deaf0":"markdown","6b2da3db":"markdown","d1e093f4":"markdown","c43cb75c":"markdown","84456cb9":"markdown","5718ac73":"markdown","fa5ae47a":"markdown","8ccbff3f":"markdown","a27a9c23":"markdown","9fbae5db":"markdown","fca17484":"markdown","58db3132":"markdown","62a5ba78":"markdown","1f55bf8d":"markdown","cf09226b":"markdown","e87bc0ac":"markdown","e20a9f15":"markdown","272a8b9d":"markdown","c037812a":"markdown","af4ddd18":"markdown","fd8c5b48":"markdown","4833b8fa":"markdown","68341274":"markdown","05ad4c1a":"markdown","c995df46":"markdown","2aac6901":"markdown","1a589eaa":"markdown","309bfe22":"markdown","115a623c":"markdown","144ba329":"markdown","4fc530ec":"markdown","4a8b7ae1":"markdown","1c69edfb":"markdown","60f45d5c":"markdown","878cf4ce":"markdown","6d649599":"markdown","4ed66372":"markdown","c0f27c57":"markdown","a3274a0f":"markdown","3dacbb11":"markdown"},"source":{"3da79725":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport missingno as miss  # Missingno library offers a very nice way to visualize the distribution of NaN values.","e68d96fb":"titanic = pd.read_csv('..\/input\/titanic\/train.csv')\nhouse = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","07508fde":"# credit: https:\/\/www.kaggle.com\/willkoehrsen\/start-here-a-gentle-introduction. \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n                \n        # Coumn for dtypes\n        dtype = df.dtypes\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent,dtype], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values', 2:'Data Types'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","2a73d6d3":"miss.matrix(house.sample(300))","080b9161":"house_miss = missing_values_table(house)\nhouse_miss","cd9e858f":"threshold = 80\ndrop_cols = house_miss[house_miss['% of Total Values'] > threshold].index.tolist()\ndrop_cols","ae1afa81":"house = house.drop(columns=drop_cols)\nhouse.shape","24f73cc7":"house_miss = missing_values_table(house)\nhouse_miss","4f8f250e":"threshold = 3\ndrop_rows = house_miss[house_miss['% of Total Values'] < threshold].index.tolist()\ndrop_rows","edce2f6f":"# This will delete all null rows of `drop_rows` column means this columns  \n# ['BsmtExposure',\n#  'BsmtFinType2',\n#  'BsmtQual',\n#  'BsmtCond',\n#  'BsmtFinType1',\n#  'MasVnrType',\n#  'MasVnrArea',\n#  'Electrical']\nhouse[drop_rows].dropna(inplace=True)","3fee419b":"# Here I will try to show you how to drop null rows from dataset\n# we can directly delete null values where null values % is too low\n# or we can fill those null values by other methods","d10dab25":"titanic_miss = missing_values_table(titanic)\ntitanic_miss","f432c89b":"age_mean = titanic.Age.mean()\nage_median = titanic.Age.median()\ntitanic['age_mean'] = titanic.Age.fillna(age_mean)\ntitanic['age_median'] = titanic.Age.fillna(age_median)","b3de0637":"sns.kdeplot(titanic['age_mean'],color='red',label='Mean')\nsns.kdeplot(titanic['age_median'],color='blue',label='Median')\nsns.kdeplot(titanic['Age'],color='black',label='Original')\nplt.legend()","229588fd":"LotFrontage_mean = house.LotFrontage.mean()\nLotFrontage_median = house.LotFrontage.median()\nhouse['LotFrontage_mean'] = house.LotFrontage.fillna(LotFrontage_mean)\nhouse['LotFrontage_median'] = house.LotFrontage.fillna(LotFrontage_median)\n\nsns.kdeplot(house['LotFrontage_mean'],color='red',label='Mean')\nsns.kdeplot(house['LotFrontage_median'],color='blue',label='Median')\nsns.kdeplot(house['LotFrontage'],color='black',label='Original')\nplt.legend()","fd22b256":"def random_rep(df,field):\n     df[field+\"_random\"]=df[field]\n     # random value to fill the na\n     random_value=df[field].dropna().sample(df[field].isnull().sum(),random_state=0)\n     #pandas need to have same index in order to merge the dataset\n     random_value.index=df[df[field].isnull()].index\n     df.loc[df[field].isnull(),field+'_random']=random_sample","00643f3e":"titanic['Age'].dropna().sample(titanic['Age'].isnull().sum())","27f9e5c0":"titanic['Age']","af8dea01":"random_sample = titanic['Age'].dropna().sample(titanic['Age'].isnull().sum(),random_state=0)\nrandom_sample.index=titanic[titanic['Age'].isnull()].index","a70f56f5":"random_sample","6ec92748":"titanic.loc[titanic['Age'].isnull(),'Age'+'_random']=random_sample","55109454":"titanic['Age_random']","5f36061a":"missing_values_table(titanic)","5ba01f5c":"titanic['Age_arbitary'] = titanic['Age'].fillna(-999)","f71d75d2":"sns.kdeplot(titanic['Age_arbitary'],color='red',label='Age_arbitary')\nsns.kdeplot(titanic['Age'],color='blue',label='Age')\nplt.legend()","5f1cdba0":"c_house = missing_values_table(house)\nc_house","44c2756e":"fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\nhouse.FireplaceQu.value_counts().plot.bar(ax=axes[0])\nhouse.GarageType.value_counts().plot.bar(ax=axes[1])\nhouse.GarageFinish.value_counts().plot.bar(ax=axes[2])","23800ba0":"house.FireplaceQu.mode()[0]","6101e174":"house.GarageType.mode()[0]","c50dda8c":"def freq_imp(df,variable):\n    frq_cat = df[variable].mode()[0]\n    df[variable].fillna(frq_cat, inplace=True)","72e287a4":"c_house[c_house['Data Types'] == 'object'].index.tolist()","3680e9f3":"cat_columns = c_house[c_house['Data Types'] == 'object'].index.tolist()","a3e1a867":"for col in cat_columns:\n    freq_imp(house,col)","d7dc7a04":"missing_values_table(house)","40574c3d":"hdf = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv',usecols=['GarageType','SalePrice'])\nhdf.head(5)","bba414b2":"missing_values_table(hdf)","37793bd7":"hdf['garage_null'] = np.where(hdf['GarageType'].isnull(),1,0)","3843d11c":"hdf['GarageType'] = hdf['GarageType'].fillna(hdf['GarageType'].mode()[0])","09668bc0":"missing_values_table(hdf)","60fa992e":"def nan_new_col(df,variable):\n    hdf[variable+'_null'] = np.where(hdf[variable].isnull(),1,0)\n    hdf[variable] = hdf[variable].fillna(hdf[variable].mode()[0])","a4551dc7":"t_miss = missing_values_table(titanic)\nt_miss","15b6f9c2":"t_miss[t_miss['Data Types'] == 'object'].index.tolist()","16512a7c":"cat_col = t_miss[t_miss['Data Types'] == 'object'].index.tolist()","0cc0f0f5":"def nan_cat(df,var):\n    df[var].fillna('Other',inplace=True)","9f425e1a":"for col in cat_col:\n    nan_cat(titanic, col)","72ffceff":"titanic.Cabin.value_counts()","51a9f112":"missing_values_table(house)","262eb8e2":"sns.histplot(house.LotFrontage, bins=20)","3dee0eb1":"interpolate = house.LotFrontage.interpolate(method='linear')\nsns.histplot(interpolate, bins=20)","f329b3ae":"sns.histplot(house.LotFrontage.interpolate(method='polynomial', order=2),bins=20)","5beb0192":"titanic = pd.read_csv('..\/input\/titanic\/train.csv')\nmissing_values_table(titanic)","384680ea":"# Prepare data for Model\ntemp_titanic = titanic.copy()\ntemp_titanic.dropna(inplace=True)  #drop all null values from New dataset\nage_X = temp_titanic[['Pclass','SibSp','Parch', 'Fare']]  # take numerical columns\nage_y = temp_titanic.Age # Our null value column is Target","9943172e":"from sklearn.neighbors import KNeighborsRegressor\nna_knn = KNeighborsRegressor()\nna_knn.fit(age_X,age_y)\nna_knn.score(age_X,age_y)","c27acf1c":"na_age_index = titanic[titanic['Age'].isna()]  \n# Take all values their Age has null value\n# Here we go slowly slowly each line by line","3372a782":"na_age_index = titanic[titanic['Age'].isna()][['Pclass','SibSp','Parch', 'Fare']]\n# we select dataframe where age has null value\n# then we select only those column that we take when we train model\ntitanic[titanic['Age'].isna()][['Pclass','SibSp','Parch', 'Fare']]","10d936bb":"age_na_pred = na_knn.predict(na_age_index)\n# we take that dataframe of null age with selected column and predict age","525af9c6":"age_fill_na = titanic[titanic['Age'].isna()].index\n# Take index where age is NaN","5eefa88f":"titanic.loc[age_fill_na,'Age'] = age_na_pred\n# We fill null values by predicted model values","8271fcad":"missing_values_table(titanic)","cbf0cc00":"## Capture NaN as new category","2f966459":"Advantage\n1. Fast implementation\n2. No change in distribution\n3. Various method available\n\nDisadvantage\n1. Not useful when lots of null values he just linearly place value\n2. Hard to select method","635d7ba9":"<a id='interpolation'><\/a>\n# Interpolation","b887a61c":"we see there is no change in distribution","b68236db":"Apply function","103cfadf":"We see here in column `PoolQC` 99.5 % values are missing, Not enough data to take insight from him\n\n`MiscFeature`, `Alley` this column also lot of missing values\n\nSo, we can decide 80 `threshold` to delete columns\n\nif column have more than 80% data missing we simply drop those columns","141e653f":"## Row delete","16c70bbf":"Advantage\n1. Might increase score of model\n1. we gather information from missing values\n\nDisadvantage\n1. Create more features","79fb5375":"It is defined as replacing all occurrences of missing values within a variable by an arbitrary value. Ideally the value should be different from the median\/mean\/mode, and not within the normal range of the variable.","44ea464a":"<a id=\"deletion\"><\/a>\n# Deletion","68be6a8f":"1. Column drop\n1. Row Drop","4ad8bc48":"* Age has 19.9% values are missing, we can fill them by mean or median","9bfdff98":"`MasVnrType`, `MasVnrArea`, `Electrical` In this columns less than `3%` data points are missing so we can directly delete those rows.","397db6c4":"Good score, it doesn't need to be 0\n\nHere, we do regression so score is in R2, lower the R2 better model","a04e0e78":"<a id='imputation'><\/a>\n# Imputation","6b4d4f7b":"Very long process\n\nAdvantage\n1. It quite good\n1. We can also check how good our model is\n\nDisadvantage\n1. Hard to implement\n1. Each column reqire different Model","074deaf0":"function to calculate how many missing values","6b2da3db":"we just replace NAN with a new category ","d1e093f4":"The mode of a set of data values is the value that appears most often.","c43cb75c":"1. Mean, Median\/Mode replace\n1. Random Sample\n1. Arbitary imputation\n1. Frequent categories imputation\n1. Capture NaN as new feature\n1. End of distribution\n1. Interpolation","84456cb9":"reading data","5718ac73":"Before that What are missing values\n\nIts has very obvious and straight forward answer, The data that is missing or not present\n\nThen Question is why data is missing?\n\nbecause of many reason like data not available, they dont want to share, machine or human error etc.\n\n","fa5ae47a":"Now no NaN values for any categorical feature","8ccbff3f":"My other useful Notebooks:\n\n### [Multiprocessing Made Easy !!!]('https:\/\/www.kaggle.com\/rushikeshdarge\/multiprocessing-made-easy')\n\n### [Popular Graphs for Beginners]('https:\/\/www.kaggle.com\/rushikeshdarge\/popular-graphs-for-beginners')\n\n### [Detail Data Exploration [EDA] of New York City Taxi]('https:\/\/www.kaggle.com\/rushikeshdarge\/data-exploration-eda-of-new-york-city-taxi')","a27a9c23":"Advantages\n1.  It\u2019s a fast way to obtain complete datasets.\n1.  It captures the importance of a value being \u201cmissing\u201d, if there is one.\n\nDisadvantage\n\n1. Distortion of the original variable distribution and variance.\n1. Distortion of the covariance with the remaining dataset variables.\n1. If the arbitrary value is at the end of the distribution, it may mask or create outliers.\n1. We need to be careful not to choose an arbitrary value too similar to the mean or median (or any other typical value of the variable distribution).\n1. The higher the percentage of NA, the higher the distortions.","9fbae5db":"## Mean, Median\n","fca17484":"* Advantage\n1. Less number of features\n1. model training faster\n\n* Disadvantage\n1. We might loose some information","58db3132":"Why not use ML models to predict NaN values (sound intreasting!) and it is!!!!","62a5ba78":"create new column as is values missing or not and then fill missing values","1f55bf8d":"## Frequent categories imputation","cf09226b":"Create seperate list for missing categorical columns","e87bc0ac":"### I will frequently update this NoteBook, so follow for cool stuff !!","e20a9f15":"* Advantage\n1. Robust to outliers\n1. Faster way\n\n* Disadvantage\n1. Impact on correlation\n1. May change or Distortion in distribution of data points\n","272a8b9d":"## Capture NaN as New Feature","c037812a":"Replace NaN values by mean or median of column","af4ddd18":"## Random Sample","fd8c5b48":"Advantages\n1. Fater way to implement \n\nDisadvantages\n1. Since we are using the more frequent labels, it may use them in an over respresented way, if there are many nan's\n1. It distorts the relation of the most frequent label","4833b8fa":"Let's try another method","68341274":"Replace NaN values by taking random values from column","05ad4c1a":"* We can use this technique for both continous and categorical \n* We can use advnace models like XGBoost, Random Forest \n\n\nAge","c995df46":"importing libraries","2aac6901":"Various methods:\n\u2018nearest\u2019, \u2018zero\u2019, \u2018slinear\u2019, \u2018quadratic\u2019, \u2018cubic\u2019, \u2018spline\u2019, \u2018barycentric\u2019, \u2018polynomial\u2019\n\nCheckOut\n[Documentaion](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.interpolate.html)","1a589eaa":"It is use for Categorical Features","309bfe22":"Fill null values with most frequent value, you can also try with other methods like pput missing values new category","115a623c":"<a id='col_drop'><\/a>\n## Column drop","144ba329":"## Arbitary imputation","4fc530ec":"<a id='model'><\/a>\n# Model-Based Imputation","4a8b7ae1":"![Missing values](https:\/\/i.imgur.com\/ZgPPVC0.jpg)","1c69edfb":"Create a new column as columnName_null fill with is value missing 1 else 0","60f45d5c":"* Red is mean fill na distribution\n* Blue is median fill na distribution\n* Black is original values\n\nWe can observe the distribution of data change after we do fillna using median or mean","878cf4ce":"3 Method to Handle it\n1. [Deletion](#deletion)\n    1. Column drop\n    1. Row drop\n1. [Imputation](#imputation)\n    1. Mean, Median\/Mode replace\n    1. Random Sample\n    1. Arbitary imputation\n    1. Frequent categories imputation\n    1. Capture NaN as new feature\n1. [Interpolation](#interpolation)\n1. [Model-Based Imputation](#model)","6d649599":"Advantage\n1. Fast way\n\nDisadvantage\n1. May change distribution\n1. Cannot use everytime","4ed66372":"Take missing catgorical values","c0f27c57":"### Pro tip: \n* Do not use your original target feature in Null value model, Beacuse that column is absent in test dataset\n* We can use decision trees when categorical features in model (trees handle categorical features)","a3274a0f":"We uses various interpolation technique to fill the missing values rather than hard-coding the value.\n\nDataFrame.interpolate(method='linear', axis=0, limit=None, inplace=False, limit_direction=None, limit_area=None, downcast=None, **kwargs)\nFill NaN values using an interpolation method.","3dacbb11":"create function"}}