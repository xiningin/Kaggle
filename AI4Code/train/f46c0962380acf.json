{"cell_type":{"157a54b2":"code","a18b637c":"code","026bcb29":"code","e8a1af2d":"code","2c09cb83":"code","c2592a39":"code","7ca5ef97":"code","6f69c22c":"code","61a516ff":"code","02a000fb":"code","97eb0845":"code","126fb8fe":"code","7fe3f6bb":"code","00f4ff95":"code","8f254a56":"code","a12164ce":"code","5f7205f9":"code","725e5e37":"code","b05ded67":"code","ae03cbb5":"code","fb84a408":"code","2a806127":"code","3e6440f3":"code","119f1dd3":"code","88c533a4":"code","a0414da5":"code","b7d89ddc":"code","cfd5ec0d":"code","207b24c2":"code","607d4497":"code","60f66100":"code","5919528c":"code","fafd2a1e":"code","6f82760b":"markdown","d67eb259":"markdown","ac661a71":"markdown","cdc639ad":"markdown","3237fbd5":"markdown","f0affc67":"markdown","be0d1804":"markdown","fbdb834c":"markdown","2e94cdbc":"markdown","445c7551":"markdown","e1d7c965":"markdown","b6376163":"markdown"},"source":{"157a54b2":"import os\nprint(os.listdir('..\/input\/image-test-1022'))","a18b637c":"dataPath = '..\/input\/image-test-1022\/'","026bcb29":"# Immport Libraries\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom sklearn.metrics import classification_report, confusion_matrix","e8a1af2d":"import numpy as np\nimport cv2\nimport glob\nimport random\n\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt","2c09cb83":"TargetSize = (224, 224)\ndef prepare_image(filepath):\n    img = cv2.imread(filepath)\n    img_resized = cv2.resize(img, TargetSize, interpolation=cv2.INTER_CUBIC)\n    img_result  = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n    return img_result","c2592a39":"dirList = glob.glob(dataPath+'*') # list of all directories in dataPath\ndirList.sort() # sorted in alphabetical order\nprint(dirList)","7ca5ef97":"Y_data = []\nfor i in range(len(dirList)):\n    fileList = glob.glob(dirList[i]+'\/*.jpg')\n    [Y_data.append(i) for file in fileList]\nprint(Y_data)","6f69c22c":"X_data = []\nfor i in range(len(dirList)):\n    fileList = glob.glob(dirList[i]+'\/*.jpg')\n    [X_data.append(prepare_image(file)) for file in fileList]\nX_data = np.asarray(X_data)\nprint(X_data.shape)","61a516ff":"## random shuffle\nfrom sklearn.utils import shuffle\nX_data, Y_data = shuffle(X_data, Y_data, random_state=0)","02a000fb":"print(Y_data)","97eb0845":"# randomly select a picture to show\ntestNum = random.randint(0,len(X_data)-1)\nprint(testNum)\nplt.imshow(X_data[testNum])","126fb8fe":"# define number of classes & labels\nnum_classes = len(dirList) \nlabels = [dir.replace(dataPath, \"\") for dir in dirList]\nprint(labels)","7fe3f6bb":"# counting number of pictures of each class\nequilibre = []\n[equilibre.append(Y_data.count(i)) for i in range(len(dirList))]\nprint(equilibre)","00f4ff95":"# plot the circle of value counts in dataset\nplt.figure(figsize=(5,5))\nmy_circle=plt.Circle( (0,0), 0.5, color='white')\nplt.pie(equilibre, labels=labels, colors=['red','green'],autopct='%1.1f%%')\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","8f254a56":"# Data Normalisation\nX_train = X_data \/ 255.0\nprint(X_train.shape)","a12164ce":"# One-hot encoding\nY_train = to_categorical(Y_data)\nprint(Y_train.shape)","5f7205f9":"# use MobieNet V2 as base model\nbase_model=MobileNetV2(input_shape=(224,224,3),weights='imagenet',include_top=False) \n\n# add Fully-Connected Layers to Model\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) # FC layer 1\nx=Dense(64,activation='relu')(x)   # FC layer 2\npreds=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n\nmodel=Model(inputs=base_model.input,outputs=preds)","725e5e37":"base_model.trainable = False\n\nmodel.summary()","b05ded67":"# Compile Model\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])","ae03cbb5":"# Train Model (target is loss <0.01)\nbatch_size = 10\nnum_epochs = 30\nhistory = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs)","fb84a408":"# Save Model\nmodel.save('tl_birds2.h5')","2a806127":"# select one bird picture to test\nimageFile = dataPath+'\/Dorami\/Dorami 20.jpg'\nplt.imshow(prepare_image(imageFile))","3e6440f3":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","119f1dd3":"# select another picture to test \nimageFile=dataPath+'Kiteretsu Daihyakka\/Kiteretsu Daihyakka 20.jpg'\nplt.imshow(prepare_image(imageFile))","88c533a4":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","a0414da5":"# select a untrained picture to test the model\nimageFile=dataPath+'Nobita Nobi\/Nobita Nobi 20.jpg'\nplt.imshow(prepare_image(imageFile))","b7d89ddc":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","cfd5ec0d":"# select another untrained picture to test\nimageFile=dataPath+'Doraemon\/Doraemon 20.jpg'\nplt.imshow(prepare_image(imageFile))","207b24c2":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","607d4497":"Y_pred = model.predict(X_train)\ny_pred = np.argmax(Y_pred,axis=1)\n#y_label= [labels[k] for k in y_pred]\ncm = confusion_matrix(Y_data, y_pred)\nprint(cm)","60f66100":"import itertools\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n        \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","5919528c":"plot_confusion_matrix(cm, \n                      normalize=False,\n                      target_names = labels,\n                      title=\"Confusion Matrix, not Normalized\")","fafd2a1e":"print(classification_report(Y_data, y_pred, target_names=labels))","6f82760b":"## Prepare Data","d67eb259":"## Train Model","ac661a71":"## Weighted Average Recall\n\n![WAR.png](attachment:WAR.png)\n* TP : True Positive\n* FP : False Positive\n* TN : True Negative\n* FN : False Negative\n\n\n","cdc639ad":"# Image Classification\n## MobileNetV2 transfer learning","3237fbd5":"## Save Model","f0affc67":"## Plot Confusion Matrix","be0d1804":"### check the entire training dataset","fbdb834c":"## Build Model\n### Load MobileNetV2 model & add FC-layers","2e94cdbc":"### Data Normalization","445c7551":"### Shuffle Data","e1d7c965":"## Test Model","b6376163":"* Accuracy = TP+TN \/ TP+FP+FN+TN\n* Precision = TP \/ TP+FP\n* Recall = TP \/ TP+FN"}}