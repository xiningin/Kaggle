{"cell_type":{"fe1e11d8":"code","823981e3":"code","4bbeb2a0":"code","ca5ac280":"code","a0e2b03a":"code","0bf09baf":"code","3172cb0d":"code","84094aff":"code","4c636b0e":"code","564908de":"code","24029aaf":"code","9c9fc690":"code","9af74179":"code","1ce2145f":"code","ce63a4eb":"code","93eb10d1":"code","b0233e17":"code","9f6e9810":"code","9c07beaa":"code","4d7e1f06":"code","d9a16fa5":"code","a0c18e23":"code","d0990251":"code","4c52d5bd":"code","7bf4b065":"code","453b5ec2":"code","23f0d284":"code","9515f534":"code","c3ece226":"code","219e2ec4":"code","b7ae2f43":"code","1f648434":"code","22177b02":"code","9d09686b":"code","dd386971":"code","74cbfa5e":"code","eeb483b0":"code","a9182136":"code","dbae670f":"code","d65cbba1":"code","14f3dc7c":"code","14ab7e5b":"code","734bb42f":"code","0945bb38":"code","23c3f3b7":"code","dcb210ad":"code","92fb942a":"code","473c9a5d":"code","27e6d0a6":"code","46cf4857":"code","d157ebf8":"code","7c1d2e7e":"code","4c5ede1a":"code","45c4e97c":"code","98fc5906":"code","04cef94c":"code","28551cfa":"code","b8cad576":"code","3155f4a8":"code","07900849":"code","47cb5f9c":"code","c9ea1a8d":"code","80feb78d":"code","507cb039":"code","91e565b7":"code","cf923b3a":"code","259aa04b":"markdown","6cfc1676":"markdown","775350dc":"markdown","4607dd88":"markdown","ad52bfd4":"markdown","fabef89f":"markdown","393d768b":"markdown","5a3978fb":"markdown","93215bd8":"markdown","a641e9a6":"markdown","d0276ab4":"markdown","dfe5d2ca":"markdown","a6c4c5a8":"markdown","e57b51b2":"markdown","356fea72":"markdown","3ca29a1c":"markdown","1cb4e7fc":"markdown","15887026":"markdown","961f82b9":"markdown","74abc665":"markdown","100a9f78":"markdown","e2a45523":"markdown","366db78c":"markdown","23e0d7d3":"markdown","08352795":"markdown","91076433":"markdown","10ac3267":"markdown","c875516a":"markdown","e1c5df5d":"markdown","337934df":"markdown","7acf8ba5":"markdown","5d913399":"markdown","949397dc":"markdown","5d537140":"markdown","fdbf09e6":"markdown","97ff1590":"markdown","dd1396e8":"markdown","d1abfaab":"markdown","9b19cb21":"markdown","e5af1aa0":"markdown","edb2389c":"markdown","c672e543":"markdown","d273cdf7":"markdown","f4fa03e5":"markdown","ecddd2eb":"markdown","77accb1d":"markdown","9d5fc8ed":"markdown","f4fad6bb":"markdown","a368c0df":"markdown","aa7bdf6d":"markdown","d40ad915":"markdown","849821fa":"markdown"},"source":{"fe1e11d8":"import numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import svm \nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics \nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import svm \nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","823981e3":"home = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv',index_col='Id')\ntest = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv',index_col='Id')","4bbeb2a0":"home.head()","ca5ac280":"test.head()","a0e2b03a":"home.shape","0bf09baf":"test.shape","3172cb0d":"home.info()","84094aff":"test.info()","4c636b0e":"#missing values\nmissing = home.isnull().sum()\nmissing = missing[missing>0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar()","564908de":"numerical_features = home.select_dtypes(exclude=['object']).drop(['SalePrice'], axis=1).copy()\nprint(numerical_features.columns)","24029aaf":"categorical_features = home.select_dtypes(include=['object']).copy()\nprint(categorical_features.columns)","9c9fc690":"fig = plt.figure(figsize=(12,18))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(9,4,i+1)\n    sns.distplot(numerical_features.iloc[:,i].dropna(), rug=True, hist=False, label='UW', kde_kws={'bw':0.1})\n    plt.xlabel(numerical_features.columns[i])\nplt.tight_layout()\nplt.show()","9af74179":"fig = plt.figure(figsize=(12,18))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(9,4,i+1)\n    sns.boxplot(y=numerical_features.iloc[:,i])\n\nplt.tight_layout()\nplt.show()","1ce2145f":"fig = plt.figure(figsize=(12,18))\nfor i in range(len(numerical_features.columns)):\n    fig.add_subplot(9, 4, i+1)\n    sns.scatterplot(numerical_features.iloc[:, i],home['SalePrice'])\nplt.tight_layout()\nplt.show()","ce63a4eb":"figure, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(nrows=5, ncols=2)\nfigure.set_size_inches(16,28)\n_ = sns.regplot(home['LotFrontage'], home['SalePrice'], ax=ax1)\n_ = sns.regplot(home['LotArea'], home['SalePrice'], ax=ax2)\n_ = sns.regplot(home['MasVnrArea'], home['SalePrice'], ax=ax3)\n_ = sns.regplot(home['BsmtFinSF1'], home['SalePrice'], ax=ax4)\n_ = sns.regplot(home['TotalBsmtSF'], home['SalePrice'], ax=ax5)\n_ = sns.regplot(home['GrLivArea'], home['SalePrice'], ax=ax6)\n_ = sns.regplot(home['1stFlrSF'], home['SalePrice'], ax=ax7)\n_ = sns.regplot(home['EnclosedPorch'], home['SalePrice'], ax=ax8)\n_ = sns.regplot(home['MiscVal'], home['SalePrice'], ax=ax9)\n_ = sns.regplot(home['LowQualFinSF'], home['SalePrice'], ax=ax10)","93eb10d1":"home.shape","b0233e17":"home = home.drop(home[home['LotFrontage']>200].index)\nhome = home.drop(home[home['LotArea']>100000].index)\nhome = home.drop(home[home['MasVnrArea']>1200].index)\nhome = home.drop(home[home['BsmtFinSF1']>4000].index)\nhome = home.drop(home[home['TotalBsmtSF']>4000].index)\nhome = home.drop(home[(home['GrLivArea']>4000) & (home['SalePrice']<300000)].index)\nhome = home.drop(home[home['1stFlrSF']>4000].index)\nhome = home.drop(home[home['EnclosedPorch']>500].index)\nhome = home.drop(home[home['MiscVal']>5000].index)\nhome = home.drop(home[(home['LowQualFinSF']>600) & (home['SalePrice']>400000)].index)","9f6e9810":"num_correlation = home.select_dtypes(exclude='object').corr()\nplt.figure(figsize=(20,20))\nplt.title('High Correlation')\nsns.heatmap(num_correlation > 0.8, annot=True, square=True)","9c07beaa":"corr = num_correlation.corr()\nprint(corr['SalePrice'].sort_values(ascending=False))","4d7e1f06":"home.drop(columns=['GarageArea','TotRmsAbvGrd','GarageYrBlt','1stFlrSF'],axis=1,inplace=True) \ntest.drop(columns=['GarageArea','TotRmsAbvGrd','GarageYrBlt','1stFlrSF'],axis=1,inplace=True)","d9a16fa5":"# Useless Columns...\nhome=home.drop(columns=['Street','Utilities','Condition2','RoofMatl','Heating']) \ntest=test.drop(columns=['Street','Utilities','Condition2','RoofMatl','Heating']) ","a0c18e23":"home.isnull().mean().sort_values(ascending=False).head(3)","d0990251":"home.drop(columns=['Alley','MiscFeature','PoolQC','PoolArea', 'YrSold', 'MoSold'], axis=1, inplace=True)\ntest.drop(columns=['Alley','MiscFeature','PoolQC','PoolArea', 'YrSold', 'MoSold'], axis=1, inplace=True)","4c52d5bd":"test.isnull().mean().sort_values(ascending=False).head(3)","7bf4b065":"# Checking Home and Test data missing value percentage\nnull = pd.DataFrame(data={'Home Null Percentage': home.isnull().sum()[home.isnull().sum() > 0], 'Test Null Percentage': test.isnull().sum()[test.isnull().sum() > 0]})\nnull = (null\/len(home)) * 100\n\nnull.index.name='Feature'\nnull","453b5ec2":"home.isnull().sum().sort_values(ascending=False)[:50]","23f0d284":"home_num_features = home.select_dtypes(exclude='object').isnull().mean()\ntest_num_features = test.select_dtypes(exclude='object').isnull().mean()\n\nnum_null_features = pd.DataFrame(data={'Missing Num Home Percentage: ': home_num_features[home_num_features>0], 'Missing Num Test Percentage: ': test_num_features[test_num_features>0]})\nnum_null_features.index.name = 'Numerical Features'\nnum_null_features","9515f534":"for df in [home, test]:\n    for col in ('GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', \n                'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotalBsmtSF',\n                'Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'MiscVal',\n                'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea'):\n                    df[col] = df[col].fillna(0)","c3ece226":"_=sns.regplot(home['LotFrontage'],home['SalePrice'])","219e2ec4":"home_num_features = home.select_dtypes(exclude='object').isnull().mean()\ntest_num_features = test.select_dtypes(exclude='object').isnull().mean()\n\nnum_null_features = pd.DataFrame(data={'Missing Num Home Percentage: ': home_num_features[home_num_features>0], 'Missing Num Test Percentage: ': test_num_features[test_num_features>0]})\nnum_null_features.index.name = 'Numerical Features'\nnum_null_features","b7ae2f43":"cat_col = home.select_dtypes(include='object').columns\nprint(cat_col)","1f648434":"home_cat_features = home.select_dtypes(include='object').isnull().mean()\ntest_cat_features = test.select_dtypes(include='object').isnull().mean()\n\ncat_null_features = pd.DataFrame(data={'Missing Cat Home Percentage: ': home_cat_features[home_cat_features>0], 'Missing Cat Test Percentage: ': test_cat_features[test_cat_features>0]})\ncat_null_features.index.name = 'Categorical Features'\ncat_null_features","22177b02":"cat_col = home.select_dtypes(include='object').columns\n\ncolumns = len(cat_col)\/4+1\n\nfg, ax = plt.subplots(figsize=(20, 30))\n\nfor i, col in enumerate(cat_col):\n    fg.add_subplot(columns, 4, i+1)\n    sns.countplot(home[col])\n    plt.xlabel(col)\n    plt.xticks(rotation=90)\n\nplt.tight_layout()\nplt.show()","9d09686b":"var = home['KitchenQual']\nf, ax = plt.subplots(figsize=(10,6))\nsns.boxplot(y=home.SalePrice, x=var)\nplt.show()","dd386971":"f, ax = plt.subplots(figsize=(12,8))\nsns.boxplot(y=home.SalePrice, x=home.Neighborhood)\nplt.xticks(rotation=45)\nplt.show()","74cbfa5e":"## Count of categories within Neighborhood attribute\nfig = plt.figure(figsize=(12.5,4))\nsns.countplot(x='Neighborhood', data=home)\nplt.xticks(rotation=90)\nplt.ylabel('Frequency')\nplt.show()","eeb483b0":"for df in [home, test]:\n    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n                  'BsmtFinType2', 'Neighborhood', 'BldgType', 'HouseStyle', 'MasVnrType', 'FireplaceQu', 'Fence'):\n        df[col] = df[col].fillna('None')","a9182136":"for df in [home, test]:\n    for col in ('LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Condition1', 'RoofStyle',\n                  'Electrical', 'Functional', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'ExterQual', 'ExterCond',\n                  'Foundation', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition'):\n        df[col] = df[col].fillna(df[col].mode()[0])","dbae670f":"home_cat_features = home.select_dtypes(include='object').isnull().mean()\ntest_cat_features = test.select_dtypes(include='object').isnull().mean()\n\ncat_null_features = pd.DataFrame(data={'Missing Cat Home Percentage: ': home_cat_features[home_cat_features>0], 'Missing Cat Test Percentage: ': test_cat_features[test_cat_features>0]})\ncat_null_features.index.name = 'Categorical Features'\ncat_null_features","d65cbba1":"_=sns.regplot(home['LotFrontage'],home['SalePrice'])","14f3dc7c":"home['LotFrontage'] = home.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))\ntest['LotFrontage'] = test.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))","14ab7e5b":"home.corr()['SalePrice'].sort_values(ascending=False)","734bb42f":"home.isnull().sum().sort_values(ascending=False)","0945bb38":"test.isnull().sum().sort_values(ascending=False)","23c3f3b7":"list(home.select_dtypes(exclude='object').columns)","dcb210ad":"figure, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\nfigure.set_size_inches(20,10)\n_ = sns.regplot(home['TotalBsmtSF'], home['SalePrice'], ax=ax1)\n_ = sns.regplot(home['2ndFlrSF'], home['SalePrice'], ax=ax2)\n_ = sns.regplot(home['TotalBsmtSF'] + home['2ndFlrSF'], home['SalePrice'], ax=ax3)","92fb942a":"home['TotalSF']=home['TotalBsmtSF']  + home['2ndFlrSF']\ntest['TotalSF']=test['TotalBsmtSF']  + test['2ndFlrSF']","473c9a5d":"figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\nfigure.set_size_inches(14,10)\n_ = sns.barplot(home['BsmtFullBath'], home['SalePrice'], ax=ax1)\n_ = sns.barplot(home['FullBath'], home['SalePrice'], ax=ax2)\n_ = sns.barplot(home['BsmtHalfBath'], home['SalePrice'], ax=ax3)\n_ = sns.barplot(home['BsmtFullBath'] + home['FullBath'] + home['BsmtHalfBath'] + home['HalfBath'], home['SalePrice'], ax=ax4)","27e6d0a6":"home['TotalBath']=home['BsmtFullBath'] + home['FullBath'] + (0.5*home['BsmtHalfBath']) + (0.5*home['HalfBath'])\ntest['TotalBath']=test['BsmtFullBath'] + test['FullBath'] + test['BsmtHalfBath'] + test['HalfBath']","46cf4857":"figure, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\nfigure.set_size_inches(18,8)\n_ = sns.regplot(home['YearBuilt'], home['SalePrice'], ax=ax1)\n_ = sns.regplot(home['YearRemodAdd'], home['SalePrice'], ax=ax2)\n_ = sns.regplot((home['YearBuilt']+home['YearRemodAdd'])\/2, home['SalePrice'], ax=ax3)","d157ebf8":"home['YrBltAndRemod']=home['YearBuilt']+(home['YearRemodAdd']\/2)\ntest['YrBltAndRemod']=test['YearBuilt']+(test['YearRemodAdd']\/2)","7c1d2e7e":"figure, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3)\nfigure.set_size_inches(20,10)\n_ = sns.regplot(home['OpenPorchSF'], home['SalePrice'], ax=ax1)\n_ = sns.regplot(home['3SsnPorch'], home['SalePrice'], ax=ax2)\n_ = sns.regplot(home['EnclosedPorch'], home['SalePrice'], ax=ax3)\n_ = sns.regplot(home['ScreenPorch'], home['SalePrice'], ax=ax4)\n_ = sns.regplot(home['WoodDeckSF'], home['SalePrice'], ax=ax5)\n_ = sns.regplot((home['OpenPorchSF']+home['3SsnPorch']+home['EnclosedPorch']+home['ScreenPorch']+home['WoodDeckSF']), home['SalePrice'], ax=ax6)","4c5ede1a":"home['Porch_SF'] = (home['OpenPorchSF'] + home['3SsnPorch'] + home['EnclosedPorch'] + home['ScreenPorch'] + home['WoodDeckSF'])\ntest['Porch_SF'] = (test['OpenPorchSF'] + test['3SsnPorch'] + test['EnclosedPorch'] + test['ScreenPorch'] + test['WoodDeckSF'])","45c4e97c":"home['Has2ndfloor'] = home['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nhome['HasBsmt'] = home['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nhome['HasFirePlace'] = home['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\nhome['Has2ndFlr']=home['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nhome['HasBsmt']=home['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n\ntest['Has2ndfloor'] = test['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ntest['HasBsmt'] = test['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ntest['HasFirePlace'] = test['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\ntest['Has2ndFlr']=test['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ntest['HasBsmt']=test['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)","98fc5906":"home['MSSubClass'] = home['MSSubClass'].apply(str)\nhome['LotArea'] = home['LotArea'].astype(np.int64)\n\ntest['MSSubClass'] = test['MSSubClass'].apply(str)\ntest['LotArea'] = test['LotArea'].astype(np.int64)","04cef94c":"fig = plt.figure(figsize=(11,11))\n\nprint (\"Skew of SalePrice:\", home.SalePrice.skew())\nplt.hist(home.SalePrice, normed=1, color='red')\nplt.show()","28551cfa":"fig = plt.figure(figsize=(11,11))\n\nprint (\"Skew of Log-Transformed SalePrice:\", np.log1p(home.SalePrice).skew())\nplt.hist(np.log1p(home.SalePrice), color='green')\nplt.show()","b8cad576":"X = home.drop(['SalePrice'], axis=1)\ny = np.log1p(home['SalePrice'])","3155f4a8":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=2)","07900849":"test.head()","47cb5f9c":"categorical_cols = [cname for cname in X.columns if\n                    X[cname].nunique() <= 30 and\n                    X[cname].dtype == \"object\"] \n                \n\n\nnumerical_cols = [cname for cname in X.columns if\n                 X[cname].dtype in ['int64','float64']]\n\n\nmy_cols = numerical_cols + categorical_cols\n\nX_train = X_train[my_cols].copy()\nX_valid = X_valid[my_cols].copy()\nX_test = test[my_cols].copy()","c9ea1a8d":"num_transformer = Pipeline(steps=[\n    ('num_imputer', SimpleImputer(strategy='constant'))\n    ])\n\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_transformer, numerical_cols),       \n        ('cat',cat_transformer,categorical_cols),\n        ])","80feb78d":"# Reversing log-transform on y\ndef inv_y(transformed_y):\n    return np.exp(transformed_y)\n\nn_folds = 10\n\n# XGBoost\nmodel = XGBRegressor(learning_rate=0.01, n_estimators=3460, max_depth=3, min_child_weight=0,gamma=0, subsample=0.7,colsample_bytree=0.7,objective='reg:squarederror', nthread=-1,scale_pos_weight=1, seed=27, reg_alpha=0.00006)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_valid)\nprint('XGBoost: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_valid))))\n\n      \n# Lasso   \nmodel = LassoCV(max_iter=1e7,  random_state=14, cv=n_folds)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_valid)\nprint('Lasso: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_valid))))\n  \n      \n      \n# GradientBoosting   \nmodel = GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=5)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_valid)\nprint('Gradient: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_valid))))\n","507cb039":"# model = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n#                      max_depth=3, min_child_weight=0,\n#                      gamma=0, subsample=0.7,\n#                      colsample_bytree=0.7,\n#                      objective='reg:squarederror', nthread=-1,\n#                      scale_pos_weight=1, seed=27,\n#                      reg_alpha=0.00006)\n\n# clf = Pipeline(steps=[('preprocessor', preprocessor),\n#                           ('model', model)])\n\n\n# scores = cross_val_score(clf, X, y, scoring='neg_mean_squared_error', \n#                          cv=n_folds)\n# gbr_mae_scores = -scores\n\n# print('Mean RMSE: ' + str(gbr_mae_scores.mean()))\n# print('Error std deviation: ' +str(gbr_mae_scores.std()))","91e565b7":"model = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n                     max_depth=3, min_child_weight=0,\n                     gamma=0, subsample=0.7,\n                     colsample_bytree=0.7,\n                     objective='reg:squarederror', nthread=-1,\n                     scale_pos_weight=1, seed=27,\n                     reg_alpha=0.00006)\n\nfinal_model = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\n\nfinal_model.fit(X_train, y_train)\n\nfinal_predictions = final_model.predict(X_test)","cf923b3a":"output = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': inv_y(final_predictions)})\n\noutput.to_csv('submission.csv', index=False)","259aa04b":"### 4.5 Filling Missing Values in 'LotFrontage'","6cfc1676":"<a id=\"7\"><\/a> <br>\n# 7) SUBMISSION","775350dc":"Split X and y into train and valid data for model testing","4607dd88":"We create extra features in order to categorize data with and without a feature\n\nFor example:\n- 'HasPool' is 1 if you have pool and 0 if you don't have a pool","ad52bfd4":"<a id=\"1\"><\/a> <br>\n# 1) IMPORTING LIBRARIES","fabef89f":"Highly-Correlated Features:\n- YearBuilt vs GarageYrBlt\n- 1stFlrSF vs TotalBsmtSF\n- GrLivArea vs TotRmsAbvGrd\n- GarageCars vs GarageArea","393d768b":"The graph shows that SalePrice is skewed to the right and must be modified","5a3978fb":"### 5.2 Create 'TotalBath' feature","93215bd8":"Our next step is setting up the final model","a641e9a6":"### 4.3 Filling Numerical Missing Values","d0276ab4":"For the remaining missing values we will impute them with 'SimpleImputer()' when modelling","dfe5d2ca":"### 6.1 Dealing with Data for Modelling","a6c4c5a8":"We can clearly see features 'Alley', 'MiscFeature' and 'PoolQC' are missing over 90% of their values. So we decide to remove them.\n'PoolArea' is pretty much a useless column because 99.6% of 'PoolQC' is missing so we also drop this feature.","e57b51b2":"<a id=\"2\"><\/a> <br>\n# 2) READING DATA AND COMPREHENDING DATA\nIn this section:\n- 2.1 Reading Data\n- 2.2 Understanding the Data\n- 2.3 Checking for missing values","356fea72":"### 4.1 Outliers","3ca29a1c":"### 5.3 Create 'YrBuiltAndRemod' feature","1cb4e7fc":"### 5.5 Creating extra features and changing types","15887026":"Some features are the wrong type so we convert them to the right type","961f82b9":"Test data doesn't have any features that have over 90% of missing values. So we don't drop any features.","74abc665":"Here we create a 'num_transformer' and a 'cat_transformer' for imputing and hot-encoding numerical and categorical values. We then store these transformers into a preprocessor column transformer","100a9f78":"### 3.4 Bivariate Analysis","e2a45523":"Notes on Outliers:\nAccording to the plots above, these are the features which appear to have outliers:\n- LotFrontage\n- LotArea\n- MasVnrArea\n- BsmtFinSF1\n- TotalBsmtSF\n- GrLivArea\n- 1stFlrSF\n- EnclosedPorch\n- MiscVal\n- LowQualFinSF\n\nLet's take a closer look at these features...","366db78c":"### 3.3 Univariate Analysis","23e0d7d3":"# OVERVIEW\n\n![](https:\/\/si.wsj.net\/public\/resources\/images\/B3-DM067_RIGHTS_IM_20190319162958.jpg)\n\nHere I made an ULTIMATE Top 5% House Pricing Guide to making a great House Pricing model. \nThis guide consists of many explanations and simple actions in order to efficiently process data and setup a model for submission. Data Visualization is used a lot in this notebook in order to understand the data clearly and perform necessary actions.\n\nI will constantly update this notebook if I find a more efficient way to doing something or if lots of support is shown for this notebook so please show your support and like this notebook in order to motivate me to updating this notebook more often. If you have questions or any tips please comment below \ud83d\ude01. VERSION LOGS are below.\n\n\n# VERSION LOGS:\n### - Version 1: \n- RELEASED\n\n<br>\n\n### - Version 2: \n- Added Data Science Workflow map for a general idea of the process\n- New subsection 'SalePrice Distribution' which visualizes SalePrice before and after log-transformation\n- We decide to log-transform SalePrice and inverse-transform it during modelling\n\n### - Version 3 [CURRENT]:\n- Organized cell involving choosing the best model\n- Dropped features 'YrSold' and 'MoSold' because we deem them useless features\n\n\n# TABLE OF CONTENTS:\n### [1) IMPORTING LIBRARIES](#1)\n### [2) READING DATA AND COMPREHENDING DATA](#2)\n### [3) DATA VISUALIZATION](#3)\n### [4) DATA PROCESSING](#4)\n### [5) FEATURE ENGINEERING](#5)\n### [6) MODELLING](#6)\n### [7) SUBMISSION](#7)\n\n# DATA SCIENCE WORKFLOW:\n![](https:\/\/miro.medium.com\/max\/2000\/1*3FQbrDoP1w1oibNPj9YeDw.png)","08352795":"### 4.2 Removing Certain Features","91076433":"### 4.4 Filling Categorical Missing Values","10ac3267":"We also have useless features so we also decide to drop the features below","c875516a":"<a id=\"3\"><\/a> <br>\n# 3) DATA VISUALIZATION\nIn this section:\n\n- 3.1 Viewing Columns\n\n- 3.2 Distribution of Data\n\n- 3.3 Univariate Analysis of Data\n\n- 3.4 Bivariate Analysis of Data","e1c5df5d":"Drop column with a lower correlation to SalePrice of the pair\n\n(Ex: GarageCars(0.88) & GarageArea(0.876))\n\n**DROP GarageArea**","337934df":"As we can see XGBoost performed the best so we will be using this. Let us check the Mean RMSE and the standard deviation of this model.\n- I commented out because it takes too long and we know this is already the best model","7acf8ba5":"We test three models: 'XGBoost', 'Lasso', and 'Gradient' and see which one performs the best","5d913399":"### 6.3 Setting up Final Model for Submission","949397dc":"### 3.2 Distribution of Data","5d537140":"<a id=\"6\"><\/a> <br>\n# 6) MODELLING\nIn this section:\n\n- 6.1 Dealing with Data for Modelling\n- 6.2 Finding the Best Model\n- 6.3 Setting up Final Model for Submission","fdbf09e6":"<a id=\"4\"><\/a> <br>\n# 4) DATA PROCESSING\nIn this section:\n- 4.1 Outliers\n- 4.2 Removing Certain Features\n- 4.3 Filling Numerical Missing Values\n- 4.4 Filling Categorical Missing Values\n- 4.5 Filling Missing Values in 'LotFrontage'","97ff1590":"### 5.1 Create 'TotalSF' feature","dd1396e8":"- We will deal with 'LotFrontage' later because it is an important feature","d1abfaab":"Lets see which features have the most missing values...","9b19cb21":"We select every numerical column from X and the categorical columns with unique values under 30","e5af1aa0":"- Find the highly-correlated (correlations higher than 0.8)","edb2389c":"### 5.4 Create 'PorchSF' feature","c672e543":"<a id=\"5\"><\/a> <br>\n# 5) FEATURE ENGINEERING\nIn this section:\n- 5.1 Create 'TotalSF' feature\n- 5.2 Create 'TotalBath' feature\n- 5.3 Create 'YrBuiltAndRemod' feature\n- 5.4 Create 'PorchSF' feature\n- 5.5 Creating extra features and changing types\n- 5.6 SalePrice Distribution Visualization","d273cdf7":"As we can see the skew improved from approximately 1.88 to approximately 0.12 so we will log-transform SalePrice in the next section","f4fa03e5":"### 6.2 Finding the Best Model","ecddd2eb":"### 5.6 SalePrice Distribution Visualization","77accb1d":"### 2.3 Checking for Missing Values","9d5fc8ed":"### 2.2 Understanding the Data","f4fad6bb":"# PLEASE <font color='red'><b>U<\/b><\/font><font color='orange'><b>P<\/b><\/font><font color='yellow'><b>V<\/b><\/font><font color='green'><b>O<\/b><\/font><font color='blue'><b>T<\/b><\/font><font color='purple'><b>E<\/b><\/font>\ud83d\udc4d if you found HELPFUL!  \n","a368c0df":"From these regplots we have confirmed there are outliers, so we decide to remove them.","aa7bdf6d":"### 3.1 Viewing Columns","d40ad915":"LotFrontage is correlated to Neighborhood, so we fill in the median based off of Neighborhood feature","849821fa":"### 2.1 Reading Data"}}