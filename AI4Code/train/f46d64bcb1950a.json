{"cell_type":{"1742c806":"code","726d411a":"code","25d94b37":"code","50778cc6":"code","6e99f102":"code","a936e884":"code","ec8571e3":"code","9646cc43":"code","669afbf8":"code","a21037a7":"code","6cfbd366":"code","9383f2a8":"code","26056381":"code","398e6323":"code","273b18c8":"code","c762b0ac":"code","2d265214":"code","17347819":"code","e40d301d":"code","583912df":"code","adf3d342":"code","8b098820":"code","e0591d1f":"code","a28a4033":"code","66d4aec5":"code","d8791d9a":"code","ece34c02":"code","c794f58b":"code","0511a0ed":"code","09a7db9d":"code","759cd904":"code","cfbc7a36":"code","a272daff":"code","5d2d54ee":"code","b0513c66":"markdown","cd6a85cd":"markdown","9635fd2b":"markdown","2ed1991e":"markdown","69436e32":"markdown","b9f55938":"markdown"},"source":{"1742c806":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","726d411a":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","25d94b37":"df = pd.read_csv('\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv', sep='\\t')\n# df.describe()","50778cc6":"df.dtypes","6e99f102":"df.isnull().sum()","a936e884":"# First deal with marital status\ndf.Marital_Status.unique() \n# we simply put the customer into 2 categories: in_relationship and not_in_relationship\n# combineing the relationship to the teen and kid at home:\n# adding 2 to the family size if the customer is in relationship, on the contrary, we add one \n\ncust_relationship = {\n    'Single' : 1,\n    'Together' : 2,\n    'Married' : 2,\n    'Divorced' : 1,\n    'Widow' : 1,\n    'Alone' : 1,\n    'Absurd' : 1,\n    'YOLO' : 1\n}\n\ndf['re_Marital_Status'] = df['Marital_Status'].map(cust_relationship)\n\nfor i in range(len(df)):\n    df['Family_Size'] = df['re_Marital_Status'] + df['Teenhome'] + df['Kidhome']\n","ec8571e3":"# sum all the accepted campigans \ndf['Cmp_accepted'] = df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3'] + df['AcceptedCmp4'] + \\\ndf['AcceptedCmp5'] + df['Response']","9646cc43":"df.head(5)","669afbf8":"df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], format=\"%d-%m-%Y\")\n# the lastest day of the date of 06\/12\/2014, so we assumer the dataset is extracted on 07\/12\/2014\n# thus the days of registion is calculated as below:\n\ndf['extracted_date'] = '07\/12\/2014'\ndf['extracted_date'] = pd.to_datetime(df['extracted_date'])\ndf['Reg_Days'] = df['extracted_date'] - df['Dt_Customer']\ndf['Reg_Days'] = df['Reg_Days'].dt.days\ndf.head(5)","a21037a7":"# sum the total products purchased\ndf['Tot_Products'] = df['MntFishProducts'] + df['MntFruits'] + df['MntMeatProducts'] + \\\n    df['MntWines'] + df['MntSweetProducts'] + df['MntGoldProds']","6cfbd366":"# replace the na value in the 'Income' column with the mean of income\ndf.loc[(df['Income'].isnull() == True), 'Income'] = df['Income'].mean()","9383f2a8":"df.drop_duplicates(inplace=True)","26056381":"df['Age'] = 2014 - df['Year_Birth']","398e6323":"df2 = df.loc[: ,['Age','Income', 'Recency', 'Family_Size','Cmp_accepted','NumDealsPurchases','Reg_Days','Tot_Products','NumWebPurchases', 'NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth']]","273b18c8":"df2.describe()","c762b0ac":"# standardize the data before PCA to avoid putting more weight on the columns who have large value\nscaler = StandardScaler()\ndf2_scaled = scaler.fit_transform(df2)\ndf2_scaled","2d265214":"pca = PCA()\npca.fit(df2_scaled)","17347819":"pca.explained_variance_ratio_\npca.explained_variance_ratio_.cumsum()","e40d301d":"plt.figure(figsize=(10,8))\nplt.plot(range(1,13), pca.explained_variance_ratio_.cumsum(), marker='x', linestyle=\"--\")\nplt.title('Explained variance by components')\nplt.xlabel('number of components')\nplt.ylabel('cumculative explained variance')","583912df":"# as rule of thumb, we take the number of components that account for 80% of the explained variance\npca6 = PCA(n_components=6)","adf3d342":"pca6.fit(df2_scaled)","8b098820":"pca6.transform(df2_scaled)\nscore_pca6 = pca6.transform(df2_scaled)","e0591d1f":"wcss = []\nfor i in range(1,11):\n    kmeans_pca = KMeans(n_clusters = i, init = 'k-means++', random_state=42)\n    kmeans_pca.fit(score_pca6)\n    wcss.append(kmeans_pca.inertia_)","a28a4033":"plt.figure(figsize=(10,8))\nplt.plot(range(1,11), wcss, marker='x', linestyle='--')","66d4aec5":"# from the graph above, we choose 3 as the number of clusters since the curve becomes smoother after 3\nkmeans_pca = KMeans(n_clusters= 3, init='k-means++', random_state= 20)","d8791d9a":"kmeans_pca.fit_transform(score_pca6)","ece34c02":"pd.DataFrame(score_pca6)","c794f58b":"df2_pca_kmeans = pd.concat([df2.reset_index(drop=True), \\\n    pd.DataFrame(score_pca6)], axis=1)\ndf2_pca_kmeans.columns.values[-6:] = ['pc1', 'pc2','pc3', 'pc4','pc5','pc6']\n\ndf2_pca_kmeans['cluster'] = kmeans_pca.labels_","0511a0ed":"df2_pca_kmeans.head()","09a7db9d":"df2_pca_kmeans['cluster'] = df2_pca_kmeans['cluster'].map({0:'First', 1:'Second', 2:'Third'})\ndf2_pca_kmeans.head()","759cd904":"plt.figure(figsize = (10,8))\nsns.scatterplot(x='pc2', y='pc1', data=df2_pca_kmeans, hue='cluster', hue_order=['First', 'Second','Third'])","cfbc7a36":"plt.figure(figsize = (8,8))\npie = df2_pca_kmeans.groupby(['cluster']).size().to_frame().reset_index()\npie.rename(columns={0: 'count'}, inplace=True)\n\npie_labels = ['first cluster', 'second cluster', 'third cluster']\nplt.pie(pie['count'], labels=pie_labels)\nplt.show()","a272daff":"fig, axs = plt.subplots(ncols=2, nrows=6, figsize=(15,30))\nfor cols, x in zip(df2_pca_kmeans.columns[:6], range(6)):\n    for y in range(1):\n        sns.boxplot(y=cols, x='cluster', data=df2_pca_kmeans, order=['First', 'Second','Third'], ax=axs[x,y], showfliers = True )\n\nfor cols, x in zip(df2_pca_kmeans.columns[6:], range(6)):\n    for y in range(1,2):\n        sns.boxplot(y=cols, x='cluster', data=df2_pca_kmeans, order=['First', 'Second','Third'], ax=axs[x,y], showfliers = True )\n","5d2d54ee":"fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(15,15))\n\nfor cols, x in zip(['Age', 'Tot_Products','NumStorePurchases',], range(3)):\n    for y in range(1):\n        sns.scatterplot(x='Income',y=cols, data=df2_pca_kmeans, hue='cluster', size='Cmp_accepted' ,palette=\"tab10\", ax=axs[x,y], hue_order=['First', 'Second','Third']).set(xlim=(0,250000))\n\nfor cols, x in zip(['NumWebPurchases','NumDealsPurchases','NumCatalogPurchases'], range(3)):\n    for y in range(1,2):\n        sns.scatterplot(x='Income',y=cols, data=df2_pca_kmeans, hue='cluster', size='Cmp_accepted' ,palette=\"tab10\", ax=axs[x,y], hue_order=['First', 'Second','Third']).set(xlim=(0,250000))","b0513c66":"### PCA <a class=\"anchor\" id=\"chapter3\"><\/a>","cd6a85cd":"### Results and Conclusion <a class=\"anchor\" id=\"chapter5\"><\/a>\n\nGroup 1: Average Customers\n\nPeople in this group have an average income, buy the average amount of products. Most of them engage in only one campaign,but they make more purchases when there is a discount. They tendto shop online more often than the other two groups.\n\nGroup 2: Low-Income and Low-Engagemnet Customers\n\nThis group of customers has the lowest purchasing ability andspend very little on this company. Nearly all of them don\u2019tparticipate in a campaign. However, they like to visit theonline shop homepage.\n\nGroup 3: High-Income and High-Spending Customers\n\nContrary to the second group, the third group has the highest incomeand purchasing record. Customers in this cluster usually have smallfamily sizes, accept more campaigns and love to make purchases instores or catalogs. They don\u2019t visit shop website much but they stillmake moderate numbers of the web purchase. Also, the discount isnot attractive to them.\n\nIt is important to note that the size of the second group is the largest as it accounts for nearly half of the total customers. The size ofthe other two groups is similar.\nThe company may leverage the current customer base and offer moreand launch campaigns to stimulate the shopping desire of the first andthird group of customers. More promotion on online stores can bemade to attack the second group of buyers since they spend much timebrowsing the webpage but make little purchases.\n\n","9635fd2b":"### Introduction <a class=\"anchor\" id=\"chapter1\"><\/a>\n\nThis notebook aims at analysing the customer information in a company's database. To find out the group that is most likely to buy the products,customer segmentation can identify the target customers. After applying principal component analysis and k-means clustering on the dataset, we divide the customers into three groups. In short, we categorise the customers into groups of low, mid and high income and expenditure.","2ed1991e":"### Data Wrangling <a class=\"anchor\" id=\"chapter2\"><\/a>","69436e32":"### K-Means Clustering <a class=\"anchor\" id=\"chapter4\"><\/a>","b9f55938":"### Table of Contents\n\n* [Introduction](#chapter1)\n* [Data Wrangling](#chapter2)\n* [PCA](#chapter3)\n* [K-Means Clustering](#chapter4)\n* [Results and Conclusion](#chapter5)"}}