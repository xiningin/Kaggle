{"cell_type":{"d42f2850":"code","e1c82b03":"code","d86095be":"code","ee68341d":"code","cadbbc05":"code","4be53b66":"code","0206b53e":"code","468f2fcc":"code","1b931feb":"code","758f2af3":"code","5672c217":"code","e9846c52":"code","920992ce":"code","b82fd4b4":"code","0a922533":"code","458f21f8":"code","05231267":"code","6992e55e":"code","127b206c":"code","0c38f75c":"markdown","d8cac14a":"markdown","ebeb87cc":"markdown","d72aee45":"markdown","7c6f9358":"markdown","354dbcfd":"markdown","a7c03a01":"markdown","75350a81":"markdown","d29ac561":"markdown","5e80d686":"markdown","276a60e7":"markdown","ec7f59e5":"markdown","1fed9aa6":"markdown","068cb01e":"markdown"},"source":{"d42f2850":"import pandas as pd\nimport numpy as np\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport re\n\npy.init_notebook_mode(connected=False)","e1c82b03":"def configure_plotly_browser_state():\n  import IPython\n  display(IPython.core.display.HTML('''\n        <script src=\"\/static\/components\/requirejs\/require.js\"><\/script>\n        <script>\n          requirejs.config({\n            paths: {\n              base: '\/static\/base',\n              plotly: 'https:\/\/cdn.plot.ly\/plotly-latest.min.js?noext',\n            },\n          });\n        <\/script>\n        '''))","d86095be":"df_customers = pd.read_csv(\"..\/input\/olist_customers_dataset.csv\")\ndf_orders = pd.read_csv(\"..\/input\/olist_orders_dataset.csv\")\ndf_order_payments = pd.read_csv(\"..\/input\/olist_order_payments_dataset.csv\")","ee68341d":"df_order_payments = df_order_payments.groupby(\"order_id\").agg({\"payment_value\": \"sum\"}).reset_index()\n\ndf_tmp = pd.merge(df_orders, df_order_payments, on=[\"order_id\"], how=\"inner\")\ndf = pd.merge(df_tmp, df_customers, on=[\"customer_id\"], how=\"inner\")\n\ncond = df[\"order_status\"] == \"delivered\"\ndf = df.loc[cond]\n\ndf[\"order_purchase_date\"] = df[\"order_purchase_timestamp\"].str.slice(0, 10)\n\ndf[\"order_purchase_date\"] = pd.to_datetime(df[\"order_purchase_date\"], format=\"%Y-%m-%d\")","cadbbc05":"def clustering_customers(df, date_max, date_min=False, group_range_days=False):\n    df = df.copy()\n\n    if(date_min == False):\n        cond_f = df[\"order_purchase_date\"] <= pd.to_datetime(date_max)\n    else:\n        cond_1 = df[\"order_purchase_date\"] <= pd.to_datetime(date_max)\n        cond_2 = df[\"order_purchase_date\"] >= pd.to_datetime(date_min)\n        cond_f = cond_1 & cond_2\n\n    df = df.loc[cond_f]\n\n    df[\"today\"] = df[\"order_purchase_date\"].max()\n\n    df[\"today\"] = df[\"today\"].dt.date\n    df[\"today\"] = pd.to_datetime(df[\"today\"], format=\"%Y-%m-%d\")\n\n    df[\"order_purchase_days_since\"] = df[\"today\"]  - df[\"order_purchase_date\"]\n    df[\"order_purchase_days_since\"] = df[\"order_purchase_days_since\"].astype(str)\n    df[\"order_purchase_days_since\"] = df[\"order_purchase_days_since\"].str.replace(r'\\s+days.*', '', regex=True)\n    df[\"order_purchase_days_since\"] = df[\"order_purchase_days_since\"].astype(int)\n    df[\"order_purchase_year\"] = df[\"order_purchase_date\"].dt.year\n\n    agg_group = {\n        \"order_purchase_days_since\": [\"min\", \"max\", \"count\"],\n        \"payment_value\": [\"sum\",\"mean\"]\n    }\n\n    df_group = df.groupby([\"customer_unique_id\"]).agg(agg_group).reset_index()\n\n    df_group.columns = [' '.join(col).strip() for col in df_group.columns.values]\n\n    columns_rename = {\n        \"order_purchase_days_since min\": \"first_order_purchase\",\n        \"order_purchase_days_since max\": \"last_order_purchase\",\n        \"order_purchase_days_since count\": \"order_purchase_qty\",\n        \"payment_value mean\": \"payment_value_mean\",\n        \"payment_value sum\": \"payment_value_sum\"\n    }\n\n    df_group.rename(columns_rename, axis=1, inplace=True)\n\n    median_payment = df_group[\"payment_value_mean\"].median()\n\n    if(group_range_days == False):\n        major_group = 4\n\n        range_days = str(df[\"order_purchase_date\"].max() - df[\"order_purchase_date\"].min()) \n        group_range_days = int(re.sub(r'\\s+days.*', '', range_days))\/major_group\n\n    cond_payment_zero = df_group['payment_value_mean'] == 0.0\n\n    cond_inactive_1 = df_group['last_order_purchase'] > group_range_days*3\n    cond_inactive = cond_inactive_1 | cond_payment_zero\n\n    cond_cold_1 = df_group['last_order_purchase'] > group_range_days*2\n    cond_cold_2 = df_group['last_order_purchase'] <= group_range_days*3\n    cond_cold = cond_cold_1 & cond_cold_2 & ~(cond_payment_zero)\n\n    cond_hot_1 = df_group['last_order_purchase'] > group_range_days\n    cond_hot_2 = df_group['last_order_purchase'] <= group_range_days*2\n    cond_hot = cond_hot_1 & cond_hot_2 & ~(cond_payment_zero)\n\n    cond_active_1 = df_group['last_order_purchase'] <= group_range_days\n    cond_active = cond_active_1 & ~(cond_payment_zero)\n\n    df_group.loc[cond_inactive, \"segment\"] = \"inactive\"\n    df_group.loc[cond_cold, \"segment\"] = \"cold\"\n    df_group.loc[cond_hot, \"segment\"] = \"hot\"\n    df_group.loc[cond_active, \"segment\"] = \"active\"\n\n    cond_hot_high_payment_1 = df_group[\"segment\"] == \"hot\"\n    cond_hot_high_payment_2 = df_group[\"payment_value_mean\"] >= median_payment\n    cond_hot_high_payment = cond_hot_high_payment_1 & cond_hot_high_payment_2\n\n    cond_hot_low_payment_1 = df_group[\"segment\"] == \"hot\"\n    cond_hot_low_payment_2 = df_group[\"payment_value_mean\"] < median_payment\n    cond_hot_low_payment = cond_hot_low_payment_1 & cond_hot_low_payment_2\n\n    cond_active_high_payment_1 = df_group[\"segment\"] == \"active\"\n    cond_active_high_payment_2 = df_group[\"payment_value_mean\"] >= median_payment\n    cond_active_high_payment = cond_active_high_payment_1 & cond_active_high_payment_2\n\n    cond_active_low_payment_1 = df_group[\"segment\"] == \"active\"\n    cond_active_low_payment_2 = df_group[\"payment_value_mean\"] < median_payment\n    cond_active_low_payment = cond_active_low_payment_1 & cond_active_low_payment_2\n\n    cond_cold_high_payment_1 = df_group[\"segment\"] == \"cold\"\n    cond_cold_high_payment_2 = df_group[\"payment_value_mean\"] >= median_payment\n    cond_cold_high_payment = cond_cold_high_payment_1 & cond_cold_high_payment_2\n\n    cond_cold_low_payment_1 = df_group[\"segment\"] == \"cold\"\n    cond_cold_low_payment_2 = df_group[\"payment_value_mean\"] < median_payment\n    cond_cold_low_payment = cond_cold_low_payment_1 & cond_cold_low_payment_2\n\n    df_group[\"sub_segment\"] = \"inactive\"\n    df_group.loc[cond_hot_high_payment, \"sub_segment\"] = \"hot_high_payment_value\"\n    df_group.loc[cond_hot_low_payment, \"sub_segment\"] = \"hot_low_payment_value\"\n    df_group.loc[cond_active_high_payment, \"sub_segment\"] = \"active_high_payment_value\"\n    df_group.loc[cond_active_low_payment, \"sub_segment\"] = \"active_low_payment_value\"\n    df_group.loc[cond_cold_high_payment, \"sub_segment\"] = \"cold_high_payment_value\"\n    df_group.loc[cond_cold_low_payment, \"sub_segment\"] = \"cold_low_payment_value\"\n\n    cond_new_customer = df_group[\"first_order_purchase\"] <= group_range_days*2\n    df_group[\"new_customer\"] = 0\n    df_group.loc[cond_new_customer, \"new_customer\"] = 1\n    \n    return group_range_days, df_group","4be53b66":"period_2018, df_clustering_2018 = clustering_customers(df, \"2018-12-31\")\n\ndf_clustering_2018.head()","0206b53e":"df_revenue_subsegment_2018 = df_clustering_2018.groupby([\"sub_segment\"]).agg({\"payment_value_sum\": \"sum\"}).reset_index()","468f2fcc":"configure_plotly_browser_state()\ntrace0 = go.Bar(\n    x=df_revenue_subsegment_2018[\"sub_segment\"].values,\n    y=df_revenue_subsegment_2018[\"payment_value_sum\"].values,\n    marker=dict(\n        color=['rgba(36,123,160,1)', \n               'rgba(75,147,177,1)',\n               'rgba(112,193,179,1)', \n               'rgba(138,204,192,1)',\n               'rgba(243,255,189,1)',\n               'rgba(247,255,213,1)',\n               'rgba(255,22,84,1)']),\n)\n\ndata = [trace0]\n\nlayout = go.Layout(\n    title='Revenue 2018',\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","1b931feb":"df_clustering_2018_qty = df_clustering_2018.loc[df_clustering_2018[\"order_purchase_qty\"] > 1]\n\ndf_qty_subsegment_2018 = df_clustering_2018_qty.groupby([\"sub_segment\"]).agg({\"order_purchase_qty\": \"count\"}).reset_index()","758f2af3":"configure_plotly_browser_state()\ntrace0 = go.Bar(\n    x=df_qty_subsegment_2018[\"sub_segment\"].values,\n    y=df_qty_subsegment_2018[\"order_purchase_qty\"].values,\n    marker=dict(\n        color=['rgba(36,123,160,1)', \n               'rgba(75,147,177,1)',\n               'rgba(112,193,179,1)', \n               'rgba(138,204,192,1)',\n               'rgba(243,255,189,1)',\n               'rgba(247,255,213,1)',\n               'rgba(255,22,84,1)']),\n)\n\ndata = [trace0]\n\nlayout = go.Layout(\n    title='Repurchase Amount 2018',\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","5672c217":"df_days_repurchase_subsegment_2018 = df_clustering_2018_qty.groupby([\"sub_segment\"]).agg({\"first_order_purchase\": \"mean\", \"last_order_purchase\": \"mean\"}).reset_index()\n\ndf_days_repurchase_subsegment_2018[\"diff_order_purchase\"] = df_days_repurchase_subsegment_2018[\"last_order_purchase\"].values - df_days_repurchase_subsegment_2018[\"first_order_purchase\"].values\n\ndf_days_repurchase_subsegment_2018[\"diff_order_purchase\"] = df_days_repurchase_subsegment_2018[\"diff_order_purchase\"].round(0)","e9846c52":"configure_plotly_browser_state()\ntrace0 = go.Bar(\n    x=df_days_repurchase_subsegment_2018[\"sub_segment\"].values,\n    y=df_days_repurchase_subsegment_2018[\"diff_order_purchase\"].values,\n    marker=dict(\n        color=['rgba(36,123,160,1)', \n               'rgba(75,147,177,1)',\n               'rgba(112,193,179,1)', \n               'rgba(138,204,192,1)',\n               'rgba(243,255,189,1)',\n               'rgba(247,255,213,1)',\n               'rgba(255,22,84,1)']),\n)\n\ndata = [trace0]\n\nlayout = go.Layout(\n    title='Avg days between first and last purchase',\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","920992ce":"period_2017, df_clustering_2017 = clustering_customers(df, \"2017-12-31\")\n\ndf_clustering_2017.head()","b82fd4b4":"df_clutering_2017_2018 =  pd.merge(df_clustering_2017, df_clustering_2018, left_on=[\"customer_unique_id\"], right_on=[\"customer_unique_id\"], how=\"inner\")\n\ncategories = [\"inactive\",\n              \"hot_high_payment_value\",\n              \"hot_low_payment_value\",\n              \"active_high_payment_value\",\n              \"active_low_payment_value\",\n              \"cold_high_payment_value\",\n              \"cold_low_payment_value\"\n             ]\n\nx = pd.Categorical(df_clutering_2017_2018[\"sub_segment_x\"].tolist(), categories=categories)\ny = pd.Categorical(df_clutering_2017_2018[\"sub_segment_y\"].tolist(), categories=categories)\n\ndf_cross_2017_2018 =  pd.crosstab(x,y)\ndf_cross_2017_2018 = df_cross_2017_2018.reindex(index=categories, columns=categories, fill_value=0.0)\n\ndf_cross_2017_2018","0a922533":"df_transition = df_cross_2017_2018.div(df_cross_2017_2018.sum(axis=1), axis=0)\n\ndf_transition","458f21f8":"years = [\"2019\",\"2020\",\"2021\",\"2022\",\"2023\"]\n\ndf_seg =  pd.DataFrame(index=categories, columns=years)\n\ndf_seg[\"seg_tmp\"] = df_seg.index\n\ndf_clustering_2018_count = df_clustering_2018.groupby([\"sub_segment\"]).count().reset_index()\n\ndf_seg = pd.merge(df_seg, df_clustering_2018_count[[\"sub_segment\", \"customer_unique_id\"]], left_on=[\"seg_tmp\"], right_on=[\"sub_segment\"], how=\"left\")\n\ndf_seg.drop([\"sub_segment\", \"seg_tmp\"], axis=1, inplace=True)\n\ndf_seg.rename({\"customer_unique_id\": \"2018\"}, axis=1, inplace=True)\n\ndf_seg[\"2018\"].fillna(0.0, inplace=True)\n\ndf_seg.index = categories\n\ndf_seg[\"2019\"] = np.dot(df_seg[\"2018\"].values, df_transition.values)\ndf_seg[\"2020\"] = np.dot(df_seg[\"2019\"].values, df_transition.values)\ndf_seg[\"2021\"] = np.dot(df_seg[\"2020\"].values, df_transition.values)\ndf_seg[\"2022\"] = np.dot(df_seg[\"2021\"].values, df_transition.values)\ndf_seg[\"2023\"] = np.dot(df_seg[\"2022\"].values, df_transition.values)\n\ndf_seg = df_seg[[\"2018\"] + years].round(0)\n\ndf_seg","05231267":"_, df_clustering_only_2018 = clustering_customers(df, \"2018-12-31\", \"2018-01-01\", period_2018)\n\ndf_revenue_only_2018 = df_clustering_only_2018.groupby([\"sub_segment\"]).agg({\"payment_value_sum\": \"mean\"}).reset_index()\n\ndf_revenue_only_2018","6992e55e":"df_seg[\"seg_tmp\"] = df_seg.index\n\ndf_seg_revenue = pd.merge(df_seg, df_revenue_only_2018, left_on=[\"seg_tmp\"], right_on=[\"sub_segment\"], how=\"left\")\n\ndf_seg_revenue[\"payment_value_sum\"].fillna(0.0, inplace=True)\n\ndf_seg_revenue.index = df_seg_revenue[\"seg_tmp\"].values\n\ndf_seg_revenue[\"2018\"] = df_seg_revenue[\"2018\"].values * df_seg_revenue[\"payment_value_sum\"].values\ndf_seg_revenue[\"2019\"] = df_seg_revenue[\"2019\"].values * df_seg_revenue[\"payment_value_sum\"].values\ndf_seg_revenue[\"2020\"] = df_seg_revenue[\"2020\"].values * df_seg_revenue[\"payment_value_sum\"].values\ndf_seg_revenue[\"2021\"] = df_seg_revenue[\"2021\"].values * df_seg_revenue[\"payment_value_sum\"].values\ndf_seg_revenue[\"2022\"] = df_seg_revenue[\"2022\"].values * df_seg_revenue[\"payment_value_sum\"].values\ndf_seg_revenue[\"2023\"] = df_seg_revenue[\"2023\"].values * df_seg_revenue[\"payment_value_sum\"].values\n\ndf_seg_revenue = df_seg_revenue.round(2)\n\ndf_seg_revenue.drop([\"sub_segment\", \"seg_tmp\", \"payment_value_sum\"], axis=1, inplace=True)\n\ndf_seg_revenue","127b206c":"df_seg_revenue_sum = df_seg_revenue.sum(axis=0)\n\ndiscount = []\ndiscount_rate = 0.10\nfor i in range(0,len(years)+1):\n    discount.append(1 \/ ((1 + discount_rate)**i))\n\ndis_revenue = df_seg_revenue_sum.values * discount\n\nprint(\"2023 - R$\",round(dis_revenue.cumsum()[5] - df_seg_revenue_sum.iloc[0], 2))","0c38f75c":"**`How much is the customer base in the year 2023?`**\n\n\n\n> To perform this calculation were considered a discount factor of 10%. Of course, there are several variables that were not considered.\n\n","d8cac14a":"# Life Time Value","ebeb87cc":"# Work in Progress\n\n\n\n1.   Perform a clusterization using machine learning with more information than the database has.\n2.   Extract profiles from the clustering performed\n\n","d72aee45":"**`Repurchase Amount by Segment 2018`**","7c6f9358":"**`Average days between first and last purchase by segment 2018`**","354dbcfd":"# Descriptive Analysis","a7c03a01":"**`Faturamento por segmento 2018`**\n\n","75350a81":"# Clustering \n\nThe function performs the creation of a hierarchical clustering defined by the following rules:\n\n**Segment**\n\n>  **incative**: Customer who did not make any purchases or that their last purchase was more than three times the period defined as a parameter.\n\n> **cold**: Customer that your last purchase was greater than twice period and less than three times the period.\n\n> **hot**: Customer that your last purchase was greater than the period and less than twice the period.\n\n> **active**: Customer that your last purchase is less than the period.\n\n\n**Sub segment**\n\n>  **incative**: Customer who did not make any purchases or that their last purchase was more than three times the period defined as a parameter.\n\n> **cold_high_payment_value**: Customer that segment is equal to cold and have purchases greater than or equal to the median of all purchases.\n\n> **cold_low_payment_value**: Customer that segment is equal to cold and have purchases less than the median of all purchases.\n\n> **hot_high_payment_value**: Customer that segment is equal to hot and have purchases greater than or equal to the median of all purchases.\n\n> **hot_low_payment_value**: Customer that the segment is equal to hot and have purchases less than the median of all purchases.\n\n> **active_high_payment_value**: Customer segment is equal to active and have purchases greater than or equal to the median of all purchases.\n\n> **active_low_payment_value**: Customer segment is equal to active and have less than the median purchases of all purchases.\n\n\n**New customer**\n\n> **new_customer**: Clientes que a primeira compra for menor que duas vezes o periodo.\n\n\n\n*period*: number of days\n\n\n","d29ac561":"# Conclusion\n\n\n\n> I believe that the analysis can be useful at a certain point, but there are several issues that can not be clearly defined because the database is relatively young to perform certain analysis.\n","5e80d686":"**`Transition Matrix`**","276a60e7":"\n\n---\n\n","ec7f59e5":"**`Predicting Revenue`**","1fed9aa6":"**`Predicting Customer Transition`**","068cb01e":"# Load Dataset"}}