{"cell_type":{"637c3f56":"code","a0f49c4c":"code","ea6a1079":"code","2c70bf05":"code","d1397000":"code","b4a0c6d3":"code","a0b5b32c":"code","175cb93f":"code","50d15e3a":"code","848cf2e3":"code","dcfce399":"markdown","006e9a52":"markdown","628bc793":"markdown"},"source":{"637c3f56":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nimport time\nimport h5py\nimport sys\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense,Flatten,Reshape\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport os\nfrom tqdm import tqdm","a0f49c4c":"# class for loading dataset\nclass TrainingDatasetLoader(object):\n    def __init__(self, data_path):\n\n        print (\"Opening {}\".format(data_path))\n        sys.stdout.flush()\n\n        self.cache = h5py.File(data_path, 'r')\n\n        print (\"Loading data into memory...\")\n        sys.stdout.flush()\n        self.images = self.cache['images'][:]\n        self.labels = self.cache['labels'][:].astype(np.float32)\n        self.image_dims = self.images.shape\n        n_train_samples = self.image_dims[0]\n\n        self.train_inds = np.random.permutation(np.arange(n_train_samples))\n\n        self.pos_train_inds = self.train_inds[ self.labels[self.train_inds, 0] == 1.0 ]\n        self.neg_train_inds = self.train_inds[ self.labels[self.train_inds, 0] != 1.0 ]\n\n    def get_train_size(self):\n        return self.train_inds.shape[0]\n\n    def get_train_steps_per_epoch(self, batch_size, factor=10):\n        return self.get_train_size()\/\/factor\/\/batch_size\n\n    def get_batch(self, n, only_faces=False, p_pos=None, p_neg=None, return_inds=False):\n        if only_faces:\n            selected_inds = np.random.choice(self.pos_train_inds, size=n, replace=False, p=p_pos)\n        else:\n            selected_pos_inds = np.random.choice(self.pos_train_inds, size=n\/\/2, replace=False, p=p_pos)\n            selected_neg_inds = np.random.choice(self.neg_train_inds, size=n\/\/2, replace=False, p=p_neg)\n            selected_inds = np.concatenate((selected_pos_inds, selected_neg_inds))\n\n        sorted_inds = np.sort(selected_inds)\n        train_img = (self.images[sorted_inds,:,:,::-1]\/255.).astype(np.float32)\n        train_label = self.labels[sorted_inds,...]\n        return (train_img, train_label, sorted_inds) if return_inds else (train_img, train_label)\n\n    def get_n_most_prob_faces(self, prob, n):\n        idx = np.argsort(prob)[::-1]\n        most_prob_inds = self.pos_train_inds[idx[:10*n:10]]\n        return (self.images[most_prob_inds,...]\/255.).astype(np.float32)\n\n    def get_all_train_faces(self):\n        return self.images[ self.pos_train_inds ]\n\n","ea6a1079":"# Geting the training data: images from CelebA and ImageNet\npath_to_training_data = tf.keras.utils.get_file('train_face.h5', 'https:\/\/www.dropbox.com\/s\/l5iqduhe0gwxumq\/train_face.h5?dl=1')\n\n# TrainingDatasetLoader using the downloaded dataset\ndata_loader = TrainingDatasetLoader(path_to_training_data)","2c70bf05":"number_of_training_examples = data_loader.get_train_size()\n\n#taking only 500 images for examining - ploting it to see what is it dataset actually\n(images, labels) = data_loader.get_batch(500)","d1397000":"### Examining the CelebA training dataset ###\nface_images = images[np.where(labels==1)[0]]\nnot_face_images = images[np.where(labels==0)[0]]\n\nidx_face = 40\nidx_not_face = 10\n\nplt.figure(figsize=(5,5))\nplt.subplot(1, 2, 1)\nplt.imshow(face_images[idx_face])\nplt.title(\"Face\"); plt.grid(False)\n\nplt.subplot(1, 2, 2)\nplt.imshow(not_face_images[idx_not_face])\nplt.title(\"Not Face\"); plt.grid(False)","b4a0c6d3":"print(\"shape of face images:\", face_images.shape)\nprint(\"Shape of no face images:\", not_face_images.shape)","a0b5b32c":"class GAN:\n    \n    def __init__(self, img_shape, z_dim):\n        self.img_shape = img_shape\n        self.z_dim = z_dim\n        self.losses = []\n        self.accuracies = []\n        self.iteration_checks = []\n\n    def build_generator(self):\n        model = Sequential()\n        model.add(Dense(128, input_dim=self.z_dim))\n        model.add(LeakyReLU(alpha=0.01))\n        model.add(Dense(64*64*1, activation='tanh'))\n        model.add(Reshape(self.img_shape))\n        return model\n\n    def build_discriminator(self):\n        model=Sequential()\n        model.add(Flatten(input_shape=self.img_shape))\n        model.add(Dense(128))\n        model.add(LeakyReLU(alpha=0.01))\n        model.add(Dense(1, activation='sigmoid'))\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n        return model\n\n    def build_gan(self, generator, discriminator):\n        discriminator.trainable=False\n        model = Sequential()\n        model.add(generator)\n        model.add(discriminator)\n        model.compile(loss='binary_crossentropy', optimizer='adam')\n        return model\n    \n    def compile_gan(self):\n        self.generator = self.build_generator()\n        self.discriminator = self.build_discriminator()\n        self.gan = self.build_gan(self.generator, self.discriminator)\n    \n    def display_images(self, ):\n        z = np.random.normal(0,1 , (16,100))\n        generator_images = self.generator.predict(z)\n        generator_images = 0.5*generator_images + 0.5\n        \n        fig,axs = plt.subplots(4,4,figsize=(4,4),sharey=True,sharex=True)\n        cnt=0\n        for i in range(4):\n            for j in range(4):\n                axs[i, j].imshow(generator_images[cnt,:,:,0],cmap='gray')\n                axs[i, j].axis('off')\n                cnt+=1\n        fig.show()\n        \n    \n    def fit(self, X, batch_size=32, interations=10, intervals=1):\n        \n        #X_train, y_train = X[0], X[1]\n        #X_train = X_train\/127.5-1.0\n        \n        X = X\/127.5-1.0\n        #X = (X_train, y_train)\n        \n        real_X = np.ones((batch_size, 1))\n        fake_X = np.zeros((batch_size, 1))\n        \n        for iteration in tqdm(range(interations)):\n            ids = np.random.randint(0, X.shape[0], batch_size)\n            imgs = X[ids]\n            \n            z = np.random.normal(0, 1, (batch_size, self.z_dim))\n            \n            generator_images = self.generator.predict(z)\n            \n            dloss_real = self.discriminator.train_on_batch(imgs, real_X)\n            dloss_fake = self.discriminator.train_on_batch(generator_images, fake_X)\n            \n            dloss, accuracy = dloss,accuracy = 0.5 * np.add(dloss_real,dloss_fake)\n            \n            \n            z = np.random.normal(0, 1, (batch_size, self.z_dim))\n            gloss = self.gan.train_on_batch(z, real_X)\n            \n            if (iteration+1) % intervals == 0:\n                self.losses.append((dloss,gloss))\n                self.accuracies.append(100.0*accuracy)\n                self.iteration_checks.append(iteration+1)\n\n                print(\"%d [D loss: %f , acc: %.2f] [G loss: %f]\" %(iteration+1,dloss,100.0*accuracy,gloss))\n                self.display_images()\n    \n            ","175cb93f":"train_size = 1000\nimg_rows=64\nimg_cols=64\n\nchannels=1\n\nimg_shape = (img_rows, img_cols, channels)\n\nz_dim=100\n\n\nX_train = data_loader.get_batch(train_size)\n\nimages = X_train[0].reshape((-1, 64,64, 1))","50d15e3a":"model = GAN(img_shape=img_shape, z_dim=z_dim)\nmodel.compile_gan()","848cf2e3":"model.fit(images, batch_size=32, interations=2000, intervals=1000)","dcfce399":"## 2. GAN Class","006e9a52":"## 1. Datasets\n\nFacial detection dataset, we'll need a dataset of positive examples (i.e., of faces) and a dataset of negative examples (i.e., of things that are not faces).  We'll use these data to train our models to classify images as either faces or not faces. \n\n\n1.   **Positive training data**: [CelebA Dataset](http:\/\/mmlab.ie.cuhk.edu.hk\/projects\/CelebA.html). A large-scale (over 200K images) of celebrity faces.   \n2.   **Negative training data**: [ImageNet](http:\/\/www.image-net.org\/). Many images across many different categories. We'll take negative examples from a variety of non-human categories. \n[Fitzpatrick Scale](https:\/\/en.wikipedia.org\/wiki\/Fitzpatrick_scale) skin type classification system, with each image labeled as \"Lighter'' or \"Darker''.\n","628bc793":"## 3. Modeling"}}