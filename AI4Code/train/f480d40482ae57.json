{"cell_type":{"c72d1df7":"code","5cc3f028":"code","c4b711e5":"code","bfb9857a":"code","74efea71":"code","0573014b":"code","c0d431c8":"code","51ecceae":"code","8fb14fae":"code","7ee6fc99":"markdown","6a64d745":"markdown","7caf4dc8":"markdown","716ee703":"markdown","28ddb570":"markdown","24a948c6":"markdown","29e680d8":"markdown","8a91d44c":"markdown","e779c32f":"markdown","c9947463":"markdown","358c891a":"markdown","43287b1a":"markdown","5c173474":"markdown","db0dabf7":"markdown","23c36f6d":"markdown","2a248696":"markdown"},"source":{"c72d1df7":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport seaborn as sns","5cc3f028":"df = pd.read_csv('..\/input\/news-classification\/final_news_data.csv')\nprint(df.shape)\ndf.head()","c4b711e5":"news_classes = df.label\nnews_classes.head()","bfb9857a":"#split the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(df['text'], news_classes, test_size=0.2, random_state=42)\n","74efea71":"#initializing the Vectorizer\nvectorizer = TfidfVectorizer(stop_words = 'english', max_df=0.7)\n\n#fit and transform the train and transform the test\ntfidf_train = vectorizer.fit_transform(X_train)\ntfidf_test = vectorizer.transform(X_test)\n","0573014b":"#initializing PassiveAggressiveClassifier & setting n_epochs\npac = PassiveAggressiveClassifier(max_iter = 50)\npac.fit(tfidf_train, y_train)\n","c0d431c8":"#predicting on the test and calculate the accuracy.\n\ny_pred = pac.predict(tfidf_test)\nscore = accuracy_score(y_test, y_pred)\n\nprint(f'Accuracy : {round(score*100, 2)}%')","51ecceae":"#Building the confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred, labels=['FAKE', 'REAL'])\n\nconf_matrix_table = classification_report(y_test, y_pred, labels=['FAKE', 'REAL'])\n\nprint(conf_matrix_table)","8fb14fae":"#visualization of confusion matrix\n\ngroup_names = ['True Negative','False Positive','False Negative','True Positive']\n\ngroup_counts = ['{0:0.0f}'.format(value) for value in\n                conf_matrix.flatten()]\ngroup_percentages = ['{0:.2%}'.format(value) for value in\n                     conf_matrix.flatten()\/np.sum(conf_matrix)]\nlabels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_matrix, annot=labels, fmt='', cmap='Blues')","7ee6fc99":"## What is a TfidfVectorizer?\n\n### TF (Term Frequency): \nThe number of times a word appears in a document is its Term Frequency. A higher value means a term appears more often than others, and so, the document is a good match when the term is part of the search terms.\n\n### IDF (Inverse Document Frequency): \nWords that occur many times a document, but also occur many times in many others, may be irrelevant. IDF is a measure of how significant a term is in the entire corpus.\n\nThe TfidfVectorizer converts a collection of raw documents into a matrix of TF-IDF features.","6a64d745":"## 3. \nGet the labels from the DataFrame.","7caf4dc8":"## About Detecting Fake News with Python\n\nThis advanced python project of detecting fake news deals with fake and real news. Using sklearn, we build a TfidfVectorizer on our dataset. Then, we initialize a PassiveAggressive Classifier and fit the model. In the end, the accuracy score and the confusion matrix tell us how well our model fares.","716ee703":"## 1. \nImporting modules to be used.","28ddb570":"## Summary.\nToday, we learned to detect fake news with Python. We took a political dataset, implemented a TfidfVectorizer, initialized a PassiveAggressiveClassifier, and fit our model. We ended up obtaining an accuracy of 93.61% in magnitude.\n\nHope you enjoyed the fake news detection python project. Keep visiting DataFlair for more interesting python, data science, and machine learning","24a948c6":"## 5. \nLet\u2019s initialize a TfidfVectorizer with stop words from the English language and a maximum document frequency of 0.7 (terms with a higher document frequency will be discarded). Stop words are the most common words in a language that are to be filtered out before processing the natural language data. And a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features.\n\nNow, fit and transform the vectorizer on the train set, and transform the vectorizer on the test set.\n\n","29e680d8":"## 4. \nSplit the dataset into training and testing sets.","8a91d44c":"## What is a PassiveAggressiveClassifier?\n\nPassive Aggressive algorithms are online learning algorithms. Such an algorithm remains passive for a correct classification outcome, and turns aggressive in the event of a miscalculation, updating and adjusting. Unlike most other algorithms, it does not converge. Its purpose is to make updates that correct the loss, causing very little change in the norm of the weight vector.","e779c32f":"# Steps for detecting fake news with Python\nFollow the below steps for detecting fake news and complete your first advanced Python Project","c9947463":"Then, we\u2019ll predict on the test set from the TfidfVectorizer and calculate the accuracy with accuracy_score() from sklearn.metrics.","358c891a":"# Fake News Detection Using TfidfVectorizer and PassiveAggressiveClassifier","43287b1a":"## 2. \nNow, let\u2019s read the data into a DataFrame, and get the shape of the data and the first 5 records.","5c173474":"## 6.\n Next, we\u2019ll initialize a PassiveAggressiveClassifier. This is. We\u2019ll fit this on tfidf_train and y_train.\n","db0dabf7":"### What is Fake News?\nA type of yellow journalism, fake news encapsulates pieces of news that may be hoaxes and is generally spread through social media and other online media. This is often done to further or impose certain ideas and is often achieved with political agendas. Such news items may contain false and\/or exaggerated claims, and may end up being viralized by algorithms, and users may end up in a filter bubble.","23c36f6d":"## 7. \nWe got an accuracy of 93.61% with this model. Finally, let\u2019s print out a confusion matrix to gain insight into the number of false and true negatives and positives.","2a248696":"## 8.\nVisualization of the accuracy on confusion matrix using seaborn heatmap."}}