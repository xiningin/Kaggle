{"cell_type":{"5f0c2d07":"code","36a9aa67":"code","e32ef679":"code","1e199cab":"code","889043a9":"code","12ce6160":"code","1c9fdaeb":"code","2f03b347":"code","9ecfdff7":"code","5e5d4d73":"code","9eb40260":"code","d4c46244":"code","db967246":"code","85508abc":"code","771827bc":"code","a4c5f089":"code","87b3d080":"code","5bf59bd9":"code","29a67cba":"code","5bb0e704":"code","f5ab992f":"code","b74435f9":"code","127a22f4":"code","91340db1":"code","00483e2e":"code","a7663b30":"code","a649474e":"code","65f35a5c":"code","1ef3511a":"code","95d497bc":"code","923be689":"code","e796d37b":"code","6d9a0805":"code","c18e528d":"markdown","0f564d02":"markdown","586b7c18":"markdown","b556aba4":"markdown","026e3d88":"markdown","17e5a5c3":"markdown","c42e2ca1":"markdown","badd7638":"markdown","61605408":"markdown","4917cb1b":"markdown","af049148":"markdown","d80865fd":"markdown","2803acda":"markdown","44269ac6":"markdown","71457076":"markdown","e768bd74":"markdown","a840b5b6":"markdown","161165a8":"markdown","e533d68a":"markdown","e26de2e0":"markdown"},"source":{"5f0c2d07":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2","36a9aa67":"test=pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Test.csv')","e32ef679":"train=pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Train.csv')","1e199cab":"train.describe()","889043a9":"X_train=[]\nfor i in range(len(train)):\n    image = tf.keras.preprocessing.image.load_img('..\/input\/gtsrb-german-traffic-sign\/'+str(train['Path'][i]),grayscale=False, color_mode='rgb', target_size=(25,25),\n    interpolation='nearest')\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n    input_arr = np.array([input_arr])\n    X_train.append(input_arr)","12ce6160":"###################### Another way to do above function using opencv ##################\n# for i in range(len(train)):\n#     img = cv2.imread('..\/input\/gtsrb-german-traffic-sign\/'+train['Path'][i], cv2.IMREAD_UNCHANGED)\n#     train.Path[i]=cv2.resize(img, (25,25),interpolation = cv2.INTER_AREA)\n# for i in range(len(train)):\n#     X_train.append(np.array(train['Path'][i]))","1c9fdaeb":"xtrain=X_train.copy()","2f03b347":"X_train=np.array(X_train)\n","9ecfdff7":"X_train.shape","5e5d4d73":"X_train=X_train.reshape((39209,25, 25, 3))","9eb40260":"Y_train=train['ClassId']","d4c46244":"data_augmentation=models.Sequential([\n    layers.experimental.preprocessing.RandomContrast(0.85,input_shape=(25,25,3)),\n    layers.experimental.preprocessing.RandomZoom(0.2)\n])","db967246":"CNN=models.Sequential([\n                      data_augmentation,\n                       #cnn\n                      layers.Conv2D(filters=20,kernel_size=(3,3),activation='relu'),\n                      layers.MaxPooling2D((2,2)),\n                       \n                       layers.Conv2D(filters=40,kernel_size=(3,3),activation='relu'),\n                       layers.MaxPooling2D((2,2)),\n                        layers.Conv2D(filters=80,kernel_size=(3,3),activation='relu'),\n                        layers.MaxPooling2D((2,2)),\n                       #dense=\n                       layers.Flatten(),\n                      layers.Dense(400,activation='relu'),\n                      layers.Dense(150,activation='relu'),\n                      layers.Dense(43,activation='softmax')\n])\n","85508abc":"CNN.summary()","771827bc":"CNN.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\nhistory=CNN.fit(X_train,Y_train,epochs=25)","a4c5f089":"X_test=[]\nfor i in range(len(test)):\n    image = tf.keras.preprocessing.image.load_img('..\/input\/gtsrb-german-traffic-sign\/'+str(test['Path'][i]),grayscale=False, color_mode='rgb', target_size=(25,25),\n    interpolation='nearest')\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n    input_arr = np.array([input_arr])\n    X_test.append(input_arr)","87b3d080":"xtest=X_test.copy()","5bf59bd9":"X_test=np.array(X_test)","29a67cba":"X_test.shape","5bb0e704":"X_test=X_test.reshape(12630,25,25,3)","f5ab992f":"test.head()","b74435f9":"Y_test=test.ClassId","127a22f4":"CNN.evaluate(X_test,Y_test)","91340db1":"ypred=CNN.predict(X_test)","00483e2e":"\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.show()","a7663b30":"plt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()","a649474e":"y_pred_classes=[np.argmax(element) for element in ypred]\nprint(\"Classfication report\\n\",classification_report(Y_test,y_pred_classes))","65f35a5c":"plt.figure(figsize=(15,15))\nsns.heatmap(confusion_matrix(Y_test,y_pred_classes))","1ef3511a":"tf.keras.models.save_model(CNN,'Internship_task')","95d497bc":"model = tf.keras.models.load_model('Internship_task')","923be689":"def checker(img):\n    img=np.array(img)\n    img=cv2.resize(img,(25,25))\n    img=np.array(img).reshape(-1,25,25,3)\n    return np.argmax(model.predict(img))","e796d37b":"img=cv2.imread('..\/input\/gtsrb-german-traffic-sign\/Meta\/1.png')","6d9a0805":"checker(img)","c18e528d":"#### Prediction and Classificaiton Report","0f564d02":"#### Confusion Matrix","586b7c18":"### Creating the Convolution nueral network for my model for better predicting","b556aba4":"#### Processing the X_test ","026e3d88":"### Checking the any missing, data distribution and description using Describe() function","17e5a5c3":"## <b>Importing all the library to be used","c42e2ca1":"### Predictor of my model ","badd7638":"##### Model Summary","61605408":"#### Model Accuracy Vs Epoch","4917cb1b":"#### Data Augmentaion of the images \n<font color=green> Data Augmentation of images just because to create accurate model by providing some more and data by doing its random contrast and random zoom of images","af049148":"#### Model Loss Vs Epoch","d80865fd":"#### Preparing the Y_train","2803acda":"#### Reshaping the data that is used as input shape in further step of model sequential","44269ac6":"### Saving the Model","71457076":"### Evaluation of Model","e768bd74":"## Read train test csv file using pandas function \"pd.read_csv\"","a840b5b6":"##### copying the data for safety of my X_train data","161165a8":"### Data Preprocessing : Resizing of image, changing it to array and preparing X_train","e533d68a":"# Internship TASK 1","e26de2e0":"#### Model Fitting"}}