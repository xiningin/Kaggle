{"cell_type":{"a216b81e":"code","3f11f8c4":"code","e2bf4d9a":"code","f4ae19c0":"code","d2b86e6a":"code","1250d9ed":"code","ba3a1d94":"code","aeeb43ea":"code","b826840a":"code","fb27a165":"code","960a1ab4":"code","ac5b5a65":"code","6b6299e3":"code","69a717b7":"code","60f7b366":"code","491f7b03":"code","d7d2844a":"code","7ef2feea":"code","469ad1dc":"code","6d0dddcc":"markdown"},"source":{"a216b81e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3f11f8c4":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\n# Understanding the size and the type of data\n'Train Data',train.shape, train.dtypes.value_counts(),'Test Data', test.shape, test.dtypes.value_counts()","e2bf4d9a":"train.describe(), test.describe()","f4ae19c0":"# Finding all object columns (Python considers strings as objects)\nobject_cols = [col for col in train if train[col].dtype=='object']\nobject_cols","d2b86e6a":"# Finding missing values in all columns\ntrain_temp=[col for col in train if train[col].isnull().any()]\ntrain_tempc = (train.isnull().sum())\n\n\ntest_temp=[col for col in test if test[col].isnull().any()]\ntest_tempc = (test.isnull().sum())\n\ntrain_temp, train_tempc, test_temp,test_tempc\n    ","1250d9ed":"# Dropping columns with large missing values i.e. 'Embarked' column \n# and columns that might not add significant value.\ntrain_data = train.drop(columns=['Embarked','Name','Ticket','PassengerId'],axis=1)\ntest_data = test.drop(columns=['Embarked','Name','Ticket','PassengerId'],axis=1)\nobject_cols = [col for col in train_data if train_data[col].dtype=='object']\n\ntrain_data.columns, test_data.columns\n","ba3a1d94":"# Replacing missing values in object columsn with 'None'\ntrain_data[object_cols] = train_data[object_cols].fillna('None')\ntest_data[object_cols] = test_data[object_cols].fillna('None')\n\ntrain_data[object_cols].describe,test_data[object_cols].describe","aeeb43ea":"# Train-Test Split\nfrom sklearn.model_selection import train_test_split\nX = train_data.drop(columns=['Survived']).copy()\ny = train_data['Survived']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X,y,random_state=0)\nX_train.shape, X_valid.shape","b826840a":"# Finding number of unique values in each column\n# Get number of unique entries in each column with categorical data\nobject_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\nd = dict(zip(object_cols, object_nunique))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])\n","fb27a165":"# One-Hot Encoding Gender column\nfrom sklearn.preprocessing import OneHotEncoder\n\nOH_encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[['Sex']]))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(X_valid[['Sex']]))\nOH_test = pd.DataFrame(OH_encoder.transform(test_data[['Sex']]))\n\n\nOH_cols_train, OH_cols_test,OH_test\n","960a1ab4":"# Adding index and column names back to One-hot encoded datasets.\nOH_cols_train.index = X_train.index\nOH_cols_test.index = X_valid.index\nOH_test.index = test_data.index\n\nOH_cols_train.columns = OH_encoder.get_feature_names(['Sex'])\nOH_cols_test.columns = OH_encoder.get_feature_names(['Sex'])\nOH_test.columns = OH_encoder.get_feature_names(['Sex'])\n\nnum_X_train = X_train.drop(['Sex'],axis=1)\nnum_X_valid = X_valid.drop(['Sex'],axis=1)\nnum_test = test_data.drop(['Sex'],axis=1)\n\n\nOH_X_train = pd.concat([num_X_train,OH_cols_train],axis=1)\nOH_X_valid = pd.concat([num_X_valid,OH_cols_test],axis=1)\nOH_test = pd.concat([num_test,OH_test],axis=1)\n\nOH_X_train.describe(), OH_X_valid.describe(), OH_test","ac5b5a65":"# Finding difference in the unique values in training data and test data for column Cabin\nOH_X_train['Cabin'].unique(),OH_X_valid['Cabin'].unique(),'Are the unique values in X_train == X_valid?',set(OH_X_train['Cabin']) == set(OH_X_valid['Cabin'])","6b6299e3":"# Dropping Cabin column too as the unique values in training dataset is not equal to validation dataset. And \n# I'm not sure how to handle new values that might show up in the validation dataset.\nprint('X_train: {},\\nX_valid: {}\\ntest_data: {}'.format(OH_X_train.shape,OH_X_valid.shape,OH_test.shape))\nOH_X_train = OH_X_train.drop(columns=['Cabin'],axis=1)\nOH_X_valid = OH_X_valid.drop(columns=['Cabin'],axis=1)\nOH_test = OH_test.drop(columns=['Cabin'],axis=1)\nprint('X_train: {},\\nX_valid: {}\\ntest_data: {}'.format(OH_X_train.shape,OH_X_valid.shape,OH_test.shape))","69a717b7":"# Checking to make sure that all object type columns are handled.\nOH_X_train.dtypes, OH_X_valid.dtypes,OH_test.dtypes","60f7b366":"# Imputing missing data from numerical columns.\n\nfrom sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer(strategy='most_frequent')\nimputed_X_train = pd.DataFrame( my_imputer.fit_transform( OH_X_train ) )\nimputed_X_valid = pd.DataFrame( my_imputer.transform( OH_X_valid ))\nimputed_test = pd.DataFrame( my_imputer.transform (OH_test))\n\n# Imputation removes column names. Need to put them back.\nimputed_X_train.columns = OH_X_train.columns\nimputed_X_valid.columns = OH_X_valid.columns\nimputed_test.columns = OH_test.columns\n\nimputed_X_train.describe(),imputed_X_valid.describe(), imputed_test","491f7b03":"# Using random forest regression\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor(random_state=1,n_estimators=300,max_depth=10)\nforest_model.fit(imputed_X_train,y_train)\nrf_preds = forest_model.predict(imputed_X_valid)\nprint(mean_absolute_error(y_valid,rf_preds))\n","d7d2844a":"rf_preds = forest_model.predict(imputed_test)\nrf_preds","7ef2feea":"# Rounding values.\nrf_preds = [int(round(v,0)) for v in rf_preds]\nrf_preds","469ad1dc":"output = pd.DataFrame({'PassengerId':test.PassengerId,'Survived':rf_preds})\noutput = output.set_index('PassengerId')\noutput.to_csv('\/kaggle\/working\/rf_imputed_oh_submission.csv')\nprint(output)\nprint('Submission saved')","6d0dddcc":"This is an attempt at the Titanic problem after learning on how to [handle missing](https:\/\/www.kaggle.com\/alexisbcook\/missing-values) and [categorical values](https:\/\/www.kaggle.com\/alexisbcook\/categorical-variables). \n\nThe hope is that this notebook will help other beginners like me to highlight common mistakes so that they don't have to.\n\n*You must learn from the mistakes of others. You can't possibly live long enough to make them all yourself.*\n\n\n# Steps Taken\n\n1. Read the files into Training and Testing data. \n**Why**? \u2192 Reading the files into Pandas' dataframe data structure allows us to use various functions to understand and work with the data.\n2. Understand the shape of the data and the type of data.\n**Why**? \u2192 Knowing the shape of the data allows us to plan on what machine learning model to use and knowing what data types each column has makes us aware of the approach to take for the next steps of the process.\n3. Find all the object type columns and the number of unique values in each of those to decide whether to drop, one-hot or label encode them.\n**Why**? \u2192 Object type columns with missing data need to be handled in a different manner than columns with numerical values. Missing numerical values can be imputed but not the case with categorical values. If the number of unique values in a categorical columns is > 15 then we should not use One-hot encoding (for nominal variables) as it will add a lot more columns than required. We would have to use label encoding (for ordinal variables) for it. The issue with label encoding is that if there is a new data type in the test dataset then label encoding will fail. Hence new values in test data need. \n4. Fill the missing values in object columns with 'None'.\n**Why**? \u2192 Columns with categorical values cannot be one-hot encoded or labelled if it has missing values. Hence the approach most suggested is to replace NaN values with 'None'\n5. Split the data into training and testing sets.\n**Why**? \u2192Splitting the training data into training and testing allows us to check various models before finalizing the right one for that problem statement.\n6. One-Hot encoding categorical columns with unique values < 15 i.e. Gender column.\n**Why**? \u2192 Most machine learning models cannot process categorical data. They need numerical values. One-hot encoding allows us to convert categorical nominal variables into numbers that can be then processed by a machine learning model.\n7. Imputing missing values\n**Why**? \u2192 To ensure we are able to use the data in the model\n8. Fit RandomForestRegression\n\n# Observations\/Mistakes\n\n1. Did not read Titanic problem statement clearly. There was a ton of data I missed. For e.g. \n    1. the meaning of different columns\n    2. Actual survival rate which can help me understand whether the given data is an actual representation of actual reality \n    3. Kaggle has their own data visualization tool built into the data part of the competition which I did not use. This could have reduced the amount of time I need to understand the data.\n2. Read a few notebooks on the same competition. They used map() and other such functions provided by Pandas and a lot of data visualization.\n3. Correlation, feature engineering and using multiple ML models is what is different from my approach and theirs.\n4. Forgot to remove PassengerId. By focusing on trying to use the techniques I learnt in Machine Learning courses I neglected common sense. In retrospect it is ok to do this because the aim of doing the courses is to learn different techniques. After learning most frequently used techniques I can start using common sense to write simpler and cleaner code.\n5. The approach to this problem is much cleaner now. Writing comments in code itself is better initially as it does not distract me from the task at hand. I can later add fancy markdowns.\n6. Forgot to apply the same preprocessing steps to the test data as I did to the training data. Due to this I had to go back and add it.\n7. Performance of this model is 0.76... not the best."}}