{"cell_type":{"5a421411":"code","3a50276c":"code","045135a7":"code","15d70720":"code","d091f452":"code","03744261":"code","36460713":"code","73d6fb3e":"code","de062faf":"code","6c6c6cd6":"code","7d047684":"code","8e792522":"code","35d0d116":"code","b7fa1c2c":"code","abc1a82e":"code","d184670b":"code","0c0aa45f":"code","7f19b927":"code","13358a8a":"code","bf0603e8":"code","c2d3d956":"code","f31351d5":"code","ba7d9c65":"code","a455d98b":"code","dad951c9":"code","2aac795b":"code","5392168e":"markdown"},"source":{"5a421411":"# required libraies\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split #for splitting dataset into train,test \nfrom sklearn.impute import SimpleImputer #for missing values\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder","3a50276c":"# reading dataset\niris = pd.read_csv(\"..\/input\/iris-nan\/data_with_nans.csv\")","045135a7":"# exploring dataset\niris.head()","15d70720":"iris.columns","d091f452":"#dropping unnecessary \"Unnamed: 0\" column\niris.drop(columns=\"Unnamed: 0\", inplace=True)","03744261":"for c in iris.columns[1:-1]:\n    plt.figure(figsize=(12,8))\n    sns.scatterplot(data=iris, x=\"Id\", y=c, hue=\"Species\")\n    plt.show();","36460713":"#clean outliers: 3 sigma method\n\"\"\"\nfor c in iris.columns[1:-1]:\n    for s in iris[\"Species\"].unique():\n        spec = iris[iris[\"Species\"] == s]\n        col = spec[c]\n        std = col.std()\n        avg = col.mean()\n        three_sig_plus = avg + 3*std\n        three_sig_minus = avg - 3*std\n        outlier = col[((spec[c] > three_sig_plus) | (spec[c] < three_sig_minus))].index\n        iris.drop(index=outlier, inplace=True)\n\"\"\"","73d6fb3e":"#clean outliers: IQR method (alternative)\nfor c in iris.columns[1:-1]:\n    for s in iris[\"Species\"].unique():\n        spec = iris[iris[\"Species\"] == s]\n        col = spec[c]\n        q1 = col.quantile(0.25)\n        q3 = col.quantile(0.75)\n        iqr = q3 - q1\n        minimum = q1 - (1.5*iqr)\n        maximum = q3 + (1.5*iqr)\n        outlier = col[((spec[c] > maximum) | (spec[c] < minimum))].index\n        iris.drop(index=outlier, inplace=True)\n        print(outlier)","de062faf":"#cleaned dataset\nfor c in iris.columns[1:-1]:\n    plt.figure(figsize=(12,8))\n    sns.scatterplot(data=iris, x=\"Id\", y=c, hue=\"Species\")\n    plt.show();","6c6c6cd6":"#set index to Id column\niris.set_index(\"Id\", inplace=True)","7d047684":"iris.describe()","8e792522":"iris.groupby(\"Species\").describe().T","35d0d116":"iris.info()","b7fa1c2c":"#setting X and y \nX = iris.select_dtypes(include=[\"float64\"])\ny = iris.select_dtypes(include=[\"object\"])","abc1a82e":"X.head()","d184670b":"y.head()","0c0aa45f":"#label encoding\nle = LabelEncoder()\ny=le.fit_transform(y)\ny","7f19b927":"#we have some nan values\nX.isna().sum()","13358a8a":"# fill na in in X data using SimpleImputer\nx_column_names = X.columns\nimputer = SimpleImputer(strategy=\"most_frequent\")\nimputer = imputer.fit(X)\nX = imputer.transform(X) \nX = pd.DataFrame(X)\nX.columns = x_column_names # put back column names","bf0603e8":"X.head()","c2d3d956":"#now, no nan values\nX.isna().sum()","f31351d5":"#spliting dataset for training and test\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=61)","ba7d9c65":"#RandomForestClassifier model\nmodel = RandomForestClassifier(random_state=61)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\nprint(accuracy_score(y_test, preds))\nprint(confusion_matrix(y_test,preds))","a455d98b":"\"\"\"\ntrying with different hyperparameters\nparams = {\"min_samples_split\":[1,3,5,8], \"max_depth\":[1,3,5,8], \"n_estimators\":[100,200,500,1000], \"max_features\":[1,3,5,8]}\ntuned = GridSearchCV(model, params, cv=5, n_jobs=-1 ,verbose=2)\ntuned.fit(X_train,y_train)\npreds=tuned.predict(X_test)\nprint(accuracy_score(y_test, preds))\nprint(tuned.best_params_)\n\"\"\"","dad951c9":"#KNeighborsClassifier model\nmodel = KNeighborsClassifier()\nmodel.fit(X_train, y_train)\npreds=model.predict(X_test)\nprint(accuracy_score(y_test, preds))\nprint(confusion_matrix(y_test,preds))","2aac795b":"\"\"\"\ntrying with different hyperparameters\nparams = {\"leaf_size\":[2,3,5,10,20], \"n_neighbors\":[3,5,7]}\ntuned = GridSearchCV(model, params, cv=10, n_jobs=-1 ,verbose=2)\ntuned.fit(X_train,y_train)\npreds=tuned.predict(X_test)\nprint(accuracy_score(y_test, preds))\nprint(tuned.best_params_)\n\"\"\"","5392168e":"The Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository.\n\nIt includes three iris species with 170 samples totally (with some nan values) as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n\nThe columns in this dataset are:\n\n* Id\n* SepalLengthCm\n* SepalWidthCm\n* PetalLengthCm\n* PetalWidthCm\n* Species"}}