{"cell_type":{"25c5dc91":"code","8453871b":"code","d81c957a":"code","970de4e5":"code","b67712a4":"code","493eb5a5":"code","65bd6e9c":"code","d59d8466":"code","10fea485":"code","e8c932e9":"code","dccb1e66":"code","931e7012":"code","b09fa002":"code","015603a7":"code","d8165d8d":"code","cf6ea63c":"code","122cfb6f":"code","1cc00768":"code","2dc5a42d":"code","056db56e":"code","eb8f22ba":"code","881e1153":"code","c780706b":"code","7634e308":"code","1889eb48":"code","084731a7":"markdown","9e811699":"markdown","1f202f0d":"markdown","ff5d0dc7":"markdown","fffccd53":"markdown","7799f2ff":"markdown","f1711673":"markdown","b8292d50":"markdown","4bf11c0b":"markdown","073301b0":"markdown","3e130825":"markdown","9abbc853":"markdown"},"source":{"25c5dc91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8453871b":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntrain.head()","d81c957a":"import matplotlib.pyplot as plt #Library to plot the digit\n\ndef ploting_a_digit(line,label):                       #this function takes a line from our df and plots a digit                        \n    digit_array=line.to_numpy().reshape((28,28)) #Transform the pixels into a 28x28 array\n    plt.title(\"Label: {}\".format(label))          \n    fig = plt.imshow(digit_array,cmap='gist_gray')     #Plot the Figure","970de4e5":"from random import randint\n\nrandom_num=randint(0,train.shape[0]-1) # train.shape[0] - 1 as randint is inclusive in both ends\nrandom_line=train.iloc[random_num,:]\n\nploting_a_digit(random_line,random_line.pop('label')) #ploting a random digit\n","b67712a4":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nlabels = train.pop('label')","493eb5a5":"train_set= scaler.fit_transform(train)\nfinal_test_set=scaler.transform(test)","65bd6e9c":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(train_set,labels,test_size=0.15) #Our split will be test = 15% train = 85%","d59d8466":"from sklearn.ensemble import RandomForestClassifier","10fea485":"model_1 = RandomForestClassifier() #Build our model\nmodel_1.fit(X_train,y_train)       #Train our model","e8c932e9":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report","dccb1e66":"y_pred = model_1.predict(X_test)\nmodel_1_score = accuracy_score(y_pred,y_test)\nprint (\"Model 1 accuracy = {:.2f}%\".format(model_1_score*100))\n","931e7012":"random_num=randint(0,test.shape[0]-1) # final_test.shape[0] - 1 as randint is inclusive in both ends\nrandom_line=test.iloc[random_num,:]\n\nfinal_pred = model_1.predict(random_line.to_numpy().reshape(1,-1)) #predict on a random sample, reshape because is a single sample\n\n\nploting_a_digit(random_line,final_pred) #ploting a random prediction\n\n","b09fa002":"model_1_pred = model_1.predict(final_test_set) #predicting values","015603a7":"#Fill label column on sample submission with our predictions\nsample_submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\",index_col='ImageId')\nsample_submission.Label = model_1_pred","d8165d8d":"#Output a csv to submit\nsample_submission.to_csv(\"model_1_predict.csv\")","cf6ea63c":"import tensorflow as tf\n\nmodel_2 = tf.keras.Sequential([\n    tf.keras.layers.Dense(200,activation='selu',input_shape = (X_train.shape[-1],)),\n    tf.keras.layers.Dense(100,activation = 'selu'),\n    tf.keras.layers.Dense(10,activation='softmax')\n])\n","122cfb6f":"model_2.compile(loss='categorical_crossentropy',\n                optimizer='Adam',\n                metrics=['acc']\n)","1cc00768":"model_2.summary()","2dc5a42d":"y_train=pd.get_dummies(y_train)\ny_train.head()","056db56e":"labels=pd.get_dummies(labels)\nlabels.head()","eb8f22ba":"history_2 = model_2.fit(train_set,labels,epochs=40,validation_split=0.1)","881e1153":"hist_pd= pd.DataFrame.from_dict(history_2.history)","c780706b":"hist_pd.loc[:,['acc']].plot()\nhist_pd.loc[:,['loss']].plot()\n","7634e308":"y_pred_2=model_2.predict(final_test_set)\nsalida = np.argmax(y_pred_2, axis=1)","1889eb48":"sample_submission_2 = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\",index_col='ImageId')\nsample_submission_2.Label = salida\n#Output a csv to submit\nsample_submission_2.to_csv(\"model_2_predict.csv\")","084731a7":"# **First Model**\nOur first model, as we said already, will be a random forest classifier. This will be a starting point for our solution.","9e811699":"**Our first model got a 96% of accuracy, pretty good for our first model, let's test some of our final_test data using random data.**","1f202f0d":"# Submission to digit recognizer\nWe'll predict on the test data and submit our results to the Digit Recognizer competition and see how good our model works","ff5d0dc7":"## ","fffccd53":"**As we can see, most of the predicted labels are correct, let's see if we can build a model using NN that improves model_1 performance**","7799f2ff":"Now we predict using our model and then measure how good it is working using accuracy_score","f1711673":"**With this simple NN we got a 98% accuracy, which is pretty good. Now we try some predictions**\nFirst, We have to predict and then get the number from the softmax prediction.\nAfter that, we fill our sample submission","b8292d50":"As our first approach we will use a random forest classifier to try to predict our value. But first, we should normalize our values. For that we'll use a min max scaler on both our train and our final test set.","4bf11c0b":"**Now we can test our function with random numbers (every time you run the next cell you get a random number and its plot)**","073301b0":"# Importing Data\nFirst we import our dataset from kaggle using pandas.read_csv and visualize the header.\nOur first feature is the label of the number, and the rest are the pixels that form the figure, with 0 being black and 254 being white. There are 784 pixels that form a figure of 28 x 28 px.","3e130825":"Now we split our train data using sklear tran_test_split so we can train our model and measure how good is working.","9abbc853":"**To better understand the problem we would like to visualize one of this figures so we need a function that can plot them.**"}}