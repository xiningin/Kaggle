{"cell_type":{"ee98390f":"code","12c61769":"code","750f38d6":"code","11c9c997":"code","ef5eca06":"code","13390716":"code","1b52c6c5":"code","19b715a3":"code","65f8b34d":"code","35b2a9a2":"code","cf5973ec":"code","1da04696":"code","e027a407":"code","0c3aabd9":"code","bc11b08e":"code","48ff83e7":"code","d6536870":"code","a4a38fdc":"code","e9a95ce4":"code","da3f3678":"code","2de01f37":"code","014bd5f5":"code","7ffebce7":"code","f2b9ddd1":"code","e0d87a03":"code","9edc72df":"code","8a924ea7":"markdown","d3de0e7d":"markdown","fa91f48d":"markdown","97b63035":"markdown","4512551f":"markdown","561a7dd9":"markdown","520b2031":"markdown","3259f619":"markdown","d0f5c20d":"markdown","5a7c4b35":"markdown","91ae356c":"markdown","e51bf97e":"markdown","43736ff2":"markdown","b7978244":"markdown","040dc77e":"markdown","3298947d":"markdown","37cf9d04":"markdown","25b5fcf8":"markdown","e7a215da":"markdown","cf093da8":"markdown","82d7681e":"markdown","2eaea272":"markdown","3ca26f5e":"markdown"},"source":{"ee98390f":"from tensorflow import keras as ks\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport time\nimport datetime\n\nfrom keras import models\nfrom tensorflow import keras as ks\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l2 ","12c61769":"num_classes=10","750f38d6":"# Creacion del modelo\nmodel = ks.Sequential()\n\nmodel.add(ks.layers.Conv2D(32, (3, 3),strides=1, input_shape=(32, 32,3), padding='same', activation='relu'))\nmodel.add(ks.layers.Conv2D(32, (3, 3),strides=1, activation='relu', padding='same'))\nmodel.add(ks.layers.Conv2D(32, (3, 3),strides=1, activation='relu', padding='valid'))\nmodel.add(ks.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(ks.layers.Dropout(0.2))\n\nmodel.add(ks.layers.Flatten())\nmodel.add(ks.layers.Dense(512, activation='relu'))\nmodel.add(ks.layers.Dropout(0.5))\nmodel.add(ks.layers.Dense(512, activation='relu'))\nmodel.add(ks.layers.Dropout(0.5))\nmodel.add(ks.layers.Dense(num_classes, activation='softmax'))","11c9c997":"model.summary()","ef5eca06":"model.compile(optimizer='Adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","13390716":"callback_val_loss = EarlyStopping(monitor=\"val_loss\", patience=10)\ncallback_val_accuracy = EarlyStopping(monitor=\"val_accuracy\", patience=10)","1b52c6c5":"cifar10 = ks.datasets.cifar10\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train, x_test = x_train \/ 255.0, x_test \/ 255.0","19b715a3":"cifar10_labels = [\n'airplane', # id 0\n'automobile',\n'bird',\n'cat',\n'deer',\n'dog',\n'frog',\n'horse',\n'ship',\n'truck',\n]\n\nprint('Number of labels: %s' % len(cifar10_labels))","65f8b34d":"# Pintemos una muestra de las las imagenes del dataset MNIST\n\nprint('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\nprint('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n\nfor i in range(9):\n\n    plt.subplot(330 + 1 + i)\n    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(cifar10_labels[y_train[i,0]])\n\nplt.subplots_adjust(hspace = 1)\nplt.show()","35b2a9a2":"x_val = x_train[-10000:]\ny_val = y_train[-10000:]\n\nx_train = x_train[:-10000]\ny_train = y_train[:-10000]","cf5973ec":"x_train_cnn = x_train.reshape((x_train.shape[0], 32, 32, 3))\nx_test_cnn = x_test.reshape((x_test.shape[0], 32, 32, 3))\nx_val_cnn = x_val.reshape((x_val.shape[0],32,32,3))\n\n# Validamos el resultado\nprint('Train: X=%s, y=%s' % (x_train_cnn.shape, y_train.shape))\nprint('Test: X=%s, y=%s' % (x_test_cnn.shape, y_test.shape))\nprint('Validation: X=%s, y=%s' % (x_val_cnn.shape, y_val.shape))","1da04696":"t = time.perf_counter()","e027a407":"history = model.fit(x_train_cnn, y_train, epochs=300, use_multiprocessing=False, \n                    batch_size= 512, validation_data=(x_val, y_val),\n                    callbacks=[callback_val_loss, callback_val_accuracy] )","0c3aabd9":"_, acc = model.evaluate(x_test, y_test, verbose=0)\nprint('> %.3f' % (acc * 100.0))","bc11b08e":"plt.title('Cross Entropy Loss')\nplt.plot(history.history['loss'], color='blue', label='train')\nplt.plot(history.history['val_loss'], color='orange', label='test')\nplt.show()\n\nplt.title('Classification Accuracy')\nplt.plot(history.history['accuracy'], color='blue', label='train')\nplt.plot(history.history['val_accuracy'], color='orange', label='test')\nplt.show()","48ff83e7":"layer_outputs = [layer.output for layer in model.layers[:4]] ","d6536870":"layer_outputs\n","a4a38fdc":"activation_model = models.Model(inputs=model.input, outputs=layer_outputs) ","e9a95ce4":"imagen= x_train_cnn[0,:,:,:]","da3f3678":"plt.imshow(imagen)","2de01f37":"img_tensor = np.expand_dims(imagen, axis=0)\nplt.imshow(img_tensor[0])\nplt.show()\nprint(img_tensor.shape)","014bd5f5":"activations = activation_model.predict( img_tensor)","7ffebce7":"fig = plt.figure( figsize=(16,16))\nfig.subplots_adjust(hspace=0.2, wspace=0.2)\nfor i in range(0, 32):\n    ax = fig.add_subplot(8, 4, i+1)\n    ax.imshow(activations[0][0, :, :, i], cmap=plt.get_cmap('viridis'))","f2b9ddd1":"fig = plt.figure( figsize=(16,16))\nfig.subplots_adjust(hspace=0.2, wspace=0.2)\nfor i in range(0, 32):\n    ax = fig.add_subplot(8, 4, i+1)\n    ax.imshow(activations[1][0, :, :, i], cmap=plt.get_cmap('viridis'))","e0d87a03":"fig = plt.figure( figsize=(16,16))\nfig.subplots_adjust(hspace=0.2, wspace=0.2)\nfor i in range(0, 32):\n    ax = fig.add_subplot(8, 4, i+1)\n    ax.imshow(activations[2][0, :, :, i], cmap=plt.get_cmap('viridis'))","9edc72df":"fig = plt.figure( figsize=(16,16))\nfig.subplots_adjust(hspace=0.2, wspace=0.2)\nfor i in range(0, 32):\n    ax = fig.add_subplot(8, 4, i+1)\n    ax.imshow(activations[3][0, :, :, i], cmap=plt.get_cmap('viridis'))","8a924ea7":"We set our test and validation dataset:","d3de0e7d":"# Images from the first convolucion","fa91f48d":"# Train the model","97b63035":"\nWe are keeping the first 4 initial outputs of the convolutions and max pooling","4512551f":"We are going to paint the 32 images resulting from the third convolution of the model.\nLook at the size of the image is reduced to 30x30","561a7dd9":"We set our callbacks:","520b2031":"# Images from the third convolucion","3259f619":"Creates a model that will return these outputs, given the model input. We copy it from internet.","d0f5c20d":"We are going to paint the 32 images resulting from the first Max pooling of the model.\nLook at the size of the image is reduced to 15x15 for the MAx Pooling filter.","5a7c4b35":"# Images from the second convolucion","91ae356c":"\n# We are going to paint the intermediate images generated in the convolutions","e51bf97e":"Now we can see the first image of the train dataset","43736ff2":"We set the model:","b7978244":"# Import libraries","040dc77e":"\nWe change the format to the image matrix so that it will be 4 dimensional","3298947d":"# Images from the Max Pooling","37cf9d04":"We are going to paint the 32 images resulting from the first convolution of the model\nLook at the size of the image is the same: 32x32 as the original.","25b5fcf8":"\nWe set the 4 dimensional format in our datasets that the model needs to train","e7a215da":"Returns a list of four Numpy arrays: one array per layer activation using the new model based in input\/ouput of the  first model.","cf093da8":"We are going to set the number of target's classes","82d7681e":"Load our Cifar10 dataset:\n","2eaea272":"\nThe model is bad but we are only interested in it for painting the intermediate images of the convolutions","3ca26f5e":"We are going to paint the 32 images resulting from the second convolution of the model.\nLook at the size of the image is the same: 32x32 as the original.\n"}}