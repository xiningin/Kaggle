{"cell_type":{"063da494":"code","49832ed3":"code","34883d7b":"code","96919a2c":"code","aac94b9c":"code","2edf1540":"code","437d79f8":"code","1d125cfa":"code","4f0ef256":"code","11ef1f18":"code","664e4e50":"code","33305934":"code","147f30f4":"code","d7838610":"code","cbaadf6f":"code","ec5da124":"code","68e1b09c":"code","5a1c2338":"code","f5016e2a":"code","9840000d":"code","a5163f5a":"code","759f4e8f":"code","6ae6d54b":"code","4d432d81":"code","4c261c34":"code","038396ca":"code","4b59bdc5":"code","c582d95f":"code","bebbec40":"code","01120519":"code","c02313f3":"code","6d33e40c":"code","f94751aa":"code","1290e19c":"code","47156ba9":"code","a9f3d445":"code","a1769ef3":"code","8264baae":"code","7c195f65":"code","10a4f063":"code","a376aef6":"code","c263bf45":"code","34393a19":"code","9c4c842f":"code","2568aac4":"code","a7f4707f":"code","04665da0":"code","24390bb6":"code","16d0897a":"code","6a0100c1":"code","efcf4ef2":"markdown","52ce835e":"markdown","16c9116e":"markdown","e47b4771":"markdown","dd560710":"markdown","957abee1":"markdown","0b285f6f":"markdown","133ba164":"markdown","fc7b18a3":"markdown"},"source":{"063da494":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","49832ed3":"#Importing Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport pylab as py\nimport warnings\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import mean_squared_error,r2_score,roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 500)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve, precision_score, recall_score, precision_recall_curve\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.filterwarnings('ignore')\nsns.set(style = 'white')","34883d7b":"train = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/jobathon-may-2021-credit-card-lead-prediction\/test.csv\")","96919a2c":"train.columns, test.columns","aac94b9c":"train.head(10)","2edf1540":"train.dtypes","437d79f8":"# As most of the features are categorical, check if test data has all categorical values same as train data.\n# If any column has new values then we should be careful using that feature in training directly..\n\ncount=0\nfor col in train.columns:\n    if col not in ['ID','Age','Vintage','Avg_Account_Balance','Is_Lead']:\n        for val in test[col].unique():\n            if val not in train[col].unique():\n                print(col,val)\n                count+=1","1d125cfa":"test_region_list=test['Region_Code'].tolist()","4f0ef256":"train=train[train['Region_Code'].isin(test_region_list)]","11ef1f18":"train.isnull().sum(), test.isnull().sum()","664e4e50":"# Lets check if data is uniformly distributed between train and test. Also,if there are any outliers or not.\ntrain.describe()","33305934":"test.describe()","147f30f4":"def UVA_outlier(data, var_group, include_outlier = True):\n  '''\n  Univariate_Analysis_outlier:\n  takes a group of variables (INTEGER and FLOAT) and plot\/print boplot and descriptives\\n\n  Runs a loop: calculate all the descriptives of i(th) variable and plot\/print it \\n\\n\n\n  data : dataframe from which to plot from\\n\n  var_group : {list} type Group of Continuous variables\\n\n  include_outlier : {bool} whether to include outliers or not, default = True\\n\n  '''\n\n  size = len(var_group)\n  plt.figure(figsize = (7*size,4), dpi = 100)\n  \n  #looping for each variable\n  for j,i in enumerate(var_group):\n    \n    # calculating descriptives of variable\n    quant25 = data[i].quantile(0.25)\n    quant75 = data[i].quantile(0.75)\n    IQR = quant75 - quant25\n    med = data[i].median()\n    whis_low = med-(1.5*IQR)\n    whis_high = med+(1.5*IQR)\n\n    # Calculating Number of Outliers\n    outlier_high = len(data[i][data[i]>whis_high])\n    outlier_low = len(data[i][data[i]<whis_low])\n\n    if include_outlier == True:\n      print(include_outlier)\n      #Plotting the variable with every information\n      plt.subplot(1,size,j+1)\n      sns.boxplot(data[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('With Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low\/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2),\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))\n      \n    else:\n      # replacing outliers with max\/min whisker\n      train = data[var_group][:]\n      train[i][train[i]>whis_high] = whis_high+1\n      train[i][train[i]<whis_low] = whis_low-1\n      \n      # plotting without outliers\n      plt.subplot(1,size,j+1)\n      sns.boxplot(train[i], orient=\"v\")\n      plt.ylabel('{}'.format(i))\n      plt.title('Without Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low\/high) = {} \\n'.format(\n                                                                                                   round(IQR,2),\n                                                                                                   round(med,2)\n                                                                                                   (round(quant25,2),round(quant75,2)),\n                                                                                                   (outlier_low,outlier_high)\n                                                                                                   ))  \n\n","d7838610":"num_cols = ['Age', 'Vintage','Avg_Account_Balance']","cbaadf6f":"UVA_outlier(train, num_cols)","ec5da124":"# There seems to be large no of outliers in variable \"Avg_Account_Balance\". Lets also check for outliers in test[\"Avr_Account_Balance\"]\ntest.boxplot(column = ['Avg_Account_Balance'])","68e1b09c":"#Bivariate Analysis\n#Continuius Continuous\nnumericals = train[['Age', 'Vintage','Avg_Account_Balance']]\ncorrelation = numericals.corr()\ncorrelation","5a1c2338":"plt.figure(figsize=(36,6), dpi=140)\nfor j,i in enumerate(['pearson','kendall','spearman']):\n  plt.subplot(1,3,j+1)\n  correlation = numericals.dropna().corr(method=i)\n  sns.heatmap(correlation, linewidth = 2)\n  plt.title(i, fontsize=18)","f5016e2a":"#BIVARIATE ANALYSIS: CONTINUOUS CATEGORICAL VARIABLES\n\n#List of Hypothesis and investigation to perform under this combination.  \n#1) Do age plays a significant role in deciding whether one will take creait card service or not?\n#2) Do duration of association of customers matter in activating credit card service?\n#3) Can avg account balance play a role in deciding whether customer will take credit card or not?\n  \ndef TwoSampZ(X1, X2, sigma1, sigma2, N1, N2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sampled Z-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import norm\n  ovr_sigma = sqrt(sigma1**2\/N1 + sigma2**2\/N2)\n  z = (X1 - X2)\/ovr_sigma\n  pval = 2*(1 - norm.cdf(abs(z)))\n  return pval\ndef TwoSampT(X1, X2, sd1, sd2, n1, n2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sample T-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import t as t_dist\n  ovr_sd = sqrt(sd1**2\/n1 + sd2**2\/n2)\n  t = (X1 - X2)\/ovr_sd\n  df = n1+n2-2\n  pval = 2*(1 - t_dist.cdf(abs(t),df))\n  return pval\n\ndef Bivariate_cont_cat(train, cont, cat, category):\n  #creating 2 samples\n  x1 = train[cont][train[cat]==category][:]\n  x2 = train[cont][~(train[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=train, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (15,6), dpi=140)\n  \n  #barplot\n  plt.subplot(1,2,1)\n  sns.barplot([str(category),'not {}'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # boxplot\n  plt.subplot(1,2,2)\n  sns.boxplot(x=cat, y=cont, data=train)\n  plt.title('categorical boxplot')","9840000d":"Bivariate_cont_cat(train, 'Age','Is_Lead', 1)","a5163f5a":"Bivariate_cont_cat(train, 'Vintage','Is_Lead', 1)","759f4e8f":"Bivariate_cont_cat(train, 'Avg_Account_Balance','Is_Lead', 1)","6ae6d54b":"##List of all the hypothesis:-\n#1 4) Do credit card issude or not depends on gender?\n#2) Is credit of any type leads to take credit card?\n#3) Do occupation of individuals plays an important role in deciding whether one will take credit card or not?\n#4) Do active customers have high frequency of taking credit card service?\n#5) Are acqistion channel an important source in deciding whether customer will take service or not?\n#6) Is region of customer an important factor in deciding the activation of service?\n#Bivariate : Categorical-Categorical\ndef BVA_categorical_plot(data, tar, cat):\n  '''\n  take data and two categorical variables,\n  calculates the chi2 significance between the two variables \n  and prints the result with countplot & CrossTab\n  '''\n  #isolating the variables\n  data = train[[cat,tar]][:]\n\n  #forming a crosstab\n  table = pd.crosstab(train[tar],train[cat],)\n  f_obs = np.array([table.iloc[0][:].values,\n                    table.iloc[1][:].values])\n\n  #performing chi2 test\n  from scipy.stats import chi2_contingency\n  chi, p, dof, expected = chi2_contingency(f_obs)\n  \n  #checking whether results are significant\n  if p<0.05:\n    sig = True\n  else:\n    sig = False\n\n  #plotting grouped plot\n  sns.countplot(x=cat, hue=tar, data= train)\n  plt.title(\"p-value = {}\\n difference significant? = {}\\n\".format(round(p,8),sig))\n\n  #plotting percent stacked bar plot\n  #sns.catplot(ax, kind='stacked')\n  ax1 = train.groupby(cat)[tar].value_counts(normalize=True).unstack()\n  ax1.plot(kind='bar', stacked='True',title=str(ax1))\n  int_level = train[cat].value_counts()\n  ","4d432d81":"BVA_categorical_plot(train, 'Gender', 'Is_Lead')","4c261c34":"BVA_categorical_plot(train, 'Region_Code', 'Is_Lead')","038396ca":"BVA_categorical_plot(train, 'Credit_Product', 'Is_Lead')","4b59bdc5":"BVA_categorical_plot(train, 'Is_Active', 'Is_Lead')","c582d95f":"BVA_categorical_plot(train, 'Channel_Code', 'Is_Lead')","bebbec40":"BVA_categorical_plot(train, 'Occupation', 'Is_Lead')","01120519":"# join both train and test data for preprocessing..\ntrain['train'] = 1\ntest['train'] = 0\n\ndf = pd.concat([train,test],axis=0).reset_index(drop=True)","c02313f3":"# check about the data type of each feature\ndf.info()","6d33e40c":"#check for missing values\ndf.isnull().sum()","f94751aa":"df['Credit_Product'].value_counts(normalize = True)","1290e19c":"# we have assigned a new category to the missing values of the credit_product because it might be that there association with bank might be of different nature?\ndf['Credit_Product'] = df['Credit_Product'].fillna('X')","47156ba9":"le = LabelEncoder()\nfor col in ['Region_Code']:\n    df[col]=  df[col].astype('str')\n    df[col]= le.fit_transform(df[col])\n       ","a9f3d445":"# Introduced dummy fot the nominal categorical varibales\ndf= pd.concat([df,pd.get_dummies(df['Gender'],prefix = str('Gender'),prefix_sep='_')],axis = 1)\ndf = pd.concat([df,pd.get_dummies(df['Occupation'],prefix = str('Occupation'),prefix_sep='_')],axis = 1)\ndf = pd.concat([df,pd.get_dummies(df['Channel_Code'],prefix = str('Channel_Code'),prefix_sep='_')],axis = 1)\ndf = pd.concat([df,pd.get_dummies(df['Credit_Product'],prefix = str('Credit_Product'),prefix_sep='_')],axis = 1)\ndf = pd.concat([df,pd.get_dummies(df['Is_Active'],prefix = str('Is_Active'),prefix_sep='_')],axis = 1)","a1769ef3":"df.drop(['Gender'], axis = 1, inplace = True)\ndf.drop(['Occupation'], axis = 1, inplace = True)\ndf.drop(['Channel_Code'], axis = 1, inplace = True)\ndf.drop(['Credit_Product'], axis =1 , inplace = True)\ndf.drop(['Is_Active'], axis =1 , inplace = True)","8264baae":"df.head()","7c195f65":"cat_features = ['Gender_Female','Gender_Male','Occupation_Entrepreneur','Occupation_Other','Occupation_Salaried','Occupation_Self_Employed','Channel_Code_X1','Channel_Code_X2','Channel_Code_X3','Channel_Code_X4','Credit_Product_No','Credit_Product_X','Credit_Product_Yes','Is_Active_No','Is_Active_Yes']","10a4f063":"seed = 0","a376aef6":"df.drop(['ID'], axis = 1, inplace = True)","c263bf45":"df.head()","34393a19":"cat_features = ['Gender_Female','Gender_Male','Occupation_Entrepreneur','Occupation_Other','Occupation_Salaried','Occupation_Self_Employed','Channel_Code_X1','Channel_Code_X2','Channel_Code_X3','Channel_Code_X4','Credit_Product_No','Credit_Product_X','Credit_Product_Yes','Is_Active_No','Is_Active_Yes']","9c4c842f":"#I have used LightGBM model for training the data. I have used stratified Kfold(10) as cross validation technique.\n\n\ndef train_lgbm(df,seed,cat_features):\n    X = df[df['train']==1]\n    y = df[df['train']==1]['Is_Lead']\n    test_data = df[df['train']==0]\n    num_split = 10\n    folds = StratifiedKFold(n_splits=num_split)\n    excluded_features = ['Is_Lead','train','ID']\n    train_features = [_f for _f in X.columns if _f not in excluded_features]\n    importances = pd.DataFrame()\n    oof_reg_preds = np.zeros(X.shape[0])\n    test_preds = np.zeros(test_data.shape[0])\n    for fold_, (trn_, val_) in enumerate(folds.split(X, y)):\n        print(\"Fold:\",fold_)\n        trn_x, trn_y = X[train_features].iloc[trn_], y.iloc[trn_]\n        val_x, val_y = X[train_features].iloc[val_], y.iloc[val_]\n        clf1 = LGBMClassifier(\n            n_jobs=-1,\n            learning_rate=0.0094,\n            n_estimators=10000,\n            colsample_bytree=0.94,\n            subsample = 0.75,\n            subsample_freq = 1,\n            reg_alpha= 1.0,\n            reg_lambda = 5.0,\n            random_state=seed\n        )\n        clf1.fit(\n            trn_x,trn_y ,\n            eval_set=[(val_x, val_y)],\n            early_stopping_rounds=100,\n            verbose=False,\n            eval_metric='auc',\n            categorical_feature = cat_features\n        )\n        \n        # Extra boosting.\n        clf = LGBMClassifier(\n            n_jobs=-1,\n            learning_rate=0.00094,\n            n_estimators=10000,\n            colsample_bytree=0.94,\n            subsample = 0.75,\n            subsample_freq = 1,\n            reg_alpha= 1.0,\n            reg_lambda = 5.0,\n            random_state=seed\n        )\n        clf.fit(\n            trn_x,trn_y ,\n            eval_set=[(val_x, val_y)],\n            early_stopping_rounds=300,\n            verbose=False,\n            eval_metric='auc',\n            categorical_feature = cat_features,\n            init_model = clf1\n        )\n        \n        imp_df = pd.DataFrame()\n        imp_df['feature'] = train_features\n        imp_df['importance'] = clf.booster_.feature_importance(importance_type='gain')\n\n        imp_df['fold'] = fold_ + 1\n        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n\n        oof_reg_preds[val_] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n        _preds = clf.predict_proba(test_data[train_features], num_iteration=clf.best_iteration_)[:, 1]\n        test_preds += _preds\n        print(\"fold\"+str(fold_)+\" auc\",roc_auc_score(val_y, oof_reg_preds[val_]))\n        del  trn_x, trn_y, val_x, val_y,trn_, val_\n        gc.collect()\n\n    test_preds = test_preds\/num_split\n    print(roc_auc_score(y, oof_reg_preds))\n    \n    return test_preds,importances,oof_reg_preds,clf,train_features","2568aac4":"# train the model by passing data, random seed as 42 and categorical feature list\nlgbm_preds,feat_imp_lgbm,oof_lgbm,lgbm_model,feats = train_lgbm(df,42,cat_features)","a7f4707f":"lgbm_preds1,feat_imp_lgbm1,oof_lgbm1,lgbm_model1,feats = train_lgbm(df,11,cat_features)","04665da0":"# Function to display feature importance...\ndef display_importances(feature_importance_df_,model):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:30].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(12, 8))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title(model+\" Features (avg over folds)\")\n    plt.tight_layout()\n    plt.savefig(model +\"_importances-01.png\")","24390bb6":"display_importances(feat_imp_lgbm,\"LGBM\")","16d0897a":"oof_ensemble = oof_lgbm*.50 + oof_lgbm1*.50\nroc_auc_score(df[df['train']==1]['Is_Lead'],oof_ensemble)","6a0100c1":"final_preds = lgbm_preds*.50 + lgbm_preds1*.50","efcf4ef2":"Data\n\n# Credit Card Lead Prediction\nHappy Customer Bank is a mid-sized private bank that deals in all kinds of banking products, like Savings accounts, Current accounts, investment products, credit products, among other offerings.The bank also cross-sells products to its existing customers and to do so they use different kinds of communication like tele-calling, e-mails, recommendations on net banking, mobile banking, etc. In this case, the Happy Customer Bank wants to cross sell its credit cards to its existing customers. The bank has identified a set of customers that are eligible for taking these credit cards. Now, the bank is looking for your help in identifying customers that could show higher intent towards a recommended credit card, given:\nCustomer details (gender, age, region etc.)\nDetails of his\/her relationship with the bank (Channel_Code,Vintage, 'Avg_Asset_Value etc.)\nData Dictionary\nTrain Data\nVariable           Definition\n\nID                Unique Identifier for a row\n\nGender            Gender of the Customer\n\nAge                Age of the Customer (in Years)\n\nRegion_Code        Code of the Region for the customers\n\nOccupatio           Occupation Type for the customer\n\nChannel_Code        Acquisition Channel Code for the Customer  (Encoded)\n\nVintag              Vintage for the Customer (In Months)\n\nCredit_Product       If the Customer has any active credit product (Home loan,\n                       Personal loan, Credit Card etc.)\n\nAvg_Account_Balance   Average Account Balance for the Customer in last 12 Months\n\nIs_Active             If the Customer is Active in last 3 Months\n\nIs_Lead(Target)       Customer is interested for the Credit Card 0:Customer is not interested 1:Customer is   interested\n\n\nTest Dat              \n\nVariable                   Definition\n\nID                   Unique Identifier for a row\n\nGender\n                     Gender of the Customer\n\nAge\n                     Age of the Customer (in Years)\n\nRegion_Code          Code of the Region for the customers\n\nOccupatio            Occupation Type for the customer\n\nChannel_Code         Acquisition Channel Code for the Customer  (Encoded)\n\nVintage              Vintage for the Customer (In Months)\n\nCredit_Product       If the Customer has any active credit product (Home loan,Personal loan, Credit Card etc.)\n\nAvg_Account_Balance  Average Account Balance for the Customer in last 12 Months\n\nIs_Active            If the Customer is Active in last 3 Months","52ce835e":"# List Of Hypothesis:\n1) Do age plays a significant role in deciding whether one will take creait card service or not?\n2) Do duration of association of customers matter in activating credit card service?\n3) Can avg account balance play a role in deciding whether customer will take credit card or not?\n4) Do credit card issude or not depends on gender?\n5) Is credit of any type leads to take credit card?\n6) Do occupation of individuals plays an important role in deciding whether one will take credit card or not?\n7) Do active customers have high frequency of taking credit card service?\n8) Are acqistion channel an important source in deciding whether customer will take service or not?\n9) Is region of customer an important factor in deciding the activation of service?","16c9116e":"#Here we can see that the variables like 'ID', 'Gender', 'Region_Code', 'Occupation', 'Channel_Code' are object type datatype. This means python in not able to recognise the data type of these variables. So, we will have to find their right data type and assign them a new data type.","e47b4771":"Avg_Account_Balacne of customers also plays an important role in deciding whether customer will avail the service of credit card or not.","dd560710":"# we can see that both test train variable avg_account_balance has outliers on the right hand side.","957abee1":"Duration of association plays an important role in deciding whether a customer will take or not take credit card.","0b285f6f":"We can see for all the categorical variables  each categorical category are statistically significant i.e. each category decides whether credit card will be issued or not","133ba164":"There seems to be significant difference between the age of person who are interested or not interested for credit card.\n","fc7b18a3":"# There seems to be no high correlation betweem continuous variables."}}