{"cell_type":{"55a3fec4":"code","679555d3":"code","1175883c":"code","e1b6f88d":"code","fdb5ebaa":"code","bc217714":"code","94f077b1":"code","160e7e2b":"code","19c30f4f":"code","a0db08ec":"code","5187d3ed":"code","032a44fa":"code","25ce4284":"code","bb9979ce":"code","a2be1833":"code","85cb2e2f":"code","e861172e":"code","9aa6217e":"code","e95866c9":"code","4061a495":"code","c0999140":"code","ae6a7557":"code","8d1bacfd":"code","0f7f3ca9":"code","cf142794":"code","fe1c5149":"code","6ed2e5d7":"code","7ff78904":"code","5a07ed46":"code","87cb24bb":"code","f9a9e5d6":"code","9ea39883":"code","57e1c5c8":"code","ec935dc3":"code","80e37686":"code","dd2c8a5f":"code","b3c04500":"code","0d861020":"code","f4e4bf15":"code","3f3bd203":"code","6619b3b6":"code","ce095df5":"code","0a022f36":"code","c9d669df":"code","9e536604":"code","01dcb83e":"code","d8847ebb":"code","ad47992d":"code","5f452160":"code","159e4633":"code","fbc221f5":"code","38cce586":"code","a0c0def4":"code","cf545ce7":"code","24eb8823":"code","be31363f":"code","d7c36d51":"code","05332e17":"code","b553257f":"code","1154f5a4":"code","e616f6c3":"code","f9031e01":"code","fa2341c2":"code","089174ae":"code","6c50a4a4":"code","84c0e656":"code","844bffc7":"code","f9a85a08":"code","d11d319f":"code","94afb0f9":"code","89b51e35":"code","1f4894b2":"code","4cce363d":"code","3c7351a0":"code","bbec2c6c":"code","9bcfacec":"code","f847d232":"code","cf168c21":"code","6e2e137b":"code","1f5df8a7":"code","d0195e21":"code","fe948bb2":"code","dcd9711f":"code","91d397ba":"code","8f4500cf":"code","a7810ccc":"code","41431b5e":"code","06e8b457":"code","40550845":"code","850a47f2":"code","a8467289":"code","fd8ce3c4":"code","97b926c0":"code","e947576f":"code","2a60b716":"code","e1c15d4c":"code","e29a0c35":"code","9c7968c3":"code","45b58ef4":"code","a0d6df2b":"code","f378aca0":"code","669f76af":"markdown","f9d5edb5":"markdown","0d32e1a2":"markdown","a2dc269d":"markdown","84ae60cd":"markdown","0c82b00b":"markdown","1a975e94":"markdown","5171d470":"markdown","161985c4":"markdown","d6572635":"markdown","7623fa04":"markdown","f059c3bb":"markdown","5f8d05f9":"markdown","5073f96b":"markdown","18ab6626":"markdown","c184efc4":"markdown","855d7812":"markdown","8d802ebf":"markdown","1bd21723":"markdown","ffa144c8":"markdown","6a140bae":"markdown","c05c600a":"markdown","3715b5b1":"markdown","41261780":"markdown","0938a7d8":"markdown","9de34a88":"markdown","970d6285":"markdown","ca8471ca":"markdown","95caca02":"markdown","d750ef0f":"markdown","26253545":"markdown","676ec9cb":"markdown","b41299b8":"markdown","1c1711a3":"markdown","aa1e1b8b":"markdown","dcd7a293":"markdown","8c7cfb84":"markdown","7457d0fe":"markdown","1ecb094f":"markdown","77f2c55c":"markdown","c073f5fa":"markdown","27086a9d":"markdown","b0c99073":"markdown","db3eccf6":"markdown","31af363f":"markdown","eab612ca":"markdown","e300d015":"markdown","4579f0fc":"markdown","c6cc94c4":"markdown"},"source":{"55a3fec4":"!pip install image-classifiers","679555d3":"import random, os, glob\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report,accuracy_score\nimport h5py\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import Image\n","1175883c":"train_path = '\/kaggle\/input\/fruit-resized-dataset\/Resized Data\/train'\nvalid_path = '\/kaggle\/input\/fruit-resized-dataset\/Resized Data\/valid'\ntest_path =  '\/kaggle\/input\/fruit-resized-dataset\/Resized Data\/test'\nbackground_path =  '\/kaggle\/input\/nobackground-fruit\/NoBackground-Data'","e1b6f88d":"labels = os.listdir(train_path)\nlabels.sort()\nprint(labels)","fdb5ebaa":"def getAllLabelObservations(array, labels, paths):\n    for path in paths:\n        for name in labels:\n            dir = os.path.join(path, name)\n            current_label = name\n            for count, filename in enumerate(os.listdir(dir)):\n                array.append(current_label)\n    print('Get all label observations complete')\n    return array","bc217714":"paths = [train_path, valid_path, test_path]\nlabel_observations = []\nlabel_observations = getAllLabelObservations(label_observations, labels, paths)\nplt.figure(figsize=(12,6))\nplt.hist(label_observations, bins=12, alpha = 0.5, align='mid')","94f077b1":"def get_random_fruit_image(label = None):\n    if label == None:\n        fruit_class = np.random.choice(list(labels), size=1)[0]\n    else:\n        fruit_class = label\n    chosen_path = np.random.choice(paths, size = 1)[0]\n    fruit_class_path = os.path.join(chosen_path, fruit_class)\n    image_names = os.listdir(fruit_class_path)\n    image_name = np.random.choice(image_names, size=1)[0]\n    image_path = os.path.join(fruit_class_path, image_name)\n    image = cv2.imread(image_path)\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    return image, fruit_class","160e7e2b":"fig, axs = plt.subplots(2, 3, figsize=(12, 12))\nfig.suptitle('M\u00f4\u0323t s\u00f4\u0301 a\u0309nh trong t\u00e2\u0323p d\u01b0\u0303 li\u00ea\u0323u', fontsize=14)\ntmp = 0\nfor ax in axs:\n    if tmp == 0:\n        loai = 'Tuoi'\n        tmp = 1\n    else:\n        loai = 'Hu'\n        tmp = 0\n    image, fruit_class = get_random_fruit_image(label='ChomChom_{}'.format(loai))\n    ax[0].set_title(f'Fruit class: {fruit_class}')\n    ax[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    \n    image, fruit_class = get_random_fruit_image(label='Chuoi_{}'.format(loai))\n    ax[1].set_title(f'Fruit class: {fruit_class}')\n    ax[1].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    \n    image, fruit_class = get_random_fruit_image(label='Quyt_{}'.format(loai))\n    ax[2].set_title(f'Fruit class: {fruit_class}')\n    ax[2].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","19c30f4f":"bins = 8\ndef fd_hu_moments(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n    return feature\n\ndef fd_histogram(image, mask=None):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n    cv2.normalize(hist, hist)\n    return hist.flatten()\n\n\ndef fd_kaze(image):\n    vector_size = 32\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    alg = cv2.KAZE_create()\n    kps = alg.detect(image)\n    kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n    kps, dsc = alg.compute(image, kps)\n    dsc = dsc.flatten()\n    needed_size = (vector_size * 64)\n    if dsc.size < needed_size:\n        dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n    return dsc\n\n\ndef fd_canny(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    edges = cv2.Canny(image,300,300)\n    return edges.flatten()\n\n\ndef Feature_extraction(x, y, img, labels, path):\n    for name in labels:\n        dir = os.path.join(path, name)\n        current_label = name\n        print (dir)\n        for count, filename in enumerate(os.listdir(dir)):\n            file = dir + \"\/\" +  filename \n            image = cv2.imread(file)\n            image = cv2.resize(image, (300,300))\n            fv_histogram  = fd_histogram(image)\n            fv_hu_moments = fd_hu_moments(image)\n            #fv_kaze = fd_kaze(image)\n            #fv_canny = fd_canny(image)\n            feature = np.hstack([fv_histogram, fv_hu_moments])\n            y.append(current_label)\n            x.append(feature)\n            img.append(file)\n    print('Feature extraction complete')\n    return x, y, img","a0db08ec":"y_train = []\nx_train = []\nimg_train = []\nx_train, y_train, img_train = Feature_extraction(x_train, y_train, img_train, labels, train_path)","5187d3ed":"y_valid = []\nx_valid = []\nimg_valid = []\nx_valid, y_valid, img_valid = Feature_extraction(x_valid, y_valid, img_valid, labels, valid_path)","032a44fa":"y_test = []\nx_test = []\nimg_test = []\nx_test, y_test, img_test = Feature_extraction(x_test, y_test, img_test, labels, test_path)","25ce4284":"y_background = []\nx_background = []\nimg_background = []\nx_background, y_background, img_background = Feature_extraction(x_background, y_background, img_background, labels, background_path)","bb9979ce":"print(np.array(x_train).shape)\nprint(np.array(x_valid).shape)\nprint(np.array(x_test).shape)\nprint(np.array(x_background).shape)","a2be1833":"plt.hist(y_train, bins = 12)","85cb2e2f":"plt.hist(y_valid, bins = 12)","e861172e":"plt.hist(y_test, bins = 12)","9aa6217e":"train_dis = x_train.copy()\ntrain_dis = np.array(train_dis)\ntrain_dis = train_dis[1000:1600,:]\ntrain_isvalid = np.zeros((len(train_dis),1))\nprint(len(train_dis))\nvalid_dis = x_valid.copy()\nvalid_dis = np.array(valid_dis)\nvalid_isvalid = np.ones((len(valid_dis),1))\nprint(len(valid_dis))\ndis = np.vstack((train_dis, valid_dis))\nisvalid = np.vstack((train_isvalid, valid_isvalid))\nprint(dis.shape)\nprint(isvalid.shape)","e95866c9":"plt.hist(train_dis)","4061a495":"plt.hist(valid_dis)","c0999140":"X_isvalid, X_isvalid_test, y_isvalid, y_isvalid_test = train_test_split(dis, isvalid, test_size=0.5, random_state=10, shuffle = True)","ae6a7557":"plt.hist(y_isvalid_test)","8d1bacfd":"rf = RandomForestClassifier(n_jobs=-1, n_estimators=100, oob_score=True, min_samples_leaf=3, max_features=0.5)\nrf.fit(X_isvalid, y_isvalid)\nprint('oob_score: {}'.format(rf.oob_score_))\ndis_pred = rf.predict(X_isvalid_test)\nprint(classification_report(y_isvalid_test, dis_pred))\n","0f7f3ca9":"plt.hist(dis_pred)","cf142794":"svm_C_list = [0.1, 1, 10, 100]\nsvm_C_train = []\nsvm_C_valid = []\nsvm_C_test = []\nfor c in svm_C_list:\n    clf = svm.SVC(kernel='linear',C=c)\n    clf.fit(x_train,y_train)\n    y_pred = clf.predict(x_train)\n    svm_C_train.append(classification_report(y_train, y_pred, output_dict = True)['accuracy'])\n    y_pred = clf.predict(x_valid)\n    svm_C_valid.append(classification_report(y_valid, y_pred, output_dict = True)['accuracy'])\n    y_pred = clf.predict(x_test)\n    svm_C_test.append(classification_report(y_test, y_pred, output_dict = True)['accuracy'])","fe1c5149":"plt.title('Tuning C Parameter SVM')\nplt.scatter(svm_C_list, svm_C_train, label = 'train')\nplt.scatter(svm_C_list, svm_C_valid, label = 'valid')\nplt.scatter(svm_C_list, svm_C_test, label = 'test')\nplt.legend()\nplt.show()","6ed2e5d7":"rf_estimator_list = [40, 60, 80, 100, 120, 140, 160, 180, 200]\nrf_estimator_train = []\nrf_estimator_valid = []\nrf_estimator_test = []\nfor e in rf_estimator_list:\n    model = RandomForestClassifier(n_jobs=-1, n_estimators=e)\n    model.fit(x_train,y_train)\n    y_pred = model.predict(x_train)\n    rf_estimator_train.append(classification_report(y_train, y_pred, output_dict = True)['accuracy'])\n    y_pred = model.predict(x_valid)\n    rf_estimator_valid.append(classification_report(y_valid, y_pred, output_dict = True)['accuracy'])\n    y_pred = model.predict(x_test)\n    rf_estimator_test.append(classification_report(y_test, y_pred, output_dict = True)['accuracy'])","7ff78904":"plt.title('Tuning Estimator Parameter Random Forest')\nplt.scatter(rf_estimator_list, rf_estimator_train, label = 'train')\nplt.scatter(rf_estimator_list, rf_estimator_valid, label = 'valid')\nplt.scatter(rf_estimator_list, rf_estimator_test, label = 'test')\nplt.legend()\nplt.show()","5a07ed46":"lr_C_list = [0.1, 1, 10, 100, 1000]\nlr_C_train = []\nlr_C_valid = []\nlr_C_test = []\nfor c in lr_C_list:\n    clf = LogisticRegression(C=c, max_iter=10000)\n    clf.fit(x_train,y_train)\n    y_pred = clf.predict(x_train)\n    lr_C_train.append(classification_report(y_train, y_pred, output_dict = True)['accuracy'])\n    y_pred = clf.predict(x_valid)\n    lr_C_valid.append(classification_report(y_valid, y_pred, output_dict = True)['accuracy'])\n    y_pred = clf.predict(x_test)\n    lr_C_test.append(classification_report(y_test, y_pred, output_dict = True)['accuracy'])","87cb24bb":"plt.title('Tuning C Parameter Logistic Regression')\nplt.scatter(lr_C_list, lr_C_train, label = 'train')\nplt.scatter(lr_C_list, lr_C_valid, label = 'valid')\nplt.scatter(lr_C_list, lr_C_test, label = 'test')\nplt.legend()\nplt.show()","f9a9e5d6":"from classification_models.tfkeras import Classifiers\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Dropout,SeparableConv2D,BatchNormalization, Activation, Dense\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2\nfrom tensorflow.keras.optimizers import Adam","9ea39883":"ResNet18, preprocess_input = Classifiers.get('resnet18')","57e1c5c8":"num_class = 6\n\n# Base model without Fully connected Layers\nbase_model = ResNet18(include_top=False, weights='imagenet', input_shape=(300,300,3))\nx=base_model.output\n# Add some new Fully connected layers to \nx=GlobalAveragePooling2D()(x)\n#x=Dense(1024,activation='relu')(x)\n#x = Dropout(0.25)(x)\n#x=Dense(512,activation='relu')(x) \n#x = Dropout(0.25)(x)\npreds=Dense(num_class, activation='softmax')(x)\n\nmodel=Model(inputs=base_model.input,outputs=preds)","ec935dc3":"model.summary()","80e37686":"for i,layer in enumerate(model.layers):\n  print(\"{}: {} is train {}\".format(i,layer,layer.trainable))","dd2c8a5f":"for layer in model.layers[:190]:\n    layer.trainable=False\nfor layer in model.layers[190:]:\n    layer.trainable=True","b3c04500":"train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,\n                                 horizontal_flip=True,\n                                 vertical_flip=True,\n                                 rotation_range=360,\n                                 width_shift_range=0.2,\n                                 height_shift_range=0.2,\n                                 shear_range=0.2,\n                                 zoom_range=[0.8,1.2],\n                                 brightness_range=[0.8,1.2])\n\ntrain_generator=train_datagen.flow_from_directory('\/kaggle\/input\/fruit-resized-dataset\/Resized Data\/train\/',\n                                                 target_size=(300,300),\n                                                 batch_size=64,\n                                                 class_mode='categorical')\n\n\nvalidation_generator = train_datagen.flow_from_directory(\n                                                '\/kaggle\/input\/fruit-resized-dataset\/Resized Data\/valid\/', \n                                                target_size=(300,300),\n                                                batch_size=64,\n                                                class_mode='categorical') ","0d861020":"epochs = 50\nlearning_rate = 0.0001\ndecay_rate = learning_rate \/ epochs\nopt = Adam(lr=learning_rate)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])","f4e4bf15":"from tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import TensorBoard\n\n!mkdir ckpt\n!mkdir logs\n\nfilepath=\"logs\/fruit_resnet18_multiclass.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only = False, save_best_only=True, mode='min')\nlogdir=\"logs\/mobilenet\"\ntfboard = TensorBoard(log_dir=logdir)\n\ncallbacks_list = [checkpoint, tfboard]","3f3bd203":"\"\"\"step_size_train = train_generator.n\/\/train_generator.batch_size\nstep_size_val = validation_generator.samples \/\/ validation_generator.batch_size\nhistory = model.fit_generator(generator=train_generator,\n                              steps_per_epoch=100,\n                              validation_data = validation_generator, \n                              validation_steps =step_size_val,\n                              callbacks = callbacks_list,\n                              epochs=epochs,\n                              initial_epoch=0,\n                              verbose = 1)\n\"\"\"","6619b3b6":"inf_model = keras.models.load_model(r\"\/kaggle\/input\/fruit-resnet18-multiclass\/fruit_resnet18_multiclass.hdf5\")\n","ce095df5":"inf_model.summary()","0a022f36":"def preprocess_image(img):\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if (img.shape[0] != 300 or img.shape[1] != 300):\n            img = cv2.resize(img, (300, 300), interpolation=cv2.INTER_NEAREST)\n        img = (img\/127.5)\n        img = img - 1\n        img = np.expand_dims(img, axis=0)\n        return img","c9d669df":"def predictImage(y, label, path):\n    for name in label:\n            dir = os.path.join(path, name)\n            current_label = name\n            print ('{} is on LIT!!!!!'.format(dir))\n            for count, filename in enumerate(os.listdir(dir)):\n                file = dir + \"\/\" +  filename \n                #image = cv2.imread(file)\n                image = keras.preprocessing.image.load_img(file, target_size=(300, 300))\n                array = keras.preprocessing.image.img_to_array(image)\n                array = np.expand_dims(array, axis=0)\n                pred = inf_model.predict(preprocess_input(array))\n                result = labels[np.argmax(pred)]\n                y.append(result)\n    print('Predicting Completed: {}'.format(path))\n    return y","9e536604":"resnet_train_pred = []\nresnet_train_pred = predictImage(resnet_train_pred, labels, train_path)\nresnet_valid_pred = []\nresnet_valid_pred = predictImage(resnet_valid_pred, labels, valid_path)\nresnet_test_pred = []\nresnet_test_pred = predictImage(resnet_test_pred, labels, test_path)","01dcb83e":"print('F1 score on train set')\nprint(classification_report(y_train, resnet_train_pred))","d8847ebb":"print('F1 score on valid set')\nprint(classification_report(y_valid, resnet_valid_pred))","ad47992d":"print('F1 score on test set')\nprint(classification_report(y_test, resnet_test_pred))","5f452160":"clf = svm.SVC(kernel='linear',C=10)\nclf.fit(x_train,y_train)\nsvm_train_pred = clf.predict(x_train)\nprint(classification_report(y_train, svm_train_pred))\nsvm_valid_pred = clf.predict(x_valid)\nprint(classification_report(y_valid, svm_valid_pred))\nsvm_test_pred = clf.predict(x_test)\nprint(classification_report(y_test, svm_test_pred))","159e4633":"target='ChomChom_Hu'\ncondition1 = np.array(y_test)==target\ncondition2 = np.array(svm_test_pred) != target\nsvm_test_pred = np.array(svm_test_pred)\nresult = svm_test_pred[condition1 & condition2]\nprint(len(result))\nplt.hist(result)","fbc221f5":"img_valid = np.array(img_test)\nlist_img_wrong = img_valid[condition1 & condition2]\nlist_feature_wrong = np.array(x_test)[condition1 & condition2]\nfig, axs = plt.subplots(3, 2, figsize=(12, 12))\nfig.suptitle('False Negative ChomChom_Hu', fontsize=14)\ntmp = 1\nfor ax in axs:\n    image1 = cv2.imread(list_img_wrong[tmp])\n    ax[0].set_title('Ch\u00f4m Ch\u00f4m H\u01b0')\n    ax[0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n    \n    chosen = list_feature_wrong[tmp]\n    ax[1].set_title('\u0110\u0103\u0323c tr\u01b0ng')\n    interval = range(1,520)\n    ax[1].plot(interval, chosen)\n    \n    \n    tmp += 1\n    \n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","38cce586":"target='ChomChom_Hu'\ncondition3 = np.array(y_test)==target\ncondition4 = np.array(svm_test_pred) == target\nimg_valid = np.array(img_test)\nlist_img_wrong = img_valid[condition3 & condition4]\nlist_feature_wrong = np.array(x_test)[condition3 & condition4]\nfig, axs = plt.subplots(3, 2, figsize=(12, 12))\nfig.suptitle('M\u00f4\u0323t s\u00f4\u0301 a\u0309nh ch\u00f4m ch\u00f4m h\u01b0 trong t\u00e2\u0323p d\u01b0\u0303 li\u00ea\u0323u', fontsize=14)\ntmp = 4\nfor ax in axs:\n    image1 = cv2.imread(list_img_wrong[tmp])\n    ax[0].set_title('Ch\u00f4m Ch\u00f4m H\u01b0')\n    ax[0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n    \n    chosen = list_feature_wrong[tmp]\n    ax[1].set_title('\u0110\u0103\u0323c tr\u01b0ng')\n    interval = range(1,520)\n    ax[1].plot(interval, chosen)\n    \n    tmp += 1\n    \n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","a0c0def4":"target='Quyt_Tuoi'\ncondition5 = np.array(y_test)!=target\ncondition6 = np.array(svm_test_pred) == target\ny_test = np.array(y_test)\nresult = y_test[condition5 & condition6]\nprint(len(result))\nplt.hist(result)\nimg_valid = np.array(img_test)\nlist_img_wrong = img_valid[condition5 & condition6]\nlist_feature_wrong = np.array(x_test)[condition5 & condition6]\nfig, axs = plt.subplots(3, 2, figsize=(12, 12))\nfig.suptitle('False Postive Quyt_Tuoi', fontsize=14)\ntmp = 0\nfor ax in axs:\n    image1 = cv2.imread(list_img_wrong[tmp])\n    ax[0].set_title('Ch\u00f4m ch\u00f4m H\u01b0')\n    ax[0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n    \n    chosen = list_feature_wrong[tmp]\n    ax[1].set_title('\u0110\u0103\u0323c tr\u01b0ng')\n    interval = range(1,520)\n    ax[1].plot(interval, chosen)\n    tmp += 1\n    \n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","cf545ce7":"target='Quyt_Tuoi'\ncondition7 = np.array(y_test)==target\ncondition8 = np.array(svm_test_pred) == target\nimg_valid = np.array(img_test)\nlist_img_wrong = img_valid[condition7 & condition8]\nlist_feature_wrong = np.array(x_test)[condition7 & condition8]\nfig, axs = plt.subplots(3, 2, figsize=(12, 12))\nfig.suptitle('M\u00f4\u0323t s\u00f4\u0301 a\u0309nh quy\u0301t t\u01b0\u01a1i trong t\u00e2\u0323p d\u01b0\u0303 li\u00ea\u0323u', fontsize=14)\ntmp = 2\nfor ax in axs:\n    image1 = cv2.imread(list_img_wrong[tmp])\n    ax[0].set_title('Quy\u0301t T\u01b0\u01a1i')\n    ax[0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n    \n    chosen = list_feature_wrong[tmp]\n    ax[1].set_title('\u0110\u0103\u0323c tr\u01b0ng')\n    interval = range(1,520)\n    ax[1].plot(interval, chosen)\n\n    tmp += 1\n    \n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","24eb8823":"def get_img_array(img_path, size):\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    array = keras.preprocessing.image.img_to_array(img)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n    last_conv_layer = model.get_layer(last_conv_layer_name)\n    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n\n    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n    x = classifier_input\n    for layer_name in classifier_layer_names:\n        x = model.get_layer(layer_name)(x)\n    classifier_model = keras.Model(classifier_input, x)\n\n    with tf.GradientTape() as tape:\n        last_conv_layer_output = last_conv_layer_model(img_array)\n        tape.watch(last_conv_layer_output)\n        preds = classifier_model(last_conv_layer_output)\n        \n        top_pred_index = tf.argmax(preds[0])\n        top_class_channel = preds[:, top_pred_index]\n    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n    pooled_grads = pooled_grads.numpy()\n    for i in range(pooled_grads.shape[-1]):\n        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n\n    heatmap = np.mean(last_conv_layer_output, axis=-1)\n\n    heatmap = np.maximum(heatmap, 0) \/ np.max(heatmap)\n    return heatmap","be31363f":"img_size = (300,300)\nlast_conv_layer_name = \"relu1\"\nclassifier_layer_names = [\"global_average_pooling2d\", \"dense\"]","d7c36d51":"def generate_gradcam(img, heatmap):\n    img = keras.preprocessing.image.img_to_array(img)\n\n    heatmap = np.uint8(255 * heatmap)\n\n    jet = cm.get_cmap(\"jet\")\n\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap.save('heatmap.jpg')\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    superimposed_img = jet_heatmap * 0.4 + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n    return superimposed_img","05332e17":"fig, axs = plt.subplots(4, 3, figsize=(12, 12))\nfig.suptitle('Visualizing with Grad-CAM', fontsize=20)\nfor ax in axs:\n    image, fruit_class = get_random_fruit_image(label='Chuoi_Hu')\n    ax[0].set_title(f'Fruit class: {fruit_class}')\n    ax[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    \n    image = cv2.resize(image, (300,300))\n    array = keras.preprocessing.image.img_to_array(image)\n    array = np.expand_dims(array, axis=0)\n    img_array = preprocess_input(array)\n    heatmap = make_gradcam_heatmap(img_array, inf_model, last_conv_layer_name, classifier_layer_names)\n    ax[1].set_title(f'Fruit class: {fruit_class} with HeatMap')\n    ax[1].matshow(heatmap)\n    \n    superimposed_img = generate_gradcam(image, heatmap)\n    ax[2].set_title(f'Fruit class: {fruit_class} with Grad-CAM')\n    ax[2].imshow(superimposed_img)\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","b553257f":"def Laytruoc_(s):\n    tmp=0\n    for i in range(len(s)):\n        if (s[i] == '_'): tmp=i\n    \n    kq = s[0:tmp]\n    return kq","1154f5a4":"def GetObservationsModel1(array, labels, paths):\n    for path in paths:\n        for name in labels:\n            dir = os.path.join(path, name)\n            current_label = Laytruoc_(name)\n            for count, filename in enumerate(os.listdir(dir)):\n                array.append(current_label)\n    print('Get all label observations complete')\n    return array","e616f6c3":"paths = [train_path, valid_path, test_path]\nlabel_observations = []\nlabel_observations = GetObservationsModel1(label_observations, labels, paths)\nplt.figure(figsize=(7,5))\nplt.hist(label_observations, bins=5, alpha = 0.5, align='mid')","f9031e01":"def Laysau_(s):\n    tmp=0\n    for i in range(len(s)):\n        if (s[i] == '_'): tmp=i\n    \n    kq = s[tmp+1:]\n    return kq","fa2341c2":"def GetObservationsModel2(array, labels, paths):\n    for path in paths:\n        for name in labels:\n            dir = os.path.join(path, name)\n            current_label = Laysau_(name)\n            for count, filename in enumerate(os.listdir(dir)):\n                array.append(current_label)\n    print('Get all label observations complete')\n    return array","089174ae":"paths = [train_path, valid_path, test_path]\nlabel_observations = []\nlabel_observations = GetObservationsModel2(label_observations, labels, paths)\nplt.figure(figsize=(5,4))\nplt.hist(label_observations, bins=3, alpha = 0.5, align='mid')\n","6c50a4a4":"bins = 8\ndef fd_hu_moments(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n    return feature\n\ndef fd_histogram(image, mask=None):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n    cv2.normalize(hist, hist)\n    return hist.flatten()\n\ndef Extraction_model1(x, y, img, labels, path):\n    for name in labels:\n        dir = os.path.join(path, name)\n        current_label = Laytruoc_(name)\n        print (path + str('\/') + current_label)\n        for count, filename in enumerate(os.listdir(dir)):\n            file = dir + \"\/\" +  filename \n            image = cv2.imread(file)\n            image = cv2.resize(image, (300,300))\n            fv_histogram  = fd_histogram(image)\n            fv_hu_moments = fd_hu_moments(image)\n            feature = np.hstack([fv_hu_moments, fv_histogram])\n            y.append(current_label)\n            x.append(feature)\n            img.append(file)\n    print('Feature extraction complete')\n    return x, y, img","84c0e656":"y1_train = []\nx1_train = []\nimg1_train = []\nx1_train, y1_train, img1_train = Extraction_model1(x1_train, y1_train, img1_train, labels, train_path)","844bffc7":"y1_valid = []\nx1_valid = []\nimg1_valid = []\nx1_valid, y1_valid, img1_valid = Extraction_model1(x1_valid, y1_valid, img1_valid, labels, valid_path)","f9a85a08":"y1_test = []\nx1_test = []\nimg1_test = []\nx1_test, y1_test, img1_test = Extraction_model1(x1_test, y1_test, img1_test, labels, test_path)","d11d319f":"bins = 8\ndef fd_hu_moments(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n    return feature\n\ndef fd_histogram(image, mask=None):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n    cv2.normalize(hist, hist)\n    return hist.flatten()\n\ndef Extraction_model2(x, y, img, labels, path):\n    for name in labels:\n        dir = os.path.join(path, name)\n        current_label = Laysau_(name)\n        print (path + str('\/') + current_label)\n        for count, filename in enumerate(os.listdir(dir)):\n            file = dir + \"\/\" +  filename \n            image = cv2.imread(file)\n            image = cv2.resize(image, (300,300))\n            fv_histogram  = fd_histogram(image)\n            fv_hu_moments = fd_hu_moments(image)\n            feature = np.hstack([fv_histogram])\n            y.append(current_label)\n            x.append(feature)\n            img.append(file)\n    print('Feature extraction complete')\n    return x, y, img","94afb0f9":"y2_train = []\nx2_train = []\nimg2_train = []\nx2_train, y2_train, img2_train = Extraction_model2(x2_train, y2_train, img2_train, labels, train_path)","89b51e35":"y2_valid = []\nx2_valid = []\nimg2_valid = []\nx2_valid, y2_valid, img2_valid = Extraction_model2(x2_valid, y2_valid, img2_valid, labels, valid_path)","1f4894b2":"y2_test = []\nx2_test = []\nimg2_test = []\nx2_test, y2_test, img2_test = Extraction_model2(x2_test, y2_test, img2_test, labels, test_path)","4cce363d":"xtrain_model2  = x2_train.copy()\nxtrain_model2 = np.c_[y1_train,xtrain_model2]\n","3c7351a0":"print(np.array(xtrain_model2).shape)\n","bbec2c6c":"xtrain_model2 = pd.DataFrame(data=xtrain_model2)","9bcfacec":"categorical = [0]\n","f847d232":"xtrain_model2 = pd.get_dummies(xtrain_model2, columns= categorical, drop_first=True)\n","cf168c21":"xtrain_model2.head(10).transpose()\n","6e2e137b":"plt.hist(y1_train, bins = 5)","1f5df8a7":"plt.hist(y1_valid, bins = 5)","d0195e21":"plt.hist(y1_test, bins = 5)\n","fe948bb2":"plt.hist(y2_train, bins = 3)\n","dcd9711f":"plt.hist(y2_valid, bins = 3)\n","91d397ba":"plt.hist(y2_test, bins = 3)\n","8f4500cf":"svm_C_train = []\nsvm_C_valid = []\nsvm_C_test = []\ny1train_predict = []\ny1valid_predict = []\ny1test_predict = []\nfor c in svm_C_list:\n    clf = svm.SVC(kernel='linear',C=c)\n    clf.fit(x1_train,y1_train)\n    y_pred = clf.predict(x1_train)\n    y1train_predict.append(y_pred)\n    svm_C_train.append(classification_report(y1_train, y_pred, output_dict = True)['accuracy'])\n    y_pred = clf.predict(x1_valid)\n    y1valid_predict.append(y_pred)\n    svm_C_valid.append(classification_report(y1_valid, y_pred, output_dict = True)['accuracy'])\n    y_pred = clf.predict(x1_test)\n    y1test_predict.append(y_pred)\n    svm_C_test.append(classification_report(y1_test, y_pred, output_dict = True)['accuracy'])","a7810ccc":"plt.title('Tuning C Parameter SVM')\nplt.scatter(svm_C_list, svm_C_train, label = 'train')\nplt.scatter(svm_C_list, svm_C_valid, label = 'valid')\nplt.scatter(svm_C_list, svm_C_test, label = 'test')\nplt.legend()\nplt.show()","41431b5e":"def Preprocess(x, y1):\n    x = np.c_[y1,x]\n    x= pd.DataFrame(data=x)\n    categorical = [0]\n    x = pd.get_dummies(x, columns= categorical, drop_first=True)\n    return x","06e8b457":"svm_C_list = [0.1, 1, 10, 100]\nsvm_C_train = []\nsvm_C_valid = []\nsvm_C_test = []\n# c model1 = 100\ntmp = 3\nfor c in svm_C_list:\n    clf = svm.SVC(kernel='linear',C=c)\n    clf.fit(xtrain_model2,y2_train)\n    # Predict train\n    x2_train_copy = x2_train.copy()\n    x2_train_copy = Preprocess(x2_train_copy,y1train_predict[tmp])\n    y_pred = clf.predict(x2_train_copy)\n    svm_C_train.append(classification_report(y2_train, y_pred, output_dict = True)['accuracy'])\n    # Predict valid\n    x2_valid_copy = x2_valid.copy()\n    x2_valid_copy = Preprocess(x2_valid_copy,y1valid_predict[tmp])\n    y_pred = clf.predict(x2_valid_copy)\n    svm_C_valid.append(classification_report(y2_valid, y_pred, output_dict = True)['accuracy'])\n    # Predict test\n    x2_test_copy = x2_test.copy()\n    x2_test_copy = Preprocess(x2_test_copy,y1test_predict[tmp])\n    y_pred = clf.predict(x2_test_copy)\n    svm_C_test.append(classification_report(y2_test, y_pred, output_dict = True)['accuracy'])","40550845":"plt.title('Tuning C Parameter SVM')\nplt.scatter(svm_C_list, svm_C_train, label = 'train')\nplt.scatter(svm_C_list, svm_C_valid, label = 'valid')\nplt.scatter(svm_C_list, svm_C_test, label = 'test')\nplt.legend()\nplt.show()","850a47f2":"rf_estimator_list = [40, 60, 80, 100, 120, 140, 160, 180, 200]\nrf_estimator_train = []\nrf_estimator_valid = []\nrf_estimator_test = []\ny1train_predict = []\ny1valid_predict = []\ny1test_predict = []\nfor e in rf_estimator_list:\n    model = RandomForestClassifier(n_jobs=-1, n_estimators=e)\n    model.fit(x1_train,y1_train)\n    y_pred = model.predict(x1_train)\n    y1train_predict.append(y_pred)\n    rf_estimator_train.append(classification_report(y1_train, y_pred, output_dict = True)['accuracy'])\n    y_pred = model.predict(x1_valid)\n    y1valid_predict.append(y_pred)\n    rf_estimator_valid.append(classification_report(y1_valid, y_pred, output_dict = True)['accuracy'])\n    y_pred = model.predict(x1_test)\n    y1test_predict.append(y_pred)\n    rf_estimator_test.append(classification_report(y1_test, y_pred, output_dict = True)['accuracy'])","a8467289":"plt.title('Tuning Estimator Parameter Random Forest')\nplt.scatter(rf_estimator_list, rf_estimator_train, label = 'train')\nplt.scatter(rf_estimator_list, rf_estimator_valid, label = 'valid')\nplt.scatter(rf_estimator_list, rf_estimator_test, label = 'test')\nplt.legend()\nplt.show()","fd8ce3c4":"rf_estimator_list = [40, 60, 80, 100, 120, 140, 160, 180, 200]\nrf_estimator_train = []\nrf_estimator_valid = []\nrf_estimator_test = []\n# n_estimators = 60\ntmp = 1\nfor e in rf_estimator_list:\n    model = RandomForestClassifier(n_jobs=-1, n_estimators=e)\n    model.fit(xtrain_model2,y2_train)\n    # Predict train\n    x2_train_copy = x2_train.copy()\n    x2_train_copy = Preprocess(x2_train_copy,y1train_predict[tmp])\n    y_pred = model.predict(x2_train_copy)\n    rf_estimator_train.append(classification_report(y2_train, y_pred, output_dict = True)['accuracy'])\n    # Predict valid\n    x2_valid_copy = x2_valid.copy()\n    x2_valid_copy = Preprocess(x2_valid_copy,y1valid_predict[tmp])\n    y_pred = model.predict(x2_valid_copy)\n    rf_estimator_valid.append(classification_report(y2_valid, y_pred, output_dict = True)['accuracy'])\n    # Predict test\n    x2_test_copy = x2_test.copy()\n    x2_test_copy = Preprocess(x2_test_copy,y1test_predict[tmp])\n    y_pred = model.predict(x2_test_copy) \n    rf_estimator_test.append(classification_report(y2_test, y_pred, output_dict = True)['accuracy'])","97b926c0":"plt.title('Tuning Estimator Parameter Random Forest')\nplt.scatter(rf_estimator_list, rf_estimator_train, label = 'train')\nplt.scatter(rf_estimator_list, rf_estimator_valid, label = 'valid')\nplt.scatter(rf_estimator_list, rf_estimator_test, label = 'test')\nplt.legend()\nplt.show()","e947576f":"lr_C_list = [0.1, 1, 10, 100, 1000]\nlr_C_train = []\nlr_C_valid = []\nlr_C_test = []\ny1train_predict = []\ny1valid_predict = []\ny1test_predict = []\nfor c in lr_C_list:\n    clf = LogisticRegression(C=c, max_iter=10000)\n    clf.fit(x1_train,y1_train)\n    y_pred = clf.predict(x1_train)\n    y1train_predict.append(y_pred)\n    lr_C_train.append(classification_report(y1_train, y_pred, output_dict = True)['accuracy'])\n    y_pred = clf.predict(x1_valid)\n    y1valid_predict.append(y_pred)\n    lr_C_valid.append(classification_report(y1_valid, y_pred, output_dict = True)['accuracy'])\n    y_pred = clf.predict(x1_test)\n    y1test_predict.append(y_pred)\n    lr_C_test.append(classification_report(y1_test, y_pred, output_dict = True)['accuracy'])","2a60b716":"plt.title('Tuning C Parameter Logistic Regression')\nplt.scatter(lr_C_list, lr_C_train, label = 'train')\nplt.scatter(lr_C_list, lr_C_valid, label = 'valid')\nplt.scatter(lr_C_list, lr_C_test, label = 'test')\nplt.legend()\nplt.show()","e1c15d4c":"lr_C_list = [0.1, 1, 10, 100, 1000]\nlr_C_train = []\nlr_C_valid = []\nlr_C_test = []\n# C=10\ntmp = 2\nfor c in lr_C_list:\n    clf = LogisticRegression(C=c, max_iter=10000)\n    clf.fit(xtrain_model2,y2_train)\n    # Predict train\n    x2_train_copy = x2_train.copy()\n    x2_train_copy = Preprocess(x2_train_copy,y1train_predict[tmp])\n    y_pred = clf.predict(x2_train_copy)\n    lr_C_train.append(classification_report(y2_train, y_pred, output_dict = True)['accuracy'])\n    # Predict valid\n    x2_valid_copy = x2_valid.copy()\n    x2_valid_copy = Preprocess(x2_valid_copy,y1valid_predict[tmp])\n    y_pred = clf.predict(x2_valid_copy)\n    lr_C_valid.append(classification_report(y2_valid, y_pred, output_dict = True)['accuracy'])\n    # Predict test\n    x2_test_copy = x2_test.copy()\n    x2_test_copy = Preprocess(x2_test_copy,y1test_predict[tmp])\n    y_pred = clf.predict(x2_test_copy)\n    lr_C_test.append(classification_report(y2_test, y_pred, output_dict = True)['accuracy'])","e29a0c35":"plt.title('Tuning C Parameter Logistic Regression')\nplt.scatter(lr_C_list, lr_C_train, label = 'train')\nplt.scatter(lr_C_list, lr_C_valid, label = 'valid')\nplt.scatter(lr_C_list, lr_C_test, label = 'test')\nplt.legend()\nplt.show()","9c7968c3":"lr_C_list = [0.1, 1, 10, 100, 1000]\nlr_C_train = []\nlr_C_valid = []\nlr_C_test = []\n# C=10\ntmp = 4\nfor c in lr_C_list:\n    clf = LogisticRegression(C=c, max_iter=10000)\n    clf.fit(xtrain_model2,y2_train)\n    # Predict train\n    x2_train_copy = x2_train.copy()\n    x2_train_copy = Preprocess(x2_train_copy,y1train_predict[tmp])\n    y_pred = clf.predict(x2_train_copy)\n    lr_C_train.append(classification_report(y2_train, y_pred, output_dict = True)['accuracy'])\n    # Predict valid\n    x2_valid_copy = x2_valid.copy()\n    x2_valid_copy = Preprocess(x2_valid_copy,y1valid_predict[tmp])\n    y_pred = clf.predict(x2_valid_copy)\n    lr_C_valid.append(classification_report(y2_valid, y_pred, output_dict = True)['accuracy'])\n    # Predict test\n    x2_test_copy = x2_test.copy()\n    x2_test_copy = Preprocess(x2_test_copy,y1test_predict[tmp])\n    y_pred = clf.predict(x2_test_copy)\n    lr_C_test.append(classification_report(y2_test, y_pred, output_dict = True)['accuracy'])","45b58ef4":"plt.title('Tuning C Parameter Logistic Regression')\nplt.scatter(lr_C_list, lr_C_train, label = 'train')\nplt.scatter(lr_C_list, lr_C_valid, label = 'valid')\nplt.scatter(lr_C_list, lr_C_test, label = 'test')\nplt.legend()\nplt.show()","a0d6df2b":"clf = LogisticRegression(C=10, max_iter=10000)\nclf.fit(x1_train,y1_train)\ny_train_pred = clf.predict(x1_train)\nprint(classification_report(y1_train, y_train_pred))\ny_valid_pred = clf.predict(x1_valid)\nprint(classification_report(y1_valid, y_valid_pred))\ny_test_pred = clf.predict(x1_test)\nprint(classification_report(y1_test, y_test_pred))\n","f378aca0":"clf = LogisticRegression(C=10, max_iter=10000)\nclf.fit(xtrain_model2,y2_train)\n# Predict train\nx2_train_copy = x2_train.copy()\nx2_train_copy = Preprocess(x2_train_copy,y_train_pred)\ny_pred = clf.predict(x2_train_copy)\nprint(classification_report(y2_train, y_pred))\n# Predict valid\nx2_valid_copy = x2_valid.copy()\nx2_valid_copy = Preprocess(x2_valid_copy,y_valid_pred)\ny_pred = clf.predict(x2_valid_copy)\nprint(classification_report(y2_valid, y_pred))\n# Predict test\nx2_test_copy = x2_test.copy()\nx2_test_copy = Preprocess(x2_test_copy,y_test_pred)\ny_pred = clf.predict(x2_test_copy)\nprint(classification_report(y2_test, y_pred))","669f76af":"# 1c. Dependent Variable","f9d5edb5":"# 2a. Support Vector Machine","0d32e1a2":"# 1. Import Library and Initialize Dataset Path","a2dc269d":"# i. Model 1 : CLassify kinds of fruits","84ae60cd":"# i. Model 1 : CLassify kinds of fruits","0c82b00b":"C \u1edf model 1 = 1000\u00b6\n","1a975e94":"# ii. Independent Variable","5171d470":"Trong qu\u00e1 tr\u00ecnh tham quan v\u01b0\u1eddn tr\u00e1i c\u00e2y \u0111\u00ea\u0309 thu nh\u00e2\u0323p d\u01b0\u0303 li\u00ea\u0323u. Nh\u00f3m nh\u1eadn th\u1ea5y \u0111\u01b0\u1ee3c l\u00e0 nh\u1eefng tr\u00e1i h\u01b0 th\u01b0\u1eddng s\u1ebd t\u1ef1 r\u01a1i xu\u1ed1ng \u0111\u1ea5t ho\u1eb7c trong qu\u00e1 tr\u00ecnh h\u00e1i ch\u1ee7 v\u01b0\u1eddn c\u1eaft b\u1ecf \u0111i v\u00e0 nh\u1eefng tr\u00e1i b\u00ecnh th\u01b0\u1eddng s\u1ebd \u0111\u01b0\u1ee3c ch\u1ee7 v\u01b0\u1eddn ch\u1ecdn l\u1ecdc t\u01b0\u0300 chi\u0301nh tr\u00ean c\u00e2y v\u00e0 \u0111\u01b0\u1ee3c b\u00e1n cho c\u00e1c ti\u1ec3u th\u01b0\u01a1ng va\u0300 \u0111a\u0323i th\u01b0\u01a1ng \u0111\u1ebfn mua. T\u1ee9c l\u00e0 khi \u0111\u1ebfn si\u00eau th\u1ecb nh\u1eefng tr\u00e1i c\u00e2y kh\u00f4ng \u0111\u1ea1t ti\u00eau chu\u1ea9n l\u00e0 do m\u00f4\u0323t trong hai ly\u0301 do sau \u0111\u00e2y:\n* Do qu\u00e1 tr\u00ecnh v\u1eadn chuy\u1ec3n qu\u00e1 l\u00e2u khi\u00ea\u0301n qu\u1ea3 qu\u00e1 th\u1eddi gian ch\u00edn d\u1eabn \u0111\u1ebfn th\u1ed1i r\u1eeda.\n* Trong qu\u00e1 tr\u00ecnh v\u1eadn chuy\u1ec3n b\u1ecb va ch\u1ea1m m\u1ea1nh d\u1eabn \u0111\u1ebfn n\u1ee9t qu\u1ea3.","161985c4":"# ii. Model 2 : CLassify spoiled fruits","d6572635":"# i. Model 1 : CLassify kinds of fruits","7623fa04":"# ii. Model 2 : CLassify spoiled fruits","f059c3bb":"# Onehot encoding","5f8d05f9":"# ii. Model 2 : CLassify spoiled fruits","5073f96b":"# 2. Explotary Data Analysis","18ab6626":"# Multi Task Approach","c184efc4":"# 5. Interpreting with Grad-Cam","855d7812":"# 1a. Overall","8d802ebf":"# 2a. Overall","1bd21723":"# 3c. Logistic Regression","ffa144c8":"# 1. Explotary Data Analysis","6a140bae":"C \u1edf model 1 = 10\n","c05c600a":"**Dataset g\u00f4\u0300m 6 class c\u00e2\u0300n \u0111\u01b0\u01a1\u0323c ph\u00e2n loa\u0323i.**","3715b5b1":"# 3a. Support Vector Machine","41261780":"# i. Model 1 : CLassify kinds of fruits","0938a7d8":"# 2c. Distribution Checking","9de34a88":"# 3b. Random Forest","970d6285":"# ii. inference model","ca8471ca":"**\u0110\u00f4\u0300ng th\u01a1\u0300i, nho\u0301m cu\u0303ng \u0111a\u0303 chia s\u0103\u0303n 6 loa\u0323i theo ti\u0309 l\u00ea\u0323 7 : 2 : 1 t\u01b0\u01a1ng \u01b0\u0301ng train : valid : test ra 3 folder ri\u00eang.**","95caca02":"**M\u00f4 hi\u0300nh \u0111a\u0323t accuracy cao nh\u00e2\u0301t multi task - Logistic Regression v\u01a1\u0301i C = 10**","d750ef0f":"T\u01b0\u0300 ca\u0301c \u0111\u0103\u0323c \u0111i\u00ea\u0309m tr\u00ean, nho\u0301m nh\u00e2\u0323n ra co\u0301 th\u00ea\u0309 s\u01b0\u0309 du\u0323ng hai ph\u01b0\u01a1ng pha\u0301p sau \u0111\u00ea\u0309 tri\u0301ch xu\u00e2\u0301t \u0111\u0103\u0323c tr\u01b0ng t\u01b0\u0300 ca\u0301c a\u0309nh:\n* Histogram: d\u00f9ng \u0111\u1ec3 t\u00ednh to\u00e1n x\u00e1c su\u1ea5t c\u1ee7a c\u00e1c gi\u00e1 tr\u1ecb nh\u1ea5t \u0111\u1ecbnh v\u00e0 t\u1eeb \u0111\u00f3 t\u00ecm \u0111\u01b0\u1ee3c s\u1ef1 ph\u00e2n b\u1ed1 m\u00e0u s\u00e1c trong h\u00ecnh \u0111\u1ec3 l\u1ea5y ra \u0111\u1eb7c tr\u01b0ng m\u00e0u s\u1eafc c\u1ee7a m\u1ed7i lo\u1ea1i tr\u00e1i c\u00e2y  va\u0300 ca\u0309 h\u01b0 hay kh\u00f4ng h\u01b0.\n* Hu moment: d\u00f9ng \u0111\u1ec3 l\u1ea5y ra \u0111\u1eb7c tr\u01b0ng h\u00ecnh d\u1ea1ng c\u1ee7a tr\u00e1i c\u00e2y trong h\u00ecnh, ngay c\u1ea3 khi \u1ea3nh c\u00f3 thay \u0111\u1ed5i k\u00edch th\u01b0\u1edbc.","26253545":"# i. Training model","676ec9cb":"# i. Dependent Variable","b41299b8":"# Model 2 : CLassify spoiled fruits","1c1711a3":"# 2) Modeling","aa1e1b8b":"# 2b. Random Forest","dcd7a293":"Th\u00eam c\u1ed9t v\u00e0o model 2\n","8c7cfb84":"# 3d. Resnet18","7457d0fe":"# ii. Model 2 : CLassify spoiled fruits","1ecb094f":"# 3. Modeling Models","77f2c55c":"**T\u01b0\u0300 \u0111\u00e2y, ta co\u0301 t\u00f4\u0309ng c\u00f4\u0323ng 519 \u0111\u0103\u0323c tr\u01b0ng \u0111\u01b0\u01a1\u0323c tri\u0301ch xu\u00e2\u0301t t\u01b0\u0300 a\u0309nh.**","c073f5fa":"# 4. Error Analysis","27086a9d":"# i. Model 1 : CLassify kinds of fruits","b0c99073":"# Model 1: CLassify kinds of fruits","db3eccf6":"# 2b. Feature Extraction - Machine Learning Approach","31af363f":"# ii. Model 2 : CLassify spoiled fruits","eab612ca":"**Ga\u0301n th\u00eam m\u00f4\u0323t bi\u00ea\u0301n m\u01a1\u0301i isValid v\u01a1\u0301i gia\u0301 tri\u0323 = 0 \u01a1\u0309 t\u00e2\u0323p train va\u0300 = 1 \u01a1\u0309 t\u00e2\u0323p valid. Mu\u0323c \u0111i\u0301ch \u0111\u00ea\u0309 ki\u00ea\u0309m tra xem li\u00ea\u0323u co\u0301 \u0111\u0103\u0323c tr\u01b0ng (feature) na\u0300o ma\u0300 m\u00f4 hi\u0300nh d\u01b0\u0323a va\u0300o \u0111\u00ea\u0309 nh\u00e2\u0323n ra s\u01b0\u0323 kha\u0301c bi\u00ea\u0323t cu\u0309a ca\u0301c \u0111\u0103\u0323c tr\u01b0ng gi\u01b0\u0303a ca\u0301c t\u00e2\u0323p hay kh\u00f4ng?. N\u00ea\u0301u m\u00f4 hi\u0300nh cho ra \u0111\u00f4\u0323 chi\u0301nh xa\u0301c cao tuy\u00ea\u0323t \u0111\u00f4\u0301i t\u01b0\u0301c t\u00f4\u0300n ta\u0323i ca\u0301c \u0111\u0103\u0323c tr\u01b0ng giu\u0301p m\u00f4 hi\u0300nh co\u0301 th\u00ea\u0309 ph\u00e2n bi\u00ea\u0323t ca\u0301c t\u00e2\u0323p.**","e300d015":"# 1b. Feature Extraction - Machine Learning Approach","4579f0fc":"Model SVM cho ra k\u00ea\u0301t qua\u0309 t\u00f4\u0301t nh\u00e2\u0301t v\u01a1\u0301i C = 10.","c6cc94c4":"# 2c. Logistic Regressio"}}