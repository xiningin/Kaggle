{"cell_type":{"1e99b324":"code","b9eff283":"code","8de2cedd":"code","ec275c5e":"code","9ac5e35b":"code","7639ed65":"code","a3494d97":"code","6b6b67eb":"code","39f9bdfe":"code","fff9e1b8":"code","c76400ce":"code","da44995e":"code","627bac23":"code","7cb6af79":"code","c639c681":"code","90355c49":"code","ff889044":"code","5518aed5":"code","d4aae7f3":"code","258242b3":"code","bd87ddd2":"code","48fba35a":"code","dadeb401":"code","6afcb656":"code","f415e676":"code","96b1dda8":"code","d1247043":"code","c5fec5f9":"code","d7f9b957":"code","bbb23076":"code","05c794e8":"code","52a4a731":"code","1b0fd9f3":"code","e8bd721b":"code","e5640076":"code","77d2d266":"code","2640bd6e":"code","284372cf":"code","b324241c":"code","34b7bc56":"code","a6068ace":"code","733a5fc1":"markdown","f1171430":"markdown"},"source":{"1e99b324":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV","b9eff283":"# Bundesliga - Data Frame\nbul = pd.read_csv(r\"..\/input\/football-data\/form-bundesliga.csv\")","8de2cedd":"# set the team names as index\nbul.set_index(\"Team\", inplace=True)","ec275c5e":"# bul is a Data Frame which includes the team name as index, the season from 2015\/16 to 2019\/20, the number of matches played \n# during that season and the result of a particular match day (W : Win, L : Loss, D : Drawn)\n\nbul","9ac5e35b":"bul.columns","7639ed65":"# function to \"translate\" the letters for wins, losses and draws(W, L, D) into points\n\ndef points(x):\n    if x == \"W\":\n        return 3\n    elif x == \"L\":\n        return 0\n    else: \n        return 1","a3494d97":"# apply the function from above at the given data of every team per match day\n# save the result as a list of lists: points per matchday and team in \"team\"-list and the collection of the \"team\"-list\n# in the list \"teams\"\n\nteams=[]\nteam=[]\n\nfor seas in bul[\"Season\"].unique():\n    for tm in bul[bul[\"Season\"] == seas].index:\n        for columns in bul.columns[2:]:\n            points(bul[bul[\"Season\"] == seas].loc[tm][columns])\n            team.append(points(bul[bul[\"Season\"] == seas].loc[tm][columns]))\n        teams.append(team)\n        team=[]","6b6b67eb":"# build a list of \"P\" plus a number symbolizing the number of points a team collected on particular match day number\n\nP_col=[]\nfor i in range(1,35):\n    P_col.append(\"P\"+str(i))\nP_col\n\n# creating a new Data Frame: overview of the number of points a team collected on a particular match day\n\nPoints_On_MatchDay = pd.DataFrame(data=teams, columns=P_col, index=bul.index)\nPoints_On_MatchDay","39f9bdfe":"# connecting the two Data Frames \"points\" and \"bul\"\n\nbul = pd.concat(objs=[bul, Points_On_MatchDay], axis=1)","fff9e1b8":"# creating a new Data Frame \"MatchDay_Points\" using only the points columns (\"P1\", \"P2\", \"P3\"...\"P33\") of the \"bul\" - Data Frame \nMatchDay_Points = bul[P_col]\n\n# calculating the cumulative sum from column to column: \n# adding the sum of the points of all previous matchdays to the points of the current match day\nMatchDay_Points = MatchDay_Points.cumsum(axis=1)    \n\n# rename the Data Frame column names in \"CS + number of the current match day\" representing the cumulative sum of the \n# collected points on that match day \nfor i,j in enumerate(MatchDay_Points.columns):\n    MatchDay_Points.rename(columns={j:\"CS\"+str(i+1)}, inplace=True)\n\n# adding the sumulative sum - columns of the Data Frame \"MatchDay_Points\" to the main data frame \"bul\"\nbul = pd.concat(objs=[bul, MatchDay_Points], axis=1)","c76400ce":"bul","da44995e":"# all_leagues is a Data Frame which includes general information of the seasons 2015\/16 - 2019\/20 from four international leagues\nall_leagues = pd.read_csv(r\"..\/input\/football-data\/all-leaguetables.csv\")","627bac23":"# using only the general information of the German Bundesliga and saving it in a new data frame\n# set index to \"Team\", like it is set in the \"bul\" - data frame \n\ngen_info_buli = all_leagues[all_leagues[\"League\"]==\"Bundesliga\"]\ngen_info_buli.set_index(\"Team\", inplace=True)\ngen_info_buli","7cb6af79":"# creating a new data frame \"b\" for Bundesliga by merging the original data frames gen_info_buli and bul on the columns\n# \"Team\" and \"Season\"\n\nb = gen_info_buli.merge(bul, on=[\"Season\", \"Team\"], how=\"left\")","c639c681":"# resetting the index of the new data frame on ascending numbers instead of the column \"Team\"\nb.reset_index(inplace=True)","90355c49":"# using the heatmap of seaborn to find missing values\n\nplt.figure(figsize=(15,10))\nsns.heatmap(b.isna())","ff889044":"# the heatmap above shows that if the first information of the column \"Match1\" is missing, it is also missing for \n# the following  columns\n# I decided to drop the whole row if the information in \"Match1\" isn\u00b4t present\n\nlist_of_rows_with_mv=[]\n\nfor row_index in range(0, len(b)):\n    if b.iloc[row_index][\"Match1\"] not in [\"W\", \"L\", \"D\"]:\n        list_of_rows_with_mv.append(row_index)\n        \nb.drop(list_of_rows_with_mv, axis=\"index\", inplace=True)","5518aed5":"# update the index\nb.reset_index(inplace=True)","d4aae7f3":"# any missing data left?\n\nplt.figure(figsize=(15,10))\nsns.heatmap(b.isna())","258242b3":"# converting the type of the \"Position\" - column values into integers\nb[\"Position\"] = b[\"Position\"].apply(lambda x: int(x[:-1]))","bd87ddd2":"# creating a list of the columns of the data frame and removing the \"Position\" - column from that list\ncols=[]\nfor column in b.columns:\n    cols.append(column)\ncols.remove(\"Position\")\n\n# deleting all the columns of the Bundesliga - data frame that I don\u00b4t need\n# only the cumsum columns and the position column should be left\nfor column in cols[0:81]:\n    b.drop(column, axis=1, inplace=True)","48fba35a":"b.columns","dadeb401":"# how visible is the correlation between the cumulative sum of points a team collected until a \n# particular match day and its final position? \n# from which match day is the correlation visible?\n# I showed that correlation exemplary for the the cumsum of the 8th, 20th, 30th and 34th match day\n# it\u00b4s not surprising that the correlation is better visible the longer the season has progressed \n# but a tendency is visible already on match day 8\n\nfor cumsum in [\"CS8\", \"CS20\", \"CS30\", \"CS34\"]:\n    \n    cumsums_on_matchday = []   # list of cumumaltive sum per team on match day 8, 20, 30, 34\n    final_pos = []             # list of the final positions \n\n    for row_nr in range(0, len(b)):\n        cumsums_on_matchday.append(b[cumsum][row_nr])\n\n    for pos in range(0, len(b)):\n        final_pos.append(b[\"Position\"][pos])\n        \n    plt.figure(figsize=(5,5))\n    plt.ylim(0,19)\n    plt.yticks(list(range(0,19)))\n    plt.xlabel(\"Points on Match Day \" + cumsum[2:])\n    plt.ylabel(\"Final Position\")\n    plt.scatter(cumsums_on_matchday, final_pos)\n    ","6afcb656":"# for the prediction of the final position I first tried the Linear Regression\n# as independent value I tried only one cumsum column in each round of a for loop\n# again I used the cumsum of points of the 8th, 20th, 30th and the last match day\n\n# at the end I calculated the standard error for the prediction of the final points for every independent value\n# it\u00b4s not surprising that the model is better the closer we got to the end of the season\n\n\nlr = LinearRegression()\nCS_testsize_stderr = [0]\nall_par = []\n\nfor CS in [\"CS8\", \"CS20\", \"CS30\", \"CS34\"]:\n        \n        x = b[CS]\n        x = x.values.reshape(-1,1)\n        y = b[\"Position\"]\n\n        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n\n        lr.fit(xtrain, ytrain)\n\n        pred = lr.predict(xtest)\n        \n        CS_testsize_stderr[0] = round((ytest-pred).std(),1)\n        \n        all_par.append(CS_testsize_stderr)\n        CS_testsize_stderr = [0]\n        \nlr_one = pd.DataFrame(data = all_par, columns= [\"standard error\"], index=[\"CS8\", \"CS20\", \"CS30\", \"CS34\"])   \nprint (\"Linear Regression: Prediction of End Position out of Points after one specific Match Day \", \"\\n\", \"\\n\",\n       lr_one)  ","f415e676":"# now I tried to improve the model by using Ridge Regression\n# first I tried to find out which alpha parameter would be the best by using the GridSearch module\n\nfor CS in [\"CS8\", \"CS20\", \"CS30\", \"CS34\"]:\n    \n    x = b[CS]\n    x = x.values.reshape(-1,1)\n    y = b[\"Position\"]\n    \n    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n\n    grid = GridSearchCV(Ridge(), param_grid = {'alpha': [1e-1000, 1e-500, 1e-300, 1e-200, 1e-100, 1e-50, 1e-30, \n                                                         1e-25, 1e-20, 1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1,5,10,20,30,\n                                                         35,40,45,50,55,100,150, 200,300,\n                                                         500,800,1000]}, verbose=0)\n    grid.fit(xtrain,ytrain)\n    print(CS, \" : \", grid.best_params_)","96b1dda8":"# for most of the independent values I tried (cumsum after match day 8, 20, 30, 34) a Ridge parameter of alpha = 1e-500 \n# (which is very close to 0) seems to be the best\n# (I also tried alpha = 55 with nearly no effect on the standard error at the end)\n\n# now I trained a Ridge Regression model\n# the standard error data frame below shows that it couldn\u00b4t outperform the Linear Regression model\n# the reason is in my opinion the small amount of data I delivered to the model\n\nridge = Ridge(alpha = 1e-500)\nCS_testsize_stderr = [0]\nall_par = []\n\nfor CS in [\"CS8\", \"CS20\", \"CS30\", \"CS34\"]:\n        \n        x = b[CS] \n        x = x.values.reshape(-1,1)\n        y = b[\"Position\"]\n\n        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n\n        ridge.fit(xtrain, ytrain)\n\n        pred = ridge.predict(xtest)\n        \n        CS_testsize_stderr[0] = round((ytest-pred).std(),1)\n        \n        all_par.append(CS_testsize_stderr)\n        CS_testsize_stderr = [0]\n        \nridge_one = pd.DataFrame(data = all_par, columns= [\"standard error\"], index=[\"CS8\", \"CS20\", \"CS30\", \"CS34\"])   \nprint (\"Ridge Regression: Prediction of End Position out of Points after one specific Match Day \", \"\\n\", \"\\n\",\n       ridge_one)  ","d1247043":"# I asked myself if the individual progress of success until a match day could better predict the final position than \n# only the state on a particular match day\n\n# so I added the columns of the cumsum of points until match day 8 (20, 30 and 34) as independent values \n# and used the Linear Regression at first again\n# that model didn\u00b4t improve the prediction, the opposite is the case\n# the reason is probably the co-correlation of the independent values\n\nlr = LinearRegression()\nCS_testsize_stderr = [0]\nall_par = []\n\nfor CS in [['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8'], \n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n            'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n            'CS18', 'CS19', 'CS20'], \n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n            'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n            'CS18', 'CS19', 'CS20', 'CS21', 'CS22', 'CS23', 'CS24', 'CS25', 'CS26',\n            'CS27', 'CS28', 'CS29', 'CS30'],\n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n           'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n           'CS18', 'CS19', 'CS20', 'CS21', 'CS22', 'CS23', 'CS24', 'CS25', 'CS26',\n           'CS27', 'CS28', 'CS29', 'CS30', 'CS31', 'CS32', 'CS33', 'CS34']]:\n        \n        x = b[CS]\n        y = b[\"Position\"]\n\n        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n\n        lr.fit(xtrain, ytrain)\n\n        pred = lr.predict(xtest)\n        \n        CS_testsize_stderr[0] = round((ytest-pred).std(),1)\n        \n        all_par.append(CS_testsize_stderr)\n        CS_testsize_stderr = [0]\n        \nlr_progress = pd.DataFrame(data = all_par, columns= [\"standard error\"], index=[\"CS1-CS8\", \"CS1-CS20\", \"CS1-CS30\", \"CS1-CS34\"])   \nprint (\"Linear Regression: Prediction of End Position out of Progress until one specific Match Day \", \"\\n\", \"\\n\",\n       lr_progress)  ","c5fec5f9":"# again I tried to improve my results by using the Ridge Regression\n# firstly I found out the best alpha parameter by using Grid Search\n\nfor CS in [['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8'], \n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n            'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n            'CS18', 'CS19', 'CS20'], \n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n            'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n            'CS18', 'CS19', 'CS20', 'CS21', 'CS22', 'CS23', 'CS24', 'CS25', 'CS26',\n            'CS27', 'CS28', 'CS29', 'CS30'],\n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n           'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n           'CS18', 'CS19', 'CS20', 'CS21', 'CS22', 'CS23', 'CS24', 'CS25', 'CS26',\n           'CS27', 'CS28', 'CS29', 'CS30', 'CS31', 'CS32', 'CS33', 'CS34']]:\n    \n    x = b[CS]\n    y = b[\"Position\"]\n    \n    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n\n    grid = GridSearchCV(Ridge(), param_grid = {'alpha': [1e-1000, 1e-500, 1e-300, 1e-200, 1e-100, 1e-50, 1e-30, \n                                                         1e-25, 1e-20, 1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1,5,10,20,30,\n                                                         35,40,45,50,55,100,150, 200,300,\n                                                         500,800,1000, 10000]}, verbose=0)\n    grid.fit(xtrain,ytrain)\n    print(CS, \" : \", grid.best_params_)","d7f9b957":"# using the Ridge Regression for the progress values as independent values with alpha = 1000\n# led to better results in comparison to the Linear Regression with the progress values \n# (using alpha = 45 didn\u00b4t improve the standard error)\n# netherthe less: using Linear Regression with only one cumsum as independent value is still the best model  \n\nridge = Ridge(alpha = 1000)\nCS_testsize_stderr = [0]\nall_par = []\n\nfor CS in [['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8'], \n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n            'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n            'CS18', 'CS19', 'CS20'], \n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n            'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n            'CS18', 'CS19', 'CS20', 'CS21', 'CS22', 'CS23', 'CS24', 'CS25', 'CS26',\n            'CS27', 'CS28', 'CS29', 'CS30'],\n           ['CS1', 'CS2', 'CS3', 'CS4', 'CS5', 'CS6', 'CS7', 'CS8',\n           'CS9', 'CS10', 'CS11', 'CS12', 'CS13', 'CS14', 'CS15', 'CS16', 'CS17',\n           'CS18', 'CS19', 'CS20', 'CS21', 'CS22', 'CS23', 'CS24', 'CS25', 'CS26',\n           'CS27', 'CS28', 'CS29', 'CS30', 'CS31', 'CS32', 'CS33', 'CS34']]:\n        \n        x = b[CS]\n        y = b[\"Position\"]\n\n        xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n\n        ridge.fit(xtrain, ytrain)\n\n        pred = ridge.predict(xtest)\n        \n        CS_testsize_stderr[0] = round((ytest-pred).std(),1)\n        \n        all_par.append(CS_testsize_stderr)\n        CS_testsize_stderr = [0]\n        \nridge_progress = pd.DataFrame(data = all_par, columns= [\"standard error\"], index=[\"CS1-CS8\", \"CS1-CS20\", \"CS1-CS30\", \"CS1-CS34\"])   \nprint (\"Ridge Regression: Prediction of End Position out of Progress until one specific Match Day \", \"\\n\", \"\\n\",\n       ridge_progress) ","bbb23076":"# to show the success of each model I put the standard error of each model:\n# Linear Regression with independent value \"cumsum of points on match day 8 (20, 30, 34)\", \n# Ridge Regression with independent value \"cumsum of points on match day 8 (20, 30, 34)\", \n# LR with independent values \"progress of cumsum of points until match day 8 (20, 30, 34)\", \n# RR with independent values \"progress of cumsum of points until match day 8 (20, 30, 34)\"\n# into one plot\n# as I already stated: the model with the lowest standard error for every match day I used \n# are the Linear Regression model and the Ridge Regression model with \n# the cumsum of points on a particular match day is independent value\n\nplt.figure(figsize=(10,6))\nplt.xticks(np.arange(4), labels=[\"LR: on Match Day\", \"RR: on Match Day\", \"LR: until Match Day\", \"RR: until Match Day\"])\nplt.plot([lr_one.iloc[0][\"standard error\"], ridge_one.iloc[0][\"standard error\"], lr_progress.iloc[0][\"standard error\"], ridge_progress.iloc[0][\"standard error\"]], label=\"CS8\")\nplt.plot([lr_one.iloc[1][\"standard error\"], ridge_one.iloc[1][\"standard error\"], lr_progress.iloc[1][\"standard error\"], ridge_progress.iloc[1][\"standard error\"]], label=\"CS20\")\nplt.plot([lr_one.iloc[2][\"standard error\"], ridge_one.iloc[2][\"standard error\"], lr_progress.iloc[2][\"standard error\"], ridge_progress.iloc[2][\"standard error\"]], label=\"CS30\")\nplt.plot([lr_one.iloc[3][\"standard error\"], ridge_one.iloc[3][\"standard error\"], lr_progress.iloc[3][\"standard error\"], ridge_progress.iloc[3][\"standard error\"]], label=\"CS34\")\nplt.legend(bbox_to_anchor = (1,1))","05c794e8":"# I` ve chosen the simple Linear Regression model with the sum of points on one match day as independent value\n# the Ridge Regression with x = sum of points on one match day didn\u00b4t diminish the standard error\n# the standard errors of the models with x = the sum of points until a specific match day were consistently higher\n\n# to compare the predicted versus measured data I trained the model again and achieved the predicted values\n# than I created a first plot with the perfect-prediction line as a reference line and the measured values (ytest) on the \n# x-axis and the predicted values (y-axis)\n# the second plot shows the difference between the real values and the predictions (= error) \n# finally I calculated the standard deviation of that error \n# I did that again within a loop using the cumulative sum of points collected until match day 8, 20, 30 and 34\n\n\nfor CS in [\"CS8\", \"CS20\", \"CS30\", \"CS34\"]:\n\n# model training and predictions\n    x = b[[CS]]\n    x = x.values.reshape(-1,1)\n    y = b[\"Position\"]\n    \n    lr = LinearRegression()\n    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n    lr.fit(xtrain, ytrain)\n    predicted = lr.predict(xtest)\n \n# scatter plot: the closer the points are to the line, the better the model predicted that particular date\n    plt.title(CS)\n    plt.xlabel(\"Measured\")\n    plt.ylabel('Predicted')\n    plt.scatter(ytest, predicted) \n    plt.plot([y.min(), y.max()], [y.min(), y.max()], \"r\")\n    plt.show()\n    \n# plot showing the difference (error) between the real and the predicted value using the Seaborn distplot module\n    plt.title(CS)\n    plt.xticks(np.arange(-10,10, step=1.0))\n    sns.distplot(ytest-predicted, bins=16)\n    plt.show()\n    \n# calculation of the standard deviation of the error\n# the real value is between the predicted value and +\/- the standard deviation with a probability of 68%\n# and with a probability of 95% the real value is between the predicted value and +\/- the double standard deviation \n    print(\"Standard Deviation Error: \", (ytest-predicted).std())\n    print(\"With a probability of around 68% the team will end up at the predicted position +\/- \", round((ytest-predicted).std(),1))\n    print(\"With a probability of around 95% the team will end up at the predicted position +\/- \", 2*round((ytest-predicted).std(),1))\n    print(\"\\n\", \"\\n\")","52a4a731":"# as a next step I wanted to use that model for a real world problem: \n# on which final position will the German fotball club FC Koeln be at the end of the current season?\n\n# to predict from a new indepoendent value it is necessary to reshape that value \nprint(\"At this point in time the FC Koeln is on position 7 after 8 Match Days. The club has got 12 points.\")\nmatchday8_fckoeln = np.array([12])\nmatchday8_fckoeln = matchday8_fckoeln.reshape(1,1)\nmatchday8_fckoeln = matchday8_fckoeln.tolist()\n\n# train the Linear Regression model with the the cumsum of points on the 8th match day \nx = b[[\"CS8\"]]\nx = x.values.reshape(-1,1)\ny = b[\"Position\"]\n\nlr = LinearRegression()\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\nlr.fit(xtrain, ytrain)\npredicted = lr.predict(xtest)\n\n# prediction of the final position of FC Koeln \nprint(\"The Linear Regression predicts \", round(lr.predict(matchday8_fckoeln)[0],1), \" as the final position.\")\n\n# calculating the intervalls of the final position for a probaility of 68% and 95%\n# as the model suggests: the club will probably not be relegated after that season\nprint(\"With a probability of around 68% the team will end up between position \", \n      round(round(lr.predict(matchday8_fckoeln)[0],1) -  round((ytest-predicted).std(),1),1),\n      \" and \",\n      round(round(lr.predict(matchday8_fckoeln)[0],1) +  round((ytest-predicted).std(),1),1))\n     \n\nprint(\"With a probability of around 95% the team will end up between position \", \n      round(round(lr.predict(matchday8_fckoeln)[0],1) -  2*round((ytest-predicted).std(),1),1),\n      \" and \",\n      round(round(lr.predict(matchday8_fckoeln)[0],1) +  2*round((ytest-predicted).std(),1),1))\n\nprint(\"\\n\", \"\\n\")","1b0fd9f3":"# at last I wanted to predict the spread of the positions of all the Bundesliga\n# teams\n\n# this is a data frame of the teams and their points on the 8th match day:  \n\nteam_points_on_md8 = pd.DataFrame(columns=[\"Team\", \"Points after 8th Match\"], \ndata=[['Munich', 19],\n ['Dortmund', 18],\n ['Leverkusen', 16],\n ['Freiburg', 16],\n ['Union Berlin', 15],\n ['Wolfsburg', 13],\n ['Koeln', 12],\n ['Leipzig', 11],\n ['Hoffenheim', 11],\n ['Moenchengladbach', 11],\n ['Mainz', 10],\n ['Stuttgart', 9],\n ['Hertha BSC Berlin', 9],\n ['Frankfurt', 8],\n ['Bochum', 7],\n ['Augsburg', 6],\n ['Bielefeld', 5],\n ['F\u00fcrth', 1]])","e8bd721b":"print(\"Current Bundesliga Table after Match Day 8\")\nprint(\"\\n\")\nteam_points_on_md8","e5640076":"\n# the model predicts the spread between which positions each team will finish \n# with a probability of 68% and 95%\n# the spreads a saved in two lists (spread_68_list and spread_95_list)\n\nfinal_position_list = []\nspread_68_list = []\nspread_95_list = []\n\nfor i in range(0,18):\n\n    matchday8_points = np.array([team_points_on_md8.iloc[i][\"Points after 8th Match\"]])\n    matchday8_points = matchday8_points.reshape(1,1)\n    matchday8_points = matchday8_points.tolist()\n\n\n    x = b[[\"CS8\"]]\n    x = x.values.reshape(-1,1)\n    y = b[\"Position\"]\n\n    lr = LinearRegression()\n    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n    lr.fit(xtrain, ytrain)\n    predicted = lr.predict(xtest)\n    \n    spread_68_list.append(\n        [round(round(lr.predict(matchday8_points)[0],1) -  round((ytest-predicted).std(),1),1),\n          round(round(lr.predict(matchday8_points)[0],1) +  round((ytest-predicted).std(),1),1)])\n\n    spread_95_list.append(\n        [round(round(lr.predict(matchday8_points)[0],1) -  2*round((ytest-predicted).std(),1),1),\n          round(round(lr.predict(matchday8_points)[0],1) +  2*round((ytest-predicted).std(),1),1)])\n","77d2d266":"# some calculated positions are lower than 1 or higher than 18\n# I correct these values with the following loops\n\nfor spread in spread_68_list:\n    if spread[0] < 1.0:\n        spread[0] = 1\n    if spread[1] > 18:\n        spread[1] = 18\n        \nspread_68_list","2640bd6e":"for spread in spread_95_list:\n    if spread[0] < 1.0:\n        spread[0] = 1\n    if spread[1] > 18:\n        spread[1] = 18\n        \nspread_95_list","284372cf":"# lastly I add the two lists as columns onto the latest data frame \n\nteam_points_on_md8[\"Position range with prob. of 68%\"] = spread_68_list\nteam_points_on_md8[\"Position range with prob. of 95%\"] = spread_95_list","b324241c":"team_points_on_md8","34b7bc56":"# Finally I created a function to predict the position of a team at the end of the season:\n\ndef position_prediction(current_points, current_match_day):\n\n    points = np.array([current_points])\n    points = points.reshape(1,1)\n    points = points.tolist()\n\n    x = b[[current_match_day]]\n    x = x.values.reshape(-1,1)\n    y = b[\"Position\"]\n\n    lr = LinearRegression()\n    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=101)\n    lr.fit(xtrain, ytrain)\n    predicted = lr.predict(xtest)\n\n    predicted_position = round(lr.predict(points)[0],1)\n    if predicted_position < 1:\n        print(\"The Linear Regression predicts 1 as the final position.\") \n    elif predicted_position > 18:\n        print(\"The Linear Regression predicts 18 as the final position.\")\n    else:\n        print(\"The Linear Regression predicts \", predicted_position, \" as the final position.\")\n\n    best = round(round(lr.predict(points)[0],1) -  round((ytest-predicted).std(),1),1)\n    if best < 1:\n        bt = 1\n    elif best > 18:\n        bt = 18\n    else:\n        bt = best\n    worst = round(round(lr.predict(points)[0],1) +  round((ytest-predicted).std(),1),1)\n    if worst < 1:\n        wt = 1\n    elif worst > 18:\n        wt = 18\n    else:\n        wt = worst\n    print(\"With a probability of around 68% the team will end up between position \", \n          bt , \" and \", wt)\n\n    best = round(round(lr.predict(points)[0],1) -  2*round((ytest-predicted).std(),1),1)\n    if best < 1:\n        bt = 1\n    elif best > 18:\n        bt = 18\n    else:\n        bt = best\n    worst = round(round(lr.predict(points)[0],1) +  2*round((ytest-predicted).std(),1),1)\n    if worst < 1:\n        wt = 1\n    elif worst > 18:\n        wt = 18\n    else:\n        wt = worst\n    print(\"With a probability of around 95% the team will end up between position \", \n          bt , \" and \", wt)","a6068ace":"current_points = int(input(\"How many points has the team currently? \"))\ncurrent_match_day = str(input(\"Which match day is it? \"))\ncurrent_match_day = \"CS\" + current_match_day\n                     \nposition_prediction(current_points, current_match_day)","733a5fc1":"My goal was to create a model that predicts the final position of a team in the German Bundesliga \nby the collected points of the team during the season as good as possible. \nTherefore I tried different ML-models, namely the Linear Regression model and the Ridge Regression model. \nI also tried different predictive variables: the points a team had on a particular match day and the course of \nsuccess of a team until a particular match day. \n\nMy biggest difficulty was that the data set is too small for a good and stable prediction and \nthat the co-correlation of the variables means that the integration of multiple predictor variables is not worthwhile.\n\nI also tried to add other ML-techniques and other variables like the position of a team in the past season to improve \nthe model but that didn\u00b4t help (not included in that notebook).\n\nI am quite new in the field of Data Science and it\u00b4s more of a hobby for me. Any questions and any advice is more than welcome!\n","f1171430":"Acknowledgements:\ndata from: https:\/\/www.transfermarkt.us\/"}}