{"cell_type":{"d72b10f3":"code","e8ed815e":"code","d2023c95":"code","239d3768":"code","d905c106":"code","bfe8db4d":"code","0efbc96f":"code","b60b0105":"code","36842919":"code","814081ba":"code","0d8e6ddf":"code","42fd5c01":"code","935c31b0":"code","7d726eea":"code","d71c29bf":"code","084bd6d1":"code","c9b4337a":"code","ff4e07e9":"code","9b0a122c":"code","06ea1277":"code","dbcba9ff":"code","944fc4b4":"code","18e9f671":"code","3e0baa72":"code","67ab5b4d":"code","6ffeb872":"markdown"},"source":{"d72b10f3":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \nimport os\nfrom glob import glob\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm import tqdm\nimport random as rn\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nimport tensorflow as tf\nfrom keras.layers import Dense,Conv2D,Flatten,BatchNormalization,MaxPooling2D,Dropout\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam,Adagrad,SGD\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\n\n%matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)","e8ed815e":"classes=os.listdir('..\/input\/flowers-recognition\/flowers\/flowers')\nclasses","d2023c95":"file_name=[]\nX=[]\ny=[]\nimage_size =150\ndaisy_dir = '..\/input\/flowers-recognition\/flowers\/flowers\/daisy'\ndandelion_dir ='..\/input\/flowers-recognition\/flowers\/flowers\/dandelion'\nsunflower_dir ='..\/input\/flowers-recognition\/flowers\/flowers\/sunflower'\ntulip_dir ='..\/input\/flowers-recognition\/flowers\/flowers\/tulip'\nrose_dir ='..\/input\/flowers-recognition\/flowers\/flowers\/rose'","239d3768":"def assign_label(img,flower_type):\n    return flower_type\n\ndef load_image(flower_type,DIR):\n    for img in tqdm(os.listdir(DIR)):\n        img_last =img.split(\".\")[-1]\n        if img_last == 'jpg':\n            label=assign_label(img,flower_type)\n            path = os.path.join(DIR,img)\n            img = cv.imread(path,cv.IMREAD_COLOR)\n            img = cv.resize(img, (image_size,image_size))\n        \n            X.append(np.array(img))\n            y.append(str(label))","d905c106":"load_image('daisy',daisy_dir)\nprint(len(X))\n","bfe8db4d":"load_image('sunflower',sunflower_dir)\nprint(len(X))","0efbc96f":"load_image('tulip',tulip_dir)\nprint(len(X))","b60b0105":"load_image('rose',rose_dir)\nprint(len(X))","36842919":"load_image('dandelion',dandelion_dir)\nprint(len(X))","814081ba":"print(len(y))","0d8e6ddf":"fig,ax =plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range(2):\n        l = rn.randint(0,len(y))\n        ax[i,j].imshow(X[l])\n        ax[i,j].set_title('Flower: '+y[l])\nplt.tight_layout()","42fd5c01":"#Label encoding and one hot encoding\nle =LabelEncoder()\ny=le.fit_transform(y)\ny=to_categorical(y,5)\nX =np.array(X)\nX =X\/255\n","935c31b0":"len(X),len(y)","7d726eea":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)","d71c29bf":"len(x_train),len(y_train),len(y_test),len(x_test)","084bd6d1":"np.random.seed(42)\nrn.seed(42)","c9b4337a":"le.inverse_transform(y_test[])","ff4e07e9":"model = Sequential()\nmodel.add(Conv2D(64,(5,5),padding='Same',activation='relu',input_shape=(150,150,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(128,(3,3),padding='Same',activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(128,(3,3),padding='Same',activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(96,(3,3),padding='Same',activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(128,(3,3),padding='Same',activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dense(5,activation='softmax'))\nmodel.summary()","9b0a122c":"epochs =50\nbatch_size =128\n\nlr = ReduceLROnPlateau(patience=3,factor=0.1,monitor='val_loss',verbose=1)","06ea1277":"\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","dbcba9ff":"model.compile(optimizer=Adam(lr=0.001),metrics=['accuracy'],loss='categorical_crossentropy')","944fc4b4":"History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_test,y_test),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ batch_size)","18e9f671":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","3e0baa72":"plt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","67ab5b4d":"# getting predictions on val set.\npred=model.predict(x_test)\npred_digits=np.argmax(pred,axis=1)","6ffeb872":"# Model"}}