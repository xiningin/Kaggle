{"cell_type":{"8db3bce0":"code","be2720b1":"code","6d25c90d":"code","be0bdd21":"code","87dbc3bd":"code","39a0fed5":"code","85abab10":"code","9ac0918c":"code","988208d0":"code","8162add1":"code","f1fc2b3c":"code","e870dae1":"code","caf88f4a":"code","5a41362a":"code","7f1012d7":"code","56092ce6":"code","9fa4f52b":"code","e55dda9e":"code","1a1d6f94":"code","d193a888":"code","600c1b14":"code","d93c31ca":"code","ee8b81a0":"code","69ee7d81":"code","9c731cc3":"code","0df21e14":"code","ba6a4431":"code","740b4182":"code","30d9096d":"code","c8ef6a95":"code","737eabb0":"code","9ac1c829":"code","e6780355":"code","f46e5b58":"code","b9f42d62":"code","c4fc8158":"code","b5d63ce7":"code","c138585c":"code","6dc8e582":"code","6f15875c":"code","9e2d846c":"code","bd0f8e17":"code","8fbb006f":"code","ad7229a2":"code","f8f68022":"code","dbf876a3":"code","3f79d800":"code","c1d759aa":"code","8d239b0d":"code","b2d5b83b":"code","9ad605af":"code","deb65131":"code","9e535ca5":"code","55df4c36":"code","2fff58ba":"code","565c0213":"code","e354dea0":"code","a443d853":"code","303b92c0":"code","897f82a4":"code","a41744fd":"markdown","5b594eb8":"markdown","6e1860b4":"markdown","0f54c62e":"markdown","e5d70ca2":"markdown","35bb1140":"markdown","0e3f9684":"markdown","b96f5d9e":"markdown","7094ecd6":"markdown","580b9028":"markdown","2f733c3c":"markdown","bace98c8":"markdown","c4271db7":"markdown","d482eccf":"markdown","917e2016":"markdown","66a357fa":"markdown","997dee1d":"markdown","8d89f0ed":"markdown","c7e19130":"markdown","9a7a1242":"markdown","55f17f3d":"markdown","6a3a1413":"markdown","be4ad18c":"markdown","c9986d95":"markdown","b82377d4":"markdown","a7c97fdb":"markdown","0404143c":"markdown","0e75fd6b":"markdown","5fe1fe13":"markdown","0cd355fa":"markdown","249c3049":"markdown","6e4b94e0":"markdown","b1f3b627":"markdown","768431af":"markdown","3a82de66":"markdown","bf09fa28":"markdown","a3fbc23c":"markdown","f42b021a":"markdown","35119023":"markdown","7f52754e":"markdown","bdecba19":"markdown","99a98348":"markdown","97b57c60":"markdown","27a1eacd":"markdown","3dbc922c":"markdown","4bca625e":"markdown","e0519ffd":"markdown","439a0d85":"markdown"},"source":{"8db3bce0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rnd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","be2720b1":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","6d25c90d":"df_train.head()","be0bdd21":"df_test.head()","87dbc3bd":"df_submission.head()","39a0fed5":"df_train.shape,df_test.shape,df_submission.shape","85abab10":"count=0\nfor i in df_test.columns:\n    if i in df_train:\n        pass\n    else:\n        count+=1\nprint('Test Fine Columns: {}\\nTest Error Columns: {}\\n'.format(len(df_test.columns)-count,count))\nprint('Number of nulls in each column for df_train\\n',df_train.isnull().sum())\nprint('Number of nulls in each column for df_test\\n',df_test.isnull().sum())","9ac0918c":"df_test.loc[df_test['Fare'].isnull()==1]","988208d0":"import seaborn as sb\nimport matplotlib.pyplot as plt\n%matplotlib inline","8162add1":"fig_dims = (15, 6)\nfig, ax = plt.subplots(figsize=fig_dims)\nb=sb.distplot(df_test['Fare'],ax=ax,bins=100)\nb.set_xticks(np.arange(0,100+1,10))\nplt.xlim(0,100)","f1fc2b3c":"df_test.groupby('Pclass')['Fare'].describe()","e870dae1":"df_test.at[152,'Fare']=12.459678 #Filling with the mean\ndf_test.iloc[152] #Check","caf88f4a":"df_train.loc[df_train['Embarked'].isnull()==1]","5a41362a":"df_train.at[61,'Embarked'] = 'S' #Refers to southampton\ndf_train.at[829,'Embarked'] = 'S'\ndf_train.Embarked.isnull().any()","7f1012d7":"df_train.Name.head(3)","56092ce6":"df_train.Name.str.split(\",\",expand=True)[1].str.split(\".\",expand=True)[0].value_counts()","9fa4f52b":"df_test.Name.str.split(\",\",expand=True)[1].str.split(\".\",expand=True)[0].value_counts()","e55dda9e":"df_train['title']=df_train.Name.str.split(\",\",expand=True)[1].str.split(\".\",expand=True)[0].str.strip()\ndf_test['title']=df_test.Name.str.split(\",\",expand=True)[1].str.split(\".\",expand=True)[0].str.strip()","1a1d6f94":"df_train[((df_train['title'] !='Mr')&(df_train['title'] !='Mrs')&(df_train['title'] !='Miss')& (df_train['title'] !='Master'))]","d193a888":"#From https:\/\/www.encyclopedia-titanica.org\/titanic-victim\/arthur-jackson-brewe.html\ndf_train.at[766,'Age'] = 46","600c1b14":"df_test[((df_test['title'] !='Mr')&(df_test['title'] !='Mrs')&(df_test['title'] !='Miss')& (df_test['title'] !='Master'))]","d93c31ca":"df_test.at[88,'Age']=21","ee8b81a0":"combine=[df_train,df_test]\nfor dataset in combine:\n    dataset['title'] = dataset['title'].replace(['Lady', 'the Countess','Capt', 'Col','Don', 'Dr', 'Major'\\\n                                                 , 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['title'] = dataset['title'].replace('Mlle', 'Miss')\n    dataset['title'] = dataset['title'].replace('Ms', 'Miss')\n    dataset['title'] = dataset['title'].replace('Mme', 'Mrs')\n    \ndf_train[['title', 'Survived']].groupby(['title'], as_index=False).mean()","69ee7d81":"combine=[df_train,df_test]\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)","9c731cc3":"grid = sb.FacetGrid(df_train, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","0df21e14":"guess_ages = np.zeros((2,3))\nguess_ages","ba6a4431":"combine=[df_train,df_test]\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            #age_mean = guess_df.mean()\n            #age_std = guess_df.std()\n            #age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age to nearest 0.5\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n","740b4182":"df_train['AgeBand'] = pd.cut(df_train['Age'], 5)\ndf_train[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","30d9096d":"combine=[df_train,df_test]\nfor dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']=4\ndf_train.head()","c8ef6a95":"df_train.drop(columns='AgeBand',inplace=True)","737eabb0":"df_train.head()","9ac1c829":"df_train.drop(['PassengerId','Name','Cabin','Ticket'],axis=1,inplace=True)\ndf_test.drop(['Name','Cabin','Ticket'],axis=1,inplace=True)\npassengerId=df_test['PassengerId']","e6780355":"df_train.head()","f46e5b58":"df_train['FareBand'] = pd.qcut(df_train['Fare'], 4)\ndf_train[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","b9f42d62":"combine=[df_train,df_test]\nfor dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\ndf_train = df_train.drop(['FareBand'], axis=1)    ","c4fc8158":"df_train.head()","b5d63ce7":"combine=[df_train,df_test]\ntitle_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\nfor dataset in combine:\n    dataset['title'] = dataset['title'].map(title_mapping) ","c138585c":"combine=[df_train,df_test]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} )","6dc8e582":"df_train","6f15875c":"title_dict = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\nembarked_dict = {'S': 0, 'C': 1, 'Q': 2}\nsex_dict = {'male':0, 'female':1}\nage_dict = { (-0.08, 16.0):0, (16.0, 32.0):1, (32.0, 48.0):2, (48.0, 64.0):3, (64.0, 80.0):4 }\nfare_dict = { (-0.001, 7.91):0, (7.91, 14.454):1, (14.454, 31.0):2, (31.0, 512.329):3 }","9e2d846c":"grid = sb.FacetGrid(df_train_keys, row='Pclass', col='Sex', size=3, aspect=2)\ngrid.map(sb.barplot,'Age','Survived', alpha=.5)\ngrid.add_legend()\nplt.xticks(range(len(list(age_dict.keys()))),age_dict.keys(),rotation=45,size='small')\nplt.tight_layout();","bd0f8e17":"df_train_keys = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ngrid = sb.FacetGrid(df_train_keys, row='Embarked', col='Survived', size=2.5, aspect=2)\ngrid.map(sb.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","8fbb006f":"grid = sb.FacetGrid(df_train_keys, col='Embarked', size=3, aspect=1.5)\ngrid.map(sb.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend();","ad7229a2":"df_train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","f8f68022":"df_train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","dbf876a3":"combine=[df_train,df_test]\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1 \n    #+1 added for the passenger himself to include the family\n    \ndf_train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean()\\\n.sort_values(by='Survived', ascending=False)","3f79d800":"combine=[df_train,df_test]\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ndf_train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","c1d759aa":"df_train = df_train.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ndf_test = df_test.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)","8d239b0d":"combine=[df_train,df_test]\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ndf_train.loc[:, ['Age*Class', 'Age', 'Pclass']].head(5)","b2d5b83b":"# I would like to compare my logistic regression model with: \n#https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","9ad605af":"X_test=df_test.drop('PassengerId',axis=1)\ny_test=df_submission['Survived']","deb65131":"y = df_train['Survived']\nX = df_train.drop('Survived',axis=1)","9e535ca5":"X_train,X_val,y_train,y_val = train_test_split(X,y)\nX_train.shape,y_train.shape,X_val.shape,y_val.shape","55df4c36":"from sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n# define dataset\n# define models and parameters\nmodel = LogisticRegression()\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\npenalty = ['l2']\nc_values = [100, 10, 1.0, 0.1, 0.01]\n# define grid search\ngrid = dict(solver=solvers,penalty=penalty,C=c_values)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(X, y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","2fff58ba":"lr_model = LogisticRegression(solver='newton-cg')\nlr_model.fit(X_train,y_train)\ny_pred = lr_model.predict(X_val)\nprint(classification_report(np.array(y_val),y_pred))","565c0213":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(lr_model, random_state=1).fit(X_val, y_val)\neli5.show_weights(perm, feature_names = X_val.columns.tolist())","e354dea0":"lr_model = LogisticRegression(solver='newton-cg')\nlr_model.fit(X_train,y_train)\ny_pred = lr_model.predict(X_test)\nprint(classification_report(np.array(y_test),y_pred))","a443d853":"compare = df_submission.copy()\ncompare['LogisticRegression']=y_pred\ncompare.head()","303b92c0":"output = compare.drop('Survived',axis=1)\noutput.rename(columns={\"LogisticRegression\": \"Survived\"},inplace=True)\noutput.head()","897f82a4":"output.to_csv('submission.csv', index=False)\nprint('Done. If you find it useful please Upvote')","a41744fd":"**The Previous Solution For Solving Missing Values Of Age Is Taken From: https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions , Now Missings Are As Following**","5b594eb8":"**\"Age VS Chance Of Surviving in All Classes And Both Sexes\"**","6e1860b4":"**We have an option which is filling his Fare with the mean of Fare associated with his Pclass (which is 3)**","0f54c62e":"**Now lets encode some variabes, remember we previously mapped 1 for female and 0 for male in Sex variable**","e5d70ca2":"**From https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions we can use this solution to estimate the remaining null ages which finding the correlation with age and estimate using it, but first lets encode sex into female:1 and male:0**","35bb1140":"**Data Exploration**","0e3f9684":"|ColumnsNulls|# nulls df_train|# nulls For df_test|\n|---|---|---|\n|Age|177|86|\n|Cabin|687|327|","b96f5d9e":"**Now lets estimate the 2 missing values in Embarked of training set**","7094ecd6":"**Now lets find and estimate the null value in df of Fare**","580b9028":"From https:\/\/machinelearningmastery.com\/hyperparameters-for-classification-machine-learning-algorithms\/","2f733c3c":"# Data Predictions ","bace98c8":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split","c4271db7":"**We can also create an artificial feature combining Pclass and Age.**","d482eccf":"*For Training Set*","917e2016":"**The accuracy is 93% and precision + recall are also above 90% which is more than : https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions**","66a357fa":"**Lets fix the least common categories null in ages since they don't have enough distribution or dataset and can be searched and found over the internet**","997dee1d":"Variable|Definition|Key\n---|---|---\nsurvival|Survival|0 = No, 1 = Yes\npclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd\nsex|Sex|\nAge|Age in years|\nsibsp|# of siblings \/ spouses aboard the Titanic|\nparch|# of parents \/ children aboard the Titanic|\nticket|Ticket number|\nfare|Passenger fare|\ncabin|Cabin number|\nembarked|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton","8d89f0ed":"# EDA and Encoded Data Visualizations","c7e19130":"# Data Wrangling","9a7a1242":"**But before completing encoding we can also encode the Fare since it is continuous we can create a range for it**","55f17f3d":"**Using Machine Learning Techniques we would go deeper into it and we will tune the model, perform validation and some PermutationImportance etc.**","6a3a1413":"Since\nsibsp: # of siblings \/ spouses aboard the Titanic\\\nparch: # of parents \/ children aboard the Titanic\\\nWe can combine these features to get a family size","be4ad18c":"|ColumnsNulls|# nulls df_train|# nulls For df_test|\n|---|---|---|\n|Cabin|687|327|","c9986d95":"## Logistic Regression","b82377d4":"**Lets see O'Donoghue, Ms. Bridge age over internet https:\/\/www.encyclopedia-titanica.org\/titanic-victim\/bridget-donohoe.html**","a7c97fdb":"**So lets find a classification report including all key metrics (accuracy recall precision) using the best tune found in the previous cell** ","0404143c":"**This chart ensures the confidelity of choosing the mean the way the line of code below shows**","0e75fd6b":"|sex|embarked|title|Each Category In Each Categorical Variable Are Encoded As|\n|---|---|---|---|\n|male|S||0|\n|female|C|Mr|1|\n||Q|Miss|2|\n|||Mrs|3|\n|||Master|4|\n|||Rate|5|","5fe1fe13":"# About Data:","0cd355fa":"**It says that Embarked = C, male are much more surviving than females.**","249c3049":"**As we can notice 766 Brew, Dr. Arthur Jackson age is not known, we have 2 approaches to fill it with the mean of Dr age or find it on google**","6e4b94e0":"# Feature Engineering","b1f3b627":"**After well estimating Fare & Embarekd, now the only nulls are in Age and Cabin:**","768431af":"|ColumnsNulls|# nulls df_train|# nulls For df_test|\n|---|---|---|\n|Age|177|86|\n|Cabin|687|327|\n|Fare|0|1|\n|Embarked|2|0|","3a82de66":"**Now we iterate over Sex (0 or 1) and Pclass (1, 2, 3) to calculate guessed values of Age for the six combinations.**","bf09fa28":"**Data Import**","a3fbc23c":"**As we may notice that the surviving rate increased when we added the 2 columns (Parch, Sibsp) into FamilySize and now we can also see if the passenger is alone or not to be 2 classes only. (This Solution Is Proposed By: https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions]**","f42b021a":"**Let us start by preparing an empty array to contain guessed Age values based on Pclass x Gender combinations.**","35119023":"***Before visualizing data we must remember the encodings we did before for the variables that have encodings***\\\n**title: {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}**\\\n**Embarked: {'S': 0, 'C': 1, 'Q': 2}**\\\n**Sex: {'male':0, 'female':1}**\\\n**Age: { [-0.08, 16.0]:0, [16.0, 32.0]:1, [32.0, 48.0]:2, [48.0, 64.0]:3, [64.0, 80.0]:4 }**\\\n**Fare: { [-0.001, 7.91]:0, [7.91, 14.454]:1, [14.454, 31.0]:2, [31.0, 512.329]:3 }**\n\n\n\n\n","7f52754e":"**It is more likely that they are both coming from the same (Embarked) since they both hold the same ticket number. But precisely, from a quick search I found that Icard,Miss,Amelie has Embarked in Southampton https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/amelia-icard.html**\n**Also Stone, Mrs. George Nelson (Martha Evelyn) in Southampton https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/martha-evelyn-stone.html**","bdecba19":"**Their must be some suspect error titles such as Dona ,Don and Jonkheer as they seem to be names not titles and lets assign titles for each. And the individual titles and check their age. Since our major problem is to estimate the missing ages so they all have ages not null so it is not a big problem to leave their titles as it is.**","99a98348":"**As a traditional analysis for titanic dataset, Pclass of 1st (people who pay much not economy) are experiencing more chance of surviving, also females are more than males in terms of surviving for the 3 classes and children from 0 to 16 age are having the highest chance of surviving among all other ages. Pclass=3|Sex=1 the age of 48 to 64 is only 1 person who survived so it is not to be considered as highest chance of surviving and also the girls in Pclass =3 aging from 0 to 16 are higher in terms of surviving chance than the other ages of this category Pclass=3|Sex=1**","97b57c60":"**Now lets drop the unwanted columns and since Cabin is having more than 70% of rows are nulls so we will not use it, the columns are (for df_train): 'PassengerId','Name','Cabin','Ticket. (for df_test): 'Cabin','Name','Ticket' because we want the passenger id of test data in order to test the submission score in the end**","27a1eacd":"*For Testing Set*","3dbc922c":"**We can extract the title after each name to enhance the estimation for each category distribution for ex: random distribution between the mean and variance of Age for the title of Miss etc.**","4bca625e":"**As a conclusion, we will mainly take into consideration the Pclass, Sex, Age, Embarked for modelling**","e0519ffd":"**Based on the PermutationImportance each of these feature seems good for the model. Now lets predict the test set**","439a0d85":"**Let us create Age bands and determine correlations with Survived.**"}}