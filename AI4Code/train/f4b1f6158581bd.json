{"cell_type":{"9a36e04e":"code","7ee39415":"code","54af1afd":"code","c0ceac18":"code","ac09c167":"code","dcef8a1f":"code","3f18b86f":"code","3107fc74":"code","0e178980":"code","fca90b09":"code","9c78e4b6":"code","c02fb812":"markdown","0f814905":"markdown","73f95266":"markdown","c2286f6d":"markdown","017b3765":"markdown","b9fa4194":"markdown","967c4184":"markdown","c26a213b":"markdown","70eb392f":"markdown","ef10014f":"markdown","bedb9f99":"markdown","afdcfca7":"markdown"},"source":{"9a36e04e":"import pandas as pd \nimport numpy as np \nhouse_file = '..\/input\/home-data-for-ml-course\/train.csv'\nhouse_data = pd.read_csv(house_file)","7ee39415":"for columns in house_data:\n    if house_data[columns].isnull().sum() >1000:\n        house_data = house_data.drop(columns, axis = 1)","54af1afd":"house_data.fillna(0, inplace= True)","c0ceac18":"y = house_data.SalePrice.astype(np.float32, copy= False)\nfeatures = ['LotFrontage', 'LotArea', 'MoSold','YrSold']\nX = house_data[features].astype(np.float32, copy = False)","ac09c167":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error ","dcef8a1f":"train_X, val_X, train_y, val_y = train_test_split(X,y, random_state=1)","3f18b86f":"def get_mae(max_leaf_nodes, train_X, val_x, train_y, val_Y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    predict_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, predict_val)\n    return (mae)","3107fc74":"possible_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\nfor max_leaf_nodes in possible_max_leaf_nodes:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(max_leaf_nodes, my_mae)","0e178980":"score = {leaf_size: get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y) for leaf_size in possible_max_leaf_nodes}\nbest_size_nodes = min(score, key= score.get)\nprint(best_size_nodes)","fca90b09":"house_final_model = DecisionTreeRegressor(max_leaf_nodes= best_size_nodes, random_state = 0)\nhouse_final_model.fit(X, y)\n","9c78e4b6":"predictions_final = house_final_model.predict(X)\nval_mae = mean_absolute_error(y, predictions_final)\nprint(val_mae)","c02fb812":"># Testing the model for the whole X,y dataset with the best score got in the code above, now changing the DecisionTreeRegressor to a specific value 'best_size_nodes'","0f814905":"># Using a FOR repetition to deleting the columns with NaN ","73f95266":"># BEST SCORE FROM HOUSING PRICES COMPETITION\n># Defining a function to get the MAE and using a FOR repetition to check all possibles leaf_nodes and respective MAE values, then getting the best score from the max_leaf_nodes setted. After that checking all the data X,y with the best score found.","c2286f6d":"># Importing the libs for training the dataset and get the MAE","017b3765":"># Training the dataset with train_test_split that get random trains and test subsets","b9fa4194":"># Predicting the MAE now for whole dataset not only for val_X, val_y","967c4184":"># By some leaf_nodes defined, the FOR repetition will pass through all the values and set in the function get_mae, to get each MAE value for each possible leaf","c26a213b":"># FOR repetition to get the best score from the possible_max_leaf_nodes","70eb392f":"># Choosing the parameters X and y for the dataset and converting the type float64 to float32","ef10014f":"># Replacing some NaN that still exist in the dataframe for 0.","bedb9f99":"># Defining a function that will return the MAE value for each X, y splitted and the max_leaf_nodes setted.","afdcfca7":"># Importing panda and numpy as common to get the dataset and modify the type of the number."}}