{"cell_type":{"f5477d99":"code","01cd3edd":"code","9e29a4b3":"code","2c3366d6":"code","a858cbd4":"code","52205138":"code","993b649c":"code","590e34e9":"code","1edf713d":"code","c36c90cb":"code","766ea8ae":"code","33b5d2bc":"code","44f4d3f1":"code","7ca603ba":"markdown","ace9849c":"markdown","23fa72f1":"markdown","f8a47a02":"markdown","5ebfc117":"markdown","1cc82c99":"markdown","e5174e73":"markdown","2b39d029":"markdown","6bf3b809":"markdown","85216206":"markdown","d8889759":"markdown","d30d11b2":"markdown","f5d0297a":"markdown","b07c7438":"markdown","59e8d4be":"markdown","f29ea3dd":"markdown","b7153dbb":"markdown","dcfd9960":"markdown"},"source":{"f5477d99":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\n\ninput_dir = '..\/input\/movielens-preprocessing'\nmodel_dir = '..\/input\/movielens-spiffy-model'\nmodel_path = os.path.join(model_dir, 'movie_svd_model_32.h5')\nmodel = keras.models.load_model(model_path)","01cd3edd":"emb_layer = model.get_layer('movie_embedding')\n(w,) = emb_layer.get_weights()\nw.shape","9e29a4b3":"w[0]","2c3366d6":"movies_path = os.path.join(input_dir, 'movie.csv')\nmovies_df = pd.read_csv(movies_path, index_col=0)\nmovies_df.head()","a858cbd4":"i_toy_story = 0\ni_shrek = movies_df.loc[\n    movies_df.title == 'Shrek',\n    'movieId'\n].iloc[0]\n\ntoy_story_vec = w[i_toy_story]\nshrek_vec = w[i_shrek]\n\nprint(\n    toy_story_vec,\n    shrek_vec,\n    sep='\\n',\n)","52205138":"from scipy.spatial import distance\n\ndistance.euclidean(toy_story_vec, shrek_vec)","993b649c":"i_exorcist = movies_df.loc[\n    movies_df.title == 'The Exorcist',\n    'movieId'\n].iloc[0]\n\nexorcist_vec = w[i_exorcist]\n\ndistance.euclidean(toy_story_vec, exorcist_vec)","590e34e9":"print(\n    distance.cosine(toy_story_vec, shrek_vec),\n    distance.cosine(toy_story_vec, exorcist_vec),\n    sep='\\n'\n)","1edf713d":"from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n\n# Limit to movies with at least this many ratings in the dataset\nthreshold = 100\nmainstream_movies = movies_df[movies_df.n_ratings >= threshold].reset_index(drop=True)\n\nmovie_embedding_size = w.shape[1]\nkv = WordEmbeddingsKeyedVectors(movie_embedding_size)\nkv.add(\n    mainstream_movies['key'].values,\n    w[mainstream_movies.movieId]\n)","c36c90cb":"kv.most_similar('Toy Story')","766ea8ae":"\nimport textwrap\nmovies = ['Eyes Wide Shut', 'American Pie', 'Iron Man 3', 'West Side Story',\n          'Battleship Potemkin', 'Clueless'\n]\n\ndef plot_most_similar(movie, ax, topn=5):\n    sim = kv.most_similar(movie, topn=topn)[::-1]\n    y = np.arange(len(sim))\n    w = [t[1] for t in sim]\n    ax.barh(y, w)\n    left = min(.6, min(w))\n    ax.set_xlim(right=1.0, left=left)\n    # Split long titles over multiple lines\n    labels = [textwrap.fill(t[0] , width=24)\n              for t in sim]\n    ax.set_yticks(y)\n    ax.set_yticklabels(labels)\n    ax.set_title(movie)    \n\nfig, axes = plt.subplots(3, 2, figsize=(15, 9))\n\nfor movie, ax in zip(movies, axes.flatten()):\n    plot_most_similar(movie, ax)\n    \nfig.tight_layout()","33b5d2bc":"kv.most_similar(\n    positive = ['Scream'],\n    negative = ['Psycho (1960)']\n)","44f4d3f1":"kv.most_similar(\n    ['Pocahontas', 'Cars 2'],\n    negative = ['Brave']\n)","7ca603ba":"Artsy erotic dramas, raunchy sophomoric comedies, old-school musicals, superhero movies... our embeddings manage to nail a wide variety of cinematic niches!","ace9849c":"How does this compare to a pair of movies that we would think of as very different?","23fa72f1":"Our weight matrix has 26,744 rows for that many movies. Each row is 32 numbers - the size of our movie embeddings.\n\nLet's look at an example movie vector:","f8a47a02":"Comparing dimension-by-dimension, these look vaguely similar. If we wanted to assign a single number to their similarity, we could calculate the euclidean distance between these two vectors. (This is our conventional 'as the crow flies' notion of distance between two points. Easy to grok in 1, 2, or 3 dimensions. Mathematically, we can also extend it to 32 dimensions, though good luck visualizing it.)","5ebfc117":"## Analogy solving\n\nThe SAT test which is used to get into American colleges and universities poses analogy questions like:\n\n    shower : deluge :: _____ : stare\n    \n(Read \"shower is to deluge as ___ is to stare\")\n\nTo solve this, we find the relationship between deluge and shower, and apply it to stare. A shower is a milder form of a deluge. What's a milder form of stare? A good answer here would be \"glance\", or \"look\". \n\nIt's kind of astounding that this works, but people have found that these can often be effectively solved by simple vector math on word embeddings. Can we solve movie analogies with our embeddings? Let's try. What about:\n\n    Brave : Cars 2 :: Pocahontas : _____\n    \nThe answer is not clear. One interpretation would be that *Brave* is like *Cars 2*, except that the latter is aimed primarily at boys, and the former might be more appealing to girls, given its female protagonist. So maybe the answer should be, like *Pocahontas*, a mid-90's conventional animation kids movie, but more of a 'boy movie'. *Hercules*? *The Lion King*? \n\nLet's ask our embeddings what they think.\n\nIn terms of vector math, we can frame this as...\n\n    Cars 2 = Brave + X\n    _____  = Pocahontas + X\n    \nRearranging, we get:\n\n    ____ = Pocahontas + (Cars 2 - Brave)\n\nWe can solve this by passing in two movies (*Pocahontas* and *Cars 2*) for the positive argument to `most_similar`, with *Brave* as the negative argument:","1cc82c99":"What movie is this the embedding of? Let's load up our dataframe of movie metadata.","e5174e73":"Earlier we trained a model to predict the ratings users would give to movies using a network with embeddings learned for each movie and user. Embeddings are powerful! But how do they actually work? \n\nPreviously, I claimed that embeddings capture the 'meaning' of the objects they represent, and discover useful latent structure. Let's put that to the test!\n\n# Looking up embeddings\n\nLet's load a model we trained earlier so we can investigate the embedding weights that it learned.","2b39d029":"> **Aside:** *Why* is cosine distance commonly used when working with embeddings? The short answer, as with so many deep learning techniques, is \"empirically, it works well\". In the exercise coming up, you'll get to do a little hands-on investigation that digs into this question more deeply.\n\nWhich movies are most similar to *Toy Story*? Which movies fall right between *Psycho* and *Scream* in the embedding space? We could write a bunch of code to work out questions like this, but it'd be pretty tedious. Fortunately, there's already a library for exactly this sort of work: **Gensim**.\n\n# Exploring embeddings with Gensim\n\nI'll instantiate an instance of [`WordEmbeddingsKeyedVectors`](https:\/\/radimrehurek.com\/gensim\/models\/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors) with our model's movie embeddings and the titles of the corresponding movies.\n\n> Aside: You may notice that Gensim's docs and many of its class and method names refer to *word* embeddings. While the library is most frequently used in the text domain, we can use it to explore embeddings of any sort.","6bf3b809":"This weakly fits our prediction: the 4 closest movies are indeed kids animated movies from the 90s. After that, the results are a bit more perplexing.\n\nIs our model wrong, or were we? Another difference we failed to account for between *Cars 2* and *Brave* is that the former is a sequel, and the latter is not. 7\/10 of our results are also sequels. This tells us something interesting about our learned embeddings (and, ultimately, about the problem of predicting movie preferences). \"Sequelness\" is an important property to our model - which suggests that some of the variance in our data is accounted for the fact that some people tend to like sequels more than others.","85216206":"Wow, these are pretty great! It makes perfect sense that *Toy Story 2* is the most similar movie to *Toy Story*. And most of the rest are animated kids movies with a similar computer-animated style.","d8889759":"Of course, it's *Toy Story*! I should have recognized that vector anywhere.\n\nOkay, I'm being facetious. It's hard to make anything of these vectors at this point. We never directed the model about how to use any particular embedding dimension. We left it alone to learn whatever representation it found useful.\n\nSo how do we check whether these representations are sane and coherent?\n\n## Vector similarity\n\nA simple way to test this is to look at how close or distant pairs of movies are in the embedding space. Embeddings can be thought of as a smart distance metric. If our embedding matrix is any good, it should map similar movies (like *Toy Story* and *Shrek*) to similar vectors.","d30d11b2":"# Your turn!\n\nHead over to [the Exercises notebook](https:\/\/www.kaggle.com\/kernels\/fork\/1598893) to get some hands-on practice working with exploring embeddings with gensim.\n### P.S...\n\nThis course is still in beta, so I'd love to get your feedback. If you have a moment to [fill out a super-short survey about this lesson](https:\/\/form.jotform.com\/82826473884269), I'd greatly appreciate it. You can also leave public feedback in the comments below, or on the [Learn Forum](https:\/\/www.kaggle.com\/learn-forum).\n","f5d0297a":"If you are familiar with these movies, you'll see that the missing ingredient that takes us from *Psycho* to *Scream* is comedy (and also late-90's-teen-movie-ness).","b07c7438":"# Semantic vector math\n\nThe [`most_similar`](https:\/\/radimrehurek.com\/gensim\/models\/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar) method optionally takes a second argument, `negative`. If we call `kv.most_similar(a, b)`, then instead of finding the vector closest to `a`, it will find the closest vector to `a - b`.\n\nWhy would you want to do that? It turns out that doing addition and subtraction of embedding vectors often gives surprisingly meaningful results. For example, how would you fill in the following equation?\n\n    Scream = Psycho + ________\n\n*Scream* and *Psycho* are similar in that they're violent, scary movies somewhere on the border between Horror and Thriller. The biggest difference is that *Scream* has elements of comedy. So I'd say *Scream* is what you'd get if you combined *Psycho* with a comedy.\n\nBut we can actually ask Gensim to fill in the blank for us via vector math (after some rearranging):\n\n    ________ = Scream - Psycho","59e8d4be":"The embedding weights are part of the model's internals, so we'll have to do a bit of digging around to access them. We'll grab the layer responsible for embedding movies, and use the `get_weights()` method to get its learned weights.","f29ea3dd":"As expected, much further apart.\n\n## Cosine Distance\n\nIf you check out [the docs for the `scipy.spatial` module](https:\/\/docs.scipy.org\/doc\/scipy-0.14.0\/reference\/spatial.distance.html), you'll see there are actually a *lot* of different measures of distance that people use for different tasks.\n\nWhen judging the similarity of embeddings, it's more common to use [cosine similarity](https:\/\/en.wikipedia.org\/wiki\/Cosine_similarity).\n\nIn brief, the cosine similarity of two vectors ranges from -1 to 1, and is a function of the *angle* between the vectors. If two vectors point in the same direction, their cosine similarity is 1. If they point in opposite directions, it's -1. If they're orthogonal (i.e. at right angles), their cosine similarity is 0.\n\nCosine distance is just defined as 1 minus the cosine similarity (and therefore ranges from 0 to 2).\n\nLet's calculate a couple cosine distances between movie vectors:","b7153dbb":"So it's learned something about 3-d animated kids flick, but maybe that was just a fluke. Let's look at the closest neighbours for a few more movies from a variety of genres:","dcfd9960":"Okay, so which movies are most similar to *Toy Story*?"}}