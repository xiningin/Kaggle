{"cell_type":{"dc5f5064":"code","bd60debb":"code","a072e196":"code","28cfff7b":"code","b23e08b4":"code","312cb02b":"code","11e7f60a":"code","f7c0e290":"markdown","97a075a0":"markdown","97acbdb8":"markdown","ddaeddeb":"markdown","9d65e5e1":"markdown","b7c9c7e0":"markdown","4fccb7fd":"markdown","748e7db2":"markdown"},"source":{"dc5f5064":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n%matplotlib inline\nimport time\nimport hashlib\nimport scipy\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans, Birch\nfrom sklearn.datasets import make_blobs\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd60debb":"x, y = make_blobs(750, n_features=2, centers=3)\n\nplt.scatter(x[:, 0], x[:, 1])\nplt.show()","a072e196":"def optimalK(data, maxClusters):\n    \"\"\"\n    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n    Params:\n        data: ndarry of shape (n_samples, n_features)\n        nrefs: number of sample reference datasets to create\n        maxClusters: Maximum number of clusters to test for\n    Returns: (gaps, optimalK)\n    \"\"\"\n    nrefs=3\n    gaps = np.zeros((len(range(1, maxClusters)),))\n    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n    for gap_index, k in enumerate(range(1, maxClusters)):\n\n        # Holder for reference dispersion results\n        refDisps = np.zeros(nrefs)\n\n        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n        for i in range(nrefs):\n            \n            # Create new random reference set\n            randomReference = np.random.random_sample(size=data.shape)\n            \n            # Fit to it\n            km = KMeans(k)\n            km.fit(randomReference)\n            \n            refDisp = km.inertia_\n            refDisps[i] = refDisp\n            \n        # Fit cluster to original data and create dispersion\n        km = KMeans(k)\n        km.fit(data)\n        \n        origDisp = km.inertia_\n\n        # Calculate gap statistic\n        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n\n        # Assign this loop's gap statistic to gaps\n        gaps[gap_index] = gap\n        \n        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n\n    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n","28cfff7b":"k, gapdf = optimalK(x,maxClusters=15)\nprint('Optimal k is: ', k)","b23e08b4":"plt.plot(gapdf.clusterCount, gapdf.gap, linewidth=3)\nplt.scatter(gapdf[gapdf.clusterCount == k].clusterCount, gapdf[gapdf.clusterCount == k].gap, s=250, c='r')\nplt.grid(True)\nplt.xlabel('Cluster Count')\nplt.ylabel('Gap Value')\nplt.title('Gap Values by Cluster Count')\nplt.show()","312cb02b":"km=KMeans(n_clusters=3,init='random', random_state=0)\ny_km=km.fit_predict(x,y)","11e7f60a":"plt.scatter(\n    x[y_km==0,0], x[y_km==0,1],\n    marker='s',\n    label='cluster  1'\n)\nplt.scatter(\n    x[y_km==1,0], x[y_km==1,1],\n    marker='o',\n    label='cluster  2'\n)\nplt.scatter(\n    x[y_km==2,0], x[y_km==2,1],\n    marker='v',\n    label='cluster  3'\n)\nplt.scatter(\n    km.cluster_centers_[:,0], km.cluster_centers_[:,1],\n    marker='*',s =250,\n    label='centroid'\n)\nplt.legend(scatterpoints=1)","f7c0e290":"# Results of the calculated gaps\n## The first peak is the optimal k value","97a075a0":"# Implementation of Gap Statistics","97acbdb8":"In this notebook we discuss what gap statistics is all about , how to implement it and an example.\nFirstly we try understand on earth what 'Gap' in gap statistics mean. As shown in the below example we see that there are 2 clusters formed and a graph of number of clusters vs within sum of squares.\n![image.png](attachment:392a836f-055c-4f67-8746-049e90d830fb.png)\n###### ***(Fig 1) Image courtesy: Robert Tibshirani's paper on gap statistics***\nHere we see from elbow method that '2' is the optimal number of clusters formed. In gap statistics a log of within sum of squres of data(log(W_data)) and a log of within sum of squraes of uniform data(log(W_uniform)) are considered. Below image shows the plot of log(W_data) and log(W_uniform) with respect to number of clusters. W_uniform is basically a simulated and averaged distribution of the within-cluster distances.\n\n![image.png](attachment:83df652f-b582-4f0a-b8d6-b0343588c55a.png)\n###### ***(Fig 2) Image courtesy: Robert Tibshirani's paper on gap statistics***\nNow gap is found out between these two curves and is ploted. Thats why the name gap statistics.\nThe formula for finding gap is\n![image.png](attachment:303d9caa-47a2-4313-98de-1ee214c04fd8.png)\n\n![image.png](attachment:a1db39e1-878a-4100-a95b-eb060dffc2b8.png)\n###### ***(Fig 3) Image courtesy: Robert Tibshirani's paper on gap statistics***\nTo find the optimal number of clusters we find the first peak that is '2' which is true according to fig 1.\nFor detailed explaination on math of gap statistics you can refer to [Trevor Hastie, Robert Tibshirani and Guenther Walther, Estimating the number of clusters in a data set via the gap statistics (2000)](https:\/\/doi.org\/10.1111\/1467-9868.00293) ","ddaeddeb":"# Applying the optimal k value to the data","9d65e5e1":"## Gap statistics using SciKit Learn","b7c9c7e0":"# Gap Statistics\nGap-Statistics was introduced by Robert Tibshirani in the year 2000 at Stanford.\nDetermining the ideal number of clusters in a dataset is one of the key tasks in the clustering exercise. After the elbow method gap-statistics is one of the most prominent ones used. The basic idea is to compute the goodness of clustering measure based on average dispersion compared to a reference distribution for an increasing number of clusters. If you find this notebook helpful then upvote and also comment.\n","4fccb7fd":"## Create Clusters","748e7db2":"# References:\n1. Estimating the number of clusters in a data set via the gap statistic Robert Tibshirani, Guenther Walther and Trevor Hastie Stanford University, USA\n2. https:\/\/towardsdatascience.com\/k-means-clustering-and-the-gap-statistics-4c5d414acd29\n3. https:\/\/github.com\/Mavengence\/Pattern_Analysis_SS20_FAU\/blob\/master\/Exercise_6.ipynb\n4. https:\/\/anaconda.org\/milesgranger\/gap-statistic\/notebook?version=2016.04.25.1430"}}