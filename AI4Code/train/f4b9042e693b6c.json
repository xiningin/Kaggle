{"cell_type":{"5c0ae8aa":"code","28e22d47":"code","19d5396a":"code","b127552a":"code","35d482ae":"code","845c1ede":"code","7cdd5480":"code","78a2b698":"code","c14d7ffe":"code","b99a15b9":"code","588b98cd":"code","910e1686":"code","a5f1fcd0":"markdown","176e2a5d":"markdown","36b798db":"markdown","c7b394ec":"markdown","ddb616f1":"markdown","7ec78d9f":"markdown","6adeea5d":"markdown","c21ca219":"markdown","61d32625":"markdown","547e79b1":"markdown","49cdd225":"markdown","edddefbf":"markdown","8a2a580f":"markdown","e3f8d9be":"markdown","db776f8a":"markdown"},"source":{"5c0ae8aa":"!curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py  > \/dev\/null\n!python pytorch-xla-env-setup.py --version 1.8.1 > \/dev\/null","28e22d47":"!pip install timm  > \/dev\/null","19d5396a":"import gc\nimport os\nimport time\nimport torch\nimport random\nimport albumentations\n\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nfrom PIL import Image\n\nimport torch.nn as nn\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\n\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.serialization as xser\n\n\nimport timm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nos.environ['XLA_USE_BF16']=\"1\"\nos.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'","b127552a":"FLAGS = {\n    \n    'fold': 0,\n    'seed': 999,\n    'model': 'resnext50_32x4d',\n    'pretrained': True,\n    'batch_size': 64,\n    'num_workers': 8,\n    'lr': 3e-4,\n    'epochs': 3\n}","35d482ae":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(FLAGS['seed'])","845c1ede":"# Using Ross Wightman's timm package\nclass TimmModels(nn.Module):\n    def __init__(self, model_name,pretrained=True, num_classes=1, inp_chan=1):\n        super(TimmModels, self).__init__()\n        self.m = timm.create_model(model_name,pretrained=pretrained,in_chans=inp_chan)\n        model_list = list(self.m.children())\n        model_list[-1] = nn.Linear(\n            in_features=model_list[-1].in_features, \n            out_features=num_classes, \n            bias=True\n        )\n        self.m = nn.Sequential(*model_list)\n        \n    def forward(self, image):\n        out = self.m(image)\n        return out","7cdd5480":"class SETIDataset:\n    def __init__(self, df, spatial=True, sixchan=True):\n        self.df = df\n        self.spatial = spatial\n        self.sixchan = sixchan\n        \n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        label = self.df.iloc[index].target\n        filename = self.df.iloc[index].path\n        data = np.load(filename).astype(np.float32)\n        if not self.sixchan: data = data[::2].astype(np.float32)\n        if self.spatial:\n            data = np.vstack(data).transpose((1, 0))\n            data = cv2.resize(data, dsize=(256,256))     \n            data_tensor = torch.tensor(data).float().unsqueeze(0)\n        else:\n            data = np.transpose(data, (1,2,0))\n            data = cv2.resize(data, dsize=(256,256))     \n            data = np.transpose(data, (2, 0, 1)).astype(np.float32)\n            data_tensor = torch.tensor(data).float()\n            \n        \n\n        return (data_tensor, torch.tensor(label))","78a2b698":"# create folds\ndf = pd.read_csv(\"..\/input\/seti-breakthrough-listen\/train_labels.csv\")\ndf['path'] = df['id'].apply(lambda x: '..\/input\/seti-breakthrough-listen\/'+'train\/'+x[0]+'\/'+x+'.npy') #adding the path for each id for easier processing\ndf[\"kfold\"] = -1    \ndf = df.sample(frac=1).reset_index(drop=True)\ny = df.target.values\nkf = model_selection.StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f\n\ndf.to_csv(\"train_folds.csv\", index=False)","c14d7ffe":"MX = xmp.MpModelWrapper(TimmModels(FLAGS['model'],pretrained=FLAGS['pretrained'], num_classes=1, inp_chan=1))","b99a15b9":"def train_loop_fn(data_loader, loss_fn, model, optimizer, device, scheduler=None):\n    model.train() # put model in training mode\n    for bi, d in enumerate(data_loader): # enumerate through the dataloader\n        \n        images = d[0] # obtain the ids\n        targets = d[1] # obtain the target\n\n        # pass image to model\n        optimizer.zero_grad()\n        outputs = model(images)\n        \n        # calculate loss\n        loss = loss_fn(outputs, targets.unsqueeze(1).float())\n        \n        # backpropagate\n        loss.backward()\n        \n        # Use PyTorch XLA optimizer stepping\n        xm.optimizer_step(optimizer)\n        \n        # Step the scheduler\n        if scheduler is not None: scheduler.step()\n    \n    # since the loss is on all 8 cores, reduce the loss values and print the average\n    loss_reduced = xm.mesh_reduce('loss_reduce',loss, lambda x: sum(x) \/ len(x)) \n    # master_print will only print once (not from all 8 cores)\n    xm.master_print(f'bi={bi}, train loss={loss_reduced}')\n        \n    model.eval() # put model in eval mode for later use\n    \ndef eval_loop_fn(data_loader, loss_fn, model, device):\n    fin_targets = []\n    fin_outputs = []\n    for bi, d in enumerate(data_loader): # enumerate through dataloader\n        \n        images = d[0] # obtain the ids\n        targets = d[1]# # obtain the targets\n        \n\n        # pass image to model\n        with torch.no_grad(): outputs = model(images)\n\n        # Add the outputs and targets to a list \n        targets_np = targets.cpu().detach().numpy().tolist()\n        outputs_np = outputs.cpu().detach().numpy().tolist()\n        fin_targets.extend(targets_np)\n        fin_outputs.extend(outputs_np)    \n        del targets_np, outputs_np\n        gc.collect() # delete for memory conservation\n                \n    o,t = np.array(fin_outputs), np.array(fin_targets)\n    \n    # calculate loss\n    loss = loss_fn(torch.tensor(o), torch.tensor(t).unsqueeze(1).float())\n    # since the loss is on all 8 cores, reduce the loss values and print the average\n    loss_reduced = xm.mesh_reduce('loss_reduce',loss, lambda x: sum(x) \/ len(x)) \n    # master_print will only print once (not from all 8 cores)\n    xm.master_print(f'val. loss={loss_reduced}')\n    \n    # since the output\/target values are on all 8 cores, reduce\/gather the values for metric calculation\n    o_reduced = xm.mesh_reduce('o_reduce', torch.tensor(o).to(device), torch.cat)\n    t_reduced = xm.mesh_reduce('t_reduce', torch.tensor(t).to(device), torch.cat)\n    \n    # metric calculation\n    auc = metrics.roc_auc_score(t_reduced.cpu(),o_reduced.cpu())\n        \n    xm.master_print(f'val. auc = {auc}')","588b98cd":"def run(rank, flags):\n    global FLAGS\n    torch.set_default_tensor_type('torch.FloatTensor')\n    \n    df = pd.read_csv(\"\/kaggle\/working\/train_folds.csv\") #read train csv created earlier\n    device = xm.xla_device() #device, will be different for each core on the TPU\n    xm.set_rng_state(FLAGS['seed'], device)\n    epochs = FLAGS['epochs']\n    fold = FLAGS['fold']\n    \n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    \n    train_dataset = SETIDataset(df_train)    \n    valid_dataset = SETIDataset(df_valid)\n\n    \n    # special sampler needed for distributed\/multi-core (divides dataset among the replicas\/cores\/devices)\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset,\n        num_replicas=xm.xrt_world_size(), #divide dataset among this many replicas\n        rank=xm.get_ordinal(), #which replica\/device\/core\n        shuffle=True)\n    \n    # define DataLoader with the defined sampler\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=FLAGS['batch_size'],\n        sampler=train_sampler,\n        num_workers=FLAGS['num_workers'],\n        drop_last=True)\n    \n    # same as train but with valid data\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n        valid_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False)\n\n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=FLAGS['batch_size'],\n        sampler=valid_sampler,\n        num_workers=FLAGS['num_workers'],\n        drop_last=False)\n    \n    \n    \n    train_loader = pl.MpDeviceLoader(train_loader, device) # puts the train data onto the current TPU core\n    valid_loader = pl.MpDeviceLoader(valid_loader, device) # puts the valid data onto the current TPU core\n    \n\n    model = MX.to(device) # put model onto the current TPU core\n    loss_fn = nn.BCEWithLogitsLoss()\n    optimizer = Adam(model.parameters(), lr=FLAGS['lr']*xm.xrt_world_size()) # often a good idea to scale the learning rate by number of cores\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader)*FLAGS['epochs']) #let's use a scheduler\n\n    gc.collect()\n    \n    xm.master_print(f'========== training fold {FLAGS[\"fold\"]} for {FLAGS[\"epochs\"]} epochs ==========')\n    for i in range(FLAGS['epochs']):\n        xm.master_print(f'EPOCH {i}:')\n        # train one epoch\n        train_loop_fn(train_loader, loss_fn, model, optimizer, device, scheduler)\n                \n        # validation one epoch\n        eval_loop_fn(valid_loader, loss_fn, model, device)\n\n        gc.collect()\n    \n    xm.rendezvous('save_model')\n    \n    xm.master_print('save model')\n    \n    xm.save(model.state_dict(), f'xla_trained_model_{FLAGS[\"epochs\"]}_epochs_fold_{FLAGS[\"fold\"]}.pth')","910e1686":"for i in range(5):\n    FLAGS['fold'] = i\n    start_time = time.time()\n    xmp.spawn(run, args=(FLAGS,), nprocs=8, start_method='fork')\n    print('time taken: ', time.time()-start_time)\n    print('==============================================================================')","a5f1fcd0":"## Training code","176e2a5d":"The below cell will install the [timm]() library, which is what we will use to define our models and get pretrained weights.","36b798db":"Let's now define our training and validationfunctions. ","c7b394ec":"Here, I define a class for the PyTorch Dataset (taken from my [earlier notebook](https:\/\/www.kaggle.com\/tanlikesmath\/seti-et-signal-detection-a-simple-cnn-starter\/notebook)).","ddb616f1":"Let's start training! To do so, we start by initializing the model. Let's make sure we initialize with the correct number of classes and input channels. We use the `xmp.MpModelWrapper` provided by PyTorch XLA to save memory when initializing the model.","7ec78d9f":"Here, I define a model class for the timm models.","6adeea5d":"Finally, we define a main function that we will run on each of the 8 cores of the TPU.","c21ca219":"## Installs & Imports\n\nThe below cell will install the PyTorch XLA package.","61d32625":"Here are all of our imports!","547e79b1":"These are the flags for training. When you fork (after you upvote of course, \ud83d\ude09), feel free to play around with these flags!","49cdd225":"# SETI PyTorch XLA\/TPU starter\n![image.png](attachment:image.png)\n\n### If you found this helpful, please give it an upvote!\n\n## Introduction\n\n[PyTorch XLA](https:\/\/pytorch.org\/xla\/master) is a PyTorch library for XLA support. XLA (Accelerated Linear Algebra) is a domain-specific compiler that was originally meant for compiling and accelerating TensorFlow models. However, other packages, like JAX and now PyTorch XLA can compile program with XLA to accelerate code. TPUs can be programmed with XLA programs and PyTorch XLA provides this interface with TPUs by compiling our PyTorch code as XLA programs to run on TPU devices.\n\nIn this kernel, I provide an in-depth look into how you can use PyTorch XLA to **train a PyTorch model on the TPU** for the SETI Breakthrough Listen - E.T. Signal Search competition.","edddefbf":"Let's train all 5 folds!","8a2a580f":"## Definitions\n\nNow let's define the necessary functions and variables needed for training.","e3f8d9be":"#### Now, **WE ARE DONE!**\n\nIf you enjoyed this kernel, please give it an upvote. If you have any questions or suggestions, please leave a comment!\n\nFeel free to check out my [EDA notebook](https:\/\/www.kaggle.com\/tanlikesmath\/seti-simple-eda-to-help-you-get-started) to learn more about the SETI E.T. Signal competition.\n\nAlso, check out my [related notebook](https:\/\/www.kaggle.com\/tanlikesmath\/the-ultimate-pytorch-tpu-tutorial-jigsaw-xlm-r) with more detailed information on PyTorch XLA\/TPU training.","db776f8a":"I now create my folds. Of course, you can replace with your own CV setup here."}}