{"cell_type":{"530fb448":"code","c283f56d":"code","e5ea120e":"code","1f2587e1":"code","d3d35039":"code","4e3ea134":"code","4a2f7088":"code","2570c82f":"code","9eb30a6e":"code","e4c9ddd2":"code","0449a123":"code","807a9193":"code","6600bd43":"code","37bfd9e4":"code","dce1e578":"code","c7f16af9":"code","a4d37977":"markdown","d6872408":"markdown","f667324e":"markdown"},"source":{"530fb448":"# Let's import some useful libraries\n\nimport pandas as pd  # \nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\nimport tensorflow as tf\nimport numpy as np\n","c283f56d":"# Read csv files \n\ntrain_df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","e5ea120e":"train_df.head()","1f2587e1":"# Let's extract Label column from our training data\n\ny = train_df['label']\ntrain_df.drop(columns = ['label'], axis = 1, inplace = True)","d3d35039":"# Let's see how many digit images we have in our training data\n\ny.value_counts()","4e3ea134":"train_df = train_df.values.reshape(-1,28,28,1)\ntest_df = test_df.values.reshape(-1,28,28,1)\n","4a2f7088":"# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\n# Index for iterating over images\npic_index = 0\n\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols * 4, nrows * 4)\n\n\nfor i in range(16):\n  # Set up subplot; subplot indices start at 1\n    sp = plt.subplot(nrows, ncols, i + 1)\n    plt.imshow(train_df[i][:,:,0])\n\nplt.show()","2570c82f":"y = to_categorical(y, num_classes = 10)\n","9eb30a6e":"# Split our data into training and validation set\n\nX_train, X_val, y_train, y_val = train_test_split(train_df, y, test_size = 0.1, random_state=2020, stratify = y)","e4c9ddd2":"# Define our CNN architecture\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(64, (7,7), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Dropout(0.4),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(512, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","0449a123":"model.summary()","807a9193":"from keras.preprocessing.image import ImageDataGenerator\n\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\nval_datagen = ImageDataGenerator(rescale=1.\/255)\n","6600bd43":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopper = EarlyStopping(monitor='val_accuracy', patience = 10, verbose=True, mode = \"max\" , restore_best_weights = True)\n\n\nhistory = model.fit_generator(\n        train_datagen.flow(X_train, y_train, batch_size = 100),\n        steps_per_epoch=378,\n        epochs=50,\n        validation_data=(X_val, y_val),\n        callbacks = [early_stopper]\n        )","37bfd9e4":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","dce1e578":"# Let's now predict results\nresults = model.predict(test_df)\n\n# We will select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results, name=\"Label\")","c7f16af9":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"CNN_MNIST_predictions.csv\",index=False)","a4d37977":"## One hot encoding of labels \n### We one hot encode our labels which are basically digits from 0 to 9. \n### For example, one hot encoding of digit 0 will be [1,0,0,0,0,0,0,0,0,0,0]\n","d6872408":"#### Let's visualize few images","f667324e":"###  Reshape our data\n\n#### We will reshape our 1-dimension vectors of 784 values into 28x28x1. As the MNIST images are grayscale, we will use channel = 1. If we would have RGB images, one has to use channel = 3.  "}}