{"cell_type":{"72877c39":"code","851909c3":"code","8c65291b":"code","d28239a9":"code","4c02bf2d":"code","49370ee0":"code","027b361a":"code","9aed80f9":"code","b7965f04":"code","741c5251":"code","4406c434":"code","6fdd261d":"markdown","4e5dbbb7":"markdown","772e8917":"markdown","5e5362e3":"markdown","c73ba6c6":"markdown","ef7ebcbe":"markdown","3d97d1b6":"markdown","5428f64f":"markdown","4aa86562":"markdown"},"source":{"72877c39":"import torch\nimport numpy as np\n\n####### HP\nnum_workers = 2\nbatch_size = 32\nvalid_size = 0.2\nnum_epochs = 10\nlr = 0.001\n\n# Check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n  print('CUDA is not available. Training on CPU...')\nelse:\n  print('CUDA is available. Training on GPU')","851909c3":"import torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import datasets\n\n# Transform train and test data\ntransform_train = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Loading train and test data\ntrain_data = datasets.ImageFolder('..\/input\/chest-xray-pneumonia\/chest_xray\/train',\n                                 transform = transform_train)\ntest_data = datasets.ImageFolder('..\/input\/chest-xray-pneumonia\/chest_xray\/test',\n                                transform = transform_test)\n\n# Create validation set\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size*num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# Define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# Create dataloaders\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size,\n                                         sampler = train_sampler,\n                                         num_workers = num_workers)\nvalidloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size,\n                                         sampler = valid_sampler,\n                                         num_workers = num_workers)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size = batch_size,\n                                        num_workers = num_workers)\n\n# Get the classes\nimport pathlib\nroot = pathlib.Path('..\/input\/chest-xray-pneumonia\/chest_xray\/train')\nclasses = sorted([j.name.split('\/')[-1] for j in root.iterdir()])\nprint(classes)","8c65291b":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef imshow(img):\n  '''\n  Function to un-normalize and display an image\n  '''\n  img = img\/2 + 0.5 # un-normalize\n  plt.imshow(np.transpose(img, (1, 2, 0))) # convert from tensor image\n  \n# Get a batch of training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# Plot the images from the batch, along with corresponding labels\nfig = plt.figure(figsize = (25, 4))\n\n# Display 20 images\nfor idx in np.arange(20):\n  ax = fig.add_subplot(2, 20\/2, idx+1, xticks = [], yticks = [])\n  imshow(images[idx])\n  ax.set_title(classes[labels[idx]])","d28239a9":"print(images.shape)","4c02bf2d":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass VGGNet (nn.Module):\n    def __init__(self):\n        super (VGGNet, self).__init__ ()\n        self.features = nn.Sequential (\n            nn.Conv2d (3, 64, 3, padding=1),  # Conv1\n            nn.BatchNorm2d(64),\n            nn.ReLU (True),\n            nn.Conv2d (64, 64, 3, padding=1),  # Conv2\n            nn.BatchNorm2d(64),\n            nn.ReLU (True),\n            nn.MaxPool2d (2, 2),  # Pool1\n            \n            nn.Conv2d (64, 128, 3, padding=1),  # Conv3\n            nn.BatchNorm2d(128),\n            nn.ReLU (True),\n            nn.Conv2d (128, 128, 3, padding=1),  # Conv4\n            nn.BatchNorm2d(128),\n            nn.ReLU (True),\n            nn.MaxPool2d (2, 2),  # Pool2\n            \n            nn.Conv2d (128, 256, 3, padding=1),  # Conv5\n            nn.BatchNorm2d(256),\n            nn.ReLU (True),\n            nn.Conv2d (256, 256, 3, padding=1),  # Conv6\n            nn.BatchNorm2d(256),\n            nn.ReLU (True),\n            nn.Conv2d (256, 256, 3, padding=1),  # Conv7\n            nn.BatchNorm2d(256),\n            nn.ReLU (True),\n            nn.MaxPool2d (2, 2),  # Pool3\n            \n            nn.Conv2d (256, 512, 3, padding=1),  # Conv8\n            nn.BatchNorm2d(512),\n            nn.ReLU (True),\n            nn.Conv2d (512, 512, 3, padding=1),  # Conv9\n            nn.BatchNorm2d(512),\n            nn.ReLU (True),\n            nn.Conv2d (512, 512, 3, padding=1),  # Conv10\n            nn.BatchNorm2d(512),\n            nn.ReLU (True),\n            nn.MaxPool2d (2, 2),  # Pool4\n            \n            nn.Conv2d (512, 512, 3, padding=1),  # Conv11\n            nn.BatchNorm2d(512),\n            nn.ReLU (True),\n            nn.Conv2d (512, 512, 3, padding=1),  # Conv12\n            nn.BatchNorm2d(512),\n            nn.ReLU (True),\n            nn.Conv2d (512, 512, 3, padding=1),  # Conv13\n            nn.BatchNorm2d(512),\n            nn.ReLU (True),\n            nn.MaxPool2d (2, 2)   # Pool5\n        )\n        \n        self.avgpool=nn.AdaptiveAvgPool2d(output_size=(7, 7))\n\n        self.classifier = nn.Sequential (\n            nn.Linear (7 * 7 * 512, 4096),\n            nn.ReLU (True),\n            nn.Dropout (0.5),\n            nn.Linear (4096, 4096),\n            nn.ReLU (True),\n            nn.Dropout (0.5),\n            nn.Linear (4096, 6)\n        )\n\n    def forward(self, x):\n        x = self.features (x)\n        x = self.avgpool(x)\n        x = x.view (x.size (0), -1)\n        x = self.classifier (x)\n        \n        return x\n\nmodel = VGGNet()\n\n# Move tensors to GPU if CUDA is available\nif train_on_gpu:\n    model.cuda ()","49370ee0":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr = lr, momentum = 0.9)","027b361a":"valid_loss_min = np.Inf # track the change in validation loss\n\ntrain_losses = []\nvalid_losses = []\n\nfor epoch in range(1, num_epochs+1):\n  # keep track of training and validation loss\n  train_loss = 0.0\n  valid_loss = 0.0\n  \n  #------------------\n  # train the model\n  #------------------\n  model.train()\n  for data, target in trainloader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n      data, target = data.cuda(), target.cuda()\n    \n    # clear the gradients of all optimized variables\n    optimizer.zero_grad()\n    \n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    \n    # calculate batch loss\n    loss = criterion(output, target)\n    \n    # backward pass: compute gradient of the loss with respect to the \n    # model parameters\n    loss.backward()\n    \n    # perform parameter update\n    optimizer.step()\n    \n    # update training loss\n    train_loss += loss.item()*data.size(0)\n    \n  #------------------\n  # validate the model\n  #------------------\n  model.eval()\n  for data, target in validloader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n      data, target = data.cuda(), target.cuda()\n    \n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    \n    # calculate the batch loss\n    loss = criterion(output, target)\n    \n    # update average validation loss\n    valid_loss += loss.item()*data.size(0)\n    \n  # calculate average losses\n  train_loss = train_loss\/len(trainloader.sampler)\n  valid_loss = valid_loss\/len(validloader.sampler)\n  train_losses.append(train_loss)\n  valid_losses.append(valid_loss)\n  \n  # print training and validation stats\n  print('Epoch: {} \\tTraining Loss: {:.4f} \\tValidation loss: {:.4f}'.format(\n        epoch, train_loss, valid_loss))\n  \n  # save model if validation loss has decreased\n  if valid_loss <= valid_loss_min:\n    print('Validation loss decreased ({:.4f} -> {:.4f}) \\n Saving model...'.format(\n          valid_loss_min, valid_loss))\n    torch.save(model.state_dict(), 'intel_image_net.pt')\n    valid_loss_min = valid_loss","9aed80f9":"plt.plot(train_losses, label = 'Training loss')\nplt.plot(valid_losses, label = 'Validation loss')\nplt.legend(frameon = False)\nplt.show()","b7965f04":"model.load_state_dict(torch.load('intel_image_net.pt'))","741c5251":"test_loss = 0.0\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\nmodel.eval()\nfor data, target in testloader:\n  if train_on_gpu:\n    data, target = data.cuda(), target.cuda()\n    \n  output = model(data)\n  loss = criterion(output, target)\n  \n  test_loss += loss.item()*data.size(0)\n  _, pred = torch.max(output, 1)\n  \n  correct_tensor = pred.eq(target.data.view_as(pred))\n  correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n  \n  for i in range(10):\n    label = target.data[i]\n    class_correct[label] += correct[i].item()\n    class_total[label] += 1\n    \ntest_loss = test_loss \/ len(testloader.dataset)\nprint('Test loss: {:.4f}\\n'.format(test_loss))\n\nfor i in range(2):\n  if class_total[i] > 0:\n    print('Test accuracy of %5s: %2d%% (%2d\/%2d)' % (\n          classes[i], 100*class_correct[i] \/ class_total[i], \n          np.sum(class_correct[i]), np.sum(class_total[i])))\n  else:\n    print('Test accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100.*np.sum(class_correct)\/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","4406c434":"transform_pred = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\npred_data = datasets.ImageFolder('..\/input\/chest-xray-pneumonia\/chest_xray\/val',\n                                transform = transform_pred)\n\npredloader = torch.utils.data.DataLoader(pred_data, batch_size = batch_size,\n                                        num_workers = num_workers)\n\ndataiter = iter(predloader)\nimages, no_labels = dataiter.next()\nimages.numpy()\n\nif train_on_gpu:\n  images = images.cuda()\n\noutput = model(images)\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# Visualize predicted labels\nfig = plt.figure(figsize = (25,4))\nfor idx in np.arange(16):\n  ax = fig.add_subplot(2, 16\/2, idx + 1, xticks = [], yticks = [])\n  imshow(images.cpu()[idx])\n  ax.set_title('{}'.format(classes[preds[idx]]))","6fdd261d":"**Specify Loss Function and Optimizer**","4e5dbbb7":"**Train the model**","772e8917":" **Check for CUDA**","5e5362e3":"**Test the trained network**","c73ba6c6":"**Load the model with the lowest validation loss**","ef7ebcbe":"**Load the data**","3d97d1b6":"**Create the Network Architecture**","5428f64f":"**Prediction on the pred data set**\n\n**Create a subfolder containing all the unlabeled images in seg_pred in order for PyTorch's ImageFolder to work.**","4aa86562":"**Visualize a batch of training data**"}}