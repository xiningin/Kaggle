{"cell_type":{"9eac1cf9":"code","4298adce":"code","91282a30":"code","6ef6c6be":"code","788fc5b1":"code","b66f31ec":"code","62e54e6c":"code","b9f66043":"code","565170bc":"code","a33814d6":"code","72f15183":"code","85851f05":"code","18f432f6":"code","72a1e4e4":"code","f6be5935":"code","bd8e2e9e":"code","0e00459c":"code","7a1b613a":"code","b139a8fd":"code","495c82cf":"code","98cb5919":"code","a6c31d10":"code","e4ce4019":"code","f9027f83":"code","229cf26c":"code","4fa262d8":"code","2f774434":"code","b50179de":"code","3302f33f":"code","2f17d031":"code","4175ee79":"code","5b5b6084":"code","bceec6ce":"code","c7c9c25f":"code","2ed07de0":"code","6244b513":"code","bb09804f":"code","e9d5c35e":"code","9afbd832":"markdown","1bf97ef6":"markdown","e817e9fb":"markdown","693f75db":"markdown","f3555ffe":"markdown","0ae9910d":"markdown","317ba217":"markdown","2703aa00":"markdown","86f68aab":"markdown","d8a6861f":"markdown","3917d8b3":"markdown","8e9fe682":"markdown","8c2dfef2":"markdown","1a319145":"markdown","0b8e703b":"markdown","e1747dd4":"markdown","e966544d":"markdown","b6237a23":"markdown","84b72b1c":"markdown","585f2eab":"markdown","b8195cb3":"markdown","2a37edb2":"markdown","bcd5d285":"markdown","8cc16012":"markdown","bb43fe94":"markdown","b8e06248":"markdown"},"source":{"9eac1cf9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4298adce":"data = pd.read_csv('..\/input\/life-expectancy-who\/Life Expectancy Data.csv')","91282a30":"data.head()","6ef6c6be":"data.shape","788fc5b1":"data.info()","b66f31ec":"data.isnull().sum()","62e54e6c":"def missing_values(df):\n    missing=pd.DataFrame(df.isnull().sum()\/len(data))*100\n    missing.columns = ['missing_values(%)']\n    missing['missing_values(numbers)'] = pd.DataFrame(df.isnull().sum())\n    return missing.sort_values(by='missing_values(%)', ascending=False)\nmissing_values(data)","b9f66043":"# Renaming some column names as they contain trailing spaces.\ndata.rename(columns={\" BMI \":\"BMI\",\"Life expectancy \":\"Life_Expectancy\",\"Adult Mortality\":\"Adult_Mortality\",\n                   \"infant deaths\":\"Infant_Deaths\",\"percentage expenditure\":\"Percentage_Exp\",\"Hepatitis B\":\"HepatitisB\",\n                  \"Measles \":\"Measles\",\"under-five deaths \":\"Under_Five_Deaths\",\"Diphtheria \":\"Diphtheria\",\n                  \" HIV\/AIDS\":\"HIV\/AIDS\",\" thinness  1-19 years\":\"thinness_1to19_years\",\" thinness 5-9 years\":\"thinness_5to9_years\",\"Income composition of resources\":\"Income_Comp_Of_Resources\",\n                   \"Total expenditure\":\"Tot_Exp\"},inplace=True)","565170bc":"data.head()","a33814d6":"for label,content in data.items():\n    if pd.isnull(content).sum():\n        data[label] = content.fillna(content.median())","72f15183":"missing_values(data)","85851f05":"data=pd.get_dummies(data, columns=['Country','Status'])","18f432f6":"data.head()","72a1e4e4":"X = data.drop('Life_Expectancy', axis=1)\ny = data['Life_Expectancy']","f6be5935":"X.head()","bd8e2e9e":"y.head()","0e00459c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state=42)","7a1b613a":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","b139a8fd":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor()\ngbr.fit(X_train, y_train)\ngbr_pred = gbr.predict(X_test)\nprint('R2 score is : {:.2f}'.format(r2_score(y_test, gbr_pred)))","495c82cf":"df = data.copy()","98cb5919":"Q1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\noutliers = pd.DataFrame(((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum())\noutliers1= outliers[:60]\noutliers2 = outliers[60:120]\noutliers3 = outliers[120:180]\noutliers4 = outliers[180:]\noutliers1,outliers2,outliers3,outliers4","a6c31d10":"from sklearn.ensemble import RandomForestRegressor","e4ce4019":"rf = RandomForestRegressor()","f9027f83":"rf.fit(X_train, y_train)","229cf26c":"rf_pred=rf.predict(X_test)","4fa262d8":"print('R2 score is : {:.2f}'.format(r2_score(y_test, rf_pred)))","2f774434":"rf.feature_importances_","b50179de":"import seaborn as sns\n# Helper function for plotting feature importance\ndef plot_features(columns, importances, n=10):\n    df = (pd.DataFrame({\"features\": columns,\n                        \"feature_importance\": importances})\n          .sort_values(\"feature_importance\", ascending=False)\n          .reset_index(drop=True))\n    \n    sns.barplot(x=\"feature_importance\",\n                y=\"features\",\n                data=df[:n],\n                orient=\"h\")","3302f33f":"plot_features(X_train.columns, rf.feature_importances_)","2f17d031":"new_data = data[['HIV\/AIDS','Adult_Mortality','Income_Comp_Of_Resources','Schooling',\n      'BMI','thinness_5to9_years','Under_Five_Deaths','Infant_Deaths',\n      'thinness_1to19_years','Year']]","4175ee79":"new_data","5b5b6084":"X_train, X_test, y_train, y_test = train_test_split(new_data,y, test_size=0.2, random_state=42)","bceec6ce":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","c7c9c25f":"rf.fit(X_train, y_train)","2ed07de0":"rf_pred_new = rf.predict(X_test)","6244b513":"print('R2 score is : {:.2f}'.format(r2_score(y_test, rf_pred_new)))","bb09804f":"rf_pred_new = pd.DataFrame(rf_pred_new)","e9d5c35e":"rf_pred_new.to_csv('predictions.csv')","9afbd832":"Not bad. But wait a minute, we've not yet checked for outliers.\n\nBut first, let's make a copy of our dataframe.","1bf97ef6":"Data is not too big.\n\nLet's take a look at what the data tells us.","e817e9fb":"Woaahhh ! That looks overwhelming.\n\nLet's try and visualize it, so that we can understand it better.","693f75db":"Now let's evaluate on new data.","f3555ffe":"Hmmm, looks clean enough now let's take care of these missing values.","0ae9910d":"This did really better compared to `GradientBoostingRegressor`.\n\nNow let's take a look at important features according to our model.","317ba217":"Now let's split our model into training & test set.","2703aa00":"Wow ! Almost all of the features have outliers.\n\nSo instead of taking care of these outliers, let's use `RandomForestRegressor`, since they're really robust and immune to outliers. ","86f68aab":"Worked like a charm.","d8a6861f":"Let's take a look at the dimension of the data.","3917d8b3":"Now let's rename the column names, because they have spaces between the words.","8e9fe682":"Let's take a look at our data now.","8c2dfef2":"Now here comes the dilemma, choosing the right estimator. But lucky for us **scikit-learn** is kind enough to provide us with a map, that'll help us choose the right estimator.\nYou can find it [here](https:\/\/scikit-learn.org\/stable\/tutorial\/machine_learning_map\/index.html)","1a319145":"Hmmm, top 10 features according to our model are : \n                                                    \n`'HIV\/AIDS',\n'Income_Comp_Of_Resources',\n'Adult_Mortality',\n'BMI',\n'Under_Five_Deaths',\n'Schooling',\n'thinness_5to9_years',\n'Year',\n'Alcohol',\n'thinness_1to19_years'`.\n                                                    \nSo let's just use these 10 features and see if the model still works good.\n\nBecause as a data scientist, we should always look at ways to cut down computational costs. And that can happen when you reduce the dimension of your data.","0b8e703b":"Let's also see if there are any missing values.","e1747dd4":"Looks like there are 2 features which are categorical in nature.","e966544d":"Now while this gives the missing values, it's not that good when it comes to readability.\nAnd as Data Scientists, we should also be careful that our code looks clean and readable.\nSo, let's make a function that throws a more clean readable output.","b6237a23":"Let's look at the top 10 features.","84b72b1c":"Let's check if we have successfully replaced missing values with ***`median()`***","585f2eab":"Let's evaluate our model.","b8195cb3":"Beautiful, all our missing values have been taken care of.\n\nNow let's take care of categorical features.\nWhile there are multipe ways of taking care of categorical features, I've decided to use **`pd.get_dummies()`** function from **`pandas`** library. \nLet's see how that works.\n\nThere are only two categorical features.","2a37edb2":"Nice, looks good.\nNow let's divide the data into X & y, so that we can split the data into training & test sets.","bcd5d285":"Now I'll first try with **`GradientBoostingRegressor`**\nBut first let's import our evaluation metrics","8cc16012":"Now let's re-train our model on this new data.","bb43fe94":"Everything look's good.","b8e06248":"Now taking care of missing values is always a pickle, because we'd be uncertain of choosing the values that are going to replace missing values. \nNow that depends upon the data.\n\nIf the feature that has missing values also has outliers, it's better to replace missing values with ***`median()`***.\nIf there are no outliers then go ahead and use ***`mean()`*** of the feature to replace missing values.\nNow while this holds good for numerical data, in categorical data we can maybe use ***`mode()`*** of that feature to fill the missing values."}}