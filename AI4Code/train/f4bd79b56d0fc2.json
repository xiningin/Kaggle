{"cell_type":{"9f50d5af":"code","20560851":"code","19cb8e13":"code","c8730701":"code","86181958":"code","d7d4fee4":"code","8974a155":"code","e23d926c":"code","ac20d05a":"code","3a1cd9d3":"code","a4ccdd9c":"code","ce4e3f7b":"code","80ba534f":"code","de7b4e56":"code","af1274a8":"code","ba1dddca":"code","c2fb30a7":"code","85fdb133":"code","6186ab52":"code","48295031":"code","c7b225bf":"code","40fabe29":"code","f05a1103":"markdown","99aa4ff8":"markdown","04e4b033":"markdown"},"source":{"9f50d5af":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)  \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20560851":"import h2o\nimport pandas as pd\nfrom h2o.automl import H2OAutoML, get_leaderboard\nfrom sklearn.model_selection import StratifiedShuffleSplit","19cb8e13":"df = pd.read_csv('\/kaggle\/input\/auto-insurance-claims-data\/insurance_claims.csv')\n\nprint(df.shape)\ndf.head()","c8730701":"df.isnull().sum()","86181958":"# drop column _c39 because it's null\n\ndf = df.drop(['_c39'], axis = 1)","d7d4fee4":"df.dtypes","8974a155":"# Set policy_bind_date type as date\ndf['policy_bind_date'] = pd.to_datetime(df['policy_bind_date'])\ndf['incident_date'] = pd.to_datetime(df['incident_date'])","e23d926c":"# How long before accident\ndf['incident_date2policy_bind_date'] = (df['incident_date'] - df['policy_bind_date']).dt.days","ac20d05a":"# Dummies columns\n                       \npolicy_state_dummies = pd.get_dummies(df['policy_state'], drop_first=True, prefix='policy_state')\nincident_type_dummies = pd.get_dummies(df['incident_type'], drop_first=True, prefix='incident_type')\ninsured_zip_dummies = pd.get_dummies(df['insured_zip'], drop_first=True, prefix='insured_zip')\ninsured_education_level_dummies = pd.get_dummies(df['insured_education_level'], drop_first=True, prefix='insured_education_level')\ninsured_sex_dummies = pd.get_dummies(df['insured_sex'], drop_first=True, prefix='insured_sex')\ninsured_occupation_dummies = pd.get_dummies(df['insured_occupation'], drop_first=True, prefix='insured_occupation')\ninsured_hobbies_dummies = pd.get_dummies(df['insured_hobbies'], drop_first=True, prefix='insured_hobbies')\ninsured_relationship_dummies = pd.get_dummies(df['insured_relationship'], drop_first=True, prefix='insured_relationship')\nincident_severity_dummies = pd.get_dummies(df['incident_severity'], drop_first=True, prefix='incident_severity')\nauthorities_contacted_dummies = pd.get_dummies(df['authorities_contacted'], drop_first=True, prefix='authorities_contacted')\nincident_city_dummies = pd.get_dummies(df['incident_city'], drop_first=True, prefix='incident_city')\nauto_make_dummies = pd.get_dummies(df['auto_make'], drop_first=True, prefix='auto_make')\n\n\ncollision_type_dummies = pd.get_dummies(df['collision_type'].replace('?','missing'), drop_first=True, prefix='collision_type')\nproperty_damage_dummies = pd.get_dummies(df['property_damage'].replace('?','missing'), drop_first=True, prefix='property_damage')\npolice_report_available_dummies = pd.get_dummies(df['police_report_available'].replace('?','missing'), drop_first=True, prefix='police_report_available')\n\n# set the target\ntarget_cols = pd.get_dummies(df['fraud_reported'], drop_first=True).astype(str)\ntarget_cols.columns = ['target']","3a1cd9d3":"# Drop unuse columns\n\ndrop_cols = ['policy_number','policy_bind_date','policy_csl','incident_date','auto_make','incident_location']\ndummies_cols = ['insured_zip','insured_education_level','insured_sex','insured_occupation','insured_hobbies','insured_relationship','incident_type',\n 'incident_severity','authorities_contacted','incident_city','auto_model','collision_type','property_damage','fraud_reported',\n               'police_report_available','policy_state','incident_state']\n\ndf = df.drop(drop_cols+dummies_cols, axis=1)","a4ccdd9c":"df.dtypes","ce4e3f7b":"# Add dummies to data frame\ndummies_df = [policy_state_dummies,insured_zip_dummies,insured_education_level_dummies,insured_sex_dummies,insured_occupation_dummies,\n             insured_hobbies_dummies,insured_relationship_dummies,incident_severity_dummies,authorities_contacted_dummies,\n             auto_make_dummies,collision_type_dummies,property_damage_dummies,police_report_available_dummies, target_cols]\n\ndf = pd.concat([df] + dummies_df, axis=1)","80ba534f":"df.shape","de7b4e56":"df.head()","af1274a8":"# Init H20\nh2o.init()","ba1dddca":"# train text split\nseed = 56\n\nhf = h2o.H2OFrame(df)\nhf['target'] =hf['target'].asfactor()\n\ntrain,test,valid = hf.split_frame(ratios=[0.7, 0.15])","c2fb30a7":"hf.shape","85fdb133":"\ntarget_label = 'target'\nfeatures_list = [x for x in hf.columns if x != target_label]","6186ab52":"# Train model\naml = H2OAutoML(max_runtime_secs=60 * 30, include_algos=[\"XGBoost\"], seed=seed)\n\naml.train(x=features_list, y=target_label, training_frame=train)","48295031":"h2o_result = get_leaderboard(aml, extra_columns='ALL').as_data_frame().loc[0]\n\nmodel_name = h2o_result['model_id']\nbest_model = h2o.get_model(model_name)\n\npreds = best_model.predict(test[:-1])\nglobal_predict_res = preds.as_data_frame()\nrun_time = h2o_result['training_time_ms']","c7b225bf":"preds","40fabe29":"h2o_result.auc","f05a1103":"Model","99aa4ff8":"Prepare data","04e4b033":"Data overview"}}