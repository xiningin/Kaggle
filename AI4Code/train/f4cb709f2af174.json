{"cell_type":{"b02b8568":"code","e26237bc":"code","f003ba57":"code","dd3f475d":"code","a8e601ad":"code","f98693a4":"code","57ff4fbf":"code","ea652b9d":"code","098da3d3":"code","bcb09769":"code","5a7d98e0":"code","2bc2db81":"code","f1c0e5ac":"markdown","3d705eca":"markdown","0c11b83b":"markdown","8b83e37d":"markdown","217d2ac4":"markdown"},"source":{"b02b8568":"import numpy as np\nimport regex as re\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport nltk\nimport re\nimport csv\nimport seaborn as sns","e26237bc":"Col_used = ['created_at_tweet', 'id_tweet', 'full_text', 'retweet_count',\n                'favorite_count', 'reply_count', 'name', 'screen_name', 'location']","f003ba57":"D1=pd.read_csv('data1.csv',usecols=Col_used)\nD2=pd.read_csv('SAP21786-tweets.csv', usecols=['date', 'id', 'content', 'retweetCount',\n                                                              'likeCount', 'replyCount', 'user'])\n\nD2.rename({'date': 'created_at_tweet', 'content': 'full_text', 'id': 'id_tweet', 'replyCount': 'reply_count',\n             'retweetCount': 'retweet_count', 'likeCount': 'favorite_count'}, inplace=True, axis=1)\n\n\nD3= pd.read_csv('tweets_pakistan-AhmedAdnan-11177.csv', usecols=['username', 'date', 'time', 'tweet',\n                                                                               'likes_count', 'retweets_count',\n                                                                               'replies_count'])\n\nD3.rename(\n    {'username': 'name', 'tweet': 'full_text', 'likes_count': 'favorite_count', 'retweets_count': 'retweet_count',\n     'replies_count': 'reply_count'}, inplace=True, axis=1)\n\n\nD4 = pd.read_excel('AmmarKhalil_19689_DeepLearning_finalPaper_part1.xlsx',\n                     usecols=['Tweet Id', 'Text', 'Name', 'Screen Name', 'Location',\n                              'Created At', 'Favorites',\n                              'Retweets'])\nD4.rename(\n    {'Tweet Id': 'id_tweet', 'Text': 'full_text', 'Name': 'name', 'Screen Name': 'screen_name', 'Location': 'location',\n     'Created At': 'created_at_tweet', 'Favorites': 'favorite_count',\n     'Retweets': 'retweet_count'}, inplace=True, axis=1)\n\nD5 = pd.read_csv('twitter dataset.csv',\n                   usecols=Col_used)\n\nD6 = pd.read_csv('tweets_new.csv', usecols=['date', 'content', 'replyCount', 'likeCount'])\nD6.rename(\n    {'date': 'created_at_tweet', 'content': 'full_text', 'replyCount': 'reply_count', 'likeCount': 'favorite_count'},\n    inplace=True, axis=1)\n\nD7 = pd.read_csv('Tweets_by_Faizan_Hussain_21409.csv',\n                   usecols=['User', 'PostDate', 'TweetText', 'ReplyCount', 'RetweetCount',\n                            'LikeCount', 'City'])\nD7.rename(\n    {'User': 'name', 'PostDate': 'created_at_tweet', 'TweetText': 'full_text', 'ReplyCount': 'reply_count',\n     'RetweetCount': 'retweet_count',\n     'LikeCount': 'favorite_count', 'City': 'location'}, inplace=True, axis=1)\n\n\nD8 = pd.read_csv('tweets.csv', usecols=['created_at_tweet',\n                                                     'id_tweet',\n                                                     'full_text',\n                                                     'retweet_count',\n                                                     'favorite_count',\n                                                     'reply_count',\n                                                     'location'])\n\n\nD9 = pd.read_csv('tweets_pakistan.csv',\n                   usecols=['created_at_tweet',\n                            'id_tweet',\n                            'full_text',\n                            'retweet_count',\n                            'favorite_count',\n                            'reply_count',\n                            'location'])\n\n\n\nD10 = pd.read_excel('FinalExam_Part1_deeplearning_Komalbatool_30342_4July21.xlsx',\n                     usecols=['Tweet Id', 'Tweet', 'Tweet Created At',\n                              'Name', 'Screen Name', 'Location',\n                              'Favorites.1', 'Retweets', ])\nD10.rename(\n    {'Tweet Id': 'id_tweet', 'Tweet': 'full_text', 'Tweet Created At': 'created_at_tweet',\n     'Name': 'name', 'Screen Name': 'screen_name', 'Location': 'location',\n     'Favorites.1': 'favorite_count', 'Retweets': 'retweet_count'}, inplace=True, axis=1)\n\nD11 = pd.read_excel('Twitter Dataset (Mohsin Suleman 25752).xlsx',\n                     usecols=['Vertex 1',\n                              'Tweet',\n                              'Tweet Date (UTC)'])\nD11.rename(\n    {'Vertex 1': 'name',\n     'Tweet': 'full_text',\n     'Tweet Date (UTC)': 'created_at_tweet'}, inplace=True, axis=1)\n\n\n\nD12 = pd.read_csv('Final Paper - Part a[M.Sohail(24721)].csv',\n                   usecols=Col_used)\n\n\n\nD13 = pd.read_csv('dataset.csv',\n                   usecols=['date', 'content'])\nD13.rename(\n    {'date': 'created_at_tweet', 'content': 'full_text'}, inplace=True, axis=1)\n\n\n\nD14 = pd.read_excel('tweets_datasete.xlsx',\n                     usecols=['Author Name', 'Screen Name', 'Created At',\n                              'Location', 'Tweet'])\nD14.rename(\n    {'Author Name': 'name', 'Screen Name': 'screen_name', 'Created At': 'created_at_tweet',\n     'Location': 'location', 'Tweet': 'full_text'}, inplace=True, axis=1)\n\n\n\nD15 = pd.read_csv('Final paper -part a(21785).csv',\n                   usecols=['id', 'created_at',\n                            'username', 'name', 'tweet', 'replies_count', 'retweets_count', 'likes_count',\n                            ])\nD15.rename(\n    {'id': 'id_tweet', 'created_at': 'created_at_tweet',\n     'username': 'name', 'name': 'screen_name', 'tweet': 'full_text', 'replies_count': 'reply_count',\n     'retweets_count': 'retweet_count', 'likes_count': 'favorite_count'}, inplace=True, axis=1)\n\n\nD16 = pd.read_csv('tweets_data.csv',\n                   usecols=Col_used)\nD16.rename(\n    {'Vertex 1': 'name',\n     'Tweet': 'full_text',\n     'Tweet Date (UTC)': 'created_at_tweet'}, inplace=True, axis=1)\n\n\n\nD17 = pd.read_csv('Paper Part 1 24714.csv',\n                   usecols=['screen_name', 'created_at', 'text', 'retweet_count', 'favorite_count',\n                            'location'])\nD17.rename(\n    {'created_at': 'created_at_tweet', 'text': 'full_text',\n     }, inplace=True, axis=1)\n\n\nD18 = pd.read_excel('Zeshan Masood SAP_ID 21709.xlsx', sheet_name=1,\n                     usecols=['date', 'username', 'tweet',\n                              'name',\n                              'retweet', 'nlikes'])\nD18.rename(\n    {'date': 'created_at_tweet', 'username': 'name', 'tweet': 'full_text',\n     'name': 'screen_name',\n     'retweet': 'retweet_count', 'nlikes': 'favorite_count'\n     }, inplace=True, axis=1)\n","dd3f475d":"tweets=pd.concat([D1,D2,D3,D4,D5,D6,D7,D8,D9,D10,D11,D12,D13,D14,D15,D16,D17,D18],ignore_index=True)","a8e601ad":"tweets.head()","f98693a4":"tweets.drop_duplicates(subset =\"full_text\",\n                     keep = False, inplace = True)","57ff4fbf":"tweets.columns","ea652b9d":"#PREPROCESSING USING REGULAR EXPRESSION\ndef clean_tweets(tweet):\n    \n    # remove URL\n#    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n    \n    # Remove usernames\n    tweet = re.sub(r\"@[^\\s]+[\\s]?\",'',tweet)\n    \n    # remove special characters \n#    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n    \n    \n    # remove Numbers\n    tweet = re.sub('[0-9]', '', tweet)\n    \n    \n    tweet = re.sub(r\"^https:\/\/t.co\/[a-zA-Z0-9]*\\s\", \" \", tweet)\n    tweet = re.sub(r\"\\s+https:\/\/t.co\/[a-zA-Z0-9]*\\s\", \" \", tweet)\n    tweet = re.sub(r\"\\s+https:\/\/t.co\/[a-zA-Z0-9]*$\", \" \", tweet)\n    tweet = tweet.lower()\n    tweet = re.sub(r\"that's\",\"that is\",tweet)\n    tweet = re.sub(r\"there's\",\"there is\",tweet)\n    tweet = re.sub(r\"what's\",\"what is\",tweet)\n    tweet = re.sub(r\"where's\",\"where is\",tweet)\n    tweet = re.sub(r\"it's\",\"it is\",tweet)\n    tweet = re.sub(r\"who's\",\"who is\",tweet)\n    tweet = re.sub(r\"i'm\",\"i am\",tweet)\n    tweet = re.sub(r\"she's\",\"she is\",tweet)\n    tweet = re.sub(r\"he's\",\"he is\",tweet)\n    tweet = re.sub(r\"they're\",\"they are\",tweet)\n    tweet = re.sub(r\"who're\",\"who are\",tweet)\n    tweet = re.sub(r\"ain't\",\"am not\",tweet)\n    tweet = re.sub(r\"wouldn't\",\"would not\",tweet)\n    tweet = re.sub(r\"shouldn't\",\"should not\",tweet)\n    tweet = re.sub(r\"can't\",\"can not\",tweet)\n    tweet = re.sub(r\"couldn't\",\"could not\",tweet)\n    tweet = re.sub(r\"won't\",\"will not\",tweet)\n#    tweet = re.sub(r\"\\W\",\" \",tweet)\n    tweet = re.sub(r\"\\d\",\" \",tweet)\n    tweet = re.sub(r\"\\s+[a-z]\\s+\",\" \",tweet)\n    tweet = re.sub(r\"\\s+[a-z]$\",\" \",tweet)\n    tweet = re.sub(r\"^[a-z]\\s+\",\" \",tweet)\n    tweet = re.sub(r\"\\s+\",\" \",tweet)\n    \n    \n    return tweet\n\n\n\n","098da3d3":"tweets['full_text'] = tweets['full_text'].apply(clean_tweets)","bcb09769":"tweets.head()","5a7d98e0":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nimport pandas as pd\ncomment_words = ''\nstopwords = set(STOPWORDS)\n\nfor val in tweets.full_text:\n     \n    # typecaste each val to string\n    val = str(val)\n \n    # split the value\n    tokens = val.split()\n     \n    # Converts each token into lowercase\n    for i in range(len(tokens)):\n        tokens[i] = tokens[i].lower()\n     \n    comment_words += \" \".join(tokens)+\" \"\n \nwordcloud = WordCloud(width = 800, height = 800,background_color ='black',stopwords = stopwords,min_font_size = 10).generate(comment_words)\n \n# plot the WordCloud image                      \nplt.figure(figsize = (15, 15), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n \nplt.show()","2bc2db81":"# import emoji\n\ne = {x for c in tweets['full_text'].values for x in c if x in emoji.UNICODE_EMOJI['en']}\n\nf = '|'.join(e)\n\n# Symbola has more emojis, just wanted to be unique\nemo = WordCloud(background_color='white',font_path='Symbola.ttf', \n                max_words=500, regexp=f, width=1500, height=1000).generate(\" \".join(tweets['full_text'].values))\n\nplt.figure(figsize=(15, 15))\nfig = plt.imshow(emo)\nplt.show(","f1c0e5ac":"# Merging Datasets in one Data Frame 'tweets'","3d705eca":"# Words Cloud(use in dataset)","0c11b83b":"# Drop_duplicates","8b83e37d":"# Emogi Cloud(use in dataset)","217d2ac4":"# Cleaning Dataset for better analysis"}}