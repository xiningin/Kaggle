{"cell_type":{"8cb6beb3":"code","a280ebca":"code","c7e4616b":"code","f579acab":"code","6efc7de5":"code","0f545282":"code","9282c201":"code","3575a3e9":"code","62d5a94f":"code","a3ab6f24":"code","033730ef":"code","32e0ed82":"code","d681be9a":"code","d8503dfd":"markdown","35443e0e":"markdown","77f20643":"markdown","9b751401":"markdown","3b75570f":"markdown","6a2929b0":"markdown"},"source":{"8cb6beb3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a280ebca":"data = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\nX = data.drop('DEATH_EVENT', axis=1).values\ny = data.DEATH_EVENT.values","c7e4616b":"pd.DataFrame(data.corr().DEATH_EVENT[:-1]).sort_values(by='DEATH_EVENT', ascending=False)","f579acab":"new = data.ejection_fraction * data.time\npd.DataFrame(np.concatenate([(new).values.reshape(-1, 1), data.DEATH_EVENT.values.reshape(-1, 1)], axis=1)).corr()","6efc7de5":"new_columns = [\n    data.serum_creatinine\/data.time, # 0.375363\n    data.serum_creatinine\/data.ejection_fraction, # 0.39516\n    data.serum_creatinine\/data.serum_sodium, # 0.29928\n    data.age\/data.serum_sodium, # 0.280502\n    data.age\/data.ejection_fraction, # 0.432706\n    data.age\/data.time, # 0.470318\n    data.serum_creatinine * data.age, # 0.327823\n    data.serum_sodium * data.ejection_fraction, # -0.279538\n    data.serum_sodium * data.time, # -0.531718\n    data.ejection_fraction * data.time, # -0.559566    \n]\nnew_arrays = np.array(data.DEATH_EVENT.values.reshape(-1, 1))\nfor new_column in new_columns:\n    new_arrays = np.concatenate([new_arrays, new_column.values.reshape(-1, 1)], axis=1)\nX = np.concatenate([X, new_arrays], axis=1)","0f545282":"# no need to modify extremely high or low values\n\n# fig, axs = plt.subplots(3, 4, figsize=(20, 14))\n# columns = data.columns\n# k = 0\n# for i in range(3):\n#     for j in range(4):\n#         axs[i, j].plot(data[columns[k]], label=columns[k])\n#         axs[i, j].legend()\n#         k += 1\n# plt.show()","9282c201":"# no need to encode\n\n# data.info()","3575a3e9":"from sklearn.decomposition import KernelPCA\npca = KernelPCA(n_components=round(X.shape[1]\/5), kernel='rbf')\nX = np.concatenate([X, pca.fit_transform(X)], axis=1)","62d5a94f":"from sklearn.preprocessing import Normalizer\nsc = Normalizer()\nX = sc.fit_transform(X)","a3ab6f24":"from sklearn.model_selection import train_test_split\nXtrain, Xvalid, ytrain, yvalid = train_test_split(X, y, test_size=.2, random_state=333)","033730ef":"from xgboost import XGBClassifier\nmodel = XGBClassifier(n_estimators=1000)\nmodel.fit(Xtrain, ytrain)\nypred = model.predict(Xvalid)","32e0ed82":"from sklearn.metrics import accuracy_score, confusion_matrix\naccuracy_score(yvalid, ypred), confusion_matrix(yvalid, ypred)","d681be9a":"from sklearn.model_selection import cross_val_score\ncross_val_score(estimator=XGBClassifier(n_estimators=1000), X=X, y=y, scoring='accuracy', cv=5, n_jobs=-1)","d8503dfd":"---","35443e0e":"---","77f20643":"---","9b751401":"---","3b75570f":"---","6a2929b0":"---"}}