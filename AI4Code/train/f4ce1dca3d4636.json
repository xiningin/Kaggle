{"cell_type":{"8e2cfa0c":"code","1e125b76":"code","82697643":"code","9da70b03":"code","b5065b2b":"code","2cb39f72":"code","41699b02":"code","6ced58eb":"code","2a9464c4":"code","4cfbd56f":"code","cef61621":"code","f57cbacd":"code","49e017d9":"code","bf75f6bc":"code","745f371d":"code","006d3f5d":"markdown"},"source":{"8e2cfa0c":"from tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.5\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n#from keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob\n\nIMAGE_SIZE = [224, 224]\n\n\ntrain_directory='..\/input\/fruit-and-vegetables-ssm\/train'\ntest_directory='..\/input\/fruit-and-vegetables-ssm\/test'\nval_directory='..\/input\/fruit-and-vegetables-ssm\/validation'\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n       print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1e125b76":"mobilenet = MobileNetV2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# don't train existing weights\nfor layer in mobilenet.layers:\n    layer.trainable = False\n\nfolders = glob('..\/input\/fruit-and-vegetables-ssm\/train\/*')\nlen(folders)\n","82697643":"x = Flatten()(mobilenet.output)\n\nprediction = Dense(len(folders), activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=mobilenet.input, outputs=prediction)","9da70b03":"# view the structure of the model\nmodel.summary()","b5065b2b":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\n\n\n\nmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n# Adam optimizer\n# loss function will be categorical cross entropy\n# evaluation metric will be accuracy\n\n# step_size_train=train_generator.n\/\/train_generator.batch_size\n# model.fit_generator(generator=train_generator,\n#                    steps_per_epoch=step_size_train,\n#                    epochs=10)","2cb39f72":"# Use the Image Data Generator to import the images from the dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\ntraining_set = train_datagen.flow_from_directory(train_directory,\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')\n\ntest_set = test_datagen.flow_from_directory(test_directory,\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')\n\nprint(len(training_set))\nprint(len(test_set))","41699b02":"r = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=20,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set),\n)\n# r = model.fit(training_set, train_labels,validation_split=0.1, batch_size = 10, epochs = 20, shuffle=True, verbose=2)","6ced58eb":"model.save(\"fruit_n_veg_model.h5\")","2a9464c4":"# serialize model to JSON\nmodel2_json = model.to_json()\nwith open(\"model2.json\", \"w\") as json_file:\n    json_file.write(model2_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model2.h5\")","4cfbd56f":"from tensorflow.keras.models import model_from_json","cef61621":"\n\n# load json and create model\njson_file = open('model2.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model2 = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model2.load_weights(\"model2.h5\")","f57cbacd":"from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nmodel = load_model('.\/fruit_n_veg_model.h5',compile=False)","49e017d9":"import json\nlab = training_set.class_indices\nlab={k:v for v,k in lab.items()}\nprint(lab)\nprint(json.dumps(lab, indent=4))","bf75f6bc":"!pip install Keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import imagenet_utils\ndef output(location):\n    img=load_img(location,target_size=(224,224,3))\n    plt.imshow(img)\n    img=img_to_array(img)\n    \n    img=img\/255\n    plt.imshow(img)\n    img=np.expand_dims(img,[0])\n    \n    answer=model.predict(img)\n  #  ans2 = imagenet_utils.decode_predictions(answer)\n    print(answer)\n    y_class = answer.argmax(axis=-1)\n    #print(answer.argmax(axis=-))\n    y = \" \".join(str(x) for x in y_class)\n    y = int(y)\n    res = lab[y]\n    return res","745f371d":"import matplotlib.pyplot as plt\nimg='..\/input\/banananaaaa\/b3.jpg'\npic=load_img(img,target_size=(224,224,3))\n#plt.imshow(pic)\noutput(img)","006d3f5d":"# fit the model\n# Run the cell. It will take some time to execute\nr = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=10,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)"}}