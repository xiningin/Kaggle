{"cell_type":{"20f02c87":"code","63784c62":"code","62eda769":"code","85d9dbfc":"code","2dc75c35":"code","548ba25f":"code","a31edb83":"code","f4ce75ee":"code","7a707724":"code","869bf35f":"code","bbddbe72":"code","fe887b6d":"code","8585473c":"code","97993409":"code","b490caeb":"code","82d3a464":"code","75e0b918":"markdown","b345c40d":"markdown","46d36b3e":"markdown","cb717864":"markdown","1e2f6b82":"markdown"},"source":{"20f02c87":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, association_rules\nfrom pandas.plotting import parallel_coordinates\nimport warnings\nwarnings.filterwarnings('ignore')","63784c62":"df = pd.read_csv('..\/input\/datasets-for-appiori\/basket_analysis.csv')","62eda769":"df.drop(df.columns[0],axis=1,inplace=True)","85d9dbfc":"df.shape","2dc75c35":"df.mean()","548ba25f":"# Compute frequent itemsets using the Apriori algorithm\nfrequent_itemsets = apriori(df,\n                            min_support = .006,\n                            max_len = 3,\n                            use_colnames = True)","a31edb83":"# Compute all association rules for frequent_itemsets\nrules = association_rules(frequent_itemsets,\n                            metric = 'support',\n                            min_threshold=0.1)","f4ce75ee":"#\nfiltered_rules = rules[(rules['antecedent support'] > 0.02)&\n                        (rules['consequent support'] >0.01) &\n                        (rules['confidence'] > 0.2) &\n                        (rules['lift'] > 1.0)]","7a707724":"filtered_rules.sort_values('confidence',ascending=False)","869bf35f":"# Generate scatterplot confidence versus support\nsns.scatterplot(x = \"support\", y = \"confidence\", data = filtered_rules)\nplt.show()","bbddbe72":"filtered_rules = rules[(rules['antecedent support'] > 0.02)&\n                        (rules['consequent support'] >0.01) &\n                        (rules['confidence'] > 0.45) &\n                        (rules['lift'] > 1.0)]","fe887b6d":"# Generate scatterplot confidence versus support\n\nsns.scatterplot(x = \"support\", y = \"confidence\", size= 'leverage',data = filtered_rules)\nplt.legend(bbox_to_anchor= (1.02, 1), loc='upper left',)\nplt.show()","8585473c":"# add extra another rule where support more than 0.2 for given itemset\nfiltered_rules = rules[(rules['antecedent support'] > 0.02)&\n                        (rules['consequent support'] >0.01) &\n                        (rules['confidence'] > 0.45) &\n                        (rules['lift'] > 1.0)&\n                        (rules['support']>0.195)]","97993409":"filtered_rules","b490caeb":"def rules_to_coordinates(rules):\n    rules['antecedent'] = rules['antecedents'].apply(lambda antecedent:list(antecedent)[0])\n    rules['consequent'] = rules['consequents'].apply(lambda consequent:list(consequent)[0])\n    rules['rule'] = rules.index\n    return rules[['antecedent','consequent','rule']]","82d3a464":"# Convert rules into coordinates suitable for use in a parallel coordinates plot\ncoords = rules_to_coordinates(filtered_rules)\n# Generate parallel coordinates plot\nplt.figure(figsize=(3,6))\nparallel_coordinates(coords, 'rule',colormap = 'ocean')\nplt.legend([])\nplt.show()","75e0b918":"With scatterplot, we can have quick glimpse, where the boundary should be and what metric should be set to filter out the frequent itemsets. ","b345c40d":"We have 999 basket for us to compute the recommendation for each item that sold in the store. There are 16 items that sold in the shop.","46d36b3e":"From the plot it seems like the butter can be used as cross-selling with other products, it also acts as something to be offered with antecedents that is low. Thus, the customers are more likely to buy them if the butter are offered with cheaper price if they buy the antecedents that sold less in a store","cb717864":"We set the mininum support as 0.06, maximum number that being analysed in the basket is 3. We are doing first pruning and see what we get from the result","1e2f6b82":"The sale transaction or count for each unique item approximately for this sample. We will dive into and see whether there is any difference or correlation between the baskets. Since the dataframe is already tabulated one hot data frame, we will straight away and use the dataset to be analyzed with apriori\n## Apriori Algorithm\nLittle bit background introduction for `Apriori Algorithm`. The algorithm assumes that any subset of a frequent itemset must be frequent. Say in our cases, where {apple, unicorn, yoghurt} is frequent then {apple,yoghurt} is frequent. Whereas {apple,unicorn} is not frequent, then {apple,unicorn,yoghurt} is not frequent.\n\n__SUPPORT__ =  A simple way to control complexity is to place a constraint that such rules must apply to some minimum percentage of the data <br>\n__CONFIDENCE__ =  The probability that B occurs when A; it is p(B|A), which in association mining.<br>\n__LIFT__ =  the co-occurrence of A and B is the probability that we actually see the two together, compared to the probability that we would see the two together if they were unrelated to (independent of) each other.<br>\n__LEVERAGE__ =  alternative is to look at the difference between these quantities rather than their ratio.<br>\n__CONVICTION__ = measure to ascertain the direction of the rule. Unlike lift, conviction is sensitive to the rule direction.\n\nJust Support and Confidence as a parameter might be misleading for items that are too common\/ popular in the basket. It is more likely that popular items are part of the same basket just because they are popular rather than anything else. "}}