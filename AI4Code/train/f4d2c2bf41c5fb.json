{"cell_type":{"393cee7c":"code","7953c4f3":"code","354594fe":"code","98544577":"code","2925c1d2":"code","59a51a35":"code","1c0ff219":"code","3dfc3337":"code","8adbcba7":"code","709b1587":"code","f9d5dfb3":"code","a65585fd":"code","66e4d4c9":"markdown","bea8f5c5":"markdown","86bbe7d2":"markdown","cdb2e447":"markdown","00e43662":"markdown","f2f52c4c":"markdown"},"source":{"393cee7c":"import pandas as pd, numpy as np, os\nimport optuna\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib as plt\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import VotingClassifier \n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBRFClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\n\nfrom sklearn.linear_model import SGDClassifier\nimport datatable as dt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nSEED = 1\nFOLD = 5","7953c4f3":"#import files here\n%time\ntrain = dt.fread('..\/input\/tsp21sep-data-folder\/final_base_train.csv').to_pandas()\ntest = dt.fread('..\/input\/tsp21sep-data-folder\/final_base_test.csv').to_pandas()\n\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","354594fe":"#preprocessing\ny = train['y_valid']\ntrain.drop('y_valid',inplace=True,axis=1)\n\nX = train\ny_meta = y\ntest_data = test","98544577":"#thanks to Edrick Kesuma\n#use for loop to get below columns\nX_data = [X.old_lgbm1, X.old_lgbm3, X.old_catb1, X.old_catb2, X.old_xgb1, X.old_xgb2, X.my_lgbm1, X.my_lgbm2, X.my_lgbm3, X.my_xgb1, X.my_xgb2, X.my_catb1, X.my_catb2, X.my_lgbm4, X.voting_catboost1, X.voting_catboost2, X.voting_xgboost1, X.voting_xgboost2, X.voting_lgbm1, X.voting_lgbm3, X.copy_lgbm2, X.new_lgbm2, X.lgbm1_latest28, X.lgbm1_latest28seed, X.lgbm1_latest28seed2, X.xgb_latest99, X.xgb_latest99_seed, X.lgbm1_gpu, X.lgbm1_cpu, X.colsample_lgbm, X.lgbm2_43gpu, X.lastlgbm43]\ngroup_labels1 = X.columns.to_list()\nfig = ff.create_distplot(X_data, group_labels1, bin_size=0.3, show_hist=False, show_rug=False)\nfig.show()","2925c1d2":"_data = [X.old_lgbm1, X.old_lgbm3, X.old_catb1, X.old_catb2, X.old_xgb1, X.old_xgb2, X.my_lgbm1, X.my_lgbm2, X.my_lgbm3, X.my_xgb1, X.my_xgb2, X.my_catb1, X.my_catb2, X.my_lgbm4, X.voting_catboost1, X.voting_catboost2, X.voting_xgboost1, X.voting_xgboost2, X.voting_lgbm1, X.voting_lgbm3, X.copy_lgbm2, X.new_lgbm2, X.lgbm1_latest28, X.lgbm1_latest28seed, X.lgbm1_latest28seed2, X.xgb_latest99, X.xgb_latest99_seed, X.lgbm1_gpu, X.lgbm1_cpu, X.colsample_lgbm, X.lgbm2_43gpu, X.lastlgbm43]\ngroup_labels = test_data.columns.to_list()\nfig = ff.create_distplot(_data, group_labels, bin_size=0.3, show_hist=False, show_rug=False)\nfig.show()","59a51a35":"#correlation between all models pred\ndata = np.corrcoef(X_data)\nfig=px.imshow(data,x=group_labels1, y=group_labels1)\n\nfig.show()","1c0ff219":"#correlation between all models pred\ndata = np.corrcoef(_data)\nfig=px.imshow(data,x=group_labels, y=group_labels)\n\nfig.show()","3dfc3337":"removed = ['voting_xgboost1', 'old_xgb1', 'my_xgb2']\n\ncols = ['old_lgbm1', 'old_lgbm3', 'old_catb1', 'old_catb2',\n       'old_xgb2', 'my_lgbm1', 'my_lgbm2', 'my_lgbm3', 'my_xgb1',\n       'my_catb1', 'my_catb2', 'my_lgbm4', 'voting_catboost1',\n       'voting_catboost2', 'voting_xgboost2',\n       'voting_lgbm1', 'voting_lgbm3', 'copy_lgbm2', 'new_lgbm2',\n       'lgbm1_latest28', 'lgbm1_latest28seed', 'lgbm1_latest28seed2',\n       'xgb_latest99', 'xgb_latest99_seed', 'lgbm1_gpu', 'lgbm1_cpu',\n       'colsample_lgbm', 'lgbm2_43gpu', 'lastlgbm43']\n\n# X = X[cols]\n# test_data = test_data[cols]\n\n#check if the all columns in train set is in test set\nassert X.columns.to_list() == test_data.columns.to_list()","8adbcba7":"# helper functions\ndef get_auc(y_true, y_hat):\n    fpr, tpr, _ = roc_curve(y_true, y_hat)\n    score = auc(fpr, tpr)\n    return score","709b1587":"meta_pred_tmp = []\nscores_tmp = []\n\n# create cv\nkf = StratifiedKFold(n_splits=50, shuffle=True, random_state=1)\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X, y)):\n    # create train, validation sets\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n    \n    model = LogisticRegression(C=4,solver='liblinear',random_state=SEED,n_jobs=-1)\n    model.fit(X_train, y_train)\n    # validation prediction\n    pred_valid = model.predict_proba(X_valid)[:,1]\n    \n    score = get_auc(y_valid, pred_valid)\n    scores_tmp.append(score)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\")\n    print('--'*20)\n    \n    # test prediction based on oof_set\n    y_hat = model.predict_proba(test_data)[:,1]\n    meta_pred_tmp.append(y_hat)\n# print overall validation scores\nprint(f\"Overall Validation Score | Meta: {np.mean(scores_tmp)}\")\nprint('::'*20)","f9d5dfb3":"#average meta predictions over each fold\nmeta_predictions = np.mean(np.column_stack(meta_pred_tmp), axis=1)\n\n# create submission file\nstacked_submission = sample_submission.copy()\nstacked_submission['claim'] = meta_predictions\nstacked_submission.to_csv('.\/Logistic_Regression.csv', index=False)","a65585fd":"plot = pd.concat([stacked_submission.claim,test_data],axis=1)\n\npred = [plot.claim, plot.old_lgbm1, plot.old_lgbm3, plot.old_catb1, plot.old_catb2, plot.old_xgb1, plot.old_xgb2, plot.my_lgbm1, plot.my_lgbm2, plot.my_lgbm3, plot.my_xgb1, plot.my_xgb2, plot.my_catb1, plot.my_catb2, plot.my_lgbm4, plot.voting_catboost1, plot.voting_catboost2, plot.voting_xgboost1, plot.voting_xgboost2, plot.voting_lgbm1, plot.voting_lgbm3, plot.copy_lgbm2, plot.new_lgbm2, plot.lgbm1_latest28, plot.lgbm1_latest28seed, plot.lgbm1_latest28seed2, plot.xgb_latest99, plot.xgb_latest99_seed, plot.lgbm1_gpu, plot.lgbm1_cpu, plot.colsample_lgbm, plot.lgbm2_43gpu,plot.lastlgbm43]\ngroup_labels = plot.columns.to_list()\nfig = ff.create_distplot(pred, group_labels, bin_size=0.3, show_hist=False, show_rug=False)\nfig.show()","66e4d4c9":"# Train Data Heatmap\n___","bea8f5c5":"# Blending Prediction Kde Plot\n___","86bbe7d2":"# Test Data KDE Plot\n___","cdb2e447":"# Test Data Heatmap\n___","00e43662":"# Blending | Logistic Regression\n___","f2f52c4c":"# Train Data KDE Plot\n___"}}