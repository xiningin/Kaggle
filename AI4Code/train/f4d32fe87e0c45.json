{"cell_type":{"fec5f3eb":"code","dcb13809":"code","ab473940":"code","830c3145":"code","c11ddf9c":"code","bb36de7e":"code","df1a43fd":"code","7fe1055a":"code","6f10f76f":"code","b5a47b1e":"code","e590eae0":"code","26063aab":"code","e3bdaf12":"code","9d2efc38":"code","087cde29":"code","b009644b":"code","c1b64382":"code","08f6bd31":"code","b79298ba":"code","9242f9a4":"code","cee2b887":"code","f06344f0":"markdown"},"source":{"fec5f3eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings('ignore') # filter warnings\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dcb13809":"data_train = pd.read_csv(\"\/kaggle\/input\/gooogle-stock-price\/Google_Stock_Price_Train.csv\")\ndata_train.head()\n","ab473940":"train = data_train.loc[:,[\"Open\"]].values # open valuelerine bakaca\u011f\u0131z values ile array'e \u00e7eviriyoruz\ntrain","830c3145":"from sklearn.preprocessing import MinMaxScaler # 0-1 aras\u0131nda scale yapaca\u011f\u0131z normalization\nscaler = MinMaxScaler(feature_range = (0,1))\ntrain_scaled = scaler.fit_transform(train) # train datam\u0131 al\u0131p 0-1 aras\u0131na scale ediyoruz\ntrain_scaled\n","c11ddf9c":"plt.plot(train_scaled)\nplt.show()","bb36de7e":"train_scaled.shape","df1a43fd":"# 50 timesteps ve 1 outputtan olu\u015fan bir data structure kuruyoruz, 50 tane data al 51.sini tahmin et gibi..\nx_train = []\ny_train = []\ntimesteps = 50\n\nfor i in range(timesteps, train_scaled.shape[0]): #1258 'e kadar t\u00fcm colon say\u0131s\u0131 # burada sorun \u00e7\u0131karsa 1258 yazabilirsin\n    x_train.append(train_scaled[i - timesteps:i, 0]) # 0'dan 50'e kadar al x'e at\n    y_train.append(train_scaled[i, 0]) # 50'den bir sonrakini y'e at\n    \nx_train, y_train = np.array(x), np.array(y)\n\n","7fe1055a":"y_train.shape","6f10f76f":"x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1)) # 1208, 50 , 1\nx_train.shape # x'mizin shape'i 3 boyutlu oldu","b5a47b1e":"y_train.shape","e590eae0":"x_train.shape[1]","26063aab":"from keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN, Dropout # dense layer , rnn, dropout overfitting \u00f6nlemek i\u00e7in\n\n#initialize RNN\n\nmodel = Sequential() # model olu\u015fturduk\n\n#ilk RNN LAYER ve dropout\n\nmodel.add(SimpleRNN(units = 50, activation = \"relu\", return_sequences = True, input_shape = (x_train.shape[1], 1))) # 50x1 'lik bir input girece\u011fimizi s\u00f6yl\u00fcyoruz\nmodel.add(Dropout(0.2)) # regularisation \n\n# 2. RNN layer ve dropout'\n\nmodel.add(SimpleRNN(units = 50, activation = \"relu\", return_sequences = True )) # 50x1 'lik bir input girece\u011fimizi s\u00f6yl\u00fcyoruz\nmodel.add(Dropout(0.2))\n\n#3. RNN layer ve dropout\n\nmodel.add(SimpleRNN(units = 50, activation = \"relu\", return_sequences = True )) # 50x1 'lik bir input girece\u011fimizi s\u00f6yl\u00fcyoruz # relu kullanarak deneyelim mi?\nmodel.add(Dropout(0.2))\n\n#4. RNN layer ve dropout\n\nmodel.add(SimpleRNN(units = 50)) # 50x1 'lik bir input girece\u011fimizi s\u00f6yl\u00fcyoruz # relu kullanarak deneyelim mi?\nmodel.add(Dropout(0.2))\n\n# son olarak output layer dense ile\n\nmodel.add(Dense(units = 1)) # 1 OUTPUT\n\n# rnn compile ediyoruz\n\nmodel.compile(optimizer = \"Adam\", loss = \"mean_squared_error\", metrics = [\"accuracy\"])\n\n#fit\n\nmodel.fit(x_train, y_train, epochs = 50, batch_size = 16)\n","e3bdaf12":"data_test = pd.read_csv(\"\/kaggle\/input\/gooogle-stock-price\/Google_Stock_Price_Test.csv\")\ndata_test.head()","9d2efc38":"real_stock_price = data_test.loc[:, [\"Open\"]].values\nreal_stock_price","087cde29":"data_total = pd.concat((data_train['Open'], data_test['Open']), axis = 0)\ninputs = data_total[len(data_total) - len(data_test) - timesteps:].values.reshape(-1,1)\ninputs = scaler.transform(inputs)  # min max scaler\ninputs","b009644b":"inputs.shape[0]","c1b64382":"x_test = []\nfor i in range(timesteps, inputs.shape[0]):\n    x_test.append(inputs[i-timesteps:i, 0])\nx_test = np.array(x_test)\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1)) # 3 boyut\npredicted_stock_price = model.predict(x_test)\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n\n# Visualising the results\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","08f6bd31":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, SimpleRNN, Dropout # dense layer , rnn, dropout overfitting \u00f6nlemek i\u00e7in\n","b79298ba":"model = Sequential() # model olu\u015fturduk\n\n#ilk LSTM LAYER ve dropout\n\nmodel.add(LSTM(15, activation = \"relu\", input_shape = (x_train.shape[1], 1))) #10 LSTM block. One layer has 10 LSTM unit (node).\n\"\"\"\nmodel.add(LSTM(units = 50, activation = \"relu\", return_sequences = True, dropout = 0.2, input_shape = (x_train.shape[1], 1))) # 50x1 'lik bir input girece\u011fimizi s\u00f6yl\u00fcyoruz\n#model.add(Dropout(0.2)) # regularisation \n\n# 2. LSTM layer ve dropout'\n\nmodel.add(LSTM(units = 50, activation = \"relu\", return_sequences = True, dropout = 0.2)) # 50x1 'lik bir input girece\u011fimizi s\u00f6yl\u00fcyoruz\n#model.add(Dropout(0.2))\n\n#3. LSTM layer ve dropout\n\nmodel.add(LSTM(units = 50, activation = \"relu\", return_sequences = True, dropout = 0.2)) # 50x1 'lik bir input girece\u011fimizi s\u00f6yl\u00fcyoruz # relu kullanarak deneyelim mi?\n#model.add(Dropout(0.2))\n\n#4. LSTM layer ve dropout\n\nmodel.add(LSTM(units = 50, activation = \"relu\", dropout = 0.2)) # 50x1 'lik bir input girece\u011fimizi s\u00f6yl\u00fcyoruz # relu kullanarak deneyelim mi?\n#model.add(Dropout(0.2))\"\"\"\n\n# son olarak output layer dense ile\n\nmodel.add(Dense(units = 1)) # 1 OUTPUT\n\n# rnn compile ediyoruz\n\nmodel.compile(optimizer = \"Adam\", loss = \"mean_squared_error\", metrics = [\"accuracy\"])\n\n#fit\n\nmodel.fit(x_train, y_train, epochs = 50, batch_size = 5)","9242f9a4":"predicted_data2 = model.predict(x_test)\npredicted_data2 = scaler.inverse_transform(predicted_data2)","cee2b887":"plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'RNN Predicted Google Stock Price')\nplt.plot(predicted_data2, color = 'green', label = 'LSTM Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","f06344f0":"# LSTM"}}