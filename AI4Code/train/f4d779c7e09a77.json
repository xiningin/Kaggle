{"cell_type":{"0bf07340":"code","3b8e8e5d":"code","0e8b392c":"code","6ce97a07":"code","2bb566ed":"code","cda0455c":"code","ab9a3dbd":"code","4a3ff6d9":"code","813d33a6":"code","dd481273":"code","2284c1ad":"code","99af461e":"code","47e9d304":"code","3717eada":"code","ec5aa364":"code","b3ff6d96":"code","47f5c55d":"code","a3f59d58":"code","555324b5":"code","9aca66d1":"code","08190e84":"code","e84123b3":"code","b3abf43c":"code","b43843b5":"code","c8069008":"code","10d1411c":"code","7d1ee048":"code","7ff80169":"markdown","30b563ad":"markdown","810f06b7":"markdown","f0798260":"markdown","e71071e2":"markdown","bf228fe9":"markdown","ac3f2b82":"markdown","003e407d":"markdown","f93d393a":"markdown","c027e6ac":"markdown","cb885118":"markdown","a69d9d54":"markdown","2867f298":"markdown","2ab33ced":"markdown","00f96353":"markdown"},"source":{"0bf07340":"import sys\nsys.path.append('..\/input\/petfinderpublic\/pytorch-image-models-master\/pytorch-image-models-master')\nsys.path.append('..\/input\/petfinderpublic\/Ranger21-main\/Ranger21-main')\n!mkdir -p \"\/root\/.cache\/torch\/hub\/checkpoints\"\n!cp \"..\/input\/petfinderpublic\/swin_pretrained\/swin_base_patch4_window7_224_22kto1k.pth\" \"\/root\/.cache\/torch\/hub\/checkpoints\/\"","3b8e8e5d":"import os\nimport gc\nimport time\nimport math\nimport copy\nimport random\nimport datetime\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nfrom torchvision.io import read_image\n\nimport timm\n\nimport pickle\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor","0e8b392c":"TRAIN_CSV = '..\/input\/petfinder-pawpularity-score\/train.csv'\nTEST_CSV = '..\/input\/petfinder-pawpularity-score\/test.csv'\nSAMPLE_SUBMISSION_CSV = '..\/input\/petfinder-pawpularity-score\/sample_submission.csv'\nTRAIN_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/train\/'\nTEST_DATA_PATH = '..\/input\/petfinder-pawpularity-score\/test\/'\nTRAIN_CROP_PATH = '..\/input\/petfinder2-cropped-dataset\/crop\/'\nOUTPUT_PATH = '..\/output\/'\n\nos.makedirs(OUTPUT_PATH, exist_ok=True)","6ce97a07":"class CFG:\n    seed = 113\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n    ### model and image features\n    # I used model_name='swin_large_patch4_window12_384' and image_size=384 in competition.\n    model_name = 'swin_base_patch4_window7_224'  # backbone model\n    image_size = 224\n    embed_dim = 512\n    n_classes = 121\n    dropout_p = 0.4  # dropout probability of head layer\n    replace_mixout = True  # replace Dropout layers to Mixout layers\n    mixout_p = 0.8\n\n    ### training\n    n_epochs = 8 # I used 16 in competition\n    n_folds = 5\n    trn_folds = [0, 1, 2, 3, 4]\n    batch_size = 12\n    batch_size_infer = batch_size * 2\n    accum_iter = 1\n    use_amp = True\n    num_workers = 4\n\n    ### learning rate and loss\n    lr_max = 1.6e-4\n    weight_decay = 1e-3\n    normal_sampling_std = 2.0  # standard deviation of target distribution\n    optimizer_name = 'Ranger21'\n    loss_weights = [1e-3, 1e-5]  # [kl_div_loss\/focal_loss, l1_loss]\n\n    ### Scheduler\n    # OneCycleLR\n    div_factor = 25\n    final_div_factor = 2\n    warmup_epo = n_epochs * 0.6\n    lr_start = lr_max \/ div_factor  # starting learning rate\n    lr_min = lr_max \/ final_div_factor  # last minimum learning rate\n\n    ### image\n    train_crop_p = 0.7\n\n    ### MixUp\n    mixup_p = 0.0\n    mix_alpha = 0.2\n    mixup_epoch_p = {1: 0.0, 2: 0.5}\n \n    ### save model weights\n    min_save_epoch = int(n_epochs * 0.3)\n    save_file_name = f\"{model_name}-ep{n_epochs}-bs{batch_size}-seed{seed}\"\n    output_dir = '..\/output\/'\n    save_model_path = os.path.join(output_dir, save_file_name)","2bb566ed":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True  # set True to be faster\n\nseed_everything(CFG.seed)","cda0455c":"def paw_to_target(x):\n    return x + 10\n\n\ndef target_to_paw(x):\n    return x - 10","ab9a3dbd":"def create_stratified_k_folds(df, cfg, binning=True):\n\n    df = df.reset_index(drop=True)\n    df[\"kfold\"] = -1\n    skf = StratifiedKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n\n    n_bins = int(np.floor(1+(3.3)*(np.log2(len(df)))))\n    df.loc[:, \"bins\"] = pd.cut(\n        df[\"target\"], bins=n_bins, labels=False\n    )\n    splits = skf.split(X=df, y=df.bins)\n\n    for fold, (_, valid_idx) in enumerate(splits):\n        df.loc[valid_idx, 'kfold'] = fold\n\n    return df","4a3ff6d9":"df = pd.read_csv(TRAIN_CSV)\n\ndf['target'] = df['Pawpularity'].apply(paw_to_target)\n\ndf = create_stratified_k_folds(df, cfg=CFG, binning=False)\n\ndf[\"file_path\"] = [os.path.join(TRAIN_DATA_PATH, f\"{id}.jpg\") for id in df.Id]\ndf[\"crop_path\"] = [os.path.join(TRAIN_CROP_PATH, f\"{id}.jpg\") for id in df.Id]\n\ndf.reset_index(drop=True)","813d33a6":"def make_scheduler(dataloader_length, optimizer, cfg):\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=cfg.lr_max,\n        epochs=cfg.n_epochs,\n        steps_per_epoch=dataloader_length,\n        pct_start=cfg.warmup_epo \/ cfg.n_epochs,\n        anneal_strategy='cos',\n        div_factor=cfg.div_factor,\n        final_div_factor=cfg.final_div_factor,\n    )\n    return scheduler\n\n\ndef make_optimizer(model, cfg):\n    # https:\/\/github.com\/lessw2020\/Ranger21\n    from ranger21 import Ranger21\n    optimizer = Ranger21(model.parameters(), lr=cfg.lr_max,\n        betas=(0.95, 0.999), eps=1e-5, weight_decay=cfg.weight_decay,  # Adam options\n        use_cheb=False,\n        lookahead_active=True,\n        lookahead_mergetime=5,\n        lookahead_blending_alpha=0.5,\n        lookahead_load_at_validation=False,\n        normloss_active=True,\n        normloss_factor=6e-4,\n        use_adaptive_gradient_clipping=True,\n        agc_clipping_value=0.1,\n        use_madgrad=False,\n        warmdown_active=False,\n        use_warmup=False,\n        num_epochs=cfg.n_epochs,\n        using_gc=True,\n        num_batches_per_epoch=len(train_loader),\n    )\n    return optimizer","dd481273":"def normal_sampling(mean, label, std=CFG.normal_sampling_std):\n    return math.exp(- (label - mean)**2 \/ (2 * std**2)) \/ (math.sqrt(2 * math.pi) * std)\n\n\ndef worker_init_fn(worker_id):\n    np.random.seed(np.random.get_state()[1][0] + worker_id)","2284c1ad":"train_aug = T.Compose([\n    #T.RandAugment(2, 10),  # Cannot use in kaggle now. I used RA with torchvision v0.11.0.\n    T.RandomChoice([\n        T.Resize(CFG.image_size),\n        T.Resize(CFG.image_size),\n        T.Resize((CFG.image_size, CFG.image_size)),\n    ]),\n    T.CenterCrop(CFG.image_size),\n    T.ConvertImageDtype(torch.float),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])\n\nvalid_aug = nn.Sequential(\n    T.Resize(CFG.image_size),\n    T.CenterCrop(CFG.image_size),\n    T.ConvertImageDtype(torch.float),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n)\n\n\nclass PawpularDataset(Dataset):\n    def __init__(self, df, cfg, augment=None, mode=\"test\"):\n        self.df = df\n        self.cfg = copy.copy(cfg)\n        self.augmentations = augment\n        self.mode = mode\n        if mode in [\"train\", \"valid\"]:\n            self.targets = df.target.values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        if (np.random.rand() < self.cfg.train_crop_p) and (self.mode == \"train\"):\n            file_path = self.df.crop_path[idx]\n        else:\n            file_path = self.df.file_path[idx]\n\n        image = read_image(file_path)\n        #image = read_image(file_path).to(self.cfg.device)\n        \n        if self.augmentations is not None:\n            image = self.augmentations(image)\n\n        if self.mode in [\"train\", \"valid\"]:\n            target = self.targets[idx]\n            target_dist = [normal_sampling(target, i) for i in range(self.cfg.n_classes)]\n            target_dist = [i if i > 1e-8 else 1e-8 for i in target_dist]\n            target_dist = torch.tensor(target_dist, dtype=torch.float32)\n\n            return {\n                \"image\": image,\n                \"target\": torch.tensor(target, dtype=torch.float),\n                \"target_dist\": target_dist,  # target age distribution\n            }\n        else:\n            return {\n                \"image\": image,\n            }","99af461e":"def mixup(batch, alpha):\n\n    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n    \n    rand_idx = torch.randperm(batch[\"image\"].size(0))\n\n    batch[\"image\"] = lam * batch[\"image\"] + (1 - lam) * batch[\"image\"][rand_idx]\n    batch[\"target_b\"] = batch[\"target\"][rand_idx]\n    batch[\"target\"] = lam * batch[\"target\"] + (1 - lam) * batch[\"target\"][rand_idx]\n    batch[\"target_dist\"] = lam * batch[\"target_dist\"] + (1 - lam) * batch[\"target_dist\"][rand_idx]\n\n    return batch, lam","47e9d304":"# https:\/\/arxiv.org\/abs\/1909.11299\n# https:\/\/github.com\/bloodwass\/mixout\n# https:\/\/www.ai-shift.co.jp\/techblog\/2170\n\nimport math\nfrom torch.autograd.function import InplaceFunction\nfrom torch.nn import Parameter\nimport torch.nn.init as init\n\nclass Mixout(InplaceFunction):\n    @staticmethod\n    def _make_noise(input):\n        return input.new().resize_as_(input)\n\n    @classmethod\n    def forward(cls, ctx, input, target=None, p=0.0, training=False, inplace=False):\n        if p < 0 or p > 1:\n            raise ValueError(\"A mix probability of mixout has to be between 0 and 1,\" \" but got {}\".format(p))\n        if target is not None and input.size() != target.size():\n            raise ValueError(\n                \"A target tensor size must match with a input tensor size {},\"\n                \" but got {}\".format(input.size(), target.size())\n            )\n        ctx.p = p\n        ctx.training = training\n\n        if ctx.p == 0 or not ctx.training:\n            return input\n\n        if target is None:\n            target = cls._make_noise(input)\n            target.fill_(0)\n        target = target.to(input.device)\n\n        if inplace:\n            ctx.mark_dirty(input)\n            output = input\n        else:\n            output = input.clone()\n\n        ctx.noise = cls._make_noise(input)\n        if len(ctx.noise.size()) == 1:\n            ctx.noise.bernoulli_(1 - ctx.p)\n        else:\n            ctx.noise[0].bernoulli_(1 - ctx.p)\n            ctx.noise = ctx.noise[0].repeat(input.size()[0], 1)\n        ctx.noise.expand_as(input)\n\n        if ctx.p == 1:\n            output = target\n        else:\n            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) \/ (1 - ctx.p)\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        if ctx.p > 0 and ctx.training:\n            return grad_output * ctx.noise, None, None, None, None\n        else:\n            return grad_output, None, None, None, None\n\n\ndef mixout(input, target=None, p=0.0, training=False, inplace=False):\n    return Mixout.apply(input, target, p, training, inplace)\n\n\nclass MixLinear(torch.nn.Module):\n    __constants__ = [\"bias\", \"in_features\", \"out_features\"]\n    def __init__(self, in_features, out_features, bias=True, target=None, p=0.0):\n        super(MixLinear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = Parameter(torch.Tensor(out_features, in_features))\n        if bias:\n            self.bias = Parameter(torch.Tensor(out_features))\n        else:\n            self.register_parameter(\"bias\", None)\n        self.reset_parameters()\n        self.target = target\n        self.p = p\n\n    def reset_parameters(self):\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 \/ math.sqrt(fan_in)\n            init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, input):\n        return F.linear(input, mixout(self.weight, self.target, self.p, self.training), self.bias)\n\n    def extra_repr(self):\n        type = \"drop\" if self.target is None else \"mix\"\n        return \"{}={}, in_features={}, out_features={}, bias={}\".format(\n            type + \"out\", self.p, self.in_features, self.out_features, self.bias is not None\n        )\n\n\ndef replace_mixout(model, mixout_p):\n    for sup_module in model.modules():\n        for name, module in sup_module.named_children():\n            if isinstance(module, nn.Dropout):\n                module.p = 0.0\n            if isinstance(module, nn.Linear):\n                target_state_dict = module.state_dict()\n                bias = True if module.bias is not None else False\n                new_module = MixLinear(\n                    module.in_features, module.out_features, bias, target_state_dict[\"weight\"], mixout_p\n                )\n                new_module.load_state_dict(target_state_dict)\n                setattr(sup_module, name, new_module)\n    return model","3717eada":"class DLDLModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = copy.copy(cfg)\n        self.rank = torch.Tensor([i for i in range(cfg.n_classes)]).to(cfg.device)\n\n        self.backbone = timm.create_model(\n            cfg.model_name,\n            pretrained=pretrained,\n            in_chans=3\n        )\n        head_in_channels = self.backbone.head.in_features\n        self.backbone.head = nn.Identity()\n\n        self.embedding = nn.Sequential(\n            nn.Dropout(cfg.dropout_p),\n            nn.Linear(head_in_channels, cfg.embed_dim)\n        )\n        self.fc = nn.Sequential(\n            nn.ReLU(),\n            nn.Dropout(cfg.dropout_p),\n            nn.Linear(cfg.embed_dim, cfg.n_classes)\n        )\n        for m in [*self.embedding, *self.fc]:\n            self._init_params(m)\n\n        self.kldivloss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n        self.l1loss_fn = nn.HuberLoss(reduction=\"mean\")\n\n    def _init_params(self, m):\n        if isinstance(m, nn.Conv2d):\n            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n            m.weight.data.normal_(0, math.sqrt(2. \/ n))\n        elif isinstance(m, nn.BatchNorm2d):\n            m.weight.data.fill_(1)\n            m.bias.data.zero_()\n        elif isinstance(m, nn.Linear):\n            nn.init.xavier_normal_(m.weight)\n            nn.init.constant_(m.bias, 0)\n\n    def forward(self, batch, embed=False):\n        feats = self.backbone(batch[\"image\"])\n        x = self.embedding(feats)\n        x = self.fc(x)\n        ps_dist = F.softmax(x, dim=1)\n        ps = torch.sum(ps_dist * self.rank, dim=1)  # expected value\n        if embed == True:\n            return {\n                \"ps_dist\": ps_dist,\n                \"ps\": ps,\n                \"feat\": feats\n            }\n        else:\n            return {\n                \"ps_dist\": ps_dist,\n                \"ps\": ps\n            }\n\n    def loss(self, outputs, batch, lam):\n        loss_kl = self.kldivloss_fn(torch.log(outputs[\"ps_dist\"]), batch[\"target_dist\"])\n        if lam > 0 and lam <= 1:\n            loss_l1 = self.l1loss_fn(outputs[\"ps\"], lam * batch[\"target\"] + (1 - lam) * batch[\"target_b\"])\n        else:\n            loss_l1 = self.l1loss_fn(outputs[\"ps\"], batch[\"target\"])\n\n        loss = loss_kl * self.cfg.loss_weights[0] + loss_l1 * self.cfg.loss_weights[1]\n\n        return loss","ec5aa364":"def train_one_epoch(fold, epoch, model, data_loader, optimizer, scheduler, cfg):\n\n    model.train()\n    optimizer.zero_grad()\n\n    scaler = torch.cuda.amp.GradScaler()\n\n    total_se = 0.0\n    total_loss = 0.0\n    total_processed = 0\n\n    pbar = tqdm(train_loader, desc=f\"Epoch [{epoch}\/{cfg.n_epochs}]\", ncols=120)\n    for step, batch in enumerate(pbar):\n        batch = {key: val.to(cfg.device, non_blocking=True) for key, val in batch.items()}\n\n        # MixUp\n        if np.random.rand() < cfg.mixup_p:\n            do_mixup = True\n            batch, lam = mixup(batch, alpha=cfg.mix_alpha)\n        else:\n            do_mixup = False\n            lam = 0.\n\n        # Training\n        with torch.cuda.amp.autocast():\n            outputs = model(batch)\n            loss = model.loss(outputs, batch, lam)\n        scaler.scale(loss).backward()\n        # mini-batch accumulation\n        if (step + 1) % cfg.accum_iter == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n        # running loss\n        bs = batch[\"image\"].size(0)\n        total_loss += loss.cpu().detach().item() * bs\n        total_processed += bs\n        running_loss = total_loss \/ total_processed\n\n        if do_mixup:\n            total_se += lam * torch.square(batch[\"target\"].cpu().detach() - outputs[\"ps\"].cpu().detach()).numpy().sum() \\\n            + (1 - lam ) * torch.square(batch[\"target_b\"].cpu().detach() - outputs[\"ps\"].cpu().detach()).numpy().sum()\n        else:\n            total_se += torch.square(batch[\"target\"].cpu().detach() - outputs[\"ps\"].cpu().detach()).numpy().sum()\n\n        running_rmse = (total_se \/ total_processed) ** 0.5\n\n        try:\n            pbar.set_postfix({\n                'loss' : '%.4f' %float(running_loss),\n                \"rmse\": '%.4f' %float(running_rmse),\n                'lr' : optimizer.param_groups[0]['lr']\n            })\n        except:\n            pass\n\n        del loss, batch, outputs\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        scheduler.step()  # update scheduler on every step end\n\n    return model, running_loss, running_rmse","b3ff6d96":"def valid_fn(model, data_loader, test_data, cfg):\n\n    model.eval()\n\n    total_se = 0.0\n    total_loss = 0.0\n    total_processed = 0\n\n    #with torch.inference_mode():\n    with torch.no_grad():\n        for step, batch in enumerate(data_loader):\n            batch = {key: val.to(cfg.device, non_blocking=True) for key, val in batch.items()}\n            bs = batch[\"image\"].size(0)\n            outputs = model(batch)\n            loss = model.loss(outputs, batch, lam=0.)\n\n            # running loss & mse\n            total_loss += loss.cpu().detach().item() * bs\n            total_processed += bs\n            running_loss = total_loss \/ total_processed\n\n            total_se += torch.square(batch[\"target\"].detach() - outputs[\"ps\"].detach()).cpu().numpy().sum()\n    \n    rmse = (total_se \/ total_processed) ** 0.5\n\n    valstr = \"Test       :\" if test_data else \"Validation :\"\n    print(f\"[{datetime.datetime.now()}] {valstr} loss={running_loss:.6f}, \"\n          f\"rmse={rmse:.6f}\"\n         )\n\n    del loss, batch, outputs\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return running_loss, rmse","47f5c55d":"def plot_history(history_trn, history_val):\n    '''Plot training and validation history graphs.'''\n\n    train_score = history_trn['score']\n    train_loss = history_trn['loss']\n    val_score = history_val['score']\n    val_loss = history_val['loss']\n    epochs = range(1, len(train_score) + 1)\n    plt.figure(figsize=(12, 6), tight_layout=True)\n\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_score, 'b', label='training rmse')\n    plt.plot(epochs, val_score, 'r', label='validation rmse')\n    plt.title('RMSE')\n    plt.legend(loc='best')\n    plt.grid()\n    plt.xlabel('epoch')\n    plt.ylabel('rmse')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_loss, 'b', label='training loss')\n    plt.plot(epochs, val_loss, 'r', label='validation loss')\n    plt.title('loss')\n    plt.legend(loc='best')\n    plt.grid()\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n\n    plt.show()","a3f59d58":"train_start_time = time.time()\nbest_valid_scores = []\n\n### Training\ncfg = CFG\n\nfor fold in range(cfg.n_folds):\n    if fold not in cfg.trn_folds:\n        continue\n\n    print(\"\")\n    print(\"=\" * 100)\n    print(f\"[{datetime.datetime.now()}] Fold {fold} \/ {cfg.n_folds - 1}\")\n    print(\"=\" * 100)\n\n    fold_start_time = time.time()\n\n    train_df = df[df[\"kfold\"] != fold].reset_index(drop=True)\n    valid_df = df[df[\"kfold\"] == fold].reset_index(drop=True)\n\n    ### Model\n    model = DLDLModel(cfg=cfg, pretrained=True)\n    if cfg.replace_mixout:\n        model = replace_mixout(model, cfg.mixout_p)\n    model = model.to(cfg.device)\n    model.zero_grad()\n\n    ### Dataloader\n    train_dataset = PawpularDataset(df=train_df, cfg=cfg, augment=train_aug, mode=\"train\")\n    valid_dataset = PawpularDataset(df=valid_df, cfg=cfg, augment=valid_aug, mode=\"valid\")\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=cfg.batch_size,\n        shuffle=True,\n        drop_last=True,\n        sampler=None,\n        worker_init_fn=worker_init_fn,\n        pin_memory=False,\n        num_workers=cfg.num_workers\n    )\n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=cfg.batch_size_infer,\n        shuffle=False,\n        worker_init_fn=worker_init_fn,\n        pin_memory=False,\n        num_workers=cfg.num_workers\n    )\n    ### Optimizer\n    optimizer = make_optimizer(model, cfg)\n\n    ### Scheduler\n    scheduler = make_scheduler(len(train_loader), optimizer, cfg)\n\n    ### Train epochs\n    best_valid_score_epoch = 0\n    best_valid_score = np.inf\n    best_valid_loss = np.inf\n    history_train = {'loss': [], 'score': []}\n    history_valid = {'loss': [], 'score': []}\n\n    for epoch in range(1, cfg.n_epochs + 1):\n        if epoch in cfg.mixup_epoch_p:\n            cfg.mixup_p = cfg.mixup_epoch_p[epoch]\n            print(f\"[{datetime.datetime.now()}] MixUp p={cfg.mixup_p}, alpha={cfg.mix_alpha}\")\n\n        time.sleep(0.3)  # prevent splitting tqdm progress bar\n\n        ### train\n        model, train_loss, train_score = train_one_epoch(fold, epoch, model, train_loader, optimizer, scheduler, cfg)\n        history_train['loss'].append(train_loss)\n        history_train['score'].append(train_score)\n\n        ### valid score\n        valid_loss, valid_score = valid_fn(model, valid_loader, test_data=False, cfg=cfg)\n        history_valid['loss'].append(valid_loss)\n        history_valid['score'].append(valid_score)\n\n        if valid_score < best_valid_score:\n            best_valid_score = valid_score\n            best_valid_score_epoch = epoch\n            best_valid_loss = valid_loss\n            if epoch >= cfg.min_save_epoch:\n                print(f\"[{datetime.datetime.now()}] Validation score improved. Saving model weights to {cfg.save_model_path}-fold{fold}.pth\")\n                torch.save(model.state_dict(), cfg.save_model_path + f\"-fold{fold}.pth\")\n\n        if (valid_loss < best_valid_loss) and (epoch >= cfg.min_save_epoch) \\\n            and (valid_score == best_valid_score) and (epoch > best_valid_score_epoch):\n                best_valid_loss = valid_loss\n                print(f\"[{datetime.datetime.now()}] Validation loss improved. Saving model weights to {cfg.save_model_path}-fold{fold}.pth\")\n                torch.save(model.state_dict(), cfg.save_model_path + f\"-fold{fold}.pth\")\n\n\n    ### fold summary\n    best_valid_scores.append(best_valid_score)\n\n    # Print fold summary\n    train_elapsed_time = time.time() - train_start_time\n    fold_elapsed_time = time.time() - fold_start_time\n    print(\"\")\n    print('Fold elapsed time: {:.0f} min {:.0f} sec'.format(fold_elapsed_time \/\/ 60, fold_elapsed_time % 60))\n    print('Training elapsed time: {:.0f} min {:.0f} sec'.format(train_elapsed_time \/\/ 60, train_elapsed_time % 60))\n\n    ### valid score\n    print('Epoch({}\/{}): Best validation accuracy: {:4f}'.format(best_valid_score_epoch, cfg.n_epochs, best_valid_score))\n\n    print()\n    print(\"history_valid\")\n    plot_history(history_train, history_valid)\n\n    del model, train_loader, valid_loader, train_dataset, valid_dataset, optimizer, scheduler, history_train, history_valid, train_df, valid_df\n    torch.cuda.empty_cache()\n    gc.collect()\n\n\nprint(f\"CV RMSE : {np.mean(best_valid_scores)}\")","555324b5":"# CatBoost Parameters\ncb_params = {'loss_function' : 'RMSE',\n             'eval_metric' : 'RMSE',\n             'iterations' : 1000,\n             'grow_policy' : 'SymmetricTree',\n             'depth' : 6,\n             'l2_leaf_reg' : 2.0,\n             'random_strength' : 1.0,\n             'learning_rate' : 0.05,\n             'task_type' : 'CPU',\n             'devices' : '0',\n             'verbose' : 0,\n             'random_state': CFG.seed}","9aca66d1":"def get_test_aug(image_size, tta):\n    if tta == 0:\n        return nn.Sequential(\n            T.Resize(image_size),\n            T.CenterCrop(image_size),\n            T.ConvertImageDtype(torch.float),\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        )\n    elif tta == 1:\n        return nn.Sequential(\n            T.Resize((image_size, image_size)),\n            T.ConvertImageDtype(torch.float),\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        )\n    else:\n        return nn.Sequential(\n            T.Resize(image_size),\n            T.CenterCrop(image_size),\n            T.RandomHorizontalFlip(p=1),\n            T.ConvertImageDtype(torch.float),\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        )","08190e84":"df_oof_pred = df[[\"Id\", \"Pawpularity\"]].copy()\ndf_oof_pred[\"oof_pred\"] = -1\n\noof_trues = []\noof_valid_embeds = []\n\nfor fold_ in range(CFG.n_folds):\n    print(f\"[{datetime.datetime.now()}] Fold {fold_}\/{CFG.n_folds - 1} predicting oof...\")\n\n    ### NN Model\n    model = DLDLModel(cfg=CFG, pretrained=False)\n    model.load_state_dict(torch.load(CFG.save_model_path + f\"-fold{fold_}.pth\", map_location='cpu'))\n    model = model.eval().to(CFG.device)\n\n    ### Datasets and Dataloaders\n    df_valid = df[df.kfold == fold_].reset_index(drop=True)\n    valid_dataset = PawpularDataset(df=df_valid, cfg=CFG, augment=get_test_aug(CFG.image_size, tta=0), mode=\"valid\")\n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=CFG.batch_size_infer,\n        shuffle=False,\n        worker_init_fn=worker_init_fn,\n        pin_memory=False,\n        num_workers=CFG.num_workers\n    )\n\n    ### OOF predictions of NN\n    valid_embeds = []\n    valid_pss = []\n    #with torch.inference_mode():\n    with torch.no_grad():\n        for step, batch in enumerate(tqdm(valid_loader, ncols=100)):\n            batch = {key: val.to(CFG.device, non_blocking=True) for key, val in batch.items()}\n            output_ = model(batch, embed=True)\n            valid_embed = output_[\"feat\"].detach().cpu()\n            valid_embeds.append(valid_embed)\n            valid_ps = output_[\"ps\"].detach().cpu()\n            valid_pss.append(valid_ps)\n\n        valid_pred_nn = np.clip(target_to_paw(torch.cat(valid_pss, dim=0).numpy()), 1, 100)\n\n    df_oof_pred[\"oof_pred\"].iloc[np.where(df.kfold == fold_)] = valid_pred_nn\n    oof_valid_embeds.append(torch.cat(valid_embeds, dim=0))\n    oof_trues.append(df_valid['Pawpularity'].values.astype('int32'))\n#     valid_embeds = torch.cat(valid_embeds, dim=0).numpy()\n#     if fold_ == 0:\n#         sorted_oof_embeds = np.zeros((len(df), valid_embeds.shape[1]), dtype=np.float32)\n#     sorted_oof_embeds[np.where(df.kfold == fold_)] = valid_embeds\n\nvalid_embeds_all = torch.cat(oof_valid_embeds, dim=0).numpy()\noof_trues_all = np.concatenate(oof_trues)\n\ndf_oof_pred.to_csv(CFG.save_model_path + f\".csv\", index=False)\nprint()\nprint(\" RMSE of NN OOF preds :\", mean_squared_error(df_oof_pred.Pawpularity.values, df_oof_pred.oof_pred, squared=False))\nprint()\ndisplay(df_oof_pred)\n\n## Histogram\nplt.figure(figsize=(12, 4), tight_layout=True)\nplt.hist(df_oof_pred.oof_pred, bins=100, alpha=0.3, color='red', label='Pred')\nplt.hist(df_oof_pred.Pawpularity, bins=100, alpha=0.3, color='blue', label='True')\nplt.legend()\nplt.show()\n\n## Scatter plot\nplt.figure(figsize=(8, 8), tight_layout=True)\nplt.scatter(df_oof_pred.Pawpularity, df_oof_pred.oof_pred, s=2)\nplt.xlabel(\"True\")\nplt.ylabel(\"Pred\")\nplt.show()","e84123b3":"df_oof_pred[\"oof_pred_svr\"] = -1\ndf_oof_pred[\"oof_pred_cat\"] = -1\n\nfor fold_ in range(CFG.n_folds):\n    print(\"\")\n    print(\"=\" * 100)\n    print(f\"[{datetime.datetime.now()}] Fold {fold_} \/ {CFG.n_folds - 1}\")\n    print(\"=\" * 100)\n\n    ### Split embeddings\n    ## Caution: following folds are different from the folds used in NN training.\n    train_embeds = valid_embeds_all[np.where(df.kfold != fold_)]\n    valid_embeds = valid_embeds_all[np.where(df.kfold == fold_)]\n    train_trues = oof_trues_all[np.where(df.kfold != fold_)]\n    valid_trues = oof_trues_all[np.where(df.kfold == fold_)]\n\n    ### Fit SVR\n    print('Fitting SVR...')\n    clf1 = SVR(C=20.0)\n    clf1.fit(train_embeds.astype('float32'), train_trues)\n\n    ### Fit Catboost\n    print(f'Fitting Catboost...')\n    clf2 = CatBoostRegressor(**cb_params)\n    clf2.fit(train_embeds, train_trues,\n            eval_set=[(valid_embeds, valid_trues)],\n            early_stopping_rounds=100, use_best_model=True, verbose=25)\n\n    ### Save extra head model\n    fname_svr = os.path.join(OUTPUT_PATH, f\"SVR_fold_{fold_}.pkl\")\n    fname_cat = os.path.join(OUTPUT_PATH, f\"CAT_fold_{fold_}.pkl\")\n    pickle.dump(clf1, open(fname_svr, \"wb\"))\n    pickle.dump(clf2, open(fname_cat, \"wb\"))\n\n    ### OOF predictions of additional heads\n    print()\n    print(\"Predicting SVR...\")\n    valid_pred_svr = clf1.predict(valid_embeds)\n    df_oof_pred[\"oof_pred_svr\"].loc[df[\"kfold\"] == fold_] = valid_pred_svr\n    print(\"Predicting Catboost...\")\n    valid_pred_cat = clf2.predict(valid_embeds)\n    df_oof_pred[\"oof_pred_cat\"].loc[df[\"kfold\"] == fold_] = valid_pred_cat\n    print(\"RMSE of valid predictions:\")\n    print(\" - SVR :\", mean_squared_error(valid_trues, valid_pred_svr, squared=False))\n    print(\" - CAT :\", mean_squared_error(valid_trues, valid_pred_cat, squared=False))","b3abf43c":"### CV\nprint(\"RMSE of OOF predictions:\")\nprint(\" - NN :\", mean_squared_error(df_oof_pred.Pawpularity.values, df_oof_pred[\"oof_pred\"].values, squared=False))\nprint(\" - SVR :\", mean_squared_error(oof_trues_all, df_oof_pred[\"oof_pred_svr\"].values, squared=False))\nprint(\" - CAT :\", mean_squared_error(oof_trues_all, df_oof_pred[\"oof_pred_cat\"].values, squared=False))","b43843b5":"N_TTA = 3\n\nSTATE_DICTS = [\n    f\"{cfg.save_model_path}-fold0.pth\",\n    f\"{cfg.save_model_path}-fold1.pth\",\n    f\"{cfg.save_model_path}-fold2.pth\",\n    f\"{cfg.save_model_path}-fold3.pth\",\n    f\"{cfg.save_model_path}-fold4.pth\",\n]\nPKL_PATH_SVRS = [\n    f\"{OUTPUT_PATH}\/SVR_fold_0.pkl\",\n    f\"{OUTPUT_PATH}\/SVR_fold_1.pkl\",\n    f\"{OUTPUT_PATH}\/SVR_fold_2.pkl\",\n    f\"{OUTPUT_PATH}\/SVR_fold_3.pkl\",\n    f\"{OUTPUT_PATH}\/SVR_fold_4.pkl\",\n]\nPKL_PATH_CATS = [\n    f\"{OUTPUT_PATH}\/CAT_fold_0.pkl\",\n    f\"{OUTPUT_PATH}\/CAT_fold_1.pkl\",\n    f\"{OUTPUT_PATH}\/CAT_fold_2.pkl\",\n    f\"{OUTPUT_PATH}\/CAT_fold_3.pkl\",\n    f\"{OUTPUT_PATH}\/CAT_fold_4.pkl\",\n]","c8069008":"df_test = pd.read_csv(TEST_CSV)\ndf_test[\"file_path\"] = [os.path.join(TEST_DATA_PATH, f\"{id}.jpg\") for id in df_test.Id]","10d1411c":"cfg = CFG\n\n### model list\nmodels = []\nclf_svrs = []\nclf_cats = []\n\n### Loading NN models\nfor state_dict in STATE_DICTS:\n    print(f\"Loading {CFG.model_name} : {state_dict}\")\n    model = DLDLModel(cfg=cfg)\n    model.load_state_dict(torch.load(state_dict, map_location='cpu'))\n    model.eval().to(cfg.device)\n    models.append(model)\n\n## Loading SVR head models\nfor pkl_path_svr in PKL_PATH_SVRS:\n    print(f\"Loading {pkl_path_svr}\")\n    clf_svrs.append(pickle.load(open(pkl_path_svr, \"rb\")))\n\n## Loading CAT head models\nfor pkl_path_cat in PKL_PATH_CATS:\n    print(f\"Loading {pkl_path_cat}\")\n    clf_cats.append(pickle.load(open(pkl_path_cat, \"rb\")))\n\n\n### TTA loop\npreds_nn_all = []\npreds_svr_all = []\npreds_cat_all = []\n\nfor tta in range(N_TTA):\n    seed_everything(cfg.seed + 20 + tta)\n    print()\n    print(\"=\" * 40)\n    print(f\"Inference TTA [{tta}\/{N_TTA - 1}]\")\n    print(\"=\" * 40)\n\n    ### Dataloader\n    dataset = PawpularDataset(df_test, cfg, augment=get_test_aug(cfg.image_size, tta), mode=\"test\")\n    data_loader = DataLoader(\n        dataset,\n        batch_size=cfg.batch_size_infer,\n        shuffle=False,\n        pin_memory=False,\n        num_workers=cfg.num_workers\n    )\n\n    ### inference\n    ps_nns2_ = []\n    ps_svrs2_ = []\n    ps_cats2_ = []\n    pbar = tqdm(data_loader, desc=f\"Inference\", ncols=80)\n    for _, batch in enumerate(pbar):\n        batch = {key: val.to(cfg.device, non_blocking=True) for key, val in batch.items()}\n        ps_nns_ = []\n        ps_svrs_ = []\n        ps_cats_ = []\n        #with torch.inference_mode():\n        with torch.no_grad():\n            for num, model in enumerate(models):\n                ### NN pred and extract embed\n                output_ = model(batch, embed=True)\n                ps_ = target_to_paw(output_['ps'].detach().cpu())\n                ps_nns_.append(ps_)\n\n                ### extra head pred\n                embed_ = output_[\"feat\"].detach().cpu().numpy()\n                ps_svr_ = clf_svrs[num].predict(embed_)  # (bs)\n                ps_cat_ = clf_cats[num].predict(embed_)  # (bs)\n                ps_svrs_.append(ps_svr_)  # -> [models, (bs)]\n                ps_cats_.append(ps_cat_)  # -> [models, (bs)]\n\n        ps_nns_ = torch.stack(ps_nns_).permute(1, 0)  # (bs, models)\n        ps_nns2_.append(ps_nns_)  # -> [steps, (bs, models)]\n        ps_svrs_ = np.stack(ps_svrs_).transpose(1, 0)  # (bs, models)\n        ps_svrs2_.append(ps_svrs_)  # -> [steps, (bs, models)]\n        ps_cats_ = np.stack(ps_cats_).transpose(1, 0)  # (bs, models)\n        ps_cats2_.append(ps_cats_)  # -> [steps, (bs, models)]\n\n    ps_nns2_ = torch.cat(ps_nns2_).permute(1, 0)  # (models, steps*bs)\n    preds_nn_all.append(ps_nns2_)  # -> [tta, (models, bs*steps)]\n    ps_svrs2_ = np.concatenate(ps_svrs2_).transpose(1, 0)  # (models, steps*bs)\n    preds_svr_all.append(ps_svrs2_)  # -> [tta, (models, bs*steps)]\n    ps_cats2_ = np.concatenate(ps_cats2_).transpose(1, 0)  # (models, steps*bs)\n    preds_cat_all.append(ps_cats2_)  # -> [tta, (models, bs*steps)]\n\npreds_nn_all = torch.cat(preds_nn_all).detach().cpu().numpy()  # (tta*models, bs*steps)\npreds_svr_all = np.concatenate(preds_svr_all)  # (tta*models, bs*steps)\npreds_cat_all = np.concatenate(preds_cat_all)  # (tta*models, bs*steps)\n\ndel batch, dataset, data_loader, output_\ngc.collect()\ntorch.cuda.empty_cache()","7d1ee048":"df_test[\"Pawpularity\"] = (np.mean(preds_nn_all, axis=0) + np.mean(preds_cat_all, axis=0) + np.mean(preds_svr_all,axis=0)) \/ 3\ndf_test[[\"Id\", \"Pawpularity\"]].to_csv(\"submission.csv\", index=False)\ndf_test[[\"Id\", \"Pawpularity\"]]","7ff80169":"EOF","30b563ad":"## Training and validation","810f06b7":"## MixUp","f0798260":"## MixOut","e71071e2":"## An example of training and inference with Deep Label Distribution Learning (DLDL) model used in [9th place solution](https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/300947)","bf228fe9":"## Torchvision transforms","ac3f2b82":"The following points are different from the competition due to environmental constraints. Therefore, the score is poor.\n\n| Difference | This Notebook | Competition |\n| --- | --- | --- |\n| model_name | swin_base_patch4_window7_224 | swin_large_patch4_window12_384 |\n| image_size | 224 | 384 |\n| n_epochs | 8 | 16 |\n| Training environment | Kaggle | Google Colab Pro|\n| PyTorch | 1.9.1 | 1.10.1 |\n| RandAugment | Not used | Used |\n| Metadata | Not used | Used (Probably not necessary)|","003e407d":"## Functions","f93d393a":"# Inference","c027e6ac":"## Model","cb885118":"## Train additional heads","a69d9d54":"## Config","2867f298":"## OOF pred and save SVR & Catboost models","2ab33ced":"## Main","00f96353":"## Load CSV"}}