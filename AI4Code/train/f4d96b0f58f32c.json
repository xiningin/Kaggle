{"cell_type":{"b4cb7948":"code","4dc0e545":"code","05c49650":"code","346e4620":"code","bdf3050f":"code","ba9be3c4":"code","e8d0f9c9":"code","e8dc8edc":"code","61dcdc44":"code","0d17bb0e":"code","7e3d8f62":"code","2d0e6bbe":"code","f5ddbb57":"code","a820c4a6":"code","7fe5c53d":"code","4bedf9d0":"markdown"},"source":{"b4cb7948":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport cv2\nfrom scipy.spatial import distance","4dc0e545":"mask_path = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\"\nno_mask_path = \"..\/input\/human-faces\/Humans\"","05c49650":"image_mask = []\ntarget_mask = []\nfor i in os.listdir(mask_path):\n    pic = os.path.join(mask_path + \"\/\", i)\n    image_mask.append(pic)\n    target_mask.append(1)   ","346e4620":"image_no_mask = []\ntarget_no_mask = []\nfor i in os.listdir(no_mask_path):\n    pic = os.path.join(no_mask_path + \"\/\", i)\n    image_no_mask.append(pic)\n    target_no_mask.append(0)","bdf3050f":"mask = pd.DataFrame()\nmask[\"image\"] = image_mask\nmask[\"target\"] = target_mask","ba9be3c4":"no_mask = pd.DataFrame()\nno_mask[\"image\"] = image_no_mask\nno_mask[\"target\"] = target_no_mask","e8d0f9c9":"data = pd.concat([mask, no_mask], axis=0, ignore_index=True)\ndata = shuffle(data)\ndata","e8dc8edc":"import torch\n\nfrom PIL import Image, ImageFile\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nclass dataset:\n    def __init__(self, image_path, targets, resize = None, augmentation = None):\n        \n        self.image_path = image_path\n        self.targets = targets\n        self.resize = resize\n        self.augmentation = augmentation\n        \n    def __len__(self):\n        \n        return len(self.image_path)\n\n    def __getitem__(self, item):\n        \n        image = Image.open(self.image_path[item])\n        \n        image = image.convert(\"RGB\")\n        \n        target = self.targets[item]\n        \n        if self.resize is not None:\n            image = image.resize((\n                self.resize[1], self.resize[0]\n            ),\n            resample = Image.BILINEAR\n            )\n            \n        image = np.array(image)\n        \n        if self.augmentation is not None:\n            augmented = self.augmentation(image=image)\n            image = augmented[\"image\"]\n            \n            \n        image = np.transpose(image, (2,0,1)).astype(np.float32)\n            \n        return {\n            \"image\" : torch.tensor(image, dtype= torch.float),\n            \"target\" : torch.tensor(target, dtype= torch.long),\n        }","61dcdc44":"pip install pretrainedmodels\n","0d17bb0e":"#engine\n\nimport torch\nimport torch.nn as nn\n\ndef train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in data_loader:\n        inputs = data[\"image\"]\n        targets = data[\"target\"]\n        \n        inputs = inputs.to(device, dtype = torch.float)\n        targets = targets.to(device, dtype= torch.float)\n        \n        optimizer.zero_grad()\n        \n        output = model(inputs)\n       \n        loss = nn.BCEWithLogitsLoss()(output, targets.view(-1,1))\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        \ndef evaluation(data_loader, model, device):\n    \n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in data_loader:\n            \n            inputs = data[\"image\"]\n            targets = data[\"target\"]\n            \n            inputs = inputs.to(device, dtype= torch.float)\n            targets = targets.to(device, dtype = torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","7e3d8f62":"import pretrainedmodels\n\ndef get_model(pretrained):\n    if pretrained:\n        model = pretrainedmodels.__dict__[\"resnet34\"](\n                pretrained=\"imagenet\"\n        )\n        \n    else:\n        model = pretrainedmodels.__dict__[\"resnet34\"](\n                pretrined = None\n        )\n        \n    model.last_linear = nn.Sequential(\n                nn.BatchNorm1d(512),\n            nn.Dropout(p=0.25),\n            nn.Linear(in_features = 512, out_features = 100),\n            nn.ReLU(),\n                nn.BatchNorm1d(100 ,eps=1e-05, momentum=0.1),\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features = 100, out_features = 1 ),\n        nn.Sigmoid()\n       \n            )\n    return model","2d0e6bbe":"\n\nimport albumentations\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\ndevice = 'cuda'\nepoch = 10\ntargets = data.target.values\nimage = data.image.values\nmodel = get_model(pretrained=True)\nmodel.to(device)\n\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\naug = albumentations.Compose(\n[\n    albumentations.Normalize(\n    mean, std, max_pixel_value=255.0, always_apply= True\n    )\n]\n)\n\n\ntrain_images, valid_images, train_targets, valid_targets = train_test_split(image, targets, stratify=targets, random_state=42)\n\ntrain_dataset = dataset(image_path= train_images, targets = train_targets, resize = (100,100), augmentation=aug)\n\ntrain_loader = torch.utils.data.DataLoader( train_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\nvalid_dataset = dataset(image_path= valid_images, targets= valid_targets, resize= (100,100), augmentation= aug)\n\nvalid_loader = torch.utils.data.DataLoader( valid_dataset, batch_size = 16, shuffle = True, num_workers = 4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 5e-4)\n\n\n\n\n","f5ddbb57":"epochs = 15\nfor epoch in range(epochs):\n    \n    train(train_loader, model, optimizer, device = device)\n    \n    prediction, valid_targets = evaluation( valid_loader, model, device = device )\n    \n    roc_auc = metrics.roc_auc_score(valid_targets, prediction)\n    print(roc_auc)","a820c4a6":"torch.save(model.state_dict(), '.\/model_new')","7fe5c53d":"prediction\n\n","4bedf9d0":"![](https:\/\/defenders.org\/sites\/default\/files\/2019-08\/convolutional_neural_network_for_image_classification_dow.jpg)"}}