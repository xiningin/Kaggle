{"cell_type":{"40f4a2f4":"code","3fbd5569":"code","56e61058":"code","4175c93c":"code","293e2f38":"code","16fae369":"code","6c6de42a":"code","530828bd":"code","7c148581":"code","6b742616":"code","227c55df":"code","d8ab0373":"code","6c4c570f":"code","481ee8ec":"code","8af2b9e8":"code","6d0bfa5b":"code","4fb5391a":"code","7827ebf0":"code","cc445be3":"code","b61911d7":"code","937bc3aa":"code","84bcc2ff":"code","117d895f":"code","b13a17c0":"code","1ec24664":"code","6fd694bd":"code","624577b0":"code","48fac8f9":"code","2abc153d":"code","85536ba8":"code","22451dcc":"code","2d444751":"code","19357d5e":"code","7c41de82":"code","686ad818":"code","8f5172aa":"code","39304689":"code","06e1d41e":"markdown","e150e18c":"markdown","178929b9":"markdown","9f95af6a":"markdown","ca2ec5bb":"markdown","86726d86":"markdown","63ea4568":"markdown","daedcf47":"markdown","9a5d5605":"markdown","b385dd79":"markdown","3b32c990":"markdown","c85cc716":"markdown","a839060a":"markdown","2def177d":"markdown","a71e89dd":"markdown","44598047":"markdown","14d15e2e":"markdown","a741bacb":"markdown","90c5290a":"markdown","fec8e5a4":"markdown","1cce0c96":"markdown","30be5db9":"markdown","9e4cca70":"markdown","f06ff8d9":"markdown","aa43cb05":"markdown","1502a403":"markdown","fa07c211":"markdown","f19d1dbb":"markdown","60a932f9":"markdown","6afc2e39":"markdown"},"source":{"40f4a2f4":"import gc\nimport os\nimport wandb\nimport logging\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nwarnings.filterwarnings('ignore')","3fbd5569":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"api_key\")\nos.environ[\"WANDB_SILENT\"] = \"true\"","56e61058":"wandb.login(key=secret_value_0)","4175c93c":"# Load csv data of this competition.\n\nDATA = \"..\/input\/tabular-playground-series-jun-2021\"\ntrain_df = pd.read_csv(DATA + \"\/train.csv\")\ntest_df = pd.read_csv(DATA + \"\/test.csv\")","293e2f38":"train_df.shape, test_df.shape","16fae369":"run = wandb.init(job_type=\"dataset-creation\")\nartifact = wandb.Artifact('my-dataset', type='dataset')\nartifact.add_file('..\/input\/tabular-playground-series-jun-2021\/train.csv')\nrun.log_artifact(artifact)","6c6de42a":"# Initialize a new W&B run\ntrain1_df = wandb.Table(dataframe=train_df)\nrun = wandb.init(project='TPSJune')\nwandb.log({'train1_df': train1_df})\nrun.finish()    \nrun","530828bd":"train_df.head()","7c148581":"test_df.head()","6b742616":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","227c55df":"%%time\nmissing_data(train_df)","d8ab0373":"%%time\nmissing_data(test_df)","6c4c570f":"%%time\ntrain_df.describe().T.style.bar(subset=['mean'], color='#ea9999')\\\n                   .background_gradient(subset=['std'], cmap='YlOrBr')","481ee8ec":"train_df = train_df[:100000]\ntest_df = test_df[:100000]","8af2b9e8":"def plot_feature_scatter(df1, df2, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(4,4,figsize=(14,14))\n\n    for feature in features:\n        i += 1\n        plt.subplot(4,4,i)\n        plt.scatter(df1[feature], df2[feature], marker='+' , color = \"#FFB14E\")\n        plt.xlabel(feature, fontsize=9)\n    plt.show();","6d0bfa5b":"features = [feature for feature in train_df.columns if feature not in ['id', 'target']]\nfeatures = features[:16]","4fb5391a":"plot_feature_scatter(train_df[::20],test_df[::20], features)","7827ebf0":"run = wandb.init(project='TPSJune', job_type='image-visualization',name='Target Feature Count')\ntargetcount_train = pd.DataFrame(train_df['target'].value_counts())\ntargetcount_train = targetcount_train.reset_index(drop=False)\ntargetcount_train.columns = ['TargetClass', 'Count']\ntable = wandb.Table(data=targetcount_train, columns = [\"TargetClass\", \"Count\"])\nwandb.log({\"my_bar_chart_id\" : wandb.plot.bar(table, \"TargetClass\",\"Count\", title=\"Target Feature Count\")})\n\n\nrun.finish()\n\nrun","cc445be3":"\n#sns.countplot(train_df['target'], palette='Set3')\n#plt.xticks(rotation=45)\n\n","b61911d7":"run = wandb.init(project='TPSJune', job_type='image-visualization',name='Unique Values')\n\nfeatures = [feature for feature in train_df.columns if feature not in ['id', 'target']]\nunique_values_train = np.zeros(2)\nfor feature in features:\n    temp = train_df[feature].unique()\n    unique_values_train = np.concatenate([unique_values_train, temp])\nunique_values_train = np.unique(unique_values_train)\n\nunique_value_feature_train = pd.DataFrame(train_df[features].nunique())\nunique_value_feature_train = unique_value_feature_train.reset_index(drop=False)\nunique_value_feature_train.columns = ['Features', 'Count']\n\ntable = wandb.Table(data=unique_value_feature_train, columns = [\"Features\", \"Count\"])\nwandb.log({\"Unique Train Features\" : wandb.plot.histogram(table, \"Features\", title=\"Unique Train Features\")})\n\n\nrun.finish()\n\nrun","937bc3aa":"def plot_feature_distribution(df1,df2,df3,df4,df5,df6,df7,df8,df9,features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(3,3,figsize=(18,22))\n\n    for feature in features:\n        i += 1\n        plt.subplot(3,3,i)\n        sns.distplot(df1[feature], hist=False,label=\"Class 1\")\n        sns.distplot(df2[feature], hist=False,label=\"Class 2\")\n        sns.distplot(df3[feature], hist=False,label=\"Class 3\")\n        sns.distplot(df4[feature], hist=False,label=\"Class 4\")\n        sns.distplot(df5[feature], hist=False,label=\"Class 5\")\n        sns.distplot(df6[feature], hist=False,label=\"Class 6\")\n        sns.distplot(df7[feature], hist=False,label=\"Class 7\")\n        sns.distplot(df8[feature], hist=False,label=\"Class 8\")\n        sns.distplot(df9[feature], hist=False,label=\"Class 9\")\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.legend()\n        plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n        plt.tick_params(axis='y', which='major', labelsize=6)\n    \n    plt.show();","84bcc2ff":"features = [feature for feature in train_df.columns if feature not in ['id', 'target']]\nfeatures = features[:9]","117d895f":"t1 = train_df.loc[train_df['target'] == 'Class_1']\nt2 = train_df.loc[train_df['target'] == 'Class_2']\nt3 = train_df.loc[train_df['target'] == 'Class_3']\nt4 = train_df.loc[train_df['target'] == 'Class_4']\nt5 = train_df.loc[train_df['target'] == 'Class_5']\nt6 = train_df.loc[train_df['target'] == 'Class_6']\nt7 = train_df.loc[train_df['target'] == 'Class_7']\nt8 = train_df.loc[train_df['target'] == 'Class_8']\nt9 = train_df.loc[train_df['target'] == 'Class_9']\nplot_feature_distribution(t1, t2,t3,t4,t5,t6,t7,t8,t9,features)","b13a17c0":"features = [feature for feature in train_df.columns if feature not in ['id', 'target']]\n","1ec24664":"run = wandb.init(project='TPSJune', job_type='image-visualization',name='Distribution of mean values')\nmean_train = pd.DataFrame(train_df[features].mean())\nmean_train = mean_train.reset_index(drop=True)\nmean_train.columns = ['MeanDistribution']\ntable = wandb.Table(data=mean_train, columns = [\"MeanDistribution\"])\nwandb.log({\"Distribution of mean values\" : wandb.plot.histogram(table, \"MeanDistribution\", title=\"Distribution of mean values\")})\n\n\nrun.finish()\n\nrun","6fd694bd":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values\")\nsns.distplot(train_df[features].mean(axis=0),color=\"magenta\",kde=True,bins=120, label='train')\nsns.distplot(test_df[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","624577b0":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values\")\nsns.distplot(train_df[features].std(),color=\"blue\",kde=True,bins=120, label='train')\nsns.distplot(test_df[features].std(),color=\"green\", kde=True,bins=120, label='test')\nplt.legend(); plt.show()","48fac8f9":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of min values \")\nsns.distplot(train_df[features].min(),color=\"red\", kde=True,bins=120, label='train')\nsns.distplot(test_df[features].min(),color=\"orange\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","2abc153d":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of max values \")\nsns.distplot(train_df[features].max(),color=\"brown\", kde=True,bins=120, label='train')\nsns.distplot(test_df[features].max(),color=\"yellow\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","85536ba8":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew \")\nsns.distplot(train_df[features].skew(),color=\"red\", kde=True,bins=120, label='train')\nsns.distplot(test_df[features].skew(),color=\"orange\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","22451dcc":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of kurtosis \")\nsns.distplot(train_df[features].kurtosis(),color=\"darkblue\", kde=True,bins=120, label='train')\nsns.distplot(test_df[features].kurtosis(),color=\"yellow\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","2d444751":"%%time\ncorrelations = train_df[features].corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']]\ncorrelations.head(10)","19357d5e":"correlations.tail(10)","7c41de82":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\ncorr_train = train_df.iloc[:20,1:20]\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(corr_train.corr().values,linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","686ad818":"%%time\nunique_max_train = []\nunique_max_test = []\nfor feature in features:\n    values = train_df[feature].value_counts()\n    unique_max_train.append([feature, values.max(), values.idxmax()])\n    values = test_df[feature].value_counts()\n    unique_max_test.append([feature, values.max(), values.idxmax()])","8f5172aa":"np.transpose((pd.DataFrame(unique_max_train, columns=['Feature', 'Max duplicates', 'Value'])).\\\n            sort_values(by = 'Max duplicates', ascending=False).head(15))","39304689":"np.transpose((pd.DataFrame(unique_max_test, columns=['Feature', 'Max duplicates', 'Value'])).\\\n            sort_values(by = 'Max duplicates', ascending=False).head(15))","06e1d41e":"<br>\n<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\"> Tabular Playground Series - June 2021<\/h1>\n<br>","e150e18c":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Missing Data<\/h4> ","178929b9":"\n\n> - ```train\/``` - the training data, one product (id) per row, with the associated features (feature_*) and class label (target)\n> - ```test\/``` - the test data; you must predict the probability the id belongs to each class\n> - ```sample_submission.csv``` - a sample submission file in the correct format \n> ","9f95af6a":"References :\n\nhttps:\/\/www.kaggle.com\/dwin183287\/tps-june-2021-eda\n\nhttps:\/\/www.kaggle.com\/bhuvanchennoju\/data-storytelling-auc-focus-on-strokes\n\nhttps:\/\/www.kaggle.com\/c\/santander-value-prediction-challenge","ca2ec5bb":"<a id = '1'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> Introduction <\/h2>","86726d86":"Work in progress \ud83d\udea7","63ea4568":"A W&B Table (wandb.Table) is a two dimensional grid of data where each column has a single type of data\u2014think of this as a more powerful DataFrame. Tables support primitive and numeric types, as well as nested lists, dictionaries, and rich media types. Log a Table to W&B, then query, compare, and analyze results in the UI.\n\nTables are great for storing, understanding, and sharing any form of data critical to your ML workflow\u2014from datasets to model predictions and everything in between.\n\n[Source ](https:\/\/docs.wandb.ai\/guides\/data-vis)","daedcf47":"Lets explore first five rows of test dataset","9a5d5605":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Correlation of Features<\/h4> ","b385dd79":"Use W&B Artifacts for dataset versioning, model versioning, and tracking dependencies and results across machine learning pipelines. Think of an artifact as a versioned folder of data. You can store entire datasets directly in artifacts, or use artifact references to point to data in other systems like S3, GCP, or your own system.\n\n[Source](https:\/\/docs.wandb.ai\/guides\/artifacts)","3b32c990":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Distribution of Kurtosis<\/h4> ","c85cc716":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Distribution of Skewness<\/h4> ","a839060a":"<h3 style = \"font-family:garamond; font-size:30px; background-color: white; color : #fe346e; border-radius: 100px 100px; text-align:left\">Metric<\/h3>\n\nSubmissions are evaluated using multi-class logarithmic loss. Each row in the dataset has been labeled with one true Class. For each row, you must submit the predicted probabilities that the product belongs to each class label. The formula is:\n\n$$ \\text{log loss} = -\\frac{1}{N}\\sum_{i=1}^N\\sum_{j=1}^My_{ij}\\log(p_{ij}), $$\n\nwhere $N$ is the number of rows in the test set, $M$ is the number of class labels, $\\text{log}$ is the natural logarithm, $y_{ij}$ is 1 if observation $i$ is in class $j$ and 0 otherwise, and $p_{ij}$ is the predicted probability that observation $i$ belongs to class $j$.","2def177d":"<a id = '1.1'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">Data Description<\/h2>","a71e89dd":"<img src=\"https:\/\/camo.githubusercontent.com\/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b\/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\">","44598047":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\">Distribution of max values<\/h4> ","14d15e2e":"<div class=\"alert alert-block alert-warning\">  \n    \nThe train dataset contains 200000 rows and 77 features and test dataset contains 100000 rows and 76 features .Train dataset is twice that of test dataset .\n    \n\nThe columns in the train data are as following:\n    \n\n```id:``` The id of the product( one per row) \n    \n\n```features_* :``` The various attribute of the product starting from ( Feature_0 to Feature_75)\n    \n\n```target:``` Class labels 0 to 9\n    \n    \n\nThe test dataset has same columns except the target value\n\n<\/div>","a741bacb":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Distribution of mean values<\/h4> ","90c5290a":"<h3 style = \"font-family:garamond; font-size:30px; background-color: white; color : #fe346e; border-radius: 100px 100px; text-align:left\">Problem Statement<\/h3>\n\nFor Tabular Playground Series - June 2021 , we have a synthetic dataset generated using CTGAN and the dataset deals with predicting the category on an eCommerce product given various attributes about the listing. Although the features are anonymized, they have properties relating to real-world features.\n","fec8e5a4":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Scatter Plot of Features<\/h4> ","1cce0c96":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\">Target Class<\/h4> ","30be5db9":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> W & B Artifacts<\/h4> ","9e4cca70":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> W & B Tables<\/h4> ","f06ff8d9":"Lets explore first five rows of train dataset","aa43cb05":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\">Distribution of Standard Deviation<\/h4> ","1502a403":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\">Distribution of min values<\/h4> ","fa07c211":"<a id = '1.1'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">Libraries<\/h2>","f19d1dbb":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\"> Checking for Duplicate Values<\/h4> ","60a932f9":"<h4 style = \"background-color: white; color : #fe346e; font-size: 30px; font-family:garamond; font-weight:normal; border-radius: 75px 150px; text-align: left\">Density Plot of Features<\/h4> ","6afc2e39":"### \ud83c\udfafObservations :\n\n\ud83d\udccc There are no missing rows in both test and train dataset"}}