{"cell_type":{"0403d08b":"code","289aa1a5":"code","997d3c05":"code","75b31edf":"code","401d2b27":"code","c09b55f6":"code","8ab053a1":"code","321b2533":"code","174cf800":"markdown"},"source":{"0403d08b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport gc\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","289aa1a5":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv')\nX_test =  pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv')\ntrain.pop('id')\n\ny = train['claim']\ntrain.pop('claim')\nX_test.pop('id')\nX=train\nX['sum_na'] = X.isna().sum(axis=1)\nX_test['sum_na'] = X_test.isna().sum(axis=1)\ndel train\ngc.collect()\n","997d3c05":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense,   Dropout,  Concatenate, Embedding,  Flatten, Add, Average\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler,  QuantileTransformer,  KBinsDiscretizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow import keras\nfrom sklearn import metrics\n\nfrom sklearn.impute import SimpleImputer\n#import tensorflow_decision_forests as tfdf","75b31edf":"def ClassModel(input_shape):\n\n    \n\n    X_input_bin = Input(input_shape)\n    X_input = Input(input_shape)\n    X = Embedding (input_dim=96, output_dim=18)(X_input_bin)\n    #X = Dropout(0.4)(X)\n    X = Flatten()(X)\n\n    \n    X = Dense(30, activation='swish')(X)\n    X1 = Dense(30, kernel_initializer=tf.keras.initializers.GlorotNormal(), activation='swish')(X_input)\n    X = Add()([X,X1])\n    X = Dropout(0.5)(X)\n    X = Dense(30, kernel_initializer=tf.keras.initializers.GlorotNormal(), activation='swish')(X)\n#     X = BatchNormalization()(X)\n    X = Dropout(0.5)(X)\n\n    X = Dense(1, kernel_initializer=tf.keras.initializers.GlorotNormal(),activation='sigmoid', name='output2')(X)\n    model = Model(inputs = [X_input_bin,X_input], outputs = X, name='ClassModel')\n\n    return model\n","401d2b27":"imp = SimpleImputer(missing_values=np.nan, strategy='median')\nX = imp.fit_transform(X)\nX_test = imp.transform(X_test)\nqt = QuantileTransformer(n_quantiles=96, output_distribution='uniform')\nX = qt.fit_transform(X)\nX_test = qt.transform(X_test)\nbin_cat = KBinsDiscretizer(n_bins=96, encode='ordinal',strategy='uniform')\nX_bin = bin_cat.fit_transform(X)\nX_test_bin = bin_cat.transform(X_test)\n\ngc.collect()\ndef prediction (X_train_bin, X_train, y_train, X_test_bin, X_test):\n    \n    keras.backend.clear_session()\n\n    kfold = StratifiedKFold(n_splits = 8, random_state=2021, shuffle=True)\n\n    y_pred = np.zeros((493474,1))\n    BATCH_SIZE=512\n    SHUFFLE_BUFFER_SIZE = 1024\n\n    for idx in kfold.split(X=X_train, y=y_train):\n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X_train[train_idx]\n        xtrain_bin = X_train_bin[train_idx]\n        ytrain = y_train[train_idx]\n        xval = X_train[val_idx]\n        xval_bin = X_train_bin[val_idx]\n        yval = y_train[val_idx]\n\n\n\n        \n        checkpoint_filepath = '\/kaggle\/working\/ckpt_cv'\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_aucroc',\n    mode='max',\n    save_best_only=True)\n        \n        \n#         train_dataset = tf.data.Dataset.from_tensor_slices((np.float32(xtrain), np.float32(ytrain)))\n#         val_dataset = tf.data.Dataset.from_tensor_slices((np.float32(xval), np.float32(yval)))\n#         train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n#         val_dataset = val_dataset.batch(BATCH_SIZE)\n        \n        keras.backend.clear_session()\n        # fit model for current fold\n        classmodel = ClassModel(xtrain.shape[1:])\n        classmodel.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=0.00012), metrics=[tf.keras.metrics.AUC(name='aucroc')])        \n        classmodel.fit([xtrain_bin,xtrain],ytrain,batch_size=512,\n        epochs = 15,\n        validation_data=([xval_bin,xval],yval),\n        callbacks=[model_checkpoint_callback])\n        keras.backend.clear_session()\n        classmodel.load_weights(checkpoint_filepath)\n        #create predictions\n        y_pred += classmodel.predict([X_test_bin,X_test])\/kfold.n_splits\n        del classmodel\n        gc.collect()\n    return y_pred","c09b55f6":"# BATCH_SIZE=1024\n# test_dataset = tf.data.Dataset.from_tensor_slices(np.float32(X_test))\n# test_dataset = test_dataset.batch(BATCH_SIZE)\nmain_pred = prediction(X_bin,X, y, X_test_bin, X_test)","8ab053a1":"main_pred[:10]","321b2533":"sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')\nsub.iloc[:,1]=main_pred\nsub=sub.set_index('id')\nsub.to_csv('baseline_nn_cv.csv')","174cf800":"## 10 - fold section"}}