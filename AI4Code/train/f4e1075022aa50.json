{"cell_type":{"9e4c5c2e":"code","22806c3a":"code","2a771ee4":"code","b99539d0":"code","9be4d1f7":"code","60a1b1a2":"code","0ea7d4a1":"code","b2c0906e":"code","1d30e626":"code","d994b6ab":"code","6dbce753":"code","7bfdff10":"code","04d6da1e":"code","1e91bbe5":"code","95df9962":"code","a80cc4c0":"code","6ad443bb":"code","f952af00":"code","82ad722a":"code","3b3f7ccc":"code","fd555cde":"code","c601cb2c":"code","a7d6c09b":"code","f59a2b1a":"code","7f83dbdd":"code","fb336b15":"code","836e3dd5":"code","2cdefd5c":"code","34681354":"code","403715d0":"code","5f1760e0":"code","4c38b072":"code","a2d5c7ca":"markdown","da7b9fa1":"markdown","5bcc4afb":"markdown","af4e511c":"markdown","4c21ec76":"markdown","0726641b":"markdown","8fcb8ee0":"markdown","ab60cdf5":"markdown","87091f4d":"markdown","db991960":"markdown","fa40fd23":"markdown","ebfcedc9":"markdown","216c0110":"markdown","a14a0499":"markdown","f89c225e":"markdown","ce098c38":"markdown","64fce1bf":"markdown","2c56c1d0":"markdown","2823a980":"markdown","450f0c2d":"markdown","15380b5a":"markdown","132b2398":"markdown","c6eec124":"markdown","1292cff7":"markdown","75999c32":"markdown","554d3a84":"markdown","1be0352a":"markdown","63956b43":"markdown","ef681581":"markdown","c1ef3834":"markdown","61d875d7":"markdown","710eb6e6":"markdown"},"source":{"9e4c5c2e":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\n\nimport time\nimport os\nimport PIL.Image as Image\nfrom IPython.display import display\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nprint(torch.cuda.get_device_name(device))","22806c3a":"path_base = \"..\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data\/\"","2a771ee4":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((400, 400)),\n        transforms.ToTensor()\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((400, 400)),\n        transforms.ToTensor()\n    ]),\n}\n\nbatch_size = 32\n\nimage_datasets = {x: torchvision.datasets.ImageFolder(root=path_base+x, transform=data_transforms[x])\n                  for x in ['train', 'test']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n              for x in ['train', 'test']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\nclass_names = image_datasets['train'].classes","b99539d0":"print('Train data, number of images: ', len(df_train))\nprint('Test data, number of images: ', len(df_test))","9be4d1f7":"def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n    \n    losses = []\n    accuracies = []\n    test_accuracies = []\n    test_losses = []\n    \n    model.to(device)\n    model.train()\n    for epoch in range(n_epochs):\n        print(f'Epoch {epoch}\/{n_epochs-1}')\n        print('-' * 10)\n        running_loss = 0.0\n        running_correct = 0.0\n        total = 0.0\n        \n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            \n            if phase == 'train':\n                losses.append(epoch_loss)\n                accuracies.append(epoch_acc)\n            else:\n                test_losses.append(epoch_loss)\n                test_accuracies.append(epoch_acc)\n            print(f'{phase} Loss: {epoch_loss} Acc: {epoch_acc}')\n        print()\n        \n    return model, losses, accuracies, test_losses, test_accuracies","60a1b1a2":"def visual(training_losses, training_accs, test_losses, test_accs, name):\n\n    f, ax = plt.subplots(2,2, figsize = (12, 8))\n    ax[0, 0].plot(training_losses)\n    ax[0, 0].set_title(\"Training loss\")\n    ax[0, 1].plot(training_accs)\n    ax[0, 1].set_title(\"Training acc\")\n    ax[1, 0].plot(test_losses)\n    ax[1, 0].set_title(\"Test loss\")\n    ax[1, 1].plot(test_accs)\n    ax[1, 1].set_title(\"Test acc\")\n    f.suptitle(f'Train visualise {name} 100\\'s of batches')\n    plt.show()","0ea7d4a1":"class ConvNet1(nn.Module):\n    def __init__(self):\n        super(ConvNet1, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n    \n        self.fc1 = nn.Linear(396010, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet1 = ConvNet1()\nprint(net1)","b2c0906e":"class ConvNet2(nn.Module):\n    def __init__(self):\n        super(ConvNet2, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n\n    \n        self.fc1 = nn.Linear(192080, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet2 = ConvNet2()\nprint(net2)","1d30e626":"class ConvNet3(nn.Module):\n    def __init__(self):\n        super(ConvNet3, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(20, 30, 3)\n        self.pool3 = nn.MaxPool2d(2, 2)\n\n    \n        self.fc1 = nn.Linear(69120, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet3 = ConvNet3()\nprint(net3)","d994b6ab":"class ConvNet4(nn.Module):\n    def __init__(self):\n        super(ConvNet4, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(20, 30, 3)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.conv4 = nn.Conv2d(30, 50, 3)\n        self.pool4 = nn.MaxPool2d(2, 2)\n        \n        self.fc1 = nn.Linear(26450, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n        x = self.pool4(F.relu(self.conv4(x)))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet4 = ConvNet4()\nprint(net4)","6dbce753":"learning_rate = 0.001\nmodels = [net1, net2, net3, net4]\n\nfor i in range(len(models)):\n    print(f'#### Model {i+1}. Baseline ####')\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(models[i].parameters(), lr=learning_rate, momentum=0.9)\n    lrscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n    model_ft, training_losses, training_accs, test_losses, test_accs = train_model(models[i], criterion, optimizer, lrscheduler, n_epochs=4)\n    visual(training_losses, training_accs, test_losses, test_accs, f'NN{i+1} ({i+1} Conv2D)')","7bfdff10":"class ConvNet11(nn.Module):\n    def __init__(self):\n        super(ConvNet11, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.drop1 = nn.Dropout(p=0.2)\n        self.fc1 = nn.Linear(396010, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.drop1(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet1 = ConvNet11()\nprint(net1)","04d6da1e":"class ConvNet22(nn.Module):\n    def __init__(self):\n        super(ConvNet22, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.drop1 = nn.Dropout(p=0.2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.drop2 = nn.Dropout(p=0.2)\n    \n        self.fc1 = nn.Linear(192080, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.drop1(x)\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.drop2(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet2 = ConvNet22()\nprint(net2)","1e91bbe5":"class ConvNet33(nn.Module):\n    def __init__(self):\n        super(ConvNet33, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.drop1 = nn.Dropout(p=0.2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.drop2 = nn.Dropout(p=0.2)\n        self.conv3 = nn.Conv2d(20, 30, 3)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.drop3 = nn.Dropout(p=0.2)\n    \n        self.fc1 = nn.Linear(69120, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.drop1(x)\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.drop2(x)\n        x = self.pool3(F.relu(self.conv3(x)))\n        x = self.drop3(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet3 = ConvNet33()\nprint(net3)","95df9962":"class ConvNet44(nn.Module):\n    def __init__(self):\n        super(ConvNet44, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.drop1 = nn.Dropout(p=0.2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.drop2 = nn.Dropout(p=0.2)\n        self.conv3 = nn.Conv2d(20, 30, 3)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.drop3 = nn.Dropout(p=0.2)\n        self.conv4 = nn.Conv2d(30, 50, 3)\n        self.pool4 = nn.MaxPool2d(2, 2)\n        self.drop4 = nn.Dropout(p=0.2)\n        \n        self.fc1 = nn.Linear(26450, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.drop1(x)\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.drop2(x)\n        x = self.pool3(F.relu(self.conv3(x)))\n        x = self.drop3(x)\n        x = self.pool4(F.relu(self.conv4(x)))\n        x = self.drop4(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet4 = ConvNet44()\nprint(net4)","a80cc4c0":"learning_rate = 0.01\nmodels = [net1, net2, net3, net4]\n\nfor i in range(len(models)):\n    print(f'#### Model {i+1}. Add Dropout ####')\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(models[i].parameters(), lr=learning_rate, momentum=0.9)\n    lrscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n    model_ft, training_losses, training_accs, test_losses, test_accs = train_model(models[i], criterion, optimizer, lrscheduler, n_epochs=5)\n    visual(training_losses, training_accs, test_losses, test_accs, f'NN{i+1} ({i+1} Conv2D + Dropouts)')","6ad443bb":"class ConvNet111(nn.Module):\n    def __init__(self):\n        super(ConvNet111, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.bn1 = nn.BatchNorm2d(10)\n        self.drop1 = nn.Dropout(p=0.2)\n        self.fc1 = nn.Linear(396010, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.bn1(self.pool1(F.relu(self.conv1(x))))\n        x = self.drop1(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet1 = ConvNet111()\nprint(net1)","f952af00":"class ConvNet222(nn.Module):\n    def __init__(self):\n        super(ConvNet222, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.bn1 = nn.BatchNorm2d(10)\n        self.drop1 = nn.Dropout(p=0.2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.bn2 = nn.BatchNorm2d(20)\n        self.drop2 = nn.Dropout(p=0.2)\n    \n        self.fc1 = nn.Linear(192080, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.bn1(self.pool1(F.relu(self.conv1(x))))\n        x = self.drop1(x)\n        x = self.bn2(self.pool2(F.relu(self.conv2(x))))\n        x = self.drop2(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet2 = ConvNet222()\nprint(net2)","82ad722a":"class ConvNet333(nn.Module):\n    def __init__(self):\n        super(ConvNet333, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.bn1 = nn.BatchNorm2d(10)\n        self.drop1 = nn.Dropout(p=0.2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.bn2 = nn.BatchNorm2d(20)\n        self.drop2 = nn.Dropout(p=0.2)\n        self.conv3 = nn.Conv2d(20, 30, 3)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.bn3 = nn.BatchNorm2d(30)\n        self.drop3 = nn.Dropout(p=0.2)\n    \n        self.fc1 = nn.Linear(69120, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.bn1(self.pool1(F.relu(self.conv1(x))))\n        x = self.drop1(x)\n        x = self.bn2(self.pool2(F.relu(self.conv2(x))))\n        x = self.drop2(x)\n        x = self.bn3(self.pool3(F.relu(self.conv3(x))))\n        x = self.drop3(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet3 = ConvNet333()\nprint(net3)","3b3f7ccc":"class ConvNet444(nn.Module):\n    def __init__(self):\n        super(ConvNet444, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, 3)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.bn1 = nn.BatchNorm2d(10)\n        self.drop1 = nn.Dropout(p=0.2)\n        self.conv2 = nn.Conv2d(10, 20, 3)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.bn2 = nn.BatchNorm2d(20)\n        self.drop2 = nn.Dropout(p=0.2)\n        self.conv3 = nn.Conv2d(20, 30, 3)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.bn3 = nn.BatchNorm2d(30)\n        self.drop3 = nn.Dropout(p=0.2)\n        self.conv4 = nn.Conv2d(30, 50, 3)\n        self.pool4 = nn.MaxPool2d(2, 2)\n        self.bn4 = nn.BatchNorm2d(50)\n        self.drop4 = nn.Dropout(p=0.2)\n        \n        self.fc1 = nn.Linear(26450, 200)\n\n        self.fc2 = nn.Linear(200, 196)\n        \n\n    def forward(self, x):\n        x = self.bn1(self.pool1(F.relu(self.conv1(x))))\n        x = self.drop1(x)\n        x = self.bn2(self.pool2(F.relu(self.conv2(x))))\n        x = self.drop2(x)\n        x = self.bn3(self.pool3(F.relu(self.conv3(x))))\n        x = self.drop3(x)\n        x = self.bn4(self.pool4(F.relu(self.conv4(x))))\n        x = self.drop4(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n    \nnet4 = ConvNet444()\nprint(net4)","fd555cde":"learning_rate = 0.001\nmodels = [net1, net2, net3, net4]\n\nfor i in range(len(models)):\n    print(f'#### Model {i+1}. Add BatchNorm  ####')\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(models[i].parameters(), lr=learning_rate, momentum=0.9)\n    lrscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n    model_ft, training_losses, training_accs, test_losses, test_accs = train_model(models[i], criterion, optimizer, lrscheduler, n_epochs=5)\n    visual(training_losses, training_accs, test_losses, test_accs, f'NN{i+1} ({i+1} Conv2D + Dropouts + BatchNorm)')","c601cb2c":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((400, 400)),\n        transforms.RandomHorizontalFlip(0.3),\n        transforms.RandomRotation(15),\n        transforms.ToTensor()\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((400, 400)),\n        transforms.ToTensor()\n    ]),\n}\n\nbatch_size = 32\n\nimage_datasets = {x: torchvision.datasets.ImageFolder(root=path_base+x, transform=data_transforms[x])\n                  for x in ['train', 'test']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n              for x in ['train', 'test']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\nclass_names = image_datasets['train'].classes","a7d6c09b":"learning_rate = 0.001\nnet3 = ConvNet333()\nnet4 = ConvNet444()\n\nmodels = [net3, net4]\n\nfor i in range(len(models)):\n    print(f'#### Model {i+3}. Add Augmentation  ####')\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(models[i].parameters(), lr=learning_rate, momentum=0.9)\n    lrscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n    model_ft, training_losses, training_accs, test_losses, test_accs = train_model(models[i], criterion, optimizer, lrscheduler, n_epochs=10)\n    visual(training_losses, training_accs, test_losses, test_accs, f'NN{i+3} (Add Augmentation)')","f59a2b1a":"weights = net4.conv1.weight.data\nw = weights.cpu().numpy()\n\nfig=plt.figure(figsize=(20, 8))\ncolumns = 5\nrows = 2\nfor i in range(0, columns*rows):\n    fig.add_subplot(rows, columns, i+1)\n    plt.imshow(w[i][0], cmap='gray')\n    \nprint('First convolutional layer')\nplt.show()\n","7f83dbdd":"weights = net4.conv4.weight.data\nw = weights.cpu().numpy()\n\nfig=plt.figure(figsize=(20, 20))\ncolumns = 5\nrows = 10\nfor i in range(0, columns*rows):\n    fig.add_subplot(rows, columns, i+1)\n    plt.imshow(w[i][0], cmap='gray')\n    \nprint('Last convolutional layer')\nplt.show()","fb336b15":"dataiter = iter(dataloaders['test'])\nimages, labels = dataiter.next()\nimages = images.numpy()\n\nidx = 3\nimg = np.squeeze(images[idx][0,:,:])\n\nimport cv2\nplt.imshow(img, cmap='gray')\n\nweights = net4.conv1.weight.data\nw = weights.cpu().numpy()\n\nfig=plt.figure(figsize=(30, 5))\ncolumns = 5*2\nrows = 2\nfor i in range(0, columns*rows):\n    fig.add_subplot(rows, columns, i+1)\n    if ((i%2)==0):\n        plt.imshow(w[int(i\/2)][0], cmap='gray')\n    else:\n        c = cv2.filter2D(img, -1, w[int((i-1)\/2)][0])\n        plt.imshow(c, cmap='gray')\nplt.show()","836e3dd5":"weights = net4.conv4.weight.data\nw = weights.cpu().numpy()\n\nfig=plt.figure(figsize=(30, 20))\ncolumns = 5*2\nrows = 10\nfor i in range(0, columns*rows):\n    fig.add_subplot(rows, columns, i+1)\n    if ((i%2)==0):\n        plt.imshow(w[int(i\/2)][0], cmap='gray')\n    else:\n        c = cv2.filter2D(img, -1, w[int((i-1)\/2)][0])\n        plt.imshow(c, cmap='gray')\nplt.show()","2cdefd5c":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n}\n\nbatch_size = 32\n\nimage_datasets = {x: torchvision.datasets.ImageFolder(root=path_base+x, transform=data_transforms[x])\n                  for x in ['train', 'test']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n              for x in ['train', 'test']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\nclass_names = image_datasets['train'].classes","34681354":"model_conv = models.resnet34(pretrained=True)\nnum_ftrs = model_conv.fc.in_features\n\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\nmodel_conv.fc = nn.Linear(num_ftrs, 196)\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\nlrscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)","403715d0":"print(f'#### Pre-trained Model ####')\nmodel_ft, training_losses, training_accs, test_losses, test_accs = train_model(model_conv, criterion, optimizer, lrscheduler, n_epochs=5)\nvisual(training_losses, training_accs, test_losses, test_accs, 'NN Pre-trained Model')","5f1760e0":"model_ft = models.resnet34(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\nmodel_ft.fc = nn.Linear(num_ftrs, 196)\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\nlrscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","4c38b072":"print(f'#### Fine-Tuning Model ####')\nmodel_ft, training_losses, training_accs, test_losses, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=5)\nvisual(training_losses, training_accs, test_losses, test_accs, 'NN Fine-Tuning Model')","a2d5c7ca":"There is a longer learning curve, but by doing so we make our learning more meaningful. The model will learn from modified images to get more generalized filters in the future.","da7b9fa1":"# Define basic CNN","5bcc4afb":"The results are not impressive because we did not retrain the pre-train model for our dataset. Most likely, the training dataset for the resnet contained pictures on a different topic, or there were few machines. Therefore filters with freeze scales capture other information.","af4e511c":"As we can see, the model has learned quite well to predict vertical transitions, which can be traced on several filters. In our case, this is important, since the car can be described using simple lines, including vertical ones.","4c21ec76":"# Load and base transform","0726641b":"*Homework by Samoshyn Andriy*","8fcb8ee0":"As we can see, models already by the 3rd epoch give better accuracy than random selection. This means that **models can learn, but hardly too well**. This can be seen from the rate at which the loss decreases. Such a slow decrease in the loss can be associated with lerning rate. Let's try to change it in the next iteration. Therefore, I see no reason to train the simplest models on a large number of epochs, because they will not be able to give a good result.","ab60cdf5":"# Add BatchNorm","87091f4d":"# Add Dropouts","db991960":"Training convolutional neural networks is a random process. This makes experiments difficult because each time you run the same experiment, you get different results.\n\nBut if we start not only from the obtained graphs, but also from common sense, then I think the **latest models (add dropout, batchnorm and augmentation)** are the best option.\n\nPerhaps they do not have the best results *(this is due to the limited resources of the GPU)*, but by the structure its are the most optimal. The only thing else that could be done was to play with the parameters a little longer (in dropout, the sizes of kernels, etc.)","fa40fd23":"> Define convolutional neural networks with 4 convolutions.","ebfcedc9":"# Model configuration","216c0110":"# Pre-trained model: freeze","a14a0499":"Let's try to add **data augmentation** transformations. **Data augmentation** is a strategy that allows practitioners to dramatically increase the variety of data available for training models without actually collecting new data. For training large neural networks, data augmentation techniques such as cropping, filling and flipping horizontally are commonly used. However, most of the approaches used in training neural networks only use basic types of augmentation.\n**Geometric transformations** work well when positional offsets are present in the images.","f89c225e":"> The standard normalization method is for each k, consider the distribution of batch elements. Subtract the mean and divide by the sample variance, obtaining a distribution centered at 0 and variance 1. Such a distribution will allow the network to learn faster, since all numbers will be of the same order. Better yet, introduce two variables for each feature, generalizing the normalization.","ce098c38":"The result is impressive! A large increase in accuracy on a test dataset and without much overfit. This is due to the fact that we have already trained weights, which gave good results on various benchmarks, adjusted to our dataset. Thus, they worked not with randomly initiated quantities, but prepared in advance. Those. we move with our data deep into the neural network and, starting from the very beginning, adjust the weights to our task.\n\nThis is the difference with the previous approach, when we fixed everything and changed only the last layer on the output.","64fce1bf":"As you can see, due to the fact that the model began to learn more effectively without disappearing or explosive gradients, with almost the same number of epochs, overfitting is formed earlier, but the results on the test are still better than before. In the future, I would try to increase the dropout percentage. On the positive side, we note that batch normalization smooths out the loss function.","2c56c1d0":"> Define convolutional neural networks with 3 convolutions.","2823a980":"Let's define our training and test (validation) datasets. We also give all the images to a uniform size. To normalize the data, you need to use **transforms.ToTensor()**:\n\n> Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]","450f0c2d":"Before training each model, you need to define an optimizer and a scheduler.","15380b5a":"Based on the visualization of the latest models, it is likely to be overfitting. Therefore, after each set of layers for convolution add a Dropout. The excluded neurons will not contribute to the learning process at any stage of the backpropagation algorithm.","132b2398":"After adding dropout layers, the loss curves are more similar to each other, i.e. the model behaves better on test data. But still there is underfitting on the current number of epochs. While researching transformation methods, it was found that after **tensor normalization (0.5 0.5 0.5)(0.5 0.5 0.5)**, the model is better to learn **(15-30% better than usual)**, but we will not apply it in this tutorial.","c6eec124":"# Layer sequence","1292cff7":"# Data Augmentation","75999c32":"I think the best option at the moment is a set of:\n* \u0421onvolution layer\n* Max Pooling\n* Batch Normalization\n* Dropout\n\n* And their further unification, after which a fully-connected dense layer.\n\nBut it all depends on the experience of choosing good parameters for training a neural network. This sequence of layers is more likely to help you not overfit, more smoother and more effective learning. Also, this combination has performed well in most popular convolutional neural networks.","554d3a84":"Here we train our model, after each epoch, we test the model on the test data to see how it's going.","1be0352a":"Now let's try to add **BatchNorm** layers to speed up and stabilize the training of the neural network. It does this by normalizing the input layer by re-centering and re-scaling.\n\nDuring training, the layer normalizes its output using the mean and standard deviation of the current batch of inputs.","63956b43":"**Of the key rules that were traced in each network, we can single out:**\n1. Start by using smaller filters to gather as much local information as possible, and then gradually increase the filter size to reduce the size of the generated function space to represent more global, high-level information.\n2. The number of channels should be small at the beginning so that it detects low-level features that combine into many complex forms.\n3. Typically 3x3, 5x5 and 7x7 filters are used for the convolutional layer for medium to small sized images, and for the Max-Pooling options we use 2x2 or 3x3 filter sizes in 2 steps.\n4. Keep adding layers until you get overfit.","ef681581":"> Let's define convolutional neural networks with 1 convolution.","c1ef3834":"# Filters and activation maps","61d875d7":"> Define convolutional neural networks with 2 convolutions.","710eb6e6":"# Pre-trained model: fine-tuning"}}