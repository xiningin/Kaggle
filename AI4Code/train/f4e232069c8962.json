{"cell_type":{"b3f42bd8":"code","7c34b936":"code","35481763":"code","3e041809":"code","52e1d10a":"code","e9498ef1":"code","a4fbe721":"code","0f6c4616":"code","617020b8":"code","e9f26d9d":"code","b105bee6":"code","07d9e712":"code","aea58b18":"code","82aec7f9":"code","bd1be77a":"code","f6c04971":"code","440154b5":"code","fd831e5b":"code","955abbd9":"code","5f6ffb2f":"markdown"},"source":{"b3f42bd8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c34b936":"from numpy import mean\nfrom numpy import std\nfrom numpy import dstack\nfrom pandas import read_csv\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM, ConvLSTM2D, GRU, Bidirectional\nfrom keras.layers import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.utils import to_categorical\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport pandas as pd","35481763":"train_dir = \"\/kaggle\/input\/human-activity-recognition-with-rnn\/train.csv\"\ntest_dir = \"\/kaggle\/input\/human-activity-recognition-with-rnn\/test.csv\"\n\ndf = read_csv(train_dir)","3e041809":"print(df.shape)\n\nprint(df.columns)\n\nprint(df['subject'])","52e1d10a":"df.set_index('id', inplace=True)\n\nprint(df.shape)\n\nprint(df.columns)\n\nprint(df.head)","e9498ef1":"df.drop('subject', axis=1, inplace=True)\n\nprint(df.shape)\n\nprint(df.columns)","a4fbe721":"labels = df['activity']\nfeatures = df.drop('activity', axis=1, inplace=False)\n\n# labels.to_csv(\"..\/Data\/train\/train_df.csv\", index = False)\n# features.to_csv(\"..\/Data\/test\/test_df.csv\", index = False)\n\nprint(features.shape)\nprint(labels.shape)","0f6c4616":"labels.value_counts()\n\n#imbalanced but\n#reasonable maybe","617020b8":"labels = labels-1\nlabels = to_categorical(labels, num_classes=6)\n\n\n#new_labels = pd.get_dummies(labels).values.to_list()\n\n#print(new_labels.shape)","e9f26d9d":"X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.1)\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)\n","b105bee6":"X_train_lstm = np.array(X_train).reshape(X_train.shape[0], 1, X_train.shape[1])\nX_val_lstm = np.array(X_val).reshape(X_val.shape[0], 1, X_val.shape[1])\n\nprint(X_train_lstm.shape)\nprint(X_val_lstm.shape)","07d9e712":"model = Sequential()\n\nmodel.add(LSTM(64,input_shape=(1, 561), activation = 'relu',return_sequences = True))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(LSTM(128,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\n# model.add(Dense(32,activation='relu'))\n# model.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(6,activation = 'softmax'))\n\n# opt = tf.keras.optimizers.Adam(lr=1e-3,decay=1e-5)\n\nmodel.compile(loss = 'categorical_crossentropy',\n             optimizer = 'adam',\n             metrics = ['accuracy'])","aea58b18":"model = Sequential()\n\nmodel.add(Bidirectional(LSTM(128, input_shape=(1, 561), activation = 'relu',return_sequences = True)))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add(Bidirectional(LSTM(128,activation='relu')))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\n# model.add(Dense(32,activation='relu'))\n# model.add(Dropout(0.2))\n# model.add(Flatten())\n\nmodel.add(Dense(6,activation = 'softmax'))\n\n#opt = tf.keras.optimizers.Adam(lr=1e-4,decay=1e-5)\n\nmodel.compile(loss = 'categorical_crossentropy',\n             optimizer = 'adam',\n             metrics = ['accuracy'])","82aec7f9":"#best one\n\nmodel = Sequential()\n\nmodel.add(LSTM(128, input_shape=(1, 561), activation = 'relu',return_sequences = True))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add((LSTM(128,activation='relu')))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\n# model.add((LSTM(256,activation='relu')))\n# model.add(Dropout(0.5))\n# model.add(BatchNormalization())\n\n# model.add(Flatten())\n# model.add(Dense(32,activation='relu'))\n# model.add(Dropout(0.2))\n# # \n\nmodel.add(Dense(6,activation = 'softmax'))\n\n#opt = tf.keras.optimizers.Adam(lr=1e-4,decay=1e-5)\n\nmodel.compile(loss = 'categorical_crossentropy',\n             optimizer = 'adam',\n             metrics = ['accuracy'])","bd1be77a":"model = Sequential()\n\nmodel.add(LSTM(8, input_shape=(1, 561), activation = 'relu',return_sequences = True))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\nmodel.add((LSTM(8,activation='relu')))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\n# model.add((LSTM(256,activation='relu')))\n# model.add(Dropout(0.5))\n# model.add(BatchNormalization())\n\n# model.add(Flatten())\n\n\nmodel.add(Dense(6,activation = 'softmax'))\n\n#opt = tf.keras.optimizers.Adam(lr=1e-4,decay=1e-5)\n\nmodel.compile(loss = 'categorical_crossentropy',\n             optimizer = 'adam',\n             metrics = ['accuracy'])","f6c04971":"model.summary()","440154b5":"# earlyStopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=0, mode='auto')\nmcp_save = ModelCheckpoint('model_weights.hdf5', save_best_only=True, monitor='val_accuracy', mode='auto', verbose=1)\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n\nresult = model.fit(X_train_lstm, y_train, epochs=100,batch_size=32, verbose=1, callbacks=[mcp_save], validation_data=(X_val_lstm, y_val), shuffle=False)","fd831e5b":"from sklearn.metrics import accuracy_score\n\ny_preds = model.predict(X_val_lstm)\ny_pred_classes = np.argmax(y_preds, axis=1)\n\ny_val_classes = np.argmax(y_val, axis=1)\n\nprint(y_preds.shape, y_val.shape)\nprint(y_pred_classes.shape, y_val_classes.shape)\n# print(y_preds[0])\n# print(y_pred_classes[0])\n\n#print(y_pred_classes)\n\nprint(accuracy_score(y_pred_classes, y_val_classes))","955abbd9":"test_df = pd.read_csv(test_dir)\n\nsubmission_df = pd.DataFrame()\n\nsubmission_df['id'] = test_df['id']\n\ntestdf = test_df.drop([\"id\", \"subject\"], axis=1)\n\nprint(testdf.shape)\n\nx_test_lstm = np.array(testdf).reshape(testdf.shape[0], 1, testdf.shape[1])\n\ntest_predictions = model.predict(x_test_lstm)\n\nprint(test_predictions.shape)\n\ntest_pred_classes = np.argmax(test_predictions, axis=1)\n\nprint(test_pred_classes.shape)\n\nprint(np.unique(test_pred_classes))\n\ntest_pred_classes = test_pred_classes + 1\n\nprint(np.unique(test_pred_classes))\n\n# submission_df = pd.DataFrame({'activity': test_pred_classes})\n\nsubmission_df['activity'] = test_pred_classes\n\nprint(submission_df.shape)\n\nprint(submission_df.head)\n\nsubmission_df.to_csv(\"submission_5.csv\", index=False)","5f6ffb2f":"generating test file\n"}}