{"cell_type":{"6a7791f4":"code","b91257e6":"code","004dfcd9":"code","440f009a":"code","497f6422":"code","7d7aa6cb":"code","9634abee":"code","6e5cd02d":"code","c37acf8f":"code","cc2e798e":"code","8d0250a2":"code","16301be2":"code","66387cd7":"code","a0af29a5":"code","72178b94":"code","5b07ad06":"code","d9c3fb9e":"code","20a9c67e":"code","937232be":"code","41477c7d":"code","f017da11":"code","94dc4cea":"code","bd5dd063":"code","b50c4d82":"code","225fed19":"code","b99a9c6d":"code","ac24b47a":"code","bc9cb2ba":"markdown","19ab78b0":"markdown","528d1deb":"markdown","7e6d859b":"markdown","a9c195b8":"markdown","86212052":"markdown","c3e032ea":"markdown","7a21b534":"markdown","5d0b877c":"markdown","cab880e0":"markdown","6ebfa890":"markdown","6e0ddf17":"markdown","19bc9e5f":"markdown","d9fbc5d7":"markdown","8b86c01c":"markdown","5e184838":"markdown","241a3651":"markdown","e5906d5a":"markdown","048c56b4":"markdown","b4ab3c36":"markdown","a20ad1ec":"markdown","adbc0a62":"markdown"},"source":{"6a7791f4":"# Some EDA elements have been inspired by Sanskar Hasija! if you like the notebook please upvote his as well\n\nimport os\nimport spacy\nimport wordcloud\nimport numpy as np\nimport pandas as pd\npd.set_option('display.float_format', lambda x: '%.3f' % x)\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n","b91257e6":"train_dir = \"..\/input\/feedback-prize-2021\/train\"\ntest_dir = \"..\/input\/feedback-prize-2021\/test\"\ntrain_files = os.listdir(train_dir)\ntest_files = os.listdir(test_dir)\n\nfor file in range(len(train_files)):\n    train_files[file] = str(train_dir) + \"\/\" +  str(train_files[file])\nfor file in range(len(test_files)):\n    test_files[file] = str(test_dir) + \"\/\" +  str(test_files[file])\n    \ntrain = pd.read_csv(\"..\/input\/feedback-prize-2021\/train.csv\")\nsub = pd.read_csv(\"..\/input\/feedback-prize-2021\/sample_submission.csv\")","004dfcd9":"print(\"Total number of train files = \" , len(train_files))\nprint(\"Total number of test files = \" , len(test_files))","440f009a":"f = open(train_files[0], \"r\")\nprint(f.read())","497f6422":"f = open(test_files[3], \"r\")\nprint(f.read())","7d7aa6cb":"train.head()","9634abee":"print(\"Number of rows in train dataframe = \" , len(train))","6e5cd02d":"train.describe()","c37acf8f":"train.isnull().sum()","cc2e798e":"sub.head()","8d0250a2":"print(f\" Average distribution of elements per story {len(train)\/len(train_files):9.2f}\")","16301be2":"fig = px.bar(x = np.unique(train[\"discourse_type\"]),\ny = [list(train[\"discourse_type\"]).count(i) for i in np.unique(train[\"discourse_type\"])] , \n            color = np.unique(train[\"discourse_type\"]),\n             color_continuous_scale=\"Emrld\") \nfig.update_xaxes(title=\"Classes\")\nfig.update_xaxes(categoryorder=\"total descending\")\nfig.update_yaxes(title = \"Number of Rows\")\nfig.update_layout(showlegend = True,\n    title = {\n        'text': 'Discourse Type Distribution ',\n        'y':0.95,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","66387cd7":"fig = px.bar(x = np.unique(train[\"discourse_type_num\"]),\ny = [list(train[\"discourse_type_num\"]).count(i) for i in np.unique(train[\"discourse_type_num\"])] , \n            color = np.unique(train[\"discourse_type_num\"]),\n             color_continuous_scale=\"blues\") \nfig.update_xaxes(title=\"Classes\")\nfig.update_xaxes(categoryorder=\"total descending\")\nfig.update_yaxes(title = \"Number of Rows\")\nfig.update_layout(showlegend = True,\n    title = {\n        'text': 'Enumerated class label of Discourse Element Distribution ',\n        'y':0.95,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","a0af29a5":"train[\"discourse_len\"] = train[\"discourse_end\"] - train[\"discourse_start\"]\npd.pivot_table(train, values='discourse_len', index=['discourse_type'],\n                    aggfunc=('count','mean','max','min')).rename_axis(None, axis=1).reset_index() ","72178b94":"train[\"discourse_len\"] = train[\"discourse_end\"] - train[\"discourse_start\"]\ntrain01 = pd.pivot_table(train, values='discourse_len', index=['id'],\n                    aggfunc=('sum')).rename_axis(None, axis=1).reset_index() \nfig = px.histogram(data_frame= train01,x = \"discourse_len\",  marginal=\"violin\",nbins = 400 )\nfig.show()","5b07ad06":"fig = px.histogram(train, x=\"discourse_len\", color=\"discourse_type\")\nfig.show()","d9c3fb9e":"\nfig = px.histogram(data_frame= train,x = \"discourse_len\",  marginal=\"violin\",nbins = 400 )\nfig.show()","20a9c67e":"#https:\/\/stackoverflow.com\/questions\/22219004\/how-to-group-dataframe-rows-into-list-in-pandas-groupby\nmarkovraw = train.groupby('id')['discourse_type'].apply(list).reset_index(name='new')","937232be":"markovraw.loc[:, 'starting'] = markovraw.new.map(lambda x: x[0])\nmarkovraw.loc[:, 'ending'] = markovraw.new.map(lambda x: x[-1])\n","41477c7d":"markovraw.head()","f017da11":"markovraw.new.apply(lambda x: {x.insert(0,'Start'),x.append('End')})\nmarkovraw.head()","94dc4cea":"markov_chain=[]\nfor mc in markovraw.new:\n    markov_chain.extend(mc)\nmy_map = dict(enumerate(set(markov_chain)))\n\nmy_map\n","bd5dd063":"inv_map = {v: k for k, v in my_map.items()}\nfinal_list= [inv_map.get(item)  for item in markov_chain]\ninv_map","b50c4d82":"T = final_list\n","225fed19":"\n\n#create matrix of zeros\n\nM = [[0]*9 for _ in range(9)]\n\nfor (i,j) in zip(T,T[1:]):\n    M[i][j] += 1\n\n#now convert to probabilities:\nfor row in M:\n    n = sum(row)\n    if n > 0:\n        row[:] = [f\/sum(row) for f in row]\n\n#print M:\n","b99a9c6d":"vals = [ key for key, value in inv_map.items() ]\nimport pandas as pd \npd.DataFrame(data = M, \n                  index = vals, \n                  columns = vals)","ac24b47a":"# This is all Sanskar Hasija ! I just picked it up for analysis , very handy\nr = 24\nents = []\nfor i, row in train[train['id'] == train_files[r][35:-4]].iterrows():\n    ents.append({\n                    'start': int(row['discourse_start']), \n                     'end': int(row['discourse_end']), \n                     'label': row['discourse_type']\n                })\n\nwith open(train_files[r], 'r') as file: data = file.read()\n\ndoc2 = {\n    \"text\": data,\n    \"ents\": ents,\n}\n\ncolors = {'Lead': '#EE11D0','Position': '#AB4DE1','Claim': '#1EDE71','Evidence': '#33FAFA','Counterclaim': '#4253C1','Concluding Statement': 'yellow','Rebuttal': 'red'}\noptions = {\"ents\": train.discourse_type.unique().tolist(), \"colors\": colors}\nspacy.displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);","bc9cb2ba":"### Discourse Type Distribution","19ab78b0":"### Basic statistics of training data","528d1deb":"# <center>EDA<\/center> ","7e6d859b":"## References \n[Text coloring](https:\/\/www.kaggle.com\/ibrezmohd\/nlp-on-student-writing-eda\/edit)","a9c195b8":"# <center>DATA DISTRIBUTION<\/center> ","86212052":"### The 7 different Discourse Type\n\n* **Lead** - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader\u2019s attention and point toward the thesis\n* **Position** - an opinion or conclusion on the main question\n* **Claim** - a claim that supports the position\n* **Counterclaim** - a claim that refutes another claim or gives an opposing reason to the position\n* **Rebuttal** - a claim that refutes a counterclaim\n* **Evidence** - ideas or examples that support claims, counterclaims, or rebuttals.\n* **Concluding Statement** - a concluding statement that restates the claims","c3e032ea":"### Column Description\n* **id** - ID code for essay response\n* **discourse_id** - ID code for discourse element\n* **discourse_start** - character position where discourse element begins in the essay response\n* **discourse_end** - character position where discourse element ends in the essay response\n* **discourse_text** - text of discourse element\n* **discourse_type** - classification of discourse element\n* **discourse_type_num** - enumerated class label of discourse element\n* **predictionstring** - the word indices of the training sample, as required for predictions","7a21b534":"### Test Essay Sample","5d0b877c":"# <center>IMPORTS<\/center> ","cab880e0":"### Enumerated class label of Discourse Element Distribution","6ebfa890":"## Train Tabular Dataframe","6e0ddf17":"For Parts of EDA -  I took inspiration from: [Sankar Hasija](https:\/\/www.kaggle.com\/odins0n\/feedback-prize-eda), upvote for this notebook too!, if you find the notebook usefull ","19bc9e5f":"### Null Values ","d9fbc5d7":"# <center>TEXT VISUALIZATION<\/center> ","8b86c01c":"In short we have **15594** file submissions by students and **144293** discourse text identified. ","5e184838":"Neglect the End to Start transition probablity of 1 , thats because I appended all the lists","241a3651":"Few Insignts :\n* More than one clain and Evidence per story\n* Looks like one position and one Concluding statement\n* Some people provide lead\n* Counterclaim and rebuttal are infrequent ( looks like most students agree with the statements )  ","e5906d5a":"### Quick view of Train Dataframe","048c56b4":"# <center>DISCOURSE TEXT DISTRIBUTION<\/center> ","b4ab3c36":"# <center>Markov Transition Matrix<\/center> ","a20ad1ec":"### Quick view of Submission File","adbc0a62":"### Train Essay Sample"}}