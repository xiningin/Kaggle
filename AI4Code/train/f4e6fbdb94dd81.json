{"cell_type":{"be460979":"code","9a65abc2":"code","cf3afd8e":"code","29711b61":"code","fb1a8e26":"code","b344ecf1":"code","d106ef35":"code","52a78b37":"code","727a73f2":"code","c711fb4b":"code","96f67f9d":"code","8ad376d7":"code","bc7a9021":"code","f6c726d3":"code","9cebf3c7":"code","52ff2e0d":"code","d3ea929d":"code","94f6494e":"code","e5e6a3c3":"code","aa0976db":"code","a7e1b4d7":"code","df962eb6":"code","964647d2":"code","7e39e5ce":"code","168bab13":"code","141b9d27":"code","b2cce8e8":"code","cf1bf1e8":"markdown"},"source":{"be460979":"from IPython.display import display,HTML\n\nc1,c2,f1,f2,fs1,fs2=\\\n'#11ff66','#6611ff','Wallpoet','Orbitron',20,10\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' \n    style='font-family:\"\"\"+font+\\\n    \"\"\"; color:\"\"\"+fontcolor+\\\n    \"\"\"; font-size:\"\"\"+str(fontsize)+\"\"\"px;'>\n    %s<\/h1>\"\"\"%string))\n\ndhtml('Code Modules, Setting, & Functions')","9a65abc2":"!python3 -m pip install --upgrade pip \\\n--user --quiet --no-warn-script-location\n!python3 -m pip install --upgrade tensorflow==2.3.0 \\\n--user --quiet --no-warn-script-location\n!pip install mplcyberpunk --user --quiet","cf3afd8e":"import warnings; warnings.filterwarnings('ignore')\nimport mplcyberpunk,numpy as np\nimport tensorflow as tf,pylab as pl\nfrom IPython.core.magic import register_line_magic\nfrom sklearn.metrics import \\\nclassification_report,confusion_matrix\npl.style.use('cyberpunk')\n\n@register_line_magic\ndef display_examples(pars):\n    pars=pars.split()\n    data,n=pars[0],int(pars[1])\n    if data=='cats_vs_dogs':\n        global cvd_test; data=cvd_test\n    if data=='tf_flowers': \n        global flower_test; data=flower_test\n    batch=next(iter(data.batch(n)))\n    images=batch[0].numpy()\n    labels=batch[1].numpy() \n    fig=pl.figure(figsize=(2*n\/\/3,4.5))\n    for i in range(n):\n        ax=fig.add_subplot(3,n\/\/3,i+1)\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(images[i])\n        ax.text(.85,.15,'{}'.format(labels[i]), \n                fontdict={'color':c1,'fontsize':30},\n                horizontalalignment='center',\n                verticalalignment='center', \n                transform=ax.transAxes)\n    pl.tight_layout(); pl.show()\n    \n@register_line_magic\ndef history_plot(yes):\n    global history\n    pl.figure(figsize=(10,10)); pl.subplot(211)\n    keys=list(history.history.keys())[0:4]\n    pl.plot(history.history[keys[0]],\n            color=c1,label=keys[0])\n    pl.plot(history.history[keys[2]],\n            color=c2,label=keys[2])\n    pl.xlabel('Epochs'); pl.ylabel('Loss')\n    pl.legend(); pl.grid(); pl.title('Loss Function')     \n    pl.subplot(212)\n    pl.plot(history.history[keys[1]],\n            color=c1,label=keys[1])\n    pl.plot(history.history[keys[3]],\n            color=c2,label=keys[3])\n    pl.xlabel('Epochs'); pl.ylabel('Accuracy')    \n    pl.legend(); pl.grid(); pl.title('Accuracy')\n    mplcyberpunk.add_glow_effects()\n    pl.tight_layout(); pl.show()\n    \n@register_line_magic\ndef display_reports(d):\n    global model,model_weights,buffer_size\n    c2,f2,fs2='#6611ff','Orbitron',12\n    model.load_weights(model_weights)\n    if d=='cats_vs_dogs': data=cvd_test\n    if d=='tf_flowers': data=flower_test\n    test_results=model.evaluate(\n        data.batch(buffer_size),verbose=0)\n    dhtml('\\ntest accuracy: {:.2f}%'\\\n          .format(test_results[1]*100),c2,f2,fs2)\n    batch=next(iter(data.batch(buffer_size)))\n    y_test=batch[1].numpy()\n    py_test=model.predict(data.batch(buffer_size))\n    if d=='cats_vs_dogs':\n        py_test=tf.sigmoid(py_test).numpy().round()\n    if d=='tf_flowers':\n        py_test=np.argmax(\n            tf.nn.softmax(py_test).numpy(),axis=-1)\n    py_test=py_test[:buffer_size]\n    dhtml('Classification Report',c2,f2,fs2)\n    print(classification_report(y_test,py_test))\n    dhtml('Confusion Matrix',c2,f2,fs2)\n    print(confusion_matrix(y_test,py_test))    ","29711b61":"%%writefile tfpreprocess_dataimage.py\nimport warnings; warnings.filterwarnings('ignore')\nimport mplcyberpunk,tensorflow as tf,pylab as pl\nimport pandas as pd,numpy as np\nimport tensorflow_datasets as tfds\nfrom IPython.display import display\npd.set_option('precision',3)\ntf.keras.backend.set_floatx('float64')\ntfds.disable_progress_bar()\npl.style.use('cyberpunk')\n\ndef get2img(file_name1,file_name2,\n            file_path='..\/input\/image-examples-for-mixed-styles\/'):\n    imgtf1=tf.image.decode_image(\n        tf.io.read_file(file_path+file_name1))\n    imgtf2=tf.image.decode_image(\n        tf.io.read_file(file_path+file_name2))\n    display(pd.DataFrame(\n    [[str(imgtf1.numpy().shape),str(imgtf2.numpy().shape)],\n     [imgtf1.numpy().dtype,imgtf2.numpy().dtype],\n     [tf.rank(imgtf1).numpy(),tf.rank(imgtf2).numpy()]],\n     index=['shape','dtype','rank'],columns=['flower','cat']))\n    return imgtf1,imgtf2\ndef show2img(imgtf1,imgtf2,fig_size):\n    pl.figure(figsize=(2*fig_size,fig_size))\n    pl.subplot(1,2,1); pl.imshow(imgtf1)\n    pl.subplot(1,2,2); pl.imshow(imgtf2)\n    pl.tight_layout(); pl.show()\ndef bcrop(img,box):\n    return tf.image.crop_to_bounding_box(\n        img,box[0],box[1],box[2],box[3])\ndef ccrop(img,c):\n    return tf.image.central_crop(img,c)\ndef hflip(img):\n    return tf.image.flip_left_right(img)\ndef vflip(img):\n    return tf.image.flip_up_down(img)\ndef bright(img,d):\n    return tf.image.adjust_brightness(img,delta=d)\n@tf.function\ndef preprocess(item,img_size,crop=.95,contrast=1.1):\n    img,lbl=item['image'],item['label']\n    img_cropped=tf.image.central_crop(img,crop)\n    img_contrast=tf.image.adjust_contrast(\n        img_cropped,contrast)\n    img_resized=tf.image.resize(\n        img_contrast,size=(img_size,img_size))\n    img_flip=tf.image\\\n    .random_flip_left_right(img_resized)\n    return (img_flip\/255.,tf.cast(lbl,tf.int32))","fb1a8e26":"%run tfpreprocess_dataimage.py\ndhtml('Image Structure')","b344ecf1":"file_name1,file_name2='flower.png','cat.png'\nimgtf1,imgtf2=get2img(file_name1,file_name2)\nshow2img(imgtf1,imgtf2,5)","d106ef35":"dhtml('Image Processing')","52a78b37":"show2img(bcrop(imgtf1,[5,35,175,195]),\n         bcrop(imgtf2,[5,15,235,155]),3)\nshow2img(ccrop(imgtf1,.95),ccrop(imgtf2,.91),3)\nshow2img(vflip(imgtf1),hflip(imgtf2),3)\nshow2img(bright(imgtf1,.3),bright(imgtf2,.1),3)","727a73f2":"dhtml('Data Processing')","c711fb4b":"cvd=tfds.builder('cats_vs_dogs:4.0.0')\ncvd.download_and_prepare()\nsplit=['train[:80%]','train[80%:90%]','train[90%:]']\nds=cvd.as_dataset(shuffle_files=False,split=split)\nimg_size=64; buffer_size,batch_size=500,128\ncvd_train=ds[0].map(\n    lambda x: preprocess(x,img_size=img_size))\ncvd_valid=ds[1].map(\n    lambda x: preprocess(x,img_size=img_size))\ncvd_test=ds[2].map(\n    lambda x: preprocess(x,img_size=img_size))\nncvd_train=int(\n    cvd.info.splits['train[:80%]'].num_examples)\ndhtml(str(ncvd_train),c2,f2,fs2)","96f67f9d":"dhtml(cvd.info.features['image'],c2,f2,fs2)\ndhtml(cvd.info.features['label'],c2,f2,fs2)\n%display_examples cats_vs_dogs 9","8ad376d7":"cvd_train=cvd_train\\\n.shuffle(buffer_size=buffer_size).repeat()\ncvd_train=cvd_train.batch(batch_size)\ncvd_valid=cvd_valid.batch(batch_size)","bc7a9021":"flower=tfds.builder('tf_flowers')\nflower.download_and_prepare()\nsplit=['train[:80%]','train[80%:90%]','train[90%:]']\nds=flower.as_dataset(shuffle_files=False,split=split)\nimg_size2=128\nflower_train=ds[0].map(\n    lambda x: preprocess(x,img_size=img_size2))\nflower_valid=ds[1].map(\n    lambda x: preprocess(x,img_size=img_size2))\nflower_test=ds[2].map(\n    lambda x: preprocess(x,img_size=img_size2))\nnflower_train=int(\n    flower.info.splits['train[:80%]'].num_examples)\ndhtml(str(nflower_train),c2,f2,fs2)","f6c726d3":"dhtml(flower.info.features['image'],c2,f2,fs2)\ndhtml(flower.info.features['label'],c2,f2,fs2)\n%display_examples tf_flowers 12","9cebf3c7":"flower_train=flower_train\\\n.shuffle(buffer_size=buffer_size).repeat()\nflower_train=flower_train.batch(batch_size)\nflower_valid=flower_valid.batch(batch_size)","52ff2e0d":"dhtml('CNN Model Building')","d3ea929d":"import warnings; warnings.filterwarnings('ignore')\nimport tensorflow as tf,numpy as np\nimport tensorflow.keras.layers as tkl\nimport tensorflow.keras.utils as tku\nimport tensorflow.keras.callbacks as tkc\ntf.keras.backend.set_floatx('float64')\nmodel_weights='\/checkpoints'\n\ndef convblock(model,f,ks,dr):\n    model.add(tkl.Conv2D(\n    filters=f,kernel_size=(ks,ks),\n    strides=(1,1),padding='same'))\n    model.add(tkl.LeakyReLU(alpha=.02))\n    model.add(tkl.MaxPool2D(pool_size=(2,2)))\n    model.add(tkl.Dropout(dr))\n\ndef convblocks(img_size,conv,ks=5,dr=.2):\n    model=tf.keras.Sequential()\n    model.add(tkl.Input(\n        (img_size,img_size,3),name='input'))\n    for i in range(len(conv)):\n        convblock(model,conv[i],ks,dr)\n    return model\n\ndef complete_model(model,dense,num_classes,dr=.5):\n    model.add(tkl.GlobalAveragePooling2D())   \n    model.add(tkl.Dense(dense))\n    model.add(tkl.LeakyReLU(alpha=.02))\n    model.add(tkl.Dropout(dr))\n    model.add(tkl.Dense(num_classes,activation=None))\n    return model\n\ndef compile_model(model,loss):\n    return model.compile(optimizer=tf.keras.optimizers.Adam(),\n                         loss=loss,metrics=['accuracy'])\n\ndef cb(fw):\n    early_stopping=tkc.EarlyStopping(\n        monitor='val_loss',patience=10,verbose=2)\n    checkpointer=tkc.ModelCheckpoint(\n        filepath=fw,save_best_only=True,verbose=2,\n        save_weights_only=True,monitor='val_accuracy',mode='max')\n    lr_reduction=tkc.ReduceLROnPlateau(\n        monitor='val_loss',verbose=2,patience=7,factor=.8)\n    return [checkpointer,early_stopping,lr_reduction]","94f6494e":"dhtml('CNN Binary Classification')","e5e6a3c3":"conv=[32,128,512]; num_classes=1\nmodel=convblocks(img_size,conv)\ndhtml('convblocks` outputs:  '+str(model.compute_output_shape(\n    input_shape=(batch_size,img_size,img_size,3))))\nmodel=complete_model(model,2048,num_classes)\ndhtml('complete model`s outputs:  '+str(model.compute_output_shape(\n    input_shape=(batch_size,img_size,img_size,3))))\nloss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\ncompile_model(model,loss)","aa0976db":"steps_per_epoch=np.ceil(ncvd_train\/batch_size)\nhistory=model.fit(\n    cvd_train,epochs=50,shuffle=True, \n    validation_data=cvd_valid,\n    callbacks=cb(model_weights),\n    steps_per_epoch=steps_per_epoch)","a7e1b4d7":"%history_plot yes","df962eb6":"%display_reports cats_vs_dogs","964647d2":"dhtml('CNN Classification')","7e39e5ce":"conv2=[32,64,128,256,512]; num_classes2=5\nmodel=convblocks(img_size2,conv2)\ndhtml('convblocks` outputs:  '+str(model.compute_output_shape(\n    input_shape=(batch_size,img_size2,img_size2,3))))\nmodel=complete_model(model,4096,num_classes2)\ndhtml('complete model`s outputs:  '+str(model.compute_output_shape(\n    input_shape=(batch_size,img_size2,img_size2,3))))\nloss=tf.keras.losses\\\n.SparseCategoricalCrossentropy(from_logits=True)\ncompile_model(model,loss)","168bab13":"steps_per_epoch=np.ceil(nflower_train\/batch_size)\nhistory=model.fit(\n    flower_train,epochs=50,shuffle=True, \n    validation_data=flower_valid,\n    callbacks=cb(model_weights),\n    steps_per_epoch=steps_per_epoch)","141b9d27":"%history_plot yes","b2cce8e8":"%display_reports tf_flowers","cf1bf1e8":"Reading classics [Python Machine Learning 3rd Edition](https:\/\/github.com\/rasbt\/python-machine-learning-book-3rd-edition\/blob\/master\/ch15\/ch15_part2.ipynb)"}}