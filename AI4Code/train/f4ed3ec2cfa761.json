{"cell_type":{"b904d8c5":"code","41d15e58":"code","5216f2b3":"code","7aa5bee5":"code","12f44cd8":"code","b9d2c88c":"code","3c23d13f":"code","ac47488d":"code","2a75a70c":"code","fe9dcbe6":"code","7cbde82b":"code","7cb72c17":"code","606d998a":"code","5f9cc870":"code","e123dbe4":"code","85a9dcf1":"code","c15bc7f2":"code","c2151fb9":"markdown","0d2ac5cb":"markdown","abcd3c62":"markdown","871d17b8":"markdown","19918a58":"markdown","d2ee3410":"markdown","9554c744":"markdown","78d17580":"markdown","6ad97036":"markdown","a903aeb2":"markdown"},"source":{"b904d8c5":"!unzip '\/content\/drive\/My Drive\/Data Set\/dogs-vs-cats-redux-kernels-edition.zip'\n!unzip 'test.zip'\n!unzip 'train.zip'\n\n!mkdir train\/{dog,cat}\n!find train -maxdepth 1 -type f | grep 'dog' | xargs -I{} mv {} train\/dog\n!find train -maxdepth 1 -type f | grep 'cat' | xargs -I{} mv {} train\/cat\n\n!mkdir test\/images\n!find test -maxdepth 1 -type f | xargs -I{} mv {} test\/images","41d15e58":"import tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport pathlib","5216f2b3":"# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\ndef plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","7aa5bee5":"train_dir = '.\/train'\ntotal_train = len(os.listdir('.\/train\/dog')) + len(os.listdir('.\/train\/cat'))\ntotal_test = len(os.listdir('.\/test\/images\/'))\nvalidation_split = 0.2\n\nbatch_size = 128\nepochs = 10\nIMG_HEIGHT = 150\nIMG_WIDTH = 150","12f44cd8":"train_image_generator = ImageDataGenerator(rescale=1.\/255,\n                                           validation_split=validation_split)\ntrain_data_gen = train_image_generator.flow_from_directory(directory=train_dir,\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                           class_mode='binary',\n                                                           batch_size=batch_size,\n                                                           shuffle=True,\n                                                           subset='training')\nval_data_gen = train_image_generator.flow_from_directory(directory=train_dir,\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                           class_mode='binary',\n                                                           batch_size=batch_size,\n                                                           shuffle=True,\n                                                           subset='validation')","b9d2c88c":"model = Sequential([\n    Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n\n    Conv2D(64, 3, padding='same', activation='relu'),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n\n    Conv2D(128, 3, padding='same', activation='relu'),\n    Conv2D(128, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])","3c23d13f":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","ac47488d":"model.summary()","2a75a70c":"history = model.fit(\n    train_data_gen,\n    epochs=epochs,\n    validation_data=val_data_gen,\n    steps_per_epoch=(total_train * (1 - validation_split) \/\/ batch_size),\n    validation_steps=(total_train * validation_split \/\/ batch_size)\n)","fe9dcbe6":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","7cbde82b":"test_image_generator = ImageDataGenerator(rescale=1.\/255)\ntest_data_gen = test_image_generator.flow_from_directory(directory='.\/test\/',\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                                           shuffle=False,\n                                                           class_mode=None,\n                                                           batch_size=1)","7cb72c17":"test_data_gen.reset()\npredictions = model.predict(test_data_gen,\n                            steps=total_test,\n                            verbose=1)","606d998a":"train_data_gen.class_indices","5f9cc870":"test_path = pathlib.Path('.\/test\/images')\npaths = [str(f) for f in test_path.glob('*')]\nfor path, pred in list(zip(paths, np.round(predictions)))[:10]:\n  plt.imshow(Image.open(path))\n  plt.show()\n  print(pred)","e123dbe4":"def extract_test_id(path):\n   file = path.split('\/')[1]\n   return file.split('.')[0]\n\ntest_ids = [extract_test_id(f) for f in test_data_gen.filenames]","85a9dcf1":"zipped = zip(test_ids, np.round(predictions.flatten()))\nrecords = sorted(list(zipped), key=lambda kv: int(kv[0]))","c15bc7f2":"output = pd.DataFrame.from_records(records, columns=['id', 'label'])\noutput.to_csv('submission.csv', index=False)","c2151fb9":"## Rearrange file structure\n\nTo make it fit to Keras [flow_from_directory](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator#flow_from_directory). See [this article](https:\/\/medium.com\/@vijayabhaskar96\/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720) for more details. It is assumed that this script runs on Google Colab which mounts Google Drive and have `\/Data Set\/<data>.zip` below it. You can find the zip file [here](https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition\/data).","0d2ac5cb":"## Visualize training results","abcd3c62":"## Generate submittion.csv","871d17b8":"Classes are `{'cat': 0, 'dog': 1}`. That matches output format so we can just round predictions value.","19918a58":"## Predict","d2ee3410":"## Check accuracy by comparing test files and corresponded predictions","9554c744":"## Define helper functions and global variables","78d17580":"## Build model and train","6ad97036":"## References\n\n- The competition is https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition (it ended long time ago)\n- This implementation is based on https:\/\/www.tensorflow.org\/tutorials\/images\/classification","a903aeb2":"## Import libraries"}}