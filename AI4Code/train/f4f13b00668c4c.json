{"cell_type":{"de77eb4c":"code","d01e6e98":"code","8e57d6cc":"code","7c5866f3":"code","09b6f463":"code","4498c029":"code","3a35bfc3":"code","44a6726e":"code","32c77ddf":"code","23b65e97":"code","80f307b5":"code","4812542c":"code","a1fc890b":"code","f1446dcb":"code","76bb7772":"code","5e48aa73":"code","77da6d42":"code","36a566ec":"code","5bc90272":"code","a9601610":"code","8ccb418d":"code","55458a5f":"code","2830fc08":"markdown","a8d74a46":"markdown","223e3d80":"markdown","8ae0ec00":"markdown","2c7d5704":"markdown"},"source":{"de77eb4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d01e6e98":"from fastai.text import *","8e57d6cc":"from pathlib import Path","7c5866f3":"folder_path = Path(\"\/kaggle\/input\/fake-and-real-news-dataset\")\nos.listdir(folder_path)","09b6f463":"folder_path.ls()","4498c029":"true_data = pd.read_csv(folder_path\/'True.csv')\nfake_data = pd.read_csv(folder_path\/'Fake.csv')","3a35bfc3":"true_data.head()","44a6726e":"fake_data.head()","32c77ddf":"print(\"Shape of the true data df is: \", true_data.shape)\nprint(\"Shape of the fake data df is: \", fake_data.shape)","23b65e97":"true_data = true_data.assign(is_fake=0);\nfake_data = fake_data.assign(is_fake=1);","80f307b5":"true_data.head()","4812542c":"fake_data.head()","a1fc890b":"full_data = true_data.append(fake_data)","f1446dcb":"full_data.head()","76bb7772":"full_data.shape","5e48aa73":"data = (TextList.from_df(df=full_data, path=folder_path, cols=1)\n       .split_by_rand_pct(0.2)\n       .label_from_df(cols=4)\n       .databunch())","77da6d42":"data.show_batch()","36a566ec":"learn = text_classifier_learner(data, AWD_LSTM, drop_mult=0.5)","5bc90272":"learn.fit_one_cycle(1)","a9601610":"data_title = (TextList.from_df(df=full_data, path=folder_path, cols=0)\n       .split_by_rand_pct(0.2)\n       .label_from_df(cols=4)\n       .databunch())","8ccb418d":"learn = text_classifier_learner(data_title, AWD_LSTM, drop_mult=0.5,\n                                model_dir='\/tmp\/models')","55458a5f":"learn.fit_one_cycle(1)","2830fc08":"So now you have pandas dataframe with the subset of true and fake news","a8d74a46":"* At first glance -- the full text has MUCH better predictive power","223e3d80":"Now let's add a column to label fake vs real before combining the frames","8ae0ec00":"21,000+ --> TRUE\n\n23,000+ --> FAKE\n\n~45,000 total. So 20% for validation would be ~9,000 samples\n","2c7d5704":"let's run two models (before utilizing a pretrained language model) between title and text to see if one does better -- who knows if they will do anything of value without ULMFiT applied"}}