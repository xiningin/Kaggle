{"cell_type":{"e59604a6":"code","219db3e3":"code","daca3227":"code","bcde9f20":"code","9633bd81":"code","2a1c785f":"code","d11fcdbf":"code","c5f83476":"code","38d6353c":"code","0a20939c":"code","913e0097":"code","c52ae1d5":"code","3061a0bc":"code","81121944":"code","8b027dc3":"code","f904cc43":"code","6390230f":"code","0faa3907":"code","5f992202":"code","0b8dca7d":"code","21b6fcbb":"code","1a8b0d3a":"code","d1c466a7":"code","2435d746":"code","b4fa2263":"code","c2b73a7d":"code","b2aa9353":"code","fb3c0140":"code","66f29de6":"code","38005451":"code","aec07a21":"code","cf3f1e80":"code","853b7aca":"code","08d3adb0":"code","e0aeedcc":"code","0ffbfd17":"code","896666f0":"code","e1b924f6":"code","31a9a2c1":"code","a63576ab":"code","f47a0f14":"code","d9c67c00":"code","6be22b7f":"code","7531dc90":"code","8f21b2ec":"code","08950677":"code","9d622521":"code","70015638":"code","94a39536":"code","7ef3603c":"code","53543596":"code","fd6fe053":"code","5eaa6d49":"code","88d0abb6":"code","394a77d9":"code","deddd8b3":"code","5a532a07":"code","c87f6e2d":"markdown","f4730f42":"markdown","2d51af0a":"markdown","5f57c3cf":"markdown","d1bc26ed":"markdown","16cf0588":"markdown","1db7ac70":"markdown","d3bf145c":"markdown","6ae22bd7":"markdown","d08a111f":"markdown","9f18349d":"markdown","13f8eeac":"markdown","f38dd586":"markdown","9fbe8689":"markdown","0d2556ea":"markdown","fadbcc9f":"markdown","82c94d15":"markdown","55d8c1ee":"markdown","809d168c":"markdown","5e915004":"markdown","058dde7e":"markdown","b8d2084d":"markdown","f38d3182":"markdown","63cd4019":"markdown","1b0d2a52":"markdown","59f4556e":"markdown","01e504a8":"markdown","9d960bdc":"markdown","d11d3283":"markdown","a5bc78d4":"markdown","b3c1547e":"markdown","da6fafdc":"markdown","0595b692":"markdown","c6114841":"markdown","66275161":"markdown","636cb89d":"markdown","1a79b885":"markdown","9b3e637f":"markdown","0a6dafaf":"markdown","17c12c7b":"markdown","b83c9a9e":"markdown","ca938594":"markdown","495e48d0":"markdown","417cc891":"markdown","e8e325f2":"markdown"},"source":{"e59604a6":"import pandas as pd\nimport numpy as np\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import WordNetLemmatizer \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import Pipeline, make_pipeline\n# Below libraries are for feature representation using sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Below libraries are for similarity matrices using sklearn\nfrom sklearn.metrics.pairwise import cosine_similarity  \nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import pairwise_distances\nimport copy\nfrom IPython.display import clear_output\nfrom eli5.lime import TextExplainer\nimport warnings\nfrom eli5.lime.samplers import MaskingTextSampler\nfrom re import sub\nimport plotly\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nplotly.offline.init_notebook_mode (connected = True)\nimport eli5\nfrom eli5.lime import TextExplainer\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nimport random\nwarnings.filterwarnings(\"ignore\")","219db3e3":"data=pd.read_csv('..\/input\/mind-news-dataset\/news.tsv',header=None,sep='\\t')","daca3227":"data.columns=['News ID',\n\"Category\",\n\"SubCategory\",\n\"Title\",\n\"Abstract\",\n\"URL\",\n\"Title Entities\",\n\"Abstract Entities \"]","bcde9f20":"data.head()","9633bd81":"data=data.iloc[:,:5]","2a1c785f":"data.head()","d11fcdbf":"c=data[['Category','SubCategory']].value_counts()","c5f83476":"index=[]\nfor i in c.index:\n    index.append(np.array(i))\nindex=np.array(index)","38d6353c":"df=pd.DataFrame(columns=['Category','Sub Category','Values'])\ndf['Category']=index[:,0]\ndf['Sub Category']=index[:,1]\ndf['Values']=c.values","0a20939c":"px.bar(data_frame=df,x='Category',y='Values',color='Sub Category')","913e0097":"text=' '\nfor i in data[data['Category']=='sports']['Title']:\n    text+=i+' '\n    \n# Make the figure\nwordcloud = WordCloud().generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\n\nplt.show()\n","c52ae1d5":"text=' '\nfor i in data[data['Category']=='news']['Title']:\n    text+=i+' '\n    \n# Make the figure\nwordcloud = WordCloud().generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\n\nplt.show()\n","3061a0bc":"t=[]\nfor i in data['Title']:\n    t.append(len(i))\npx.histogram(t,color=data['Category'])","81121944":"print('the number of articles before processing :',len(data))\ndata.drop_duplicates(subset=['Title'],inplace=True)\nprint('The number of articles after processing :',len(data))","8b027dc3":"data.isna().sum()","f904cc43":"plt.figure(figsize=(18,8))\nsns.heatmap(data.isnull(), cbar=True, cmap='magma')\n","6390230f":"data.dropna(inplace=True)","0faa3907":"print('the number of articles before processing :',len(data))\ndata=data[data['Title'].apply((lambda x: len(x.split())>=4))]\nprint('The number of articles after processing :',len(data))","5f992202":"df2=data.copy()","0b8dca7d":"# This function is to remove stopwords from a particular column and to tokenize it\ndef rem_stopwords_tokenize(data,name):\n      \n    def getting(sen):\n        example_sent = sen\n\n        stop_words = set(stopwords.words('english')) \n\n        word_tokens = word_tokenize(example_sent) \n\n        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n\n        filtered_sentence = [] \n\n        for w in word_tokens: \n            if w not in stop_words: \n                filtered_sentence.append(w) \n        return filtered_sentence\n    x=[]\n    for i in data[name].values:\n        x.append(getting(i))\n    data[name]=x","21b6fcbb":"# Making a function to lemmatize all the words\nlemmatizer = WordNetLemmatizer() \ndef lemmatize_all(data,name):\n    arr=data[name]\n    a=[]\n    for i in arr:\n        b=[]\n        for j in i:\n            x=lemmatizer.lemmatize(j,pos='a')\n            x=lemmatizer.lemmatize(x)\n            b.append(x)\n        a.append(b)\n    data[name]=a\n  \n  \n","1a8b0d3a":"# Removing Stop words from Title Column\nrem_stopwords_tokenize(data,'Title')","d1c466a7":"# Lemmatizing the Title column\nlemmatize_all(data,'Title')","2435d746":"# Making a copy of data to use in the future\ndata4=data.copy()","b4fa2263":"def convert_to_string(data,name):\n    t=data[name].values\n    p=[]\n    for i in t:\n        listToStr = ' '.join(map(str, i))\n        p.append(listToStr)\n    data[name]=p\n","c2b73a7d":"convert_to_string(data,'Title')","b2aa9353":"headline_vectorizer = CountVectorizer()\n","fb3c0140":"def Euclidean_Distance_based_model(row_index, num_similar_items):\n    cate=data['Category'][row_index]\n    name=data['Title'][row_index]\n    cate_data=data[data['Category']==cate]\n \n    row_index2=cate_data[cate_data['Title']==name].index\n    headline_features   = headline_vectorizer.fit_transform(cate_data['Title'].values)\n    couple_dist = pairwise_distances(headline_features,headline_features[row_index2])\n    indices = np.argsort(couple_dist.ravel())[0:num_similar_items]\n    df = pd.DataFrame({'headline':df2[df2['Category']==cate]['Title'].values[indices],\n                       'Category':cate_data['Category'].values[indices],\n                       'Abstract':cate_data['Abstract'].values[indices],\n                'Euclidean similarity with the queried article': couple_dist[indices].ravel()})\n    print(\"=\"*30,\"News Article Name\",\"=\"*30)\n    print('News Headline : ',data['Title'][indices[0]])\n    print(\"\\n\",\"=\"*30,\"Recommended News : \",\"=\"*30)\n    return df.iloc[1:,:]\nname=input('News Title For Recommendation :')\nclear_output()\nind=df2[df2['Title']==name].index[0]\ndd=Euclidean_Distance_based_model(ind, 100)\ndd.head(10)","66f29de6":"tfidf_headline_vectorizer = TfidfVectorizer(min_df = 0)","38005451":"def TFIDF_based_model(row_index, num_similar_items):\n    cate=data['Category'][row_index]\n    name=data['Title'][row_index]\n    cate_data=data[data['Category']==cate]\n \n    row_index2=cate_data[cate_data['Title']==name].index\n    headline_features   = tfidf_headline_vectorizer.fit_transform(cate_data['Title'].values)\n    couple_dist = pairwise_distances(headline_features,headline_features[row_index2])\n    indices = np.argsort(couple_dist.ravel())[0:num_similar_items]\n    df = pd.DataFrame({'headline':df2[df2['Category']==cate]['Title'].values[indices],\n                       'Category':cate_data['Category'].values[indices],\n                       'Abstract':cate_data['Abstract'].values[indices],\n                'Euclidean Distance Similarity': couple_dist[indices].ravel()})\n    print(\"=\"*30,\"News Article Name\",\"=\"*30)\n    print('News Headline : ',data['Title'][indices[0]])\n    print(\"\\n\",\"=\"*26,\"Recommended News Using TFIDf: \",\"=\"*30)\n    return df.iloc[1:,:]\nname=input('News Title For Recommendation :')\nclear_output()\nind=df2[df2['Title']==name].index[0]\ndd=TFIDF_based_model(ind, 100)\ndd.head(10)","aec07a21":"X=data['Title'].values\ny=data['Category'].values","cf3f1e80":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)","853b7aca":"def print_report(pipe):\n    y_pred = pipe.predict(X_test)\n    p=np.unique(y_test)\n    report = metrics.classification_report(y_test, y_pred,\n        target_names=p)\n    print(report)\n    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n\n","08d3adb0":"vec = TfidfVectorizer(min_df=4)\nsvd = TruncatedSVD(n_components=400, n_iter=8, random_state=42)\nlsa = make_pipeline(vec, svd)\nds=DecisionTreeClassifier()\npipe = make_pipeline(lsa, ds)","e0aeedcc":"pipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","0ffbfd17":"# Making report for decision tree classifier\nprint_report(pipe)","896666f0":"vec = TfidfVectorizer(min_df=0)\nsvd = TruncatedSVD(n_components=10, n_iter=1, random_state=42)\nlsa = make_pipeline(vec, svd)\nxgb=XGBClassifier()\npipe = make_pipeline(lsa, xgb)","e1b924f6":"pipe.fit(X_train, y_train)\npipe.score(X_test, y_test)","31a9a2c1":"# Making report for pipeline using XGBClassifier\nprint_report(pipe)","a63576ab":"vec = TfidfVectorizer(min_df=0)\nsvd = TruncatedSVD(n_components=100, n_iter=1, random_state=42)\nlsa = make_pipeline(vec, svd)\nlgm=LGBMClassifier()\npipe2 = make_pipeline(lsa, lgm)","f47a0f14":"pipe2.fit(X_train, y_train)\npipe2.score(X_test, y_test)","d9c67c00":"# Making report for pipeline using LGBMClassifier\nprint_report(pipe2)","6be22b7f":"data['Title'][0]","7531dc90":"p=np.unique(y_test)\n\ndef print_prediction(doc):\n    y_pred = pipe2.predict_proba([doc])[0]\n    for target, prob in zip(p, y_pred):\n        print(\"{:.3f} {}\".format(prob, target))\n\ndoc = data['Title'][0]\nprint_prediction(doc)","8f21b2ec":"te = TextExplainer(random_state=42)\nte.fit(doc, pipe2.predict_proba)\nte.show_prediction(target_names=list(p))","08950677":"vec = TfidfVectorizer(min_df=0, analyzer='char',\n                      ngram_range=(3,6))\nsvd = TruncatedSVD(n_components=100, n_iter=1, random_state=42)\nlsa = make_pipeline(vec, svd)\nlgm=LGBMClassifier()\npipe3 = make_pipeline(lsa, lgm)","9d622521":"pipe3.fit(X_train, y_train)\npipe3.score(X_test, y_test)","70015638":"# Making report for decision tree classifier\nprint_report(pipe3)","94a39536":"sampler = MaskingTextSampler(\n\n    token_pattern='.',\n\n    max_replace=3,\n\n    # by default all tokens are replaced;\n    # replace only a token at a given position.\n    bow=False,\n)\nsamples, similarity = sampler.sample_near(doc)\nprint(samples[0])\n","7ef3603c":"te = TextExplainer(char_based=True, sampler=sampler, random_state=42)\nte.fit(doc, pipe3.predict_proba)\nte.show_prediction()","53543596":"print(te.metrics_)\n","fd6fe053":"all_title=''\nfor i in data['Title'].values:\n    all_title+=i+' '\n# Let's select 40 random words from this \nx=[]\nfor i in range(30):\n    x.append(random.choice(all_title.split(' ')))","5eaa6d49":"# Getting probablities of being a class\nprobs=pipe3.predict_proba(x)","88d0abb6":"# Getting labels of the words\nlabels=pipe3.predict(x)","394a77d9":"svd = TruncatedSVD(n_components=3, n_iter=4, random_state=42)","deddd8b3":"transformed=svd.fit_transform(probs)","5a532a07":"px.scatter_3d(x=transformed[:,0],y=transformed[:,1],color=labels,z=transformed[:,2],text=x)","c87f6e2d":"<a id='2'><\/a>\n# Importing the data","f4730f42":"<a id='6'><\/a>\n# Data Preprocessing","2d51af0a":"<a id='5'><\/a>\n# Visualizing The Data","5f57c3cf":"# Update :\n<a href='#the_destination'>Debugging the recommendation model<\/a>\nOver here we are trying to debug the genre recommendation model to find the best model :)\n\n<a href='#13'>Influence of words on predicting categories  <\/a> \nHere we are trying to see the influence of words on prediction of categories and also tells us the weight of those words which is pretty helpfull in recommendation","d1bc26ed":"## A custom sampler instance can be passed to TextExplainer if we want to experiment with sampling.","16cf0588":"<a id='10.2'><\/a>\n# Pipeline using TruncatedSVD and XGBClassifier","1db7ac70":"<a id='4'><\/a>\n# Selecting the needed columns","d3bf145c":"# MIND: Microsoft News Recommendation","6ae22bd7":"<a id='8'><\/a>\n# Bagging Method ","d08a111f":"## Explanation makes sense - we expect reasonable classifier to take highlighted words in account. ","9f18349d":"<a id='7'><\/a>\n# Text Preprocessing","13f8eeac":"I think we got some good recommendations here  :)\n\nThe thing about using this model is that it gives real less importance to less frequent words but sometimes those are the words that could make some real difference .","f38dd586":"<a id='11'><\/a>\n# Let's have a look at the text explainer ","9fbe8689":"Well most of the titles are in the range of 50 to 100 words :) So if you are gonna write a news article keep the title in 50 - 100 words :)","0d2556ea":"<a id='6.1'><\/a>\n## Checking and removing all the duplicate values","fadbcc9f":"This is text explainer which tries to explain the text and their classes :)","82c94d15":"<a id='5.1'><\/a>\n# Category and Subcategory distribution in data","55d8c1ee":"# To Be Continued :)","809d168c":"<a id='6.3'><\/a>\n## Getting Titles with more than 4 words","5e915004":"<a id='10.1'><\/a>\n# Truncated SVD and Decision Tree Classifier","058dde7e":"<a id='the_destination'><\/a>\n# Debugging the Recommendation model \n","b8d2084d":"## Converting Back To String","f38d3182":"<a id='5.3'><\/a>\n# Wordcloud for news","63cd4019":"<a id='5.2'><\/a>\n# WordCloud For Sports News","1b0d2a52":"# Content Of The File :\n1. <a href='#1'> Importing The Packages <\/a>\n2. <a href='#2'> Importing The Data <\/a>\n3. <a href='#3'>Having a look at the data<\/a>\n4. <a href='#4'>Selecting Columns<\/a>\n5. <a href='#5'>Visualizing The data<\/a>  <ol>\n    <li> <a href='#5.1'>Category and Subcategory distribution in the data<\/a><\/li>\n    <li> <a href='#5.2'>WordClouds For Sports<\/a><\/li>\n    <li> <a href='#5.3'>Wordcloud For News<\/a><\/li>\n    <li> <a href='#5.4'>Title Length Distribution per Category<\/a><\/li><\/ol>\n\n6. <a href='#6'>Data Preprocessing<\/a> <ol>\n    <li> <a href='#6.1'>Checking and removing all the duplicate values<\/a><\/li>\n    <li> <a href='#6.2'>Checking for NaN values<\/a><\/li>\n    <li> <a href='#6.3'>Getting Titles with more than 4 words<\/a><\/li><\/ol>\n7. <a href='#7'>Text Preprocessing <\/a>\n8. <a href='#8'> Bagging Method <\/a>\n9. <a href='#9'>TF-IDF Method<\/a>\n10. <a href='#10'>Category Recommendation System<\/a><ol>\n    <li> <a href='#10.1'>Using SVD and Decision Tree<\/a><\/li>\n    <li> <a href='#10.2'>Using SVD and XGBClassifier<\/a><\/li>\n    <li> <a href='#10.3'>Using SVD and LGBMClassifier<\/a><\/li>\n    <\/ol>\n11. <a href='#11'>Using Text Explainer On The Best Model <\/a>\n12. <a href='#12'>Using Text Explainer in character mode <\/a>\n13. <a href='#13'>Influence of words on predicting categories  <\/a>","59f4556e":"WEll the recommendations are different and looks better :) \n\nLet's see if we can make it much better :)","01e504a8":"**MIcrosoft News Dataset (MIND)** is a large-scale dataset for news recommendation research. It was collected from anonymized behavior logs of Microsoft News website. The mission of MIND is to serve as a benchmark dataset for news recommendation and facilitate the research in news recommendation and recommender systems area.\n\nMIND contains about **160k English news** articles and **more than 15 million impression logs** generated by **1 million users**. Every news article contains rich textual content including title, abstract, body, category and entities. Each impression log contains the click events, non-clicked events and historical news click behaviors of this user before this impression","9d960bdc":"<a id='10.3'><\/a>\n# Pipeline using TruncatedSVD and LGBMClassifier","d11d3283":"<a id='3'><\/a>\n# Having a look at the data","a5bc78d4":"# LGBMClassifier worked the best amongst all 3 it gave 48% accuracy","b3c1547e":"# Give a like if ya liked the file :)","da6fafdc":"<a id='6.2'><\/a>\n## Checking for NaN values","0595b692":"Wow the main attraction of news has been Trump :)","c6114841":"<a id='1'><\/a>\n# Importing The Packages","66275161":"<a id='9'><\/a>\n# Using TF-IDF Method","636cb89d":"<a id='10'><\/a>\n# Let's Make A Category Recommendation System Too","1a79b885":"![](data:image\/png;base64,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)","9b3e637f":"<a id='5.4'><\/a>\n# Histogram For Title Length","0a6dafaf":"<a id='12'><\/a>\n# Text Explainer with char analyzer","17c12c7b":"<a id='13'><\/a>\n# Let's See The Influence Of Words On Deciding categories","b83c9a9e":"### From this we can clearly see that the most of the news was on the Category of news with subcategory newsus followed by sports with football news","ca938594":"# Next Content Be Coming Soon :)","495e48d0":"### Why TFIDF is good ??\n\n* It\u2019s fast and works well when documents are large and\/or have lots of overlap.\n* It looks for exact matches, so at the very least you should use a lemmatizer to take care of the plurals.\n* When comparing short documents with limited-term variety \u2014 such as search queries \u2014 there is a risk that you will miss semantic relationships where there isn\u2019t an exact word match.","417cc891":"# Wow That graph shows the words as a vector and helps us understand which word is highly important in selecting the category\n## For eg. words chunk and withdraw are close which means they might have a mixed prob which is not near 1 so they are close to each other but words like billion which are farthest away shows high weightage towards their class finance :)","e8e325f2":"## Converting the text"}}