{"cell_type":{"ea1b3f66":"code","eed959c4":"code","27a193f6":"code","41afe630":"code","f6587409":"code","562109de":"code","3c7635c7":"code","df3e7f01":"code","f9bea3cd":"code","5f908e9b":"code","1a89a85b":"code","cf281e62":"code","0d65be01":"code","24cbaa40":"code","213f9635":"code","a1f38d04":"code","ced0d23e":"code","a2a43c41":"code","9937d713":"code","7aae84ed":"markdown","0496e684":"markdown","6c1d1005":"markdown","d228f631":"markdown"},"source":{"ea1b3f66":"# Importing Necessary Libraries\nimport cv2\nimport os\nimport shutil \nimport math\nimport random\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","eed959c4":"# Function for Formatting Dataset\ndef FormatDataset(dataset_src, dataset_dest, classes):\n    # Making a Copy of Dataset\n    new_cropped_dest = [os.path.join(dataset_dest, cls, 'CROPPED') for cls in classes];\n    new_complete_dest = [os.path.join(dataset_dest, cls, 'COMPLETE') for cls in classes];\n    cropped_src = [ dataset_src + \"\/im_\" + cls + \"\/im_\" + cls + \"\/CROPPED\" for cls in classes ];\n    complete_src = [ dataset_src + \"\/im_\" + cls + \"\/im_\" + cls for cls in classes ];\n    for (dest1, dest2) in zip(new_cropped_dest, new_complete_dest):\n        os.makedirs(dest1);\n        os.makedirs(dest2);\n    # Formating Cropped Images\n    for (src,new_dest) in zip(cropped_src, new_cropped_dest):\n        for file in os.listdir(src):\n            filename, file_ext = os.path.splitext(file);\n            if file_ext == '.bmp':\n                img_des = os.path.join(new_dest, filename + '.jpg');\n                img = cv2.imread(os.path.join(src, file));\n                img = cv2.resize(img, (64, 64));\n                img = cv2.copyMakeBorder(img, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0);\n                img = cv2.blur(img, (2, 2));\n                cv2.imwrite(img_des ,img);\n    # Formatting Complete Images\n    for (src,new_dest) in zip(complete_src, new_complete_dest):\n        for file in os.listdir(src):\n            filename, file_ext = os.path.splitext(file);\n            if file_ext == '.bmp':\n                img_des = os.path.join(new_dest, filename + '.jpg');\n                img = cv2.imread(os.path.join(src, file));\n                img = cv2.resize(img, (256, 256));\n                img = cv2.copyMakeBorder(img, 2, 2, 2, 2, cv2.BORDER_CONSTANT, value=0);\n                img = cv2.blur(img, (2, 2));\n                cv2.imwrite(img_des ,img);\n\n# Source Location for Dataset\nsrc = '..\/input\/cervical-cancer-largest-dataset-sipakmed';\n# Destination Location for Dataset\ndest = '.\/CervicalCancer';\n# Image Classes\nclasses = [\"Dyskeratotic\",\"Koilocytotic\",\"Metaplastic\",\"Parabasal\",\"Superficial-Intermediate\"];\n# Formatting Dataset\nFormatDataset(src, dest, classes);","27a193f6":"root_dir = \".\/CervicalCancer\"\nclasses = [\"Dyskeratotic\",\"Koilocytotic\",\"Metaplastic\",\"Parabasal\",\"Superficial-Intermediate\"]\n\ndef GetDatasetSize(path, classes, main = \"CROPPED\"):\n    num_of_image = {}\n    for cls in classes:\n        # Counting the Number of Files in the Folder\n        num_of_image[cls] = len(os.listdir(os.path.join(path, cls, main)));\n    return num_of_image;\n\nprint(GetDatasetSize(root_dir, classes, \"COMPLETE\"));","41afe630":"# Function for Creating Train \/ Validation \/ Test folders (One time use Only)\n\ndef TrainValTestSplit(root_dir, classes_dir, main = \"CROPPED\", val_ratio = 0.15, test_ratio = 0.15):\n    for cls in classes_dir:\n        # Creating Split Folders\n        os.makedirs('train\/' + cls)\n        os.makedirs('val\/' + cls)\n        os.makedirs('test\/' + cls)\n\n        # Folder to copy images from\n        src = os.path.join(root_dir, cls, main);\n\n        # Spliting the Files in the Given ratio\n        allFileNames = os.listdir(src)\n        np.random.shuffle(allFileNames)\n        train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames), [int(len(allFileNames)* (1 - (val_ratio + test_ratio))), int(len(allFileNames)* (1 - test_ratio))])\n\n        train_FileNames = [src+'\/'+ name for name in train_FileNames.tolist()]\n        val_FileNames = [src+'\/' + name for name in val_FileNames.tolist()]\n        test_FileNames = [src+'\/' + name for name in test_FileNames.tolist()]\n\n        # Printing the Split Details\n        print(cls,':')\n        print('Total images: ', len(allFileNames))\n        print('Training: ', len(train_FileNames))\n        print('Validation: ', len(val_FileNames))\n        print('Testing: ', len(test_FileNames))\n\n        # Copy-pasting images\n        for name in train_FileNames:\n            shutil.copy(name, 'train\/' + cls)\n\n        for name in val_FileNames:\n            shutil.copy(name, 'val\/' + cls)\n\n        for name in test_FileNames:\n            shutil.copy(name, 'test\/' + cls)\n        print();\n        \n\n# Preforming Train \/ Validation \/ Test Split\nroot_dir = \".\/CervicalCancer\"               # Dataset Root Folder\nclasses_dir = [\"Dyskeratotic\", \"Koilocytotic\", \"Metaplastic\", \"Parabasal\", \"Superficial-Intermediate\"]   # Classes\nTrainValTestSplit(root_dir, classes_dir);","f6587409":"# Importing Keras for Image Classification\nimport keras\nfrom keras.layers import Dense,Conv2D, Flatten, MaxPool2D, Dropout\nfrom keras.models import Sequential\nfrom keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model","562109de":"# CNN Model \n\nmodel = Sequential() \n# Convolutional Layer with input shape (64,64,3)\nmodel.add(Conv2D(filters=16, kernel_size= (3,3), activation= 'relu', input_shape=(64,64,3)) )\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=5, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']  )\n \nmodel.summary()","3c7635c7":"# Expand the size of dataset with new transformed images from the original dataset using ImageDataGenerator.\ntrain_datagen = image.ImageDataGenerator(zoom_range = 0.2, shear_range = 0.2 , rescale = 1.\/255 , horizontal_flip=True)\nval_datagen = image.ImageDataGenerator(rescale = 1.\/255)\ntest_datagen = image.ImageDataGenerator(rescale = 1.\/255)","df3e7f01":"train_data = train_datagen.flow_from_directory(directory= \".\/train\", target_size=(64, 64), batch_size=100, class_mode = 'categorical')","f9bea3cd":"train_data.class_indices","5f908e9b":"val_data = val_datagen.flow_from_directory(directory= \".\/val\", target_size=(64, 64), batch_size=100, class_mode = 'categorical')","1a89a85b":"test_data = test_datagen.flow_from_directory(directory= \".\/test\", target_size=(64, 64), batch_size=100, class_mode = 'categorical')","cf281e62":"# Adding Model check point Callback\nmc = ModelCheckpoint(filepath=\"cervical_cancer_best_model.hdf5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto');\ncall_back = [ mc ];","0d65be01":"# Fitting the Model\ncnn = model.fit(train_data, \n                  steps_per_epoch= 28, \n                  epochs= 32,\n                  validation_data= val_data, \n                  validation_steps= 6,\n                  callbacks = call_back )","24cbaa40":"# Loading the Best Fit Model \nmodel = load_model(\".\/cervical_cancer_best_model.hdf5\")","213f9635":"# Checking the Accuracy of the Model \naccuracy = model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of your model is = {accuracy*100} %\")","a1f38d04":"h =  cnn.history;\nh.keys();","ced0d23e":"# Ploting Accuracy In Training Set & Validation Set\n\nplt.plot(h['accuracy'])\nplt.plot(h['val_accuracy'] , c = \"red\")\nplt.title(\"acc vs v-acc\")\nplt.show()","a2a43c41":"# Ploting Loss In Training Set & Validation Set\n\nplt.plot(h['loss'])\nplt.plot(h['val_loss'] , c = \"red\")\nplt.title(\"loss vs v-loss\")\nplt.show()","9937d713":"def cancerPrediction(path):\n    classes_dir = [\"Dyskeratotic\",\"Koilocytotic\",\"Metaplastic\",\"Parabasal\",\"Superficial-Intermediate\"]\n    # Loading Image\n    img = image.load_img(path, target_size=(64,64))\n    # Normalizing Image\n    norm_img = image.img_to_array(img)\/255\n    # Converting Image to Numpy Array\n    input_arr_img = np.array([norm_img])\n    # Getting Predictions\n    pred = np.argmax(model.predict(input_arr_img))\n    # Printing Model Prediction\n    print(classes_dir[pred])\n\npath = \"..\/input\/cervical-cancer-largest-dataset-sipakmed\/im_Dyskeratotic\/im_Dyskeratotic\/CROPPED\/002_04.bmp\"\ncancerPrediction(path)","7aae84ed":"### Building Model \n","0496e684":"### Split the Dataset such that we have\n* 70% for Train Data\n* 15% for Validation Data\n* 15% for Testing Data","6c1d1005":"### Preparing data using data generator ","d228f631":"### Model Accuracy"}}