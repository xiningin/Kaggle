{"cell_type":{"a5f68f5c":"code","b38e3384":"code","4155e412":"code","666efe7a":"code","f59ff966":"code","b84c5840":"code","742d383a":"code","ea0fd4af":"code","925b3cf4":"code","825a2716":"code","e3f888ab":"code","d77b897c":"code","86240bcd":"code","c61f3ba0":"code","d8774d86":"code","d14645ad":"code","eb008abb":"code","efc0de40":"code","74539bc0":"code","a0ff6fbc":"code","92529c5e":"code","1641d60e":"code","c047dab4":"markdown","84e587cb":"markdown","9781c6de":"markdown","95945630":"markdown","15d4650e":"markdown"},"source":{"a5f68f5c":"import numpy as np\nimport pandas as pd\nimport datetime\nfrom catboost import CatBoostClassifier\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm","b38e3384":"from sklearn.metrics import confusion_matrix\ndef qwk(act,pred,n=4,hist_range=(0,3)):\n    \n    O = confusion_matrix(act,pred)\n    O = np.divide(O,np.sum(O))\n    \n    W = np.zeros((n,n))\n    for i in range(n):\n        for j in range(n):\n            W[i][j] = ((i-j)**2)\/((n-1)**2)\n            \n    act_hist = np.histogram(act,bins=n,range=hist_range)[0]\n    prd_hist = np.histogram(pred,bins=n,range=hist_range)[0]\n    \n    E = np.outer(act_hist,prd_hist)\n    E = np.divide(E,np.sum(E))\n    \n    num = np.sum(np.multiply(W,O))\n    den = np.sum(np.multiply(W,E))\n        \n    return 1-np.divide(num,den)\n    ","4155e412":"train = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train.csv')\ntrain_labels = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train_labels.csv')\nspecs = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/specs.csv')\ntest = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/sample_submission.csv')","666efe7a":"# encode title\nlist_of_user_activities = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\nactivities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n\ntrain['title'] = train['title'].map(activities_map)\ntest['title'] = test['title'].map(activities_map)\ntrain_labels['title'] = train_labels['title'].map(activities_map)","f59ff966":"win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\nwin_code[activities_map['Bird Measurer (Assessment)']] = 4110","b84c5840":"train['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'])","742d383a":"# no intersection between installation ids of train and test","ea0fd4af":"# user_sample = train.query('installation_id==\"0006a69f\"')\n# user_sample = test.query('installation_id==\"01242218\"') ","925b3cf4":"def get_data(user_sample, test_set=False):\n    last_activity = 0\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy=0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0 \n    accumulated_actions = 0\n    counter = 0\n    durations = []\n    for i, session in user_sample.groupby('game_session', sort=False):\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        if test_set == True:\n            second_condition = True\n        else:\n            if len(session)>1:\n                second_condition = True\n            else:\n                second_condition= False\n            \n        if (session_type == 'Assessment') & (second_condition):\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            features = user_activities_count.copy()\n    #         features['installation_id'] = session['installation_id'].iloc[0]\n#             features['game_session'] = i\n            features['session_title'] = session['title'].iloc[0] \n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            features['accumulated_accuracy'] = accumulated_accuracy\/counter if counter > 0 else 0\n            accuracy = true_attempts\/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n\n            features.update(accuracy_groups)\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group\/counter if counter > 0 else 0\n            features['accumulated_actions'] = accumulated_actions\n            accumulated_accuracy_group += features['accuracy_group']\n            accuracy_groups[features['accuracy_group']] += 1\n            if test_set == True:\n                all_assessments.append(features)\n            else:\n                if true_attempts+false_attempts > 0:\n                    all_assessments.append(features)\n                \n            counter += 1\n\n    #         break\n\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type\n\n    if test_set:\n        return all_assessments[-1] \n    return all_assessments","825a2716":"compiled_data = []\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=17000):\n    compiled_data += get_data(user_sample)","e3f888ab":"new_train = pd.DataFrame(compiled_data)\ndel compiled_data\nnew_train.shape","d77b897c":"new_train.head()","86240bcd":"all_features = [x for x in new_train.columns if x not in ['accuracy_group']]\ncat_features = ['session_title']\nX, y = new_train[all_features], new_train['accuracy_group']\ndel train","c61f3ba0":"def make_classifier():\n    clf = CatBoostClassifier(\n                               loss_function='MultiClass',\n    #                            eval_metric=\"AUC\",\n                               task_type=\"CPU\",\n                               learning_rate=0.01,\n                               iterations=2000,\n                               od_type=\"Iter\",\n#                                depth=8,\n                               early_stopping_rounds=500,\n    #                            l2_leaf_reg=1,\n    #                            border_count=96,\n                               random_seed=2019\n                              )\n        \n    return clf\noof = np.zeros(len(X))","d8774d86":"# CV\nfrom sklearn.model_selection import KFold\n# preds = np.zeros(len(X_test))\noof = np.zeros(len(X))\nNFOLDS = 5\nfolds = KFold(n_splits=NFOLDS, shuffle=True, random_state=2019)\n\ntraining_start_time = time()\nfor fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n    start_time = time()\n    print(f'Training on fold {fold+1}')\n    clf = make_classifier()\n    clf.fit(X.loc[trn_idx, all_features], y.loc[trn_idx], eval_set=(X.loc[test_idx, all_features], y.loc[test_idx]),\n                          use_best_model=True, verbose=500, cat_features=cat_features)\n    \n#     preds += clf.predict(X_test).reshape(len(X_test))\/NFOLDS\n    oof[test_idx] = clf.predict(X.loc[test_idx, all_features]).reshape(len(test_idx))\n    \n    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n    \nprint('-' * 30)\nprint('OOF QWK:', qwk(y, oof))\nprint('-' * 30)","d14645ad":"# train model on all data once\nclf = make_classifier()\nclf.fit(X, y, verbose=500, cat_features=cat_features)\n\ndel X, y","eb008abb":"# process test set\nnew_test = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=1000):\n    a = get_data(user_sample, test_set=True)\n    new_test.append(a)\n    \nX_test = pd.DataFrame(new_test)\ndel test","efc0de40":"# make predictions on test set once\npreds = clf.predict(X_test)\ndel X_test","74539bc0":"submission['accuracy_group'] = np.round(preds).astype('int')\nsubmission.to_csv('submission.csv', index=None)\nsubmission.head()","a0ff6fbc":"submission['accuracy_group'].plot(kind='hist')","92529c5e":"train_labels['accuracy_group'].plot(kind='hist')","1641d60e":"pd.Series(oof).plot(kind='hist')","c047dab4":"Below are the features I have generated. Note that all of them are **prior** to each event. For example, the first row shows **before** this assessment, the player have watched 3 clips, did 3 activities, played 4 games and solved 0 assessments, so on so forth.","84e587cb":"Note that Cross validation is only for the feature engineering part and you don't actually need it if you want to submit the results. You can safely comment it out. ","9781c6de":"## Make submission","95945630":"## Model","15d4650e":"I had posted my very naive baseline at https:\/\/www.kaggle.com\/mhviraf\/a-baseline-for-dsb-2019. In that kernel I only used the mode label for each Assessment and I thought it should be very easy to beat. This kernel shows how you can beat that baseline by actually applying a model. In this kernel via `get_data()` function, I go over each `installation_id` and try to extract some features based on his\/her behavior prior to the assessment. I will then train a `Catboost` classifier on it and make predictions on the test set. Note that the features I made in this kernel are so very basic and you can easily add many more to it. Good luck and happy kaggling. Don't forget to upvote if you found it useful ;)"}}