{"cell_type":{"f585a186":"code","bb4f544d":"code","898add35":"code","7a394e6d":"code","adfe3ba0":"code","f7da606e":"code","1bc33db7":"code","84026b01":"code","421e8c37":"code","d1c7cf64":"code","cee4ef76":"code","89acba05":"code","75d3d786":"code","1f190238":"code","d051949a":"code","15bbac0d":"code","18216e29":"code","f61c9d3b":"code","c643ca81":"code","6811c842":"code","ff9064de":"code","7fdcc2e1":"code","203c0bf6":"code","c12c61fa":"code","b5cab429":"code","1fc69c6d":"code","34aee2d8":"code","bbfdc5ab":"code","7776a814":"code","54346142":"code","db6fd716":"code","99397212":"code","34579151":"code","2836311c":"code","b07aa2d6":"code","5e8e8a46":"code","a844eef3":"code","a2f291d3":"code","902c09df":"code","97d107d3":"code","a0c61350":"code","ba963f3f":"code","488a90d9":"code","f8201667":"code","164230bf":"markdown","d18112ac":"markdown","f5937c10":"markdown","1bfc5497":"markdown","a6d4a504":"markdown","4de614a4":"markdown","d6725820":"markdown","85d8db3f":"markdown","13889972":"markdown","fa2a7c1a":"markdown","e2520c70":"markdown","df8b0a90":"markdown","90d4e206":"markdown","29f5050e":"markdown","61a1d357":"markdown","3946572b":"markdown","3d6a071d":"markdown","d8dae0bc":"markdown","2f530891":"markdown","9a522187":"markdown","22dcff11":"markdown","a19c7970":"markdown","948c9717":"markdown","ae138345":"markdown","761f7b55":"markdown","ce1f3c4f":"markdown","1d3cb003":"markdown","ade8fc33":"markdown","5ac4919a":"markdown","d078d815":"markdown","d5444c4e":"markdown","ab2bddf5":"markdown","c89c737e":"markdown","64716185":"markdown","13d2c127":"markdown","9af89b1d":"markdown","f3d37cdd":"markdown","bf3ea6f2":"markdown","9e3b13fb":"markdown","adec42f0":"markdown","f1aab386":"markdown","fef58f87":"markdown","cff61a6c":"markdown","ca18cf91":"markdown","b1af9df2":"markdown","ac48282a":"markdown"},"source":{"f585a186":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bb4f544d":"import numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\", None)\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nfrom plotly.offline import init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom surprise import Dataset, Reader, KNNBasic\nfrom surprise.model_selection import train_test_split\nimport sys\nfrom itertools import combinations, groupby\nfrom collections import Counter\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.sparse import csr_matrix\nfrom fuzzywuzzy import fuzz\nfrom sklearn.neighbors import NearestNeighbors","898add35":"metadata = pd.read_csv('..\/input\/the-movies-dataset\/movies_metadata.csv', parse_dates=True)\nmetadata.head()","7a394e6d":"metadata.genres = [', '.join(i for i in re.findall(r\"(?<='name': ')\\w+(?='})\", j)) for j in metadata.genres]\n\ndef freq(column, xlab, ylab, title): \n    str = ', '.join(i.replace(',','') for i in column).replace(',', '')\n    str = str.split()          \n    str2 = []\n    count = []\n    for i in str:              \n        if i not in str2:\n            str2.append(i)    \n    for i in range(0, len(str2)):\n        count.append(str.count(str2[i]))\n        print('Frequency of', str2[i], 'is :', str.count(str2[i]))\n        \n    df = pd.DataFrame({'word': str2, 'frequency': count}).sort_values(ascending=False, by=['frequency'])[::-1]\n    # Create trace\n    trace = go.Bar(x = df.frequency, text = df['word'],\n                   textposition = 'outside', textfont = dict(color = '#000000'),\n                   orientation = 'h', y = list(range(0, len(str2))), marker = dict(color = '#db0000'))\n    # Create layout\n    layout = dict(title = title, xaxis = dict(title = xlab, range = (0, max(count)+2000)),\n                  yaxis = dict(title = ylab))\n    # Create plot\n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)\n          \nfreq(metadata.genres, xlab='frequency', ylab='genres', title='Genres Frequency')","adfe3ba0":"metadata.spoken_languages = [', '.join(i for i in re.findall(r\"(?<='name': ')[a-zA-Z\\s]+(?='})\", str(j))) for j \\\n                                 in metadata.spoken_languages]\n\nlanguages = metadata.spoken_languages.value_counts().sort_values(ascending=False)[:10][::-1]\n\ntrace = go.Bar(x = languages.values, text = languages.values, orientation = 'h',\n                   textposition = 'auto', textfont = dict(color = '#000000'),\n               y = languages.index, marker = dict(color = '#db0000'))\n    \nlayout = dict(title = 'Top 20 Most Spoken Languages', xaxis = dict(title = 'Count'),\n              yaxis = dict(title = 'Languages'))\n    \nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","f7da606e":"metadata.production_companies = [', '.join(i for i in re.findall(r\"(?<={'name': ')[a-zA-Z\\s]+(?=',)\", str(j))) for j \\\n                                 in metadata.production_companies]\n\n# Remove 1st value because there is no company shown\ncomps = metadata.production_companies.value_counts().sort_values(ascending=False)[1:20]\n\ntrace = go.Bar(x = comps.index, text = comps.values,\n                   textposition = 'auto', textfont = dict(color = '#000000'),\n               y = comps.values, marker = dict(color = '#db0000'))\n    \nlayout = dict(title = 'Top 20 production companies', xaxis = dict(title = 'Companies'),\n              yaxis = dict(title = 'Count'))\n    \nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","1bc33db7":"date = []\nfor i in metadata[~metadata.release_date.isna()]['release_date']:\n    try:\n        date.append(pd.to_datetime(i, format='%Y-%m-%d').year)\n    except:\n        pass\nyear = pd.Series(date).value_counts().sort_index()\n\ntrace = go.Scatter(x = year.index, y = year.values)\n# Create layout\nlayout = dict(title = 'Number of Movies Released Throughout {} Years'.format(year.shape[0]),\n              xaxis = dict(title = 'Release Year'),\n              yaxis = dict(title = 'Number of Movies'))\n\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","84026b01":"ratings = pd.read_csv('..\/input\/the-movies-dataset\/ratings_small.csv')\nratings.head()","421e8c37":"rate_year = pd.to_datetime(ratings['timestamp'], unit='s').dt.year.value_counts().sort_index()\n\ntrace = go.Scatter(x = rate_year.index, y = rate_year.values)\n# Create layout\nlayout = dict(title = 'Number of Movies Ratings Throughout {} Years'.format(rate_year.shape[0]),\n              xaxis = dict(title = 'Year'),\n              yaxis = dict(title = 'Number of Movies Ratings'))\n\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","d1c7cf64":"r = ratings.rating.value_counts().sort_index()\n\ntrace = go.Bar(x = r.index, text = ['{:.1f} %'.format(val) for val in (r.values * 100 \/ r.values.sum())],\n                                    y = r.values, textposition = 'auto',\n              marker = dict(color = '#df1447'))\n# Create layout\nlayout = dict(title = 'Ratings by Users',\n              xaxis = dict(title = 'Ratings'),\n              yaxis = dict(title = 'count'))\n\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","cee4ef76":"links = pd.read_csv('..\/input\/the-movies-dataset\/links_small.csv')\nlinks.dropna(inplace=True)\nlinks.tmdbId = links.tmdbId.map(int)\nlinks.head()","89acba05":"df = metadata[['genres', 'id', 'imdb_id', 'overview', 'release_date', 'title']]\ndf.dropna(inplace=True)\ndf.imdb_id = df.imdb_id.str.replace('tt', '')\ndf.imdb_id = df.imdb_id.map(int)\ndf.id = df.id.map(int)\nprint(df.info())\ndf.head()","75d3d786":"data = ratings.set_index('movieId').join(links.set_index('movieId')).reset_index().set_index('tmdbId').join(df.set_index('id')).dropna()\ndata = data.reset_index(drop=True)\ndata.drop(columns=['imdb_id'], inplace=True)\ndata.sample(6)","1f190238":"data.shape","d051949a":"def filtered_items(n, f, group, series, df):\n    stats = df.groupby(group)[series].agg(f)\n    stats.index = stats.index.map(int)\n    benchmark = round(stats['count'].quantile(n), 0)\n    rm_items_index = stats[stats['count'] < benchmark].index\n    return rm_items_index\ndrop_m_ind = filtered_items(n=0.7, f=['count', 'mean'], group='movieId', series='rating', df=ratings)\ndrop_u_ind = filtered_items(n=0.7, f=['count', 'mean'], group='userId', series='rating', df=ratings)\n\nratings_filtered = ratings[~ratings.movieId.isin(drop_m_ind)]\nratings_filtered = ratings_filtered[~ratings_filtered.userId.isin(drop_u_ind)].drop('timestamp', axis=1)\nratings_filtered.tail()","15bbac0d":"n = 20\nmost_rated = data.groupby('title')['rating'].count().sort_values(ascending=False).head(n)\n\ntrace = go.Bar(x = most_rated.index, text = most_rated.values,\n                                    y = most_rated.values, textposition = 'auto', marker = dict(color = '#df0003'))\n\n# Create layout\nlayout = dict(title = 'Top {} Most Rated Movies'.format(n),\n              xaxis = dict(title = 'Movie Titles'),\n              yaxis = dict(title = 'count'))\n\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","18216e29":"movies_link = data[['movieId', 'title', 'genres']].drop_duplicates(['movieId', 'title', 'genres']).set_index('movieId')\nmovies_link.head()","f61c9d3b":"m = ratings_filtered.pivot_table(index='userId', columns='movieId', values='rating')\nuser_m = m.fillna(0)\nmovie_m = user_m.T\nm.head()","c643ca81":"m.shape","6811c842":"m.count(axis=0)","ff9064de":"n = 20\n\nrating_mean = m.mean(axis=0).rename('rating_mean').to_frame()\n\nrating_count = m.count(axis=0).rename('rating_count').to_frame()\n\nd = rating_mean.join(rating_count).join(data[['movieId', 'title']].drop_duplicates\\\n                                        (subset=['movieId', 'title']).set_index('movieId'))\n\nd = d.sort_values(by='rating_mean', ascending=False)[:n]\n\nprint(d)\n\ntrace = go.Bar(x = d.title, text = d.rating_mean,\n                                    y = d.rating_mean, textposition = 'auto', marker = dict(color = '#df0003'))\n\n# Create layout\nlayout = dict(title = 'Top {} high rated movies'.format(n),\n              xaxis = dict(title = 'Movie Titles'),\n              yaxis = dict(title = 'count'))\n\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","7fdcc2e1":"def cosine_re_userBased(n, userId):\n    \n    cosine_user_m = cosine_similarity(user_m) - np.eye(user_m.shape[0])\n    \n    sim_index_user = np.argsort(cosine_user_m[userId-1])[::-1]\n    sim_score_user = np.sort(cosine_user_m[userId-1])[::-1]\n    \n    urated_movies = m.loc[userId,][m.loc[userId,].isna()].index\n    \n    mean_mov_re = (user_m.iloc[sim_index_user[:50]].T * sim_score_user[:50]).T.mean(axis=0)\n    \n    top_recommendation = mean_mov_re[urated_movies].sort_values(ascending=False)[:n].to_frame().join(movies_link[['title']])\n    \n    print(top_recommendation)\n    \n    trace = go.Bar(x=top_recommendation.title, text=[round(i, 3) for i in top_recommendation.iloc[:, 0]],\n                   y=top_recommendation.iloc[:, 0],\n                  textposition = 'auto', marker = dict(color = '#df0003'))\n    layout = dict(title = 'Top 10 Recommended Movies for User {}'.format(userId),\n              xaxis = dict(title = 'Movie Titles'),\n              yaxis = dict(title = 'Similarity Score'))\n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)","203c0bf6":"cosine_re_userBased(n=20, userId=119)","c12c61fa":"# similar movies based on users rating and genres\ndef moviesBased_rec(n, title):\n    \n    positionId = [movie_m.index.get_loc(i) for i in movies_link[movies_link.title == title].index]\n    cosine_movies_m = cosine_similarity(movie_m)\n    sim_index_mov = [np.argsort(cosine_movies_m[pId])[::-1][:50] for pId in positionId]\n    \n    for sim_index_ in sim_index_mov:\n        simMovies = (movie_m.iloc[sim_index_,]).T.mean\\\n        (axis=0).sort_values(ascending=False).to_frame().join(movies_link)\n        simMovies = simMovies.reset_index().rename(columns={'index': 'movieId'})\n        \n        # improve model by involving genres\n        guess = []\n        for i, v in enumerate(simMovies.genres):\n            try:\n                for j in v.split(', '):\n                    if j in \", \".join(i for i in movies_link[movies_link.title == title]['genres'].values).split(', ') \\\n                    and j not in guess:\n                        guess.append(i)\n            except: pass\n    \n        simMovies = simMovies.iloc[guess,:][:n]\n        simMovies = simMovies.drop_duplicates(['movieId', 'title', 'genres'])#[1:]\n        print(simMovies.to_string())\n        \n        trace = go.Bar(x= simMovies.title, text=[round(i, 4) for i in  simMovies.iloc[:, 1]],\n                       y= simMovies.iloc[:, 1],\n                      textposition = 'auto', marker = dict(color = '#df0003'))\n        layout = dict(title = 'Top Similar Rated Movies to {}'.format(title),\n                  xaxis = dict(title = 'Movie Titles'),\n                  yaxis = dict(title = 'Similarity Score'))\n        fig = go.Figure(data=[trace], layout=layout)\n        iplot(fig)\nmoviesBased_rec(n=20, title='The Notebook')","b5cab429":"def may_also_like(n, title):\n    # get the movieId\n    movieId = [i for i in movies_link[movies_link.title == title].index]\n    \n    # begin the loop\n    for mId in movieId:\n        # users that watched the movies\n        watched_users = [uid for uid in m.loc[:, mId].dropna().index]\n        # get the Id of users that rated more than 3 for the movie\n        ref_users = [index for (index, value) in zip(watched_users, \\\n                                                     m.loc[watched_users, mId]) if value >=3.0]\n        # create matrix with columns of ref_users \n        sameWatchs = m.loc[ref_users,:].dropna(how='all', axis=1)\n        sameWatchs = sameWatchs.T\n        #sameWatchs_m = sameWatchs.T.fillna(sameWatchs.mean(axis=1)).T\n        sameWatchs_m = sameWatchs.fillna(0)\n        \n        # get the index of movieId inside matrix of ref_users\n        pos = sameWatchs.index.get_loc(sameWatchs.loc[mId,:].name)\n    \n    \n        cosine_ref_users = (cosine_similarity(sameWatchs_m) - np.eye(sameWatchs_m.shape[0]))\n        # get the 50 highest cosine scores\n        sim_index_mov = np.argsort(cosine_ref_users[pos])[::-1][:50]\n    \n        # calculate the mean of 50 movie with highest score from ref_users matrix \n        posibility = (sameWatchs_m.iloc[sim_index_mov,:]).T.mean\\\n                     (axis=0).sort_values(ascending=False).to_frame().join(movies_link)\n        posibility = posibility.reset_index().rename(columns={'index': 'movieId'})[:n]\n        \n        guess = []\n        for i, v in enumerate(posibility.genres):\n            for j in v.split(', '):\n                if j in \", \".join(i for i in movies_link[movies_link.title == title]['genres'].values).split(', ') \\\n                and j not in guess:\n                    guess.append(i)\n        guess = list(set([x for x in guess if guess.count(x) >= 1]))\n        final = posibility.iloc[guess,:][:n]\n        final = final.drop_duplicates(['movieId', 'title', 'genres'])\n        print(final.to_string())\n    \n        trace = go.Bar(x= final.title, text=[round(i, 4) for i in  final.iloc[:, 1]],\n                        y= final.iloc[:, 1],\n                        textposition = 'auto', marker = dict(color = '#df0003'))\n        layout = dict(title = 'Top {} Recommended Movies if you enjoy {}'.format(n, title),\n                      xaxis = dict(title = 'Movie Titles'),\n                      yaxis = dict(title = 'Similarity Score'))\n        fig = go.Figure(data=[trace], layout=layout)\n        iplot(fig)","1fc69c6d":"may_also_like(n=20, title='The Notebook')","34aee2d8":"def next_movies(n, userId):\n    \n    watched = data[(data.userId == userId) & (data.rating >= 4)]['movieId']\n    \n    #position = np.argmax(cosine_sim(user_m) - np.eye(user_m.shape[0]), axis=1).tolist()[userId-1]\n    position = np.argmax(cosine_similarity(user_m) - np.eye(user_m.shape[0]), axis=1).tolist()[userId-1]\n\n    #suggest = user_m.iloc[position,].sort_values(ascending=False).to_frame().join(movies_link)\n    suggest = m.fillna(0).iloc[position,].sort_values(ascending=False).to_frame().join(movies_link)\n    \n    for w in watched:\n        if w in suggest.index: suggest = suggest.drop(w, axis=0)\n        else: pass\n    suggest = suggest[:n]\n    \n    print(suggest.to_string())\n    trace = go.Bar(x= suggest.title, text=[round(i, 4) for i in  suggest.iloc[:, 0]],\n                   y= suggest.iloc[:, 0],\n                  textposition = 'auto', marker = dict(color = '#df0003'))\n    layout = dict(title = 'Top {} Recommended Movies for User {}'.format(n, userId),\n              xaxis = dict(title = 'Movie Titles'),\n              yaxis = dict(title = 'Similarity Score'))\n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)\nnext_movies(n=20, userId=119)","bbfdc5ab":"# Getting suggestions from users of same ratings\n\ndef next_movies2(n, userId):\n\n    bestMovies = [i for i, v in zip(data[data.userId == userId]['movieId'],\n                                    data[data.userId == userId]['rating']) if v >= 4]\n    sameWatchs = m.loc[:, bestMovies].dropna(how='all').index\n\n    pref = []\n    for ui in sameWatchs:\n        for mId in bestMovies:\n            try:\n                if m.loc[ui, mId] == np.nan: pass\n                else:\n                    if m.loc[ui, mId] >= 4:\n                        pref.append(ui)\n            except: pass\n    following_suggest = list(set([x for x in pref if pref.count(x) >= 2]))\n    #following_suggest.remove(userId)\n    following_m = user_m.loc[following_suggest,]\n    \n    \n    watched = data[(data.userId == userId) & (data.rating >= 4)]['movieId']\n    \n    position = following_m.index.get_loc(userId)\n\n    suggest = following_m.iloc[np.argmax(cosine_similarity(following_m) - np.eye(following_m.shape[0]), axis=1).tolist()\\\n                               [position]][::-1].sort_values(ascending=False).to_frame().join(movies_link)\n    for w in watched:\n        if w in suggest.index: suggest = suggest.drop(w, axis=0)\n        else: pass\n    suggest = suggest[:n]\n    \n    print(suggest.to_string())\n    trace = go.Bar(x= suggest.title, text=[round(i, 4) for i in  suggest.iloc[:, 0]],\n                   y= suggest.iloc[:, 0],\n                  textposition = 'auto', marker = dict(color = '#df0003'))\n    layout = dict(title = 'Top {} Recommended Movies for User {}'.format(n, userId),\n              xaxis = dict(title = 'Movie Titles'),\n              yaxis = dict(title = 'Similarity Score'))\n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)\nnext_movies2(n=20, userId=119)","7776a814":"m_corr = ratings_filtered.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\nm_corr.head()","54346142":"def pearson_rec(n, title):\n    print(\"- Top 10 movies recommended for {} based on Pearsons'R correlation - \".format(title))\n    # mId = int(movies_link2.index[movies_link2['title'] == title][0])\n    mId = [i for i in movies_link[movies_link['title'] == title].index]\n    targets = [user_m.loc[:,i] for i in mId]\n    sim_targets = [user_m.corrwith(target) for target in targets]\n    for sim_target in sim_targets:\n        corr_target = pd.DataFrame(sim_target, columns = ['PearsonR'])\n        corr_target.dropna(inplace = True)\n        corr_target = corr_target.sort_values('PearsonR', ascending = False)\n        corr_target.index = corr_target.index.map(int)\n        corr_target = corr_target.join(movies_link)[['PearsonR', 'title', 'genres']][:n]\n        print(corr_target.to_string(index=False))\n    \n        # Graph\n        trace = go.Bar(x=corr_target.title, text=[round(i, 4) for i in  corr_target['PearsonR']],\n                        y= corr_target['PearsonR'],\n                        textposition = 'auto', marker = dict(color = '#df0003'))\n        layout = dict(title = 'Top Similar Movies to {}'.format(title),\n                      xaxis = dict(title = 'Movie Titles'),\n                      yaxis = dict(title = 'PearsonR Score'))\n        fig = go.Figure(data=[trace], layout=layout)\n        iplot(fig)\n    \npearson_rec(n = 20, title='Batman Begins')","db6fd716":"pearson_rec(n = 20, title='Iron Man')","99397212":"from scipy.sparse import csr_matrix\nfrom fuzzywuzzy import fuzz\nfrom sklearn.neighbors import NearestNeighbors\n\ndef fuzzy_match(title):\n    match = [fuzz.ratio(title, i) for i in data['title']]\n    return data.iloc[match.index(100),]['movieId']\n\ndef Knn_recommendation(n, data, matrix, title):\n    \n    csr_m_knn = csr_matrix(matrix)\n    #make an object for the NearestNeighbors Class.\n    model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=n+1, n_jobs=-1)\n\n    # fit the dataset\n    model_knn.fit(csr_m_knn)\n\n    ix = fuzzy_match(title=title)\n    idx = matrix.index.get_loc(matrix.loc[ix,].name)\n\n    distances, indices = model_knn.kneighbors(csr_m_knn[idx], n_neighbors=n+1)\n\n    df = pd.DataFrame({'position': indices.squeeze(), 'score': distances.squeeze()}).sort_values\\\n    (by='score', ascending=False)\n\n    movies_title = [data[data.movieId == matrix.iloc[i,].name]['title'].values[0] for i in df['position']]\n\n    df['title'] = movies_title\n    print(df.to_string())\n    \n    trace = go.Bar(x= df.title, text=[round(i, 4) for i in  df['score']],\n                    y=df['score'], textposition = 'auto', marker = dict(color = '#df0003'))\n    layout = dict(title = 'Top Similar Rated Movies to {}'.format(title),\n                  xaxis = dict(title = 'Movie Titles'),\n                  yaxis = dict(title = 'Similarity Score'))\n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)\nKnn_recommendation(n=20, data=data, matrix=movie_m, title='Iron Man')","34579151":"Knn_recommendation(n=20, data=data, matrix=movie_m, title='Batman Begins')","2836311c":"Knn_recommendation(n=20, data=data, matrix=movie_m, title='The Notebook')","b07aa2d6":"def pearson_rec(n, title):\n    print(\"- Top 10 movies recommended for {} based on Pearsons'R correlation - \".format(title))\n    # mId = int(movies_link2.index[movies_link2['title'] == title][0])\n    mId = [i for i in movies_link[movies_link['title'] == title].index]\n    targets = [user_m.loc[:,i] for i in mId]\n    sim_targets = [user_m.corrwith(target) for target in targets]\n    for sim_target in sim_targets:\n        corr_target = pd.DataFrame(sim_target, columns = ['PearsonR'])\n        corr_target.dropna(inplace = True)\n        corr_target = corr_target.sort_values('PearsonR', ascending = False)\n        corr_target.index = corr_target.index.map(int)\n        corr_target = corr_target.join(movies_link)[['PearsonR', 'title', 'genres']][:n]\n        print(corr_target.to_string(index=False))\n    \n        # Graph\n        trace = go.Bar(x=corr_target.title, text=[round(i, 4) for i in  corr_target['PearsonR']],\n                        y= corr_target['PearsonR'],\n                        textposition = 'auto', marker = dict(color = '#df0003'))\n        layout = dict(title = 'Top Similar Movies to {}'.format(title),\n                      xaxis = dict(title = 'Movie Titles'),\n                      yaxis = dict(title = 'PearsonR Score'))\n        fig = go.Figure(data=[trace], layout=layout)\n        iplot(fig)\n    \npearson_rec(n = 20, title='Batman Begins')","5e8e8a46":"pearson_rec(n = 20, title='Iron Man')","a844eef3":"from scipy.sparse.linalg import svds\n\nm_demeaned = user_m - np.mean(user_m, axis=1).values.reshape(-1, 1)\n\nU, sigma, Vt = svds(m_demeaned, k = 50)\nsigma = np.diag(sigma)\n\nprint(m_demeaned.shape)\nprint(U.shape)\nprint(sigma.shape)\nprint(Vt.shape)","a2f291d3":"user_preds = np.dot(np.dot(U, sigma), Vt) + np.mean(user_m, axis=1).values.reshape(-1, 1)\npreds_df = pd.DataFrame(user_preds, columns = user_m.columns)\npreds_df.index = user_m.index\npreds_df.head()","902c09df":"def svd_recommendation(n, user, user_predictions):\n    # sort the prediction df\n    sorted_preds = user_predictions.loc[user,].sort_values(ascending=False)\n    \n    # \n    watched = data[data.userId == user][['userId', 'rating', 'movieId', 'title']]\n    unwatched = movies_link[~movies_link.index.isin(watched['movieId'])]\n    \n    recommendations = unwatched.join(sorted_preds).rename(columns={user: 'pred'}).sort_values(by='pred', ascending=False)[:n]\n    \n    # Graph\n    trace = go.Bar(x= recommendations.title, text=[round(i, 4) for i in  recommendations['pred']],\n                    y=recommendations['pred'], textposition = 'auto', marker = dict(color = '#df0003'))\n    layout = dict(title = 'Top Recommended Movies to user {}'.format(user),\n                  xaxis = dict(title = 'Movie Titles'),\n                  yaxis = dict(title = 'Prediction Score'))\n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)\nsvd_recommendation(n=20, user=119, user_predictions=preds_df)","97d107d3":"m_m_demeaned = movie_m - np.mean(movie_m, axis=1).values.reshape(-1, 1)\nU_m, sigma_m, Vt_m = svds(m_m_demeaned, k = 50)\nsigma_m = np.diag(sigma_m)\nmovie_preds = np.dot(np.dot(U_m, sigma_m), Vt_m) + np.mean(movie_m, axis=1).values.reshape(-1, 1)\npreds_m_df = pd.DataFrame(movie_preds, columns = movie_m.columns)\npreds_m_df.index = movie_m.index\npreds_m_df.head()","a0c61350":"def svd_movies_recommendation(n, title):\n    \n    positionId = [preds_m_df.index.get_loc(i) for i in movies_link[movies_link.title == title].index]\n    cosine_movies_m = cosine_similarity(preds_m_df)\n    sim_index_mov = [np.argsort(cosine_movies_m[pId])[::-1][:50] for pId in positionId]\n    \n    for sim_index_ in sim_index_mov:\n        simMovies = (preds_m_df.iloc[sim_index_,]).T.mean\\\n        (axis=0).sort_values(ascending=False).to_frame().join(movies_link)\n        simMovies = simMovies.rename(columns={0: 'pred'})[:n]\n    \n        print(simMovies.to_string())\n        \n        trace = go.Bar(x= simMovies.title, text=[round(i, 4) for i in  simMovies['pred']],\n                       y= simMovies['pred'],\n                      textposition = 'auto', marker = dict(color = '#df0003'))\n        layout = dict(title = 'Top Similar Rated Movies to {}'.format(title),\n                  xaxis = dict(title = 'Movie Titles'),\n                  yaxis = dict(title = 'Similarity Score'))\n        fig = go.Figure(data=[trace], layout=layout)\n        iplot(fig)\n        \nsvd_movies_recommendation(n=20, title='The Notebook')","ba963f3f":"# Define a function for calculating pair of items\n\ndef get_item_pairs(order_item):\n    order_item = order_item.reset_index().as_matrix()\n    for order_id, order_object in groupby(order_item, lambda x: x[0]):\n        item_list = [item[1] for item in order_object]\n              \n        for item_pair in combinations(item_list, 2):\n            yield item_pair\n","488a90d9":"def top_association(n, min_support, min_size):\n    \n    orders = ratings.drop(columns=['rating', 'timestamp'])\n    orders = orders.set_index('userId')['movieId']\n\n    # Calculate frequency and support\n    stats = orders.value_counts().to_frame(\"freq\")\n    stats['support']  = stats['freq'] \/ len(set(orders.index))\n    \n    # Filter out items below min support \n    qualifying_items = stats[stats['support'] >= min_support].index\n    orders = orders[orders.isin(qualifying_items)]\n\n    # Filter out orders with less than minimum requirement\n    order_size = orders.index.value_counts().rename(\"freq\")\n    qualifying_orders  = order_size[order_size >= min_size].index\n    orders  = orders[orders.index.isin(qualifying_orders)]\n    \n    # Recalculate item frequency and support\n    stats  = orders.value_counts().rename('freq').to_frame(\"freq\")\n    stats['support']  = stats['freq'] \/ len(set(orders.index))\n\n    # get values for pair of items\n    pair_gen  = get_item_pairs(orders)\n    \n    # Calculate item pair frequency and support\n    pairs  = pd.Series(Counter(pair_gen)).rename('freq').to_frame(\"freqAB\")\n    pairs['supportAB'] = pairs['freqAB'] \/ len(qualifying_orders)\n    \n    # Filter from item_pairs those below min support\n    pairs = pairs[pairs['supportAB'] >= min_support]\n\n    # Create table of association rules and compute relevant metrics\n    pairs = pairs.reset_index().rename(columns={'level_0': 'item_A', 'level_1': 'item_B'})\n    pairs = pairs\\\n    .merge(stats.rename(columns={'freq': 'freqA', 'support': 'supportA'}), left_on='item_A', right_index=True)\\\n    .merge(stats.rename(columns={'freq': 'freqB', 'support': 'supportB'}), left_on='item_B', right_index=True)\n\n    # Create table of association rules\n    pairs['confidenceAtoB'] = pairs['supportAB'] \/ pairs['supportA']\n    pairs['confidenceBtoA'] = pairs['supportAB'] \/ pairs['supportB']\n    pairs['lift']           = pairs['supportAB'] \/ (pairs['supportA'] * pairs['supportB'])\n    \n    # sort dataframe by lift\n    rules = pairs.sort_values('lift', ascending=False)\n    \n    # merge with movie title dataframe\n    title_list = movies_link.drop('genres', axis=1).reset_index()\n\n    final_rules = rules.merge(title_list.rename(columns={'title': 'itemA'}), left_on='item_A', right_on=\\\n                              'movieId').merge(title_list.rename(columns={'title': 'itemB'}),\n                                               left_on='item_B', right_on='movieId').sort_values('lift', ascending=False)\n\n    final_rules = final_rules[['itemA','itemB','freqAB','supportAB','freqA','supportA','freqB','supportB', \n                               'confidenceAtoB','confidenceBtoA','lift']]\n    \n    # Remove instances with matched titles\n    final_rules = final_rules[final_rules.itemA != final_rules.itemB]\n    \n    # Graph\n    trace = go.Bar(x=list(range(1, n+1)), text=final_rules.itemA[:n].astype(str)+\" & \"+final_rules.itemB[:n].astype(str),\n                    y=final_rules.lift[:n], textposition = 'auto', marker = dict(color = '#df0003'))\n    layout = dict(title = 'Top Most Associated Movies',\n                  xaxis = dict(title = 'Movie Titles'),\n                  yaxis = dict(title = 'Lift Score'))\n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)\n    \ntop_association(n=20, min_support=0.10, min_size=10)","f8201667":"top_association(n=20, min_support=0.05, min_size=5)","164230bf":"# - An extra data visulization created from our matrix which was just created.","d18112ac":"# 2. EDA","f5937c10":"# K-NEAREST NEIGHBOR","1bfc5497":"**Predict movie ratings for each user**","a6d4a504":"# - ASSOCIATION RULE","4de614a4":"First thing we need to do is creating a matrix with rows and columns containing user Ids and movie Ids, respectively. The values in the matrix is the ratings of users.","d6725820":"First, we will load the metadata dataset which has all of information of every movie.","85d8db3f":"#### The last dataset that we need for this notebook will help us to connect ratings dataset with the metadata.","13889972":"# - What movie genres have been made?","fa2a7c1a":"Starting from the far left of the graph, we see that user 12 will be most interested in watching \"The Shawshank Redemption\".","e2520c70":"English sure has been the most popular language to be used in cinema industy.","df8b0a90":"Association Rule will help us find the relationship between items based on the shoppers or users preferences. For more information on association rule, please refer to \"https:\/\/towardsdatascience.com\/association-rules-2-aa9a77241654\"","90d4e206":"Import necessary packages","29f5050e":"**SVD on movies similarity recommendation**","61a1d357":"# - SVD-based Collaborative Filtering","3946572b":"**Filtering for movies that do not have sufficient ratings and users with a limited ratings**","3d6a071d":"# - How is the distribution of the ratings from the audience?","d8dae0bc":"# - The languages used in movies","2f530891":"# 1. INTRODUCTION\nShopping online or watching movies is always one of the favorite activities to do for most of us, but most people tend to experience difficult times in finding a good suggestion for their likings and taste. Recommendation system, thus, is introduced as a powerful tool with advanced data leverage techniques on products and customers\u2019 preferences to help in suggesting movie titles and shopping items that can satisfy all.","9a522187":"We now will load the ratings dataset.","22dcff11":"**Since our matrix is very sparse, we need to impute missing values using mean value of ratings from the users.**","a19c7970":"# - A time series of the numbers of produced movies","948c9717":"**Calculate the cosine similarity of the users_based matrix and have it minused by the diagonal matrix since we know that the cosine similarity of a vector and itself is always 1.**","ae138345":"We can see the most frequent movie genre has been made is drama, with comedy and thriller in second and third tiers, respectively.","761f7b55":"Then, combine the above dataframe with the ratings and links dataframes.","ce1f3c4f":"# PEARSONS'R CORRELATION","1d3cb003":"# - Which companies produce most movies?","ade8fc33":"It looks like the audience like to share their reviews the most in 2000.","5ac4919a":"**Similar to the users_based matrix, this time we will create a movies_based matrix.**","d078d815":"**We can clearly see that top most associated movies are related to one another. They are either part 1 and 2 of same movie or they are both in the same genres with similar plots.**","d5444c4e":"# 5. CONCLUSION","ab2bddf5":"**We need a dataframe that has movie Ids and movie titles with their genres together.**","c89c737e":"\n# - What movie is most rated by users?","64716185":"**Clearly, it was a better recommendation that our last functions.**","13d2c127":"# 4. MODELING","9af89b1d":"Next is a function that will suggest new movies to the users based on the data of users with same references.","f3d37cdd":"# PEARSONS'R CORRELATION","bf3ea6f2":"First, drop unused columns or features from the metadata dataframe.","9e3b13fb":"Lots of movies were created and produced during 2000's era. ","adec42f0":"**This function is 80% similar to the above function. However, the matrix will be created from the data of users that used to watch the particular movie.**","f1aab386":"Based on the results of our models above, Pearsons'r correlation gave the most satisfactory recommendations\/suggestions to our movies. Second to the list is the K-nearest neighbors. Cosine similarity and SVD gave us kind of mixed results, with some in same genres and some is not.","fef58f87":"# - A time series of users rating activity over the years","cff61a6c":"**This function below will help us to predict what movies will interest a particular user.**","ca18cf91":"# 3. COMBINE NECESSARY DATA TOGETHER","b1af9df2":"# - Recommend new movies based on watching history or an interested movie","ac48282a":"With K-Nearest Neighbor, we hope that we can enhance our recommendation since the algorithm of K-Nearest Neighbor will group movies with same references together."}}