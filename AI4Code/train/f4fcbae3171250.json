{"cell_type":{"cabc5be6":"code","16e26098":"code","71ce391b":"code","ac75ccff":"code","10d59d74":"code","e4e39b96":"code","298dbc87":"code","05b5e8ee":"code","4f0972a6":"code","7657f219":"code","30d7436d":"code","7227e0ac":"code","a7941845":"code","0b3442cd":"code","c05a6cac":"code","90f3fb07":"markdown","9d4189f2":"markdown","665fe693":"markdown","fe7511ed":"markdown","1cb5e330":"markdown","fe1db909":"markdown","15101ca3":"markdown","b1637dae":"markdown","2aec093d":"markdown","94971681":"markdown","4cbe1bc3":"markdown","812f3b0c":"markdown","2543e6b4":"markdown"},"source":{"cabc5be6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","16e26098":"# importing the library which is useful for us:\nimport matplotlib.pyplot as plt # for performing data visulization through graph and plotting data\nimport seaborn as sns # it is another useful library to plot graphs and data visualization, but it provides better and beautiful graphs","71ce391b":"# Reading data\ndata=pd.read_csv('\/kaggle\/input\/windows-store\/msft.csv')\ndata.head()","ac75ccff":"# info of data\ndata.info()","10d59d74":"print(data.isnull().sum()) # printing the null values within data\ndata.dropna(how='any',inplace=True)# dropping rows having null value\ndata.isnull().sum()# checking again","e4e39b96":"#lets desribe about the data\nprint(data.describe(include='all').T)\nfig,ax=plt.subplots(1,2,figsize=(10,4))\nplt.style.use('ggplot')\nsns.boxplot(y=data['Rating'],ax=ax[0])\nsns.boxplot(y=data['No of people Rated'],ax=ax[1])\nax[0].set_title(\"What people rated\")\nax[1].set_title(\"How many people Rated\")","298dbc87":"# To check unique value within various categorical variable\nprint('Category has Unique values\\n',data['Category'].unique())\nprint('Price has Unique values\\n',data['Price'].unique())\n","05b5e8ee":"data['Price'].replace({'Free':0},inplace=True)\ndata.head()","4f0972a6":"data['Price']=data['Price'].str.extract('(\\d+)')\ndata['Price'].fillna(0,inplace=True)# we have to fill Nan value with 0 as previously our 0 is converted to nan value\ndata.head()","7657f219":"plt.figure(figsize=(10,5))\nplt.style.use('ggplot')\nsns.countplot(data['Category'])\nplt.xticks(rotation=70)","30d7436d":"data['Price']=data['Price'].astype(int)\ndata.info()","7227e0ac":"book_data=data[data['Category']=='Books']\nprint('Avg,Max,Min Rating of Book columns')\nprint(round(book_data['Rating'].mean(),2),book_data['Rating'].max(),book_data['Rating'].min())\nbook_data['Value']=book_data['Price'].apply(lambda x :'Free' if x ==0 else 'SomeCost')\nfig,ax=plt.subplots(1,2,figsize=(10,5))\nsns.countplot(book_data['Value'],ax=ax[0])\nsns.distplot(book_data['Rating'],ax=ax[1])\n\n","a7941845":"music_data=data[data['Category']=='Music']\nprint('Avg,Max,Min Rating of Music columns')\nprint(round(music_data['Rating'].mean(),2),music_data['Rating'].max(),music_data['Rating'].min())\nmusic_data['Value']=music_data['Price'].apply(lambda x :'Free' if x ==0 else 'SomeCost')\nfig,ax=plt.subplots(1,2,figsize=(10,5))\nsns.countplot(music_data['Value'],ax=ax[0])\nsns.distplot(music_data['Rating'],ax=ax[1])","0b3442cd":"book_data['Popularity']=book_data['Rating'] * book_data['No of people Rated']\ntop5_book=book_data.loc[book_data['Popularity'].nlargest(5).index]\nprint(\"Top 5 books are:\\n\",top5_book['Name'].to_string(index=False))","c05a6cac":"music_data['Popularity']=music_data['Rating'] * music_data['No of people Rated']\ntop5_music=music_data.loc[music_data['Popularity'].nlargest(5).index]\nprint(\"Top 5 books are:\\n\",top5_music['Name'].to_string(index=False))","90f3fb07":"#### So from the above we can see that we have:\n- we have a dataset with 6 columns namely- Name,Rating,No of people Rated, Category,Date,Price\n- The product rating have been given out of 5\n- Then we have count of people who rated particular product\n- Then we have category of item like books\n- then the mentioned dates \n- Price","9d4189f2":"Obsevation: \n- every category belong to music is free\n- avrage rating is 3.76","665fe693":"As we can see that now our price columns is quite sorted\nbut still we have to filter the rupee(\u20b9) from it to purely covert it into numeric data.","fe7511ed":"- From the above code we can see that Books has 13 Unique Columns which can be converted into one hot encoding.\n- In the Price columns we have some prices and one having free columns which we will convert it into 0.","1cb5e330":"#### Here we are starting our notebook exploration in following steps:\n- lets start with importing useful library\n- Reading the Dataset","fe1db909":"This is how we can find top 5 items in this dataset. Similarly you can do this for all important category like business, Health and fitness etc.\n\n## If you like this. Please Upvote and connect with me.","15101ca3":"our Price column is fully sorted and now we can draw various conclusion from it.Now we will see how the category is distributed.","b1637dae":"- so we have total 5322 enteries and 6 columns\n- we have 4 object type data and 1 float type and one int type\n- also one thing to consider we have **Date** as object so for the sake of usability we will convert it into datetime object later\n\n<h2><font color=\"orange\">We will check for null values within the dataset<\/font><\/h2>","2aec093d":"Obsevation: \n- almost every book is free\n- avrage rating is 3.79","94971681":"<h2 ><center><font color=\"brown\"> Let's dive deeper into the Dataset<\/font><\/h2>\n","4cbe1bc3":"Lets explore some more about data.we will explore in the following manner.\n1. Relation bw price and book columns.","812f3b0c":"#### Lets look for 5  popular Items:\n- Book\n- Music\n","2543e6b4":"so we have dropped all the rows having null value as there are less null values in data it is advised to drop the value.\n\n<h1 ><center><font color=\"#6f85a6\">Exploratory Data Analysis<\/font><\/h1>\n\n"}}