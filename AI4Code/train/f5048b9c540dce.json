{"cell_type":{"ff8b0693":"code","88370cfa":"code","4be719e2":"code","c54088d3":"code","91867a2e":"code","d10ff110":"code","0cf2c8cc":"code","331782ee":"code","1c57c006":"code","d4778199":"code","545dbd88":"code","b5a0227c":"code","35c7b6f2":"code","6562d14d":"code","73cd81a7":"code","5eb32ba3":"code","3946fc0a":"code","227e0bd8":"code","ba94ae8f":"code","3e63c24a":"code","321ee6ff":"code","95021cbd":"code","2138dbaf":"code","ef5e9b3f":"markdown","aac5829a":"markdown","9160d3a5":"markdown","4cbc01be":"markdown","a8de0095":"markdown","34677fdc":"markdown","d9babb0d":"markdown","e162dea4":"markdown","b6ce6aa8":"markdown","4b9c009a":"markdown","0e484112":"markdown","51ca260e":"markdown","5d20a076":"markdown","d13e2a5b":"markdown","2e487bb1":"markdown","befaa9a9":"markdown","51551144":"markdown"},"source":{"ff8b0693":"\n#################################################\n# Dependencies\n#################################################\n\n#To run it locally, we install dependencies:\n\n# for a local notebook, uncomment these:\n#!pip install pandas\n#!pip install openpyxl\n#!pip install plotly\n#!pip install pywin32 \n#! pip install ptitprince\n\n\n# To run in Kaggle:\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n\n\n","88370cfa":"\n#################################################\n# Configuration\n#################################################\n\n#in kaggle:\ndatapath= '..\/input\/evaluatingparticipantresponsestovrusingrl'\n\n#in a local notebook:\n#datapath= '.'\n\n\n#to write intermediary files:\nWRITE_DATA = True\n\n\nif WRITE_DATA:\n    import datetime\n    now = datetime.datetime.now()\n    filename_individual_data = 'rldata_participants'+str(now.date())+'.xlsx'\n    filename_collective_data = 'rldata_group'+str(now.date())+'.xlsx'\n    print(\"ready to save data\")","4be719e2":"\n\n#general dependencies\nimport pandas as pd\nimport numpy as np\n\n\nimport seaborn as sb\nimport matplotlib.pyplot as plt\npng_res = 300\n\n\nimport re\nimport openpyxl\n\n\n#import pdb; #this is for the debugger\nfrom openpyxl import load_workbook\n\nfrom collections import Counter \n\n\nfrom scipy import stats\n\nif WRITE_DATA:\n    from openpyxl import load_workbook\n","c54088d3":"selectedParticipants = ['101','102', '103', '104', '105', '109', '110', '111','112','113','114','115','116','118','119','120','121','122','124','125']\n\n\nlast_iteration = 24\n\n#to check with half the iterations:\n#last_iteration = 12\n\nparticipant_data = []\n\n\n#support function used to parse a matrix: \ndef _parse_matrix(matstring):\n    vals = []\n    for val in matstring.split(', '):#important to have a space\n        val = val.strip() #to remove additional spaces\n        val = val.replace(',','.') #decimals marked with points\n        val = val.strip()\n        if(len(val)>0):\n            #print(val)\n            vals.append(float(val))\n    return vals\n\n\n\nfor x in selectedParticipants :\n    filename = datapath + '\/data-raw\/rldata' +x+'.txt'\n    one_participant_data = []\n\n    with open(filename) as file:\n        file_contents = file.read()\n        #print(file_contents)\n\n        rest = file_contents\n        i = 0\n        while(i < last_iteration ):\n            data_dict = {}\n            #first line is info:\n            #infoline = file.readline();\n\n            temp1 = rest.split('\\n',1);\n            infoline = temp1[0];\n            rest = temp1[1];\n\n            #up to next semicolon it is a matrix (3 times)\n            temp2 = rest.split(';',3)\n\n            infoQmat = temp2[0]\n            infoPresentations = temp2[1]\n            infoAccepted = temp2[2]\n            rest = temp2[3]\n            #print(\"the length left is: \" + str(len(rest)))\n\n            #we take care of the infoline:\n            vals = []\n            for val in  infoline.split(';'):\n                vals.append(val);\n\n            #pdb.set_trace()\n            #print(vals)\n            #print(\"length of vals is: \" + str(len(vals)));\n            data_dict['participantID'] = vals[0];\n            data_dict['datetime'] = (vals[1]);\n            data_dict['secsstarted'] = vals[2];\n            data_dict['currentstate'] = str(vals[3]);\n\n            #we also take care of the matrices:\n            data_dict['infoQmat'] = _parse_matrix(infoQmat);\n            data_dict['infoPres'] = _parse_matrix(infoPresentations);\n            data_dict['infoAccepted'] = _parse_matrix(infoAccepted);\n\n            one_participant_data.append(data_dict)\n            #we need to remove a \" ;\" that is at the end of the infoAccepted matrix\n            rest.strip()\n            temp3 = rest.split('\\n',1)\n            \n            #print(filename)\n            if(i < last_iteration-1):\n                rest = temp3[1]\n            else:\n                break;\n            i = i+1\n            #print('i:')\n            #print(i)\n \n        participant_data.append(one_participant_data)   \nprint(\"we captured a dataset of \" + str(len(participant_data)) + \" participants and \" + str(len(participant_data[0])) + \" trials \") \n        \n#we also read the subjective preferences:\nsubj_pref = pd.read_csv(datapath + '\/data-raw\/explicit_choices.csv')\nsubj_quest = pd.read_csv(datapath + '\/data-raw\/responses_questionnaire.csv')\nprint(\"we loaded subj_pref and subj_quest\")\n#print(subj_quest)\n\n#Creating a new dataframe from the subj_quest, just including preferences\nquest00 = subj_quest[[\"Por favor, ind\u00edquenos su n\u00famero de participante\",\"\u00bfQu\u00e9 prefiere, la configuraci\u00f3n sin cuerpo, o con cuerpo?\", \"\u00bfQu\u00e9 prefiere, el mundo pintado de modo realista, o de dibujo animado?\", \"\u00bfQu\u00e9 prefiere, la configuraci\u00f3n con personajes m\u00e1s pasivos, o m\u00e1s reactivos?\", \"\u00bfQu\u00e9 prefiere, la navegaci\u00f3n con tele-transporte, o imitar el caminar real?\" ]]\nquest01 = quest00.sort_values(\"Por favor, ind\u00edquenos su n\u00famero de participante\")\n#renaming questionnaire columns for easier data manipulation\nquest01 = quest01.rename(index=str, columns={\"\u00bfQu\u00e9 prefiere, la configuraci\u00f3n sin cuerpo, o con cuerpo?\": \"sin cuerpo o cuerpo\", \"\u00bfQu\u00e9 prefiere, el mundo pintado de modo realista, o de dibujo animado?\": \"realista o dibujo\", \"\u00bfQu\u00e9 prefiere, la configuraci\u00f3n con personajes m\u00e1s pasivos, o m\u00e1s reactivos?\" : \"personas pasivos o reactivos\", \"\u00bfQu\u00e9 prefiere, la navegaci\u00f3n con tele-transporte, o imitar el caminar real?\" : \"teleporte o caminar\"})\nquest02 = quest01.drop([\"17\",\"18\",\"23\"])\nquest= quest02.reset_index()","91867a2e":"\n#1. support function to find the indices of our matrices:\n\n#this function changes one 0 to 1, viceversa, or adds a # in case you are not providing a 0 or a 1\ndef _swaponebit(yourString,yourIndexToReplace): #output: string, input: string, int\n    if(yourString[yourIndexToReplace]=='0'):\n        yourStringNew=\"\".join((yourString[:yourIndexToReplace],\"1\",yourString[yourIndexToReplace+1:]))\n    elif(yourString[yourIndexToReplace]=='1'):\n        yourStringNew=\"\".join((yourString[:yourIndexToReplace],\"0\",yourString[yourIndexToReplace+1:]))\n    else:\n        yourStringNew=\"\".join((yourString[:yourIndexToReplace],\"#\",yourString[yourIndexToReplace+1:]))\n    return yourStringNew\n\n\n#a support function: you give an integer between 0 and 15 (which can be expressed in binary with 4 bits), and \n# it returns 4 integers,  each corresponding to a change in one bit in its binary form\ndef _myindices(mystate): #output 4 int, input int\n    indices = np.zeros((4,1),dtype=int)\n    mystatebin = format(mystate, '04b')\n    for charindex in range(len(mystatebin)):\n        #print(charindex)\n        b= mystatebin[charindex]\n        #print(b)\n        #if(b=='0'):\n        temp = _swaponebit(mystatebin,charindex)\n        #print(mystatebin)\n        #print(temp)\n        indices[charindex] = int(temp,2)\n        col=int(temp,2)\n        #print(col)\n            #print(indices)\n    return(indices)\n\n\n\n#2. a script to build the matrix of indices that allows us to move from a Qtable format to a transition matrix format\nstates = range(16)\ns=(16,4)\ntrans_indices = np.zeros(s,dtype=int)\nfor s in states:\n    row = s\n    indicesrow = _myindices(s)\n    trans_indices[s,:]= indicesrow[:,0]\n\n    \n#to recheck manually all makes sense\n#print(\"trans_indices: \")\n#print(trans_indices)\n\n#from Unity debugger:\n#Last State: 7in bin: 0111\n# Proposed State: 3in bin: 0011\n#it fits!\n\n\n# 3. the labels for the data and the plots\nlabels = [\"\" for x in range(16)]\nfor a in range(16):\n    stim_bin = format (a, \"4b\")#this puts in strings of size 4, adding spaces at the beginning if needed\n    if(stim_bin[0]!='1'):\n        labels[a] += 'Tele.'\n    else:\n        labels[a] +=  'Walk.'\n    \n    if(stim_bin[1]!='1'):\n         labels[a] +=  ' - No Body \\n'\n    else:\n        labels[a] +=  ' - Body \\n'\n\n    if(stim_bin[2]!='1'):\n        labels[a] +=  ' - No  Int.'\n    else:\n        labels[a] +=   ' - Int.'\n\n    if(stim_bin[3]!='1'):\n        labels[a] +=  ' - Real'\n    else:\n        labels[a] +=  ' - Toon'\n        \n#print(labels )\n\nlabels2 =   [a.replace(\"\\n\", \"\") for a in labels ]","d10ff110":"# this functions gives the presentation and acceptance matrices from the data, for a fixed participant and iteration.\ndef get_data_matrix(index_participant, iteration):\n    p = participant_data[index_participant]\n    presentedmat = p[iteration][\"infoPres\"]\n    acceptedmat = p[iteration][\"infoAccepted\"]\n    s=(16,4)\n    tmp1 = np.asarray(presentedmat)\n    pmat = np.reshape(tmp1,s)\n    amat = np.reshape(np.asarray(acceptedmat),s)\n    #trans_matrix = np.zeros((16,16),dtype=float)\n    pres_matrix = np.zeros((16,16),dtype=float)\n    acce_matrix = np.zeros((16,16),dtype=float)\n    #the rows are the same, the columns are indicated by the 4 indices in trans_indices:\n    [nrows, ncols] = pres_matrix.shape\n    #the accepted transitions:\n    for j in range(4):\n        for i in range(nrows):\n            c = trans_indices[i,j]\n            #print(c)\n            if(pmat[i,j] != 0):\n                #trans_matrix[i,c] = amat[i,j]*1.0\/pmat[i,j] #i multiply by 1.0 to make sure we have a proper division\n                pres_matrix[i,c] = pmat[i,j]\n                acce_matrix[i,c] = amat[i,j]\n            else: \n                pres_matrix[i,c] = 0\n                acce_matrix[i,c] = 0\n    return [pres_matrix, acce_matrix]    \n\n#to build the probability transition matrix \n# from the total numbers in a configuration and the total  acceptance times:\n# def get_prob_transition_matrix(pres_matrix,acce_matrix):\n#     [nrows, ncols] = pres_matrix.shape\n#     prob_matrix = np.zeros((16,16),dtype=float)\n#     for i in range(nrows):\n#         pres_sum = 0.0;\n#         for j in range(ncols):\n#             pres_sum += pres_matrix[i,j]        \n    \n#         for j in range(ncols):\n#             if( (pres_sum != 0) and (acce_matrix[i,j] != 0) ):\n#                 prob_matrix[i,j]=acce_matrix[i,j] \/pres_sum\n#         prob_sum = 0.0\n#         for j in range(ncols):\n#             prob_sum += prob_matrix[i,j]     \n#         prob_matrix[i,i]= 1.0 - prob_sum\n#     return prob_matrix\n\n#we build the acceptance ratios\ndef get_accept_ratio_matrix(pres_matrix,acce_matrix):\n    [nrows, ncols] = pres_matrix.shape\n    prob_matrix = np.zeros((16,16),dtype=float)\n    for i in range(nrows):\n        for j in range(ncols):\n            if(pres_matrix[i,j] != 0 ):\n                prob_matrix[i,j]=acce_matrix[i,j] \/pres_matrix[i,j]\n        prob_sum = 0.0\n        for j in range(ncols):\n            prob_sum += prob_matrix[i,j]     \n        prob_matrix[i,i]= 1.0 - prob_sum\n    return prob_matrix\n\n\n\n\n\n# 4. we prepare the relevant matrices\nnparticipants=len(participant_data)\nalls_pres = np.zeros((16,16),dtype=float)\nalls_acce = np.zeros((16,16),dtype=float)\n\n# 4.b extra step if we want to save them\n\n\n\n# 5. we build the relevant matrices\n\nfor s in range(nparticipants):\n    [PresM, AcceM] = get_data_matrix(s, last_iteration - 1)\n    alls_pres += PresM\n    alls_acce += AcceM\n\n    \n\n        \n    \n\n\n# alls_prob = get_prob_transition_matrix(alls_pres,alls_acce)\n# print(\"calculated probability transition matrix\")\n\nalls_ratio = get_accept_ratio_matrix(alls_pres,alls_acce)\n\n\n    \n\n","0cf2c8cc":"# #we save it in latex\n# df_prob_matrix4latex = pd.DataFrame(alls_prob,columns=labels2)\n\n# df_prob_matrix4latex = np.round(df_prob_matrix4latex,2)\n# df_prob_matrix4latex.columns = range(16)\n\n\n\n# df_labels = pd.DataFrame(labels2,columns= [\"configurations\"])\n# df_labels[\" \"] = range(16)\n# #df_prob_matrix4latex [\"configurations\"] = labels2\n\n\n# #in paper this is Table 1\n# with open('my_labels_prob_matrix_table.tex', 'w') as myfile:\n#     myfile.write(df_labels.to_latex(index=False))\n\n\n    \n# #in paper this is Table 2\n# with open('my_prob_acce_matrix_table.tex', 'w') as myfile:\n#     #myfile.write(df_prob_matrix4latex.to_latex(index=False))\n#     myfile.write(df_prob_matrix4latex.to_latex(index=True))\n\n# #df_labels","331782ee":"# this functions gives the configuration in which one participant was at a given iteration \ndef get_config(index_participant, iteration):\n    p = participant_data[index_participant]\n    c = p[iteration][\"currentstate\"]\n    return c    \n\nnparticipants=len(participant_data)\n\n\nconfig_lastvisit = np.zeros((16,1))\n\nfor s in range(nparticipants):\n    c = get_config(s, last_iteration - 1)\n    d= int(c,2)\n    config_lastvisit[d,0] +=1 \n#config_lastvisit = config_lastvisit \/  nparticipants\n\n\n# config_5lastvisits = np.zeros((16,1))\n# for s in range(nparticipants):\n#     for a in range(5):\n#         #print(a)\n#         c = get_config(s, last_iteration - 1- a)\n#         d = int(c,2)\n#         config_5lastvisits[d,0] +=1 \n# config_5lastvisits = config_5lastvisits \/  (nparticipants*5)\n\n\n\ndf_last_visit =  pd.DataFrame(config_lastvisit,columns=[\"last visit\"])\n# df_last_visit[\"5last\"] = config_5lastvisits\n#display(df_last_visit)\n\n\n","1c57c006":"#First, some sanity checks\n\n#**How many configurations did they visit?**\n#We use this measure  to make sure they had not made their mind before starting\n\nConfiguration_visits = pd.DataFrame(np.zeros((24,nparticipants)))\n\ntransition_indicators = pd.DataFrame()\n\n\ndistinct_configs = []\nfor experiment_participant in range(nparticipants):\n    \n    configs1part = [] \n    for experiment_step in range(24):\n        config = participant_data[experiment_participant][experiment_step]['currentstate']\n        \n        configs1part.append(config)\n        \n    Configuration_visits[experiment_participant] = configs1part\n    myset = set(configs1part)\n    distinct_configs.append (len(myset))\n\ntransition_indicators['distinct_configs'] = distinct_configs\n\n\n\ntransitions_accepted =[]\nfor experiment_participant in range(nparticipants):\n    configs1part = Configuration_visits[experiment_participant]\n    #display(configs1part)\n    temp = 0\n    for experiment_step in range(24-1):\n        if(configs1part[experiment_step] != (configs1part[experiment_step+1]) ):\n            temp = temp+1\n    transitions_accepted.append(temp)\n    \ntransition_indicators['transitions_accepted'] = transitions_accepted\n\ndisplay(transition_indicators)\n\nif WRITE_DATA:\n    with open('transition_indicators.csv', 'w') as myfile:\n        myfile.write(transition_indicators.to_csv())\n\n        \n#**To show statistically that the results are different from chance**\n#Under the null hypothesis of chance decisions, each vector has a multinomial distribution with p0 = p1 = ... = p15 = #1\/16, and N = 24. For each subject individually we need a vector:\n#(no. of visits to config 0, no. of visits to config. 2, ..., no. of visits to config. 15).\n\n\n\nVisitsPerSubject = pd.DataFrame(np.zeros((16,nparticipants)))\nfor p in range(nparticipants):\n    for v in range(24):\n        #Configuration_visits_int[p][v] = int(str(Configuration_visits[p][v]),2)\n        config = int(str(Configuration_visits[p][v]),2)\n        VisitsPerSubject[p][config] += 1\n        \n#display(Configuration_visits)\n\nVisitsPerSubject.columns = selectedParticipants\n #   VisitsPerSubject[0][p] = int(selectedParticipants[p])\n\n\ndisplay(VisitsPerSubject)\n\nif WRITE_DATA:\n    with open('VisitsPerSubject.csv', 'w') as myfile:\n        myfile.write(VisitsPerSubject.to_csv())\n\n\n        ","d4778199":"\nparticipants = []\n## creating a pandas dataframe for easier data manipulation\nfor i in range(len(selectedParticipants)):\n    if i == 0: participants = pd.DataFrame.from_dict(participant_data[i]) \n    else: participants= participants.append(pd.DataFrame.from_dict(participant_data[i]), ignore_index=True)\n    \n    \ncurrentnum =[] # the list including the real number of the current state\nfor i in range(len(participants[\"currentstate\"])): currentnum.append(int(participants[\"currentstate\"][i], 2))\nparticipants[\"currentstatenumbers\"] = currentnum # appending the list into the dataframe\n\n# in order to count which state has the biggest arc\ncount = Counter(list(zip(participants[\"currentstatenumbers\"])))\ncount ## shows how many times the configurations have repeated\n\n\ncurrentState = participants[\"currentstatenumbers\"].values\n#print ( \"Total number of states: \"+  str(np.size(currentState)))\nsplit_state = np.split(currentState, len(selectedParticipants)) # creating a new list including each participant and their trials with the current state data\n\n\ninitial_state =[] # the beginning states of the participants, the states coming out of nowhere\nfor i in range(len(selectedParticipants)):\n    initial_state.append(split_state[i][0])\n\n\nmatrix = np.zeros((16,16)) # Origin-Destination Matrix, which gives the subarcs of the circle, arrival to one state from another\nfor e in split_state:\n    for state in range(len(e)-1):\n        origin = e[state]\n        destination = e[state+1]\n        matrix[origin][destination] += 1\n#matrix.shape\n\n#print(\"the matrix generated portrays the arrivals to state X. One column states how many people arrived to a given state, and from which state. \")\n","545dbd88":"#we build a dataframe to show whether the number of times they stayed in a given configuration \n#fits with their reported preferences.\n\nglob_pref_count = np.zeros((16,1))\n  \n# the order in subj_pref does not correspond to the order used to define the states. We would need to do:\n#print(subj_pref)\n# subj_pref_reordered = subj_pref[[\"WiP\" \"body\" \"expresssive_chars\" \"toon\"]]    \nfor rowid in selectedParticipants: \n    temp = subj_pref.loc[subj_pref[\"id\"]==int(rowid)]\n    val = temp[\"WiP\"]*8 + temp[\"body\"]*4 + temp[\"expressive_chars\"]*2 + temp[\"toon\"]*1\n    #print(val.values)\n    index = int(val)\n    glob_pref_count[index,0] +=1\n\n\n\n\n        \n    \nmywip = []\nmybody = []\nmycharint = []\nmytoon = []\n\nfor tmp in range(16):\n    mystatebin = format(tmp, '04b')\n    mywip.append(mystatebin[0])\n    mybody.append(mystatebin[1])\n    mycharint.append(mystatebin[2])\n    mytoon.append(mystatebin[3])\n\n#a = pd.DataFrame(labels, columns=[ \"experiment configuration\" ])\n#a = pd.DataFrame([mywip,mybody,mycharint,mytoon], columns=[ \"WiP\",\"body\",\"int_char\",\"toon\" ])\n\na = pd.DataFrame(mywip, columns=[ \"WiP\"])\na [\"body\"]= mybody\na [\"int_char\"]= mycharint\na [\"toon\"]= mytoon\n\n\n\nTotalVisits = np.sum(VisitsPerSubject,1)\n# display(TotalVisits)\n\na[\"visits\"] = TotalVisits\n\na[\"stay_r\"] = np.round( np.divide(np.diagonal(visits),a[\"visits\"]),2)\n\n#b = [str(int(x[0])) + \"\/20\" for x in glob_pref_count]\nb = [str(int(x[0]))  for x in glob_pref_count]\n#a[\"pref_ratio\"] = np.divide(glob_pref_count, 20.0)\na[\"pref_r\"] = b\n\n\n# we generate labels that reflect these counts:\nlabels_with_counts = [\"\"]*len(labels)\n\n##if we wanted the explicit preferences:\n# onall = \"\/\" + str(len(selectedParticipants))\n# for ind in range(len(glob_pref_count)):\n#     labels_with_counts[ind] = labels[ind] + \"\\n \"+ str(int(glob_pref_count[ind,0]))+onall\n\n# print(labels_with_counts)\n\nfor ind in range(len(glob_pref_count)):\n    tmp =   \"{0:.2f}\".format(a[\"stay_r\"][ind]) \n    labels_with_counts[ind] = labels[ind] + \"\\n v:\"+ str(int(a[\"visits\"][ind]))+\" s.r.:\" + tmp\n#print(labels_with_counts)\n\n\n# we sort a and save it:\nsorted_a = a.sort_values(by=['visits'],ascending = False, inplace = False)\n\nif WRITE_DATA:\n    with open('my_pref_table.tex', 'w') as myfile:\n        myfile.write(sorted_a.to_latex(index=True))\n\n# display(sorted_a)\n\n","b5a0227c":"def get_qvals_matrix(index_participant, iteration):\n    p = participant_data[index_participant]\n    qmat0 = p[iteration][\"infoQmat\"]\n    \n    s=(16,4)\n    tmp1 = np.asarray(qmat0)\n    qmat = np.reshape(qmat0,s)\n    \n    q_matrix = np.zeros((16,16),dtype=float)\n    #the rows are the same, the columns are indicated by the 4 indices in trans_indices:\n    [nrows, ncols] = q_matrix.shape\n    #the accepted transitions:\n    for j in range(4):\n        for i in range(nrows):\n            c = trans_indices[i,j]\n            q_matrix[i,c] = qmat[i,j]\n            \n    return q_matrix   ","35c7b6f2":"\n# 4. we build the q-value matrix:\nnparticipants=len(participant_data)\n\n\n#we create:\nAllQvals = np.zeros((16,16))\n\nfor s in range(nparticipants):\n    Qvals = get_qvals_matrix(s, last_iteration-1)  \n    AllQvals += Qvals\n    \n#this is a bit a monstruosity, but...    \n#df = pd.DataFrame(AllQvals, columns=labels2)\n\n#we want to compare these with the preferences of the participants:\n\nall_qvals = pd.DataFrame(np.sum(AllQvals, 1))\nall_qvals.columns = ['RL_score']\n\nall_qvals['order']= range(16)\n\n#all_scores.sort_values(by=['time_score'],ascending = False, inplace = True)\n#all_qvals.sort_values(by=['RL_score'],ascending = True, inplace = True)\n#display(all_qvals)","6562d14d":"\n\nsorted_b = sorted_a\n\n#we add the values of R_vals\nsorted_b['RL_score'] = all_qvals['RL_score'] \n#sorted_b['order_qvals'] = all_qvals['order'] \n\ndf_last_visit[\"last visit2\"] = [int(x)  for x in df_last_visit[\"last visit\"]]\n\nsorted_b['last_visit'] = df_last_visit[\"last visit2\"]\n\nprint(\"Table 4:\")\nsorted_b.sort_values(by=['RL_score'],ascending = True, inplace = True)\ndisplay(sorted_b)\n\n\nif WRITE_DATA:\n    with open('table4.csv', 'w') as myfile:\n        myfile.write(sorted_b.to_csv())\n","73cd81a7":"\nmeasures =  [\"visits\", \"stay_r\",\"RL_score\", \"pref_r\"]\n        \nstats_measures = [\"visits_mean\",\"visits_std\", \"stay_ratio_mean\",\"stay_ratio_std\",\"RL_score_mean\",\"RL_score_std\",\"pref_r_mean\",\"pref_r_std\" ]\nfactors= [ \"WiP\",\"body\",\"int_char\",\"toon\" ]\noptions = [\"0\", \"1\"]\n\ncol = [\"factor\", \"option\"]\nrows = []\nfor f in factors:\n    for o in options:\n        mask = sorted_b[f]== o\n        res = [f, o]\n        for mes in measures:\n            #print(mes)\n            x = ( sorted_b[mes][mask]).astype(float)\n            m = np.mean(x)\n            s = stats.sem(x)\n            res.append(m)\n            res.append(s)\n            \n        #print(res)\n        rows.append(res)\n        \ndf_measures = pd.DataFrame(rows, columns= col+stats_measures);\nprint(\"Table 5:\")\ndisplay(df_measures)","5eb32ba3":"quest = subj_quest[[\"Por favor, ind\u00edquenos su n\u00famero de participante\",\"\u00bfQu\u00e9 prefiere, la configuraci\u00f3n sin cuerpo, o con cuerpo?\", \"\u00bfQu\u00e9 prefiere, el mundo pintado de modo realista, o de dibujo animado?\", \"\u00bfQu\u00e9 prefiere, la configuraci\u00f3n con personajes m\u00e1s pasivos, o m\u00e1s reactivos?\", \"\u00bfQu\u00e9 prefiere, la navegaci\u00f3n con tele-transporte, o imitar el caminar real?\" ]]\n\n#quest.sort_values(\"Por favor, ind\u00edquenos su n\u00famero de participante\", inplace = True)\nquest = quest.sort_values(\"Por favor, ind\u00edquenos su n\u00famero de participante\")\n#renaming questionnaire columns for easier data manipulation\nquest = quest.rename(index=str, columns={\"\u00bfQu\u00e9 prefiere, la configuraci\u00f3n sin cuerpo, o con cuerpo?\": \"sin cuerpo o cuerpo\", \"\u00bfQu\u00e9 prefiere, el mundo pintado de modo realista, o de dibujo animado?\": \"realista o dibujo\", \"\u00bfQu\u00e9 prefiere, la configuraci\u00f3n con personajes m\u00e1s pasivos, o m\u00e1s reactivos?\" : \"personas pasivos o reactivos\", \"\u00bfQu\u00e9 prefiere, la navegaci\u00f3n con tele-transporte, o imitar el caminar real?\" : \"teleporte o caminar\"})\n\n\nquest.drop([\"23\",\"17\",\"16\",\"2\"], inplace = True)\nquest.reset_index(inplace= True)\n\ndisplay(quest)","3946fc0a":"\nquest2= quest.copy()\nquest2.columns = [\"index\", \"part ID\",\"body\", \"toon\", \"soci\", \"WiP\"]\n\n#order of the questions:    \n#mycols = [\"body\", \"toon\", \"soci\", \"WiP\"]\n#tmp= pd.concat(map(quest2.get, mycols))\n\n#q3 = pd.DataFrame(tmp, columns=[\"Questionnaire Score\"])\n\n#al = [\"Full Body\" for x in range(20)]\n#bl = [\"Cartoon Rendering\" for x in range(20)]    \n#cl = [\"Responsive\" for x in range(20)]\n#dl = [\"Walking in Place\" for x in range(20)]\n\n#order used in the data analysis:\nmycols = [ \"WiP\",\"body\",  \"soci\",\"toon\"]\ntmp= pd.concat(map(quest2.get, mycols))\n\nq3 = pd.DataFrame(tmp, columns=[\"Questionnaire Score\"])\n\nal = [\"Walking in Place\" for x in range(20)]\nbl = [\"Full Body\" for x in range(20)]\ncl = [\"Responsive\" for x in range(20)]\ndl = [\"Cartoon Rendering\" for x in range(20)]    \n#Notice: both of previous options display the same result, just in a different order\n\nll = al +bl  +cl+dl\nq3[\" \"] = ll\n\n#pal = \"Set2\";\nsigma = .05;\n\nprint(\"Figure 4:\")\nax=sb.boxplot( x =  \" \", y = \"Questionnaire Score\", data = q3, showcaps = True, boxprops = { },showfliers=True, whiskerprops = {'linewidth':2, \"zorder\":10}, saturation = 1, orient = \"v\")\n\n#if WRITE_DATA:\n    #we save the figure:    \nplt.savefig(\"questionnaire_boxplot.png\", dpi=png_res,\n        transparent=True,\n        bbox_inches='tight', pad_inches=0.02)\n\n\n\n","227e0bd8":"\n#we create:\nRLscore_per_subject = pd.DataFrame(np.zeros((16,nparticipants)))\n\nfor s in range(nparticipants):\n    temp = np.zeros((16,16))\n    temp = get_qvals_matrix(s, last_iteration-1)\n    rl_score_1subj = np.sum(temp, 1)\n    #display(rl_score_1subj)\n    RLscore_per_subject[s]= rl_score_1subj\n    \n#RLscore_per_subject","ba94ae8f":"       \nimport random\n\nimport scipy\nparticipant_sample = 15\nnumber_iterations = 10000\n \ndisplay(\"samples of \"+ str(participant_sample) + \" participants,\"\n    \"we are calculating:\" +\n        str(number_iterations)+ \n        \" combinations of a total of :\" \n        +str (scipy.special.binom(nparticipants, participant_sample)))\n    \n     \nRLscore_per_iteration = pd.DataFrame(np.zeros((16,number_iterations)))\n\n\nfor it in range(number_iterations):\n\n    #we pick a random subset of participants of size number_participants\n    l=list(range(nparticipants))\n    \n    random.shuffle(l)#with this commented all columns must look the same\n    part_subset = l[0:participant_sample]\n\n    \n    #we want to compare these with the preferences of the participants:      \n    sampled_qvals = RLscore_per_subject[part_subset]\n    #sampled_qvals.columns = ['RL_score']\n    rl_score_1col = np.sum(sampled_qvals, 1)\n    RLscore_per_iteration[it] = rl_score_1col;\n    \n    \ndisplay(RLscore_per_iteration)\nif WRITE_DATA:\n    with open('rl_score_per_iteration.csv', 'w') as myfile:\n        myfile.write(RLscore_per_iteration.to_csv())\n","3e63c24a":"\ndemo_data = []\n\n\n\n#we  read the demographics:\nsubj_demographics = pd.read_csv(datapath + '\/data-raw\/responses_demographics.csv')\nsubj_demographics = subj_demographics.loc[subj_demographics[\"Por favor, ind\u00edquenos su n\u00famero de participante\"].isin(selectedParticipants)]\n\n#Creating a new dataframe from the subj_quest, just including preferences\nquest_dem = subj_demographics[[\"Por favor, ind\u00edquenos su n\u00famero de participante\",\"Es usted mujer o hombre?\", \"Edad\",\n                               \"Por favor, indique su nivel de conocimientos en inform\u00e1tica\",\n                               \"Por favor, indique su nivel de conocimientos en programaci\u00f3n inform\u00e1tica\",\n                               \"Ha tenido alguna experiencia con Realidad Virtual anteriormente?\",\"Cu\u00e1ntas horas a la semana juega con videojuegos?\" ]]\n\nquest_dem.columns =[\"ID\",\"gender\",\"age\",\"computer-knowledge\",\"programming-knowledge\",\"VR-experiences\",\"weekly-videogame-hours\"]\nquest_dem[\"gender\"] = quest_dem[\"gender\"].replace(\"Mujer\",\"F\")\nquest_dem[\"gender\"] = quest_dem[\"gender\"].replace(\"Hombre\",\"M\")\n\nquest_dem[\"weekly-videogame-hours\"] = quest_dem[\"weekly-videogame-hours\"].replace(\"entre 5 y 7 horas\",\"between 5 and 7\")\nquest_dem[\"weekly-videogame-hours\"] = quest_dem[\"weekly-videogame-hours\"].replace(\"menos de 2 horas\",\"less than 2 hours\")\n\nquest_dem= quest_dem.reset_index()\n\ndisplay(quest_dem)\n\nprint(\"mean age: \" + str (np.mean(quest_dem[\"age\"])))\nprint(\"std age: \" + str(np.std(quest_dem[\"age\"])))\n\nquest_dem['gender'].value_counts()\n\n\n#display(len(selectedParticipants))","321ee6ff":"\nparticipants = []\n## creating a pandas dataframe for easier data manipulation\nfor i in range(len(selectedParticipants)):\n    if i == 0: participants = pd.DataFrame.from_dict(participant_data[i]) \n    else: participants= participants.append(pd.DataFrame.from_dict(participant_data[i]), ignore_index=True)\n    \n    \ncurrentnum =[] # the list including the real number of the current state\nfor i in range(len(participants[\"currentstate\"])): currentnum.append(int(participants[\"currentstate\"][i], 2))\nparticipants[\"currentstatenumbers\"] = currentnum # appending the list into the dataframe\n\n# in order to count which state has the biggest arc\ncount = Counter(list(zip(participants[\"currentstatenumbers\"])))\ncount ## shows how many times the configurations have repeated\n\n\ncurrentState = participants[\"currentstatenumbers\"].values\n#print ( \"Total number of states: \"+  str(np.size(currentState)))\nsplit_state = np.split(currentState, len(selectedParticipants)) # creating a new list including each participant and their trials with the current state data\n\n\ninitial_state =[] # the beginning states of the participants, the states coming out of nowhere\nfor i in range(len(selectedParticipants)):\n    initial_state.append(split_state[i][0])\n\n\nmatrix = np.zeros((16,16)) # Origin-Destination Matrix, which gives the subarcs of the circle, arrival to one state from another\nfor e in split_state:\n    for state in range(len(e)-1):\n        origin = e[state]\n        destination = e[state+1]\n        matrix[origin][destination] += 1\n#matrix.shape\n\n#print(\"the matrix generated portrays the arrivals to state X. One column states how many people arrived to a given state, and from which state. \")\n","95021cbd":"# chord diagram\n## code is taken from: https:\/\/github.com\/fengwangPhysics\/matplotlib-chord-diagram\/blob\/master\/matplotlib-chord.py\n\n\n# 4 the chord diagram:\nimport holoviews as hv\nfrom holoviews import opts\nfrom bokeh.sampledata.les_mis import data\n\nfrom matplotlib.path import Path\nimport matplotlib.patches as patches\n\nhv.extension('bokeh')\nhv.output(size=200)\n\n\nLW = 0.3\n\ndef polar2xy(r, theta):\n    return np.array([r*np.cos(theta), r*np.sin(theta)])\n\ndef hex2rgb(c):\n    return tuple(int(c[i:i+2], 16)\/256.0 for i in (1, 3 ,5))\n\ndef IdeogramArc(start=0, end=60, radius=1.0, width=0.2, ax=None, color=(1,0,0)):\n    # start, end should be in [0, 360)\n    if start > end:\n        start, end = end, start\n    start *= np.pi\/180.\n    end *= np.pi\/180.\n    # optimal distance to the control points\n    # https:\/\/stackoverflow.com\/questions\/1734745\/how-to-create-circle-with-b%C3%A9zier-curves\n    opt = 4.\/3. * np.tan((end-start)\/ 4.) * radius\n    inner = radius*(1-width)\n    verts = [\n        polar2xy(radius, start),\n        polar2xy(radius, start) + polar2xy(opt, start+0.5*np.pi),\n        polar2xy(radius, end) + polar2xy(opt, end-0.5*np.pi),\n        polar2xy(radius, end),\n        polar2xy(inner, end),\n        polar2xy(inner, end) + polar2xy(opt*(1-width), end-0.5*np.pi),\n        polar2xy(inner, start) + polar2xy(opt*(1-width), start+0.5*np.pi),\n        polar2xy(inner, start),\n        polar2xy(radius, start),\n        ]\n\n    codes = [Path.MOVETO,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.LINETO,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CLOSEPOLY,\n             ]\n\n    if ax == None:\n        return verts, codes\n    else:\n        path = Path(verts, codes)\n        patch = patches.PathPatch(path, facecolor=color+(0.5,), edgecolor=color+(0.4,), lw=LW)\n        ax.add_patch(patch)\n\n\ndef ChordArc(start1=0, end1=60, start2=180, end2=240, radius=1.0, chordwidth=0.7, ax=None, color=(1,0,0)):\n    # start, end should be in [0, 360)\n    if start1 > end1:\n        start1, end1 = end1, start1\n    if start2 > end2:\n        start2, end2 = end2, start2\n    start1 *= np.pi\/180.\n    end1 *= np.pi\/180.\n    start2 *= np.pi\/180.\n    end2 *= np.pi\/180.\n    opt1 = 4.\/3. * np.tan((end1-start1)\/ 4.) * radius\n    opt2 = 4.\/3. * np.tan((end2-start2)\/ 4.) * radius\n    rchord = radius * (1-chordwidth)\n    verts = [\n        polar2xy(radius, start1),\n        polar2xy(radius, start1) + polar2xy(opt1, start1+0.5*np.pi),\n        polar2xy(radius, end1) + polar2xy(opt1, end1-0.5*np.pi),\n        polar2xy(radius, end1),\n        polar2xy(rchord, end1),\n        polar2xy(rchord, start2),\n        polar2xy(radius, start2),\n        polar2xy(radius, start2) + polar2xy(opt2, start2+0.5*np.pi),\n        polar2xy(radius, end2) + polar2xy(opt2, end2-0.5*np.pi),\n        polar2xy(radius, end2),\n        polar2xy(rchord, end2),\n        polar2xy(rchord, start1),\n        polar2xy(radius, start1),\n        ]\n\n    codes = [Path.MOVETO,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             ]\n\n    if ax == None:\n        return verts, codes\n    else:\n        path = Path(verts, codes)\n        patch = patches.PathPatch(path, facecolor=color+(0.5,), edgecolor=color+(0.4,), lw=LW)\n        ax.add_patch(patch)\n\ndef selfChordArc(start=0, end=60, radius=1.0, chordwidth=0.7, ax=None, color=(1,0,0)):\n    # start, end should be in [0, 360)\n    if start > end:\n        start, end = end, start\n    start *= np.pi\/180.\n    end *= np.pi\/180.\n    opt = 4.\/3. * np.tan((end-start)\/ 4.) * radius\n    rchord = radius * (1-chordwidth)\n    verts = [\n        polar2xy(radius, start),\n        polar2xy(radius, start) + polar2xy(opt, start+0.5*np.pi),\n        polar2xy(radius, end) + polar2xy(opt, end-0.5*np.pi),\n        polar2xy(radius, end),\n        polar2xy(rchord, end),\n        polar2xy(rchord, start),\n        polar2xy(radius, start),\n        ]\n\n    codes = [Path.MOVETO,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             Path.CURVE4,\n             ]\n\n    if ax == None:\n        return verts, codes\n    else:\n        path = Path(verts, codes)\n        patch = patches.PathPatch(path, facecolor=color+(0.5,), edgecolor=color+(0.4,), lw=LW)\n        ax.add_patch(patch)\n\ndef chordDiagram(X, ax, colors=None, width=0.1, pad=2, chordwidth=0.7):\n    \"\"\"Plot a chord diagram\n    Parameters\n    ----------\n    X :\n        flux data, X[i, j] is the flux from i to j\n    ax :\n        matplotlib `axes` to show the plot\n    colors : optional\n        user defined colors in rgb format. Use function hex2rgb() to convert hex color to rgb color. Default: d3.js category10\n    width : optional\n        width\/thickness of the ideogram arc\n    pad : optional\n        gap pad between two neighboring ideogram arcs, unit: degree, default: 2 degree\n    chordwidth : optional\n        position of the control points for the chords, controlling the shape of the chords\n    \"\"\"\n    # X[i, j]:  i -> j\n    x = X.sum(axis = 1) # sum over rows\n    ax.set_xlim(-1.1, 1.1)\n    ax.set_ylim(-1.1, 1.1)\n\n    if colors is None:\n    # use d3.js category10 https:\/\/github.com\/d3\/d3-3.x-api-reference\/blob\/master\/Ordinal-Scales.md#category10\n        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n          '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf','#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n          '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n        #if len(x) > 10:\n            #print('x is too large! Use x smaller than 10')\n        colors = [hex2rgb(colors[i]) for i in range(len(x))]\n\n    # find position for each start and end\n    y = x\/np.sum(x).astype(float) * (360 - pad*len(x))\n\n    pos = {}\n    arc = []\n    nodePos = []\n    start = 0\n    for i in range(len(x)):\n        end = start + y[i]\n        arc.append((start, end))\n        angle = 0.5*(start+end)\n        #print(start, end, angle)\n        if -30 <= angle <= 210:\n            angle -= 90\n        else:\n            angle -= 270\n        nodePos.append(tuple(polar2xy(1.1, 0.5*(start+end)*np.pi\/180.)) + (angle,))\n        z = (X[i, :]\/x[i].astype(float)) * (end - start)\n        ids = np.argsort(z)\n        z0 = start\n        for j in ids:\n            pos[(i, j)] = (z0, z0+z[j])\n            z0 += z[j]\n        start = end + pad\n\n    for i in range(len(x)):\n        start, end = arc[i]\n        IdeogramArc(start=start, end=end, radius=1.0, ax=ax, color=colors[i], width=width)\n        start, end = pos[(i,i)]\n        selfChordArc(start, end, radius=1.-width, color=colors[i], chordwidth=chordwidth*0.7, ax=ax)\n        for j in range(i):\n            color = colors[i]\n            if X[i, j] > X[j, i]:\n                color = colors[j]\n            start1, end1 = pos[(i,j)]\n            start2, end2 = pos[(j,i)]\n            ChordArc(start1, end1, start2, end2,\n                     radius=1.-width, color=colors[i], chordwidth=chordwidth, ax=ax)\n\n    #print(nodePos)\n    return nodePos\n\n\n\n#we build the graph\n\n\n#we remove conf\u0131gurat\u0131on 9 from the matrix\nlist_a = []\nlist_b = []\nf = 0\nfor row in matrix:\n    if f == 9:\n        f+=1\n        pass\n    else:\n        for i in range(len(row)):\n            if i != 9:\n                list_a.append(row[i])\n\n        list_b.append(list_a)\n        list_a = []\n        f += 1\nmatrix_c = np.stack(list_b)\n\n\nfig = plt.figure(figsize=(12,12))\nax = plt.axes([0,0,1,1])\n\n\n#we take our label names\nnodes = labels_with_counts\n\n\n#we draw\nnodePos = chordDiagram(matrix, ax)\nax.axis('off')\nprop = dict(fontsize=16, ha='center', va='center')\n\nextrarot =0\nextrax = 0\nextray = 0\nfor i in range(matrix.shape[0]):\n    if(i<6):\n        extrarot = 90\n    else:\n        extrarot = -90\n    extraradius = 1.05   \n    ax.text(extraradius*nodePos[i][0], extraradius*nodePos[i][1], nodes[i], rotation=nodePos[i][2]+extrarot, **prop)\n\n    \nif WRITE_DATA:\n    #we save the figure:    \n    plt.savefig(\"chord_diagram.png\", dpi=png_res,\n            transparent=True,\n            bbox_inches='tight', pad_inches=0.02)\n\n","2138dbaf":"number_iterations =  int(last_iteration\/2)\n# number_iterations =  int(last_iteration*3\/4)\n#number_iterations =  last_iteration-1 #this gives the same result than in table 4\n\n\nrl_half = pd.DataFrame(mywip, columns=[ \"WiP\"])\nrl_half [\"body\"]= mybody\nrl_half [\"int_char\"]= mycharint\nrl_half [\"toon\"]= mytoon\n\n\n#we create:\nAllQvals = np.zeros((16,16))\n\nfor s in range(nparticipants):\n    Qvals = get_qvals_matrix(s, number_iterations)  \n    AllQvals += Qvals\n    \n#we want to compare these with the preferences of the participants:\n\nRLscores = pd.DataFrame(np.sum(AllQvals, 1))\nRLscores.columns = ['RL_score']\n\n\nrl_half['RL_score'] = RLscores['RL_score']\n\nrl_half.sort_values(by=['RL_score'],ascending = True, inplace = True)\n\ndisplay(rl_half)\n","ef5e9b3f":"Functions to calculate preferences over global configurations","aac5829a":"This section visualizes the transitions presented and accepted in the form of a chord diagram. It uses code adapted from: https:\/\/github.com\/fengwangPhysics\/matplotlib-chord-diagram\/blob\/master\/matplotlib-chord.py , as implemented by Feng Wang (https:\/\/fengwangphysics.github.io\/)","9160d3a5":"\n**S3: The Chord diagram**\n\nchord diagram showing number of visits and stay ratio in a more compact way \n","4cbc01be":"**We process Reinforcement Learning Data to know about global user preferences**","a8de0095":"**Mean and Standard error of each measure: **","34677fdc":"To find out the number of times they ended up in one configuration","d9babb0d":"## 2. Support functions\n\nWe introduce some functions useful for all the matrices that we will calculate","e162dea4":"**Subjective questionnaire**","b6ce6aa8":"## 1. Data parsing\n\nThis section introduces the main data parser. The data parser works iteratively. It gets the data of all participants, one by one, and stores it in the format:\n\n     data[participant_num][iteration][dictionary_key]","4b9c009a":"**Sample Size**\n\nWe consider the sensitivity of the results to the number of subjects","0e484112":"**S4: the RL scores calculated with half the iterations:**\n\nThe same scores tha twe got in table 4, but calculated only with half the iterations","51ca260e":"## 0. Setup","5d20a076":"# Evaluating Participant Responses to a Virtual Reality Experience Using Reinforcement Learning \nThis notebook is a supplementary material of the article submitted \n\n\n*Evaluating Participant Responses to a Virtual Reality Experience Using Reinforcement Learning*\n\nby Joan Llobera Alejandro Beacco, Ramon Oliva, Gizem \u015eenel, Domna Banakou and Mel Slater\n\n\n \nIt contains the scripts to run the data analysis reported in this article, as well as the links to the data needed to do so.\nThis notebook is organized in different sections:\n0. **Setup** We import dependencies and visualization scripts.\n1. **Data parsing**\nThis section contains the data parser. It also imports the data files.\n2. **Functions for Data Extraction**\nTools to extract different measures\n3. **Results** \nWe generate the tables and figures that are in the results section\n\n4. **Supplementary materials**\n\nAs additional materials, we generate the following tables and figures:\n - S1: demographics data\n - S2: chord diagram showing number of visits and stay ratio in a more compact way \n - S3: the RL scores that we get with half the iterations, to show how the method is robust to a shorter experiment\n \n\n","d13e2a5b":"## 4. Supplementary materials\n\nAs additional materials, we generate the following tables and figures:\n - S2: demographics data\n - S3: chord diagram showing number of visits and stay ratio in a more compact way \n - S4: the main results with half the iterations, to show how the method is robust to a shorter experiment","2e487bb1":"**S2: a table with demographics table**","befaa9a9":" If we wanted  to save it in latex form","51551144":"## 3. Preferences over global configurations"}}