{"cell_type":{"53fd5e47":"code","71e6a47e":"code","43934f28":"code","00c003b7":"code","bbbd6824":"code","90b1892e":"code","4f860ee7":"code","12e0dcfb":"code","a4339fb9":"code","d039a810":"code","f61303a9":"code","fc958e12":"code","9849ab03":"code","c0fcd4a0":"code","36716307":"code","fe06bc14":"code","9797818f":"code","8a1bb339":"code","9d561555":"code","0c0da4c9":"code","76e164ae":"code","3000abb6":"code","f7293fb8":"code","eeccc9a6":"code","fcd10cc6":"code","14111320":"code","ad7ab585":"code","e69068ab":"code","f72be8b6":"code","0e78f7b7":"code","d705eacb":"markdown","851ebb91":"markdown","073420d3":"markdown","e7f393ac":"markdown","bd17fb5f":"markdown","4f816160":"markdown","ed257b46":"markdown","8c7f9d72":"markdown","3581f653":"markdown","f20798e7":"markdown","ecef3881":"markdown","6c41d539":"markdown","ebe33c2f":"markdown","e8130829":"markdown","e20e0926":"markdown","dca932a8":"markdown","acee1a5a":"markdown","c007cfb1":"markdown"},"source":{"53fd5e47":"#sklearn\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\nfrom sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n\n#load package\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#from math import sqrt\nimport seaborn as sns\n","71e6a47e":"## Read in file\ntrain_original = pd.read_csv('..\/input\/train.csv')\ntest_original = pd.read_csv('..\/input\/test.csv')\n\ntotal = [train_original,test_original]","43934f28":"train_original.sample(2)\ntest_original.sample(2)","00c003b7":"#Retrive the salutation from 'Name' column\nfor dataset in total:\n    dataset['Salutation'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)   \n    \npd.crosstab(train_original['Salutation'], train_original['Sex'])\npd.crosstab(test_original['Salutation'], test_original['Sex'])\n    ","bbbd6824":"for dataset in total:\n    dataset['Salutation'] = dataset['Salutation'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Salutation'] = dataset['Salutation'].replace('Mlle', 'Miss')\n    dataset['Salutation'] = dataset['Salutation'].replace('Ms', 'Miss')\n    dataset['Salutation'] = dataset['Salutation'].replace('Mme', 'Mrs')\n    dataset['Salutation'] = pd.factorize(dataset['Salutation'])[0] #label encoding","90b1892e":"pd.crosstab(train_original['Salutation'], train_original['Sex'])\n# pd.crosstab(test_original['Salutation'], test_original['Sex'])","4f860ee7":"#clean unused variable\ntrain=train_original.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\ntest=test_original.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\ntotal = [train,test]\n\ntrain.shape, test.shape","12e0dcfb":"#Detect the missing data in 'train' dataset\ntrain.isnull().sum()","a4339fb9":"## Create function to replace missing data with the median value\ndef fill_missing_age(dataset):\n    dataset['Age']=dataset['Age'].fillna(dataset['Age'].mean())\n    return dataset\n\nfill_missing_age(train)","d039a810":"## Embarked missing cases \ntrain[train['Embarked'].isnull()]\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna('C')","f61303a9":"#apply the missing age method to test dataset\ntest = fill_missing_age(test)","fc958e12":"#filling the missing 'Fare' data with the  median\ndef fill_missing_fare(dataset):\n    median_fare=dataset[(dataset[\"Pclass\"]==3) & (dataset[\"Embarked\"]==\"S\")][\"Fare\"].median()\n    dataset[\"Fare\"]=dataset[\"Fare\"].fillna(median_fare)\n    return dataset\n\ntest = fill_missing_fare(test)","9849ab03":"## Re-Check for missing data\ntrain.isnull().any()\n## Re-Check for missing data\ntest.isnull().any()\n","c0fcd4a0":"for dataset in total:\n    dataset.loc[dataset[\"Age\"] <= 9, \"Age\"] = 0\n    dataset.loc[(dataset[\"Age\"] > 9) & (dataset[\"Age\"] <= 19), \"Age\"] = 1\n    dataset.loc[(dataset[\"Age\"] > 19) & (dataset[\"Age\"] <= 29), \"Age\"] = 2\n    dataset.loc[(dataset[\"Age\"] > 29) & (dataset[\"Age\"] <= 39), \"Age\"] = 3\n    dataset.loc[(dataset[\"Age\"] > 29) & (dataset[\"Age\"] <= 39), \"Age\"] = 3\n    dataset.loc[dataset[\"Age\"] > 39, \"Age\"] = 4\n","36716307":"for dataset in total:\n    dataset.loc[dataset[\"Fare\"] <= 7.75, \"Fare\"] = 0\n    dataset.loc[(dataset[\"Fare\"] > 7.75) & (dataset[\"Fare\"] <= 7.91), \"Fare\"] = 1\n    dataset.loc[(dataset[\"Fare\"] > 7.91) & (dataset[\"Fare\"] <= 9.841), \"Fare\"] = 2\n    dataset.loc[(dataset[\"Fare\"] > 9.841) & (dataset[\"Fare\"] <= 14.454), \"Fare\"] = 3   \n    dataset.loc[(dataset[\"Fare\"] > 14.454) & (dataset[\"Fare\"] <= 24.479), \"Fare\"] = 4\n    dataset.loc[(dataset[\"Fare\"] >24.479) & (dataset[\"Fare\"] <= 31), \"Fare\"] = 5   \n    dataset.loc[(dataset[\"Fare\"] > 31) & (dataset[\"Fare\"] <= 69.487), \"Fare\"] = 6\n    dataset.loc[dataset[\"Fare\"] > 69.487, \"Fare\"] = 7","fe06bc14":"for dataset in total:\n    dataset['Sex'] = pd.factorize(dataset['Sex'])[0]\n    dataset['Embarked']= pd.factorize(dataset['Embarked'])[0]\ntrain.head()","9797818f":"#correlation map\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","8a1bb339":"x = train.drop(\"Survived\", axis=1)\ny = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.25,random_state=1)","9d561555":"\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model. RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier()\n   \n    \n    ]","0c0da4c9":"MLA_columns = []\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n\nrow_index = 0\nfor alg in MLA:\n    \n    \n    predicted = alg.fit(x_train, y_train).predict(x_test)\n    fp, tp, th = roc_curve(y_test, predicted)\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index,'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(alg.score(x_train, y_train), 4)\n    MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round(alg.score(x_test, y_test), 4)\n    MLA_compare.loc[row_index, 'MLA Precission'] = precision_score(y_test, predicted)\n    MLA_compare.loc[row_index, 'MLA Recall'] = recall_score(y_test, predicted)\n    MLA_compare.loc[row_index, 'MLA AUC'] = auc(fp, tp)\n\n\n\n\n\n    row_index+=1\n    \nMLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)    \nMLA_compare","76e164ae":"plt.subplots(figsize=(15,6))\nsns.barplot(x=\"MLA Name\", y=\"MLA Train Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('MLA Train Accuracy Comparison')\nplt.show()\n\n","3000abb6":"plt.subplots(figsize=(15,6))\nsns.barplot(x=\"MLA Name\", y=\"MLA Test Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\nplt.xticks(rotation=90)\nplt.title('MLA Test Accuracy Comparison')\nplt.show()","f7293fb8":"index = 1\nfor alg in MLA:\n    \n    \n    predicted = alg.fit(x_train, y_train).predict(x_test)\n    fp, tp, th = roc_curve(y_test, predicted)\n    roc_auc_mla = auc(fp, tp)\n    MLA_name = alg.__class__.__name__\n    plt.plot(fp, tp, lw=2, alpha=0.3, label='ROC %s (AUC = %0.2f)'  % (MLA_name, roc_auc_mla))\n   \n    index+=1\n\nplt.title('ROC Curve comparison')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')    \nplt.show()","eeccc9a6":"tunealg = ensemble.ExtraTreesClassifier() #Select the algorithm to be tuned\ntunealg.fit(x_train, y_train)\n\nprint('BEFORE tuning Parameters: ', tunealg.get_params())\nprint(\"BEFORE tuning Training w\/bin set score: {:.2f}\". format(tunealg.score(x_train, y_train))) \nprint(\"BEFORE tuning Test w\/bin set score: {:.2f}\". format(tunealg.score(x_test, y_test)))\nprint('-'*10)","fcd10cc6":"#tune parameters\nparam_grid = {#'bootstrap': [True, False],\n              'class_weight': ['balanced' , None],\n              #'max_depth': [1, 2,3,4, None],\n              #'max_features': ['log2', 'auto'],\n              #'max_leaf_nodes': [0,1,2,3,4, None],\n              #'min_impurity_decrease': [True, False, None],\n              #'min_impurity_split': [True, False],\n              #'min_samples_leaf': [1, 2,3,4,5],\n              #'min_samples_split': [1,2,3,4,5],\n              #'min_weight_fraction_leaf': [0.0,1.0,2.0,3.0,4.0,5.0], \n              #'n_estimators': [10,15,25,35,45], \n              'n_jobs':  [1,2,3,4,5], \n              #'oob_score': [True, False], \n              'random_state': [0,1, 2,3,4, None], \n              #'verbose': [0,1, 2,3,4, 5], \n              'warm_start': [True, False]\n             }\n# So, what this GridSearchCV function do is finding the best combination of parameters value that is set above.\ntune_model = model_selection.GridSearchCV(linear_model.PassiveAggressiveClassifier(), param_grid=param_grid, scoring = 'roc_auc')\ntune_model.fit (x_train, y_train)\n\nprint('AFTER tuning Parameters: ', tune_model.best_params_)\nprint(\"AFTER tuning Training w\/bin set score: {:.2f}\". format(tune_model.score(x_train, y_train))) \nprint(\"AFTER tuning Test w\/bin set score: {:.2f}\". format(tune_model.score(x_test, y_test)))\nprint('-'*10)","14111320":"test_pred = tune_model.predict(test)\n","ad7ab585":"len(test_pred)","e69068ab":"test_submission = pd.DataFrame({'PassengerId':test_original['PassengerId'],'Survived':test_pred})\ntest_submission.sample(5)\n\n\n","f72be8b6":"test_submission.to_csv(\"test_submission.csv\",index=False)","0e78f7b7":"test_submission.shape","d705eacb":"Checking the correlation between features","851ebb91":"Will try to create ml models and compare them to choose the best .\n\nSteps involved:\n\n1. Load the library and data\n2. Data cleaning\n3. Data spliting\n4. Training,testing, and Peformance comparison\n5. Tuning the algorithm","073420d3":"Performance Comparison.\n\nList of Machine Learning Algorithm (MLA) used","e7f393ac":"Data Cleaning\nRetrive the salutation and Eliminating unused variable","bd17fb5f":"'Salutation' variable can be retrieved from 'Name' column by taking the string between space string and '.' string","4f816160":"Detect and fill the missing data","ed257b46":"Re-Check for missing data","8c7f9d72":"Spliting the data\nSeperate input features from target feature","3581f653":"discretize Age feature","f20798e7":"The next step is deleting column that will not be used in our models.","ecef3881":"As it is shown above, there are 2 columns which have missing data. the way I'm handling missing 'Age' column is by filling them by the median of age in every passenger class. there are only two data missing in 'Embarked' column. Considering Sex=female and Fare=80, Ports of Embarkation (Embarked) for two missing cases can be assumed to be Cherbourg (C).","6c41d539":"Load the data","ebe33c2f":"afterward, 'Salutation' column should be factorized to be fit in our future model","e8130829":"Detecting the missing data in 'test' dataset is done to get the insight which column consist missing data. as it is shown below, there are 2 column which have missing value. they are 'Age' and 'Fare' column. The same function is used in order to filled the missing 'Age' value. missing 'Fare' value is filled by finding the median of 'Fare' value in the 'Pclass' = 3 and 'Embarked' = S.","e20e0926":"Discretize Fare","dca932a8":"Factorizing 2 of the column whic are 'Sex' and 'Embarked'","acee1a5a":"Load the library and data","c007cfb1":"Train the data into the model and calculate the performance"}}