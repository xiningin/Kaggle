{"cell_type":{"5231ef7b":"code","73d72d2d":"code","a7f302e7":"code","cee541d2":"code","ffbdc190":"code","bf93693e":"code","1551924b":"code","367d9e3f":"code","fbf6b0d9":"code","a74b8bad":"code","27d48f85":"code","194662dc":"code","2efe2a9b":"code","6f336c63":"code","b2ec3109":"code","db8ca3fa":"code","0297292e":"code","cfdfaeb1":"code","1fafb17d":"code","7a140bcf":"code","a4503a24":"code","861b1ad4":"code","321da3cd":"code","500f125b":"code","c4938bdb":"code","bacc85b1":"code","b96b4237":"code","2c6a4948":"code","bfd1c941":"code","5e607753":"code","543620f1":"code","ff942d54":"markdown","a7d27a33":"markdown"},"source":{"5231ef7b":"import numpy as np\nimport os\nimport datetime\nimport time\nimport pandas as pd\nfrom PIL import Image\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\nimport seaborn as sn\nimport re\nimport tensorflow as tf\nimport tensorflow.keras.preprocessing as pp\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\nimport tensorflow_addons as tfa\nfrom imgaug import augmenters as iaa\n\nfrom skimage import transform\n%config IPCompleter.greedy = True\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\npd.set_option('mode.chained_assignment', None)\nsn.set(font_scale=1.5)","73d72d2d":"print(tf.__version__)","a7f302e7":"RANDOM_STATE=42","cee541d2":"test = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\ntrain = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')","ffbdc190":"train.head()","bf93693e":"test.head()","1551924b":"test.shape","367d9e3f":"train.shape","fbf6b0d9":"y_train = train['label']\nX_train = train.drop('label',axis=1).values\n\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=.2, random_state = RANDOM_STATE)\n\n\ny_test = test['label']\nX_test = test.drop('label',axis=1).values\n","a74b8bad":"RANDOM_STATE = 75\n\ndef random_seed(seed):\n    random.seed(RANDOM_STATE)\n    os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n    np.random.seed(RANDOM_STATE)\n    tf.random.set_seed(RANDOM_STATE)","27d48f85":"def show_image(image):\n    plt.rcParams[\"axes.grid\"] = False\n    plt.axis('off')\n    plt.imshow(image)   \n    plt.show()","194662dc":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nEPOCHS=50\nSHUFFLE_BUFFER_SIZE=5000 \nBATCH_SIZE=64","2efe2a9b":"@tf.function\ndef reshape(image, label):\n    return tf.reshape(image,(28,28,1)),label","6f336c63":"@tf.function\ndef normalize(image, label):\n    image = tf.cast(image, tf.float32)\n    return image\/255.0, label","b2ec3109":"@tf.function\ndef rotate_tf(image):\n    #https:\/\/github.com\/tensorflow\/tensorflow\/issues\/30112#issuecomment-549330939\n    random_angles = tf.random.uniform(shape = (), minval = -np\n    .pi \/ 15, maxval = np.pi \/ 15)\n    return tfa.image.rotate(image,random_angles)","db8ca3fa":"@tf.function\ndef translate_tf(image):\n    ratio=tf.random.uniform((2,), minval=-2, maxval=2, dtype=tf.dtypes.int32)\n    ratio=tf.cast(ratio, tf.dtypes.float32)\n    return tfa.image.translate(image, ratio,'BILINEAR')","0297292e":"@tf.function\ndef augment_cutout(image):\n    image = tf.expand_dims(image, 0)\n    image = tfa.image.random_cutout(image, (5,5), constant_values = 0)\n    return tf.squeeze(image,[0])","cfdfaeb1":"@tf.function\ndef augment(image, label):\n    random= tf.random.uniform((1,), minval=0, maxval=5, dtype=tf.dtypes.int32)\n    if random==0:\n        image = rotate_tf(image)\n    elif random==1:\n        image = translate_tf(image)\n    elif random == 2:\n        image = tf.image.flip_left_right(image)\n    elif random == 3:\n        image = augment_cutout(image)\n    return image, label","1fafb17d":"def get_data_set(images, labels, is_training=False):\n    dataset = tf.data.Dataset.from_tensor_slices((images,labels))\n    dataset = dataset.map(reshape, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(normalize, num_parallel_calls=AUTOTUNE)\n    \n#     if is_training:\n#         dataset = dataset.map(augment, num_parallel_calls=AUTOTUNE)\n    if is_training:    \n        dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE)\n        dataset = dataset.map(augment, num_parallel_calls=AUTOTUNE)\n    else:\n        dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE)\n        \n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","7a140bcf":"train_dataset = get_data_set(X_train, y_train, is_training=True)\nval_dataset = get_data_set(X_validation,y_validation)\n\ntest_dataset = get_data_set(X_test,y_test)\n\nsample_x, sample_y = next(iter(train_dataset))\nprint(sample_x.shape) \nprint(sample_y.shape) ","a4503a24":"show_image(sample_x[0][:,:,0])","861b1ad4":"class CNNBlock(layers.Layer):\n    def __init__(self, out_channel, kernel_size=3, dropout=None):\n        super(CNNBlock,self).__init__()\n        self.conv = layers.Conv2D(out_channel, kernel_size,kernel_initializer='he_normal', padding=\"same\")\n        self.bn = layers.BatchNormalization()\n        self.maxpool = layers.MaxPool2D(pool_size=(2,2))\n        self.dropout=None\n        if dropout:\n            self.dropout = layers.Dropout(dropout)\n    \n    def call(self, input_tensor, training=False):\n        x = self.conv(input_tensor)\n        x = self.bn(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.maxpool(x)\n        if self.dropout:\n            x = self.dropout(x)\n        return x    ","321da3cd":"\nfrom tensorflow.python.keras.engine.input_spec import InputSpec\nfrom tensorflow.python.keras.engine.base_preprocessing_layer import PreprocessingLayer\nfrom tensorflow.python.keras.utils import tf_utils\n\nclass RandomCutout(PreprocessingLayer):\n\n    def __init__(self, mask, seed=None, name=None, **kwargs):\n        self.mask = mask\n        if isinstance(mask, (tuple, list)):\n            self.lower = mask[0]\n            self.upper = mask[1]\n            \n        else:\n            raise ValueError('RandomCutout layer {name} received an invalid mask '\n                       'argument {arg}. only list or touple of size 2 should be passed'.format(name=name, arg=mask))\n\n        self.seed = seed\n        self.input_spec = InputSpec(ndim=4)\n        super(RandomCutout, self).__init__(name=name, **kwargs)\n\n    def call(self, inputs, training=True):\n        if training is None:\n            training = K.learning_phase()\n\n        def random_cutout_inputs():\n            return tfa.image.random_cutout(inputs, (self.lower, self.upper), constant_values = 0)\n\n        output = tf_utils.smart_cond(training, random_cutout_inputs,\n                                              lambda: inputs)\n        output.set_shape(inputs.shape)\n        return output\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n    def get_config(self):\n        config = {\n            'mask': self.mask,\n            'seed': self.seed,\n        }\n        \n        base_config = super(RandomCutout, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","500f125b":"from tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.experimental import CosineDecay\n# https:\/\/www.tensorflow.org\/guide\/keras\/train_and_evaluate\ndef get_uncompiled_model():\n    img_augmentation = tf.keras.Sequential(\n        [\n            layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2),\n            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n            layers.experimental.preprocessing.RandomRotation(0.15),\n            #layers.experimental.preprocessing.RandomZoom((-0.15, 0.15)),\n            RandomCutout(mask=(4,4)),\n        ],\n        name=\"img_augmentation\",\n    )\n    \n    model = keras.Sequential(\n     [\n      #img_augmentation, \n      CNNBlock(32), \n      CNNBlock(64,dropout=.1), \n      CNNBlock(128, dropout=.1), \n      CNNBlock(256, dropout=.1), \n      layers.Flatten(), \n      layers.Dense(128, activation = \"relu\"),\n      layers.Dropout(.3), \n      layers.Dense(10)]\n)\n    return model","c4938bdb":"def get_compiled_model():\n    model = get_uncompiled_model()\n    decay_steps = int(round(len(X_train)\/BATCH_SIZE)) * EPOCHS\n    \n    cosine_decay = CosineDecay(initial_learning_rate=0.0001, decay_steps=decay_steps, alpha=0.3)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(cosine_decay),\n        loss=[keras.losses.SparseCategoricalCrossentropy(from_logits=True),],\n        metrics=[\"accuracy\"],\n    )\n    return model","bacc85b1":"model = get_compiled_model()","b96b4237":"\nfilepath = 'model.h5'\ncheckpoint=tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='min')\n#early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\ncallbacks_list = [checkpoint]\nhistory = model.fit(train_dataset, epochs=EPOCHS, verbose=1,validation_data=val_dataset,callbacks=callbacks_list).history","2c6a4948":"model.summary()","bfd1c941":"fig_size=(15,8)\nsn.set(rc={'figure.figsize':fig_size})\nplt.figure()\nplt.ylabel(\"Loss (training and validation)\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,2])\nplt.plot(history[\"loss\"])\nplt.plot(history[\"val_loss\"])\n\nplt.figure()\nplt.ylabel(\"Accuracy (training and validation)\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,1])\nplt.plot(history[\"accuracy\"])\nplt.plot(history[\"val_accuracy\"])\n","5e607753":"model.load_weights('model.h5')","543620f1":"print(\"Evaluate on test data\")\nresults = model.evaluate(test_dataset, batch_size=128)\nprint(\"test loss, test acc:\", results)\n","ff942d54":"## Model","a7d27a33":"## This notebook features Tensorflow **tf.data API** and **custom Keras classes** for the model. \n>\n92.2%+ accuracy\n\n***If You like it please upvote :)***"}}