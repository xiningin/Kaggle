{"cell_type":{"e45547b9":"code","bbfcd1ce":"code","f19ba09c":"code","aec05802":"code","d9cf8d21":"code","d10f8084":"code","1aaf4088":"code","73503e91":"code","1ef48eff":"code","7f80180c":"code","07c5fd17":"code","73489bf9":"code","4b180507":"code","99185a3d":"code","6827e7b9":"code","20d63422":"code","d1c037e6":"code","20f6945e":"code","aaa1a37c":"code","4b630657":"markdown","a6b58f4d":"markdown","bf2ef261":"markdown","2c2b0a9b":"markdown","23ccbcb3":"markdown","e935821d":"markdown","b31d7649":"markdown","8bd62523":"markdown","a15cf1e0":"markdown","8ccd3a59":"markdown"},"source":{"e45547b9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import backend as K\nimport pickle\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os","bbfcd1ce":"# Load the training data into a DataFrame named 'train'. \n# Print the shape of the resulting DataFrame. \n\n\ntrain = pd.read_csv(f'..\/input\/histopathologic-cancer-detection\/train_labels.csv', dtype=str)\n\nprint('Training Set Size:', train.shape)\n\ntrain.head()","f19ba09c":"#The id in the csv file does not have .tif extension, let's add it.\ntrain['id'] = train['id'].apply(lambda x: f'{x}.tif')\ntrain.head()","aec05802":"(train.label.value_counts() \/ len(train)).to_frame().sort_index().T","d9cf8d21":"train_path = \"..\/input\/histopathologic-cancer-detection\/train\"\nprint('Training Images:', len(os.listdir(train_path)))\n\nsample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(8,8))\n\nfor i, row in sample.iterrows():\n\n    img = mpimg.imread(f'..\/input\/histopathologic-cancer-detection\/train\/{row.id}')    \n    label = row.label\n\n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n        \n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","d10f8084":"train_df, valid_df = train_test_split(train, test_size=0.2, random_state=1, stratify=train.label)\n\nprint(train_df.shape)\nprint(valid_df.shape)","1aaf4088":"# Create image data generators for both the training set and the validation set. \n# Use the data generators to scale the pixel values by a factor of 1\/255. \n\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\nvalid_datagen = ImageDataGenerator(rescale=1\/255)","73503e91":"# Complete the code for the data loaders below. \n\nBATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (96,96)\n)\n\nvalid_loader = valid_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (96,96)\n)","1ef48eff":"TR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","7f80180c":"base_model = tf.keras.applications.VGG16(input_shape=(96,96,3),\n                                         include_top=False,\n                                         weights='imagenet')\n\nbase_model.trainable = False","07c5fd17":"base_model.summary()","73489bf9":"cnn = Sequential([\n    base_model,\n    \n    Flatten(),\n    \n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dropout(0.25),\n    BatchNormalization(),\n    Dense(2, activation='softmax')\n])\n\ncnn.summary()","4b180507":"# Define an optimizer and select a learning rate. \n# Then compile the model. \n\nopt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","99185a3d":"%%time \n\n# Complete one or more training runs. \n# Display training curves after each run. \n\nh1 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 15,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)\n\nhistory = h1.history\nprint(history.keys())","6827e7b9":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","20d63422":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","d1c037e6":"%%time \n\nh2 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 20,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","20f6945e":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","aaa1a37c":"cnn.save('cancer_model_v00.h5')\npickle.dump(history, open(f'cancer_history_v00.pkl', 'wb'))","4b630657":"In this section, we will split the labeled observations into training and validation sets. We will then create data loaders to feed the images into our neural network during training.","a6b58f4d":"# Train Network","bf2ef261":"# Import Packages","2c2b0a9b":"# Save model and history","23ccbcb3":"# Training Run 2","e935821d":"# Label distribution","b31d7649":"# Build Network","8bd62523":"# Data generators","a15cf1e0":"# Load dataframe","8ccd3a59":"# View sample images"}}