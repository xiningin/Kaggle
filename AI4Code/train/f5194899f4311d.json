{"cell_type":{"8f85baa9":"code","a7a14908":"code","e9d2cc12":"code","d2bfbe0c":"code","f20763fd":"code","025d1099":"code","2f3eea2b":"code","045327d4":"code","8549eafc":"code","afee58c7":"code","22a652ac":"code","22fa51ad":"code","274aabea":"code","4d26937b":"code","9eba0030":"code","f131fa8c":"code","cedcab74":"code","64eff24d":"code","d5c56731":"code","8211e771":"code","92904073":"code","264c9f84":"code","2c1a1c3d":"code","68f05208":"code","f22ff1d3":"code","670c8fe6":"code","6bb4e662":"code","67ce057c":"code","bb20bfcd":"code","475b1e29":"code","df029b61":"code","bdb4e128":"code","3bd2aba4":"code","b8cf5c43":"code","2a298190":"code","e14ac729":"code","5590f003":"code","68d21eb2":"code","286ebdb0":"markdown","d6836492":"markdown"},"source":{"8f85baa9":"# General imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt","a7a14908":"# Specific imports\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix","e9d2cc12":"# Training and testing folders\ntrain_path = '..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Training'\nvalid_path = '..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Test'","d2bfbe0c":"# Get train and test files\nimage_files = glob(train_path + '\/*\/*.jp*g')\nvalid_image_files = glob(valid_path + '\/*\/*.jp*g')","f20763fd":"# Get number of classes\nfolders = glob(train_path + '\/*')\n\n# Display any random image\nplt.imshow(plt.imread(np.random.choice(image_files)))\nplt.axis('off')\nplt.show()","025d1099":"print(folders)","2f3eea2b":"# Specific imports\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix","045327d4":"# Resize all the images to this\nIMAGE_SIZE = [100, 100]\n# Training config\nepochs = 5\nbatch_size = 50","8549eafc":"vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='..\/input\/keras-pretrained-models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False)\n# Don't train existing weights\nfor layer in vgg.layers:\n  layer.trainable = False\n\nx = Flatten()(vgg.output)\nprediction = Dense(len(folders), activation='softmax')(x)","afee58c7":"print(folders)","22a652ac":"# Create Model\nmodel = Model(inputs=vgg.input, outputs=prediction)\n\n# View structure of the model\nmodel.summary()\n\n# Configure model\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='rmsprop',\n  metrics=['accuracy']\n)","22fa51ad":"# Create an instance of ImageDataGenerator\ngen = ImageDataGenerator(\n  rotation_range=20,\n  width_shift_range=0.1,\n  height_shift_range=0.1,\n  shear_range=0.1,\n  zoom_range=0.2,\n  horizontal_flip=True,\n  vertical_flip=True,\n  rescale=1.\/255,  \n  preprocessing_function=preprocess_input\n)\n\n# Get label mapping of class and label number\ntest_gen = gen.flow_from_directory(valid_path, target_size=IMAGE_SIZE)\nprint(test_gen.class_indices)\nlabels = [None] * len(test_gen.class_indices)\nfor k, v in test_gen.class_indices.items():\n  labels[v] = k","274aabea":"test_gen.class_indices","4d26937b":"# Create generators for training and validation\ntrain_generator = gen.flow_from_directory(\n  train_path,\n  target_size=IMAGE_SIZE,\n  shuffle=True,\n  batch_size=batch_size,\n)\nvalid_generator = gen.flow_from_directory(\n  valid_path,\n  target_size=IMAGE_SIZE,\n  shuffle=False,\n  batch_size=batch_size,\n)\n# Fit the model\nr = model.fit_generator(\n  train_generator,\n  validation_data=valid_generator,\n  epochs=epochs,\n  steps_per_epoch=len(image_files) \/\/ batch_size,\n  validation_steps=len(valid_image_files) \/\/ batch_size,\n)","9eba0030":"print(r)","f131fa8c":"model.summary()","cedcab74":"print(model)","64eff24d":"# serialize model to JSON\nmodel1_json = model.to_json()\nwith open(\"model1.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model1.h5\")","d5c56731":"from keras.models import model_from_json\n\n# load json and create model\njson_file = open('model1.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model1 = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model1.load_weights(\"model1.h5\")","8211e771":"arr = os.listdir('.\/')","92904073":"print(arr)","264c9f84":"print(r)","2c1a1c3d":"# Plot the train and validation loss\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n\n# Plot the train and validation accuracies\nplt.plot(r.history['acc'], label='train acc')\nplt.plot(r.history['val_acc'], label='val acc')\nplt.legend()\nplt.show()","68f05208":"print(\"Final training accuracy = {}\".format(r.history[\"acc\"][-1]))\nprint(\"Final validation accuracy = {}\".format(r.history[\"val_acc\"][-1]))","f22ff1d3":"%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","670c8fe6":"# Visualizing predictions\n\nresult = np.round(model.predict_generator(valid_generator))\nimport random\ntest_files = []\nactual_res = []\ntest_res = []\nfor i in range(0, 3):\n  rng = random.randint(0, len(valid_generator.filenames))\n  test_files.append(valid_path + '\/'+ valid_generator.filenames[rng])\n  actual_res.append(valid_generator.filenames[rng].split('\/')[0])\n  test_res.append(labels[np.argmax(result[rng])])\n\n  \nfrom IPython.display import Image, display\nfor i in range(0, 3):\n  display(Image(test_files[i]))\n \n\n  print(\"Actual class: \" + str(actual_res[i]))\n  print(\"Predicted class: \" + str(test_res[i]))\n  ","6bb4e662":"from keras.applications.vgg16 import decode_predictions\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt \nfrom PIL import Image \nimport seaborn as sns\nimport pandas as pd \nimport numpy as np \nimport os \n\nimg1 = \"..\/input\/banananaaaa\/ap1.jfif\"\nimg2 = \"..\/input\/banananaaaa\/b2.jpg\"\nimg3 = \"..\/input\/banananaaaa\/b3.jpg\"\nimg4 = \"..\/input\/banananaaaa\/b4.jpg\"\nimgs = [img1, img2, img3, img4]\n\ndef _load_image(img_path):\n    img = image.load_img(img_path, target_size=(100, 100))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = preprocess_input(img)\n    return img \n\n","67ce057c":"def _get_predictions(model):\n    f, ax = plt.subplots(1, 4)\n    f.set_size_inches(80, 40)\n    for i in range(4):\n        ax[i].imshow(Image.open(imgs[i]).resize((200, 200), Image.ANTIALIAS))\n    plt.show()\n    \n    f, axes = plt.subplots(1, 4)\n    f.set_size_inches(80, 20)\n    for i,img_path in enumerate(imgs):\n        img = _load_image(img_path)\n        x=model.predict(img)\n        print(x)\n        classes = np.argmax(x, axis = 1)\n        print(classes)\n        ","bb20bfcd":"\n_get_predictions(loaded_model1)","475b1e29":"_get_predictions(model)","df029b61":"test_gen.class_indices","bdb4e128":"type(model)","3bd2aba4":"\nmodel.save('model.h5')","b8cf5c43":"model=model.fit_generator(\n  train_generator,\n  validation_data=valid_generator,\n  epochs=epochs,\n  steps_per_epoch=len(image_files) \/\/ batch_size,\n  validation_steps=len(valid_image_files) \/\/ batch_size,\n)","2a298190":"_get_predictions(model)","e14ac729":"test_images.shape()","5590f003":"predictions = model.predict(test_images)","68d21eb2":"from keras.applications.vgg16 import decode_predictions\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt \nfrom PIL import Image \nimport seaborn as sns\nimport pandas as pd \nimport numpy as np \nimport os \n\nimg1 = \"..\/input\/banananaaaa\/b1.jpg\"\nimg2 = \"..\/input\/banananaaaa\/b2.jpg\"\nimg3 = \"..\/input\/banananaaaa\/b3.jpg\"\nimg4 = \"..\/input\/banananaaaa\/b4.jpg\"\nimgs = [img1, img2, img3, img4]\n\ndef _load_image(img_path):\n    img = image.load_img(img_path, target_size=(224, 224))\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = preprocess_input(img)\n    return img \n\ndef _get_predictions(_model):\n    f, ax = plt.subplots(1, 4)\n    f.set_size_inches(80, 40)\n    for i in range(4):\n        ax[i].imshow(Image.open(imgs[i]).resize((200, 200), Image.ANTIALIAS))\n    plt.show()\n    \n    f, axes = plt.subplots(1, 4)\n    f.set_size_inches(80, 20)\n    for i,img_path in enumerate(imgs):\n        img = _load_image(img_path)\n        preds  = decode_predictions(_model.predict(img), top=3)[0]\n        b = sns.barplot(y=[c[1] for c in preds], x=[c[2] for c in preds], color=\"gray\", ax=axes[i])\n        b.tick_params(labelsize=55)\n        f.tight_layout()","286ebdb0":"import os\nimport cv2\nbad_list=[]\ndir=r'..\/input\/fruit-and-vegetables-ssm\/train'\nsubdir_list=os.listdir(dir) # create a list of the sub directories in the directory ie train or test\nfor d in subdir_list:  # iterate through the sub directories train and test\n    dpath=os.path.join (dir, d) # create path to sub directory\n    if d in ['test', 'train']:\n        class_list=os.listdir(dpath) # list of classes ie dog or cat\n       # print (class_list)\n        for klass in class_list: # iterate through the two classes\n            class_path=os.path.join(dpath, klass) # path to class directory\n            #print(class_path)\n            file_list=os.listdir(class_path) # create list of files in class directory\n            for f in file_list: # iterate through the files\n                fpath=os.path.join (class_path,f)\n                index=f.rfind('.') # find index of period infilename\n                ext=f[index+1:] # get the files extension\n                if ext  not in ['jpg', 'png', 'bmp', 'gif']:\n                    print(f'file {fpath}  has an invalid extension {ext}')\n                    bad_list.append(fpath)                    \n                else:\n                    try:\n                        img=cv2.imread(fpath)\n                        size=img.shape\n                    except:\n                        print(f'file {fpath} is not a valid image file ')\n                        bad_list.append(fpath)\n                       \nprint (bad_list)","d6836492":"import os\nfrom PIL import Image\nfolder_path = '..\/input\/fruit-and-vegetables-ssm\/train'\nextensions = []\nfor fldr in os.listdir(folder_path):\n    sub_folder_path = os.path.join(folder_path, fldr)\n    for filee in os.listdir(sub_folder_path):\n        file_path = os.path.join(sub_folder_path, filee)\n        print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n        im = Image.open(file_path)\n        rgb_im = im.convert('RGB')\n        if filee.split('.')[1] not in extensions:\n            extensions.append(filee.split('.')[1])"}}