{"cell_type":{"b46b6a8a":"code","9da539ac":"code","166d022c":"code","de7cbf5f":"code","e3cd93e1":"code","7b8e2d2e":"code","5e161d75":"code","c766b86e":"code","6ee0cbf3":"code","b587979a":"code","29a4459e":"code","ac90e5cb":"code","1cb3088d":"code","67df36d0":"code","f4520889":"code","8b89aeff":"code","3998152d":"code","050e3f3d":"code","f9fbe438":"markdown","6c9fe07f":"markdown","6e541fbf":"markdown","9517b1a7":"markdown","cebb493d":"markdown","6ed9ad54":"markdown"},"source":{"b46b6a8a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    count = len([filename for filename in os.listdir(dirname) if os.path.isfile(os.path.join(dirname,filename)) ])\n    if count > 0:\n        print(dirname.split('\/')[-2:], str(count)) ","9da539ac":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import preprocessing\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","166d022c":"train_path = '\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/'\nvalid_path = '\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\/'\ntest_path = '\/kaggle\/input\/intel-image-classification\/seg_pred\/'","de7cbf5f":"img=mpimg.imread(train_path+'\/glacier\/10.jpg')\nimgplot = plt.imshow(img)\nplt.show()\nimg.shape","e3cd93e1":"# Using Preprocessing Techniques From VGG16 model\ndatagen = preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)","7b8e2d2e":"train_generator = datagen.flow_from_directory(train_path, color_mode='rgb', batch_size=32, class_mode='categorical', target_size=(150, 150), shuffle=True, seed=42)\nvalid_generator = datagen.flow_from_directory(valid_path, color_mode='rgb', batch_size=32, class_mode='categorical', target_size=(150, 150), shuffle=True, seed=42)\ntest_generator = datagen.flow_from_directory(test_path, color_mode=\"rgb\", class_mode='categorical', target_size=(150, 150), batch_size=10, shuffle=False, seed=42)","5e161d75":"train_generator.n\/\/train_generator.batch_size","c766b86e":"train_generator.fit(images, augment=True, seed=42)","6ee0cbf3":"# train_generator.image_shape\nimgs, labels = next(train_generator)","b587979a":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","29a4459e":"plotImages(imgs)\nprint(labels)","ac90e5cb":"input_shape = (150, 150, 3)\n\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        keras.layers.Flatten(),\n        keras.layers.Dropout(0.5),\n        keras.layers.Dense(6, activation=\"softmax\"),\n    ]\n)","1cb3088d":"# loss = tf.keras.backend.sparse_categorical_crossentropy(target, output, from_logits=False)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])","67df36d0":"model.summary()","f4520889":"model.fit(x=train_generator, steps_per_epoch=len(train_generator), validation_data=valid_generator, validation_steps=len(valid_generator), epochs=10, verbose=2)","8b89aeff":"model.fit(x=train_generator, steps_per_epoch=len(train_generator), validation_data=valid_generator, validation_steps=len(valid_generator), epochs=10, verbose=2)","3998152d":"history = model.fit(x=train_generator, steps_per_epoch=len(train_generator), validation_data=valid_generator, validation_steps=len(valid_generator), epochs=2, verbose=2)","050e3f3d":"model.evaluate(test_generator)","f9fbe438":"### Import Libraries","6c9fe07f":"### Model Build and Training","6e541fbf":"### Sample Images","9517b1a7":"## Evaluate","cebb493d":"### Data Preprocessing - Train, Valid and Test","6ed9ad54":"Image data of Natural Scenes around the world.\n\n"}}