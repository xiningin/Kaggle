{"cell_type":{"83c5a12c":"code","627c30e0":"code","590d7e68":"code","b6323cec":"code","757d8785":"code","e695bef8":"code","897f5b4d":"code","daef6033":"code","7b933539":"code","706b9d23":"code","3b1d9fa3":"code","2dd2027e":"code","3ab391bd":"code","3202adad":"code","5f36204e":"code","75f86a35":"code","4ca87c53":"code","ae6d5aca":"code","c3b4ea4f":"code","c78526ea":"code","24f37b88":"code","c793dbb0":"code","02f9a909":"code","5e1bdf58":"code","38855626":"code","fb92e798":"code","98633203":"code","9463acf7":"code","91bede12":"code","0364bdca":"code","d4e9c7a4":"code","fe552ace":"code","ec745379":"code","df871e9f":"code","94d61ee5":"code","a8e77dbd":"code","49de0c0a":"code","88efb37f":"code","122ab600":"code","00d23b37":"code","c07e35d3":"code","bcee1930":"code","98253b04":"code","04f2ce6d":"code","842508a1":"code","6232fb96":"code","b6299fd5":"code","d9153cbf":"markdown","4e6b32b7":"markdown","bc516343":"markdown","eca4009b":"markdown","3bd2b4a9":"markdown","d1e23307":"markdown","4ea7cda0":"markdown","ca460b86":"markdown","a98df780":"markdown"},"source":{"83c5a12c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","627c30e0":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn as sk\nimport numpy as np","590d7e68":"train_data = pd.read_csv(\"..\/input\/loan-eligible-dataset\/loan-train.csv\")\ntest_data = pd.read_csv(\"..\/input\/loan-eligible-dataset\/loan-test.csv\")","b6323cec":"train_data.head()","757d8785":"test_data.head()","e695bef8":"train_data.shape, test_data.shape","897f5b4d":"train_data.info()","daef6033":"train_data.describe()","7b933539":"def explore_object_type(df ,feature_name):\n    \"\"\"\n    To know, How many values available in object('categorical') type of features\n    And Return Categorical values with Count.\n    \"\"\"    \n    if df[feature_name].dtype ==  'object':\n        print(df[feature_name].value_counts())","706b9d23":"for featureName in train_data.columns:\n    if train_data[featureName].dtype == 'object':\n        print('\\n\"' + str(featureName) + '\\'s\" Values with count are :')\n        explore_object_type(train_data, str(featureName))","3b1d9fa3":"# Checking for Null values in the data set\ntrain_data.isna().sum()","2dd2027e":"import missingno as msno\nmsno.bar(train_data)","3ab391bd":"msno.matrix(train_data)","3202adad":"train_data['Credit_History'].fillna(train_data['Credit_History'].mode()[0], inplace = True) # Mode\ntest_data['Credit_History'].fillna(test_data['Credit_History'].mode()[0], inplace = True) # Mode\n\ntrain_data['LoanAmount'].fillna(train_data['LoanAmount'].mean(), inplace = True) # Mean\ntest_data['LoanAmount'].fillna(test_data['LoanAmount'].mean(), inplace = True)","5f36204e":"ax1 = train_data['Gender'].value_counts(normalize=True).plot.bar(title='Train Dataset')\nplt.show()\nax2 = test_data['Gender'].value_counts(normalize=True).plot.bar(title='Test Dataset')\nplt.show()","75f86a35":"# For Gender \ntrain_data['Gender'].fillna(train_data['Gender'].mode()[0], inplace = True) # Mode\ntest_data['Gender'].fillna(test_data['Gender'].mode()[0], inplace = True) ","4ca87c53":"sns.countplot(train_data['Married']);","ae6d5aca":"# For Married\ntrain_data['Married'].fillna(train_data['Married'].mode()[0], inplace = True) # Mode\ntest_data['Married'].fillna(test_data['Married'].mode()[0], inplace = True) ","c3b4ea4f":"sns.countplot(train_data['Dependents']);","c78526ea":"# For Dependents\ntrain_data['Dependents'].fillna(train_data['Dependents'].mode()[0], inplace = True) # Mode\ntest_data['Dependents'].fillna(test_data['Dependents'].mode()[0], inplace = True) ","24f37b88":"sns.countplot(train_data['Self_Employed']);","c793dbb0":"train_data['Self_Employed'] = train_data['Self_Employed'].fillna('No')\ntest_data['Self_Employed'] = test_data['Self_Employed'].fillna('No')","02f9a909":"plt.figure(figsize=(12,8))\nsns.countplot(train_data['Loan_Amount_Term']);","5e1bdf58":"train_data['Loan_Amount_Term']= train_data['Loan_Amount_Term'].fillna(360)","38855626":"plt.figure(figsize=(12,8))\nsns.countplot(test_data['Loan_Amount_Term']);","fb92e798":"test_data['Loan_Amount_Term']= test_data['Loan_Amount_Term'].fillna(360)","98633203":"train_data.isna().sum()","9463acf7":"test_data.head()","91bede12":"# For Loan Status\ntrain_data['Loan_Status'] = train_data['Loan_Status'].replace({\"Y\" : 1, \"N\" : 0})\n\n# For Gender\ntrain_data['Gender'] = train_data['Gender'].replace({\"Male\" : 1, \"Female\" : 0})\ntest_data['Gender'] = test_data['Gender'].replace({\"Male\" : 1, \"Female\" : 0})\n\n# For Married\ntrain_data['Married'] = train_data['Married'].replace({\"Yes\" : 1, \"No\" : 0})\ntest_data['Married'] = test_data['Married'].replace({\"Yes\" : 1, \"No\" : 0})\n\n# For Credit History\ntrain_data['Self_Employed'] = train_data['Self_Employed'].replace({\"Yes\" : 1, \"No\" : 0})\ntest_data['Self_Employed'] = test_data['Self_Employed'].replace({\"Yes\" : 1, \"No\" : 0})\n","0364bdca":"from sklearn.preprocessing import LabelEncoder\nfeature_col = ['Property_Area','Education', 'Dependents']\nle = LabelEncoder()\nfor col in feature_col:\n    train_data[col] = le.fit_transform(train_data[col])\n    test_data[col] = le.fit_transform(test_data[col])","d4e9c7a4":"train_data.head()","fe552ace":"sns.set_style('dark')","ec745379":"train_data.plot(figsize=(18, 8))\n\nplt.show()","df871e9f":"plt.figure(figsize=(18, 6))\nplt.subplot(1, 2, 1)\n\n\ntrain_data['ApplicantIncome'].hist(bins=15)\nplt.title(\"Loan Application Amount \")\n\nplt.subplot(1, 2, 2)\nplt.grid()\nplt.hist(np.log(train_data['LoanAmount']))\nplt.title(\"Log Loan Application Amount \")\n\nplt.show()","94d61ee5":"plt.figure(figsize=(18, 6))\nplt.title(\"Relation Between Applicatoin Income vs Loan Amount \")\n\nplt.grid()\nplt.scatter(train_data['ApplicantIncome'] , train_data['LoanAmount'], c='k', marker='x')\nplt.xlabel(\"Applicant Income\")\nplt.ylabel(\"Loan Amount\")\nplt.show()","a8e77dbd":"plt.figure(figsize=(12,8))\nsns.heatmap(train_data.corr(), cmap='coolwarm', annot=True, fmt='.1f', linewidths=.1)\nplt.show()","49de0c0a":"X = train_data.drop(columns=['Loan_Status', 'Loan_ID'], axis=1)\ny = train_data['Loan_Status']","88efb37f":"from sklearn .model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3)","122ab600":"X_train.shape","00d23b37":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","c07e35d3":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nLR = LogisticRegression()\nLR = LR.fit(X_train,y_train)\n\ny_predlr = LR.predict(X_test)\n\nprint(classification_report(y_test,y_predlr))\nprint(f\"Accuracy Score: {accuracy_score(y_test,y_predlr)}\")\nlr_results = accuracy_score(y_test,y_predlr)","bcee1930":"from sklearn.ensemble import RandomForestClassifier\nrf_classifier = RandomForestClassifier(n_estimators = 100,\n                                      criterion = \"entropy\",\n                                      random_state =42)\nrf_classifier.fit(X_train,y_train)\ny_predrf = rf_classifier.predict(X_test)\n\nprint(classification_report(y_test,y_predrf))\nprint(f\"Accuracy Score: {accuracy_score(y_test,y_predrf)}\")\nrf_results = accuracy_score(y_test,y_predrf)","98253b04":"from sklearn.tree import DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier(criterion = \"entropy\",random_state = 42)\ndt_classifier.fit(X_train,y_train)\ny_preddt = dt_classifier.predict(X_test)\n\nprint(classification_report(y_test,y_preddt))\nprint(f\"Accuracy Score: {accuracy_score(y_test,y_preddt)}\")\ndt_results = accuracy_score(y_test,y_preddt)","04f2ce6d":"from sklearn.naive_bayes import GaussianNB\nNBClassifier=GaussianNB()\nNBClassifier.fit(X_train,y_train)\ny_prednb = NBClassifier.predict(X_test)\nprint(classification_report(y_test,y_prednb))\nprint(f\"Accuracy Score: {accuracy_score(y_test,y_prednb)}\")\n\nnb_results = accuracy_score(y_test,y_prednb)","842508a1":"# creating the dataset\ndata = {'Logistic Regression':round(lr_results,2),\n        'Random Forest Classification':round(rf_results,2),\n        'Decision Tree':round(dt_results,2),\n        'Naive Bayes':round(nb_results,2)}\nAlgo = list(data.keys())\nvalues = list(data.values())","6232fb96":"# Visualize the Models\nplt.figure(figsize=(24, 8))\nplt.subplot(1, 2, 1)\n\nplt.grid()\nplt.bar(Algo, values, color ='maroon',\n        width = 0.4) \nplt.xlabel(\"Type of Algo\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Comparison between algo\")\n\nplt.subplot(1, 2, 2)\nplt.grid()\nplt.bar(Algo, np.log(values), color ='blue',\n        width = 0.4)\nplt.title(\"Log of Accuracy\")\n\nplt.show()","b6299fd5":"# model.fit(X_train, Y_train)\n# # save the model to disk\n# filename = 'finalized_model.sav'\n# pickle.dump(model, open(filename, 'wb'))\n\n# # some time later...\n\n# # load the model from disk\n# loaded_model = pickle.load(open(filename, 'rb'))\n# result = loaded_model.score(X_test, Y_test)\n# print(result)","d9153cbf":"**4. Naive Bayes**","4e6b32b7":"**1. Linear Regression Model**","bc516343":"**3. Decision Tree**","eca4009b":"**Data Analysis**","3bd2b4a9":"**4. Choosing ML Model\nfrom the following choices\n\nLogistic Regression\nRandom Forest Classifier\nDecision Tree**","d1e23307":"**2. Random Forest Tree**","4ea7cda0":"**3. Data Visualization**","ca460b86":"**ALL THE MISSING VALUES ARE FILLED USING DATA VISUALIZATION AND STATISTICS**","a98df780":"**5. Deploy the Model**"}}