{"cell_type":{"d316af72":"code","94007516":"code","c6ae6ac5":"code","d53f1e43":"code","43536a27":"code","38edb3b2":"code","547766b0":"code","11a5f9d2":"code","24dfc6d9":"code","bc3e52f0":"markdown","7b506d42":"markdown","6b972859":"markdown","5f8e2b72":"markdown","5ce001c1":"markdown","188a41e4":"markdown","2a5f5a53":"markdown","6764b655":"markdown","d554de22":"markdown"},"source":{"d316af72":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.models import Sequential \nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense ,LeakyReLU\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom keras.applications import InceptionV3\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","94007516":"train_path = \"\/kaggle\/input\/skin-cancer9-classesisic\/skin cancer isic the international skin imaging collaboration\/Skin cancer ISIC The International Skin Imaging Collaboration\/Train\/\"\ntest_path = \"\/kaggle\/input\/skin-cancer9-classesisic\/skin cancer isic the international skin imaging collaboration\/Skin cancer ISIC The International Skin Imaging Collaboration\/Test\/\"","c6ae6ac5":"img = load_img(train_path + \"nevus\/ISIC_0000041.jpg\")\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()\n","d53f1e43":"x = img_to_array(img)\nprint(x.shape)","43536a27":"\nclassName = glob(train_path + '\/*' )\nnumberOfClass = len(className)\nprint(\"NumberOfClass: \",numberOfClass)","38edb3b2":"\n\nmodel = Sequential()\nmodel.add(InceptionV3(include_top=False, input_shape=(299,299,3)))\nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(LeakyReLU(0.001))\nmodel.add(Dense(16))\nmodel.add(LeakyReLU(0.001))\nmodel.add(Dense(numberOfClass, activation='softmax'))\nmodel.layers[0].trainable = False\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\nmodel.summary()","547766b0":"model.compile(loss = \"categorical_crossentropy\",\n              optimizer = \"rmsprop\",\n              metrics = [\"accuracy\"])\nbatch_size = 250","11a5f9d2":"train_datagen = ImageDataGenerator(rescale= 1.\/255,\n                   shear_range = 0.3,\n                   horizontal_flip=True,\n                   zoom_range = 0.3)\n\ntest_datagen = ImageDataGenerator(rescale= 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_path, \n        target_size=(299,299),\n        batch_size = batch_size,\n        color_mode= \"rgb\",\n        class_mode= 'categorical')\n\ntest_generator = test_datagen.flow_from_directory(\n        test_path, \n        target_size=(299,299),\n        batch_size = batch_size,\n        color_mode= \"rgb\",\n        class_mode= 'categorical')\n\nhist = model.fit_generator(\n        generator = train_generator,\n        steps_per_epoch = 5000,\n        epochs=1,\n        validation_data = test_generator,\n        validation_steps = 250)","24dfc6d9":"model.save_weights(\"weights.h5\")","bc3e52f0":"**define loss and optimizer method ...**","7b506d42":"**convert images to array** \n\n\n**show to shape** ","6b972859":"**Testing paths and images **\n\n","5f8e2b72":"\n\n\n**Firt of all  define test path and train path **","5ce001c1":"**if you want to save the train weights like me, you must push to internet button in setting on right vertical menu ** ","188a41e4":"accuracy= 0,20 this is mean that dataset is not corrrect separetaly pehh ;)","2a5f5a53":"**We get various images by zooming and rotating and flipping **","6764b655":"\n**Using the glob function, we learn how many different folders there are in the dataset.**","d554de22":"**we are building the cnn structure**"}}