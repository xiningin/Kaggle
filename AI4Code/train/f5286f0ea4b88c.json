{"cell_type":{"75bfb84e":"code","47d25527":"code","1106cb45":"code","2d76f6e1":"code","19766f5a":"code","cc2f9f9c":"code","9629e888":"code","4de4797e":"code","f1cb815c":"code","a4545867":"code","51909b7e":"code","e92ef433":"code","662ef845":"code","14c235d2":"code","614f780d":"code","f1fba131":"code","fc965e7e":"code","d36c9d6f":"code","b639198b":"code","5a65b00f":"code","ae81bceb":"markdown","35afbf6f":"markdown","95ad030d":"markdown","776c9da5":"markdown","db717b87":"markdown","2ba8411a":"markdown"},"source":{"75bfb84e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47d25527":"df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ndf.head()","1106cb45":"df.shape","2d76f6e1":"import tensorflow as tf\nfrom tensorflow import keras","19766f5a":"x_train = df.drop([\"label\"],axis=1)\ny_train = df[\"label\"]","cc2f9f9c":"print(type(y_train))","9629e888":"x_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","4de4797e":"x_train = x_train.astype('float32')\/255\ny_train = y_train.astype('float32')\nx_test = x_test.astype('float32')\/255","f1cb815c":"x_train= x_train.to_numpy()\ny_train= y_train.to_numpy()\nx_test = x_test.to_numpy()","a4545867":"x_train = x_train.reshape(-1,28,28,1)\nx_test = x_test.reshape(-1,28,28,1)","51909b7e":"y_train = keras.utils.to_categorical(y_train, 10)","e92ef433":"\"\"\"\"model = keras.Sequential()\nmodel.add(keras.layers.Conv2D(32,3,activation=\"relu\",padding = 'same',input_shape=(28,28,1)))\n#model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(keras.layers.Conv2D(32,3,activation=\"relu\",padding = 'same'))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dense(10, activation='softmax'))\"\"\"\nvgg_model = keras.Sequential()\nfrom tensorflow.keras.layers import Dense, MaxPool2D, Flatten, Conv2D, Dropout\nvgg_model.add(Conv2D(32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape=(28,28,1)))\nvgg_model.add(Conv2D(32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nvgg_model.add(MaxPool2D(pool_size=(2,2)))\nvgg_model.add(Dropout(0.5*0.5))\n\nvgg_model.add(Conv2D(64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nvgg_model.add(Conv2D(64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nvgg_model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nvgg_model.add(Dropout(0.5*0.5))\n\nvgg_model.add(Flatten())\nvgg_model.add(Dense(256, activation = \"relu\"))\nvgg_model.add(Dropout(0.5))\nvgg_model.add(Dense(10, activation = \"softmax\"))","662ef845":"vgg_model.compile(optimizer=\"sgd\",loss='categorical_crossentropy', metrics=['accuracy'])","14c235d2":"vgg_model.summary()","614f780d":"history = vgg_model.fit(x_train,y_train,epochs=21)","f1fba131":"df1 = pd.DataFrame(history.history)","fc965e7e":"df1[\"accuracy\"].plot()","d36c9d6f":"df1[\"loss\"].plot()","b639198b":"preds = vgg_model.predict(x_test)","5a65b00f":"results = np.argmax(preds,axis=1)\nresults = pd.Series(results, name=\"Label\")\nlist=[]\n[list.append(i) for i in range(1,28001)]\nImageID = pd.Series(list, name=\"ImageID\").astype(\"int32\")\nsubmission = pd.concat([ImageID,results],axis = 1)\nsubmission.to_csv(\"preds.csv\", index=False)\n","ae81bceb":"# Converting Y train into different categories","35afbf6f":"# Reshaping the array","95ad030d":"# Model building","776c9da5":"# Normalizing the data","db717b87":"## Seperating Independent and dependent features","2ba8411a":"# Converting data to numpy array"}}