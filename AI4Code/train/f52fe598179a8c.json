{"cell_type":{"aa01341c":"code","9835b2fa":"code","6d319d66":"code","5c8e7cf0":"code","c63a4afa":"code","df4d63ac":"code","d4f12c7d":"code","11d3ea19":"code","8d44d990":"code","a052b714":"code","e5be82b5":"code","b9a37b14":"code","1dc3e7d7":"code","5536c7c0":"code","a5dfd7d1":"code","882aea66":"code","1814cfc6":"code","0e9a2a84":"markdown","0583c5a0":"markdown","02e3d5f5":"markdown","5a1db2db":"markdown","d45a2ec9":"markdown","bd5be697":"markdown","82c5ac69":"markdown","a5e7ce42":"markdown","30d084c7":"markdown","ed60e648":"markdown"},"source":{"aa01341c":"from sklearn.model_selection import train_test_split\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.utils.np_utils import to_categorical\n%matplotlib inline\n\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\n","9835b2fa":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)\n\n","6d319d66":"X_train.isnull().any().describe()\n","5c8e7cf0":"test.isnull().any().describe()","c63a4afa":"X_train = X_train \/ 255.0\ntest = test \/ 255.0","df4d63ac":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","d4f12c7d":"Y_train = to_categorical(Y_train, num_classes = 10)","11d3ea19":"X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","8d44d990":"# printing the number of samples in X_train, X_test, y_train, y_test\nprint(\"Initial shape of dimensions of X_train\", str(X_train.shape))\n\nprint(\"Number of samples in our training data: \"+ str(len(X_train)))\nprint(\"Number of labels in out training data: \"+ str(len(y_train)))\nprint(\"Number of samples in our test data: \"+ str(len(X_test)))\nprint(\"Number of labels in out test data: \"+ str(len(y_test)))\nprint()\nprint(\"Dimensions of x_train:\" + str(X_train[0].shape))\nprint(\"Labels in x_train:\" + str(y_train.shape))\nprint()\nprint(\"Dimensions of X_test:\" + str(X_test[0].shape))\nprint(\"Labels in X_test:\" + str(y_test.shape))","a052b714":"g = plt.imshow(X_train[0][:,:,0])","e5be82b5":"num_classes = y_test.shape[1]\nnum_pixels = X_train.shape[1] * X_train.shape[2]\nimport keras\nfrom tensorflow.keras.utils import plot_model\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.optimizers import SGD\n\noptimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\ndropout=0.2\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3,3),\n                     activation='relu',\n                     input_shape=(28,28,1)))\nmodel.add(Conv2D(64, \n                     (3,3),\n                     activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(dropout))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy',\n                 optimizer = optimizer,\n                 metrics = ['accuracy'])\n\n\nprint(model.summary())\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","b9a37b14":"batch_size = 64\nepochs = 100\n\nhistory = model.fit(X_train,\n                    y_train,\n                    batch_size = batch_size,\n                    epochs = epochs,\n                    verbose = 1,\n                    validation_data = (X_test, y_test))\n\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","1dc3e7d7":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\n\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\n\nline1 = plt.plot(epochs, val_loss_values, label='Validation\/Test Loss')\nline2 = plt.plot(epochs, loss_values, label='Training Loss')\nplt.setp(line1, linewidth=1.0, marker = '+', markersize=1.0)\nplt.setp(line2, linewidth=1.0, marker = '4', markersize=1.0)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.grid(True)\nplt.legend()\nplt.show()","5536c7c0":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\n\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(loss_values) + 1)\n\nline1 = plt.plot(epochs, val_acc_values, label='Validation\/Test Accuracy')\nline2 = plt.plot(epochs, acc_values, label='Training Accuracy')\nplt.setp(line1, linewidth=1.0, marker = '+', markersize=1.0)\nplt.setp(line2, linewidth=1.0, marker = '4', markersize=1.0)\nplt.xlabel('Epochs') \nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.legend()\nplt.show()","a5dfd7d1":"model.save(\"\/mnist_simple_cnn_10_epochs.h5\")\nprint(\"Model save\")","882aea66":"from keras.models import load_model\nclassifier = load_model(\"\/mnist_simple_cnn_10_epochs.h5\")\nprint(\"Model loaded\")","1814cfc6":"\nresults = model.predict(test)\n\n\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","0e9a2a84":"# Examine dataset and normalize data","0583c5a0":"# Create Our Model\n- We're constructing a simple but effective CNN that uses 32 filters of size 3x3\n- We've added a 2nd CONV layer of 64 filters of the same size 3x2\n- We then downsample out data to 2x2, hete he apply a dropout where p is set to 0.2\n- We then flatten out Max Pool output that is connected to a Dense\/FC layer has an output size of 128\n- How we apply a dropout where P is set to 0.5\n- Thus 128 output is connected to another FC\/Dense layer that outputs to the 10 categorical units","02e3d5f5":"##  If you like, please upvote!","5a1db2db":"# Examine the size and image dimensions\n\n","d45a2ec9":"# Let's take a look at some of images in this dataset\n","bd5be697":"# Saving our Model\n","82c5ac69":"# Plotting out Loss and Accuracy Charts\n","a5e7ce42":"# Loading our Model","30d084c7":"# Loading dataset and Libs","ed60e648":"# Train our Model\n"}}