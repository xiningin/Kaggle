{"cell_type":{"bb5f9f24":"code","68ffbc0b":"code","a1b5d195":"code","3bc5cc55":"code","e5d8fc6f":"code","59b3027b":"code","173fcbec":"code","72347f73":"code","ba097ef7":"code","c64baba9":"code","42153bec":"code","cb9fcce3":"code","2de32568":"code","9cd7c8df":"code","311b85ff":"code","ee5451e3":"code","d98e53eb":"code","c8c37f39":"code","322d206f":"code","95208146":"code","7cfd851d":"code","b59ec6ff":"code","737aa8ac":"code","862f96a0":"code","a3dac7bb":"code","c7aeaa1d":"code","3e9e906c":"code","d7280e37":"code","ded0e309":"code","535f9bb0":"code","a3eaf872":"code","33f55001":"markdown","ffab88d0":"markdown","b249ea74":"markdown","e8a5435d":"markdown","feb88c4a":"markdown"},"source":{"bb5f9f24":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport tensorflow as tf\nfrom tensorflow import keras\nimport re\nimport string\n\nimport os","68ffbc0b":"kaggle_path = '..\/input\/nlp-getting-started\/train.csv'\ndf = pd.read_csv(kaggle_path)\n\ndf.head()","a1b5d195":"df.shape  # We have 7613 rows and 5 columns","3bc5cc55":"df['text'][100]","e5d8fc6f":"from nltk.corpus import stopwords\n\ncached_stop_words = stopwords.words(\"english\")\n\ndef remove_at_url(my_string):\n    new_text = re.sub(r'http\\S+', '', my_string)\n    new_text = re.sub(r'@\\S+','', new_text)\n    new_text = ''.join([x for x in new_text if x not in string.punctuation])\n    new_text = ' '.join([x for x in new_text.split() if x not in cached_stop_words])\n    return new_text\n\n\ndf['text'] = df['text'].map(lambda x: remove_at_url(x))","59b3027b":"print(df['text'][12])\nprint(df['text'][100])","173fcbec":"df['target'].value_counts()","72347f73":"df = df.sample(frac=1, random_state=42).reset_index(drop=True)\ndf.head()","ba097ef7":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","c64baba9":"vocab_size = 5000\n\ntokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(df['text'])\nword_index = tokenizer.word_index\n# print(word_index)","42153bec":"df['seq'] = tokenizer.texts_to_sequences(df['text'])\n# df['seq'] = pad_sequences(df['seq'], padding='post')","cb9fcce3":"temp = pad_sequences(df['seq'], padding='post')\ntemp","2de32568":"df.head()","9cd7c8df":"temp","311b85ff":"temp.shape  # Hence there are 7613 entries each of length 27","ee5451e3":"training_size = 6090\n\ntraining_sentences = temp[: training_size]\nvalidation_sentences = temp[training_size: ]\n\nlabels = np.array(df['target'])\n\ntraining_labels = labels[: training_size]\nvalidation_labels = labels[training_size: ]","d98e53eb":"len(training_sentences), len(training_labels)","c8c37f39":"model = keras.models.Sequential([\n    keras.layers.Embedding(vocab_size, 32),\n    keras.layers.LSTM(24),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])","322d206f":"my_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n\nhistory = model.fit(training_sentences, training_labels, epochs=200, \n              validation_data=(validation_sentences, validation_labels),\n              callbacks=[my_cb])","95208146":"print(history.history.keys())\nepochs = len(history.history['loss'])\nepochs","7cfd851d":"y1 = history.history['loss']\ny2 = history.history['val_loss']\nx = np.arange(1, epochs+1)\n\nplt.plot(x, y1, y2)\nplt.legend(['loss', 'val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.tight_layout()","b59ec6ff":"y1 = history.history['acc']\ny2 = history.history['val_acc']\nx = np.arange(1, epochs+1)\n\nplt.plot(x, y1, y2)\nplt.legend(['acc', 'val_acc'])\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.tight_layout()","737aa8ac":"res = model.evaluate(validation_sentences, validation_labels)","862f96a0":"kaggle_test_path = '..\/input\/nlp-getting-started\/test.csv'\n\ntest_df = pd.read_csv(kaggle_test_path)\ntest_df.head()","a3dac7bb":"test_seq = test_df['text'].map(lambda x: remove_at_url(x))\ntest_seq","c7aeaa1d":"test_seq = tokenizer.texts_to_sequences(test_seq)\ntest_seq","3e9e906c":"test_seq = pad_sequences(test_seq,  padding='post')\ntest_seq","d7280e37":"predictions = model.predict(test_seq)\npredictions = predictions.flatten()\npredictions","ded0e309":"predictions = np.rint(predictions)\npredictions = predictions.astype(np.int32)\npredictions","535f9bb0":"ans = pd.DataFrame({'id': test_df['id'], 'target': predictions})\nans.head()","a3eaf872":"kaggle_output_path = '.\/my_submission.csv'\nans.to_csv(kaggle_output_path, index=False)","33f55001":"# Building and Compiling the model","ffab88d0":"# Data Preprocessing","b249ea74":"# Training the model","e8a5435d":"# Making predictions","feb88c4a":"# Evaluating the model"}}