{"cell_type":{"b11d7f7b":"code","92193178":"code","eb364d0e":"code","ac896067":"code","ff019c03":"code","b1d39e99":"code","af0f4db4":"code","273c8ca7":"code","6257514d":"code","e9fc1045":"code","e132d33d":"code","3f3f889f":"code","c2faa97c":"code","ae9ffa01":"code","a1edec47":"code","dd7150a1":"code","b77257f9":"code","19607a3b":"code","dd552928":"code","7824bc0f":"code","b0b065bf":"code","8caac36f":"code","a5ca9bfe":"code","7581456e":"code","f3286eb6":"code","6f17051f":"code","711d5e6c":"code","207e0cb7":"code","b047f2a6":"code","7cf3d7ab":"code","31e4f3d7":"code","ccca9a66":"code","9c8a32bd":"code","62ab3d93":"code","f22671a1":"code","c6afbab0":"code","abec54f6":"code","2c81c935":"code","efb3768a":"code","f2245367":"code","af0e2369":"code","57b2ee6c":"code","4013f462":"code","b59cc09e":"code","87d81789":"code","318beff9":"code","b48033a5":"code","612540c5":"code","92a7f8f2":"code","bc0482f0":"code","c47672dd":"code","8be3fea5":"code","33fe2418":"code","5c3ab418":"code","c85a0a77":"code","a4cd129c":"code","0b19986c":"code","305669cc":"code","465ac839":"code","ed19a19c":"markdown","fafe64c8":"markdown","3fe00860":"markdown","de25522e":"markdown","52191a6e":"markdown","887d0bf0":"markdown","b0bdcb29":"markdown","3ed23ade":"markdown","49bc60b3":"markdown","e40e0705":"markdown","9b25235a":"markdown","e2213011":"markdown","e0ddd45e":"markdown","d6a817ce":"markdown","5120fad0":"markdown"},"source":{"b11d7f7b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfrom mpl_toolkits.mplot3d import Axes3D\nimport statsmodels.api as sm\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom scipy.stats import levene\nfrom scipy.stats import shapiro\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import ShuffleSplit, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import tree\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nimport os\nimport os.path\nfrom pathlib import Path\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical","92193178":"filterwarnings(\"ignore\", category=DeprecationWarning) \nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","eb364d0e":"Meat_Data_Data = Path(\"..\/input\/meat-quality-assessment-based-on-deep-learning\")\n# main path","ac896067":"JPG_Path = list(Meat_Data_Data.glob(r\"*\/*.jpg\"))\n# jpg path","ff019c03":"print(JPG_Path[0:5])","b1d39e99":"Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],JPG_Path))\n# splitting fresh and spoiled","af0f4db4":"print(Labels.count(\"Fresh\"))","273c8ca7":"print(Labels.count(\"Spoiled\"))","6257514d":"File_Path = pd.Series(JPG_Path,name=\"JPG\").astype(str)","e9fc1045":"print(File_Path.head())","e132d33d":"Label_Name = pd.Series(Labels,name=\"CATEGORY\")","3f3f889f":"print(Label_Name.head())","c2faa97c":"print(Label_Name.value_counts())","ae9ffa01":"Main_Data = pd.concat([File_Path,Label_Name],axis=1)","a1edec47":"Main_Data = Main_Data.sample(frac=1).reset_index(drop=True)\n# we need to shuffle it, because of perfect training","dd7150a1":"print(Main_Data.head())","b77257f9":"print(Main_Data[\"CATEGORY\"].value_counts())","19607a3b":"Fresh_Meat = Main_Data[Main_Data[\"CATEGORY\"] == \"Fresh\"]\nSpoiled_Meat = Main_Data[Main_Data[\"CATEGORY\"] == \"Spoiled\"]","dd552928":"print(Fresh_Meat.head())","7824bc0f":"print(Spoiled_Meat.head())","b0b065bf":"figure = plt.figure(figsize=(8,8))\nplt.imshow(plt.imread(Main_Data[\"JPG\"][10]))\nplt.show()","8caac36f":"figure = plt.figure(figsize=(8,8))\nplt.imshow(plt.imread(Main_Data[\"JPG\"][2]))\nplt.show()","a5ca9bfe":"figure = plt.figure(figsize=(8,8))\nplt.imshow(plt.imread(Fresh_Meat[\"JPG\"][10]))\nplt.show()","7581456e":"figure = plt.figure(figsize=(8,8))\nplt.imshow(plt.imread(Spoiled_Meat[\"JPG\"][1]))\nplt.show()","f3286eb6":"fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(8, 8),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Main_Data[\"JPG\"][i]))\n    ax.set_title(Main_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","6f17051f":"Train_Data, Test_Data = train_test_split(Main_Data, train_size=0.8, shuffle=True, random_state=42)","711d5e6c":"print(Train_Data.shape)","207e0cb7":"print(Test_Data.shape)","b047f2a6":"Data_Generator = ImageDataGenerator(rescale=1.\/255,validation_split=0.2)","7cf3d7ab":"Train_Gen = Data_Generator.flow_from_dataframe(dataframe=Train_Data,\n                                               x_col=\"JPG\",\n                                               y_col=\"CATEGORY\",\n                                               shuffle=True,seed=42,\n                                               color_mode=\"rgb\",\n                                               class_mode=\"categorical\",\n                                               batch_size=32,\n                                               subset=\"training\")","31e4f3d7":"print(Train_Gen.classes[0:20])","ccca9a66":"print(Train_Gen.split)","9c8a32bd":"Test_Gen = Data_Generator.flow_from_dataframe(dataframe=Test_Data,\n                                               x_col=\"JPG\",\n                                               y_col=\"CATEGORY\",\n                                               shuffle=False,seed=42,\n                                               color_mode=\"rgb\",\n                                               class_mode=\"categorical\",\n                                               batch_size=32)","62ab3d93":"print(Test_Gen.classes[0:20])","f22671a1":"print(Test_Gen.split)","c6afbab0":"Validation_Gen = Data_Generator.flow_from_dataframe(dataframe=Train_Data,\n                                               x_col=\"JPG\",\n                                               y_col=\"CATEGORY\",\n                                               shuffle=True,seed=42,\n                                               color_mode=\"rgb\",\n                                               class_mode=\"categorical\",\n                                               batch_size=32,\n                                               subset=\"validation\")","abec54f6":"print(Validation_Gen.classes[0:20])","2c81c935":"print(Validation_Gen.split)","efb3768a":"model = tf.keras.models.Sequential([\n  \n  tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255),\n  tf.keras.layers.Flatten(input_shape=(113,)),\n  \n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  \n  tf.keras.layers.Dense(2,activation=\"softmax\")\n])","f2245367":"model.compile(optimizer=\"rmsprop\",\n             loss=\"binary_crossentropy\",\n             metrics=[\"accuracy\"])","af0e2369":"Call_Back = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=2)","57b2ee6c":"ANN_Model = model.fit(Train_Gen,\n                     validation_data=Validation_Gen,\n                     epochs=10,batch_size=5,\n                     callbacks=Call_Back)","4013f462":"Model_Results = model.evaluate(Test_Gen,verbose=False)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])","b59cc09e":"print(model.summary())","87d81789":"plt.plot(ANN_Model.history[\"accuracy\"])\nplt.plot(ANN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","318beff9":"HistoryDict = ANN_Model.history\n\nval_losses = HistoryDict[\"val_loss\"]\nval_acc = HistoryDict[\"val_accuracy\"]\nacc = HistoryDict[\"accuracy\"]\nlosses = HistoryDict[\"loss\"]\nepochs = range(1,len(val_losses)+1)","b48033a5":"plt.plot(epochs,val_losses,\"k-\",label=\"LOSS\")\nplt.plot(epochs,val_acc,\"r\",label=\"ACCURACY\")\nplt.title(\"LOSS & ACCURACY\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"Loss & Acc\")\nplt.legend()\nplt.show()","612540c5":"plt.plot(epochs,acc,\"k-\",label=\"ACCURACY\")\nplt.plot(epochs,val_acc,\"r\",label=\"ACCURACY VAL\")\nplt.title(\"ACCURACY & ACCURACY VAL\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"ACCURACY & ACCURACY VAL\")\nplt.legend()\nplt.show()","92a7f8f2":"plt.plot(epochs,losses,\"k-\",label=\"LOSS\")\nplt.plot(epochs,val_losses,\"r\",label=\"LOSS VAL\")\nplt.title(\"LOSS & LOSS VAL\")\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"LOSS & LOSS VAL\")\nplt.legend()\nplt.show()","bc0482f0":"Dict_Summary = pd.DataFrame(ANN_Model.history)\nDict_Summary.plot()","c47672dd":"Model_Predict = model.predict(Test_Gen)","8be3fea5":"Model_Predict = np.argmax(Model_Predict,axis=1)","33fe2418":"Predict_Label = (Test_Gen.class_indices)\nPredict_Label = dict((v,k) for k,v in Predict_Label.items())","5c3ab418":"Model_Predict = [Predict_Label[k] for k in Model_Predict]","c85a0a77":"print(Model_Predict[:10])","a4cd129c":"Test_Results = list(Test_Data[\"CATEGORY\"])","0b19986c":"Class_Report = classification_report(Test_Results,Model_Predict)\nprint(Class_Report)","305669cc":"Conf_Report = confusion_matrix(Test_Results,Model_Predict, normalize=\"true\")\nfigure = plt.figure(figsize=(10,10))\nsns.heatmap(Conf_Report,vmax=1,center=0,vmin=-1,annot=True)\nplt.show()","465ac839":"fig, axes = plt.subplots(nrows=8,\n                         ncols=8,\n                         figsize=(15, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(Test_Data[\"JPG\"].iloc[i]))\n    ax.set_title(f\"TEST:{Test_Data.CATEGORY.iloc[i]}\\n PREDICTION:{Model_Predict[i]}\")\nplt.tight_layout()\nplt.show()","ed19a19c":"#### IGNORING WARNINGS","fafe64c8":"all the libraries and packages you will need when needed","3fe00860":"#### Classification Report","de25522e":"# SPLITTING TRAIN AND TEST","52191a6e":"# PATH PROCESS","887d0bf0":"# IMAGE GENERATOR","b0bdcb29":"# VISUALIZATION","3ed23ade":"#### TRANSFORMATION PANDAS SERIES","49bc60b3":"# MODEL","e40e0705":"# CHECKING PREDICTION","9b25235a":"#### TRANSFORMATION PANDAS DATAFRAME","e2213011":"# PACKAGES AND LIBRARIES","e0ddd45e":"# PREDICTION PROCESS","d6a817ce":"#### Confusion Matrix","5120fad0":"#### MODEL CHECKING"}}