{"cell_type":{"dd365c77":"code","5a6c462b":"code","e2d1cb74":"code","c2410e1b":"code","edd05541":"code","777b9577":"code","879ba413":"code","4bd20593":"code","6ba423f2":"markdown","f35990bf":"markdown","ae5731d9":"markdown","96922512":"markdown","c5935c28":"markdown","72394326":"markdown","9b5fd43a":"markdown","7e04df25":"markdown","d0d69685":"markdown","37a89734":"markdown","8840ca29":"markdown"},"source":{"dd365c77":"# PCA\n# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n        \n# Importing the dataset\ndataset = pd.read_csv('\/kaggle\/input\/covid19-healthy-diet-dataset\/Protein_Supply_Quantity_Data.csv')\ndataset=dataset.replace(\"<2.5\", 0)\n\n#dataset=dataset.dropna(inplace=True)\ndataset = dataset.dropna()\ndataset = dataset.reset_index(drop=True)\n\ndataset.head()\n","5a6c462b":"X_ori = dataset.iloc[:, 1:25].values\ny_ori = dataset.iloc[:, 26].values\n\ncolumn_names=dataset.columns[1:25]\n\nX=X_ori\ny=y_ori\n\nX = StandardScaler().fit_transform(X)\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train_ori = X_train\nX_test_ori = X_test\n\n# Applying PCA\nfrom sklearn.decomposition import PCA\nfor i in range (5,0,-1):\n    pca = PCA(n_components = i)\n    X_train = pca.fit_transform(X_train_ori)\n    X_test = pca.transform(X_test_ori)\n    explained_variance = pca.explained_variance_ratio_\n    print(explained_variance)\n    n_pcs= pca.components_.shape[0]\n    most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n    most_important_names = [column_names[most_important[i]] for i in range(n_pcs)]\n    #print(most_important)\n    print(most_important_names)\n    print(\"------\")","e2d1cb74":"    \nX_new = X_ori[:,most_important[0]]\ny_new = y_ori\n\naxes = plt.gca()\n#axes.set_xlim([min(X_new[:])-.15,max(X_new[:])+.15])\n#axes.set_ylim([min(y_new[:])-.09,max(y_new[:])+.001])\naxes.spines[\"bottom\"].set_color(\"purple\")\naxes.spines[\"left\"].set_color(\"purple\")\naxes.tick_params(axis='x', colors='purple')\naxes.tick_params(axis='y', colors='purple')\n\nfor i in range (0,X.shape[0]):\n    plt.scatter(X_new[i], y_new[i], s = 100, c = 'red')\n    if i%2 == 1:\n        plt.annotate(dataset.iloc[i, 0], (X_new[i], y_new[i]), fontsize=16,rotation=-45,va='top')\n    else:\n        plt.annotate(dataset.iloc[i, 0], (X_new[i], y_new[i]), fontsize=16,rotation=+45,va='bottom')\n\nplt.title(column_names[most_important[0]] +' Consumed vs Confirmed cases',fontsize=20, fontweight='bold',c = 'purple')\nplt.xlabel(column_names[most_important[0]] + ' Consumed Percentage',fontsize=16, fontweight='bold',c = 'purple')\nplt.ylabel('Confirmed Cases Percentage',fontsize=16, fontweight='bold',c = 'purple')\n\nfigure = plt.gcf()  # get current figure\nfigure.set_size_inches(32, 18) # set figure's size manually to your full screen (32x18)\nplt.show()","c2410e1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n \n    #for filename in filenames:\n     #   print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Mon May  4 16:48:47 2020\n\n@author: rashmibh\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Importing the INDIA dataset\ndataset = pd.read_csv('\/kaggle\/input\/covid19-healthy-diet-dataset\/Fat_Supply_Quantity_Data.csv',usecols=[0,24,26])\n\ndataset=dataset.replace(\"<2.5\", 0)\n\ndataset = dataset.dropna()\ndataset = dataset.reset_index(drop=True)\ndataset.head()","edd05541":"X = dataset.iloc[:, [1,2]].values\n\nscalerX = StandardScaler().fit(X)\nX_scaled = scalerX.transform(X)\n\n# Using the elbow method to find the optimal number of clusters\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X_scaled)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\n#plt.show()\nfigure = plt.gcf()  # get current figure\nfigure.set_size_inches(8, 4) # set figure's size manually to your full screen (32x18)\n#plt.savefig(\"Elbow.png\", bbox_inches='tight') # bbox_inches removes extra white spaces\nplt.show()\n#plt.clf()\n","777b9577":"num_opt_clusters=3\n\n# Fitting K-Means to the dataset\nkmeans = KMeans(n_clusters = num_opt_clusters, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X_scaled)\n\noriginal_len=dataset.shape[0]\nfor i in range(0,original_len):\n    dataset.loc[i,\"Cluster\"]=y_kmeans[i]\n \n#dataset.to_csv('Cluster Assignment Result.csv') \n   \nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.title('Cluster Analysis',fontsize=20, fontweight='bold')\nplt.xlabel('Obesity',fontsize=16, fontweight='bold')\nplt.ylabel('Confirmed',fontsize=16, fontweight='bold')\n\nfigure = plt.gcf()  # get current figure\nfigure.set_size_inches(32, 18) # set figure's size manually to your full screen (32x18)\nplt.show()\n","879ba413":"\naxes = plt.gca()\naxes.set_xlim([min(X[:,0])-.05,max(X[:,0])+.05])\naxes.set_ylim([min(X[:,1])-.005,max(X[:,1])+.005])\naxes.spines[\"bottom\"].set_color(\"purple\")\naxes.spines[\"left\"].set_color(\"purple\")\naxes.tick_params(axis='x', colors='purple')\naxes.tick_params(axis='y', colors='purple')\n    \nfor i in range (0,X.shape[0]):\n    if y_kmeans[i] == 1 :\n        plt.scatter(X[i,0], X[i,1], s = 100, c = 'green')\n    elif y_kmeans[i] == 2 :\n        plt.scatter(X[i,0], X[i,1], s = 100, c = 'red')\n    elif y_kmeans[i] == 0 :\n        plt.scatter(X[i,0], X[i,1], s = 100, c = 'blue')\n   # plt.annotate(dataset.iloc[i, 0], (X[i,0], X[i,1]))\n    if i%2 == 1:\n        plt.annotate(dataset.iloc[i, 0], (X[i,0], X[i,1]), fontsize=14,rotation=35,va='bottom')\n    else:\n        plt.annotate(dataset.iloc[i, 0], (X[i,0], X[i,1]), fontsize=14,rotation=-35,va='top')\n\nplt.title('Cluster Analysis',fontsize=20, fontweight='bold',c = 'purple')\nplt.xlabel('Obesity Percentage',fontsize=16, fontweight='bold',c = 'purple')\nplt.ylabel('Confirmed Cases Percentage',fontsize=16, fontweight='bold',c = 'purple')\n#plt.show()\n\nfigure = plt.gcf()  # get current figure\nfigure.set_size_inches(32, 18) # set figure's size manually to your full screen (32x18)\n#plt.savefig(\"Cluster.png\", bbox_inches='tight') # bbox_inches removes extra white spaces\n#plt.clf()\nplt.show()","4bd20593":"\nfor j in range(0,num_opt_clusters):\n    if j==1:\n        colour = 'green'\n    elif j==2:\n        colour = 'red'\n    elif j==0:\n        colour = 'blue'\n    else:\n        print(\"Error:\")\n    \n    axes = plt.gca()\n    axes.set_xlim([min(X[y_kmeans==j,0])-.05,max(X[y_kmeans==j,0])+.05])\n    axes.set_ylim([min(X[y_kmeans==j,1])-.005,max(X[y_kmeans==j,1])+.005])\n    axes.spines[\"bottom\"].set_color(\"purple\")\n    axes.spines[\"left\"].set_color(\"purple\")\n    axes.tick_params(axis='x', colors='purple')\n    axes.tick_params(axis='y', colors='purple')\n\n    for i in range (0,X.shape[0]):\n        if y_kmeans[i] == j :\n            plt.scatter(X[i,0], X[i,1], s = 150, c = colour)\n            if i%2 == 1:\n                plt.annotate(dataset.iloc[i, 0], (X[i,0], X[i,1]), fontsize=14,rotation=-45,va='top')\n            else:\n                plt.annotate(dataset.iloc[i, 0], (X[i,0], X[i,1]), fontsize=14,rotation=+45,va='bottom')\n        \n    plt.title('Cluster_' + str(j) + ' Detail',fontsize=22, fontweight='bold',c = 'purple')\n    plt.xlabel('Obesity Percentage',fontsize=20, fontweight='bold',c = 'purple')\n    plt.ylabel('Confirmed Cases percentage',fontsize=20, fontweight='bold',c = 'purple')\n    \n    \n    figure = plt.gcf()  # get current figure\n    figure.set_size_inches(32, 18) # set figure's size manually to your full screen (32x18)\n    plt.show()\n    #plt.savefig(\"Cluster\"+str(j)+\".png\", bbox_inches='tight') # bbox_inches removes extra white spaces\n    #plt.clf()\n","6ba423f2":"Used Elbow method to find optimum number of clusters. In this case, it was found that 3 is the optimum number of clusters.","f35990bf":"It is found out that Animal Products are the most important factor( Principal Component) with explained_variance_ratio_ of 0.25363972.\n\nIt is also found that \"Vegetable Products\" column is redundant.If we remove \"Animal Products\" feature from analysis then \"Vegetable Products\" becomes principle component.\n","ae5731d9":"Using PCA Technique, I have tried to analyse and find out the most important factor of Protein Source. ","96922512":"Cluster chart with name of the countries.","c5935c28":"1. Cluster 0 -- Low COVID-19 confirmed percentage and Low Obesity percentage.\n             Ex. India,Kenya, Thailand\n2. Cluster 1 -- Low COVID-19 confirmed percentage and High Obesity percentage.\n             Ex. Australia, Jordan, Mexico\n3. Cluster 2 -- High COVID-19 confirmed percentage and High Obesity percentage.\n             Ex. United States of America, Spain, Iceland             \n\nSo we can see that contries where obesity is low COVID-19 cases are low. ","72394326":"# **Analysis based on Confirmed Cases Percentage and Obesity Percentage**\n\nTo understand the relationship between Covid-19 and Obesity, I have applied K Means clustering to the data obtained from Fat_Supply_Quantity_Data.csv.\n","9b5fd43a":"Dataset:[](\/\/https:\/\/www.kaggle.com\/mariaren\/covid19-healthy-diet-dataset)\n","7e04df25":"# **Analysis based on Covid-19 Confirmed cases and Protein Intake **\n\nTo understand the relationship between Covid-19 and Source of Protein, I have applied Principal Component Analysis(PCA) to the data from Protein_Supply_Quantity_Data.csv.\nDataset provides us the % of Protein Source (i.e. From Animal Products, Milk, Pulses etc.,) for different countries and confirmed COVID-19 cases. \n","d0d69685":"Below charts provide closer look into 3 clusters.\n","37a89734":"From the above chart we can see that COVID-19 confirmed percentage is less in the contries where Animal Product Protein consumption is low like India.\n\nAmongst the contries where Animal Product Protein consumption is high, we see confirmed percentage also high,like Spain, United States of America, Italy.\n\nHowever, there are countries like Australia where confirmed percentage is low despite High % of Protein intake from Animal Product source, may be, perhaps, due to other fitness habits and wide spread population etc.\n","8840ca29":"I have plotted Principal Component Vs Confirmed Cases percentage to see relationship between them."}}