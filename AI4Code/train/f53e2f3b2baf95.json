{"cell_type":{"01796c84":"code","91dafc5a":"code","3c6af5a7":"code","429051e1":"code","6c78fc2e":"code","268534ee":"code","6a858c96":"code","7ebe8463":"code","46ab11be":"code","5b03a59b":"code","84a031ed":"code","e304c024":"code","f5726f33":"code","5d003d6a":"code","50b84c06":"code","80343cf7":"code","e8f1a593":"code","bc3b9b9e":"markdown","4022f751":"markdown","344eb3e5":"markdown","0040795d":"markdown","8ae7f182":"markdown","5fc885ec":"markdown"},"source":{"01796c84":"import numpy as np\nimport pandas as pd\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import r2_score","91dafc5a":"data = pd.read_csv('..\/input\/melbourne-housing-market\/MELBOURNE_HOUSE_PRICES_LESS.csv')","3c6af5a7":"data","429051e1":"data.info()","6c78fc2e":"pd.get_dummies(data['Method'])","268534ee":"def onehot_encode(df, column_dict):\n    df = df.copy()\n    for column, prefix in column_dict.items():\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","6a858c96":"def get_sequences(texts):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(texts)\n    \n    vocab_length = len(tokenizer.word_index) + 1\n    print(\"Vocab length:\", vocab_length)\n    \n    sequences = tokenizer.texts_to_sequences(texts)\n    \n    max_seq_length = np.max([len(sequence) for sequence in sequences])\n    print(\"Max sequence length:\", max_seq_length)\n    \n    sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n    \n    return sequences","7ebe8463":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop rows with missing target values\n    df = df.dropna(axis=0).reset_index(drop=True)\n    \n    # One-hot encode nominal features\n    column_dict = {\n        'Suburb': 'SU',\n        'Type': 'TY',\n        'Method': 'ME',\n        'SellerG': 'SE',\n        'Postcode': 'PO',\n        'Regionname': 'RE',\n        'CouncilArea': 'CO'\n    }\n    \n    df = onehot_encode(df, column_dict)\n    \n    # Create date features\n    df['Date'] = pd.to_datetime(df['Date'])\n    \n    df['Year'] = df['Date'].apply(lambda x: x.year)\n    df['Month'] = df['Date'].apply(lambda x: x.month)\n    df['Day'] = df['Date'].apply(lambda x: x.day)\n    \n    df = df.drop('Date', axis=1)\n    \n    # Get address sequences\n    addr_sequences = get_sequences(df['Address'])\n    df = df.drop('Address', axis=1)\n    \n    # Split df into X and y\n    y = df['Price'].copy()\n    X = df.drop('Price', axis=1).copy()\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n    \n    return X, addr_sequences, y","46ab11be":"X, addr_sequences, y = preprocess_inputs(data)","5b03a59b":"X","84a031ed":"addr_sequences","e304c024":"y","f5726f33":"X_train, X_test, addr_train, addr_test, y_train, y_test = train_test_split(X, addr_sequences, y, train_size=0.7, random_state=123)","5d003d6a":"X_inputs = tf.keras.Input(shape=(X_train.shape[1],), name='X_input')\naddr_inputs = tf.keras.Input(shape=(addr_train.shape[1],), name='addr_input')\n\n# X\nX_dense1 = tf.keras.layers.Dense(512, activation='relu', name='X_dense1')(X_inputs)\nX_dense2 = tf.keras.layers.Dense(512, activation='relu', name='X_dense2')(X_dense1)\n\n# addr\naddr_embedding = tf.keras.layers.Embedding(\n    input_dim=10774,\n    output_dim=64,\n    input_length=addr_train.shape[1],\n    name='addr_embedding'\n)(addr_inputs)\naddr_flatten = tf.keras.layers.Flatten(name='addr_flatten')(addr_embedding)\n\n# concatenate\nconcat = tf.keras.layers.concatenate([X_dense2, addr_flatten], name='concatenate')\n\noutputs = tf.keras.layers.Dense(1, activation='linear')(concat)\n\n\nmodel = tf.keras.Model(inputs=[X_inputs, addr_inputs], outputs=outputs)\n\n\nprint(model.summary())\ntf.keras.utils.plot_model(model)","50b84c06":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n    loss='mse'\n)\n\nhistory = model.fit(\n    [X_train, addr_train],\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=50,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau()\n    ]\n)","80343cf7":"y_true = np.array(y_test)\ny_pred = np.squeeze(model.predict([X_test, addr_test]))","e8f1a593":"model_r2 = r2_score(y_true, y_pred)\n\nprint(\"Model R^2 Score: {:.6f}\".format(model_r2))","bc3b9b9e":"# Getting Started","4022f751":"# Task for Today  \n\n***\n\n## Melbourne House Price Prediction  \n\nGiven *data about the housing market in Melbourne*, let's try to predict the **price** of a given property.  \n  \nWe will use a multi-input TensorFlow neural network to make our predictions.","344eb3e5":"# Training","0040795d":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/vzWbbqgjV9g","8ae7f182":"# Preprocessing","5fc885ec":"# Results"}}