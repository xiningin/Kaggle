{"cell_type":{"d310a368":"code","68fe57c8":"code","e4cc6cab":"code","2c015406":"code","350cbf34":"code","acf9b49e":"code","49e941f7":"code","2a10b521":"code","c07c2395":"code","aac36eb5":"code","1dca55ce":"code","77299ee4":"code","b05d4d72":"code","feeabab5":"code","6c6d0923":"code","27d2dd0c":"code","e2df3018":"code","5c3e7a1e":"code","8c956045":"code","6422a04b":"code","45c5a4ea":"code","28a3a7e0":"code","813b6639":"code","826755c5":"markdown","efa9f156":"markdown","44d1051f":"markdown","1953bff0":"markdown","3b80773c":"markdown","dd4636bd":"markdown","35fe52b3":"markdown","4648a420":"markdown","c2e9572b":"markdown","ff518775":"markdown"},"source":{"d310a368":"# Imports\nimport os\nimport random\nimport copy\nimport pandas as pd\nimport numpy as np\nfrom numpy import percentile\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom math import sqrt\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nfrom sklearn import preprocessing\n\n%matplotlib inline \n\nprint(\"Setup Complete\")","68fe57c8":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Path of the file to read\ndata_filepath = \"\/kaggle\/input\/absenteeism-at-work\/Absenteeism_at_work.csv\"\n\n# Import Data set\nemployee_data = pd.read_csv(data_filepath,\n                            header=0, \n                            sep=',', \n                            na_values=['.', '??', '', ' ', 'NA', 'na', 'Na', 'N\/A', 'N\/a', 'n\/a'],\n                            index_col=\"ID\"\n                           )\n\n# Print the first 5 rows of the data\nemployee_data.head()\n# employee_data.to_excel(\"..\/employee-data-raw.xlsx\")\n","e4cc6cab":"# Exploratory Data Analysis\nprint('Shape of dataset: {}'.format(employee_data.shape))\n\n# Data Types of all the variables\nprint('Feature Type: ')\nprint('{}'.format(employee_data.dtypes))\n\n# Number of Unique values present in each variable\nemployee_data.nunique()\n","2c015406":"\n# categorising the variables in two category \" Continuos\" and \"Categorical\"\ncontinuous_attributes = ['Distance from Residence to Work', 'Service time', 'Age', 'Work load Average\/day ', 'Transportation expense',\n       'Hit target', 'Weight', 'Height', 'Body mass index', 'Absenteeism time in hours']\n\ncategorical_attributes = ['Reason for absence','Month of absence','Day of the week',\n                     'Seasons','Disciplinary failure', 'Education', 'Social drinker',\n                     'Social smoker', 'Pet', 'Son']\n\n\n# Transformation DataTypes\nfor key in employee_data.keys():\n    if key in categorical_attributes:\n        if key == 'Reason for absence':\n#             employee_data[key] = employee_data[key].replace(0,np.nan)\n            employee_data[key] = employee_data[key].replace(0,employee_data[key].mean())\n\n        elif key == 'Month of absence':\n#             employee_data[key] = employee_data[key].replace(0,employee_data[key].mean())\n            employee_data[key] = employee_data[key].replace(0,np.nan)\n\n        employee_data[key] = employee_data[key].astype('category')\nprint('{}'.format(employee_data.dtypes))\n","350cbf34":"# Number of Unique values present in each variable\n# employee_data.nunique()\n\n# Make a copy of employee dataframe\ndf = employee_data.copy()\n\nprint(df[df.isnull().any(axis=1)])\n\n#Creating dataframe with number of missing values\nnull_data_rows = df[df.isnull().any(axis=1)]\nnull_data_columns = df.columns[df.isnull().any()]\nmissing_val = pd.DataFrame(df.isnull().sum())\n\n#Reset the index to get row names as columns\nmissing_val = missing_val.reset_index()\n\n#Rename the columns\nmissing_val = missing_val.rename(columns = {'index': 'Variables', 0: 'Missing_percntage'})\nmissing_val\n\n#Calculate percentage\nmissing_val['Missing_percntage'] = (missing_val['Missing_percntage']\/len(df))*100\n\n#Sort the rows according to decreasing missing percentage\nmissing_val = missing_val.sort_values('Missing_percntage', ascending = False).reset_index(drop = True)\n\n#Save output to csv file\nmissing_val.to_csv(\"Missing_percntage.csv\", index = False)\n\n# Return the percentage of missing data in the original dataset\ndef PerOfMissing(d1,d2):# d1--data by droping the NAN value d2--Original data\n    percent_of_missing_data = round( 100 - ((len(d1)\/len(d2))*100), 2)\n    percent_of_missing_data = str(percent_of_missing_data) + '% of data has Missing value'\n    return percent_of_missing_data\n\n# droping all the NAN value from the data and saving the data in data_without_NAN\ndata_without_NAN = employee_data.dropna()\nprint (PerOfMissing(data_without_NAN,employee_data))\n\nprint(null_data_rows[null_data_columns].head())\nprint(null_data_columns)\nmissing_val\n\n","acf9b49e":"# # 5 point summary on 'Absenteeism time in hours'\n# mean = df['Absenteeism time in hours'].mean()\n# # calculate quartiles\n# quartiles = percentile(df['Absenteeism time in hours'], [25, 50, 75])\n# # calculate min\/max\n# data_min, data_max = df['Absenteeism time in hours'].min(), df['Absenteeism time in hours'].max()\n# # print 5-number summary\n# print('Min: %.3f' % data_min)\n# print('Q1: %.3f' % quartiles[0])\n# print('Mean: %.3f' % mean)\n# print('Median: %.3f' % quartiles[1])\n# print('Q3: %.3f' % quartiles[2])\n# print('Max: %.3f' % data_max)\n\nsns.boxplot(data=df[['Body mass index']])\nfig=plt.gcf()\nfig.set_size_inches(5,5)\n","49e941f7":"# ['Distance from Residence to Work', 'Service time', 'Age', 'Work load Average\/day ', 'Transportation expense',\n#        'Hit target', 'Weight', 'Height', 'Body mass index', 'Absenteeism time in hours']\nsns.boxplot(data=df[['Absenteeism time in hours']])\nfig=plt.gcf()\nfig.set_size_inches(5,5)","2a10b521":"# Check the categorical data \nsns.set_style(\"whitegrid\")\nsns.catplot(data=df, x='Reason for absence', kind= 'count',size=4, aspect=4)\nsns.catplot(data=df, x='Seasons',y=\"Absenteeism time in hours\", size=2, aspect=2)\nsns.catplot(data=df, x='Education', kind= 'count', size=2, aspect=2)\n# Disciplinary failure                2\n# Education                           4\n# Son                                 5\n# Social drinker                      2\n# Social smoker                       2\n# Pet                                 6\n# Day of week and seasons\n\nsns.catplot(data=df, x='Education',y=\"Absenteeism time in hours\", hue= 'Disciplinary failure', size=8,aspect=2)","c07c2395":"#Check the distribution of numerical data using histogram\n# ['Distance from Residence to Work', 'Service time', 'Age', 'Work load Average\/day ', 'Transportation expense',\n#        'Hit target', 'Weight', 'Height', 'Body mass index', 'Absenteeism time in hours']\nplt.hist(data=df, x='Service time', bins='auto', label='Service time')\nplt.xlabel('Service time')\nplt.title(\"Service time Distribution\")","aac36eb5":"# Check the distribution of numerical data using histogram\nd_f = pd.DataFrame(df[continuous_attributes])\nhist = d_f.hist(bins=14, figsize=(17,15))","1dca55ce":"\n# plt.figure(figsize=(18,8))\nsns.jointplot(x='Absenteeism time in hours',y='Seasons',data=df)\nsns.jointplot(x='Absenteeism time in hours',y='Age',data=df)\nsns.jointplot(x='Absenteeism time in hours',y='Reason for absence',data=df)\n","77299ee4":"s = sns.FacetGrid(data=df,col='Son')\ns.map(plt.hist,'Absenteeism time in hours')","b05d4d72":"s = sns.FacetGrid(data=df,col='Education')\ns.map(plt.hist,'Absenteeism time in hours')","feeabab5":"s = sns.FacetGrid(data=df,col='Pet')\ns.map(plt.hist,'Absenteeism time in hours')","6c6d0923":"# checking the corellation between all the attributes\ncorrelation_matrix = df.corr().round(2)\nsns.heatmap(data=correlation_matrix, annot=True)","27d2dd0c":"# corellation using scatter plots\n\nplt.scatter(employee_data['Body mass index'], employee_data['Weight'], alpha=0.5)\nplt.title('Scatter plot Weight V\/S Body mass index')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()","e2df3018":"# corellation using scatter plots\n\nplt.scatter(employee_data['Age'], employee_data['Service time'], alpha=0.5)\nplt.title('Scatter plot pythonspot.com')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()","5c3e7a1e":"# Check for outliers using boxplots\n# Replace that with MEAN\n\nfor i in continuous_attributes:\n    # Getting 75 and 25 percentile of variable \"i\"\n    Q3, Q1 = np.percentile(data_without_NAN[i], [75,25])\n    MEAN = data_without_NAN[i].mean()\n    \n    # Calculating Interquartile range\n    IQR = Q3 - Q1\n    \n    # Calculating upper extream and lower extream\n    minimum = Q1 - (IQR*1.5)\n    maximum = Q3 + (IQR*1.5)\n    \n    # Replacing all the outliers value to Mean\n    data_without_NAN.loc[data_without_NAN[i]< minimum,i] = MEAN\n    data_without_NAN.loc[data_without_NAN[i]> maximum,i] = MEAN\n    ","8c956045":"# Return MAE, MRSE, R\u00b2, Adjusted R\u00b2\ndef Print_Analysis(y_true, y_pred):\n    print (\"Mean Square Error (MSE) of data: \", mean_squared_error(y_true,y_pred))\n    print (\"RMSE of data: \", sqrt(mean_squared_error(y_true,y_pred)))\n    print (\"R^2 Score(coefficient of determination) : \", r2_score(y_true,y_pred))\n    print ('MAE:',mean_absolute_error(y_true,y_pred))","6422a04b":"copy_data_without_NAN = copy.deepcopy(data_without_NAN)","45c5a4ea":"# Linear regression\n\n# Normalize the contineous models\nscaling_col = continuous_attributes \n# scaling_col = ['Transportation expense', 'Distance from Residence to Work',\n#               'Work load Average\/day ', 'Hit target','Body mass index']\n\nfor i in scaling_col:\n    data_without_NAN[i]=(data_without_NAN[i]-min(data_without_NAN[i]))\/(max(data_without_NAN[i])-min(data_without_NAN[i]))\n\ndata_without_NAN = data_without_NAN.drop(['Weight', 'Service time'],axis=1)\n    \nX = data_without_NAN.iloc[:, data_without_NAN.columns != 'Absenteeism time in hours']\ny = data_without_NAN['Absenteeism time in hours']\n\n\n#Splitting data into train and test data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.20, random_state = 0)\n# Importing libraries for Linear Regression\nfrom sklearn.linear_model import LinearRegression\n\n#Train the model\nlr_model = LinearRegression().fit(X_train , y_train)\n\n#Perdict for test cases\nlr_predictions = lr_model.predict(X_test)\n\n#Create data frame for actual and predicted values\ndf_lr = pd.DataFrame({'actual': y_test, 'pred': lr_predictions})\nprint(df_lr.head())\n\nPrint_Analysis(y_test, lr_predictions)\n\nprint('Intercept: \\n', lr_model.intercept_)\nprint('Coefficients: \\n', lr_model.coef_)\n","28a3a7e0":"# with statsmodels\n# Linear regression using ordinary least squares.(OLS)\n\nX = sm.add_constant(X) # adding a constant\n \nmodel = sm.OLS(y.astype(float),  X.astype(float)).fit()\npredictions = model.predict(X) \nprint_model = model.summary()\nprint(print_model)","813b6639":"# using SVM\n\ndata_without_NAN = copy.deepcopy(copy_data_without_NAN)\n# Normalize the contineous models\nscaling_col = continuous_attributes \n# scaling_col = ['Transportation expense', 'Distance from Residence to Work',\n#               'Work load Average\/day ', 'Hit target','Body mass index']\n\nfor i in scaling_col:\n    data_without_NAN[i]=(data_without_NAN[i]-min(data_without_NAN[i]))\/(max(data_without_NAN[i])-min(data_without_NAN[i]))\n\n# data_without_NAN = data_without_NAN.drop(['Weight', 'Service time'],axis=1)\nX = data_without_NAN.iloc[:, data_without_NAN.columns != 'Absenteeism time in hours']\ny = data_without_NAN['Absenteeism time in hours']\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.20, random_state = 0)\n\nlab_enc = preprocessing.LabelEncoder()\ny_encoded = lab_enc.fit_transform(y_train)\n\n# Fitting Support Vector Machine (SVM) to the opt Training set\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf')\nclassifier.fit(X_train, y_encoded)\n\n# predicting the test set result\ny_pred = classifier.predict(X_test)\n\n#Create data frame for actual and predicted values\ndf_lr = pd.DataFrame({'actual': y_test, 'pred': y_pred})\nprint(df_lr.head())\n\nPrint_Analysis(y_test, y_pred)","826755c5":"**Data mining of Employee Absentee data to increase productivit of the company** \n\nPredict the trend in absenteeism of employees of the online retailer **Amazing Zone** and what actions should the company undertake to reduce such absenteeism.\n\nThe database was created with records of absenteeism at work from July 2007 to July 2010 at a courier company in Brazil.\n\n***","efa9f156":"### Project Details\n\n- Language: Python v3\n","44d1051f":"# Absenteeism at Work\n***","1953bff0":"***\n### Data Exploration and Preparation\n***","3b80773c":"## Problem Statement\n    1. Business Context \nA big online retailer company \u201cAmazing Zone\u201d sells various products through their portal. One of the important feature of this business model is that the retailer takes responsibility of the shipment of the product. As the retailer takes guarantee that the purchased product will be delivered within promised timeline, customers are more inclined to purchase the products that has \u201cRetailer fulfilled\u201d tag associated with them. In order to keep the promise, the retailer has to invest heavily into the background shipment process that insures that the products are delivered to the customers before or on the guaranteed timeline. \n\n    2. Business Problem Understanding\nThe shipment process constitutes of several important components. The last mile delivery is carried out by the delivery boys, which are working on the company\u2019s payroll. They are considered as critical because they are the one who faces the customer while delivering the product. They play an important role to increase the customer\u2019s happiness by delivering the product before time, which improves upon the customer happiness index. These delivery personnel\u2019s are many times over-loaded with the task of the deliveries, as company cannot afford to lose the customer because of bad impression at time of delivery. Due to the heavy workload, these delivery boys are not able to perform to their optimum limits on every business day, which results into their absenteeism from the work, which in turn increases the load on the other delivery personnel\u2019s. This is not a good sign for the company as this influences the last mile delivery of the products. \nYou are the emerging analyst of data science department of company. You have been appointed to take a closer look at the absenteeism records of delivery personnel\u2019s and \n\n    - Identify the factors causing the absenteeism at work\n    - Suggest a model that can help to determine the absenteeism hours for an employee \n    - Suggest ways by which absenteeism can be reduced \n","dd4636bd":"## DATA\nThe data is gathered for three years absenteeism records of the delivery personnel\u2019s. You need to make utilization of the features presented in the data set for your task. The data set and a document containing the information about the attributes are attached with the assignment problem statement. You can also visit the following link to access the data set and relevant information. \n\nlink for [Data Set](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Absenteeism+at+work)\n\nMake yourself familiar with these attributes as these might help you in determining the contributing factors with respect to the successful product purchase.\n***","35fe52b3":"***\n### Import Data\n***","4648a420":"### Attribute Information\n***\nThere are 21 variables in our data in which 20 are independent variables and 1 (Absenteeism time in hours) is dependent variable. Since the type of target variable is continuous, this is a regression problem.\n\n    - Individual identification (ID)\n    - Reason for absence (ICD).\n\nAbsences attested by the International Code of Diseases (ICD) stratified into 21 categories (I to XXI) as follows: I Certain infectious and parasitic diseases II Neoplasms III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism IV Endocrine, nutritional and metabolic diseases V Mental and behavioural disorders VI Diseases of the nervous system VII Diseases of the eye and adnexa VIII Diseases of the ear and mastoid process IX Diseases of the circulatory system X Diseases of the respiratory system XI Diseases of the digestive system XII Diseases of the skin and subcutaneous tissue XIII Diseases of the musculoskeletal system and connective tissue XIV Diseases of the genitourinary system XV Pregnancy, childbirth and the puerperium XVI Certain conditions originating in the perinatal period XVII Congenital malformations, deformations and chromosomal abnormalities XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified XIX Injury, poisoning and certain other consequences of external causes XX External causes of morbidity and mortality XXI Factors influencing health status and contact with health services And 7 categories without (CID) patient follow-up (22), medical consultation (23), blood donation (24), laboratory examination (25), unjustified absence (26), physiotherapy (27), dental consultation (28).\n\n    - Month of absence\n    - Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n    - Seasons (summer (1), autumn (2), winter (3), spring (4))\n    - Transportation expense\n    - Distance from Residence to Work (KMs)\n    - Service time\n    - Age\n    - Work load Average\/day\n    - Hit target\n    - Disciplinary failure (yes=1; no=0)\n    - Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n    - Son (number of children)\n    - Social drinker (yes=1; no=0)\n    - Social smoker (yes=1; no=0)\n    - Pet (number of pet)\n    - Weight\n    - Height\n    - Body mass index\n    - Absenteeism time in hours (target)\n","c2e9572b":"Display Of Performance of regression model","ff518775":"***\n### CODE\n***"}}