{"cell_type":{"1e8fe79d":"code","7cbd5485":"code","b38de054":"code","5c3e0589":"code","eee99d22":"code","4ac77b83":"code","bf65bf96":"code","74abff53":"code","ba560705":"code","e43f6ec5":"code","e1e9448e":"code","8bf03257":"code","12c88970":"code","5c2f66c2":"code","032bb639":"code","32e49bc4":"code","448e6700":"markdown","dccdc78a":"markdown","29f5ea8e":"markdown","6eb716a6":"markdown","3d26c73d":"markdown","daf72062":"markdown","ed4f256b":"markdown","fdad9144":"markdown","bd9c743d":"markdown","25abdc44":"markdown","681c8080":"markdown","9fb34f5e":"markdown","3fe35901":"markdown","fb76f2d0":"markdown","c68d1247":"markdown","221003f4":"markdown","f38b97ca":"markdown","c488fa98":"markdown","1714169d":"markdown","dd9ad74d":"markdown","9e376409":"markdown","b5b93d40":"markdown","083a8224":"markdown"},"source":{"1e8fe79d":"import numpy as np\nimport plotly.graph_objects as go","7cbd5485":"class Gradient_descent():\n    def __init__(self):\n\n        self.beta = 0.6\n        self.p_0 = 1\n        self.function = None\n        self.x0 = None\n\n    def derivative(self, function, x, dx=1e-6):\n        return (self.function(x+dx) - self.function(x)) \/ dx\n\n    def gradient(self, function, x, dx=1e-6):\n        dim = x.shape[0]\n        grad = np.zeros(x.shape)\n        for i in range(dim):\n            right = x.copy().astype(float)\n            right[i, :] = right[i, :] + dx\n            grad[i, :] = (function(right) - function(x)) \/ dx\n\n        return grad\n\n    def gradient_descent(self, function, start_point, p_o, beta, iteration):\n        self.function = function\n        self.x0 = start_point\n        self.min_legend = []\n        # VALIDATE USER`S INPUTS\n        if p_o <= 0:\n            raise Exception(\"p_0 should be greater than 0\")\n        if not ((beta < 1) and (0.5 <= beta)):\n            raise Exception(\"beta should be in range(0.5,1)\")\n            # add validate on start_point(optional)\n\n        # ALGORITM\n        # 1\n        p_k = p_o\n        x_k = start_point\n        self.min_legend.append(x_k)\n        for k in range(iteration):\n            # 2\n            grad_f = self.gradient(function, x_k)\n            norm = np.linalg.norm(grad_f)\n            if grad_f.any() == 0:\n                return x_k\n                break\n            h_k = grad_f\/norm  # 3\n\n            p_k1 = p_k  # 4\n\n            flag = True\n            while flag:\n                x_k1 = x_k-p_k*h_k  # 5\n                self.min_legend.append(x_k)\n                if self.function(x_k1) < self.function(x_k):\n                    k = k+1\n                    flag = False\n                else:\n                    p_k = beta*p_k  # goto 5\n\n            x_k = x_k1\n            self.min_legend.append(x_k)\n        self.extr = x_k\n        return x_k, self.function(x_k)\n\n\n    def show_me_visualisation(self, parametr):\n\n        bound = 4  # need to be specified partiqulary\n        X = np.linspace(-bound, bound, 100)\n        Y = np.linspace(-bound, bound, 100)\n        Z = np.zeros((X.shape[0], Y.shape[0]))\n\n        x_ = []\n        y_ = []\n        z_ = []\n        for i in self.min_legend:\n            x_.append(float(i[0]))\n            y_.append(float(i[1]))\n            z_.append(float(self.function(i)))\n\n        X, Y = np.meshgrid(X, Y)\n        for i in range(X.shape[0]):\n            for j in range(X.shape[0]):\n                Z[i, j] = self.function(np.asarray((X[i, j], Y[i, j])))\n\n        if parametr == \"3D\":\n            trace = go.Surface(x=X, y=Y, z=Z)\n            data = [trace]\n            layout = go.Layout(title='3D Surface plot')\n            fig = go.Figure(data=data)\n            fig.update_traces(contours_z=dict(show=True, usecolormap=True,\n                                              highlightcolor=\"limegreen\", project_z=True))\n\n            fig.add_scatter3d(x=x_, y=y_, z=z_, marker=dict(\n                size=5, color=\"Pink\"), opacity=True)\n            fig.update_layout(width=1000, height=1000)\n\n                              \n        if parametr == \"countour\":\n            trace=go.Contour(z=Z)\n            data=[trace]\n            fig=go.Figure(data=data)\n\n            fig.add_scatter(x=x_, y=y_) #NEED TO FIX\n            fig.update_layout(title_text=\"{}heatmap\".format(parametr))\n            \n        fig.show()\n\n\n\ndef himmelblau(X):\n\n    output=(X[0]**2+X[1]-11)**2 + (X[0]+X[1]**2-7)**2\n\n    return output\n","b38de054":"# initialise start point\nstart = np.array([[-0.27], [-0.92]])","5c3e0589":"gd = Gradient_descent()\nmin_point, function_value = gd.gradient_descent(himmelblau,start_point=start,p_o=1,beta=1\/2,iteration=11)\nprint(f\"Min point is: \\t {min_point.T} \\\n        Value of function is {function_value}\")","eee99d22":"gd.show_me_visualisation(\"3D\")","4ac77b83":"import matplotlib.pyplot as plt","bf65bf96":"class Optimize:\n    def __init__(self):\n        self.methods_to_choose_step = {\n            \"naive\": self.naive,\n            \"newton\": self.newton,\n            \"golden\": self.golden,\n            \"built\": self.built_min,\n        }\n        self.methods_to_choose_direction = {\n            \"CG\": self.reset,\n            \"GD\": self.antigradient,\n        }\n\n    def derivative(self, function, x, dx=1e-6, order=1):\n        if order == 0:\n            return function(x)\n\n        return (self.derivative(function, x + dx, dx, order - 1) - self.derivative(function, x, dx, order - 1)) \/ dx\n\n    def gradient(self, x, dx=1e-6):\n        dim = x.shape[0]\n        grad = np.zeros(x.shape)\n        for i in range(dim):\n            right = x.copy().astype(float)\n            right[i, :] = right[i, :] + dx\n            grad[i, :] = (self.function(right) - self.function(x)) \/ dx\n\n        return grad\n\n    def __call__(self, function, x0, method, threshold=None, iters_num=None, visualize=False, **kwargs):\n        self.function = function\n        step = self.methods_to_choose_step[\"built\"]\n        Direction = self.methods_to_choose_direction[method]\n\n        period = None\n        if method == \"CG\":\n            period = kwargs[\"period\"]\n\n        counter = 0\n        args = None\n        func = None\n        steps = None\n        dirs = None\n        if visualize:\n            args = np.array(x0.T)\n            func = np.array([function(x0)])\n            steps = np.zeros(1)\n            dirs = np.array([])\n\n        x = x0\n        extr = x\n        if (threshold and iters_num) or (not threshold and not iters_num):\n            raise Exception(\"You must specify either number of iterations or threshold.\")\n\n        if not threshold:\n            direction = - self.gradient(extr)\n            for i in range(iters_num):\n                if np.linalg.norm(self.gradient(extr)) == 0:\n                    break\n\n                direction = Direction(x=x, x_next=extr, direction=direction, iteration=i, period=period)\n                s = step(extr, direction)\n                if s == 0:\n                    #                     print(\"Zero step\")\n                    break\n                x = extr\n                extr = x + s * direction\n\n                if visualize:\n                    args = np.vstack((args, extr.T))\n                    func = np.append(func, function(extr))\n                    steps = np.append(steps, s)\n                    dirs = np.append(dirs, np.linalg.norm(direction))\n                    counter += 1\n\n        elif not iters_num:\n            direction = -self.gradient(extr)\n            i = 0\n            while np.linalg.norm(self.gradient(extr)) > threshold:\n                direction = Direction(x=x, x_next=extr, direction=direction, iteration=i, period=period)\n                s = step(extr, direction)\n                if s == 0:\n                    #                     print(\"Zero step\")\n                    break\n\n                x = extr\n                extr = x + s * direction\n                i += 1\n\n                if visualize:\n                    args = np.vstack((args, extr.T))\n                    func = np.append(func, function(extr))\n                    steps = np.append(steps, s)\n                    dirs = np.append(dirs, np.linalg.norm(direction))\n                    counter += 1\n\n        if visualize:\n            print(f\"\\nTotal number of steps: {counter}\\n\" +\n                  f\"Found extrema: ~({round(extr[0, 0], 3)}, {round(extr[1, 0], 3)})\\n\" +\n                  f\"Function value in extrema: ~{round(float(np.squeeze(function(extr))), 3)}\\n\")\n\n            if counter > 0:\n                x = np.array([p[0] for p in args])\n                y = np.array([p[1] for p in args])\n\n                gridsize = (3, 5)\n                fig = plt.figure(figsize=(20, 12))\n                ax1 = plt.subplot2grid(gridsize, (0, 0), colspan=3, rowspan=3,\n                                       projection=\"3d\")  # add_subplot(221, projection='3d')\n                ax3 = plt.subplot2grid(gridsize, (0, 3), colspan=2, rowspan=2)  # add_subplot(222)\n                ax2 = plt.subplot2grid(gridsize, (2, 3), colspan=1, rowspan=1,\n                                       title=\"Step\")  # add_subplot(223, title=\"Steps\")\n                ax4 = plt.subplot2grid(gridsize, (2, 4), colspan=1, rowspan=1,\n                                       title=\"Function descent\")  # add_subplot(224, title=\"Function descent\")\n                ax2.grid(True)\n                ax4.grid(True)\n\n                bound = max(np.max(np.abs(extr)), np.max(np.abs(x0))) + 1  # max(np.max(np.abs(x)), np.max(np.abs(y)))\n                X = np.linspace(-bound, bound, 100)\n                Y = np.linspace(-bound, bound, 100)\n                Z = np.zeros((X.shape[0], Y.shape[0]))\n                X, Y = np.meshgrid(X, Y)\n                for i in range(X.shape[0]):\n                    for j in range(X.shape[0]):\n                        Z[i, j] = function(np.asarray((X[i, j], Y[i, j])))\n\n                ax1.view_init(60, -30)\n                ax1.plot_surface(X, Y, Z, cmap=\"jet\", alpha=0.5)\n                ax1.plot(x, y, func, \"black\")\n\n                ax2.plot(np.arange(1, counter + 1), steps[1:])\n                ax4.plot(np.arange(counter + 1), func)\n\n                cp = ax3.contour(X, Y, Z, 10)\n                plt.clabel(cp, inline=1, fontsize=10)\n                ax3.plot(x, y, \"-o\")\n\n        return extr\n\n    ########################################\n    ### Methods to choose step:\n    ########################################\n\n    def naive(self, x, direction):\n        steps = np.arange(.0, 1, .001)\n        func = np.vectorize(lambda p: self.function(x + p * direction))\n        f = func(steps)\n        minima_idx = np.argsort(f)[0]\n\n        return steps[minima_idx]\n\n    def newton(self, X, direction, threshold=None, iters_num=100):\n        f = lambda p: self.function(X + p * direction)\n        x = 0\n        x_new = x\n\n        if (threshold and iters_num) or (not threshold and not iters_num):\n            raise Exception(\"You must specify either number of iterations or threshold.\")\n\n        if not threshold:\n            for i in range(iters_num):\n                der1 = self.derivative(f, x)\n                der2 = self.derivative(f, x, order=2)\n                assert (der2 != 0)\n\n                x_new = x - der1 \/ der2\n\n        elif not iters_num:\n            der1 = self.derivative(f, x)\n            while abs(der1) > threshold:\n                der2 = self.derivative(f, x, order=2)\n                assert (der2 != 0)\n\n                x_new = x - der1 \/ der2\n                der1 = self.derivative(f, x)\n\n        return x_new\n\n    def golden(self, x, direction, threshold=1e-6, iters_num=None):\n        f = lambda p: np.squeeze(self.function(x + p * direction))\n        alpha = (3 - np.sqrt(5)) \/ 2\n        a = 0\n        b = 1\n        x1 = a + alpha * (b - a)\n        x2 = a + b - x1\n        x_new = 0\n\n        if (threshold and iters_num) or (not threshold and not iters_num):\n            raise Exception(\"You must specify either number of iterations or threshold.\")\n\n        if not threshold:\n            for i in range(iters_num):\n                if f(x1) <= f(x2):\n                    b = x2\n                    x1 = a + b - x1\n                    x2 = x1\n                else:\n                    a = x1\n                    x1 = x2\n                    x2 = a + b - x2\n\n                x_new = (a + b) \/ 2\n\n        elif not iters_num:\n            while b - a > threshold:\n                if f(x1) <= f(x2):\n                    b = x2\n                    x1 = a + b - x1\n                    x2 = x1\n                else:\n                    a = x1\n                    x1 = x2\n                    x2 = a + b - x2\n\n                delta = x_new - (a + b) \/ 2\n                x_new = (a + b) \/ 2\n\n        return x_new\n\n    def built_min(self, x, direction):\n        from scipy.optimize import minimize\n\n        f = lambda p: np.squeeze(self.function(x + p * direction))\n        return minimize(f, 0, bounds=[(0, np.inf)]).x\n\n    ########################################\n    ### Methods to choose direction:\n    ########################################\n\n    def antigradient(self, **kwargs):\n        x = kwargs[\"x_next\"]\n\n        return - self.gradient(x)\n\n    def reset(self, **kwargs):\n        x = kwargs[\"x\"]\n        x_next = kwargs[\"x_next\"]\n        direction = kwargs[\"direction\"]\n        iteration = kwargs[\"iteration\"]\n        period = kwargs[\"period\"]\n\n        next_dir = None\n        if 1 - ((iteration + 1) % period):\n            aux1 = - self.gradient(x)\n            aux2 = - self.gradient(x_next)\n            coeff = np.dot(aux2.T, aux1) \/ np.dot(aux1.T, aux1) - 1\n            next_dir = aux2 + coeff * direction\n        else:\n            next_dir = - self.gradient(x_next)\n\n        return next_dir","74abff53":"minimize = Optimize()\nhimm = lambda x: (x[0] ** 2 + x[1] - 11) ** 2 + (x[0] + x[1] ** 2 - 7) ** 2\nrosen = lambda x: (1 - x[0]) ** 2 + 100 * (x[1] - x[0]**2) ** 2\ncirc = lambda x: np.sum(x ** 2)\nrastrigin = lambda x: x[0]**2 + x[1]**2 - np.cos(18*x[0]) - np.cos(18*x[1])\nbill = lambda x: (1.5 - x[0] - x[0] * x[1]) ** 2 + (2.25 - x[0] - x[0] * x[1] ** 2) ** 2 + (2.625 - x[0] - x[0] * x[1] ** 3) ** 2\nboot = lambda x: (x[0] + 2*x[1] - 7) ** 2 + (2*x[0] + x[1] - 5) ** 2","ba560705":"start = np.array([[-0.27], [-0.92]])\n\na = minimize(himm, start, method=\"GD\", threshold=1e-6, visualize=True)","e43f6ec5":"start = -2 * np.ones((2, 1))\n\na = minimize(rosen, start, method=\"CG\", threshold=1e-6, period=2, visualize=True)","e1e9448e":"import numpy as np\nimport copy\nimport pylab\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n","8bf03257":"# defining test functions\n\ndef func(x):\n    return x[0]**2+x[1]**2-np.cos(18*x[0])-np.cos(18*x[1])\n\ndef func1(x):\n    return (x[0]**2+x[1]**2)\n\ndef func4(x):\n    return (x[0]*x[1]*np.sin(x[0]**2+x[1]**2))","12c88970":"def create_antibody(quan, leng, dim):\n    population = [np.random.choice([0, 1], size=(dim, leng)) for x in range (quan)]\n    return population\n\ndef convert(antibody, area):# \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0438 - \u043a\u043e\u0434 \u0413\u0440\u0456\u043d\u0430 -> \u043a-\u0442\u0438 - \u0434\u0456\u0439\u0441\u043d\u0456 \u0447\u0438\u0441\u043b\u0430\n    x = []\n    for i in range (0,len(antibody)):\n        summ=0\n        for k in range (len(antibody[i])):\n            summ+=antibody[i][k]*2**k \n        x.append(summ)\n        x[i]=area[i][0]+x[i]*((area[i][1]-area[i][0])\/(2**len(antibody[i])-1))\n    return x\n\ndef affinity(dec_antibody,function):\n    return function(dec_antibody)\n\ndef clone(population, quan_c):\n    return [[copy.copy(population[i]) for x in range (quan_c)] for i in range(len(population))]\n\ndef mutate(clones, prob):\n    num = int(prob*len(clones[0][0][0]))\n    for s in range(len(clones)):\n        for i in range(len(clones[s])):\n            for n in range (0,len(clones[s][i])):\n                el = np.random.choice(range(0,len(clones[s][i][n])),num, replace=False)\n                for p in el:\n                    clones[s][i][n][p]=int(not(clones[s][i][n][p]))\n    return clones\n\ndef select(clones,aff):\n    final_clones=[clones[i][aff[i].index(min(aff[i]))] for i in range(len(clones))]\n    return final_clones\n\ndef replace(population, final_clones, aff_ant, aff_c):\n    for i in range(len(population)):\n        if aff_ant[i]>aff_c[i]:\n            population[i]=final_clones[i]\n            aff_ant[i]=aff_c[i]\n            \ndef edit(population,d,func,leng,dim,aff_ant):\n    for i in range(d):\n        num = aff_ant.index(max(aff_ant))\n        del(aff_ant[num])\n        del(population[num])\n    population+=create_antibody(d, leng, dim)","5c2f66c2":"def clon_alg(func, quan, leng, dim, area, prob, quan_c, gen, d):\n    population=create_antibody(quan, leng, dim)\n    for number in range(0,gen):\n        con_ant=[]\n        for i in range(quan):\n            con_ant.append(convert(population[i],area))\n            for k in range(dim):\n                xdot[k].append(con_ant[i][k])\n        aff_ant=[affinity(con_ant[i],func) for i in range(quan)]\n        zdot.extend(aff_ant)\n        clones = mutate(clone(population,quan_c),prob)\n        aff_c=[[affinity(convert(clones[s][i],area),func) for i in range(quan_c)] for s in range(quan)]\n        clones=select(clones,aff_c)\n        for i in range(quan):\n            aff_c[i]=min(aff_c[i])\n        replace(population, clones, aff_ant, aff_c)\n        edit(population,d,func,leng,dim,aff_ant)\n    ans=population[aff_ant.index(min(aff_ant))]\n    return convert(ans, area)","032bb639":"xdot=[]\n[xdot.append([]) for i in range(2)]\nzdot=[]\nclon_alg(func4, 100, 22, 2, [[-1,1],[-1,1]], 0.3, 10, 50, 5)","32e49bc4":"def makeData ():\n    x = np.arange (-1, 1, 0.001)\n    y = np.arange (-1, 1, 0.001)\n    xgrid, ygrid = np.meshgrid(x, y)\n\n    zgrid = func4([xgrid,ygrid])\n    return xgrid, ygrid, zgrid\n\nx, y, z = makeData()\n\nfig = pylab.figure()\naxes = Axes3D(fig)\n\naxes.scatter(xdot[0],xdot[1],zdot,c='b',s=20)\naxes.plot_surface(x, y, z,color='c', alpha = 0.3)\n\nfig.set_figwidth(14)\nfig.set_figheight(14)\n\npylab.show()","448e6700":"2) \u0437\u043d\u0430\u0439\u0442\u0438 \u0432\u0456\u0434\u043f\u043e\u0432\u0456\u0434\u043d\u0435 \u0434\u0432\u0456\u0439\u043a\u043e\u0432\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f x:\n$$x=x_{min}+x'\\frac{x_{max} - x_{min}}{2^L-1},$$\n\u0434\u0435 $x_{max},x_{min}$ - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0435 \u0456 \u043c\u0456\u043d\u0456\u043c\u0430\u043b\u044c\u043d\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044f \u0437\u043c\u0456\u043d\u043d\u043e\u0457 \u0437 \u043e\u0431\u043b\u0430\u0441\u0442\u0456 \u0434\u043e\u0441\u043b\u0456\u0434\u0436\u0435\u043d\u043d\u044f \u0444\u0443\u043d\u043a\u0446\u0456\u0457","dccdc78a":"\u041e\u0431\u043b\u0430\u0441\u0442\u0456 \u0437\u0430\u0441\u0442\u043e\u0441\u0443\u0432\u0430\u043d\u043d\u044f \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0443 CLONALG:\n* \u0440\u043e\u0437\u043f\u0456\u0437\u043d\u0430\u0432\u0430\u043d\u043d\u044f \u043e\u0431\u0440\u0430\u0437\u0456\u0432 (\u0431\u0456\u043d\u0430\u0440\u043d\u0438\u0445 \u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u044c);\n* \u043e\u043f\u0442\u0438\u043c\u0456\u0437\u0430\u0446\u0456\u044f \u043c\u0443\u043b\u044c\u0442\u0438\u043c\u043e\u0434\u0430\u043b\u044c\u043d\u0438\u0445 \u0444\u0443\u043d\u043a\u0446\u0456\u0439;\n* \u043a\u043e\u043c\u0431\u0456\u043d\u0430\u0442\u043e\u0440\u043d\u0430 \u043e\u043f\u0442\u0438\u043c\u0456\u0437\u0430\u0446\u0456\u044f (\u0437\u0430\u0434\u0430\u0447\u0430 \u043a\u043e\u043c\u0456\u0432\u043e\u044f\u0436\u0435\u0440\u0430). ","29f5ea8e":"3. $z=x^2+y^2-cos(18x)-cos(18y)$\n\n\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0440\u043e\u0431\u043e\u0442\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0443:(0.002825976091856086, -0.0016686920329790356)\n\n![image.png](attachment:image.png)","6eb716a6":"# \u041c\u0435\u0442\u043e\u0434 \u0441\u043f\u0440\u044f\u0436\u0435\u043d\u0438\u0445 \u0433\u0440\u0430\u0434\u0456\u0454\u043d\u0442\u0456\u0432\n\n\u0420\u043e\u0431\u043e\u0442\u0430 \u043c\u0435\u0442\u043e\u0434\u0443 \u043f\u043e\u0447\u0438\u043d\u0430\u0454\u0442\u044c\u0441\u044f \u0437\u0456 \u0437\u0434\u0456\u0439\u0441\u043d\u0435\u043d\u043d\u044f \u0432\u0438\u0431\u043e\u0440\u0443 \u043f\u043e\u0447\u0430\u0442\u043a\u043e\u0432\u043e\u0433\u043e \u043d\u0430\u0431\u043b\u0438\u0436\u0435\u043d\u043d\u044f $x^{0}\\in R^n$,\n\n\u043d\u0430\u0442\u0443\u0440\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0447\u0438\u0441\u043b\u0430 $\\tau \\geq n $ (\u0434\u0435 $\\tau$ \u043c\u043e\u043c\u0435\u043d\u0442 \u0432\u0456\u0434\u043d\u043e\u0432\u043b\u0435\u043d\u043d\u044f),\n\n\u0442\u0430 \u043f\u043e\u0447\u0430\u0442\u043a\u043e\u0432\u043e\u0433\u043e $k=0$.\n\n\u0414\u0430\u043b\u0456 \u043e\u0431\u0447\u0438\u0441\u043b\u044e\u0454\u0442\u044c\u0441\u044f $\\nabla f_0 (x^0)$ \u0442\u0430 \u0432\u0438\u0437\u043d\u0430\u0447\u0430\u044e\u0442\u044c\u0441\u044f \u043d\u0430\u0441\u0442\u0443\u043f\u043d\u0456 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0438:\n\n$g^0=-\\nabla f_0(x^0)$,\n\n$h^0=-\\nabla f_0(x^0)$.\n\n$(1)$ \u0411\u0435\u0440\u0435\u0442\u044c\u0441\u044f \u043a\u0440\u043e\u043a\u043e\u0432\u0438\u0439 \u043c\u043d\u043e\u0436\u043d\u0438\u043a $\\rho$, \u0449\u043e \u0437\u0430\u0434\u043e\u0432\u0456\u043b\u044c\u043d\u044f\u0442\u0438\u043c\u0435 \u0443\u043c\u043e\u0432\u0443 $$f_0 (x^k + \\rho_k h^k)=min_{\\rho \\geq0} f_0 (x^k + \\rho h^k)$$. \n\n\u0417\u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f $x^{k+1}=x^k+\\rho_k h^k$.\n\n\u0422\u0435\u043f\u0435\u0440 \u043e\u0431\u0447\u0438\u0441\u043b\u044e\u0454\u0442\u044c\u0441\u044f $\\nabla f_0 (x^{k+1})$, \u0442\u0430 \u0432\u0438\u0437\u043d\u0430\u0447\u0430\u0454\u0442\u044c\u0441\u044f \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430 $g^{k+1}=- \\nabla f_0 (x^{k+1})$.\n\n\u042f\u043a\u0449\u043e \u0432\u0438\u044f\u0432\u043b\u044f\u0454\u0442\u044c\u0441\u044f \u0449\u043e $g^{k+1}=0$, \u0430\u043b\u0433\u043e\u0440\u0438\u043c \u0432\u0432\u0430\u0436\u0430\u0454\u0442\u044c\u0441\u044f \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u043c, \u0430 $x^*=x^{k+1}$. \u042f\u043a\u0449\u043e \u0436 \u043d\u0456, \u0432\u0438\u043a\u043e\u043d\u0443\u044e\u0442\u044c\u0441\u044f \u043d\u0430\u0441\u0442\u0443\u043f\u043d\u0456 \u043a\u0440\u043e\u043a\u0438.\n\n\u0417 \u0444\u043e\u0440\u043c\u0443\u043b\u0438 $$\\beta_k = w (\\frac{k+1}{\\tau}) \\frac{(g^{k+1}-g^k, g^{k+1})}{(g^k, g^k)}$$ \u043e\u0442\u0440\u0438\u043c\u0443\u0454\u0442\u044c\u0441\u044f \u043a\u043e\u0435\u0444\u0456\u0446\u0456\u0454\u043d\u0442 $\\beta_k$, \u0434\u0435\n\n$$\nw(t) = \\left\\{\n    \\begin{array}{ll}\n        0, & t \\in Z \\\\\n        1, & t \\notin Z\n    \\end{array}\n\\right.\n$$\n\n\u0417\u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f \u0432\u0435\u043a\u0442\u043e\u0440 $h^{k+1}=g^{k+1}+ \\beta_k h^k$.\n\u041f\u043e\u043a\u043b\u0430\u0434\u0430\u0454\u0442\u044c\u0441\u044f $k=k+1$, \u0456 \u0437\u0434\u0456\u0439\u0441\u043d\u044e\u0454\u0442\u044c\u0441\u044f \u043f\u0435\u0440\u0435\u0445\u0456\u0434 \u043d\u0430 \u043a\u0440\u043e\u043a $(1)$","3d26c73d":"2. $z=x(e^{-x^2-y^2})$\n\n\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0440\u043e\u0431\u043e\u0442\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0443:(-0.7167317191914844, 0.011737349447571432)\n\n![image.png](attachment:image.png)\n","daf72062":"#### Code implemintation  \n","ed4f256b":"## \u0413\u0440\u0430\u0434\u0456\u0435\u043d\u0442\u043d\u0438\u0439 \u0441\u043f\u0443\u0441\u043a \u0437 \u043f\u043e\u0434\u0440\u0456\u0431\u043d\u0435\u043d\u043d\u044f\u043c \u043a\u0440\u043e\u043a\u0443","fdad9144":"1. $z=(x^2+y^2-11)^2+(x+y^2-7)^2$- \u0444\u0443\u043d\u043a\u0446\u0456\u044f \u0425\u0456\u043c\u043c\u0435\u043b\u044c\u0431\u043b\u0430\u0443 \n\n\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0440\u043e\u0431\u043e\u0442\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0443:(3.0026466852776252, 2.018511776569314)\n\n![image.png](attachment:image.png)","bd9c743d":"#### Code implemintation  ","25abdc44":"\u041c\u0435\u0442\u043e\u0434 \u043f\u043e\u0447\u0438\u043d\u0430\u0454 \u0441\u0432\u043e\u044e \u0440\u043e\u0431\u043e\u0442\u0443 \u0437 \u0434\u0435\u044f\u043a\u043e\u0457 \u0434\u043e\u0432\u0456\u043b\u044c\u043d\u043e \u043e\u0431\u0440\u0430\u043d\u043e\u0457 \u0442\u043e\u0447\u043a\u0438 $x^1 \\in R^n$, \n\n\u0434\u043e\u0432\u0456\u043b\u044c\u043d\u043e\u0433\u043e \u043c\u043d\u043e\u0436\u043d\u0438\u043a\u0430 $\\beta \\in [ 1\/2; 1)$, \n\n\u0434\u043e\u0432\u0456\u043b\u044c\u043d\u043e\u0457 \u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u0438 $\\rho_0 > 0$, \n\n\u0442\u0430 \u043f\u043e\u0447\u0430\u0442\u043a\u043e\u0432\u043e\u0433\u043e $k=1$. \n\n$(1)$ \u041f\u0440\u043e\u0432\u043e\u0434\u044f\u0442\u044c\u0441\u044f \u043e\u0431\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f $\\nabla f_0(x^k)$ \u0442\u0430 $||\\nabla f_0(x^k)||$.\n\n\u0414\u0430\u043b\u0456 \u0437\u0430 \u0444\u043e\u0440\u043c\u0443\u043b\u043e\u044e $h^k=\\frac{\\nabla f_0(x^k)}{||\\nabla f_0 (x^k)||}$ \u043e\u0431\u0447\u0438\u0441\u043b\u044e\u0454\u0442\u044c\u0441\u044f \u043e\u0434\u0438\u043d\u0438\u0447\u043d\u0438\u0439 \u0432\u0435\u043a\u0442\u043e\u0440.\n\n$(2)$ \u0414\u043b\u044f \u043e\u0431\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f $x^{k+1}$ \u0432\u0438\u0437\u043d\u0430\u0447\u0438\u043c\u043e $\\rho_k=\\rho_{k-1}$ \u0442\u0430 \u0437\u043d\u0430\u0439\u0434\u0435\u043c\u043e $x^{k+1}=x^k- \\rho_k h^k$.\n\n\u041f\u0435\u0440\u0435\u0432\u0456\u0440\u044f\u0454\u043c\u043e \u0447\u0438 \u043f\u0440\u0430\u0432\u0434\u0436\u0443\u0454\u0442\u044c\u0441\u044f \u043d\u0435\u0440\u0456\u0432\u043d\u0456\u0441\u0442\u044c $f_0(x^{k+1})<f_0(x^k)$ \u0442\u0430, \u0432 \u0440\u0430\u0437\u0456 \u0432\u0438\u043a\u043e\u043d\u0430\u043d\u043d\u044f, \u0437\u0431\u0456\u043b\u044c\u0448\u0443\u0454\u043c\u043e $k=k+1$ \u0442\u0430 \n\n\u043f\u0435\u0440\u0435\u0445\u043e\u0434\u0438\u043c\u043e \u043d\u0430 \u043a\u0440\u043e\u043a $(1)$. \u0412 \u043f\u0440\u043e\u0442\u0438\u043b\u0435\u0436\u043d\u043e\u043c\u0443 \u0432\u0438\u043f\u0430\u0434\u043a\u0443 \u043f\u0435\u0440\u0435\u0432\u0438\u0437\u043d\u0430\u0447\u0430\u0454\u043c\u043e $\\rho_k = \\beta \\rho_k$ \u0442\u0430 \u043f\u043e\u0432\u0435\u0440\u0442\u0430\u0454\u043c\u043e\u0441\u044f \u0434\u043e \u043e\u0431\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f $x^{k+1}$ (\u043a\u0440\u043e\u043a $(2)$).\n\n\u0410\u043b\u0433\u043e\u0440\u0438\u043c \u0437\u0430\u0432\u0435\u0440\u0448\u0443\u0454\u0442\u044c\u0441\u044f \u043a\u043e\u043b\u0438 $\\nabla f_0(x^k)=0$. \n\n\u0422\u043e\u0434\u0456 $x^*=x^k$.","681c8080":"\u0412 \u0440\u0435\u0430\u043b\u0456\u0437\u0430\u0446\u0456\u0457 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0443 \u0431\u0443\u043b\u0438 \u0432\u0438\u043a\u043e\u0440\u0438\u0441\u0442\u0430\u043d\u0456 \u0442\u0430\u043a\u0456 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0438: \n* quan=100 - \u043a\u0456\u043b\u044c\u043a\u0456\u0441\u0442\u044c \u0430\u043d\u0442\u0438\u0442\u0456\u043b \u0432 \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u0457 \n* leng=22- \u0434\u043e\u0432\u0436\u0438\u043d\u0430 \u0431\u0456\u0442\u043e\u0432\u043e\u0433\u043e \u0441\u043b\u043e\u0432\u0430 \n* dim=2- \u0440\u043e\u0437\u043c\u0456\u0440\u043d\u0456\u0441\u0442\u044c area - \u043e\u0431\u043b\u0430\u0441\u0442\u044c \u0432\u0438\u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044f, \u044f\u043a\u0443 \u0434\u043e\u0441\u043b\u0456\u0434\u0436\u0443\u0454\u043c\u043e \n* prob=0.4 - \u0439\u043c\u043e\u0432\u0456\u0440\u043d\u0456\u0441\u0442\u044c \u043c\u0443\u0442\u0430\u0446\u0456\u0457\n* quan_c=10 - \u043a\u0456\u043b\u044c\u043a\u0456\u0441\u0442\u044c \u043a\u043b\u043e\u043d\u0456\u0432 \u043a\u043e\u0436\u043d\u043e\u0433\u043e \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0430\n* gen=70 - \u043a\u0456\u043b\u044c\u043a\u0456\u0441\u0442\u044c \u043f\u043e\u043a\u043e\u043b\u0456\u043d\u044c\n* d =8 - \u043a\u0456\u043b\u044c\u043a\u0456\u0441\u0442\u044c \u0430\u043d\u0442\u0438\u0442\u0456\u043b \u0437 \u043d\u0430\u0439\u0433\u0456\u0440\u0448\u043e\u044e \u0430\u0444\u0444\u0456\u043d\u0456\u0441\u0442\u044e, \u044f\u043a\u0456 \u0437\u0430\u043c\u0456\u043d\u044f\u044e\u0442\u044c\u0441\u044f \u043d\u0430 \u0440\u0430\u043d\u0434\u043e\u043c\u043d\u0456 \u0431\u0456\u0442\u043e\u0432\u0456 \u0440\u044f\u0434\u043a\u0438","9fb34f5e":"Output","3fe35901":"Visualisation (using Plotly)","fb76f2d0":"# Lab 1 optimization \n\n## prepared by Artur Markov, Pavel Pelikh, Polina Ptukha\n","c68d1247":"![image.png](attachment:image.png)","221003f4":"# Task to implement&analyze: \n* Step split gradient descent\n* Faststest decsent\n* Nonlinear conjugate gradient method\n* ClonAlg","f38b97ca":"# \u041c\u0435\u0442\u043e\u0434 \u043d\u0430\u0439\u0448\u0432\u0438\u0434\u0448\u043e\u0433\u043e \u0441\u043f\u0443\u0441\u043a\u0443\n\n\u041d\u0435\u0445\u0430\u0439 $f(x)$ *\u043e\u043f\u0443\u043a\u043b\u0430* \u0434\u0438\u0444\u0435\u0440\u0435\u043d\u0446\u0456\u0439\u043e\u0432\u0430\u043d\u0430 \u043d\u0430 \u0432\u0441\u044c\u043e\u043c\u0443 $n$-\u0432\u0438\u043c\u0456\u0440\u043d\u043e\u043c\u0443 \u0435\u0432\u043a\u043b\u0456\u0434\u043e\u0432\u043e\u043c\u0443 \u043f\u0440\u043e\u0441\u0442\u043e\u0440\u0456.\n\n\n>*\u041e\u043f\u0443\u043a\u043b\u0430 \u0444\u0443\u043d\u043a\u0446\u0456\u044f* - \u0442\u0430\u043a\u0430 \u0444\u0443\u043d\u043a\u0446\u0456\u044f, \u0449\u043e \u0437\u0430\u0434\u0430\u043d\u0430 \u043d\u0430 *\u043e\u043f\u0443\u043a\u043b\u0456\u0439 \u043c\u043d\u043e\u0436\u0438\u043d\u0456* $U$ \u0442\u0430 \u0434\u043b\u044f \u0431\u0443\u0434\u044c-\u044f\u043a\u0438\u0445 \u0434\u0432\u043e\u0445 \u0442\u043e\u0447\u043e\u043a $x^{(1)},x^{(2)} \\in U$ \u0456  \u0434\u043e\u0432\u0456\u043b\u044c\u043d\u043e\u0433\u043e \u0447\u0438\u0441\u043b\u0430 $\\alpha \\in [0;1]$ \u0432\u0438\u043a\u043e\u043d\u0443\u0454\u0442\u044c\u0441\u044f \u043d\u0435\u0440\u0456\u0432\u043d\u0456\u0441\u0442\u044c:  $f[\\alpha x^{(1)}+(1-\\alpha)x^2]\\leq \\alpha f(x^{(1)})+(1-\\alpha)f(x^{(2)})$\n\n\n>*\u041e\u043f\u0443\u043a\u043b\u0430 \u043c\u043d\u043e\u0436\u0438\u043d\u0430* - \u0442\u0430\u043a\u0430 \u043c\u043d\u043e\u0436\u0438\u043d\u0430 $U$, \u0449\u043e \u0440\u0430\u0437\u043e\u043c \u0437 \u0434\u0432\u043e\u043c\u0430 \u0442\u043e\u0447\u043a\u0430\u043c\u0438 $x^{(1)}, x^{(2)} \\in U$, \u043c\u0456\u0441\u0442\u0438\u0442\u044c \u0432 \u0441\u043e\u0431\u0456 \u0439 \u043f\u043e\u0454\u0434\u043d\u0443\u044e\u0447\u0438\u0439 \u0457\u0445 \u0432\u0456\u0434\u0440\u0456\u0437\u043e\u043a, \u0442\u043e\u0431\u0442\u043e $\\alpha x^{(1)}+(1-\\alpha)x^{(2)} \\in U $ \u0434\u043b\u044f \u0443\u0441\u0456\u0445 $\\alpha \\in [0;1]$\n\n\u041e\u0431\u0440\u0430\u0432\u0448\u0438 \u0434\u043e\u0432\u0456\u043b\u044c\u043d\u0435 \u043f\u043e\u0447\u0430\u0442\u043a\u043e\u0432\u0435 \u043d\u0430\u0431\u043b\u0438\u0436\u0435\u043d\u043d\u044f $x^{(0)}$ \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u0438\u043c\u043e \u043f\u043e\u0441\u043b\u0456\u0434\u043e\u0432\u043d\u0456\u0441\u0442\u044c \n\n$x^{(k+1)}=x^{(k)}-\\alpha_k f'(x^{(k)}),  k=0, 1, ...$\n\u0412\u0438\u0431\u0456\u0440 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0438\u0447\u043d\u0438\u0445 \u043a\u0440\u043e\u043a\u0456\u0432 $\\alpha_k$ \u0437\u0434\u0456\u0439\u0441\u043d\u044e\u0454\u0442\u044c\u0441\u044f \u0437\u0433\u0456\u0434\u043d\u043e \u0443\u043c\u043e\u0432\u0438 \n\n(1)  $f(x^{(k+1)})<f(x^{k})$\n\n\u041e\u0431\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f \u0432\u0438\u043a\u043e\u043d\u0443\u044e\u0442\u044c\u0441\u044f \u0434\u043e\u0442\u0438, \u0434\u043e\u043a\u0438 \u0433\u0440\u0430\u0434\u0456\u0454\u043d\u0442 $f'(x^{(k)})$ \u043d\u0435 \u0431\u0443\u0434\u0435 *\u0434\u043e\u0441\u0442\u0430\u0442\u043d\u044c\u043e* \u0431\u043b\u0438\u0437\u044c\u043a\u0438\u0439 \u0434\u043e \u043d\u0443\u043b\u044f, \u0430 \u0441\u0430\u043c\u0435:\n\n$|\\frac{\\partial f(x^{(k)})}{\\partial x_i}|\\leq \\varepsilon$\n\n\n\u041d\u0430\u0432\u0456\u0434\u043c\u0456\u043d\u0443 \u0432\u0456\u0434 \u043c\u0435\u0442\u043e\u0434\u0443 \u0433\u0440\u0430\u0434\u0456\u0454\u043d\u0442\u043d\u043e\u0433\u043e \u0441\u043f\u0443\u0441\u043a\u0443 (\u0434\u0435 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430 $\\alpha_k$ \u0437\u0430\u0437\u043d\u0430\u0454 \u0437\u043c\u0435\u043d\u0448\u0435\u043d\u043d\u044f \u043f\u0440\u0438 \u043a\u043e\u0436\u043d\u043e\u043c\u0443 \u043f\u043e\u0440\u0443\u0448\u0435\u043d\u043d\u0456 \u0443\u043c\u043e\u0432\u0438 (1), \u0434\u043e\u043a\u0438 \u043d\u0435 \u0437\u0430\u0434\u043e\u0432\u043e\u043b\u044c\u043d\u0438\u0442\u044c \u0457\u0457 \u0437\u043d\u043e\u0432\u0443), \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430 $\\alpha_k$ \u0437\u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f \u0437 \u0443\u043c\u043e\u0432\u0438, \u0449\u043e \u0437\u0430\u0431\u0435\u0437\u043f\u0435\u0447\u0443\u0454 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e \u043c\u043e\u0436\u043b\u0438\u0432\u0435 \u0437\u043c\u0435\u043d\u0448\u0435\u043d\u043d\u044f \u0444\u0443\u043d\u043a\u0446\u0456\u0457 $f(x)$ \u0432\u0437\u0434\u043e\u0432\u0436 \u043d\u0430\u043f\u0440\u044f\u043c\u043a\u0443 \u0457\u0457 \u0430\u043d\u0442\u0438\u0433\u0440\u0430\u0434\u0456\u0454\u043d\u0442\u0430 $f'(x^{(k)})$ \u0432 \u0442\u043e\u0447\u0446\u0456 $x^{(k)}$. \u0414\u0430\u043d\u0430 \u0443\u043c\u043e\u0432\u0430 \u0437\u0430\u0434\u0430\u0454\u0442\u044c\u0441\u044f \u043d\u0430\u0441\u0443\u043f\u043d\u0438\u043c \u0447\u0438\u043d\u043e\u043c:\n\n$\\Phi_k(\\alpha_k)=min_{\\alpha>0}\\Phi_k(\\alpha)$, \u0434\u0435 $\\Phi_k(\\alpha)=f[x^{(k)}-\\alpha f'(x^{(k)})]$\n\n\u0412\u0432\u0430\u0436\u0430\u0454\u0442\u044c\u0441\u044f, \u0449\u043e $x^{*}\\approx x^{(k)},  f^{*}\\approx f(x^{(k)})$","c488fa98":"\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c CLONALG \u0434\u043b\u044f \u0440\u0456\u0448\u0435\u043d\u043d\u044f \u0437\u0430\u0434\u0430\u0447\u0456 \u043e\u043f\u0442\u0438\u043c\u0456\u0437\u0430\u0446\u0456\u0457 \u043c\u0430\u0454 \u0442\u0430\u043a\u0443 \u043f\u043e\u0441\u043b\u0456\u0434\u043e\u0432\u043d\u0456\u0441\u0442\u044c \u043a\u0440\u043e\u043a\u0456\u0432: \n\n1. \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0456\u044f \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u0457 \u0430\u043d\u0442\u0438\u0442\u0456\u043b Ab (\u0444\u0443\u043d\u043a\u0446\u0456\u044f rand). \u041f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u044f \u0430\u043d\u0442\u0438\u0442\u0456\u043b - \u043c\u043d\u043e\u0436\u0438\u043d\u0430 \u043c\u043e\u0436\u043b\u0438\u0432\u0438\u0445 \u0440\u0456\u0448\u0435\u043d\u044c \u0437\u0430\u0434\u0430\u0447\u0456 \u043e\u043f\u0442\u0438\u043c\u0456\u0437\u0430\u0446\u0456\u0457.\u041a\u043e\u0436\u043d\u0435 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u043e \u044f\u0432\u043b\u044f\u0454 \u0441\u043e\u0431\u043e\u044e \u0431\u0456\u0442\u043e\u0432\u0438\u0439 \u0440\u044f\u0434\u043e\u043a, \u0432 \u044f\u043a\u0456\u0439 \u0437\u0431\u0435\u0440\u0456\u0433\u0430\u044e\u0442\u044c\u0441\u044f \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0438 \u0442\u043e\u0447\u043a\u0438 \u043c\u043e\u0436\u043b\u0438\u0432\u043e\u0433\u043e \u043c\u0456\u043d\u0456\u043c\u0443\u043c\u0443 (x1, x2), \u0437\u0430\u043a\u043e\u0434\u043e\u0432\u0430\u043d\u0438\u0439 \u0432 \u043a\u043e\u0434\u0456 \u0413\u0440\u0435\u044f. \u041f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u044f \u0433\u0435\u043d\u0435\u0440\u0443\u0454\u0442\u044c\u0441\u044f \u0432\u0438\u043f\u0430\u0434\u043a\u043e\u0432\u0438\u043c \u0447\u0438\u043d\u043e\u043c \u0448\u043b\u044f\u0445\u043e\u043c \u0437\u0430\u043f\u043e\u0432\u043d\u0435\u043d\u043d\u044f \u0440\u043e\u0437\u0440\u044f\u0434\u0456\u0432 \u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044f\u043c\u0438 0 \u0456 1.\n\n2. \u041e\u0431\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f \u0430\u0444\u0456\u043d\u043d\u043e\u0441\u0442\u0456 \u0430\u043d\u0442\u0438\u0442\u0456\u043b \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u0457 Ab \u0434\u043e \u0430\u043d\u0442\u0438\u0433\u0435\u043d\u0443 (\u0444\u0443\u043d\u043a\u0446\u0456\u044f affinity). \u0412 \u044f\u043a\u043e\u0441\u0442\u0456 \u0430\u043d\u0442\u0438\u0433\u0435\u043d\u0443 \u0432\u0438\u0441\u0442\u0443\u043f\u0430\u0454 \u0446\u0456\u043b\u044c\u043e\u0432\u0430 \u0444\u0443\u043d\u043a\u0446\u0456\u044f - F(x1, x2). \u0410\u0444\u0456\u043d\u043d\u0456\u0441\u0442\u044c \u043a\u043e\u0436\u043d\u043e\u0433\u043e \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0430 \u0432 \u0442\u0430\u043a\u043e\u043c\u0443 \u0432\u0438\u043f\u0430\u0434\u043a\u0443 \u0431\u0443\u0434\u0435 \u043e\u0431\u0447\u0438\u0441\u043b\u044e\u0432\u0430\u0442\u0438\u0441\u044f \u044f\u043a \u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044f \u0446\u0456\u043b\u044c\u043e\u0432\u043e\u0457 \u0444\u0443\u043d\u043a\u0446\u0456\u0457 \u0432 \u0442\u043e\u0447\u0446\u0456, \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0438 \u044f\u043a\u043e\u0457 \u0437\u0430\u043a\u043e\u0434\u043e\u0432\u0430\u043d\u0456 \u0432 \u0434\u0430\u043d\u043e\u043c\u0443 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0456 .\n\u0414\u043b\u044f \u043e\u0431\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f \u0430\u0444\u0456\u043d\u043d\u043e\u0441\u0442\u0456 \u043d\u0435\u043e\u0431\u0445\u0456\u0434\u043d\u043e \u0434\u0435\u043a\u043e\u0434\u0443\u0432\u0430\u0442\u0438 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0438 \u0442\u043e\u0447\u043a\u0438 \u0437 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0430 \u0456 \u043f\u0456\u0434\u0441\u0442\u0430\u0432\u0438\u0442\u0438 \u0457\u0445 \u0443 \u0444\u0443\u043d\u043a\u0446\u0456\u044e.\n \u0414\u0435\u043a\u043e\u0434\u0443\u0432\u0430\u043d\u043d\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u044c \u0437\u043c\u0456\u043d\u043d\u043e\u0457 x \u0437 \u0434\u0432\u0456\u0439\u043a\u043e\u0432\u043e\u0433\u043e \u0432\u0438\u0434\u0443 \u0432\u0438\u043a\u043e\u043d\u0443\u0454\u0442\u044c\u0441\u044f \u0432 \u0434\u0432\u0430 \u0435\u0442\u0430\u043f\u0438: \n1) \u043f\u0435\u0440\u0435\u0442\u0432\u043e\u0440\u0438\u0442\u0438 \u0434\u0432\u0456\u0439\u043a\u043e\u0432\u0438\u0439 \u0440\u044f\u0434\u043e\u043a, \u0432\u0456\u0434 \u0447\u0438\u0441\u0435\u043b \u0432 \u0434\u0432\u0456\u0439\u043a\u043e\u0432\u0456\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u0456 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f \u0432 \u0447\u0438\u0441\u043b\u0430 \u0432 \u0434\u0435\u0441\u044f\u0442\u043a\u043e\u0432\u0456\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u0456 \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f: \n$$(\\left\\langle m_{L-1},..,m_1,m_0 \\right\\rangle)_2 = (\\sum_{i=0}^{L-1} m_i 2^i)_{10}= x',$$\n\u0434\u0435 L - \u0434\u043e\u0432\u0436\u0438\u043d\u0430 \u0440\u044f\u0434\u043a\u0443","1714169d":"4. $z=xy*sin(x^2+y^2)$\n\n\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0440\u043e\u0431\u043e\u0442\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0443:(0.9991855619396119, -0.9992041585932157)\n\n","dd9ad74d":"3. \u041a\u043b\u043e\u043d\u0443\u0432\u0430\u043d\u043d\u044f \u0430\u043d\u0442\u0438\u0442\u0456\u043b (\u0456\u043c\u0443\u043d\u043d\u0438\u0439 \u043e\u043f\u0435\u0440\u0430\u0442\u043e\u0440 clone).\u041f\u0440\u0438 \u0446\u044c\u043e\u043c\u0443 \u0441\u0442\u0432\u043e\u0440\u044e\u0454\u0442\u044c\u0441\u044f \u0442\u0438\u043c\u0447\u0430\u0441\u043e\u0432\u0430 \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u044f \u043a\u043b\u043e\u043d\u0456\u0432 C *, \u0440\u043e\u0437\u043c\u0456\u0440 \u044f\u043a\u043e\u0457 \u0432\u0438\u0437\u043d\u0430\u0447\u0430\u0454\u0442\u044c\u0441\u044f \u043f\u043e\u043f\u0435\u0440\u0435\u0434\u043d\u044c\u043e \u0432\u0432\u0435\u0434\u0435\u043d\u0438\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u043c.\n\n4. \u041c\u0443\u0442\u0430\u0446\u0456\u044f \u043a\u043b\u043e\u043d\u0456\u0432 (\u0456\u043c\u0443\u043d\u043d\u0438\u0439 \u043e\u043f\u0435\u0440\u0430\u0442\u043e\u0440 mutate). \n\u0417\u043c\u0456\u043d\u044e\u0454\u043c\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044f \u043e\u0431\u0440\u0430\u043d\u0438\u0445 \u0432\u0438\u043f\u0430\u0434\u043a\u043e\u0432\u0438\u043c \u0447\u0438\u043d\u043e\u043c \u043a\u043b\u043e\u043d\u0456\u0432, \u0432\u0456\u0440\u043e\u0433\u0456\u0434\u043d\u0456\u0441\u0442\u044c \u043c\u0443\u0442\u0430\u0446\u0456\u0457 \u0437\u0430\u0434\u0430\u0454\u0442\u044c\u0441\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u043c.\n","9e376409":"## CloneAlg","b5b93d40":"5. \u041e\u0431\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044f \u0430\u0444\u0456\u043d\u043d\u043e\u0441\u0442\u0456 \u043a\u043b\u043e\u043d\u0456\u0432 \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u0457 C *.\n6. \u0412\u0456\u0434\u0431\u0456\u0440 \u043a\u043b\u043e\u043d\u0456\u0432 \u0456 \u0437\u0430\u043c\u0456\u043d\u0430 \u043d\u0438\u043c\u0438 \u0432\u0456\u0434\u043f\u043e\u0432\u0456\u0434\u043d\u0438\u0445 \u0430\u043d\u0442\u0438\u0442\u0456\u043b (\u0456\u043c\u0443\u043d\u043d\u0443 \u043e\u043f\u0435\u0440\u0430\u0442\u043e\u0440 select + \u0444\u0443\u043d\u043a\u0446\u0456\u044f replace).\n\u0412\u0438\u0431\u0440\u0430\u0442\u0438 \u0437 \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u0457 C * \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0430 \u0437 \u043f\u043e\u043b\u0456\u043f\u0448\u0435\u043d\u043e\u044e \u0432 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0456 \u043c\u0443\u0442\u0430\u0446\u0456\u0457 \u0430\u0444\u0456\u043d\u043d\u0456\u0441\u0442\u044e, \u0437\u0430\u043c\u0456\u043d\u0438\u0442\u0438 \u043d\u0438\u043c\u0438 \u0432\u0456\u0434\u043f\u043e\u0432\u0456\u0434\u043d\u0456 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0430, \u0432\u0456\u0434 \u044f\u043a\u0438\u0445 \u0431\u0443\u043b\u0438 \u0437\u0440\u043e\u0431\u043b\u0435\u043d\u0456 \u043a\u043b\u043e\u043d\u0438.\n7.  \u0420\u0435\u0434\u0430\u0433\u0443\u0432\u0430\u043d\u043d\u044f \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u0457 (\u0444\u0443\u043d\u043a\u0446\u0456\u044f rand + \u0456\u043c\u0443\u043d\u043d\u0438\u0439 \u043e\u043f\u0435\u0440\u0430\u0442\u043e\u0440 edit). \n\u0417\u0430\u043c\u0456\u043d\u0438\u0442\u0438 d \u0430\u043d\u0442\u0438\u0442\u0456\u043b \u0437 \u0433\u0456\u0440\u0448\u043e\u044e \u0430\u0444\u0456\u043d\u043d\u0456\u0441\u0442\u044e \u043d\u043e\u0432\u0438\u043c\u0438 \u0432\u0438\u043f\u0430\u0434\u043a\u043e\u0432\u043e \u0437\u0433\u0435\u043d\u0435\u0440\u043e\u0432\u0430\u043d\u0438\u043c\u0438 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0430\u043c\u0438 \u0434\u043b\u044f \u043f\u0456\u0434\u0442\u0440\u0438\u043c\u043a\u0438 \u0440\u0456\u0437\u043d\u043e\u043c\u0430\u043d\u0456\u0442\u043d\u043e\u0441\u0442\u0456 \u043f\u043e\u043f\u0443\u043b\u044f\u0446\u0456\u0457. \u0427\u0438\u043c \u0433\u0456\u0440\u0448\u0435 \u0430\u0444\u0456\u043d\u043d\u0456\u0441\u0442\u044c \u0430\u043d\u0442\u0438\u0442\u0456\u043b, \u0442\u0438\u043c \u0431\u0456\u043b\u044c\u0448\u0435 \u0448\u0430\u043d\u0441\u0456\u0432, \u0449\u043e \u0432\u043e\u043d\u0438 \u0431\u0443\u0434\u0443\u0442\u044c \u0437\u0430\u043c\u0456\u043d\u0435\u043d\u0456 \u043d\u043e\u0432\u0438\u043c\u0438. ","083a8224":"**\u041a\u043b\u043e\u043d\u0430\u043b\u044c\u043d\u0438\u0439 \u0432\u0456\u0434\u0431\u0456\u0440** \u2013 \u0446\u0435 \u043d\u0430\u0437\u0432\u0430 \u0442\u0435\u043e\u0440\u0456\u0457, \u044f\u043a\u0430 \u043f\u043e\u044f\u0441\u043d\u044e\u0454, \u044f\u043a \u0430\u0434\u0430\u043f\u0442\u0438\u0432\u043d\u0430 \u0456\u043c\u0443\u043d\u043d\u0430 \u0441\u0438\u0441\u0442\u0435\u043c\u0430 (\u043d\u0430\u0431\u0443\u0442\u0438\u0439 \u0456\u043c\u0443\u043d\u0456\u0442\u0435\u0442) \u0441\u043f\u0440\u0430\u0432\u043b\u044f\u0454\u0442\u044c\u0441\u044f \u0437 \u043f\u0430\u0442\u043e\u0433\u0435\u043d\u043d\u0438\u043c\u0438 \u043c\u0456\u043a\u0440\u043e\u043e\u0440\u0433\u0430\u043d\u0456\u0437\u043c\u0430\u043c\u0438. \u0412 \u043f\u0440\u043e\u0446\u0435\u0441\u0456 \u043a\u043b\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0432\u0456\u0434\u0431\u043e\u0440\u0443 \u0432 \u043f\u0440\u0438\u0440\u043e\u0434\u043d\u0456\u0439 \u0456\u043c\u0443\u043d\u043d\u0456\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u0456 \u0431\u0435\u0440\u0443\u0442\u044c \u0443\u0447\u0430\u0441\u0442\u044c \u0412- \u0456 \u0422-\u043b\u0456\u043c\u0444\u043e\u0446\u0438\u0442\u0438, \u0437 \u0442\u0456\u0454\u044e \u0432\u0456\u0434\u043c\u0456\u043d\u043d\u0456\u0441\u0442\u044e, \u0449\u043e \u0412-\u043b\u0456\u043c\u0444\u043e\u0446\u0438\u0442\u0438 \u043f\u0456\u0434\u0434\u0430\u044e\u0442\u044c\u0441\u044f \u043c\u0443\u0442\u0430\u0446\u0456\u0457, \u0430 \u0422-\u043b\u0456\u043c\u0444\u043e\u0446\u0438\u0442\u0438 \u043d\u0456. \u0422\u043e\u043c\u0443 \u0432 \u043e\u0431\u0447\u0438\u0441\u043b\u044e\u0432\u0430\u043b\u044c\u043d\u0438\u0445 \u043c\u043e\u0434\u0435\u043b\u044f\u0445 \u043a\u043b\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0432\u0456\u0434\u0431\u043e\u0440\u0443 \u043c\u043e\u0434\u0435\u043b\u044e\u0454\u0442\u044c\u0441\u044f \u0440\u043e\u0431\u043e\u0442\u0430 \u0442\u0456\u043b\u044c\u043a\u0438 \u0412-\u043b\u0456\u043c\u0444\u043e\u0446\u0438\u0442\u0456\u0432, \u0442\u043e\u043c\u0443 \u0449\u043e \u0441\u0430\u043c\u0435 \u0437\u0430\u0432\u0434\u044f\u043a\u0438 \u043c\u0443\u0442\u0430\u0446\u0456\u0457 \u0456\u043c\u0443\u043d\u043d\u0430 \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u0441\u0442\u0430\u0454 \u0430\u0434\u0430\u043f\u0442\u0438\u0432\u043d\u043e\u044e. \n\u0412 \u0442\u0435\u043e\u0440\u0456\u0457 \u043a\u043b\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0432\u0456\u0434\u0431\u043e\u0440\u0443 \u043d\u0430\u0439\u0431\u0456\u043b\u044c\u0448 \u0432\u0430\u0436\u043b\u0438\u0432\u0438\u043c\u0438 \u0437 \u043e\u0431\u0447\u0438\u0441\u043b\u044e\u0432\u0430\u043b\u044c\u043d\u043e\u0457 \u0442\u043e\u0447\u043a\u0438 \u0437\u043e\u0440\u0443 \u0454 \u043d\u0430\u0441\u0442\u0443\u043f\u043d\u0456 \u043f\u043e\u043b\u043e\u0436\u0435\u043d\u043d\u044f:\n* \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u043e \u0440\u043e\u0437\u043f\u0456\u0437\u043d\u0430\u0454 \u0447\u0443\u0436\u043e\u0440\u0456\u0434\u043d\u0438\u0439 \u0430\u043d\u0442\u0438\u0433\u0435\u043d \u0437 \u043f\u0435\u0432\u043d\u043e\u044e \u0430\u0444\u0456\u043d\u043d\u0456\u0441\u0442\u044e;\n* \u0434\u0430\u043d\u0435 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u043e \u0432\u0456\u0434\u0431\u0438\u0440\u0430\u0454\u0442\u044c\u0441\u044f \u0434\u043b\u044f \u043a\u043b\u043e\u043d\u0443\u0432\u0430\u043d\u043d\u044f \u0456 \u0432\u0438\u0440\u043e\u0431\u043b\u044f\u0454 \u043c\u043d\u043e\u0436\u0438\u043d\u0443 \u043a\u043b\u043e\u043d\u0456\u0432 \u0430\u043d\u0442\u0438\u0442\u0456\u043b, \u044f\u043a\u0456 \u043f\u043e\u0442\u0456\u043c \u043f\u0456\u0434\u0434\u0430\u044e\u0442\u044c\u0441\u044f \u043f\u0440\u043e\u0446\u0435\u0441\u0443 \u043c\u0443\u0442\u0430\u0446\u0456\u0457;\n* \u043f\u0440\u043e\u0446\u0435\u0441 \u043c\u0443\u0442\u0430\u0446\u0456\u0457 \u043f\u0440\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u044c \u0434\u043e \u0442\u043e\u0433\u043e, \u0449\u043e \u043d\u043e\u0432\u0456 \u0441\u0442\u0432\u043e\u0440\u0435\u043d\u0456 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0430 \u043c\u0430\u044e\u0442\u044c \u043a\u0440\u0430\u0449\u0443 \u0430\u0444\u0456\u043d\u043d\u0456\u0441\u0442\u044c \u0434\u043e \u0434\u0430\u043d\u043e\u0433\u043e \u0430\u043d\u0442\u0438\u0433\u0435\u043d\u0443, \u043d\u0456\u0436 \u043f\u043e\u0447\u0430\u0442\u043a\u043e\u0432\u0435 \u0432\u0456\u0434\u0456\u0431\u0440\u0430\u043d\u0435 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u043e;\n* \u0430\u043a\u0442\u0438\u0432\u043e\u0432\u0430\u043d\u0456 \u0430\u043d\u0442\u0438\u0442\u0456\u043b\u0430 \u0437 \u0432\u0438\u0441\u043e\u043a\u043e\u044e \u0430\u0444\u0456\u043d\u043d\u0456\u0441\u0442\u044e \u0437\u0431\u0435\u0440\u0456\u0433\u0430\u044e\u0442\u044c\u0441\u044f \u0432 \u043f\u0430\u043c'\u044f\u0442\u0456. \n"}}