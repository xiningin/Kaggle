{"cell_type":{"537d2fc9":"code","6dd17414":"code","1d11df94":"code","7b8ab7e9":"code","d3e2af6b":"code","f0226569":"code","39eb4080":"code","622eb54d":"code","69568ecb":"code","47f5c054":"code","f58e013a":"code","da891577":"code","6c1586e7":"code","187a8b15":"code","037a99db":"code","980f030c":"code","4b2d5e01":"code","2fd3665d":"code","cc7a234a":"code","d870897f":"code","fc70734b":"code","37cbdcf9":"code","bfd85293":"code","cc7ed299":"code","844f9367":"code","d4ebf73d":"code","f10f7ca0":"code","a2443f7d":"code","61557994":"code","f9c871b0":"code","fe2374cf":"code","7a3417ea":"code","35b41ffd":"code","ebef2373":"code","8db4c810":"code","b3e5794e":"code","407a8e04":"code","a71552f2":"code","3f5cb8ac":"code","770eb336":"markdown","2e2469cb":"markdown","bf85b9cb":"markdown","f20c5150":"markdown","85e27c22":"markdown","3e0e6f89":"markdown"},"source":{"537d2fc9":"import numpy as np\nimport pandas as pd\nimport pickle\nfrom typing import Tuple\n\npd.set_option(\"max_columns\", 5000)\nfrom scipy.stats import norm\nimport warnings\n\nwarnings.filterwarnings(action=\"ignore\")\nimport seaborn as sns\n\ncolor = sns.color_palette()\nsns.set_style(\"darkgrid\")\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.ensemble import RandomForestClassifier as RFC\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import roc_auc_score, make_scorer\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nimport optuna","6dd17414":"test = pd.read_csv(\"..\/input\/dogus-teknoloji-zingat\/zingat_usecase_testset_null.csv\")\ntrain = pd.read_csv(\"..\/input\/dogus-teknoloji-zingat\/zingat_usecase_trainset.csv\")\nusdtry = pd.read_csv(\"..\/input\/zingat-external\/usdtry.csv\")\ncredit_rates = pd.read_csv(\"..\/input\/zingat-external\/kredi_oranlari.csv\")\nistanbul_index = pd.read_csv(\"..\/input\/zingat-external\/istanbul_index.csv\")\nizmir_index = pd.read_csv(\"..\/input\/zingat-external\/izmir_index.csv\")\ncounty_index = pd.read_csv(\"..\/input\/zingat-external\/county_index.csv\")\nsubmission = pd.read_csv(\"..\/input\/dogus-teknoloji-zingat\/sample_submission_zingat.csv\")","1d11df94":"# Column name changes\ntrain.columns = ['date','place','price','room','gross_area','net_area','building_type','building_age','floor_number',\n                'number_of_floors','heating','bath_count','scene','carpark','intercom','earthquake_regulations','elevator','playground','changing_room','parent_bath','id']\ntest.columns = ['date','place','room','gross_area','net_area','building_type','building_age','floor_number',\n                'number_of_floors','heating','bath_count','scene','carpark','intercom','earthquake_regulations','elevator','playground','changing_room','parent_bath','id','price']","7b8ab7e9":"izmir_index[\"date\"] = pd.to_datetime(izmir_index[\"month\"], format=\"%m-%Y\")\nizmir_index = izmir_index.set_index(\"date\")\nizmir_index_1 = izmir_index.resample(\"D\").interpolate(method='linear')\n\nistanbul_index[\"date\"] = pd.to_datetime(istanbul_index[\"month\"], format=\"%m-%Y\")\nistanbul_index = istanbul_index.set_index(\"date\")\nistanbul_index_1 = istanbul_index.resample(\"D\").interpolate(method='linear')\n\ncounty_index[\"date\"] = pd.to_datetime(county_index[\"month\"], format=\"%B %Y\", errors='coerce')\ncounty_index = county_index.set_index(\"date\")\ncounty_index = county_index[['county', 'county_index']]\ncounty_list = ['\u0130zmir-Narl\u0131dere', '\u0130zmir-Karaburun', '\u0130zmir-Kemalpa\u015fa', '\u0130zmir-Alia\u011fa', '\u0130zmir-Menemen', '\u0130zmir-Bayrakl\u0131', '\u0130zmir-\u00c7i\u011fli', '\u0130zmir-\u00d6demi\u015f', '\u0130zmir-Bal\u00e7ova', '\u0130zmir-Urla', '\u0130zmir-Torbal\u0131', '\u0130stanbul-Pendik', '\u0130zmir-Fo\u00e7a', '\u0130zmir-Bornova', '\u0130zmir-Bay\u0131nd\u0131r', '\u0130zmir-Seferihisar', '\u0130zmir-Konak', '\u0130zmir-Bergama', '\u0130stanbul-Ba\u011fc\u0131lar', '\u0130stanbul-Kad\u0131k\u00f6y', '\u0130zmir-Buca', '\u0130zmir-Gaziemir', '\u0130zmir-Menderes', '\u0130zmir-\u00c7e\u015fme', '\u0130zmir-Dikili', '\u0130zmir-Tire', '\u0130stanbul-Be\u015fikta\u015f', '\u0130stanbul-Beylikd\u00fcz\u00fc', '\u0130zmir-G\u00fczelbah\u00e7e', '\u0130zmir-Karaba\u011flar', '\u0130zmir-K\u0131n\u0131k', '\u0130zmir-Sel\u00e7uk', '\u0130zmir-Kar\u015f\u0131yaka']\npd_list = [county_index[county_index.county==c].resample(\"D\").interpolate(method='linear') for c in county_list]\ncounty_index = pd.concat(pd_list, axis=0)\ncounty_index.fillna(method='ffill', inplace=True)\ncounty_base_index = county_index['2019-01-01'].rename(columns={\"county_index\": \"county_base_index\"})","d3e2af6b":"# USD-TRY\nusdtry.fillna(method=\"ffill\", inplace=True)\nusdtry['usdtry'] = usdtry.usdtry.cummax()\ncredit_rates.fillna(method=\"ffill\", inplace=True)\nusdtry[\"date\"] = pd.to_datetime(usdtry.date, format=\"%d-%m-%Y\", errors=\"coerce\")\ncredit_rates[\"date\"] = pd.to_datetime(credit_rates.date, format=\"%d-%m-%Y\", errors=\"coerce\")\nusdtry[\"usdtry\"] = usdtry[\"usdtry\"].astype(\"float\")","f0226569":"# Merge Test-Train\ntrain[\"is_train\"] = 1\ntest[\"is_train\"] = 0\n\nall = pd.concat([train, test], ignore_index=True)\ntrain_idxes = all[all.is_train == 1].index","39eb4080":"all[\"price\"] = all[\"price\"].str.strip(\"TRY\").astype(\"float\")","622eb54d":"# Il-Ilce-Mahalle\nall.loc[all.place == \"\u0130zmir\", \"place\"] = \"\u0130zmir\/Kar\u015f\u0131yaka\/Bostanl\u0131\"\nall[[\"city\", \"county\", \"district\"]] = all.place.str.split(pat=\"\/\", expand=True)\nall[\"county\"] = all[\"city\"] + \"-\" + all[\"county\"]\nall[\"district\"] = all[\"county\"] + \"-\" + all[\"district\"]\nall.loc[all.county == \"\u0130zmir-Kiraz\", \"place\"] = \"\u0130zmir\/Kar\u015f\u0131yaka\/Bostanl\u0131\"\nall.loc[all.county == \"\u0130zmir-Beyda\u011f\", \"county\"] = '\u0130zmir-\u00d6demi\u015f'\nall.loc[all.county == \"\u0130zmir-Kiraz\", \"county\"] = '\u0130zmir-\u00d6demi\u015f'","69568ecb":"# Index multipliers\nall[\"date\"] = pd.to_datetime(all.date, format=\"%Y-%m-%d\", errors=\"coerce\")\nall = pd.merge(all, istanbul_index_1, on=\"date\", how=\"left\")\nall = pd.merge(all, izmir_index_1, on=\"date\", how=\"left\")\nall = pd.merge(all, county_index, on=[\"county\", \"date\"], how=\"left\")\nall = pd.merge(all, county_base_index, on=[\"county\"], how=\"left\")\n\nizmir_201901_index = 3000\nistanbul_201901_index = 3527.11\n\nall[\"index_base\"] = -1\nall[\"index_current\"] = -1\nall.loc[all.city == \"\u0130zmir\", \"index_base\"] = izmir_201901_index\nall.loc[all.city == \"\u0130stanbul\", \"index_base\"] = istanbul_201901_index\nall.loc[all.city == \"\u0130zmir\", \"index_current\"] = all.izmir_index\nall.loc[all.city == \"\u0130stanbul\", \"index_current\"] = all.istanbul_index\nall[\"index_multiplier\"] = all[\"index_current\"] \/ all[\"index_base\"]\nall[\"county_index_multiplier\"] = all[\"county_index\"] \/ all[\"county_base_index\"]","47f5c054":"all[all.net_area == 2048]","f58e013a":"# train_data 59977,83239 are similar, I used this data to predict 83393 at submission cell\nall.at[83393, 'room'] = \"10+0\"\nall.at[83393, 'building_type'] = \"Villa\"","da891577":"#room corrections\nall.loc[all.room == \"-\", \"room\"] = \"0+0\"\nall.loc[all.room == \"1149+0\", \"room\"] = \"0+0\"''\nall.at[11600, 'room'] = \"1+0\"\nall.at[38130, 'room'] = \"1+0\"\nall.at[44775, 'room'] = \"1+0\"\nall.at[85846, 'room'] = \"1+1\"\nall.at[86012, 'room'] = \"1+1\"\nall.at[86468, 'room'] = \"1+0\"\nall[[\"nroom_count\", \"lroom_count\"]] = all.room.str.split(pat=\"+\", expand=True)\nall[\"nroom_count\"] = all[\"nroom_count\"].astype(\"int32\")\nall[\"lroom_count\"] = all[\"lroom_count\"].astype(\"int32\")\nall[\"room_count\"] = all[\"nroom_count\"] + all[\"lroom_count\"]\n\nall[\"gross_area\"] = all[\"gross_area\"].astype(\"float\")\nall[\"net_area\"] = all[\"net_area\"].astype(\"float\")\n# area corrections\nall.at[4043, 'gross_area'] = 100\nall.at[6334, 'gross_area'] = 150\nall.at[7316, 'gross_area'] = 100\nall.at[9931, 'gross_area'] = 125\nall.at[20087, 'gross_area'] = 95\nall.at[26265, 'gross_area'] = 145\nall.at[31045, 'gross_area'] = 120\nall.at[37515, 'gross_area'] = 350\nall.at[42195, 'gross_area'] = 145\nall.at[42941, 'gross_area'] = 80\nall.at[48835, 'gross_area'] = 240\nall.at[54531, 'gross_area'] = 78\nall.at[64798, 'gross_area'] = 130\nall.at[64859, 'gross_area'] = 130\nall.at[65891, 'gross_area'] = 65\nall.at[69588, 'gross_area'] = 100\nall.at[72085, 'gross_area'] = 90\nall.at[77161, 'gross_area'] = 270\nall.at[81276, 'gross_area'] = 148\nall.at[1250, 'gross_area'] = 600\nall.at[5294, 'gross_area'] = 950\nall.at[6491, 'gross_area'] = 300\nall.at[14828, 'gross_area'] = 100\nall.at[34195, 'gross_area'] = 90\nall.at[34223, 'gross_area'] = 100\nall.at[34305, 'gross_area'] = 120\nall.at[34310, 'gross_area'] = 110\nall.at[34408, 'gross_area'] = 100\nall.at[34417, 'gross_area'] = 70\nall.at[36094, 'gross_area'] = 125\nall.at[43910, 'gross_area'] = 100\nall.at[46614, 'gross_area'] = 130\nall.at[55043, 'gross_area'] = 95\nall.at[56082, 'gross_area'] = 1070\nall.at[59788, 'gross_area'] = 90\nall.at[59816, 'gross_area'] = 135\nall.at[60218, 'gross_area'] = 656\nall.at[60442, 'gross_area'] = 290\nall.at[63206, 'gross_area'] = 250\nall.at[63212, 'gross_area'] = 231\nall.at[63830, 'gross_area'] = 200\nall.at[64863, 'gross_area'] = 800\nall.at[75791, 'gross_area'] = 315\nall.at[79578, 'gross_area'] = 150\nall.at[81757, 'gross_area'] = 400\nall.at[82936, 'gross_area'] = 500\nall.at[91386, 'gross_area'] = 250\nall.at[53907, 'gross_area'] = 140\nall.at[9374, 'gross_area'] = 205\nall.at[9528, 'gross_area'] = 120\nall.at[30298, 'gross_area'] = 55\nall.at[40757, 'gross_area'] = 110\nall.at[48386, 'gross_area'] = 100\nall.at[50987, 'gross_area'] = 108\nall.at[60052, 'gross_area'] = 130\nall.at[60503, 'gross_area'] = 95\nall.at[64984, 'gross_area'] = 135\nall.at[65871, 'gross_area'] = 400\nall.at[68884, 'gross_area'] = 130\nall.at[25540, 'gross_area'] = 70\nall.at[4134, 'gross_area'] = 100\nall.at[4143, 'gross_area'] = 100\nall.at[22285, 'gross_area'] = 100\nall.at[13157, 'gross_area'] = 145\nall.at[46497, 'gross_area'] = 130\nall.at[46497, 'gross_area'] = 130\nall.at[8851, 'gross_area'] = 3000\nall.at[5097, 'gross_area'] = 1000\nall.at[8921, 'gross_area'] = 3000\nall.at[96128, 'gross_area'] = 300\nall.at[68973, 'gross_area'] = 120\n\n\nall.at[59781, 'net_area'] = 110\nall.at[59815, 'net_area'] = 100\nall.at[60229, 'net_area'] = 300\nall.at[72369, 'net_area'] = 220\nall.at[85441, 'net_area'] = 75\nall.at[6491, 'net_area'] = 120\nall.at[14828, 'net_area'] = 98\nall.at[34195, 'net_area'] = 70\nall.at[34223, 'net_area'] = 70\nall.at[34305, 'net_area'] = 110\nall.at[34310, 'net_area'] = 80\nall.at[34408, 'net_area'] = 80\nall.at[34417, 'net_area'] = 60\nall.at[36094, 'net_area'] = 120\nall.at[43910, 'net_area'] = 91\nall.at[46614, 'net_area'] = 115\nall.at[55043, 'net_area'] = 90\nall.at[59788, 'net_area'] = 60\nall.at[60218, 'net_area'] = 553\nall.at[60442, 'net_area'] = 145\nall.at[63206, 'net_area'] = 200\nall.at[63212, 'net_area'] = 171\nall.at[63830, 'net_area'] = 170\nall.at[64863, 'net_area'] = 180\nall.at[75791, 'net_area'] = 250\nall.at[79578, 'net_area'] = 130\nall.at[81757, 'net_area'] = 143\nall.at[82936, 'net_area'] = 424\nall.at[91386, 'net_area'] = 200\nall.at[78397, 'net_area'] = 130\nall.at[96874, 'net_area'] = 100\nall.at[97142, 'net_area'] = 100\nall.at[60503, 'net_area'] = 85\nall.at[70053, 'net_area'] = 130\nall.at[70195, 'net_area'] = 185\nall.at[25540, 'net_area'] = 70\nall.at[4088, 'net_area'] = 80\nall.at[4134, 'net_area'] = 95\nall.at[4143, 'net_area'] = 95\nall.at[6931, 'net_area'] = 100\nall.at[22285, 'net_area'] = 90\nall.at[96874, 'net_area'] = 100\nall.at[13157, 'net_area'] = 145\nall.at[46497, 'net_area'] = 125\nall.at[8851, 'net_area'] = 3000\nall.at[5097, 'net_area'] = 1000\nall.at[8921, 'net_area'] = 3000\nall.at[96128, 'net_area'] = 250\nall.at[68973, 'net_area'] = 100\n\nbuilding_type_average_room_ares = all.groupby('building_type')['net_area'].mean() \/ all.groupby('building_type')['room_count'].mean()\nall[\"building_type_avg_area\"] = building_type_average_room_ares[all.building_type].reset_index(drop=True)\n\nall.loc[all.room == \"0+0\", 'room_count'] = (all.loc[all.nroom_count == 0][\"net_area\"] \/  all.loc[all.nroom_count == 0][\"building_type_avg_area\"]).round(decimals = 0)\nall.loc[(all.room == \"0+0\") & (all.room_count > 11), 'room_count'] = 11\nall.loc[(all.room == \"0+0\") & (all.room_count == 1), 'nroom_count'] = 1\nall.loc[(all.room == \"0+0\") & (all.room_count > 1), 'nroom_count'] = all.room_count - 1\nall.loc[(all.room == \"0+0\") & (all.room_count == 1), 'lroom_count'] = 0\nall.loc[(all.room == \"0+0\") & (all.room_count > 1), 'lroom_count'] = 1","6c1586e7":"# Price corrections\nall.at[57161, 'price'] = 85500\nall.at[57298, 'price'] = 85500\nall.at[2638, 'price'] = 510000\nall.at[3351, 'price'] = 300000\nall.drop(all[(all.price\/all.net_area < 500) & (all.building_type != \"Prefabrik Ev\")].index, inplace=True)","187a8b15":"all.loc[all.gross_area < all.net_area, \"gross_area\"] = all.net_area\n\nall[\"avg_room_area\"] = all[\"net_area\"] \/ all[\"room_count\"]\nall.loc[all.avg_room_area < 11, \"avg_room_area\"] = all.groupby(\"building_type\")[\"avg_room_area\"].transform(\"mean\")\nall.loc[all.avg_room_area < 11, \"gross_area\"] = all.avg_room_area * all.room_count\nall.loc[all.avg_room_area < 11, \"net_area\"] = all.avg_room_area * all.room_count\n\nall.loc[(all.net_area < 20) & (all[\"building_type\"] != \"Prefabrik Ev\"), \"avg_room_area\"] = all.groupby(\"building_type\")[\"avg_room_area\"].transform(\"mean\")\nall.loc[(all.gross_area < 20) & (all[\"building_type\"] != \"Prefabrik Ev\"), \"avg_room_area\"] = all.groupby(\"building_type\")[\"avg_room_area\"].transform(\"mean\")\nall.loc[(all.net_area < 20) & (all[\"building_type\"] != \"Prefabrik Ev\"), \"net_area\"] = all.avg_room_area * all.room_count\nall.loc[(all.gross_area < 20) & (all[\"building_type\"] != \"Prefabrik Ev\"), \"gross_area\"] = all.avg_room_area * all.room_count\n\nall[\"gross_area - net_area\"] = all[\"gross_area\"] - all[\"net_area\"]\nall[\"gross_area \/ net_area\"] = all[\"gross_area\"] \/ all[\"net_area\"]\nall[\"gross_area_squared\"] = all[\"gross_area\"] ** 2\nall[\"gross_area_log\"] = np.log1p(all[\"gross_area\"])","037a99db":"all.loc[all.building_age == \"6-10 aras\u0131\", \"building_age\"] = \"8\"\nall.loc[all.building_age == \"11-15 aras\u0131\", \"building_age\"] = \"13\"\nall.loc[all.building_age == \"16-20 aras\u0131\", \"building_age\"] = \"18\"\nall.loc[all.building_age == \"21-25 aras\u0131\", \"building_age\"] = \"23\"\nall.loc[all.building_age == \"26-30 aras\u0131\", \"building_age\"] = \"28\"\nall.loc[all.building_age == \"31-35 aras\u0131\", \"building_age\"] = \"33\"\nall.loc[all.building_age == \"36-40 aras\u0131\", \"building_age\"] = \"38\"\nall.loc[all.building_age == \"40 ve \u00fczeri\", \"building_age\"] = \"45\"\nall.loc[all.building_age == \"-\", \"building_age\"] = None\nall[\"building_age\"] = all[\"building_age\"].astype(\"float\")\nall[\"building_age\"] = all[\"building_age\"].fillna(\n    all.groupby(\"district\")[\"building_age\"].transform(\"mean\")\n)\nall[\"building_age\"].fillna(all[\"building_age\"].mean(), inplace=True)","980f030c":"all[\"is_summerplace\"] = 0\nall.loc[all.building_type == \"Yazl\u0131k\", \"is_summerplace\"] = 1\n\nall[\"is_new\"] = 0\nall.loc[all.building_age == 0.0, \"is_new\"] = 1\nall[\"is_mustakil\"] = 0\nall.loc[all.floor_number == \"M\u00fcstakil\", \"is_mustakil\"] = 1\nall.loc[all.floor_number == \"Komple\", \"is_mustakil\"] = 1\nall.loc[all.building_type == \"M\u00fcstakil Ev\", \"is_mustakil\"] = 1\nall.loc[all.building_type == \"Villa\", \"is_mustakil\"] = 1\nall.loc[all.building_type == \"\u00c7iftlik Evi\", \"is_mustakil\"] = 1\nall.loc[all.building_type == \"K\u00f6\u015fk \/ Konak \/ Yal\u0131\", \"is_mustakil\"] = 1\nall.loc[all.building_type == \"\u00c7iftlik Evi\", \"is_mustakil\"] = 1\nall.loc[all.building_type == \"Yal\u0131 Dairesi\", \"is_mustakil\"] = 1","4b2d5e01":"all[\"is_whole_building\"] = 0\nall.loc[all.floor_number == \"Komple\", \"is_whole_building\"] = 1\n\nall[\"is_teras\"] = 0\nall.loc[all.floor_number == \"Teras Kat\", \"is_teras\"] = 1\n\nall[\"is_underground\"] = 0\nall.loc[all.floor_number.isin([\"Bodrum Kat\", \"Kot 1\", \"Kot 2\", \"Kot 3\", \"Kot 4\"]), \"is_underground\"] = 1\n\nall[\"is_top\"] = 0\nall.loc[all.floor_number == \"En \u00dcst Kat\", \"is_top\"] = 1\nall.loc[all.floor_number == all.number_of_floors, \"is_top\"] = 1\n\nall.loc[all.floor_number == \"En \u00dcst Kat\", \"floor_number\"] = all.number_of_floors\nall.loc[all.floor_number == \"Teras Kat\", \"floor_number\"] = all.number_of_floors\n\nall.loc[all.floor_number == \"Komple\", \"floor_number\"] = all.number_of_floors\nall.loc[all.floor_number == \"M\u00fcstakil\", \"floor_number\"] = \"0\"\nall.loc[all.floor_number == \"-\", \"floor_number\"] = \"0\"\nall.loc[all.floor_number == \"Bah\u00e7e kat\u0131\", \"floor_number\"] = \"0\"\nall.loc[all.floor_number == \"Y\u00fcksek Giri\u015f\", \"floor_number\"] = \"0\"\nall.loc[all.floor_number == \"Giri\u015f Kat\u0131\", \"floor_number\"] = \"0\"\nall.loc[all.floor_number == \"Zemin Kat\", \"floor_number\"] = \"0\"\nall.loc[all.floor_number == \"\u00c7at\u0131 Kat\u0131\", \"floor_number\"] = \"0\"\nall.loc[all.floor_number == \"20 ve \u00fczeri\", \"floor_number\"] = \"20\"\nall.loc[all.floor_number == \"10-20 aras\u0131\", \"floor_number\"] = \"15\"\nall.loc[all.floor_number == \"Bodrum Kat\", \"floor_number\"] = \"-1\"\nall.loc[all.floor_number == \"Kot 1\", \"floor_number\"] = \"-1\"\nall.loc[all.floor_number == \"Kot 2\", \"floor_number\"] = \"-2\"\nall.loc[all.floor_number == \"Kot 3\", \"floor_number\"] = \"-3\"\nall.loc[all.floor_number == \"Kot 4\", \"floor_number\"] = \"-4\"\nall[\"floor_number\"] = all[\"floor_number\"].astype(\"int\")","2fd3665d":"all[\"is_daire\"] = (all[\"building_type\"] == \"Daire\").astype(\"int8\")\nall[\"is_villa\"] = (all[\"building_type\"] == \"Villa\").astype(\"int8\")\nall[\"is_rezidans\"] = (all[\"building_type\"] == \"Rezidans\").astype(\"int8\")\nall[\"is_prefabric\"] = (all[\"building_type\"] == \"Prefabrik Ev\").astype(\"int8\")\nall[\"is_ciftlik\"] = (all[\"building_type\"] == \"\u00c7iftlik Evi\").astype(\"int8\")\nall[\"is_yali\"] = (all[\"building_type\"] == \"Yal\u0131 Dairesi\").astype(\"int8\")\nall[\"is_kosk\"] = (all[\"building_type\"] == \"K\u00f6\u015fk \/ Konak \/ Yal\u0131\").astype(\"int8\")\n\nall.loc[all.number_of_floors == \"20 ve \u00fczeri\", \"number_of_floors\"] = \"20\"\nall.loc[all.number_of_floors == \"10-20 aras\u0131\", \"number_of_floors\"] = \"15\"\nall.loc[all.number_of_floors == \"-\", \"number_of_floors\"] = None\nall[\"number_of_floors\"] = all[\"number_of_floors\"].astype(\"float\")\n\nall.number_of_floors.fillna(all.number_of_floors.median(), inplace=True)\nall.loc[all.number_of_floors < all.floor_number, \"number_of_floors\"] = all.floor_number","cc7a234a":"all.loc[all.heating == \"-\", \"heating\"] = \"Yok\"\nall[\"is_heating\"] = 1\nall.loc[all.heating == \"Yok\", \"is_heating\"] = 0\n\nall.loc[all.bath_count == \"-\", \"bath_count\"] = 0\nall.loc[all.bath_count == \"6 ve \u00fczeri\", \"bath_count\"] = 6\nall[\"bath_count\"] = all[\"bath_count\"].astype(\"int\")","d870897f":"all['scene_count'] = all.scene.str.count(\",\") + 1\nall.loc[(all.scene_count > 5) & (all.county == '\u0130stanbul-Beylikd\u00fcz\u00fc'), \"scene\"] = \"\u015eehir\"\nall['scene_count'] = all.scene.str.count(\",\") + 1\nall.loc[all.scene == '_', \"scene_count\"] = 0\n\nall[\"scene_city\"] = all[\"scene\"].str.contains(\"\u015eehir\").astype(\"int8\")\nall[\"scene_Do\u011fa\"] = all[\"scene\"].str.contains(\"Do\u011fa\").astype(\"int8\")\nall[\"scene_Cadde\"] = all[\"scene\"].str.contains(\"Cadde\").astype(\"int8\")\nall[\"scene_Deniz\"] = all[\"scene\"].str.contains(\"Deniz\").astype(\"int8\")\nall[\"scene_Bo\u011faz\"] = all[\"scene\"].str.contains(\"Bo\u011faz\").astype(\"int8\")\nall[\"scene_double_Bo\u011faz\"] = (all[\"scene\"].str.count(\"Bo\u011faz\") > 1).astype(\"int8\")\nall[\"scene_Da\u011f\"] = all[\"scene\"].str.contains(\"Da\u011f\").astype(\"int8\")\nall[\"scene_G\u00f6l\"] = all[\"scene\"].str.contains(\"G\u00f6l\").astype(\"int8\")\nall[\"scene_Havuz\"] = all[\"scene\"].str.contains(\"Havuz\").astype(\"int8\")\nall[\"scene_Nehir\"] = all[\"scene\"].str.contains(\"Nehir\").astype(\"int8\")\nall[\"scene_Park\"] = all[\"scene\"].str.contains(\"Park\").astype(\"int8\")\nall[\"scene_Vadi\"] = all[\"scene\"].str.contains(\"Vadi\").astype(\"int8\")\nall[\"scene_Ye\u015fil\"] = all[\"scene\"].str.contains(\"Ye\u015fil Alan\").astype(\"int8\")\nall.loc[all.city == '\u0130stanbul', \"scene_city\"] = 1\nall.loc[all.county == '\u0130stanbul-Pendik', \"scene_Bo\u011faz\"] = 0\nall.loc[all.county == '\u0130stanbul-Ba\u011fc\u0131lar', \"scene_Bo\u011faz\"] = 0\nall.loc[all.county == '\u0130stanbul-Beylikd\u00fcz\u00fc', \"scene_Bo\u011faz\"] = 0\nall.loc[all.county == '\u0130stanbul-Ba\u011fc\u0131lar', \"scene_Deniz\"] = 0","fc70734b":"all.loc[all.carpark == \"-\", \"carpark\"] = \"Yok\"\nall.loc[all.carpark == \"-\", \"carpark\"] = \"Yok\"\nall[\"carpark_kapali\"] = all[\"carpark\"].str.contains(\"Kapal\u0131\").astype(\"int8\")\nall[\"carpark_acik\"] = all[\"carpark\"].str.contains(\"A\u00e7\u0131k\").astype(\"int8\")\nall[\"carpark_\u00dccretli\"] = all[\"carpark\"].str.contains(\"\u00dccretli\").astype(\"int8\")","37cbdcf9":"all[\"normalized_price\"] = all[\"price\"] \/ all[\"index_multiplier\"]\nall[\"normalized_price_log\"] = np.log1p(all[\"normalized_price\"])\n\nall[\"county_normalized_price\"] = all[\"price\"] \/ all[\"county_index_multiplier\"]\nall[\"county_normalized_price_log\"] = np.log1p(all[\"county_normalized_price\"])\n\nall[\"district_priceperare\"] = all.iloc[train_idxes].groupby(\"district\")[\"normalized_price\"].transform('mean') \/ all.iloc[train_idxes].groupby(\"district\")[\"net_area\"].transform('mean')\nall[\"city_priceperare\"] = all.iloc[train_idxes].groupby(\"city\")[\"normalized_price\"].transform('mean') \/ all.iloc[train_idxes].groupby(\"city\")[\"net_area\"].transform('mean')\nall[\"county_priceperare\"] = all.iloc[train_idxes].groupby(\"county\")[\"normalized_price\"].transform('mean') \/ all.iloc[train_idxes].groupby(\"county\")[\"net_area\"].transform('mean')\n\nall = pd.merge(all, usdtry, on=\"date\", how=\"left\")\nall[\"price_in_usd\"] = all[\"price\"] \/ all[\"usdtry\"]\nall[\"price_in_usd_per_meter\"] = all[\"price_in_usd\"] \/ all[\"gross_area\"]\nall[\"price_in_usd_log\"] = np.log1p(all[\"price_in_usd\"])","bfd85293":"basedate = pd.Timestamp(\"2019-01-01\")\nall[\"days_passed\"] = (all[\"date\"] - basedate).dt.days\n\nall = pd.merge(all, credit_rates, on=\"date\", how=\"left\")\n\n\nall[\"floor_number\"] = all[\"floor_number\"] + 4\n\nall[\"priceperarea\"] = all[\"price\"] \/ all[\"net_area\"]","cc7ed299":"adversarial_validation = True\nhp_optimize = False\nisolation_forest = False\nrun_train = True\nrun_plot = False\nlofo_importance = False\ncheck_val_results = True\nmodel_type = \"xgb\"\ntrial = 1","844f9367":"features = [\n    \"building_type\",\n    \"building_age\",\n    \"floor_number\",\n    \"number_of_floors\",\n    \"heating\",\n    \"bath_count\",\n    \"carpark\",\n    \"earthquake_regulations\",\n    \"elevator\",\n    \"playground\",\n    \"parent_bath\",\n    \"city\",\n    \"county\",\n    \"district\",\n    \"nroom_count\",\n    \"lroom_count\",\n    \"room_count\",\n    \"avg_room_area\",\n    \"is_summerplace\",\n    \"scene_city\",\n    \"scene_Do\u011fa\",\n    \"scene_Cadde\",\n    \"scene_Da\u011f\",\n    \"scene_Havuz\",\n    \"scene_Vadi\",\n    \"scene_Ye\u015fil\",\n    \"scene_count\",\n    \"is_new\",\n    \"is_mustakil\",\n    \"is_whole_building\",\n    \"net_area\",\n    \"is_underground\",\n    \"is_top\",\n    \"is_teras\",\n    \"gross_area - net_area\",\n    \"gross_area \/ net_area\",\n    \"gross_area\",\n    \"is_heating\",\n    \"carpark_\u00dccretli\",\n    \"scene_Park\",\n    \"scene_G\u00f6l\",\n    \"changing_room\",\n    \"scene_Deniz\",\n    \"scene_Bo\u011faz\",\n    \"scene_double_Bo\u011faz\",\n    \"scene_Nehir\",\n    \"carpark_acik\",\n    \"is_daire\",\n    \"is_villa\",\n    \"is_rezidans\",\n    \"is_prefabric\",\n    \"is_ciftlik\",\n    \"is_yali\",\n    \"is_kosk\",\n    #\"credit_rate\",\n    \"carpark_kapali\",\n    \"intercom\",\n]\ncategorical_features = [\n    #\"building_type\",\n    \"heating\",\n    \"carpark\",\n    \"intercom\",\n    \"earthquake_regulations\",\n    \"elevator\",\n    \"playground\",\n    #\"changing_room\",\n    \"parent_bath\",\n    \"changing_room\",\n    \"city\",\n    \"county\",\n    \"district\",\n    \"is_summerplace\",\n    \"is_new\",\n    \"is_mustakil\",\n    \"is_whole_building\",\n    \"is_teras\",\n    \"is_underground\",\n    \"is_top\",\n    \"is_heating\",\n    #\"scene_city\",\n    \"scene_Do\u011fa\",\n    \"scene_Cadde\",\n    \"scene_Deniz\",\n    \"scene_Bo\u011faz\",\n    #\"scene_double_Bo\u011faz\",\n    \"scene_Da\u011f\",\n    \"scene_G\u00f6l\",\n    \"scene_Havuz\",\n    \"scene_Nehir\",\n    \"scene_Park\",\n    \"scene_Vadi\",\n    \"scene_Ye\u015fil\",\n    \"carpark_kapali\",\n    \"carpark_acik\",\n    \"carpark_\u00dccretli\",\n    \"is_daire\",\n    \"is_villa\",\n    \"is_rezidans\",\n    \"is_prefabric\",\n    \"is_ciftlik\",\n    \"is_yali\",\n    \"is_kosk\",\n]\ntarget_feature = \"price_in_usd_log\"","d4ebf73d":"# Duplicated Rows\n# duplicated_rows 3082 rows\nall['is_duplicated'] = all.drop(['id'], axis=1).duplicated()\nduplicated_indexes = all[all.is_duplicated == 1].index\nnot_duplicated_indexes = all[all.is_duplicated == 0].index","f10f7ca0":"districts_only_exists_in_train = set(all[all.is_train == 1].district.unique().tolist()).difference(set(all[all.is_train == 0].district.unique().tolist()))\nother_district_indexes = all[all.district.isin(districts_only_exists_in_train)].index\n\ntrain_keep_indexes = not_duplicated_indexes\n\ntrain_idxes = all[all.is_train == 1].index\ntrain_idxes = train_idxes.difference(duplicated_indexes)","a2443f7d":"#Category Encoding\nall[categorical_features] = all[categorical_features].astype(\"category\")\nle = LabelEncoder()\nall[categorical_features] = all[categorical_features].apply(le.fit_transform)","61557994":"if adversarial_validation:\n    adv_ban_list = [\"days_passed\", \"credit_rate\", \"building_type\"]\n    features_adv = [feat for feat in features if feat not in adv_ban_list]\n    y = all.loc[train_keep_indexes][\"is_train\"]\n    X = all.loc[train_keep_indexes][features_adv]\n\n    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n    oof = np.zeros(len(X))\n\n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X.values, y)):\n        print(\"fold n\u00b0{}\".format(fold_))\n\n        classifier = RFC(n_estimators=1000, n_jobs=-1, verbose=True)\n        classifier.fit(all.iloc[trn_idx][features_adv], y.iloc[trn_idx])\n        oof[val_idx] = classifier.predict_proba(all.iloc[val_idx][features_adv])[:, 1]\n    print(f\"ROC Adv score: {roc_auc_score(y, oof)}\")\n\n    all.loc[train_keep_indexes, 'adv_score'] = oof\n    top_2_district_indexes = all.loc[train_idxes].sort_values('adv_score').groupby('district').head(2).index.difference(other_district_indexes).to_numpy()\n    val_idxes = all.loc[train_idxes].sort_values('adv_score')[:5000].index.to_numpy()\n    val_idxes = np.union1d(top_2_district_indexes, val_idxes)\n    val_idxes_weights = 1 - all.loc[val_idxes, \"adv_score\"]\n    val_idxes_weights = val_idxes_weights \/ val_idxes_weights.mean()\n    train_idx_to_drop = all.loc[train_idxes].sort_values('adv_score', ascending=False)[:5000].index\n    train_train_idxes = train_idxes.difference(val_idxes).difference(train_idx_to_drop)\n    with open(\".\/val_indexes.pickle\", \"wb\") as handle:\n        pickle.dump(val_idxes, handle)\n    with open(\".\/val_weights.pickle\", \"wb\") as handle:\n        pickle.dump(val_idxes_weights, handle)\n    with open(\".\/train_indexes.pickle\", \"wb\") as handle:\n        pickle.dump(train_train_idxes, handle)\nelse:\n    with open(\".\/val_indexes.pickle\", \"rb\") as handle:\n        val_idxes = pickle.load(handle)\n    with open(\".\/val_weights.pickle\", \"rb\") as handle:\n        val_idxes_weights = pickle.load(handle)\n    with open(\".\/train_indexes.pickle\", \"rb\") as handle:\n        train_train_idxes = pickle.load(handle)","f9c871b0":"features.remove(\"building_type\")\ntrain_x = all.iloc[train_train_idxes][features]\ntrain_y = all.iloc[train_train_idxes][target_feature]\n\nval_x = all.iloc[val_idxes][features]\nval_y = all.iloc[val_idxes][target_feature]\n\nX_test = all[all.is_train == 0][features]","fe2374cf":"# Add more train test for high prices\n# additional_idxes = train_y[train_y > 14].index\n# train_x = pd.concat([train_x, train_x.loc[additional_idxes]], axis=0)\n# train_y = pd.concat([train_y, train_y.loc[additional_idxes]], axis=0)","7a3417ea":"test_district_distribution = X_test.district.value_counts() \/ len(X_test)\nval_district_distribution = val_x.district.value_counts() \/ len(val_x)\ntrain_district_distribution = train_x.district.value_counts() \/ len(train_x)\nval_district_weights = test_district_distribution \/ val_district_distribution\ntrain_district_weights = test_district_distribution \/ train_district_distribution\n\nval_district_weights.fillna(0, inplace=True)\ntrain_district_weights.fillna(0, inplace=True)\n\nval_set_district_weights = val_district_weights[val_x.district]\ntrain_set_district_weights = train_district_weights[train_x.district]\n\nval_set_district_weights = val_set_district_weights \/ val_set_district_weights.mean()\ntrain_set_district_weights = train_set_district_weights \/ train_set_district_weights.mean()\n\nall['val_w'] = 0\nall['train_w'] = 0\nall.loc[val_idxes, 'val_w'] = val_set_district_weights.reset_index()['district']\nall.loc[train_train_idxes, 'train_w'] = train_set_district_weights.reset_index()['district']","35b41ffd":"if isolation_forest:\n    model = IsolationForest(n_estimators=500, max_samples='auto', contamination=float(0.001), max_features=1.0)\n    model.fit(train_x, train_y)\n    train_x['preds'] = model.predict(train_x)\n    nominal_indexes = train_x[train_x.preds == 1].index\n    train_x = all.iloc[nominal_indexes][features]\n    train_y = all.iloc[nominal_indexes][target_feature]\n    train.head()","ebef2373":"# Create xgd data\ndtrain = xgb.DMatrix(train_x.values, train_y.values, weight=train_set_district_weights, missing=0.0, nthread=-1)\ndval = xgb.DMatrix(val_x.values, val_y.values, missing=0.0, nthread=-1)\ndtest = xgb.DMatrix(X_test.values)","8db4c810":"# Custom metric\ndef weighted_exp_usd_rmse(pred: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n    y = dtrain.get_label()\n    pred = np.exp(pred) * 5.28\n    y = np.exp(y) * 5.28\n    error = (pred - y) ** 2\n    # error = error * val_idxes_weights\n    score = np.sqrt(np.mean(error))\n    return 'WE_usd_rmse', float(score)","b3e5794e":"def objective_xgb(trial):\n    # To select which parameters to optimize, please look at the XGBoost documentation:\n    # https:\/\/xgboost.readthedocs.io\/en\/latest\/parameter.html\n    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, observation_key='validation_0-rmse')\n    param = {\n        \"tree_method\": \"gpu_hist\",  # Use GPU acceleration\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 1e3),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 1e3),\n        \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", [0.8, 0.9, 1.0]),\n        \"subsample\": trial.suggest_categorical(\"subsample\", [0.6, 0.7, 0.8, 1.0]),\n        \"learning_rate\": trial.suggest_float(\"eta\", 0.002, 0.1),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 4000, 400),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 15),\n        \"random_state\": 42,\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 1e-4, 1e4),\n        \"objective\": 'reg:squarederror'\n    }\n    model = XGBRegressor(**param)\n\n    model.fit(\n        train_x,\n        train_y,\n        sample_weight=train_set_district_weights,\n        eval_set=[(val_x, val_y)],\n        eval_metric=\"rmse\",\n        early_stopping_rounds=70,\n        callbacks=[pruning_callback],\n        verbose=False,\n    )\n\n    preds = model.predict(val_x)\n\n    # return mse(pred, val_y, squared=False)\n    if target_feature == \"price_in_usd_log\":\n        oof_adjusted = np.exp(pred) * 5.28\n        train_y_adjusted = np.exp(val_y) * 5.28\n    elif target_feature == \"price_in_usd\":\n        oof_adjusted = pred * 5.28\n        train_y_adjusted = val_y * 5.28\n    elif target_feature == \"county_normalized_price_log\":\n        oof_adjusted = np.exp(pred)\n        train_y_adjusted = np.exp(val_y)\n    elif target_feature == \"county_normalized_price\":\n        oof_adjusted = pred\n        train_y_adjusted = val_y\n    elif target_feature == \"normalized_price_log\":\n        oof_adjusted = np.exp(pred)\n        train_y_adjusted = np.exp(val_y)\n    else:\n        oof_adjusted = np.exp(oof)\n        train_y_adjusted = np.exp(val_y)\n\n    errors = (train_y_adjusted - oof_adjusted) ** 2\n    errors = errors * val_set_district_weights\n    # errors = errors * val_idxes_weights\n    return np.sqrt(np.mean(errors))","407a8e04":"def objective_lgb(trial):\n\n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, metric='rmse')\n\n    param = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'device': 'gpu',\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n    }\n\n    gbm = lgb.train(params=param, train_set=dtrain, valid_sets=[dval],num_boost_round=2000,\n                    early_stopping_rounds=50, callbacks=[pruning_callback],\n                    verbose_eval=100)\n    preds = gbm.predict(val_x)\n    rmse = mse(val_y, preds, squared=False)\n    return rmse","a71552f2":"model = None\n\nif run_train:\n\n    if model_type == \"xgb\":\n        if hp_optimize:\n            \n            study = optuna.create_study(direction=\"minimize\")\n            study.optimize(objective_xgb, n_trials=10)\n            print(\"Number of finished trials:\", len(study.trials))\n            print(\"Best trial:\", study.best_trial.params)\n\n            best_params = study.best_params\n            best_params[\"tree_method\"] = \"gpu_hist\"\n            best_params[\"random_state\"] = 42\n        else:\n            # best_params = {'lambda': 0.07625074611819621, 'alpha': 17.17965668652807, 'colsample_bytree': 0.9, 'subsample': 0.8, 'eta': 0.06413320796249009, 'n_estimators': 2800, 'max_depth': 9, 'min_child_weight': 0.0001728063335245539}\n            best_params = {'lambda': 12.906735593486854, 'alpha': 0.2721164393950793, 'colsample_bytree': 0.8, 'subsample': 1.0, 'eta': 0.08639453515257925, 'n_estimators': 3600, 'max_depth': 14, 'min_child_weight': 0.0003164572981086507}\n        model = XGBRegressor(**(best_params))\n        model.fit(\n            train_x,\n            train_y,\n            sample_weight=train_set_district_weights,\n            eval_set=[(val_x, val_y)],\n            eval_metric=\"rmse\",\n            early_stopping_rounds=200,\n        )\n\n        model.save_model(f\".\/{model_type}_{trial}.model\")\n\n    elif model_type == \"lgb\":\n        study = optuna.create_study(direction=\"minimize\")\n        study.optimize(objective_lgb, n_trials=40)\n        print(\"Number of finished trials:\", len(study.trials))\n        print(\"Best trial:\", study.best_trial.params)\n\n        best_params = study.best_params\n        best_params[\"random_state\"] = 42\n\n        dtrain = lgb.Dataset(train_x, label=train_y)\n        dval = lgb.Dataset(val_x, label=val_y)\n        gbm = lgb.train(params=best_params, train_set=dtrain, valid_sets=[dval], num_boost_round=10000,\n                        early_stopping_rounds=100,\n                        verbose_eval=100)\n\n        gbm.save_model(f\"lgb_{trial}.model\")\n        model = lgb.Booster(model_file=f\"lgb_{trial}.model\")\n\nelse:\n\n    if model_type == \"xgb\":\n        model = xgb.Booster()\n        model.load_model(f\"{model_type}_{trial}.model\")  # load data\n    elif model_type == \"lgb\":\n        model = lgb.Booster(model_file=f\"lgb_{trial}.model\")","3f5cb8ac":"if check_val_results:\n    preds = model.predict(val_x)\n    val_x[\"preds\"] = preds\n    if target_feature == \"price_in_usd_log\":\n        val_x[\"preds\"] = np.exp(val_x[\"preds\"].abs()) * 5.28\n        val_x[\"price_target\"] = np.exp(val_y.abs()) * 5.28\n    if target_feature == \"price_in_usd\":\n        val_x[\"preds\"] = val_x[\"preds\"].abs() * 5.28\n        val_x[\"price_target\"] = val_y.abs() * 5.28\n    elif target_feature == \"county_normalized_price_log\":\n        val_x[\"preds\"] = np.exp(val_x[\"preds\"].abs())\n        val_x[\"price_target\"] = np.exp(val_y.abs())\n    elif target_feature == \"county_normalized_price\":\n        val_x[\"preds\"] = val_x[\"preds\"].abs()\n        val_x[\"price_target\"] = val_y.abs()\n    elif target_feature == \"normalized_price_log\":\n        val_x[\"preds\"] = np.exp(val_x[\"preds\"].abs())\n        val_x[\"price_target\"] = np.exp(val_y.abs())\n\n    errors = (val_x.preds - val_x.price_target) ** 2\n    errors_district = errors * val_set_district_weights\n    errors_val = errors * val_idxes_weights\n    val_score = errors.mean() ** 0.5\n    val_weight_score = errors_val.mean() ** 0.5\n    district_weight_score = errors_district.mean() ** 0.5\n    print(f\"Validation score: {val_score}\")\n    print(f\"Weight Validation score: {val_weight_score}\")\n    print(f\"Disctict Weight Validation score: {district_weight_score}\")\n\npreds = model.predict(X_test)\nsubmission[\"Expected\"] = preds\nsubmission = pd.merge(submission, all, left_on=\"Id\", right_on=\"id\")\nif target_feature == \"price_in_usd_log\":\n    submission[\"Expected\"] = np.exp(submission[\"Expected\"].abs()) * submission[\"usdtry\"]\nelif target_feature == \"price_in_usd\":\n    submission[\"Expected\"] = submission[\"Expected\"].abs() * submission[\"usdtry\"]\nelif target_feature == \"county_normalized_price_log\":\n    submission[\"Expected\"] = np.exp(submission[\"Expected\"].abs()) * submission[\"county_index_multiplier\"]\nelif target_feature == \"county_normalized_price\":\n    submission[\"Expected\"] = submission[\"Expected\"].abs() * submission[\"county_index_multiplier\"]\nelif target_feature == \"normalized_price_log\":\n    submission[\"Expected\"] = np.exp(submission[\"Expected\"].abs()) * submission[\"index_multiplier\"]\nprint(f\"We predicted: {submission.loc[submission.Id == 83476, 'Expected']}\")\nsubmission.loc[submission.Id == 83476, \"Expected\"] = 150000000 * 1.09\nprint(f\"Sub mean: {submission['Expected'].mean()}\")\nsubmission[[\"Id\", \"Expected\"]].to_csv(\n    f\"submission_{model_type}_{trial}.csv\", sep=\",\", index=False\n)","770eb336":"# County Indexes","2e2469cb":"# **Libraries**","bf85b9cb":"# Configurations","f20c5150":"# Import Data","85e27c22":"# EDA","3e0e6f89":"# Data Corrections"}}