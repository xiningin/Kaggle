{"cell_type":{"bfd211af":"code","5e924321":"code","39f53096":"code","f35d6568":"code","808e0888":"code","ca6c4916":"code","1379a131":"code","6a8f03e5":"code","52314928":"code","e88b5c6d":"code","1f5bd54a":"code","e446c847":"code","fa1843b1":"code","b1020971":"code","bcf1309e":"code","9d2b0595":"code","59349c00":"code","e91ee9ec":"code","05d2f5c6":"code","e3482074":"code","b5ebd53b":"code","c8df9b0e":"code","eeabb89f":"code","241e8898":"code","c7faf0fa":"code","ab321fc2":"code","ac46af89":"code","aaeb973d":"code","d23904e0":"code","32017f0c":"code","6fd8216f":"code","65ee6949":"code","95eab34e":"code","bc2766ec":"code","01677505":"code","3b20a9cd":"markdown","cd27df55":"markdown","d3a9a0fc":"markdown","dea81d7d":"markdown","a76767bb":"markdown","5b736d11":"markdown"},"source":{"bfd211af":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5e924321":"pip install seaborn==0.11.0","39f53096":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer","f35d6568":"df=pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","808e0888":"df.head()","ca6c4916":"df.info()","1379a131":"df.describe()","6a8f03e5":"#Check for null values\ndf.isnull().sum().sum()","52314928":"df['DEATH_EVENT'].value_counts()","e88b5c6d":"\ndf.loc[df['sex'] == 1, 'sex'] = 'Male'\ndf.loc[df['sex'] == 0, 'sex'] = 'Female'\n\n","1f5bd54a":"#Function for changing the category\ndef change_cat(coln):\n    df.loc[df[coln] == 1, coln] = 'YES'\n    df.loc[df[coln] == 0, coln] = 'NO'\n\n#Function for the reverse so we can use int values for prediction\ndef reverse_cat(coln):\n    df.loc[df[coln] == 'YES', coln] = 1\n    df.loc[df[coln] == 'NO', coln] = 0","e446c847":"change_cat('high_blood_pressure')\nchange_cat('DEATH_EVENT')\nchange_cat('anaemia')\nchange_cat('smoking')\nchange_cat('diabetes')","fa1843b1":"sns.countplot(x='DEATH_EVENT',data=df)","b1020971":"sns.distplot(df['age'],bins=40,kde=False)","bcf1309e":"sns.countplot(x='anaemia',hue='DEATH_EVENT',data=df)","9d2b0595":"sns.countplot(x='diabetes',hue=df['DEATH_EVENT'],data=df)","59349c00":"sns.countplot(x='smoking',hue='DEATH_EVENT',data=df)","e91ee9ec":"sns.countplot(x='sex',hue='DEATH_EVENT',data=df)","05d2f5c6":"#Histogram comparing some of the features in terms of Death event\nplt.figure(figsize=(20,20))\nfor i, col in enumerate(['creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']):\n    plt.subplot(4,4,i+1)\n    sns.histplot(x=df[col],hue=df['DEATH_EVENT'])\n    plt.tight_layout()","e3482074":"##Histogram comparing some of the features in terms of High blood pressure\nplt.figure(figsize=(20,20))\nfor i, col in enumerate(['creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']):\n    plt.subplot(4,4,i+1)\n    sns.histplot(x=df[col],hue=df['high_blood_pressure'])\n    plt.tight_layout()","b5ebd53b":"#Histogram comparing some of the features in terms of Smoking\nplt.figure(figsize=(20,20))\nfor i, col in enumerate(['creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']):\n    plt.subplot(4,4,i+1)\n    sns.histplot(x=df[col],hue=df['smoking'])\n    plt.tight_layout()","c8df9b0e":"#Histogram comparing some of the features in terms of Anaemia\nplt.figure(figsize=(20,20))\nfor i, col in enumerate(['creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']):\n    plt.subplot(4,4,i+1)\n    sns.histplot(x=df[col],hue=df['anaemia'])\n    plt.tight_layout()","eeabb89f":"plt.figure(figsize=(20,20))\nfor i, col in enumerate(['creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']):\n    plt.subplot(4,4,i+1)\n    sns.boxplot(x=df[col])\n    plt.tight_layout()","241e8898":"#Correlation heatmap\nc=df.corr()\nsns.heatmap(c,annot=True)","c7faf0fa":"#Bact to the original convention \nreverse_cat('high_blood_pressure')\nreverse_cat('DEATH_EVENT')\nreverse_cat('anaemia')\nreverse_cat('smoking')\nreverse_cat('diabetes')","ab321fc2":"#Log transformation of creatinine phosphokinase and creatinine phosphokinase\ndf['log_creatinine_phosphokinase']=np.log(df['creatinine_phosphokinase'])\ndf['log_serum_creatinine']=np.log(df['serum_creatinine'])","ac46af89":"#Defining X and Y\nX=df[['ejection_fraction','platelets','serum_sodium','time','log_creatinine_phosphokinase','log_serum_creatinine']]\ny=df['DEATH_EVENT']\ny=y.astype('int')","aaeb973d":"#Split into test and train\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","d23904e0":"scaler = StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\n","32017f0c":"#Applying logistic regression algorithm\nlr=LogisticRegression(random_state=0)\nlr.fit(X_train,y_train)\npredictions=lr.predict(X_test)\nprint(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions),'\\n')\nLR_acc=accuracy_score(y_test,predictions)\nprint('Accuracy:',LR_acc)\n","6fd8216f":"#Applying Decision Tree Classifier\ndt = DecisionTreeClassifier()\nparams = {'criterion':['gini', 'entropy'], \n          'random_state':[0]}\ndt1 = GridSearchCV(dt, param_grid=params)\ndt1.fit(X_train,y_train)\ndtpredictions = dt1.predict(X_test)\n#Confusion Matrix\nprint(confusion_matrix(y_test,dtpredictions))\n#Classsification Report\nprint(classification_report(y_test,dtpredictions),'\\n')\nDT_acc=accuracy_score(y_test,dtpredictions)\nprint('Accuracy:',DT_acc)","65ee6949":"#Applying Naive Bayes\nNB= GaussianNB()\nNB.fit(X_train,y_train)\nNBpredictions = NB.predict(X_test)\n\n#Confusion Matrix\nprint(confusion_matrix(y_test,NBpredictions))\n#Classification Report\nprint(classification_report(y_test,NBpredictions),'\\n')\nNB_acc=accuracy_score(y_test,NBpredictions)\nprint('Accuracy:',NB_acc)","95eab34e":"#SVM\nsvc = SVC()\nparams = {'kernel':['linear','rbf'], \n          'random_state':[0]}\nsvc1 = GridSearchCV(svc, param_grid=params)\nsvc1.fit(X_train,y_train)\nsvc_predictions = svc1.predict(X_test)\n#Confusion Matrix\nprint(confusion_matrix(y_test,svc_predictions))\n#Classification Report\nprint(classification_report(y_test,svc_predictions),'\\n')\nSVC_acc=accuracy_score(y_test,svc_predictions)\nprint('Accuracy:',SVC_acc)","bc2766ec":"#Random Forest\nrf=RandomForestClassifier()\nrf.fit(X_train,y_train)\nrf_pred=rf.predict(X_test)\nrf_acc=accuracy_score(y_test,rf_pred)\nprint(confusion_matrix(y_test,rf_pred))\nprint(classification_report(y_test,rf_pred),'\\n')\nprint('Accuracy:',rf_acc)","01677505":"#Comparison of various models\nmodels = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Naive Bayes','SVC', 'Decision Tree','Random Forrest Classifier'],\n    'Score': [LR_acc,NB_acc,SVC_acc,DT_acc,rf_acc]})\nmodels.sort_values(by='Score', ascending=False,ignore_index=True)\n","3b20a9cd":"For the sake of vizualizations,we will convert the 0s and 1s value to Yes and No respectively. Refering some notebooks, ive taken 0 as count of Females and 1 as count of males.","cd27df55":"No null values in this dataset, which is good.","d3a9a0fc":"A brief about the data\n* Age: The age of the patient\n* Anaemia: The presence of Anaemia. 1 if present, 0 if absent\n* creatinine_phosphokinase: The level of creatinine phosphokinase of the patient\n* ejection_fraction: Measurement of the heart's ejection fraction\n* High_blood_pressure: The presence of Anaemia. 1 if present, 0 if absent\n* platelets: Platelet count of the patient\n* serum_creatinine: level of creatinine in the blood\n* serum_sodium: level of sodium in the blood\n* sex: Male or Female\n* smoking: If the patient is a smoker. 1 if yes, 0 if no.\n* Death event: The target variable, 1 if it resulted in death, 0 if there was no death.","dea81d7d":"   # Heart failure prediction","a76767bb":"As seen from the histograms, the 2 features:creatinine phosphokinase and creatinine phosphokinase had a right skewed distribution, using the log transformation will conform it to normality.","5b736d11":"### We see that Random Forrest Classifier has performed the best with a 91% accuracy."}}