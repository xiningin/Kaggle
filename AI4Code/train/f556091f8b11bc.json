{"cell_type":{"b1924b28":"code","afaa223d":"code","2cca30cc":"code","cc4efe8b":"code","d111cae6":"code","a449ac51":"code","76d4538c":"code","6d01e81d":"code","9cb658aa":"code","5236be9c":"code","ba16ab3c":"code","24c96911":"code","5ce4bbca":"code","ee917bd0":"code","d4d2432c":"code","2208d2b3":"code","094b7d1c":"code","d095a299":"code","6323a560":"code","b9c66d8f":"code","bceae64e":"code","d9309737":"code","59693ae4":"code","7660921a":"code","add22a95":"code","2e271604":"code","e76e2a44":"code","636c3052":"code","b94f651b":"code","51f7b1c6":"code","b0c32059":"code","fd5702a8":"code","05805553":"markdown","c6ed3976":"markdown","fefe3189":"markdown","7818adce":"markdown","cbcc515c":"markdown","825b36a4":"markdown","c1397732":"markdown","b9081cdb":"markdown","b413d3d1":"markdown","f29534ed":"markdown","6629fe28":"markdown","e8648bbd":"markdown","ba044406":"markdown","3b46e22a":"markdown","134856c0":"markdown","cf211ba5":"markdown","e48a76e8":"markdown","42c9a7f2":"markdown","c1b54f18":"markdown","47ddd17c":"markdown","76c9e912":"markdown","25e74007":"markdown"},"source":{"b1924b28":"import pandas as pd\nimport numpy as np","afaa223d":"train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nsample = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","2cca30cc":"train.head()","cc4efe8b":"test.head()","d111cae6":"sample.head()","a449ac51":"train.shape, test.shape, sample.shape","76d4538c":"def remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',text)","6d01e81d":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)","9cb658aa":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nREPLACE_BY_SPACE_RE = re.compile('[\/(){}\\[\\]\\|@,;]')\nBAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\nstop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    text = text.lower()\n    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n    text = BAD_SYMBOLS_RE.sub(' ', text)\n    text = ' '.join(word for word in text.split() if word not in stop_words)\n    return text","5236be9c":"train = np.array(train)\ntest = np.array(test)","ba16ab3c":"train[:3]","24c96911":"test[:3]","5ce4bbca":"def search(input_string, search_string):\n    length = len(input_string)\n    start_index = []\n    length = len(input_string)\n    index = 0\n    while index < length:\n        i = input_string.find(search_string, index)\n        if i == -1:\n            return start_index\n        start_index.append(i)\n        index = i + 1\n    return start_index","ee917bd0":"## For example, we have:\n\nsearch(\"hello I am having a good day today, what about you?\", \"good day today\")\n\n# This will return the value of the character index where the first letter of the search_string starts.\n# In this case, it is the 20th position.","d4d2432c":"def convert_train_to_json(train_set): \n    \n    outer_list = []\n    \n    for row in train_set:\n        qid = row[0]        # As explained previously, this is the textID column value\n        context = row[1]    # As explained previously, this is the text column value\n        answer = row[2]     # As explained previously, this is the selected_text column value\n        question = row[-1]  # As explained previously, this is the sentiment column value\n\n                             # Here, we consider the sentiment value as \"question\" because given\n                             # the sentiment we, then predict what should be the selected_text.\n        inner_list = []              \n        answers = []\n        \n        # We need to run the following IF command because if there are non string values then the code \n        # will throw an error and this is what we have to prevent. \n        # Hence, as soon as the error comes, we ask the code to CONTINUE.\n        \n        if type(context) != str or type(answer) != str or type(question) != str: \n            continue\n        answer_starts = search(context, answer)\n        for answer_start in answer_starts:\n            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n            break\n        inner_list.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n\n        outer_list.append({'context': context.lower(), 'qas': inner_list})\n        \n    return outer_list","2208d2b3":"train = convert_train_to_json(train)","094b7d1c":"len(train)","d095a299":"train[:3]","6323a560":"def convert_test_to_json(test_set):\n    \n    outer_list = []\n    \n    for row in test_set:\n        \n        qid = row[0]\n        context = row[1]\n        question = row[-1]\n        inner_list = []\n                \n        if type(context) != str or type(question) != str:\n            continue\n            \n        answers = []\n        answers.append({'answer_start': 1000000, 'text': '__None__'}) # Random initialisation of values\n        inner_list.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n        outer_list.append({'context': context.lower(), 'qas': inner_list})\n    return outer_list","b9c66d8f":"test = convert_test_to_json(test)","bceae64e":"len(test)","d9309737":"test[:3]","59693ae4":"import os\nimport json\n\nos.makedirs('data', exist_ok = True)\n\nwith open('data\/train.json', 'w') as f:\n    json.dump(train, f)\n    f.close()\n    \nwith open('data\/test.json', 'w') as f:\n    json.dump(test, f)\n    f.close()","7660921a":"!pip install '\/kaggle\/input\/simple-transformers-pypi\/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '\/kaggle\/input\/simple-transformers-pypi\/simpletransformers-0.22.1-py3-none-any.whl' -q","add22a95":"from simpletransformers.question_answering import QuestionAnsweringModel","2e271604":"MODEL = '\/kaggle\/input\/transformers-pretrained-distilbert\/distilbert-base-uncased-distilled-squad\/'\n\nmodel = QuestionAnsweringModel('distilbert',  \n                               MODEL,\n                               args={'reprocess_input_data': True,\n                                     'overwrite_output_dir': True,\n                                     'learning_rate': 5e-5,\n                                     'num_train_epochs': 2,\n                                     'max_seq_length': 192,\n                                     'doc_stride': 64,\n                                     'fp16': False\n                                    }, \n                               use_cuda=True\n                              )","e76e2a44":"model.train_model('data\/train.json')","636c3052":"pred_df = model.predict(test)\npred_df = pd.DataFrame.from_dict(pred_df)","b94f651b":"pred_df.head()","51f7b1c6":"sample[\"selected_text\"] = pred_df[\"answer\"]","b0c32059":"sample.to_csv('submission.csv', index=False)","fd5702a8":"print(\"Everything is successful! Good Luck for the score!\")","05805553":"### Importing Libraries","c6ed3976":"### Reading train, test and sample submission data","fefe3189":"### Pre-processing of data","7818adce":"### Converting train into json format","cbcc515c":"### Natural Language Processing - M3\n### Maaz Ansari (J002), Riddhi Mehta (J030), Husain Ghadiali (J056)","825b36a4":"We observe that the columns are named according to the dictionary key values. Hence, we change the the column names according to the exact ones needed in sample_submission.csv","c1397732":"So, this is how the json format should be.\n\nOuter list has:\n* context\n* inner_list (key = qas)\n\nInner list has:\n* question\n* id\n* is_impossible - which is always False\n* answers\n\nAnswers has:\n* answer_start \n* selected_text","b9081cdb":"### Converting test into json format","b413d3d1":"### Importing the required pip install files which we added using the \"add data\" option in kaggle kernel using the URLs mentioned in the start of this kernel. ","f29534ed":"###### In this notebook, we focus on creating a model and training it for prediction on test data. We have planned to use the Question Answer model and for that we need to convert our data in json format.\n\nIt is important to understand that this kernel does not allow internet access.\nSo in order to use the QuestionAnswer Model froms simpletransformers library, we need to first add the following URL links into our input folder. \n\n* https:\/\/www.kaggle.com\/jonathanbesomi\/simple-transformers-pypi\n* https:\/\/www.kaggle.com\/jonathanbesomi\/transformers-pretrained-distilbert","6629fe28":"Here we observe that after converting the data into array format, we have shown the first three rows. So technically it is a list of lists. Let's focus on the first list. The values in it are of the column headings:\n* textID\n* text\n* selected_text\n* sentiment","e8648bbd":"### Converting the data into array format","ba044406":"### Dumping the json structure of train and test into .json files","3b46e22a":"### Search function","134856c0":"Similarly for test data, we only have the columns:\n* textID\n* text\n* sentiment","cf211ba5":"##### I believe that the format of the json file has already been explained previously for the train set. The explanation is same for test json.","e48a76e8":"### Viewing the data","42c9a7f2":"These are a few definitions that we created in order to clean the data. But, then while understanding the needs and requirements of the type of input that the Question Answering Model has, we dont use these functions for pre-processing. Although, these functions are highly robust and can clean dirtiest data! It can be used to explore other models for this problem statement.","c1b54f18":"# -----------THE END-----------","47ddd17c":"#### We finally save our submission file in the format required. And now we are ready to obtain a score!","76c9e912":"##### So this means that we have to select those phrases from the text in the test data that are expressing the sentiment which is asked. And to bring it in a format that is required, we make the following three very important functions.","25e74007":"### Predicting the selected_text of the test set using the weights of the above model"}}