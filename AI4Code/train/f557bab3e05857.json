{"cell_type":{"902352a9":"code","0d588bcd":"code","d8e3fe7b":"code","ac2a053f":"code","4732526b":"code","c3a2acb6":"code","2c869932":"code","95f4e266":"code","0f79b939":"code","b32b0b36":"code","4fb4025e":"code","3bc69b0a":"code","fa132120":"code","e63121ce":"code","18280a46":"code","3bf6b586":"code","400a8d4a":"markdown","fd61e1f5":"markdown","d290bd91":"markdown","5de47c99":"markdown","1df2db88":"markdown","b1ea1697":"markdown","ed4f4037":"markdown","a1fe74da":"markdown","41cc42d3":"markdown","23d98dc5":"markdown","08d95189":"markdown","96510d9b":"markdown","d764a1a8":"markdown","27163256":"markdown","ca056745":"markdown","4b25820e":"markdown","26fde3ef":"markdown","1967eeab":"markdown","5f4191da":"markdown","ef7feb17":"markdown","9db0441c":"markdown","d1abf099":"markdown","87a8c1e1":"markdown","191176ee":"markdown"},"source":{"902352a9":"import numpy as np\nimport pandas as pd\nimport zipfile\nimport os\nfrom keras.preprocessing.image import load_img, ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nfrom keras.models import model_from_json\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\", \"r\") as z:\n    z.extractall(\".\")\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\", \"r\") as z:\n    z.extractall(\".\")\n","0d588bcd":"# Lista de las categorias\ncategorias = []\n# Lista de archivos dentro de los datos de train\narchivos = os.listdir(\"train\")\n# Bucle para obtener los nombres de los archivos (Etiquetas de salida)\nfor archivo in archivos:\n    categoria = archivo.split('.')[0]\n    if categoria == 'dog':\n        categorias.append(\"dog\")\n    else:\n        categorias.append(\"cat\")\n        \n# Se crea un dataframe en base del nombre del archivo y la categoria (tipo de animal)\ndf = pd.DataFrame({\n    'archivo': archivos,\n    'categoria': categorias\n})\nprint(categoria, '\\n', df)","d8e3fe7b":"# Separamos dos conjuntos, train(80% del dataset) y test(20%).\ntrain, test = train_test_split(df, test_size=0.20, random_state=42)\n\n# Reseteamos los index para vayan al comienzo de daatframe.\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\n# Imprimimos el tamano de los dataframes.\nprint(train.shape, '<-->', test.shape)","ac2a053f":"# Generador De Entrenamiento (Preprocesamiento de las imagenes)\nTAM_IMG = (128, 128)\n\"\"\"\nGeneramos nuevas imagenes en base a las pre existentes, por ejmplo, podemos cambiar el rango de rotacion, \ncortamos la imagen, hacemos zoom, volteamos, entre otras tecnicas para que de esta manera podamos tener\nuna mayor cantidad de imagenes para entrenar y hacer el testing.\n\n\"\"\"\ntrain_image_data = ImageDataGenerator(\n    rotation_range = 15,\n    rescale = 1.\/255,\n    shear_range = 0.1,\n    zoom_range=0.2,\n    horizontal_flip = True,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1\n)\n\n# Procedemos ha generar las imagenes y preprocesarlas.\ntrain_generador = train_image_data.flow_from_dataframe(\n    train,\n    'train\/',\n    x_col = 'archivo',\n    y_col = 'categoria',\n    target_size = TAM_IMG,\n    class_mode = 'categorical',\n    batch_size = 32\n)\n\n# Escalamos la imagen diviendo cada pixel para 255.\ntest_image_data = ImageDataGenerator(rescale=1.\/255)\ntest_generador = test_image_data.flow_from_dataframe(\n    test,\n    'train\/',\n    x_col = 'archivo',\n    y_col = 'categoria',\n    target_size = TAM_IMG,\n    class_mode = 'categorical',\n    batch_size = 32\n)","4732526b":"# Modelo para el entrenamiento\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nmodelo = Sequential()\n\nmodelo.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\nmodelo.add(BatchNormalization())\nmodelo.add(MaxPooling2D(pool_size=(2, 2)))\nmodelo.add(Dropout(0.25))\n\nmodelo.add(Conv2D(64, (3, 3), activation='relu'))\nmodelo.add(BatchNormalization())\nmodelo.add(MaxPooling2D(pool_size=(2, 2)))\nmodelo.add(Dropout(0.25))\n\nmodelo.add(Conv2D(128, (3, 3), activation='relu'))\nmodelo.add(BatchNormalization())\nmodelo.add(MaxPooling2D(pool_size=(2, 2)))\nmodelo.add(Dropout(0.25))\n\nmodelo.add(Conv2D(128, (3, 3), activation='relu'))\nmodelo.add(BatchNormalization())\nmodelo.add(MaxPooling2D(pool_size=(2, 2)))\nmodelo.add(Dropout(0.25))\n\nmodelo.add(Flatten())\nmodelo.add(Dense(512, activation = 'relu'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(2, activation='softmax'))\n\nmodelo.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\nmodelo.summary()","c3a2acb6":"train_shape = train.shape[0]\ntest_shape = test.shape[0]\n\nhistory = modelo.fit_generator(\n    train_generador,\n    epochs = 25,\n    validation_data = test_generador,\n    validation_steps = test_shape\/\/64,\n    steps_per_epoch = train_shape\/\/64,\n)","2c869932":"accuracy_training = history.history['accuracy']\naccuracy_testing = history.history['val_accuracy']\nepochs = 26","95f4e266":"plt.rcParams[\"figure.figsize\"] = (12,8)\nplt.grid()\nplt.plot(accuracy_training, color='b', label=\"Training accuracy\")\nplt.xticks(np.arange(1, epochs, 1))\nplt.xlabel('EPOCHS')\nplt.ylabel('Accuracy en Training')\nplt.tight_layout()\nplt.show()\n","0f79b939":"plt.rcParams[\"figure.figsize\"] = (12,8)\nplt.grid()\nplt.plot(accuracy_testing, color='r')\nplt.xticks(np.arange(1, epochs, 1))\nplt.xlabel('EPOCHS')\nplt.ylabel('Accuracy en Testing')\nplt.tight_layout()\nplt.show()\n","b32b0b36":"def guardar_pesos(nombre_archivo='pesos.h5'):\n    modelo.save_weights(nombre_archivo)\n\ndef guardar_modelo(nombre_archivo='modelo.json'):\n    modelo_json = modelo.to_json()\n    with open(nombre_archivo, \"w\") as json_file:\n        json_file.write(modelo_json)\n\ndef cargar_modelo(archivo_modelo='modelo.json', archivo_pesos='pesos.h5'):\n    with open(archivo_modelo, 'r') as f:\n        modelo = model_from_json(f.read())\n    \n    modelo.load_weights(archivo_pesos)\n    \n    return modelo\n\nmodelo = cargar_modelo(archivo_modelo='..\/input\/cats-v-dogs-leo\/modelo.json', archivo_pesos='..\/input\/cats-v-dogs-leo\/pesos.h5')","4fb4025e":"archivos_test = os.listdir(\"test1\")\ntest1 = pd.DataFrame({\n    'archivo': archivos_test\n})\nmuestras = test1.shape[0]\nprint(muestras)","3bc69b0a":"# Preprocesamiento y generador de imagenes para testing.\nTAM_IMG = (128, 128)\n\ntest_generador = ImageDataGenerator(rescale=1.\/255)\ntest_gen = test_generador.flow_from_dataframe(\n    test1,\n    'test1',\n    x_col = 'archivo',\n    y_col = None,\n    class_mode = None,\n    target_size = TAM_IMG,\n    batch_size = 32,\n    shuffle = False\n)","fa132120":"prediccion = modelo.predict_generator(test_gen, steps=np.ceil(muestras\/32))","e63121ce":"test1['categoria'] = np.argmax(prediccion, axis = 1)\nlabel_map = dict((v, k) for k, v in train_generador.class_indices.items())\ntest1['categoria'] = test1['categoria'].replace(label_map)","18280a46":"from io import BytesIO\nfrom six.moves import urllib\nfrom keras.preprocessing import image\n\nTAM_IMG = (128, 128)\n\n\ndef predecir_img(URL):\n    img = None\n    with urllib.request.urlopen(URL) as url:\n        img = load_img(BytesIO(url.read()), target_size=(128, 128))\n    imagen = img\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img \/= 255\n    resultado = modelo.predict(img)\n    val0 = resultado.tolist()[0][0]\n    val1 = resultado.tolist()[0][1]\n    if val0 > val1:\n        return ('GATO', val0, imagen)\n    elif val1 > val0:\n        return ('PERRO', val1, imagen)\n\nplt.figure(figsize=(12, 12))\n    \nanimal, accuracy, imagen = predecir_img('https:\/\/static.iris.net.co\/semana\/upload\/images\/2019\/6\/18\/620159_1.jpg')\nprint(animal +', probabilidad: ', str(round(accuracy*100, 2))+'%')\nplt.subplot(5, 3, 1)\nplt.imshow(imagen)\n\nanimal, accuracy, imagen = predecir_img('https:\/\/www.petdarling.com\/articulos\/wp-content\/uploads\/2014\/08\/gatos-persa.jpg?width=1200&enable=upscale')\nprint(animal +', probabilidad: ', str(round(accuracy*100, 2))+'%')\nplt.subplot(5, 3, 2)\nplt.imshow(imagen)\n\nplt.tight_layout()\nplt.show()","3bf6b586":"# METODO \nfrom keras.preprocessing import image\n\ndef display_stats(sample_id = 5):\n    train_len = len([name for name in os.listdir('test1')])\n    \n    if sample_id < train_len:\n        names = []\n        datos = dict()\n        for name in os.listdir('test1'):\n            names.append(name)\n        file = load_img('test1\/'+ names[sample_id], target_size=(128, 128))\n        datos['Imagen:'] = names[sample_id]\n        img = image.img_to_array(file)\n        datos['Valor minimo:'] = np.min(img)\n        datos['Valor maximo:'] = np.max(img)\n        datos['Shape:'] = img.shape\n        img = np.expand_dims(img, axis=0)\n        img \/= 255\n        \n        resultado = modelo.predict(img)\n        val0 = resultado.tolist()[0][0]\n        val1 = resultado.tolist()[0][1]\n        if val0 > val1:\n            #return ('GATO', val0, imagen)\n            datos['% Prediccion:'] = round(val0*100, 2)\n            datos['ETIQUETA'] = 'GATO'\n        elif val1 > val0:\n            datos['% Prediccion:'] = round(val1*100, 2)\n            datos['ETIQUETA'] = 'PERRO'\n        for x, y in datos.items():\n            print(x, '\\t', y)\n        print()\n        plt.imshow(file)\n \n# EJEMPLO PERRO\ndisplay_stats(27)\n# EJEMPLO GATO\n#display_stats(98)\n","400a8d4a":"Declaramos un Preprocesador para las imagenes de test, este procesador se encarga de genenrar mas im\u00e1genes para que la red aprenda con un numero mayor de registros en test.","fd61e1f5":"# Concluciones:\n\n*  En cuanto a lo elaborado en esta pr\u00e1ctica aprendemos sobre el manejo de im\u00e1genes para ingresar dicha informaci\u00f3n en una red neuronal aplicando reducci\u00f3n de dimensiones y capas que obtienen la informaci\u00f3n m\u00e1s relevante de las im\u00e1genes.\n*  Frente a los resultados obtenidos podemos establecer que en determinados casos una optimizaci\u00f3n de par\u00e1metros no refleja mejora en la precisi\u00f3n de una red neuronal.\n* En particular las redes neuronales tienen mejor desempe\u00f1o en comparaci\u00f3n con otros algoritmos ya que simulan el comportamiento de las redes neuronales humanas.\n","d290bd91":"M\u00e9todo donde se puede visualizar una imagen del dataset determinando por un \u00edndice.","5de47c99":"<h2> Almacenamiento Del Modelo y Pesos <\/h2>","1df2db88":"<h2>Preprocesamiento De Los Datos<\/h2>","b1ea1697":"<h2>Obtenci\u00f3n De Los Resultados <\/h2>","ed4f4037":"<h2>Splitting Del Dataset<\/h2>","a1fe74da":"<h2> Preprocesamiento De Los Datos Para Testing <\/h2>","41cc42d3":"# Universidad Polit\u00e9cnica Salesiana \n## Presentaci\u00f3n de modelo de red neuronal convolucional CNN\n\nDescripci\u00f3n Dataset: \n \nEn la presente practica realizaremos la clasificaci\u00f3n entre perros y gatos en base al conjunto de datos llamado Asirra disponible en kaggle consiste en 25,000 de im\u00e1genes que fueron clasificadas manualmente por personas de miles de refugios de animales dichas im\u00e1genes est\u00e1n etiquetadas como 1= perro, 0= gato , este conjunto de datos tiene cierto grado de complejidad porque las im\u00e1genes ofrecen distintos tonos de iluminaci\u00f3n y distintas poses en las que se encuentran los perros como los gatos.\n\nEnlace \n[https:\/\/www.kaggle.com\/c\/dogs-vs-cats](https:\/\/)","23d98dc5":" Separamos el conjunto de train y test, luego indicamos que los \u00edndices o puteros est\u00e9n en el comienzo de los dataframes.","08d95189":"Establecemos un conjunto de par\u00e1metros para generar m\u00e1s im\u00e1genes partiendo de las que ya tenemos, buscando generar m\u00e1s datos para que la red neuronal entrene con mas informaci\u00f3n, estos par\u00e1metros se fijan en la variable train_image_data. Luego hacemos uso del m\u00e9todo flow_from_dataframe() donde especificamos los par\u00e1metros anteriores y hacemos referencia a el apartado de train del dataset anterior, pro ultimo procedemos a realizar una normalizaci\u00f3n de los valores de los pixeles. \n\nLas im\u00e1genes de este conjunto de datos tienen la dimensi\u00f3n de 128x128 y contiene tres canales.","96510d9b":"<h2> Entrenamiento De La CNN <\/h2>","d764a1a8":"<h1>Se importan las librerias necesarias para la practica<\/h1>","27163256":"El modelo de red neuronal propuesto presentamos tres de capas convolucionales de 32, 64, 128 neuronas las donde se aplica un filtro(kernel) de 3x3 con activaci\u00f3n relu (en la primera capa se establece la dimensi\u00f3n de la imagen en este caso es 128x128 con 3 canales), adem\u00e1s se realizamos un max pooling (obtiene los pixeles m\u00e1s representativos) de una dimensi\u00f3n de 2x2, La capa de aplanamiento consta de 256 neuronas.\n\nEn la capa de salida tenemos solamente dos neuronas porque en este caso de estudio vamos a clasificar dos clases (perros y gatos) donde aplicamos una activaci\u00f3n softmax.\n\nEl modelo general tendr\u00e1 una funci\u00f3n de perdida categorical_crossentropy en conjunto con un optimizador rmsprop.\n","ca056745":"<h2> Agrupamiento De Los Resultados<\/h2>","4b25820e":"<h3> Predicci\u00f3n De Im\u00e1genes A Trav\u00e9s De Im\u00e1genes De Testing <\/h3>","26fde3ef":"<h2>Modelo De La Red Neuronal Convolucional<\/h2>","1967eeab":"<h2> Predicci\u00f3n De Los Datos De Testing <\/h2>","5f4191da":"<h2> Predicci\u00f3n De Resultados A Trav\u00e9s De URL's <\/h2>","ef7feb17":"Declaramos las funciones que nos permitir\u00e1n guardar y cargar los modelos de la red neuronal y tambi\u00e9n guardar los pesos de la misma.","9db0441c":"<h2>Descripci\u00f3n del Dataset<\/h>","d1abf099":"\nEste conjunto de datos est\u00e1 conformado por 25.000 im\u00e1genes entonces en el siguiente bloque de c\u00f3digo procederemos a obtener informaci\u00f3n de las etiquetas, recorri\u00e9ndolas mediante un ciclo for, Luego procedemos a generar el dataframe para su posterior estudio.","87a8c1e1":"<h2> Listado De Archivos Para Testing <\/h2>","191176ee":"Declaramos una funci\u00f3n que nos permite predecir si lo que representa una imagen corresponde a un perro o gato, como par\u00e1metro recibimos la url de la imagen a clasificar y como resultado obtenemos imprimimos la imagen ingresada acompa\u00f1ada del porcentaje de precisi\u00f3n con la que la red neuronal determina para esa imagen. "}}