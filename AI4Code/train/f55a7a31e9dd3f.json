{"cell_type":{"32ed1226":"code","f552b58c":"code","1381faa2":"code","2608bbd2":"code","1a3b3930":"code","c8e8fbd6":"code","0fb7308a":"code","7f4f4e5f":"code","9de18d03":"code","257bd604":"code","52e2a074":"code","5907f61a":"code","48cafea7":"code","e44730a5":"code","685226cd":"code","ecee8348":"code","3210ad9a":"code","cf4ebcf4":"code","12854895":"code","51594829":"code","b61aea2c":"code","0151138d":"code","04359a8e":"code","96203e35":"code","0db7429a":"code","0390ee00":"code","05005cee":"code","b2cb81d6":"code","d977c539":"code","2a5f3853":"code","9ddfa7eb":"code","a1d4c760":"code","edf2efe1":"code","f8b8dd88":"code","bfeed050":"code","6112cf32":"code","b0b80fee":"code","9a523ec8":"code","9f667dcd":"code","d594875d":"code","695f4c52":"code","27d49dd7":"code","e1367751":"code","9e5cdabd":"code","12a1f6c2":"code","00b44d80":"code","fb08b64b":"code","e98819cf":"code","55fb9461":"code","b7c52c61":"code","34839c3f":"code","b44e13c3":"code","99dd5798":"code","b7010376":"code","ce4e1522":"code","6d2cb54d":"code","b4e02ade":"code","f250ba46":"code","cd66a0e8":"code","1a678e6d":"code","94a24ea9":"code","080947ec":"code","06631962":"code","e6dcceef":"code","52020c2e":"code","84b84c19":"code","45f6422a":"code","fc1f3e3b":"code","8ac7b571":"code","6777b246":"code","11ed01e9":"code","1a8594f7":"code","8dd30a6f":"code","d1ec5e2e":"code","c3863e72":"code","774da46a":"code","bfb18b9d":"code","ae05bb75":"code","f42938c3":"code","f51614ae":"code","36e0bc32":"code","522b773b":"code","46777d7d":"code","b70fa3f7":"code","6fb49700":"code","a6cb8537":"code","6f2e686c":"code","c51a3730":"code","9c2929ea":"code","c5009961":"code","78348d5b":"code","3af04dab":"code","dcacf8ca":"code","ff71f959":"code","ac538096":"code","d7d433d7":"code","4b9f48c5":"code","521f97d8":"code","45212e9c":"code","efb728b1":"code","a9a83e2e":"code","c8213a29":"code","532c99e1":"code","52709ebe":"code","5c62e554":"code","74ce1800":"code","ffe5b510":"code","65b9f1cc":"code","cf7c3bdd":"code","8015eb0a":"code","a22f637a":"code","ad559bd8":"code","15d57714":"code","10096749":"markdown","5f2fd976":"markdown","baf77362":"markdown","0115dfe7":"markdown"},"source":{"32ed1226":"#The right way to ovversample\n#https:\/\/beckernick.github.io\/oversampling-modeling\/\n    \n#How to Handle Imbalanced Classes in Machine Learning    \n#https:\/\/elitedatascience.com\/imbalanced-classes\n\n#Over-sampling\n#https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/over_sampling.html\n\n#https:\/\/datascienceplus.com\/selecting-categorical-features-in-customer-attrition-prediction-using-python\/\n#https:\/\/www.datacamp.com\/community\/tutorials\/understanding-logistic-regression-python","f552b58c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import metrics\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nfrom imblearn.over_sampling import SMOTE, ADASYN   #reamostragem com a rotina SMOTE\nfrom sklearn.utils import resample #resample with replacement.\n\n#Importando pacote de regressao e de  medida de acuracia\nfrom sklearn.linear_model import LogisticRegression\n\n#Importa o pacote para medida de acur\u00e1cia\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.metrics import accuracy_score\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1381faa2":"#leitura da base\ndf = pd.read_csv('\/kaggle\/input\/agoravaimesmo\/basefinalagoravaimesmo.csv',sep=';')\n","2608bbd2":"#df2 = pd.read_csv('\/kaggle\/input\/base-completa\/PES2015.txt',sep=';')","1a3b3930":"#define o numero de casa decimais a serem visualizadas = 0\npd.options.display.float_format = '{:.0f}'.format","c8e8fbd6":"df.T","0fb7308a":"#Imputa\u00e7\u00e3o de dados nas colunas\ndf.loc[df['TinhaCartAssin'].isnull(),'TinhaCartAssin'] = 0\ndf.loc[df['EraServPubEst'].isnull(),'EraServPubEst'] = 0\ndf.loc[df['EraServPubEstAnt'].isnull(),'EraServPubEstAnt'] = 0\ndf.loc[df['RendMenPerc'].isnull(),'RendMenPerc'] = 0\ndf.loc[df['EsferaAtual'].isnull(),'EsferaAtual'] = 0\ndf.loc[df['EsferaAnt'].isnull(),'EsferaAnt'] = 0\ndf.loc[df['EstadoCivil'].isnull(),'EstadoCivil'] = 9\n","7f4f4e5f":"df.info()","9de18d03":"#Lista de colunas para o filtro\n#colunas = ['UF','Sexo','Idade','Ra\u00e7a','EstadoCivil','EsferaAtual','EraServPubEst','EsferaAnt','EraServPubEstAnt','TinhaCartAssin','QtdAnosEmpAnt','PosOcu358','RendMenPerc','Aposentado','ocupacao','atividade','GrAnterior']","257bd604":"#Lista de colunas para o filtro sem dados atuais de emprego\n#EsferaAnt foi retirado porque tem forte correla\u00e7\u00e3o com EraServPubEstAnt\ncolunas_ant = ['UF','Sexo','Idade','Ra\u00e7a','EstadoCivil','EraServPubEstAnt','QtdAnosEmpAnt','GrAnterior']","52e2a074":"#Tabela de dorrela\u00e7\u00f5es\ndf_merged2 = df.loc[:,['UF','Sexo','Idade','Ra\u00e7a','EstadoCivil','EraServPubEstAnt','QtdAnosEmpAnt','GrAnterior','EsferaAnt','Mobilidade']]\ndf_merged2.to_csv('df_merged2.csv')\ndf_merged2.corr()","5907f61a":"df_merged2","48cafea7":"df['Mobilidade'].value_counts()","e44730a5":"#Apiica\u00e7\u00e3o do filtro\nX = df.loc[:,colunas_ant]","685226cd":"X.T","ecee8348":"df[df['Mobilidade'].notnull()]['Mobilidade'].value_counts()","3210ad9a":"#Importa a bibilioteca de split\nfrom sklearn.model_selection import train_test_split\n","cf4ebcf4":"#Separando a variavel dependente\ny = df['Mobilidade']","12854895":"#verificando o tamanho das classes na base completa\ny.value_counts().to_frame()","51594829":"#verificando a proporcao das classes na base completa\n(y.value_counts(normalize=True) * 100).to_frame()","b61aea2c":"#separando os dados de teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25)","0151138d":"#df_test = pd.concat([X_test, y_test], axis=1)","04359a8e":"#verificando a frequencia das classes nos dados de teste\ny_test.value_counts().to_frame()","96203e35":"##verificando a proporcao das classes nos dados de teste\n(y_test.value_counts(normalize=True) * 100).to_frame()","0db7429a":"# dividindo novamente os dados de treino em treino e valida\u00e7\u00e3o\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.25)","0390ee00":"#verificando a proporcao das classes nos dados de treino\n(y_train.value_counts(normalize=True) * 100).to_frame()","05005cee":"#verificando a quantidade das classes nos dados de treino\ny_train.value_counts().to_frame()","b2cb81d6":"##verificando a proporcao das classes nos dados de valida\u00e7\u00e3o\n(y_val.value_counts(normalize=True) * 100).to_frame()","d977c539":"#verificando a quantidade das classes nos dados de valida\u00e7\u00e3o\ny_val.value_counts().to_frame()","2a5f3853":"#oversampling os dados de treino","9ddfa7eb":"X_train.info()","a1d4c760":"acuracia = pd.DataFrame({\n                'Treino Score':    [0.0, 0.0, 0.0],\n                'Treino Auroc':    [0.0, 0.0, 0.0],\n                'Valida\u00e7\u00e3o Score': [0.0, 0.0, 0.0],\n                'Valida\u00e7\u00e3o Auroc': [0.0, 0.0, 0.0],\n                'Teste Score':     [0.0, 0.0, 0.0],\n                'Teste Auroc':     [0.0, 0.0, 0.0]\n                },\n                index=['Base Original', 'Reamostragem (RESAMPLE)', 'Reamostragem (SMOTE)'])","edf2efe1":"acuracia['Treino Score']['Base Original']","f8b8dd88":"#Efetua a regressao logistica co os dados de treinamento\nreg1 = LogisticRegression().fit(X_train, y_train)","bfeed050":"def f_coef(reg,base_x):\n    intercept = pd.DataFrame ([['Intercept',reg.intercept_[0]]], columns = ['Vari\u00e1vel','Coeficiente'])\n    coefficients =  pd.concat([pd.DataFrame(base_x.columns),pd.DataFrame(np.transpose(reg.coef_))], axis = 1)\n    coefficients.columns = ['Vari\u00e1vel','Coeficiente']\n    return intercept.append(coefficients, ignore_index = True)","6112cf32":"f_coef(reg1,X_train)","b0b80fee":"intercept = pd.DataFrame ([['Intercept',reg1.intercept_[0]]], columns = ['Vari\u00e1vel','Coeficiente'])\nintercept","9a523ec8":"coefficients =  pd.concat([pd.DataFrame(X_train.columns),pd.DataFrame(np.transpose(reg1.coef_))], axis = 1)\ncoefficients.columns = ['Vari\u00e1vel','Coeficiente']\ncoefficients","9f667dcd":"all_coefs = intercept.append(coefficients)\nall_coefs","d594875d":"coefficients","695f4c52":"#prevendo os resultados do modelo com o uso dos dados de treinamento\npred_y_1 = reg1.predict(X_train)","27d49dd7":"#mede a acur\u00e1cia do modelo\naccuracy_score(y_train, pred_y_1)","e1367751":"acuracia['Treino Score']['Base Original'] = accuracy_score(y_train, pred_y_1)","9e5cdabd":"#Repetimos com dados de valida\u00e7\u00e3o - sem reamostragem\nval_y_1 = reg1.predict(X_val)\naccuracy_score(y_val, val_y_1)","12a1f6c2":"acuracia['Valida\u00e7\u00e3o Score']['Base Original'] = accuracy_score(y_val, val_y_1)","00b44d80":"\n#Repetimos com dados de teste - sem reamostragem\ntest_y_1 = reg1.predict(X_test)\naccuracy_score(y_test, test_y_1)","fb08b64b":"acuracia['Teste Score']['Base Original'] = accuracy_score(y_test, test_y_1)","e98819cf":"#Prevendo os dados para a matriz de confus\u00e3o","55fb9461":"\ncnf_matrix = metrics.confusion_matrix(y_test, test_y_1)\ncnf_matrix","b7c52c61":"\n# import required modules\n# is scikit's classifier.predict() using 0.5 by default?\n\n#In probabilistic classifiers, yes. It's the only sensible threshold from a mathematical viewpoint, as others have explained.\n\n%matplotlib inline\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Matriz Confus\u00e3o', y=1.1)\nplt.ylabel('Real')\nplt.xlabel('Predito')","34839c3f":"#Vamos usar agora um m\u00e9todo de medida mais confi\u00e1vel - AUROC\n#Geramos as probabilidades das classes na previs\u00e3o (necess\u00e1rio para a rotina de medida AUROC)\nprob_y_1 = reg1.predict_proba(X_train)","b44e13c3":"prob_y_1","99dd5798":"y_train","b7010376":"#Pega so uma coluna\nprob_y_1 = [p[1] for p in prob_y_1]","ce4e1522":"prob_y_1","6d2cb54d":"#Medida da acur\u00e1cia  - sem reamostragem - AUROC\n#metrics.roc_auc_score gives the area under the ROC curve. Can anyone tell me what command will find the optimal cut-off point (threshold value)?\nroc_auc_score(y_train, prob_y_1) ","b4e02ade":"acuracia['Treino Auroc']['Base Original'] = roc_auc_score(y_train, prob_y_1) ","f250ba46":"#Repetimos com dados de valida\u00e7\u00e3o - sem reamostragem - AUROC\nprob_val_y_1 = reg1.predict_proba(X_val)\nprob_val_y_1 = [p[1] for p in prob_val_y_1]\nroc_auc_score(y_val, prob_val_y_1)","cd66a0e8":"acuracia['Valida\u00e7\u00e3o Auroc']['Base Original'] = roc_auc_score(y_val, prob_val_y_1)","1a678e6d":"#Repetimos com dados de teste - sem reamostragem - AUROC\nprob_test_y_1 = reg1.predict_proba(X_test)\nprob_test_y_1 = [p[1] for p in prob_test_y_1]\nroc_auc_score(y_test, prob_test_y_1)","94a24ea9":"acuracia['Teste Auroc']['Base Original'] = roc_auc_score(y_test, prob_test_y_1)","080947ec":"y_train.value_counts()","06631962":"#Curva ROC para os dados originais\n\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, prob_test_y_1)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\n\nplt.title('Curva ROC')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n\n#plt.plot(np.linspace(0,1,10), np.linspace(0,1,10), label=\"diagonal\")\n    \nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('Taxa de positivos verdadeiros')\nplt.xlabel('Taxa de falsos positivos')\nplt.show()\n","e6dcceef":"threshold","52020c2e":"X_train","84b84c19":"#1. Up-sample Minority Class\n#Up-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal.\n#There are several heuristics for doing so, but the most common way is to simply resample with replacement.\n\n\n\n#merge de X_train e y_train paraa efetuar o upscaling\ndf_merged = pd.concat([X_train, y_train], axis=1)\n\n# Separate majority and minority classes\ndf_majority = df_merged[df_merged.Mobilidade==0]\ndf_minority = df_merged[df_merged.Mobilidade==1]\n\n#Faz o upscaling (reamostragem) usando a rotina resample\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=1556,    # to match majority class\n                                 random_state=123) # reproducible results\n\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])   #merge das tabelas\n\ndf_upsampled['Mobilidade'].value_counts()  # contagem das classes\n\n#Separa\u00e7\u00e3o de colunas\nX_upsampled = df_upsampled.loc[:,colunas_ant]\n#Separando a variavel dependente\ny_upsampled = df_upsampled['Mobilidade']\n","45f6422a":"y_upsampled.value_counts()","fc1f3e3b":"reg2 = LogisticRegression().fit(X_upsampled, y_upsampled)","8ac7b571":"#prevendo os resultados do modelo com o uso dos dados reamostrados\npred_y_2 = reg2.predict(X_upsampled)","6777b246":"#mede a acur\u00e1cia do modelo\naccuracy_score(y_upsampled, pred_y_2)","11ed01e9":"acuracia['Treino Score']['Reamostragem (RESAMPLE)'] = accuracy_score(y_upsampled, pred_y_2)","1a8594f7":"#Repetimos com dados de valida\u00e7\u00e3o\nval_y_2 = reg2.predict(X_val)\naccuracy_score(y_val, val_y_2)","8dd30a6f":"acuracia['Valida\u00e7\u00e3o Score']['Reamostragem (RESAMPLE)'] = accuracy_score(y_val, val_y_2)","d1ec5e2e":"#Repetimos com dados de teste\ntest_y_2 = reg2.predict(X_test)\naccuracy_score(y_test, test_y_2)","c3863e72":"acuracia['Teste Score']['Reamostragem (RESAMPLE)'] = accuracy_score(y_test, test_y_2)","774da46a":"# MAtriz de confurs\u00e3o pra RESAMPLE nos dados de teste\n\n\ncnf_matrix = metrics.confusion_matrix(y_test, test_y_2)\n# import required modules\n\n\n\n%matplotlib inline\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Matriz Confus\u00e3o Resample', y=1.1)\nplt.ylabel('Real')\nplt.xlabel('Predito')","bfb18b9d":"#Gera as probabilidades das classes na previs\u00e3o (necess\u00e1rio para a rotina de medida AUROC)\nprob_y_2 = reg2.predict_proba(X_upsampled)","ae05bb75":"#Pega so uma coluna\nprob_y_2 = [p[1] for p in prob_y_2]","f42938c3":"#Medida da acur\u00e1cia  para os dados reamostrados\nroc_auc_score(y_upsampled, prob_y_2) ","f51614ae":"acuracia['Treino Auroc']['Reamostragem (RESAMPLE)'] = roc_auc_score(y_upsampled, prob_y_2) ","36e0bc32":"#Repetimos com dados de valida\u00e7\u00e3o\nprob_val_y_2 = reg2.predict_proba(X_val)\nprob_val_y_2 = [p[1] for p in prob_val_y_2]\nroc_auc_score(y_val, prob_val_y_2)","522b773b":"acuracia['Valida\u00e7\u00e3o Auroc']['Reamostragem (RESAMPLE)'] = roc_auc_score(y_val, prob_val_y_2)","46777d7d":"#Repetimos com dados de teste\nprob_test_y_2 = reg2.predict_proba(X_test)\nprob_test_y_2 = [p[1] for p in prob_test_y_2]\nroc_auc_score(y_test, prob_test_y_2)","b70fa3f7":"acuracia['Teste Auroc']['Reamostragem (RESAMPLE)'] = roc_auc_score(y_test, prob_test_y_2)","6fb49700":"#Curva ROC para os dados reamostrados com RESMAPLE\n\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, prob_test_y_2)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\n\nplt.title('Curva ROC')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('Taxa de positivos verdadeiros')\nplt.xlabel('Taxa de falsos positivos')\nplt.show()","a6cb8537":"#Efetuamos agora a reamostragem usando a rotina SMOTE\nX_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)","6f2e686c":"X_resampled.info()","c51a3730":"y_resampled.value_counts()","9c2929ea":"##verificando a proporcao das classes nos dados de valida\u00e7\u00e3o\n(y_resampled.value_counts(normalize=True) * 100).to_frame()","c5009961":"#Efetuamos aqui a regressao logistica para os dados reamostrados com SMOTE\nreg3 = LogisticRegression().fit(X_resampled, y_resampled)","78348d5b":"#prevendo os resultados do modelo com o uso dos dados reamostrados\npred_y_3 = reg3.predict(X_resampled)","3af04dab":"#mede a acur\u00e1cia do modelo\naccuracy_score(y_resampled, pred_y_3)","dcacf8ca":"acuracia['Treino Score']['Reamostragem (SMOTE)'] = accuracy_score(y_resampled, pred_y_3)","ff71f959":"#Repetimos com dados de valida\u00e7\u00e3o\nval_y_3 = reg3.predict(X_val)\naccuracy_score(y_val, val_y_3)","ac538096":"acuracia['Valida\u00e7\u00e3o Score']['Reamostragem (SMOTE)'] = accuracy_score(y_val, val_y_3)","d7d433d7":"#Repetimos com dados de valida\u00e7\u00e3o\ntest_y_3 = reg3.predict(X_test)\naccuracy_score(y_test, test_y_3)","4b9f48c5":"acuracia['Teste Score']['Reamostragem (SMOTE)'] = accuracy_score(y_test, test_y_3)","521f97d8":"# MAtriz de confurs\u00e3o pra SMOTE nos dados de teste\n\ncnf_matrix = metrics.confusion_matrix(y_test, test_y_3)\n    \n%matplotlib inline\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Matriz Confus\u00e3o SMOTE', y=1.1)\nplt.ylabel('Real')\nplt.xlabel('Predito')","45212e9c":"#Gera as probabilidades das classes na previs\u00e3o (necess\u00e1rio para a rotina de medida AUROC)\nprob_y_3 = reg3.predict_proba(X_resampled)","efb728b1":"#Pega so uma coluna\nprob_y_3 = [p[1] for p in prob_y_3]","a9a83e2e":"#Medida da acur\u00e1cia  para os dados reamostrados\nroc_auc_score(y_resampled, prob_y_3) ","c8213a29":"acuracia['Treino Auroc']['Reamostragem (SMOTE)'] = roc_auc_score(y_resampled, prob_y_3) ","532c99e1":"#Repetimos com dados de valida\u00e7\u00e3o\nprob_val_y_3 = reg3.predict_proba(X_val)\nprob_val_y_3 = [p[1] for p in prob_val_y_3]\nroc_auc_score(y_val, prob_val_y_3)","52709ebe":"acuracia['Valida\u00e7\u00e3o Auroc']['Reamostragem (SMOTE)'] = roc_auc_score(y_val, prob_val_y_3)","5c62e554":"#Repetimos com dados de valida\u00e7\u00e3o\nprob_test_y_3 = reg3.predict_proba(X_test)\nprob_test_y_3 = [p[1] for p in prob_test_y_3]\nroc_auc_score(y_test, prob_test_y_3)","74ce1800":"acuracia['Teste Auroc']['Reamostragem (SMOTE)'] = roc_auc_score(y_test, prob_test_y_3)","ffe5b510":"#Curva ROC para os dados reamostrados com SMOTE\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, prob_test_y_3)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\n\nplt.title('Curva ROC')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('Taxa de positivos verdadeiros')\nplt.xlabel('Taxa de falsos positivos')\nplt.show()\n","65b9f1cc":"pd.options.display.float_format = '{:.4f}'.format\n#acuracia[['Valida\u00e7\u00e3o Score','Valida\u00e7\u00e3o Auroc']]\nacuracia","cf7c3bdd":"pd.options.display.float_format = '{:.4f}'.format\ndf_resampled = pd.concat([X_resampled, y_resampled], axis=1)\ndf_upsampled.to_csv('df_upsampled.csv')\ndf_merged.to_csv('df_merged.csv')\ndf_resampled.to_csv('df_resampled.csv')\n","8015eb0a":"df_merged","a22f637a":"df_upsampled.info()","ad559bd8":"X.cov()","15d57714":"X.corr()","10096749":"# Regress\u00e3o Logistica","5f2fd976":"true positive  = 139\/1000, 0.139, true negative = 38\/1000 = 0.038","baf77362":"Model Evaluation using Confusion Matrix\nA confusion matrix is a table that is used to evaluate the performance of a classification model. You can also visualize the performance of an algorithm. The fundamental of a confusion matrix is the number of correct and incorrect predictions are summed up class-wise.\nHere, you can see the confusion matrix in the form of the array object. The dimension of this matrix is 2*2 because this model is binary classification. You have two classes 0 and 1. Diagonal values represent accurate predictions, while non-diagonal elements are inaccurate predictions. In the output, 119 and 36 are actual predictions, and 26 and 11 are incorrect predictions.","0115dfe7":"Visualizing Confusion Matrix using Heatmap\nLet's visualize the results of the model in the form of a confusion matrix using matplotlib and seaborn.\n\nHere, you will visualize the confusion matrix using Heatmap."}}