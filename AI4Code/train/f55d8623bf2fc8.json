{"cell_type":{"ebcf911d":"code","cd06978b":"code","3b467cc4":"code","70bca061":"code","caa979dc":"code","e4eb9b81":"code","abf580c7":"code","fc587368":"code","9e61edf5":"code","fcf23a19":"code","ae4d58e3":"code","2b7e2048":"code","0283604a":"code","6e4532a8":"code","81762ca5":"code","f6d991d3":"code","86f872dc":"code","ffa3abb7":"code","e8b82ebe":"code","4c782056":"code","65b34f8a":"code","59c699ab":"code","a393a90d":"code","1594210b":"code","f2ff7141":"code","2a0cba16":"code","32a2d2f0":"code","b76a9915":"code","197e3056":"code","caf17efe":"code","dcc26558":"code","5cec8dcb":"code","2b3dacc9":"code","d76ff54c":"code","b5a76569":"code","08a0f0ad":"code","59793d58":"code","9fe664e0":"code","148590aa":"code","ff3fbfb0":"code","4f21987d":"code","dbfe9b42":"code","b6e26223":"code","3143562a":"code","bf22cc94":"code","0d473745":"code","eff778f4":"code","6e31917a":"code","c467b9d5":"code","fe0cd390":"code","9ec97612":"code","c1d8a81e":"code","8e6aef4a":"code","06355a8a":"code","7568f9cb":"code","dd3af7af":"code","e38dd1e4":"code","9a6621c2":"code","27ce8561":"code","a4de8939":"code","0a9935ff":"code","07c1ad0f":"code","8facd79f":"code","2a6088bc":"code","0d1f8fa7":"code","c9fdd850":"code","0c984c81":"code","80552c88":"code","a3ece1d0":"code","fe1b317e":"code","58376d88":"markdown","60597cd2":"markdown","17451d94":"markdown","15a0ede5":"markdown","eae84cb5":"markdown","320aa3ff":"markdown","3c71187c":"markdown","3db381ba":"markdown","95518847":"markdown","5cb7d999":"markdown","fe1266d5":"markdown","a4ebe195":"markdown","92d5ed4e":"markdown","a9eda965":"markdown","6d9f7b4c":"markdown","cd607455":"markdown","2a2217af":"markdown","7bf5c22d":"markdown","f5b13cf3":"markdown","017175f3":"markdown","94e2c561":"markdown","4ae3386a":"markdown","cf3b521c":"markdown","e3a19702":"markdown","7e40c5ef":"markdown","81d3e94b":"markdown","40145d9a":"markdown","6bf339a2":"markdown","8c576dbc":"markdown","ea41f79b":"markdown","7707a19a":"markdown","d5eaefe0":"markdown","a9912c22":"markdown","f64a5711":"markdown"},"source":{"ebcf911d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","cd06978b":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","3b467cc4":"pd.set_option('display.float_format', lambda x: '{:.2f}'.format(x)) ","70bca061":"import matplotlib.pyplot as plt  # Matlab-style plotting\n%matplotlib inline\nimport seaborn as sns\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #ignore annoying warning (from e.g. seaborn)","caa979dc":"sns.set_style('darkgrid')","e4eb9b81":"#display the first five rows of the train dataset.\ntrain.head(5)","abf580c7":"#display the first five rows of the test dataset.\ntest.head(5)","fc587368":"print('The training data size before dropping Id feature is : {} '.format(train.shape))\nprint('The test data size before dropping Id feature is : {} '.format(test.shape))","9e61edf5":"print('The information of training data is:')      \nprint(train.info())","fcf23a19":"print('The information of test data is:')      \nprint(test.info())","ae4d58e3":"print('The summary of training data is:')      \nprint(train.describe())","2b7e2048":"print('The summary of test data is:')      \nprint(test.describe())","0283604a":"from scipy import stats\nfrom scipy.stats import norm, skew #for some statistics","6e4532a8":"# Get the fitted parameters used by the function and limit floats output to 2 decimal points.\n(mu, sigma) = norm.fit(train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))","81762ca5":"sns.distplot(train['SalePrice'] , fit=norm)\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')","f6d991d3":"fig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)","86f872dc":"train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])","ffa3abb7":"# Get the fitted parameters used by the function and plot the distribution \n(mu, sigma) = norm.fit(train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\nsns.distplot(train['SalePrice'] , fit=norm)","e8b82ebe":"fig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)","4c782056":"# check the missing value in training data\nmissing_train = train.isnull().sum().sort_values(ascending = False)\nmissing_train","65b34f8a":"#plot the top 10 missing values\nmissing_x_axis = missing_train[:10]\nmissing_y_axis = missing_train[:10].index\nwidth = 10\nheight = 8\nplt.figure(figsize=(width, height))\n\nsns.barplot(missing_x_axis, missing_y_axis)\nplt.title('Missing value in trianing data')","59c699ab":"# check the top 10 missing values in test data\nmissing_test = test.isnull().sum().sort_values(ascending = False)\n\nmissing_x_axis = missing_test[:10]\nmissing_y_axis = missing_test[:10].index\n\nwidth = 10\nheight = 8\nplt.figure(figsize=(width, height))\n\nsns.barplot(missing_x_axis, missing_y_axis)\nplt.title('Missing value in test data')","a393a90d":"# columns where NaN values have meaning e.g. no pool etc.\ncols_fillna = ['PoolQC','MiscFeature','Alley','Fence','MasVnrType','FireplaceQu',\n               'GarageQual','GarageCond','GarageFinish','GarageType', 'Electrical',\n               'KitchenQual', 'SaleType', 'Functional', 'Exterior2nd', 'Exterior1st',\n               'BsmtExposure','BsmtCond','BsmtQual','BsmtFinType1','BsmtFinType2',\n               'MSZoning', 'Utilities']\n\n# replace 'NaN' with 'None' in these columns\nfor col in cols_fillna:\n    train[col].fillna('None',inplace=True)\n    test[col].fillna('None',inplace=True)","1594210b":"missing_total = train.isnull().sum().sort_values(ascending=False)\nmissing_percent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([missing_total, missing_percent], axis=1, keys=['Missing Value Total', 'Percent'])\nmissing_data.head()","f2ff7141":"# fillna with mean for the remaining columns: LotFrontage, GarageYrBlt, MasVnrArea\ncols_fillna = ['LotFrontage', 'GarageYrBlt', 'MasVnrArea']\n\nfor col in cols_fillna:\n    train[col].fillna(train[col].mean(), inplace=True)\n    test[col].fillna(test[col].mean(), inplace=True)","2a0cba16":"missing_total = train.isnull().sum().sort_values(ascending=False)\nmissing_percent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([missing_total, missing_percent], axis=1, keys=['Missing Values Total', 'Percent'])\nmissing_data.head()","32a2d2f0":"numerical_feats = train.dtypes[train.dtypes != \"object\"].index\nprint(\"Number of Numerical features: \", len(numerical_feats))\n\ncategorical_feats = train.dtypes[train.dtypes == \"object\"].index\nprint(\"Number of Categorical features: \", len(categorical_feats))","b76a9915":"print(train[numerical_feats].columns)\nprint(\"*\"*100)\nprint(train[categorical_feats].columns)","197e3056":"for col in numerical_feats:\n    print('{:15}'.format(col), \n          'Skewness: {:05.2f}'.format(train[col].skew()) , \n          '   ' ,\n          'Kurtosis: {:06.2f}'.format(train[col].kurt())  \n         )","caf17efe":"skewed_features = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF2', 'LowQualFinSF', 'GrLivArea'\n                   , 'BsmtHalfBath', 'BsmtFinSF1', 'TotalBsmtSF', 'WoodDeckSF', 'OpenPorchSF'\n                   , 'KitchenAbvGr', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']","dcc26558":"for feature in skewed_features:\n    train[feature] = np.log1p(train[feature])\n    test[feature] = np.log1p(test[feature])","5cec8dcb":"len(numerical_feats)","2b3dacc9":"nr_rows = 12\nnr_cols = 3\n\nfig, axs = plt.subplots(nr_rows, nr_cols, figsize=(nr_cols*3.5,nr_rows*3))\n\nli_num_feats = list(numerical_feats)\nli_not_plot = ['Id', 'SalePrice']\nli_plot_num_feats = [c for c in list(numerical_feats) if c not in li_not_plot]\n\n\nfor r in range(0,nr_rows):\n    for c in range(0,nr_cols):  \n        i = r*nr_cols+c\n        if i < len(li_plot_num_feats):\n            sns.regplot(train[li_plot_num_feats[i]], train['SalePrice'], ax = axs[r][c])\n            stp = stats.pearsonr(train[li_plot_num_feats[i]], train['SalePrice'])\n            #axs[r][c].text(0.4,0.9,\"title\",fontsize=7)\n            str_title = \"r = \" + \"{0:.2f}\".format(stp[0]) + \"      \" \"p = \" + \"{0:.2f}\".format(stp[1])\n            axs[r][c].set_title(str_title,fontsize=11)\n            \nplt.tight_layout()    \nplt.show()   ","d76ff54c":"train = train.drop(\n    train[(train['OverallQual']==10) & (train['SalePrice']<12.3)].index)\ntrain = train.drop(\n    train[(train['GrLivArea']>8.3) & (train['SalePrice']<12.5)].index)","b5a76569":"corr = train.corr()\ncorr_abs = corr.abs()\nmin_val_corr = 0.4    \n\n\nnr_num_cols = len(numerical_feats)\nser_corr = corr_abs.nlargest(nr_num_cols, 'SalePrice')['SalePrice']\n\ncols_abv_corr_limit = list(ser_corr[ser_corr.values > min_val_corr].index)\ncols_bel_corr_limit = list(ser_corr[ser_corr.values <= min_val_corr].index)","08a0f0ad":"print(ser_corr)","59793d58":"print(\"List of numerical features with r above min_val_corr :\", cols_abv_corr_limit)","9fe664e0":"print(\"List of numerical features with r below min_val_corr :\", cols_bel_corr_limit)","148590aa":"for catg in list(categorical_feats) :\n    print(train[catg].value_counts())\n    print('*'*50)","ff3fbfb0":"nr_rows = 15\nnr_cols = 3\n\nfig, axs = plt.subplots(nr_rows, nr_cols, figsize=(nr_cols*4,nr_rows*3))\n\nfor r in range(0,nr_rows):\n    for c in range(0,nr_cols):  \n        i = r*nr_cols+c\n        if i < len(list(categorical_feats)):\n            sns.boxplot(x=list(categorical_feats)[i], y='SalePrice', data=train, ax = axs[r][c])\n    \nplt.tight_layout()    \nplt.show()   ","4f21987d":"catg_strong_corr = [ 'MSZoning', 'Neighborhood', 'Condition2', 'MasVnrType', 'ExterQual', \n                     'BsmtQual','CentralAir', 'Electrical', 'KitchenQual', 'SaleType']\n\ncatg_weak_corr = ['Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', \n                  'LandSlope', 'Condition1',  'BldgType', 'HouseStyle', 'RoofStyle', \n                  'RoofMatl', 'Exterior1st', 'Exterior2nd', 'ExterCond', 'Foundation', \n                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', \n                  'HeatingQC', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', \n                  'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', \n                  'SaleCondition']","dbfe9b42":"def plot_corr_matrix(df, nr_c, targ) :\n    \n    corr = df.corr()\n    corr_abs = corr.abs()\n    cols = corr_abs.nlargest(nr_c, targ)[targ].index\n    cm = np.corrcoef(df[cols].values.T)\n\n    plt.figure(figsize=(nr_c\/1.5, nr_c\/1.5))\n    sns.set(font_scale=1.25)\n    sns.heatmap(cm, linewidths=1.5, annot=True, square=True, \n                fmt='.2f', annot_kws={'size': 10}, \n                yticklabels=cols.values, xticklabels=cols.values\n               )\n    plt.show()","b6e26223":"nr_feats = len(cols_abv_corr_limit)","3143562a":"plot_corr_matrix(train, nr_feats, 'SalePrice')","bf22cc94":"id_test = test['Id']\n\nto_drop_num  = cols_bel_corr_limit\nto_drop_catg = catg_weak_corr\n\ncols_to_drop = ['Id'] + to_drop_num + to_drop_catg \n\nfor df in [train, test]:\n    df.drop(cols_to_drop, inplace= True, axis = 1)","0d473745":"catg_list = catg_strong_corr.copy()\ncatg_list.remove('Neighborhood')\n\nfor catg in catg_list :\n    sns.boxenplot(x=catg, y='SalePrice', data=train)\n    plt.show()","eff778f4":"fig, ax = plt.subplots()\nfig.set_size_inches(16, 5)\nsns.boxenplot(x='Neighborhood', y='SalePrice', data=train, ax=ax)\nplt.xticks(rotation=45)\nplt.show()","6e31917a":"for catg in catg_list :\n    group = train.groupby(catg)['SalePrice'].mean()\n    print(group)","c467b9d5":"# 'MSZoning'\nmsz_catg2 = ['RM', 'RH']\nmsz_catg3 = ['RL', 'FV'] \n\n\n# Neighborhood\nnbhd_catg2 = ['Blmngtn', 'ClearCr', 'CollgCr', 'Crawfor', 'Gilbert', 'NWAmes', 'Somerst', 'Timber', 'Veenker']\nnbhd_catg3 = ['NoRidge', 'NridgHt', 'StoneBr']\n\n# Condition2\ncond2_catg2 = ['Norm', 'RRAe']\ncond2_catg3 = ['PosA', 'PosN'] \n\n# SaleType\nSlTy_catg1 = ['Oth']\nSlTy_catg3 = ['CWD']\nSlTy_catg4 = ['New', 'Con']","fe0cd390":"for df in [train, test]:\n    \n    df['MSZ_num'] = 1  \n    df.loc[(df['MSZoning'].isin(msz_catg2) ), 'MSZ_num'] = 2    \n    df.loc[(df['MSZoning'].isin(msz_catg3) ), 'MSZ_num'] = 3        \n    \n    df['NbHd_num'] = 1       \n    df.loc[(df['Neighborhood'].isin(nbhd_catg2) ), 'NbHd_num'] = 2    \n    df.loc[(df['Neighborhood'].isin(nbhd_catg3) ), 'NbHd_num'] = 3    \n\n    df['Cond2_num'] = 1       \n    df.loc[(df['Condition2'].isin(cond2_catg2) ), 'Cond2_num'] = 2    \n    df.loc[(df['Condition2'].isin(cond2_catg3) ), 'Cond2_num'] = 3    \n    \n    df['Mas_num'] = 1       \n    df.loc[(df['MasVnrType'] == 'Stone' ), 'Mas_num'] = 2 \n    \n    df['ExtQ_num'] = 1       \n    df.loc[(df['ExterQual'] == 'TA' ), 'ExtQ_num'] = 2     \n    df.loc[(df['ExterQual'] == 'Gd' ), 'ExtQ_num'] = 3     \n    df.loc[(df['ExterQual'] == 'Ex' ), 'ExtQ_num'] = 4     \n   \n    df['BsQ_num'] = 1          \n    df.loc[(df['BsmtQual'] == 'Gd' ), 'BsQ_num'] = 2     \n    df.loc[(df['BsmtQual'] == 'Ex' ), 'BsQ_num'] = 3     \n    \n    df['CA_num'] = 0          \n    df.loc[(df['CentralAir'] == 'Y' ), 'CA_num'] = 1    \n\n    df['Elc_num'] = 1       \n    df.loc[(df['Electrical'] == 'SBrkr' ), 'Elc_num'] = 2 \n\n\n    df['KiQ_num'] = 1       \n    df.loc[(df['KitchenQual'] == 'TA' ), 'KiQ_num'] = 2     \n    df.loc[(df['KitchenQual'] == 'Gd' ), 'KiQ_num'] = 3     \n    df.loc[(df['KitchenQual'] == 'Ex' ), 'KiQ_num'] = 4      \n    \n    df['SlTy_num'] = 2       \n    df.loc[(df['SaleType'].isin(SlTy_catg1) ), 'SlTy_num'] = 1  \n    df.loc[(df['SaleType'].isin(SlTy_catg3) ), 'SlTy_num'] = 3  \n    df.loc[(df['SaleType'].isin(SlTy_catg4) ), 'SlTy_num'] = 4  ","9ec97612":"new_col_num = ['MSZ_num', 'NbHd_num', 'Cond2_num'\n               , 'Mas_num', 'ExtQ_num', 'BsQ_num'\n               , 'CA_num', 'Elc_num', 'KiQ_num', 'SlTy_num']","c1d8a81e":"nr_rows = 4\nnr_cols = 3\n\nfig, axs = plt.subplots(nr_rows, nr_cols, figsize=(nr_cols*3.5,nr_rows*3))\n\nfor r in range(0,nr_rows):\n    for c in range(0,nr_cols):  \n        i = r*nr_cols+c\n        if i < len(new_col_num):\n            sns.regplot(train[new_col_num[i]], train['SalePrice'], ax = axs[r][c])\n            stp = stats.pearsonr(train[new_col_num[i]], train['SalePrice'])\n            str_title = \"r = \" + \"{0:.2f}\".format(stp[0]) + \"      \" \"p = \" + \"{0:.2f}\".format(stp[1])\n            axs[r][c].set_title(str_title,fontsize=11)\n            \nplt.tight_layout()    ","8e6aef4a":"catg_cols_to_drop = ['Neighborhood' , 'Condition2', 'MasVnrType'\n                     , 'ExterQual', 'BsmtQual','CentralAir', 'Electrical'\n                     , 'KitchenQual', 'SaleType']","06355a8a":"corr1 = train.corr()\ncorr_abs_1 = corr1.abs()\n\nnr_all_cols = len(train)\nser_corr_1 = corr_abs_1.nlargest(nr_all_cols, 'SalePrice')['SalePrice']\n\nprint(ser_corr_1)","7568f9cb":"cols_bel_corr_limit_1 = list(ser_corr_1[ser_corr_1.values <= min_val_corr].index)\nfor df in [train, test] :\n    df.drop(catg_cols_to_drop, inplace= True, axis = 1)\n    df.drop(cols_bel_corr_limit_1, inplace= True, axis = 1)    ","dd3af7af":"corr = train.corr()\ncorr_abs = corr.abs()\n\nnr_all_cols = len(train)\nprint (corr_abs.nlargest(nr_all_cols, 'SalePrice')['SalePrice'])","e38dd1e4":"nr_feats=len(train.columns)\nplot_corr_matrix(train, nr_feats, 'SalePrice')","9a6621c2":"# switch for dropping columns that are similar to others already used and show a high correlation to these     \ndrop_similar = 1","27ce8561":"cols = corr_abs.nlargest(nr_all_cols, 'SalePrice')['SalePrice'].index\ncols = list(cols)\n\nif drop_similar == 1 :\n    for col in ['GarageArea','1stFlrSF','TotRmsAbvGrd','GarageYrBlt'] :\n        if col in cols: \n            cols.remove(col)","a4de8939":"print(list(cols))","0a9935ff":"feats = cols.copy()\nfeats.remove('SalePrice')\n\nprint(feats)","07c1ad0f":"df_train_ml = train[feats].copy()\ndf_test_ml  = test[feats].copy()\n\ny = train['SalePrice']","8facd79f":"all_data = pd.concat((train[feats], test[feats]))","2a6088bc":"df_train_ml = all_data[:train.shape[0]]\ndf_test_ml  = all_data[train.shape[0]:]","0d1f8fa7":"from sklearn.preprocessing import StandardScaler","c9fdd850":"sc = StandardScaler()\ndf_train_ml_sc = sc.fit_transform(df_train_ml)\ndf_test_ml_sc = sc.transform(df_test_ml)","0c984c81":"df_train_ml_sc = pd.DataFrame(df_train_ml_sc)\ndf_test_ml_sc = pd.DataFrame(df_test_ml_sc)","80552c88":"X = df_train_ml.copy()\ny = train['SalePrice']\nX_test = df_test_ml.copy()\n\nX_sc = df_train_ml_sc.copy()\ny_sc = train['SalePrice']\nX_test_sc = df_test_ml_sc.copy()","a3ece1d0":"X.info()","fe1b317e":"X_test.info()","58376d88":"Finally, let's list of all features with strong correlation to target variable.","60597cd2":"Find out the features which have a strong correlation to the target variable. ","17451d94":"### Load Data from CSV File","15a0ede5":"Their correlations to the target variable.","eae84cb5":"Let's plot Q-Q plot to compare the shapes of distributions, providing a graphical view of how properties such as location, scale, and skewness are similar or different in the two distributions. Q\u2013Q plots can be used to compare collections of data, or theoretical distributions. ","320aa3ff":"Let's replot Q-Q plot to compare the shapes of distributions","3c71187c":"### Creating the new dataset for the further modelling","3db381ba":"### Multicollinearity\n\nMulticollinearity (or inter correlation) exists when at least some of the predictor variables are correlated among themselves.\n\nStrong correlation of these features to other, similar features:\n\n* 'GrLivArea_Log' and 'TotRmsAbvGrd'\n\n* 'GarageCars' and 'GarageArea'\n\n* 'TotalBsmtSF' and '1stFlrSF'\n\n* 'YearBuilt' and 'GarageYrBlt'\n\nOf those features we drop the one  with a less correlated coeffiecient to target variable.","95518847":"### **Target variable**\n\nIn this project, we train the data to make various moedls to predict the House Price, aka the column 'SalePrice' in the data set. Therefore, we regard 'SalePrice' as the targer variable.\n\nLet's import the relevant libraries firstly and have a look at its normal distribution.","5cb7d999":"***\n\n### Data Wrangling \n\nIn this section, the priority is to drop the less correlated features to the target variable in the dataset. Plus, transform some of the catregorical features to the numerical ones.\n\nIn a nutshell: \n\n* for numerical features: drop the similar and less correlated features\n* for categorical features: transform them to numerical","fe1266d5":"Any comment or upvote will be appreciated :)","a4ebe195":"***","92d5ed4e":"Check the numbers of samples and features.","a9eda965":"### skewness and kurtosis\nLet's check for skewness and kurtosis in numerical features","6d9f7b4c":"**Pandas describe() method** gives a summary of the statistics (only for numerical columns)","cd607455":"<a href=\"https:\/\/github.com\/xiuwenbo?tab=repositories\">\n    <img src=\"https:\/\/raw.githubusercontent.com\/xiuwenbo\/Markdown-Photos\/master\/IMG_5508.JPG\" width=\"200\" align=\"center\">\n<\/a>  \n\n\n                                                                                                    @Xiuwenbo\n                                                                                                    \n<h1 align=center><font size=\"5\"> House Price Prediction (EDA+DataWrangling) with Python <\/font><\/h1>","2a2217af":"Check the information of the data set","7bf5c22d":"I like the plot I draw has a clear style with a dark background","f5b13cf3":"If one tail is longer than another, the distribution is skewed.\n* A left-skewed distribution has a long left tail. Left-skewed distributions are also called negatively-skewed distributions. That\u2019s because there is a long tail in the negative direction on the number line. The mean is also to the left of the peak.\n* A right-skewed distribution has a long right tail. Right-skewed distributions are also called positive-skew distributions. That\u2019s because there is a long tail in the positive direction on the number line. The mean is also to the right of the peak.\n\nThe target variable is right skewed. As (linear) models love normally distributed data , we need to transform this variable and make it more normally distributed.\n\nThe log transformation is the most popular among the different types of transformations used to transform skewed data to approximately conform to normality. If the original data follows a log-normal distribution or approximately so, then the log-transformed data follows a normal or near normal distribution.\n\nLet's apply the numpy fuction log1p which use log(1+x) to all elements of the column","017175f3":"List the features and their correlation coeffient to the target variable.","94e2c561":"Get the list of the features\/columns for the following modelling","4ae3386a":"### StandardScaler \n\nStandardize features by removing the mean and scaling to unit variance","cf3b521c":"***\n\nLike the target variable, some of the feature values are not normally distributed and it is therefore better to use log values in both training and test data. \n\nInitially let's divide the feature into numerical and categorical and find out some interesting details. ","e3a19702":"***\n\n### Let's turn to the categoical features.\n\nThe unique value in these categorical features.","7e40c5ef":"The plot above illustrate that there are plenty of variables are missing value. \n\nBefore we proceed to deeper analysis, we need to have a look at these missing variables during the process of EDA. After that, I am going to apply feature engineering to deal with those missing value and make more correlated variables to make a accurate prediction model.\n\n### **Filling the missing values**\n\nFor a few columns there is lots of NaN entries. However, reading the data description we find this is not missing data: For example, PoolQC, NaN is not missing data but means no pool, likewise for Fence, FireplaceQu etc.","81d3e94b":"This is much better. \n\n***","40145d9a":"### Summary on numerical features:\n\n* some of the features like \"OverallQual\" have strong linear correlation 82% towards the target. \n* while some of other features like \"MSSubClass\" have a quite weak correlation to the taget variable. \n* there are several features in the numerical way turns out to be the categorical based on the plots (like \"OverallQual\"). \n\n### Remove the outliers","6bf339a2":"### About the dataset\n\nThe dataset is about the sale of individual residential property in Ames, Iowa from 2006 to 2010. The data set contains 2930 observations and a large number of explanatory variables (23 nominal, 23 ordinal, 14 discrete, and 20 continuous) involved in assessing home values. \n\n### Data fields\nHere's a brief version of what you'll find in the data description file.\n\n* SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n* MSSubClass: The building class\n* MSZoning: The general zoning classification\n* LotFrontage: Linear feet of street connected to property\n* LotArea: Lot size in square feet\n* Street: Type of road access\n* Alley: Type of alley access\n* LotShape: General shape of property\n* LandContour: Flatness of the property\n* Utilities: Type of utilities available\n* LotConfig: Lot configuration\n* LandSlope: Slope of property\n* Neighborhood: Physical locations within Ames city limits\n* Condition1: Proximity to main road or railroad\n* Condition2: Proximity to main road or railroad (if a second is present)\n* BldgType: Type of dwelling\n* HouseStyle: Style of dwelling\n* OverallQual: Overall material and finish quality\n* OverallCond: Overall condition rating\n* YearBuilt: Original construction date\n* YearRemodAdd: Remodel date\n* RoofStyle: Type of roof\n* RoofMatl: Roof material\n* Exterior1st: Exterior covering on house\n* Exterior2nd: Exterior covering on house (if more than one material)\n* MasVnrType: Masonry veneer type\n* MasVnrArea: Masonry veneer area in square feet\n* ExterQual: Exterior material quality\n* ExterCond: Present condition of the material on the exterior\n* Foundation: Type of foundation\n* BsmtQual: Height of the basement\n* BsmtCond: General condition of the basement\n* BsmtExposure: Walkout or garden level basement walls\n* BsmtFinType1: Quality of basement finished area\n* BsmtFinSF1: Type 1 finished square feet\n* BsmtFinType2: Quality of second finished area (if present)\n* BsmtFinSF2: Type 2 finished square feet\n* BsmtUnfSF: Unfinished square feet of basement area\n* TotalBsmtSF: Total square feet of basement area\n* Heating: Type of heating\n* HeatingQC: Heating quality and condition\n* CentralAir: Central air conditioning\n* Electrical: Electrical system\n* 1stFlrSF: First Floor square feet\n* 2ndFlrSF: Second floor square feet\n* LowQualFinSF: Low quality finished square feet (all floors)\n* GrLivArea: Above grade (ground) living area square feet\n* BsmtFullBath: Basement full bathrooms\n* BsmtHalfBath: Basement half bathrooms\n* FullBath: Full bathrooms above grade\n* HalfBath: Half baths above grade\n* Bedroom: Number of bedrooms above basement level\n* Kitchen: Number of kitchens\n* KitchenQual: Kitchen quality\n* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n* Functional: Home functionality rating\n* Fireplaces: Number of fireplaces\n* FireplaceQu: Fireplace quality\n* GarageType: Garage location\n* GarageYrBlt: Year garage was built\n* GarageFinish: Interior finish of the garage\n* GarageCars: Size of garage in car capacity\n* GarageArea: Size of garage in square feet\n* GarageQual: Garage quality\n* GarageCond: Garage condition\n* PavedDrive: Paved driveway\n* WoodDeckSF: Wood deck area in square feet\n* OpenPorchSF: Open porch area in square feet\n* EnclosedPorch: Enclosed porch area in square feet\n* 3SsnPorch: Three season porch area in square feet\n* ScreenPorch: Screen porch area in square feet\n* PoolArea: Pool area in square feet\n* PoolQC: Pool quality\n* Fence: Fence quality\n* MiscFeature: Miscellaneous feature not covered in other categories\n* MiscVal: $Value of miscellaneous feature\n* MoSold: Month Sold\n* YrSold: Year Sold\n* SaleType: Type of sale\n* SaleCondition: Condition of sale","8c576dbc":"### **Check the missing data**","ea41f79b":"Let's have a overview of features in the data set and relations to the target variable first.  \n\nApply **Pandas head() method, shape() method and info() method** to get a first overview of the train and test dataset and to answer how many rows and columns are there and what are the names of the features (columns).","7707a19a":"In these plots, we can see there are several features like \"NbHd_num, ExtQ_num, BsQ_num, KiQ_num\" have a strong correlation to the target variable.","d5eaefe0":"## Exploratory Data Analysis (**EDA**)\n\nInitially import some required libraries in this section.\n\nImport the warnings library in case you are not a fan of being warned.","a9912c22":"### Confusion Matrix","f64a5711":"Let's limit floats output to 2 decimal points for convenience."}}