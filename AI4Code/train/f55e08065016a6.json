{"cell_type":{"8ba6235b":"code","50794bbf":"code","d3ac18bb":"code","454d1267":"code","b6fe4f08":"code","44aff71a":"code","c472e265":"code","66167ebf":"code","16b58a08":"code","0efb41ab":"code","bd33bfef":"code","00127b6e":"code","9272410f":"code","313c0830":"code","b0311dde":"code","f4acef0e":"code","2df294b9":"code","858ff37a":"code","70672906":"code","92b0ab52":"code","869456da":"markdown","ebc55057":"markdown","7a088227":"markdown","1f172ce5":"markdown","98ce5687":"markdown","8875f36c":"markdown","9f5fce70":"markdown","f4e6f947":"markdown","53dac3d1":"markdown","aa489e11":"markdown","f53bcc46":"markdown"},"source":{"8ba6235b":"import matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","50794bbf":"df = pd.read_csv(\"\/kaggle\/input\/ad-tracking-fraud-detection\/train.csv\").drop(columns=\"attributed_time\")\ntest = pd.read_csv(\"\/kaggle\/input\/ad-tracking-fraud-detection\/test.csv\")\n\nprint (\"length of train set is\", len(df))\nprint (\"length of test set is\", len(test), end='\\n\\n')\n\nprint (\"train set example\", df.head(3), sep='\\n', end='\\n')\nprint (\"test set example\", test.head(3), sep='\\n', end='\\n')","d3ac18bb":"print (df.is_attributed.value_counts(), end='\\n\\n')\nprint (df.is_attributed.mean())","454d1267":"df.click_time = pd.to_datetime(df.click_time, infer_datetime_format=True)\ntest.click_time = pd.to_datetime(test.click_time, infer_datetime_format=True)\n\nprint (\"train set starts from\", df[\"click_time\"].min())\nprint (\"and ends\", df[\"click_time\"].max())\n\nprint (\"test set starts from\", test[\"click_time\"].min())\nprint (\"and ends\", test[\"click_time\"].max())","b6fe4f08":"fig, ax = plt.subplots()\n\ndf.groupby(df.click_time.dt.hour).count().plot(kind=\"bar\", ax=ax)\nfigtext = \"Dataset distribution per hour\"\nlegend = \"samples\"\nax.legend(legend)\nplt.figtext(.4, -.03, figtext)","44aff71a":"for i in df.click_time.dt.day.unique():\n    fig, ax = plt.subplots()\n    legend = \"samples\"\n    figtext = \"Day number {}\".format(i)\n    _ = df[df.click_time.dt.day == i]\n    _.groupby(_.click_time.dt.hour).count().plot(kind=\"bar\", ax=ax)\n    ax.legend(legend)\n    plt.figtext(.4, -.03, figtext)","c472e265":"_ = df.nunique().to_dict()\ncolumns, n_unique = _.keys(), _.values()\n\nfigtext = \"number of unique values per column\"\nplt.bar(columns, n_unique)\nplt.figtext(.4, -.03, figtext);","66167ebf":"print (\"number of categories in app column is\", len(df.app.unique()))\n\ndf[\"app\"].value_counts().plot(kind=\"bar\")","16b58a08":"df[df.app < 20].app.count() \/ len(df)","0efb41ab":"df.app.value_counts().apply(np.log).plot(kind=\"bar\")","bd33bfef":"print (\"number of categories in os column is\", len(df.os.unique()))\n\ndf.os.value_counts().plot(kind=\"bar\")","00127b6e":"df[df.os < 20].os.count() \/ len(df)","9272410f":"df.os.value_counts().apply(np.log).plot(kind=\"bar\")","313c0830":"print (\"Number of categories in os column is\", len(df.device.unique()))\n\n_ = df.device.value_counts()\n_.iloc[0] \/ len(df)","b0311dde":"print (\"Number of categories in os column is\", len(df.channel.unique()))\n\ndf.channel.value_counts().plot(kind=\"bar\")","f4acef0e":"df.channel.value_counts().apply(np.log).plot(kind=\"bar\")","2df294b9":"ips_pivot = pd.pivot_table(df, index=\"ip\", values=\"is_attributed\", aggfunc=[\"mean\", \"sum\", \"count\"])\n\nips_pivot.columns = ips_pivot.columns.to_series().str.join('_')\n\nips_pivot.head()","858ff37a":"ips_500 = ips_pivot[ips_pivot.count_is_attributed > 500]\n\nips_500.mean_is_attributed = ips_500.mean_is_attributed.round(decimals=4)\n\nips_500.head()","70672906":"_ = ips_500.groupby(\"mean_is_attributed\").count()[\"count_is_attributed\"]\n_.plot(use_index=True, xlim=[0, 0.0024])\nplt.figtext(.2, -.03, \"number of channels depending on conversion rate\");","92b0ab52":"_ = ips_500.groupby(\"mean_is_attributed\").sum()[\"count_is_attributed\"]\n_.plot(use_index=True, xlim=[0, 0.0024])\nplt.figtext(.2, -.03, \"number of samples depending on conversion rate\");","869456da":"Things go even weirder. We have significant part of 6th day and some small parts of 7th and 9th days!\n\nAnd amount of samples per hour is completely different. We have to keep in mind this trait to when we will make our cross validation scheme.","ebc55057":"One most popular device accounts 94% of all samples","7a088227":"Let's look on ips and check the hypothesis that exist spam ips with very little conversion\n\nLet's remember that average conversion rate in training set is 0.0024","1f172ce5":"First of all. Let's look on our target feature. Is there any class imbalance?","98ce5687":"First 20 most popular apps cover almost 87% of all data","8875f36c":"App distribution lookl like logarithmic one","9f5fce70":"Let's ignore ips with less than 500 samples","f4e6f947":"As often happens, we have a strong class imbalance. We have to keep this in mind.","53dac3d1":"There is no 15th hour in training data. In coincidence our test set almost completely consists off 15th hour\n\nLet's go a little bit further and look at each day in train set separately.","aa489e11":"As we see, test set starts right after when train set is over. It is popular train\\test split for time series data","f53bcc46":"As we see. There is a lot of ips with about of zero conversion rate. Probably we should use this information for our future model"}}