{"cell_type":{"0f174498":"code","5ec93f73":"code","38c160ad":"code","07db484f":"code","efb092db":"code","9d258169":"code","52c3f276":"code","477ae90e":"code","7d5c3561":"code","69417d42":"code","b7c8203a":"code","f8418b9c":"code","713069a4":"code","5622c9fc":"code","cb2a0497":"code","62db4f04":"code","0fcf41d3":"code","9fa11418":"code","21365fdb":"code","26083a81":"code","01c6cde5":"code","46b62ef0":"code","d73587b9":"code","deca761b":"code","54392556":"code","7bec2f19":"code","a486640b":"code","952d2d58":"code","e20d7dcc":"code","267bfd4a":"code","b3b32bb2":"code","2663f1bc":"code","2a5f9f00":"code","d59862dd":"code","6e4a7988":"code","b50264e6":"code","b33c043e":"code","64689312":"code","cc390958":"code","aaa9f2be":"code","59198c05":"markdown","72724688":"markdown"},"source":{"0f174498":"import numpy as np \nimport pandas as pd\nimport tensorflow.keras as keras\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5ec93f73":"# loading data\ndata = pd.read_csv(\"..\/input\/diabetes-health-indicators-dataset\/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\ndata.info()","38c160ad":"data.head()","07db484f":"data.describe()","efb092db":"corr = data.corr()\nfig, ax = plt.subplots(figsize=(10,7)) \nsns.heatmap(corr)\nplt.title(\"Correlation matrix of features\")","9d258169":"corr","52c3f276":"corr[\"Diabetes_binary\"]","477ae90e":"th=0.2\n\ncorr_th = corr[\"Diabetes_binary\"][corr[\"Diabetes_binary\"] > th]\ncorr_th","7d5c3561":"# drop features that under the threshold\ndata = data.drop(corr[\"Diabetes_binary\"][corr[\"Diabetes_binary\"] <= th].keys(), axis=1)\ndata.head()","69417d42":"data[\"BMI\"] *= 1\ndata[\"BMIBand\"] = pd.cut(data[\"BMI\"], 5)\n\nbmi = data[[\"BMIBand\", \"Diabetes_binary\"]].groupby([\"BMIBand\"], as_index=False).mean().sort_values(by=\"BMIBand\", ascending=True)\n\nfor i in range(5):\n        left = bmi[\"BMIBand\"][i].left\n        right = bmi[\"BMIBand\"][i].right\n        \n        if i == 0:\n            data.loc[ data[\"BMI\"] <= right, \"BMI\"] = i\n        \n        else:\n            data.loc[(data[\"BMI\"] > left) & (data[\"BMI\"] <= right), \"BMI\"] = i\n            \ndata = data.drop(\"BMIBand\", axis=1)\n\nbmi","b7c8203a":"data.head()","f8418b9c":"data[\"PhysHlth\"] *= 1\ndata[\"PhysHlthBand\"] = pd.cut(data[\"PhysHlth\"], 5)\n\nbmi = data[[\"PhysHlthBand\", \"Diabetes_binary\"]].groupby([\"PhysHlthBand\"], as_index=False).mean().sort_values(by=\"PhysHlthBand\", ascending=True)\n\nfor i in range(5):\n        left = bmi[\"PhysHlthBand\"][i].left\n        right = bmi[\"PhysHlthBand\"][i].right\n        \n        if i == 0:\n            data.loc[ data[\"PhysHlth\"] <= right, \"PhysHlth\"] = i\n        \n        else:\n            data.loc[(data[\"PhysHlth\"] > left) & (data[\"PhysHlth\"] <= right), \"PhysHlth\"] = i\n          \ndata = data.drop(\"PhysHlthBand\", axis=1)\n\nbmi","713069a4":"data.head()","5622c9fc":"data[[\"HighBP\", \"Diabetes_binary\"]].groupby([\"HighBP\"], as_index=False).mean().sort_values(by=\"HighBP\", ascending=True)","cb2a0497":"data[[\"HighChol\", \"Diabetes_binary\"]].groupby([\"HighChol\"], as_index=False).mean().sort_values(by=\"HighChol\", ascending=True)","62db4f04":"data[[\"GenHlth\", \"Diabetes_binary\"]].groupby([\"GenHlth\"], as_index=False).mean().sort_values(by=\"GenHlth\", ascending=True)","0fcf41d3":"data[\"GenHlth+PhysHlth\"] = data[\"GenHlth\"] + data[\"PhysHlth\"]\ndata = data.drop([\"GenHlth\", \"PhysHlth\"], axis=1)\ndata.head()","9fa11418":"data[[\"GenHlth+PhysHlth\", \"Diabetes_binary\"]].groupby([\"GenHlth+PhysHlth\"], as_index=False).mean().sort_values(by=\"GenHlth+PhysHlth\", ascending=True)","21365fdb":"data[[\"Age\", \"Diabetes_binary\"]].groupby([\"Age\"], as_index=False).mean().sort_values(by=\"Age\", ascending=True)","26083a81":"data[\"HighBP+HighChol\"] = data[\"HighBP\"] + data[\"HighChol\"]\ndata = data.drop([\"HighBP\", \"HighChol\"], axis=1)\ndata.head()","01c6cde5":"data[[\"HighBP+HighChol\", \"Diabetes_binary\"]].groupby([\"HighBP+HighChol\"], as_index=False).mean().sort_values(by=\"HighBP+HighChol\", ascending=True)","46b62ef0":"# # preprocessing\n# x = data.drop(\"Diabetes_binary\", axis=1)\n# x[\"Age\"] \/= np.max(x[\"Age\"])\n# x[\"BMI\"] \/= np.max(x[\"BMI\"])\n# x[\"Education\"] \/= np.max(x[\"Education\"])\n# x[\"GenHlth\"] \/= np.max(x[\"GenHlth\"])\n# x[\"Income\"] \/= np.max(x[\"Income\"])\n# x[\"MentHlth\"] \/= np.max(x[\"MentHlth\"])\n# x[\"PhysHlth\"] \/= np.max(x[\"PhysHlth\"])\n\n# y = data[\"Diabetes_binary\"]\n# y = to_categorical(y)\n\n# print(f\"Shape: {x.shape}, {y.shape}\")","d73587b9":"# preprocessing\nx = data.drop(\"Diabetes_binary\", axis=1)\n# x[\"Age\"] \/= x[\"Age\"].max()\ny = data[\"Diabetes_binary\"]\n\nprint(f\"Shape: {x.shape}, {y.shape}\")\nx.head()","deca761b":"# building set of train_val and test \nx_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.2)\n\nprint(f\"Train_val Counts: {x_train_val.shape[0]}\\nTest Counts: {x_test.shape[0]}\")","54392556":"# building model\nclass Keras_Model(keras.Model):\n    def __init__(self):\n        super(Keras_Model, self).__init__()\n\n        self.act = keras.layers.Activation(\"relu\")\n        self.dropout = keras.layers.Dropout(0.25)\n\n        self.block_1 = keras.Sequential()\n        for i in range(1):\n            self.block_1.add(keras.layers.Dense(128))\n            self.block_1.add(self.act)\n#             self.block_1.add(self.dropout)\n\n        self.block_2 = keras.Sequential()\n        for i in range(1):\n            self.block_2.add(keras.layers.Dense(64))\n            self.block_2.add(self.act)\n#             self.block_2.add(self.dropout)\n\n        self.block_3 = keras.Sequential()\n        for i in range(1):\n            self.block_3.add(keras.layers.Dense(32))\n            self.block_3.add(self.act)\n            self.block_3.add(self.dropout)\n\n        self.fc_out = keras.layers.Dense(1, activation=\"sigmoid\")\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.block_1(inputs)\n\n        x = self.block_2(x)\n\n        x = self.block_3(x)\n\n        x = self.fc_out(x)\n        return x\n\n    def get_config(self):\n        config = super(Keras_Model, self).get_config()\n        config.update()\n        return config","7bec2f19":"# callbacks\ndef lr_scheduler(base_lr, epochs):\n    def scheduler(epoch, lr):\n        p = epoch \/ epochs\n\n        if p > 0.9:\n            lr_n = base_lr * 1e-3\n\n        elif p > 0.75:\n            lr_n = base_lr * 1e-2\n\n        elif p >= 0.5:\n            lr_n = base_lr * 1e-1\n\n        else:\n            lr_n = lr\n\n        print(f\"[INFO] {epoch + 1}\/{epochs} LR From \", lr, \" to \", lr_n)\n\n        return lr_n\n\n    return LearningRateScheduler(scheduler)","a486640b":"learning_rate = 5e-3\nepochs = 50\n\nopt = keras.optimizers.SGD(\n    learning_rate=learning_rate,\n    momentum=0.9,\n    decay=1e-4,\n)\nmodel = Keras_Model()\nmodel.compile(\n    optimizer=opt,\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=[\"mae\", \"acc\"]\n)","952d2d58":"history = model.fit(\n        x=x_train_val, y=y_train_val,\n        validation_data=(x_test, y_test),\n        epochs=epochs,\n        callbacks=[lr_scheduler(base_lr=learning_rate, epochs=epochs)],\n        verbose=0,\n    )","e20d7dcc":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Keras Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.grid()\nplt.tight_layout()\nplt.show()\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Keras Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.grid()\nplt.tight_layout()\nplt.show()\n\nplt.plot(history.history['mae'])\nplt.plot(history.history['val_mae'])\nplt.title('Keras Model MAE')\nplt.ylabel('MAE')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.grid()\nplt.tight_layout()\nplt.show()\n","267bfd4a":"log = model.evaluate(x_test,y_test)\n\nprint(f\"\\nTest Loss: {log[0]}\\nTest Accuracy: {log[2]}\\nTest MAE: {log[1]}\")","b3b32bb2":"from sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\n\ny_pred = model.predict(x_test)\n\nnp.array(y_pred[:20]), np.array(y_test[:20])","2663f1bc":"rf = RandomForestClassifier(100, max_features='sqrt', n_jobs=1, random_state=1)\n%time rf.fit(x_train_val, y_train_val)","2a5f9f00":"%time rf.score(x_test, y_test)","d59862dd":"y_pred_rf = rf.predict(x_test)\ny_pred_rf[:20]","6e4a7988":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)\nfpr_rf, tpr_rf, thresholds = roc_curve(y_test, y_pred_rf)\n\nauc = metrics.roc_auc_score(y_test, y_pred)\nauc_rf = metrics.roc_auc_score(y_test, y_pred_rf)\n\nplt.figure(figsize=(10, 8))\nplt.plot(fpr, tpr, label=\"Keras: ROC curve (area=%.2f)\"%auc)\nplt.plot(fpr_rf, tpr_rf, label=\"Random Forest: ROC curve (area=%.2f)\"%auc_rf)\nplt.plot((0,1), (0,1), 'r-.')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.grid()","b50264e6":"precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred)\nprecision_rf, recall_rf, thresholds = metrics.precision_recall_curve(y_test, y_pred_rf)\n\n\nap = metrics.average_precision_score(y_test, y_pred)\nap_rf = metrics.average_precision_score(y_test, y_pred_rf)\n\n\nplt.figure(figsize=(10, 8))\nplt.plot(recall, precision, label=\"Keras: Average Precision (ap=%.2f)\" % (ap))\nplt.plot(recall_rf, precision_rf, label=\"Random Forest: Average Precision (ap=%.2f)\" % (ap_rf))\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.legend()\nplt.grid()","b33c043e":"# confusion matrix\nth_o = 0.5\n\ny_pred[y_pred > th_o] = 1\ny_pred[y_pred <= th_o] = 0\n\ny_pred[:10]","64689312":"print(\"Keras\")\nprint(\"=\"*50)\nprint(metrics.confusion_matrix(y_test, y_pred))\nprint(\"\\nRandom Forest\")\nprint(\"=\"*50)\nprint(metrics.confusion_matrix(y_test, y_pred_rf))","cc390958":"print(\"Keras\")\nprint(\"=\"*50)\nprint(metrics.classification_report(y_test, y_pred))","aaa9f2be":"print(\"Random Forest\")\nprint(\"=\"*50)\nprint(metrics.classification_report(y_test, y_pred_rf))","59198c05":"## Let's plot the correlation heat map","72724688":"## It shows negative value on \"PhysActivity\", \"Fruits\", \"Veggies\", \"HvyAlcoholConsump\", \"Education\" and \"Income\"."}}