{"cell_type":{"066bbeae":"code","11a9515a":"code","e47296ab":"code","3e7fbe00":"code","3239c37c":"code","cc67551e":"code","b8df81df":"code","f8f98e67":"code","68fd9ffa":"code","5a1c7656":"code","aaf1fcbb":"markdown","94a27268":"markdown","8a1f3ea6":"markdown","0246c0d6":"markdown","8b7c9085":"markdown"},"source":{"066bbeae":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datatable as dt\n\nimport os","11a9515a":"import copy\nimport time\nimport random\n\nimport warnings\n\nfrom sklearn.preprocessing import RobustScaler\n\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.ensemble import VotingClassifier\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\ndef ht(df, n=2):\n    display(df.head(n))\n    display(df.tail(n))\n    display(df.shape)\n    \ntarget = 'claim'","e47296ab":"SEED = 2021\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(SEED)","3e7fbe00":"train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')","3239c37c":"y = train[target].copy()\nfeatures = train.columns.tolist()\nfeatures.remove('id')\nfeatures.remove(target)","cc67551e":"train['n_missing'] = train[features].isna().sum(axis=1)\ntest['n_missing'] = test[features].isna().sum(axis=1)\n\ntrain['std'] = train[features].std(axis=1)\ntest['std'] = test[features].std(axis=1)\n\nn_missing = train['n_missing'].copy()\n\ntrain[features] = train[features].fillna(train[features].mean())\ntest[features] = test[features].fillna(test[features].mean())\n\nfeatures += ['n_missing', 'std']\n\nscaler = RobustScaler()\ntrain[features] = scaler.fit_transform(train[features])\ntest[features] = scaler.transform(test[features])\n\ntrain.shape, test.shape","b8df81df":"lgbm_params = {\n    'objective': 'binary',\n    'n_estimators': 20000,\n    'learning_rate': 5e-3,\n    'subsample': 0.6,\n    'subsample_freq': 1,\n    'colsample_bytree': 0.4,\n    'reg_alpha': 10.0,\n    'reg_lambda': 1e-1,\n    'min_child_weight': 256,\n    'min_child_samples': 20,\n    'importance_type': 'gain',\n} ","f8f98e67":"lgbm_clf0 = LGBMClassifier(**lgbm_params, random_state=17)\nlgbm_clf1 = LGBMClassifier(**lgbm_params, random_state=42)\nlgbm_clf2 = LGBMClassifier(**lgbm_params, random_state=2021)\nlgbm_clf3 = LGBMClassifier(**lgbm_params, random_state=31)\nlgbm_clf4 = LGBMClassifier(**lgbm_params, random_state=19)\nlgbm_clf5 = LGBMClassifier(**lgbm_params, random_state=77)\nlgbm_clf6 = LGBMClassifier(**lgbm_params, random_state=119)","68fd9ffa":"if 'claim' in train.columns.tolist():\n    y = train.pop('claim')\nprint(train.shape, test.shape)    \n\nestimators=[('lgbm0', lgbm_clf0), ('lgbm1', lgbm_clf1), ('lgbm2', lgbm_clf2), ('lgbm3', lgbm_clf3), ('lgbm4', lgbm_clf4), ('lgbm5', lgbm_clf5), ('lgbm6', lgbm_clf6)]\n\nstart = time.time()\nprint(f'fitting ...')\nmodel = VotingClassifier(estimators=estimators, voting='soft', verbose=True)\nmodel.fit(train, y)\n\nprint('predicting ...')\nmodel_pred = model.predict_proba(test)[:, -1]\n\nelapsed = time.time() - start\nprint(f'elapsed time: {elapsed:.2f}sec\\n')","5a1c7656":"sample_solution = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')\nsample_solution[target] = model_pred\nht(sample_solution)\nsample_solution.to_csv('submission.csv', index=False)\nprint()\nprint('==================== R E A D Y ====================')","aaf1fcbb":"> Thanks [BIZEN](https:\/\/www.kaggle.com\/hiro5299834) for **lgbm_params** from this [notebook](https:\/\/www.kaggle.com\/hiro5299834\/tps-sep-2021-single-lgbm)","94a27268":"# VotingClassifier with only one model  \n\nI started the competition with no model [notebook](https:\/\/www.kaggle.com\/martynovandrey\/prediction-without-model)  just for fun, but the public score **0.79946** is good for start :)\n\nThen I tried a number of solutions with different FE and models, and the best was LGBMClassifier with very simple FE (the same as in this notebook) with public score **0.81800**. See the  [notebook](https:\/\/www.kaggle.com\/martynovandrey\/tps-september-lgbm) if you are interested.  \n\nWell, it's a time for blending. I used VotingClassifier (and StackingClassifier) with LGBMClassifier, CatBoostClassifier and XGBClassifier. As usual. The result of voting was not very good. One estimator has highest single score, but the others are worse ...  \n\nWhat if use only the best model as all estimators? But it's no use to blend with itself. May be use one model with different parameters? It works, but only the best parameters are the best.\n\nThe idea is to use one best model with the same parameters, but different `random_state`s. \n\n> Thanks [Towhidul.Tonmoy](https:\/\/www.kaggle.com\/towhidultonmoy) for [random_state: Things you need to know](https:\/\/www.kaggle.com\/c\/tabular-playground-series-sep-2021\/discussion\/271694) post.\n\nLet's try!\n\nThe result surprised me, public score jumped to **0.81837**!","8a1f3ea6":"#### Thanks for reading. Don't forget to upvote if you find it usefull.","0246c0d6":"## Preprocessing","8b7c9085":"The same method increased the score of CatBoost from 0.81751 to 0.81816"}}