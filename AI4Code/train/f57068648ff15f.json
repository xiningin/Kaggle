{"cell_type":{"d8d3af1c":"code","81ea8abd":"code","14621881":"code","6ed7f277":"code","284b2ab4":"code","edc96ef4":"code","bbbd9793":"code","7b1135e7":"code","0d73b1a1":"code","2fcd1e5a":"code","89e843a7":"code","94ef4a84":"code","aba6123e":"code","9ced04df":"code","0a8eaff4":"code","5e4f8f65":"code","f0d12131":"code","3e6a1add":"code","02f0eefc":"code","81b88a06":"code","d3131bd9":"code","6959ebee":"code","128c9277":"code","68acc5d8":"code","da767e1a":"code","a46e98a8":"code","12d4c506":"code","9cc44f7d":"code","4545a14b":"code","287d72cd":"code","683333be":"code","9f211167":"code","b70d772e":"code","d7094a3e":"code","609453c8":"code","286417c2":"code","6f8f9f5f":"code","b6e010ff":"code","3d9ab40e":"code","da127fa9":"code","f1b1cb71":"code","3d98fe42":"code","1beba845":"code","e776a373":"code","3b648892":"code","c5210519":"code","45088318":"code","c302b6e9":"code","7d38711c":"code","00a89809":"code","7574b1e7":"code","9f37bb51":"markdown","b775542e":"markdown","6c90609e":"markdown","e1264540":"markdown","ddbb5904":"markdown","176686fd":"markdown","27e62f1e":"markdown","1a7a81c6":"markdown","e77d6a18":"markdown","2740a948":"markdown","224377d7":"markdown","7d5e10d8":"markdown","e7b4f426":"markdown","4b01ef00":"markdown","d38ee8ae":"markdown","847b1d99":"markdown","14c41068":"markdown","ce06f2be":"markdown","2219eac9":"markdown","13a36866":"markdown","0a390260":"markdown","47168a4b":"markdown","e3db29fe":"markdown","4f21efdd":"markdown","d2b9a35c":"markdown","93f8bda7":"markdown","fadaa8e6":"markdown","9aef5c53":"markdown","2e33e398":"markdown","3b383702":"markdown","3b416f28":"markdown","c70145e8":"markdown","39f674f8":"markdown","82d4c192":"markdown","0f8d1e2d":"markdown","48406d37":"markdown","bb60eca5":"markdown","e4456aff":"markdown","92bd9004":"markdown","ad7a362a":"markdown","af1f0bf1":"markdown"},"source":{"d8d3af1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81ea8abd":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers,mixed_precision\nfrom shutil import copyfile\n","14621881":"def walk_through_dir(directory_name):\n    \n    '''\n    Accepts the dirname as argument and prints the contents of each directory sequentially.\n    It prints the sub-directories and number of images present in each.\n    '''\n    for dirpaths,dirnames,filenames in os.walk(directory_name):\n        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpaths}'\")\n","6ed7f277":"input_data_dir='..\/input\/images-of-mechanical-parts-boltnut-washerpin\/blnw-images-224'\nwalk_through_dir(input_data_dir)","284b2ab4":"os.mkdir('.\/data')\nos.mkdir('.\/data\/train')\nos.mkdir('.\/data\/test')\nfor folder in os.listdir(input_data_dir):\n    files=os.listdir(os.path.join(input_data_dir,folder))\n    images=[]\n    for f in files:\n        try:\n            img=tf.io.read_file(os.path.join(input_data_dir,folder,f))\n            img=tf.image.decode_image(img)\n            images.append(f)\n        except:\n               pass\n            \n            \n    random.shuffle(images)\n    count=len(images)\n    split=int(0.8*count)\n    os.mkdir(os.path.join('.\/data\/train',folder))\n    os.mkdir(os.path.join('.\/data\/test',folder))\n\n    for c in range(split):\n        source_file=os.path.join(input_data_dir,folder,images[c])\n        distination=os.path.join('.\/data\/train',folder,images[c])\n        copyfile(source_file,distination)\n    for c in range(split,count):\n        source_file=os.path.join(input_data_dir,folder,images[c])\n        distination=os.path.join('.\/data\/test',folder,images[c])\n        copyfile(source_file,distination)","edc96ef4":"train_dir='.\/data\/train'\ntest_dir='.\/data\/test'","bbbd9793":"walk_through_dir(train_dir)","7b1135e7":"walk_through_dir(test_dir)","0d73b1a1":"def plot_random_image(target_dir):\n    \"\"\"\n    takes the directory as input and prints 5 random images from the randomly choosen class.\n    \"\"\"\n    target_class=random.choice(os.listdir(target_dir))\n    target_folder=os.path.join(target_dir,target_class)\n    random_image=random.sample(os.listdir(target_folder),5)\n \n    plt.figure(figsize=(16,5))\n    for i in range(5):\n        \n        plt.subplot(1,5,i+1)\n        img=tf.io.read_file(os.path.join(target_folder,random_image[i]))\n        img=tf.io.decode_image(img)\n        plt.imshow(img)\n        plt.title(f'{target_class}\\n{img.shape}')\n        plt.axis(False)","2fcd1e5a":"plot_random_image(train_dir)","89e843a7":"IMAGE_SIZE=(224,224)\n\ntrain_data=tf.keras.preprocessing.image_dataset_from_directory(\n    train_dir,\n    label_mode='categorical',\n    image_size=IMAGE_SIZE\n)\nclass_names=train_data.class_names\nnum_classes=len(class_names)\ntest_data=tf.keras.preprocessing.image_dataset_from_directory(\n    test_dir,\n    label_mode='categorical',\n    image_size=IMAGE_SIZE,\n    shuffle=False\n)","94ef4a84":"\ninputs=layers.Input(shape=(224,224,3),name='input_layer')\n\nbase_model=keras.applications.efficientnet.EfficientNetB0(include_top=False)\nbase_model.trainable=False\n\nx=base_model(inputs,training=False)\n\nx=layers.GlobalAveragePooling2D(name='Global_Average_Pool_2D')(x)\n\noutputs=layers.Dense(num_classes,activation='softmax',name=\"Output_layer\")(x)\n\nmodel=keras.Model(inputs,outputs,name=\"model\")","aba6123e":"model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy']\n)","9ced04df":"def create_model_check_point_callback(checkpoint_path,monitor='val_loss'):\n    \"\"\"\n    Takes the path where to save the best model weights obtained during training.\n    \"\"\"\n    model_checkpoint_cb=tf.keras.callbacks.ModelCheckpoint(\n        \n        monitor=monitor,\n        filepath=checkpoint_path,\n        save_best_only=True,\n        save_weights_only=True,\n        save_freq='epoch',\n        verbose=1\n    )\n    return model_checkpoint_cb","0a8eaff4":"%%time\nModelCheckPoint_model_cb=create_model_check_point_callback('.\/ModelCheckPoints\/model.ckpt')\nEPOCHS=5\nhistory_of_model=model.fit(\n    train_data,\n    epochs=EPOCHS,\n    steps_per_epoch=int (0.3*len(train_data)),\n    validation_data=test_data,\n    validation_steps=len(test_data),\n    callbacks=[ModelCheckPoint_model_cb]\n)","5e4f8f65":"model_result=model.evaluate(test_data)\nmodel_result","f0d12131":"def plot_loss_curves(history):\n    \n    '''\n      returns seperate loss curves for training and validation metrics\n    '''\n    train_loss=history.history['loss']\n    val_loss=history.history['val_loss']\n\n    train_accuracy=history.history['accuracy']\n    val_accuracy=history.history['val_accuracy']\n\n    epochs=range(1,len(history.history['loss'])+1)\n    plt.figure(figsize=(20,7))\n  # plot loss data\n    plt.subplot(1,2,1)\n    plt.plot(epochs,train_loss,label=\"training_loss\")\n    plt.plot(epochs,val_loss,label=\"validation_loss\")\n    plt.title(\"Loss curves\")\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.legend()\n  # plt.show()\n\n  # plot accuracy data\n    plt.subplot(1,2,2)\n    plt.plot(epochs,train_accuracy,label=\"training_acc\")\n    plt.plot(epochs,val_accuracy,label=\"validation_acc\")\n    plt.title(\"Accuracy curves\")\n    plt.xlabel('epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()","3e6a1add":"plot_loss_curves(history_of_model)","02f0eefc":"# set mixed_precision to `mixed_float16`\nmixed_precision.set_global_policy('mixed_float16')\n\ninputs=layers.Input(shape=(224,224,3),name='input_layer')\n\nbase_model=keras.applications.efficientnet.EfficientNetB0(include_top=False)\nbase_model.trainable=False\n\nx=base_model(inputs,training=False)\n\nx=layers.GlobalAveragePooling2D(name='Global_Average_Pool_2D')(x)\n\n# set dtype float32 to prevent numerical underflow\noutputs=layers.Dense(num_classes,activation='softmax',dtype=tf.float32,name=\"Output_layer\")(x)\n\nmodel=keras.Model(inputs,outputs,name=\"model\")","81b88a06":"model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy']\n)","d3131bd9":"%%time\nModelCheckPoint_model_cb=create_model_check_point_callback('.\/ModelCheckPoints\/model.ckpt')\nEPOCHS=5\nhistory_of_model=model.fit(\n    train_data,\n    epochs=EPOCHS,\n    steps_per_epoch=int (0.3*len(train_data)),\n    validation_data=test_data,\n    validation_steps=len(test_data),\n    callbacks=[ModelCheckPoint_model_cb]\n)","6959ebee":"model_result=model.evaluate(test_data)\nmodel_result","128c9277":"plot_loss_curves(history_of_model)","68acc5d8":"train_data_pf=train_data.prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_data_pf=test_data.prefetch(buffer_size=tf.data.AUTOTUNE)","da767e1a":"# set mixed_precision to `mixed_float16`\nmixed_precision.set_global_policy('mixed_float16')\n\ninputs=layers.Input(shape=(224,224,3),name='input_layer')\n\nbase_model=keras.applications.efficientnet.EfficientNetB0(include_top=False)\nbase_model.trainable=False\n\nx=base_model(inputs,training=False)\n\nx=layers.GlobalAveragePooling2D(name='Global_Average_Pool_2D')(x)\n\n# set dtype float32 to prevent numerical underflow\noutputs=layers.Dense(num_classes,activation='softmax',dtype=tf.float32,name=\"Output_layer\")(x)\n\nmodel=keras.Model(inputs,outputs,name=\"model\")","a46e98a8":"model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy']\n)","12d4c506":"%%time\nModelCheckPoint_model_cb=create_model_check_point_callback('.\/ModelCheckPoints\/model.ckpt')\nEPOCHS=5\nhistory_of_model=model.fit(\n    train_data_pf,\n    epochs=EPOCHS,\n    steps_per_epoch=int (0.3*len(train_data_pf)),\n    validation_data=test_data_pf,\n    validation_steps=int(0.25*len(test_data_pf)),\n    callbacks=[ModelCheckPoint_model_cb]\n)","9cc44f7d":"model_result=model.evaluate(test_data_pf)\nmodel_result","4545a14b":"plot_loss_curves(history_of_model)","287d72cd":"# set mixed_precision to `mixed_float16`\nmixed_precision.set_global_policy('mixed_float16')\n\ninputs=layers.Input(shape=(224,224,3),name='input_layer')\n\nbase_model=keras.applications.efficientnet.EfficientNetB0(include_top=False)\nbase_model.trainable=False\n\nx=base_model(inputs,training=False)\n\nx=layers.GlobalAveragePooling2D(name='Global_Average_Pool_2D')(x)\n\n# set dtype float32 to prevent numerical underflow\noutputs=layers.Dense(num_classes,activation='softmax',dtype=tf.float32,name=\"Output_layer\")(x)\n\nmodel=keras.Model(inputs,outputs,name=\"model\")","683333be":"model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy']\n)","9f211167":"%%time\nModelCheckPoint_model_cb=create_model_check_point_callback('.\/ModelCheckPoints\/model_1.ckpt')\nEPOCHS=5\nhistory_of_model_1=model.fit(\n    train_data_pf,\n    epochs=EPOCHS,\n    steps_per_epoch=len(train_data_pf),\n    validation_data=test_data_pf,\n    validation_steps=len(test_data_pf),\n    callbacks=[ModelCheckPoint_model_cb]\n)","b70d772e":"# load the weight which gave the best results\nmodel.load_weights('.\/ModelCheckPoints\/model_1.ckpt')","d7094a3e":"model_1_result=model.evaluate(test_data_pf)\nmodel_1_result","609453c8":"plot_loss_curves(history_of_model_1)","286417c2":"model.layers[1].trainable=True\nfor layer in model.layers[1].layers[:-10]:\n    layer.trainable=False","6f8f9f5f":"# checking the number of trainable layers in feature extraction model\nlen(model.layers[1].trainable_variables)","b6e010ff":"model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    metrics=['accuracy']\n)","3d9ab40e":"early_stop_cb=tf.keras.callbacks.EarlyStopping(patience=4,restore_best_weights=True)\nreduce_lr_cb=tf.keras.callbacks.ReduceLROnPlateau(factor=0.2,patience=2,verbose=1,min_lr=1e-7,min_delta=1e-3)","da127fa9":"ModelCheckPoint_model_cb=create_model_check_point_callback('.\/ModelCheckPoints\/model_2.ckpt')\nfine_tune_epoch=EPOCHS+20\nhistory_of_model_2=model.fit(\n    train_data_pf,\n    epochs=fine_tune_epoch,\n    initial_epoch=EPOCHS-1,\n    steps_per_epoch=len(train_data_pf),\n    validation_data=test_data_pf,\n    validation_steps=len(test_data_pf),\n    callbacks=[ModelCheckPoint_model_cb,early_stop_cb,reduce_lr_cb]\n)","f1b1cb71":"model_2_result=model.evaluate(test_data_pf)\nmodel_2_result","3d98fe42":"def plot_and_compare_history(original_history,new_history,initial_epoch):\n    \"\"\"\n    the function accepts the histories of a model before and after fine-tunning.\n    initial_epoch:#epochs used to train the original model.\n    \"\"\"\n    #get original history measurements\n    acc=original_history.history['accuracy']\n    loss=original_history.history['loss']\n    val_acc=original_history.history['val_accuracy']\n    val_loss=original_history.history['val_loss']\n    \n    #combining \n    total_acc=acc+new_history.history['accuracy']\n    total_loss=loss+new_history.history['loss']\n    total_val_acc=val_acc+new_history.history['val_accuracy']\n    total_val_loss=val_loss+new_history.history['val_loss']\n    \n    #make plots\n    plt.figure(figsize=(16,6))\n    plt.subplot(1,2,1)\n    plt.plot(total_acc,label='Training Accuracy')    \n    plt.plot(total_val_acc,label='Validation Accuracy')\n    plt.plot([initial_epoch-1,initial_epoch-1],plt.ylim(),label='Start fine tunning')\n    plt.title(\"Accuracy\")\n    plt.legend(loc='lower right')\n    plt.subplot(1,2,2)\n    plt.plot(total_loss,label='Training loss')\n    plt.plot(total_val_loss,label=\"Validation loss\")\n    plt.plot([initial_epoch-1,initial_epoch-1],plt.ylim(),label='Start fine tunning')\n    plt.title(\"Loss\")\n    plt.legend(loc=\"upper right\")","1beba845":"plot_and_compare_history(history_of_model_1,history_of_model_2,initial_epoch=EPOCHS)","e776a373":"# make predictions on the test data\npred_proba=model.predict(test_data)\npred_proba[:2]","3b648892":"# converting the class probabilities to class labels\npred_class_number=tf.argmax(pred_proba,axis=1).numpy()\npred_class_number[:5]","c5210519":"# true labels\ny_labels=[]\nfor _,label in test_data.unbatch():\n    y_labels.append(label.numpy().argmax())\n\ny_labels[:5]","45088318":"# filepaths of the test data images\nfilepaths=[]\nfor filepath in test_data.list_files(test_dir+'\/*\/*.png',shuffle=False):\n    filepaths.append(filepath.numpy())\n\nfilepaths[:2]","c302b6e9":"# summarizing the various attributes inside a Dataframe\npred_df=pd.DataFrame({\n    'filepaths':filepaths,\n    'y_true':y_labels,\n    'y_pred':pred_class_number,\n    'pred_conf':pred_proba.max(axis=1),\n    'actual_class_name':[class_names[i] for i in y_labels],\n    'pred_class_name':[class_names[i] for i in pred_class_number]\n     })\npred_df.head()","7d38711c":"# filtering the instances the model has failed to classify correctly\npred_wrong_df=pred_df[pred_df['y_true']!=pred_df['y_pred']].reset_index(drop=True)\npred_wrong_df","00a89809":"def load_and_prep_image(filename,img_shape=224,scale=True):\n    \n    '''\n    reads an image from the filename and turns it into a tensor,\n    and reshapes it to the specified size.\n    \n    args:\n    filename(str):path to the target image.\n    img_shahape(a,b,c)=target shape.\n    scale(boolean): specifies wheather scaling is required to be done or not.\n    \n    returns:\n    image tensor with the target shape.\n    '''\n    \n    img=tf.io.read_file(filename)\n    img=tf.io.decode_image(img,channels=3)\n    img=tf.image.resize(img,size=[img_shape,img_shape])\n    \n    if scale:\n        img=img\/255.0\n    return img","7574b1e7":"images_to_view=3\nstart_index=0\nplt.figure(figsize=(12,10))\nfor i,row in enumerate(pred_wrong_df[start_index:start_index+images_to_view].itertuples()):\n    plt.subplot(3,3,i+1)\n    img=load_and_prep_image(row[1],scale=False)\n    _,_,_,_,pred_p,act_cls,prd_cls=row\n    plt.imshow(img\/255.0)\n    plt.title(f\"pred_class:{prd_cls} pred:{pred_p*100:.2f}\\nactual_class:{act_cls}\")\n    plt.axis(False)","9f37bb51":"# 6.3.3 Compile the model","b775542e":"# 6.2.1 Create the model","6c90609e":"# 6.2.2 Compile the model","e1264540":"# 8.5 model_2 result","ddbb5904":"# 7.model 1 \n* using efficientnetB0 as the feature extraction layer and training using 100% of the training batches.","176686fd":"# 6.1 Without using mixed_precision\n","27e62f1e":"# 6.1.4 model result","1a7a81c6":"**Infernce**:As expected the training time was significantly less when we use mixed_precision to `mixed_float32`and accuracy remains the same.","e77d6a18":"# 6.3.2 Create the model","2740a948":"# 7.1 Create the model","224377d7":"# 6. model_0\n* using efficientnetB0 as the feature extraction layer and training using 30% of the training batches.","7d5e10d8":"# 3.1 Walk through train and test directories","e7b4f426":"# 2.  Walk Through Input Data Directory","4b01ef00":"# 7.3 Fit the model","d38ee8ae":"**Inference:From the Accuracy curves it is clear that the model starts overfitting the training data,\nTo improve the performance my next step is to fine tune the later layers(top 10 layers) of the feature extraction layer.**","847b1d99":"# 6.2.4 model result","14c41068":"# 6.1.2 Compile the model","ce06f2be":"# 6.3.1 Prefetching the data batches","2219eac9":"# 3.Split the Data into Train and Test","13a36866":"# 6.1.1 Create the model","0a390260":"**Inference**:I can't fault the model for classifying these wrongly as:\n1. the first image looks like bolt if one ignores the head,this can be rectified by collecting images of these types of\n   locating pin from various angles.\n2. Same can be said about the second image it largely resembles a locating pin ignoring the slot provided at the sides.","47168a4b":"# 8.1 unfreezing the top 10 layers of feature extraction model","e3db29fe":"**Inference:Fine tunning improved the performance of the model and model performance accuracy is now 99.87%**","4f21efdd":"# 7.4 model_1 result","d2b9a35c":"# 7.2 Compile the model","93f8bda7":"# Hope you find this to be helpfull,Thank You","fadaa8e6":"# 8.3 Define Early Stopping and Reduce Learning rate callbacks","9aef5c53":"# 8.2 Recompile the model","2e33e398":"**Inference**:pretching further helps in speed up the training by preparing the next data batch while in advance.","3b383702":"# 6.2.3 Fit the model","3b416f28":"# 5.Converting the input data into batch datasets","c70145e8":"# 9.Analyzing and Visualizing the predictions","39f674f8":"# 6.3.5 model result","82d4c192":"# 6.3 With mixed_precision and prefetch","0f8d1e2d":"# 8.4 Fit the model","48406d37":"# 6.1.3 Fit the model","bb60eca5":"# 6.3.4 Fit the model","e4456aff":"# 1.  Importing Libraries","92bd9004":"# 4 Visualizing the train data","ad7a362a":"# 6.2 With mixed_precision","af1f0bf1":"# 8.model_2\n* Unfreezing the top 10 layers of the feature extraction layer and fine tunning model_1."}}