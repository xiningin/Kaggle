{"cell_type":{"6262d09e":"code","1caa668e":"code","308fc9bc":"code","5a2d02ba":"code","ad9b62d5":"code","85d1e2e2":"code","7cfb61b3":"code","58a847c7":"code","5aa69367":"code","797ebd9f":"code","61d0a53e":"code","91e454ab":"code","28d2b48e":"code","18178cee":"code","7b1cb060":"code","34cd4543":"code","4c9310b4":"code","e01d6040":"code","e8273167":"code","1600cd31":"code","03a2224f":"code","b8f3e6f7":"code","a6bee148":"code","131523cc":"code","970dad4c":"code","f0b4073c":"code","82d6c746":"code","e74de73a":"code","230261c2":"code","4c57209f":"code","15c3363d":"code","db84c060":"code","794fba41":"code","827a8477":"code","cae485cd":"code","3605347d":"code","d2ab9cdb":"code","b48d2dc7":"code","84e2bf0b":"code","6cc7c644":"code","c94db88b":"code","adc2719f":"code","cc1d9965":"code","069579a3":"code","590d1021":"code","cfa1630f":"code","4d42d6fc":"code","2dcb0e00":"code","61b13047":"code","9a07e497":"code","3d8858a7":"code","bfc9987f":"code","0a07a97c":"code","25ab5b84":"code","0a4a05aa":"code","4af0277d":"code","908a7490":"code","94ab960d":"code","b122c018":"code","0f18b2e0":"code","3da834f9":"code","a7097c05":"code","69a21737":"code","96892d51":"code","177a6810":"code","3ba238d2":"code","59e2636b":"code","8f35fd5e":"code","0a8f75cb":"code","58ee7e3f":"code","4ce7d3d4":"code","9ac68a28":"code","b29b4994":"code","425138a4":"code","e11445a2":"code","ebc80e9b":"code","7279ac7e":"code","41db7fc6":"code","333f41ee":"code","ed4aeff7":"code","97ad07f7":"code","97645b53":"code","916926c7":"code","3208b1c9":"code","7912c299":"code","68885533":"code","50de340c":"code","993a6a18":"code","0d3eeeb4":"code","3fb12986":"code","4bdb4f94":"code","49a81c9e":"code","11ca1edd":"code","3eb8f08d":"code","d2f3e9e3":"code","bb756fce":"code","45c256a5":"code","f3a4dc8f":"code","31a79b3b":"code","54bf1648":"code","5f52e8f9":"code","7248f15a":"code","512928d1":"code","8dccef9f":"code","730ff934":"code","a5075064":"code","4d4d4fcf":"code","4056c3b6":"code","316505cb":"code","1b5f666f":"code","fe017206":"code","da0fe446":"code","cd692d16":"code","82f209a8":"code","3f8e7562":"code","3a48f8c0":"code","0e3d2c34":"code","5fcf5247":"code","84d5d529":"code","06f4155a":"code","0fb10830":"code","0146218f":"code","d973f7e4":"markdown","c609ebbc":"markdown","e963abd1":"markdown","dbddc469":"markdown","c76e6d2f":"markdown","7236902d":"markdown","89f72f8b":"markdown","bba979e8":"markdown","3f58e3d2":"markdown","cfc69f75":"markdown","51611438":"markdown","1e5507e0":"markdown","76fbeaff":"markdown","38c5a1be":"markdown","7aa48a49":"markdown","571f8f31":"markdown","adba7894":"markdown","86fc4dcf":"markdown","1e9bdc09":"markdown","d9716058":"markdown","6789f8ed":"markdown","284f0fa2":"markdown","e7cf7d83":"markdown","0767e791":"markdown","00ab3108":"markdown","8dce697a":"markdown","ee7e5a11":"markdown","6ba6ebbb":"markdown","09714dfc":"markdown","88bf46dd":"markdown","efd65839":"markdown","5a989fcb":"markdown","85ce497a":"markdown","08cc4a1e":"markdown","793c493c":"markdown","ba6c3865":"markdown","344d2993":"markdown","35e17835":"markdown","e6f7f1ac":"markdown","a8c1ce0f":"markdown","8087ed6f":"markdown","a658744c":"markdown","6e7b5d9d":"markdown","07a4836e":"markdown","a432b304":"markdown","63908cf4":"markdown","cffe428b":"markdown","541ef198":"markdown","97cdbc51":"markdown","8ef67243":"markdown","0ae48c37":"markdown","3c8deec2":"markdown","e645169d":"markdown","a3758e50":"markdown","0833021a":"markdown","a711229d":"markdown","ed84e1ec":"markdown","012f40fb":"markdown","74add863":"markdown","fc04e94a":"markdown","5ea796ec":"markdown","670b08da":"markdown","406f8d17":"markdown","93c4b7bf":"markdown","204c8ed0":"markdown","927e6d9b":"markdown","ca6bf5e1":"markdown","9573f99b":"markdown","fbd8d843":"markdown","2c2bc95d":"markdown","e43c48bd":"markdown","a3a5533e":"markdown","37560d85":"markdown","04b8a19f":"markdown","74f59984":"markdown","7141e53c":"markdown","17423695":"markdown","96b17f31":"markdown","bf5a5462":"markdown","4a71f31d":"markdown","751152d6":"markdown","c9732068":"markdown","465a6621":"markdown","0f086a1f":"markdown","7c8eb03e":"markdown","997aa967":"markdown","528d388e":"markdown","c8f20dcb":"markdown","de66c7d5":"markdown","a536fe23":"markdown","e3bc3acf":"markdown","7a58ed81":"markdown","72408c5d":"markdown","5e9b5f05":"markdown","788fec48":"markdown","e073f49b":"markdown","436fd994":"markdown","4fac877a":"markdown","b30dff4c":"markdown","ca458c55":"markdown","ab5380b2":"markdown","cb1361d1":"markdown","f6f609b3":"markdown","b12ee18d":"markdown","e8bbf1af":"markdown","fbdfb29b":"markdown","cd0abc57":"markdown","7f46e9d0":"markdown","ed8cd407":"markdown"},"source":{"6262d09e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom sklearn.preprocessing import OneHotEncoder\nimport plotly.express as px\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nimport array\nimport warnings\nfrom pylab import rcParams\nfrom scipy.stats import f_oneway\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline","1caa668e":"df = pd.read_csv('https:\/\/raw.githubusercontent.com\/Siddharth1698\/New-York-City-Airbnb-Data-Case-Study\/main\/AB_NYC_2019.csv')","308fc9bc":"df_copy = df.copy()\ndf.head()","5a2d02ba":"df.shape","ad9b62d5":"#+--------------------------------+------------------------------------------------------+\n#| 1. id                             | listing id                                           |\n#+--------------------------------+------------------------------------------------------+\n#| 2. name                           | name of the listing                                  |\n#+--------------------------------+------------------------------------------------------+\n#| 3. host_id                        | host ID                                              |\n#+--------------------------------+------------------------------------------------------+\n#| 4. host_name                      | name of the host                                     |\n#+--------------------------------+------------------------------------------------------+\n#| 5. neighbourhood_group            | location                                             |\n#+--------------------------------+------------------------------------------------------+\n#| 6. neighbourhood                  | area                                                 |\n#+--------------------------------+------------------------------------------------------+\n#| 7. latitude                       | latitude coordinates                                 |\n#+--------------------------------+------------------------------------------------------+\n#| 8. longitude                      | longitude                                            |\n#+--------------------------------+------------------------------------------------------+\n#| 9. room_type                      | listing space type                                   |\n#+--------------------------------+------------------------------------------------------+\n#| 10. price                          | price in dollars                                     |\n#+--------------------------------+------------------------------------------------------+\n#| 11. minimum_nights                 | amount of nights minimum                             |\n#+--------------------------------+------------------------------------------------------+\n#| 12. number_of_reviews              | number of reviews                                    |\n#+--------------------------------+------------------------------------------------------+\n#| 13. last_review                    | latest review                                        |\n#+--------------------------------+------------------------------------------------------+\n#| 14. reviews_per_month              | number of reviews per month                          |\n#+--------------------------------+------------------------------------------------------+\n#| 15. calculated_host_listings_count | amount of listing per host                           |\n#+--------------------------------+------------------------------------------------------+\n#| 16. availability_365               | number of days when listing is available for booking |\n#+--------------------------------+------------------------------------------------------+","85d1e2e2":"# Understanding types\ndf.info()","7cfb61b3":"df.isnull().sum()","58a847c7":"df.describe()","5aa69367":"# Insight about unique values\ndf.nunique()","797ebd9f":"# Making sure if any duplicatd values.\ndf.duplicated().sum()","61d0a53e":"df.host_id.value_counts().iloc[:5]","91e454ab":"df.host_id.value_counts().iloc[:5].plot(kind = 'barh')","28d2b48e":"# we noted that the room_type is only of 3 particular types.\ndf['room_type'].value_counts()","18178cee":"fig = plt.figure(figsize=(5,5), dpi=80)\ndf['room_type'].value_counts().plot(kind='pie',  autopct='%1.0f%%', startangle=360, fontsize=13)","7b1cb060":"# There are 5 particular neighbourhood_group, which means 5 unique locations.\ndf['neighbourhood_group'].value_counts()","34cd4543":"fig = plt.figure(figsize=(5,5), dpi=80)\ndf['neighbourhood_group'].value_counts().plot(kind='pie',  autopct='%1.0f%%', startangle=360, fontsize=13)","4c9310b4":"df['neighbourhood'].value_counts().iloc[:5]","e01d6040":"df['neighbourhood'].unique()","e8273167":"plt.subplots(figsize=(10,10))\nwordcloud = WordCloud(background_color='white', width=1920,height=1080).generate(\" \".join(df_copy.neighbourhood))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","1600cd31":"fig = plt.figure(figsize=(5,5), dpi=80)\ndf['neighbourhood'].value_counts().iloc[:5].plot(kind='pie',  autopct='%1.0f%%', startangle=360, fontsize=13)","03a2224f":"df.price.value_counts().iloc[:10]","b8f3e6f7":"df.price.value_counts().iloc[:10].plot(kind = 'bar')","a6bee148":"df.price.describe()","131523cc":"df[df['price'] == 10000.000000]","970dad4c":"df['minimum_nights'].value_counts()","f0b4073c":"for i in range(1,11):\n  print(\"Number of nights: \",i)\n  print(\"Amount of trasactions:\",len(df[df['minimum_nights'] == i]))","82d6c746":"df['minimum_nights'].value_counts().iloc[:4].plot(kind = 'barh')","e74de73a":"df['number_of_reviews'].value_counts()","230261c2":"df[df['number_of_reviews'] == 607]","4c57209f":"df['availability_365'].value_counts()","15c3363d":"df[df['availability_365'] == 365].describe()","db84c060":"df_copy[df_copy['reviews_per_month'] > 1].reviews_per_month.value_counts().sum()                 ","794fba41":"df[df['reviews_per_month'] > 1]['reviews_per_month'].value_counts().iloc[:5]            ","827a8477":"df['reviews_per_month'].max()","cae485cd":"df_copy[df['reviews_per_month'] == 58.5]","3605347d":"df.calculated_host_listings_count.value_counts().iloc[:5]","d2ab9cdb":"df.calculated_host_listings_count.value_counts().iloc[:5].plot(kind = 'bar')","b48d2dc7":"df.calculated_host_listings_count.describe()","84e2bf0b":"corr = df.corr()\nplt.figure(figsize=(15,8))\nsns.heatmap(corr, annot=True)","6cc7c644":"df['neighbourhood_group'].value_counts()","c94db88b":"plt.figure(figsize=(10,6))\nsns.scatterplot(df.longitude,df.latitude,hue=df.neighbourhood_group)","adc2719f":"df['room_type'].value_counts()","cc1d9965":"plt.figure(figsize=(10,6))\nsns.scatterplot(df.longitude,df.latitude,hue=df.room_type)","069579a3":"plt.figure(figsize=(10,6))\nsns.scatterplot(df_copy.longitude,df_copy.latitude,hue=df_copy.availability_365)","590d1021":"plt.figure(figsize=(10,6))\nsns.countplot(data = df, x = 'room_type', hue = 'neighbourhood_group')","cfa1630f":"plt.figure(figsize=(10,6))\nax = sns.boxplot(data=df_copy, x='neighbourhood_group',y='availability_365',palette='plasma')","4d42d6fc":"v2=sns.violinplot(data=df[df.price < 200], x='neighbourhood_group', y='price')\nv2.set_title('Density and distribution of prices for each neighberhood_group')","2dcb0e00":"df['neighbourhood'].value_counts().iloc[:10]","61b13047":"neighb =df.loc[df['neighbourhood'].isin(['Williamsburg','Bedford-Stuyvesant','Harlem','Bushwick','Upper West Side','Hell\\'s Kitchen','East Village','Upper East Side','Crown Heights','Midtown'])]\npl =sns.catplot(x='neighbourhood', hue='neighbourhood_group', col='room_type', data=neighb, kind='count')\npl.set_xticklabels(rotation=90)","9a07e497":"# Rooms with top 100 reviews by neighbourhood\ndfr=df.sort_values(by=['number_of_reviews'],ascending=False).head(100)\ndfr['neighbourhood_group'].value_counts().plot(kind = 'barh')","3d8858a7":"# Rooms with top 100 expensive by neighbourhood\ndfr=df.sort_values(by=['price'],ascending=False).head(100)\ndfr['neighbourhood_group'].value_counts().plot(kind = 'barh')","bfc9987f":"# Rooms with top 100 minimum_nights  by neighbourhood\ndfr=df.sort_values(by=['minimum_nights'],ascending=False).head(100)\ndfr['neighbourhood_group'].value_counts().plot()","0a07a97c":"plt.figure(figsize=(10,10))\nsns.scatterplot(x=\"room_type\", y=\"price\",\n            hue=\"neighbourhood_group\", size=\"neighbourhood_group\",\n            sizes=(50, 200), palette=\"Dark2\", data=df)\n\nplt.xlabel(\"Room Type\", size=13)\nplt.ylabel(\"Price\", size=13)\nplt.title(\"Room Type vs Price vs Neighbourhood Group\",size=15, weight='bold')","25ab5b84":"## We can remove the unwanted columns. Here id,name , host_name and last_review doesnt help us in anyway in our approch for data analysis.\ndf.drop(['host_id','name','latitude','longitude','id','host_name','last_review'], axis=1, inplace=True)\ndf.head()","0a4a05aa":"df.isna().sum()","4af0277d":"df['reviews_per_month'].describe()","908a7490":"df['reviews_per_month'] = df['reviews_per_month'].fillna(0)\n# Missing value implies there are no reviews for the location.","94ab960d":"df.isna().sum()","b122c018":"df_copy.loc[df_copy['room_type'] == 'Entire home\/apt', 'home'] = True\ndf_copy.loc[df_copy['room_type'] != 'Entire home\/apt', 'home'] = False\n","0f18b2e0":"df_hyp = df_copy[['home','availability_365']]\ndf_hyp.head()","3da834f9":"df_hyp.groupby('home').count()","a7097c05":"home = df_hyp['availability_365'][df_hyp['home']==True]\nnon_home = df_hyp['availability_365'][df_hyp['home']==False]\n","69a21737":"import matplotlib.pyplot as plt\n%matplotlib inline\ndf_hyp.hist(by ='home')","96892d51":"import seaborn as sns\nhome.hist(histtype='stepfilled', alpha=.5, bins=20)     # default number of bins = 10\nnon_home.hist(histtype='stepfilled', alpha=.5,color=sns.desaturate(\"indianred\", 0.75 ), bins=10)\nplt.xlabel('availability_365',fontsize=15)\nplt.ylabel('Home\/Apt',fontsize=15)\nplt.show()\n","177a6810":"means_table =df_hyp.groupby('home').mean()\nmeans_table","3ba238d2":"observatied_diff = means_table['availability_365'][1] - means_table['availability_365'][0]\nobservatied_diff","59e2636b":"shuffled = df_hyp.sample(len(df_hyp),replace = False)\nshuffled","8f35fd5e":"shuffled_availablity = shuffled['availability_365']\ntype(shuffled_availablity)","0a8f75cb":"orig_and_shuff = df_hyp.assign(shuffled_availablity = shuffled_availablity.values)\norig_and_shuff","58ee7e3f":"all_group_means = orig_and_shuff.groupby('home').mean()\nall_group_means","4ce7d3d4":"difference = all_group_means['shuffled_availablity'][0]- all_group_means['shuffled_availablity'][1]\ndifference","9ac68a28":"observatied_diff","b29b4994":"shuffled = df_hyp.sample(len(df_hyp),replace = False)\nshuffled_availablity = shuffled['availability_365']\norig_and_shuff = df_hyp.assign(shuffled_availablity = shuffled_availablity.values)\nall_group_means = orig_and_shuff.groupby('home').mean()\ndifferences = abs(all_group_means['shuffled_availablity'][0] - all_group_means['shuffled_availablity'][1])","425138a4":"differences","e11445a2":"\n\ndifferences = np.zeros(5000)","ebc80e9b":"for i in range(5000):\n    shuffled = df_hyp.sample(len(df_hyp),replace = False)\n    shuffled_availablity = shuffled['availability_365']\n    orig_and_shuffled = df_hyp.assign(shuffled_availablity = shuffled_availablity.values)\n    all_group_means = orig_and_shuffled.groupby('home').mean()\n    difference = (all_group_means['shuffled_availablity'][0] - all_group_means['shuffled_availablity'][1])\n    differences[i] = difference\n","7279ac7e":"differnces_df = pd.DataFrame(differences)\ndiffernces_df","41db7fc6":"import matplotlib\n%matplotlib inline\nplt.style.use('fivethirtyeight')","333f41ee":"differnces_df.hist()\nplt.title('Prediction Under Null Hypotheses');\nplt.xlabel('mean differences between home and non home availablity',fontsize=15)\nplt.ylabel('Units',fontsize=15);\nplt.axvline(observatied_diff, color='red');\nprint(observatied_diff)","ed4aeff7":"np.count_nonzero(differences <= observatied_diff)\/differences.size","97ad07f7":"%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\nrcParams['figure.figsize'] = 8,8\nrcParams['font.size'] = 30\nsns.set()\nnp.random.seed(8)","97645b53":"def plot_distribution(inp):\n    plt.figure()\n    ax = sns.distplot(inp)\n    ax.set_xlim([30, 365])\n    plt.axvline(np.mean(inp), color=\"k\", linestyle=\"dashed\", linewidth=3)\n    _, max_ = plt.ylim()\n    plt.text(\n        inp.mean() + inp.mean() \/ 10,\n        max_ - max_ \/ 10,\n        \"Mean: {:.2f}\".format(inp.mean()),\n    )\n    return plt.figure","916926c7":"df_copy.columns","3208b1c9":"df_hyp = df_copy[['neighbourhood_group','availability_365']]\ndf_hyp = df_hyp[df_hyp['availability_365'] > 30]\ndf_hyp.head()","7912c299":"plot_distribution(df_hyp['availability_365'])","68885533":"sample_size = 2000\navail_sample=np.random.choice(df_hyp['availability_365'],sample_size)\navail_sample","50de340c":"np.mean(avail_sample)","993a6a18":"plot_distribution(avail_sample)","0d3eeeb4":"plt.figure()\nax1 = sns.distplot(avail_sample)\nax2 = sns.distplot(df_hyp['availability_365'])\nax1.set_xlim([30, 365])\nax2.set_xlim([30, 365])\nplt.axvline(np.mean(avail_sample), color='b', linestyle='dashed', linewidth=3)\nplt.axvline(np.mean(df_hyp['availability_365']), color='orange', linestyle='dashed', linewidth=3)","3fb12986":"def compare_2_groups(arr_1, arr_2, alpha):\n    stat, p = ttest_ind(arr_1, arr_2)\n    print('Statistics=%.3f, p=%.3f' % (stat, p))\n    if p > alpha:\n        print('Same distributions hence we fail to reject H0(Null Hypothesis)')\n    else:\n        print('Different distributions hence we reject H0(Null Hypothesis)')\n\ncompare_2_groups(df_hyp['availability_365'], avail_sample, 0.05)","4bdb4f94":"df = pd.read_csv('https:\/\/raw.githubusercontent.com\/Siddharth1698\/New-York-City-Airbnb-Data-Case-Study\/main\/AB_NYC_2019.csv')\n\nfig = px.box(df, y=\"price\")\nfig.update_layout(\n    autosize=False,\n    width=500,\n    height=400\n)\nfig.show()","49a81c9e":"dfp = df[\"price\"][df[\"price\"] < 250]\ndfp[dfp > 20].hist()\n","11ca1edd":"df=df[df[\"price\"]<250]\ndf=df[df[\"price\"]>20]\ndf['room_type'].value_counts()","3eb8f08d":"fig = px.box(df, y=\"price\")\nfig","d2f3e9e3":"df.fillna({'reviews_per_month':0}, inplace=True)\ndf.drop(['id','host_id','latitude','longitude','host_name','last_review','name'], axis = 1,inplace=True)\ndf = pd.get_dummies(df, columns=['neighbourhood_group',\"room_type\"], prefix = ['ng',\"rt\"],drop_first=True)\ndf.drop([\"neighbourhood\"], axis=1, inplace=True)\ndf.head()","bb756fce":"def linear(x,z):\n  global X,y,predictions,residue\n  X = df_reg[x].values.reshape(-1,1)\n  y = df_reg[z].values.reshape(-1,1)\n  \n\n  #3 Feature Scaling\n  from sklearn.preprocessing import StandardScaler\n  sc_X = StandardScaler()\n  sc_y = StandardScaler()\n\n  X = sc_X.fit_transform(X)\n  y = sc_X.fit_transform(y)\n\n  from sklearn.linear_model import LinearRegression\n  reg = LinearRegression()\n  reg.fit(X, y)\n\n  print(\"The linear model is: Y = {:.2} + {:.2}X\".format(reg.intercept_[0], reg.coef_[0][0]))\n\n  print(\"Regression Intercept : \",reg.intercept_[0])\n\n\n  predictions = reg.predict(X)\n  rms = mean_squared_error(y, predictions, squared=False)\n\n  fig = px.scatter(\n    df_reg, x=x, y=z, opacity=0.65,\n    trendline='ols', trendline_color_override='darkblue')\n  fig.show()\n\n  # Plot the residuals after fitting a linear model\n  sns.residplot(x=X, y=y, lowess=True, color=\"g\")\n\n  print(\"RMSE is: \", rms)\n  x2 = sm.add_constant(X)\n\n  est = sm.OLS(y, x2)\n  #OLS is Ordinary Least Squares\n\n  #est.TAB\n  est2 = est.fit()\n  print(est2.summary())\n\n  residue = y - predictions","45c256a5":"df_reg = df[['number_of_reviews','reviews_per_month']]\ndf_reg = df_reg[df_reg['number_of_reviews']<400]\ndf_reg = df_reg[df_reg['reviews_per_month']<15]\ndf_reg","f3a4dc8f":"linear('number_of_reviews','reviews_per_month')\ndf_n = pd.DataFrame(predictions, columns = ['Predictions'])\ndf_reg_new = pd.concat([df_reg,df_n],axis = 1)\ndf_n = pd.DataFrame(residue, columns = ['Residue'])\ndf_reg_new = pd.concat([df_reg_new,df_n],axis = 1)\ndf_reg_new[['number_of_reviews','reviews_per_month','Predictions','Residue']].head()","31a79b3b":"df.head()","54bf1648":"df.shape","5f52e8f9":"X = df.drop(['price'],axis=1)\ny = df['price'].values.reshape(-1,1)\n\n\nsc_X = StandardScaler()\nsc_y = StandardScaler()\n\nX = sc_X.fit_transform(X)\ny = sc_X.fit_transform(y)\n","7248f15a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","512928d1":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","8dccef9f":"\n\n\n# instantiate\nlinreg = LinearRegression()\n\n# fit the model to the training data (learn the coefficients)\nlinreg.fit(X_train, y_train)\n\n# print the intercept and coefficients\nprint(\"intercept is: \",linreg.intercept_)\n\nprint(\"coefficients are: \",linreg.coef_)","730ff934":"y_pred = linreg.predict(X_test)","a5075064":"\nprint(\"R-Square Value\",r2_score(y_test,y_pred))\nprint(\"\\n\")\nprint (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\nprint(\"\\n\")\nprint (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\nprint(\"\\n\")\nprint (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","4d4d4fcf":"\nmy_pipeline = Pipeline(steps=[('model', LinearRegression())])\n\nfrom sklearn.model_selection import cross_val_score\n\n# Multiply by -1 since sklearn calculates *negative* scores\nscores1 =  1 * cross_val_score(my_pipeline, X, y,\n                              cv=10,\n                              scoring='r2')\nscores2 = -1 * cross_val_score(my_pipeline, X, y,\n                              cv=10,\n                              scoring='neg_mean_absolute_error')\nscores3 = -1 * cross_val_score(my_pipeline, X, y,\n                              cv=10,\n                              scoring='neg_root_mean_squared_error')\n\nprint(\"R squared scores:\\n\", scores1)\nprint(\"Average R squared score (across experiments):\",scores1.mean())\n\n\nprint(\"RMSE scores:\\n\", scores3)\nprint(\"Average RMSE score (across experiments):\",scores3.mean())","4056c3b6":"x2 = sm.add_constant(X)\nest = sm.OLS(y, x2)\n#OLS is Ordinary Least Squares\n#est.TAB\nest2 = est.fit()\nprint(est2.summary())","316505cb":"df_classif = df","1b5f666f":"df_classif['availability_365'] = df_classif['availability_365'].apply(lambda x: 1 if x == 365 else 0)","fe017206":"sns.countplot(df_classif['availability_365'])","da0fe446":"X = df_classif.drop(['availability_365'],axis=1)\ny = df_classif['availability_365'].values\n","cd692d16":"from imblearn.over_sampling import SMOTE\nimport imblearn\noversample = SMOTE()\nX, y = oversample.fit_resample(X, y)","82f209a8":"sns.countplot(y)","3f8e7562":"len(y)","3a48f8c0":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\n    \n# Used for classification of dataset.\ndef classif_results(): \n  conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n  print('Confusion matrix:\\n', conf_mat)\n\n  labels = ['Class 0', 'Class 1']\n  fig = plt.figure()\n  ax = fig.add_subplot(111)\n  cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n  fig.colorbar(cax)\n  ax.set_xticklabels([''] + labels)\n  ax.set_yticklabels([''] + labels)\n  plt.xlabel('Predicted')\n  plt.ylabel('Expected')\n  plt.show()\n\n  print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred))\n\n  from sklearn.metrics import classification_report\n  print(classification_report(y_test, y_pred))\n\n  \n  auc = roc_auc_score(y_test, y_pred)\n  print(\"AUC Score: \")\n  print(auc)\n\n  fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n  plot_roc_curve(fpr, tpr)\n\n","0e3d2c34":"from sklearn.linear_model import LogisticRegression \nclassifier = GaussianNB()\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\nclassifier.fit(X_train,y_train)\n\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\n\n\nclassif_results()","5fcf5247":"from sklearn.linear_model import LogisticRegression \nclassifier = LogisticRegression()\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\nclassifier.fit(X_train,y_train)\n\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\n\n\nclassif_results()","84d5d529":"classifier = KNeighborsClassifier()\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\nclassifier.fit(X_train,y_train)\n\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\n\n\nclassif_results()","06f4155a":"error = []\n# Calculating error for K values between 1 and 30\nfor i in range(1, 30):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error.append(np.mean(pred_i != y_test))\n\nplt.figure(figsize=(12, 6))\nplt.plot(range(1, 30), error, color='red', linestyle='dashed', marker='o',\n         markerfacecolor='blue', markersize=10)\nplt.title('Error Rate K Value')\nplt.xlabel('K Value')\nplt.ylabel('Mean Error')\nprint(\"Minimum error:-\",min(error),\"at K =\",error.index(min(error)))","0fb10830":"classifier = tree.DecisionTreeClassifier()\nclassifier.fit(X_train,y_train)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\n\n\nclassif_results()","0146218f":"lr_model = LogisticRegression()\nknn_model = KNeighborsClassifier()\nnb_model = GaussianNB()\ndes_model = tree.DecisionTreeClassifier()\n\nmodels = [\n  \n    {\n        'label': 'Naive Bayes',\n        'model': nb_model\n    },\n    {\n        'label': 'Logistic Regression',\n        'model': lr_model\n    },\n      {\n        'label': 'KNN',\n        'model': knn_model\n    },\n  \n    {\n        'label': 'Decision Tree ',\n        'model': des_model\n    }\n]\n\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\n\n\nplt.clf()\nplt.figure(figsize=(8,8))\nfor m in models:\n    m['model'].probability = True\n    probas = m['model'].fit(X_train,y_train).predict_proba(X_test)\n    fpr, tpr, thresholds = roc_curve(y_test, probas[:, 1])\n    roc_auc  = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (m['label'], roc_auc))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=0, fontsize='small')\nplt.show()","d973f7e4":"### Maps - Scatterplots","c609ebbc":"## Loading the dataset","e963abd1":"Most hosts used the listings only once that is around 32.3k and 6.6k around 2 times.\n","dbddc469":"#### Latitude and Longitude with loaction","c76e6d2f":"We dont require host_id,name,id,host_name and last_review as these do not any way effect for further analysis or pre-processing. So we can drop them.","7236902d":"### Plots","89f72f8b":"#### Predicting the Statistic under null hypothesis\nSimulating the null hypothesis under permuation \n","bba979e8":"#### One simulation","3f58e3d2":"On an average non homes availablity is more in a year than homes.","cfc69f75":"Intresting to note that in our dataset, around 25k people (52%) choose to use a house while 22k(46%) for a private room. Only 1k(2%) people choose a shared room. This could mean more people who use airbnb , use it with family maybe for tours,visits,etc... ","51611438":"#### Permutation test\nSimulating for many times and collecting the differences in an array","1e5507e0":"#### Here we fail to reject H0 and hence we accept the null hypothesis itself that the average availablity of Airbnbs would be same even if we take a sample of availablity data.","76fbeaff":"Here, we can check on how the mean error gets varied with respect to that of the number of neighbours. We can see that the best k value that corresponds to least error rate comes initially and gradually increases across the scale. This is because we have initaially done a synthesised oversampling of data so already data points are plotted based on feature grouping and thats why wehen we run KNN we would end up with least error at first and gradually error increases on increasing n.","38c5a1be":"## Linear Regression","7aa48a49":"### Naive Bayes","571f8f31":"## T-Test (Students T-Test)","adba7894":"We can find that almost 23k airbnb's are non-homes that is a private room or shared room while 25k of them are homes.","86fc4dcf":"Above 1, around 406 airbnbs have 2 reviews per month, 222 with 3 and 130 with 4.\n\n","1e9bdc09":"Around 1.3k airbnbs have 365 days availablity and rest doesnt.\n","d9716058":"### Price:","6789f8ed":"Here, i performed t-test to check wheather the availablity of airbnb when taken a sample would change majorly with that of the overall average avaialblity of all airbnbs for airbnb's which are available for atleast more than a month.\n\nNull hypothsis : Average availablity of Airbnbs would be same even if we take a sample of availablity data.\n\nAlternate : Average availablity of Airbnbs would be different if we take a sample of availablity data.","284f0fa2":"I have taken a large sample of data as my data is not normal taking small sample size for t-test would be invalid.","e7cf7d83":"Decision Tree as well as KNN model seems to be working well for our data and has good classification ability over Naive Bayes and Logistic Regression.","0767e791":"#### Hypothesis:","00ab3108":"A function to carry out plotting for distributions.","8dce697a":"#### Latitude and Longitude with room availablity for 365 days","ee7e5a11":"## Data Analysis and Visualization","6ba6ebbb":"We are intrested to get the data of airbnb's available over a month.","09714dfc":"Next, we go for a 10 fold cross validation on our Linear model.","88bf46dd":"Almost 2k+ airbnb's has a price of 100 dollars and 150 dollars each respectively.\n\n1.5k airbnb's have around 50 dollars price.","efd65839":"Null hypothsis : Availablity has no influence over airbnb being home or non-home.\n\nAlternate : Availablity has an influence over airbnb being home or non-home.","5a989fcb":"Staten Island has th highest average airbnb availablity. ","85ce497a":"### Data Cleaning","08cc4a1e":"## New York City Airbnb Open Data\n### Airbnb listings and metrics in NYC, NY, USA (2019)\n## Airbnb : Wrangling, Analysis, Visualization, Regression, Classification, Hypothesis-Testing","793c493c":"Manhattan is the city where most Airbnb transactions have occured with 44% of entire dataset. The least happend in Staten Island only 1%. Brooklyn consisted on 41% of transactions with 12% Queens and 2 % in Bronx.","ba6c3865":"We can from here interpret the fact that R2 is almost 0.5 which means the model is moderate in nature and not particularly weak. We have also got our RMSE around 0.7 which is fine.","344d2993":"Following is the hist representation of both homes and non-homes.","35e17835":"We can first see the box plot of the price and find some outliers and remove them so that we can do better in further steps.","e6f7f1ac":"## Multiple Linear Regression","a8c1ce0f":"The empirical P-value is nearly 0, meaning that none of the 5,000 observed samples resulted in a difference of -1.79 or lower. This is an approximation; the exact chance of getting a difference in that range is not 0 but it is vanishingly small. \n#### Therefore, we reject the null hypothesis and go for alternate hypothesis. Therefore, Availablity do have an influence on airbnb being home or non-home.","8087ed6f":"Here we are plotting thr linear model for this simple linear regression. We can analyze the model and get the regression Intercept.\n\nAlso i have plotted the residue plot at the end so that we can see how the difference between actual value and prediction is.","a658744c":"15.9k reviews were above 1.\n","6e7b5d9d":"### Availablity","07a4836e":"In the availablity_365 , if we have 365 days availablity then we can directly assgn them as 365 itself and 0 for rest because they isnt availavle for 365 days.","a432b304":"### Neighbourhood Groups - Location","63908cf4":"### Number of reviews","cffe428b":"\n\nEnjoy great views in Manhattan has the highest reviews per month. They offer Private room and is worth 100 dollars a night. \n\n","541ef198":"### Room Type","97cdbc51":"We can see that Williamsburg is the hottest area of transaction followed by Bedford-Stuyvesant.\n\nThis pie-chart shows the top 5 areas by percentage in the dataset.","8ef67243":"Manhattan has highest airbnbs with highest minimum nights.","0ae48c37":"We can from here interpret the fact that R2 is almost 0.35 which means the model is considered weak in nature and not particularly weak. We have also got our RMSE around 0.8 which is fine to an extent.","3c8deec2":"## Data Wrangling and Cleaning ","e645169d":"On an average the non-homes were more as compared to that of homes data.","a3758e50":"This shows us the dataset distribution in NewYork city with respect to latitude and longitude.","0833021a":"###  Decision tree","a711229d":"### Minimum Nights","ed84e1ec":"Here, we can see that there are a lot of outliers taking up the data, it could be expensive Airbnbs, but there are a very few of them compared to data and it overall has a huge impact and must be removed.","012f40fb":"## Importing libraries\nHere we are importing all the libraries required for the case study.","74add863":"\n\nWe have 3 airbnbs with 10k per night luxury stay, one private room and 2 home stay.","fc04e94a":"### Context:\nThis dataset describes the listing activity and metrics in NYC, NY for 2019.\n","5ea796ec":"### Host ID","670b08da":"\nCostliest airbnb with 365 days availablity costs around 10k dollars with average of 250 dollars.","406f8d17":"Home service seems to be most used by people and the highest in Manhattan. This is also the highest service used across New York City.\n\nIn Brooklyn, Private rooms were more used.\n\n","93c4b7bf":"Went for oversampling as we can see a huge imbalance in data, so we would end up with very low AUC score. Oversampling seem to work better than undersampling in this case.","204c8ed0":"I have use Scipy library to import ttest_ind which helps us to carry out the t-test and give us the p-value.","927e6d9b":"We performed an Encoding on neighbourhood and room type and removed some unwanted columns.","ca6bf5e1":"Here i got intrested to know how the regresion line performs as early during wrangling i found number of reviews and reviews per month to be correlated with an coeffecient of 0.5. I have specfically taken a range of data for my regression purpose for better visualization. That is num of reviews less than 400 and reviews per month less than 15.","9573f99b":"We do not have any duplicate rows in our dataset.","fbd8d843":"## Understanding the dataset","2c2bc95d":"If we look at the top 100 airbnb's with number of reviews, Brooklyn has highest reviews followed by Queens and then Manhattan.","e43c48bd":"Defining a functiom to perform classification plotting of confusion matrix.","a3a5533e":"Manhattan airbnb's has the highest average price.\n\n\n","37560d85":"### Reviews per month","04b8a19f":"If we take the top 100 airbnbs then almost 70+ comes in Manhattan, followed by 25 in Brooklyn.","74f59984":"We can see that the average R square came around 0.48 and RMSE around 0.71.","7141e53c":"## Hypothesis Testing","17423695":"After experimenting around values the range of (20,250) has a good gaussian wise distribution and hence we can go ahead with data in this range and remove others as outliers.","96b17f31":"I defined a function here that will help us automatically do the regression and show the plot and OLS results.","bf5a5462":"### KNN","4a71f31d":"We can observe that most of almost 12k people used 1 night stay in airbnb.\n\n11k people choose 2 night stay while 7k choose 3 night stay.\n\nAlmost 3.7k stayed upto a month.","751152d6":"We can visualize the distribution with its mean value for entire dataframe.","c9732068":"So, we can see there are around 10k null values in the last_review and review_per_month columns and a very few null values in name and host_name.","465a6621":"#### Logistic Regression","0f086a1f":"#### Test Statics\nUsing the mean availablity difference of homes and non-homes.","7c8eb03e":"Here we have almost 48.8k rows with 16 columns for each. It is composed of 3 float types, 7 int types and 6 object types.","997aa967":"Now we can take both homes and non-homes and plot and overlay to get the mean of each on graph.","528d388e":"Here we are intrested to predict the prices of Airbnb's with help of all other variables assosiated with it.","c8f20dcb":"This is the final price data on which we are performing the rest of operations.","de66c7d5":"### Calculate host listing","a536fe23":"\n\nGreat Bedroom in Manhattan gets the highest reviews and it costs around 69 dollars.\n\n\n\n\n\n ","e3bc3acf":"We can actually fill all the rows of column of reviews_per_month as 0 where its null value, this is because the data is null only because no one has reviewd it and hence the number of review is 0 here.","7a58ed81":"We can observe that the highest times transaction done by a customer is 327 in the year 2019.","72408c5d":"### Bivariate Analysis","5e9b5f05":"<a href=\"https:\/\/colab.research.google.com\/github\/Siddharth1698\/New-York-City-Airbnb-Data-Case-Study\/blob\/main\/New_York_City_AirBnb_Open_Data.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","788fec48":"Notable that we have 5 locations in dataset and 3 room types.","e073f49b":"## Encoding Data and Outlier removal.","436fd994":"\nOn an average, a host has used listings 7 times.\n\nMaximum times being 327.","4fac877a":"We can visualize the distribution with its mean value for sample dataframe.","b30dff4c":"I used 30% of the data for testing and fitting it to the linear model which we generated using the rest off the data.","ca458c55":"This is our linear model and we can see the intercept and coefficents at the end.","ab5380b2":"I am taking the price as 'y' and the rest of columns as 'X'. Here we can see that the data are all of different scales and hence we use the help of StandardScaler to scale them and we can procced with out splitting.","cb1361d1":"#### Latitude and Longitude with room type","f6f609b3":"10k airbnbs dont have any reviews.\n\n5.2k has around 1 review and the maximum number of reviews is 607 which only 1 airbnb has.","b12ee18d":"Since we removed 4 columns from the dataframe, we now have to deal with 12 columns.","e8bbf1af":"Here we have taken a dataset where we have room types as homes and non-homes and their total availablity.","fbdfb29b":"\n\nThe average pricing is around 152 dollars.\n\n50% of data has price greater than 106 dollars.\n\nThe costliest airbnb has around 10k dollars as price.","cd0abc57":"-> From this we can see the mean price to be around 152 dollars. \n\n-> Average availablity of an airbnb around a year is 112 days.\n","7f46e9d0":"### Neighbourhoods:","ed8cd407":"## Classification"}}