{"cell_type":{"afea53b0":"code","f781730b":"code","1ce548a1":"code","aa41fec2":"code","37c7936f":"code","3321cd52":"code","9872e3bc":"code","769082b6":"code","03db96f6":"markdown","0dd54b5e":"markdown","1d83a8b5":"markdown"},"source":{"afea53b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f781730b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nimport graphviz \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.tree import plot_tree\nfrom sklearn.model_selection import GridSearchCV","1ce548a1":"# Data loading \uc548\ub420 \ub54c, [winequality-red.csv]\ubcf5\uc0ac -> \uc624\ub978\ucabd \uc0c1\ub2e8 +Add data click -> \uac80\uc0c9\ucc3d\uc5d0 \ubd99\uc5ec\ub123\uae30 \ud6c4 winequality-red\ub97c \ucc3e\uc544 \uc624\ub978\ucabd add click, \n# \uc624\ub978\ucabd input \ucc3d\uc5d0\uc11c winequalityred\ub97c \ub204\ub974\uace0 \ud558\ub2e8\uc758 winequality-red.csv\uc5d0 \ub9c8\uc6b0\uc2a4\ub97c \uac16\ub2e4\ub300\uba74 \uc6b0\uce21\uc5d0 \uacbd\ub85c\ubcf5\uc0ac click\n# \uc544\ub798 \" \"\uc548\uc758 \ub0b4\uc6a9\uc744 \ubaa8\ub450 \ub4dc\ub798\uadf8 \ud574 \ub2e4\uc2dc \ubd99\uc5ec\ub123\ub294\ub2e4.\nwine = pd.read_csv(\"..\/input\/winequalityred\/winequality-red.csv\")","aa41fec2":"wine.head()","37c7936f":"# y= quality\uc5d0 \ub300\ud55c \ube48\ub3c4 \uc218\nquality_dist = wine['quality'].value_counts()\nplt.bar(quality_dist.index, quality_dist)\nplt.xlabel('quality')\nplt.ylabel('frequency')\nplt.show()","3321cd52":"#code copy \uc2dc '''\uc740 \uc81c\uc678 \ud6c4 \ubd99\uc5ec\ub123\uae30, \ubaa8\ub378\uba85 \uc790\ub9ac\uc5d0 dt or dt_best \uc785\ub825\n'''\nplt.figure(figsize=(20, 15))\nplot_tree(decision_tree=\ubaa8\ub378\uba85, filled=True)\nplt.show()\n# fig.savefig('imagename.png') # <- \uadf8\ub9bc \ud655\uc778\ud558\uace0 \uc2f6\uc740 \uacbd\uc6b0, \uc800\uc7a5 \ud6c4 \ud655\uc778\n'''","9872e3bc":"#code copy \uc2dc '''\uc740 \uc81c\uc678 \ud6c4 \ubd99\uc5ec\ub123\uae30\n'''\nparams = {\n    \"criterion\" : ['gini', 'entropy'],\n    \"max_depth\" : [3, 4, 5],\n    \"min_samples_split\" : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n}\n'''","769082b6":"X = wine.drop('quality',axis=1)\ny = wine['quality']","03db96f6":"1. Data\ub97c X, y \ub85c \uad6c\ubd84\n2. X, y\uc5d0 \ub300\ud574 \uac01\uac01 train, test set \ubd84\ud560 (train: test = 70: 30, random_state = 42)\n3. (1)\uae30\ubcf8 Hyper-parameter\uc758 DecisionTreeClassifier(random_state = 0)\ub97c dt\ubcc0\uc218\uc5d0 \uc815\uc758, (2) Train data fitting, (3) X_test \uc14b\uc5d0 \ub300\ud55c \uc608\uce21 \uac12\uc744 \ub3c4\ucd9c\ud558\uc5ec y_pred\uc5d0 \uc800\uc7a5\n4. \ud558\uae30 \uc2dc\uac01\ud654 code\ub97c \uc774\uc6a9\ud558\uc5ec plotting (% runnig \uc2dc\uac04 \uc18c\uc694\ub428)\n5. classification_report()\uc774\uc6a9\ud558\uc5ec test set\uc5d0 \ub300\ud55c performance \ud655\uc778\n6. Best hyper-parameter \ub3c4\ucd9c(code \ucc38\uc870, (1) GridSearchCV()\ub294 grid_tree\uc5d0 \uc815\uc758\ud558\uace0, cv=3 \uc73c\ub85c \uc124\uc815, (2) grid_tree\ub97c train set\uc5d0 fitting, (3) print(grid_tree.best_params_) )\n7. (1) Best parameter \uac12\uc774 \uc785\ub825\ub41c DecisionTreeClassifier(random_state = 0)\ub97c dt_best \ubcc0\uc218\uc5d0 \uc815\uc758,(2) Train data fitting, (3) X_test \uc14b\uc5d0 \ub300\ud55c \uc608\uce21 \uac12\uc744 \ub3c4\ucd9c\ud558\uc5ec y_pred_best\uc5d0 \uc800\uc7a5\n8. \uc2dc\uac01\ud654 code\ub97c \uc774\uc6a9\ud558\uc5ec plotting\n9. classification_report()\uc774\uc6a9\ud558\uc5ec y_pred_best\uc5d0 \ub300\ud55c \uac1c\uc120\ub41c performance \ud655\uc778\n10. \uae30\ubcf8 \ubaa8\ub378\uc758 \uc131\ub2a5\uacfc hyper-parameter \uac1c\uc120 \ud6c4 \uc131\ub2a5\uc758 \ucc28\uc774\uc5d0 \ub300\ud574 \ub17c\uc758","0dd54b5e":"# \uc2e4\uc2b5 -  Decision Tree model\uc744 \uc774\uc6a9\ud558\uc5ec wine class \uc608\uce21","1d83a8b5":"## 1. Data\ub97c X, y \ub85c \uad6c\ubd84"}}