{"cell_type":{"23fd5621":"code","fe1c4a13":"code","6cad78d2":"code","5ce47c54":"code","80a41a62":"code","48987558":"code","5a9ba063":"code","4e557157":"code","ceb351fc":"code","c9f7a075":"code","44236272":"code","eba25162":"code","f44017bd":"code","793c4616":"code","38e4ad02":"code","06a8ee1d":"code","bc949fd7":"code","9a9f547f":"code","d17d6520":"code","99c1bb27":"code","c4d5f5ff":"code","fcb58830":"code","7d3d5d61":"code","759814fe":"code","ed29b62f":"markdown","d7475b85":"markdown","dea8d2d7":"markdown","b8b1bdf0":"markdown","3679d4a3":"markdown","147aad0b":"markdown","886bceed":"markdown","e18915fe":"markdown","520a7d0e":"markdown","c0579fbb":"markdown","2f2ca45b":"markdown","8462c7a1":"markdown"},"source":{"23fd5621":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fe1c4a13":"os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning","6cad78d2":"import tensorflow as tf\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n    \nprint('Number of replicas:', strategy.num_replicas_in_sync)","5ce47c54":"import random\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\nimport transformers\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification, TFAutoModel\nfrom transformers import AdamW\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","80a41a62":"train = pd.read_csv(\"..\/input\/contradictory-my-dear-watson\/train.csv\")\ntrain.shape","48987558":"train.head()","5a9ba063":"train['label'].value_counts()","4e557157":"train['premise'].str.len().describe(np.linspace(0, 1, 9))","ceb351fc":"train['hypothesis'].str.len().describe(np.linspace(0, 1, 9))","c9f7a075":"train.premise.values[1]","44236272":"train.hypothesis.values[1]","eba25162":"train.label.values[1]","f44017bd":"labels, frequencies = np.unique(train.language.values, return_counts = True)\n\nplt.figure(figsize = (10,10))\nplt.pie(frequencies,labels = labels, autopct = '%1.1f%%')\nplt.show()","793c4616":"tokenizer = AutoTokenizer.from_pretrained('joeddav\/xlm-roberta-large-xnli')","38e4ad02":"encoded = tokenizer(train['premise'].tolist(), train['hypothesis'].tolist(), padding='max_length', return_tensors='tf')","06a8ee1d":"with strategy.scope():\n    input_ids = tf.keras.Input(shape =(512,), dtype=tf.int32, name='input_ids') \n    attention_mask = tf.keras.Input(shape=(512,),dtype=tf.int32, name='attention_mask')  \n    \n    roberta = TFAutoModel.from_pretrained('joeddav\/xlm-roberta-large-xnli')\n    roberta = roberta([input_ids, attention_mask])[0]\n    \n    output = tf.keras.layers.GlobalAveragePooling1D()(roberta)\n    output = tf.keras.layers.Dense(3, activation = 'softmax')(output)\n        \n    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n    \n    model.compile(optimizer = tf.keras.optimizers.Adam(lr=1e-5), \n                  loss='sparse_categorical_crossentropy', \n                  metrics=['accuracy']) \n    \n    model.summary()","bc949fd7":"early_stop = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n\nmodel.fit(encoded.data, tf.convert_to_tensor(train.label), \n          validation_split=0.2, \n          epochs=10,\n          batch_size=8*strategy.num_replicas_in_sync,\n          callbacks=[early_stop],\n          verbose=1)","9a9f547f":"test = pd.read_csv('..\/input\/contradictory-my-dear-watson\/test.csv')","d17d6520":"test_encoded = tokenizer(test['premise'].tolist(), test['hypothesis'].tolist(), padding='max_length', return_tensors='tf')","99c1bb27":"predictions = [np.argmax(i) for i in model.predict(test_encoded.data)]","c4d5f5ff":"submission = test.id.copy().to_frame()\nsubmission['prediction'] = predictions","fcb58830":"submission['prediction'].value_counts()","7d3d5d61":"submission.head()","759814fe":"submission.to_csv(\"submission.csv\", index=False)","ed29b62f":"These statements are contradictory, and the label shows that.\n\nLet's look at the distribution of languages in the training set.","d7475b85":"Hi!\n\n[This notebook is based on official tutorial;](https:\/\/www.kaggle.com\/anasofiauzsoy\/tutorial-notebook) and [Detecting Contradictions in Multilingual Text](https:\/\/www.kaggle.com\/sukanyabag\/detecting-contradictions-in-multilingual-text)\n\nIf you like it, please do a upvote! ;)","dea8d2d7":"The submission file will consist of the ID column and a prediction column. We can just copy the ID column from the test file, make it a dataframe, and then add our prediction column.","b8b1bdf0":"The training set contains a premise, a hypothesis, a label (0 = entailment, 1 = neutral, 2 = contradiction), and the language of the text. For more information about what these mean and how the data is structured, check out the data page: https:\/\/www.kaggle.com\/c\/contradictory-my-dear-watson\/data","3679d4a3":"## Creating & Training Model","147aad0b":"## Downloading Data","886bceed":"Let's set up our TPU.","e18915fe":"And now we've created our submission file, which can be submitted to the competition.","520a7d0e":"Creating the model for parallelization:","c0579fbb":"## Preparing Data for Input","2f2ca45b":"## Generating & Submitting Predictions","8462c7a1":"Let's look at one of the pairs of sentences."}}