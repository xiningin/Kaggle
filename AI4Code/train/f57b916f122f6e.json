{"cell_type":{"5ecbd591":"code","e8b43889":"code","d859b033":"code","ae6a63ba":"code","4bd9e8cd":"code","a9c03ece":"code","aef46193":"code","e92e3fb6":"markdown","e1b8cf20":"markdown","21be9765":"markdown","ba8dc6ec":"markdown","a60e2dda":"markdown","6c43d084":"markdown","c33b743c":"markdown"},"source":{"5ecbd591":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)4\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchvision.datasets import ImageFolder\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport os\ntorch.cuda.empty_cache()","e8b43889":"data_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray'\npneumonia_files = os.listdir(data_dir + \"\/train\/PNEUMONIA\")\nnormal_files = os.listdir(data_dir + \"\/train\/NORMAL\")\n#print(os.listdir(data_dir))\ntrainset = ImageFolder(data_dir+'\/train', \n                      transform=transforms.Compose([transforms.Resize(200),\n                                            transforms.CenterCrop(200),\n                                            transforms.RandomHorizontalFlip(),\n                                            transforms.RandomRotation(10),\n                                            transforms.RandomGrayscale(),\n                                            transforms.RandomAffine(translate=(0.05,0.05), degrees=0),\n                                            transforms.ToTensor(),\n                                            #transforms.Normalize((0.5,), (0.5,))\n                                                   ]))\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n                                          shuffle=True, num_workers=2)\ntestset = ImageFolder(data_dir+'\/test', \n                      transform=transforms.Compose([transforms.Resize(200),\n                                            transforms.CenterCrop(200),\n                                            transforms.ToTensor()\n                                                   ]))\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64,\n                                          shuffle=True, num_workers=2)\nclasses = trainset.classes\nimg, label = trainset[1]\nprint(img.shape, label)\n","d859b033":"def show_example(img, label):\n    print('Label: ', trainset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0))\n    \nshow_example(*trainset[1000])","ae6a63ba":"#resnet50 = models.resnet50(pretrained=True)\ndevice = torch.device('cuda')\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.network = models.resnet50(pretrained=True) \n        num_features = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_features, 2)\n\n    def forward(self, x):\n        return self.network(x)\n\n\nnet = Net().to(device)","4bd9e8cd":"import torch.optim as optim\nweights = [1.5, 1.0]\nclass_weights = torch.FloatTensor(weights).cuda()\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","a9c03ece":"for epoch in range(8):  # loop over the dataset multiple times\n    \n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n        inputs, labels = inputs.to(device),labels.to(device)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n       \n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        # print statistics\n        running_loss += loss.item()\n        if i % 20 == 19:    # print every 20 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 20))\n            running_loss = 0.0\n\nprint('Finished Training')","aef46193":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images: %d %%' % (\n    100 * correct \/ total))\n\n","e92e3fb6":"Next we can set up our CNN. For this project, I decided to use the resnet50 model. More information about resnet in the original paper: https:\/\/arxiv.org\/pdf\/1512.03385.pdf. We are using the version that's pretrained on ImageNET (this significantly reduces total training time). We will also utilitize the GPU here and in the training step to increase performance.","e1b8cf20":"We will import the dataset directly in Kaggle. Since the images have varying sizes, we will first transform the dataset into size of 200x200. As we can below, each image is of size (3,200,200). I find this to be a good size for training while still retaining all of the necessary information in the original image. ","21be9765":"Now it's time to choose our loss function and optimization function for training. Here we will use the cross entropy loss and the stochastic gradient descent with momentum. These parameters are what I have found to work decently well but can be changed around for slightly different results. ","ba8dc6ec":"Let's train our CNN using the training set. Since the CNN is pre-trained, we can get good results with a fairly low number of epoches. We will print our progress from time to time to see if our loss is decreasing!","a60e2dda":"Here we will show what the image looks like after our pre-processing steps.","6c43d084":"For this project, we will to use pytorch to implement a Convolutional Neural Network that can identify Pneumonia from the chest X-ray images in this link: https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia. First we import all the necessary libraries:","c33b743c":"We can see that our loss is generally decreasing with every epoch! We usually want to avoid training for too many iterations to avoid overfitting. Now that we've finished training, let's see how good the CNN model is on our test set. "}}