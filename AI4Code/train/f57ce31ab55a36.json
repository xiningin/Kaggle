{"cell_type":{"93006fe3":"code","ccb0d9e1":"code","9cb024da":"code","9a4a87a5":"code","05414ad7":"code","bec13b38":"code","736f79f9":"code","1f8afeba":"code","7439f382":"code","8a515de0":"code","233756f9":"code","bf733cbc":"code","89cef598":"code","4ebf1340":"code","7c52c605":"code","4f9e3672":"code","612db3a6":"code","a197f18a":"code","713b7abf":"code","d3ac1d6c":"code","efe0ab2b":"code","277349e4":"code","e2f1e8d4":"code","b65635df":"code","cb00c531":"code","4124ef44":"code","81c0a2f8":"code","59906bc6":"code","3dcb4914":"code","0030ddf7":"code","a141c7fb":"code","1b86a454":"code","c53cffad":"code","b4e8f1b3":"code","b506a368":"code","831af7be":"code","b70bd41c":"code","6478dc15":"code","9dd9d374":"code","1969caef":"code","50119d0a":"code","c601cdb2":"code","ebc1aa0b":"code","31ba6997":"code","acb47265":"code","face64c2":"code","85a82085":"code","e1b736d5":"code","4dd41b41":"code","699e0075":"code","50c8c494":"code","59eac287":"code","35038590":"code","71e0ff75":"code","0d4bfeb3":"code","6c49a37c":"code","825c04ba":"code","bd876b41":"code","e2fa4583":"code","4cc03173":"code","4f93b7c6":"code","e2521082":"code","423c1097":"code","fd860ed3":"code","3776c27c":"code","f025cc6c":"code","2f94b3cb":"code","19135a2d":"code","3cf077d0":"code","ba8103d0":"code","231e6959":"code","b69f933b":"code","c07c2db5":"code","04560737":"code","03432763":"code","fcde06bf":"markdown","fe96984a":"markdown","062f08c5":"markdown","07217ed2":"markdown","b3cedfb5":"markdown","98d46d42":"markdown","1e3f3b8f":"markdown","f87494e1":"markdown","57c44d0b":"markdown","1f6d0650":"markdown","f3b661e0":"markdown","a2b8ab78":"markdown","34776102":"markdown","0e1de96d":"markdown","679bc75d":"markdown","fbd6a73c":"markdown","5d375d54":"markdown","a9886f25":"markdown","2afde9bf":"markdown","3eb87b7b":"markdown","f07a159a":"markdown","a565ec8c":"markdown","8826d909":"markdown","083c4e49":"markdown","8670e872":"markdown","1e37ce68":"markdown","34b520bd":"markdown","30962f5b":"markdown","3c3079e2":"markdown"},"source":{"93006fe3":"import pandas as pd\nimport numpy as np\nimport os\n\nimport ast\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nimport shutil\nfrom tqdm.notebook import tqdm\nimport tqdm.notebook as tq\n\nimport albumentations as albu\nfrom albumentations import Compose\n\nimport matplotlib.pyplot as plt","ccb0d9e1":"os.listdir('..\/input\/v2-balloon-detection-dataset')","9cb024da":"base_path = '..\/input\/v2-balloon-detection-dataset\/'","9a4a87a5":"import torch\nfrom IPython.display import Image, clear_output\n\nclear_output()\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","05414ad7":"# Print the current working directory\n!pwd","bec13b38":"# List the files and folders in the working directory\n!ls","736f79f9":"# clone repo\n!git clone https:\/\/github.com\/ultralytics\/yolov5.git  \n\n# change the working directory to yolov5\n#%cd yolov5\nos.chdir('\/kaggle\/working\/yolov5')\n\n# install dependencies\n%pip install -qr requirements.txt \n\n# Change the working directory back to \/kaggle\/working\/\nos.chdir('\/kaggle\/working\/')\n\n!pwd","1f8afeba":"# Ref: https:\/\/www.kaggle.com\/awsaf49\/vinbigdata-cxr-ad-yolov5-14-class-train\/data\n\n# Copy the yolov5 folder from the dataset to  \/kaggle\/working\/\n\n# Uncomment this line to set up yolov5 offline.\n#shutil.copytree('..\/input\/v2-balloon-detection-dataset\/yolov5', '\/kaggle\/working\/yolov5')\n","7439f382":"# We need to be in \/kaggle\/working\/ for the next cell to run.\n\n!pwd","8a515de0":"path = base_path + 'balloon-data.csv'\n\ndf_data = pd.read_csv(path)\n\n# Convert bbox column entries from strings to lists\n# \"[........]\" to [......]\ndf_data['bbox'] = df_data['bbox'].apply(ast.literal_eval)\n\nprint(df_data.shape)\n\ndf_data.head()","233756f9":"# https:\/\/pythonprogramming.net\/drawing-writing-python-opencv-tutorial\/\n# https:\/\/codeyarns.com\/tech\/2015-03-11-fonts-in-opencv.html\n# https:\/\/stackoverflow.com\/questions\/60674501\/how-to-make-black-background-in-cv2-puttext-with-python-opencv\n# https:\/\/www.geeksforgeeks.org\/python-opencv-cv2-puttext-method\/\n# https:\/\/pysource.com\/2018\/01\/22\/drawing-and-writing-on-images-opencv-3-4-with-python-3-tutorial-3\/\n\n\ndef draw_bbox(image, xmin, ymin, xmax, ymax, text=None):\n    \n    \"\"\"\n    This functions draws one bounding box on an image.\n    \n    Input: Image (numpy array)\n    Output: Image with the bounding box drawn in. (numpy array)\n    \n    If there are multiple bounding boxes to draw then simply\n    run this function multiple times on the same image.\n    \n    Set text=None to only draw a bbox without\n    any text or text background.\n    E.g. set text='Balloon' to write a \n    title above the bbox.\n    \n    xmin, ymin --> coords of the top left corner.\n    xmax, ymax --> coords of the bottom right corner.\n    \n    \"\"\"\n\n\n    w = xmax - xmin\n    h = ymax - ymin\n\n    # Draw the bounding box\n    # ......................\n    \n    start_point = (xmin, ymin) \n    end_point = (xmax, ymax) \n    bbox_color = (255, 0, 0) \n    bbox_thickness = 15\n\n    image = cv2.rectangle(image, start_point, end_point, bbox_color, bbox_thickness) \n    \n    \n    \n    # Draw the tbackground behind the text and the text\n    # .................................................\n    \n    # Only do this if text is not None.\n    if text:\n        \n        # Draw the background behind the text\n        text_bground_color = (0,0,0) # black\n        cv2.rectangle(image, (xmin, ymin-150), (xmin+w, ymin), text_bground_color, -1)\n\n        # Draw the text\n        text_color = (255, 255, 255) # white\n        font = cv2.FONT_HERSHEY_DUPLEX\n        origin = (xmin, ymin-30)\n        fontScale = 3\n        thickness = 10\n\n        image = cv2.putText(image, text, origin, font, \n                           fontScale, text_color, thickness, cv2.LINE_AA)\n\n\n\n    return image","bf733cbc":"def display_images(df):\n\n    # set up the canvas for the subplots\n    plt.figure(figsize=(20,70))\n\n\n    for i in range(1,13):\n\n        index = i\n\n        # Load an image\n        path = base_path + 'images\/' + df.loc[index, 'fname']\n        image = plt.imread(path)\n        #image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n\n        plt.subplot(10,3,i)\n\n        plt.imshow(image)\n        plt.axis('off')","89cef598":"display_images(df_data)","4ebf1340":"# set the figsize so the image is larger\nplt.figure(figsize=(8,8))\n\n# Choose an index.\n# Change this number to see different images.\ni = 4   \n\n# Load an image\nfname = df_data.loc[i, 'fname']\n\npath = base_path + 'images\/' + fname\nimage = plt.imread(path)\n\nbbox_list = df_data.loc[i, 'bbox']\n\n# Draw the bboxes on the image\nfor coord_dict in bbox_list:\n    \n    xmin = int(coord_dict['xmin'])\n    ymin = int(coord_dict['ymin'])\n    xmax = int(coord_dict['xmax'])\n    ymax = int(coord_dict['ymax'])\n    \n    image = draw_bbox(image, xmin, ymin, xmax, ymax, text=None)\n\nprint(image.dtype)\nprint(image.min())\nprint(image.max())\nprint(image.shape)\n\nplt.imshow(image)\nplt.axis('off')\nplt.show()","7c52c605":"df_train, df_val = train_test_split(df_data, test_size=0.2, random_state=101)\n\nprint(df_train.shape)\nprint(df_val.shape)","4f9e3672":"# Note the the following folder structure must be\n# located inside the yolov5 folder\n\n# base_dir\n    # images\n        # train (contains image files)\n        # validation (contains image files)\n    # labels \n        # train (contains .txt files)\n        # validation (contains .txt files)\n        \n# Yolo expects the bounding box dimensions to be\n# normalized to have values between 0 and 1.\n        \n# Label format in .txt file\n# class x-center y-center width height\n# E.g. 0 0.1 0.2 200 300\n\n# Each label is on a new line, in the .txt file:\n# 0 0.1 0.2 200 300\n# 0 0.1 0.2 200 300","612db3a6":"! pwd","a197f18a":"# change the working directory to yolov5\n#%cd yolov5\n\nos.chdir('\/kaggle\/working\/yolov5')\n\n!pwd","713b7abf":"# Create a new directory (this is happening inside the yolov5 directory)\n\nbase_dir = 'base_dir'\nos.mkdir(base_dir)\n\n\n# Now we create folders inside 'base_dir':\n\n# base_dir\n\n    # images\n        # train\n        # validation\n\n    # labels\n        # train\n        # validation\n\n# images\nimages = os.path.join(base_dir, 'images')\nos.mkdir(images)\n\n# labels\nlabels = os.path.join(base_dir, 'labels')\nos.mkdir(labels)\n\n\n\n# Inside each folder we create seperate folders for each class\n\n# create new folders inside images\ntrain = os.path.join(images, 'train')\nos.mkdir(train)\nvalidation = os.path.join(images, 'validation')\nos.mkdir(validation)\n\n\n# create new folders inside labels\ntrain = os.path.join(labels, 'train')\nos.mkdir(train)\nvalidation = os.path.join(labels, 'validation')\nos.mkdir(validation)","d3ac1d6c":"# This is the contents of the yolov5 folder\n!ls","efe0ab2b":"# check that the folders have been created\nos.listdir('base_dir\/images')","277349e4":"# Display the folder structure\n\n!tree base_dir","e2f1e8d4":"!pwd","b65635df":"# Change the working directory\n# go one level up --> back to kaggle\/working\n#%cd ..\n\nos.chdir('\/kaggle\/working\/')\n\n!pwd","cb00c531":"df_train.head()","4124ef44":"# Iterate through each row in the dataframe\n\n# We run the function below separately for\n# the train and val sets.\n# Remember that each image gets it's own text file\n# containing the info for all bboxes on that image.\n\n# For each image:\n# 1- get the info for each bounding box\n# 2- write the bounding box info to a txt file\n# 3- save the txt file in the correct folder\n# 4- copy the image to the correct folder\n\n\ndef process_data_for_yolo(df, data_type='train'):\n\n    for _, row in tq.tqdm(df.iterrows(), total=len(df)):\n        \n        image_name = row['fname']\n        bbox_list = row['bbox']\n        \n        image_width = row['width']\n        image_height = row['height']\n \n        \n        # Convert into the Yolo input format\n        # ...................................\n        \n\n        yolo_data = []\n        \n        # row by row\n        for coord_dict in bbox_list:\n\n            xmin = int(coord_dict['xmin'])\n            ymin = int(coord_dict['ymin'])\n            xmax = int(coord_dict['xmax'])\n            ymax = int(coord_dict['ymax'])\n            \n            # We only have one class i.e. balloon.\n            # We will set the class_id to 0 for all images.\n            # Class numbers must start from 0.\n            class_id = 0\n            \n            bbox_h = int(ymax - ymin)\n            bbox_w = int(xmax - xmin)\n\n            x_center = xmin + (bbox_w\/2)\n            y_center = ymin + (bbox_h\/2)\n            \n\n            # Normalize\n            # Yolo expects the dimensions to be normalized i.e.\n            # all values between 0 and 1.\n\n            x_center = x_center\/image_width\n            y_center = y_center\/image_height\n            bbox_w = bbox_w\/image_width\n            bbox_h = bbox_h\/image_height\n\n            # [class_id, x-center, y-center, width, height]\n            yolo_list = [class_id, x_center, y_center, bbox_w, bbox_h]\n\n            yolo_data.append(yolo_list)\n\n        # convert to nump array\n        yolo_data = np.array(yolo_data)\n\n\n        # save the text file\n        image_id = image_name.split('.')[0]\n        np.savetxt(os.path.join('yolov5\/base_dir', \n                    f\"labels\/{data_type}\/{image_id}.txt\"),\n                    yolo_data, \n                    fmt=[\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"]\n                    ) # fmt means format the columns\n\n        # Copy the image to images\n        shutil.copyfile(\n            os.path.join(base_path, f\"images\/{image_name}\"),\n            os.path.join('yolov5\/base_dir', f\"images\/{data_type}\/{image_name}\")\n        )\n        \n\n# Call the function    \nprocess_data_for_yolo(df_train, data_type='train')\nprocess_data_for_yolo(df_val, data_type='validation')","81c0a2f8":"# Check that the files have been created\n\nprint(len(os.listdir('yolov5\/base_dir\/images\/train')))\nprint(len(os.listdir('yolov5\/base_dir\/images\/validation')))\n\nprint(len(os.listdir('yolov5\/base_dir\/labels\/train')))\nprint(len(os.listdir('yolov5\/base_dir\/labels\/validation')))","59906bc6":"text_file_list = os.listdir('yolov5\/base_dir\/labels\/train')\n\ntext_file = text_file_list[0]\n\ntext_file","3dcb4914":"# Display the contents of a text file\n\n! cat 'yolov5\/base_dir\/labels\/train\/155815494_800fc9aa32_b.txt'","0030ddf7":"# List the images in the train folder\n\n#os.listdir('yolov5\/base_dir\/images\/train')","a141c7fb":"# Ref:\n# Reading and Writing YAML to a File in Python\n# https:\/\/stackabuse.com\/reading-and-writing-yaml-to-a-file-in-python","1b86a454":"yaml_dict = {'train': 'base_dir\/images\/train',   # path to the train folder\n            'val': 'base_dir\/images\/validation', # path to the val folder\n            'nc': 1,                             # number of classes\n            'names': ['balloon']}                # list of label names","c53cffad":"# Create the yaml file called my_data.yaml\n# We will save this file inside the yolov5 folder.\n\nimport yaml\n\nwith open(r'yolov5\/my_data.yaml', 'w') as file:\n    documents = yaml.dump(yaml_dict, file)","b4e8f1b3":"# Check that the my_data.yaml file is in the yolov5 folder.\n# It should appear in the list of files.\n\nos.listdir('yolov5')","b506a368":"# Display the contents of the yaml file\n\n! cat 'yolov5\/my_data.yaml'","831af7be":"# change the working directory to yolov5\n#%cd yolov5\n\nos.chdir('\/kaggle\/working\/yolov5')\n\n!pwd","b70bd41c":"# Make a prediction.\n# Note that we are typing on the command line.\n# The exclamation mark (!) allows command line instructions\n# to be issued from a notebook cell.\n\n# Make a prediction\n!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data\/images\/ --save-txt --save-conf --exist-ok\n\n# Display the predicted image.\n# Yolo draws the predicted bounding boxes onto the image.\nImage(filename='runs\/detect\/exp\/zidane.jpg', width=600)","6478dc15":"os.listdir('runs\/detect\/exp\/labels\/')","9dd9d374":"# These are the predicted bounding box coords and their confidence scores.\n# The results are in a txt file - one txt file per test image.\n# Because we used --exist-ok each time a prediction is made\n# the results get appended to the same text file (not overwritten).\n\n# Next we will see how to put this info into a dataframe.\n# Format: [class, x-center, y-center, width, height, conf-score]\n\n# Display the contents of the text file.\n# The number of lines keep increasing each time you run the prediction cell above.\n!cat 'runs\/detect\/exp\/labels\/zidane.txt'","1969caef":"# get a list of detect experiments\nexp_list = os.listdir('runs\/detect\/')\n\nexp_list","50119d0a":"# How to put the bbox info from one txt file into a dataframe\n# https:\/\/stackoverflow.com\/questions\/21546739\/load-data-from-txt-with-pandas\n\npath = f'runs\/detect\/exp\/labels\/zidane.txt'\n\ncols = ['class', 'x-center', 'y-center', 'width', 'height', 'conf-score']\n\ndf = pd.read_csv(path, sep=\" \", header=None)\n\ndf.columns = cols\n\ndf.head()","c601cdb2":"# We should be inside the yolov5 folder\n!pwd","ebc1aa0b":"# What some of the parameters mean:\n\n# --weights => the pre-trained model that we are using.\n# The list of available pre-trained models can be found here:\n# https:\/\/github.com\/ultralytics\/yolov5\n\n# --save-txt => The predicted bbox coordinates get saved to a txt file. One txt file per image.\n# --save-conf => The conf score gets included in the above txt file.\n# --img => The image will be resized to this size before creating the mosaic.\n# --conf => The confidence threshold\n# --rect => Means don't use mosaic augmentation during training\n# --name => Give a model a name e.g. --name my_model\n# --batch => batch size\n# --epochs => number of training epochs\n# --data => the yaml file path\n# --exist-ok => do not increment the project names with each run i.e. don't change exp to epx2, exp3 etc.\n# --nosave => do not save the images\/videos (helpful when deploying to a server)\n\n# It's helpful to review the source code in detect.py to know what the above parameters mean.\n# detect.py is located inside the yolov5 folder.","31ba6997":"# If you uncomment and run this line you will get a request to enter a \n# wandb password. To solve this problem we include WANDB_MODE=\"dryrun\" in\n# the next line.\n#! python train.py --img 1024 --batch 8 --epochs 2 --data my_data.yaml --cfg models\/yolov5s.yaml --name wheatmodel\n\n# Without using pre-trained weights\n#!WANDB_MODE=\"dryrun\" python train.py --img 1024 --batch 24 --epochs 10 --data my_data.yaml --cfg models\/yolov5s.yaml --name my_model\n\n# Using pre-trained weights and image cache i.e. loading all images into RAM\n#!WANDB_MODE=\"dryrun\" python train.py --img 1024 --batch 24 --epochs 10 --data my_data.yaml --weights yolov5s.pt --cache\n\n# Not caching images\n!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 200 --data my_data.yaml --weights yolov5s.pt","acb47265":"# Create the custom file\n\n# Ref:\n# Reading and Writing YAML to a File in Python\n# https:\/\/stackabuse.com\/reading-and-writing-yaml-to-a-file-in-python\n\n\nyaml_dict = {\n    \n'lr0': 0.01,  # initial learning rate (SGD=1E-2, Adam=1E-3)\n'lrf': 0.032,  # final OneCycleLR learning rate (lr0 * lrf)\n'momentum': 0.937,  # SGD momentum\/Adam beta1\n'weight_decay': 0.0005,  # optimizer weight decay 5e-4\n'warmup_epochs': 3.0,  # warmup epochs (fractions ok)\n'warmup_momentum': 0.8,  # warmup initial momentum\n'warmup_bias_lr': 0.1,  # warmup initial bias lr\n'box': 0.1,  # box loss gain\n'cls': 1.0,  # cls loss gain\n'cls_pw': 0.5,  # cls BCELoss positive_weight\n'obj': 2.0,  # obj loss gain (scale with pixels)\n'obj_pw': 0.5,  # obj BCELoss positive_weight\n'iou_t': 0.20,  # IoU training threshold\n'anchor_t': 4.0,  # anchor-multiple threshold\n'anchors': 0,  # anchors per output layer (0 to ignore)\n'fl_gamma': 0.0,  # focal loss gamma (efficientDet default gamma=1.5)\n'hsv_h': 0,  # image HSV-Hue augmentation (fraction)\n'hsv_s': 0,  # image HSV-Saturation augmentation (fraction)\n'hsv_v': 0,  # image HSV-Value augmentation (fraction)\n'degrees': 0,  # image rotation (+\/- deg)\n'translate': 0.2,  # image translation (+\/- fraction)\n'scale': 0.3,  # image scale (+\/- gain)\n'shear': 0.0,  # image shear (+\/- deg)\n'perspective': 0.0,  # image perspective (+\/- fraction), range 0-0.001\n'flipud': 0,  # image flip up-down (probability)\n'fliplr': 0.5,  # image flip left-right (probability)\n'mosaic': 1.0,  # image mosaic (probability)\n'mixup': 0.0  # image mixup (probability)\n    \n}\n\n\n# Create the yaml file called my_hyp.yaml\n# We will save this file inside the yolov5 folder.\n\n# change the working directory to yolov5\nos.chdir('\/kaggle\/working')\n\nimport yaml\n\nwith open(r'yolov5\/my_hyp.yaml', 'w') as file:\n    documents = yaml.dump(yaml_dict, file)\n    ","face64c2":"# Train the model\n\n# Add the --hyp parameter with the path to the custom file.\n\n# !WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 200 --data my_data.yaml --hyp my_hyp.yaml --weights yolov5s.pt","85a82085":"# change the working directory to yolov5\nos.chdir('\/kaggle\/working\/yolov5')\n\n!pwd","e1b736d5":"os.listdir('runs\/train\/')","4dd41b41":"# get a list of experiments\nexp_list = os.listdir('runs\/train\/')\n\nexp_list","699e0075":"# Get the latest exp.\n# I found that the first item in the list is the latest experiment. Not\n# the last item as one would normally expect.\nexp = exp_list[0]\n\nexp","50c8c494":"# Display the contents of the \"exp\" folder\nos.listdir(f'runs\/train\/{exp}')","59eac287":"# Display the contents of the \"exp\" folder\nos.listdir(f'runs\/train\/{exp}')","35038590":"# change the working directory to yolov5\n\nos.chdir('\/kaggle\/working\/yolov5')\n\n!pwd","71e0ff75":"plt.figure(figsize = (15, 15))\nplt.imshow(plt.imread(f'runs\/train\/{exp}\/results.png'))","0d4bfeb3":"# Display the contents of the results.txt file\n\npath = f'runs\/train\/{exp}\/results.txt'\n\n!cat $path","6c49a37c":"# Read the results from the training log: results.txt\n\n# https:\/\/stackoverflow.com\/questions\/3277503\/how-to-read-a-file-line-by-line-into-a-list\n# https:\/\/stackoverflow.com\/questions\/65381312\/how-to-convert-a-yolo-darknet-format-into-csv-file\n\n\nfilename = f'runs\/train\/{exp}\/results.txt'\n\nfile_list = []\n\nwith open(filename) as f:\n    # read a line into a list, format: ['item item item', 'item item item', ...]\n    file_line_list = f.readlines()\n    \n    \nfor i in range(0, len(file_line_list)):\n    \n    # Get the first item in the list and split on the spaces.\n    # This returns a list of all items in the line: ['item', 'item', 'item']\n    line_list = file_line_list[i].split()\n    \n    # remove whitespace characters like `\\n` at the end of each line\n    line_list = [x.strip() for x in line_list]\n    \n    # Save the list.\n    # all_lines_list is a list of lists\n    file_list.append(line_list)\n    \nlen(file_list)","825c04ba":"# Put the file data into a dataframe\n\ndf = pd.DataFrame(file_list)\n\ndf.head(10)","bd876b41":"# choose only the columns we want\n\ncol_names = ['epoch', 'P', 'R', 'map0.5', 'map0.5:0.95']\n\n# filter out specific columns\ndf_results = df[[0, 8, 9, 10, 11]]\n\ndf_results.columns = col_names\n\n# change the column names\ndf_results.head(10)","e2fa4583":"# Get the best map0.5\n\nbest_map = df_results['map0.5'].max()\n\nprint('---------------------')\n\nprint('Best map0.5:', best_map)\nprint()\n\n# print the row that contains the best map0.5\ndf = df_results[df_results['map0.5'] == best_map]\n\nprint(df.head())\n\nprint('---------------------')","4cc03173":"# Train\n# One mosaic batch of train images with labels\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread(f'runs\/train\/{exp}\/train_batch0.jpg'))","4f93b7c6":"# BATCH 0 - TRUE BBOXES\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread(f'runs\/train\/{exp}\/test_batch0_labels.jpg'))","e2521082":"# BATCH 0 - PREDICTED BBOXES\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread(f'runs\/train\/{exp}\/test_batch0_pred.jpg'))","423c1097":"!pwd","fd860ed3":"# From the printout at the end of the training. It tells us where\n# the weights for the last model and the weights for the best model are stored:\n\n# Example:\n# Optimizer stripped from runs\/train\/exp2\/weights\/last.pt, 14.5MB\n# Optimizer stripped from runs\/train\/exp2\/weights\/best.pt, 14.5MB\n\n# Display the contents of the \"weights\" folder.\n# You will see the weights of the best model and the last model.\nos.listdir(f'runs\/train\/{exp}\/weights')","3776c27c":"# change the working directory to yolov5\n#%cd yolov5","f025cc6c":"!ls","2f94b3cb":"# Make a prediction on the test images\n\n# Note if we had test images, the absolute path to the folder containing the\n# test images can be set as follows:\n# '\/kaggle\/input\/global-wheat-detection\/test'\n# (note it's \/kaggle\/input\/ and not \/kaggle\/working\/)\n\n# Adding --save-txt means that after prediction each image will have a txt file with bounding box info.\n# https:\/\/github.com\/ultralytics\/yolov5\/issues\/388\n# --save-conf means that we will also save the confidence scores for each bounding box.\n\n# Here we are just making a prediction on images that are inside the 'images' folder.\n# This is just a demo. Change the path to point to your test images.\n# Note that we are using --save-txt and --save-conf because we want to save the \n# predicted bounding box coordinates and confidence scores.\n!python detect.py --source '\/kaggle\/input\/v2-balloon-detection-dataset\/images' --weights 'runs\/train\/exp\/weights\/best.pt' --img 640 --save-txt --save-conf --exist-ok","19135a2d":"# get a list of detect experiments\nexp_list = os.listdir('runs\/detect\/')\n\n#latest_index = len(exp_list) - 1\n\n# Get the latest experiment\n\n# ** NOTE: Here the latest experiment is sometimes the last element in the list and\n# sometimes it's the first element in the list. Could be a bug. **\n# This is not the same as for training experiments.\ndetect_exp = exp_list[0]\n\ndetect_exp","3cf077d0":"exp_list","ba8103d0":"# How to display the contents of a predicted txt file\n\n# Example:\n# ! cat 'runs\/detect\/exp2\/labels\/cc3532ff6.txt'","231e6959":"# These are the predicted images with the bboxes already drawn in:\n\n# os.listdir(f'runs\/detect\/{detect_exp}')","b69f933b":"pred_list = os.listdir(f'runs\/detect\/{detect_exp}')\n\nimage_id = pred_list[3]\n\npath = f'runs\/detect\/{detect_exp}\/' + image_id\nimage = plt.imread(path)\n\nplt.imshow(image)","c07c2db5":"# change the working directory to yolov5\n#%cd yolov5\n\nos.chdir('\/kaggle\/working\/yolov5')\n\n!pwd","04560737":"# Delete the folder to prevent a Kaggle error.\n\nif os.path.isdir('base_dir') == True:\n    shutil.rmtree('base_dir')\n    ","03432763":"# Check that base_dir is no longer in the yolov5 folder\n\nos.listdir('\/kaggle\/working\/yolov5')","fcde06bf":"## How to put the predictions into a dataframe","fe96984a":"## How to use yolov5 offline\n\nIn some Kaggle competitions the internet cannot be on during inference. In those cases it helps to know how to use Yolov5 offline. \n\nI have included a yolov5 folder in the v2-balloon-detection-dataset. To use yolov5 offline first comment out all the lines in the cell above. Then uncomment and run the cell below. It will work even if the internet is off. \n\nInstalling requirements.txt is not essential on Kaggle.","062f08c5":"## Introduction\n\nThese are some of the questions that this notebook will answer:\n\n- What does the step by step Yolo v5 workflow look like?<br>\n- What format does the input data need to have?<br>\n- How do you load a trained model and make a prediction?<br>\n\nA few things to keep in mind:\n- Yolo v5 uses mosaic augmentation by default during training (probability = 1). Please scroll down to the end of this notebook to see a batch of mosaic training images. Also, refer to the section on using custom training settings to see how the probability of doing mosaic augmentation can be set.\n- We will be changing the working directory as we move in and out of the yolov5 folder. It's helpful to understand how the command line is used to cd into a directory and to print the working directory.\n- One thing I found confusing is that the results of each training (and inference) run are stored in a different folder e.g. exp, exp2 etc. Therefore, when displaying or retrieving predictions it's important to make sure that you are getting the preds for the latest experiment. If you print a list of train experiments you will find that the latest experiment is the first element in the list. But,when I printed a list of prediction (detect) experiments I found that the latest experiment is sometimes the last element in the list and sometimes it's the first element in the list. To prevent this confusion use the --exist-ok parameter. This tells Yolo not to increment the experiment names. Each run will always be named exp. But keep in mind that if you use --exist-ok then the results of every run are appended to the same text file i.e. the results already in the text file are not overwritten by the results from the latest run.","07217ed2":"**1- Do I need to resize images for Yolo?**<br>\nNo. We give Yolo the original image sizes and the original bounding box sizes. Yolo does the resizing automatically. During training and inference we specify the --img parameter.<br>\n\nThis quote explains what the --img parameter does:<br>\n\n*python train.py --img 640 means that the mosaic dataloader pulls up the selected image along with 3 random images, resizes them all to 640, joins all 4 at the seams into a 1280x1280 mosaic, augments them, and then crops a center 640x640 area for placement as 1 image into the batch.*<br>\nhttps:\/\/github.com\/ultralytics\/yolov5\/issues\/46\n\n**2- If the image does not contain any objects do I need to create a txt file for that image?**<br>\nQuote:\n*if no objects in image, no *.txt file is required*<br>\nhttps:\/\/github.com\/ultralytics\/yolov5\/wiki\/Train-Custom-Data\n\n**3- How can I train Yolo without applying the default mosaic augmentation?**<br>\nQuote:\n*you can use train.py --rect to omit mosaic, and you can set any image augmentation hyps you want in the data\/hyps files.*<br>\nhttps:\/\/github.com\/ultralytics\/yolov5\/issues\/700\n\n**4- How do I change the training and augmentation hyperparameters?**<br>\nQuote: \nhttps:\/\/github.com\/ultralytics\/yolov5\/issues\/607#issuecomment-680685682\n- data\/hyp.scratch.yaml will be automatically used by python train.py --weights ''<br>\n- data\/hyp.finetune.yaml will be automatically used by python train.py --weights yolov5s.pt<br>\n- hyp.custom.yaml can be force-selected by python train.py --hyp hyp.custom.yaml<br>\n\n\nThis notebook, by Alien, shows how to use custom hyperparameters:<br>\nhttps:\/\/www.kaggle.com\/h053473666\/siim-cov19-yolov5-train\n\nYou can find the hyps files inside the yolov5 folder: yolov5\/data\/hyps","b3cedfb5":"## Get the name of the last experiment","98d46d42":"## Create train and val data","1e3f3b8f":"## Display the training curves\n\nFrom these curves you will be able to see at which epoch the model started to overfit.","f87494e1":"## Process the data\n\nHere we will write a function to process the training and validation data. \n\nWe need to create a separate txt file for each image that contains the details of all the bounding boxes on that image.  This function will also move the training and val data into the directory structure that we created above. We won't need to do any image resizing for Yolo. It will do that automatically during training.","57c44d0b":"## Delete base_dir to prevent a Kaggle error\n\nIf there are too many files in this notebook's output then the notebook commit may fail. That's why we need to delete the base_dir folder.","1f6d0650":"## How to train using custom augmentation and hyperparameter settings\n\nBy default Yolo uses the augmentation and hyperparameter settings in this file during training: hyp=data\/hyps\/hyp.scratch.yaml\n\nTo train with custom settings we need to create a custom hyp yaml file and then set the --hyp parameter before training. --hyp is the path to the custom file that we created.","f3b661e0":"## Create the Yolo directory structure\n\nWe need to create a directory structure inside the yolov5 folder. This is where the training and validation data will need to be stored.","a2b8ab78":"# Review the training results\n\n**Please look at the list of files in the output of the the above cell.**\n\n- Yolo stores all the training curves as one png file. To view the training curves we need to display the png file.\n\n- **IMPORTANT NOTE:** The summary displayed at the end of training shows the resuts for the LAST epoch. This is not the results for the BEST epoch. The results for each epoch are logged in a file called results.txt. We will load that file into a pandas dataframe and then get the best epoch and the best mAP score.\n\n- Yolo also stores png images showing the true and predicted labels for each val batch. In these images the true and predicted bounding boxes are drawn in. One batch is shown on one image.\n\nThere's more results info available. The yolov5 folder will appear in the output of this notebook. I suggest that you download it and look at the contents of the yolov5\/runs\/train\/exp folder.","34776102":"## References and Resources\n\nThese are a few good resources that helped me understand how to use Yolo. I suggest that you start by watching the video tutorial by Abishek Thakur.\n\nTrain custom object detection model with YOLO V5<br>\nAbishek Thakur<br>\nhttps:\/\/www.youtube.com\/watch?v=NU9Xr_NYslo\n\nNotebook explaining yolo by Awsaf<br>\nhttps:\/\/www.kaggle.com\/awsaf49\/vinbigdata-cxr-ad-yolov5-14-class-train\/data?select=yolov5\n\nYolo v5 training notebook by Alien<br>\nhttps:\/\/www.kaggle.com\/h053473666\/siim-cov19-yolov5-train\n\nYolo v5 inference notebook by Alien<br>\nhttps:\/\/www.kaggle.com\/h053473666\/siim-cov19-efnb7-yolov5-infer\n\nUltralytics GitHub<br>\nhttps:\/\/github.com\/ultralytics\/yolov5\n\nUltralytics Yolo getting started tutorial<br>\nhttps:\/\/github.com\/ultralytics\/yolov5\/wiki\/Train-Custom-Data\n\nUltralytics notebook<br>\nhttps:\/\/github.com\/ultralytics\/yolov5\/blob\/master\/tutorial.ipynb","0e1de96d":"## Conclusion\n\nThank you for reading.","679bc75d":"#### I followed the following steps to get the yolov5 folder used in the above cell:<br>\n\n1- Create a new notebook<br>\n2- Place the following line of code in that notebook to clone the repo. The yolov5 folder will download into the notebook.<br>\n\n!git clone https:\/\/github.com\/ultralytics\/yolov5.git  \n\n3- Commit the notebook. The yolov5 folder will be saved in the notebook's output.<br>\n4- I downloaded the yolov5 folder from the output of the committed notebook to my local computer.<br>\n5- I then uploaded the yolov5 folder to the v2-balloon-detection-dataset. When uploading to a dataset, don't allow the system to 'skip duplicates'. Click on the right portion of the button and select 'include duplicates'. Also, if you upload a zipped yolov5 folder then the kaggle dataset system will create a yolov5 folder within another yolov5 folder. In that case you will need to correct some of the paths below in order for the code to work.","fbd6a73c":"## Display one image with bounding boxes","5d375d54":"## Get the best mAP and best epoch\n\nHere we will read the results.txt file and put the results into a dataframe. We will then filter this dataframe to find the max map0.5 value.","a9886f25":"## Train the model","2afde9bf":"## Where is the trained model saved?","3eb87b7b":"#### Basics of Yolo v5 - Balloon detection\nby @vbookshelf<br>\n29 June 2021","f07a159a":"## Load the data","a565ec8c":"## How to do inference","8826d909":"## Make a prediction on an existing image\n\nThis is how to make a prediction on the popular \"Zedan\" image. This image is not from our dataset. It comes with the yolov5 folder by default.","083c4e49":"## Set up yolov5","8670e872":"## Display true and predicted val set bboxes\n\nHere we will display the true and predicted bboxes for two val batches.","1e37ce68":"## Create the yaml file\nYolo requires that we also create a yaml file inside the yolov5 folder.","34b520bd":"## Display a few images","30962f5b":"## Display one batch of train images","3c3079e2":"## Helper functions"}}