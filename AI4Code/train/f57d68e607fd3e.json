{"cell_type":{"7c8c345e":"code","2a3416af":"code","141b0696":"code","7013cad0":"code","8880ae80":"code","b9c4285e":"code","df65895a":"code","b674c8b7":"code","fc3b1c7a":"code","d8ade647":"code","2b34421a":"code","9e1d1553":"markdown","3e17faf9":"markdown","d8f7d180":"markdown","d7f584f9":"markdown","2e142e84":"markdown","2958a1c6":"markdown","b1b272dc":"markdown"},"source":{"7c8c345e":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport ast\nimport os\nimport json\nimport pandas as pd\nimport torch\nimport importlib\nimport cv2 \n\nfrom shutil import copyfile\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nfrom sklearn.model_selection import GroupKFold\n\nTRAIN_PATH = '\/kaggle\/input\/tensorflow-great-barrier-reef'","2a3416af":"df = pd.read_csv(\"\/kaggle\/input\/tensorflow-great-barrier-reef\/train.csv\")\ndf.head(5)","141b0696":"def get_bbox(annots):\n    # get bbox corrdinates only by using anno.values() in annotations dict\n    # since the values are string type, we need to convert to list\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_img_path(row):\n    # \/kaggle\/input\/tensorflow-great-barrier-reef\/train_images\/video_2\/16.jpg\n    row['image_path'] = f'{TRAIN_PATH}\/train_images\/video_{row.video_id}\/{row.video_frame}.jpg'\n    return row ","7013cad0":"# Taken only annotated photos and add in num_bbox column in df\ndf[\"num_bbox\"] = df['annotations'].apply(lambda x: str.count(x, 'x'))\n\n# to make sure num_bbox in each row is greater than 0 and greate df_train\ndf_train = df[df[\"num_bbox\"]>0]\n\n# change annotations str type to list and add bboxes values in df \ndf_train['annotations'] = df_train['annotations'].progress_apply(lambda x: ast.literal_eval(x))\ndf_train['bboxes'] = df_train.annotations.progress_apply(get_bbox)\n\n# add image resoultuion column in dataframe\ndf_train[\"width\"] = 1280\ndf_train[\"height\"] = 720\n\n# add image path in dataframe\ndf_train = df_train.progress_apply(get_img_path, axis=1)","8880ae80":"kf = GroupKFold(n_splits = 5)\ndf_train = df_train.reset_index(drop=True)\ndf_train['fold'] = -1\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(df_train, y=df_train.video_id.tolist(), groups=df_train.sequence)):\n    df_train.loc[val_idx, 'fold'] = fold\n    \ndf_train.head(5)","b9c4285e":"HOME_DIR = '\/kaggle\/working\/'\nDATASET_PATH = 'dataset\/COTS-COCO'\n\n!mkdir {HOME_DIR}dataset\n!mkdir {HOME_DIR}{DATASET_PATH}\n!mkdir {HOME_DIR}{DATASET_PATH}\/images\n!mkdir {HOME_DIR}{DATASET_PATH}\/images\/train2017\n!mkdir {HOME_DIR}{DATASET_PATH}\/images\/val2017\n!mkdir {HOME_DIR}{DATASET_PATH}\/annotations","df65895a":"SELECTED_FOLD = 4\n# fold 1,2,3,5 --> train\n# fold 4 --> val\n\nfor i in tqdm(range(len(df_train))):\n    \n    row = df_train.loc[i]\n    \n    if row.fold != SELECTED_FOLD: # train\n        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}\/images\/train2017\/{row.image_id}.jpg')\n    \n    elif row.fold == SELECTED_FOLD: # val\n        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}\/images\/val2017\/{row.image_id}.jpg')","b674c8b7":"print(f'Number of training files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}\/images\/train2017\/\"))}')\nprint(f'Number of validation files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}\/images\/val2017\/\"))}')","fc3b1c7a":"def save_annot_json(annotation_dict, fname):\n    with open(fname, 'w') as f:\n        output_json = json.dumps(annotation_dict)\n        f.write(output_json)","d8ade647":"annotation_id = 0\nfrom datetime import datetime\n\ndef dataset_to_coco(df):\n        \n    global annotation_id\n    \n    annotations_json = {\n        \"info\": [],\n        \"licenses\": [],\n        \"categories\": [],\n        \"images\": [],\n        \"annotations\": []\n    }\n    \n    info = {\n        \"year\": \"2021\",\n        \"version\": \"1\",\n        \"description\": \"COTS dataset - COCO format\",\n        \"contributor\": \"\",\n        \"url\": \"https:\/\/www.kaggle.com\/c\/tensorflow-great-barrier-reef\/overview\",\n        \"date_created\": str(datetime.now())\n    }\n    annotations_json[\"info\"].append(info)\n    \n    lic = {\n            \"id\": 1,\n            \"url\": \"https:\/\/www.kaggle.com\/c\/tensorflow-great-barrier-reef\/rules\",\n            \"name\": \"Unknown\"\n        }\n    annotations_json[\"licenses\"].append(lic)\n\n    classes = {\"id\": 0, \"name\": \"starfish\", \"supercategory\": \"none\"}\n\n    annotations_json[\"categories\"].append(classes)\n\n    \n    for ann_row in df.itertuples():\n            \n        images = {\n            \"id\": ann_row[0],\n            \"license\": 1,\n            \"file_name\": ann_row.image_id + '.jpg',\n            \"height\": ann_row.height,\n            \"width\": ann_row.width,\n            \"date_captured\": str(datetime.now())\n        }\n        \n        annotations_json[\"images\"].append(images)\n        \n        bbox_list = ann_row.bboxes\n        \n        for bbox in bbox_list:\n            b_width = bbox[2]\n            b_height = bbox[3]\n            \n            # some boxes in COTS are outside the image height and width\n            if (bbox[0] + bbox[2] > 1280):\n                b_width = bbox[0] - 1280 \n            if (bbox[1] + bbox[3] > 720):\n                b_height = bbox[1] - 720 \n                \n            image_annotations = {\n                \"id\": annotation_id,\n                \"image_id\": ann_row[0],\n                \"category_id\": 0,\n                \"bbox\": [bbox[0], bbox[1], b_width, b_height],\n                \"area\": bbox[2] * bbox[3],\n                \"segmentation\": [],\n                \"iscrowd\": 0\n            }\n            \n            annotation_id += 1\n            annotations_json[\"annotations\"].append(image_annotations)\n        \n        \n    print(f\"Dataset COTS annotation to COCO json format completed! Files: {len(df)}\")\n    return annotations_json","2b34421a":"# fold 1,2,3,5\ntrain_df = df_train[df_train.fold != SELECTED_FOLD]\ntrain_coco_dict = dataset_to_coco(df=train_df)\ntrain_json_path = f'{HOME_DIR}{DATASET_PATH}\/annotations\/train.json'\nsave_annot_json(annotation_dict=train_coco_dict, fname=train_json_path)\n\n\n# fold 4\nval_df = df_train[df_train.fold == SELECTED_FOLD]\nval_coco_dict = dataset_to_coco(df=val_df)\nval_json_path = f'{HOME_DIR}{DATASET_PATH}\/annotations\/val.json'\nsave_annot_json(annotation_dict=val_coco_dict, fname=val_json_path)","9e1d1553":"# Import libraries","3e17faf9":"# Save coco json annotation file","d8f7d180":"# Add no of bbox, bbox values, image resolution and image path in new dataframe","d7f584f9":"# Split train and val depending on fold id","2e142e84":"# GroupK Folding (5 folds)","2958a1c6":"# Convert to COCO Json for annotations","b1b272dc":"# Ref: https:\/\/www.kaggle.com\/remekkinas\/yolox-training-pipeline-cots-dataset-lb-0-507"}}