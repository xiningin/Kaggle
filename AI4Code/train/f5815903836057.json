{"cell_type":{"c9b22b63":"code","45a9a45a":"code","694bea6b":"code","51b07ef0":"code","581dcd55":"code","b781a1c2":"code","cdd1a8bc":"code","cab4e318":"code","ae367d8d":"code","19f01a4d":"code","7b1c9068":"code","facb4340":"code","da435f78":"code","60db099c":"code","ed8f609b":"code","ad5d6b02":"code","8a996ee3":"code","c1bab5a5":"code","31ac42bc":"code","272b8d45":"code","86e1b903":"markdown","55ffe309":"markdown","e256affe":"markdown","cd4c109e":"markdown","ed50a4fa":"markdown","fb2d3a16":"markdown","6854f8a8":"markdown","bfd1eb33":"markdown","06c1cab3":"markdown","9ad611f4":"markdown"},"source":{"c9b22b63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as tkr\nimport seaborn as sns\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","45a9a45a":"# import prices\n\nprices=pd.read_csv('\/kaggle\/input\/values-of-top-nasdaq-copanies-from-2010-to-2020\/CompanyValues.csv')\n# format date\nprices['day_date'] = pd.to_datetime(prices['day_date'], format=\"%Y-%m-%d\").dt.date.astype('datetime64[ns]')\nprices=prices.sort_values(by=['day_date']).reset_index()\n# rename date column for consistency\nprices=prices.rename(columns={\"day_date\": \"date\"})\n\ndef create_indicators(data):\n    \n    prices = data.sort_values(by=['date']).reset_index()\n\n    # create simple moving average\n    n=[10,20,50,100]\n    for i in n:\n        prices.loc[:,(str(\"MA\"+str(i)))]=prices['close_value'].rolling(i).mean()    \n\n    # Calculate MACD  \n    day26=prices['close_value'].ewm(span=26, adjust=False).mean()\n    day12=prices['close_value'].ewm(span=12, adjust=False).mean()\n    prices.loc[:,('macd')]=day12-day26 \n    prices.loc[:,('signal')]=prices['macd'].ewm(span=9, adjust=False).mean()\n\n    # Calculate RSI \n    up = np.log(prices.close_value).diff(1)\n    down = np.log(prices.close_value).diff(1)\n\n    up[up<0]=0\n    down[down>0]=0\n\n    # Calculate the EWMA\n    roll_up = up.ewm(span=14).mean()\n    roll_down = down.abs().ewm(span=14).mean()\n\n    # Calculate the RSI based on EWMA\n    RS1 = roll_up \/ roll_down\n    RSI1 = 100.0 - (100.0 \/ (1.0 + RS1))\n    prices.loc[:,('rsi')]=RSI1\n\n    return prices\n\n# create dict, by ticker\nd = dict(tuple(prices.groupby('ticker_symbol')))\nd = {k:create_indicators(v) for k, v in d.items()}\n\ndef subset_prices(d,ticker,start,end):\n    x=d[ticker]\n    x=x[((x.date>=start)&(x.date<=end))]\n    return x","694bea6b":"# import tweets\ntweets=pd.read_csv('\/kaggle\/input\/tweets-about-the-top-companies-from-2015-to-2020\/Tweet.csv')\ncompany_tweet=pd.read_csv('\/kaggle\/input\/tweets-about-the-top-companies-from-2015-to-2020\/Company_Tweet.csv')\n\ntweets=tweets.merge(company_tweet,how='left',on='tweet_id')\n# format dates\ntweets['date'] = pd.to_datetime(tweets['post_date'], unit='s').dt.date\ntweets.date=pd.to_datetime( tweets.date,errors='coerce')\ntweets['time'] = pd.to_datetime(tweets['post_date'], unit='s').dt.time","51b07ef0":"sia = SentimentIntensityAnalyzer()\n\ndef get_sentiment(tweets,ticker='TSLA',start='2017-01-01',end='2017-02-01'):\n    #sbuset\n    df=tweets.loc[((tweets.ticker_symbol==ticker)&(tweets.date>=start)&(tweets.date<=end))]\n    # applt the SentimentIntensityAnalyzer\n    df.loc[:,('score')]=df.loc[:,'body'].apply(lambda x: sia.polarity_scores(x)['compound'])\n    # create label\n    #bins= pd.interval_range(start=-1, freq=3, end=1)\n    df.loc[:,('label')]=pd.cut(np.array(df.loc[:,'score']),bins=[-1, -0.66, 0.32, 1],right=True ,labels=[\"bad\", \"neutral\", \"good\"])\n    \n    df=df.loc[:,[\"date\",\"score\",\"label\",\"tweet_id\",\"body\"]]\n    return df\n\nprint('tesla misses earnings, analyst suggest downgrade , sell now ')\nsia.polarity_scores('tesla misses earnings, analyst suggest downgrade , sell now ')","581dcd55":"# augment vocab\n\npositive_words='buy bull long support undervalued underpriced cheap upward rising trend moon rocket hold breakout call beat support buying holding high profit'\nnegative_words='sell bear bubble bearish short overvalued overbought overpriced expensive downward falling sold sell low put miss resistance squeeze cover seller '\n\ndictOfpos = { i : 4 for i in positive_words.split(\" \") }\ndictOfneg = { i : -4 for i in negative_words.split(\" \")  }\nFinancial_Lexicon = {**dictOfpos, **dictOfneg}\n\nsia.lexicon.update(Financial_Lexicon)\n\n\nprint('tesla misses earnings, analyst suggest downgrade , sell now ')\nsia.polarity_scores('tesla misses earnings, analyst suggest downgrade , sell now ')","b781a1c2":"## Sentiment from Price\ndef price_plot_ma(df,ax=None, **plt_kwargs):\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import matplotlib.dates as mdates\n    import matplotlib.ticker as tkr\n\n    n = df.shape[0] # number of dates\n    if ax is None:\n        ax = plt.gca()\n        \n    # format data for seaborn\n    df=df.melt(id_vars='date',var_name='var', value_name='vals')\n    df=df[df['var'].isin(['close_value','MA10','MA20','MA50','MA100'])]\n    df['vals']=df['vals'].astype(float)\n    df.index=df.date.dt.date\n    df.date=df.date.dt.date\n    # set axis formats \/ Set the locator\n    if ax is None:\n        ax = plt.gca()\n        \n    major_locator = mdates.MonthLocator()  \n    major_fmt = mdates.DateFormatter('%b')\n    minor_locator = mdates.DayLocator(interval=1) \n    minor_fmt = mdates.DateFormatter('%d')\n    ax.xaxis.set_major_locator(major_locator)\n    ax.xaxis.set_major_formatter(major_fmt)\n    ax.xaxis.set_minor_locator(minor_locator)\n    ax.grid(True, which='major',axis='both')\n    \n    if n > 750:\n        major_locator = mdates.YearLocator()   # every year and quarter\n        major_fmt = mdates.DateFormatter('%Y')\n        minor_locator =  mdates.MonthLocator()\n        minor_fmt = mdates.DateFormatter('%b')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        ax.xaxis.set_minor_locator(minor_locator)\n        ax.grid(True, which='major',axis='both')\n        \n    if((n > 250 ) & (n< 750 )):\n        major_locator = mdates.MonthLocator()   # every year and quarter\n        major_fmt = mdates.DateFormatter('%b-%Y')\n        #minor_locator =  mdates.MonthLocator()\n        #minor_fmt = mdates.DateFormatter('%b')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        #ax.xaxis.set_minor_locator(minor_locator)\n        ax.grid(True, which='major',axis='both')\n        \n    if ((n > 90 ) & (n< 250 )):\n        major_locator = mdates.MonthLocator()   # every  month\n        major_fmt = mdates.DateFormatter('%b-%y')\n        minor_locator = tkr.AutoMinorLocator(4)\n        minor_fmt = mdates.DateFormatter('%d-%m')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        ax.xaxis.set_minor_locator(minor_locator)\n        #ax.xaxis.set_minor_formatter(minor_fmt)\n        ax.grid(True, which='major',axis='both')\n        \n    \n\n        \n    ax.set_ylabel('Close Price')\n    ax.set_xlabel('Date')\n    ax.tick_params(axis='x', labelrotation = 45)\n    ax.yaxis.set_major_formatter(tkr.FuncFormatter(lambda x, p: format(int(x), ',')))\n    sns.lineplot(data=df, x='date', y='vals',hue='var',palette='cool_r',ax=ax)\n    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),fancybox=True, shadow=True)\n    return ax\n","cdd1a8bc":"def price_plot_vol(df,ax=None, **plt_kwargs):\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import matplotlib.dates as mdates\n    import matplotlib.ticker as tkr\n    \n    n=df.shape[0]\n    \n    df.index=df.date.dt.date\n    if ax is None:\n        ax = plt.gca()\n    \n    major_locator = mdates.MonthLocator()  \n    major_fmt = mdates.DateFormatter('%b')\n    minor_locator = mdates.DayLocator(interval=1) \n    minor_fmt = mdates.DateFormatter('%d')\n    ax.xaxis.set_major_locator(major_locator)\n    ax.xaxis.set_major_formatter(major_fmt)\n    ax.xaxis.set_minor_locator(minor_locator)\n    ax.grid(True, which='major',axis='both')\n    \n    if n > 750:\n        major_locator = mdates.YearLocator()   # every year and quarter\n        major_fmt = mdates.DateFormatter('%Y')\n        minor_locator =  mdates.MonthLocator()\n        minor_fmt = mdates.DateFormatter('%b')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        ax.xaxis.set_minor_locator(minor_locator)\n        ax.grid(True, which='major',axis='both')\n        \n    if((n > 250 ) & (n< 750 )):\n        major_locator = mdates.MonthLocator()   # every year and quarter\n        major_fmt = mdates.DateFormatter('%b-%Y')\n        #minor_locator =  mdates.MonthLocator()\n        #minor_fmt = mdates.DateFormatter('%b')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        #ax.xaxis.set_minor_locator(minor_locator)\n        ax.grid(True, which='major',axis='both')\n        \n    if ((n > 90 ) & (n< 250 )):\n        major_locator = mdates.MonthLocator()   # every  month\n        major_fmt = mdates.DateFormatter('%b-%y')\n        minor_locator = tkr.AutoMinorLocator(4)\n        minor_fmt = mdates.DateFormatter('%d-%m')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        ax.xaxis.set_minor_locator(minor_locator)\n        #ax.xaxis.set_minor_formatter(minor_fmt)\n        ax.grid(True, which='major',axis='both')\n        \n    \n    ax.set_ylabel('Traded Volume (million)')\n    ax.set_xlabel('Date')\n    ax.tick_params(axis='x', labelrotation = 45)\n    ax.yaxis.set_major_formatter(tkr.FuncFormatter(lambda x, p: format(int(x\/1000000), ',')))\n    sns.lineplot(data=df, x='date', y='volume',palette='cool_r',ax=ax)\n\n    return ax","cab4e318":"def sentiment_barplot(df,ax=None, **plt_kwargs):\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import matplotlib.dates as mdates\n    import matplotlib.ticker as tkr\n    \n    df=df.groupby(['date','label'])['tweet_id'].agg('count').reset_index(name=\"count\")\n    \n    n=len(df.date.unique())\n    \n    # format the data and make proportion\n    df=df.pivot(index='date',columns='label',values='count')\n    df=pd.DataFrame(df.to_records()).reset_index()\n    df.loc[:,\"total\"]=df.loc[:,['bad','neutral','good']].sum(axis=1)\n    df.loc[:,['bad','neutral','good']]=df.loc[:,['bad','neutral','good']].div(df.total,axis=0)\n    df.loc[:,\"total\"]=df.loc[:,['bad','neutral','good']].sum(axis=1)\n    df=df.drop(['total'], axis=1)\n   \n    df.index=df.date.dt.date\n    if ax is None:\n        ax = plt.gca()\n    colors=['crimson','lightgrey','mediumseagreen']\n    df.loc[:,['bad','neutral', 'good']].plot.bar(stacked=True, color=colors, width=1.0,alpha=0.5,ax=ax)\n    \n   \n    # set axis formats \/ Set the locato\n    \n    major_locator = mdates.MonthLocator()  \n    major_fmt = mdates.DateFormatter('%b')\n    minor_locator = mdates.DayLocator(interval=1) \n    minor_fmt = mdates.DateFormatter('%d')\n    ax.xaxis.set_major_locator(major_locator)\n    ax.xaxis.set_major_formatter(major_fmt)\n    ax.xaxis.set_minor_locator(minor_locator)\n    ax.grid(True, which='major',axis='both')\n    \n    if n > 750:\n        major_locator = mdates.YearLocator()   # every year and quarter\n        major_fmt = mdates.DateFormatter('%Y')\n        minor_locator =  mdates.MonthLocator()\n        minor_fmt = mdates.DateFormatter('%b')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        ax.xaxis.set_minor_locator(minor_locator)\n        ax.grid(True, which='major',axis='both')\n        \n    if((n > 250 ) & (n< 750 )):\n        major_locator = mdates.MonthLocator()   # every year and quarter\n        major_fmt = mdates.DateFormatter('%b-%Y')\n        #minor_locator =  mdates.MonthLocator()\n        #minor_fmt = mdates.DateFormatter('%b')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        #ax.xaxis.set_minor_locator(minor_locator)\n        ax.grid(True, which='major',axis='both')\n        \n    if ((n > 90 ) & (n< 250 )):\n        major_locator = mdates.MonthLocator()   # every  month\n        major_fmt = mdates.DateFormatter('%b-%y')\n        minor_locator = tkr.AutoMinorLocator(4)\n        minor_fmt = mdates.DateFormatter('%d-%m')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        ax.xaxis.set_minor_locator(minor_locator)\n        #ax.xaxis.set_minor_formatter(minor_fmt)\n        ax.grid(True, which='major',axis='both')\n         \n    \n    ax.set_ylabel('Sentiment')\n    ax.set_xlabel('Date')\n    ax.tick_params(axis='x', labelrotation = 45)\n    \n    ax.grid(True, which='major',axis='both')\n    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),fancybox=True, shadow=True)\n    return ax","ae367d8d":"def sentiment_tweet_vol(df,ax=None,**kwargs):\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import matplotlib.dates as mdates\n    import matplotlib.ticker as tkr\n    df=df.groupby(['date'])['label'].agg('count').reset_index(name=\"count\")\n    df.index=df.date.dt.date\n    n=len(df.date.unique())\n    \n    if ax is None:\n        ax = plt.gca()\n    # set axis formats \/ Set the locator\n    \n    major_locator = mdates.MonthLocator()  \n    major_fmt = mdates.DateFormatter('%b')\n    minor_locator = mdates.DayLocator(interval=1) \n    minor_fmt = mdates.DateFormatter('%d')\n    ax.xaxis.set_major_locator(major_locator)\n    ax.xaxis.set_major_formatter(major_fmt)\n    ax.xaxis.set_minor_locator(minor_locator)\n    ax.grid(True, which='major',axis='both')\n    \n    if n > 750:\n        major_locator = mdates.YearLocator()   # every year and quarter\n        major_fmt = mdates.DateFormatter('%Y')\n        minor_locator =  mdates.MonthLocator()\n        minor_fmt = mdates.DateFormatter('%b')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        ax.xaxis.set_minor_locator(minor_locator)\n        ax.grid(True, which='major',axis='both')\n        \n    if((n > 250 ) & (n< 750 )):\n        major_locator = mdates.MonthLocator()   # every year and quarter\n        major_fmt = mdates.DateFormatter('%b-%Y')\n        #minor_locator =  mdates.MonthLocator()\n        #minor_fmt = mdates.DateFormatter('%b')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        #ax.xaxis.set_minor_locator(minor_locator)\n        ax.grid(True, which='major',axis='both')\n        \n    if ((n > 90 ) & (n< 250 )):\n        major_locator = mdates.MonthLocator()   # every  month\n        major_fmt = mdates.DateFormatter('%b-%y')\n        minor_locator = tkr.AutoMinorLocator(4)\n        minor_fmt = mdates.DateFormatter('%d-%m')\n        ax.xaxis.set_major_locator(major_locator)\n        ax.xaxis.set_major_formatter(major_fmt)\n        ax.xaxis.set_minor_locator(minor_locator)\n        #ax.xaxis.set_minor_formatter(minor_fmt)\n        ax.grid(True, which='major',axis='both')\n        \n    ax.set_ylabel('Tweet Volume')\n    ax.set_xlabel('Date')\n    ax.tick_params(axis='x', labelrotation = 45)\n    ax.yaxis.set_major_formatter(tkr.FuncFormatter(lambda x, p: format(int(x), ',')))\n    sns.lineplot(data=df, x='date', y='count',palette='cool_r',ax=ax)\n    \n    return ax","19f01a4d":"def corr_plot(sp,tw):\n    \n    x=tw.groupby(['date','label']).agg({\"score\":['count','mean']}).unstack('label') \n    sp=sp.reset_index(drop=True)\n    # format the data and make proportion\n    x=pd.DataFrame(x.to_records())\n    # format columns names\n    x.columns=['date','count_bad','count_neutral','count_good','score_mean_bad','score_mean_neutral','score_mean_good']\n    x.loc[:,'tweet_volume']=x.loc[:,['count_bad','count_neutral','count_good']].sum(axis=1)\n    x.loc[:,'count_ratio_gb']=x.count_good\/x.count_bad # create a ratio good:bad\n    # join price\n    x=x.merge(sp.loc[:,['date','MA10', 'MA20', 'MA50','MA100', 'macd', 'rsi','volume']],how='left',left_on='date',right_on='date')\n\n    corr = x.corr()\n    # Getting the Upper Triangle of the co-relation matrix\n    matrix = np.triu(corr)\n    ax = sns.heatmap(\n        round(corr,3),\n        vmin=-1, vmax=1, center=0,\n        cmap=\"YlGnBu\",annot=True,annot_kws={\"fontsize\":8}, fmt=\".2\",\n        square=True\n    )\n    ax.set_xticklabels(\n        ax.get_xticklabels(),\n        rotation=45,\n        horizontalalignment='right'\n    )\n    return ax","7b1c9068":"start='2015-01-01'\nend='2020-12-31'\nticker='TSLA'\n# get data\nsp=subset_prices(d,ticker,start,end) #get price info\nfig,ax=plt.subplots(figsize=(12, 8))\nfig.suptitle(ticker+ \": Price,Moving Averages\",fontsize=14,horizontalalignment='right', verticalalignment='top')\nprice_plot_ma(ax=ax,df=sp)","facb4340":"start='2018-06-01'\nend='2019-12-31'\nticker='TSLA'\n# get data\nsp=subset_prices(d,ticker,start,end) #get price info\ntw=get_sentiment(tweets,ticker,start,end) # get tweets\ngridsize = (3, 2) # 3 rows, 2 cols\nfig = plt.figure(figsize=(12, 8))\nax1 = plt.subplot2grid(gridsize, (0, 0), colspan=2, rowspan=2)\nax1.set_xlim(min(sp.date),max(sp.date))\nax2 = plt.subplot2grid(gridsize, (2, 0), colspan=2, rowspan=1)\nfig.suptitle(ticker+ \": Price,Moving Averages & Twitter Sentimet\",fontsize=14,horizontalalignment='right', verticalalignment='top')\nfig.subplots_adjust(hspace=0.4)\nprice_plot_ma(ax=ax1,df=sp)\nsentiment_barplot(ax=ax2,df=tw)","da435f78":"gridsize = (2, 2) # 2 rows, 2 cols\nfig = plt.figure(figsize=(12, 8))\nax1 = plt.subplot2grid(gridsize, (0, 0), colspan=2, rowspan=1)\nax2 = plt.subplot2grid(gridsize, (1, 0), colspan=2, rowspan=1)\nfig.suptitle(ticker+ \": Trade Volumes & Tweet Volumes\",fontsize=14,horizontalalignment='right', verticalalignment='top')\nfig.subplots_adjust(hspace=0.5)\nax1.set_xlim(min(sp.date),max(sp.date))\nax2.set_xlim(min(tw.date),max(tw.date))\nprice_plot_vol(ax=ax1, df=sp)\nsentiment_tweet_vol(ax=ax2,df=tw)","60db099c":"fig,ax = plt.subplots(figsize=(12, 8))\nfig.suptitle(ticker + \": Correlation Analysis \"+ start+ \" - \" + end,fontsize=14,horizontalalignment='right', verticalalignment='top')\nax=corr_plot(sp,tw)","ed8f609b":"for i in tw.sort_values('score',ascending=False).body.head(10):\n    print(i, sep=\"\\n\")","ad5d6b02":"for i in tw.sort_values('score',ascending=False).body.tail(10):\n        print(i)","8a996ee3":"start='2015-01-01'\nend='2020-12-31'\nticker='AAPL'\n# get data\nsp=subset_prices(d,ticker,start,end) #get price info\nfig,ax=plt.subplots(figsize=(12, 8))\nfig.suptitle(ticker+ \": Price,Moving Averages\",fontsize=14,horizontalalignment='right', verticalalignment='top')\nprice_plot_ma(ax=ax,df=sp)","c1bab5a5":"start='2018-06-01'\nend='2019-02-28'\nticker='AAPL'\n# get data\nsp=subset_prices(d,ticker,start,end) #get price info\ntw=get_sentiment(tweets,ticker,start,end) # get tweets\ngridsize = (3, 2) # 3 rows, 2 cols\nfig = plt.figure(figsize=(12, 8))\nax1 = plt.subplot2grid(gridsize, (0, 0), colspan=2, rowspan=2)\nax1.set_xlim(min(sp.date),max(sp.date))\nax2 = plt.subplot2grid(gridsize, (2, 0), colspan=2, rowspan=1)\nfig.suptitle(ticker+ \": Price,Moving Averages & Twitter Sentimet\",fontsize=14,horizontalalignment='right', verticalalignment='top')\nfig.subplots_adjust(hspace=0.4)\nprice_plot_ma(ax=ax1,df=sp)\nsentiment_barplot(ax=ax2,df=tw)\n\ngridsize = (2, 2) # 2 rows, 2 cols\nfig = plt.figure(figsize=(12, 8))\nax1 = plt.subplot2grid(gridsize, (0, 0), colspan=2, rowspan=1)\nax2 = plt.subplot2grid(gridsize, (1, 0), colspan=2, rowspan=1)\nfig.suptitle(ticker+ \": Trade Volumes & Tweet Volumes\",fontsize=14,horizontalalignment='right', verticalalignment='top')\nfig.subplots_adjust(hspace=0.5)\nax1.set_xlim(min(sp.date),max(sp.date))\nax2.set_xlim(min(tw.date),max(tw.date))\nprice_plot_vol(ax=ax1, df=sp)\nsentiment_tweet_vol(ax=ax2,df=tw)","31ac42bc":"for i in tw.sort_values('score',ascending=False).body.head(10):\n    print(i, sep=\"\\n\")","272b8d45":"for i in tw.sort_values('score',ascending=False).body.tail(10):\n    print(i, sep=\"\\n\")","86e1b903":"### Tweet Data Preperation\n\nEstimating the sentiment of each tweet\n\nIt would be interesting to investigate whether stock sentiment can be quantified using tweets related to a company.\n\nThis large dataset of tweets doesn't come with a sentiment tag so I will use NLTK's built-in, pretrained sentiment analyzer called VADER (Valence Aware Dictionary and sEntiment Reasoner).\n\nVADER relies on a dictionary that maps words and other numerous lexical features common to sentiment expression in microblogs.\n\nThese features include:\n\nA full list of Western-style emoticons ( for example - :D and :P )\nSentiment-related acronyms ( for example - LOL and ROFL )\nCommonly used slang with sentiment value ( for example - Nah and meh )\nManually creating a thorough sentiment dictionary is a labour-intensive and sometimes error-prone process.\nThus it is no wonder that many NLP researchers rely so heavily on existing dictionaries as primary resources.\n\nThe below code returns the 'compound' score for each tweet,this score ranges from -1 (most negative) to +1 ( most positive).\n\nTo create a categorical variable I apply the following heuristic:\n\nNeg = compound score < -0.6\nPos = compound score > +1.4\nNeutral = -0.6 < compound score < +1.4\nHaving tested VADER against a selection of hypothetical tweets, it appeared that the standard vocabulary wasn't sufficent for this task (see the below examples), but we can augment this vocabulary used by the sentiment analyser with some terminology related to stock market sentiment\n\ne.g. \"Buy\",\"Hold\",\"Bull\",\"Bear\",\"Bubble\"","55ffe309":"### There is always more bulls than bears?\n\nAgain, twitter sentiment has a strong postivie bias (almost 50% positive) , which doesn't tie in to the market moves. \n\nAlso the top\/bottom tweets look to caputure the correct sentiment, but I suspect that there is a lot of 'noise' being captured that is unrelated to the financial performance of Apple.","e256affe":"Visually there does appear to be a relationship between the volume metrics, but it is difficult to say which is the driving force, are people tweeting because the market is moving, or vice versa?\n\nFor example, you see similar spikes in Aug-2018 and Oct-2018. The pattern of traded volume seems to be monthly, whereas twitter volume seems to follow a pattern of spikes every few months, broadly in line with quarterly earning announcements.\n\nI generate a simple correlation plot to measure the relationship of the variables, from the plots above I would expect some positive correlation between tweet and trade volume, and not expect to see a very string relationship between twitter sentiment and my technical indicators of sentiment (MA,MACD,RSI)","cd4c109e":"### Conclusion\n\nCertainly an interesting topic, and there is lots more to explore here particularily in how the sentiment is assign to the trades ( this was my first attempt at NLP), a better understanding of the tweet sentiment might lead to more interesting results, but it can be seen that the sentiment analyser works pretty well all in all. Looking at stock trends versus the market as benchmark would also add value to the analysis.\n\nI added a (small) financial lexicon to the existing NLTK vocab, perhaps it would be best to create a new vocabulary that focuses soley on financial sentiment.","ed50a4fa":"### Stonks, HODL, to the moon, and wallstreetbets\n\n2020 has shown the power of social media and it's ability to move financial markets.\n\nWhether this power is at best a way of increasing market efficeincy by improving the flow of information to a wider audience of investors, or at worst a way for malicious market participants to pump and dump stock prices at the expense of the less informed, or maybe it is an annomoly, with people stuck at home during the pandemic with a lot of time on their hands and maybe a few extra dollars saved to play with.\n\n### Technical Indicators ~ Sentiment\n\nTechnical Indicators are a branch of financial analysis based on the idea that the share price and it's movements encapsulates a huge amount of information, and by tracking various metrics a practitioner will be able to derive a view of the market or a stock solely on these technical indicators. There are many indicators widely used, and resources available online to dive into the detail of each indicator and what it represents.\n\nHere I use some of the most common technical indicators as a way to measure market sentiment and test whether the implied market sentiment is related to the sentiment we find in twitter universe.\n\nI use price data which was sourced from https:\/\/www.kaggle.com\/omermetinn\/values-of-top-nasdaq-copanies-from-2010-to-2020\n\n#### Moving Averages\n\nMA's are intended to capture the price momentum of a stock by identifying trend direction and determining support and resistance levels. Here I use some of the most common horizons 10 day, 20 day, 50 day and 100 day. Analysts monitor these to determine trends, and maybe crucially these can be used to predict when trends may change direction.\n\n#### Relative Strength Index\n\nThe relative strength index (RSI) is a momentum indicator used in technical analysis that measures the magnitude of recent price changes to evaluate overbought or oversold conditions in the price of a stock or other asset.\n\n#### MACD\n\nMoving average convergence divergence (MACD) is a trend-following momentum indicator that shows the relationship between two moving averages of a security\u2019s price. The MACD is calculated by subtracting the 26-period exponential moving average (EMA) from the 12-period EMA. Traders may buy the security when the MACD crosses above its signal line and sell the security when the MACD crosses below the signal line.\n\nCheck out investopeida.com for further detail.","fb2d3a16":"## Telsa - As an example\n\nTaking Tesla as an example, we'll first examine the price plot to examine an interval where we see an interesting pattern in the stock price, and then drill down to examine any relationship between market and twitter sentiment. \n\nIt looks like the period from 2018 - 2020 could be an interesting case study, from the chart we see sentiment go from a downward price trend to a very strong upward trend, where the TSLA share price has increased massively right up to the COVID-19 panic.","6854f8a8":"### AAPL - As an example\n\nTaking Tesla as an example, we'll first examine the price plot to examine an interval where we see an interesting pattern in the stock price, and then drill down to examine any relationship between market and twitter sentiment.\n\nIt looks like the period from 2018 - 2020 could be an interesting case study, from the chart we see sentiment go from a downward price trend to a very strong upward trend, where the TSLA share price has increased massively right up to the COVID-19 panic.","bfd1eb33":"Volume & Tweet volume do exhibit fairly strong correlation\nThe average score (strength of sentiment) does have the expected behavipur w.r.t to the MA,MACD and RSI sentiment measures.\n\nPositive twitter sentiment is reflected in the positive correlation (very weak) with MACD and RSI\nSimilarily for negative tweet sentiment, although again this is a weak effect.\n\n### What are the best and worse tweets?\n\nHaving applied the sentiment analyser, it would be interesting to see what the best and worst tweets were, and how closely the relate to the goal here, linking twitter sentiment to the stock market.\n\nThe following are the top 10 and bottom 10 tweets based on the NLTK's VADER, and we can certainly see that the sentiment of this falls into \"good' and \"bad categories, but they aren't always specific to Tesla stock, and there is a lot of noise related to people's customer experience of tesla ( in particular the negative sentiment tweets below).\n","06c1cab3":"I create some reusable funcitions for plotting (should I do some more analysis)","9ad611f4":"Having categorised each tweet as good, neutral or bad, I plot the daily propotion alongside the price chart to see if the change in trend is reflected in both.\n\nHowever, it appears that across this time period, even though market sentiment was quite up and down, positive twitter sentiment persisted. Perhaps I need to account for the trend in the broader market (S&P 500), as although the Tesla stock does trend down it may have performed better than the market and this might explain the persisiting twitter sentiment\n\nI also examine the relationship between 'tweet volume' and 'trade volume' to see if there is any correlatio"}}