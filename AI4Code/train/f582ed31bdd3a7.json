{"cell_type":{"f56261c2":"code","791994fa":"code","dd495ac9":"code","1695e324":"code","3142570f":"code","fdda74a9":"code","c391f23d":"code","94fdb5af":"code","f2daf904":"code","f2054e4c":"code","1ad8b0c8":"code","3501f8f6":"code","afc7be15":"code","5edc8f2b":"code","550a7764":"code","b83db7fb":"markdown","61cbeb6d":"markdown","99afa735":"markdown","78c067d6":"markdown","a2249ea4":"markdown","7346cde2":"markdown","808cdad7":"markdown","1898dbcf":"markdown","44af2527":"markdown","e8c08e1e":"markdown"},"source":{"f56261c2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file \n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras import layers\n\nfrom pylab import plt\nplt.style.use ('seaborn')\n#import matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nkeras.backend.set_image_data_format('channels_last')\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Dropout\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.utils import plot_model","791994fa":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dd495ac9":"mnist_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\nmnist_test = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\ndisplay(\" train data\",mnist_train )\ndisplay(\" test data\",mnist_test )","1695e324":"# Convert to trian and test data; Preserve original dataset\nX_train = mnist_train.drop('label', axis=1).copy()\nX_test = mnist_test.copy()\nY_train = mnist_train['label'].copy()","3142570f":"print (f'The train dataset has shape {X_train.shape} and the labels shape is: {Y_train.shape}')\nprint (f'The test dataset has shape {X_test.shape}')","fdda74a9":"# Reshape to 28 x 28 so that we can see the image ie. handwritten number\n# resahping the train inputs to be 4D arrays so we can be able to load them\nX_train = X_train.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)","c391f23d":"# plot some of the data with their labels as titles:\nfig, ax= plt.subplots (2, 8, figsize= [12,4])\nfor i in range (2):\n    for j in range (8):\n        rnd= np.random.randint (len(X_train))\n        ax[i, j].imshow (X_train[rnd])\n        ax[i, j].set_title (Y_train [rnd])\n        ax[i, j].set_xticklabels([])\n        ax[i, j].set_yticklabels([])","94fdb5af":"# Some preprocess on data:\n\nX_train= X_train.reshape ((X_train.shape[0], -1))  ### flatten the train inputs to be 1D arrays\nX_test= X_test.reshape ((X_test.shape[0], -1))     ### flatten the test inputs to be 1D arrays\n\nprint (X_train.shape, X_test.shape)\n\nY_train= to_categorical(Y_train, num_classes=10, dtype=\"int\")   ###  One-hot encode the labels to make them real classes, due to do classification","f2daf904":"X_train= X_train \/ 255\nX_test= X_test \/ 255","f2054e4c":"model= Sequential ()\n\n# INputs and first HIDDEN layer\nmodel.add (Dense (512, input_shape= (X_train.shape[1], )))\nmodel.add (Activation ('relu'))\n\n# HIDDEN layers\nmodel.add (Dense (256))\nmodel.add (Dense (128))\n\n# OUTput\nmodel.add (Dense (10))\nmodel.add (Activation('softmax'))\n\n### Visualize the model's detail\nprint (model.summary())\nplot_model (model, show_shapes=True)","1ad8b0c8":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","3501f8f6":"history= model.fit (X_train, Y_train, epochs= 50, batch_size= 32, validation_split= 0.3, verbose= 1, callbacks= [])","afc7be15":"plt.plot(history.history ['loss'], label= 'loss')\nplt.plot(history.history ['val_loss'], label= 'val_loss')\n\nplt.legend ()","5edc8f2b":"plt.plot(history.history ['accuracy'], label= 'accuracy')\nplt.plot(history.history ['val_accuracy'], label= 'val_accuracy')\n\nplt.legend ()","550a7764":"results = model.predict(X_test)\n\n# select the indices with the maximum probability\nresults = np.argmax(results,axis = 1) \nresults = pd.Series(results,name=\"Label\")\nresults","b83db7fb":"# A Model","61cbeb6d":"Here a simple model with a few hidden layers is used.\nIn new updates, I will add methods on how to prevent overfitting and also strengthen the model...","99afa735":"# Introduction","78c067d6":"# Import required modules","a2249ea4":"To see how our model is going, we plot \"Learning Curves\"","7346cde2":"Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.","808cdad7":"# Read Directories & Folders","1898dbcf":"Mnist digit classification is a project involving image recognition wich we have to cassify images of handwritten digits as 0 to 9.","44af2527":"We will normalize the input dataset. This is generally a good idea to avoide some issues like \"nan loss\"","e8c08e1e":"# Load the Data"}}