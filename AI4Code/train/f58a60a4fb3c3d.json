{"cell_type":{"b3328301":"code","a485f92d":"code","32098bee":"code","1a4d3c96":"code","80a84950":"code","e8d5361a":"code","fc4af2af":"code","8cf60a75":"code","a74f579f":"code","93fd774b":"code","6a515ae1":"code","dbc69c6f":"code","4584fe87":"code","95dd738f":"code","815c0f98":"code","372cef16":"code","6b5f9245":"code","4cd0d8b1":"code","3626e199":"code","ad1d6453":"code","283b8096":"code","64c1763b":"code","f002f0de":"code","76543dbf":"code","027b6cf5":"code","32291337":"code","2684be71":"code","d4d3c7dd":"code","8dc4534e":"code","3cee8e8c":"code","474cda13":"code","b0d46ad8":"code","2a7bf5f6":"code","a9703115":"code","3076163d":"code","d16456f1":"code","a69fbb3c":"code","a1134d47":"markdown","ff5ed4eb":"markdown","9ae7ec5d":"markdown","a9ec33f9":"markdown","5543cfb5":"markdown","f9d0f770":"markdown","5e9160a8":"markdown","1df4a995":"markdown","93b035cc":"markdown","3114890b":"markdown","14d74902":"markdown","af051569":"markdown","c064fd30":"markdown","2c16497f":"markdown","0640f2f0":"markdown","b025d930":"markdown","38f39c32":"markdown","29dd00de":"markdown","b9cbe2b4":"markdown","5fa10b29":"markdown"},"source":{"b3328301":"import gc\nimport sys\nimport warnings\nfrom pathlib import Path\n\nimport ipywidgets as widgets\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.tsa.deterministic import (CalendarFourier,\n                                           CalendarSeasonality,\n                                           CalendarTimeTrend,\n                                           DeterministicProcess)\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nwarnings.simplefilter(\"ignore\")\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 5))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)","a485f92d":"data_dir = Path('..\/input\/mlb-player-digital-engagement-forecasting\/')\ntraining = pd.read_csv(data_dir \/ 'train.csv')","32098bee":"training[\"date\"] = pd.to_datetime(training[\"date\"], format=\"%Y%m%d\")","1a4d3c96":"training.head()","80a84950":"display(training.info())","e8d5361a":"#### Look at data from each of the input dfs (data frames) read in ####\ndf_names = ['seasons', 'teams', 'players', 'awards']","fc4af2af":"for name in df_names:\n    globals()[name] = pd.read_csv(data_dir \/ f\"{name}.csv\")","8cf60a75":"kaggle_data_tabs = widgets.Tab()\n# Add Output widgets for each pandas DF as tabs' children\nkaggle_data_tabs.children = list([widgets.Output() for df_name in df_names])","a74f579f":"for index in range(0, len(df_names)):\n    # Rename tab bar titles to df names\n    kaggle_data_tabs.set_title(index, df_names[index])\n    \n    # Display corresponding table output for this tab name\n    with kaggle_data_tabs.children[index]:\n        display(eval(df_names[index]))\n\ndisplay(kaggle_data_tabs)","93fd774b":"import pdb\n\n# Helper function to unpack json found in daily data\ndef unpack_json(json_str):\n    return np.nan if pd.isna(json_str) else pd.read_json(json_str)","6a515ae1":"#### Unnest various nested data within training (daily) data ####\ndaily_data_unnested_dfs = pd.DataFrame(data = {\n  'dfName': training.drop('date', axis = 1).columns.values.tolist()\n  })","dbc69c6f":"daily_data_unnested_dfs['df'] = [pd.DataFrame() for row in \n  daily_data_unnested_dfs.iterrows()]","4584fe87":"daily_data_unnested_dfs","95dd738f":"training[\"nextDayPlayerEngagement\"]","815c0f98":"for df_index, df_row in daily_data_unnested_dfs.iterrows():\n    nestedTableName = str(df_row['dfName'])\n    \n    date_nested_table = training[['date', nestedTableName]]\n    \n    date_nested_table = (date_nested_table[\n      ~pd.isna(date_nested_table[nestedTableName])\n      ].\n      reset_index(drop = True)\n      )\n    \n    daily_dfs_collection = []\n    for date_index, date_row in date_nested_table.iterrows():\n        daily_df = unpack_json(date_row[nestedTableName])\n        \n        daily_df['dailyDataDate'] = date_row['date']\n        \n        daily_dfs_collection = daily_dfs_collection + [daily_df]\n\n    unnested_table = pd.concat(daily_dfs_collection,\n      ignore_index = True).set_index('dailyDataDate').reset_index()\n\n    # Creates 1 pandas df per unnested df from daily data read in, with same name\n    globals()[df_row['dfName']] = unnested_table    \n    \n    daily_data_unnested_dfs['df'][df_index] = unnested_table\n\n","372cef16":"del training\ngc.collect()","6b5f9245":"games.shape","4cd0d8b1":"daily_data_unnested_dfs.head()","3626e199":"#### Get some information on each date in daily data (using season dates of interest) ####\ndates = pd.DataFrame(data = \n  {'dailyDataDate': nextDayPlayerEngagement['dailyDataDate'].unique()})\n","ad1d6453":"dates['date'] = pd.to_datetime(dates['dailyDataDate'].astype(str))\n\ndates['year'] = dates['date'].dt.year\ndates['month'] = dates['date'].dt.month","283b8096":"dates_with_info = pd.merge(\n  dates,\n  seasons,\n  left_on = 'year',\n  right_on = 'seasonId'\n  )","64c1763b":"dates_with_info['inSeason'] = (\n  dates_with_info['date'].between(\n    dates_with_info['regularSeasonStartDate'],\n    dates_with_info['postSeasonEndDate'],\n    inclusive = True\n    )\n  )\n","f002f0de":"dates_with_info['seasonPart'] = np.select(\n  [\n    dates_with_info['date'] < dates_with_info['preSeasonStartDate'], \n    dates_with_info['date'] < dates_with_info['regularSeasonStartDate'],\n    dates_with_info['date'] <= dates_with_info['lastDate1stHalf'],\n    dates_with_info['date'] < dates_with_info['firstDate2ndHalf'],\n    dates_with_info['date'] <= dates_with_info['regularSeasonEndDate'],\n    dates_with_info['date'] < dates_with_info['postSeasonStartDate'],\n    dates_with_info['date'] <= dates_with_info['postSeasonEndDate'],\n    dates_with_info['date'] > dates_with_info['postSeasonEndDate']\n  ], \n  [\n    'Offseason',\n    'Preseason',\n    'Reg Season 1st Half',\n    'All-Star Break',\n    'Reg Season 2nd Half',\n    'Between Reg and Postseason',\n    'Postseason',\n    'Offseason'\n  ], \n  default = np.nan\n  )\n\n","76543dbf":"#### Add some pitching stats\/pieces of info to player game level stats ####\n\nplayer_game_stats = (playerBoxScores.copy().\n  # Change team Id\/name to reflect these come from player game, not roster\n  rename(columns = {'teamId': 'gameTeamId', 'teamName': 'gameTeamName'})\n  )\n","027b6cf5":"# Adds in field for innings pitched as fraction (better for aggregation)\nplayer_game_stats['inningsPitchedAsFrac'] = np.where(\n  pd.isna(player_game_stats['inningsPitched']),\n  np.nan,\n  np.floor(player_game_stats['inningsPitched']) +\n    (player_game_stats['inningsPitched'] -\n      np.floor(player_game_stats['inningsPitched'])) * 10\/3\n  )\n","32291337":"# Add in Tom Tango pitching game score (https:\/\/www.mlb.com\/glossary\/advanced-stats\/game-score)\nplayer_game_stats['pitchingGameScore'] = (40\n#     + 2 * player_game_stats['outs']\n    + 1 * player_game_stats['strikeOutsPitching']\n    - 2 * player_game_stats['baseOnBallsPitching']\n    - 2 * player_game_stats['hitsPitching']\n    - 3 * player_game_stats['runsPitching']\n    - 6 * player_game_stats['homeRunsPitching']\n    )","2684be71":"# Add in criteria for no-hitter by pitcher (individual, not multiple pitchers)\nplayer_game_stats['noHitter'] = np.where(\n  (player_game_stats['gamesStartedPitching'] == 1) &\n  (player_game_stats['inningsPitched'] >= 9) &\n  (player_game_stats['hitsPitching'] == 0),\n  1, 0\n  )","d4d3c7dd":"player_date_stats_agg = pd.merge(\n  (player_game_stats.\n    groupby(['dailyDataDate', 'playerId'], as_index = False).\n    # Some aggregations that are not simple sums\n    agg(\n      numGames = ('gamePk', 'nunique'),\n      # Should be 1 team per player per day, but adding here for 1 exception:\n      # playerId 518617 (Jake Diekman) had 2 games for different teams marked\n      # as played on 5\/19\/19, due to resumption of game after he was traded\n      numTeams = ('gameTeamId', 'nunique'),\n      # Should be only 1 team for almost all player-dates, taking min to simplify\n      gameTeamId = ('gameTeamId', 'min')\n      )\n    ),\n  # Merge with a bunch of player stats that can be summed at date\/player level\n  (player_game_stats.\n    groupby(['dailyDataDate', 'playerId'], as_index = False)\n    [['runsScored', 'homeRuns', 'strikeOuts', 'baseOnBalls', 'hits',\n      'hitByPitch', 'atBats', 'caughtStealing', 'stolenBases',\n      'groundIntoDoublePlay', 'groundIntoTriplePlay', 'plateAppearances',\n      'totalBases', 'rbi', 'leftOnBase', 'sacBunts', 'sacFlies',\n      'gamesStartedPitching', 'runsPitching', 'homeRunsPitching', \n      'strikeOutsPitching', 'baseOnBallsPitching', 'hitsPitching',\n      'inningsPitchedAsFrac', 'earnedRuns', \n      'battersFaced','saves', 'blownSaves', 'pitchingGameScore', \n      'noHitter'\n      ]].\n    sum()\n    ),\n  on = ['dailyDataDate', 'playerId'],\n  how = 'inner'\n  )\n\n#### Turn games table into 1 row per team-game, then merge with team box scores ####\n# Filter to regular or Postseason games w\/ valid scores for this part\ngames_for_stats = games[\n  np.isin(games['gameType'], ['R', 'F', 'D', 'L', 'W', 'C', 'P']) &\n  ~pd.isna(games['homeScore']) &\n  ~pd.isna(games['awayScore'])\n  ]\n\n# Get games table from home team perspective\ngames_home_perspective = games_for_stats.copy()\n\n# Change column names so that \"team\" is \"home\", \"opp\" is \"away\"\ngames_home_perspective.columns = [\n  col_value.replace('home', 'team').replace('away', 'opp') for \n    col_value in games_home_perspective.columns.values]\n\ngames_home_perspective['isHomeTeam'] = 1\n\n# Get games table from away team perspective\ngames_away_perspective = games_for_stats.copy()\n\n# Change column names so that \"opp\" is \"home\", \"team\" is \"away\"\ngames_away_perspective.columns = [\n  col_value.replace('home', 'opp').replace('away', 'team') for \n    col_value in games_away_perspective.columns.values]\n\ngames_away_perspective['isHomeTeam'] = 0\n\n# Put together games from home\/away perspective to get df w\/ 1 row per team game\nteam_games = (pd.concat([\n  games_home_perspective,\n  games_away_perspective\n  ],\n  ignore_index = True)\n  )\n\n# Copy over team box scores data to modify\nteam_game_stats = teamBoxScores.copy()\n\n# Change column names to reflect these are all \"team\" stats - helps \n# to differentiate from individual player stats if\/when joining later\nteam_game_stats.columns = [\n  (col_value + 'Team') \n  if (col_value not in ['dailyDataDate', 'home', 'teamId', 'gamePk',\n    'gameDate', 'gameTimeUTC'])\n    else col_value\n  for col_value in team_game_stats.columns.values\n  ]\n\n# Merge games table with team game stats\nteam_games_with_stats = pd.merge(\n  team_games,\n  team_game_stats.\n    # Drop some fields that are already present in team_games table\n    drop(['home', 'gameDate', 'gameTimeUTC'], axis = 1),\n  on = ['dailyDataDate', 'gamePk', 'teamId'],\n  # Doing this as 'inner' join excludes spring training games, postponed games,\n  # etc. from original games table, but this may be fine for purposes here \n  how = 'inner'\n  )\n\nteam_date_stats_agg = (team_games_with_stats.\n  groupby(['dailyDataDate', 'teamId', 'gameType', 'oppId', 'oppName'], \n    as_index = False).\n  agg(\n    numGamesTeam = ('gamePk', 'nunique'),\n    winsTeam = ('teamWinner', 'sum'),\n    lossesTeam = ('oppWinner', 'sum'),\n    runsScoredTeam = ('teamScore', 'sum'),\n    runsAllowedTeam = ('oppScore', 'sum')\n    )\n   )\n\n# Prepare standings table for merge w\/ player digital engagement data\n# Pick only certain fields of interest from standings for merge\nstandings_selected_fields = (standings[['dailyDataDate', 'teamId', \n  'streakCode', 'divisionRank', 'leagueRank', 'wildCardRank', 'pct'\n  ]].\n  rename(columns = {'pct': 'winPct'})\n  )\n\n# Change column names to reflect these are all \"team\" standings - helps \n# to differentiate from player-related fields if\/when joining later\nstandings_selected_fields.columns = [\n  (col_value + 'Team') \n  if (col_value not in ['dailyDataDate', 'teamId'])\n    else col_value\n  for col_value in standings_selected_fields.columns.values\n  ]\n\nstandings_selected_fields['streakLengthTeam'] = (\n  standings_selected_fields['streakCodeTeam'].\n    str.replace('W', '').\n    str.replace('L', '').\n    astype(float)\n    )\n\n# Add fields to separate winning and losing streak from streak code\nstandings_selected_fields['winStreakTeam'] = np.where(\n  standings_selected_fields['streakCodeTeam'].str[0] == 'W',\n  standings_selected_fields['streakLengthTeam'],\n  np.nan\n  )\n\nstandings_selected_fields['lossStreakTeam'] = np.where(\n  standings_selected_fields['streakCodeTeam'].str[0] == 'L',\n  standings_selected_fields['streakLengthTeam'],\n  np.nan\n  )\n\nstandings_for_digital_engagement_merge = (pd.merge(\n  standings_selected_fields,\n  dates_with_info[['dailyDataDate', 'inSeason']],\n  on = ['dailyDataDate'],\n  how = 'left'\n  ).\n  # Limit down standings to only in season version\n  query(\"inSeason\").\n  # Drop fields no longer necessary (in derived values, etc.)\n  drop(['streakCodeTeam', 'streakLengthTeam', 'inSeason'], axis = 1).\n  reset_index(drop = True)\n  )\n\n#### Merge together various data frames to add date, player, roster, and team info ####\n# Copy over player engagement df to add various pieces to it\nplayer_engagement_with_info = nextDayPlayerEngagement.copy()\n\n# Take \"row mean\" across targets to add (helps with studying all 4 targets at once)\nplayer_engagement_with_info['targetAvg'] = np.mean(\n  player_engagement_with_info[['target1', 'target2', 'target3', 'target4']],\n  axis = 1)\n\n# Merge in date information\nplayer_engagement_with_info = pd.merge(\n  player_engagement_with_info,\n  dates_with_info[['dailyDataDate', 'date', 'year', 'month', 'inSeason',\n    'seasonPart']],\n  on = ['dailyDataDate'],\n  how = 'left'\n  )\n\n# Merge in some player information\nplayer_engagement_with_info = pd.merge(\n  player_engagement_with_info,\n  players[['playerId', 'playerName', 'DOB', 'mlbDebutDate', 'birthCity',\n    'birthStateProvince', 'birthCountry', 'primaryPositionName']],\n   on = ['playerId'],\n   how = 'left'\n   )\n\n# Merge in some player roster information by date\nplayer_engagement_with_info = pd.merge(\n  player_engagement_with_info,\n  (rosters[['dailyDataDate', 'playerId', 'statusCode', 'status', 'teamId']].\n    rename(columns = {\n      'statusCode': 'rosterStatusCode',\n      'status': 'rosterStatus',\n      'teamId': 'rosterTeamId'\n      })\n    ),\n  on = ['dailyDataDate', 'playerId'],\n  how = 'left'\n  )\n    \n# Merge in team name from player's roster team\nplayer_engagement_with_info = pd.merge(\n  player_engagement_with_info,\n  (teams[['id', 'teamName']].\n    rename(columns = {\n      'id': 'rosterTeamId',\n      'teamName': 'rosterTeamName'\n      })\n    ),\n  on = ['rosterTeamId'],\n  how = 'left'\n  )\n\n# Merge in some player game stats (previously aggregated) from that date\nplayer_engagement_with_info = pd.merge(\n  player_engagement_with_info,\n  player_date_stats_agg,\n  on = ['dailyDataDate', 'playerId'],\n  how = 'left'\n  )\n\n# Merge in team name from player's game team\nplayer_engagement_with_info = pd.merge(\n  player_engagement_with_info,\n  (teams[['id', 'teamName']].\n    rename(columns = {\n      'id': 'gameTeamId',\n      'teamName': 'gameTeamName'\n      })\n    ),\n  on = ['gameTeamId'],\n  how = 'left'\n  )\n\n# Merge in some team game stats\/results (previously aggregated) from that date\nplayer_engagement_with_info = pd.merge(\n  player_engagement_with_info,\n  team_date_stats_agg.rename(columns = {'teamId': 'gameTeamId'}),\n  on = ['dailyDataDate', 'gameTeamId'],\n  how = 'left'\n  )\n\n# Merge in player transactions of note on that date\n    \n# Merge in some pieces of team standings (previously filter\/processed) from that date\nplayer_engagement_with_info = pd.merge(\n  player_engagement_with_info,\n  standings_for_digital_engagement_merge.\n    rename(columns = {'teamId': 'gameTeamId'}),\n  on = ['dailyDataDate', 'gameTeamId'],\n  how = 'left'\n  )\n\ndisplay(player_engagement_with_info)","8dc4534e":"def seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\n        \"husl\",\n        n_colors=X[period].nunique(),\n    )\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}\/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax\n\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") \/ pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual\",\n            \"Semiannual\",\n            \"Quarterly\",\n            \"Bimonthly\",\n            \"Monthly\",\n            \"Biweekly\",\n            \"Weekly\",\n            \"Semiweekly\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Density\")\n    ax.set_title(\"Periodogram\")\n    return ax","3cee8e8c":"# Extract player engagement time series \nindex = [\"playerId\", \"date\"]\ntargets = [\"target1\", \"target2\", \"target3\", \"target4\"]\nY = player_engagement_with_info.loc[:, index + targets]\nY = Y.assign(date=lambda x: pd.to_datetime(x.date))\nY = Y.set_index(\"date\").to_period(\"D\")\nY = Y.pivot(columns=\"playerId\")\n\n# Select Yankees players\nyankees_players = player_engagement_with_info.query(\"rosterTeamName == 'Yankees'\").playerId.unique()\nyankees = Y.loc(axis=1)[:, yankees_players]\n\n# Create average engagement series\nteam = (yankees \/ yankees.max(axis=0)).mean(axis=1)\nteam.name = \"target\"\n\n# Yearly plot\nS = team.to_frame()\nS[\"month\"] = S.index.month  # the frequency\nS[\"year\"] = S.index.year  # the period\n_ = seasonal_plot(S, y=\"target\", period=\"year\", freq=\"month\")\n\n# Weekly plot\nS = team.to_frame()\nS[\"day\"] = S.index.dayofweek  # the frequency\nS[\"week\"] = S.index.week  # the period\n_ = seasonal_plot(S, y=\"target\", period=\"week\", freq=\"day\")","474cda13":"_ = plot_periodogram(team)","b0d46ad8":"df = player_engagement_with_info\n\n# Columns to select\nindex = [\"playerId\", \"date\"]\ntargets = [\"target1\", \"target2\", \"target3\", \"target4\"]\nfeatures = [\n    \"runsScored\", \"hits\", \"stolenBases\", \"rbi\", \"atBats\", \"saves\", \"homeRuns\",\n    \"stolenBases\", \"strikeOuts\",\n]\n\n# Targets\nY = df.loc[:, index + targets]\nY = Y.assign(date=lambda x: pd.to_datetime(x.date))\nY = Y.set_index(\"date\").to_period(\"D\")\nY = Y.pivot(columns=\"playerId\")\n\n# Features\nX = df.loc[:, index + features].set_index(\"date\").to_period(\"D\")\nfor col in features:\n    X[col] = X[col].fillna(-1)\nX = X.pivot(columns=[\"playerId\"])\n\n# Temporal features\nfourier = CalendarFourier(freq='A', order=8)\ndeterministic = DeterministicProcess(\n    index=X.index,\n    order=0,\n    seasonal=False,  # set to True to create indicators for days of the week (weekly seasonality)\n    additional_terms=[fourier],\n)\nX = pd.concat([X, deterministic.in_sample()], axis=1)\n\n# Training splits\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X,\n    Y,\n    test_size=30,  # 30-day validation set\n    shuffle=False,\n)","2a7bf5f6":"OUTPUTS = y_train.shape[-1]\nearly_stopping = keras.callbacks.EarlyStopping(patience=5,\n                                               restore_best_weights=True)\n\nmodel = keras.Sequential([\n    layers.Dense(1024, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(1024, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(1024, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(OUTPUTS),\n])\n","a9703115":"model.compile(\n    optimizer='adam',\n    loss='mae',\n    metrics=['mae'],\n)\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_data=(X_valid, y_valid),\n    epochs=50,\n    callbacks=[early_stopping]\n)","3076163d":"y_eval = model.predict(X_valid)\ny_eval = pd.DataFrame(y_eval,\n                      index=y_valid.index,\n                      columns=y_valid.columns)\ny_fit = model.predict(X_train)\ny_fit = pd.DataFrame(y_fit,\n                     index=y_train.index,\n                     columns=y_train.columns)","d16456f1":"player = 592450  # Aaron Judge of the NY Yankees\nfig, ax = plt.subplots(figsize=(11, 8))\nax = y_eval.loc(axis=1)[:, player].plot(ax=ax, subplots=True, color='C0')\nax = y_valid.loc(axis=1)[:, player].plot(subplots=True,\n                                         sharex=True,\n                                         ax=ax,\n                                         color='0.25')\nax = y_fit.loc(axis=1)[:, player].plot(subplots=True,\n                                       sharex=True,\n                                       ax=ax,\n                                       color='C3')\nax = y_train.loc(axis=1)[:, player].plot(subplots=True,\n                                         sharex=True,\n                                         ax=ax,\n                                         color='0.25')","a69fbb3c":"if 'kaggle_secrets' in sys.modules:  # only run while on Kaggle\n    import mlb\n\n    env = mlb.make_env()\n    iter_test = env.iter_test()\n\n    for (test_df, sample_prediction_df) in iter_test:\n    \n        # Example: unpack a dataframe from a json column\n        today_games = unpack_json(test_df['games'].iloc[0])\n    \n        # Make your predictions for the next day's engagement\n        sample_prediction_df['target1'] = 100.00\n    \n        # Submit your predictions \n        env.predict(sample_prediction_df)","a1134d47":"# Getting Started with MLB Player Digital Engagement Forecasting #","ff5ed4eb":"Both of these visualizations indicate yearly (or annual) seasonality in the engagement time series. We'll model this effect with Fourier features, which we create below.","9ae7ec5d":"For this getting started notebook, we'll just create a simple feedforward network.","a9ec33f9":"Now let's do a little bit of data visualization to motivate our feature engineering. We'll investigate seasonal effects for the *Yankees* team, the team with the most overall engagement.","5543cfb5":"We can verify this with the *periodogram*. The periodogram illustrates the strength of the frequencies within a signal -- specifically, the variance of the sine \/ cosine Fourier component oscillating at that frequency.","f9d0f770":"A *seasonal plot* can reveal seasonal effects in a time series. Here are two seasonal plots for the average player engagement for the Yankees, one for yearly seasonality and one for weekly.","5e9160a8":"# Load and Join Data #","1df4a995":"# Explainable AI with Vertex #\n\n[This complementary notebook](https:\/\/www.kaggle.com\/ryanholbrook\/vertex-ai-with-mlb-player-digital-engagement) demonstrates how to run this notebook in Vertex AI Notebooks and use Explainable AI (XAI) to refine your features.","93b035cc":"Let's look at predictions for Aaron Judge of the NY Yankees, the player with the overall highest engagement.","3114890b":"Let's take a look at some data.\n\nThe training data is a time-indexed collection of nested JSON fields containing information about each player. The targets are contained in the `nextDayPlayerEngagement` column, while the remaining columns contain data that may be used as features.","14d74902":"In the next cell we'll restructure this data into a single dataframe `player_engagement_with_info` convienient for modeling.","af051569":"There are in addition a number of supplementary files. See the [data documentation](https:\/\/www.kaggle.com\/c\/mlb-player-digital-engagement-forecasting\/data) on the competition page for more information.","c064fd30":"The next cell illustrates how you to create a submission for this competition. As this is a code competition that relies on a time series module, submissions must follow the requirements described on the [Evaluation Page](https:\/\/www.kaggle.com\/c\/mlb-player-digital-engagement-forecasting\/overview\/evaluation) and [Data Page](https:\/\/www.kaggle.com\/c\/mlb-player-digital-engagement-forecasting\/data).","2c16497f":"# Data Pipeline #","0640f2f0":"# Model #","b025d930":"# Data Exploration #","38f39c32":"# Create Submission #","29dd00de":"# Evaluate #","b9cbe2b4":"The following cell creates our data splits for training. We will:\n- select a set of features from `player_engagement_with_info`\n- pivot the dataframe from long to wide format so that each column comprises a time series for the training period\n- create Fourier features to model the annual seasonality\n- split data into training and validation sets","5fa10b29":"Welcome to the Getting Started notebook for the *MLB Digital Engagement Forecasting* competition! This notebook is a complete start-to-finish guide to entering this competition. We will:\n- load and join the data,\n- explore time series properties,\n- create a feature set,\n- train a neural network, and\n- make a submission.\n\nAs this is a *code competition*, be aware that your submission will be a notebook to make predictions during the test period. Read more about [code competitions](https:\/\/www.kaggle.com\/docs\/competitions#notebooks-only-competitions).\n\nIn the complementary notebook, [Vertex AI with MLB Player Digital Engagement](https:\/\/www.kaggle.com\/ryanholbrook\/vertex-ai-with-mlb-player-digital-engagement), we'll also demonstrate some of the capabilities of Vertex AI, Google's new unified AI platform:\n- using Vertex AI Notebooks on Google Cloud Platform\n- exploring explainable AI on Vertex AI to refine your features"}}