{"cell_type":{"cd7db64f":"code","4863d7c7":"code","8c95c7f1":"code","9981bbee":"code","d30df701":"code","327b5fda":"code","162a0a43":"code","554559c0":"code","41353f80":"code","549e1188":"code","4c0db64c":"code","0f50678b":"code","7e3b7453":"code","91e42ec6":"code","9b73d428":"code","d1e9fe76":"code","060c0fbd":"code","652a8f61":"code","9053b08c":"code","56ce4bcb":"code","24ff15e0":"code","9d765d5d":"code","054be83a":"code","50b03968":"code","f28d795d":"code","1ffb132a":"code","b36a798a":"code","73acba11":"code","4c58674d":"code","feafd0ec":"code","4adb0a1f":"code","46d7903f":"code","08923c75":"code","0028f5ec":"code","683daa51":"code","cd229fc3":"code","cccdcbde":"code","b82d60e6":"code","b033b3fb":"code","49878f38":"code","88eae56e":"code","d9ba28b5":"code","6f55d28e":"code","642e460e":"code","9d9b036e":"code","07dbb18b":"code","4905aa72":"code","726fcf69":"code","f9402919":"code","a255bf07":"code","92d04f16":"code","ba55c59a":"code","ee2ebdea":"markdown","7b352386":"markdown","4d53ff8c":"markdown","84f9795c":"markdown","5ae0a251":"markdown","2872bd56":"markdown","b08ca8ab":"markdown","bff96cf7":"markdown","64362d04":"markdown","0cc84230":"markdown","ff37e033":"markdown","c8b54514":"markdown","6c2ad57f":"markdown","31130931":"markdown","d6272f74":"markdown","6e4da0f7":"markdown","9945bce5":"markdown","d7748378":"markdown","31bf9143":"markdown","c1e4143e":"markdown","9a9c54c1":"markdown","601a65fe":"markdown","de6cfc4c":"markdown","29e744c3":"markdown","19444222":"markdown","6deca825":"markdown","e86f5ab0":"markdown","9c85806a":"markdown","0cc164d4":"markdown","729b112f":"markdown","273afd82":"markdown","cd89c7da":"markdown","1f46738a":"markdown","50bb58a0":"markdown","73db5378":"markdown","d35491db":"markdown","f0747af1":"markdown","6637c580":"markdown","e4b45cd9":"markdown","e84f6f68":"markdown","186e9ac6":"markdown"},"source":{"cd7db64f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4863d7c7":"import matplotlib as mpl  # data visualization library\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport seaborn as sns ","8c95c7f1":"covid_data_path = \"..\/input\/new-data-2\/linear-comprehensive-covid-data (1).csv\"\ndf = pd.read_csv(covid_data_path)\ndf.head()","9981bbee":"df.columns #displays columns in the df","d30df701":"print(\"Shape of the Covid DataFrame:\",df.shape,\"\\n\")","327b5fda":"NZ_df = df.loc[df[\"location\"] ==\"New Zealand\"]\nGer_df = df.loc[df[\"location\"] ==\"Germany\"]\nSlv_df = df.loc[df[\"location\"] ==\"Slovakia\"]\n\n\ndisplay(NZ_df.head())\nNZ_df.shape","162a0a43":"NZ_df = NZ_df.reset_index()  #RESETS THE INDEX OF THE DF\nNZ_df.drop('index', axis=1, inplace=True)\n\nGer_df = Ger_df.reset_index()  #RESETS THE INDEX OF THE DF\nGer_df.drop('index', axis=1, inplace=True)\n\nSlv_df = Slv_df.reset_index()  #RESETS THE INDEX OF THE DF\nSlv_df.drop('index', axis=1, inplace=True)","554559c0":"NZ_df.head()  #display the data to see if the index is reset","41353f80":"Ger_df.head()","549e1188":"NZ_df.info()  #info about the raw dataset\n#Ger_df.info()\n#Slv_df.info()","4c0db64c":"NZ_df.describe()    #describing the raw dataset","0f50678b":"NZ_df.isnull().sum()   #Checking the count of NULL values in each column","7e3b7453":"print(NZ_df.population.value_counts())\nprint(NZ_df.population_density.value_counts())\nprint(NZ_df.aged_65_older.value_counts())\nprint(NZ_df.aged_70_older.value_counts())\nprint(NZ_df.median_age.value_counts())\n\n##Checking unique elements in thses columns","91e42ec6":"NZ_df['date']   #Checking the format of the date","9b73d428":"NZ_process_df = NZ_df.drop(['iso_code', 'continent', 'handwashing_facilities', 'extreme_poverty', 'tests_per_case', 'tests_units', 'human_development_index','median_age','population',\n                             'population_density','aged_65_older','aged_70_older','gdp_per_capita','cardiovasc_death_rate','diabetes_prevalence','female_smokers','male_smokers',\n                            'hospital_beds_per_thousand','life_expectancy',  'total_vaccinations', 'people_vaccinated','people_fully_vaccinated', 'new_vaccinations' ,\n                            'new_vaccinations_smoothed','total_vaccinations_per_hundred','people_vaccinated_per_hundred','people_fully_vaccinated_per_hundred',\n                            'new_vaccinations_smoothed_per_million','icu_patients',  'icu_patients_per_million', 'hosp_patients'          \n   ,'hosp_patients_per_million'       \n   ,'weekly_icu_admissions'            \n   ,'weekly_icu_admissions_per_million'  \n   ,'weekly_hosp_admissions'\n,'weekly_hosp_admissions_per_million'\n                            ],axis = 1,inplace=False)\nNZ_process_df.columns","d1e9fe76":"Ger_process_df = Ger_df.drop(['iso_code', 'continent', 'handwashing_facilities', 'extreme_poverty', 'tests_per_case', 'tests_units', 'human_development_index','median_age','population',\n                             'population_density','aged_65_older','aged_70_older','gdp_per_capita','cardiovasc_death_rate','diabetes_prevalence','female_smokers','male_smokers',\n                            'hospital_beds_per_thousand','life_expectancy',  'total_vaccinations', 'people_vaccinated','people_fully_vaccinated', 'new_vaccinations' ,\n                            'new_vaccinations_smoothed','total_vaccinations_per_hundred','people_vaccinated_per_hundred','people_fully_vaccinated_per_hundred',\n                            'new_vaccinations_smoothed_per_million','icu_patients',  'icu_patients_per_million', 'hosp_patients'          \n   ,'hosp_patients_per_million'       \n   ,'weekly_icu_admissions'            \n   ,'weekly_icu_admissions_per_million'  \n   ,'weekly_hosp_admissions'\n,'weekly_hosp_admissions_per_million', 'new_tests', 'new_tests_per_thousand'\n                            ],axis = 1,inplace=False)\nGer_process_df.columns","060c0fbd":"Slv_process_df = Slv_df.drop(['iso_code', 'continent', 'handwashing_facilities', 'extreme_poverty', 'tests_per_case', 'tests_units', 'human_development_index','median_age','population',\n                             'population_density','aged_65_older','aged_70_older','gdp_per_capita','cardiovasc_death_rate','diabetes_prevalence','female_smokers','male_smokers',\n                            'hospital_beds_per_thousand','life_expectancy',  'total_vaccinations', 'people_vaccinated','people_fully_vaccinated', 'new_vaccinations' ,\n                            'new_vaccinations_smoothed','total_vaccinations_per_hundred','people_vaccinated_per_hundred','people_fully_vaccinated_per_hundred',\n                            'new_vaccinations_smoothed_per_million','icu_patients',  'icu_patients_per_million', 'hosp_patients'          \n   ,'hosp_patients_per_million'       \n   ,'weekly_icu_admissions'            \n   ,'weekly_icu_admissions_per_million'  \n   ,'weekly_hosp_admissions'\n,'weekly_hosp_admissions_per_million'\n                            ],axis = 1,inplace=False)\nSlv_process_df.columns","652a8f61":"NZ_process_df.head()","9053b08c":"NZ_replace_initial = ['total_deaths', 'total_tests', 'total_cases', 'new_tests', 'new_cases',\n     'positive_rate', 'new_deaths', 'new_tests_smoothed', 'new_deaths_smoothed', 'stringency_index']\nGer_replace_initial =  ['total_deaths', 'total_tests', 'total_cases', 'new_cases',\n     'positive_rate', 'new_deaths', 'new_tests_smoothed', 'new_deaths_smoothed', 'stringency_index']\n\nfor i in NZ_replace_initial:\n    s = pd.Series(NZ_df[i])\n    NZ_process_df.loc[0:s.first_valid_index(),i] = 0.0   \n    \nfor i in Ger_replace_initial:\n    s = pd.Series(Ger_df[i])\n    Ger_process_df.loc[0:s.first_valid_index(),i] = 0.0   \n    \nfor i in NZ_replace_initial:\n    s = pd.Series(Slv_df[i])\n    print(s.first_valid_index())\n    Slv_process_df.loc[0:s.first_valid_index(),i] = 0.0  ","56ce4bcb":"# replacing the missing values with mean \n\nreplace_mean_list = ['total_cases', 'new_cases', 'new_cases_smoothed',\n       'total_deaths', 'new_deaths', 'new_deaths_smoothed',\n       'total_cases_per_million', 'new_cases_per_million',\n       'new_cases_smoothed_per_million', 'total_deaths_per_million',\n       'new_deaths_per_million', 'new_deaths_smoothed_per_million',\n       'new_tests', 'total_tests', 'total_tests_per_thousand',\n       'new_tests_per_thousand', 'new_tests_smoothed',\n       'new_tests_smoothed_per_thousand', 'positive_rate', 'stringency_index','reproduction_rate']\n\nreplace_mean_list_ger = ['total_cases', 'new_cases', 'new_cases_smoothed',\n       'total_deaths', 'new_deaths', 'new_deaths_smoothed',\n       'total_cases_per_million', 'new_cases_per_million',\n       'new_cases_smoothed_per_million', 'total_deaths_per_million',\n       'new_deaths_per_million', 'new_deaths_smoothed_per_million',\n       'total_tests', 'total_tests_per_thousand',\n       'new_tests_smoothed',\n       'new_tests_smoothed_per_thousand', 'positive_rate', 'stringency_index','reproduction_rate']\n\nfor i in replace_mean_list:\n    NZ_process_df[i].fillna(NZ_process_df[i].mean(), inplace=True)\n    \nfor i in replace_mean_list_ger:\n    Ger_process_df[i].fillna(Ger_process_df[i].mean(), inplace=True)\n    \nfor i in replace_mean_list:\n    Slv_process_df[i].fillna(Slv_process_df[i].mean(), inplace=True)\n    \n    \nNZ_process_df.to_csv('NZ.csv', index=False)\nGer_process_df.to_csv('GER.csv', index=False)\nSlv_process_df.to_csv('SLV.csv', index=False)","24ff15e0":"NZ_process_df.info()","9d765d5d":"Ger_process_df.info()","054be83a":"NZ_process_df.describe()","50b03968":"NZ_process_df.corr()\n#Finding correlation between columns of the df ","f28d795d":"fig, ax = plt.subplots(figsize=(20,20))         # Sample figsize in inches\nsns.heatmap(NZ_process_df.corr(), annot=True , ax = ax , cmap = 'RdYlGn', center=0)","1ffb132a":"import matplotlib.ticker as ticker  \n\nfig,ax =  plt.subplots( 2, 2,  figsize = ( 20, 10)) \n\nsns.lineplot(x=\"date\", y=\"total_deaths\",data=NZ_process_df,ax =ax[0][0],color = 'r')\nax[0][0].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[0][0].tick_params(labelrotation = 45) \n\nsns.lineplot(x=\"date\", y=\"new_deaths_smoothed\",data=NZ_process_df,ax =ax[0][1],color = 'g')\nax[0][1].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[0][1].tick_params(labelrotation = 45) \n\nsns.lineplot(x=\"date\", y=\"new_cases\",data=NZ_process_df,ax =ax[1][0],color = 'b')\nax[1][0].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[1][0].tick_params(labelrotation = 45) \nax[1][0].annotate('FIRST WAVE: ~45 DAYS', xy=(40, 80), xytext=(80, 88),\n            arrowprops=dict(facecolor='black', shrink=0.05))\n\nsns.lineplot(x=\"date\", y=\"stringency_index\",data=NZ_process_df,ax =ax[1][1],color = 'y')\nax[1][1].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[1][1].tick_params(labelrotation = 45) ","b36a798a":"fig, ax = plt.subplots(figsize=(20,6))\nsns.lineplot(x=\"date\", y=\"new_cases\",sizes=(10, 10),data=NZ_df,ax =ax)\nplt.xticks(rotation=45);\nfig.tight_layout(pad = 1.2)\nax.xaxis.set_major_locator(ticker.MultipleLocator(7)) ","73acba11":"NZ_df.hist(column='new_tests', bins='auto')\nplt.xlabel('New Tests')\nplt.ylabel('Count')","4c58674d":"fig,ax =  plt.subplots( 2, 2,  figsize = ( 20, 10)) \n\nsns.lineplot(x=\"date\", y=\"new_cases\",data=NZ_process_df,ax =ax[0][0],color = 'r')\nax[0][0].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[0][0].tick_params(labelrotation = 45) \n\nsns.lineplot(x=\"date\", y=\"total_cases\",data=NZ_process_df,ax =ax[0][1],color = 'g')\nax[0][1].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[0][1].tick_params(labelrotation = 45) \n\nsns.lineplot(x=\"date\", y=\"new_tests_smoothed\",data=NZ_process_df,ax =ax[1][0],color = 'b')\nax[1][0].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[1][0].tick_params(labelrotation = 45) \n\nsns.lineplot(x=\"date\", y=\"stringency_index\",data=NZ_process_df,ax =ax[1][1],color = 'y')\nax[1][1].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[1][1].tick_params(labelrotation = 45) \n","feafd0ec":"fig,ax =  plt.subplots( 2, 2,  figsize = ( 20, 10)) \n\nsns.lineplot(x=\"date\", y=\"new_cases\",data=NZ_process_df,ax =ax[0][0],color = 'r')\nax[0][0].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[0][0].tick_params(labelrotation = 45)\nax[0][0].annotate('FIRST WAVE: ~45 DAYS', xy=(40, 80), xytext=(80, 88),\n            arrowprops=dict(facecolor='black', shrink=0.05))\n\nsns.lineplot(x=\"date\", y=\"new_cases\",data=Ger_process_df,ax =ax[0][1],color = 'g')\nax[0][1].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[0][1].tick_params(labelrotation = 45)\nax[0][1].annotate('FIRST WAVE: ~150 DAYS', xy=(320, 45000), xytext=(150, 48000),\n            arrowprops=dict(facecolor='black', shrink=0.05))\n\nsns.lineplot(x=\"date\", y=\"new_cases\",data=Slv_process_df,ax =ax[1][0],color = 'b')\nax[1][0].xaxis.set_major_locator(ticker.MultipleLocator(30)) \nax[1][0].tick_params(labelrotation = 45)\nax[1][0].annotate('FIRST WAVE: ~100 DAYS', xy=(300, 5500), xytext=(150, 6000),\n            arrowprops=dict(facecolor='black', shrink=0.05))","4adb0a1f":"fig = go.Figure(data=[go.Bar(name='Corona Positive', x=NZ_process_df['date'], y=NZ_process_df['new_cases_smoothed'],marker_color='#2fcc41'),\n                      go.Bar(name='Deaths', x=NZ_process_df['date'], y=NZ_process_df['new_deaths_smoothed'],marker_color='#FF0000')] )\n\nfig.update_layout(barmode='stack',width=1000, height=600)\nfig.update_traces(textposition='inside')\nfig.update_layout(title_text='Number of people tested and positive among them',plot_bgcolor='rgb(255,255,255)')\nfig.show()","46d7903f":"import sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import scale\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline","08923c75":"NZ_process_df_model = NZ_process_df.iloc[0:320]\nNZ_process_df_predict = NZ_process_df.iloc[320:]\n\nGer_process_df_model = Ger_process_df.iloc[0:320]\nGer_process_df_predict = Ger_process_df.iloc[320:]\n\nSlv_process_df_model = Slv_process_df.iloc[0:310]\nSlv_process_df_predict = Slv_process_df.iloc[310:]\n","0028f5ec":"y_data_NZ = NZ_process_df_model['new_cases_smoothed']      #new cases\nx_data_NZ = NZ_process_df_model[['total_cases','total_deaths', 'new_deaths', 'new_deaths_smoothed'\n  ,'new_tests', 'total_tests', 'new_tests_smoothed' , 'positive_rate', 'stringency_index']]\n\nx_train_NZ, x_test_NZ, y_train_NZ, y_test_NZ = train_test_split(x_data_NZ, y_data_NZ, test_size=0.22, random_state=0)\n\nprint(\"number of test samples :\", x_test_NZ.shape[0])\nprint(\"number of training samples:\",x_train_NZ.shape[0])\n#x_data.head(5)\n","683daa51":"y_data_ger = Ger_process_df_model['new_cases_smoothed']      #new cases\nx_data_ger = Ger_process_df_model[['total_cases','total_deaths', 'new_deaths', 'new_deaths_smoothed'\n  , 'total_tests', 'new_tests_smoothed' , 'positive_rate', 'stringency_index']]\n\nx_train_ger, x_test_ger, y_train_ger, y_test_ger = train_test_split(x_data_ger, y_data_ger, test_size=0.2, random_state=0)\n\nprint(\"number of test samples :\", x_test_ger.shape[0])\nprint(\"number of training samples:\",x_train_ger.shape[0])\nx_data_ger.head(5)","cd229fc3":"y_data_slv = Slv_process_df_model['new_cases_smoothed']      #new cases\nx_data_slv = Slv_process_df_model[['total_cases','total_deaths', 'new_deaths', 'new_deaths_smoothed'\n  , 'total_tests', 'new_tests_smoothed' , 'positive_rate', 'stringency_index']]\n\nx_train_slv, x_test_slv, y_train_slv, y_test_slv = train_test_split(x_data_slv, y_data_slv, test_size=0.2, random_state=0)\n\nprint(\"number of test samples :\", x_test_slv.shape[0])\nprint(\"number of training samples:\",x_train_slv.shape[0])\nx_data_slv.head(5)","cccdcbde":"lm_NZ = LinearRegression()\nlm_NZ.fit(x_train_NZ, y_train_NZ)\nY_hat_NZ=lm_NZ.predict(x_test_NZ)","b82d60e6":"lm_ger = LinearRegression()\nlm_ger.fit(x_train_ger, y_train_ger)\nY_hat_ger=lm_ger.predict(x_test_ger)","b033b3fb":"\nlm_slv = LinearRegression()\nlm_slv.fit(x_train_slv, y_train_slv)\nY_hat_slv=lm_slv.predict(x_test_slv)","49878f38":"print ('Coefficients: ', lm_NZ.coef_)\nprint ('Intercept: ' , lm_NZ.intercept_)\nprint(\"\\nR2 Score for New Zealand model\")\nprint('Train score :',lm_NZ.score(x_train_NZ, y_train_NZ))\nprint('Test score :', lm_NZ.score(x_test_NZ, y_test_NZ) )","88eae56e":"print ('Coefficients: ', lm_ger.coef_)\nprint ('Intercept: ' , lm_ger.intercept_)\nprint(\"\\nR2 Score for Germany model\")\nprint('Train score :',lm_ger.score(x_train_ger, y_train_ger))\nprint('Test score :', lm_ger.score(x_test_ger, y_test_ger) )","d9ba28b5":"\nprint ('Coefficients: ', lm_slv.coef_)\nprint ('Intercept: ' , lm_slv.intercept_)\nprint(\"\\nR2 Score for Slovakia model\")\nprint('Train score :',lm_slv.score(x_train_slv, y_train_slv))\nprint('Test score :', lm_slv.score(x_test_slv, y_test_slv) )","6f55d28e":"width = 12\nheight = 10\nplt.figure(figsize=(width, height))\n\nY_hat_NZ=lm_NZ.predict(x_train_NZ)\nax1 = sns.distplot(y_data_NZ, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(Y_hat_NZ, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n\n\nplt.title('Actual vs Fitted Values of New cases for New Zealand')\nplt.xlabel('New cases')\nplt.ylabel('Proportion of New cases')\n\nplt.show()\nplt.close()","642e460e":"width = 12\nheight = 10\nplt.figure(figsize=(width, height))\n\nY_hat_ger=lm_ger.predict(x_train_ger)\nax1 = sns.distplot(y_data_ger, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(Y_hat_ger, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n\n\nplt.title('Actual vs Fitted Values for New cases')\nplt.xlabel('New cases')\nplt.ylabel('Proportion of New cases')\n\nplt.show()\nplt.close()","9d9b036e":"width = 12\nheight = 10\nplt.figure(figsize=(width, height))\n\nY_hat_slv=lm_slv.predict(x_train_slv)\nax1 = sns.distplot(y_data_slv, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(Y_hat_slv, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n\n\nplt.title('Actual vs Fitted Values for New cases')\nplt.xlabel('New cases')\nplt.ylabel('Proportion of New cases')\n\nplt.show()\nplt.close()","07dbb18b":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\ncv = KFold(n_splits = 10, random_state = 1, shuffle = True)\nRc_NZ = cross_val_score(lm_NZ, x_train_NZ, y_train_NZ, cv = 10)\nprint(Rc_NZ)\nprint(\"The mean of the folds are\", Rc_NZ.mean(),\n      \"\\nand the standard deviation is\" , Rc_NZ.std())","4905aa72":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\ncv = KFold(n_splits = 10, random_state = 1, shuffle = True)\nRc_ger = cross_val_score(lm_ger, x_train_ger, y_train_ger, cv = 10)\nprint(Rc_ger)\nprint(\"The mean of the folds are\", Rc_ger.mean(),\n      \"\\nand the standard deviation is\" , Rc_ger.std())","726fcf69":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\ncv = KFold(n_splits = 10, random_state = 1, shuffle = True)\nRc_slv = cross_val_score(lm_slv, x_train_slv, y_train_slv, cv = 10)\nprint(Rc_slv)\nprint(\"The mean of the folds are\", Rc_slv.mean(),\n      \"\\nand the standard deviation is\" , Rc_slv.std())","f9402919":"#Prediction NZ for next 2 months\ny_data_predict_NZ = NZ_process_df_predict['new_cases_smoothed']      \nx_data_predict_NZ = NZ_process_df_predict[['total_cases','total_deaths', 'new_deaths', 'new_deaths_smoothed'\n  ,'new_tests', 'total_tests', 'new_tests_smoothed' , 'positive_rate', 'stringency_index']]\n\nY_hat_predict_NZ=lm_NZ.predict(x_data_predict_NZ)\nax1 = sns.distplot(y_data_predict_NZ, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(Y_hat_predict_NZ, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)","a255bf07":"def customLegend(fig, nameSwap):\n    for i, dat in enumerate(fig.data):\n        for elem in dat:\n            if elem == 'name':\n                fig.data[i].name = nameSwap[fig.data[i].name]\n    return(fig)\n\ncolumn_list = [NZ_process_df_predict['new_cases_smoothed'], Y_hat_predict_NZ]\nfig = px.line(NZ_process_df_predict, x=\"date\", y=column_list,\n              title='Actual vs Predicted New Cases for the 2nd wave for New Zealand', labels={\"date\": \"Date\", \"value\": \"New Cases\"})\n\nfig = customLegend(fig=fig, nameSwap = {'new_cases_smoothed': 'Actual_New_Cases', 'wide_variable_1':'Predicted_New_Cases'})\n\nfig.show()","92d04f16":"#Prediction Ger for next 2 months\ny_data_predict_ger = Ger_process_df_predict['new_cases_smoothed']      \nx_data_predict_ger = Ger_process_df_predict[['total_cases','total_deaths', 'new_deaths', 'new_deaths_smoothed'\n  , 'total_tests', 'new_tests_smoothed' , 'positive_rate', 'stringency_index']]\n\nY_hat_predict_ger=lm_ger.predict(x_data_predict_ger)\nax1 = sns.distplot(y_data_predict_ger, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(Y_hat_predict_ger, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)","ba55c59a":"column_list = [Ger_process_df_predict['new_cases_smoothed'], Y_hat_predict_ger]\nfig = px.line(Ger_process_df_predict, x=\"date\", y=column_list,\n              title='Actual vs Predicted for the 2nd wave for Germany', labels={\"date\": \"Date\", \"value\": \"New Cases\"})\n\nfig = customLegend(fig=fig, nameSwap = {'new_cases_smoothed': 'Actual_New_Cases', 'wide_variable_1':'Predicted_New_Cases'})\n\nfig.show()","ee2ebdea":" Here we import all the preprocessing and data visulization libraries","7b352386":"## Importing required Libraries","4d53ff8c":"## Exploratory Data Analysis","84f9795c":"The features used for model implementation were chosen after taking correlation statistics into consideration.","5ae0a251":"## Predicting New cases in New Zealand For Next 2 Months","2872bd56":"Interpretation:\n\nHere we can see that the First wave had the largest Time period in Germany(nearly 150 days) among all three countries\n","b08ca8ab":"## **CREATING A NEW DATAFRAME FOR THE NEW ZEALAND DATA**","bff96cf7":"### **Now we make a new data frame of only the important columns by dropping the others**","64362d04":"- ### R2 Score for Model Evaluation","0cc84230":"### **Here we get a uniform dataset having all columns of equal length**","ff37e033":"### Feature Selection for New Zealand","c8b54514":"Interpretation: Thus we see that our model is not overfitting","6c2ad57f":"### **Interpretation:  Here we see that the data that we have is daily starting from 31 Dec 2019 to 14 Mar 2021 for a total of 381 days**","31130931":"# 1 - PROJECT OVERVIEW\n\nThe novel respiratory infection disease we are collectively battling emerged last year in China and although it is still unknown exactly where the outbreak first started, many early cases of COVID-19 have been attributed to people who have visited the Huanan Seafood Wholesale Market, located in Wuhan, Hubei, China.\n\nThe earliest known person with symptoms was later discovered to have fallen ill on 1 December 2019, and that person did not have visible connections with the later wet market cluster. Of the early cluster of cases reported that month, two thirds were found to have a link with the market.\n\nAt present, humanity continues to fight the global epidemic, weapons in the form of vaccines against the virus have been developed in various countries, and mass vaccination of the entire population of the planet is underway.\n\n- The purpose of this work is to tell the story of how the struggle of the people with an mysterious virus that has claimed millions of human lives all over the world is going on.\n\n- Perform Exploratory Data Analysis and provide meaningful insights.\n\n- Build a Machine Learning Model to predict the new cases during the Second wave of Coronavirus.\n\n- Build a Basic COVID-19 Dashboard to try and present your work in an Interactive way.\n","d6272f74":"## **IMPORTANT variables:**\n\n* new_tests_smoothed\n\n* new_cases_smoothed\n\n* new_deaths_smoothed","6e4da0f7":"Interpretation:\n\nFrom the above results we see that our mean R^2 values for all 3 countries after performing cross validation are 91%, 93%, 94% resp. which suggests that our model is not overfitted.","9945bce5":"# Part-II  Model Development","d7748378":"**Replacing the NULL values upto the first NON-NULL value with zero**","31bf9143":"- ### Distribution Plot for Model Evaluation","c1e4143e":" # Conclusion:\n1.  Earlier implementation of Agent based Model for predicting the New Cases in New Zealand was tried, but due to lack of Features required for ABM implementation in currently available datasets and lack of resources for Implementation of Agent Based Modelling we shifted our focus on Implementing Multivariate Linear Regression.\n2. A detailed Exploratory Data Analysis was performed on the New Zealand Covid-19 data and prediction of new cases during 2nd wave was done by using Multi-Variate Linear Regression Model.\n3. Further the model was evaluated using different evaluation metrices and was tested for different countries as well.(such as Germany, Slovakia) \n4. Then the Prediction of new covid 19 cases in New Zealand & Germany during 2nd wave(i.e Last 2 months of our dataset) was done.","9a9c54c1":"# **We observe that:**\n\n1. Corona peak hit the New Zealand in March-end\n\n2. Corona Tests per day was maximum in Mid-August\n\n3. Total Corona cases are nearly 1500 in New Zealand uptil Mid October\n\n4. Total tests done are nearly 1M","601a65fe":"Interpretation:\n\nWe observe that there were many deaths in March-April whereas the situation was nealy under control during the period of May-Jul.","de6cfc4c":"**Interpretation**: \n* Thus, from the above graph we see that the predicted new cases for the 2nd wave in Germany starting from 12 Dec 2020 to 14 March 2021 are a close estimate to the Actual new cases","29e744c3":"## **K-Folds CROSS VALIDATION**","19444222":"Interpretation: ","6deca825":"# Time Period of First wave in New Zealand, Slovakia and Germany","e86f5ab0":"## Handling Missing Value","9c85806a":"Interpretation: \nHere we see that features such as total_vaccinations, people_vaccinated, icu_patients_per_million,           \nweekly_hosp_admissions, new_vaccinations , handwashing_facilities, extreme_poverty have all values NULL.       \n","0cc164d4":"## Loading the Dataset","729b112f":"## Model Evaluation","273afd82":"## Feature Selection & Data splitting for First 8 months ","cd89c7da":"# **Plotting the correlation matrix**","1f46738a":"## Model Training \n\n     \n","50bb58a0":"About Dataset:\n \n* #### We used 2 different datasets are used:<br\/>\n- Time series Comprehensive Covid-19 data of the World available at ourworldindata.org was used.\n-  Mobility Data of New Zealand from \"COVID-19 Community Mobility Reports\" provided by google.\n\n\nCountry Used for Analysis:<br\/>\n     Before moving to rigorous analysis of a particular country, New Zealand Covid Data seemed to be interesting and it was confirmed after performing Exploratory Data Analysis hence we choosed New Zealand was choosen as a Test Case.","73db5378":"### Feature Selection for Germany","d35491db":"# **Few insights from the Data**\nTime series plots for some important varibles","f0747af1":"- ## Methodology Used:\n- First we tried implementing Agent based Model for predicing the New Cases in New Zealand, but due to insufficient data about the pandemic, time constraints and lack of resources for Implementation of Agent Based Modelling we shifted our focus on Implementing Multivariate Linear Regression.\n- We divided the dataset into two parts\n    >>- Nearly 10 months for Model Development\n    >> - Last 2 months for Predicting the impact of coronavirus and the number of new cases per day.\n- Further Model Evaluation was done by using \n    >> - R2 score,MSE, MAE\n    >> - Distribution plot of Actual vs Predicted cases \n    >> - Comparison of Predicted new cases vs Actual New Cases for Last 2 months.","6637c580":"**Interpretation:** \n* We can see from the above graph that the predicted new cases for the 2nd wave in New Zealand starting from 13 Jan 2021 to 14 March 2021 are a close estimate to the Actual new cases.\n* As New Zealand does not have a significant 2nd wave as compared to other countries, the predicted values are slightly deviated from the actual results.","e4b45cd9":"Interpretation:\n* We see that New Zealand has done nearly 0-5K tests per day for nearly 150 days out of 290 days.","e84f6f68":"## Predicting New cases in Germany For Next 2 Months","186e9ac6":"### Feature Selection for Slovakia"}}