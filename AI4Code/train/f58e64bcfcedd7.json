{"cell_type":{"8ec4d223":"code","23827e55":"code","5de9c638":"code","2102cd75":"code","11e641dc":"code","fff3cf95":"code","76bf9f8e":"code","a7efde4d":"code","8d3f2684":"code","84bb7c3d":"code","762ef1a6":"code","04c02db8":"code","b512f080":"code","097bb1fc":"code","3926f2ef":"code","dfe6ea4a":"code","ab98f590":"code","e49730bf":"code","aa25ed05":"code","5d58c5cd":"code","69bf597c":"code","9a45a16f":"code","52fdcd76":"code","07d49834":"code","e45c9e86":"code","1fb317b3":"code","29a31a3f":"code","0ab11d2c":"code","0dbe2f04":"code","0b7f6c5c":"code","6370d1e9":"code","357df52b":"code","cd89f476":"code","799036fb":"code","dc96b081":"code","3702172f":"code","a9cc4885":"code","68f6f05c":"code","728d90d8":"code","d6f6743b":"code","6adb2309":"code","d006683f":"code","d15f6e63":"code","236e0754":"code","a28c7050":"code","fd007ff6":"code","a740c13e":"code","0860f33b":"code","fbc1b3d7":"code","ec5b9691":"code","f985a806":"code","363f8298":"code","0f2de09f":"code","b235c90b":"code","fa74643a":"code","5af106c4":"code","d9709334":"code","78ce4aad":"code","e75c84d2":"code","990ce9e0":"code","cc628153":"code","a3de5c00":"code","b02b5b39":"code","6835d98c":"code","aa5acd14":"code","9afc8028":"code","45f17b72":"code","88e29bd8":"code","9bd782ce":"code","468503fd":"code","21796186":"code","53409d6b":"code","5e34bf4a":"code","bccda5db":"code","46228d86":"code","52b93715":"code","64c5d7ae":"markdown","2a9fed5d":"markdown","eb79a812":"markdown","8ee59f45":"markdown","d74cff0b":"markdown","c7a3307e":"markdown","fe3f83c7":"markdown","fd659e79":"markdown","100d90ff":"markdown","bde7dd6c":"markdown","188c8cf4":"markdown","84106a83":"markdown","f73bdea2":"markdown","1ff031e3":"markdown","cb7b22d1":"markdown","cd7e52a6":"markdown","25c5500c":"markdown","20256789":"markdown","5c0da904":"markdown","9c7ddf60":"markdown","2613cf5b":"markdown","5d6b1431":"markdown"},"source":{"8ec4d223":"# Get File\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","23827e55":"#downgrading colab \n!pip install -r \"requirements.txt\"","5de9c638":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2102cd75":"import warnings\nwarnings.filterwarnings(\"ignore\")","11e641dc":"df = pd.read_csv('\/kaggle\/input\/kiit-counselling-dataset\/Branch_Allocation_Final.csv',error_bad_lines=False) ","fff3cf95":"df","76bf9f8e":"sns.pairplot(df)","a7efde4d":"df['Nationality'].unique()","8d3f2684":"df.info()","84bb7c3d":"df.describe()","762ef1a6":"x = df.iloc[:,:5]","04c02db8":"x","b512f080":"y=df.iloc[:,-1]","097bb1fc":"type(y)","3926f2ef":"#encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder\nl = LabelEncoder()\nx.iloc[:,-1]=l.fit_transform(x.iloc[:,-1])           #gender\ny.iloc[:] = l.fit_transform(y.iloc[:])             #department  \nx.iloc[:,1] = l.fit_transform(x.iloc[:,1])         #nationality","dfe6ea4a":"x","ab98f590":"y","e49730bf":"def change(row):\n    if row['12th'] >= 65 and row['10th'] >= 75:\n      return 1\n    else:\n      return 0","aa25ed05":"#adding admission column\nx['Adm']=x.apply(change,axis=1)","5d58c5cd":"x","69bf597c":"x.head(5)","9a45a16f":"from sklearn.preprocessing import StandardScaler\nsc= StandardScaler()\nx = sc.fit_transform(x)","52fdcd76":"x","07d49834":"y.shape","e45c9e86":"y=y.values.reshape(-1,1)","1fb317b3":"#splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y ,test_size = 0.25, random_state = 0, shuffle = True)","29a31a3f":"x_train.shape, y_train.shape","0ab11d2c":"x_test.shape, y_test.shape","0dbe2f04":"from sklearn import utils\nprint(utils.multiclass.type_of_target(x_train.astype('int')))","0b7f6c5c":"#fitting random forest classifier to the training set\nfrom sklearn.ensemble import RandomForestClassifier as rfc\nclassifier = rfc(n_estimators=100,criterion='entropy',random_state=0)\nclassifier.fit(x_train, y_train)","6370d1e9":"#predicting the test set results\ny_pred=classifier.predict(x_test)","357df52b":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","cd89f476":"print(classification_report(y_test, y_pred))","799036fb":"#applying k-fold cross validation\nfrom sklearn.model_selection import cross_val_score as cvs\naccuracies = cvs(estimator=classifier,X=x_train,y=y_train,cv=10)\nprint(accuracies.mean())\nprint(accuracies.std())","dc96b081":"#fitting logistic regression to the training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier.fit(x_train, y_train)","3702172f":"#predicting the test set results\ny_pred=classifier.predict(x_test)","a9cc4885":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","68f6f05c":"print(classification_report(y_test, y_pred))","728d90d8":"#applying k-fold cross validation\nfrom sklearn.model_selection import cross_val_score as cvs\naccuracies = cvs(estimator=classifier,X=x_train,y=y_train,cv=10)\nprint(accuracies.mean())\nprint(accuracies.std())","d6f6743b":"#fitting kernel SVM to the training set\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='rbf', random_state=0)\nclassifier.fit(x_train, y_train)","6adb2309":"#predicting the test set results\ny_pred=classifier.predict(x_test)","d006683f":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","d15f6e63":"print(classification_report(y_test, y_pred))","236e0754":"#applying k-fold cross validation\nfrom sklearn.model_selection import cross_val_score as cvs\naccuracies = cvs(estimator=classifier,X=x_train,y=y_train,cv=10)\nprint(accuracies.mean())\nprint(accuracies.std())","a28c7050":"#fitting kernel SVM to the training set\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel='linear', random_state=0)\nclassifier.fit(x_train, y_train)","fd007ff6":"#predicting the test set results\ny_pred=classifier.predict(x_test)","a740c13e":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","0860f33b":"print(classification_report(y_test, y_pred))","fbc1b3d7":"#applying k-fold cross validation\nfrom sklearn.model_selection import cross_val_score as cvs\naccuracies = cvs(estimator=classifier,X=x_train,y=y_train,cv=10)\nprint(accuracies.mean())\nprint(accuracies.std())","ec5b9691":"from sklearn.neighbors import KNeighborsClassifier as knc\nclassifier=knc(n_neighbors=10,metric='minkowski',p=2)\nclassifier.fit(x_train, y_train)","f985a806":"#predicting the test set results\ny_pred=classifier.predict(x_test)","363f8298":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","0f2de09f":"print(classification_report(y_test, y_pred))","b235c90b":"#applying k-fold cross validation\nfrom sklearn.model_selection import cross_val_score as cvs\naccuracies = cvs(estimator=classifier,X=x_train,y=y_train,cv=10)\nprint(accuracies.mean())\nprint(accuracies.std())","fa74643a":"#fitting decision tree classifier to the training set\nfrom sklearn.tree import DecisionTreeClassifier as dtc\nclassifier = dtc(criterion='entropy' , random_state=0)\nclassifier.fit(x_train, y_train)","5af106c4":"#predicting the test set results\ny_pred=classifier.predict(x_test)","d9709334":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","78ce4aad":"print(classification_report(y_test, y_pred))","e75c84d2":"#applying k-fold cross validation\nfrom sklearn.model_selection import cross_val_score as cvs\naccuracies = cvs(estimator=classifier,X=x_train,y=y_train,cv=10)\nprint(accuracies.mean())\nprint(accuracies.std())","990ce9e0":"#fitting naive bayes to the training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)","cc628153":"#predicting the test set results\ny_pred=classifier.predict(x_test)","a3de5c00":"from sklearn.metrics import confusion_matrix, classification_report\n\ncm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm, annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","b02b5b39":"print(classification_report(y_test, y_pred))","6835d98c":"#applying k-fold cross validation\nfrom sklearn.model_selection import cross_val_score as cvs\naccuracies = cvs(estimator=classifier,X=x_train,y=y_train,cv=10)\nprint(accuracies.mean())\nprint(accuracies.std())","aa5acd14":"#fitting decision tree classifier to the training set\nfrom sklearn.tree import DecisionTreeClassifier as dtc\nclassifier = dtc(criterion='entropy', random_state=0)\nclassifier.fit(x_train, y_train)","9afc8028":"#applying grid search to find the best model and best parameters\nfrom sklearn.model_selection import GridSearchCV as gsv\nparameters = [{'splitter':['best','random'],'criterion':['entropy','gini'],'max_depth':['None',2,4,6]}]\ngrid_search=gsv(estimator=classifier,\n                param_grid=parameters,\n                scoring='accuracy',\n                cv=10,\n                n_jobs=1)\ngrid_search=grid_search.fit(x_train,y_train)\nprint('best_accuracy=',grid_search.best_score_)\nprint('best_parameters=',grid_search.best_params_)","45f17b72":"#fitting decision tree classifier to the training set\nfrom sklearn.tree import DecisionTreeClassifier as dtc\nclassifier = dtc(criterion='entropy' ,random_state=0, splitter='best', max_depth=4)\nclassifier.fit(x_train, y_train)","88e29bd8":"#predicting the test set results\ny_pred=classifier.predict(x_test)","9bd782ce":"cm=confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (10,10))\nsns.heatmap(cm, annot=True)","468503fd":"#observating classification report for performance evaluation\nprint(classification_report(y_test, y_pred))","21796186":"import pickle\nfilename = 'branch_allocation.sav'\npickle.dump(dtc, open(filename, 'wb'))","53409d6b":"from sklearn.pipeline import Pipeline","5e34bf4a":"pipe = Pipeline([('standard', StandardScaler()),\n                    #('boxcox'), stats.boxcox()),\n                    ('l-svm', dtc())])","bccda5db":"pipe.fit(x_train, y_train)","46228d86":"score = pipe.score(x_test, y_test)\nprint('Decision Tree pipeline test accuracy: %.3f' % score)","52b93715":"!pip freeze > requirements.txt","64c5d7ae":"Therefore, Best Parameters = {'criterion': 'entropy', 'max_depth': 4, 'splitter': 'best'}","2a9fed5d":"# 10. Creating a ML Pipeline","eb79a812":"Naive Bayes","8ee59f45":"Modeling","d74cff0b":"# 9. Saving the Model","c7a3307e":"# 1. Importing Libaries and Dataset","fe3f83c7":"# Enhanced-Analytic-System-for-Smart-University-Assistance\nName - Rahul Bordoloi                                         \nRoll No - 1729048                                           \nProject Name - Be-Friend      \nGithub Repo -  [Link](https:\/\/github.com\/rahulbordoloi\/Enhanced-Analytic-System-for-Smart-University-Assistance\/)                  \nEmail - rahulbordoloi24@gmail.com, 1729048@kiit.ac.in                          \nLanguage - Python                      \nProject is Done on Google Colab.                      ","fd659e79":"# 4. Splitting Train into x_train\/y_train","100d90ff":"# 11. Generating Requirements File","bde7dd6c":"# End","188c8cf4":"# Hyperparameter Tuning","84106a83":"# 2. Visualising the Data","f73bdea2":"*   Libraries Pre-requisites -  [requirements.txt](https:\/\/drive.google.com\/file\/d\/1IPznNDrrz_7DHokUfSML4lq4hAPmyEcI\/view?usp=sharing)        \n\n*   Download Pre-loaded Model -  [Pickle Link](https:\/\/drive.google.com\/file\/d\/1q0_bDgkY8V8fkADRffcBShXkh3MWs8Ex\/view?usp=sharing)\n\n\nTo install , download the file and run -\n```\n!pip install -r requirements.txt\n```\n*   RAM of 8GB is preferred if run on Local.\n\n\n\n\n\n","1ff031e3":"Linear SVM","cb7b22d1":"# 5. Model Testing for Best Results","cd7e52a6":"Logistic Regression","25c5500c":"K-NN","20256789":"Random Forest","5c0da904":"# 3. Data Preprocessing","9c7ddf60":"Therefore Final Evaluation will be done with Decision Tree as its                 \nMean Accuracy = 0.9911111111111112                            \nMean Std. Dev = 0.014740554623801772, is highest amongst all the classifiers.","2613cf5b":"Kernel SVM","5d6b1431":"Decision Tree"}}