{"cell_type":{"05d94063":"code","d25bdf16":"code","19313218":"code","fe11fc7f":"code","094f597a":"code","d8f3f622":"code","24ea8b8d":"code","872e3a17":"code","abea83ee":"code","81c04a46":"code","797e56fa":"code","f040ee0d":"code","92e93703":"code","3e77b427":"code","807c858b":"code","004e77c3":"code","0cf37934":"code","cbdd1095":"code","782bded9":"code","5e77f20f":"code","c40b363f":"code","f3e9b77b":"code","e8853818":"code","272da765":"code","22c6f562":"code","a3b801d8":"code","f76940b6":"code","6ac8f372":"code","b2b1e569":"code","9d193d5f":"code","62d00f68":"markdown","562851a3":"markdown","5a045f1d":"markdown","aa91cad0":"markdown","81fae124":"markdown","a2762ce9":"markdown","a56eac12":"markdown","87dbb393":"markdown","1ca33b21":"markdown","0484ca37":"markdown","b779ee4d":"markdown","4b31ba26":"markdown","5dd1e2e9":"markdown","b92903b3":"markdown","67a26296":"markdown","148830d5":"markdown","26ed678e":"markdown","b48456e3":"markdown","6ad964a6":"markdown","5a86df9e":"markdown","73c7b1a8":"markdown","8573972c":"markdown","a0271b5d":"markdown","8a498c64":"markdown","681edad7":"markdown","2a7db9c4":"markdown","b9162862":"markdown","85747bb0":"markdown","88759080":"markdown","012e17ea":"markdown","309bce5d":"markdown","47a8e731":"markdown","241cf29b":"markdown","2dcffdb7":"markdown"},"source":{"05d94063":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#To select the test-train set, metrics etc.\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\nfrom imblearn.over_sampling import SMOTE\n\n#Our models\nfrom sklearn.ensemble import RandomForestClassifier #\nfrom xgboost import XGBClassifier \nfrom lightgbm import LGBMClassifier\nfrom sklearn import tree\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression #\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\n#Ignore the warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","d25bdf16":"hr=pd.read_csv(\"\/kaggle\/input\/employee-attrition-data\/MFG10YearTerminationData.csv\")","19313218":"hr.head()","fe11fc7f":"hr_terminated = hr[hr.STATUS=='TERMINATED'].reset_index()","094f597a":"hr_active=hr.copy()\ncond=hr_active['EmployeeID'].isin(hr_terminated['EmployeeID'])\nhr_active.drop(hr_active[cond].index, inplace = True)\nhr_active = hr_active.drop_duplicates(subset=\"EmployeeID\", keep=\"last\",inplace=False).reset_index()","d8f3f622":"hr_terminated = hr_terminated.drop(['index','EmployeeID', 'birthdate_key', 'recorddate_key', 'gender_full'], axis=1) # we don't need any of them\nhr = hr.drop(['EmployeeID', 'birthdate_key', 'recorddate_key', 'gender_full'], axis=1) # we don't need any of them\nhr_active = hr_active.drop(['index','EmployeeID', 'birthdate_key', 'recorddate_key', 'gender_full'], axis=1) # we don't need any of them\n\nhr_terminated.head()","24ea8b8d":"print(hr.city_name.unique())\nprint('\\n')\nprint(hr.job_title.unique())\nprint('\\n')\nprint(hr.department_name.unique())","872e3a17":"board = ['CEO','VP Stores', 'Director, Recruitment', 'VP Human Resources', 'VP Finance',\n         'Director, Accounts Receivable', 'Director, Accounting',\n         'Director, Employee Records', 'Director, Accounts Payable',\n         'Director, HR Technology', 'Director, Investments',\n         'Director, Labor Relations', 'Director, Audit', 'Director, Training',\n         'Director, Compensation']\nexecutive = [ 'Exec Assistant, VP Stores', 'Exec Assistant, Legal Counsel',\n 'CHief Information Officer', 'Exec Assistant, Human Resources', 'Exec Assistant, Finance']\n\nmanager = ['Customer Service Manager', 'Processed Foods Manager', 'Meats Manager',\n           'Bakery Manager', 'Produce Manager', 'Store Manager', 'Trainer', 'Dairy Manager']\n\nemployee = ['Meat Cutter', 'Dairy Person', 'Produce Clerk', 'Baker', 'Cashier',\n            'Shelf Stocker', 'Recruiter', 'HRIS Analyst', 'Accounting Clerk',\n            'Benefits Admin', 'Labor Relations Analyst', 'Accounts Receiveable Clerk',\n            'Accounts Payable Clerk', 'Auditor', 'Compensation Analyst',\n            'Investment Analyst', 'Systems Analyst', 'Corporate Lawyer', 'Legal Counsel']\n\ndef apply(job):\n    if job in board: return 'board'\n    if job in executive: return 'executive'\n    if job in manager: return 'manager'\n    if job in employee: return 'employee'\n    \nfor i in range(0,hr_terminated.shape[0]):\n    hr_terminated.at[i,'job_title'] = apply(hr_terminated.iloc[i]['job_title'])\n\nfor i in range(0,hr_active.shape[0]):\n    hr_active.at[i,'job_title'] = apply(hr_active.iloc[i]['job_title'])\n\nfor i in range(0,hr.shape[0]):\n    hr.at[i,'job_title'] = apply(hr.iloc[i]['job_title'])","abea83ee":"# I borrowed the population from another notebook(reference given at the bottom). Hope he doesnt mind :-)\n\ncity_pop_2020 = {'Vancouver':2313328,\n                 'Victoria':289625,\n                 'Nanaimo':84905,\n                 'New Westminster':58549,\n                 'Kelowna':125109,\n                 'Burnaby':202799,\n                 'Kamloops':68714,\n                 'Prince George':65558,\n                 'Cranbrook':18610,\n                 'Surrey':394976,\n                 'Richmond':182000,\n                 'Terrace':19443,\n                 'Chilliwack':77000,\n                 'Trail':9707,\n                 'Langley':23606,\n                 'Vernon':47274,\n                 'Squamish':19512,\n                 'Quesnel':13799,\n                 'Abbotsford':151683,\n                 'North Vancouver':48000,\n                 'Fort St John':17402,\n                 'Williams Lake':14168,\n                 'West Vancouver':42694,\n                 'Port Coquitlam':114565,\n                 'Aldergrove':12363,\n                 'Fort Nelson':3561,\n                 'Nelson':9813,\n                 'New Westminister':58549,\n                 'Grand Forks':4049,\n                 'White Rock':66450,\n                 'Haney':82256,\n                 'Princeton':2828,\n                 'Dawson Creek':10802,\n                 'Bella Bella':1019,\n                 'Ocean Falls':129,\n                 'Pitt Meadows':174410,\n                 'Cortes Island':1042,\n                 'Valemount':1021,\n                 'Dease Lake':335,\n                 'Blue River':157}\n\ndef city(pop):\n    str = 'rural'\n    if (pop>=10000) & (pop<100000): str = 'town'\n    if pop>=100000: str = 'mega'\n    return str\n\ntemp = hr_terminated['city_name'].map(city_pop_2020)\ntemp2 = hr_active['city_name'].map(city_pop_2020)\ntemp3 = hr['city_name'].map(city_pop_2020)\n\nfor i in range(0,hr_terminated.shape[0]):\n    hr_terminated.at[i,'city_name'] = city(temp[i])\nfor i in range(0,hr_active.shape[0]):\n    hr_active.at[i,'city_name'] = city(temp2[i])\nfor i in range(0,hr.shape[0]):\n    hr.at[i,'city_name'] = city(temp3[i])","81c04a46":"hr_terminated.head()","797e56fa":"plt.bar([\"Terminated\", \"Active\"],[hr_terminated.shape[0], hr_active.shape[0]], color = '#cf6f2b')\nplt.xlabel(\"Employees\")\nplt.ylabel(\"Count\")\nplt.title(\"Working Status\")\nplt.show()","f040ee0d":"fig = plt.figure(figsize = (20, 10))\n\nplt.subplot(221)\nsns.set_style('white')\nplt.title('age', size = 14)\nsns.kdeplot(hr_terminated['age'], color = '#32384D', shade = True, label = 'terminated', alpha = 0.5)\nsns.kdeplot(hr_active['age'], color = '#E29930', shade = True, label = 'active', alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\nplt.legend(loc = 'upper left')\n\nplt.subplot(222)\nsns.set_style('white')\nplt.title('length_of_service', size = 14)\nsns.kdeplot(hr_terminated['length_of_service'], color = '#32384D', shade = True, label = 'terminated', alpha = 0.5)\nsns.kdeplot(hr_active['length_of_service'], color = '#E29930', shade = True, label = 'active', alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\nplt.legend(loc = 'upper left')\n\nplt.subplot(223)\nsns.set_style('white')\nplt.title('STATUS_YEAR', size = 14)\nsns.distplot(hr_terminated,x=hr_terminated['STATUS_YEAR'], color = '#32384D', label = 'terminated')\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\nplt.legend(loc = 'upper left')\n\n\nplt.subplot(224)\nsns.set_style('white')\nplt.title('store_name', size = 14)\nsns.distplot(hr_terminated,x=hr_terminated['store_name'], color = '#32384D', label = 'terminated', kde=False)\nsns.distplot(hr_active,x=hr_active['store_name'], color = '#E29930', label = 'terminated', kde=False)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\nplt.legend(loc = 'upper left')\nplt.show()","92e93703":"le = preprocessing.LabelEncoder()\nle.fit(hr.city_name.unique())\nhr.city_name=le.transform(hr.city_name)\nhr_active.city_name = le.transform(hr_active.city_name)\nhr_terminated.city_name=le.transform(hr_terminated.city_name)\n\n'''keys=le.classes_\nvalues = le.transform(le.classes_)\ndictionary = dict(zip(keys, values))\nprint(dictionary)'''\n\nle.fit(hr.job_title.unique())\nhr.job_title=le.transform(hr.job_title)\nhr_active.job_title = le.transform(hr_active.job_title)\nhr_terminated.job_title=le.transform(hr_terminated.job_title)\n\n'''keys=le.classes_\nvalues = le.transform(le.classes_)\ndictionary = dict(zip(keys, values))\nprint(dictionary)'''\n\nle.fit(hr.termreason_desc.unique())\nhr.termreason_desc=le.transform(hr.termreason_desc)\nhr_active.termreason_desc = le.transform(hr_active.termreason_desc)\nhr_terminated.termreason_desc=le.transform(hr_terminated.termreason_desc)\n\n'''keys=le.classes_\nvalues = le.transform(le.classes_)\ndictionary = dict(zip(keys, values))\nprint(dictionary)'''\n\nle.fit(hr.termtype_desc.unique())\nhr.termtype_desc=le.transform(hr.termtype_desc)\nhr_active.termtype_desc = le.transform(hr_active.termtype_desc)\nhr_terminated.termtype_desc=le.transform(hr_terminated.termtype_desc)\n\n'''keys=le.classes_\nvalues = le.transform(le.classes_)\ndictionary = dict(zip(keys, values))\nprint(dictionary)'''\n\nle.fit(hr.STATUS.unique())\nhr.STATUS=le.transform(hr.STATUS)\nhr_active.STATUS = le.transform(hr_active.STATUS)\nhr_terminated.STATUS=le.transform(hr_terminated.STATUS)\n\n'''keys=le.classes_\nvalues = le.transform(le.classes_)\ndictionary = dict(zip(keys, values))\nprint(dictionary)'''\n\nle.fit(hr.BUSINESS_UNIT.unique())\nhr.BUSINESS_UNIT=le.transform(hr.BUSINESS_UNIT)\nhr_active.BUSINESS_UNIT = le.transform(hr_active.BUSINESS_UNIT)\nhr_terminated.BUSINESS_UNIT=le.transform(hr_terminated.BUSINESS_UNIT)\n\n'''keys=le.classes_\nvalues = le.transform(le.classes_)\ndictionary = dict(zip(keys, values))\nprint(dictionary)'''\n\nle.fit(hr.department_name.unique())\nhr.department_name=le.transform(hr.department_name)\nhr_active.department_name = le.transform(hr_active.department_name)\nhr_terminated.department_name=le.transform(hr_terminated.department_name)\n\n'''keys=le.classes_\nvalues = le.transform(le.classes_)\ndictionary = dict(zip(keys, values))\nprint(dictionary)'''\n\nle.fit(hr.gender_short.unique())\nhr.gender_short=le.transform(hr.gender_short)\nhr_active.gender_short = le.transform(hr_active.gender_short)\nhr_terminated.gender_short=le.transform(hr_terminated.gender_short)\n\n'''keys=le.classes_\nvalues = le.transform(le.classes_)\ndictionary = dict(zip(keys, values))\nprint(dictionary)'''","3e77b427":"hr_final=pd.concat([hr_active, hr_terminated]).reset_index()","807c858b":"hr_corr=hr_final.corr()\nplt.figure(figsize=(13, 10))\nsns.heatmap(hr_corr, annot = True, cmap = 'YlOrBr', fmt=\".2f\",\n            vmin = -1, vmax = 1, linewidths = 0.1, linecolor = 'white', cbar = False)\nplt.show()","004e77c3":"hr_corr.abs()['STATUS'].sort_values(ascending=False)","0cf37934":"hr_final=hr_final.drop(['termreason_desc', 'termtype_desc', 'index', 'orighiredate_key', 'terminationdate_key'], axis=1)","cbdd1095":"y=hr_final.STATUS\nhr_final=hr_final.drop('STATUS', axis=1)","782bded9":"hr_final.head() #looks so clean, doesn't it?","5e77f20f":"X_train, X_test, y_train, y_test = train_test_split(hr_final, y, test_size = 0.2, random_state = 2021)\n\nsmote = SMOTE()\nX_train, y_train = smote.fit_resample(X_train, y_train)\ny_train.value_counts()","c40b363f":"results = pd.DataFrame(columns = ['LR', 'RF','KNC' ,'XGB', 'LGBM', 'CB', \"SVC\"], index = range(4))","f3e9b77b":"def ourmodel(model, X_train, X_test, y_train, y_test, i):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_prob = model.predict_proba(X_test)[:,1]\n\n    # Metrics\n    model_cm = confusion_matrix(y_test, y_pred)\n    results.iloc[0, i] = round(precision_score(y_test, y_pred), 2)\n    results.iloc[1, i] = round(recall_score(y_test, y_pred), 2)\n    results.iloc[2, i] = round(f1_score(y_test, y_pred), 2)\n    results.iloc[3, i] = round(roc_auc_score(y_test, y_prob), 3)\n\n    print(classification_report(y_test, y_pred))\n    print(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\n    print('')\n    print('-----------------------------------------------------')\n    print('')\n    print('Cross-validation scores with 5 folds:')\n    print('')\n    print(f\"ROC AUC: {round(cross_val_score(model, X_train, y_train, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\n    print(f\"precision: {round(cross_val_score(model, X_train, y_train, cv = 5, scoring = 'precision').mean(), 3)}\")\n    print(f\"recall: {round(cross_val_score(model, X_train, y_train, cv = 5, scoring = 'recall').mean(), 3)}\")\n    print(f\"f1: {round(cross_val_score(model, X_train, y_train, cv = 5, scoring = 'f1').mean(), 3)}\")\n\n    # Visualize confusion matrix\n    plt.figure(figsize = (14, 5))\n    plt.subplot(121)\n    sns.heatmap(model_cm, cmap = 'YlOrBr', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},\n               yticklabels = ['Not looking for job change', 'Looking for job change'], xticklabels = ['Predicted not looking for job change', 'Predicted looking for job change'])\n    plt.yticks(rotation = 0)\n\n    # Roc curve\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    \n    plt.subplot(122)\n    sns.set_theme(style = 'white')\n    plt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\n    plt.axis('tight')\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","e8853818":"#logistic regression model\nlr=LogisticRegression()\nourmodel(lr, X_train, X_test, y_train, y_test, 0)","272da765":"#random forest classifier model\nrfc=RandomForestClassifier(random_state = 2021, max_depth = 5)\nourmodel(rfc, X_train, X_test, y_train, y_test, 1)","22c6f562":"#k nieghbour classifier\nknc = KNeighborsClassifier()\nourmodel(knc, X_train, X_test, y_train, y_test, 2)","a3b801d8":"# xgboost classifier\nxgbc = XGBClassifier(random_state=2021, eval_metric= 'error')\nourmodel(xgbc, X_train, X_test, y_train, y_test, 3)","f76940b6":"# light gbm classifier\nlgbm=LGBMClassifier(random_state=2021)\nourmodel(lgbm, X_train, X_test, y_train, y_test, 4)","6ac8f372":"#cat boost(categorical boost) classifier\ncbc = CatBoostClassifier(random_state = 2021, depth = 5, iterations = 500, verbose = False)\nourmodel(cbc, X_train, X_test, y_train, y_test, 5)","b2b1e569":"svc = SVC(kernel='linear', C = 1.0, probability = True)\nourmodel(svc, X_train, X_test, y_train, y_test, 6)","9d193d5f":"plt.figure(figsize = (10, 7))\nsns.heatmap(results[results.columns.to_list()].astype(float), cmap = 'YlOrBr', annot = True, linewidths = 1, cbar = False, annot_kws = {'fontsize': 12},\n           yticklabels = ['Precision', 'Recall', 'F1', 'ROC AUC'])\nsns.set(font_scale = 1.5)\nplt.yticks(rotation = 0)\nplt.show()","62d00f68":"Now, let us create a dataset which contains both active and terminated data","562851a3":"# Hello Guys\nThis notebook consists of exploratory data analysis of the dataset and non sequential prediction of the status of the employees(Whether he\/she is still active or terminated from the company) through Non-Sequential Models (NSMs)\n\nHere, we have tested following models for our evaluation and then compared their results.\n\nThough this is still a work in progress, I would appriciate suggestions or a constructive feedback regarding my effort. \nPlease do upvote if you find my Notebook helpful. Thank You!\n**-Harit Gedia**\n\nIndex:-\n\n* [Importing the libraries](#1-import-libraries)\n* [Cleaning the data](#2-Let-us-First-clean-the-data)\n    * [Removing the irrelavant rows and seperating the data](#10)\n    * [Removing the irrelavant coloumns](#22)\n    * [Categorizing the features](#23)    \n* [Plotting the data](#3)\n    * [Deduction](#32)\n* [Preparing the dataset for modelling](#4)\n    * [Using Lable encoder for Categorical Variables](#42)\n    * [Building a correlation matrix](#5)\n    * [Further removing more useless data](#52)\n* [Applying the models(+ Oversampling)](#6)\n    * [Creating a common modelling function](#62)\n    * [Creating a result table](#63)\n    * [Logistic Regression](#64)\n    * [Random Forest Classifier](#65)\n    * [K- Neighbour Classifier](#66)\n    * [XGBoost Classifier](#67)\n    * [LightGBM Classifier](#68)\n    * [Categorical Boost Classifier](#69)\n    * [SVC Classifier](#70)\n* [Results](#71)","5a045f1d":"Now, Let us change the city names into the categories of their sizes","aa91cad0":"<a id=\"5\"><\/a>\n# Building a correlation matrix","81fae124":"<a id=\"42\"><\/a>\nWe will use label encoder to label each of the categorical data that we have.","a2762ce9":"<a id=\"65\"><\/a>\nRandom Forest Classifier model","a56eac12":"<a id=\"67\"><\/a>\nXGB model","87dbb393":"<a id=\"64\"><\/a>\nlogistic regression model","1ca33b21":"<a id=\"70\"><\/a>\nSVC model","0484ca37":"<a id=\"62\"><\/a>\nResult table(Will be used at the end)","b779ee4d":"Here, we have uneven dataset, thus, density plots should be used instead of absolute","4b31ba26":"<a id=\"4\"><\/a>\n\n# Now, prepearing our dataset for modeling","5dd1e2e9":"Rankings of the feature based on their correlation with STATUS(what we want to predict)","b92903b3":"<a id=\"69\"><\/a>\nCatBoost Model","67a26296":"<a id=\"22\"><\/a>\n**First, let us study the terminated data. Still we will take original as well as active data with us, who knows what can help us later.**\n\n['index','EmployeeID', 'birthdate_key', 'recorddate_key', 'gender_full'] are not required as they are either given in short way here \n**(gender_full -> gender_short, recorddate -> status_year, birthdate -> age)** or are useless **(EmployeeID, index)**\n\nWe still dont know about terminationdate and origindate, so we will keep it for the timebeing","148830d5":"# XGBoost, Light GBM and Categorical Boost gave us the best results\nWhat a surprise! (Or was it?)","26ed678e":"<a id=\"2-cleaning-data\"><\/a>\n# Let us First clean the data","b48456e3":"<a id=\"23\"><\/a>\n\nNow,the city names and job labels are far too many for them to categorize. Thus we need to establish a better, more inclusive categorical variable. \n* Considering the size of cities and establishing them on the basis of **'rural', 'town', 'metro'**\n* Considering the positions of the jobs and describing them as **'board', 'executive', 'manager', 'employee'**","6ad964a6":"Let us see the unique values in the main data (here we are using the main data instead of just terminated one so any unique value present in active data is also not left)","5a86df9e":"Thus, we have cleaned the dataset into a neat and non-sequential one.","73c7b1a8":"Now, here we want a model to predict the status","8573972c":"<a id=\"63\"><\/a>\nLet us create a function so that we dont need to type it again and again for every model we train","a0271b5d":"<a id=\"52\"><\/a>\nNow, here is a catch, **termreason, termtype and index are of no use to us** in predicting the status, as they **does not contribute to the reasoning and rather just add to the status**. (For example, retirement of person on the index is more elaborate term for termination, isn't it?, and it should be voluntary. Thus they cannot be used to predict the status of termination). Still we will keep them in case we want to predict them in future. Also, this is non sequential modeling, thus we do not require **orighiredate_key and terminationdate_key**","8a498c64":"<a id=\"1-import-libraries\"><\/a>\n# Importing the libraries","681edad7":"<a id=\"68\"><\/a>\nLGBM model","2a7db9c4":"Now, let us see the data ","b9162862":"<a id=\"3\"><\/a>\n# Plotting the most relavant data\n\nHere, we are plotting the data that we find the most relavant just for analysis perspective","85747bb0":"# \ud83d\udea7\ud83d\udea7\ud83d\udea7WORK IS STILL IN PROGRESS\ud83d\udea7\ud83d\udea7\ud83d\udea7","88759080":"Took the categorical data from notebook https:\/\/www.kaggle.com\/musaberatbahadir\/sequential-non-sequential-model-benchmarking Thank You!","012e17ea":"*<a id=\"10\"><\/a>\n\n\n**We can see that the same ID is entered every year till the person is terminated or 10 years passes. So we need to remove the dupilcate entries as well as seperate the terminated and the active ones.**","309bce5d":"<a id=\"66\"><\/a>\nKNeighbour model","47a8e731":"<a id=\"71\"><\/a>\n# Results","241cf29b":"<a id=\"6\"><\/a>\n# Applying the models\n\n* Here, as the terminated employees are very less as compared to the active ones, the present dataset is skewed.(Not to confuse with 'screwed' \ud83d\ude1b)\n* We will oversample the terminated employees to make it non skewed dataset.\n* We will use Synthetic Minority Over-sampling Technique(SMOTE) for the same","2dcffdb7":"<a id=\"32\"><\/a>\n\nThus, from the above plot, we can say that\n* most people terminated are in their 20s of 50s\/60s, we have also put the hr_active for the reference\n* most people terminated have done around 10-15 years in service, followed by 5-10 years, we have also put the hr_active for the reference\n* Among our dataset, most people are terminated in the stores 35-40 while most people are active in stores 40-50\n* Also, we found out that we do not have dataset after 2015, thus, all the active eployees will have status year as 2015. However, it should also be noted that most of the employees were terminated in 2015"}}