{"cell_type":{"c532c60e":"code","faa6b0f1":"code","5de91df1":"code","3fa19783":"code","15c0dba7":"code","92772694":"code","143cdbc8":"code","ade56e7f":"code","31d9fcfc":"code","dc08db49":"code","4bdee99a":"code","f74edb63":"code","8198a36d":"code","b3fe11c4":"code","4056f9ec":"code","7ca8d6ca":"code","583beb89":"code","af6aeb43":"code","2450b2cc":"code","23162c8e":"code","5a2473cc":"code","6161e459":"code","73967c0b":"code","da360c3d":"code","3a4d657f":"code","231036d0":"code","f060d4b4":"code","1aff10e2":"code","574a14b4":"code","37e61070":"code","a9e4da20":"code","ccb438d3":"code","99d2097a":"code","bdcda152":"code","9414a158":"markdown","dfc5dc9f":"markdown"},"source":{"c532c60e":"import pandas as pd\nimport numpy as np\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport math\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, KFold\nimport plotly.express as px\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","faa6b0f1":"data = pd.read_csv('\/kaggle\/input\/car-purchase-data\/Car_Purchasing_Data.csv',encoding='latin-1')","5de91df1":"data","3fa19783":"data.isnull().sum()","15c0dba7":"def plot_3chart(df, feature):\n\n    # Creating a customized chart. and giving in figsize and everything.\n    fig = plt.figure(constrained_layout=True, figsize=(27, 10))\n    # creating a grid of 3 cols and 3 rows.\n    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n\n    # Customizing the histogram grid.\n    ax1 = fig.add_subplot(grid[0, :2])\n    # Set the title.\n    ax1.set_title('Histogram')\n    # plot the histogram.\n    sns.distplot(df.loc[:, feature],\n                 hist=True,\n                 kde=True,\n                 ax=ax1,\n                 color='Red')\n    ax1.legend(labels=['Normal', 'Actual'])\n\n    # customizing the QQ_plot.\n    ax2 = fig.add_subplot(grid[1, :2])\n    # Set the title.\n    ax2.set_title('Probability Plot')\n    # Plotting the QQ_Plot.\n    stats.probplot(df.loc[:, feature].fillna(np.mean(df.loc[:, feature])),\n                   plot=ax2)\n    ax2.get_lines()[0].set_markerfacecolor('Blue')\n    ax2.get_lines()[0].set_markersize(12.0)\n\n    # Customizing the Box Plot.\n    ax3 = fig.add_subplot(grid[:, 2])\n    # Set title.\n    ax3.set_title('Box Plot')\n    # Plotting the box plot.\n    sns.boxplot(df.loc[:, feature], orient='v', ax=ax3, color='Green')\n    ax3.yaxis.set_major_locator(MaxNLocator(nbins=24))\n\n    plt.suptitle(f'{feature}', fontsize=24)","92772694":"plot_3chart(data, 'Age')\nplot_3chart(data,'Annual Salary')\n","143cdbc8":"plot_3chart(data,'Net Worth')","ade56e7f":"plot_3chart(data,'Credit Card Debt')","31d9fcfc":"sns.countplot(data['Gender'])\n","dc08db49":"fig = px.treemap(data, path=['Country'], values='Annual Salary',\n                  color='Net Worth', hover_data=['Country'],\n                  color_continuous_scale='dense', title='Countries with different annual salaries ')\nfig.show()","4bdee99a":"lable = LabelEncoder()\ndata.Country = lable.fit_transform(data.Country)","f74edb63":"X = data.drop([\"Customer Name\", 'Country',\"Customer e-mail\", \"Car Purchase Amount\",'Credit Card Debt'], axis=1)\ny = data[\"Car Purchase Amount\"]","8198a36d":"X.head()","b3fe11c4":"sns.set(font_scale=1.1)\ncorrelation_train = data.corr()\nmask = np.triu(correlation_train.corr())\nplt.figure(figsize=(18, 15))\nsns.heatmap(correlation_train,\n            annot=True,\n            fmt='.1f',\n            cmap='coolwarm',\n            square=True,\n            mask=mask,\n            linewidths=1)\n\nplt.show()","4056f9ec":"y1 = y\ny1=y1.values.reshape(-1,1)\n","7ca8d6ca":"from sklearn.preprocessing import MinMaxScaler,StandardScaler\nscaler=MinMaxScaler()\n#scaler = StandardScaler()\ny1 = scaler.fit_transform(y1)","583beb89":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15)","af6aeb43":"X_train","2450b2cc":"\nscores = []\nn = 100\nmodel1 = RandomForestRegressor(n_estimators = n)\nmodel1.fit(X_train, y_train)\nscores.append(model1.score(X_test, y_test))","23162c8e":"y_pred1 = model1.predict(X_test)\n","5a2473cc":"RFerror =  mean_absolute_error(y_test, y_pred1)","6161e459":"from sklearn import datasets, ensemble\nfrom sklearn.inspection import permutation_importance\nparams = {'n_estimators': 1000,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}\nreg = ensemble.GradientBoostingRegressor(**params)\nreg.fit(X_train, y_train)\n\nGBRerror = mean_absolute_error(y_test, reg.predict(X_test))\nregpred = reg.staged_predict(X_test)\n","73967c0b":"test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\nfor i, y_pred in enumerate(reg.staged_predict(X_test)):\n    test_score[i] = reg.loss_(y_test, y_pred)\n\nfig = plt.figure(figsize=(18, 10))\nplt.subplot(1, 1, 1)\nplt.title('Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, reg.train_score_, 'b-',\n         label='Training Set Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n         label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')\nfig.tight_layout()\nplt.show()","da360c3d":"from xgboost import XGBRegressor\nxgb=XGBRegressor()\nfrom sklearn.model_selection import cross_val_score\ncv = 10\nperformance=cross_val_score(xgb,X,y,cv=cv,scoring=\"neg_mean_absolute_error\",n_jobs=-1)\nmae=-performance\nxgb.fit(X,y)\n\ny_pred3=xgb.predict(X_test)\nprint(mae)","3a4d657f":"XGBerror = mae","231036d0":"print(\"Mean Absolute Errors by: Random Forest =\",RFerror)\nprint(\"Gradient Boost = \",GBRerror)\nprint(\"XGB regressor = \",XGBerror.mean())","f060d4b4":"X.shape\nX=scaler.fit_transform(X)\n","1aff10e2":"X_train,X_test,y_train,y_test=train_test_split(X,y1,test_size=0.15)","574a14b4":"import tensorflow.keras \nfrom keras.models import Sequential \nfrom keras.layers import Dense \n\nmodel=Sequential()\nmodel.add(Dense(80,input_dim=4,activation='relu'))\nmodel.add(Dense(40,activation='relu'))\nmodel.add(Dense(1,activation='linear'))\nmodel.compile(optimizer='adam',loss='mean_squared_error')\n\nmodel.summary()","37e61070":"epochs_hist=model.fit(X_train,y_train,epochs=200,batch_size=50,verbose=1,validation_split=0.2)\n","a9e4da20":"y_predict=model.predict(X_test)\ny_predict.shape","ccb438d3":"mae = mean_absolute_error(y_test,y_predict)\nmse = mean_squared_error(y_test,y_predict)\nprint(f'MAE = {mae}')\nprint(f'RMSE = {mse}')","99d2097a":"ANNpredictions = pd.DataFrame(y_predict)\nRFpredictions = pd.DataFrame(y_pred1)\nXGBpredictions = pd.DataFrame(y_pred3)\nGBRprediction = pd.DataFrame(regpred)\nXdata = pd.DataFrame(X)\nydata = pd.DataFrame(y)","bdcda152":"Xdata.to_csv('Xdata.csv', index=False)\nydata.to_csv('ydata.csv', index=False)\nANNpredictions.to_csv('Predictedcarprices', index = False)","9414a158":"# TRAINING ANN MODEL","dfc5dc9f":"# Mean Absolute Error of our Neural Network is far better than the Regressor Models.\n"}}