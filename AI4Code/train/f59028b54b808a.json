{"cell_type":{"8ab3b06e":"code","cae675bf":"code","c213da17":"code","1e0d3499":"code","97b7b635":"code","6bffe061":"code","1b20ee80":"code","6976ebf8":"code","a0878914":"code","7d4cd271":"code","753a67fa":"code","06a51a1e":"code","9a2442dc":"code","683f69f4":"code","28eacce1":"code","47882dcd":"code","eb54ca60":"code","bcb760fd":"code","c8cb1133":"code","39055ee2":"code","2df6711f":"code","c112f4f9":"code","8f97dce9":"markdown","054f34b1":"markdown","67692d78":"markdown","54694e3a":"markdown","7bbc841a":"markdown","5baf9139":"markdown","d11c112a":"markdown","8d3432f1":"markdown","9bf5569f":"markdown","41433fea":"markdown","cd26b555":"markdown","56937b66":"markdown","a8cf9aa8":"markdown"},"source":{"8ab3b06e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set()\n\nfrom IPython.display import HTML\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","cae675bf":"train = pd.read_csv(\"..\/input\/train.csv\", nrows=10000000)\ntrain.head()","c213da17":"train.rename({\"acoustic_data\": \"signal\", \"time_to_failure\": \"quaketime\"}, axis=\"columns\", inplace=True)\ntrain.head()","1e0d3499":"for n in range(5):\n    print(train.quaketime.values[n])","97b7b635":"fig, ax = plt.subplots(2,1, figsize=(20,12))\nax[0].plot(train.index.values, train.quaketime.values)\nax[0].set_title(\"Quaketime of 10 Mio rows\")\nax[0].set_xlabel(\"Index\")\nax[0].set_ylabel(\"Quaketime in ms\");\nax[1].plot(train.index.values, train.signal.values, c=\"green\")\nax[1].set_title(\"Signal of 10 Mio rows\")\nax[1].set_xlabel(\"Index\")\nax[1].set_ylabel(\"Acoustic Signal\");","6bffe061":"fig, ax = plt.subplots(3,1,figsize=(20,18))\nax[0].plot(train.index.values[0:50000], train.quaketime.values[0:50000], c=\"Red\")\nax[0].set_xlabel(\"Index\")\nax[0].set_ylabel(\"Time to quake\")\nax[0].set_title(\"How does the second quaketime pattern look like?\")\nax[1].plot(train.index.values[0:49999], np.diff(train.quaketime.values[0:50000]))\nax[1].set_xlabel(\"Index\")\nax[1].set_ylabel(\"Difference between quaketimes\")\nax[1].set_title(\"Are the jumps always the same?\")\nax[2].plot(train.index.values[0:4000], train.quaketime.values[0:4000])\nax[2].set_xlabel(\"Index from 0 to 4000\")\nax[2].set_ylabel(\"Quaketime\")\nax[2].set_title(\"How does the quaketime changes within the first block?\");\n","1b20ee80":"import os \nfrom os import listdir\ntest_path = \"..\/input\/test\/\"\ntest_files = listdir(\"..\/input\/test\")\nprint(test_files[0:5])\n\nlen(test_files)","6976ebf8":"sample_submission = pd.read_csv(\"..\/input\/sample_submission.csv\")\nprint (sample_submission.head())\nlen(sample_submission.seg_id.values)","a0878914":"fig, ax = plt.subplots(4,1, figsize=(20,25))\n\nfor n in range(4):\n    seg = pd.read_csv(test_path  + test_files[n])\n    ax[n].plot(seg.acoustic_data.values, c=\"mediumseagreen\")\n    ax[n].set_xlabel(\"Index\")\n    ax[n].set_ylabel(\"Signal\")\n    ax[n].set_ylim([-300, 300])\n    ax[n].set_title(\"Test {}\".format(test_files[n]));\n","7d4cd271":"train.describe()","753a67fa":"fig, ax = plt.subplots(1,2, figsize=(20,5))\nsns.distplot(train.signal.values, ax=ax[0], color=\"Red\", bins=100, kde=False)\nax[0].set_xlabel(\"Signal\")\nax[0].set_ylabel(\"Density\")\nax[0].set_title(\"Signal distribution\")\n\nlow = train.signal.mean() - 3 * train.signal.std()\nhigh = train.signal.mean() + 3 * train.signal.std() \nsns.distplot(train.loc[(train.signal >= low) & (train.signal <= high), \"signal\"].values,\n             ax=ax[1],\n             color=\"Orange\",\n             bins=150, kde=False)\nax[1].set_xlabel(\"Signal\")\nax[1].set_ylabel(\"Density\")\nax[1].set_title(\"Signal distribution without peaks\");","06a51a1e":"stepsize = np.diff(train.quaketime)\ntrain = train.drop(train.index[len(train)-1])\ntrain[\"stepsize\"] = stepsize\ntrain.head(5)","9a2442dc":"train.stepsize = train.stepsize.apply(lambda l: np.round(l, 10))\nstepsize_counts = train.stepsize.value_counts()\nstepsize_counts","683f69f4":"window_sizes = [10, 50, 100, 1000]\nfor window in window_sizes:\n    train[\"rolling_mean_\" + str(window)] = train.signal.rolling(window=window).mean()\n    train[\"rolling_std_\" + str(window)] = train.signal.rolling(window=window).std()","28eacce1":"fig, ax = plt.subplots(len(window_sizes),1,figsize=(20,6*len(window_sizes)))\n\nn = 0\nfor col in train.columns.values:\n    if \"rolling_\" in col:\n        if \"mean\" in col:\n            mean_df = train.iloc[4435000:4445000][col]\n            ax[n].plot(mean_df, label=col, color=\"mediumseagreen\")\n        if \"std\" in col:\n            std = train.iloc[4435000:4445000][col].values\n            ax[n].fill_between(mean_df.index.values,\n                               mean_df.values-std, mean_df.values+std,\n                               facecolor='lightgreen',\n                               alpha = 0.5, label=col)\n            ax[n].legend()\n            n+=1","47882dcd":"float_data = pd.read_csv(\"..\/input\/train.csv\",dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32})\nfloat_data = float_data.values","eb54ca60":"#Helper Function\ndef extract_features(z):\n     return np.c_[z.mean(axis=1), \n                  np.median(np.abs(z), axis=1),\n                  z.std(axis=1), \n                  z.max(axis=1),\n                  z.min(axis=1)]","bcb760fd":"def create_X(x, last_index=None, n_steps=150, step_length=1000):\n    if last_index == None:\n        last_index=len(x)\n    assert last_index - n_steps * step_length >= 0\n    temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) \/ 3\n    return np.c_[extract_features(temp),\n                 extract_features(temp[:, -step_length \/\/ 10:]),\n                 extract_features(temp[:, -step_length \/\/ 100:]),\n                 temp[:, -1:]]\n        ","c8cb1133":"n_features = 16\ndef generator(data, min_index=0, max_index=None, batch_size=16, n_steps=150, step_length=1000):\n    if max_index is None:\n        max_index = len(data) - 1\n    while True:\n        # Pick indices of ending positions\n        rows = np.random.randint(min_index + n_steps * step_length, max_index, size=batch_size)\n         \n        # Initialize feature matrices and targets\n        samples = np.zeros((batch_size, n_steps, n_features))\n        targets = np.zeros(batch_size, )\n        \n        for j, row in enumerate(rows):\n            samples[j] = create_X(data[:, 0], last_index=row, n_steps=n_steps, step_length=step_length)\n            targets[j] = data[row, 1]\n        yield samples, targets","39055ee2":"batch_size = 32\n\ntrain_gen = generator(float_data, batch_size=batch_size)\nvalid_gen = generator(float_data, batch_size=batch_size)\n\n# Define model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, CuDNNGRU\nfrom keras.optimizers import adam\nfrom keras.callbacks import ModelCheckpoint\n\ncb = [ModelCheckpoint(\"model.hdf5\", monitor='val_loss', save_weights_only=False, period=3)]\n\nmodel = Sequential()\nmodel.add(CuDNNGRU(48, input_shape=(None, n_features)))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1))\n\nmodel.summary()\n","2df6711f":"model.compile(optimizer=adam(lr=0.0005), loss=\"mae\")\n\nhistory = model.fit_generator(train_gen,\n                              steps_per_epoch=1000,#n_train \/\/ batch_size,\n                              epochs=30,\n                              verbose=0,\n                              callbacks=cb,\n                              validation_data=valid_gen,\n                              validation_steps=100)#n_valid \/\/ batch_size)","c112f4f9":"import matplotlib.pyplot as plt\n\ndef perf_plot(history, what = 'loss'):\n    x = history.history[what]\n    val_x = history.history['val_' + what]\n    epochs = np.asarray(history.epoch) + 1\n    \n    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n    plt.title(\"Training and validation \" + what)\n    plt.xlabel(\"Epochs\")\n    plt.legend()\n    plt.show()\n    return None\n\nperf_plot(history)","8f97dce9":"# Column Rename \nWe can see two columns: Acoustic data and time_to_failure. The further is the seismic singal and the latter corresponds to the time until the laboratory earthquake takes place.\n","054f34b1":"# Check signals of test data","67692d78":"# Data ","54694e3a":"# Counting Stepsize","7bbc841a":"# Rolling sizes and window features","5baf9139":"# Test Data","d11c112a":"# Let's Plot this data","8d3432f1":"# See earthquack time , cross check","9bf5569f":"# Check with sample submission file","41433fea":"# EDA ","cd26b555":"# Signal Distribution ","56937b66":"# How does the earthquck changes ","a8cf9aa8":"  # Loading packages"}}