{"cell_type":{"ee011d83":"code","6d44619f":"code","f4a4770c":"code","72e5c553":"code","64f3e3ad":"code","5001553a":"code","6b1c9ff7":"code","1d4b2e44":"code","90785111":"code","e107e4a9":"code","da2e95cf":"code","92056df8":"code","e7b68e4b":"code","bcd8e7fe":"code","dcd7edb8":"code","04cfdecb":"code","463dc22b":"code","2b6212c0":"code","69d257b7":"markdown","b650cfd9":"markdown","06c6651e":"markdown","18b169ac":"markdown","f5d4048c":"markdown","253098f8":"markdown","1be5df09":"markdown","7e01b53f":"markdown","282a2e69":"markdown"},"source":{"ee011d83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport altair as alt\nalt.renderers.enable('notebook')\nprint(os.listdir(\"..\/input\"))\nfrom IPython.display import HTML\n\n\n# The below is great for working but if you publish it, no charts show up.\n# The workaround in the next cell deals with this.\n#alt.renderers.enable('notebook')\n\nHTML(\"This code block contains import statements and setup.\")\n# Any results you write to the current directory are saved as output.","6d44619f":"## Dont worry about the code in this block. This is just the setup for showing Altair graphs in Kaggle Notebooks\n\n\nfrom  altair.vega import v3\nimport json\nfrom IPython.display import HTML\n\n\nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v3.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\",\n    \"This code block sets up embedded rendering in HTML output and<br\/>\",\n    \"provides the function `render(chart, id='vega-chart')` for use below.\"\n)))\n","f4a4770c":"#!pip install fbprophet","72e5c553":"from fbprophet import Prophet\n\n#!mkdir -p dataset\n#!wget -c -b http:\/\/www-personal.umich.edu\/~mejn\/cp\/data\/sunspots.txt -P dataset\ndata = pd.read_excel('..\/input\/tech-mahindra\/HCL.xlsx', header=0, index_col=0, parse_dates=True, squeeze=True)","64f3e3ad":"#!ls dataset\/","5001553a":"# View the data as a table\ndata_as_frame = pd.DataFrame(data, columns=['Tech_Mahindra', 'Day'])\ndata_as_frame.tail(10)","6b1c9ff7":"data_as_frame['ds']=data_as_frame['Day'].astype(int)","1d4b2e44":"data_as_frame.head()","90785111":" data_as_frame['time_stamp']=data_as_frame.apply(lambda x:(pd.Timestamp('01-01-2008')+pd.DateOffset(days = int(x['ds']))),axis=1)","e107e4a9":"#Cleaning the df, we only need two columns date time and the data\nclean_df=data_as_frame.drop(['Day','ds'],axis=1)","da2e95cf":"clean_df.head()","92056df8":"render(alt.Chart(clean_df).mark_line(size=15, opacity=0.8, color = 'Orange').encode(\n        x='yearmonthdate(time_stamp):T',\n        y=alt.Y('Tech_Mahindra', title='Tech_Mahindra'),    \n        tooltip=['yearmonthdate(time_stamp)', 'Tech_Mahindra']\n    ).interactive().properties(width=900, height=450,title='Tech_Mahindra Stock Price')\\\n              .configure_title(fontSize=20))","e7b68e4b":"## Prophet requires two columns, one is ds (the date time) and y (variable to be forecasted)\nclean_df.columns = ['y', 'ds']","bcd8e7fe":"def fit_predict_model(dataframe, interval_width = 0.99, changepoint_range = 0.99):\n    m = Prophet(daily_seasonality = False, yearly_seasonality = False, weekly_seasonality = False,\n                seasonality_mode = 'multiplicative', \n                interval_width = interval_width,\n                changepoint_range = changepoint_range)\n    m = m.fit(dataframe)\n    \n    forecast = m.predict(dataframe)\n    forecast['fact'] = dataframe['y'].reset_index(drop = True)\n    print('Displaying Prophet plot')\n    fig1 = m.plot(forecast)\n    return forecast\n    \npred = fit_predict_model(clean_df)\n","dcd7edb8":"def detect_anomalies(forecast):\n    forecasted = forecast[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper', 'fact']].copy()\n    #forecast['fact'] = df['y']\n\n    forecasted['anomaly'] = 0\n    forecasted.loc[forecasted['fact'] > forecasted['yhat_upper'], 'anomaly'] = 1\n    forecasted.loc[forecasted['fact'] < forecasted['yhat_lower'], 'anomaly'] = -1\n\n    #anomaly importances\n    forecasted['importance'] = 0\n    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n        (forecasted['fact'] - forecasted['yhat_upper'])\/forecast['fact']\n    forecasted.loc[forecasted['anomaly'] ==-1, 'importance'] = \\\n        (forecasted['yhat_lower'] - forecasted['fact'])\/forecast['fact']\n    \n    return forecasted\n\npred = detect_anomalies(pred)","04cfdecb":"pred.head()","463dc22b":"pred[pred.anomaly == 1]","2b6212c0":"def plot_anomalies(forecasted):\n    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color = '#7FC97F').encode(\n    x=alt.X('ds:T',  title ='date'),\n    y='yhat_upper',\n    y2='yhat_lower',\n    tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive().properties(\n        title='Anomaly Detection'\n    )\n\n    fact = alt.Chart(forecasted[forecasted.anomaly==0]).mark_circle(size=15, opacity=0.7, color = 'Black').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive()\n\n    anomalies = alt.Chart(forecasted[forecasted.anomaly!=0]).mark_circle(size=30, color = 'Red').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper'],\n        size = alt.Size( 'importance', legend=None)\n    ).interactive()\n\n    return render(alt.layer(interval, fact, anomalies)\\\n              .properties(width=870, height=450)\\\n              .configure_title(fontSize=20))\n              \nplot_anomalies(pred)","69d257b7":"# Detecting Anomalies:\n* The light blue boundaries in the above graph are yhat_upper and yhat_lower.\n* If y value is greater than yhat_upper and less than yhat lower then it is an anomaly.\n* Also getting the importance of that anomaly based on its distance from yhat_upper and yhat_lower.","b650cfd9":"### Converting data to Pandas dataframe","06c6651e":"# Preparing data for modelling in Prophet","18b169ac":"## Lets Predict","f5d4048c":"## Lets view the data in graphical format","253098f8":"### Converting the months column in format acceptable for Prophet, starting from 1749 ","1be5df09":"References:\n* http:\/\/www-personal.umich.edu\/~mejn\/cp\/programs.html\n* https:\/\/towardsdatascience.com\/anomaly-detection-time-series-4c661f6f165f\n* https:\/\/github.com\/altair-viz\/altair\/issues\/1270\n","7e01b53f":"# Plotting the anomalies for a better view","282a2e69":"# Getting the data"}}