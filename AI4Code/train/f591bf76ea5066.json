{"cell_type":{"291c8323":"code","f000d9aa":"code","60518a33":"code","374aefe9":"code","25bee625":"code","1626ad74":"code","8dafdb7c":"code","a3a4fc47":"code","0f888380":"code","50651a05":"code","086a7645":"markdown","ce652f9b":"markdown","ad8ba4ec":"markdown","941a6a94":"markdown","595d7853":"markdown","4a96a864":"markdown","293ae9d4":"markdown","1b78ec8d":"markdown","d356c50d":"markdown","f4d71236":"markdown","59106ea3":"markdown","cc5cfa2d":"markdown"},"source":{"291c8323":"# Here we import standard libraries and our environment\n# You must first add the data for the task in the settings column\nimport random\nimport numpy as np\nfrom kaggle_environments import make, evaluate\n\n# Create the game environment\nenv = make(\"connectx\", debug=True)\n\n# List the available agents\nprint(list(env.agents))","f000d9aa":"env.run([\"random\", \"random\"])\n\n# To render using iPython, we have to use a notebook as the Kaggle editor can't show HTML objects\nenv.render(mode=\"ipython\")","60518a33":"# Gets board at next step if agent drops piece in selected column\ndef drop_piece(grid, col, piece, config):\n    next_grid = grid.copy()\n    for row in range(config.rows-1, -1, -1):\n        if next_grid[row][col] == 0:\n            break\n    next_grid[row][col] = piece\n    return next_grid\n\n# Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\ndef count_windows(grid, num_discs, piece, config):\n    num_windows = 0\n    # horizontal\n    for row in range(config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[row, col:col+config.inarow])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n    # vertical\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns):\n            window = list(grid[row:row+config.inarow, col])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n    # positive diagonal\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n    # negative diagonal\n    for row in range(config.inarow-1, config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n    return num_windows","374aefe9":"# Helper function for minimax: checks if agent or opponent has four in a row in the window\ndef is_terminal_window(window, config):\n    return window.count(1) == config.inarow or window.count(2) == config.inarow\n\n# Helper function for minimax: checks if game has ended\ndef is_terminal_node(grid, config):\n    # Check for draw \n    if list(grid[0, :]).count(0) == 0:\n        return True\n    # Check for win: horizontal, vertical, or diagonal\n    # horizontal \n    for row in range(config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[row, col:col+config.inarow])\n            if is_terminal_window(window, config):\n                return True\n    # vertical\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns):\n            window = list(grid[row:row+config.inarow, col])\n            if is_terminal_window(window, config):\n                return True\n    # positive diagonal\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n            if is_terminal_window(window, config):\n                return True\n    # negative diagonal\n    for row in range(config.inarow-1, config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n            if is_terminal_window(window, config):\n                return True\n    return False","25bee625":"# Helper function for get_heuristic: checks if window satisfies heuristic conditions\ndef check_window(window, num_discs, piece, config):\n    return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n\ndef get_heuristic(grid, mark, config):\n    num_threes = count_windows(grid, 3, mark, config)\n    num_fours = count_windows(grid, 4, mark, config)\n    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n    num_fours_opp = count_windows(grid, 4, mark%2+1, config)\n    score = num_threes - 1e2*num_threes_opp - 1e4*num_fours_opp + 1e6*num_fours\n    return score","1626ad74":"def minimax(node, depth, maximizingPlayer, mark, config):\n    is_terminal = is_terminal_node(node, config)\n    valid_moves = [c for c in range(config.columns) if node[0][c] == 0]\n    if depth == 0 or is_terminal:\n        return get_heuristic(node, mark, config)\n    if maximizingPlayer:\n        value = -np.Inf\n        for col in valid_moves:\n            child = drop_piece(node, col, mark, config)\n            value = max(value, minimax(child, depth-1, False, mark, config))\n        return value\n    else:\n        value = np.Inf\n        for col in valid_moves:\n            child = drop_piece(node, col, mark%2+1, config)\n            value = min(value, minimax(child, depth-1, True, mark, config))\n        return value\n\n# Uses minimax to calculate value of dropping piece in selected column\ndef score_move(grid, col, mark, config, nsteps):\n    next_grid = drop_piece(grid, col, mark, config)\n    score = minimax(next_grid, nsteps-1, False, mark, config)\n    return score","8dafdb7c":"def agent_minimax(obs, config):\n    # How deep to make the game tree: higher values take longer to run!\n    N_STEPS = 3\n    # Get list of valid moves\n    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n    # Convert the board to a 2D grid\n    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n    # Use the heuristic to assign a score to each possible board in the next step\n    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, config, N_STEPS) for col in valid_moves]))\n    # Get a list of columns (moves) that maximize the heuristic\n    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n    # Select at random from the maximizing columns\n    return random.choice(max_cols)","a3a4fc47":"# Run once to observe the procedure is implemented correctly\nenv.run([agent_minimax, \"random\"])\nenv.render(mode=\"ipython\")\n\n# Determine the winning percentages with\n# get_win_percentages(agent1=agent_blocker, agent2=agent_random)","0f888380":"def get_win_percentages(agent1, agent2, n_rounds=100):\n    # Use default Connect Four setup\n    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n    # Agent 1 goes first (roughly) half the time          \n    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds\/\/2)\n    # Agent 2 goes first (roughly) half the time      \n    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds\/\/2)]\n    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])\/len(outcomes), 2))\n    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])\/len(outcomes), 2))\n    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))","50651a05":"import inspect\nimport os\n\nf = open(\"submission.py\", \"w\")\nf.write(\"import random \\n\")\nf.write(\"import numpy as np \\n\")\nf.write(inspect.getsource(drop_piece))\nf.write(inspect.getsource(count_windows))\nf.write(inspect.getsource(is_terminal_window))\nf.write(inspect.getsource(is_terminal_node))\nf.write(inspect.getsource(check_window))\nf.write(inspect.getsource(get_heuristic))\nf.write(inspect.getsource(minimax))\nf.write(inspect.getsource(score_move))\nf.write(inspect.getsource(agent_minimax))\nf.close()\n\nprint(\"agent_minimax\", \"written to\", \"submission.py\")","086a7645":"# Test the Agent","ce652f9b":"To check this has worked, look in the tab to the right. Under data, find the \"output\" folder. Find your \"submission.py\" file and download it to observe the contents. We should have a self-contained script with all necessary functions for our agent. Now, we are ready to submit this solution!","ad8ba4ec":"Finally we need to define a heuristic to rank our move","941a6a94":"# Helping Functions\nBefore defining our agent, we first define some functions that determine how a given move might affect play.","595d7853":"# Reinforcement Learning in ConnectX\n\nThe following notebook follows the third step of the tutorial. It should provide an introduction to submitting reinforcement learning solutions to Kaggle. This notebook does not act as a detailed guide. For more detail, see my other notebook on ConnectX or the Intro to Game AI and Reinforcement Learning course.","4a96a864":"# Minimax Agent","293ae9d4":"# Generate the submission.py file\nYou may notice the following script is different to that in the course. Hopefully this is more intuitive.\n\nFirst, we open our file \"submission.py\". Then, we search through our notebook and one-by-one add the functions needed for our agent. Finally we close our file.\n\nSuppose we wanted to add our leftmost agent, we would use the following script.","1b78ec8d":"# Additional Functions","d356c50d":"# Submitting to the Competition\nI want to refer back to the course here as it offers a very good explanation of how to make our final submission.\n\n1. Begin by clicking on the blue Save Version button in the top right corner of the window. This will generate a pop-up window.\n2. Ensure that the Save and Run All option is selected, and then click on the blue Save button.\n3. This generates a window in the bottom left corner of the notebook. After it has finished running, click on the number to the right of the Save Version button. This pulls up a list of versions on the right of the screen. Click on the ellipsis (...) to the right of the most recent version, and select Open in Viewer. This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the Output tab on the right of the screen. Then, click on the blue Submit button to submit your results to the leaderboard.\n\nAnd you've submitted!!! :)\n\nI hope you all found success with this notebook. If you're still having difficulties submitting, feel free to comment on this notebook and I'll reply as soon as I can.","f4d71236":"# Determine the Winning Perccentages","59106ea3":"# Implement the game environment\nWe want to do two things in this notebook:\n1. Test and edit our agents\n2. Submit our solution\n\nTo test and edit our agents, we have to set up the test environment as shown in the Reinforcement Learning course.","cc5cfa2d":"Let's check this works by running two random agents against each other and rendering to watch the game."}}