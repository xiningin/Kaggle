{"cell_type":{"c78625d6":"code","763533e4":"code","d9f06338":"code","c5249e2b":"code","543f94d4":"code","82cccad8":"code","20674cce":"code","d7bd3939":"code","21f57f82":"code","b5c98378":"code","c2a5b8c1":"code","0301c999":"code","408833de":"code","552ead28":"code","8bf2b348":"code","bcad9fbe":"code","1c2dc68c":"code","ce790fde":"code","25edcbcf":"code","0066fd6c":"code","0cf00975":"code","ee2bd67a":"code","b4f90197":"code","5c5aa33c":"code","e3cd04e7":"code","9ef78bac":"code","8d1cc8af":"code","ce79e777":"code","1ab971c2":"code","d97a4a57":"code","7f5610e9":"code","75f9c897":"code","4112a9df":"code","b48ca4da":"code","82f94625":"code","cefb760c":"markdown","4d8ba13c":"markdown","dac00150":"markdown","4b344085":"markdown","61a40f42":"markdown","12646ad4":"markdown","6b4e693c":"markdown","40548289":"markdown","28252c31":"markdown"},"source":{"c78625d6":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport nltk\nimport os \nimport io \nfrom textblob import TextBlob\nfrom nltk.corpus import stopwords\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline","763533e4":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d9f06338":"#load fake news \nfake=pd.read_csv('\/kaggle\/input\/fake-and-real-news-dataset\/True.csv')\n#load true news \ntrue=pd.read_csv('\/kaggle\/input\/fake-and-real-news-dataset\/True.csv')","c5249e2b":"# show the head \nfake.head()","543f94d4":"fake.info()","82cccad8":"fake.shape","20674cce":"fake.describe()","d7bd3939":"#show the head of true news \ntrue.head()","21f57f82":"true.info()","b5c98378":"true.describe()","c2a5b8c1":"true.shape","0301c999":"#add a label column to both datasets \nfake['label']='fake'\ntrue['label']= 'true'","408833de":"fake.head()","552ead28":"true.head()","8bf2b348":"# Now , lest's concat the two datasets \nnews=pd.concat([true,fake])\nnews.sample(frac = 1) #Shuffle 100%\n","bcad9fbe":"news.groupby('label').size()","1c2dc68c":"# a funstion that converts list to string \ndef listostring(lst):\n    \n        listToString = ' '.join([str(elem) for elem in lst]) \n        \n        return listToString\n    \n# let's define a function that processes the text of news \n  \ndef text_tokenizer(txt):\n    \n    text_blob = TextBlob(txt)\n    text_cleaned= ' '.join(text_blob.words)\n    words=text_cleaned.split(' ')\n\n    text=[]\n    for word in words:\n        if word.lower()  not in stopwords.words('english'):\n            text.append(word)\n     \n    \n    listToString = ' '.join([str(elem) for elem in text]) \n  \n    return listToString","ce790fde":"#add another column to dataset contains text preprocessed \nnews['clean_text'] = news['clean_text'].apply(listostring)","25edcbcf":"news.head()","0066fd6c":"print(news['clean_text'][0])","0cf00975":"#create bag of words \nbow_transformer = CountVectorizer(analyzer=text_tokenizer).fit_transform(news['clean_text'])","ee2bd67a":"#show the sparce Matrix \nprint('Shape of Sparse Matrix: ', bow_transformer.shape)","b4f90197":"#create tfidf \ntfidf_transformer= TfidfTransformer()\ntfidf = tfidf_transformer.fit_transform(bow_transformer)\nprint(tfidf.shape)","5c5aa33c":"#train the model \nrfc= RandomForestClassifier(n_estimators=100)\nrfc.fit(tfidf, news['label'])\n","e3cd04e7":"#predict\npredictions= rfc.predict(tfidf)","9ef78bac":"print(predictions)","8d1cc8af":"#show some metrics \nlabel=news['label']\n\nprint(\"Metrics Report \\n :\",classification_report(label, predictions))\nprint('\\n')\nprint('\\n')\nprint(\"Accuracy Score :\",accuracy_score(label, predictions))","ce79e777":"X=news['text']\ny=news['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n","1ab971c2":"#now let's try the easy way and build our pipline \n#But this time with RFC classifier \n\npipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=text_tokenizer)),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', RandomForestClassifier(n_estimators=600)),  # train on TF-IDF vectors w\/ Naive Bayes classifier\n])","d97a4a57":"#train the pipline \npipeline.fit(X_train,y_train)\n","7f5610e9":"# predict \npreds= pipeline.predict(X_test)","75f9c897":"#print some outcomes \nprint(list(preds)[:10])","4112a9df":"print(\"Metrics Report \\n :\",classification_report(y_test, preds))\nprint('\\n')\n\nprint('\\n')\nprint(\"Accuracy Score :\",accuracy_score(y_test, preds))","b48ca4da":"# Submit the results \nsubmission = pd.DataFrame({'news_Id':X_test.index , 'Label':preds})\nsubmission.to_csv('submission.csv', index=False)\nprint(\" Submission  successfully saved!\")","82f94625":"submission.head(20)","cefb760c":"## Train-Test Split","4d8ba13c":"## Data Analaysis ","dac00150":"## Import the usual suspects ","4b344085":"## Model Evaluation\n","61a40f42":"## show some infos ","12646ad4":"## Load the datasets ","6b4e693c":"## Submission ","40548289":"## Build the pipline ","28252c31":"### Data Preprocessing "}}