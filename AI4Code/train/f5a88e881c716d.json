{"cell_type":{"0834ca63":"code","57ee6c18":"code","7d367da4":"code","8f1504b2":"code","ce11aa69":"code","afdbe91f":"code","2a11df31":"code","f4f79b06":"code","b60418dc":"code","f7f94979":"code","a1b785be":"code","28ac1599":"code","a8435ccd":"code","48908b89":"code","380cc55f":"code","81555651":"code","a0b69267":"code","f2ffede0":"code","f0d12fb0":"code","75dbff3f":"code","da6b21b6":"code","f84d43fa":"code","8152e9f4":"code","b0a29a0b":"code","210cd55f":"code","db3196d7":"code","fb538ad6":"code","ae14286e":"code","29a48b76":"code","7f6ef26a":"code","8ed8d3d4":"code","f075a2e7":"code","0ecc8eef":"code","e9096eb9":"code","5e1dcaa4":"code","18cf3ba8":"markdown","72bf5169":"markdown","48146de3":"markdown","f2975438":"markdown"},"source":{"0834ca63":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\ndavis = pd.read_csv(\"..\/input\/davis-data-set\/Davis.csv\")\n\ndavis.columns = ['id','sex', 'weight', 'height', 'repwt', 'repht']\ndavis.sex = pd.get_dummies(davis['sex'])\n\n\ndavis.head()","57ee6c18":"davis.weight.corr(davis.height)\n","7d367da4":"davis.weight.corr(davis.sex)","8f1504b2":"\n\nax = plt.gca()\nax.bar(davis.weight, davis.repwt, align='edge') # align='edge' - \u0432\u044b\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u043d\u0438\u0435 \u043f\u043e \u0433\u0440\u0430\u043d\u0438\u0446\u0435, \u0430 \u043d\u0435 \u043f\u043e \u0446\u0435\u043d\u0442\u0440\u0443\nax.set_xlabel('weight')\nax.set_ylabel('repwt')\nplt.show()","ce11aa69":"sns.set(style = 'whitegrid', context = 'notebook')\ncols = ['sex','height', 'weight']\nsns.pairplot(davis[cols],height = 2.5)\nplt.show()","afdbe91f":"def lin_regplot (X, \u0443, model) :\n    plt.scatter(X,Y, \u0441= 'blue')\n    plt.plot(X, model.predict(X), color= ' red ')\n    return None ","2a11df31":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score,mean_squared_error\ndavis.head()\nX = davis.loc[:,['sex','height']].values\nY = davis['weight'].values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n\nslr = LinearRegression()\nslr = slr.fit(X_train, Y_train)\ny_train_pred = slr.predict(X_train)\n\n\n\ny_test_pred = slr.predict(X_test)\nprint('R2 training: %.3f, test: %.3f' %(r2_score(Y_train, y_train_pred),r2_score(Y_test,y_test_pred)))\n\n\n","f4f79b06":"x_davis_hght = davis.height.values\nx_davis_hght = np.resize(x_davis_hght, (200,1))\ny_train_pred_graph = np.resize(y_train_pred,(200,1))\ny_test_pred_graph = np.resize(y_test_pred,(200,1))","b60418dc":"plt.scatter(x_davis_hght, y_train_pred_graph, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(x_davis_hght,y_test_pred_graph, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('height')\nplt.ylabel('weight')\nplt.legend(loc = 'upper left')\n\n\nplt.show()","f7f94979":"plt.scatter(y_train_pred, y_train_pred - Y_train, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(y_test_pred, y_test_pred - Y_test, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('\u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435')\nplt.ylabel('\u043e\u0441\u0442\u0430\u0442\u043a\u0438')\nplt.legend(loc = 'upper left')\nplt.hlines(y = 0, xmin = 50, xmax = 100 , lw =2, color = 'red')\nplt.xlim([50,100])\nplt.show()","a1b785be":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nhousing = pd.read_csv(\"..\/input\/california-housing-prices\/housing.csv\")\nhousing.columns = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population','households','median_income','median_house_value','ocean_proximity']\nhousing.ocean_proximity = pd.get_dummies(housing['ocean_proximity'])\n\ndisplay(housing)","28ac1599":"housing = housing.fillna(housing.median(axis=0), axis=0)\n\nhousing = (housing  - housing.mean()) \/ housing.std()\nhousing.describe()","a8435ccd":"housing.corr()","48908b89":"sns.set(style = 'whitegrid', context = 'notebook')\ncols = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population','households','median_income','median_house_value','ocean_proximity']\ncm = np.corrcoef(housing[cols].values.T)\nsns.set(font_scale = 1)\nhm = sns.heatmap(cm, cbar = True, annot=True,square = True, fmt ='.2f', annot_kws ={'size':7 },yticklabels = cols, xticklabels = cols)","380cc55f":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\nX = housing.loc[:,['longitude','latitude','housing_median_age','total_rooms','ocean_proximity','median_income']].values\nY = housing['median_house_value'].values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n\nslr = RandomForestRegressor(n_estimators = 1000,criterion = 'mse',random_state = 1, n_jobs = -1)\nslr = slr.fit(X_train, Y_train)\n\ny_train_pred = slr.predict(X_train)\n\ny_test_pred = slr.predict(X_test)\nprint('R2 training: %.3f, test: %.3f' %(r2_score(Y_train, y_train_pred),r2_score(Y_test,y_test_pred)))\nprint('Mean_squared: %.3f, test: %.3f' %(mean_squared_error(Y_train, y_train_pred),mean_squared_error(Y_test,y_test_pred)))\n","81555651":"plt.scatter(y_train_pred,y_train_pred - Y_train,c = 'black',marker = 'o', s = 35, alpha = 0.5, label = 'train data')\nplt.scatter(y_test_pred,y_test_pred - Y_test, c = 'blue', marker = 's', s = 35,alpha = 0.5 , label = 'test data')","a0b69267":"x_ocean_inc = np.resize(housing.ocean_proximity.values,(100,1))\ny_housing_med_inc = np.resize(housing['median_house_value'].values,(100,1))\n\ny_test_pred_graph = np.resize(y_test_pred,(100,1))\nx = np.resize(np.arange(1,100),(100,1))\nplt.scatter(x,y_test_pred_graph, c = 'black', marker = 's', label ='Test_Data')\nplt.scatter(x,y_housing_med_inc, c = 'red', marker = 'o', label = 'Table_Data')\nplt.xlabel('ocean_proximuty')\nplt.ylabel('median_value')\n\nplt.legend(loc = 'upper left')\n\n\nplt.show()","f2ffede0":"plt.scatter(y_train_pred, y_train_pred - Y_train, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(y_test_pred, y_test_pred - Y_test, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('\u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435')\nplt.ylabel('\u043e\u0441\u0442\u0430\u0442\u043a\u0438')\nplt.legend(loc = 'upper left')\n\nplt.xlim(-0.1,0.1)\nplt.ylim(-0.5,0.5)\nplt.show()","f0d12fb0":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\ntest = pd.read_csv(\"..\/input\/combined-cycle-power-plant-data-set\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/simple-linear-regression\/powerplant.csv\")\n\n\n","75dbff3f":"train = train.fillna(train.median(axis=0), axis=0)\n\ntrain = (train  - train.mean()) \/ train.std()\ntrain.tail()","da6b21b6":"train.corr()","f84d43fa":"sns.set(style = 'whitegrid', context = 'notebook')\ncols = ['AT', 'V', 'AP', 'RH', 'PE']\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale = 1)\nhm = sns.heatmap(cm, cbar = True, annot=True,square = True, fmt ='.2f', annot_kws ={'size':7 },yticklabels = cols, xticklabels = cols)","8152e9f4":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error\n\nX = train.loc[:,['AT', 'V', 'AP', 'RH']].values\nY = train.PE.values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n\nslr = LinearRegression()\nslr = slr.fit(X_train, Y_train)\ny_train_pred = slr.predict(X_train)\ny_test_pred = slr.predict(X_test)\n\nprint('R2 training: %.3f, test: %.3f' %(r2_score(Y_train, y_train_pred),r2_score(Y_test,y_test_pred)))\nprint('Mean_squared: %.3f, test: %.3f' %(mean_squared_error(Y_train, y_train_pred),mean_squared_error(Y_test,y_test_pred)))\n\nX = train.iloc[:, :-1]\nY = train.iloc[:, -1]\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 0)\n\nslr = RandomForestRegressor(n_estimators = 1000,criterion = 'mse',random_state = 1, n_jobs = -1)\nslr = slr.fit(X_train, Y_train)\n\ny_train_pred = slr.predict(X_train)\n\ny_test_pred = slr.predict(X_test)\nprint('R2 training: %.3f, test: %.3f' %(r2_score(Y_train, y_train_pred),r2_score(Y_test,y_test_pred)))\nprint('Mean_squared: %.3f, test: %.3f' %(mean_squared_error(Y_train, y_train_pred),mean_squared_error(Y_test,y_test_pred)))\n","b0a29a0b":"#\u041b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0430 \u0445\u0443\u0436\u0435 \u0447\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043b\u0435\u0441, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430","210cd55f":"x_train_AT = train.AT.values\nx_train_AT = np.resize(x_train_AT, (9567,1))\ny_train_pred_graph = np.resize(y_train_pred,(9567,1))\ny_test_pred_graph = np.resize(y_test_pred,(9567,1))","db3196d7":"plt.scatter(x_train_AT, y_train_pred_graph, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(x_train_AT,y_test_pred_graph, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('AT')\nplt.ylabel('PE')\nplt.legend(loc = 'upper left')\nplt.xlim(-2,-1)\nplt.ylim(-2,-1)\n\nplt.show()","fb538ad6":"print(y_train_pred - Y_train)","ae14286e":"plt.scatter(y_train_pred, y_train_pred - Y_train, c = 'blue',marker ='o', label = 'Train Data')\nplt.scatter(y_test_pred, y_test_pred - Y_test, c = 'black', marker = 's', label ='Test Data')\nplt.xlabel('\u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435')\nplt.ylabel('\u043e\u0441\u0442\u0430\u0442\u043a\u0438')\nplt.legend(loc = 'upper left')\nplt.xlim(-1,1)\nplt.ylim(-0.1,0.1)\nplt.show()","29a48b76":"import pandas as pd\nimport seaborn as sns\ndiabetes = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndiabetes.columns = ['Pregns','Glucose','BldPress','SkinThick','Insulin','BMI','DiabPedFunc','Age','Outcome']\n\ndiabetes.tail()","7f6ef26a":"sns.set(style = 'whitegrid', context = 'notebook')\ncols =['Pregns','Glucose','BldPress','SkinThick','Insulin','BMI','DiabPedFunc','Age','Outcome']\nsns.pairplot(diabetes[cols],height = 2.5)\nplt.show()","8ed8d3d4":"diabetes_categorical = diabetes.Outcome\ndiabetes_numerical=diabetes.drop(columns= 'Outcome')\n\ndiabetes_numerical = (diabetes_numerical - diabetes_numerical.mean()) \/ diabetes_numerical.std()\ndiabetes_numerical.describe()\ndata = pd.concat((diabetes_numerical,diabetes_categorical),axis = 1)\ndata.head()","f075a2e7":"data = diabetes\ndata.head()","0ecc8eef":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nX = data.iloc[:, :-1]\ny = data.iloc[:, -1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nLR = LogisticRegression()\n\n\nLR.fit(X_train, y_train)\n\n\ny_train_pred = LR.predict(X_train)\ny_test_pred = LR.predict(X_test)\n\n\nprint(\"Accuracy \", LR.score(X_test, y_test)*100)\nsns.set(font_scale=1.5)\ncm = confusion_matrix(y_test_pred, y_test)\nsns.heatmap(cm, annot=True, fmt='g')\nplt.show()","e9096eb9":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nX = data.iloc[:, :-1]\ny = data.iloc[:, -1]\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.3, random_state = 1)\n\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\n\ny_train_pred = svc.predict(X_train)\n\ny_test_pred = svc.predict(X_test)\n\nprint(\"Accuracy \", svc.score(X_test, Y_test)*100)\nsns.set(font_scale=1.5)\ncm = confusion_matrix(y_test_pred, Y_test)\nsns.heatmap(cm, annot=True, fmt='g')\nplt.show()\n","5e1dcaa4":"from sklearn.ensemble import RandomForestClassifier\nX = data.iloc[:, :-1]\nY = data.iloc[:, -1]\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, random_state = 0)\nforest = RandomForestClassifier(criterion = 'entropy', n_estimators = 1000, max_depth = 3)\nforest.fit(X_train,Y_train)\ny_train_pred = forest.predict(X_train)\n\ny_test_pred = forest.predict(X_test)\n\nprint(\"Accuracy \", forest.score(X_test, Y_test)*100)\nsns.set(font_scale=1.5)\ncm = confusion_matrix(y_test_pred, Y_test)\nsns.heatmap(cm, annot=True, fmt='g')\nplt.show()\n","18cf3ba8":"#task \u21161","72bf5169":"#Task 2","48146de3":"#Task \u21163","f2975438":"Task 4"}}