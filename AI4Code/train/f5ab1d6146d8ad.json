{"cell_type":{"b5c2503c":"code","390379b9":"code","30ddb743":"code","f7663367":"code","15e4f0b4":"code","99f0fe95":"code","f1cb8fba":"code","6b58d776":"code","0a424fd3":"code","fe301970":"code","15f7a2ed":"code","fa7ff7c3":"code","593fb2af":"code","22d0c525":"code","816b2ae2":"code","06d91b56":"code","bb10cb38":"code","1523b289":"code","1faa8029":"code","20b2a8f3":"code","91b011d2":"markdown","eccee831":"markdown","3c916b38":"markdown","3df52c48":"markdown","a10b33e5":"markdown","a15b3905":"markdown","971f1075":"markdown","8a872256":"markdown","97830b69":"markdown","de1d8282":"markdown","7a7ee2e8":"markdown","f02d464e":"markdown"},"source":{"b5c2503c":"# importing libraries\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","390379b9":"df=pd.read_csv('..\/input\/heartcsv\/heart.csv')\ndf.head()","30ddb743":"df.shape","f7663367":"df.info()","15e4f0b4":"df.describe()","99f0fe95":"sns.countplot(data=df,x='target')\nplt.title('Classification of People with Heart Disease')","f1cb8fba":"categorical_val = []\ncontinous_val = []\nfor column in df.columns:\n    print('==============================')\n    print(f\"{column} : {df[column].unique()}\")\n    if len(df[column].unique()) <= 10:\n        categorical_val.append(column)\n    else:\n        continous_val.append(column)","6b58d776":"# graphs for categorical values\nplt.figure(figsize=(15,15))\nfor i, column in enumerate(categorical_val, 1):\n    plt.subplot(3, 3, i)\n    df[df[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n    df[df[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","0a424fd3":"# graphs for continous values\nplt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(continous_val, 1):\n    plt.subplot(3, 2, i)\n    df[df[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n    df[df[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","fe301970":"corr_matrix = df.corr()\nfig, ax = plt.subplots(figsize=(12, 8))\nax = sns.heatmap(corr_matrix,\n                 annot=True,\n                 linewidths=0.5,\n                 fmt=\".2f\",\n                 cmap=\"viridis\")\n","15f7a2ed":"plt.figure(figsize=(10, 8))\n\n# Scatter with postivie examples\nplt.scatter(df.age[df.target==1],\n            df.thalach[df.target==1],\n            c=\"black\")\n\nplt.scatter(df.age[df.target==0],\n            df.thalach[df.target==0],\n            c=\"red\")\n\n# Add some helpful info\nplt.title(\"Heart Disease in function of Age and Max Heart Rate\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Max Heart Rate\")\nplt.legend([\"Disease\", \"No Disease\"]);","fa7ff7c3":"\ncategorical_val.remove('target')\ndataset = pd.get_dummies(df, columns = categorical_val)\n\nfrom sklearn.preprocessing import StandardScaler\n\ns_sc = StandardScaler()\ncol_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\ndataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale])","593fb2af":"# creating classification report function\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nscore=[]\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n     if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        accuracies = cross_val_score(estimator = clf, X = X_train, y = y_train, cv = 10)\n        print(\"Train Result:\\n================================================\")\n        print(clf,\":Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        score.append(accuracies.mean()*100)\n        \n     elif train==False:\n         pred = clf.predict(X_test)\n         clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n         print(\"Test Result:\\n================================================\")        \n         print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n         print(\"_______________________________________________\")\n         print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n         print(\"_______________________________________________\")\n         print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","22d0c525":"from sklearn.model_selection import train_test_split\n\nX = dataset.drop('target', axis=1)\ny = dataset.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)","816b2ae2":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\n\nlog_clf = LogisticRegression()\nrnd_clf = RandomForestClassifier()\nsvm_clf = SVC()\nvoting_clf = VotingClassifier(\nestimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\nvoting='hard')\nvoting_clf.fit(X_train, y_train)\nfrom sklearn.metrics import accuracy_score\nfor clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n","06d91b56":"print_score(log_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(log_clf, X_train, y_train, X_test, y_test, train=False)","bb10cb38":"print_score(rnd_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(rnd_clf, X_train, y_train, X_test, y_test, train=False)","1523b289":"print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm_clf, X_train, y_train, X_test, y_test, train=False)","1faa8029":"print_score(voting_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(voting_clf, X_train, y_train, X_test, y_test, train=False)","20b2a8f3":"log_test_score = round(accuracy_score(y_test, log_clf.predict(X_test)) * 100,2)\nlog_accuracies = cross_val_score(estimator = log_clf, X = X_train, y = y_train, cv = 10)\nlog_train_score=round(log_accuracies.mean()*100,2)\nrnd_test_score = round(accuracy_score(y_test, rnd_clf.predict(X_test)) * 100,2)\nrnd_accuracies = cross_val_score(estimator = rnd_clf, X = X_train, y = y_train, cv = 10)\nrnd_train_score=round(rnd_accuracies.mean()*100,2)\nsvm_test_score = round(accuracy_score(y_test, svm_clf.predict(X_test)) * 100,2)\nsvm_accuracies = cross_val_score(estimator = rnd_clf, X = X_train, y = y_train, cv = 10)\nsvm_train_score = round(svm_accuracies.mean()*100,2)\nvoting_test_score = round(accuracy_score(y_test, voting_clf.predict(X_test)) * 100,2)\nvoting_accuracies = cross_val_score(estimator = rnd_clf, X = X_train, y = y_train, cv = 10)\nvoting_train_score = round(voting_accuracies.mean()*100,2)\n\nresults_df = pd.DataFrame(data=[[\"Logistic Regression\", log_train_score, log_test_score],['Random Forrest',rnd_train_score, rnd_test_score],\n                                ['SVM',svm_train_score,svm_test_score],['Voting Classifier',voting_train_score,voting_test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nresults_df.index += 1 \nresults_df","91b011d2":"no null values present in the dataset so need to do data cleaning","eccee831":"Predicting and diagnosing heart disease is the biggest challenge in the medical industry and relies on factors such as the physical examination, symptoms and signs of the patient.\n\nHeart disease can be predicted based on various symptoms such as age, gender, heart rate, etc. and reduces the death rate of heart patients.\n\nDue to the increasing use of technology and data collection, we can now predict heart disease using machine learning algorithms. Now let\u2019s go further with the task of heart disease prediction using machine learning with Python.","3c916b38":"restbps: resting blood pressure anything above 130-140 is generally of concern\n\nchol: greater than 200 is of concern.\n\nthalach: People with a maximum of over 140 are more likely to have heart disease.\n\nthe old peak of exercise-induced ST depression vs. rest looks at heart stress during exercise an unhealthy heart will stress more.","3df52c48":"cp {Chest pain}:  People with cp 1, 2, 3 are more likely to have heart disease than people with cp 0.\nrestecg {resting EKG results}: People with a value of 1 (reporting an abnormal heart rhythm, which can range from mild symptoms to severe problems) are more likely to have heart disease.\n\n\nexang {exercise-induced angina}: people with a value of 0 (No ==> angina induced by exercise) have more heart disease than people with a value of 1 (Yes ==> angina induced by exercise)\n\n\nslope {the slope of the ST segment of peak exercise}: People with a slope value of 2 (Downslopins: signs of an unhealthy heart) are more likely to have heart disease than people with a slope value of 2 slope is 0 (Upsloping: best heart rate with exercise) or 1 (Flatsloping: minimal change (typical healthy heart)).\n\n\nca {number of major vessels (0-3) stained by fluoroscopy}: the more blood movement the better, so people with ca equal to 0 are more likely to have heart disease.\n\n\nthal {thalium stress result}: People with a thal value of 2 (defect corrected: once was a defect but ok now) are more likely to have heart disease.\n","a10b33e5":"Upvote the notebook if you liked it and any suggestions and comment on how i can improve will be appreciated and i'll try to improve . Thanks :)","a15b3905":"We have 165(1) people with heart disease and 138(0) people without heart disease, so our problem is balanced.\n","971f1075":"## Applying Algorithms","8a872256":"EDA helps us find answers to some important questions such as: What question (s) are you trying to solve? What kind of data do we have and how do we handle the different types? What is missing in the data and how do you deal with it? Where are the outliers and why should you care? How can you add, change, or remove features to get the most out of your data?","97830b69":"## Data Processing","de1d8282":"since voting classifier is performing the best in training and testing data ,we'll use it.\n","7a7ee2e8":"# Heart Disease Prediction using Machine Learning\n","f02d464e":"## Exploratory Data Analysis"}}