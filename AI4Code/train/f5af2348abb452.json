{"cell_type":{"9c9f1119":"code","1a2313da":"code","798d3447":"code","579dc4e3":"code","5d7d0dfd":"code","4a896dee":"code","11679e2c":"code","f96dc111":"code","280d3c16":"code","724495a5":"code","05ffe244":"code","19b5f92b":"markdown","8aa80ae0":"markdown","0a6066ff":"markdown","09b040b1":"markdown","a8db616f":"markdown","60dcb3e7":"markdown","b77f0800":"markdown","81b28146":"markdown"},"source":{"9c9f1119":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport PIL\nimport pathlib\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","1a2313da":"train_path=pathlib.Path(\"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/train\")\ntest_path=pathlib.Path(\"..\/input\/rock-paper-scissors-dataset\/Rock-Paper-Scissors\/test\")","798d3447":"rock=list(train_path.glob(\"rock\/*.png\"))\nplt.figure(figsize=(10,10))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img=PIL.Image.open(str(rock[i]))\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","579dc4e3":"train_gen=ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=90,\n    height_shift_range=0.2,\n    width_shift_range=0.2,\n    validation_split=0.1)\n\ntest_gen=ImageDataGenerator(rescale=1.\/255)","5d7d0dfd":"train=train_gen.flow_from_directory(\n\ntrain_path,\ntarget_size=(224,224),\ncolor_mode=\"rgb\",\nclass_mode=\"categorical\",\nbatch_size=32,\nshuffle=True,\nseed=42,\nsubset=\"training\")\n\n\nvalidation=train_gen.flow_from_directory(\n\ntrain_path,\ntarget_size=(224,224),\ncolor_mode=\"rgb\",\nclass_mode=\"categorical\",\nbatch_size=32,\nshuffle=True,\nseed=42,\nsubset=\"validation\")\n\n\ntest=test_gen.flow_from_directory(\n\ntest_path,\ntarget_size=(224,224),\ncolor_mode=\"rgb\",\nclass_mode=\"categorical\",\nbatch_size=32,\nshuffle=False)","4a896dee":"inception = tf.keras.applications.InceptionResNetV2(weights='imagenet', input_shape=(224,224,3), include_top=False)\n\ninception.trainable = False\n\ninput=inception.input\n\nx=layers.GlobalAveragePooling2D()(inception.output)\nx=layers.Dense(64,activation=\"relu\")(x)\nx=layers.Dropout(0.3)(x)\noutput=layers.Dense(3,activation=\"softmax\")(x)\n\nmodel=Model(input,output)\n\nmodel.summary()","11679e2c":"model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","f96dc111":"history=model.fit(train,validation_data=validation,epochs=50,callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ])","280d3c16":"import plotly.express as px\nfig=px.line(history.history,\n           y=[\"loss\",\"val_loss\"],\n           labels={\"index\":\"epochs\",\"value\":\"loss\"},\n           title=\"train & val loss\")\nfig.show()","724495a5":"fig=px.line(history.history,\n           y=[\"accuracy\",\"val_accuracy\"],\n           labels={\"index\":\"epochs\",\"value\":\"acc\"},\n           title=\"train & val acc\")\nfig.show()","05ffe244":"results = model.evaluate(test)\nprint(\"    Loss: {:.5f}\".format(results[0]))\nprint(\"Accuracy: {:.3f}%\".format(results[1] * 100))","19b5f92b":"# 4-Use pretrain network to make our network","8aa80ae0":"# 4-Create datagenerator","0a6066ff":"# 7-Evaluate on test images","09b040b1":"# 3-Plot some samples","a8db616f":"# 5-Compile and fit the model on our data","60dcb3e7":"# 2-Read images","b77f0800":"# 1-Import necessary libraries","81b28146":"# 6-Draw outputs plots"}}