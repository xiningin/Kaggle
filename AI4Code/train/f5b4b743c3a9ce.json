{"cell_type":{"af606e37":"code","ef5bfc88":"code","8fe9bc3d":"code","509fab6f":"code","05566294":"code","2a851f2a":"code","e027961b":"code","d0b75643":"code","65286c2d":"code","5ec9e801":"code","ec21c56c":"code","5c3f93fb":"code","df422e34":"code","52093fa6":"code","9da2b0f1":"code","ac274a9d":"code","ce5e6cfd":"code","becc9909":"code","27d5d35f":"code","412a3ce8":"code","bf2405d8":"code","ca1f667a":"code","ad6fd7dc":"code","56cd7c04":"code","c7db63f8":"code","4b074bd7":"code","007b12bd":"code","39f34bb9":"code","e31b06e7":"code","35269321":"code","35ab7beb":"code","1c33664f":"code","a9e7d8a2":"code","f58c82a7":"code","52f5ae1b":"code","740d3129":"code","da461a87":"code","5d96baf4":"code","74001a0d":"code","91937368":"code","18e380a9":"code","c25e7213":"code","79076ba9":"code","37a6d56b":"code","7c2eb7d7":"code","2513de6f":"code","ac2a9718":"code","e98edac6":"code","bfc5469e":"code","c98dd819":"code","37a99c29":"code","15b0d92b":"code","63101d02":"code","a6ef7d2d":"code","e1e563e0":"code","5d7a3422":"code","5507d389":"code","672cb7a1":"code","77a0371c":"code","3a5d6484":"code","fdbf5494":"code","2f6964f1":"code","e2396814":"code","9a305b27":"code","9e5d7717":"code","3bb4c535":"code","8cdb89ab":"code","68badf90":"code","efba8c13":"code","aaeedca6":"code","7d662989":"code","665e553e":"code","f629e1fe":"code","5589dac4":"code","9f8fb2b9":"markdown","ca21284b":"markdown","d180a793":"markdown","d044bd82":"markdown","568f4a85":"markdown","7161f417":"markdown","31f3bf06":"markdown","78069d02":"markdown","60d76889":"markdown","2f829535":"markdown","a26af56d":"markdown","04561f0e":"markdown","dcea3bcb":"markdown","4983ace1":"markdown","d2138cc7":"markdown","6aed68e2":"markdown","655e2b86":"markdown","158bfa34":"markdown","f6d734a8":"markdown","a39b3a00":"markdown","98eb7888":"markdown","85305253":"markdown","2df59f1b":"markdown"},"source":{"af606e37":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ef5bfc88":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.inspection import plot_partial_dependence\nimport pdpbox\nfrom pdpbox import pdp, get_dataset, info_plots\nimport xgboost as xgb\nfrom sklearn.model_selection import ParameterGrid\nfrom tqdm import tqdm\n\nnp.random.seed(1)\n","8fe9bc3d":"hour = pd.read_csv(\"..\/input\/bike-sharing-dataset\/hour.csv\")","509fab6f":"hour.head(6)","05566294":"hour.shape","2a851f2a":"# Plottong data.","e027961b":"hour['season'].unique()","d0b75643":"hour['yr'].unique()","65286c2d":"hour['mnth'].unique()","5ec9e801":"hour['hr'].unique()","ec21c56c":"hour['holiday'].unique()","5c3f93fb":"hour['weekday'].unique()","df422e34":"hour['workingday'].unique()","52093fa6":"hour['weathersit'].unique()","9da2b0f1":"plt.figure(figsize=(12, 6))\nplt.plot(hour['temp'], '.')\nplt.show()","ac274a9d":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['temp'])","ce5e6cfd":"plt.figure(figsize=(12, 6))\nplt.plot(hour['atemp'], '.')\nplt.show()","becc9909":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['atemp'])\n# are they related?","27d5d35f":"plt.figure(figsize=(12, 6))\nplt.plot(hour['hum'][:200], '.')\nplt.show()","412a3ce8":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['hum'])","bf2405d8":"plt.figure(figsize=(12, 6))\nplt.plot(hour['windspeed'], '.')\nplt.show()","ca1f667a":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['windspeed'])","ad6fd7dc":"plt.figure(figsize=(12, 6))\nplt.plot(hour['casual'], '.')\nplt.show()","56cd7c04":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['casual'])","c7db63f8":"plt.figure(figsize=(12, 6))\nplt.plot(hour['registered'], '.')\nplt.show()","4b074bd7":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['registered'])","007b12bd":"plt.figure(figsize=(12, 6))\nplt.plot(hour['cnt'], '.')\nplt.show()","39f34bb9":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['cnt'])","e31b06e7":"# Exclude casual and registered and use cnt as target.","35269321":"# Number of days since the 01.01.2011 (the first day in the dataset). \n# This feature was introduced to take account of the trend over time.\n\nhour['date'] = pd.to_datetime(hour['dteday'])\n\nbasedate = pd.Timestamp('2011-01-01')\nhour['days_since'] = hour['date'].apply(lambda x: (x - basedate).days)","35ab7beb":"plt.figure(figsize=(12, 6))\nplt.plot(hour['hum'], hour['days_since'], '.')\nplt.show()","1c33664f":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"temp\"], y=hour[\"cnt\"])","a9e7d8a2":"plt.figure(figsize=(12, 6))\nsns.jointplot(x=hour[\"temp\"], y=hour[\"cnt\"], kind='scatter')","f58c82a7":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"atemp\"], y=hour[\"cnt\"])","52f5ae1b":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"hum\"], y=hour[\"cnt\"])","740d3129":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"days_since\"], y=hour[\"cnt\"])","da461a87":"# For categorial features.\nplt.figure(figsize=(12, 6))\nsns.violinplot(x=\"season\", y=\"cnt\", data=hour, palette=\"muted\")","5d96baf4":"plt.figure(figsize=(12, 6))\nsns.boxplot(x=\"season\", y=\"cnt\", data=hour)","74001a0d":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"yr\", y=\"cnt\", data=hour, palette=\"muted\")","91937368":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"mnth\", y=\"cnt\", data=hour, palette=\"muted\")","18e380a9":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"hr\", y=\"cnt\", data=hour, palette=\"muted\")","c25e7213":"plt.figure(figsize=(12, 6))\nsns.boxplot(x=\"hr\", y=\"cnt\", data=hour)","79076ba9":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"holiday\", y=\"cnt\", data=hour, palette=\"muted\")","37a6d56b":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"weekday\", y=\"cnt\", data=hour, palette=\"muted\")","7c2eb7d7":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"workingday\", y=\"cnt\", data=hour, palette=\"muted\")","2513de6f":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"weathersit\", y=\"cnt\", data=hour, palette=\"muted\")","ac2a9718":"# Cyclical features. Hour, weekday and month. It is usefull for NN algorhitms. Tree algos are robust without it.\n\ndef encode_cyclical(data, col_name, max_val):\n    data[col_name + '_sin'] = np.sin(2 * np.pi * data[col_name] \/ max_val)\n    data[col_name + '_cos'] = np.cos(2 * np.pi * data[col_name] \/ max_val)\n    return data\n\n\nhour = encode_cyclical(hour, 'hr', 24)\nhour = encode_cyclical(hour, 'mnth', 12)\nhour = encode_cyclical(hour, 'weekday', 7)\n","e98edac6":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']","bfc5469e":"def rand_forest_model(X, y):\n    rmse_arr = []\n    \n    kf = KFold(n_splits=5, random_state=1, shuffle=True)\n\n    for n, (train_index, val_index) in enumerate(kf.split(X, y)):\n        print(f'fold: {n}')\n        train_X = X.iloc[train_index].values\n        val_X = X.iloc[val_index].values\n        train_y = y[train_index].values\n        val_y = y[val_index].values\n        \n        regr = RandomForestRegressor(max_depth=20, n_estimators=140, random_state=0)\n        regr.fit(train_X, train_y)\n        # print(regr.feature_importances_)\n\n        y_pred = regr.predict(val_X)\n        \n        # Predicted values should be non negative.\n        y_pred[y_pred < 0] = 0\n        \n        rmse = np.sqrt(mean_squared_error(val_y, y_pred))\n        rmse_arr.append(rmse)\n        \n    print('RMSE list:', rmse_arr)\n    print('RMSE AVG:', np.mean(rmse_arr))\n    return {'rmse_arr': rmse_arr, 'y_pred': y_pred, 'y_val': val_y, 'train_X': train_X, 'model': regr}\n\n\nres = rand_forest_model(X, y)","c98dd819":"# Pot predicitons.\nplt.figure(figsize=(12, 6))\nplt.plot(res['y_pred'], '.', label='pred')\nplt.plot(res['y_val'], '.', label='original')\nplt.legend()\nplt.show()\n","37a99c29":"# plotting absolute deviation.\nplt.figure(figsize=(12, 6))\nplt.plot(np.abs(res['y_pred'] - res['y_val']), '.')\nplt.title('Deviation from val.')\nplt.show()\n","15b0d92b":"# Evaluating features importance for RFregressor model.\n# res['model'].feature_importances_\nplt.figure(figsize=(12, 6))\nsns.barplot(x=res['model'].feature_importances_, y=features)\nplt.title('Feature importances')","63101d02":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[(0, 2), 2], feature_names=features) ","a6ef7d2d":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[0, 1], feature_names=features) ","e1e563e0":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[2, 3], feature_names=features) \n","5d7a3422":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[4, 5], feature_names=features) ","5507d389":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[6, 7], feature_names=features) ","672cb7a1":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[8, 9], feature_names=features) ","77a0371c":"print(np.corrcoef(hour[\"temp\"], hour[\"atemp\"]))","3a5d6484":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"temp\"], y=hour[\"atemp\"])","fdbf5494":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[10, 11], feature_names=features) ","2f6964f1":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[12], feature_names=features) ","e2396814":"# Excluding holiday, \"not very important\" feature.\nfeatures = ['season', 'yr', 'mnth', 'hr',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\nrand_forest_model(X, y)","9a305b27":"# excluding atemp, \"not very important\" feature.\nfeatures = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\nrand_forest_model(X, y)","9e5d7717":"# Excluding hour, \"very important\" feature.\nfeatures = ['season', 'yr', 'mnth', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\nrand_forest_model(X, y)","3bb4c535":"# Lets try to remove days_since feature.\nfeatures = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed']\n\nX, y = hour[features], hour['cnt']\n\nrand_forest_model(X, y)","8cdb89ab":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed']\n\nrmse_ft_arr = []\n\nfor n in range(len(features)):\n    print(f'step {n}')\n    features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed']\n    features.remove(features[n])\n    X, y = hour[features], hour['cnt']\n\n    res1 = rand_forest_model(X, y)\n\n    rmse_ft_arr.append(np.mean(res1['rmse_arr']))\n","68badf90":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed']\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=rmse_ft_arr, y=features)\nplt.title('RMSE vs removed feature.')\n","efba8c13":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\ndata_df = pd.DataFrame(res['train_X'], columns=features)\n\npdp_hr = pdp.pdp_isolate(\n    model=res['model'], dataset=data_df, model_features=features, feature='hr', num_grid_points=200\n)\n\nfig, axes = pdp.pdp_plot(pdp_hr, 'hr', plot_lines=True, frac_to_plot=400)","aaeedca6":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[3], feature_names=features, grid_resolution=200) ","7d662989":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\npars = {\n    'learning_rate': 0.1,\n    'max_depth': 12,\n    'objective': 'reg:squarederror',\n    'eval_metric': 'rmse',\n    'gamma': 0.25,\n    'n_estimators': 280\n}\n\ndef xgb_model(X, y, pars):    \n    rmse_arr = []\n    \n    kf = KFold(n_splits=5, random_state=1, shuffle=True)\n\n    for n, (train_index, val_index) in enumerate(kf.split(X, y)):\n#         print(f'fold: {n}')\n        \n        train_X = X.iloc[train_index]\n        val_X = X.iloc[val_index]\n        train_y = y[train_index]\n        val_y = y[val_index]\n        \n        xgb_train = xgb.DMatrix(train_X, label=train_y)\n        xgb_eval = xgb.DMatrix(val_X, label=val_y)\n        \n        xgb_model = xgb.train(pars,\n              xgb_train,\n              num_boost_round=800,\n              evals=[(xgb_train, 'train'), (xgb_eval, 'val')],\n              verbose_eval=False,\n              early_stopping_rounds=30\n             )\n    \n        y_pred = xgb_model.predict(xgb.DMatrix(val_X))\n\n        rmse = np.sqrt(mean_squared_error(val_y, y_pred))\n        rmse_arr.append(rmse)\n        \n    print('RMSE list:', rmse_arr)\n    print('RMSE AVG:', np.mean(rmse_arr))\n    return {'rmse_arr': rmse_arr, 'y_pred': y_pred, 'y_val': val_y, 'train_X': train_X, 'model': xgb_model}\n\n\nfeatures = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit',\n            'temp', 'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\nres = xgb_model(X, y, pars)\n","665e553e":"par_grid = {\n    \"max_depth\": [3, 6, 7, 8, 9],\n    \"min_child_weight\": [0.5, 1, 3],\n    \"gamma\": [0.25, 0.5, 0.8, 0.9, 1.1],\n    \"n_estimators\": [60, 80, 100, 140]\n#     \"learning_rate\": [0.05, 0.15, 0.25, 0.30],\n#     \"colsample_bytree\": [0.3, 0.4, 0.5, 0.7, 0.9],\n#     \"etha\": [0.01, 0.5, 0.1, 0.2],\n#     \"subsample\": [0.5, 0.7, 1.0],\n#     \"lambda\": [0.5, 1.0, 2.0]\n}\n\nrmse_avg_min = 1e10\nmin_pars = None\n\n\nprint('total:', len(ParameterGrid(par_grid)))\nfor n, par in enumerate(ParameterGrid(par_grid)):\n    print(f'step {n}')\n    \n    model_pars = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n    }\n    \n    for k, v in par.items():\n        model_pars[k] = v \n    \n    res = xgb_model(X, y, model_pars)\n    \n    rmse_avg = np.mean(res['rmse_arr'])\n    \n    if rmse_avg < rmse_avg_min:\n        rmse_avg_min = rmse_avg\n        min_pars = par\n\n        \nprint(f'Best AVG RMSE: {rmse_avg_min}')\nprint('Best parameters:', min_pars)","f629e1fe":"print(f'With tunned parameters:', min_pars)\nprint('xgb model gives:')\nres = xgb_model(X, y, min_pars)","5589dac4":"plt.figure(figsize=(12, 6))\nplt.plot(np.abs(res['y_pred'] - res['y_val']), '.')\nplt.title('Abs deviation from validation set.')\nplt.ylabel('Rentals')\nplt.show()","9f8fb2b9":"# Here we will take a closer look at the feature selection on the example of the Bike Rentals dataset.\nData source and description:\n\nhttp:\/\/archive.ics.uci.edu\/ml\/datasets\/Bike+Sharing+Dataset\n\n# Plan:\n1. Data exploration.\n2. Random forest model.\n3. Feature importance understanding and selection.\n\n# References:\n - https:\/\/arxiv.org\/pdf\/1309.6392.pdf\n - Friedman, Jerome H. \u201cGreedy function approximation: A gradient boosting machine.\u201d Annals of statistics (2001): 1189-1232.\u21a9\n\n","ca21284b":"Temperature plays a big role, no surprise when its cold its not pleasant to bike. These two features might depend on each other (check it later).","d180a793":"# ICE plots.","d044bd82":"RMSE rises a lot. So the hour is obviously an important feature.","568f4a85":"# Since the features are far from linear we will try a simple tree algorhitm first namely Random Forest.","7161f417":"It seems this feature captures trend in rentals.","31f3bf06":"Here humidity plays a big role.","78069d02":"Temp and atemp show clear influence on cnt.","60d76889":"# Here, we analyze feature influence on the result (feature importance).","2f829535":"Weather situation has hight variation in PDP, means high dependance. Working day plays smaller role.","a26af56d":"# Partial dependence plots.","04561f0e":"The average RMSE with xgb is smaler than with random forest.","dcea3bcb":"RMSE changes not much.","4983ace1":"Usually if one instance of the model is trained slowly, it could take a lot of time to find optimal hyperparameters in one kernel. This procedure can be done with several cores via \"lazy paralelism\".","d2138cc7":"# Simple hyperparameters tuning.\nreference:\n\nhttps:\/\/xgboost.readthedocs.io\/en\/latest\/tutorials\/param_tuning.html","6aed68e2":"# First, we will make a data exploration.","655e2b86":"Weekday plays a significant role.","158bfa34":"Here we can a see strong dependance on \"hour\", obviously people rent more during day than night and at specific hours.","f6d734a8":"As expected removing atemp changes RMSE not much (almost the same value).","a39b3a00":"Days since is an importnt feature.","98eb7888":"# XGB Model.","85305253":"Now we are going to exclude couple of important features and not important and understand its influence on the resulting score.","2df59f1b":"Temp or atemp can be excluded (one of them)."}}