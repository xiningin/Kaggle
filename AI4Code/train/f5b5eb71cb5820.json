{"cell_type":{"6b5163f5":"code","cf4a5da3":"code","739b0c7b":"code","2a0715f8":"code","c6394c60":"code","ddd9bd6d":"code","2fdc481f":"code","f89950c5":"code","c8488bab":"code","cd5a9350":"code","6ffdf4d9":"code","07a98326":"code","2814c5ab":"code","d3476b6d":"markdown"},"source":{"6b5163f5":"import os\nimport sys\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFilter\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, mean_squared_error, log_loss, confusion_matrix\nimport matplotlib.pyplot as plt\n\nnp.random.seed(100)\nLEVEL = 'level_1'","cf4a5da3":"class SigmoidNeuron:\n    def __init__(self):\n        self.w = None\n        self.b = None\n    \n    def perceptron(self, x):\n        return np.dot(x, self.w.T) + self.b\n    \n    def sigmoid(self, x):\n        return 1.0\/(1.0 + np.exp(-x))\n    \n    def grad_w_mse(self, x, y):\n        y_pred = self.sigmoid(self.perceptron(x))\n        return (y_pred - y) * y_pred * (1 - y_pred) * x\n    \n    def grad_b_mse(self, x, y):\n        y_pred = self.sigmoid(self.perceptron(x))\n        return (y_pred - y) * y_pred * (1 - y_pred)\n    \n    def grad_w_ce(self, x, y):\n        y_pred = self.sigmoid(self.perceptron(x))\n        if y == 0:\n            return y_pred * x\n        elif y == 1:\n            return -1 * (1 - y_pred) * x\n        else:\n            raise ValueError(\"y should be 0 or 1\")\n    \n    def grad_b_ce(self, x, y):\n        y_pred = self.sigmoid(self.perceptron(x))\n        if y == 0:\n            return y_pred \n        elif y == 1:\n            return -1 * (1 - y_pred)\n        else:\n            raise ValueError(\"y should be 0 or 1\")\n    \n    def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n        if initialise:\n            self.w = np.random.randn(1, X.shape[1])\n            self.b = 0\n        if display_loss:\n            loss = {}\n    \n        for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n            dw = 0\n            db = 0\n            for x, y in zip(X, Y):\n                if loss_fn == \"mse\":\n                    dw += self.grad_w_mse(x, y)\n                    db += self.grad_b_mse(x, y) \n                elif loss_fn == \"ce\":\n                    dw += self.grad_w_ce(x, y)\n                    db += self.grad_b_ce(x, y)\n            self.w -= learning_rate * dw\n            self.b -= learning_rate * db\n            if display_loss:\n                Y_pred = self.sigmoid(self.perceptron(X))\n                if loss_fn == \"mse\":\n                    loss[i] = mean_squared_error(Y, Y_pred)\n                elif loss_fn == \"ce\":\n                    loss[i] = log_loss(Y, Y_pred)\n    \n        if display_loss:\n            plt.plot(loss.values())\n            plt.xlabel('Epochs')\n        if loss_fn == \"mse\":\n            plt.ylabel('Mean Squared Error')\n        elif loss_fn == \"ce\":\n            plt.ylabel('Log Loss')\n            plt.show()\n\n    def predict(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.sigmoid(self.perceptron(x))\n            Y_pred.append(y_pred)\n        return np.array(Y_pred)","739b0c7b":"def read_all(folder_path, key_prefix=\"\"):\n    '''\n    It returns a dictionary with 'file names' as keys and 'flattened image arrays' as values.\n    '''\n    print(\"Reading:\")\n    images = {}\n    files = os.listdir(folder_path)\n    for i, file_name in tqdm_notebook(enumerate(files), total=len(files)):\n        file_path = os.path.join(folder_path, file_name)\n        image_index = key_prefix + file_name[:-4]\n        image = Image.open(file_path)\n        image = image.convert(\"L\")\n        images[image_index] = np.array(image.copy()).flatten()\n        image.close()\n    return images","2a0715f8":"languages = ['ta', 'hi', 'en']\n\nimages_train = read_all(\"..\/input\/level_1_train\/level_1\/\"+\"background\", key_prefix='bgr_') # change the path\nfor language in languages:\n    images_train.update(read_all(\"..\/input\/level_1_train\/level_1\/\"+language, key_prefix=language+\"_\" ))\nprint(len(images_train))\n\nimages_test = read_all(\"..\/input\/level_1_test\/kaggle_level_1\", key_prefix='') # change the path\nprint(len(images_test))","c6394c60":"list(images_test.keys())[:5]","ddd9bd6d":"X_train = []\nY_train = []\nfor key, value in images_train.items():\n    X_train.append(value)\n    if key[:4] == \"bgr_\":\n        Y_train.append(0)\n    else:\n        Y_train.append(1)\n\nID_test = []\nX_test = []\nfor key, value in images_test.items():\n    ID_test.append(int(key))\n    X_test.append(value)\n\nX_train = np.array(X_train)\nY_train = np.array(Y_train)\nX_test = np.array(X_test)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape)","2fdc481f":"scaler = StandardScaler()\nX_scaled_train = scaler.fit_transform(X_train)\nX_scaled_test = scaler.transform(X_test)","f89950c5":"sn_mse = SigmoidNeuron()\nsn_mse.fit(X_scaled_train, Y_train, epochs=500, learning_rate=0.011, loss_fn=\"mse\", display_loss=True)","c8488bab":"def print_accuracy(sn):\n    Y_pred_train = sn.predict(X_scaled_train)\n    Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n    accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\n    print(\"Train Accuracy : \", accuracy_train)\n    print(\"-\"*50)","cd5a9350":"print_accuracy(sn_mse)","6ffdf4d9":"sn_ce = SigmoidNeuron()\nsn_ce.fit(X_scaled_train, Y_train, epochs=300, learning_rate=0.01, loss_fn=\"ce\", display_loss=True)","07a98326":"print_accuracy(sn_ce)   ","2814c5ab":"Y_pred_test = sn_ce.predict(X_scaled_test)\nY_pred_binarised_test = (Y_pred_test >= 0.5).astype(\"int\").ravel()\n\nsubmission = {}\nsubmission['ImageId'] = ID_test\nsubmission['Class'] = Y_pred_binarised_test\n\nsubmission = pd.DataFrame(submission)\nsubmission = submission[['ImageId', 'Class']]\nsubmission = submission.sort_values(['ImageId'])\nsubmission.to_csv(\"submisision.csv\", index=False)","d3476b6d":"> ** Submission** "}}