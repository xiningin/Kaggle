{"cell_type":{"891431bd":"code","e253fd0a":"code","83f6c283":"code","76da0919":"code","2904f5a5":"code","42aec00a":"code","dd4f42ff":"code","08f38031":"code","af584122":"code","e890f77e":"code","7eba4513":"code","cc6d0d7a":"code","7b9dbc29":"code","bb6fa625":"code","4d8edce6":"code","eb25a272":"code","d25ec2be":"code","06b8efb5":"code","62301f45":"code","e2a27ed2":"code","d5ea5fda":"code","b9490943":"code","3a8b1dcf":"code","5204bd8c":"code","3e33eecc":"code","d83e14de":"code","c4ee73ee":"code","5e282ff9":"code","f82b648a":"code","0d909f43":"code","7533735d":"code","fe00aec2":"code","d47c49aa":"code","e8410637":"code","05c60bbb":"code","88227759":"code","299da567":"code","a2e49968":"code","3193c20c":"code","03a21dad":"code","8dbbf7b4":"code","b2825c8a":"markdown","42f60381":"markdown","9f6a61ce":"markdown","d7721b3a":"markdown","911c2f0b":"markdown","94038a47":"markdown","cd013748":"markdown","4dd2c7a4":"markdown"},"source":{"891431bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport datetime\nimport os\nprint(os.listdir(\"..\/input\"))\nimport numpy as np\nimport pandas as pd \nfrom collections import defaultdict\nfrom pprint import pprint\nimport xgboost as xgb\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras.utils import plot_model\nmatplotlib.rcParams['figure.figsize'] = (8, 6)\n\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nseed = 0\nnp.random.seed(seed)\n\nfrom ann_visualizer.visualize import ann_viz\n\n# Any results you write to the current directory are saved as output.","e253fd0a":"start_time = datetime.datetime.now()\n\ndemographic_cols = ['ncodpers','fecha_alta','ind_empleado','pais_residencia','sexo','age','ind_nuevo','antiguedad','indrel',\n 'indrel_1mes','tiprel_1mes','indresi','indext','conyuemp','canal_entrada','indfall',\n 'tipodom','cod_prov','ind_actividad_cliente','renta','segmento']\n\nnotuse = [\"ult_fec_cli_1t\",\"nomprov\",'fecha_dato']\n\nproduct_col = [\n 'ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1',\n 'ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1',\n 'ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1',\n 'ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1',\n 'ind_nom_pens_ult1','ind_recibo_ult1']","83f6c283":"df_train = pd.read_csv('..\/input\/datamulticlass-6-withpast2\/DataMulticlass_6_withpast2.csv')","76da0919":"df_test = pd.read_csv('..\/input\/testset-withpast3\/TestSet_withpast3.csv')","2904f5a5":"pd.set_option('display.max_columns', None)","42aec00a":"def filter_data(df):\n    df = df[df['ind_nuevo'] == 0]\n    df = df[df['antiguedad'] != -999999]\n    df = df[df['indrel'] == 1]\n    df = df[df['indresi'] == 'S']\n    df = df[df['indfall'] == 'N']\n    df = df[df['tipodom'] == 1]\n    df = df[df['ind_empleado'] == 'N']\n    df = df[df['pais_residencia'] == 'ES']\n    df = df[df['indrel_1mes'] == 1]\n    df = df[df['tiprel_1mes'] == ('A' or 'I')]\n    df = df[df['indext'] == 'N']","dd4f42ff":"filter_data(df_train)","08f38031":"drop_column = ['ind_nuevo','indrel','indresi','indfall','tipodom','ind_empleado','pais_residencia','indrel_1mes','indext','conyuemp','fecha_alta','tiprel_1mes']\n\ndf_train.drop(drop_column, axis=1, inplace = True)\ndf_test.drop(drop_column, axis=1, inplace = True)","af584122":"df_test[\"renta\"]   = pd.to_numeric(df_test[\"renta\"], errors=\"coerce\")\nunique_prov = df_test[df_test.cod_prov.notnull()].cod_prov.unique()\ngrouped = df_test.groupby(\"cod_prov\")[\"renta\"].median()\n\ndef impute_renta(df):\n    df[\"renta\"]   = pd.to_numeric(df[\"renta\"], errors=\"coerce\")       \n    for cod in unique_prov:\n        df.loc[df['cod_prov']==cod,['renta']] = df.loc[df['cod_prov']==cod,['renta']].fillna({'renta':grouped[cod]}).values\n    df.renta.fillna(df_test[\"renta\"].median(), inplace=True)\n    \nimpute_renta(df_train)\nimpute_renta(df_test)","e890f77e":"def drop_na(df):\n    df.dropna(axis = 0, subset = ['ind_actividad_cliente'], inplace = True)\n    \ndrop_na(df_train)","7eba4513":"# These column are categories feature, I'll transform them using get_dummy\ndummy_col = ['sexo','canal_entrada','cod_prov','segmento']\ndummy_col_select = ['canal_entrada','cod_prov']","cc6d0d7a":"limit = int(0.01 * len(df_train.index))\nuse_dummy_col = {}\n\nfor col in dummy_col_select:\n    trainlist = df_train[col].value_counts()\n    use_dummy_col[col] = []\n    for i,item in enumerate(trainlist):\n        if item > limit:\n            use_dummy_col[col].append(df_train[col].value_counts().index[i])   ","7b9dbc29":"def get_dummy(df):\n    for col in dummy_col_select:\n        for item in df[col].unique(): \n            if item not in use_dummy_col[col]:\n                row_index = df[col] == item\n                df.loc[row_index,col] = np.nan\n    return pd.get_dummies(df, prefix=dummy_col, columns = dummy_col)\n    \ndf_train = get_dummy(df_train)\ndf_test = get_dummy(df_test)","bb6fa625":"def clean_age(df):\n    df[\"age\"]   = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n    max_age = 80 \n\n    df[\"age\"]   = df['age'].apply(lambda x: min(x ,max_age))\n    df[\"age\"]   = df['age'].apply(lambda x: round( x\/max_age, 6))\n\ndef clean_renta(df):\n    max_renta = 1.0e6\n\n    df[\"renta\"]   = df['renta'].apply(lambda x: min(x ,max_renta))\n    df[\"renta\"]   = df['renta'].apply(lambda x: round( x\/max_renta, 6))\n    \ndef clean_antigue(df):\n    df[\"antiguedad\"]   = pd.to_numeric(df[\"antiguedad\"], errors=\"coerce\")\n    df[\"antiguedad\"] = df[\"antiguedad\"].replace(-999999, df['antiguedad'].median())\n    max_antigue = 256\n\n    df[\"antiguedad\"]   = df['antiguedad'].apply(lambda x: min(x ,max_antigue))\n    df[\"antiguedad\"]   = df['antiguedad'].apply(lambda x: round( x\/max_antigue, 6))  ","4d8edce6":"clean_age(df_train)\nclean_age(df_test)\n\nclean_renta(df_train)\nclean_renta(df_test)\n\nclean_antigue(df_train)\nclean_antigue(df_test)\n","eb25a272":"product_col_5 = [col for col in df_train.columns if '_ult1_5' in col]\nproduct_col_4 = [col for col in df_train.columns if '_ult1_4' in col]\nproduct_col_3 = [col for col in df_train.columns if '_ult1_3' in col]\nproduct_col_2 = [col for col in df_train.columns if '_ult1_2' in col]\nproduct_col_1 = [col for col in df_train.columns if '_ult1_1' in col]\n\ndf_train['tot5'] = df_train[product_col_5].sum(axis=1)\ndf_test['tot5'] = df_test[product_col_5].sum(axis=1)\ndf_train['tot4'] = df_train[product_col_4].sum(axis=1)\ndf_test['tot4'] = df_test[product_col_4].sum(axis=1)\ndf_train['tot3'] = df_train[product_col_3].sum(axis=1)\ndf_test['tot3'] = df_test[product_col_3].sum(axis=1)\ndf_train['tot2'] = df_train[product_col_2].sum(axis=1)\ndf_test['tot2'] = df_test[product_col_2].sum(axis=1)\ndf_train['tot1'] = df_train[product_col_1].sum(axis=1)\ndf_test['tot1'] = df_test[product_col_1].sum(axis=1)","d25ec2be":"for col in product_col[2:]:\n    df_train[col+'_past'] = (df_train[col+'_5']+df_train[col+'_4']+df_train[col+'_3']+df_train[col+'_2']+df_train[col+'_1'])\/5\n    df_test[col+'_past'] = (df_test[col+'_5']+df_test[col+'_4']+df_test[col+'_3']+df_test[col+'_2']+df_test[col+'_1'])\/5","06b8efb5":"for pro in product_col[2:]:\n    df_train[pro+'_past'] = df_train[pro+'_past']*(1-df_train[pro+'_5'])\n    df_test[pro+'_past'] = df_test[pro+'_past']*(1-df_test[pro+'_5'])","62301f45":"for col in product_col[2:]:\n    for month in range(2,6):\n        df_train[col+'_'+str(month)+'_diff'] = df_train[col+'_'+str(month)] - df_train[col+'_'+str(month-1)]\n        df_test[col+'_'+str(month)+'_diff'] = df_test[col+'_'+str(month)] - df_test[col+'_'+str(month-1)]\n        df_train[col+'_'+str(month)+'_add'] = df_train[col+'_'+str(month)+'_diff'].apply(lambda x: max(x,0))\n        df_test[col+'_'+str(month)+'_add'] = df_test[col+'_'+str(month)+'_diff'].apply(lambda x: max(x,0))","e2a27ed2":"product_col_5_diff = [col for col in df_train.columns if '5_diff' in col]\nproduct_col_4_diff = [col for col in df_train.columns if '4_diff' in col]\nproduct_col_3_diff = [col for col in df_train.columns if '3_diff' in col]\nproduct_col_2_diff = [col for col in df_train.columns if '2_diff' in col]\n\nproduct_col_5_add = [col for col in df_train.columns if '5_add' in col]\nproduct_col_4_add = [col for col in df_train.columns if '4_add' in col]\nproduct_col_3_add = [col for col in df_train.columns if '3_add' in col]\nproduct_col_2_add = [col for col in df_train.columns if '2_add' in col]\n\nproduct_col_all_diff = [col for col in df_train.columns if '_diff' in col]\nproduct_col_all_add = [col for col in df_train.columns if '_add' in col]","d5ea5fda":"df_train['tot5_add'] = df_train[product_col_5_add].sum(axis=1)\ndf_test['tot5_add'] = df_test[product_col_5_add].sum(axis=1)\ndf_train['tot4_add'] = df_train[product_col_4_add].sum(axis=1)\ndf_test['tot4_add'] = df_test[product_col_4_add].sum(axis=1)\ndf_train['tot3_add'] = df_train[product_col_3_add].sum(axis=1)\ndf_test['tot3_add'] = df_test[product_col_3_add].sum(axis=1)\ndf_train['tot2_add'] = df_train[product_col_2_add].sum(axis=1)\ndf_test['tot2_add'] = df_test[product_col_2_add].sum(axis=1)","b9490943":"df_train.head()","3a8b1dcf":"df_test.head()","5204bd8c":"cols = list(df_train.drop(['target','ncodpers']+product_col_all_diff+product_col_all_add, 1).columns.values)\n\nid_preds = defaultdict(list)\nids = df_test['ncodpers'].values\n\n# predict model \ny_train = pd.get_dummies(df_train['target'].astype(int))\nx_train = df_train[cols]","3e33eecc":"# create model\nmodel = Sequential()\nmodel.add(Dense(150, input_dim=len(cols), activation='relu'))\nmodel.add(Dense(22, activation='softmax'))\n# Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['categorical_accuracy'])\n\nmodel.fit(x_train.as_matrix(), y_train.as_matrix(), validation_split=0.2, nb_epoch=150, batch_size=10)\n#model.fit(x_train.as_matrix(), y_train.as_matrix(), nb_epoch=150, batch_size=10)\n\nx_test = df_test[cols]\nx_test = x_test.fillna(0) \n        \np_test = model.predict(x_test.as_matrix())\n        \nfor id, p in zip(ids, p_test):\n    #id_preds[id] = list(p)\n    id_preds[id] = [0,0] + list(p)","d83e14de":"len(cols)","c4ee73ee":"x_train","5e282ff9":"model.inputs","f82b648a":"model.summary()","0d909f43":"model.outputs","7533735d":"customer=list(id_preds.keys())","fe00aec2":"fraction = 1\nid_preds_combined = {}\n\nfor uid, p in id_preds.items():\n    id_preds_combined[uid] = fraction*np.asarray(id_preds[uid])\n    \nid_preds = id_preds_combined    ","d47c49aa":"usecols = ['ncodpers', 'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']","e8410637":"df_recent =  pd.read_csv('..\/input\/train-ver2\/train_ver2.csv',usecols=usecols)\ndf_recent=df_recent[df_recent['ncodpers'].isin(customer)]\ndf_recent.fillna(0, inplace=True)","05c60bbb":"sample = pd.read_csv('..\/input\/sample-submission\/sample_submission.csv')","88227759":"# check if customer already have each product or not. \nalready_active = {}\nfor row in df_recent.values:\n    row = list(row)\n    id = row.pop(0)\n    active = [c[0] for c in zip(tuple(product_col), row) if c[1] > 0]\n    already_active[id] = active\n\n# add 7 products(that user don't have yet), higher probability first -> train_pred   \ntrain_preds = {}\nfor id, p in id_preds.items():\n    preds = [i[0] for i in sorted([i for i in zip(tuple(product_col), p) if i[0] not in already_active[id]],\n                                  key=lambda i:i [1], \n                                  reverse=True)[:7]]\n    train_preds[id] = preds\n    \ntest_preds = []\nfor row in sample.values:\n    id = row[0]\n    p = train_preds[id]\n    test_preds.append(' '.join(p))\n","299da567":"print(model.summary())","a2e49968":"model.save('kerass.model')","3193c20c":"plot_model(model,show_shapes=True, to_file='model1.png')","03a21dad":"#ann_viz(model, title='Neural Network Model')","8dbbf7b4":"sample['added_products'] = test_preds\nsample.to_csv('Keras1.csv', index=False)\nprint(datetime.datetime.now()-start_time)","b2825c8a":"# Import Data","42f60381":"### Filter Data","9f6a61ce":"### Convert and make dummy","d7721b3a":"### Add missing income","911c2f0b":"# Clean Data","94038a47":"# Make submission","cd013748":"# Model","4dd2c7a4":"### Drop unneccessary column"}}