{"cell_type":{"1911fd63":"code","e37c95a8":"code","fe3dbe37":"code","019f4007":"code","d41a44f8":"code","8887ff2b":"code","96d73b85":"code","93c88514":"code","2fcb3466":"code","673d16d4":"code","5c02862e":"code","8b4248f9":"code","c0c88170":"code","3328c06f":"code","0e6f2a6d":"code","374bc2f8":"code","50ef80a8":"code","caf0f3f9":"code","37003112":"code","549483e7":"code","5d1954a4":"code","ac29ea2b":"code","63fd3419":"code","8e6868bc":"code","6d4de2dd":"code","bd842967":"code","32106c2c":"code","6d2f7c26":"code","7747860b":"code","aaefd8db":"code","09a4f188":"code","d10875d3":"code","e1633594":"code","591f2575":"code","7cf60a8b":"code","942cb17f":"code","d12b9e66":"code","b294c245":"markdown","a9e55cb3":"markdown","d1596be6":"markdown","f0ca92f4":"markdown","cc8967ea":"markdown","4545eb25":"markdown","1792b696":"markdown","a7037bd0":"markdown","c01fbb28":"markdown","2414a1e4":"markdown","5a9ea8fa":"markdown","0c44593c":"markdown","6e7e4af4":"markdown","63819e16":"markdown","83e1af7e":"markdown","b07d5a74":"markdown","7b8fbfe0":"markdown","3a7db58a":"markdown","062ead8d":"markdown","16e45d2a":"markdown","5087e656":"markdown","9895ad31":"markdown","adc28c9d":"markdown","8a758cd8":"markdown","13a0e237":"markdown","2319551d":"markdown","07de8de1":"markdown","184b2fa7":"markdown","45ce81be":"markdown","7d0d5c3c":"markdown","47c39591":"markdown","e9ebb15c":"markdown","4c3071a6":"markdown","e6fcc85e":"markdown","6d58a8a2":"markdown","c707a6bf":"markdown","356fdd4d":"markdown","68be7a17":"markdown","dbef77a2":"markdown","93a554ec":"markdown"},"source":{"1911fd63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Charts\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\nimport os","e37c95a8":"# Import Datasets\n\n# Train DF\ndf_train = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\n\n# Test DF\ndf_test = pd.read_csv('..\/input\/mobile-price-classification\/test.csv')","fe3dbe37":"df_train.head()","019f4007":"df_train.info()\n\ndf_test.info()","d41a44f8":"# Check missing value from dataset\nplt.figure(figsize=(18,18))\nplt.subplot(221)\nsns.heatmap(data=df_train.isnull())\nplt.subplot(222)\nsns.heatmap(data=df_test.isnull())","8887ff2b":"# Let's see howmany price ranges we have in train dataset\n\nplt.figure(figsize=(10,4))\nsns.set_style('whitegrid')\nsns.set(font_scale=1)\n\nsns.countplot(x='price_range', data=df_train)\nplt.xlabel('Price Ranges')\nplt.ylabel('Number of devices')\nplt.title('Price Range wise visualization')\nplt.show()","96d73b85":"# Count 4G devices\ndf_train.four_g.value_counts()","93c88514":"# Percentage of mobiles with 4G feature\n\nlabels = [\"4G Supported\",'Not supported']\nvalues = df_train['four_g'].value_counts().values\nplt.pie(values, labels=labels, autopct='%1.1f%%',shadow=True,startangle=90)","2fcb3466":"# Visulize price range on internal memory and ram which is top most parameters when anyone buy mobile phone\n\ng = sns.FacetGrid(df_train, col=\"price_range\", hue=\"price_range\")\ng.map(sns.scatterplot, \"int_memory\", \"ram\")\ng.set_axis_labels(\"Internal Memory (GB)\", \"Ram (MB)\")","673d16d4":"# Visulize \n\nplt.figure(figsize=(10,4))\nsns.set_style('whitegrid')\nsns.set(font_scale=1)\n\nsns.scatterplot(data=df_train, x='px_width', y='px_height')\nplt.xlabel('Width')\nplt.ylabel('Height')\nplt.title('Mobile Size')\nplt.show()","5c02862e":"# Visulize Screen size (Height x Width) vs Price Range\n\nplt.figure(figsize=(10,4))\nsns.set_style('whitegrid')\nsns.set(font_scale=1)\ng = sns.jointplot(data=df_train, x=\"sc_w\", y=\"sc_h\", hue=\"price_range\")\nplt.show()","8b4248f9":"# Mobile Weght vs Price range\n\nsns.jointplot(x='mobile_wt', y='price_range',data=df_train, kind='kde')","c0c88170":"def detect_outliers(df,n,features):\n    outlier_indices = []\n    \"\"\"\n    Detect outliers from given list of features. It returns a list of the indices\n    according to the observations containing more than n outliers according\n    to the Tukey method\n    \"\"\"\n    # iterate over features(columns)\n    for col in features:\n        Q1 = np.percentile(df[col], 25)\n        Q3 = np.percentile(df[col],75)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from numeric features\noutliers_to_drop = detect_outliers(df_train, 2 ,[\"battery_power\", \"clock_speed\", \"int_memory\",\n    \"m_dep\", \"mobile_wt\", \"n_cores\", \"px_height\", \"px_width\", \"ram\", \"sc_h\", \"sc_w\"])\n","3328c06f":"df_train.loc[outliers_to_drop] # Show the outliers rows","0e6f2a6d":"plt.figure(figsize=(23,20))\nsns.heatmap(df_train.corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")\n","374bc2f8":"# Explore battery power vs price\n\nplt.figure(figsize=(13,6))\ng = sns.kdeplot(df_train[\"battery_power\"][df_train[\"price_range\"] == 0], color=\"Yellow\", shade = True)\ng = sns.kdeplot(df_train[\"battery_power\"][df_train[\"price_range\"] == 1], color=\"Red\", shade = True)\ng = sns.kdeplot(df_train[\"battery_power\"][df_train[\"price_range\"] == 2], ax =g, color=\"Blue\", shade= True)\ng = sns.kdeplot(df_train[\"battery_power\"][df_train[\"price_range\"] == 3], ax =g, color=\"Green\", shade= True)\ng.set_xlabel(\"Battery Power\")\ng.set_ylabel(\"Price\")\ng.legend([\"Range 0\", \"Range 1\",\"Range 2\", \"Range 3\"])\n","50ef80a8":"# Categorical values explore\n\ng = sns.barplot(x=\"dual_sim\",y=\"price_range\",data=df_train)\ng.set_xlabel(\"Is Dual Sim?\")\ng.set_ylabel(\"Price Range\")\n","caf0f3f9":"# Ram vs Price Range\n\nplt.figure(figsize=(13,6))\ng = sns.kdeplot(df_train[\"ram\"][df_train[\"price_range\"] == 0], color=\"Yellow\", shade = True)\ng = sns.kdeplot(df_train[\"ram\"][df_train[\"price_range\"] == 1], color=\"Red\", shade = True)\ng = sns.kdeplot(df_train[\"ram\"][df_train[\"price_range\"] == 2], ax =g, color=\"Blue\", shade= True)\ng = sns.kdeplot(df_train[\"ram\"][df_train[\"price_range\"] == 3], ax =g, color=\"Green\", shade= True)\ng.set_xlabel(\"RAM\")\ng.set_ylabel(\"Price\")\ng.legend([\"Range 0\", \"Range 1\",\"Range 2\", \"Range 3\"])","37003112":"# Pixel Height vs Width vs Price Range\n\nplt.figure(figsize=(23,15))\ncmap = sns.cubehelix_palette(rot=-.2, as_cmap=True)\ng = sns.relplot(\n    data=df_train,\n    x=\"px_height\", y=\"px_width\",\n    hue=\"price_range\",\n    palette=cmap, sizes=(10, 200),\n)\ng.set(xscale=\"log\", yscale=\"log\")\ng.ax.xaxis.grid(True, \"minor\", linewidth=.25)\ng.ax.yaxis.grid(True, \"minor\", linewidth=.25)\ng.despine(left=True, bottom=True)\n","549483e7":"# Internal memory vs Price range\n\nsns.set_theme(style=\"ticks\")\n\n# Initialize the figure with a logarithmic x axis\nf, ax = plt.subplots(figsize=(7, 6))\n# ax.set_xscale(\"log\")\n\n# Plot the orbital period with horizontal boxes\nsns.boxplot(x=\"price_range\", y=\"int_memory\", data=df_train,\n            whis=[0, 100], width=.6, palette=\"vlag\")\n\n# Tweak the visual presentation\nax.xaxis.grid(True)\nax.set(ylabel=\"Internal Memory (GB)\", xlabel=\"Price Range\")\nsns.despine(trim=True, left=True)","5d1954a4":"# Categorical values explore\n\n# Initialize the figure with a logarithmic x axis\nplt.subplots(figsize=(15, 6))\n\n# Draw a nested violinplot and split the violins for easier comparison\nsns.violinplot(data=df_train, x=\"n_cores\", y=\"price_range\", hue=\"dual_sim\", \n               palette={0: \"b\", 1: \".85\"}, split=True, inner=\"quart\", linewidth=1)\nsns.despine(left=True)\nplt.ylabel(\"Price Range\")\nplt.xlabel(\"No of Core\")","ac29ea2b":"sns.set_theme(style=\"ticks\")\n\n# Initialize the figure with a logarithmic x axis\nf, ax = plt.subplots(figsize=(7, 6))\nax.set_xscale(\"log\")\n\n\n# Plot the orbital period with horizontal boxes\nsns.boxplot(x=\"price_range\", y=\"mobile_wt\", data=df_train,\n            whis=[0, 100], width=.6, palette=\"vlag\")\n\n# Tweak the visual presentation\nax.xaxis.grid(True)\nax.set(ylabel=\"Weight\", xlabel=\"Price Range\")\nsns.despine(trim=True, left=True)","63fd3419":"df_train","8e6868bc":"train_x = df_train.drop('price_range', axis=1)\ntrain_y = df_train.price_range","6d4de2dd":"print(\"Freature shape: \", train_x.shape, \" | Labels\", train_y.shape)","bd842967":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.35, random_state=5)","32106c2c":"# Importing required libraries\n\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, Lasso\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.metrics import make_scorer, accuracy_score, classification_report, confusion_matrix","6d2f7c26":"# Define models in object\nmodels = {\n    \"Linear Regression\": LinearRegression(fit_intercept=True),\n    \"KNN\": KNeighborsClassifier(),\n    \"Decisiontree\": DecisionTreeClassifier(random_state=5),\n    'RandomForest': RandomForestClassifier(max_features='sqrt', random_state=5),\n    'LogisticRegression': LogisticRegression(random_state=5),\n    'Lasso': Lasso(alpha=0.1),\n    'SVC': SVC(random_state = 5)\n}","7747860b":"# Looping through the models and fiting dataset to each model. Calculate score\nfor model in models.items():\n    m = model[1]\n    m.fit(x_train, y_train)\n    print(model[0])\n    print(\"Score: \", m.score(x_test,y_test))\n    print(\"\")\n    ","aaefd8db":"def evaluate_model(models):\n    \"\"\"\n    Takes a list of models and returns chart of cross validation scores using mean accuracy\n    \"\"\"\n    \n    # Cross validate model with Kfold stratified cross val\n    kfold = StratifiedKFold(n_splits = 10)\n    \n    result = []\n    for model in models :\n        result.append(cross_val_score(model, train_x, y = train_y, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\n    cv_means = []\n    cv_std = []\n    for cv_result in result:\n        cv_means.append(cv_result.mean())\n        cv_std.append(cv_result.std())\n\n    result_df = pd.DataFrame({\n        \"CrossValMeans\":cv_means,\n        \"CrossValerrors\": cv_std,\n        \"Models\":[\n            \"LogisticRegression\",\n            \"DecisionTreeClassifier\",\n            \"AdaBoostClassifier\",\n            \"SVC\",\n            \"RandomForestClassifier\",\n            \"GradientBoostingClassifier\",\n            \"KNeighborsClassifier\"\n        ]\n    })\n\n    # Generate chart\n    bar = sns.barplot(x = \"CrossValMeans\", y = \"Models\", data = result_df, orient = \"h\")\n    bar.set_xlabel(\"Mean Accuracy\")\n    bar.set_title(\"Cross validation scores\")\n    return result_df\n","09a4f188":"# Modeling step Test differents algorithms \nrandom_state = 30\nmodels = [\n    LogisticRegression(random_state = random_state),\n    DecisionTreeClassifier(random_state = random_state),\n    AdaBoostClassifier(DecisionTreeClassifier(random_state = random_state), random_state = random_state, learning_rate = 0.2),\n    SVC(random_state = random_state),\n    RandomForestClassifier(random_state = random_state),\n    GradientBoostingClassifier(random_state = random_state),\n    KNeighborsClassifier(),\n]\nevaluate_model(models)\n","d10875d3":"# Preparing test dataset\ndata_test = df_test.drop('id',axis=1)","e1633594":"data_test.info()\ndata_test.shape","591f2575":"x = df_train.drop('price_range', axis=1)\ny = df_train['price_range']","7cf60a8b":"# Predict price range using KNN model\nknn = SVC()\nknn.fit(x, y)\npred_price = knn.predict(data_test)","942cb17f":"# Adding Predicted price range to test dataset \ndata_test['price_range'] = pred_price","d12b9e66":"data_test.head()","b294c245":"# Missing Values Corrections","a9e55cb3":"# Mobile Price Prediction\n\nIn this project we will predict possible price of mobile phones on the base of phone specification. Mobile industry is widely expanding day by day. Lots of new mobile models coming everyday with various specification. Sometimes its hard to compare mobiles and decide which one is good and worth to buy.\n","d1596be6":"**Method - 2**","f0ca92f4":"# Import datase and initial dataset review","cc8967ea":"**Understanding Data**\n\nNext, I wanted to get a better idea of what I was working with.","4545eb25":"This is a very beginner-friendly dataset. I did not have to deal with any missing values, and there isn\u2019t much flexibility to conduct some feature engineering given these variables. Next, I wanted to explore my data a little bit more.\n","1792b696":"# Predicting Test Data","a7037bd0":"The objectives of this project are as follows\n1. To experiment with different classification methods to see which yields the highest accuracy\n2. To determine which features are the most indicative of a good quality wine\nWith that said, here we go!\n","c01fbb28":"# Data Spliting\nNext I split the data into a training and test set so that I could cross-validate my models and determine their effectiveness.\n","2414a1e4":"# Dataset Introduction\n\n**Columns**\n* id: ID\n* battery_power: Battry power in mAH (Total energy a battery can store in one time measured)\n* blue: If mobile has bluetooth or not\n* clock_speed: microprocessor speed to executes instructions\n* dual_sim: Dual sim or not\n* fc:Front Camera mega pixels\n* four_g:Has 4G or not\n* int_memory: Internal Memory in Gigabytes\n* m_dep: Mobile Depth in cm\n* mobile_wt: Weight\n* n_cores: Number of cores of processor\n* pc:Primary Camera mega pixels\n* px_height: Pixel Resolution Height\n* px_width: Pixel Resolution Width\n* ram: RAM in Megabytes\n* sc_h: Screen Height of mobile in cm\n* sc_w: Screen Width of mobile in cm\n* talk_time: Aingle battery charge's longest time\n* three_g: Has 3G or not\n* touch_screen: Touch screen or not\n* wifi: Has wifi or not\n","5a9ea8fa":"**Pixel Height & Width**","0c44593c":"**dual_sim**","6e7e4af4":"When we superimpose the two densities , we cleary see a peak correponsing (between 300 and 2500) to battery power\n\n","63819e16":"**ram**","83e1af7e":"Phone size data is consistant. As height is increasing, width is increasing which is ideal case","b07d5a74":"**battery_power**","7b8fbfe0":"# Objectives","3a7db58a":"1043 devices has 4G and 957 devices does not have 4G","062ead8d":"On the base of validation scores, I decided to go with SVC as it have 0.94 of Mean accuracy\n\n","16e45d2a":"Range 1 has large range of ram configurations where as for range 0 and 3 have lower and higher configuration of ram respactively","5087e656":"Here we can see price range 0 has lower configuration. Configuration is increasing when price range is increasing. Mobiles with price range 4 has more RAM comparing to others.\n\nI also observed there are some mobiles with higher RAM in price range 1 and 2","9895ad31":"# Data Visualization","adc28c9d":"I compared 7 most popular classification models and evaluate the mean accuracy by kfold cross validation procedure\n","8a758cd8":"According to the correlations, battery power, ram, px_height, px_width are more correlated with price. Interesting fact is screen height and width are not correlated with price","13a0e237":"# Outlier Detection","2319551d":"We have 2000 records in train dataset and 1000 records in test dataset. The data looks very clean by looking at the first five rows, but I still wanted to make sure that there were no missing values.\n","07de8de1":"Next I wanted to see the correlations between the variables that I\u2019m working with. This allows me to get a much better understanding of the relationships between my variables in a quick glimpse.\n\nImmediately, I can see that there are some variables that are strongly correlated to price range. It\u2019s likely that these variables are also the most important features in our machine learning model, but we\u2019ll take a look at that later.\n","184b2fa7":"For this project, I wanted to compare five different machine learning models: decision trees, random forests, AdaBoost, Gradient Boost, KNeighbors and LogisticRegression. For the purpose of this project, I wanted to compare these models by their accuracy.\n","45ce81be":"**No of Core**","7d0d5c3c":"From above test we found that SVC predicted the price range most accurately. This is the method-2 to compare the models, you can use any of it","47c39591":"I used Tukey method. Tukey method is a single-step multiple comparison procedure and statistical test. It can be used to find means that are significantly different from each other. I detected outliers from the numerical values features (Age, anaemia, creatinine_phosphokinase etc). Then, i considered outliers as rows that have at least two outlied numerical values.","e9ebb15c":"# Model Evaluation & Cross Validate Models","4c3071a6":"- Dataset Introduction\n- Objectives\n- Import datase and initial dataset review\n- Missing Values Corrections\n- Data Visualization\n- Outlier Detection\n- Feature Enginnering\n- Data Spliting\n- Model Evaluation & Cross Validate Models\n- Predicting Test Data","e6fcc85e":"**Internal memory**","6d58a8a2":"Awesome, There is not features containing more than 2 outliers","c707a6bf":"**Method - 1**","356fdd4d":"**Please upvote if you like **","68be7a17":"**To be continued**","dbef77a2":"First, I wanted to see the distribution of the price range variable. I wanted to make sure that I had enough price ranges in my dataset \n","93a554ec":"# Feature Enginnering"}}