{"cell_type":{"57a084d7":"code","1f3b9995":"code","d192805d":"code","e7265340":"code","01624313":"code","5505b382":"code","a42a06dd":"code","baf9c621":"code","83090211":"code","468498b7":"code","5e1a429d":"code","28557d76":"code","aa7c285f":"code","06716a08":"code","a608e90a":"code","e44c0712":"code","b2f1c6ae":"code","58f65884":"code","ec795c87":"code","b3c18396":"code","ac434506":"code","a3ce7678":"code","dee535f0":"code","6fb9f705":"code","7c36fb3c":"code","2ec6758d":"code","a49957ab":"code","0c62f3e7":"code","fe48fa45":"code","0c3c727b":"code","38755d2f":"code","cbbdb742":"code","bf9fa542":"code","fb4d3ae3":"code","f875abe5":"code","cb49a9ca":"code","e55d5394":"code","bd034b0a":"code","f6e6a848":"code","c69d398e":"code","83aba95a":"code","465bc59e":"code","5d0353a2":"code","b80f72d9":"code","4bf63cf5":"code","953f9ae9":"code","8a5216fb":"code","4c88df14":"code","68991c81":"code","9d8e8410":"code","f42cfe77":"code","cc862e85":"code","f610389e":"code","8650d88d":"code","51da1c68":"code","306f6205":"code","ea4fa3b5":"markdown","efbe4841":"markdown","bbe6c4e3":"markdown","d03700cd":"markdown","6f41c629":"markdown","e4d01110":"markdown","82a67a42":"markdown","3087635a":"markdown","0b8cf4e2":"markdown","7e16c8e1":"markdown","aa1a4bfb":"markdown","c324a36e":"markdown","e053e43f":"markdown","9d8a00a8":"markdown","700127e8":"markdown","7972d7b4":"markdown","6fcca51e":"markdown","0f483bce":"markdown","5aabbc8e":"markdown","ab3339a3":"markdown","18f0733a":"markdown","dbab06cd":"markdown","b00a1a1e":"markdown","88344094":"markdown","4fb5cc77":"markdown","eb13ef9f":"markdown","73e7628f":"markdown","08f6d6a9":"markdown","3fd48f68":"markdown","f3b7f2c0":"markdown"},"source":{"57a084d7":"!pip install tensorflow==2.2.0","1f3b9995":"import tensorflow as tf","d192805d":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e7265340":"tf.__version__","01624313":"PATH = \"..\/input\/chest-xray-pneumonia\/chest_xray\"","5505b382":"train_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'val')\ntest_dir = os.path.join(PATH, 'test')\n\ntrain_normal = os.path.join(train_dir ,'NORMAL')\ntrain_pneu   = os.path.join(train_dir ,'PNEUMONIA')\nvalidation_normal = os.path.join(validation_dir , 'NORMAL')\nvalidation_pnem = os.path.join(validation_dir , 'PNEUMONIA')\ntest_normal = os.path.join(test_dir ,'NORMAL')\ntest_pnem   = os.path.join(test_dir ,'PNEUMONIA')","a42a06dd":"num_normal_tr = len(os.listdir(train_normal))\nnum_pnem_tr = len(os.listdir(train_pneu))\n\nnum_normal_val = len(os.listdir(validation_normal))\nnum_pnem_val = len(os.listdir(validation_pnem))\n\nnum_normal_test = len(os.listdir(test_normal))\nnum_pnem_test = len(os.listdir(test_pnem))\n\ntotal_train = num_normal_tr + num_pnem_tr\ntotal_val = num_normal_val + num_pnem_val\ntotal_test = num_normal_test + num_pnem_test\n\nprint('total training normal images:', num_normal_tr)\nprint('total training pnemonia images:', num_pnem_tr)\n\nprint('total validation normal images:', num_normal_val)\nprint('total validation pnemonia images:', num_pnem_val)\n\nprint('total test normal images:', num_normal_test)\nprint('total test pnemonia images:', num_pnem_test)\nprint(\"--\")\nprint(\"Total training images:\", total_train)\nprint(\"Total validation images:\", total_val)\nprint(\"Total test images:\", total_test)","baf9c621":"list_train_normal_ds = tf.data.Dataset.list_files(str(train_dir + '*\/NORMAL\/*'))\nlist_train_pneu_ds = tf.data.Dataset.list_files(str(train_dir + '*\/PNEUMONIA\/*'))\nlist_val_normal_ds = tf.data.Dataset.list_files(str(validation_dir + '*\/NORMAL\/*'))\nlist_val_pneu_ds = tf.data.Dataset.list_files(str(validation_dir + '*\/PNEUMONIA\/*'))","83090211":"list_combined_normal = list_train_normal_ds.concatenate(list_val_normal_ds)\nlist_combined_pnem = list_train_pneu_ds.concatenate(list_val_pneu_ds)","468498b7":"total_val_train_combined_normal = len(list(list_combined_normal.as_numpy_iterator()))\ntotal_val_train_combined_pnem = len(list(list_combined_pnem.as_numpy_iterator()))\nprint(\"Total normal images after combining train and validation:\",total_val_train_combined_normal)\nprint(\"Total pneumonia images after combining train and validation:\",total_val_train_combined_pnem)","5e1a429d":"val_normal_size = int(0.15 * total_val_train_combined_normal)\nval_pnem_size = int(0.10 * total_val_train_combined_pnem)\n\nlist_combined_normal_ds = list_combined_normal.shuffle(1000)\nlist_combined_normal = list(list_combined_normal_ds.as_numpy_iterator())\n\nlist_val_normal = list_combined_normal[:val_normal_size]\nlist_train_normal = list_combined_normal[val_normal_size:]\n\nlist_val_normal_dataset = tf.data.Dataset.from_tensor_slices(list_val_normal)\nlist_train_normal_dataset = tf.data.Dataset.from_tensor_slices(list_train_normal)","28557d76":"len(set(list(list_val_normal_dataset.as_numpy_iterator())) & set(list(list_train_normal_dataset.as_numpy_iterator())))","aa7c285f":"list_combined_pnem_ds = list_combined_pnem.shuffle(4000)\nlist_combined_pnem = list(list_combined_pnem_ds.as_numpy_iterator())\n\nlist_val_pnem = list_combined_pnem[:val_pnem_size]\nlist_train_pnem = list_combined_pnem[val_pnem_size:]\n\nlist_val_pnem_dataset = tf.data.Dataset.from_tensor_slices(list_val_pnem)\nlist_train_pnem_dataset = tf.data.Dataset.from_tensor_slices(list_train_pnem)","06716a08":"len(set(list(list_val_pnem_dataset.as_numpy_iterator())) & set(list(list_train_pnem_dataset.as_numpy_iterator())))","a608e90a":"list_val_ds = list_val_normal_dataset.concatenate(list_val_pnem_dataset).shuffle(500)\nlist_train_ds = list_train_normal_dataset.concatenate(list_train_pnem_dataset).shuffle(4600)\nlist_test_ds = tf.data.Dataset.list_files(str(test_dir + '*\/*\/*'), shuffle=False)","e44c0712":"len(set(list(list_val_ds.as_numpy_iterator())) & set(list(list_train_ds.as_numpy_iterator())) & set(list(list_test_ds.as_numpy_iterator())))","b2f1c6ae":"total_train = len(list(list_train_ds.as_numpy_iterator()))\ntotal_val = len(list(list_val_ds.as_numpy_iterator()))\nprint(\"Total train after split:\",total_train)\nprint(\"Total validation after split:\", total_val)\nprint(\"Total test:\", len(list(list_test_ds.as_numpy_iterator())))","58f65884":"for f in list_train_ds.take(5):\n  print(f.numpy())","ec795c87":"for f in list_val_ds.take(5):\n  print(f.numpy())","b3c18396":"IMG_WIDTH = 224\nIMG_HEIGHT = 224\nBATCH_SIZE = 32\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","ac434506":"def get_label(file_path):\n  # convert the path to a list of path components\n  parts = tf.strings.split(file_path, os.path.sep)\n  #The second to last is the class-directory\n  if (parts[-2] == 'PNEUMONIA'):\n    class_label = 1\n  else:\n    class_label = 0\n  return class_label\n\ndef decode_img(img):\n  # convert the compressed string to a 3D uint8 tensor\n  img = tf.image.decode_jpeg(img, channels=3)\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  # resize the image to the desired size.\n  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n\ndef process_path(file_path):\n  label = get_label(file_path)\n  # load the raw data from the file as a string\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label","a3ce7678":"# Set `num_parallel_calls` so multiple images are loaded\/processed in parallel.\nlabeled_train_ds = list_train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nlabeled_val_ds = list_val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nlabeled_test_ds = list_test_ds.map(process_path, num_parallel_calls=AUTOTUNE)","dee535f0":"for image, label in labeled_train_ds.take(1):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())","6fb9f705":"def prepare_for_training(ds, cache=True, shuffle_buffer_size=4000):\n  # This is a small dataset, only load it once, and keep it in memory.\n  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n  # fit in memory.\n  if cache:\n    if isinstance(cache, str):\n      ds = ds.cache(cache)\n    else:\n      ds = ds.cache()\n\n  ds = ds.shuffle(buffer_size=shuffle_buffer_size)#, reshuffle_each_iteration = True)\n\n  # Repeat forever\n  ds = ds.repeat()\n\n  ds = ds.batch(BATCH_SIZE)\n\n  # `prefetch` lets the dataset fetch batches in the background while the model\n  # is training.\n  ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n  return ds","7c36fb3c":"train_ds = prepare_for_training(labeled_train_ds)\nimage_batch, label_batch = next(iter(train_ds))","2ec6758d":"image_batch.numpy().shape","a49957ab":"label_batch","0c62f3e7":"def show_batch(image_batch, label_batch):\n  plt.figure(figsize=(10,10))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.title(label_batch[n].numpy())\n      plt.axis('off')","fe48fa45":"show_batch(image_batch, label_batch)","0c3c727b":"IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n\n# Create the base model from the pre-trained model MobileNet V2\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","38755d2f":"feature_batch = base_model(image_batch)\nprint(feature_batch.shape)","cbbdb742":"base_model.trainable = False","bf9fa542":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","fb4d3ae3":"prediction_layer = tf.keras.layers.Dense(1)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","f875abe5":"model = tf.keras.Sequential([\n  base_model,\n  global_average_layer,\n  prediction_layer\n])","cb49a9ca":"lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n  0.0001,\n  decay_steps=(total_train \/\/ BATCH_SIZE)*15,\n  decay_rate=1,\n  staircase=False)\n\ndef get_optimizer():\n  return tf.keras.optimizers.RMSprop(lr_schedule)","e55d5394":"base_learning_rate = 0.0001\nmodel.compile(optimizer=get_optimizer(),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","bd034b0a":"model.summary()","f6e6a848":"initial_epochs = 15\nvalidation_steps=total_val \/\/ BATCH_SIZE\n\nloss0,accuracy0 = model.evaluate(labeled_val_ds.batch(32), steps = validation_steps)","c69d398e":"print(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","83aba95a":"history = model.fit(train_ds,\n                    epochs=initial_epochs,\n                    steps_per_epoch=total_train \/\/ BATCH_SIZE,\n                    validation_data=labeled_val_ds.batch(32),\n                    validation_steps=total_val \/\/ BATCH_SIZE)","465bc59e":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","5d0353a2":"base_model.trainable = True","b80f72d9":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","4bf63cf5":"# We should recompile the model for the above changes to take effect\n# Also using a much lower learning rate..\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate\/10),\n              metrics=['accuracy'])","953f9ae9":"model.summary()","8a5216fb":"len(model.trainable_variables)","4c88df14":"fine_tune_epochs = 12\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(train_ds,\n                         epochs=total_epochs,\n                         steps_per_epoch=total_train \/\/ BATCH_SIZE,\n                         initial_epoch =  history.epoch[-1],\n                         validation_data=labeled_val_ds.batch(32),\n                         validation_steps=total_val \/\/ BATCH_SIZE\n                         )","68991c81":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","9d8e8410":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","f42cfe77":"model.evaluate(labeled_test_ds.batch(32))","cc862e85":"predictions_logits = model.predict(labeled_test_ds.batch(32))\nprediction_labels = np.where(predictions_logits >=0, 1, 0)","f610389e":"orig_test_labels = [image_lable_tuple[1] for image_lable_tuple in list(labeled_test_ds.as_numpy_iterator())]","8650d88d":"cf_matrix = tf.math.confusion_matrix(orig_test_labels, prediction_labels.squeeze())\ncf_matrix","51da1c68":"fig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(cf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","306f6205":"tn, fp, fn, tp = cf_matrix.numpy().ravel()\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\n\nprint(\"Recall of the model is {:.4f}\".format(recall))\nprint(\"Precision of the model is {:.4f}\".format(precision))","ea4fa3b5":"After the train\/validation split for pneumonia images, making sure that same images are not present in both validation and training set.","efbe4841":"We will initially set the base model trainable to false","bbe6c4e3":"Shuffling, batching and caching the training data.","d03700cd":"After combining the training and validation data:\n\n-taking 15% of normal images to validation set\n\n-taking 10% of pneumonia images to validation set","6f41c629":"So, we have got accuracy of 88.30%. Note that when this notebook is rerun, then this accuracy value may vary slightly. I think this is possibly due to randomness of variable initializations.","e4d01110":"Train\/validation split for pneumonia images:","82a67a42":"To get the image data and label from file path:","3087635a":"Note that the first dimension now indicates the batch size:","0b8cf4e2":"Since this data set is slightly imbalanced, we cannot completely rely on accuracy as metric. Hence computing and plotting confusion matrix, to understand the performance of the model.","7e16c8e1":"By now, we have trained for the weights of output layer.\n\nLet us now fine tune the model by unfreezing a few layers in mobileNet and then retraining it.","aa1a4bfb":"Training this model for 15 epochs","c324a36e":"Adding a dense layer with only one unit, as this is a binary classification problem","e053e43f":"After the train\/validation split for normal images, making sure that same images are not present in both validation and training set.","9d8a00a8":"Plotting and viewing the training data:","700127e8":"Adding a global average pooling layer to get the 1280 dimensional feature vector for images","7972d7b4":"Hello everyone!\nI tried out different possible model architectures for this problem, but the best I was able to get was from transer learning and fine tuning from mobileNet. In fact, I was surprised to see 88.3% accuracy. with 99% recall and 83% precison. Hence decided to share this with everyone.\n\nThis tensorflow tutorial about transfer learning helped me a lot: https:\/\/www.tensorflow.org\/tutorials\/images\/transfer_learning\n\nAt the time of creating this, the default version of tensorflow in kaggle notebook was 2.1.0. I wanted to use tensorflow version 2.2.0. Hence have installed 2.2.0 tensorflow version.","6fcca51e":"Since the number of validation images is very less, decided to combine the training and validation set images. Then shuffle and split to get more data for validatoin.","0f483bce":"Analysing the number of norma\/pneumonia images in train,validation and test sets:","5aabbc8e":"Printing and checking the values in list:","ab3339a3":"Making sure that there is no repeated images in train, test and validation sets","18f0733a":"Evaluating the model with test data:","dbab06cd":"Now, the basic preprocessing and data visualization has been done and we move on to transfer learning.","b00a1a1e":"Fine tuning for 12 epochs:","88344094":"Now we have enough number of validation records, with which we can do validation during training.","4fb5cc77":"Checking the tensorflow version to make sure Tf 2.2.0 has been installed successfully","eb13ef9f":"Calculating precision and recall:","73e7628f":"so, this model has accuracy of 88.3%, Recall:99.23%, Precision:83.23%\n\nHope someone finds this notebook useful! \n\nThank you :)","08f6d6a9":"Checkind the shape of image and label:","3fd48f68":"Note that, test set is untouched and have set shuffle to flase, as we need to retain order to calculate precison and recall in later stage.","f3b7f2c0":"Setting image size, batch size.\n\nSetting autotune value"}}