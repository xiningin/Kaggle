{"cell_type":{"ec716c05":"code","9e3b61be":"code","8168e9e5":"code","92b0a894":"code","5dd1bfc8":"code","4b2c6eda":"code","c6bbffa8":"code","5c3ae428":"code","022d5ddd":"code","515e0b84":"code","4db0ab41":"code","106236ce":"code","856c6b27":"code","a21bfb6e":"code","79c5f55d":"code","4fbe7190":"code","c3bc3716":"code","05b4c042":"code","08d5a6e9":"code","b9428eb8":"code","52faa736":"code","72161b73":"code","488e1ae9":"code","9733dfa1":"code","fd97af0d":"code","8cd6507e":"code","fc0de550":"code","f436fca3":"markdown","daa8569f":"markdown","35bf5e3b":"markdown","34ee4fbe":"markdown","1007286f":"markdown","2c5121fb":"markdown"},"source":{"ec716c05":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport xgboost\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf","9e3b61be":"# Load the dataset\ntrain_df = pd.read_csv('..\/input\/cat-in-the-dat\/train.csv')\ntest_df = pd.read_csv('..\/input\/cat-in-the-dat\/test.csv')","8168e9e5":"train_df.head()","92b0a894":"test_df.head()","5dd1bfc8":"train_df.shape,test_df.shape","4b2c6eda":"#check for missing values in train dataset\ntrain_df.isnull().sum()","c6bbffa8":"#check for missing values in test dataset\ntest_df.isnull().sum()","5c3ae428":"train_df.columns","022d5ddd":"nom = [\"nom_0\",\"nom_1\",\"nom_2\",\"nom_3\",\"nom_4\"]\nfor i,col in enumerate(nom):\n    plt.figure(i)\n    sns.countplot(x=train_df[col],hue=train_df[\"target\"])","515e0b84":"ords = [\"ord_0\",\"ord_1\"]\nfor i,col in enumerate(ords):\n    plt.figure(i)\n    sns.countplot(x=train_df[col],hue=train_df[\"target\"])","4db0ab41":"for feature in train_df.columns: # Loop through all columns in the dataframe\n    if train_df[feature].dtype == 'object': # Only apply for columns with categorical strings\n        train_df[feature] = pd.Categorical(train_df[feature]).codes # Replace strings with an integer","106236ce":"for feature in test_df.columns: # Loop through all columns in the dataframe\n    if test_df[feature].dtype == 'object': # Only apply for columns with categorical strings\n        test_df[feature] = pd.Categorical(test_df[feature]).codes # Replace strings with an integer","856c6b27":"train_df.head()","a21bfb6e":"# drop id and target columns from train and test dataset\ntrain_drops = [\"id\",\"target\"]\ntest_drops = [\"id\"]\nX = train_df.drop(train_drops,axis=1)\ny = train_df[\"target\"]","79c5f55d":"X.shape","4fbe7190":"std = MinMaxScaler()\nstd.fit(X)\nX_train = std.transform(X)\nX_test = std.transform(test_df.drop(test_drops,axis=1))","c3bc3716":"# RandomForestClassifier\ni=1\nkf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train,y):\n     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n     xtr,xvl = X.loc[train_index],X.loc[test_index]\n     ytr,yvl = y[train_index],y[test_index]\n    \n     model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', class_weight={0:.5,1:.5}, max_depth = 5, min_samples_leaf=5)\n     model.fit(xtr, ytr)\n     pred_test = model.predict(xvl)\n     score = accuracy_score(yvl,pred_test)\n     print('accuracy_score',score)\n     i+=1","05b4c042":"# XGBClassifier\ni=1\nkf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\nfor train_index,test_index in kf.split(X_train,y):\n     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n     xtr,xvl = X.loc[train_index],X.loc[test_index]\n     ytr,yvl = y[train_index],y[test_index]\n    \n     model = xgboost.XGBClassifier()\n     model.fit(xtr, ytr)\n     pred_test = model.predict(xvl)\n     score = accuracy_score(yvl,pred_test)\n     print('accuracy_score',score)\n     i+=1","08d5a6e9":"# split data into train and validation set\ntrainX,validX,trainy,validy = train_test_split(X_train,y)","b9428eb8":"# Build DNN\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(128,input_dim = 23, activation=\"relu\"))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(32,activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(1,activation=\"sigmoid\"))\nmodel.summary()","52faa736":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","72161b73":"model.fit(trainX,trainy,validation_data=(validX,validy),batch_size=128,epochs=30)","488e1ae9":"pred = model.predict_proba(X_test)","9733dfa1":"outs = [x[0] for x in pred]","fd97af0d":"sub = pd.DataFrame({\"id\":test_df[\"id\"],\"target\":outs})","8cd6507e":"# sub.to_csv(\"sample_submission.csv\",index=False)","fc0de550":"# from IPython.display import FileLink\n# FileLink('sample_submission.csv')","f436fca3":"### Let's apply clssification algorithms with StratifiedKFold","daa8569f":"### Nominal features","35bf5e3b":"### Let's use DNN","34ee4fbe":"### Scaling Data","1007286f":"### Let's Convert categorical strings into intergers ","2c5121fb":"### Ordinal features"}}