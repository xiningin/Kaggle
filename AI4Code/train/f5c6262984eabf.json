{"cell_type":{"515fdcd3":"code","8afb4bdf":"code","587cfa5a":"code","2725daaa":"code","0b3195e0":"code","45d8bec2":"code","90bd72df":"code","ddf07c46":"code","073d59e1":"code","2812fefa":"code","02269117":"code","86fae043":"code","9f6f5b75":"markdown","616a00bc":"markdown","2629bdec":"markdown","e09776c8":"markdown","fc61cd78":"markdown","6c203644":"markdown","1b006f64":"markdown","9f3d8d4d":"markdown","f51537aa":"markdown","2ca4025a":"markdown","5870beb3":"markdown","e31a9341":"markdown"},"source":{"515fdcd3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nglobaldata = pd.concat([train,test])","8afb4bdf":"pd.set_option('display.max_rows', 500)\n((globaldata.isna().sum()\/len(globaldata)*100).round(3))","587cfa5a":"globaldata.info()","2725daaa":"!pip install pycaret\nfrom pycaret.regression import *","0b3195e0":"reg= setup(data= train, target = 'SalePrice',train_size= 0.75,numeric_features=['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', \n                               'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr','TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'PoolArea'],\n                                ordinal_features= {'ExterQual': ['Fa', 'TA', 'Gd', 'Ex'],'ExterCond' : ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n                                'BsmtQual' : ['Fa', 'TA', 'Gd', 'Ex'],'BsmtCond' : ['Po', 'Fa', 'TA', 'Gd'],'BsmtExposure' : ['No', 'Mn', 'Av', 'Gd'],\n                                'HeatingQC' : ['Po', 'Fa', 'TA', 'Gd', 'Ex'],'KitchenQual' : ['Fa', 'TA', 'Gd', 'Ex'],'GarageQual' : ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n                                'GarageCond' : ['Po', 'Fa', 'TA', 'Gd', 'Ex']},ignore_features = ['Alley','MasVnrType','MasVnrArea','FireplaceQu',\"PoolQC\",\"Fence\",\"MiscFeature\"],         \n                                 categorical_imputation= 'mode',feature_selection = True,feature_selection_threshold= 0.8,ignore_low_variance = True, combine_rare_levels =True,\n                                 remove_outliers= True,outliers_threshold = 0.01,feature_interaction = False, feature_ratio = False,silent = True,normalize = True, \n                                 normalize_method = 'zscore', transform_target = True, transform_target_method = 'yeo-johnson')","45d8bec2":"compare_models(blacklist =['tr'],turbo = True)","90bd72df":"catboost = tune_model('catboost', n_iter = 50)\nxgboost = tune_model('xgboost', n_iter = 50)\ngbr = tune_model('gbr', n_iter = 50)\nrf = tune_model('rf', n_iter = 100)\nlightgbm = tune_model('lightgbm', n_iter = 50)\net = tune_model('et', n_iter = 100)\nsvm = tune_model('svm', n_iter = 100)","ddf07c46":"blend_specific = blend_models([catboost,xgboost,gbr,rf,lightgbm,et,svm] )","073d59e1":"final_blender = finalize_model(blend_specific)","2812fefa":"plot_model(rf,'feature') #'learning','vc','error'","02269117":"predictions = predict_model(final_blender, data = test)","86fae043":"datasets=pd.concat([test['Id'],predictions['Label']],axis=1)\ndatasets.columns=['Id','SalePrice']\ndatasets.to_csv('sample_submission.csv',index=False)","9f6f5b75":"Run the model on  hold-out set i.e 25% ; it is the final assurance and used for diagnosis of overfitting \/ underfitting","616a00bc":"Now, in the pipeline best model is now trained anow its time to predict on never seen data","2629bdec":"Now plot some Model optimizers ","e09776c8":"In this stage, create a setup (Environment)\n\n1) training and cross validation I have kept 75% of original data and rest 25% for testing.\n2) manually given the numerical feature to enhance the model as in automatic mode it was not dealing with these columns as numerical feature\n3) Ordinal feature catagories are set as in order low < medium < high\n4) In step check NA values we have seen more missing values in some features; that I have ignored\n5) Missing values in categorical features will be imputed with 'mode' or 'constant'\n6) Feature selection is by default is true and threshold can be changed\n7) To avoid dominance of one catagorical level that will not be helpful to ML model to train; ignore low varience\n8) all levels in categorical features below the threshold defined are combined together as a single level\n9) removing oitliers; 1 % data of both side of each feature data distribution\n10) I have manually supervised almost everything, thus to automate further silent= T\n11) Normalization feature scaling (feature values in standard normal distribution) ie = x-mean\/sd\n12) perform johnson transformation\n13) transform target as well","fc61cd78":"See data type for each feature","6c203644":"with blend_specific, results of above all top 5 ML models gets blend together","1b006f64":"Check NA value","9f3d8d4d":"Import basic libraries and test and train data","f51537aa":"compare ML model performance \nIn this case , Thielsen Regressor = tr takes lot of time so I wish to not run that.","2ca4025a":"import pycaret (* = import all)","5870beb3":"Predictions and save to CSV ","e31a9341":"Now, take top six best models and tune those ML models"}}