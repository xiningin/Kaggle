{"cell_type":{"35173b1d":"code","037807e0":"code","336152fc":"code","6a9a2bad":"code","0bc4705e":"code","0a7e3d95":"code","d843a811":"code","e95bb912":"code","03f4332a":"markdown","ccf6f7e4":"markdown","368a3fcc":"markdown","c759fdd8":"markdown","839208d1":"markdown","9836567e":"markdown","4fba7379":"markdown"},"source":{"35173b1d":"# general imports\nimport pandas as pd\nimport numpy as np\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nimport time\n\n# time based features\nfrom datetime import datetime\nfrom dateutil.parser import parse\n\n# sentiment analysis\nfrom textblob import TextBlob\n\n# models\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier","037807e0":"def classAssignment(x):\n    if x == True:\n        return 1\n    else:\n        return 0\n\ndef sentimentPolarity(x):\n    blob = TextBlob(x)\n    return blob.sentiment.polarity\n\ndef sentimentSubjectivity(x):\n    blob = TextBlob(x)\n    return blob.sentiment.subjectivity\n\ndef combineColumns(row):\n    concat_columns = \"\"\n    for column in row:\n        words = column.split()\n        for item in words:\n            concat_columns += \" \" + item\n    return concat_columns\n\ndef avgCommentPolarity(row):\n    concat_comments = combineColumns(row)\n    return sentimentPolarity(concat_comments)\n\ndef avgCommentSubjectivity(row):\n    concat_comments = combineColumns(row)\n    return sentimentSubjectivity(concat_comments)\n\ndef avgCommentLength(row):\n    concat_comments = combineColumns(row)\n    words = concat_comments.split()\n    return len(words)\n\ndef capitalizedWordRatio(row):\n    concat_columns = combineColumns(row)\n    capital_count = 0\n    total_count = 0\n    words = concat_columns.split()\n    \n    # check for division by 0\n    if len(words) == 0:\n        return 0\n    \n    for word in words:\n        total_count += 1\n        if word[0].isalpha() and word == word.upper():\n            capital_count += 1\n    return capital_count \/ total_count\n\ndef dayPart(time):\n    hour = parse(time).hour\n    \n    if hour < 7:\n        return \"EM\"\n    elif hour < 12:\n        return \"LM\"\n    elif hour < 17:\n        return \"EE\"\n    elif hour < 20:\n        return \"LE\"\n    elif hour < 22:\n        return \"PT\"\n    else:\n        return \"LN\"\n        \n","336152fc":"# read in data to df\n#train_data_raw = pd.read_csv(\"..\/input\/clickbait-thumbnail-detection\/train.csv\") \n#prediction_data_raw = pd.read_csv(\"..\/input\/clickbait-thumbnail-detection\/test_1.csv\")\n\n# update to test_2.csv data\ntrain_data_raw = pd.read_csv(\"..\/input\/clickbait-thumbnail-detection\/train.csv\") \nprediction_data_raw = pd.read_csv(\"..\/input\/clickbait-thumbnail-detection\/test_2.csv\")\n\n# create a dummy class column for test so the dfs are identical\nprediction_data_raw[\"class\"] = 0\n\ntrain_data_raw.head(1)","6a9a2bad":"# ~ 90 seconds\ntrain_data = pd.DataFrame()\nprediction_data = pd.DataFrame()\n\ndf_new = [train_data, prediction_data]\ndf_raw = [train_data_raw, prediction_data_raw]\n\nuser_comment_list = [\"user_comment_\" + str(x+1) for x in range(0,10)]\n\n# perform the same transformations on both datasets\nstart_time = time.time()\nfor i in range(0,2):\n    # bring in ready features\n    df_new[i] = df_raw[i][[\"ID\", \"viewCount\", \"likeCount\",\"dislikeCount\",\"commentCount\", \"class\"]]\n    \n    # turns class into 1 or 0\n    df_new[i].loc[:,\"class\"] = df_raw[i][\"class\"].apply(classAssignment)\n    \n    # title length feature\n    df_new[i].loc[:,\"title_len\"] = df_raw[i][\"title\"].apply(lambda x: len(x))\n    \n    # description length feature\n    df_new[i].loc[:,\"description_len\"] = df_raw[i][\"description\"].apply(lambda x: len(x))\n    \n    # like dislike ratio feature\n    df_new[i].loc[:,\"like_dislike_ratio\"] = (df_raw[i][\"likeCount\"] \/ df_raw[i][\"dislikeCount\"]).replace([np.inf, -np.inf], 100)\n    \n    # comment count \/ view count\n    df_new[i].loc[:,\"comment_view_ratio\"] = (df_raw[i][\"commentCount\"] \/ df_raw[i][\"viewCount\"]).replace([np.inf, -np.inf], 0)\n    \n    # comment count \/ like ratio\n    df_new[i].loc[:,\"comment_like_ratio\"] = (df_raw[i][\"commentCount\"] \/ df_raw[i][\"likeCount\"]).replace([np.inf, -np.inf], 0)\n    \n    # comment count \/ dislike ratio\n    #df_new[i].loc[:,\"comment_dislike_ratio\"] = (df_raw[i][\"commentCount\"] \/ df_raw[i][\"dislikeCount\"]).replace([np.inf, -np.inf], 0)\n    \n    # log view count\n    df_new[i].loc[:,\"log_view_count\"] = df_raw[i][\"viewCount\"].apply(lambda x: math.log2(x)).replace([np.inf, -np.inf], -1)\n    \n    # title polarity\n    df_new[i].loc[:,\"title_polarity\"] = df_raw[i][\"title\"].apply(lambda x: sentimentPolarity(x))\n    \n    # title subjectivity\n    df_new[i].loc[:,\"title_subjectivity\"] = df_raw[i][\"title\"].apply(lambda x: sentimentSubjectivity(x))\n    \n    # description polarity\n    df_new[i].loc[:,\"description_polarity\"] = df_raw[i][\"description\"].apply(lambda x: sentimentPolarity(x))\n    \n    # description subjectivity\n    df_new[i].loc[:,\"description_subjectivity\"] = df_raw[i][\"description\"].apply(lambda x: sentimentSubjectivity(x))\n    \n    # average comment length\n    df_new[i].loc[:,\"avg_comment_length\"] = df_raw[i][user_comment_list].apply(avgCommentLength, axis=1)\n    \n    # average comment polarity\n    df_new[i].loc[:,\"avg_comment_polarity\"] = df_raw[i][user_comment_list].apply(avgCommentPolarity, axis=1)\n    \n    # average comment subjectivity\n    df_new[i].loc[:,\"avg_comment_subjectivity\"] = df_raw[i][user_comment_list].apply(avgCommentSubjectivity, axis=1)\n    \n    # title capitalization ratio\n    df_new[i].loc[:,\"title_capitalization_ratio\"] = df_raw[i][\"title\"].apply(lambda x: capitalizedWordRatio(x))\n    \n    # description capitalization ratio\n    df_new[i].loc[:,\"description_capitalization_ratio\"] = df_raw[i][\"description\"].apply(lambda x: capitalizedWordRatio(x))\n    \n    # comments capitalization ratio\n    df_new[i].loc[:,\"comment_capitalization_ratio\"] = df_raw[i][user_comment_list].apply(capitalizedWordRatio, axis=1)\n    \n    # day part dummy creation\n    df_new[i].loc[:,\"day_part\"] = df_raw[i][\"timestamp\"].apply(dayPart)\n    df_new[i] = df_new[i].drop(\"day_part\", axis=1).merge(pd.get_dummies(df_new[i][\"day_part\"], prefix=\"day_part\"), \n                                                        right_index = True, left_index=True)\n    \n    df_new[i] = df_new[i].fillna(method=\"ffill\")\n    \n    print(\"Part\", i, \"created. Time: \", round(time.time() - start_time, 2))\n    \n    \n# save output into original dfs   \ntrain_data = df_new[0]\nprediction_data = df_new[1]\n\n# check that it worked\ntrain_data.head()","0bc4705e":"# check for any bad values that can cause an error in the next step\nbad_indices = np.where(np.isinf(train_data.drop(columns=[\"ID\",\"class\"], axis=1)))\nif len(bad_indices[0])== 0:\n    print(\"No bad values\")\nelse:\n    print(bad_indices)","0a7e3d95":"# split the training data into X and y\nX = train_data.drop(columns=[\"ID\",\"class\"], axis=1)\ny = train_data[[\"class\"]]\n\n# scale the training data\nsc = StandardScaler()\nX_scaled = sc.fit_transform(X)\n\n# split to test and train groups\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# print shape as a check\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","d843a811":"#model = SVC(kernel='rbf',C=3000,gamma=0.3, probability=True) # -> 91%\n#model = DecisionTreeClassifier() # -> 90.5%\n#model = LogisticRegression() # -> 81%\nmodel = XGBClassifier() # -> 90.6%\n\n# fit the model to the training data\nmodel.fit(X_train, np.array(y_train))\n\n# print score\nmetrics.fbeta_score(model.predict(X_test), np.array(y_test), beta=0.5)","e95bb912":"# scale the prediction data for input into the model\nscaled_prediction_data = sc.transform(prediction_data.drop(columns=[\"ID\",\"class\"], axis=1))\n\n# use the model to make predictions\nY_pred = model.predict(scaled_prediction_data)\n\n# assign the class for the prediction data\nprediction_data[\"class\"] = Y_pred\nprediction_data[\"class\"] = prediction_data[\"class\"].map(lambda x: \"True\" if x==1 else \"False\")\n\n# subset the relevant columns\nresult = prediction_data[[\"ID\",\"class\"]]\n\n# print to csv\nresult.to_csv(\"submission.csv\", index=False)\n\n# check the result to make sure its in the right format\nresult.head(10)","03f4332a":"<h2>Test Train Split<\/h2>","ccf6f7e4":"<h2>Imports<\/h2>","368a3fcc":"<h2>Model Training<\/h2>","c759fdd8":"<h2>Functions for feature Creation<\/h2>","839208d1":"<h2>Prediction and Output<\/h2>","9836567e":"<h2>Initial Data Read In<\/h2>","4fba7379":"<h2>Feature Creation<\/h2>"}}