{"cell_type":{"67daef3f":"code","00452a76":"code","3cae7284":"code","2df3228f":"code","6d9b1f6c":"code","07b3bdd3":"code","dc2ecd32":"code","1454545a":"code","ef860966":"code","f570214a":"code","4e74100e":"code","137bcd2d":"code","6593f1fa":"code","cd7bd901":"code","94ce8d30":"code","c919f3ec":"code","0e6fcba0":"code","b93fac5e":"code","f2b72c12":"code","f6363019":"code","f3f81ee4":"markdown","225ed746":"markdown","dce8084f":"markdown","eec1aedd":"markdown"},"source":{"67daef3f":"import random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))","00452a76":"SEED = 42 # \"Answer to the Ultimate Question of Life, the Universe, and Everything\"\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nimg_size = 64\n\nbatch_size = 64","3cae7284":"chin_mnist_df = pd.read_csv('..\/input\/chinese-mnist\/chinese_mnist.csv')\nchin_mnist_df.head(5)","2df3228f":"print(chin_mnist_df['value'].nunique())\nprint(chin_mnist_df['value'].unique())","6d9b1f6c":"# file from csv: f\"input_{suiteid}_{sampleid}_{code}.jpg\"\nitem = chin_mnist_df.iloc[0, :]\n\nimg = Image.open(f\"..\/input\/chinese-mnist\/data\/data\/input_{item['suite_id']}_{item['sample_id']}_{item['code']}.jpg\")\nprint(type(img))\nimg = np.array(img) # convert to np.array\nprint(type(img))\nplt.imshow(img, cmap='gray')","07b3bdd3":"chin_mnist_df['character'].apply(lambda char: char)","dc2ecd32":"plt.bar(np.sort(chin_mnist_df['value'].unique()).astype(np.str), chin_mnist_df['character'].value_counts())","1454545a":"# get sample for each class\n# sample is already without replacement\n#chin_mnist_df.groupby('value').apply(lambda x: x.sample(1))","ef860966":"#testing_df = chin_mnist_df.groupby('value').apply(lambda x: x.sample(3)).reset_index(drop=True)\n\n#testing_df_1 = testing_df.groupby('value').apply(lambda x: x.sample(1))\n#testing_df_2 = testing_df.groupby('value').apply(lambda x: x.sample(2))\n\n#testing_df","f570214a":"#testing_df_1","4e74100e":"#testing_df_2","137bcd2d":"labels = np.sort(chin_mnist_df['value'].\\\nunique())\nlabels","6593f1fa":"class Dataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        self.n_classes = y.nunique()\n        self.labels    = np.sort(y.unique())\n                \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, index):\n        img_path_info = self.x.iloc[index, :]\n        img = Image.open(f\"..\/input\/chinese-mnist\/data\/data\/input_{self.x.iloc[index, 0]}_{self.x.iloc[index, 1]}_{self.x.iloc[index, 2]}.jpg\")\n        img = np.array(img) # convert to np.array\n        \n        label = self.y.iloc[index]\n        label_index   = np.where(self.labels == label)[0][0]\n        \n        return img, label_index # returns features (image) and target index in self.labels, which corresponds to the target softmax index in the model","cd7bd901":"# Train (70%), valid (20%) and test (hold-out) (10%) splits\n\n# Not securing samples of each class\n#train_df = chin_mnist_df.sample(frac=0.7, random_state=SEED)\n#chin_mnist_df.drop(train_df.index)\n#valid_df = chin_mnist_df.sample(frac=0.7, random_state=SEED) # 66% (ceiled to 70%) of the remaining 30% from original\n#chin_mnist_df.drop(valid_df.index)\n#test_df = chin_mnist_df\n#chin_mnist_df.drop(test_df.index)\n\n# Securing equal number of samples from each class (sample bootstraps without replacement by default)\ntrain_df = chin_mnist_df.groupby('value').apply(lambda x: x.sample(700, random_state=SEED)).reset_index(drop=True)\nx_train, y_train  = train_df.iloc[:, :-2], train_df.iloc[:, -2]\n\nvalid_df = chin_mnist_df.groupby('value').apply(lambda x: x.sample(200, random_state=SEED)).reset_index(drop=True)\nx_valid, y_valid  = valid_df.iloc[:, :-2], valid_df.iloc[:, -2]\n\ntest_df  = chin_mnist_df.groupby('value').apply(lambda x: x.sample(100, random_state=SEED)).reset_index(drop=True)\nx_test, y_test    = test_df.iloc[:, :-2], test_df.iloc[:, -2]","94ce8d30":"train_ds = Dataset(x_train, y_train)\ntrain_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n\nvalid_ds = Dataset(x_valid, y_valid)\nvalid_dataloader = torch.utils.data.DataLoader(valid_ds, batch_size=16, shuffle=True)\n\ntest_ds = Dataset(x_test, y_test)\ntest_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=True)","c919f3ec":"images, labels = next(iter(test_dataloader))\nplt.imshow(images[0], cmap='gray')\nprint(images.shape)\nprint(labels[0])","0e6fcba0":"class ConvNet(nn.Module):\n    def __init__(self):\n        super(ConvNet, self).__init__()\n                \n        convs = [\n            nn.Conv2d(1, 32, kernel_size=3, stride=1),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n            nn.MaxPool2d(2),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=2, stride=1, dilation=2),\n            nn.Conv2d(128, 256, kernel_size=2, stride=2, dilation=2),\n            nn.MaxPool2d(2),\n            nn.ReLU(),\n            nn.Conv2d(256, 512, kernel_size=2, stride=1, dilation=2),\n            #nn.Conv2d(512, 1024, kernel_size=2, stride=2, dilation=2),\n            nn.MaxPool2d(2),\n            nn.GELU()\n        ]\n        \n        self.conv = nn.Sequential(*convs)\n        \n        self.linear = nn.Linear(2048, 15)\n        \n        self.log_softmax = nn.LogSoftmax(dim=0) # avoid overflowing: large number -> exp() -> NaN -> log() -> NaN. I think I could also solve this through batch normalization.\n        \n    def forward(self, x):\n        x = x.unsqueeze(1) # single channel image\n        #print(x.size())\n        \n        hidden = self.conv(x)\n        #print(hidden.size())\n        \n        hidden = torch.flatten(hidden, start_dim=1)\n        #print(hidden.size())\n        \n        \n        output = self.log_softmax(self.linear(hidden))\n        return output","b93fac5e":"model = ConvNet()\nmodel = model.to(device)\nprint(model)\nprint(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=10e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\ncriterion = nn.CrossEntropyLoss()","f2b72c12":"epochs = 10\ntrain_size = len(train_ds)\nvalid_size = len(valid_ds)\n\nvalid_conf_matrixes = []\n\nfor epoch in range(epochs):\n    labels = torch.tensor([]).to(device).detach()\n    preds  = torch.tensor([]).to(device).detach()\n    \n    total_preds = 0\n    correct_preds = 0\n    \n    train_running_loss = 0.0\n    \n    for index, data in enumerate(train_dataloader):\n        model.train()\n        \n        batch_inputs, batch_labels = data[0][:].to(device).type(torch.float), data[1][:].to(device)\n        \n        outputs = model(batch_inputs)\n        \n        loss = criterion(outputs, batch_labels) # expects distribution from model softmax as pred and target_index as target\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_running_loss += loss.mean()\n        \n        labels = torch.cat((labels, batch_labels))\n        #total_preds += 1\n        \n        for idx, item in enumerate(outputs):                \n            preds  = torch.cat((preds, torch.argmax(item).unsqueeze(-1)))\n            \n        if index % 10 == 1 :\n            if index == 1:\n                print(f'Training Epoch: {epoch+1}, step: {index+1}, first step training loss: {train_running_loss\/1}')\n            else:\n                print(f'Training Epoch: {epoch+1}, step: {index+1}, moving average of training loss: {train_running_loss\/10}')\n            train_running_loss = 0.0\n    \n    print('Calculating conf_matrix')\n    conf_mat = confusion_matrix(labels.cpu().numpy(), preds.cpu().numpy())\n    \n    total = np.sum(conf_mat)\n    \n    correct_count = 0\n    \n    for i, data in enumerate(conf_mat[0]):\n        correct_count += conf_mat[i][i]\n    \n    \n    print(f'Training Epoch {epoch+1}:\\n Accuracy: {correct_count\/total}\\n{conf_mat}\\n')\n    print()\n    \n    labels = torch.tensor([]).to(device).detach()\n    preds  = torch.tensor([]).to(device).detach()\n    \n    total_preds = 0\n    correct_preds = 0\n    \n    valid_running_loss = 0.0\n    \n    for index, data in enumerate(valid_dataloader):\n        model.eval()\n        \n        batch_inputs, batch_labels = data[0][:].to(device).type(torch.float), data[1][:].to(device)\n        \n        outputs = model(batch_inputs)\n        \n        loss = criterion(outputs, batch_labels) # expects distribution from model softmax as pred and target_index as target\n        \n        valid_running_loss += loss.mean()\n        \n        labels = torch.cat((labels, batch_labels))\n        #total_preds += 1\n        \n        for i, item in enumerate(outputs):                \n            preds  = torch.cat((preds, torch.argmax(item).unsqueeze(-1)))\n        \n        if index % 10 == 1:\n            print(f'Validation Epoch: {epoch+1}, step: {index+1}, running average validation loss: {valid_running_loss\/10}')\n            valid_running_loss = 0.0\n        \n    print('Calculating conf_matrix')\n    conf_mat = confusion_matrix(labels.cpu().numpy(), preds.cpu().numpy())\n    \n    total = np.sum(conf_mat)\n    \n    correct_count = 0\n    \n    for i, data in enumerate(conf_mat[0]):\n        correct_count += conf_mat[i][i]\n    \n    valid_conf_matrixes.append(conf_mat)   \n    \n    print(f'Validation Epoch {epoch+1}:\\n Accuracy: {correct_count\/total}\\n{conf_mat}')\n    print()","f6363019":"test_size = len(test_ds)\n\nlabels = np.array([])\npreds  = np.array([])\n\ntest_running_loss = 0.0\n\nfor index, data in enumerate(test_dataloader):\n    model.eval()\n\n    batch_inputs, batch_labels = data[0][:].to(device).type(torch.float), data[1][:].to(device)\n\n    outputs = model(batch_inputs)\n\n    loss = criterion(outputs, batch_labels) # expects distribution from model softmax as pred and target_index as target\n\n    test_running_loss += loss.mean()\n\n    labels = np.concatenate((labels, batch_labels.cpu().numpy()))\n\n    for index, item in enumerate(outputs):\n        preds  = np.concatenate((preds, torch.argmax(item).unsqueeze(-1).detach().cpu().numpy()))\n\n    if index % 10 == 1:\n        print(f'Testing Step: {index+1}, mean testing loss: {test_running_loss \/ 10}')\n        test_running_loss = 0.0\n\nconf_mat = confusion_matrix(labels, preds)\n\ntotal_preds = np.sum(conf_mat)\n    \ncorrect_preds = 0\n\nfor i, data in enumerate(conf_mat[0]):\n    correct_preds += conf_mat[i][i]\n\nprint(f'Test Accuracy: {correct_preds\/total_preds}\\n{conf_mat}')\nprint()","f3f81ee4":"1000 samples for each class, so we will have 700 train, 200 valid and 100 test samples from each class","225ed746":"# Model","dce8084f":"# Training, validation and testing sets and loaders","eec1aedd":"### sampling keeps track of sampled indices even when called in different scopes"}}