{"cell_type":{"cbed680f":"code","4182a4c6":"code","83b09a68":"code","1832ff46":"code","7d8e208a":"code","cf1c40d0":"code","7d8c560e":"code","7682fea0":"code","fe4e8f76":"code","acf3e7e9":"code","6f6796eb":"code","41ed4fd7":"code","88bb9624":"code","228074d7":"code","65401252":"code","07d92d21":"code","a84e4c01":"code","312604a8":"code","f5e52680":"code","279cefe2":"code","0e77f595":"code","c627e902":"code","c151bbd7":"code","34563053":"code","a5cf9909":"code","911b91d6":"code","7c5d0190":"code","221d2b39":"code","5f58fc65":"code","c4bcaf11":"code","6896d9c3":"code","906c0a62":"code","f6c438da":"markdown","782e333e":"markdown","b8b72bfd":"markdown","1ce8f423":"markdown","5b9a673e":"markdown","e5a210ba":"markdown","96b45c4a":"markdown","aab06aec":"markdown","b59a141c":"markdown"},"source":{"cbed680f":"# Importing libraries for EDA\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom matplotlib.ticker import FuncFormatter \nfrom matplotlib.ticker import StrMethodFormatter \nimport seaborn as sns","4182a4c6":"df_raw = pd.read_csv('\/kaggle\/input\/bluebook-for-bulldozers\/TrainAndValid.csv', \n                 low_memory=False, parse_dates=['saledate'])\ndf_raw.head()","83b09a68":"df_raw.info()","1832ff46":"df_raw.isna().sum()","7d8e208a":"# Sort the dataframe in order by date\ndf_raw.sort_values(by=['saledate'], inplace=True, ascending=True)\ndf_raw['saledate'].head(10)","cf1c40d0":"# Copy the dataframe\ndata = df_raw.copy()","7d8c560e":"data['saleYear'] = data.saledate.dt.year\ndata['saleMonth'] = data.saledate.dt.month\ndata['saleDay'] = data.saledate.dt.day\ndata['saleDayofWeek'] = data.saledate.dt.dayofweek\ndata['saleDayofYear'] = data.saledate.dt.dayofyear\n\ndata.drop('saledate', axis=1, inplace=True)","7682fea0":"# Columns that contains strings\nfor label, content in data.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)","fe4e8f76":"# Converting strings to categories\nfor label, content in data.items():\n    if pd.api.types.is_string_dtype(content):\n        data[label] = content.astype('category').cat.as_ordered()","acf3e7e9":"data.info()","6f6796eb":"data.isna().sum()\/len(data)","41ed4fd7":"# Check for which numeric columns have null values\nfor label, content in data.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","88bb9624":"# Check the numeric columns and fill with median\nfor label, content in data.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Add a binary column to tell if the data was missing or not\n            data[label + '_is_missing'] = pd.isnull(content)\n            \n            # Fill the missing values with median \n            data[label] = content.fillna(content.median())","228074d7":"# Columns which aren't numeric\nfor label, content in data.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        print(label)","65401252":"# Turn the categorical variables into numbers\nfor label, content in data.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        # add binary column to check missing value\n        data[label + '_is_missing'] = pd.isnull(content)\n        \n        # Add +1 because pandas encodes the missing categories as -1\n        data[label] = pd.Categorical(content).codes + 1","07d92d21":"data.info()","a84e4c01":"data.isna().sum()","312604a8":"# Splitting the data into training and validation\n# Training = all samples up until 2011\n# Valid = all samples form January 1, 2012 - April 30, 2012\n# Test = all samples from May 1, 2012 - November 2012\ndata_train = data[data['saleYear'] != 2012]\ndata_valid = data[data['saleYear'] == 2012]","f5e52680":"# Split data into X and y\nX_train, y_train = data_train.drop('SalePrice', axis=1), data_train.SalePrice\nX_valid, y_valid = data_valid.drop('SalePrice', axis=1), data_valid.SalePrice\n\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","279cefe2":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error as MSErr\nfrom sklearn.metrics import mean_absolute_error as MAErr\nfrom sklearn.metrics import r2_score","0e77f595":"lr = LinearRegression()\nlr.fit(X_train, y_train)\nprint(lr.coef_)","c627e902":"s = StandardScaler()\nX_train_ss = s.fit_transform(X_train)\nlr2 = LinearRegression()\nlr2.fit(X_train_ss, y_train)\nprint(lr2.coef_)","c151bbd7":"pd.DataFrame(zip(X_train.columns, lr2.coef_)).sort_values(by=1)","34563053":"kf = KFold(shuffle=True, random_state=42, n_splits=3)","a5cf9909":"#Retrieve R2 scores for different alpha for LASSO or Ridge.\ndef optimize_alpha(alphas, x, y, model, kf):\n    \n    #Scale and transform x.\n    s = StandardScaler()\n    x = s.fit_transform(x)\n    \n    #List of R2.\n    r2_scores = []\n    \n    for alpha in alphas:\n        \n        reg = model(alpha = alpha, max_iter = 5e4)\n        y_pred = cross_val_predict(reg, x, y, cv = kf)\n        score = r2_score(y, y_pred)\n        r2_scores.append(score)\n    \n    return(r2_scores)","911b91d6":"def alpha_r2_graph(alphas, R2s, xlabels, model):\n    \n    df = pd.DataFrame(data = {'alpha': alphas,\n                              'R2': R2s})\n    sns.set()\n\n    #Scatter Plot.\n    sns.lineplot(data = df,\n                 x = 'alpha',\n                 y = 'R2',\n                 marker = 'o')\n    \n    #Size.\n    plt.gcf().set_size_inches(15, 6.92)\n    paper_rc = {'lines.linewidth': 2, 'lines.markersize': 6}  \n    \n    #Axes.\n    ax = plt.gca()\n    \n    #Title setup.\n    ax.set_title(\"Optimizing Hyperparameter for {} Regression\".format(model), fontsize = 24)\n\n    #X-axis setup.\n    ax.set_xlabel(\"\u03b1\", fontsize = 22)\n    ax.set_xscale('log')\n    ax.set_xticks(xlabels)\n    ax.set_xticklabels(xlabels, rotation = 45, ha = 'right')\n    if (model == 'Ridge') :\n        ax.get_xaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\n\n    #Y-axis setup.\n    ax.set_ylabel(\"R2\", fontsize = 22)\n    ylabels = [0, 0.2, 0.4, 0.6, 0.8, 1]\n    ax.set_xticks(xlabels)\n    \n    ax.tick_params(axis = 'both', which = 'major', labelsize = 14)","7c5d0190":"# Lasso\nalphas = np.array([1e-5, 5e-5, 0.0001, 0.0005])\nxlabels = [a for a in np.array([1e-5, 5e-5, 0.0001, 0.0005])]\n\ns = StandardScaler()\nX_train_lasso = s.fit_transform(X_train)\n\n#Determine R2s and graph.\nr2s_l = optimize_alpha(alphas, X_train_lasso, y_train, Lasso, kf)\nalpha_r2_graph(alphas, r2s_l, xlabels, 'LASSO')","221d2b39":"X_test_opt_alpha = s.transform(X_valid)\n\nlr3 = Lasso(alpha = 0.005).fit(X_train_3, y_train)","5f58fc65":"# Ridge\nalphas_r = [0.005, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 80]\nxlabels_r = [a for a in alphas]\n\ns = SS()\nX_train_ridge = s.fit_transform(X_train)\n\n#Determine R2s and graph.\nr2s_r = optimize_alpha(alphas_r, X_train_ridge, y_train, Ridge, kf)\nalpha_r2_graph(alphas_r, r2s_r, xlabels_r, 'Ridge')","c4bcaf11":"X_test_4 = s.transform(X_valid)\n\nlr4 = Ridge(alpha = 200).fit(X_train_4, y_train)","6896d9c3":"#Inputs regression models, predictors, and y-values, outputs DataFrame of R2, Adjusted R2, RMSE, and MAE.\ndef summary_df(models, Xs, Y) :\n\n    index = ['All Variables', 'My Variables', 'LASSO', 'Ridge']\n    R2 = []\n    ADJ_R2 = []\n    RMSE = []\n    MAE = []\n\n    for i in range(4):\n        y_pred = models[i].predict(Xs[i])\n        \n        #R2.\n        r2 = r2_score(Y, y_pred)\n        R2.append(r2)\n        \n        #Adj R2.\n        adj_r2 = 1.0 - (1.0 - r2) * (len(Y) - 1.0) \/ (len(Y) - Xs[i].shape[1] - 1.0)\n        ADJ_R2.append(adj_r2)\n        \n        #RMSE.\n        rmse = math.sqrt(MSErr(Y, y_pred))\n        RMSE.append(rmse)\n                         \n        #MAE.\n        mae = MAErr(Y, y_pred)\n        MAE.append(mae)\n\n    df = pd.DataFrame(data = {'R2': R2,\n                              'Adjusted R2': ADJ_R2,\n                              'RMSE': RMSE,\n                              'MAE': MAE},\n                      index = index)\n    return(df)","906c0a62":"models = [lr, lr2, lr3, lr4]\nX_trains = [X_train, X_train_ss, X_train_lasso, X_train_ridge]\n\nsummary_df(models, X_trains, y_train)","f6c438da":"Evaluation","782e333e":"Linear Regression","b8b72bfd":"## Modelling","1ce8f423":"## Data\nThere are three main datasets:\n\n* Train.csv is the training set, which contains data through the end of 2011.\n* Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n* Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition\n\nThe key fields are in train.csv are:\n\n* SalesID: the uniue identifier of the sale\n* MachineID: the unique identifier of a machine.  A machine can be sold multiple times\n* saleprice: what the machine sold for at auction (only provided in train.csv)\n* saledate: the date of the sale\n\n## Evaluation\nThe evaluation metric is the RMSLE (root mean squared log error) between the actual and predicted auction prices.","5b9a673e":"Optimization Function","e5a210ba":"### Splitting Data into Training and Validation sets","96b45c4a":"### Data Cleaning and Feature Engineering","aab06aec":"Optimal alpha is: ","b59a141c":"Optimal Alpha is: "}}