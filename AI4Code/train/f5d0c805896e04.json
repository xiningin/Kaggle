{"cell_type":{"7cbb3439":"code","a488d6ab":"code","bdb97d6d":"code","ef07cad4":"code","00dbc42a":"code","319ee0b6":"code","1de0607e":"markdown","94a39d86":"markdown"},"source":{"7cbb3439":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport pandas as pd\nimport os\n\n\nprint(os.listdir(\"..\/input\/tiny-imagenet-200\/tiny-imagenet-200\"))","a488d6ab":"BATCH_SIZE = 20\nNUM_CLASSES = 200\nNUM_IMAGES_PER_CLASS = 500\nNUM_IMAGES = NUM_CLASSES * NUM_IMAGES_PER_CLASS\nTRAINING_IMAGES_DIR = '..\/input\/tiny-imagenet-200\/tiny-imagenet-200\/train\/'\nTRAIN_SIZE = NUM_IMAGES\n\nNUM_VAL_IMAGES = 9832\nVAL_IMAGES_DIR = '..\/input\/tiny-imagenet-200\/tiny-imagenet-200\/val\/'\nIMAGE_SIZE = 64\nNUM_CHANNELS = 3\nIMAGE_ARR_SIZE = IMAGE_SIZE * IMAGE_SIZE * NUM_CHANNELS\n\nDATA_DIR = '..\/input\/tiny-imagenet-200\/'\nIMAGE_DIR = '..\/input\/tiny-imagenet-200\/tiny-imagenet-200\/'\n\nprint('Image categories:\\n' + str(os.listdir(TRAINING_IMAGES_DIR)))","bdb97d6d":"def load_training_images(image_dir, batch_size=250):\n\n    image_index = 0\n    \n    images = np.ndarray(shape=(NUM_IMAGES\/\/2, IMAGE_ARR_SIZE))\n    names = []\n    labels = []                       \n    print(\"Loading training images from \", image_dir)\n    # Loop through all the types directories\n    img_num = 0\n    for type in os.listdir(image_dir):\n        if os.path.isdir(image_dir + type + '\/images\/'):\n            type_images = os.listdir(image_dir + type + '\/images\/')\n            # Loop through all the images of a type directory\n            batch_index = 0;\n            #print (\"Loading Class \", type)\n            for image in type_images:\n                if img_num % 5000 == 0:\n                    print(img_num)\n                image_file = os.path.join(image_dir, type + '\/images\/', image)\n                # reading the images as they are; no normalization, no color editing\n                image_data = mpimg.imread(image_file) \n                #print ('Loaded Image', image_file, image_data.shape)\n                if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n                    images[image_index, :] = image_data.flatten()\n\n                    labels.append(type)\n                    names.append(image)\n                    \n                    img_num += 1\n                    image_index += 1\n                    batch_index += 1\n                if (batch_index >= batch_size):\n                    break;\n    \n    print(\"Loaded Training Images\", image_index)\n    return (images, np.asarray(labels), np.asarray(names))\n","ef07cad4":"training_images, training_labels, training_files = load_training_images(TRAINING_IMAGES_DIR)","00dbc42a":"def get_label_from_name(data, name):\n    for idx, row in data.iterrows():       \n        if (row['File'] == name):\n            return row['Class']\n        \n    return None\n\ndef load_validation_images(testdir, validation_data, batch_size=NUM_VAL_IMAGES):\n    labels = []\n    names = []\n    image_index = 0\n    \n    images = np.ndarray(shape=(batch_size, IMAGE_ARR_SIZE))\n    val_images = os.listdir(testdir + '\/images\/')\n           \n    # Loop through all the images of a val directory\n    batch_index = 0;\n    img_n = 0\n    print(\"Loading validation images from \", testdir)\n    for image in val_images:\n        if img_n%500 == 0:\n            print(\"Loading image \" + str(img_n))\n        image_file = os.path.join(testdir, 'images\/', image)\n        #print (testdir, image_file)\n        img_n += 1\n        # reading the images as they are; no normalization, no color editing\n        image_data = mpimg.imread(image_file) \n        if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n            images[image_index, :] = image_data.flatten()\n            image_index += 1\n            labels.append(get_label_from_name(validation_data, image))\n            names.append(image)\n            batch_index += 1\n            \n        if (batch_index >= batch_size):\n            break;\n    \n    print (\"Loaded Validation images \", image_index)\n    return (images, np.asarray(labels), np.asarray(names))\n   \n        \ndef get_next_batch(batchsize=50):\n    for cursor in range(0, len(training_images), batchsize):\n        batch = []\n        batch.append(training_images[cursor:cursor+batchsize])\n        batch.append(training_labels_encoded[cursor:cursor+batchsize])       \n        yield batch\n\n    \ndef reset_graph(seed=42):\n    tf.reset_default_graph()\n    tf.set_random_seed(seed)\n    np.random.seed(seed)","319ee0b6":"val_data = pd.read_csv(VAL_IMAGES_DIR + 'val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\nval_images, val_labels, val_files = load_validation_images(VAL_IMAGES_DIR, val_data)","1de0607e":"**Load Validation Data**","94a39d86":"**Load Training Data**"}}