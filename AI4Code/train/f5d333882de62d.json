{"cell_type":{"3fcf3e76":"code","d3b071f4":"code","05baa52d":"code","e973813f":"code","a7c25800":"markdown","0641404a":"markdown","bc800c54":"markdown"},"source":{"3fcf3e76":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3b071f4":"from google.cloud import bigquery\n\n# creating a client object\nclient = bigquery.Client()\n\n# creating a dataset reference\ndataset_reference = client.dataset(\"nhtsa_traffic_fatalities\", project=\"bigquery-public-data\")\n\n# API call to fetch the data set \ndataset = client.get_dataset(dataset_reference)\n\n# creating a table reference\ntable_reference = dataset_reference.table(\"accident_2015\")\n\n# API call to fetch the table\ntable = client.get_table(table_reference)\n\nclient.list_rows(table, max_results = 5).to_dataframe()","05baa52d":"# Query to find out the number of accidents for each day of the week\nquery_accidents = \"\"\"\n                  SELECT COUNT(consecutive_number) AS num_accidents, \n                      EXTRACT(DAYOFWEEK FROM timestamp_of_crash) AS day_of_week\n                  FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n                  GROUP BY day_of_week\n                  ORDER BY num_accidents DESC\n                  \"\"\"","e973813f":"# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed = 10**9)\nquery_job = client.query(query_accidents, job_config=safe_config)\n\n# API request - run the query, and convert the results to a pandas DataFrame\naccidents_by_day = query_job.to_dataframe()\n\n# Print the DataFrame\naccidents_by_day","a7c25800":"## SQL Practice 4\n\nJust some code to learn using SQL integrated within the *Kaggle environment*. \n\nWe're gonna be exploring the **ORDER BY** clause as well as the **EXTRACT** function within this SQL integrated python environment to explore information about traffic accidents.","0641404a":"Let's take a look at this data to figure out how numbers of accidents can vary by days of the week, using the **extract** function from the given data column. Group the data by day of the week and then order that data in descending order to find the days with the highest accidents.","bc800c54":"The `DAYOFWEEK` is a great SQL function that allows us to pull the *day data* out of the *date* type.\n\nOf course we will then run the following code snippet to create a `data frame` within the python environment."}}