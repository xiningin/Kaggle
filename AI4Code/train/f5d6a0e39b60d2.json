{"cell_type":{"7a9f4b17":"code","94a89e5c":"code","cf9a9b30":"code","b82fe9ca":"code","75e8c9a8":"code","a803a167":"code","bb8fbf2d":"code","c437c651":"code","08dcaa76":"code","63e161fe":"code","15a5257f":"code","5cb601e6":"code","a0e999d2":"markdown","0a3d7f67":"markdown","ea4d53c0":"markdown","48bec799":"markdown","bfa66c14":"markdown","4c21c787":"markdown","ce57271b":"markdown","691d57f5":"markdown"},"source":{"7a9f4b17":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 as cv\nimport random\nfrom pathlib import Path\nimport os\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation\nfrom keras import optimizers\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model","94a89e5c":"import tensorflow as tf\nfrom tensorflow.python.keras import backend as K\n\n# adjust values to your needs\nconfig = tf.compat.v1.ConfigProto( device_count = {'GPU': 15 , 'CPU': 58} )\nsess = tf.compat.v1.Session(config=config) \nK.set_session(sess)","cf9a9b30":"img = cv.imread(\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\/Sea Bass\/Sea Bass\/00001.png\")\nimg = cv.resize(img, (64,64))\nplt.imshow(img)","b82fe9ca":"file = Path(\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\")\nFile_Path = list(file.glob(r\"**\/*.png\"))\nLabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],File_Path))\n\n# Convert to series then contact them as a data frame, rename the columns\nFile_Path = pd.Series(File_Path).astype(str)\nLabels = pd.Series(Labels)\ndf = Main_Data = pd.concat([File_Path,Labels],axis=1)\ndf.columns = ['image', 'label']\n# Drop all the images that ends with (GT)\ndf = df[df[\"image\"].apply(lambda x: x[-2:] != \"GT\")]\ndf = df.reset_index(drop=True)\n# Show the last 5 rows\ndf.tail()","75e8c9a8":"classes = df['label'].unique()\nprint(f'\\nThe Classes:\\n {classes} ')","a803a167":"# Make a list that contains all the file paths for images and it's label\nfile = Path(\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\")\nFile_Path = list(file.glob(r\"**\/*.png\"))\nLabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],File_Path))\n\n# Convert to series then contact them as a data frame, rename the columns\nFile_Path = pd.Series(File_Path).astype(str)\nLabels = pd.Series(Labels)\ndf = Main_Data = pd.concat([File_Path,Labels],axis=1)\ndf.columns = ['image', 'label']\n# Drop all the images that ends with (GT)\ndf = df[df[\"label\"].apply(lambda x: x[-2:] != \"GT\")]\ndf = df.reset_index(drop=True)\n# Get a 500 random values\/rows\nrand = random.sample(range(len(df)), 500)\n# Make the random 500 as a validation data\nvalidation_set = pd.DataFrame(df.iloc[rand, :].values, columns=['image', 'label'])\n# Drop the 500 from the orignal data set\ndf.drop(rand, inplace=True)\n# Get a 5 random rows\/values from the validation set\nrand = random.sample(range(len(validation_set)), 5)\n# from the 5 random Create the test set \ntest_set = pd.DataFrame(validation_set.iloc[rand, :].values, columns=['image', 'label'])\n# Drop the 5 from the validation set\nvalidation_set.drop(rand, inplace=True)\n# The number of unique values in the label column\nprint('The number of unique values in the label column: ',len(df['label'].unique()))\n# Show the Test set as a example of the data\ntest_set","bb8fbf2d":"DATADIR = ''\ntrain_data_generator = ImageDataGenerator(rescale=1\/255, shear_range=0.2, zoom_range=0.2)\ndata_generator = ImageDataGenerator(rescale=1\/255)\ntraining_data_frame = train_data_generator.flow_from_dataframe(dataframe=df, directory=DATADIR, x_col='image', y_col='label', \n                                                               target_size=(64, 64), class_mode='categorical')\nvalidation_data_frame = data_generator.flow_from_dataframe(dataframe=validation_set, directory=DATADIR, x_col='image', y_col='label', \n                                                           target_size=(64, 64), class_mode='categorical')\ntest_data_frame = data_generator.flow_from_dataframe(dataframe=test_set, directory=DATADIR, x_col='image', y_col='label', \n                                                     target_size=(64, 64), class_mode='categorical', shuffle=False)","c437c651":"# Define the model\nmodel = Sequential()\n\n# Add first Convolutional Layer\nmodel.add(Conv2D(64, (3, 3), padding='same',\n                 input_shape=(64,64,3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a second Convolutional Layer\nmodel.add(Conv2D(64, (3, 3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a Max pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout layer\nmodel.add(Dropout(0.25))\n\n# Add third Convolutional Layer\nmodel.add(Conv2D(128, (3, 3), padding='same'))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add Fourth Convolutional Layer\nmodel.add(Conv2D(128, (3, 3)))\n# Add a relu Activation \nmodel.add(Activation('relu'))\n# Add a Max pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout Layer\nmodel.add(Dropout(0.25))\n\n# Add Fifth Convolutional Layer\nmodel.add(Conv2D(256, (3, 3), padding='same'))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a sixth Convolutional Layer\nmodel.add(Conv2D(256, (3, 3)))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a Max Pooling Layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Add a Dropout Layer\nmodel.add(Dropout(0.25))\n\n# Add a Flatten Layer\nmodel.add(Flatten())\n# Add a Dense layer Layer\nmodel.add(Dense(512))\n# Add a Activation Layer\nmodel.add(Activation('relu'))\n# Add a Dropout Layer\nmodel.add(Dropout(0.5))\n# Add the Output Dense Layer\nmodel.add(Dense(9, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizers.RMSprop(lr=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","08dcaa76":"# Train the model for 50 epochs\nhistory = model.fit(training_data_frame, validation_data=validation_data_frame, epochs=20)","63e161fe":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(20)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","15a5257f":"# Save the model as model.h5\nmodel.save('model.h5')\n# Load the model\nmodel = load_model('model.h5')","5cb601e6":"# Print the class indices \nprint(\"Prediction Dict: \", training_data_frame.class_indices)\n# Predict on the test data \npred = model.predict(test_data_frame)\n# Create a class\/labels dictionary\nclassDict = { \n                 0:'Black Sea Sprat',\n                 1:'Gilt-Head Bream',\n                 2:'Hourse Mackerel',\n                 3:'Red Mullet',\n                 4:'Red Sea Bream',\n                 5:'Sea Bass',\n                 6:'Shrimp',\n                 7:'Striped Red Mullet',\n                 8:'Trout'}\n\n# Make a data frame that contains the probability for each class\noutputDf = pd.DataFrame(pred)\n# Get the index of the max probability from the output Data frame\nmaxIndex = list(outputDf.idxmax(axis=1))\n# Print the max index\nprint(\"Max index: \", maxIndex)\n# Make a loop in range the length of the test data (5)\nfor i in range(len(test_set)):\n    # Read the image \n    image = cv.imread(test_set['image'][i])\n    # The title of the plot which is the predicted label\n    print('Predicted: ',classDict.get(maxIndex[i], \"error\"),'\/Real: ',test_set['label'][i])\n    plt.title(classDict.get(maxIndex[i], \"error\"))\n    # Show the actual image\n    plt.imshow(image)\n    plt.show()\n    ","a0e999d2":"## Explore the classes","0a3d7f67":"## Save the model","ea4d53c0":"## Importing the libraries","48bec799":"## Show a example of the data","bfa66c14":"## Create the Generators","4c21c787":"## Read the images, Split the data: Train\/Validation\/Test","ce57271b":"## Make a Data Frame with the image path and it's label ","691d57f5":"# The link of the data set:\nhttps:\/\/www.kaggle.com\/crowww\/a-large-scale-fish-dataset"}}