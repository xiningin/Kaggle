{"cell_type":{"d8b8903c":"code","47a7cf66":"code","9c2b249c":"code","9cc193bc":"code","b28ed114":"code","f6575f16":"code","0cd4f522":"code","14246506":"code","91415915":"code","87aa618f":"code","9609d6f6":"code","13f5396d":"markdown","38cd07f5":"markdown","b1be7573":"markdown","7f7df7f3":"markdown","6dcfc463":"markdown"},"source":{"d8b8903c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","47a7cf66":"hist_df = pd.read_csv('..\/input\/historical_transactions.csv')\nhist_df.head()","9c2b249c":"hist_df.size","9cc193bc":"history_reader = pd.read_csv('..\/input\/historical_transactions.csv', chunksize = 10)\ntype(history_reader)\n\nhist_chunk = None\nfor chunk in history_reader:\n    hist_chunk = chunk\n    print(hist_chunk)\n    break","b28ed114":"type(hist_chunk)","f6575f16":"history_columns = list(hist_chunk.columns)\nprint(history_columns)","0cd4f522":"hist_chunk.dtypes","14246506":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if df[col].dtypes == 'object':\n            df[col] = df[col].astype('category')\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","91415915":"import gc\n\nhistorical_transactions = reduce_mem_usage(hist_df)\ngc.collect()","87aa618f":"historical_transactions.dtypes","9609d6f6":"historical_transactions.head()","13f5396d":"Ref:[ Ashish Patel's kernel](http:\/\/www.kaggle.com\/ashishpatel26\/lightgbm-goss-dart-parameter-tuning) \n### 2) Reduce memory usage.\n\n* Load objects as categories\n* Binary values are switched to int8\n* Binary values with missing values are switched to float16 (int does not understand nan)\n* 64 bits encoding are all switched to 32 or 16bits if possible.","38cd07f5":"### History data file size is quite large. even preview of this file is not supported. \n\n**File size is 2.65 GB**\n\n### How can we preview data? or read just a chunk of data?\n\nLoading through panda dataframe read_csv function , occupies 9.7GB space. it's very costly at the middle of the program when you have already load couple of data and run out of memory.\n\nHere are two options:\n### 1) Read in a chunk \n\nGet idea or preview of data\n\n### 2) Reduce memory usage.\n\n* Load objects as categories\n* Binary values are switched to int8\n* Binary values with missing values are switched to float16 (int does not understand nan)\n* 64 bits encoding are all switched to 32 or 16bits if possible.","b1be7573":"Wow!  Reading the same file just took 1GB memory space instad of reading original file took 9GB space. That is a magic of converting data types.","7f7df7f3":"### 1) Read in a chunk","6dcfc463":"Wow! with very less memory usage we can preview our data, can read column names. check the data types of each column and can reduce memory to load the whole file."}}