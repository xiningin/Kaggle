{"cell_type":{"62a64239":"code","524c3400":"code","9291456d":"code","b5f4a252":"code","56f325dc":"code","f9c4dfdb":"code","f01b94ae":"code","95984997":"code","eb171951":"code","37d24e6e":"code","04baed4a":"code","601a2fb9":"code","a7c4fc39":"code","209352c4":"code","7b7839e0":"code","4e556a47":"code","3177a2d0":"code","57a19896":"code","e3e655bf":"code","f30c992c":"code","a111a320":"code","f356301b":"code","4b361fef":"code","1273c175":"code","629f6947":"code","e3504bcc":"code","e84f218b":"code","750589d3":"code","99abe5be":"markdown","69d7a441":"markdown","4848a5cf":"markdown","cb895c6b":"markdown","fa184c67":"markdown","f3983a67":"markdown","25c2cfa2":"markdown","716ddd3c":"markdown","750214f0":"markdown"},"source":{"62a64239":"import os\nimport  cv2\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport matplotlib.pyplot as plt \nfrom random import shuffle , seed\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom tensorflow.keras.applications.vgg19 import VGG19 \nfrom tensorflow.keras.applications   import EfficientNetB3\nfrom tensorflow.keras.applications.densenet import DenseNet169\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input ,concatenate, Dense,Flatten , Activation,Conv2D ,Dropout ,MaxPooling2D ,GlobalAveragePooling2D,BatchNormalization","524c3400":"df=pd.read_csv(\"..\/input\/sample\/sample\/sample_labels.csv\")\ndf.head()","9291456d":"#explore Labels\nLabels_before_pre=df[\"Finding Labels\"]\ndf[\"Finding Labels\"].value_counts()","b5f4a252":"sns.countplot(df[\"Patient Gender\"])\nplt.show()","56f325dc":"plt.style.use(\"ggplot\")\nplt.figure(figsize=(20,20))\nsns.countplot(df[\"Finding Labels\"][:20])\nplt.show()","f9c4dfdb":"#prepare labels \nLabels_after_pre=[]\n\nfor i in range(len(Labels_before_pre)):\n    split_labels=Labels_before_pre[i].split(\"|\")\n    if len(split_labels)==1:\n            Labels_after_pre.append(split_labels)\n    else:\n        lab=[]\n        for j in range(len(split_labels)):\n            lab.append(split_labels[j])\n        Labels_after_pre.append(lab)\n            \n            \nLabels_after_pre           ","f01b94ae":"#read x-rays\nimage_size=256\nimage_file_path=\"..\/input\/sample\/sample\/images\/\"\nLabels=[]\nscans=[]\nfor i in tqdm(range(len(df[\"Image Index\"]))):\n    image=cv2.imread(image_file_path+df[\"Image Index\"][i]) \n    if len(image.shape)>2: # to save images as (heigth , width, 3) rather than (hieght , width ,4)\n        resize_image=cv2.resize(image,(image_size,image_size)) # resize all x-rays as (256 , 256)\n        scans.append(resize_image[:,:,:4]) # I assigned labels before into Labels_after_pre list\n    else :\n        image=np.dstack([image] * 3)\n        resize_image=cv2.resize(image,(image_size,image_size)) # resize all x-rays as (256 , 256)\n        scans.append(resize_image) # I assigned labels before into Labels_after_pre list","95984997":"print([x.shape for x in scans])","eb171951":"print(set([x.shape for x in scans]))","37d24e6e":"len(Labels_after_pre), len(scans)","04baed4a":"#function to show images\ndef image_show(data, labels , number_of_image ):\n    #to generate a random numbers\n    numbers=np.random.randint(0,len(data),number_of_image)\n    plt.figure(figsize=(40,20))\n    j = number_of_image\/10\n    for _,i in enumerate(numbers):\n        plt.subplot(j,10,_+1)\n        plt.imshow(data[i] , cmap=\"gray\")\n        label=\"\"\n        for x in labels[i]:\n            label+=x+\" , \"\n        \n            \n        plt.title(label+\"\\n\"+f\"size {data[i].shape}\")\n        #to remove the number that appear around image\n        plt.xticks([]),plt.yticks([])\n    plt.show()","601a2fb9":"#show images\nimage_show(scans,Labels_after_pre,40)","a7c4fc39":"# dict for annotuation labels\nclasses={\n0:\"Hernia\",\n1:\"Pneumonia\",\n2:\"Fibrosis\",\n3:\"Edema\",\n4:\"Emphysema\",\n5:\"Cardiomegaly\",\n6:\"Pleural_Thickening\",\n7:\"Consolidation\",\n8:\"Pneumothorax\",\n9:\"Mass\",\n10:\"Nodule\",\n11:\"Atelectasis\",\n12:\"Effusion\",\n13:\"Infiltration\",\n14:\"No Finding\",\n}\n\ndef get_class(code):\n    return classes[code]\n\ndef get_code(labels):\n    for key,value  in classes.items():\n        if value ==labels:\n            return key\n        \nprint(get_code(\"Hernia\"))\nprint(get_class(0))","209352c4":"#convert labels to Label encoder\nfor i in tqdm(range(len(Labels_after_pre))):\n    Labels_after_pre[i]=[get_code(x) for x in Labels_after_pre[i]]\n        \n\nLabels_after_pre","7b7839e0":"#convert labels to one-hot-encoder with  MultiLabelBinarizer form sklearn\nmlp=MultiLabelBinarizer()\nLabels=mlp.fit_transform(Labels_after_pre)\nLabels[0],Labels\n","4e556a47":"#converte scans and labels to array\nscans=np.array(scans)\nLabels=np.array(Labels)","3177a2d0":"scans.shape, Labels.shape","57a19896":"from skmultilearn.model_selection import iterative_train_test_split\n#split to train and test\nX_train, y_train, X_test, y_test = iterative_train_test_split(scans, Labels, test_size = 0.2 )\n#split to train and test\nX_val, y_val, X_test, y_test = iterative_train_test_split(X_test, y_test, test_size = 0.7)","e3e655bf":"print(\"X_train shape\",X_train.shape)\nprint(\"y_train shape\",y_train.shape)\nprint(\"X_val shape\",X_val.shape)\nprint(\"y_val shape\",y_val.shape)\nprint(\"X_test shape\",X_test.shape)\nprint(\"y_test shape\",y_test.shape)","f30c992c":"generator=ImageDataGenerator(\n        rescale=1\/255.0,\n        samplewise_std_normalization=True,\n        samplewise_center=True,\n        rotation_range=90)\n\nbatch_size=16                                              \ntrain_generator=generator.flow(X_train,y_train ,batch_size=batch_size)\nval_generator=generator.flow(X_val,y_val,batch_size=batch_size)\ntest_generator=generator.flow(X_test,y_test,batch_size=batch_size)","a111a320":"#get data for generator\ntrain_scans=train_generator.__getitem__(0)[0]\ntrain_labels=train_generator.__getitem__(0)[1]\n#show images\nplt.imshow(train_scans[10])","f356301b":"Inputs=Input((image_size,image_size,3))\n\n#1\nc1=Conv2D(64 , (3,3) , activation=\"relu\" , padding=\"same\")(Inputs)\nc1=Conv2D(64 , (3,3) , activation=\"relu\" , padding=\"same\")(c1)\nc1=Conv2D(64 , (3,3) , activation=\"relu\" , padding=\"same\")(c1)\np1=MaxPooling2D(pool_size=(3,3))(c1)\n#2\nc2=Conv2D(128 , (3,3) , activation=\"relu\" , padding=\"same\")(p1)\nc2=Conv2D(128 , (3,3) , activation=\"relu\" , padding=\"same\")(c2)\nc2=Conv2D(128 , (3,3) , activation=\"relu\" , padding=\"same\")(c2)\np2=MaxPooling2D(pool_size=(3,3))(c2)\n\n#3\n\nc3=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(p2)\nc3=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(c3)\nc3=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(c3)\np3=MaxPooling2D(pool_size=(2,2))(c3)\n\n#4\n\nc4=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(p3)\nc4=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(c4)\nc4=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(c4)\np4=MaxPooling2D(pool_size=(2,2))(c4)\n\n#5\n\nc5=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(p4)\nc5=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(c5)\nc5=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(c5)\np5=MaxPooling2D(pool_size=(2,2))(c5)\n\n#6\n\nc6=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(p5)\nc6=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(c6)\nc6=Conv2D(256 , (5,5) , activation=\"relu\" , padding=\"same\")(c6)\np6=MaxPooling2D(pool_size=(2,2))(c6)\n\n#fully connected layers\nf=Flatten()(p3)\n#FC1\nfc1=Dense(1024)(f)\nb1=BatchNormalization()(fc1)\nac=Activation(\"relu\")(b1)\nd1=Dropout(0.2)(ac)\n\n#FC2\nfc2=Dense(1024)(d1)\nb2=BatchNormalization()(fc2)\nac=Activation(\"relu\")(b2)\nd2=Dropout(0.2)(ac)\n\n#FC3\nfc3=Dense(1024)(d2)\nb2=BatchNormalization()(fc3)\nac=Activation(\"relu\")(b2)\nd3=Dropout(0.2)(ac)\n\n\n#FC4\nx=Dense(512 , activation=\"relu\")(d3)\nx=Dense(512 , activation=\"relu\")(x)\nx=Dense(512 , activation=\"relu\")(x)\nx=Dense(256 , activation=\"relu\")(x)\nx=Dense(128 , activation=\"relu\")(x)\n\n\noutput=Dense(len(classes) , activation=\"sigmoid\")(x)\n\nmodel=Model(inputs=Inputs , outputs=output)\n\nmodel.summary()","4b361fef":"#callbacks\ncallbacks=[\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\" , patience=5 , verbose=1),\n    \n    tf.keras.callbacks.ModelCheckpoint(\"NIH_model_1.h5\" , save_best_only=True ,verbose=1),\n    \n    tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1,  # lr*factor\n                                      patience = 1, min_delta = 0.001,\n                                      min_lr=0.000001 , # lower lr\n                                      mode = 'min', verbose = 1)\n    \n    ]\n\n#compile\nmodel.compile(tf.keras.optimizers.Adam(learning_rate=0.0001) , loss=tf.keras.losses.binary_crossentropy , metrics=[\"accuracy\"] )\n#fit\nmodel.fit(X_train,y_train , epochs=10 , batch_size=32,validation_data=(X_val, y_val) , verbose=1  ,callbacks=callbacks)","1273c175":"#evaluate \nprint('evaluate')\nmodel.evaluate(train_generator),model.evaluate(val_generator), model.evaluate(test_generator)","629f6947":"\n\ndenenet_model=DenseNet169(weights=\"imagenet\", include_top=False )\n\n\nfor layer in denenet_model.layers[:150]:\n    layer.trainable=False\n \n    \n# denenet_model.summary()\n\nInputs=Input((image_size,image_size,3))\nc=Conv2D(512 , (3,3) , activation=\"relu\")(denenet_model(Inputs))\nc=Conv2D(512 , (3,3) , activation=\"relu\")(c)\nc=Conv2D(512 , (3,3) , activation=\"relu\" , name=\"for_class_activation\")(c)\np=Flatten()(c)\n\n# Fine tuning  dense net model model\n\nx=Dense(2048, activation=\"relu\")(p)\nx=BatchNormalization()(x)\nx=Dropout(0.2)(x)\n\nx=Dense(1024, activation=\"relu\")(x)\n\nx=Dense(1024, activation=\"relu\")(x)\nx=BatchNormalization()(x)\nx=Dropout(0.2)(x)\n\nx=Dense(1024, activation=\"relu\")(x)\n\nx=Dense(512, activation=\"relu\")(x)\nx=BatchNormalization()(x)\nx=Dropout(0.2)(x)\n\nx=Dense(512, activation=\"relu\")(x)\n\n\n\nx=Dense(256, activation=\"relu\")(x)\nx=BatchNormalization()(x)\nx=Dropout(0.2)(x)\n\nx=Dense(256, activation=\"relu\")(x)\nx=Dense(128, activation=\"relu\")(x)\nx=Dense(128, activation=\"relu\")(x)\nx=Dense(64, activation=\"relu\")(x)\n\noutput=Dense(len(classes), activation=\"softmax\")(x)\n\nmodel=Model(inputs=Inputs, outputs=output)\nmodel.summary()\n\n#plot model\nfrom tensorflow.python.keras.utils.vis_utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True , to_file=\"model.png\")\n\n\n\n","e3504bcc":"#############################################################train#############################################################\ncallbacks_denseNet=[\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\" , patience=5 , verbose=1),\n    tf.keras.callbacks.ModelCheckpoint(\"NIH_model_2.h5\" , save_best_only=True ,verbose=1),\n# tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1,  # lr*factor\n#                               patience = 1, min_delta = 0.001,\n#                                      min_lr=0.000001 , # lower lr\n#                               mode = 'min', verbose = 1)\n    \n    ]\n\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum =0.2)  , \n              loss=tf.keras.losses.binary_crossentropy , \n              metrics=[\"accuracy\"])\n\nDenseNet_history=model.fit(train_generator, \n                           epochs=20 \n                           ,steps_per_epoch=X_train.shape[0]\/batch_size\n                           ,validation_data=(val_generator),\n                           callbacks=callbacks_denseNet\n                           , verbose=1 )","e84f218b":"#evaluate \nprint('evaluate')\nmodel.evaluate(train_generator),model.evaluate(val_generator), model.evaluate(test_generator)","750589d3":"\nprint(\"- the Accuracy and Loss for DenseNet Model With 20 Epochs\")\nplt.figure(figsize=(40,20))\n\n\n\n# summarize history for accuracy \nplt.subplot(5,5,1)\nplt.plot(DenseNet_history.history['accuracy'])\nplt.plot(DenseNet_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','validation'], loc='upper left')\n\n\n\n# summarize history for loss\nplt.subplot(5,5,2)\nplt.plot(DenseNet_history.history['loss'])\nplt.plot(DenseNet_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','loss'], loc='upper left')\nplt.show()","99abe5be":"# train","69d7a441":"# read data\n","4848a5cf":"# Fit model","cb895c6b":"# Data augmentation","fa184c67":"# Build model","f3983a67":"DenseNet Models\n","25c2cfa2":"**Data descriptions**\n\nThere are 15 classes (14 diseases, and one for \"No findings\") in the full dataset, but since this is drastically reduced version of the full dataset, some of the classes are sparse with the labeled as \"No findings\"\n\n    Hernia - 13 images\n    Pneumonia - 62 images\n    Fibrosis - 84 images\n    Edema - 118 images\n    Emphysema - 127 images\n    Cardiomegaly - 141 images\n    Pleural_Thickening - 176 images\n    Consolidation - 226 images\n    Pneumothorax - 271 images\n    Mass - 284 images\n    Nodule - 313 images\n    Atelectasis - 508 images\n    Effusion - 644 images\n    Infiltration - 967 images\n    No Finding - 3044 images\n","716ddd3c":"# exploration","750214f0":"# split dataset\n"}}