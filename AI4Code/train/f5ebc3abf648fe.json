{"cell_type":{"85f9be65":"code","eda63a01":"code","61389a07":"code","305d461c":"code","718e6b62":"code","a16d1716":"code","d618c2ee":"code","dff415ea":"code","788e42fd":"code","416e9152":"code","6e671970":"code","f100a232":"code","12a49e7c":"code","41b13b03":"code","a18d0b6c":"code","cd00abfa":"code","bcef8a6a":"code","ae5dc62f":"code","964803cb":"code","9a2d3e75":"code","df8d7561":"code","3344ef39":"code","ae179b11":"markdown","1e3ed8c4":"markdown","42cc1b99":"markdown","38dda607":"markdown","f23a99d5":"markdown","d1b2885a":"markdown","04a1d47d":"markdown","828a4b79":"markdown","ee30b294":"markdown"},"source":{"85f9be65":"!git clone https:\/\/github.com\/rkuo2000\/yolov5\n%cd yolov5","eda63a01":"!mkdir -p Dataset\/FaceMask\/Images\n!mkdir -p Dataset\/FaceMask\/Labels","61389a07":"# copy image files\n!cp -rf \/kaggle\/input\/face-mask-detection\/images\/* Dataset\/FaceMask\/Images","305d461c":"!mkdir -p Dataset\/images Dataset\/labels","718e6b62":"import os\nimport numpy as np\nfrom pathlib import Path\nfrom xml.dom.minidom import parse\nfrom shutil import copyfile","a16d1716":"FILE_ROOT = \"\/kaggle\/input\/face-mask-detection\/\"\nIMAGE_PATH = FILE_ROOT + \"images\"  \nANNOTATIONS_PATH = FILE_ROOT + \"annotations\"\n\nDATA_ROOT = \"Dataset\/\"\nLABELS_ROOT = DATA_ROOT + \"FaceMask\/Labels\"\nIMAGES_ROOT = DATA_ROOT + \"FaceMask\/Images\"  \n\nDEST_IMAGES_PATH = \"images\"\nDEST_LABELS_PATH = \"labels\" ","d618c2ee":"classes = ['with_mask', 'without_mask', 'mask_weared_incorrect']","dff415ea":"def cord_converter(size, box):\n    \"\"\"\n    convert xml annotation to darknet format coordinates\n    :param size\uff1a [w,h]\n    :param box: anchor box coordinates [upper-left x,uppler-left y,lower-right x, lower-right y]\n    :return: converted [x,y,w,h]\n    \"\"\"\n    x1 = int(box[0])\n    y1 = int(box[1])\n    x2 = int(box[2])\n    y2 = int(box[3])\n\n    dw = np.float32(1. \/ int(size[0]))\n    dh = np.float32(1. \/ int(size[1]))\n\n    w = x2 - x1\n    h = y2 - y1\n    x = x1 + (w \/ 2)\n    y = y1 + (h \/ 2)\n\n    x = x * dw\n    w = w * dw\n    y = y * dh\n    h = h * dh\n    return [x, y, w, h]\n\ndef save_file(img_jpg_file_name, size, img_box):\n    save_file_name = LABELS_ROOT + '\/' + img_jpg_file_name + '.txt'\n    print(save_file_name)\n    file_path = open(save_file_name, \"a+\")\n    for box in img_box:\n\n        cls_num = classes.index(box[0])\n\n        new_box = cord_converter(size, box[1:])\n\n        file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n\n    file_path.flush()\n    file_path.close()\n    \ndef get_xml_data(file_path, img_xml_file):\n    img_path = file_path + '\/' + img_xml_file + '.xml'\n    print(img_path)\n\n    dom = parse(img_path)\n    root = dom.documentElement\n    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n    img_size = root.getElementsByTagName(\"size\")[0]\n    objects = root.getElementsByTagName(\"object\")\n    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n    # print(\"img_name:\", img_name)\n    # print(\"image_info:(w,h,c)\", img_w, img_h, img_c)\n    img_box = []\n    for box in objects:\n        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n        x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n        y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n        x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n        y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n        # print(\"box:(c,xmin,ymin,xmax,ymax)\", cls_name, x1, y1, x2, y2)\n        img_jpg_file_name = img_xml_file + '.jpg'\n        img_box.append([cls_name, x1, y1, x2, y2])\n    # print(img_box)\n\n    # test_dataset_box_feature(img_jpg_file_name, img_box)\n    save_file(img_xml_file, [img_w, img_h], img_box)","788e42fd":"files = os.listdir(ANNOTATIONS_PATH)\nfor file in files:\n    print(\"file name: \", file)\n    file_xml = file.split(\".\")\n    get_xml_data(ANNOTATIONS_PATH, file_xml[0])","416e9152":"from sklearn.model_selection import train_test_split\nimage_list = os.listdir('Dataset\/FaceMask\/Images')\ntrain_list, test_list = train_test_split(image_list, test_size=0.2, random_state=7)\nval_list, test_list = train_test_split(test_list, test_size=0.5, random_state=8)\n\nprint('total =',len(image_list))\nprint('train :',len(train_list))\nprint('val   :',len(val_list))\nprint('test  :',len(test_list))","6e671970":"def copy_data(file_list, img_labels_root, imgs_source, type):\n\n    root_file = Path(DATA_ROOT + DEST_IMAGES_PATH + '\/' + type)\n    if not root_file.exists():\n        print(f\"Path {root_file} is not exit\")\n        os.makedirs(root_file)\n\n    root_file = Path(DATA_ROOT + DEST_LABELS_PATH + '\/' + type)\n    if not root_file.exists():\n        print(f\"Path {root_file} is not exit\")\n        os.makedirs(root_file)\n\n    for file in file_list:\n        img_name = file.replace('.png', '')\n        img_src_file = imgs_source + '\/' + img_name + '.png'\n        label_src_file = img_labels_root + '\/' + img_name + '.txt'\n\n        # print(img_sor_file)\n        # print(label_sor_file)\n        # im = Image.open(rf\"{img_sor_file}\")\n        # im.show()\n\n        # Copy image\n        DICT_DIR = DATA_ROOT + DEST_IMAGES_PATH + '\/' + type\n        img_dict_file = DICT_DIR + '\/' + img_name + '.png'\n\n        copyfile(img_src_file, img_dict_file)\n\n        # Copy label\n        DICT_DIR = DATA_ROOT + DEST_LABELS_PATH + '\/' + type\n        img_dict_file = DICT_DIR + '\/' + img_name + '.txt'\n        copyfile(label_src_file, img_dict_file)","f100a232":"copy_data(train_list, LABELS_ROOT, IMAGES_ROOT, \"train\")\ncopy_data(val_list,   LABELS_ROOT, IMAGES_ROOT, \"val\")\ncopy_data(test_list,  LABELS_ROOT, IMAGES_ROOT, \"test\")","12a49e7c":"!echo \"train: Dataset\/images\/train\\n\" > data\/facemask.yaml\n!echo \"val:   Dataset\/images\/val\\n\" >> data\/facemask.yaml\n!echo \"nc : 3\\n\" >> data\/facemask.yaml\n!echo \"names: ['With_Mask', 'Without_Mask', 'Incorrect_Mask']\\n\" >> data\/facemask.yaml\n\n!cat data\/facemask.yaml","41b13b03":"!python train.py --img 320 --batch 16 --epochs 300 --data data\/facemask.yaml --cfg models\/yolov5s.yaml --weights yolov5s.pt","a18d0b6c":"# save trained weights for detection\n!cp runs\/train\/exp\/weights\/best.pt weights","cd00abfa":"!python detect.py --source Dataset\/images\/test --img-size 320 --conf 0.4 --weights weights\/best.pt ","bcef8a6a":"# display detected images\nfrom IPython.display import Image","ae5dc62f":"from glob import glob\nimport matplotlib.pyplot as plt\ntestfiles = glob('runs\/detect\/exp\/*')\n\nimg = plt.imread(testfiles[0]) \nplt.imshow(img)    \nplt.show","964803cb":"!python detect.py --source \/kaggle\/input\/input-images\/facemask.jpg --img-size 320 --conf 0.4 --weights weights\/best.pt ","9a2d3e75":"Image('runs\/detect\/exp2\/facemask.jpg')","df8d7561":"!python detect.py --source \/kaggle\/input\/input-images\/facemask1.jpg --img-size 320 --conf 0.4 --weights weights\/best.pt ","3344ef39":"Image('runs\/detect\/exp3\/facemask1.jpg')","ae179b11":"## Create Dataset","1e3ed8c4":"## split Images dataset","42cc1b99":"## Dataset: [Face Mask Detection](https:\/\/www.kaggle.com\/andrewmvd\/face-mask-detection)","38dda607":"## Test YOLOv5","f23a99d5":"## Repro [YOLOv5](https:\/\/github.com\/ultralytics\/yolov5)","d1b2885a":"### convert annotations (from COCO .xml to YOLO format .txt)","04a1d47d":"### detect facemask","828a4b79":"## Train YOLOv5","ee30b294":"## Create data\/facemask.yaml"}}