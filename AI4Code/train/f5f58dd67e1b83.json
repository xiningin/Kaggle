{"cell_type":{"2c26b848":"code","9d22a70f":"code","1c552aec":"code","1d7cd13e":"code","8f0d0e7f":"code","cc4f397a":"code","819e3c75":"code","74104eb2":"code","48e5141f":"code","7e9f6b3d":"code","09a10f1e":"code","5437f759":"code","d60ef1aa":"code","6363c22a":"code","d921ab5e":"code","68da60e3":"code","dc870ac5":"code","a8c5e3e3":"code","e673cc86":"code","53103c8f":"code","efa75971":"code","9bab418b":"code","2961c04a":"code","c647ce30":"code","5982bd35":"code","312efcd4":"code","69ac9f99":"code","44f1a5df":"code","81df2d0b":"code","8b2fc704":"code","7a696243":"code","fb1c087e":"markdown","48be4662":"markdown","2d9d7f2e":"markdown","b2c8cf88":"markdown","f52f9506":"markdown","c1f303a1":"markdown","4647faaf":"markdown","7d22b7f2":"markdown","e8fdff68":"markdown","31f5d6b7":"markdown","bede9be8":"markdown","ca7e8d7a":"markdown","4aa6b107":"markdown","2d7b6060":"markdown","d9a56aa9":"markdown","3e03f1c1":"markdown","ef9c1203":"markdown","5afbff78":"markdown","0e881c64":"markdown","783d941d":"markdown","bf93d889":"markdown","5bc6d0f5":"markdown","739ada0b":"markdown","aa36806d":"markdown","6a73f21c":"markdown"},"source":{"2c26b848":"# import libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib\nimport matplotlib.pyplot as plt # plotting\n%matplotlib inline \nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\n\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nprint(\"plotly version: {}\". format(plotly.__version__))\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9d22a70f":"from plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n# added to get Plotly working again, see\n# https:\/\/www.kaggle.com\/product-feedback\/138599","1c552aec":"# read input files\ndf_train = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv\")\ntarget_cols = [\"target_carbon_monoxide\",\"target_benzene\",\"target_nitrogen_oxides\"]\ndf_all = df_train.drop(columns=target_cols).append(df_test) # makes preprocessing easier","1d7cd13e":"print(\"Size of training data: \", df_train.shape)\ndf_train.head()","8f0d0e7f":"print(\"Size of test data: \", df_test.shape)\ndf_test.head()","cc4f397a":"#df_train.describe()\n#df_train.dtypes\ndf_train.info()","819e3c75":"df_train.date_time","74104eb2":"# calculate how much entries are supposed to be there\n# month * 24 + rest from 2010-03-10 + 2011-01-01 00:00:00 \nno_expected_dates = (31+30+31+30+31+31+30+31+30+21) * 24 + 6 + 1\nprint(\"Training data:\")\nprint(\"Number of expected entries if each hour has one timestamp: \", no_expected_dates)\nprint(\"Number of actual entries: \", df_train.shape[0])\nprint(\"Are there duplicated dates? \", df_train.duplicated(subset = \"date_time\").any())","48e5141f":"# calculate how much entries are supposed to be there\n# month * 24 + rest from 2010-03-10 + 2011-01-01 00:00:00 \nno_expected_dates = (31+28+31+3) * 24 + 15 \nprint(\"Test data:\")\nprint(\"Number of expected entries if each hour has one timestamp: \", no_expected_dates)\nprint(\"Number of actual entries: \", df_test.shape[0])\nprint(\"Are there duplicated dates? \", df_test.duplicated(subset = \"date_time\").any())","7e9f6b3d":"# create new date based columns, will be useful for modelling later\n\n#df_all[[\"date\",\"time\"]] = df_all.date_time.str.split(\" \", expand=True)  # altenative to using the datetime functions in pandas\n#df_all[[\"year\", \"month\", \"day\"]] = df_all.date.str.split(\"-\", expand=True)\n\ndf_all['date'] = df_all.date_time.str.split(\" \", expand=True)[0] #needed for quick daily grouping\ndf_all['date_time'] = pd.to_datetime(df_all['date_time'])\ndf_all['year'] = df_all['date_time'].dt.year\ndf_all['month'] = df_all['date_time'].dt.month\ndf_all['day'] = df_all['date_time'].dt.day\ndf_all['hour'] = df_all['date_time'].dt.hour\ndf_all['dayofweek'] = df_all['date_time'].dt.dayofweek\ndf_all['weekend'] = df_all['dayofweek'].apply(lambda x: 1 if (x>4)  else 0) #Sat, Sun are counted as weekend\ndf_all.head()","09a10f1e":"# check data types again, look good\ndf_all.dtypes","5437f759":"timestamp_max_temp = df_all.loc[df_all.deg_C == df_all.deg_C.max(),\"date\"].values[0]\ntimestamp_min_temp = df_all.loc[df_all.deg_C == df_all.deg_C.min(),\"date\"].values[0]\nprint(\"Minimum temperature: \", df_all.deg_C.min(), \" on \", timestamp_min_temp)\nprint(\"Maximum temperature: \", df_all.deg_C.max(), \" on \", timestamp_max_temp)","d60ef1aa":"# keep in mind that there is one duplicated row at the concatenation of train and test\ndf_all.iloc[7109:7113]","6363c22a":"# plot temperature range\ntemperature_range = df_all.deg_C.value_counts().sort_index()\n\nfig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=temperature_range.index,\n                 y=temperature_range,\n                 line = {'width':1}\n                )\n)\nfig.update_layout(\n    title=\"Temperature Range\",\n    xaxis_title=\"Temperature\",\n    yaxis_title=\"Number of occurances\")\nfig","d921ab5e":"fig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=df_all.date_time,\n                 y=df_all.deg_C,\n                 line = {'width':1}\n                )\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=45, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=45, text=\"Test\", showarrow=False, xanchor='left')\nfig.add_annotation(x=timestamp_min_temp, y=df_all.deg_C.min()-2, text=\"Min\", showarrow=False)\nfig.add_annotation(x=timestamp_max_temp, y=df_all.deg_C.max()+2, text=\"Max\", showarrow=False)\n\nfig.update_layout(\n    title=\"Temperature over time\",\n    yaxis_title=\"Temperature\")\nfig.show()","68da60e3":"# detect temperature anomalies - compute standard deviation of temperature for each day\n# flag all above a certain threshold \n#np.std(df_all.deg_C[6:30]) # interesting, np.std() seems to be different from pandas .std()\n#df_all.deg_C[6:30].std()\n#np.std(df_all.loc[df_all.date_time.str.contains(\"2011-02-12\")][\"deg_C\"])\ndaily_temp_std = df_all.groupby([\"year\",\"month\",\"day\"])[\"deg_C\"].std()\ndisplay(daily_temp_std[daily_temp_std<1])\ndisplay(daily_temp_std[daily_temp_std>7])\n#fig = px.histogram(daily_temp_std, nbins=30)\n#fig.show()\n# discontinoued, not really suitable to detect potential outliers, visual inspection is better","dc870ac5":"# calculate daily averages\nhumidity_per_day = df_all.groupby(\"date\").mean()[\"relative_humidity\"].reset_index()\n\nfig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=df_all.date_time,  # hourly data makes messy graph\n                 y=df_all.relative_humidity,\n                 line = {'width':1},\n                 name=\"Hourly\")\n)\n\nfig.add_trace(\n      go.Scatter(x=humidity_per_day.date, # use daily averages\n                 y=humidity_per_day.relative_humidity,\n                 mode = 'lines', \n                 line = {'color':'coral', \n                        'width':1\n                         },\n                 name=\"Daily Average\")\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=90, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=90, text=\"Test\", showarrow=False, xanchor='left')\n\nfig.update_layout(\n    title=\"Relative humidity over time\",\n    xaxis_title=\"Time\",\n    yaxis_title=\"Humidity\")\nfig.show()","a8c5e3e3":"# calculate daily averages\nahumidity_per_day = df_all.groupby(\"date\").mean()[\"absolute_humidity\"].reset_index()\n\nfig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=df_all.date_time,  # hourly data makes messy graph\n                 y=df_all.absolute_humidity,\n                 line = {'width':1},\n                 name=\"Hourly\")\n)\n\nfig.add_trace(\n      go.Scatter(x=ahumidity_per_day.date, # use daily averages\n                 y=ahumidity_per_day.absolute_humidity,\n                 mode = 'lines', \n                 line = {'color':'coral', \n                        'width':1\n                         },\n                 name=\"Daily Average\")\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=2.2, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=2.2, text=\"Test\", showarrow=False, xanchor='left')\n\nfig.update_layout(\n    title=\"Absolute humidity over time\",\n    #xaxis_title=\"Time\",\n    yaxis_title=\"Humidity\")\nfig.show()","e673cc86":"fig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_1,\n                 line = {'width':1},\n                 name=\"Sensor 1\")\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=2000, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=2000, text=\"Test\", showarrow=False, xanchor='left')\n\nfig.update_layout(\n    title=\"Sensor 1 Data\"\n)\nfig.show()","53103c8f":"fig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_2,\n                 line = {'width':1},\n                 name=\"Sensor 2\")\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=2250, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=2250, text=\"Test\", showarrow=False, xanchor='left')\n\nfig.update_layout(\n    title=\"Sensor 2 Data\"\n)\nfig.show()","efa75971":"fig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_3,\n                 line = {'width':1},\n                 name=\"Sensor 3\")\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=2500, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=2500, text=\"Test\", showarrow=False, xanchor='left')\n\nfig.update_layout(\n    title=\"Sensor 3 Data\"\n)\nfig.show()","9bab418b":"fig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_4,\n                 line = {'width':1},\n                 name=\"Sensor 4\")\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=2800, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=2800, text=\"Test\", showarrow=False, xanchor='left')\n\nfig.update_layout(\n    title=\"Sensor 4 Data\"\n)\nfig.show()","2961c04a":"fig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_5,\n                 line = {'width':1},\n                 name=\"Sensor 5\")\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=2500, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=2500, text=\"Test\", showarrow=False, xanchor='left')\n\nfig.update_layout(\n    title=\"Sensor 5 Data\"\n)\nfig.show()","c647ce30":"fig = go.Figure()\n\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_1, \n                 mode = 'lines', \n                 line = {'width':1},\n                 name=\"Sensor 1\")\n)\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_2,\n                 mode = 'lines', \n                 line = {'width':1},\n                 name=\"Sensor 2\")\n)\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_3,\n                 mode = 'lines', \n                 line = {'width':1},\n                 name=\"Sensor 3\")\n)\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_4,\n                 mode = 'lines', \n                 line = {'width':1},\n                 name=\"Sensor 4\")\n)\nfig.add_trace(\n      go.Scatter(x=df_all.date_time, \n                 y=df_all.sensor_5,\n                 mode = 'lines', \n                 line = {'width':1},\n                 name=\"Sensor 5\")\n)\n\nfig.add_vrect(x0=\"2011-01-01 00:00:00\", x1=\"2011-04-04 14:00:00\", line_width=0, fillcolor=\"grey\", opacity=0.1)\n\nfig.add_annotation(x=\"2010-12-30 00:00:00\", y=2500, text=\"Train\", showarrow=False, xanchor='right')\nfig.add_annotation(x=\"2011-01-03 00:00:00\", y=2500, text=\"Test\", showarrow=False, xanchor='left')\n\nfig.update_layout(\n    title=\"Sensor Data, 1-5\"\n)\nfig.show()","5982bd35":"hourly_values = df_all.groupby([\"hour\"]).mean()\n\nfig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=hourly_values.index, \n                 y=hourly_values.sensor_1,\n                 line = {'width':1},\n                 name=\"Sensor 1\")\n)\n\nfig.add_trace(\n      go.Scatter(x=hourly_values.index, \n                 y=hourly_values.sensor_2,\n                 line = {'width':1},\n                 name=\"Sensor 2\")\n)\n\nfig.add_trace(\n      go.Scatter(x=hourly_values.index, \n                 y=hourly_values.sensor_3,\n                 line = {'width':1},\n                 name=\"Sensor 3\")\n)\n\nfig.add_trace(\n      go.Scatter(x=hourly_values.index, \n                 y=hourly_values.sensor_4,\n                 line = {'width':1},\n                 name=\"Sensor 4\")\n)\n\nfig.add_trace(\n      go.Scatter(x=hourly_values.index, \n                 y=hourly_values.sensor_5,\n                 line = {'width':1},\n                 name=\"Sensor 5\")\n)\n\nfig.update_layout(\n    title=\"Mean Sensor Values per Hour\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0,\n        dtick = 1\n    )\n)\nfig.show()","312efcd4":"# comparing groupby and resample\n#df_all.groupby([\"month\"]).mean() # groups by month number: 12 entries\n#df_all.resample(\"m\", on=\"date_time\").mean() # groups by year and month: 13 entries as for March there is data from 2010 and 2011","69ac9f99":"daily_values = df_all.groupby([\"dayofweek\"]).mean()\n\nfig = go.Figure()\nfig.add_trace(\n      go.Scatter(x=daily_values.index, \n                 y=daily_values.sensor_1,\n                 line = {'width':1},\n                 name=\"Sensor 1\")\n)\n\nfig.add_trace(\n      go.Scatter(x=daily_values.index, \n                 y=daily_values.sensor_2,\n                 line = {'width':1},\n                 name=\"Sensor 2\")\n)\n\nfig.add_trace(\n      go.Scatter(x=daily_values.index, \n                 y=daily_values.sensor_3,\n                 line = {'width':1},\n                 name=\"Sensor 3\")\n)\n\nfig.add_trace(\n      go.Scatter(x=daily_values.index, \n                 y=daily_values.sensor_4,\n                 line = {'width':1},\n                 name=\"Sensor 4\")\n)\n\nfig.add_trace(\n      go.Scatter(x=daily_values.index, \n                 y=daily_values.sensor_5,\n                 line = {'width':1},\n                 name=\"Sensor 5\")\n)\n\nfig.update_layout(\n    title=\"Mean Sensor Values per Weekday\",\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = list(range(0,7,1)),\n        ticktext = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n    )\n)\nfig.show()","44f1a5df":"fig = go.Figure()\n\nfig.add_trace(\n      go.Scatter(x=df_train.date_time, \n                 y=df_train.target_carbon_monoxide, \n                 mode = 'lines', \n                 line = {'color':'darkgoldenrod', 'width' : 1},\n                 #opacity=0.1,\n                 name=\"Carbon Monoxide\")\n)\n\nfig.update_layout(\n    title=\"Carbon Monoxide over time\"\n)\nfig.show()","81df2d0b":"fig = go.Figure()\n\nfig.add_trace(\n      go.Scatter(x=df_train.date_time, \n                 y=df_train.target_benzene,\n                 #mode = 'lines', \n                 line = {'color':'darkgoldenrod', 'width' : 1},\n                 name=\"Target Benzene\")\n)\n\nfig.update_layout(\n    title=\"Benzene over time\"\n)\nfig.show()","8b2fc704":"fig = go.Figure()\n\nfig.add_trace(\n      go.Scatter(x=df_train.date_time, \n                 y=df_train.target_nitrogen_oxides,\n                 mode = 'lines', \n                 line = {'color':'darkgoldenrod', 'width' : 1},\n                 name=\"Nitrogen_oxides\")\n)\n\nfig.update_layout(\n    title=\"Nitrogen Oxides over time\"\n)\nfig.show()","7a696243":"# check correlation between the target columns\ndf_train[target_cols].corr()","fb1c087e":"Nitrogen Oxides are a group of molucules consisting of nitrogen and oxygen. Examples are: NO, NO2, N2O, N2O3... While there are natural sources like lightening, a big part of the nitrogen oxides comes from burning fossile fuels. A high concentration of nitrogen oxides negatively impacts human lung function. (Source: Wikipedia)\n\nThere is a daily pattern with one peak in the morning and one in the afternoon. There is a \"low season\" in August and higher values over the winter. ","48be4662":"For Sensor 4, the pattern is not so clear. There seems to be one peak in the morning and one peak in the afternoon. ","2d9d7f2e":"## Overlaying the Sensor Data\nWithout zoom we see a mess.\n\nWhen we zoom in, e.g. to the December and January data, we can see that there are times where all sensors show untypical values. Why would that be?","b2c8cf88":"## Examining Sensor Data\nZoom in to spot the daily trends and exceptions!","f52f9506":"We can see, that the correlation of target_carbon_monoxide and target_benzene with target_nitrogen_oxides is the weakest. The first two target columns might not help much in predicting the last one. ","c1f303a1":"## Quick overview","4647faaf":"The temperature range shows a typcical pattern. Temperatures between 10 and 25 degree C most of the times. Few high extremes with temperature rising up to 46.1 degree C. Hardly any frost, only few days a year with low minus degrees. Minimum temperature is -1.8 degrees C.","7d22b7f2":"## Examining the target variables\n\nSummary: \n* All target variables are air pollutants.\n* There is a yearly pattern with a low in August (vacation time?) and higher values in winter (more exhausts?).\n* There is a daily pattern with a high in the morning and one in the afternoon (commuting to and from work?).","e8fdff68":"Here we see a temperature curve that is higher in summer, lower in winter. When zooming in, a daily temperature pattern can be seen with higher temperature in the afternoon, lower temperature in the night. So far, so good. \n\nBut it's easy to spot several areas that are worth further exploration. From December 2010 to March 2011 there are five areas that look erroneous. Zoom in to examine them more closely. There might be more of those areas hidden in the plot...","31f5d6b7":"**Summary**:\n* No missing values. \n* Data types as expected. \n* The dataset is rather small. This needs to be taken into account when choosing the validation scheme. ","bede9be8":"Sensor 3 data follows a cyclical pattern with a high in the early morning (3-4 am) and a low around 8 am.\n\nExceptions are: April 9th, June 20th+21st, Jul 30th, Aug 9th, Aug 26th+27th, Sept 8th, Oct 1st, Nov 14th, Dec 1st, Dec 10th, Dec 15th-17th, Dec 24th, Jan 3rd+4th, Feb 9th-11th, Mar 1st, Mar 11th.","ca7e8d7a":"## Examining date and time","4aa6b107":"**Train set**:\n* First timestamp: 2010-03-10 18:00:00 \n* Last timestamp: 2011-01-01 00:00:00\n* 1 entry every hour\n* March till December (9 and a half month full of data -> 295 days plus 6 hours)\n\n\n**Test set**:\n* First timestamp: 2011-01-01 00:00:00 -- identical to last timestamp from training data!\n* Last timestamp: 2011-04-04 14:00:00\n* 1 entry every hour\n* January till April (approx. 3.2 month of data -> 93 days and 15 hours)\n\nThe training data is less than one year. The time range for prediction covers month where no training data are available. Not good.","2d7b6060":"Carbon Monoxide (CO) is a colorless, odorless, tasteless and flammable gas. Among other sources it is caused by industrial activities and liked to climate change. High doses are toxic. (Source: Wikipedia)\n\nThere is a daily pattern with one peak in the morning and one in the afternoon. There is a \"low season\" in August and higher values over the winter.","d9a56aa9":"Benzene is an organic chemical compound with the formula C6H6. Benzene is classified as a carcinogen and originates for example from tobacco smoke or motor exhausts but also vulcanic erruptions and wildfires. (Source: Wikipedia)\n\nThere is a daily pattern with one peak in the morning and one in the afternoon. There is a \"low season\" in August and higher values over the winter. We can see several occasions where the sensor seems to have reached it's lower end. ","3e03f1c1":"## Examining Humidity\nClick on the legend to show or hide daily averages.","ef9c1203":"# Exploratory Data Analysis for Tabular Playground Series July 2021\n\nThe dataset deals with predicting air pollution in a city via various input sensor values. The task is to predict, based on the sensor, values **three** target variables: target_carbon_monoxide,target_benzene and target_nitrogen_oxides. Submissions are evaluated using the [mean column-wise root mean squared logarithmic error](http:\/\/www.kaggle.com\/c\/tabular-playground-series-jul-2021\/overview\/evaluation).\n\n\nI chose to use **Plotly** this time as Plotly allows interactive exploration of the data. This is especially nice when examining larger or shorter time intervals.\n\nLooking forward to your feedback and comments!","5afbff78":"Sensor 2 data shows a pattern with a drop in the early morning hours (3-4 am), like Sensor 1. \n\nExceptions are: April 9th, Mai 26th, June 19th-21st, August 9th, August 26th-28th, Sept 8th, Oct 1st, Dec 15th-17th, Jan 3rd+4th, Feb 9th-11th, March 11th. There, the values drop close to the minimum.\n\n","0e881c64":"Four sensors show lower values over the weekend. Experiment with weekend = Sat+Sun or weekend = Sat+Sun+Mon.","783d941d":"### These figures are interactive, please explore!\nYou can zoom in to areas that interest you (form a rectangle with your cursor). To reset the view, double-click or click the house button on the upper right of the plot.","bf93d889":"On the graph displaying absolute humidity over time there are several occasions with strange drops in absolute humidity, e.g. July 31th, Aug 27th. ","5bc6d0f5":"Sensor 1 data shows a pattern with a drop in the early morning hours (3-4 am).\n\nExceptions are: August 26th+27th, December 15th-17th, January 3rd+4th, January 29th+30th and February 9th-11th.","739ada0b":"## Examining temperature","aa36806d":"We can see that there are common peaks and lows between the sensors. Sensor_3 seems to be inversly related. Based on this analysis I will introduce an additional day_time feature called \"rush-hour\".","6a73f21c":"Like Sensor 4, not such a clear pattern. There seems to be a peak in the morning and one in the afternoon."}}