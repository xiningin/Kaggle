{"cell_type":{"d46492dd":"code","d7d657b1":"code","6f8b6cd0":"code","8df560d0":"code","19106c49":"code","fa0542c4":"code","3537c944":"code","dc636743":"code","a6430ebf":"code","a29bd145":"code","cc0db340":"code","1eddcb8e":"markdown","0aba9ee9":"markdown","e54f93cd":"markdown","193a445b":"markdown","8dc89973":"markdown"},"source":{"d46492dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7d657b1":"#Loading the dataset\ndf = pd.read_csv('\/kaggle\/input\/wisconsin-breast-cancer-cytology-features\/wisconsin_breast_cancer.csv')\ndf.fillna(0, inplace=True)\ndf.info()","6f8b6cd0":"#Checking the head of the data\ndf.head(5)","8df560d0":"#Visualising the data as a pairplot\nimport seaborn as sns\nsns.pairplot(data=df, hue='class')","19106c49":"#Setting X to all features except \"class\"\nX = df.iloc[:, 1:-1]\nX \n#Setting Y to \"class\" feature\ny = df.iloc[:, -1]\ny","fa0542c4":"#Splitting into train and test with with test_size=0.2, or 20%, and using random_state=YOUR_ID\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1508018)\nX_train.shape","3537c944":"#Train an SVC classifier on the train set\nfrom sklearn.svm import SVC\nm = SVC()\nm\nm.fit(X_train, y_train)","dc636743":"#Predict for the test set\np = m.predict(X_test)\nprint(p[:10])","a6430ebf":"#Check that predictions match data\nprint(y_test[:10])","a29bd145":"#Generate a confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, p))","cc0db340":"#Generate a classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, p))","1eddcb8e":"The pairplot shows that there is no natural classifier","0aba9ee9":"Precision:\nFor the data that was predicted to not have cancer, 97% do in fact not have cancer.\nFor the data that was predicted to have cancer, 92% do in fact have cancer.\n\nRecall:\nFor the data that did not have cancer, 96% were correctly predicted to not have cancer.\nFor the data that did have cancer, 94% were correctly predicted to have cancer.\n\nFl-score:\nFl score is the average of the precision and recallm of that class. Class 0 has a higher f1-score of 96% compared to class 1 which has 93%.\n\nSupport:\nSupport is the number of cases in each class that are being tested. 90 cases were from class 0 and 50 cases were from class 1.","e54f93cd":"Name: Connor Welham\nID: 1508018","193a445b":"7 data points were incorrectly classified. 3 of the data points were predicted to be class 0, but were actually class 1. 4 data points were predicted to be class 1, but were actually class 0.","8dc89973":" As shown by the predictionbs and the actual data, the two match which means we have correctly predicted the class of the last 10 data"}}