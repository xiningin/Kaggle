{"cell_type":{"a1f9f719":"code","f6ef0852":"code","b14e74c5":"code","a885b2ce":"code","c5745a9c":"code","7c2634d2":"code","3411f8c1":"code","48328fae":"code","8a661679":"code","33f958b0":"code","2a1d657f":"code","c724fa5a":"code","90445754":"code","4525a6c1":"code","e3831e9f":"code","66d1c53c":"markdown","ef42b127":"markdown","3bb43772":"markdown","1801c898":"markdown","9aba16b5":"markdown","913d814c":"markdown","86848c05":"markdown","68d54a10":"markdown","1318dc47":"markdown","e59b914f":"markdown","50b708b6":"markdown","4802c80d":"markdown","3750c335":"markdown"},"source":{"a1f9f719":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.inspection import permutation_importance\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Load data\ndf = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndf.head()","f6ef0852":"df.isnull().sum()","b14e74c5":"# Drop rows with NaN values\ndf = df.dropna()","a885b2ce":"#drop variables that will not be used in model\ndf =df.drop(['id','work_type','ever_married'],axis=1)","c5745a9c":"# View statistics of numerical data\ndf.describe(include = 'all')","7c2634d2":"#Create non-numerical data dummies\ndf = pd.get_dummies(df)\n\ndf.describe(include='all')","3411f8c1":"#Plotting the distribution plot.\nplt.figure(figsize=(20,25))\nplotnumber=1\n\nfor column in df:\n  if plotnumber<15:\n    ax=plt.subplot(4,4,plotnumber)\n    sns.distplot(df[column])\n    plt.xlabel(column,fontsize=20)\n    plt.ylabel('Values',fontsize=20)\n  plotnumber+=1\nplt.show()","48328fae":"#Correlation matrix\n\nplt.figure(figsize = (16, 8))\n\ncorr = df.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\nsns.heatmap(corr, cmap='YlGnBu',mask = mask, annot = True, fmt = '.2g', linewidths = 1)\nplt.show()","8a661679":"# Split data into inputs and target result\ninput = df.drop([\"heart_disease\"], axis=1)\ntarget = df[\"heart_disease\"]","33f958b0":"# Normalize the data\nscaler = StandardScaler()\ninput_scaled = scaler.fit_transform(input)","2a1d657f":"# Split the data into train and test sets with a 80\/20 ratio\nX_train, X_test, y_train, y_test = train_test_split(input_scaled, target, test_size=0.2, random_state=0)","c724fa5a":"# Fit a random forest classifier on train set and predict on test set\nclf = RandomForestClassifier(random_state=0)\nclf.fit(X_train, y_train)\n\ntarget_predict = clf.predict(X_test)","90445754":"#Show Feature Importance\nclf_summary = pd.DataFrame(input.columns.values, columns=['Features'])\nclf_summary['weight'] = clf.feature_importances_\nclf_summary.sort_values","4525a6c1":"# Output classification metrics\nprint(classification_report(y_test, target_predict))","e3831e9f":"conf_matrix = pd.crosstab(y_test,target_predict)\nconf_matrix","66d1c53c":"To include categorical data into the model. use dummies to turn these fields into binary true false values with dummies. This changes the data from 9 columns to 15 columns.","ef42b127":"## Train Classifier","3bb43772":"Below we can see where the model miscategorized the data. This model was wrong on 4 records. 3 of the records were labeled for no heart disease and only 1 recorded was wrongly predicted to have heart disease.","1801c898":"To ensure our numeric features are being measured on a common scale, normalize the data set to before training the model.","9aba16b5":"Train the model, because our target output is to determine if an indivdual has heart disease or not, we use a classifier to predict which category to assign. After training the model, we can see which features we included have the most significant impact. features being closer to 1 having the most importance. this can be used to simplify the model if a feature appears irrelevant.","913d814c":"## Import Libraries and Load Data","86848c05":"# Heart Disease Prediction","68d54a10":"Now test the accuracy of our logic on the test data. we can see the current model is 95% accurate","1318dc47":"To get a better image of the data, this look creates a distribution plot of all the features. It shows the frequency histogram of our numerical variables and how our categorical data is separated.","e59b914f":"To train and test the accuracy of our model, we split the data. 80% of the records will be used to train our model to evaluate if an individual has heart disease or not. Then the remaining 20% of records are used to test how well the model performs.","50b708b6":"Before we build our model, it is important to check the correlation coefficients of our features. When a correlation coefficient is close to 0, there is a weaker relationship. When a correlation is strong, it affects the models' ability to estimate the relationship between each independent and dependant variable","4802c80d":"## Clean the Data","3750c335":"## Model Accuracy"}}