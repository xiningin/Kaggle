{"cell_type":{"532d3b2d":"code","b5befbd2":"code","22136583":"code","c1f044e6":"code","c5a1d424":"code","80787c71":"code","e6960c45":"code","7877bc66":"code","715fc54d":"code","cecb013e":"code","3cc9721c":"code","de72f7e0":"code","795244e2":"code","1e06a167":"markdown","9cfab1a6":"markdown","304abb48":"markdown","8b49ed71":"markdown","322d303e":"markdown","bee2b4dc":"markdown","cd39fb86":"markdown","7a46ea1f":"markdown","c4e15890":"markdown","fa15d386":"markdown","79984879":"markdown","c4fdb0b7":"markdown"},"source":{"532d3b2d":"import os\nimport time\nimport gc\nimport random\n\nfrom glob import glob\nimport numpy as np\nfrom matplotlib import pylab as plt\nimport cv2\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.models import Model\nfrom osgeo import gdal\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib.colors import LinearSegmentedColormap\n\nprint(tf.__version__)","b5befbd2":"image_size = 512\nimage_channels = 3\nlabel_values = list(range(44))","22136583":"def transform_labels(labels_array, labels):\n    lb = preprocessing.LabelBinarizer()\n    \n    lb.fit(labels)\n    \n    new_labels_array = []\n    \n    for ix, l in enumerate(labels_array):\n        \n        flat_labels = l.reshape((l.shape[0] * l.shape[1],))\n        \n        transformed_flat_labels = lb.transform(flat_labels)\n        \n        new_labels_array.append(transformed_flat_labels.reshape((l.shape[0], l.shape[1], len(labels))))\n\n    new_labels_array = np.array(new_labels_array)\n\n    return new_labels_array","c1f044e6":"def load_dataset(X, y):\n    img1=gdal.Open(X).ReadAsArray().transpose(1, 2, 0)\n    img1  = np.array((img1 \/ 255.0) - 1)\n\n    img2=gdal.Open(y).ReadAsArray()\n    img2 = img2.reshape((img2.shape[0], img2.shape[1], 1))\n    img2 = transform_labels([img2], label_values)[0]\n      \n    img1=np.array(img1).astype('float16')\n    img2=np.array(img2).astype('int8')\n    \n    return img1, img2","c5a1d424":"X_train, y_train = sorted(glob('..\/input\/california-crop-mapping\/train_images\/*')), sorted(glob('..\/input\/california-crop-mapping\/train_label\/*'))\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.30, random_state=1)\n\nX_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=1)\n\nprint(\"Train: {}, Validation: {}, Test: {}\".format(len(X_train),len(X_val), len(X_test))) ","80787c71":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, Add\n\n\n\ndef model_fn(input_shape, n_filters=64, labels=[]):\n    inputs = keras.Input(input_shape)\n\n    x = Conv2D(n_filters, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    x = Conv2D(n_filters, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n    x = Dropout(0.25) (x)\n    pool1 = x\n    \n    # Block 2\n    x = Conv2D(n_filters * 2, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(n_filters * 2, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n    x = Dropout(0.25) (x)\n    pool2 = x\n\n    # Block 3\n    x = Conv2D(n_filters * 4, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(n_filters * 4, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(n_filters * 4, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n    x = Dropout(0.5) (x)\n    pool3 = x\n\n    # Block 4\n    x = Conv2D(n_filters * 8, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(n_filters * 8, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(n_filters * 8, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n    pool4 = Dropout(0.5) (pool4)\n\n    # Block 5\n    x = Conv2D(n_filters * 8, (3, 3), activation='relu', padding='same', name='block5_conv1')(pool4)\n    x = Conv2D(n_filters * 8, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(n_filters * 8, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n    pool5 = Dropout(0.5) (pool5)\n\n    if len(labels) > 2:\n        n_classes = len(labels)\n        output_activation = 'softmax'\n        loss_function = 'categorical_crossentropy'\n        metrics = ['categorical_accuracy']\n    else:\n        n_classes = 1\n        output_activation = 'sigmoid'\n        loss_function = 'binary_crossentropy'\n        metrics = ['binary_accuracy']\n    \n    \n    o = (Conv2D(n_classes, (7, 7), activation='relu', padding='same', name=\"conv6\"))(pool5)\n        \n    ## 4 times upsamping for final layer\n    conv6_4 = Conv2DTranspose(n_classes, kernel_size=(4,4),  strides=(4,4), use_bias = False)(o)\n    conv6_4 = Dropout(0.5) (conv6_4)\n\n    ## 2 times upsampling for pool411\n    pool4_n = ( Conv2D(n_classes, (1, 1), activation='relu', padding='same', name=\"pool4_n\"))(pool4)\n    pool4_n_2 = (Conv2DTranspose(n_classes, kernel_size=(2,2), strides=(2,2), use_bias=False))(pool4_n)\n    pool4_n_2 = Dropout(0.5) (pool4_n_2)\n\n    #1 time for pool3\n    pool3_n = (Conv2D( n_classes , ( 1 , 1 ) , activation='relu' , padding='same', name=\"pool3_n\"))(pool3)\n    pool3_n = Dropout(0.5) (pool3_n)\n        \n    o = Add(name=\"add\")([pool4_n_2, pool3_n, conv6_4 ])\n    o = Conv2DTranspose( n_classes , kernel_size=(8,8) ,  strides=(8,8) , use_bias=False)(o)\n\n    o = (Activation(output_activation))(o)\n    \n    model = keras.Model(inputs, o)\n    model.compile(loss=loss_function, optimizer='adam', metrics=metrics)\n    return model\n\nmodel = model_fn((image_size, image_size, image_channels), labels=label_values)\nmodel.summary()","e6960c45":"model_dir = '\/kaggle\/working\/logs'\n\ncheckpoint_path = model_dir + '\/model.ckpt'\n\nes_callback = tf.keras.callbacks.EarlyStopping(\n            patience=5, verbose=1)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(\n            filepath=checkpoint_path,\n            save_weights_only=True,\n            save_best_only=True)\n\ncallbacks = [es_callback, cp_callback]","7877bc66":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, x_data, y_data=None, batch_size=32, labels=None, shuffle=True):\n        self.batch_size = batch_size\n        self.indices = range(len(x_data))\n        self.shuffle = shuffle\n        self.x_data = x_data\n        self.y_data = y_data\n        self.labels = labels\n        self.on_epoch_end()\n\n    def __len__(self):\n        return len(self.indices) \/\/ self.batch_size\n\n    def __getitem__(self, index):\n        X, y = self.__get_data(start=index, end=index + self.batch_size)\n        return X, y\n\n    def on_epoch_end(self):\n        self.index = np.arange(len(self.indices))\n        if self.shuffle == True:\n            np.random.shuffle(self.index)\n\n    def __get_data(self, start, end):\n        \n        X = self.x_data[start:end]\n        y = self.y_data[start:end]\n        \n        X_values = []\n        y_values = []\n        for image_path, labels_path in zip(X, y):\n            image, labels = load_dataset(image_path, labels_path)\n            X_values.append(image)\n            y_values.append(labels)\n        \n        X_values = np.array(X_values)\n        y_values = np.array(y_values)\n        \n        return X_values, y_values","715fc54d":"batch_size = 5\n\nhistory = model.fit_generator(DataGenerator(X_train, y_train, batch_size, label_values),\n                              validation_data=DataGenerator(X_val, y_val, batch_size, label_values),\n                              validation_steps=len(X_val)\/\/batch_size,\n                              steps_per_epoch=len(X_train)\/\/batch_size, \n                              epochs=100, \n                              verbose=1, \n                              callbacks=callbacks)","cecb013e":"# plot history\nplt.figure(figsize=(20,8))\nplt.plot(history.history['loss'], label='Train loss')\nplt.plot(history.history['val_loss'], label='Validation loss')\nplt.legend()\nplt.ylabel('Model loss')\nplt.xlabel('Epochs')\nplt.show()\nplt.savefig('\/kaggle\/working\/model_loss.png', dpi=300, bbox_inches='tight')","3cc9721c":"latest = tf.train.latest_checkpoint(model_dir)\n\nif latest:\n    print(\"Loading best model....\")\n    model.load_weights(latest)","de72f7e0":"model.save('\/kaggle\/working\/model.h5')","795244e2":"rows = len(X_test)\n\ncolors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(label_values))]\n\ncmap = LinearSegmentedColormap.from_list('sss', colors, N=len(label_values))\n\ncount = 1\n\nfor x, y in zip(X_test, y_test):\n    image, labels = load_dataset(x, y)\n\n    predicted = model.predict(np.array([image]))[0]\n\n    if len(label_values) > 2:\n        predicted = np.array(tf.math.argmax(predicted, axis=2))\n    else:\n        predicted[predicted > 0.5] = 1\n        predicted[predicted <= 0.5] = 0\n\n    predicted = predicted.reshape((predicted.shape[0], predicted.shape[1]))\n\n    rgb_image = np.array((image + 1) * 255).astype(int)\n    \n    fig, axs = plt.subplots(1, 3, figsize=(15, 10))\n    \n    axs[0].imshow(rgb_image)\n    axs[0].set_title('Image')\n    axs[0].axis('off')\n\n    axs[1].imshow(tf.math.argmax(labels, axis=2), vmin=0, vmax=len(label_values) - 1,cmap=cmap)\n    axs[1].set_title('Labels')\n    axs[1].axis('off')\n\n    axs[2].imshow(predicted, vmin=0, vmax=len(label_values) - 1, cmap=cmap)\n    axs[2].set_title('Predicted')\n    axs[2].axis('off')\n    \n    plt.show()\n    \n    if count  == 20:\n        break\n    else:\n        count += 1","1e06a167":"# Load dataset","9cfab1a6":"# Plot history","304abb48":"# Create callbacks","8b49ed71":"# Predict test images","322d303e":"# Save model","bee2b4dc":"# Imports","cd39fb86":"# Split data in train, validation and test sets","7a46ea1f":"# Load best model","c4e15890":"# Train model","fa15d386":"# Build DataGenerator","79984879":"# Settings","c4fdb0b7":"# FCNN - Fully Convolutional Neural Network model"}}