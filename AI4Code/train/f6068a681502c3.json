{"cell_type":{"b9cbfc99":"code","71dbba70":"code","1a030e7d":"code","7e173d35":"code","ef420543":"code","6b242719":"code","72069319":"code","20b2dc46":"code","8c43f052":"code","e5bb7137":"code","886dd8f4":"code","628eb139":"code","2a8edc38":"code","07aa8e91":"code","b2d6b992":"code","97618159":"code","2f1ce3ab":"code","26d1e685":"code","4e133faa":"code","04242393":"code","8dff5053":"code","63289472":"code","6f1caf0d":"code","68051330":"code","5c779c8e":"code","46092d1e":"code","d2c3bfbd":"code","0fc2fdaf":"code","558b18e5":"code","666fdd57":"code","d96e8ce9":"code","c379cd22":"code","c856376f":"code","407407f1":"code","863e785c":"code","7afbab54":"code","a4a68a39":"code","ec3d0ca1":"code","c2d08e0c":"code","291208ff":"code","c144a18c":"markdown","4f289bde":"markdown","8a02bef4":"markdown"},"source":{"b9cbfc99":"# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# pd.set_option('display.max_columns', None)  # or 1000\npd.set_option('display.max_rows', None)  # or 1000 to get all the rows for our dataframe\n# pd.set_option('display.max_colwidth', None)  # or 199\n","71dbba70":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\")","1a030e7d":"test_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\")","7e173d35":"train_df.head(10)","ef420543":"Summary = pd.DataFrame(train_df.dtypes, columns=['Dtype'])\nSummary[\"max\"] = train_df.max()\nSummary[\"min\"] = train_df.min()\nSummary[\"Null\"] = train_df.isnull().sum() # to get null values\nSummary[\"First\"] = train_df.iloc[0] # to get first value\nSummary[\"Second\"] = train_df.iloc[1] # to get second value\nSummary\n","6b242719":"# train_df = train_df.fillna(0)\ntrain_df = train_df.fillna(train_df.median())","72069319":"print(len(train_df))","20b2dc46":"test_df.head(10)","8c43f052":"# y.nunique.count()","e5bb7137":"test_df = test_df.drop(\"id\", axis=1)","886dd8f4":"test_df = test_df.fillna(test_df.median())\n","628eb139":"y = train_df[\"claim\"]\ntrain_df = train_df.drop([\"id\"], axis=1)","2a8edc38":"import matplotlib.pyplot as plt\ncorr_mat = train_df.corr()","07aa8e91":"# corr_mat[abs(corr_mat) > 0.5]\n\ncor_target = abs(corr_mat[\"claim\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target<0.0009]\nrelevant_features","b2d6b992":"feat_to_drop = relevant_features.index.to_list()\ntrain_df = train_df.drop(feat_to_drop, axis = 1)\ntest_df = test_df.drop(feat_to_drop, axis = 1)","97618159":"train_df = train_df.drop([\"claim\"], axis=1)","2f1ce3ab":"# test_df.isnull().sum()\ny.value_counts()","26d1e685":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(train_df, y,random_state = 123, test_size = 0.1)","4e133faa":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","04242393":"from xgboost import XGBRegressor\n# import lightgbm","8dff5053":"print(len(X_train))\nprint(len(X_test))\nprint(len(y_train))\nprint(len(y_test))","63289472":"lr = LinearRegression()\n# lr = LogisticRegression(random_state=123)\nlr.fit(X_train, y_train)\n","6f1caf0d":"xgbr= XGBRegressor(\n    n_estimators=3000,\n    learning_rate=0.03,\n    subsample=0.8,\n    colsample_bytree=0.1,\n    max_depth=3,\n    booster='gbtree',\n    reg_lambda=0.0008,\n    reg_alpha=24,\n    random_state=123\n)\n# xgbr = XGBRegressor(random_state = 123)\nxgbr.fit(X_train, y_train)","68051330":"y_pred_xgb = xgbr.predict(X_test)","5c779c8e":"y_pred = lr.predict(X_test)","46092d1e":"y_pred","d2c3bfbd":"# y_pred_reshaped = []\n# for val in y_pred:\n#     if val[0] > val[1]:\n#         y_pred_reshaped.append()","0fc2fdaf":"y_pred.shape","558b18e5":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nprint(auc(fpr, tpr))\n# this is the score: 0.5254161343242256\n# this is the score with logisticR: 0.530162419244593","666fdd57":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_xgb)\nprint(auc(fpr, tpr))\n# this is the score: 0.776245437662909","d96e8ce9":"test_df = scaler.transform(test_df)","c379cd22":"y_val = lr.predict(test_df)","c856376f":"y_val_xgbr = xgbr.predict(test_df)","407407f1":"sub = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")","863e785c":"y_val","7afbab54":"y_val_xgbr","a4a68a39":"sub[\"claim\"] = y_val_xgbr","ec3d0ca1":"y_val_xgbr","c2d08e0c":"y_res = (y_val_xgbr + y_val)\/2","291208ff":"sub[\"claim\"] = y_val_xgbr\nsub.to_csv(\"submission.csv\", index=False)\nsub.head(10)","c144a18c":"Almost all the rows have null values and the datatypes for all column is float except for claim, that is target variable, in that case it is int.\n\nLet's drop the target variable and id from the training data.","4f289bde":"So, there are some 119 features and and a target variable claim. \nLet's first try to train the model without null values and will then impute the null values with some value. ","8a02bef4":"We can see that the test_df also have 119 features. Target variable is not included in the dataset. \n\nLet's drop the id column from the test dataset as well and impute the missing values with zero."}}