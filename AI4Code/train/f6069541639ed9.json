{"cell_type":{"dd6b8f95":"code","1e6a55d3":"code","28092539":"code","6a2f0bf0":"code","0cecef6f":"code","b912a561":"code","56e2d53f":"code","6a8a58c5":"code","a8f7957c":"code","55bb59a1":"code","fabe4263":"code","cd386f45":"code","455494ae":"code","ac6ecee3":"code","ee6b036d":"code","be5ac7f3":"code","3e90d678":"code","7ec97eba":"code","da866282":"code","bf164d08":"code","75bad505":"code","22a36436":"code","9ab28402":"code","cdedc8b6":"code","6aaaef3a":"markdown","0f692262":"markdown","0a0866bf":"markdown","98cbfe80":"markdown","4032f45f":"markdown","bc646000":"markdown","125c3ab9":"markdown"},"source":{"dd6b8f95":"import numpy as np \nimport pandas as pd\nimport os\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom plotly import tools\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nfrom sklearn import preprocessing\nimport itertools\nimport tensorflow as tf\n%matplotlib inline\nprint(os.listdir(\"..\/input\"))","1e6a55d3":"df = pd.read_excel(\"..\/input\/loan.xlsx\")\nsol = pd.read_excel(\"..\/input\/Data_Dictionary.xlsx\")\n# Best to save a copy in case data gets corrupted\ndf_copy = df.copy()","28092539":"# Get idea of genral structre of dataet\ndf.head()","6a2f0bf0":"# Getting details which can't be seen directly by structre\ndf.info()","0cecef6f":"# Checking all the null and NaN values in dataset\nprint(df.isnull().sum().value_counts())","b912a561":"#Columns Details\ndf.columns","56e2d53f":"# Removing useless coloumns\ndf.drop(['emp_title', 'desc', 'zip_code', 'url', 'title'], axis=1, inplace=True)","6a8a58c5":"# Basic details about loan\nprint(df['loan_amnt'].describe())\nprint('----------------------------------------------------------------------------------------------------------')\nprint(df['funded_amnt'].describe())","a8f7957c":"fig, ax = plt.subplots(1, 2, figsize=(16,5))\n\n\nloan_amount = df[\"loan_amnt\"].values\nfunded_amount = df[\"funded_amnt\"].values\n\nsns.distplot(loan_amount, ax=ax[0], color=\"#c42d1f\")\nax[0].set_title(\"Requested amount by the borrower\", fontsize=16)\nsns.distplot(funded_amount, ax=ax[1], color=\"#1F8A3F\")\nax[1].set_title(\"Amount Funded\", fontsize=16)","55bb59a1":"# intrest rate distribution\ndf['int_round'] = df['int_rate'].round(0).astype(int)\n\nplt.figure(figsize = (10,8))\n\n#Exploring the Int_rate\nplt.subplot(211)\ng = sns.distplot(np.log(df[\"int_rate\"]))\ng.set_xlabel(\"\", fontsize=12)\ng.set_ylabel(\"Distribuition\", fontsize=12)\ng.set_title(\"Int Rate Log distribuition\", fontsize=20)\n\nplt.show()","fabe4263":"# Getting info about \nprint('Types:\\t', df[\"loan_status\"].unique())\nprint('----------------------------------------------------------------------------------------------------------\\n')\nprint('Distribution:\\n\\n',df[\"loan_status\"].describe())\nprint('----------------------------------------------------------------------------------------------------------\\n')\nprint('No. of bad loans present:\\t',df.loan_status.str.contains(r'Charged Off').sum())\nprint('Percentage of bad loans:\\t',(df.loan_status.str.contains(r'Charged Off').sum()\/39717)*100)","cd386f45":"#correlation matrix\ndf_correlations = df.corr()\n# f, ax = plt.subplots(figsize=(12, 10))\n# sns.heatmap(corrmat, vmax=.8, square=True);\n\n\n\ntrace = go.Heatmap(z=df_correlations.values,\n                   x=df_correlations.columns,\n                   y=df_correlations.columns,\n                  colorscale=[[0.0, 'rgb(165,0,38)'], \n                              [0.1111111111111111, 'rgb(215,48,39)'], \n                              [0.2222222222222222, 'rgb(244,109,67)'], \n                              [0.3333333333333333, 'rgb(253,174,97)'], \n                              [0.4444444444444444, 'rgb(254,224,144)'], \n                              [0.5555555555555556, 'rgb(224,243,248)'], \n                              [0.6666666666666666, 'rgb(171,217,233)'], \n                              [0.7777777777777778, 'rgb(116,173,209)'], \n                              [0.8888888888888888, 'rgb(69,117,180)'], \n                              [1.0, 'rgb(49,54,149)']],\n            colorbar = dict(\n            title = 'Level of Correlation',\n            titleside = 'top',\n            tickmode = 'array',\n            tickvals = [-0.52,0.2,0.95],\n            ticktext = ['Negative Correlation','Low Correlation','Positive Correlation'],\n            ticks = 'outside'\n        )\n                  )\n\n\nlayout = {\"title\": \"Correlation Heatmap\"}\nsns.heatmap(df_correlations, vmax=.8, square=True);\n# data=[trace]\n\n# fig = dict(data=data, layout=layout)\n# iplot(fig, filename='labelled-heatmap')","455494ae":"df['Default_Binary'] = int(0)\nfor index, value in df.loan_status.iteritems():\n    if value == 'Default':\n        df.set_value(index,'Default_Binary',int(1))\n    if value == 'Charged Off':\n        df.set_value(index, 'Default_Binary',int(1))\n    if value == 'Late (31-120 days)':\n        df.set_value(index, 'Default_Binary',int(1))    \n    if value == 'Late (16-30 days)':\n        df.set_value(index, 'Default_Binary',int(1))\n    if value == 'Does not meet the credit policy. Status:Charged Off':\n        df.set_value(index, 'Default_Binary',int(1))","ac6ecee3":"df['Purpose_Cat'] = int(0) \nfor index, value in df.purpose.iteritems():\n    if value == 'debt_consolidation':\n        df.set_value(index,'Purpose_Cat',int(1))\n    if value == 'credit_card':\n        df.set_value(index, 'Purpose_Cat',int(2))\n    if value == 'home_improvement':\n        df.set_value(index, 'Purpose_Cat',int(3))    \n    if value == 'other':\n        df.set_value(index, 'Purpose_Cat',int(4))    \n    if value == 'major_purchase':\n        df.set_value(index,'Purpose_Cat',int(5))\n    if value == 'small_business':\n        df.set_value(index, 'Purpose_Cat',int(6))\n    if value == 'car':\n        df.set_value(index, 'Purpose_Cat',int(7))    \n    if value == 'medical':\n        df.set_value(index, 'Purpose_Cat',int(8))   \n    if value == 'moving':\n        df.set_value(index, 'Purpose_Cat',int(9))    \n    if value == 'vacation':\n        df.set_value(index,'Purpose_Cat',int(10))\n    if value == 'house':\n        df.set_value(index, 'Purpose_Cat',int(11))\n    if value == 'wedding':\n        df.set_value(index, 'Purpose_Cat',int(12))    \n    if value == 'renewable_energy':\n        df.set_value(index, 'Purpose_Cat',int(13))     \n    if value == 'educational':\n        df.set_value(index, 'Purpose_Cat',int(14))","ee6b036d":"df_train = pd.get_dummies(df.purpose).astype(int)\n\ndf_train.columns = ['debt_consolidation','credit_card','home_improvement',\n                     'other','major_purchase','small_business','car','medical',\n                     'moving','vacation','house','wedding','renewable_energy','educational']\n\n# Also add the target column we created at first\ndf_train['Default_Binary'] = df['Default_Binary']\ndf_train.head()","be5ac7f3":"x = np.array(df.int_rate.values).reshape(-1,1) \nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf['int_rate_scaled'] = pd.DataFrame(x_scaled)\nprint (df.int_rate_scaled[0:5])","3e90d678":"x = np.array(df.funded_amnt.values).reshape(-1,1) \nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf['funded_amnt_scaled'] = pd.DataFrame(x_scaled)\nprint (df.funded_amnt_scaled[0:5])","7ec97eba":"df_train['int_rate_scaled'] = df['int_rate_scaled']\ndf_train['funded_amnt_scaled'] = df['funded_amnt_scaled']","da866282":"training_set = df_train[0:23000] # Train on first 500k rows\ntesting_set = df_train[23001:30000] # Test on next 400k rows\nprediction_set = df_train[30001:] # Predict on final ~87k rows\n\nCOLUMNS = ['debt_consolidation','credit_card','home_improvement',\n           'other','major_purchase','small_business','car','medical',\n           'moving','vacation','house','wedding','renewable_energy','educational',\n           'funded_amnt_scaled','int_rate_scaled','Default_Binary']   \n\nFEATURES = ['debt_consolidation','credit_card','home_improvement',\n           'other','major_purchase','small_business','car','medical',\n           'moving','vacation','house','wedding','renewable_energy','educational',\n           'funded_amnt_scaled','int_rate_scaled'] \n\n#CONTINUOUS_COLUMNS = ['funded_amnt_scaled','int_rate_scaled'] \n#CATEGORICAL_COLUMNS = ['Purpose_Cat']\n\nLABEL = 'Default_Binary'\n\ndef input_fn(data_set):\n    ### Simple Version ######\n    feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES} # Working method for continous data DO NOT DELETE \n    labels = tf.constant(data_set[LABEL].values)\n    return feature_cols, labels","bf164d08":"learning_rate = 0.01\nfeature_cols = [tf.contrib.layers.real_valued_column(k)\n              for k in FEATURES]\n#config = tf.contrib.learn.RunConfig(keep_checkpoint_max=1) ######## DO NOT DELETE\nregressor = tf.contrib.learn.DNNRegressor(\n                    feature_columns=feature_cols,\n                    optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate),\n                    hidden_units=[10, 20, 10], )\n\nregressor.fit(input_fn=lambda: input_fn(training_set), steps=500)","75bad505":"# Score accuracy\nev = regressor.evaluate(input_fn=lambda: input_fn(testing_set), steps=1)\nloss_score = ev[\"loss\"]\nprint(\"Loss: {0:f}\".format(loss_score))","22a36436":"y = regressor.predict(input_fn=lambda: input_fn(prediction_set))\npredictions = list(itertools.islice(y, 87378))\n","9ab28402":"plt.plot(prediction_set.int_rate_scaled, predictions, 'ro')\nplt.ylabel(\"Model Prediction Value\")\nplt.xlabel(\"Interest Rate of Loan (Scaled between 0-1)\")\nplt.show()","cdedc8b6":"plt.plot(prediction_set.funded_amnt_scaled, predictions, 'ro')\nplt.ylabel(\"Model Prediction Value\")\nplt.xlabel(\"Funded Amount of Loan (Scaled between 0-1)\")\nplt.show()","6aaaef3a":"## Observations\n- Now we have to check the relation b\/w the the requested amounts and the people who are been allocated these amounts\n- Relation b\/w the interest rates","0f692262":"## Observations\n- We have figured out the relation b\/w the reqursted amount and the funded amount\n- Now we have to check the relation b\/w loan status and the funded amount by the company","0a0866bf":"## Importing Libraries\nContains some basic data preprocessing and visulization libraries.","98cbfe80":"## Observations\n- By analyzing the heatmap we can see the garbage\/insignificiant data which would be removed in establishment of a neural network","4032f45f":"## Observation\n- Now we have to observe the similarities beetween the bad loans.\n\n\n## Factors causing bad loans\n- Low credit score\n- High debt to income\n- Low annual income \n- High interest rates","bc646000":"## Importing Dataset","125c3ab9":"# Neural Network\nThe things observed by the visulization will be used here"}}