{"cell_type":{"c67da184":"code","cd934a85":"code","157c01c7":"code","6a2cb3d3":"code","204f71e9":"code","cacdac61":"code","c9ac6610":"code","bb463f7c":"code","a595165a":"code","7ae595af":"code","4d280b69":"code","63febe05":"code","b95b9beb":"code","c761ae61":"markdown","b7887c2e":"markdown","bb3e95a0":"markdown","cd493fa7":"markdown","e128e045":"markdown","cf0d36e1":"markdown"},"source":{"c67da184":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport math\nimport keras\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.layers import Dense, Activation\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n%matplotlib inline","cd934a85":"'''Pulling the photos from folders with their paths'''\n\npath_0 = []\ntrain_path_0 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/0\/\"                #zero\nfor path in os.listdir(train_path_0):\n    if '.JPG' in path:\n        path_0.append(os.path.join(train_path_0, path))\n        \npath_1 = []\ntrain_path_1 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/1\/\"                #one\nfor path in os.listdir(train_path_1):\n    if '.JPG' in path:\n        path_1.append(os.path.join(train_path_1, path))\n        \npath_2 = []\ntrain_path_2 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/2\/\"                #two\nfor path in os.listdir(train_path_2):\n    if '.JPG' in path:\n        path_2.append(os.path.join(train_path_2, path))\n\npath_3 = []\ntrain_path_3 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/3\/\"                #three\nfor path in os.listdir(train_path_3):\n    if '.JPG' in path:\n        path_3.append(os.path.join(train_path_3, path))\n        \npath_4 = []\ntrain_path_4 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/4\/\"                #four\nfor path in os.listdir(train_path_4):\n    if '.JPG' in path:\n         path_4.append(os.path.join(train_path_4, path))\n        \npath_5 = []\ntrain_path_5 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/5\/\"                #five\nfor path in os.listdir(train_path_5):\n    if '.JPG' in path:\n        path_5.append(os.path.join(train_path_5, path))\n\nprint(\"Number of pics for each digit:\")\nprint((len(path_0), len(path_1), len(path_2), len(path_3), len(path_4), len(path_5)))\n\nprint(\"Total pics in the dataset: \" + str(len(path_0) + len(path_1) + len(path_2) + len(path_3) + len(path_4) + len(path_5)))","157c01c7":"'''Load training set'''\n\n'''total pics in training set =  1237\n    training_set = 1230 --- 205 for each digit'''\n\ntrain_set_orig = np.zeros((1230, 64, 64, 3), dtype='float32')\n\nfor i in range(205):\n    image = Image.open(path_0[i])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n    \nfor i in range(205, 410):                                                           #loading \"one\"\n    image = Image.open(path_1[i - 205])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(410, 615):                                                           #loading \"two\"\n    image = Image.open(path_2[i - 410])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(615, 820):                                                           #loading \"three\"\n    image = Image.open(path_3[i - 615])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n    \nfor i in range(820, 1025):                                                           #loading \"four\"\n    image = Image.open(path_4[i - 820])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(1025, 1230):                                                          #loading \"five\"\n    image = Image.open(path_5[i - 1025])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)","6a2cb3d3":"'''Labelling the training set having 6-dimensional vector of o's and 1's with 1 where index  = digit and zero otherwise'''\n\ntrain_y_ = np.zeros((1230, 6))\n\nfor i in range(205):                                                               #labelling \"zero\"\n    train_y_[i, 0] = 1\n\nfor i in range(205, 410):                                                          #labelling \"one\"\n    train_y_[i, 1] = 1\n        \nfor i in range(410, 615):                                                          #labelling \"two\"\n    train_y_[i, 2] = 1\n    \nfor i in range(615, 820):                                                          #labelling \"three\"\n    train_y_[i, 3] = 1\n    \nfor i in range(820, 1025):                                                          #labelling \"four\"\n    train_y_[i, 4] = 1\n    \nfor i in range(1025, 1230):                                                         #labelling \"five\"\n    train_y_[i, 5] = 1\n","204f71e9":"m_train = train_set_orig.shape[0]\nnum_px = train_set_orig.shape[1]\n\nprint(\"SUMMARY OF DATASET:\")\nprint (\"Number of training examples: m_train = \" + str(m_train))\nprint (\"Height\/Width of each image: num_px = \" + str(num_px))\nprint (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\nprint (\"train_set_x shape: \" + str(train_set_orig.shape))\nprint (\"train_set_y shape: \" + str(train_y_.shape))","cacdac61":"''''Suffling training set pics'''\n\nnp.random.seed(0)\nm_train = train_set_orig.shape[0]\npermutation = list(np.random.permutation(m_train))\ntrain_set_x = train_set_orig[permutation, :]\ntrain_y = train_y_[permutation, :]","c9ac6610":"train_x = train_set_x.reshape(1230,-1)\nprint (\"train_set_x_flatten shape: \" + str(train_x.shape))\nprint (\"train_set_y shape: \" + str(train_y.shape))","bb463f7c":"'''Standardizing dataset'''\n\ntrain_x = train_x \/255","a595165a":"'''Example of an image'''\n\nindex = 20\nplt.imshow(np.uint8(train_set_x[index]), interpolation='nearest')\nplt.show()\nprint(np.where(train_y[index] == 1)[0])","7ae595af":"'''Making sequential deep learning model using keras\n   input layer: shape -- ((64, 64, 3), number of examples)\n   layer 1: -- Conv2D with 50 filters (3, 3) and stride of 1, with \"relu\" activation, + max pooling with (2, 2)\n   layer 2: -- Conv2D with 75 filters (3, 3) and stride of 1, with \"relu\" activation, + max pooling with (2, 2)\n   layer 3: -- Conv2D with 100 filters (3, 3) and stride of 1, with \"relu\" activation,+ max pooling with (2, 2)\n   layer 4: -- Fully connected with 1024 units size with relu activation\n   layer 5: -- Fully connected with 1024 units size with relu activation\n   layer 6: -- Fully connected with 6 units size with softmax activation (output layer)'''\n\nmodel = Sequential()\n\nmodel.add(layers.Conv2D(input_shape = (64, 64, 3), filters = 50, strides = 1,\n                        kernel_size = (3, 3), padding = \"same\", activation = \"relu\"))   #layer 1\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2), padding = \"same\"))\n\nmodel.add(layers.Conv2D(filters = 75, strides = 1,\n                        kernel_size = (3, 3), padding = \"same\", activation = \"relu\"))   #layer 2\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2), padding = \"same\"))\n\nmodel.add(layers.Conv2D(filters = 100, strides = 1,\n                        kernel_size = (3, 3), padding = \"same\", activation = \"relu\"))   #layer 3\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2), padding = \"same\"))\n\nmodel.add(layers.Flatten())\nmodel.add(Dense(units = 1024, activation = \"relu\"))                                      #layer 4\nmodel.add(layers.Dropout(0.2))\nmodel.add(Dense(units = 1024, activation = \"relu\"))                                      #layer 5\nmodel.add(layers.Dropout(0.2))\nmodel.add(Dense(units = 6, activation = \"softmax\"))                                      #output layer\n\n'''using \"Adam\" optimizer'''\n\nopt = keras.optimizers.Adam(learning_rate = 0.0001)\n\n'''Compiling the model using the \"categorical_crossentropy\" loss function'''\n\nmodel.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n\nmodel.summary()","4d280b69":"'''Fitting the model using training set'''\n\nlanguage = model.fit(train_set_x, train_y, epochs = 20, batch_size = 32, validation_split = 0.05)","63febe05":"print(\"Training set accurarcy: \" + str((language.history[\"accuracy\"])[-1]*100) + \"%\")\nprint(\"Validation set accurarcy: \" + str((language.history[\"val_accuracy\"])[-1]*100) + \"%\")","b95b9beb":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1,2,1)\n\nplt.plot(language.history[\"accuracy\"], label = \"training set\")\nplt.plot(language.history[\"val_accuracy\"], label = \"validation set\")\nplt.title(\"accuracy versus epochs curve\")\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2)\n\nplt.plot(language.history[\"loss\"], label = \"training set\")\nplt.plot(language.history[\"val_loss\"], label = \"validation set\")\nplt.title(\"loss versus epochs curve\")\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend(loc='best')\n\nplt.show()","c761ae61":"# *Reading images data from the folder named \"hand-sign-language-digit-dataset-for-0-5\"*","b7887c2e":"# *Keras Model*","bb3e95a0":"# *Visualizing an image from training data*","cd493fa7":"# *Preprocessing training data*","e128e045":"# *Train\/Validation set accuracy*","cf0d36e1":"# *Learning curves of the model*"}}