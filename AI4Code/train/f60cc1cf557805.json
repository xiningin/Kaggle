{"cell_type":{"28e74439":"code","c73f011b":"code","9c992d9c":"code","d788ea88":"code","bdcc40bf":"code","265e1a36":"code","5c255081":"code","4d416895":"code","c08b314a":"code","852ec11f":"code","6b92a70d":"code","2367ad97":"code","395f31ac":"code","e3e778be":"code","8276f1b9":"code","0e414fa4":"code","fca24473":"code","932c8ea3":"code","ce997ae2":"code","40a50698":"code","5b1e0c74":"code","1eb6c8f4":"code","b2fbda58":"code","77d64455":"code","4b29291d":"code","4149c8db":"code","fc08a24a":"code","002fdb78":"code","0d62e9ac":"code","1da02d80":"code","389271da":"code","7e936c39":"code","d53e6ef1":"code","3e5b215f":"code","9d67a00d":"code","ab7ac52b":"code","0e740465":"code","28832e7a":"code","3c84df1f":"code","f7c5fa06":"code","7b308bca":"code","70763407":"code","7894d1b1":"code","d2d67b73":"code","e0bd86c0":"markdown","5379807c":"markdown","36b6b50a":"markdown","53cbbaa3":"markdown","1781bd96":"markdown","462c361b":"markdown","b3879364":"markdown","c5147c2e":"markdown","877f4d0b":"markdown","51b4ffec":"markdown","d6fd79f6":"markdown","fc6f5893":"markdown","817d59b8":"markdown","079b1c13":"markdown","6927407f":"markdown","d4fa5984":"markdown","845cfacb":"markdown","8d0994f5":"markdown","ddb83088":"markdown","ca037368":"markdown","d20d111a":"markdown","bdd40d5a":"markdown","c0eae5a1":"markdown","70a7b25d":"markdown","ea4ff2ad":"markdown","15c51c8a":"markdown","f77a1eda":"markdown","99bc8b67":"markdown","7a297261":"markdown","4111ab6e":"markdown","d75171f0":"markdown","a9c89dc3":"markdown","6bde6c7e":"markdown","192b2073":"markdown","8c3721c1":"markdown","0cd70af5":"markdown","5a1bf96a":"markdown","0009396b":"markdown"},"source":{"28e74439":"#import all packages\nimport numpy as np \nimport pandas as pd \n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n\nimport seaborn as sns\nimport scikitplot as skplt\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import RobustScaler\nfrom imblearn.under_sampling import RandomUnderSampler\n\nfrom imblearn.under_sampling import InstanceHardnessThreshold\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import make_pipeline\nfrom imblearn.metrics import specificity_score\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import recall_score, roc_auc_score, roc_curve, accuracy_score, precision_score, make_scorer\n\n\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout\nfrom keras.layers.core import Dense\nfrom keras.optimizers import Adamax\nfrom keras.metrics import categorical_crossentropy","c73f011b":"#read data and take first look at it\ndf = pd.read_csv('..\/input\/creditcard.csv')\ndf.head()","9c992d9c":"#get information provided by pandas\ndf.info()","d788ea88":"df.describe()","bdcc40bf":"# graph to show imbalance of the dataset\n\nsns.countplot(df[\"Class\"])\nplt.title(\"Fraud==1 vs. Non fraud==0\")\nplt.show()","265e1a36":"#plot \"Amount\" column\n\nfig, ax = plt.subplots(1,3, figsize=(20, 8))\n\ndf['Amount'].plot(ax=ax[0])\nax[0].set_title(\"Amount per Transaction\")\nax[0].set_xlabel(\"Transaction Number\")\nax[0].set_ylabel(\"Amount in Dollar\")\n\ndf['Amount'].plot.hist(ax=ax[1], bins=200, color=\"r\")\nax[1].set_title(\"Distribution of Amounts\")\nax[1].set_xlabel(\"Amount in Dollar\")\n\ndf['Amount'].plot.hist(ax=ax[2], bins=200, color=\"g\")\nax[2].set_title(\"Distribution of Amounts closup\")\nax[2].set_xlabel(\"Amount in Dollar\")\nax[2].set_ylim([0,50])\nplt.show()","5c255081":"#plot \"Time\" distribution\n\ndf[\"Time\"].plot.hist(bins=50)\nplt.title(\"Distribution of time since first transaction\")\nplt.xlabel(\"Time in seconds\")\nplt.axvline(x=12500, color='r')\nplt.axvline(x=12500+86400, color='r')\nplt.show()","4d416895":"#check the distributions of the pca-features for fraud and non fraud and compare them\n\npca_features = df.iloc[0:-1,0:28].columns\nplt.figure(figsize=(35,30*4))\ngrid = gridspec.GridSpec(28, 1)\nfor i, feat in enumerate(df[pca_features]):\n    ax = plt.subplot(grid[i])\n    sns.distplot(df[feat][df.Class == 1], bins=200)\n    sns.distplot(df[feat][df.Class == 0], bins=200)\n    ax.set_xlabel('')\n    ax.set_title('Feature : ' + str(feat))\nplt.show()","c08b314a":"# remove features where the distributions are for both classes are too similar\ndf = df.drop(['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8'], axis =1)","852ec11f":"# converting \"Time\" to a time period of one day from 0 to 86400 seconds\n\nsecond_day_indices = df[df[\"Time\"]>86400].index\ndf.loc[second_day_indices, \"Time\"] = df.loc[second_day_indices, \"Time\"] - 86400\n\nprint(\"Minimum time is now {}\".format(df[\"Time\"].min()))\nprint(\"Maximum time is now {}\".format(df[\"Time\"].max()))","6b92a70d":"# scale \"Time\" and \"Drop\", delete original columns\nrobust_scaler = RobustScaler()\n\ndf[\"time_scaled\"] = robust_scaler.fit_transform(df['Time'].values.reshape(-1,1))\ndf[\"amount_scaled\"] = robust_scaler.fit_transform(df[\"Amount\"].values.reshape(-1,1))\ndf.drop([\"Time\", \"Amount\"], inplace=True, axis=1)\ndf.head()","2367ad97":"# create feature and target dataset\nX = df.drop([\"Class\"], axis=1)\ny = df[\"Class\"]","395f31ac":"rus = RandomUnderSampler(random_state=42)\nX_ramdom_undersampled, y_random_undersampled = rus.fit_resample(X, y)\n\n\nsns.countplot(y_random_undersampled)\nplt.title(\"Distribution of Class for random undersampling\")\nplt.show()","e3e778be":"iht = InstanceHardnessThreshold(random_state=42, estimator=LogisticRegression(\n                                    solver='liblinear', multi_class='auto'))\nX_iht_undersampled, y_iht_undersampled = iht.fit_resample(X, y)\n\n\nsns.countplot(y_iht_undersampled)\nplt.title(\"Distribution of Class for IHT undersampling\")\nplt.show()","8276f1b9":"ros = RandomOverSampler(random_state=42)\nX_ramdom_oversampled, y_random_oversampled = ros.fit_resample(X, y)\n\n\nsns.countplot(y_random_oversampled)\nplt.title(\"Distribution of Class for random oversampling\")\nplt.show()","0e414fa4":"smote = SMOTE(random_state=42)\nX_smote_oversampled, y_smote_oversampled = smote.fit_resample(X, y)\n\n\nsns.countplot(y_smote_oversampled)\nplt.title(\"Distribution of Class for smote oversampling\")\nplt.show()","fca24473":"# splitting in training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","932c8ea3":"# make a first prediction with RandomForestClassifier\nclf_rf = RandomForestClassifier(n_estimators=10)\nclf_rf.fit(X_train, y_train)\nprediction = clf_rf.predict(X_test)","ce997ae2":"# print roc curve\ny_true = y_test\ny_probas = clf_rf.predict_proba(X_test)\nskplt.metrics.plot_roc(y_true, y_probas)\nplt.show()","40a50698":"#roc-auc-score\nroc_auc_score(y_true,y_probas[:,1])","5b1e0c74":"#print confusion matrix\nskplt.metrics.plot_confusion_matrix(y_true, prediction)\nplt.show()","1eb6c8f4":"#accuracy score\naccuracy_score(y_test, prediction)","b2fbda58":"#recall score\nrecall_score(y_test.values, prediction)","77d64455":"# precision-recall curve\nskplt.metrics.plot_precision_recall(y_test, y_probas)\nplt.show()","4b29291d":"# specificity score\nspecificity_score(y_test.values, prediction)","4149c8db":"# build custom scorer for finding best hyperparameters\ndef custom_score(y_true, y_pred):\n    \n    conf_matrix = confusion_matrix(y_true, y_pred)\n    #define measures\n    recall = 0.75 * recall_score(y_true, y_pred) \n    specificy = 0.25 * conf_matrix[0,0]\/conf_matrix[0,:].sum() \n    #punish low recall scores\n    if recall < 0.75:\n        recall -= 0.2\n    return recall + specificy \n    \n#initialize make_scorer\noptimized_score = make_scorer(custom_score)","fc08a24a":"clf_rf = RandomForestClassifier(n_estimators=10)\nrf_params = {\"max_depth\" : [5,7,10], 'criterion':['gini','entropy']}\n\nclf_lr = LogisticRegression(solver='liblinear')\nlr_params = {\"C\" : [0.001,0.01,0.1,1,10,100], \"warm_start\" :[True, False]}\n\nclf_gb = GradientBoostingClassifier()\ngb_params = {\"learning_rate\" : [0.001,0.01,0.1], 'criterion' : ['friedman_mse', 'mse']}\n\nclf_svc = SVC(gamma='scale', probability=True)\nsvc_params = {'kernel' : ['linear', 'poly', 'rbf'], \"C\" : [0.001,0.01,0.1,1,10,100]}","002fdb78":"# splitting in training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n\nX_train = X_train.values\ny_train = y_train.values\n    \ndef find_best_estimator(estimator, params):\n    gridsearch_cv = GridSearchCV(estimator, param_grid=params, cv=5, iid=False, scoring=optimized_score)\n\n    sss = StratifiedShuffleSplit(n_splits = 5, test_size = 0.2, random_state=42)\n\n    rus = RandomUnderSampler()\n    \n\n    recall_list = []\n    specificity_list = []\n    i=0\n    print(\"\")\n    print( type(estimator).__name__)\n    \n    for train_index, test_index in sss.split(X_train, y_train):\n        pipeline = make_pipeline(rus, gridsearch_cv)\n        model = pipeline.fit(X_train[train_index], y_train[train_index])\n        best_estimator = gridsearch_cv.best_estimator_\n        prediction = best_estimator.predict(X_train[test_index])\n\n        recall_list.append(recall_score(y_train[test_index], prediction))\n        specificity_list.append(specificity_score(y_train[test_index], prediction))\n        i=i+1\n        \n        print(\"Iteration {} out of 5 is finished\".format(i))\n      \n    print(\"\")\n    print(\"recall on X_train split in train and test: {}\".format(np.mean(recall_list)))\n    print(\"Specificy on X_train split in train and test: {}\".format(np.mean(specificity_list)))\n    return best_estimator  ","0d62e9ac":"best_est_gb = find_best_estimator(clf_gb, gb_params)\nbest_est_lr = find_best_estimator(clf_lr, lr_params)\nbest_est_rf = find_best_estimator(clf_rf, rf_params)\nbest_est_svc = find_best_estimator(clf_svc, svc_params)","1da02d80":"#change fond size for all plots\nplt.rcParams.update({'font.size': 16})","389271da":"# function to display all the metrics on the estimators\ndef evaluation_report(estimator):\n\n    prediction = estimator.predict(X_test)\n    prediction_proba = estimator.predict_proba(X_test)\n       \n    fig, ax = plt.subplots(1,3, figsize=(30, 8))\n\n    fig.suptitle('Evaluation report for '+type(estimator).__name__, fontsize=16)\n\n    skplt.metrics.plot_precision_recall(y_test, prediction_proba, ax=ax[0])\n    ax[0].set_title(\"Precision-recall-curve\")\n\n    skplt.metrics.plot_roc(y_test, prediction_proba, ax=ax[1])\n    ax[1].set_title(\"ROC-curve\")\n\n    skplt.metrics.plot_confusion_matrix(y_test, prediction, ax=ax[2])\n    ax[2].set_title(\"Confusion-matrix\")\n    plt.show()\n    print('The recall is {}'.format(recall_score(y_test.values, prediction)))\n    print('The specificity is {}'.format(specificity_score(y_test.values, prediction)))\n    print('The accuracy is {}'.format(accuracy_score(y_test, prediction)))\n    print('The AUC-score is {}'.format(roc_auc_score(y_test,prediction_proba[:,1])))","7e936c39":"evaluation_report(best_est_svc)","d53e6ef1":"evaluation_report(best_est_lr)","3e5b215f":"evaluation_report(best_est_gb)","9d67a00d":"evaluation_report(best_est_rf)","ab7ac52b":"# oversampling model with SMOTE\nX_smote_oversampled, y_smote_oversampled = SMOTE().fit_resample(X_train, y_train)\nn_inputs = X_smote_oversampled.shape[1]\n\noversample_model = Sequential([\n    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n    Dense(32, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dropout(0.5),    \n    Dense(2, activation='softmax')\n])\n\noversample_model.summary()\n\n","0e740465":"# compile model\noversample_model.compile(Adamax(lr=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","28832e7a":"# fit model\noversample_model.fit(X_smote_oversampled, y_smote_oversampled, validation_split=0.2, batch_size=25, epochs=15, shuffle=True, verbose=2)","3c84df1f":"# create same model with RandomUnderSampler\nX_rus_undersampled, y_rus_undersampled = RandomUnderSampler().fit_resample(X_train, y_train)\nn_inputs = X_rus_undersampled.shape[1]\n\nundersample_model = Sequential([\n    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n    Dense(32, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dropout(0.5),    \n    Dense(2, activation='softmax')\n])","f7c5fa06":"# compile model\nundersample_model.compile(Adamax(lr=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","7b308bca":"# fit model\nundersample_model.fit(X_rus_undersampled, y_rus_undersampled, validation_split=0.2, batch_size=25, epochs=15, shuffle=True, verbose=2)","70763407":"# the prediction and probas in the evaluation report have to be adjusted slightly\ndef evaluation_report_keras(estimator):\n\n    prediction = estimator.predict_classes(X_test, batch_size=200, verbose=0)\n    prediction_proba = estimator.predict(X_test, batch_size=200, verbose=0)\n       \n    fig, ax = plt.subplots(1,3, figsize=(30, 8))\n\n    \n    skplt.metrics.plot_precision_recall(y_test, prediction_proba, ax=ax[0])\n    ax[0].set_title(\"Precision-recall-curve\")\n\n    skplt.metrics.plot_roc(y_test, prediction_proba, ax=ax[1])\n    ax[1].set_title(\"ROC-curve\")\n\n    skplt.metrics.plot_confusion_matrix(y_test, prediction, ax=ax[2])\n    ax[2].set_title(\"Confusion-matrix\")\n    plt.show()\n    print('The recall is {}'.format(recall_score(y_test.values, prediction)))\n    print('The specificity is {}'.format(specificity_score(y_test.values, prediction)))\n    print('The accuracy is {}'.format(accuracy_score(y_test, prediction)))\n    print('The AUC-score is {}'.format(roc_auc_score(y_test,prediction_proba[:,1])))","7894d1b1":"# show evaluation report SMOTE-Keras-model\nevaluation_report_keras(oversample_model)","d2d67b73":"# show evaluation report RandomUnderSampler-Keras-model\nevaluation_report_keras(undersample_model)","e0bd86c0":"The metrics for the classification evaluation which are used are the roc-curve, confusion-matrix, accuracy, recall, roc-auc-score,  specificity and the precision-recall-curve. I choose the RandomForestClassifer without sampling to show an example of the metrics.","5379807c":"From this first overview we can retrieve a lot of information about feature extraction and how to start to treat the dataset.\n* there are no missing data\n* all columns are of a numeric type\n* the columns from V1 to V28 are the result of Dimensionality Reduction with Principal Component Analyisis, so scaling was already done (mean of nearly 0)\n* the columns time and amount have not been scaled\n* the column class (1==fraud, 0==non fraud) has a mean of 0.001727, which implies a small amount of frauds in the dataset\n* the max of \"Time\" is 172792 which is nearly equal to 172800, which is the sum of seconds of 2 days","36b6b50a":"**Prediction with keras**","53cbbaa3":"The precision-recall-curve shows us the tradeoff between finding all frauds(recall) and the accuracy of finding them(precision).","1781bd96":"1. To find the best algorithm I choose 4 to test them with the following parameters to test","462c361b":"Now we have mentioned four different sampling methods and seen the results. One could assume to use all of these for feeding the algorithms. But I also want to use cross-validation. The problem is that by using the sampling the test set will be affected because it is part of the sampling result. As we know the test set should be untouched. So the solution is to just sample the trainingset.","b3879364":"The most important metrics are the recall and the specificity. The recall is important because I want to find all fraudulent activities. In production this algorithm will only stop the transaction but further investigation will be done for every single as fraudulent labeled transaction. Thatswhy the specificity has to be good too, so that not many non fraudulent transactions labeled wrong which will reduce the cost of further investigations.\n\n**Testing algorithms**","c5147c2e":"**Introduction**\n\nThis is a notebook to find an algorithm to predict credit card frauds. The main focus is on the classification of an imbalanced dataset.","877f4d0b":"Now that all the estimators have a decent score on there test sets I can build an evaluation report for all of them with the metrics mentioned at the beginning and predicting on X_test.","51b4ffec":"Now I will use Keras with a simple neural network with dropouts to predict. First I will use the network with oversampling SMOTE and after that I will compare it with RandomUnderSampling.","d6fd79f6":"In the diagrams above for each feauture V1-V28 you can see the distribution of the values for the feature. There are two graphs in each diagram, one for each classe. So for every feature the two classes can be compared. If the distribution is too similar they are not useful for the algorithm because the feature should be different for both classes.","fc6f5893":"**Feature Transformation**","817d59b8":"**Metrics for evaluation**","079b1c13":"**Data Exploration**","6927407f":"The confusion matrix gives us the exact numbers of the false and true predicted transactions.","d4fa5984":"The accuracy score gives us the ratio of how many transactions where labeled right.","845cfacb":"First variant of oversampling is random oversampling which just randomly replicates the underrepresented class until both classes are equal.","8d0994f5":"**Detailed look into the finding of the best estimator for each classifier **","ddb83088":"The columns amount and time have to be scaled to be used with algorithms. For example for all algorithms which use the Euclidian distance as a measurement it makes a difference if the scale of the value is in a similar proportion. The choice falls on the RobustScaler from scikit learn because it is less prone against outliers like in the amount column.","ca037368":"The ROC-curve tells us how good the algorithm can distinguish between the two classes of frauds and non frauds. The bigger the area under the curve is the better.","d20d111a":"**Sampling and crossvalidation**","bdd40d5a":"The classes are very imbalanced. This is a problem when predicting because the algorithms to predict will \"learn\" on nearly only non fraudulent activities. This issue has to be treated for a good prediction.","c0eae5a1":"When looking at the metrics one can see that they are all close together. For example if the specificity is 0.95 and the recall 0.93 that means that 93 % of the frauds are detected and 5 % of the non fraudulent transaction are classified as fraud, which is still a high number. So around 25 transactions are labeled as fraud for further investigation and only one out of them is a real fraud.","70a7b25d":"1. StratifiedShuffleSplit.split  of X_train and y_train creates 5 train and test sets (X_test stays untouched during the whole process)\n2. On each of these train sets RandomUnderSampling and GridSearchCV fitting is done to get the best estimator\n3. On each of the corresponding test sets the best estimator is tested with the scores\n4. The average score of all the best estimator results is calculated","ea4ff2ad":"A second method called \"Instance hardness threshold\" can be used for undersampling. Here a classifier is trained on the data and the data with lesser probabilities are not in the sample. The result looks similar but with another less random choice of the non fraudulent data for the sample.","15c51c8a":"**Oversampling**","f77a1eda":"The second variant of undersampling is \"Synthetic Minority Over-sampling Technique\" that generates new samples of the minority class which are close to the original samples using K-Nearest-Neighbors.","99bc8b67":"The specificity gives us the ratio of correct classification of non fraudulent transactions","7a297261":"The recall score gives us the ratio of how many of the fraudulent transactions where found","4111ab6e":" I want to use GridSearchCV and to make it find the best algorithm I created  a custom scorer which takes recall and specificity into considiration when checking for the ideal parameters. After finding the best estimator for the classifier algorithm this estimator will be evaluated with the other metrics on the test set.","d75171f0":"**Undersampling**","a9c89dc3":"**Methods of sampling **\n\nThe motivation for sampling is to give the classifier a better ratio of fraudulent activity when it is training, so it will not be trained only on non fraudulent activity and will not only predict these.","6bde6c7e":"* Due to computational limitations only RandomUnderSampling as sampling method will be used\n* training, validation and sampling will be done only on X_train to keep X_test untouched before testing\n* StratifiedShuffleSplit is used for cross validation and sampling is done during cross validation\n* the score on which GridSearchCV decides the best scorer is the custom scorer shown in the metrics\n* sampling is done during cross validation.","192b2073":"The roc-auc-score is the numeric representation of the area under the roc-curve with 1 as the perfect score.","8c3721c1":"**Conclusion**\n\nAstonishingly undersampling with ca. 750 and oversampling with 450,000 transactions gave nearly the same result in the neural network. The specificity for the neural network is sligthly better with SMOTE but it is very close. In comparison to the other non neural network classifiers the specificity is much better but the important recall is lower. For further investigation with more computing power the oversampling methods could be investigated in more detail and other classifiers and neural networks could be used.","0cd70af5":"The distribution of time is time a cycle of days with 86400 seconds. A random period of a day is marked with red lines.","5a1bf96a":"The distribution of the amount is highly skewed with most of the transaction under 5000.","0009396b":"The first method is called random undersampling. This means to change the data to an equal (50\/50) distribution of classes by randomly selecting as many non fraudulent transactions as fraudulent and put them in one dataset."}}