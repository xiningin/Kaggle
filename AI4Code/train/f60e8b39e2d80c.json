{"cell_type":{"09cb1beb":"code","4f58ba73":"code","ff611437":"code","75f79c97":"code","d3eed25c":"code","4741647d":"code","d0eb8435":"code","368f6968":"code","1d7f620b":"code","6daf1fe2":"code","eba16c77":"code","02cf8022":"markdown","84e3cf74":"markdown","bdfd1b7f":"markdown","27385bdc":"markdown","7d024ae6":"markdown","644644ab":"markdown","9eff3b7a":"markdown","64336b66":"markdown","e9f5adf0":"markdown","9142ebb5":"markdown","cc846f5e":"markdown","0c94f735":"markdown"},"source":{"09cb1beb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4f58ba73":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ff611437":"from __future__ import print_function\nimport numpy as np\nimport pandas as pd\nfrom scipy import linalg\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import confusion_matrix\nimport keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.utils import plot_model\nimport matplotlib.pyplot as plt","75f79c97":"#------------------------------------------------------------------------------\n# UNPACKING THE DATA FILES\n#------------------------------------------------------------------------------ \nx_train = np.load('\/kaggle\/input\/cifar10-comp\/train_images.npy')\nx_train = np.reshape(x_train,(50000,32,32,3))\ny_train = pd.read_csv('\/kaggle\/input\/cifar10-comp\/train_labels.csv')\ny_train = pd.Series(y_train['Category'])\n# print the first 10 labels in y_train\ny_train.head(10)","d3eed25c":"#------------------------------------------------------------------------------\n# DATA PREPARATION\n#------------------------------------------------------------------------------ \nlb=LabelBinarizer()\ny_train=lb.fit_transform(y_train)\n# Set aside the test and validation set\nx_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2)\nx_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2)\n# Standarisation\nnormalizer = keras.preprocessing.image.ImageDataGenerator(featurewise_center=True, \n    featurewise_std_normalization=True)\nnormalizer.fit(x_train)\nnormalizer.fit(x_val)","4741647d":"#------------------------------------------------------------------------------\n# CREATING THE CNN\n#------------------------------------------------------------------------------\nnclasses = 10\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',activation='relu',input_shape=(32,32,3) ))\nmodel.add(Conv2D(64, (3, 3), activation='relu') )\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu') )\nmodel.add(Conv2D(256, (3, 3), activation='relu') )\nmodel.add(MaxPooling2D(pool_size=(2, 2)) )\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nclasses, activation='softmax'))\n\nopt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)","d0eb8435":"#------------------------------------------------------------------------------\n# TRAINING THE CNN ON THE TRAIN\/VALIDATION DATA\n#------------------------------------------------------------------------------\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\nhistory = model.fit(x_train, y_train,\n              batch_size=128,\n              epochs=100,\n              validation_data=(x_val, y_val),\n              shuffle=True)","368f6968":"#------------------------------------------------------------------------------\n# TESTING THE CNN ON THE TEST DATA\n#------------------------------------------------------------------------------\n\n# Normalizing test data\nnormalizer.fit(x_test)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n\npred = model.predict(x_test,verbose=1) \npred_labels = lb.classes_[np.argmax(pred,axis=1)]   \nlabels = lb.classes_[np.argmax(y_test,axis=1)]  ","1d7f620b":"# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","6daf1fe2":"# Check the model behavior for the first 10 images\nfor i in range(0,10): \n    print(pred_labels[i]==labels[i])\n# Check the number of correct predictions\ncounter = 0\nn_images = 10000\nfor i in range(0,n_images):\n    cond = pred_labels[i]==labels[i]\n    if cond:\n        counter = counter + 1\nprint('Percentage of correct predictions:', counter\/n_images)","eba16c77":"# Compute the confusion matrix\ncm = confusion_matrix(labels, pred_labels)\nprint(cm)","02cf8022":"**Overview of Network Architecture**\n\nThe Convolutional Neural Network (CNN) architecture was chosen for this project, given its proven capabilities of dealing with image structures. As the input layer of neurons, the CNN takes the channel features from the images in the dataset, and learns enhanced representations of these features by applying the hidden convolution and pooling layers. The output layer contains a prediction of the classification label for the image.\n\nIn order to build the CNN, Keras (https:\/\/keras.io) deep learning library in Python was utilised. Keras uses Tensorflow on the backend and enables a higher level API for the development of deep neural networks, where the programmer adds one layer at a time, defining its parameters. For CNNs, we can define convolution and polling layers by specifying the number of output neurons and the kernel size for the former, and the pool filter size for the latter. These parameters are tuned to match the structure of the images. First, we will import the required packages:","84e3cf74":"The confusion matrix can also be generated by means of a scikit-learn procedure, and by inspecting it, we can better understand how the neural network is doing on the classification task. The confusion matrix encodes the number of times that the prediction for one class occurred in other classes. For this project\u2019s CNN, the confusion matrix on the test set was:","bdfd1b7f":"**Data pre-processing**\n\nThe label data is a nominal column that categorises the images from the dataset in 1 out of 10 categories. Each label contains the name of the category, i.e.: \u2019airplane\u2019, \u2019frog\u2019, etc. The sklearn library in Python contains a function called LabelBinarizer(), which is applied for the transformation of nominal categories into one-hot encoding of the labels, creating 10-dimensional vectors in order to represent the 10 classes.\n\nThe image features were standarised in order to improve the consistency of the input data. The input mean was set to 0 over the dataset, and the inputs were divided by the standard deviation of the dataset. 20% of the data was set aside for validation purposes.","27385bdc":"**Evaluation**\n\nTo evaluate the CNN, a couple of metrics were utilised: the accuracy of the model on the test data, the confusion matrix generated from the predicted labels vs real labels, and a comparison of the accuracy of the neural network model with a support vector machine applied to the same classification problem.\n\nIn order to evaluate the accuracy of the model on the test data, the test data labels were compared to the model\u2019s predictions. The number of right predictions was divided by the number of data points in the test set.\n\nThe support vector machine was developed with the scikit-learn library in python. The functions from this library accept 2-dimensional numpy arrays as inputs, and thus for this model, the shape of the input had to be modified. Instead of using (32,32,3) tensors, each image for the SVM model has the 1D shape (3072,1,1), in which the data is stored in row-major format, and so the first 1024 pixels correspond to the first rgb colour, and so forth. The data in this format can be readily downloaded from Alex Krizhevsky\u2019s public page: https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html","7d024ae6":"**The Selected Problem**\n\nThis is a classic image recognition project, where a system is trained to predict the category of a given image. The dataset contains 60000 (50000 training and 10000 test) images where each image belongs to 1 out of 10 possible categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. There is no overlap between categories, therefore each image will be categorised by one and only one label. \n\nOnce trained, this system can be used for applications such as enabling the search for pictures on a cellphone photo album by specifying the category, or even for the generation of security questions for detecting non-human activity on sensible web form submissions.\n\nEach data point from the CIFAR10 dataset contains a 32x32 image and a class label. Each image is represented by a 32x32x3 tensor feature where each feature is a pixel channel value. The collection of features across all image pixels and rgb colours is part of one row in the dataset. Let us take a look at the data files from the directory:","644644ab":"**Model training**\n\nIn order to tune the parameters, the number of epochs was initially set to 10, so that comparisons of different arrangements could be achieved within a couple of minutes. Initially, the model was trained with 2 convolution layers and a polling layer. The validation accuracy was 0.4715 for that configuration after 10 epochs, which is not bad, considering that a random classifier would have an accuracy of about 0.1.\n\nThe number of layers was then increased to 8 and the network followed the pattern: \u2019convolution\u2019, \u2019convolution\u2019, \u2019pool\u2019, with dropout indexes in between. In order to tune the number of output neurons of the convolution layers, different combinations of multiples of 32 were tested, thus respecting the structure of the images. The arrangement of neurons that achieved the best validation accuracy after training on 10 epochs was when 32, 64, 128 and 256 was set to each convolution layer.\n\nthe dropout combination of 0.1,0.1,0.2 was the value that rendered the highest validation accuracy. However, the combination 0.25,0.25,0.5 indicated a better fit when the system was let run for more epochs. In fact, for 100 epochs, the former combination exhibited a validation accuracy of 0.5855 vs 0.9725 of training accuracy, while the latter obtained 0.6279 and 0.8781 for validation and training, respectively.","9eff3b7a":"**Results**\n\nThe neural network was trained for 100 epochs, and for each epoch, the training and validation accuracy indexes were recorded. the figure below shows the evolution of those accuracy indexes throughout the epochs of the training process:","64336b66":"Since the main diagonal of the confusion matrix exhibited the highest values, we can conclude that the majority of predictions of each category was correctly conveyed by the network, which confirms the accuracy level obtained for the tests. Some interesting patterns can also be noted from the confusion matrix. As indicated by the large factor in positions (9,2) and (10,2), we can see that many ships and trucks were wrongly classified as automobiles. On the other hand, automobiles were classified correctly most of the times. This pattern indicates a tendency of the CNN for gathering transport machines together and labelling them as automobiles.\n\nThe category with the lowest number of correct predictions was the cat. It was largely confused with the other animals on the list, specially the deer and the dog. In order to correct these confusions in the future, it would be a good idea to train the CNN with more hidden layers, so that more details are captured in the image features.","e9f5adf0":"In order to finally compute the class scores, a fully connected layer is used. The Keras command for building fully connected layers is called Dense, and it takes as arguments the number of possible output classes (10 for this project), and an optional activation function. In this case the softmax activation function was chosen, given its satisfactory performance with AlexNet.\n\nThe optimization algorithm chosen for this project was RSMprop. It combines the power of SGD for dealing with mini-batches with the efficiency of rprop, which takes adaptive steps towards the minimum just by looking at the gradient signs. Therefore, the batch size must be specified and tuned. Cross-entropy was the chosen loss function, since it applies well to binary classification problems.","9142ebb5":"For the first convolution layer of the network, an expected input shape can be specified, and it must match the tensor structure of the input image. This specific project requires the input shape to be (32,32,3). Dropout percentages can also be defined within layers and tuned to prevent overfitting and achieve optimum performance. However, high dropout values can lead to slower convergence. The ReLU activation function was applied together with the convolution layers.","cc846f5e":"As we can see, the validation accuracy attains a plateau as of epoch 20, exhibiting a very small growth in accuracy for subsequent epochs, while the training accuracy keeps on increasing. This behavior indicates a slight overfit for epochs beyond 20, where the model behaves increasingly better on the training data than on the validation data. Therefore, having an early stop around epoch 20 would be a good strategy.\n\nA closer inspection of the predictions generated by the CNN model vs the actual test labels gives us a general idea of the model\u2019s performance. The following table provides a means of visualising it. The CNN model is able to predict the correct image label in about 65% of the cases. In fact, the number of correctly predicted labels for the whole test set was 6234 out of 10000, or roughly 62%.","0c94f735":"Comparing the performance of the neural network with another machine learning model is a good way to have an idea of how well the network is actually doing on the problem. For this project, a support vector machine was trained on the CIFAR-10 dataset as well, and its accuracy was measured by counting the number of correct predictions on the test data, in the same way that the CNN accuracy was measured.\n\nSupport vector machines are well suited for supervised classification problems, since it fits hyperplanes between groups of nearby data points, generating classification groups. Therefore, it should perform well on the dataset chosen for this project, and it provides a decent reference frame for comparisons. The accuracy index for the SVM was found to be 54% on the test data. The CNN is able to identify the classes correctly in more cases than the SVM by a factor of 10%."}}