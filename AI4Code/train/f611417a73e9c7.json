{"cell_type":{"77abb8e1":"code","20097732":"code","cbb8bd19":"code","ccb58bc5":"code","8019b7fc":"code","7a1112a0":"code","37567d68":"code","9dc0a2aa":"code","c37774e4":"code","51c49fd4":"code","957e36f4":"code","2a611949":"code","9066a1a0":"code","bc200d6d":"code","5b25fc0a":"code","c39cedce":"markdown","2733bd3b":"markdown","29319e96":"markdown","c815070a":"markdown","3c5bab04":"markdown","04b048ac":"markdown","7e6ca707":"markdown","f8878791":"markdown"},"source":{"77abb8e1":"# ! pip install -q lightning-flash[text]\n# ! pip install -q 'https:\/\/github.com\/PyTorchLightning\/lightning-flash\/archive\/refs\/heads\/master.zip#egg=lightning-flash[text]'\n! pip install -q 'https:\/\/github.com\/PyTorchLightning\/lightning-flash\/archive\/refs\/heads\/fix\/serialize_tokenizer.zip#egg=lightning-flash[text]'\n! pip install -q mplfinance\n! pip install -q --upgrade pandas --force-reinstall\n! pip list | grep -E \"lightning|torch\"","20097732":"# ! pip download -q lightning-flash[text] --prefer-binary --dest frozen_packages\n! pip wheel -q 'https:\/\/github.com\/PyTorchLightning\/lightning-flash\/archive\/refs\/heads\/fix\/serialize_tokenizer.zip#egg=lightning-flash[text]' --wheel-dir frozen_packages\n! rm frozen_packages\/torch-*\n! ls frozen_packages","cbb8bd19":"! ls \/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification","ccb58bc5":"import pandas as pd\n\ncsv_train = \"\/kaggle\/input\/jigsaw-multilingual-toxic-comment-classification\/jigsaw-toxic-comment-train.csv\"\ndf_train = pd.read_csv(csv_train)\ndisplay(df_train.head())\n\n_= df_train.plot.hist(bins=2, grid=True, sharex=True, logy=True)","8019b7fc":"csv_comemnts = \"\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\"\ndf_comments = pd.read_csv(csv_comemnts)\ndisplay(df_comments.head())","7a1112a0":"df_train[\"sum\"] = df_train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].sum(axis=1)\ndf_train[\"any\"] = df_train[\"sum\"].gt(0).astype(int)\n_= df_train[\"any\"].plot.hist(bins=2, grid=True)","37567d68":"import torch\n\nimport flash\nfrom flash.text import TextClassificationData, TextClassifier","9dc0a2aa":"datamodule = TextClassificationData.from_data_frame(\n    input_field=\"comment_text\",\n    target_fields=\"any\",  # \"toxic\",\n    train_data_frame=df_train,\n    val_data_frame=df_train,\n    backbone=\"xlm-roberta-base\",\n    batch_size=64,\n    num_workers=0,\n)","c37774e4":"from torchmetrics import F1, Precision\n\nmodel = TextClassifier(\n    backbone=datamodule.backbone,\n    num_classes=datamodule.num_classes,\n    metrics=[Precision(), F1()],\n)\nmodel.model.save_pretrained(\".\/used-HF-model\")\n! ls -l .\/used-HF-model","51c49fd4":"import torch\nfrom pytorch_lightning.loggers import CSVLogger\n# from pytorch_lightning.callbacks import StochasticWeightAveraging\n\n# swa = StochasticWeightAveraging(swa_epoch_start=0.6)\nlogger = CSVLogger(save_dir='logs\/')\ntrainer = flash.Trainer(\n    max_epochs=10,\n    logger=logger,\n    gpus=torch.cuda.device_count(),\n    # callbacks=[swa],\n    accumulate_grad_batches=12,\n    gradient_clip_val=0.1,\n    precision=16,\n    # enable_ort=True,  # if you have PT>=1.5\n    auto_lr_find=True,\n)\n\ntrainer.tune(model, datamodule=datamodule, lr_find_kwargs=dict(min_lr=1e-5, max_lr=0.1, num_training=65),)\nprint(f\"Learning Rate: {model.learning_rate}\")\n\ntrainer.finetune(model, datamodule=datamodule, strategy=\"freeze\")\n\n# Save the model!\ntrainer.save_checkpoint(\"text_classification_model.pt\")","957e36f4":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nmetrics = pd.read_csv(f'{trainer.logger.log_dir}\/metrics.csv')\ndel metrics[\"step\"]\nmetrics.set_index(\"epoch\", inplace=True)\ndisplay(metrics.dropna(axis=1, how=\"all\").head())\ng = sns.relplot(data=metrics, kind=\"line\")\nplt.gcf().set_size_inches(15, 5)","2a611949":"# ! ls -l ~\/.cache\/huggingface\/\n# ! mkdir -p cache\/huggingface\n# ! rsync -ahv ~\/.cache\/huggingface\/ cache\/huggingface --exclude=\"*.lock\"\n# ! ls -l cache\/huggingface","9066a1a0":"import math\nfrom flash.core.classification import Logits, Probabilities\nfrom tqdm.auto import tqdm\n\nmodel.output = Logits()\n# predictions = model.predict(df_comments[\"text\"])\n\npredictions = []\nfor i in tqdm(range(math.ceil(len(df_comments) \/ datamodule.batch_size))):\n    batch = df_comments[\"text\"][i * datamodule.batch_size:(i + 1) * datamodule.batch_size]\n    predictions += model.predict(batch)\n\nprint(f\"inputs={len(df_comments)} ; preds={len(predictions)}\")\nprint(predictions[0])","bc200d6d":"import numpy as np\n\npredictions = np.array(predictions)[:, -1]\n_= plt.hist(predictions, bins=25)","5b25fc0a":"df_submit = pd.DataFrame(zip(df_comments[\"comment_id\"], predictions), columns=(\"comment_id\", \"score\"))\ndf_submit.set_index(\"comment_id\", inplace=True)\ndf_submit.to_csv(\"submission.csv\")\n\n! head submission.csv","c39cedce":"### ToDo\n\nConsider some label aggregation for this competition...","2733bd3b":"### 1. Create the DataModule","29319e96":"# Training with Flash Lightning\n\nSee the classification docs: https:\/\/lightning-flash.readthedocs.io\/en\/stable\/reference\/text_classification.html","c815070a":"## Data exolorations & preparation\n\nChecking the input data and pairing with Crypto names","3c5bab04":"### 3. Create the trainer and finetune the model","04b048ac":"### 4. Classify new comments","7e6ca707":"# \ud83d\ude4aToxic comments with Lightning\u26a1Flash\n\n[Flash](https:\/\/lightning-flash.readthedocs.io\/en\/stable) makes complex AI recipes for over 15 tasks across 7 data domains accessible to all.\n\nIn a nutshell, Flash is the production grade research framework you always dreamed of but didn't have time to build.","f8878791":"### 2. Build the task"}}