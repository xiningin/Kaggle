{"cell_type":{"afc2ccbf":"code","b67a66d6":"code","dd6f43e4":"code","858e8aff":"code","81f0bfe0":"code","e615966f":"code","05e1cc5f":"code","57879e3d":"code","5ab21258":"code","5b5ec874":"code","7e7e36b8":"code","797d70c4":"code","32a2656c":"code","de1977d7":"code","6ee0cc82":"code","e26b8867":"code","f5740a6c":"code","4db6f723":"code","321e8432":"code","e1fa6130":"code","30a09f23":"code","6c23b098":"code","34afdc24":"code","2bd7d36c":"code","7a056a08":"code","a1f683b9":"code","c8611338":"code","ea490eac":"code","0735c27b":"code","dde10fe2":"markdown","8911be96":"markdown","68cf9858":"markdown","3a2139bf":"markdown","8c97d353":"markdown","974cd9ad":"markdown","7b1e8aa4":"markdown","6c5ebba6":"markdown","446a3d75":"markdown","67a5fe9e":"markdown","af3e9d7f":"markdown","25258418":"markdown"},"source":{"afc2ccbf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate,accuracy\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b67a66d6":"import gc\ngc.collect()","dd6f43e4":"size = 224\nbs = 64\npath = \"..\/input\/\"\nnp.random.seed(1)","858e8aff":"path_anno = path+'annotations\/Annotation\/'\npath_img = path+'images\/Images'","81f0bfe0":"labels = os.listdir(path_img)\nprint(\"No. of labels: {}\".format(len(labels)))\nprint(\"-----------------\")\n\nfor label in labels:\n    print(\"{}, {} files\".format(label, len(os.listdir(path_img+'\/'+label))))","e615966f":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\nfig, ax = plt.subplots(nrows=3, ncols=4,figsize=(20, 10))\nfig.tight_layout()\ncnt = 0\nfor row in ax:\n    for col in row:\n        image_name = np.random.choice(os.listdir(path_img+ '\/' + labels[cnt]))\n        im = Image.open(path_img+\"\/{}\/{}\".format(labels[cnt],image_name))\n        col.imshow(im)\n        col.set_title(labels[cnt])\n        col.axis('off')\n        cnt += 1\nplt.show();","05e1cc5f":"data = ImageDataBunch.from_folder(path_img, \n                                  ds_tfms=get_transforms(),\n                                  valid_pct=0.2, \n                                  size=size, \n                                  bs=bs).normalize(imagenet_stats)","57879e3d":"data.show_batch(rows=3, figsize=(20,10))","5ab21258":"print(data.classes)\nlen(data.classes),data.c","5b5ec874":"learn = cnn_learner(data, models.resnet34, metrics=[accuracy,error_rate], callback_fns=ShowGraph ,model_dir=\"\/tmp\/model\/\")","7e7e36b8":"learn.model","797d70c4":"learn.fit_one_cycle(4)","32a2656c":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","de1977d7":"interp.plot_top_losses(6, figsize=(25,20));","6ee0cc82":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.most_confused(min_val=10)","e26b8867":"interp.plot_confusion_matrix(figsize=(40,40), dpi=60)","f5740a6c":"learn.fit_one_cycle(1)","4db6f723":"learn.lr_find()\nlearn.recorder.plot()","321e8432":"learn.unfreeze()\nlearn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))","e1fa6130":"data = ImageDataBunch.from_folder(path_img, \n                                  ds_tfms=get_transforms(),\n                                  valid_pct=0.2, \n                                  size=299, \n                                  bs=bs\/\/2).normalize(imagenet_stats)","30a09f23":"learn = cnn_learner(data, models.resnet50, metrics=[accuracy,error_rate], callback_fns=ShowGraph ,model_dir=\"\/tmp\/model\/\")","6c23b098":"learn.lr_find()\nlearn.recorder.plot()","34afdc24":"learn.fit_one_cycle(8)","2bd7d36c":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.most_confused(min_val=10)","7a056a08":"interp.plot_confusion_matrix(figsize=(40,40), dpi=60)","a1f683b9":"learn.save('stage-1-50')","c8611338":"learn.unfreeze()\nlearn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))","ea490eac":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.most_confused(min_val=10)","0735c27b":"interp.plot_confusion_matrix(figsize=(40,40), dpi=60)","dde10fe2":"Image size = 224, Batch Size = 64, path for model and random seed","8911be96":"We can visualize the most incorrect predictions to check model performance.","68cf9858":"We will now try predicting with resnet50 as base model but we will need to increase image size, the more the image size the better the performance but it becomes more computational. We will use a smaller batch size due to this.","3a2139bf":"We can clearly see the difference between both ResNet models, now we will try to tune the model.\nIf tuning does not improve in predicting we can load the previous model using learn.load('stage-1-50').","8c97d353":"Now we can create a learner object, we are using resnet34 as our base model and using metrics accuracy and error rate. \nDefining the callback function ShowGraph simply tells the learner that it should return a graph for whatever it does, which seems very useful for seeing whether the model is still improving.\nWe are assigning a model directory as in kaggle the \"..input\/\" is read only and thus creating this temporary folder will allow us to change the location of the learner. (Ignore this parameter if not using Kaggle)","974cd9ad":"We will try to make better predictions using ResNet50.","7b1e8aa4":"**Inspecting the data**","6c5ebba6":"path_img is where we will find all the image folders with labels as name of these folders","446a3d75":"Using most_confused we can find where the algorithm is making most mistakes. (minimum value of mistakes = 10)","67a5fe9e":"Since our images are placed in folders whose names correspond to the image labels, we will use the ImageDataBunch.from_folder() function to create an object that contains our image data. \n\nA function argument called get_transforms() which returns a list of available image transformations upon call.\n\nFast.ai can automatically split our data into train and validation sets using valid_pct = 0.2(20%), so we don't even need to create these on our own.\n\nSize refers to the Image size and bs to batch size.\n\nTo normalize the data in our object, we simply call normalize() on the object. Since we will be using a ResNet architecture for our model which was trained on ImageNet, we will be using the ImageNet stats.","af3e9d7f":"Tuning the learner.","25258418":"Randomly displaying 12 Images"}}