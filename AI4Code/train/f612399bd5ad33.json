{"cell_type":{"e20071c7":"code","d7cc516b":"code","2ad207c8":"code","2a2ba327":"code","1c7e1dd4":"code","608e6582":"code","531717cf":"code","558b6e8c":"code","6d641b82":"code","0b10bbf8":"code","cac41381":"code","b26a2d29":"code","1983eb6b":"code","190fea02":"markdown","f40987cf":"markdown","6ece404f":"markdown","64934833":"markdown","efa61356":"markdown","8c43ac87":"markdown","ccf6b2c5":"markdown"},"source":{"e20071c7":"from keras import layers, models\nimport numpy as np # to use reshape()\nfrom keras import datasets  # we can bring our mnist data from here\nfrom keras.utils import np_utils  # to_categorical\nimport matplotlib.pyplot as plt\n","d7cc516b":"# bring our data\n\n(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()","2ad207c8":"# check \n\nprint(X_train.shape)\nprint(X_test.shape)\n","2a2ba327":"# check\n\nX_train[0]","1c7e1dd4":"# check\n\nplt.imshow(X_train[0])\nplt.show()","608e6582":"# we change from output(0~9) to output((0 or 1) * 10) vector for ANN classification\n\nY_train = np_utils.to_categorical(y_train)\nY_test = np_utils.to_categorical(y_test)","531717cf":"# we need to change 3 dimention data to 2 dimention for training\n\nL, H, W = X_train.shape\nX_train = X_train.reshape(-1,W*H) # -1 means auto\nX_test = X_test.reshape(-1,W*H)","558b6e8c":"X_train.shape","6d641b82":"# normalization\n\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","0b10bbf8":"def Data_func():\n    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n\n    Y_train = np_utils.to_categorical(y_train)\n    Y_test = np_utils.to_categorical(y_test)\n\n    L, W, H = X_train.shape\n    X_train = X_train.reshape(-1, W * H)\n    X_test = X_test.reshape(-1, W * H)\n\n    X_train = X_train \/ 255.0\n    X_test = X_test \/ 255.0\n\n    return (X_train, Y_train), (X_test, Y_test)","cac41381":"class ANN_models_class(models.Model) :\n    def __init__(self,Nin,Nh,Nout) : # (Nin : input layer nodes), (Nh : hidden layer nodes), (Nout : output layer nodes)\n        \n        # Prepare network layers and activate functions\n        hidden = layers.Dense(Nh) # our ANN has only one hidden layer\n        output = layers.Dense(Nout)\n        relu = layers.Activation('relu') \n        softmax = layers.Activation('softmax')\n        \n        # Connect network elements\n        x = layers.Input(shape=(Nin,))\n        h = relu(hidden(x))\n        y = softmax(output(h))\n        \n        super().__init__(x,y)\n        self.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","b26a2d29":"# check for accuracy\n\ndef plot_acc(history, title=None):\n    # summarize history for accuracy\n    if not isinstance(history, dict):\n        history = history.history\n\n    plt.plot(history['accuracy'])\n    plt.plot(history['val_accuracy'])\n    if title is not None:\n        plt.title(title)\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Training', 'Verification'], loc=0)\n    # plt.show()\n    \n# check for loss\n\ndef plot_loss(history, title=None):\n    # summarize history for loss\n    if not isinstance(history, dict):\n        history = history.history\n\n    plt.plot(history['loss'])     # training loss\n    plt.plot(history['val_loss']) # validation loss\n    if title is not None:\n        plt.title(title)\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Training', 'Verification'], loc=0)\n    # plt.show()","1983eb6b":"def main():\n    Nin = 784 # input layer nodes\n    Nh = 100 # hidden layer nodes\n    number_of_class = 10 # output layer nodes\n    Nout = number_of_class\n\n    model = ANN_models_class(Nin, Nh, Nout)\n    (X_train, Y_train), (X_test, Y_test) = Data_func()\n\n \n    # Training\n    history = model.fit(X_train, Y_train, epochs=15, batch_size=100, validation_split=0.2)\n    \n    # test\n    performace_test = model.evaluate(X_test, Y_test, batch_size=100)\n    print('Test Loss and Accuracy ->', performace_test)\n\n    plot_loss(history)\n    plt.show()\n    plot_acc(history)\n    plt.show()\n\n\n\n# Run code\nif __name__ == '__main__':\n    main()","190fea02":"<a id=\"four\"><\/a>\n# 4. Training & Evaluation","f40987cf":"# Simple ANN![0.png](attachment:0.png)\n![01.png](attachment:01.png)\n\nANN (Artificail Neural Network)\n* **ANN (Artificail Neural Network):** usually simply called neural networks (NNs), are computing systems vaguely inspired by the biological neural networks \n* Our **ANN** is focusing on classification which number is, when **ANN** gets ficture of number (MNIST)\n* An artificial neural network is an interconnected group of nodes, there are input layer, hidden layer, output layer\n* We are using Keras module\n\n<hr>\n\nHow to use this notebook :\n\nThere is only minimum explanation\n\nThis notebook could be helpful for who want to see how code works right away\n\nPlease upvote if it was helpful !\n\n<hr>\n\n## Content\n1. [Import Libraries](#one)\n2. [Prepare Data](#two)\n3. [Modeling](#three)\n4. [Training & Evaluation](#four)\n\n<hr>","6ece404f":"## Reference\n* Coding chef 3 minute deep learning  -(https:\/\/github.com\/jskDr\/keraspp\/blob\/master\/ex2_1_ann_mnist_cl.py)\n[Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Artificial_neural_network)","64934833":"* 70000 data ( 60000 for training, 10000 for test)\n* 28 * 28 (each pixel can have 0~255 value)\n* 0 ~ 9 (10 classes)\n* example)\n\n![d4e5709ebb4ba940126de44c76ca71b0@2x.png](attachment:d4e5709ebb4ba940126de44c76ca71b0@2x.png)","efa61356":"<a id=\"two\"><\/a>\n# 2. Prepare Data","8c43ac87":"<a id=\"three\"><\/a>\n# 3. Modeliing","ccf6b2c5":"<a id=\"one\"><\/a>\n# 1. Import Libraries"}}