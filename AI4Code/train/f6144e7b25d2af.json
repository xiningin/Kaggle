{"cell_type":{"e0814bf8":"code","1f8e3aed":"code","c97316bf":"code","90dc71dc":"code","09cbc84d":"code","08adc502":"code","cd00c348":"code","41c15b8c":"code","b04d2a9e":"code","832007c2":"code","641bf68d":"code","50d97695":"code","6566888b":"code","69d5b4d3":"code","73ed2ce8":"code","f79c683a":"code","cfb61a6b":"code","03fc1a7a":"code","6c3835c3":"code","026fe09b":"code","6ab73b0b":"code","0be03385":"code","f74029b6":"code","830d9620":"code","3d8239d5":"code","65d29f9c":"code","8d7c1190":"code","e4d0f332":"code","0378a2b6":"code","c4ba4567":"code","82ce6d67":"code","06341515":"code","34da77f7":"code","e6c4fa0e":"markdown","2ae9a4ec":"markdown","c6772891":"markdown","fcdbe782":"markdown","5d91f6b6":"markdown","31b5f0ad":"markdown","02677a9f":"markdown","6f50bc3f":"markdown","576801d9":"markdown","da31dcc2":"markdown","734ced29":"markdown","d30a0bc8":"markdown","ae5649cc":"markdown","924fe17a":"markdown","b4e3ed75":"markdown","653734bf":"markdown","f1083081":"markdown","79500cff":"markdown"},"source":{"e0814bf8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f8e3aed":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncolor = sns.color_palette()\n\n%matplotlib inline\n","c97316bf":"items_df=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nshops_df=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\nsales_train_df=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\ntest_df=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")\n#sample_df=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nitem_categories_df=pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")","90dc71dc":"items_df.head(3)","09cbc84d":"items_df.shape","08adc502":"shops_df.head(3)","cd00c348":"item_categories_df.head(3)","41c15b8c":"sales_train_df.head(5)","b04d2a9e":"sales_train_df.tail(5)","832007c2":"df_list = [items_df, sales_train_df, shops_df,item_categories_df,test_df]\ndf_list_names = [\"items_df\", \"sales_train_df\", \"shops_df\",\"item_categories_df\",\"test_df\"]\n\nfor i, n in zip(df_list, df_list_names):\n    null_status = i.isnull().values.any()\n    if null_status:\n        print(n + \" has null values\")\n    else:\n        print(n + \" doesn't have null values\")","641bf68d":"#from collections import defaultdict \n#item_cnt_dict=defaultdict()\n#for key in sorted(sales_train_df.item_id.unique()):\n#    item_cnt_dict[key]=[]\n#for key in item_cnt_dict.keys():\n#    item_cnt_dict[key]=sales_train_df[sales_train_df[\"item_id\"]==key][\"item_cnt_day\"].sum()","50d97695":"#import operator\n#N=5\n#sorted_df = dict(sorted(item_cnt_dict.items(), key=operator.itemgetter(1),reverse=True)[:N])\n#sorted_df","6566888b":"item_cnt_df=sales_train_df.groupby('item_id')['item_cnt_day'].sum().to_frame().reset_index().sort_values(by=['item_cnt_day'], ascending=False)[:10]","69d5b4d3":"#item_cnt_df = pd.DataFrame(list(sorted_df.items()),columns = ['item_id','total_count']) \nmerged_item_df = pd.merge(left=items_df, right=item_cnt_df, left_on='item_id', right_on='item_id')\nmerged_item_df = pd.merge(left=merged_item_df, right=item_categories_df, left_on='item_category_id', right_on='item_category_id')\nmerged_item_df=merged_item_df.sort_values('item_cnt_day',ascending=False)\nmerged_item_df","73ed2ce8":"\nplt.figure(figsize=(12,8))\n\nsns.barplot(x='item_id', y=\"item_cnt_day\", data=merged_item_df,\n            order=merged_item_df.sort_values('item_cnt_day',ascending = False).item_id,alpha=0.8,color=color[2])\nplt.xlabel('Item_id', fontsize=12)\nplt.ylabel('Total_count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.ylim(0,25000)\nplt.show()","f79c683a":"sales_train_df.head(3)","cfb61a6b":"import operator\nN=30\nshop_cnt_dict={}\nfor key in np.sort(sales_train_df.shop_id.unique()).tolist():\n    shop_cnt_dict[key]=[]\nfor key in shop_cnt_dict.keys():\n    shop_cnt_dict[key]=sales_train_df[sales_train_df[\"shop_id\"]==key][\"item_cnt_day\"].sum()\nsorted_df = dict(sorted(shop_cnt_dict.items(), key=operator.itemgetter(1),reverse=True)[:N])\nshop_cnt_df = pd.DataFrame(list(sorted_df.items()),columns = ['shop_id','total_count']) \nshop_cnt_df  ","03fc1a7a":"\nplt.figure(figsize=(12,8))\n\nsns.barplot(x='shop_id', y=\"total_count\", data=shop_cnt_df,\n            order=shop_cnt_df.sort_values('total_count',ascending = False).shop_id,alpha=0.8,color=color[2])\nplt.xlabel('Shop_id', fontsize=12)\nplt.ylabel('Total_count', fontsize=12)\nplt.xticks(rotation='vertical')\n#plt.ylim(0,25000)\nplt.show()","6c3835c3":"shop_price_dict={}\nfor key in np.sort(sales_train_df.shop_id.unique()).tolist():\n    shop_price_dict[key]=[]\nfor key in shop_price_dict.keys():\n    shop_price_dict[key]=sales_train_df[sales_train_df[\"shop_id\"]==key][\"item_price\"].sum()\nsorted_df = dict(sorted(shop_price_dict.items(), key=operator.itemgetter(1),reverse=True)[:N])\nshop_price_df = pd.DataFrame(list(sorted_df.items()),columns = ['shop_id','total_price']) \nshop_price_df  ","026fe09b":"\nplt.figure(figsize=(12,8))\n\nsns.barplot(x='shop_id', y=\"total_price\", data=shop_price_df,\n            order=shop_price_df.sort_values('total_price',ascending = False).shop_id,alpha=0.8,color=color[2])\nplt.xlabel('Shop_id', fontsize=12)\nplt.ylabel('Total_price', fontsize=12)\nplt.xticks(rotation='vertical')\n#plt.ylim(0,25000)\nplt.show()","6ab73b0b":"sales_train_df.head(2)","0be03385":"mon_v={'01':'Jan','02':'Feb','03':'Mar','04':'Apr','05':'May','06':'Jun','07':'Jul','08':'Aug','09':'Sep','10':'Oct','11':'Nov','12':'Dec'}","f74029b6":"cols=['day','mon','year']\ndatalist = list(map(lambda x: x.split(\".\"), sales_train_df.date)) # create list from entries in \"sec\" \nnewdf = pd.DataFrame(data=datalist, columns=cols)   # create dataframe of new columns\nsales_train_mon_df = pd.concat([sales_train_df, newdf], axis=1) \nsales_train_mon_df['mon'].replace(mon_v,inplace=True)\nsales_train_mon_df.head(2)","830d9620":"shop_price_2013_df=sales_train_mon_df[sales_train_mon_df['year']=='2013'].groupby('shop_id')['item_price'].sum().to_frame().reset_index().sort_values(by=['item_price'], ascending=False)[:5]\nshop_price_2014_df=sales_train_mon_df[sales_train_mon_df['year']=='2014'].groupby('shop_id')['item_price'].sum().to_frame().reset_index().sort_values(by=['item_price'], ascending=False)[:5]\nshop_price_2015_df=sales_train_mon_df[sales_train_mon_df['year']=='2015'].groupby('shop_id')['item_price'].sum().to_frame().reset_index().sort_values(by=['item_price'], ascending=False)[:5]","3d8239d5":"fig = plt.figure(figsize=(12,5))\n\n# Divide the figure into a 1x2 grid, and give me the first section\nax1 = fig.add_subplot(131)\nplt.title('2013', fontsize=14)\n\nax2 = fig.add_subplot(132)\nplt.title('2014', fontsize=14)\n\nax3 = fig.add_subplot(133)\nplt.title('2015', fontsize=14)\n\nshop_price_2013_df.plot(kind='bar', ax=ax1)\nshop_price_2014_df.plot(kind='bar', ax=ax2)\nshop_price_2015_df.plot(kind='bar', ax=ax3)\n","65d29f9c":"sales_train_mon_df.head(2)","8d7c1190":"sales_train_shop26_df=sales_train_mon_df[sales_train_mon_df['shop_id']==26].groupby('mon')['item_price'].sum().to_frame().reset_index().sort_values(by=['mon'], ascending=False)\nsales_train_shop23_df=sales_train_mon_df[sales_train_mon_df['shop_id']==23].groupby('mon')['item_price'].sum().to_frame().reset_index().sort_values(by=['mon'], ascending=False)\nsales_train_shop22_df=sales_train_mon_df[sales_train_mon_df['shop_id']==22].groupby('mon')['item_price'].sum().to_frame().reset_index().sort_values(by=['mon'], ascending=False)","e4d0f332":"shops_final_df=pd.merge(sales_train_shop26_df, sales_train_shop23_df, how = 'outer' ,on='mon')\nshops_final_df=pd.merge(shops_final_df, sales_train_shop22_df, how = 'outer' ,on='mon')","0378a2b6":"shops_final_df.rename(columns = {'item_price_x':'shop_26', 'item_price_y':'shop_23', 'item_price' : 'shop_22'}, inplace = True) \nshops_final_df","c4ba4567":"shops_final_df.plot(kind='bar',x='mon', y=['shop_26', 'shop_23','shop_22'], figsize=(15,5), grid=True)","82ce6d67":"sales_train_26_year_df=sales_train_mon_df[sales_train_mon_df['shop_id']==26].groupby('year')['item_price'].sum().to_frame().reset_index().sort_values(by=['year'], ascending=False)\nsales_train_23_year_df=sales_train_mon_df[sales_train_mon_df['shop_id']==23].groupby('year')['item_price'].sum().to_frame().reset_index().sort_values(by=['year'], ascending=False)\nsales_train_22_year_df=sales_train_mon_df[sales_train_mon_df['shop_id']==22].groupby('year')['item_price'].sum().to_frame().reset_index().sort_values(by=['year'], ascending=False)\n","06341515":"sales_train_23_year_df","34da77f7":"plt.figure(figsize=(12,8))\n# plot chart\nax1 = plt.subplot(131, aspect='equal')\nsales_train_26_year_df.plot(kind='pie', y = 'item_price', ax=ax1, autopct='%1.1f%%',title='shop_26' ,\n startangle=90, shadow=False, labels=sales_train_26_year_df['year'], legend = False, fontsize=14)\nax2 = plt.subplot(132, aspect='equal')\nsales_train_23_year_df.plot(kind='pie', y = 'item_price', ax=ax2, autopct='%1.1f%%', title='shop_23' ,\n startangle=90, shadow=False, labels=sales_train_23_year_df['year'], legend = False, fontsize=14)\nax3 = plt.subplot(133, aspect='equal')\nsales_train_22_year_df.plot(kind='pie', y = 'item_price', ax=ax3, autopct='%1.1f%%', title='shop_22' ,\n startangle=90, shadow=False, labels=sales_train_22_year_df['year'], legend = False, fontsize=14)\n\nplt.show()","e6c4fa0e":"**Finding top 10 items sold the most**","2ae9a4ec":"**Let us explore date w.r.t to dates**","c6772891":"**Find top 30 shops that sold more items**","fcdbe782":"**Importing the Dataset**","5d91f6b6":"1. Converting the dict to a dataframe\n2. Merging the new df with items_df to identify its name and categories","31b5f0ad":"**We will see the profitable year for the top 3 shops**\n","02677a9f":"*2014 was the best for shops 26 and 22. Shop 23 has sold items only on 2013.*","6f50bc3f":"*Basic information about each dataframe*","576801d9":"*Clearly shop 26 is the best seller consistently. Followed by shop 23 and shop 22*","da31dcc2":"****","734ced29":"**Let us explore monthly sale performance of these shops**\nHere we are summing up the yearly performances within the same month to get the avg performance of the shops.","d30a0bc8":"Initially i wrote the below lines, Later found a line that is faster than the below","ae5649cc":"1. Identifying the unique items and making them as keys for the new dict\n2. Values are calculated by grouping and summing the item_cnt_day for the specific keys","924fe17a":"**Checking for null values**","b4e3ed75":"1. Values are sorted in descending to find top 30 sold items","653734bf":"This is faster and much simpler","f1083081":"**Let us find the top 3 shops which got more revenue each year**","79500cff":"**Let us find out top 30 profitable shops**"}}