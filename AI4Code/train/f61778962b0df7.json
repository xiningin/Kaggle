{"cell_type":{"090b6863":"code","430ecb1f":"code","48f71dbf":"code","f22141ee":"code","e49b046f":"code","fe35b39a":"code","8ec87da3":"code","de37032a":"code","f7729bcb":"code","46e3cebc":"code","67c62bc8":"code","040cd8ae":"code","eda51764":"code","2512a51b":"code","9c5a047a":"code","477365f6":"code","83652fe4":"code","1297735a":"code","ad3e68e3":"code","6cc4f56e":"markdown","0855660f":"markdown","ad9d4e2b":"markdown"},"source":{"090b6863":"#import essential libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.cm as cm\n\n%matplotlib inline","430ecb1f":"df = pd.read_csv('..\/input\/mall-customers\/Mall_Customers.csv')\ndf.head()","48f71dbf":"df.isna().sum()","f22141ee":"len(df)","e49b046f":"sns.scatterplot(x='Annual Income (k$)' , y = 'Spending Score (1-100)',data=df , hue='Genre')","fe35b39a":"x = df.iloc[:,[3,4]].values","8ec87da3":"x[:10]","de37032a":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1,11):\n    k_means = KMeans(n_clusters=i,init='k-means++',random_state=42)\n    k_means.fit(x)\n    wcss.append(k_means.inertia_)","f7729bcb":"plt.plot(range(1,11),wcss)\nplt.xticks(range(1,11));","46e3cebc":"kmeans = KMeans(n_clusters=5,init='k-means++',n_init=10,max_iter=300,random_state=42)\nykmeans = kmeans.fit_predict(x)","67c62bc8":"ykmeans","040cd8ae":"#Visualix=ziing the clusters\ndf2 = df\ndf2['ykmeans'] = ykmeans","eda51764":"df2.head(2)","2512a51b":"sns.scatterplot(x='Annual Income (k$)' , y = 'Spending Score (1-100)',data=df2 , hue='ykmeans',palette=['red','green','blue','black','brown'])","9c5a047a":"#let's say possible clusters are [3,4,5,6]\nrange_n_clusters = [3, 4, 5, 6]","477365f6":"\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 2 columns\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(x) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=42)\n    cluster_labels = clusterer.fit_predict(x)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(x, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(x, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) \/ n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels \/ ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    # 2nd Plot showing the actual clusters formed\n    colors = cm.nipy_spectral(cluster_labels.astype(float) \/ n_clusters)\n    ax2.scatter(x[:, 0], x[:, 1], marker='*', s=30, lw=0, alpha=0.7,\n                c=colors, edgecolor='k')\n\n    # Labeling the clusters\n    centers = clusterer.cluster_centers_\n    # Draw white circles at cluster centers\n    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n                c=\"white\", alpha=1, s=200, edgecolor='k')\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                    s=50, edgecolor='k')\n\n    ax2.set_title(\"The visualization of the clustered data.\")\n    ax2.set_xlabel(\"Feature space for the 1st feature\")\n    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold');\n\nplt.show()\n","83652fe4":"kmeans = KMeans(n_clusters=4,init='k-means++',n_init=10,max_iter=300,random_state=42)\ny4kmeans = kmeans.fit_predict(x)","1297735a":"df2['y4kmeans'] = y4kmeans","ad3e68e3":"\nfig , (ax1,ax2) = plt.subplots(1,2)\nfig.set_size_inches(18, 7)\nsns.scatterplot(ax=ax1,x='Annual Income (k$)' , y = 'Spending Score (1-100)',data=df2 , hue='ykmeans',palette=['red','green','blue','black','brown'])\nax1.set_title(\"5 clusters\");\n## Now do the same thing with 4 clusters and compare\nsns.scatterplot(ax=ax2,x='Annual Income (k$)' , y = 'Spending Score (1-100)',data=df2 , hue='y4kmeans',palette=['red','green','blue','brown'])\nax2.set_title(\"4 clusters\");","6cc4f56e":"We can use another validation techinque called `Silhouette (clustering)` .The intuation behind this technique can be found **-** <a href='https:\/\/en.wikipedia.org\/wiki\/Silhouette_(clustering)#:~:text=The%20silhouette%20value%20is%20a,poorly%20matched%20to%20neighboring%20clusters'>Silhouette<\/a> ","0855660f":"`As per my personal intuation 4 would be the optimal number of clusters`","ad9d4e2b":"The above **elbow method** shows that the optimal number of clusters for this data set is `5` ."}}