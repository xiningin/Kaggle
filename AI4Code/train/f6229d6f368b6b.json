{"cell_type":{"aa20ca5a":"code","50bfec58":"code","cf7f7531":"code","bb1590f3":"code","766ed475":"code","c2b76340":"code","d892710d":"code","4dacc037":"code","1c8bb45d":"code","d3d21506":"code","06793c19":"code","e00f0056":"code","9d04bc86":"code","c592e8fe":"code","45b3b1d2":"code","49bf6ce6":"code","bfa0d665":"code","a486f8ce":"code","eb09ba24":"code","f92d6c7d":"code","3dd47a10":"code","01d139db":"code","5a839bf4":"code","990633d8":"markdown","c581dc08":"markdown","4a6d1b6f":"markdown","fd0bc145":"markdown","8c5d2927":"markdown","b9bd898e":"markdown","54db4a87":"markdown"},"source":{"aa20ca5a":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge, LinearRegression, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom time import perf_counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Markdown, display\n\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n","50bfec58":"df = pd.read_csv('..\/input\/brasilian-houses-to-rent\/houses_to_rent_v2.csv')\ndf.head()","cf7f7531":"df['total (R$)'].plot.box(by='total (R$)', color = '#ff8c8e')\nplt.title('Display all the price\\nInclusive outliers')\nplt.show()","bb1590f3":"# As we can see there are strong outliers. We'll filter them out and \n# keep only the prices lower or igual to 20.000.\ndf = df[df['total (R$)'] <= 20000]","766ed475":"df['total (R$)'].plot.box(by='total (R$)', color = '#ff8c8e')\nplt.title('Display the price\\n(max 20.000 R$)')\nplt.show()","c2b76340":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n\ndf['total (R$)'].plot.hist(by='total (R$)',ax = axes[0], color = '#ff8c8e')\naxes[0].set_title('total (R$)\\'s histogram\\n', fontsize = 15)\n\ndf['total (R$)'].plot.box(ax = axes[1])\naxes[1].set_title('total (R$)\\'s Boxplot\\n', fontsize = 15)\n\nsns.violinplot(ax = axes[2], y = 'total (R$)', data = df, color = '#ff8c8e')\naxes[2].set_title('total (R$)\\'s distribution\\n(violinplot)', fontsize = 15)\n\nplt.show()","d892710d":"df['area'].plot.box(by='total (R$)', color = '#ff8c8e')\nplt.title('Display all the areas\\nInclusive outliers')\nplt.show()","4dacc037":"# As we can see there are strong outliers. We'll filter them out and \n# keep only the prices lower or igual to 500.\ndf = df[df['area'] <= 500]","1c8bb45d":"df['area'].plot.box(by='total (R$)', color = '#ff8c8e')\nplt.title('Display the areas\\n(max 500)')\nplt.show()","d3d21506":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n\ndf['area'].plot.hist(by='area',ax = axes[0])\naxes[0].set_title('Area\\'s histogram\\n', fontsize = 15)\n\ndf['area'].plot.box(ax = axes[1])\naxes[1].set_title('Area\\'s Boxplot\\n', fontsize = 15)\n\nsns.violinplot(ax = axes[2], y = 'area', data = df)\naxes[2].set_title('Area\\'s distribution\\n(violinplot)', fontsize = 15)\n\nplt.show()","06793c19":"printmd(f'### Number of rows in the dataset: {df.shape[0]}')","e00f0056":"# Select the columns to display\ncols = df.columns\ncols = list(cols)\ncols.remove('area')\ncols.remove('floor')\n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    col = cols[i]\n    sns.boxplot(x=col,y='total (R$)', data = df, ax = ax)\n    ax.set_title(f\"Boxplot: Price distribution depending on the {col.capitalize()}\")\nplt.tight_layout()\nplt.show()","9d04bc86":"df.columns","c592e8fe":"# Drop the column with various prices\n# because we want to keep only the total price\ncols_drop = ['hoa (R$)', 'rent amount (R$)','property tax (R$)', 'fire insurance (R$)']\ndf = df.drop(cols_drop, axis = 1)\n\n# Create dummies for the columns with strings\ncols_dummies = ['city','animal','furniture']\ndf = pd.get_dummies(df, columns = cols_dummies )\n\n# Show the result\ndf.head(5)","45b3b1d2":"# Where there is no floor, it is signalized as \"-\"\n# in the dataset\n# Replace \"-\" with \"0\"\ndf.loc[df['floor'] == '-','floor']= 0\n\n# Change the column \"floor\" to the integer data type\ndf = df.astype({'floor': 'int64'})","49bf6ce6":"def preprocessing(df):\n    df = df.copy()\n       \n    # Shuffle the data\n    df = df.sample(frac=1.0, random_state=0).reset_index(drop=True)\n    cols = ['city', 'area', 'rooms', 'bathroom', 'parking spaces', 'floor','animal', 'furniture']\n    X = df.drop('total (R$)', axis = 1)\n    y = df['total (R$)']\n    \n    X = pd.DataFrame(X, index=X.index, columns=X.columns)\n    \n    return X, y\n\n# Preprocessing\nX,y = preprocessing(df)\n\n# Split into a training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n# Scale the datasets\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Display the result\nX_train[:2], y_train[:2]","bfa0d665":"models = {\n    \"LinearRegression\":{\"model\":LinearRegression() },\n    \"Lasso\":{\"model\":Lasso() },\n    \"Ridge\":{\"model\":Ridge() },\n    \"DecisionTreeRegressor\":{\"model\":DecisionTreeRegressor() },\n    \"RandomForestRegressor\":{\"model\":RandomForestRegressor() },\n    \"MLPRegressor\":{\"model\":MLPRegressor() },\n    \"GradientBoostingRegressor\":{\"model\":GradientBoostingRegressor() },\n    \"AdaBoostRegressor\":{\"model\":AdaBoostRegressor() }\n}\n\n# Use the K-fold cross validation for each model\n# to get the mean validation accuracy and the mean training time\nk = 5\nfor name, m in models.items():\n    # Cross validation of the model\n    model = m['model']\n    result = cross_validate(model, X_train,y_train, cv = k, scoring='neg_mean_squared_error')\n    \n    # Mean accuracy and mean training time\n    result['test_score'] = result['test_score']\n    mean_RMSE = [(-x)**0.5 for x in result['test_score']] # Root Mean Square Error\n    mean_RMSE = sum(mean_RMSE)\/len(mean_RMSE)\n    mean_RMSE = int(mean_RMSE)\n    mean_fit_time = round( sum(result['fit_time']) \/ len(result['fit_time']), 4)\n    \n    # Add the result to the dictionary witht he models\n    m['mean_RMSE'] = mean_RMSE\n    m['Training time (sec)'] = mean_fit_time\n    \n    # Display the result\n    print(f\"{name:27} mean RMSE for {k}-fold CV: {mean_RMSE} - mean training time {mean_fit_time} sec\")","a486f8ce":"# Create a DataFrame with the results\nmodels_result = []\n\nfor name, v in models.items():\n    lst = [name, v['mean_RMSE'],v['Training time (sec)']]\n    models_result.append(lst)\n\ndf_results = pd.DataFrame(models_result, \n                          columns = ['model','RMSE','Training time (sec)'])\ndf_results.sort_values(by='RMSE', ascending=True, inplace=True)\ndf_results.reset_index(inplace=True,drop=True)\ndf_results","eb09ba24":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'RMSE', data = df_results)\nplt.title(f'{k}-fold mean RMSE for each Model\\nSmaller is better', fontsize = 15)\n# plt.ylim(0.8,1.005)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('RMSE',fontsize=15)\nplt.xticks(rotation=90, fontsize=12)\nplt.show()","f92d6c7d":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\nplt.title('Training time for each Model in sec\\nSmaller is better', fontsize = 15)\nplt.xticks(rotation=90, fontsize=12)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Training time (sec)',fontsize=15)\nplt.show()","3dd47a10":"# Get the model with the highest mean validation accuracy\nbest_model = df_results.iloc[0]\n\n# Fit the model\nmodel = models[best_model[0]]['model']\nmodel.fit(X_train,y_train)\n\n# Predict the labels with the data set\npred = model.predict(X_test)\n\nRMSE = mean_squared_error(y_test,pred)**0.5\nRMSE = int(RMSE)\n\n# Display the results\nprintmd(f'### Best Model: {best_model[0]} with a RMSE of {RMSE} on the test set')\nprintmd(f'### Trained in: {best_model[2]} sec')","01d139db":"# Concatenate the ratings of the test set\n# with the predictions of those ratings\npred_s = pd.Series(pred)\ny_test_s = y_test.reset_index(drop=True)\n\ndf_result = pd.concat([y_test_s,round(pred_s,0)], axis = 1)\ndf_result.columns = ['Real Rating', 'Predicted Rating']\ndf_result = df_result.astype({'Predicted Rating': 'int64'})\ndf_result.head(10)","5a839bf4":"df_result.plot.box()\nplt.title('Boxplot Real Rating VS Predicted Rating', fontsize = 12)\nplt.show()\n\ndf_result.plot.scatter(x='Real Rating', y='Predicted Rating', alpha = 0.1)\nplt.title('Scatterplot Real Rating VS Predicted Rating', fontsize = 12)\nplt.show()","990633d8":"# Predict housing price in Brazil\n## *Comparing 8 regression algorithms*\n*This dataset contains 10962 houses to rent with 13 diferent features.*\n\n![housing brazil](https:\/\/i.imgur.com\/wOKxor1.pnghttps:\/\/i.imgur.com\/wOKxor1.png)\n\n\n","c581dc08":"# Table of contents\n\n[<h3>1. Data Analysis & Data Processing<\/h3>](#1)\n\n[<h3>2. Model comparison<\/h3>](#2)\n\n[<h3>3. Prediction metrics of the best model using the test set<\/h3>](#3)\n\n[<h3>4. Visualization of the result<\/h3>](#4)\n\n","4a6d1b6f":"# 1. Data Analysis & Data Preprocessing<a class=\"anchor\" id=\"1\"><\/a><a class=\"anchor\" id=\"1\"><\/a>","fd0bc145":"# 3. Prediction metrics of the best model using the test set<a class=\"anchor\" id=\"4\"><\/a>","8c5d2927":"# 2. Model comparison<a class=\"anchor\" id=\"2\"><\/a>","b9bd898e":"![Bazial Rio de Janeiro](https:\/\/i.imgur.com\/phixAyv.png)","54db4a87":"# Load the libraries"}}