{"cell_type":{"e3ec74ee":"code","9b794417":"code","c13be36a":"code","ece7f624":"code","b052a236":"code","ff9bddc8":"code","fbc2faa2":"code","8492fbf0":"code","9f48eb40":"code","74fa39e6":"code","54f308f5":"code","edd58d89":"markdown","6b08610c":"markdown","14d89cfc":"markdown","b8435fb0":"markdown","bdb78344":"markdown","5b86edfe":"markdown","30d2ab45":"markdown","52e2ae25":"markdown","3d61b53d":"markdown","e9d0dad2":"markdown"},"source":{"e3ec74ee":"!pip install imageio-ffmpeg","9b794417":"!git clone https:\/\/github.com\/AliaksandrSiarohin\/first-order-model","c13be36a":"import os\nos.chdir('first-order-model')","ece7f624":"import imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom skimage.transform import resize\nfrom IPython.display import HTML","b052a236":"def display(source, driving, generated=None):\n    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n\n    ims = []\n    for i in range(len(driving)):\n        cols = [source]\n        cols.append(driving[i])\n        if generated is not None:\n            cols.append(generated[i])\n        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n        plt.axis('off')\n        ims.append([im])\n\n    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n    plt.close()\n    return ani","ff9bddc8":"from demo import load_checkpoints\ngenerator, kp_detector = load_checkpoints(config_path='config\/vox-256.yaml', \n                            checkpoint_path='..\/..\/input\/first-order-motion-model\/vox-cpk.pth.tar')","fbc2faa2":"from demo import make_animation\nfrom skimage import img_as_ubyte","8492fbf0":"# read source image and driving video\nsource_image = imageio.imread('..\/..\/input\/input-faces\/Vladimir_Putin.jpg')\ndriving_video = imageio.mimread('..\/..\/input\/input-talking\/Trump.mp4')\n\n# resize image and video to 256x256\nsource_image = resize(source_image, (256, 256))[..., :3]\ndriving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n\n# use AI\u3000model to generate animation\npredictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n\n#save resulting video\nimageio.mimsave('..\/generated_Putin.mp4', [img_as_ubyte(frame) for frame in predictions])\n\n# merge source_image, driving_video, animation into html video\nHTML(display(source_image, driving_video, predictions).to_html5_video())","9f48eb40":"# read source image and driving video\nsource_image = imageio.imread('..\/..\/input\/input-faces\/Taylor_Swift.jpg')\ndriving_video = imageio.mimread('..\/..\/input\/input-talking\/Obama.mp4', memtest=False)\n\n# resize image and video to 256x256\nsource_image = resize(source_image, (256, 256))[..., :3]\ndriving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n\n# use AI\u3000model to generate animation\npredictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True, adapt_movement_scale=True)\n\n#save resulting video\nimageio.mimsave('..\/generated_TaylorSwift.mp4', [img_as_ubyte(frame) for frame in predictions])\n\n# merge source_image, driving_video, animation into html video\nHTML(display(source_image, driving_video, predictions).to_html5_video())","74fa39e6":"# read source image and driving video\nsource_image = imageio.imread('..\/..\/input\/input-faces\/Mona_Lisa.jpg')\ndriving_video = imageio.mimread('..\/..\/input\/input-talking\/Leonardo.mp4', memtest=False)\n\n# resize image and video to 256x256\nsource_image = resize(source_image, (256, 256))[..., :3]\ndriving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n\n# use AI\u3000model to generate animation\npredictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True, adapt_movement_scale=True)\n\n#save resulting video\nimageio.mimsave('..\/generated_MonaLisa.mp4', [img_as_ubyte(frame) for frame in predictions])\n\n# merge source_image, driving_video, animation into html video\nHTML(display(source_image, driving_video, predictions).to_html5_video())","54f308f5":"# read source image and driving video\nsource_image = imageio.imread('..\/..\/input\/input-faces\/Van_Gogh.jpg')\ndriving_video = imageio.mimread('..\/..\/input\/input-talking\/Trump.mp4', memtest=False)\n\n# resize image and video to 256x256\nsource_image = resize(source_image, (256, 256))[..., :3]\ndriving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n\n# use AI\u3000model to generate animation\npredictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True, adapt_movement_scale=True)\n\n#save resulting video\nimageio.mimsave('..\/generated_VanGoph.mp4', [img_as_ubyte(frame) for frame in predictions])\n\n# merge source_image, driving_video, animation into html video\nHTML(display(source_image, driving_video, predictions).to_html5_video())","edd58d89":"## Obama driving Taylor Swift","6b08610c":"## Perform image animation","14d89cfc":"### Approach\n![First-Order-Motion-Model.JPG](attachment:First-Order-Motion-Model.JPG)","b8435fb0":"## Load Model","bdb78344":"## Trump driving Van Goph","5b86edfe":"## Trump driving Putin","30d2ab45":"## Paper: [First Order Motion Model for Image Animation](https:\/\/arxiv.org\/abs\/2003.00196)","52e2ae25":"# Talking Head Image Animation","3d61b53d":"## Repro [GitHub](https:\/\/github.com\/AliaksandrSiarohin\/first-order-model)","e9d0dad2":"## Leonardo driving Mona Lisa"}}