{"cell_type":{"12a30827":"code","7d89e4d1":"code","cccdf721":"code","dcfd344c":"code","76fc4e97":"code","febdd4b2":"code","4ba4ee14":"code","2c549939":"code","234c1ea5":"code","60aadeb2":"code","85c56c1b":"code","ed7669ff":"code","15294a70":"code","68097aa5":"code","5140a45e":"code","7780fab1":"code","cad3a18b":"code","df68d81e":"code","d002ee98":"code","352c6111":"code","3f08cc11":"code","dc29cb82":"code","cd78185c":"code","431775cf":"code","6b1fa759":"code","c971b757":"code","f96f544e":"code","cedba2f4":"code","34f95f55":"code","a6bcdc77":"code","2a68c500":"code","2b958c47":"code","12ba12eb":"code","a5401812":"code","f4a13d96":"code","4bd4fc17":"code","e669ec9c":"code","31ed8b6a":"code","9e38af3b":"code","8f84189a":"markdown","01bcec66":"markdown","baf3f817":"markdown","eabfce2e":"markdown","0c034014":"markdown","52d9d15e":"markdown","097d1024":"markdown","45f5a98a":"markdown","c74bec4f":"markdown","f3b1b0f7":"markdown","b3959236":"markdown","c6520c8a":"markdown","eaf8362f":"markdown"},"source":{"12a30827":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.layers import Dropout\ntf.__version__","7d89e4d1":"# Loading the train file \ndf = pd.read_csv(\"..\/input\/review-sentimet-anaysis-data\/TRAIN.csv\")\ndf.head()","cccdf721":"print(df)","dcfd344c":"df.info()","76fc4e97":"df=df.dropna()","febdd4b2":"df.isnull().sum()","4ba4ee14":"X=df.drop('category',axis=1)\ny=df['category']","2c549939":"df['text']","234c1ea5":"df['text'] = df['text'].str.split()\ndf['text']","60aadeb2":"sent_length=200\nembedded_docs=pad_sequences(df.text,padding='pre',maxlen=sent_length)\nprint(embedded_docs)","85c56c1b":"embedded_docs[0]\n","ed7669ff":"len(embedded_docs),y.shape","15294a70":"y.value_counts()","68097aa5":"sns.countplot(y)","5140a45e":"# SMOTE Oversampling\noversample = SMOTE()\nX_final, y_final = oversample.fit_resample(embedded_docs, y)","7780fab1":"y_final.value_counts()","cad3a18b":"sns.countplot(y_final)","df68d81e":"X_final.shape,y_final.shape","d002ee98":"X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.30, random_state=7)","352c6111":"rfc = RandomForestClassifier(n_estimators=200,criterion='entropy')\nrfc.fit(X_train, y_train)\ny_pred1 = rfc.predict(X_test) \nprint(confusion_matrix(y_test,y_pred1))\nprint(accuracy_score(y_test,y_pred1))\nprint(classification_report(y_test,y_pred1))","3f08cc11":"nb = GaussianNB()\nnb.fit(X_train, y_train)\ny_pred2 = nb.predict(X_test) \nprint(confusion_matrix(y_test,y_pred2))\nprint(accuracy_score(y_test,y_pred2))\nprint(classification_report(y_test,y_pred2))","dc29cb82":"ab = AdaBoostClassifier(n_estimators=100, random_state=7)\nab.fit(X_train, y_train)\ny_pred3 = ab.predict(X_test) \nprint(confusion_matrix(y_test,y_pred3))\nprint(accuracy_score(y_test,y_pred3))\nprint(classification_report(y_test,y_pred3))","cd78185c":"xgb = xgboost.XGBClassifier()\nxgb.fit(X_train, y_train)\ny_pred4 = xgb.predict(X_test) \nprint(confusion_matrix(y_test,y_pred4))\nprint(accuracy_score(y_test,y_pred4))\nprint(classification_report(y_test,y_pred4))","431775cf":"svc = svm.SVC()\nsvc.fit(X_train, y_train)\ny_pred5 = svc.predict(X_test) \nprint(confusion_matrix(y_test,y_pred5))\nprint(accuracy_score(y_test,y_pred5))\nprint(classification_report(y_test,y_pred5))","6b1fa759":"dtc = tree.DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\ny_pred6 = dtc.predict(X_test) \nprint(confusion_matrix(y_test,y_pred6))\nprint(accuracy_score(y_test,y_pred6))\nprint(classification_report(y_test,y_pred6))","c971b757":"knn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(X_train, y_train)\ny_pred7 = knn.predict(X_test) \nprint(confusion_matrix(y_test,y_pred7))\nprint(accuracy_score(y_test,y_pred7))\nprint(classification_report(y_test,y_pred7))","f96f544e":"## Creating model using LSTM\n\nvoc_size=50000\nembedding_vector_features=40\n\nmodel_1=Sequential()\nmodel_1.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel_1.add(LSTM(100))\nmodel_1.add(Dense(1,activation='sigmoid'))\nmodel_1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model_1.summary())","cedba2f4":"model_1.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","34f95f55":"y_pred8=model_1.predict_classes(X_test)\nprint(confusion_matrix(y_test,y_pred8))\nprint(accuracy_score(y_test,y_pred8))\nprint(classification_report(y_test,y_pred8))","a6bcdc77":"## Creating model using Bidirectional LSTM\nvoc_size=50000\nembedding_vector_features=40\n\nmodel_2=Sequential()\nmodel_2.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel_2.add(Bidirectional(LSTM(100)))\nmodel_2.add(Dropout(0.3))\nmodel_2.add(Dense(1,activation='sigmoid'))\n\nmodel_2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nprint(model_2.summary())","2a68c500":"model_2.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","2b958c47":"y_pred9=model_2.predict_classes(X_test)\nprint(confusion_matrix(y_test,y_pred9))\nprint(accuracy_score(y_test,y_pred9))\nprint(classification_report(y_test,y_pred9))","12ba12eb":"# Loading the test file \ndf1 = pd.read_csv(\"..\/input\/review-sentimet-anaysis-data\/TEST.csv\")\ndf1.head()","a5401812":"df1['text']","f4a13d96":"df1['text'] = df1['text'].str.split()\ndf1['text']","4bd4fc17":"sent_length=200\nembedded_test_docs=pad_sequences(df1.text,padding='pre',maxlen=sent_length)\nprint(embedded_test_docs)","e669ec9c":"predictions=model_1.predict_classes(embedded_test_docs)","31ed8b6a":"pred=pd.DataFrame(predictions,columns=['category'])\npred.head()","9e38af3b":"pred.to_csv('submission.csv', index=False)","8f84189a":"### LSTM","01bcec66":"### XGBoost Classifier","baf3f817":"### C-Support Vector Classifier","eabfce2e":"### Gaussian Naive Bayes Classifier","0c034014":"### K Nearest Neighbour Classifier","52d9d15e":"### Adaboost Classifier","097d1024":"# Submission \n","45f5a98a":"### Biderectional LSTM","c74bec4f":"### Importing Libraries","f3b1b0f7":"### Decision Tree Classifier","b3959236":"### Random Forest Classifier","c6520c8a":"### Sequence Paddding","eaf8362f":"### As LSTM gives better macro average than others, we will use it for out test data prediction"}}