{"cell_type":{"fcb1e760":"code","e46bc83e":"code","eee40cb0":"code","2f461416":"code","a135d412":"code","a533c795":"code","f25454c2":"code","390ab909":"code","62b4bcc1":"code","8939d22d":"code","e3cbcd84":"markdown","c1d58ea6":"markdown","bd17c26c":"markdown","0e5624f4":"markdown","f61fef96":"markdown","68151bb1":"markdown","52d73e37":"markdown","27b58e8f":"markdown","cc0ac21b":"markdown","34cb4fdf":"markdown","78dc9349":"markdown","f8bf4a1e":"markdown","8aad485d":"markdown","0814bf85":"markdown"},"source":{"fcb1e760":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\n# ensure consistency across runs\nfrom numpy.random import seed\nseed(1)\n\n# Imports to view data\nimport cv2\nfrom glob import glob","e46bc83e":"# Loading the data\ntrain_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"\nval_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/val\"\ntest_data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"\n\ntarget_size = (128,128)   \ntarget_dims = (128, 128, 3) # add channel for RGB\nn_batch_size = 32 ","eee40cb0":"data_augmentor = ImageDataGenerator(samplewise_center=True, rescale=1.\/255, shear_range=0.2,zoom_range = 0.2,samplewise_std_normalization=True)\n\ntrain_generator = data_augmentor.flow_from_directory(train_data_dir,  target_size=target_size, subset='training',batch_size= n_batch_size,class_mode='binary')\nval_generator = data_augmentor.flow_from_directory(val_data_dir, target_size=target_size,subset='validation',class_mode='binary')\ntest_generator = data_augmentor.flow_from_directory(test_data_dir, target_size=target_size,batch_size= 1,class_mode=None, shuffle=False)\n\n# \ntrain_generator.class_indices","2f461416":"data_augmentor = ImageDataGenerator(samplewise_center=True, rescale=1.\/255, shear_range=0.2,zoom_range = 0.2,samplewise_std_normalization=True,validation_split=0.2) \n\ntrain_generator = data_augmentor.flow_from_directory(train_data_dir,  target_size=target_size, subset='training',batch_size= n_batch_size,class_mode='binary')\nval_generator = data_augmentor.flow_from_directory(train_data_dir, target_size=target_size,subset='validation',class_mode='binary')\ntest_generator = data_augmentor.flow_from_directory(test_data_dir, target_size=target_size,batch_size= 1,class_mode=None, shuffle=False)","a135d412":"input_path = '..\/input\/chest-xray-pneumonia\/\/chest_xray\/chest_xray\/'\n\ndef process_data(img_dims, batch_size):\n    # Data generation objects\n    train_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, vertical_flip=True)\n    test_val_datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n    directory=input_path+'train', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n\n    test_gen = test_val_datagen.flow_from_directory(\n    directory=input_path+'test', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n    \n    # I will be making predictions off of the test set in one batch size\n    # This is useful to be able to get the confusion matrix\n    test_data = []\n    test_labels = []\n\n    for cond in ['\/NORMAL\/', '\/PNEUMONIA\/']:\n        for img in (os.listdir(input_path + 'test' + cond)):\n            img = plt.imread(input_path+'test'+cond+img)\n            img = cv2.resize(img, (img_dims, img_dims))\n            img = np.dstack([img, img, img])\n            img = img.astype('float32') \/ 255\n            if cond=='\/NORMAL\/':\n                label = 0\n            elif cond=='\/PNEUMONIA\/':\n                label = 1\n            test_data.append(img)\n            test_labels.append(label)\n        \n    test_data = np.array(test_data)\n    test_labels = np.array(test_labels)\n    \n    return train_gen, test_gen, test_data, test_labels","a533c795":"# Hyperparameters\nimg_dims = 150\nepochs = 10\nbatch_size = 32\n\n# Getting the data\ntrain_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)","f25454c2":"# Input layer\ninputs = Input(shape=(img_dims, img_dims, 3))\n\n# First conv block\nx = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\nx = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Second conv block\nx = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Third conv block\nx = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Fourth conv block\nx = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = Dropout(rate=0.2)(x)\n\n# Fifth conv block\nx = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = Dropout(rate=0.2)(x)\n\n# FC layer\nx = Flatten()(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(rate=0.7)(x)\nx = Dense(units=128, activation='relu')(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(units=64, activation='relu')(x)\nx = Dropout(rate=0.3)(x)\n\n# Output layer\noutput = Dense(units=1, activation='sigmoid')(x)\n\n# Creating model and compiling\nmodel = Model(inputs=inputs, outputs=output)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Callbacks\ncheckpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\nlr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')","390ab909":"# Fitting the model\nhist = model.fit_generator(\n           train_gen, steps_per_epoch=train_gen.samples \/\/ batch_size, \n           epochs=epochs, validation_data=test_gen, \n           validation_steps=test_gen.samples \/\/ batch_size, callbacks=[checkpoint, lr_reduce])","62b4bcc1":"fig, ax = plt.subplots(1, 2, figsize=(10, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['acc', 'loss']):\n    ax[i].plot(hist.history[met])\n    ax[i].plot(hist.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","8939d22d":"from sklearn.metrics import accuracy_score, confusion_matrix\n\npreds = model.predict(test_data)\n\nacc = accuracy_score(test_labels, np.round(preds))*100\ncm = confusion_matrix(test_labels, np.round(preds))\ntn, fp, fn, tp = cm.ravel()\n\nprint('CONFUSION MATRIX ------------------')\nprint(cm)\n\nprint('\\nTEST METRICS ----------------------')\nprecision = tp\/(tp+fp)*100\nrecall = tp\/(tp+fn)*100\nprint('Accuracy: {}%'.format(acc))\nprint('Precision: {}%'.format(precision))\nprint('Recall: {}%'.format(recall))\nprint('F1-score: {}'.format(2*precision*recall\/(precision+recall)))\n\nprint('\\nTRAIN METRIC ----------------------')\nprint('Train acc: {}'.format(np.round((hist.history['acc'][-1])*100, 2)))","e3cbcd84":"## What is Pneumonia?\n\nPneumonia is a form of acute respiratory infection that affects the lungs. The lungs are made up of small sacs called alveoli, which fill with air when a healthy person breathes. When an individual has pneumonia, the alveoli are filled with pus and fluid, which makes breathing painful and limits oxygen intake.\n\nPneumonia is the single largest infectious cause of death in children worldwide. Pneumonia killed 740 180 children under the age of 5 in 2019, accounting for 14% of all deaths of children under five years old but 22% of all deaths in children aged 1 to 5. Pneumonia affects children and families everywhere, but deaths are highest in South Asia and sub-Saharan Africa.\n\n## The Importance of Diagnosing Pneumonia?\n\nDespite the fact that pneumonia is the most common\ncause of serious illness and death in young children\nworldwide, our ability, as clinicians, to infer an infectious\npathological process in the lung from specific features of\nthe history and examination is poor (Scott et al., 2012).\n\nMisdiagnosis, arbitrary charges, annoying queues, and clinic waiting times among others are long-standing phenomena in the medical industry across the world. These factors can contribute to patient anxiety about misdiagnosis by clinicians. However, with the increasing growth in use of big data in biomedical and health care communities, the performance of artificial intelligence (Al) techniques of diagnosis is improving and can help avoid medical practice errors.\n\nThe development of diverse AI techniques has contributed to early detections, disease diagnoses, and referral management. In addition, A total of 55.8% of the respondents (428 out of 767) opted for AI diagnosis regardless of the description of the clinicians (Liu et al., 2020)\n\n\nThe risk of pneumonia is immense for many, especially in developing nations where billions face energy poverty and rely on polluting forms of energy. Over 150 million people get infected with pneumonia on an annual basis especially children under 5\u2009years old. In such regions, the problem can be further aggravated due to the dearth of medical resources and personnel. For example, in Africa\u2019s 57 nations, a gap of 2.3 million doctors and nurses exists. For these populations, accurate and fast diagnosis means everything. It can guarantee timely access to treatment and save much needed time and money for those already experiencing poverty (Stephen, Sain, Maduh, & Jeong, 2019).\n\n\n****\n_Pneumonia. (2021, 11th of November). World Health Organisation. Consulted on 13th of December 2021, van https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/pneumonia_\n\n_Scott, J. A. G., Wonodi, C., Mo\u00efsi, J. C., Deloria-Knoll, M., DeLuca, A. N., Karron, R. A., Bhat, N., Murdoch, D. R., Crawley, J., Levine, O. S., O\u2019Brien, K. L., & Feikin, D. R. (2012). The Definition of Pneumonia, the Assessment of Severity, and Clinical Standardization in the Pneumonia Etiology Research for Child Health Study. Clinical Infectious Diseases, 54(suppl_2), S109\u2013S116. https:\/\/doi.org\/10.1093\/cid\/cir1065_\n\n_Stephen, O., Sain, M., Maduh, U. J., & Jeong, D. U. (2019). An Efficient Deep Learning Approach to Pneumonia Classification in Healthcare. Journal of Healthcare Engineering, 2019, 1\u20137. https:\/\/doi.org\/10.1155\/2019\/4180949_\n","c1d58ea6":"## The Challenge\nBuild an algorithm to automatically identify whether a patient is suffering from pneumonia or not by looking at chest X-ray images. The algorithm had to be extremely accurate because lives of people is at stake.","bd17c26c":"**Resize, Normalize and Scale data**\nKeras ImageDataGenerator class allows image rescaling, resizing options. here, image augmentation is applied and also converted every image into binary (0 and 1). Resizing and scaling is applied on images to save time in training. Data augmenting helps to avoid overfitting. By augmenting data, we will be making slight variations to our data so that we have more data, without losing semantic meaning. The augmentation occurs in the parameters of the ImageDataGenerator method. \n\nThe key idea is to transform samples by small transformations\nthat induce maximal loss to the current classifier","0e5624f4":"### Who performs better: Doctors or Deep Learning?","f61fef96":"** **\n- Afshar, P., Mohammadi, A., & Plataniotis, K. N. (2018). Brain Tumor Type Classification via Capsule Networks. 2018 25th IEEE International Conference on Image Processing (ICIP). Published. https:\/\/doi.org\/10.1109\/icip.2018.8451379\n- Daniel, P., Bewick, T., Welham, S., Mckeever, T. M., & Lim, W. S. (2017). Adults miscoded and misdiagnosed as having pneumonia: results from the British Thoracic Society pneumonia audit. Thorax, 72(4), 376\u2013379. https:\/\/doi.org\/10.1136\/thoraxjnl-2016-209405\n- Fourcade, A., & Khonsari, R. (2019). Deep learning in medical image analysis: A third eye for doctors. Journal of Stomatology, Oral and Maxillofacial Surgery, 120(4), 279\u2013288. https:\/\/doi.org\/10.1016\/j.jormas.2019.06.002\n- Liu, T., Tsang, W., Huang, F., Lau, O. Y., Chen, Y., Sheng, J., Guo, Y., Akinwunmi, B., Zhang, C. J., & Ming, W. K. (2021). Patients\u2019 Preferences for Artificial Intelligence Applications Versus Clinicians in Disease Diagnosis During the SARS-CoV-2 Pandemic in China: Discrete Choice Experiment. Journal of Medical Internet Research, 23(2), e22841. https:\/\/doi.org\/10.2196\/22841\n- Liu, X., Faes, L., Kale, A. U., Wagner, S. K., Fu, D. J., Bruynseels, A., Mahendiran, T., Moraes, G., Shamdas, M., Kern, C., Ledsam, J. R., Schmid, M. K., Balaskas, K., Topol, E. J., Bachmann, L. M., Keane, P. A., & Denniston, A. K. (2019). A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis. The Lancet Digital Health, 1(6), e271\u2013e297. https:\/\/doi.org\/10.1016\/s2589-7500(19)30123-2\n- Nagendran, M., Chen, Y., Lovejoy, C. A., Gordon, A. C., Komorowski, M., Harvey, H., Topol, E. J., Ioannidis, J. P. A., Collins, G. S., & Maruthappu, M. (2020). Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies. BMJ, m689. https:\/\/doi.org\/10.1136\/bmj.m689\n- Nagendran, M., Chen, Y., Lovejoy, C. A., Gordon, A. C., Komorowski, M., Harvey, H., Topol, E. J., Ioannidis, J. P. A., Collins, G. S., & Maruthappu, M. (2020b). Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies. BMJ, m689. https:\/\/doi.org\/10.1136\/bmj.m689\n- Shen, J., Zhang, C. J. P., Jiang, B., Chen, J., Song, J., Liu, Z., He, Z., Wong, S. Y., Fang, P. H., & Ming, W. K. (2019). Artificial Intelligence Versus Clinicians in Disease Diagnosis: Systematic Review. JMIR Medical Informatics, 7(3), e10010. https:\/\/doi.org\/10.2196\/10010\n- Toraman, S., Alakus, T. B., & Turkoglu, I. (2020). Convolutional capsnet: A novel artificial neural network approach to detect COVID-19 disease from X-ray images using capsule networks. Chaos, Solitons & Fractals, 140, 110122. https:\/\/doi.org\/10.1016\/j.chaos.2020.110122\n- Yadav, S. S., & Jadhav, S. M. (2019). Deep convolutional neural network based medical image classification for disease diagnosis. Journal of Big Data, 6(1). https:\/\/doi.org\/10.1186\/s40537-019-0276-2","68151bb1":"![Schermafbeelding 2021-12-13 om 14.06.16.png](attachment:414d6d6f-b6c1-47b6-8e53-56434f452415.png)","52d73e37":"![Schermafbeelding 2021-12-13 om 14.00.40.png](attachment:ecb0443e-b3b1-454a-94b6-6b82dcc45e26.png)\n\n","27b58e8f":"## Data Neural Network on Medical Image Classification\nThe dataset contains two kinds of chest X-ray Images: NORMAL and PNEUMONIA, which are stored in two folders.\nIn the PNEUMONIA folder, two types of specifc PNEUMONIA can be recognized by the fle name: BACTERIA and VIRUS.\n\n__Table 1.__ describes the composition of the dataset. The training dataset contains 5232 X-ray images, while the testing dataset contains 624 images. In the training dataset, the image in the NORMAL class only occupies one-fourth of all data. In the testing dataset, the PNEUMONIA consists of 62.5% of all data, which means the accuracy of the testing data should higher 62.5%.\n\n** **\n_Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), \u201cLabeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification\u201d, Mendeley Data, V2, doi: 10.17632\/rscbjbr9sj.2_","cc0ac21b":"# Load the data\nPrepare the data for training the CNN. The Chest X-ray data is given into three saperate folders: train, val, and test. Run following cell to set dataset path and other few variables which are used by ImageDataGenerator in next step.","34cb4fdf":"### How do Deep Learning Networks distinguish between healthy and unhealthy lungs?\n\nMost deep neural network applied to the task of pneumonia diagnosis have been adapted from natural image classification. These models have a large number of parameters as well as high hardware requirements, which makes them prone to overfitting and harder to deploy in mobile settings. Some research on medical image classification by CNN has achieved performances rivaling human experts. For example, CheXNet, a CNN with 121 layers trained on a dataset with more than 100,000 frontal-view chest X-rays (ChestX-ray 14), achieved a better performance than the average performance of four radiologists. \n\nConvolutional Neural Networks are a common form of deep networks for classification tasks. The CNNs have extensive learning capacity and can infer the nature of an input image without any prior knowledge, which makes them a suitable method for image classification. CNNs make use of the following three properties:\n\n1. First, units in each layer receive inputs from the previous units which are located in a small neighborhood. This way, elementary features such as edges and corners can be extracted. Then these features will be combined in next layers to detect higher order features. \n2. Second important property is the concept of shared weights, which means similar feature detectors are used for the entire image. \n3. Finally, CNNs usually have several sub-sampling layers. These layers are based on the fact that the precise location of the features are not only beneficial, but also harmful, because this information tends to vary for different instances (Yadav & Jadhav, 2019).\n\nCNN-based methods have various strategies to increase the performance of image classifcation: \n- One method is data augmentation. Where the traditional transform-based data augmentation has better performance than generative adversarial network (GAN) and other neural networkbased methods. \n- Another method is transfer learning An accuracy of 92% accuracy is already achieved on a small pneumonia X-rays image dataset by transfer learning. \n- The third method is the capsule network, which achieves state-of-the-art performance on the Modifed National Institute of Standards and Technology (MNIST) database. Afshar, Mohammadi, and Plataniotis (2018) have utilized a Capsule Neural Network to detect brain tumors and got 86.56% accuracy. \n\n----\nAlthough CNNs have been proved to be useful in many areas,\nthey have several drawbacks specially related to the sub-sampling\nlayers, because these layers give a small amount of translational invariance and they loose the exact location of the most active feature detectors. In addition, CNN's have a hard time with small datasets. \nThe shortcomings of CNNs are mostly related to the pooling layers.\n--> As a result, in Capsule networks, these layers are replaced with a more appropriate criteria called \u201crouting by agreement.\u201d\nCapsule networks can effectively classify even in a limited data set (Toraman, Alakus, Turkoglu, 2020). \n\n----\n\nMost of the experts got high sensitivity but low specificity, while the CNN-based system got high values on both sensitivity and specificity. Moreover, on the average weight error measure, the CNN-based system exceeds two human experts.\n\n\n\n","78dc9349":"There aren't enough files in the validation folder. To generate enough validation samples, we can try following things:\n\nSplit training data into train and validation (80:20) sets. To perform this specify validation_split parameter in ImageDataGenerator function. Set directory path to training directory so that the Generator can take data from training directory.\nTest generator Shuffle is set to FALSE. This is because, after predictions we want to plot our predictions to a Confusion Matrix and we want to be able to have one-one direct mapping of unshuffled samples.","f8bf4a1e":"- medicine: we are hired by the hospitle, First EDA with plots. How do docters distinguish between healthy and unhealthy lungs. \n- Then replicate \n- Then original new idea. Can be different architecture, if that makes sense. Can treat them all as hyperparameters to see which are best. \n- Little more consideration of the problem. Can you integrate data from a different place. What can you subtracts as features by hand. Hypotheses test between data augmentation (color flips not, but horizontal flips makes more sense)\n\nSome smart considerations of the problem as part of your notebook. \nI would always link it to medical, or diagnosis based on images papers. Articles newer than the dataset. Typification of misclassifications. What are the types of images where the model performs poorly. What types of images you got mispredictions. Usually you define a range of the hyperparameters (3, 4, 5, layes, this many nodes, max_pooling) list of combinations and will go through them. Only select the best one. You can only be better by thinking more about the problem, and caring about the mispredictions. \"oke Accuracy of 93, but we should look into sensitivity and specificity. Maybe in medical context these are more important. False negative more important, so optimize for sensitivity\"\nYou need to get creative there, and it just has to show that you care about the problem youre analysing. \n\nGrading: not accuracy, 100% on having a nice notebook (understanadble, citations, explanations, comments, graphs, pictures) just super readable. Engaging and readable. \nBAD: if it is copy pasted, problem, hyperparameter training, score. No creative additional original idea or perspective on the problem. Not more text than you need. \nthe less text, the better, the more informative plots, the better, extra points on creativity (make it original)\nJust add a nice original twist. \nPlanning: until next week you should have a skeleton: notebook with EDA, some model, some accuracy score and replicates some better earlier versions, and then start adding your project specific ideas.  \nClear goals until next week.","8aad485d":"### Typification of misclassifications\n\n- What are the types of images where the model performs poorly.\n","0814bf85":"### How do doctors distinguish between healthy and unhealthy lungs?\n\n__Figure 1.__ shows examples of chest X-rays from the dataset. The normal chest X-ray (left panel) depicts clear lungs without any areas of abnormal opacifcation in the image.\n\nBacterial pneumonia (middle) typically exhibits a focal lobar consolidation, in the right upper lobe (red rectangle), whereas viral pneumonia (right) manifests with a more difuse interstitial pattern in both lungs (Kermany et al., 2018).\n\n** **\n_Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), \u201cLabeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification\u201d, Mendeley Data, V2, doi: 10.17632\/rscbjbr9sj.2_\n\n\n\n**Figure 1**\n\n"}}