{"cell_type":{"2f7eab06":"code","86ca8255":"code","33dd70d9":"code","8a71cbbb":"code","8cb33eae":"code","268dbf13":"code","4f0ae1ac":"code","8f18da5f":"code","d974ac27":"markdown"},"source":{"2f7eab06":"#load in packages\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import confusion_matrix, make_scorer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.ensemble import EasyEnsembleClassifier\n\n\nrandom_state=7","86ca8255":"df = pd.read_csv('..\/input\/heart-disease-health-indicators-dataset\/heart_disease_health_indicators_BRFSS2015.csv')","33dd70d9":"pd.set_option('display.max_columns', 500)\ndf.head()","8a71cbbb":"#select HeartDiseaseorAttack as target variable:\ny = df['HeartDiseaseorAttack']\n\n#select all the other columns minus HeartDiseaseorAttack as the feature variables:\nX = df.drop(['HeartDiseaseorAttack'],axis=1)","8cb33eae":"#now make the train-test splits\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)\nprint('Dimensions: \\n x_train:{} \\n x_test{} \\n y_train{} \\n y_test{}'.format(x_train.shape, x_test.shape, y_train.shape, y_test.shape))","268dbf13":"#create true negative, false positive, false negative, and true positive \ndef tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\ndef fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\ndef fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\ndef tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]","4f0ae1ac":"#Setup classifier scorers\nscorers = {'Accuracy': 'accuracy', \n           'roc_auc': 'roc_auc', \n           'Sensitivity':'recall', \n           'precision':'precision',\n            'tp': make_scorer(tp), \n           'tn': make_scorer(tn),\n           'fp': make_scorer(fp), \n           'fn': make_scorer(fn)}                                                                                                              ","8f18da5f":"#change this name here to change the print name\nclassifier_name = 'Easy Ensemble'\n\nstart_ts=time.time()\n#try swapping out the classifier for random forest instead\n#clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3,criterion='entropy', class_weight='balanced', random_state=random_state)   \nclf = EasyEnsembleClassifier(n_estimators=10)\nscores = cross_validate(clf, X, y, scoring=scorers, cv=5)          \n\nSensitivity = round(scores['test_tp'].mean() \/ (scores['test_tp'].mean() + scores['test_fn'].mean()),3)*100   #TP\/(TP+FN) also recall\nSpecificity = round(scores['test_tn'].mean() \/ (scores['test_tn'].mean() + scores['test_fp'].mean()),3)*100    #TN\/(TN+FP)\nPPV = round(scores['test_tp'].mean() \/ (scores['test_tp'].mean() + scores['test_fp'].mean()),3)*100           #PPV = tp\/(tp+fp) also precision\nNPV = round(scores['test_tn'].mean() \/ (scores['test_fn'].mean() + scores['test_tn'].mean()),3)*100           #TN(FN+TN)\n\nscores_Acc = scores['test_Accuracy']                                                                                                                                    \nprint(f\"{classifier_name} Acc: %0.2f (+\/- %0.2f)\" % (scores_Acc.mean(), scores_Acc.std() * 2))                                                                                                    \nscores_AUC = scores['test_roc_auc']                                                                     #Only works with binary classes, not multiclass                  \nprint(f\"{classifier_name} AUC: %0.2f (+\/- %0.2f)\" % (scores_AUC.mean(), scores_AUC.std() * 2))      \nscores_sensitivity = scores['test_Sensitivity']                                                                     #Only works with binary classes, not multiclass                  \nprint(f\"{classifier_name} Recall: %0.2f (+\/- %0.2f)\" % (scores_sensitivity.mean(), scores_sensitivity.std() * 2)) \nscores_precision = scores['test_precision']                                                                     #Only works with binary classes, not multiclass                  \nprint(f\"{classifier_name} Precision: %0.2f (+\/- %0.2f)\" % (scores_precision.mean(), scores_precision.std() * 2))                          \nprint(f\"{classifier_name} Sensitivity = \", Sensitivity, \"%\")\nprint(f\"{classifier_name} Specificity = \", Specificity, \"%\")\nprint(f\"{classifier_name} PPV = \", PPV, \"%\")  \nprint(f\"{classifier_name} NPV = \", NPV, \"%\")\n\nprint(\"CV Runtime:\", time.time()-start_ts)","d974ac27":"# Example Model - EasyEnsembleClassifier\nTo get the ball rolling for others I chose a model that's a little less common. Try out Logistic Regression, Random Forests, SVMs, Neural Networks, XGBoost, etc. to see what works and what doesn't. Practice dealing with the class imbalance!\n\nEasyEnsembleClassifier Documentation: https:\/\/imbalanced-learn.org\/stable\/references\/generated\/imblearn.ensemble.EasyEnsembleClassifier.html"}}