{"cell_type":{"78cb54eb":"code","db8e65b7":"code","b0b491d8":"code","bf646b3f":"code","9daf875b":"code","db9e6f1f":"code","06f395df":"code","24fa1664":"code","6c287711":"code","af80e915":"code","7c3fa7ac":"code","1e3a14ca":"code","c28c17e2":"code","0964e68a":"code","2039c032":"code","8b796a24":"code","b1ba9430":"code","9aa98237":"code","cc8dd85e":"code","9eac828b":"code","f64c19bc":"markdown","40f2fbaf":"markdown","a4ff523a":"markdown","3f6c76a5":"markdown","cb323db6":"markdown","c3a6f5e9":"markdown","f0c7caa6":"markdown","89c55de1":"markdown","8289e1f4":"markdown","2e41a232":"markdown","d5d0615b":"markdown","a2cca7a7":"markdown","8d2cd06a":"markdown"},"source":{"78cb54eb":"\nimport numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","db8e65b7":"path = \"\/kaggle\/input\/test-file\/tested.csv\"\ndf = pd.read_csv(path)\n%config Completer.use_jedi = False\ndf.head()","b0b491d8":"df.isna().sum()\n","bf646b3f":"#Since from above we see missing values is Cabin column are 327 out of 417 so it would be better to drop it..\ndft = df.drop([\"Cabin\"],axis=1)","9daf875b":"dft.shape","db9e6f1f":"#we may replace missing 87 age values with average age\ndft2 = dft.replace(np.nan,df.Age.mean() )","06f395df":"dft2.isna().sum()\n","24fa1664":"dft3 = dft2.drop([\"SibSp\"],axis=1)\ndft3.info()","6c287711":"# Removing row at index 1\ndft3[dft3.PassengerId != 893].head()","af80e915":"dft3.duplicated().sum()","7c3fa7ac":"dft3.duplicated(subset=['Ticket']).value_counts()","1e3a14ca":"len(dft3)","c28c17e2":"len(dft3.drop_duplicates(subset=['Ticket']))","0964e68a":"dft3.groupby('Pclass').count()","2039c032":"dft3.groupby(['Sex','Survived'])['Age'].mean()","8b796a24":"def uppercase(x):\n    return x.upper()\n# Apply function, show two rows\ndft3['Sex'].apply(uppercase)[0:4]","b1ba9430":"# Load libraries\nimport pandas as pd\nimport numpy as np\n# Create date range\ntime_index = pd.date_range('06\/06\/2017', periods=100000, freq='30S')\n# Create DataFrame\ndataframe = pd.DataFrame(index=time_index)\n# Create column of random values\ndataframe['Sale_Amount'] = np.random.randint(1, 10, 100000)","9aa98237":"# Group rows by week, calculate sum per week\ndataframe.resample('W').sum()","cc8dd85e":"dft3.groupby('Sex').apply(lambda x: x.count())\n","9eac828b":"import pandas as pd\n# Create DataFrame\ndf1 = {'employee_id': [k for k in range(1,11)],\n                  'name': ['Amy Jones', 'Allen Keys', 'Alice Bees', 'Tim Horton','Amy Jones', \n                           'Allen Keys', 'Alice Bees', 'Tim Horton','Alice Bees', 'Tim Horton']\n                }\ndf1 = pd.DataFrame(df1, columns = ['employee_id','name'])\n# Create DataFrame\ndf2 = {'employee_id': [k for k in range(11,21)],\n       'name': ['Amy Jones', 'Allen Keys','Amy Jones', 'Allen Keys','Amy Jones', 'Allen Keys',\n                'Amy Jones', 'Allen Keys','Amy Jones', 'Allen Keys']\n      }\ndf2 = pd.DataFrame(df2, columns = ['employee_id','name'])\nframes = [df1, df2]\npd.concat(frames)","f64c19bc":"#### drop duplicates on specific column(s)-","40f2fbaf":"#### 1.  finding perfectly duplicated columns i.e. entire row values are same","a4ff523a":"# 8. group rows by time","3f6c76a5":"# 7. Write a code to apply functions over all elements in a column.","cb323db6":"# 3.write a code to delete a row.","c3a6f5e9":"# 1. Write the logic and code to handle missing values.","f0c7caa6":"#### 2. duplicates on specific column(s), use subset.","89c55de1":"# 9. write a code to apply function to groups.\n","8289e1f4":"# 4. write a code to find duplicate rows.\n","2e41a232":"# 6. Write a code to group rows by values.\n","d5d0615b":"# 5. write a code to delete duplicate rows.\n\n","a2cca7a7":"# 10. write a code to create 2 data frames which contain first ten and last 10 values. Now merge both data frames into one.","8d2cd06a":"# 2.Write a code to delete a column."}}