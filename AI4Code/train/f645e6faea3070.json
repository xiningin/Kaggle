{"cell_type":{"3d3afc38":"code","52f065a6":"code","4413ccc2":"code","16582754":"code","14c3d874":"code","caece588":"code","0c6b7dc8":"code","6e226486":"code","210bb88f":"code","febed08c":"code","fa3141e0":"code","6d123963":"code","217d991e":"code","3268070b":"code","42e6ea8c":"code","529b520c":"code","f9603165":"code","89899e20":"code","bdbf4270":"markdown","b6026d0a":"markdown"},"source":{"3d3afc38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","52f065a6":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","4413ccc2":"pip install pycaret","16582754":"df = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")","14c3d874":"df_train=df.drop(columns=\"id\", axis=1)","caece588":"from pycaret.regression import *\nexp_reg = setup(data = df_train, \n                target = 'target', #target column\n                session_id=123,  #random states\n                use_gpu = True,  #activating GPU ->> use_gpu=True \n                silent=True,      # Runs the command without user input\n               normalize = True,\n                transformation = True,\n                ignore_low_variance = True,\n                remove_multicollinearity = True,\n                multicollinearity_threshold = 0.95)  ","0c6b7dc8":"\nlightgbm = create_model('lightgbm')\n","6e226486":"xgboost = create_model('xgboost')\n","210bb88f":"catboost = create_model('catboost')","febed08c":"tune_lightgbm=tune_model(lightgbm, optimize=\"RMSE\")","fa3141e0":"tune_xgboost=tune_model(xgboost, optimize=\"RMSE\")","6d123963":"tune_catboost=tune_model(catboost, optimize=\"RMSE\")","217d991e":"blender_specific = blend_models(estimator_list = [tune_xgboost,tune_lightgbm,tune_catboost], fold=10)","3268070b":"blender_specific","42e6ea8c":"blender_specifictuned = predict_model(blender_specific, data = df_test)\nsample_submission['target'] = blender_specifictuned['Label']\nsample_submission.to_csv('blender_specifictuned.csv',index=False)\nsample_submission.head()","529b520c":"blender_specific2 = blend_models(estimator_list = [tune_xgboost,tune_lightgbm], fold=10)","f9603165":"blender_specifictuned_2 = predict_model(blender_specific2, data = df_test)\nsample_submission['target'] = blender_specifictuned_2['Label']\nsample_submission.to_csv('blender_specifictuned_2.csv',index=False)\nsample_submission.head()","89899e20":"#plotting the feature importance\n#plot_model(tune_lightgbm, plot = 'feature')    #change the model to check the feature importance\n","bdbf4270":"**blending individually**","b6026d0a":"PyCaret solution"}}