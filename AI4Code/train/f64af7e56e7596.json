{"cell_type":{"309c11d5":"code","1a8668ab":"code","e824c070":"code","8cfc0920":"code","0f6311d4":"code","b26f80f9":"code","9dd8c6ad":"code","c429bd13":"code","6e1ce001":"code","eb56636d":"code","20d3c48c":"code","a3da9798":"code","e48461f5":"code","2545c712":"code","eaaec40b":"code","a8105dae":"code","3febb1ce":"code","edb5114d":"code","f05d2de7":"code","c9bf8c8f":"code","b9f9eedc":"code","6961342a":"code","a3003d1a":"code","0f1c82d7":"code","1ceecc59":"code","53e75d0b":"code","c86231d2":"code","b9a6e719":"code","09270a9f":"code","f2c1ec40":"code","9482dc93":"code","2058f77c":"code","cd2ae133":"code","9bbc93eb":"markdown","928c5737":"markdown","257d3421":"markdown","60b49ae8":"markdown","cdad6824":"markdown","59488f07":"markdown","5b0bd6ac":"markdown","9ad5f078":"markdown","19c76f56":"markdown"},"source":{"309c11d5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","1a8668ab":"#Loading necessary packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mlxtend.frequent_patterns import apriori \nfrom mlxtend.preprocessing import TransactionEncoder\n\n# Warnings\n# import warnings\n# warnings.filterwarnings('ignore')\n\n# Style\nsns.set(style='darkgrid')\nplt.rcParams[\"patch.force_edgecolor\"] = True","e824c070":"groceries=pd.read_csv(\"\/kaggle\/input\/groceriesdata\/Groceries.csv\",header=None) #reading data\ngroceries.shape\n","8cfc0920":"groceries.dropna(how=\"all\",inplace=True) #drop rows with all missing values\ngroceries.shape","0f6311d4":" \ngroceries.tail() #column 9001 has values in between\n","b26f80f9":"groceries.loc[9001,:] = groceries.loc[9001,:].shift(-26) #shifting the values to left\ngroceries.tail()","9dd8c6ad":"# Converting dataframe into list of lists\nrecords=[]\nfor i in range (0,7835):\n    records.append([str(groceries.values[i,j]) for j in range (0,32)])\nrecords=np.array(records)\nprint(records.shape)\nprint(records[:2])","c429bd13":"#deleteing the missing values\nnew_record=[]\nfor j in records:\n    j=[j for j in j if str(j) != 'nan']\n    new_record.append(j)\nnew_record[:2]","6e1ce001":"#Converting entire data into a single list to plot frequency of each item\nb=[j for i in records for j in i]\nb=[b for b in b if str(b)!='nan']\nprint(b[:2])  \nprint(len(b)) ","eb56636d":"#Frequency Plot\nplt.rcParams['figure.figsize'] = (18, 7)\ncolor = plt.cm.ocean(np.linspace(0, 1, 40))\npd.DataFrame(b)[0].value_counts().head(20).plot.bar(color = color)\nplt.title('Frequency Plot for Top 20 Products', fontsize = 30)\nplt.xticks(rotation = 90 ,fontsize=20)\nplt.grid(b=False)\nplt.show()","20d3c48c":"y = pd.DataFrame(b)[0].value_counts().head(50).to_frame()\ny.index\nimport squarify\nplt.rcParams['figure.figsize'] = (20, 20)\ncolor = plt.cm.cool(np.linspace(0, 1, 50))\nsquarify.plot(sizes = y.values, label = y.index, alpha=.8, color = color)\nplt.title('Tree Map for top 50 Popular Items',fontsize=30)\nplt.axis('off')\nplt.savefig('books_read.png')\nplt.show()","a3da9798":"groceries[\"frequency\"] = groceries.notnull().sum(axis=1)\ngroceries[\"frequency\"].head()","e48461f5":"plt.rcParams['figure.figsize'] = (18, 7)\ncolor = plt.cm.rainbow(np.linspace(0, 1, 40))\ngroceries[\"frequency\"].value_counts().plot.bar(color = color)\nplt.title('Product frequency per transaction', fontsize = 30)\nplt.xticks(rotation = 45 ,fontsize=15)\nplt.grid(b=False)\nplt.show()","2545c712":"groceries.drop(\"frequency\",axis=1,inplace=True)","eaaec40b":"te = TransactionEncoder()\ngroceries = te.fit(new_record).transform(new_record)\ngroceries = pd.DataFrame(groceries, columns = te.columns_)\ngroceries.head()\n","a8105dae":"groceries.drop('`',axis=1,inplace=True) #false entry in data","3febb1ce":"from mlxtend.frequent_patterns import apriori\n\n#Now, let us return the items and itemsets with suitable support:\nrule_size = []\nfor i in np.arange(0.01,0.1,0.005):\n    rule = apriori(groceries, min_support = i, use_colnames = True)\n    size=rule.shape[0]\n    rule_size.append(size)\nprint(rule_size)   #179 rules were considered based on the support(1.5%)\n","edb5114d":"#Choosing a suitable support\nplt.figure(figsize=(16, 6))\nax = sns.lineplot(np.arange(0.01,0.1,0.005),rule_size)\nax.set_xlabel(\"Support\",fontsize=20)\nax.set_ylabel(\"Number of rules\",fontsize=20)\nax.grid(False)","f05d2de7":"rules_final = frequent_items=apriori(groceries, min_support = 0.015, use_colnames = True) \nrules_final.shape","c9bf8c8f":"from mlxtend.frequent_patterns import association_rules\n #Choosing a suitable confidence metric\nrule_size = []\nfor i in np.arange(0.1,1,0.05):\n    rule = association_rules(rules_final, metric=\"confidence\", min_threshold=i)\n    size=rule.shape[0]\n    rule_size.append(size)\nprint(rule_size)","b9f9eedc":"#Choosing a suitable confidence\nplt.figure(figsize=(16, 6))\nax = sns.lineplot(np.arange(0.1,1,0.05),rule_size)\nax.set_xlabel(\"Confidence\",fontsize=20)\nax.set_ylabel(\"Number of rules\",fontsize=20)\nax.grid(False)","6961342a":"final_rule = association_rules(rules_final, metric=\"confidence\", min_threshold=0.35)\nfinal_rule.shape","a3003d1a":"final_rule.sort_values(\"lift\",ascending=False)[:10] #top 10 rules based on lift","0f1c82d7":"final_rule.sort_values(\"confidence\",ascending=False)[:10] #top 10 rules based on confidence \n#","1ceecc59":"#Finding length of antecedents\nfinal_rule['length'] = final_rule['antecedents'].apply(lambda x: len(x))\n","53e75d0b":"#thetopfinalrules\nf = final_rule[ (final_rule['length'] == 1) &\n                   (final_rule['lift'] >= 1.8)  &\n                   (final_rule['confidence'] >= 0.35)]\nf","c86231d2":"testdata=pd.read_excel(\"..\/input\/testdata\/test.xlsx\")\ntestdata.shape","b9a6e719":"testdata.dropna(how='all',inplace=True)\ntestdata.shape","09270a9f":"#Preparing data\nstrings = []\nfor i in range(0,2000):\n    strings.append([str(testdata.values[i,j]) for j in range(0,25) ])\nnew=[]\nfor j in strings:\n    j=[j for j in j if str(j)!='nan']\n    new.append(j)\n","f2c1ec40":"te = TransactionEncoder()\nte_ary = te.fit_transform(new)\ndf = pd.DataFrame(te_ary, columns=te.columns_)\ndf.shape\n","9482dc93":"frequent_itemsets_test = apriori(df, min_support=0.015,use_colnames=True)","2058f77c":"rule_test = association_rules(frequent_itemsets_test, metric=\"confidence\",min_threshold=0.35)","cd2ae133":"pd.merge(rule_test,final_rule[['antecedents','consequents']],on = ['antecedents','consequents'] )","9bbc93eb":"## Importing Libraries","928c5737":"## Question no 4\n\n##Intesting rules","257d3421":"### TREE MAP","60b49ae8":"## Question no 5\n\n\n## Validating on test data","cdad6824":"## Question no 3","59488f07":"### DATA CLEANING","5b0bd6ac":"# Question 2 \n## FILTERING TRANSACTIONS\n","9ad5f078":"# TOP RULES","19c76f56":"## Question 1\n\n\n# DATA VISUALIZATION"}}