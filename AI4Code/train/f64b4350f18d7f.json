{"cell_type":{"bb45eb43":"code","d814f6d0":"code","658303e0":"code","aa1fc8c6":"code","d883fd88":"code","24e55982":"code","dc50d33c":"code","bfaf9aeb":"code","0aa93349":"code","7b070cf4":"code","5da2e917":"code","b60f6806":"code","8c1ad63a":"code","070ddee8":"code","bab37d73":"code","fcef8f20":"code","9c46041a":"code","ea3e456c":"code","0ae64c7e":"code","7a572855":"code","6c61e6f1":"markdown","66a330b7":"markdown","efeffb5a":"markdown","435b5814":"markdown","bbf12734":"markdown","3b2242c5":"markdown","482c6e73":"markdown","14b8e446":"markdown","3a7a4a45":"markdown","c6014f18":"markdown","b7955371":"markdown","6b3c203a":"markdown","393d897c":"markdown"},"source":{"bb45eb43":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d814f6d0":"train_data = pd.read_csv('\/kaggle\/input\/ghouls-goblins-and-ghosts-boo\/train.csv.zip')\ntest_data = pd.read_csv('\/kaggle\/input\/ghouls-goblins-and-ghosts-boo\/test.csv.zip')","658303e0":"print(\"Colums: \", train_data.columns.values)\nprint(\"Shape: \", train_data.shape)","aa1fc8c6":"print(\"Missing values:\")\nprint(train_data.isnull().sum())","d883fd88":"train_data.color.unique()","24e55982":"test_data = pd.concat([test_data,\n                pd.get_dummies(test_data.color, prefix=\"color\", drop_first = True)\n                 ], axis=1)\ntrain_data = pd.concat([train_data,\n                pd.get_dummies(train_data.color, prefix=\"color\", drop_first = True)\n                 ], axis=1)","dc50d33c":"test_id = test_data['id'].copy()\ntest_data.drop(['color','id'], axis=1, inplace=True)\ntrain_data.drop(['color','id'], axis=1, inplace=True)","bfaf9aeb":"print(\"Colums: \", train_data.columns.values)","0aa93349":"y=train_data['type']\nX=train_data.copy()\ndel X['type']\nprint(X)\nnp.shape(X)","7b070cf4":"y.unique()\nmy_map = {'Ghoul': 1, 'Goblin': 2, 'Ghost': 3}\ninv_map = {1: 'Ghoul', 2: 'Goblin', 3: 'Ghost'}\ny = y.map(my_map)\nprint(y)\n","5da2e917":"print(X)","b60f6806":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)","8c1ad63a":"from sklearn.preprocessing import normalize\nX_train_norm=normalize(X_train)\nX_test_norm=normalize(X_test)","070ddee8":"from sklearn.ensemble import GradientBoostingClassifier\n\n\n\nclf = GradientBoostingClassifier(learning_rate=0.1,\n                                 n_estimators=700,\n                                 max_depth=2)\n\nclf.fit(X_train_norm, y_train)\nprint(\"RF Accuracy: \" + repr(round(clf.score(X_test_norm, y_test) * 100, 2)) + \"%\")\n","bab37d73":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(criterion='entropy',\n                             n_estimators=700,\n                             min_samples_split=5,\n                             min_samples_leaf=1,\n                             max_features = \"auto\",\n                             oob_score=True,\n                             random_state=0,\n                             n_jobs=-1)\n\nclf.fit(X_train_norm, y_train)\nprint(\"RF Accuracy: \" + repr(round(clf.score(X_test_norm, y_test) * 100, 2)) + \"%\")","fcef8f20":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nclf=MLPClassifier(solver='adam',hidden_layer_sizes=350, alpha=1e-04, max_iter =120000)\nclf.fit(X_train_norm,y_train)\n\npreds=pd.Series(clf.predict(X_test_norm))\nprint(accuracy_score(y_test,preds))","9c46041a":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(C=1000000, max_iter=120000)\nclf.fit(X_train_norm,y_train)\npreds=pd.Series(clf.predict(X_test_norm))\nprint(accuracy_score(y_test,preds))","ea3e456c":"from sklearn.neighbors import KNeighborsClassifier\n\nclf= KNeighborsClassifier(n_neighbors=5)\nclf.fit(X_train_norm,y_train)\npreds=pd.Series(clf.predict(X_test_norm))\nprint(accuracy_score(y_test,preds))\n","0ae64c7e":"X_pred=test_data\nprint(X_pred)","7a572855":"from sklearn.preprocessing import normalize\n\nresult = pd.Series(clf.predict(normalize(X_pred)), name='type')\nresult = result.map(inv_map)\nresult = pd.concat([test_id,result], axis=1)\ndf=pd.DataFrame(result)\ndf.index+=1\nprint(result.shape)\nfilename = 'Prediction.csv'\ndf.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","6c61e6f1":"# MLPClassifier","66a330b7":"# GradientBoostingClassifier","efeffb5a":"# Analyze data\n\n**Describe data**\n\n* look at columns\n* check shape\n* check null columns","435b5814":"# Init MLP","bbf12734":"# KNeighborsClassifier","3b2242c5":"**Cool, there are no missing values =)**","482c6e73":"# Optimize labels","14b8e446":"# All colors","3a7a4a45":"# Load data","c6014f18":"# LogisticRegression [BEST]","b7955371":"# Feature Engineering\n\n* Categorical: 'color'\n* Numerical: 'bone_length' 'rotting_flesh' 'hair_length'\n","6b3c203a":"Transform color column to binary columns","393d897c":"# RandomForestClassifier"}}