{"cell_type":{"52984eb1":"code","c0397c34":"code","1ad574cc":"code","c412d199":"code","e8bdb4b0":"code","d23773ca":"code","c9c54645":"code","7ec4186b":"code","5b0cdbb0":"code","7ccb5d38":"code","c2e4a787":"code","5849fb43":"code","ddb1788a":"code","6b83eea6":"code","f76d3b32":"code","ea8be2db":"code","e3aff02b":"code","f869935e":"code","6ba397d9":"code","8c98af4e":"code","986581e3":"code","905b3c90":"code","6d1486fc":"code","fdcdc615":"code","b977b924":"code","dcc015d9":"code","c01de80d":"code","f7066cc4":"code","a7b553cb":"code","b0e02d4e":"code","1c6fdb87":"code","fa0516cc":"code","3cecf24e":"code","0465083a":"code","cfdb6e76":"code","18960b35":"code","c37df83d":"code","4c48f25a":"code","2135b3d5":"code","1cd0e632":"code","75d8f100":"code","53251419":"code","bada3913":"code","b3e05655":"code","4b875a32":"code","8557842b":"code","63decdc7":"code","025d72bf":"code","5075d274":"code","e93d7be2":"code","00870724":"code","a3282f8e":"markdown","fff6a12f":"markdown","2302e65e":"markdown","ca43c161":"markdown","c4dca2ec":"markdown","e6ab68e1":"markdown","78063777":"markdown","39c7fe8f":"markdown","6b57ce6e":"markdown","2abe0715":"markdown","e3ce3899":"markdown","21beb478":"markdown","62635673":"markdown","f19a03ae":"markdown","e3fc0c99":"markdown","983fe005":"markdown","099c80de":"markdown","b61360db":"markdown","7cff1ba5":"markdown"},"source":{"52984eb1":"def add_seven(x):\n    return x + 7\n\nlist(map(add_seven, [-1,0,1,2]))","c0397c34":"import re\n\nphone_numbers = [\n    \"(123) 456-7890\",\n    \"1234567890\",\n    \"123.456.7890\",\n    \"+1 123 456-7890\"\n]\n\nnew_numbers = []\n\nR = re.compile(r\"\\d\")                        ","1ad574cc":"R.findall(\"123.231.=3-131\")","c412d199":"for number in phone_numbers:                  \n    digits = R.findall(number)\n\n    area_code = \"\".join(digits[-10:-7])         \n    first_3 = \"\".join(digits[-7:-4])\n    last_4 = \"\".join(digits[-4:len(digits)])\n\n    correct_format = \"({}) {}-{}\".format(area_code,first_3,last_4)\n    new_numbers.append(correct_format)","e8bdb4b0":"new_numbers","d23773ca":"class PhoneFormatter:                              \n    \n    def __init__(self):                              \n        self.r = re.compile(r\"\\d\")\n    \n    def pretty_format(self, phone_number):           \n        phone_numbers = self.r.findall(phone_number)\n        area_code = \"\".join(phone_numbers[-10:-7])     \n\n        first_3 = \"\".join(phone_numbers[-7:-4])\n        last_4 = \"\".join(phone_numbers[-4:len(phone_numbers)])\n        return \"({}) {}-{}\".format(area_code, first_3, last_4)\n","c9c54645":"P = PhoneFormatter ()                         \n\nprint(list(map(P.pretty_format, phone_numbers)))","7ec4186b":"from datetime import date                                    \n\ndef days_between(start, stop):                                \n    today = date(*start)                                        \n    stop = date(*stop)\n    \n    while today < stop:   \n        datestr = today.strftime(\"%m-%d-%Y\")\n        yield \"http:\/\/jtwolohan.com\/arch-rival-blog\/\" + datestr\n        today = date.fromordinal(today.toordinal() + 1) ","5b0cdbb0":"from urllib import request\n\ndef get_url(path):\n    return request.urlopen(path).read()","7ccb5d38":"blog_posts = map(get_url, days_between((2000,1,1),(2000,1,2)))","c2e4a787":"blog_posts","5849fb43":"list(blog_posts)","ddb1788a":"import os\nos.cpu_count()","6b83eea6":"!python3 -c \"import os; print(os.cpu_count())\"","f76d3b32":"from datetime import date\nfrom urllib import request\n\nfrom multiprocessing import Pool\n\ndef days_between(start,stop):\n    today = date(*start)\n    stop = date(*stop)\n    while today < stop:\n        datestr = today.strftime(\"%m-%d-%Y\")\n        yield \"http:\/\/jtwolohan.com\/arch-rival-blog\/\" + datestr\n        today = date.fromordinal(today.toordinal() + 1)\n\ndef get_url(path):\n    return request.urlopen(path).read()\n\nwith Pool() as P:                                \n    blog_posts = P.map(get_url, days_between((2000,1,1),(2000,1,3)))","ea8be2db":"blog_posts","e3aff02b":"!pip install pathos","f869935e":"with Pool() as P:\n    blog_posts = P.map(get_url,days_between((2000,1,1),(2000,1,5)))","6ba397d9":"from pathos.multiprocessing import ProcessPool","8c98af4e":"with ProcessPool(nodes=2) as P:\n    blog_posts = P.map(get_url, days_between((2000,1,1),(2000,1,2)))","986581e3":"blog_posts","905b3c90":"with Pool() as P:\n    P.map(print,range(100))","6d1486fc":"def print_and_return(x):\n    print(x); return x\n\nwith Pool() as P:\n    P.map(print_and_return, range(20))","fdcdc615":"class FizzBuzzer:\n    \n    def __init__(self):\n        self.n = 0 \n        \n    def foo(self,_):           \n        self.n += 1              \n        if (self.n % 3)  == 0:   \n            x = \"buzz\"             \n        else: \n            x = \"fizz\"         \n        print(x)                 \n        return x                 \n\nFB = FizzBuzzer()            \nfor i in range(21):          \n    FB.foo(i)         ","b977b924":"FB = FizzBuzzer()\n\nwith Pool() as P:\n    P.map(FB.foo, range(21))","dcc015d9":"FB = FizzBuzzer()\nFB.n = 2\n\nwith Pool() as P:\n    P.map(FB.foo, range(21))","c01de80d":"def foo(n):\n    if (n % 3) == 0:\n        x = \"buzz\"\n    else: \n        x = \"fizz\"\n    print(x)\n    return x","f7066cc4":"with Pool() as P:\n    print(P.map(foo, range(1,22)))","a7b553cb":"import json\nfrom urllib import request, parse","b0e02d4e":"def link_to_title(link):\n    return link[\"title\"]\n\ndef clean_if_key(page,key):                                  \n    if key in page.keys():\n        return map(link_to_title,page[key])\n    else: \n        return []\n    \ndef get_wiki_links(pageTitle):                               \n    safe_title = parse.quote(pageTitle)                      \n    \n    url = \"https:\/\/en.wikipedia.org\/w\/api.php?action=query&prop=links|linkshere&pllimit=500&lhlimit=500&titles={}&format=json&formatversion=2\".format(safe_title)\n    page = request.urlopen(url).read()                       \n    \n    j = json.loads(page)                                     \n    \n    jpage = j[\"query\"][\"pages\"][0]\n    inbound = clean_if_key(jpage,\"links\")                    \n    \n    outbound = clean_if_key(jpage,\"linkshere\")\n    return {\"title\": pageTitle, \"in-links\":list(inbound), \"out-links\":list(outbound)}","1c6fdb87":"def flatten_network(page):\n    return page[\"in-links\"] + page[\"out-links\"]","fa0516cc":"root = get_wiki_links(\"Parallel_computing\")\ninitial_network = flatten_network(root)","3cecf24e":"print(f\"there {len(initial_network)} initial network comprising of in-links and out-links.\")","0465083a":"initial_network[:10]","cfdb6e76":"with Pool() as P:\n    all_pages = P.map(get_wiki_links, initial_network)","18960b35":"all_pages[:1]","c37df83d":"print(f\"there are {len(all_pages)} pages in total and their own a title value, in-links array and out-links arrays\")","4c48f25a":"def page_to_edges(page):\n    a = [(page['title'],p) for p in page['out-links']]\n    b = [(p,page['title']) for p in page['in-links']]\n    return a + b","2135b3d5":"root = get_wiki_links (\"Parallel_computing\")\ninitial_network = flatten_network(root)\n\nwith Pool() as P:\n    all_pages = P.map(get_wiki_links, initial_network)\n    edges = P.map(page_to_edges, all_pages)","1cd0e632":"from itertools import chain\n\nedges = chain.from_iterable(edges)\nedges","75d8f100":"len(list(edges))","53251419":"first_5_initial_network = initial_network[:5]","bada3913":"first_5_initial_network","b3e05655":"with Pool() as P:\n    all_pages = P.map(get_wiki_links, first_5_initial_network)\n    edges = P.map(page_to_edges, all_pages)","4b875a32":"edges = chain.from_iterable(edges)\nedges","8557842b":"import networkx as nx\n\nG = nx.DiGraph()","63decdc7":"for e in edges:\n    G.add_edge(*e)\n\nnx.readwrite.gexf.write_gexf(G,\".\/my_graph.gexf\")","025d72bf":"!ls -lha","5075d274":"input_data = [{\"headers\":(\"01\/19\/2018\",\"Mozilla\",300), \"response\":{\"text\":\"Hello world!\",\"encoding\":\"utf-8\"}},\n              {\"headers\":(\"01\/19\/2018\",\"Chrome\",404), \"response\":{\"text\":\"No page found\",\"encoding\":\"ascii\"}},\n              {\"headers\":(\"01\/20\/2018\",\"Mozilla\",300), \"response\":{\"text\":\"Yet another web page.\",\"encoding\":\"utf-8\"}}]","e93d7be2":"list(map(lambda row: row['response']['text'], input_data))","00870724":"def handle_heterogenous_date(value):\n    if type(value) == bool:\n        return not value\n    elif type(value) == int:\n        return value + 1\n    else:\n        return chr(ord(value) + 1) \n        \nlist(map(handle_heterogenous_date, [1, \"A\", False]))","a3282f8e":"## Exercices","fff6a12f":"```\n> list(edges)[:1][0][:10]\n[('16-bit', 'ASCII'),\n ('16-bit', 'Amiga'),\n ('16-bit', 'Apple II series'),\n ('16-bit', 'Apple III'),\n ('16-bit', 'Atari ST'),\n ('16-bit', 'Advanced Micro Devices'),\n ('16-bit', 'Athlon'),\n ('16-bit', 'Amiga 500'),\n ('16-bit', 'Amiga 1000'),\n ('16-bit', 'Amiga 500 Plus')]\n```","2302e65e":"## 2.1. AN INTRODUCTION TO MAP","ca43c161":"### 2.2.3. Order and parallelization","c4dca2ec":"we can load up Gephi, created the `.gefx` file, and view our graph. If you don\u2019t have Gephi installed, you can find it at https:\/\/gephi.org. Here is the graph tree of 2243 samples.","e6ab68e1":"The chain function allows us to treat `[[1,2,3],[1,2],[1,2,3]]` as if it was `[1,2,3,1,2,1,2,3]`.","78063777":"```\n> list(edges)\n[('16-bit', 'ASCII'),\n ('16-bit', 'Amiga'),\n ('16-bit', 'Apple II series'),\n ('16-bit', 'Apple III'),\n ('16-bit', 'Atari ST'),\n ('16-bit', 'Advanced Micro Devices'),\n ('16-bit', 'Athlon'),\n ...\n ('Wikipedia:Protection policy', '16-bit'),\n ('Wikipedia:Redirect', '16-bit'),\n ('Category:Redirects from moves', '16-bit'),\n ('4-bit', 'Advanced Micro Devices'),\n ...\n]\n```","39c7fe8f":"![](https:\/\/i.imgur.com\/kxOLg0O.png)","6b57ce6e":"This chapter is one of the chapters of the book, Mastering Large Datasets with Python. The key takeaway to learn something comes from applying each steps one by one which makes it easy to understand the concepts so, I have created this kernel to practice the source code of the chapter 2 while reading the book. You can also examine all the main chapters' code over the original GitHub repository of the book: https:\/\/github.com\/jtwool\/mastering-large-datasets","2abe0715":"### 2.1.1. Retrieving URLs with map","e3ce3899":"### 2.2.1. Processors and processing","21beb478":"### 2.2.2. Parallelization and pickling","62635673":"# Chapter 2. Accelerating large dataset work: Map and parallel computing","f19a03ae":"### 2.3.1. Visualizing our graph","e3fc0c99":"1. Parallelization is an effective way to speed up our programs but may come with a few problems. Earlier in this chapter, I named three. How many can you remember, and what are they?\n\n    * when a process is required in a linear order, we probably shouldn\u2019t do it in parallel. we could face inconsistent results\n    * when a process is depend on a state, we could face inconsistent results since the parallelization is state-independent\n    * be aware of some python objects are not pickable. That can cause our programs to not run.\n    \n    \n2. The map function is a key piece of how we\u2019ll approach large datasets in this book. Which sentence best describes the map function?\n\nmap transforms a sequence of data into a different, same-sized sequence.\n\n3. Parallelization is useful because it allows us to process large datasets more quickly. Which of the following explains how parallelization works?\n\nParallelization computes similar tasks on several compute resources.\n\n4. Which of the following is not a good use for pickling?\n\nLong-term storage where data integrity is key\n\n5. Use map to transform a list of dicts into only the page text, with this as your input data:\n\n```\n[{\"headers\":(01\/19\/2018,Mozilla,300),\n  \"response\":{\"text\":\"Hello world!\",\"encoding\"0:\"utf-8\"}},\n     {\"headers\":(01\/19\/2018,Chrome,404),\n  \"response\":{\"text\":\"No page found\",\"encoding\":\"ascii\"}},\n     {\"headers\":(01\/20\/2018,Mozilla,300),\n  \"response\":{\"text\":\"Yet another web page.\",\"encoding\":\"utf-8\"}}]\n```\n","983fe005":"6. Write a function that turns `[1, \"A\", False]` into `[2,\"B\",True]`.","099c80de":"## 2.3. PUTTING IT ALL TOGETHER: SCRAPING A WIKIPEDIA NETWORK","b61360db":"### 2.2.4. State and parallelization","7cff1ba5":"```\n> len(list(edges)) # fair enough to visualize\n2243\n```"}}