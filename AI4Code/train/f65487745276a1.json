{"cell_type":{"64f33391":"code","566e9fe7":"code","f10b527d":"code","b8c1d09b":"code","6ddd28fd":"code","8357c0d1":"code","98cd360a":"code","dffc6f07":"code","4cc110a3":"code","8b0002fc":"code","a65013d4":"code","df5753d4":"code","0c296e2b":"code","56eed534":"code","9a25a89e":"code","57a1508c":"code","efa0a2c9":"code","d743e80b":"markdown","4f29f7b0":"markdown","0c03214a":"markdown","1188793c":"markdown","622f32bd":"markdown","682f35c0":"markdown","b060b2d9":"markdown","47d216c2":"markdown","0c92936d":"markdown","4b52bb0c":"markdown","fb05da65":"markdown","8aae7311":"markdown","e966ed1e":"markdown","5fc86910":"markdown","be79f0cb":"markdown","d72780a6":"markdown"},"source":{"64f33391":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nfrom scipy.spatial import distance\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","566e9fe7":"#loading haarcascade_frontalface_default.xml\nface_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')","f10b527d":"import matplotlib.pyplot as plt\n#trying it out on a sample image\nimg = cv2.imread('..\/input\/face-mask-detection\/images\/maksssksksss244.png')\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4) #returns a list of (x,y,w,h) tuples\n\nout_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n\n#plotting\nfor (x,y,w,h) in faces:\n    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),1)\nplt.figure(figsize=(12,12))\nplt.imshow(out_img)","b8c1d09b":"MIN_DISTANCE = 130","6ddd28fd":"if len(faces)>=2:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        if label[i]==1:\n            cv2.rectangle(new_img,(x,y),(x+w,y+h),(255,0,0),1)\n        else:\n            cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,255,0),1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n            \nelse:\n    print(\"No. of faces detected is less than 2\")","8357c0d1":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras import Sequential\nfrom keras.layers import Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator","98cd360a":"#Load train and test set\ntrain_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\ntest_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'\nval_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation'","dffc6f07":"# Data augmentation\n\ntrain_datagen = ImageDataGenerator(rescale=1.0\/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\ntrain_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n\nval_datagen = ImageDataGenerator(rescale=1.0\/255)\nval_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n\ntest_datagen = ImageDataGenerator(rescale=1.0\/255)\ntest_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)","4cc110a3":"vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n\nfor layer in vgg19.layers:\n    layer.trainable = False\n    \nmodel = Sequential()\nmodel.add(vgg19)\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='sigmoid'))\nmodel.summary()","8b0002fc":"model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics =\"accuracy\")","a65013d4":"history = model.fit_generator(generator=train_generator,\n                              steps_per_epoch=len(train_generator)\/\/32,\n                              epochs=20,validation_data=val_generator,\n                              validation_steps=len(val_generator)\/\/32)","df5753d4":"model.evaluate_generator(test_generator)","0c296e2b":"sample_mask_img = cv2.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithMask\/1565.png')\nsample_mask_img = cv2.resize(sample_mask_img,(128,128))\nplt.imshow(sample_mask_img)\nsample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\nsample_mask_img = sample_mask_img\/255.0","56eed534":"model.predict(sample_mask_img)","9a25a89e":"model.save('masknet.h5')","57a1508c":"mask_label = {0:'MASK',1:'NO MASK'}\ndist_label = {0:(0,255,0),1:(255,0,0)}","efa0a2c9":"if len(faces)>=2:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(128,128))\n        crop = np.reshape(crop,[1,128,128,3])\/255.0\n        mask_result = model.predict(crop)\n        cv2.putText(new_img,mask_label[mask_result.argmax()],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n            \nelse:\n    print(\"No. of faces detected is less than 2\")","d743e80b":"### Detecting social distancing violations\n\nThis can be done by iterating over the coordinates of faces and calculating the distance for each possible pair, if the distance for a particular pair is less than MIN_DISTANCE then the bounding boxes for those faces are colored red. MIN_DISTANCE must be manually initialized in such a way that it corresponds to the minimum allowable distance in real life (ex. 6ft in India).","4f29f7b0":"# Mask and Social distancing Detection ","0c03214a":"#### Red boxes shows violation of social distancing.","1188793c":"### Testing the model on the test data","622f32bd":"![d8ce0480-9ac0-11ea-8062-809a1b8bfab6.png](attachment:d8ce0480-9ac0-11ea-8062-809a1b8bfab6.png)","682f35c0":"### Save the model.","b060b2d9":"**Social distancing**, also called **\u201cphysical distancing,\u201d** means keeping a safe space between yourself and other people who are not from your household.\n\nTo practice social or physical distancing, stay at least 6 feet (about 2 arm lengths) from other people who are not from your household in both indoor and outdoor spaces.","47d216c2":"### Using haar cascade to detect faces\n\nObject Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images. We'll be using a Haar Cascade Model trained to detect faces in order to obtain the bounding box coordinates of faces in an image.","0c92936d":"**Objective** is to build a Deep Learning model which can identify if the person is wearing a mask or not, also detecting if people vilating social distancing norms.","4b52bb0c":"#### Red box shows violation of social distancing.","fb05da65":"The model is able to classify if the person is wearing a mask or not.","8aae7311":"### Integrating with haar cascade","e966ed1e":"Our modela achieved 98% accuracy on test data.","5fc86910":"### Building VGG19 transfer learning model.","be79f0cb":"We now take crops of the faces detected in the image and use the model trained in the above section to determine whether the individual faces have a mask or not.","d72780a6":"### Using VGG19 for mask detection\n"}}