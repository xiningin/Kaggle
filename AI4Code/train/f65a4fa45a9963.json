{"cell_type":{"6596641a":"code","72d87c27":"code","a3593be2":"code","dfbc41be":"code","282572ca":"code","a4cdba14":"code","f91b5124":"code","7cc32c3c":"code","da4564d7":"code","12162bb7":"code","1f7ad66b":"code","2711d44b":"code","6288e9dc":"code","151b12a7":"code","a8a77748":"code","cd142b94":"code","71a20fe6":"code","94e2b998":"code","bb2671ed":"code","39703f97":"code","22126270":"code","ebc95999":"code","51ed30ca":"code","a9f1c1ae":"code","c098f673":"code","dcf3a24f":"code","2698961f":"code","50433fc3":"code","9e203ca9":"code","612ef765":"code","101c0793":"code","69a3aaf8":"code","1f278ce4":"code","ebee3f4a":"markdown","4138e71f":"markdown","b65e3977":"markdown","46dd694e":"markdown","158ec131":"markdown","21140b1d":"markdown","45927a79":"markdown","7c671cf5":"markdown","78f10d90":"markdown","2e2b5dd6":"markdown","d7ca1870":"markdown","76bc5716":"markdown","6d59c716":"markdown","4eaed80c":"markdown","867d069e":"markdown","27c19aa9":"markdown","701c97c4":"markdown","7a37868f":"markdown","eb8fc440":"markdown","6524bfac":"markdown","edaca1fc":"markdown","fd151623":"markdown","707a4dbf":"markdown","ed5b862c":"markdown","a8af3343":"markdown","3772d7c8":"markdown","6994da07":"markdown","e4820b89":"markdown","bc21a661":"markdown"},"source":{"6596641a":"import os\nimport numpy as np\nimport pandas as pd\n\n#plotting\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n#sklearn\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_validate, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.linear_model import Ridge\n\n#surprise package\nimport surprise\nfrom surprise import SVD, Dataset, Reader, accuracy\nfrom surprise.model_selection import cross_validate\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","72d87c27":"#read in data \nr_cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\nratings = pd.read_csv(\n    \"..\/input\/movielens-100k-dataset\/ml-100k\/u.data\",\n    sep=\"\\t\",\n    names=r_cols,\n    encoding=\"latin-1\",\n)\nratings.head()","a3593be2":"#plot\nfig = px.bar(ratings[\"rating\"].value_counts(normalize=True),\n            labels={'value':'Count of records (% of total)', 'index': 'Movie Rating'},\n            width=800, height=400,\n            title = \"Breakdown of movie ratings count\")\nfig.update_layout(showlegend=False)\nfig.show()","dfbc41be":"# get number of users and movies in the data\nuser_key = \"user_id\"\nitem_key = \"movie_id\"\n\nN = len(ratings[user_key].unique())\nM = len(ratings[item_key].unique())\n\nprint(f'Number of users (N): {N}')\nprint(f'Number of movies (M): {M}')","282572ca":"print(f'Fraction of non missing ratings in Utility Matrix Y: {round(len(ratings) \/ (N * M), 3)}')","a4cdba14":"print(f'Average number of ratings per user: {round(len(ratings) \/ N)}')\nprint(f'Average number of ratings per movie: {round(len(ratings) \/ M)}')","f91b5124":"#split data into train test splits\nX = ratings.copy()\ny = ratings[user_key]\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train.shape, X_valid.shape","7cc32c3c":"#create utility matrices for train and validation sets \nuser_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\nitem_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n# user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n# item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))\n\n# helper function to create utility matrix\ndef create_Ymatrix_from_ratings(data, N, M):\n    \"\"\"\n    function creates matrix from ratings df\n    \"\"\"\n    Y = np.zeros((N, M))\n    Y.fill(np.nan)\n    for index, val in data.iterrows():\n        n = user_mapper[val[user_key]]\n        m = item_mapper[val[item_key]]\n        Y[n, m] = val[\"rating\"]\n\n    return Y\n","da4564d7":"# create train and validation matrices using function\ntrain_mat = create_Ymatrix_from_ratings(X_train, N, M)\nvalid_mat = create_Ymatrix_from_ratings(X_valid, N, M)","12162bb7":"print(f'Shape of train_mat N x M: {train_mat.shape}')\nprint(f'Shape of valid_mat N x M: {valid_mat.shape}')","1f7ad66b":"# helper functions to calculate RMSE \ndef error(Y1, Y2):\n    \"\"\"\n    Returns the root mean squared error (RMSE).\n    \"\"\"\n    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n\n\ndef evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n    \"\"\"\n    Evaluates the train and validation RMSEs\n    \"\"\"\n    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))","2711d44b":"#predict every rating as the global average\nglobal_avg = np.nanmean(train_mat)\npred_g = np.zeros(train_mat.shape) + global_avg\n\n#evaluate\nevaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")","6288e9dc":"#predict every rating as the user average for each user\nuser_avg = np.nanmean(train_mat, axis=1)\n#user_avg[np.isnan(user_avg)] = avg\npred_n = np.tile(user_avg[:, None], (1, M))\n\n# evaluate\nevaluate(pred_n, train_mat, valid_mat, model_name=\"Per-user average\")","151b12a7":"#predict every rating as the movie average for each movie\nmovie_avg = np.nanmean(train_mat, axis=0)\n#avg_m[np.isnan(avg_m)] = avg\npred_m = np.tile(movie_avg[None, :], (N,1))\n\nevaluate(pred_m, train_mat, valid_mat, model_name=\"Per-movie average\")","a8a77748":"#predict every rating as the per-user and per-movie average\npred_nm = (user_avg[:, None] + movie_avg[None, :])\/2\nevaluate(pred_nm, train_mat, valid_mat, model_name = \"per-movie and per-user average\")","cd142b94":"#remove columns where all entries are NaN \nknn_train_mat = train_mat[:,~np.all(np.isnan(train_mat), axis=0)]\nknn_valid_mat = valid_mat[:,~np.all(np.isnan(train_mat), axis=0)]\n\nimputer = KNNImputer(n_neighbors=20)\nknn_preds = imputer.fit_transform(knn_train_mat)\n\n# evaluate\nevaluate(knn_preds, knn_train_mat, knn_valid_mat, model_name = \"Knn\")","71a20fe6":"#read in data and get train validation splits \nratings_drop = ratings.drop(columns = \"timestamp\")\n\nreader = Reader()\ndata = Dataset.load_from_df(ratings_drop, reader)  # Load the data\n\ntrainset, validset = surprise.model_selection.train_test_split(data, test_size=0.2, random_state=42) ","94e2b998":"# train model and evaluation\nk=10 #reduce number of dimensions to k \ns_svd = SVD(n_factors=k, random_state=42)\ns_svd.fit(trainset)\ns_svd_preds = s_svd.test(validset)\n\nresults = cross_validate(s_svd, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)\npd.DataFrame(results).mean()","bb2671ed":"#fit model\ntrainset, validset = surprise.model_selection.train_test_split(\n    data, test_size=0.2, random_state=42\n)\n\nk = 10\nalgo = SVD(n_factors=k, random_state=42)\nalgo.fit(trainset)\nsvd_preds = algo.test(validset)\naccuracy.rmse(svd_preds, verbose=True)","39703f97":"# Attributions: Functions below from Surprise package:\n# https:\/\/github.com\/NicolasHug\/Surprise\/blob\/master\/examples\/top_n_recommendations.py\n\nfrom collections import defaultdict\n\ndef get_top_n(predictions, n=10):\n    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n\n    Args:\n        predictions(list of Prediction objects): The list of predictions, as\n            returned by the test method of an algorithm.\n        n(int): The number of recommendation to output for each user. Default\n            is 10.\n\n    Returns:\n    A dict where keys are user (raw) ids and values are lists of tuples:\n        [(raw item id, rating estimation), ...] of size n.\n    \"\"\"\n\n    # First map the predictions to each user.\n    top_n = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        top_n[uid].append((iid, est))\n\n    # Then sort the predictions for each user and retrieve the k highest ones.\n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n\n    return top_n\n\n\ndef top_n_recs(user_id, n=5):\n    top_n = get_top_n(svd_preds, n=n)\n    return pd.DataFrame(top_n[user_id], columns=[\"movie_id\", \"pred\"])\n","22126270":"# get top 5 recommendations for 5 random users \nuser_id_sample = ratings[\"user_id\"].sample(5).to_list()\nn = 5\nfor user_id in user_id_sample:\n    print(\"\\nTop %d recommendations for user %d\" % (n, user_id))\n    print(top_n_recs(user_id))\n","ebc95999":"# read in data for u.item (movie )\ncols = [\n    \"movie_id\",\n    \"movie title\",\n    \"release date\",\n    \"video release date\",\n    \"IMDb URL\",\n    \"unknown\",\n    \"Action\",\n    \"Adventure\",\n    \"Animation\",\n    \"Children\",\n    \"Comedy\",\n    \"Crime\",\n    \"Documentary\",\n    \"Drama\",\n    \"Fantasy\",\n    \"Film-Noir\",\n    \"Horror\",\n    \"Musical\",\n    \"Mystery\",\n    \"Romance\",\n    \"Sci-Fi\",\n    \"Thriller\",\n    \"War\",\n    \"Western\",\n]\n\nmovies_data = pd.read_csv(\n    \"..\/input\/movielens-100k-dataset\/ml-100k\/u.item\",\n    sep=\"|\",\n    names=cols,\n    encoding=\"latin-1\",\n)\n","51ed30ca":"#take only the movie genre attributes\ngenres = [\n    \"Action\",\n    \"Adventure\",\n    \"Animation\",\n    \"Children\",\n    \"Comedy\",\n    \"Crime\",\n    \"Documentary\",\n    \"Drama\",\n    \"Fantasy\",\n    \"Film-Noir\",\n    \"Horror\",\n    \"Musical\",\n    \"Mystery\",\n    \"Romance\",\n    \"Sci-Fi\",\n    \"Thriller\",\n    \"War\",\n    \"Western\",\n]\nmovie_genres = movies_data[genres]\nmovie_genres.head()","a9f1c1ae":"Z = movie_genres.to_numpy()\nZ.shape","c098f673":"print(\"Average number of genres per movie: %.1f\" % (Z.sum() \/ M))","dcf3a24f":"from collections import defaultdict\n\n# function creates X and y for each user for a supervised learning approach\ndef get_X_y_per_user(ratings_df, d=Z.shape[1]):\n    \"\"\"\n    Returns X and y for each user.\n\n    Parameters:\n    ----------\n    ratings_df : pandas.DataFrame\n         ratings data as a dataframe\n\n    d : int\n        number of item features\n\n    Return:\n    ----------\n        dictionaries containing X and y for all users\n    \"\"\"\n    lr_y = defaultdict(list)\n    lr_X = defaultdict(list)\n\n    for index, val in ratings_df.iterrows():\n        n = user_mapper[val[user_key]]\n        m = item_mapper[val[item_key]]\n        lr_X[n].append(Z[m])\n        lr_y[n].append(val[\"rating\"])\n\n    for n in lr_X:\n        lr_X[n] = np.array(lr_X[n])\n        lr_y[n] = np.array(lr_y[n])\n\n    return lr_X, lr_y","2698961f":"# call function and get X and y train\/valid for each user\nX_train_usr, y_train_usr = get_X_y_per_user(X_train);\nX_valid_usr, y_valid_usr = get_X_y_per_user(X_valid);","50433fc3":"# sanity check - users will have different number of rows (movies) because rows represent only movies the user has rated\nprint(\"User 1:\")\nprint(f'Shape of X_train_usr for one user (movies x genres): {pd.DataFrame(X_train_usr[1]).shape}')\nprint(f'Shape of y_train_usr for one user (movies x rating): {pd.DataFrame(y_train_usr[1]).shape}')\nprint(\"\")\nprint(\"User 25:\")\nprint(f'Shape of X_train_usr for another user (movies x genres): {pd.DataFrame(X_train_usr[25]).shape}')\nprint(f'Shape of y_train_usr for another user (movies x user rating): {pd.DataFrame(y_train_usr[25]).shape}')","9e203ca9":"# functions to train and predict ratings\ndef train_usr(user_name, model=Ridge()):\n    \"\"\"\n    train model; default uses Ridge Regression\n    \"\"\"\n    X = X_train_usr[user_name] \n    y = y_train_usr[user_name] \n    model.fit(X, y)\n    return model\n\n\ndef predict_usr(model):\n    \"\"\"\n    Predict ratings for movies\n    \"\"\"\n    feat_vecs = movie_genres\n    preds = model.predict(feat_vecs)\n    return preds","612ef765":"#train and predict for one user \nmodel_1 = train_usr(0)\npreds = predict_usr(model_1)\nrecon_x = pd.DataFrame(preds)\n\n#prediction for user 0\nrecon_x.head()","101c0793":"#train and predict for all users \nusers = range(1, train_mat.shape[0])\n\nfor i in users:\n    model = train_usr(i)\n    scores = predict_usr(model)\n    recon_x[i] = pd.DataFrame(scores)","69a3aaf8":"# prediction for all users and movies in the utility matrix\nrecon_x.T.head()","1f278ce4":"#evaluate content-based method\nevaluate(recon_x.T, train_mat, valid_mat, model_name=\"Content-Based filtering\")","ebee3f4a":"### Creating the  Utility Matrix ","4138e71f":"### 2. Setting up data for regression","b65e3977":"> KNN train has RMSE: 0.00 because KNNImpter is only filling in missing values, hence the perfect score","46dd694e":"## Content-based recommenders <a name=\"4\"><\/a>\n<hr> \n","158ec131":"<br>","21140b1d":"### 4. Evaluating Results","45927a79":"**K-Nearest Neighbours imputation for ratings**","7c671cf5":"<br>","78f10d90":"<br><br>","2e2b5dd6":"### Evaluation Metric\n\n\nThe evaluation metric used to measure the performance of various recommender systems will be RMSE (Root mean square error). \nRMSE calculates the error between the actual ratings and the predicted ratings.","d7ca1870":"**Per-user and per-movie average rating**","76bc5716":"**Global average rating baseline**","6d59c716":"### 3. Train model and Predict Ratings","4eaed80c":"<br><br>","867d069e":"## Exploring Baselines <a name=\"2\"><\/a>\n<hr>","27c19aa9":"> `train_mat` only has the ratings from X_train whereas `valid_mat` only has ratings from X_valid","701c97c4":"<br>","7a37868f":"<br>","eb8fc440":"## Imports <a name=\"im\"><\/a>","6524bfac":"### Getting top *n* predictions for users","edaca1fc":"## Collaborative filtering <a name=\"3\"><\/a>\n","fd151623":"**Per-user average rating baseline**","707a4dbf":"## Table of contents\n\n- [Imports](#im)\n- [Data and Setup](#1) \n- [Baselines](#2) \n- [Collaborative filtering](#3) \n- [Content-based recommendations](#4) \n","ed5b862c":"Using [`surprise`](https:\/\/surprise.readthedocs.io\/en\/stable\/) package's implementation of SVD for recommendation systems","a8af3343":"## Data and Setup <a name=\"1\"><\/a>\n<hr>\n","3772d7c8":"<br>","6994da07":"<br>","e4820b89":"### 1. Reading in `u.item` Data","bc21a661":"**Per-movie average rating baseline**"}}