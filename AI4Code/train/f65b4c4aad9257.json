{"cell_type":{"b93ff1a4":"code","2aebaebc":"code","002612f5":"code","50359c40":"code","7e2fea14":"code","e99aefb0":"code","27dbe11c":"code","70990736":"code","faf54efa":"code","b736fb92":"markdown"},"source":{"b93ff1a4":"###Importing the necessary libraries###\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import (Dataset,\n                              DataLoader)\nfrom torch.optim import lr_scheduler\nfrom torchvision import (datasets, \n                         transforms, \n                         models)\nfrom PIL import Image\nfrom sklearn.metrics import classification_report\nimport  time, copy, glob, torchvision, torch, os, json\npd.set_option('display.max_rows', 500)","2aebaebc":"###Defining the global variables###\nNUM_CLASSES = 102\nROOT_DIR = '..\/input\/flower_data\/flower_data'\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nDATA_TRANSFORMS = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\nCAT_TO_NAMES = json.load(open('..\/input\/cat_to_name.json', 'r'))","002612f5":"class FlowerDS(Dataset):\n    def __init__(self, root, phase, transforms):\n        self.filenames = []\n        self.root = root\n        self.phase = phase\n        self.transform = transforms\n        self.classes = os.listdir(root)\n        self.labels = []\n        if self.phase == 'test':\n            filenames = glob.glob(os.path.join(root, '*'))\n            self.filenames.extend(filenames)\n        else:\n            for dir in os.listdir(root):\n                path = os.path.join(self.root, dir)\n                filenames = glob.glob(os.path.join(path, '*'))\n                for fn in filenames:\n                    self.filenames.append(fn)\n                    self.labels.append(int(dir)-1)\n        self.labels = np.array(self.labels)\n        self.len = len(self.filenames)\n        \n    def __getitem__(self, index):\n        image = Image.open(self.filenames[index])\n        image = image.convert('RGB')\n        if self.phase == 'train':\n            if (torch.randn(1)[0] > 0):\n                if(torch.randn(1)[0] < 0):\n                    image = transforms.functional.adjust_gamma(image, gamma = 0.5)\n                else: image = transforms.functional.adjust_gamma(image, gamma = 1.0)\n        image = self.transform(image)\n        if (self.phase == 'test'):\n            return image\n        return image, self.labels[index]\n\n    def __len__(self):\n        return self.len","50359c40":"###Defining all the required funtions###\ndef get_count_per_class(data_dir, phase = 'train'):\n    train_labels_count = [0]*NUM_CLASSES\n    phase_path = os.path.join(data_dir, phase)\n    for ind, dir in enumerate(os.listdir(phase_path)):\n        path, dirs, files = next(os.walk(os.path.join(phase_path, dir)))\n        file_count = len(files)\n        train_labels_count[ind] = file_count\n    return train_labels_count\n\ndef plot_images_per_class(labels_count=None, phase = 'train'):\n    if (labels_count is None):\n        labels_count = get_count_per_class(phase)\n    plt.figure()\n    f, ax = plt.subplots(figsize=(25,10))\n    plt.bar(np.arange(102), labels_count)\n    plt.xticks(np.arange(102), np.arange(102))\n    plt.ylabel(\"No. of samples\")\n    plt.xlabel(\"Classes\")\n    plt.title(phase)\n    plt.show()\n    \ndef plot_xy(x, y, title=\"\", xlabel=\"\", ylabel=\"\"):\n    plt.figure()\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    for i in range(len(y)):\n        plt.plot(x, y[i], label = str(i))\n    plt.show()\n\ndef create_dataset(data_dir, phase = 'train'):\n    #image_datasets = datasets.ImageFolder(os.path.join(data_dir, phase), DATA_TRANSFORMS[phase])\n    image_dataset = FlowerDS(os.path.join(data_dir, phase), phase = phase, transforms = DATA_TRANSFORMS[phase])\n    return image_dataset\n\ndef get_data_loader(data_dir, phase = 'train', batch_size = 64, doShuffle = True, no_workers = 4):\n    image_dataset = create_dataset(data_dir, phase=phase)\n    return DataLoader(image_dataset, batch_size=batch_size, shuffle=doShuffle, num_workers=no_workers)\n\ndef train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    losses = {'train': [], 'valid':[]}\n    acc = {'train': [], 'valid': []}\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(DEVICE)\n                labels = labels.to(DEVICE)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            losses[phase].append(epoch_loss)\n            acc[phase].append(epoch_acc)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n            if (phase == 'valid' and epoch + 1 == num_epochs):\n                print (\"--------------\")\n                print (\"Final Classification Report\")\n                print (\"--------------\")\n                print (classification_report(preds.cpu(), labels.cpu()))\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    plot_xy(np.arange(num_epochs), [losses['train'], losses['valid']], xlabel = 'Epochs', ylabel = 'Loss', title = 'Loss Plot')\n    plot_xy(np.arange(num_epochs), [acc['train'], acc['valid']], xlabel = 'Epochs', ylabel = 'Accuracy', title = 'Accuracy Plot')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\ndef do_transform(path, gammas):\n    image = Image.open(path)\n    for gamma in gammas:\n        new_image = transforms.functional.adjust_gamma(image, gamma = gamma)\n        plt.figure()\n        plt.imshow(new_image, aspect=1.0)\n\ndef save(model, path):\n    torch.save(model, path)\n\ndef load(path):\n    return torch.load(path)","7e2fea14":"###Analysis over the dataset and certain transforms###\ndataset_sizes = {x: len(create_dataset(ROOT_DIR, x)) for x in ['train', 'valid']}\nprint (\"Train Size : {0}\".format(dataset_sizes['train']))\nprint (\"Validation Size : {0}\".format(dataset_sizes['valid']))\ndo_transform(\"..\/input\/flower_data\/flower_data\/train\/24\/image_06816.jpg\", gammas = [0.5, 1.0, 2.0])\ntrain_labels_count = get_count_per_class(ROOT_DIR, phase='train')\nplot_images_per_class(train_labels_count, phase='train')","e99aefb0":"###Creating the model###\nmodel = models.resnet101(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, NUM_CLASSES)\nmodel = model.to(DEVICE)\nclass_weights = [1-(float(train_labels_count[class_id])\/(dataset_sizes['train'])) for class_id in range(NUM_CLASSES)]\ncriterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(DEVICE))\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","27dbe11c":"###Training the model###\ndoTrain = True\ndataloaders = {'train': get_data_loader(ROOT_DIR, 'train'),\n               'valid': get_data_loader(ROOT_DIR, 'valid', batch_size = len(create_dataset(ROOT_DIR, phase='valid')), doShuffle=False)}\nif doTrain:\n    model = train_model(dataloaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n    save(model, \"..\/working\/flower_classification.pt\")","70990736":"###Testing with random validation samples###\nwith torch.no_grad():\n    model.eval()\n    print (\"Evaluating random validation samples:\")\n    test_data, test_targets = next(iter(dataloaders['valid']))\n    outputs = model(test_data[0].unsqueeze(0).to(DEVICE))\n    _, pred = torch.max(outputs, 1)\n    print (\"Actual Class - {0}\".format(CAT_TO_NAMES[str(int(test_targets[0]) + 1)]))\n    print (\"Predicted Class - {0}\".format(CAT_TO_NAMES[str(int(pred) + 1)]))","faf54efa":"###Testing with the test set samples###\nLOAD_MODEL = False\nwith torch.no_grad():\n    if (LOAD_MODEL):\n        model = load(\"..\/working\/flower_classification.pt\")\n    model.eval()\n    print (\"Test set prediction results:\")\n    test_set = FlowerDS('..\/input\/test set\/test set', transforms=DATA_TRANSFORMS['valid'], phase='test')\n    test_loader = DataLoader(test_set, batch_size = len(test_set), shuffle=False)\n    test_data = next(iter(test_loader))\n    outputs = model(test_data.to(DEVICE))\n    _, pred = torch.max(outputs, 1)\n    results = []\n    for index, filename in enumerate(test_set.filenames):\n        results.append((filename.split(\"\/\")[-1], int(pred[index]) + 1, CAT_TO_NAMES[str(int(pred[index] + 1))]))\n    result_df = pd.DataFrame(results, columns=['Filename', 'Class ID', 'Class Name'])\n    result_df = result_df.sort_values(by=['Filename'])\n    print (result_df)\n    result_df.to_csv('..\/working\/test_results.csv')","b736fb92":"**Flower Classification - My Approach**\n1. The transfer learning approach is adopted to solve this classification problem.  Fine tuning a model which is already trained on a larger set in the same domain (i.e. image classification) gives an upperhand in solving the problem rather than training a model from zero knowledge.\n2. The pretrained model that has been choosen here is Resnet-101 as this model has the least top-5 error on Imagenet 1-crop dataset.  The advantage of Resnet (introduced by Microsoft) is that the model has a deeper architecture than a wider one.  The number of parameters to be trained in Resnet is comparatively smaller than its variants due to its shortcut connections.  This helps in training the model faster than the others.\n3. The dataset given for training is found to be unbalanced.  This has been clearly shown in the results obtained through analyzing a dataset where the difference between the class with highest number of samples and the one with the lowest is 8 fold.To mitigate this bias, the following steps have been taken.\n  * **Transforms** - One way of mitigating the unbalanced dataset problem is to do possible and suitable transformations at each iteration.  Along with the standard transformations that include randomized cropping, and flipping, gamma correction has also been done on the images.  This gamma correction helps in changing the intensity of the images.  In the dataset, one could notice that for the some flowers, the samples are given at different intensities.  To make it common to all the flower classes and simultaneously to augment the dataset, this has been done.  The gamma values were chosen empirically.\n  * **Weighted Criterion** - Even with the data augmentation approach, there is a high possibility of repetitive images for a class with minimum number of samples.  To overcome this, while penalizing the model for giving wrong prediction, the class with lesser no. of samples are given more weightage and are penalized more than the one with many samples to rectify the bias in the dataset.\n4.  The optimizer chosen is Adam and the learning rate is fixed to 0.0001 empirically.  The weight decay parameter is set to 1e-5 to decay the hyperparameters along with the learning rate.  The learning Rate Scheduler has been used to gradually change the learning rate over the training phase.  The step size is empirically set to 7 and gamma value is set to default.  The number of epochs is empirically set to 25 as the loss became saturated at that point.\n5.  The model which gave the best validation accuracy is saved for further testing.\n6.  In addition to accuracy and loss, the model's performance is also evaluated by finding the precision, recall, and f1-score for each of the class in the validation phase."}}