{"cell_type":{"02b92b4c":"code","d6914bb2":"code","7321f8f1":"code","3e26663c":"code","8c3d57ec":"code","120f6c7c":"code","a93653a2":"code","e09622f8":"code","7028e306":"code","ba0aa87f":"code","b0412532":"code","d214f25d":"code","690d3ce2":"code","aaf3d944":"code","30a274e9":"code","9e86149e":"code","618a529d":"code","b1815f37":"code","1b2d7cce":"code","c4c4ad7a":"code","835da81f":"code","adfb182c":"code","62f17ec9":"code","79e2f8b2":"code","f538560f":"code","8b712066":"code","c92c66d4":"code","a0abfc66":"code","7c93106a":"code","a50f519a":"markdown","a824b5ed":"markdown","364d00fe":"markdown","b2691499":"markdown","a2e04a94":"markdown"},"source":{"02b92b4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport cv2\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d6914bb2":"import tensorflow as tf\nprint(tf.__version__)\n# tested on tensorflow v2.1.0\n# Will not work on tensorflow v1","7321f8f1":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import model_from_json","3e26663c":"from tensorflow.keras import Model, Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\n# from tensorflow.keras import ImageDatagenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint","8c3d57ec":"DATA_PATH = '\/kaggle\/input\/mobile-gallery-image-classification-data\/mobile_gallery_image_classification\/mobile_gallery_image_classification'","120f6c7c":"print(os.listdir(DATA_PATH))","a93653a2":"train_path = os.path.join(DATA_PATH, 'train')\ntest_path = os.path.join(DATA_PATH, 'test')\n# print(os.listdir(train_path))\n# print(os.listdir(test_path))","e09622f8":"def show_samples_train(train_path, to_analyze):\n    for folder_name in os.listdir(train_path):\n        image_folder = os.path.join(train_path, folder_name)\n        count = 0\n        for image in os.listdir(image_folder):\n            image_path = os.path.join(image_folder, image)\n            if(count < to_analyze):\n                image = cv2.imread(image_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                plt.imshow(image)\n                plt.title(folder_name)\n                plt.xticks([])\n                plt.yticks([])\n                plt.show()\n                count += 1\n            else:\n                break","7028e306":"def show_samples_test(test_path, to_analyze):\n    count = 0\n    for image in os.listdir(test_path):\n        image_path = os.path.join(test_path, image)\n        if(count < to_analyze):\n                image = cv2.imread(image_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                plt.imshow(image)\n                plt.xticks([])\n                plt.yticks([])\n                plt.show()\n                count += 1\n        else:\n            break\n    ","ba0aa87f":"# Given the train folder it finds the distribution of the number of classes in it\ndef get_distribution_train(train_path, display=False):\n    lengths = {}\n    count = 0\n    for folder in os.listdir(train_path):\n        folder_path = os.path.join(train_path, folder)\n        length = len(os.listdir(folder_path))\n        count += length\n        lengths[folder] = length\n    \n    if display is True:\n        names = list(lengths.keys())\n        values = list(lengths.values())\n        plt.bar(range(len(lengths)), values, tick_label=names)\n        plt.show()\n    \n    print(\"Total number of classes in training folder = %d\"%(len(lengths)))\n    print(\"Total number of images in training folder = %d\"%(count))\n    return lengths    ","b0412532":"# to_analyze = 10 \n# Analyzing 10 images per folder\nshow_samples_train(train_path, to_analyze=10)","d214f25d":"# There anre only 7 images in the test folder will add more\n# to_analyze = 8\nshow_samples_test(test_path, to_analyze=8)","690d3ce2":"images_per_folder = get_distribution_train(train_path, display=True)","aaf3d944":"train_datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2,\n                                   height_shift_range=0.3, zoom_range=0.3,\n                                   channel_shift_range=0.0,\n                                   fill_mode='nearest', cval=0.0, horizontal_flip=True, vertical_flip=False, rescale=1\/255.,\n                                   data_format='channels_last', validation_split=0.3,\n                                   dtype='float32')","30a274e9":"val_datagen = ImageDataGenerator(rescale=1\/255.,\n                                   data_format='channels_last', validation_split=0.3,\n                                   dtype='float32')","9e86149e":"train_generator = train_datagen.flow_from_directory(train_path, target_size=(256,256), color_mode=\"rgb\", \n                                                    class_mode=\"categorical\", batch_size=64, subset=\"training\")","618a529d":"val_generator = val_datagen.flow_from_directory(train_path, target_size=(256,256), color_mode=\"rgb\", \n                                                    class_mode=\"categorical\", batch_size=64, subset=\"validation\")","b1815f37":"def make_model(i_shape=(256,256,1), o_shape=10):\n    model = Sequential()\n    \n    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=i_shape, activation='elu'))\n    model.add(layers.MaxPooling2D())\n    model.add(layers.BatchNormalization())\n\n    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='elu'))\n    model.add(layers.MaxPooling2D())\n    model.add(layers.BatchNormalization())\n\n    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='elu'))\n    model.add(layers.MaxPooling2D())\n    model.add(layers.BatchNormalization())\n\n    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='elu'))\n    model.add(layers.MaxPooling2D())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(rate=0.20))\n\n    model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), activation='elu'))\n    model.add(layers.MaxPooling2D())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(rate=0.20))\n\n#     model.add(Conv2D(filters=512, kernel_size=(3, 3), activation='elu'))\n# #     model.add(Activation(activation=elu))\n#     model.add(MaxPooling2D())\n#     model.add(BatchNormalization())\n\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(256, activation='elu'))\n    model.add(layers.Dropout(rate=0.20))\n    \n    model.add(layers.Dense(128, activation='elu'))\n    model.add(layers.Dropout(rate=0.20))\n    model.add(layers.Dense(o_shape, activation='softmax'))\n    \n    return model\n    ","1b2d7cce":"model = make_model(i_shape=(256,256,3), o_shape=6)","c4c4ad7a":"model.summary()","835da81f":"opt = optimizers.Adam(lr=0.000001)","adfb182c":"filepath = 'mobile_gallery.h5'","62f17ec9":"chkpt = ModelCheckpoint(filepath, monitor='val_loss', verbose=1,\n                        save_best_only=True, save_weights_only=False, mode='auto', period=1) \ncallbacks_l = [chkpt]","79e2f8b2":"model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])","f538560f":"epochs = 20\nbatch_size = 32","8b712066":"# Note tf v2 will deprecate model.fit_generator we need to use model.fit instead\n# history = model.fit(train_generator,\n#                               steps_per_epoch= train_generator.samples \/\/ batch_size,\n#                               epochs=epochs,\n#                               validation_data=val_generator,\n#                               validation_steps=val_generator.samples \/\/ batch_size, callbacks=callbacks_l)","c92c66d4":"# acc = history.history['acc']\n# val_acc = history.history['val_acc']\n# loss = history.history['loss']\n# val_loss = history.history['val_loss']\n\n# epochs = range(1, len(acc) + 1)\n\n# plt.plot(epochs, acc, 'g', label='Training acc')\n# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n# plt.title('Training and validation accuracy')\n# plt.legend()\n# plt.figure()\n\n# plt.plot(epochs, loss, 'g', label='Training loss')\n# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n# plt.title('Training and validation loss')\n# plt.legend()\n# plt.show()","a0abfc66":"# model_json = model.to_json()\n# with open(\"model.json\", \"w\") as json_file:\n#     json_file.write(model_json)\n# print(\"Saved model to disk\")","7c93106a":"# Plot some graphs\n# Use tf_explain","a50f519a":"# Data Augmentation","a824b5ed":"# Analyzing the model performance","364d00fe":"# Buildinig a CNN Classifier","b2691499":"# Fitting and Saving the Model","a2e04a94":"# Analysis of the data"}}