{"cell_type":{"93402cd0":"code","87055683":"code","081e0361":"code","9bc9d89e":"code","9ea3baf9":"code","56744f69":"code","835e407e":"code","00f16595":"code","1acd0977":"code","ea026f16":"code","3da72d46":"code","6a100989":"code","26ecc341":"markdown","abe508e3":"markdown"},"source":{"93402cd0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","87055683":"#Read data from a tab separeted file, using a delimeter '\\t' for separating feature values.\ndataset = pd.read_csv('..\/input\/amazon_alexa.tsv',delimiter='\\t',quoting=3)","081e0361":"#Reviewing data\ndataset.head(5)","9bc9d89e":"#Using nltk library for preparing data for ready to use for sentimental analysis\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\nreviews=[]\nfor i in range(0,3150):\n    review = re.sub('[^a-zA-Z]',' ',dataset['verified_reviews'][i])\n    review = review.lower()\n    review = review.split()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    reviews.append(review)","9ea3baf9":"#Creating a bag of words that contains all the unique words in all the reviews\n#Each column in X will represent each word\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(reviews).toarray()\ny = dataset.iloc[:,4]","56744f69":"#Split data into train and test set\nfrom sklearn.model_selection import train_test_split\nxtr, xtst, ytr, ytst = train_test_split(X,y,test_size=0.25,random_state=0)","835e407e":"#Building a Naive bayes classifier for classification\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\n\n#fitting train data in the classifier\nclassifier.fit(xtr,ytr)\nclassifier.score(xtr,ytr)","00f16595":"#Testing our classifier onto test data and storing the results in y_pred variable\ny_pred = classifier.predict(xtst)","1acd0977":"#Checking accuracy of predictions on test data\n#We are using confusion matrix from sklearn.metrics\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(ytst,y_pred)\nprint((cm[0,0]+cm[1,1])\/cm.sum()*100)","ea026f16":"#Modelling a Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier2 = DecisionTreeClassifier(criterion='entropy',random_state=0)\n\n#Training the classifier\nclassifier2.fit(xtr,ytr)\nclassifier2.score(xtr,ytr)","3da72d46":"#Prediction over test data\ny_pred2 = classifier2.predict(xtst)","6a100989":"#Check accuracy\ncm = confusion_matrix(ytst,y_pred2)\nprint((cm[0,0]+cm[1,1])\/cm.sum()*100)","26ecc341":"The confusion matrix is clearly showing we have built a great model for our data, the model is 92% accurate if you will calculate the score. So Decision Tree classifier predictions are far better than Naive Bayes Classifier.","abe508e3":"The prediction is not very good enough as you can see if you will calculate correct % accuracy it will be 55% only. We will try to use another model."}}