{"cell_type":{"690fddad":"code","cec63ff9":"code","31dc6f29":"code","2740cb12":"code","9ebd7459":"code","6d3428e9":"code","dfc85690":"code","5e6c7408":"code","dead490a":"code","5b88c3cb":"code","104dc5b4":"code","6c12035c":"code","80356c53":"code","0dc68d3a":"code","1f1a7d61":"code","daa9e4b0":"markdown"},"source":{"690fddad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cec63ff9":"import zipfile","31dc6f29":"\nzip_ref = zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/train.zip', 'r')\nzip_ref.extractall('\/tmp\/train')\nzip_ref.close()","2740cb12":"filenames = os.listdir(\"\/tmp\/train\/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'label': categories\n})","9ebd7459":"df.head()","6d3428e9":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Activation, Input\nimport pandas as pd\nimport os\nimport numpy as np\nfrom keras.models import load_model\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import img_to_array\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport time\nimport h5py","dfc85690":"print(\"[INFO] loading images...\")\ndata = []\nlabels = []\n\n# grab the image paths and randomly shuffle them\n\npath=\"\/tmp\/train\/train\/\"\n\n\n# test=test.drop('label',1)\ntemp = []\nfor img_name in df.filename:\n    image_path = path+img_name\n    img = cv2.imread(image_path, 0)\n    img = cv2.resize(img, (128, 128))\n    img = img.reshape(1, 128 * 128)\n    img = img.astype('float32')\n    temp.append(img)\n\n\ntrain_x = np.stack(temp)\n\ntrain_x \/= 255.0\n\ntrain_x = train_x.reshape(len(df), 128,128,1).astype('float32')\ntrain_y = to_categorical(df.label.values,num_classes=2)\n\nprint(\"no_prob\")\ntrain_x=np.array(train_x)\ntrain_y=np.array(train_y)\n\nx_train,x_test,y_train,y_test=train_test_split(train_x,train_y,test_size=0.2,random_state=4)\n# time.sleep(10)\n\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n    horizontal_flip=True, fill_mode=\"nearest\")\n\n\naug.fit(train_x)","5e6c7408":"class CNNmodel:\n    @staticmethod\n    def build(width, height, depth, classes):\n        # initialize the model\n        model = Sequential()\n        inputShape = (height, width, depth)\n \n        # if we are using \"channels first\", update the input shape\n        if K.image_data_format() == \"channels_first\":\n            inputShape = (depth, height, width)\n\n        # first set of CONV => RELU => POOL layers\n        model.add(Conv2D(20, (5, 5), padding=\"same\",\n            input_shape=inputShape))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # second set of CONV => RELU => POOL layers\n        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # first (and only) set of FC => RELU layers\n        model.add(Flatten())\n        model.add(Dense(500))\n        model.add(Activation(\"relu\"))\n \n        # softmax classifier\n        model.add(Dense(classes))\n        model.add(Activation(\"sigmoid\"))\n \n        # return the constructed network architecture\n        return model\n","dead490a":"EPOCHS = 50\nINIT_LR = 1e-3\nBS = 32","5b88c3cb":"print(\"[INFO] compiling model...\")\nmodel = CNNmodel.build(width=128, height=128, depth=1, classes=2)\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n    metrics=[\"accuracy\"])\n\n# train the network\nprint(\"[INFO] training network...\")\nH = model.fit_generator(aug.flow(x_train, y_train, batch_size=BS),validation_data=(x_test, y_test),steps_per_epoch=len(x_train) \/\/ BS,epochs=EPOCHS, verbose=1)\n\n# save the model to disk\nprint(\"[INFO] serializing network...\")\n# model.save('model.h5')","104dc5b4":"def plot_graph(H,EPOCHS,INIT_LR,BS):\n\n    plt.style.use(\"ggplot\")\n    plt.figure()\n    N = EPOCHS\n    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n    plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n    plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n    plt.title(\"Training Loss and Accuracy on our system\")\n    plt.xlabel(\"Epoch #\")\n    plt.ylabel(\"Loss\/Accuracy\")\n    plt.legend(loc=\"lower left\")\n    # plt.savefig(args[\"plot\"])\n    plt.show()","6c12035c":"plot_graph(H,EPOCHS,INIT_LR,BS)","80356c53":"zip_ref = zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/test1.zip', 'r')\nzip_ref.extractall('\/tmp\/test1')\nzip_ref.close()","0dc68d3a":"path=\"\/tmp\/train\/test1\/\"","1f1a7d61":"c = 1\nsubmission = pd.DataFrame(columns = ['id', 'label'])\nfor img in os.listdir(path):\n    image = cv2.imread(path + img,0)\n    # orig = image.copy()\n\n    # pre-process the image for classification\n    image = cv2.resize(image, (128, 128))\n    image = image.astype(\"float32\") \/ 255.0\n    image = img_to_array(image)\n    image = np.expand_dims(image, axis=0)\n    predictions=model.predict(image)\n    val = np.argmax(np.squeeze(predictions))\n    submission = submission.append({'id': c,'label': val},ignore_index=True)\n\nsubmission.to_csv('submission.csv' ,index=False)\nprint(submission.head())","daa9e4b0":"Do give an upvote if you like it :)"}}