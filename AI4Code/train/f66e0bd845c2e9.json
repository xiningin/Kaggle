{"cell_type":{"23d73eb5":"code","7721ca96":"code","0f3348f0":"code","ac7d4eba":"code","4486e761":"code","e4684401":"code","dad7bc55":"code","95981e24":"code","618c6b5d":"code","34c40511":"code","05e8c6ec":"code","1bf44f7b":"markdown","b960eded":"markdown","2fe23abf":"markdown","fb2093a8":"markdown","24d2ae70":"markdown","4977e620":"markdown","baf06245":"markdown","0b5ff4b4":"markdown"},"source":{"23d73eb5":"!pip install pystan==2.19.1.1\n!pip install prophet\n!pip install neuralprophet[live]","7721ca96":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 50)\npd.set_option('display.max_columns', 50)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom prophet import Prophet\nfrom neuralprophet import NeuralProphet","0f3348f0":"df_train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\n\ndf_train['date'] = pd.to_datetime(df_train['date'])\ndf_test['date'] = pd.to_datetime(df_test['date'])\n\ncountries = ['Sweden', 'Finland', 'Norway']\nstores = ['KaggleMart', 'KaggleRama']\nproducts = ['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker']\n\nprint(f'Training Set Shape: {df_train.shape} - Memory Usage: {df_train.memory_usage().sum() \/ 1024 ** 2:.2f} MB')\nprint(f'Test Set Shape: {df_test.shape} - Memory Usage: {df_test.memory_usage().sum() \/ 1024 ** 2:.2f} MB')","ac7d4eba":"def visualize_ts(df, t, y, forecasts, start, end, country, store, product):\n    \n    idx = (df[t] >= start) & (df[t] < end) & (df['country'] == country) & (df['store'] == store) & (df['product'] == product)\n    \n    fig, ax = plt.subplots(figsize=(24, 6), dpi=100)\n    ax.plot(df.loc[idx].set_index(t)[y], linewidth=2, label=y)\n    if forecasts is not None:\n        for forecast in forecasts:\n            ax.plot(df.loc[idx].set_index(t)[forecast], linewidth=2, label=forecast)\n    ax.tick_params(axis='x', labelsize=12.5, pad=10)\n    ax.tick_params(axis='y', labelsize=12.5, pad=10)\n    ax.set_title(f'[{start}, {end}) - {country} - {store} - {product}', size=20, pad=15)\n    ax.legend(prop={'size': 18})\n    plt.show()\n    \n    \nfor country in countries:\n    for store in stores:\n        for product in products:\n            visualize_ts(\n                df=df_train,\n                t='date',\n                y='num_sold',\n                forecasts=None,\n                start='2015-01-01',\n                end='2019-01-01',\n                country=country,\n                store=store,\n                product=product\n            )","4486e761":"new_year = pd.DataFrame({\n  'holiday': 'new_year',\n  'ds': pd.to_datetime(['2015-01-01', '2016-01-01', '2017-01-01', '2018-01-01', '2019-01-01']),\n  'lower_window': -1,\n  'upper_window': 0,\n})\n\neaster = pd.DataFrame({\n  'holiday': 'easter',\n  'ds': pd.to_datetime(['2015-04-05', '2016-03-27', '2017-04-16', '2018-04-01', '2019-04-21']),\n  'lower_window': 0,\n  'upper_window': 7,\n})\n\nholidays = pd.concat((new_year, easter))\nholidays","e4684401":"def smape(y_true, y_pred):\n    return 1 \/ len(y_true) * np.sum(2 * np.abs(y_pred - y_true) \/ (np.abs(y_true) + np.abs(y_pred)) * 100)","dad7bc55":"# Training period is between 2015-01-01 and 2018-01-01\n# Validation period is between 2018-01-01 and 2019-01-01\nfolds = [\n    ('2015-01-01', '2018-01-01'),\n    ('2018-01-01', '2019-01-01'),\n]\n\nfor country in countries:\n    for store in stores:\n        for product in products:\n            for fold, (start, end) in enumerate(folds):\n                # Skip iteration if it's the last fold\n                if fold == len(folds) - 1:\n                    continue\n                    \n                train_idx = (df_train['date'] >= start) &\\\n                            (df_train['date'] < end) &\\\n                            (df_train['country'] == country) &\\\n                            (df_train['store'] == store) &\\\n                            (df_train['product'] == product)\n                train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n                train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n                val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n                          (df_train['date'] < folds[fold + 1][1]) &\\\n                          (df_train['country'] == country) &\\\n                          (df_train['store'] == store) &\\\n                          (df_train['product'] == product)\n                val = df_train.loc[val_idx, ['date', 'num_sold']].reset_index(drop=True)\n                val = val.rename(columns={'date': 'ds', 'num_sold': 'y'})\n                \n                model = Prophet(\n                    growth='linear',\n                    holidays=holidays,\n                    n_changepoints=10,\n                    changepoint_range=0.4,\n                    yearly_seasonality=True,\n                    weekly_seasonality=True,\n                    daily_seasonality=False,\n                    seasonality_mode='additive',\n                    seasonality_prior_scale=25,\n                    holidays_prior_scale=100,\n                    changepoint_prior_scale=0.01,\n                    interval_width=0.5,\n                    uncertainty_samples=False\n                )\n                model.fit(train)\n                \n                train_predictions = model.predict(train[['ds']])['yhat']\n                val_predictions = model.predict(val[['ds']])['yhat']\n                df_train.loc[val_idx, 'prophet_forecast'] =  val_predictions.values\n\n                train_score = smape(train['y'].values, train_predictions.values)\n                val_score = smape(val['y'].values, val_predictions.values)\n                print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n                print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n                \n                test_idx = (df_test['country'] == country) &\\\n                           (df_test['store'] == store) &\\\n                           (df_test['product'] == product)\n                test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n                test = test.rename(columns={'date': 'ds'})\n                test_predictions = model.predict(test[['ds']])['yhat']\n                df_test.loc[test_idx, 'prophet_forecast'] = test_predictions.values\n","95981e24":"# Training period is between 2015-01-01 and 2018-01-01\n# Validation period is between 2018-01-01 and 2019-01-01\nfolds = [\n    ('2015-01-01', '2018-01-01'),\n    ('2018-01-01', '2019-01-01'),\n]\n\n# Neural Prophet requires holidays to be in one-hot encoded format on all timesteps\nevents = pd.concat((holidays['ds'], pd.get_dummies(holidays['holiday'])), axis=1)\n\nfor country in countries:\n    for store in stores:\n        for product in products:\n            for fold, (start, end) in enumerate(folds):\n                # Skip iteration if it's the last fold\n                if fold == len(folds) - 1:\n                    continue\n                    \n                train_idx = (df_train['date'] >= start) &\\\n                            (df_train['date'] < end) &\\\n                            (df_train['country'] == country) &\\\n                            (df_train['store'] == store) &\\\n                            (df_train['product'] == product)\n                train = df_train.loc[train_idx, ['date', 'num_sold']].reset_index(drop=True)\n                train = train.rename(columns={'date': 'ds', 'num_sold': 'y'})\n                train = train.merge(events, on='ds', how='left').fillna(0)\n                train['easter'] = train['easter'].astype(np.uint8)\n                train['new_year'] = train['new_year'].astype(np.uint8)\n                val_idx = (df_train['date'] >= folds[fold + 1][0]) &\\\n                          (df_train['date'] < folds[fold + 1][1]) &\\\n                          (df_train['country'] == country) &\\\n                          (df_train['store'] == store) &\\\n                          (df_train['product'] == product)\n                val = df_train.loc[val_idx, ['date', 'num_sold']].reset_index(drop=True)\n                val = val.rename(columns={'date': 'ds', 'num_sold': 'y'})\n                val = val.merge(events, on='ds', how='left').fillna(0)\n                val['easter'] = val['easter'].astype(np.uint8)\n                val['new_year'] = val['new_year'].astype(np.uint8)\n                \n                model = NeuralProphet(\n                    growth='linear',\n                    n_changepoints=10,\n                    changepoints_range=0.4,\n                    trend_reg=1,\n                    trend_reg_threshold=False,\n                    yearly_seasonality=True,\n                    weekly_seasonality=True,\n                    daily_seasonality=False,\n                    seasonality_mode='additive',\n                    seasonality_reg=1,\n                    n_forecasts=365,\n                    normalize='off'\n                )\n                model = model.add_events(['new_year'], mode='multiplicative', lower_window=-1)\n                model = model.add_events(['easter'], mode='additive', upper_window=7)\n                model.fit(train, freq='D')\n                \n                train_predictions = model.predict(train)['yhat1']\n                val_predictions = model.predict(val)['yhat1']\n                df_train.loc[val_idx, 'neural_prophet_forecast'] =  val_predictions.values\n\n                train_score = smape(train['y'].values, train_predictions.values)\n                val_score = smape(val['y'].values, val_predictions.values)\n                print(f'\\nTraining Range [{start}, {end}) - {country} - {store} - {product} - Train SMAPE: {train_score:4f}')\n                print(f'Validation Range [{folds[fold + 1][0]}, {folds[fold + 1][1]}) - {country} - {store} - {product} - Validation SMAPE: {val_score:4f}\\n')\n                \n                test_idx = (df_test['country'] == country) &\\\n                           (df_test['store'] == store) &\\\n                           (df_test['product'] == product)\n                test = df_test.loc[test_idx, ['date']].reset_index(drop=True)\n                test = test.rename(columns={'date': 'ds'})\n                test['y'] = np.nan\n                test = test.merge(events, on='ds', how='left').fillna(0)\n                test['easter'] = test['easter'].astype(np.uint8)\n                test['new_year'] = test['new_year'].astype(np.uint8)\n                test_predictions = model.predict(test)['yhat1']\n                df_test.loc[test_idx, 'neural_prophet_forecast'] = test_predictions.values\n","618c6b5d":"val_idx = (df_train['date'] >= '2018-01-01') & (df_train['date'] < '2019-01-01')\nprophet_score = smape(df_train.loc[val_idx, 'num_sold'], df_train.loc[val_idx, 'prophet_forecast'])\nneural_prophet_score = smape(df_train.loc[val_idx, 'num_sold'], df_train.loc[val_idx, 'neural_prophet_forecast'])\nprint(f'Prophet - Validation SMAPE: {prophet_score:6f}')\nprint(f'Neural Prophet - Validation SMAPE: {neural_prophet_score:6f}')","34c40511":"df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n\nfor country in countries:\n    for store in stores:\n        for product in products:\n            visualize_ts(\n                df=df_all,\n                t='date',\n                y='num_sold',\n                forecasts=['prophet_forecast', 'neural_prophet_forecast'],\n                start='2018-01-01',\n                end='2020-01-01',\n                country=country,\n                store=store,\n                product=product\n            )","05e8c6ec":"test_idx = (df_all['date'] >= '2019-01-01') & (df_all['date'] < '2020-01-01')\ndf_submission = df_all.loc[test_idx, ['row_id', 'prophet_forecast', 'neural_prophet_forecast']].reset_index(drop=True)\ndf_submission['num_sold'] = (df_submission['prophet_forecast'] + df_submission['neural_prophet_forecast']) \/ 2\ndf_submission[['row_id', 'num_sold']].to_csv('submission.csv', index=False)","1bf44f7b":"## 5. Prophet\n\nIn this section, Prophet is used for forecasting. [Prophet](https:\/\/facebook.github.io\/prophet\/) is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data.\n\nSales data between 2015-01-01 and 2018-01-01 are used as training set and sales data between 2018-01-01 and 2019-01-01 are used as validation set. Every country-store-product combination are modeled separately and forecasts are combined afterwards.","b960eded":"## 8. Submission\n\nTest date range is indexed and data is converted to submission format below. Forecast of Prophet and Neural Prophet models are blended and submitted.","2fe23abf":"## 4. Metric\n\nSubmissions are evaluated on SMAPE (symmetric mean absolute percentage error) between forecasts and actual values. Advantages of using SMAPE are; it can interpreted as a percentage and it has lower (0%) and upper (200%) bounds.","fb2093a8":"## 7. Evaluation\n\nForecasts look decent. Models were able capture yearly and weekly seasonal fluctuations but struggle to fit some of the spikes.","24d2ae70":"## 1. Introduction\n\nThis competition's objective is predicting a full year of sales for three items at two stores located in three different countries. Three countries are Sweden, Finland and Norway. Two stores located in those countries are KaggleMart and KaggleRama. Three items sold in those stores are Kaggle Mug, Kaggle Hat and Kaggle Sticker.","4977e620":"## 6. Neural Prophet\n\nIn this section, Neural Prophet is used for forecasting. [Neural Prophet](https:\/\/neuralprophet.com\/html\/contents.html) has a number of added features with respect to original Prophet. They are as follows.\n\n* Gradient Descent for optimisation via using PyTorch as the backend\n* Modelling autocorrelation of time series using AR-Net\n* Modelling lagged regressors using a sepearate Feed-Forward Neural Network\n* Configurable non-linear deep layers of the FFNNs\n* Tuneable to specific forecast horizons (greater than 1)\n* Custom losses and metrics\n\nSales data between 2015-01-01 and 2018-01-01 are used as training set and sales data between 2018-01-01 and 2019-01-01 are used as validation set. Every country-store-product combination are modeled separately and forecasts are combined afterwards.","baf06245":"## 2. Data Analysis\n\nSales of every country-store-product combination is visualized below. All of the sales have very similar characteristics. Yearly and weekly seasonal fluctuations are quite strong and effects of holidays can be seen easily.","0b5ff4b4":"## 3. Holidays\n\nThe highest fluctuations can be seen on New Year's Day and Easter. The effect of New Year's Day is very short and strong but the effect Easter is weaker and longer."}}