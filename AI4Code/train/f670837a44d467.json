{"cell_type":{"bb95bae9":"code","aeeaf5ae":"code","9c185db4":"code","fae322a8":"code","1f12c7ce":"code","0b77b1b8":"code","1b8e2691":"code","443ba97d":"code","54a4723f":"code","243b29c0":"code","f8a4fc89":"code","8d3f09f6":"code","3f9666b5":"code","6d31962c":"code","6833f685":"code","93e0304b":"code","7079ad9f":"code","1fc4d476":"markdown","227d09f2":"markdown","881455b2":"markdown","cd81228a":"markdown","5946117b":"markdown","f6c3a346":"markdown"},"source":{"bb95bae9":"# Set up code checking\nimport os\nif not os.path.exists(\"..\/input\/train.csv\"):\n    os.symlink(\"..\/input\/home-data-for-ml-course\/train.csv\", \"..\/input\/train.csv\")  \n    os.symlink(\"..\/input\/home-data-for-ml-course\/test.csv\", \"..\/input\/test.csv\") \nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.ml_intermediate.ex2 import *\nprint(\"Setup Complete\")","aeeaf5ae":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n\n# Read the data\nX_full = pd.read_csv('..\/input\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('..\/input\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# To keep things simple, we'll use only numerical predictors\nX = X_full.select_dtypes(exclude=['object'])\nX_test = X_test_full.select_dtypes(exclude=['object'])\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","9c185db4":"X_train.head()","fae322a8":"# Shape of training data (num_rows, num_columns)\nprint(X_train.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (X_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","1f12c7ce":"# How many missing entries are contained in all of the training data?\ntot_missing = missing_val_count_by_column[missing_val_count_by_column > 0].sum()","0b77b1b8":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","1b8e2691":"# Get names of columns with missing values\ncols_with_missing = [col for col in X_train.columns\n                     if X_train[col].isnull().any()] # Your code here\n\n# Drop columns in training and validation data\nreduced_X_train = X_train.drop(cols_with_missing, axis=1)\nreduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n","443ba97d":"print(\"MAE (Drop columns with missing values):\")\nprint(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))","54a4723f":"from sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns\nimputed_X_test = pd.DataFrame(my_imputer.fit_transform(X_test))\nimputed_X_test.columns = X_test.columns","243b29c0":"print(\"MAE (Imputation):\")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))","f8a4fc89":"print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))","8d3f09f6":"# Preprocessed training and validation features\nfinal_X_train = imputed_X_train\nfinal_X_valid = imputed_X_valid","3f9666b5":"# Define and fit model\nmodel = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\nmodel.fit(final_X_train, y_train)\n\n# Get validation predictions and MAE\npreds_valid = model.predict(final_X_valid)\nprint(\"MAE (Your approach):\")\nprint(mean_absolute_error(y_valid, preds_valid))","6d31962c":"from pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(model.get_params())","6833f685":"X_test.shape","93e0304b":"# Get test predictions\npreds_test = model.predict(imputed_X_test)\n","7079ad9f":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","1fc4d476":"# Step 3: Imputation\n","227d09f2":"# Step 2: Drop columns with missing values","881455b2":"[Housing Prices Competition ](https:\/\/www.kaggle.com\/c\/home-data-for-ml-course). \n\n![Ames Housing dataset image](https:\/\/i.imgur.com\/lTJVG4e.png)\n","cd81228a":"To compare different approaches to dealing with missing values, you'll use the same `score_dataset()` function from the tutorial.  This function reports the [mean absolute error](https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_error) (MAE) from a random forest model.","5946117b":"# Step 4: Generate test predictions","f6c3a346":"# Step 1: Preliminary investigation"}}