{"cell_type":{"8869e6dc":"code","e1a785f6":"code","84ff0672":"code","e9f89032":"code","d603109b":"code","1be0ff79":"code","cebf030c":"code","ab27dfaa":"code","7f075305":"code","46f38a75":"code","389ef4f6":"code","5bf1030f":"code","0e217c73":"code","04d77b3e":"code","fb0e2229":"code","ada16201":"code","c025fa1e":"code","1d05dcb7":"code","23118c47":"code","fbba4085":"code","d3ce09f2":"code","559446fa":"code","93822eb8":"code","896eb84c":"code","ed8fc493":"code","322d925c":"code","313d505e":"code","c3f8c4a1":"code","89d365b5":"code","9024d435":"code","3aae6c7e":"code","08d973be":"code","86e53fd9":"code","c16f48b2":"code","d1b90279":"code","c4812283":"code","56821a18":"code","9169434f":"code","d4df6b3c":"code","0a0feef3":"code","ab54095f":"code","962e5112":"code","26728b24":"code","abbc8af3":"code","edfbbaff":"code","506abc61":"code","39b12d62":"code","c849b2d7":"code","2f71fcdc":"code","c6494b48":"code","553c2098":"code","b8ef80de":"code","70d5907b":"code","7f0a5150":"code","fa866c46":"code","bcb95b85":"code","d45d67f4":"code","912ff82e":"code","819a0d72":"code","5b9d7317":"code","6d508710":"code","fb98585c":"code","ecbf3ce9":"code","df5246db":"code","06283d98":"code","1da7cdd8":"code","906c1263":"code","51a1ab64":"code","fbbe4f36":"code","e90cf869":"code","4c42243c":"code","8b22358c":"code","254f03df":"code","9fc36398":"code","c7a35038":"code","aada54e8":"code","18a809f3":"code","6665e258":"code","49ce3038":"code","f4c396c7":"code","56f3c69d":"code","5cc07355":"code","09322c0b":"code","738d3f8c":"code","04064e58":"code","48a3aec6":"code","d8352e01":"code","6060b844":"code","380095e6":"code","adc959e8":"code","54a4fc3f":"code","059e7748":"code","afef04fe":"code","a7ff7987":"code","191f2d53":"code","1fb460ce":"code","75e3befe":"code","7ee8d61b":"code","8a4a0120":"markdown","e74123f6":"markdown","616b6327":"markdown","e14890d6":"markdown","d8e05350":"markdown","c6893109":"markdown","c16e1456":"markdown","0d548dee":"markdown","c6b9dfc9":"markdown","f732dcd9":"markdown","b135ec88":"markdown","f7f92be3":"markdown","c789d083":"markdown","07719986":"markdown"},"source":{"8869e6dc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e1a785f6":"# %matplotlib inline\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression, Ridge, LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport string\nimport math\nimport sys","84ff0672":"titanic = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntitanic_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntitanic_copy = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntitanic_test_copy = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","e9f89032":"# check the types of dataframe\ntitanic.dtypes","d603109b":"target = titanic['Survived']","1be0ff79":"target.unique()","cebf030c":"# check if any null value in target\ntarget.isnull().sum()","ab27dfaa":"# plot target values\ntarget.value_counts().plot.pie(autopct='%1.2f%%')","7f075305":"titanic.info()\nprint('----------------------------------------------')\ntitanic_test.info()","46f38a75":"# check how many unique values each feature have\nfor column in titanic.columns:\n    print(column, len(titanic[column].unique()))","389ef4f6":"print('Train Data Embarked', titanic['Embarked'].isnull().sum())\nprint('Train Data Fare', titanic['Fare'].isnull().sum())\n\nprint('test Data embarked', titanic_test['Embarked'].isnull().sum())\nprint('test Data Fare', titanic_test['Fare'].isnull().sum())\n\n","5bf1030f":"# because missing values are less we replace embarked with most recurrent value and fare with median\ntitanic['Embarked'] = titanic['Embarked'].fillna(\"S\")\ntitanic_test['Fare'] = titanic_test['Fare'].fillna(titanic_test['Fare'].median())","0e217c73":"titanic['Age'].describe()","04d77b3e":"# create feature where missing age is imputed with mean of age values that are not missing\ntitanic['Age_mean'] =np.where(titanic.Age.isnull(), titanic['Age'].mean(), titanic['Age'])\ntitanic_test['Age_mean'] =np.where(titanic_test.Age.isnull(), titanic_test['Age'].mean(), titanic_test['Age'])","fb0e2229":"# drop PasssengerId because it has no impact in survival rate\ntitanic = titanic.drop('PassengerId', axis=1)\ntitanic_test = titanic_test.drop('PassengerId', axis=1)","ada16201":"titanic.head()\n","c025fa1e":"def ticket_sep(tickets):\n    ticket_type = []\n    for i in range(len(tickets)):\n        one = tickets.iloc[i].split(\" \")[0]\n        if(one.isdecimal()):\n            ticket_type.append('NO')\n        else:\n            ticket_type.append(''.join(e for e in one if e.isalnum()))\n    return ticket_type\n    ","1d05dcb7":"titanic['ticket_type'] = ticket_sep(titanic['Ticket'])\ntitanic_test['ticket_type'] = ticket_sep(titanic_test['Ticket'])","23118c47":"print(titanic_test['ticket_type'].value_counts())","fbba4085":"# put all tickets which are less than 15 into OTHER_T\ntrain_values = titanic['ticket_type'].value_counts()\ntest_values = titanic_test['ticket_type'].value_counts()\n\nfor i,t in enumerate(titanic['ticket_type']):\n    if (train_values[t] < 15):\n        titanic['ticket_type'][i] = 'OTHER_T'\n        \nfor i,t in enumerate(titanic_test['ticket_type']):\n    if (t not in titanic['ticket_type'].unique()):\n        titanic_test['ticket_type'][i] = 'OTHER_T'","d3ce09f2":"print(titanic['ticket_type'].unique())\nprint(titanic_test['ticket_type'].unique())","559446fa":"sns.barplot(x = 'ticket_type', y = 'Survived', data = titanic)","93822eb8":"# where ticket_type is 'SOTONOQ' convert it to 'A5'\ntitanic[\"ticket_type\"] = np.where(titanic[\"ticket_type\"]=='SOTONOQ', 'A5', titanic[\"ticket_type\"])\ntitanic_test['ticket_type'] = np.where(titanic_test['ticket_type'] == 'SOTONOQ', 'A5', titanic_test['ticket_type'])","896eb84c":"sns.barplot(x='ticket_type', y='Survived', data=titanic)","ed8fc493":"# drop ticket from dataframe\ntitanic = titanic.drop('Ticket', axis = 1)\ntitanic_test = titanic_test.drop('Ticket', axis = 1)","322d925c":"print('null in training set', titanic['Cabin'].isnull().sum())\nprint('null in testing set', titanic_test['Cabin'].isnull().sum())","313d505e":"# create function that takes cabin type from cabin and if value is missing copy NaN\ndef sep_cabin(cabin):\n    cabin_type = []\n    \n    for c in range(len(cabin)):\n        if cabin.isnull()[c] == True:\n            cabin_type.append('NaN')\n        else:\n            cabin_type.append(cabin[c][:1])\n    return cabin_type\n            ","c3f8c4a1":"titanic['cabin_type'] = sep_cabin(titanic['Cabin'])\ntitanic_test['cabin_type'] = sep_cabin(titanic_test['Cabin'])","89d365b5":"titanic.head()","9024d435":"sns.barplot(x='cabin_type', y='Survived', data=titanic)","3aae6c7e":"# put all cabin which are less than 15 into OTHER_C\ntrain_values = titanic['cabin_type'].value_counts()\ntest_values = titanic_test['cabin_type'].value_counts()\n\nfor i,t in enumerate(titanic['cabin_type']):\n    if (train_values[t] < 15):\n        titanic['cabin_type'][i] = 'OTHER_C'\n        \nfor i,t in enumerate(titanic_test['cabin_type']):\n    if (t not in titanic['cabin_type'].unique()):\n        titanic_test['cabin_type'][i] = 'OTHER_C'","08d973be":"sns.barplot(x='cabin_type', y='Survived', data=titanic)","86e53fd9":"# drop cabin from dataset\ntitanic = titanic.drop('Cabin', axis = 1)\ntitanic_test = titanic_test.drop('Cabin', axis = 1)","c16f48b2":"titanic['Name']","d1b90279":"# Create function that take name and separates it into title, family name and deletes all puntuation from name column:\ndef sep_name(data):\n    families=[]\n    titles = []\n    new_name = []\n    #for each row in dataset:\n    for i in range(len(data)):\n        name = data.iloc[i]\n        # extract name inside brakets into name_bracket:\n        if '(' in name:\n            name_no_bracket = name.split('(')[0] \n        else:\n            name_no_bracket = name\n            \n        family = name_no_bracket.split(\",\")[0]\n        title = name_no_bracket.split(\",\")[1].strip().split(\" \")[0]\n        \n        #remove punctuations accept brackets:\n        for c in string.punctuation:\n            name = name.replace(c,\"\").strip()\n            family = family.replace(c,\"\").strip()\n            title = title.replace(c,\"\").strip()\n            \n        families.append(family)\n        titles.append(title)\n        new_name.append(name)\n            \n    return [families, titles, new_name]   ","c4812283":"# apply name_sep on train and test set:\ntitanic['family'], titanic['title'], titanic['Name']  = sep_name(titanic.Name)\ntitanic_test['family'], titanic_test['title'], titanic_test['Name'] = sep_name(titanic_test.Name)\n\ntitanic.head()","56821a18":"g = sns.barplot(x='title', y='Survived', data=titanic)\ng.figure.set_figwidth(15)","9169434f":"# put all title which are less than 15 into OTHER\ntrain_values = titanic['title'].value_counts()\ntest_values = titanic_test['title'].value_counts()\n\nfor i,t in enumerate(titanic['title']):\n    if (train_values[t] < 15):\n        titanic['title'][i] = 'OTHER'\n        \nfor i,t in enumerate(titanic_test['title']):\n    if (t not in titanic['title'].unique()):\n        titanic_test['title'][i] = 'OTHER'","d4df6b3c":"g = sns.barplot(x='title', y='Survived', data=titanic)","0a0feef3":"# amount of overlapping family names in train and test set:\nlen([x for x in titanic.family.unique() if x in titanic_test.family.unique()])","ab54095f":"# amount of non overlapping names in train and test set\nlen([x for x in titanic.family.unique() if x not in titanic_test.family.unique()])","962e5112":"# amount of non overlapping with train set unique family names in test set:\nlen([x for x in titanic_test.family.unique() if x not in titanic.family.unique()])","26728b24":"#create a list with all overlapping families\noverlap = [x for x in titanic.family.unique() if x in titanic_test.family.unique()]","abbc8af3":"# introduce new column to data called family_size:\ntitanic['family_size'] = titanic.SibSp + titanic.Parch +1\ntitanic_test['family_size'] = titanic_test.SibSp + titanic_test.Parch +1\n\n# calculate survival rate for each family in train_set:\nrate_family = titanic.groupby('family')['Survived', 'family','family_size'].median()\nrate_family.head()","edfbbaff":"# if family size is more than 1 and family name is in overlap list \noverlap_family ={}\nfor i in range(len(rate_family)):\n    if rate_family.index[i] in overlap and  rate_family.iloc[i,1] > 1:\n        overlap_family[rate_family.index[i]] = rate_family.iloc[i,0]","506abc61":"mean_survival_rate = np.mean(titanic.Survived)\nfamily_survival_rate = []\nfamily_survival_rate_NA = []\n\nfor i in range(len(titanic)):\n    if titanic.family[i] in overlap_family:\n        family_survival_rate.append(overlap_family[titanic.family[i]])\n        family_survival_rate_NA.append(1)\n    else:\n        family_survival_rate.append(mean_survival_rate)\n        family_survival_rate_NA.append(0)\n        \ntitanic['family_survival_rate']= family_survival_rate\ntitanic['family_survival_rate_NA']= family_survival_rate_NA","39b12d62":"# repeat the same for test set:\nmean_survival_rate = np.mean(titanic.Survived)\nfamily_survival_rate = []\nfamily_survival_rate_NA = []\n\nfor i in range(len(titanic_test)):\n    if titanic_test.family[i] in overlap_family:\n        family_survival_rate.append(overlap_family[titanic_test.family[i]])\n        family_survival_rate_NA.append(1)\n    else:\n        family_survival_rate.append(mean_survival_rate)\n        family_survival_rate_NA.append(0)\ntitanic_test['family_survival_rate']= family_survival_rate\ntitanic_test['family_survival_rate_NA']= family_survival_rate_NA","c849b2d7":"# drop name and family from dataset:\ntitanic = titanic.drop(['Name', 'family'], axis=1)\ntitanic_test = titanic_test.drop(['Name', 'family'], axis=1)\n\ntitanic.head()","2f71fcdc":"sns.boxplot(titanic.Age)","c6494b48":"sns.boxplot(titanic.Fare)","553c2098":"sns.boxplot(titanic.Age_mean)","b8ef80de":"print('skew for fare', titanic['Fare'].skew())\nprint('skew for age mean', titanic['Age_mean'].skew())","70d5907b":"# use IQR to handle skewed data of Fare\nquar_range = titanic.Fare.quantile(0.75) - titanic.Fare.quantile(0.25)\nupper_bound = titanic.Fare.quantile(0.75) + 3*quar_range\ntitanic.loc[titanic.Fare > upper_bound, 'Fare'] = upper_bound\ntitanic_test.loc[titanic_test.Fare > upper_bound, 'Fare'] = upper_bound\nmax(titanic.Fare)","7f0a5150":"# use IQR to handle age_mean\nquar_range = titanic.Age_mean.quantile(0.75) - titanic.Age_mean.quantile(0.25)\nupper_bound = titanic.Age_mean.quantile(0.75) + 3*quar_range\ntitanic.loc[titanic.Age_mean > upper_bound, 'Age_mean'] = upper_bound\ntitanic_test.loc[titanic_test.Age_mean > upper_bound, 'Age_mean'] = upper_bound\nmax(titanic.Age_mean)","fa866c46":"# use IQR to handle age \nquar_range = titanic.Age.quantile(0.75) - titanic.Age.quantile(0.25)\nupper_bound = titanic.Age.quantile(0.75) + 3*quar_range\ntitanic.loc[titanic.Age > upper_bound, 'Age'] = upper_bound\ntitanic_test.loc[titanic_test.Age > upper_bound, 'Age'] = upper_bound\nmax(titanic.Age)","bcb95b85":"# check all columns values in training set are in test set also\ncolumns = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n\nfor c in columns:\n    print(c)\n    print(titanic[c].unique())\n    print(titanic_test[c].unique())","d45d67f4":"sns.barplot(x='SibSp', y = 'Survived', data=titanic)\n","912ff82e":"sns.barplot(x='Parch', y = 'Survived', data=titanic)\n","819a0d72":"sns.barplot(x='family_size', y = 'Survived', data=titanic)","5b9d7317":"# combine train and test set\ndata = pd.concat([titanic.drop('Survived', axis = 1), titanic_test], axis = 0, sort=False)\ndata.head()","6d508710":"# encode variables onto numberic labels\nle = LabelEncoder()\ncolumns = ['Sex', 'Embarked', 'ticket_type', 'cabin_type', 'title']\n\nfor c in columns:\n    le.fit(data[c])\n    data[c] = le.transform(data[c])\ndata.head()","fb98585c":"# drop columns that have information about age or are strongly correlated with other features\ndata = data.drop(['Age_mean'], axis =1)","ecbf3ce9":"sns.pairplot(data, \n             x_vars=['Pclass', 'Sex','Fare','Embarked','ticket_type','cabin_type','title', 'family_survival_rate'],\n            y_vars='Age')","df5246db":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,8))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(data.corr(), linewidth=0.1, vmax=1.0, square=False, linecolor='black', cmap=colormap, annot=True)","06283d98":"x_train_age = data.dropna().drop(['Age'], axis=1)\ny_train_age = data.dropna()['Age']","1da7cdd8":"x_test_age = data[pd.isnull(data.Age)].drop(['Age'], axis=1)","906c1263":"model_lin = make_pipeline(StandardScaler(), KernelRidge())\nkfold = model_selection.KFold(n_splits=10, random_state=4, shuffle=True)\nparameters = {'kernelridge__gamma' : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n              'kernelridge__kernel': ['rbf', 'linear'],\n               'kernelridge__alpha' :[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n             }\nsearch_lin = GridSearchCV(model_lin, parameters, n_jobs=-1, cv=kfold, scoring='r2', verbose=1)\nsearch_lin.fit(x_train_age, y_train_age)","51a1ab64":"print('Best paramter are:', search_lin.best_params_)\nprint(\"Best accuracy achieved:\",search_lin.cv_results_['mean_test_score'].mean())","fbbe4f36":"y_test_age = search_lin.predict(x_test_age)","e90cf869":"data.loc[data['Age'].isnull(), 'Age'] = y_test_age","4c42243c":"titanic.shape","8b22358c":"# seperate train and test data from data variable\nidx = titanic.shape[0]\ntitanic['Age'] = data.iloc[:idx].Age\ntitanic_test['Age'] = data.iloc[idx:].Age","254f03df":"titanic['Age'].isnull().sum()","9fc36398":"le = LabelEncoder()\ntitanic_train_LE = titanic.copy()\ntitanic_test_LE = titanic_test.copy()\n\ncolumns = ['Sex', 'Embarked', 'ticket_type', 'cabin_type', 'title']\n\nfor c in columns:\n    le.fit(titanic_train_LE[c])\n    titanic_train_LE[c] = le.transform(titanic_train_LE[c])    \n    titanic_test_LE[c] = le.transform(titanic_test_LE[c])\ntitanic_train_LE.head()","c7a35038":"plt.figure(figsize=(17,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(titanic_train_LE.corr(),linewidths=0.1,vmax=1.0, \n            square=True,linecolor='white',cmap=colormap, annot=True)","aada54e8":"drop_col = ['Age_mean', 'SibSp', 'Parch']\ntitanic_train_LE = titanic_train_LE.drop(drop_col, axis=1)\ntitanic_test_LE = titanic_test_LE.drop(drop_col, axis=1)","18a809f3":"drop_col = ['Age_mean', 'SibSp', 'Parch']\nX_train_ohe = titanic.drop(drop_col, axis = 1)\nX_test_ohe = titanic_test.drop(drop_col, axis = 1)\n","6665e258":"columns = ['cabin_type', 'title',  'Sex', 'Embarked', 'ticket_type', 'Pclass']\n\nfor c in columns:\n    X_train_ohe = pd.concat([X_train_ohe, pd.get_dummies(X_train_ohe[c], drop_first=True)], axis=1)\n#     X_test_ohe = pd.concat([X_train_ohe, pd.get_dummies(X_test_ohe[c], drop_first=True)], axis = 1)\n    X_test_ohe = pd.concat([X_test_ohe, pd.get_dummies(X_test_ohe[c], drop_first = True)], axis =1)","49ce3038":"X_train_ohe = X_train_ohe.drop(columns, axis=1)\nX_test_ohe = X_test_ohe.drop(columns, axis=1)\nX_test_ohe.head()","f4c396c7":"sns.clustermap(X_train_ohe.corr(),linewidths=0.1,vmax=1.0, \n            square=True,linecolor='white',cmap=colormap)","56f3c69d":"X_train_lab = titanic.drop(drop_col, axis=1)\nX_test_lab = titanic_test.drop(drop_col, axis=1)","5cc07355":"le = LabelEncoder()\ncolumns = ['Sex', 'Embarked', 'ticket_type', 'cabin_type', 'title']\n\nfor col in columns:\n    le.fit(titanic[col])\n    X_train_lab[col] = le.transform(X_train_lab[col])\n    X_test_lab[col] = le.transform(X_test_lab[col])\n    \nX_test_lab.head()","09322c0b":"sns.clustermap(X_train_lab.corr(),linewidths=0.1,vmax=1.0, \n            square=True,linecolor='white',cmap=colormap)","738d3f8c":"X_train_mean = titanic.drop(drop_col, axis=1)\nX_test_mean = titanic_test.drop(drop_col, axis=1)","04064e58":"columns = ['cabin_type', 'title',  'Sex', 'Embarked', 'ticket_type']\n\nfor col in columns:\n    ordered_labels = X_train_mean.groupby([col])['Survived'].mean().to_dict()\n    X_train_mean[col] = X_train_mean[col].map(ordered_labels)\n    X_test_mean[col] = X_test_mean[col].map(ordered_labels)","48a3aec6":"X_train_mean.head()","d8352e01":"sns.clustermap(X_train_mean.corr(),linewidths=0.1,vmax=1.0, \n            square=True,linecolor='white',cmap=colormap)","6060b844":"X_train_freq = titanic.drop(drop_col, axis=1)\nX_test_freq = titanic_test.drop(drop_col, axis=1)","380095e6":"columns = ['cabin_type', 'title',  'Sex', 'Embarked', 'ticket_type']\n\nfor col in columns:\n    ordered_labels = X_train_freq[col].value_counts().to_dict()\n    X_train_freq[col] = X_train_freq[col].map(ordered_labels)\n    X_test_freq[col] = X_test_freq[col].map(ordered_labels)","adc959e8":"X_train_freq.head()","54a4fc3f":"sns.clustermap(X_train_freq.corr(),linewidths=0.1,vmax=1.0, \n            square=True,linecolor='white',cmap=colormap)","059e7748":"#  function split into x and y\ndef split_x_y(dataset):\n    X = dataset.drop(columns= ['Survived'])\n    Y = dataset['Survived']\n    return X,Y","afef04fe":"kfold = StratifiedKFold(n_splits=5)","a7ff7987":"X_ohe, Y_ohe = split_x_y(X_train_ohe)\nX_lab, Y_lab = split_x_y(X_train_lab)\nX_mean, Y_mean  = split_x_y(X_train_mean)\nX_freq, Y_freq  = split_x_y(X_train_freq)","191f2d53":"random_state = 4\nclassifiers = []\n\nclassifiers.append(('SVC', make_pipeline(StandardScaler(),SVC(random_state=random_state))))\nclassifiers.append(('DecisionTree', DecisionTreeClassifier(random_state=random_state)))\nclassifiers.append(('AdaBoost', AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1)))\nclassifiers.append(('RandomForest', RandomForestClassifier(random_state=random_state)))\nclassifiers.append(('GradientBoost', GradientBoostingClassifier(random_state=random_state)))\nclassifiers.append(('MPL', make_pipeline(StandardScaler(), MLPClassifier(random_state=random_state))))\nclassifiers.append(('KNN',make_pipeline(MinMaxScaler(),KNeighborsClassifier(n_neighbors=7))))\n\nresults = []\nnames = []\nmeans = []\nstds = []\nfor name, classifier in classifiers:\n    kfold = model_selection.KFold(n_splits=3, random_state=random_state, shuffle=True)\n    cv_result = model_selection.cross_val_score(classifier, X_ohe, y=Y_ohe, cv=kfold, scoring='accuracy')\n    results.append(cv_result)\n    means.append(cv_result.mean())\n    stds.append(cv_result.std())\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_result.mean(), cv_result.std())\n    print(msg)","1fb460ce":"g=sns.barplot(x=names, y=means)\ng.figure.set_figwidth(15)","75e3befe":"def random_forest(X, Y, X_test):\n    parameters = {'max_depth': [2, 4, 5, 10],\n                 'n_estimators': [200, 500, 1000, 2000],\n                 'min_samples_split': [3, 4, 5]}\n    \n    kfold = model_selection.KFold(n_splits=3, random_state=4, shuffle=True)\n    modelRFC = RandomForestClassifier(random_state=4, n_jobs=-1)\n    searchRFC = GridSearchCV(modelRFC, parameters, n_jobs=-1, cv=kfold, scoring='accuracy', verbose=1)\n    searchRFC.fit(X, Y)\n    predict = searchRFC.predict(X_test)\n    \n    print('Best Parameters of RFC are:', searchRFC.best_params_)\n    print('Best accuracy achieved of RFC', searchRFC.best_score_)\n    \n    return searchRFC.best_params_, modelRFC, searchRFC, predict","7ee8d61b":"paramsRFCohe,modelRFCohe,searchRFCohe, predictRFCohe = random_forest(X_ohe, Y_ohe, X_test_ohe)\nparamsRFClab,modelRFClab,searchRFClab, predictRFClab = random_forest(X_lab, Y_lab, X_test_lab)\nparamsRFCmean,modelRFCmean,searchRFCmean, predictRFCmean = random_forest(X_mean, Y_mean, X_test_mean)\nparamsRFCfreq,modelRFCfrq,searchRFCfreq, predictRFCfreq = random_forest(X_freq, Y_freq, X_test_freq)\n","8a4a0120":"# Features with Outliers","e74123f6":"# Handle mission Values","616b6327":"# Ticket","e14890d6":"# Random Forest","d8e05350":"# Cabin","c6893109":"# Rare Values","c16e1456":"# One Hot Encoding","0d548dee":"# Frequency encoder","c6b9dfc9":"# Label Encoder ","f732dcd9":"# Modeling","b135ec88":"# Name","f7f92be3":"# Predict missing age ","c789d083":"# Mean Encoder","07719986":"# Feature Correlation and Dependencies"}}