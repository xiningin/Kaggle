{"cell_type":{"f82b7462":"code","ccb89d41":"code","69fa275e":"code","40f572b4":"code","d9095e92":"code","1f39196a":"code","85c8631d":"code","076eae8f":"code","2d5e5cff":"code","61f61b69":"code","fcd855a2":"code","b5c00030":"code","fbba1110":"code","bafba500":"code","af78d1f7":"code","489c9368":"code","2ffc0758":"code","15746834":"code","f9731131":"code","b7419989":"code","bd6745da":"code","3ea17b5a":"code","c8203747":"code","adaa5b16":"code","2f3158e3":"markdown","9e47c566":"markdown"},"source":{"f82b7462":"from tensorflow.keras.models import Sequential, Model \nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Input, SpatialDropout1D, Conv1D,MaxPool1D,BatchNormalization, GRU, SimpleRNN, Dropout,Flatten, concatenate,Bidirectional, GlobalMaxPool1D\nfrom tensorflow.keras import utils \nfrom sklearn.model_selection import train_test_split\nimport numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.optimizers import Adam, RMSprop, Adadelta\nimport matplotlib.pyplot as plt \nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences \nimport random\nimport time\nimport re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk.corpus import brown\nfrom textblob import TextBlob\nfrom tensorflow.keras import regularizers\n","ccb89d41":"import nltk\nnltk.download('wordnet')","69fa275e":"stop_words = set(stopwords.words(\"english\")) \nlemmatizer = WordNetLemmatizer()","40f572b4":"from google.colab import drive\ndrive.mount('\/content\/drive')","d9095e92":"train = pd.read_csv('\/content\/drive\/My Drive\/kaggle\/train (1).csv')","1f39196a":"!unzip '\/content\/drive\/My Drive\/glove.6B.100d.zip'","85c8631d":"def clean_text(text):\n    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n    text = text.lower()\n    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n    text = [word for word in text if not word in stop_words]\n    text = \" \".join(text)\n    return text\n","076eae8f":"train['textNltk'] = train['text'].apply(lambda x: clean_text(x))","2d5e5cff":"maxWordsCount = 20000\ntokenizer = Tokenizer(num_words=maxWordsCount, filters='!\"#$%&()*+,-.\/:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', oov_token='unknown', char_level=False)\ntokenizer.fit_on_texts(train['textNltk'])\nword_index = tokenizer.word_index\nvocab_size = max_features = len(word_index)","61f61b69":"trainWordIndexes = tokenizer.texts_to_sequences(train['textNltk']) ","fcd855a2":"path_file = 'glove.6B.100d.txt'\nembedding_dict_100d={}\nwith open(path_file,'r', encoding='utf8') as f:\n    for line in f:\n        values=line.split(' ')\n        word=values[0]\n        vectors=np.asarray(values[1:],'float32')\n        embedding_dict_100d[word]=vectors\nf.close()\n\nprint('The size of the embedding index is : %d'%(len(embedding_dict_100d)))","b5c00030":"embedding_dim  = 100\n\nembedding_matrix = np.zeros((max_features+1, embedding_dim))\n\nfor word, i in word_index.items():\n  if i < max_features:\n    \n    try:\n      embedding_matrix[i] =embedding_dict_100d[word]\n    except KeyError:  \n      embedding_matrix[i] = np.zeros((1, embedding_dim))\nembedding_matrix.shape","fbba1110":"maxLen = 25\nXEmb = pad_sequences(trainWordIndexes, maxlen=maxLen,padding='post')\ny = np.asarray(train['target'])","bafba500":"xTrain, xVal, yTrain, yVal = train_test_split(XEmb, y, test_size=0.20)","af78d1f7":"def plots_visual(result_model):\n  fig, axes = plt.subplots(1, 2, figsize=(13,5))\n  axes[0].plot(result_model.history['accuracy'])\n  axes[0].plot(result_model.history['val_accuracy'])\n  axes[0].legend(['accuracy', 'val_accuracy'])\n  axes[0].set_title('Accuracy')\n  axes[0].set_xlabel('Epochs')\n  axes[1].plot(result_model.history['loss'])\n  axes[1].plot(result_model.history['val_loss'])\n  axes[1].legend(['loss', 'val_loss'])\n  axes[1].set_title('Loss')\n  axes[1].set_xlabel('Epochs')","489c9368":"from keras.initializers import Constant","2ffc0758":"#Base Model EMB + LSTM","15746834":"def models():\n    model = Sequential()\n    model.add(Embedding(max_features+1, embedding_dim, mask_zero=True,embeddings_initializer=Constant(embedding_matrix)))\n    model.add(SpatialDropout1D(0.5))\n    model.add(Bidirectional(LSTM(32, return_sequences = True, dropout=0.3, recurrent_dropout=0.5)))\n    model.add(GlobalMaxPool1D())\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])\n    model.summary()\n    return model\n\nmodel = models()","f9731131":"history = model.fit(xTrain,yTrain,epochs=150,batch_size=32, validation_data=(xVal, yVal), callbacks=[callbaks])","b7419989":"Epoch 1\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.7184 - accuracy: 0.5103\nEpoch 00001: val_accuracy improved from -inf to 0.65266, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 207ms\/step - loss: 0.7184 - accuracy: 0.5103 - val_loss: 0.6653 - val_accuracy: 0.6527 - lr: 1.0000e-04\nEpoch 2\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.6821 - accuracy: 0.5649\nEpoch 00002: val_accuracy improved from 0.65266 to 0.70519, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 209ms\/step - loss: 0.6821 - accuracy: 0.5649 - val_loss: 0.6378 - val_accuracy: 0.7052 - lr: 1.0000e-04\nEpoch 3\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.6007\nEpoch 00003: val_accuracy improved from 0.70519 to 0.73145, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 207ms\/step - loss: 0.6642 - accuracy: 0.6007 - val_loss: 0.6155 - val_accuracy: 0.7315 - lr: 1.0000e-04\nEpoch 4\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.6246\nEpoch 00004: val_accuracy improved from 0.73145 to 0.75837, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 208ms\/step - loss: 0.6531 - accuracy: 0.6246 - val_loss: 0.5940 - val_accuracy: 0.7584 - lr: 1.0000e-04\nEpoch 5\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.6445\nEpoch 00005: val_accuracy improved from 0.75837 to 0.77741, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 207ms\/step - loss: 0.6335 - accuracy: 0.6445 - val_loss: 0.5735 - val_accuracy: 0.7774 - lr: 1.0000e-04\nEpoch 6\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.6662\nEpoch 00006: val_accuracy improved from 0.77741 to 0.78070, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 207ms\/step - loss: 0.6193 - accuracy: 0.6662 - val_loss: 0.5541 - val_accuracy: 0.7807 - lr: 1.0000e-04\nEpoch 7\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.6897\nEpoch 00007: val_accuracy improved from 0.78070 to 0.78726, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 208ms\/step - loss: 0.5992 - accuracy: 0.6897 - val_loss: 0.5351 - val_accuracy: 0.7873 - lr: 1.0000e-04\nEpoch 8\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.6969\nEpoch 00008: val_accuracy improved from 0.78726 to 0.78989, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 207ms\/step - loss: 0.5909 - accuracy: 0.6969 - val_loss: 0.5188 - val_accuracy: 0.7899 - lr: 1.0000e-04\nEpoch 9\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.7118\nEpoch 00009: val_accuracy did not improve from 0.78989\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.5778 - accuracy: 0.7118 - val_loss: 0.5046 - val_accuracy: 0.7866 - lr: 1.0000e-04\nEpoch 10\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5689 - accuracy: 0.7154\nEpoch 00010: val_accuracy did not improve from 0.78989\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.5689 - accuracy: 0.7154 - val_loss: 0.4937 - val_accuracy: 0.7866 - lr: 1.0000e-04\nEpoch 11\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.7140\nEpoch 00011: val_accuracy did not improve from 0.78989\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.5646 - accuracy: 0.7140 - val_loss: 0.4857 - val_accuracy: 0.7886 - lr: 1.0000e-04\nEpoch 12\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.7182\nEpoch 00012: val_accuracy did not improve from 0.78989\n191\/191 [==============================] - 37s 194ms\/step - loss: 0.5670 - accuracy: 0.7182 - val_loss: 0.4795 - val_accuracy: 0.7886 - lr: 1.0000e-04\nEpoch 13\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.7304\nEpoch 00013: val_accuracy improved from 0.78989 to 0.79120, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 206ms\/step - loss: 0.5529 - accuracy: 0.7304 - val_loss: 0.4743 - val_accuracy: 0.7912 - lr: 1.0000e-04\nEpoch 14\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.7376\nEpoch 00014: val_accuracy improved from 0.79120 to 0.79317, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 207ms\/step - loss: 0.5421 - accuracy: 0.7376 - val_loss: 0.4702 - val_accuracy: 0.7932 - lr: 1.0000e-04\nEpoch 15\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.7473\nEpoch 00015: val_accuracy improved from 0.79317 to 0.79383, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 209ms\/step - loss: 0.5363 - accuracy: 0.7473 - val_loss: 0.4671 - val_accuracy: 0.7938 - lr: 1.0000e-04\nEpoch 16\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5279 - accuracy: 0.7435\nEpoch 00016: val_accuracy did not improve from 0.79383\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.5279 - accuracy: 0.7435 - val_loss: 0.4653 - val_accuracy: 0.7938 - lr: 1.0000e-04\nEpoch 17\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7476\nEpoch 00017: val_accuracy improved from 0.79383 to 0.79514, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 204ms\/step - loss: 0.5328 - accuracy: 0.7476 - val_loss: 0.4627 - val_accuracy: 0.7951 - lr: 1.0000e-04\nEpoch 18\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.7450\nEpoch 00018: val_accuracy did not improve from 0.79514\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.5335 - accuracy: 0.7450 - val_loss: 0.4592 - val_accuracy: 0.7951 - lr: 1.0000e-04\nEpoch 19\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.7493\nEpoch 00019: val_accuracy improved from 0.79514 to 0.79580, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 204ms\/step - loss: 0.5252 - accuracy: 0.7493 - val_loss: 0.4574 - val_accuracy: 0.7958 - lr: 1.0000e-04\nEpoch 20\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.7502\nEpoch 00020: val_accuracy improved from 0.79580 to 0.79711, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 208ms\/step - loss: 0.5251 - accuracy: 0.7502 - val_loss: 0.4546 - val_accuracy: 0.7971 - lr: 1.0000e-04\nEpoch 21\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5189 - accuracy: 0.7502\nEpoch 00021: val_accuracy improved from 0.79711 to 0.79777, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.5189 - accuracy: 0.7502 - val_loss: 0.4526 - val_accuracy: 0.7978 - lr: 1.0000e-04\nEpoch 22\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5201 - accuracy: 0.7540\nEpoch 00022: val_accuracy improved from 0.79777 to 0.80039, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 207ms\/step - loss: 0.5201 - accuracy: 0.7540 - val_loss: 0.4521 - val_accuracy: 0.8004 - lr: 1.0000e-04\nEpoch 23\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.7601\nEpoch 00023: val_accuracy improved from 0.80039 to 0.80105, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 208ms\/step - loss: 0.5146 - accuracy: 0.7601 - val_loss: 0.4518 - val_accuracy: 0.8011 - lr: 1.0000e-04\nEpoch 24\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.7609\nEpoch 00024: val_accuracy did not improve from 0.80105\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.5085 - accuracy: 0.7609 - val_loss: 0.4477 - val_accuracy: 0.8004 - lr: 1.0000e-04\nEpoch 25\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.7703\nEpoch 00025: val_accuracy improved from 0.80105 to 0.80171, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.5016 - accuracy: 0.7703 - val_loss: 0.4489 - val_accuracy: 0.8017 - lr: 1.0000e-04\nEpoch 26\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5039 - accuracy: 0.7685\nEpoch 00026: val_accuracy did not improve from 0.80171\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.5039 - accuracy: 0.7685 - val_loss: 0.4470 - val_accuracy: 0.8011 - lr: 1.0000e-04\nEpoch 27\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.7668\nEpoch 00027: val_accuracy improved from 0.80171 to 0.80499, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 206ms\/step - loss: 0.5006 - accuracy: 0.7668 - val_loss: 0.4444 - val_accuracy: 0.8050 - lr: 1.0000e-04\nEpoch 28\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.7688\nEpoch 00028: val_accuracy improved from 0.80499 to 0.80565, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 204ms\/step - loss: 0.4979 - accuracy: 0.7688 - val_loss: 0.4456 - val_accuracy: 0.8056 - lr: 1.0000e-04\nEpoch 29\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.7734\nEpoch 00029: val_accuracy improved from 0.80565 to 0.80762, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 207ms\/step - loss: 0.4996 - accuracy: 0.7734 - val_loss: 0.4444 - val_accuracy: 0.8076 - lr: 1.0000e-04\nEpoch 30\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.7729\nEpoch 00030: val_accuracy did not improve from 0.80762\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4948 - accuracy: 0.7729 - val_loss: 0.4429 - val_accuracy: 0.8076 - lr: 1.0000e-04\nEpoch 31\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.7813\nEpoch 00031: val_accuracy did not improve from 0.80762\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4906 - accuracy: 0.7813 - val_loss: 0.4424 - val_accuracy: 0.8076 - lr: 1.0000e-04\nEpoch 32\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.7757\nEpoch 00032: val_accuracy improved from 0.80762 to 0.81090, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 207ms\/step - loss: 0.4872 - accuracy: 0.7757 - val_loss: 0.4394 - val_accuracy: 0.8109 - lr: 1.0000e-04\nEpoch 33\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.7775\nEpoch 00033: val_accuracy did not improve from 0.81090\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4881 - accuracy: 0.7775 - val_loss: 0.4377 - val_accuracy: 0.8109 - lr: 1.0000e-04\nEpoch 34\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.7757\nEpoch 00034: val_accuracy improved from 0.81090 to 0.81221, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.4836 - accuracy: 0.7757 - val_loss: 0.4387 - val_accuracy: 0.8122 - lr: 1.0000e-04\nEpoch 35\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4868 - accuracy: 0.7750\nEpoch 00035: val_accuracy improved from 0.81221 to 0.81418, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 204ms\/step - loss: 0.4868 - accuracy: 0.7750 - val_loss: 0.4373 - val_accuracy: 0.8142 - lr: 1.0000e-04\nEpoch 36\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4796 - accuracy: 0.7757\nEpoch 00036: val_accuracy improved from 0.81418 to 0.81550, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.4796 - accuracy: 0.7757 - val_loss: 0.4379 - val_accuracy: 0.8155 - lr: 1.0000e-04\nEpoch 37\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.7872\nEpoch 00037: val_accuracy did not improve from 0.81550\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4768 - accuracy: 0.7872 - val_loss: 0.4365 - val_accuracy: 0.8148 - lr: 1.0000e-04\nEpoch 38\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.7824\nEpoch 00038: val_accuracy did not improve from 0.81550\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.4797 - accuracy: 0.7824 - val_loss: 0.4356 - val_accuracy: 0.8155 - lr: 1.0000e-04\nEpoch 39\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.7882\nEpoch 00039: val_accuracy did not improve from 0.81550\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4735 - accuracy: 0.7882 - val_loss: 0.4345 - val_accuracy: 0.8155 - lr: 1.0000e-04\nEpoch 40\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.7870\nEpoch 00040: val_accuracy improved from 0.81550 to 0.81878, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.4742 - accuracy: 0.7870 - val_loss: 0.4330 - val_accuracy: 0.8188 - lr: 1.0000e-04\nEpoch 41\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.7903\nEpoch 00041: val_accuracy did not improve from 0.81878\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4689 - accuracy: 0.7903 - val_loss: 0.4327 - val_accuracy: 0.8188 - lr: 1.0000e-04\nEpoch 42\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.7877\nEpoch 00042: val_accuracy improved from 0.81878 to 0.81944, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.4721 - accuracy: 0.7877 - val_loss: 0.4330 - val_accuracy: 0.8194 - lr: 1.0000e-04\nEpoch 43\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.7877\nEpoch 00043: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4680 - accuracy: 0.7877 - val_loss: 0.4326 - val_accuracy: 0.8194 - lr: 1.0000e-04\nEpoch 44\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.7959\nEpoch 00044: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4659 - accuracy: 0.7959 - val_loss: 0.4326 - val_accuracy: 0.8168 - lr: 1.0000e-04\nEpoch 45\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.7906\nEpoch 00045: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4638 - accuracy: 0.7906 - val_loss: 0.4303 - val_accuracy: 0.8188 - lr: 1.0000e-04\nEpoch 46\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.7938\nEpoch 00046: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.4613 - accuracy: 0.7938 - val_loss: 0.4323 - val_accuracy: 0.8162 - lr: 1.0000e-04\nEpoch 47\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.7877\nEpoch 00047: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4597 - accuracy: 0.7877 - val_loss: 0.4323 - val_accuracy: 0.8148 - lr: 1.0000e-04\nEpoch 48\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.7985\nEpoch 00048: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 37s 195ms\/step - loss: 0.4573 - accuracy: 0.7985 - val_loss: 0.4308 - val_accuracy: 0.8162 - lr: 1.0000e-04\nEpoch 49\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.7977\nEpoch 00049: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.4531 - accuracy: 0.7977 - val_loss: 0.4300 - val_accuracy: 0.8181 - lr: 1.0000e-04\nEpoch 50\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.8002\nEpoch 00050: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4514 - accuracy: 0.8002 - val_loss: 0.4287 - val_accuracy: 0.8155 - lr: 1.0000e-04\nEpoch 51\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8007\nEpoch 00051: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 37s 195ms\/step - loss: 0.4516 - accuracy: 0.8007 - val_loss: 0.4274 - val_accuracy: 0.8194 - lr: 1.0000e-04\nEpoch 52\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.8011\nEpoch 00052: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4490 - accuracy: 0.8011 - val_loss: 0.4285 - val_accuracy: 0.8175 - lr: 1.0000e-04\nEpoch 53\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8033\nEpoch 00053: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4461 - accuracy: 0.8033 - val_loss: 0.4274 - val_accuracy: 0.8188 - lr: 1.0000e-04\nEpoch 54\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.8046\nEpoch 00054: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 196ms\/step - loss: 0.4450 - accuracy: 0.8046 - val_loss: 0.4270 - val_accuracy: 0.8194 - lr: 1.0000e-04\nEpoch 55\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.8023\nEpoch 00055: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4497 - accuracy: 0.8023 - val_loss: 0.4274 - val_accuracy: 0.8188 - lr: 1.0000e-04\nEpoch 56\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.8021\nEpoch 00056: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4380 - accuracy: 0.8021 - val_loss: 0.4277 - val_accuracy: 0.8181 - lr: 1.0000e-04\nEpoch 57\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8011\nEpoch 00057: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4461 - accuracy: 0.8011 - val_loss: 0.4278 - val_accuracy: 0.8194 - lr: 1.0000e-04\nEpoch 58\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.8113\nEpoch 00058: val_accuracy did not improve from 0.81944\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4370 - accuracy: 0.8113 - val_loss: 0.4264 - val_accuracy: 0.8194 - lr: 1.0000e-04\nEpoch 59\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.8039\nEpoch 00059: val_accuracy improved from 0.81944 to 0.82009, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.4432 - accuracy: 0.8039 - val_loss: 0.4271 - val_accuracy: 0.8201 - lr: 1.0000e-04\nEpoch 60\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.8107\nEpoch 00060: val_accuracy did not improve from 0.82009\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4404 - accuracy: 0.8107 - val_loss: 0.4271 - val_accuracy: 0.8194 - lr: 1.0000e-04\nEpoch 61\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.8123\nEpoch 00061: val_accuracy did not improve from 0.82009\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4321 - accuracy: 0.8123 - val_loss: 0.4267 - val_accuracy: 0.8181 - lr: 1.0000e-04\nEpoch 62\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.8077\nEpoch 00062: val_accuracy improved from 0.82009 to 0.82075, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.4351 - accuracy: 0.8077 - val_loss: 0.4244 - val_accuracy: 0.8207 - lr: 1.0000e-04\nEpoch 63\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.8074\nEpoch 00063: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.4333 - accuracy: 0.8074 - val_loss: 0.4256 - val_accuracy: 0.8181 - lr: 1.0000e-04\nEpoch 64\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8154\nEpoch 00064: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4278 - accuracy: 0.8154 - val_loss: 0.4261 - val_accuracy: 0.8194 - lr: 1.0000e-04\nEpoch 65\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.8158\nEpoch 00065: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4264 - accuracy: 0.8158 - val_loss: 0.4332 - val_accuracy: 0.8142 - lr: 1.0000e-04\nEpoch 66\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.8144\nEpoch 00066: val_accuracy did not improve from 0.82075\n\nEpoch 00066: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4294 - accuracy: 0.8144 - val_loss: 0.4290 - val_accuracy: 0.8168 - lr: 1.0000e-04\nEpoch 67\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.8153\nEpoch 00067: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4291 - accuracy: 0.8153 - val_loss: 0.4268 - val_accuracy: 0.8194 - lr: 8.0000e-05\nEpoch 68\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.8179\nEpoch 00068: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4210 - accuracy: 0.8179 - val_loss: 0.4263 - val_accuracy: 0.8194 - lr: 8.0000e-05\nEpoch 69\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.8135\nEpoch 00069: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4306 - accuracy: 0.8135 - val_loss: 0.4240 - val_accuracy: 0.8201 - lr: 8.0000e-05\nEpoch 70\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8167\nEpoch 00070: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 37s 195ms\/step - loss: 0.4247 - accuracy: 0.8167 - val_loss: 0.4243 - val_accuracy: 0.8207 - lr: 8.0000e-05\nEpoch 71\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.8232\nEpoch 00071: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 39s 203ms\/step - loss: 0.4146 - accuracy: 0.8232 - val_loss: 0.4268 - val_accuracy: 0.8181 - lr: 8.0000e-05\nEpoch 72\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4218 - accuracy: 0.8236\nEpoch 00072: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4218 - accuracy: 0.8236 - val_loss: 0.4263 - val_accuracy: 0.8194 - lr: 8.0000e-05\nEpoch 73\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.8250\nEpoch 00073: val_accuracy did not improve from 0.82075\n\nEpoch 00073: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4098 - accuracy: 0.8250 - val_loss: 0.4270 - val_accuracy: 0.8188 - lr: 8.0000e-05\nEpoch 74\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.8136\nEpoch 00074: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4261 - accuracy: 0.8136 - val_loss: 0.4266 - val_accuracy: 0.8201 - lr: 6.4000e-05\nEpoch 75\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.8227\nEpoch 00075: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4101 - accuracy: 0.8227 - val_loss: 0.4269 - val_accuracy: 0.8201 - lr: 6.4000e-05\nEpoch 76\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.8200\nEpoch 00076: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4124 - accuracy: 0.8200 - val_loss: 0.4284 - val_accuracy: 0.8201 - lr: 6.4000e-05\nEpoch 77\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.8222\nEpoch 00077: val_accuracy did not improve from 0.82075\n\nEpoch 00077: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.4154 - accuracy: 0.8222 - val_loss: 0.4273 - val_accuracy: 0.8207 - lr: 6.4000e-05\nEpoch 78\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.8261\nEpoch 00078: val_accuracy did not improve from 0.82075\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4113 - accuracy: 0.8261 - val_loss: 0.4259 - val_accuracy: 0.8207 - lr: 5.1200e-05\nEpoch 79\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4110 - accuracy: 0.8245\nEpoch 00079: val_accuracy improved from 0.82075 to 0.82141, saving model to \/content\/drive\/My Drive\/kaggle\/best_model.h5\n191\/191 [==============================] - 40s 208ms\/step - loss: 0.4110 - accuracy: 0.8245 - val_loss: 0.4259 - val_accuracy: 0.8214 - lr: 5.1200e-05\nEpoch 80\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.8184\nEpoch 00080: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.4179 - accuracy: 0.8184 - val_loss: 0.4273 - val_accuracy: 0.8188 - lr: 5.1200e-05\nEpoch 81\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4106 - accuracy: 0.8223\nEpoch 00081: val_accuracy did not improve from 0.82141\n\nEpoch 00081: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4106 - accuracy: 0.8223 - val_loss: 0.4251 - val_accuracy: 0.8201 - lr: 5.1200e-05\nEpoch 82\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.8271\nEpoch 00082: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4111 - accuracy: 0.8271 - val_loss: 0.4250 - val_accuracy: 0.8194 - lr: 4.0960e-05\nEpoch 83\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.8278\nEpoch 00083: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4099 - accuracy: 0.8278 - val_loss: 0.4253 - val_accuracy: 0.8201 - lr: 4.0960e-05\nEpoch 84\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.8268\nEpoch 00084: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4056 - accuracy: 0.8268 - val_loss: 0.4250 - val_accuracy: 0.8207 - lr: 4.0960e-05\nEpoch 85\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.8251\nEpoch 00085: val_accuracy did not improve from 0.82141\n\nEpoch 00085: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.4097 - accuracy: 0.8251 - val_loss: 0.4252 - val_accuracy: 0.8201 - lr: 4.0960e-05\nEpoch 86\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.8246\nEpoch 00086: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4050 - accuracy: 0.8246 - val_loss: 0.4255 - val_accuracy: 0.8201 - lr: 3.2768e-05\nEpoch 87\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.8207\nEpoch 00087: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4154 - accuracy: 0.8207 - val_loss: 0.4240 - val_accuracy: 0.8201 - lr: 3.2768e-05\nEpoch 88\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8215\nEpoch 00088: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 39s 203ms\/step - loss: 0.4119 - accuracy: 0.8215 - val_loss: 0.4229 - val_accuracy: 0.8201 - lr: 3.2768e-05\nEpoch 89\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.8271\nEpoch 00089: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4075 - accuracy: 0.8271 - val_loss: 0.4240 - val_accuracy: 0.8194 - lr: 3.2768e-05\nEpoch 90\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8263\nEpoch 00090: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 202ms\/step - loss: 0.4044 - accuracy: 0.8263 - val_loss: 0.4235 - val_accuracy: 0.8194 - lr: 3.2768e-05\nEpoch 91\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8315\nEpoch 00091: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.4049 - accuracy: 0.8315 - val_loss: 0.4254 - val_accuracy: 0.8194 - lr: 3.2768e-05\nEpoch 92\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8263\nEpoch 00092: val_accuracy did not improve from 0.82141\n\nEpoch 00092: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n191\/191 [==============================] - 39s 202ms\/step - loss: 0.4061 - accuracy: 0.8263 - val_loss: 0.4255 - val_accuracy: 0.8207 - lr: 3.2768e-05\nEpoch 93\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8253\nEpoch 00093: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.4094 - accuracy: 0.8253 - val_loss: 0.4255 - val_accuracy: 0.8214 - lr: 2.6214e-05\nEpoch 94\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.8271\nEpoch 00094: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 39s 203ms\/step - loss: 0.4079 - accuracy: 0.8271 - val_loss: 0.4258 - val_accuracy: 0.8214 - lr: 2.6214e-05\nEpoch 95\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8246\nEpoch 00095: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4080 - accuracy: 0.8246 - val_loss: 0.4253 - val_accuracy: 0.8207 - lr: 2.6214e-05\nEpoch 96\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.8230\nEpoch 00096: val_accuracy did not improve from 0.82141\n\nEpoch 00096: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n191\/191 [==============================] - 39s 204ms\/step - loss: 0.4053 - accuracy: 0.8230 - val_loss: 0.4242 - val_accuracy: 0.8194 - lr: 2.6214e-05\nEpoch 97\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.8253\nEpoch 00097: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 39s 202ms\/step - loss: 0.4060 - accuracy: 0.8253 - val_loss: 0.4243 - val_accuracy: 0.8194 - lr: 2.0972e-05\nEpoch 98\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4018 - accuracy: 0.8269\nEpoch 00098: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.4018 - accuracy: 0.8269 - val_loss: 0.4251 - val_accuracy: 0.8214 - lr: 2.0972e-05\nEpoch 99\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3958 - accuracy: 0.8333\nEpoch 00099: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.3958 - accuracy: 0.8333 - val_loss: 0.4252 - val_accuracy: 0.8214 - lr: 2.0972e-05\nEpoch 100\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.8230\nEpoch 00100: val_accuracy did not improve from 0.82141\n\nEpoch 00100: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4085 - accuracy: 0.8230 - val_loss: 0.4251 - val_accuracy: 0.8214 - lr: 2.0972e-05\nEpoch 101\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8266\nEpoch 00101: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 39s 202ms\/step - loss: 0.4029 - accuracy: 0.8266 - val_loss: 0.4255 - val_accuracy: 0.8214 - lr: 1.6777e-05\nEpoch 102\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.8236\nEpoch 00102: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 39s 204ms\/step - loss: 0.4038 - accuracy: 0.8236 - val_loss: 0.4252 - val_accuracy: 0.8214 - lr: 1.6777e-05\nEpoch 103\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8310\nEpoch 00103: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 201ms\/step - loss: 0.3995 - accuracy: 0.8310 - val_loss: 0.4254 - val_accuracy: 0.8214 - lr: 1.6777e-05\nEpoch 104\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8289\nEpoch 00104: val_accuracy did not improve from 0.82141\n\nEpoch 00104: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n191\/191 [==============================] - 39s 205ms\/step - loss: 0.4049 - accuracy: 0.8289 - val_loss: 0.4248 - val_accuracy: 0.8214 - lr: 1.6777e-05\nEpoch 105\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8266\nEpoch 00105: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 202ms\/step - loss: 0.4030 - accuracy: 0.8266 - val_loss: 0.4246 - val_accuracy: 0.8214 - lr: 1.3422e-05\nEpoch 106\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.8351\nEpoch 00106: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 39s 203ms\/step - loss: 0.3972 - accuracy: 0.8351 - val_loss: 0.4255 - val_accuracy: 0.8207 - lr: 1.3422e-05\nEpoch 107\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.8287\nEpoch 00107: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4063 - accuracy: 0.8287 - val_loss: 0.4257 - val_accuracy: 0.8207 - lr: 1.3422e-05\nEpoch 108\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.8274\nEpoch 00108: val_accuracy did not improve from 0.82141\n\nEpoch 00108: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4074 - accuracy: 0.8274 - val_loss: 0.4258 - val_accuracy: 0.8201 - lr: 1.3422e-05\nEpoch 109\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.8266\nEpoch 00109: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4093 - accuracy: 0.8266 - val_loss: 0.4253 - val_accuracy: 0.8207 - lr: 1.0737e-05\nEpoch 110\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8322\nEpoch 00110: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4041 - accuracy: 0.8322 - val_loss: 0.4254 - val_accuracy: 0.8207 - lr: 1.0737e-05\nEpoch 111\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4014 - accuracy: 0.8284\nEpoch 00111: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4014 - accuracy: 0.8284 - val_loss: 0.4255 - val_accuracy: 0.8207 - lr: 1.0737e-05\nEpoch 112\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8261\nEpoch 00112: val_accuracy did not improve from 0.82141\n\nEpoch 00112: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4076 - accuracy: 0.8261 - val_loss: 0.4255 - val_accuracy: 0.8207 - lr: 1.0737e-05\nEpoch 113\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8278\nEpoch 00113: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4020 - accuracy: 0.8278 - val_loss: 0.4257 - val_accuracy: 0.8207 - lr: 8.5899e-06\nEpoch 114\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3999 - accuracy: 0.8332\nEpoch 00114: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.3999 - accuracy: 0.8332 - val_loss: 0.4257 - val_accuracy: 0.8207 - lr: 8.5899e-06\nEpoch 115\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.8315\nEpoch 00115: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4025 - accuracy: 0.8315 - val_loss: 0.4258 - val_accuracy: 0.8207 - lr: 8.5899e-06\nEpoch 116\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8269\nEpoch 00116: val_accuracy did not improve from 0.82141\n\nEpoch 00116: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4041 - accuracy: 0.8269 - val_loss: 0.4257 - val_accuracy: 0.8207 - lr: 8.5899e-06\nEpoch 117\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.8263\nEpoch 00117: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4059 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 6.8719e-06\nEpoch 118\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.8348\nEpoch 00118: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.3994 - accuracy: 0.8348 - val_loss: 0.4261 - val_accuracy: 0.8201 - lr: 6.8719e-06\nEpoch 119\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.8299\nEpoch 00119: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.3988 - accuracy: 0.8299 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 6.8719e-06\nEpoch 120\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.8317\nEpoch 00120: val_accuracy did not improve from 0.82141\n\nEpoch 00120: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4023 - accuracy: 0.8317 - val_loss: 0.4257 - val_accuracy: 0.8207 - lr: 6.8719e-06\nEpoch 121\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4010 - accuracy: 0.8317\nEpoch 00121: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4010 - accuracy: 0.8317 - val_loss: 0.4258 - val_accuracy: 0.8201 - lr: 5.4976e-06\nEpoch 122\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.8340\nEpoch 00122: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 196ms\/step - loss: 0.3939 - accuracy: 0.8340 - val_loss: 0.4257 - val_accuracy: 0.8201 - lr: 5.4976e-06\nEpoch 123\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.8255\nEpoch 00123: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 196ms\/step - loss: 0.3997 - accuracy: 0.8255 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 5.4976e-06\nEpoch 124\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.8274\nEpoch 00124: val_accuracy did not improve from 0.82141\n\nEpoch 00124: ReduceLROnPlateau reducing learning rate to 4.398046075948514e-06.\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4062 - accuracy: 0.8274 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 5.4976e-06\nEpoch 125\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8268\nEpoch 00125: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4072 - accuracy: 0.8268 - val_loss: 0.4258 - val_accuracy: 0.8201 - lr: 4.3980e-06\nEpoch 126\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.8258\nEpoch 00126: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4008 - accuracy: 0.8258 - val_loss: 0.4258 - val_accuracy: 0.8201 - lr: 4.3980e-06\nEpoch 127\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.8299\nEpoch 00127: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4023 - accuracy: 0.8299 - val_loss: 0.4261 - val_accuracy: 0.8201 - lr: 4.3980e-06\nEpoch 128\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.8245\nEpoch 00128: val_accuracy did not improve from 0.82141\n\nEpoch 00128: ReduceLROnPlateau reducing learning rate to 3.518437006277964e-06.\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4048 - accuracy: 0.8245 - val_loss: 0.4260 - val_accuracy: 0.8201 - lr: 4.3980e-06\nEpoch 129\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8309\nEpoch 00129: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.4049 - accuracy: 0.8309 - val_loss: 0.4260 - val_accuracy: 0.8201 - lr: 3.5184e-06\nEpoch 130\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8314\nEpoch 00130: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.3982 - accuracy: 0.8314 - val_loss: 0.4260 - val_accuracy: 0.8201 - lr: 3.5184e-06\nEpoch 131\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8325\nEpoch 00131: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 196ms\/step - loss: 0.3952 - accuracy: 0.8325 - val_loss: 0.4261 - val_accuracy: 0.8201 - lr: 3.5184e-06\nEpoch 132\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.8302\nEpoch 00132: val_accuracy did not improve from 0.82141\n\nEpoch 00132: ReduceLROnPlateau reducing learning rate to 2.814749677781947e-06.\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.3937 - accuracy: 0.8302 - val_loss: 0.4261 - val_accuracy: 0.8201 - lr: 3.5184e-06\nEpoch 133\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.8264\nEpoch 00133: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.4040 - accuracy: 0.8264 - val_loss: 0.4261 - val_accuracy: 0.8201 - lr: 2.8147e-06\nEpoch 134\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.8271\nEpoch 00134: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 196ms\/step - loss: 0.4053 - accuracy: 0.8271 - val_loss: 0.4261 - val_accuracy: 0.8201 - lr: 2.8147e-06\nEpoch 135\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.8289\nEpoch 00135: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.3970 - accuracy: 0.8289 - val_loss: 0.4261 - val_accuracy: 0.8201 - lr: 2.8147e-06\nEpoch 136\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8251\nEpoch 00136: val_accuracy did not improve from 0.82141\n\nEpoch 00136: ReduceLROnPlateau reducing learning rate to 2.2517997422255576e-06.\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4072 - accuracy: 0.8251 - val_loss: 0.4260 - val_accuracy: 0.8201 - lr: 2.8147e-06\nEpoch 137\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8289\nEpoch 00137: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.4029 - accuracy: 0.8289 - val_loss: 0.4260 - val_accuracy: 0.8201 - lr: 2.2518e-06\nEpoch 138\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.8297\nEpoch 00138: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.3993 - accuracy: 0.8297 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 2.2518e-06\nEpoch 139\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8300\nEpoch 00139: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.4020 - accuracy: 0.8300 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 2.2518e-06\nEpoch 140\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.8278\nEpoch 00140: val_accuracy did not improve from 0.82141\n\nEpoch 00140: ReduceLROnPlateau reducing learning rate to 1.801439793780446e-06.\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.4048 - accuracy: 0.8278 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 2.2518e-06\nEpoch 141\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.8266\nEpoch 00141: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4024 - accuracy: 0.8266 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 1.8014e-06\nEpoch 142\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.8356\nEpoch 00142: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.3874 - accuracy: 0.8356 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 1.8014e-06\nEpoch 143\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8305\nEpoch 00143: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.3974 - accuracy: 0.8305 - val_loss: 0.4260 - val_accuracy: 0.8201 - lr: 1.8014e-06\nEpoch 144\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.8310\nEpoch 00144: val_accuracy did not improve from 0.82141\n\nEpoch 00144: ReduceLROnPlateau reducing learning rate to 1.441151835024357e-06.\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.3966 - accuracy: 0.8310 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 1.8014e-06\nEpoch 145\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4042 - accuracy: 0.8233\nEpoch 00145: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 200ms\/step - loss: 0.4042 - accuracy: 0.8233 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 1.4412e-06\nEpoch 146\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.8256\nEpoch 00146: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.4038 - accuracy: 0.8256 - val_loss: 0.4258 - val_accuracy: 0.8201 - lr: 1.4412e-06\nEpoch 147\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4104 - accuracy: 0.8230\nEpoch 00147: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 199ms\/step - loss: 0.4104 - accuracy: 0.8230 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 1.4412e-06\nEpoch 148\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.8276\nEpoch 00148: val_accuracy did not improve from 0.82141\n\nEpoch 00148: ReduceLROnPlateau reducing learning rate to 1.1529215043992736e-06.\n191\/191 [==============================] - 37s 196ms\/step - loss: 0.4055 - accuracy: 0.8276 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 1.4412e-06\nEpoch 149\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3949 - accuracy: 0.8300\nEpoch 00149: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 198ms\/step - loss: 0.3949 - accuracy: 0.8300 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 1.1529e-06\nEpoch 150\/150\n191\/191 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8338\nEpoch 00150: val_accuracy did not improve from 0.82141\n191\/191 [==============================] - 38s 197ms\/step - loss: 0.3942 - accuracy: 0.8338 - val_loss: 0.4259 - val_accuracy: 0.8201 - lr: 1.1529e-06","bd6745da":" plots_visual(history)","3ea17b5a":"from tensorflow.keras.models import load_model\nmodel  = load_model('\/content\/drive\/My Drive\/kaggle\/best_model.h5')","c8203747":"test =  pd.read_csv('\/content\/drive\/My Drive\/kaggle\/test (1).csv')\n\ndef prediction(data, namefile):\n    data = data.copy()\n    data['text'] = data['text'].apply(clean_text)\n    dataval = tokenizer.texts_to_sequences(data['text'])\n    text_sequens = pad_sequences(dataval, maxlen=maxLen,padding='post')\n    predictions = model.predict(text_sequens)\n    predictions = np.round(predictions).astype(int).reshape(3263)\n    testData = data[['id']]\n    testData['target'] = predictions\n    testData.to_csv(f'{namefile}.csv',index=False)\n","adaa5b16":"prediction(test, 'submitnew')","2f3158e3":"Import ","9e47c566":"PREDICT MODEL"}}