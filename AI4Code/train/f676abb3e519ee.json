{"cell_type":{"e501015f":"code","420045f6":"code","f2b08811":"code","48e0f6c1":"code","2fd04b31":"code","b63ea49b":"code","5c3cde7c":"code","34e4db7b":"code","e8094a0f":"code","4e158e9c":"code","539d9df5":"code","57f995c0":"markdown","836e7bda":"markdown","64ad10af":"markdown","5571c994":"markdown","c0d3375f":"markdown","37b0cd43":"markdown","cd183603":"markdown","a26cf980":"markdown","dcb5274d":"markdown","9622a5fa":"markdown","737135d5":"markdown","6bc6abd5":"markdown","93720497":"markdown"},"source":{"e501015f":"#import required packages\n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport plotly\nimport numpy as np\nimport plotly.graph_objs as go\nimport seaborn as sns\nimport pandas as pd\nimport datetime as dt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#read the data file\ndf1 = pd.read_csv('..\/input\/metacritic_games.csv', delimiter=',')\n\n#add total critics and total users\ndf1['total_critics'] = df1['positive_critics'] + df1['neutral_critics'] + df1['negative_critics'] \ndf1['total_users'] = df1['positive_users'] + df1['neutral_users'] + df1['negative_users']\n\n#make release date a datetime\ndf1['release_date'] = pd.to_datetime(df1['release_date'])\n\n#quick checkup that the data looks good\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns. Below is a sample of 5 random rows.')\ndf1.sample(5)","420045f6":"#SUB-PROJECT 1: create a visualization showing the total percentage of positive\/neutral\/negative critic scores and user scores\n\n#get the percentage of each review type\npercent_positive_reviews = [df1['positive_critics'].sum()\/df1['total_critics'].sum()*100, df1['positive_users'].sum()\/df1['total_users'].sum()*100]\npercent_neutral_reviews = [df1['neutral_critics'].sum()\/df1['total_critics'].sum()*100, df1['neutral_users'].sum()\/df1['total_users'].sum()*100]\npercent_negative_reviews = [df1['negative_critics'].sum()\/df1['total_critics'].sum()*100, df1['negative_users'].sum()\/df1['total_users'].sum()*100]\n\n#display data\nx_shape = [0,1]\nx_names = ('Critics','Users')\nplt.bar(x_shape, percent_positive_reviews, color='g', edgecolor='white', label = 'Postive reviews')\nplt.bar(x_shape, percent_neutral_reviews, bottom=percent_positive_reviews, color='y', edgecolor='white', label = 'Neutral reviews')\nplt.bar(x_shape, percent_negative_reviews, bottom=np.add(percent_positive_reviews, percent_neutral_reviews), color='r', edgecolor='white', label = 'Negative reviews')\nplt.xticks(x_shape, x_names)\nplt.legend(loc='right', bbox_to_anchor=(1.45, 0.5))\nplt.show()","f2b08811":"#SUB-PROJECT 2: create a visualization showing number of games in each genre and platform\n#Also decide if this looks better with the filter at over 300 or over 100 for the \"Other\" category in the Genre Breakdown\n\n#count occurences of each genre and platform\ngenre_series = df1['genre'].value_counts().sort_values(ascending=True)\nplatform_series = df1['platform'].value_counts().sort_values(ascending=True)\n\n#filter out genres with less than 300 occurences and group them in an \"Other category\" (\"Misc\" has 282)\nlarge_genres = genre_series[genre_series > 300] \nother_count = 0\nfor x in genre_series:\n    if x < 300:\n        other_count = other_count + x\nlarge_genres.set_value('Other', other_count)\n\n#display data\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.pie(large_genres.values, labels=large_genres.index, autopct='%1.0f%%')\nax1.set_title(\"Genre Breakdown\")\nax2.pie(platform_series.values, labels=platform_series.index, autopct='%1.0f%%')\nax2.set_title(\"Platform Breakdown\")\nplt.show()","48e0f6c1":"#SUB-PROJECT 3: create a visualization of the correlation between total critic reviews vs metascore\n\n#display data\ndf1.plot(kind='scatter', x='total_critics', y='metascore')\nplt.show()","2fd04b31":"#SUB-PROJECT 4: create a visualization of game score vs. \"popularity\", i.e., user reviews. Need to study additional data to determine how sales\/active players correlate to user reviews\n\n#manually marking notable games on the graph to appear red\nnotable_points_df = pd.DataFrame(df1[(df1['game'] == 'Diablo III') | (df1['game'] == 'Infestation: Survivor Stories (The War Z)') | (df1['game'] == 'Star Wars Battlefront II')])\n\n#display data\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7))\ndf1.plot(kind='scatter', x='total_users', y='user_score', ax = ax1)\nnotable_points_df.plot(kind='scatter', x='total_users', y='user_score', ax = ax1, color = 'r')\ndf1.plot(kind='scatter', x='total_users', y='metascore', ax = ax2)\nnotable_points_df.plot(kind='scatter', x='total_users', y='metascore', ax = ax2, color = 'r')\n\nplt.show()","b63ea49b":"#SUB-PROJECT 5: visualization with rating on the x-axis, and metascore + user score on the y-axis. \n#perhaps I can figure out how to put these both on the same graph maybe with a violinplot where each \"violin\" is split down the middle?\n#Also having trouble putting these side by side. the method I used above doesn't seem to work with seaborn?\n#investigate whether difference in metascore for M and T games is statistically significant\n\n#remove RP and AO due to low sample sizes and investigate correlation between genre and score UNFINISHED\n#clean_ratings = df1[(df1['rating'] == 'E10+') | (df1['rating'] == 'M') | (df1['rating'] == 'T') | (df1['rating'] == 'E')]\n\n#display data\nsns.catplot(x='rating',y='metascore', data = df1, kind=\"boxen\")\nsns.catplot(x='rating',y='user_score', data = df1, kind=\"boxen\")\nplt.show()","5c3cde7c":"#SUB-PROJECT 6: activity on metacritic by year\n\n#display data\ndf1['release_date'].groupby(df1['release_date'].dt.year).hist()\nplt.show()","34e4db7b":"#SUB-PROJECT 7. market share of each platform by year. VERY UNFINISHED\n#alright wait, why is there a missing slot in 2014. huh. I don't think I understand how map lambda works...\ndf1['release_date'].map(lambda d: d.year).plot(kind='hist')\nplt.show()","e8094a0f":"#SUB-PROJECT 8. games that critics hated while users loved, and vice versa\n\n#Went back to check the average metascore and user score due to such a large discrepancy in \"games users hate\" vs. \"games users love\" at the +\/- 25 rating threshold\nprint(\"Correlation between user score and metascore: \" + str(df1['metascore'].corr(df1['user_score']))[:4])\ndf1['metascore'].plot(kind = 'kde', xlim = (0, 100), label = ('metascore (mean = ' + (str(df1['metascore'].mean())[:4])) + ')')\ndf1['user_score'].plot(kind = 'kde', xlim = (0, 100), label = ('user score (mean = ' + (str(df1['user_score'].mean())[:4])) + ')')\nplt.xlabel('score')\nplt.legend()\n\n#Due to aforementioned discrepancy, we use a threshold of +50 for games users hate\nusers_hate_df = pd.DataFrame(df1[(df1['metascore'] - df1['user_score'] > 50) & (df1['total_users'] > 5)]) \nusers_love_df = pd.DataFrame(df1[(df1['metascore'] - df1['user_score'] < -25) & (df1['total_users'] > 5)])\n\n#display data\nplt.show()\nprint(\"Games with much higher critic reviews\")\ndisplay(users_hate_df[['game','developer','platform','genre','release_date','total_critics','total_users','metascore', 'user_score']])\nprint(\"Games with much higher user reviews\")\ndisplay(users_love_df[['game','developer','platform','genre','release_date','total_critics','total_users','metascore', 'user_score']])","4e158e9c":"#SUB-PROJECT 9. correlation between user score and metascore across popularity buckets, genres, dates. VERY UNFINISHED\nprint(\"Correlation between user score and metascore for:\")\nprint(\"Overall: \" + str(df1['metascore'].corr(df1['user_score']))[:4])\n\n#alright, replace this trash-tier code with a loop when you get the chance. should be pretty easy. Then get the correlations for genres, ratings, dates, etc.\nprint(\"PC games: \" + str(df1[(df1['platform'] == 'PC')].metascore.corr(df1.user_score))[:4])\nprint(\"PS4 games: \" + str(df1[(df1['platform'] == 'PS4')].metascore.corr(df1.user_score))[:4])\nprint(\"XONE games: \" + str(df1[(df1['platform'] == 'XONE')].metascore.corr(df1.user_score))[:4])\nprint(\"Switch games: \" + str(df1[(df1['platform'] == 'Switch')].metascore.corr(df1.user_score))[:4])","539d9df5":"#SUB-PROJECT 10 Analyze polarizing games (lots of positive and negative reviews) vs non-polarizing games (lots of middling reviews)\n\n#metacritic considers a score \"neutral\" if it is between 50 and 75. I manually toyed with numbers to achieve a reasonably-sized result here\npolarizing_critics_df = pd.DataFrame(df1[(df1['neutral_critics'] \/ df1['total_critics'] < .2) & (df1['metascore'] > 50) & (df1['metascore'] < 75) & (df1['total_users'] > 5)]) \npolarizing_users_df = pd.DataFrame(df1[(df1['neutral_users'] == 0) & (df1['user_score'] > 50) & (df1['user_score'] < 75) & (df1['total_users'] > 13)]) \n\n#display data\nprint(\"Games with polarized critic reviews\")\ndisplay(polarizing_critics_df[['game','developer','platform','genre','release_date','total_critics','total_users', 'metascore', 'user_score']])\nprint(\"Games with polarized user reviews\")\ndisplay(polarizing_users_df[['game','developer','platform','genre','release_date','total_critics','total_users', 'metascore', 'user_score']])","57f995c0":"Metacritic is growing, perhaps alongside the growing video game industry (although metacritic's growth rate seems to be slowing down). An interesting discovery here is that most video games release near the end of the year- additional research seems to indicate this is primarily due to Christmas.","836e7bda":"I decided to manually look at the outliers for this data. There are 13 games where the metascore is lower than the user score by 25, whereas there are 227 games (17x!) where the metascore is higher than the user score by the same value of 25 (and at least 5 user reviews). I was surprised at such a huge discrepancy here, so I went back to take a quick look at the correlation and distribution between average metascore vs. user score overall for all 5699 games in the data.\n\n227 games is of course too many, so I looked at games where the metascore is higher than the user score by a whopping 50 points, for which there were 21 games. Looking at these first, I quickly recognized all of them except for Out of the Park Baseball 17. Fortnite is objectively one of the most successful, if not the most successful, game of all time. The rest of these are all AAA titles, and every single one of them was a very successful game with the exception of the aforementioned Star Wars Battlefront II and Artifact, both faltering due to their monetization models rather than gameplay faults. Thus, I have to conclude that most of these games were review bombed. Note how many are EA games- a company that is often despised within the more serious gaming community due to the way they implement microtransactions despite consistently producing best-sellers. Also note that the trend of review bombing and seems to have started in 2017, around the time when companies started to push the envelope with microtransactions.\n\nFor games that users rated higher than critics, 4\/13 games are fanservice\/sex\/dating themed: Leisure Suit Larry: Reloaded, Dead or Alive Xtreme 3: Fortune, Senra Kagura Reflexions, and Super Seducer: How to Talk to Girls. Another 4\/13 are horror themed: The Haunted: Hell's Reach, Knock-knock, Crystal Rift, and loosely Immortal: Unchained. Note that sample sizes for these games are much lower; thus, I investigated some expanded data and it definitely seems that a disproportionately high number of games in these two categories are rated low by critics but high by users. Amusingly, Left Alive, released very recently in March of 2019, appears to be the only game I've ever seen that has clearly been reverse-review-bombed; it has a 8.6\/10 on metacritic with an extremely high number of ratings (1382), despite a 18% user rating for the PC version on Steam with 347 total reviews. ","64ad10af":"The percentage of positive reviews is actually pretty close. For bad but not super bad experiences, i.e., roughly the bottom quartile excluding the bottom 5%, critics are more likely to be neutral whereas users are negative. Makes sense- as an gamer, if I'm investing money and time in a bottom quartile gaming experience, I'm generally not going to be happy. A reviewer may be more forgiving- additionally, I also suspect reviewers have some incentive to avoid negative reviews.","5571c994":"Some data points that drew my attention on the graph (which I went back and marked in red):\n1. Diablo III, with 4682 user reviews. \n2. Infestation: Survivor Stories with 1601 user reviews but a metascore of only 20. \n3. The only game with over 1000 reviews and a lower user score than I:SS's 17 is Star Wars Battlefront II on the PS4 with 2331 users and a user score of 11. It also has an entry for the PC and XONE versions.\n\nAll 3 of these games were \"review bombed\" to protest their inclusion of ways to gain gameplay-impacting advantages with real money purchases, i.e., microtransactions. \n1. Top ranked players in Diablo II often bought and sold items through eBay; thus, its successor, Diablo III included a real money auction house within the game. It was removed after community backlash with little long-term damage done, as evidenced by Reaper of Souls (the expansion) selling 2.7 million copies in its first week. \n2. It's hard to tell how much of Infestation: Survivor Stories's rating is due to review bombing as it's widely regarded as a bad game anyway, but many reviews do complain about gameplay-impacting microtransactions.\n3. Star Wars Battlefront II locked playable characters through playtime, a fairly common practice in video games- however, the playtime requirements were unprecedently steep (40 hours for Darth Vader). Alternatively, players could unlock them with real money, which the gaming community viewed as an unethical cash grab. Notably, an EA employee discussing microtransactions in SWBCII holds the most downvoted commented on reddit with roughly 30x more downvotes than second place. Following the controversy, costs of unlocking characters were reduced by 75%, but sales of the game were still significantly affected- some sources report that SWBCII only sold 50% of what analysts expected!\n\nFurther investigation suggests that review bombing is much more common than I had anticipated, and thus my original hypothesis that the number of user reviews is a good indicator of game's sales and active players is incorrect. \n\nInterestingly, the games with the two highest user scores are God of War and The Witcher 3 (with 2500+ reviews each across all platforms). Both clearly merit high marks on gameplay alone; however, perhaps it isn't coincidental that the both of the development teams have been outspoken against microtransactions!","c0d3375f":"Top genres in \"Other\" include Sports, Racing, Simulation, and Puzzle, as well as games simply listed as Miscellaneous. The platform breakdown is quite interesting\/surprising to me, although it doesn't answer many questions on its own- would be interested in doing further research (for example, why does Nintendo never release its flagship games such as Mario on PC?). Nintendo is represented through 3 different consoles between Switch, 3DS, and WIIU, while Sony is represented through both PS4 and VITA. ","37b0cd43":"There are only 19 games listed as RP (Rating Pending); while the sample size is very low, I would expect this category to have a lower average score since it includes unfinished or cancelled games such as Clockwork Empires.\n\nThere are only two games rated \"AO\" released within the time frame of the data (2011-2019): Hatred for violence, and Seduce Me for sexual content. \n\nOtherwise, it seems that M games average the highest metascore while T games average the lowest. I will be doing more investigation to see if the difference is statistically significant (as per usual, once I figure out how), especially since the user ratings seem very consistent between M and T games.","cd183603":"NINTENDO GAMERS ARE SHEEP (jk)","a26cf980":"A positive correlation here is expected, of course. Even so, it is interesting to see the extent that having a number of critic reviews past a certain threshold (i.e., AAA games) guarantees a score higher than some threshold. I will look into learning how to quantify that extent more than simply eyeballing it on a scatter plot soon! But for now, we can see on the graph that games with 60+ critics all have metascores of 50+, and games with 100+ critics all have metascores of 70+. ","dcb5274d":"Most interesting overall conclusions for me as a gamer:\n1. Users leave about half as many neutral reviews as critics, opting for negative reviews instead.\n2. PC games account for 38% of games listed on metacritic, and console games account for the rest.\n3. Critics never rate a AAA title poorly. Ever.\n4. Users especially love leaving negative reviews to protest microstransactions.\n5. M-rated games score the highest, T-rated games score the lowest (needs verification for statistical sigificance).\n6. Most games are released near the end of the year in order to capitalize on buyers celebrating the birth of Christ.\n7. \n8. Once again, users love leaving extremely negative users to protest microtransactions. Games in the horror and dating genres seem prone to be underrated by critics.\n9. \n10. Weak data, but games in the hack and slash genre seem to be polarizing to critics. ","9622a5fa":"A few quick notes about the data. Many games are on multiple platforms, each with their own data entry (e.g., Stardew Valley is on PC, PS4, Switch, and XONE, and thus occupies 4 different rows). The counts of user reviews (e.g., the positive_users columns) refer to how many written reviews there are, not the number of ratings which the user_score is based off of. Unfortunately, the data does not contain the number of user ratings. Also for some reason metacritic ranges critic scores from 0 to 100 and user scores from 0 to 10- thus the user score is multiplied by 10 in this data. \n\nFinally, for qualitative analysis, it's important to keep in mind that metacritic is a much smaller review site than Steam. Of course, Steam only contains reviews for games on its own platform. I'd be very interested in comparing metacritic reviews for games that are on Steam vs. not on Steam, but that is a stretch goal as it would require web scraping Steam reviews. At any rate, the goal of this project is for me to learn some basic Python and data science using this simple dataset rather than form robust conclusions about the gaming industry :)","737135d5":"OK SERIOUSLY WHERE IS 2014","6bc6abd5":"I wasn't sure what parameters to use here to best represent polarizing games for critics and users- the data presented here is not that great as it has serious sample size issues. As discussed earlier, users leave neutral reviews much more rarely than critics- thus the two tables were created differently. Unsurprisingly, very unique games show up in both the critics and users sections, e.g., Fortix 2 and Cloud Chamber, respectively. \"Hack and slash\" games appear to be overrepresented in the set of games with polarizing critic reviews. Some possible reasons for polarizing user reviews include: too high expectations (BioShock: The Collection), too buggy (Out of the Park Baseball 15), or too difficult (Mark McMorris Infinite Air). Some gamers tend to be more accepting of these things while others are not. ","93720497":"Hi I'm Don! While I do have a Computer Science degree, this will be my first time working on anything related to programming, data science, etc. in over 7 years, and also my first time ever using Python. I will be investigating this dataset containing reviews of games released in 2011-2019 scraped from metacritic.com by Andrea Cadeddu at https:\/\/www.kaggle.com\/skateddu\/metacritic-games-stats-20112019. \n\nI have given myself 10 practice sub-projects to look at the data in ways I think could be interesting (ordered by estimated difficulty to implement). Progress rating at the end of each sub-project: 0\/5 indicates no progress beyond ideation, 1\/5 indicates a cell has been created, 2\/5 indicates some working code has been run, 3\/5 indicates presentable data, 4\/5 indicates some polish, 5\/5 indicates completion:\n\n1. create a visualization showing the percent of total positive\/neutral\/negative critic scores and user scores (5\/5)\n2. create a visualization showing number of games in each genre (4\/5)\n3. create a visualization of the correlation between total critic reviews vs. metascore (3\/5)\n4. create a visualization of both metascore and user score vs. \"popularity\", i.e., total user reviews (4\/5)\n5. analyze any correlation between rating vs. both metascore and user score (3\/5)\n6. create a visualization showing the number of critic\/user reviews by year, look at the breakdown by positive\/neutral\/negative (3\/5)\n7. create a visualization showing the market share of each platform per year, really curious how PC vs. everything else has fared, and also what the life cycle of a console looks like- how many games are released in the 1st, 2nd, 3rd, etc. year for consoles and how well-received are those games? (1\/5)\n8. analyze any games that critics hated but users loved, and vice versa (3\/5)\n9. determine correlation between metascore\/user_score across genres, dates, and popularity buckets, create visualization of any interesting findings. (2\/5)\n10. analyze polarizing games (lots of positive\/negative with little neutral) vs. non-polarizing games for both critics\/users. Investigate correlation with popularity and year (2\/5)\n11. Stretch goals: 11A) web scrape Steam data, 11B) compare Steam reviews to metacritic reviews, 11C) compare metacritic reviews of games not on Steam to metacritic reviews of games on Steam\n\nOverall progress estimate: 80% complete"}}