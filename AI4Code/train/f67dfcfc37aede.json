{"cell_type":{"41785dac":"code","53583920":"code","815f4f54":"code","d8df149c":"code","dd3c4708":"code","58e482c7":"code","7bed8dfd":"code","aa11a024":"code","cff81e01":"code","804e3f88":"code","d0a81f1d":"code","51a762c1":"code","a6838cbb":"markdown","7e6d5abf":"markdown","cdcb5c14":"markdown","8ba32025":"markdown","eba3749c":"markdown","35548232":"markdown"},"source":{"41785dac":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport sklearn\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold","53583920":"tabular_columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nimage_size = 224\nbatch_size = 128","815f4f54":"test = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/sample_submission.csv\")\ntest[\"file_path\"] = test[\"Id\"].apply(lambda identifier: \"..\/input\/petfinder-pawpularity-score\/test\/\" + identifier + \".jpg\")\ntest.head()","d8df149c":"efficient_net = tf.keras.applications.EfficientNetB0(\n    weights = \"..\/input\/efficientnet-b0-for-keras-no-top\/efficientnetb0_notop.h5\", \n    include_top = False, \n    input_shape = (image_size, image_size, 3)\n)    \nefficient_net.trainable = False\nefficient_net.summary()","dd3c4708":"keras.utils.plot_model(efficient_net, show_shapes=True)","58e482c7":"def get_image_prediction_model(inputs):\n    x = efficient_net(inputs)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.0)(x)\n    return x","7bed8dfd":"def get_tabular_prediciton_model(inputs):\n    width = 32\n    depth = 3\n    activation = \"relu\"\n    kernel_regularizer = keras.regularizers.l2()\n    x = keras.layers.Dense(\n            width, \n            activation=activation,\n            kernel_regularizer=kernel_regularizer\n        )(inputs)\n    for i in range(depth):\n        if i == 0:\n            x = inputs\n        x = keras.layers.Dense(\n            width, \n            activation=activation,\n            kernel_regularizer=kernel_regularizer\n        )(x)\n        if (i + 1) % 3 == 0:\n            x = keras.layers.Concatenate()([x, inputs])\n    return x","aa11a024":"def get_model():\n    image_inputs = tf.keras.Input((image_size, image_size , 3))\n    tabular_inputs = tf.keras.Input(len(tabular_columns))\n    image_x = get_image_prediction_model(image_inputs)\n    tabular_x = get_tabular_prediciton_model(tabular_inputs)\n    x = tf.keras.layers.Concatenate(axis=1)([image_x, tabular_x])\n    output = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs=[image_inputs, tabular_inputs], outputs=[output])\n    optimizer = tf.keras.optimizers.Adam(1e-3)\n    model.compile(loss=rmse, optimizer=optimizer, metrics=[\"mae\", \"mape\"])\n    return model","cff81e01":"def rmse(y_true, y_pred):\n    return tf.sqrt(tf.reduce_mean((y_true -  y_pred) ** 2))","804e3f88":"def preprocess_test_data(image_url, tabular):\n    print(image_url, tabular)\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (image_size, image_size))\n    # 0 won't be used in prediction, but it's needed in this senario or the tabular variable is treated as label.\n    return (image, tabular), 0","d0a81f1d":"test_ds = tf.data.Dataset.from_tensor_slices((test[\"file_path\"], test[tabular_columns])).map(preprocess_test_data).batch(batch_size).cache().prefetch(2)","51a762c1":"total_results = []\nfor i in [0, 1, 2, 4]:\n    model = get_model()\n    model.load_weights(\"..\/input\/petfinder-efficientnet-model\/petfinder_efficientnet_model_%d.h5\"%(i))\n    results = model.predict(test_ds).reshape(-1)\n    total_results.append(results)\nresults = np.mean(total_results, axis=0).reshape(-1)\nsample_submission[\"Pawpularity\"] = results\nsample_submission.to_csv(\"submission.csv\", index=False)\n","a6838cbb":"# Pawpularity with EfficientNet: [Inference]\n\n<font size=\"5\" color=\"red\">If you found my work useful, please upvote!<\/font>","7e6d5abf":"### The Pawpularity Model","cdcb5c14":"### The Tabular Prediciton Model","8ba32025":"This is Inference Notebook, training notebook can be found [here]( https:\/\/www.kaggle.com\/lonnieqin\/pawpularity-with-efficientnet-training).\n\nAccording to the training notebook, validation RMSE for different models are following:\n\n|  Model   | Validation RMSE  |\n|  ----  | ----  |\n| petfinder_efficientnet_model_0.h5  | 18.96 |\n| petfinder_efficientnet_model_1.h5  | 18.84 |\n| petfinder_efficientnet_model_2.h5  | 18.41 |\n| petfinder_efficientnet_model_3.h5  | 18.34 |\n| petfinder_efficientnet_model_4.h5  | 19.04 |\n\n\n\n\nI have been trying different ways of ensambe method. Here are results of different experiments, currently using mean ensamble removing best and worst models have slightly better Test RMSE score.\n\n|  Method   | Test RMSE  |\n|  ----  | ----  |\n| mean ensamble of all models  | 18.75475 |\n| mean ensamble of top 2 models  | 18.77554 |\n| mean ensamble of top 3 models  | 18.77399 |\n| mean ensamble removing best and worst models  | 18.74878 |\n| mean ensamble removing worst model  | 18.75553 |\n| mean ensamble removing best model  | 18.74980 |\n\n\n\n","eba3749c":"### The Efficient Net Model","35548232":"### The Image Prediciton Model"}}