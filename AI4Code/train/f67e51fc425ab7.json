{"cell_type":{"77933d12":"code","fd165276":"code","9bdc33a8":"code","dc43d4dc":"code","a41ea06f":"code","b536b67b":"code","ec5c2bc0":"code","d68c8920":"code","320338d7":"code","01006007":"code","f63c6e4b":"code","417ba745":"code","f4023d87":"code","3920bd97":"code","880db373":"markdown","e31f7f78":"markdown","97f65e0d":"markdown","b84e0869":"markdown","1b39bf2f":"markdown","5aa09b79":"markdown","a775374d":"markdown"},"source":{"77933d12":"%cd ..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\nfrom efficientnet_pytorch import EfficientNet\n%cd -","fd165276":"from fastai.vision.all import *","9bdc33a8":"class AlbumentationsTransform(RandTransform):\n    \"A transform handler for multiple `Albumentation` transforms\"\n    split_idx,order=None,2\n    def __init__(self, train_aug, valid_aug): store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        return PILImage.create(aug_img)","dc43d4dc":"def get_x(row): return data_path\/row['image_id']\ndef get_y(row): return row['label']","a41ea06f":"class LeafModel(Module):\n    def __init__(self, num_classes):\n\n        self.effnet = EfficientNet.from_pretrained(\"efficientnet-b3\")\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(1536, num_classes)\n\n    def forward(self, image):\n        batch_size, _, _, _ = image.shape\n\n        x = self.effnet.extract_features(image)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        outputs = self.out(self.dropout(x))\n        return outputs","b536b67b":"path = Path(\"..\/input\")\ndata_path = path\/'cassava-leaf-disease-classification'","ec5c2bc0":"learn = load_learner(Path('..\/input\/abishektez\/baseline'), cpu=False)","d68c8920":"learn.to_native_fp32()","320338d7":"sample_df = pd.read_csv(data_path\/'sample_submission.csv')\nsample_df.head()","01006007":"sample_copy = sample_df.copy()\nsample_copy['image_id'] = sample_copy['image_id'].apply(lambda x: f'test_images\/{x}')","f63c6e4b":"test_dl = learn.dls.test_dl(sample_copy)","417ba745":"preds, _ = learn.tta(dl=test_dl, n=15, beta=0)","f4023d87":"sample_df['label'] = preds.argmax(dim=-1).numpy()","3920bd97":"sample_df.to_csv('submission.csv',index=False)","880db373":"## Bringing in the Items We Need\n\nWhen we export a `Learner` object, it expects *everything* we had be available when we load it back in. Specifically our **functions** should be in the available namespace. Below we've done just that, bringing back `AlbumentationsTransform`, our `get_x` and `get_y`, and our `LeafModel`:","e31f7f78":"We'll also need that `data_path`","97f65e0d":"## fastai Abhishek Inference Module\n\nThis will be an inference module based on my previous notebook [here](https:\/\/www.kaggle.com\/muellerzr\/recreating-abhishek-s-tez-with-fastai)\n\nWe'll be showing how to import our exported learner, perform a 15x TTA (as is done with his notebook), as well as recreate our transform pipeline","b84e0869":"## Performing TTA\n\nFor our TTA we will be doing a 15x ensemble similar to what was performed there. \n\n> Inference code is based off my kernel [here](https:\/\/www.kaggle.com\/muellerzr\/submission-notebook)","1b39bf2f":"Let's build our `test_dl` and grab our predictions:","5aa09b79":"## Our Imports\n\nLet's grab all our imports","a775374d":"And now we can load our model back in with a simple `load_learner`"}}