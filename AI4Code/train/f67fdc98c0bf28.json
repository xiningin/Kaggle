{"cell_type":{"6f9253fa":"code","05320f53":"code","eeab9fbb":"code","21277bb3":"code","b8cbfc5f":"code","b6992a43":"code","e6ccbb40":"code","4f996ed0":"code","f5fdca66":"code","286c4bdf":"code","05bb6c8e":"code","1ccf02c9":"code","3c96cea5":"code","eefddc08":"code","57cf51c1":"code","46ae668e":"code","b3c65ec8":"code","f337652b":"code","a88eb2ec":"code","57c5f3e0":"code","069d5ebe":"code","35cd567f":"code","398806e9":"code","26feeff4":"code","c7ae6d38":"code","822c2be2":"code","61829f75":"code","113daa06":"code","cfddea0e":"code","186a4f9e":"code","17405b8d":"markdown","6d68202c":"markdown","f53a8d2c":"markdown","7e1368a0":"markdown","08f807fc":"markdown","cfcd52f0":"markdown"},"source":{"6f9253fa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier","05320f53":"X = pd.read_csv(\"..\/input\/titanic2\/test.csv\")\ny = pd.read_csv(\"..\/input\/titanic2\/train.csv\")","eeab9fbb":"print(X.shape,y.shape)","21277bb3":"y.info()","b8cbfc5f":"y.describe()","b6992a43":"y.head(8)","e6ccbb40":"total = y.isnull().sum().sort_values(ascending=False)\npercent_1 = y.isnull().sum()\/y.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(5)","4f996ed0":"#Step 1 Passenger Id now drop\n\ny= y.drop(['PassengerId'], axis=1)","f5fdca66":"# Step 2 Cabin ''A cabin number looks like \u2018C123\u2019 and the letter refers to the deck.''\n\nimport re\ndeck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\ndata = [X, y]\n\nfor dataset in data:\n    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    dataset['Deck'] = dataset['Deck'].map(deck)\n    dataset['Deck'] = dataset['Deck'].fillna(0)\n    dataset['Deck'] = dataset['Deck'].astype(int)\n\n# we can now drop the cabin feature\ny = y.drop(['Cabin'], axis=1)\nX = X.drop(['Cabin'], axis=1)","286c4bdf":"# Step 3 Age ''the age features missing values''\n\ndata = [y, X]\n\nfor dataset in data:\n    mean = y[\"Age\"].mean()\n    std = X[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    \n    # compute random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    \n    # fill NaN values in Age column with random values generated\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = y[\"Age\"].astype(int)\n\n\ny[\"Age\"].isnull().sum()","05bb6c8e":"# Step 4 Embarked ''feature has only 2 missing values''\n\ny['Embarked'].describe()","1ccf02c9":"# y = train-dataset , X = test-dataset\ncommon_value = 'S'\ndata = [y, X]\n\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)","3c96cea5":"# Now Show Converting Features\n\ny.info()","eefddc08":"# Step 5 Fare ''Converting \u201cFare\u201d from float to int64, using the \u201castype()\u201d function pandas''\n\ndata = [y, X]\n\nfor dataset in data:\n    dataset['Fare'] = dataset['Fare'].fillna(0)\n    dataset['Fare'] = dataset['Fare'].astype(int)","57cf51c1":"# Step 6 Name \n'''the Name feature to extract the Titles from the Name, \nso that we can build a new feature out of that.'''\n\ndata = [y, X]\ntitles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\nfor dataset in data:\n    # extract titles\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    # replace titles with a more common title or as Rare\n    \n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    # convert titles into numbers\n    dataset['Title'] = dataset['Title'].map(titles)\n    # filling NaN with 0, to get safe\n    dataset['Title'] = dataset['Title'].fillna(0)\ny = y.drop(['Name'], axis=1)\nX = X.drop(['Name'], axis=1)\n","46ae668e":"# Step 7 Sex ''Convert \u2018Sex\u2019 feature into numeric''\n\ngenders = {\"male\": 0, \"female\": 1}\ndata = [y, X]\n\nfor dataset in data:\n    dataset['Sex'] = dataset['Sex'].map(genders)","b3c65ec8":"# Step 8 Ticket ''Describe after that Drop that Coloumn''\n\ny['Ticket'].describe()","f337652b":"y =  y.drop(['Ticket'], axis=1)\nX = X.drop(['Ticket'], axis=1)","a88eb2ec":"# Step 9 Embarked ''Convert \u2018Embarked\u2019 feature into numeric''\n\nports = {\"S\": 0, \"C\": 1, \"Q\": 2}\ndata = [y, X]\n\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].map(ports)","57c5f3e0":"data = [y, X]\nfor dataset in data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\ny['Age'].value_counts()","069d5ebe":"#SibSp and Parch\n\ndata = [y, X]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n    dataset['not_alone'] = dataset['not_alone'].astype(int)\ny['not_alone'].value_counts()","35cd567f":"# \u2018Fare\u2019 feature, we need to do the same as with the \u2018Age\u2019 feature\ny.head(8)","398806e9":"data = [y, X]\n\nfor dataset in data:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n    dataset['Fare'] = dataset['Fare'].astype(int)","26feeff4":" # creating new features\n\n # 1. Age time Class\n\n data = [y, X]\nfor dataset in data:\n    dataset['Age_Class']= dataset['Age']* dataset['Pclass']","c7ae6d38":"# 2. Fare per Person\n\nfor dataset in data:\n    dataset['Fare_Per_Person'] = dataset['Fare']\/(dataset['relatives']+1)\n    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n# Let's take a last look at the training set, before we start training the models.\ny.head(10)","822c2be2":"X_train = y.drop(\"Survived\", axis=1)\nY_train = y[\"Survived\"]\nX_test  = X.drop(\"PassengerId\", axis=1).copy()","61829f75":"# K Nearest Neighbor\n\nknn = KNeighborsClassifier(n_neighbors = 3) \nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test) \nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n\n","113daa06":"from sklearn.model_selection import GridSearchCV, cross_val_score\nknn = KNeighborsClassifier()","cfddea0e":"params = {\"n_neighbors\": [6,8,10,12,14,16,18,20],\n          'leaf_size':list(range(1,50,5))}\nclf = GridSearchCV(knn, param_grid=params,scoring=\"roc_auc\", verbose=1,cv=3,n_jobs=-1)\nclf.fit(X_train, Y_train)\nprint(clf.best_score_)\nprint(clf.best_estimator_)\nprint(clf.best_params_)","186a4f9e":"test_copy = X.copy()\npreds = clf.predict(X_test)\npd.DataFrame({'PassengerId': test_copy['PassengerId'],\n              'Survived': preds}).to_csv('submission.csv', index = False)","17405b8d":"- Creating Categories","6d68202c":"- Using GridSearchCV","f53a8d2c":"7. Use titanic dataset. Handle the null values and convert the categorical values into numerical \nvalues. \n- Make a classification model using k-nn classifier to predict the survival of a passenger on the ship. \n- Use \u201cgridsearchCV( )\u201d to find the best value of \u2018k\u2019","7e1368a0":"- Now Applying On This Data PreProcessing","08f807fc":"- Building M\/c Learning Method","cfcd52f0":"- Now Generate A Submission.csv file"}}