{"cell_type":{"45a56ab9":"code","6b4d68e1":"code","0df54b00":"code","b53e6db2":"code","7629876e":"code","2993c374":"code","8ecc4b78":"code","d5b351c2":"code","6bad08b5":"code","10a7616e":"code","eff0ed88":"code","f40bdb14":"code","afe544ef":"code","58e8f00d":"code","5f84dcd8":"code","b3ce7805":"code","e747cf79":"code","7538fe6f":"code","6acd2e8f":"code","6a685ef0":"code","3c5a3b94":"code","0cf849c0":"code","5126b1e7":"code","3d16b4b9":"code","1430764e":"code","bcb0ef31":"code","73848353":"code","ca134844":"code","9a9f95d5":"code","abd6e7c2":"code","ab4671e3":"code","65a5f846":"code","d4097994":"code","7c1d59ac":"code","fe1f6b37":"code","a4b9ee1b":"code","1c7dd773":"code","ee66b337":"code","27563285":"code","a1001dfd":"code","67014e4b":"markdown","8e60a26f":"markdown","1c2dd5bb":"markdown","f02b1fed":"markdown","1a51769b":"markdown","b5480c24":"markdown","7006d077":"markdown","cc854929":"markdown","3f46c28a":"markdown","6e70da1d":"markdown","ed64c867":"markdown","41b13158":"markdown","bfd4202a":"markdown","86eb9f33":"markdown","8d1e47b3":"markdown","c66b6ed0":"markdown","dfc79d16":"markdown","af2a23fb":"markdown","35868d9c":"markdown","f6c79b99":"markdown","38972f4f":"markdown","895bb215":"markdown","9a86a39e":"markdown","e622feb9":"markdown","56c419ab":"markdown","c1ef3331":"markdown","56854c81":"markdown","2a311ef7":"markdown","37b3dbc0":"markdown","43ff5f1e":"markdown","3e9a4edf":"markdown","7a708e6d":"markdown"},"source":{"45a56ab9":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.patches as patch\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import NuSVR\nfrom scipy.stats import norm\nfrom scipy import linalg\nfrom sklearn import svm\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport glob\nimport sys\nimport os","6b4d68e1":"%matplotlib inline\n%precision 4\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')\nnp.set_printoptions(suppress=True)\npd.set_option(\"display.precision\", 15)","0df54b00":"print('pandas: {}'.format(pd.__version__))\nprint('numpy: {}'.format(np.__version__))\nprint('Python: {}'.format(sys.version))","b53e6db2":"print(os.listdir(\"..\/input\/\"))","7629876e":"# import Dataset to play with it\ntest = pd.read_csv('..\/input\/test_stage_1.tsv', delimiter='\\t')","2993c374":"sample_submission = pd.read_csv('..\/input\/sample_submission_stage_1.csv')\nsample_submission.head()","8ecc4b78":"test.head()","d5b351c2":"print(test.columns)","6bad08b5":"test.describe()","10a7616e":"test.shape","eff0ed88":"test.isna().sum()","f40bdb14":"type(test)","afe544ef":"#acoustic_data means signal\ntest.hist();","58e8f00d":"pd.plotting.scatter_matrix(test,figsize=(10,10))\nplt.figure();","5f84dcd8":"sns.jointplot(x='Pronoun-offset',y='A-offset' ,data=test, kind='reg')","b3ce7805":"sns.swarmplot(x='Pronoun-offset',y='B-offset',data=test);","e747cf79":"from wordcloud import WordCloud as wc\nfrom nltk.corpus import stopwords\ndef generate_wordcloud(text): \n    wordcloud = wc(relative_scaling = 1.0,stopwords = eng_stopwords).generate(text)\n    fig,ax = plt.subplots(1,1,figsize=(10,10))\n    ax.imshow(wordcloud, interpolation='bilinear')\n    ax.axis(\"off\")\n    ax.margins(x=0, y=0)\n    plt.show()","7538fe6f":"from nltk.corpus import stopwords\neng_stopwords = set(stopwords.words(\"english\"))","6acd2e8f":"text =\" \".join(test.Text)\ngenerate_wordcloud(text)","6a685ef0":"sns.distplot(test[\"Pronoun-offset\"])","3c5a3b94":"sns.kdeplot(test[\"Pronoun-offset\"] )","0cf849c0":"test.head()","5126b1e7":"test.describe()","3d16b4b9":"test.Pronoun.tail()","1430764e":"test.shape","bcb0ef31":"test.isna().sum()","73848353":"test[\"num_words\"] = test[\"Text\"].apply(lambda x: len(str(x).split()))","ca134844":"#MJ Bahmani\nprint('maximum of num_words in test',test[\"num_words\"].max())\nprint('min of num_words in test',test[\"num_words\"].min())","9a9f95d5":"test[\"num_unique_words\"] = test[\"Text\"].apply(lambda x: len(set(str(x).split())))\nprint('maximum of num_unique_words in test',test[\"num_unique_words\"].max())\nprint('mean of num_unique_words in test',test[\"num_unique_words\"].mean())","abd6e7c2":"test[\"num_chars\"] = test[\"Text\"].apply(lambda x: len(str(x)))\nprint('maximum of num_chars in data_df',test[\"num_chars\"].max())","ab4671e3":"from nltk.corpus import stopwords\neng_stopwords = set(stopwords.words(\"english\"))","65a5f846":"test[\"num_stopwords\"] = test[\"Text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n\nprint('maximum of num_stopwords in test',test[\"num_stopwords\"].max())","d4097994":"import string\ntest[\"num_punctuations\"] =test['Text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\nprint('maximum of num_punctuations in data_df',test[\"num_punctuations\"].max())","7c1d59ac":"test[\"num_words_upper\"] = test[\"Text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\nprint('maximum of num_words_upper in test',test[\"num_words_upper\"].max())","fe1f6b37":"print(test.columns)\ntest.head(1)","a4b9ee1b":"pronoun=test[\"Pronoun\"]","1c7dd773":"np.unique(pronoun)","ee66b337":"test[\"Pronoun_binary\"] = test[\"Pronoun\"]","27563285":"test[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('He','0')\ntest[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('he','0')\ntest[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('she','1')\ntest[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('She','1')\ntest[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('His','2')\ntest[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('his','2')\ntest[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('him','3')\ntest[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('her','4')\ntest[\"Pronoun_binary\"]=test[\"Pronoun_binary\"].str.replace('Her','4')","a1001dfd":"sns.violinplot(data=test,x=\"Pronoun_binary\", y=\"num_words\")","67014e4b":" <a id=\"2\"><\/a> <br>\n ## 2- Load packages\n  <a id=\"21\"><\/a> <br>\n## 2-1 Import","8e60a26f":"you can follow me on:\n> ###### [ GitHub](https:\/\/github.com\/mjbahmani\/)\n> ###### [Kaggle](https:\/\/www.kaggle.com\/mjbahmani\/)\n\n <b>I hope you find this kernel helpful and some <font color='red'>UPVOTES<\/font> would be very much appreciated.<b\/>\n ","1c2dd5bb":" <a id=\"22\"><\/a> <br>\n##  2-2 Setup","f02b1fed":" #  <div style=\"text-align: center\">Gendered Pronoun Explainability  <\/div> \n<img src='https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/GoogleAI-GenderedPronoun\/PronounResolution.png' width=600 height=600>\n<div style=\"text-align:center\"> last update: <b>10\/02\/2019<\/b><\/div>\n\n\n\nYou can Fork code  and  Follow me on:\n\n> ###### [ GitHub](https:\/\/github.com\/mjbahmani\/10-steps-to-become-a-data-scientist)\n> ###### [Kaggle](https:\/\/www.kaggle.com\/mjbahmani\/)\n-------------------------------------------------------------------------------------------------------------\n <b>I hope you find this kernel helpful and some <font color='red'>UPVOTES<\/font> would be very much appreciated.<\/b>\n    \n -----------","1a51769b":"<a id=\"32\"><\/a> \n### 3-2 Aim\nUnlike many **Kaggle challenges**, this competition does not provide an explicit labeled training set. Files are also available on the GAP Dataset Github Repo. Note that the labels for the test set are available on this page. However, your final score and ranking will be determined in stage 2, against a withheld private test set.\n\n1. test_stage_1.tsv - the test set data for stage 1\n1. sample_submission_stage_1.csv - a file showing the correct submission format for stage 1","b5480c24":"### Number of punctuations in the text\n","7006d077":" <a id=\"1\"><\/a> <br>\n## 1- Introduction\nPronoun resolution is part of coreference resolution, the task of pairing an expression to its referring entity. This is an important task for natural language understanding, and the resolution of ambiguous pronouns is a longstanding challenge.","cc854929":"<a id=\"431\"><\/a> <br>\n## 4-3-1 Some new features\nIn this section, I will extract a few new statistical features from the text field","3f46c28a":"### Number of words in the text","6e70da1d":" <a id=\"23\"><\/a> <br>\n## 2-3 Version\n","ed64c867":"# Not Completed yet!!!","41b13158":"### Number of characters in the text","bfd4202a":"<a id=\"427\"><\/a> \n### 4-2-7 kdeplot","86eb9f33":"<a id=\"423\"><\/a> \n### 4-2-3 jointplot","8d1e47b3":"### Number of unique words in the text","c66b6ed0":"<a id=\"4\"><\/a> \n## 4- Exploratory Data Analysis(EDA)\n In this section, we'll analysis how to use graphical and numerical techniques to begin uncovering the structure of your data. \n \n* Which variables suggest interesting relationships?\n* Which observations are unusual?\n* Analysis of the features!\n\nBy the end of the section, you'll be able to answer these questions and more, while generating graphics that are both insightful and beautiful.  then We will review analytical and statistical operations:\n\n*  Data Collection\n*  Visualization\n*  Data Preprocessing\n*  Data Cleaning","dfc79d16":"<a id=\"34\"><\/a> \n## 3-4 evaluation\nSubmissions are evaluated using the multi-class logarithmic loss. Each pronoun has been labeled with whether it refers to A, B, or NEITHER. For each pronoun, you must submit a set of predicted probabilities (one for each class). The formula is :\n<img src='http:\/\/s8.picofile.com\/file\/8351608076\/1.png'>","af2a23fb":"<a id=\"3\"><\/a> \n<br>\n## 3- Problem Definition\nI think one of the important things when you start a new machine learning project is Defining your problem. that means you should understand business problem.( **Problem Formalization**)\n\nProblem Definition has four steps that have illustrated in the picture below:\n<img src=\"http:\/\/s8.picofile.com\/file\/8338227734\/ProblemDefination.png\">\n\n**Kagglers** are challenged to build pronoun resolution systems that perform equally well regardless of pronoun gender. Stage two's final evaluation will use a new dataset following the same format.\n","35868d9c":" <a id=\"top\"><\/a> <br>\n## Notebook  Content\n1. [Introduction](#1)\n1. [Load packages](#2)\n    1. [import](21)\n    1. [Setup](22)\n    1. [Version](23)\n1. [Problem Definition](#3)\n    1. [Problem Feature](#31)\n    1. [Aim](#32)\n    1. [Variables](#33)\n    1. [Evaluation](#34)\n1. [Exploratory Data Analysis(EDA)](#4)\n    1. [Data Collection](#41)\n    1. [Visualization](#42)\n    1. [Data Preprocessing](#43)\n        1. [Some new features](#431)\n1. [Conclusion](#5)","f6c79b99":"<a id=\"426\"><\/a> \n### 4-2-6 Distplot","38972f4f":"<a id=\"424\"><\/a> \n### 4-2-4 Scatter_matrix","895bb215":"<a id=\"33\"><\/a> \n### 3-3 Variables\n\n1. ID - Unique identifier for an example (Matches to Id in output file format)\n1. Text - Text containing the ambiguous pronoun and two candidate names (about a paragraph in length)\n1. Pronoun - The target pronoun (text)\n1. Pronoun-offset The character offset of Pronoun in Text\n1. A - The first name candidate (text)\n1. A-offset - The character offset of name A in Text\n1. B - The second name candidate\n1. B-offset - The character offset of name B in Text\n1. URL - The URL of the source Wikipedia page for the example\n","9a86a39e":"Go to first step: [Course Home Page](https:\/\/www.kaggle.com\/mjbahmani\/10-steps-to-become-a-data-scientist)\n\nGo to next step : [Titanic](https:\/\/www.kaggle.com\/mjbahmani\/a-comprehensive-ml-workflow-with-python)\n","e622feb9":" <a id=\"43\"><\/a> <br>\n## 4-3 Data Preprocessing","56c419ab":"### Number of title case words in the text","c1ef3331":"### Number of stopwords in the text","56854c81":" <a id=\"42\"><\/a> <br>\n## 4-2 Visualization","2a311ef7":"<a id=\"31\"><\/a> \n### 3-1 Problem Feature\nIn this competition, you must identify the target of a pronoun within a text passage. The source text is taken from Wikipedia articles. You are provided with the pronoun and two candidate names to which the pronoun could refer. You must create an algorithm capable of deciding whether the pronoun refers to name A, name B, or neither.\n","37b3dbc0":"<a id=\"421\"><\/a> \n### 4-2-1 hist","43ff5f1e":" <a id=\"41\"><\/a> <br>\n## 4-1 Data Collection","3e9a4edf":"<a id=\"422\"><\/a> \n### 4-2-2 scatter_matrix","7a708e6d":"<a id=\"425\"><\/a> \n### 4-2-5 WordCloud"}}