{"cell_type":{"eddaa0b3":"code","932b86e7":"code","bb3b68fa":"code","52c8ab7d":"code","0b03a1dd":"code","eae9b8f5":"code","04513715":"code","cb221e8e":"code","2a7bcdf8":"code","eb595dd4":"code","73fb0b1c":"code","85b52db8":"code","2aff2a68":"code","d216cd0a":"code","e43217ff":"code","76dd0b84":"code","20bb5766":"code","459bfaac":"code","126ea8b9":"code","063a7a57":"code","598a21af":"code","997435c9":"markdown","dafbd2fc":"markdown","baeb695a":"markdown","fa650553":"markdown","2cc7a1e7":"markdown","82901897":"markdown","c44996c3":"markdown","5d110dd4":"markdown","ac6e4cf4":"markdown","97d4e4b0":"markdown","0d91775a":"markdown","e18f02a9":"markdown","4be7b633":"markdown","a9ae358f":"markdown"},"source":{"eddaa0b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","932b86e7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport glob\n%matplotlib inline \nimport os","bb3b68fa":"from tqdm import tqdm\nimport tensorflow.keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D,Activation,BatchNormalization,LeakyReLU,GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam,SGD\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import CSVLogger,ModelCheckpoint,ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom PIL import Image","52c8ab7d":"import pandas as pd\nimport cv2\nimport os\n\ndef load_imgs(path):\n    imgs = {}\n    for f in os.listdir(path):\n        fname = os.path.join(path, f)\n        imgs[f] = cv2.imread(fname)\n    return imgs\n\nimg_train = load_imgs('..\/input\/train\/train\/')\nimg_test = load_imgs('..\/input\/test\/test\/')","0b03a1dd":"train_csv = pd.read_csv('..\/input\/train.csv')\nimport numpy as np\n\nX_train = []\nY_train = []\n\nfor _, row in train_csv.iterrows():\n    X_train.append(img_train[row['id']]\/255)\n    Y_train.append(int(row['has_cactus']))\n\nX_train = np.array(X_train)\nY_train = np.array(Y_train)\n\nX_test = np.array([img_test[f] for f in img_test])\n\nprint('Training data shape:', X_train.shape, '=>', Y_train.shape)","eae9b8f5":"%matplotlib inline\nimport numpy as np\nfrom matplotlib import pyplot as plt\nplt.rcParams[\"axes.grid\"] = False","04513715":"fig, axes = plt.subplots(1, 5, figsize=(15, 4))\naxes[0].imshow(X_train[0])\naxes[0].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[1].imshow(X_train[1])\naxes[1].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[2].imshow(X_train[2])\naxes[2].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[3].imshow(X_train[1000])\naxes[3].set_title(\"Has cactus:\" + str(Y_train[1000]))\naxes[4].imshow(X_train[1050])\naxes[4].set_title(\"Has cactus:\" + str(Y_train[1050]))","cb221e8e":"from scipy.ndimage import gaussian_filter\n\ndef img_sharpen(img):\n    blurred_f = gaussian_filter(img, 2)\n\n    filter_blurred_f = gaussian_filter(blurred_f, 2)\n\n    alpha = 15\n    sharpened = blurred_f + alpha * (blurred_f - filter_blurred_f)\n    return sharpened","2a7bcdf8":"#Sharpen the low quality cactus images\nsharp_img_xtrain = []\n\nfor im in X_train:\n    sharp_img_xtrain.append(img_sharpen(im))","eb595dd4":"fig, axes = plt.subplots(1, 5, figsize=(15, 4))\naxes[0].imshow(sharp_img_xtrain[0])\naxes[0].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[1].imshow(sharp_img_xtrain[1])\naxes[1].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[2].imshow(sharp_img_xtrain[2])\naxes[2].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[3].imshow(sharp_img_xtrain[1000])\naxes[3].set_title(\"Has cactus:\" + str(Y_train[1000]))\naxes[4].imshow(sharp_img_xtrain[1050])\naxes[4].set_title(\"Has cactus:\" + str(Y_train[1050]))","73fb0b1c":"from sklearn.model_selection import train_test_split\nfrom numpy import array\n\nsharp_xtrain = array(sharp_img_xtrain)\nx_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2)","85b52db8":"import tensorflow as tf\n\nclass noisyand(tf.keras.layers.Layer):\n    def __init__(self, num_classes, a = 20, **kwargs):\n        self.num_classes = num_classes\n        self.a = max(1,a)\n        super(noisyand,self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.b = self.add_weight(name = \"b\",shape = (1,input_shape[-1].value), initializer = \"uniform\",trainable = True)\n        super(noisyand,self).build(input_shape)\n\n    def call(self,x):\n        mean = tf.reduce_mean(x, axis = [1,2])\n        return (tf.nn.sigmoid(self.a * (mean - self.b)) - tf.nn.sigmoid(-self.a * self.b)) \/ (tf.nn.sigmoid(self.a * (1 - self.b)) - tf.nn.sigmoid(-self.a * self.b))\n    \n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[3]","2aff2a68":"def define_model(input_shape= (32,32,3), num_classes=1):\n    model = Sequential()\n    model.add(Conv2D(64, kernel_size=(3, 3),\n                     activation='relu',\n                     padding = 'same',\n                     input_shape=input_shape))\n    \n    model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D())\n    \n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D())\n\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(Conv2D(128, (1, 1), activation='relu'))\n    \n    model.add(noisyand(num_classes+1))\n    model.add(Dense(num_classes, activation='sigmoid'))\n    \n    return model","d216cd0a":"model = define_model()\nmodel.summary()","e43217ff":"model.compile(loss=tensorflow.keras.losses.binary_crossentropy,\n                  optimizer=tensorflow.keras.optimizers.RMSprop(),\n                  metrics=['accuracy'])","76dd0b84":"epoch=15\nhistory = model.fit(x_train, y_train,\n         batch_size=32,\n         epochs=epoch,\n         verbose=1,\n         validation_data=(x_test, y_test))","20bb5766":"acc=history.history['acc']\nepochs_=range(0,epoch)\nplt.plot(epochs_,acc,label='training accuracy')\n\nacc_val=history.history['val_acc']\nplt.scatter(epochs_,acc_val,label=\"validation accuracy\")\nplt.ylim([0.85,1.0])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Accuracy Plot of Model')\n\nplt.legend()","459bfaac":"acc=history.history['loss']\nepochs_=range(0,epoch)\nplt.plot(epochs_,acc,label='training loss')\n\nacc_val=history.history['val_loss']\nplt.scatter(epochs_,acc_val,label=\"validation loss\")\nplt.ylim([0,0.5])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss Plot of Model')\n\nplt.legend()","126ea8b9":"submission_set=pd.read_csv('..\/input\/sample_submission.csv')\nsubmission_set.head()","063a7a57":"predictions=np.empty((submission_set.shape[0],))\n    \nfor n in tqdm(range(submission_set.shape[0])):\n    data=np.array(Image.open('..\/input\/test\/test\/'+submission_set.id[n]))\n    data=data.astype(np.float32)\/255\n    #Sharpen the low quality cactus images\n    data=img_sharpen(data)\n    predictions[n]=model.predict(data.reshape((1,32,32,3)))[0]\n\n    \nsubmission_set['has_cactus']=predictions\nsubmission_set.to_csv('sample_submission.csv',index=False)\n\nsubmission_set.head()","598a21af":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\nclf=model\ny_pred_proba = clf.predict_proba(x_test)\ny_pred = clf.predict_classes(x_test)\n\nfpr,tpr,_= roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange',\n         lw=1.5, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--')\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","997435c9":"Plotting the accuracy scores of the model","dafbd2fc":"## Data Prep","baeb695a":"Defining a class for pooling a layer using Mulitple Learning Instance. \nInspire by article on classifying images using deep multiple instance learning: https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC4908336\/pdf\/btw252.pdf","fa650553":"Reading from the train folder, we normalized the images","2cc7a1e7":"## Train\/Test Split for CNN","82901897":"Predicting images has cactus for submission","c44996c3":"Defining the Deep CNN model","5d110dd4":"Plotting the same images as above except with the sharpening filter using Gaussian filtering","ac6e4cf4":"Plotting the loss scores of the model","97d4e4b0":"## ROC Curve","0d91775a":"## Image preprocessing using Guassian filtering\nFor sharpening the edges of cactus in the pixelated images, we applied Gaussian filtering","e18f02a9":"# Cactus Classification","4be7b633":"## Submission Part","a9ae358f":"Plotting the normalized images- showing three images with cactus and two without cactus"}}