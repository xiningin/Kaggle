{"cell_type":{"056d6bce":"code","18d69fee":"code","f240d467":"code","c0b4661d":"code","ff236228":"code","8818aeb4":"code","5f267612":"code","ee6433d2":"code","4be8dcd9":"code","682fbd56":"code","460ac0d4":"code","3196cb71":"code","da7010f8":"code","6444e4bb":"code","a9943ec1":"code","e221181e":"code","9b99f3c7":"markdown","c705aff0":"markdown","a915901d":"markdown","f184023a":"markdown","49aedf7d":"markdown","568f554b":"markdown","423c4e21":"markdown","8d707317":"markdown","aa4c4aed":"markdown","0cfaab51":"markdown","a391c357":"markdown","8ef84630":"markdown","e37b7550":"markdown","19db5a83":"markdown","8c4edb6e":"markdown","75e5736e":"markdown","3be7f708":"markdown"},"source":{"056d6bce":"from glob import glob\nimport os\nimport pandas as pd\n\n#checnking the input files\nprint(os.listdir(\"..\/input\/siim-acr-pneumothorax-segmentation-data\"))\n\n#reading all dcm files into train and text\ntrain = sorted(glob(\"..\/input\/siim-acr-pneumothorax-segmentation-data\/pneumothorax\/dicom-images-train\/*\/*\/*.dcm\"))\ntest = sorted(glob(\"..\/input\/siim-acr-pneumothorax-segmentation-data\/pneumothorax\/dicom-images-test\/*\/*\/*.dcm\"))\nprint(\"train files: \", len(train))\nprint(\"test files: \", len(test))\n\npd.reset_option('max_colwidth')\n\n#reading the csv\nprint(\"the csv with the labels: -1 means no Pneumothorax, othervise there is an encoding for the place of Pneumothorax\")\nmasks = pd.read_csv(\"..\/input\/siim-acr-pneumothorax-segmentation-data\/pneumothorax\/train-rle.csv\", delimiter=\",\")\nmasks.head()","18d69fee":"import pydicom\nimport matplotlib.pyplot as plt\n\n#displaying the image\nimg = pydicom.read_file(train[0]).pixel_array\nplt.imshow(img, cmap='bone')\nplt.grid(False)\n\n#displaying metadata\ndata = pydicom.dcmread(train[0])\nprint(data)","f240d467":"#dataframe to ease the access\npatients = []\nmissing = 0\n\npd.reset_option('max_colwidth')\n\nfor t in train:\n    data = pydicom.dcmread(t)\n    patient = {}\n    patient[\"UID\"] = data.SOPInstanceUID\n    try:\n        encoded_pixels = masks[masks[\"ImageId\"] == patient[\"UID\"]].values[0][1]\n        patient[\"EncodedPixels\"] = encoded_pixels\n    except:\n        missing = missing + 1\n    patient[\"Age\"] = data.PatientAge\n    patient[\"Sex\"] = data.PatientSex\n    patient[\"Modality\"] = data.Modality\n    patient[\"BodyPart\"] = data.BodyPartExamined\n    patient[\"ViewPosition\"] = data.ViewPosition\n    patient[\"path\"] = \"..\/input\/siim-acr-pneumothorax-segmentation-data\/pneumothorax\/dicom-images-train\/\" + data.StudyInstanceUID + \"\/\" + data.SeriesInstanceUID + \"\/\" + data.SOPInstanceUID + \".dcm\"\n    patients.append(patient)\n\nprint(\"missing labels: \", missing)\n#pd.set_option('display.max_colwidth', -1)\ndf_patients = pd.DataFrame(patients, columns=[\"UID\", \"EncodedPixels\", \"Age\", \"Sex\", \"Modality\", \"BodyPart\", \"ViewPosition\", \"path\"])\nprint(\"images with labels: \", df_patients.shape[0])\ndf_patients.head()","c0b4661d":"import matplotlib as mpl\nimport numpy as np\n\n#gender\nmen = df_patients[df_patients[\"Sex\"] == \"M\"].shape[0]\nwomen = df_patients.shape[0] - men\nprint(men, women)\n\n\n#illness\nhealthy = df_patients[df_patients[\"EncodedPixels\"] == \" -1\"].shape[0]\nill = df_patients.shape[0] - healthy\nprint(healthy, ill)\n\n#gender + illness\nmen_h = df_patients[(df_patients[\"Sex\"] == \"M\") & (df_patients[\"EncodedPixels\"] == \" -1\")].shape[0]\nmen_ill = men - men_h\nwomen_h = df_patients[(df_patients[\"Sex\"] == \"F\") & (df_patients[\"EncodedPixels\"] == \" -1\")].shape[0]\nwomen_ill = women - women_h\nprint(men_h, men_ill, women_h, women_ill)\n\nperc = [str(round(men_ill\/107.12, 1)) + \"% \\n ill\", \"healthy \\n\" + str(round(men_h\/107.12, 1)) + \"%\", \"healthy \\n\" + str(round(women_h\/107.12, 1)) + \"%\",str(round(women_ill\/107.12, 1)) + \"% \\n ill\"]\n\nfig, ax = plt.subplots(1, 3, figsize=(15, 5))\n\nfig.suptitle(\"4.1 Gender and Pneumothorax distributions\", fontsize=24, y=1.1)\n\nmpl.rcParams['font.size'] = 12.0\n\n#circle for donut chart\ncircle0 = plt.Circle( (0,0), 0.6, color = 'white')\ncircle1 = plt.Circle( (0,0), 0.4, color = 'white')\ncircle2 = plt.Circle( (0,0), 0.6, color = 'white')\n\n#men women\nax[0].pie([men, women], labels=[\"men\", \"women\"], colors=[\"#42A5F5\", \"#E57373\"], autopct='%1.1f%%', pctdistance=0.8, startangle=90)\nax[0].add_patch(circle0)\nax[0].axis('equal')\n\n#gender healthy\nmypie, _ = ax[2].pie([men, women], radius=1.3, labels=[\"men\", \"women\"], colors=[\"#42A5F5\", \"#E57373\"], startangle=90)\nplt.setp( mypie, width=0.3, edgecolor='white')\n\nmypie2, _ = ax[2].pie([ men_ill, men_h, women_h, women_ill], radius = 1.3 - 0.3, labels=perc, labeldistance=0.61,\n                      colors = [\"#FFB74D\", \"#9CCC65\", \"#9CCC65\", \"#FFB74D\"], startangle=90)\nplt.setp( mypie2, width=0.4, edgecolor='white')\nplt.margins(0,0)\n\n#healthy ill\nax[1].pie([healthy, ill], labels=[\"healthy\", \"ill\"], colors=[\"#9CCC65\", \"#FFB74D\"], autopct='%1.1f%%', pctdistance=0.8, startangle=135)\nax[1].add_patch(circle2)\nax[1].axis('equal')  \n\nplt.tight_layout()\nplt.show()","ff236228":"import numpy as np\n#group into bins the same aged men and women with histogram --> all of them and ill of them\n\n#convert he Age column to int\ndf_patients[\"Age\"] = pd.to_numeric(df_patients[\"Age\"])\n\nsorted_ages = np.sort(df_patients[\"Age\"].values)\nprint(sorted_ages)","8818aeb4":"import seaborn as sns\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(17, 5))\nplt.hist(sorted_ages[:-2], bins=[i for i in range(100)])\nplt.title(\"4.2 All patients age histogram\", fontsize=18, pad=10)\nplt.xlabel(\"age\", labelpad=10)\nplt.xticks([i*10 for i in range(11)])\nplt.ylabel(\"count\", labelpad=10)\nplt.show()","5f267612":"#calculating all and ill men and women histograms\nbins = [i for i in range(100)]\nplt.style.use('seaborn-whitegrid')\n\nall_men = np.histogram(df_patients[df_patients[\"Sex\"] == \"M\"][\"Age\"].values, bins=bins)[0]\nall_women = np.histogram(df_patients[df_patients[\"Sex\"] == \"F\"][\"Age\"].values, bins=bins)[0]\n\nill_men = np.histogram(df_patients[(df_patients[\"Sex\"] == \"M\") & (df_patients[\"EncodedPixels\"] != ' -1')][\"Age\"].values, bins=bins)[0]\nill_women = np.histogram(df_patients[(df_patients[\"Sex\"] == \"F\") & (df_patients[\"EncodedPixels\"] != ' -1')][\"Age\"].values, bins=bins)[0]\n\nfig, axes = plt.subplots(ncols=2, sharey=True, figsize=(17, 16))\n\nfig.suptitle(\"4.3 The presence of Pneumothorax at particular ages and genders\", fontsize=22, y=0.96)\n\naxes[0].margins(x=0.1, y=0.01)\nm1 = axes[0].barh(bins[:-1], all_men, color='#90CAF9')\nm2 = axes[0].barh(bins[:-1], ill_men, color='#0D47A1')\naxes[0].set_title('Men', fontsize=18, pad=15)\naxes[0].invert_xaxis()\naxes[0].set(yticks=[i*5 for i in range(20)])\naxes[0].tick_params(axis=\"y\", labelsize=14)\naxes[0].yaxis.tick_right()\naxes[0].xaxis.tick_top()\naxes[0].legend((m1[0], m2[0]), ('healthy', 'with Pneumothorax'), loc=2, prop={'size': 16})\n\nlocs = axes[0].get_xticks()\n\naxes[1].margins(y=0.01)\nw1 = axes[1].barh(bins[:-1], all_women, color='#EF9A9A')\nw2 = axes[1].barh(bins[:-1], ill_women, color='#B71C1C')\naxes[1].set_title('Women', fontsize=18, pad=15)\naxes[1].xaxis.tick_top()\naxes[1].set_xticks(locs)\naxes[1].legend((w1[0], w2[0]), ('healthy', 'with Pneumothorax'), prop={'size': 17})\n\n#for i, v in enumerate(depos[\"ItemViewCount\"].values):\n   #print(i, v)\n    #axes[1].text(int(v) + 3, int(i)-0.25, str(v))\nplt.show()","ee6433d2":"bodypart = df_patients[\"BodyPart\"].values\nprint(\"Body parts:\", list(set(bodypart)))\n\nmodality = df_patients[\"Modality\"].values\nprint(\"Modality:\", list(set(modality)))\n\nview = list(df_patients[\"ViewPosition\"].values)\nprint(\"View Positions: \", list(set(view)))\n\npa = view.count(\"PA\")\nap = view.count(\"AP\")\nprint(pa, ap)","4be8dcd9":"\nbasic_palette = sns.color_palette()\nplt.style.use('seaborn-whitegrid')\nplt.pie([pa, ap], labels = [\"PA\", \"AP\"], colors=[basic_palette[-2], basic_palette[4]], autopct='%1.1f%%', startangle=70)\nplt.title(\"Occurrences of View positions\", fontsize=16)","682fbd56":"#mask functions from sample dataset\nimport numpy as np\n\ndef mask2rle(img, width, height):\n    rle = []\n    lastColor = 0;\n    currentPixel = 0;\n    runStart = -1;\n    runLength = 0;\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 255:\n                    runStart = currentPixel;\n                    runLength = 1;\n                else:\n                    rle.append(str(runStart));\n                    rle.append(str(runLength));\n                    runStart = -1;\n                    runLength = 0;\n                    currentPixel = 0;\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor;\n            currentPixel+=1;\n\n    return \" \".join(rle)\n\ndef rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 255\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","460ac0d4":"df_pneumo = df_patients[df_patients[\"EncodedPixels\"] != ' -1']\n\n#print(df_pneumo.values[3][2], df_pneumo.values[3][3])\n\nmask = rle2mask(df_pneumo.values[3][1], 1024, 1024)\nmask = np.rot90(mask, 3) #rotating three times 90 to the right place\nmask = np.flip(mask, axis=1)\nimg = pydicom.read_file(df_pneumo.values[3][-1]).pixel_array\n\nfig = plt.figure(figsize=(15, 10))\na = fig.add_subplot(1, 3, 1)\nplt.imshow(img, cmap='bone') #original x-ray\na.set_title(\"Original x-ray image\")\nplt.grid(False)\nplt.axis(\"off\")\n\na = fig.add_subplot(1, 3, 2)\nimgplot = plt.imshow(mask, cmap='binary')\n\na.set_title(\"The mask\")\nplt.grid(False)\nplt.xticks([])\nplt.yticks([])\n\na = fig.add_subplot(1, 3, 3)\nplt.imshow(img, cmap='bone')\nplt.imshow(mask, cmap='binary', alpha=0.3)\na.set_title(\"Mask on the x-ray: air in the pleura\")\n\nplt.axis(\"off\")\n\nplt.grid(False)\n\nmask = rle2mask(df_pneumo.values[6][1], 1024, 1024)\nmask = np.rot90(mask, 3) #rotating three times 90 to the right place\nmask = np.flip(mask, axis=1)\nimg = pydicom.read_file(df_pneumo.values[6][-1]).pixel_array\n\nfig = plt.figure(figsize=(15, 10))\na = fig.add_subplot(1, 3, 1)\nplt.imshow(img, cmap='bone') #original x-ray\na.set_title(\"Original x-ray image\")\nplt.grid(False)\nplt.axis(\"off\")\n\na = fig.add_subplot(1, 3, 2)\nimgplot = plt.imshow(mask, cmap='binary')\n\na.set_title(\"The mask\")\nplt.grid(False)\nplt.xticks([])\nplt.yticks([])\n\na = fig.add_subplot(1, 3, 3)\nplt.imshow(img, cmap='bone')\nplt.imshow(mask, cmap='binary', alpha=0.3)\na.set_title(\"Mask on the x-ray: air in the pleura\")\n\nplt.axis(\"off\")\n\nplt.grid(False)","3196cb71":"area = []\npos = []\npa_area = []\nap_area = []\n\nc = 0\n\nfor p in df_pneumo.values:\n    try:\n        mask = rle2mask(p[1], 1024, 1024)\n        pixels = np.count_nonzero(mask)\n        area.append(pixels)\n        pos.append(p[6])\n        if p[6] == \"AP\":\n            ap_area.append(pixels)\n        else:\n            pa_area.append(pixels)\n    except:\n        c = c + 1\n\nprint(\"missing labels\", c)\nprint(\"all area\", np.sort(np.array(area)))\n#print(\"ap area\", np.sort(np.array(ap_area)))\nprint(\"pa area\", np.sort(np.array(pa_area)))","da7010f8":"plt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(17, 5))\nplt.hist(area, bins=[i*500 for i in range(340)])\nplt.title(\"The affected area by Pneumothorax\", fontsize=18, pad=10)\nplt.xlabel(\"area [pixels]\", labelpad=10)\n#plt.xticks([i*10 for i in range(1000)])\nplt.ylabel(\"count of patient in groups\", labelpad=10)\nplt.show()","6444e4bb":"fig = plt.figure(figsize=(17, 5))\nbasic_palette = sns.color_palette()\n\nax1 = plt.subplot2grid((1, 3), (0, 0), colspan=2)\n\nsns.boxplot(x=area, y=pos, palette={\"AP\": basic_palette[4], \"PA\": basic_palette[-2]})#, height=[0.6, 0.4])\nax1.set_xlabel(\"area [pixels]\", fontsize=14, labelpad=10)\nax1.set_ylabel(\"view position\", fontsize=14, labelpad=10)\nax1.set_title(\"6.1 Affected area vs view position\", fontsize=18, pad=10)\n\nax2 = plt.subplot2grid((1, 3), (0, 2))\n\nax2.pie([pa, ap], labels = [\"PA\", \"AP\"], colors=[basic_palette[-2], basic_palette[4]], autopct='%1.1f%%', startangle=70)\nax2.set_title(\"Occurrences of View positions\", fontsize=18)\n","a9943ec1":"c = 0\nap_sum = np.array([[0 for i in range(1024)] for j in range(1024)])\npa_sum = np.array([[0 for i in range(1024)] for j in range(1024)])\n\nap = 0\npa = 0\n\nfor p in df_pneumo.values:\n    try :\n        mask = rle2mask(p[1], 1024, 1024)\n        mask = np.rot90(mask, 3) #rotating three times 90 to the right place\n        mask = np.flip(mask, axis=1)\n        if p[6] == 'AP':\n            ap_sum = ap_sum + mask\n            ap = ap + 1\n        else:\n            pa_sum = pa_sum + mask\n            pa = pa + 1\n    except:\n        c = c + 1","e221181e":"fig = plt.figure(figsize=(17, 5))\nbasic_palette = sns.color_palette()\n\nax1 = plt.subplot2grid((1, 3), (0, 0))\nax1.imshow(pa_sum, cmap='magma_r')\nax1.set_title(\"All PA positioned masks\", fontsize=18, pad=15)\n\n#colorbar\nmaxval = np.max(pa_sum)\ncmap = plt.get_cmap('magma_r', maxval)\n\nnorm = mpl.colors.Normalize()\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n\nticks=[1\/(maxval+1)\/2, 0.5, 1-1\/(maxval+1)\/2]\n\ncb_1 = plt.colorbar(sm,ticks=[0, 1], fraction=0.046, ax=ax1)#ticks and boundaries\ncb_1.ax.set_yticklabels([\"no Pneu\", str(int(maxval))]) #label of colormap\ncb_1.ax.yaxis.set_label_position('left')\n\nplt.grid(False)\nplt.xticks([])\nplt.yticks([])\n\nax2 = plt.subplot2grid((1, 3), (0, 1))\nax2.pie([pa, ap], labels = [\"PA\", \"AP\"], colors=[basic_palette[-2], basic_palette[4]], autopct='%1.1f%%', startangle=70)\nax2.set_title(\"Occurrences of View positions\", fontsize=18)\n\nax3 = plt.subplot2grid((1, 3), (0, 2))\nax3.imshow(ap_sum, cmap='magma_r')\nax3.set_title(\"All AP positioned masks\", fontsize=18, pad=15)\n\nmaxval = np.max(ap_sum)\ncmap2 = plt.get_cmap('magma_r', maxval)\n\nnorm = mpl.colors.Normalize()\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n\ncb_2 = plt.colorbar(sm,ticks=[0, 1], fraction=0.046, ax=ax3)#ticks and boundaries\ncb_2.ax.set_yticklabels([\"no Pneu\", str(int(maxval))]) #label of colormap\ncb_2.ax.yaxis.set_label_position('left')\n\nplt.grid(False)\nplt.xticks([])\nplt.yticks([])","9b99f3c7":"<a class=\"anchor\" id=\"section6a\"><\/a>\n### 6.1 The affected area and the view position\n\nAs mentioned before, let's see if the \"AP\" positioned x-ray images has a more serious Pneumothorax? On the plots below can be seen that this supposition tend to be true. The x-ray images with the biggest masks are made in AP position, howewer, this view position occurs fewer times than PA.","c705aff0":"As we expected, all the BodyPart fields are chests, the modality is CR, which means Computed Radiography (I think). \n\n<a class=\"anchor\" id=\"section4d\"><\/a>\n### 4.4 The importance of view positions on an x-ray image \n\nThe view position can be AP or PA. These refer to the way of x-ray in the body, [based on this source](https:\/\/www.quora.com\/What-is-the-difference-between-an-AP-and-a-PA-view-of-an-X-ray)\n* PA: passes from posterior of the body to anterior --> getting better anterior shadings\n* AP: passes from anterior of the body to posterior --> getting better posterior shaginds\n\n![image.png](attachment:image.png)\n\nThey say usually AP view is used for x-rays, but in the case of the chest x-rays are rather taken from the PA view. If the health level of the patient does not allow to do PA, AP can also help. It would be interesting to check the Pneumothorax severity level in relation to view position too. But first, we have to decode the run-length-encoding (RLE) present int the train csv file. ","a915901d":"There are a bit more of men, so in proportion with that, there are a bit more men with Pneumothorax than women. We also know the age of patients, so let's see the age distribution. To create a histogram, we have to know the maximum ages, for example by sorting.","f184023a":"It seems that some images are missing based on the csv file. Anyway, now we have a dataframe which ease to visualize some aspects of the train metadata. First, let's see the gender and diagnosis distributions.\n\n<a class=\"anchor\" id=\"section4a\"><\/a>","49aedf7d":"Now that we can decode the rle, we can analyze some aspects of the masks separately and together with the metadata. Let's start with the area of the air in the chest, which could measure the severity of the disease.\n\n<a class=\"anchor\" id=\"section6\"><\/a>\n## 6. Analyzing the masks\n\nAs the masks are created from pixels, we can eaisly count them to calculate the area. As we can see the majority of ill patients suffer from a smaller Pneumothorax, and some patients have a severely collapsed lung. Note: we didn't take in consideration the overlapping masks, just the masked pixels, and at some images the scale may differ too.","568f554b":"* [1. Introduction](#section1)  \n* [2. What is Pneumothorax and how can data science help?](#section2)  \n* [3. The dataset and how to decode](#section3)  \n* [4. Exploring the train metadata](#section4)  \n    * [4.1. Gender and Pneumothorax distribution](#section4a)  \n    * [4.2. All patients age distribution](#section4b)\n    * [4.3. The presence of Pneumothorax at particular ages and genders](#section4c)\n    * [4.4. The importance of view positions on an x-ray image](#section4d)\n* [5. The run-length-encoding](#section5)  \n    * [5.1 Mask functions](#section5a)\n* [6. Analyzing the masks](#section6)\n    * [6.1 The affected area and the view position](#section6a)\n    * [6.2 The location of Pneumothorax](#section6b)\n* [7. Conclusion](#section7)\n\n<a class=\"anchor\" id=\"section1\"><\/a> \n## 1. Introduction \n\nThe idea of using data science to help in identifying diseases is respectable, a really noble goal. This contest is about identifying Pneumothorax disease in chest x-rays. As a junior data scientist, I will present here in detail my curiosity-driven explorations about the dataset and the project, hoping it will be helpful for other juniors.\n\nFirst, we need some domain knowledge.\n\n<a class=\"anchor\" id=\"section2\"><\/a>\n## 2. What is Pneumothorax and how can data science help? \n\nPneumothorax refers to the presence of air in the pleural space, between the lung and the chest wall. This causes collapsed lung, because thus the dilation of the chest wall would not involve the dilation of the lung. Shortness of breath, pain in the chest can be symptoms, the level of severity can vary. It sounds scary, but suddenly I am grateful for every breath I take. You can find some references [here](https:\/\/www.mountnittany.org\/articles\/healthsheets\/5473), \n[here](https:\/\/www.mayoclinic.org\/diseases-conditions\/pneumothorax\/symptoms-causes\/syc-20350367) \n[or here](https:\/\/radiopaedia.org\/articles\/pneumothorax?lang=us) They say, this disease can be identified from chest x-ray images, and here comes in the data science.\n\n<img src=\"https:\/\/www.fairview.org\/hlimg\/krames\/344230.jpg\" width=\"300px\">\n\nUsing a dataset with x-ray images and their diagnosis with the exact place of the air in pleura, a model could be trained to recognize Pneumothorax. Additional information about the patients could also be useful when analyzing an x-ray image.\n\n<a class=\"anchor\" id=\"section3\"><\/a>\n## 3. The dataset and how to decode \n\nOriginally the creators of the contest had the idea of downloading the data from Google Cloud Healthcare API, to learn a bit about accessing real-world data. Here are the [instructions](https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/overview\/siim-cloud-healthcare-api-tutorial). Thanks for [Jesper](https:\/\/www.kaggle.com\/jesperdramsch), the data is easily accessible [here](https:\/\/www.kaggle.com\/jesperdramsch\/siim-acr-pneumothorax-segmentation-data)\n\nThe main folder contains two subfolders: train and test, and a csv file with the train labels.\nThe train and test folders contain DICOM (Digital Imaging and Communications in Medicine) formatted files, for some reason every single image is embedded in two more folders. We are happy for our data, but new challenges appear: the CSV content seems complicated and the dcm file can not be opened easily.\n![image.png](attachment:image.png)\n\nNow, let's see some code. To access the dataset to the kaggle notebook, I found useful [See--](https:\/\/www.kaggle.com\/seesee)'s [kernel](https:\/\/www.kaggle.com\/seesee\/full-dataset). I have uploaded the full dataset to Workspace, and I could read the dcm files.","423c4e21":"Here are two examples of the encoded pixels. The rle2mask function returns a filter which has the same size as the original image. Some rotation and mirroring were needed, to place the mask correctly.","8d707317":"<a class=\"anchor\" id=\"section6b\"><\/a>\n### 6.2 The location of Pneumothorax\n\nTo get a general insight into the location of Pneumothorax, we can create some \"lung heatmaps\" for  AP and PA views. Of course, every patient is different, thus the size of the lungs and their place on the x-ray image can be different. However, a heatmap may give an overview.","aa4c4aed":"<a class=\"anchor\" id=\"section4\"><\/a>\n## 4. Exploring the train metadata ","0cfaab51":"# Exploratory Data Analysis of Pneumothorax dataset","a391c357":"To find out more about the occurence of Pneumothorax at different ages and genders, we can create a plot like the following:\n\n<a class=\"anchor\" id=\"section4c\"><\/a>","8ef84630":"Oops, it's seems there are errors in the dataset, 413 is far to old, and the 148 is also unbeliveable. For the histogram, I will skip these two values.\n\n<a class=\"anchor\" id=\"section4b\"><\/a>","e37b7550":"It is striking that many 16-year-old boys suffer from Pneumothorax, even more than the 64 years old men. The result seems unexpected, but if we read more about the disease, it turns out that the [young, tall and thin men](https:\/\/edmonton.ctvnews.ca\/tall-thin-young-man-you-could-suffer-from-a-collapsed-lung-1.1234203) are more vulnerable. Young women in their twenties don't seem to be an exception. However this information is based only on a small amount of data.\n\nNext let's check the other extracted attributes: Modality, BodyPart, ViewPosition.","19db5a83":"<a class=\"anchor\" id=\"section7\"><\/a>\n## 7. Conclusion\n\nSo these were some brief explorations to get a bit more insight into the dataset and its metadata. We have seen the gender and age distributions of healthy and ill people, we discovered more about the x-ray image view positions and about the affected areas. Hopefully, it was useful to understand a bit the nature of the disease and of the affected people.","8c4edb6e":"<a class=\"anchor\" id=\"section5\"><\/a>\n## 5. The run-length-encoding \n\nSo as we could see, the train csv contains the image id and the rle-encodings of the place of Pneumothorax. But what does this mean? Run-length-encoding (RLE) is a simple lossless compression method, it replaces data sequences with identical values (run) with the respective value stored once and the length of the run. It can be useful when the data contains relatively long sequences. Here is a very simple example. \n\n![image.png](attachment:image.png)\n\nWe have to work with **relative** RLE, which means, that the pixel locations are measured from the previous run. For example, '1 3 10 5' implies pixels 1,2,3 are to be included in the mask, as well as 14,15,16,17,18, according to [Robin Schwob](https:\/\/www.kaggle.com\/schwobr) in this [discussion](https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/discussion\/98397#latest-567740).\n\n<a class=\"anchor\" id=\"section5a\"><\/a>\n### 5.1 Mask functions\nFortunately there are decoding and encoding functions inculded to the sample data: mask_functions.py. As I would like to analyze the train data rle labels, I will use only the rle2mask function. Let's check how it is working.","75e5736e":"It seems that in both cases the top left corner of the lung is the most common location. In the PA cases, the x-ray images create a cleaner view, the lungs are outlined, while the general lungs of AP cases are noisier and have orange tone. From the colorbar can be read the maximum number of overlapped pixels.","3be7f708":"Let's start with the DICOM files. Fortunately, Python has a library called [pydicom](https:\/\/pydicom.github.io\/pydicom\/stable\/getting_started.html) for reading them. As we can see below, a lot of metadata are available beside the x-ray image, but only a few of them may be useful for us. This patient, 38 years old man, is lucky, he has no Pneumothorax."}}