{"cell_type":{"4d27d821":"code","dc9ef3da":"code","5144cdd6":"code","d4433bb4":"code","540faa89":"code","cc889c2e":"code","7b0a965c":"code","d34a2670":"code","3d49407d":"code","2b1f4c9b":"code","5812302c":"code","5095187a":"code","319fe191":"code","bc3ae8c2":"code","79526d31":"code","299319f6":"code","0cfcdb66":"code","f1a39d23":"code","8619ed71":"code","5a28785c":"code","54b49460":"markdown","a2781f62":"markdown","05d496c8":"markdown","08ea3f95":"markdown","a7cdd3dd":"markdown"},"source":{"4d27d821":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u3092import\u3057\u307e\u3059\nimport os\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tqdm.notebook import tqdm\nimport librosa \nimport librosa.display\nimport IPython","dc9ef3da":"INPUT_DIR = '\/kaggle\/input\/hah-data-science-challenge'","5144cdd6":"# \u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\ndf_train = pd.read_csv('\/kaggle\/input\/hah-data-science-challenge\/train.csv', index_col=False)\ndf_test = pd.read_csv('\/kaggle\/input\/hah-data-science-challenge\/test.csv', index_col=False)\n\n# meta_data\u306b\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u3092\u8ffd\u52a0\ndf_train['filepath'] = INPUT_DIR + '\/train\/train\/' + df_train['\u30d5\u30a1\u30a4\u30eb']\ndf_test['filepath'] = INPUT_DIR + '\/test\/test\/' + df_test['\u30d5\u30a1\u30a4\u30eb']\n\n# train\u3068test\u3092\u3072\u3068\u3064\u306b\ndf = pd.concat([df_train, df_test]).reset_index(drop=True)","d4433bb4":"# \u540d\u5bc4\u305b\nrecording_map = {\n    'PC\u5185\u81d3': 'PC\u5185\u8535', \n    'PC\u5185\u8535': 'PC\u5185\u8535', \n    'USB1': 'USB1', \n    'USB2': 'USB2', \n    'USB3': 'USB3', \n    'USB4': 'USB4', \n    '\u30b9\u30de\u30db': '\u30b9\u30de\u30db', \n    '\u30b9\u30de\u30db\u306e\u30dc\u30a4\u30b9\u30ec\u30b3\u30fc\u30c0': '\u30b9\u30de\u30db', \n    '\u5185\u8535\u30de\u30a4\u30af': 'PC\u5185\u8535'\n}\n\ndistance_map = {\n    '10cm': '10cm',\n    '10\u339d': '10cm',\n    '1M': '1m',\n    '20cm': '20cm',\n    '20\u339d': '20cm',\n    '2M': '2m',\n    '2m': '2m',\n    '30cm': '30cm',\n    '30cn': '30cm',\n    '30\u339d': '30cm',\n    '3m': '3m',\n    '40cm': '40cm',\n    '40\u339d': '40cm',\n    '50cm': '50cm',\n    '50\u339d': '50cm',\n    '5cm': '5cm',\n    '8cm': '8cm',\n    '\uff11\uff2d': '1m'\n}\n\ndf['\u9332\u97f3\u65b9\u6cd5'] = df['\u9332\u97f3\u65b9\u6cd5'].replace(recording_map)\ndf['\u30de\u30a4\u30af\u8ddd\u96e2'] = df['\u30de\u30a4\u30af\u8ddd\u96e2'].replace(distance_map)","540faa89":"# \u4e00\u6253\u97f31\u30ec\u30b3\u30fc\u30c9\u306e\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u4f5c\u6210\u3059\u308b\nresults = []\nfilelist = df['filepath'].to_list()\n\nfor i in tqdm(range(len(df))):\n    filepath = df.loc[i, 'filepath']\n    y, sr = librosa.load(filepath)\n    onset_envelope = librosa.onset.onset_strength(y, sr)\n    onset_times = librosa.onset.onset_detect(y=y, sr=sr, onset_envelope=onset_envelope, units='time')\n    \n    for j, onset_time in enumerate(onset_times):\n        tmp = pd.DataFrame([df.loc[i]])\n        tmp['split_id'] = j\n        tmp['onset_time'] = onset_time\n        tmp['play_time'] = y.size \/ sr\n        results.append(tmp)\ndf_split = pd.concat(results)","cc889c2e":"# onset_detect\u3067\u691c\u51fa\u3055\u308c\u305f\u6642\u9593\u3092\u5143\u306b\u5207\u308a\u51fa\u3059\u6642\u9593\u3092\u8a2d\u5b9a\n# onset_detect\u306f\u3001\u59cb\u70b9\u304c\u82e5\u5e72\u9045\u308c\u3066\u3044\u308b\u306e\u3067\u30de\u30a4\u30ca\u30b9\u306e\u30aa\u30d5\u30bb\u30c3\u30c8\u3092\u4ed8\u4e0e\n# \u30aa\u30d5\u30bb\u30c3\u30c8\u639b\u3051\u305f\u59cb\u70b9\u304b\u3089\u56fa\u5b9a\u6642\u9593\u5206\u3092\u8db3\u3057\u305f\u5024\u3092\u7d42\u70b9\u3068\u3059\u308b\n\nst_offset = 0.05 # \u59cb\u70b9\u306e\u30aa\u30d5\u30bb\u30c3\u30c8\nduration = 0.2 # \u5207\u308a\u51fa\u3059\u6642\u9593\n\ndf_split['st_time'] = df_split['onset_time'] - st_offset\ndf_split['ed_time'] = df_split['st_time'] + duration\ndf_split['duration'] = duration\n\n# \u7d42\u70b9\u3067\u56fa\u5b9a\u6642\u9593\u306b\u6e80\u305f\u306a\u3044\u5834\u5408\u306f\u9664\u5916\ndf_split = df_split[df_split['ed_time'] <= df_split['play_time']].reset_index(drop=True)","7b0a965c":"# \u5207\u308a\u51fa\u3057\u305f\u6253\u97f3\u3054\u3068\u306esignal\u306e\u6700\u5927\u5024\u3092\u30e1\u30bf\u30c7\u30fc\u30bf\u306b\u8ffd\u52a0\u3059\u308b\nfor i in tqdm(range(len(df_split))):\n    filepath = df_split.loc[i, 'filepath']\n    st_time = df_split.loc[i, 'st_time']\n    duration = df_split.loc[i, 'duration']\n    \n    # load\u3059\u308b\u3068\u304d\u306boffset\u3067\u59cb\u70b9\u3001duration\u3067\u671f\u9593\u3092\u6307\u5b9a\u3059\u308b\n    y, sr = librosa.load(filepath, offset=st_time, duration=duration)\n    df_split.loc[i, 'signal_max'] = max(abs(y))","d34a2670":"# \uff11\u6253\u97f3\u3054\u3068\u306e\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u4fdd\u5b58\ndf_split.to_csv('split_metadata.csv', index=False)","3d49407d":"df = df_split.copy()","2b1f4c9b":"# \u97f3\u306e\u5927\u304d\u3055\u304c\u4e00\u5b9a\u4ee5\u4e0b\u306e\u30c7\u30fc\u30bf\u306f\u7121\u97f3\u3068\u3057\u3066\u3001\u5bfe\u8c61\u304b\u3089\u9664\u5916\nth = 0.5\ndf = df[df['signal_max']>0.5].reset_index(drop=True)","5812302c":"# librosa\u3067.wav\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u7279\u5fb4\u62bd\u51fa\u3057\u307e\u3059\u3002\nn_features = 20\n\nfeatures = np.zeros((len(df), n_features))\nfor i in tqdm(range(len(df))):\n    filepath = df.loc[i, 'filepath']\n    st_time = df.loc[i, 'st_time']\n    duration = df.loc[i, 'duration']\n    \n    y, sr = librosa.load(filepath, offset=st_time, duration=duration)\n    y = (y-y.min())\/(y.max()-y.min()) # \u30b5\u30f3\u30d7\u30eb\u3054\u3068\u306e\u6b63\u898f\u5316\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n    ceps = mfcc.mean(axis=1)\n    \n    # \u8907\u6570\u306e\u30ed\u30fc\u30ea\u30f3\u30b0\u30a6\u30a3\u30f3\u30c9\u30a6\u3067\u305d\u308c\u305e\u308c20\u6b21\u5143\u306eMFCC\u3092\u5f97\u3089\u308c\u308b\u306e\u3067\u3001\u305d\u306e\u5e73\u5747\u3092\u3068\u308b\u3002\n    features[i] = ceps","5095187a":"def outlier_scoring(train_data, pred_data, n_neighbors=15):\n    # \u6559\u5e2b\u306a\u3057\u7570\u5e38\u691c\u77e5\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3067\u7570\u5e38\u30b9\u30b3\u30a2\u3092\u4ed8\u4e0e\u3057\u307e\u3059\n    model = LocalOutlierFactor(novelty=True, n_neighbors=n_neighbors) # \u3053\u3053\u3067\u306fk-\u8fd1\u508d\u6cd5\u306e\u6d41\u308c\u3092\u304f\u3080LocalOutlierFactor\u3092\u7528\u3044\u307e\u3059\n    model.fit(train_data) # \u6b63\u5e38\u30c7\u30fc\u30bf\u306e\u307f\u3092\u7528\u3044\u3066\u5b66\u7fd2\u3057\u307e\u3059\n    pred = model.score_samples(pred_data) \n    # \u5024\u304c\u5c0f\u3055\u3044\u307b\u3069\u7570\u5e38\u5ea6\u304c\u9ad8\u3044\u306e\u3067\u3001\u7b26\u53f7\u3092\u3072\u3063\u304f\u308a\u8fd4\u3057\u30660\u304b\u30891\u306b\u304a\u3055\u3081\u308b\n    scaler = MinMaxScaler()\n    pred = scaler.fit_transform(-pred.reshape(-1,1))\n    return pred","319fe191":"# \u5f8c\u3005\u306e\u51e6\u7406\u306e\u305f\u3081\u306b\u305d\u308c\u305e\u308c\u306e\u6761\u4ef6\u306b\u5408\u81f4\u3059\u308bid\u3092\u53d6\u5f97\u3057\u3066\u304a\u304f\nnorm_idx = list(df[df['Target']==0].index)\nanorm_idx = list(df[df['Target']==1].index)\n\ntr_idx = norm_idx[:int(len(norm_idx)\/2)]\nval_idx = norm_idx[int(len(norm_idx)\/2):] + anorm_idx","bc3ae8c2":"tr = features[tr_idx]\nval = features[val_idx]","79526d31":"# LOF\u306en_neighbors\u3092\u632f\u3063\u3066cv\u30b9\u30b3\u30a2\u78ba\u8a8d\nfor param in [5,10,15,20]:\n    df_valid = df.copy()\n    df_valid.loc[val_idx, 'pred'] = outlier_scoring(tr, val, param)\n    df_valid = df_valid.dropna(subset=['Target', 'pred'])\n    score = roc_auc_score(df_valid['Target'], df_valid['pred'])\n    print(f'n_neighbors={param} | roc_auc_socre={score}')","299319f6":"tr_idx = norm_idx\npred_idx = list(df[df['\u30d5\u30a1\u30a4\u30eb'].str.contains('test')].index)","0cfcdb66":"tr = features[tr_idx]\npred = features[pred_idx]","f1a39d23":"df_pred = df.copy()\ndf_pred.loc[pred_idx, 'Target'] = outlier_scoring(tr, pred)\ndf_pred = df_pred[df_pred['\u30d5\u30a1\u30a4\u30eb'].str.contains('test')]","8619ed71":"# 1\u6253\u97f3\u3054\u3068\u306e\u7d50\u679c\u306e\u5e73\u5747\u53d6\u3063\u3066\u30d5\u30a1\u30a4\u30eb\u5358\u4f4d\u306e\u4e88\u6e2c\u5024\u3092\u7b97\u51fa\u3059\u308b\nmean_pred = df_pred.groupby('ID')['Target'].mean().reset_index()","5a28785c":"# sample_sub\u306b\u7d50\u679c\u3092merge\nsub = pd.read_csv('..\/input\/hah-data-science-challenge\/sample_submission.csv', usecols=['ID'])\nsub = sub.merge(mean_pred, on='ID', how='left')\n\n# \u3059\u3079\u3066\u7121\u97f3\u3060\u3063\u305f\u5834\u5408\u3001\u4e88\u6e2c\u5024\u304c\u306a\u3044\u306e\u3067\u5e73\u5747\u5024\u3067\u57cb\u3081\u308b\nsub = sub.fillna(sub['Target'].mean())\nsub = sub.set_index('ID')\nsub.to_csv('submission.csv')\nsub","54b49460":"# \u6253\u97f3\u5206\u89e3","a2781f62":"# \u5b66\u7fd2\u30fb\u8a55\u4fa1","05d496c8":"1\u6253\u97f3\u3054\u3068\u306b\u5206\u89e3\u3057\u305f\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066simple_baseline\u306e\u7570\u5e38\u691c\u77e5\u51e6\u7406\u3092\u884c\u3046","08ea3f95":"\u5206\u89e3\u524d\u3068\u6bd4\u8f03\u3059\u308b\u3068\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u5927\u304d\u304f\u5909\u52d5\u3059\u308b\u3053\u3068\u306f\u306a\u304f\u306a\u3063\u305f\uff1f","a7cdd3dd":"# sub\u4f5c\u6210"}}