{"cell_type":{"ca68e3ef":"code","9a4f11a9":"code","3d786066":"code","587afca8":"code","ded4e056":"code","e6c2eaca":"code","00742cce":"code","857afee5":"code","7bb286e2":"code","fe23295c":"code","ac0f2a9f":"code","f7a06539":"code","9a3da352":"code","b8170245":"code","892ae8c9":"code","b33d566f":"code","f6d97d5e":"code","58b8887f":"code","0117d61d":"code","ada46083":"code","c3a4e3a6":"code","ec4f33d3":"code","d4b5c1f1":"code","ba1af437":"code","faf59233":"code","6df66e6e":"code","b540f697":"code","4c78c92a":"code","3da7e21b":"code","a98fe067":"code","a110d1af":"code","a19ec6d4":"code","230ac5b3":"code","669dfe43":"code","51876256":"code","b483cf2f":"code","f14d9fa0":"code","9e3e3080":"code","a8873e1d":"code","08c450d6":"code","6428ab8c":"code","8e717b6d":"markdown","1493c1f6":"markdown","06873092":"markdown","c56ac5da":"markdown","ddf7562f":"markdown","4af84a6a":"markdown","19a3116a":"markdown","80af405f":"markdown","219389e6":"markdown","8b37ba4d":"markdown","3dd4d583":"markdown","2bd759c1":"markdown","231d1d8a":"markdown","010e20da":"markdown","60714c36":"markdown","e387f381":"markdown","4b657ac1":"markdown","ef240c29":"markdown","e26d01b8":"markdown","4b217512":"markdown","2f33f736":"markdown","2b818364":"markdown","25afe751":"markdown","1a478cdc":"markdown","382a04cd":"markdown","b40c4e34":"markdown","9a4b571c":"markdown","5e848db5":"markdown"},"source":{"ca68e3ef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2","9a4f11a9":"labels = os.listdir(\"..\/input\/drowsiness-dataset\/train\")","3d786066":"labels","587afca8":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/Closed\/_0.jpg\"))","ded4e056":"a = plt.imread(\"..\/input\/drowsiness-dataset\/train\/yawn\/10.jpg\")","e6c2eaca":"a.shape","00742cce":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/yawn\/10.jpg\"))","857afee5":"def face_for_yawn(direc=\"..\/input\/drowsiness-dataset\/train\", face_cas_path=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\"):\n    yaw_no = []\n    IMG_SIZE = 145\n    categories = [\"yawn\", \"no_yawn\"]\n    for category in categories:\n        path_link = os.path.join(direc, category)\n        class_num1 = categories.index(category)\n        print(class_num1)\n        for image in os.listdir(path_link):\n            image_array = cv2.imread(os.path.join(path_link, image), cv2.IMREAD_COLOR)\n            face_cascade = cv2.CascadeClassifier(face_cas_path)\n            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n            for (x, y, w, h) in faces:\n                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n                roi_color = img[y:y+h, x:x+w]\n                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n                yaw_no.append([resized_array, class_num1])\n    return yaw_no\n\n\nyawn_no_yawn = face_for_yawn()","7bb286e2":"def get_data(dir_path=\"..\/input\/drowsiness-dataset\/train\/\", face_cas=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\", eye_cas=\"..\/input\/prediction-images\/haarcascade.xml\"):\n    labels = ['Closed', 'Open']\n    IMG_SIZE = 145\n    data = []\n    for label in labels:\n        path = os.path.join(dir_path, label)\n        class_num = labels.index(label)\n        class_num +=2\n        print(class_num)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                data.append([resized_array, class_num])\n            except Exception as e:\n                print(e)\n    return data","fe23295c":"data_train = get_data()","ac0f2a9f":"def append_data():\n#     total_data = []\n    yaw_no = face_for_yawn()\n    data = get_data()\n    yaw_no.extend(data)\n    return np.array(yaw_no)","f7a06539":"new_data = append_data()","9a3da352":"X = []\ny = []\nfor feature, label in new_data:\n    X.append(feature)\n    y.append(label)","b8170245":"X = np.array(X)\nX = X.reshape(-1, 145, 145, 3)","892ae8c9":"from sklearn.preprocessing import LabelBinarizer\nlabel_bin = LabelBinarizer()\ny = label_bin.fit_transform(y)","b33d566f":"y = np.array(y)","f6d97d5e":"from sklearn.model_selection import train_test_split\nseed = 40\ntest_size = 0.20\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)","58b8887f":"len(X_test)","0117d61d":"# !pip install tensorflow==2.3.1\n# !pip install keras==2.4.3","ada46083":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","c3a4e3a6":"tf.__version__","ec4f33d3":"import keras\nkeras.__version__","d4b5c1f1":"train_generator = ImageDataGenerator(rescale=1\/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\ntest_generator = ImageDataGenerator(rescale=1\/255)\n\ntrain_generator = train_generator.flow(np.array(X_train), y_train, shuffle=False)\ntest_generator = test_generator.flow(np.array(X_test), y_test, shuffle=False)","ba1af437":"model = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=X_train.shape[1:]))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(128, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n\nmodel.summary()","faf59233":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='mymodel1.png', show_layer_names=True)\nImage(filename='mymodel1.png') ","6df66e6e":"history = model.fit(train_generator, epochs=30, validation_data=test_generator, shuffle=True, validation_steps=len(test_generator))","b540f697":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='mymodel.png', show_shapes=True,show_layer_names=True)\nImage(filename='mymodel.png') ","4c78c92a":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, \"b\", label=\"trainning accuracy\")\nplt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, \"b\", label=\"trainning loss\")\nplt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\nplt.legend()\nplt.show()","3da7e21b":"model.save(\"drowiness_new_finalmee.h5\")","a98fe067":"model.save(\"drowiness_new_final.model\")","a110d1af":"prediction = model.predict_classes(X_test)","a19ec6d4":"prediction","230ac5b3":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]","669dfe43":"from sklearn.metrics import classification_report\nprint(classification_report(np.argmax(y_test, axis=1), prediction, target_names=labels_new))","51876256":"from sklearn import metrics\nprint('Accucary:', metrics.accuracy_score(np.argmax(y_test, axis=1), prediction))\nprint('Confusion Matrix\\n',metrics.confusion_matrix(np.argmax(y_test, axis=1),prediction))","b483cf2f":"import seaborn as sb\nplt.figure(figsize=(4,4))\nsb.heatmap(metrics.confusion_matrix(np.argmax(y_test, axis=1),prediction), annot=True, fmt=\".1f\", linewidths=.90, square = True, cmap = 'Blues_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(metrics.accuracy_score(np.argmax(y_test, axis=1), prediction))\nplt.title(all_sample_title, size = 15);","f14d9fa0":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\nIMG_SIZE = 145\ndef prepare(filepath, face_cas=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\"):\n    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n    img_array = img_array \/ 255\n    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nmodel = tf.keras.models.load_model(\".\/drowiness_new_final.h5\")","9e3e3080":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/no_yawn\/1068.jpg\"))\nprediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/no_yawn\/1067.jpg\")])\nnp.argmax(prediction)","a8873e1d":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/Closed\/_101.jpg\"))\nprediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/Closed\/_101.jpg\")])\nnp.argmax(prediction)","08c450d6":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/yawn\/113.jpg\"))\nprediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/Open\/_104.jpg\")])\nnp.argmax(prediction)","6428ab8c":"prediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/yawn\/113.jpg\")])\nnp.argmax(prediction)","8e717b6d":"# image shape","1493c1f6":"# extend data and convert array","06873092":"# separate label and features","c56ac5da":"# Data Augmentation","ddf7562f":"# classification report","4af84a6a":"# for yawn and not_yawn. Take only face","19a3116a":"# keras version","80af405f":"# label array","219389e6":"# reshape the array","8b37ba4d":"# import some dependencies","3dd4d583":"# save model","2bd759c1":"# image array","231d1d8a":"# If you like please upvote","010e20da":"# Prediction","60714c36":"# for closed and open eye","e387f381":"# tensorflow version","4b657ac1":"# Model","ef240c29":"# Prediction \n## 0-yawn, 1-no_yawn, 2-Closed, 3-Open","e26d01b8":"# visualize random 1 image","4b217512":"# Not necessary, only use to matching with my pc version","2f33f736":"# new variable to store","2b818364":"# length of X_test","25afe751":"# train test split","1a478cdc":"# LabelBinarizer","382a04cd":"# visualize yawn image. \n# Here background is unnecessary. we need only face image array","b40c4e34":"# predicting function","9a4b571c":"# history","5e848db5":"# labels"}}