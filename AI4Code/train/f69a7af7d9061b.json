{"cell_type":{"6a637d69":"code","3ab84cea":"code","fe198aa9":"code","f9a43ef6":"code","0cf9bccb":"code","65c9619f":"code","ab854420":"code","a86c3083":"code","406c1a9b":"code","40c5c283":"code","57ecfeb9":"code","6f029842":"code","e69ce1be":"code","26fced60":"code","4a277322":"code","26fec0a9":"markdown","3b8c6f0f":"markdown","58415ee6":"markdown","f29195b7":"markdown","74e1eb63":"markdown","695cec2b":"markdown","929791be":"markdown","f591ad08":"markdown","00761cd8":"markdown"},"source":{"6a637d69":"import numpy as np\nimport pandas as pd\nimport os\nimport time\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.utils import np_utils\nfrom keras import backend as k\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt","3ab84cea":"img_path = '..\/input\/sheep-breed-classification\/SheepFaceImages\/Marino\/00.jpgMA8.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))\nplt.imshow(img)\n\n# Convert the images to numpy array\nx = image.img_to_array(img)\nprint (x.shape)\nx = np.expand_dims(x, axis=0)\nprint (x.shape)\nx = preprocess_input(x)\nprint('Input image shape:', x.shape)","fe198aa9":"PATH = '..\/input\/sheep-breed-classification'\n# Define data path\ndata_path = PATH + '\/SheepFaceImages'\ndata_dir_list = os.listdir(data_path) # List containing names of sheep breeds","f9a43ef6":"img_data_list = []\nimg_list_lengths = []\nnames = []\n\n# labels = np.ones((num_of_samples,),dtype='int64')\n\nfor dataset in data_dir_list:\n    # Load images in dataset\n    img_list = os.listdir(data_path+'\/'+ dataset)\n    img_list_lengths.append(len(img_list))\n    \n    # Save the name of the dataset\n    names.append(dataset) \n\n    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n    for img in img_list:\n        img_path = data_path + '\/'+ dataset + '\/'+ img \n        img = image.load_img(img_path, target_size=(224, 224))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        x = preprocess_input(x)\n        #print('Input image shape:', x.shape)\n        img_data_list.append(x)\n","0cf9bccb":"print(names)","65c9619f":"img_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nprint (img_data.shape)\nimg_data=np.rollaxis(img_data,1,0)\nprint (img_data.shape)\nimg_data=img_data[0]\nprint (img_data.shape)","ab854420":"num_classes = 4\nnum_of_samples = img_data.shape[0]\nlabels = np.ones((num_of_samples,),dtype='int64')","a86c3083":"# Assign correct label to the list of images\nstart = 0\nfor label in range(num_classes):\n    end = start + img_list_lengths[label]\n    labels[start : end] = label\n    start = end","406c1a9b":"Y = np_utils.to_categorical(labels, num_classes)","40c5c283":"#Shuffle the dataset\nx, y = shuffle(img_data, Y, random_state=777)\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=777)","57ecfeb9":"print('X_train shape: ', X_train.shape)\nprint('X_test shape: ', X_test.shape)\nprint('y_train shape: ', y_train.shape)\nprint('y_test shape: ', y_test.shape)","6f029842":"inputs = np.concatenate((X_train, X_test), axis=0)\ntargets = np.concatenate((y_train, y_test), axis=0)\n\ndel X_train, X_test, y_train, y_test, Y","e69ce1be":"folds = 10\n\n# Lists for storing training metrics per fold \ntrain_acc_per_fold = []\nloss_per_fold = []\n\n# Lists for storing test metrics per fold\nval_acc_per_fold = []\nval_prec_per_fold = []\nval_rec_per_fold = []\nval_f1_per_fold = []\n\nkfold = KFold(n_splits=folds, shuffle=True)\n\ncallback = EarlyStopping(monitor='accuracy', patience=10)\n\nimage_input = Input(shape=(224, 224, 3))\n\nfold_no = 1\nfor train, test in kfold.split(inputs, targets):\n    \n    y_test = targets[test]\n    test_labels = np.argmax(y_test, axis=1)\n    \n    # Save the labels in a file\n    pd.DataFrame(y_test).to_csv('resnet50_y_test_fold' + str(fold_no) + '.csv', index=False)\n    \n    # Load the ResNet50 model with imagenet weights\n    model = ResNet50(input_tensor = image_input, weights = 'imagenet', include_top = True)\n    \n    # Add some more layers to accomodate to our needs of classifying the sheep\n    last_layer = model.get_layer('avg_pool').output  \n    x = BatchNormalization()(last_layer)  # Accuracy: 94.58 (with this layer included)\n    #x = Dropout(0.2)(last_layer)           # Accuracy: 93.63 (with this layer included)\n    x = Flatten(name='flatten')(x)         # Accuracy: 94.24\n    out = Dense(num_classes, activation='softmax', name='output_layer')(x)\n    custom_resnet50_model = Model(inputs=image_input, outputs=out)\n    #custom_resnet50_model.summary()\n    \n    for layer in model.layers:\n        layer.trainable = False\n        \n    # Compile the model\n    custom_resnet50_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    print(f'Training for fold {fold_no} ...')\n    \n    t=time.time()\n    hist = custom_resnet50_model.fit(inputs[train], targets[train], batch_size=32, epochs=200, verbose=0, callbacks=[callback])\n    print('Training time: %s seconds' % (time.time() - t))\n    \n    # Evaluate the trained model\n    scores = custom_resnet50_model.evaluate(inputs[test], targets[test], batch_size=10, verbose=0)\n    \n    # Make predictions on the validation set and flatten\n    preds = custom_resnet50_model.predict(inputs[test], batch_size=10, verbose=0)\n    preds_flat = np.argmax(preds, axis=1)\n    \n    # Calculate validation metrics\n    val_acc = accuracy_score(test_labels, preds_flat)\n    val_prec = precision_score(test_labels, preds_flat, average='weighted')\n    val_rec = recall_score(test_labels, preds_flat, average='weighted')\n    val_f1 = f1_score(test_labels, preds_flat, average='weighted')\n    \n    val_acc_per_fold.append(val_acc*100)\n    val_prec_per_fold.append(val_prec*100)\n    val_rec_per_fold.append(val_rec*100)\n    val_f1_per_fold.append(val_f1*100)\n    \n    # Save the scores and the validation predictions foldwise (if needed)\n    pd.DataFrame(preds).to_csv('resnet50_preds_fold' + str(fold_no) + '.csv', index=False)\n    pd.DataFrame(scores).to_csv('resnet50_history_fold' + str(fold_no) + '.csv', index=False)\n    \n    print(f'Training score for fold {fold_no}: {custom_resnet50_model.metrics_names[0]} of {scores[0]}; {custom_resnet50_model.metrics_names[1]} of {scores[1]*100}%')\n    train_acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    \n    fold_no += 1","26fced60":"# Average Scores for training and validation\nprint('------------------------------------------------------------------------')\nprint('Training score per fold')\nfor i in range(0, len(train_acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {train_acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\n\nprint('Validation score per fold')\nfor i in range(0, len(val_acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Accuracy: {val_acc_per_fold[i]}% - Precision: {val_prec_per_fold[i]}% - Recall: {val_rec_per_fold[i]}% - F1 Score: {val_f1_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\n\nprint('Average training scores for all folds:')\nprint(f'> Accuracy: {np.mean(train_acc_per_fold)}% (+- {np.std(train_acc_per_fold)}%)')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')\n\nprint('Average validation scores for all folds:')\nprint(f'> Accuracy: {np.mean(val_acc_per_fold)}% (+- {np.std(val_acc_per_fold)}%)')\nprint(f'> Precision: {np.mean(val_prec_per_fold)}% (+- {np.std(val_prec_per_fold)}%)')\nprint(f'> Recall: {np.mean(val_rec_per_fold)}% (+- {np.std(val_rec_per_fold)}%)')\nprint(f'> F1 Score: {np.mean(val_f1_per_fold)}% (+- {np.std(val_f1_per_fold)}%)')\nprint('------------------------------------------------------------------------')","4a277322":"# resnet50_df = pd.DataFrame({'0': preds[:, 0], '1': preds[:, 1], '2': preds[:, 2], '3': preds[:, 3]})\n# resnet50_df.to_csv('resnet50_predictions.csv', index=False)","26fec0a9":"#### This notebook aims to develop a ResNet50 model to classify sheep breeds. The model scores over 93% with a standard deviation of 1.5-2%. It is a code implementation used in the paper:\n[Ensemble Algorithm using Transfer Learning for Sheep Breed Classification](http:\/\/https:\/\/ieeexplore.ieee.org\/document\/9465609)","3b8c6f0f":"### Load the images spread across different directories","58415ee6":"#### Let's dive deep into modelling...","f29195b7":"### Here goes everyone is concerned about \ud83d\ude0e... ***Training and Validation***","74e1eb63":"### *Necessary Imports*","695cec2b":"### *Plot a beautiful sheep face... Well, at least I think they are cute!* ","929791be":"### Here's what managers are concerned about \ud83d\ude05... ***Classification metrics***","f591ad08":"### *Assign the labels to the images, don't mess up!!! Merino is for wool and Suffolk is for meat! Mistakes can be costly, after all!!*","00761cd8":"#### *A lots of wool!! Certainly this one is not meant for meat!! This is the Merino sheep, wool of which is one of the most expensive in the world!!!*\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/a\/a1\/Merino_sheep.png)"}}