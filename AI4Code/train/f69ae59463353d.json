{"cell_type":{"044d58fb":"code","fa2eb12a":"code","28f2c06a":"code","e13ae60f":"code","4ad81895":"code","9ce955a9":"code","367a1335":"code","906aaa9e":"code","561aa982":"code","02e48e49":"code","ed08cf26":"code","cd88f961":"code","2a17d19c":"code","15a7b129":"code","6ebc91a3":"code","530ae530":"code","89931e90":"code","1702a2b5":"code","314ac603":"code","4b748a05":"code","054b5d39":"markdown","fd9ce70a":"markdown","481eeb33":"markdown","ddef49f7":"markdown","15340846":"markdown","17953b24":"markdown","ac00eb83":"markdown","49b203ee":"markdown","23173458":"markdown","bb12f552":"markdown","06cae9cb":"markdown","d4a81dac":"markdown","8acbcc3d":"markdown","adf7caa8":"markdown","e4d690c4":"markdown","34cf2369":"markdown"},"source":{"044d58fb":"!pip install git+https:\/\/github.com\/qubvel\/efficientnet","fa2eb12a":"# LOAD LIBRARIES\nimport time\nstartNB = time.time()\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, AvgPool2D, MaxPool2D , Flatten , Dropout, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import recall_score, accuracy_score, precision_recall_fscore_support, classification_report,confusion_matrix, f1_score\nfrom sklearn.utils import class_weight\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport cv2\nimport os\n\nprint(tf.__version__)\n\nprint('TensorFlow version =',tf.__version__)","28f2c06a":"# VERSION MAJOR and MINOR for logging\nmm = 1; rr = 1\n\n# Default batch size can be changed later\nSEED = 36\nBATCH_SIZE = 64\nDIM = 128\nimg_size = DIM\nLR = 1e-3\nDECAY = 0.75\n\n# BEGIN LOG FILE\nf = open(f'log-{mm}-{rr}.txt','a')\nprint('Logging to \"log-%i-%i.txt\"'%(mm,rr))\nf.write('TensorFlow version ={tf.__version__}')\nf.write('#############################\\n')\nf.write(f'Trial mm={mm}, rr={rr}\\n')\nf.write('efNetB4, batch_size='+str(BATCH_SIZE)+', seed='+str(SEED)+', '+str(DIM)+'x'+str(DIM)+', fold=0, LR '+str(1e-3)+' with '+str(0.75)+' decay\\n')\nf.write('#############################\\n')\nf.close()","e13ae60f":"# Let's create a function that will import and label the image set\nlabels = [\"jute\", \"maize\", \"sugarcane\", \"wheat\", \"rice\"]\n\ndef get_data(data_dir):\n    data = [] \n    path = os.path.join('\/kaggle\/input\/', data_dir)\n    for label in labels:\n        path_label = os.path.join(path, label)\n        for img in os.listdir(path_label):\n            try:\n                img_arr = cv2.imread(os.path.join(path_label, img), cv2.IMREAD_COLOR)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                # Images are charged as BGR we switch channels to RGB\n                RGB_arr = resized_arr[:,:,[2,1,0]]\n                data.append([RGB_arr, labels.index(label)])\n            except Exception as e:\n                print(img, e)                    \n    return np.array(data)\n\ndef get_extra_data(data_dir):\n    \"\"\"\n    Serves for the extra data set of 8 images\n    \"\"\"\n    data = [] \n    path_label = os.path.join('\/kaggle\/input\/', data_dir)\n    for img in os.listdir(path_label):\n        try:\n            img_arr = cv2.imread(os.path.join(path_label, img), cv2.IMREAD_COLOR)\n            resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n            # Images are charged as BGR we switch channels to RGB\n            RGB_arr = resized_arr[:,:,[2,1,0]]\n            for label in labels:\n                if label in img:\n                    # print(img, label)\n                    data.append([RGB_arr, labels.index(label)])\n        except Exception as e:\n            print(img, e)                    \n    return np.array(data)","4ad81895":"train_data = get_data('agriculture-crop-images\/kag2')\ntest_extra_data =  get_extra_data('testssss\/test_crop_image')","9ce955a9":"x_data = []\ny_data = []\n\nx_test_extra = []\ny_test_extra = []\n\nfor feature, label in train_data:\n    x_data.append(feature)\n    y_data.append(label)\n    \nfor feature, label in test_extra_data: \n    x_test_extra.append(feature)\n    y_test_extra.append(label)","367a1335":"sns.set_style('darkgrid')\nsns.countplot(y_data).set_title('Train data')","906aaa9e":"sns.set_style('darkgrid')\nsns.countplot(y_test_extra).set_title('Test data')","561aa982":"X_train = np.array(x_data).reshape(-1, img_size, img_size, 3)\nX_test_extra = np.array(x_test_extra).reshape(-1, img_size, img_size, 3)\n\n# We convert numerical to one hot encoding\ny_train = np.array(tf.keras.utils.to_categorical(y_data, num_classes=5))\ny_test_extra = np.array(tf.keras.utils.to_categorical(y_test_extra, num_classes=5))\n\nprint(X_train.shape, y_train.shape, X_test_extra.shape, y_test_extra.shape)","02e48e49":"def build_model():\n    \n    # We input the images we have reshaped in 3 channels (RGB)\n    inp = tf.keras.Input(shape=(DIM,DIM,3))\n    # We use the pretrained weights but not the top\n    base_model = efn.EfficientNetB4(weights='imagenet',include_top=False, input_shape=(DIM,DIM,3))\n\n    x = base_model(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    # use a strong droptout because we have few input images\n    x = tf.keras.layers.Dropout(0.5)(x)\n    # predict for 5 classes\n    x = tf.keras.layers.Dense(5, activation='softmax',name='x1',dtype='float32')(x)\n    \n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(lr=0.00001)\n    model.compile(loss='categorical_crossentropy', optimizer = opt,\\\n              metrics=['categorical_accuracy'])\n        \n    return model","ed08cf26":"# CUSTOM LEARNING SCHEUDLE\nLR_START = 1e-5\nLR_MAX = 1e-3\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_STEP_DECAY = 0.75\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)\/\/10)\n    return lr\n    \nlr2 = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n\nrng = [i for i in range(100)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y); \nplt.xlabel('epoch',size=14); plt.ylabel('learning rate',size=14)\nplt.title('Training Schedule',size=16); plt.show()","cd88f961":"train_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\n# Test gen is useless in this case\n# test_datagen = ImageDataGenerator()","2a17d19c":"class CustomCallback(tf.keras.callbacks.Callback):\n    def __init__(self, valid_data, target, fold, mm=0, rr=0, patience=10):\n        self.valid_inputs = valid_data\n        self.valid_outputs = target\n        self.fold = fold\n        self.patience = patience\n        self.mm = mm\n        self.rr = rr\n        \n    def on_train_begin(self, logs={}):\n        self.valid_f1 = [0]\n        \n    def on_epoch_end(self, epoch, logs={}):\n        # At the end of the epoch we predict the classes on validation\n        preds = self.model.predict(self.valid_inputs)\n        # we transform vector prediction into numerical class\n        preds = np.argmax(preds,axis=1)\n\n        # Calculate metrics\n        p, r, f1score, support = precision_recall_fscore_support(self.valid_outputs,preds,average='macro')\n        a = accuracy_score(self.valid_outputs,preds)\n\n        # LOG TO FILE\n        f = open('log-%i-%i.txt'%(self.mm,self.rr),'a')\n        f.write('#'*25); f.write('\\n')\n        f.write('#### FOLD %i EPOCH %i\\n'%(self.fold+1,epoch+1))\n        f.write('#### PRECISION: p=%.5f' % (p) )\n        f.write('#### RECALL: r=%.5f' % (r) )\n        f.write('#### F1SCORE: f1=%.5f' % (f1score) )\n        f.write('#### ACCURACY: a1=%.5f\\n' % (a) )\n\n\n        print('\\n'); print('#'*25)\n        print('#### FOLD %i EPOCH %i'%(self.fold+1,epoch+1))\n        print('#### PRECISION: p=%.5f' % (p) )\n        print('#### RECALL: r=%.5f' % (r) )\n        print('#### F1SCORE: f1=%.5f' % (f1score) )\n        print('#### ACCURACY: a1=%.5f' % (a) )\n        print('#'*25)\n        \n        # Stop training after multiple epochs if validation f1 score is not improving\n        self.valid_f1.append(f1score)\n        x = np.asarray(self.valid_f1)\n        if np.argsort(-x)[0]==(len(x)-self.patience-1):\n            print('#### F1 no increase for %i epochs: EARLY STOPPING' % self.patience)\n            f.write('#### F1 no increase for %i epochs: EARLY STOPPING\\n' % self.patience)\n            self.model.stop_training = True\n            \n        if (f1score>0.000)&(f1score>np.max(self.valid_f1[:-1])):\n            print('#### Saving new best...')\n            f.write('#### Saving new best...\\n')\n            self.model.save_weights('fold%i-m%i-%i.h5' % (self.fold,self.mm,self.rr))\n            \n        f.close()","15a7b129":"# TRAIN MODEL\n# Predictions will be saved for future uses\noo = np.zeros((X_train.shape[0],5))\n\n# We will get 5 split of our data which could give 5 attempts at training\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\n# We retransform y with argmax because split method can't handle onehotencoding\nfor fold,(idxT,idxV) in enumerate(skf.split(X_train,np.argmax(y_train, axis=1))):\n         \n    print('#'*25)\n    print('### FOLD %i' % (fold+1))\n    print('### train on %i images. validate on %i images'%(len(idxT),len(idxV)))\n    print('#'*25)\n    \n    K.clear_session()\n    model = build_model()\n    \n    # We identify the training flow wwith the IDs given by split method\n    # Shuffle is very important \n    train_flow = train_datagen.flow(\n        x=X_train[idxT],\n        y=y_train[idxT],\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        sample_weight=None,\n        seed=SEED\n    )\n    \n    # CustomCallback will allow us to save best model weights\n    cc = CustomCallback(valid_data=X_train[idxV], target=np.argmax(y_train[idxV], axis=1), fold=fold, mm=mm, rr=rr, patience=15)\n    \n    h = model.fit(train_flow, epochs = 30, verbose=1, callbacks=[cc, lr2])\n\n    print('#### Loading best weights...')\n    model.load_weights('fold%i-m%i-%i.h5' % (fold,mm,rr))\n    \n    oo = model.predict(X_train)\n\n    # SAVE OOF and IDXV\n    np.save('oo-%i-%i'%(mm,rr),oo)\n    np.save('idxV-%i-%i'%(mm,rr),idxV)\n    np.save('Y_train-%i-%i'%(mm,rr),y_train)\n    # we will limit ourself to one fold\n    break","6ebc91a3":"def display_stats_and_confusion_matrix(y_pred, y, names=labels):\n    \"\"\"\n    Print stats and display confustion matrix\n    y must be provided as numerical values not one hot\n    \"\"\"\n    cm = confusion_matrix(y,y_pred)\n    cm = pd.DataFrame(cm , index = names , columns = names)\n    cm.index.name = 'Label'\n    cm.columns.name = 'Predicted'\n\n    precision, recall, fscore, support = precision_recall_fscore_support(y_pred, y, average=None)\n    print(\"#########################\")\n    for p,l in zip(precision, names):\n        print(\"#### Precision for %s %.2f\" % (l, p))\n    print(\"#########################\")        \n    for r,l in zip(recall, names):\n        print(\"#### Recall for %s %.2f\" % (l, r))\n    print(\"#########################\")        \n    for f,l in zip(fscore, names):\n        print(\"#### F1Score for %s %.2f\" % (l, f))\n    print(\"#########################\")\n\n    group_counts = [\"{0:0.0f}\".format(value) for value in cm.to_numpy().flatten()]\n    # Percentage are normalized so as to interpret read values\n    group_percentages = [\"{0:.2%}\".format(value) for value in cm.to_numpy().flatten()\/np.sum(cm.to_numpy())]\n    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(5,5)\n\n    plt.figure(figsize = (10,10))\n    sns.heatmap(cm,\n                annot=labels,\n                cmap= \"coolwarm\",\n                linecolor = 'black',\n                linewidth = 1,\n                fmt='')    ","530ae530":"y_pred_num = np.argmax(model.predict(X_train[idxV]),axis=1)\ny_num = np.argmax(y_train[idxV],axis=1)\ndisplay_stats_and_confusion_matrix(y_pred_num,y_num)","89931e90":"y_pred_extra_num = np.argmax(model.predict(X_test_extra), axis=1)\ny_extra_num = np.argmax(y_test_extra,axis=1)\ndisplay_stats_and_confusion_matrix(y_pred_extra_num,y_extra_num)","1702a2b5":"df = pd.DataFrame({'label':y_extra_num, 'prediction':y_pred_extra_num, 'img': X_test_extra.reshape(len(y_extra_num),-1).tolist()})","314ac603":"print(\"### Correctly classifed images\")\nplt.figure(figsize=(20,20))\ni_ = 0\n\ncorrectImages = df[df['label'] == df['prediction']]\nfor index, row in correctImages.iterrows():\n    im = np.array(row['img']).reshape(DIM,DIM,3)\n    actual_label = labels[row['label']]\n    predicted = labels[row['prediction']]\n    plt.subplot(5, 5, i_+1).title.set_text(\"Label: %s \" % (predicted))\n    plt.imshow(im)\n    plt.axis('off')\n    i_ += 1\n    if index >= 25:\n        break","4b748a05":"print(\"### Misclassified images\")\nplt.figure(figsize=(20,20))\ni_ = 0\n\nmultipleImages = df[df['label'] != df['prediction']]\nfor index, row in multipleImages.iterrows():\n    im = np.array(row['img']).reshape(DIM,DIM,3)\n    actual_label = labels[row['label']]\n    predicted = labels[row['prediction']]\n    plt.subplot(5, 5, i_+1).title.set_text(\"Label: %s Predicted: %s\"%(actual_label, predicted))\n    plt.imshow(im)\n    plt.axis('off')\n    i_ += 1\n    if index >= 25:\n        break","054b5d39":"The model is not doing quite well, this is because they significantly differ from the training set which could also be too small.","fd9ce70a":"Last but not least our CustomCallback will allow us to save the best results after each epoch","481eeb33":"<h1>Preambule<\/h1>\n\nI will try to give tips for beginners to progress in what they can include in their models.\n\nI used some of the ideas in this notebook from a grand master:\nhttps:\/\/www.kaggle.com\/cdeotte\/how-to-compete-with-gpus-workshop\n\nAs requested by the uploader of the dataset, I added his test set which I named extra_test and countains only 8 images","ddef49f7":"<h1>Data Loading<\/h1>","15340846":"<h1>Predictions<\/h1>\nLet's look at predictions on our validation data","17953b24":"We need to preprocess data so as it has the rights shapes and types to be accepted for the model","ac00eb83":"<h1>Working on our model<\/h1>\n\nWe use EfficientNetB4 and remove the top layer to include our 5 classes","49b203ee":"We can see from previous accuracy that we are overfitting despite image augmentation and high dropout but we have few data image","23173458":"All images are correctly or closed to correctly classified for the set provided.\nIt seems some of the images are already data augmented from an original set which leads to this overfit.\n\n\nNow we can test with the 8 images provided as extra data.","bb12f552":"It's usually helpful to keep trace of executed tensorflow version as you may want to reuse your code later and have to update some parts.","06cae9cb":"<h1>Installation and imports<\/h1>\n\nLet's start by installing EfficientNet a lightweight convolutional neural network architecture, we will use this pretrained model to categorize the images, here is a comparision with other models:\n![](https:\/\/raw.githubusercontent.com\/tensorflow\/tpu\/master\/models\/official\/efficientnet\/g3doc\/params.png)\n\nWe will be using B4 which is at the inflection point between perfomance and results.","d4a81dac":"<h1>Training<\/h1>\n","8acbcc3d":"We will use a method that changes learning rate over epochs, those values can be adapted based on trials","adf7caa8":"We will be using 2 keras standard Image generator that will apply transformation on our training data and none on our test.","e4d690c4":"<h1>Parameters and logging<\/h1>\n\nWe will log and save training and model thus enabling to reopen previous calculations and parameter tries and compare results.","34cf2369":"Let's display the training set class num to check they are globally balanced"}}