{"cell_type":{"58e84bae":"code","11c31972":"code","8f86522f":"code","e58f84e3":"code","d3c6abe4":"code","ca9e0e5d":"code","378f9d3d":"code","fcbd8297":"code","281cd414":"code","15d02658":"code","c672c2ad":"code","a6216e13":"code","88ddebbd":"code","27c06f50":"code","eecd56df":"code","6567de07":"code","ce433b22":"code","0c97be61":"code","aa3ed4d5":"code","fff509e7":"code","c42946e6":"code","64ede0cf":"code","d5c9ce8f":"code","22c1d078":"code","d4cc060f":"code","6dacdc2b":"code","ceadd816":"code","7c9a9458":"code","9ac06a32":"code","23dab9f6":"code","cacc4ac2":"code","c7c268ad":"code","de006d92":"code","04246b6c":"code","991d3a8c":"code","e9daa85f":"code","bb71e074":"code","907c22c6":"code","e4b11fbe":"markdown","14698437":"markdown","3efb556e":"markdown","fca5899c":"markdown","8706ce5a":"markdown","40f50840":"markdown","ffa6a51d":"markdown","7d0ddd0e":"markdown","c4c3a8a0":"markdown","e3eb3876":"markdown","f6497807":"markdown","74a2b403":"markdown","f634cfca":"markdown","0a8b9480":"markdown","26d824c5":"markdown","2b81c68f":"markdown","9072c369":"markdown"},"source":{"58e84bae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11c31972":"import numpy as np\nimport pandas as pd\nimport random\n\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.linear_model import LinearRegression\n\nfrom datetime import datetime\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","8f86522f":"import warnings\nwarnings.filterwarnings('ignore')\n\nmatplotlib.rcParams.update({'font.size': 14})","e58f84e3":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","d3c6abe4":"TEST_DATASET_PATH = '..\/input\/coursework\/test.csv'\nTRAIN_DATASET_PATH = '..\/input\/coursework\/train.csv'\nDATASET_PATH_TARGET = '..\/input\/coursework\/sample_submission.csv'","ca9e0e5d":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntrain_df.tail()","378f9d3d":"test_df = pd.read_csv(TEST_DATASET_PATH)\ntest_df.tail()","fcbd8297":"print('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0440\u0435\u0439\u043d\u0435:', train_df.shape[0])\nprint('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0435\u0441\u0442\u0435', test_df.shape[0])","281cd414":"train_df.dtypes","15d02658":"def memory_compression(df):\n    original_mem = df.memory_usage().sum()\/1024**2\n    \n    for col in df.columns:\n        \n        if df[col].dtype != object:\n            col_min = df[col].min()\n            col_max = df[col].max()\n\n            if str(df[col].dtype)[:3] == 'int':\n                if col_min > np.iinfo(np.int8).min and col_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif col_min > np.iinfo(np.int16).min and col_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif col_min > np.iinfo(np.int32).min and col_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif col_min > np.iinfo(np.int64).min and col_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            elif str(df[col].dtype)[:5] == 'float':\n                if col_min > np.finfo(np.float32).min and col_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n            \n    reduced_mem = df.memory_usage().sum()\/1024**2\n    \n    print(f'\u0418\u0437\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0437\u0430\u043d\u0438\u043c\u0430\u0435\u043c\u043e\u0439 \u043f\u0430\u043c\u044f\u0442\u0438 \u0440\u0430\u0432\u0435\u043d {round(original_mem,2)} \u043c\u0431.')\n    print(f'\u041a\u043e\u043d\u0435\u0447\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0437\u0430\u043d\u0438\u043c\u0430\u0435\u043c\u043e\u0439 \u043f\u0430\u043c\u044f\u0442\u0438 \u0440\u0430\u0432\u0435\u043d {round(reduced_mem,2)} \u043c\u0431.')","c672c2ad":"memory_compression(train_df)\nmemory_compression(test_df)","a6216e13":"target_mean = round(train_df['Price'].mean(), 2)\ntarget_median = train_df['Price'].median()\nplt.figure(figsize = (16, 8))\n\nsns.distplot(train_df['Price'], bins=50)\n\ny = np.linspace(0, 0.000005, 10)\nplt.plot([target_mean] * 10, y, label='mean', linestyle=':', linewidth=4)\nplt.plot([target_median] * 10, y, label='median', linestyle='--', linewidth=4)\n\n\nplt.title('Distribution of Price')\nplt.legend()\nplt.show()","88ddebbd":"numeric_cols = ['int16', 'float16', 'int8', 'int32', 'float32']\ntrain_numeric = train_df.select_dtypes(include = numeric_cols)\ntrain_numeric.drop('Price', axis='columns', inplace=True)\nfig, axes = plt.subplots(nrows=7,ncols=2)\nfor col, axis in zip(train_numeric.columns, axes.flatten()):\n    train_numeric.hist(column = col, bins=100, ax=axis)\nfig.set_size_inches(12, 19)\nfig.subplots_adjust(wspace=0.5, hspace=0.5)","27c06f50":"train_df.describe()","eecd56df":"train_df['Id'] = train_df['Id'].astype(str)\n\ntrain_df['DistrictId'] = train_df['DistrictId'].astype(int)\n\ngrid = sns.jointplot(train_df['DistrictId'], train_df['Price'], kind='hex')\ngrid.fig.set_figwidth(8)\ngrid.fig.set_figheight(8)\n\nplt.show()","6567de07":"grid = sns.jointplot(train_df['Rooms'], train_df['Price'], kind='hex')\ngrid.fig.set_figwidth(8)\ngrid.fig.set_figheight(8)\n\nplt.show()","ce433b22":"grid = sns.jointplot(train_df['Square'], train_df['Price'], kind='hex')\ngrid.fig.set_figwidth(8)\ngrid.fig.set_figheight(8)\n\nplt.show()","0c97be61":"plt.figure(figsize = (20,10))\n\nsns.set(font_scale=1.4)\n\nsns.heatmap(train_df.corr(), linecolor='white', linewidths=1, fmt = '.1g', annot=True);","aa3ed4d5":"train_df.isna().sum()","fff509e7":"X = train_df.drop('Price', axis=1)\ny = train_df[['Price']]","c42946e6":"X['DistrictId'] = X['DistrictId'].astype(str)\ntest_df['DistrictId'] = test_df['DistrictId'].astype(str)","64ede0cf":"class DataPreprocessing:\n    \"\"\"\u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432\"\"\"\n    \n    def __init__(self):\n        self.medians=None\n        \n    def fit(self, X):\n        self.medians = X.median()\n    \n    def transform(self, X):\n        \n        # \u043d\u0435\u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n        not_LifeSquare = X['Square'] - X['LifeSquare']\n        \n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        X.loc[(X['Rooms'] >= 6) & (X['LifeSquare'] < 100 ), 'Rooms'] = self.medians['Rooms'] \n        \n         # Square \n        X.loc[(X['Square'] < 10) | (X['Square'] > 500), 'Square'] = self.medians['Square']\n        \n        # KitchenSquare\n        X.loc[(X['KitchenSquare'] < 6) & (X['KitchenSquare'] < (not_LifeSquare - 6)), 'KitchenSquare'] = 6\n        X.loc[(X['KitchenSquare'] < 6) & (X['KitchenSquare'] > not_LifeSquare ), 'KitchenSquare'] = self.medians['KitchenSquare']\n        X.loc[X['KitchenSquare'] > 100, 'KitchenSquare'] = X['KitchenSquare'].max()\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        X.loc[X['Floor'] > X['HouseFloor'], 'Floor'] = X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor']\n\n        # HouseYear\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # Healthcare_1\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n            \n        # LifeSquare\n        X['LifeSquare_nan'] = X['LifeSquare'].isna() * 1\n        \n        condition = (X['LifeSquare'].isna()) &\\\n                      (~X['Square'].isna()) & \\\n                      (~X['KitchenSquare'].isna())\n        \n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] - X.loc[condition, 'KitchenSquare'] - 3\n        \n        X.fillna(self.medians, inplace=True)\n        \n        return X","d5c9ce8f":"class FeatureGenetator():\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447\"\"\"\n    \n    def __init__(self):\n        self.DistrictId_counts = None\n        self.binary_to_numbers = None\n        self.med_price_by_district = None\n        self.med_price_by_floor_year = None\n        self.house_year_max = None\n        self.floor_max = None\n        self.district_size = None\n        \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        # Binary features\n        self.binary_to_numbers = {'A': 0, 'B': 1}\n        \n        # DistrictID\n        self.district_size = X['DistrictId'].value_counts().reset_index() \\\n                               .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n                \n        # Target encoding\n        ## District, Rooms\n        df = X.copy()\n        \n        if y is not None:\n            df['Price'] = y.values\n            \n            self.med_price_by_district = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                                            .rename(columns={'Price':'MedPriceByDistrict'})\n            \n            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()\n            \n        ## floor, year\n        if y is not None:\n            self.floor_max = df['Floor'].max()\n            self.house_year_max = df['HouseYear'].max()\n            df['Price'] = y.values\n            df = self.floor_to_cat(df)\n            df = self.year_to_cat(df)\n            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\n            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()\n        \n\n        \n    def transform(self, X):\n        \n        # Binary features\n        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}\n        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)\n        \n        # DistrictId, IsDistrictLarge\n        X = X.merge(self.district_size, on='DistrictId', how='left')\n        \n        X['new_district'] = 0\n        X.loc[X['DistrictSize'].isna(), 'new_district'] = 1\n        \n        X['DistrictSize'].fillna(5, inplace=True)\n        \n        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)\n        \n        # More categorical features\n        X = self.floor_to_cat(X)  # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 floor_cat\n        X = self.year_to_cat(X)   # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 year_cat\n        \n        # Target encoding\n        if self.med_price_by_district is not None:\n            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\n            X['MedPriceByDistrict'].fillna(self.med_price_by_district_median, inplace=True)\n            \n        if self.med_price_by_floor_year is not None:\n            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\n            X['MedPriceByFloorYear'].fillna(self.med_price_by_floor_year_median, inplace=True)\n        \n        return X\n    \n    def floor_to_cat(self, X):\n        bins = [0, 3, 5, 9, 15, self.floor_max]\n        X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n\n        X['floor_cat'].fillna(-1, inplace=True) \n        return X\n     \n    def year_to_cat(self, X):\n        bins = [0, 1941, 1945, 1980, 2000, 2010, self.house_year_max]\n        X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n\n        X['year_cat'].fillna(-1, inplace=True)\n        return X\n            \n    ","22c1d078":"feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',\n                 'Helthcare_2', 'Shops_1', 'Shops_2']\n\nnew_feature_names = ['Rooms_outlier', 'HouseFloor_outlier', 'HouseYear_outlier', 'LifeSquare_nan', 'DistrictSize',\n                     'new_district', 'IsDistrictLarge',  'MedPriceByDistrict', 'MedPriceByFloorYear']\n\ntarget_name = 'Price'\n","d4cc060f":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\n\nX = train_df.drop(columns=target_name)\ny = train_df[target_name]","6dacdc2b":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=100)","ceadd816":"preprocessor = DataPreprocessing()\npreprocessor.fit(X_train)\n\nX_train = preprocessor.transform(X_train)\nX_valid = preprocessor.transform(X_valid)\ntest_df = preprocessor.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","7c9a9458":"features_gen = FeatureGenetator()\nfeatures_gen.fit(X_train, y_train)\n\nX_train = features_gen.transform(X_train)\nX_valid = features_gen.transform(X_valid)\ntest_df = features_gen.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","9ac06a32":"X_train = X_train[feature_names + new_feature_names]\nX_valid = X_valid[feature_names + new_feature_names]\ntest_df = test_df[feature_names + new_feature_names]\nX_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()","23dab9f6":"gbr = GradientBoostingRegressor(criterion='mse',\n                                        max_depth=6,\n                                        max_features=5,\n                                        min_samples_leaf=70,\n                                        random_state=42,  \n                                        n_estimators=150)\n","cacc4ac2":"gbr.fit(X_train, y_train)","c7c268ad":"y_train_preds = gbr.predict(X_train)\ny_test_preds = gbr.predict(X_valid)\n\nevaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)","de006d92":"feature_importances = pd.DataFrame(zip(X_train.columns, gbr.feature_importances_), \n                                   columns=['feature_name', 'importance'])\n\nfeature_importances.sort_values(by='importance', ascending=False)","04246b6c":"test_df.shape","991d3a8c":"submit = pd.read_csv('..\/input\/coursework\/sample_submission.csv')\nsubmit.head()","e9daa85f":"predictions = gbr.predict(test_df)\npredictions","bb71e074":"submit['Price'] = predictions\nsubmit.head()","907c22c6":"submit.to_csv('rf_submit.csv', index=False)","e4b11fbe":"## \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435","14698437":"## \u0412\u044b\u0432\u043e\u0434 \u043f\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c:\n* \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0432 LifeSquare \u0438 Healthcare_1\n* \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u043f\u043e MIN \u0438 MAX \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c Rooms, Square, LifeSquare, KitchenSquare, HouseFloor, HouseYear\n","3efb556e":"## \u0417\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u043e\u0442 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432.","fca5899c":"### \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043d\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","8706ce5a":"## \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432 \u0438 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432","40f50840":"# EDA","ffa6a51d":"### \u041e\u0442\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","7d0ddd0e":"###  \u0420\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0430 train \u0438 test","c4c3a8a0":"### \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432","e3eb3876":"## \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","f6497807":"\u0413\u0438\u0441\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u0438\u0441\u043a\u043e\u043c\u043e\u0433\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 (price)","74a2b403":"### \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","f634cfca":"## \u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u044f \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u0430\u043c\u044f\u0442\u0438.","0a8b9480":"# Data fields\n* Id - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b\n* DistrictId - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u0440\u0430\u0439\u043e\u043d\u0430\n* Rooms - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442\n* Square - \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n* LifeSquare - \u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n* KitchenSquare - \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043a\u0443\u0445\u043d\u0438\n* Floor - \u044d\u0442\u0430\u0436\n* HouseFloor - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0434\u043e\u043c\u0435\n* HouseYear - \u0433\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0434\u043e\u043c\u0430\n* Ecology_1, Ecology_2, Ecology_3 - \u044d\u043a\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\n* Social_1, Social_2, Social_3 - \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\n* Healthcare_1, Helthcare_2 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043e\u0445\u0440\u0430\u043d\u043e\u0439 \u0437\u0434\u043e\u0440\u043e\u0432\u044c\u044f\n* Shops_1, Shops_2 - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043d\u0430\u043b\u0438\u0447\u0438\u0435\u043c \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u043e\u0432, \u0442\u043e\u0440\u0433\u043e\u0432\u044b\u0445 \u0446\u0435\u043d\u0442\u0440\u043e\u0432\n* Price - \u0446\u0435\u043d\u0430 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b","26d824c5":"## \u0412\u044b\u0432\u043e\u0434 \u043f\u043e \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u043c\u0430\u0442\u0440\u0438\u0446\u0435\n\u041d\u0430 \u043c\u0430\u0442\u0440\u0438\u0446\u0435 \u043f\u043e\u0434\u0442\u0432\u0435\u0440\u0434\u0438\u043b\u0438\u0441\u044c \u0440\u0430\u043d\u0435\u0435 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 Rooms \u0438 Square. \u0422\u0430\u043a \u0436\u0435 \u0432\u044b\u044f\u0432\u0438\u043b\u0430\u0441\u044c \u0441\u043b\u0430\u0431\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u043e\u0442 DistrictId, Social_1 \u0438 Social_2, \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 Healthcare_2.\n\u0415\u0441\u0442\u044c \u044f\u0432\u043d\u0430\u044f \u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f Floor \u0438 HouseFloor.\n\u0425\u043e\u0440\u043e\u0448\u043e \u0432\u0438\u0434\u043d\u0430 \u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f \u0432\u0441\u0435\u0445 Social_1, Social_2, Social_3 \u0438 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044f Healthcare_2 \u043e\u0442 Shops_1.\n\u0415\u0441\u0442\u044c \u0441\u043b\u0430\u0431\u0430\u044f \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u044f  Healthcare_1, Healthcare_2 \u0438 Social_1 \u043e\u0442 DistrictId.","2b81c68f":"## \u0412\u044b\u0432\u043e\u0434 \u043f\u043e \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044f\u043c\n\u0417\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u0446\u0435\u043d\u044b \u043e\u0442 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432:\n* Square;\n* Rooms.\n* \u041d\u0435\u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u0435\u0441\u0442\u044c \u043e\u0442 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 DistrictId.\n \n* \u0423 \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u043d\u0435\u0432\u044b\u0440\u0430\u0436\u0435\u043d\u043d\u0430\u044f.","9072c369":"### \u0412\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432"}}