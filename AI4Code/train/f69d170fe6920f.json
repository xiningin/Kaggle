{"cell_type":{"9f51976f":"code","657dbba5":"code","3a14b657":"code","efe2122f":"code","9c36a3bb":"code","1f83ce64":"code","d988e8e0":"code","9dabb5c9":"code","3ed113bf":"code","41404867":"code","a0b9c864":"code","04e55473":"code","cba91e6f":"code","7728b091":"code","8cd8cdb9":"code","69565cbf":"code","e0b0bafa":"code","f6b1ef5e":"code","5b36982d":"code","0841bf44":"code","773ad5de":"code","ff06e9be":"code","b1e42e10":"code","19ebfc50":"code","cc34db07":"code","f9acf3b2":"code","fbee7424":"code","ee7925e2":"code","c6b2bdb1":"code","996b9a66":"code","3612d9c5":"code","bd1c71bd":"code","d500e0f2":"code","39306bc7":"code","2741b793":"code","cbeeb657":"markdown","7a7581af":"markdown","c12eec99":"markdown"},"source":{"9f51976f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","657dbba5":"translate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\", \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \"scoiattolo\": \"squirrel\", \"dog\": \"cane\", \"cavallo\": \"horse\", \"elephant\" : \"elefante\", \"butterfly\": \"farfalla\", \"chicken\": \"gallina\", \"cat\": \"gatto\", \"cow\": \"mucca\", \"spider\": \"ragno\", \"squirrel\": \"scoiattolo\"}","3a14b657":"translate = dict(zip(list(translate.keys())[:9]+list(translate.values())[9:],list(translate.values())[:9]+list(translate.keys())[9:]))","efe2122f":"translate","9c36a3bb":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageFilter\nimport numpy as np\nimport tqdm.auto as tqdm\nimport kornia","1f83ce64":"data_transforms = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","d988e8e0":"data_dir = '\/kaggle\/input\/skeweddata\/images\/'","9dabb5c9":"image_datasets = datasets.ImageFolder(data_dir,data_transforms)","3ed113bf":"image_datasets.classes = [translate[i] for i in image_datasets.classes]","41404867":"dict(zip(image_datasets.class_to_idx.values(),[translate[i] for i in image_datasets.class_to_idx.keys()]))","a0b9c864":"counts = np.unique(image_datasets.targets,return_counts=True)","04e55473":"df = pd.DataFrame({'name':image_datasets.classes,'count':counts[1]})","cba91e6f":"import plotly.express as px","7728b091":"fig = px.bar(df,x='name',y='count')\nfig.show()","8cd8cdb9":"train, valid = torch.utils.data.random_split(image_datasets,[int(0.8*len(image_datasets)),len(image_datasets)-int(0.8*len(image_datasets))])","69565cbf":"dataloaders = {'train': torch.utils.data.DataLoader(train, batch_size=4,\n                                             shuffle=True, num_workers=4),\n              'val': torch.utils.data.DataLoader(valid, batch_size=4,\n                                             shuffle=True, num_workers=4)}","e0b0bafa":"inputs, classes = next(iter(dataloaders['train']))\n# inputs.to('cuda')","f6b1ef5e":"blur_images = torch.stack([kornia.gaussian_blur2d(inputs[i].view(1,3,224,224),kernel_size=(25,25),sigma=(4,4)).view(3,224,224) for i in range(len(inputs))])","5b36982d":"edge_sharp_img = torch.stack([kornia.sobel(inputs[i].view(1,3,224,224)).view(3,224,224) for i in range(len(inputs))])","0841bf44":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)","773ad5de":"out = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[image_datasets.classes[x] for x in classes])","ff06e9be":"out = torchvision.utils.make_grid(blur_images)\n\nimshow(out, title=[image_datasets.classes[x] for x in classes])","b1e42e10":"out = torchvision.utils.make_grid(edge_sharp_img)\n\nimshow(out, title=[image_datasets.classes[x] for x in classes])","19ebfc50":"class ImageClassifier(nn.Module):\n    def __init__(self):\n        super(ImageClassifier,self).__init__()\n        num_classes=10\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.feature_extractor = models.mobilenet_v2(pretrained=True)\n        self.feature_extractor.classifier[1] = nn.Linear(in_features=self.feature_extractor.classifier[1].in_features,out_features=num_classes)\n#         self.feature_extractor = models.resnet50(pretrained=True)\n#         self.feature_extractor.eval()\n#         self.feature_extractor.fc = nn.Linear(self.feature_extractor.fc.in_features,out_features=num_classes)\n#         self.classifier = nn.Linear(in_features=1000,out_features=num_classes)\n        \n        \n        self.data_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n                                                   transforms.RandomHorizontalFlip(),\n                                                   transforms.ToTensor(),\n                                                   transforms.Normalize([0.485, 0.456, 0.406], \n                                                                         [0.229, 0.224, 0.225])])\n        \n        self.translate = {'cane': 'dog',\n                          'cavallo': 'horse',\n                          'elefante': 'elephant',\n                          'farfalla': 'butterfly',\n                          'gallina': 'chicken',\n                          'gatto': 'cat',\n                          'mucca': 'cow',\n                          'pecora': 'sheep', \n                          'scoiattolo': 'squirrel',\n                          'ragno': 'spider'}\n        \n    def forward(self,x):\n        embeddings = self.feature_extractor(x)\n        x = embeddings\n#         x = self.classifier(embeddings)\n        return x\n    \n    def fit(self,root_dir,num_epochs,batch_size,val_split=0.1,num_workers=4):\n        image_datasets = datasets.ImageFolder(root_dir,self.data_transforms)\n        image_datasets.classes = [self.translate[i] for i in image_datasets.classes]\n        train_size = int((1-val_split)*len(image_datasets))\n        train, valid = torch.utils.data.random_split(image_datasets,[train_size,len(image_datasets)-train_size])\n        dataloaders = {'train': torch.utils.data.DataLoader(train, batch_size=batch_size,\n                                             shuffle=True, num_workers=num_workers),\n                       'val': torch.utils.data.DataLoader(valid, batch_size=batch_size,\n                                             shuffle=True, num_workers=num_workers)}\n        \n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(self.parameters(),lr=0.0001)\n        epoch_bar = tqdm.tqdm(range(num_epochs),desc='Epochs---',position=0)\n        self.train_epoch_loss = []\n        self.val_epoch_loss = []\n        train_acc = 0.\n        val_acc = 0.\n        for epoch in epoch_bar:\n            self.train()\n            pbar = tqdm.tqdm(dataloaders['train'],desc='Epoch= {}'.format(epoch+1),position=1)\n            running_loss = 0.0\n            val_loss = 0.0\n            total = 0\n            correct = 0\n            for inputs, labels in pbar:\n                inputs = inputs.to(self.device)\n                labels = labels.to(self.device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                labels_hat = self(inputs)\n                _, predicted = torch.max(labels_hat.data, 1)\n                loss = criterion(labels_hat,labels)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                pbar.set_postfix(train_run_loss='{:.4f}'.format(loss.item()))\n                running_loss += loss.item()\n                loss.backward()\n                optimizer.step()\n            self.train_epoch_loss.append(running_loss \/ len(dataloaders['train']))\n            train_acc = 100 * correct \/ total\n            epoch_bar.set_postfix(train_acc='{:.4f}'.format(train_acc),val_acc='{:.4f}'.format(val_acc))    \n#             pbar = tqdm.tqdm(dataloaders['val'],desc='Epoch={}, train_epoch_loss= {}'.format(epoch+1,epoch_loss))\n            total = 0\n            correct = 0\n            with torch.no_grad():\n                self.eval()\n                for inputs, labels in dataloaders['val']:\n                    inputs = inputs.to(self.device)\n                    labels = labels.to(self.device)\n                    labels_hat = self(inputs)\n                    _, predicted = torch.max(labels_hat.data, 1)\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n                    loss = criterion(labels_hat,labels)\n                    val_loss += loss.item()\n                self.val_epoch_loss.append(val_loss \/ len(dataloaders['val']))\n                val_acc = 100 * correct \/ total\n                epoch_bar.set_postfix(train_acc='{:.4f}'.format(train_acc),val_acc='{:.4f}'.format(val_acc))\n                \n    def fit_on_blur(self,root_dir,num_epochs,batch_size,val_split=0.1,num_workers=4):\n        image_datasets = datasets.ImageFolder(root_dir,self.data_transforms)\n        image_datasets.classes = [self.translate[i] for i in image_datasets.classes]\n        train_size = int((1-val_split)*len(image_datasets))\n        train, valid = torch.utils.data.random_split(image_datasets,[train_size,len(image_datasets)-train_size])\n        dataloaders = {'train': torch.utils.data.DataLoader(train, batch_size=batch_size,\n                                             shuffle=True, num_workers=num_workers),\n                       'val': torch.utils.data.DataLoader(valid, batch_size=batch_size,\n                                             shuffle=True, num_workers=num_workers)}\n        \n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(self.parameters(),lr=0.0001)\n        epoch_bar = tqdm.tqdm(range(num_epochs),desc='Epochs---',position=0)\n        self.train_epoch_loss = []\n        self.val_epoch_loss = []\n        train_acc = 0.\n        val_acc = 0.\n        for epoch in epoch_bar:\n            self.train()\n            pbar = tqdm.tqdm(dataloaders['train'],desc='Epoch= {}'.format(epoch+1),position=1)\n            running_loss = 0.0\n            val_loss = 0.0\n            total = 0\n            correct = 0\n            for inputs, labels in pbar:\n                inputs = inputs.to(self.device)\n                labels = labels.to(self.device)\n                inputs = torch.stack([kornia.gaussian_blur2d(inputs[i].view(1,3,224,224),kernel_size=(25,25),sigma=(4,4)).view(3,224,224) for i in range(len(inputs))])\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                labels_hat = self(inputs)\n                _, predicted = torch.max(labels_hat.data, 1)\n                loss = criterion(labels_hat,labels)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                pbar.set_postfix(train_run_loss='{:.4f}'.format(loss.item()))\n                running_loss += loss.item()\n                loss.backward()\n                optimizer.step()\n            self.train_epoch_loss.append(running_loss \/ len(dataloaders['train']))\n            train_acc = 100 * correct \/ total\n            epoch_bar.set_postfix(train_acc='{:.4f}'.format(train_acc),val_acc='{:.4f}'.format(val_acc))    \n#             pbar = tqdm.tqdm(dataloaders['val'],desc='Epoch={}, train_epoch_loss= {}'.format(epoch+1,epoch_loss))\n            total = 0\n            correct = 0\n            with torch.no_grad():\n                self.eval()\n                for inputs, labels in dataloaders['val']:\n                    inputs = inputs.to(self.device)\n                    inputs = torch.stack([kornia.gaussian_blur2d(inputs[i].view(1,3,224,224),kernel_size=(25,25),sigma=(4,4)).view(3,224,224) for i in range(len(inputs))])\n                    labels = labels.to(self.device)\n                    labels_hat = self(inputs)\n                    _, predicted = torch.max(labels_hat.data, 1)\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n                    loss = criterion(labels_hat,labels)\n                    val_loss += loss.item()\n                self.val_epoch_loss.append(val_loss \/ len(dataloaders['val']))\n                val_acc = 100 * correct \/ total\n                epoch_bar.set_postfix(train_acc='{:.4f}'.format(train_acc),val_acc='{:.4f}'.format(val_acc))   \n\n    def fit_on_edges(self,root_dir,num_epochs,batch_size,val_split=0.1,num_workers=4):\n        image_datasets = datasets.ImageFolder(root_dir,self.data_transforms)\n        image_datasets.classes = [self.translate[i] for i in image_datasets.classes]\n        train_size = int((1-val_split)*len(image_datasets))\n        train, valid = torch.utils.data.random_split(image_datasets,[train_size,len(image_datasets)-train_size])\n        dataloaders = {'train': torch.utils.data.DataLoader(train, batch_size=batch_size,\n                                             shuffle=True, num_workers=num_workers),\n                       'val': torch.utils.data.DataLoader(valid, batch_size=batch_size,\n                                             shuffle=True, num_workers=num_workers)}\n        \n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.Adam(self.parameters(),lr=0.0001)\n        epoch_bar = tqdm.tqdm(range(num_epochs),desc='Epochs---',position=0)\n        self.train_epoch_loss = []\n        self.val_epoch_loss = []\n        train_acc = 0.\n        val_acc = 0.\n        for epoch in epoch_bar:\n            self.train()\n            pbar = tqdm.tqdm(dataloaders['train'],desc='Epoch= {}'.format(epoch+1),position=1)\n            running_loss = 0.0\n            val_loss = 0.0\n            total = 0\n            correct = 0\n            for inputs, labels in pbar:\n                inputs = inputs.to(self.device)\n                inputs = torch.stack([kornia.sobel(inputs[i].view(1,3,224,224)).view(3,224,224) for i in range(len(inputs))])\n                labels = labels.to(self.device)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n                labels_hat = self(inputs)\n                _, predicted = torch.max(labels_hat.data, 1)\n                loss = criterion(labels_hat,labels)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                pbar.set_postfix(train_run_loss='{:.4f}'.format(loss.item()))\n                running_loss += loss.item()\n                loss.backward()\n                optimizer.step()\n            self.train_epoch_loss.append(running_loss \/ len(dataloaders['train']))\n            train_acc = 100 * correct \/ total\n            epoch_bar.set_postfix(train_acc='{:.4f}'.format(train_acc),val_acc='{:.4f}'.format(val_acc))    \n#             pbar = tqdm.tqdm(dataloaders['val'],desc='Epoch={}, train_epoch_loss= {}'.format(epoch+1,epoch_loss))\n            total = 0\n            correct = 0\n            with torch.no_grad():\n                self.eval()\n                for inputs, labels in dataloaders['val']:\n                    inputs = inputs.to(self.device)\n                    inputs = torch.stack([kornia.sobel(inputs[i].view(1,3,224,224)).view(3,224,224) for i in range(len(inputs))])\n                    labels = labels.to(self.device)\n                    labels_hat = self(inputs)\n                    _, predicted = torch.max(labels_hat.data, 1)\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n                    loss = criterion(labels_hat,labels)\n                    val_loss += loss.item()\n                self.val_epoch_loss.append(val_loss \/ len(dataloaders['val']))\n                val_acc = 100 * correct \/ total\n                epoch_bar.set_postfix(train_acc='{:.4f}'.format(train_acc),val_acc='{:.4f}'.format(val_acc))","cc34db07":"import gc\ngc.collect()","f9acf3b2":"torch.cuda.empty_cache()","fbee7424":"model = ImageClassifier().cuda()","ee7925e2":"model.fit(data_dir,num_epochs=5,batch_size=128,val_split=0.2)","c6b2bdb1":"model.fit_on_blur(data_dir,num_epochs=2,batch_size=128,val_split=0.2)","996b9a66":"model.fit_on_edges(data_dir,num_epochs=2,batch_size=128,val_split=0.2)","3612d9c5":"torch.save(model.state_dict(),'\/kaggle\/working\/weights')","bd1c71bd":"model.load_state_dict(torch.load('\/kaggle\/working\/weights'))","d500e0f2":"model.eval()","39306bc7":"def get_prediction(image_bytes):\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    tensor = data_transforms(image_bytes).view(1,3,224,224).to(device)\n    outputs = model.forward(tensor)\n    prob, y_hat = torch.topk(outputs,k=5)\n    return y_hat, prob","2741b793":"%timeit get_prediction(Image.open('..\/input\/skeweddata\/images\/scoiattolo\/0.jpg'))","cbeeb657":"**Normal ----- epoch = 1\/1 [01:18<00:00, 78.01s\/it, train_acc=82.9698, val_acc=90.8926]**","7a7581af":"On blur = epoch=1\/1 [05:12<00:00, 312.41s\/it, train_acc=81.4602, val_acc=84.7940]","c12eec99":"On edges = epochs = 1\/1 [01:28<00:00, 88.01s\/it, train_acc=82.0913, val_acc=85.7431]"}}