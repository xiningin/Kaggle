{"cell_type":{"ab436720":"code","9dd755b5":"code","1517bb5a":"code","b8d16a60":"code","6ec0c841":"code","8797a04f":"code","2766013b":"code","ade2209c":"code","90da25c0":"code","3afcb89a":"code","d6e8a6a0":"code","58745405":"code","eb734662":"code","69430726":"code","da43613c":"code","c811cfb9":"code","d4e870c7":"code","da8c37b1":"code","d2da65d1":"code","71456cc1":"code","7ffab8a5":"code","0f2a9b8b":"code","88fa1e69":"code","1dda94e0":"code","680aa21f":"code","b34f0322":"code","038b2475":"code","02824219":"code","fb7dd038":"code","d2d7e5de":"code","5e7e44d9":"code","efca74f7":"code","5a9cb2ab":"code","aeb76bf1":"code","1fb9659c":"code","b74c1dcb":"code","de5d05db":"code","ba4830af":"code","babc7522":"code","dd12f19a":"code","28460a31":"code","445ed0c3":"code","49c90dfd":"code","82dd98f1":"code","0b02d989":"code","378ddb13":"code","dec59589":"code","63256493":"code","dad1c54a":"code","afa1e2b2":"code","d77769e9":"code","a2464ff1":"code","a02f025b":"code","36fe647f":"code","910d289a":"code","47b6755a":"code","5a28f6db":"code","1ed16efb":"code","22fc7992":"code","e4b4c555":"code","7c9b3873":"code","91f9e853":"code","717acfb5":"code","8a90e1c7":"code","b8e1812f":"code","4714ec62":"code","40675286":"code","f8b4b36d":"code","10dac34f":"code","b2daf1fb":"code","f9986a4d":"code","3333a903":"code","ae53dcc3":"code","7e9d939c":"code","2685cc4a":"markdown","5153f32e":"markdown","ea0b4def":"markdown","fb01d743":"markdown","2019dc35":"markdown","bb37cf34":"markdown","f04fba20":"markdown","9f1bfaf2":"markdown","763a9518":"markdown","3b50360a":"markdown","78b403ca":"markdown","dc2289ff":"markdown","cd0cfee9":"markdown","f7865bf8":"markdown","1d60f8ab":"markdown","effac3ce":"markdown","7469f2b2":"markdown"},"source":{"ab436720":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime as dt\n\nimport warnings\nwarnings.filterwarnings('ignore')","9dd755b5":"!pip install openpyxl","1517bb5a":"train_data = pd.read_excel(\"..\/input\/flight-fare-prediction-mh\/Data_Train.xlsx\")","b8d16a60":"pd.set_option('display.max_columns', None)","6ec0c841":"train_data.head()","8797a04f":"train_data.info()","2766013b":"# check if count of null values which are present\ntrain_data.isnull().sum()","ade2209c":"# there is only 2 null values so we drop this values\ntrain_data.dropna(inplace=True)","90da25c0":"# recheck after handling null values \ntrain_data.isnull().sum()","3afcb89a":"# Date_of_Journey column is of object type first convert it into datetime \n# then create day and month column and detele Date_of_Journey column\ntrain_data['Journey_day'] = pd.to_datetime(train_data['Date_of_Journey'],format='%d\/%m\/%Y').dt.day\ntrain_data['Journey_month'] = pd.to_datetime(train_data['Date_of_Journey'],format='%d\/%m\/%Y').dt.month\n\ntrain_data.drop(['Date_of_Journey'],axis=1,inplace=True)\ntrain_data.head()","d6e8a6a0":"train_data[['Route','Total_Stops','Additional_Info']]","58745405":"# we can see that Route and Total_Stops are releated to each other so we use Total_Stops\n# Additional_info does not conten required data\/ there is no info so we drop it\ntrain_data.drop(['Route','Additional_Info'],axis=1,inplace=True)\ntrain_data.head()","eb734662":"train_data[['Dep_Time','Arrival_Time','Duration']].head()","69430726":"# Create new columns for min and hour\n\n# for Dep_Time\n\ntrain_data['Dep_Hour'] = pd.to_datetime(train_data.Dep_Time).dt.hour\ntrain_data['Dep_Min'] = pd.to_datetime(train_data.Dep_Time).dt.minute\n\n# for Arrival_Time\ntrain_data['Arrival_Hour'] = pd.to_datetime(train_data.Arrival_Time).dt.hour\ntrain_data['Arrival_Min'] = pd.to_datetime(train_data.Arrival_Time).dt.minute\n\n#drop 'Arrival_Time','Dep_Time'\ntrain_data.drop(['Arrival_Time','Dep_Time'],axis=1,inplace=True)\n\ntrain_data.head()","da43613c":"# train_data['Journey_day'] = pd.to_datetime(train_data['Date_of_Journey'],format='%d\/%m\/%Y').dt.day\n# train_data['Journey_month'] = pd.to_datetime(train_data['Date_of_Journey'],format='%d\/%m\/%Y').dt.month\n\n# train_data['Dep_Hour'] = pd.to_datetime(train_data.Dep_Time).dt.hour\n# train_data['Dep_Min'] = pd.to_datetime(train_data.Dep_Time).dt.minute\n\n# # for Arrival_Time\n# train_data['Arrival_Hour'] = pd.to_datetime(train_data.Arrival_Time).dt.hour\n# train_data['Arrival_Min'] = pd.to_datetime(train_data.Arrival_Time).dt.minute\n\n\nduration = list(train_data.Duration)\nfor i in range(len(duration)):\n    if len(duration[i].split())!=2:\n        if 'h' in duration[i]:\n            duration[i] = duration[i] + ' 0m'\n        else:\n            duration[i] = '0h '+ duration[i]\n\n\n# Extract hour and minute and create new column\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))\n    \ntrain_data[\"duration_hours\"] = duration_hours\ntrain_data[\"duration_mins\"] = duration_mins\n\ntrain_data.drop('Duration',axis=1,inplace=True)\ntrain_data.head()","c811cfb9":"train_data['Airline'].value_counts()","d4e870c7":"plt.figure(figsize=(14,6))\nplt.xticks(rotation=90)\nsns.boxplot(y = \"Price\", x = \"Airline\", data = train_data.sort_values(\"Price\", ascending = False))\n","da8c37b1":"Airline = train_data[['Airline']]\nAirline = pd.get_dummies(Airline,drop_first=True)\nAirline","d2da65d1":"plt.figure(figsize=(14,6))\nplt.xticks(rotation=90)\nsns.boxplot(y = \"Price\", x = \"Source\", data = train_data.sort_values(\"Price\", ascending = False))\n","71456cc1":"Source = train_data[['Source']]\nSource = pd.get_dummies(Source,drop_first=True)\nSource","7ffab8a5":"plt.figure(figsize=(14,6))\nplt.xticks(rotation=90)\nsns.boxplot(y = \"Price\", x = \"Destination\", data = train_data.sort_values(\"Price\", ascending = False))\n","0f2a9b8b":"Destination = train_data[['Destination']]\nDestination = pd.get_dummies(Destination,drop_first=True)\nDestination","88fa1e69":"train_data[\"Total_Stops\"].value_counts()","1dda94e0":"# It an label data so we perform label encoding here\ntrain_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)","680aa21f":"train_data.head()","b34f0322":"trained_data = pd.concat([train_data,Airline,Source,Destination],axis=1)\ntrained_data.drop(['Airline','Source','Destination'],axis=1,inplace=True)\ntrained_data.head()","038b2475":"trained_data.shape","02824219":"test_data = pd.read_excel(\"..\/input\/flight-fare-prediction-mh\/Test_set.xlsx\")\ntest_data.head()","fb7dd038":"test_data.dropna(inplace=True)\n\ntest_data['Journey_day'] = pd.to_datetime(test_data['Date_of_Journey'],format='%d\/%m\/%Y').dt.day\ntest_data['Journey_month'] = pd.to_datetime(test_data['Date_of_Journey'],format='%d\/%m\/%Y').dt.month\n\ntest_data['Dep_Hour'] = pd.to_datetime(test_data.Dep_Time).dt.hour\ntest_data['Dep_Min'] = pd.to_datetime(test_data.Dep_Time).dt.minute\n\n# for Arrival_Time\ntest_data['Arrival_Hour'] = pd.to_datetime(test_data.Arrival_Time).dt.hour\ntest_data['Arrival_Min'] = pd.to_datetime(test_data.Arrival_Time).dt.minute\n\n\nduration = list(test_data.Duration)\nfor i in range(len(duration)):\n    if len(duration[i].split())!=2:\n        if 'h' in duration[i]:\n            duration[i] = duration[i] + ' 0m'\n        else:\n            duration[i] = '0h '+ duration[i]\n\n# Extract hour and minute and create new column\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))\n    \ntest_data[\"duration_hours\"] = duration_hours\ntest_data[\"duration_mins\"] = duration_mins\n\ntest_data.head()\n\nAirline = test_data[['Airline']]\nAirline = pd.get_dummies(Airline,drop_first=True)\nAirline\n\nSource = test_data[['Source']]\nSource = pd.get_dummies(Source,drop_first=True)\nSource\n\nDestination = test_data[['Destination']]\nDestination = pd.get_dummies(Destination,drop_first=True)\nDestination\n\ntest_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n\ntested_data = pd.concat([test_data,Airline,Source,Destination],axis=1)\ntested_data.drop(['Airline', 'Date_of_Journey', 'Source', 'Destination','Duration' ,'Route','Additional_Info','Dep_Time','Arrival_Time'],axis=1,inplace=True)\n\ntested_data.head()","d2d7e5de":"len(trained_data.columns), len(tested_data.columns)","5e7e44d9":"X = trained_data.drop('Price',axis=1)","efca74f7":"y = trained_data['Price']","5a9cb2ab":"X.shape , y.shape","aeb76bf1":"plt.figure(figsize = (18,18))\nsns.heatmap(trained_data.corr(), annot = True, cmap = \"RdYlGn\")\nplt.show()","1fb9659c":"# non of feature is highlt correlated so we are not going to remove any feature","b74c1dcb":"from sklearn.feature_selection import mutual_info_classif","de5d05db":"X","ba4830af":"FS = pd.DataFrame(mutual_info_classif(X,y),index=X.columns)\nFS.columns=['Importance']\nFS.sort_values(by='Importance',ascending=False)\nFS","babc7522":"# Important feature using ExtraTreesRegressor\n\nfrom sklearn.ensemble import ExtraTreesRegressor\nselection = ExtraTreesRegressor()\nselection.fit(X, y)","dd12f19a":"print(selection.feature_importances_)","28460a31":"#plot graph of feature importances for better visualization\n\nplt.figure(figsize = (12,8))\nfeat_importances = pd.Series(selection.feature_importances_, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()","445ed0c3":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","49c90dfd":"X_train.shape,y_train.shape","82dd98f1":"X_test.shape,y_test.shape","0b02d989":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn import metrics\nreg_rf = RandomForestRegressor()\nreg_rf.fit(X_train, y_train)","378ddb13":"y_pred = reg_rf.predict(X_test)","dec59589":"reg_rf.score(X_train, y_train)","63256493":"reg_rf.score(X_test, y_test)","dad1c54a":"sns.distplot(y_test-y_pred)\nplt.show()","afa1e2b2":"print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","d77769e9":"metrics.r2_score(y_test, y_pred)","a2464ff1":"from sklearn.model_selection import RandomizedSearchCV","a02f025b":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","36fe647f":"# Create the random grid\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}","910d289a":"# Random search of parameters, using 5 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)","47b6755a":"rf_random.fit(X_train,y_train)","5a28f6db":"rf_random.best_params_","1ed16efb":"prediction = rf_random.predict(X_test)","22fc7992":"plt.figure(figsize = (8,8))\nsns.distplot(y_test-prediction)\nplt.show()","e4b4c555":"plt.figure(figsize = (8,8))\nplt.scatter(y_test, prediction, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_pred\")\nplt.show()","7c9b3873":"print('MAE:', metrics.mean_absolute_error(y_test, prediction))\nprint('MSE:', metrics.mean_squared_error(y_test, prediction))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))","91f9e853":"import pickle\n# open a file, where you ant to store the data\nfile = open('flight_rf.pkl', 'wb')\n\n# dump information to that file\npickle.dump(reg_rf, file)","717acfb5":"model = open('flight_rf.pkl','rb')\nforest = pickle.load(model)","8a90e1c7":"y_prediction = forest.predict(X_test)","b8e1812f":"metrics.r2_score(y_test, y_prediction)","4714ec62":"for i in trained_data.columns:\n    if i not in tested_data.columns:\n        print(i)","40675286":"(tested_data.shape)","f8b4b36d":"[0]*10","10dac34f":"df = tested_data.assign(profit=[0]*len(tested_data))\ndf.shape","b2daf1fb":"y_pred = forest.predict(df)\ny_pred = [round(i) for i in y_pred]","f9986a4d":"sample_submission_data = pd.read_excel(\"..\/input\/flight-fare-prediction-mh\/Sample_submission.xlsx\")","3333a903":"metrics.r2_score(sample_submission_data,y_pred)","ae53dcc3":"metrics.explained_variance_score(sample_submission_data,y_pred)","7e9d939c":"pd.DataFrame({'Price':y_pred}).to_csv(\"Submition.csv\")","2685cc4a":"### Data Gathering\n\n\n- Since data is in form of excel file we have to use pandas read_excel to load the data\n- After loading data it is important to check the complete information of data ","5153f32e":"## Save the model to reuse it again","ea0b4def":"## EDA","fb01d743":"<h1 align='center'> Flight Price Prediction\n   \n------\n    \n![flight](https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2021\/04\/25317plane.jpg)","2019dc35":"<h3 align='right'> Thank you","bb37cf34":"### Data Cleaning\n\n- Check whether any null values are there or not. \n- If it is present then following can be done,\n    1. Imputing data using Imputation method in sklearn\n    2. Filling NaN values with mean, median and mode using fillna() method\n- Describe data --> which can give statistical analysis","f04fba20":"## Training Data","9f1bfaf2":"#### - Date Columns ","763a9518":"## Testing data","3b50360a":"- #### 'Route','Total_Stops','Additional_Info' columns","78b403ca":"## Feature Selection","dc2289ff":"## Hyperparameter Tuning\n\n\n* Choose following method for hyperparameter tuning\n    1. **RandomizedSearchCV** --> Fast\n    2. **GridSearchCV**\n* Assign hyperparameters in form of dictionery\n* Fit the model\n* Check best paramters and best score","cd0cfee9":"#### - Work on Categorical Data","f7865bf8":"#### - Time Columns","1d60f8ab":"## Model Fitting","effac3ce":"- ### Ramdom Forest","7469f2b2":"## Import required libraries"}}