{"cell_type":{"ee8c427e":"code","70424776":"code","723ade6a":"code","68f5af76":"code","0530e770":"code","017b3892":"code","b4e5a198":"code","edd3656a":"code","1352e6b1":"code","dc92cc3f":"code","7ef88567":"code","2119c640":"code","daf24c45":"code","048f137b":"code","10397bed":"code","2263daff":"code","26084006":"code","4e58ac71":"code","60a81127":"code","2e343e2c":"code","ed5ee56f":"code","ad389ede":"code","6cd03a7a":"code","dc8adcdb":"code","f8c5e085":"markdown","1a3847e3":"markdown","c3363475":"markdown","74b148e1":"markdown","0fe28bc1":"markdown","1b78bc8d":"markdown","d2a49584":"markdown","4a1d4582":"markdown","a11d640b":"markdown","b564e551":"markdown","7b9fe0b3":"markdown","b7c0e012":"markdown"},"source":{"ee8c427e":"import numpy as np # linear algebra \nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import timedelta\nimport os, sys, gc, warnings, random, datetime\nimport hashlib\nimport matplotlib.pyplot as plt\nimport os\nimport gc\n\"\"\"\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n# Any results you write to the current directory are saved as output.","70424776":"pd.options.display.max_rows = 500\npd.options.display.max_columns = 100","723ade6a":"train = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv')\ntrain_ind = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv')\ntest = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv')\ntest_ind = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv')","68f5af76":"#train = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv')\ntrain_len = len(train)\n#del train\n#gc.collect()","0530e770":"train = train.merge(train_ind, how = 'left', on ='TransactionID' )\ntest = test.merge(test_ind, how = 'left', on ='TransactionID' )\ndel train_ind,test_ind","017b3892":"all_data = pd.concat([train, test])\ndel train,test\ngc.collect()","b4e5a198":"START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\nall_data['DT_time'] = all_data['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\nall_data['count'] = 1\nall_data['diff_days_from_first_transaction'] = all_data['D1'].fillna(0).apply(lambda x: (datetime.timedelta(days = x)))\nall_data['client_firstdate'] = all_data['DT_time']- all_data['diff_days_from_first_transaction']\nall_data['client_firstdate_days'] = (all_data['DT_time']- all_data['diff_days_from_first_transaction']).apply(lambda x:str(x.date()))","edd3656a":"all_data[['DT_time','diff_days_from_first_transaction','client_firstdate_days','D1']].head()","1352e6b1":"anaysis_fea = [ 'TransactionID',\n 'isFraud',\n 'TransactionDT',\n 'TransactionAmt',\n 'ProductCD',\n 'device_hash','card_hash', 'V307','id_30','id_31','id_32','id_33','DeviceType','DeviceInfo',\n 'card1','card2','card3','card4','card5','card6','client_firstdate_days','dist1','dist2','P_emaildomain','addr1','addr2','train_or_test','count','DT_time','diff_days_from_first_transaction','client_firstdate']\n#anaysis_fea+['M'+str(i+1) for i in range(9)]\ndrop_fea = [col for col in all_data.columns if col not in anaysis_fea]","dc92cc3f":"all_data = all_data.drop(drop_fea,axis=1)","7ef88567":"gc.collect()","2119c640":"def card_info_hash(x):\n    s = (str(int(x['card1']))+\n         str(int(x['card2']))+\n         str(int(x['card3']))+\n         str(x['card4'])+\n         str(int(x['card5']))+\n         str(x['card6']))\n    h = hashlib.sha256(s.encode('utf-8')).hexdigest()[0:15]\n    return h","daf24c45":"all_data['card1'] = all_data['card1'].fillna(0)\nall_data['card2'] = all_data['card2'].fillna(0)\nall_data['card3'] = all_data['card3'].fillna(0)\nall_data['card5'] = all_data['card5'].fillna(0)\nall_data['card4'] = all_data['card4'].fillna('nan')\nall_data['card6'] = all_data['card6'].fillna('nan')","048f137b":"all_data['card_hash'] = all_data.apply(lambda x: card_info_hash(x), axis=1)","10397bed":"def get_data_by_card_hash( data, card_hash):\n    mask = data['card_hash']==card_hash\n    return data.loc[mask,:].copy()\n\n\ndef get_data_by_device_hash( data, device_hash):\n    mask = data['device_hash']==device_hash\n    return data.loc[mask,:].copy()\n\n\ndef get_data_by_card_and_startdate( data, card_hash, device_hash):\n    mask = (data['client_firstdate_days']==card_hash) &(data['card_hash']==device_hash)\n    return data.loc[mask,:].copy()","2263daff":"all_data['count']=1\ngrp = all_data.iloc[:train_len].groupby(['client_firstdate_days','card_hash'])['count'].agg('sum')\n#Let us display the count >10 client \ndisplay_group = get_data_by_card_and_startdate(all_data,grp[grp>10].index[0][0],grp[grp>10].index[0][1])\ndisplay_group[['DT_time','TransactionAmt','V307','id_30','id_31','id_32','id_33','DeviceType','DeviceInfo','dist1','dist2','P_emaildomain']]","26084006":"s = all_data.iloc[:train_len].groupby(['client_firstdate_days','card_hash'])['isFraud'].agg(['mean', 'count'])","4e58ac71":"s.head()","60a81127":"from tqdm import tqdm\nTest_ID=[]\nfor ind in tqdm(s[(s['mean']==1)].index):\n    very_strange_thing = get_data_by_card_and_startdate(all_data, ind[0],ind[1])\n    Test_ID.extend(very_strange_thing[very_strange_thing['isFraud'].isna()]['TransactionID'].tolist())","2e343e2c":"Test_ID[:20]","ed5ee56f":"submit = pd.read_csv('..\/input\/rank-blend\/easy_blend4.csv')","ad389ede":"mask = submit['TransactionID'].isin(Test_ID)\nsubmit.loc[mask,'isFraud'] =1","6cd03a7a":"submit.loc[mask,:]","dc8adcdb":"submit.to_csv('submit_try.csv',index = False)","f8c5e085":"### Set those client as Fraud client","1a3847e3":"### Merge ID to original training data","c3363475":"### Read Data","74b148e1":"### Remove no need feature","0fe28bc1":"# Find unique client by using D1 and Card information\n\nI joined this competition two weeka ago, and try to [find the good teammate](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/109873#latest-632441), Finally team up with @[Nanashi](https:\/\/www.kaggle.com\/jesucristo), very great team work experience with him.\n\n## EDA on first week\nBecause we don't have feature, I foucs on EDA, base on Konstantin's feature on this great kernel,and try some FE\n* https:\/\/www.kaggle.com\/kyakovlev\/ieee-simple-lgbm\n* Generate some new feature, single LGBM model, LB 0.9485 to 0.9504\n\n## Below is the leak that we find, implemnt it on submit file, boost ~ 0.002 score \n### [Reference kernel](https:\/\/www.kaggle.com\/alexanderzv\/find-unique-clients)","1b78bc8d":"### D1 meaning (days from the first transaction of each client)\n* https:\/\/www.kaggle.com\/akasyanama13\/eda-what-s-behind-d-features\n\nAs my experimence of time series base data analysis, time correlate feature is the important information, I read this great kernel and I realize the D1 meaning, using D1 and try to find client information.","d2a49584":"### What we found \n* You can see the V307 means the \"cumulative sum of amounts\", I don't think it's coincidence.\n* So I think that \"Same start date\" and \"same Card information\" would be the unique client \n* Then we can use this information to featch more things and create more features.","4a1d4582":"### Find the client that all Fraud\n* Base on AirmH's [discussion](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/109455) here.\n* Once we can find the unique client, and if the client alwasy fraud, and the client also in the test set, then we can just set them to isFraus=1","a11d640b":"## Groupby start_date and unique card to find the unique client","b564e551":"## Conclusion\n* I found this at last 4 hours, and boost our ensemble model to silver zone, it's the key that we can get the silver.\n* I wish I have more time to use this information to create mroe feature and imporve model.\n* It's really fun and interest competition, I am very regret that I didn't join this competition early.\n* Congrats to all winners! Happy kagglers!","7b9fe0b3":"### Get those client in Test set, and record the Transaction ID","b7c0e012":"### Functions that will help us find unique cards."}}