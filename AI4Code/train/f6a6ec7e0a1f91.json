{"cell_type":{"1d19a66e":"code","3e2be10f":"code","1a089a04":"code","a40e41c4":"code","c7f8459c":"code","50bb1124":"code","87487069":"code","802c2b23":"code","ace55b22":"code","66ca1005":"code","ca4d3c75":"code","970b3fb7":"code","f56d0e3e":"code","9cbd91cf":"code","e3d97ad9":"markdown","f1adbb7b":"markdown","84df346c":"markdown"},"source":{"1d19a66e":"import numpy as np\nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport pandas as pd\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import *","3e2be10f":"train_df = pd.read_csv(\"..\/input\/tweet-sentiment-extraction\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/tweet-sentiment-extraction\/test.csv\")\nsubmission_df = pd.read_csv(\"..\/input\/tweet-sentiment-extraction\/sample_submission.csv\")","1a089a04":"train_df['text'] = train_df['text'].str.lower()\ntest_df['text'] = test_df['text'].str.lower()\ntrain_df['selected_text'] = train_df['selected_text'].str.lower()","a40e41c4":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\ndef evaluation(actual_list, pred_list):\n    score = 0\n    for (actual, pred) in zip(actual_list, pred_list):\n        score += jaccard(actual, pred)\n    return score \/ len(pred)","c7f8459c":"lm = WordNetLemmatizer()","50bb1124":"def Remove_Special_Char(text):\n    text = re.sub('[-=+,#\/\\?:^$.@*\\\"\u203b~&%\u318d!\u300f\\\\\u2018|\\(\\)\\[\\]\\<\\>`\\'\u2026\u300b]', '', text) \n    return text","87487069":"# remove special characters from selected text \ntrain_df['selected_text'] = train_df['selected_text'].astype(str).apply(Remove_Special_Char)\nsentiment_value_counts = train_df['sentiment'].value_counts()\n\n# initialize sentiment score dictionary\nsentiment_score = {'neutral': dict(), \n                  'positive': dict(),\n                  'negative': dict()}\n\n# generate selected text corpus\nselected_text_corpus = train_df['selected_text'].values.flatten()\nselected_text_corpus = np.array(selected_text_corpus, dtype = str)\nselected_text_corpus = ' '.join(selected_text_corpus)\n\nfor selected_text, sentiment in zip(train_df['selected_text'], train_df['sentiment']):\n    word_list_in_selected_text = word_tokenize(selected_text)    \n    for word in word_list_in_selected_text:\n        lemmatized_word = lm.lemmatize(word)\n        if lemmatized_word in sentiment_score[sentiment].keys():\n            sentiment_score[sentiment][lemmatized_word] += 1\n        else:\n            sentiment_score[sentiment][lemmatized_word] = 1\n                \nfor sentiment in sentiment_score.keys():\n    expected_value = sentiment_value_counts[sentiment] \/ sum(sentiment_value_counts)\n    for word in sentiment_score[sentiment].keys():\n        word_frequency = sentiment_score['positive'].get(word, 0) + sentiment_score['neutral'].get(word, 0) + sentiment_score['negative'].get(word, 0)\n        actual_value = sentiment_score[sentiment][word] \/ word_frequency\n        sentiment_score[sentiment][word] = actual_value - expected_value","802c2b23":"train_df['text'] = train_df['text'].astype(str).apply(Remove_Special_Char)\ntrain_df['selected_text'] = train_df['selected_text'].astype(str).apply(Remove_Special_Char)\n\ntrain_df['tokend_text'] = train_df['text'].apply(word_tokenize)\ntrain_df['tokend_selected_text'] = train_df['selected_text'].apply(word_tokenize)","ace55b22":"def find_neighbor(t, window_size):\n    T = np.arange(0, 100)\n    return np.argsort(np.abs(T - t))[:window_size]","66ca1005":"def generate_dataset(df, window_size):\n    X = []; Y = []\n    for tokend_text, tokend_selected_text, sentiment in zip(df['tokend_text'], df['tokend_selected_text'], df['sentiment']):\n        try:\n            s, e = [(i, i+len(tokend_selected_text)) for i in range(len(tokend_text)) if tokend_text[i:i+len(tokend_selected_text)] == tokend_selected_text][0] #s: start point of tokend_selected_text in tokend_text \/\/ e: end point of tokend_selected_text in tokend_text\n        except:\n            s, e = (0, 0)\n        y = [0] * s + [1] * (e-s) + [0] * (len(tokend_text) - e)\n        x = []\n        for word in tokend_text:\n            lemmatized_word = lm.lemmatize(word)\n            x.append(sentiment_score[sentiment].get(word, 0))        \n        \n        x = np.array(x)\n        y = np.array(y)\n        for t in range(len(x)):            \n            neighbor = find_neighbor(t, window_size)\n            try:\n                X.append(x[neighbor])\n                Y.append(y[t])\n            except:\n                pass\n\n    return X, Y","ca4d3c75":"X, Y = generate_dataset(df = train_df, window_size = 3)\nmodel = SVC(kernel = 'linear').fit(X, Y)","970b3fb7":"def make_prediction(test_df, model, window_size):\n    test_df['text'] = test_df['text'].astype(str).apply(Remove_Special_Char)\n    test_df['tokend_text'] = test_df['text'].apply(word_tokenize)\n    result = []\n    for tokend_text, sentiment in zip(test_df['tokend_text'], test_df['sentiment']):\n        x = []\n        for word in tokend_text:\n            lemmatized_word = lm.lemmatize(word)\n            x.append(sentiment_score[sentiment].get(word, 0))\n\n        X = []\n        x = np.array(x)\n        for t in range(len(x)):            \n            neighbor = find_neighbor(t, window_size)\n            try:\n                X.append(x[neighbor])\n            except:\n                pass        \n        \n        try:\n            pred_Y = model.predict(X)\n            pred_sentence = ''\n            for (word, y) in zip(tokend_text, pred_Y):\n                if y == 1:\n                    pred_sentence += word + ' '            \n            while pred_sentence[-1] == ' ':\n                pred_sentence = pred_sentence[:-1]\n            result.append(pred_sentence)\n        except:\n            result.append('')\n    \n    return result","f56d0e3e":"result = make_prediction(test_df, model, window_size = 3)","9cbd91cf":"submission_df['selected_text'] = result\nsubmission_df.to_csv('submission.csv', index=False)","e3d97ad9":"# Make sentiment score dictionary","f1adbb7b":"# Problem Definition\nProblem is to find start point s, and end point of a document, where selected document is document[s:e]\n\n\n\n\n","84df346c":"# Preparation\nImporting module and data"}}