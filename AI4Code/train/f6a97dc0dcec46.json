{"cell_type":{"6e6a9f73":"code","f2844d91":"code","5f4f3884":"code","a4012132":"code","f4856302":"code","08d484ba":"code","71e4c115":"code","ed594651":"code","a44c33b5":"code","985ac0bb":"code","b49a00fe":"code","ced117bc":"code","ccb56b2f":"code","4d033608":"code","22de6b0c":"markdown","8ca61c5e":"markdown","406e94ab":"markdown","07a2d2d6":"markdown","87f2147c":"markdown","c5dfac61":"markdown","1b50cde3":"markdown","068d7682":"markdown","daf49d07":"markdown"},"source":{"6e6a9f73":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport gc\nfrom tqdm import tqdm\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt","f2844d91":"#read each stock id pq file and store as dataframe  \ndef read_data(path):\n    trade = pd.read_parquet(path)\n    return trade\n\ndef RMSPE(y_true, y_pred):\n    loss = np.sqrt(np.mean(np.square(((y_true - y_pred) \/ y_true)), axis=0))\n    return loss\n\ndef WAP1(df):\n    WAP = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * \n           df['bid_size1'])\/(df['bid_size1'] + df['ask_size1'])\n    return WAP\n\ndef WAP2(df):\n    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * \n           df['bid_size2'])\/(df['bid_size2'] + df['ask_size2'])\n    return wap\n\ndef log_return(WAP):\n    return np.log(WAP).diff() \n\ndef realized_volatility(log_r):\n    return np.sqrt((log_r**2).sum())\n\n#book features\ndef consol_book_df(path):\n\n    #read stock pq file\n    df = read_data(path)\n    \n    #add stock-id column\n    df['stock_id'] = int(path.split(\"=\")[1]) #extract stock id by removing directory\n    \n    #Spread\n    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) \/ ((df['ask_price1'] + df['bid_price1'])\/2)\n    df['bid_spread'] = abs(df['bid_price1'] - df['bid_price2'])\n    df['ask_spread'] = abs(df['ask_price1'] - df['ask_price2'])\n    \n    #Volume features\n    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n    \n    #WAP\n    df['WAP1'] = WAP1(df)\n    df['WAP2'] = WAP2(df)\n    \n    #log return\n    df['book_log_ret1'] = df.groupby('time_id')['WAP1'].apply(log_return).fillna(0)\n    df['book_log_ret2'] = df.groupby('time_id')['WAP2'].apply(log_return).fillna(0)\n    \n    #Volume features\n    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n    \n    #Book features\n    final_book = df.groupby(['stock_id', 'time_id']).agg(\n                                              real_vol_1 =('book_log_ret1', realized_volatility),\n                                              real_vol_2 = ('book_log_ret2', realized_volatility),\n                                              price_spread_mean = ('price_spread', 'mean'),           \n                                              bid_spread = ('bid_spread', 'mean'),\n                                              ask_spread = ('ask_spread', 'mean'),\n                                              total_vol_mean = ('total_volume', 'mean'),\n                                              vol_imbal_mean = ('volume_imbalance', 'mean')).reset_index()\n    return final_book\n\n#Trade features\ndef consol_trade_df(path):\n    \n    #read stock pq file\n    df = read_data(path)\n    \n    #add stock-id column\n    df['stock_id'] = int(path.split(\"=\")[1])  #extract stock id by removing directory\n    \n    #trade log return\n    df['trade_log_ret'] = df.groupby('time_id')['price'].apply(log_return).fillna(0)\n    \n    #position size = price * size\n    df['position_size'] = df['price']*df['size']\n    \n    #average order size\n    df['average_ord_size'] = df['size']\/df['order_count']\n    \n    #Trade features\n    final_trade = df.groupby(['time_id', 'stock_id']).agg(\n                                                     total_size = ('size', 'sum'),\n                                                     position_size_mean = ('position_size', 'mean'),\n                                                     avg_ord_size_mean = ('average_ord_size', 'mean'),\n                                                     mean_order = ('order_count', 'mean'),\n                                                     max_sec_in_bucket = ('seconds_in_bucket', 'max'), \n                                                     min_sec_in_bucket = ('seconds_in_bucket', 'min'),\n                                                     real_vol_trade=('trade_log_ret', realized_volatility)).reset_index()\n\n    return final_trade\n\n","5f4f3884":"def create_dataSet(df, book_paths, trade_paths):\n    final_df = pd.DataFrame()\n    for book_path, trade_path in tqdm(zip(book_paths, trade_paths)):\n        book = consol_book_df(book_path)\n        trade = consol_trade_df(trade_path)\n        merged_df = (pd.merge(book, trade, on=['stock_id', 'time_id'], how='left')\n                     .merge(df, on=['stock_id', 'time_id'], how='left'))\n        final_df = pd.concat([final_df, merged_df])\n        gc.collect()\n    return final_df ","a4012132":"order_book_training = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')\ntrade_training = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/*')\ntrain_df = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\n\ntrain_set = create_dataSet(train_df, order_book_training, trade_training)","f4856302":"#check rows for nans\ntrain_set_final = train_set.replace([np.inf,-np.inf],np.nan).dropna()\ntrain_set_final[train_set_final.isnull().any(axis=1)]\n\n#prepare X and y\nX = train_set_final.loc[ : , train_set.columns != 'target']\n\n#remove id coluimns\ndel X['time_id']\n\ny = train_set_final['target']\n\nmodel = LinearRegression().fit(X,y)","08d484ba":"abs(train_set.corr().loc['target']).sort_values()","71e4c115":"train_set.corr()","ed594651":"plt.scatter(train_set['target'], train_set['real_vol_1'])\nplt.show()\nplt.scatter(train_set['target'], train_set['price_spread_mean'])\nplt.show()\nplt.scatter(train_set['target'], train_set['total_vol_mean'])\nplt.show()","a44c33b5":"importance = model.coef_\nplt.bar([x for x in range(len(importance))], importance)","985ac0bb":"print(np.argmin(model.coef_))\nX","b49a00fe":"order_book_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\ntrade_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/trade_test.parquet\/*')\ntest_df = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\n\ntest_set = create_dataSet(test_df, order_book_test, trade_test)","ced117bc":"#check rows for nans\ntest_set = test_set.replace([np.inf,np.nan,-np.inf],0.0)\ntest_set[test_set.isnull().any(axis=1)]\n\n#prepare X and y\nX = test_set.loc[ : , test_set.columns != 'row_id']\n\n#remove id coluimns\ndel X['time_id']\n","ccb56b2f":"submission = pd.DataFrame({\"row_id\" : test_set['row_id'], \"target\": model.predict(X)})  \nsubmission.to_csv('submission.csv',index = False)\n","4d033608":"submission","22de6b0c":"# Key functions and Features","8ca61c5e":"## Prediction","406e94ab":"# Features Importance","07a2d2d6":"## Linear Regression","87f2147c":"Feature 4 seems to be causing an issue","c5dfac61":"# Import Libraries","1b50cde3":"## Submission File","068d7682":"# Joint Dataset\nCreate a aggregate dataset which contains both the book and trade features for modelling","daf49d07":"## Prepare test set\n\nNew consol functions are written due to different length of the directory string for test files"}}