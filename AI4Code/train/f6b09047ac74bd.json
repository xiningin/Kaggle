{"cell_type":{"41f35c88":"code","c93c89c2":"code","85c7a3c2":"code","257d6887":"code","80046daa":"code","41603fbe":"code","782a9a60":"code","018dcfb5":"code","f39444dc":"code","b3a76638":"code","add1a097":"code","fb93d352":"code","459bb447":"code","249219f2":"code","83bc3398":"code","251256eb":"code","1b106ca4":"code","c99a1fc2":"code","d7e6982e":"code","0a8d002f":"code","746f89df":"markdown","c09910fd":"markdown","8ce085cc":"markdown","6b42487f":"markdown","60c566e8":"markdown","0cbcd8ce":"markdown","6ab5e0fc":"markdown","29d17478":"markdown","844c9958":"markdown","3b0d6547":"markdown","d7a71615":"markdown","25504fc8":"markdown","6f25e261":"markdown"},"source":{"41f35c88":"import sqlite3\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf","c93c89c2":"data = pd.read_sql(\"\"\"\n    select\n        content,\n        case when rating < 3 then 0\n            when rating > 4 then 2\n            else 1\n        end as sentiment\n    from reviews\n\"\"\", sqlite3.connect(\"\/kaggle\/input\/podcastreviews\/database.sqlite\"))","85c7a3c2":"data","257d6887":"data.sentiment.value_counts()","80046daa":"class_weights = {k: (len(data) \/ v) for k, v in data.sentiment.value_counts().items()}\nclass_weights","41603fbe":"%%time\nVOCAB_SIZE = 100_000\n\ntokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\ntokenizer.fit_on_texts(data.content)","782a9a60":"tokenizer.texts_to_sequences([\"This is how we do it. It's Friday night, and I feel all right, and the party's here on the west side.\"])","018dcfb5":"SEQ_LEN = 128\n\ndef prepare_texts(texts: list) -> np.array:\n    return tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(texts), maxlen=SEQ_LEN)","f39444dc":"%%time\n\nx = prepare_texts(data.content)\ny = data.sentiment","b3a76638":"print(f\"Corpus has {np.count_nonzero(x)} words in it\")","add1a097":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.05, random_state=0)","fb93d352":"def build_model(vocab_size: int, embed_dim: int, seq_len: int, rnn_dim: int, num_classes: int) -> tf.keras.models.Model:\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=seq_len))\n    model.add(tf.keras.layers.SpatialDropout1D(0.5))\n    model.add(tf.keras.layers.LSTM(rnn_dim, return_sequences=True, dropout=0.5))\n    model.add(tf.keras.layers.GlobalAveragePooling1D())\n    model.add(tf.keras.layers.Dense(rnn_dim, activation=\"relu\"))\n    model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\"))\n    \n    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    return model","459bb447":"model = build_model(VOCAB_SIZE, 100, SEQ_LEN, 256, 3)","249219f2":"model.summary()","83bc3398":"model.fit(x_train, y_train, batch_size=1024, class_weight=class_weights, epochs=5, validation_data=(x_val, y_val))","251256eb":"model.predict(prepare_texts([\n    \"I love this podcast!\",\n    \"It's not qutie as good as when it started, but I still listen every week.\",\n    \"Not worth listening to.\",\n    \"I used to love this podcast, but now I can't stand the back and forth.\",\n])).argmax(axis=1)","1b106ca4":"from sklearn.metrics import classification_report, confusion_matrix","c99a1fc2":"y_pred = model.predict(x_val, batch_size=2048)","d7e6982e":"print(classification_report(y_val, y_pred.argmax(1), target_names=[\"Negative\", \"Neutral\", \"Positive\"]))","0a8d002f":"print(confusion_matrix(y_val, y_pred.argmax(1)))","746f89df":"## Data Loading\n\nLoading data from the source database is easy with pandas' `read_sql` function, giving us a convenient dataframe to work with:","c09910fd":"Here we can make sure our tokenizer is working well. The token indexes should be relatively low, since most words in the following sentence are common:","8ce085cc":"There we have it - 10M parameters, mostly in the embeddings. Now, onto our training! We'll run for 5 epochs at a relatively large batch size (since bigger is better for text classification).","6b42487f":"## Data Prep\n\nPreparation of our data here will be fairly straight forward: just tokenizing reviwes into sequences, and padding or truncating review sequences to `SEQ_LEN`, to allow for efficient training in an RNN on GPU.","60c566e8":"For sentiment, we'll use 2 as positive (five stars), 1 as neutral (three or four stars), and 0 as negative (1 or 2 stars).","0cbcd8ce":"Now, to see how our classifier has performed.  I always like to use a sniff test afterwards, just to get an intuitive feel for how its performing. We expect the first to be positive, the second to be neutral, and then the following two to be negative.  The last one is a bit nuanced, so it should required word-order understanding for the network to classify it correctly!","6ab5e0fc":"For a more in-depth view, we can use SKlearn's `classification_report` to see per-class accuracy metrics like precision, recall, and F1.  Hopefully our class-imbalance measures have helped us here, but if not, we'll see significantly worse precision and recall for our less common classes, neutral and negative.","29d17478":"These numbers should be taken in context: when determining precision for class 0 (negative), it is considering largely false-positives from the majority class 2. A recall of 0.86 for class 2 means 14% of class 2 examples (about 6000) were classified as class 1 or 0, meaning for this distribution, half of the false-positives in class 0 or 1 can be expected to be errors from class 2.  In this sense, applying this classifier to data whose distribution was more uniform would improve it's per-class metrics signifiacntly!","844c9958":"## Class Imbalance\n\nThere is obvious class imbalance here, as almost 90% of reviews are 5 stars, and thus positive.  We'll use keras's weighting to help combat class imbalance and ensure that the resulting classifier is sensitive to each class. Let's calculate class weights that we'll use later to impose this.","3b0d6547":"Great! Now we just need to tokenize all the intput data and build our datasets.","d7a71615":"Plotting the confusion matrix helps us see this more plainly. This confusion matrix shows us, for each class, what was the distribution of classifications over that class? For instance, in the second row, the middle value shows us the number of true positive predictions, which validates our observed recall from before. But, as we can see, the contributions of false positives from class 2 impact accuracy far greater, causing low precision in classes 0 and 1.","25504fc8":"Here, we'll use SKlearn's `train_test_split` to give us our training and validation sets.  Due to the size of the dataset, our validation portion can be a failrly small portion of the total dataset.","6f25e261":"## Model Training\n\nNow we'll train our model! We can use a basic text classifier design: text embeddings into an LSTM, with global average pooling following, fed into a linear RELU layer, followed by the softmax classification layer at the end.  We'll also add significant dropout to prevent the model from overfitting:"}}