{"cell_type":{"088f5be2":"code","e0761273":"code","24be1ee3":"code","2ca17279":"code","29580950":"code","6df770d6":"code","535bd76b":"code","ba45fde4":"code","06596dab":"code","d1d3390c":"code","9085a057":"code","54c90eef":"code","90e166ab":"code","b418107a":"code","85d75b65":"code","51981f7b":"code","b79c33fd":"code","be18d66f":"code","4c076452":"code","e9fa78fa":"code","667e8a60":"code","68440d00":"code","bdafd392":"code","83558a9b":"code","4f1783a5":"code","ff731c4c":"code","0e6bf847":"code","fe1ab30c":"code","545980bd":"code","84947006":"code","50de9251":"code","0d164185":"code","9a9adfa4":"code","a4f8bc5d":"code","9e249baa":"code","96ae6076":"code","52f3aae9":"code","8181dc21":"code","b851f4e5":"code","9a7d0cf2":"code","e6971e0a":"code","23cb2238":"code","93e95411":"code","3c8b0ddc":"markdown"},"source":{"088f5be2":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","e0761273":"train = pd.read_csv('\/kaggle\/input\/tmdb-box-office-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tmdb-box-office-prediction\/test.csv')","24be1ee3":"X_train = train.drop(['revenue'],axis=1)\ny_train = train['revenue']\nprint(X_train.shape, y_train.shape)","2ca17279":"X = pd.concat([X_train, test], axis=0)","29580950":"X.head(3)","6df770d6":"X['has_homepage'] = X['homepage'].isnull() == False\nX['is_original_english'] = X['original_language'] == 'en'\nX['has_collection'] = X['belongs_to_collection'].isnull() == False\nX['has_two_titles'] = X['original_title'] != X['title']\nX.drop(['status','original_language','poster_path', 'homepage', 'imdb_id','belongs_to_collection', 'id'], axis=1, inplace=True)\nX.head(2)","535bd76b":"X.columns","ba45fde4":"X.loc[pd.isnull(X['spoken_languages']) == True,'spoken_languages'] = 0\nX['lang'] = list(map(lambda x: [i['iso_639_1'] for i in eval(x)] if x!=0 else [], X['spoken_languages'].values))\nX['n_lang'] = X['lang'].apply(lambda x: len(x))\n\n# temp_lang = ' '.join(list(map(lambda x: ' '.join(x), X['lang']))).split(' ')\n\nspoken_features = ['' + i for i in ['', 'la', 'it', 'cs', 'ta', 'pt', 'hu', 'zh', 'pl', 'ar', 'en', 'ja', 'de', 'ko', 'cn', 'tr',\n 'he', 'sv', 'el', 'ru', 'fr', 'es', 'hi', 'th']]\n\nfor i in spoken_features:\n    X[i] = X['lang'].apply(lambda x: i[7:] in x)\n\nX.drop(['original_title', 'spoken_languages', 'lang'], axis=1, inplace=True)","06596dab":"X.head(2)","d1d3390c":"X.loc[pd.isnull(X['genres']) == True,'genres'] = 0\ngenres = set(' '.join([' '.join(i) for i in list(map(lambda x: [i['name'] for i in eval(x)] if x!=0 else [], X['genres'].values))]).split())\n\nX['genres'] = list(map(lambda x: [i['name'] for i in eval(x)] if x!=0 else [], X['genres'].values))\n\nfor i in genres:\n    X['genre_' + i] = X['genres'].apply(lambda x: i in x)","9085a057":"X['n_genres'] =  X['genres'].apply(lambda x: len(x))","54c90eef":"X['release_month'] = 0\nX['release_day'] = 0\nX['release_year'] = 0\n\nX = pd.concat([X, X['release_date'].str.split('\/', expand=True)], axis=1)\nX.head(2)","90e166ab":"X.iloc[:,-1] = X.iloc[:,-1].fillna('0').astype(int)","b418107a":"year_mod = []\nfor i in X.iloc[:,-1].values:\n    if i in range(0, 19):\n        year_mod.extend([2000 + i])\n    else:\n        year_mod.extend([1900 + i])\nyear_mod\n\nX['release_year'] = year_mod","85d75b65":"X.head(2)","51981f7b":"X = pd.concat([X, pd.get_dummies(X[0], prefix='release_month')], axis=1)\nX.head(2)","b79c33fd":"X['release_date'] = pd.to_datetime(X['release_date'])","be18d66f":"X['release_weekday'] = X['release_date'].dt.weekday.fillna(8).astype(int)","4c076452":"X.loc[:,'production_companies'] = X.loc[:,'production_companies'].fillna('[]')\n\ncompanies = ','.join([','.join(i) for i in list(map(lambda x: [i['name'] for i in eval(x)], X['production_companies'].values))]).split(',')\nunique_companies = set(companies)\n# print(companies)\n\nX['production_companies'] = list(map(lambda x: [i['name'] for i in eval(x)], X['production_companies'].values))","e9fa78fa":"prod_count = {i: sum([1 for j in companies if i == j]) for i in unique_companies}\n\nmost_famous_prod = [k for k,v in prod_count.items() if v > 100 and k]\nfamous_prod = [k for k,v in prod_count.items() if 30 <= v < 100 and k]","667e8a60":"X['n_production_companies'] = X['production_companies'].apply(lambda x: len(x))\nX['most_famous_prod'] = X['production_companies'].apply(lambda x: sum([1 for i in x if i in most_famous_prod]))\nX['famous_prod'] = X['production_companies'].apply(lambda x: sum([1 for i in x if i in famous_prod]))\nX.head(2)","68440d00":"X.loc[:,'production_countries'] = X.loc[:,'production_countries'].fillna('[]')\n\ncountries = ','.join([','.join(i) for i in list(map(lambda x: [i['iso_3166_1'] for i in eval(x)], X['production_countries'].values))]).split(',')\nunique_countries = set(countries)\n# print(unique_countries)\n\nX['production_countries'] = list(map(lambda x: [i['iso_3166_1'] for i in eval(x)], X['production_countries'].values))","bdafd392":"country_count = {i: sum([1 for j in countries if i == j]) for i in unique_countries}\n# sorted(country_count.items(), key=lambda x: x[1], reverse=True)\n\nmost_famous_countries= [k for k,v in country_count.items() if v > 100 and k]\nfamous_countries = [k for k,v in country_count.items() if 30 <= v < 100 and k]\n\nX['n_production_countries'] = X['production_countries'].apply(lambda x: len(x))\nX['most_famous_countries'] = X['production_countries'].apply(lambda x: sum([1 for i in x if i in most_famous_countries]))\nX['famous_countries'] = X['production_countries'].apply(lambda x: sum([1 for i in x if i in famous_countries]))","83558a9b":"X.columns","4f1783a5":"X['has_tagline'] = X['tagline'].apply(lambda x: pd.isnull(x))","ff731c4c":"X.drop(['genres', 'overview', 'production_companies', 'production_countries', 'release_date', 'tagline', 'release_month', 'release_day', 0, 2,\n       'title', 'Keywords', 'cast','crew'], axis=1, inplace=True)\nX.head(2)","0e6bf847":"X['runtime'] = X['runtime'].fillna(X['runtime'].mean())","fe1ab30c":"X[1] = X[1].fillna(1)","545980bd":"for f in X.dtypes[X.dtypes == 'bool'].index:\n    X[f] = X[f].astype(int)","84947006":"X['popularity'] = (X['popularity'] - X['popularity'].mean()) \/ (X['popularity'].max()-X['popularity'].min())","50de9251":"X['runtime'] = (X['runtime'] - X['runtime'].mean()) \/ (X['runtime'].max()-X['runtime'].min())","0d164185":"X['inflationBudget'] = X['budget'] + X['budget']*1.8\/100*(2019-X['release_year'])","9a9adfa4":"X['budget'] = (X['budget'] - X['budget'].mean()) \/ (X['budget'].max()-X['budget'].min())\nX['inflationBudget'] = (X['inflationBudget'] - X['inflationBudget'].mean()) \/ (X['inflationBudget'].max()-X['inflationBudget'].min())","a4f8bc5d":"X.head(2)","9e249baa":"X = X.reset_index()","96ae6076":"from sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression(normalize=True)\nregressor.fit(X[:X_train.shape[0]], y_train)\n\ny_test_pred = regressor.predict(X[X_train.shape[0]:])","52f3aae9":"y_test_pred.shape","8181dc21":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\n\nscore = cross_val_score(regressor, X[:X_train.shape[0]], y_train)\n(abs(score[0]) + abs(score[1]) + abs(score[2]))\/3","b851f4e5":"# import xgboost as xgb\n\n# def xgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n#     params = {'objective': 'reg:linear', \n#               'eta': 0.01, \n#               'max_depth': 6, \n#               'subsample': 0.6, \n#               'colsample_bytree': 0.7,  \n#               'eval_metric': 'rmse', \n#               'seed': random_seed, \n#               'silent': True,\n#     }\n    \n#     record = dict()\n#     model = xgb.train(params\n#                       , xgb.DMatrix(trn_x, trn_y)\n#                       , 100000\n#                       , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n#                       , verbose_eval=verbose\n#                       , early_stopping_rounds=500\n#                       , callbacks = [xgb.callback.record_evaluation(record)])\n#     best_idx = np.argmin(np.array(record['valid']['rmse']))\n\n#     val_pred = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n#     test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n\n#     return {'val':val_pred, 'test':test_pred, 'error':record['valid']['rmse'][best_idx], 'importance':[i for k, i in model.get_score().items()]}","9a7d0cf2":"# import lightgbm as lgb\n\n# def lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n\n#     params = {'objective':'regression',\n#          'num_leaves' : 30,\n#          'min_data_in_leaf' : 20,\n#          'max_depth' : 9,\n#          'learning_rate': 0.004,\n#          #'min_child_samples':100,\n#          'feature_fraction':0.9,\n#          \"bagging_freq\": 1,\n#          \"bagging_fraction\": 0.9,\n#          'lambda_l1': 0.2,\n#          \"bagging_seed\": random_seed,\n#          \"metric\": 'rmse',\n#          #'subsample':.8, \n#           #'colsample_bytree':.9,\n#          \"random_state\" : random_seed,\n#          \"verbosity\": -1}\n\n#     record = dict()\n#     model = lgb.train(params\n#                       , lgb.Dataset(trn_x, trn_y)\n#                       , num_boost_round = 100000\n#                       , valid_sets = [lgb.Dataset(val_x, val_y)]\n#                       , verbose_eval = verbose\n#                       , early_stopping_rounds = 500\n#                       , callbacks = [lgb.record_evaluation(record)]\n#                      )\n#     best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n\n#     val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n#     test_pred = model.predict(test, num_iteration = model.best_iteration)\n    \n#     return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}","e6971e0a":"# from catboost import CatBoostRegressor\n\n# def cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n#     model = CatBoostRegressor(iterations=100000,\n#                                  learning_rate=0.004,\n#                                  depth=5,\n#                                  eval_metric='RMSE',\n#                                  colsample_bylevel=0.8,\n#                                  random_seed = random_seed,\n#                                  bagging_temperature = 0.2,\n#                                  metric_period = None,\n#                                  early_stopping_rounds=200\n#                                 )\n#     model.fit(trn_x, trn_y,\n#                  eval_set=(val_x, val_y),\n#                  use_best_model=True,\n#                  verbose=False)\n    \n#     val_pred = model.predict(val_x)\n#     test_pred = model.predict(test)\n    \n#     return {'val':val_pred, \n#             'test':test_pred, \n#             'error':model.get_best_score()['validation_0']['RMSE']}","23cb2238":"# result_dict = dict()\n# val_pred = np.zeros(train.shape[0])\n# test_pred = np.zeros(test.shape[0])\n# final_err = 0\n# verbose = False\n\n# for i, (trn, val) in enumerate(fold) :\n#     print(i+1, \"fold.    RMSE\")\n    \n#     trn_x = train.loc[trn, :]\n#     trn_y = y[trn]\n#     val_x = train.loc[val, :]\n#     val_y = y[val]\n    \n#     fold_val_pred = []\n#     fold_test_pred = []\n#     fold_err = []\n    \n#     #\"\"\" xgboost\n#     start = datetime.now()\n#     result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n#     fold_val_pred.append(result['val']*0.2)\n#     fold_test_pred.append(result['test']*0.2)\n#     fold_err.append(result['error'])\n#     print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds\/60)) + 'm)')\n#     #\"\"\"\n    \n#     #\"\"\" lightgbm\n#     start = datetime.now()\n#     result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n#     fold_val_pred.append(result['val']*0.4)\n#     fold_test_pred.append(result['test']*0.4)\n#     fold_err.append(result['error'])\n#     print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds\/60)) + 'm)')\n#     #\"\"\"\n    \n#     #\"\"\" catboost model\n#     start = datetime.now()\n#     result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n#     fold_val_pred.append(result['val']*0.4)\n#     fold_test_pred.append(result['test']*0.4)\n#     fold_err.append(result['error'])\n#     print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds\/60)) + 'm)')\n#     #\"\"\"\n    \n#     # mix result of multiple models\n#     val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n#     #print(fold_test_pred)\n#     #print(fold_test_pred.shape)\n#     #print(fold_test_pred.columns)\n#     test_pred += np.mean(np.array(fold_test_pred), axis = 0) \/ k\n#     final_err += (sum(fold_err) \/ len(fold_err)) \/ k\n    \n#     print(\"---------------------------\")\n#     print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) \/ len(fold_err)))\n#     print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n    \n#     print('')\n    \n# print(\"fianl avg   err.\", final_err)\n# print(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))","93e95411":"submission = pd.read_csv('\/kaggle\/input\/tmdb-box-office-prediction\/sample_submission.csv')\nsubmission['revenue'] = y_test_pred\nsubmission.to_csv('submission.csv', index=False)","3c8b0ddc":"<a href=\".\/submission.csv\"> Download File <\/a>"}}