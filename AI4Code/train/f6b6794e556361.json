{"cell_type":{"0eb4cc1f":"code","77e21f1b":"code","a0f0bd31":"code","367a0be2":"code","71f15518":"code","5acb8857":"code","84fdc7ea":"code","a38cda9a":"code","79a5b350":"code","197bc96b":"code","80acae05":"code","c3ca9c71":"code","9214266c":"code","27ea7ab6":"code","50d77a1c":"code","d67db36e":"code","b711b065":"markdown","6e6c7d77":"markdown","555a841f":"markdown","9d5d09ea":"markdown"},"source":{"0eb4cc1f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom PIL import Image \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tensorflow.keras.layers import Conv2D , MaxPool2D , Flatten\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport os, cv2, json","77e21f1b":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","a0f0bd31":"# For easy acces to files\nWORK_DIR = \"..\/input\/cassava-leaf-disease-classification\/\"\nos.listdir(WORK_DIR)\n","367a0be2":"train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\ntrain_labels.head()","71f15518":"sns.countplot(train_labels.label, edgecolor = 'black',\n              palette = sns.color_palette(\"viridis\", 5))\nplt.show()","5acb8857":"BATCH_SIZE = 64\nSTEPS_PER_EPOCH = len(train_labels)*0.8 \/ BATCH_SIZE\nVALIDATION_STEPS = len(train_labels)*0.3 \/ BATCH_SIZE\nEPOCHS = 5\nTARGET_SIZE = 512","84fdc7ea":"train_labels.label = train_labels.label.astype('str')\n\ntrain_generator = ImageDataGenerator(validation_split = 0.2,\n                                     preprocessing_function = None,\n                                     zoom_range = 0.15,\n                                     cval = 0.,\n                                     horizontal_flip = True,\n                                     vertical_flip = True,\n                                     fill_mode = 'nearest',\n                                     shear_range = 0.15,\n                                     height_shift_range = 0.15,\n                                     width_shift_range = 0.15) \\\n    .flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n\nvalidation_generator = ImageDataGenerator(validation_split = 0.2) \\\n    .flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"validation\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")","a38cda9a":"IMAGE_SIZE = [512, 512]\nvgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n","79a5b350":"# don't train existing weights\nfor layer in vgg16.layers:\n    layer.trainable = False\n    \nx = Flatten()(vgg16.output)\nprediction = Dense(5, activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=vgg16.input, outputs=prediction)","197bc96b":"model.summary()","80acae05":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='sparse_categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\n","c3ca9c71":"model_save = ModelCheckpoint('.\/baseline_model_vgg16.h5', \n                             save_best_only = True, \n                             save_weights_only = True,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 5, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)\n\n\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    callbacks = [model_save, early_stop, reduce_lr]\n)","9214266c":"s = pd.read_csv(os.path.join(WORK_DIR, \"sample_submission.csv\"))\ns","27ea7ab6":"preds = []\n\nfor image_id in s.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n\ns['label'] = preds\ns","50d77a1c":"s.to_csv('submission_5.csv', index = False)","d67db36e":"s.to_csv(\"\/kaggle\/working\/submission.csv\", index=False,header=True)","b711b065":"Describing Image Size,Batch Size,Epoch,Validations Steps and Steps Per Epcohs","6e6c7d77":"Adding a softmax layers for classification.You can add add more layers for more accuracy.","555a841f":"Importing VGG16 using Transfer Learning","9d5d09ea":"Perparing Dataset"}}