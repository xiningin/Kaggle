{"cell_type":{"9a36f5de":"code","e0c3d91a":"code","90222ad6":"code","886cce89":"code","728c911c":"code","72777414":"code","6ea5d99a":"code","ceeb1175":"code","501dd2a0":"code","00fcd24c":"code","817403a5":"code","79ea50d1":"code","992a1f0d":"code","fb6768d8":"code","6f9b8a88":"code","02395f16":"code","62fd4b59":"code","28ae9d10":"code","0e2064c5":"code","813aff7d":"code","120d796d":"code","34b5e296":"code","d420f9c7":"code","b7f50a10":"code","82d7d861":"code","a97a8566":"code","fd5aac14":"code","705b61cb":"code","00d8d3e4":"markdown","efc3598c":"markdown","7af9f65d":"markdown","15071e8c":"markdown","43459f1d":"markdown","da93ae9f":"markdown","3dbb2810":"markdown","723f8b31":"markdown","dcf39793":"markdown","9bfa8530":"markdown","d99d5bbd":"markdown","ddd3726a":"markdown","dff82771":"markdown","32647230":"markdown","86228f4b":"markdown","10f3c7bc":"markdown","daa49595":"markdown","7b5fe5b3":"markdown","b85f94c4":"markdown","e59a5627":"markdown"},"source":{"9a36f5de":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","e0c3d91a":"df = pd.read_csv('..\/input\/noshowappointments\/KaggleV2-May-2016.csv')\nprint('Count of rows', str(df.shape[0]))\nprint('Count of Columns', str(df.shape[1]))\ndf.head()","90222ad6":"df.describe()","886cce89":"df.isnull().any().any()","728c911c":"df.info()","72777414":"for i in df.columns:\n    print(i+\":\",len(df[i].unique()))","6ea5d99a":"df.drop('AppointmentID', axis=1,inplace = True)","ceeb1175":"df","501dd2a0":"df['PatientId'] = df['PatientId'].apply(int).apply(str)\ndf['Handcap'] = df['Handcap'].apply(lambda x: 0 if x == 0 else 1)\ndf['No-show'] = df['No-show'].map({'No':0, 'Yes':1})\ndf['Gender'] = df['Gender'].map({'F':0, 'M':1})","00fcd24c":"df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay']).dt.strftime('%Y-%m-%d')\ndf['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'])\ndf['ScheduledDay']","817403a5":"df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay']).dt.strftime('%Y-%m-%d')\ndf['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\ndf['AppointmentDay']","79ea50d1":"df['Day_diff'] = (df['AppointmentDay'] - df['ScheduledDay']).dt.days\ndf['Day_diff'].unique()","992a1f0d":"df['ScheduledDay_Y'] = df['ScheduledDay'].dt.year\ndf['ScheduledDay_M'] = df['ScheduledDay'].dt.month\ndf['ScheduledDay_D'] = df['ScheduledDay'].dt.day\ndf.drop(['ScheduledDay'], axis=1, inplace=True)\n\ndf['AppointmentDay_Y'] = df['AppointmentDay'].dt.year\ndf['AppointmentDay_M'] = df['AppointmentDay'].dt.month\ndf['AppointmentDay_D'] = df['AppointmentDay'].dt.day\ndf.drop(['AppointmentDay'], axis=1, inplace=True)","fb6768d8":"df.drop(df[df['Age'] < 0].index, inplace = True)","6f9b8a88":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ndf['Neighbourhood'] = le.fit_transform(df['Neighbourhood'])\nle = preprocessing.LabelEncoder()\ndf['PatientId'] = le.fit_transform(df['PatientId'])","02395f16":"df","62fd4b59":"df.info()","28ae9d10":"X = df.drop(['No-show'], axis=1)\ny = df['No-show']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)","0e2064c5":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report","813aff7d":"lr = LogisticRegression(solver='liblinear')\nlr.fit(X_train, y_train)\n\ny_pred_lr = lr.predict(X_test)\nclf_report = classification_report(y_test, y_pred_lr)\nprint(f\"Classification Report : \\n{clf_report}\")","120d796d":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\ny_pred_knn = knn.predict(X_test)\n\nclf_report = classification_report(y_test, y_pred_knn)\nprint(f\"Classification Report : \\n{clf_report}\")","34b5e296":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\n\ny_pred_dtc = dtc.predict(X_test)\nclf_report = classification_report(y_test, y_pred_dtc)\n\nprint(f\"Classification Report : \\n{clf_report}\")","d420f9c7":"rd_clf = RandomForestClassifier()\nrd_clf.fit(X_train, y_train)\n\ny_pred_rd_clf = rd_clf.predict(X_test)\nclf_report = classification_report(y_test, y_pred_rd_clf)\n\nprint(f\"Classification Report : \\n{clf_report}\")","b7f50a10":"ada = AdaBoostClassifier(base_estimator = dtc)\nada.fit(X_train, y_train)\n\ny_pred_ada = ada.predict(X_test)\nclf_report = classification_report(y_test, y_pred_ada)\n\nprint(f\"Classification Report : \\n{clf_report}\")","82d7d861":"gb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)\n\ny_pred_gb = gb.predict(X_test)\nclf_report = classification_report(y_test, y_pred_gb)\n\nprint(f\"Classification Report : \\n{clf_report}\")","a97a8566":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)","fd5aac14":"lr = LogisticRegression(solver='liblinear')\nlr.fit(X_train, y_train)\n\ny_pred_lr = lr.predict(X_test)\nclf_report = classification_report(y_test, y_pred_lr)\nprint(f\"Classification Report : \\n{clf_report}\")","705b61cb":"from sklearn.model_selection import cross_val_score\n\naccuracy = cross_val_score(estimator = lr, X = X, y =y, cv = 10)\nprint(\"avg acc: \",np.mean(accuracy))\nprint(\"acg std: \",np.std(accuracy))","00d8d3e4":"## Split dataframe into train and test","efc3598c":"## Even we scale the data into 0,1 the accuracy is not changed as expected!","7af9f65d":"## Last Check","15071e8c":"**There are 110527 rows & 14 features.**","43459f1d":"## As seen above, average test accuracy is 80% & average standard deviation is very low which is ok for now.","da93ae9f":"## Average test set accuracy in these models is %80.\n## We did not scaled whole data. What changes if we scale whole data?\n## Let's try it!","3dbb2810":"**Checking how pandas read datatypes in that dataframe**","723f8b31":"## Let's classify the dataset into a few classifiers.","dcf39793":"## Let's try a cross validation to validate our results.","9bfa8530":"## There can be a time between Appointment Day and Scheduled Day which can be a good feature to classify. \n## So, let's create that feature","d99d5bbd":"## We also have to parse dates to correctly classify the data.\n## Let's convert it to datetime object for both \"ScheduledDay\" & \"AppointmentDay\"","ddd3726a":"## Neighbourhood: str -> integer (Categorical)\n## PatientId: integer -> Categorical Integer (Categorical)","dff82771":"## To give the data a classifier we have to digitilaze that features. \n## Let's seperate the date columns into year, month, day. (Also, weekday and season column can be added but I did not used it here)","32647230":"**There are 110527 rows & all values in \"AppointmentID\" feature is unique. So, we do not need that feature because in every appointment there is an unique appointment ID even it's same person who looks for.**","86228f4b":"## There are negative integers in Age column which is not possible, so easyly drop them.","10f3c7bc":"**There is no null(NAN) values in dataset which is good! :)**","daa49595":"# Preprocess\n## PatientID: Float -> String (we are going to assume that feature like it's categorical)\n## No-show: String -> Integer (categorical feature)\n## Gender: String -> Integer (categorical feature)","7b5fe5b3":"# Now, our dataframe is ready to split & classify. It's all digitized.","b85f94c4":"# Let's read data!","e59a5627":"**Check unique values in features. So, we can choose right methods to encode features.**"}}