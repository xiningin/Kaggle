{"cell_type":{"73ff107e":"code","f4233235":"code","5f6b2dad":"code","87bd74dd":"code","fe4bb63b":"code","4e940a13":"code","53069b04":"code","c9b94919":"code","c88a9cb8":"code","ef869bbf":"code","32d7810e":"code","ce1f1ba0":"code","5c17dde7":"code","f5f5c57f":"code","19802d58":"code","52ba4597":"code","8adcd552":"code","4ee7bf99":"code","684e1340":"code","01cfdca9":"code","fba72b36":"code","dc65c5cb":"code","3a9ccb43":"markdown","b5b70f10":"markdown","ce227b89":"markdown","7b447d59":"markdown","8283d3f2":"markdown","75daa5c0":"markdown","9dd78891":"markdown","178e4e38":"markdown","ec4f0ead":"markdown","11d9ee5b":"markdown","4a9c02b7":"markdown","20c6fdd6":"markdown","b0f49ed1":"markdown","f56d3d1c":"markdown","c92869ff":"markdown","574f3fc2":"markdown","10a283c4":"markdown","de75aac2":"markdown","2ea709eb":"markdown","1cc7fae4":"markdown","f626dbc7":"markdown","8a33935d":"markdown","9fc970f3":"markdown","37f758e5":"markdown","7c2da0d8":"markdown","57fb4c27":"markdown","980259c9":"markdown"},"source":{"73ff107e":"import numpy as np\nimport pandas as pd\nimport random\nimport copy\nimport timeit\nimport pickle\nimport dill\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f4233235":"from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import make_scorer, precision_recall_curve, auc, f1_score, precision_score, recall_score, classification_report, confusion_matrix, plot_confusion_matrix","5f6b2dad":"# Preprocessing data\nclass PreProcessing():\n    \n    def __init__(self, path):\n        # Import data\n        self.data = pd.read_csv(path)\n\n    def process_data(self, shuffle_data):\n        if shuffle_data==False:\n            #\u00a0Check for duplicates and remove them\n            cc_main_ds = self.data.drop_duplicates().reset_index(drop=True) \n            return cc_main_ds.dropna()\n        else:\n            #\u00a0Check for duplicates and remove them\n            cc_main_ds = self.data.drop_duplicates().reset_index(drop=True)\n            #\u00a0Shuffle data to reduce selection bias\n            data_np = np.array(cc_main_ds)\n            random.Random(0).shuffle(data_np)\n            cc_main_ds = pd.DataFrame(data_np, columns= list(self.data.columns))\n            return cc_main_ds.dropna()\n        \n    def datasets(self, X_cols, shuffle_data, standardise):\n        # Retrieve X and y datasets\n        X = self.process_data(shuffle_data)[X_cols]\n        if standardise==True:\n            X = (X - np.mean(X, axis=0))\/np.std(X, axis=0, ddof=0)\n        y = self.process_data(shuffle_data).iloc[:,-1:]\n        return X, y","87bd74dd":"# Obtain datasets and information \nclass DataInfo():\n    \n    def __init__(self, path):\n        # Import data\n        self.data = pd.read_csv(path)\n    \n    def fraud_balance(self, y):\n        # Return classes ratio\n        target_pd = pd.DataFrame(index = [\"Not Fraud\",\"Fraud\"], columns= [\"Quantity\", \"Percentage\"])\n        # Not fraud\n        target_pd.loc[\"Not Fraud\"][\"Quantity\"] = len(y[y==0].dropna())\n        target_pd.loc[\"Not Fraud\"][\"Percentage\"] = target_pd.iloc[0,0]\/len(y)*100\n        #\u00a0Fraud\n        target_pd.loc[\"Fraud\"][\"Quantity\"] = len(y[y==1].dropna())\n        target_pd.loc[\"Fraud\"][\"Percentage\"] = target_pd.iloc[1,0]\/len(y)*100\n        #\u00a0Plot barchart\n        fig = plt.figure(figsize = (10, 5))\n        # creating the bar plot\n        plt.bar(list(target_pd.index), target_pd.iloc[:,0], color ='maroon',width = 0.4)\n        plt.ylabel(\"Number of cases\")\n        plt.title(\"Distribution of fraud and non-fraud cases\")\n        plt.show()\n        return target_pd\n    \n    def draw_histograms(self, rows, cols):\n        # Histogram of features (check for skew)\n        fig=plt.figure(figsize=(20,20))\n        for i, feature in enumerate(self.data.columns):\n            ax=fig.add_subplot(rows,cols,i+1)\n            self.data[feature].hist(bins=20,ax=ax,facecolor='black')\n            ax.set_title(feature+\" Distribution\",color='DarkRed')\n            ax.set_yscale('log')\n        fig.tight_layout()  \n        plt.show()\n    \n    # Heatmap (check for feature correlation)\n    def heatmap(self):\n        plt.figure(figsize = (40,30))\n        sns.heatmap(self.data.corr(), annot = True, cmap=\"tab20c\")\n        plt.show()","fe4bb63b":"# Cross validation analysis on different machine learning models using AUC of precision-recall\nclass fraud_models():\n    \n    def __init__(self, models, model_names):\n        # Initialise pipeline\n        self.models = models\n        self.model_names = model_names\n \n    def pr_auc(self, y_true, probas_pred):\n        # Calculate precision-recall curve\n        p, r, _ = precision_recall_curve(y_true, probas_pred)\n        # Calculate area under curve\n        return auc(r, p)\n\n    def evaluate_models(self, X, y):\n        #\u00a0Store results\n        self.results = list()\n        #\u00a0Time each algorithm\n        self.time = list()\n        for i in range(len(self.models)):\n            start = timeit.default_timer()\n            # Define the model evaluation metric\n            metric = make_scorer(self.pr_auc, needs_proba=True)\n            # Evaluate model\n            scores = cross_val_score(self.models[i], X, np.ravel(y), scoring=metric, \n                                     cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=0))\n            self.results.append(scores)\n            stop = timeit.default_timer()\n            self.time.append(stop-start)\n            print(f\"Cross Validation on {self.model_names[i]} complete!\")\n    \n    def convert(self):\n        #\u00a0Calculate time taken for models to run\n        i=0\n        for seconds in self.time:\n            seconds = seconds % (24 * 3600)\n            hour = seconds \/\/ 3600\n            seconds %= 3600\n            minutes = seconds \/\/ 60\n            seconds %= 60\n            print(f\"{self.model_names[i]} took {int(hour)} hour {int(minutes)} minutes and {round(seconds)} seconds\")\n            i+=1","4e940a13":"#\u00a0Instantiate class\ndf_model = PreProcessing('..\/input\/creditcardfraud\/creditcard.csv')","53069b04":"#\u00a0Print data to see which X columns we need\ndf_model.data","c9b94919":"# Check for NaNs, missing values etc...\ndf_model.info()","c88a9cb8":"#\u00a0Overall statistics\ndf_model.describe()","ef869bbf":"# Obtain X and y datasets (by processing data)\nX, y = df_model.datasets(X_cols=list(data_model.data.columns)[1:30], shuffle_data=True, standardise=True)","32d7810e":"#\u00a0Instantiate class\ndf_metrics = DataInfo('..\/input\/creditcardfraud\/creditcard.csv')","ce1f1ba0":"# Histogram of features\ndf_metrics.draw_histograms(8, 4)","5c17dde7":"# Heatmap correlation\ndf_metrics.heatmap()","f5f5c57f":"#\u00a0Print class ratio\ndf_metrics.fraud_balance(y)","19802d58":"from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb","52ba4597":"# Define models to use\nmodels = list((DecisionTreeClassifier(),\n               KNeighborsClassifier(),\n               RandomForestClassifier(),\n               xgb.XGBClassifier(objective='binary:logistic', \n                                 random_state=0, \n                                 eval_metric='aucpr', \n                                 use_label_encoder=False)))\nmodel_names = list(('DT', 'KNN', 'RF', 'XGB'))","8adcd552":"#\u00a0Instantiate pipeline\nfraud_pipeline = fraud_models(models, model_names)\n#\u00a0Run cross validation algorithm for each model (with equal class splits of fraud and non-fraud)\nfraud_pipeline.evaluate_models(X, y)","4ee7bf99":"# AUC scores per cross validation for each model\nfraud_pipeline.results","684e1340":"# Collate results in dataframe\nresults_df = pd.concat((pd.DataFrame(np.mean(np.array(fraud_pipeline.results), axis=1), columns= [\"Mean\"]),\n           pd.DataFrame(np.std(np.array(fraud_pipeline.results), axis=1), columns= [\"Standard Deviation\"])), axis=1)\nresults_df.index = fraud_pipeline.model_names\nresults_df","01cfdca9":"# Plot the results\nplt.boxplot(fraud_pipeline.results, labels=fraud_pipeline.model_names, showmeans=True)\nplt.ylabel(\"P-R AUC\")\nplt.xlabel(\"Machine Learning Methods\")\nplt.title(\"Distribution of Precision-Recall AUC scores through cross validation\")\nplt.show()","fba72b36":"# Runtime performance\nfraud_pipeline.convert()","dc65c5cb":"# Save machine learning model results and datasets\nmodels = dill.dump([X, y, fraud_pipeline], open( \"save.b\", \"wb\" ))","3a9ccb43":"# Data Processing","b5b70f10":"<p> <center> This notebook is in <span style=\"color: green\"> <b> Active <\/b> <\/span> state of development! <\/center> <\/p>  \n<p> <center> Be sure to checkout my other notebooks for <span style=\"color: blue\"> <b> knowledge, insight and laughter <\/b> <\/span>! \ud83e\udde0\ud83d\udca1\ud83d\ude02<\/center> <\/p> ","ce227b89":"### Import modules","7b447d59":"<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">","8283d3f2":"<center> <h1>\ud83d\udcb3  Credit Card Fraud Detection Dataset \ud83d\udcb3 <\/h1> <\/center>","75daa5c0":"There are a few skewed features displayed and there does not seem to be a great deal of correlation between the features as values are well below the $\\pm$0.5 threshold (only between V2 & Amount and V7 and Amount have value close to this).","9dd78891":"# Summary","178e4e38":"A figure is created showing one box and whisker plot for each algorithm\u2019s sample of results. The box shows the middle 50 percent of the data, the orange line in the middle of each box shows the median of the sample, and the green triangle in each box shows the mean of the sample.","ec4f0ead":"<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">","11d9ee5b":"# Background","4a9c02b7":"# Data Collection","20c6fdd6":"<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">","b0f49ed1":"For this notebook, we will be dealing with a credit card fraud dataset. The dataset contains transactions, that occurred in two days, made by credit cards in September 2013 by European cardholders.\n\nThe following tasks will be performed: \n1. Exploratory Data Analysis (EDA)\n3. Machine Learning (Baseline Models)","f56d3d1c":"<center> <img src=\"https:\/\/i.pinimg.com\/originals\/5e\/2e\/a9\/5e2ea94eb6d47c16ece524873234d199.png\" width=\"300\" height=\"300\" \/> <\/center> ","c92869ff":"<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">","574f3fc2":"Overall, the model we will continue to push forward with is XGB. Its' mean AUC precision-recall and standard deviation are slightly less than and greater than RF respectively however this is compensated by the much faster runtime it possesses over RF. \n\nThe next step will be to apply hyperparameter tuning on XGBoost via GridSearchCV to optimise the performance, in which we can then calculate other metrics (from the confusion matrix).","10a283c4":"Thanks for reading this notebook. If you would like to see further work on this dataset e.g. feature importance, feature engineering, optimisation process etc..., respond in the comment sections and I will be happy to provide this. Additionally, if there are any mistakes or things that need more clarity, please do the same. \n\nAs always, please leave an upvote - it would also be helpful if you cite this documentation if you are going to use any of the code. \ud83d\ude0a\n\n#CodeWithSid ","de75aac2":"# Data Visualisations","2ea709eb":"# Model Testing and Results","1cc7fae4":"# Helper Classes ","f626dbc7":"Ranking | Mean AUC Precision-Recall | Standard Deviation | Run-time\n:-|:-|:-|-:\n1|RF|DT|DT\n2|XGB|KNN|XGB\n3|KNN|RF|RF\n4|DT|XGB|KNN","8a33935d":"The machine learning algorithms (baseline models) we will be testing the dataset on are:\n\n- Decision Trees\n- K-Nearest Neighbours\n- Random Forests\n- XGBoost \n\nIt is typical to focus on tree-ensemble methods for fraud detection datasets as they achieve higher accuracy on these complex datasets. We will be using precision-recall (area under curve) as our metric to evaluate a score of the models, by using repeated stratified k-fold as our cross validation procedure (to deal with imbalance datasets and their stochastic nature). \n\n**Note:** XGBoost uses the logistic regression backbone as their binary classification objective function (and so testing logistic regression is not necessarily needed). ","9fc970f3":"### Fit and evaluate models","37f758e5":"## Import modules","7c2da0d8":"# Full Machine Learning Models","57fb4c27":"V1,...,V28 are the transformed features via PCA. \n\n**Note:** In the pre-processing code, we have dealt with duplicate entries and checked for any NaNs\/missing values\/delimiter issues and have imputed there (if needed).","980259c9":"Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). We could also use the imblearn library to oversample our dataset as well. \n\n**Note:** Confusion matrix accuracy is not meaningful for unbalanced classification. We can also use Amount in a cost-sensitive learning procedure (as we have an imbalanced dataset)."}}