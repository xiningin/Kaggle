{"cell_type":{"f4f672b6":"code","a604ca36":"code","97e8d475":"code","2a74d558":"code","274a7a11":"code","aa3834b6":"code","95c66029":"code","06f08a41":"code","71ec8049":"code","c397b0af":"code","63a322be":"code","875c7163":"code","987ab0a2":"code","095715e1":"code","d8403a5c":"code","d7750128":"code","d8f62dec":"code","ae398f22":"code","256077d5":"code","ac7dd421":"code","c6a1cc84":"code","abea21a0":"code","d52e2fdb":"code","4c6dbf3e":"code","5f04b283":"code","e39767b8":"code","f8551317":"code","322a3634":"code","4dfd07d2":"code","cb7903c2":"code","71d4e820":"code","d141a68e":"code","ca42c2f3":"code","97dbf0ac":"code","1d7514e3":"code","0261549c":"markdown","a61176d8":"markdown","2e5f76cd":"markdown","e2485062":"markdown","4435cf29":"markdown","6f87c9ad":"markdown","cad082ad":"markdown","93daffaa":"markdown","ec786131":"markdown","9badc927":"markdown","e6da0893":"markdown","22b8ad07":"markdown"},"source":{"f4f672b6":"import numpy as np \nimport pandas as pd \n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.model_selection import train_test_split\n#from sklearn.cross_validation import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport os\nprint(os.listdir(\"..\/input\"))\nnp.random.seed(0)","a604ca36":"train = pd.read_csv(\"..\/input\/train.csv\",index_col='PassengerId')\ntest = pd.read_csv(\"..\/input\/test.csv\",index_col='PassengerId')#","97e8d475":"train.isna().sum()","2a74d558":"test.isna().sum()","274a7a11":"train.shape,test.shape","aa3834b6":"train.head()","95c66029":"def replaceGen(sex):\n    gen =0\n    if sex=='male':\n        gen=0\n    elif sex=='female':\n        gen=1\n    return gen\n    ","06f08a41":"train['Sex'] = train['Sex'].apply(replaceGen)\ntest['Sex'] = test['Sex'].apply(replaceGen)","71ec8049":"train['Age'].hist(figsize=(10, 4));","c397b0af":"train['Age'].fillna(train['Age'].mean(), inplace=True)\ntest['Age'].fillna(test['Age'].mean(), inplace=True)","63a322be":"test[test['Fare'].isna()]","875c7163":"Age_mean = train[(train['Pclass']==3) & (train['Embarked']=='S') & (train['Age']>55) & (train['Sex']==0)]['Fare'].mean()","987ab0a2":"test['Fare'].fillna(Age_mean, inplace=True)","095715e1":"X =train.drop(['Survived','Name','Ticket','Cabin','Embarked'],axis=1)\ny =pd.DataFrame(train['Survived'])\ntest_f =test.drop(['Name','Ticket','Cabin','Embarked'],axis=1)","d8403a5c":"X.shape,y.shape","d7750128":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","d8f62dec":"X_train.shape,y_train.shape","ae398f22":"X.head()","256077d5":"model1 = DecisionTreeClassifier()\nmodel2 = KNeighborsClassifier()\nmodel3= LogisticRegression()\nmodel4 = RandomForestClassifier()\nmodel5 = GradientBoostingClassifier()","ac7dd421":"model1.fit(X_train,y_train)\nmodel2.fit(X_train,y_train)\nmodel3.fit(X_train,y_train)\nmodel4.fit(X_train,y_train)\nmodel5.fit(X_train,y_train)","c6a1cc84":"pred1=model1.predict(X_test)\npred2=model2.predict(X_test)\npred3=model3.predict(X_test)\npred4=model4.predict(X_test)\npred5=model5.predict(X_test)","abea21a0":"print(\"Modelo 1 DecisionTreeClassifier\",model1.score(X_test,y_test))\nprint(\"Modelo 2 KNeighborsClassifier\",model2.score(X_test,y_test))\nprint(\"Modelo 3 LogisticRegression\",model3.score(X_test,y_test))\nprint(\"Modelo 4 RandomForestClassifier\",model4.score(X_test,y_test))\nprint(\"Modelo 5 GradientBoostingClassifier\",model5.score(X_test,y_test))","d52e2fdb":"def Stacking(model,train,y,test,n_fold,t=1):\n    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n    test_pred=np.empty((0,1),float)\n    train_pred=np.empty((0,1),float)\n    for train_indices,val_indices in folds.split(train,y.values):\n        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n        if t==1:\n            model.fit(X=x_train,y=y_train)\n        else:\n            model.train(x_train,y_train)\n        train_pred=np.append(train_pred,model.predict(x_val))\n    test_pred=np.append(test_pred,model.predict(test))\n    return test_pred.reshape(-1,1),train_pred\n","4c6dbf3e":"#Number of Folds\nnfolds = 5","5f04b283":"model1 = DecisionTreeClassifier()\n\ntest_pred1 ,train_pred1=Stacking(model=model1,n_fold=nfolds, train=X_train,test=X_test,y=y_train)\n\ntrain_pred1=pd.DataFrame(train_pred1)\ntest_pred1=pd.DataFrame(test_pred1)","e39767b8":"model2 = KNeighborsClassifier()\n\ntest_pred2 ,train_pred2=Stacking(model=model2,n_fold=nfolds,train=X_train,test=X_test,y=y_train)\n\ntrain_pred2=pd.DataFrame(train_pred2)\ntest_pred2=pd.DataFrame(test_pred2)","f8551317":"model3 = RandomForestClassifier()\n\ntest_pred3 ,train_pred3=Stacking(model=model3,n_fold=nfolds,train=X_train,test=X_test,y=y_train)\n\ntrain_pred3=pd.DataFrame(train_pred3)\ntest_pred3=pd.DataFrame(test_pred3)","322a3634":"model4 = GradientBoostingClassifier()\n\ntest_pred4 ,train_pred4=Stacking(model=model4,n_fold=nfolds,train=X_train,test=X_test,y=y_train)\n\ntrain_pred4=pd.DataFrame(train_pred4)\ntest_pred4=pd.DataFrame(test_pred4)","4dfd07d2":"df = pd.concat([train_pred1, train_pred2, train_pred3, train_pred4], axis=1)\ndf_test = pd.concat([test_pred1, test_pred2, test_pred3, test_pred4], axis=1)\n\nmodel = LogisticRegression(random_state=1)\nmodel.fit(df,y_train)\n#y_test = model.predict(df_test)\n##df_test\n#y_test","cb7903c2":"print(\"HiperModelo LogisticRegression\",model.score(df_test, y_test))","71d4e820":"test_pred1 ,train_pred1=Stacking(model=model1,n_fold=nfolds, train=X,test=test_f,y=y,t=1)\ntest_pred2 ,train_pred2=Stacking(model=model2,n_fold=nfolds,train=X,test=test_f,y=y,t=1)\ntest_pred3 ,train_pred3=Stacking(model=model3,n_fold=nfolds,train=X,test=test_f,y=y,t=1)\ntest_pred4 ,train_pred4=Stacking(model=model4,n_fold=nfolds,train=X,test=test_f,y=y,t=1)\n","d141a68e":"train_pred1=pd.DataFrame(train_pred1)\ntest_pred1=pd.DataFrame(test_pred1)\n\ntrain_pred2=pd.DataFrame(train_pred2)\ntest_pred2=pd.DataFrame(test_pred2)\n\ntrain_pred3=pd.DataFrame(train_pred3)\ntest_pred3=pd.DataFrame(test_pred3)\n\ntrain_pred4=pd.DataFrame(train_pred4)\ntest_pred4=pd.DataFrame(test_pred4)\n\ndf = pd.concat([train_pred1, train_pred2, train_pred3, train_pred4], axis=1)\ndf_test = pd.concat([test_pred1, test_pred2, test_pred3, test_pred4], axis=1)\n\nmodel = LogisticRegression(random_state=1)\nmodel.fit(df,y)\ny_target = model.predict(df_test)","ca42c2f3":"test_salida = pd.DataFrame( { 'PassengerId': test_f.index , 'Survived': y_target } )","97dbf0ac":"#Show Output\ntest_salida.head(20)","1d7514e3":"#Generate file\ntest_salida.to_csv( 'titanic_pred.csv' , index = False )","0261549c":"Run model with Dataset of test","a61176d8":"I build a function for make  the stacking","2e5f76cd":"i count data missing and count dataset","e2485062":"Show my Dataset","4435cf29":"We test the models and its accuracy","6f87c9ad":"Run model with all Dataset ","cad082ad":"\nThis Kernel es a basic example of implementation about Stacking, this technique is very import for understand techniques more avanzed <br><br>\n\n\n![Model](https:\/\/burakhimmetoglu.files.wordpress.com\/2016\/12\/workflow.png)\n\n1. Initial training data (X) has m observations, and n features (so it is m x n).\n2. There are M different models that are trained on X (by some method of training, like cross-validation) before hand.\n3. Each model provides predictions for the outcome (y) which are then cast into a second level training data (Xl2) which is now m x M. Namely, the M predictions become features for this second level data.\n4. A second level model (or models) can then be trained on this data to produce the final outcomes which will be used for predictions.","93daffaa":"## Advanced Ensemble Techniques **Stacking**\n\nthis Kernel is built in base to this documents: \nhttps:\/\/www.analyticsvidhya.com\/blog\/2018\/06\/comprehensive-guide-for-ensemble-models\/\nhttps:\/\/burakhimmetoglu.com\/2016\/12\/01\/stacking-models-for-improved-predictions\/ <br> \nIf I help you please upvote","ec786131":"Split the Dataset in Train and test","9badc927":"Upload dataset","e6da0893":"Show the accuracy in the model of second level","22b8ad07":"## Engineer Features\n\nWe work in the features Dataset, this example is about Stacking, and it's not important to deep in the features "}}