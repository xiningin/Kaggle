{"cell_type":{"edf54178":"code","04474aad":"code","84cb396b":"code","069634d4":"code","9432ea67":"code","4246a783":"code","306bc33c":"code","eefa002c":"code","e48c508f":"code","c8e4c11d":"code","abdc6c65":"code","5446116b":"code","c8a4299f":"code","5fddd587":"code","3e4e79ec":"code","2745d796":"code","69d1697b":"code","7565b769":"code","8ead0e1c":"code","77eeaa41":"code","3475f441":"code","ed64041a":"code","c071a766":"code","a344e18f":"code","ecad5f5a":"markdown","b9a836de":"markdown","c3e446b2":"markdown","b4f650d7":"markdown","d8a8eb8f":"markdown","e7599369":"markdown","58f0a9ee":"markdown","eb87e9e7":"markdown","1ead7c27":"markdown","10a23f08":"markdown","46d7ff45":"markdown","d2f42798":"markdown","28b9fd3b":"markdown","ba6322d6":"markdown","66a464c5":"markdown","f346e896":"markdown","7c25a5cb":"markdown","ac1f5799":"markdown","e8f2183b":"markdown","e6701b30":"markdown","1a50ceb2":"markdown","522e75b7":"markdown"},"source":{"edf54178":"import numpy as np\nimport pandas as pd","04474aad":"data = pd.read_csv(\"..\/input\/housedata\/data.csv\")\nprint(\"Taille du jeu de donn\u00e9es :\")\nprint(data.shape)\nprint(\"\\nType des colonnes :\")\nprint(data.info(verbose=True))\nprint(\"\\nOn remarque que la colonne 'date' n'est pas consid\u00e9r\u00e9e comme un type de date, mais comme 'object'.\")\nprint(\"Il faudra changer le type par la suite.\")\nprint(\"\\nRegarder \u00e0 quoi ressemblent les donn\u00e9es :\")\ndata.head()","84cb396b":"# Pour les colonnes num\u00e9riques :\ndata.describe()","069634d4":"# On remarque le minimum du prix est 0, on va retirer les maisons vendues pour 0$ :\ndata = data[data.price > 0]","9432ea67":"# Pour les colonnes qualitatives: \nprint(\"Nombre de valeurs pour les 10 villes contenant le plus de valeurs :\")\ndata.city.value_counts().head(10)","4246a783":"# Construction de la variable cible Y (prix) et suppression de cette variable de data :\nY = data.price\ndata = data.loc[:,data.columns.difference(['price'])]\n# On construit une cible en trois tranches de prix :\nY_cut = pd.cut(Y,Y.quantile([0,.33,.66,1]), include_lowest=True) # On inclue pour \u00e9viter de cr\u00e9er des NAs\nprint(\"Quantiles \u00e0 33% et 66% :\")\nprint(Y.quantile([.33,.66]))\n\n# On modifie le type de la colonne date :\n# Ici, nous allons utiliser le Timestamp sans chercher \u00e0 retrouver le mois o\u00f9 l'ann\u00e9e.\ndata.date = pd.to_numeric(pd.to_datetime(data.date))\nprint(\"\\nLe type de la colonne 'date' a bien chang\u00e9 en integer :\")\nprint(data[['date']].info())","306bc33c":"# On visualise la boxplot des prix :\nY.plot.box()\n\n# Quelques rares valeurs sont sup\u00e9rieures \u00e0 50 000 000$, on supprime donc ces outliers :\ndata = data.loc[Y<=5000000]\nY_cut = Y_cut.loc[Y<=5000000]\nY = Y.loc[Y<=5000000]","eefa002c":"ix_train = data.sample(frac=.7, replace=False, random_state=0).index.values # On tire 70% des individus parmis les n_individus pr\u00e9sents, sans remplacement\nix_test = data.index.difference(ix_train).values # Les autres iandexes forment le test set\nprint(\"Nombre d'\u00e9l\u00e9ments dans le jeu d'entra\u00eentement : {}\".format(len(ix_train)))\nprint(\"Nombre d'\u00e9l\u00e9ments dans le jeu de test : {}\".format(len(ix_test)))","e48c508f":"print(\"Moyenne des prix sur le jeu d'entra\u00eenement :\")\nprint(round(Y.loc[ix_train].mean()))\nprint(\"\\nMoyenne des prix sur le jeu de test :\")\nprint(round(Y.loc[ix_test].mean()))","c8e4c11d":"from sklearn.model_selection import KFold\n\n# Cr\u00e9ation de 5 jeux d'indexes :\nkf = KFold(n_splits=5)\nfolds = [(train, test) for train, test in kf.split(data.index.values)]\n\nprint(\"Nombre de tupple cr\u00e9es :\")\nprint(len(folds))\nprint(\"\\nNombre d'\u00e9l\u00e9ments dans le train et le test set du premier fold :\")\nprint(len(folds[0][0]), len(folds[0][1]))","abdc6c65":"data = data[data.columns.difference(['country', 'street', 'statezip'])]\n\nprint(\"Comme on peut le voir, supprimer les colonnes dans le jeu de donn\u00e9es complet impact les jeux d'entrainement et de test :\")\ndata.loc[ix_train].head()","5446116b":"### 1. Standardisation des donn\u00e9es num\u00e9riques :\nfrom sklearn import preprocessing\n\n# Initialisation du standard scaler :\nstd_scaler = preprocessing.StandardScaler()\n# R\u00e9cup\u00e9rer la liste des colonnes num\u00e9riques :\nnum_cols = data.select_dtypes(exclude=[\"object\"]).columns\n\n# Pour ne pas \"tricher\" en appliquant la standardisation \u00e0 partir des donn\u00e9es du test set,\n# on param\u00e8tre le scaler avec les donn\u00e9es du jeu d'entrainement exclusivement :\nstd_scaler.fit(data.loc[:,num_cols].loc[ix_train])\n# On applique ensuite sur tout le jeu de donn\u00e9es :\ndata.loc[:,num_cols] = std_scaler.transform(data.loc[:,num_cols])","c8a4299f":"### 2. Transformation les modalit\u00e9s de la variable city :\ndict_replace = {city_name:'Other' for city_name,counter in data.city.value_counts().iteritems() if counter<50}\ndata.city = data.city.replace(dict_replace)\n\n### 3. Encodage en dummy variables de city :\n# Construction des colonnes contenant les dummies :\ndata_with_dummies = pd.get_dummies(data, drop_first=True) # On retire la premi\u00e8re colonne pour \u00e9viter la multi-colin\u00e9arit\u00e9 dans les mod\u00e8les lin\u00e9aires.\ndata_with_dummies.head()","5fddd587":"from sklearn.cluster import KMeans\n# Initialisation des param\u00e8tres de l'algorithme :\nKmeans_model = KMeans(n_clusters=6, init = 'k-means++', random_state=123)\n\n# On applique le clustering sur le jeu d'entra\u00eenement (train) :\n# On enregistre dans la variable clusters le num\u00e9ro du cluster auquel chaque maison est identifi\u00e9e\nclusters = Kmeans_model.fit_predict(data.loc[ix_train, data.columns.difference(['city'])])\n\n# On enregistre les clusters et les colonnes \u00e0 comparer dans un dataframe pandas :\ntrain_clusters = pd.DataFrame([*zip(clusters,Y.loc[ix_train],Y_cut.loc[ix_train])], columns=['cluster','price','price_cut'])\n\ntrain_clusters.boxplot(by='cluster')\nprint('On affiche les boxplot de prix par clusters :')","3e4e79ec":"print(\"On affiche la table des profils ligne par tranche de prix, pour chaque cluster :\")\ncross_table = pd.crosstab(train_clusters.cluster, train_clusters.price_cut, normalize='index')\ncross_table.style.background_gradient(cmap='Reds', axis=1, low=0, high=1)","2745d796":"# Pour chaque maison du jeu test, on retrouve le cluster auquel elle appartient :\nclusters_test = Kmeans_model.predict(data.loc[ix_test, data.columns.difference(['city'])])\n\n# On construit un dictionnaire pour associer \u00e0 chaque cluster la classe dominante :\ndict_cluster_pred = {\n    0:'(370000.0, 575000.0]' ,\n    1:'(575000.0, 26590000.0]' ,\n    2:'(7799.999, 370000.0]' ,\n    3:'(575000.0, 26590000.0]' ,\n    4:'(575000.0, 26590000.0]' ,\n    5:'(7799.999, 370000.0]'\n}\ny_test_clusters = [dict_cluster_pred[c] for c in clusters_test]\n\n# Calcul de l'accuracy et du recall :\nfrom sklearn.metrics import accuracy_score, recall_score\nprint(\"Classe dominante du cluster :\\n- Accuracy : {}\\n- Recall   : {}\".format(\n    round(accuracy_score(y_test_clusters, Y_cut.astype(str)[ix_test]),4),\n    round(recall_score(y_test_clusters, Y_cut.astype(str)[ix_test], average='macro'),4)\n))","69d1697b":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n# Initialisation des mod\u00e8les :\nKNN_model = KNeighborsClassifier(n_neighbors=11)\nRFC_model = RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_leaf=7, random_state=0)\nMLPC_model = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', max_iter=1000, random_state=0)","7565b769":"# Pour la pr\u00e9diction, le type Categorical (cat\u00e9gories ordonn\u00e9es de pandas)\n# n'est pas compatible avec les fonctions de sklearn.metrics, on \n# le convertit dans le type string :\nY_cut_str = Y_cut.astype(str)\n\n# Entra\u00eenement :\n%time KNN_model.fit(data_with_dummies.loc[ix_train], Y_cut_str.loc[ix_train])\n%time RFC_model.fit(data_with_dummies.loc[ix_train], Y_cut_str.loc[ix_train])\n%time MLPC_model.fit(data_with_dummies.loc[ix_train], Y_cut_str.loc[ix_train])\n\n# Pr\u00e9diction sur le jeu de test :\ny_test_knn = KNN_model.predict(data_with_dummies.loc[ix_test])\ny_test_rfc = RFC_model.predict(data_with_dummies.loc[ix_test])\ny_test_mlpc = MLPC_model.predict(data_with_dummies.loc[ix_test])\n\n# On affiche la pr\u00e9cision (accuracy) et le rappel (recall) pour chaque m\u00e9thode :\nfrom sklearn.metrics import accuracy_score, recall_score\nprint(\"\\n11 plus proches voisins :\\n- Accuracy : {}\\n- Recall   : {}\".format(\n    round(accuracy_score(y_test_knn, Y_cut_str[ix_test]),4),\n    round(recall_score(y_test_knn, Y_cut_str[ix_test], average='macro'),4)\n))\nprint(\"\\nRandom Forest Classifier (100 arbres) :\\n- Accuracy : {}\\n- Recall   : {}\".format(\n    round(accuracy_score(y_test_rfc, Y_cut_str[ix_test]),4),\n    round(recall_score(y_test_rfc, Y_cut_str[ix_test], average='macro'),4)\n))\nprint(\"\\nMulti Layer Perceptron Classifier (50 couches) :\\n- Accuracy : {}\\n- Recall   : {}\".format(\n    round(accuracy_score(y_test_mlpc, Y_cut_str[ix_test]),4),\n    round(recall_score(y_test_mlpc, Y_cut_str[ix_test], average='macro'),4)\n))","8ead0e1c":"from sklearn.model_selection import cross_val_score\n\n# Cross validation avec 5 folds : \nscores_knn = cross_val_score(KNN_model, data_with_dummies, Y_cut_str, cv=5)\nscores_rfc = cross_val_score(RFC_model, data_with_dummies, Y_cut_str, cv=5)\nscores_mlpc = cross_val_score(MLPC_model, data_with_dummies, Y_cut_str, cv=5)\n\n# Afficher la moyenne et l'\u00e9cart type des accuracy :\nprint(\"Accuracy KNN  : %0.2f (+\/- %0.2f)\" % (scores_knn.mean(), scores_knn.std() * 2))\nprint(\"Accuracy RFC  : %0.2f (+\/- %0.2f)\" % (scores_rfc.mean(), scores_rfc.std() * 2))\nprint(\"Accuracy MLPC : %0.2f (+\/- %0.2f)\" % (scores_mlpc.mean(), scores_mlpc.std() * 2))","77eeaa41":"from sklearn.model_selection import KFold\n\n# Cr\u00e9ation de 5 jeux d'indexes :\nkf = KFold(n_splits=5)\nfolds = [(train, test) for train, test in kf.split(data_with_dummies.index)]\n# KFold renvoie les index num\u00e9rot\u00e9s et pas le nom de la ligne\n# on les utilisera avec .iloc et pas .loc comme pr\u00e9c\u00e9demment.\n\n# Application dans une boucle :\naccuracy_knn, accuracy_rfc, accuracy_mlpc = [], [], []\nfor ix_train_cv, ix_test_cv in folds :\n    # Entra\u00eenement :\n    KNN_model.fit(data_with_dummies.iloc[ix_train_cv], Y_cut_str.iloc[ix_train_cv])\n    RFC_model.fit(data_with_dummies.iloc[ix_train_cv], Y_cut_str.iloc[ix_train_cv])\n    MLPC_model.fit(data_with_dummies.iloc[ix_train_cv], Y_cut_str.iloc[ix_train_cv])\n\n    # Pr\u00e9diction sur le jeu de test :\n    y_test_knn = KNN_model.predict(data_with_dummies.iloc[ix_test_cv])\n    y_test_rfc = RFC_model.predict(data_with_dummies.iloc[ix_test_cv])\n    y_test_mlpc = MLPC_model.predict(data_with_dummies.iloc[ix_test_cv])\n\n    # Calcul de l'accuracy :\n    accuracy_knn.append(accuracy_score(y_test_knn, Y_cut_str.iloc[ix_test_cv]))\n    accuracy_rfc.append(accuracy_score(y_test_rfc, Y_cut_str.iloc[ix_test_cv]))\n    accuracy_mlpc.append(accuracy_score(y_test_mlpc, Y_cut_str.iloc[ix_test_cv]))\n    \n# Afficher la moyenne et l'\u00e9cart type des accuracy :\nprint(\"Accuracy KNN  : %0.2f (+\/- %0.2f)\" % (np.mean(accuracy_knn), np.std(accuracy_knn) * 2))\nprint(\"Accuracy RFC  : %0.2f (+\/- %0.2f)\" % (np.mean(accuracy_rfc), np.std(accuracy_rfc) * 2))\nprint(\"Accuracy MLPC : %0.2f (+\/- %0.2f)\" % (np.mean(accuracy_mlpc), np.std(accuracy_mlpc) * 2))","3475f441":"# Entrainement et pr\u00e9diction :\nRFC_model.fit(data_with_dummies.loc[ix_train], Y_cut_str.loc[ix_train])\ny_test_rfc = RFC_model.predict(data_with_dummies.loc[ix_test])\ny_test_rfc = pd.Series(y_test_rfc, name='Predictions') # Transformation en s\u00e9rie pour donner un nom \u00e0 la colonne\n\nprint(\"On affiche la matrice de confusion sur le jeu de test :\")\ncross_table = pd.crosstab(y_test_rfc, Y_cut_str.loc[ix_test].reindex(ix_test).reset_index(drop=True))\ncross_table = cross_table.iloc[[2,0,1],[2,0,1]] # On r\u00e9ordonne les colonnes pour qu'elles soient dans le 'bon' ordre\ncross_table.style.background_gradient(cmap='Reds', axis=1, low=0, high=1)","ed64041a":"from sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n# Initialisation des mod\u00e8les :\nLASSO_model = Lasso(alpha=.1, random_state=0)\nRFR_model = RandomForestRegressor(n_estimators=500, max_depth=20, min_samples_leaf=7, random_state=0)\nMLPR_model = MLPRegressor(hidden_layer_sizes=(500,), activation='relu', max_iter=2000, random_state=0)","c071a766":"# Entra\u00eenement :\n%time LASSO_model.fit(data_with_dummies.loc[ix_train], Y.loc[ix_train])\n%time RFR_model.fit(data_with_dummies.loc[ix_train], Y.loc[ix_train])\n%time MLPR_model.fit(data_with_dummies.loc[ix_train], Y.loc[ix_train])\n\n# Pr\u00e9diction sur le jeu de test :\ny_test_lasso = LASSO_model.predict(data_with_dummies.loc[ix_test])\ny_test_rfr = RFR_model.predict(data_with_dummies.loc[ix_test])\ny_test_mlpr = MLPR_model.predict(data_with_dummies.loc[ix_test])\n\n# On affiche la pr\u00e9cision (accuracy) et le rappel (recall) pour chaque m\u00e9thode :\nfrom sklearn.metrics import r2_score, mean_squared_error\nprint(\"\\nLASSO :\\n- R2   : {}\\n- RMSE : {}\".format(\n    round(r2_score(y_test_lasso, Y[ix_test]),4),\n    round(np.sqrt(mean_squared_error(y_test_lasso, Y[ix_test])),4)\n))\nprint(\"\\nRandom Forest Regression (500 arbres) :\\n- R2   : {}\\n- RMSE : {}\".format(\n    round(r2_score(y_test_rfr, Y[ix_test]),4),\n    round(np.sqrt(mean_squared_error(y_test_rfr, Y[ix_test])),4)\n))\nprint(\"\\nMulti Layer Perceptron Regression (500 couches) :\\n- R2   : {}\\n- RMSE : {}\".format(\n    round(r2_score(y_test_mlpr, Y[ix_test]),4),\n    round(np.sqrt(mean_squared_error(y_test_mlpr, Y[ix_test])),4)\n))","a344e18f":"from sklearn.model_selection import cross_validate\n\n# Cross validation avec 5 folds : \nscores_lasso = cross_validate(LASSO_model, data_with_dummies, Y, cv=5, scoring=[\"r2\",\"neg_mean_squared_error\"])\nscores_rfr = cross_validate(RFR_model, data_with_dummies, Y, cv=5, scoring=[\"r2\",\"neg_mean_squared_error\"])\nscores_mlpr = cross_validate(MLPR_model, data_with_dummies, Y, cv=5, scoring=[\"r2\",\"neg_mean_squared_error\"])\n\nprint(\"R\u00e9sultats pour la m\u00e9thode LASSO :\")\nprint(scores_lasso)\nprint('-'*30)\n\n# Afficher la moyenne et l'\u00e9cart type des accuracy :\nprint(\"\\nR2 LASSO   : %0.2f (+\/- %0.2f)\" % (scores_lasso[\"test_r2\"].mean(), scores_lasso[\"test_r2\"].std() * 2))\nprint(\"RMSE LASSO : %0.2f (+\/- %0.2f)\" % (np.sqrt(scores_lasso[\"test_neg_mean_squared_error\"]*-1).mean(), np.sqrt(scores_lasso[\"test_neg_mean_squared_error\"]*-1).std() * 2))\n\nprint(\"\\nR2 RFR     : %0.2f (+\/- %0.2f)\" % (scores_rfr[\"test_r2\"].mean(), scores_rfr[\"test_r2\"].std() * 2))\nprint(\"RMSE RFR   : %0.2f (+\/- %0.2f)\" % (np.sqrt(scores_rfr[\"test_neg_mean_squared_error\"]*-1).mean(), np.sqrt(scores_rfr[\"test_neg_mean_squared_error\"]*-1).std() * 2))\n\nprint(\"\\nR2 MLPR    : %0.2f (+\/- %0.2f)\" % (scores_mlpr[\"test_r2\"].mean(), scores_mlpr[\"test_r2\"].std() * 2))\nprint(\"RMSE MLPR  : %0.2f (+\/- %0.2f)\" % (np.sqrt(scores_mlpr[\"test_neg_mean_squared_error\"]*-1).mean(), np.sqrt(scores_mlpr[\"test_neg_mean_squared_error\"]*-1).std() * 2))","ecad5f5a":"On entra\u00eene sur notre jeu d'entrainement, puis on regarde l'erreur sur notre jeu de test :","b9a836de":"Scikit-learn pr\u00e9sente beaucoup de fonctions de *preprocessing* classiques, n'h\u00e9sitez pas \u00e0 jeter un oeuil \u00e0 [leur documentation](https:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html#preprocessing).<br>\nUn grand nombre des algorithmes et outils de la librairie fonctionnent sur le principe du `fit - transform`, comme pr\u00e9sent\u00e9 ci-apr\u00e8s.\n\nTrois exemples :\n1. Beaucoup d'algorithmes sont sensibles \u00e0 l'\u00e9chelle des valeurs, il est souvent recommand\u00e9 de centrer-r\u00e9duire les valeurs num\u00e9riques.\n- Certaines modalit\u00e9s de la variable `city` ont peu d'\u00e9l\u00e9ments. Nous remplacerons les villes avec moins de 50 maisons par la modalit\u00e9 `Other`.\n- Beaucoup d'algorithmes n'acceptent pas les variables qualitatives et n\u00e9cessitent un \"encodage\" en *dummy variables*.","c3e446b2":"# Exemples de mod\u00e9lisation :\n\nNous allons maintenant proc\u00e9der \u00e0 trois exemples de mod\u00e9lisation :\n- Un clustering non supervis\u00e9\n- Une classification supervis\u00e9e pour pr\u00e9dire une tranche de prix\n- Une r\u00e9gression supervis\u00e9e pour pr\u00e9dire le prix\n\n## Clustering non supervis\u00e9 :\n\nOn va appliquer un [algorithme K-means](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) sur notre jeu de donn\u00e9e (sauf les noms de ville) et les comparer aux prix et tranches de prix. (Vous pouvez appliquer par villes pour voir ce que \u00e7a donne).\n\nVous trouverez d'autres algorithmes de clustering dans [la documentation scikit-learn](https:\/\/scikit-learn.org\/stable\/modules\/clustering.html#clustering).","b4f650d7":"Les scores en cross-validation semblent beaucoup plus serr\u00e9s. La m\u00e9thode LASSO reste la meilleure en terme de performances, mais celles-ci sont aussi les plus variables.\n\nEn observant les r\u00e9sultats pour cette m\u00e9thode, on voit bien que les r\u00e9sultats sont p\u00e9nalis\u00e9s par la derni\u00e8re partie de cross-validation (5\u00e8me \u00e9l\u00e9ment dans les listes de r\u00e9sultats).\n\n# Ce qui n'appara\u00eet pas dans ce tutoriel\n\nAfin de rester relativement court, j'ai omis certaines possibilit\u00e9s bien int\u00e9gr\u00e9es dans scikit-learn. J'en liste quelques unes ici :\n- Pour obtenir de meilleurs r\u00e9sultats, on peut mettre en place une optimisation d'hyper-param\u00e8tres avec les fonctions [GridSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html) ou [RandomizedSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RandomizedSearchCV.html), qu'on ne d\u00e9crira pas dans ce tutoriel.\n- Il est possible d'acc\u00e9der aux \u00e9l\u00e9ments internes d'un mod\u00e8le, pour cela se r\u00e9f\u00e9rer \u00e0 la documentation (et fouiller un peu ... beaucoup). Par exemple, pour une RandomForest, on peut retrouver les arbres composant la for\u00eats et obtenir les pr\u00e9dictions de chacun d'entre eux !\n- Certaines m\u00e9thodes tr\u00e8s sympathiques, sp\u00e9cifiques \u00e0 tel ou tel algorithme. Par exemple les feature importance pour les random forest.\n- La possibilit\u00e9 de structurer ses \u00e9tapes de mod\u00e9lisation dans [un pipeline de traitements](https:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.pipeline). \n- Les options graphiques (semi-)int\u00e9gr\u00e9es, que vous d\u00e9couvrirez dans la documentation ou les tutoriels.\n\nEt plein d'autres subtilit\u00e9s...","d8a8eb8f":"\n\n### Pour aller plus loin :\n\nJe vous invite \u00e0 passer un peu de temps sur [la documentation de scikit-learn](https:\/\/scikit-learn.org\/stable\/index.html), qui est tr\u00e8s intuitive et p\u00e9dagogique. Vous trouverez beaucoup de tutos et de remarques pertinentes sur l'utilisation des mod\u00e8les et leurs param\u00e8tres.\n\nUn [petit sommaire du contenu de la doc](https:\/\/scikit-learn.org\/stable\/user_guide.html) :\n- **Pour la mod\u00e9lisation, class\u00e9e par type d'apprentissage** :\n    1. [Mod\u00e9lisation supervis\u00e9e](https:\/\/scikit-learn.org\/stable\/supervised_learning.html) : Generalized Linear Models, Linear and Quadratic Discriminant Analysis, Kernel ridge regression, Support Vector Machines, Stochastic Gradient Descent, Nearest Neighbors, Gaussian Processes, Cross decomposition, Naive Bayes, Decision Trees, Ensemble methods, Multiclass and multilabel algorithms, Feature selection, Semi-Supervised, Isotonic regression, Probability calibration, Neural network models (supervised)\n    2. [Mod\u00e9lisation non-supervis\u00e9e](https:\/\/scikit-learn.org\/stable\/unsupervised_learning.html) : Gaussian mixture models, Manifold learning, Clustering, Biclustering, Decomposing signals in components (matrix factorization problems), Covariance estimation, Novelty and Outlier Detection, Density Estimation, Neural network models (unsupervised)\n- **Des outils indispensables** :\n    3. [S\u00e9lection et \u00e9valutaion des mod\u00e8les](https:\/\/scikit-learn.org\/stable\/model_selection.html) : Cross-validation, Tuning the hyper-parameters of an estimator, Model evaluation (including metrics), Model persistence, Validation curves\n    4. [Explicabilit\u00e9 des mod\u00e8les](https:\/\/scikit-learn.org\/stable\/inspection.html) : Partial dependence plots (A noter que certains mod\u00e8les int\u00e8grent des outils d'explicabilit\u00e9 propre \u00e0 la m\u00e9thode)\n    5. [Transformation du jeu de donn\u00e9es](https:\/\/scikit-learn.org\/stable\/data_transforms.html) : Pipelines and composite estimators, Feature extraction, Preprocessing data, Imputation of missing values, Unsupervised dimensionality reduction, Random Projection, Kernel Approximation, Pairwise metrics Affinities and Kernels, Transforming the prediction target (y)\n- **Pour tester des mod\u00e8les dans les meilleures conditions ou effectuer un benchmark** :\n    6. [Jeux de donn\u00e9es (usuels et factices)](https:\/\/scikit-learn.org\/stable\/datasets\/index.html) : General dataset API, Toy datasets, Real world datasets, Generated datasets, Loading other datasets\n    7. [Passage \u00e0 l'\u00e9chelle et performances](https:\/\/scikit-learn.org\/stable\/modules\/computing.html) : Strategies to scale computationally, Computational Performance, Parallelism resource management and configuration\n- **L'int\u00e9gralit\u00e9 des fonctions sont r\u00e9f\u00e9renc\u00e9es \u00e0 [un unique endroit](https:\/\/scikit-learn.org\/stable\/modules\/classes.html)**, pratique pour une recherche avec Ctrl+H.\n- **Plusieurs tutoriels bien r\u00e9alis\u00e9s et simples \u00e0 reproduire**:\n    - [Les tutoriels](https:\/\/scikit-learn.org\/stable\/tutorial\/index.html)\n    - [De nombreux exemples d'applications](https:\/\/scikit-learn.org\/stable\/auto_examples\/)\n- **[D'autres librairies](https:\/\/scikit-learn.org\/stable\/related_projects.html) compatibles avec scikit-learn ou compl\u00e9mentaires**\n\n\nQuelques tutoriels issus de Kaggle (en anglais), pour aller plus loin :\n- [Quelques exemples pour l'exploration d'un nouveau jeu de donn\u00e9es](https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python) : Statistiques et graphes univari\u00e9s, bivari\u00e9s, cleaning de donn\u00e9es et test des hyopth\u00e8ses pour la r\u00e9gression\n- [Les \u00e9tapes d'un kaggle de bout en bout, avec les r\u00e9f\u00e9rences \u00e0 la doc](https:\/\/www.kaggle.com\/ldfreeman3\/a-data-science-framework-to-achieve-99-accuracy) : Etude compl\u00e8te et illustr\u00e9e, de la pr\u00e9paration des donn\u00e9es \u00e0 l'optimisation d'un mod\u00e8le (choix des param\u00e8tres et des variables)\n\n\nJe compl\u00e8terai \u00e9ventuellement cette liste, si je trouve d'autres \u00e9l\u00e9ments de documentation compl\u00e9mentaires qui me semblent pertinent !","e7599369":"La r\u00e9gression LASSO donne ici les meilleurs r\u00e9sultats, et dans un temps de calcul bien moindre !<br>\nOn notera que le Multi-layer Perceptron n'a pas converg\u00e9. Avec davantages d'it\u00e9rations on peut s'attendre \u00e0 de meilleurs r\u00e9sultats.\n\nPour la cross-validation, on utilisera ici la fonction `cross_validate`, qui permet d'\u00e9valuer simultan\u00e9ment plusieurs m\u00e9triques (contrairement \u00e0 `cross_val_score`) et performances temporelles d'entrainement (`fit_time`) et d'application (`score_time`).\n\nLes r\u00e9sultats sont fournis sous la forme d'un dictionnaire, on peut y acc\u00e9der avec la cl\u00e9 portant le nom de la m\u00e9trique de performance :","58f0a9ee":"Les r\u00e9sultats sont un peu meilleurs que l'al\u00e9atoire (3 classes => 33,33...%). Mais ils ne sont pas grandement satisfaisants. Cela dit, l'apprentissage \u00e9tant non supervis\u00e9, on ne pouvait s'attendre \u00e0 des performances extraordinaires.\n\n## Classification supervis\u00e9e, pour retrouver une tranche de prix :\n\nOn va appliquer trois m\u00e9thodes diff\u00e9rentes de classification, les param\u00e8tres sont d\u00e9crits dans la doc :\n- Les [K plus proches voisins](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n- Une [for\u00eat al\u00e9atoire pour la classification](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n- Un [r\u00e9seau de neuronnes](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) (Multi Layer Perceptron Classifier)\n\nPour avoir la liste des mod\u00e8les propos\u00e9s dans scikit-learn, [on peut se r\u00e9f\u00e9rer \u00e0 la documentation](https:\/\/scikit-learn.org\/stable\/supervised_learning.html) ou \u00e0 [un benchmark de plusieurs m\u00e9thodes](https:\/\/scikit-learn.org\/stable\/auto_examples\/classification\/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py).","eb87e9e7":"Quelques statistiques sur les colonnes :","1ead7c27":"## Chargement et d\u00e9couverte des donn\u00e9es :\n\nNous allons explorer un petit jeu de donn\u00e9es pr\u00e9sent sur Kaggle : House price prediction\n\nTout d'abord, on charge les librairies et le jeu de donn\u00e9es.<br>\nOn explore rapidement son contenu.","10a23f08":"## Transformation sur le jeu de donn\u00e9es :\n\nEn proc\u00e9dant avec les indexes, le gros avantage est que l'on peut modifier tout le jeu de donn\u00e9es d'un coup lorsqu'on a besoin de supprimer une colonne ou de transformer les donn\u00e9es !\n\nPar exemple, on va supprimer les colonnes `country`, `street` et `statezip` qui sont difficiles \u00e0 exploiter sans pr\u00e9-traitements pouss\u00e9s :`","46d7ff45":"Pour \u00e9viter l'overfitting et pour v\u00e9rifier la performance de ses algorithmes, il est d'usage de s\u00e9parer le jeu d'entra\u00eenement en *train set* et en *test set*. Le *validation set* \u00e9tant r\u00e9serv\u00e9 \u00e0 la soumission des r\u00e9sultats (dans Kaggle) ou \u00e0 la validation des r\u00e9sultats (dans la vraie vie).\n\nNous n'utiliserons pas le jeu de validation ici, car notre but est d'illustrer la construction d'un algorithme de pr\u00e9diction, sans pour autant chercher \u00e0 \u00eatre dans le top classement ;)\n\nTout d'abord, effectuer soit m\u00eame un tirage al\u00e9atoire permettant de mettre 70% des valeurs dans le *train set* et 30% dans le *test set* :","d2f42798":"# Mod\u00e9lisation par r\u00e9gression :\n\nOn va appliquer trois m\u00e9thodes de r\u00e9gression, les param\u00e8tres sont d\u00e9crits dans la documentation :\n- la [r\u00e9gression LASSO](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.Lasso.html)\n- la [random forest regression](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestRegressor.html)\n- le [Multi Layer Perceptron Regression](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPRegressor.html)\n\nPour avoir la liste des mod\u00e8les propos\u00e9s dans scikit-learn, [on peut se r\u00e9f\u00e9rer \u00e0 la documentation](https:\/\/scikit-learn.org\/stable\/supervised_learning.html).\n\nPour la for\u00eat al\u00e9atoire et le multi-layer perceptron, on a chang\u00e9 quelques param\u00e8tres par rapport \u00e0 leurs \u00e9quivalents en classification.<br>\nEn particulier, augmenter le nombre d'arbres et leur profondeur d'une part, et augmenter le nombre de couches et le nombre d'it\u00e9ration test\u00e9es si arr\u00eat avant convergence.","28b9fd3b":"On va v\u00e9rifier la pr\u00e9sence d'outliers dans la cible (le prix) et retirer les valeurs extr\u00eames du jeu de donn\u00e9es :","ba6322d6":"On pourra s\u00e9lectionner le *train set* et le *test set* par leurs indexes pour effectuer des calculs.\n\nPar exemple, calculer la moyenne sur chaque jeu de donn\u00e9es :","66a464c5":"**Astuce :** scikit-learn embarque [plusieurs fonctions tr\u00e8s pratiques pour effectuer de la cross-validation](https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html).\n\nPour garder la main sur les index construits, on peut utiliser des fonctions comme `KFold` :","f346e896":"## Pr\u00e9paration des jeux d'entrainement et de test\n\nAvant tout, on s\u00e9pare la cible des donn\u00e9es explicatives.\n\nOn en profite pour cr\u00e9er une variable cible de cat\u00e9gories `Y_cut` en cr\u00e9ant trois tranches de prix.<br>\nCes tranches sont construites d'apr\u00e8s les quantiles 33% et 66%.","7c25a5cb":"Les r\u00e9sultats sont plut\u00f4t corrects. Le *Multi Layer Perceptron Classifier* est ici le plus performant de nos trois mod\u00e8les test\u00e9s.\n\nAfin de s'assurer que les performances de nos mod\u00e8les ne sont pas \"dues \u00e0 la chance\", nous allons mettre en place une **cross-validation**.<br>\nScikit-learn a pour \u00e7a un fonction tr\u00e8s pratique, [cross_val_score](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.cross_val_score.html), que nous pouvons appliquer directement sur le jeu de donn\u00e9e complet (train + test) :","ac1f5799":"# Mod\u00e9lisation avec scikit-learn\n\nCe troisi\u00e8me tutoriel a pour but de pr\u00e9senter rapidement quelques principes de mod\u00e9lisation avec le package scikit-learn (`sklearn`).<br>\nC'est aussi un bon moyen de mettre en pratique les bases du [tutoriel 1](https:\/\/www.kaggle.com\/leowanty\/tuto-1-prise-en-main-de-jupyter) et du [tutoriel 2](https:\/\/www.kaggle.com\/leowanty\/tuto-2-numpy-et-pandas).\n\nIl permet aussi de se familiariser avec les concepts de base de la mod\u00e9lisation et certaines notions techniques qui seront utiles pour la compr\u00e9hension et la mise en place d'algorithmes de Deep Learning, comme nous allons le voir dans le prochain tutoriel.\n\nDans ce tutoriel, nous allons :\n- Ouvrir et pr\u00e9parer un jeu de donn\u00e9es\n- Faire du clustering\n- Faire de la classification\n- Faire de la r\u00e9gression\n\nLes \u00e9tapes s'enchaineront rapidement, nous n'effectuerons pas d'analyse pouss\u00e9e des donn\u00e9es ni d'optimisation dans la s\u00e9lection de mod\u00e8les.\n\n## Quelques mots sur scikit-learn\n\nScikit-learn est une biblioth\u00e8que libre Python destin\u00e9e \u00e0 l'apprentissage automatique. Elle est d\u00e9velopp\u00e9e par de nombreux contributeurs, notamment dans le monde acad\u00e9mique par des instituts fran\u00e7ais d'enseignement sup\u00e9rieur et de recherche comme l'Inria et T\u00e9l\u00e9com ParisTech.\n\nElle propose :\n- une synthaxe simple et intuitive\n- des outils simple et efficaces pour le data mining et l'analyse de donn\u00e9e\n- une impl\u00e9mentation d'un grand nombre de mod\u00e8les de machine learning\n- des fonctions pour traiter des probl\u00e8mes connexes (pr\u00e9paration de donn\u00e9es, s\u00e9lection de mod\u00e8les ...)\n- les fonctions sont construites sur NumPy, SciPy (fonctions de calcul num\u00e9rique sur l'opimisation, l'int\u00e9gration, l'alg\u00e8bre lin\u00e9aire, les probabilit\u00e9s ...) et matplotlib (affichage de graphes et d'images)\n\nSur le [site de documentation](https:\/\/scikit-learn.org\/stable\/), les fonctions sont r\u00e9parties en 6 th\u00e8mes :\n- Classification\n- R\u00e9gression\n- Clustering\n- Dimensionality reduction\n- Model selection\n- Preprocessing\n\nLa documentation est tr\u00e8s compl\u00e8te et contient de nombreux exemples facilement r\u00e9utilisables, n'h\u00e9sitez pas \u00e0 y faire quelques recherches !","e8f2183b":"On en conclue que le clustering parvient \u00e0 former des groupes de maisons avec des niveaux de prix plus ou moins homog\u00e8nes :\n- Les clusters 0 et 2 sont principalement compos\u00e9s de maisons peu ch\u00e8res.\n- Les clusters 1, 3 et 4 contiennent des maisons au prix \u00e9lev\u00e9.\n- Le cluster 5 est a peu pr\u00e8s \u00e9quitablement r\u00e9parti entre les trois classes de prix.\n\nQuelle serait notre pr\u00e9cision (accuracy) et notre rappel (recall) si on classait chaque cluster selon la classe dominante ?","e6701b30":"Le *Multi Layer Perceptron Classifier* qui pr\u00e9sente toujours la meilleure accuracy est aussi le mod\u00e8le avec la plus grande variance dans les r\u00e9sultats.\n\nNous lui pr\u00e9f\u00e9rerons donc le *Random Forest Classifier*, pour lequel nous sommes plus certains de la qualit\u00e9 de la classification.\n\nNous aurions pu proc\u00e9der \u00e0 la cross validation avec nos index construits dans la partie sur les index. Voici un exemple de comment nous aurions pu coder \u00e7a (on reprend ici les codes pr\u00e9c\u00e9dents) :","1a50ceb2":"Enfin, pour le model de Random Forest, on affiche la matrice de confusion (ici, de la mod\u00e9lisation sans cross-validation) :","522e75b7":"On entra\u00eene sur notre jeu d'entrainement, puis on regarde l'erreur sur notre jeu de test :"}}