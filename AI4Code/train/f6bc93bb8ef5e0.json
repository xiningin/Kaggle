{"cell_type":{"401cec42":"code","716fcecd":"code","dd981ba7":"code","8ea5d8de":"code","dcf9f0d5":"code","10322813":"code","b787d67b":"code","5288e5de":"code","8d29c599":"code","20472a44":"code","a1e94d34":"code","c44046bd":"code","2b7c479c":"code","812a9e78":"code","c9bdf168":"code","5621c4be":"code","9baaf923":"code","7911e79a":"code","b8b69638":"code","2305c437":"code","55209ff6":"code","65732d72":"code","aa4061cd":"code","daa2d51d":"code","5a15a33c":"code","14f16f1e":"code","928b27e4":"code","4533b2c4":"code","093154cf":"code","c97cf377":"code","0c69e5f7":"code","454a662a":"code","f4518249":"code","e0578663":"code","bdab5f18":"code","4802a5ea":"code","09261a01":"code","926c0a75":"code","8761da52":"code","8916db31":"code","fb72167d":"code","3b80dcd7":"code","a7884060":"code","11313fcc":"code","8a717641":"code","9d5ce8f2":"code","59422bac":"code","4d9a7042":"code","5a6f768c":"code","b971945c":"code","e2b749ad":"code","75379c0e":"code","365862e1":"code","b08e5c54":"code","824c1e52":"code","de894159":"code","23c2ccbc":"code","ed102671":"code","02683afe":"code","645c72fd":"code","03792bd3":"code","57252a5a":"code","1d3f6119":"markdown","64689c7f":"markdown","13745609":"markdown","38d43843":"markdown","78f4c117":"markdown","0572bff6":"markdown","1854cf25":"markdown","d457ee0b":"markdown","b6855d8b":"markdown","c177e08e":"markdown","458cb4b8":"markdown"},"source":{"401cec42":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","716fcecd":"pd.options.display.max_columns = None\npd.options.display.max_rows = None\nsns.set(style=\"whitegrid\", color_codes=True)","dd981ba7":"train = pd.read_csv('..\/input\/train.csv')","8ea5d8de":"holdout = pd.read_csv('..\/input\/test.csv')","dcf9f0d5":"# Read sample submission file\nss = pd.read_csv('..\/input\/sample_submission.csv')","10322813":"df=train.sample(frac=0.1,random_state=200)","b787d67b":"df.head()","5288e5de":"df.shape","8d29c599":"df.info()","20472a44":"X = df.drop('label', axis = 1)","a1e94d34":"y = df['label']","c44046bd":"y.shape","2b7c479c":"y.value_counts().plot(kind = 'bar')","812a9e78":"df.describe()","c9bdf168":"# Missing values & Duplicates","5621c4be":"train.isna().sum().sum()","9baaf923":"test.isna().sum().sum()","7911e79a":"train.duplicated().sum()","b8b69638":"images = X.values.reshape(-1,28,28,1)","2305c437":"g = plt.imshow(images[0][:,:,0])","55209ff6":"y.iloc[0]","65732d72":"# Scaling the features","aa4061cd":"X = X\/255","daa2d51d":"X.describe()","5a15a33c":"from sklearn.model_selection import train_test_split","14f16f1e":"# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)","928b27e4":"from sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV","4533b2c4":"base_model = SVC(kernel = 'rbf')","093154cf":"base_model.fit(X_train, y_train)","c97cf377":"y_pred = base_model.predict(X_test)","0c69e5f7":"print('Accuracy = {}%'.format(round(metrics.accuracy_score(y_test, y_pred),3)*100))","454a662a":"plt.figure(figsize = (8,5))\nsns.heatmap(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred), annot = True, fmt = '0.3g')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')","f4518249":"folds = KFold(n_splits = 5, shuffle = True, random_state = 101)","e0578663":"params = [{'gamma': [0.0001, 0.001, 0.01], 'C': [1, 10, 100, 1000]}]","bdab5f18":"model = SVC(kernel = 'rbf')","4802a5ea":"model_cv = GridSearchCV(estimator=model, param_grid = params, scoring = 'accuracy', \n                        cv = folds, verbose = 1, \n                       return_train_score=True)","09261a01":"model_cv.fit(X_train, y_train)","926c0a75":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results[['param_C', 'param_gamma','mean_train_score', 'mean_test_score']].sort_values(by = 'mean_test_score', \n                                                                                        ascending = False)","8761da52":"plt.figure(figsize = (16,6))\n\n\nplt.subplot(1,3,1)\ngamma_01 = cv_results[cv_results['param_gamma'] == 0.01]\nsns.lineplot(x = 'param_C', y = 'mean_test_score', data = gamma_01)\nsns.lineplot(x = 'param_C', y = 'mean_train_score', data = gamma_01)\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.ylim([0.6,1])\nplt.title('Gamma = 0.01')\nplt.legend(['test_accuracy', 'train_accuracy'], loc = 'upper_left')\nplt.xscale('log')             \n\n                      \nplt.subplot(1,3,2)\ngamma_001 = cv_results[cv_results['param_gamma'] == 0.001]\nsns.lineplot(x = 'param_C', y = 'mean_test_score', data = gamma_001)\nsns.lineplot(x = 'param_C', y = 'mean_train_score', data = gamma_001)\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.ylim([0.6,1])\nplt.title('Gamma = 0.001')\nplt.legend(['test_accuracy', 'train_accuracy'], loc = 'upper_left')\nplt.xscale('log')\n                      \n\nplt.subplot(1,3,3)\ngamma_0001 = cv_results[cv_results['param_gamma'] == 0.0001]\nsns.lineplot(x = 'param_C', y = 'mean_test_score', data = gamma_0001)\nsns.lineplot(x = 'param_C', y = 'mean_train_score', data = gamma_0001)\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.ylim([0.6,1])\nplt.title('Gamma = 0.0001')\nplt.legend(['test_accuracy', 'train_accuracy'], loc = 'upper_left')\nplt.xscale('log')","8916db31":"# printing the optimal accuracy score and hyperparameters\nbest_score = model_cv.best_score_\nbest_hyperparams = model_cv.best_params_\n\nprint(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))","fb72167d":"params_2 = [{'gamma': [0.001, 0.01,0.05], 'C': [0.1,1, 10, 100]}]","3b80dcd7":"model_cv_2 = GridSearchCV(estimator=model, param_grid = params_2, scoring = 'accuracy', \n                        cv = folds, verbose = 1, \n                       return_train_score=True)","a7884060":"model_cv_2.fit(X_train, y_train)","11313fcc":"cv_results_2 = pd.DataFrame(model_cv_2.cv_results_)\ncv_results_2[['param_C', 'param_gamma','mean_train_score', 'mean_test_score']].sort_values(by = 'mean_test_score', \n                                                                                        ascending = False)","8a717641":"plt.figure(figsize = (16,6))\n\n\nplt.subplot(1,3,1)\ngamma_05 = cv_results_2[cv_results_2['param_gamma'] == 0.05]\nsns.lineplot(x = 'param_C', y = 'mean_test_score', data = gamma_05)\nsns.lineplot(x = 'param_C', y = 'mean_train_score', data = gamma_05)\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.ylim([0.6,1])\nplt.title('Gamma = 0.05')\nplt.legend(['test_accuracy', 'train_accuracy'], loc = 'upper_left')\nplt.xscale('log')             \n\n                      \nplt.subplot(1,3,2)\ngamma_01 = cv_results_2[cv_results_2['param_gamma'] == 0.01]\nsns.lineplot(x = 'param_C', y = 'mean_test_score', data = gamma_01)\nsns.lineplot(x = 'param_C', y = 'mean_train_score', data = gamma_01)\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.ylim([0.6,1])\nplt.title('Gamma = 0.01')\nplt.legend(['test_accuracy', 'train_accuracy'], loc = 'upper_left')\nplt.xscale('log')\n                      \n\nplt.subplot(1,3,3)\ngamma_001 = cv_results_2[cv_results_2['param_gamma'] == 0.001]\nsns.lineplot(x = 'param_C', y = 'mean_test_score', data = gamma_001)\nsns.lineplot(x = 'param_C', y = 'mean_train_score', data = gamma_001)\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.ylim([0.6,1])\nplt.title('Gamma = 0.001')\nplt.legend(['test_accuracy', 'train_accuracy'], loc = 'upper_left')\nplt.xscale('log')","9d5ce8f2":"C_final = model_cv.best_params_['C']\ngamma_final = model_cv.best_params_['gamma']","59422bac":"model_f = SVC(C = C_final, gamma = gamma_final, kernel = 'rbf')","4d9a7042":"model_f.fit(X_train, y_train)","5a6f768c":"y_test_pred = model_f.predict(X_test)","b971945c":"print(\"Accuracy on test data = {}%\".format(round(metrics.accuracy_score(y_test, y_test_pred),2)*100))","e2b749ad":"plt.figure(figsize = (8,5))\nsns.heatmap(metrics.confusion_matrix(y_true=y_test, y_pred=y_test_pred), annot = True, fmt = '0.3g')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')","75379c0e":"holdout.head()","365862e1":"holdout.shape","b08e5c54":"holdout_scaled = holdout\/255","824c1e52":"holdout_pred = model_f.predict(holdout_scaled)","de894159":"holdout_pred","23c2ccbc":"# Checking sample submission file\nss.head()","ed102671":"submission = pd.DataFrame(list(zip(holdout.index, holdout_pred)), columns = ['ImageId', 'Label'])","02683afe":"submission['ImageId'] = submission['ImageId'].apply(lambda x: x+1)","645c72fd":"submission.head()","03792bd3":"submission.to_csv(\"Nischay_svm_mnist.csv\",index=False)","57252a5a":"submission.shape","1d3f6119":"# Step 4: SVM Modelling","64689c7f":"## Base modeling (Non-linear kernel)","13745609":"## Hyperparameter Tuning","38d43843":"**With higher gamma (0.05 from 0.01) - we don't see any significant improvement in test accuracy - so we'll keep the optimal hyperparamaters as identified in original hyperparameter tuning, i.e. C = 10, gamma = 0.01**","78f4c117":"# Step 5: Prediction for Test & Holdout data","0572bff6":"# Step 2: Data Cleaning","1854cf25":"# Step 1: Reading and Understanding the Data","d457ee0b":"## Prediction for Holdout data","b6855d8b":"## Prediction for test data","c177e08e":"# Step 3: Data Preparation","458cb4b8":"### Further hyperparameter tuning\nTrying more values for gamma & C"}}