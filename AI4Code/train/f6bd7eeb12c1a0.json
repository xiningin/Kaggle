{"cell_type":{"dcdd1945":"code","d4bbe228":"code","a0825bf4":"code","f3fa45d8":"code","cd1a5075":"code","03aa77be":"code","6878a01c":"code","bc443012":"code","dba79342":"code","fbf8ae9c":"code","3488f0b8":"code","1ccd52c2":"code","a75e4576":"code","aac54fb8":"code","df85cce2":"code","bbbe32e7":"code","bd33d584":"code","7c29183c":"code","8b84d100":"code","db931109":"code","9d732fe6":"code","7895dfba":"code","cd39f162":"code","21a9c751":"code","582d01bd":"code","0d7debe3":"code","00b70dcc":"code","f8538c78":"code","79d5e83d":"code","a6518a42":"code","cf16a450":"code","8939fb09":"code","d61292dd":"code","2a3f47c2":"code","e5284395":"code","6cc184a2":"markdown","f7b334d9":"markdown","4d8449a9":"markdown","9e3e55ab":"markdown","a969fe62":"markdown","358df259":"markdown","395d88cf":"markdown","88cf4c0e":"markdown","46477948":"markdown","885d5ebd":"markdown"},"source":{"dcdd1945":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","d4bbe228":"data = pd.read_csv('..\/input\/mental-health-in-tech-survey\/survey.csv')","a0825bf4":"data","f3fa45d8":"data.isna().sum()","cd1a5075":"data = data.drop('comments', axis=1)","03aa77be":"data['self_employed'].unique()","6878a01c":"data['self_employed'].mode()","bc443012":"data['self_employed'] = data['self_employed'].fillna('No')","dba79342":"data['work_interfere'].unique()","fbf8ae9c":"data['work_interfere'].mode()","3488f0b8":"data['work_interfere'] = data['work_interfere'].fillna('Sometimes')","1ccd52c2":"data","a75e4576":"data['Timestamp']","aac54fb8":"data['Year'] = data['Timestamp'].apply(lambda x: np.int(x[0:4]))\ndata['Month'] = data['Timestamp'].apply(lambda x: np.int(x[5:7]))\ndata['Day'] = data['Timestamp'].apply(lambda x: np.int(x[8:10]))\n\ndata['Hour'] = data['Timestamp'].apply(lambda x: np.int(x[11:13]))\ndata['Minute'] = data['Timestamp'].apply(lambda x: np.int(x[14:16]))\ndata['Second'] = data['Timestamp'].apply(lambda x: np.int(x[17:19]))\n\ndata = data.drop('Timestamp', axis=1)","df85cce2":"data","bbbe32e7":"{column: len(data[column].unique()) for column in data.select_dtypes('object').columns}","bd33d584":"{column: list(data[column].unique()) for column in data.select_dtypes('object').columns}","7c29183c":"def encode_gender(x):\n    if x.lower()[0] == 'f':\n        return 0\n    elif x.lower()[0] == 'm':\n        return 1\n    else:\n        return 2","8b84d100":"data['Gender'] = data['Gender'].apply(encode_gender)","db931109":"target = 'treatment'\n\nbinary_features = [\n    'self_employed',\n    'family_history',\n    'remote_work',\n    'tech_company',\n    'obs_consequence'\n]\n\nordinal_features = [\n    'work_interfere',\n    'no_employees'\n]\n\nnominal_features = [\n    'Country',\n    'state',\n    'benefits',\n    'care_options',\n    'wellness_program',\n    'seek_help',\n    'anonymity',\n    'leave',\n    'mental_health_consequence',\n    'phys_health_consequence',\n    'coworkers',\n    'supervisor',\n    'mental_health_interview',\n    'phys_health_interview',\n    'mental_vs_physical'\n]","9d732fe6":"def binary_encode(df, columns, positive_values):\n    df = df.copy()\n    for column, positive_value in zip(columns, positive_values):\n        df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n    return df\n\ndef ordinal_encode(df, columns, orderings):\n    df = df.copy()\n    for column, ordering in zip(columns, orderings):\n        df[column] = df[column].apply(lambda x: ordering.index(x))\n    return df\n\ndef onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","7895dfba":"binary_positive_values = ['Yes' for feature in binary_features]\n\nordinal_orderings = [\n    ['Never', 'Rarely', 'Sometimes', 'Often'],\n    ['1-5', '6-25', '26-100', '100-500', '500-1000', 'More than 1000']\n]\n\nnominal_prefixes = [\n    'co',\n    'st',\n    're',\n    'be',\n    'ca',\n    'we',\n    'se',\n    'an',\n    'le',\n    'mc',\n    'ph',\n    'cw',\n    'su',\n    'mi',\n    'pi',\n    'mp'\n]","cd39f162":"data = binary_encode(\n    data,\n    columns=binary_features,\n    positive_values=binary_positive_values\n)\n\ndata = ordinal_encode(\n    data,\n    columns=ordinal_features,\n    orderings=ordinal_orderings\n)\n\ndata = onehot_encode(\n    data,\n    columns=nominal_features,\n    prefixes=nominal_prefixes\n)","21a9c751":"data","582d01bd":"data = binary_encode(data, columns=['treatment'], positive_values=['Yes'])","0d7debe3":"print(\"Remaining non-numeric columns:\", len(data.select_dtypes('object').columns))","00b70dcc":"print(\"Remaining missing values:\", data.isna().sum().sum())","f8538c78":"y = data['treatment'].copy()\nX = data.drop('treatment', axis=1).copy()","79d5e83d":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","a6518a42":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=100)","cf16a450":"X.shape","8939fb09":"print(\"Class Distribution (Positive to Negative): {:.1f}% \/ {:.1f}%\".format(y_train.mean() * 100, (1 - y_train.mean()) * 100))","d61292dd":"inputs = tf.keras.Input(shape=(X.shape[1],))\nx = tf.keras.layers.Dense(1024, activation='relu')(inputs)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)\n\n\nbatch_size = 64\nepochs = 50\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau()\n    ]\n)","2a3f47c2":"plt.figure(figsize=(12, 6))\n\nplt.plot(range(epochs), history.history['accuracy'], label=\"Training Accuracy\")\nplt.plot(range(epochs), history.history['val_accuracy'], label=\"Validation Accuracy\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\n\nplt.legend()\nplt.title(\"Accuracy Over Time\")\n\nplt.show()","e5284395":"model.evaluate(X_test, y_test)","6cc184a2":"# Getting Started","f7b334d9":"# Encoding Features","4d8449a9":"# Splitting\/Scaling","9e3e55ab":"# Results","a969fe62":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/G0Wh-xTnCHs","358df259":"# Encoding Labels","395d88cf":"# Cleaning","88cf4c0e":"# Training","46477948":"# Task for Today  \n\n***\n\n## Mental Health Treatment Prediction  \n\nGiven *data about the mental health of employees in the tech industry*, let's try to predict whether a given subject has **sought treatment** in the past.  \n  \nWe will use a TensorFlow ANN to make our predictions.","885d5ebd":"# Feature Engineering"}}