{"cell_type":{"91b14a7d":"code","615696ce":"code","f22faeb7":"code","39b4d7c4":"code","195f8980":"code","0340bc53":"code","521e48ac":"code","6518be46":"code","a707df22":"code","0b892f3c":"code","0ba0383a":"code","2d86110c":"code","e672801d":"code","c8b32319":"code","2f73f1e7":"code","d8bb9d19":"code","aa549272":"code","1a1a44e0":"code","551b5b39":"markdown","ebdfe4df":"markdown","f341b4e9":"markdown","37fd8218":"markdown","062ecd18":"markdown","e2e601d7":"markdown","9c67c62e":"markdown","57ee0e4d":"markdown","8792deed":"markdown","8efcb47d":"markdown","174ca9ce":"markdown"},"source":{"91b14a7d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","615696ce":"df = pd.read_csv('\/kaggle\/input\/us-news-and-world-reports-college-data\/College.csv',index_col=0)\ndf.head()","f22faeb7":"df.info()","39b4d7c4":"df.describe()","195f8980":"def converter(cluster):\n    if cluster=='Yes':\n        return 1\n    else:\n        return 0","0340bc53":"df['Private'] = df['Private'].apply(converter)\ndf.info()","521e48ac":"X = df.drop(['Private'],axis=1)\ny = df[\"Private\"]","6518be46":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif, mutual_info_classif","a707df22":"f_classif = SelectKBest(score_func=f_classif, k=11)","0b892f3c":"fit = f_classif.fit(X,y)","0ba0383a":"features = fit.transform(X)\nfeatures","2d86110c":"cols = fit.get_support(indices=True)\ndf.iloc[:,cols]","e672801d":"x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,cols], y, test_size=0.25, random_state=42)\n","c8b32319":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler().fit(x_train)\nx_scaled = scaler.transform(x_train)\n\nkmeans = KMeans(n_clusters=2, random_state = 100)\n\nkmeans.fit(x_scaled)","2f73f1e7":"scaler = preprocessing.StandardScaler().fit(x_test)\nx_test_scaled = scaler.transform(x_test)","d8bb9d19":"y_pred = kmeans.predict(x_test_scaled)\nprint(classification_report(y_test,y_pred))","aa549272":"from sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(x_scaled, x_test_scaled, y_train, y_test):\n    kmeans = KMeans(n_clusters=2, random_state = 100)\n    kmeans.fit(x_scaled)\n    preds = kmeans.predict(x_test_scaled)\n    return mean_absolute_error(y_test, preds)","1a1a44e0":"print(\"MAE:\")\nprint(score_dataset(x_scaled, x_test_scaled, y_train, y_test))","551b5b39":"Let's preprocess our selected features to improve our model prediction ","ebdfe4df":"After running the model a couple times, we decided to use eleven features as a parameter to our feature classifier.","f341b4e9":"We can see that our dataset does not have NaN values","37fd8218":"Then, we load our dataset in df and take a look at its first 5 row of the data. It's a nice way to get an overview of the data.","062ecd18":"Using mae to check our model","e2e601d7":"Applying function converter","9c67c62e":"Defining our function to convert categorical variables","57ee0e4d":"\nAt first we import the necessary librarys","8792deed":"Defining our label and inputs","8efcb47d":"Getting the chosen features","174ca9ce":"Importing methods to auxiliate in the choosing of our features"}}