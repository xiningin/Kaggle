{"cell_type":{"16b06392":"code","0fe16523":"code","907b9292":"code","34aef465":"code","3f722833":"code","205c0e25":"code","1a90c78a":"code","aae36bc0":"code","9dc8750b":"code","a4d5ae8d":"code","f7e1e820":"code","0ebbfef6":"code","22209941":"code","dbb14a0e":"code","7d5ef9ee":"code","9425eb7c":"code","1da8bc16":"code","01b9a16e":"code","d5aad445":"code","9256cc3f":"code","7e646e30":"code","b5969efa":"code","5c8ca74d":"code","03aff81e":"code","25add6de":"code","1c7f7c54":"code","bae35e13":"markdown","48eacdd0":"markdown","a73aa151":"markdown","0515ecc5":"markdown","7cc55472":"markdown","f1df0ee6":"markdown","b25764d1":"markdown","b5c4ced3":"markdown","b26680b4":"markdown","92355bfc":"markdown","9c426242":"markdown","50f5b101":"markdown","be3850f4":"markdown","aa103260":"markdown","0535ee74":"markdown","637b0663":"markdown","b2910601":"markdown","ef0a5901":"markdown","9a8968c8":"markdown","57723038":"markdown","f7a8d5b9":"markdown","3d5f6694":"markdown","16873c6f":"markdown"},"source":{"16b06392":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom pandas_profiling import ProfileReport\nfrom pandas.plotting import lag_plot,autocorrelation_plot\n\nsns.set_style('ticks')\npd.set_option('display.max_columns',500)","0fe16523":"df = pd.read_csv('\/kaggle\/input\/transaction_dataset.csv')","907b9292":"class Preprocessor:\n    \"\"\"\n    This is the base Preprocessor class that will be using for \n    any data preprocessing required\n    \"\"\"\n    def __init__(self,df):\n        self.df = df\n\n    def clean(self):\n        self.remove_features()\n        self.drop_duplicates()\n    \n    def add_columns(self,inference=0):\n        \"\"\"\n        This method adds columns to the data fetched via the REST API\n        Parameters:\n        filename = the name of the file, without the .csv extension\n        Returns:\n        df = A DataFrame of the dataset with columns\n        \"\"\"\n        # Define list of columns\n        cols = ['Index',\n                         'Address',\n                         'FLAG',\n                         'Avg min between sent tnx',\n                         'Avg min between received tnx',\n                         'Time Diff between first and last (Mins)',\n                         'Sent tnx',\n                         'Received Tnx',\n                         'Number of Created Contracts',\n                         'Unique Received From Addresses',\n                         'Unique Sent To Addresses',\n                         'min value received',\n                         'max value received ',\n                         'avg val received',\n                         'min val sent',\n                         'max val sent',\n                         'avg val sent',\n                         'min value sent to contract',\n                         'max val sent to contract',\n                         'avg value sent to contract',\n                         'total transactions (including tnx to create contract',\n                         'total Ether sent',\n                        #  'total ether received',\n                         'total ether sent contracts',\n                         'total ether balance',\n                         ' Total ERC20 tnxs',\n                         ' ERC20 total Ether received',\n                         ' ERC20 total ether sent',\n                         ' ERC20 total Ether sent contract',\n                         ' ERC20 uniq sent addr',\n                         ' ERC20 uniq rec addr',\n                         ' ERC20 uniq sent addr.1',\n                         ' ERC20 uniq rec contract addr',\n                         ' ERC20 avg time between sent tnx',\n                         ' ERC20 avg time between rec tnx',\n                         ' ERC20 avg time between rec 2 tnx',\n                         ' ERC20 avg time between contract tnx',\n                         ' ERC20 min val rec',\n                         ' ERC20 max val rec',\n                         ' ERC20 avg val rec',\n                         ' ERC20 min val sent',\n                         ' ERC20 max val sent',\n                        #  ' ERC20 avg val sent',\n                         ' ERC20 min val sent contract',\n                         ' ERC20 max val sent contract',\n                         ' ERC20 avg val sent contract',\n                         ' ERC20 uniq sent token name',\n                         ' ERC20 uniq rec token name',\n                         ' ERC20 most sent token type',\n                         ' ERC20_most_rec_token_type']\n\n        # Read file,assign cols\n        self.df.columns = cols\n\n    def remove_features(self,inference=False):\n        \"\"\"\n        This method removes unnecessary features\n        Returns:\n        \n        df = a DataFrame without unneeded features\n        \"\"\"\n        # Remove unnecessary fields\n        self.df.drop(['Index','Address', ' ERC20 uniq sent token name',\n ' ERC20 uniq rec token name',\n ' ERC20 most sent token type',\n ' ERC20_most_rec_token_type',' ERC20 min val sent contract',' ERC20 max val sent contract',' ERC20 avg val sent contract','min value sent to contract','max val sent to contract','avg value sent to contract',' ERC20 avg time between sent tnx',' ERC20 avg time between rec tnx',' ERC20 avg time between rec 2 tnx','total ether sent contracts',' ERC20 avg time between contract tnx',' ERC20 total Ether sent contract',' ERC20 uniq sent addr.1'],axis=1,inplace=True)\n    def drop_duplicates(self):\n        self.df.drop_duplicates(inplace=True)","34aef465":"preprocessor = Preprocessor(df)\npreprocessor.remove_features()","3f722833":"ProfileReport(df,minimal=True)","205c0e25":"df.head(5)","1a90c78a":"df.info()","aae36bc0":"df.nunique()","9dc8750b":"df.skew()","a4d5ae8d":"df.describe()","f7e1e820":"df.isnull().sum()","0ebbfef6":"print('Percentage of missing rows: ' + str(round(((829\/len(df)) * 100),1)) + '%') ","22209941":"df[df.isnull().T.any()]","dbb14a0e":"df[df.isnull().T.any()]['FLAG'].value_counts()","7d5ef9ee":"sns.countplot(df['FLAG'])\nplt.show()","9425eb7c":"df['FLAG'].value_counts()","1da8bc16":"print('Percentage of non-fraudulent instances: ' + str(round(((7662\/len(df)) * 100))) + '%') ","01b9a16e":"print('Percentage of fraudulent instances: ' + str(round(((2179\/len(df)) * 100))) + '%') ","d5aad445":"df.skew()","9256cc3f":"sns.kdeplot(df.dropna()[' ERC20 avg val sent'],bw=1.5)\nplt.show()","7e646e30":"sns.kdeplot(boxcox1p(df.dropna()[' ERC20 avg val sent'],boxcox_normmax(df.dropna()[' ERC20 avg val sent'] + 1)), bw=1.5)\nplt.show()","b5969efa":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(),annot=False,cmap='coolwarm',fmt='')\nplt.show()","5c8ca74d":"df.corr()['FLAG'].sort_values(ascending=False)[1:]","03aff81e":"plt.figure(figsize=(10,10))\nsns.barplot(df['Number of Created Contracts'],df['FLAG'])\nplt.show()","25add6de":"plt.figure(figsize=(15,15))\nautocorrelation_plot(df['total ether balance'])\nplt.show()","1c7f7c54":"plt.figure(figsize=(10,10))\nlag_plot(df['total ether balance'])\nplt.show()","bae35e13":"<h1>Q3. Is the data skewed?<\/h1>","48eacdd0":"If we plot a KDE plot of `ERC20 avg val sent`:","a73aa151":"We can clearly see here that the data is heavily imblanced, with only 22% of the accounts considered as fraudulent. Possible courses of action:\n\n1. Oversampling\/Undersampling.\n2. Leaving it as it is for the model.","0515ecc5":"Our theory is true; All the missing values are of the positive class!","7cc55472":"We can also see here that the majority of our features are heavily skewed, so we will have to apply feature engineering and possibly some transformations to the features","f1df0ee6":"As we can see, there seems to be no real correlations at all between features, with the highest correled feature being the `Time Diff between first and last (Mins)`, with a correlation of around -0.26. However, there could be some underlying correlations:","b25764d1":"Clearly here we can see that the majority of the data points are random, with the autocorrelation plot showing us that most of the points are located in the 99% confidence band. \n\nThe lag plot shows a similar story, with many of the points clustered at the center, showing us that the data has a few non-zero values, but the points are mainly non-zero, and do not follow any trend","b5c4ced3":"The answer is yes, and we see that some features, such as `ERC20 avg val sent`, are heavily skewed, with most of the weight being on the left tail. Except `total ether balance`, which is slightly skewed to the right","b26680b4":"Here we can seew that the features all lie in different ranges. Usually, we would normalise our features before training, however I am going to use a tree-based model, so normalisation is not needed here","92355bfc":"Here, we notice something; all the missing values seem to belong to fraudulent accounts. We can confirm this:","9c426242":"We get data that is normally distributed!","50f5b101":"8.4% of our data is missing. Possible courses of action:\n\n1. Drop NaN value rows\n2. Impute NaN value rows","be3850f4":"This is the `Preprocessor` class being called. All I am doing for now is removing unneeded features","aa103260":"<h1>Q2: Is the data balanced?<\/h1>","0535ee74":"<h1>Q1. Do we have any missing values?<\/h1>","637b0663":"<h1> Ethereum Fraud Detection EDA <\/h1>\n\n<h3>the purpose of this notebook is to gain a better understanding of the data. The following questions are going to be asked:<\/h3>\n<h4>Q1. Do we have any missing values?<\/h4>\n<h4>Q2. Is the data balanced?<\/h4>\n<h4>Q3. Is the data skewed?<\/h4>\n<h4>Q4. What feature values often belong to fraud accounts?<\/h4>\n<h4>Q5. Is our data random or does it follow a certain trend?<\/h4>","b2910601":"We can see that there are 12 features, each missing 829 rows. In other words:","ef0a5901":"Straight away, we can see that there are several features with missing values. Either Imputation or Removal will be required","9a8968c8":"<h1>Q4. What feature values often belong to fraud accounts?<\/h1>","57723038":"Let's take a closer look the rows with missing values:","f7a8d5b9":"<h1>Q5. Is our data random or does it follow a certain trend?<\/h1>","3d5f6694":"We can see that the more contacts a user has created, the more likely they are to be of a fraudulent transaction","16873c6f":"We get this plot, with some random distribution. However, when we perform a boxcox transformation of the data:"}}