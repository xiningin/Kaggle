{"cell_type":{"7d5eb6e5":"code","f20f6bd1":"code","73cc4a29":"code","954abfb9":"code","c27eafc7":"code","84fa3247":"code","3dc0ef16":"code","62668e3d":"code","ef64b243":"code","cc757adc":"code","203232f3":"code","dbaa5c00":"code","49d93df6":"code","e7fbe09e":"code","89969e2b":"code","d484eeb0":"code","f3493b34":"code","6630468a":"markdown","6329a4a8":"markdown","2da899a8":"markdown","15615c63":"markdown","606e4b9d":"markdown","6740a3dd":"markdown","1f00e21a":"markdown","c009ced8":"markdown","4f47fb18":"markdown","9e627434":"markdown"},"source":{"7d5eb6e5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #For data visualization\nimport numpy as np #For data processing on series\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f20f6bd1":"print(\"Hello Capstone Project Course!\")","73cc4a29":"df = pd.read_csv(\"..\/input\/capstone-car-accident-serveity\/Data_Collisions.csv\")\ndf.info() #Analysing data types of each column","954abfb9":"df.nunique() #Analysing number of unique values per column","c27eafc7":"df.isna().sum() #Finding total number of missing values in the data.","84fa3247":"sns.heatmap(df.isnull(), cbar=False) #Visualizing the missing values","3dc0ef16":"df.describe()","62668e3d":"corr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","ef64b243":"df[\"ST_COLCODE\"] = df[\"ST_COLCODE\"].fillna(df[\"ST_COLCODE\"].mode()[0])\ndf[\"UNDERINFL\"] = df[\"UNDERINFL\"].fillna(df[\"UNDERINFL\"].mode()[0])\ndf[\"X\"] = df[\"X\"].fillna(df[\"X\"].median())\ndf[\"Y\"] = df[\"Y\"].fillna(df[\"Y\"].median())\ndf[\"LIGHTCOND\"] = df[\"LIGHTCOND\"].fillna(df[\"LIGHTCOND\"].mode()[0])\ndf = df.drop([\"SDOTCOLNUM\",\"INTKEY\",\"COLDETKEY\",\"SEVERITYCODE.1\",\"SPEEDING\" ,\"EXCEPTRSNDESC\",\"PEDROWNOTGRNT\",\"INATTENTIONIND\",\"EXCEPTRSNCODE\",\"LOCATION\",\"INCDATE\",\"INCDTTM\",\"OBJECTID\",\"REPORTNO\",\"SDOT_COLDESC\",\"ST_COLDESC\",\"ST_COLCODE\",\"SEVERITYDESC\"], axis=1)\ndf.info()","cc757adc":"df.dtypes","203232f3":"\n#Making a list of all categorical variables\nclmn = {\"STATUS\",\"ADDRTYPE\",\"COLLISIONTYPE\",\"JUNCTIONTYPE\",\"UNDERINFL\",\"WEATHER\",\"ROADCOND\",\"LIGHTCOND\",\"HITPARKEDCAR\"}\n\n#Converting them into dummy variables\ndf = pd.get_dummies(data=df,columns=clmn,prefix=clmn)\n\n#Concatnating them to the dataframe\ndf.dtypes","dbaa5c00":"df.shape","49d93df6":"X = df.drop([\"SEVERITYCODE\"],axis=1)\ny = df[\"SEVERITYCODE\"]\n","e7fbe09e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n\nLR = LogisticRegression(max_iter=100000)\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\n\nLR.fit(X_train,y_train)\nscore = LR.score(X_test, y_test)\nprint(score)\n\n#y_pred = LR.predict(X_test)\n\n\nplot_confusion_matrix(LR,X_test,y_test)\n\ny_pred = LR.predict(X_test) \nprint(classification_report(y_test, y_pred))\n","89969e2b":"from sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import  cross_val_score\n\nDT = DecisionTreeClassifier()\n\nDT.fit(X_train,y_train)\nscore_1 = DT.score(X_test, y_test)\nprint(score_1)\nfrom sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(DT,X_test,y_test)\n\ny_pred_1 = DT.predict(X_test) \n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_1))\n","d484eeb0":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n\nrandom_forest.fit(X_train,y_train)\nscore_2 = random_forest.score(X_test, y_test)\nprint(score_2)\n\nplot_confusion_matrix(random_forest,X_test,y_test)\n\n\ny_pred_2 = random_forest.predict(X_test) \n\nprint(classification_report(y_test, y_pred_2))\n\n\n","f3493b34":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier()\n\nxgb.fit(X_train,y_train)\nscore_3 = xgb.score(X_test, y_test)\nprint(score_3)\n\nplot_confusion_matrix(xgb,X_test,y_test)\n\n\ny_pred_3 = xgb.predict(X_test) \n\nprint(classification_report(y_test, y_pred_3))","6630468a":"# Using Decision Tree Classifier","6329a4a8":"# Using XGBoost Classifier","2da899a8":"# Splitting data into two dataframes. ","15615c63":"# Converting Categorical variables to Dummy","606e4b9d":"# Data Visualization","6740a3dd":"# Using Logistic Regression Model","1f00e21a":"From the above correlation matrix we find out that datafields \"SDOTCOLNUM\", \"INCKEY\", \"COLDETKEY\" & \"OBJECTID\" are highly correlated. Hence we can drop 3 columns from them. As \"OBJECTID\" does not have any NaN values hence we can use that . Also there are two identical columns \"SEVERITYCODE.1\" and \"SEVERITYCODE\" hence we can drop 1 of them as well.","c009ced8":"# Using Random Forest Classifier","4f47fb18":"# Introduction\n\nIn this capstone project we are given data of car accidents and have to predict the severity of accident. \nThere are total 38 columns, 1 of which is the severity itself.\nFirst let us import the data and explore some of its basic features such as data-types of columns, Missing values ..etc.","9e627434":"The following data columns have missing values more than 50% of the total entries.\n1. **EXCEPTRSNDESC**\n2. **SPEEDING**\n3. **PEDROWNOTGRNT**\n4. **INATTENTIONIND**\n\nWe can use the NaN values as a separate \"unkown\" variable and move forward.\n"}}