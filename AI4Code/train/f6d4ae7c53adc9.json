{"cell_type":{"7960e54b":"code","2300191a":"code","a7d9df45":"code","27374365":"code","f52efa22":"code","acbe4bf7":"code","5d5bf472":"code","db443cbd":"code","73e6a925":"code","109583ce":"code","5ed0f29e":"code","215e916b":"code","edd89b5d":"code","b2f94cf9":"code","853c3063":"code","764e9f7e":"code","9da60c65":"code","9290946b":"code","a0f6d61a":"markdown","cc1af826":"markdown","473c613f":"markdown","6c9eeb84":"markdown","34129d7b":"markdown","e1bdaec7":"markdown","ef8a5246":"markdown","7679dfe0":"markdown"},"source":{"7960e54b":"import pandas as pd\nimport numpy as np\n\n# Visualization\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\n\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance","2300191a":"csv_filepath = \"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\ndata = pd.read_csv(csv_filepath)\ndata.head()","a7d9df45":"data.info()","27374365":"data.shape","f52efa22":"data.isnull().sum()","acbe4bf7":"def plot_pie(df):\n  labels = [\"No\", \"Yes\"]\n  values = df[\"Churn\"].value_counts().to_list()\n\n  colors = ['gold', 'royalblue']\n\n  # Pie plot\n  fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4)])\n  fig.update_traces(hoverinfo=\"label+value+text\", textfont_size=20, textinfo=\"value\",\n                   marker=dict(colors=colors, line=dict(color=\"white\", width=2)))\n  fig.update_layout(dict(title=\"Customer Churn\"))\n  fig.show()","5d5bf472":"plot_pie(data)","db443cbd":"def distribution_pie_plot(df, column):\n  churn = df[df[\"Churn\"] == \"Yes\"]\n  no_churn = df[df[\"Churn\"] == \"No\"]\n\n\n  # Create subplots: use 'domain' type for Pie subplot\n  fig = make_subplots(rows=1, cols=2, specs=[[{\"type\" : \"domain\"}, {\"type\": \"domain\"}]])\n  # Churn\n  fig.add_trace(go.Pie(values=churn[column].value_counts().values.tolist(), \n                       labels=churn[column].value_counts().keys().tolist(), \n                       name=\"Churn\"),\n                1, 1)\n  # No Churn\n  fig.add_trace(go.Pie(values=no_churn[column].value_counts().values.tolist(), \n                       labels=no_churn[column].value_counts().keys().tolist(), \n                       name=\"No Churn\"),\n                1, 2)\n  \n  fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\n  fig.update_layout(title_text= column + \"\\n\" + \"Distribution Customer Analysis\",\n                     # Add annotations in the center of the donut pies\n                     annotations=[\n                                  dict(text=\"Churn\", x=0.18, y=0.5, font_size=20, showarrow=False),\n                                  dict(text=\"No Churn\", x=0.82, y=0.5, font_size=20, showarrow=False)\n                     ])\n  fig.show()","73e6a925":"category_columns = [\"Contract\", \"gender\", \"Partner\",\t\"Dependents\", \"PhoneService\", \"MultipleLines\", \"OnlineSecurity\",\"OnlineBackup\",\t\n                    \"DeviceProtection\",\t\"TechSupport\",\t\"StreamingTV\", \"StreamingMovies\" , \"PaperlessBilling\", \"PaymentMethod\"]\n\n#for all categorical columns plot pie and distribution    \nfor col in category_columns:\n    distribution_pie_plot(data, col)","109583ce":"def distribution_histogram(df, column):\n  churn = df[df[\"Churn\"] == \"Yes\"]\n  no_churn = df[df[\"Churn\"] == \"No\"]\n\n\n  # Create subplots: use 'domain' type for Pie subplot\n  fig = go.Figure()\n  # Churn\n  fig.add_trace(go.Histogram(x=churn[column],\n                             histnorm=\"percent\",\n                             name=\"Churn\",\n                             marker=dict(line = dict(width=0.5, color=\"black\")),\n                             opacity=0.75)\n  )\n  # No Churn\n  fig.add_trace(go.Histogram(x=no_churn[column],\n                             histnorm=\"percent\",\n                             name=\"No Churn\",\n                             marker=dict(line = dict(width=0.5, color=\"black\")),\n                             opacity=0.75)\n  )\n  \n  fig.update_layout(title_text= column + \"\\n\" + \"Histogram Customer Analysis\",\n                    bargap=0.2,\n                    bargroupgap=0.1,\n                    # xaxis label\n                     xaxis = dict(gridcolor=\"white\",\n                                  title = column,\n                                  zerolinewidth=1,\n                                  ticklen=5,\n                                  gridwidth=2), \n                    # yaxis label\n                    yaxis = dict(gridcolor=\"white\",\n                                title = \"percent\",\n                                zerolinewidth=1,\n                                ticklen=5,\n                                gridwidth=2)\n                    )\n  fig.show()","5ed0f29e":"num_columns = [\"SeniorCitizen\", \"tenure\", \"MonthlyCharges\",\t\"TotalCharges\"]\nfor col in num_columns:\n  distribution_histogram(data, col)","215e916b":"category_columns = [\"Contract\", \"gender\", \"Partner\",\t\"Dependents\", \"PhoneService\", \"MultipleLines\", \n                    \"InternetService\", \"OnlineSecurity\",\"OnlineBackup\", \"DeviceProtection\",\t\"TotalCharges\",\n                    \"TechSupport\",\t\"StreamingTV\", \"StreamingMovies\" , \"PaperlessBilling\", \"PaymentMethod\", \"Churn\"]\n\n# Encode Categorical Columns\nlabelencoder = LabelEncoder()\ndata[category_columns] = data[category_columns].apply(labelencoder.fit_transform)\ndata.head(5)","edd89b5d":"def get_correlation(df):\n  correlation = df.corr()\n  # Labels\n  cols_matrix = correlation.columns.tolist()\n  # Convert to numpy array \n  correlation_arr = np.array(correlation)\n\n  # Plot\n  fig = go.Figure()\n  fig.add_trace(go.Heatmap(x = cols_matrix,\n                           y = cols_matrix,\n                           z = correlation_arr,\n                           colorscale = \"Viridis\",\n                           colorbar = dict(title = \"Pearson Correlation coefficient\",\n                                           titleside = \"right\"))\n  )\n  fig.update_layout(dict(title = \"Correlation Matrix\",\n                      height = 770,\n                      width = 900,\n                      autosize = False,\n                      yaxis = dict(tickfont = dict(size = 9)),\n                      xaxis = dict(tickfont = dict(size = 9)),\n                      )\n  )\n  fig.show()","b2f94cf9":"get_correlation(data)","853c3063":"Y = data[\"Churn\"]\nX = data.drop([\"Churn\", \"customerID\"], axis=1)\nprint(\"Shape of X = {}\".format(X.shape))\nprint(\"Shape of Y = {}\".format(Y.shape))\n\n# Normalize data\nscaler = MinMaxScaler()\nscaler.fit(X)\nX = scaler.transform(X)\n\n# Separate train and test data\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n\nprint(\"Shape of X_train = {}\".format(X_train.shape))\nprint(\"Shape of X_test = {}\".format(X_test.shape))\nprint(\"Shape of Y_train = {}\".format(Y_train.shape))\nprint(\"Shape of Y_test = {}\".format(Y_test.shape))","764e9f7e":"import xgboost as xgb","9da60c65":"# use DMatrix for xgbosot\nd_train_Matrix = xgb.DMatrix(X_train, label=Y_train)\nd_test_Matrix = xgb.DMatrix(X_test, label=Y_test)\n\n# set xgboost params\nparam = {\n    \"max_depth\" : 3,\n    \"eta\" : 0.3,\n    \"silent\" : 1,\n    \"objective\": \"multi:softprob\",\n    \"num_class\" : 2,\n\n}\n\n# the number of training iterations\nnum_iteration = 20 \n\n# training and testing - numpy matrices\nmodel = xgb.train(param, d_train_Matrix, num_iteration)\n# Prediction\npred = model.predict(d_test_Matrix)\n\n# extracting most confident predictions\nbest_pred = np.asarray([np.argmax(feature) for feature in pred])\n\n# Eval model\nprint(\"Accuracy score = {}\".format(accuracy_score(Y_test, best_pred)))\nprint(\"Percision score = {}\".format(precision_score(Y_test, best_pred, average=\"macro\")))\nprint(\"Recall score = {}\".format(recall_score(Y_test, best_pred, average=\"macro\")))","9290946b":"plot_importance(model)\nplt.show()","a0f6d61a":"**Feature importance**","cc1af826":"**Correlation**","473c613f":"# XGBoost Model","6c9eeb84":"**Build the model**","34129d7b":"**Histogram for distribution of numerical columns**","e1bdaec7":"**Distribution customers analysis**","ef8a5246":"** Import Packages **","7679dfe0":"**Prepare train set and test set**"}}