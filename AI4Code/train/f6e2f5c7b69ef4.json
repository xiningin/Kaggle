{"cell_type":{"23ffba2c":"code","ec9f82a3":"code","1f519bcf":"code","b8a111f2":"code","de753606":"code","8ca3937e":"code","b592390f":"code","706c9163":"code","bb596a8e":"code","200cb9d3":"code","309a5c05":"code","354371d2":"code","b0c594d9":"code","c42af4dd":"code","51a7d00a":"code","3676ca05":"code","37452956":"code","ff136c26":"code","f1b57e4b":"code","a7458c37":"code","661dda96":"code","02de087a":"code","64ac4625":"code","7a1a66c7":"code","58e66db5":"code","03b0cb6d":"code","57f9de22":"markdown","88ed4269":"markdown","daa40c7f":"markdown","562e6ec6":"markdown","342e0e69":"markdown","59b03557":"markdown","caac9f98":"markdown","2fce6ddc":"markdown","2a3ce118":"markdown","6d4b0ce8":"markdown","c8f295b5":"markdown","cb30f658":"markdown","f7a11cf8":"markdown","1f4e368a":"markdown","bd239f3c":"markdown","285c5ab5":"markdown","8dd6aa94":"markdown","aefd0fd6":"markdown","5a56c2a1":"markdown","7ab698c0":"markdown","7282ec82":"markdown","3bd0949b":"markdown","9cb0519e":"markdown","ff6afea4":"markdown","0c044cd1":"markdown","5635068e":"markdown","2bc46b01":"markdown","e6bf8629":"markdown"},"source":{"23ffba2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ec9f82a3":"!pip install pywaffle\nfrom pywaffle import Waffle\nimport matplotlib.image as img\nimport seaborn as sns\nimport matplotlib.pyplot as plt","1f519bcf":"df2021 = pd.read_csv(\"..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\")\ndf2020 = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\")\ndf2019 = pd.read_csv(\"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\")\ndf2018 = pd.read_csv(\"..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv\")\ndf2021.head()","b8a111f2":"# In this Kaggle Bowl, we are making a Waffle.\n# Did I tell you that this is my first time making waffle and you are the first lucky ones to taste it.\n# According to a video I saw on YouTube, the major components (in quantity) in waffle are Flour, Buttermilk, Melted Butter,\n# & Large Eggs. So Flour be India, buttermilk be USA and so on.\n# And many countries like Norway, Ethiopia, Kazakhstan, Algeria, Iraq, etc are other components of Waffle. \n# Their quantity could be small but they sure are needed.\n\ndf2021.iloc[1:].groupby(['Q3']).size().sort_values(ascending=False)","de753606":"TopRespondingCountries = df2021.iloc[1:].groupby(['Q3']).size().sort_values(ascending=False)\nTopRespondingCountries = TopRespondingCountries[:5]\nTopRespondingCountries.drop('Other', inplace=True)\nTopRespondingCountries","8ca3937e":"eat = img.imread(\"..\/input\/eating\/sss.jpg\")\nplt.xkcd(scale=0.5)\nfis = plt.figure(figsize=(10,6),\n    FigureClass = Waffle,\n    rows = 4,\n    columns = 10,\n    values = list(TopRespondingCountries.values),\n    labels = list(TopRespondingCountries.index),\n    rounding_rule='floor',\n    title={\n        'label': 'Waffle of countries with most respondents',\n        'loc': 'left',\n        'fontdict': {\n            'fontsize': 12\n        }\n    },\n    legend={\n        'loc': 'lower left',\n        'bbox_to_anchor': (0, -0.4),\n        'ncol': len(df2021),\n        'framealpha': 0.2,\n        'fontsize': 15\n    },\n    cmap_name=\"tab10\"\n)\ndd = fis.add_axes([0.9, 0.2, 0.85, 0.5])\ndd.imshow(eat)\ndd.axis(\"off\")","b592390f":"sages = list(df2021.Q15.value_counts().index[5:9])\nDS_ML_RS = ['Research Scientist', 'Data Scientist', 'Machine Learning Engineer']\nLanguageSagesRecommends = pd.DataFrame(df2021[(df2021['Q15'].isin(sages)) & \n                                         (df2021['Q5'].isin(DS_ML_RS))].groupby(['Q8']).size())\nLanguageSagesRecommends = pd.DataFrame(LanguageSagesRecommends[0].sort_values())\nLanguageSagesRecommends = LanguageSagesRecommends[1:]\nSages_Lang_Recommend_percentage = pd.DataFrame(round((LanguageSagesRecommends[0]\/LanguageSagesRecommends[0].sum())*100, 2))\nSages_Lang_Recommend_percentage","706c9163":"Sages_Lang_Recommend_percentage.drop(index='Other', inplace=True)","bb596a8e":"LTimage = img.imread(\"..\/input\/train-languagex\/Untitledass.jpg\")\nf = plt.figure(figsize=(10, 6))\nbarchart = f.add_axes([0.1, 0.1, 0.85, 0.85])\nLanguageTrain = f.add_axes([0.9, 0.1, 0.55, 0.4])\nbarchart.bar(list(Sages_Lang_Recommend_percentage.index),list(Sages_Lang_Recommend_percentage[0].values),\n            color=['white','white', 'white', 'white','white','white', 'white', 'white','white',],\n            edgecolor=['#306998','#306998','#306998','#306998','#306998','#306998',\n                       '#306998','#306998','#306998','#306998',],\n            linewidth=['3.5', '3.5', '3.5', '3.5', '3.5', '3.5', '3.5', '3.5', '3.5', '3.5'])\nbarchart.set_ylabel(\"Language recommendation percenatage\")\nbarchart.set_xlabel(\"Languages\")\nLanguageTrain.imshow(LTimage, alpha = 0.85)\nLanguageTrain.axis(\"off\")","200cb9d3":"def Rusers(YearDataFrame, question):\n    x = YearDataFrame.groupby(question).size()\n    return x.reset_index()[:1].values[0][1]","309a5c05":"PDimage = img.imread(\"..\/input\/proudd\/Pridd.jpg\")\nfg = plt.figure(figsize=(9, 6))\nR_bar = fg.add_axes([0.1, 0.1, 0.85, 0.85])\nHappyStatistician = fg.add_axes([0.9, 0.15, 0.55, 0.45])\nyear = ['2018', '2019', '2020', '2021']\nrusers = [Rusers(df2018, 'Q16_Part_2'), Rusers(df2019, 'Q18_Part_2'), \n          Rusers(df2020, 'Q7_Part_2'), Rusers(df2021, 'Q7_Part_2')]\nR_bar.bar(year, rusers,\n            color= 'white',\n            edgecolor=['#900D09','#900D09', '#900D09', '#306998'],\n            linewidth=['3.5', '3.5', '3.5', '3.5'])\nR_bar.set_ylabel(\"Number of R users\")\nR_bar.set_xlabel(\"Year\")\nR_bar.set_title(\"Number of R users by year\")\nHappyStatistician.imshow(PDimage, alpha = 0.9)\nHappyStatistician.axis(\"off\")\nHappyStatistician.set_title(\"A Happy Statistician\")","354371d2":"STimage = img.imread(\"..\/input\/confusion\/fdff.jpg\")\nfgx = plt.figure(figsize=(9, 6))\nper_R_bar = fgx.add_axes([0.1, 0.1, 0.85, 0.85])\naStatistician = fgx.add_axes([1.2, 0.15, 0.55, 0.35])\nPercentage_rusers = [(i \/ j) * 100 for i, j in zip(rusers, [len(df2018), len(df2019), len(df2020), len(df2021)])]\nper_R_bar.bar(year, Percentage_rusers,\n            color= 'white',\n            edgecolor=['#900D09','#900D09', '#900D09', '#FF0000'],\n            linewidth=['3', '3', '3', '3.5'])\nper_R_bar.set_ylabel(\"Percentage of R users\")\nper_R_bar.set_xlabel(\"Year\")\nper_R_bar.set_title(\"Percentage of R users by year\")\naStatistician.imshow(STimage, alpha = 0.9)\naStatistician.axis(\"off\")\naStatistician.set_title(\"a statistician\")","b0c594d9":"TBBI = img.imread(\"..\/input\/tabvsbi\/dddd.jpg\")\nfgx = plt.figure(figsize=(8, 5.6))\nbicompare = fgx.add_axes([0, 0, 1, 1])\nTBBIaxes = fgx.add_axes([1.1, 0.0, 0.55, 0.85])\nxc = np.arange(2)\n\ntusers = [Rusers(df2020, 'Q31_A_Part_5'), Rusers(df2021, 'Q34_A_Part_5')]\nbusers = [Rusers(df2020, 'Q31_A_Part_2'), Rusers(df2021, 'Q34_A_Part_2')]\n\nPercentage_tusers = [(i \/ j) * 100 for i, j in zip(tusers, [len(df2020), len(df2021)])]\nPercentage_busers = [(i \/ j) * 100 for i, j in zip(busers, [len(df2020), len(df2021)])]\n\n\nc1 = bicompare.bar(xc, Percentage_tusers, \n                   color= 'white', \n                   edgecolor='#3895D3', \n                   linewidth=5, width = 0.25)\nc2 = bicompare.bar(xc + 0.3, Percentage_busers, \n                   color= 'white', \n                   edgecolor='#FFBA01', \n                   linewidth=5, width = 0.25)\n\nbicompare.set_xticks(xc + 0.3 \/ 2)\nbicompare.set_xticklabels(['2020', '2021']) #The data is only available for two years.\nbicompare.set_yticks([])\nbicompare.set_ylabel('Percentage of Users')\nbicompare.set_xlabel('Year')\n\nbicompare.set_title('Tableau vs Power BI users')\n\nTBBIaxes.imshow(TBBI, alpha = 0.9)\nTBBIaxes.axis(\"off\")\n\ncols = {'Tableau Users':'x', 'Microsoft Power BI users':'y'}\nbicompare.legend(cols, loc='upper right', bbox_to_anchor=(1.42, 1), shadow=True)","c42af4dd":"v1 = pd.DataFrame(df2021[df2021['Q34_A_Part_2'].notnull()].groupby('Q5').size())\nv2 = pd.DataFrame(df2021[df2021['Q34_A_Part_5'].notnull()].groupby('Q5').size())\nTBshare = pd.merge(v1, v2, left_index=True, right_index=True)\nTBshare.drop(['Select the title most similar to your current role (or most recent title if retired): - Selected Choice', 'Other'],\n             inplace=True)","51a7d00a":"tbn = np.arange(len(TBshare))\nfy = plt.figure(figsize=(14, 6))\nf2 = fy.add_axes([0,0,1,1])\nf2.stem(tbn, TBshare['0_x'])\nf2.stem(tbn + 0.4, TBshare['0_y'])\n\n(markers, stemlines, baseline) = plt.stem(TBshare['0_x'])\nplt.setp(markers, markersize=10, markeredgecolor=\"orange\", markeredgewidth=10)\n\n(markers1, stemlines1, baseline1) = plt.stem(tbn + 0.4, TBshare['0_y'])\nplt.setp(markers1, markersize=10, markeredgecolor=\"#3895D3\", markeredgewidth=10)\n\nf2.set_yticks([])\nf2.set_ylabel('# Users')\nf2.set_xticks(tbn + 0.4 \/ 2)\nf2.set_xticklabels(list(TBshare.index))\nf2.set_xlabel('Profession')\nplt.setp(f2.get_xticklabels(), rotation=25, horizontalalignment='right', fontsize='small')\ncolss = {'Power BI users':'markers', 'Tableau Users':'markers1'}\nf2.legend(colss, loc='upper right', shadow=True)\n\nf2.grid()","3676ca05":"m1 = df2021[df2021['Q15'].isin(['10-20 years', '20 or more years'])].groupby('Q3').size().sort_values()[-11:]\nm1.drop('Other', inplace=True)\nm1.rename(index={'United Kingdom of Great Britain and Northern Ireland': \n                 'UK', 'United States of America':'USA'}, inplace=True)\n\nm2 = df2021[df2021['Q15'].isin(['10-20 years', '20 or more years', '5-10 years'])].groupby('Q3').size().sort_values()[-11:]\nm2.drop('Other', inplace=True)\nm2.rename(index={'United Kingdom of Great Britain and Northern Ireland': \n                 'UK', 'United States of America':'USA'}, inplace=True)\n\nm3 = df2021[df2021['Q15'].isin(['1-2 years'])].groupby('Q3').size().sort_values()[-11:]\nm3.drop('Other', inplace=True)\nm3.rename(index={'United Kingdom of Great Britain and Northern Ireland': \n                 'UK', 'United States of America':'USA'}, inplace=True)\n\nm4 = df2021[df2021['Q15'].isin(['Under 1 year'])].groupby('Q3').size().sort_values()[-11:]\nm4.drop('Other', inplace=True)\nm4.rename(index={'United Kingdom of Great Britain and Northern Ireland': \n                 'UK', 'United States of America':'USA'}, inplace=True)\n\nfigg, axss = plt.subplots(4, figsize=(15,15))\n\nfigg.suptitle('__________________')\nfigg.tight_layout(pad=3)\naxss[0].bar(m1.index, m1.values, color='#ffe066')\naxss[1].bar(m2.index, m2.values, color='#ffe066')\naxss[2].bar(m3.index, m3.values, color='#247ba0')\naxss[3].bar(m4.index, m4.values, color='#247ba0')\naxss[0].set_title(\"Respondents having more than 10 years of experience in Machine Learning\", loc='left')\naxss[1].set_title(\"Respondents having more than 5 years of experience in Machine Learning\", loc='left')\naxss[2].set_title(\"Respondents having experience between 1-2 years in Machine Learning\", loc='left')\naxss[3].set_title(\"Respondents having less than 1 year of experience in Machine Learning\", loc='left')\nplt.setp(axss[ :], xlabel='Countries')\naxss[0].set_xlabel(\"\")\naxss[1].set_xlabel(\"\")\naxss[2].set_xlabel(\"\")\nplt.setp(axss[:], ylabel='# Respondents')","37452956":"m5 = df2021[df2021['Q15'].isin(['Under 1 year'])].groupby('Q3').size().sort_values()\nm5.rename(index={'United Kingdom of Great Britain and Northern Ireland': 'UK',\n                 'United States of America':'USA'}, inplace=True)\nm6final = (pd.DataFrame(m2).divide(pd.DataFrame(m5), axis='index').dropna())*100\nfgr = plt.figure(figsize=(12, 6))\nplotting_bar = fgr.add_axes([0, 0, 1, 1])\nplotting_bar.bar(list(m6final.index), list(m6final.values[:, 0]),\n            color= '#FCE205')\nplotting_bar.set_ylabel(\"Ratio of New Learners vs Experienced\")\nplotting_bar.set_xlabel(\"Countries\")\nplotting_bar.set_title(\"Ten Countries with mentor to pupil ratio\")","ff136c26":"m7 = pd.merge(pd.DataFrame(m2), pd.DataFrame(m5) , left_index=True, right_index=True)\nm7.rename(columns={'0_x': 'Sages', '0_y':'Learners'}, inplace=True)\nm7.plot.bar(figsize=(14, 6), width = 0.7, \n            title = 'Number of Sages vs Number of Learners', \n            color=['#ffe066', '#247ba0'],\n            xlabel = 'Countries')","f1b57e4b":"def Jusers(year, question1, question2):\n    j = year[(year[question1].isin(Datapeople))].groupby([question2]).size()[0]\n    return j\n\ndef totaldatapeople(year, question):\n    k = year[(year[question].isin(Datapeople))].groupby([question]).size().sum()\n    return k","a7458c37":"Datapeople = ['Data Scientist', 'Data Analyst', 'Research Assistant', 'Research Scientist', \n              'Statistician', 'Machine Learning Engineer']\nJSusers = [Jusers(df2018, 'Q6', 'Q16_Part_6'), Jusers(df2019, 'Q5', 'Q18_Part_7'), \n           Jusers(df2020, 'Q5', 'Q7_Part_7'), Jusers(df2021, 'Q5', 'Q7_Part_7')]\n\nTotalDataPeople = [totaldatapeople(df2018, 'Q6'), totaldatapeople(df2019, 'Q5'),\n                   totaldatapeople(df2020, 'Q5'), totaldatapeople(df2021, 'Q5')]\n\nPer_JS_user = [(i \/ j) * 100 for i, j in zip(JSusers, TotalDataPeople)]","661dda96":"TFimage = img.imread(\"..\/input\/tf-imafes\/1aee0ede85885520.png\")\n\nfgr = plt.figure(figsize=(8, 4))\nplotting_bar = fgr.add_axes([0, 0, 1, 1])\nTF = fgr.add_axes([1.1, 0.15, 0.55, 0.75])\nplotting_bar.plot(year, Per_JS_user,\n            color= '#2a9d8f')\nplotting_bar.set_ylabel(\"Percentage of JavaScript users\")\nplotting_bar.set_xlabel(\"Year\")\nplotting_bar.set_title(\"Percentage of JavaScript users in  \\n Machine Learning and Data Science community\")\nTF.imshow(TFimage)\nTF.axis(\"off\")","02de087a":"# Let's find out how many people use GANs on regular basis.\nTotalGANusers = len(df2021[df2021['Q17_Part_8'].notnull()])-1\n\n# People using GANs and the programming experience they have\nGANs_Prog_Exp21 = df2021[(df2021['Q17_Part_8'].notnull())].groupby(['Q6']).size().reset_index()[:-1]","64ac4625":"WSimage = img.imread(\"..\/input\/wsianfw\/Untitledss.jpg\")\n\nfgt = plt.figure(figsize=(8, 4))\nplotting_bar = fgt.add_axes([0, 0, 1, 1])\nWS = fgt.add_axes([1.0, 0.0, 1, 1])\nplotting_bar.bar(list(GANs_Prog_Exp21['Q6']), list(GANs_Prog_Exp21[0]),\n            color= ['#29c5f6', '#29c5f6', '#29c5f6', '#29c5f6', '#29c5f6', '#ffd700'])\nplotting_bar.set_ylabel(\"# Programmers\")\nplotting_bar.set_xlabel(\"Years of experience\")\nplotting_bar.set_title(\"GANs users according to programming experience\")\nWS.imshow(WSimage)\nWS.set_title(\"Image augmentation using GANs\")\nWS.axis(\"off\")","7a1a66c7":"toddlers = df2021.groupby('Q6').size()\ntoddlers.drop('For how many years have you been writing code and\/or programming?', inplace=True)\ntoddlers.sort_values(inplace=True)","58e66db5":"toddlers.rename(index={'I have never written code': 'Zero Coding'}, inplace=True)","03b0cb6d":"TDimage = img.imread(\"..\/input\/jvvvjjnjnj2-k\/ssaaaaa.jpg\")\n\nfgf = plt.figure(figsize=(8, 4))\nplotting_bar = fgf.add_axes([0, 0, 1, 1])\nTD = fgf.add_axes([1.0, 0.0, 1, 1])\nplotting_bar.bar(list(toddlers.index), list(toddlers.values),\n            color= ['#ffd700', '#29c5f6', '#29c5f6', '#29c5f6', '#29c5f6', '#ffd700', '#ffd700'])\nplotting_bar.set_ylabel(\"# Programmers\")\nplotting_bar.set_xlabel(\"Years of experience\")\nplotting_bar.set_title(\"Machine Learning and Data Science Community \\n according to years of programming experience\")\nTD.imshow(TDimage)\nTD.axis(\"off\")","57f9de22":"# ***Have you ever met a Superhuman?***","88ed4269":"# **Waffle of Top Responding Countries**","daa40c7f":"According to the percentage metric, the number of R users haven't changed much since last year which is a good thing for R as compared to the preceding years where it had been continuously falling. This means that people using R have increased proportionately with the data community. If more people takes the Google's certification, we might see a taller bar next year.\n\n(A word - This analysis takes into consideration that this survey is God's words and an actual representaion of the data world. But also, the launch of Google Data Analytics Certicate was a big event, I think. To support my point, a data person's feed was filled with certification review videos, a lot of blogs and articles covered it, and there was an increase in Python vs R debate.)","562e6ec6":"# Installing libraries and importing the datasets we need","342e0e69":"If you have been in the job market, you will know that this two softwares are mentioned frequently. Each organisation has their own preferences depending on their needs. Learning either or both is not difficult but which one is used by Kagglers on regular basis?","59b03557":"In the above figure, the first bar graph shows countries having more than 10 years of experience in Machine Learning. Even though India is still in the ranking but it tells us that she does not have enough experienced ML practitioners. USA has quite a lot of experienced Machine Learning people.\nAlso, we see new countries making their appearance in the analysis like Spain and Germany. As we move down each chart, you will notice that the bar of India is getting taller. The figure is plotted descendingly according machine learning experience. In the last graph, India has a tall bar because most of the ML enthusiasts are young. I wanted to plot only two graphs in the figure but I wanted to show the appearance and disappearnce of Spain and Germany as well as the rise and fall of India and USA respectively as move down the graph.\nSpain and Germany are not in the last graph because I consider they have a balanced machine learning environment. Keep reading to understand what I mean by balanced environment?","caac9f98":"Both the data visualisation\/business intelligence tools occupy almost the same market share with Tableau having a little edge over Power BI. If we Slice-and-Dice this share according to the profession of users, we will see a similar trend.","2fce6ddc":"# **What languages do the sages speak?**","2a3ce118":"This graph is a side by side comparison of Experienced people and new people in machine learning. It can be clearly seen for such a huge number of young minds, the corresponding mentor population is too less in India. Except India and to some extent Japan, all the eight countries have a balanced machine learning environment.","6d4b0ce8":"We all know Uncle Guido's Python is the most prominent language in the world of Data Science and Machine Learning. The language is so sweet, it is easy for us toddlers to learn. Thank you uncle Guido. I wanted to know what programming language the wise sages of the Data World who have been in this community for considerable time recommends aspiring data babies to learn first.","c8f295b5":"The competition between Tableau and Power BI is proportionately divided in the profession too. Almost every profession uses both the tools equally.","cb30f658":"# Slow Acceptance of Javascript, according to Tensorflow community","f7a11cf8":"# **Google Data Analytics Certificate**","1f4e368a":"1) The above bar graph shows respondents using GANs on regular basis. Further, I have sliced the respondents according to their programming experience. The last golden bar shows people whom I consider to be superhumans. Why? As I said, GANs is one of the reasons I am here. To learn GANs, I bought every available book on the market. In most of the books, it is mentioned that to practice GANs you should have at least two years of programming experience. \n        I will quote Jakub Langr and Vladimir Bok, authors of *GANs in Action*, \"you should have at least two years of Python experience (ideally as a full-time data scientist or software engineer)\".\n        So when I see this people with less than one year experience in programming, it reminds me of a person I met in graduation. During our time together, I never saw him reading or learning, except the day before an examination, and he would ace every test, outdoing everyone studying whole semesters. These are the people to whom learning is a piece of cake and they leave everyone around them mesmerized and confused.\n        It feels good to stay in the glow of such people. The people in the golden bar I think are like the person I met. Read once and remember forever\n        .\n2) And the image above shows an image of Shakespeare augmented to High definition. If the image is too small, you can try any image augmenting apps in the market and use it on a bad image. It is magic! GANs has given and giving birth to new technologies like neural rendering.","bd239f3c":"The above golden graph shows some prominent names in the machine learning. India has a poor pupil to mentor ratio. They have a lot of young enthusiastic talent but they do not have enough experienced people to guide them properly. Machine learning is such a vast field with applications everywhere and every subclass in Machine learning has their own use cases. On the other hand, Spain, Germany, Canada, USA has good ratios. The young people in this countries have\/are going to have proper and well-directed guidance.","285c5ab5":"The percentage of Machine Learning JavaScript community has definitely increased in 2020. In 2021, it has not risen much but as the TF community said \"it is slowly growing\". It's all good as long as it does not fall. So we have confirmed that Javascript\/Tensorflow JS are rising in popularity.","8dd6aa94":"# More than half are Toddlers and babies","aefd0fd6":"One of the main reasons I am waddling here is GANs. Generative Adversarial Networks. The first application I used of GANs was a photo augmenting app 'Remini'. The way it transformed my old blurry images into super HD was nothing short of magic and suddenly the phone I had in my hand felt like a magic wand. The first photo transformation it did sent high-powered electric waves into my brain. I decided then I want it - the tech, the source behind it. In the movie 'Pirates of Silicon Valley', I guess this is what Bill Gates felt when he saw Apple's GUI computers.","5a56c2a1":"This is the wisdom of the wise sages of the data world. These is what Data Scientists, Machine Learning Engineers,and Research Scientists having more than 4 years of experience in the field recommends people entering the data world to learn first. This is literally a sort of Monopoly by Python with a whopping ~80% of the sages recommending it.\nR and SQL comes at distant 2nd and 3rd place while other languages are on their knees.\nRecently, I saw an article posted by Tensorflow community where they said that the use of Javascript has increased in Machine Learning from 2020. We will see its analysis later.","7ab698c0":"# **Balanced machine learning society**","7282ec82":"We all know that the most number of respondents are from India. I am from India. The survey shows we are a lot. But most of us are newcomers in machine learning.","3bd0949b":"References\n1) William Shakespear image (https:\/\/en.wikipedia.org\/wiki\/William_Shakespeare)\n2) Stickers - I could not find the exact source of the stickers.\n3) GANs in action book - Jakub Langr, Vladimir Bok","9cb0519e":"There's definitely an increase in the number of R users this year. Would we see more....\nWait! Wait! The graph shows the number of R users in a particular year. We have 5000, no almost 6000, more respondents this year than last year. So the bar of Year2021 is surely going to be taller. Let's check with another metric which is 'percentage of R users in a year'.","ff6afea4":"This year, we saw almost 26,000 respondents. Most of this respondents are new to machine learning field. In the entire analysis, I called toddlers to people having less than three years of experience in programming. They are more than 50% of the respondents. So when I say most of us toddlers or babies, this is what I mean.\nAnd thank you, this was my first time doing any kind of analysis.","0c044cd1":"# Tableau vs Power BI - Shoulder to Shoulder or not?","5635068e":"Few months back, Google launched their Data Analytics Certificate.\nI was happy!\nI was not.\nThe certification was in R. I had just passed the stage of mumbling in Python. Anyway, I thought with Google sort of promoting R, the number of R users would increase in the data world. I had no data to confirm the thought then but I have now.\nLet us see if R is peeking her head.","2bc46b01":"This is a toddler's notebook. I am a toddler. I reckon you are too. Most of us are, most. I guess I should say Hi. So Hi to everyone, hope you are having a good day. And would you like a waffle? Let's have a waffle. I'll make a multi-diverse colorful waffle.","e6bf8629":"Tensorflow has a youtube channel. Now and then, I watch the videos. I haven't started with Tensorflow yet. Recently, I saw a video where they say that the Javascript community of Tensorflow has shown increase in 2020. The increase has not been much compared to Python but in a period where all the languages are hardly meeting the popularity of Python, a slight increase means a great deal for that particular language users. Let's verify the claim made by Tensorflow people.\n\nWe will only include professions that mainly deal with data. I have considered these six profiles: 'Data Scientist', 'Data Analyst', 'Research Assistant', 'Research Scientist', 'Statistician' and 'Machine Learning Engineer'.\n\nI have created a function that calculates the number of JavaScript users and the number of respondents in these professions.\nWe will start calculating the number of JavaScript users from 2018 till 2021."}}