{"cell_type":{"9fc94060":"code","97e5b064":"code","3d68399a":"code","db0d5e44":"code","97edfccf":"code","413fd2ab":"code","420eefe2":"code","9bbf269b":"code","2899c6fe":"code","48835185":"code","6be131f3":"code","47947063":"code","28ac00d8":"code","fd0c0aef":"code","aca9e6b8":"markdown","bbae0297":"markdown"},"source":{"9fc94060":"ls ..\/input\/m5-forecasting-accuracy\/","97e5b064":"import pandas as pd\nsample = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sample_submission.csv')","3d68399a":"sample.head()","db0d5e44":"# util functions to reduce pandas dataframe memory\nimport numpy as np\ndef df_mem_reduce(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\nsales_train = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\nsales_train = df_mem_reduce(sales_train)","97edfccf":"calendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\nprint(calendar.head())\nprint(calendar.tail())\ncalendar['date'].shape","413fd2ab":"sales_train.head()","420eefe2":"sales_train.shape","9bbf269b":"sales_train.loc[sales_train['item_id']=='HOBBIES_1_001',:]","2899c6fe":"sales_train_dates_columns = sales_train.columns[6:]\nsales_train_dates_columns_recent_28 = sales_train_dates_columns[-28:]\n\nsales_train.loc[sales_train['item_id']=='HOBBIES_1_001',sales_train_dates_columns_recent_28].head()","48835185":"sales_train_agg_cat_store = sales_train.groupby(['cat_id','store_id'])[sales_train_dates_columns_recent_28].mean().reset_index()\nsales_train_agg_cat_store['_cat_store'] = sales_train_agg_cat_store.apply(lambda x: x['cat_id'] + \"_\" + x['store_id'], axis=1)\nsales_train_agg_cat_store.drop(['cat_id','store_id'],axis=1,inplace=True)\nnewCols = {x:'F'+str(id_+1) for id_,x in enumerate(sales_train_agg_cat_store.columns) if not x.startswith('_')}\nsales_train_agg_cat_store.rename(columns=newCols, inplace=True)\nsales_train_agg_cat_store.head()","6be131f3":"sample['_cat_store'] = sample.apply(lambda x:x['id'].split('_')[0]+\"_\"+x['id'].split('_')[3]+\"_\"+x['id'].split('_')[4] , axis=1 )#cat_id\tstore_id\t\nprint(sample.head())\nsample_joint = sample[['id','_cat_store']].merge(sales_train_agg_cat_store, on='_cat_store', how='left')\nprint(sample_joint.head())","47947063":"import os\nos.system(\"rm -rf output\")\nos.system(\"mkdir -p output\")\nif '_cat_store' in sample_joint.columns:\n    sample_joint.drop('_cat_store',axis=1, inplace=True)\nsample_joint.to_csv('output\/submission_last_28_days.csv', index=False, float_format='%.2f')","28ac00d8":"ls -alh output\/","fd0c0aef":"!head output\/submission_last_28_days.csv","aca9e6b8":"# Use this zipped file,upload and submit. \n# Contratulations, You are a Contributor now.","bbae0297":"#### We Will use the last 28 days data on category-store level as prediction for next 28(validation) and later 28 days(as evaluation) as our first submission. We will check the score and improve it later in our next attempt. \n## If you do not have any submission and are stuck at Novice level, use this Notebook, run it and submit the output file to become a contributor.\n#### Feel free to fork and update the notebook."}}