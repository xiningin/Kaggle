{"cell_type":{"a0ab5079":"code","61bbc5ee":"code","e0e1580b":"code","21bc233b":"code","805ce24a":"code","18e0b60d":"code","68538401":"code","4e1bd437":"code","31bee129":"code","a9c4b3c6":"code","516aae53":"code","fd676ace":"code","6e30db0c":"code","4733786f":"code","739aca24":"code","3bb80d69":"code","aadd22fb":"code","f4945bcb":"code","05c7819b":"code","2383a295":"code","ffa9157c":"markdown"},"source":{"a0ab5079":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61bbc5ee":"train = pd.read_csv('..\/input\/titanic\/train.csv')","e0e1580b":"train.describe","21bc233b":"train.corr()","805ce24a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x = 'SibSp', hue = \"Survived\", data = train)","18e0b60d":"train.isnull().sum()","68538401":"train.drop(['PassengerId','Name','Cabin','Ticket', ], axis=1, inplace=True)\ntrain[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True)\ntrain[\"Embarked\"].fillna(train['Embarked'].value_counts().idxmax(), inplace=True)","4e1bd437":"train['Alone']=np.where((train[\"SibSp\"]+train[\"Parch\"])>0, 0, 1)\ntrain.drop(['SibSp', 'Parch'], axis=1, inplace=True)","31bee129":"pd.get_dummies(train['Sex'])","a9c4b3c6":"training = pd.get_dummies(train, columns=[\"Pclass\",\"Embarked\",\"Sex\"], drop_first=True)\ntraining","516aae53":"from sklearn.preprocessing import StandardScaler\ntrain_standard = StandardScaler()\ntrain_copied = training.copy()\ntrain_standard.fit(train_copied[['Age','Fare']])\ntrain_std = pd.DataFrame(train_standard.transform(train_copied[['Age','Fare']]))\ntrain_std","fd676ace":"training[['Age','Fare'] ] = train_std\ntraining","6e30db0c":"from sklearn.linear_model import LogisticRegression\ncols = [\"Age\",\"Fare\",\"Alone\",\"Pclass_2\",\"Pclass_2\",\"Embarked_Q\",\"Embarked_S\",\"Sex_male\"] \nX = training[cols]\ny = training['Survived']\n# Build a logreg and compute the feature importances\nmodel = LogisticRegression()\n# create the RFE model and select 8 attributes\nmodel.fit(X,y)","4733786f":"from sklearn.metrics import accuracy_score\ntrain_predicted = model.predict(X)\naccuracy_score(train_predicted, y)","739aca24":"test = pd.read_csv('..\/input\/titanic\/test.csv')","3bb80d69":"test.isnull().sum()","aadd22fb":"test.drop(['PassengerId','Name','Cabin','Ticket'], axis=1, inplace=True)\ntest[\"Age\"].fillna(28, inplace=True)\ntest[\"Embarked\"].fillna(test['Embarked'].value_counts().idxmax(), inplace=True)\ntest[\"Fare\"].fillna(train.Fare.median(), inplace=True)\ntest['Alone']=np.where((test[\"SibSp\"]+test[\"Parch\"])>0, 0, 1)\ntest.drop(['SibSp', 'Parch'], axis=1, inplace=True)\ntesting=pd.get_dummies(test, columns=[\"Pclass\",\"Embarked\",\"Sex\"], drop_first=True)\nprint(testing.dtypes)\ntest_copied = testing.copy()\ntest_std = train_standard.transform(test_copied[['Age','Fare']])\ntest_std\ntesting[['Age','Fare']] = test_std\ntesting","f4945bcb":"cols = [\"Age\",\"Fare\",\"Alone\",\"Pclass_2\",\"Pclass_2\",\"Embarked_Q\",\"Embarked_S\",\"Sex_male\"] \nX_test=testing[cols]\nprint(X_test.dtypes)\ntest_predicted = model.predict(X_test)","05c7819b":"sub = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","2383a295":"sub['Survived'] = list(map(int, test_predicted))\nsub.to_csv('submission.csv', index=False)","ffa9157c":"## \u7279\u5fb4\u91cf\u3092\u78ba\u8a8d\u3059\u308b"}}