{"cell_type":{"de783bea":"code","f8140eb9":"code","16303994":"code","4f6b7044":"code","1041be3a":"code","5ff1a32d":"code","1265c8a2":"code","600fb51e":"code","7aee367d":"code","d56c7770":"code","ae2d9b45":"code","e3183de8":"code","4f705deb":"code","bef656a8":"code","70379bad":"code","d1e6f199":"code","684f0e8c":"code","5e25dea5":"code","929b1798":"code","48f85ecb":"code","8d465f8d":"code","a69ad93d":"code","49085d33":"code","e0440c13":"code","1afdfae5":"code","7d8159ba":"markdown","a9749489":"markdown","136bd3be":"markdown","dfc5cc08":"markdown","6ec2d463":"markdown","947df3d3":"markdown","35493ed0":"markdown"},"source":{"de783bea":"!pip show torch","f8140eb9":"import os\nimport math\nimport shutil\nimport time\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport collections\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.autograd import Variable\n\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm import trange\n#import torchvision\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#%matplotlib notebook\n\nprint(os.listdir(\"..\/input\"))","16303994":"LR                  = 0.1\nBATCH_SIZE          = 128\nEPOCHS              = 170\n\nLAYERS              = 28        # total number of layers (default: 28)\nWIDE                = 10        # widen factor (default: 10) \nBATCHNORM           = True      # apply BatchNorm\nFIXUP               = True      # apply Fixup\nDROPOUT             = 0.3         # dropout probability (default: 0.0)\n\nAUGMENT             = True      # use standard augmentation (default: True)\nCUTOUT              = True     # apply cutout\nN_HOLES             = 1         # number of holes to cut out from image\nLENGHT              = 5        # length of the holes\n\n# Image Setup\nCLASS_NUM          = 10\nIMG_ROWS, IMG_COLS = 32, 32\nIMG_CHANNELS       = 3\nIMG_MEAN           = [125.3, 123.0, 113.9]\nIMG_STD            = [63.0, 62.1, 66.7]\n\n# Setup SGD\nmomentum = 0.9\nnesterov = True\nweight_decay = 5e-4\nstart_epoch = 0\n\nprint_freq = 10","4f6b7044":"# Random seed\nRANDOM_SEED        = 42\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed_all(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\n\n# tmp\nbest_acc = 0\nlr_tmp = 0","1041be3a":"\"\"\"\nWide ResNet by Sergey Zagoruyko and Nikos Komodakis\nFixup initialization by Hongyi Zhang, Yann N. Dauphin, Tengyu Ma\nBased on code by xternalz and Andy Brock: \nhttps:\/\/github.com\/xternalz\/WideResNet-pytorch\nhttps:\/\/github.com\/ajbrock\/BoilerPlate\n\"\"\"\n\n\nclass BasicBlock(nn.Module):\n    droprate = 0.0\n    use_bn = True\n    use_fixup = False\n    fixup_l = 12\n\n    def __init__(self, in_planes, out_planes, stride):\n        super(BasicBlock, self).__init__()\n\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        self.equalInOut = in_planes == out_planes\n        self.conv_res = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, padding=0, bias=False)\n        self.conv_res = not self.equalInOut and self.conv_res or None\n\n        assert self.use_fixup or self.use_bn, \"Need to use at least one thing: Fixup or BatchNorm\"\n\n        if self.use_fixup:\n            self.multiplicator = nn.Parameter(torch.ones(1,1,1,1))\n            self.biases = nn.ParameterList([nn.Parameter(torch.zeros(1,1,1,1))] * 4)\n\n            k = self.conv1.kernel_size[0] * self.conv1.kernel_size[1] * self.conv1.out_channels\n            self.conv1.weight.data.normal_(0, self.fixup_l ** (-0.5) * math.sqrt(2. \/ k)) \n            self.conv2.weight.data.zero_()\n            \n            if self.conv_res is not None:\n                k = self.conv_res.kernel_size[0] * self.conv_res.kernel_size[1] * self.conv_res.out_channels\n                self.conv_res.weight.data.normal_(0, math.sqrt(2. \/ k))\n\n    def forward(self, x):\n        if self.use_bn:\n            x_out = self.relu(self.bn1(x))\n            out = self.relu(self.bn2(self.conv1(x_out)))\n            if self.droprate > 0:\n                out = F.dropout(out, p=self.droprate, training=self.training)\n            out = self.conv2(out)\n        else:\n            x_out = self.relu(x + self.biases[0])\n            out = self.conv1(x_out) + self.biases[1]\n            out = self.relu(out) + self.biases[2]\n            if self.droprate > 0:\n                out = F.dropout(out, p=self.droprate, training=self.training)\n            out = self.multiplicator * self.conv2(out) + self.biases[3]\n\n        if self.equalInOut:\n            return torch.add(x, out)\n\n        return torch.add(self.conv_res(x_out), out)\n\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride):\n        super(NetworkBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride)\n\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride):\n        layers = []\n\n        for i in range(int(nb_layers)):\n            _in_planes = i == 0 and in_planes or out_planes\n            _stride = i == 0 and stride or 1\n            layers.append(block(_in_planes, out_planes, _stride))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.layer(x)\n\n#@registry.Model\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, droprate=0.0, use_bn=True, use_fixup=False):\n        super(WideResNet, self).__init__()\n\n        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n\n        assert (depth - 4) % 6 == 0, \"You need to change the number of layers\"\n        n = (depth - 4) \/ 6\n\n        BasicBlock.droprate = droprate\n        BasicBlock.use_bn = use_bn\n        BasicBlock.fixup_l = n * 3\n        BasicBlock.use_fixup = use_fixup\n        block = BasicBlock\n        \n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1, padding=1, bias=False)\n\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1)\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2)\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2)\n        \n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                k = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. \/ k))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n                if use_fixup:\n                    m.weight.data.zero_()\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)","5ff1a32d":"\"\"\"\nCutout implementation by Machine Learning Research Group at the University of Guelph:\nhttps:\/\/github.com\/uoguelph-mlrg\/Cutout\n\"\"\"\n\n\nclass Cutout(object):\n    \"\"\"Randomly mask out one or more patches from an image.\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    \"\"\"\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        \"\"\"\n        Args:\n            img (Tensor): Tensor image of size (C, H, W).\n        Returns:\n            Tensor: Image with n_holes of dimension length x length cut out of it.\n        \"\"\"\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length \/\/ 2, 0, h)\n            y2 = np.clip(y + self.length \/\/ 2, 0, h)\n            x1 = np.clip(x - self.length \/\/ 2, 0, w)\n            x2 = np.clip(x + self.length \/\/ 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img","1265c8a2":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count","600fb51e":"def adjust_learning_rate(optimizer, epoch):\n    \"\"\"Sets the learning rate to the initial LR divided by 5 at 60th, 120th and 160th epochs\"\"\"\n    lr_tmp = LR * ((0.2 ** int(epoch >= 50)) * (0.2 ** int(epoch >= 100))* (0.2 ** int(epoch >= 140)))\n\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr_tmp","7aee367d":"def accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 \/ batch_size))\n\n    return res","d56c7770":"def train(train_loader, model, criterion, optimizer, epoch):\n    \"\"\"Train for one epoch on the training set\"\"\"\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        target = target.cuda(async=True)\n        input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        prec1 = accuracy(output.data, target, topk=(1,))[0]\n        losses.update(loss.data.item(), input.size(0))\n        top1.update(prec1.item(), input.size(0))\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        batch_time.update(time.time() - end)\n        end = time.time()\n    \n        \n        #if i % print_freq == 0:\n        #    print(\"Epoch: [{0}][{1}\/{2}]\\t\"\n        #          \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n        #          \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n        #          \"Prec@1 {top1.val:.3f} ({top1.avg:.3f})\".format(\n        #              epoch, i, len(train_loader), batch_time=batch_time,\n        #              loss=losses, top1=top1))\n    return top1.avg","ae2d9b45":"def validate(val_loader, model, criterion, epoch):\n    \"\"\"Perform validation on the validation set\"\"\"\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        with torch.no_grad():\n            output = model(input_var)\n        loss = criterion(output, target_var)\n\n        prec1 = accuracy(output.data, target, topk=(1,))[0]\n        losses.update(loss.data.item(), input.size(0))\n        top1.update(prec1.item(), input.size(0))\n\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        #if i % print_freq == 0:\n        #    print(\"Test: [{0}\/{1}]\\t\"\n        #          \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n        #          \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n        #          \"Prec@1 {top1.val:.3f} ({top1.avg:.3f})\".format(\n        #              i, len(val_loader), batch_time=batch_time, loss=losses,\n        #              top1=top1))\n\n    #print(\" * Prec@1 {top1.avg:.3f}\".format(top1=top1))\n    return top1.avg","e3183de8":"def predict_proba(model, test_loader):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    all_pred = np.empty((0, CLASS_NUM), float)\n    for images, labels in test_loader:\n        #images, labels = data\n        images = images.to(device)\n        outputs = model(Variable(images))\n        curr_pred = F.softmax(outputs).data.cpu().numpy()\n        all_pred = np.vstack([all_pred, curr_pred])\n    return(all_pred)","4f705deb":"def predict(model, test_loader):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    #device = 'cuda'\n    all_pred = np.empty((0, CLASS_NUM), float)\n    for images, labels in test_loader:\n        #images, labels = data\n        images = images.to(device)\n        outputs = model(Variable(images))\n        curr_pred = F.softmax(outputs, dim=1).data.cpu().numpy()\n        all_pred = np.vstack([all_pred, curr_pred])\n    \n    predictions = np.argmax(all_pred, axis=1)\n    return(predictions)","bef656a8":"class MyDataset(torch.utils.data.Dataset):\n    ''' Load data from np.array '''\n    def __init__(self, labels, data, transform=None):\n        self.labels = labels\n        self.images = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        resImg = self.images[idx]\n\n        if self.transform:\n            resImg = self.transform(resImg)\n\n        return resImg, self.labels[idx]","70379bad":"def data_processing (x_train, y_train, train=True):\n    ''' normalize, augmentation and load data in DataLoader'''\n    normalize = transforms.Normalize(mean=[x \/ 255.0 for x in IMG_MEAN],\n                                     std=[x \/ 255.0 for x in IMG_STD])\n    \n    # augmentation\n    transform_train = transforms.Compose([transforms.ToTensor(),\n            transforms.Lambda(lambda x: F.pad(x.unsqueeze(0), (4,4,4,4), mode=\"reflect\").squeeze()),\n            transforms.ToPILImage(),\n            transforms.RandomCrop(32),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n            ])\n    if CUTOUT:\n        transform_train.transforms.append(Cutout(n_holes=N_HOLES, length=LENGHT))\n        \n    transform_test = transforms.Compose([transforms.ToTensor(),normalize])\n    \n    # DataLoader\n    kwargs = {\"num_workers\": 2, \"pin_memory\": True}\n    if train:\n        trainset = MyDataset(y_train, x_train, transform=transform_train) \n        train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n                                          shuffle=True, **kwargs)\n    else:\n        test_set = MyDataset(y_train, x_train, transform=transform_test) \n        train_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n                                         shuffle=False, **kwargs)\n        \n    return(train_loader)","d1e6f199":"# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435\ndata = np.load('..\/input\/train.npz')\nx_train = data['x']\ny_train_ = data['y']\nX_sub = np.load('..\/input\/test.npy')\ntmp_y_sub = np.zeros(10000, dtype=np.long) # \u043a\u043e\u0441\u0442\u044b\u043b\u044c \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u0430\n\n#x_train, x_test, y_train_, y_test_ = train_test_split(X, Y, test_size=0.02, random_state=RANDOM_SEED)\nprint(x_train.shape, X_sub.shape)\n    \ny_train = np.asarray(list(map(lambda x: x[0], y_train_)), dtype=np.long)\n#y_test = np.asarray(list(map(lambda x: x[0], y_test_)), dtype=np.long)\n\nplt.imshow(x_train[1])\nplt.show()","684f0e8c":"train_loader = data_processing (x_train, y_train, train=True)\n#test_loader  = data_processing (x_test, y_test, train=False)\nX_sub_loader = data_processing (X_sub, tmp_y_sub, train=False)","5e25dea5":"model = WideResNet(LAYERS, CLASS_NUM, WIDE, \n                   droprate=DROPOUT,\n                   use_bn=BATCHNORM, \n                   use_fixup=FIXUP)\n\nparam_num = sum([p.data.nelement() for p in model.parameters()])\nprint(\"Number of model parameters:\", param_num)","929b1798":"model = model.cuda()\ncudnn.benchmark = True\ncriterion = nn.CrossEntropyLoss().cuda()\noptimizer = torch.optim.SGD(model.parameters(), \n                            LR,\n                            momentum=momentum, \n                            nesterov=nesterov,\n                            weight_decay=weight_decay)","48f85ecb":"best_acc = 0\ntrain_acc_plt = []\n#test_acc_plt = []\n\nfor epoch in range(start_epoch, EPOCHS):\n    time_start = time.time()\n    adjust_learning_rate(optimizer, epoch+1)\n    \n    train_acc = train(train_loader, model, criterion, optimizer, epoch)\n    train_acc_plt.append(train_acc)\n    \n    #test_acc = validate(test_loader, model, criterion, epoch)\n    #test_acc_plt.append(test_acc)\n\n    # Save model with best accuracy\n    #if test_acc > best_acc:\n    #    torch.save(model.state_dict(), 'best_model.pth') \n\n    #best_acc = max(test_acc, best_acc)\n    time_end = (time.time() - time_start)\n    print(f'EPOCH: {epoch}\/{EPOCHS} \\t',\n          f'Time: {round(time_end)} sec \\t', \n          \"Train Accuracy:\", round(train_acc,2), '% \\t'\n          #\"Test Accuracy:\", round(test_acc,2), '% \\t'\n          #\"Best Accuracy:\", round(best_acc,2), '%'\n         )","8d465f8d":"plt.plot(train_acc_plt, label='Train Accuracy')\n#plt.plot(test_acc_plt, label='Test Accuracy')\nplt.legend()\nplt.savefig('accuracy_rate.png')\nplt.show()","a69ad93d":"torch.save(model.state_dict(), 'best_model.pth') \n#model.load_state_dict(torch.load('best_model.pth'))\n#model.eval()","49085d33":"# Test Validate\nmodel.eval()\nmodel.zero_grad()\n#print(\"Test Accuracy:\", accuracy_score(y_test_, predict(model, test_loader)))","e0440c13":"predictions = predict(model, X_sub_loader)\nout = np.column_stack((range(predictions.shape[0]), predictions))\nnp.savetxt('submission_v2.csv', out, header=\"Id,Category\", comments=\"\", fmt=\"%d,%d\")\nprint('Save submit')","1afdfae5":"print(os.listdir())","7d8159ba":"# DATA","a9749489":"#### Test Validate","136bd3be":"# Model","dfc5cc08":"# Submit","6ec2d463":"# FIT","947df3d3":"# NET def\n\u0442\u0443\u0442 \u043c\u043d\u043e\u0433\u043e \u043a\u043e\u0434\u0430 \u0441\u043e\u043f\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0445 \u0444\u0443\u043d\u043a\u0446\u0438\u0439\n\u0432 \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0435 \u0438\u0445 \u0445\u043e\u0442\u044f\u0431 \u0441\u043a\u0440\u044b\u0442\u044c \u043c\u043e\u0436\u043d\u043e \u0438 \u044d\u0442\u043e \u0443\u0434\u043e\u0431\u043d\u0435\u0439 \u0447\u0435\u043c \u043b\u0438\u0441\u0442\u0430\u0442\u044c \u0446\u0435\u043b\u0438\u043a\u043e\u0432\u044b\u0439 .py \u0444\u0430\u0439\u043b","35493ed0":"# Setup"}}