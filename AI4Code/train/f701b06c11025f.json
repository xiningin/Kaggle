{"cell_type":{"419d4fb8":"code","2b7e4169":"code","bebcacba":"code","647b6d04":"code","8f0def4b":"code","8bc902a2":"code","9c1a643e":"code","630438f5":"code","b20c99a0":"code","13552434":"code","79bb5e6a":"code","de30bd94":"code","fddaaa03":"code","aa738953":"code","1447dcf0":"code","f951da22":"code","b85b6f38":"code","c989f27a":"code","3d0f8e85":"code","76fe8c4f":"code","ed08b49e":"code","31b325b6":"markdown","3b490ee3":"markdown","e3598d3a":"markdown","0e646d8f":"markdown","30c18cd3":"markdown"},"source":{"419d4fb8":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport keras\nimport keras.backend as K\nimport tensorflow as tf\nfrom keras import applications\nfrom keras.models import Model\nfrom keras.layers import Flatten, Dense, Input,concatenate\nfrom keras.optimizers import Adam\nfrom keras.models import load_model, model_from_json\n\nimport random\n#from PIL import Image, ImageChops","2b7e4169":"gen=\"..\/input\/handwritten-signatures\/sample_signature\/sample_Signature\/genuine\"\nforg=\"..\/input\/handwritten-signatures\/sample_signature\/sample_Signature\/forged\"\n\ngentr=\"..\/input\/sigcomp-2009-train\/sigcomp 2009 train\/Sigcomp 2009 train\/genuine\"\nforgtr=\"..\/input\/sigcomp-2009-train\/sigcomp 2009 train\/Sigcomp 2009 train\/forgeries\"\n\ngent=\"..\/input\/sigcomp-2009\/sigcomp 2009\/genuines\"\nforgt=\"..\/input\/sigcomp-2009\/sigcomp 2009\/forgeries\"","bebcacba":"img_width, img_height, channels = 224, 224, 3\n\ndim = (img_width, img_height)\n\ndef to_rgb(img):\n    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) \n    img_rgb = np.asarray(np.dstack((img, img, img)), dtype=np.uint8)\n    return img_rgb\n\ndef returnimages(path,img):\n    image=cv2.imread(path+\"\/\"+ img)                  #bringing the image\n    image=cv2.resize(image, (img_width, img_height))\n    image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    image=to_rgb(image).reshape(1,img_width, img_height,3)\/255.0       #resizing and normalizing    \n    return image     \n\ndef getfiles(num,gen,forg):\n    a=os.listdir(gen)\n    b=os.listdir(forg)\n    c=str(num)\n    c=c[2:]\n    if(len(c)==2):\n        c=c+\"0\"\n    \n    n,m=[],[]\n    for i in b:\n        if i.endswith(c+\".png\"):\n            n=n+[i]\n        elif i.endswith(c+\".PNG\"):\n            n=n+[i]\n    for i in a:\n        if i.endswith(c+\".png\"):\n            m=m+[i]\n        elif i.endswith(c+\".PNG\"):\n            m=m+[i]\n    return m.pop(),n,m\n\ndef getfiles2(num):\n    a=os.listdir(gentr)\n    b=os.listdir(forgtr)\n    c=str(num)\n    c=c[2:]\n    if(len(c)==2):\n        c=c+\"0\"\n    n,m=[],[]\n    for i in b:\n        if (i.endswith(c+\"_001_6g.png\") or i.endswith(c+\"_002_6g.png\") or i.endswith(c+\"_003_6g.png\")\n            or i.endswith(c+\"_004_6g.png\") or i.endswith(c+\"_005_6g.png\")):\n            n=n+[i]\n        elif (i.endswith(c+\"_001_6g.PNG\") or i.endswith(c+\"_002_6g.PNG\") or i.endswith(c+\"_003_6g.PNG\")\n              or i.endswith(c+\"_004_6g.PNG\") or i.endswith(c+\"_005_6g.PNG\")):\n            n=n+[i]\n    for i in a:\n        if (i.endswith(c+\"_001_6g.png\") or i.endswith(c+\"_002_6g.png\") or i.endswith(c+\"_003_6g.png\")\n            or i.endswith(c+\"_004_6g.png\") or i.endswith(c+\"_005_6g.png\")):\n            m=m+[i]\n        elif (i.endswith(c+\"_001_6g.PNG\") or i.endswith(c+\"_002_6g.PNG\") or i.endswith(c+\"_003_6g.PNG\")\n              or i.endswith(c+\"_004_6g.PNG\") or i.endswith(c+\"_005_6g.PNG\")):\n            m=m+[i]\n    return m.pop(),n,m\n\n","647b6d04":"def triplet_loss(y_true, y_pred):\n    alpha = 0.5 #whatt is the alpha\n    anchor, positive, negative =y_pred[0,0:512], y_pred[0,512:1024], y_pred[0,1024:1536]# why do we take the same cell twice?\n    #i mean, 0:512, 512:1024 overlap while 0:511, 512:1023 from the testing file didn't\n    \n    positive_distance = K.mean(K.square(anchor - positive),axis=-1)\n    negative_distance = K.mean(K.square(anchor - negative),axis=-1)\n    return K.mean(K.maximum(0.0, positive_distance - negative_distance + alpha))","8f0def4b":"model = applications.vgg19.VGG19(weights='imagenet', include_top=False, pooling='max')\n#what are these options exactly","8bc902a2":"for layer in model.layers[:15]:\n    #why are just the top 15 not trainable\n    layer.trainable = False","9c1a643e":"anchor_in = Input(shape=(img_width, img_height, channels))\npos_in = Input(shape=(img_width, img_height, channels))\nneg_in = Input(shape=(img_width, img_height, channels))\n\n#what exactly are these? I heard about siamese nets, but what about this anchor out ?\n\nanchor_out = model(anchor_in)\npos_out = model(pos_in)\nneg_out = model(neg_in)\nmerged_vector = concatenate([anchor_out, pos_out, neg_out],axis=1)","630438f5":"model = Model(inputs=[anchor_in, pos_in, neg_in], outputs=merged_vector)","b20c99a0":"model.compile(optimizer=Adam(lr=0.000005),loss=triplet_loss)\n#lr is learning rate i think - why this number","13552434":"def generator():\n    for i in range(1,31):\n        if(i<10):\n            anc,neg,pos=getfiles(float(\"0.00\"+str(i)),gen,forg)\n        else:\n            anc,neg,pos=getfiles(float(\"0.0\"+str(i)),gen,forg)\n        for i in range(len(neg)):\n            for j in range(len(pos)):\n                anchor=returnimages(gen,anc)\n                positive=returnimages(gen,pos[j])\n                negative=returnimages(forg,neg[i])\n               # yield ([anc,pos[j],neg[i]],[0])\n                yield ([anchor,positive,negative],[0])","79bb5e6a":"for x in range(2):\n    model.fit_generator(generator(),steps_per_epoch=200,epochs=3)","de30bd94":"model.compile(optimizer=Adam(lr=0.000002),loss=triplet_loss)","fddaaa03":"def generator2():\n    x=[\"0.001\",\"0.004\", \"0.005\", \"0.006\", \"0.007\",\n       \"0.008\", \"0.009\", \"0.010\", \"0.011\", \"0.001\", \"0.010\"]\n    #what is this array, why do we take \u00b01 twice (0.001)\n  #  x=[\"0.001\", \"0.004\", \"0.006\", \"0.010\"]\n\n    for k in x:\n        anc,neg,pos=getfiles2(k)\n        frac=0.95 #what is this\n        inds = set(random.sample(list(range(len(neg))), int(frac*len(neg))))\n        neg = [n for i,n in enumerate(neg) if i not in inds]\n    \n        for i in range(len(neg)):\n            for j in range(len(pos)):\n                anchor=returnimages(gentr,anc)\n                positive=returnimages(gentr,pos[j])\n                negative=returnimages(forgtr,neg[i])\n               # yield ([anc,pos[j],neg[i]])\n                yield ([anchor,positive,negative],[0])","aa738953":"for x in range(2):\n    model.fit_generator(generator2(),steps_per_epoch=32,epochs=11)\n    \n    #why do we fit the model twice","1447dcf0":"tneg,tpos=0,0\nx=[0.002, 0.008, 0.016, 0.018, 0.024, 0.033, 0.035, 0.044, 0.046, 0.063,\n   0.070, 0.071, 0.077, 0.084, 0.085, 0.086, 0.089, 0.092, 0.093]\nfor k in x: #the id of signatures you want to check\n    #print(\"When k is \", k)\n    anc,neg,pos=getfiles(k,gent,forgt)\n    tneg=tneg+len(neg)\n    tpos=tpos+len(pos)\nprint(tneg,tpos)","f951da22":"os.listdir('..\/working')","b85b6f38":"# Save the weights\nmodel.save_weights('model_weights.h5')\n\n# Save the model architecture\n#with open('model_architecture.json', 'w') as f:\n#    f.write(model.to_json())","c989f27a":"os.listdir('..\/working')","3d0f8e85":"forg_passed=0\ngen_flagged=0\nx=[0.002, 0.008, 0.016, 0.018, 0.024, 0.033, 0.035, 0.044, 0.046, 0.063,\n   0.070, 0.071, 0.077, 0.084, 0.085, 0.086, 0.089, 0.092, 0.093]\n\nfor k in x: #the id of signatures you want to check\n    print(\"When k is \", k)\n    anc,neg,pos=getfiles(k,gent,forgt)\n    \n    anchor=returnimages(gent,anc)\n    for i in range(len(pos)): #pos\n        positive=returnimages(gent,pos[i])\n        x=model.predict([anchor,positive,anchor])\n        a, p, useless = x[0,0:512], x[0,512:1024], x[0,1024:1536]\n        #what are the useless parameters\n        #dist=sum(a-p)\n        dist=np.linalg.norm(a-p)\n        #print(\"positive distance is \",dist)\n        if(dist>32):\n        #  print(\"0\")\n            gen_flagged=gen_flagged+1\n            print(\"gen flagged - \",dist, \"file name is - \", pos[i])\n            \n        else:\n            gen_flagged=gen_flagged\n        #   print(\"1\")\n        \n    for j in range(len(neg)): #neg\n        negative=returnimages(forgt,neg[j])\n        x=model.predict([anchor,negative,anchor])\n        a, n, useless = x[0,0:512], x[0,512:1024], x[0,1024:1536]\n        #dist=sum(a-n)\n        dist=np.linalg.norm(a-n)\n        #print(\"negative distance is \",dist)\n        if(dist>32):\n            forg_passed=forg_passed\n          #  print(\"0\")\n        else:\n            forg_passed=forg_passed+1\n            print(\"forg passed - \",dist, \"file name is - \", neg[j])\n          #  print(\"1\")\n\nprint(\"forg_passed is \",forg_passed)\nprint(\"gen_flagged is \",gen_flagged)","76fe8c4f":"def getfilest(num,gen,forg):\n    a=os.listdir(gen)\n    b=os.listdir(forg)\n    c=str(num)\n    c=c[2:]\n    if(len(c)==2):\n        c=c+\"0\"\n    \n    n,m=[],[]\n    for i in b:\n        if i.endswith(c+\".png\"):\n            n=n+[i]\n        elif i.endswith(c+\".PNG\"):\n            n=n+[i]\n    for i in a:\n        if i.endswith(c+\".png\"):\n            m=m+[i]\n        elif i.endswith(c+\".PNG\"):\n            m=m+[i]\n    return m.pop(),m.pop(),n,m","ed08b49e":"forg_passed=0\ngen_flagged=0\nx=[0.002, 0.008, 0.016, 0.018, 0.024, 0.033, 0.035, 0.044, 0.046, 0.063,\n   0.070, 0.071, 0.077, 0.084, 0.085, 0.086, 0.089, 0.092, 0.093]\n\nfor k in x: #the id of signatures you want to check\n    print(\"When k is \", k)\n    anc1,anc2,neg,pos=getfilest(k,gent,forgt)\n    \n    anchor1=returnimages(gent,anc1)\n    anchor2=returnimages(gent,anc2)\n    for i in range(len(pos)): #pos\n        positive=returnimages(gent,pos[i])\n        x=model.predict([anchor1,positive,anchor2])\n        a1, p, a2 = x[0,0:512], x[0,512:1024], x[0,1024:1536]\n        #dist=sum(a-p)\n        dist1=np.linalg.norm(a1-p)\n        dist2=np.linalg.norm(a2-p)\n        dist=(dist1+dist2)\/2\n        #print(\"positive distance is \",dist)\n        if(dist>32):\n        #  print(\"0\")\n            gen_flagged=gen_flagged+1\n            print(\"gen flagged - \",dist, \"file name is - \", pos[i])\n            \n        else:\n            gen_flagged=gen_flagged\n        #   print(\"1\")\n        \n    for j in range(len(neg)): #neg\n        negative=returnimages(forgt,neg[j])\n        x=model.predict([anchor1,negative,anchor2])\n        a1, n, a2 = x[0,0:512], x[0,512:1024], x[0,1024:1536]\n        #dist=sum(a-n)\n        dist1=np.linalg.norm(a1-n)\n        dist2=np.linalg.norm(a2-n)\n        #print(\"negative distance is \",dist)\n        dist=(dist1+dist2)\/2\n        if(dist>32):\n            forg_passed=forg_passed\n          #  print(\"0\")\n        else:\n            forg_passed=forg_passed+1\n            print(\"forg passed - \",dist, \"file name is - \", neg[j])\n          #  print(\"1\")\n\nprint(\"forg_passed is \",forg_passed)\nprint(\"gen_flagged is \",gen_flagged)","31b325b6":"![](https:\/\/zefort.com\/wp-content\/uploads\/2018\/11\/signatures.jpg)","3b490ee3":"### Handwritten signature has been an important identity-verification method since ancient times. Compared with manual handwriting verification, the use of computer image recognition technology for handwriting verification is faster and avoids subjectivity. However, there are still some challenges in traditional image recognition methods, such as feature selection, lack of a standard basis, and low accuracy. For the first time, generative adversarial nets (GAN) technology is adopted to study the task of handwritten signature identification. A special network SIGAN (Signature Identification GAN, SIGAN)is proposed based on the idea of dual learning. The loss value of the trained discriminator of SIGAN is used as the identification threshold. The authenticity of the test handwritten signature is determined by comparing the threshold and loss value of the test image obtained through the network. The experimental data set in this study consists of five hard pen-type signatures, which include some real signatures and some deliberate imitations.","e3598d3a":"# GANs\n### Generative Adversarial Networks, or GANs, are deep learning architecture generative models that have seen wide success.There are thousands of papers on GANs and many hundreds of named-GANs, that is, models with a defined name that often includes \u201cGAN\u201c, such as DCGAN, as opposed to a minor extension to the method. Given the vast size of the GAN literature and number of models, it can be, at the very least, confusing and frustrating as to know what GAN models to focus on. In this post, you will discover the Generative Adversarial Network models that you need to know to establish a useful and productive foundation in the field.","0e646d8f":" # AI are Revolutionize forensic handwriting analysis  based on generative adversarial networks. (GANs)","30c18cd3":"![](https:\/\/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com\/wp-content\/uploads\/2019\/05\/Example-of-the-Architecture-for-the-Stacked-Generative-Adversarial-Network-for-Text-to-Image-Generation-1024x462.png)"}}