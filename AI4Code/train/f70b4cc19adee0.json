{"cell_type":{"c9962bca":"code","8837db51":"code","ffcf194b":"code","ac5496f2":"code","951343a1":"code","ef76f5aa":"code","5c873131":"code","0ed54339":"code","d9f43f4a":"code","bc38612a":"code","0d835fd7":"code","bbcb322e":"code","58e734f2":"code","9dd01f8b":"code","e90c1852":"markdown","6a3e6e95":"markdown","eb21a939":"markdown","49c825f2":"markdown","ee06392f":"markdown","3f683259":"markdown","13e6e02f":"markdown","a59096d8":"markdown","c6df8d47":"markdown","6b4a4182":"markdown","84d0801f":"markdown"},"source":{"c9962bca":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout \nimport pandas as pd\nimport matplotlib.pyplot as plt","8837db51":"train = np.loadtxt(open('\/kaggle\/input\/digit-recognizer\/train.csv', 'r'), delimiter=',', skiprows=1, dtype='float32')\ntest = np.loadtxt(open('\/kaggle\/input\/digit-recognizer\/test.csv', 'r'), delimiter=',', skiprows=1, dtype='float32')\ntrain_images = train[:, 1:].reshape((train.shape[0], 28, 28, 1)) \/ 255.0\ntrain_labels = train[:, 0].astype(np.uint8)\ntest_images = test.reshape((test.shape[0], 28, 28, 1)) \/ 255.0","ffcf194b":"plt.imshow(train_images[0])","ac5496f2":"augmentation_layer = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1, input_shape=(28, 28, 1)),\n    tf.keras.layers.experimental.preprocessing.RandomZoom((0.2, 0.2)),\n])","951343a1":"for i in range(5):\n    new_img = augmentation_layer(train_images[np.random.randint(train_images.shape[0])]).numpy()\n    plt.imshow(new_img.reshape((28, 28)))\n    plt.show()","ef76f5aa":"model = Sequential([\n    tf.keras.layers.Input((28, 28, 1)),\n    augmentation_layer,\n    Conv2D(32, 3, activation='relu', padding=\"same\"),\n    MaxPooling2D(2),\n    Conv2D(64, 3, activation='relu', padding=\"same\"),\n    MaxPooling2D(2),\n    Conv2D(64, 3, activation='relu', padding=\"same\"),\n    MaxPooling2D(2),\n    Flatten(),\n    Dropout(0.3),\n    Dense(128, activation='relu'),\n    Dropout(0.3),\n    Dense(10, activation='softmax')\n])","5c873131":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","0ed54339":"model.summary()","d9f43f4a":"history = model.fit(train_images, train_labels, epochs=100)","bc38612a":"import pandas as pd\npd.DataFrame(history.history).plot()","0d835fd7":"predition_model = tf.keras.Sequential()\nfor layer in model.layers:\n    if layer != augmentation_layer:\n        predition_model.add(layer)\npredition_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")","bbcb322e":"test_labels = np.argmax(predition_model.predict(test_images), axis=-1)\nprint(test_labels.shape)","58e734f2":"print(test_labels[:100])","9dd01f8b":"image_ids = np.arange(1, test_labels.shape[0]+1)\nresult = np.concatenate((image_ids.reshape(image_ids.shape[0], 1), test_labels.reshape(test_labels.shape[0], 1)), axis=1)\ndf = pd.DataFrame(result, columns=[\"ImageId\", \"Label\"], dtype='int')\ndf.to_csv(\"submission.csv\", index=False)","e90c1852":"## Create the model","6a3e6e95":"## Load data","eb21a939":"## Compile the model","49c825f2":"## Display summary of the model","ee06392f":"## Import necessary Libraries","3f683259":"## Sumbit the data","13e6e02f":"## Train the Model","a59096d8":"## Predict data","c6df8d47":"## Plot the learning curve","6b4a4182":"### Data Augmentation Layer","84d0801f":"Now we print first 100 item of test_labels."}}