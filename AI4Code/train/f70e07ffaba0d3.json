{"cell_type":{"e3a8ee11":"code","ada05519":"code","eca486ea":"code","7a85bba4":"code","4850f71b":"code","ec66bf9e":"code","b48efaee":"code","e73fbde1":"code","0156d447":"code","f8d5c302":"code","2a661446":"code","24947af8":"code","ccc79daa":"code","a9fe2fcf":"code","bfd8be6a":"code","c698558b":"code","7dcf6447":"code","516c453a":"code","18396d31":"code","3446af50":"code","9a38debe":"code","9e112fc9":"code","81780716":"markdown","434f3fb5":"markdown","98d3accb":"markdown","75eaf6e8":"markdown","db3d773b":"markdown","bd64e6f0":"markdown","64eb4d57":"markdown","79286764":"markdown","d1a3b239":"markdown","e56a5859":"markdown","0b0370cb":"markdown","132f036a":"markdown","b4a33ab2":"markdown"},"source":{"e3a8ee11":"# Import libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport cv2\nimport os\n\nimport seaborn as sns","ada05519":"labels = ['PNEUMONIA', 'NORMAL']\nimg_size = 150\n\ndef get_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","eca486ea":"train = get_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train')\ntest = get_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test')\nval = get_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val')","7a85bba4":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\nx_test = []\ny_test = []\n\nfor feature, label in train:\n    x_train.append(feature)\n    y_train.append(label)\n\nfor feature, label in test:\n    x_test.append(feature)\n    y_test.append(label)\n    \nfor feature, label in val:\n    x_val.append(feature)\n    y_val.append(label)","4850f71b":"x_train = np.array(x_train) \/ 255\nx_val = np.array(x_val) \/ 255\nx_test = np.array(x_test) \/ 255","ec66bf9e":"x_train = x_train.reshape(-1, img_size, img_size, 1)\ny_train = np.array(y_train)\n\nx_val = x_val.reshape(-1, img_size, img_size, 1)\ny_val = np.array(y_val)\n\nx_test = x_test.reshape(-1, img_size, img_size, 1)\ny_test = np.array(y_test)","b48efaee":"plt.figure(figsize=(10,10))\nfor i in range(5):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train[i][0], cmap='gray')\n    plt.title(labels[train[i][1]])\nplt.show()\n\nplt.figure(figsize=(10,10))\nfor i in range(1,6):\n    plt.subplot(5,5,i)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train[-i][0], cmap='gray')\n    plt.title(labels[train[-i][1]])\nplt.show()","e73fbde1":"l = []\nfor i in train:\n    if(i[1] == 0):\n        l.append(\"Pneumonia\")\n    else:\n        l.append(\"Normal\")\nsns.set_style(style='darkgrid')\nsns.countplot(x=l)","0156d447":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","f8d5c302":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))","2a661446":"model.summary()","24947af8":"model.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(10))","ccc79daa":"model.summary()","a9fe2fcf":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)","bfd8be6a":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train ,epochs = 12 , validation_data=(x_test, y_test), callbacks = [learning_rate_reduction])","c698558b":"plt.plot(history.history['accuracy'], label='test_accuracy')\nplt.plot(history.history['val_accuracy'], label = 'validation_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)","7dcf6447":"print(test_acc)","516c453a":"# Deprecated\npredictions = model.predict_classes(x_test)\n\n# Not working\n# predictions = (model.predict(x_test) > 0.5).astype(\"int32\")\n\npredictions = predictions.reshape(1,-1)[0]\npredictions[:15]","18396d31":"print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))","3446af50":"cm = confusion_matrix(y_test,predictions)\ncm","9a38debe":"cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])","9e112fc9":"plt.figure(figsize = (10,10))\nsns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = labels,yticklabels = labels)","81780716":"### Adding learning rate","434f3fb5":"# Training the model","98d3accb":"## Show five first and ten last images","75eaf6e8":"## With data augmentation to prevent overfitting (caused by the imbalance in dataset)","db3d773b":"## Normalize the data","bd64e6f0":"In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 75% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable : a sign of overfitting.","64eb4d57":"## Defining the Model","79286764":"## reshape data for deep learning","d1a3b239":"# Creating Confusion Matrix","e56a5859":"# Data augmentation","0b0370cb":"#  Loading the dataset and resizing images","132f036a":"# Testing the model","b4a33ab2":"## Data visualization"}}