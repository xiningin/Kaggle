{"cell_type":{"de6229b5":"code","fc3dd63d":"code","3ce0603a":"code","292c9f02":"code","7c54ccd9":"code","253ecd7b":"code","be8f9b36":"code","ba2b2f08":"code","66933869":"code","9a8abb87":"code","e7b68a2a":"code","f63d370f":"code","ed041873":"code","2f2c802e":"code","4e320b8e":"code","0df269f4":"code","8c3a508d":"code","96a0ce7d":"code","de9d294c":"code","5dc57a89":"code","33d3be15":"code","2be9dd5a":"code","157c98a3":"code","0fd27adb":"code","5743776f":"code","adfb4ac6":"code","b9a4ad30":"code","3a3ee00d":"code","71300ee3":"code","0464458b":"code","ccf87a25":"code","f3c04ba6":"code","eed09a6a":"code","5db19a41":"code","e6cf12c2":"code","4785f7ed":"code","6e6551cf":"code","57c8a995":"code","9e5f9f0b":"code","37fcf69d":"code","41991386":"code","52dfe922":"code","ae046ce5":"code","b3d136c6":"code","af95662f":"code","25b44b0c":"code","ba821115":"code","59433501":"markdown","a82ac474":"markdown","f3db88a6":"markdown","d11bbfbb":"markdown","06ba5f0c":"markdown","1133992f":"markdown","b8bffbe6":"markdown","b8e5105e":"markdown","3ac06ac7":"markdown","74c4fa88":"markdown","4ae8f4ee":"markdown","905e871a":"markdown","00aa4034":"markdown","c99d38fd":"markdown","8fb95cc3":"markdown","a010915e":"markdown","32b3fa44":"markdown","f97f6fa3":"markdown","aaa4611d":"markdown","1b6ac658":"markdown","37182e72":"markdown","47ef4c97":"markdown","cc2a8d0b":"markdown","26967c36":"markdown","b14ccfab":"markdown","64a0589f":"markdown","b5d504a0":"markdown","c2081bff":"markdown","6b8cdea9":"markdown","46d8fc16":"markdown","1a8ab1ac":"markdown","522ed5b7":"markdown","fb2cd3ef":"markdown","57bad00b":"markdown","9338acb2":"markdown","95b30475":"markdown","0e788875":"markdown","7a7c5371":"markdown"},"source":{"de6229b5":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","fc3dd63d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","3ce0603a":"#Load datasets\ntrain=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrain","292c9f02":"\n#Load datasets\ntest=pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntest\n","7c54ccd9":"submission = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsubmission","253ecd7b":"target = train['SalePrice']\nsns.distplot(train['SalePrice']);\n","be8f9b36":"var = 'OverallQual'\ndata = pd.concat([train['SalePrice'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(14, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","ba2b2f08":"corrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","66933869":"train_copy = train\ncombi = train_copy.drop('SalePrice', axis =1)\ncombi = combi.append(test)\ncombi","9a8abb87":"combi.drop(['Id'], axis=1, inplace=True)\ncombi","e7b68a2a":"combi.isnull().sum()","f63d370f":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimp = IterativeImputer(random_state=42)\n\n\nfor col in combi:\n    if combi[col].dtype==\"object\":\n        combi[col].fillna(\"not listed\", inplace=True)\n    if combi[col].dtype==\"int\":\n        #combi[col].fillna(combi[col].mode()[0], inplace=True)\n        combi[col].fillna(combi[col].mean(), inplace=True)\n    if combi[col].dtype=='float':\n        combi[col] = imp.fit_transform(combi[col].values.reshape(-1,1))\ncombi","ed041873":"combi.isnull().sum()","2f2c802e":"from sklearn import preprocessing\nfrom sklearn.preprocessing import OrdinalEncoder\n\nenc = OrdinalEncoder()\n\nfor col in combi:\n    if combi[col].dtype==\"object\":\n        combi[col] = enc.fit_transform(combi[col].values.reshape(-1,1))\ncombi","4e320b8e":"#combi = (combi - np.average(combi)) \/ (np.std(combi))\n#combi","0df269f4":"#combi = (combi - combi.min()) \/ (combi.max() - combi.min())\n#combi","8c3a508d":"long_train = combi[: len(train)]\nlong_test = combi[len(train) :]\nlong_train['target'] = target\nlong_train","96a0ce7d":"for col in long_train:\n    q_low = long_train[col].quantile(0.01)\n    q_hi  = long_train[col].quantile(0.99)\n    long_train_filtered = long_train[(long_train[col] < q_hi) & (long_train[col] > q_low)]\n\nlong_train_filtered","de9d294c":"long_train_filtered.isnull().sum()","5dc57a89":"y = long_train_filtered.target\nlong_train_filtered.drop(['target'], axis=1, inplace=True)","33d3be15":"combi_filtered = long_train_filtered.append(long_test)\ncombi_filtered","2be9dd5a":"X = combi_filtered[: len(long_train_filtered)]\nX_test = combi_filtered[len(long_train_filtered) :]","157c98a3":"\nfrom sklearn.preprocessing import RobustScaler\n\nrobust = RobustScaler()\n\nX = robust.fit_transform(X)\nX_test = robust.transform(X_test)\nX","0fd27adb":"from sklearn.feature_selection import SelectKBest, f_regression\n\nskb = SelectKBest(f_regression, k=20)\n\nX = skb.fit_transform(X, y)\nX_test = skb.transform(X_test)\nX.shape, y.shape, X_test.shape\n","5743776f":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\nX_train.shape, X_val.shape, y_train.shape,y_val.shape, X_test.shape","adfb4ac6":"from sklearn.linear_model import LinearRegression\n\nmodel1 = LinearRegression().fit(X_train, y_train)\nprint(model1.score(X_train, y_train))","b9a4ad30":"y_pred1 = model1.predict(X_val)\nprint(model1.score(X_val, y_val))","3a3ee00d":"from sklearn.metrics import mean_squared_error\n\nrmse = mean_squared_error(y_val, y_pred1, squared=False)\nrmse","71300ee3":"df=pd.DataFrame({'Actual': y_val, 'Predicted':y_pred1})\ndf","0464458b":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred1, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","ccf87a25":"from sklearn.neighbors import KNeighborsRegressor\n\nmodel2 = KNeighborsRegressor(algorithm='auto', n_neighbors=7,p=1, weights='distance').fit(X_train, y_train)\nprint(model2.score(X_train, y_train))","f3c04ba6":"y_pred2 = model2.predict(X_val)\nprint(model2.score(X_val, y_val))","eed09a6a":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred2))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred2))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred2)))","5db19a41":"compare = pd.DataFrame({'actual': y_val.values.ravel(), 'predicted': y_pred2})\ncompare","e6cf12c2":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred2, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","4785f7ed":"from sklearn.ensemble import ExtraTreesRegressor\n\nmodel3 = ExtraTreesRegressor(ccp_alpha=0, criterion='mse', max_features='auto', n_estimators=500, random_state=42).fit(X_train, y_train)\nprint(model3.score(X_train, y_train))","6e6551cf":"y_pred3 = model3.predict(X_val)\nprint(model3.score(X_val, y_val))","57c8a995":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred3))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred3))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred3)))","9e5f9f0b":"compare = pd.DataFrame({'actual': y_val.values.ravel(), 'predicted': y_pred3})\ncompare","37fcf69d":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred3, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","41991386":"from sklearn.ensemble import VotingRegressor\n\nemodel1 = VotingRegressor(estimators=[('LR', model1), ('KNN', model2), ('ET', model3)]).fit(X_train, y_train)\nprint(emodel1.score(X_train, y_train))","52dfe922":"y_pred4 = emodel1.predict(X_val)\nprint(emodel1.score(X_val, y_val))","ae046ce5":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_val, y_pred4))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_val, y_pred4))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, y_pred4)))","b3d136c6":"compare = pd.DataFrame({'actual': y_val.values.ravel(), 'predicted': y_pred4})\ncompare","af95662f":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred4, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","25b44b0c":"preds = emodel1.predict(X_test)\npreds = preds.astype(int)\npreds[preds < 0] = 0\npreds","ba821115":"submission.SalePrice = preds\nsubmission.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv(\"submission.csv\")\nsubmission","59433501":"Predict on validation set","a82ac474":"Predict on test set and submit","f3db88a6":"Compare","d11bbfbb":"Remove outliers","06ba5f0c":"Plot graph","1133992f":"Predict on validation set","b8bffbe6":"Fill null values","b8e5105e":"Normalise","3ac06ac7":"Problem statement","74c4fa88":"Graphics","4ae8f4ee":"Submit","905e871a":"Plot predictions","00aa4034":"Heatmap","c99d38fd":"KNN","8fb95cc3":"Extra Trees","a010915e":"Encode","32b3fa44":"Compare","f97f6fa3":"Predict on validation set","aaa4611d":"Import libraries","1b6ac658":"Compare","37182e72":"Load and read csv files","47ef4c97":"Define X and y","cc2a8d0b":"Graph of SalePrice","26967c36":"Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\nAcknowledgments\n\nThe Ames Housing dataset was compiled by Dean De Cock for use in data science education. It's an incredible alternative for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset.","b14ccfab":"Scale Robust","64a0589f":"Drop Id","b5d504a0":"Voting Regressor","c2081bff":"Check null values","6b8cdea9":"Append train and test","46d8fc16":"Metrics","1a8ab1ac":"Metrics","522ed5b7":"Split X_Train for training and validation","fb2cd3ef":"Metrics","57bad00b":"Select K Best","9338acb2":"Plot predictions","95b30475":"Predict on validation","0e788875":"Standardise","7a7c5371":"Select model - Linear Regression"}}