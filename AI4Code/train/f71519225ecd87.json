{"cell_type":{"88e99aa7":"code","52c97754":"code","8ae79a5a":"code","6cfe16f2":"code","bef2f97e":"code","abbcf7e5":"markdown","4bb38f8e":"markdown","e740b647":"markdown","be4c47f0":"markdown","4040b56e":"markdown"},"source":{"88e99aa7":"import pandas as pd\n\nimport time\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nimport torch\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.optim import lr_scheduler\nimport os\n\ndevice = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","52c97754":"class RetinopathyDatasetTrain(Dataset):\n\n    def __init__(self, csv_file):\n\n        self.data = pd.read_csv(csv_file)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join('..\/input\/aptos2019-blindness-detection\/train_images', self.data.loc[idx, 'id_code'] + '.png')\n        image = Image.open(img_name)\n        image = image.resize((256, 256), resample=Image.BILINEAR)\n        label = torch.tensor(self.data.loc[idx, 'diagnosis'])\n        return {'image': transforms.ToTensor()(image),\n                'labels': label\n                }","8ae79a5a":"model = torchvision.models.resnet101(pretrained=False)\nmodel.load_state_dict(torch.load(\"..\/input\/pytorch-pretrained-models\/resnet101-5d3b4d8f.pth\"))\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(2048, 1)\n\nmodel = model.to(device)","6cfe16f2":"train_dataset = RetinopathyDatasetTrain(csv_file='..\/input\/aptos2019-blindness-detection\/train.csv')\ndata_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n\nplist = [\n         {'params': model.layer4.parameters(), 'lr': 1e-4, 'weight': 0.001},\n         {'params': model.fc.parameters(), 'lr': 1e-3}\n         ]\n\noptimizer = optim.Adam(plist, lr=0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=10)","bef2f97e":"since = time.time()\ncriterion = nn.MSELoss()\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n    print('-' * 10)\n    scheduler.step()\n    model.train()\n    running_loss = 0.0\n    tk0 = tqdm(data_loader, total=int(len(data_loader)))\n    counter = 0\n    for bi, d in enumerate(tk0):\n        inputs = d[\"image\"]\n        labels = d[\"labels\"].view(-1, 1)\n        inputs = inputs.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.float)\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n        counter += 1\n        tk0.set_postfix(loss=(running_loss \/ (counter * data_loader.batch_size)))\n    epoch_loss = running_loss \/ len(data_loader)\n    print('Training Loss: {:.4f}'.format(epoch_loss))\n\ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\ntorch.save(model.state_dict(), \"model.bin\")","abbcf7e5":"# Dataset Class","4bb38f8e":"# Create dataset + optimizer","e740b647":"# Training Loop","be4c47f0":"# Cool Imports","4040b56e":"# Get the model"}}