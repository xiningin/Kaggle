{"cell_type":{"f8b772b2":"code","abb824eb":"code","3d541c6d":"code","778a49ec":"code","ce63e9cb":"code","974e3d1a":"code","27435e07":"code","34624c76":"code","a090c3d2":"code","93ad6b9e":"code","f0a2d23a":"code","b82099b1":"code","9b605523":"code","9832fcf1":"code","bb2e6025":"code","b7858163":"code","487bd5da":"code","d1257972":"code","e98af699":"code","d45b0793":"code","8026db8d":"code","843079bb":"code","601cd3f3":"code","8984804f":"code","db53b2c9":"code","b0315006":"code","4123c001":"code","b9b5e6f5":"code","f89b3fa5":"code","44b13fc3":"code","3e12c178":"code","be7ac2b4":"code","7fe7b85f":"code","55435494":"code","235fb682":"code","4f4a4d40":"code","28809d37":"code","48e09983":"code","764fdd76":"code","96c6c6bb":"code","4003a70f":"markdown","7bcb807d":"markdown","5edd2af4":"markdown","9302f6b9":"markdown","ef3e6cb3":"markdown","1865e347":"markdown","1c0477d7":"markdown","67f0b4b1":"markdown","e5eeacc8":"markdown","f485d787":"markdown","9859cf22":"markdown","3914fac5":"markdown","991f0e2c":"markdown","68a8c623":"markdown","3a64ff22":"markdown","ac1cd28d":"markdown","75f0f277":"markdown","d1659b97":"markdown","8fb99289":"markdown","efacf299":"markdown","ab771ca2":"markdown","71e6b036":"markdown","2bd08192":"markdown","403ea55b":"markdown"},"source":{"f8b772b2":"import numpy as np # linear algebra\nimport pandas as pd\nfrom tqdm import tqdm\nfrom glob import glob\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.utils import *\nimport numpy as np\nimport os","abb824eb":"normal = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/train_Normal_128.npy')\nviral = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/train_Virus_128.npy')\nbacterial = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/train_bacteria_128.npy')","3d541c6d":"normal.shape, viral.shape, bacterial.shape","778a49ec":"label_normal = np.zeros(len(normal))\nlabel_bacterial = np.ones(len(bacterial))\nlabel_viral = np.full(len(viral),2, dtype = int)","ce63e9cb":"train_data = np.concatenate((normal,bacterial,viral),axis=0)\ntrain_label = np.concatenate((label_normal,label_bacterial,label_viral),axis=0)","974e3d1a":"train_label.shape, train_data.shape","27435e07":"import matplotlib.pyplot as plt","34624c76":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(normal[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","a090c3d2":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(viral[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","93ad6b9e":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(bacterial[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","f0a2d23a":"test_normal = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/test_Normal_128.npy')\ntest_viral = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/test_Virus_128.npy')\ntest_bacterial = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/test_bacteria_128.npy')","b82099b1":"test_normal.shape, test_viral.shape , test_bacterial.shape","9b605523":"label_test_normal = np.zeros(len(test_normal))\nlabel_test_bacterial = np.ones(len(test_bacterial))\nlabel_test_viral = np.full(len(test_viral),2, dtype = int)","9832fcf1":"test_data = np.concatenate((test_normal, test_bacterial, test_viral),axis=0)\ntest_label = np.concatenate((label_test_normal,label_test_bacterial,label_test_viral),axis=0)","bb2e6025":"test_data.shape","b7858163":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(test_normal[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","487bd5da":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(test_viral[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","d1257972":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(test_bacterial[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","e98af699":"from sklearn.utils import class_weight\n \n \nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train_label),\n                                                 train_label)\nclass_weights","d45b0793":"# plot confusion matrix\n\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport pandas.util.testing as tm\nfrom sklearn import metrics\nimport seaborn as sns\nsns.set()\n\nplt.rcParams[\"font.family\"] = 'DejaVu Sans'\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues,\n                          save = False):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.grid(b=False)\n    if save == True:\n      plt.savefig('Confusion Matrix.png', dpi = 900)\n    \ndef plot_roc_curve(y_true, y_pred, classes):\n\n    from sklearn.metrics import roc_curve, auc\n\n    # create plot\n    fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n    for (i, label) in enumerate(classes):\n        fpr, tpr, thresholds = roc_curve(y_true[:,i].astype(int), y_pred[:,i])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (label, auc(fpr, tpr)))\n\n    # Set labels for plot\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n    c_ax.set_title('Roc AUC Curve')","8026db8d":"pred = model.predict_generator(val_generator, steps= test_label.shape[0]\/batch_size)","843079bb":"pred.shape","601cd3f3":"test_label.shape[0]\/32","8984804f":"# test model performance\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\n\n\ndef test_model(model, test_generator, y_test, class_labels, cm_normalize=True, \\\n                 print_cm=True):\n    \n    # BS = 16\n    results = dict()\n    \n    # n = len(testy)\/\/ BS\n\n    # testX = testX[:BS*n]\n    # testy = testy[:BS*n]\n    steps = y_test.shape[0]\/batch_size\n#     y_test = y_test[:steps*batch_size]\n\n    print('Predicting test data')\n    test_start_time = datetime.now()\n    y_pred_original = model.predict_generator(test_generator, verbose=1, steps = steps)\n    # y_pred = (y_pred_original>0.5).astype('int')\n\n    y_pred = np.argmax(y_pred_original, axis = 1)\n    # y_test = np.argmax(testy, axis= 1)\n    #y_test = np.argmax(testy, axis=-1)\n    \n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n    y_test = y_test.astype(int) # sparse form not categorical\n    \n\n    # balanced_accuracy\n    from sklearn.metrics import balanced_accuracy_score\n    balanced_accuracy = balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n    print('---------------------')\n    print('| Balanced Accuracy  |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(balanced_accuracy))\n\n    \n    # calculate overall accuracty of the model\n    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n\n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_report = metrics.classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_report'] = classification_report\n    print(classification_report)\n\n\n    \n    # confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    plt.figure(figsize=(6,4))\n    plt.grid(b=False)\n    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix')\n    plt.show()\n    \n    #roc plot\n#     plot_roc_curve(to_categorical(y_test), y_pred_original, class_labels)\n    \n    from sklearn.metrics import roc_curve, auc\n\n    # create plot\n    fig, c_ax = plt.subplots(1,1, figsize = (7, 7))\n    for (i, label) in enumerate(class_labels):\n        fpr, tpr, thresholds = roc_curve(to_categorical(y_test)[:,i].astype(int), y_pred_original[:,i])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (label, auc(fpr, tpr)))\n\n    # Set labels for plot\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n    c_ax.set_title('Roc AUC Curve')\n    plt.show()\n\n\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    return\n\n\nfrom keras.callbacks import Callback\nclass MyLogger(Callback):\n  \n  def __init__(self, test_generator, y_test, class_labels):\n    super(MyLogger, self).__init__()\n    self.test_generator = test_generator\n    self.y_test = y_test\n    self.class_labels = class_labels\n    \n  def on_epoch_end(self, epoch, logs=None):\n    test_model(self.model, self.test_generator, self.y_test, self.class_labels)","db53b2c9":"from keras.utils import to_categorical\ntrain_label = to_categorical(train_label, num_classes= 3)\ntest_label  = to_categorical(test_label, num_classes = 3)","b0315006":"batch_size = 32","4123c001":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.callbacks import *\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1\/255,\n                                  width_shift_range = 0.1,\n                                  height_shift_range = 0.1,\n                                  fill_mode = 'constant',\n                                  zoom_range = 0.2,\n                                  rotation_range = 30)\n\nval_datagen = ImageDataGenerator(rescale = 1\/255)\n\ntrain_generator = train_datagen.flow(train_data,\n                                     train_label, \n                                     batch_size = batch_size, \n                                     shuffle = True)\n\nval_generator = val_datagen.flow(test_data,\n                                 test_label,\n                                 batch_size = batch_size,\n                                 shuffle = False)","b9b5e6f5":"images, labels = train_generator.next()","f89b3fa5":"images.shape","44b13fc3":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(images[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","3e12c178":"def fix_generator(data_generator):\n    \n    for img, label in data_generator:\n        \n        img = np.stack((img.squeeze(),)*3, axis=-1)\n        \n        yield img, label\n\ntrain_generator = fix_generator(train_generator)\nval_generator = fix_generator(val_generator)","be7ac2b4":"os.mkdir('Model')\nos.mkdir('History')","7fe7b85f":"\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.000001, lr_rampup_epochs=10, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * 4\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    \n    return lrfn\n","55435494":"from keras.callbacks import *\n\ndef get_callbacks():\n    \n    filepath = 'Model\/best_model_multiclass_128.h5'\n    callback1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n    callback2 = MyLogger(val_generator, \n                         y_test = np.argmax(test_label, axis = 1),\n                         class_labels = ['Normal', 'Viral', 'Bacterial'])\n    \n    callback3 = CSVLogger('History\/Multiclass_Log_128.csv')\n    lr_schedule = LearningRateScheduler(build_lrfn(), verbose=1)\n\n    return [callback1 ,callback2, callback3, lr_schedule]","235fb682":"from keras.layers import *\nfrom keras.models import *\nfrom keras.applications import *\nfrom keras.optimizers  import *\n\nbase_model = ResNet50(input_shape = (128, 128, 3), weights = 'imagenet', include_top = False)\n\ninputs = base_model.input\noutputs = base_model.output\noutputs = GlobalAveragePooling2D()(outputs)\noutputs = Dense(64, activation = 'relu')(outputs)\noutputs = Dense(3, activation = 'softmax')(outputs)\n\nmodel = Model(inputs, outputs)\nmodel.compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = 1e-6), metrics = ['acc'])\nmodel.summary()","4f4a4d40":"test_model(model, val_generator, y_test = np.argmax(test_label, axis = 1),\n                         class_labels = ['Normal', 'Viral', 'Bacterial'])","28809d37":"history = model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_data)\/ batch_size,\n                              validation_data=val_generator,\n                              validation_steps= len(test_data)\/batch_size,\n                              class_weight =class_weights,\n                              epochs = 300,\n                              callbacks = get_callbacks(),\n                              verbose = 1\n                              )","48e09983":"from keras.models import load_model\nbest_model = load_model('\/kaggle\/working\/Model\/best_model_multiclass_128.h5')","764fdd76":"test_model(best_model, \n           val_generator,\n           y_test = np.argmax(test_label, axis = 1),\n           class_labels = ['Normal', 'Viral', 'Bacterial'])","96c6c6bb":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nacc = model.history.history['acc']\nval_acc = model.history.history['val_acc']\nloss = model.history.history['loss']\nval_loss = model.history.history['val_loss']\n\nepochs = range(0,len(acc))\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\n\nplt.plot(epochs, acc, 'r', label='Training accuracy',marker = \"o\")\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy',marker = \"o\")\nplt.title('Training and validation accuracy')\nplt.xticks(np.arange(0, len(acc), 10))\nplt.legend(loc=0)\nplt.figure()\n\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\nplt.plot(epochs, loss, 'r', label='Training Loss',marker = \"o\")\nplt.plot(epochs, val_loss, 'b', label='Validation Loss',marker = \"o\")\nplt.title('Training and validation Loss')\nplt.xticks(np.arange(0, len(acc), 10))\nplt.legend(loc=0)\n#plt.savefig('Multiclass Model .png')\nplt.figure()\nplt.show()\n","4003a70f":"# **Loading Training Files**","7bcb807d":"# Dealing with Class Imbalance","5edd2af4":"## Normal","9302f6b9":"# ImageDataGenerator","ef3e6cb3":"# Vizualization After Augmentation","1865e347":"# Callback","1c0477d7":"### Normal","67f0b4b1":"## Viral","e5eeacc8":"# Training","f485d787":"# Best Model Performance","9859cf22":"## Bacterial","3914fac5":"## Visualization","991f0e2c":"## Bacterial","68a8c623":"# Plotting EpochPlot","3a64ff22":"# One Hot Encoding the labels","ac1cd28d":"# Loading Test Data","75f0f277":"# Custom Callback","d1659b97":"# Fixing the channels","8fb99289":"# Viral","efacf299":"# Loading Best Model","ab771ca2":"I have converted all images to numpy array to boost speed","71e6b036":"## Visualization","2bd08192":"# Grad-CAM and Saliency Map \ncoming soon....","403ea55b":"# Building Model"}}