{"cell_type":{"1dc754ea":"code","48ada8da":"code","efee6e83":"code","becaa9ce":"code","d4fd2c23":"code","3c0e1ea3":"code","f0797154":"markdown","0be5874b":"markdown","39e97d30":"markdown","12b07777":"markdown","db49d459":"markdown","4a700420":"markdown"},"source":{"1dc754ea":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","48ada8da":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nfrom sklearn.preprocessing import StandardScaler\nfrom PIL import Image\n\n\ndef plot_images(X_image, num_images, title):\n    num_images_x = int(np.sqrt(num_images))\n    fig3, ax_array = plt.subplots(num_images_x, num_images_x, figsize=(8, 8))\n    for i, ax in enumerate(ax_array.flat):\n        image = X_image[i, :]\n        num_rows = num_cols = int(np.sqrt(len(image)))\n        ax.imshow(image.reshape(num_rows, num_cols, order='F'), cmap='gray')\n        fig3.suptitle(title)\n        ax.axis('off')\n\nos.chdir('\/kaggle\/input\/coursera-andrewng-ml-dataset')\ndata2 = sio.loadmat('ex7faces.mat')\nX_image = data2['X']\nnum_images = 100\nplot_images(X_image, num_images, 'Original face images')","efee6e83":"from sklearn.decomposition import PCA\nscaler = StandardScaler()\nX_image_scaled = scaler.fit_transform(X_image)\npca = PCA(n_components=100)\npca.fit(X_image_scaled)","becaa9ce":"X_image_reduced = pca.transform(X_image_scaled)\nprint(X_image_reduced[0, :])","d4fd2c23":"X_image_recovered = pca.inverse_transform(X_image_reduced)\nplot_images(X_image_recovered, num_images, 'Recovered face images')","3c0e1ea3":"pca = PCA(n_components=36)\npca.fit(X_image_scaled)\nX_image_reduced = pca.transform(X_image_scaled)\nX_image_recovered = pca.inverse_transform(X_image_reduced)\nplot_images(X_image_recovered, num_images, 'Recovered face images from 36 principal components')","f0797154":"# PCA on Faces","0be5874b":"To understand what is lost in the dimension reduction, you can recover the data using only the projected dataset. This can be done using the inverse_transform method of PCA class. Now display the images using recovered data. From the reconstruction, you can ob-serve that the general structure and appearance of the face are kept while\nthe fine details are lost.","39e97d30":"We can experiment further by increasing or decreasing the number of principal components to be used for the projected dataset and then plotting the images using recovered data from the projected dataset. We will see that as the number of components increases, finer details of the images are captured.","12b07777":"Now that you have computed the principal components for the face dataset, you can use it to reduce the dimension of the face dataset. This allows you to use your learning algorithm with a smaller input size (e.g., 100 dimensions) instead of the original 1024 dimensions. This can help speed up your learning algorithm.project the face dataset onto only the first 100 principal components. Concretely, each face image is now described\nby a vector z(i) which is an element of R100.","db49d459":"In this exercise, you will run PCA on face images to see how it can be used in practice for dimension reduction.The dataset ex7faces.mat contains a dataset X of face images, each 32 by 32 in grayscale. Each row of X corresponds to one face image (a row vector of length 1024). The first step is to load and visualize the first 100 of these face images.","4a700420":"To run PCA on the face dataset, we first normalize the dataset by subtracting the mean of each feature from the data matrix X. We will also do feature scaling using sklearn's StandardScaler which performs mean normalization of the features in addition to feature scaling. We will the run sklearn's PCA algorithm and compute the principal components of the image dataset."}}