{"cell_type":{"cfff1abe":"code","e653931f":"code","e926cad2":"code","4bdb8019":"code","d190ec4f":"code","bcfd6abc":"code","0870dcff":"code","ce0542be":"code","0c5b9a9f":"code","3a34f273":"code","b1ea9a30":"code","1f11240b":"code","599410de":"code","4707bb85":"code","cbd80fe3":"code","e9bbb9d9":"code","29192ac4":"code","a77e6d26":"code","f586a696":"code","e28fc101":"code","454366ae":"code","7ec0d429":"code","2dcad63a":"code","3733012a":"code","c8217484":"code","277e89a8":"code","b977e4bd":"code","92d8a14e":"code","20a639e2":"code","b4bb4165":"code","e22a3934":"code","2cec729a":"code","1cea925e":"code","1cec0367":"markdown","6c187865":"markdown","42673618":"markdown","da53ac44":"markdown","8ae78703":"markdown","f20b34fd":"markdown","e82fbf70":"markdown","4277d07f":"markdown","1feb87aa":"markdown","e66ded6a":"markdown","a5010a73":"markdown"},"source":{"cfff1abe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e653931f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","e926cad2":"df = pd.read_csv('\/kaggle\/input\/judicial-expenditures-across-all-50-states\/jeee16t08.csv',index_col=0)","4bdb8019":"df.head()","d190ec4f":"df.drop(df.index[0],inplace=True)","bcfd6abc":"df.isnull().sum()","0870dcff":"df.columns","ce0542be":"df.columns = ['Population_2016','Total_justice_system_PC','Police_Protection_PC','Judicial_and_legal_PC','Corrections_PC','Total_justice_system_Employment','police_protection_Total_Employment','police_protection_Sworn_only_Employment','Judicial_and_legal_Employment','Corrections_Employment']","0c5b9a9f":"df.head()","3a34f273":"sns.scatterplot(x='Total_justice_system_PC',y='Population_2016',data=df)","b1ea9a30":"scaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df)","1f11240b":"pca = PCA()\npca.fit(df_scaled)","599410de":"pca.explained_variance_ratio_.round(3)","4707bb85":"plt.figure(figsize=(12,10))\nplt.plot(range(1,11),pca.explained_variance_ratio_.cumsum(),marker='o',linestyle='--')\nplt.title(\"Explained Variance by components\")\nplt.xlabel(\"Number of components\")\nplt.ylabel(\"cumulative explained variance\")\nplt.show()","cbd80fe3":"pca = PCA(n_components=3)","e9bbb9d9":"pca.fit(df_scaled)","29192ac4":"pca.transform(df_scaled)","a77e6d26":"scores_pca = pca.transform(df_scaled)","f586a696":"wcss = []\nfor i in range(1,21):\n    kmeans_pca = KMeans(n_clusters=i,init='k-means++',random_state=42)\n    kmeans_pca.fit(scores_pca)\n    wcss.append(kmeans_pca.inertia_)","e28fc101":"plt.figure(figsize=(12,10))\nplt.plot(range(1,21),wcss,marker='o',linestyle='--')\nplt.xlabel('no of clusters')\nplt.ylabel('WCSS')\nplt.title('Kmeans with PCA Clustering')\nplt.show()","454366ae":"# no of clusters =4\nkmeans_pca = KMeans(n_clusters=4,init='k-means++',random_state=42)","7ec0d429":"kmeans_pca.fit(scores_pca)","2dcad63a":"#We create new dataframe with original Features and PCA scores and assigned clusters\ndf_pca_seg_Kmeans = pd.concat([df.reset_index(drop=True),pd.DataFrame(scores_pca)],axis=1)","3733012a":"df_pca_seg_Kmeans.columns.values[-3:] = ['component_1','component_2','component_3']\ndf_pca_seg_Kmeans['Segment_KMeans_PCA'] =kmeans_pca.labels_ ","c8217484":"df_pca_seg_Kmeans['Segment'] = df_pca_seg_Kmeans['Segment_KMeans_PCA'].map({0:'First',1:'Second',2:'Third',3:'Fourth'})","277e89a8":"x_axis = df_pca_seg_Kmeans['component_2']\ny_axis = df_pca_seg_Kmeans['component_1']\n\nplt.figure(figsize=(12,8))\nsns.scatterplot(x_axis,y_axis,hue=df_pca_seg_Kmeans['Segment'],palette=['g','r','c','m'])\nplt.title('Clusters by PCA Components')\nplt.show()","b977e4bd":"df1 = df.copy()\ndf1.reset_index(inplace=True)","92d8a14e":"df_pca_seg_Kmeans['State'] = df1['State']","20a639e2":"df_pca_seg_Kmeans[df_pca_seg_Kmeans['Segment']=='First']['State']","b4bb4165":"df_pca_seg_Kmeans[df_pca_seg_Kmeans['Segment']=='Second']['State']","e22a3934":"df_pca_seg_Kmeans[df_pca_seg_Kmeans['Segment']=='Third']['State']","2cec729a":"df_pca_seg_Kmeans[df_pca_seg_Kmeans['Segment']=='Fourth']['State']","1cea925e":"sns.scatterplot(x='Total_justice_system_PC',y='Population_2016',hue='Segment',data=df_pca_seg_Kmeans)","1cec0367":"#### K Means Clustering using PCA","6c187865":"### Visualizing the components","42673618":"The graph shows the amount of variance captured (on the y-axis) depending on the number of components we include (the x-axis). A rule of thumb is to preserve around 80 % of the variance. So, in this instance, we decide to keep 3 components.","da53ac44":"we run the algorithm with a different number of clusters. Then, we determine the Within Cluster Sum of Squares or WCSS for each solution. Based on the values of the WCSS and an approach known as the Elbow method, we make a decision about how many clusters we\u2019d like to keep.","8ae78703":"We\u2019ll incorporate the newly obtained PCA scores in the K-means algorithm. That\u2019s how we can perform segmentation based on principal components scores instead of the original features.","f20b34fd":"### Data Preprocessing","e82fbf70":"For our data set, that means 3 principal components:","4277d07f":"### KMeans Clustering with PCA results","1feb87aa":"#### Determine no of clusters for K means","e66ded6a":"when we employ PCA prior to using K-means we can visually separate almost the entire data set. That was one of the biggest goals of PCA \u2013 to reduce the number of variables by combining them into bigger, more meaningful features.\n","a5010a73":"And from this graph, we determine the number of clusters we\u2019d like to keep. To that effect, we use the Elbow-method. The approach consists of looking for a kink or elbow in the WCSS graph. Usually, the part of the graph before the elbow would be steeply declining, while the part after it \u2013 much smoother. In this instance, the kink comes at the 4 clusters mark. So, we\u2019ll be keeping a four-cluster solution."}}