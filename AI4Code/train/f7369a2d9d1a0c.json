{"cell_type":{"4ac008d0":"code","9db2bf05":"code","47b1f785":"code","1fa667c1":"code","3ae7f4e2":"code","a0bab418":"code","2c6d4906":"code","4513cfca":"code","4a69b0c7":"code","47be43be":"code","05687e53":"code","968c47d7":"code","c5da4d49":"code","888be1a4":"code","60c02621":"code","e130db1e":"code","c410bdee":"code","ad4af0ed":"code","15550c04":"code","224d4dea":"code","17589b9e":"code","985662be":"code","b4237291":"code","5af6408a":"code","e9e6163f":"code","1582e52c":"markdown","33a5bfc1":"markdown","540e469c":"markdown","3a132936":"markdown","735efcf6":"markdown","f04f9a6e":"markdown","be4d4795":"markdown","0dcd80df":"markdown","f441f471":"markdown","af01a6c2":"markdown","cabe0c8b":"markdown","ce0a589e":"markdown","6030c529":"markdown","74212d7f":"markdown","09d20ff6":"markdown","a7d74015":"markdown","8548618b":"markdown","a50fa9a3":"markdown","5e496f2e":"markdown","93b47b42":"markdown","a3b7edf5":"markdown","a1b70588":"markdown"},"source":{"4ac008d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9db2bf05":"import pandas as pd\ntrain_dir='\/kaggle\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/train'\ntest_dir='\/kaggle\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test'","47b1f785":"import os\nclasses_train=os.listdir(train_dir)\nclasses_test=os.listdir(test_dir)","1fa667c1":"print(classes_train)","3ae7f4e2":"print(classes_test)","a0bab418":"# First for Training data\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen=ImageDataGenerator(\n    zoom_range=0.2, #the amount of zooming u need\n    horizontal_flip=True, # Make a horizontal copy of image\n    rescale=1.0\/255.0, # Normalize the new images\n    width_shift_range=0.10, # The percentage of Width shifitning\n    height_shift_range=0.10, # The percentage of height shifitning\n    shear_range=0.1 #Shear angle in counter-clockwise direction in degrees\n)\ntrain_generator=train_datagen.flow_from_directory(\n    train_dir,\n    class_mode='binary',\n    color_mode='rgb',\n    batch_size=32,\n    target_size=(1000,1000,3)[:2]\n)","2c6d4906":"# Second for Testing data\ntest_datagen=ImageDataGenerator(\n    rescale=1.0\/255.0\n)\ntest_generator=test_datagen.flow_from_directory(\n    test_dir,\n    class_mode='binary',\n    color_mode='rgb',\n    batch_size=32,\n    target_size=(1000,1000,3)[:2]\n)","4513cfca":"from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nearlystop=EarlyStopping(patience=6)\nlearning_rate_reduction=ReduceLROnPlateau(\n    monitor='val_acc',\n    patience=3,\n    verbose=1,\n    factor=0.5,\n    min_lr=0.00001\n)","4a69b0c7":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Flatten,MaxPooling2D,Conv2D,Dropout,Activation,BatchNormalization\n\nmodel=Sequential() \n\n\nmodel.add(Conv2D(32,(5,5),activation='relu',input_shape=(1000,1000,3)))\n# 16 is the number of filters, (3,3) it the filter size,acitivation is the activation function and input_shape is the size of the image \nmodel.add(MaxPooling2D(5,5))\n#(2,2) is the pool size \n\nmodel.add(Conv2D(64,(5,5),activation='relu'))\nmodel.add(MaxPooling2D(5,5))\n\n\nmodel.add(Conv2D(128,(5,5),activation='relu'))\nmodel.add(MaxPooling2D(5,5))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\n# 128 is the number of the hideen layers\n#model.add(Dropout(0.5))\n# Dropout is a function that reducess over fiting by removing random layers every epoch\n\nmodel.add(Dense(1,activation='sigmoid'))\n# 1 the number of outputs \n","47be43be":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","05687e53":"model.summary()","968c47d7":"callbacks = [earlystop, learning_rate_reduction]","c5da4d49":"model.fit(\n    train_generator, \n    epochs=10,\n    validation_data=test_generator,\n    callbacks=callbacks\n)","888be1a4":"losses = pd.DataFrame(model.history.history)","60c02621":"losses.head()","e130db1e":"losses[['loss','val_loss']].plot()","c410bdee":"losses[['accuracy','val_accuracy']].plot()","ad4af0ed":"losses.plot()","15550c04":"model.evaluate(test_generator)","224d4dea":"model_pred=model.predict(test_generator)","17589b9e":"print(model_pred)","985662be":"test_generator.classes","b4237291":"from tensorflow.keras.preprocessing import image\npredict_path='\/kaggle\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test\/NORMAL\/NORMAL2-IM-0059-0001.jpeg'\nmy_image = image.load_img(predict_path,target_size=(1000,1000,3))","5af6408a":"import numpy as np\nmy_image = np.expand_dims(my_image, axis=0)","e9e6163f":"np.argmax(model.predict(my_image))","1582e52c":"# 7. Data Augmentation\n","33a5bfc1":"To understand how CNN work you first need to understand what is the image and how it works. Any image could be 1D in gray scale case, or it may be 3D in the case of RGB. 1D array may that each pixel in the image will have a singel value. On the contrary, in the case of RGB each pixel will have 3 values: one for red, one for green and one for blue.\n\n\n![306461_15yDvGKV47a0nkf5qLKOOQ.png](attachment:67acb278-8bfb-4279-9a4b-40c3871b57e0.png)\n\n\n\nLets talk about grayscale images so it will be more clearier. In this image show what is the convolution is, we have an input image and the kernel is the filter size here it is (3 x 3). Each pixel value is multiplied by its corresponding value, after this All pixel values are summed. This convolution passed to the second convolution and so on..\n![750710_QS1ArBEUJjjySXhE.png](attachment:8a722775-d3c5-483c-af37-59882c6f3ccf.png)","540e469c":"# 6. Start the project","3a132936":"# 1. What is the CNN?","735efcf6":"Lets say if we have images in size of (1000 X 1000) and there are in RGB. So that means we have 3,000,000 feature, and it is a very big number. Especialy the network will have 3 million input, so lets say the hidden layer will 1,000 unit which leads to the matrix of weights to the first hidden layer is 3,000,000 * 1,000 which will be 3 billion element. This is an enormus number, and needs to alot of very big number of data to avoid Over fiting and need to great computer capabilities.","f04f9a6e":"Callbacks is a method we use it to reduce over fiting and to save time.\nWe will use EarlyStopping to stop the training process if the accuracy dose not improved for 5 times.\nReduceLROnPlateau to minimize learning rate if the accuracy dose not improved for 2 times \n","be4d4795":"In the first layer it detect the edges of the image, then in the second layer it detect corners and contours, in the last layer it collect all parts together and it tell you what is this.\n\n\n![95438neural-networks-deep-learning-artificial-intelligence.png](attachment:ff2bc023-ee9d-45b5-b59e-b47127dc791c.png)","0dcd80df":"The CNN in deep learning means Convolutional Neural Networks. It`s  is a class of deep neural networks, most commonly applied to analyze visual imagery. Now when we think of a neural network we think about matrix multiplications but that is not the case with ConvNet. It uses a special technique called Convolution. Now in mathematics convolution is a mathematical operation on two functions that produces a third function that expresses how the shape of one is modified by the other.![1_t6XfdzrOIOCEMMZLJ0ncBQ.jpg](attachment:b6af3c1f-165a-46f5-bab4-958e1f2681f0.jpg)","f441f471":"# Let`s check the model","af01a6c2":"# 2. Why using CNN instead of normal deep neural network?","cabe0c8b":"# 10. Fit","ce0a589e":"# 11. Accuracy","6030c529":"**We need to know what is the data augmentation**\nDatat augmentation means generate new data from exisiting data. We do this because the performance of deep learning neural networks often improves with the amount of data available. In this example the data was small so we use this","74212d7f":"# 3. what is the image?","09d20ff6":"# 12. predictions","a7d74015":"so this person not sick ","8548618b":"# 9. Model","a50fa9a3":"#  4. How does it works? ","5e496f2e":"# 5. MaxPooling","93b47b42":"# Complie the model","a3b7edf5":"MaxPooling it is the operation that calculates the maximum value in each batch of feature map. It is used for feature reductions. In this example we have (4 x 4) matrix with pool size (2 x 2). So it will split the matrix to 4 mini matrices and will take the biggest value for each batch ,then it will merge them in one final matrix,\n\n![MaxpoolSample2.png](attachment:46c0184e-d362-437e-97cf-bc9a8976750c.png)","a1b70588":"# 8. Callbacks"}}