{"cell_type":{"56187399":"code","59296832":"code","8c6972cb":"code","f51b79d2":"code","17d76f52":"code","0b767284":"code","dc0b5910":"code","da924475":"code","91d3c15e":"code","6921d26c":"code","79a903ee":"code","709a4d89":"markdown","6692f2b9":"markdown","8cb4a261":"markdown"},"source":{"56187399":"import random\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import models\nfrom torch.utils.data import Dataset,DataLoader\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom collections import Counter\n\nfrom sklearn.model_selection import KFold\n\nimport vtk\nfrom vtk.util import numpy_support\nfrom tqdm.auto import tqdm\n","59296832":"folder_path = \"..\/input\/rsna-str-pulmonary-embolism-detection\"\ntrain_path = folder_path + \"\/train\/\"\ntest_path = folder_path + \"\/test\/\"\n    \n# train_data = pd.read_csv(folder_path + \"\/train.csv\")\ntest_data  = pd.read_csv(folder_path + \"\/test.csv\")\nsample = pd.read_csv(folder_path + \"\/sample_submission.csv\")\n\ncols_ID = [\"StudyInstanceUID\",\"SeriesInstanceUID\",\"SOPInstanceUID\"]\ntest_data[\"ImagePath\"] = test_path+ test_data[cols_ID[0]]+\"\/\"+test_data[cols_ID[1]]+\"\/\"+test_data[cols_ID[2]]+\".dcm\"","8c6972cb":"SEED  = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASSEED']  = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)\n","f51b79d2":"target_columns = ['pe_present_on_image', 'negative_exam_for_pe', 'rv_lv_ratio_gte_1', \n                  'rv_lv_ratio_lt_1','leftsided_pe', 'chronic_pe','rightsided_pe', \n                  'acute_and_chronic_pe', 'central_pe', 'indeterminate']\n\nstudy_level_columns = [ 'negative_exam_for_pe', 'rv_lv_ratio_gte_1', \n                  'rv_lv_ratio_lt_1','leftsided_pe', 'chronic_pe','rightsided_pe', \n                  'acute_and_chronic_pe', 'central_pe', 'indeterminate']\n\nclasses = len(target_columns)\nmodel = models.resnet18(pretrained=False)\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features,classes)\n\nmodel_path = \"..\/input\/rsna-super-cool-eda-and-pytorch-baseline-train\/\"\n\nconfig={\n       \"learning_rate\":0.001,\n       \"train_batch_size\":32,\n        \"valid_batch_size\":32,\n        \"test_batch_size\":64,\n       \"epochs\":10,\n       \"nfolds\":3,\n       \"number_of_samples\":7000\n       }\n\nreader = vtk.vtkDICOMImageReader()\ndef get_img(path):\n    reader.SetFileName(path)\n    reader.Update()\n    _extent = reader.GetDataExtent()\n    ConstPixelDims = [_extent[1]-_extent[0]+1, _extent[3]-_extent[2]+1, _extent[5]-_extent[4]+1]\n\n    ConstPixelSpacing = reader.GetPixelSpacing()\n    imageData = reader.GetOutput()\n    pointData = imageData.GetPointData()\n    arrayData = pointData.GetArray(0)\n    ArrayDicom = numpy_support.vtk_to_numpy(arrayData)\n    ArrayDicom = ArrayDicom.reshape(ConstPixelDims, order='F')\n    ArrayDicom = cv2.resize(ArrayDicom,(512,512))\n    return ArrayDicom\n\n\ndef convert_to_rgb(array):\n    array = array.reshape((512, 512, 1))\n    return np.stack([array, array, array], axis=2).reshape((3,512, 512))","17d76f52":"class RsnaDataset(Dataset):\n    \n    def __init__(self,df,transforms=None):\n        super().__init__()\n        self.image_paths = df['ImagePath'].unique()\n        self.df = df\n        self.study_ids= df[cols_ID[1]].values\n        self.sop_ids = df[cols_ID[2]].values\n        self.transforms = transforms\n    \n    def __getitem__(self,index):\n        \n        image_path = self.image_paths[index]\n        image = get_img(image_path)\n        image = convert_to_rgb(image)\n        \n        study_id = self.study_ids[index]\n        sop_id = self.sop_ids[index]\n        \n        if self.transforms:\n            image = self.transforms(image=image)['image']\n        \n\n        image = torch.tensor(image,dtype=torch.float)        \n        \n        return {\"image\":image,\n                \"study_id\":study_id,\n                \"sop_id\":sop_id}   \n    \n    def __len__(self):\n        return self.image_paths.shape[0]  ","0b767284":"def inference():\n    model.eval()\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    all_prediction = np.zeros((test_data.shape[0],len(target_columns)))\n    study_ids = list()\n    sop_ids = list()\n    for i in range(config[\"nfolds\"]):\n        model.load_state_dict(torch.load(f\"{model_path}model{i}.bin\"))\n        predictions = list()\n        model.to(device)\n        test_ds = RsnaDataset(test_data)\n        test_dl = DataLoader(test_ds,\n                        batch_size=config['test_batch_size'],\n                        shuffle=False)\n        \n        tqdm_loader = tqdm(test_dl)\n        \n        with torch.no_grad():\n            for inputs in tqdm_loader:\n                images = inputs[\"image\"].to(device, dtype=torch.float)\n                outputs = model(images) \n                predictions.extend(outputs.cpu().detach().numpy())\n                if i == 0:\n                    study_ids.extend(inputs[\"study_id\"])\n                    sop_ids.extend(inputs[\"sop_id\"])\n\n        all_prediction += np.array(predictions)\/config['nfolds']\n        \n    return all_prediction, study_ids, sop_ids","dc0b5910":"predictions,study_ids,sop_ids = inference()","da924475":"df = pd.DataFrame(predictions)\ndf.columns = target_columns\ndf[\"StudyInstanceUID\"] = study_ids\ndf[\"SOPInstanceUID\"] = sop_ids","91d3c15e":"temp1 = df.groupby(\"StudyInstanceUID\")[target_columns].mean().reset_index()\ntemp1.drop(\"pe_present_on_image\",inplace=True,axis=1)\ntemp1 = pd.melt(temp1, id_vars=[\"StudyInstanceUID\"], value_vars=study_level_columns)\ntemp1[\"label\"] = temp1[\"StudyInstanceUID\"].astype(str) + \"_\" +temp1[\"variable\"].astype(str)\ntemp1.drop([\"StudyInstanceUID\",\"variable\"],axis=1,inplace=True)\ntemp1.columns = [\"label\",\"id\"]\n\ntemp2 = df.drop(study_level_columns +[\"StudyInstanceUID\"],axis=1)\ntemp2 = pd.melt(temp2, id_vars=[\"SOPInstanceUID\"], value_vars=['pe_present_on_image'])\ntemp2[\"label\"] = temp2[\"SOPInstanceUID\"].astype(str) \ntemp2.drop([\"SOPInstanceUID\",\"variable\"],axis=1,inplace=True)\ntemp2.columns = [\"label\",\"id\"]\n\nsubmission = temp2.append(temp1)\nsubmission.to_csv(\"submission.csv\",index=False)","6921d26c":"Counter(sample.id) == Counter(submission.id)","79a903ee":"print(submission.shape)\nsubmission.head()","709a4d89":"### Import Libraries \ud83d\udcd8","6692f2b9":"# RSNA: Pytorch Baseline-inference\n\n[Here](https:\/\/www.kaggle.com\/maunish\/rsna-super-cool-eda-and-pytorch-baseline-train) is notebook for training code.\n","8cb4a261":"## Todo\n\nchecking for logical consistency"}}