{"cell_type":{"d8fcde6b":"code","3f4ef522":"code","6fcf02ea":"code","fc6466b6":"code","83f0d7d6":"code","be29bfb5":"code","52cad973":"code","582c27f1":"code","95bd1f0e":"code","cbed863f":"code","c0c0d96a":"code","4d6eb1a2":"code","9b6ead55":"code","61a21b95":"code","0c2872c5":"code","cb63d4ee":"code","063ddb3e":"code","83d01583":"code","b45c5cc8":"code","74c81eb6":"code","11ee1a12":"code","da52d95d":"code","0c12c58f":"code","03905bdc":"code","b31cd1cf":"code","e29fe857":"code","df9a153d":"code","de9efc4f":"markdown","50d98b7d":"markdown"},"source":{"d8fcde6b":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score,f1_score","3f4ef522":"df = pd.read_csv('..\/input\/hotel-booking-demand\/hotel_bookings.csv')\ndf","6fcf02ea":"df.isnull().sum()","fc6466b6":"replace = {\"children:\": 0.0,\"country\": \"Unknown\", \"agent\": 0, \"company\": 0}\ndf1 = df.fillna(replace)","83f0d7d6":"df1.drop(df1.loc[df['adults']+df['children']+df['babies']==0].index,inplace=True)","be29bfb5":"df1.shape","52cad973":"resort = df1.loc[(df1[\"hotel\"] == \"Resort Hotel\") & (df1[\"is_canceled\"] == 0)]\ncity = df1.loc[(df1[\"hotel\"] == \"City Hotel\") & (df1[\"is_canceled\"] == 0)]","582c27f1":"ms=df1[\"market_segment\"].value_counts()\nms","95bd1f0e":"lab = ['Online TA', 'Offline TA\/TO','Groups','Direct','Corporate','Complementary','Aviation','Undefined'] ","cbed863f":"plt.figure(figsize=(15,8))\nplt.pie(ms,autopct='%1.2f%%',explode=[0,0,0,0,0,0.5,0.8,1.4],labels=lab)\nplt.show()","c0c0d96a":"total_cancels = df1[\"is_canceled\"].sum()\nresort_cancels = df1.loc[df1[\"hotel\"] == \"Resort Hotel\"][\"is_canceled\"].sum()\ncity_cancels = df1.loc[df1[\"hotel\"] == \"City Hotel\"][\"is_canceled\"].sum()\n\ncancel_per = (total_cancels \/ df1.shape[0]) * 100\nrh_cancel_per = (resort_cancels \/ df1.loc[df1[\"hotel\"] == \"Resort Hotel\"].shape[0]) * 100\nch_cancel_per = (city_cancels \/ df1.loc[df1[\"hotel\"] == \"City Hotel\"].shape[0]) * 100\n\nprint(f\"Total bookings canceled: {total_cancels:,} ({cancel_per:.0f} %)\")\nprint(f\"Resort hotel bookings canceled: {resort_cancels:,} ({rh_cancel_per:.0f} %)\")\nprint(f\"City hotel bookings canceled: {city_cancels:,} ({ch_cancel_per:.0f} %)\")","4d6eb1a2":"rbook_per_month = df1.loc[(df1[\"hotel\"] == \"Resort Hotel\")].groupby(\"arrival_date_month\")[\"hotel\"].count()\nrcancel_per_month = df1.loc[(df1[\"hotel\"] == \"Resort Hotel\")].groupby(\"arrival_date_month\")[\"is_canceled\"].sum()\n\ncbook_per_month = df1.loc[(df1[\"hotel\"] == \"City Hotel\")].groupby(\"arrival_date_month\")[\"hotel\"].count()\nccancel_per_month = df1.loc[(df1[\"hotel\"] == \"City Hotel\")].groupby(\"arrival_date_month\")[\"is_canceled\"].sum()\n\nrcancel = pd.DataFrame({\"Hotel\": \"Resort Hotel\",\n                                \"Month\": list(rbook_per_month.index),\n                                \"Bookings\": list(rbook_per_month.values),\n                                \"Cancelations\": list(rcancel_per_month.values)})\nccancel = pd.DataFrame({\"Hotel\": \"City Hotel\",\n                                \"Month\": list(cbook_per_month.index),\n                                \"Bookings\": list(cbook_per_month.values),\n                                \"Cancelations\": list(ccancel_per_month.values)})\n\nfull_cancel_data = pd.concat([rcancel, ccancel], ignore_index=True)\nfull_cancel_data[\"cancel_percent\"] = full_cancel_data[\"Cancelations\"] \/ full_cancel_data[\"Bookings\"] * 100\n\nordered_months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\nfull_cancel_data[\"Month\"] = pd.Categorical(full_cancel_data[\"Month\"], categories=ordered_months, ordered=True)\n\n# show figure:\nplt.figure(figsize=(12, 8))\nsns.barplot(x = \"Month\", y = \"cancel_percent\" , hue=\"Hotel\",\n            hue_order = [\"City Hotel\", \"Resort Hotel\"], data=full_cancel_data)\nplt.title(\"Cancelations per month\", fontsize=16)\nplt.xlabel(\"Month\", fontsize=16)\nplt.xticks(rotation=45)\nplt.ylabel(\"Cancelations [%]\", fontsize=16)\nplt.legend(loc=\"upper right\")\nplt.show()","9b6ead55":"cancel_corr = df.corr()[\"is_canceled\"]\ncancel_corr.abs().sort_values(ascending=False)[1:]","61a21b95":"df.groupby(\"is_canceled\")[\"reservation_status\"].value_counts()","0c2872c5":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\n","cb63d4ee":"df1.isnull().sum()","063ddb3e":"df1['children'].fillna(df1['children'].median(),inplace=True)","83d01583":"df1.isnull().sum()","b45c5cc8":"df1 = df1.drop_duplicates()","74c81eb6":"y = df1[\"is_canceled\"]\nX = df1.drop([\"is_canceled\"], axis=1)\n\nx_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=0)\n\n\nnum_features = [\"lead_time\",\"arrival_date_week_number\",\"arrival_date_day_of_month\",\n                \"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\n                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n                \"previous_bookings_not_canceled\",\"agent\",\"company\",\n                \"required_car_parking_spaces\", \"total_of_special_requests\", \"adr\"]\n\ncat_features = [\"hotel\",\"arrival_date_month\",\"meal\",\"market_segment\",\n                \"distribution_channel\",\"reserved_room_type\",\"deposit_type\",\"customer_type\"]\n\nx_train = x_train[num_features + cat_features].copy()\nx_test = x_test[num_features + cat_features].copy()\n\nnum_transformer = SimpleImputer(strategy=\"constant\")\n\n\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\n\npreprocessor = ColumnTransformer(transformers=[('num', num_transformer, num_features),\n                                               ('cat', cat_transformer, cat_features)])","11ee1a12":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=1000, gamma=0, \n                        min_child_weight=1, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.005,random_state=101)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n\npipeline.fit(x_train, y_train)\n\n\npredictions = pipeline.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(classification_report(y_test,predictions))\n\nconfusion_matrix=metrics.confusion_matrix(y_test,predictions)\n\nsensitivity = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[1,0])\n\nspecificity = confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[0,1])\n\nprecision = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[0,1])\n\nf1_score = (2*sensitivity*precision)\/(sensitivity+precision)\nprint('f1_score1 :% .2f '% f1_score)","da52d95d":"model = KNeighborsClassifier(n_neighbors=5,\n    weights='uniform',\n    algorithm='auto',\n    leaf_size=30,\n    p=2,\n    metric='minkowski')\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n\npipeline.fit(x_train, y_train)\n\n\npredictions = pipeline.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(classification_report(y_test,predictions))\n\nconfusion_matrix=metrics.confusion_matrix(y_test,predictions)\n\nsensitivity = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[1,0])\n\nspecificity = confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[0,1])\n\nprecision = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[0,1])\n\nf1_score = (2*sensitivity*precision)\/(sensitivity+precision)\nprint('f1_score :% .2f '% f1_score)","0c12c58f":"model = DecisionTreeClassifier(criterion='gini',\n    splitter='best',\n    max_depth=None,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    min_weight_fraction_leaf=0.0,\n    max_features=None,\n    random_state=None,\n    max_leaf_nodes=None,\n    min_impurity_decrease=0.0,\n    min_impurity_split=None,\n    class_weight=None,\n    presort='deprecated',\n    ccp_alpha=0.0)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n\npipeline.fit(x_train, y_train)\n\n\npredictions = pipeline.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(classification_report(y_test,predictions))\n\nconfusion_matrix=metrics.confusion_matrix(y_test,predictions)\n\nsensitivity = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[1,0])\n\nspecificity = confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[0,1])\n\nprecision = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[0,1])\n\nf1_score = (2*sensitivity*precision)\/(sensitivity+precision)\nprint('f1_score :% .2f '% f1_score)","03905bdc":"model = RandomForestClassifier(n_estimators=100,\n    criterion='gini',\n    max_depth=None,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    min_weight_fraction_leaf=0.0,\n    max_features='auto',\n    max_leaf_nodes=None,\n    min_impurity_decrease=0.0,\n    min_impurity_split=None,\n    bootstrap=True,\n    oob_score=False,\n    n_jobs=None,\n    random_state=None,\n    verbose=0,\n    warm_start=False,\n    class_weight=None,\n    ccp_alpha=0.0,\n    max_samples=None)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n\npipeline.fit(x_train, y_train)\n\n\npredictions = pipeline.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(classification_report(y_test,predictions))\n\nconfusion_matrix=metrics.confusion_matrix(y_test,predictions)\n\nsensitivity = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[1,0])\n\nspecificity = confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[0,1])\n\nprecision = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[0,1])\n\nf1_score = (2*sensitivity*precision)\/(sensitivity+precision)\nprint('f1_score :% .2f '% f1_score)","b31cd1cf":"model = BaggingClassifier(base_estimator=None,\n    n_estimators=10,\n    max_samples=1.0,\n    max_features=1.0,\n    bootstrap=True,\n    bootstrap_features=False,\n    oob_score=False,\n    warm_start=False,\n    n_jobs=None,\n    random_state=None,\n    verbose=0)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n\npipeline.fit(x_train, y_train)\n\n\npredictions = pipeline.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(classification_report(y_test,predictions))\n\nconfusion_matrix=metrics.confusion_matrix(y_test,predictions)\n\nsensitivity = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[1,0])\n\nspecificity = confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[0,1])\n\nprecision = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[0,1])\n\nf1_score = (2*sensitivity*precision)\/(sensitivity+precision)\nprint('f1_score :% .2f '% f1_score)","e29fe857":"model = AdaBoostClassifier(base_estimator=None,\n    n_estimators=50,\n    learning_rate=1.0,\n    algorithm='SAMME.R',\n    random_state=None)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n\npipeline.fit(x_train, y_train)\n\n\npredictions = pipeline.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(classification_report(y_test,predictions))\n\nconfusion_matrix=metrics.confusion_matrix(y_test,predictions)\n\nsensitivity = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[1,0])\n\nspecificity = confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[0,1])\n\nprecision = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[0,1])\n\nf1_score = (2*sensitivity*precision)\/(sensitivity+precision)\nprint('f1_score :% .2f '% f1_score)","df9a153d":"model = GradientBoostingClassifier(loss='deviance',\n    learning_rate=0.1,\n    n_estimators=100,\n    subsample=1.0,\n    criterion='friedman_mse',\n    min_samples_split=2,\n    min_samples_leaf=1,\n    min_weight_fraction_leaf=0.0,\n    max_depth=3,\n    min_impurity_decrease=0.0,\n    min_impurity_split=None,\n    init=None,\n    random_state=None,\n    max_features=None,\n    verbose=0,\n    max_leaf_nodes=None,\n    warm_start=False,\n    presort='deprecated',\n    validation_fraction=0.1,\n    n_iter_no_change=None,\n    tol=0.0001,\n    ccp_alpha=0.0)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n\npipeline.fit(x_train, y_train)\n\n\npredictions = pipeline.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint(classification_report(y_test,predictions))\n\nconfusion_matrix=metrics.confusion_matrix(y_test,predictions)\n\nsensitivity = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[1,0])\n\nspecificity = confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[0,1])\n\nprecision = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[0,1])\n\nf1_score = (2*sensitivity*precision)\/(sensitivity+precision)\nprint('f1_score :% .2f '% f1_score)","de9efc4f":"fig = px.pie(segments,\n             values=segments.values,\n             names=segments.index,\n             title=\"Bookings per market segment\",\n             template=\"seaborn\")\nfig.update_traces(rotation=-90, textinfo=\"percent+label\")\nfig.show()","50d98b7d":"# Finally after running different classification models , both RandomForest Classifier and XGBoost Classifier has got the highest f1score (0.88)"}}