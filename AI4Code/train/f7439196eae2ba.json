{"cell_type":{"a52bf6c8":"code","c253f83f":"code","2c858111":"code","5980dfbf":"code","04af56c1":"code","f076cabc":"code","f7666391":"code","cc9781a8":"code","3cd817bf":"code","79b2c26e":"code","83e4c103":"code","b2bfc0cf":"code","d77ce553":"code","e6692d5d":"code","db8285a4":"code","8367d958":"code","bb831897":"code","cec5d8d9":"code","fa51d4d5":"code","6baf02e8":"code","41235dc7":"code","6d030671":"code","8b4e38db":"code","36034144":"code","460225e9":"code","c2fac289":"code","0f97791b":"code","3203602b":"code","0ed138d1":"code","09ee7472":"code","b28e0436":"code","c21a5d7f":"code","77bf291e":"code","efad774c":"code","1a08513d":"code","a6253cf2":"code","5f25aa8c":"code","60bebcb0":"code","982488fb":"code","381c86a4":"code","e108435a":"code","9214adb3":"code","b679363a":"code","7393e3ba":"code","a896ebd6":"code","80a7e9c1":"code","190ef54a":"code","3da3a54e":"code","6160e421":"code","72bc3b62":"code","8e09198d":"code","b92f2fed":"code","78ce21d5":"code","652ab7fa":"code","b104c213":"code","904aea7e":"code","64037434":"code","c993f7cf":"code","c63bc842":"code","28fc2bad":"code","84c54991":"code","013080c3":"code","785fee2f":"code","d8e2a1ea":"code","6628fa9f":"code","5347b26d":"code","04c25d9b":"code","515bc11a":"code","25548aa3":"code","c79b6b38":"code","e59d83cb":"code","c32542db":"code","a4eb6cb2":"code","39214b92":"code","6b60d5a2":"code","b72a5b86":"code","3af2cafe":"code","0fae6927":"code","75100226":"code","d78288e3":"code","1158636c":"code","f048295c":"code","c5f02293":"code","9c842ecd":"code","62acecf0":"code","1f237760":"code","eb360f02":"code","1de9064c":"code","ad4b2b83":"code","b1d84f52":"code","42a8fec2":"code","c8d11d40":"code","45e1227b":"code","1d54176a":"code","2f8ef0cb":"code","57c42ab5":"code","75f166e3":"code","bb4ecdf9":"code","d0faed6b":"markdown","20dde103":"markdown","7886e680":"markdown","7b4f71ea":"markdown","56cbc14d":"markdown","bd12d630":"markdown","b6c02fe9":"markdown","ba386237":"markdown","051ea686":"markdown","2956ac7b":"markdown","42a4bc77":"markdown","f7d75baa":"markdown","f350c9fb":"markdown","3e8959a2":"markdown","9f2619d3":"markdown","37be400d":"markdown","7c107021":"markdown","8da4d68f":"markdown","44dd28f4":"markdown","de6dec49":"markdown","e315a19b":"markdown","243ee9dd":"markdown","e2d036de":"markdown","31f99b64":"markdown","78331893":"markdown","fb6a3d10":"markdown","e85db85c":"markdown","792e7cd3":"markdown","d4aef329":"markdown","ce758308":"markdown","48281b2b":"markdown","17937341":"markdown"},"source":{"a52bf6c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nimport xgboost\nfrom sklearn.model_selection import cross_val_score\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\ndf = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","c253f83f":"#Lets check first 5 rows\ndf.head()","2c858111":"#bottom 5 rows\ndf.tail()","5980dfbf":"#lets get some statistics regarding the data\ndf.describe()","04af56c1":"#lets check the shape\ndf.shape","f076cabc":"#check for null value\ndf.isnull().sum()","f7666391":"#lets check for datatype\ndf.dtypes","cc9781a8":"#lets get the categorical variables\ncat_vars = [var for var in df.columns if df[var].dtypes=='O']\ncat_vars","3cd817bf":"#lets get the numerical variables\nnum_vars = [var for var in df.columns if df[var].dtypes!='O' and var!='PassengerId']\nnum_vars","79b2c26e":"#length of categorical and numerical variables\nprint(len(cat_vars))\nprint(len(num_vars))","83e4c103":"#lets check for unique labels in the categorical variables\nprint(df['Name'].nunique())\nprint(df['Sex'].nunique())\nprint(df['Ticket'].nunique())\nprint(df['Cabin'].nunique())\nprint(df['Embarked'].nunique())","b2bfc0cf":"#NUMBER OF PEOPLE IN EACH VARIABLE\n#for categorical variables\ncat_vars=['Sex', 'Ticket', 'Cabin', 'Embarked']\nfor var in cat_vars:\n    sns.barplot(x=df[var].value_counts().index,y=df[var].value_counts(),palette=\"Set1\")\n    plt.show()","d77ce553":"#for numerical varaibles\nfor var in num_vars:\n    sns.barplot(x=df[var].value_counts().index,y=df[var].value_counts(),palette=\"Set1\")\n    plt.show()","e6692d5d":"#for categorical variables\nfor var in cat_vars:\n        sns.barplot(x=df[var],y=df['Survived'],palette=\"Set1\",data=df)\n        plt.show()","db8285a4":"#for numerical variables\nnum_vars=['Pclass', 'SibSp', 'Parch',]\nfor var in num_vars:\n        sns.barplot(x=df[var],y=df['Survived'],palette=\"Set1\",data=df)\n        plt.show()","8367d958":"sns.barplot(x=df['Survived'],y=df['Fare'],palette=\"Set1\",data=df)\nplt.show()","bb831897":"sns.barplot(x=df['Survived'],y=df['Age'],palette=\"Set1\",data=df)\nplt.show()","cec5d8d9":"for var in num_vars:\n    sns.histplot(df[var])\n    plt.show()","fa51d4d5":"df.head()","6baf02e8":"print('carbin:',df['Cabin'].unique())\nprint('Name:',df['Name'].unique())\nprint('Ticket:',df['Ticket'].unique())","41235dc7":"df['Ticket_type'] = df['Ticket'].apply(lambda x: 'single_ticket' if x.isnumeric() else 'multiple_ticket')\ntest['Ticket_type'] = test['Ticket'].apply(lambda x: 'single_ticket' if x.isnumeric() else 'multiple_ticket')","6d030671":"sns.barplot(x=df['Ticket_type'],y=df['Survived'])\nplt.show()","8b4e38db":"df['Cabin'] = df['Cabin'].str[:1]\ntest['Cabin'] = test['Cabin'].str[:1]","36034144":"df[\"Cabin\"].fillna(\"Missing\",inplace=True)\ntest[\"Cabin\"].fillna(\"Missing\",inplace=True)","460225e9":"sns.barplot(x=df['Cabin'],y=df['Survived'])\nplt.show()","c2fac289":"#lets create a new feature from the name\ndf['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ndf['Title'] = df['Title'].replace(['Lady', 'Countess','Don', 'Jonkheer', 'Dona'], 'Royalty')\ndf['Title'] = df['Title'].replace(['Capt', 'Col','Dr', 'Major', 'Rev', 'Sir'], 'Sir')\ndf['Title'] = df['Title'].replace(['Mlle', 'Ms','Mme', 'Miss'], 'Mrs')\ndf['Title'] = df['Title'].replace('Master', 'Mr')","0f97791b":"#lets create a new feature from the name\ntest['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest['Title'] = test['Title'].replace(['Lady', 'Countess','Don', 'Jonkheer', 'Dona'], 'Royalty')\ntest['Title'] = test['Title'].replace(['Capt', 'Col','Dr', 'Major', 'Rev', 'Sir'], 'Sir')\ntest['Title'] = test['Title'].replace(['Mlle', 'Ms','Mme', 'Miss'], 'Mrs')\ntest['Title'] = test['Title'].replace('Master', 'Mr')","3203602b":"sns.barplot(x=df['Title'],y=df['Survived'])\nplt.show()","0ed138d1":"df.head()","09ee7472":"df=df.drop(['Name'],axis=1)\ntest=test.drop(['Name'],axis=1)","b28e0436":"df = df.drop(['Ticket'],axis=1)\ntest = test.drop(['Ticket'],axis=1)","c21a5d7f":"x_train, x_test, y_train, y_test = train_test_split(\n    df,\n    df['Survived'], # target\n    test_size=0.3, # percentage of observations in the test set\n    random_state=0)","77bf291e":"x_train.isnull().sum()","efad774c":"def impute_null(df, vr, median):\n\n    return df[vr].fillna(median)","1a08513d":"median = x_train.Age.median()\nmedian","a6253cf2":"x_train['Age'] = impute_null(x_train, 'Age', median)\nx_test['Age'] = impute_null(x_test,'Age',median)\ntest['Age'] = impute_null(test,'Age',median)\ntest['Fare'] = impute_null(test,'Fare',median)","5f25aa8c":"x_test.isnull().sum()","60bebcb0":"x_train['Embarked'].mode()","982488fb":"test['Embarked'].mode()","381c86a4":"x_train['Embarked'].fillna('S', inplace=True)","e108435a":"test['Embarked'].fillna('S', inplace=True)","9214adb3":"x_train.isnull().sum()","b679363a":"title_dict = {\"Mr\":0,'Mrs':0.5,\"Royalty\":0.8,\"Sir\":1.4}","7393e3ba":"x_train['Title'] = x_train['Title'].map(title_dict)\nx_test['Title'] = x_test['Title'].map(title_dict)\ntest['Title'] = test['Title'].map(title_dict)","a896ebd6":"cabin_dict = {\"B\":0,'D':0,\"E\":0,\"F\":1,\"C\":1,'T':1,'G':1.5,\"A\":1.5,\"Missing\":1.5}","80a7e9c1":"x_train['Cabin'] = x_train['Cabin'].map(cabin_dict) \nx_test['Cabin'] = x_test['Cabin'].map(cabin_dict) \ntest['Cabin'] = test['Cabin'].map(cabin_dict)","190ef54a":"x_train = pd.get_dummies(x_train,drop_first=True) ","3da3a54e":"x_test = pd.get_dummies(x_test,drop_first=True)\ntest = pd.get_dummies(test,drop_first=True)","6160e421":"x_train.columns","72bc3b62":"x_train = x_train.drop([\"PassengerId\"],axis=True)\nx_test = x_test.drop([\"PassengerId\"],axis=True)","8e09198d":"x_train = x_train.drop([\"Survived\"],axis=True)\nx_test = x_test.drop([\"Survived\"],axis=True)","b92f2fed":"x_test.head()","78ce21d5":"#define and fit to data\nbest_feat = SelectKBest(chi2, k=10)\nfit = best_feat.fit(x_train,y_train)","652ab7fa":"#get the scores for each variable\nxscores = pd.DataFrame(fit.scores_)\nxcolumns = pd.DataFrame(x_train.columns)","b104c213":"feat_scores = pd.concat([xcolumns,xscores],axis=1)\nfeat_scores.columns = ['Features','Strength']","904aea7e":"feat_scores","64037434":"print(feat_scores.nlargest(6,'Strength'))","c993f7cf":"scaler=StandardScaler()\nscaler.fit(x_train)","c63bc842":"x_train_scaled = scaler.transform(x_train)\nx_test_scaled = scaler.transform(x_test)","28fc2bad":"knn_classif = KNeighborsClassifier()","84c54991":"#hyperparameters\nleaf_size = list(range(1,10))\nn_neighbors = list(range(1,10))\np=[1,2]\n#setting hyperparameters as dictionary\nhyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n#Use GridSearch\nknn_grid = GridSearchCV(knn_classif, hyperparameters, cv=5,scoring='roc_auc',n_jobs=1)","013080c3":"#Fit the model\nknn_class = knn_grid.fit(x_train_scaled,y_train)\npred_knn=knn_class.predict(x_test_scaled)","785fee2f":"#Using cross validation to see 10 possible scores for training data\nknn_score=cross_val_score(knn_class,x_train_scaled,y_train,cv=10)\nknn_score","d8e2a1ea":"print('The knn mean score after 10 cv for train data:',knn_score.mean())","6628fa9f":"knn_score_test=cross_val_score(knn_class,x_test_scaled,y_test,cv=10)\nknn_score_test","5347b26d":"print('The knn mean score after 10 cv for test data:',knn_score_test.mean())","04c25d9b":"#define svc object\nsvc_classify = SVC()","515bc11a":"#seting parameters grid\nsvc_grid = {'C': [0.1,1, 10, 101], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}","25548aa3":"svc_model = GridSearchCV(svc_classify,svc_grid,scoring='roc_auc',refit=True,verbose=2,cv=5)\nsvc_model.fit(x_train_scaled,y_train)","c79b6b38":"print(svc_model.best_estimator_)","e59d83cb":"#Using cross validation to see 10 possible scores for training data\nsvc_cv_score=cross_val_score(svc_model,x_train_scaled,y_train,cv=3)\n","c32542db":"svc_cv_score","a4eb6cb2":"print('The mean score for the train set using svc is:',svc_cv_score.mean())","39214b92":"svc_cv_score_t=cross_val_score(svc_model,x_test_scaled,y_test,cv=3)","6b60d5a2":"svc_cv_score_t","b72a5b86":"print('The mean score for the test set using svc is:',svc_cv_score_t.mean())","3af2cafe":"log_classify = LogisticRegression(random_state=1)","0fae6927":"param_dict = {'C': [0.1, 0.5, 1, 5, 10, 50, 100]}\nlog_model = GridSearchCV(log_classify, param_dict, cv=10, scoring='roc_auc')\nlog_model.fit(x_train_scaled, y_train)","75100226":"print(log_model.best_estimator_)","d78288e3":"log_score=cross_val_score(log_model,x_train_scaled,y_train,cv=10)\nlog_score_t=cross_val_score(log_model,x_test_scaled,y_test,cv=10)","1158636c":"print('cv scores for training data:',log_score)\nprint(\"\")\nprint('cv scores for test data:',log_score_t)","f048295c":"print(\"The logistic reg cv mean score for the train data is:\",log_score.mean())\nprint(\"The logistic reg cv mean score for the test data is:\",log_score_t.mean())\n","c5f02293":"xg_classifier=xgboost.XGBClassifier()","9c842ecd":"\n\n## Hyper Parameter Optimization\n\nparam_dict={\n \"learning_rate\"    : [0.05, 0.08, 0.10, 0.20, 0.26, 0.30 ] ,\n \"max_depth\"        : [ 3, 5, 6, 7, 8, 9, 10, 15],\n \"min_child_weight\" : [ 1, 2, 5, 8 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.5 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.8 ]\n    \n}\n\n","62acecf0":"#lets search for best parameters and fit to our data\nxgb_search=RandomizedSearchCV(xg_classifier,param_distributions=param_dict,n_iter=6,scoring='roc_auc',n_jobs=1,cv=5,verbose=3)\nxgb_search.fit(x_train_scaled,y_train)","1f237760":"\nxgb_search.best_estimator_\n\n","eb360f02":"score_xgb=cross_val_score(xgb_search,x_train_scaled,y_train,cv=5)\nscore_xgb_t=cross_val_score(xgb_search,x_test_scaled,y_test,cv=5)","1de9064c":"print('xgb cv scores for training data:',score_xgb)\nprint(\"\")\nprint('xgb cv scores for test data:',score_xgb_t)","ad4b2b83":"print('xgb mean cv scores for training data:',score_xgb.mean())\nprint(\"\")\nprint('xgb mean cv scores for test data:',score_xgb_t.mean())","b1d84f52":"print('The knn mean score after 10 cv for train data:',knn_score.mean())\nprint('The knn mean score after 10 cv for test data:',knn_score_test.mean())\nprint('The mean score for the train set using svc is:',svc_cv_score.mean())\nprint('The mean score for the test set using svc is:',svc_cv_score_t.mean())\nprint(\"The logistic reg cv mean score for the train data is:\",log_score.mean())\nprint(\"The logistic reg cv mean score for the test data is:\",log_score_t.mean())\nprint('xgb mean cv scores for training data:',score_xgb.mean())\nprint('xgb mean cv scores for test data:',score_xgb_t.mean())","42a8fec2":"#lets combine all data set\ndata = pd.concat([x_train,x_test])","c8d11d40":"#choose best features\ndata = data[['Pclass', 'Age', 'Fare', 'Cabin','Title', 'Sex_male']]","45e1227b":"#lets scale the data\nall_scaler=StandardScaler()\nall_scaler.fit(data)\ndata_scaled = all_scaler.transform(data)","1d54176a":"#lets scale the test data\ntest_df = test[['Pclass', 'Age', 'Fare', 'Cabin','Title', 'Sex_male']]\n\ntest_scaled = all_scaler.transform(test_df)","2f8ef0cb":"#lets get the target\ntarget = df['Survived']","57c42ab5":"#lets train with all the data\nknn_class = knn_grid.fit(data_scaled,target)","75f166e3":"#lets make predictions\npred = knn_class.predict(test_scaled)","bb4ecdf9":"result = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': pred})\nresult.to_csv('submission.csv', index=False)","d0faed6b":"MODEL SUMMARY:\n* The knn train data: 0.8477112010796223\n* The knn test data: 0.8663235294117648\n* The svc train data: 0.8504477738893749\n* The svc test data: 0.7724089635854341\n* The logistic reg train data: 0.8532738416554206\n* The logistic reg test data is: 0.8349632352941176\n* xgb training data: 0.8703606622074667\n* xgb test data: 0.8045989304812835","20dde103":"# KNN CLASSIFIER","7886e680":"# Distribution of numerical varaibles","7b4f71ea":"# AGE","56cbc14d":"# Title","bd12d630":"# FILLING MISSING VALUES","b6c02fe9":"# FEATURE SELECTION","ba386237":"graph1:females had the  highier chance of survival compared to males.\ngraph2:people that embarked from locatonC have a highier chance of survival than other other locations","051ea686":"# FEATURE SCALING","2956ac7b":"Women survived more ,followed by royalty but ordinary males were likely to die.","42a4bc77":"graph1:The number of males is more than the number of females.\ngraph4:Peple embarked more from location S followed by C","f7d75baa":"# LOADING AND DATA EXPLORATION","f350c9fb":"NOTE:I divided my training data into x_train and x_test to understand how well the model will perform in unseen data. After getting the best model i combined the x_train and x_test to train my final model.","3e8959a2":"# Name","9f2619d3":"# HANDLING HIGH  CARDINALITY","37be400d":"# Support Vector Machine","7c107021":"Age tends to follow a normal distribution while fare is skewed left","8da4d68f":"# CATEGORICAL ENSODING","44dd28f4":"# Steps:\n1. Loading and data exploration.\n2. Handling high cardinality\n3. Filling misssing values.\n4. Categorical Encoding.\n5. Feature Scaling.\n6. Model Bulding.\n7. Selecting Best Model\n8. Converting prediction to csv","de6dec49":"# Cabin","e315a19b":"graph1)The number of people that died where more than  people that survived\ngraph2)People that board with third class option where more than those with first and second class.\ngraph3)The age tends to be normally distributed.\ngraph4) Most people did not travel with siblings and spouse\ngrah5)Most people where without children or the children travelled with nannies.","243ee9dd":"# ALL MODELS AND SCORES","e2d036de":"# Embark","31f99b64":"# Logistic Regressionn","78331893":"# Cabin","fb6a3d10":"# Relationship With Target","e85db85c":"# Ticket","792e7cd3":"# The best model is Knearest neighbor classifier(KNN) ,so i will use it to train all the data and predict the unknown(test data).","d4aef329":"# Goal:To predict who survived the titanic disaster","ce758308":"# MODEL BULDING","48281b2b":"Using Univariate selection","17937341":"# XGBOOST Classifier"}}