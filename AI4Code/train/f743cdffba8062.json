{"cell_type":{"8e6c7214":"code","21af8b11":"code","d8796524":"code","1dd6b428":"code","6ee98d23":"code","d340ca81":"code","341c2564":"code","d97e5cd2":"code","d70713f4":"code","2c9d76f1":"code","54a67064":"code","e2920f53":"code","0e6e36f1":"code","94def596":"code","807cd7b2":"code","0fe57755":"code","db047586":"code","58d2737d":"code","2fb43902":"code","6f0dfffb":"code","6d80fbf4":"markdown","5539fefe":"markdown","05a66f08":"markdown","e6745a15":"markdown","1c5bffba":"markdown","cbf075c4":"markdown","ad1267f5":"markdown","e62c7107":"markdown","3ee97d8d":"markdown","576ecdbc":"markdown","d8679182":"markdown","5dabf7eb":"markdown","45f006d9":"markdown","a92bdccb":"markdown","8dae7f58":"markdown","014e7c3e":"markdown","19724ff3":"markdown","2b3b37cd":"markdown"},"source":{"8e6c7214":"# Importing numpy library and giving it a name \"np\" for fast access\nimport numpy as np\n\ntest_arr = np.array([1,5,2,6,8,3])","21af8b11":"# Calculating the mean\nmean = np.mean(test_arr)\n\nprint(\"The mean of the array = %f\" % mean) # Must be 4.1667 Why wrong answer? HINT what does the %i in the format string do","d8796524":"# Calculating the midean\nmedian = np.median(test_arr)\n\nprint(\"The median of the array = %0.2f\" % median)","1dd6b428":"#Calculat the STD using the same array\nstd = np.std(test_arr)\n\nprint(\"The median of the array = %0.2f\" % std)","6ee98d23":"#Calculat the mode using scipy\nfrom scipy import stats\n\nstats.mode([2,3,4,5])","d340ca81":"# Importing the data set from sklearn library\nfrom sklearn.datasets import fetch_covtype\n\ncov = fetch_covtype()\ncolumns = ['Elevation', 'Aspect', 'Slope',\n       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n       'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n\n# ??? Why all of this?? np arrays doesn't have info about the features names","341c2564":"import pandas as pd\n\n# Import the data into a dataframe for exploration\ndata = pd.DataFrame(cov.data, columns = columns)\ndata['Cover_Type'] = cov.target","d97e5cd2":"data.head(5) # Default?","d70713f4":"data.Soil_Type35.value_counts()","2c9d76f1":"data['Elevation'] # Could be data.Elevation as well","54a67064":"data.Elevation.value_counts();\ndata.Cover_Type.value_counts()","e2920f53":"data.info();","0e6e36f1":"data.describe()","94def596":"# Import matplotlib to show the graph\nimport matplotlib.pyplot as plt\n\n# Why using bins??\ndata.Cover_Type.hist(bins=7)\nplt.show()","807cd7b2":"data[['Elevation', 'Aspect', 'Slope', 'Cover_Type']].corr()","0fe57755":"data.corr()","db047586":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ncorr = data[['Elevation', 'Aspect', 'Slope',\n       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']].corr()\nf, ax = plt.subplots(figsize=(25, 25))\n\n# Color Map, not mandatory\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Heat Map\nsns.heatmap(corr, cmap=cmap, vmax=1, vmin = -1, center=0,\n            square=True, linewidths=.5)","58d2737d":"import seaborn as sns\n\nExploration_columns = data[['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology','Cover_Type']].head(1000)\nsns.pairplot(Exploration_columns, hue='Cover_Type')","2fb43902":"\nfrom pandas.plotting import scatter_matrix\n\n# Can select multiple rows for exploration\nscatter_matrix(data[['Elevation', 'Aspect', 'Slope']])\n\nplt.show()","6f0dfffb":"data.isna().sum()","6d80fbf4":"#### Calculating the midean:\nWe calculate the median manually by sorting the elements and picking the value (or mean of the values) in the middle. To calculate the median using Numpy we can use numpy.median() function.<br>\nWe will use the same array arr == Note that the sorted array will be arr_sorted = [1,2,3,5,6,8] so the median must be (3+5)\/2 = 4","5539fefe":"Looks good, what if the columns count was huge?? would it look good??","05a66f08":"#### Calculating the Standart Deviation (std):\nOne of the very important statistical terms that measures the dispersion of the data values of the dataset, can be a measure to judge if a data point (data instance\/example) is an outlier or not (researchers usually consider points with std greater that 2.5\/3 an outlier), So why are outliers bad?\nWe calculate the STD using Numpy by using numpy.std() function.","e6745a15":"We can visualize some of the dataset features histograms and correlations using pandas as follows. Remember how we calculated the frequency of the items in the label feature (which is the target value), we will now visualize the histogram.","1c5bffba":"The second function describes the statistical properties of each feature in the dataset as follows:","cbf075c4":"Oh, the data was continuous, should have checked the column's value before counting its values.\nWe mainly use two functions to get the basic statistical info from the data. The first one is DataFrame.info() function which returns a summary of the dataframe","ad1267f5":"#### Calculating the mode:\nThe most represented value. Numpy?","e62c7107":"There are many other libraries that have very interesting usage in Data Science in general.\nWe will now use seaborn library to visualize the scatter plot of three dataset features","3ee97d8d":"### Numpy (Numerical Python)\nUnlike using basic python functions and loops, numpy is so fast as most of its modules are implemented in C language. Let's now have a look on some of the basic operations in Numpy.\n#### Calculating the mean:\nTo calculate the mean for the following array, we need to use numpy.mean() function.<br>\narr = [1,5,2,7,9,10]","576ecdbc":"Let's explore what a dataframe can do. We will start with the head([n_rows]) function that displays the first n_rows from the dataset as follows:","d8679182":"Resources:\n\nhttps:\/\/github.com\/MoghazyCoder\/a-2017\/blob\/master\/Labs\/Lab1_numstack\/Lab1-numstack_solutions.ipynb\nhttps:\/\/www.kaggle.com\/moghazy\/ensemble-learning-with-feature-engineering\nhttps:\/\/pandas.pydata.org\/\nhttps:\/\/docs.scipy.org\/\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype","5dabf7eb":"Can also scatter using pandas but in a more premitive way","45f006d9":"We can also know the frequency of each value in this column using value_counts() function","a92bdccb":"### Pandas \ud83d\udc3c\ud83d\udc3c\nThe very famous Python Data Analysis Library, mainly used in the EDA (Exploratory Data Analysis) stage to import data into a dataframe, explore the correlations between features, visualise the scatter plot of the data points and etc.\nBut what is a dataframe?<br>\nPandas is usually used to import data from a (CSV file)?? which is the most poplular formats for structured datasets. <br>\nLet's first start by importing the cover_type dataset from sklearn library. Cover_type dataset?? Trees?? \ud83d\ude02\n\n","8dae7f58":"Using pandas DataFrames we can select specific columns now only specific rows. Let's now start selecting and exploring some rows.","014e7c3e":"Really hard to read floating point number and compare them. Solutions?? Heat Map","19724ff3":"# Exploratory Data Analysis libraries (Entry Level)\n\n### In this tutorial we will discuss the basics of the following libraries:\n* Numby \n* Pandas\n* Matplotlib\n\n### This is the introduction tutorial for my Data Science series of tutorials on Kaggle, I will follow this one with other tutorials later, stay tuned!","2b3b37cd":"It is very important to explore the correlation betwwen the features as explained in the lecture (Remember Naive bayes?). We will now descover the corelation between some numerical features that we have in the dataset usign Dataframe.corr(). The correlation value must be between -1 and 1 where -1 means inversly correlated and 1 means correlated. Why is this important? Feature selection and other reasons."}}