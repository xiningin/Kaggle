{"cell_type":{"76c204fd":"code","11500e01":"code","316769f8":"code","9e6d7d88":"code","e4ea9d0d":"code","b20af254":"code","57277cf9":"code","6a7584cc":"code","8c99208e":"code","476cba4a":"code","ee7dab6c":"code","24569f77":"code","1c339ebd":"code","9b9f4af0":"code","fb0f4ac8":"code","7f6e4727":"code","147ee0a6":"code","508b877f":"code","79dc5ff6":"code","80128467":"code","ce3c1f23":"code","14f31ae7":"code","00910bd4":"code","82c28b2c":"code","cedd6874":"code","4b83111e":"code","96f1a40e":"code","aafd50f2":"code","c31d375f":"code","4c88b905":"code","cca51879":"code","fdbd2f1c":"markdown","42b424fd":"markdown","bc5449be":"markdown","f9081b49":"markdown","a39a546e":"markdown","fc6d967c":"markdown","0899f7cc":"markdown","c05e96ff":"markdown","5d81c2d0":"markdown","2d3fdba6":"markdown","843522fe":"markdown","896e8979":"markdown","78e4b5f9":"markdown","8c528673":"markdown","3ca80f88":"markdown","aa816e4c":"markdown","b4ed78be":"markdown","f60177f2":"markdown","826d5935":"markdown","f82b2f81":"markdown","d6f8fd1e":"markdown","03ecd6cd":"markdown","71df267d":"markdown","3263eeaa":"markdown","cc0c1e48":"markdown","90f867fa":"markdown","7bcaaba3":"markdown","387b93e3":"markdown","f5b52655":"markdown"},"source":{"76c204fd":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, make_scorer","11500e01":"path = '..\/input\/tabular-playground-series-jan-2022\/'\npath_holidays = '..\/input\/holidays-finland-norway-sweden-20152019\/'\n\nprint('Compedition data:', os.listdir(path))\nprint('Holiday data:', os.listdir(path_holidays))","316769f8":"train_data = pd.read_csv(path+'train.csv')\ntest_data = pd.read_csv(path+'test.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')\n\nholidays = pd.read_csv(path_holidays+'Holidays_Finland_Norway_Sweden_2015-2019.csv')","9e6d7d88":"train_data['date'] = pd.to_datetime(train_data['date'])\ntest_data['date'] = pd.to_datetime(test_data['date'])\n\nholidays['Date'] = pd.to_datetime(holidays['Date'])","e4ea9d0d":"print('Number train samples:', len(train_data.index))\nprint('Number test samples:', len(test_data.index))\nprint('Number holiday samples:', len(holidays))","b20af254":"train_data.head()","57277cf9":"holidays.head()","6a7584cc":"country_list = list(train_data['country'].unique())\ntrain_data['country'].value_counts()","8c99208e":"store_list = list(train_data['store'].unique())\ntrain_data['store'].value_counts()","476cba4a":"product_list = ['Kaggle Hat', 'Kaggle Mug', 'Kaggle Sticker']\ntrain_data['product'].value_counts()","ee7dab6c":"def plot_timeseries(country):\n    fig, axs = plt.subplots(2, 3, figsize=(30, 10))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    for row in range(len(store_list)):\n        store = store_list[row]\n        for col in range(len(product_list)):\n            product = product_list[col]\n            temp = train_data[(train_data['country']==country) &\n                              (train_data['store']==store) &\n                              (train_data['product']==product)]\n            temp.index = temp['date']\n            axs[row][col].plot(temp.index, temp['num_sold'])\n            axs[row][col].set_title('Store:'+store+', Product:'+product)\n            axs[row][col].grid()","24569f77":"plot_timeseries(country='Finland')","1c339ebd":"plot_timeseries(country='Norway')","9b9f4af0":"plot_timeseries(country='Sweden')","fb0f4ac8":"country = 'Finland'\nstore = 'KaggleMart'\nproduct = 'Kaggle Mug'","7f6e4727":"df_temp = train_data[(train_data['country']==country) &\n                     (train_data['store']==store) &\n                     (train_data['product']==product)]\n\ndf_temp.index = df_temp['date']","147ee0a6":"decompose = seasonal_decompose(df_temp['num_sold'], model=\"multiplicative\")","508b877f":"def plot_timeseries(decompose):\n    fig, axs = plt.subplots(1, 4, figsize=(40, 10))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    part = ['observed', 'trend', 'saisonal', 'resid']\n    axs = axs.ravel()\n    axs[0].plot(decompose.observed.index, decompose.observed.values)\n    axs[1].plot(decompose.trend.index, decompose.trend.values)\n    axs[2].plot(decompose.seasonal.index, decompose.seasonal.values)\n    axs[3].plot(decompose.resid.index, decompose.resid.values)\n    \n    for i in range(4):\n        axs[i].set_title(part[i])\n        axs[i].grid()","79dc5ff6":"plot_timeseries(decompose)","80128467":"def extract_year(s):\n    return s.year\n\ntrain_data['year'] = train_data['date'].apply(extract_year)\ntest_data['year'] = test_data['date'].apply(extract_year)\n\nyear_list = list(train_data['year'].unique()) + list(test_data['year'].unique())","ce3c1f23":"def extract_month_name(s):\n    return s.month_name()\n\ntrain_data['month_name'] = train_data['date'].apply(extract_month_name)\ntest_data['month_name'] = test_data['date'].apply(extract_month_name)\n\nmonth_list = list(train_data['month_name'].unique())\n\ndef extract_month(s):\n    return s.month\n\ntrain_data['month'] = train_data['date'].apply(extract_month)\ntest_data['month'] = test_data['date'].apply(extract_month)","14f31ae7":"def extract_day_name(s):\n    return s.day_name()\n\ntrain_data['day_name'] = train_data['date'].apply(extract_day_name)\ntest_data['day_name'] = test_data['date'].apply(extract_day_name)\n\nday_list = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\ndef extract_day(s):\n    return s.dayofweek\n\ntrain_data['day'] = train_data['date'].apply(extract_day)\ntest_data['day'] = test_data['date'].apply(extract_day)","00910bd4":"def extract_weekend(s):\n    if s == 'Saturday' or s == 'Sunday':\n        return 1\n    else:\n        return 0\n    \ntrain_data['weekend'] = train_data['day'].apply(extract_weekend)\ntest_data['weekend'] = test_data['day'].apply(extract_weekend)","82c28b2c":"rename_dict = {'Date': 'date', 'Country': 'country'}\nholidays = holidays.rename(rename_dict, axis=1)\n\ntrain_data = pd.merge(train_data, holidays, how='left', on=['date', 'country'])\ntest_data = pd.merge(test_data, holidays, how='left', on=['date', 'country'])","cedd6874":"def extract_holiday(s):\n    if type(s)==float:\n        return 0\n    else:\n        return 1\n    \ntrain_data['holiday'] = train_data['Name'].apply(extract_holiday)\ntest_data['holiday'] = test_data['Name'].apply(extract_holiday)","4b83111e":"train_data[pd.get_dummies(train_data['country']).columns] = pd.get_dummies(train_data['country'])\ntrain_data[pd.get_dummies(train_data['store']).columns] = pd.get_dummies(train_data['store'])\ntrain_data[pd.get_dummies(train_data['product']).columns] = pd.get_dummies(train_data['product'])\ntrain_data[pd.get_dummies(train_data['day_name']).columns] = pd.get_dummies(train_data['day_name'])\ntrain_data[pd.get_dummies(train_data['month_name']).columns] = pd.get_dummies(train_data['month_name'])\ntrain_data[pd.get_dummies(train_data['year']).columns] = pd.get_dummies(train_data['year'])\ntrain_data[2019] = 0\n\ntest_data[pd.get_dummies(test_data['country']).columns] = pd.get_dummies(test_data['country'])\ntest_data[pd.get_dummies(test_data['store']).columns] = pd.get_dummies(test_data['store'])\ntest_data[pd.get_dummies(test_data['product']).columns] = pd.get_dummies(test_data['product'])\ntest_data[pd.get_dummies(test_data['day_name']).columns] = pd.get_dummies(test_data['day_name'])\ntest_data[pd.get_dummies(test_data['month_name']).columns] = pd.get_dummies(test_data['month_name'])\ntest_data[pd.get_dummies(test_data['year']).columns] = pd.get_dummies(test_data['year'])\ntest_data[[2015, 2016, 2017, 2018]]=0","96f1a40e":"features_cyclic = ['day', 'month']\nfor feature in features_cyclic:\n    train_data[feature+'_sin'] = np.sin((2*np.pi*train_data[feature])\/max(train_data[feature]))\n    train_data[feature+'_cos'] = np.cos((2*np.pi*train_data[feature])\/max(train_data[feature]))\n    test_data[feature+'_sin'] = np.sin((2*np.pi*test_data[feature])\/max(test_data[feature]))\n    test_data[feature+'_cos'] = np.cos((2*np.pi*test_data[feature])\/max(test_data[feature]))\n    \nfeature_cyc_list = ['day_sin', 'day_cos', 'month_sin', 'month_cos']","aafd50f2":"def smape_error(y_true, y_pred):\n    smape = 1\/len(y_true) * np.sum(2 * np.abs(y_pred-y_true) \/ (np.abs(y_true) + np.abs(y_pred))*100)\n    return smape\n\nscore = make_scorer(smape_error, greater_is_better=False)","c31d375f":"def get_params(X, y):\n    params = {'objective': ['reg:squarederror'],\n              'max_depth': [4, 5, 6, 7],\n              'learning_rate': [0.1],\n              'n_estimators': [50, 100, 125, 150],\n              'colsample_bytree': [0.8, 0.9, 1.0]}\n    \n    #params = {'objective': ['reg:squarederror'],\n    #          'max_depth': [6],\n    #          'learning_rate': [0.1],\n    #          'n_estimators': [50, 75, 100],\n    #          'colsample_bytree': [0.8, 0.9]}\n\n    xgb = XGBRegressor(seed = 2022)\n\n    clf = GridSearchCV(cv=10,\n                       estimator=xgb, \n                       param_grid=params,\n                       scoring=score, \n                       verbose=0,\n                       n_jobs=4)\n    \n    clf.fit(X, y)\n    print('Best SMAPE Score:', round(-(clf.best_score_), 2))\n    print('Best Params:', clf.best_params_)\n    print('\\n')\n    return clf.best_params_","4c88b905":"for country in country_list:\n    for store in store_list:\n        for product in product_list:\n            print(country, ' - ', store, ' - ', product)\n            train_temp = train_data[(train_data[country]==1)&\n                                    (train_data[store]==1)&\n                                    (train_data[product]==1)]\n            test_temp = test_data[(test_data[country]==1)&\n                                  (test_data[store]==1)&\n                                  (test_data[product]==1)]\n            \n            features = ['year', 'month', 'day', 'weekend', 'holiday']+day_list+month_list+year_list+feature_cyc_list\n            \n            X = train_temp[features]\n            y = train_temp['num_sold']\n            X_test = test_temp[features]\n            \n            #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=2022)\n            X_train = X\n            y_train = y\n            params = get_params(X_train, y_train)\n            \n            #model = XGBRegressor(objective='reg:squarederror',\n            #                     n_estimators=50,\n            #                     learning_rate=0.1,\n            #                     colsample_bytree=0.8,\n            #                     max_depth=5)\n            model = XGBRegressor(**params)\n            #model = LinearRegression(normalize=False)\n            model.fit(X_train, y_train)\n            #y_val_pred = model.predict(X_val)\n            #print('SMAPE:', round(smape_error(y_val, y_val_pred), 2))\n            \n            y_test = model.predict(X_test)\n            samp_subm.loc[X_test.index, 'num_sold'] = y_test\n        ","cca51879":"samp_subm.to_csv('submission.csv', index=False)","fdbd2f1c":"Products","42b424fd":"# Path","bc5449be":"# Intro\nWelcome to the [Tabular Playground Series - Jan 2022](https:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2022) competition.\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/33101\/logos\/header.png)\n\nWe use the dates of the holidays in Finland, Norway and Sweden from here:\n* Source [Finland](https:\/\/date.nager.at\/PublicHoliday\/Country\/FI), \n* Source [Norway](https:\/\/date.nager.at\/PublicHoliday\/Country\/NO), \n* Source [Sweden](https:\/\/date.nager.at\/PublicHoliday\/Country\/SE). \n\nThe file with all holidays you can find [here](https:\/\/www.kaggle.com\/drcapa\/holidays-finland-norway-sweden-20152019). \n\n**Table of content:**\n1. [Exploratory Data Analysis](#EDA)\n2. [Plot Time Series](#PTS)\n3. [Time Series Analysis](#TSA)\n4. [Feature Engineering](#FE)\n5. [Define Model](#DE)\n6. [Export](#Export)\n\n\n<font size=\"4\"><span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. <\/span><\/font>","f9081b49":"# Libraries","a39a546e":"Countries:","fc6d967c":"# Define Model <a name=\"DM\"><\/a>","0899f7cc":"Create feature month:","c05e96ff":"Holidays:","5d81c2d0":"## Finland","2d3fdba6":"Set feature date to datetime format:","843522fe":"# Overview\nIn this compedition we have to predict number of sales of products in the kaggle stores.","896e8979":"Create feature day of week:","78e4b5f9":"**Observation:** The products have an individually structure. It could be helpful to use different models for different products.","8c528673":"Because of the different structure of the products we use different models to train and predict the data.","3ca80f88":"# Export <a name=\"Export\"><\/a>","aa816e4c":"The [symmetric mean absolute percentage error](https:\/\/en.wikipedia.org\/wiki\/Symmetric_mean_absolute_percentage_error) (smape) is used to measure the predictive accuracy of the submission results:","b4ed78be":"# Feature Engineering <a name=\"FE\"><\/a>\nWe create new features based on the date.","f60177f2":"Now we encode the categorical features. Therefor we recommend this [notebook](https:\/\/www.kaggle.com\/drcapa\/categorical-feature-engineering-xgb).","826d5935":"Stores:","f82b2f81":"# Plot Time Series <a name=\"PTS\"><\/a>\nWe plot the target value **num_sold** countrywise for every shop and every product","d6f8fd1e":"Weekend:","03ecd6cd":"# Exploratory Data Analysis <a name=\"EDA\"><\/a>","71df267d":"# Load Data","3263eeaa":"Train data:","cc0c1e48":"Create feature year:","90f867fa":"Holiday data:","7bcaaba3":"# Time Series Analysis <a name=\"TSA\"><\/a>","387b93e3":"## Norway","f5b52655":"## Sweden"}}