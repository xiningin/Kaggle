{"cell_type":{"093b0de8":"code","b772cf6b":"code","1c25fc0e":"code","0087a681":"code","4faf829d":"code","9c979c86":"code","ef4eaea5":"code","54a40602":"code","eb897ecf":"code","38214aa9":"code","e6999618":"code","e4da1fee":"code","0ad3f43a":"code","2e74d418":"code","22b02c70":"code","df155b9f":"code","246c9066":"code","116b514c":"code","0518b1dd":"markdown","a758572b":"markdown","c7e25dd3":"markdown","20ed494b":"markdown","0f772bee":"markdown","f00b1804":"markdown","0ad61f60":"markdown","ecaafbee":"markdown","757fd376":"markdown","64a346fa":"markdown","c0d61d3d":"markdown"},"source":{"093b0de8":"pip install mplcyberpunk","b772cf6b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data process\/ng, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport mplcyberpunk\nplt.style.use(\"cyberpunk\")\nmplcyberpunk.add_glow_effects()\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c25fc0e":"dataset = pd.read_csv(\"\/kaggle\/input\/habermans-survival-data-set\/haberman.csv\", names =[\"age\",\"year\",\"n_auxillary_nodes\",\"survival_after_5years\"])\ndataset.head()","0087a681":"print(dataset.info())","4faf829d":"dataset.shape[0]","9c979c86":"print(dataset.survival_after_5years.value_counts())\nprint(dataset.iloc[:,-1].value_counts(normalize = True))\n","ef4eaea5":"dataset['survival_after_5years'] = dataset['survival_after_5years'].map({1:\"yes\", 2:\"no\"})\ndataset.head()","54a40602":"dataset.info()","eb897ecf":"dataset['survival_after_5years'] = dataset['survival_after_5years'].astype(('category'))","38214aa9":"dataset.info()","e6999618":"print(dataset.describe())","e4da1fee":"dataset.isna().sum()","0ad3f43a":"#Distribution plots\n\"\"\"\n* Distribution plots are used to visually assess how the data points are distributed with respect to its frequency.\n* Usually the data points are grouped into bins and the height of the bars representing each group increases with increase in the number of data points \nlie within that group. (histogram)\n* Probality Density Function (PDF) is the probabilty that the variable takes a value x. (smoothed version of the histogram)\n* Kernel Density Estimate (KDE) is the way to estimate the PDF. The area under the KDE curve is 1.\n* Here the height of the bar denotes the percentage of data points under the corresponding group\n\"\"\"\nfor idx, feature in enumerate(list(dataset.columns)[:-1]):\n    fg = sns.FacetGrid(dataset, hue='survival_after_5years', height=5)\n    fg.map(sns.distplot, feature).add_legend()\n    plt.show()","2e74d418":"dataset[dataset.n_auxillary_nodes>20]","22b02c70":"\"\"\"\nThe cumulative distribution function (cdf) is the probability that the variable takes a value less than or equal to x.\n\"\"\"\nplt.figure(figsize=(20,5))\nfor idx, feature in enumerate(list(dataset.columns)[:-1]):\n    plt.subplot(1, 3, idx+1)\n    print(\"********* \"+feature+\" *********\")\n    counts, bin_edges = np.histogram(dataset[feature], bins=10, density=True)\n    print(\"Bin Edges: {}\".format(bin_edges))\n    pdf = counts\/sum(counts)\n    print(\"PDF: {}\".format(pdf))\n    cdf = np.cumsum(pdf)\n    print(\"CDF: {}\".format(cdf))\n    plt.plot(bin_edges[1:], pdf, bin_edges[1:], cdf)\n    plt.xlabel(feature)","df155b9f":"\"\"\"\nBox plot takes a less space and visually represents the five number summary of the data points in a box. \nThe outliers are displayed as points outside the box.\n1. Q1 - 1.5*IQR\n2. Q1 (25th percentile)\n3. Q2 (50th percentile or median)\n4. Q3 (75th percentile)\n5. Q3 + 1.5*IQR\nInter Quartile Range = Q3 -Q1\n\"\"\"\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfor idx, feature in enumerate(list(dataset.columns)[:-1]):\n    sns.boxplot( x='survival_after_5years', y=feature, data=dataset, ax=axes[idx])\nplt.show()  ","246c9066":"\"\"\"\nViolin plot is the combination of box plot and probability density function.\n\"\"\"\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nfor idx, feature in enumerate(list(dataset.columns)[:-1]):\n    sns.violinplot( x='survival_after_5years', y=feature, data=dataset, ax=axes[idx])\nplt.show()","116b514c":"\"\"\"\nPair plot in seaborn plots the scatter plot between every two data columns in a given dataframe.\nIt is used to visualize the relationship between two variables\n\"\"\"\nsns.pairplot(dataset, hue='survival_after_5years', size=4)\nplt.show()","0518b1dd":"**Observations - Higher level statistics of the dataset**\n- There are 306 datapoints in each of the 4 features. survival_after_5years is the target feature containing binary values - 1 & 2\n- There are 225 patients and 81 patients who survived and who did not after treatment respectively. Hence the target column is imbalanced with 73% of values being '1'\n","a758572b":"**Data Description** The Haberman's survival dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.\n\n**Attribute Information:**\n\n* Age of patient at time of operation (numerical)\n* Patient's year of operation (year - 1900, numerical)\n* Number of positive axillary nodes detected (numerical)\n* Survival status (class attribute) 1 = the patient survived 5 years or longer 2 = the patient died within 5 years","c7e25dd3":"Domain inputs from https:\/\/pubmed.ncbi.nlm.nih.gov\/6352003\/\nFrom the paper, we come to know that the number of positive auxillary nodes is greatly related to the survival rate.The greater the value, smaller the chances of survival.But let's analyse the data to know more about that feature. ","20ed494b":"**UNIVARIATE ANALYSIS**\n- Probability Density Functions\n- Cummulative Density Functions \n- Box plots\n- Violin plots","0f772bee":"**Observations**\n- Almost 80% of the patients have less than or equal to 5 auxillary nodes\n- Almost equal number of patients(50%) took surgery before and after 1964 ","f00b1804":"**BIVARIATE ANALYSIS**","0ad61f60":"**OBJECTIVE** - *To perform exploratary data analysis on Haberman cancer survival Dataset to know which features are useful towards classification.*","ecaafbee":"**Observations**\n- The age column is have greater deviation compared to other columns and there is no patient under age 30 affected from this cancer (According to the data provided). Patient Age ranges between 30 and 83. \n- Year ranges between 1958 to 1969. \n- Although the maximum number of positive auxillary nodes observed is 52, nearly 75% of the patients have less than 5 positive auxillary nodes and nearly 25% of the patients have no positive auxillary nodes\n- Data is pretty clean as there is no missing values. So imputation is not necessary.","757fd376":"**Observation** - We find that survival_after_5years falls into object Dtype. We want that to be our class variable containing 2 categories ","64a346fa":"**Observations**\n- Patients having number of auxillary nodes above 20 are unlikely to survive. (Domain inputs are hence proved here)\n","c0d61d3d":"**Observations**\n- From pairplots, we see that combination of features aren't useful for classification because nowhere we could linearly seperate yes\" and \"no\" between any two combination of features.\n- Considering the above plots, just by the overall look, we can say that the plots of the attributes are highly overlapped. An inference from such plots would be quite difficult.\n\n- But, the patient's age and the number of positive axillary nodes have some useful characteristics for classification which can be more revealed by more advanced machine learning algorithms.\n"}}