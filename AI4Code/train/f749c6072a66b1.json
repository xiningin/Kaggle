{"cell_type":{"fb216def":"code","5d2187c1":"code","b8edfd7d":"code","bd4b0b1d":"code","cc059d9b":"code","32822d82":"code","33f215bf":"code","0dff6d92":"code","d5950f12":"code","9e7aea53":"code","6392a995":"code","f078ba09":"code","7fbbb0f3":"code","f656f1fa":"code","d2375336":"code","1c401c7b":"code","ffb03a5c":"code","8b0e73ce":"code","a61451f1":"code","47d704f0":"code","ee2eb505":"code","bdb19226":"markdown","f182cc19":"markdown","32650439":"markdown","e2f61046":"markdown","575bbea8":"markdown","af43542d":"markdown","45d22ef8":"markdown","f6a7d1f5":"markdown","9360230a":"markdown","156ca5a6":"markdown","485d060f":"markdown","e0d42ed8":"markdown"},"source":{"fb216def":"# Importing libraries and changing working directory\nimport matplotlib.pyplot as plt\nimport matplotlib as mat\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport os\n%matplotlib inline\nwarnings.filterwarnings('ignore')\npath = r'..\/input\/pima-indians-diabetes-database'\nos.chdir(path)","5d2187c1":"# Reading csv file\ndata = pd.read_csv('diabetes.csv')\ndata.head()","b8edfd7d":"# Checking field formats\ndisplay(data.dtypes)\nprint(\"NOTE: Data types are already correct format ('Outcome' is a boolean field but for now it will be considered int64)\")","bd4b0b1d":"# Checking for missing values (NA)\ndisplay(data.isnull().any())\nprint(\"NOTE: No missing inputs, but do we have inconsistent observations in our dataset (registrations with zeros only)?\")","cc059d9b":"# Statistics summary for variables\ndisplay(data.describe())\nprint(\"NOTE: In 'min' row we can see fields only with zeros. By filtering them in our dataset, we can see how many zeros we have in:\\n\")\n\nfor col in data.columns.tolist()[1:-1]:\n    print(col + \" = \" + str(len(data[data[col] == 0])), end = \"\\n\")\n    \nprint(\"\\nNOTE: For now, we'll leave as it is and check later if normalizing the dataset is sufficient for having a good accuracy.\")    ","32822d82":"# Checking for outliers with boxplots\ndata.plot(kind = 'box', subplots = True, layout = (3,3), sharex = False, sharey = False, figsize=(12, 12))\nplt.show()\nprint(\"NOTE: Since we have many observations with zeros, some boxplots may be out of scale.\")","33f215bf":"# Checking data distribution with histograms\ndata.hist(figsize=(12, 12))\nplt.show()","0dff6d92":"# Checking data distribution for diabetes patients\ndisplay(data['Outcome'].value_counts())\nprint(\"NOTE: Data is not equally distributed between patients with and without diabetes (we have 500 cases with negative results and  268 with diabetes).\")","d5950f12":"# Plotting correlation matrices (Pearson)\ncorr = data.corr()\ndisplay(corr.style.background_gradient(cmap='coolwarm').set_precision(2))\n# Alternative view with heatmap\nf, ax = plt.subplots(figsize=(10, 8))\ndisplay(sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool),\n            cmap=sns.diverging_palette(1000, 10, as_cmap=True),\n            square=True, ax=ax))","9e7aea53":"# Normalizing dataset using MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\narray = data.values\n\n# Separating into dependent and independent variables\nX = array[:, 0:8]\nY = array[:, 8]\n\n# Normalizing data with scaler\nscaler = MinMaxScaler(feature_range = (0, 1))\nrescaledX = scaler.fit_transform(X)\n\n# Summarizing transformed data\nprint(\"Original data: \\n\\n\", X)\nprint(\"\\nNormalized data: \\n\\n\", rescaledX)\n\nprint(\"\\nNOTE: For logistic regression, standard scaler was applied.\")\n\n# Using standard scaler\nscaler = StandardScaler().fit(X)\nstandardX = scaler.transform(X)\n\nprint(\"\\nStandarized data: \\n\\n\", standardX)","6392a995":"# Splitting data into Train\/Test (into 70\/30 ratio)\nfrom sklearn.model_selection import train_test_split\n\ntest_size = 0.3\nX_train, X_test, Y_train, Y_test = train_test_split(standardX, Y, test_size = test_size)\nprint(f\"NOTE: Training train batch size is {len(X_train)} and test is {len(X_test)}\")","f078ba09":"# Creating models for Logistic Regression, KNN and Random Forest\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Defining hyperparameters for cross Validation testing\nnum_folds = 50\nrandom_state = 8\nkfold = KFold(num_folds, True, random_state = random_state)\n\n# Logistic Regression\nregrl = LogisticRegression()\nregrl.fit(X_train, Y_train)\nregrl.score(X_train, Y_train)\nresults = cross_val_score(regrl, X_train, Y_train, cv = kfold)\nprint(\"Accuracy (Logistic Regression): %.3f\" % (results.mean() * 100))\n\n# KNN\nknn = KNeighborsClassifier()\nresults = cross_val_score(knn, X_train, Y_train, cv = kfold)\nprint(\"Accuracy (KNN): %.3f\" % (results.mean() * 100))\n\n# Random Forest\nnum_trees = 100\nmax_features = 8\nrandom_forest = RandomForestClassifier(n_estimators = num_trees, max_features = max_features)\nresults = cross_val_score(random_forest, X_train, Y_train, cv = kfold)\nprint(\"Accuracy (Random Forest): %.3f\" % (results.mean() * 100))","7fbbb0f3":"# Creating model predictions with logistic regression\npredicts = regrl.predict(X_test)\npredicts","f656f1fa":"# Evaluating model with confusion matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix = pd.DataFrame(confusion_matrix(Y_test, predicts))\n# Plotting confusion matrix\nsns.heatmap(confusion_matrix, annot = True, cmap=\"YlGnBu\" ,fmt='2g')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n# Plotting measurements for errors (Type I\/False Positives and Type II\/False Negatives)\nprint(classification_report(Y_test, predicts))","d2375336":"# Evaluating ROC (area under the curve) - values above .5 indicates good precision\nresult = cross_val_score(regrl, X_train, Y_train, cv = kfold, scoring = 'roc_auc')\nprint(\"AUC: %.3f\" % (result.mean() * 100))","1c401c7b":"# Approach 1 - Optimizing with RFE (recursive feature elimination)\nfrom sklearn.feature_selection import RFE\n\n# Finding out the four best variables in our dataset\nvar_num = 4\nvars_fit = []\nvars_org = data.columns[0:8].tolist()\nrfe = RFE(regrl, 4)\nfit = rfe.fit(X_train, Y_train)\n\nfor e in range(len(fit.support_)):\n    if fit.support_[e] == True:\n        vars_fit.append(vars_org[e])\n        \n# Printing results\nprint(\"Variables in dataset:\", data.columns[0:8].tolist())\nprint(\"Selected variables: %s\" % vars_fit)\nprint(\"Features ranking: %s\" % fit.ranking_)\nprint(\"Number of n features selected: %d\" % fit.n_features_)","ffb03a5c":"# Approach 2 - Slicing dataset only with relevant variables\nstandardX_2 = standardX[:, list(fit.support_)]\nX_train_2, X_test_2, Y_train_2, Y_test_2 = train_test_split(standardX_2, Y, test_size = test_size)\n\n# Re-running logistic regression model \nregrl.fit(X_train_2, Y_train_2)\nregrl.score(X_train_2, Y_train_2)\nresults = cross_val_score(regrl, X_train_2, Y_train_2, cv = kfold)\n\nprint(\"Accuracy (Logistic Regression): %.3f\" % (results.mean() * 100))","8b0e73ce":"# Using Random Search Parameter Tuning to evaluate parameters\nfrom sklearn.model_selection import RandomizedSearchCV\n\nvalores_grid = {'penalty': ['l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\niterations = 14\nrsearch = RandomizedSearchCV(estimator = LogisticRegression(solver='liblinear'), \n                             param_distributions = valores_grid, \n                             n_iter = iterations)\nrsearch.fit(X, Y)\n\nprint(\"Accuracy: %.3f\" % (rsearch.best_score_ * 100))\nprint(\"Best parameters:\\n\", rsearch.best_estimator_)","a61451f1":"# Exporting model into .sav file\n# import pickle\n# f = 'models\/regrl_classifier.sav'\n# pickle.dump(regrl, open(f, 'wb'))\n\n# # Loading .sav file\n# model = pickle.load(open(f, 'rb'))","47d704f0":"# Recreating test dataset for visualization\npredicts_df = pd.DataFrame(scaler.inverse_transform(X_test), columns = data.columns.tolist()[0:8])\npredicts_df['Prediction'] = pd.Series(predicts).map(lambda x: True if x == 1 else False)\npredicts_df.head()","ee2eb505":"# Checking data distribution\nf, ax = plt.subplots(figsize=(10, 6))\n\npredicts_df['Prediction'].value_counts().plot(kind = \"bar\", align='center')\nrects = predicts_df['Prediction'].value_counts().plot(kind = \"bar\", align='center').patches\nlabels = predicts_df['Prediction'].value_counts()\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width() \/ 2, height + 1, str(label),\n            ha='center', va='bottom', fontsize = 10)\n\nplt.xlabel('Prediction for diabetes', fontsize= 12)\nplt.ylabel('Qty patients', fontsize= 12)\nplt.title(\"Estimated Quantity of Patients with Diabetes\", fontsize = 16)\nplt.show()\n\ndisplay(pd.DataFrame(predicts_df['Prediction'].value_counts()))","bdb19226":"CONCLUSION: For the visualization above, we can see that the model predicts and separates 172 patients without diabetes and 59 positive cases. For the positive cases, we could easily filter their characteristics from the dataset and take a deeper look individually to identify further patterns for this disease.","f182cc19":"### Relevant Notes\n1. Data is already organised but needs to be normalized because we have different columns in different scales (i.e. 'Age' and 'Glucose'), which can be a problem when implementing our chosen model;\n2. 'Outcome' column is our target variable (dependent) and all other columns are our predictors (independent); a correlation test will be useful to see if all variables should be considered in our model;\n3. In the correlation matrix above, we can see some relationships between Age\/Pregnancies, Skin Thickness\/Insulin and Skin Thickness\/BMI that can be used in the subsequent steps (for feature selection);\n4. Data has been split into train and test subsets (variables X_train, Y_train, X_test and Y_test);\n5. We have a classification problem (identify if a specific patient have diabetes or not), so we'll create a benchmark between three algorithms: logistic regression model, KNN (K-nearest neighbours) and random forest.","32650439":"# Model Deployment","e2f61046":"# Conclusion","575bbea8":"# Process Description\nThis analysis was structured in the following steps:\n1. Process and data understanding \n2. Data handling\/wrangling\n3. Machine Learning model implementation\n4. Model Evaluation\n5. Optimization\/deployment\n6. Conclusion","af43542d":"# Machine Learning model implementation","45d22ef8":"## End","f6a7d1f5":"As we can see above, after cross-validating three different Machine Learning models, Logistic regression stands out comparing with random forest and KNN algorithms, so we'll use this model for predicting our test subset.","9360230a":"# Optimization approaches","156ca5a6":"# Pima Indians Diabetes Database","485d060f":"# Model evaluation","e0d42ed8":"# Data Handling\/wrangling"}}