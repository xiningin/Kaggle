{"cell_type":{"dfdcd917":"code","19b961cd":"code","cabe8242":"code","7234ee10":"code","766d1f8e":"code","e51d3213":"code","2caecee4":"code","1a7629ee":"code","a285bdc6":"code","973acdd7":"code","b9bba409":"code","12ad201e":"code","20737811":"code","f98b52d7":"code","80be00f7":"code","dd86b485":"code","f9d3a604":"markdown"},"source":{"dfdcd917":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","19b961cd":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npd.set_option('display.max_columns',None)\n%matplotlib inline","cabe8242":"data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\nprint(data.shape)\ndata.head()","7234ee10":"\ncat_var = [col for col in data.columns if data[col].dtype =='O']\ncat_var","766d1f8e":"data.Class.value_counts()","e51d3213":"(data.Class.value_counts()\/len(data))*100","2caecee4":"fraud =data[data['Class']==1]\nnot_fraud=data[data['Class']==0][:492]\n","1a7629ee":"df =pd.concat([fraud, not_fraud])\n","a285bdc6":"df.Class.value_counts()","973acdd7":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndf['Time'] = sc.fit_transform(df['Time'].values.reshape(-1,1))\ndf['Amount'] = sc.transform(df['Amount'].values.reshape(-1,1))","b9bba409":"df.head()","12ad201e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df.drop('Class', axis =1), df.Class, test_size =0.2, random_state =0)\nX_train.shape, X_test.shape","20737811":"from sklearn.decomposition import PCA,TruncatedSVD\npca =PCA(n_components=2)\nX_train_pca= pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\npca.explained_variance_ratio_","f98b52d7":"from sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\n\nlogit_model = LogisticRegression()\nlogit_model.fit(X_train_pca, y_train)\n\npred = logit_model.predict_proba(X_train_pca)\n\nprint('Logit train roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n\npred = logit_model.predict_proba(X_test_pca)\n\nprint('Logit test roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))","80be00f7":"import xgboost as xgb\nxgb_model = xgb.XGBClassifier(n_estimators=100)\n\nxgb_model = xgb.XGBClassifier()\nxgb_model.fit(X_train_pca, y_train)\n\npred = xgb_model.predict_proba(X_train_pca)\nprint('xgb train roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n\npred = xgb_model.predict_proba(X_test_pca)\nprint('xgb test roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))","dd86b485":"from sklearn.ensemble import AdaBoostClassifier\nada_model = AdaBoostClassifier()\nada_model.fit(X_train_pca, y_train)\n\npred = ada_model.predict_proba(X_train_pca)\nprint('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\npred = ada_model.predict_proba(X_test_pca)\nprint('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))","f9d3a604":"truncated_svd = TruncatedSVD(n_components=2)\nX_train_svd= truncated_svd .fit_transform(X_train)\nX_test_svd = truncated_svd .transform(X_test)"}}