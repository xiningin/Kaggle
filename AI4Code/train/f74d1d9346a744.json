{"cell_type":{"e87cdf2e":"code","5a76a12b":"code","421fb6f1":"code","d2f232ff":"code","d8a74399":"code","3de8f1b3":"code","5412f70f":"code","0a3caabc":"code","89e18c49":"code","23ebc664":"code","319c8b30":"code","0432f3e6":"code","6fb44631":"code","b13bb364":"code","5cc305ff":"code","e14ff0ff":"code","86e8e7d0":"code","794555e1":"markdown","5666303c":"markdown","e249d25c":"markdown","6c325472":"markdown","3f079b47":"markdown","670e065b":"markdown","4d4d606e":"markdown","f0b8edb1":"markdown","8ce833bd":"markdown","7418e82b":"markdown","a252a4b8":"markdown","8d90733b":"markdown"},"source":{"e87cdf2e":"import numpy as np\nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\n%matplotlib inline\nimport tensorflow as tf\nimport glob\n\nfrom skimage.io import imread, imshow\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","5a76a12b":"# organic type\ntrain_o = glob.glob('..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/*.jpg')","421fb6f1":"# recycle type\ntrain_r = glob.glob('..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/*.jpg')","d2f232ff":"# Total training images \nprint(\"Nos of training samples: {}\".format(len(train_o)+len(train_r)))","d8a74399":"plt.figure(figsize=(12, 5))\nsp = plt.subplot(2, 5, 1)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_20.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 2)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_25.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 3)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_800.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 4)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_1004.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 5)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_1658.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 6)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_6783.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 7)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_11783.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 8)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_8583.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 9)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_9000.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 10)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/O\/O_12000.jpg\")\nplt.imshow(img)","3de8f1b3":"plt.figure(figsize=(12, 5))\nsp = plt.subplot(2, 5, 1)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_20.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 2)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_25.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 3)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_800.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 4)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_1004.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 5)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_1658.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 6)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_6783.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 7)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_1783.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 8)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_8589.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 9)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_9000.jpg\")\nplt.imshow(img)\nsp = plt.subplot(2, 5, 10)\nsp.axis('Off')\nimg = mpimg.imread(\"..\/input\/waste-classification-data\/DATASET\/TRAIN\/R\/R_5000.jpg\")\nplt.imshow(img)","5412f70f":"# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator(rescale = 1.0 \/ 255.0,\n                                   zoom_range = 0.4,\n                                   rotation_range = 10,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   validation_split = 0.2)\n\nvalid_datagen = ImageDataGenerator(rescale = 1.0 \/ 255.0,\n                                   validation_split = 0.2)\n\ntest_datagen  = ImageDataGenerator(rescale = 1.0 \/ 255.0)","0a3caabc":"# --------------------\n# Flow training images in batches of 64 using train_datagen generator\n# --------------------\ntrain_dataset  = train_datagen.flow_from_directory(directory = '..\/input\/waste-classification-data\/DATASET\/TRAIN',\n                                                   target_size = (224,224),\n                                                   class_mode = 'binary',\n                                                   batch_size = 64, \n                                                   subset = 'training')\n# --------------------\n# Flow validation images in batches of 64 using valid_datagen generator\n# --------------------\nvalidation_dataset = valid_datagen.flow_from_directory(directory = '..\/input\/waste-classification-data\/DATASET\/TRAIN',\n                                                  target_size = (224,224),\n                                                  class_mode = 'binary',\n                                                  batch_size = 64, \n                                                  subset = 'validation')\n\n# Test Data \n\ntest_dataset = test_datagen.flow_from_directory(directory = '..\/input\/waste-classification-data\/DATASET\/TEST',\n                                             target_size = (224,224),\n                                             class_mode = 'binary',\n                                             batch_size = 64)","89e18c49":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 224x224 with 3 color\n    tf.keras.layers.Conv2D(filters=32,activation='relu',input_shape=(224,224,3),padding='same',kernel_size=(3,3)),\n    tf.keras.layers.Conv2D(filters=32,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    tf.keras.layers.Conv2D(filters=64,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.Conv2D(filters=64,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    tf.keras.layers.Conv2D(filters=128,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.Conv2D(filters=128,activation='relu',padding='same',kernel_size=(3,3)),\n    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(units=512,activation='relu'),\n    tf.keras.layers.Dropout(0.1),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(units=256,activation='relu'),\n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('Organic') \n    # and 1 for the other ('Recycled')\n    tf.keras.layers.Dense(units=1,activation='sigmoid'),\n])","23ebc664":"#The following is the model summary of the model:\nmodel.summary()","319c8b30":"monitor = EarlyStopping(monitor='val_auc', patience=2, \n                        verbose=1, mode='max',restore_best_weights=True)\n# Defining Callbacks\n\nfilepath = '.\/best_weights.hdf5'\ncheckpoint    = ModelCheckpoint(filepath, \n                                monitor = 'val_auc', \n                                mode='max', \n                                save_best_only=True, \n                                verbose = 1)\n\n\ncallback_list = [monitor, checkpoint]\n\n# model compile\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n              metrics = [tf.keras.metrics.AUC(name = 'auc')])","0432f3e6":"history = model.fit(train_dataset,\n                              validation_data=validation_dataset,\n                              epochs=15,\n                              verbose=1, callbacks=callback_list)","6fb44631":"# plotting model auc\n\nplt.plot(history.history['auc'])\nplt.plot(history.history['val_auc'])\nplt.title('Model AUC')\nplt.ylabel('AUC')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\nplt.show()","b13bb364":"# plotting model loss\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\nplt.show()","5cc305ff":"# Evaluating Loss and AUC for Test data \n\nmodel.evaluate(test_dataset)","e14ff0ff":"# Test - ORGANIC\n\ntest_dict = test_dataset.class_indices\nidc = {k:v for v,k in test_dict.items()}\n\nimg = load_img('..\/input\/waste-classification-data\/DATASET\/TEST\/O\/O_12596.jpg', target_size=(224,224))\nimg = img_to_array(img)\nimg = img \/ 255\nimshow(img)\nplt.axis('off')\nimg = np.expand_dims(img,axis=0)\npred = model.predict_proba(img)\n\nif pred[0][0] > 0.5:\n    print(\"The image belongs to Recycle waste category\")\nelse:\n    print(\"The image belongs to Organic waste category \")","86e8e7d0":"# Test - RECYCLE\n\ntest_dict = test_dataset.class_indices\nidc = {k:v for v,k in test_dict.items()}\n\nimg = load_img('..\/input\/waste-classification-data\/DATASET\/TEST\/R\/R_10011.jpg', target_size=(224,224))\nimg = img_to_array(img)\nimg = img \/ 255\nimshow(img)\nplt.axis('off')\nimg = np.expand_dims(img,axis=0)\npred = model.predict_proba(img)\n\nif pred[0][0] > 0.5:\n    print(\"The image belongs to Recycle waste category\")\nelse:\n    print(\"The image belongs to Organic waste category \")","794555e1":"###  Model Fitting","5666303c":"#### Training Data","e249d25c":"### Let us view some of the images of **Organic** type","6c325472":"### **Importing Required Libraries**","3f079b47":"### Let us view some of the images of **Recycle** type","670e065b":"#### Specifying the optimizers and compile the model","4d4d606e":"### Model Evaluation","f0b8edb1":"#### Formation of CNN","8ce833bd":"### Conclusion - \n\n1. We were able to classify images properly having accuracy of 92.70% in training dataset.\n\n2. We achieved an accuracy of 92.63% on validation data and 95% accuracy on test accuracy.","7418e82b":"### **Model Building**","a252a4b8":"### **Load Data**","8d90733b":"### **Data Augmentation**"}}