{"cell_type":{"74eba365":"code","1eee8447":"code","4d867669":"code","ab509bb0":"code","928e2f89":"code","0880d063":"code","96490a65":"code","083bf868":"code","3a1ffb56":"code","6efa9608":"code","4fc3f7d1":"code","fabe0e24":"code","54030ad1":"code","99387d72":"code","7635ffae":"code","dc08896a":"code","0915bb56":"code","169c4d9a":"code","aa1a6521":"code","aed6b2e3":"code","1d24f6f2":"code","2ecfcaa8":"code","5db38281":"code","1f220241":"code","f029e1eb":"code","f73b304e":"code","6ca536e1":"code","b8c741c6":"code","dade2b4e":"code","5cc0246f":"markdown","1044654d":"markdown","b94f67ce":"markdown","9361ce94":"markdown","c1e78f6b":"markdown","358642fe":"markdown","fc4498ee":"markdown","d49d0f15":"markdown"},"source":{"74eba365":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1eee8447":"import tqdm\nimport random\nfrom collections import deque\nfrom random import randint, sample, choice","4d867669":"permutations = pd.read_csv(\"\/kaggle\/input\/santa-2021\/permutations.csv\")\ndistances = pd.read_csv(\"\/kaggle\/input\/santa-2021\/distance_matrix.csv\")\npermutations_ = [p[0] for p in permutations.values].copy()\n","ab509bb0":"permutations.head()","928e2f89":"distance_dict = {}\n\nfor i, row in distances.iterrows():\n    row_index = row.values[0]\n    \n    vals = row[1:]\n    \n    ldict = {}\n    for j in range(1,8):\n        ldict[j] = vals[vals == j].index.values\n    \n    distance_dict[row_index] = ldict\n    \nd = np.array(distances.values[:,1:], np.int32)","0880d063":"ids = {s[0]:i for i, s in enumerate(permutations.values)}\n\ndistance_dict_id = {}\n\nfor k, v in tqdm.tqdm(distance_dict.items()):\n    local = {}\n    for k_, v_ in v.items():\n        local[k_] = [ids[c] for c in v_]\n    distance_dict_id[ids[k]] = local","96490a65":"print(row_index)\ndistance_dict[row_index][2]","083bf868":"list(distance_dict_id.keys())[0]","3a1ffb56":"def get_score_graph(list_of_lists):\n    score = 0\n    \n    for l in list_of_lists:\n        total = 7\n        for i in range(1,len(l)):\n            total += d[l[i - 1], l[i]]\n        score = max(score, total)\n    return score\n","6efa9608":"nodes_covered = {}\n\nfor id1 in range(120):\n    nodes_covered_ = {}\n    perm1 = permutations_[id1]\n    for id2 in range(120):\n        n_ = []\n        perm2 = permutations_[id2]\n        for dist in range(0,8):\n            new_string = perm1[dist:] + perm2[:dist]\n            if new_string in permutations_:\n                n_.append(ids[new_string])\n        nodes_covered_ [id2] = n_\n    nodes_covered[id1] = nodes_covered_\n        \nnodes_covered[0][1]","4fc3f7d1":"best_routs = []\nbest_seen = 0\n\nroute_lst = list(range(0,120))\n\nfor k in tqdm.trange(500):\n    routs = []\n\n    seen_nodes = set(route_lst)\n    \n    routs = [[i] for i in random.sample(route_lst, 3)]\n    nodes_to_cover = [set(route_lst) for _ in range(3)]\n    \n    for j, r in enumerate(routs):\n        nodes_to_cover[j].remove(r[0])\n    \n    while nodes_to_cover[0] or nodes_to_cover[1] or nodes_to_cover[2]:\n        for j, route in enumerate(routs):\n            nodes_covered_ = nodes_covered[route[-1]]\n\n            best_next = None\n            best_value = -1\n            \n            l_ = lambda n_ : n_ not in seen_nodes\n\n            for n in nodes_to_cover[j]:\n                val = sum(map(l_, nodes_covered_[n])) + 0.01 * random.random()\n\n                if val > best_value:\n                    best_next = n\n                    best_value = val\n            \n            nodes_to_cover[j].remove(best_next)\n            route.append(best_next)\n\n            seen_nodes.update(nodes_covered_[best_next])\n\n    if len(seen_nodes) > best_seen:\n        best_routs = routs\n        best_seen = len(seen_nodes)\n        \n#         if best_seen == 840:\n#             break\n        \nprint(best_seen)","fabe0e24":"list_of_list = [[permutations_[i] for i in l] for l in routs]\n\nfor l in list_of_list:\n    seen_nodes = set()\n    seen_nodes.update(nodes_covered)\n    for i in range(1,120):\n        seen_nodes.update(nodes_covered[ids[l[i - 1]]][ids[l[i]]])\n        seen_nodes.update(nodes_covered[ids[l[i]]][ids[l[i]]])\n    print(len(seen_nodes))","54030ad1":"base_score = len(permutations_[120:])\nbest_list_of_list = list_of_list.copy()\n\nresult = [\"\".join(l) for l in list_of_list]\nresult0 = result[0]\nresult1 = result[1]\nresult2 = result[2]\n\nl_ = lambda p: (p in result0) or (p in result1) or (p in result2)\nlast_permutations = permutations_[120:]\n\nmin_score = sum(map(l_, last_permutations))\n\n\nsample_range = list(range(0,120))\n\nloop_size = 5000\n\nrandom_i1 = np.random.randint(120, size = loop_size)\nrandom_i2 = np.random.randint(120, size = loop_size)\n# random_i3 = np.random.randint(120, size = loop_size)\n# random_i4 = np.random.randint(120, size = loop_size)\n# random_i5 = np.random.randint(120, size = loop_size)\n\nrandom_l1 = np.random.randint(3, size = loop_size)\nimport itertools\n\nfor k in tqdm.trange(loop_size):\n    \n    list_of_list = [l.copy() for l in best_list_of_list]\n\n    lst = [random_i1[k], random_i2[k]]\n    first = True\n    for p in itertools.permutations(lst):\n        if first:\n            first = False\n            continue\n        l1 = list_of_list[random_l1[k]]\n        l2 = l1.copy()\n        \n        for i, p_ in zip(lst, p):\n            l1[i] = l2[p_]\n\n        result = [\"\".join(l) for l in list_of_list]\n        result0 = result[0]\n        result1 = result[1]\n        result2 = result[2]\n\n        l_ = lambda p: (p in result0) or (p in result1) or (p in result2)\n\n        score = sum(map(l_, last_permutations)) + 0.01 * random.random()\n\n        if score > min_score:\n            min_score = score\n            base_result = result.copy()\n            best_list_of_list = list_of_list\n\n            print(min_score)\n\n\n","99387d72":"sub = set(permutations_[120:])\n\nfor p in permutations_[120:]:\n    if (p in base_result[0]) or (p in base_result[1]) or (p in base_result[2]):\n        sub.remove(p)\n        \nbase_sub = set([ids[s] for s in sub])\nbase_list_of_lists = [[ids[r[7 * i: i * 7 + 7]] for i in range(120)] for r in base_result]","7635ffae":"def find_best_route(depth):\n    \n    sub = base_sub.copy()\n\n    list_of_lists = [deque(l) for l in base_list_of_lists]\n    list_of_distances = np.zeros(3)\n    \n    while sub:\n        min_total_dist = 100000\n        shortest = 0\n        min_new_dist = 7\n        min_next_closest_id = None\n        \n        last_words = [l[-1] for l in list_of_lists]\n        \n        for i, l in enumerate(list_of_lists):\n            \n            next_closest_id, dist = get_next_graph(l[-1], last_words, distance_dict_id, sub, d, depth)\n            \n            new_dist = list_of_distances[i] + dist * 2\n            \n            if new_dist < min_total_dist:\n                min_total_dist = new_dist\n                shortest = i\n                min_new_dist = dist\n                min_next_closest_id = next_closest_id\n                \n                if new_dist < min(list_of_distances):\n                    break\n                                \n        if min_next_closest_id:\n            if min_next_closest_id in sub:\n                sub.remove(min_next_closest_id)\n            shortest_list = list_of_lists[shortest]\n            shortest_list.append(min_next_closest_id)\n            list_of_distances[shortest] += d[shortest_list[-2], shortest_list[-1]]\n        \n    \n    list_of_lists = remove_end(list_of_lists)\n    \n#     k_opt(list_of_lists, 8)\n    \n    return list_of_lists, get_score_graph(list_of_lists)\n\ndef get_next_graph(last_word_id, last_words, distance_dict_id, sub_id, d, step = 0):\n    \n    dist = 1\n    distances = distance_dict_id[last_word_id]\n    next_closest_id = distances[dist][0]\n\n    if (next_closest_id in sub_id):\n          \n        if step > 0:\n            \n#             for last_word in last_words:\n#                 if last_word != last_word_id:\n#                     dist -= 0.1 * d[next_closest_id, last_word]\n                \n            dist += get_next_graph(next_closest_id, last_words, distance_dict_id, sub_id, d, step - 1)[1]\n\n        return next_closest_id, dist\n    \n    candidates = []\n    l_ = lambda p: p in sub_id\n    \n    while (dist < 7) and (not candidates):\n        candidates.clear()\n        dist += 1\n        capp = candidates.append\n        for c in filter(l_, distances[dist]):\n            capp(c)\n        \n    if candidates and step > 0:\n        next_closest_id = None\n        min_dist = 8 * step\n        \n        for c in candidates:\n            \n            new_dist = dist + get_next_graph(c, last_words, distance_dict_id, sub_id, d, step - 1)[1] + 0.01 * random.random()\n            \n            min_d = 100\n            \n            for last_word in last_words:\n                if last_word != last_word_id:\n                    min_d = min(min_d, d[last_word, c])\n\n            new_dist -= 0.5 * min_d\n\n            if new_dist < min_dist:\n                next_closest_id = c\n                min_dist = new_dist\n                \n        dist = min_dist\n            \n    elif candidates:\n        \n        next_closest_id = None\n        min_dist = 8\n        \n        for c in candidates:\n            \n            new_dist = dist + 0.01 * random.random()\n            \n            min_d = 100\n            \n            for last_word in last_words:\n                if last_word != last_word_id:\n                    min_d = min(min_d, d[last_word, c])\n\n            new_dist -= 0.5 * min_d\n            \n            if new_dist < min_dist:\n                next_closest_id = c\n                min_dist = new_dist\n                \n        dist = min_dist\n            \n    return next_closest_id, dist\n\ndef remove_end(best_list_of_lists):\n    current_score = get_score_graph(best_list_of_lists)\n    new_score = current_score\n\n    current_score += 1\n\n    while current_score > new_score:\n        current_score = new_score\n\n        for j in range(3):\n            l = list(best_list_of_lists[j])\n            last_word = l[-1]\n            \n            if last_word in l[:-1]:\n                best_list_of_lists[j].pop()\n            else:\n                for l_ in [l_ for k, l_ in enumerate(best_list_of_lists) if k != j]:\n                    if last_word in l_:\n                        best_list_of_lists[j].pop()\n                        break\n                        \n            \n        new_score = get_score_graph(best_list_of_lists)\n    return best_list_of_lists\n         \ndef k_opt(best_list_of_lists, length_):\n\n    for l in best_list_of_lists:\n\n        for i in range(120, len(l)- length_):\n            lst = [i + j for j in range(length_)]\n            old_total = d[l[i - 1], l[i]]\n            for i_ in lst:\n                old_total += d[l[i_], l[i_ + 1]]\n\n            start_pos = l[i - 1]\n            end_pos = l[i + length_]\n\n            if old_total < 2 * length_:\n                continue\n\n\n            for p in itertools.permutations(lst):\n\n                pos = start_pos\n                new_total = 0.0\n\n                for p_ in p:\n                    new_pos = l[p_]\n                    new_total += d[pos, new_pos]\n                    if new_total > old_total:\n                        break\n                    pos = new_pos\n                new_total += d[pos, end_pos]    \n                if new_total < old_total:\n\n                    l_slice = list(l)[i:i+length_].copy()\n\n                    for j, p_ in enumerate(p):\n                        l[i + j ] = l_slice[p_ - i]","dc08896a":"best_list_of_lists = None\n\nfor k in tqdm.trange(10_000):\n\n    r = find_best_route(2)\n    \n    r_ = r\n    list_of_lists = r_[0]\n    score = r_[1]\n\n    if best_list_of_lists:\n        new_result_len = score\n        if new_result_len < shortest_result_len:\n            shortest_result_len = new_result_len\n            best_list_of_lists = [l.copy() for l in list_of_lists]\n            print(shortest_result_len)\n    else:\n        shortest_result_len = score\n        best_list_of_lists = [l.copy() for l in list_of_lists]\n        print(shortest_result_len)","0915bb56":"get_score_graph(best_list_of_lists)","169c4d9a":"import matplotlib.pyplot as plt\n\ndistance_distributions = []\n\nfor l in best_list_of_lists:\n    dist = list()\n    for i in range(len(l) - 1):\n        dist.append(d[l[i], l[i + 1]])\n    distance_distributions.append(dist)\n    print(sum(dist))\n    plt.plot(list(dist)[120:])\n    plt.show()\n    print(dist[-10:])","aa1a6521":"pd.DataFrame(distance_distributions).T.groupby(1).count()","aed6b2e3":"max_index = 0\nmax_value = 0\n\nfor j, l in enumerate(best_list_of_lists):\n    total = 0\n    for i in range(1, len(l)):\n        total += d[l[i - 1], l[i]]\n        \n    if total > max_value:\n        max_value = total\n        max_index = j\n        \n    print(total)","1d24f6f2":"l = list(best_list_of_lists[2])[120:]\ncount = 0\n\nfor j in range(len(l) - 1):\n    word1 = permutations_[l[j]]\n    word2 = permutations_[l[j + 1]]\n    for i in range(1,7):\n        new_perm = word1[i:] + word2[:i] \n        if new_perm in ids:\n            count += 1\n            \nprint(count)","2ecfcaa8":"# loop_size = 1_000_000\n\n\n# randi1 = [np.random.randint(120, len(city_list_of_list[i]) - 2, size = loop_size) for i in range(3)]\n# randi2 = [np.random.randint(120, len(city_list_of_list[i]) - 2, size = loop_size) for i in range(3)]\n# randm1 = np.random.randint(0, 2, size = loop_size)\n# randm2 = np.random.randint(0, 2, size = loop_size)\n\n# d_ = [get_distance(l) for l in city_list_of_list]\n\n# print(d_)\n\n# for k in tqdm.trange(loop_size):\n# #         total = 0\n\n#     for m2, l2 in enumerate(city_list_of_list):\n#         m1 = d_.index(max(d_))\n# #         m2 = l2\n\n#         i1 = randi1[m1][k] #randint(120, len(l) - 2)\n#         i2 = randi2[m2][k] #randint(120, len(l) - 2)\n\n#         if (abs(i1 - i2) < 2):\n#             continue\n\n#         l1 = city_list_of_list[m1]\n#         li1m1 = l1[i1 - 1]\n#         li1 = l1[i1]\n#         li1p1 = l1[i1 + 1]\n\n# #         l2 = city_list_of_list[m2]\n#         li2m1 = l2[i2 - 1]\n#         li2 = l2[i2]\n#         li2p1 = l2[i2 + 1]\n\n#         l1_diff = d[li1m1, li2] + d[li2, li1p1] - d[li1m1, li1] - d[li1, li1p1 ] \n#         l2_diff = d[li2m1, li1] + d[li1, li2p1] - d[li2m1, li2] - d[li2, li2p1]\n\n#         if l1_diff + l2_diff < 0:\n#             l1[i1], l2[i2] = li2, li1\n#             break\n\n# get_score_graph(city_list_of_list)","5db38281":"current_score = get_score_graph(best_list_of_lists)\nnew_score = current_score\n\ncurrent_score += 1\n\nwhile current_score > new_score:\n    current_score = new_score\n\n    for j in range(3):\n        l = list(best_list_of_lists[j])\n        last_word = l[-1]\n        last_word_dist = d[l[-2], l[-1]]\n        \n        for i in range(120, len(l) - 1):\n            old_dist = d[l[i - 1], l[i]] + last_word_dist\n            new_dist = d[l[i - 1], last_word] + d[last_word, l[i]]\n            \n            if new_dist < old_dist:\n                print('insert')\n                best_list_of_lists[j] = l[:-1]\n                l.insert(i, last_word)\n                break\n        \n    new_score = get_score_graph(best_list_of_lists)","1f220241":"get_score_graph(best_list_of_lists)","f029e1eb":"string_result = []\n\nfor l in best_list_of_lists:\n    local_result = permutations_[l[0]]\n    \n    for i in list(l)[1:]:\n        local_result += permutations_[i][-d[ids[local_result[-7:]], ids[permutations_[i]]]:]\n    string_result.append(local_result)\n\nshortest_result = string_result\n\nfor r in shortest_result:\n    print(len(r))","f73b304e":"for p in permutations.values:\n    word = p[0]\n    found = False\n    for r in shortest_result:\n        if word in r:\n            found = True\n    \n    if not found:\n        print(\"failure \" + word)\n        break","6ca536e1":"# wildcard_char = '\ud83c\udf1f'\n\n# max_r = sorted(shortest_result, key = len)[-1]\n# max_index = shortest_result.index(max_r)\n# print(len(max_r), max_index)\n\n# last_word = max_r[-7:]\n# last_word_index = len(max_r) - 7\n\n# for i, r in enumerate(shortest_result):\n#     if last_word[:-1] in r and i != max_index:\n#         replace_index = r.index(last_word[:-1]) + 6\n#         shortest_result[i] = shortest_result[i][:replace_index] + wildcard_char + shortest_result[i][replace_index + 1]\n        \n#         l = best_list_of_lists[max_index]\n        \n#         shortest_result[max_index] = shortest_result[max_index][:-d[l[-2], l[-1]]]\n#         break\n    \n","b8c741c6":"result_df = pd.DataFrame(shortest_result, columns = [\"schedule\"])","dade2b4e":"result_df.to_csv(\"submission.csv\", index=False)","5cc0246f":"# Score function\nCalculation of distance for the score, i.e. distance of each route in the list and taking maximum of those.","1044654d":"# Distance Distribution Visualization","b94f67ce":"****","9361ce94":"# First part 120 (or more)\n\nWe first build the three basic routes that cover the first 120 permutations, but we want them to actually cover as many permutations as possible. For this we first make a set of all nodes\/permutations.","c1e78f6b":"# Distance Formatting\nWe format the distance matrix as a map that maps each permutations to a map of distances, for each distance a list of all the permutations with that distance. We also prepare maps that connect id and permutation string. We will use the id further as nodes for our graph.","358642fe":"# Imports","fc4498ee":"# Loading Data","d49d0f15":"# **Introduction**\n\nWelcome to this notebook. The idea of this jumble of code is to explore how to approach this problem without too much technical knowledge. Over the previous year I learned a lot about graph theory and reinforcement learning, so I am using this competition to test some concepts.\n\nAs a start the issue at hand can be phrased as a graph problem. Chaining the different permutations of the symbols is equivalent of following a route through this graph, the nodes or vertices being the permutations. What is interesting is that this graph is fully connected (you can go directly from each node a to node b), the graph is weighted and directed (the distance from node a to node b is not the same as the distance from node b to node a). This is reflected in the form of the distance matrix, also known as adjacency matrix, which is dense, (almost) no zeros and asymmetric.\n\nOn this graph, you have three agents that try to cover all of it as efficiently as possible, with a subset of the nodes that need to be covered by all of them first. This splits the problem in two parts:\n\n1. Go through the first 120 nodes (permutations with fixed first two entries, 120 = (7 - 2)! = 5!). This is a path with a fixed length (120 * 7 = 840) and if I am correct it is not possible to shorten it. However, what is possible is to choose paths that go through more than 120 nodes. Think of this as in 2d three nodes being on a straight line connecting them, if you from node one to three you have to go through two. This allows to cover more nodes that 120 in the first part of the route. Also, the three agents do not need to take the same route\/order for these first 120 nodes. In fact, you want them to be as different as possible to cover more nodes. This can be realized for example by the first agent going through the nodes in order, the second agent in reverse order and the third agent going first through the even and then the odd nodes. (The nodes always have some id on which you can sort them). We optimize this by randomly permutating two elements of a random list to cover more nodes with the starting three routes.\n\n2. After having found the first part of the three routes, we greedily add the remaining nodes to the three routes. This means that we try to find for each route the next node with the shortest distance to the last node of each route and then add the node which will lead to the minimum increase in max length of all routes. As the selection of the next node is not necessarily unique, we break ties by choosing randomly from the eligible candidates."}}