{"cell_type":{"cf389a89":"code","c9eab49b":"code","c618c9a3":"code","366795ee":"code","86e646b9":"code","8eaf0578":"code","10fe8f7b":"code","066b36e7":"code","78516750":"code","f991f169":"code","ae90fb74":"code","c2153e0e":"code","77e6e139":"code","d52fe457":"code","2272f1e2":"code","ab6e9236":"code","98aca6a0":"code","74d85bbc":"code","a34f158d":"code","dcf7c419":"code","792cd4fc":"markdown","1fecf02a":"markdown","e2aa97c9":"markdown","c1f0947a":"markdown","f550779a":"markdown","c1dce33d":"markdown","29c51b82":"markdown","d398efc9":"markdown","44712f16":"markdown","a08b2fb9":"markdown"},"source":{"cf389a89":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c9eab49b":"df_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsample_submission = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","c618c9a3":"df_test = pd.concat([df_test, sample_submission.drop(['Id'], axis='columns')], axis=1)\ndf_test['SalePrice'] = df_test['SalePrice'].astype(int)\ndf = pd.concat([df_train, df_test], axis=0)\ndf","366795ee":"fig , ax = plt.subplots(figsize = (14,10))\nsns.heatmap(df.isnull() , cbar = False, cmap = \"YlGnBu_r\")","86e646b9":"df.columns","8eaf0578":"f, ax = plt.subplots(figsize=(8,6))\nfig = sns.boxplot(x='OverallQual' , y='SalePrice', data=df)","10fe8f7b":"f, ax = plt.subplots(figsize=(16,8))\nfig = sns.boxplot(x='YearBuilt' , y='SalePrice', data=df)\n","066b36e7":"f, ax = plt.subplots(figsize=(16,16))\nsns.heatmap(df.corr(), vmax=.8, square=True, fmt=\".2f\")","78516750":"sns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df[cols], size = 2.5)\nplt.show()","f991f169":"#missing data\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","ae90fb74":"#dealing with missing data\ndf = df.drop((missing_data[missing_data['Total'] > 1]).index,1)\ndf = df.drop(df.loc[df['Electrical'].isnull()].index)\ndf = df.dropna()\ndf.shape","c2153e0e":"from sklearn import preprocessing\n#encoding of object type columns in int\ndef number_encode_features(init_df):\n    result = init_df.copy() \n    encoders = {}\n    for column in result.columns:\n        if result.dtypes[column] == np.object:\n            encoders[column] = preprocessing.LabelEncoder()\n            result[column] = encoders[column].fit_transform(result[column])\n    return result, encoders\nencoded_data, encoders = number_encode_features(df) \nencoded_data.head() ","77e6e139":"from sklearn.model_selection import train_test_split\n\nX = encoded_data.iloc[: , encoded_data.columns!='SalePrice']\ny =  encoded_data['SalePrice']\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size= 0.3, random_state=42)","d52fe457":"from sklearn import metrics\n\ndef print_evaluate(true, predicted):  \n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)","2272f1e2":"from sklearn.ensemble import GradientBoostingRegressor\n\nreg = GradientBoostingRegressor(random_state=42,\n                                n_estimators = 1000,\n                                max_depth = 5,\n                                min_samples_leaf = 6,\n                                min_samples_split = 10)\n                                \nreg.fit(X_train, y_train)\npred_reg = reg.predict(X_test)","ab6e9236":"y_test = y_test.reset_index(drop=True)\nplt.figure(figsize=(14,7))\nplt.plot(y_test,label ='Test')\nplt.plot(pred_reg, label = 'predict')\nplt.show()\n\nprint_evaluate(pred_reg, y_test)\nreg.score(X_train, y_train)","98aca6a0":"from xgboost import XGBRegressor\nfrom sklearn.preprocessing import LabelEncoder\n\n\nxgb = XGBRegressor(learning_rate=0.01,\n                       n_estimators=1000,\n                       max_depth=4,\n                       min_child_weight=0,\n                       gamma=0.6,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:linear',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=42)\n\n\n# Add silent=True to avoid printing out updates with each cycle\nxgb.fit(X_train, y_train, verbose=False)\npred_xgb = xgb.predict(X_test)","74d85bbc":"plt.figure(figsize=(14,7))\nplt.plot(y_test,label ='Test')\nplt.plot(pred_xgb, label = 'predict')\nplt.show()\n\nprint_evaluate(pred_xgb, y_test)\nxgb.score(X_train, y_train)","a34f158d":"from catboost import CatBoostRegressor\n\ncat_model = CatBoostRegressor(iterations = 1000,\n                              random_state = 42)\ncat_model.fit(X_train,y_train, verbose=False)\ncat_pred = cat_model.predict(X_test)","dcf7c419":"plt.figure(figsize=(14,7))\nplt.plot(y_test,label ='Test')\nplt.plot(cat_pred, label = 'predict')\nplt.show()\n\nprint_evaluate(cat_pred, y_test)\ncat_model.score(X_train, y_train)","792cd4fc":"### For the convenience of combining data into one dataset","1fecf02a":"## For further training, we need to remove the features with missing data.","e2aa97c9":"# 2. XGBRegressor","c1f0947a":"The price depends on the overall quality","f550779a":"### Based on quality metrics (MAE, MSE, RMSE, R2 Square) we can conclude that the CatBoostRegressor algorithm was the best. ","c1dce33d":"There is no strong correlation between the price and the age of the house","29c51b82":"# 3. CatBoostRegressor","d398efc9":"# 1. GradientBoostingRegressor","44712f16":"## Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.","a08b2fb9":"#  Visualization "}}