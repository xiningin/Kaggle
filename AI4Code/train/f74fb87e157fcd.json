{"cell_type":{"05cec858":"code","936f00e8":"code","f4a9f943":"code","a4abbfcb":"code","aab9d21f":"code","e67f24a7":"code","94f7fc0e":"code","2b435a43":"code","50fa39f8":"code","f966d3bc":"code","6f654ab1":"code","3e8dd371":"code","00c9df4d":"code","8cd2fbf8":"code","43fc4249":"code","70a0cfa1":"code","e47ce33e":"code","9ea27a18":"code","278a10b3":"code","291a462a":"code","6b6cc231":"code","89f97f4d":"code","3d29c5fa":"code","65687bc6":"code","9a91f87f":"code","cc39b677":"code","5d132c0a":"code","c6de160f":"code","a1c78236":"code","588bd563":"code","34d8a596":"code","cac02775":"code","9a516ac2":"code","606cb6c9":"markdown","70ce4bbc":"markdown","85ca57f2":"markdown","5a94fe68":"markdown","80182287":"markdown","3ac8cc2f":"markdown","18227143":"markdown"},"source":{"05cec858":"import os\nprint(os.listdir(\"..\/input\"))","936f00e8":"# Loading library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline ","f4a9f943":"human_data = pd.read_table('..\/input\/human_data.txt')\nhuman_data.head()","a4abbfcb":"chimp_data = pd.read_table('..\/input\/chimp_data.txt')\nchimp_data.head()\n","aab9d21f":"dog_data= pd.read_table('..\/input\/dog_data.txt')\ndog_data.head()","e67f24a7":"# function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\ndef getKmers(sequence, size=6):\n    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]","94f7fc0e":"human_data['words'] = human_data.apply(lambda x: getKmers(x['sequence']), axis=1)\nhuman_data = human_data.drop('sequence', axis=1)\nchimp_data['words'] = chimp_data.apply(lambda x: getKmers(x['sequence']), axis=1)\nchimp_data = chimp_data.drop('sequence', axis=1)\ndog_data['words'] = dog_data.apply(lambda x: getKmers(x['sequence']), axis=1)\ndog_data = dog_data.drop('sequence', axis=1)","2b435a43":"human_texts = list(human_data['words'])\nfor item in range(len(human_texts)):\n    human_texts[item] = ' '.join(human_texts[item])\ny_human_data = human_data.iloc[:, 0].values                         ","50fa39f8":"chimp_texts = list(chimp_data['words'])\nfor item in range(len(chimp_texts)):\n    chimp_texts[item] = ' '.join(chimp_texts[item])\ny_chimp_data = chimp_data.iloc[:, 0].values   ","f966d3bc":"dog_texts = list(dog_data['words'])\nfor item in range(len(dog_texts)):\n    dog_texts[item] = ' '.join(dog_texts[item])\ny_dog_data = dog_data.iloc[:, 0].values ","6f654ab1":"print(human_texts[2])","3e8dd371":"print(chimp_texts[2])","00c9df4d":"print(dog_texts[2])","8cd2fbf8":"y_human_data","43fc4249":"y_chimp_data","70a0cfa1":"y_dog_data","e47ce33e":"# The n-gram size of 4 was previously determined by testing\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(ngram_range=(4,4))\n#X = cv.fit_transform(human_texts)\nX_human=cv.fit_transform(human_texts)\nX_chimp = cv.fit_transform(chimp_texts)\nX_dog = cv.fit_transform(dog_texts)","9ea27a18":"print(X_human.shape)\nprint(X_chimp.shape)\nprint(X_dog.shape)","278a10b3":"human_data['class'].value_counts().sort_index().plot.bar();","291a462a":"chimp_data['class'].value_counts().sort_index().plot.bar();","6b6cc231":"dog_data['class'].value_counts().sort_index().plot.bar();","89f97f4d":"# Splitting the human dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_human_train, X_human_test, y_human_train, y_human_test = train_test_split(X_human, \n                                                    y_human_data, \n                                                    test_size = 0.20, \n                                                    random_state=42)","3d29c5fa":"# Splitting the chimp dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_chimp_train, X_chimp_test, y_chimp_train, y_chimp_test = train_test_split(X_chimp, \n                                                    y_chimp_data, \n                                                    test_size = 0.20, \n                                                    random_state=42)","65687bc6":"# Splitting the dog dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_dog_train, X_dog_test, y_dog_train, y_dog_test = train_test_split(X_dog, \n                                                    y_dog_data, \n                                                    test_size = 0.20, \n                                                    random_state=42)","9a91f87f":"print(X_human_train.shape)\nprint(X_human_test.shape)","cc39b677":"print(X_chimp_train.shape)\nprint(X_chimp_test.shape)","5d132c0a":"print(X_dog_train.shape)\nprint(X_dog_test.shape)","c6de160f":"### Multinomial Naive Bayes Classifier ###\n# The alpha parameter was determined by grid search previously\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier1 = MultinomialNB(alpha=0.1)\nclassifier1.fit(X_human_train, y_human_train)\nclassifier2 = MultinomialNB(alpha=0.1)\nclassifier2.fit(X_chimp_train, y_chimp_train)\nclassifier3 = MultinomialNB(alpha=0.1)\nclassifier3.fit(X_dog_train, y_dog_train)\n","a1c78236":"y_human_pred = classifier1.predict(X_human_test)\ny_chimp_pred = classifier2.predict(X_chimp_test)\ny_dog_pred = classifier3.predict(X_dog_test)","588bd563":"from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\ndef get_metrics(y_test, y_predicted):\n    accuracy = accuracy_score(y_test, y_predicted)\n    precision = precision_score(y_test, y_predicted, average='weighted')\n    recall = recall_score(y_test, y_predicted, average='weighted')\n    f1 = f1_score(y_test, y_predicted, average='weighted')\n    return accuracy, precision, recall, f1","34d8a596":"print(\"Confusion matrix\\n\")\nprint(pd.crosstab(pd.Series(y_human_test, name='Actual'), pd.Series(y_human_pred, name='Predicted')))\naccuracy, precision, recall, f1 = get_metrics(y_human_test, y_human_pred)\nprint(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))","cac02775":"print(\"Confusion matrix\\n\")\nprint(pd.crosstab(pd.Series(y_chimp_test, name='Actual'), pd.Series(y_chimp_pred, name='Predicted')))\naccuracy, precision, recall, f1 = get_metrics(y_chimp_test, y_chimp_pred)\nprint(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))","9a516ac2":"print(\"Confusion matrix\\n\")\nprint(pd.crosstab(pd.Series(y_dog_test, name='Actual'), pd.Series(y_dog_pred, name='Predicted')))\naccuracy, precision, recall, f1 = get_metrics(y_dog_test, y_dog_pred)\nprint(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))","606cb6c9":"## If we have a look at class balance we can see we have relatively balanced dataset.","70ce4bbc":"Let's define a function to collect all possible overlapping k-mers of a specified length from any sequence string. We will basically apply the k-mers to the complete sequences.","85ca57f2":"Since we are going to use scikit-learn natural language processing tools to do the k-mer counting, we need to now convert the lists of k-mers for each gene into string sentences of words that the count vectorizer can use.  We can also make a y variable to hold the class labels.  Let's do that now.","5a94fe68":"## Now we will apply the BAG of WORDS using CountVectorizer using NLP","80182287":"In this notebook, I will apply a classification model that can predict a gene's function based on the DNA sequence of the coding sequence alone.","3ac8cc2f":"## A multinomial naive Bayes classifier will be created.  I previously did some parameter tuning and found the ngram size of 4 (reflected in the Countvectorizer() instance) and a model alpha of 0.1 did the best.","18227143":"Now we can convert our training data sequences into short overlapping k-mers of legth 6. Lets do that for each species of data we have using our getKmers function.\u00b6"}}