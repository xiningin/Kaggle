{"cell_type":{"f3ce72c8":"code","5b250bbd":"code","72c3a5fe":"code","45104db6":"code","bb6bf7b1":"code","113253e9":"code","d1773eb0":"code","8bf29ed2":"code","2e70408a":"code","25c7ed0d":"code","02a9d93a":"code","79f80bd7":"code","da53df4e":"code","02d5cff1":"code","fd34c96b":"code","f5c19679":"code","987b6ebf":"code","dacab7e3":"code","34ca5176":"code","562f43f1":"code","ad9302f9":"code","6b7d95f5":"code","520b71ec":"code","9d4ed786":"code","1e6d4c0a":"markdown","b68e96e9":"markdown","8bfd9dc8":"markdown","1c77969e":"markdown","a6624f33":"markdown","6e31633c":"markdown","5ecf873a":"markdown","1ee89d27":"markdown","acaa9255":"markdown","2782937f":"markdown","e9dae341":"markdown","64deb90a":"markdown","069f84fe":"markdown","27bfcf83":"markdown","e3fc7e0b":"markdown","939c92a2":"markdown","46e577b7":"markdown","a1988733":"markdown","7450b957":"markdown","16fd02b8":"markdown","bd06dd60":"markdown"},"source":{"f3ce72c8":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nplt.rcParams['figure.figsize'] = [15, 6]\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler","5b250bbd":"dt = pd.read_csv(\"..\/input\/heart-disease\/heart.csv\")\ndata = dt.copy()","72c3a5fe":"data.head()","45104db6":"data.dtypes","bb6bf7b1":"data.isnull().sum(axis = 0)","113253e9":"data.target.value_counts()","d1773eb0":"for col in data.columns:\n    print(col,\" : \", data[col].unique().size)","8bf29ed2":"df = data\nfor col in data.columns:\n    if df[col].unique().size < 6:                # 5 is the maximum for 'value_couts' categorical features \n        df = df.drop(columns = [col])\nsns.boxplot(data = df, orient = 'h')","2e70408a":"positive =data[data['target'] == 1]\nnegative =data[data['target'] == 0]","25c7ed0d":"def set_kde(col):\n    if data[col].unique().size < 7:\n        return False\n    else : return True\n    \n    \nfor col in data.columns :\n    plt.figure()\n    sns.distplot(positive[col], label = 'positive', kde = set_kde(col))\n    sns.distplot(negative[col], label = 'negative', kde = set_kde(col))\n    plt.legend()\n","02a9d93a":"sns.clustermap(data.corr())","79f80bd7":"a = pd.get_dummies(data['cp'], prefix = \"cp\")\nb = pd.get_dummies(data['thal'], prefix = \"thal\")\nc = pd.get_dummies(data['slope'], prefix = \"slope\")\n\nframes = [data, a, b, c]\ndata = pd.concat(frames, axis = 1)\n\ndata = data.drop(columns = ['cp', 'thal', 'slope'])","da53df4e":"data.head()","02d5cff1":"y = data['target']\nX = data.drop(columns = ['target'])\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)","fd34c96b":"def prepare_data(dt):\n    y = dt['target']\n    X = dt.drop(columns = ['target'])\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n\n    scaler = MinMaxScaler()\n    scaler.fit(X_train, X_test)\n    X_train_scaled = scaler.transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    return X_train_scaled, X_test_scaled\n\nX_train_scaled, X_test_scaled = prepare_data(dt)","f5c19679":"from sklearn.ensemble import RandomForestClassifier\nRF = RandomForestClassifier(random_state = 0)","987b6ebf":"from sklearn.neighbors import KNeighborsClassifier\nKNN = KNeighborsClassifier()\n\ngrid_params = {\n    'n_neighbors' : range(2,20),\n    'weights' : ['uniform', 'distance'],\n    'metric' : ['euclidian', 'manhattan']\n}\n\nGKNN = GridSearchCV(\n    KNN,\n    grid_params,\n    cv = 4\n)","dacab7e3":"from sklearn.svm import SVC\nSVM = SVC(random_state = 1)","34ca5176":"from sklearn.naive_bayes import GaussianNB\nNB = GaussianNB()","562f43f1":"def evaluation(X_train_scaled, X_test_scaled, msg = ''):\n    models = {'RandomForest' : RF,\n          'KNearestNeighbors': GKNN,\n          'Support Vector' : SVM,\n          'Naive Bayes' : NB}\n\n    dfmd = pd.DataFrame(list(models.items()),columns = ['models','params'])\n    labels = models.keys()\n\n    scores = []\n    for mdl in models.values(): \n        mdl.fit(X_train_scaled, y_train)\n        scores.append(100 * mdl.score(X_test_scaled, y_test))\n    dfmd['scores'] = scores\n    #print(np.mean(scores))\n    #if msg != '': print(msg)\n    splot = plt.figure()\n    splot = sns.barplot(data = dfmd, y = 'scores', x = 'models')\n    for p in splot.patches:\n        splot.annotate(format(p.get_height(), '.1f'), \n                       (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                       ha = 'center', va = 'center', \n                       xytext = (0, 9), \n                       textcoords = 'offset points')\n    plt.legend(msg)\n    plt.show()\n    return scores\n    \n\nevaluation(X_train_scaled, X_test_scaled)","ad9302f9":"balanced_sus = ['trestbps', 'fbs']\nbalanced_sus1 = ['fbs']\nbalanced_sus2 = ['trestbps']\nimbalanced_sus = ['sex']\nall_sus = balanced_sus + imbalanced_sus\ntest_features = [balanced_sus, balanced_sus1, balanced_sus2, imbalanced_sus, all_sus]\ntest_scores = []\nfor fts in test_features:\n    test_data = data.copy()\n    test_data.drop(columns = fts, inplace = True)\n    for col in fts :\n        X_train_scaled_h, X_test_scaled_h = prepare_data(test_data)\n    #print('\\nUsing', fts)\n    test_scores.append(np.mean(evaluation(X_train_scaled_h, X_test_scaled_h, msg = fts)))\ntest_scores_a = np.array(test_scores)\nprint(\"scores were : \", test_scores_a, \"\\n \\n\")\nprint(\"the higher score was for \", np.max(test_scores), \" by eliminating \", \n      test_features[np.argmax(test_scores_a)][0])\n\n# Then we set the optimal data \ndata = dt.drop(columns = [test_features[np.argmax(test_scores_a)][0]])","6b7d95f5":"from sklearn.metrics import recall_score","520b71ec":"def recall_evaluation():\n    models = {'RandomForest' : RF,\n          'KNearestNeighbors': GKNN,\n          'Support Vector' : SVM,\n          'Naive Bayes' : NB}\n    recalls = []\n    dfmd = pd.DataFrame(list(models.items()),columns = ['models','params'])\n    labels = models.keys()\n    scores = []\n    for mdl in models.values(): \n        mdl.fit(X_train_scaled, y_train)\n        y_pred = mdl.predict(X_test_scaled)\n        recalls.append(100 * recall_score(y_test, y_pred, average='binary'))\n    dfmd['recalls'] = recalls\n    print(recalls)\n    splot = sns.barplot(data = dfmd, y = 'recalls', x = 'models')\n    for p in splot.patches:\n        splot.annotate(format(p.get_height(), '.1f'), \n                       (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                       ha = 'center', va = 'center', \n                       xytext = (0, 9), \n                       textcoords = 'offset points')\n    plt.show()\n    \nrecall_evaluation()","9d4ed786":"print(\"On default scoring\")\nprint('  Train score  : ', SVM.score(X_train_scaled, y_train))\nprint('  Test score   : ', SVM.score(X_test_scaled, y_test))\nprint('\\n\\n')\n\n\nprint(\"On recall scoring\")\ny_pred = SVM.predict(X_test_scaled)\nprint('  Train score  :', 100 * recall_score(y_test, y_pred, average='binary'))\ny_pred = SVM.predict(X_train_scaled)\nprint('  Test score   :', 100 * recall_score(y_train, y_pred, average='binary'))\n","1e6d4c0a":"### features\/target relation\nThen we plot the distributions of features for the two target categories to check for the feature\/taregt relation","b68e96e9":"# Modelling","8bfd9dc8":"Let's start with separating data based on the target value using boolean masks","1c77969e":"## Choice of the adequate scoring\n\nSince we are dealing with a disease problem, it's more convenient to use the recall score to evaluate our models, because it wil be more safer for patient if we raise the percentage of cases correctly identified as positive out of total true positives \n\n#####  Recall = TruePositives \/ ( TruePositives + FalseNegatives )","a6624f33":"cp', 'thal' and 'slope' are categorical features, it's better to turn them into dummy variables.","6e31633c":"It looks like our features are not strongly correlated to each others, except for 'cp', 'thal' and 'slope' wich have a relatively higher correlation values ( also with the target )\n","5ecf873a":"The last chart make it obvious to choose Support Vector Machine  ","1ee89d27":"# Exploratory Data Analysis","acaa9255":"# Optimizing ML models to classify heart disease \n\nGiven clinical parameters about a patient, how well can we predict whether or not they have heart disease?","2782937f":"## Hypothesis testing \n\nWe'll run the evaluation function for all models, with the the next testing data : \n\n* Data without all those suspected columns \n* Data witout balnced suspected features\n* Data witout imbalnced suspected features\n\nThen we compare the average score of models","e9dae341":"### About overfitting : \n\nOverfitting is a scenario where your model performs well on training data but performs poorly on data not seen during training. This basically means that your model has memorized the training data instead of learning the relationships between features and labels.\n#### Let's check it on our model","64deb90a":"Fortunately there is no missing values in our data set","069f84fe":"## Initiating some sklearn models","27bfcf83":"# Import libraries","e3fc7e0b":"## Variablility & Dispertion","939c92a2":"## Hypothesis\n\nBased on my analysis, the columns containing the next variables do not seem to related to the target variable for the next reasons :\n\n#### Balanced features : 'trestbps' & 'fbs'\nTheir distribustions seem not te depend on the target classes\n* trestbps :  Same mean and shape for 'sick' and 'not_sick' distributions ( continious distribusion ) \n* fbs : High similarity for 'sick' and 'not_sick' distributions ( binary distribution ) \n\n#### Imbalanced features :\n* sex : We do not have equally balanced gender classes ( 68 % men, 32% women ).\n\nWe'll test later eliminating those features later and check if this could affect the precisions of our models positively or negatively.","46e577b7":"* The train score is not too close to 100%\n* The difference between the test (default) score and the train score is less than 5%\n* The difference between the test recall score and the train score is less than 1%\n \n\n### We can then confirm that our model had a good enough leaning and did not fall into the trap of particular cases, so it is able to generalize the data set especially when using recall scoring","a1988733":"### features\/target relation\nNext the seaborn heatmap applied to correlation matrix of data make it easeier to check if there is some strong correlations between our features","7450b957":"Data contains; <br>\n\n* age - age in years <br>\n* sex - (1 = male; 0 = female) <br>\n* cp - chest pain type <br>\n* trestbps - resting blood pressure (in mm Hg on admission to the hospital) <br>\n* chol - serum cholestoral in mg\/dl <br>\n* fbs - (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false) <br>\n* restecg - resting electrocardiographic results <br>\n* thalach - maximum heart rate achieved <br>\n* exang - exercise induced angina (1 = yes; 0 = no) <br>\n* oldpeak - ST depression induced by exercise relative to rest <br>\n* slope - the slope of the peak exercise ST segment <br>\n* ca - number of major vessels (0-3) colored by flourosopy <br>\n* thal - 3 = normal; 6 = fixed defect; 7 = reversable defect <br>\n* target - have disease or not (1=yes, 0=no)","16fd02b8":"## Relations between variables","bd06dd60":"## Initial evaluation"}}