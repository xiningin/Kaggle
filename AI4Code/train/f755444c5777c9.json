{"cell_type":{"9f8303d5":"code","e1de71cd":"code","74dc9a56":"code","e2dcb85a":"code","f39fc86e":"code","e8f7da64":"code","893ea581":"code","43756402":"code","b669f359":"code","770daf08":"code","172b3508":"code","21a455fe":"code","37b2305a":"markdown","c7d95ca3":"markdown","741e919c":"markdown","a7c48a68":"markdown","648ea677":"markdown","e8548c70":"markdown","3cd5c67b":"markdown","fbf4632b":"markdown","76be6fb7":"markdown"},"source":{"9f8303d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.cluster import KMeans # KMeans algorithm for data clustering\n\n# And all of this is needed for plotting the maps at the end\nimport matplotlib.pyplot as plt\nfrom geopy.geocoders import Nominatim\nimport folium\nfrom folium.plugins import MarkerCluster\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e1de71cd":"# Read the CSV containing the cities data\ndata = pd.read_csv(\"\/kaggle\/input\/climate-change-earth-surface-temperature-data\/GlobalLandTemperaturesByCity.csv\")\ndata.head()","74dc9a56":"# Convert the date column to pandas datetime\ndata.dt = pd.to_datetime(data.dt)\n\n# Keep only the data chunk after 1980\nnewer_climate_data = data[pd.DatetimeIndex(data['dt']).year >= 1980].copy()\nnewer_climate_data","e2dcb85a":"# I will also remove the missing value rows, to make everything easier\nnewer_climate_data.dropna(inplace=True)\n\n# Add columns for year, month and day\nnewer_climate_data['Year'] = pd.DatetimeIndex(newer_climate_data['dt']).year\nnewer_climate_data['Month'] = pd.DatetimeIndex(newer_climate_data['dt']).month\nnewer_climate_data['Day'] = pd.DatetimeIndex(newer_climate_data['dt']).day\nnewer_climate_data","f39fc86e":"# First issue\nprint(\"Notice that the day is always 1\")\nprint(newer_climate_data[(newer_climate_data['City'] == 'London') & (newer_climate_data['Month'] == 1)].Day.unique())\n\n# Second issue\nprint(\"\\nMultiple countries with the same city name\")\nprint(newer_climate_data[(newer_climate_data['City'] == 'Worcester')].Country.unique())\n\n# Third issue\nprint(\"\\nNotice that the data is the same in the output\")\nprint(newer_climate_data[(newer_climate_data['City'] == 'Baia Mare') & (newer_climate_data['Year'] == 2000)].head())\nprint(\"\\nAnd now Oradea\")\nprint(newer_climate_data[(newer_climate_data['City'] == 'Oradea') & (newer_climate_data['Year'] == 2000)].head())","e8f7da64":"# Now, it is time to compute the mean for each month by city\nkeep_columns = ['City', 'Country', 'Month', 'AverageTemperature']\nmean_data = newer_climate_data[keep_columns].groupby(['City', 'Country', 'Month']).mean().reset_index()\nmean_data.groupby(['City', 'Country']).head()","893ea581":"# I will create a separate dataframe with only the cities name, location and the temperature for each month\ncities_data = newer_climate_data[['City', 'Country', 'Latitude', 'Longitude']].copy()\ncities_data.drop_duplicates(inplace=True)\ncities_data.reset_index(drop=True, inplace=True)\n\n# Add the month columns\nmonths = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\nfor month in months:\n    cities_data[month] = np.nan\n\n# I do not know how to make this more efficient, suggestions are very welcomed\n# The idea is to fill each city in the dataframe column by column\nfor idx in cities_data.index:\n    # Get the data part of the current city\n    city_part = mean_data[(mean_data['City'] == cities_data.loc[idx, 'City']) & \n                          (mean_data['Country'] == cities_data.loc[idx, 'Country'])]\n    # Add the months temperatures\n    for m_index, month in enumerate(months):\n        cities_data.loc[idx, month] = city_part[city_part['Month'] == m_index + 1].AverageTemperature.mean()\n\n# Let's see how the dataframe looks (spoilers: not so bad)\ncities_data.head()","43756402":"# Let's not forget to remove the duplicate rows (issue 3 from above)\ncities_data_normalized = cities_data.drop_duplicates(subset=['Jan', 'Feb', 'Mar', 'Apr', 'May']).copy()\n\n# You can see that the temperatures during Jun-Aug are colder than during Dec-Feb\ncities_data_normalized[cities_data_normalized.Latitude.str.contains('S')]","b669f359":"# Get the cities in the southern hemisphere\nsouthern = cities_data_normalized[cities_data_normalized.Latitude.str.contains('S')]\n\n# Rotate by 6 months\nfor index in southern.index:\n    for idx, month in enumerate(months):\n        cities_data_normalized.loc[index, month] = cities_data.loc[index, months[(idx + 6) % 12]]\n\n# Now it looks normal (summer is hotter than the winter)\ncities_data_normalized[cities_data_normalized.Latitude.str.contains('S')]","770daf08":"# I will use KMeans to cluster the climate regions\n\n# Calculate distortion for a range of number of cluster\ndistortions = []\ndropped_columns = ['City', 'Country', 'Latitude', 'Longitude']\nfor i in range(1, 30):\n    km = KMeans(\n        n_clusters=i, init='random',\n        n_init=10, max_iter=300,\n        tol=1e-04, random_state=0\n    )\n    km.fit(cities_data_normalized.drop(dropped_columns, axis=1))\n    distortions.append(km.inertia_)\n\n# Plot the distortions\nplt.plot(range(1, 30), distortions, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.show()","172b3508":"# 13 seems like an ok number, also considering the number of climates in the K\u00f6ppen climate classification\n\nkm = KMeans(\n    n_clusters=13, init='random',\n    n_init=20, max_iter=500, \n    tol=1e-04, random_state=0,\n    algorithm='elkan'\n)\n\n# Add the cluster index to the table\npred = km.fit_predict(cities_data_normalized.drop(dropped_columns, axis=1))\ncities_data_normalized['pred'] = pred\ncities_data_normalized","21a455fe":"# Create a world map and place the points with different colors based on the cluster\n\nworld_map= folium.Map()\ngeolocator = Nominatim(user_agent=\"Temperatures\")\n\n# Give each cluster its color\ncity_color = [\n    \"red\",\n    \"orange\",\n    \"indigo\",\n    \"green\",\n    \"blue\",\n    \"yellow\",\n    \"violet\",\n    \"purple\",\n    \"pink\",\n    \"silver\",\n    \"gold\",\n    \"lightgreen\",\n    \"brown\",\n    \"black\",\n    \"gray\",\n]\n\n# Add each data row to the map as a point\nfor i in range(len(cities_data_normalized)):\n        lat = float(cities_data_normalized.iloc[i]['Latitude'][:-1])\n        long = float(cities_data_normalized.iloc[i]['Longitude'][:-1])\n        if cities_data_normalized.iloc[i]['Latitude'][-1] == 'S':\n            lat *= (-1)\n        if cities_data_normalized.iloc[i]['Longitude'][-1] == 'W':\n            long *= (-1)\n        radius = 30000\n        folium.Circle(location = [lat, long], \n                      popup=cities_data_normalized.iloc[i]['City'],\n                      radius=radius,\n                      color=city_color[cities_data_normalized.iloc[i]['pred']],\n                      fill=True, \n                      fill_color=city_color[cities_data_normalized.iloc[i]['pred']]\n                     ).add_to(world_map)\n\n# Display the map\nworld_map","37b2305a":"# Creating a map of the regions\n\nNow, the cities are plotted on a world map, with a different color for each climate region.","c7d95ca3":"# Conclusions\n\nThe result looks very similar to a classification map. Climate areas (eg: equatorial, mediterranean, temperate) and sub-areas (eg: more continental variants in central and eastern Europe) are clearly seen. Of course, there are some issues (like having the same climate in Sudan and central India), but that is due to the fact that the analysis does not include other factors.","741e919c":"# Introduction\n\nI am a beginner in the data science world, with some geographical knowledge. So, after learning about data clustering and about the existence of this dataset, my first thought was \"Could I use exclusively the temperature data in an attempt at finding climate areas?\". \n\nClimate classifications (eg: [K\u00f6ppen](https:\/\/en.wikipedia.org\/wiki\/K%C3%B6ppen_climate_classification)) also utilize other factors besides temperatures (such as rainfall, seasonal winds and metheorological events, humidity, etc), but using only this dataset, it is possible to find general climate areas. This is my attempt.","a7c48a68":"# Geographical observations and processing\n\nThe geographic problem with regions in the southern hemisphere is that their winter is during the May-August period.\n\nSo, to avoid having different climate regions with the same monthly temperatures, but different seasons, we will have\nto 'rotate' (basically shift the values to the right) the temperatures by six months.","648ea677":"# Clustering","e8548c70":"Now, some of the issues of this dataset regarding what I intend to do are:\n* There is a single measurement per month per year for each city;\n* There are cities with the same name but different countries;\n* There are multiple cities with exactly the same data, but only the city name differs (eg: 'Baia Mare' and 'Oradea').\n\nThe first point is not that important in this case, but it may affect others.\nA solution for the second point is always keeping the City-Country columns, not just the city name\nAnd, for the last point, the solution would be to remove the rows with duplicates in this sense (because in the end all I want is a simple map with points).","3cd5c67b":"# Reading and initial data processing","fbf4632b":"The main idea would be to have the monthly mean temperature for each city in the dataset, due to the fact that the monthly temperature average 'should' remain constant. It is enough to keep the rows with temperatures from dates beginning with 1980.","76be6fb7":"# Climate clustering based on temperatures\n"}}