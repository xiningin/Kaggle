{"cell_type":{"e82ff4a1":"code","a40537bd":"code","f0b61103":"code","b01e8379":"code","7f4f91bb":"code","5db8648b":"code","c723c91f":"code","327b235d":"code","3ebc7485":"code","f12112f6":"code","124ef373":"code","e2371cd6":"code","27fa2f5c":"code","c090b26a":"code","da276dbd":"code","ecb04fd0":"code","a8bd3ebf":"code","fb81dc04":"code","70186e43":"code","7ee06340":"code","381baafd":"code","7f9279c1":"code","35b4d1b7":"code","1e311e3f":"code","eafef0de":"code","e406bd1b":"code","9bdd1df4":"code","34c355c0":"code","4d0bc1ea":"code","ada549da":"code","e4d5a882":"code","415f809b":"code","08647dd4":"code","ead57a1c":"code","fd68dee8":"code","df3bb9f3":"code","c117d36a":"code","923bdd0b":"code","2bb3a8a0":"code","86784b47":"code","5dd91e7f":"code","637a74d6":"code","f932808a":"code","69016309":"code","90967282":"code","af45b25c":"code","4626134b":"code","a9d6bd65":"code","b71d686b":"code","4e79d67b":"code","98583e37":"code","cf34e302":"code","41ea14cd":"code","a344fe20":"code","e2021b25":"code","d10400c8":"code","cdd7067f":"code","7bd5f1f3":"code","2e4062cb":"code","4e409c6b":"code","27a1b4bc":"code","c5cbc919":"code","ecdd31f6":"code","59150dd5":"code","d8291c52":"code","177dbfdb":"code","8a2fd743":"code","9b123dc1":"code","e0094aa1":"code","c234e48a":"code","2b244aca":"code","ed595913":"code","d1a5e381":"code","4fb92698":"code","8c6ceeb9":"code","4a2b709d":"code","32d3e0da":"code","68df2692":"code","bb933b8f":"code","d9753db7":"code","17c51c5e":"code","7bfdb879":"code","0bf1139e":"code","c98f5f13":"code","e7e98bd0":"markdown","2b8195f8":"markdown","52be9a01":"markdown","b1420a37":"markdown","e2457c55":"markdown","b9f8f368":"markdown","37e29f70":"markdown","db38e181":"markdown","b27de0a7":"markdown","df2fa541":"markdown","53b06376":"markdown","43dd32fd":"markdown","844c2190":"markdown","739c327d":"markdown","96eff701":"markdown","44d861f2":"markdown","59c3dcae":"markdown"},"source":{"e82ff4a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a40537bd":"housing = pd.read_csv('..\/input\/train.csv')","f0b61103":"housing.head()","b01e8379":"housing.info()","7f4f91bb":"housing.describe()","5db8648b":"%matplotlib inline\nimport matplotlib.pyplot as plt\nhousing.hist(bins=50, figsize=(20,15))\nplt.show()","c723c91f":"corr_matrix = housing.corr()\ncorr_matrix['SalePrice'].sort_values(ascending=False)","327b235d":"from pandas.plotting import scatter_matrix\nattributes = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF']\nscatter_matrix(housing[attributes], figsize=(12, 12))","3ebc7485":"quantitative = [f for f in housing.columns if housing.dtypes[f] != 'object']\nquantitative.remove('SalePrice')\nquantitative.remove('Id')\nqualitative = [f for f in housing.columns if housing.dtypes[f] == 'object']","f12112f6":"# check which columns has missing values\nmissing_columns = [column for column in quantitative if housing[column].isna().sum() > 0]\nmissing_columns","124ef373":"housing[missing_columns].hist()","e2371cd6":"X = housing[quantitative].values\nX","27fa2f5c":"np.argwhere(np.isnan(X))[:10]","c090b26a":"from sklearn.preprocessing import Imputer\n\nimputer = Imputer()\n\nimputer.fit(X)\n\nimputer_X = imputer.transform(X)\n\nnp.argwhere(np.isnan(imputer_X))","da276dbd":"X = imputer_X","ecb04fd0":"y = housing[['SalePrice']]\ny[0:10]","a8bd3ebf":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","fb81dc04":"from sklearn import linear_model\nridge = linear_model.Ridge()\nridge.fit(X_train, y_train)","70186e43":"def error(actual, predicted):\n    actual = np.log(actual)\n    predicted = np.log(predicted)\n    return np.sqrt(np.sum(np.square(actual-predicted))\/len(actual))","7ee06340":"ridge.score(X_train, y_train)","381baafd":"error(y_train, ridge.predict(X_train))","7f9279c1":"error(y_test, ridge.predict(X_test))","35b4d1b7":"ridge.score(X_test, y_test)","1e311e3f":"lasso = linear_model.Lasso()\nlasso.fit(X_train, y_train)","eafef0de":"lasso.score(X_train, y_train)","e406bd1b":"lasso.score(X_test, y_test)","9bdd1df4":"import xgboost as xgb\nxgb_reg = xgb.XGBRegressor(n_jobs=2)\nxgb_reg.fit(X_train, y_train)","34c355c0":"xgb_reg.score(X_train, y_train)","4d0bc1ea":"xgb_reg.score(X_test, y_test)","ada549da":"test = pd.read_csv('..\/input\/test.csv')\ntest_ids = test['Id']\ntest.drop(columns=['Id'])","e4d5a882":"xgb_submit1 = xgb.XGBRegressor(n_jobs=2)\nxgb_submit1.fit(X, y)\n\ntest_X = test[quantitative].values\n#test_X = imputer.fit(test_X)\npredicted_prices = xgb_submit1.predict(test_X)\npredicted_prices","415f809b":"my_submission = pd.DataFrame({'Id': test_ids, 'SalePrice': predicted_prices})\nmy_submission.to_csv('submission1.csv', index=False)","08647dd4":"from category_encoders import OneHotEncoder\n\ncategory_data = housing.drop(columns=quantitative + ['Id', 'SalePrice'])","ead57a1c":"encoder = OneHotEncoder().fit(category_data, y)\nencoder.category_mapping","fd68dee8":"encoded_X = encoder.transform(category_data)","df3bb9f3":"encoded_X.head()","c117d36a":"encoded_X.isna().sum().sum()","923bdd0b":"imputer_X.shape","2bb3a8a0":"encoded_X.shape","86784b47":"X = np.append(imputer_X, encoded_X, axis=1)\nX.shape","5dd91e7f":"X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X, y, test_size=0.2)","637a74d6":"xgb_cat = xgb.XGBRegressor(n_jobs=2)\nxgb_cat.fit(X_train_cat, y_train_cat)","f932808a":"xgb_cat.score(X_train_cat, y_train_cat)","69016309":"xgb_cat.score(X_test_cat, y_test_cat)","90967282":"import xgboost as xgb\nxgb.plot_importance(xgb_cat, max_num_features=20)","af45b25c":"xgb.plot_tree(xgb_cat)","4626134b":"xgb_submit2 = xgb.XGBRegressor(n_jobs=2)\nxgb_submit2.fit(X, y)","a9d6bd65":"encoded_test = encoder.transform(test[qualitative])","b71d686b":"trasnformed_test = np.append(test[quantitative], encoded_test, axis=1)","4e79d67b":"predicted_prices2 = xgb_submit2.predict(trasnformed_test)\nsubmission2 = pd.DataFrame({'Id': test_ids, 'SalePrice': predicted_prices2})\nsubmission2.to_csv('submission2.csv', index=False)","98583e37":"from sklearn.model_selection import cross_val_score","cf34e302":"xgb_cat = xgb.XGBRegressor(n_jobs=2)\nscores = cross_val_score(xgb_cat, X, y, cv=5, n_jobs=1, verbose=2)","41ea14cd":"print('Scores:', scores)\nprint('Mean:', scores.mean())\nprint('Standard deviation:', scores.std())","a344fe20":"# https:\/\/www.analyticsvidhya.com\/blog\/2016\/03\/complete-guide-parameter-tuning-xgboost-with-codes-python\/\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid={ \n    'max_depth': [3],\n    'learning_rate': [0.1],\n    'n_estimators': [100],\n    'gamma': [0],\n    'min_child_weight': [1],\n    'max_delta_step': [0],\n    'subsample': [1],\n    'colsample_by_tree': [1],\n    'colsample_bylevel': [1]\n}","e2021b25":"xgb_search0 = xgb.XGBRegressor(\n    n_estimators=1000,\n    n_jobs=2\n)\nxgb_search0.fit(\n    X_train_cat, y_train_cat,\n    early_stopping_rounds=10,\n    eval_set= [[X_test_cat, y_test_cat]]\n)","d10400c8":"xgb_search0.score(X_test_cat, y_test_cat)","cdd7067f":"param1= {\n    'max_depth': range(3,6),\n    'min_child_weight': range(1,6,2)\n}\nxgb_search1 = xgb.XGBRegressor(n_estimators=147, n_jobs=2)\ngrid_search1 = GridSearchCV(\n    xgb_search1, param1,\n    cv=5,\n    verbose=1,\n#     scoring='neg_mean_squared_error'\n)\ngrid_search1.fit(X, y)","7bd5f1f3":"grid_search1.best_score_","2e4062cb":"grid_search1.best_params_","4e409c6b":"param2 = {\n    'gamma': [i\/10.0 for i in range(0,5)]\n}\nxgb_search2 = xgb.XGBRegressor(n_estimators=147, n_jobs=2)\ngrid_search2 = GridSearchCV(\n    xgb_search2, param2, \n    cv=5,\n    verbose=1,\n#     scoring='neg_mean_squared_error'\n)\ngrid_search2.fit(X, y)","27a1b4bc":"grid_search2.best_score_","c5cbc919":"grid_search2.best_params_","ecdd31f6":"param3= {\n    'subsample': [i\/10.0 for i in range(6,10)],\n    'colsample_bytree': [i\/10.0 for i in range(6,10)]\n}\nxgb_search3 = xgb.XGBRegressor(n_estimators=147, n_jobs=2)\ngrid_search3 = GridSearchCV(\n    xgb_search3, param3, \n    cv=5,\n    verbose=1,\n#     scoring='neg_mean_squared_error'\n)\ngrid_search3.fit(X, y)","59150dd5":"grid_search3.best_score_","d8291c52":"grid_search3.best_params_","177dbfdb":"xgb_search4 = xgb.XGBRegressor(\n    learning_rate=0.05,\n    n_estimators=1000,\n    subsample= 0.7,\n    colsample_bytree=0.8,\n    n_jobs=2\n)\nxgb_search4.fit(\n    X_train_cat, y_train_cat,\n    early_stopping_rounds=10,\n    eval_set= [[X_test_cat, y_test_cat]]\n)","8a2fd743":"xgb_search4.score(X_test_cat, y_test_cat)","9b123dc1":"param3= {\n    'subsample': [i\/10.0 for i in range(6,10)],\n    'colsample_bytree': [i\/10.0 for i in range(6,10)]\n}\nxgb_search5 = xgb.XGBRegressor(\n    learnin_rate=0.05,\n    n_estimators=188, n_jobs=2)\ngrid_search5 = GridSearchCV(\n    xgb_search5, param3, \n    cv=5,\n    verbose=1,\n#     scoring='neg_mean_squared_error'\n)\ngrid_search5.fit(X, y)","e0094aa1":"grid_search5.best_score_","c234e48a":"grid_search5.best_params_","2b244aca":"predicted_prices3 = grid_search5.best_estimator_.predict(trasnformed_test)\nsubmission3 = pd.DataFrame({'Id': test_ids, 'SalePrice': predicted_prices3})\nsubmission3.to_csv('submission3.csv', index=False)","ed595913":"from sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\nscaler.fit(X)\nscaled_X = scaler.transform(X)","d1a5e381":"xgb_best = xgb.XGBRegressor(\n    learning_rate=0.05,\n    n_estimators=188,\n    subsample= 0.7,\n    colsample_bytree=0.8,\n    n_jobs=2\n)\nscores_encoded = cross_val_score(xgb_best, X, y, cv=5, verbose=3)\nscores_scaled = cross_val_score(xgb_best, scaled_X, y, cv=5, verbose=3)","4fb92698":"print('Scores:', scores_encoded)\nprint('Mean:', scores_encoded.mean())\nprint('Standard deviation:', scores_encoded.std())","8c6ceeb9":"print('Scores:', scores_scaled)\nprint('Mean:', scores_scaled.mean())\nprint('Standard deviation:', scores_scaled.std())","4a2b709d":"scaled_X_train, scaled_X_test, scaled_y_train, scaled_y_test = train_test_split(scaled_X, y, test_size=0.2)","32d3e0da":"xgb_best.fit(scaled_X_train, scaled_y_train)\nxgb_predictions = xgb_best.predict(scaled_X_test)","68df2692":"from sklearn.metrics import r2_score\nr2_score(scaled_y_test, xgb_predictions)","bb933b8f":"# lasso = linear_model.LassoCV(cv=5, verbose=True)\nlasso = linear_model.Lasso()\nlasso.fit(scaled_X_train, scaled_y_train)\nlasso_predictions = lasso.predict(scaled_X_test)\nr2_score(scaled_y_test, lasso_predictions)","d9753db7":"stacked = lasso_predictions * 0.5 + xgb_predictions * 0.5\nr2_score(scaled_y_test,stacked)","17c51c5e":"stacked_predictions = [lasso_predictions * (i \/ 10.0) + xgb_predictions * ((10 - i)\/ 10)for i in range(10)]","7bfdb879":"stacked_scores = [r2_score(scaled_y_test, stacked) for stacked in stacked_predictions]","0bf1139e":"stacked_scores","c98f5f13":"best_i = np.argmax(stacked_scores)\nbest_i, stacked_scores[best_i]","e7e98bd0":"## XGBoost","2b8195f8":"## Submit answer","52be9a01":"# Submit Answer","b1420a37":"# Cross Validation","e2457c55":"# Categorical Encoder","b9f8f368":"# Data Split","37e29f70":"# Train Model","db38e181":"# Fine-tune Model","b27de0a7":"## Ridge","df2fa541":"# Data Cleaning","53b06376":"# Stacking","43dd32fd":"# Feature Scaling","844c2190":"## Lasso","739c327d":"# References\n* https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\n* https:\/\/www.kaggle.com\/dgawlik\/house-prices-eda\n* https:\/\/www.kaggle.com\/hemingwei\/top-2-from-laurenstc-on-house-price-prediction\n* https:\/\/www.kaggle.com\/massquantity\/all-you-need-is-pca-lb-0-11421-top-4","96eff701":"# \u8cc7\u6599\u63a2\u7d22","44d861f2":"## Train with categorical features","59c3dcae":"## submit answer"}}