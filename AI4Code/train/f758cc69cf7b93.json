{"cell_type":{"a2108d8d":"code","c6b92773":"code","7413daa1":"code","866abe27":"code","e9f158b1":"code","15ae016c":"code","4c1380a2":"code","87e52566":"code","9948a0e7":"code","3bcca076":"code","e0ea0cb7":"code","43918f54":"code","2b4c2026":"code","3a9b9d2a":"code","ec6bda9f":"code","e22b5f0b":"code","9a5bdecb":"code","faebd2d0":"code","87066f3b":"code","52255d8c":"code","838cc36c":"code","811512fb":"code","b7e1684d":"code","bc31aba8":"code","0e9db2e3":"code","8bcaca0b":"code","03a9f15d":"code","e95ad0eb":"code","67f61374":"code","76c01988":"code","2d840468":"code","b94b3305":"code","480e93b8":"code","2dd02bbc":"code","81599fc3":"code","cacbfe7e":"code","91cd27f9":"code","3a1f1918":"code","f5d564a6":"code","8a13adc9":"code","da62d363":"code","de33140c":"code","8b1c1549":"code","6a384146":"code","b4b79d77":"code","db06f973":"code","13f708bb":"markdown","2752831d":"markdown","d9c8ae7e":"markdown"},"source":{"a2108d8d":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\nimport PIL\nfrom IPython import display\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","c6b92773":"Video_Path = \"..\/input\/human-evolution-video\/human.mp4\"","7413daa1":"Video_IMG_List = []\n\nVideo_Cap = cv2.VideoCapture(Video_Path)\n\n\nwhile Video_Cap.isOpened():\n\n    \n    ret,frame = Video_Cap.read()\n    \n    if ret != True:\n        break\n        \n    if Video_Cap.isOpened():\n        Transformation_IMG = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n        Resize_IMG = cv2.resize(Transformation_IMG,(180,180))\n        Video_IMG_List.append(Resize_IMG)\n        \n        \nVideo_Cap.release()","866abe27":"print(np.shape(np.asarray(Video_IMG_List)))","e9f158b1":"figure = plt.figure(figsize=(8,8))\n\nPick_IMG = Video_IMG_List[1]\nplt.xlabel(Pick_IMG.shape)\nplt.ylabel(Pick_IMG.size)\nplt.imshow(Pick_IMG)","15ae016c":"figure = plt.figure(figsize=(8,8))\n\nPick_IMG = Video_IMG_List[1000]\nplt.xlabel(Pick_IMG.shape)\nplt.ylabel(Pick_IMG.size)\nplt.imshow(Pick_IMG)","4c1380a2":"figure = plt.figure(figsize=(8,8))\n\nPick_IMG = Video_IMG_List[3410]\nplt.xlabel(Pick_IMG.shape)\nplt.ylabel(Pick_IMG.size)\nplt.imshow(Pick_IMG)","87e52566":"figure,axis = plt.subplots(4,4,figsize=(10,10))\n\nfor i,ax in enumerate(axis.flat):\n    \n    IMG_From_List = Video_IMG_List[i]\n    ax.set_xlabel(IMG_From_List.shape)\n    ax.imshow(IMG_From_List)\n    \nplt.tight_layout()\nplt.show()","9948a0e7":"X_Train = np.asarray(Video_IMG_List)","3bcca076":"print(X_Train.shape)","e0ea0cb7":"figure = plt.figure(figsize=(8,8))\n\nPick_IMG = X_Train[410]\nplt.xlabel(Pick_IMG.shape)\nplt.ylabel(Pick_IMG.size)\nplt.imshow(Pick_IMG)","43918f54":"figure = plt.figure(figsize=(8,8))\n\nPick_IMG = X_Train[3532]\nplt.xlabel(Pick_IMG.shape)\nplt.ylabel(Pick_IMG.size)\nplt.imshow(Pick_IMG)","2b4c2026":"iterations = 50\nvector_noise_dim = 180\ncount_example = 16\nbatch_size=12\ncount_buffer = 60000","3a9b9d2a":"X_Train = X_Train \/ 255.","ec6bda9f":"Train_Data = tf.data.Dataset.from_tensor_slices(X_Train).shuffle(count_buffer).batch(batch_size)","e22b5f0b":"print(Train_Data)","9a5bdecb":"def Generator_Model():\n    \n    \n    Model = Sequential()\n    #\n    Model.add(Dense(90*90*128,use_bias=False,input_shape=(180,)))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Reshape((90,90,128)))\n    #\n    Model.add(Conv2DTranspose(128,(3,3),padding=\"same\",use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Conv2DTranspose(3,(3,3),padding=\"same\",use_bias=False,activation=\"tanh\"))\n    \n    \n    return Model","faebd2d0":"Generator = Generator_Model()","87066f3b":"print(Generator.summary())","52255d8c":"def Discriminator_Model():\n    \n    model = Sequential()\n    \n    model.add(Conv2D(64,(3,3),padding=\"same\",input_shape=[180,180,3]))\n    model.add(Dropout(0.3))\n    model.add(LeakyReLU())\n    \n    \n    model.add(Conv2D(128,(3,3),padding=\"same\"))\n    model.add(Dropout(0.3))\n    model.add(LeakyReLU())\n    \n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n    \n    return model","838cc36c":"Discriminator = Discriminator_Model()","811512fb":"print(Discriminator.summary())","b7e1684d":"Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)","bc31aba8":"Generator_Optimizer = tf.keras.optimizers.RMSprop(lr=0.0001,clipvalue=1.0,decay=1e-8)\nDiscriminator_Optimizer = tf.keras.optimizers.RMSprop(lr=0.0001,clipvalue=1.0,decay=1e-8)","0e9db2e3":"seed = tf.random.normal([count_example, vector_noise_dim])","8bcaca0b":"def Discriminator_Loss(real_out,fake_out):\n    \n    real_loss_function = Loss_Function(tf.ones_like(real_out),real_out)\n    fake_loss_function = Loss_Function(tf.zeros_like(fake_out),fake_out)\n    total_loss = real_loss_function + fake_loss_function\n    \n    return total_loss","03a9f15d":"def Generator_Loss(fake_out):\n    return Loss_Function(tf.ones_like(fake_out),fake_out)","e95ad0eb":"def generate_and_save_images(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(10, 10))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(6, 6, i+1)\n        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","67f61374":"def Train_Step(images):\n    \n    random_noise_vector = tf.random.normal([batch_size,vector_noise_dim])\n    \n    with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n        \n        Generator_Fake_IMG = Generator(random_noise_vector,training=False)\n        \n        real_out = Discriminator(images,training=True)\n        fake_out = Discriminator(Generator_Fake_IMG,training=True)\n        \n        Generator_Loss_Out = Generator_Loss(fake_out)\n        Discriminator_Loss_Out = Discriminator_Loss(real_out,fake_out)\n        \n    Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Out,Generator.trainable_variables)\n    Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Out,Discriminator.trainable_variables)\n    \n    Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))","76c01988":"def Train(dataset,iterations):\n    \n    for epoch in range(iterations):\n        \n        start = time.time()\n        \n        for image_batch in dataset:\n            Train_Step(image_batch)\n            \n        display.clear_output(wait=True)\n        generate_and_save_images(Generator,epoch+1,seed)\n    \n    display.clear_output(wait=True)\n    generate_and_save_images(Generator,epoch,seed)","2d840468":"Train(Train_Data, iterations)","b94b3305":"Predict_Noise = tf.random.normal(shape=[30,vector_noise_dim])","480e93b8":"Generator_Predict_Noise = Generator(Predict_Noise)","2dd02bbc":"figure, axes = plt.subplots(nrows=5,ncols=6,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMG_Random = Generator_Predict_Noise[i]\n    ax.imshow(IMG_Random)\n    ax.set_xlabel(Generator_Predict_Noise[i].shape)\nplt.tight_layout()\nplt.show()","81599fc3":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[25])\nplt.show()","cacbfe7e":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[29])\nplt.show()","91cd27f9":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[9])\nplt.show()","3a1f1918":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[1])\nplt.show()","f5d564a6":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[10])\nplt.show()","8a13adc9":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[13])\nplt.show()","da62d363":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[2])\nplt.show()","de33140c":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[11])\nplt.show()","8b1c1549":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[17])\nplt.show()","6a384146":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[16])\nplt.show()","b4b79d77":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[21])\nplt.show()","db06f973":"figure = plt.figure(figsize=(14,14))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict_Noise[15])\nplt.show()","13f708bb":"# DATA EXPORT AND TRANSFORMATION","2752831d":"# PACKAGES AND LIBRARIES","d9c8ae7e":"# DATA ENGINEERING BEFORE DC-GAN TRAINING"}}