{"cell_type":{"fcf911ed":"code","1bdd12c4":"code","07223f47":"code","96b56ab6":"code","e903987b":"code","05794260":"code","c53ba34e":"code","c127b0c4":"code","3428d643":"code","8ffb0466":"code","2d7d99ae":"markdown","e335b09e":"markdown"},"source":{"fcf911ed":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","1bdd12c4":"import os\n\nimage_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n\n\ndef list_images(basePath, contains=None):\n    # return the set of files that are valid\n    return list_files(basePath, validExts=image_types, contains=contains)\n\n\ndef list_files(basePath, validExts=None, contains=None):\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image and should be processed\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename)\n                yield imagePath","07223f47":"import random\n\n\nimagePaths = sorted(list(list_images(\"\/kaggle\/input\/data19c3\/data19c\")))  #list \u662f\u5c06\u5143\u7956\u8f6c\u6362\u6210\u5217\u8868  sorted\u8fdb\u884c\u6392\u5e8f\nrandom.seed(42) #\u968f\u673a\u79cd\u5b50\u8fdb\u884c\u6392\u5e8f\nrandom.shuffle(imagePaths) ","96b56ab6":"import cv2\nfrom keras.utils import np_utils\nimport numpy as np\n\n\nlabels = []\ndata = []\nfor j,imagePath in enumerate(imagePaths): #\u83b7\u53d6\u56fe\u50cf\n    image = cv2.imread(imagePath)\n\n    image = cv2.resize(image, (224, 224))#\u8bbe\u7f6e\u56fe\u50cf\u7684\u5927\u5c0f\n    # cv2.imshow(\"ssdf\",image)\n    # cv2.waitKey(50)\n    data.append(image) #extend \u548c append \u7684\u533a\u522b  \u8fd9\u91cc\u662f\u6bcf\u4e00\u4e2a\u90fd\u52a0\n    label = imagePath.split(os.path.sep)[-2]  #os.path.sep\u8def\u5f84\u5206\u5272\u7b26\u53f7  #slit\u4ee5\u5206\u5272\u7b26\u53f7\u8fdb\u884c\u5206\u5272 \u83b7\u53d6\u5012\u6570\u7b2c\u4e8c\u4e2a\u53c2\u6570\n    labels.append(label) #\u8fd9\u91cc\u662f\u83b7\u53d6\u5217\u8868\n    \n    aa = set(labels)\n    num_classes  = len(aa)\ndata = np.array(data)\nlabels = np.array(labels)\nlabels = np_utils.to_categorical(labels, num_classes)","e903987b":"from sklearn.model_selection import train_test_split\n\n(X_train, Y_train, X_valid, Y_valid) = train_test_split(data,\n\tlabels, test_size=0.25, random_state=42)","05794260":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_valid.shape)\nprint(Y_valid.shape)","c53ba34e":"\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras import applications\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, add,  Activation\nfrom keras.optimizers import SGD\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, add, Flatten, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.utils import plot_model\nfrom sklearn.metrics import log_loss\n\npath = \"\/kaggle\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nbase_model = applications.VGG16(weights=path, include_top=False,\n                                input_shape=(224, 224, 3)) \n\n\nfor layer in base_model.layers[:15]: layer.trainable = False\n\n\ntop_model = Sequential()  # \u81ea\u5b9a\u4e49\u9876\u5c42\u7f51\u7edc\ntop_model.add(AveragePooling2D((7, 7), name='avg_pool'))\ntop_model.add(Flatten(input_shape=base_model.output_shape[1:]))  # \u5c06\u9884\u8bad\u7ec3\u7f51\u7edc\u5c55\u5e73\ntop_model.add(Dense(256, activation='relu'))  # \u5168\u8fde\u63a5\u5c42\uff0c\u8f93\u5165\u50cf\u7d20256\ntop_model.add(Dropout(0.5))  # Dropout\u6982\u73870.5\ntop_model.add(Dense(13, activation='softmax'))  # \u8f93\u51fa\u5c42\uff0c\u4e8c\u5206\u7c7b\n\n# top_model.load_weights(\"\")  # \u5355\u72ec\u8bad\u7ec3\u7684\u81ea\u5b9a\u4e49\u7f51\u7edc\n\nmodel = Model(inputs=base_model.input, outputs=top_model(base_model.output))  # \u65b0\u7f51\u7edc=\u9884\u8bad\u7ec3\u7f51\u7edc+\u81ea\u5b9a\u4e49\u7f51\u7edc\nsgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n","c127b0c4":"print(model.summary())","3428d643":"img_rows, img_cols = 224, 224 # h,w\nchannel = 3\nnum_classes = 13\nbatch_size = 16 \nnb_epoch = 500","8ffb0466":"\n\n\n\n\n\nH = model.fit(X_train, X_valid,\n          batch_size=batch_size,\n          epochs=nb_epoch,\n          shuffle=True,\n          verbose=1,\n          validation_data=(Y_train, Y_valid),\n          )\n\n\n    \nplt.style.use(\"ggplot\")\nplt.figure()\nplt.ylim(0,3)\nN = nb_epoch\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.savefig('result.png')","2d7d99ae":"print(base_model.summary())","e335b09e":"\u642d\u5efa\u7f51\u7edc\u6a21\u578b"}}