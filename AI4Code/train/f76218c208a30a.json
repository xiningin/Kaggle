{"cell_type":{"889a5dde":"code","09c5c54b":"code","e389cf3a":"code","70cc841c":"code","2f555cb5":"code","7b46152a":"code","997fb17b":"code","a46f8cea":"code","8ad1b864":"code","951efb58":"code","111a1067":"code","266afdf1":"code","b04091b3":"code","2747ba70":"code","1b263f83":"code","b7bb8389":"markdown","5c9444c4":"markdown","f96b28c1":"markdown","7f507a24":"markdown","314b2f25":"markdown","00c17214":"markdown","cde8e936":"markdown"},"source":{"889a5dde":"# Basics\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Preprocssing\nimport missingno as msno\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, binarize\n\n# Model Selection \nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n# Ensemble\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n\n# Metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score\n\n# Feature Selection\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n# Warnings\nimport warnings as ws\nws.filterwarnings('ignore')","09c5c54b":"# Load dataset\ndata = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndata.head()","e389cf3a":"# Summary\ndef summary(data):\n    df = {\n     'Count' : data.shape[0],\n     'NA values' : data.isna().sum(),\n     '% NA' : round((data.isna().sum()\/data.shape[0]) * 100, 2),\n     'Unique' : data.nunique(),\n     'Dtype' : data.dtypes,\n     'min' : round(data.min(),2),\n     '25%' : round(data.quantile(.25),2),\n     '50%' : round(data.quantile(.50),2),\n     'mean' : round(data.mean(),2),\n     '75%' : round(data.quantile(.75),2),   \n     'max' : round(data.max(),2)\n    } \n    return(pd.DataFrame(df))\n\nprint('Shape is :', data.shape)\nsummary(data)","70cc841c":"data.hist(figsize = (10,10))\nplt.show()","2f555cb5":"# Target Variables\ndata['quality'].value_counts()","7b46152a":"# Convert Target variable into binary\nbins = [2,6.5, 8]\nlabels = ['Bad','Good']\ndata['quality'] = pd.cut(data['quality'], bins = bins, labels = labels)\n\ndata['quality'].value_counts()","997fb17b":"col_names = data.drop('quality', axis = 1).columns.tolist()\n\nplt.figure(figsize = (15,10))\ni=0\nfor col in col_names:\n    plt.subplot(3,4, i+1)\n    plt.grid(True, alpha = 0.5)\n    sns.kdeplot(data[col][data['quality'] == 'Bad'], label = 'Bad Quality')\n    sns.kdeplot(data[col][data['quality'] == 'Good'], label = 'Good Quality')\n    plt.title(col + ' vs Quality', size = 15)\n    plt.xlabel(col, size = 12)\n    plt.ylabel('Density')    \n    plt.tight_layout()\n    i+=1\nplt.show()","a46f8cea":"X = data.drop('quality', axis = 1)\nY = data['quality'].replace({'Bad':0, 'Good' : 1})\n\nx_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state = 42)","8ad1b864":"models = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('SVM', SVC()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('ADA', AdaBoostClassifier()))\nmodels.append(('GB', GradientBoostingClassifier()))","951efb58":"def model_selection(X,Y):\n    acc_results = []\n    auc_results = []\n    names = []\n\n    # Set Table\n    col = ['Model Name','ROC AUC Mean','ROC AUC Std','ACC Mean', 'AUC Std']\n    model_results = pd.DataFrame(columns = col)\n\n    i = 0\n    for name, model in models:\n        kfold = KFold(n_splits = 10, random_state = 7)\n\n        cv_acc_results = cross_val_score(model, X,Y, cv = kfold, scoring = 'accuracy')\n        cv_auc_results = cross_val_score(model, X,Y, cv = kfold, scoring =  'roc_auc')\n\n        acc_results.append(cv_acc_results)\n        auc_results.append(cv_auc_results)\n        names.append(name)\n\n        model_results.loc[i] = [name, cv_auc_results.mean(),cv_auc_results.std(), cv_acc_results.mean(), cv_acc_results.std()]\n        i+=1\n\n    model_results = model_results.sort_values(['ROC AUC Mean'], ascending = False)     \n\n    # View Model Results\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    sns.boxplot(x = names, y = acc_results)\n    plt.title('Accuracy Score')\n\n    plt.subplot(1,2,2)\n    sns.boxplot(x = names, y = auc_results)\n    plt.title('AUC Score')\n    plt.show()\n    \n    return(model_results)","111a1067":"model_selection(x_train, y_train)","266afdf1":"def model_validation(model,x_test,y_test,thr = 0.5) :\n    \n    y_pred_prob = model.predict_proba(x_test)[:,1]\n    y_pred = binarize(y_pred_prob.reshape(1,-1), thr)[0]\n    \n    cnf_matrix = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize = (10,3))\n    plt.subplot(1,2,1)\n    sns.heatmap(cnf_matrix, annot = True, fmt = 'g')\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted label')\n    plt.ylabel('Actual label')\n\n    fpr, tpr, threshold = roc_curve(y_test, y_pred_prob)\n    plt.subplot(1,2,2)\n    sns.lineplot(fpr, tpr)\n    plt.plot([0,1],[0,1], 'r--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show()\n\n    \n    print('Classification Report :')\n    print('===' * 20)\n    print(classification_report(y_test, y_pred))\n\n    score = tpr - fpr\n    opt_threshold = sorted(zip(score,threshold))[-1][1]\n    print('='*20)\n    print('Area Under Curve', roc_auc_score(y_test,y_pred))\n    print('Accuracy', accuracy_score(y_test,y_pred))\n    print('Optimal Threshold : ',opt_threshold)\n    print('='*20)","b04091b3":"param_grid = {\n    'bootstrap': [True,False],\n    'max_depth': [10, 50, 100],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [10,100, 200, 300, 1000]\n}\n\nrf = RandomForestClassifier()\ngrid = GridSearchCV(rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 1)\n\ngrid.fit(x_train, y_train)\ngrid.best_params_","2747ba70":"model_validation(grid, x_test, y_test)","1b263f83":"# Final Model\nfinal_model = grid.best_estimator_\nfinal_model.fit(x_train, y_train)\n\nmodel_validation(final_model,x_test,y_test, 0.106)","b7bb8389":"This dataset seems like imbalanced dataset ","5c9444c4":"There is no missing values in this dataset. All variables are numeric and we found our target varibale have 6 unique values.\n\n### Visualization","f96b28c1":"### Model Selection\nWe don't  know which model is perform well for this dataset. So we validate all the models on trian test dataset","7f507a24":"### Train Test Split","314b2f25":"Random Forest fits well in this dataset. \n\nTo avoid overfitting in final model we have to use hyper parameters of the models. This basically done by cross valdation technique","00c17214":"### Load Libraries ","cde8e936":"Recall for 1 in final model has improved lot. which means 90% of True positive predicted as True.\n\n"}}