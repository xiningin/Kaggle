{"cell_type":{"3389ddd8":"code","25ffaa7a":"code","c1745485":"code","1a414a0d":"code","6f99ed85":"code","ccc0fe77":"code","b9d655ce":"code","d11a7d4c":"code","fc78ab87":"code","f8c33a3b":"code","24b6a863":"code","1d130a1c":"code","14bf34ff":"code","553a6feb":"code","e6233025":"code","608205c1":"code","d1a72d24":"code","ede5742b":"markdown","1ef1ca05":"markdown","52a8b935":"markdown","a0f25490":"markdown","ed818f9b":"markdown","66df895e":"markdown"},"source":{"3389ddd8":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Dense,Flatten,BatchNormalization,Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image","25ffaa7a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","c1745485":"from sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","1a414a0d":"df = pd.read_csv('..\/input\/movie-classifier\/Multi_Label_dataset\/train.csv')","6f99ed85":"# Taking 30 percentage of the dataset for this project as using whole dataset crashes the memory threshold of kaggle kernels\ndf = df.head(2300)","ccc0fe77":"df.head()","b9d655ce":"width = 350\nheight = 350\nX = []\nfor i in tqdm(range(df.shape[0])):\n  path = '..\/input\/movie-classifier\/Multi_Label_dataset\/Images\/'+df['Id'][i]+'.jpg'\n  img = image.load_img(path,target_size=(width,height,3))\n  img = image.img_to_array(img)\n  img = img\/255.0\n  X.append(img)\n\nX = np.array(X)","d11a7d4c":"X.shape","fc78ab87":"y = df.drop(['Id','Genre'],axis=1)\ny = y.to_numpy()\ny.shape","f8c33a3b":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1)","24b6a863":"model = Sequential()\nmodel.add(Conv2D(16,kernel_size=(3,3),activation='relu',input_shape=X_train[0].shape))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,2))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,2))\nmodel.add(Dropout(0.3))\n\n\nmodel.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(2,2))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(25,activation='sigmoid'))","1d130a1c":"model.summary()","14bf34ff":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","553a6feb":"history = model.fit(X_train,y_train,epochs=5,validation_data=(X_test,y_test))","e6233025":"def plotLearningCurve(history,epochs):\n  epochRange = range(1,epochs+1)\n  plt.plot(epochRange,history.history['accuracy'])\n  plt.plot(epochRange,history.history['val_accuracy'])\n  plt.title('Model Accuracy')\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy')\n  plt.legend(['Train','Validation'],loc='best')\n  plt.show()\n\n  plt.plot(epochRange,history.history['loss'])\n  plt.plot(epochRange,history.history['val_loss'])\n  plt.title('Model Loss')\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  plt.legend(['Train','Validation'],loc='best')\n  plt.show()","608205c1":"plotLearningCurve(history,5)","d1a72d24":"img = image.load_img('..\/input\/movie-classifier\/Multi_Label_dataset\/Images\/tt0088247.jpg',target_size=(width,height,3))\nplt.imshow(img)\nimg = image.img_to_array(img)\nimg = img\/255.0\nimg = img.reshape(1,width,height,3)\nclasses = df.columns[2:]\ny_pred = model.predict(img)\ntop3=np.argsort(y_pred[0])[:-4:-1]\nfor i in range(3):\n  print(classes[top3[i]])","ede5742b":"# Reading the Dataset","1ef1ca05":"# Converting the images into Numpy array to train the CNN","52a8b935":"# Importing Neccessary Libraries","a0f25490":"# As you can see from the above output Model predicted the \"Drama\", \"Thriller\" and \"Action\" genre of the film from the poster of the image.","ed818f9b":"# Preparing the model","66df895e":"# Applying the trained model to Predict the Genre of the input image"}}