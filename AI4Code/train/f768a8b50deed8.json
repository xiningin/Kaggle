{"cell_type":{"8d73c3b0":"code","13f0499b":"code","c286f075":"code","425584f2":"code","a6335a03":"code","82485d22":"code","67675f3a":"code","8f2948a3":"code","f3b4adc5":"code","ea093119":"code","c9047555":"code","e306f489":"code","f3ac760f":"code","b5a7d46d":"code","68eb4ae6":"code","24161872":"code","4b50d232":"code","938d7523":"code","f5273520":"code","14c53663":"code","bbe24ccd":"code","3d748bcb":"code","6630a839":"code","d669b3a1":"code","fd0f356b":"code","da7f6e4f":"code","b9e969b9":"code","a2fd682b":"code","6546d54b":"code","9771bf0a":"code","240bd9f1":"code","f530e256":"code","a5e43000":"code","4b51c5c0":"code","f2e3fd65":"code","80463741":"code","ab6cf1e7":"code","5dc17f22":"code","820f90b0":"code","bdd96d7e":"code","9d926285":"markdown","5ce58532":"markdown","00bbdfcd":"markdown","6031b493":"markdown","84e5d338":"markdown","13920034":"markdown","59c58fef":"markdown","56f1d9af":"markdown","bf4d155f":"markdown","8985fe1e":"markdown","49646662":"markdown","9cea9b4d":"markdown","6a3ff117":"markdown","5aa4e82b":"markdown","c06905a4":"markdown"},"source":{"8d73c3b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13f0499b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","c286f075":"# importing dataset\ndf = pd.read_csv(\"\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/merc.csv\")\ndf.head(10)","425584f2":"# rows and columns of data\ndf.shape","a6335a03":"# info of data like memory used and datatypes of columns\ndf.info()","82485d22":"#checking for null values\ndf.isna().sum()","67675f3a":"# Statistical info of data\ndf.describe()","8f2948a3":"df.columns","f3b4adc5":"# Number of unique car models\ndf.model.nunique()","ea093119":"df.fuelType.unique()","c9047555":"df.transmission.unique()","e306f489":"plt.figure(figsize=(14,6))\nsns.countplot(df[\"model\"])\nplt.xticks(rotation=45)\nplt.title(\"Car models Countplot\")\nplt.ylabel(\"Number of Cars\")\nplt.xlabel(\"Car Models\")","f3ac760f":"sns.countplot(df[\"fuelType\"])","b5a7d46d":"sns.countplot(df[\"transmission\"])","68eb4ae6":"plt.figure(figsize=(25,8))\nsns.countplot(df['year'])\nplt.show()","24161872":"plt.figure(figsize=(13,8))\nsns.countplot(df['engineSize'])\nplt.show()","4b50d232":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf[\"transmission\"] = le.fit_transform(df[\"transmission\"])\ndf[\"fuelType\"] = le.fit_transform(df[\"fuelType\"])\ndf[\"model\"] = le.fit_transform(df[\"model\"])","938d7523":"df.head()","f5273520":"X = df.drop(columns=\"price\")\ny = df.price","14c53663":"X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\nprint(X_train.shape)\nprint(y_train.shape)","bbe24ccd":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","3d748bcb":"from sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators=400, max_depth=15)\nregressor.fit(X_train, y_train)","6630a839":"from sklearn.metrics import r2_score\ny_pred = regressor.predict(X_test)\nr2_score(y_pred, y_test)","d669b3a1":"from xgboost import XGBRegressor\nregressor2 = XGBRegressor(n_estimators=500,learning_rate=0.05, max_depth=6)\nregressor2.fit(X_train, y_train)","fd0f356b":"y_pred2 = regressor2.predict(X_test)\nr2_score(y_test,y_pred2)","da7f6e4f":"from lightgbm import LGBMRegressor\nregressor3 = LGBMRegressor(n_estimators=600, max_depth= 7)\nregressor3.fit(X_train, y_train)","b9e969b9":"y_pred3 = regressor3.predict(X_test)\nr2_score(y_test,y_pred3)","a2fd682b":"from sklearn.model_selection import cross_val_score, StratifiedKFold\nskf = StratifiedKFold(n_splits=5, shuffle=True,random_state=42)","6546d54b":"val_scores = cross_val_score(estimator=regressor3, X=X_train, y=y_train, cv=skf)\nval_scores","9771bf0a":"val_scores.mean()","240bd9f1":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nparams={ 'n_estimators': (100,200,300,400,500,600,700,800),\n         'max_depth': np.arange(2,21)}\ngrid_cv = GridSearchCV(estimator=regressor3, param_grid = params, cv=skf,verbose=True, n_jobs=-1)\nrandom_cv = RandomizedSearchCV(estimator=regressor, cv=skf, param_distributions=params,verbose=True,n_jobs=-1)","f530e256":"%%time\nrandom_cv.fit(X_train, y_train)","a5e43000":"random_cv.best_params_","4b51c5c0":"%%time\ngrid_cv.fit(X_train, y_train)","f2e3fd65":"grid_cv.best_params_","80463741":"print(\"r2_scores of models\")\nprint(\"Random Forest Regressor {} %\".format(r2_score(y_pred, y_test)))\nprint(\"XGBoost Regressor {}%\".format(r2_score(y_pred2,y_test)))\nprint(\"LightGBM Regressor {}%\".format(r2_score(y_test,y_pred3)))","ab6cf1e7":"df.head(20)","5dc17f22":"regressor3.predict([[18,2016,1,14000,3,325,30.4,4.0]])","820f90b0":"regressor.predict([[20,2011,2,6000,2,225,30.4,5.0]])","bdd96d7e":"#from sklearn.cross_validati import cross_val_predict\n#predicted = cross_val_predict(regressor3, X_train, y_train, cv=10)\nplt.figure(figsize=(12,8))\n\nsns.scatterplot(y_test, y_pred)\nplt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.show()","9d926285":"# Splitting Data into Dependent and Independent variables","5ce58532":"# Visualization","00bbdfcd":"# Applying Standard Scaler","6031b493":"## LightGBM Regressor","84e5d338":"Applying train_test_split to split data into training and testing set","13920034":"# R2_scores","59c58fef":"## Random Forest Regressor","56f1d9af":"<div class=\"alert alert-box alert-warning\">\n Please UPVOTE the notebook if you find it insightful!\n    \n See ya!\n    <\/div>","bf4d155f":"# Encoding Columns with categorical data","8985fe1e":"## XGBoost Regressor","49646662":"# StratifiedKFold","9cea9b4d":"* There are 27 car models of Mercedes.","6a3ff117":"# Importing libraries","5aa4e82b":"<div class=\"alert alert-box alert-info\">\nPredicting by input\n<\/div>","c06905a4":"# Model Training..\ud83d\udeb4"}}