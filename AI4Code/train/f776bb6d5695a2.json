{"cell_type":{"ed8e5821":"code","3bb26a2c":"code","974ce822":"code","93d0feee":"code","77f77711":"code","fa7e4916":"code","1bcc6dca":"code","8b073d40":"code","327198e3":"code","b980c7aa":"code","b5f4f48f":"code","23fe682b":"code","a7be2c9c":"code","dfce6508":"markdown","f28d11c9":"markdown","23a673ac":"markdown","6ec2e450":"markdown","8641432e":"markdown","7f829811":"markdown","4b3441b5":"markdown","05f8955a":"markdown","f22a0a82":"markdown","b1b774b6":"markdown","4ed09fcd":"markdown","7def2e7b":"markdown","1257216f":"markdown","a3d43b43":"markdown","eb5e27a3":"markdown","cdb5a326":"markdown","4958760d":"markdown","22e296d7":"markdown","f9ca117c":"markdown","5553f262":"markdown","aaf4b361":"markdown","26f89c52":"markdown","3684f7b0":"markdown","2cacfba5":"markdown","09d66ac1":"markdown","e2dabd08":"markdown","396a9ca0":"markdown","2cf98b3d":"markdown","87f1bf47":"markdown","5d3d3557":"markdown","9078adaa":"markdown","4de98074":"markdown","d30f2654":"markdown","35fc82f4":"markdown","fb77bb05":"markdown","0c628b06":"markdown","7d3c6807":"markdown","16b3a64f":"markdown","d639d45c":"markdown","2aa38c39":"markdown"},"source":{"ed8e5821":"!pip install openpyxl","3bb26a2c":"#package to use\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm \nimport statsmodels.formula.api as smf\nimport statsmodels.stats.api as sms \nimport pandas_profiling\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sns\nimport pandas.util.testing as tm\nfrom sklearn.model_selection import StratifiedKFold\nfrom numpy import arange\nfrom sklearn.linear_model import HuberRegressor\nfrom statsmodels.compat import lzip","974ce822":"#We load the dataset already treated according to the proxy definition of variables\n\ndf = pd.read_excel(\"\/kaggle\/input\/gcidataset\/dataset.xlsx\")\n\n#we visualize the dataset\n\ndf.head()","93d0feee":"#work base to have vectors of X and y\n#X with keras takes the values of X into a matrix so it works for us if it comes in table\/dataset,\n#So we only need to keep the X variables that we are going to use for each regression.\n\n\nX1 = df[[\"ep\"]]\nX2 = df[[ \"ep\", \"ied\"]]\nX3 = df[[\"pib\", \"ep\", \"ied\"]]\nX4 = df[[\"pib\", \"ex\", \"ep\", \"ied\"]]\n\n#we define \"y\" as the vector of the dependent variable\n\ny = df[\"gci\"]\ny = y.to_numpy()\n\n#We run the four regressions\n\nreg1 = LinearRegression().fit(X1, y)\nreg2 = LinearRegression().fit(X2, y)\nreg3 = LinearRegression().fit(X3, y)\nreg4 = LinearRegression().fit(X4, y)\n\n\n","77f77711":"#Let's put the parameters together\nreg_names1 = np.array([\"ep\", \"intercept\"])\nreg_names2 = np.array([\"ep\", \"ied\", \"intercept\"])\nreg_names3 = np.array([\"pib\", \"ep\", \"ied\", \"intercept\"])\nreg_names4 = np.array([\"pib\", \"ex\", \"ep\", \"ied\", \"intercept\"])\n\n# joining intercepts with coefficients\n#Reg1\nreg1_coef = np.array(reg1.coef_)\nreg1_intercept = np.array(reg1.intercept_)\nreg1_params = np.append(reg1_coef, reg1_intercept)\ndict1 = dict(zip(reg_names1, reg1_params))\ndfreg1 = pd.DataFrame(dict1.items(), index= dict1.keys())\ndfreg1 = dfreg1.transpose()\ndfreg1 = dfreg1.drop([0])\n#Reg2\nreg2_coef = np.array(reg2.coef_)\nreg2_intercept = np.array(reg2.intercept_)\nreg2_params = np.append(reg2_coef, reg2_intercept)\ndict2 = dict(zip(reg_names2, reg2_params))\ndfreg2 = pd.DataFrame(dict2.items(), index= dict2.keys())\ndfreg2 = dfreg2.transpose()\ndfreg2 = dfreg2.drop([0])\n\n#Reg3\nreg3_coef = np.array(reg3.coef_)\nreg3_intercept = np.array(reg3.intercept_)\nreg3_params = np.append(reg3_coef, reg3_intercept)\ndict3 = dict(zip(reg_names3, reg3_params))\ndfreg3 = pd.DataFrame(dict3.items(), index= dict3.keys())\ndfreg3 = dfreg3.transpose()\ndfreg3 = dfreg3.drop([0])\n\n#Reg4\nreg4_coef = np.array(reg4.coef_)\nreg4_intercept = np.array(reg4.intercept_)\nreg4_params = np.append(reg4_coef, reg4_intercept)\ndict4 = dict(zip(reg_names4, reg4_params))\ndfreg4 = pd.DataFrame(dict4.items(), index= dict4.keys())\ndfreg4 = dfreg4.transpose()\ndfreg4 = dfreg4.drop([0])\n\n#joining all params\n\nregtotal = pd.concat([dfreg1, dfreg2, dfreg3, dfreg4])\nregtotal = regtotal.fillna(\"\")\nregtotal[\"index\"] = [1,2,3,4]\nregtotal = regtotal.set_index(regtotal[\"index\"])\nregtotal = regtotal.drop(\"index\", axis= \"columns\")\nregtotal = regtotal.transpose()\n\n#let's see the resul\nregtotal","fa7e4916":"plt.figure(figsize = (20,10))\n\nplt.subplot(2,2,1)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg1.predict(X1), color =\"orange\", element = \"step\");\nplt.title('Regression 1')\n\nplt.subplot(2,2,2)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg2.predict(X2), color =\"orange\", element = \"step\");\nplt.title('Regression 2')\n\nplt.subplot(2,2,3)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg3.predict(X3), color =\"orange\", element = \"step\");\nplt.title('Regression 3')\n\nplt.subplot(2,2,4)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg4.predict(X4), color =\"orange\", element = \"step\");\nplt.title('Regression 4')\n","1bcc6dca":"prediction = reg4.predict(X4)\nresidual = (y - prediction)\nresidualpd = pd.DataFrame(residual)\nresidualpd.describe()","8b073d40":"#regression model using most representative regression (reg4)\nregBP = smf.ols ('gci ~ pib + ep + ied', data = df). fit()\n\nindicadores = ['Lagrange', 'p-value',\n        'F-Value', 'p-value(F)']\ntest = sms.het_breuschpagan(regBP.resid, regBP.model.exog)\n\nlzip (indicadores, test)","327198e3":"CIP = df[\"cip\"]\nEduc = df[\"ep\"]\n\ncovariance = np.cov(CIP, Educ)[0][1]\nprint(covariance)","b980c7aa":"#Running regression with the instrumental variable\nX5 = df[[\"pib\", \"cip\", \"ied\"]]\nreg5 = LinearRegression().fit(X5, y)\n\nprediction5 = reg5.predict(X5)\nresidual5 = (y - prediction5)\nresidualpd5 = pd.DataFrame(residual5)\nresidualpd5.describe()\n\n","b5f4f48f":"#getting covariance\ncovariance5 = np.cov(residual5, CIP)[0][1]\nprint(covariance5)","23fe682b":"reg_names5 = np.array([\"pib\", \"cip\", \"ied\", \"intercept\"])\n\nreg5_coef = np.array(reg5.coef_)\nreg5_intercept = np.array(reg5.intercept_)\nreg5_params = np.append(reg5_coef, reg5_intercept)\ndict5 = dict(zip(reg_names5, reg5_params))\ndfreg5 = pd.DataFrame(dict5.items(), index= dict5.keys())\ndfreg5 = dfreg5.transpose()\ndfreg5 = dfreg5.drop([0])\n\n#Let's join all the parameters of all the regressions.\n\nregtotal = pd.concat([dfreg1, dfreg2, dfreg3, dfreg4, dfreg5])\nregtotal = regtotal.fillna(\"\")\nregtotal[\"index\"] = [1,2,3,4,5]\nregtotal = regtotal.set_index(regtotal[\"index\"])\nregtotal = regtotal.drop(\"index\", axis= \"columns\")\nregtotal = regtotal.transpose()\n\n#Let's visualize the regressions together\nregtotal","a7be2c9c":"plt.figure(figsize = (20,10))\n\nplt.subplot(3,2,1)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg1.predict(X1), color =\"orange\", element = \"step\");\nplt.title('Regression 1')\n\nplt.subplot(3,2,2)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg2.predict(X2), color =\"orange\", element = \"step\");\nplt.title('Regression 2')\n\nplt.subplot(3,2,3)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg3.predict(X3), color =\"orange\", element = \"step\");\nplt.title('Regression 3')\n\nplt.subplot(3,2,4)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg4.predict(X4), color =\"orange\", element = \"step\");\nplt.title('Regression 4')\n\nplt.subplot(3,2,5)\nsns.histplot(y, element = \"step\", kde = \"true\");\nsns.histplot(reg5.predict(X5), color =\"orange\", element = \"step\");\nplt.title('Regression 5')","dfce6508":"Then, four regression models are replicated from the theory and it is established whether they are BLUE. Given what the theory indicates, a section is used to solve the problems found by solving an endogeneity problem by MC2E. Finally, the coefficients obtained from the model are discussed to finally establish conclusions on how the different factors evaluated in the models can provide important information in the improvement of countries competitiveness.","f28d11c9":"F4 is fulfilled. Because if we run a Bresuch-pagan, relying on statsmodel to evaluate if the errors are constant, we get the following result:","23a673ac":"As a first step, the CIP variable, which denotes competitive industrial performance, was tested for its relevance in the model. To this end, it was evaluated whether COV(Educ, CIP) is non-zero. ","6ec2e450":"## python model execution","8641432e":"<p style=\"text-align: center;\">   Competitiveness=\u03b21+ \u03b22educ <\/p>\n<p style=\"text-align: center;\">   Competitiveness=\u03b21+ \u03b22educ+B3Lnfdi <\/p>\n<p style=\"text-align: center;\">   Competitiveness=\u03b21+ \u03b22educ+B3Lnfdi+ \u03b24gdp <\/p>\n<p style=\"text-align: center;\">   Competitiveness=\u03b21+ \u03b22educ+B3Lnfdi+ \u03b24gdp+ \u03b25exports <\/p>\n\n","7f829811":"We can note that at the distribution level, regression 5 is the one that best fits the model. It should be noted that overfitting has not been evaluated, but this project seeks to explain in detail how a regression works and to make its results statistically significant.","4b3441b5":"First, four regressions are used in order to check if they are significant for the analysis and check the marginal effect of each of the variables. The contained model expresses the variables as follows:","05f8955a":"In this way it is verified through the resulting covariance very close to 0 that: the CIP variable is exogenous to the residuals and can be used in the model.","f22a0a82":"|Variable|Description|\n|:---:|:---:|\n|Competitiveness|Index given by the GCI|\n|Education|Average years of education|\n|GDP|Level of GDP measured in dollars|\n|LnFDI|Natural logarithm of foreign direct investment measured in dollars|\n|Exports|Measured in dollars|\n|CIP|Competitive Country Competitive Industrial Performance Weighting Index|\n","b1b774b6":"## Comparing distributions","4ed09fcd":"F2 is satisfied. If we extract the error statistics from the model (4) we get the following:","7def2e7b":"## Final Results","1257216f":"## Proxy definition of variables","a3d43b43":"# Competitiveness of countries | A regression application with Python","eb5e27a3":"The E(e) = 0 (mean) or near zero because the mean of the residuals is denoted as 7.85E-16 a number very close to zero. This also proves that the errors are being minimized and that the assumption that the expectation of the errors tends to zero causes the second criterion to be satisfied.","cdb5a326":"As expected, the factor most conducive to competitiveness is the CIP variable, followed by GDP and ending with foreign direct investment. This article discusses different influences on competitiveness and variables that lead to improvement in this area. However, there are still many other possible explanations for this phenomenon.","4958760d":"## Conclusions","22e296d7":"F3 is not satisfied. The errors are not independent of the education variable. First, because the competitiveness index is calculated through average education data in different countries, this causes a double causality between competitiveness and education. Second, the theory also suggests that competitiveness contains education as an endogenous variable (Baumann, 2014). Both statements lead us to the conclusion that the third criterion is not met and is causing the education coefficient to be biased. But despite this situation we proceeded to a solution that will be explained at the end of the criteria section.","f9ca117c":"## bibliography","5553f262":"Due to the presence of an endogenous variable, based on the literature, it was found that competitive industrial performance has an impact on the standards and development of education and at the same time is a good criterion to be used as an instrumental variable that serves as a channel to eliminate the existing dependence on errors. For this reason, we resorted to using an MC2E resolution that will allow us to solve, through two stages, the third criterion of the Gauss-Markov theorem.","aaf4b361":"## First interpretations","26f89c52":"Each column is each of the regressions evaluated. Each represents different results concerning the number of variables affecting the dependent variable. Considering the last regression containing all the variables (column 4) the results could be read as follows:\n\n- For an increase of one average year in education the competitiveness index would increase by 0.05.\n- If FDI increases by 1% the competitiveness index of a given country will increase by 2.72377e-12.\n- For one million dollars of additional gross domestic product the competitiveness index would increase by 2.45.\n- If the dollar value of a given country's exports increases by one million, the competitiveness index will also increase by 0.00000059.","3684f7b0":"- Baumann, C., & Winzar, H., (2016). The role of secondary education in\nexplaining competitiveness. Asia Pacific Journal of Education. Obtenido de https:\/\/www.tandfonline.com\/doi\/full\/10.1080\/02188791.2014.924387?casa_token=InimLZgOoJIAAAAA%3AtIJFQmiLREfUCPC3c4hQ9kPmuhFvBvbHtkeUGLNOzVQ6NULxtC3fpToLOXKFihegWqtEZP444kbna3c\n\n- Cann, O. (12 de Oct de 2016). \u00bfQu\u00e9 es la competitividad? Obtenido de: \nWorld Economic Forum: https:\/\/es.weforum.org\/agenda\/2016\/10\/que-es-la-competitividad\/\n\n- Porter, M. (1989). La Ventaja Competitiva de las Naciones. \n\n- Becker, G. (1983). El capital Humano. S.A. Madrid: Alianza Uni- versidad de Textos, Alianza Editorial.\n\n- Lombana Coy, J. (2012). Pertinencia de la educacio\u0301n en la competitividad. Barranquilla, Colombia: Revista del Instituto de Estudios en Educacio\u0301n Universidad del Norte.\n\n- Doryan, E. (1999). Educacio\u0301n y Competitividad en Centroame\u0301rica. Centro Latinoamericano para la Competitividad y el Desarrollo Sostenible, CLACDS.\n\n- West, E. (1993). Education and Competitiveness. Queens University, Canada: GCSPS Discussion Paper No. 93-02, 1993.Go- vernment and Competitiveness School of Policy Studies.\n\n","2cacfba5":"As a first glance we can observe that the best fitting distribution is regression 4, but we are not only looking for efficiency but also for it to be statistically significant. For now we have not observed any inference error, so we will continue to analyze if this model is a BLUE model which will denote if it is unbiased and that we will be choosing the model with the minimum variance. This will be done through the Gauss-Markov theorem so that we can see if the four criteria that this theorem establishes based on the model (4) are fulfilled.","09d66ac1":"## Fourth criterion","e2dabd08":"## Third criterion","396a9ca0":"## Data characteristics","2cf98b3d":"## Second criterion","87f1bf47":"## Prediction vs. testing across distributions","5d3d3557":"## Resolution of the third criterion","9078adaa":"## First criterion","4de98074":"|Data|Description|Countries taken into account|Source|\n|:---:|:---:|:---:|:---:|\n|GDP, PPP|It is a macroeconomic magnitude that expresses the monetary value of production expressed in dollars.|30 countries|World Bank database, available at: https:\/\/datos.bancomundial.org\/indicator\/NY.GDP.PCAP.KD.ZG|\n|Foreign direct investment, net capital inflow|This is the capital investment by a subject in a foreign country. Expressed in dollars.|30 countries|World Bank database, available at: https:\/\/datos.bancomundial.org\/indicador\/BX.KLT.DINV.CD.WD|\n|Exports of goods and services |Exports of goods and services are all goods and services sold by a country. Expressed in dollars.|30 countries|World Bank database, available at: datos.bancomundial.org\/indicator\/BX.GSR.GNFS.CD|\n|Average schooling (expressed in years)|The average number of years of schooling passed by the adult population in the country. Expressed in years|30 countries|United Nations Development Programme database, available at: http:\/\/hdr.undp.org\/en\/data|\n|Global Competitiveness Index (GCI) score| is a score obtained by rating 12 areas of a nation's economic activity. |30 countries|World Economic Forum database, available at: http:\/\/www3.weforum.org\/docs\/GCR2017-2018\/GCI_Dataset_2007-2017.xlsx|\n|Competitive Industrial Performance Index (CIP)| A score obtained by analyzing eight indicators of a country's industrial performance. |30 countries|United Nations Industrial Development Organization database, available at: https:\/\/stat.unido.org\/database\/CIP%202019|\n","d30f2654":"F1 is satisfied. Because no independent variable is explained through another independent variable. This is because we tried to avoid using variables related to GDP that could have caused the Rank assumption to fail. Education, gdp, lnfdi and exports are independent of each other, therefore, they satisfy the assumption that rank(x) = 0 and the first criterion is met.","35fc82f4":"- For an increase of one average year in education (through instrumental variable) the competitiveness index would increase by 2.3.\n- If FDI increases by 1% the competitiveness index of a given country will increase by 1.03428e-12.\n- For one million dollars of additional gross domestic product the competitiveness index would increase by 2.28.\n","fb77bb05":"This application aims to analyze how education, among other factors, influences a country's competitiveness. First, this paper evaluates the impact of variables such as GDP, foreign direct investment and exports on competitiveness measured as a proxy variable through the GCI (Global Competitive Index)","0c628b06":"And not only can it be solved through regression, there are many other models offered by keras that could solve this projection problem. Moreover, you can compare them and find the most efficient one!","7d3c6807":"As a result we get a non-rejection of the hypothesis test because the p-value is not less than 0.05 . By not rejecting it is affirmed that there is no heteroscedasticity which indicates that the coefficients are statistically significant. ","16b3a64f":"## Using Keras","d639d45c":"As a final result, the model (5) has the BLUE characteristics, satisfying the four criteria established by Gauss M\u00e1rkov. Exports lost its significance. And due to the low correlation strength in the first regression table, it was omitted from the analysis.\nTherefore, we can conclude the following:\n","2aa38c39":"With these results it can be affirmed that the relationship between education and the CIP variable is significant and therefore the covariance between the two is non-zero. Additionally, the variable was checked to see if it was exogenous so that the residuals were used to observe if the COV(errors, CIP) is equal to 0. The results were as follows:"}}