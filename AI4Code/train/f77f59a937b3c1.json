{"cell_type":{"f5a15bfb":"code","b325cee5":"code","b1c4f106":"code","3b531d86":"code","00c8f63d":"code","39cd6a55":"code","fbfa1b57":"code","fcf2132f":"code","67a24276":"code","2547bfd5":"code","aba1bd12":"code","9e5d4150":"code","fedd0b0d":"code","83608f8f":"code","39daf768":"code","fd8e2da3":"code","bbb9f12e":"code","02a6628d":"code","66726f01":"code","733006a5":"code","ab6063a3":"code","084d286c":"code","3aba907a":"code","435a2250":"code","c6962999":"code","c8fde38d":"code","032691df":"code","c7b4ab67":"code","946b4ad0":"code","07c37087":"code","203ab85d":"code","db9ad2a6":"code","f14b2970":"code","26fcbdd5":"code","0b9f8fc5":"code","7a2df598":"code","f4521c0e":"code","7b318373":"code","c47c4946":"code","e9490c62":"code","de5a33ac":"code","8e0e44c5":"code","2e2ab0c6":"code","1d7ec650":"code","35135deb":"code","3d8bdedf":"code","f91398de":"code","f3a8923e":"code","496d873f":"code","d3ea3a0d":"code","13044a14":"code","1947f85e":"code","9c27725f":"code","90a36d7e":"code","ac2cc84c":"code","c04ae877":"code","cbcdc369":"code","6e1a3570":"code","ba2b10a8":"code","65d940a1":"code","17dec6ac":"code","e00268b0":"code","8bf4eb4d":"code","1997d03c":"code","41b1c9e1":"code","f19d9593":"code","efe25112":"code","dd2ae2c5":"code","55372991":"code","8d0f1d12":"markdown","5443c36c":"markdown","035e4852":"markdown","a8cc565f":"markdown","60e77971":"markdown","732f705c":"markdown","c85448a2":"markdown","eb72d4be":"markdown","6fc7a34a":"markdown","e17a58b1":"markdown","c33c50f5":"markdown","d7a2d498":"markdown","d31d16ad":"markdown","7105f86d":"markdown","84a24eca":"markdown","b10ad830":"markdown","57c47305":"markdown","a8d1992a":"markdown","b17b4642":"markdown"},"source":{"f5a15bfb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b325cee5":"!pip install -U scikit-learn","b1c4f106":"import sklearn\nsklearn.__version__","3b531d86":"import matplotlib.pyplot as plt\nimport seaborn as sns\ndata = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nsubmission= pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","00c8f63d":"from IPython.display import Image\nImage(\"..\/input\/ai-image\/Data describe.png\")","39cd6a55":"Image(\"..\/input\/ai-image\/data describe 2.png\")","fbfa1b57":"test.head()","fcf2132f":"data.head()","67a24276":"submission.head()","2547bfd5":"print(data.shape) # size cua file train\n#print(test.shape) no need","aba1bd12":"data.info() # t\u1ed5ng quan v\u1ec1 d\u1eef li\u1ec7u","9e5d4150":"print(\"Data with null values\", data.isnull().sum()) # th\u1ed1ng k\u00ea nh\u1eefng gi\u00e1 tr\u1ecb null","fedd0b0d":"data.describe() ","83608f8f":"#plot numeric data type\nplottedCategorize= ['Survived', 'Pclass', 'Age', \"SibSp\", 'Parch','Fare']\ndata.hist(column=plottedCategorize, figsize=(15,10))\nplt.show()","39daf768":"#plot categorical data type\nsns.set(style=\"darkgrid\")\nfig, saxis = plt.subplots(1,2,figsize=(10,5))\nsns.countplot(x=\"Embarked\", data=data, ax= saxis[0])\nsns.countplot(x=\"Sex\", data=data, ax= saxis[1])","fd8e2da3":"#plot the correlation data","bbb9f12e":"# Drop the unecessary column\ndata_cleaned= data.drop(['Name', 'Ticket','Cabin','Survived'], axis=1)\nlabel= data['Survived']\ntest_cleaned = test.drop(['Name', 'Ticket', 'Cabin'], axis=1)","02a6628d":"# Divide the data 80 tran \/ 20 valid\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(data_cleaned, label, test_size=0.2, random_state=42)","66726f01":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_valid.shape)\nprint(y_valid.shape)","733006a5":"#building model\nfrom sklearn.pipeline import Pipeline # build pipeline\nfrom sklearn.impute import SimpleImputer #fill nan value by median\nfrom sklearn.preprocessing import OrdinalEncoder # map categoric to numeric\nfrom sklearn.preprocessing import StandardScaler # scale the numeric data\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin","ab6063a3":"# pipeline x\u1eed l\u00fd d\u1eef li\u1ec7u d\u1ea1ng s\u1ed1\nnum_pipeline= Pipeline([\n    ('imputer', SimpleImputer(strategy = 'median')), #thay gi\u00e1 tr\u1ecb null b\u1eb1ng median\n    ('std_scaler', StandardScaler()), # chu\u1ea9n h\u00f3a d\u1eef li\u1ec7u \n])","084d286c":"#pipeline x\u1eed l\u00fd d\u1eef li\u1ec7u d\u1ea1ng c\u1ed9t\ncat_pipeline= Pipeline([\n    ('imputer', SimpleImputer(strategy= 'most_frequent')), # thay gi\u00e1 tr\u1ecb null b\u1eb1ng gi\u00e1 tr\u1ecb xu\u1ea5t hi\u1ec7n th\u01b0\u1eddng xuy\u00ean\n    ('encoding', OrdinalEncoder()), # thay c\u00e1c k\u00ed t\u1ef1 b\u1eb1ng c\u00e1c s\u1ed1 \u0111\u1ea1i di\u1ec7n\n])\n","3aba907a":"X_train_num= data_cleaned.drop(['Embarked', 'Sex'], axis=1)","435a2250":"from sklearn.compose import ColumnTransformer\nnum_attribs= list(X_train_num)\ncat_attribs= [\"Embarked\", \"Sex\"]\nfull_pipeline= ColumnTransformer([(\"num\", num_pipeline, num_attribs),\n                                 (\"cat\", cat_pipeline, cat_attribs),\n                                 ])\n","c6962999":"X_train_prepared = full_pipeline.fit_transform(X_train)\nX_valid_prepared = full_pipeline.transform(X_valid)","c8fde38d":"from sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.svm import NuSVC\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","032691df":"#create model list\nmodelList= [\n    BernoulliNB(),\n    GaussianNB(),\n    KNeighborsClassifier(),\n    SVC(probability=True),\n    NuSVC(probability=True),\n    LinearSVC(),\n    DecisionTreeClassifier(),\n]","c7b4ab67":"#metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import ConfusionMatrixDisplay\nimport time","946b4ad0":"print(X_valid.shape)\nprint(y_valid.shape)","07c37087":"model_info= ['model name', 'model parameters','model accuracy','f1_score','time consuming']\nmodel_info_compare= pd.DataFrame(columns= model_info)\n\nmodel_predict= pd.DataFrame()\n\nrow_index= 0\nfor m in modelList:\n    model_name= m.__class__.__name__\n    model_info_compare.loc[row_index, 'model name']= model_name\n    model_info_compare.loc[row_index, 'model parameters']= str(m.get_params())\n    start_time = time.time()\n    m.fit(X_train_prepared, y_train)\n    finish_time = time.time() - start_time\n    model_predict[model_name]= m.predict(X_valid_prepared)\n    model_info_compare.loc[row_index, 'model accuracy']= accuracy_score(y_valid,model_predict[model_name])\n    model_info_compare.loc[row_index, 'time consuming']= finish_time\n    model_info_compare.loc[row_index, 'f1_score']= f1_score(y_valid, model_predict[model_name])\n    row_index+=1\n    \n#model_info_compare.sort_values(by = 'model accuracy', ascending= False, inplace= True)\nmodel_info_compare","203ab85d":"model_info_compare= model_info_compare.astype({'model accuracy': 'float64','time consuming': 'float64','f1_score': 'float64'})","db9ad2a6":"#save d\u1eef li\u1ec7u\nmodel_info_compare.to_csv('.\/model_info_compare.csv')","f14b2970":"model_info_compare.info()","26fcbdd5":"# visualizing model accuracy\nfig, ax = plt.subplots(figsize=(10,5))\ng = sns.lineplot(x='model name',  y='model accuracy', data= model_info_compare, ax=ax,hue = 'model name',marker='o', markersize=10,legend= False)\nax2 = ax.twinx()\ng = sns.barplot(x='model name',  y='time consuming', data=model_info_compare, ax=ax2,alpha=.5)\nax.set_title('accuracy vs time consuming', fontsize = 17)\n\nfig.legend(labels=model_info_compare['model name'])\n#plt.tight_layout()\n\nplt.show()","0b9f8fc5":"sns.barplot(x='time consuming', y='model name', data= model_info_compare)\nplt.show()","7a2df598":"sns.barplot(x='model accuracy', y='model name', data= model_info_compare)\nplt.show()","f4521c0e":"sns.barplot(x='f1_score', y='model name', data= model_info_compare)\nplt.show()","7b318373":"# visualizing heat map\nfig, axes = plt.subplots(ncols= 7, figsize=(20,7), sharey='row')\nfor ax, i in zip(axes, model_predict.columns):\n    cf_matrix = confusion_matrix(y_valid, model_predict[i])\n    heatmap= ConfusionMatrixDisplay(cf_matrix, display_labels= None)\n    heatmap.plot(ax= ax, xticks_rotation= 45)\n    heatmap.ax_.set_title(i)\n    heatmap.im_.colorbar.remove()\n    heatmap.ax_.set_xlabel('')\n\nfig.text(0.4, 0.1, 'Predicted label', ha='left')\nplt.subplots_adjust(wspace=0.40, hspace=0.1)\n\n\nfig.colorbar(heatmap.im_, ax=axes)\nplt.show()","c47c4946":"#shuffle the data\ndata_optimized= data.copy()","e9490c62":"#create regex for title\nimport re\ntitle= re.compile(r' ([A-Z][a-z]+)\\.')\ntitle_list= data['Name'].apply(lambda x: title.search(x).group(1))","de5a33ac":"plt.figure(figsize=(15,7))\nsns.countplot(y=title_list)","8e0e44c5":"data_optimized['Name']= title_list","2e2ab0c6":"data_optimized['Name'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndata_optimized[\"Name\"] = data_optimized[\"Name\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndata_optimized['Name']=data_optimized['Name'].fillna(4)","1d7ec650":"def familyFilter(x):\n    if x['SibSp'] + x['Parch'] >1:\n        return 1\n    else:\n        return 0","35135deb":"data_optimized['Have family']= data_optimized.apply(familyFilter, axis=1)","3d8bdedf":"data_optimized= pd.get_dummies(data_optimized, columns=['Embarked'], prefix='E')","f91398de":"data_optimized.info()","f3a8923e":"data_optimized= data_optimized.drop(['Survived','Cabin','Ticket'], axis=1)","496d873f":"# Divide the data 80 tran \/ 20 valid\nfrom sklearn.model_selection import train_test_split\nX_train_op, X_valid_op, y_train_op, y_valid_op = train_test_split(data_optimized, label, test_size=0.2, random_state=42)","d3ea3a0d":"X_train_num_op= data_optimized.drop([\"Sex\"], axis=1)","13044a14":"X_train_op.head()","1947f85e":"print(list(X_train_num_op))","9c27725f":"cat_pipeline= Pipeline([\n    ('imputer', SimpleImputer(strategy= 'most_frequent')),\n    ('encoding', OrdinalEncoder()),\n])\n","90a36d7e":"num_attribs= list(X_train_num_op)\ncat_attribs= [\"Sex\"]\nfull_pipeline= ColumnTransformer([(\"num\", num_pipeline, num_attribs),\n                                 (\"cat\", cat_pipeline, cat_attribs),\n                                 ])","ac2cc84c":"X_train_prepared_op = full_pipeline.fit_transform(X_train_op)\nX_valid_prepared_op = full_pipeline.transform(X_valid_op)","c04ae877":"#ghi k\u1ebft qu\u1ea3 v\u00e0o b\u1ea3ng\nmodel_info= ['model name', 'model parameters','model accuracy','f1_score','time consuming']\nmodel_info_compare_op= pd.DataFrame(columns= model_info)\n\nmodel_predict= pd.DataFrame()\n\nrow_index= 0\nfor m in modelList:\n    model_name= m.__class__.__name__\n    model_info_compare_op.loc[row_index, 'model name']= model_name\n    model_info_compare_op.loc[row_index, 'model parameters']= str(m.get_params())\n    start_time = time.time()\n    m.fit(X_train_prepared_op, y_train_op)\n    finish_time = time.time() - start_time\n    model_predict[model_name]= m.predict(X_valid_prepared_op)\n    model_info_compare_op.loc[row_index, 'model accuracy']= accuracy_score(y_valid_op,model_predict[model_name])\n    model_info_compare_op.loc[row_index, 'time consuming']= finish_time\n    model_info_compare_op.loc[row_index, 'f1_score']= f1_score(y_valid, model_predict[model_name])\n    row_index+=1\n    \n#model_info_compare.sort_values(by = 'model accuracy', ascending= False, inplace= True)\nmodel_info_compare_op","cbcdc369":"model_info_compare_op.to_csv('.\/model_info_compare_op.csv')","6e1a3570":"# visualizing heat map\nfig, axes = plt.subplots(ncols= 7, figsize=(20,7), sharey='row')\nfor ax, i in zip(axes, model_predict.columns):\n    cf_matrix = confusion_matrix(y_valid, model_predict[i])\n    heatmap= ConfusionMatrixDisplay(cf_matrix, display_labels= None)\n    heatmap.plot(ax= ax, xticks_rotation= 45)\n    heatmap.ax_.set_title(i)\n    heatmap.im_.colorbar.remove()\n    heatmap.ax_.set_xlabel('')\n\nfig.text(0.4, 0.1, 'Predicted label', ha='left')\nplt.subplots_adjust(wspace=0.40, hspace=0.1)\n\n\nfig.colorbar(heatmap.im_, ax=axes)\nplt.show()","ba2b10a8":"compare_table= pd.DataFrame()\ncompare_table['model name']= model_info_compare['model name']\ncompare_table['model accuracy']= model_info_compare_op['model accuracy'] - model_info_compare['model accuracy']\ncompare_table['f1_score']= model_info_compare_op['f1_score'] - model_info_compare['f1_score']\ncompare_table['time consuming']= model_info_compare_op['time consuming'] - model_info_compare['time consuming']","65d940a1":"compare_table","17dec6ac":"from sklearn.model_selection import GridSearchCV","e00268b0":"SVCclf = GridSearchCV(SVC(probability=True), {\n    'gamma' : [0.001,0.1,0.2, 1, 10],\n    'C' : [0.1, 1, 10, 100],\n    'kernel' : ['linear', 'rbf']\n}, cv = 4, return_train_score = False)\n\nSVCclf.fit(X_train_prepared, y_train)\ndframe = pd.DataFrame(SVCclf.cv_results_)\ndframe[['param_C', 'param_gamma', 'param_kernel', 'mean_test_score']]","8bf4eb4d":"SVCclf = GridSearchCV(SVC(probability=True), {\n    'gamma' : [0.001,0.1,0.2, 1, 10],\n    'C' : [0.1, 1, 10, 100],\n    'kernel' : ['linear', 'rbf']\n}, cv = 4, return_train_score = False)\n\nSVCclf.fit(X_train_prepared_op, y_train_op)\ndframe = pd.DataFrame(SVCclf.cv_results_)\ndframe[['param_C', 'param_gamma', 'param_kernel', 'mean_test_score']]","1997d03c":"KNNclf=  GridSearchCV(KNeighborsClassifier(), {'n_neighbors': [4,5,6],'weights': ('uniform', 'distance')})\nKNNclf.fit(X_train_prepared, y_train)\ndframe2 = pd.DataFrame(KNNclf.cv_results_)\ndframe2[['param_n_neighbors', 'param_weights', 'mean_test_score']]","41b1c9e1":"KNNclf=  GridSearchCV(KNeighborsClassifier(), {'n_neighbors': [4,5,6],'weights': ('uniform', 'distance')})\nKNNclf.fit(X_train_prepared_op, y_train_op)\ndframe2 = pd.DataFrame(KNNclf.cv_results_)\ndframe2[['param_n_neighbors', 'param_weights', 'mean_test_score']]","f19d9593":"GNBclf = GridSearchCV(GaussianNB(), {\n    'var_smoothing' : [1e-9, 0.001, 0.01, 0.1, 1, 10]}, \n                      cv = 4, return_train_score = False)\nGNBclf.fit(X_train_prepared, y_train)\ndframe3 = pd.DataFrame(GNBclf.cv_results_)\ndframe3[['param_var_smoothing', 'mean_test_score']]","efe25112":"GNBclf = GridSearchCV(GaussianNB(), {\n    'var_smoothing' : [1e-9, 0.001, 0.01, 0.1, 1, 10]}, \n                      cv = 4, return_train_score = False)\nGNBclf.fit(X_train_prepared_op, y_train_op)\ndframe3 = pd.DataFrame(GNBclf.cv_results_)\ndframe3[['param_var_smoothing', 'mean_test_score']]","dd2ae2c5":"BNBclf = GridSearchCV(BernoulliNB(), {'alpha' : [0.1, 1, 10, 100]}, cv = 4, return_train_score = False)\nBNBclf.fit(X_train_prepared, y_train)\ndframe4 = pd.DataFrame(BNBclf.cv_results_)\ndframe4[['param_alpha', 'mean_test_score']]","55372991":"BNBclf = GridSearchCV(BernoulliNB(), {'alpha' : [0.1, 1, 10, 100]}, cv = 4, return_train_score = False)\nBNBclf.fit(X_train_prepared_op, y_train_op)\ndframe4 = pd.DataFrame(BNBclf.cv_results_)\ndframe4[['param_alpha', 'mean_test_score']]","8d0f1d12":"B\u1ea5t c\u1ee9 ai c\u00f3 SibSp ho\u1eb7c Parch th\u00ec \u0111\u1ec1u quy v\u1ec1 c\u00f3 gia \u0111\u00ecnh","5443c36c":"# **C\u1ea5u tr\u00fac b\u1ea3ng d\u1eef li\u1ec7u**","035e4852":"1. SVM","a8cc565f":"2. KNN","60e77971":"4. D\u1ea1ng d\u1eef li\u1ec7u sau khi ch\u1ec9nh s\u1eeda","732f705c":"Chuy\u1ec3n 3 n\u01a1i g\u1eb7p th\u00e0nh 3 h\u00e0ng","c85448a2":"# Tunning hyperparameter","eb72d4be":"# Optimizing dataset","6fc7a34a":"1. Name and titles","e17a58b1":"\u00fd t\u01b0\u1edfng >> c\u1eaft t\u00ean ri\u00eang, l\u1ea5y nh\u1eefng ch\u1ee9c danh xu\u1ea5t hi\u1ec7n nhi\u1ec1u","c33c50f5":"# 1. T\u1ed5ng quan v\u1ec1 d\u1eef li\u1ec7u\n","d7a2d498":"# So s\u00e1nh c\u00e1c model","d31d16ad":"3. Embarked","7105f86d":"# Training model on optimized data","84a24eca":"# Kh\u1edfi t\u1ea1o h\u1ec7 th\u1ed1ng","b10ad830":"2. Family","57c47305":"# Compare two table","a8d1992a":"3. Bayes","b17b4642":"# Ph\u00e2n t\u00edch v\u00e0 l\u00e0m s\u1ea1ch d\u1eef li\u1ec7u"}}