{"cell_type":{"8779ee59":"code","4ddc2a78":"code","75f14903":"markdown","33a71ac0":"markdown","25e26e02":"markdown","cc4f16ba":"markdown","2e9faefe":"markdown","a9229965":"markdown","feee6481":"markdown","c0adce6e":"markdown","b8202190":"markdown","e28c7636":"markdown","58239108":"markdown","8cb8ca2f":"markdown","4a69d35f":"markdown","afd45665":"markdown","becbdff5":"markdown","5b8789b4":"markdown","3ad3f4bb":"markdown","40b9cfa9":"markdown","ba5434c1":"markdown","92b47044":"markdown","ebad1468":"markdown","7b36572b":"markdown"},"source":{"8779ee59":"# exampe of feed-forward neural network(FFNN) from scratch with numpy\n# find more different ML models in Math of Intelligence course by Siraj Raval\n\nimport numpy as np\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\n\n\nclass FFNNetwork:\n  \n  #initialize number of networks inputs list of hidden neurons number in each layer\n  def __init__(self, n_inputs, hidden_sizes=[2]):\n    #intialize the inputs\n    self.nx = n_inputs\n    self.ny = 1\n    self.nh = len(hidden_sizes)\n    self.sizes = [self.nx] + hidden_sizes + [self.ny]\n    \n    self.W = {}\n    self.B = {}\n    for i in range(self.nh+1):\n      self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n      self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n  \n  # just a simple sigmoid activation function\n  def sigmoid(self, x):\n    return 1.0\/(1.0 + np.exp(-x))\n  \n  \n  # initialize weights and biases as W and H dictionaries\n  def forward_pass(self, x):\n    self.A = {}\n    self.H = {}\n    self.H[0] = x.reshape(1, -1)\n    for i in range(self.nh+1):\n      # compute A and H as pre- and past- processing activation\n      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]\n      self.H[i+1] = self.sigmoid(self.A[i+1])\n    return self.H[self.nh+1]\n  \n  \n  # compute sigmoid gradient\n  def grad_sigmoid(self, x):\n    return x*(1-x) \n  \n  \n  # compute the partial derivatives of the parameters with respect to the loss function\n  def grad(self, x, y):\n    self.forward_pass(x)\n    self.dW = {}\n    self.dB = {}\n    self.dH = {}\n    self.dA = {}\n    L = self.nh + 1\n    self.dA[L] = (self.H[L] - y)\n    for k in range(L, 0, -1):\n      self.dW[k] = np.matmul(self.H[k-1].T, self.dA[k])\n      self.dB[k] = self.dA[k]\n      self.dH[k-1] = np.matmul(self.dA[k], self.W[k].T)\n      self.dA[k-1] = np.multiply(self.dH[k-1], self.grad_sigmoid(self.H[k-1]))\n  \n  \n  # update weights -> add a bias -> activate\n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, display_loss=False):\n    \n    # initialise w, b\n    if initialise:\n      for i in range(self.nh+1):\n        self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n        self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n      \n    if display_loss:\n      loss = {}\n    \n    for e in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n      dW = {}\n      dB = {}\n      for i in range(self.nh+1):\n        dW[i+1] = np.zeros((self.sizes[i], self.sizes[i+1]))\n        dB[i+1] = np.zeros((1, self.sizes[i+1]))\n      for x, y in zip(X, Y):\n        self.grad(x, y)\n        for i in range(self.nh+1):\n          dW[i+1] += self.dW[i+1]\n          dB[i+1] += self.dB[i+1]\n        \n      m = X.shape[1]\n      for i in range(self.nh+1):\n        self.W[i+1] -= learning_rate * dW[i+1] \/ m\n        self.B[i+1] -= learning_rate * dB[i+1] \/ m\n      \n      if display_loss:\n        Y_pred = self.predict(X)\n        loss[e] = mean_squared_error(Y_pred, Y)\n    \n    if display_loss:\n      plt.plot(loss.values())\n      plt.xlabel('Epochs')\n      plt.ylabel('Mean Squared Error')\n      plt.show()\n  \n  \n  #compute the predicted value for each input by calling the forward_pass\n  def predict(self, X):\n    Y_pred = []\n    for x in X:\n      y_pred = self.forward_pass(x)\n      Y_pred.append(y_pred)\n    return np.array(Y_pred).squeeze()","4ddc2a78":"# example of FFNN in pytorch is like a plain english\n\nimport torch.nn as nn\n\n\nclass FeedforwardNeuralNetModel(nn.Module):\n  \n    #initialize input, hidden and output dimensions size\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(FeedforwardNeuralNetModel, self).__init__()\n        # fc stands for fully connected layer\n        self.fc1 = nn.Linear(input_dim, hidden_dim) \n\n        self.sigmoid = nn.Sigmoid()\n\n        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n\n        \n    def forward(self, x):\n        out = self.fc1(x)\n\n        out = self.sigmoid(out)\n\n        out = self.fc2(out)\n        return out","75f14903":"\n\n---\n\n","33a71ac0":"\n\n---\n\n","25e26e02":"# Computer Vision","cc4f16ba":"![](https:\/\/www.swri.org\/sites\/default\/files\/styles\/client_services_banner\/public\/client-services-images\/AdobeStock_42876724.jpeg?itok=FKjLMb09&c=21e5097a3ed82d41e2e62e5ba0f42a11)\n\nI will be surprised if you heard before this article something about the ML in DSP. So lets mention what is DSP in the context of ML.\n\nDigital Signal Processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations.\n\nSo most of the tasks will be related with another domains:\n\n*   Speech recognition (NLP)\n*   Get streaming video from camera and use CV\n*   Recommendations based on sensors data\n\nThe most popular courses in this domain are [ee269 from Stanford](http:\/\/web.stanford.edu\/class\/ee269\/) and [IBM on Coursera](https:\/\/ru.coursera.org\/learn\/advanced-machine-learning-signal-processing) .\n\nFor me this topic is the dark forest, so I can`t provide blogs for this domain, I will be so grateful if you write it in comments)\n\n\n","2e9faefe":"![](https:\/\/www.wallpaperup.com\/uploads\/wallpapers\/2014\/08\/25\/428197\/d0b4fb377785574eb6cc63b2c9e5c3ac.jpg)\n\nIn conclusion, I want to say that  you should read new papers about new architectures and try to implement them to see its effectiveness, because many state-of-the-art(SOTA) algorithms are useless in production or won't be useful in Kaggle competition. \n\nMoreover, Kaggle Competitions are a good way to learn. Especially because you can try a problem, and then see how your approach compares to others (since so many people publish their work in easily accessible \u201ckernel notebooks\u201d). And by teaming you can meet new cool data scientists from whom you can learn  a lot of useful things about Kaggle and real projects and fill up you contacts.\n\nMore, you can visit your local meetups for getting new info about actual technologies or production-ready solutions or listen about somebody's fuckups or success and don't hestitate to ask a questions to the speaker and stay in the networking sessions, because you can meet very skilled Data Scientists(even Kaggle Masters) make new friends and useful connections or even find a menthor.","a9229965":"# Conclusion","feee6481":"# Digital Signal Processing","c0adce6e":"![alt text](https:\/\/wallpaperstream.com\/wallpapers\/full\/mountain\/Stubai-Glacier-Snowy-Mountains-Wallpaper-HD.jpg)\n","b8202190":"Write your feedback in the comments and any ideas about improvements. Please upvote this kernel, if you like it.","e28c7636":"# What to do after mlcourse ending?","58239108":"![](http:\/\/www.themtank.org\/images\/c-image12.jpg)\n\nComputer Vision  gain high level understanding, so we seek to automate with it routine tasks that the human visual system can do. \n\nCV tasks cover :\n\n*   Mentioned on the photo\n*   Recognition(face, person re-id and and actions)\n*   Object tracking\n*   Crowd detection\n*   Pose estimation (find connections between body parts)\n*   Image Question Answering (by finding objects on the picture)\n*   Enhancement and Restoration (Rick and Morty from HD to 4K)\n*   Picture generation([lNvidia doodle to realistic landscape GAN](https:\/\/youtu.be\/p5U4NgVGAwg))\n\nMeet in this [article](https:\/\/https:\/\/heartbeat.fritz.ai\/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b)  proficient Computer Vision techniques dedicated to above topics.\n\nThe most remarkable courses for Computer Vision are[ c231n from Stanford](http:\/\/cs231n.stanford.edu\/) and [Introduction to Computer Vision by Georgia Tech on Udacity](https:\/\/www.udacity.com\/course\/introduction-to-computer-vision--ud810). \n\nAlso,  you can read cool blogs with bunch of CV stuff from [Google AI](https:\/\/ai.googleblog.com\/), [Facebook Research](https:\/\/research.fb.com\/category\/computer-vision\/) and [Piekniewski](http:\/\/blog.piekniewski.info\/)\n","8cb8ca2f":"But all of these domains have a common part and prerequisites to use up-to-date solutions, guess that it may be basic neural networks(NN), you are right!","4a69d35f":"![](https:\/\/www.ontotext.com\/wp-content\/uploads\/2017\/01\/NLP-768x356.png)\n\nNLP consists of numerous of text related tasks that we use so frequent:\n\n*   Machine Translation (hi, Google Translate!)\n*   Question Answering (so popular in chatbots)\n*   Sentiment Analysis (Good, neutral or bad comment)\n*   Part Of Speech Tagging(detect noun or objective)\n*   Named Entity Recognition (Find location, persons in text)\n    \nand many others that can be find [there](https:\/\/natural-language-understanding.fandom.com\/wiki\/List_of_natural_language_processing_tasks).\n\n*For NLP learning I advise to pass [cs224n from Stanford](https:\/\/http:\/\/web.stanford.edu\/class\/cs224n\/) that will be soon updated with new NLP architectures or if you can afford it [Udacity NLP Nanodegree](https:\/\/www.udacity.com\/course\/natural-language-processing-nanodegree--nd892) .*\n\n*Also, strongly recommend to read one of the biggest NLP blog by [Sebastian Ruder](http:\/\/ruder.io\/).\nThe latest architectures like ULMFit, OpenGPT2 and BERT are described in this [blog by Jay Alammar](https:\/\/jalammar.github.io\/) .* ","afd45665":"In the end of the course I wanna say great thank you to the organizers - [@yorko](https:\/\/https:\/\/www.kaggle.com\/kashnitsky) and the company. They do really a honorable thing, because they have helped a thousands of people to cope with ML by practical learning, don't forget to write them a couple of gratitude words. And thanks to mlcourse I find Data Science Internship in NLP domain that I am interested in.\n\nAlso, I want to give thanks to my course mates, we learn a lot one from another with Kaggle competitions, tutorial kernels and slack chatting and meet new interesting folks and made new friends)","becbdff5":"It is a great time to think about new course after ending actual one. In [mlcourse](https:\/\/mlcourse.ai) we get a great basis. We learn a lot about *classic linear and tree-based ML models*, work with different type of data, understand *feature extraction, selection* and its difference , why *pre-processing* and *cross-validation* is so important. **But when you reach the peak of a mountain, it's time to scale another one, right? **","5b8789b4":"# Prerequisites for passing to choosen domain","3ad3f4bb":"I think that after numpy from scratch implementation you will get deep understanding how this model works, after pytorch one you' ll see how  it works and constructed in context of DL framework.","40b9cfa9":"# General or Focused","ba5434c1":"![a](http:\/\/yesofcorsa.com\/wp-content\/uploads\/2018\/02\/Neural-Network-Art-Wallpaper-1080p.jpg)\nYou wanna see domain chosen materials and links to the courses, of course, you can. *But we must learn to walk before we can run. As a Data Scientist or ML Engineers we should cover the culture of development,  DNN understanding,  CI\/CD, model deployment,  DevOps monitoring and etc.*\n\nBut lets talk more about neural networks, we need learn enough of them to understand and implement(from scratch or with tensorflow\/pytorch) [basic neural networks](https:\/\/www.kdnuggets.com\/2018\/02\/8-neural-network-architectures-machine-learning-researchers-need-learn.html)  such as:\n\n*   One and multi layer perceptron\n*   Feed-Forward\n*  Symmetrically Connected\n*  Convolutional\n*  Recurrent(and its subtype LSTM)\n\nOf course, you should have good understand of math behind the NN works, it can be gained with [math deep learning book](https:\/\/www.deeplearningbook.org\/).\n\n***For those who prefer Russian-speaking courses I would recommend to pass [dlcourse.ai](https:\/\/dlcourse.ai). You can find a lot of courses about Deep Learning, but the most bright are [dlcourse.ru](https:\/\/dlcourse.ru) (from Carnegie Mellon University and [ods.ai](https:\/\/ods.ai)) and [Coursera specification from deeplearning.ai](https:\/\/https:\/\/ru.coursera.org\/specializations\/deep-learning). Also you can watch Deep Learning video courses from YouTube from [Siraj Raval](https:\/\/https:\/\/www.youtube.com\/playlist?list=PL2-dafEMk2A7YdKv4XfKpfbTH5z6rEEj3) or [sentdex](https:\/\/https:\/\/www.youtube.com\/playlist?list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN) as an interesting practical tasks.  I can't consider them as good as MOOC, because they will be without kaggle in-class competions and homeworks may seem to be unneccessary and you will not keep touch with course community like in MOOC.***\n","92b47044":"I meet a lot of people and see even more job positions like *Machine or Deep Learning Engineer* where employer wants to find a \"universal soldier\".  For example, you can work on domain X and then switch to Y or you like both and don`t want to order between them.\n\nOr you can *find another way* and order one of the following domains:\n\n*   **NLP** (Question Answering, Sentiment Analysis and etc.)\n*   **Computer Vision** (Image-video recognition, segmentation)\n*   **Digital Signal Processing** (Sensor data and many-many signals)\n*   **Recommendation systems**\n\nAlso, you can try to play with Reinforcement learning :)","ebad1468":"# Natural Language Processing","7b36572b":"![Select your path](https:\/\/lightbulbmanifesto.files.wordpress.com\/2012\/11\/morpheus.jpg?w=620)\n\nSelect one or make a trick and get both with Kaggle competions and\/or pet-projects!"}}