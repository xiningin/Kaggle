{"cell_type":{"9fa48be8":"code","752b61db":"code","e9c811d4":"code","c3412871":"code","9cd1622a":"code","63fa55e6":"code","047fdc58":"code","2f62d534":"code","5972b9e6":"code","86d24427":"code","dd6862d4":"code","789f0e71":"code","de389959":"code","ae5c69c0":"code","179abd7f":"code","908dad26":"code","2b63a914":"code","c603452c":"code","69344f00":"code","c4a76030":"code","3544e4fa":"code","983cb628":"code","8ea14e8f":"markdown","e5785eeb":"markdown","f8ce74ae":"markdown","3d3e9d10":"markdown","ab920323":"markdown","b0667aed":"markdown","2f26c582":"markdown","882c4285":"markdown","2d26389e":"markdown","f11dba04":"markdown","cc3acfd8":"markdown","ad2a7bf7":"markdown","6eb55410":"markdown","f57ef484":"markdown","ec184330":"markdown","40b40708":"markdown","a248097a":"markdown","742c7993":"markdown"},"source":{"9fa48be8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","752b61db":"df = pd.read_csv('..\/input\/chocolatecsv\/chocolate.csv',na_values='\\xa0')","e9c811d4":"b = pd.DataFrame(df.isnull().sum(), columns= ['Number of missing values'])\nb","c3412871":"df.head()","9cd1622a":"plt.figure(figsize=(8,6))\nsns.distplot(df['Rating'],bins=5,color='brown')","63fa55e6":"df['Cocoa % as num'] = df['Cocoa\\nPercent'].apply(lambda x: x.split('%')[0])\ndf['Cocoa % as num'] = df['Cocoa % as num'].astype(float)","047fdc58":"plt.figure(figsize=(12,6))\nsns.distplot(df['Cocoa % as num'],bins=20,color='Brown')","2f62d534":"df['Review\\nDate'] = df['Review\\nDate'].astype(str)\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x='Review\\nDate', y='Rating',data=df)","5972b9e6":"fig, (ax1, ax2, ax3) = plt.subplots(nrows=3,figsize=(12,15))\n\n\na = df.groupby(['Company\\nLocation'])['Rating'].mean()\na = a.sort_values(ascending=False)\n\nb = df.groupby(['Company\\nLocation'])['Rating'].median()\nb = b.sort_values(ascending=False)\n\na = pd.DataFrame(a)\nb = pd.DataFrame(b)\n\nRatings_by_location = a.join(b, how='left',lsuffix='_mean', rsuffix='_median')\nRatings_by_location['Mean-Median'] = Ratings_by_location['Rating_mean']-Ratings_by_location['Rating_median']\nRating_difference = sns.barplot(x=Ratings_by_location.index,y=Ratings_by_location['Mean-Median'], ax = ax3)\nRating_difference.set_xticklabels(labels = Ratings_by_location.index, rotation =90)\nRating_difference.set_ylabel(\"Mean-Median of ratings\")\n\n\n#plt.figure(figsize=(12,6))\nratings_mean = sns.barplot(x=Ratings_by_location.index,y=Ratings_by_location['Rating_mean'],ax=ax1)\nratings_mean.set_xticklabels(labels = Ratings_by_location.index, rotation =90)\nratings_mean.set_ylabel(\"Mean of Ratings\")\n\n\n#plt.figure(figsize=(12,6))\nratings_median = sns.barplot(x=Ratings_by_location.index,y=Ratings_by_location['Rating_median'], ax = ax2)\nratings_median.set_xticklabels(labels = Ratings_by_location.index, rotation =90)\nratings_median.set_ylabel(\"Median of ratings\")\n\nplt.tight_layout()","86d24427":"plt.figure(figsize=(12,6))\n\nc = df.groupby(['Company\\nLocation'])['Cocoa % as num'].mean()\nc = c.sort_values(ascending=False)\n\nratings = sns.barplot(x=c.index,y=c)\nratings.set_xticklabels(labels = c.index, rotation =90)","dd6862d4":"\nfig, (ax1, ax2) = plt.subplots(ncols=2,figsize=(12,15))\n\ne = df.groupby(['Bean\\nType'])['Rating'].mean()\ne = e.sort_values(ascending=False)\nRating_beanType = sns.barplot(y=e.index,x=e,ax = ax1)\n\n\nf = df.groupby(['Broad Bean\\nOrigin'])['Rating'].mean()\nf = f.sort_values(ascending=False)\nRating_broadbean = sns.barplot(y=f.index,x=f,ax = ax2)\n\nplt.tight_layout()","789f0e71":"df1 = df[['Cocoa % as num','Rating','Review\\nDate']]","de389959":"#non_numerical_columns = ['Review\\nDate','Bean\\nType', 'Broad Bean\\nOrigin','Company\\nLocation']\n\nnon_numerical_columns = ['Review\\nDate']\n\nfor i in non_numerical_columns:\n    x1 = pd.get_dummies(df1[i])\n    df1 = df1.join(x1,lsuffix='_l',rsuffix='_r')\n    df1.drop(i,axis=1,inplace=True)","ae5c69c0":"from sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler","179abd7f":"df_num = StandardScaler().fit_transform(df1)","908dad26":"A = []\nB = []\nC = []\n\nfor i in np.linspace(0.1,5,50):\n    db = DBSCAN(eps=i, min_samples=10).fit(df_num)\n\n    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n    core_samples_mask[db.core_sample_indices_] = True\n    labels = db.labels_\n    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n    \n    sum = 0\n    for t in labels:\n        if t == -1: \n            sum = sum + 1\n    C.append(sum)\n            \n    \n    \n    A.append(i)\n    B.append(int(n_clusters_))","2b63a914":"results = pd.DataFrame([A,B,C]).T\nresults.columns = ['distance','Number of clusters','Number of outliers']\nresults.plot(x='distance',y='Number of clusters',figsize=(10,6))","c603452c":"db = DBSCAN(eps=1, min_samples=10).fit(df_num)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_clusters_","69344f00":"df = df.join(pd.DataFrame(labels))\ndf = df.rename(columns={0:'Cluster'})\n\ndf['Cluster'].value_counts()","c4a76030":"df_clusters = df.groupby('Cluster')['Rating','Cocoa % as num']\ndf_clusters.describe()","3544e4fa":"fig, (ax1,ax2) = plt.subplots(nrows = 2,figsize=(12,12))\n\nplt.figure(figsize=(12,8))\nplot1 = sns.boxplot(x=df['Cluster'],y=df['Rating'],data=df, ax = ax1)\n\n\nplt.figure(figsize=(12,8))\nplot2 = sns.boxplot(x=df['Cluster'],y=df['Cocoa % as num'],data=df, ax= ax2)","983cb628":"plt.figure(figsize=(16,12))\nX = df_num\n\nunique_labels = set(labels)\ncolors = [plt.cm.Spectral(each)\n          for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = [0, 0, 0, 1]\n\n    class_member_mask = (labels == k)\n\n    xy = X[class_member_mask & core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=14)\n\n    xy = X[class_member_mask & ~core_samples_mask]\n    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=6)\n\nplt.title('Estimated number of clusters: %d' % n_clusters_)\nplt.show()","8ea14e8f":"Lets looks at the Cocoa percentage used in Chocolates in different countries. \nFrom the below chart, the distribution of cocoa varied from 40% to around 80% in our dataset. ","e5785eeb":"Standardizing the data is key for most of the clustering techniques to avoid a feature biasing the results of clustering","f8ce74ae":"labels are the label of the clusters.\nIf the label is -1, then the observation is an outlier\/noise within our dataset.\n\n\ndb.core_sample_indices_   are the indices of the core points in the cluster, the indices that are excluded here are of outliers and the edges of the clusters","3d3e9d10":"Cocoa is a key ingredient of any chocolate. Now, lets look at the distribution of cocoa percentage.\nAs expected, we see that the distribution of cocoa percentage in chocolates is normally distributed with a majority of the chocolates having 70% of cocoa.","ab920323":"Soon to be added: Will try to spot anomalies in this dataset using techniques like DBScan.\n\nWe have chosen Cocoa percentage, Review date, Rating, Broad bean origin, Company location to be included in the training data for our clustering model.\n\nThe clustering technique we will be using is DBScan\n\nDensity-based spatial clustering of applications with noise (DBSCAN) is a data clustering algorithm proposed by Martin Ester, Hans-Peter Kriegel, J\u00f6rg Sander and Xiaowei Xu in 1996. It is a density-based clustering algorithm: given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away). DBSCAN is one of the most common clustering algorithms and also most cited in scientific literature.\n\nIn 2014, the algorithm was awarded the test of time award (an award given to algorithms which have received substantial attention in theory and practice) at the leading data mining conference, KDD.\n\nSource: Wikipedia\n\n\n![image.png](attachment:image.png)\n\n\nThe above figure is taken from https:\/\/stats.stackexchange.com\/questions\/194734\/dbscan-what-is-a-core-point\n\nBlue observations are noise\n\nRed observations are core points\n\nYellow ones are non core point aka edges of the cluster\n\n","b0667aed":"-1 stands for outliers\/Noise, we see that there are 93 outliers in our dataset. \n\nThe number of observations in our clusters range from 20 to 283.\n\nLet's look at some statistics within our clusters.","2f26c582":"From the above visualizations, we can see that there is no much difference between mean and median of the data except for the company that's located in Sao Tome.\n\nA very important observation is that, Rating seems to be dependent on the country of company location.\nWe can spot several European and South American countries with a higher mean Rating, this could be due to the availability of Cocoa in these countries. The availability cocoa can influence the percentage of Cocoa used in the chocolates at these companies.","882c4285":"Based on the above plot, I decided to go forward with a distance (epsilon) value of 1","2d26389e":"The following code is actually taken from scikit learn for visualization of our clusters.\n\nhttp:\/\/scikit-learn.org\/stable\/auto_examples\/cluster\/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py","f11dba04":"Let's have a look at the ratings by Review year, we would like to see if the review date has an effect on the Rating. Also, we would like to see if the outliers in the Rating. A boxplot would be very helpful in this case.","cc3acfd8":"Extracted the Cocoa percentage and converted it into float for further analysis","ad2a7bf7":"We can infer from the above plots that the rating as well as the Cocoa percentage is much different for our outliers from the remaining clusters within the dataset.\n\nA high Cocoa percentage in a chocolate doesn't necessarily prompt higher ratings, looks like it actually worsens the ratings from our dataset.","6eb55410":"The distribution of the ratings is somewhat skewed from normal. We see that there is a high number of  3 and 4 ratings. There are very few 1 and 5 ratings.","f57ef484":"The number of clusters in our dataset is 12. Remember that the number of clusters does not include outliers\/noise in the dataset.","ec184330":"The Ratings might be possibly influenced by the bean type and broad bean type used in the production.\nSince we have these features in our dataset, we can plot the effect these features have on our ratings.\n\nFrom the below visualizations, we can see that the distribution of ratings is different based on bean type and broad bean type.","40b40708":"The black markers in the above dataset is the noise\/outliers in our dataset.\n\nMore analysis to follow soon. \n\nThanks, upvote if you liked it :)","a248097a":"let's check for some missing values first","742c7993":"There is an interesting trend in the Rating. From the years 2006 to 2009, the median of the Ratings is consistent around 3. There is a jump in the median to a value of 3.3 from 2010 and it remained around 3.3 until 2016. "}}