{"cell_type":{"6524de7f":"code","e1101122":"code","03f60e38":"code","5165cabf":"code","38df2e00":"code","dd39e954":"code","3be7353b":"code","f85f4ec3":"code","a2b03f94":"code","75254d98":"code","15d52192":"code","0b90b0a6":"code","fe75f1b7":"code","7992d6f4":"code","432588bd":"code","a24659bc":"code","7764675f":"code","f05ebde4":"code","445aa221":"code","f7c7c868":"markdown","9e956a96":"markdown"},"source":{"6524de7f":"import tensorflow as tf\nfrom IPython.display import clear_output\nimport itertools, re, os, random, keras\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport matplotlib\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom pylab import rcParams\nfrom keras.models import Sequential, save_model\n\nfrom keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization, Input, concatenate, Reshape, Conv2DTranspose, Conv2D, MaxPool2D, GlobalAveragePooling2D\nfrom keras import layers, Input, Model, models, regularizers, optimizers\n\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nfrom keras.utils import np_utils\n\n\nfrom sklearn.utils import class_weight\n\nimport tensorflow_addons as tfa\n\nfrom keras.layers.convolutional import Conv1D, Convolution1D, MaxPooling1D\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import MobileNetV2\nimport math\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns\nimport matplotlib.image as mpimg\nimport plotly.express as px\nfrom keras.utils.vis_utils import plot_model\n\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array","e1101122":"train_path='..\/input\/intel-image-classification\/seg_train\/seg_train'\ntest_path='..\/input\/intel-image-classification\/seg_pred\/seg_pred'\nvalidation_path='..\/input\/intel-image-classification\/seg_test\/seg_test'\npath=[train_path,validation_path]","03f60e38":"def ploti(train_path,which):\n    directory=os.listdir(train_path)\n    train=pd.DataFrame(directory,columns=['folders'])\n    counts=[]\n    for i in directory:\n        path=train_path+'\/'+i\n        num_files = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n        counts.append(num_files)\n    train['counts']=counts\n    fig = px.pie(train, values='counts', names='folders', title='distribution across '+str(which))\n    fig.show()","5165cabf":"ploti(train_path,'Train')\nploti(validation_path,\"Validation\")","38df2e00":"def show_no(path):\n    sho=pd.DataFrame(['Train','Validation'],columns=['categories'])\n    counting=[]\n    for i in path:\n        count=0\n        directory=os.listdir(i)\n        for j in directory:\n            pathi=i+'\/'+j\n            num_files = len([f for f in os.listdir(pathi)if os.path.isfile(os.path.join(pathi, f))])\n            count+=num_files\n        counting.append(count)   \n    sho['counts']=counting    \n    sns.barplot(x='categories', y='counts', data=sho);","dd39e954":"show_no(path)","3be7353b":"def plotImagesAndLabels(folder):\n    c=1\n    directory=os.listdir(folder)\n    plt.figure(figsize=(28,20))\n    for each in directory:\n        currentFolder=folder+ \"\/\" +each\n        for i, file in enumerate(os.listdir(currentFolder)[0:4]):\n            full_path=currentFolder+\"\/\"+file\n            plt.subplot(3, 8, c)\n            img = mpimg.imread(full_path)\n            plt.imshow(img)\n            plt.title(each)\n            c+=1\n    plt.subplots_adjust(wspace=0.3, hspace=-0.1)\n    plt.show()","f85f4ec3":"print(\"Lets see some samples from training data...\")\nplotImagesAndLabels(train_path)","a2b03f94":"print(\"Lets see some samples from validation data...\")\nplotImagesAndLabels(validation_path)","75254d98":"def create_dataframe(path):\n    paths=[]\n    labels=[]\n    directories=os.listdir(path)\n    for i in directories:\n        current_path=path+\"\/\"+i\n        for file in os.listdir(current_path):\n            final_path=current_path+\"\/\"+file\n            paths.append(final_path)\n            labels.append(i)\n    df=pd.DataFrame(paths, columns=['path'])  \n    df['label']=labels\n    return df\n\ndef create_for_test(path):\n    paths=[]\n    for file in os.listdir(path):\n        final_path=path+\"\/\"+file\n        paths.append(final_path)\n    df=pd.DataFrame(paths, columns=['path'])\n    return df","15d52192":"train=create_dataframe(train_path).sample(frac=1)\nvalidation=create_dataframe(validation_path).sample(frac=1)\ntest=create_for_test(test_path).sample(frac=1)","0b90b0a6":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)\n\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=train,\n    x_col='path',\n    y_col='label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=validation,\n    x_col='path',\n    y_col='label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test,\n    x_col='path',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode=None,\n    batch_size=32,\n    shuffle=False\n)","fe75f1b7":"print(\"making a CNN model...\")\ndef create_model():\n    pretrained_model = tf.keras.applications.MobileNetV2(\n        input_shape=(224, 224, 3),\n        include_top=False,\n        weights='imagenet',\n        pooling='avg'\n    )\n    pretrained_model.trainable = False\n    inputs = pretrained_model.input\n\n    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n    x = tf.keras.layers.Dense(64, activation='relu')(x)\n\n    outputs = tf.keras.layers.Dense(6, activation='softmax')(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","7992d6f4":"model=create_model()\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","432588bd":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True, patience=5)\nhistory = model.fit(train_images,\n                    validation_data=val_images,\n                    epochs=10,\n                    callbacks=[es,mc])","a24659bc":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","7764675f":" model=tf.keras.models.load_model('.\/best_model.h5')","f05ebde4":"pred = model.predict(test_images)\npredi=pred.copy()\npredi = np.amax(predi, axis=1)\npred = np.argmax(pred,axis=1)\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]","445aa221":"fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test.path.iloc[i]))\n    ax.set_title(f\"confidence: {predi[i]}\\nPredicted: {pred[i]}\")\nplt.tight_layout()\nplt.show()","f7c7c868":"# IF you like this notebook then please give an upvote \ud83d\udc4d\n**and also give suggestions in comment \ud83d\ude4c**","9e956a96":"# IF you like this notebook then please give an upvote \ud83d\udc4d\n**and also give suggestions in comment \ud83d\ude4c**"}}