{"cell_type":{"457dd3fe":"code","f5aedfbf":"code","16706e34":"code","68b018fa":"code","a74d71cf":"code","5e20da6d":"code","06bd7976":"code","91e3a343":"code","b5565c59":"code","4b3c2471":"code","67c5fc6d":"code","a80a0750":"code","33fdd322":"code","47f12534":"code","b6d42165":"code","4b1af09d":"code","ab7555a9":"code","af8940b5":"code","04f7225c":"code","d60cb8e1":"code","fa4db810":"code","bc35a927":"code","6088045c":"code","97f4a957":"code","50ec7c79":"code","41043bde":"code","15bf45e0":"code","607850f4":"code","223d66c4":"code","7b0689c5":"code","fd7f11ff":"markdown","3e6654d6":"markdown","ec7b5dac":"markdown","26a4e7a4":"markdown","9742657d":"markdown","3f15da23":"markdown"},"source":{"457dd3fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5aedfbf":"#usual imports\nimport os\nimport sys\nassert sys.version_info >= (3,5)\nimport numpy as np\nimport pandas as pd\n#handle unwanted warnings\nimport warnings\nwarnings.filterwarnings(action='ignore',category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore',category=FutureWarning)\n#set no limits on the dataframe columns display\npd.options.display.max_columns = None","16706e34":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv',delimiter=',',engine='python')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv',delimiter=',',engine='python')","68b018fa":"#check info\ntrain.info()","a74d71cf":"#check the shape of the train and test set\ntrain.shape, test.shape","5e20da6d":"#top few rows of the train set \ntrain.head(7)","06bd7976":"#occurrence per target class\ntrain['target'].value_counts().sort_values(ascending=False)","91e3a343":"#number of unique target class\ntrain['target'].nunique()","b5565c59":"#check for any duplicates\ntrain.duplicated().any()","4b3c2471":"#shuffle the dataset \nshuffled_indices = np.random.permutation(len(train))\nshuffled_train = train.iloc[shuffled_indices]","67c5fc6d":"shuffled_train.head()","a80a0750":"X = shuffled_train.drop(['id','target'],axis=1).astype('float')\nY = shuffled_train['target']","33fdd322":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","47f12534":"from sklearn.preprocessing import PowerTransformer\npt = PowerTransformer()\nX = pt.fit_transform(X)","b6d42165":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\n#encoded_Y = encoded_Y.reshape((-1,1))\n#one_hot_y = np_utils.to_categorical(encoded_Y)","4b1af09d":"from sklearn.decomposition import PCA\npca = PCA(n_components=0.90)\nX = pca.fit_transform(X)","ab7555a9":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=200,random_state=51,max_depth=5)","af8940b5":"clf.fit(X,encoded_Y)","04f7225c":"train_pred = clf.predict(X)","d60cb8e1":"train_pred","fa4db810":"#accuracy on the entire train set -- > likely overfit better approach to split and check performance on the validation set\nfrom sklearn.metrics import accuracy_score\naccuracy_score(encoded_Y,train_pred)","bc35a927":"#prepare the test data\ntest_set = test.drop('id',axis=1)\ntest_set = scaler.transform(test_set)\ntest_set = pca.transform(test_set)\npredictions = clf.predict_proba(test_set)","6088045c":"#check predicted probabilities\npredictions","97f4a957":"predictions.shape","50ec7c79":"submission = pd.DataFrame(predictions,columns=['Class_1','Class_2','Class_3','Class_4','Class_5',\n                                              'Class_6','Class_7','Class_8','Class_9'])","41043bde":"submission['id'] = test['id']","15bf45e0":"submission = submission[['id','Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n                         'Class_7', 'Class_8', 'Class_9']]","607850f4":"submission.head()","223d66c4":"submission.to_csv('tps_submission.csv',index=False)","7b0689c5":"import pickle\n# Save the trained model as a pickle string.\nsaved_model = pickle.dumps(clf)\n  \n# Load the pickled model\nrf_from_pickle = pickle.loads(saved_model)\n  \n# Use the loaded pickled model to make predictions\nrf_from_pickle.predict(test_set)","fd7f11ff":"For better result, set max_features to a lower values, around 0.5. However the computation will be impacted. ","3e6654d6":"<a name='3'><\/a>\n## 3 - Data Preparation","ec7b5dac":"<a name='1'><\/a>\n## 1 - Import Libraries","26a4e7a4":"<a name='4'><\/a>\n## 4 - Modeling & Submission","9742657d":"## Table of Contents\n- ### [1 - Import Libraries](#1)\n- ### [2 - Load Data & Basic Data Exploration](#2)\n- ### [3 - Data Preparation](#3)\n- ### [4 - Modeling & Submission](#4)\n","3f15da23":"<a name='2'><\/a>\n## 2 - Load Data & Basic Data Exploration"}}