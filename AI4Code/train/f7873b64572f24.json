{"cell_type":{"5e820124":"code","20fa1318":"code","f58f7b9b":"code","a4235cd8":"code","bbae627e":"code","a23b2b57":"code","efe82281":"code","0cba5b7e":"code","b5b42a90":"code","f71deb19":"code","ec87622d":"code","d5cba3cf":"code","0bb56b01":"code","bf2b8de5":"code","b4bccd22":"code","1b87b562":"code","472319e9":"code","a664c0f6":"code","d49c69da":"code","16643876":"markdown","9a8fae2e":"markdown","824deca8":"markdown","a3107a09":"markdown","e1263390":"markdown","c8539299":"markdown","646e55da":"markdown","f545949a":"markdown","24f394dd":"markdown","7666c6cf":"markdown","f9b00825":"markdown","90c06cbf":"markdown"},"source":{"5e820124":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","20fa1318":"train_df = pd.read_json('..\/input\/train.json')\ntest_df = pd.read_json('..\/input\/test.json')\n\ntrain_df['seperated_ingredients'] = train_df['ingredients'].apply(','.join)\ntest_df['seperated_ingredients'] = test_df['ingredients'].apply(','.join)","f58f7b9b":"print('Maximum Number of Ingredients in a Dish: ',train_df['ingredients'].str.len().max())\nprint('Minimum Number of Ingredients in a Dish: ',train_df['ingredients'].str.len().min())","a4235cd8":"plt.hist(train_df['ingredients'].str.len(),bins=max(train_df['ingredients'].str.len()),edgecolor='b')\nplt.gcf().set_size_inches(16,8)\nplt.title('Ingredients in a Dish Distribution')","bbae627e":"sns.countplot(y='cuisine', data=train_df,palette=sns.color_palette('inferno',15))\nplt.gcf().set_size_inches(15,10)\nplt.title('Cuisine Distribution',size=20)","a23b2b57":"from sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)\ncounts = vec.fit_transform(train_df['seperated_ingredients']) \ncount=dict(zip(vec.get_feature_names(), counts.sum(axis=0).tolist()[0]))\ncount=pd.DataFrame(list(count.items()),columns=['Ingredient','Count'])\ncount.set_index('Ingredient').sort_values('Count',ascending=False)[:15].plot.barh(width=0.9)\nplt.gcf().set_size_inches(10,10)\nplt.gca().invert_yaxis()\nplt.title('Top 15 Ingredients')","efe82281":"ingreList = []\nfor index, row in train_df.iterrows():\n    ingre = row['ingredients']\n    \n    for i in ingre:\n        if i not in ingreList:\n            ingreList.append(i)\ndef binary(ingre_list):\n    binaryList = []\n    \n    for item in ingreList:\n        if item in ingre_list:\n            binaryList.append(1)\n        else:\n            binaryList.append(0)\n    \n    return binaryList\ntrain_df['bin ingredients']=train_df['ingredients'].apply(lambda x: binary(x))","0cba5b7e":"from scipy import spatial\n\ndef Similarity(Id1, Id2):\n    a = train_df.iloc[Id1]\n    b = train_df.iloc[Id2]\n    \n    A = a['bin ingredients']\n    B = b['bin ingredients']\n    distance=spatial.distance.cosine(A,B)\n    \n    return distance, Id2\n","b5b42a90":"food=[]\nfor i in train_df.index:\n    food.append(Similarity(1,i))\ncommon_ingredients=sorted(food,key=lambda x: x[0])[1:10]\nindexes=[]\nfor i in range(len(common_ingredients)):\n    indexes.append(common_ingredients[i][1])\ntrain_df.iloc[indexes]","f71deb19":"import nltk\nfrom collections import Counter","ec87622d":"train_df['for ngrams']=train_df['seperated_ingredients'].str.replace(',',' ')\nf,ax=plt.subplots(2,2,figsize=(20,20))\ndef ingre_cusine(cuisine):\n    frame=train_df[train_df['cuisine']==cuisine]\n    common=list(nltk.bigrams(nltk.word_tokenize(\" \".join(frame['for ngrams']))))\n    return pd.DataFrame(Counter(common),index=['count']).T.sort_values('count',ascending=False)[:15]\ningre_cusine('mexican').plot.barh(ax=ax[0,0],width=0.9,color='#45ff45')\nax[0,0].set_title('Mexican Cuisine')\ningre_cusine('indian').plot.barh(ax=ax[0,1],width=0.9,color='#df6dfd')\nax[0,1].set_title('Indian Cuisine')\ningre_cusine('italian').plot.barh(ax=ax[1,0],width=0.9,color='#fbca5f')\nax[1,0].set_title('Italian Cuisine')\ningre_cusine('chinese').plot.barh(ax=ax[1,1],width=0.9,color='#ffff00')\nax[1,1].set_title('Chinese Cuisine')\nplt.subplots_adjust(wspace=0.5)","d5cba3cf":"import networkx as nx\ndef generate_ngrams(text, n):\n    words = text.split(' ')\n    iterations = len(words) - n + 1\n    for i in range(iterations):\n       yield words[i:i + n]\ndef net_diagram(*cuisines):\n    ngrams = {}\n    for title in train_df[train_df.cuisine==cuisines[0]]['for ngrams']:\n            for ngram in generate_ngrams(title, 2):\n                ngram = ','.join(ngram)\n                if ngram in ngrams:\n                    ngrams[ngram] += 1\n                else:\n                    ngrams[ngram] = 1\n\n    ngrams_mws_df = pd.DataFrame.from_dict(ngrams, orient='index')\n    ngrams_mws_df.columns = ['count']\n    ngrams_mws_df['cusine'] = cuisines[0]\n    ngrams_mws_df.reset_index(level=0, inplace=True)\n\n    ngrams = {}\n    for title in train_df[train_df.cuisine==cuisines[1]]['for ngrams']:\n            for ngram in generate_ngrams(title, 2):\n                ngram = ','.join(ngram)\n                if ngram in ngrams:\n                    ngrams[ngram] += 1\n                else:\n                    ngrams[ngram] = 1\n\n    ngrams_mws_df1 = pd.DataFrame.from_dict(ngrams, orient='index')\n    ngrams_mws_df1.columns = ['count']\n    ngrams_mws_df1['cusine'] = cuisines[1]\n    ngrams_mws_df1.reset_index(level=0, inplace=True)\n    cuisine1=ngrams_mws_df.sort_values('count',ascending=False)[:25]\n    cuisine2=ngrams_mws_df1.sort_values('count',ascending=False)[:25]\n    df_final=pd.concat([cuisine1,cuisine2])\n    g = nx.from_pandas_dataframe(df_final,source='cusine',target='index')\n    cmap = plt.cm.RdYlGn\n    colors = [n for n in range(len(g.nodes()))]\n    k = 0.35\n    pos=nx.spring_layout(g, k=k)\n    nx.draw_networkx(g,pos, node_size=df_final['count'].values*8, cmap = cmap, node_color=colors, edge_color='grey', font_size=15, width=3)\n    plt.title(\"Top 25 Bigrams for %s and %s\" %(cuisines[0],cuisines[1]), fontsize=30)\n    plt.gcf().set_size_inches(30,30)\n    plt.show()\n    plt.savefig('network.png')","0bb56b01":"net_diagram('french','mexican')","bf2b8de5":"net_diagram('thai','chinese')","b4bccd22":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvect = TfidfVectorizer(binary=True).fit(train_df['seperated_ingredients'].values)\nX_train_vectorized = vect.transform(train_df['seperated_ingredients'].values)\nX_train_vectorized = X_train_vectorized.astype('float')\nResult_transformed = vect.transform(test_df['seperated_ingredients'].values)\nResult_transformed = Result_transformed.astype('float')","1b87b562":"from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ny_transformed = encoder.fit_transform(train_df.cuisine)","472319e9":"from sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_train_vectorized, y_transformed , random_state = 0)\n\nfrom sklearn.linear_model import LogisticRegression\n\nclf1 = LogisticRegression(C=10,dual=False)\nclf1.fit(X_train , y_train)\nclf1.score(X_test, y_test)","a664c0f6":"from sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nvclf=VotingClassifier(estimators=[('clf1',LogisticRegression(C=10,dual=False)),('clf2',SVC(C=100,gamma=1,kernel='rbf',probability=True))],voting='soft',weights=[1,2])\nvclf.fit(X_train , y_train)\nvclf.score(X_test, y_test)","d49c69da":"y_predicted = vclf.predict(Result_transformed)\ny_predicted_final = encoder.inverse_transform(y_predicted)\npredictions = pd.DataFrame({'cuisine' : y_predicted_final , 'id' : test_df.id })\npredictions = predictions[[ 'id' , 'cuisine']]\npredictions.to_csv('submit.csv', index = False)","16643876":"The dish with just a single ingredient might be a simple boiled dish :D.","9a8fae2e":"## Logistic Regression","824deca8":"## Main Ingredients","a3107a09":"### Dishes Similar to Dish No 1","e1263390":"## Ensemble Model","c8539299":"## Top Cuisines","646e55da":"## Finding Similar Dishes","f545949a":"## Modeling","24f394dd":"## Network Diagrams for Bigrams","7666c6cf":"# If You Smelllll What The Rock Is Cooking\n\n![](http:\/\/gifimage.net\/wp-content\/uploads\/2017\/10\/can-you-smell-what-the-rock-is-cooking-gif-8.gif)\n","f9b00825":"## Ingredients in a Dish","90c06cbf":"## Top Bigrams by Cuisines"}}