{"cell_type":{"57503841":"code","8df89709":"code","23a3e8b2":"code","ef0f8e00":"code","cb16115c":"code","cb0e15d9":"code","f145ba2f":"code","7b9532b9":"code","55b4311f":"code","865bec65":"code","f0ad4fbd":"code","41d3df26":"code","e200f837":"code","8e461ba7":"code","7d5e6523":"code","853d7b46":"code","aa6b8111":"code","3b7d9a62":"code","6e4109fc":"code","bcf33158":"code","22e6630a":"code","4af0e29d":"code","f04aaec9":"code","2b5cff9e":"code","ec307847":"code","63901075":"code","61665c03":"code","07993eb3":"code","808af9bd":"code","dc3a95df":"markdown","e5863932":"markdown","0406f2b8":"markdown","7ba0e2c7":"markdown","93a00745":"markdown","b72abf5e":"markdown","74ee022e":"markdown","b9c57022":"markdown","3591bf4a":"markdown","5b1cc53d":"markdown"},"source":{"57503841":"# Setup\n\n# common:\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport matplotlib.patches as mpatches\nfrom scipy.stats import norm\nfrom scipy import stats\nimport time\nimport folium\nimport collections\nimport eli5 # Feature importance evaluation\nimport urllib\nfrom PIL import Image\n\n# for ML:\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, average_precision_score, roc_curve, precision_recall_curve, classification_report, confusion_matrix, mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, ShuffleSplit, cross_validate, cross_val_score, cross_val_predict, RandomizedSearchCV, GridSearchCV, learning_curve\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, RobustScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\nfrom xgboost import XGBClassifier\n\n# Imported Libraries\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom imblearn.pipeline import Pipeline\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# set some display options:\nsns.set(style=\"whitegrid\")\npd.set_option(\"display.max_columns\", 36)","8df89709":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","23a3e8b2":"# load data:\nfile_path = '\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv'\ndf = pd.read_csv(file_path)","ef0f8e00":"df.head()","cb16115c":"df.info()","cb0e15d9":"pd.set_option(\"display.float_format\", \"{:.2f}\".format)\ndf.describe()","f145ba2f":"# check for missing values\ndf.isnull().sum()","7b9532b9":"df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=\"columns\", inplace=True)","55b4311f":"df.Attrition = df.Attrition.astype('category').cat.codes","865bec65":"categorical_features = []\nfor column in df.columns:\n    if df[column].dtype == object:\n        categorical_features.append(column)\n        print(f\"{column}\")\n        print(\"====================================\")","f0ad4fbd":"numerical_features = []\nfor column in df.columns:\n    if df[column].dtype != object:\n        numerical_features.append(column)\n        print(f\"{column}\")\n        print(\"====================================\")","41d3df26":"numerical_features.remove('Attrition')","e200f837":"# The classes are skewed we need to solve this issue later.\nprint('No Attrition', round(df['Attrition'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Attrition', round(df['Attrition'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')","8e461ba7":"sns.countplot(x='Attrition', data=df)\nplt.title('Attrition Distributions \\n (0: No Attrition || 1: Attrition)', fontsize=14)","7d5e6523":"plt.figure(figsize=(20, 40))\n\nfor i, feature in enumerate(numerical_features, 1):\n    plt.subplot(8, 3, i)\n    df[df[\"Attrition\"] == 0][feature].hist(bins=35, color='blue', label='Not Attrition', alpha=0.6)\n    df[df[\"Attrition\"] == 1][feature].hist(bins=35, color='red', label='Attrition', alpha=0.6)\n    plt.legend()\n    plt.xlabel(feature)\n    plt.ylabel('count')","853d7b46":"plt.figure(figsize=(20, 15))\n\nfor i, feature in enumerate(categorical_features, 1):\n    plt.subplot(3, 3, i)\n    df[df[\"Attrition\"] == 0][feature].hist(bins=35, color='blue', label='Not Attrition', alpha=0.6)\n    df[df[\"Attrition\"] == 1][feature].hist(bins=35, color='red', label='Attrition', alpha=0.6)\n    plt.legend()\n    plt.xlabel(feature)\n    plt.ylabel('count')","aa6b8111":"plt.figure(figsize=(30, 24))\npalette = sns.diverging_palette(20, 220, n=256)\ncorr=df.corr(method='pearson')\nsns.heatmap(corr, annot=True, cmap=palette, vmax=.3, center=0, square=True, linewidths=.5, annot_kws={\"size\":15}, cbar_kws={'shrink': .5})\nplt.title('Correlation Matrix', size=15, weight='bold')","3b7d9a62":"df.drop('Attrition', axis=1).corrwith(df.Attrition).plot(kind='barh', figsize=(10, 7))","6e4109fc":"# Separate features and predicted value\nfeatures = numerical_features + categorical_features\nY = df['Attrition']\nX = df.drop('Attrition', axis=1)[features]\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n# preprocess numerical feats:\n# for most num cols, except the dates, 0 is the most logical choice as fill value\n# and here no dates are missing.\nnum_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n    ('scaler', StandardScaler())])\n\n# Preprocessing for categorical features:\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical features:\npreprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, numerical_features),\n                                               (\"cat\", cat_transformer, categorical_features)])","bcf33158":"# define base_models to test:\nbase_models = {\n    'LOR_model': LogisticRegression(),\n    'KNC_model': KNeighborsClassifier(),\n    'SVM_model': SVC(),\n    'DTR_model': DecisionTreeClassifier(),\n    'RFC_model': RandomForestClassifier(),\n    'ETC_model': ExtraTreesClassifier(),\n    'BAG_model': BaggingClassifier(),\n    'MLP_model': MLPClassifier(),\n    'XGB_model': XGBClassifier(),\n}\n\nnormal_model_score = {}\n\n# split data into 'kfolds' parts for cross validation,\n# use shuffle to ensure random distribution of data:\nkfolds = 4 # 4 = 75% train, 25% validation\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n\n# Preprocessing, fitting, making predictions and scoring for every model:\nfor name, model in base_models.items():\n    # pack preprocessing of data and the model in a pipeline:\n    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n    \n    # get cross validation score for each model:\n    cv_results = cross_val_score(model_steps, \n                                 X_train, Y_train, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n    normal_model_score[name] = cv_results\n    \n    # output:\n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} model cross validation accuracy score: {mean_score} +\/- {std_dev} (std) min: {min_score}, max: {max_score}\")","22e6630a":"# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n\n# Lets shuffle the data before creating the subsamples\n\ndf = df.sample(frac=1, random_state=42)\n\n# amount of fraud classes 492 rows.\nfraud_df = df.loc[df['Attrition'] == 1]\nnon_fraud_df = df.loc[df['Attrition'] == 0][:237]\n\nnormal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n\n# Shuffle dataframe rows\nnew_df = normal_distributed_df.sample(frac=1, random_state=42)\n\nnew_df.head()","4af0e29d":"# Separate features and predicted value\nfeatures = numerical_features + categorical_features\nY = normal_distributed_df['Attrition']\nX = normal_distributed_df.drop('Attrition', axis=1)[features]\n\nunder_X_train, under_X_test, under_Y_train, under_Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n# preprocess numerical feats:\n# for most num cols, except the dates, 0 is the most logical choice as fill value\n# and here no dates are missing.\nnum_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n    ('scaler', StandardScaler())])\n\n# Preprocessing for categorical features:\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical features:\npreprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, numerical_features),\n                                               (\"cat\", cat_transformer, categorical_features)])","f04aaec9":"# define base_models to test:\nbase_models = {\n    'LOR_model': LogisticRegression(),\n    'KNC_model': KNeighborsClassifier(),\n    'SVM_model': SVC(),\n    'DTR_model': DecisionTreeClassifier(),\n    'RFC_model': RandomForestClassifier(),\n    'ETC_model': ExtraTreesClassifier(),\n    'BAG_model': BaggingClassifier(),\n    'MLP_model': MLPClassifier(),\n    'XGB_model': XGBClassifier(),\n}\n\nunder_sampling_model_score = {}\n\n# split data into 'kfolds' parts for cross validation,\n# use shuffle to ensure random distribution of data:\nkfolds = 4 # 4 = 75% train, 25% validation\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n\n# Preprocessing, fitting, making predictions and scoring for every model:\nfor name, model in base_models.items():\n    # pack preprocessing of data and the model in a pipeline:\n    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n    \n    # get cross validation score for each model:\n    cv_results = cross_val_score(model_steps, \n                                 under_X_train, under_Y_train, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n    under_sampling_model_score[name] = cv_results\n\n    # output:\n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} model cross validation accuracy score: {mean_score} +\/- {std_dev} (std) min: {min_score}, max: {max_score}\")","2b5cff9e":"# Separate features and predicted value\nfeatures = numerical_features + categorical_features\nY = df['Attrition']\nX = df.drop('Attrition', axis=1)[features]\n\nover_X_train, over_X_test, over_Y_train, over_Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\n# preprocess numerical feats:\n# for most num cols, except the dates, 0 is the most logical choice as fill value\n# and here no dates are missing.\nnum_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n    ('scaler', StandardScaler())])\n\n# Preprocessing for categorical features:\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical features:\npreprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, numerical_features),\n                                               (\"cat\", cat_transformer, categorical_features)])\n\n# SMOTE Technique (OverSampling) After splitting and Cross Validating\nsm = SMOTE(sampling_strategy='minority', random_state=42)","ec307847":"# define base_models to test:\nbase_models = {\n    'LOR_model': LogisticRegression(),\n    'KNC_model': KNeighborsClassifier(),\n    'SVM_model': SVC(),\n    'DTR_model': DecisionTreeClassifier(),\n    'RFC_model': RandomForestClassifier(),\n    'ETC_model': ExtraTreesClassifier(),\n    'BAG_model': BaggingClassifier(),\n    'MLP_model': MLPClassifier(),\n    'XGB_model': XGBClassifier(),\n}\n\nover_sampling_model_score = {}\n\n# split data into 'kfolds' parts for cross validation,\n# use shuffle to ensure random distribution of data:\nkfolds = 4 # 4 = 75% train, 25% validation\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n\n# Preprocessing, fitting, making predictions and scoring for every model:\nfor name, model in base_models.items():\n    # pack preprocessing of data and the model in a pipeline:\n    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('smote', sm),\n                              ('model', model)])\n    \n    # get cross validation score for each model:\n    cv_results = cross_val_score(model_steps, \n                                 over_X_train, over_Y_train, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n    over_sampling_model_score[name] = cv_results\n\n    # output:\n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} model cross validation accuracy score: {mean_score} +\/- {std_dev} (std) min: {min_score}, max: {max_score}\")\n    ","63901075":"model_score = {\n    \"normal_model_score\": normal_model_score,\n    \"under_sampling_model_score\": under_sampling_model_score,\n    \"over_sampling_model_score\": over_sampling_model_score\n}\n\nfigure = plt.figure(figsize=(15,12))\nfor name, score_dict in model_score.items():\n    mean_score = []\n    lower_mean_socre = []\n    upper_mean_socre = []\n    model_name = []\n    for model, score in score_dict.items():\n        mean_score.append(round(np.mean(score), 4))\n        lower_mean_socre.append(round(np.mean(score), 4) - round(np.std(score), 4))\n        upper_mean_socre.append(round(np.mean(score), 4) + round(np.std(score), 4))\n        model_name.append(model)\n    plt.plot(model_name, mean_score, 'o-', label=f\"{name}\")\n    plt.fill_between(model_name, lower_mean_socre, upper_mean_socre, alpha=0.1)\nplt.title(\"Sampling Score Curve\", fontsize=14)\nplt.xlabel('model name')\nplt.ylabel('Score')\nplt.grid(True)\nplt.legend(loc=\"best\")","61665c03":"print(\"Normal Model\\n\")\nmodel = RandomForestClassifier(random_state=42, n_jobs=-1,)\n\nmodel_steps = Pipeline(steps=[\n                            ('preprocessor', preprocessor),\n                            ('model', model)])\n\n# fit model(pipeline) so values can be accessed:\nmodel_steps.fit(X_train, Y_train)\n\nY_pred = model_steps.predict(X_test)\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\nlabels = ['No Attrition', 'Attrition']\nprint(classification_report(Y_test, Y_pred, target_names=labels))","07993eb3":"print(\"Over Sampling Model\\n\")\nmodel = RandomForestClassifier(random_state=42, n_jobs=-1,)\n\nmodel_steps = Pipeline(steps=[\n                            ('preprocessor', preprocessor),\n                            ('model', model)])\n\n# fit model(pipeline) so values can be accessed:\nmodel_steps.fit(over_X_train, over_Y_train)\n\nover_Y_pred = model_steps.predict(over_X_test)\nActVPred = pd.DataFrame({'Actual': over_Y_test, 'Predicted': over_Y_pred})\nprint(ActVPred)\n\nlabels = ['No Attrition', 'Attrition']\nprint(classification_report(over_Y_test, over_Y_pred, target_names=labels))","808af9bd":"# Names of all (encoded) features are needed.\n# Get names of columns from One Hot Encoding:\nonehot_columns = list(model_steps.named_steps['preprocessor'].\n                      named_transformers_['cat'].\n                      named_steps['onehot'].\n                      get_feature_names(input_features=categorical_features))\n\n# Add num_features for full list.\n# Order must be as in definition of X, where num_features are first: \nfeat_imp_list = numerical_features + onehot_columns\n\n# show 10 most important features, provide names of features:\nfeat_imp_df = eli5.formatters.as_dataframe.explain_weights_df(\n    model_steps.named_steps['model'],\n    feature_names=feat_imp_list)\nfeat_imp_df.head(10)","dc3a95df":"So, we select the over sampling method.","e5863932":"## Over sampling","0406f2b8":"# ML","7ba0e2c7":"### To Drop:\n+ EmployeeCount: All values have the same value.\n+ EmployeeNumber: Irrelevant variable, it is only an employee identifier.\n+ Over18: All values have the same value.\n+ StandartHours: All values have the same value.","93a00745":"## Normal","b72abf5e":"### Correlation Matrix","74ee022e":"**Conclusions:**\n\n***\n- `BusinessTravel` : The workers who travel a lot are more likely to quit than other employees.\n\n- `Department` : The worker in `Research & Development` are more likely to stay than the workers on other departement.\n\n- `EducationField` : The workers with `Human Resources` and `Technical Degree` are more likely to quit than employees from other fields of educations.\n\n- `Gender` : The `Male` are more likely to quit.\n\n- `JobRole` : The workers in `Laboratory Technician`, `Sales Representative`, and `Human Resources` are more likely to quit the workers in other positions.\n\n- `MaritalStatus` : The workers who have `Single` marital status are more likely to quit the `Married`, and `Divorced`.\n\n- `OverTime` : The workers who work more hours are likely to quit then others.\n\n*** ","b9c57022":"## Under Sampling","3591bf4a":"### Attrition rate","5b1cc53d":"# EDA"}}