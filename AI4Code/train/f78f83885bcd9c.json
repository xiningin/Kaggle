{"cell_type":{"0a1b7a90":"code","d2aadaad":"code","6137a4c1":"code","4a1328a6":"code","e93309d6":"code","af92d3a0":"code","cc48607c":"code","c751bf90":"code","47682df1":"code","88584fdc":"code","3356fc68":"code","d3a5decf":"code","f4aa4914":"code","6093443f":"code","600bae2f":"code","9112e4f3":"code","fd8bfbbf":"code","55372fe3":"code","7b680fa8":"code","a8d496ab":"code","c0a32329":"code","19db8db5":"code","3069810c":"code","5bae044c":"code","a46aa41d":"code","eb3a8b4e":"code","036c544a":"code","15f512d1":"code","8054c7cf":"code","2ea1e94c":"code","b1a82998":"code","cfe7cf63":"code","c81d57a5":"code","de3adc03":"code","bfe47768":"code","86b27e32":"code","7ad65db0":"code","c94f5b45":"code","300c81a9":"code","84464964":"code","2a339afb":"code","68601aeb":"code","89170a14":"code","c08d6ce4":"code","d2903e30":"code","fa4f8bb1":"code","8c73750c":"code","d3a77bb6":"code","e2c7ba2d":"code","363065b6":"code","048d7576":"code","7c713807":"code","3e23f77e":"code","b2098e6e":"code","f9f0dfa8":"code","113c7bb6":"code","27f19cab":"code","17bfc276":"code","605c76df":"code","93fd3a67":"code","457eb7e5":"code","0d07ae7d":"code","b5129cc9":"code","48880c4f":"code","f20f26e4":"code","a9c072a2":"code","78767d1c":"code","5767d2ad":"code","ffec666d":"code","453c4f25":"code","d345f36c":"code","8704e4b1":"code","45dfa8e9":"code","f0f22ce0":"code","5765d9ca":"code","97a38532":"code","04b2cd96":"code","362ead23":"code","5ea3cf59":"code","f92509f9":"code","12b940f1":"code","22480190":"code","c8994edf":"code","7a5515be":"code","1aafa5ff":"code","36ea9ce5":"code","c9add80e":"code","7920e8d9":"code","8dff28ef":"code","1d469ec8":"code","88dad83a":"code","8f29ce43":"code","73aa68a7":"code","15209276":"code","584e423d":"code","1ba87ca1":"code","114a1623":"code","3d8e8969":"code","69e54bde":"code","158c509f":"code","87197c82":"code","1a494084":"code","758aa465":"code","1a6b1097":"code","fbf1241d":"code","2f9b0a46":"code","099ab88d":"code","cce3a135":"markdown","925399c5":"markdown","f4b531b1":"markdown","56990c75":"markdown","1de1e302":"markdown","8b27aff4":"markdown","e53bd7d6":"markdown","f18e8e10":"markdown","a68dec40":"markdown","fd4343c2":"markdown","78d37cfd":"markdown","48944df6":"markdown","1767601e":"markdown","9ea1447f":"markdown","c7c8411e":"markdown","d6e39990":"markdown","86fe9488":"markdown","6810c606":"markdown","c2805acc":"markdown","ee8d81fc":"markdown","9baf0b79":"markdown","8481d113":"markdown","f034b793":"markdown","f0acb5f0":"markdown","0e34659c":"markdown","9fda7768":"markdown","0ce02539":"markdown","dbd44e4b":"markdown","94413436":"markdown","a25dcb46":"markdown","8785793d":"markdown","d24c514a":"markdown","3dde8540":"markdown","a8d8bf5e":"markdown","c57c761c":"markdown","bb3ae1a8":"markdown","ed039a5e":"markdown","cf602b53":"markdown","440c188c":"markdown","100bf85c":"markdown","08dfbc1e":"markdown","6c4c5978":"markdown","2e701e15":"markdown","f2e63f42":"markdown","aaf706c3":"markdown","c0adc338":"markdown","e815b7d0":"markdown","b95e66f6":"markdown","6986d739":"markdown","0fd880c3":"markdown","56979e1d":"markdown","2e7bc786":"markdown","1b5fd9cd":"markdown","4baf4fbf":"markdown","e6e471bc":"markdown","6140e139":"markdown","6222cb52":"markdown","0a7ea2ea":"markdown","58eac9dd":"markdown","8f7a0ae7":"markdown","d3d9ad68":"markdown","ea55c843":"markdown","94260c06":"markdown","06eda171":"markdown","5daf93e7":"markdown","e5fbbd22":"markdown","8fb0630b":"markdown","26e9dbcf":"markdown","687e65dc":"markdown","a4cc8a84":"markdown","c991e8dd":"markdown","9f2ba1d8":"markdown","e9c9d632":"markdown","a808d670":"markdown","786a2ab2":"markdown","100e5fa1":"markdown","7f014263":"markdown","8af0ce13":"markdown","d580a075":"markdown","989c0f5f":"markdown","0c5af962":"markdown","7c958909":"markdown","c52c05ee":"markdown","4fe69eb4":"markdown","3be868a8":"markdown","ed7a0ade":"markdown"},"source":{"0a1b7a90":"pip install openpyxl","d2aadaad":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport scipy.stats as stats\nfrom scipy.stats import norm\nimport pylab\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, classification_report, confusion_matrix\nfrom statsmodels.formula.api import ols\nimport statsmodels.stats.api as sms\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\nimport statsmodels.api as sm\nfrom xgboost import XGBClassifier\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#set pandas to display more rows and columns\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 200)\n\n#set seaborn plot grid style\nsns.set_style(\"whitegrid\");","6137a4c1":"dat = pd.read_excel('..\/input\/tourism\/Tourism.xlsx', sheet_name='Tourism')","4a1328a6":"dat.info()","e93309d6":"dat['ProductPitched'].value_counts()","af92d3a0":"dat.describe()","cc48607c":"#apply str manipulation functions\ndef toc(x):\n    if x == 'Self Enquiry': \n        return 0 \n    else: \n        return 1\n    \ndat['Gender'] = dat['Gender'].apply(lambda x: x.replace(' ','').capitalize())\ndat['Invited'] = dat['TypeofContact'].apply(toc)\n\ndat.drop(columns=['TypeofContact','CustomerID'], inplace=True)","c751bf90":"#convert dummy variables to counts to generate bar charts for univariate analysis\nprodtaken = np.unique(dat['ProdTaken'], return_counts=True)\npassport = np.unique(dat['Passport'], return_counts=True)\nowncar = np.unique(dat['OwnCar'], return_counts=True)\nproductpitched = np.unique(dat['ProductPitched'], return_counts=True)\ninvited = np.unique(dat['Invited'], return_counts=True)\noccupation = np.unique(dat['Occupation'], return_counts=True)\ngender = np.unique(dat['Gender'], return_counts=True)\nmaritalstatus = np.unique(dat['MaritalStatus'], return_counts=True)\ndesignation = np.unique(dat['Designation'], return_counts=True)","47682df1":"#plot data spread\nfig = plt.figure(figsize = [20,28]);\nfig.subplots_adjust(hspace=0.6, wspace=0.2);\n\nplt.subplot(5,4,1);\nsns.barplot(x = prodtaken[0], y=prodtaken[1], color='slategrey');\nplt.title('ProdTaken', fontsize=14, fontweight='bold');\nplt.xticks([0,1],['No','Yes'], fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,2);\nsns.distplot(dat['Age'], hist=False, kde_kws=dict(linewidth=3), color='limegreen');\nplt.title('Age', fontsize=14, fontweight='bold');\nplt.xlabel('(yrs)', fontsize=12, fontweight='bold');\nplt.yticks(np.arange(0,0.051,0.01),labels=['','','','','',''])\n\nplt.subplot(5,4,3);\nsns.barplot(x = invited[0], y=invited[1], color='burlywood');\nplt.title('TypeofContact', fontsize=14, fontweight='bold');\nplt.xticks(np.arange(0,2),['Self Enquiry', 'Company Invited'], fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,4);\nsns.distplot(dat['CityTier'], hist=True, kde=False, color='midnightblue');\nplt.title('CityTier', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,5);\nsns.barplot(x = occupation[0], y=occupation[1], color='darkgoldenrod');\nplt.title('Occupation', fontsize=14, fontweight='bold');\nplt.xticks(np.arange(0,4),['Free Lancer', 'Large Business', 'Salaried', 'Small Business'], fontsize=12, fontweight='bold', rotation=45);\n\nplt.subplot(5,4,6);\nsns.barplot(x = gender[0], y=gender[1], color='salmon');\nplt.title('Gender', fontsize=14, fontweight='bold');\nplt.xticks(np.arange(0,2),['Female', 'Male'], fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,7);\nsns.distplot(dat['NumberOfPersonVisiting'], hist=True, kde=False, color='cornflowerblue');\nplt.title('NumberOfPersonVisiting', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\nplt.xticks(np.arange(1,6,1))\n\nplt.subplot(5,4,8);\nsns.distplot(dat['PreferredPropertyStar'], hist=True, kde=False, color='lightseagreen');\nplt.title('PreferredPropertyStar', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\nplt.xticks(np.arange(1,6,1))\n\nplt.subplot(5,4,9);\nsns.barplot(x = maritalstatus[0], y=maritalstatus[1], color='darkviolet');\nplt.title('MaritalStatus', fontsize=14, fontweight='bold');\nplt.xticks(np.arange(0,4),['Divorced', 'Married', 'Single', 'Unmarried'], fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,10);\nsns.distplot(dat['NumberOfTrips'], hist=False, kde_kws=dict(linewidth=3), color='darkslategrey');\nplt.title('NumberOfTrips', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\nplt.yticks(np.arange(0,0.45,0.1),labels=['','','','',''])\n\nplt.subplot(5,4,11);\nsns.barplot(x = passport[0], y=passport[1], color='forestgreen');\nplt.title('passport', fontsize=14, fontweight='bold');\nplt.xticks([0,1],['No','Yes'], fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,12);\nsns.barplot(x = owncar[0], y=owncar[1], color='navy');\nplt.title('owncar', fontsize=14, fontweight='bold');\nplt.xticks([0,1],['No','Yes'], fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,13);\nsns.distplot(dat['NumberOfChildrenVisiting'], hist=True, kde=False, color='sienna');\nplt.title('NumberOfChildrenVisiting', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\nplt.xticks(np.arange(0,4,1))\n\nplt.subplot(5,4,14);\nsns.barplot(x = designation[0], y=designation[1], color='royalblue');\nplt.title('Designation', fontsize=14, fontweight='bold');\nplt.xticks(np.arange(0,5),['AVP', 'Executive', 'Manager', 'Senior Manager', 'VP'], fontsize=12, fontweight='bold', rotation=45);\n\nplt.subplot(5,4,15);\nsns.distplot(dat['MonthlyIncome'], hist=False, kde_kws=dict(linewidth=3), color='gold');\nplt.title('MonthlyIncome', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\nplt.yticks(np.arange(0,0.00013,0.00002),labels=['','','','','','',''])\n\nplt.subplot(5,4,17);\nsns.distplot(dat['PitchSatisfactionScore'], hist=True, kde=False, color='darkmagenta');\nplt.title('PitchSatisfactionScore', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,18);\nsns.barplot(x = productpitched[0], y=productpitched[1], color='cyan');\nplt.title('ProductPitched', fontsize=14, fontweight='bold');\nplt.xticks(np.arange(0,5),['Basic', 'Deluxe', 'King', 'Standard', 'Super Deluxe'], fontsize=12, fontweight='bold', rotation=45);\n\nplt.subplot(5,4,19);\nsns.distplot(dat['NumberOfFollowups'], hist=True, kde=False, color='firebrick');\nplt.title('NumberOfFollowups', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\n\nplt.subplot(5,4,20);\nsns.distplot(dat['DurationOfPitch'], hist=False, kde_kws=dict(linewidth=3), color='rebeccapurple');\nplt.title('DurationOfPitch', fontsize=14, fontweight='bold');\nplt.xlabel('', fontsize=12, fontweight='bold');\nplt.yticks(np.arange(0,0.07,0.01),labels=['','','','','','','',''])","88584fdc":"#create dataset of records where the customer purchased a travel package for further analysis\ndat_analysis = dat[dat['ProdTaken']==1]","3356fc68":"fig = plt.figure(figsize=[9,6]);\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Basic','Age'], kde=True, hist=False, label='Basic');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Standard','Age'], kde=True, hist=False, label='Standard');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Deluxe','Age'], kde=True, hist=False, label='Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Super Deluxe','Age'], kde=True, hist=False, label='Super Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'King','Age'], kde=True, hist=False, label='King');\nplt.yticks(np.arange(0,0.12,0.02),labels=['','','','','','']);\nplt.xticks(fontsize=14)\nplt.xlabel('Age', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","d3a5decf":"fig = plt.figure(figsize=[9,6]);\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Basic','MonthlyIncome'], kde=True, hist=False, label='Basic');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Deluxe','MonthlyIncome'], kde=True, hist=False, label='Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Standard','MonthlyIncome'], kde=True, hist=False, label='Standard');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Super Deluxe','MonthlyIncome'], kde=True, hist=False, label='Super Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'King','MonthlyIncome'], kde=True, hist=False, label='King');\nplt.yticks(np.arange(0,0.0002,0.000025),labels=['','','','','','','','']);\nplt.xticks(fontsize=14);\nplt.xlabel('Monthly Income', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","f4aa4914":"fig = plt.figure(figsize=[9,6]);\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Basic','NumberOfTrips'], kde=True, hist=False, label='Basic');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Deluxe','NumberOfTrips'], kde=True, hist=False, label='Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Standard','NumberOfTrips'], kde=True, hist=False, label='Standard');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Super Deluxe','NumberOfTrips'], kde=True, hist=False, label='Super Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'King','NumberOfTrips'], kde=True, hist=False, label='King');\nplt.yticks(np.arange(0,0.4,0.05),labels=['','','','','','','','']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number Of Trips', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","6093443f":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='MaritalStatus', hue='ProductPitched', order=['Single','Divorced','Unmarried','Married'],hue_order=['Basic','Deluxe','Standard','Super Deluxe','King'])\nplt.xticks(fontsize=14);\nplt.xlabel('Marital Status', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12, bbox_to_anchor=(0.5,1));\nplt.title('Current Products', fontsize=16, fontweight='bold');","600bae2f":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='Invited', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks([0,1],labels=['No','Yes'],fontsize=14);\nplt.xlabel('Invited', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","9112e4f3":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='CityTier', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('City Tier', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","fd8bfbbf":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='Gender', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Gender', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","55372fe3":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='NumberOfPersonVisiting', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Persons Visiting', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","7b680fa8":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='Occupation', hue='ProductPitched', order=['Free Lancer','Salaried','Small Business','Large Business'],hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Occupation', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","a8d496ab":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='PreferredPropertyStar', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Preferred Property Star', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","c0a32329":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='Passport', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks([0,1], labels=['No','Yes'],fontsize=14);\nplt.xlabel('Passport', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","19db8db5":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='Designation', hue='ProductPitched',order=['Executive','Manager','Senior Manager','AVP','VP'], hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Designation', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","3069810c":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='NumberOfFollowups', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Followups', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","5bae044c":"fig = plt.figure(figsize=[9,6]);\nsns.barplot(data=dat_analysis, x='NumberOfFollowups', y='ProductPitched', order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Followups', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.title('Current Products', fontsize=16, fontweight='bold');","a46aa41d":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='PitchSatisfactionScore', hue='ProductPitched', hue_order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Pitch Satisfaction Score', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products - Package Purchased', fontsize=16, fontweight='bold');","eb3a8b4e":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat[dat['ProdTaken']==0], x='PitchSatisfactionScore', hue='ProductPitched', hue_order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Pitch Satisfaction Score', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products - Package Not Purchased', fontsize=16, fontweight='bold');","036c544a":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='NumberOfChildrenVisiting', hue='ProductPitched', hue_order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Children Visiting', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","15f512d1":"fig = plt.figure(figsize=[9,6]);\nsns.countplot(data=dat_analysis, x='OwnCar', hue='ProductPitched', hue_order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks([0,1],labels=['No','Yes'],fontsize=14);\nplt.xlabel('Own Car?', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');","8054c7cf":"fig = plt.figure(figsize=[9,6]);\nsns.swarmplot(data=dat_analysis, y='DurationOfPitch', x='ProductPitched', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Duration of Pitch', fontsize=14, fontweight='bold');\nplt.title('Current Products', fontsize=16, fontweight='bold');","2ea1e94c":"x1 = dat_analysis.loc[dat_analysis['ProductPitched']=='Basic', 'DurationOfPitch'].fillna(0)\nx2 = dat_analysis.loc[dat_analysis['ProductPitched']=='Standard', 'DurationOfPitch'].fillna(0)\nx3 = dat_analysis.loc[dat_analysis['ProductPitched']=='Deluxe', 'DurationOfPitch'].fillna(0)\nx4 = dat_analysis.loc[dat_analysis['ProductPitched']=='Super Deluxe', 'DurationOfPitch'].fillna(0)\nx5 = dat_analysis.loc[dat_analysis['ProductPitched']=='King', 'DurationOfPitch'].fillna(0)\n#test for normality of sample data using both Shapiro-Wilks Test and Anderson-Darling Test\nstatistic1, pval1 = stats.shapiro(x1)\nstatistic2, pval2 = stats.shapiro(x2)\nstatistic3, pval3 = stats.shapiro(x3)\nstatistic4, pval4 = stats.shapiro(x4)\nstatistic5, pval5 = stats.shapiro(x5)\nastat1, crit1, sig1 = stats.anderson(x1, dist='norm')\nastat2, crit2, sig2 = stats.anderson(x2, dist='norm')\nastat3, crit3, sig3 = stats.anderson(x3, dist='norm')\nastat4, crit4, sig4 = stats.anderson(x4, dist='norm')\nastat5, crit5, sig5 = stats.anderson(x5, dist='norm')\n\n#print results\nblah1 = astat1\/crit1[4]\nblah2 = astat2\/crit2[4]\nblah3 = astat3\/crit3[4]\nblah4 = astat4\/crit4[4]\nblah5 = astat5\/crit5[4]\nprint(\"Shapiro-Wilks test:\")\nprint('Duration of Pitch for Basic:          p-value: %.8f' % pval1)\nprint('Duration of Pitch for Standard:       p-value: %.8f' % pval2)\nprint('Duration of Pitch for Deluxe:         p-value: %.8f' % pval3)\nprint('Duration of Pitch for Super Deluxe:   p-value: %.8f' % pval4)\nprint('Duration of Pitch for King:           p-value: %.8f' % pval5)\nprint('\\nAnderson-Darling Test:')\nprint('Duration of Pitch for Basic:          Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah1)\nprint('Duration of Pitch for Standard:       Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah2)\nprint('Duration of Pitch for Deluxe:         Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah3)\nprint('Duration of Pitch for Super Deluxe:   Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah4)\nprint('Duration of Pitch for King:           Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah5)\nprint('\\nNumber of samples:')\nprint('Duration of Pitch for Basic:          n = {}' .format(len(x1)))\nprint('Duration of Pitch for Standard:       n = {}' .format(len(x2)))\nprint('Duration of Pitch for Deluxe:         n = {}' .format(len(x3)))\nprint('Duration of Pitch for Super Deluxe:   n = {}' .format(len(x4)))\nprint('Duration of Pitch for King:           n = {}' .format(len(x5)))","b1a82998":"#use Levene's test for equality of variace because the data departs from normality, otherwise, we would have used Bartlett's test\nstat, pval = stats.levene(x1, x2, x3, x4, x5, center='mean')\n\nif pval < 0.05:\n    print('Reject Null Hypothesis: the variances are not equal for at least one pair.\\np-value: %.8f' % pval)\nelse:\n    print('Fail to Reject Null Hypothesis: the variances are equal across all samples.\\np-value: %.8f' % pval)","cfe7cf63":"formulated = pd.DataFrame()\n\na = pd.DataFrame({'product': 'Basic', 'durationpitch':x1})\nb = pd.DataFrame({'product': 'Standard', 'durationpitch':x2})\nc = pd.DataFrame({'product': 'Deluxe', 'durationpitch':x3})\nd = pd.DataFrame({'product': 'Super Deluxe', 'durationpitch':x4})\ne = pd.DataFrame({'product': 'King', 'durationpitch':x5})\n\nformulated = formulated.append(a) \nformulated = formulated.append(b) \nformulated = formulated.append(c)\nformulated = formulated.append(d)\nformulated = formulated.append(e)\nformulated = formulated.reset_index(drop=True)","c81d57a5":"mod = ols('durationpitch ~ C(product)', data = formulated).fit()\n#We'll assume that interactions are not significant and perform a type II sums of squares ANOVA\naov = sm.stats.anova_lm(mod, typ='II')  \naov","de3adc03":"name = ['Jarque-Bera', 'Chi^2 two-tail prob.', 'Skew', 'Kurtosis']\ntest = sms.jarque_bera(mod.resid)\nprint('Jarque-Bera: %.4f' % test[0])\nprint('Chi-Square:  %.4f' % test[1])\nprint('Skew:        %.4f' % test[2])\nprint('Kurtosis:    %.4f' % test[3])","bfe47768":"tukey = pairwise_tukeyhsd(endog=formulated['durationpitch'], groups=formulated['product'], alpha=0.05)\nprint(tukey)","86b27e32":"fig=plt.figure(figsize=[9,6]);\nsns.boxplot(data=dat_analysis, y='DurationOfPitch', x='ProductPitched', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Duration of Pitch', fontsize=14, fontweight='bold');\nplt.title('Current Products', fontsize=16, fontweight='bold');","7ad65db0":"fig=plt.figure(figsize=[9,6]);\nsns.countplot(data=dat, x='ProductPitched', order=['Basic','Standard','Deluxe','Super Deluxe','King'], color='navy', label='Pitched');\nsns.countplot(data=dat_analysis, x='ProductPitched', order=['Basic','Standard','Deluxe','Super Deluxe','King'], color='slategray', Label='Bought');\nplt.xticks(fontsize=14);\nplt.xlabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('count', fontsize=14, fontweight='bold');\nplt.title('Current Products', fontsize=16, fontweight='bold');","c94f5b45":"pp_dat = np.unique(dat['ProductPitched'], return_counts=True)\npp_dat_a = np.unique(dat_analysis['ProductPitched'], return_counts=True)\npp_per = pd.DataFrame()\npp_per['desc'] = pp_dat[0]\npp_per['percent'] = pp_dat_a[1]\/pp_dat[1]*100\npp_per['percent'] = pp_per['percent'].apply(int)\nfig = plt.figure(figsize=[9,6])\nsns.barplot(data=pp_per, x='percent', y='desc', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.ylabel('');\nplt.yticks(fontsize=14, fontweight='bold');\nplt.xticks(fontsize=14, fontweight='bold');\nplt.xlabel('(%)',fontsize=14, fontweight='bold');\nplt.title('Conversion Rate - Current Products', fontsize=14, fontweight='bold');","300c81a9":"for i in dat.columns:\n    if np.dtype(dat[i]) == 'O':\n        dat[i] = dat[i].astype('category')","84464964":"#plot correlation matrix heatmap\nfig, ax = plt.subplots(figsize=[30,20])\nsns.heatmap(pd.get_dummies(dat).corr(), ax=ax,  annot=True, linewidths=0.05, fmt= '.2f',cmap=\"RdBu\", vmin=-1, vmax=1)\nax.tick_params(axis='both', which='major', labelsize=14)\nax.set_title('Dataset Correlation Matrix', fontdict={'family': 'serif', 'color': 'black', 'size': 18, 'weight': 'bold'})\nfig.show();","2a339afb":"#create dummie variables from boolean and integer categorical so that the model may perform better.\ndat1 = pd.get_dummies(dat)","68601aeb":"#look at nan and null values\ndat1.isna().sum()[dat1.isna().sum()!= 0]","89170a14":"# work on copy of dataframe\ndat2=dat1.copy()\n\n#initialize imputer\nimputer = KNNImputer(n_neighbors=3)\n\n# Run imputer on dataframe\ndat2[:] = imputer.fit_transform(dat2)","c08d6ce4":"a = dat1.describe().T\nb = dat2.describe().T\n\ncomp = pd.DataFrame()\n\ncomp['before_mean'] = a['mean'].values\ncomp['after_mean'] = b['mean'].values\ncomp['before_std'] = a['std'].values\ncomp['after_std'] = b['std'].values\ncomp['before_min'] = a['min'].values\ncomp['after_min'] = b['min'].values\ncomp['before_25%'] = a['25%'].values\ncomp['after_25%'] = b['25%'].values\ncomp['before_50%'] = a['50%'].values\ncomp['after_50%'] = b['50%'].values\ncomp['before_75%'] = a['75%'].values\ncomp['after_75%'] = b['75%'].values\ncomp['before_max'] = a['max'].values\ncomp['after_max'] = b['max'].values\ncomp.set_index(a.index.values, inplace=True)\ncomp","d2903e30":"blah = list(dat.dtypes != 'category')\n    \n#create fontdict for axis labels\naxlab2 = {'family': 'serif',\n              'color': 'black',\n              'weight': 'bold',\n              'size': 16\n         }\n#create subplot layout\nfig = plt.figure(figsize=[10,20]);\nx = list(dat.loc[:,blah].columns);\ngrid = plt.GridSpec(len(x), 1, wspace=0.3, hspace=1.2);\ncol = ['forestgreen','dodgerblue','goldenrod', 'coral', 'slategrey','magenta','indigo','cyan','lime','saddlebrown', 'maroon', 'darkseagreen','deepskyblue','khaki'];\n\n#loop to populate boxplots within subplots\nfor i in np.arange(0,len(x)):\n    for j in np.arange(0,1): \n        exec(f'ax{i}{j} = plt.subplot(grid[i,j]);')\n        exec(f'sns.boxplot(x=dat1[x[{i}]], ax=ax{i}{j}, color=col[{i}]);')\n        exec(f'ax{i}{j}.set_title(x[{i}], fontdict=axlab2);')\n        exec(f'ax{i}{j}.set_xlabel(\"\", fontdict=axlab2);')\n        exec(f'a{i} = ax{i}{j}.axvline(dat1[x[{i}]].mean(),color= \"red\", linestyle=\"--\", label=\"mean\")')\n        exec(f'b{i} = ax{i}{j}.axvline(dat1[x[{i}]].mean()+ 3 * dat1[x[{i}]].std(),color= \"orange\", linestyle=\"--\", label=\"3sigma\")')\n        exec(f'ax{i}{j}.axvline(max([dat1[x[{i}]].mean()- 3 * dat1[x[{i}]].std(), 0]),color= \"orange\", linestyle=\"--\")')\n        exec(f'c{i} = ax{i}{j}.axvline(dat1[x[{i}]].mean()+ 2 * dat1[x[{i}]].std(),color= \"slategrey\", linestyle=\"--\", label=\"2sigma\")')\n        exec(f'ax{i}{j}.axvline(max([dat1[x[{i}]].mean()- 2 * dat1[x[{i}]].std(), 0]),color= \"slategrey\", linestyle=\"--\")')\n        plt.xticks(fontsize=14);\n\nplt.legend([a0, c0, b0], ['mean','2sigma','3sigma'], loc='upper center', bbox_to_anchor=(0.9, 31.8), fontsize=14)        \nfig.show();","fa4f8bb1":"#creating a sample_weights array based upon demographic data from the Jamaica study on tourism \nsamp_weights = []\nfor i in np.arange(0,len(dat2)):\n    blah = 0\n    \n    # Calculate weight factor for age\n    if dat2.loc[i,'Age'] <= 24:\n        blah += 8\n    elif np.logical_and(dat2.loc[i,'Age'] > 24, dat2.loc[i,'Age'] <= 34):\n        blah += 23\n    elif np.logical_and(dat2.loc[i,'Age'] > 34, dat2.loc[i,'Age'] <= 49):\n        blah += 34\n    elif np.logical_and(dat2.loc[i,'Age'] > 49, dat2.loc[i,'Age'] <= 64):\n        blah += 28\n    else:\n        blah += 6\n    \n    #caclulate weight factor for gender\n    if dat2.loc[i,'Gender_Male'] == 1:\n        blah += 42\n    else:\n        blah += 58\n    \n    #calculate weight factor for income\n    if dat2.loc[i,'MonthlyIncome'] <= 25000:\n        blah += 74\n    elif np.logical_and(dat2.loc[i,'MonthlyIncome'] > 25000, dat2.loc[i,'MonthlyIncome'] <= 50000):\n        blah += 9\n    elif np.logical_and(dat2.loc[i,'MonthlyIncome'] > 50000, dat2.loc[i,'MonthlyIncome'] <= 75000):\n        blah += 7\n    elif np.logical_and(dat2.loc[i,'MonthlyIncome'] > 75000, dat2.loc[i,'MonthlyIncome'] <= 100000):\n        blah += 4\n    else:\n        blah += 7\n    \n    #calculate weight factor for maritalstatus\n    if np.logical_or(dat2.loc[i,'MaritalStatus_Married'] == 1, dat2.loc[i,'MaritalStatus_Unmarried'] == 1):\n        blah += 53\n    \n    #calculate weight factor for children\n    if dat2.loc[i, 'NumberOfChildrenVisiting'] > 0:\n        blah += 21\n    \n    #calculate weight for travelling alone (this is a likelihood guess here)\n    if np.logical_and(np.logical_and(dat2.loc[i,'MaritalStatus_Married'] == 0, dat2.loc[i,'MaritalStatus_Unmarried'] == 0), dat2.loc[i,'NumberOfChildrenVisiting'] == 0):\n        blah += 12\n    \n    #caclulate weight for domestic vs. international possibility (domestic weighting factor 82, international 82+18)\n    #this was determined from the statistic that 82% of welness trips were domestic, so if a potential traveller\n    #doesnt have a passport, they are not part of the international travel group (18%) are are weighted at 82, not 100\n    if dat2.loc[i, 'Passport'] == 1:\n        blah += 100\n    else:\n        blah += 82\n    \n    samp_weights.append(blah)","8c73750c":"pd.DataFrame(samp_weights, columns=['Sample Weights']).describe()","d3a77bb6":"fig = plt.figure(figsize=[9,8])\ngrid = plt.GridSpec(6, 1, wspace=0.3, hspace=0.2)\n\nax0 = plt.subplot(grid[0:5, 0])\nsns.distplot(samp_weights, ax=ax0, color='green');\nax0.axvline(np.mean(samp_weights),color= \"red\", linestyle=\"--\", label=\"mean\")\nplt.title('Sample Weights Caclulated from Jamaica Tourism Demographics', fontsize = 16, fontweight='bold');\nplt.xticks(np.arange(125,401,25),labels=['','','','','','','','','','','',''])\nplt.yticks(np.arange(0,0.0121,0.002),labels=['','','','','','',''])\nax1 = plt.subplot(grid[5, 0])\nsns.boxplot(x = samp_weights, ax=ax1, color='forestgreen')\nplt.xticks(np.arange(125,401,25),labels=['125','150','175','200','225','250','275','300','325','350','375','400'], fontsize=14, fontweight='bold');","e2c7ba2d":"fig = plt.figure(figsize=[16,6]);\nsns.swarmplot(hue = dat['ProdTaken'], y = samp_weights, x=dat['ProductPitched'], order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.title('Sample Weights by Product', fontsize=16, fontweight='bold');\nplt.ylabel('Sample Weights', fontsize=16);\nplt.yticks(np.arange(150,351,25),labels=['150','175','200','225','250','275','300','325','350'], fontsize=14, fontweight='bold');\nplt.xlabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.xticks([0,1,2,3,4], labels=['Basic','Deluxe','Standard','Super Deluxe','King'], fontsize=14);\nplt.legend(title='Product Taken');","363065b6":"#generate boolean fields to look at ProdTaken=1 when weights are above mean for the purpose of making a prediction\n#about where to expect the accuracy of the model to make a presumption about how closely the model follows the \n#sample weights.\nsamp_bool = []\nfor i in np.arange(0,len(samp_weights)):\n    if samp_weights[i] > np.mean(samp_weights):\n        samp_bool.append(1)\n    else:\n        samp_bool.append(0)\nsamp_bool = samp_bool*dat['ProdTaken']        ","048d7576":"#make approximation of ideal accuracy score using sample weights. The idea here is that weights above the mean\n#are accurate predictions of wellness tourists \n(samp_bool == dat['ProdTaken']).sum()\/len(dat['ProdTaken'])","7c713807":"#drop dummy variables that will cause overfitting\n#also dropping PitchSatisfactionScore because it is not helpful because the information is gained after the pitch\ndat2.drop(columns=['Occupation_Free Lancer', 'Gender_Male','ProductPitched_Super Deluxe','MaritalStatus_Unmarried','Designation_Senior Manager','PitchSatisfactionScore'], inplace=True)\ndat2['samp_weights'] = samp_weights","3e23f77e":"X = dat2.drop(columns=['ProdTaken'])\ny = dat['ProdTaken']\n#Perform 50\/50 test train split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=42)\nfit_weights_train = X_train['samp_weights']\nfit_weights_test = X_test['samp_weights']\nX_train.drop(columns=['samp_weights'], inplace=True)\nX_test.drop(columns=['samp_weights'], inplace=True)","b2098e6e":"#the below function displays performance metrics for each model as CVGridSearch performs cross validation\ndef evaluate_model(name, model, features, labels):\n    beg = datetime.datetime.now()\n    pred = model.predict(features)\n    end = datetime.datetime.now()\n    accuracy = round(accuracy_score(labels, pred), 3)\n    precision = round(precision_score(labels, pred), 3)\n    recall = round(recall_score(labels, pred), 3)\n    print('{} -- Accuracy: {} \/ Precision: {} \/ Recall: {} \/ Latency: {}ms'.format(name, accuracy, precision, recall, (end-beg).microseconds\/1000))\n    \n#the below function displays performance metrics of best model calculated through CVGridSearch\ndef print_results(results):\n    print('BEST PARAMETERS: {}\\n'.format(results.best_params_))\n\n    means = results.cv_results_['mean_test_score']\n    stds = results.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n        print('{} (+\/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))\n\n#Function to calculate recall score\ndef get_recall_score(model, train, test):\n    pred_train = model.predict(train)\n    pred_test = model.predict(test)\n    print(\"Recall on training set : \",metrics.recall_score(y_train,pred_train))\n    print(\"Recall on test set : \",metrics.recall_score(y_test,pred_test))\n    \n#the below function generated confusion matrix\ndef make_confusion_matrix(y_actual,y_predict,labels=[1, 0]):\n    cm=confusion_matrix( y_actual,y_predict, labels=[1, 0])\n    df_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in ['Product Taken','Product Not Taken']])\n    group_counts = [\"{0:0.0f}\".format(value) for value in\n                cm.flatten()]\n    group_percentages = [\"{0:.2%}\".format(value) for value in\n                         cm.flatten()\/np.sum(cm)]\n    labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n              zip(group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n    fig = plt.figure(figsize = (10,7))\n    hmp = sns.heatmap(df_cm, annot=labels,fmt='')\n    hmp.set_xticklabels(hmp.get_xmajorticklabels(), fontsize = 14, fontweight='bold')\n    hmp.set_yticklabels(hmp.get_ymajorticklabels(), fontsize = 14, fontweight='bold')\n    plt.ylabel('True label', fontsize = 14, fontweight='bold')\n    plt.xlabel('Predicted label',fontsize = 14, fontweight='bold')","f9f0dfa8":"# compute optimal class weight using sklearn function\nclass_weights = compute_class_weight('balanced', [0,1], y)","113c7bb6":"class_weights","27f19cab":"#parameter grid for CVGridSearch to iterate through to tune hyperparameters\nparams = {'max_depth': list(np.arange(2,20)) + [None], \n          'min_samples_leaf': [1, 3, 5, 7, 10],\n          'max_leaf_nodes' : [2, 3, 5, 10, 15] + [None],\n          'min_impurity_decrease': [0.001, 0.01, 0.1, 0.0]\n          }\n\n#initialize decision tree classifier solver\ndt = DecisionTreeClassifier(random_state=42)\n\n#initialize grid search by inputting model, paramter grid, and # of folds in cross validation\ncv = GridSearchCV(dt, params, cv=5)\n\n#Fit the model to the training data\ncv.fit(X_train, y_train, sample_weight=fit_weights_train)\ndtree = cv.best_estimator_","17bfc276":"evaluate_model('Decision Tree', cv.best_estimator_, X_test, y_test)","605c76df":"make_confusion_matrix(y_test, cv.best_estimator_.predict(X_test))\nplt.title('Confusion Matrix', fontsize=16, fontweight='bold');","93fd3a67":"feature_names = X_train.columns\nimportances = dtree.feature_importances_\nindices = np.argsort(importances);\nfig=plt.figure(figsize=[4,10]);\nplt.title('Decision Tree', fontsize=14, fontweight='bold');\nplt.barh(range(len(indices)), importances[indices], align='center', color='saddlebrown');\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices], fontsize=12);\nplt.xlabel('Feature Importance', fontsize=14, fontweight='bold');","457eb7e5":"#parameter grid for CVGridSearch to iterate through to tune hyperparameters\nparams = {'base_estimator': [DecisionTreeClassifier(criterion='gini',class_weight={0: class_weights[0], 1: class_weights[1]},random_state=42)],\n          'n_estimators': [50, 80, 100, 120],\n          'max_samples': np.arange(0.6,0.91,0.1),\n          'max_features': np.arange(0.6,0.91,0.1),\n          'bootstrap': [False],\n          'bootstrap_features': [False]}\n\n#initialize bagging classifier solver\nbc = BaggingClassifier(random_state=42)\n\n#initialize grid search by inputting model, paramter grid, and # of folds in cross validation\ncv = GridSearchCV(bc, params, cv=5)\n\n#Fit the model to the training data\ncv.fit(X_train, y_train, sample_weight=fit_weights_train)\nbagging = cv.best_estimator_","0d07ae7d":"evaluate_model('Bagging', cv.best_estimator_, X_test, y_test)","b5129cc9":"make_confusion_matrix(y_test, cv.best_estimator_.predict(X_test))\nplt.title('Confusion Matrix', fontsize=16, fontweight='bold');","48880c4f":"#parameter grid for CVGridSearch to iterate through to tune hyperparameters\nparams = {'max_depth':[4, 6, 8, 10, None],\n          'max_features': ['sqrt','log2',None],\n          'n_estimators': [80, 90, 100, 110, 120]}\n\n#initialize bagging classifier solver\nrf = RandomForestClassifier(random_state=42)\n\n#initialize grid search by inputting model, paramter grid, and # of folds in cross validation\ncv = GridSearchCV(rf, params, cv=5)\n\n#Fit the model to the training data\ncv.fit(X_train, y_train, sample_weight=fit_weights_train)\nrandfor = cv.best_estimator_","f20f26e4":"evaluate_model('Random Forest', cv.best_estimator_, X_test, y_test)","a9c072a2":"make_confusion_matrix(y_test, cv.best_estimator_.predict(X_test))\nplt.title('Confusion Matrix', fontsize=16, fontweight='bold');","78767d1c":"feature_names = X_train.columns\nimportances = randfor.feature_importances_\nindices = np.argsort(importances)\nfig=plt.figure(figsize=[4,10]);\nplt.title('Random Forest', fontsize=14, fontweight='bold');\nplt.barh(range(len(indices)), importances[indices], align='center', color='forestgreen');\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices], fontsize=12);\nplt.xlabel('Feature Importance', fontsize=14, fontweight='bold');","5767d2ad":"#parameter grid for CVGridSearch to iterate through to tune hyperparameters\nparams = {'n_estimators': np.arange(10,100,10), \n          'learning_rate': [1, 0.1, 0.5, 0.01]}\n\n#initialize bagging classifier solver\nab = AdaBoostClassifier(random_state=42)\n\n#initialize grid search by inputting model, paramter grid, and # of folds in cross validation\ncv = GridSearchCV(ab, params, cv=5)\n\n#Fit the model to the training data\ncv.fit(X_train, y_train, sample_weight=fit_weights_train)\nada = cv.best_estimator_","ffec666d":"evaluate_model('AdaBoost', cv.best_estimator_, X_test, y_test)","453c4f25":"make_confusion_matrix(y_test, cv.best_estimator_.predict(X_test))\nplt.title('Confusion Matrix', fontsize=16, fontweight='bold');","d345f36c":"#parameter grid for CVGridSearch to iterate through to tune hyperparameters\nparams = {'n_estimators': np.arange(50,200,25), \n          'subsample':[0.7,0.8,0.9,1],\n          'max_features':[0.7,0.8,0.9,1],\n          'max_depth':[3,5,7,10]}\n\n#initialize bagging classifier solver\ngb = GradientBoostingClassifier(random_state=42)\n\n#initialize grid search by inputting model, paramter grid, and # of folds in cross validation\ncv = GridSearchCV(gb, params, cv=5)\n\n#Fit the model to the training data\ncv.fit(X_train, y_train, sample_weight=fit_weights_train)\ngradboost = cv.best_estimator_","8704e4b1":"evaluate_model('Gradient Boosting', cv.best_estimator_, X_test, y_test)","45dfa8e9":"make_confusion_matrix(y_test, cv.best_estimator_.predict(X_test))\nplt.title('Confusion Matrix', fontsize=16, fontweight='bold');","f0f22ce0":"feature_names = X_train.columns\nimportances = gradboost.feature_importances_\nindices = np.argsort(importances)\nfig=plt.figure(figsize=[4,10]);\nplt.title('Gradient Boosting', fontsize=14, fontweight='bold');\nplt.barh(range(len(indices)), importances[indices], align='center', color='darkorange');\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices], fontsize=12);\nplt.xlabel('Feature Importance', fontsize=14, fontweight='bold');","5765d9ca":"#parameter grid for CVGridSearch to iterate through to tune hyperparameters\nparams = {'n_estimators': [75,100,125,150], \n          'subsample':[0.7, 0.8, 0.9, 1],\n          'gamma':[0, 1, 3, 5],\n          'colsample_bytree':[0.7, 0.8, 0.9, 1],\n          'colsample_bylevel':[0.7, 0.8, 0.9, 1]}\n\n#initialize XBBoost classifier solver\nXgb = XGBClassifier(random_state=42, eval_metric='logloss')\n\n#initialize grid search by inputting model, paramter grid, and # of folds in cross validation\ncv = GridSearchCV(Xgb, params, cv=5)\n\n#Fit the model to the training data\ncv.fit(X_train, y_train, sample_weight=fit_weights_train)\nXgboost = cv.best_estimator_","97a38532":"evaluate_model('XGBoost', cv.best_estimator_, X_test, y_test)","04b2cd96":"feature_names = X_train.columns\nimportances = Xgboost.feature_importances_\nindices = np.argsort(importances)\nfig=plt.figure(figsize=[4,10]);\nplt.title('XGBoost', fontsize=14, fontweight='bold');\nplt.barh(range(len(indices)), importances[indices], align='center', color='cornflowerblue');\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices], fontsize=12);\nplt.xlabel('Feature Importance', fontsize=14, fontweight='bold');","362ead23":"estimators=[('Decision Tree', dtree),('Random Forest', randfor),('Gradient Boosting', gradboost)]\nfinal_estimator=AdaBoostClassifier(random_state=42)\n\nstacking=StackingClassifier(estimators=estimators, final_estimator=final_estimator,cv=5)\nstacking.fit(X_train,y_train, sample_weight=fit_weights_train)","5ea3cf59":"evaluate_model('Stacking', stacking, X_test, y_test)","f92509f9":"make_confusion_matrix(y_test, stacking.predict(X_test))\nplt.title('Confusion Matrix', fontsize=16, fontweight='bold');","12b940f1":"##  Function to calculate accuracy score ***From MLS1 Notebook*** \ndef get_accuracy_score(model,flag=True):\n    '''\n    model : classifier to predict values of X\n\n    '''\n    c = [] # defining an empty list to store train and test results\n    train_acc = model.score(X_train,y_train)\n    test_acc = model.score(X_test,y_test)\n    c.append(train_acc) # adding train accuracy to list\n    c.append(test_acc) # adding test accuracy to list\n    if flag == True: # If the flag is set to True then only the following print statements will be dispayed\n        print(\"Accuracy on training set : \",model.score(X_train,y_train))\n        print(\"Accuracy on test set : \",model.score(X_test,y_test))\n    \n    return c # returning the list with train and test scores\n\n##  Function to calculate recall score ***From MLS1 Notebook***\ndef get_recall_score(model,flag=True):\n    '''\n    model : classifier to predict values of X\n\n    '''\n    a = [] # defining an empty list to store train and test results\n    pred_train = model.predict(X_train)\n    pred_test = model.predict(X_test)\n    train_recall = recall_score(y_train,pred_train)\n    test_recall = recall_score(y_test,pred_test)\n    a.append(train_recall) # adding train recall to list \n    a.append(test_recall) # adding test recall to list\n    if flag == True: # If the flag is set to True then only the following print statements will be dispayed\n        print(\"Recall on training set : \",metrics.recall_score(y_train,pred_train))\n        print(\"Recall on test set : \",metrics.recall_score(y_test,pred_test))\n    \n    return a # returning the list with train and test scores\n\n##  Function to calculate precision score ***From MLS1 Notebook*** \ndef get_precision_score(model,flag=True):\n    '''\n    model : classifier to predict values of X\n\n    '''\n    b = []  # defining an empty list to store train and test results\n    pred_train = model.predict(X_train)\n    pred_test = model.predict(X_test)\n    train_precision = precision_score(y_train,pred_train)\n    test_precision = precision_score(y_test,pred_test)\n    b.append(train_precision) # adding train precision to list\n    b.append(test_precision) # adding test precision to list\n    if flag == True: # If the flag is set to True then only the following print statements will be dispayed\n        print(\"Precision on training set : \",metrics.precision_score(y_train,pred_train))\n        print(\"Precision on test set : \",metrics.precision_score(y_test,pred_test))\n\n    return b # returning the list with train and test scores\n\n# defining list of models\nmodels = [dtree,bagging,randfor,ada,gradboost,Xgboost,stacking]\n# defining empty lists to add train and test results\nacc_train = []\nacc_test = []\nrecall_train = []\nrecall_test = []\nprecision_train = []\nprecision_test = []\n\n# looping through all the models to get the accuracy,recall and precision scores\nfor model in models:\n    # accuracy score\n    j = get_accuracy_score(model,False)\n    acc_train.append(j[0])\n    acc_test.append(j[1])\n    # recall score\n    k = get_recall_score(model,False)\n    recall_train.append(k[0])\n    recall_test.append(k[1])\n    # precision score\n    l = get_precision_score(model,False)\n    precision_train.append(l[0])\n    precision_test.append(l[1])\n\ncomparison_frame = pd.DataFrame({'Model':['Decision Tree','Bagging Classifier',\n                                          'Random Forest','AdaBoost Classifier',\n                                          'GradientBoost Classifier','XGBoost','Stacking'], \n                                          'Train_Accuracy': acc_train,\n                                          'Test_Accuracy': acc_test,\n                                          'Train_Recall': recall_train,\n                                          'Test_Recall': recall_test,\n                                          'Train_Precision': precision_train,\n                                          'Test_Precision': precision_test}) \n#comparison_frame = comparison_frame.append(Xgboost)\ncomparison_frame['sort'] = [0,1,2,3,4,6,5]\ncomparison_frame.sort_values(by='sort', inplace=True)\ncomparison_frame.reset_index(drop=True, inplace=True)\ncomparison_frame.drop(columns='sort', inplace=True)\ncomparison_frame","22480190":"dat_well = X_test.copy()\npred = stacking.predict(X_test)\nblah = list(dat_well[pred==1].index)\nwell_analysis = dat.loc[blah,:]","c8994edf":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.1);\n\nplt.subplot(1,2,1);\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Basic','Age'], kde=True, hist=False, label='Basic');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Standard','Age'], kde=True, hist=False, label='Standard');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Deluxe','Age'], kde=True, hist=False, label='Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Super Deluxe','Age'], kde=True, hist=False, label='Super Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'King','Age'], kde=True, hist=False, label='King');\nplt.yticks(np.arange(0,0.12,0.02),labels=['','','','','','']);\nplt.xticks(fontsize=14)\nplt.xlabel('Age', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Basic','Age'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Standard','Age'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Deluxe','Age'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Super Deluxe','Age'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'King','Age'], kde=True, hist=False);\nplt.yticks(np.arange(0,0.12,0.02),labels=['','','','','','']);\nplt.xticks(fontsize=14)\nplt.xlabel('Age', fontsize=14, fontweight='bold');\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","7a5515be":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.1);\n\nplt.subplot(1,2,1);\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Basic','MonthlyIncome'], kde=True, hist=False, label='Basic');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Deluxe','MonthlyIncome'], kde=True, hist=False, label='Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Standard','MonthlyIncome'], kde=True, hist=False, label='Standard');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Super Deluxe','MonthlyIncome'], kde=True, hist=False, label='Super Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'King','MonthlyIncome'], kde=True, hist=False, label='King');\nplt.yticks(np.arange(0,0.0002,0.000025),labels=['','','','','','','','']);\nplt.xticks(fontsize=14);\nplt.xlabel('Monthly Income', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Basic','MonthlyIncome'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Deluxe','MonthlyIncome'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Standard','MonthlyIncome'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Super Deluxe','MonthlyIncome'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'King','MonthlyIncome'], kde=True, hist=False);\nplt.yticks(np.arange(0,0.0002,0.000025),labels=['','','','','','','','']);\nplt.xticks(fontsize=14);\nplt.xlabel('Monthly Income', fontsize=14, fontweight='bold');\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","1aafa5ff":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.1);\n\nplt.subplot(1,2,1);\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Basic','NumberOfTrips'], kde=True, hist=False, label='Basic');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Deluxe','NumberOfTrips'], kde=True, hist=False, label='Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Standard','NumberOfTrips'], kde=True, hist=False, label='Standard');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'Super Deluxe','NumberOfTrips'], kde=True, hist=False, label='Super Deluxe');\nsns.distplot(dat_analysis.loc[dat_analysis['ProductPitched'] == 'King','NumberOfTrips'], kde=True, hist=False, label='King');\nplt.yticks(np.arange(0,0.4,0.05),labels=['','','','','','','','']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number Of Trips', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Basic','NumberOfTrips'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Deluxe','NumberOfTrips'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Standard','NumberOfTrips'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'Super Deluxe','NumberOfTrips'], kde=True, hist=False);\nsns.distplot(well_analysis.loc[well_analysis['ProductPitched'] == 'King','NumberOfTrips'], kde=True, hist=False);\nplt.yticks(np.arange(0,0.4,0.05),labels=['','','','','','','','']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number Of Trips', fontsize=14, fontweight='bold');\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","36ea9ce5":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='MaritalStatus', hue='ProductPitched', order=['Single','Divorced','Unmarried','Married'],hue_order=['Basic','Deluxe','Standard','Super Deluxe','King'])\nplt.xticks(fontsize=14);\nplt.xlabel('Marital Status', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12, bbox_to_anchor=(0.5,1));\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='MaritalStatus', hue='ProductPitched', order=['Single','Divorced','Unmarried','Married'],hue_order=['Basic','Deluxe','Standard','Super Deluxe','King'])\nplt.xticks(fontsize=14);\nplt.xlabel('Marital Status', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","c9add80e":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='Invited', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks([0,1],labels=['No','Yes'],fontsize=14);\nplt.xlabel('Invited', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='Invited', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks([0,1],labels=['No','Yes'],fontsize=14);\nplt.xlabel('Invited', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","7920e8d9":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='CityTier', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('City Tier', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='CityTier', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('City Tier', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","8dff28ef":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='Gender', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Gender', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='Gender', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Gender', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","1d469ec8":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='NumberOfPersonVisiting', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Persons Visiting', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='NumberOfPersonVisiting', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Persons Visiting', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","88dad83a":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='Occupation', hue='ProductPitched', order=['Free Lancer','Salaried','Small Business','Large Business'],hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Occupation', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='Occupation', hue='ProductPitched', order=['Free Lancer','Salaried','Small Business','Large Business'], hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Occupation', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","8f29ce43":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='PreferredPropertyStar', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Preferred Property Star', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='PreferredPropertyStar', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Preferred Property Star', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","73aa68a7":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='Passport', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks([0,1], labels=['No','Yes'],fontsize=14);\nplt.xlabel('Passport', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='Passport', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks([0,1], labels=['No','Yes'],fontsize=14);\nplt.xlabel('Passport', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","15209276":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='Designation', hue='ProductPitched',order=['Executive','Manager','Senior Manager','AVP','VP'], hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Designation', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='Designation', hue='ProductPitched',order=['Executive','Manager','Senior Manager','AVP','VP'], hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Designation', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","584e423d":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='NumberOfFollowups', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Followups', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='NumberOfFollowups', hue='ProductPitched', hue_order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Followups', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","1ba87ca1":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.35);\n\nplt.subplot(1,2,1);\nsns.barplot(data=dat_analysis, x='NumberOfFollowups', y='ProductPitched', order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Followups', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.barplot(data=well_analysis, x='NumberOfFollowups', y='ProductPitched', order=['Basic','Deluxe','Standard','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Followups', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","114a1623":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='NumberOfChildrenVisiting', hue='ProductPitched', hue_order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Children Visiting', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='NumberOfChildrenVisiting', hue='ProductPitched', hue_order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Number of Children Visiting', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","3d8e8969":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.countplot(data=dat_analysis, x='OwnCar', hue='ProductPitched', hue_order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks([0,1],labels=['No','Yes'],fontsize=14);\nplt.xlabel('Own Car?', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend(fontsize=12);\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.countplot(data=well_analysis, x='OwnCar', hue='ProductPitched', hue_order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks([0,1],labels=['No','Yes'],fontsize=14);\nplt.xlabel('Own Car?', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Count', fontsize=14, fontweight='bold');\nplt.legend('',frameon=False);\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","69e54bde":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.swarmplot(data=dat_analysis, y='DurationOfPitch', x='ProductPitched', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Duration of Pitch', fontsize=14, fontweight='bold');\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.swarmplot(data=well_analysis, y='DurationOfPitch', x='ProductPitched', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Duration of Pitch', fontsize=14, fontweight='bold');\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","158c509f":"fig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.15);\n\nplt.subplot(1,2,1);\nsns.boxplot(data=dat_analysis, y='DurationOfPitch', x='ProductPitched', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Duration of Pitch', fontsize=14, fontweight='bold');\nplt.title('Current Products', fontsize=16, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.boxplot(data=well_analysis, y='DurationOfPitch', x='ProductPitched', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.xticks(fontsize=14);\nplt.xlabel('Product Pitched', fontsize=14, fontweight='bold');\nplt.yticks(fontsize=14);\nplt.ylabel('Duration of Pitch', fontsize=14, fontweight='bold');\nplt.title('Wellness Tourism Prediction', fontsize=16, fontweight='bold');","87197c82":"x1 = well_analysis.loc[well_analysis['ProductPitched']=='Basic', 'DurationOfPitch'].fillna(0)\nx2 = well_analysis.loc[well_analysis['ProductPitched']=='Standard', 'DurationOfPitch'].fillna(0)\nx3 = well_analysis.loc[well_analysis['ProductPitched']=='Deluxe', 'DurationOfPitch'].fillna(0)\nx4 = well_analysis.loc[well_analysis['ProductPitched']=='Super Deluxe', 'DurationOfPitch'].fillna(0)\nx5 = well_analysis.loc[well_analysis['ProductPitched']=='King', 'DurationOfPitch'].fillna(0)\n#test for normality of sample data using both Shapiro-Wilks Test and Anderson-Darling Test\nstatistic1, pval1 = stats.shapiro(x1)\nstatistic2, pval2 = stats.shapiro(x2)\nstatistic3, pval3 = stats.shapiro(x3)\nstatistic4, pval4 = stats.shapiro(x4)\nstatistic5, pval5 = stats.shapiro(x5)\nastat1, crit1, sig1 = stats.anderson(x1, dist='norm')\nastat2, crit2, sig2 = stats.anderson(x2, dist='norm')\nastat3, crit3, sig3 = stats.anderson(x3, dist='norm')\nastat4, crit4, sig4 = stats.anderson(x4, dist='norm')\nastat5, crit5, sig5 = stats.anderson(x5, dist='norm')\n\n#print results\nblah1 = astat1\/crit1[4]\nblah2 = astat2\/crit2[4]\nblah3 = astat3\/crit3[4]\nblah4 = astat4\/crit4[4]\nblah5 = astat5\/crit5[4]\nprint(\"Shapiro-Wilks test:\")\nprint('Duration of Pitch for Basic:          p-value: %.8f' % pval1)\nprint('Duration of Pitch for Standard:       p-value: %.8f' % pval2)\nprint('Duration of Pitch for Deluxe:         p-value: %.8f' % pval3)\nprint('Duration of Pitch for Super Deluxe:   p-value: %.8f' % pval4)\nprint('Duration of Pitch for King:           p-value: %.8f' % pval5)\nprint('\\nAnderson-Darling Test:')\nprint('Duration of Pitch for Basic:          Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah1)\nprint('Duration of Pitch for Standard:       Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah2)\nprint('Duration of Pitch for Deluxe:         Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah3)\nprint('Duration of Pitch for Super Deluxe:   Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah4)\nprint('Duration of Pitch for King:           Anderson-Darling statistic is %.2f times the critical value for alpha = 0.01' % blah5)\nprint('\\nNumber of samples:')\nprint('Duration of Pitch for Basic:          n = {}' .format(len(x1)))\nprint('Duration of Pitch for Standard:       n = {}' .format(len(x2)))\nprint('Duration of Pitch for Deluxe:         n = {}' .format(len(x3)))\nprint('Duration of Pitch for Super Deluxe:   n = {}' .format(len(x4)))\nprint('Duration of Pitch for King:           n = {}' .format(len(x5)))","1a494084":"#use Levene's test for equality of variace because the data departs from normality, otherwise, we would have used Bartlett's test\nstat, pval = stats.levene(x1, x2, x3, x4, x5, center='mean')\n\nif pval < 0.05:\n    print('Reject Null Hypothesis: the variances are not equal for at least one pair.\\np-value: %.8f' % pval)\nelse:\n    print('Fail to Reject Null Hypothesis: the variances are equal across all samples.\\np-value: %.8f' % pval)","758aa465":"formulated = pd.DataFrame()\n\na = pd.DataFrame({'product': 'Basic', 'durationpitch':x1})\nb = pd.DataFrame({'product': 'Standard', 'durationpitch':x2})\nc = pd.DataFrame({'product': 'Deluxe', 'durationpitch':x3})\nd = pd.DataFrame({'product': 'Super Deluxe', 'durationpitch':x4})\ne = pd.DataFrame({'product': 'King', 'durationpitch':x5})\n\nformulated = formulated.append(a) \nformulated = formulated.append(b) \nformulated = formulated.append(c)\nformulated = formulated.append(d)\nformulated = formulated.append(e)\nformulated = formulated.reset_index(drop=True)","1a6b1097":"mod = ols('durationpitch ~ C(product)', data = formulated).fit()\n#We'll assume that interactions are not significant and perform a type II sums of squares ANOVA\naov = sm.stats.anova_lm(mod, typ='II')  \naov","fbf1241d":"name = ['Jarque-Bera', 'Chi^2 two-tail prob.', 'Skew', 'Kurtosis']\ntest = sms.jarque_bera(mod.resid)\nprint('Jarque-Bera: %.4f' % test[0])\nprint('Chi-Square:  %.4f' % test[1])\nprint('Skew:        %.4f' % test[2])\nprint('Kurtosis:    %.4f' % test[3])","2f9b0a46":"tukey = pairwise_tukeyhsd(endog=formulated['durationpitch'], groups=formulated['product'], alpha=0.05)\nprint(tukey)","099ab88d":"c_pp_dat = np.unique(dat['ProductPitched'], return_counts=True)\nc_pp_dat_a = np.unique(dat_analysis['ProductPitched'], return_counts=True)\nc_pp_per = pd.DataFrame()\nc_pp_per['desc'] = c_pp_dat[0]\nc_pp_per['percent'] = c_pp_dat_a[1]\/c_pp_dat[1]*100\nc_pp_per['percent'] = c_pp_per['percent'].apply(int)\n\nw_pp_dat = np.unique(dat.loc[list(X_test.index),'ProductPitched'], return_counts=True)\nw_pp_dat_a = np.unique(well_analysis['ProductPitched'], return_counts=True)\nw_pp_per = pd.DataFrame()\nw_pp_per['desc'] = w_pp_dat[0]\nw_pp_per['percent'] = w_pp_dat_a[1]\/w_pp_dat[1]*100\nw_pp_per['percent'] = w_pp_per['percent'].apply(int)\n\nfig = plt.figure(figsize=[18,6]);\nfig.subplots_adjust(hspace=0.6, wspace=0.3);\n\nplt.subplot(1,2,1);\nsns.barplot(data=c_pp_per, x='percent', y='desc', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.ylabel('');\nplt.yticks(fontsize=14, fontweight='bold');\nplt.xticks(fontsize=14, fontweight='bold');\nplt.xlabel('(%)',fontsize=14, fontweight='bold');\nplt.title('Conversion Rate - Current Products', fontsize=14, fontweight='bold');\n\nplt.subplot(1,2,2);\nsns.barplot(data=w_pp_per, x='percent', y='desc', order=['Basic','Standard','Deluxe','Super Deluxe','King']);\nplt.ylabel('');\nplt.yticks(fontsize=14, fontweight='bold');\nplt.xticks(fontsize=14, fontweight='bold');\nplt.xlabel('(%)',fontsize=14, fontweight='bold');\nplt.title('Conversion Rate - Wellness Tourism Prediction', fontsize=14, fontweight='bold');","cce3a135":"### Observations\nAlthough the graph may indicate that the Standard product level mean pitch duration is substantially different for the wellness package compared to the other groupings, the p-value, as compared to those generated for the current product groupings, demonstrates otherwise.","925399c5":"### Observations\nIncome demographics do not appear to have changed from the current product demographics.","f4b531b1":"### Observations\nCustomers across the board prefer 3 star properties over other stars, though 5 star properties are more popular than 4 star (except for king packages).","56990c75":"### Observations\nBasic, Deluxe, and Standard packages on average required 4 follow-ups before purchase made. Super Deluxe on average required 3 follow ups before purchase made. And King on average required 4-5 follow-ups. ** there may be an indicator here on the Super Deluxe package performance - the lower than average follow-ups may indicate that low sales might be due to not following up enough. ","1de1e302":"### Summary of Model Performances\nAll of the models except the Decision Tree and Adaboost classifier appear to be slightly overfitting. Adaboost should not be seriously considered given its recal scoring. For the remainder of the models, the appearance of overfitting may indicate that the sample_weights are being countered by the nature of the error correcting process of the algorithms. The Stacking model is definitely thebest performing model here and predictions from this model will be utilized going forward to Exploratory Analysis of the predicted subset.  ","8b27aff4":"### Observations\nThe wellness tourism predictions demonstrate that the conversion rate for the basic package may increase over the current package offerings but may significantly decrease for the standard and super deluxe packages.","e53bd7d6":"### Observations\nNumber of trips appears to be consistent across all product offerings","f18e8e10":"## Demographics of Wellness Tourists\n\nThe following demographics were obtained through the below-referenced study:\n\nValentine, N.A. 2016. 'Wellness Tourism: Using Tourists\u2019 Preferences to Evaluate the Wellness Tourism Market in Jamaica.' Rev. Soc. Sci., 01(03), 25-44 (2016).\n\n<b>Characteristics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;              Frequency &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                Percentages<\/b><br><br>\n\n<b>Age Group n=200<\/b><br>\n24 years and younger &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;             16 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8<br>\n25 - 34 years     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                46 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                       23<br>\n35 - 49 years      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;               69 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                       34<br>\n50 - 64 years      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;              56 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                       28<br>\n65 years and older  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;              13 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                        6<br>\n<br>\n<b>Gender n = 200<\/b><br>\nMale &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                             83  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                      42<br>\nFemale &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                          116  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                      58<br>\n<br>\n<b>Gross Monthly Income n=138<\/b><br>\nUnder 25,000 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                    102  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                      74<br>\n25,100 - 49,900  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                 12  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                       9<br>\n50,000 - 74,900  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                  9  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                       7<br>\n75,000 - 99,900  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                  6  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                       4<br>\n100,000 and over &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                 9  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                       7<br>\n\nOf those who travelled with others on their visit, approximately 53% had partners accompanying them and 21% were accompanied by family and relatives; 12% were travelling alone. Those accompanied by co-workers and business partners were 3 and 2% respectively. Given the age ranges, the wellness market can potentially cater to families.\n\n## Overview of Dataset problems and How the Analysis will be Approached to Overcome\n\nThe dataset that we have is relevant to the characteristics of customers as it relates to the current travel packages offered by the company but we want to use this data to make predictions about a new travel package, wellness travel or tourism. Since the dataset that is going to be used in this analysis is not directly relevant to the predictions that are sought, the data will need to be weighted to conform it into a representative reflection of the population of interest. This will be done by making an \"Educated Guess\" about the demographics and characteristics of wellness tourism travelers, and then weights assigned employing a standardized process to give preference to those samples that most closely match our guesses. Utilizing the weighted dataset, predictions will be made against the data, and those predictions will be utilized to make inferences about which customers are ripe for marketing wellness tourism to and how best to pitch wellness tourism to customers based upon their demographics. \n\n## Metrics Employed and Measurements of Success\nThe ideal machine learning algorithm among DecisionTreeClassifier, BaggingClassifier, RandomForestClassifier, AdaBoost, GradientBoost, XGBoost, and Stacked models utilizing a sample_weight array to conform the data so that it is applicable to wellness tourism will be selected based upon the following criteria:\n\n1. Consistency of its Accuracy score with a predicted accuracy score based upon greater than the mean sample weights.\n2. The highest available recall score to aim for the most correct predictions that lead to purchases of the wellness tourism package.\n\nBeyond predicting customers who would are more likely to purchase the wellness travel package, the predictions made against the weighted dataset will be used to determine ideal parameters to guide customer interactions.","a68dec40":"## Bagging Classifier","fd4343c2":"### Observations\nThere does not appear to be much of a difference.","78d37cfd":"<p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Is the mean duration of pitch the same across all products for wellness tourism predictions?<\/p>\n\n<p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">H$_0$: $\\mu_1$ = $\\mu_2$ = $\\mu_3$ = $\\mu_4$ = $\\mu_5$<br>\nH$_a$: $\\mu_1$ $\\neq$ $\\mu_2$ &nbsp;|&nbsp; $\\mu_2$ $\\neq$ $\\mu_3$ &nbsp;|&nbsp; $\\mu_1$ $\\neq$ $\\mu_3$ etc. etc.<br><br><\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3; font-weight:bold;\">Where:<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">$\\mu_1$ = Basic Package<br>\n$\\mu_2$ = Standard Package<br>\n$\\mu_3$ = Deluxe Package<br>\n$\\mu_4$ = Super Deluxe Package<br>\n$\\mu_5$ = King Package<br><br>\n$\\alpha$ = 0.05 &nbsp;&nbsp;&nbsp;&nbsp;(95% Confidence Interval)<\/p>","48944df6":"### Observations\nDoesn't appear to be much of a change.","1767601e":"### Observations\nMajority of customers own a car, but those that do not are likely to putchase lower end packages, especially the basic package.","9ea1447f":"### Observation:\nThe residuals appear to be approximately normal. Jarque_Bera is high (likely due to large n), but chi-square, skew, and kurtosis indicate approximate normality.","c7c8411e":"### Observations\nAccuracy of the Bagging Classifier model was at about 90% which was what was predicted as a reasonable accuracy for the weighted model. Recall saw an improvement over the Decision Tree model, but it is still quite low (50%) at about equal to a random event. Latency of the prediction is much greater than the decision tree, but it is not clear whether latency is important here.","d6e39990":"### Observations\nAge demographics do not appear to different between the current products and those predicted for wellness tourism.","86fe9488":"## Decision Tree Classification Model","6810c606":"### Observations\nBasic package: popular with customers in their 20s, 30s, and 40s <br>\nStandard and Deluxe packages: skewed towards customers in their 30s and 40s<br>\nSuper Deluxe package: popular with customers in their 40s and 50s<br>\nKing package: popular with customers in their 40s and 50s<br>","c2805acc":"# <p style=\"font-size:24px; font-family:'Calibri Light'; font-weight:bold;\">Tukey's Range Function (aka Honest Significant Difference test)<\/p>\n<ul>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">The observations being tested are independent within and among the groups.<\/p><\/li>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">The groups associated with each mean in the test are normally distributed.<\/p><\/li>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">There is equal within-group variance across the groups associated with each mean in the test (homogeneity of variance).<\/p><\/li>\n<\/ul>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">These assumptions have already been verified so the test will proceed.<\/p>","ee8d81fc":"### Observation\nIt is presumed that a good model with good predicitons for wellness tourism from the sample weights and current travel packages dataset should be about 90% accurate (meaning that about 10% of the predicitons do not fit the educated guess of the wellness tourism demographics).","9baf0b79":"### Observations\nThe data is skewed: Basic << Deluxe << Standard << Super Deluxe << King","8481d113":"### Observations\n1. The mean pitch durations for the standard travel package is statistically different than the mean duration for the Basic package but is not different than the Deluxe or Super Deluxe, even though those two packages have a statistically similar mean to the basic travel package. This implies that there is not in-fact much difference between the means, but an overall difference in the IQR of the two distributions.\n2. The mean pitch duration for the king travel package was statistically less than all other packages.\n\nA pitch duration of about 20 minutes is recommended for the Basic, Deluxe, Standard, and Super Deluxe packages for optimal sales performance. For the king package, it is recommended that pitch length be apprimately 10 minutes but not more than 15 minutes.","f034b793":"### Observations\nCustomers from city tier 1 were predicted to be more likely to purchase a basic wellness tourism package than what was demonstrated for Basic current products. The remainder of the distribution doesn't look to have changed. ","f0acb5f0":"### Observations\nAs demonstrated above, the sample-weight distributions are spread out pretty well, though they are left-skewed toward higher weights. ","0e34659c":"## Gradient Boosting Classifier","9fda7768":"### Observations\n<b>Basic Package:<\/b>        Popular with customers with income range between 15k and 25k<br>\n<b>Deluxe Package:<\/b>       Popular with customers with income range between 20k and 30k<br>\n<b>Standard Package:<\/b>     Popular with customers with income range between 20k and 35k<br>\n<b>Super Deluxe Package:<\/b> Popular with income range between 25k and 35k<br>\n<b>King:<\/b>                 Popular with customers with income range between 30k and 45k.","0ce02539":"### Observations\nInvited customers do not appear to be any more likely to purchase a travel package.","dbd44e4b":"### Observations\nFor the wellness tourism predictions, there has been a shift demonstrating that customers are more likely to purchase a wellness tourism package if they have a passport (international traveler).","94413436":"### Observations\nHigher \"wellness tourism\" weighted customers highly preferred the Basic and Deluxe packages and somewhat preferred the standard package. Super Deluxe and King packages were weighted lower.","a25dcb46":"### Observations\nThere are several features that will need missing value treatment.\n\n## Missing Value treatment employing KNNImputer","8785793d":"### Observations\nAs with the current products, the invitations does not appear to demonstration any pattern which indicates that marketing was not successful.","d24c514a":"## AdaBoost Classifier","3dde8540":"### Observations\nBasic customers more likely to have a passport but equal for relatively equal chance for other packages.","a8d8bf5e":"<p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Is the mean duration of pitch the same across all products?<\/p>\n\n<p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">H$_0$: $\\mu_1$ = $\\mu_2$ = $\\mu_3$ = $\\mu_4$ = $\\mu_5$<br>\nH$_a$: $\\mu_1$ $\\neq$ $\\mu_2$ &nbsp;|&nbsp; $\\mu_2$ $\\neq$ $\\mu_3$ &nbsp;|&nbsp; $\\mu_1$ $\\neq$ $\\mu_3$ etc. etc.<br><br><\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3; font-weight:bold;\">Where:<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">$\\mu_1$ = Basic Package<br>\n$\\mu_2$ = Standard Package<br>\n$\\mu_3$ = Deluxe Package<br>\n$\\mu_4$ = Super Deluxe Package<br>\n$\\mu_5$ = King Package<br><br>\n$\\alpha$ = 0.05 &nbsp;&nbsp;&nbsp;&nbsp;(95% Confidence Interval)<\/p>","c57c761c":"<p style=\"font-size:20px; font-weight:bold; font-family:'Calibri Light';\">Test for normality to determine which test for equality of variance to use.<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">Will use Shapiro-Wilks and Anderson-Darling tests to determine whether the data is normally distributed. The hypothesis is as follows:<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">H<sub>0<\/sub>: The data is normally distributed<br>\nH<sub>a<\/sub>: The data is not normally distributed<br><br>\n$\\alpha$ = 0.01<\/p>","bb3ae1a8":"### Observations\nThis plot demonstrates that there was not a set duration of pitch and that each pitch went from about 5 to up to 35 minutes. For super deluxe and king packages, it is likely that the durations would have followed suit had there been a greater sample of customers who purchased those packages.","ed039a5e":"### Observations\nConsistent with what was observed with the current products, wellness tourism predictions followed similar trends, with designation being a 100% predictor of package type. Again, this is not consistent with the real world.","cf602b53":"# Visit With Us - Predictive Sales Operations: Pre-Launch Modelling of New Products Employing Similar Sample-Weighted Data \n<br>\nUT Texas Austin - DSBA Program<br><br>\nAnalyst: Jordan Rich<br>\n\n### Background and Context\n\nVisit With Us is a travel and tourism company that is looking to expand into the wellness tourism market. Currently, there are 5 types of packages the company offers - Basic, Standard, Deluxe, Super Deluxe, and King. Data collected over the last year indicates that 18% of the customers purchased the packages. During that same period, marketing costs were quite high because customers were contacted at random without any data driven decision making.\n\nThe company is now planning to launch the Wellness Tourism Package. Wellness Tourism is defined as travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being. This time around, the company wants to harness the avalable data of existing and potential customers to make the expenditure more efficient.\n\nHere, we are going analyze the company's data and information to provide recommendations for policy makers and the marketing team and also, build a model to predict potential customers who are more likely to purchase the wellness tourism package.\n\n### Data Dictionary\n\n#### Customer details:\n\n- CustomerID: Unique customer ID\n- ProdTaken: Product taken flag\n- Age: Age of customer\n- TypeofContact: How customer was contacted (Company Invited or Self Inquiry)\n- CityTier: City tier\n- Occupation: Occupation of customer\n- Gender: Gender of customer\n- NumberOfPersonVisited: Total number of person came with customer\n- PreferredPropertyStar: Preferred hotel property rating by customer\n- MaritalStatus: Marital status of customer\n- NumberOfTrips: Average number of the trip in a year by customer\n- Passport: The customer has passport or not\n- OwnCar: Customers owns a car flag\n- NumberOfChildrenVisited: Total number of children visit with customer\n- Designation: Designation of the customer in the current organization\n- MonthlyIncome: Gross monthly income of the customer\n\n#### Customer interaction data: \n\n- PitchSatisfactionScore: Sales pitch satisfactory score\n- ProductPitched: Product pitched by a salesperson\n- NumberOfFollowups: Total number of follow up has been done by sales person after sales pitch\n- DurationOfPitch: Duration of the pitch by a salesman to customer\n","440c188c":"### Observations\nNumber of Trips distributions by package levels does not appear to have changed with the wellness tourism predictions.","100bf85c":"### Observations\nAccuracy near prediction 90% but recall lower than the Gradient Boosting model. Feature importance indicates that the model is using all of the features of the dataset in making its predicitons.","08dfbc1e":"### Observations\nOf those that purchased a package, none came to pitch alone. Customers were most likely to purchase if they came with 3 or less people. The dip in sales with customers visiting with 4 or more vistors is likely due to lower discretionary income from having a lot of children.","6c4c5978":"### Observations\nFor the wellness tourism predictions, there appears to be a significant difference in the mean pitch duration for the standard package. This will be statistically investigated below.","2e701e15":"# <p style=\"font-size:24px; font-family:'Calibri Light';\">One-Way ANOVA<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">Because the eqaulity of five population means will be tested, one-way ANOVA is the ideal test.<\/p>\n<p style=\"font-size:20px; font-weight:bold; font-family:'Calibri Light';\">The assumptions of one-way ANOVA :<\/p>\n<ul>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light';\">Residuals (experimental error) are normally distributed.<\/p><\/li>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light';\">Homogeneity of variances (variances are equal between treatment groups).<\/p><\/li>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light';\">Observations are sampled independently from each other<\/p><\/li>\n<\/ul>","f2e63f42":"### Observation:\n\nThere is some outliers here which don't need to be treated for decision tree, bagging, and random forest. Normally they should be treated when using Boosting models because those models are not robust to outliers due to the algorithm in which successive models place preference on the worst performings for successive iterations, which could lead to model overfitting. For several reasons, the outliers are not going to be treated in this case: 1) There's not many outliers, and importantly, 2) outlier treatment might affect the outcome of the weighting and analysis performed here. Outliers will be left untouched though it will be presumed that Boosting may have more overfitting than they would if the outliers were treated.","aaf706c3":"## Prediction of reliable model accuracy from sample weights","c0adc338":"### Observations\nFor wellness tourism predictions, female appear to be more likely to puchase a Deluxe Wellness Tourism package than they were observed for the current products, otherwise there does not appear to be a significant change for the wellness tourism predictions for other packages across genders","e815b7d0":"### Observation:\nThe residuals appear to be approximately normal. Jarque_Bera is high (likely due to large n), but chi-square, skew, and kurtosis indicate approximate normality.","b95e66f6":"### Observations\nCustomers from city tier 1 appear highly likely to purchase a basic travel package. Customers from City tier 2 do not appear likely to purchase any travel package. And customers from city tier 3 have higher likelihood than other tiers of purchases greater travel packages.","6986d739":"### Observations\nA majority of customers required 3-5 follow-ups before making a purchase. ","0fd880c3":"### Observations\nThere does not appear to be much of a correlation between pitch satisfaction score and purchase. Maybe the customers didn't understand whether 1 or 5 were best or worst scores?","56979e1d":"### Observations\nThe Random Forest model has a near 90% accuracy rate consistent with the expected accuracy for the weighted model, similar to Bagging. Recall is better than random at 57%, though not by much. Analysis of feature importance indicates that all features contributed to the model, except Designation_VP (and most significantly contributed).","2e7bc786":"## XGBoost Classifier.","1b5fd9cd":"# <p style=\"font-size:24px; font-weight:bold; font-family:'Calibri Light';\">Levene's Test for Equality of Variance<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">H<sub>0<\/sub>: The variances are equal across all samples.<br>\nH<sub>a<\/sub>: The variances are not equal for at least one pair.<br><br>\n$\\alpha$ = 0.05<br>\n<br>\nHere we will use Levene's Test because the data failed Shapiro-Wilks test and Anderson-Darling's test. Levene's test is more robust with data that is found to not follow a normal distribution. If the samples had passed the Shapiro-Wilks test and Anderson-Darling's test, Bartlett's test for equality of variance is the more appropriate test.<\/p>","4baf4fbf":"### Observations\nThe wellness tourism predictions may indicate that there is more of a demand for the basic wellness tourism package for customers with 2 or less visitors as compared to the demographics obtained for current products","e6e471bc":"## Creation of Sample-Weights for conforming data to make \"educated guess\" about wellness tourisms package\n\nWellness tourists are a subset of the overall tourist population, and as such, we can assume that the data about the current travel packages also contains information about wellness tourists. The idea here is to use tourist demographic information that was obtained from a study on wellness tourism in Jamaica and use the demographic information to create an array of sample weights to pass through during model training to conform the current travel packages data into an education guess of what the data may look like for the  wellness tourism packages (i.e. extract out the wellness tourist demographic) so that we can make preliminary inferences to guide sales operations and marketing.","6140e139":"BEST PARAMETERS: {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 75, 'subsample': 0.9}\n\n0.878 (+\/-0.015) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 75, 'subsample': 0.7}<br>\n0.876 (+\/-0.013) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 75, 'subsample': 0.8}<br>\n0.886 (+\/-0.022) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 75, 'subsample': 0.9}<br>\n0.872 (+\/-0.016) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 75, 'subsample': 1}<br>\n0.88 (+\/-0.018) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 100, 'subsample': 0.7}<br>\n0.881 (+\/-0.015) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 100, 'subsample': 0.8}<br>\n0.878 (+\/-0.021) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 100, 'subsample': 0.9}<br>\n0.875 (+\/-0.021) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 100, 'subsample': 1}<br>\n0.877 (+\/-0.015) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 125, 'subsample': 0.7}<br>\n0.879 (+\/-0.014) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 125, 'subsample': 0.8}<br>\n0.88 (+\/-0.017) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 125, 'subsample': 0.9}<br>\n0.872 (+\/-0.02) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 125, 'subsample': 1}<br>\n0.878 (+\/-0.018) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 150, 'subsample': 0.7}<br>\n0.881 (+\/-0.013) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 150, 'subsample': 0.8}<br>\n0.88 (+\/-0.017) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 150, 'subsample': 0.9}<br>\n0.874 (+\/-0.023) for {'colsample_bylevel': 0.8, 'colsample_bytree': 1, 'gamma': 5, 'n_estimators': 150, 'subsample': 1}<br>","6222cb52":"### Observations\nMales are more likely than females to purchase a travel package though when males (or females) purchase they are likely to be purchasing for themselves and a partner or family.","0a7ea2ea":"### Observations\nThe basic tranvel package has the highest conversion rate, at about 30% of total pitches, followed by the Standard at about 15%, then the Deluxe (10%) and King (8%). The super-deluxe package had the worst performance, though it is not clear why. It may be that the super deluxe package is not appealing to customers and should not be offered anymore, or the pitch needs to be improved upon and customers selected in a more methodical way. For all of the lower performing packages, it is recommended that their performance be further studied to find areas of improvement.","58eac9dd":"### Observations\nThere does not appear to be a change","8f7a0ae7":"### Observations\nFree lancers appear to be unlikely to purchase a travel package, likely due to low income, this may also be due to a limited amount of representative samples for that population. Small business employees have a higher likelihood than other employees of purchasing higher end travel packages.","d3d9ad68":"## Introduction to Wellness Tourism and Traveler Demographics\n\nWellness tourism is travel associated with the pursuit of maintaining or enhancing one's personal wellbeing. It was estimated in 2017 that wellness tourism was a $639 Billion Global market at that time (See Global Wellness Tourism Economy \u2013 November 2018 Report by Global Wellness Institute). Of all Wellness Trips, 82\\% were domestic trips, and 18\\% were international. It's not clear, today, what affect the COVID-19 pandemic has or will have on the future of this market, but one might think that an increase in focus toward ones health and wellness brought on by the pandemic will increase overall demand. Compared to standard tourists, wellness tourists on average spend between 50\\%-175\\% more during their trip, therefore, wellness tourism may be far more profitable than standard tourism and may be an avenue for the hard-hit tourism industry to enhance profit following the pandemic.","ea55c843":"# <p style=\"font-size:24px; font-family:'Calibri Light'; font-weight:bold;\">Tukey's Range Function (aka Honest Significant Difference test)<\/p>\n<ul>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">The observations being tested are independent within and among the groups.<\/p><\/li>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">The groups associated with each mean in the test are normally distributed.<\/p><\/li>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light'; line-height:1.3;\">There is equal within-group variance across the groups associated with each mean in the test (homogeneity of variance).<\/p><\/li>\n<\/ul>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">These assumptions have already been verified so the test will proceed.<\/p>","94260c06":"## Stacking Classifier\n\nEmploying Decision Tree, Random Forest, and Gradient Boosting, followed by Adaboost as a final Estimator.","06eda171":"<p style=\"font-size:20px; font-weight:bold; font-family:'Calibri Light';\">Test for normality to determine which test for equality of variance to use.<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">Will use Shapiro-Wilks and Anderson-Darling tests to determine whether the data is normally distributed. The hypothesis is as follows:<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">H<sub>0<\/sub>: The data is normally distributed<br>\nH<sub>a<\/sub>: The data is not normally distributed<br><br>\n$\\alpha$ = 0.01<\/p>","5daf93e7":"### Observations\nThere does not appear to be much of a difference.","e5fbbd22":"XGBoost -- Accuracy: 0.892 \/ Precision: 0.768 \/ Recall: 0.587 \/ Latency: 10.344ms","8fb0630b":"### Observation - The mean Pitch Duration is different for at least one Product","26e9dbcf":"### Observations\nThere does not appear to be much of a difference here.","687e65dc":"### Observations\nDoes not to appear to be different. ","a4cc8a84":"### Observations\nMarital status distributions does not appear to have changed with the wellness tourism predicitons","c991e8dd":"### Observations\nPeople with more than 2 children were unlikely to purchase a travel package. A majority of customers had 1 or 2 children, though childless customers were also prevalent.","9f2ba1d8":"### Observations\nDecision Tree accuracy on the testing data was at about 85% with is slightly lower than the 90% expected rate. The recall is quite low, at around %40 (worse than what would be expected for a random \/ chance event). The Featuere importance plot demonstrates that a little more than half of the features were used toward making predictions in this model.","e9c9d632":"### Compute class weights to fixe inbalance in dependant variable","a808d670":"### Observations\nThis plot speaks for itself. Executives: Basic package, Manager: Deluxe Package, Senior Manager: Standard Package, AVP: Super Deluxe, VP: King. Real life isn't like this, but for the dataset provided, a customers Designation is all that would be needed to determine with level of package to pitch.","786a2ab2":"### Observations\nThere does not appear to be much of a difference.","100e5fa1":"# <p style=\"font-size:24px; font-family:'Calibri Light';\">One-Way ANOVA<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">Because the eqaulity of five population means will be tested, one-way ANOVA is the ideal test.<\/p>\n<p style=\"font-size:20px; font-weight:bold; font-family:'Calibri Light';\">The assumptions of one-way ANOVA :<\/p>\n<ul>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light';\">Residuals (experimental error) are normally distributed.<\/p><\/li>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light';\">Homogeneity of variances (variances are equal between treatment groups).<\/p><\/li>\n    <li><p style=\"font-size:18px; font-family:'Calibri Light';\">Observations are sampled independently from each other<\/p><\/li>\n<\/ul>","7f014263":"### Observations\nThe stacking classifier is achieving a 90% accuracy rate, which is where it should be based upon predictions using the sample_weights. Most import, the stacking classifier is achieving a near 72% Recall, which is the best model and therefore the model that will be used going forward. Latency was sacrificed in using the stacking classifier, which is expected considering that it is employing 4 models to make its predictions.","8af0ce13":"### Observations\nModel performance is terrible, with recall at 28%. This may be due to not having treated outliers, but more than likely, the algorithm performs in a way that just doesn't mesh well with the sample_weights and distributions of the features of this dataset.","d580a075":"### Observations\nBased upon the statistical distributions of the before-imputation and after-imputation datasets, the imputation appears to have been successful as there does not appear to be a significant shift in the distributions.","989c0f5f":"## Look at Outliers:","0c5af962":"# Exploratory Data Analysis of Current Product Sales and Customer Trends\n\nBelow, customer trends for current product sales are visualized and explored to gain insight into current sales operations. Later on in this notebook, these same visualizations will be compared against predicted wellness tourism customers to attempt a differentiation.","7c958909":"### Observations\nSingle and Married substantially more likely to purchase a basic travel package, though Married have higher likelihood than single a deluxe or standard package. Divorced and Unmarried far more likely to purchase Standard and Deluxe packages. Super Deluxe does not appear to be popular among Divorced and King does not appear to be popular among Unmarrier, though this is likely due to a limited number of samples.","c52c05ee":"# Summary and Recommendations for the Business\n\n<b>For the current travel packages oit is recommended that marketing is aimed as follows:<\/b><br><br>\n<u>Age:<\/u><br>\nBasic - Predominately in 20s, also 30s and 40s<br>\nStandard & Deluxe - Predominately in 30s, also 40s<br>\nSuper Deluxe - Predominately in 40s, also 50s<br>\nKing - 30s, 40s, but predominately in 50s<br>\n<br>\n<u>Income:<\/u><br>\nBasic - 15k - 25k<br>\nDeluxe - 20k - 30k<br>\nStandard - 20k - 35k<br>\nSuper Deluxe - 25k - 35k<br>\nKing - 30k - 45k<br>\n<br>\n<u>Marital Status:<\/u><br>\nBasic - Single, Divorced, Unmarried, & Married<br>\nDeluxe - Single, Divorced, Unmarried, & Married<br>\nStandard - Divorced, Unmarried, & Married<br>\nSuper Deluxe - Single & Married<br>\nKing - Single, Divorced, & Married<br>\n<br>\n<u>City Tier<\/u><br>\nBasic - 1, 2, & 3<br>\nDeluxe - 1 & 3<br>\nStandard - 1 & 3<br>\nSuper Deluxe - 3<br>\nKing - 1 & 3<br>\n<br>\n<u>Gender<\/u>\nNo Gender Specificity<br>\n<br>\n<u># of Persons<\/u><br>\nBasic, Deluxe, Standard, & King - 2, 3, & 4<br>\nSuper Deluxe - 2 & 3<br>\n<br>\n<u>Occupation<\/u><br>\nBasic, Deluxe, Standard, & King - Salaried, Small Business, and Large Business<br>\nSuper Deluxe - Salaried & Small Business<br>\nFreelancers very unlikely to purchase travel package<br>\n<br>\n<u>Preferred Property Scores<\/u><br>\nBasic - 3, 4, & 5<br>\nDeluxe, Standard, and Super Deluxe - Predominately 3<br>\nKing - 3 & 4 but predominately 4<br>\n<br>\n<u>Passport<\/u><br>\nBasic more likely for International Travel<br>\n<br>\n<u>Designation<\/u><br>\nBasic - Executive<br>\nDeluxe - Manager<br>\nStandard - Senior Manager<br>\nSuper Deluxe - AVP<br>\nKing - VP<br>\n<br>\n<u>Follow-ups<\/u><br>\nExpect 3-5 follow-ups before purchase<br>\nOn Average:<br>\nBasic, Deluxe, Standard, & King - 4 follow-ups<br>\nSuper Deluxe - 3 ** There is some indication that by increasing follow-ups to at least 4, this may result in an uptick in sales.<br>\n<br>\n<u>Pitch Satisfaction Score<\/u><br>\nThere appears to be a problem with the survey for pitch satisfaction which is indicating satisfaction scores that are inconsistent with purchasing behavior. This may be due to a misunderstanding in which rating is god or bad. Recommend switch to Excellent, Good, Average, Poor scoring to get better feedback.<br>\n<br>\n<u># of children visiting<\/u><br>\nMore sales when <= 2, but overall indeterminate.<br>\n<br>\n<u>Own Car<\/u><br>\nSuper Deluxe & King - Yes<br>\nAll others, indeterminate<br>\n<br>\n<u>Pitch Time Recommendations:<\/u>\nBasic, Standard, Deluxe, and Super Deluxe - ~20 minutes<br>\nKing - ~10 minutes<br>\n<br>\n<u>Conversion Rates<\/u><br>\nBasic - 30%<br>\nStandard - 15%<br>\nDeluxe - 10%<br>\nSuper Deluxe - 5% <b>-->Uptick may be obtained by increasing # of follow-ups to at least 4<\/b><br>\nKing - 8%<br>\n<br>\n<br>\n<b>For the wellness travel package everything appears to be similar to current packages except:<\/b><br>\n<u>Passport:<\/u><br>\nThe prediction indicates that much more wellness tourists have passports, thus are more likely to go for international travel packages.<br>\n<br>\n<u>Predicted Conversion Rates<\/u><br>\nBasic - 30%<br>\nStandard - 10%<br>\nDeluxe - 11%<br>\nSuper Deluxe - 4%<br>\nKing - 9%<br>\n## As far as the model is concerned, 90% accuracy, 72% Recall, and 74% Precision was obtained, which was the best scores out of all the models that were evaluated. While this model may be sufficient to obtain better than random results for an initial marketing program, it is recommended that Visit With Us obtain data on Wellness Tourism package sales and customers as the product rolls out so that the model may be updated with actual data to obtain better predictions as soon as practicable.","4fe69eb4":"## Exploratory Analysis of Wellness Tourism Predicitons.","3be868a8":"### Observations\nThis model has slighlty higher than predict accuracy but that is not necessary a bad thing. Recall at 63% is an improvement over other models (especially the 23% offered by AdaBoost). The model is using most features in its prediction.","ed7a0ade":"# <p style=\"font-size:24px; font-weight:bold; font-family:'Calibri Light';\">Levene's Test for Equality of Variance<\/p>\n<p style=\"font-size:18px; font-family:'Calibri Light';\">H<sub>0<\/sub>: The variances are equal across all samples.<br>\nH<sub>a<\/sub>: The variances are not equal for at least one pair.<br><br>\n$\\alpha$ = 0.05<br>\n<br>\nHere we will use Levene's Test because the data failed Shapiro-Wilks test and Anderson-Darling's test. Levene's test is more robust with data that is found to not follow a normal distribution. If the samples had passed the Shapiro-Wilks test and Anderson-Darling's test, Bartlett's test for equality of variance is the more appropriate test.<\/p>"}}