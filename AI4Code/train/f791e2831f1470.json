{"cell_type":{"d86e51ab":"code","9388caf7":"code","a910b93a":"code","f388e7b7":"code","28fcfe0d":"code","f05516da":"code","966dd75b":"code","ab4c39b7":"code","2ce62efe":"code","57c3f26c":"code","72350922":"code","74d6f12c":"code","b5e3bffa":"code","47e6938e":"code","da321050":"code","39a7597d":"code","678f0ea6":"code","e14621e0":"code","f036420b":"code","5aa18752":"code","e3053b27":"code","5d8fcac8":"code","0d9405b1":"code","5fbd904e":"code","a5fdd231":"code","7a669f9c":"code","d8760773":"code","13abbc7d":"code","3fa90c95":"code","f8f4a791":"code","bb3cbc33":"code","3ee9dd9c":"markdown","26e5faf6":"markdown","b8a09831":"markdown","595e2cfa":"markdown","4e9c68b9":"markdown","4945e9a8":"markdown","6eb41ffc":"markdown","2b267c13":"markdown","8c54dd74":"markdown","11675239":"markdown","e9c49b94":"markdown","a4c343de":"markdown","4668842d":"markdown","12bce6f2":"markdown","0a595265":"markdown","594341c3":"markdown","419e64c6":"markdown","fe1c0926":"markdown"},"source":{"d86e51ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9388caf7":"import tensorflow as tf\ntf.test.gpu_device_name()","a910b93a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport cv2\nimport os\nfrom tqdm import tqdm","f388e7b7":"from keras.applications.inception_v3 import InceptionV3\nmodel = InceptionV3()\nmodel.summary()","28fcfe0d":"from tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import decode_predictions","f05516da":"N = 224","966dd75b":"chair = []\n\nfor filepath in tqdm(sorted(os.listdir('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/chair\/'))):\n    src = cv2.imread('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/chair\/{0}'.format(filepath),1)\n    src = cv2.resize(src, (N, N))\n    chair.append(src)\n\nchair = np.array(chair)\n\nbed = []\n\nfor filepath in tqdm(sorted(os.listdir('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/bed\/'))):\n    src = cv2.imread('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/table\/{0}'.format(filepath),1)\n    src = cv2.resize(src, (N, N))\n    bed.append(src)\n\nbed = np.array(bed)\n\ntable = []\n\nfor filepath in tqdm(sorted(os.listdir('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/table\/'))):\n    src = cv2.imread('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/table\/{0}'.format(filepath),1)\n    src = cv2.resize(src, (N, N))\n    table.append(src)\n\ntable = np.array(table)\n\nsofa = []\n\nfor filepath in tqdm(sorted(os.listdir('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/sofa\/'))):\n    src = cv2.imread('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/sofa\/{0}'.format(filepath),1)\n    src = cv2.resize(src, (N, N))\n    sofa.append(src)\n\nsofa = np.array(sofa)\n\nswivle_chair = []\n\nfor filepath in tqdm(sorted(os.listdir('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/swivelchair\/'))):\n    src = cv2.imread('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/train\/swivelchair\/{0}'.format(filepath),1)\n    src = cv2.resize(src, (N, N))\n    swivle_chair.append(src)\n\nswivle_chair = np.array(swivle_chair)\n\n\nprint(chair.shape, table.shape, bed.shape, swivle_chair.shape, sofa.shape)","ab4c39b7":"image = chair[0]\n\nplt.imshow(image)\n\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n\nimage = preprocess_input(image)\n\nmodel = InceptionV3()\n\nyhat = model.predict(image)\n\nlabel = decode_predictions(yhat)\n\nlabel = label[0][0]\nprint('%s (%.5f%%)' % (label[1], label[2]*100))","2ce62efe":"print(yhat.shape, '\\n', yhat)","57c3f26c":"def label_image(images):\n\n    images = preprocess_input(images)\n\n    model = InceptionV3()\n\n    yhat = model.predict(images, verbose=1)\n    \n    return yhat\n    \nyhat_chair = label_image(chair)\nyhat_bed = label_image(bed)\nyhat_sofa = label_image(sofa)\nyhat_swivel_chair = label_image(swivle_chair)\nyhat_table = label_image(table)","72350922":"x_inception = np.array([i for i in yhat_chair] + [i for i in yhat_swivel_chair] + [i for i in yhat_table] + [i for i in yhat_bed] + [i for i in yhat_sofa])\ny_inception = np.array([1 for _ in range(yhat_chair.shape[0])] + [3 for _ in range(yhat_swivel_chair.shape[0])] + [4 for _ in range(yhat_table.shape[0])] + [0 for _ in range(yhat_bed.shape[0])] + [2 for _ in range(yhat_sofa.shape[0])])\n\nnp.random.seed(0)\nindexes = np.arange(x_inception.shape[0])\nnp.random.shuffle(indexes)\n\nx_inception = x_inception[indexes]\ny_inception = y_inception[indexes]\n\nprint(x_inception.shape)\nprint(y_inception.shape)","74d6f12c":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(random_state=0, n_estimators=500) #for reproducibility\nclf.fit(x_inception[:int(0.85*x_inception.shape[0])], y_inception[:int(0.85*x_inception.shape[0])])\ny_rf = clf.predict(x_inception)\nprint('Validation',clf.score(x_inception[int(0.85*x_inception.shape[0]):], y_inception[int(0.85*x_inception.shape[0]):]))\nprint('Training',clf.score(x_inception[:int(0.85*x_inception.shape[0])], y_inception[:int(0.85*x_inception.shape[0])]))","b5e3bffa":"groups = {0:[], 1:[], 2:[], 3:[], 4:[]}\nfor i,j in zip(y_inception, y_rf):\n    groups[i].append(j)\n    \np_error = {0:[], 1:[], 2:[], 3:[], 4:[]}\nfor key, item in groups.items():\n    for i in range(5):\n        p_error[key].append(item.count(i))\n    total = sum(p_error[key])\n    p_error[key] = [round(i\/total, 5) for i in p_error[key]]\n\n_ = [print(key,':',item) for key, item in p_error.items()]","47e6938e":"import networkx as nx \n\ndef error_graph(p_error):\n    \n    G = nx.DiGraph() \n    for i in range(5):\n        G.add_node(i)\n    \n    for key, item in p_error.items():\n        for i,x in enumerate(item):\n            x = round(x, 3)\n            if i!=key and x>0.01:\n                G.add_edge(key, i, weight=x)\n    \n    plt.figure(figsize =(4, 4)) \n    nx.draw_networkx(G, with_label = True, node_color ='green')\n    \nerror_graph(p_error)","da321050":"x = np.array([i for i in chair[:int(0.9*chair.shape[0])]] + [i for i in table[:int(0.9*table.shape[0])]] + [i for i in bed[:int(0.9*bed.shape[0])]] + [i for i in swivle_chair[:int(0.9*swivle_chair.shape[0])]] + [i for i in sofa[:int(0.9*sofa.shape[0])]] + [i for i in chair[int(0.9*chair.shape[0]):]] + [i for i in table[int(0.9*table.shape[0]):]] + [i for i in bed[int(0.9*bed.shape[0]):]] + [i for i in swivle_chair[int(0.9*swivle_chair.shape[0]):]] + [i for i in sofa[int(0.9*sofa.shape[0]):]])\ny_sparse = np.array([1 for _ in range(int(0.9*chair.shape[0]))] + [4 for _ in range(int(0.9*table.shape[0]))] + [0 for _ in range(int(0.9*bed.shape[0]))] + [3 for _ in range(int(0.9*swivle_chair.shape[0]))] + [2 for _ in range(int(0.9*sofa.shape[0]))] + [1 for _ in range(chair.shape[0]-int(0.9*chair.shape[0]))] + [4 for _ in range(table.shape[0]-int(0.9*table.shape[0]))] + [0 for _ in range(bed.shape[0]-int(0.9*bed.shape[0]))] + [3 for _ in range(swivle_chair.shape[0] - int(0.9*swivle_chair.shape[0]))] + [2 for _ in range(sofa.shape[0] - int(0.9*sofa.shape[0]))])\ny_encoded = []\n\nfor i in y_sparse:\n    a = [0 for _ in range(5)]\n    a[i] = 1\n    y_encoded.append(a)\ny_encoded = np.array(y_encoded)\n\nprint(x.shape, y_encoded.shape)","39a7597d":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, BatchNormalization\nfrom tensorflow.keras.layers import Flatten, GlobalAveragePooling2D, Concatenate, Dropout\nimport tensorflow as tf","678f0ea6":"model = InceptionV3(include_top=False, input_shape=(N, N, 3))\nmodel.trainable = True\n\ngap1 = GlobalAveragePooling2D()(model.layers[-1].output)\nflat1 = Flatten()(gap1)\nbn = BatchNormalization()(flat1)\nclass1 = Dense(1024, activation='relu')(bn)\nclass2 = Dense(256, activation='relu')(class1)\nclass3 = Dense(32, activation='relu')(class2)\noutput = Dense(5, activation='softmax')(class3)\n\nmodel = Model(inputs=model.inputs, outputs=output)\n\nmodel.summary()","e14621e0":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])","f036420b":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.75, patience=4, verbose=1, mode='auto',\n    min_delta=0.0001, cooldown=0, min_lr=5*1e-5,\n)","5aa18752":"early_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_acc', min_delta=0, patience=15, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=True\n)","e3053b27":"model.fit(x[:int(0.9*x.shape[0])], y_encoded[:int(0.9*x.shape[0])], epochs=25, shuffle=True, callbacks=[reduce_lr, early_stop], validation_data=(x[x.shape[0]-int(0.9*x.shape[0]):], y_encoded[x.shape[0]-int(0.9*x.shape[0]):]))","5d8fcac8":"test = []\nfiles = sorted(os.listdir('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/test\/'))\nfor filepath in tqdm(files):\n    src = cv2.imread('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/test\/{0}'.format(filepath),1)\n    src = cv2.resize(src, (N, N))\n    test.append(src)\n\ntest = np.array(test)","0d9405b1":"y_pred = model.predict(test, verbose=1)\ny_pred = [np.argmax(i) for i in y_pred]\nsubmission = pd.DataFrame({'image': files, 'target':y_pred})\nsubmission.to_csv('submission_basic.csv', index=False)","5fbd904e":"model1 = InceptionV3(include_top=False, input_shape=(N, N, 3))\nmodel1.trainable = True\n\ngap1 = GlobalAveragePooling2D()(model1.layers[-1].output)\nflat1 = Flatten()(gap1)\nflat1 = BatchNormalization()(flat1)\n\nout1 = Dense(1024, activation='relu')(flat1)\n\ninput2 = tf.keras.layers.Input([N, N, 3])\nx = tf.keras.applications.inception_v3.preprocess_input(input2)\nmodel2 = tf.keras.applications.InceptionV3()\nout2 = model2(x)\nout2 = BatchNormalization()(out2)\n\nmergedOut = Concatenate()([out1,out2])\nclass1 = Dense(1228, activation='relu')(mergedOut)\nclass1 = Dense(1024, activation='relu')(class1)\nclass1 = Dense(516, activation='relu')(class1)\nclass2 = Dense(256, activation='relu')(class1)\nclass3 = Dense(32, activation='relu')(class2)\noutput = Dense(5, activation='softmax')(class3)\n\n\nmodel = Model(inputs=[model1.inputs, input2], outputs=[output])\nmodel.summary()","a5fdd231":"x = np.array([i for i in chair[:int(0.9*chair.shape[0])]] + [i for i in table[:int(0.9*table.shape[0])]] + [i for i in bed[:int(0.9*bed.shape[0])]] + [i for i in swivle_chair[:int(0.9*swivle_chair.shape[0])]] + [i for i in sofa[:int(0.9*sofa.shape[0])]] + [i for i in chair[int(0.9*chair.shape[0]):]] + [i for i in table[int(0.9*table.shape[0]):]] + [i for i in bed[int(0.9*bed.shape[0]):]] + [i for i in swivle_chair[int(0.9*swivle_chair.shape[0]):]] + [i for i in sofa[int(0.9*sofa.shape[0]):]])\ny_sparse = np.array([1 for _ in range(int(0.9*chair.shape[0]))] + [4 for _ in range(int(0.9*table.shape[0]))] + [0 for _ in range(int(0.9*bed.shape[0]))] + [3 for _ in range(int(0.9*swivle_chair.shape[0]))] + [2 for _ in range(int(0.9*sofa.shape[0]))] + [1 for _ in range(chair.shape[0]-int(0.9*chair.shape[0]))] + [4 for _ in range(table.shape[0]-int(0.9*table.shape[0]))] + [0 for _ in range(bed.shape[0]-int(0.9*bed.shape[0]))] + [3 for _ in range(swivle_chair.shape[0] - int(0.9*swivle_chair.shape[0]))] + [2 for _ in range(sofa.shape[0] - int(0.9*sofa.shape[0]))])\ny_encoded = []\n\nfor i in y_sparse:\n    a = [0 for _ in range(5)]\n    a[i] = 1\n    y_encoded.append(a)\ny_encoded = np.array(y_encoded)","7a669f9c":"print(x.shape, y_encoded.shape)","d8760773":"model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0025), loss='categorical_crossentropy', metrics=['acc'])","13abbc7d":"model.fit([x, x], y_encoded, epochs=5, validation_split=0.1, shuffle=True)","3fa90c95":"test = []\nfiles = sorted(os.listdir('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/test\/'))\nfor filepath in tqdm(files):\n    src = cv2.imread('\/kaggle\/input\/day-3-kaggle-competition\/data_comp\/data_comp\/test\/{0}'.format(filepath),1)\n    src = cv2.resize(src, (N, N))\n    test.append(src)\n\ntest = np.array(test)","f8f4a791":"y_pred = model.predict([test, test], verbose=1)\ny_peed = [np.argmax(i) for i in y_pred]\nsubmission = pd.DataFrame({'image': files, 'target':y_peed})\nsubmission.to_csv('submission_skipped.csv', index=False)","bb3cbc33":"for index in range(10):\n    \n    np.random.shuffle(chair)\n    np.random.shuffle(table)\n    np.random.shuffle(bed)\n    np.random.shuffle(sofa)\n    np.random.shuffle(swivle_chair)\n\n    x = np.array([i for i in chair[:int(0.9*chair.shape[0])]] + [i for i in table[:int(0.9*table.shape[0])]] + [i for i in bed[:int(0.9*bed.shape[0])]] + [i for i in swivle_chair[:int(0.9*swivle_chair.shape[0])]] + [i for i in sofa[:int(0.9*sofa.shape[0])]] + [i for i in chair[int(0.9*chair.shape[0]):]] + [i for i in table[int(0.9*table.shape[0]):]] + [i for i in bed[int(0.9*bed.shape[0]):]] + [i for i in swivle_chair[int(0.9*swivle_chair.shape[0]):]] + [i for i in sofa[int(0.9*sofa.shape[0]):]])\n    y_sparse = np.array([1 for _ in range(int(0.9*chair.shape[0]))] + [4 for _ in range(int(0.9*table.shape[0]))] + [0 for _ in range(int(0.9*bed.shape[0]))] + [3 for _ in range(int(0.9*swivle_chair.shape[0]))] + [2 for _ in range(int(0.9*sofa.shape[0]))] + [1 for _ in range(chair.shape[0]-int(0.9*chair.shape[0]))] + [4 for _ in range(table.shape[0]-int(0.9*table.shape[0]))] + [0 for _ in range(bed.shape[0]-int(0.9*bed.shape[0]))] + [3 for _ in range(swivle_chair.shape[0] - int(0.9*swivle_chair.shape[0]))] + [2 for _ in range(sofa.shape[0] - int(0.9*sofa.shape[0]))])\n    y_encoded = []\n\n    for i in y_sparse:\n        a = [0 for _ in range(5)]\n        a[i] = 1\n        y_encoded.append(a)\n    y_encoded = np.array(y_encoded)\n    \n    model = InceptionV3(include_top=False, input_shape=(N, N, 3))\n    model.trainable = True\n\n    gap1 = GlobalAveragePooling2D()(model.layers[-1].output)\n    flat1 = Flatten()(gap1)\n    bn = BatchNormalization()(flat1)\n    class1 = Dense(1024, activation='relu')(bn)\n    class2 = Dense(256, activation='relu')(class1)\n    class3 = Dense(32, activation='relu')(class2)\n    output = Dense(5, activation='softmax')(class3)\n\n    model = Model(inputs=model.inputs, outputs=output)\n    \n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n    \n    model.fit(x[:int(0.9*x.shape[0])], y_encoded[:int(0.9*x.shape[0])], epochs=20, shuffle=True, callbacks=[reduce_lr, early_stop], validation_data=(x[x.shape[0]-int(0.9*x.shape[0]):], y_encoded[x.shape[0]-int(0.9*x.shape[0]):]))\n    \n    y_pred = model.predict(test, verbose=1)\n    y_pred = [np.argmax(i) for i in y_pred]\n    submission = pd.DataFrame({'image': files, 'target':y_pred})\n    submission.to_csv('submission_basic_'+str(index)+'.csv', index=False)\n    \n    del model    ","3ee9dd9c":"## The above code is actually repeated 100 times totally, but the output would be too large and the results are consistent so, I did it only 10 times here","26e5faf6":"## IMPORTS:","b8a09831":"## Checking Out Inception","595e2cfa":"## Let's take a look at the yhat raw","4e9c68b9":"## Kind of interesting that, swivel chair and chair can be classified. But table and bed cannot","4945e9a8":"## Trying out Inception V3","6eb41ffc":"## Getting Tensorflow Read","2b267c13":"## The model is slow, but it does not require data augmentation, which is an area I did not want to use. On the other hand it was my first chance to implement any type of skipping networks \n(https:\/\/link.springer.com\/chapter\/10.1007%2F978-3-658-14577-4_8)","8c54dd74":"## Looking at who went wrong?","11675239":"## Building The Model","e9c49b94":"## Training it","a4c343de":"## Well the model already gives results let's take a look at more interesting facts about the challenge and Inception:","4668842d":"### Building The Training Set:","12bce6f2":"## Used the main model as well, since, the skipping connection model had only run for 2 epochs and wasn't promising. It showed signs of underfitting. So, the following was done to correct anything possible. However, it gives better results after running for more epochs","0a595265":"## Loading Images:","594341c3":"## Preparing Submission:","419e64c6":"## Skipping connections:","fe1c0926":"## Checking Validity of Inception using RF:"}}