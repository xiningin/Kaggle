{"cell_type":{"dcbf8627":"code","98627b77":"code","cd0d9441":"code","c5c6de9b":"code","2735513b":"code","b5719d9f":"code","605a1a6c":"code","49453907":"code","f53b00a7":"code","e795d7c1":"code","fbf880fc":"code","de03bff0":"code","853d5f04":"code","0d40f8f7":"code","69f4a662":"code","befced8f":"code","3e5bd08d":"code","b4ce6f2f":"code","d00ea1fd":"code","120ab2f8":"code","cd021522":"code","991adccd":"code","d7bbb280":"code","396a4b92":"code","42d9e064":"code","7b580d4f":"code","ab90d2ac":"code","35723877":"code","8db7ebf8":"code","67c496b7":"markdown"},"source":{"dcbf8627":"import numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split","98627b77":"directory = '..\/input\/brain-tumor-classification-mri\/Training'\ndirectory2 = '..\/input\/brain-tumor-classification-mri\/Testing'","cd0d9441":"File=[]\nfor file in os.listdir(directory):\n    File+=[file]\nprint(File)","c5c6de9b":"dataset=[]\nmapping={'no_tumor':0, 'pituitary_tumor':1, 'meningioma_tumor':2, 'glioma_tumor':3}\ncount=0\n\nfor file in os.listdir(directory):\n    path=os.path.join(directory,file)\n    for im in os.listdir(path):\n        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(150,150))\n        image=img_to_array(image)\n        image=image\/255.0\n        dataset.append([image,count])     \n    count=count+1","2735513b":"testset=[]\nmapping={'no_tumor':0, 'pituitary_tumor':1, 'meningioma_tumor':2, 'glioma_tumor':3}\ncount=0\n\nfor file in os.listdir(directory2):\n    path=os.path.join(directory2,file)\n    for im in os.listdir(path):\n        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(150,150))\n        image=img_to_array(image)\n        image=image\/255.0\n        testset.append([image,count])         \n    count=count+1","b5719d9f":"data,labels0=zip(*dataset)\ntest,testlabels0=zip(*testset)","605a1a6c":"labels1=to_categorical(labels0)\ndata=np.array(data)\nlabels=np.array(labels1)\nprint(data.shape)\nprint(labels.shape)","49453907":"testlabels1=to_categorical(testlabels0)\ntest=np.array(test)\ntestlabels=np.array(testlabels1)\nprint(test.shape)\nprint(testlabels.shape)","f53b00a7":"data2=data.reshape(-1,150,150,3)\ntest2=test.reshape(-1,150,150,3)","e795d7c1":"trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=44)","fbf880fc":"print(trainx.shape)\nprint(testx.shape)\nprint(trainy.shape)\nprint(testy.shape)","de03bff0":"datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=20,zoom_range=0.2,\n                    width_shift_range=0.2,height_shift_range=0.2,shear_range=0.1,fill_mode=\"nearest\")","853d5f04":"pretrained_model3 = tf.keras.applications.DenseNet201(input_shape=(150,150,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model3.trainable = False","0d40f8f7":"inputs3 = pretrained_model3.input\nx3 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model3.output)\noutputs3 = tf.keras.layers.Dense(4, activation='softmax')(x3)\nmodel = tf.keras.Model(inputs=inputs3, outputs=outputs3)\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","69f4a662":"his=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=30)","befced8f":"y_pred=model.predict(testx)\npred=np.argmax(y_pred,axis=1)\nground = np.argmax(testy,axis=1)\nprint(classification_report(ground,pred))","3e5bd08d":"get_acc = his.history['accuracy']\nvalue_acc = his.history['val_accuracy']\nget_loss = his.history['loss']\nvalidation_loss = his.history['val_loss']\n\nepochs = range(len(get_acc))\nplt.plot(epochs, get_acc, 'r', label='Accuracy of Training data')\nplt.plot(epochs, value_acc, 'b', label='Accuracy of Validation data')\nplt.title('Training vs validation accuracy')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","b4ce6f2f":"epochs = range(len(get_loss))\nplt.plot(epochs, get_loss, 'r', label='Loss of Training data')\nplt.plot(epochs, validation_loss, 'b', label='Loss of Validation data')\nplt.title('Training vs validation loss')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","d00ea1fd":"load_img(\"..\/input\/brain-tumor-classification-mri\/Testing\/meningioma_tumor\/image(112).jpg\",target_size=(150,150))","120ab2f8":"image=load_img(\"..\/input\/brain-tumor-classification-mri\/Testing\/meningioma_tumor\/image(112).jpg\",target_size=(150,150))\n\nimage=img_to_array(image) \nimage=image\/255.0\nprediction_image=np.array(image)\nprediction_image= np.expand_dims(image, axis=0)","cd021522":"reverse_mapping={0:'no_tumor', 1:'pituitary_tumor', 2:'meningioma_tumor', 3:'glioma_tumor'}\n\ndef mapper(value):\n    return reverse_mapping[value]\n\nprediction=model.predict(prediction_image)\nvalue=np.argmax(prediction)\nmove_name=mapper(value)\nprint(\"Prediction is {}.\".format(move_name))","991adccd":"def generate_adversary(image, label):\n  image = tf.cast(image, tf.float32)\n\n  with tf.GradientTape() as tape:\n    tape.watch(image)\n    prediction = model(image)\n    loss = tf.keras.losses.MSE(label, prediction)\n  gradient = tape.gradient(loss, image)\n  sign_grad = tf.sign(gradient)\n\n  return sign_grad","d7bbb280":"def print_shapes(trainx, testx, trainy, testy):\n  print(f\"x_train: {trainx.shape}\\n\"\\\n      f\"x_test: {testx.shape}\\n\"\\\n      f\"y_train: {trainy.shape}\\n\"\\\n      f\"y_test: {testy.shape}\\n\")\nprint_shapes(trainx, testx, trainy, testy)","396a4b92":"from random import randint\nheight, width, channels = 150, 150, 3\n\nreverse_mapping={0:'no_tumor', 1:'pituitary_tumor', 2:'meningioma_tumor', 3:'glioma_tumor'}\n\ndef mapper(value):\n    return reverse_mapping[value]\n\nrand_idx = randint(0,2995)\nimage = trainx[rand_idx].reshape((1, height, width, channels))\nlabel = trainy[rand_idx]\nprediction=model.predict(image)\nvalue=np.argmax(prediction)\nmove_name=mapper(value)\nprint(\"Prediction before Attack is {}.\".format(move_name))\n\nplt.figure(figsize=(3,3))\nplt.imshow(image.reshape((height, width, channels)))\nplt.show()","42d9e064":"perturbations = generate_adversary(image,label).numpy()\nadversarial = image + (perturbations * 3)","7b580d4f":"fig, (ax1,ax2) = plt.subplots(1, 2, sharey=True)\nax1.imshow(image.reshape(height,width, channels))\nax1.set_title(\"Original Image\")\nax2.imshow(adversarial.reshape(height,width, channels))\nax2.set_title(\"Image with Adversary\")\nplt.show()","ab90d2ac":"prediction=model.predict(image)\nvalue=np.argmax(prediction)\nmove_name=mapper(value)\nprint(\"Prediction before Attack is {}.\".format(move_name))\n\nprediction=model.predict(adversarial)\nvalue=np.argmax(prediction)\nmove_name=mapper(value)\nprint(\"Prediction after Attack is {}.\".format(move_name))","35723877":"def adversary_generator(batch_size):\n  while True:\n    images = []\n    labels = []\n    for batch in range(batch_size):\n      N = randint(0, 2295)\n      label = trainy[N]\n      image = trainx[N].reshape((1,height, width, channels))\n\n      perturbations = generate_adversary(image, label).numpy()\n      adversarial = image + (perturbations * 3)\n\n      images.append(adversarial)\n      labels.append(label)\n\n      if batch%100 == 0:\n        print(f\"{batch} images generated\")\n\n    images = np.asarray(images).reshape((batch_size, height, width, channels))\n    labels = np.asarray(labels)\n\n    yield images, labels","8db7ebf8":"x_adversarial, y_adversarial = next(adversary_generator(574))\nad_acc = model.evaluate(x_adversarial, y_adversarial, verbose=0)\nprint(f\"Accuracy on Adversarial Examples: {ad_acc[1]*100}\")","67c496b7":"# **Adversarial Attack**"}}