{"cell_type":{"a8d81689":"code","a8fb2667":"code","22267c8a":"code","b2b2e19a":"code","41b1ebce":"code","3059c5f6":"code","6b48ea12":"code","494ec6dc":"code","cdca2b85":"code","53368829":"code","40a1503c":"code","3f051cd9":"code","d3d4a4bf":"code","0ab2e6ec":"code","713afc7b":"code","2553921c":"code","95651fa3":"code","5471dcf1":"code","3ebc73f4":"code","3e06ae28":"code","758a1da0":"code","5b37b1b6":"code","9c07eaca":"markdown","2f049678":"markdown","e9d6f47d":"markdown","18ac9c4c":"markdown","e51b1a0a":"markdown","d5710f7d":"markdown","b62572e4":"markdown"},"source":{"a8d81689":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a8fb2667":"from keras.preprocessing import image","22267c8a":"train_images = sorted(os.listdir('\/kaggle\/input\/medical-image-dataset\/Dataset'))","b2b2e19a":"train_image = []\nfor im in train_images:\n    img = image.load_img('\/kaggle\/input\/medical-image-dataset\/Dataset\/'+ im, target_size=(64,64), color_mode= 'grayscale')\n    img = image.img_to_array(img)\n    img = img\/255\n    train_image.append(img)\ntrain_df = np.array(train_image)","41b1ebce":"import matplotlib.pyplot as plt\n\ndef show_img(dataset):\n    f, ax = plt.subplots(1,5)\n    f.set_size_inches(40, 20)\n    for i in range(5,10):\n        ax[i-5].imshow(dataset[i].reshape(64,64), cmap='gray')\n    plt.show()","3059c5f6":"def add_noice(image):\n    row,col,ch= image.shape\n    mean = 0\n    sigma = 1\n    gauss = np.random.normal(mean,sigma,(row,col,ch))\n    gauss = gauss.reshape(row,col,ch)\n    noisy = image + gauss*0.07\n    return noisy","6b48ea12":"noised_df= []\n\nfor img in train_df:\n    noisy= add_noice(img)\n    noised_df.append(noisy)","494ec6dc":"noised_df= np.array(noised_df)","cdca2b85":"show_img(train_df)","53368829":"show_img(noised_df)","40a1503c":"noised_df.shape","3f051cd9":"train_df.shape","d3d4a4bf":"xnoised= noised_df[0:100]\nxtest= noised_df[100:]","0ab2e6ec":"xnoised.shape","713afc7b":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D,MaxPool2D ,UpSampling2D, Flatten, Input\nfrom keras.optimizers import SGD, Adam, Adadelta, Adagrad\nfrom keras import backend as K\n\ndef autoencoder():\n    \n    input_img = Input(shape=(64,64,1), name='image_input')\n    \n    #enoder \n    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n    x = MaxPooling2D((2,2), padding='same', name='pool1')(x)\n    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv2')(x)\n    x = MaxPooling2D((2,2), padding='same', name='pool2')(x)\n    \n    #decoder\n    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3')(x)\n    x = UpSampling2D((2,2), name='upsample1')(x)\n    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv4')(x)\n    x = UpSampling2D((2,2), name='upsample2')(x)\n    x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv5')(x)\n    \n    #model\n    autoencoder = Model(inputs=input_img, outputs=x)\n    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n    \n    return autoencoder","2553921c":"model= autoencoder()\nmodel.summary()","95651fa3":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping","5471dcf1":"with tf.device('\/device:GPU:0'):\n    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n    model.fit(xnoised, xnoised, epochs=40, batch_size=10, validation_data=(xtest, xtest), callbacks=[early_stopping])","3ebc73f4":"xtrain= train_df[100:]","3e06ae28":"import cv2\n\npred= model.predict(xtest[:5])\ndef plot_predictions(y_true, y_pred):    \n    f, ax = plt.subplots(4, 5)\n    f.set_size_inches(10.5,7.5)\n    for i in range(5):\n        ax[0][i].imshow(np.reshape(xtrain[i], (64,64)), aspect='auto', cmap='gray')\n        ax[1][i].imshow(np.reshape(y_true[i], (64,64)), aspect='auto', cmap='gray')\n        ax[2][i].imshow(np.reshape(y_pred[i], (64,64)), aspect='auto', cmap='gray')\n        ax[3][i].imshow(cv2.medianBlur(xtrain[i], (5)), aspect='auto', cmap='gray')\n       \n    plt.tight_layout()\nplot_predictions(xtest[:5], pred[:5])","758a1da0":"new_image = cv2.medianBlur(xtrain[0], (5))\nplt.figure(figsize=(6,3))\nplt.subplot(121)\nplt.imshow(pred[0].reshape(64,64), cmap='gray')\nplt.title('Autoencoder Image')\nplt.xticks([])\nplt.yticks([])\nplt.subplot(122)\nplt.imshow(new_image, cmap='gray')\nplt.title('Median Filter')\nplt.xticks([])\nplt.yticks([])\nplt.show()","5b37b1b6":"from math import log10, sqrt \n  \ndef PSNR(original, denoiced): \n    mse = np.mean((original - denoiced) ** 2) \n    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n                  # Therefore PSNR have no importance. \n        return 100\n    max_pixel = 255.0\n    psnr = 20 * log10(max_pixel \/ sqrt(mse)) \n    return psnr \n  \nvalue1 = PSNR(xtest[0], new_image)\nvalue2 = PSNR(xtest[0], pred[0])\n\nprint(f\"PSNR value for Denoised image is {value2} dB while for Median filtered image is {value1} dB\")","9c07eaca":"### Constructing the dataset in the required format","2f049678":"### Paper suggests to set epoch=100, but, due to less computational power available and small dataset, we'll use 40 epochs with a batch size of 10.","e9d6f47d":"### Defining a plot function","18ac9c4c":"### Defining a function for Noice addition. 0.07 is multiplied as it is the fraction of noice that we want in our picture.","e51b1a0a":"### Defining the model architecture as per the design suggested in the paper","d5710f7d":"## Plotting the predictions.\n\n### First row:   Original image\n### Second row:  Noice image\n### Third row:   Denoised image using Autoencoder\n### Fourth row:  Median filter image","b62572e4":"### In this notebook, I've implemented the [following](https:\/\/arxiv.org\/pdf\/1608.04667.pdf) paper. The aim is to contruct a denoising autoencoder yielding superior results than that from Median filtering. Dental X-ray dataset is used for training and testing."}}