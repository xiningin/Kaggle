{"cell_type":{"5573248c":"code","f98bdbfb":"code","6657a47a":"code","1cd69679":"code","356a7599":"code","0c97958e":"code","cead1f81":"code","5458ab7e":"code","b9d0f081":"code","4e1b6a55":"code","954db790":"code","1e383d36":"code","a0f150b7":"code","e7878af1":"code","9ae2a1d4":"code","915c914b":"code","22db9b18":"code","8acb44e2":"code","22b5e4dc":"code","2b4a41d4":"code","0ce74c94":"code","ec1fadee":"code","3bd45368":"code","64bbfcf1":"code","978f194b":"code","5197f7fa":"code","75a3e53e":"code","5a1fa950":"code","67116311":"code","7c318920":"code","fa050d47":"code","3c2a00fa":"code","9c2899bb":"code","6cecc90b":"code","21aed504":"code","7c875b83":"code","adadf9c6":"code","73156aa8":"code","4342f89e":"code","2bb346d7":"code","9b59fead":"code","3203f5b0":"code","b41eb124":"code","6931bd09":"code","ed9b5e6b":"code","e442ea94":"code","32484d03":"code","5453186c":"code","434d8f60":"markdown","b9224952":"markdown"},"source":{"5573248c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f98bdbfb":"PATH=os.getcwd()\nprint(PATH)","6657a47a":"PATH=\"..\/input\/image-classification\/image\/Image\/10_categories\"","1cd69679":"print(os.listdir(PATH))","356a7599":"img_rows=224\nimg_cols=224\nnum_channel=3\n\nnum_epoch=3\nbatch_size=32\n\nimg_data_list=[]\nclasses_names_list=[]\ndata_dir_list=os.listdir(PATH)","0c97958e":"import cv2\n\nfor dataset in data_dir_list:\n    classes_names_list.append(dataset) \n    print ('Loading images from {} folder\\n'.format(dataset)) \n    img_list=os.listdir(PATH+'\/'+ dataset)\n    for img in img_list:\n        input_img=cv2.imread(PATH + '\/'+ dataset + '\/'+ img )\n        input_img_resize=cv2.resize(input_img,(img_rows, img_cols))\n        img_data_list.append(input_img_resize)","cead1f81":"num_classes = len(classes_names_list)\nprint(num_classes)","5458ab7e":"import numpy as np\n\nimg_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data \/= 255","b9d0f081":"num_of_samples = img_data.shape[0]\ninput_shape = img_data[0].shape","4e1b6a55":"print (img_data.shape)\nprint(num_of_samples)\nprint(input_shape)","954db790":"classes = np.ones((num_of_samples,), dtype='int64')\n\nclasses[0:239]=0\nclasses[239:367]=1\nclasses[367:490]=2\nclasses[490:690]=3\nclasses[690:1490]=4\nclasses[1490:1958]=5\nclasses[1958:2393]=6\nclasses[2393:2828]=7\nclasses[2828:3626]=8\nclasses[3626:]=9\n","1e383d36":"from keras.utils import to_categorical\n\nclasses = to_categorical(classes, num_classes)","a0f150b7":"print(classes.shape)\nprint(classes)\n","e7878af1":"from sklearn.utils import shuffle\n\nX, Y = shuffle(img_data, classes, random_state=2)","9ae2a1d4":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)","915c914b":"y_test.shape","22db9b18":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D","8acb44e2":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))","22b5e4dc":"model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])","2b4a41d4":"num_epoch=12","0ce74c94":"from keras.preprocessing.image import ImageDataGenerator\n\ndata_gen = ImageDataGenerator(\n    rotation_range=20,\n    shear_range=0.5, \n    zoom_range=0.4, \n    rescale=1.\/255,\n    vertical_flip=True, \n    validation_split=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True) ","ec1fadee":"#TRN_AUGMENTED = os.path.join(PATH  , 'Trn_Augmented_Images')\n#TST_AUGMENTED = os.path.join(PATH  , 'Tst_Augmented_Images')","3bd45368":"train_generator = data_gen.flow_from_directory(\n        PATH,\n        target_size=(img_rows, img_cols), \n        batch_size=batch_size,\n        class_mode='categorical',\n        color_mode='rgb', \n        shuffle=True)\n\n #       save_to_dir=TRN_AUGMENTED, \n #       save_prefix='TrainAugmented', \n #       save_format='png', \n #       subset=\"training\")","64bbfcf1":"train_generator.class_indices","978f194b":"test_generator = data_gen.flow_from_directory(\n        PATH,\n        target_size=(img_rows, img_cols),\n        batch_size=32,\n        class_mode='categorical',\n        color_mode='rgb', \n        shuffle=True, \n        seed=None)\n\n#        save_to_dir=TST_AUGMENTED, \n#        save_prefix='TestAugmented', \n#        save_format='png',\n#        subset=\"validation\")","5197f7fa":"test_generator.class_indices","75a3e53e":"model.fit_generator(train_generator, epochs=num_epoch, validation_data=test_generator,steps_per_epoch = len(X_train)\/batch_size,validation_steps=len(X_test)\/batch_size)","5a1fa950":"model.evaluate_generator(train_generator,steps = len(X_train)\/batch_size,verbose=1)","67116311":"Y_pred = model.predict(X_test)\nprint(Y_pred)\nY_train_result = model.predict(X_train)\nprint(Y_train_result)","7c318920":"y_pred = np.argmax(Y_pred, axis=1)\nprint(y_pred)\ny_train_result = np.argmax(Y_train_result, axis=1)\nprint(y_train_result)","fa050d47":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report,accuracy_score\n","3c2a00fa":"\ny_true=np.argmax(y_test,axis=1)\ny_true_train=np.argmax(y_train,axis=1)\n","9c2899bb":"print(classification_report(y_pred,y_true))\nprint(classification_report(y_train_result,y_true_train))\nprint(\"test accuracy = \",accuracy_score(y_pred,y_true))\nprint(\"validation accuracy = \",accuracy_score(y_train_result,y_true_train))","6cecc90b":"#from IPython.display import Image\n#Image(filename='vgg16.png')","21aed504":"from tensorflow.keras.layers import Input, Dense","7c875b83":"# Custom_vgg_model_1\n#Training the classifier alone\nimage_input = Input(shape=(img_rows, img_cols, num_channel))","adadf9c6":"from tensorflow.keras.applications.vgg16 import VGG16\n\nprint(os.listdir(\"..\/input\/vgg16-weights\"))","73156aa8":"from keras import applications\nmodel = VGG16(input_tensor=image_input, include_top=True, weights='..\/input\/vgg16-weights\/vgg16_weights_tf_dim_ordering_tf_kernels.h5', )","4342f89e":"last_layer = model.get_layer('fc2').output\nout = Dense(num_classes, activation='softmax', name='output')(last_layer)","2bb346d7":"from tensorflow.keras.models import Model\n\ncustom_vgg_model = Model(image_input, out)\ncustom_vgg_model.summary()","9b59fead":"for layer in custom_vgg_model.layers[:-1]:\n    layer.trainable = False","3203f5b0":"custom_vgg_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])","b41eb124":"num_epoch = 100\ncustom_vgg_model.fit(X_train, y_train, batch_size=512, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))","6931bd09":"from keras.models import load_model\n\ncustom_vgg_model.save('Image_Class_Cute5.h5')","ed9b5e6b":"(loss, accuracy) = custom_vgg_model.evaluate(X_train, y_train, batch_size=batch_size, verbose=1)\n\nprint(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))","e442ea94":"Y_train_pred = custom_vgg_model.predict(X_test)","32484d03":"y_train_pred = np.argmax(Y_train_pred, axis=1)\nprint(y_train_pred)","5453186c":"from sklearn.metrics import classification_report,accuracy_score\nprint(\"test accuracy = \",accuracy_score(y_train_pred ,np.argmax(y_test, axis=1),))\n#print(\"test accuracy = \",accuracy_score(y_pred,y_true))","434d8f60":"Get the current working directory","b9224952":"# This is Image Classification for Cute"}}