{"cell_type":{"f4ef7cc8":"code","51c106ae":"code","2ae58769":"code","5eaa5bb9":"code","c8a811d2":"code","961f3444":"code","e2101f74":"code","3132556e":"code","35e0fe3c":"code","9490ee71":"code","de9cf639":"code","2746b266":"code","a58d16b9":"code","36e011af":"code","352b92e7":"code","b73c6e60":"code","651c52a9":"code","dbf329ee":"code","20617b94":"code","f942a1fb":"code","ab06c482":"code","64594766":"code","b65562d8":"code","4911a03a":"code","adb515de":"code","35bfce47":"code","ba92f00e":"code","65f8277c":"code","15a085e1":"code","5f7d6fc2":"code","70375aa4":"code","a1999ab1":"code","01d38b90":"code","6119e8f5":"code","8a6b9845":"code","cae510d9":"code","3132fce3":"code","d94cefa6":"code","eb2a7ea5":"code","10f353cf":"code","dea61bc6":"code","6b37d592":"code","f3a532b0":"code","36f00bee":"code","7c9ff36e":"code","38c1074e":"code","e84441c0":"code","aa8cd95d":"code","34278a89":"code","10b724be":"code","f198d1ba":"code","f91a7522":"code","548ca1d2":"code","08b20ab7":"code","2152fae2":"code","e2c158a1":"code","821953b0":"code","2dc82905":"code","8842f82a":"code","d45331ee":"code","a96518f3":"code","7481e33c":"code","b9550f82":"code","418915cd":"code","b6c1d631":"code","094d4567":"code","a7bf33a0":"code","feb1ce4d":"markdown","ba4599fb":"markdown","1caae0e9":"markdown","8e59fbef":"markdown","6e504060":"markdown"},"source":{"f4ef7cc8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib \nmatplotlib.rcParams['figure.figsize']=(15,7)\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51c106ae":"df1 = pd.read_csv('..\/input\/pune-house-data\/Pune house data.csv')\ndf1.head()","2ae58769":"df1.shape","5eaa5bb9":"df1.groupby('area_type')['area_type'].agg('count')","c8a811d2":"#check null values\ndf1.isnull().sum()","961f3444":"#remove unwanted columns\ndf2= df1.drop(['society', 'availability'], axis='columns')\ndf2.head()","e2101f74":"#again check null values\ndf2.isnull().sum()\n#balcony has more null values.","3132556e":"#checking count of unique values \ndf2.groupby('balcony')['balcony'].agg('count')","35e0fe3c":"#assume that null values means no balacony(0).\n\ndf2['balcony'] = df2['balcony'].fillna('0')\ndf2.isnull().sum()","9490ee71":"#drop other null rows from the data.\ndf3=df2.dropna()\ndf3.shape","de9cf639":"df3.isnull().sum()\n#now dataset has no null values.","2746b266":"df3.head()\n#size columns has to be neat.","a58d16b9":"#check columns unique one-by-one to clean data.\ndf3['area_type'].unique()\n\n#looks like area_type colum is clean.","36e011af":"#checking size column\ndf3['size'].unique()","352b92e7":"#create new columns to only pic number from size.\ndf3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))","b73c6e60":"df3.head()\n#seperate columns of only number of bhk is created. Now drop size column.","651c52a9":"df4 = df3.drop('size', axis='columns')\ndf4['bhk'].unique()\n#there are houses which contains more than 20 rooms.","dbf329ee":"#there are houses which contains more than 20 rooms. Lets check them how many houses are there.\n\ndf4[df4.bhk>20]","20617b94":"#checking total_sqft columns for cleaning.\ndf4['total_sqft'].unique()\n\n#there are some values like (113-1384) in ranges.","f942a1fb":"def is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","ab06c482":"df4[~df4['total_sqft'].apply(is_float)].head(10)","64594766":"#convert those to numbers\ndef convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens)==2:\n        return(float(tokens[0])+float(tokens[1]))\/2\n    try:\n        return float(x)\n    except:\n        return None","b65562d8":"#checking the function works properly\nconvert_sqft_to_num('2548-2825')\n\n#return(float(tokens[0])+float(tokens[1]))\/2","4911a03a":"convert_sqft_to_num('2548')\n#return float(x)","adb515de":"convert_sqft_to_num('4.46Sq. Meter')\n#return None\n#all works.","35bfce47":"#apply it full column\ndf5 = df4.copy()\ndf5['total_sqft'] = df5['total_sqft'].apply(convert_sqft_to_num)\ndf5.head()","ba92f00e":"#check is it changed ot not\ndf5.loc[30]\n#changed from 2100-2850 to 2475","65f8277c":"df5.loc[410]\n#changed from 34.46Sq. Meter to NaN.","15a085e1":"df5.isnull().sum()","5f7d6fc2":"#drop those null values.\ndf6 = df5.dropna()","70375aa4":"#now create a new colum price per sqft.\ndf6['price_per_sqft'] = df6['price']*100000 \/ df6['total_sqft']\ndf6.head(10)","a1999ab1":"#continue checking of other columns.\ndf6['bath'].unique()\n\n#there is 40 bathrooms, it is unusual but in this data there 40bhk house also there,so leave this.\n","01d38b90":"df6['site_location'].unique()\n#its fine.","6119e8f5":"df6.head()\n#all data columns are looks fine.\n#now move to check outliers.","8a6b9845":"df6.shape","cae510d9":"#outliers are found in only numeric columns.\n#note there is usual sqft of 1bhk is more than 300. check whether is any less than 300.\ndf6[df6.total_sqft\/df6.bhk<300]\n\n#correct there are some house which cann't believe. so remove them from data.","3132fce3":"df7 = df6[~(df6.total_sqft\/df6.bhk<300)]","d94cefa6":"df7.shape","eb2a7ea5":"df7.price_per_sqft.describe()\n\n#min is 267 \n#max is 176470, it is unbelivable for one sqft.","10f353cf":"def remove_pps_outliers(df):\n    df_out = pd.DataFrame()\n    for key, subdf in df.groupby('site_location'):\n        m = np.mean(subdf.price_per_sqft)\n        st = np.std(subdf.price_per_sqft)\n        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n        df_out = pd.concat([df_out, reduced_df], ignore_index = True)\n    return df_out\n\ndf8 = remove_pps_outliers(df7)\ndf8.shape","dea61bc6":"def plot_scatter_chart(df,location):\n    bhk2 = df[(df.site_location==location) & (df.bhk==2)]\n    bhk3 = df[(df.site_location==location) & (df.bhk==3)]\n    matplotlib.rcParams['figure.figsize'] = (15,10)\n    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter_chart(df8,\"Anandnagar\")\n#some house price have 3 bhk there prices are less 2 bhk house.","6b37d592":"def remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('site_location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean' : np.mean(bhk_df.price_per_sqft),\n                'std' : np.std(bhk_df.price_per_sqft),\n                'count' : bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n    return df.drop(exclude_indices, axis ='index')\n\ndf9 = remove_bhk_outliers(df8)\ndf9.shape","f3a532b0":"def plot_scatter_chart(df,location):\n    bhk2 = df[(df.site_location==location) & (df.bhk==2)]\n    bhk3 = df[(df.site_location==location) & (df.bhk==3)]\n    matplotlib.rcParams['figure.figsize'] = (15,10)\n    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter_chart(df9,\"Anandnagar\")\n#some outliers are removed.","36f00bee":"import matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(df9.price_per_sqft,rwidth=0.8)\nplt.xlabel(\"Price Per Square Feet\")\nplt.ylabel(\"Count\")","7c9ff36e":"df9.bath.unique()","38c1074e":"plt.hist(df9.bath, rwidth=0.8)\nplt.xlabel('Number of bathrooms')\nplt.ylabel('count')","e84441c0":"df9[df9.bath>10]","aa8cd95d":"#some house have bathrooms more than rooms, it is belivable if 1 extra is there, but if more 1 extra is unbelivable.\n\ndf9[df9.bath>df9.bhk+2]\n\n#is there. drop them.","34278a89":"df10= df9[df9.bath<df9.bhk+2]","10b724be":"df10.shape","f198d1ba":"df10.head()","f91a7522":"#all data are clear now.\n#remove price_per_sqft.\ndf11 = df10.drop('price_per_sqft', axis='columns')\ndf11.head()","548ca1d2":"location_dummies = pd.get_dummies(df11.site_location)\nlocation_dummies.head()","08b20ab7":"area_type_dummies = pd.get_dummies(df11.area_type)\narea_type_dummies.head()","2152fae2":"df12 = pd.concat([df11, location_dummies.drop('Yerawada', axis='columns'), area_type_dummies.drop('Built-up  Area', axis='columns')], axis='columns')\ndf12.head()","e2c158a1":"df13 = df12.drop(['site_location', 'area_type'], axis='columns')\ndf13.head()","821953b0":"df13.shape","2dc82905":"X = df13.drop('price', axis='columns')\nX.head()","8842f82a":"y=df13.price\ny.head()","d45331ee":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=10)","a96518f3":"from sklearn.linear_model import LinearRegression\nlr_clf = LinearRegression()\nlr_clf.fit(X_train, y_train)\nlr_clf.score(X_test, y_test)","7481e33c":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n\ncross_val_score(LinearRegression(), X, y, cv=cv)","b9550f82":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,y):\n    algos = {\n        'linear_regression' : {\n            'model': LinearRegression(),\n            'params': {\n                'normalize': [True, False]\n            }\n        },\n        'lasso': {\n            'model': Lasso(),\n            'params': {\n                'alpha': [1,2],\n                'selection': ['random', 'cyclic']\n            }\n        },\n        'decision_tree': {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion' : ['mse','friedman_mse'],\n                'splitter': ['best','random']\n            }\n        }\n    }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        })\n\n    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n\nfind_best_model_using_gridsearchcv(X,y)","418915cd":"def predict_price(location,sqft,bath,bhk):    \n    loc_index = np.where(X.columns==location)[0][0]\n\n    x = np.zeros(len(X.columns))\n    x[0] = sqft\n    x[1] = bath\n    x[2] = bhk\n    if loc_index >= 0:\n        x[loc_index] = 1\n\n    return lr_clf.predict([x])[0]","b6c1d631":"predict_price('Alandi Road', 1000,2,2)","094d4567":"predict_price('Alandi Road', 1000,3,3)","a7bf33a0":"predict_price('Ambegaon Budruk', 1000,3,3)","feb1ce4d":"**Model building**","ba4599fb":"**Import Dataset- Pune house data**","1caae0e9":"**Outlier detection and treatment**","8e59fbef":"**Data cleaning**","6e504060":"**One-hot coding**"}}