{"cell_type":{"829ceb9d":"code","3793365e":"code","88369be1":"code","43a2c243":"code","d9443f8a":"code","741e53c0":"code","d9fb5ee6":"code","dae32ece":"code","53960326":"code","1f3f2703":"code","3cb96e56":"code","60274dde":"code","cd635044":"code","025041ec":"code","a54fbf74":"code","3fa83dc5":"code","943b6636":"code","f10aa098":"code","1257eba4":"code","68ca015b":"code","44ee7295":"code","d1b333eb":"code","7f3ce4a9":"code","ab4545d5":"code","a0057b5e":"code","010347d1":"code","a3bfa863":"code","e984a9b1":"code","aebfcb15":"code","a3366363":"markdown","f5afa860":"markdown","94b82869":"markdown","f8fe5be4":"markdown"},"source":{"829ceb9d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3793365e":"from sklearn.model_selection import train_test_split\nfrom keras.models import Model\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping","88369be1":"data = pd.read_csv('..\/input\/spam.csv', delimiter=\",\", encoding=\"latin-1\")\ndata.head()","43a2c243":"data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\ndata.head()","d9443f8a":"data.columns = ['category', 'content']","741e53c0":"data['category'].value_counts().plot(kind = 'bar')","d9fb5ee6":"sns.countplot(data['category'])","dae32ece":"X = data.content\ny = data.category","53960326":"le = LabelEncoder()\ny = le.fit_transform(y)\nprint(y)","1f3f2703":"y = y.reshape(-1,1)","3cb96e56":"print(y[:5])","60274dde":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)","cd635044":"train_length = X.apply(len)\ntrain_length.head()","025041ec":"plt.figure(figsize = (12, 5))\nplt.hist(train_length, bins = 50, alpha = 0.5, color = 'r')\nplt.show()","a54fbf74":"print(np.mean(train_length))\nprint(np.std(train_length))\nprint(np.percentile(train_length, 75))\nprint(np.percentile(train_length, 80))","3fa83dc5":"max_words = 1000\nmax_len = 150\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)","943b6636":"sequences = tok.texts_to_sequences(X_train)\nprint(sequences[:1])","f10aa098":"sequences_matrix = sequence.pad_sequences(sequences, maxlen = max_len)","1257eba4":"sequences_matrix[0]","68ca015b":"for key, value in tok.word_index.items():\n    if value > 10:break\n    print(value, \" : \", key)","44ee7295":"def model():\n    inputs = Input(name = 'input', shape = [max_len])\n    layer = Embedding(max_words, 50, input_length = max_len)(inputs)\n    layer = LSTM(64)(layer)\n    layer = Dense(256, name = 'hidden')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(1, name='output')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs = inputs, outputs = layer)\n    return model","d1b333eb":"model = model()\nmodel.summary()","7f3ce4a9":"model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics =['accuracy'])","ab4545d5":"hist = model.fit(sequences_matrix, y_train, batch_size = 128, epochs = 10, validation_split = 0.2, callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2)])","a0057b5e":"test_sequences = tok.texts_to_sequences(X_test)\ntest_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)","010347d1":"acc = model.evaluate(test_sequences_matrix, y_test)","a3bfa863":"print(\"loss : %.2f,  acc : %.2f\" %(acc[0], acc[1]))","e984a9b1":"vloss = hist.history['val_loss']\nloss = hist.history['loss']\n\nx_len = np.arange(len(loss))\n\nplt.plot(x_len, vloss, marker='.', c='red', label='vloss')\nplt.plot(x_len, loss, marker='.', c='blue', label='loss')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.grid()\nplt.show()","aebfcb15":"vacc = hist.history['val_acc']\nacc = hist.history['acc']\n\nx_len = np.arange(len(vacc))\n\nplt.plot(x_len, vacc, marker='.', c='red', label='vacc')\nplt.plot(x_len, acc, marker='.', c='blue', label='acc')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.grid()\nplt.show()","a3366363":"drop unnecessary columns","f5afa860":"** preprocessing data **\n\n- tokenize the data and convert text to sequence\n- add padding\n- set max length and max words","94b82869":"load data using pandas","f8fe5be4":"** create input, output vector and split data **"}}