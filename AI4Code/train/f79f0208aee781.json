{"cell_type":{"356b785a":"code","d83757f7":"code","4650d093":"code","cf9547fd":"code","f50af075":"code","e9fbb66e":"code","7000ccf3":"code","b45572ed":"code","2e543f86":"code","f1f7d531":"code","dabe5dfa":"code","46f4d320":"code","5ad1060d":"code","a26bf0f3":"code","f716b839":"code","50878c26":"code","7c19b975":"code","990c61be":"code","e8fd9b40":"code","3d591b80":"code","7bef5833":"code","70e28e05":"code","5550b664":"markdown","8f4df037":"markdown","e850f0f6":"markdown","78a7e7dc":"markdown","cd4789a5":"markdown","7e0b542a":"markdown"},"source":{"356b785a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport cv2\n\n\nimport keras\nimport tensorflow as tf\nfrom keras.layers import BatchNormalization, Conv2D, Concatenate, Dense, Dropout,\\\n                          GlobalAveragePooling2D, Input, MaxPooling2D, Multiply,\\\n                            UpSampling2D, concatenate\\\n                            \nfrom keras.preprocessing import image as ki\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nfrom matplotlib import pyplot as plt\n","d83757f7":"PATH_TO_IMAGE_DIR='\/kaggle\/input\/bacteria-detection-with-darkfield-microscopy\/images\/'\n\nPATH_TO_MASK_DIR='\/kaggle\/input\/bacteria-detection-with-darkfield-microscopy\/masks\/'\n\nPATH_TO_PROCESSED_MASK_DIR='\/kaggle\/working\/masks\/'\n\nPATH_TO_BEST_MODEL_SAVED=os.path.join(\"kaggle\",\"working\",\"model\")\n\nos.environ['KERAS_BACKEND']='tensorflow'\n\nRANDOM_SEED=1511\n\nBATCH_SIZE=8\n\n%matplotlib inline\n\nIMAGE_WIDTH=256\nIMAGE_HEIGHT=256\nIMAGE_CHANNELS=3","4650d093":"physical_devices = tf.config.list_physical_devices('GPU')\ntry:\n  tf.config.experimental.set_memory_growth(physical_devices[0], True)\nexcept:\n  # Invalid device or cannot modify virtual devices once initialized.\n  pass","cf9547fd":"if not os.path.exists(PATH_TO_PROCESSED_MASK_DIR):\n    os.mkdir(PATH_TO_PROCESSED_MASK_DIR)","f50af075":"help(os.mkdir)","e9fbb66e":"dataset=pd.DataFrame(columns=[\"file_name\", 'mask_file_name'])","7000ccf3":"dataset.file_name=os.listdir(PATH_TO_IMAGE_DIR)\n\n","b45572ed":"for mask_file in os.listdir(PATH_TO_MASK_DIR):\n    dataset.loc[dataset.file_name==mask_file, 'mask_file_name']=mask_file\n    mask_matrix=cv2.imread(os.path.join(PATH_TO_MASK_DIR, mask_file))\n    mask_matrix=cv2.cvtColor(mask_matrix, cv2.COLOR_BGR2RGB)\n    mask_matrix=mask_matrix[:,:,2]==1\n    mask_matrix=mask_matrix*255\n    \n    cv2.imwrite(os.path.join(PATH_TO_PROCESSED_MASK_DIR,mask_file), mask_matrix)","2e543f86":"sample_mask=cv2.imread(os.path.join(PATH_TO_PROCESSED_MASK_DIR, '101.png'), cv2.IMREAD_GRAYSCALE)\nplt.imshow(sample_mask)\nplt.show()\n\nprint(sample_mask.shape)","f1f7d531":"dataset_train, dataset_test= train_test_split(dataset, test_size=0.2, random_state=RANDOM_SEED)","dabe5dfa":"image_gen_args=dict(\n#     featurewise_center=True,\n#     featurewise_std_normalization=True,\n    rescale=1\/255,\n    rotation_range=30,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.2\n)\n\ntrain_image_generator=ki.ImageDataGenerator(**image_gen_args)\ntrain_mask_generator=ki.ImageDataGenerator(**image_gen_args)\n\n\ntrain_image_collection=train_image_generator.flow_from_dataframe(\n    dataframe=dataset_train,\n    x_col='file_name',\n    directory=PATH_TO_IMAGE_DIR,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    subset='training',\n    batch_size=BATCH_SIZE,\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)\n\n)\n\ntrain_mask_collection=train_image_generator.flow_from_dataframe(\n    dataframe=dataset_train,\n    x_col='file_name',\n    directory=PATH_TO_PROCESSED_MASK_DIR,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    subset='training',\n    batch_size=BATCH_SIZE,\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n    color_mode='grayscale',\n    \n\n)\n\n\nval_image_collection=train_image_generator.flow_from_dataframe(\n    dataframe=dataset_train,\n    x_col='file_name',\n    directory=PATH_TO_IMAGE_DIR,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    subset='validation',\n    batch_size=BATCH_SIZE,\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)\n\n)\n\n\nval_mask_collection=train_image_generator.flow_from_dataframe(\n    dataframe=dataset_train,\n    x_col='file_name',\n    directory=PATH_TO_PROCESSED_MASK_DIR,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    subset='validation',\n    batch_size=BATCH_SIZE,\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n    color_mode='grayscale'\n    \n\n)\n\n\ntrain_collection=zip(train_image_collection, train_mask_collection)\n\nval_collection=zip(val_image_collection, val_mask_collection)\n\n\ntest_gen=ki.ImageDataGenerator(\n    rescale=1\/255,\n)\n\n\ntest_image_collection=test_gen.flow_from_dataframe(\n    dataframe=dataset_test,\n    x_col='file_name',\n    directory=PATH_TO_IMAGE_DIR,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    subset=None,\n    batch_size=BATCH_SIZE,\n    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)\n\n)\n    \n    ","46f4d320":"image_to_inspect=train_image_collection.next()[0].astype(np.uint8)\nmask_to_inspect=train_mask_collection.next()\n\n\nplt.subplot(1,2,1)\n\nplt.imshow(image_to_inspect)\n\nplt.subplot(1,2,2)\n\nplt.imshow(np.squeeze(mask_to_inspect[0,:,:,:],axis=-1 ),cmap=plt.cm.gray )\n\nplt.show()","5ad1060d":"input_to_model=Input(\n    shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), name=\"input_to_model\"\n    \n                    )\n\nconv0 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',\\\n               name=\"conv0_1_input_layer\")(input_to_model)\n\nconv0 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',\\\n               name=\"conv0_2_input_layer\")(conv0)\n\nconv0 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',\\\n               name=\"conv0_3_input_layer\")(conv0)\n\n# inputs = Input(input_size)\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',\\\n               name=\"conv1_input_layer\")(conv0)\nconv1=BatchNormalization(name=\"conv1_batch_norm\")(conv1)\n\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',\\\n              name=\"conv1_output_layer\")(conv1)\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\nconv2 = BatchNormalization(name=\"conv2_batch_norm\")(conv2)\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\nconv3 = BatchNormalization(name=\"conv3_batch_norm\")(conv3)\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\nconv4 = BatchNormalization(name=\"conv4_batch_norm\")(conv4)\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n\ndrop4 = Dropout(0.5)(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\nconv5 = BatchNormalization(name=\"conv5_batch_norm\")(conv5)\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n\ndrop5 = Dropout(0.5)(conv5)\n\n#############################################\n\ngolbal_average_for_drop4=GlobalAveragePooling2D()(drop4)\n\nfc1_for_drop4=Dense(\n    128, activation='relu', \n)(golbal_average_for_drop4)\n\nfc2_for_drop4=Dense(512, activation='sigmoid')(fc1_for_drop4)\n\n\nmultiply_for_drop4=Multiply()([drop4, fc2_for_drop4])\n\n\n#############################################\n\nup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\nmerge6 = concatenate([multiply_for_drop4,up6], axis = 3)\n\n\n\n\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\nconv6 = BatchNormalization(name=\"conv6_batch_norm\")(conv6)\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n\n#############################################\n\ngolbal_average_for_conv3=GlobalAveragePooling2D()(conv3)\n\nfc1_for_conv3=Dense(\n    128, activation='relu', \n)(golbal_average_for_conv3)\n\nfc2_for_conv3=Dense(256, activation='sigmoid')(fc1_for_conv3)\n\n\nmultiply_for_conv3=Multiply()([conv3, fc2_for_conv3])\n\n\n#############################################\n\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\nmerge7 = concatenate([multiply_for_conv3,up7], axis = 3)\n\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\nconv7 = BatchNormalization(name=\"conv7_batch_norm\")(conv7)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n\n#############################################\n\n# golbal_average_for_conv2=GlobalAveragePooling2D()(conv2)\n\n# fc1_for_conv2=Dense(\n#     6, activation='relu', \n# )(golbal_average_for_conv2)\n\n# fc2_for_conv2=Dense(128, activation='sigmoid')(fc1_for_conv2)\n\n\n# multiply_for_conv2=Multiply()([conv2, fc2_for_conv2])\n\n\n#############################################\n\n\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n# merge8 = concatenate([multiply_for_conv2,up8], axis = 3)\nmerge8 = concatenate([conv2,up8], axis = 3)\n\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\nconv8 = BatchNormalization(name=\"conv8_batch_norm\")(conv8)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n#############################################\n\n# golbal_average_for_conv1=GlobalAveragePooling2D()(conv1)\n\n# fc1_for_conv1=Dense(\n#     32, activation='relu', \n# )(golbal_average_for_conv1)\n\n# fc2_for_conv1=Dense(64, activation='sigmoid')(fc1_for_conv1)\n\n\n# multiply_for_conv1=Multiply()([conv1, fc2_for_conv1])\n\n\n#############################################\n\nup9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n# merge9 = concatenate([multiply_for_conv1,up9], axis = 3)\nmerge9 = concatenate([conv1,up9], axis = 3)\n\n\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\nconv9 = BatchNormalization(name=\"conv9_batch_norm\")(conv9)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\nconv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n\nconv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\nmodel1 = Model(inputs = input_to_model, outputs = conv10)\n\nmodel1.compile(optimizer = keras.optimizers.Adam(lr = 1e-4), loss = 'binary_crossentropy',\\\n               metrics = ['accuracy', ])","a26bf0f3":"keras.utils.plot_model(model1, to_file='model.png', show_shapes=True, show_layer_names=True,\n    )","f716b839":"EarlyStoppingCallback=EarlyStopping(monitor=\"val_acc\",\n    min_delta=1e-3,\n    patience=10,\n    verbose=1,\n    mode=\"max\",\n    baseline=None,\n    restore_best_weights=True,)\n\nModelCheckpointCallback=ModelCheckpoint(filepath=PATH_TO_BEST_MODEL_SAVED,\n    save_weights_only=True,\n    monitor='val_acc',\n    mode='max',\n    save_best_only=True)","50878c26":"history_of_execution=model1.fit(train_collection, epochs=50,  steps_per_epoch=20,\\\n                                validation_data=val_collection, validation_steps=20, \\\n                                validation_batch_size=BATCH_SIZE,\n                                callbacks=[EarlyStoppingCallback, ModelCheckpointCallback],\n#                                 callbacks=[ ModelCheckpointCallback] \n\n                               )\n\n\n ","7c19b975":"%%timeit\npredicted_masks=model1.evaluate(\n   x=val_collection,\n    y=None,\n    batch_size=BATCH_SIZE,\n    verbose=1,\n    sample_weight=None,\n    steps=100,\n    callbacks=[EarlyStoppingCallback],\n    max_queue_size=10,\n    workers=-1,\n    use_multiprocessing=False,\n    return_dict=False,)","990c61be":"test_images=test_image_collection.next()\npredicted_masks=model1.predict(\n    test_images,\n    batch_size=None,\n    verbose=0,\n    steps=None,\n    callbacks=None,\n    max_queue_size=10,\n    workers=1,\n    use_multiprocessing=False,\n)","e8fd9b40":"rand_indx=np.random.randint(BATCH_SIZE)\nplt.subplot(1,2,1)\nplt.imshow(test_images[rand_indx,:,:,:])\nplt.subplot(1,2,2)\nplt.imshow(np.squeeze(predicted_masks[rand_indx,:,:], axis=-1))\nplt.imsave(str(BATCH_SIZE)+\"_\"+str(rand_indx)+\".png\",np.squeeze(predicted_masks[rand_indx,:,:], axis=-1))\n\nplt.show()\n","3d591b80":"test_file=cv2.imread(os.path.join(PATH_TO_IMAGE_DIR,\"216.png\"))\ntest_file=cv2.cvtColor(test_file, cv2.COLOR_BGR2RGB)\nprint(test_file.shape)\ntest_file=cv2.resize(test_file, (IMAGE_WIDTH, IMAGE_HEIGHT))\nprint(test_file.shape)\ntest_file=np.expand_dims(test_file, axis=0)\nprint(test_file.shape)\ntest_file=test_file\/255","7bef5833":"predicted_mask_1=model1.predict(\n    test_file,\n    batch_size=None,\n    verbose=0,\n    steps=None,\n    callbacks=None,\n    max_queue_size=10,\n    workers=1,\n    use_multiprocessing=False,\n)","70e28e05":"plt.subplot(1,2,1)\nplt.imshow(test_file[0,:,:,:])\nplt.subplot(1,2,2)\nplt.imshow(np.squeeze(predicted_mask_1[0,:,:], axis=-1))\n# plt.imsave(str(BATCH_SIZE)+\"_\"+str(rand_indx)+\".png\",np.squeeze(predicted_masks[rand_indx,:,:], axis=-1))\n\nplt.show()","5550b664":"<h2> <font color=\"darkcyan\"> Package Import <\/font><\/h2>","8f4df037":"<h2><font color='darkcyan'>System and Global Variables<\/font><\/h2>","e850f0f6":"<H2> <font color=\"darkcyan\">Data Generator<\/font><\/H2>","78a7e7dc":"##Evaluate","cd4789a5":"<h2><font color=\"darkcyan\">Model Fit with generator<\/font><\/h2>","7e0b542a":"<h2><font color=\"darkcyan\">Model Definition<\/font><\/h2>"}}