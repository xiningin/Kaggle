{"cell_type":{"9bd2d675":"code","5bcd2e9c":"code","026d844e":"code","030c60e4":"code","5279f479":"code","69218770":"code","0032f68e":"code","8db5d353":"code","f96d25d9":"code","4c3ce3dc":"code","bfcb8a2f":"code","175b821b":"code","b92ee577":"code","3497cb90":"code","36c85247":"code","c652e94c":"code","61a258ee":"code","0a42f695":"markdown","3517c462":"markdown","58c4cd4c":"markdown","9cade88d":"markdown","0c481c08":"markdown","1feeb50d":"markdown","e4132a75":"markdown","397ea46e":"markdown","bf9bb7a1":"markdown","3e7e8fff":"markdown","6f1473aa":"markdown","97da2be4":"markdown","cddb131e":"markdown","9370069f":"markdown","c91d98ef":"markdown","7a44a03e":"markdown","04b27404":"markdown"},"source":{"9bd2d675":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tensorflow.keras.preprocessing.image import img_to_array,load_img\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5bcd2e9c":"path= '..\/input\/utkface-new\/UTKFace' \nimg= load_img(path+ \"\/\"+ \"100_1_0_20170110183726390.jpg.chip.jpg\")\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()","026d844e":"x= img_to_array(img) #convert from image to array\nx= np.expand_dims(x, axis=0) \nx\/=255 #Normalization\nprint(\"image shape: \",x.shape)","030c60e4":"file_list = os.listdir(path) #Go path and list files\nprint(\"Number Of \u0130mages: \", len(file_list))\n#Gender\ngender = [i.split('_')[1] for i in file_list]\ngender_labels= [\"Male\",\"Female\"]\n\ngender_classes = []\ny_gender= []\nfor i in gender:\n    i= int(i)\n    if i== 0:\n        gender_classes.append(0)\n    else:\n        gender_classes.append(1)\n    y_gender.append(i)\n    \ngender_classes= np.array(gender_classes)\nprint(\"gender_classes shape: \",gender_classes.shape) \n","5279f479":"x_data=[]\nfor file in file_list:\n    img= cv2.imread(path+'\/'+file)\n    img=cv2.resize(img,(48,48)) # (200,200)--->(48,48)\n    x_data.append(img)\nx_data= np.array(x_data)\nprint(\"x_data shape: \",x_data.shape)","69218770":"#%%Train-Test Split for gender\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x_data,gender_classes,test_size=0.2,\n                                               shuffle=True,random_state=42)\nprint(\"Samples in Training:\",x_train.shape)\nprint(\"Samples in Testing:\",x_test.shape)\n\ny_train= to_categorical(y_train,num_classes=2) #one hot encoding\ny_test= to_categorical(y_test,num_classes=2) #[1,0, ...]---> [[1,0],[0,1], ...]\n\nprint(\"y_train shape: \",y_train.shape)\nprint(\"y_test shape: \",y_test.shape)\n\ninput_shape= x_train.shape[1:] #we don't take the number of samples\nprint(\"input shape: \",input_shape)","0032f68e":"#%% vgg16\nfrom keras.applications.vgg16 import VGG16 \n\nvgg= VGG16(include_top= False,weights=\"imagenet\",input_shape=input_shape)\n\n#include_top=False bencause I'll modify fully connected layers\n# weights='imagenet' because I want the weights used in the imagenet competition\nprint(vgg.summary())","8db5d353":"vgg_layer_list= vgg.layers #I keep the layers in the vgg_layer_list\n\nmodel= Sequential() #I create my model\n\nfor layer in vgg_layer_list: \n    model.add(layer)        # I transfer vgg layers to my model\n\nfor layer in model.layers:\n    layer.trainable= False  #I'll use vgg16 weights so trainable=False\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation=\"relu\"))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(256, activation=\"relu\"))\nmodel.add(layers.Dense(128, activation=\"relu\"))\nmodel.add(layers.Dense(64, activation=\"relu\"))\nmodel.add(layers.Dense(32, activation=\"relu\"))\nmodel.add(layers.Dense(2, activation=\"sigmoid\"))\n\nprint(model.summary())","f96d25d9":"x_val= x_train[14200:]\npartial_x_train=x_train[:14200]\n\ny_val= y_train[14200:]\npartial_y_train=y_train[:14200]","4c3ce3dc":"model.compile(loss=\"binary_crossentropy\",\n              optimizer= optimizers.RMSprop(lr=1e-3),\n              metrics=[\"accuracy\"])","bfcb8a2f":"\n\nhist= model.fit(partial_x_train,partial_y_train,\n                validation_data=(x_val,y_val),\n                epochs=20,\n                batch_size= 64)","175b821b":"#Train and Validation Loss\nplt.plot(hist.history[\"loss\"],label=\"train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"val loss\")\nplt.legend()\nfig1 = plt.gcf() # I create figure because \u0131 want to save\nplt.show()\nplt.draw()\nfig1.savefig('genderclfloss.png')\n\nplt.figure()\n\n##Train and Validation Accuracy\nplt.plot(hist.history[\"accuracy\"],label=\"train acc\")\nplt.plot(hist.history[\"val_accuracy\"],label=\"val acc\")\nplt.legend()\n\nfig2 = plt.gcf()\nplt.show()\nplt.draw()\nfig2.savefig('genderclfacc.png')","b92ee577":"results= model.evaluate(x_test,y_test)\nprint(\"Results: \",results)","3497cb90":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n","36c85247":"model.save(\"model.h5\")\nprint(\"Saved model to disk\")","c652e94c":"model.save_weights(\"model_weights.h5\")","61a258ee":"model.save(\"gender.model\")","0a42f695":"# Gender Classification with Transfer Learning\n1. * Preview to Image\n2. * Process\n3. * Convert Images to Vector and Resize\n4. * Train-Test Split\n5. * VGG16 Architecture\n6. * Transfer VGG-16 Model Layers to Our Model\n7. * Create Validation Set\n8. * Training\n9. * Visualize\n10. * Evaluate Model\n11. * Save Model","3517c462":"This is my first notebook so sorry if I made a mistake. Thanks :)","58c4cd4c":"# Transfer VGG-16 Model Layers to Our Model","9cade88d":"# Save Model","0c481c08":"Images have labels in their names.Since labels (1-Female,0-Male) are separated by underscores, we specify this with the split method.Image Name Labels respectively Age_Gender_Ethnicity....jpg","1feeb50d":"# Train-Test Split","e4132a75":"# Training","397ea46e":"# VGG-16 Architecture","bf9bb7a1":"* Save as json","3e7e8fff":"# Process","6f1473aa":"# Preview to Image","97da2be4":"# Create Validation Dataset","cddb131e":"* Save as weights","9370069f":"# Evaluate to Model","c91d98ef":"# Visualize","7a44a03e":"* Save as h5","04b27404":"# Convert Images to Vector and Resize"}}