{"cell_type":{"da924c24":"code","027db2c6":"code","e77f0a93":"code","4c0f95fc":"code","6394a79a":"code","adacaa19":"code","8fc91adb":"code","e1b175b5":"code","95f396c8":"code","f70325fd":"code","89f0366c":"code","3ff3c867":"code","d10482c6":"code","44b27e27":"code","def413b9":"code","86581244":"code","89e0789b":"code","5123249d":"code","0ca252a2":"code","1bd7591c":"code","cd19e6ad":"code","a8740de6":"markdown","71f29b56":"markdown","a5d60603":"markdown","4cee8ae2":"markdown","5413606f":"markdown","4095043a":"markdown"},"source":{"da924c24":"!pip install pyenchant pysastrawi","027db2c6":"!wget http:\/\/archive.ubuntu.com\/ubuntu\/pool\/main\/libr\/libreoffice-dictionaries\/hunspell-id_6.4.3-1_all.deb\n!dpkg -i hunspell-id_6.4.3-1_all.deb","e77f0a93":"!apt update && apt install -y enchant libenchant1c2a hunspell hunspell-en-us libhunspell-1.6-0","4c0f95fc":"import re\nimport os\nimport gc\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport enchant","6394a79a":"!pip freeze > requirements.txt","adacaa19":"print('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('Scikit-Learn version:', sklearn.__version__)\nprint('Matplotlib version:', matplotlib.__version__)\nprint('Seaborn version:', sns.__version__)\nprint('NLTK version:', nltk.__version__)","8fc91adb":"SEED = 42\n\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)","e1b175b5":"nltk.download('wordnet')","95f396c8":"!ls -lha \/kaggle\/input\n!ls -lha \/kaggle\/input\/student-shopee-code-league-sentiment-analysis","f70325fd":"df_train = pd.read_csv('\/kaggle\/input\/student-shopee-code-league-sentiment-analysis\/train.csv')\ndf_train.sample(10)","89f0366c":"df_train2 = pd.read_csv('\/kaggle\/input\/shopee-reviews\/shopee_reviews.csv')\n\ndef to_int(r):\n    try:\n        return np.int32(r)\n    except:\n        return np.nan\n\ndf_train2['label'] = df_train2['label'].apply(to_int)\ndf_train2 = df_train2.dropna()\ndf_train2['label'] = df_train2['label'].astype(np.int32)\ndf_train2","3ff3c867":"df_test = pd.read_csv('\/kaggle\/input\/student-shopee-code-league-sentiment-analysis\/test.csv')\ndf_test.sample(10)","d10482c6":"X_train = pd.concat([df_train['review'], df_train2['text']], axis=0)\nX_train = X_train.reset_index(drop=True)\ny_train = pd.concat([df_train['rating'], df_train2['label']], axis=0)\ny_train = y_train.reset_index(drop=True)\n\nX_test = df_test['review']","44b27e27":"rating_count = y_train.value_counts().sort_index().to_list()\ntotal_rating = sum(rating_count)\nlowest_rating_count = min(rating_count)\nrating_weight = [lowest_rating_count\/rc for rc in rating_count]\n\nprint(rating_count)\nprint(total_rating)\nprint(rating_weight)","def413b9":"class_weight = np.empty((total_rating,))\nfor i in range(total_rating):\n    class_weight[i] = rating_weight[y_train[i] - 1]","86581244":"from nltk.stem import WordNetLemmatizer\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n\nlemmatizer = WordNetLemmatizer() # for en\nfactory = StemmerFactory() # for id\nstemmer = factory.create_stemmer() # for id\n\ntweet_tokenizer = nltk.tokenize.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n\neng_dict = enchant.Dict('en')\nind_dict = enchant.Dict('id_ID')\n\ndef remove_char(text):\n    text = re.sub(r'[^a-z ]', ' ', text)\n    return text\n\n\ndef stem_lemma(tokens):\n    new_token = []\n    for token in tokens:\n        if eng_dict.check(token):\n            new_token.append(lemmatizer.lemmatize(token))\n        elif ind_dict.check(token):\n            new_token.append(stemmer.stem(token))\n        else:\n            new_token.append(token)\n    return new_token\n\ndef upper_or_lower(tokens):\n    new_token = []\n    for token in tokens:\n        total_lower = len(re.findall(r'[a-z]',token))\n        total_upper = len(re.findall(r'[A-Z]',token))\n        if total_lower == 0 or total_upper == 0:\n            new_token.append(token)\n        elif total_lower > total_upper:\n            new_token.append(token.lower())\n        else:\n            new_token.append(token.upper())\n    return new_token\n    \n\ndef preprocess(X):\n    X = X.apply(tweet_tokenizer.tokenize)\n    X = X.apply(lambda token: [t for t in token if t != ''])\n    X = X.apply(upper_or_lower)\n    X = X.apply(stem_lemma)\n#     X = X.apply(lambda token: ' '.join(token)) # need to join token because sklearn tf-idf only accept string, not list of string\n    \n#     X = X.apply(remove_char)\n    return X","89e0789b":"X_train = preprocess(X_train)\nX_test = preprocess(X_test)","5123249d":"X_train.sample(10)","0ca252a2":"X_train = pd.DataFrame({'X': X_train})\nX_train.to_parquet('X_train.parquet', engine='pyarrow')","1bd7591c":"X_test = pd.DataFrame({'X': X_test})\nX_test.to_parquet('X_test.parquet', engine='pyarrow')","cd19e6ad":"y_train = pd.DataFrame({'y': y_train})\ny_train.to_parquet('y_train.parquet', engine='pyarrow')","a8740de6":"# Preprocess","71f29b56":"# Changelog\n\n### Version 3\n\n* Convert series to dataframe before save to parquet format\n\n### Version 1\n\n* Initialize code","a5d60603":"# Save to parquet","4cee8ae2":"# Dataset","5413606f":"# Library","4095043a":"# Class weight"}}