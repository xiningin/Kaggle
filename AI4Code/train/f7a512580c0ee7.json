{"cell_type":{"cab3ae4d":"code","154686bb":"code","05445690":"code","d2264ede":"code","310fff61":"code","c7678c37":"code","13e4b155":"code","0cc4bca6":"code","3d7f15a0":"code","2969dbd0":"code","a9be66a7":"code","9f7fe03c":"code","75ee9736":"markdown","de2f65e4":"markdown","cc614445":"markdown","aeb39734":"markdown","3f487ff2":"markdown","60d0dd41":"markdown","1f377266":"markdown"},"source":{"cab3ae4d":"!pip install keras-metrics #used for F1 score\nimport keras_metrics as km\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #plotting \nimport matplotlib.patches as patches\nfrom tqdm import tqdm #progress bar\nfrom glob import glob #finds files matching regex \nimport os,imageio,time #for IO, resizing and runtime profiling\nfrom skimage import img_as_ubyte\nfrom skimage.transform import resize\n\nimport keras #keras related\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D\nfrom keras.applications.resnet50 import ResNet50","154686bb":"#Now, let's load the data and split it into training and validation set.\nfiles = pd.read_csv(\"..\/input\/data\/training.csv\")[\"Id\"].values\ntrain_labels = np.asarray(pd.read_csv(\"..\/input\/data\/training.csv\")[\"Expected\"].values)\ntrain_imgs = []\nfor file in tqdm(files):\n    img = img_as_ubyte(resize(imageio.imread(\"..\/input\/data\/training\/\"+file),(112,112))) #read image and resize all images to  112,112 for convenience\n    train_imgs.append(preprocess_input(img)) #normalize images\ntrain_imgs = np.asarray(train_imgs,dtype=\"uint8\")","05445690":"#Plot some examples, the title 1 will indicate the presence of the parasite\nfig = plt.figure(figsize=(8, 5), dpi=100)\nfor idx,file in enumerate(files[:32]):\n    img = img_as_ubyte(resize(imageio.imread(\"..\/input\/data\/training\/\"+file),(112,112)))\n    label = train_labels[idx]\n    ax = fig.add_subplot(4, 8, idx+1, xticks=[], yticks=[])\n    plt.imshow(img)\n    plt.title(str(label))","d2264ede":"#just some network parameters, see above link regarding the layers for details\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\n#dropout is used for regularization here with a probability of 0.3 for conv layers, 0.5 for the dense layer at the end\ndropout_conv = 0.3\ndropout_dense = 0.5\n\n#initialize the model\nsmall_model = Sequential()\n\n#now add layers to it\n\n#conv block 1\nsmall_model.add(Conv2D(first_filters, kernel_size, input_shape = (112, 112, 3)))\nsmall_model.add(BatchNormalization())\nsmall_model.add(Activation(\"relu\"))\nsmall_model.add(Conv2D(first_filters, kernel_size, use_bias=False))\nsmall_model.add(BatchNormalization())\nsmall_model.add(Activation(\"relu\"))\nsmall_model.add(MaxPool2D(pool_size = pool_size)) \nsmall_model.add(Dropout(dropout_conv))\n\n#conv block 2\nsmall_model.add(Conv2D(second_filters, kernel_size, use_bias=False))\nsmall_model.add(BatchNormalization())\nsmall_model.add(Activation(\"relu\"))\nsmall_model.add(Conv2D(second_filters, kernel_size, use_bias=False))\nsmall_model.add(BatchNormalization())\nsmall_model.add(Activation(\"relu\"))\nsmall_model.add(MaxPool2D(pool_size = pool_size))\nsmall_model.add(Dropout(dropout_conv))\n\n#conv block 3\nsmall_model.add(Conv2D(third_filters, kernel_size, use_bias=False))\nsmall_model.add(BatchNormalization())\nsmall_model.add(Activation(\"relu\"))\nsmall_model.add(Conv2D(third_filters, kernel_size, use_bias=False))\nsmall_model.add(BatchNormalization())\nsmall_model.add(Activation(\"relu\"))\nsmall_model.add(MaxPool2D(pool_size = pool_size))\nsmall_model.add(Dropout(dropout_conv))\n\n#a fully connected (also called dense) layer at the end\nsmall_model.add(Flatten())\nsmall_model.add(Dense(256, use_bias=False))\nsmall_model.add(BatchNormalization())\nsmall_model.add(Activation(\"relu\"))\nsmall_model.add(Dropout(dropout_dense))\n\n#finally convert to values of 0 to 1 using the sigmoid activation function\nsmall_model.add(Dense(1, activation = \"sigmoid\"))","310fff61":"#Now, we will compile the model and train it for 5 epochs\nsmall_model.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(0.00075), \n              metrics=['accuracy',km.binary_f1_score()])\nsmall_model.fit(x=train_imgs,y=train_labels,batch_size=50,epochs=5,validation_split=0.05)","c7678c37":"inputs = keras.layers.Input((112, 112, 3)) #declare input shape\nbase_model = ResNet50(include_top=False, input_tensor=inputs, weights='imagenet') #load pretrained model\nx = base_model(inputs) #get resnet output\nout = Flatten()(x) #flatten output\nout = Dropout(0.5)(out) #perform dropout\nout = Dense(1, activation=\"sigmoid\", name=\"out_\")(out) # convert to values of 0 to 1 using the sigmoid activation function\nmodel = keras.models.Model(inputs, out) #define model","13e4b155":"#Now, we will compile the ResNet-50 model and also train it for 5 epochs\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(0.00075), \n              metrics=['accuracy',km.binary_f1_score()])\nmodel.fit(x=train_imgs,y=train_labels,batch_size=50,epochs=5,validation_split=0.05)","0cc4bca6":"#Load test data\nN = 7558\ntest_files = [\"..\/input\/data\/test\/\" + str(idx) + \".png\" for idx in range(N)]\ntest_imgs = []\nfor file in tqdm(test_files):\n    img = img_as_ubyte(resize(imageio.imread(file),(112,112))) #read image and resize all images to  112,112 for convenience\n    test_imgs.append(preprocess_input(img)) #normalize images\ntest_imgs = np.asarray(test_imgs,dtype=\"uint8\")\ntest_files = [file.split(\"test\/\")[1] for file in test_files] #only remember the final name for the submission csv","3d7f15a0":"# Get number of model parameters\nresnet_params = model.count_params() \/ 1e6\nsmall_model_params = small_model.count_params() \/ 1e6\n\nprint(\"ResNet-50: Number of parameters in millions: \",resnet_params)\nprint(\"Small Model: Number of parameters in millions: \",small_model_params)","2969dbd0":"#Infer test data predictions using both models\nfor i in range(3): # we run it thrice to avoid potential overhead during the first run for initializations\n    start = time.time()\n    resnet_preds = model.predict(test_imgs,batch_size = 50,verbose=0)\n    resnet_time = (1000*(time.time() - start) \/ N)\n    print(\"ResNet-50: Inference runtime per image [ms]: \",str(resnet_time))","a9be66a7":"for i in range(3): # we run it thrice to avoid potential overhead during the first run for initializations\n    start = time.time()\n    small_model_preds = small_model.predict(test_imgs,batch_size = 50,verbose=0)\n    small_model_time = (1000*(time.time() - start) \/ N)\n    print(\"Small Model: Inference runtime per image [ms]: \",str(small_model_time))","9f7fe03c":"resnet_submission = pd.DataFrame(data = {\"Id\" : test_files,\n                                  \"Predicted\" : np.round(resnet_preds.squeeze())})\nresnet_submission.Predicted = resnet_submission.Predicted.apply(int) #convert to 0 or 1\nresnet_submission.to_csv(\"resnet_submission.csv\", index = False, header = True)\nresnet_submission.head(5)","75ee9736":"Okay. That already works quite well and, it seems, we can achieve an F1 score of about 0.94-0.95 using this model. Now, let's test the more complex ResNet-50!\n\n<h3>Creating a ResNet-50 model<\/h3>","de2f65e4":"<h3>Training a model<\/h3>\nWe will now define two networks. A simple convolutional neural network as a very fast baseline and a ResNet-50 based one that is a little more involved. We will define two models to demonstrate the idea of this challenges that you not only consider accuracy of the model but also it's runtime and space constraints. For more on details on that check out the [evaluation page](https:\/\/www.kaggle.com\/c\/health-hackers-malaria\/overview\/evaluation).\n\nFor an introduction to the building blocks of neural networks have a look [here](https:\/\/cs231n.github.io\/convolutional-networks\/).\n\nIf you are new to machine learning \/ deep learning, be sure to check out our [learning resources repository](https:\/\/github.com\/healthhackersER\/DeepLearningResources).\n\n<h3>Creating a simple convolutional model<\/h3>\n\nWe will begin with the smaller and simpler model. It will feature 3 convolutional blocks and a fully connected layer in the end. It will use dropout and batch normalization.","cc614445":"<h1>Welcome to the Health Hackers Malaria Challenge!<\/h1>\nThis Kernel will provide you will all the basic necesseties to get started. This Kernel uses Keras. You can, of course, use any framework you want.\n\nIt features:\n* A first look at the data\n* Two rudimentary baselines\n* Example submission and evaluation\n\n<h3>Setup<\/h3>\n\nLet's start by importing all the packages we need.","aeb39734":"<h3>Creating a submission<\/h3>\nFinally, we will now create an examplary submission. Note that you need to have 0 or 1 entries in the submission file not 0.0 or 1.0!","3f487ff2":"Okay, so let's compute the expected scores using the validation ***F1*** results, the number of parameters ***P*** and the measured inference time ***T***:\n\n<h3>Scoring Formula<\/h3>\n$ Score = F1 + 0.025 \\cdot \\frac{0.1}{max(T,0.1)} + 0.025 \\cdot \\frac{1 }{max(P,1)} $\n\n\n<h3>Model Scores<\/h3>\n**ResNet-50** - 23.62 million parameters, inference time of 0.76 ms and and an F1 score of 0.9495\n\n**Small Model** - 3.57 million parameters, inference time of 0.31 ms and and an F1 score of 0.9458\n\nHence\n\nExpected ResNet-50 Score $=  0.9495 + 0.025 * \\frac{0.1}{0.76} + 0.025 * \\frac{1}{23.62} = 0.9538$\n\nExpected Small Model Score $=  0.9458 + 0.025 * \\frac{0.1}{0.31} + 0.025 * \\frac{1}{3.57} = 0.9609$","60d0dd41":"Technically, the goal of this challenge is a binary classification task for images, meaning we want to divide images into two classes. Practically, blood smear images containing either malaria parasites or not with varying resolutions are provided and we should provide a prediction indicating if the images show parasites or not.\n\n20,000 labeled images are provided for training and about 7,500 make up the test set.\n\n<h3>Preparing the data<\/h3>\n\nLet's start by loading the data, resizing all images to a common size and having a look at some of the images.","1f377266":"Okay, so the ResNet-50 gives a very slight improvement in validation F1 score. \n\n<h3>Evaluating the models and predicting on the test data<\/h3>\n\nNow that we have trained both models, let's see how we can create an submission and also, how we can compute the actual evaluation metric which will be used in the end. That metric will rely on model parameters and inference time per image, so let's measure those first! In Keras, this is very straight forward, but can be similarly  easy with other frameworks, just google it. :)\n\nWe will measure the inference time when we compute the predictions on the test data. But first, we need to load and resize the test data"}}