{"cell_type":{"c30ed1e9":"code","47bbaef1":"code","de25057a":"code","9584e8ed":"code","c8790730":"code","0278fc62":"code","2adf6e29":"code","732f4e2a":"code","708f029f":"code","1ee998f5":"code","2fa4a34a":"code","d0b75d50":"code","114a1fda":"code","0a8b5949":"code","8be3fd38":"markdown","4a8fe1d9":"markdown","e0dd12d5":"markdown","4234a36a":"markdown","257ef848":"markdown","424ed563":"markdown","1f9d75a0":"markdown","eca0936c":"markdown","36b6438f":"markdown"},"source":{"c30ed1e9":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('svg')\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\n\ncandidates = pd.read_csv('..\/input\/candidates.csv')","47bbaef1":"candidates.head()","de25057a":"sns.pairplot(\n    x_vars = [\"gpa\"],\n    y_vars = [\"experience\"],\n    data = candidates,\n    hue = \"offer\",\n    height = 5,\n    palette = {0:\"red\", 1:\"green\"}\n)","9584e8ed":"# Scatter plot (same as before)\ng = sns.pairplot(\n    x_vars = [\"gpa\"],\n    y_vars = [\"experience\"],\n    data = candidates,\n    hue = \"offer\",\n    height = 5,\n    palette = {0:\"red\", 1:\"green\"}\n)\n\n# Add Labels, axes\ng.set(\n    xlim = (2.5, 10.5),\n    ylim = (1.5, 10.5),\n    xlabel=\"GPA (X1)\",\n    ylabel=\"Experience (X2)\"\n)\n\n# Plot line\nplt.plot([2, 16], [10, -1])","c8790730":"# Scatter plot (same as before)\ng = sns.pairplot(\n    x_vars = [\"gpa\"],\n    y_vars = [\"experience\"],\n    data = candidates,\n    hue = \"offer\",\n    height = 5,\n    palette = {0:\"red\", 1:\"green\"}\n)\n\n# Add Labels, axes (same as before)\ng.set(\n    xlim = (2.5, 10.5),\n    ylim = (1.5, 10.5),\n    xlabel=\"GPA (X1)\",\n    ylabel=\"Experience (X2)\"\n)\n\ndef draw_the_random_line_with_region():\n    # Draw a random line (say, x + 7y - 45 = 0)\n    x  = np.arange(0, 12, 0.1)\n    y_line = (45 - x) \/ 7\n\n    y_lower = np.zeros(x.shape)        # For Lower box (y = 0)\n    y_upper = 11 * np.ones(x.shape)  # For Upper box (y = 11x)\n\n    plt.plot(x, y_line)\n\n    plt.fill_between(x, y_line, y_lower, color='red', alpha='0.2')\n    plt.fill_between(x, y_line, y_upper, color='green', alpha='0.2')\n    \ndraw_the_random_line_with_region()","0278fc62":"# Get red points in green region, and\n#     green points in red region\nmisclassified_candidates = candidates \\\n    .query(\"\"\"\n        (offer == 0 & (gpa + 7*experience - 45) > 0) | (offer == 1 & (gpa + 7*experience - 45) < 0)\n    \"\"\")\nmisclassified_candidates","2adf6e29":"# Scatter plot (same as before, with `misclassified_candidates`)\ng = sns.pairplot(\n    x_vars = [\"gpa\"],\n    y_vars = [\"experience\"],\n    data = misclassified_candidates,\n    hue = \"offer\",\n    height = 5,\n    palette = {0:\"red\", 1:\"green\"}\n)\n\n# Add Labels, axes (same as before)\ng.set(\n    xlim = (2.5, 10.5),\n    ylim = (1.5, 10.5),\n    xlabel=\"GPA (X1)\",\n    ylabel=\"Experience (X2)\"\n)\n\ndraw_the_random_line_with_region()","732f4e2a":"draw_the_random_line_with_region() # Line before subtraction\nplt.plot(9.1, 8.0, marker = 'o')   # Plot the point\n\nx_hat  = np.arange(0, 12, 0.1)\ny_hat = (45.1 - 0.09 * x_hat) \/ 6.2\nplt.plot(x_hat, y_hat, linestyle=':', color='blue')","708f029f":"X = candidates.as_matrix()[:,[0, 1]]\ny = candidates.as_matrix()[:,[2]]\n\n# Normalize\nX \/= 10\nprint(X[:5])  # Top 5\nprint(y[:5])  # Top 5","1ee998f5":"def step_function(x):\n    \"\"\"Step function\n    \n    Returns 1 if x >= 0\n    Returns 0 if x < 0\n    \n    \"\"\"\n    if x >= 0: return 1\n    return 0\n\nassert(step_function(1) == 1)\nassert(step_function(0) == 1)\nassert(step_function(-5) == 0)","2fa4a34a":"def prediction(X, W, b):\n    \"\"\"Prediction function\n    \n    W = (w1, w2), X = (x1, x2), b\n    \"\"\"\n    product = np.matmul(X, W) + b\n    return step_function(product[0])\n\nprediction(\n    [[0.5, 0.8], [0.3, 0.2]],\n    [[-0.2], [0.5]],\n    [[-0.9]]\n)","d0b75d50":"def perceptron_step(X, y, W, b, learning_rate):\n    for i in range(len(X)):\n        point = X[i]\n        pred = prediction(point, W, b)\n        if y[i] - pred == 1: # y[i] = 1, pred = 0\n            W[0] += point[0] * learning_rate\n            W[1] += point[1] * learning_rate\n            b += learning_rate\n        elif y[i] - pred == -1: # y[i] = 0, pred = 1\n            W[0] -= point[0] * learning_rate\n            W[1] -= point[1] * learning_rate\n            b -= learning_rate\n    return W, b","114a1fda":"def train_perceptron(X, y, learning_rate = 0.01, epochs = 25):\n    W = np.random.rand(2, 1) # [[w1], [w2]]\n    b = np.random.rand(1)\n    \n    lines = []\n    for _ in range(epochs):\n        W, b = perceptron_step(X, y, W, b, learning_rate)\n        lines.append((-W[0] \/ W[1], -b \/ W[1]))\n        \n    return lines","0a8b5949":"np.random.seed(43)\ng = sns.pairplot(\n    x_vars = [\"gpa\"],\n    y_vars = [\"experience\"],\n    data = candidates,\n    hue = \"offer\",\n    height = 5,\n    palette = {0:\"red\", 1:\"green\"}\n)\n\n# Add Labels, axes (same as before)\ng.set(\n    xlim = (2.5, 10.5),\n    ylim = (1.5, 10.5),\n    xlabel=\"GPA (X1)\",\n    ylabel=\"Experience (X2)\"\n)\n\n# Train Perceptron\nlines = train_perceptron(X, y, epochs=25)\n\n# Draw all the lines\nlines_draw = []\nfor line in lines:\n    x_points = np.arange(0, 12, 0.1)\n    y_points = line[0][0] * x_points + line[1][0] * 10\n    lines_draw.append((x_points, y_points))\n\nfor line in lines_draw[:-1]:\n    plt.plot(line[0], line[1], linestyle=':', color='blue', alpha=0.3)\n    \n# Draw the final line\nlast = lines_draw[-1]\nplt.plot(last[0], last[1], linestyle='-', color='blue')","8be3fd38":"**Draw a scatter plot**\n\n* **X-axis** - GPA\n* **Y-axis** - Years of experience\n* **Colors**\n    * **Red**   - Reject\n    * **Green** - Accept","4a8fe1d9":"Equation of the line passing through points `(2, 16)`, `(10, -1)` can be calculated as,\n\n$$\n\\frac{y - y_1}{x - x_1} = \\frac{y_2 - y_1}{x_2 - x_1}\n$$\n\n$$\n\\frac{y - 16}{x - 2} = \\frac{-17}{8}\n$$\n\n$$\n17x + 8y - 162 = 0\n$$\n\nIn terms of $x_1$ and $x_2$,\n\n$$\n17x_1 + 8x_2 - 162 = 0\n$$\n\nWe can use this equation to determine whether a new candidate would be offered an interview or not. Consider the left part of the equation as `Score`\n\n**Score**\n\n`Score = (17 * GPA) + (8 * Experience) - 162`\n\n**Prediction**\n\n* `Score > 0` - **<span style=\"color:green\">Accept<\/span>**\n* `Score < 0` - **<span style=\"color:red\">Reject<\/span>**\n\n### Modelling\n\n**Boundary Line**\n\n$$\nw_1 x_1 + w_2 x_2 + b = 0\n$$\n\nIn terms of vectors,\n\n$$\nWx + b = 0\n$$\n\nwhere,\n\n$$\nW = (w_1, w_2),\nx = (x_1, x_2),\ny = \"0\" or \"1\"\n$$\n\n**Prediction**\n\n$$\n\\hat{y} =\n\\left\\{\n\\begin{array}{ll}\n1 & \\mbox{if $Wx + b \\geq 0$},\\\\\n0 & \\mbox{if $Wx + b \\lt 0$},\\\\\n\\end{array}\n\\right.\n$$\n\n## Perceptron\n\nThe equation `Score = (17 * GPA) + (8 * Experience) - 162` can be modelled as a **Perceptron**. Following diagram represents the model visualization\n\n![Perceptron - Candidate](https:\/\/raw.githubusercontent.com\/nowke\/notebooks\/master\/perceptron-candidate.png)\n\nIn the case of Candidate selection, only 2 dimensions (GPA, Experience) are considered for decision. We can extend to `N` dimensions using perceptron model\n\n![Perceptron - general](https:\/\/raw.githubusercontent.com\/nowke\/notebooks\/master\/perceptron-general.png)\n\n### Step function\n\nFor calculating `y`, we use the following function knows as **Step function**\n\n$$\ny =\n\\left\\{\n\\begin{array}{ll}\n1 & \\mbox{if $x\\geq 0$},\\\\\n0 & \\mbox{if $x \\lt 0$},\\\\\n\\end{array}\n\\right.\n$$\n\n![Step function](https:\/\/raw.githubusercontent.com\/nowke\/notebooks\/master\/perceptron-step.png)\n\n### Perceptron trick\n\nHow do we actually let the computer calculate equation of the line? It can be achieved using the following abstract algorithm\n\n```\n1  Draw a random line\n2  Get all mis-classified points\n3  Improve the line using the mis-classified points\n4  Repeat 2-3 for n times or until satisfactory result\n```","e0dd12d5":"A line can be easily drawn to separate **Red** and **Green** dots. Let's draw a line with points determined from naked eye. Also, label **GPA** as `x1` and **Experience** as `x2`.","4234a36a":"Let's plot only the misclassified points","257ef848":"## Linear classification - Perceptron\n\nConsider a simple classification problem of whether or not a candidate's profile is accepted for a job interview.\n\n**Problem Statement**\n\n> HR of company ABC decides whether or not to give a chance for the job interview. For simplicity, only two parameters are considered - **GPA** and **year of experience**. A dataset of GPA, year of experience and decision (True or False) is provided in `candidates.csv`.\n\n### Preview dataset","424ed563":"In order to move the line **closer** to the point,\n\n* **For red point in green region** -> *Subtract* `(p1, p2, 1)` from the line coefficients `(a, b, c)`\n* **For green point in red region** -> *Add*      `(p1, p2, 1)` from the line coefficients `(a, b, c)`\n\nBut to avoid biasing, we add\/subtract only a fraction of the point, known as **Learning rate**. \n\nLet `learning_rate = 0.1`\n\nFor example, consider a red point in green region - `(9.1, 8.0)`\n\nWe subtract `(9.1, 8.0, 1) x 0.1 = (0.91, 0.8, 0.1)` \n\n```\n       1     7     -45\n-   0.91   0.8     0.1\n------------------------\n    0.09   6.2     -45.1\n------------------------\n```\n\nBut, \n\nNew line is `0.09x + 6.2y - 45.1 = 0`\n\nLet's plot the line before (solid) and after (dotted) subtraction","1f9d75a0":"### Perceptron algorithm\n\nUsing the **Perceptron trick**, Perceptron algorithm can be written as follows\n\n```\nPERCEPTRON_ALGORITHM()\n\n1   Initialize the line with random weights: w1, w2 ... wn, b\n2   For each misclassified point (x1, x2 ..., xn) do\n3       if prediction == 0:\n4           Wi = Wi + xi * learning_rate\n5           b  = b + learning_rate\n6       else if prediction == 1:\n7           Wi = Wi - xi * learning_rate\n8           b  = b - learning_rate\n```\n\nTo implement the perceptron algorithm, the following are the building blocks\n\n* Step function\n* Prediction function\n* Perceptron step\n* Perceptron training\n\nFirst, get `X` and `y`","eca0936c":"#### Step function","36b6438f":"The **blue** line is generated by the **Perceptron algorithm**"}}