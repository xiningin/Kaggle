{"cell_type":{"b51ab151":"code","92844491":"code","bb60560a":"code","10c2028f":"code","db9e0c9a":"code","6546e3d0":"code","a47404ce":"code","d38df16b":"code","2cc1135c":"code","7f933489":"code","cc231179":"code","ad14163e":"code","a167181c":"code","e020eedd":"code","84272f14":"code","aace6658":"code","12b66ec1":"code","e562513d":"code","fc405894":"code","96e96e50":"code","e3be8ccd":"code","8c4cda24":"code","9d82ec77":"code","853b809c":"code","e229ac7e":"code","dc2f565c":"code","ba9d1ae2":"code","6a14e584":"code","edcea74f":"code","998073bc":"code","bcd78f63":"code","1ee60636":"code","5878dcac":"code","cc33230d":"code","1f04013f":"code","e878ed3f":"code","2e5ca5a3":"markdown","6acbd642":"markdown","5fd3ef3b":"markdown","f6500fe8":"markdown","33c8b827":"markdown","7ac2bc58":"markdown","6cc219fc":"markdown","412a3333":"markdown","0524ea2d":"markdown","e1687f3b":"markdown","9b41442f":"markdown","8c13fdb5":"markdown","2a8ece34":"markdown","03c8715f":"markdown","b63ae665":"markdown","d1875db6":"markdown","fa517b64":"markdown","31b9fee6":"markdown","9db66993":"markdown"},"source":{"b51ab151":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92844491":"df=pd.read_csv(\"..\/input\/glass\/glass.csv\")","bb60560a":"df.head()","10c2028f":"#checking data type and null values\ndf.info()","db9e0c9a":"#checking null values\ndf.isna().sum()","6546e3d0":"#checking Over of data distribution\ndf.describe()","a47404ce":"sns.countplot(x=df['Type'])","d38df16b":"sns.pairplot(df)","2cc1135c":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),annot=True,cmap=\"coolwarm\")","7f933489":"# Separating Features and Label\nx=df.drop(columns=['Type'])\ny=df['Type']","cc231179":"# splitting dataset in train data and test data\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=4)","ad14163e":"# as accuracy is very less we use scalling\nfrom sklearn.preprocessing import StandardScaler\nscale=StandardScaler()\nscale_xtrain=scale.fit_transform(xtrain)\nscale_xtest=scale.fit_transform(xtest)","a167181c":"# training and fitting model\nfrom sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nmodel.fit(scale_xtrain,ytrain)\nypred=model.predict(scale_xtest)","e020eedd":"# Evaluation of Model\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nlg_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy Score is:\",lg_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","84272f14":"# training and fitting model\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel=KNeighborsClassifier()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","aace6658":"# Evaluation of Model\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nknn_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy Score is:\",knn_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))\nplt.ylabel('actual label')\nplt.xlabel('predicted label')\n\nplt.show()","12b66ec1":"# training and fitting model\nfrom sklearn.svm import SVC\nmodel=SVC(kernel=\"linear\")\nmodel.fit(scale_xtrain,ytrain)\nypred=model.predict(scale_xtest)","e562513d":"# Evaluation of Model\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nsvc_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy is:\",svc_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","fc405894":"# training and fitting model\nfrom sklearn.naive_bayes import GaussianNB\nmodel=GaussianNB()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","96e96e50":"# Evaluation of Model\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nGNB_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy is:\",GNB_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","e3be8ccd":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","8c4cda24":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nDt_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy is:\",Dt_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","9d82ec77":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(n_estimators=20)\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","853b809c":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nRFC_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy is:\",RFC_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","e229ac7e":"from sklearn.ensemble import GradientBoostingClassifier\nmodel=GradientBoostingClassifier()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","dc2f565c":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nGBC_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy is:\",GBC_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","ba9d1ae2":"from sklearn.ensemble import AdaBoostClassifier\nmodel=AdaBoostClassifier(n_estimators=5)\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","6a14e584":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nABC_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy is:\",ABC_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","edcea74f":"from xgboost import XGBClassifier\nmodel=XGBClassifier()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","998073bc":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nXGB_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy is:\",XGB_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","bcd78f63":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nmodels=[\n    #(\"lr\",LogisticRegression()),\n    (\"knn\",KNeighborsClassifier(n_neighbors=5)),\n    (\"GNB\",GaussianNB()),\n    (\"RF\",RandomForestClassifier(n_estimators=50)),\n    ('ABC',AdaBoostClassifier(n_estimators=50)),\n    ('GBC',GradientBoostingClassifier(n_estimators=50)),\n    ('SVM',SVC(C=0.1,probability=True))\n]","1ee60636":"# # training and fitting model\nfrom sklearn.ensemble import VotingClassifier\nmodel=VotingClassifier(estimators=models,voting=\"soft\")\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","5878dcac":"# Evaluation of Model\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nvoting_acc=accuracy_score(ytest,ypred)\nprint(\"Accuracy is:\",voting_acc)\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(classification_report(ytest,ypred))","cc33230d":"models=[(\"LogisticRegression\",lg_acc),\n    (\"KNeighborsClassifier\",knn_acc),\n        (\"SVM\",svc_acc),\n        (\"DecisionTree\",Dt_acc),\n        (\"GuessinNB\",GNB_acc),\n        (\"RanodmForest\",RFC_acc),\n        (\"Gradientboost\",GBC_acc),\n        (\"AdaBoost\",ABC_acc),\n        (\"XGboost\",XGB_acc),\n        (\"Voting\",voting_acc)\n]","1f04013f":"predict = pd.DataFrame(data = models, columns=['Model', \"Accuracy\"])\npredict","e878ed3f":"# plogttin bargraph of r2score of each model\nf, axe = plt.subplots(1,1, figsize=(15,10))\npredict.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n\nsns.barplot(x='Accuracy', y='Model', data = predict, ax = axe)\naxe.set_xticks(np.arange(0, 1.1, 0.1))\nplt.show()","2e5ca5a3":"## 4.3 SVC Support Vector Classifier","6acbd642":"# 5. Accuracy of different Model","5fd3ef3b":"# 6. Conclusion\nIn this activity I have explored the different classification models. Then visulized and measured performance of models.","f6500fe8":"## 4.8 AdaBoost Classifier","33c8b827":"## 4.2 KNN  (k-nearest neighbors)","7ac2bc58":"# 3. Data Visulization","6cc219fc":"## 4.4 Naive Byes","412a3333":"## 4.9 XG Boost Classifier","0524ea2d":"### This  graph clearly shows the XGboost model gives higher accuracy compare to other model.","e1687f3b":"## 4.6 Random Forest Classifier","9b41442f":"# Dataset Loading","8c13fdb5":"<center>                               ****** END******  <center>","2a8ece34":"From above graph <br>\nPositive corelated column: Ca-Rl<br>\nNegative corelated column: mg-Type","03c8715f":"## 4.7 Gradient Boosting Classifier","b63ae665":"## 4.5 Decision Tree Classifier","d1875db6":"# 2.Data Preprocessing","fa517b64":"# 4.Classification Models","31b9fee6":"## 4.1 Logistic Regression","9db66993":"## 4.10 Voting"}}