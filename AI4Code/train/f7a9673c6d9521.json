{"cell_type":{"c02e0ba1":"code","651abebf":"code","674ea4e5":"code","bb81fe3c":"code","4abf3791":"code","aafeba6c":"code","b375dc73":"code","c38a6de3":"code","5dcdb849":"code","fef13338":"code","e5f14e6f":"code","8a018b07":"code","43a19722":"code","aa9ad36c":"code","7aa2e42c":"code","958ff3cf":"code","1ebedabe":"code","af34354f":"code","862d2e45":"markdown","26f70700":"markdown","5028e711":"markdown","b539968d":"markdown","df740564":"markdown","c20cd7fb":"markdown","4e43191f":"markdown","8eee38eb":"markdown","1831dcb2":"markdown","4fc84258":"markdown","8f2d8d58":"markdown","8568e22f":"markdown","321cc227":"markdown","00179c91":"markdown","ca66266e":"markdown","2bc4a281":"markdown","c8f79c8c":"markdown","45175e82":"markdown","039f9f6b":"markdown"},"source":{"c02e0ba1":"import pandas as pd\nfrom tqdm import tqdm\nimport albumentations as A\nimport numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","651abebf":"# https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","674ea4e5":"## adding the center of each bbox\ndf = pd.read_csv('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv')\ndf['x_center'] = (df['x_min'] + df['x_max'])\/2\ndf['y_center'] = (df['y_min'] + df['y_max'])\/2","bb81fe3c":"def drawBBoxOnImage(img, bboxes):\n    for i, box in enumerate(bboxes):\n        cv2.rectangle(img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), [0,0,0], 3)\n    return img","4abf3791":"bbox = df[df.image_id=='0108949daa13dc94634a7d650a05c0bb'].iloc[0][['x_min','y_min', 'x_max', 'y_max']]","aafeba6c":"bboxes = [list(bbox)]","b375dc73":"def getOrigImage():\n    img = read_xray('..\/input\/vinbigdata-chest-xray-abnormalities-detection\/train\/0108949daa13dc94634a7d650a05c0bb.dicom')\n    bbox = df[df.image_id=='0108949daa13dc94634a7d650a05c0bb'].iloc[0][['x_min','y_min', 'x_max', 'y_max']].astype(int)\n    img = cv2.imwrite('.\/test_img.jpg', img)\n    img = cv2.imread('.\/test_img.jpg')\n    return img, bbox","c38a6de3":"def plotBBoxLevelAug(imgs, subTitles, cols = 4, size = 7, scale=4, cmap='gray'):\n    rows = 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img is not None:\n            img = cv2.resize(img, None, fx=1\/scale, fy=1\/scale)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n        plt.title(subTitles[i])\n    plt.show()","5dcdb849":"configDict = {'CoarseDropout' : {\"p\":1, \"max_holes\":30},\n'Blur' : {'p': 1},\n'Clahe' : {'p':1},\n'ColorJitter' : {'brightness':0.4, 'contrast':0.4, 'saturation':0.4, 'hue':0.4, 'p':1},\n'Cutout' : {'p':1},\n'Equalize' : {'p':1},\n}\n","fef13338":"bboxAugmentations = {\n    'CoarseDropout': lambda dic: A.CoarseDropout(**dic)(image=img[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']])['image'],\n    'Blur': lambda dic: A.Blur(**dic)(image=img[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']])['image'],\n    'ColorJitter': lambda dic: A.ColorJitter(**dic)(image=img[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']])['image'],\n    'Clahe': lambda dic: A.CLAHE(**dic)(image=img[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']])['image'],\n    'Cutout': lambda dic: A.Cutout(**dic)(image=img[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']])['image'],\n    'Equalize': lambda dic: A.Equalize(**dic)(image=img[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']])['image']\n}\n\n\n    ","e5f14e6f":"def applyAugOnBBox(img, bbox, augType):\n    imgCopyWithAug = img.copy()\n    bbox = bbox.astype(int)\n    bboxImg = img[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']]\n    augmentedBBox = bboxAugmentations[augType](configDict[augType])\n    imgCopyWithAug[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']] = augmentedBBox\n    plotBBoxLevelAug([img, bboxImg, augmentedBBox, imgCopyWithAug], ['Original Image', 'bboxImage','augmented bbox', 'bbox augmentaion merged with image'])\n    ","8a018b07":"img, bbox = getOrigImage()","43a19722":"applyAugOnBBox(img, bbox, 'Clahe')","aa9ad36c":"applyAugOnBBox(img, bbox, 'CoarseDropout')","7aa2e42c":"applyAugOnBBox(img, bbox, 'Blur')","958ff3cf":"applyAugOnBBox(img, bbox, 'ColorJitter')","1ebedabe":"applyAugOnBBox(img, bbox, 'Cutout')","af34354f":"applyAugOnBBox(img, bbox, 'Equalize')","862d2e45":"Equalize the image histogram.","26f70700":"\nExample of transformation on data from the author:\n\nFrom the Paper![image.png](attachment:image.png)\n\n","5028e711":"# Reading Dicom Images Correctly","b539968d":"Blur the input image using a random-sized kernel.","df740564":"CoarseDropout of the square regions in the image.","c20cd7fb":"**If you have reached here then thanks for your time!!**","4e43191f":"I have added few other transformation as below, will soon add the operations by the author also.","8eee38eb":"Randomly changes the brightness, contrast, and saturation of an image.","1831dcb2":"**CLAHE:** Contrast Limited Adaptive Histogram Equalization to the input image","4fc84258":"A short note about the paper:\n\n1. The paper aimed to learn the data augmentation policy from a COCO training set and verify if the similar policies can be transferred to other data sets for increasing mAP score for object detection.\n2. They used validation set accuracy to seach for novel object detection augmentation policy.\n3. Examples of these policy:\n\n    1. (Color, 0.2, 8), (Rotate, 0.8, 10)\n    2. (BBox Only ShearY, 0.8, 5)\n    3. (SolarizeAdd, 0.6, 8), (Brightness, 0.8, 10)\n    4. (ShearY, 0.6, 10), (BBox Only Equalize,0.6, 8)\n    5. (Equalize, 0.6, 10), (TranslateX, 0.2, 2)\n","8f2d8d58":"# Reading the csv File","8568e22f":"# Get Sample Image And BBox\n","321cc227":"# Plotting BBox Augmented Samples","00179c91":"7. **In the paper the authors have used following BBox_only operation:**\n\n    1. policy(name='Translate_Y_BBox', probability=0.6, magnitude=6)\n    \n    2. policy(name='Shear_X_BBox', probability=0.8, magnitude=4)\n    \n    3. policy(name='Shear_Y_BBox', probability=0.8, magnitude=2)\n    \n    4. policy(name='Fliplr_BBox', probability=0.0, magnitude=10)\n    \n    5. policy(name='Cutout_BBox', probability=0.4, magnitude=6)","ca66266e":"# BBox Level Augmentations","2bc4a281":"6. The result of applying these policies is as follows:\n    1. The bbox only operation provides an increase of 0.4 mAP.\n        From the Paper![image.png](attachment:image.png)\n\n\n","c8f79c8c":"The aim of this notebook is to show some samples of augmentation on bbox level as opposed to entire image. The idea was taken from the paper [Learning Data Augmentation Strategies for Object Detection](https:\/\/arxiv.org\/pdf\/1906.11172.pdf). ","45175e82":"4. (Rotate, 0.8, 10): \n\n    1. Rotate: Name of the transformation\n    2. 0.8: probability with which to apply transformation\n    3. 10: Magnitute of the transformation.\n    \n    \n5. The complete list of transformation applied were classified into 3 categories:\n\n    1. **Color operations:** Distort color channels like Equalize, Contrast etc.\n    2. **Geomertic Operation:** Rotate, Shear etc.\n    3. **Bounding Box Operations:** BBox_Only_Equalize, BBox_only_Rotate etc.","039f9f6b":"**CoarseDropout**: Dropping rectangular regions in the image and filling them with 0."}}