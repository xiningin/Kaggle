{"cell_type":{"90eadd58":"code","4cbd64b3":"code","ea2fd728":"code","54738c7c":"code","be934f4d":"code","d4eb0660":"code","3a16ac47":"code","dd8a9fe5":"code","d1e08b59":"code","437cca75":"code","328ef523":"code","19873d6f":"code","9c5cb4c7":"code","0bb999d3":"code","79ddb934":"markdown","7210182e":"markdown","fe4b90c3":"markdown","2239f314":"markdown"},"source":{"90eadd58":"!pip install ..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\/ > \/dev\/null # no output\n!pip install torch_optimizer --no-index --find-links=file:\/\/\/kaggle\/input\/torch-optimizer\/torch_optimizer","4cbd64b3":"import os\nimport gc\ngc.enable()\nimport sys\nimport math\nimport json\nimport time\nimport random\nfrom glob import glob\nfrom datetime import datetime\n\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport multiprocessing\nfrom sklearn.preprocessing import LabelEncoder\n\nimport torch\nimport torchvision\nfrom torch import Tensor\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.nn.parameter import Parameter\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\nfrom tqdm import tqdm\n\nimport efficientnet_pytorch\n\nimport torch_optimizer as optim\nimport albumentations as A\n\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ea2fd728":"IN_KERNEL = os.environ.get('KAGGLE_WORKING_DIR') is not None\nBATCH_SIZE = 64\nNUM_WORKERS = multiprocessing.cpu_count()\nMAX_STEPS_PER_EPOCH = 15000\nNUM_EPOCHS = 3\nLOG_FREQ = 10\nNUM_TOP_PREDICTS = 1","54738c7c":"train = pd.read_csv('..\/input\/landmark-recognition-2021\/train.csv')\ntrain_dir = '..\/input\/landmark-recognition-2021\/train\/'","be934f4d":"class ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe: pd.DataFrame, image_dir:str, mode: str):\n        self.df = dataframe\n        self.mode = mode\n        self.image_dir = image_dir\n        \n        transforms_list = []\n        if self.mode == 'train':\n            transforms_list = [\n                transforms.Resize((64,64)),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomChoice([\n                    transforms.RandomResizedCrop(64),\n                    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n                    transforms.RandomAffine(degrees=15, translate=(0.2, 0.2),\n                                            scale=(0.8, 1.2), shear=15,\n                                            resample=Image.BILINEAR)\n                ]),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                      std=[0.229, 0.224, 0.225]),\n            ]\n        else:\n            transforms_list.extend([\n                # Keep this resize same as train\n                transforms.Resize((64,64)),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                      std=[0.229, 0.224, 0.225]),\n            ])\n        self.transforms = transforms.Compose(transforms_list)\n\n    def __getitem__(self, index: int):\n        image_id = self.df.iloc[index].id\n        image_path = f\"{self.image_dir}\/{image_id[0]}\/{image_id[1]}\/{image_id[2]}\/{image_id}.jpg\"\n        image = Image.open(image_path)\n        image = self.transforms(image)\n\n        if self.mode == 'test':\n            return {'image':image}\n        else:\n            return {'image':image, \n                    'target':self.df.iloc[index].landmark_id}\n\n    def __len__(self) -> int:\n        return self.df.shape[0]","d4eb0660":"def load_data(train, train_dir):\n    print('Original train_df size:', train.shape)     \n    counts = train.landmark_id.value_counts()\n    \n    num_samples=10\n    num_classes = 30000\n    print(f'Select train data from top {num_classes} classes, {num_samples} samples of each class')\n    x=[]\n    y=[]\n    \n    for k,landmark_id in enumerate(tqdm(counts.index[:num_classes])):\n        x.extend(train[train['landmark_id']==landmark_id]['id'].sample(n=num_samples, random_state=1,replace=True).values)\n        y.extend([landmark_id]*num_samples)\n    train=pd.DataFrame({'id':x,'landmark_id':y})\n    print('Filtered train_df size:', train.shape)\n\n    #Encode target labels with value between 0 and n_classes-1\n    label_encoder = LabelEncoder() \n    label_encoder.fit(train.landmark_id.values)\n    \n    #Check if the number of the classes are ok\n    assert len(label_encoder.classes_) == num_classes \n\n    train.landmark_id = label_encoder.transform(train.landmark_id)\n\n    train_dataset = ImageDataset(train, train_dir, mode='train')\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True,\n                              num_workers=NUM_WORKERS,\n                              drop_last=True)\n\n    return train_loader, label_encoder, num_classes","3a16ac47":"def radam(parameters, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n    if isinstance(betas, str):\n        betas = eval(betas)\n    return optim.RAdam(parameters,\n                      lr=lr,\n                      betas=betas,\n                      eps=eps,\n                      weight_decay=weight_decay)","dd8a9fe5":"class AverageMeter:\n    ''' Computes and stores the average and current value '''\n    def __init__(self) -> None:\n        self.reset()\n\n    def reset(self) -> None:\n        self.val = 0.0\n        self.avg = 0.0\n        self.sum = 0.0\n        self.count = 0\n\n    def update(self, val: float, n: int = 1) -> None:\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count","d1e08b59":"def GAP(predicts: torch.Tensor, confs: torch.Tensor, targets: torch.Tensor) -> float:\n    ''' Simplified GAP@1 metric: only one prediction per sample is supported '''\n    assert len(predicts.shape) == 1\n    assert len(confs.shape) == 1\n    assert len(targets.shape) == 1\n    assert predicts.shape == confs.shape and confs.shape == targets.shape\n\n    _, indices = torch.sort(confs, descending=True)\n\n    confs = confs.cpu().numpy()\n    predicts = predicts[indices].cpu().numpy()\n    targets = targets[indices].cpu().numpy()\n\n    res, true_pos = 0.0, 0\n\n    for i, (c, p, t) in enumerate(zip(confs, predicts, targets)):\n        rel = int(p == t)\n        true_pos += rel\n\n        res += true_pos \/ (i + 1) * rel\n\n    res \/= targets.shape[0] # FIXME: incorrect, not all test images depict landmarks\n    return res","437cca75":"class EfficientNetEncoderHead(nn.Module):\n    def __init__(self, depth, num_classes):\n        super(EfficientNetEncoderHead, self).__init__()\n        self.depth = depth\n        self.base = efficientnet_pytorch.EfficientNet.from_name(f'efficientnet-b{self.depth}')\n        pretrained_file = glob(f'..\/input\/efficientnet-pytorch\/efficientnet-b{self.depth}*')[0]\n        checkpoint = torch.load(pretrained_file)\n        self.base.load_state_dict(checkpoint)\n        \n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.output_filter = self.base._fc.in_features\n        self.classifier = nn.Linear(self.output_filter, num_classes)\n        \n    def forward(self, x):\n        x = self.base.extract_features(x)\n        x = self.avg_pool(x).squeeze(-1).squeeze(-1)\n        x = self.classifier(x)\n        return x","328ef523":"def train_step(train_loader, \n          model, \n          criterion, \n          optimizer,\n          epoch, \n          lr_scheduler):\n    print(f'epoch {epoch}')\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    avg_score = AverageMeter()\n\n    model.train()\n    num_steps = min(len(train_loader), MAX_STEPS_PER_EPOCH)\n\n    print(f'total batches: {num_steps}')\n\n    end = time.time()\n    lr = None\n\n    for i, data in enumerate(train_loader):\n        input_ = data['image']\n        target = data['target']\n        batch_size, _, _, _ = input_.shape\n        \n        output = model(input_.cuda())\n        loss = criterion(output, target.cuda())\n        confs, predicts = torch.max(output.detach(), dim=1)\n        avg_score.update(GAP(predicts, confs, target))\n        losses.update(loss.data.item(), input_.size(0))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        lr = optimizer.param_groups[0]['lr']\n        \n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % LOG_FREQ == 0:\n            print(f'{epoch} [{i}\/{num_steps}]\\t'\n                    f'time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                    f'loss {losses.val:.4f} ({losses.avg:.4f})\\t'\n                    f'GAP {avg_score.val:.4f} ({avg_score.avg:.4f})'\n                    + str(lr))\n\n    print(f' * average GAP on train {avg_score.avg:.4f}')","19873d6f":"if __name__ == '__main__':\n    print(\"A\")\n    train_loader, label_encoder, num_classes = load_data(train, train_dir)\n    \n    print(\"B\")\n    model = EfficientNetEncoderHead(depth=0, num_classes=num_classes)\n    \n    print(\"C\")\n    model.cuda()\n    \n    print(\"D\")\n    criterion = nn.CrossEntropyLoss()\n    \n    print(\"E\")\n    optimizer = radam(model.parameters(), lr=1e-3, betas=(0.9,0.999), eps=1e-3, weight_decay=1e-4)\n    \n    print(\"F\")\n    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*NUM_EPOCHS, eta_min=1e-6)\n    \n    print(\"G\")\n    for epoch in range(1, NUM_EPOCHS + 1):\n        print('-' * 50)\n        train_step(train_loader, model, criterion, optimizer, epoch, scheduler)","9c5cb4c7":"np.save('classes.npy', label_encoder.classes_)","0bb999d3":"torch.save(model.state_dict(), \"new_weight_efficientnet.pth\")","79ddb934":"# Train model","7210182e":"# Save classes of the label_encoder","fe4b90c3":"# Introduction\nThis notebook generates the trained model for https:\/\/www.kaggle.com\/hdsk38\/pytorch-starter-inference-efficientnet, which should give Public Score 0.003. Many codes are forked from https:\/\/www.kaggle.com\/rhtsingh\/pytorch-training-inference-efficientnet-baseline. Thank you [\ntorch](https:\/\/www.kaggle.com\/rhtsingh)!\n\nSince the train data is big (1,580,470 images!!), I filtered the train data by selecting 10 images from each of the top 30,000 classes (out of 81,313 classes). Only 3 epochs were implemented in order to finish the training within a couple of hours. I hope this notebook will help you to join this competition :) !","2239f314":"# Save model weights"}}