{"cell_type":{"17362688":"code","a20f9413":"code","a045f059":"code","dc7948d8":"code","cd81a20b":"code","3fcc07b7":"code","b5a07f81":"code","cff9e3bb":"code","09016851":"code","545942d0":"code","79630c25":"code","5a696ac4":"code","19aae6f3":"code","eb91f16e":"code","4a519fbb":"code","978c58af":"code","6e2ab04f":"code","1c948c79":"code","db4aff1a":"code","4dd5e551":"code","e5879cf3":"code","67edfae4":"code","cb2be11d":"code","30f3f630":"code","77dce361":"code","c34eee59":"code","05b5a118":"code","9f53f803":"code","19071967":"code","86561754":"code","6aaeaf37":"markdown","ddd70707":"markdown","6c2b84d0":"markdown","76d9373d":"markdown","378c2eb1":"markdown","ffd45429":"markdown","3a0a3583":"markdown","e20e1a29":"markdown","7e895024":"markdown","97f6b654":"markdown","df738872":"markdown","8fd8f6ec":"markdown","4e357cc1":"markdown","c03fba0a":"markdown","98d45c8b":"markdown","9f2757f9":"markdown","bb45705d":"markdown","471a3be8":"markdown","42ccff4a":"markdown","ab640f66":"markdown","9089bb22":"markdown","bf7619a9":"markdown","d74f1e5c":"markdown","95d93dae":"markdown","853f944d":"markdown","3a95f545":"markdown","f47fd2e2":"markdown","09cbb2fd":"markdown","b3376ab9":"markdown","875ac423":"markdown","5de15856":"markdown","374bd289":"markdown"},"source":{"17362688":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport plotly.express as px\nfrom IPython.core.display import display, HTML, Javascript\nfrom plotly.offline import download_plotlyjs,init_notebook_mode\ninit_notebook_mode(connected=True)","a20f9413":"data_o = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndata_o.head(8)","a045f059":"data = data_o.drop(\"id\",axis=1)\ndata.info()","dc7948d8":"data[\"bmi\"].fillna(data[\"bmi\"].mean(),inplace=True)\ndata.isna().sum()","cd81a20b":"data.describe()","3fcc07b7":"plt.figure(figsize=(15,10))\ncorr = data.corr()\nsns.heatmap(corr,cmap = 'viridis',annot=True,fmt=\".2f\",vmin=-1,vmax=1,linewidths=0.2)","b5a07f81":"fig = plt.figure(figsize=(20,5))\nuncat_data = [\"age\",\"bmi\",\"avg_glucose_level\"]\n\nplt.subplot(1,3,1)\natt = data[\"age\"].values\np = sns.distplot(att,color=\"violet\")\np.set_title(\"Age Distribution\",fontsize=16)\np.set_xlim([min(att),max(att)])\n\nplt.subplot(1,3,2)\natt = data[\"bmi\"].values\np = sns.distplot(att,color=\"black\")\np.set_title(\"BMI Distribution\",fontsize=16)\np.set_xlim([min(att),max(att)])\n\nplt.subplot(1,3,3)\natt = data[\"avg_glucose_level\"].values\np = sns.distplot(att,color=\"orange\")\np.set_title(\"Age Distribution\",fontsize=16)\np.set_xlim([min(att),max(att)])","cff9e3bb":"import plotly.figure_factory as ff\ngroup_labels = ['0', '1']\nl = [data['age'][(data[\"stroke\"] == 0)],data['age'][(data[\"stroke\"] == 1)]]\nfig = ff.create_distplot(l, group_labels,curve_type='kde',colors = ['slategray', 'magenta'])\nfig.update_layout(title_text='Age & Stroke Distribution',xaxis_title=\"Age Distribution\",yaxis_title=\"Frequency\")\nfig.show()","09016851":"import plotly.figure_factory as ff\ngroup_labels = ['0', '1']\nl = [data['bmi'][(data[\"stroke\"] == 0)],data['bmi'][(data[\"stroke\"] == 1)]]\nfig = ff.create_distplot(l, group_labels,curve_type='kde',colors = ['#F66095', '#2BCDC1']\n)\nfig.update_layout(title_text='BMI & Stroke Distribution',xaxis_title=\"BMI Distribution\",yaxis_title=\"Frequency\")\nfig.show()","545942d0":"import plotly.figure_factory as ff\ngroup_labels = ['0', '1']\nl = [data['avg_glucose_level'][(data[\"stroke\"] == 0)],data['avg_glucose_level'][(data[\"stroke\"] == 1)]]\nfig = ff.create_distplot(l, group_labels,curve_type='kde',colors = ['#393E46', 'rgb(0, 200, 200)'])\nfig.update_layout(title_text='Avg Glucose Level & Stroke Distribution',xaxis_title=\"Avg_Glucose_Level Distribution\",yaxis_title=\"Frequency\")\nfig.show()","79630c25":"print('No Stroke :', round(data['stroke'].value_counts()[0]\/len(data) * 100,2), '% of the dataset')\nprint('Stroke :', round(data['stroke'].value_counts()[1]\/len(data) * 100,2), '% of the dataset')\nfig = px.histogram(data, x=\"stroke\", color=\"stroke\",barmode=\"group\") \nfig.update_layout(title_text=\"Stroke Count\")\nfig.show()","5a696ac4":"fig = px.histogram(data, x=\"smoking_status\", color=\"stroke\",barmode=\"group\") \nfig.update_layout(title_text=\"Smoking Status Count\")\nfig.show()","19aae6f3":"plt.subplots(figsize=(20,5))\nsns.set_style(style=\"darkgrid\")\n\nplt.subplot(1,3,1)\nsns.countplot(\"ever_married\",data=data,palette=\"Paired\",hue=\"stroke\")\n\nplt.subplot(1,3,2)\nsns.countplot(\"hypertension\",data=data,palette=\"crest\",hue='stroke')\n\nplt.subplot(1,3,3)\nsns.countplot(\"heart_disease\",data=data,palette=\"tab10\",hue='stroke')","eb91f16e":"plt.subplots(figsize=(20,10))\n\nplt.subplot(2,3,1)\nsns.countplot(\"gender\",data=data,palette=\"mako\",hue='stroke')\n\nplt.subplot(2,3,2)\nsns.countplot(\"work_type\",data=data,palette=\"rocket_r\",hue='stroke')\n\nplt.subplot(2,3,3)\nsns.countplot(\"Residence_type\",data=data,palette=\"autumn\",hue='stroke')","4a519fbb":"import plotly.express as px\nfig = px.scatter(data, x=\"bmi\", y=\"avg_glucose_level\", color=\"stroke\",color_continuous_scale=\"tropic\")\nfig.show()","978c58af":"data_X = data.drop(\"stroke\",axis=1)\ndata_y = data.iloc[:,-1]","6e2ab04f":"cat_col = data_X.select_dtypes(include = 'object').columns.to_list()\nnum_col = data_X.select_dtypes(include= ['int64','float64']).columns.to_list()\n\nfor i in num_col:\n    print(i + \": \",data_X[i].nunique())\n    print(\"------------------------------------------------------------------\")","1c948c79":"data[data_X[\"age\"]==0.32]","db4aff1a":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\ncat_encode = ColumnTransformer([('encoder', OneHotEncoder(), [0,5,9])], remainder= 'passthrough')\ndata_X = cat_encode.fit_transform(data_X)\ndata_X = pd.DataFrame(data_X)\ndata_X","4dd5e551":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ndata_X[15] = encoder.fit_transform(data_X[15])\ndata_X[16] = encoder.fit_transform(data_X[16])","e5879cf3":"data_X.shape","67edfae4":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size= 0.2, random_state=42)\n\nfrom sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","cb2be11d":"ax = plt.subplots(figsize=(20,7))\nplt.subplot(1,2,1)\nax=sns.countplot('stroke', data=pd.DataFrame(y_train), palette='viridis',hue=\"stroke\",dodge=False)\nplt.title(\"Stroke Count Before Oversampling\")\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n\nfrom imblearn.over_sampling import SMOTE\nsamp = SMOTE(random_state=3)\nX_train, y_train = samp.fit_resample(X_train, y_train.ravel())\n    \nplt.subplot(1,2,2)\nax=sns.countplot('stroke', data=pd.DataFrame(y_train,columns=[\"stroke\"]), palette='viridis',hue=\"stroke\",dodge=False)\nplt.title(\"Stroke Count After Oversampling\")\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')","30f3f630":"from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, average_precision_score, precision_recall_curve, plot_precision_recall_curve\nfrom sklearn.model_selection import cross_val_score","77dce361":"def metrics(model,x,y_test,y_pred):\n    cv = cross_val_score(model_1,X_train,y_train, cv = 5) \n    roc = roc_auc_score(y_test, y_pred)  \n    precision = precision_score(y_test, y_pred)  \n    recall = recall_score(y_test, y_pred)  \n    f1 = f1_score(y_test, y_pred)\n    print(classification_report(y_test, y_pred))\n    print(\"\\nAccuracy Score: \",accuracy_score(y_test, y_pred))\n    print(\"\\nROC AUC Score: {:.2f}\".format(roc))\n    print(\"\\nPrecision: {:.2f}\".format(precision))\n    print(\"\\nRecall: {:.2f}\".format(recall))\n    print(\"\\nF1: {:.2f}\".format(f1))\n    f, axes = plt.subplots(1,2, figsize=(20,7))\n    sns.set_theme(style = 'white')\n    #-------------------------------------CONFUSION MATRIX----------------------------------\n    \n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, cmap = 'Blues_r', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},ax=axes[0] ,yticklabels = ['0', '1'], xticklabels = ['Predicted 0', 'Predicted 1'])\n    \n    #-------------------------------------ROC_AUC Curve----------------------------------\n    \n    plot_roc_curve(model, x, y_test,ax=axes[1]) \n    plt.plot([0, 1], [0, 1], linestyle = '--', color = '#b01717')\n    plt.show()        ","c34eee59":"from sklearn.linear_model import LogisticRegression\nmodel_1 = LogisticRegression(random_state=42)\nmodel_1.fit(X_train,y_train)\ny_pred = model_1.predict(X_test)\nmetrics(model_1,X_test,y_test,y_pred)","05b5a118":"from sklearn.svm import SVC\nmodel_2 = SVC(random_state=42)\nmodel_2.fit(X_train,y_train)\ny_pred = model_2.predict(X_test)\nmetrics(model_2,X_test,y_test,y_pred)","9f53f803":"from sklearn.tree import DecisionTreeClassifier\nmodel_3 = DecisionTreeClassifier(random_state=42)\nmodel_3.fit(X_train,y_train)\ny_pred = model_3.predict(X_test)\nmetrics(model_3,X_test,y_test,y_pred)","19071967":"from sklearn.ensemble import RandomForestClassifier\nmodel_4 = RandomForestClassifier(random_state=42)\nmodel_4.fit(X_train,y_train)\ny_pred = model_4.predict(X_test)\nmetrics(model_4,X_test,y_test,y_pred)","86561754":"from xgboost import XGBClassifier\nmodel_5 = XGBClassifier(random_state=42,eval_metric=\"error\")\nmodel_5.fit(X_train,y_train)\ny_pred = model_5.predict(X_test)\nmetrics(model_5,X_test,y_test,y_pred)","6aaeaf37":"### **Random Forest**\n<div id=\"RF\"><\/div>","ddd70707":"<h1 id=\"contents\" style=\"text-align:center; background-color:#acdf87;color:white;padding-top:15px;padding-bottom:15px\"><strong>CONTENTS<\/strong><a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/abtabm\/indepth-stroke-analysis-eda-smote-91-acc\/#contents\">\u00b6<\/a><\/h1>\n","6c2b84d0":"### **Decision Tree**\n<div id=\"DT\"><\/div>","76d9373d":"**Due to imbalance in dataset it is hard to analyze but we can see that:**\n- **Higher the glucose level (150-250) Result in high Stroke chances.**\n- **BMI Above 30-40 intersecting with the glucose level has a higher risk of stroke.**","378c2eb1":"<div id=\"imp\"><\/div>","ffd45429":"### **CATEGORICAL & BOOLEAN FEATURES**\n<div id=\"cat\"><\/div>","3a0a3583":"- Below 18.5 - Underweight\n- 18.5-24.9 - Normal\n- 25.0-29.9 - Overweight\n- 30.0 And Above - Obese\n- **The BMI 30 above is considered as Obese, hence the chance of stroke is more in obese people.**","e20e1a29":"<div id=\"model\"><\/div>","7e895024":"### **SMOTE Handling Imbalance Data**\n<div id=\"smt\"><\/div>","97f6b654":"### **NUMERICAL FEATURES**\n<div id=\"num\"><\/div>","df738872":"**There is a high disproportion in the dataset, which could eventually lead to bad model, hence Sampling is required**","8fd8f6ec":"- **Elevated glucose level results in higher chances of a stroke, a trait observed in diabetic patients.**\n- **From the graph we can infer that above the level of 150\/160, the risk of stroke increases.**","4e357cc1":"<h1 id=\"modelling\" style=\"font-size:20px; color:White; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>MODELLING<\/strong><a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/abtabm\/indepth-stroke-analysis-eda-smote-91-acc\/#modelling\">\u00b6<\/a><\/h1>","c03fba0a":"### **Support Vector Machine**\n<div id=\"SVM\"><\/div>","98d45c8b":"### **Scaling & Splitting The Data**\n<div id=\"spl\"><\/div>","9f2757f9":"<div id=\"DataPre\"><\/div>","bb45705d":"**The age column looks weird as the min value is 0.08 which probably means that age is counted in days or there is some noise in this column , we need to analyze it in data cleaning**","471a3be8":"**A total of 201 missing values in BMI**","42ccff4a":"Well if we convert it into int, we can loose children's data, as 0.32 might be 32 days.","ab640f66":"<div id=\"num\"><\/div>","9089bb22":"<div id=\"eda\"><\/div>","bf7619a9":"<h1 id=\"conclusion\" style=\"font-size:20px; color:White; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>CONCLUSION<\/strong><a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/abtabm\/indepth-stroke-analysis-eda-smote-91-acc\/#conclusion\">\u00b6<\/a><\/h1>\n\n<div id=\"concl\"><\/div>","d74f1e5c":"1. [Importing Packages & Dataset](#imp)\n1. [EDA](#eda)\n   1. [Numerical Features](#num)\n   1. [Categorical Features](#cat)\n1. [Data Preprocessing](#DataPre)\n   1. [Encoding](#enc)\n   1. [Splitting](#spl)\n   1. [SMOTE](#smt)\n1. [Modelling](#model)\n   1. [Logistic Regression](#LR)\n   1. [SVM](#SVM)\n   1. [Decision Tree](#DT)\n   1. [Random Forest](#RF)\n   1. [XGBoost](#XG)\n1. [Conclusion](#concl)","95d93dae":"<h1 id=\"preprocessing\" style=\"font-size:20px; color:White; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>DATA PREPROCESSING<\/strong><a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/abtabm\/indepth-stroke-analysis-eda-smote-91-acc\/#preprocessing\"><\/a><\/h1>","853f944d":"- **We can infer that after the age of 40 the risk of Stroke increases.**\n- **At the age above 76 there is high chance of stroke.**","3a95f545":"- Higher **recall** and **f1-score** is required, but there aren't many True postives in the dataset. \n- The AUC Score of **Random Forest** and **Logistic Regression** is high, \n- Moreover True positive are more in the **XGBoost** and **Random Forest** Model\n\n#### I am open to advice\/suggestions to improve this notebook and i am curious to know which metric should be focussed more for this problem.","f47fd2e2":"### **Encoding Data**\n<div id=\"enc\"><\/div>","09cbb2fd":"<h1 id=\"importing-packages\" style=\"font-size:20px; color:white; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>IMPORTING PACKAGES & DATASET<\/strong><a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/abtabm\/indepth-stroke-analysis-eda-smote-91-acc\/#importing-packages\">\u00b6<\/a><\/h1>","b3376ab9":"<h1 id= \"eda\" style=\"font-size:20px; color:White; background-color:#5dd466 ;text-align:center;padding-top:10px;padding-bottom:10px\"><strong>EXPLORATORY DATA ANALYSIS<\/strong><a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/abtabm\/indepth-stroke-analysis-eda-smote-91-acc\/#eda\">\u00b6<\/a><\/h1>","875ac423":"### **Logistic Regression**\n<div id=\"LR\"><\/div>","5de15856":"### **XGBoost**\n<div id=\"XG\"><\/div>","374bd289":"### **Checking for unique values in the dataset**"}}