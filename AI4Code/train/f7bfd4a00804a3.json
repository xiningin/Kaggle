{"cell_type":{"6ee4b109":"code","f10b25a3":"code","1dd23904":"code","a4ec5d69":"code","fd04fd54":"code","74b04f47":"code","d03d10d6":"code","b880865e":"code","193367fa":"code","b7607982":"code","5fb05331":"code","a58266d1":"code","eeb670ff":"code","f03560d7":"code","2e1e6a1a":"code","8388f602":"markdown","6e48e395":"markdown","e6c79902":"markdown","c6284c70":"markdown","0e105d24":"markdown","5456d547":"markdown","b35a4156":"markdown","c9568d91":"markdown","7c05eb06":"markdown","44bf09b8":"markdown","8e133f8a":"markdown","89bbfe9f":"markdown","32b24692":"markdown","c7e62c0d":"markdown"},"source":{"6ee4b109":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f10b25a3":"import matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers, optimizers\nfrom tensorflow.keras.utils import to_categorical","1dd23904":"tf.random.set_seed(3)","a4ec5d69":"train_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nsub_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\ntrain_df.shape, test_df.shape","fd04fd54":"train_X, test_X = train_test_split(train_df, test_size=0.2, random_state=1)\n\ntrain_y, test_y = train_X.pop(\"label\"), test_X.pop(\"label\")\n\ntrain_X, test_X = train_X.values, test_X.values\n\ntrain_X.shape","74b04f47":"train_X = train_X.reshape(33600, 28, 28)\n\n\nfor i in range(9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(train_X[i], cmap=plt.get_cmap(\"gray\"))\n               \nplt.show()","d03d10d6":"train_X = train_X.reshape((train_X.shape[0], 28, 28, 1))\ntest_X = test_X.reshape((test_X.shape[0], 28, 28, 1))\ntrain_X, test_X = train_X \/ 255.0, test_X \/ 255.0\n\n\ntrain_y = to_categorical(train_y)\ntest_y = to_categorical(test_y)\n\ntrain_X.shape, test_X.shape, train_y.shape, test_y.shape","b880865e":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\",\n                           kernel_initializer=\"he_uniform\", input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\"),\n    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_uniform\"),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation=\"relu\",kernel_initializer=\"he_uniform\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.9),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=[\"accuracy\"])\n\nhistory = model.fit(train_X, train_y, epochs=3, validation_split=0.2, verbose=0)\n\nscore = model.evaluate(test_X, test_y, verbose=0)\nprint(f\"Test_loss: {score[0]} \/ Test accuracy: {score[1]}\")","193367fa":"hist = pd.DataFrame(history.history)\nhist[\"epoch\"] = history.epoch\n\ndef plot_history(history):\n    plt.figure()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Train, Val Accuracy\")\n    plt.plot(hist[\"epoch\"], hist[\"accuracy\"], label=\"Train acc\")\n    plt.plot(hist[\"epoch\"], hist[\"val_accuracy\"], label=\"Val acc\")\n    plt.legend()\n    \n    plt.figure()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Train, Val Loss\")\n    plt.plot(hist[\"epoch\"], hist[\"loss\"], label=\"Train Loss\")\n    plt.plot(hist[\"epoch\"], hist[\"val_loss\"], label=\"Val loss\")\n    plt.legend()\n    plt.show()\n    \n\nplot_history(history)","b7607982":"n_folds = 5\n\nacc_fold = []\nloss_fold = []\n\ninputs = np.concatenate((train_X, test_X), axis=0)\ntargets = np.concatenate((train_y, test_y), axis=0)","5fb05331":"def evaluate_model(inputs, targets, n_folds=n_folds):\n    kfold = RepeatedKFold(n_splits=n_folds, n_repeats=3, random_state=2)\n    fold_no = 1\n\n    \n    for train_ix, test_ix in kfold.split(inputs, targets):\n        print(f\"Train for fold {fold_no} ...\")\n        history = model.fit(inputs[train_ix], targets[train_ix], epochs=5, verbose=0)\n        scores = model.evaluate(inputs[test_ix], targets[test_ix], verbose=0)\n        print(f\"Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%\")\n        acc_fold.append(scores[1] * 100)\n        loss_fold.append(scores[0])\n        fold_no = fold_no + 1\n    \nevaluate_model(inputs, targets)\n\n\nprint(\"score per fold\")\nfor i in range(0, len(acc_fold)):\n    print(f\"> Fold {i+1} - loss: {loss_fold[i]} - Accuracy: {acc_fold[i]}%\")","a58266d1":"test_df = test_df.values\ntest_df = test_df.reshape((test_df.shape[0], 28, 28, 1))\ntest_df = test_df \/ 255.0","eeb670ff":"pred = model.predict(test_df)\npred = [np.argmax(y, axis=None, out=None)for y in pred]","f03560d7":"sub_df[\"Label\"] = pred\nsub_df.head()","2e1e6a1a":"sub_df.to_csv(\"my_submision1.csv\", index=False)","8388f602":"Kfold model appears to work, so preprocess, reshape, and normalize input test_df","6e48e395":"Set fold number for kfold cross validation splits.\n\nConcat the train\\test datasets and targets for kfold cross validation","e6c79902":"Use Pandas read_csv to read file and transform to dataframe.\n\nView dataframe's shape to verify split","c6284c70":"For Anyone interested or Learning more about Deep Learning Models,\ncopy and edit this notebook and try changing the Model's number of epochs,\nlearning rate, add layers to the base model, change the number of layers.\nOr you can change the number of kfold splits, epochs, or even the optimizer to see the effects\non training and results!\nif you dont set your parameters right, or process and normalize the data correctly\nit will greatly affect your models performance. ...\n\nOK,\n\nImport necessary modules !\nTo view, clean, process and evaluate data","0e105d24":"Plot model training, validation with matplotlib.pyplot","5456d547":"Define and build \"KFold\" validation split model from \"sklearn.model_selection\".\n\nEvaluate data and print accuracy, loss scores for each kfold split\nand print overall results for each fold.","b35a4156":"Predictions from model(test_data).\n\nUse \"Numpy\" argmax to find highest probability match in row of results array\nand convert back to integer","c9568d91":"Set tensorflow's random seed to a number(integer) to replicate model results","7c05eb06":"Reshape train, test arrays to 28 x 28 x 1 vectors for model input\nscale pictures for normalization(between [0, 1]) by dividing by 255.0\n\nConvert Targets\\Labels using keras \"to_categorical\" from integers to 10 class array\n\nVerify shape of input and targets","44bf09b8":"Finally assign the \"predictions\" to the existing dataframe Sub_df\n\"Label\" column and check results.","8e133f8a":"Split train.csv dataframe into train and test samples,\nfor training and validation testing.\n\nCreate target variable from data, which is the \"Survived\" column.\n\nConvert train and test dataframes to numpy arrays and verify shape again","89bbfe9f":"Reshape array rows by flattening to a 28 x 28 matrix to see input pictures\n\nUse a for loop to iterate though first few rows and then\n\"Matplotlib.pyplot\" to have a quick view of the input pictures.","32b24692":"Convert sub dataframe to csv file for kaggle comp entry and submit","c7e62c0d":"Build Conv2d model from keras,\napplying softmax function to the output layer to read probabilities.\nCompile model with \"SGD\" optimizer and \"Categorical Crossentropy\" as loss function\nand \"Accuracy\" as the metric used for training and predictions.\n\nFit model with train data and target using the test data and target as validation data,\nthen evaluate model with the test data and target."}}