{"cell_type":{"4dae3cc6":"code","f8aa384f":"code","6a008b8f":"code","fa565232":"code","678aebaf":"code","2b3cc14c":"code","737da64e":"code","ad85ee70":"code","533553f4":"code","4800dc67":"code","84697ab1":"code","de6856fa":"code","fb50eeb3":"code","9018b5a3":"code","657b81b2":"code","788d8f4f":"code","6004e94c":"code","30419b19":"code","8dc74b58":"code","b48187fd":"code","05bad105":"code","3453811f":"code","545ff322":"code","e9f3e42b":"code","355af608":"code","eceb0260":"code","e8a38e1f":"code","6431e1a2":"code","bd79a40e":"code","6fbe94c7":"code","4bb26119":"code","bca8fcc2":"code","a297a795":"code","1662623d":"code","8eac6024":"code","ce39254b":"code","09c09728":"code","5e2a2a37":"code","bb391982":"code","76618f27":"code","8836a51b":"code","fbfe2d8e":"code","530bf1ab":"code","ff51ea0c":"code","130de2d8":"code","8d618ee5":"code","c52b6ab4":"code","4cf5f3fd":"code","b331d9d3":"code","606f3072":"code","277b71e0":"code","8de8a59f":"code","d2cf32b3":"code","2be7c54d":"code","1e476a5e":"code","ae5b8e79":"code","772925fe":"code","5d784a62":"code","3dbb6e34":"code","e9979c08":"code","47cd12fe":"code","c86ceaf0":"code","be35482c":"code","359c061d":"code","760d0b07":"code","299ab728":"code","da6492e7":"code","6999043b":"code","403875d8":"code","cdf60b4b":"code","8b0d492c":"code","8e826647":"code","278cddc1":"code","0bac4d66":"code","a69d99b0":"code","eee166c1":"code","ad12b44f":"code","d9a710c1":"code","f07c7265":"code","286f956c":"code","c0855206":"code","f5b7be77":"code","3a5eb9d2":"code","645a92ce":"code","59c3c91e":"code","f4a2b4e4":"markdown","ef981b64":"markdown","1d314696":"markdown","eed40e32":"markdown","def8b9e6":"markdown","46e1e8be":"markdown","7c1ab944":"markdown","fb7d5fc7":"markdown","04a8bf03":"markdown","341779c0":"markdown","0391992f":"markdown","98258264":"markdown","b40b61b6":"markdown","c6cb33e9":"markdown","e496b2ee":"markdown","32ce0e11":"markdown","95a9337a":"markdown","ec3eb92f":"markdown","abea9282":"markdown","84ccffbe":"markdown","1c895500":"markdown","4208f7b5":"markdown","95960866":"markdown","e90ccab5":"markdown","10744244":"markdown","740a73a6":"markdown","881ce965":"markdown","5c73f507":"markdown","7e43fdbf":"markdown","d4c049ec":"markdown","7990db81":"markdown","15d47d22":"markdown","3a5599ad":"markdown","f95e8d75":"markdown","8f6fed56":"markdown"},"source":{"4dae3cc6":"from IPython.display import HTML\n\nHTML('<iframe width=\"800\" height=\"400\" src=\"https:\/\/www.youtube.com\/embed\/-UeC4MR3PHM?start=0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","f8aa384f":"\"\"\"\nSome visualization methods used in this tutorial is supported in optuna from v0.18.0 released recently!\nHowever this kaggle kernel pre-installs version 0.16.0\n\"\"\"\n!pip install optuna==0.18.1","6a008b8f":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm import tqdm_notebook as tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n","fa565232":"# Original code from https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage by @gemartin\n# Modified to support timestamp type, categorical type\n# Modified to add option to use float16 or not. feather format does not support float16.\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            # skip datetime type or categorical type\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","678aebaf":"!ls ..\/input","2b3cc14c":"%%time\nroot = Path('..\/input\/ashrae-feather-format-for-fast-loading')\n\ntrain_df = pd.read_feather(root\/'train.feather')\nweather_train_df = pd.read_feather(root\/'weather_train.feather')\nbuilding_meta_df = pd.read_feather(root\/'building_metadata.feather')","737da64e":"train_df['date'] = train_df['timestamp'].dt.date\ntrain_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])","ad85ee70":"np.sum(train_df['meter_reading_log1p'].values < 0)","533553f4":"def plot_date_usage(train_df, meter=0, building_id=0):\n    train_temp_df = train_df[train_df['meter'] == meter]\n    train_temp_df = train_temp_df[train_temp_df['building_id'] == building_id]    \n    train_temp_df_meter = train_temp_df.groupby('date')['meter_reading_log1p'].sum()\n    train_temp_df_meter = train_temp_df_meter.to_frame().reset_index()\n    fig = px.line(train_temp_df_meter, x='date', y='meter_reading_log1p')\n    fig.show()","4800dc67":"plot_date_usage(train_df, meter=0, building_id=0)","84697ab1":"building_meta_df[building_meta_df.site_id == 0]","de6856fa":"train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')","fb50eeb3":"debug = False","9018b5a3":"def preprocess(df):\n    df[\"hour\"] = df[\"timestamp\"].dt.hour\n#     df[\"day\"] = df[\"timestamp\"].dt.day\n    df[\"month\"] = df[\"timestamp\"].dt.month\n    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n    df[\"weekend\"] = df[\"dayofweek\"] >= 5\n\n#     hour_rad = df[\"hour\"].values \/ 24. * 2 * np.pi\n#     df[\"hour_sin\"] = np.sin(hour_rad)\n#     df[\"hour_cos\"] = np.cos(hour_rad)","657b81b2":"preprocess(train_df)","788d8f4f":"# take stats by ONLY building_id. meter type is merged in this script...\n\n# df_group = train_df.groupby('building_id')['meter_reading_log1p']\n# building_mean = df_group.mean().astype(np.float16)\n# building_median = df_group.median().astype(np.float16)\n# building_min = df_group.min().astype(np.float16)\n# building_max = df_group.max().astype(np.float16)\n# building_std = df_group.std().astype(np.float16)\n\n# train_df['building_mean'] = train_df['building_id'].map(building_mean)\n# train_df['building_median'] = train_df['building_id'].map(building_median)\n# train_df['building_min'] = train_df['building_id'].map(building_min)\n# train_df['building_max'] = train_df['building_id'].map(building_max)\n# train_df['building_std'] = train_df['building_id'].map(building_std)","6004e94c":"df_group = train_df.groupby(['building_id', 'meter'])['meter_reading_log1p']\nbuilding_mean = df_group.mean().astype(np.float16)\nbuilding_median = df_group.median().astype(np.float16)\nbuilding_min = df_group.min().astype(np.float16)\nbuilding_max = df_group.max().astype(np.float16)\nbuilding_std = df_group.std().astype(np.float16)","30419b19":"building_stats_df = pd.concat([building_mean, building_median, building_min, building_max, building_std], axis=1,\n                              keys=['building_mean', 'building_median', 'building_min', 'building_max', 'building_std']).reset_index()\ntrain_df = pd.merge(train_df, building_stats_df, on=['building_id', 'meter'], how='left', copy=False)","8dc74b58":"train_df.head()","b48187fd":"weather_train_df.head()","05bad105":"weather_train_df.isna().sum()","3453811f":"weather_test_df = pd.read_feather(root\/'weather_test.feather')\nweather = pd.concat([weather_train_df, weather_test_df],ignore_index=True)\ndel weather_test_df\nweather_key = ['site_id', 'timestamp']","545ff322":"# https:\/\/www.kaggle.com\/nz0722\/aligned-timestamp-lgbm-by-meter-type\n\ntemp_skeleton = weather[weather_key + ['air_temperature']].drop_duplicates(subset=weather_key).sort_values(by=weather_key).copy()\n\n# calculate ranks of hourly temperatures within date\/site_id chunks\ntemp_skeleton['temp_rank'] = temp_skeleton.groupby(['site_id', temp_skeleton.timestamp.dt.date])['air_temperature'].rank('average')\n\n# create a dataframe of site_ids (0-16) x mean hour rank of temperature within day (0-23)\ndf_2d = temp_skeleton.groupby(['site_id', temp_skeleton.timestamp.dt.hour])['temp_rank'].mean().unstack(level=1)\n\n# Subtract the columnID of temperature peak by 14, getting the timestamp alignment gap.\nsite_ids_offsets = pd.Series(df_2d.values.argmax(axis=1) - 14)\nsite_ids_offsets.index.name = 'site_id'\n\ndef timestamp_align(df):\n    df['offset'] = df.site_id.map(site_ids_offsets)\n    df['timestamp_aligned'] = (df.timestamp - pd.to_timedelta(df.offset, unit='H'))\n    df['timestamp'] = df['timestamp_aligned']\n    del df['timestamp_aligned']\n    return df\n\ndel weather\ndel temp_skeleton\ngc.collect()","e9f3e42b":"weather_train_df = timestamp_align(weather_train_df)\nweather_train_df = weather_train_df.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))","355af608":"def add_lag_feature(weather_df, window=3):\n    group_df = weather_df.groupby('site_id')\n    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n    rolled = group_df[cols].rolling(window=window, min_periods=0)\n    lag_mean = rolled.mean().reset_index().astype(np.float16)\n    lag_max = rolled.max().reset_index().astype(np.float16)\n    lag_min = rolled.min().reset_index().astype(np.float16)\n    lag_std = rolled.std().reset_index().astype(np.float16)\n    for col in cols:\n        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n        weather_df[f'{col}_std_lag{window}'] = lag_std[col]","eceb0260":"add_lag_feature(weather_train_df, window=3)\nadd_lag_feature(weather_train_df, window=72)","e8a38e1f":"weather_train_df.head()","6431e1a2":"weather_train_df.columns","bd79a40e":"# categorize primary_use column to reduce memory on merge...\n\nprimary_use_list = building_meta_df['primary_use'].unique()\nprimary_use_dict = {key: value for value, key in enumerate(primary_use_list)} \nprint('primary_use_dict: ', primary_use_dict)\nbuilding_meta_df['primary_use'] = building_meta_df['primary_use'].map(primary_use_dict)\n\ngc.collect()","6fbe94c7":"reduce_mem_usage(train_df, use_float16=True)\nreduce_mem_usage(building_meta_df, use_float16=True)\nreduce_mem_usage(weather_train_df, use_float16=True)","4bb26119":"building_meta_df.head()","bca8fcc2":"category_cols = ['building_id', 'site_id', 'primary_use']  # , 'meter'\nweather_cols = [\n    'air_temperature', 'cloud_coverage',\n    'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure',\n    'wind_direction', 'wind_speed', 'air_temperature_mean_lag72',\n    'air_temperature_max_lag72', 'air_temperature_min_lag72',\n    'air_temperature_std_lag72', 'cloud_coverage_mean_lag72',\n    'dew_temperature_mean_lag72', 'precip_depth_1_hr_mean_lag72',\n    'sea_level_pressure_mean_lag72', 'wind_direction_mean_lag72',\n    'wind_speed_mean_lag72', 'air_temperature_mean_lag3',\n    'air_temperature_max_lag3',\n    'air_temperature_min_lag3', 'cloud_coverage_mean_lag3',\n    'dew_temperature_mean_lag3',\n    'precip_depth_1_hr_mean_lag3', 'sea_level_pressure_mean_lag3',\n    'wind_direction_mean_lag3', 'wind_speed_mean_lag3']\nfeature_cols = ['square_feet', 'year_built'] + [\n    'hour', 'weekend', 'dayofweek', # 'month'\n    'building_median'] + weather_cols","a297a795":"def create_X_y(train_df, target_meter):\n    target_train_df = train_df[train_df['meter'] == target_meter]\n    target_train_df = target_train_df.merge(building_meta_df, on='building_id', how='left')\n    target_train_df = target_train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\n    X_train = target_train_df[feature_cols + category_cols]\n    y_train = target_train_df['meter_reading_log1p'].values\n\n    del target_train_df\n    return X_train, y_train","1662623d":"import optuna\nfrom optuna import Trial\n\noptuna.__version__","8eac6024":"debug = False\n\ntrain_df_original = train_df\n# Only use 10000 data,,, for fast computation for debugging.\ntrain_df = train_df.sample(10000)","ce39254b":"def objective(trial: Trial, fast_check=True, target_meter=0, return_info=False):\n    folds = 5\n    seed = 666\n    shuffle = False\n    kf = KFold(n_splits=folds, shuffle=shuffle, random_state=seed)\n\n    X_train, y_train = create_X_y(train_df, target_meter=target_meter)\n    y_valid_pred_total = np.zeros(X_train.shape[0])\n    gc.collect()\n    print('target_meter', target_meter, X_train.shape)\n\n    cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n    print('cat_features', cat_features)\n\n    models = []\n    valid_score = 0\n    for train_idx, valid_idx in kf.split(X_train, y_train):\n        train_data = X_train.iloc[train_idx,:], y_train[train_idx]\n        valid_data = X_train.iloc[valid_idx,:], y_train[valid_idx]\n\n        print('train', len(train_idx), 'valid', len(valid_idx))\n    #     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n        model, y_pred_valid, log = fit_lgbm(trial, train_data, valid_data, cat_features=category_cols,\n                                            num_rounds=1000)\n        y_valid_pred_total[valid_idx] = y_pred_valid\n        models.append(model)\n        gc.collect()\n        valid_score += log[\"valid\/l2\"]\n        if fast_check:\n            break\n    valid_score \/= len(models)\n    if return_info:\n        return valid_score, models, y_pred_valid, y_train\n    else:\n        return valid_score","09c09728":"# Referred https:\/\/github.com\/pfnet\/optuna\/blob\/master\/examples\/lightgbm_simple.py\n\ndef fit_lgbm(trial, train, val, devices=(-1,), seed=None, cat_features=None, num_rounds=1500):\n    \"\"\"Train Light GBM model\"\"\"\n    X_train, y_train = train\n    X_valid, y_valid = val\n    metric = 'l2'\n    params = {\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'objective': 'regression',\n#               'max_depth': -1,\n        'learning_rate': 0.1,\n        \"boosting\": \"gbdt\",\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        \"bagging_freq\": 5,\n        \"bagging_fraction\": trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        \"metric\": metric,\n        \"verbosity\": -1,\n    }\n    device = devices[0]\n    if device == -1:\n        # use cpu\n        pass\n    else:\n        # use gpu\n        print(f'using gpu device_id {device}...')\n        params.update({'device': 'gpu', 'gpu_device_id': device})\n\n    params['seed'] = seed\n\n    early_stop = 20\n    verbose_eval = 20\n\n    d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n    d_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_features)\n    watchlist = [d_train, d_valid]\n\n    print('training LGB:')\n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n\n    # predictions\n    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n    \n    print('best_score', model.best_score)\n    log = {'train\/l2': model.best_score['training']['l2'],\n           'valid\/l2': model.best_score['valid_1']['l2']}\n    return model, y_pred_valid, log","5e2a2a37":"study = optuna.create_study()\nstudy.optimize(objective, n_trials=10)","bb391982":"# Referred https:\/\/github.com\/pfnet\/optuna\/blob\/master\/examples\/pruning\/lightgbm_integration.py\n\ndef fit_lgbm_with_pruning(trial, train, val, devices=(-1,), seed=None, cat_features=None, num_rounds=1500):\n    \"\"\"Train Light GBM model\"\"\"\n    X_train, y_train = train\n    X_valid, y_valid = val\n    metric = 'l2'\n    params = {\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'objective': 'regression',\n#               'max_depth': -1,\n        'learning_rate': 0.1,\n        \"boosting\": \"gbdt\",\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        \"bagging_freq\": 5,\n        \"bagging_fraction\": trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        \"metric\": metric,\n        \"verbosity\": -1,\n    }\n    device = devices[0]\n    if device == -1:\n        # use cpu\n        pass\n    else:\n        # use gpu\n        print(f'using gpu device_id {device}...')\n        params.update({'device': 'gpu', 'gpu_device_id': device})\n\n    params['seed'] = seed\n\n    early_stop = 20\n    verbose_eval = 20\n\n    d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n    d_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_features)\n    watchlist = [d_train, d_valid]\n\n    # Add a callback for pruning.\n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'l2', valid_name='valid_1')    \n    print('training LGB:')\n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop,\n                      callbacks=[pruning_callback])\n\n    # predictions\n    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n    \n    print('best_score', model.best_score)\n    log = {'train\/l2': model.best_score['training']['l2'],\n           'valid\/l2': model.best_score['valid_1']['l2']}\n    return model, y_pred_valid, log","76618f27":"def objective_with_prune(trial: Trial, fast_check=True, target_meter=0):\n    \"\"\"This method is completely same with previous `objective` method except calling `fit_lgbm_with_pruning`\"\"\"\n    folds = 5\n    seed = 666\n    shuffle = False\n    kf = KFold(n_splits=folds, shuffle=shuffle, random_state=seed)\n\n    X_train, y_train = create_X_y(train_df, target_meter=target_meter)\n    y_valid_pred_total = np.zeros(X_train.shape[0])\n    gc.collect()\n    print('target_meter', target_meter, X_train.shape)\n\n    cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n    print('cat_features', cat_features)\n\n    models0 = []\n    valid_score = 0\n    for train_idx, valid_idx in kf.split(X_train, y_train):\n        train_data = X_train.iloc[train_idx,:], y_train[train_idx]\n        valid_data = X_train.iloc[valid_idx,:], y_train[valid_idx]\n\n        print('train', len(train_idx), 'valid', len(valid_idx))\n        model, y_pred_valid, log = fit_lgbm_with_pruning(trial, train_data, valid_data, cat_features=category_cols,\n                                                         num_rounds=1000)\n        y_valid_pred_total[valid_idx] = y_pred_valid\n        models0.append(model)\n        gc.collect()\n        valid_score += log[\"valid\/l2\"]\n        if fast_check:\n            break\n    valid_score \/= len(models0)\n    return valid_score","8836a51b":"study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\nstudy.optimize(objective_with_prune, n_trials=50)","fbfe2d8e":"print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))\n\n# It has alias, below is also same.\n# print('Best trial: score {}, params {}'.format(study.best_value, study.best_params))","530bf1ab":"trials_df = study.trials_dataframe()\ntrials_df","ff51ea0c":"optuna.visualization.plot_optimization_history(study)","130de2d8":"optuna.visualization.plot_intermediate_values(study)","8d618ee5":"optuna.visualization.plot_slice(study)","c52b6ab4":"optuna.visualization.plot_contour(study)","4cf5f3fd":"optuna.visualization.plot_parallel_coordinate(study)","b331d9d3":"if not debug:\n    # Restore to original data size for actual computation\n    train_df = train_df_original\n    timeout = 60 * 60 * 2  # For 2 hours...\nelse:\n    timeout = 60 * 1       # Debug mode, only for 1 mins\n\nprint('train_df.shape', train_df.shape)\nprint(f'timeout {timeout \/60} min')","606f3072":"study = optuna.create_study(pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=2, reduction_factor=4, min_early_stopping_rate=1))\nstudy.optimize(objective_with_prune, timeout=timeout)","277b71e0":"print(f'Executed {len(study.trials)} trials, best score {study.best_value} with best_params {study.best_params}')","8de8a59f":"trials_df = study.trials_dataframe()\ntrials_df.to_csv('trials_history.csv')","d2cf32b3":"# optuna.visualization.plot_optimization_history(study)\nfig = optuna.visualization._get_optimization_history_plot(study)\npy.plot(fig, filename='optimization_history.html')\nfig.show()","2be7c54d":"# optuna.visualization.plot_intermediate_values(study)\nfig = optuna.visualization._get_intermediate_plot(study)\npy.plot(fig, filename='intermediate_values.html')\nfig.show()","1e476a5e":"# optuna.visualization.plot_slice(study)\nfig = optuna.visualization._get_slice_plot(study)\npy.plot(fig, filename='slice.html')\nfig.show()","ae5b8e79":"# optuna.visualization.plot_contour(study)\nfig = optuna.visualization._get_contour_plot(study)\npy.plot(fig, filename='contour.html')\nfig.show()","772925fe":"# optuna.visualization.plot_parallel_coordinate(study)\nfig = optuna.visualization._get_parallel_coordinate_plot(study)\npy.plot(fig, filename='parallel_coordinate.html')\nfig.show()","5d784a62":"print(\"Training model with best_params {}\".format(study.best_params))","3dbb6e34":"# For meter 0\nvalid_score, models0, y_pred_valid, y_train = objective(optuna.trial.FixedTrial(study.best_params), fast_check=False, target_meter=0, return_info=True)\n\nsns.distplot(y_pred_valid, label='pred')\nsns.distplot(y_train, label='ground truth')\nplt.legend()\nplt.show()\n\ndel y_pred_valid, y_train","e9979c08":"# For meter 1\nvalid_score, models1, y_pred_valid, y_train = objective(optuna.trial.FixedTrial(study.best_params), fast_check=False, target_meter=1, return_info=True)\n\nsns.distplot(y_pred_valid, label='pred')\nsns.distplot(y_train, label='ground truth')\nplt.legend()\nplt.show()\n\ndel y_pred_valid, y_train","47cd12fe":"# For meter 2\nvalid_score, models2, y_pred_valid, y_train = objective(optuna.trial.FixedTrial(study.best_params), fast_check=False, target_meter=2, return_info=True)\n\nsns.distplot(y_pred_valid, label='pred')\nsns.distplot(y_train, label='ground truth')\nplt.legend()\nplt.show()\n\ndel y_pred_valid, y_train","c86ceaf0":"# For meter 3\nvalid_score, models3, y_pred_valid, y_train = objective(optuna.trial.FixedTrial(study.best_params), fast_check=False, target_meter=3, return_info=True)\n\nsns.distplot(y_pred_valid, label='pred')\nsns.distplot(y_train, label='ground truth')\nplt.legend()\nplt.show()\n\ndel y_pred_valid, y_train","be35482c":"try:\n    del train_df\n    del train_df_original\n    del weather_train_df\nexcept:\n    pass\ngc.collect()","359c061d":"print('loading...')\ntest_df = pd.read_feather(root\/'test.feather')\nweather_test_df = pd.read_feather(root\/'weather_test.feather')\n\nprint('preprocessing building...')\ntest_df['date'] = test_df['timestamp'].dt.date\npreprocess(test_df)\n\nprint('preprocessing weather...')\nweather_test_df = timestamp_align(weather_test_df)\nweather_test_df = weather_test_df.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\nweather_test_df.groupby('site_id').apply(lambda group: group.isna().sum())\n\nadd_lag_feature(weather_test_df, window=3)\nadd_lag_feature(weather_test_df, window=72)\n\nprint('reduce mem usage...')\nweather_test_df = weather_test_df[['site_id', 'timestamp'] + weather_cols]\nreduce_mem_usage(test_df, use_float16=True)\nreduce_mem_usage(weather_test_df, use_float16=True)\n\ngc.collect()","760d0b07":"del df_2d\ndel site_ids_offsets\ngc.collect()","299ab728":"def create_X(test_df, target_meter):\n    target_test_df = test_df[test_df['meter'] == target_meter]\n    target_test_df = target_test_df.merge(building_meta_df, on='building_id', how='left', copy=False)\n    target_test_df = pd.merge(target_test_df, building_stats_df, on=['building_id', 'meter'], how='left', copy=False)\n    target_test_df = target_test_df.merge(weather_test_df, on=['site_id', 'timestamp'], how='left', copy=False)\n    X_test = target_test_df[feature_cols + category_cols]\n    return X_test\n\ndef pred(X_test, models, batch_size=1000000):\n    iterations = (X_test.shape[0] + batch_size -1) \/\/ batch_size\n    print('iterations', iterations)\n\n    y_test_pred_total = np.zeros(X_test.shape[0])\n    for i, model in enumerate(models):\n        print(f'predicting {i}-th model')\n        for k in tqdm(range(iterations)):\n            y_pred_test = model.predict(X_test[k*batch_size:(k+1)*batch_size], num_iteration=model.best_iteration)\n            y_test_pred_total[k*batch_size:(k+1)*batch_size] += y_pred_test\n\n    y_test_pred_total \/= len(models)\n    return y_test_pred_total","da6492e7":"%%time\nX_test = create_X(test_df, target_meter=0)\ngc.collect()\n\ny_test0 = pred(X_test, models0)\n\ndel X_test\ngc.collect()","6999043b":"%%time\nX_test = create_X(test_df, target_meter=1)\ngc.collect()\ny_test1 = pred(X_test, models1)\n\ndel X_test\ngc.collect()","403875d8":"%%time\nX_test = create_X(test_df, target_meter=2)\ngc.collect()\ny_test2 = pred(X_test, models2)\n\ndel X_test\ngc.collect()","cdf60b4b":"%%time\nX_test = create_X(test_df, target_meter=3)\ngc.collect()\ny_test3 = pred(X_test, models3)\n\ndel X_test\ngc.collect()","8b0d492c":"sns.distplot(y_test0)\nplt.title('test prediction for meter type 0')","8e826647":"sns.distplot(y_test1)\nplt.title('test prediction for meter type 1')","278cddc1":"sns.distplot(y_test2)\nplt.title('test prediction for meter type 2')","0bac4d66":"sns.distplot(y_test3)\nplt.title('test prediction for meter type 3')","a69d99b0":"sample_submission = pd.read_feather(os.path.join(root, 'sample_submission.feather'))\nreduce_mem_usage(sample_submission)","eee166c1":"print(np.sum(y_test0 < 0))\nprint(np.sum(y_test1 < 0))\nprint(np.sum(y_test2 < 0))\nprint(np.sum(y_test3 < 0))\n\ny_test0 = np.where(y_test0 < 0, 0, y_test0)\ny_test1 = np.where(y_test1 < 0, 0, y_test1)\ny_test2 = np.where(y_test2 < 0, 0, y_test2)\ny_test3 = np.where(y_test3 < 0, 0, y_test3)","ad12b44f":"sample_submission.loc[test_df['meter'] == 0, 'meter_reading'] = np.expm1(y_test0)\nsample_submission.loc[test_df['meter'] == 1, 'meter_reading'] = np.expm1(y_test1)\nsample_submission.loc[test_df['meter'] == 2, 'meter_reading'] = np.expm1(y_test2)\nsample_submission.loc[test_df['meter'] == 3, 'meter_reading'] = np.expm1(y_test3)","d9a710c1":"sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')","f07c7265":"sample_submission.head()","286f956c":"np.log1p(sample_submission['meter_reading']).hist()","c0855206":"def plot_feature_importance(model):\n    importance_df = pd.DataFrame(model.feature_importance(),\n                                 index=feature_cols + category_cols,\n                                 columns=['importance']).sort_values('importance')\n    fig, ax = plt.subplots(figsize=(8, 8))\n    importance_df.plot.barh(ax=ax)\n    fig.show()","f5b7be77":"plot_feature_importance(models0[1])","3a5eb9d2":"plot_feature_importance(models1[1])","645a92ce":"plot_feature_importance(models2[1])","59c3c91e":"plot_feature_importance(models3[1])","f4a2b4e4":"Seems number of nan has reduced by `interpolate` but some property has never appear in specific `site_id`, and nan remains for these features.","ef981b64":"<a id=\"id3\"><\/a>\n# 3. Make \"study\" and let optimize!\n\nAfter you define `objective` function and write a code to use hyperparamers by `trial` module, we are ready to go!\n\nJust 2 lines of code do the all troublesome hyperparameter tuning for you. That's all!!","1d314696":"## Visualize pruning history\n\nYou can visualize how the pruning is executed!<br>\nEach color shows the loss curve of each trial.","eed40e32":"## Visualize plot slice\n\nWe can see how the optuna's sampler searches hyperparameter space.<br>\nThe white dots are searched in the early stage, while blue dots are searched in the later stage.\n\nWe can see following behavior (This is for the debugging small train_df training, actual dataset behavior maybe different!)\n\n - `feature_fraction`: Low value (0.4~0.8) got very but score at the begging of trial, and thus high value (0.9~1.0) are extensively searched in the later stage.\n - `num_leaves`      : Intermediate value around 32~64 are extensively searched in the later stage, which may be \"reasonable\".","def8b9e6":"## Visualize parallel_coordinate\n\nWhen I check the best valued line, which is most blue color line starts from left-bottom, we can see following behavior:\n\n - higher high feature_fraction seems better\n - lower lambda_l1 seems better\n - lower lambda_l2 seems better\n - not too big num_leaves seems better\n \nfor debugging data. This is very small data, so it is reasonable that it should use all the feature and less regularization...","46e1e8be":"## More examples?\n\nSee [https:\/\/github.com\/pfnet\/optuna\/tree\/master\/examples\/visualization](https:\/\/github.com\/pfnet\/optuna\/tree\/master\/examples\/visualization) !!","7c1ab944":"## Create test data","fb7d5fc7":"I just added `LightGBMPruningCallback` for LightGBM training.<br>\nThe difference is only 2 line. Define `pruning_callback` and set it in `lgb.train` method.\n\nThe example below will check validation score each iteration for pruning.","04a8bf03":"## lags\n\nAdding some lag feature","341779c0":"## Removing weired data on site_id 0\n\nAs you can see above, this data looks weired until May 20. It is reported in [this discussion](https:\/\/www.kaggle.com\/c\/ashrae-energy-prediction\/discussion\/113054#656588) by @barnwellguy that **All electricity meter is 0 until May 20 for site_id == 0**. I will remove these data from training data.\n\nIt corresponds to `building_id <= 104`.","0391992f":"Some features introduced in https:\/\/www.kaggle.com\/ryches\/simple-lgbm-solution by @ryches\n\nFeatures that are likely predictive:\n\n#### Weather\n\n- time of day\n- holiday\n- weekend\n- cloud_coverage + lags\n- dew_temperature + lags\n- precip_depth + lags\n- sea_level_pressure + lags\n- wind_direction + lags\n- wind_speed + lags\n\n#### Train\n\n- max, mean, min, std of the specific building historically\n\n\n\nHowever we should be careful of putting time feature, since we have only 1 year data in training,\nincluding `date` makes overfiting to training data.\n\nHow about `month`? It may be better to check performance by cross validation.\nI go not using this data in this kernel for robust modeling.","98258264":"<a id=\"title\"><\/a>\n# ASHRAE - Great Energy Predictor III\n\nOur aim in this competition is to predict energy consumption of buildings.\n\nThere are 4 types of energy to predict:\n\n - 0: electricity\n - 1: chilledwater\n - 2: steam\n - 3: hotwater\n\nElectricity and water consumption may have different behavior!\nSo I tried to separately train & predict the model.\n\nI moved previous [ASHRAE: Simple LGBM submission](https:\/\/www.kaggle.com\/corochann\/ashrae-simple-lgbm-submission) kernel.","b40b61b6":"Now you can check this kind of message:\n\n> [I 2019-10-28 13:03:33,408] Setting status of trial#15 as TrialState.PRUNED. Trial was pruned at iteration 6.\n\nSome unpromised trial is pruned before totally taining the model, so that we can check more trial!","c6cb33e9":"Then you can again create `study` object with **setting `pruner` object**, and let optimize!\n\n`pruner` class defines strategy how to prune in each intermediate step.<br>\n`MedianPruner` used in this example just check reported value each iteration, and if its score is higher than the median value of whole study history in this iteration, prunes.","e496b2ee":"<a id=\"id2\"><\/a>\n# 2. Use \"trial\" module to define hyperparameters dynamically!\n\ntrial module can be used to get hyperparameters.\nAs shown in below figure, we just need to get hyperparameters from `trial` module where we want to use hyper parameters!\n\n<img src=\"https:\/\/optuna.org\/assets\/img\/define-by-run.png\"><\/img>\nfrom [https:\/\/optuna.org\/](https:\/\/optuna.org\/)\n\nThis scheme is called \"Define-by-Run\" which makes user to intuitively write code to get hyperparameters, instead of defining whole search space in advance.\n\nYou can call these methods to get hyperparametes (ref: [Defining Parameter Spaces](https:\/\/optuna.readthedocs.io\/en\/latest\/tutorial\/configurations.html#defining-parameter-spaces)):\n\n    # Categorical parameter\n    optimizer = trial.suggest_categorical('optimizer', ['MomentumSGD', 'Adam'])\n\n    # Int parameter\n    num_layers = trial.suggest_int('num_layers', 1, 3)\n\n    # Uniform parameter\n    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 1.0)\n\n    # Loguniform parameter\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n\n    # Discrete-uniform parameter\n    drop_path_rate = trial.suggest_discrete_uniform('drop_path_rate', 0.0, 1.0, 0.1)\n","32ce0e11":"<a id=\"id4\"><\/a>\n# 4. [Advanced] Pruning unpromising trials for more faster search\n\nAnother important functionality is **\"pruning\"**. When human try hyperparameter tuning, we usually stop training earlier when the learning curve was much worse than the best known result.\n\n`optuna` provides pruning feature, and also provides integration modules for famous ML framework so that user can easily try pruning during hyperparameter optimization.<br>\nSupported modules are following\n\n - XGBoost: `optuna.integration.XGBoostPruningCallback`\n - LightGBM: `optuna.integration.LightGBMPruningCallback`\n - Chainer: `optuna.integration.ChainerPruningExtension`\n - Keras: `optuna.integration.KerasPruningCallback`\n - TensorFlow `optuna.integration.TensorFlowPruningHook`\n - tf.keras `optuna.integration.TFKerasPruningCallback`\n - MXNet `optuna.integration.MXNetPruningCallback`\n\nSee [pruning](https:\/\/optuna.readthedocs.io\/en\/stable\/tutorial\/pruning.html) section for details.\n\n<img src=\"https:\/\/optuna.org\/assets\/img\/pruning-example-with-caption.png\"><\/img>","95a9337a":"## Train model\n\nTo win in kaggle competition, how to evaluate your model is important.\nWhat kind of cross validation strategy is suitable for this competition? This is time series data, so it is better to consider time-splitting.\n\nHowever this notebook is for simple tutorial, so I will proceed with KFold splitting without shuffling, so that at least near-term data is not included in validation.","ec3eb92f":"## Fill Nan value in weather dataframe by interpolation\n\n\nweather data has a lot of NaNs!!\n\n![](http:\/\/)I tried to fill these values by **interpolating** data.","abea9282":"## Visualize plot contour\n\nWe can see 2 parametes pair plot with objective value as contour.","84ccffbe":"<a id=\"id1\"><\/a>\n# 1. Define \"objective\" function\n\nTo start hyperparameter tuning, we need an objective function to optimize the score.<br>\n**`objective` method needs to receive `trial` object as args, and return \"score\" to be optimized.**<br>\n(What is trial module? it is explained in next section) \n\n```\ndef objective(trial, ...):\n    # calculate score...\n    return score\n```\n\nBelow example, I train LightGBM model (only for electricity meter), get best validation score, and return this validation score as the final score.\n\n**The `objective` function is called many times** by `optuna` framework to try different hyperparameters, to search best hyperparameters.","1c895500":"Here I passed `trial` module to `fit_lgbm` function, which is the core training code and defines hyperparameters.<br>\nLet's see inside of `fit_lgbm` module next.","4208f7b5":"# Train model and make submission with best params\n\nI just tuned parameter for meter type 0 and only for 1st fold above.<br>\nBut I use this parameter for all training for simplicity.","95960866":"## Summary of trial & study\n\n - **`trial` manages each execution of model training, evaluation, getting a score by specifying one trial of hyperparameter**\n - **`study` manages all history of `trial`. So that we can know best hyperparamers, and suggest next hyperparameters to search etc**\n\n\n## Sampler\n\n`optuna` provides many types of `Sampler` class to suggest next hyperparameters. (Ref: [sampler](https:\/\/optuna.readthedocs.io\/en\/stable\/tutorial\/sampler.html))\n\nDefault behavior is to use TPE algorithm, which is same with famous `hyperopt` library. This is kind of a bayesian optimization based sampling.\n\n\n## FAQ: How to define objective functions that have own arguments?\n\n`study.optimize` method receives `objective` method with `trial` args, how to pass other 2nd, 3rd argument?<br>\nWe can use class or lambda expression.<br>\nFor example, `study.optimize(lambda trial: objective(trial, arg0=1, arg1=2), n_trials=100)`<br>\n\nRefer [How to define objective functions that have own arguments?](https:\/\/optuna.readthedocs.io\/en\/latest\/faq.html#how-to-define-objective-functions-that-have-own-arguments) for details.","e90ccab5":"# Let's start actual hyperparameter optimization\n\nReharsal is done! Now let's proceed with the actual tuning.<br>\n`study.optimize` can be configured **by time limitation using `timeout`**, instead of number of trials `n_trials`. It is convinient for kaggle kernel.","10744244":"# Optuna tutorial for begginers: hyperparameter optimization framework\n\nWhen I try building a model (XGBoost, LightGBM, CatBoost, Neural Network etc...), I always face an issue of how to tune these hyperparameters?<br>\nSome people may be trying to set parameters manually to see if the score improves or not.\n\n**In this tutorial, I will introduce [optuna](https:\/\/optuna.org\/), *Define-by-Run Hyperparameter Optimization Framework* for automated hyperparameter tuning.**\n\n**<p style=\"color:red\">UPDATE: added <a href=\"#id6\">6. Visualize study history to analayze the hyperparams-performance relationship<\/a> section, please check!!!<\/p>**","740a73a6":"<a id=\"id0\"><\/a>\n# Data preprocessing\n\nNow, Let's try building GBDT (Gradient Boost Decision Tree) model to predict `meter_reading_log1p`. I will try using LightGBM in this notebook.\n\n\n[UPDATE]\n - Processing of 'weekend'\n - Take building stats by building_id **and meter type**\n - Align timestamp in weather data, by@nz0722 https:\/\/www.kaggle.com\/nz0722\/aligned-timestamp-lgbm-by-meter-type","881ce965":"Another tips: If you want to see all the history of trials, you can get `pandas.DataFrame` format by calling `study.trials_dataframe()`.","5c73f507":"When running the training again with specific hyperparameters, we can use `FixedTrial` object to reuse `objective` function which we defined before.<br>\n`FixedTrial` object always returns fixed value, so we can run with `best_params`.","7e43fdbf":"<a id=\"id6\"><\/a>\n# 6. Visualize study history to analayze the hyperparams-performance relationship\n\nSince we have history of trials, we can analyze how each hyperparams affects to the performance.<br>\nAll the visualization below can be done in just one line!!!\n\n(Acknowledgement: thank you @shotaro for let me know this feature)","d4c049ec":"<a id=\"id10\"><\/a>\n# More to go\n\n## Other features...\n\nThat's all for this tutorial. However `optuna` further provides other useful functionality.\n\n - Store trial information in Relational Database (SQLite, PostgreSQL, MySQL) rather than on memory, to save hyperparameter search history.\n - Parallel distributed optimization: you can run several process at the same time to asyncronously search hyperparameters with many CPUs in parallel.\n\nSee Official document, github for details!\n\n - [web site](https:\/\/optuna.org\/)\n - [github: pfnet\/optuna](https:\/\/github.com\/pfnet\/optuna)\n - [document](https:\/\/optuna.readthedocs.io\/en\/latest\/)\n\n**Recently LightGBMTuner is introduced (See [this PR#549](https:\/\/github.com\/pfnet\/optuna\/pull\/549)), maybe it is quite interesting to try!**\n\nIf this kernel helps you, please upvote to keep me motivated \ud83d\ude01<br>Thanks!","7990db81":"<a id=\"id5\"><\/a>\n# 5. Check study history to get best hyperparameters\n\nNow we've done hyperparameter optimization. So we want to know the best hyperparameters.<br>\nWhole `trial` history is managed in `study` object, we can get best trial by **`study.best_trial`**","15d47d22":"# Table of Contents:\n\nBelow code forked and a bit modified from [ASHRAE: Training LGBM by meter type](https:\/\/www.kaggle.com\/corochann\/ashrae-training-lgbm-by-meter-type) kernel (taken from version 25) until data preprocessing.<br>\nPlease jump to **[1. Define objective function](#id1)** to start learning optuna usage!\n\n**[ASHRAE - Great Energy Predictor III](#title)** <br>\n**[Data Preprocessing](#id0)** <br>\n**[1. Define \"objective\" function](#id1)** <br>\n**[2. Use \"trial\" module to define hyperparameters dynamically!](#id2)** <br>\n**[3. Make \"study\" and let optimize!](#id3)** <br>\n**[4. [Advanced] Pruning unpromising trials for more faster search](#id4)** <br>\n**[5. Check study history to get best hyperparameters](#id5)** <br>\n**[6. Visualize study history to analayze the hyperparams-performance relationship](#id6)** <br>\n**[More to go](#id10)** <br>","3a5599ad":"## Add time feature","f95e8d75":"## Fast data loading\n\nThis kernel uses the preprocessed data from my previous kernel, [\nASHRAE: feather format for fast loading](https:\/\/www.kaggle.com\/corochann\/ashrae-feather-format-for-fast-loading), to accelerate data loading!","8f6fed56":"## Optimization history\n\nIt is a best score's history, blue dot is the score of this trial and orange line show the best score.<br>\nNote that blue dot is not in the all trial, because we turned on pruning thus many of the trials are stopped before getting final objective value."}}