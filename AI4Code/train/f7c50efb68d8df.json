{"cell_type":{"4ef35768":"code","6e40ef7b":"code","f0d6662e":"code","1f9b2911":"code","495380f0":"code","2f0840ba":"code","ba2dd807":"code","fa49f6aa":"code","1cad982f":"code","6f98d6d8":"code","4e9776a2":"code","c0f4d3e5":"code","58870d34":"code","587d51e6":"code","82083c50":"code","ae167131":"code","14aa11a0":"code","305b7cab":"code","4b13d803":"code","12a2a34c":"code","9c86728e":"code","0928232f":"markdown","24f36089":"markdown","e3ef7ecc":"markdown","a78a0c05":"markdown","9835ad35":"markdown","3bedd009":"markdown","cc9f39dd":"markdown","54d81fb4":"markdown","c05cad73":"markdown","7e11cab3":"markdown","5f5384f5":"markdown","283f983b":"markdown","ed9e23aa":"markdown","961598d3":"markdown","2603795f":"markdown","de262ffe":"markdown","5208855e":"markdown","d54318dd":"markdown","60946334":"markdown","6c5aeb72":"markdown","c84a4f52":"markdown","5ce233f4":"markdown","4eb3a918":"markdown","0e2d6c1d":"markdown","85d7bfa0":"markdown","8e70c575":"markdown"},"source":{"4ef35768":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6e40ef7b":"df = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\n#The data has a column called  'Unnamed: 32' with nothing but NaN values.\ndf.drop(['Unnamed: 32'], axis = 1, inplace = True)\ndf.head()","f0d6662e":"print(df.isnull().sum().sum())\nprint(df.shape)","1f9b2911":"df['diagnosis'].replace({'B' : 0, 'M' : 1}, inplace = True)\ndf['diagnosis'].value_counts()","495380f0":"# Allocating 69 rows to the test data and rest to the train data. \ndf_train = df.iloc[:500]\ndf_test = df.iloc[500:]\n\n# Re-indexing of the test data\ndf_test.reset_index(inplace = True)\ndf_test.drop('index', axis = 1,inplace = True)","2f0840ba":"df_corr = df_train.corr()\ndf_corr = df_corr.where(abs(df_corr['diagnosis']) > 0.5)\ndf_corr.dropna(inplace=True)\ncols_to_drop = df_corr.columns.drop(df_corr.index.drop('diagnosis'))\ndf_corr.drop(columns = cols_to_drop, inplace = True)\nprint(\"Important features  are - \", df_corr.columns.values)","ba2dd807":"#defining the features\nfeatures = ['radius_mean', 'concave points_mean', 'radius_se', 'radius_worst', 'concave points_worst']","fa49f6aa":"from sklearn.preprocessing import StandardScaler\nX = df_train[features]\ny = df_train.diagnosis\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","1cad982f":"X_test = df_test[features]\ny_test = df_test.diagnosis\nscale = StandardScaler()\nX_test_scaled = scale.fit_transform(X_test)","6f98d6d8":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\n\n#developing baseline model\nRF_model = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 7, n_jobs = -1)\nscores = cross_val_score(RF_model, X_scaled, y, cv = 5, scoring = 'f1')\nscores.mean()*100","4e9776a2":"#hyperparamter tuning\nfor n_est in [200,400,600,800]:\n    for m_d in [5,6,7,8,12]:\n        RF_model = RandomForestClassifier(n_estimators = n_est, max_depth = m_d, random_state = 7, n_jobs = -1)\n        scores = cross_val_score(RF_model, X_scaled, y, cv = 5, scoring = 'f1')\n        print('estimators = ',n_est,\" max depth = \",m_d,\" score = \",scores.mean()*100)","c0f4d3e5":"#developing the optimized model\nRF_model = RandomForestClassifier(n_estimators = 600, max_depth = 10, random_state = 7, n_jobs = -1)\nRF_model.fit(X,y)\nscores = cross_val_score(RF_model, X_scaled, y, cv = 5, scoring = 'f1')\nscores.mean()*100","58870d34":"from sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#developing baseline model\nknn_model = KNeighborsClassifier(n_neighbors = 5, leaf_size = 20, n_jobs = -1)\nscores = cross_val_score(knn_model, X_scaled, y, cv = 5, scoring = 'f1')\nscores.mean()*100","587d51e6":"#hyperparameter tuning\nfor ne in [4,5,6,7,8,9,10]:\n    for ls in [10,20,30,40,50,60,80]:\n        knn_model = KNeighborsClassifier(n_neighbors = ne, leaf_size = ls, n_jobs = -1)\n        scores = cross_val_score(knn_model, X_scaled, y, cv = 5, scoring = 'f1')\n        print('n_neighbors = ', ne, ' leaf_size = ', ls, 'score = ', scores.mean()*100)            ","82083c50":"#developing the optimized model\nknn_model = KNeighborsClassifier(n_neighbors = 5, leaf_size = 20, n_jobs = -1)\nscores = cross_val_score(knn_model, X_scaled, y, cv = 5, scoring = 'f1')\nscores.mean()*100","ae167131":"from sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\n#developing the baseline model and tuning it\nfor c in [0.1,0.2,0.3,0.4,0.5,1]:\n    LoReg_model = LogisticRegression(C = c, random_state = 3, n_jobs = -1)\n    scores = cross_val_score(LoReg_model, X_scaled ,y , cv=5, scoring='f1')\n    print(scores.mean()*100)","14aa11a0":"#developing the optimized model\nLoReg_model = LogisticRegression(C = 0.5, random_state = 3, n_jobs = -1)\nscores = cross_val_score(LoReg_model, X_scaled ,y , cv=5, scoring='f1')\nscores.mean()*100","305b7cab":"#Fit the final model on the train data\nfinal_model = RandomForestClassifier(n_estimators = 600, max_depth = 10, random_state = 7, n_jobs = -1)\nfinal_model.fit(X_scaled, y);","4b13d803":"#Scoring on test data\ny_true = y_test\ny_pred = final_model.predict(X_test_scaled)","12a2a34c":"#defining labels for prognosis\nlabels = ['Benign', 'Malignant']\n\n#using yellowbricks Classification Report\nfrom yellowbrick.classifier import ClassificationReport\n\nreport = ClassificationReport(final_model, size=(480,240), classes = labels, cmap = 'PuBu')\nreport.score(X_test_scaled, y_test)\nreport.show()  ","9c86728e":"#using yellowbrick class prediction error\nfrom yellowbrick.classifier import ClassPredictionError\n\nerror = ClassPredictionError(final_model, size=(540,360), classes = labels)\nerror.score(X_test_scaled, y_test)\nerror.show()","0928232f":"* Logistic Regression and hyperparamter tuning","24f36089":"This code snippet tunes 20 values. Hence it might take a few mins to run.... The optimized hyper-paramters will be displayed on the next cell... ","e3ef7ecc":"The dataset used is the very popular Wisconsin Cancer dataset. The link to the data is - https:\/\/www.kaggle.com\/uciml\/breast-cancer-wisconsin-data.\nThe data has been licensed under CC BY-NC-SA 4.0. Details about the license can be found at - https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/.\n\nThe author of the dataset, in no way endorses this project of mine.","a78a0c05":"### Inferences and Report on the Test data","9835ad35":"From the above tuned models, it can be seen that, all of the models have a similar f1 score around 92. The f1_score is higher because of the earlier feature selection we performed. To finalize the model, I will be using the Random Forest Classifer. This is because, Random Forest is an ensemble classifier and it generally works better with un-seen data i.e. test data.","3bedd009":"### Normalizing the data","cc9f39dd":"With a slightly tuned Logistic Regression Classifier, we get a f1_score of 92.45%","54d81fb4":"The tuned hyperparameter is C = 0.5","c05cad73":"* K-Nearest Neighbour Classification and hyperparameter tuning","7e11cab3":"### Identifying target variable and encoding it to support Classification.\nThe target variable is the 'diagnosis' column which classifies the cancerous tumour as Malignant(M) or Benign(B). Malignant tumours are cancerous whereas Benign aren't. \n","5f5384f5":"### Performing preliminary EDA","283f983b":"* Random Forest Classification and hyperparameter tuning","ed9e23aa":"With a tuned RandomForest ensemble model, we get a f1 score of 92.26%","961598d3":"**Note - It is important to note that in Regression and Classification models, the features should be independent of each other. This ensures better fitting and less chances of errors.** \n\nHence only one feature is selcted from each set of mean,se and worst values.","2603795f":"The data has 569 rows of patient data with 32 features. The data also has no missing values.","de262ffe":"### Classification model(s)","5208855e":"### Feature Analysis","d54318dd":"Tuned hyperparameters are - 5 and 20 respectively, which is the baseline model itself.","60946334":"### Reading the data","6c5aeb72":"The model has been trained on a data of 500 rows and tested on a smaller data of 69 rows. From the yellowbrick analysis of test data, it can be ascertained that the model has performed well with the previously unseen test data. Owing to the small size of the test data, the following results can't be generalized.\n\nFor the class label Benign, i.e. non cancerous tumours, the model always predicts correctly and hence has a precision of 100%. However, for the class label Malignant, i.e. actual cancerous tumours, the model most of the time predicts correctly. It has a precision of 0.8%. \n\n------------------","c84a4f52":"### Analysis on Test Data (with yellowbrick)","5ce233f4":"## Breast Cancer Prediction using the Wisconsin Cancer Dataset","4eb3a918":"Using co-relation matrix to identify important features","0e2d6c1d":"Optimized Hyperparamters are - 600 and 10 respectively.","85d7bfa0":"### Splitting the data into train and test set.\n\nThe test set is for final check of the accuracy metric used. Validation of the data will be done on the test data itself using cross validation.  ","8e70c575":"With a tuned KNN model we get an f1 score of 92.25%."}}