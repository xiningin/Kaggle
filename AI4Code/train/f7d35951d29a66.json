{"cell_type":{"c01fe93f":"code","e7f87548":"code","024a5a0a":"code","cdf53647":"code","5050efb1":"code","88fc5944":"code","4d642bfa":"code","5c43a204":"code","c028f64f":"code","e6132b38":"code","a58d1b6a":"code","34e9cfef":"code","5d18dba4":"code","45223eba":"code","5b20bf24":"code","22188e10":"code","f7a9c04e":"code","d74f6777":"code","c538ffe9":"code","0f78145f":"code","5676a31a":"code","58687e94":"code","1fe4606c":"code","c818155e":"code","3a061bfc":"code","d589ef45":"code","bdf78e05":"code","c6ea073a":"code","eb511046":"code","21cecd96":"code","495d3e52":"code","d6f8ea8b":"code","178aff84":"code","34572843":"code","da8256cf":"code","5926a962":"code","822c085b":"code","ecdd178d":"code","06dda627":"code","ef804b29":"code","d8dc39f7":"code","c76e451d":"code","66fc0242":"code","c7bda00e":"code","d3cfb253":"code","605acb62":"code","a9866c61":"code","1e23563f":"code","d804e4fa":"code","1fa925e3":"code","d236ae50":"code","a16571cb":"code","be471c63":"code","bf6f5452":"code","304cba7e":"code","2d7ffa6c":"markdown","79a2eea1":"markdown","d84fe845":"markdown","f2ed9b0d":"markdown","5f6142ad":"markdown","64b000ba":"markdown","eb8c4d5f":"markdown","2a47a473":"markdown","4ca56f75":"markdown","a8864529":"markdown","b0e89fbf":"markdown"},"source":{"c01fe93f":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nplt.style.use('fivethirtyeight') # For plots","e7f87548":"import pandas as pd\ntrain = pd.read_csv(\"..\/input\/application-train\/train.csv\")","024a5a0a":"train['application_date']=train['application_date'].astype('datetime64')","cdf53647":"train1=train[train['segment']==1].groupby(['application_date'])['case_count'].sum().reset_index()","5050efb1":"train2=train[train['segment']==2].groupby(['application_date'])['case_count'].sum().reset_index()","88fc5944":"import seaborn as sns\nsns.boxplot('case_count',data=train1)\nQ1 = train1['case_count'].quantile(0.25)\nQ3 = train1['case_count'].quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","4d642bfa":"train1 = train1[~((train1['case_count'] < (Q1 - 1.5 * IQR)) |(train1['case_count'] > (Q3 + 1.5 * IQR)))]","5c43a204":"train1","c028f64f":"def create_features(df, label=None):\n    \"\"\"\n    Creates time series features from application_datetime index.\n    \"\"\"\n    df = df.copy()\n  \n    df['dayofweek'] = df['application_date'].dt.dayofweek\n    df['quarter'] = df['application_date'].dt.quarter\n    df['month'] = df['application_date'].dt.month\n    df['year'] = df['application_date'].dt.year\n    df['dayofyear'] = df['application_date'].dt.dayofyear\n    df['dayofmonth'] = df['application_date'].dt.day\n    df['weekofyear'] = df['application_date'].dt.weekofyear\n    \n    X = df[['dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X\n\nX, y = create_features(train1, label='case_count')\n\nfeatures_and_target = pd.concat([X, y], axis=1)","e6132b38":"X, y = create_features(train2, label='case_count')\nfeatures_and_target1 = pd.concat([X, y], axis=1)","a58d1b6a":"features_and_target['ds']=train1['application_date'].astype('datetime64')","34e9cfef":"features_and_target1['ds']=train2['application_date'].astype('datetime64')","5d18dba4":"# See our features and target\n\nfeatures_and_target=features_and_target.rename({'case_count':'y'},axis=1)\nfeatures_and_target1=features_and_target1.rename({'case_count':'y'},axis=1)","45223eba":"features_and_target","5b20bf24":"\npjme_train = features_and_target[:600].copy()\npjme_test = features_and_target[600:].copy()\npjme_train1 = features_and_target1[:600].copy()\npjme_test1 = features_and_target1[600:].copy()","22188e10":"features_and_target.columns","f7a9c04e":"exogenous_features=['dayofweek', 'quarter', 'month', 'year', 'dayofyear', 'dayofmonth',\n       'weekofyear']","d74f6777":"model=Prophet()\nfor feature in exogenous_features:\n     model.add_regressor(feature)","c538ffe9":"\nmodel.fit(pjme_train[[\"ds\", \"y\"] + exogenous_features])","0f78145f":"model1 = Prophet()\nfor feature in exogenous_features:\n     model1.add_regressor(feature)\nmodel1.fit(pjme_train1[[\"ds\", \"y\"] + exogenous_features])","5676a31a":"# Predict on training set with model\npjme_test_fcst = model.predict(pjme_test)","58687e94":"pjme_test_fcst1=model1.predict(pjme_test1)","1fe4606c":"pjme_test_fcst.head()","c818155e":"# Plot the forecast\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nfig = model.plot(pjme_test_fcst,\n                 ax=ax)\nplt.show()","3a061bfc":"# Plot the components of the model\nfig = model.plot_components(pjme_test_fcst)","d589ef45":"mean_squared_error(y_true=pjme_test['y'],\n                   y_pred=pjme_test_fcst['yhat'])","bdf78e05":"mean_absolute_error(y_true=pjme_test['y'],\n                   y_pred=pjme_test_fcst['yhat'])","c6ea073a":"def mean_absolute_percentage_error(y_true, y_pred): \n    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\nmean_absolute_percentage_error(y_true=pjme_test['y'],\n                   y_pred=pjme_test_fcst['yhat'])","eb511046":"mean_absolute_percentage_error(y_true=pjme_test1['y'],\n                   y_pred=pjme_test_fcst1['yhat'])","21cecd96":"!pip install holidays","495d3e52":"import holidays\nholidays=pd.DataFrame({'ds':list(holidays.IND(years=[2017,2018,2019,2020]).keys()),'holiday':list(holidays.IND(years=[2017,2018,2019,2020]).values())})","d6f8ea8b":"\nmodel_with_holidays = Prophet(holidays=holidays)\nfor feature in exogenous_features:\n    model_with_holidays.add_regressor(feature)\nmodel_with_holidays.fit(pjme_train[[\"ds\", \"y\"] + exogenous_features])\n# Setup and train model with holidaysmodel = Prophet()","178aff84":"# Predict on training set with model\npjme_test_fcst_with_hols = \\\n    model_with_holidays.predict(pjme_test)","34572843":"fig2 = model_with_holidays.plot_components(pjme_test_fcst_with_hols)","da8256cf":"mean_squared_error(y_true=pjme_test['y'],\n                   y_pred=pjme_test_fcst_with_hols['yhat'])","5926a962":"mean_absolute_error(y_true=pjme_test['y'],\n                   y_pred=pjme_test_fcst_with_hols['yhat'])","822c085b":"def mean_absolute_percentage_error(y_true, y_pred): \n    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\nmean_absolute_percentage_error(y_true=pjme_test['y'],\n                   y_pred=pjme_test_fcst_with_hols['yhat'])","ecdd178d":"pjme_test_fcst_with_hols[pjme_test_fcst_with_hols['yhat']<0]","06dda627":"test = pd.read_csv(\"..\/input\/test-data\/test.csv\")\ntest1=test[test['segment']==1].copy()\ntest2=test[test['segment']==2].copy()\ntest1['application_date']=test1['application_date'].astype('datetime64')\ntest2['application_date']=test2['application_date'].astype('datetime64')","ef804b29":"def create_features(df, label=None):\n    \"\"\"\n    Creates time series features from application_datetime index.\n    \"\"\"\n    df = df.copy()\n  \n    df['dayofweek'] = df['application_date'].dt.dayofweek\n    df['quarter'] = df['application_date'].dt.quarter\n    df['month'] = df['application_date'].dt.month\n    df['year'] = df['application_date'].dt.year\n    df['dayofyear'] = df['application_date'].dt.dayofyear\n    df['dayofmonth'] = df['application_date'].dt.day\n    df['weekofyear'] = df['application_date'].dt.weekofyear\n    \n    X = df[['dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X\n\nX= create_features(test1)\n\n","d8dc39f7":"test1","c76e451d":"X1= create_features(test2)","66fc0242":"X1","c7bda00e":"test2","d3cfb253":"X['ds']=test1['application_date'].astype('datetime64')\nX1['ds']=test2['application_date'].astype('datetime64')","605acb62":"predict=model.predict(X)","a9866c61":"predict1=model.predict(X1)","1e23563f":"predict[predict['yhat']<0]","d804e4fa":"predict1[predict1['yhat']<0]","1fa925e3":"final=pd.concat([predict,predict1])","d236ae50":"final","a16571cb":"test","be471c63":"final=final.reset_index()","bf6f5452":"test['case_count']=final['yhat']\n\n","304cba7e":"test.to_csv('submission.csv',index=False)","2d7ffa6c":"## Plotting the Features to see trends\n- Power demand has strong daily and seasonal properties.\n- Day of week also seems to show differences in peaks","79a2eea1":"# Train\/Test Split\nCut off the data after 2015 to use as our validation set. We will train on earlier data.","d84fe845":"# Error Metrics\n\nOur RMSE error is 43761675  \nOur MAE error is 5181.78  \nOur MAPE error is 16.5%\n\nby comparison in the XGBoost model our errors were significantly less (8.9% MAPE):\n[Check that out here](https:\/\/www.kaggle.com\/robikscube\/hourly-time-series-forecasting-with-xgboost\/)","f2ed9b0d":"## Plot Holiday Effect","5f6142ad":"## Predict With Holidays","64b000ba":"# Adding Holidays\nNext we will see if adding holiday indicators will help the accuracy of the model. Prophet comes with a *Holiday Effects* parameter that can be provided to the model prior to training. \n\nWe will use the built in pandas `USFederalHolidayCalendar` to pull the list of holidays","eb8c4d5f":"# Error Metrics with Holidays Added\nSuprisingly the error has gotten worse after adding holidays.","2a47a473":"# Look at first month of predictions","4ca56f75":"# Simple Prophet Model\n- Prophet model expects the dataset to be named a specific way. We will rename our dataframe columns before feeding it into the model.","a8864529":"# Compare Forecast to Actuals","b0e89fbf":"# Data\nThe data we will be using is hourly power consumption data from PJM. Energy consumtion has some unique charachteristics. It will be interesting to see how prophet picks them up.\n\nPulling the `PJM East` which has data from 2002-2018 for the entire east region."}}