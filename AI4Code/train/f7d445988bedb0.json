{"cell_type":{"e9ebe410":"code","29f02fb8":"code","8d9f9682":"code","8dc1d6aa":"code","d761a6b8":"code","d180d520":"code","773348a0":"code","87dc2a14":"code","81dc774a":"code","215ed3d2":"code","3203d3f4":"code","6aad8c56":"code","7cca6700":"code","fa3c257d":"code","7b421b78":"code","a798a34e":"markdown","18964e4a":"markdown","0d496422":"markdown","6f2cd5b4":"markdown","f95e71d9":"markdown","7ad37e2c":"markdown","84552c92":"markdown","4750fc52":"markdown","b7d4d640":"markdown","224af0e6":"markdown","6d5c6495":"markdown","a9774a49":"markdown","b7d2ac66":"markdown","fdb8016b":"markdown","43d73daa":"markdown","5c2bc6a5":"markdown","925aa17d":"markdown","75d599e7":"markdown"},"source":{"e9ebe410":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","29f02fb8":"# Importing tools for preprocessing and feature engineering of the data:\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom category_encoders import CatBoostEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\n# Importing plotting tools to plot the data:\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Importing Algorithms so that I can train the data:\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Importing a loss tool to check how well our algorithms is doing:\nfrom keras.losses import mean_absolute_percentage_error\n","8d9f9682":"data = pd.read_csv(\"..\/input\/predict-demand\/train.csv\")\ndata.head()","8dc1d6aa":"data.isnull().sum()","d761a6b8":"dropdata = data.dropna()","d180d520":"y = dropdata['quantity']\n\ndropdata.drop(['quantity', 'id'], inplace=True, axis=1)","773348a0":"sns.set_context(\"poster\", font_scale=.7)\nplt.figure(figsize=(7,7))\nsns.set_palette('RdYlBu')\nsns.countplot(dropdata['city'])","87dc2a14":"sns.set_palette('PiYG')\nplt.figure(figsize=(10,10))\nsns.set_context(\"poster\", font_scale=0.7)\nsns.countplot(dropdata['shop'])","81dc774a":"sns.set_palette('RdPu')\nplt.figure(figsize=(10,10))\nsns.set_context(\"poster\", font_scale=0.7)\nsns.scatterplot(data = dropdata, y='price', x=y, hue='capacity')","215ed3d2":"sns.set_palette('YlOrRd')\nplt.figure(figsize=(10,10))\nsns.set_context(\"poster\", font_scale=0.7)\nsns.countplot(dropdata['brand'])","3203d3f4":"c = (data.dtypes == 'object')\ncategorical_col = list(c[c].index)","6aad8c56":"enc = CatBoostEncoder()\nenc.fit(dropdata[categorical_col], y)\ndropdata[categorical_col] = enc.transform(dropdata[categorical_col])","7cca6700":"xtrain, xtest, ytrain, ytest = train_test_split(dropdata, y, train_size=0.9, test_size=0.1)","fa3c257d":"xgmodel = XGBRegressor(n_estimators=1000)\n\nxgmodel.fit(xtrain, ytrain)\n\nxgPreds = xgmodel.predict(xtest)\n\n","7b421b78":"print('The Mean Accuracy for XGBoost Regressor model is,', 100 - mean_absolute_percentage_error(ytest, xgPreds), '%')","a798a34e":"Yep it does :(","18964e4a":"Reading the data:\n","0d496422":"# Importing the libraries:","6f2cd5b4":"Finally splitting the data:","f95e71d9":"# Preprocessing:","7ad37e2c":"Here is the countplot for the brands:","84552c92":"Training, fitting and predicting on the data using XGBoost:","4750fc52":"# Predicting:","b7d4d640":"Checking if our data has NaN values:","224af0e6":"Lets see the relation between the quanity sold and the prices:","6d5c6495":"Defining the labels to predict on:","a9774a49":"Finding the categorical columns in our dataset's index:","b7d2ac66":"# Data Visualisation:\n","fdb8016b":"Dropping the rows with NaN values:","43d73daa":"Thank you for going through this notebook I am glad you made it all the way down here! ","5c2bc6a5":"Replacing the categorical values with numerical probabilities of them happening:\n","925aa17d":"Lets take a look at the dustribution of sales across the various shops:","75d599e7":"Lets try plotting the demand in various cities:"}}