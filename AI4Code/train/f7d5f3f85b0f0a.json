{"cell_type":{"bd0c330a":"code","35016d70":"code","4b07937e":"code","b5e73e23":"code","a700b1b8":"code","5b297ee4":"code","9ad48e53":"code","80f46281":"code","3aed6e9f":"code","62050544":"code","eb71d0b5":"code","5218f281":"code","8740d311":"code","99575c06":"code","1fc79a2b":"code","8f5f29ef":"code","23173f2e":"code","25718504":"code","6a13b4e7":"code","5d279b05":"code","b83617ce":"code","d21a607a":"code","72556b5e":"code","1e8646c0":"code","628210cc":"code","21267d89":"code","48c57e35":"code","b8c65b58":"code","bd66598d":"code","ca2ec195":"code","701c4208":"code","9cc11f3a":"code","c51bf193":"code","9af27eaa":"code","460ab433":"code","457b7486":"code","1f16a9b6":"code","ec5f6997":"code","d4fae96a":"code","c0eca5b1":"code","82e80b11":"code","0317ae41":"code","c4da2e92":"code","214ac5d7":"code","006d25e2":"code","16a1e1cc":"code","f8849cec":"code","674401ef":"code","bc01701d":"code","ddfa26aa":"code","9c19b3fd":"code","ed3bd01c":"code","f26a97ed":"code","929c6b7f":"code","7d813bce":"code","7d6de99d":"markdown","876ddea1":"markdown","c1e4a620":"markdown","72befa9d":"markdown","22b9e2d0":"markdown","9231b728":"markdown","0ff37578":"markdown","6be9a751":"markdown","5bbe6185":"markdown","7d0a7be4":"markdown","e70ca867":"markdown","e98eae0c":"markdown","7f068b44":"markdown","eeaf98e4":"markdown"},"source":{"bd0c330a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as plt\nimport numpy as np\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","35016d70":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_train.head()","4b07937e":"df_train.head().T","b5e73e23":"df_train.info()","a700b1b8":"df_train.isnull().any()","5b297ee4":"df_train.isnull().sum()","9ad48e53":"## Para Age, preencher os espa\u00e7oes com a m\u00e9dia das idades:\nnp.mean(df_train['Age'])\ndf_train['Age'].fillna(value = 29, inplace = True)","80f46281":"## Para 'Embarked', preencher NaN com o valor mais comum:\ndf_train['Embarked'].describe()\ndf_train['Embarked'] = df_train['Embarked'].fillna(value = 'S')","3aed6e9f":"## Para 'Cabin', a coluna ser\u00e1 retirada, pois h\u00e1 muitos valores faltantes\n\ndf_train = df_train.drop(columns=['Cabin'])","62050544":"df_train.isnull().sum()","eb71d0b5":"## Name, Sex, Ticket, Embarked\n## Tratar o tipo de dado de Fare\ndf_train.info()","5218f281":"## Converter Sex para num\u00e9rico\ndf_train['Sex'] = df_train['Sex'].map({\"male\": 0, \"female\": 1})","8740d311":"## Categorizar Embarked\ndf_train['Embarked'] = df_train['Embarked'].map({\"S\": 0, \"C\": 1, \"Q\": 2})","99575c06":"## Covnerter Fate de float64 para int64\n\ndf_train['Fare'] = df_train['Fare'].fillna(0)\ndf_train['Fare'] = df_train['Fare'].astype(int)","1fc79a2b":"df_train","8f5f29ef":"### Dropar PassengerID\ndf_train = df_train.drop(['PassengerId'], axis=1)","23173f2e":"### Dropar Name\ndf_train = df_train.drop(['Name'], axis=1)","25718504":"### Dropar Ticket\ndf_train = df_train.drop(['Ticket'], axis=1)","6a13b4e7":"## Criar categoria para a Idade\n\ndf_train['Age'] = df_train['Age'].astype(int)\ndf_train.loc[ df_train['Age'] <= 11, 'Age'] = 0\ndf_train.loc[(df_train['Age'] > 11) & (df_train['Age'] <= 18), 'Age'] = 1\ndf_train.loc[(df_train['Age'] > 18) & (df_train['Age'] <= 22), 'Age'] = 2\ndf_train.loc[(df_train['Age'] > 22) & (df_train['Age'] <= 27), 'Age'] = 3\ndf_train.loc[(df_train['Age'] > 27) & (df_train['Age'] <= 33), 'Age'] = 4\ndf_train.loc[(df_train['Age'] > 33) & (df_train['Age'] <= 40), 'Age'] = 5\ndf_train.loc[(df_train['Age'] > 40) & (df_train['Age'] <= 66), 'Age'] = 6\ndf_train.loc[ df_train['Age'] > 66, 'Age'] = 6\n\ndf_train['Age'].value_counts()","5d279b05":"## Criar categoria para Fare\n\ndf_train.loc[ df_train['Fare'] <= 7.91, 'Fare'] = 0\ndf_train.loc[(df_train['Fare'] > 7.91) & (df_train['Fare'] <= 14.454), 'Fare'] = 1\ndf_train.loc[(df_train['Fare'] > 14.454) & (df_train['Fare'] <= 31), 'Fare']   = 2\ndf_train.loc[(df_train['Fare'] > 31) & (df_train['Fare'] <= 99), 'Fare']   = 3\ndf_train.loc[(df_train['Fare'] > 99) & (df_train['Fare'] <= 250), 'Fare']   = 4\ndf_train.loc[ df_train['Fare'] > 250, 'Fare'] = 5\ndf_train['Fare'] = df_train['Fare'].astype(int)\n\ndf_train['Fare'].value_counts()","b83617ce":"df_train","d21a607a":"sns.heatmap(df_train.corr(),annot=True,linewidths=0.2) #data.corr()-->correlation matrix","72556b5e":"df_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_test.head()","1e8646c0":"df_test.info()","628210cc":"df_test.isnull().sum()","21267d89":"## Para 'Cabin', a coluna ser\u00e1 retirada, pois h\u00e1 muitos valores faltantes\ndf_test = df_test.drop(columns=['Cabin'])","48c57e35":"## Para Age, preencher os espa\u00e7oes com a m\u00e9dia das idades:\nnp.mean(df_test['Age'])\ndf_test['Age'].fillna(value = 29, inplace = True)","b8c65b58":"## Categorizar Embarked\ndf_test['Embarked'] = df_test['Embarked'].map({\"S\": 0, \"C\": 1, \"Q\": 2})","bd66598d":"## Covnerter Fate de float64 para int64\ndf_test['Fare'] = df_test['Fare'].fillna(0)\ndf_test['Fare'] = df_test['Fare'].astype(int)","ca2ec195":"## Converter Sex para num\u00e9rico\ndf_test['Sex'] = df_test['Sex'].map({\"male\": 0, \"female\": 1})","701c4208":"### Dropar Name\ndf_test = df_test.drop(['Name'], axis=1)","9cc11f3a":"### Dropar Ticket\ndf_test = df_test.drop(['Ticket'], axis=1)","c51bf193":"## Criar categoria para a Idade\n\ndf_test['Age'] = df_test['Age'].astype(int)\ndf_test.loc[ df_test['Age'] <= 11, 'Age'] = 0\ndf_test.loc[(df_test['Age'] > 11) & (df_test['Age'] <= 18), 'Age'] = 1\ndf_test.loc[(df_test['Age'] > 18) & (df_test['Age'] <= 22), 'Age'] = 2\ndf_test.loc[(df_test['Age'] > 22) & (df_test['Age'] <= 27), 'Age'] = 3\ndf_test.loc[(df_test['Age'] > 27) & (df_test['Age'] <= 33), 'Age'] = 4\ndf_test.loc[(df_test['Age'] > 33) & (df_test['Age'] <= 40), 'Age'] = 5\ndf_test.loc[(df_test['Age'] > 40) & (df_test['Age'] <= 66), 'Age'] = 6\ndf_test.loc[ df_test['Age'] > 66, 'Age'] = 6\n\ndf_test['Age'].value_counts()","9af27eaa":"## Criar categoria para Fare\n\ndf_test.loc[ df_test['Fare'] <= 7.91, 'Fare'] = 0\ndf_test.loc[(df_test['Fare'] > 7.91) & (df_test['Fare'] <= 14.454), 'Fare'] = 1\ndf_test.loc[(df_test['Fare'] > 14.454) & (df_test['Fare'] <= 31), 'Fare']   = 2\ndf_test.loc[(df_test['Fare'] > 31) & (df_test['Fare'] <= 99), 'Fare']   = 3\ndf_test.loc[(df_test['Fare'] > 99) & (df_test['Fare'] <= 250), 'Fare']   = 4\ndf_test.loc[ df_test['Fare'] > 250, 'Fare'] = 5\ndf_test['Fare'] = df_test['Fare'].astype(int)","460ab433":"df_test['Fare'].value_counts()","457b7486":"sns.heatmap(df_test.corr(),annot=True,linewidths=0.2) #data.corr()-->correlation matrix","1f16a9b6":"df_test","ec5f6997":"df_train","d4fae96a":"# Modelos:\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\n#train_test_split\nfrom sklearn.model_selection import train_test_split\n#metrics\nfrom sklearn.metrics import confusion_matrix,accuracy_score","c0eca5b1":"X = df_train.drop('Survived',axis=1)\ny = df_train['Survived']","82e80b11":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2,random_state = 10)\n","0317ae41":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\nY_pred_reg = logreg.predict(X_test)\n\nacc_log = accuracy_score(y_test, Y_pred_reg)\nprint('Acur\u00e1cia Regress\u00e3o log\u00edstica: {} '.format(acc_log))","c4da2e92":"gaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\nY_pred_gau = gaussian.predict(X_test)\nacc_gaussian = accuracy_score(y_test, Y_pred_gau)\nprint('Acur\u00e1cia Gaussian NB: {} '.format(acc_gaussian))","214ac5d7":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\n\nY_pred_rf = random_forest.predict(X_test)\n\n\nacc_random_forest = accuracy_score(y_test, Y_pred_rf)\nprint('Acur\u00e1cia Random Forest: {}'.format(acc_random_forest))","006d25e2":"results = pd.DataFrame({\n    'Model': ['Logistic Regression','Naive Bayes', 'Random Forest'],\n    'Score': [acc_log, acc_gaussian, acc_random_forest]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head()\n","16a1e1cc":"from sklearn.model_selection import cross_val_score","f8849cec":"logreg = LogisticRegression()\nscores = cross_val_score(logreg, X, y, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","674401ef":"gaussian = GaussianNB()\nscores = cross_val_score(gaussian, X, y, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","bc01701d":"random_forest = RandomForestClassifier(n_estimators=100)\nscores = cross_val_score(random_forest, X, y, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","ddfa26aa":"print('Matriz de confus\u00e3o LogReg')\nprint(confusion_matrix(y_test,Y_pred_reg))","9c19b3fd":"print('Matriz de confus\u00e3o GaussianNB')\nprint(confusion_matrix(y_test,Y_pred_gau))","ed3bd01c":"print('Matriz de confus\u00e3o Random Forest Classifier')\nprint(confusion_matrix(y_test,Y_pred_rf))","f26a97ed":"random_forest.fit(X,y)\npred_sub = random_forest.predict(df_test[X_train.columns])","929c6b7f":"sub = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsub['Survived'] = pred_sub","7d813bce":"sub.to_csv('sub.csv',index=False)#Public score: 0.78468","7d6de99d":"A confusion matrix is a table that is often used to describe the performance of a classification model (or \u201cclassifier\u201d) \n<br>on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.","876ddea1":"### Random Forest:","c1e4a620":"### Logistic Regression:","72befa9d":"### Processamento dos Dados","22b9e2d0":"* ### K-Fold Cross Validation:*","9231b728":"K-Fold Cross Validation randomly splits the training data into K subsets called folds. \n<br>Let\u2019s image we would split our data into 10 folds (K = 10). \n<br>Our model would be trained and evaluated 10 times, using a different fold for evaluation everytime, while it would be trained on the remaining 3 folds.\n\n<p>The result of our K-Fold Cross Validation example would be an array that contains 4 different scores.\n<br>We then need to compute the mean and the standard deviation for these scores.","0ff37578":"## Modelo de Predi\u00e7\u00e3o:","6be9a751":"### Sobre os dados:\n\ntrain.csv (data for a subset of the passengers including outcomes (survived or perished))\ntest.csv (data for a subset of passengers without outcomes)\n\nColunms:\n\n- Survival - Survival (0 = No; 1 = Yes). Not included in test.csv file.\n- Pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n- Name - Name\n- Sex - Sex\n- Age - Age\n- Sibsp - Number of Siblings\/Spouses Aboard\n- Parch - Number of Parents\/Children Aboard\n- Ticket - Ticket Number\n- Fare - Passenger Fare\n- Cabin - Cabin\n- Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","5bbe6185":"## Dataset TRAIN","7d0a7be4":"## Dataset TEST","e70ca867":"### Tratar os NaN\nAs colunas Age, Cabin e Embarked apresentam valores nulos ou NaN","e98eae0c":"### Matriz de Confus\u00e3o","7f068b44":"### Gaussian Naive Bayes:","eeaf98e4":"### Converter colunas categ\u00f3ricas:"}}