{"cell_type":{"1d6f077f":"code","5a58571f":"code","892d5584":"code","598fb5b1":"code","8d6c5c2e":"code","7a5012ac":"code","4d58663b":"code","3a0d39d5":"code","1546d445":"code","3f3224f4":"code","2647b7c2":"code","89d2b999":"code","83e57f52":"code","968673e7":"code","d20132a1":"code","f0b9c428":"code","b0c01268":"code","b7b03e0d":"code","9eb0642f":"code","c7434ca2":"code","d2c2a1fc":"code","c7d4e670":"code","3c6c2a2b":"code","30d26a64":"code","61bdd336":"code","c9415ab6":"code","cb89a00c":"code","deb78a7d":"code","1d77dbb2":"code","3d6baa68":"code","b8cf7922":"code","4f2dec64":"code","3c9e9c62":"code","5c347d67":"code","40bdf14c":"code","f4409613":"code","3b708d92":"code","9002fcf5":"code","3ec74e66":"code","bc00cd85":"code","ffb4432a":"code","f8a00ddf":"code","9adf8e8e":"code","91709909":"code","31f17db9":"code","d6aa6d93":"code","31253457":"code","bbd9edc5":"code","3cd63902":"code","3e63efea":"code","7d7c58d3":"code","62c3cbd8":"code","eba8b47c":"code","3bed3154":"code","87109414":"code","e96f14f1":"code","baa5e11c":"code","77dfa6f2":"code","9a06f9d3":"markdown","a0a92e61":"markdown","3fcaf37b":"markdown","dee26ee1":"markdown","47abda57":"markdown","083e8f0e":"markdown","9c109683":"markdown","a8a40cd3":"markdown","9423a1d8":"markdown","2621390f":"markdown","ddede540":"markdown","1d659af2":"markdown","833e2c73":"markdown","5760a2d9":"markdown","0c94cc21":"markdown","3c84da1e":"markdown","f8095e3c":"markdown","cef5decc":"markdown","b6355a17":"markdown","c59def24":"markdown","38ef3625":"markdown","31e828dd":"markdown","5324b714":"markdown","ebed6a53":"markdown","91bafd1e":"markdown","92280392":"markdown","a9f1ca9f":"markdown","b5725f3e":"markdown","6e52a153":"markdown","4e4df11a":"markdown","80443e66":"markdown","0fabe0dd":"markdown","0a7982d1":"markdown","469e1248":"markdown"},"source":{"1d6f077f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom scipy import stats\nfrom scipy.stats import norm\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","5a58571f":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","892d5584":"# Print some useful info for the train set\nprint(f'Train size is: {train.shape}')\nprint(f'Test size is: {test.shape}')","598fb5b1":"train['SalePrice'].describe()","8d6c5c2e":"def distribution_plot_and_qqplot(data):\n    # Get the fitted parameters used by the function\n    (mu, sigma) = norm.fit(data)\n    print('mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\n\n    # Plot the distribution\n    g = sns.distplot(data, fit=norm)\n    legend1 = plt.legend(['Skewness : {:.2f}'.format(data.skew())], loc=4)\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\n    plt.gca().add_artist(legend1)\n    plt.ylabel('Frequency')\n    plt.title(f'{data.name} distribution')\n\n    # Get also the QQ-plot\n    fig = plt.figure()\n    res = stats.probplot(data, plot=plt)\n    plt.show()\n    \ndistribution_plot_and_qqplot(train['SalePrice'])","7a5012ac":"f,ax = plt.subplots(figsize = (15,15))\nsns.heatmap(train.corr(), annot = True, linewidths=.5, fmt='.1f', ax=ax)\nplt.show()","4d58663b":"corre = train.corr()\ntop_corr_features = corre.index[abs(corre['SalePrice'])>0.5]\ng = sns.heatmap(train[top_corr_features].corr(),annot=True)","3a0d39d5":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train[cols], size = 2.5)\nplt.show()","1546d445":"# Before plotting let's create a useful function to use it again later\ndef plot_scatter(x, y):\n    fig, ax = plt.subplots()\n    ax.scatter(x=x, y=y)\n    plt.xlabel(x.name, fontsize=12)\n    plt.ylabel(y.name, fontsize=12)\n    plt.show()\n    ","3f3224f4":"plot_scatter(train['GrLivArea'], train['SalePrice'])\nplot_scatter(train['TotalBsmtSF'], train['SalePrice'])\nplot_scatter(train['1stFlrSF'], train['SalePrice'])\nplot_scatter(train['OverallQual'], train['SalePrice'])\nplot_scatter(train['GarageCars'], train['SalePrice'])\n","2647b7c2":"train[train.GrLivArea>4500]\ntrain[train.TotalBsmtSF>4000]\ntrain[train['1stFlrSF']>4000]","89d2b999":"train = train.drop(train[train['Id']==524].index)\ntrain = train.drop(train[train['Id']==1299].index)\ntrain.shape","83e57f52":"df = pd.concat([train,test])\n\npd.set_option('display.max_rows',5000)\npd.set_option('display.max_columns',500)\n","968673e7":"df = df.drop(['GarageArea','1stFlrSF','TotRmsAbvGrd'], axis =1)\n","d20132a1":"#checkig the columns for categorical and numerical values\nprint(df.select_dtypes(include = ['int64','float64']).columns)\nprint(df.select_dtypes(include = ['object']).columns)\n","f0b9c428":"df = df.set_index('Id')","b0c01268":"#missing data\ntotal_miss = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.shape[0]*100).sort_values(ascending=False)\nmissing_data = pd.concat([total_miss,percent], axis=1, keys=['Total','Percent'])\n\nmissing_data.head(35)","b7b03e0d":"columns_drop =percent[percent > 20].keys()\n\ncolumns_drop","9eb0642f":"df = df.drop(columns_drop, axis = 1)\n\nprint(df.shape)\ndf.describe(include = 'all')","c7434ca2":"missing_cols = df.columns[df.isnull().any()]\n\nmissing_cols","d2c2a1fc":"bsmt_cols = ['BsmtCond', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFinType1',\n       'BsmtFinType2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtQual', 'BsmtUnfSF','TotalBsmtSF']\n\nbsmt_feat = df[bsmt_cols]\nbsmt_feat.info()","c7d4e670":"bsmt_feat = bsmt_feat[bsmt_feat.isnull().any(axis=1)]\n\n#print(bsmt_feat)\nprint(bsmt_feat.shape)","3c6c2a2b":"bsmt_feat_all_nan = bsmt_feat[(bsmt_feat.isnull() | bsmt_feat.isin([0])).all(1)]\n\n#print(bsmt_feat_all_nan)\nprint(bsmt_feat_all_nan.shape)","30d26a64":"qual = list(df.loc[:,df.dtypes=='object'].columns.values)\n\nfor i in bsmt_cols:\n    if i in qual:\n        bsmt_feat_all_nan[i] = bsmt_feat_all_nan[i].replace(np.nan,'NA')\n    else:\n        bsmt_feat_all_nan[i] = bsmt_feat_all_nan[i].replace(np.nan,0)\n\nbsmt_feat.update(bsmt_feat_all_nan)\ndf.update(bsmt_feat_all_nan)","61bdd336":"#Finding remaining rows which have null columns\n\nbsmt_feat = bsmt_feat[bsmt_feat.isin([np.nan]).any(axis=1)]\n\n#print(bsmt_feat)\nprint(bsmt_feat.shape)","c9415ab6":"#Bucket the continuous columns\nprint(df['BsmtFinSF2'].max())\nprint(df['BsmtFinSF2'].min())\n\n#Bucket this  range in 5 buckets.\n#pd.cut(range(0,1526),5)","cb89a00c":"df_slice = df[(df['BsmtFinSF2'] >= 305) & (df['BsmtFinSF2'] <= 610)]\n\n#Impute this particular row\nbsmt_feat.at[333,'BsmtFinType2'] = df_slice['BsmtFinType2'].mode()[0]","deb78a7d":"#Impute the missing BsmtExposure value with the slice of BsmtExposure when BsmtQual is Gd.\nbsmt_feat['BsmtExposure'] = bsmt_feat['BsmtExposure'].replace(np.nan, df[df['BsmtQual'] == 'Gd']['BsmtExposure'].mode()[0])\n\n#Similarily\nbsmt_feat['BsmtCond'] = bsmt_feat['BsmtCond'].replace(np.nan, df['BsmtCond'].mode()[0])\nbsmt_feat['BsmtQual'] = bsmt_feat['BsmtQual'].replace(np.nan, df['BsmtQual'].mode()[0])\n","1d77dbb2":"df.update(bsmt_feat)\n\ndf.columns[df.isnull().any()]","3d6baa68":"#Now impute the missing values in Garage Features.\n\ngarage_cols = ['GarageCars', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType',\n       'GarageYrBlt']\n\ngar_feat = df[garage_cols]\ngar_feat.info()","b8cf7922":"gar_feat = gar_feat[gar_feat.isnull().any(axis=1)]\n\n#print(gar_feat)\nprint(gar_feat.shape)","4f2dec64":"gar_feat_all_nan = gar_feat[(gar_feat.isnull() | gar_feat.isin([0])).all(1)]\n\n#print(gar_feat_all_nan)\nprint(gar_feat_all_nan.shape)","3c9e9c62":"for i in garage_cols:\n    if i in qual:\n        gar_feat_all_nan[i] = gar_feat_all_nan[i].replace(np.nan,'NA')\n    else:\n        gar_feat_all_nan[i] = gar_feat_all_nan[i].replace(np.nan,0)\ngar_feat.update(gar_feat_all_nan)\ndf.update(gar_feat_all_nan)","5c347d67":"gar_feat = gar_feat[gar_feat.isnull().any(axis=1)]\n\n#gar_feat","40bdf14c":"for i in garage_cols:\n    gar_feat[i] = gar_feat[i].replace(np.nan, df[df['GarageType'] == 'Detchd'][i].mode()[0])\n\n#gar_feat","f4409613":"df.update(gar_feat)\n\ndf.columns[df.isnull().any()]","3b708d92":"df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n\ndf['Exterior1st'] = df['Exterior1st'].fillna(df['Exterior1st'].mode()[0])\n\ndf['Exterior2nd'] = df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])\n\ndf['Functional'] = df['Functional'].fillna(df['Functional'].mode()[0])\n\ndf['KitchenQual'] = df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\n\ndf['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])\n\ndf['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])\n\ndf['Utilities'] = df['Utilities'].fillna(df['Utilities'].mode()[0])\n\ndf['MasVnrType'] = df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])","9002fcf5":"df[df['MasVnrArea'].isnull() == True]['MasVnrType'].unique()","3ec74e66":"df.loc[(df['MasVnrType'] == 'None') & (df['MasVnrArea'].isnull() == True), 'MasVnrArea'] = 0","bc00cd85":"#print(df['MasVnrArea'].isnull().sum())\n#print(df['MasVnrType'].isnull().sum())\n#print(df.columns[df.isnull().any()])","ffb4432a":"lotconfig = ['Corner','Inside','CulDSac','FR2','FR3']\n\nfor i in lotconfig:\n    df['LotFrontage'] = pd.np.where((df['LotFrontage'].isnull() == True) & (df['LotConfig'] == i), df[df['LotConfig'] == i]['LotFrontage'].mean(),df['LotFrontage'])\n\ndf.isnull().sum().max()","f8a00ddf":"#Few Features are in numerical in nature but actually are of Categorical\n\ncat_con_columns = ['MSSubClass', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt','YrSold']\nfor i in cat_con_columns:\n    df[i] = df[i].astype(str)","9adf8e8e":"import calendar\ndf['MoSold'] = df['MoSold'].apply(lambda x : calendar.month_abbr[x])\n\ndf['MoSold'].unique()","91709909":"quan = list(df.loc[:,df.dtypes != 'object'].columns.values)\n","31f17db9":"# Ordered Data\nfrom pandas.api.types import CategoricalDtype\n\ndf['BsmtCond'] = df['BsmtCond'].astype(CategoricalDtype(categories=['NA','Po','Fa','TA','Gd','Ex'], ordered = True)).cat.codes\n\ndf['BsmtExposure'] = df['BsmtExposure'].astype(CategoricalDtype(categories=['NA','No','Mn','Av','Gd'], ordered = True)).cat.codes\n\ndf['BsmtFinType1'] = df['BsmtFinType1'].astype(CategoricalDtype(categories=['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'], ordered = True)).cat.codes\n\ndf['BsmtFinType2'] = df['BsmtFinType2'].astype(CategoricalDtype(categories=['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'], ordered = True)).cat.codes\n\ndf['BsmtQual'] = df['BsmtQual'].astype(CategoricalDtype(categories=['NA','Po','Fa','TA','Gd','Ex'], ordered = True)).cat.codes\n\ndf['ExterQual'] = df['BsmtQual'].astype(CategoricalDtype(categories=['Po','Fa','TA','Gd','Ex'], ordered = True)).cat.codes\n\ndf['ExterCond'] = df['ExterCond'].astype(CategoricalDtype(categories=['Po','Fa','TA','Gd','Ex'], ordered = True)).cat.codes\n\ndf['Functional'] = df['Functional'].astype(CategoricalDtype(categories=['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'], ordered = True)).cat.codes\n\ndf['GarageCond'] = df['GarageCond'].astype(CategoricalDtype(categories=['NA','Po','Fa','TA','Gd','Ex'], ordered = True)).cat.codes\n\ndf['GarageQual'] = df['GarageQual'].astype(CategoricalDtype(categories=['NA','Po','Fa','TA','Gd','Ex'], ordered = True)).cat.codes\n\ndf['GarageFinish'] = df['GarageFinish'].astype(CategoricalDtype(categories=['NA','Unf','RFn','Fin'], ordered = True)).cat.codes\n\ndf['HeatingQC'] = df['HeatingQC'].astype(CategoricalDtype(categories=['Po','Fa','TA','Gd','Ex'], ordered = True)).cat.codes\n\ndf['KitchenQual'] = df['KitchenQual'].astype(CategoricalDtype(categories=['Po','Fa','TA','Gd','Ex'], ordered = True)).cat.codes\n\ndf['PavedDrive'] = df['PavedDrive'].astype(CategoricalDtype(categories=['N','P','Y'], ordered = True)).cat.codes\n\ndf['Utilities'] = df['Utilities'].astype(CategoricalDtype(categories=['ELO','NoSeWa','NoSewr','AllPub'], ordered = True)).cat.codes\n","d6aa6d93":"skewed_features = ['2ndFlrSF','3SsnPorch',\n 'BedroomAbvGr','BsmtFinSF1','BsmtFinSF2',\n 'BsmtFullBath','BsmtHalfBath','BsmtUnfSF',\n 'EnclosedPorch','Fireplaces','FullBath',\n 'GarageCars','GrLivArea', 'HalfBath',\n 'KitchenAbvGr','LotArea','LotFrontage',\n 'LowQualFinSF','MasVnrArea','MiscVal',\n 'OpenPorchSF','PoolArea','ScreenPorch',\n 'TotalBsmtSF','WoodDeckSF']","31253457":"## Remove Skewness from the data\nfor i in skewed_features:\n    df[i] = np.log1p(df[i])\n\nlog_SalePrice = np.log1p(train['SalePrice'])\n\ndistribution_plot_and_qqplot(log_SalePrice)","bbd9edc5":"# Create Dummies for all non ordinal categorical data\nqual1 = list(df.loc[:,df.dtypes == 'object'].columns.values)\nprint(len(qual1))\n\ndf_with_dummies = pd.get_dummies(df, columns=qual1, drop_first=True)\ndf_with_dummies.shape\n","3cd63902":"##Normalize\n\ndf_inputs = df_with_dummies.copy()\ntargets = log_SalePrice.copy()\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df_inputs)\ndf_inputs_scaled = scaler.transform(df_inputs)","3e63efea":"#Segregate data into original train and test\ntrain_len = len(train)\ntrain_scaled = df_inputs_scaled[:train_len]\ntest_scaled = df_inputs_scaled[train_len:]\n\nprint(train_scaled.shape)\n\nprint(test_scaled.shape)\n","7d7c58d3":"# Train Test Split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train_scaled, targets, test_size=0.2, random_state=365)\n","62c3cbd8":"import xgboost\nregressor = xgboost.XGBRegressor(learning_rate = 0.06, max_depth= 3, n_estimators = 350, random_state= 0)\nregressor.fit(x_train,y_train)","eba8b47c":"y_hat = regressor.predict(x_train)\n\nplt.scatter(y_train, y_hat, alpha = 0.2)\nplt.xlabel('Targets (y_train)',size=18)\nplt.ylabel('Predictions (y_hat)',size=18)\nplt.show()","3bed3154":"regressor.score(x_train,y_train)","87109414":"##Testing\ny_hat_test = regressor.predict(x_test)\n\n\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('Targets (y_test)',size=18)\nplt.ylabel('Predictions (y_hat_test)',size=18)\nplt.show()","e96f14f1":"y_predict = regressor.predict(test_scaled)\ny_predict = np.expm1(y_predict)","baa5e11c":"## k-Fold cross validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = regressor, X = x_train, y = y_train, cv = 10)\n","77dfa6f2":"print(accuracies.mean())\nprint(accuracies.std())","9a06f9d3":"# 4. Data Cleaning <a id='DC'><\/a>","a0a92e61":"*Missing Value Imputation*<a id='MVI'><\/a>","3fcaf37b":"Now, lets impute the missing value.","dee26ee1":"# 3. Exploratory Data Analysis <a id='EDA'><\/a>","47abda57":"First impute the missing values in Bsmt Features.","083e8f0e":"Lets first impute the missing values in rows.","9c109683":"*Skewness*","a8a40cd3":"# 6. Modelling <a id='Mod'><\/a>","9423a1d8":"Replace the BsmtFinType2 based on BsmtFinSF2 by bucketing the BsmtFinSF2.\n","2621390f":"replace the NaN in categorical with NA(ie No Basement) and with 0 in Numerical data.","ddede540":"Let's combine both train and test data to save our time and energy. :)","1d659af2":"# Contents\n1. [Identify the Problem](#IP)\n2. [Import the Data](#ID)\n3. [Exploratory Data Analysis](#EDA)\n4. [Data Cleaning](#DC)\n     1. [Outlier Detection](#OD)\n     2. [Missing Value Imputation](#MVI)\n5. [Feature Transformation](#FT)\n     1. [Convert Categorical to Numerical Data](#C2N)\n     2. [Reduce Skewness](#RS)\n     3. [Normalise Data Columns](#NDC)\n6. [Modelling](#Mod)\n     1. [Model Learning](#ML)\n     2. [Model Validation](#MV)\n","833e2c73":"*Outlier Detection*<a id='OD'><\/a>","5760a2d9":"*Correlation*","0c94cc21":"First, let's Analyze the dependent Variable","3c84da1e":"*Normalisation* <a id='NDC'><\/a>","f8095e3c":"Now impute the LotFrontage based on LotConfig","cef5decc":"Model Learning <a id='ML'><\/a>","b6355a17":"# 2. Import the Data <a id='ID'><\/a>","c59def24":"# 5. Feature Transformation <a id='FT'><\/a>","38ef3625":"Model Validation <a id='MV'><\/a>","31e828dd":"# 1. Identify the Problem <a id='IP'><\/a>","5324b714":"These are the variables most correlated with 'SalePrice'. We can say:\n* 'OverallQual', 'GrLivArea' and 'TotalBsmtSF' are strongly correlated with 'SalePrice'.\n* 'GarageCars' and 'GarageArea' are also some of the most strongly correlated variables. However, we can say, the number of       cars that fit into the garage is a consequence of the garage area. 'GarageCars' and 'GarageArea' are like twin brothers.       You'll never be able to distinguish them. Therefore, we just need one of these variables in our analysis (we can keep          'GarageCars' since its correlation with 'SalePrice' is higher).\n* 'TotalBsmtSF' and '1stFlrSF' also seem to be twin brothers. We can keep 'TotalBsmtSF' just to say that our first guess was       right.\n* 'TotRmsAbvGrd' and 'GrLivArea', twin brothers again.\n* 'YearBuilt'... It seems that 'YearBuilt' is slightly correlated with 'SalePrice'.","ebed6a53":"Since, the problem statement says to predict the House Prices of given multiple variables.\nSo. it is a Multivariable Regression Problem.","91bafd1e":"We can see that there are two point with (very) large value of GrLivArea and with (very) low price. Similarily, one point each  with (very) large value of TotalBsmtSF & 1stFlrSF and with (very) low price.\nThese are outliers and we can safely remove them.","92280392":"Removing the highly correlated variables","a9f1ca9f":"We can observe that the target variable:\n* deviate from the normal distribution\n* have appreciable positive skewness\n* show peakedness\n   \n   \nAs, the data in linear models should be normally distributed, later we will transform this variable and make it more normally distributed.","b5725f3e":"Deleting Outliers","6e52a153":"Although we already know some of the main figures, this mega scatter plot gives us a reasonable idea about variables relationships.\n\nOne of the figures we may find interesting is the one between 'TotalBsmtSF' and 'GrLiveArea'. In this figure we can see the dots drawing a linear line, which almost acts like a border. It totally makes sense that the majority of the dots stay below that line. Basement areas can be equal to the above ground living area, but it is not expected a basement area bigger than the above ground living area.\n\nThe plot concerning 'SalePrice' and 'YearBuilt' can also make us think. In the bottom of the 'dots cloud', we see what almost appears to be an exponential function. We can also see this same tendency in the upper limit of the 'dots cloud'. Also, notice how the set of dots regarding the last years tend to stay above this limit (I just wanted to say that prices are increasing faster now).","4e4df11a":"Here, we can see few variables are highly correlated. Lets plot the 'SalePrice' correlation matrix (highly correlated variables).","80443e66":"*Dealing with the Categorical Data*<a id='C2N'><\/a>","0fabe0dd":"To explore the data, we will start with \n* Correlation matrix ie plotting heatmap.\n* Scatter plots between the most correlated variables.","0a7982d1":"*Reducing Skewness among numerical data* <a id='RS'><\/a>","469e1248":"Scatter plots between 'SalePrice' and highly correlated variables"}}