{"cell_type":{"1b9620b4":"code","cfb43d6e":"code","2d3f7099":"code","41d058a7":"code","701e86f4":"code","3f22045a":"code","8735622b":"code","0fb31405":"code","5f2a9860":"code","de11f976":"code","15d691b0":"code","37362871":"code","bab8fa60":"code","c2c3b1dd":"code","29ae982b":"code","40fc1263":"code","368f2830":"code","bc0c1b4b":"code","23edca22":"code","95d1dc95":"code","90c05fec":"code","716ce9ca":"markdown","6f3b6adc":"markdown","8787401b":"markdown","88f4b705":"markdown","5b1a9306":"markdown","cb478066":"markdown","13275a68":"markdown","7f0837f6":"markdown"},"source":{"1b9620b4":"import os\nprint(os.listdir('\/kaggle\/input\/fer2013'))","cfb43d6e":"train_path = '\/kaggle\/input\/fer2013\/train'\nval_path = '\/kaggle\/input\/fer2013\/test'","2d3f7099":"import matplotlib.pyplot as plt\ndef plot_images(img_dir, top=10):\n    all_img_dirs = os.listdir(img_dir)\n    img_files = [os.path.join(img_dir, file) for file in all_img_dirs][:5]\n  \n    plt.figure(figsize=(10, 10))\n  \n    for idx, img_path in enumerate(img_files):\n        plt.subplot(5, 5, idx+1)\n    \n        img = plt.imread(img_path)\n        plt.tight_layout()         \n        plt.imshow(img, cmap='gray') ","41d058a7":"plot_images(train_path+'\/angry')","701e86f4":"plot_images(train_path+'\/disgust')","3f22045a":"plot_images(train_path+'\/fear')","8735622b":"plot_images(train_path+'\/happy')","0fb31405":"plot_images(train_path+'\/neutral')","5f2a9860":"plot_images(train_path+'\/sad')","de11f976":"plot_images(train_path+'\/surprise')","15d691b0":"from tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras import models, layers, regularizers","37362871":"emotion_labels = sorted(os.listdir(train_path))\nprint(emotion_labels)","bab8fa60":"batch_size = 64\ntarget_size = (48,48)\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\nval_datagen   = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_path,\n        target_size=target_size,\n        batch_size=batch_size,\n        color_mode=\"grayscale\",\n        class_mode='categorical',\n        shuffle=True)\n\nval_generator = val_datagen.flow_from_directory(\n        val_path,\n        target_size=target_size,\n        batch_size=batch_size,\n        color_mode=\"grayscale\",\n        class_mode='categorical')","c2c3b1dd":"input_shape = (48,48,1) # img_rows, img_colums, color_channels\nnum_classes = 7","29ae982b":"# Build Model\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape)) #, data_format='channels_last', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(64, activation='relu'))\n\nmodel.add(layers.Dense(num_classes, activation='softmax'))\n\nmodel.summary()","40fc1263":"# Compile Model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) ","368f2830":"num_epochs = 100\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VAL   = val_generator.n\/\/val_generator.batch_size","bc0c1b4b":"# Train Model\nhistory = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, verbose=1, validation_data=val_generator, validation_steps=STEP_SIZE_VAL)","23edca22":"# Save Model\nmodels.save_model(model, 'fer2013_cnn.h5') ","95d1dc95":"# Evaluate Model\nscore = model.evaluate_generator(val_generator, steps=STEP_SIZE_VAL) \nprint('Test loss: ', score[0])\nprint('Test accuracy: ', score[1])","90c05fec":"# Show Train History\nkeys=history.history.keys()\nprint(keys)\n\ndef show_train_history(hisData,train,test): \n    plt.plot(hisData.history[train])\n    plt.plot(hisData.history[test])\n    plt.title('Training History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\nshow_train_history(history, 'loss', 'val_loss')\nshow_train_history(history, 'accuracy', 'val_accuracy')","716ce9ca":"# Facial Expression Recognition (Emotion Detection)","6f3b6adc":"## Data Generator","8787401b":"## Train Model","88f4b705":"## Evaluate Model","5b1a9306":"## Show Training History","cb478066":"## Build Model","13275a68":"## Save Model","7f0837f6":"## Dataset : [FER-2013](https:\/\/www.kaggle.com\/msambare\/fer2013)\n![fer2013](https:\/\/miro.medium.com\/max\/602\/1*slyZ64ftG12VU4VTEmSfBQ.png)"}}