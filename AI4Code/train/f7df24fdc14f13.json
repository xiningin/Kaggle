{"cell_type":{"35b7bf0f":"code","08d83145":"code","fc56acf7":"code","7c2efe0b":"code","5c40d1be":"code","4a417eb7":"code","20a9e246":"code","ad2a5177":"code","53f90862":"code","2408225c":"code","2ebb1537":"code","add62002":"code","57c15308":"code","c4e0193d":"code","bfa7c6dc":"code","7cd7094d":"code","ac35822d":"code","33ee7fd1":"code","00c3387b":"code","ab35735e":"code","b13615f1":"code","f7bd45c2":"code","90c24e05":"code","c35c63f4":"code","cf82be21":"code","2418b0a6":"code","1508ca8f":"markdown","b58871ed":"markdown"},"source":{"35b7bf0f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\nimport plotly.graph_objs as go\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.\n# plotly\nimport plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go","08d83145":"from keras.applications.vgg19 import VGG19\nfrom keras.utils import to_categorical\nimport cv2\nimport numpy as np\nfrom keras.layers import Dense, Flatten\nfrom glob import glob","fc56acf7":"X = np.load('..\/input\/X.npy') # images\nY = np.load('..\/input\/Y.npy') # labels associated to images (0 = no IDC, 1 = IDC)","7c2efe0b":"imgsize = 64\nplt.subplot(1,4,1)\nplt.imshow(cv2.cvtColor(X[1], cv2.COLOR_BGR2RGB))\nplt.axis(\"on\")\n\nplt.subplot(1,4,2)\nplt.imshow(cv2.cvtColor(X[2], cv2.COLOR_BGR2RGB))\nplt.axis(\"on\")\n\nplt.subplot(1,4,3)\nplt.imshow(cv2.cvtColor(X[3], cv2.COLOR_BGR2RGB))\nplt.axis(\"on\")\n\nplt.subplot(1,4,4)\nplt.imshow(cv2.cvtColor(X[4], cv2.COLOR_BGR2RGB))\nplt.axis(\"on\")","5c40d1be":"print(\"X shape: \", X.shape)\nprint(\"Y shape: \", Y.shape)","4a417eb7":"#Normalization\nX = X \/ 255.0\nprint(\"X Shape:\",X.shape)","20a9e246":"from sklearn.model_selection import train_test_split\n\nxtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 0.2, random_state=2)\nnumberoftrain = xtrain.shape[0]\nnumberoftest = xtest.shape[0]\nxtrain.shape","ad2a5177":"#Reshape Xtrain & Xtest\n\nxtrain = xtrain.reshape(numberoftrain,xtrain.shape[1]*xtrain.shape[2]*xtrain.shape[3])\nxtest = xtest.reshape(numberoftest,xtest.shape[1]*xtest.shape[2]*xtest.shape[3])\nprint(\"X Train: \",xtrain.shape)\nprint(\"X Test: \",xtest.shape)\n","53f90862":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\n\ndef buildclassifier():\n    classifier = Sequential() # initialize neural network\n    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = xtrain.shape[1]))\n    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier","2408225c":"classifier = KerasClassifier(build_fn = buildclassifier, epochs = 200)\naccuracies = cross_val_score(estimator = classifier, X = xtrain, y = ytrain, cv = 6)\nmean = accuracies.mean()\nvariance = accuracies.std()\nprint(\"Accuracy mean: \"+ str(mean))\nprint(\"Accuracy variance: \"+ str(variance))","2ebb1537":"from sklearn.tree import DecisionTreeClassifier\nDTC = DecisionTreeClassifier()\nDTC.fit(xtrain,ytrain) #learning","add62002":"#prediciton\ndtscore = DTC.score(xtest,ytest)\nprint(\"Decision Tree Score: \",DTC.score(xtest,ytest))","57c15308":"#Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nRFC= RandomForestClassifier(n_estimators = 100, random_state=42) #n_estimator = DT\nRFC.fit(xtrain,ytrain) # learning\nrfsc=RFC.score(xtest,ytest)\nprint(\"Random Forest Score: \",RFC.score(xtest,ytest))","c4e0193d":"#SVM with Sklearn\n\nfrom sklearn.svm import SVC\n\nSVM = SVC(random_state=42)\nSVM.fit(xtrain,ytrain)  #learning \n#SVM Test \nsvmsc = SVM.score(xtest,ytest)\nprint (\"SVM Accuracy:\", SVM.score(xtest,ytest))","bfa7c6dc":"from sklearn.model_selection import train_test_split\n\nxtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 0.2, random_state=2)\nnumberoftrain = xtrain.shape[0]\nnumberoftest = xtest.shape[0]\nxtrain.shape","7cd7094d":"numberOfClass = 2\n\n\nytrain = to_categorical(ytrain, numberOfClass)\nytest = to_categorical(ytest, numberOfClass)\n\ninput_shape = xtrain.shape[1:]","ac35822d":"def resize_img(img):\n    numberOfImage = img.shape[0]\n    new_array = np.zeros((numberOfImage, 64,64,3))\n    for i in range(numberOfImage):\n        new_array[i] = cv2.resize(img[i,:,:,:],(64,64))\n    return new_array\n\nxtrain = resize_img(xtrain)\nxtest = resize_img(xtest)\nprint(\"increased dim x_train: \",xtrain.shape)","33ee7fd1":"\nvgg = VGG19(include_top = False, weights = \"imagenet\", input_shape = (64,64,3))\n\nprint(vgg.summary())","00c3387b":"vgg_layer_list = vgg.layers\n#print(vgg_layer_list)","ab35735e":"model = Sequential()\nfor layer in vgg_layer_list:\n    model.add(layer)\n    \nprint(model.summary())","b13615f1":"for layer in model.layers:\n    layer.trainable = False\n\n# fully con layers\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Dense(128))\nmodel.add(Dense(numberOfClass, activation= \"sigmoid\"))\n\nprint(model.summary())","f7bd45c2":"model.compile(loss = \"binary_crossentropy\",\n              optimizer = \"rmsprop\",\n              metrics = [\"accuracy\"])","90c24e05":"#validation_split = 0.2, epochs = 100, batch_size = 1000\nhist = model.fit(xtrain, ytrain, validation_split = 0.3, epochs = 100, batch_size = 1000)","c35c63f4":"plt.title('vgg19 - Loss')\nplt.plot(hist.history[\"loss\"], label = \"train loss\")\nplt.plot(hist.history[\"val_loss\"], label = \"val loss\")\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.title('vgg19 - Accuracy')\nplt.plot(hist.history[\"acc\"], label = \"train acc\")\nplt.plot(hist.history[\"val_acc\"], label = \"val acc\")\nplt.legend()\nplt.show()","cf82be21":"acc1= np.mean(hist.history[\"acc\"])","2418b0a6":"scoresf1=[mean,dtscore,rfsc,svmsc,acc1]\n#create traces\nAlgorthmsName=[\"Artificial Neural Network\",\"Decision Tree\",\n                \"Random Forest\",\"Support Vector Machine\",'VGG19-Transfer Learning-']\n\ntrace1 = go.Scatter(\n    x = AlgorthmsName,\n    y= scoresf1,\n    name='Algortms Name',\n    marker =dict(color='rgba(225,126,0,0.5)',\n               line =dict(color='rgb(0,0,0)',width=2)),\n                text=AlgorthmsName\n)\ndata = [trace1]\n\nlayout = go.Layout(barmode = \"group\", \n                  xaxis= dict(title= 'ML Algorithms',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Prediction Scores(F1)',ticklen= 5,zeroline= False))\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","1508ca8f":"# If you like this kernel, Please Upvote :) Thanks","b58871ed":"# Transfer Learning Section -VGG19-"}}