{"cell_type":{"8fec2bcf":"code","021a4eb0":"code","2d53c10f":"code","43f837d7":"code","17403fdd":"code","ae35dfbb":"code","c1126b7a":"code","b074b7f5":"code","45b46c8c":"code","c287d59a":"code","5d439934":"code","9346eda5":"code","6b82e069":"code","87e96017":"code","05c07488":"code","2123a6a4":"code","df30b3f4":"code","76a5790a":"code","9af0e528":"code","c4b2f3bb":"code","27d22079":"code","286771d5":"code","ce5aa1f3":"code","19730ccf":"code","8651288e":"code","f7d1f597":"code","b253c3a7":"code","6c2856dc":"code","e8dfd907":"code","13c5720a":"code","6e9fca6a":"code","f539c269":"code","c048d70e":"code","c9d9e08b":"code","598c3a5d":"code","7bb2c0d7":"code","bae6599d":"code","c9e68a4e":"code","66f51cb7":"code","280424b3":"code","b7efc9d3":"code","3ee52634":"code","eb8f87bb":"code","9b14d3a6":"code","7e3ccf28":"code","deba8f2b":"code","c77b9eb4":"code","c6e5c078":"code","97da2e08":"code","393534fe":"code","5eaaac37":"code","66b19e27":"code","40a1dedc":"code","1ac6819b":"code","8313248e":"code","b6efdfef":"code","1746cb89":"markdown","02e7f5a9":"markdown","afc6e311":"markdown","40c720e2":"markdown","dcbf49b4":"markdown","0396bb6e":"markdown","ba104be7":"markdown","ff9561a6":"markdown","85ee15b3":"markdown","59b009a9":"markdown","9837c0fd":"markdown","108d195f":"markdown","f908db65":"markdown","a9000d7d":"markdown","104f5f89":"markdown","363fb222":"markdown","71d4c199":"markdown","05f34786":"markdown","f29ec80d":"markdown","a3d2e9b8":"markdown","9b3b8049":"markdown","e513867c":"markdown"},"source":{"8fec2bcf":"import pandas as pd\nimport numpy as np","021a4eb0":"# Importing Housing.csv\nhousing = pd.read_csv('..\/input\/housing-simple-regression\/Housing.csv')","2d53c10f":"# Looking at the first five rows\nhousing.head()","43f837d7":"# What type of values are stored in the columns?\nhousing.info()","17403fdd":"# Converting Yes to 1 and No to 0\nhousing['mainroad'] = housing['mainroad'].map({'yes': 1, 'no': 0})\nhousing['guestroom'] = housing['guestroom'].map({'yes': 1, 'no': 0})\nhousing['basement'] = housing['basement'].map({'yes': 1, 'no': 0})\nhousing['hotwaterheating'] = housing['hotwaterheating'].map({'yes': 1, 'no': 0})\nhousing['airconditioning'] = housing['airconditioning'].map({'yes': 1, 'no': 0})\nhousing['prefarea'] = housing['prefarea'].map({'yes': 1, 'no': 0})","ae35dfbb":"# Now let's see the head\nhousing.head()","c1126b7a":"# Creating a dummy variable for 'furnishingstatus'\nstatus = pd.get_dummies(housing['furnishingstatus'])","b074b7f5":"# The result has created three variables that are not needed.\nstatus.head()","45b46c8c":"# we don't need 3 columns. Because any one category should be 1, so only 2 is enough\n# we can use drop_first = True to drop the first column from status df.\nstatus = pd.get_dummies(housing['furnishingstatus'], drop_first=True)","c287d59a":"status","5d439934":"#Adding the results to the master dataframe\nhousing = pd.concat([housing,status],axis=1)","9346eda5":"# Now let's see the head of our dataframe.\nhousing.head()","6b82e069":"# Dropping furnishingstatus as we have created the dummies for it\nhousing.drop(['furnishingstatus'],axis=1,inplace=True)","87e96017":"# Now let's see the head of our dataframe.\nhousing.head()","05c07488":"# Let us create the new metric and assign it to \"areaperbedroom\"\nhousing['areaperbedroom'] = housing['area']\/housing['bedrooms']","2123a6a4":"# Metric:bathrooms per bedroom\nhousing['bbratio'] = housing['bathrooms']\/housing['bedrooms']","df30b3f4":"housing.head()","76a5790a":"#defining a normalisation function \ndef normalize (x): \n    return ( (x-np.min(x))\/ (max(x) - min(x)))\n                                            \n                                              \n# applying normalize ( ) to all columns \nhousing = housing.apply(normalize) ","9af0e528":"housing.head(5)","c4b2f3bb":"housing.columns","27d22079":"# Putting feature variable to X\nX = housing[['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad',\n       'guestroom', 'basement', 'hotwaterheating', 'airconditioning',\n       'parking', 'prefarea', 'semi-furnished', 'unfurnished',\n       'areaperbedroom', 'bbratio']]\n\n# Putting response variable to y\ny = housing['price']","286771d5":"#random_state is the seed used by the random number generator, it can be any integer.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7 ,test_size = 0.3, random_state=100)","ce5aa1f3":"import statsmodels.api as sm          # Importing statsmodels\nX_train = sm.add_constant(X_train)    # Adding a constant column to our dataframe\n# create a first fitted model\nlm_1 = sm.OLS(y_train,X_train).fit()","19730ccf":"#Let's see the summary of our first linear model\nprint(lm_1.summary())","8651288e":"\n# UDF for calculating vif value\ndef vif_cal(input_data, dependent_col):\n    vif_df = pd.DataFrame( columns = ['Var', 'Vif'])\n    x_vars=input_data.drop([dependent_col], axis=1)\n    xvar_names=x_vars.columns\n    for i in range(0,xvar_names.shape[0]):\n        y=x_vars[xvar_names[i]] \n        x=x_vars[xvar_names.drop(xvar_names[i])]\n        rsq=sm.OLS(y,x).fit().rsquared  \n        vif=round(1\/(1-rsq),2)\n        vif_df.loc[i] = [xvar_names[i], vif]\n    return vif_df.sort_values(by = 'Vif', axis=0, ascending=False, inplace=False)","f7d1f597":"# Calculating Vif value|\nvif_cal(input_data=housing, dependent_col=\"price\")","b253c3a7":"# Importing matplotlib and seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","6c2856dc":"# Let's see the correlation matrix \nplt.figure(figsize = (16,10))     # Size of the figure\nsns.heatmap(housing.corr(),annot = True)","e8dfd907":"# Dropping highly correlated variables and insignificant variables\nX_train = X_train.drop('bbratio', 1)","13c5720a":"# Create a second fitted model\nlm_2 = sm.OLS(y_train,X_train).fit()","6e9fca6a":"#Let's see the summary of our second linear model\nprint(lm_2.summary())","f539c269":"# Calculating Vif value\nvif_cal(input_data=housing.drop([\"bbratio\"], axis=1), dependent_col=\"price\")","c048d70e":"# Dropping highly correlated variables and insignificant variables\nX_train = X_train.drop('bedrooms', 1)","c9d9e08b":"# Create a third fitted model\nlm_3 = sm.OLS(y_train,X_train).fit()","598c3a5d":"#Let's see the summary of our third linear model\nprint(lm_3.summary())","7bb2c0d7":"# Calculating Vif value\nvif_cal(input_data=housing.drop([\"bedrooms\",\"bbratio\"], axis=1), dependent_col=\"price\")","bae6599d":"# # Dropping highly correlated variables and insignificant variables\nX_train = X_train.drop('areaperbedroom', 1)","c9e68a4e":"# Create a fourth fitted model\nlm_4 = sm.OLS(y_train,X_train).fit()","66f51cb7":"#Let's see the summary of our fourth linear model\nprint(lm_4.summary())","280424b3":"# Calculating Vif value\nvif_cal(input_data=housing.drop([\"bedrooms\",\"bbratio\",\"areaperbedroom\"], axis=1), dependent_col=\"price\")","b7efc9d3":"# # Dropping highly correlated variables and insignificant variables\nX_train = X_train.drop('semi-furnished', 1)","3ee52634":"# Create a fifth fitted model\nlm_5 = sm.OLS(y_train,X_train).fit()","eb8f87bb":"#Let's see the summary of our fifth linear model\nprint(lm_5.summary())","9b14d3a6":"# Calculating Vif value\nvif_cal(input_data=housing.drop([\"bedrooms\",\"bbratio\",\"areaperbedroom\",\"semi-furnished\"], axis=1), dependent_col=\"price\")","7e3ccf28":"# # Dropping highly correlated variables and insignificant variables\nX_train = X_train.drop('basement', 1)","deba8f2b":"# Create a sixth fitted model\nlm_6 = sm.OLS(y_train,X_train).fit()","c77b9eb4":"#Let's see the summary of our sixth linear model\nprint(lm_6.summary())","c6e5c078":"# Calculating Vif value\nvif_cal(input_data=housing.drop([\"bedrooms\",\"bbratio\",\"areaperbedroom\",\"semi-furnished\",\"basement\"], axis=1), dependent_col=\"price\")","97da2e08":"# Adding  constant variable to test dataframe\nX_test_m6 = sm.add_constant(X_test)","393534fe":"# Creating X_test_m6 dataframe by dropping variables from X_test_m6\nX_test_m6 = X_test_m6.drop([\"bedrooms\",\"bbratio\",\"areaperbedroom\",\"semi-furnished\",\"basement\"], axis=1)","5eaaac37":"# Making predictions\ny_pred_m6 = lm_6.predict(X_test_m6)","66b19e27":"# Actual vs Predicted\nc = [i for i in range(1,165,1)]\nfig = plt.figure()\nplt.plot(c,y_test, color=\"blue\", linewidth=2.5, linestyle=\"-\")     #Plotting Actual\nplt.plot(c,y_pred_m6, color=\"red\",  linewidth=2.5, linestyle=\"-\")  #Plotting predicted\nfig.suptitle('Actual and Predicted', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                               # X-label\nplt.ylabel('Housing Price', fontsize=16)                       # Y-label","40a1dedc":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred_m6)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)                          # Y-label","1ac6819b":"# Error terms\nfig = plt.figure()\nc = [i for i in range(1,165,1)]\nplt.plot(c,y_test-y_pred_m6, color=\"blue\", linewidth=2.5, linestyle=\"-\")\nfig.suptitle('Error Terms', fontsize=20)              # Plot heading \nplt.xlabel('Index', fontsize=18)                      # X-label\nplt.ylabel('ytest-ypred', fontsize=16)                # Y-label","8313248e":"# Plotting the error terms to understand the distribution.\nfig = plt.figure()\nsns.distplot((y_test-y_pred_m6),bins=50)\nfig.suptitle('Error Terms', fontsize=20)                  # Plot heading \nplt.xlabel('y_test-y_pred', fontsize=18)                  # X-label\nplt.ylabel('Index', fontsize=16)                          # Y-label","b6efdfef":"import numpy as np\nfrom sklearn import metrics\nprint('RMSE :', np.sqrt(metrics.mean_squared_error(y_test, y_pred_m6)))","1746cb89":"### Dropping the Variable and Updating the Model","02e7f5a9":"### Checking VIF","afc6e311":"### Dropping the Variable and Updating the Model","40c720e2":"## Correlation matrix","dcbf49b4":"### Importing and Understanding Data","0396bb6e":"### Dropping the Variable and Updating the Model","ba104be7":"## Model Evaluation","ff9561a6":"### Prediction with Model 6","85ee15b3":"## Making Predictions Using the Final Model","59b009a9":"The variable 'furnishingstatus' had three levels. We need to convert it to integer.","9837c0fd":"Multi Collinearlity is a problem, multiple columns having high variance ","108d195f":"### Data Preparation","f908db65":"## Building a linear model","a9000d7d":"### Dropping the Variable and Updating the Model","104f5f89":"- You can see that your dataset has many columns with values as 'Yes' or 'No'.\n\n- We need to convert them to 1s and 0s, where 1 is a 'Yes' and 0 is a 'No'.","363fb222":"## Splitting Data into Training and Testing Sets","71d4c199":"## Housing Case Study","05f34786":"### Dropping the Variable and Updating the Model","f29ec80d":"#### Assessment  question\n#### Design four models by dropping all the variables one by one with high vif (>5). Then, compare the results.","a3d2e9b8":"### Rescaling the Features \nIt is extremely important to rescale the variables so that they have a comparable scale. \nThere are twocoon ways of rescaling \n1. Normalisation (min-max scaling) and \n   - Values to 0 to 1\n2. standardisation (mean-o, sigma-1) \n   - Z score Value\nLet's try normalisation","9b3b8049":"Problem Statement:\n\nConsider a real estate company that has a dataset containing the prices of properties in the Delhi region. It wishes to use the data to optimise the sale prices of the properties based on important factors such as area, bedrooms, parking, etc.\n\nEssentially, the company wants \u2014\n\n\n- To identify the variables affecting house prices, e.g. area, number of rooms, bathrooms, etc.\n\n- To create a linear model that quantitatively relates house prices with variables such as number of rooms, area, number of bathrooms, etc.\n\n- To know the accuracy of the model, i.e. how well these variables can predict house prices.","e513867c":"#### Creating a new variable"}}