{"cell_type":{"7471d006":"code","89a57a94":"code","18fb6634":"code","a0ccc5f0":"code","e466fa05":"code","dbad7669":"code","04b78fb2":"code","79d546fa":"code","c172647c":"code","495ab442":"code","3141690e":"code","f06a8dc8":"code","550f1ffc":"code","23ec1b65":"code","78c12bed":"code","f42facee":"code","b6aa2817":"code","96578cb4":"code","d1d6e0d7":"code","dd65d211":"code","9d6c2859":"code","8f4d5cc5":"code","8dcaeb0f":"code","ffacfa61":"code","72d62aa5":"code","0b505cb0":"code","102bbd9e":"code","c4bf5822":"code","0ad1c8b1":"code","e400db03":"code","5899e1fe":"code","054f5cd7":"code","466bd56b":"code","421f2a42":"code","1c7eed0f":"code","f4d61231":"code","abab168f":"code","d7cb1bf6":"code","8a4ed9dd":"code","02bb2d66":"code","1f906b85":"code","d0f0d89c":"code","62633c7e":"code","96dac200":"code","7f31be0b":"code","690e5602":"code","0a93377d":"code","ee209766":"code","7c68e276":"code","fe50081b":"code","8dc58e75":"code","28c98dbc":"code","9aaaa071":"code","cf6c3e7a":"code","5d188e68":"code","877ae78d":"code","57d33b53":"code","722cdab7":"code","d3b3af15":"code","a1631488":"code","57ab5528":"code","ae80412b":"code","c9b88a48":"code","1eee990c":"code","c5df86a9":"code","604390b4":"code","893d06c1":"code","9c8601ab":"code","b8af9676":"code","b69413b1":"code","562cf14e":"code","8394ecd4":"code","c9eb3efb":"code","3563c3fa":"code","d4ad28f5":"code","d3cd412f":"code","8268abb8":"code","9827c218":"markdown","1420f738":"markdown"},"source":{"7471d006":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","89a57a94":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping","18fb6634":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')","a0ccc5f0":"df.info()","e466fa05":"df.describe().T","dbad7669":"sns.countplot(df['target'])","04b78fb2":"df['age'].plot(kind='hist')","79d546fa":"age_tgt_0 = df[df['target'] == 0]['age']\nage_tgt_1 = df[df['target'] == 1]['age']\n\n#f, axes = plt.subplots(1, 2, figsize=(10, 4))\n\nsns.distplot(age_tgt_0, label='age category 0')\nsns.distplot(age_tgt_1, label='age category 1')\nplt.legend()\nplt.show()","c172647c":"# sex - (1 = male; 0 = female)\n\nsns.countplot(df['sex'])","495ab442":"# cp - chest pain type\n\nsns.countplot(df['cp'])","3141690e":"# trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n\ndf['trestbps'].plot(kind='hist')","f06a8dc8":"# chol - serum cholestoral in mg\/dl\n\ndf['chol'].plot(kind='hist')","550f1ffc":"# fbs - (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n\nsns.countplot(df['fbs'])","23ec1b65":"# restecg - resting electrocardiographic results\n\nsns.countplot(df['restecg'])","78c12bed":"# thalach - maximum heart rate achieved\n\ndf['thalach'].plot(kind='hist')","f42facee":"# exang - exercise induced angina (1 = yes; 0 = no)\n\nsns.countplot(df['exang'])","b6aa2817":"# oldpeak - ST depression induced by exercise relative to rest\n\ndf['oldpeak'].plot(kind='hist')","96578cb4":"# slop - ethe slope of the peak exercise ST segment\n\nsns.countplot(df['slope'])","d1d6e0d7":"# ca - number of major vessels (0-3) colored by flourosopy\n\nsns.countplot(df['ca'])","dd65d211":"# thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n\nsns.countplot(df['thal'])","9d6c2859":"# Exploring gender differences\n\nmale_df = df[df['sex'] == 1]\nfemale_df = df[df['sex'] == 0]","8f4d5cc5":"bins = [25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\nmale_df['age'].plot(kind='hist', label='male age', bins=bins)\nfemale_df['age'].plot(kind='hist', label='female age', bins=bins)\nplt.legend()","8dcaeb0f":"# Males get more heartache\n\nsns.countplot(x='cp', data=df, hue='sex')\n#sns.countplot(female_df['cp'], label='chest pain femaile')\nplt.legend(labels=['Female', 'Male'])\nplt.show()","ffacfa61":"figure, axs = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 6))\nsns.distplot(male_df['trestbps'], ax=axs[0])\naxs[0].legend(['Male BP'])\nsns.distplot(female_df['trestbps'], ax=axs[1], )\naxs[1].legend(['Female BP'])\naxs[0].set_title('BP By Sex', size=16)\nplt.show()","72d62aa5":"bins = np.linspace(0, 600, 25, dtype='int')\n\nfig, axs = plt.subplots(2, figsize=(10, 6), sharex=True)\n\nsns.distplot(male_df['chol'], ax=axs[0], bins=bins)\naxs[0].legend(['Male Cholestrol'])\naxs[0].set_xlabel('')\n\nsns.distplot(female_df['chol'], ax=axs[1], bins=bins)\naxs[0].legend(['Female Cholestrol'])\naxs[1].set_xlabel('serum cholestoral in mg\/dl')","0b505cb0":"sns.countplot(x='fbs', hue='sex', data=df)\nplt.legend(['Female', 'Male'])\nplt.xlabel('fasting blood sugar > 120 mg\/dl \\n 1 = true; 0 = false')","102bbd9e":"sns.countplot(x='restecg', hue='sex', data=df)\nplt.legend(['Female', 'Male'])\nplt.xlabel('resting electrocardiographic results')","c4bf5822":"bins = np.linspace(50, 220, 18)\n\nfig, axs = plt.subplots(2, sharex=True, sharey=True, figsize=(10, 6))\n\nsns.distplot(male_df['thalach'], ax=axs[0], bins=bins)\naxs[0].legend(['Male Max HR'])\naxs[0].set_xlabel('')\n\nsns.distplot(female_df['thalach'], ax=axs[1], bins=bins)\naxs[1].legend(['Female Max HR'])\naxs[1].set_xlabel('maximum heart rate achieved')","0ad1c8b1":"sns.countplot(x='exang', hue='sex', data=df)\nplt.legend(['Females', 'Males'])\nplt.xlabel('exercise induced angina \\n (1 = yes; 0 = no)')","e400db03":"fig, axs = plt.subplots(2, sharex=True, sharey=True)\n\nsns.distplot(female_df['oldpeak'], ax=axs[0])\nsns.distplot(male_df['oldpeak'], ax=axs[1])\naxs[0].legend(['Females'])\naxs[1].legend(['Males'])\naxs[0].set_xlabel('')\naxs[1].set_xlabel('ST depression induced by exercise relative to rest')\nplt.show()","5899e1fe":"sns.countplot(x='slope', hue='sex', data=df)\nplt.legend(['Females', 'Males'])\nplt.xlabel('the slope of the peak exercise ST segment')","054f5cd7":"ax = sns.countplot(x='ca', hue='sex', data=df)\nax.legend(['Female', 'Male'])\nax.set_xlabel('number of major vessels (0-3) colored by flourosopy')","466bd56b":"ax = sns.countplot(x='thal', hue='sex', data=df)\nax.legend(['Female', 'Male'])\nax.set_xlabel('3 = normal; 6 = fixed defect; 7 = reversable defect')","421f2a42":"# Converting categorical variables to data type string, so onehotencoding \n# can be applied or dummy variables can be created\n\ndf[['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']] = df[['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']].astype('str')\n\ndf_dumms = pd.get_dummies(df, drop_first=True)","1c7eed0f":"X = df_dumms.drop(columns='target').values\ny = df_dumms['target'].values","f4d61231":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","abab168f":"logreg = LogisticRegression()\n\ngrid = {'penalty' : ['l1', 'l2', 'elasticnet', 'none'], \n       'C' : [1, 10, 100, 1000], 'solver' : ['liblinear', 'lbfgs']}\n\ngsearch = GridSearchCV(estimator=logreg, param_grid=grid, n_jobs=-1, \n                       cv=5, verbose=True)","d7cb1bf6":"gsearch.fit(X_train, y_train)","8a4ed9dd":"gsearch.best_params_","02bb2d66":"logestic_regression = LogisticRegression(**gsearch.best_params_)\n\nlogestic_regression.fit(X_train, y_train)\n\nlog_reg_preds = logestic_regression.predict(X_test)","1f906b85":"log_reg_cm = confusion_matrix(y_test, log_reg_preds)\nsns.heatmap(log_reg_cm, annot=True, annot_kws={'size':24})","d0f0d89c":"log_reg_accu = accuracy_score(y_test, log_reg_preds)\nprint('The Logestic Regression model achieved an accuracy score of {}'.format(log_reg_accu))","62633c7e":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)\ngnb_preds = gnb.predict(X_test)","96dac200":"gnb_cm = confusion_matrix(y_test, gnb_preds)\n\nsns.heatmap(gnb_cm, annot=True, annot_kws={'size':24})","7f31be0b":"gnb_accu = accuracy_score(y_test, gnb_preds)\nprint('The Gaussian NB Classifier accuracy score is {}'.format(gnb_accu))","690e5602":"dtree = DecisionTreeClassifier()\n\ndtree_grid = {'criterion' : ['gini', 'entropy'], 'splitter' : ['best', 'random'], \n             'min_samples_split' : [20, 25, 30, 35, 40, 50]}\n\ngsearch = GridSearchCV(dtree, param_grid=dtree_grid, n_jobs=-1, cv=5, verbose=True)\n\ngsearch.fit(X_train, y_train)","0a93377d":"dec_tree = DecisionTreeClassifier(**gsearch.best_params_)\n\ndec_tree.fit(X_train, y_train)\n\ndtree_preds = dec_tree.predict(X_test)","ee209766":"dtree_cm = confusion_matrix(y_test, dtree_preds)\n\nsns.heatmap(dtree_cm, annot=True, annot_kws={'size':24})","7c68e276":"dtree_acc = accuracy_score(y_test, dtree_preds)\nprint('The Decesion Tree model yielded an accuracy of {}'.format(dtree_acc))","fe50081b":"rf = RandomForestClassifier()\n\ngrid = {'n_estimators' : [18, 20, 22], \n       'criterion' : ['gini'], 'min_samples_split' : [8, 10, 12, 15], \n       'min_samples_leaf' : [7, 8, 9], 'max_depth' : [12, 15, 18], \n       'max_features' : [1, 2]}\n\ngridsearch = GridSearchCV(estimator=rf, param_grid=grid, n_jobs=-1, cv=5, verbose=3)\n\ngridsearch.fit(X_train, y_train)","8dc58e75":"rf_clf = RandomForestClassifier(**gridsearch.best_params_)\n\nrf_clf.fit(X_train, y_train)\n\nrf_preds = rf_clf.predict(X_test)","28c98dbc":"rf_cm = confusion_matrix(y_test, rf_preds)\n\nsns.heatmap(rf_cm, annot=True, annot_kws={'size':24})","9aaaa071":"rf_accu = accuracy_score(y_test, rf_preds)\n\nprint('The Random Forest Classifier model yielded an accuracy of {}'.format(rf_accu))","cf6c3e7a":"mm_scaler = MinMaxScaler()\nmm_scaler.fit(X_train)\nX_train_scaled = mm_scaler.transform(X_train)\nX_test_scaled = mm_scaler.transform(X_test)","5d188e68":"knn = KNeighborsClassifier()\n\nknn_grid = {'n_neighbors' : [13, 15, 17, 19],\n            'weights' : ['distance'],\n            'algorithm' : ['auto'],\n            'leaf_size' : [2, 3, 5, 7, 9],\n            'metric' : ['manhattan']}\n\ngs = GridSearchCV(estimator=knn, param_grid=knn_grid, n_jobs=-1, verbose=3)\n\ngs.fit(X_train_scaled, y_train)","877ae78d":"knn_clf = KNeighborsClassifier(**gs.best_params_)\nknn_clf.fit(X_train_scaled, y_train)\nknn_preds = knn_clf.predict(X_test_scaled)","57d33b53":"knn_cm = confusion_matrix(y_test, knn_preds)\n\nsns.heatmap(knn_cm, annot=True, annot_kws={'size':24})","722cdab7":"knn_acc = accuracy_score(y_test, knn_preds)\n\nprint('KNN accuracy score is {}'.format(knn_acc))","d3b3af15":"svc = SVC()\n\nsvc_grid = {'C' : [0.1, 1.0, 10.0],\n            'kernel' : ['rbf', 'linear'],\n            'gamma' : [0.00001, 0.0001, 0.001, 0.01]}\n\nsvc_gs = GridSearchCV(estimator=svc, param_grid=svc_grid, n_jobs=-1, verbose=3)\n\nsvc_gs.fit(X_train, y_train)","a1631488":"svm_clf = SVC(**svc_gs.best_params_)\n\nsvm_clf.fit(X_train, y_train)\n\nsvm_preds = svm_clf.predict(X_test)","57ab5528":"svm_cm = confusion_matrix(y_test, svm_preds)\n\nsns.heatmap(svm_cm, annot=True, annot_kws={'size':24})","ae80412b":"svm_accu = accuracy_score(y_test, svm_preds)\n\nprint('The SVM Classifier achieved an accuracy score of {}'.format(svm_accu))","c9b88a48":"gpc = GaussianProcessClassifier()\ngpc.fit(X_train, y_train)\n\ngpc_preds = gpc.predict(X_test)","1eee990c":"gpc_cm = confusion_matrix(y_test, gpc_preds)\n\nsns.heatmap(gpc_cm, annot=True, annot_kws={'size' : 24})","c5df86a9":"gpc_accu = accuracy_score(y_test, gpc_preds)\n\nprint('The GP Classifier had an accuracy score of {}'.format(gpc_accu))","604390b4":"mlp = MLPClassifier()\n\nmlp_grid = {'hidden_layer_sizes' : [(7, 3), (8, 4, 2), (14, 7, 3), (10,), (7,), (4,)],\n            'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n            'solver' : ['lbfgs', 'sgd', 'adam'],\n            'alpha' : [0.00001, 0.0001, 0.001],\n            'learning_rate' : ['constant', 'invscaling', 'adaptive']}\n\nmlp_gs = GridSearchCV(estimator=mlp, param_grid=mlp_grid, n_jobs=-1, verbose=4)\n\nmlp_gs.fit(X_train_scaled, y_train)","893d06c1":"mlp_cls = MLPClassifier(**mlp_gs.best_params_)\n\nmlp_cls.fit(X_test_scaled, y_test)\n\nmlp_preds = mlp_cls.predict(X_test_scaled)","9c8601ab":"mlp_cm = confusion_matrix(y_test, mlp_preds)\n\nsns.heatmap(mlp_cm, annot=True, annot_kws={'size' : 24})","b8af9676":"mlp_accu = accuracy_score(y_test, mlp_preds)\n\nprint('MLPClassifier achieved an accuracy score of {}'.format(mlp_accu))","b69413b1":"model = Sequential()\n\nmodel.add(Dense(units=12, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(units=4, activation='relu'))\n#model.add(Dropout(0.25))\n\nmodel.add(Dense(units=1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\n\nmodel.fit(x=X_train_scaled, y=y_train, epochs=1000, callbacks=[early_stopping], \n          validation_data=(X_test_scaled, y_test))","562cf14e":"loss = pd.DataFrame(model.history.history)\nloss.plot()","8394ecd4":"ann_preds = model.predict_classes(X_test_scaled)","c9eb3efb":"ann_cm = confusion_matrix(y_test, ann_preds)\n\nsns.heatmap(ann_cm, annot=True, annot_kws={'size' : 24})","3563c3fa":"ann_accu = accuracy_score(y_test, ann_preds)\n\nprint('The TF Keras ANN Model achieved an accuracy score of {}'.format(ann_accu))","d4ad28f5":"# Classifiers compared\n\ncls_scores = pd.DataFrame(data= [log_reg_accu, gnb_accu, dtree_acc, rf_accu, knn_acc,\n                    svm_accu, gpc_accu, mlp_accu, ann_accu],\n             index= ['Logistic Cls', 'GaussianNP Cls', 'DecisionTree Cls',\n                     'RandomForest Cls', 'KNNeighbours Cls', 'SVM Cls',\n                     'GaussianProcess Cls', 'MLP Cls', 'ANNs'], \n             columns= ['Accuracy Scores'])","d3cd412f":"cls_scores = cls_scores.sort_values(by='Accuracy Scores', ascending=False)\ncls_scores","8268abb8":"cls_scores.plot(kind='bar', figsize=(10, 4))","9827c218":"# Welcome\n## In this notebook you will find...\n## 1. EDA\n## 2. Experimentation with various classifiers, including TF Keras ANNs, to find the best one for this dataset ","1420f738":"# Thank you for viewing this notebook. Please suggest what could I have done better.\n### I know ideally I should have done a validation split too, to validate models applying them to test set. But I thought the data set was not big enough and I was a bit lazy ;-)"}}