{"cell_type":{"04fab89f":"code","d261498a":"code","db998493":"code","ae35a683":"code","15a58401":"code","1f4d4a86":"code","a958cf2c":"code","4f826656":"code","08b78c4c":"code","d6f90231":"code","7a097ff2":"code","a41a6bad":"code","be5c37ab":"code","66ee9e6c":"code","eee35b21":"code","feb90bba":"code","69756770":"code","b06a0ab8":"code","628515ba":"code","b0bca5f5":"code","11b09856":"code","3ad7ea14":"code","4d9ccbdf":"code","cf448235":"code","43fc57b7":"code","84c4b026":"code","03c1be54":"code","8dab632e":"code","68b202a7":"code","776fd2c1":"code","5266187a":"code","f4e71476":"code","9d300261":"code","0be0f8b5":"code","88bdb0c3":"code","c9fe5186":"code","84153be1":"markdown","d22eb263":"markdown","7fd38ccb":"markdown","fc88a45d":"markdown","aa47e0ee":"markdown","9c2db424":"markdown","dd71e8af":"markdown","958eb281":"markdown","c8d114fb":"markdown","b0142ba5":"markdown","18376b9d":"markdown","71224857":"markdown","2f60ed99":"markdown","6a5c43c1":"markdown","23942626":"markdown","d8d1b722":"markdown","28b5b571":"markdown","46250f6b":"markdown","9d38d7cd":"markdown","5a7e9f20":"markdown","bb0c07ba":"markdown","d3362907":"markdown","a19597bb":"markdown","6c52745c":"markdown","b8d75b6d":"markdown"},"source":{"04fab89f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d261498a":"input = \"..\/input\/assignment-regression-1\/\"","db998493":"import os\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ae35a683":"sns.set_style(\"whitegrid\")\nsns.set(rc={'figure.figsize':(20,8.27)})","15a58401":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n","1f4d4a86":"train_df = pd.read_csv(f\"{input}\/train.csv\")","a958cf2c":"train_df.shape","4f826656":"train_df.info()","08b78c4c":"train_df.head()","d6f90231":"train_df.columns","7a097ff2":"train_df['timestamp'].head()","a41a6bad":"train_df['timestamp'] = pd.to_datetime(train_df['timestamp'])","be5c37ab":"train_df['timestamp'].head()","66ee9e6c":"train_df.nunique()","eee35b21":"train_df['primary_use'].unique()","feb90bba":"train_df.isnull().sum()","69756770":"train_df.isnull().sum()\/len(train_df)*100","b06a0ab8":"df_group= train_df.groupby('primary_use')","628515ba":"train_df['meter_reading'].mean()","b0bca5f5":"df_group['meter_reading'].mean()","11b09856":"df_group['meter_reading'].sum()","3ad7ea14":"df_group['meter_reading'].describe()","4d9ccbdf":"train_df.groupby(['primary_use'])['meter_reading'].count().plot()","cf448235":"train_df.groupby(['primary_use'])['meter_reading'].mean().plot()","43fc57b7":"train_df.groupby(['primary_use'])['meter_reading'].sum().plot()","84c4b026":"train_df.groupby(['primary_use'])['timestamp'].max()","03c1be54":"train_df['timestamp_month']=train_df['timestamp'].dt.isocalendar().week","8dab632e":"train_df['timestamp_week']=train_df['timestamp'].dt.isocalendar().week","68b202a7":"train_df['building_id'].value_counts()","776fd2c1":"print(f\"{train_df['timestamp'].max()}\\n{train_df['timestamp'].min()}\")","5266187a":"def timespan_building(building_id):\n    print(f\"{train_df[train_df['building_id']==building_id]['timestamp'].max()}\\n{train_df[train_df['building_id']==building_id]['timestamp'].min()}\")","f4e71476":"timespan_building(83)","9d300261":"train_df.loc[ (train_df['building_id']==83) & (train_df['meter_reading']!=0.0) ] [['id','timestamp','meter_reading']].sort_values(by=\"timestamp\")","0be0f8b5":"train_df.loc[ (train_df['building_id']==83) & (train_df['meter_reading']==0.0) ] [['id','timestamp','meter_reading']].sort_values(by=\"timestamp\")","88bdb0c3":"train_df['timestamp_hour']=train_df['timestamp'].dt.hour","c9fe5186":"train_df.loc[ (train_df['building_id']==83) & (train_df['meter_reading']==0.0) & (train_df['timestamp']> pd.Timestamp('2016-02-07 13:00:00') ) ] [['id','timestamp','meter_reading', 'timestamp_hour']].sort_values(by=\"timestamp\")","84153be1":"I even tried random values for building_id and I found that always first data is of 1st January'16 and last data is of 31st Dec'16.\n\nI am not totally certain but I guess we have same first and last reading date for all buildings.","d22eb263":"# Exploratory Data Analysis\n    Electricity Consumption of a City\n    ","7fd38ccb":"Now Let's see the period of meter_reading measurment.","fc88a45d":"1. Education sector buildings have most consumption on an avg as well as maximum.\n2. The other major consumer of electricity are Entertainment\/Public Assembly. They may be theatres or public halls, etc.\n3. Parking buildings have very less consumption as expected.","aa47e0ee":"building_id 83, 33, 13 have most number of data.","9c2db424":"No. of buildings of particular type:","dd71e8af":"Why all building have not same number of readings?\nLet's check meter_reading and timestamp of particular building and see how it varies.","958eb281":"Our Y column is **meter_reading**.\n\n\"**meter_reading**\" is measurment of electricity consumption since last reading taken.","c8d114fb":"Parsing timestamp column into **datetime64**.","b0142ba5":"# Let see things by grouping buildings in their primary_use. ","18376b9d":"Total Consumption for Buildings grouped by **\"primary_use\"**","71224857":"Setting the limit for number of columns and rows to be printed to all.","2f60ed99":"We can see here that there is a **timestamp** column we must parse it into **datetime** datatype for more better analysis.","6a5c43c1":"Here we can see that total data is only of **101** different buildings.\n","23942626":"Here we can see that **cloud_coverage** data has lots of null values, **43.55%**. We can't amputate this much amount so we will drop it.","d8d1b722":"1. there is total 173 rows missing with air temperature.\n2. cloud coverage has a large amount of data missing","28b5b571":"So, this whole data is of 2016.","46250f6b":"Total of 558940 rows and 14 columns.","9d38d7cd":"Total consumption of Education is way more than others","5a7e9f20":"Setting the plot style and size.","bb0c07ba":"Mean Consumption for Buildings grouped by **\"primary_use\"**","d3362907":"I have questions regarding geography and location of data. Because it would had helped for better ananlysis.","a19597bb":"Average Consumption per building is 213.37102....","6c52745c":"Lets see time span for building_id 83, 33, 13","b8d75b6d":"Lets take a better look in terms of percentage."}}