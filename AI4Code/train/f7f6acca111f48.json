{"cell_type":{"ba5fdce6":"code","6785bf8a":"code","120eb74b":"code","5be801b3":"code","56ca4a04":"code","4bba0c26":"code","e61c01b9":"code","f02cf5e1":"code","cb3d318f":"code","52524a2c":"code","836eed0e":"code","747bc584":"code","4dd7f6c1":"code","6fc5abfa":"code","9d99bf92":"code","f111b2ef":"code","cc532989":"code","40ded5c4":"code","2b809232":"code","c6a04c3e":"code","6c4d00a1":"code","a65deea9":"code","369aef41":"code","734194f9":"code","48e2f197":"code","30a192ff":"code","4eb45ec3":"code","e9bb57da":"code","a5af8276":"code","d3e3e53f":"code","6060765b":"code","8058ba2e":"code","845db202":"code","834509e2":"code","6d4d3cbe":"code","605b50f2":"code","04822bea":"code","83e0ce41":"code","e21ddf7d":"code","5a2ae15e":"code","4a34029c":"code","318b8bb9":"code","d095c9ae":"code","27799a22":"code","05ee00bb":"code","add48092":"code","a7b89857":"markdown","03436bc4":"markdown","35e5e293":"markdown","1b5f2339":"markdown","842e2fae":"markdown","b7e1fba2":"markdown","88a6c5d3":"markdown","62b49c11":"markdown","a868fc01":"markdown","c4f8b9d0":"markdown","747326cf":"markdown","bc1a8d88":"markdown","84ba6952":"markdown","bd90c4a0":"markdown"},"source":{"ba5fdce6":"# Basic imports for the entire Kernel\nimport numpy as np\nimport pandas as pd\n# imports for loading data\nimport pydicom\nfrom glob import glob\nfrom tqdm import tqdm\n# import mask function\nimport sys\nsys.path.insert(0, '..\/input\/siim-acr-pneumothorax-segmentation')\nfrom mask_functions import rle2mask, mask2rle\n# plotting function\nfrom matplotlib import pyplot as plt","6785bf8a":"# load rles\nrles_df = pd.read_csv('..\/input\/siim-train-test\/siim\/train-rle.csv')\n# the second column has a space at the start, so manually giving column name\nrles_df.columns = ['ImageId', 'EncodedPixels']","120eb74b":"def dicom_to_dict(dicom_data, file_path, rles_df, encoded_pixels=True):\n    \"\"\"Parse DICOM dataset and returns a dictonary with relevant fields.\n\n    Args:\n        dicom_data (dicom): chest x-ray data in dicom format.\n        file_path (str): file path of the dicom data.\n        rles_df (pandas.core.frame.DataFrame): Pandas dataframe of the RLE.\n        encoded_pixels (bool): if True we will search for annotation.\n        \n    Returns:\n        dict: contains metadata of relevant fields.\n    \"\"\"\n    \n    data = {}\n    \n    # Parse fields with meaningful information\n    data['patient_name'] = dicom_data.PatientName\n    data['patient_id'] = dicom_data.PatientID\n    data['patient_age'] = int(dicom_data.PatientAge)\n    data['patient_sex'] = dicom_data.PatientSex\n    data['pixel_spacing'] = dicom_data.PixelSpacing\n    data['file_path'] = file_path\n    data['id'] = dicom_data.SOPInstanceUID\n    \n    # look for annotation if enabled (train set)\n    if encoded_pixels:\n        encoded_pixels_list = rles_df[rles_df['ImageId']==dicom_data.SOPInstanceUID]['EncodedPixels'].values\n       \n        pneumothorax = False\n        for encoded_pixels in encoded_pixels_list:\n            if encoded_pixels != ' -1':\n                pneumothorax = True\n        \n        # get meaningful information (for train set)\n        data['encoded_pixels_list'] = encoded_pixels_list\n        data['has_pneumothorax'] = pneumothorax\n        data['encoded_pixels_count'] = len(encoded_pixels_list)\n        \n    return data","5be801b3":"# create a list of all the files\ntrain_fns = sorted(glob('..\/input\/siim-train-test\/siim\/dicom-images-train\/*\/*\/*.dcm'))\n# parse train DICOM dataset\ntrain_metadata_df = pd.DataFrame()\ntrain_metadata_list = []\nfor file_path in tqdm(train_fns):\n    dicom_data = pydicom.dcmread(file_path)\n    train_metadata = dicom_to_dict(dicom_data, file_path, rles_df)\n    train_metadata_list.append(train_metadata)\ntrain_metadata_df = pd.DataFrame(train_metadata_list)","56ca4a04":"# create a list of all the files\ntest_fns = sorted(glob('..\/input\/siim-train-test\/siim\/dicom-images-test\/*\/*\/*.dcm'))\n# parse test DICOM dataset\ntest_metadata_df = pd.DataFrame()\ntest_metadata_list = []\nfor file_path in tqdm(test_fns):\n    dicom_data = pydicom.dcmread(file_path)\n    test_metadata = dicom_to_dict(dicom_data, file_path, rles_df, encoded_pixels=False)\n    test_metadata_list.append(test_metadata)\ntest_metadata_df = pd.DataFrame(test_metadata_list)","4bba0c26":"import tensorflow as tf\nimport cv2\nfrom skimage import morphology, io, color, exposure, img_as_float, transform","e61c01b9":"model_dir = '..\/input\/lung-segmentation-for-siimacr-pneumothorax\/trained_model.hdf5'\nlung_seg_model = tf.keras.models.load_model(model_dir, custom_objects=None, compile=True)","f02cf5e1":"def get_lung_seg_tensor(file_path, batch_size, seg_size, n_channels):\n    \n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((batch_size, seg_size, seg_size, n_channels))\n\n        # Process Image\n        pixel_array = pydicom.read_file(file_path).pixel_array\n        image_resized = cv2.resize(pixel_array, (seg_size, seg_size))\n        image_resized = exposure.equalize_hist(image_resized)\n        image_resized = np.array(image_resized, dtype=np.float64)\n        image_resized -= image_resized.mean()\n        image_resized \/= image_resized.std()\n        # Store Image\n        X[0,] = np.expand_dims(image_resized, axis=2)\n\n        return X","cb3d318f":"def remove_small_regions(img, size):\n    \"\"\"Morphologically removes small (less than size) connected regions of 0s or 1s.\"\"\"\n    img = morphology.remove_small_objects(img, size)\n    img = morphology.remove_small_holes(img, size)\n    return img","52524a2c":"def bounding_box(img):\n    # return max and min of a mask \n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n    return rmin, rmax, cmin, cmax","836eed0e":"def get_lung_seg_rle(metadata_df, seg_size):\n\n    processed_images = []\n\n    for id, row in metadata_df.iterrows():\n        # get image in the 4d tensor\n        img = get_lung_seg_tensor(row['file_path'],1,seg_size,1)\n        # get segmented mask\n        seg_mask = lung_seg_model.predict(img).reshape((seg_size,seg_size))\n        # only take above .5\n        seg_mask = seg_mask > 0.5\n        # remove small region\n        seg_mask = remove_small_regions(seg_mask, 0.02 * np.prod(seg_size))\n        processed_img = {}\n        processed_img['id'] = row['id']\n        processed_img['lung_mask'] = mask2rle(seg_mask*255, seg_size, seg_size)\n        processed_img['rmin'], processed_img['rmax'], processed_img['cmin'], processed_img['cmax'] = bounding_box(seg_mask)\n        processed_images.append(processed_img)\n    \n    return pd.DataFrame(processed_images)","747bc584":"seg_size = 256","4dd7f6c1":"#try:\n#    train_lung_mask_df = pd.read_csv('..\/input\/lung-segmentation-for-siimacr-pneumothorax\/train_lung_mask.csv')\n#except FileNotFoundError:\ntrain_lung_mask_df = get_lung_seg_rle(train_metadata_df, seg_size)\ntrain_lung_mask_df.to_csv('.\/train_lung_mask.csv', index=False)","6fc5abfa":"#try:\n#    test_lung_mask_df = pd.read_csv('..\/input\/lung-segmentation-for-siimacr-pneumothorax\/test_lung_mask.csv')\n#except FileNotFoundError:\ntest_lung_mask_df = get_lung_seg_rle(test_metadata_df, seg_size)\ntest_lung_mask_df.to_csv('.\/test_lung_mask.csv', index=False)","9d99bf92":"def plot_lung_seg(file_path, mask_encoded_list, lung_mask, rmin, rmax, cmin, cmax):\n    \n    pixel_array = pydicom.dcmread(file_path).pixel_array\n    \n    # use the masking function to decode RLE\n    mask_decoded_list = [rle2mask(mask_encoded, 1024, 1024).T for mask_encoded in mask_encoded_list]\n    lung_mask_decoded = cv2.resize(rle2mask(lung_mask, 256, 256), (1024,1024))\n    rmin, rmax, cmin, cmax =  rmin * 4, rmax * 4, cmin * 4, cmax * 4 \n    \n    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(20,10))\n    \n    \n    ax[0].imshow(pixel_array, cmap=plt.cm.bone)\n    ax[0].imshow(lung_mask_decoded, alpha=0.3, cmap=\"Blues\")\n    ax[0].set_title('Xray with Lung Mask')\n    \n    ax[1].imshow(pixel_array[rmin:rmax+1,cmin:cmax+1], cmap=plt.cm.bone)\n    ax[1].set_title('Cropped Xray')\n   \n    ax[2].imshow(lung_mask_decoded, cmap='Blues')\n    for mask_decoded in mask_decoded_list:\n        ax[2].imshow(mask_decoded, alpha=0.3, cmap=\"Reds\")\n    ax[2].set_title('Lung Mask with Pneumothorax')","f111b2ef":"train_lm_metadata_df = pd.concat([train_metadata_df, train_lung_mask_df.drop('id',axis=1)], axis=1)\ntest_lm_metadata_df = pd.concat([test_metadata_df, test_lung_mask_df.drop('id',axis=1)], axis=1)","cc532989":"for i, r in train_lm_metadata_df[train_lm_metadata_df['has_pneumothorax']==True][:10].iterrows():\n    file_path = r['file_path']\n    encoded_pixels_list = r['encoded_pixels_list']\n    lung_mask = r['lung_mask']\n    rmin = r['rmin'] \n    rmax = r['rmax']\n    cmin = r['cmin']\n    cmax = r['cmax']\n    \n    plot_lung_seg(file_path, encoded_pixels_list, lung_mask, rmin, rmax, cmin, cmax)","40ded5c4":"# defining configuration parameters\nimg_size = 512 # image resize size\nbatch_size = 8\n# batch size for training unet\nk_size = 3 # kernel size 3x3\nval_size = .20 # split of training set between train and validation set\nno_pneumo_drop = 0 # dropping some data to balance the class a little bit better","2b809232":"# imports for building the network\nfrom tensorflow import reduce_sum\nfrom tensorflow.keras.backend import pow\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom sklearn.model_selection import train_test_split\nimport cv2","c6a04c3e":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, file_path_list, labels, batch_size=32, \n                 img_size=256, channels=1, shuffle=True):\n        self.file_path_list = file_path_list\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.channels = channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    \n    def __len__(self):\n        'denotes the number of batches per epoch'\n        return int(np.floor(len(self.file_path_list)) \/ self.batch_size)\n    \n    def __getitem__(self, index):\n        'generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # get list of IDs\n        file_path_list_temp = [self.file_path_list[k] for k in indexes]\n        # generate data\n        X, y = self.__data_generation(file_path_list_temp)\n        # return data \n        return X, y\n    \n    def on_epoch_end(self):\n        'update ended after each epoch'\n        self.indexes = np.arange(len(self.file_path_list))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, file_path_list_temp):\n        'generate data containing batch_size samples'\n        X = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n        y = np.empty((self.batch_size, self.img_size, self.img_size, self.channels))\n        \n        for idx, file_path in enumerate(file_path_list_temp):\n            \n            id = file_path.split('\/')[-1][:-4]\n            rle = self.labels.get(id)\n            image = pydicom.read_file(file_path).pixel_array\n            image_resized = cv2.resize(image, (self.img_size, self.img_size))\n            image_resized = np.array(image_resized, dtype=np.float64)\n            \n            X[idx,] = np.expand_dims(image_resized, axis=2)\n            \n            # if there is no mask create empty mask\n            # notice we are starting of with 1024 because we need to use the rle2mask function\n            if rle is None:\n                mask = np.zeros((1024, 1024))\n            else:\n                if len(rle) == 1:\n                    mask = rle2mask(rle[0], 1024, 1024).T\n                else: \n                    mask = np.zeros((1024, 1024))\n                    for r in rle:\n                        mask =  mask + rle2mask(r, 1024, 1024).T\n                        \n            mask_resized = cv2.resize(mask, (self.img_size, self.img_size))\n            y[idx,] = np.expand_dims(mask_resized, axis=2)\n            \n        # normalize \n        X = X \/ 255\n        y = (y > 0).astype(int)\n            \n        return X, y","6c4d00a1":"masks = {}\nfor index, row in train_metadata_df[train_metadata_df['has_pneumothorax']==1].iterrows():\n    masks[row['id']] = list(row['encoded_pixels_list'])","a65deea9":"bad_data = train_metadata_df[train_metadata_df['encoded_pixels_count']==0].index\nnew_train_metadata_df = train_metadata_df.drop(bad_data)","369aef41":"drop_data = new_train_metadata_df[new_train_metadata_df['has_pneumothorax'] == False].sample(no_pneumo_drop).index\nnew_train_metadata_df = new_train_metadata_df.drop(drop_data)","734194f9":"# split the training data into train and validation set (stratified)\nX_train, X_val, y_train, y_val = train_test_split(new_train_metadata_df.index, new_train_metadata_df['has_pneumothorax'].values, test_size=val_size, random_state=42)\nX_train, X_val = new_train_metadata_df.loc[X_train]['file_path'].values, new_train_metadata_df.loc[X_val]['file_path'].values","48e2f197":"params = {'img_size': img_size,\n          'batch_size': batch_size,\n          'channels': 1,\n          'shuffle': True}\n\n# Generators\ntraining_generator = DataGenerator(X_train, masks, **params)\nvalidation_generator = DataGenerator(X_val, masks, **params)","30a192ff":"x, y = training_generator.__getitem__(0)\nprint(x.shape, y.shape)","4eb45ec3":"fig = plt.figure()\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nax = fig.add_subplot(1, 2, 1)\nax.imshow(x[6].reshape(img_size, img_size), cmap=plt.cm.bone)\nax = fig.add_subplot(1, 2, 2)\nax.imshow(np.reshape(y[6], (img_size, img_size)), cmap=\"gray\")","e9bb57da":"def bn_act(x, act=True):\n    'batch normalization layer with an optinal activation layer'\n    x = tf.keras.layers.BatchNormalization()(x)\n    if act == True:\n        x = tf.keras.layers.Activation('relu')(x)\n    return x","a5af8276":"def conv_block(x, filters, kernel_size=3, padding='same', strides=1):\n    'convolutional layer which always uses the batch normalization layer'\n    conv = bn_act(x)\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n    return conv","d3e3e53f":"def stem(x, filters, kernel_size=3, padding='same', strides=1):\n    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n    conv = conv_block(conv, filters, kernel_size, padding, strides)\n    shortcut = Conv2D(filters, kernel_size=1, padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    output = Add()([conv, shortcut])\n    return output","6060765b":"def residual_block(x, filters, kernel_size=3, padding='same', strides=1):\n    res = conv_block(x, filters, k_size, padding, strides)\n    res = conv_block(res, filters, k_size, padding, 1)\n    shortcut = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    output = Add()([shortcut, res])\n    return output","8058ba2e":"def upsample_concat_block(x, xskip):\n    u = UpSampling2D((2,2))(x)\n    c = Concatenate()([u, xskip])\n    return c","845db202":"def ResUNet(img_size):\n    f = [16, 32, 64, 128, 256, 512, 1024, 2048] * 32\n    inputs = Input((img_size, img_size, 1))\n    \n    ## Encoder\n    e0 = inputs\n    e1 = stem(e0, f[0])\n    e2 = residual_block(e1, f[1], strides=2)\n    e3 = residual_block(e2, f[2], strides=2)\n    e4 = residual_block(e3, f[3], strides=2)\n    e5 = residual_block(e4, f[4], strides=2)\n    e6 = residual_block(e5, f[5], strides=2)\n    e7 = residual_block(e6, f[6], strides=2)\n    \n    ## Bridge\n    b0 = conv_block(e7, f[6], strides=1)\n    b1 = conv_block(b0, f[6], strides=1)\n    \n    ## Decoder\n    u1 = upsample_concat_block(b1, e6)\n    d1 = residual_block(u1, f[6])\n    \n    u2 = upsample_concat_block(d1, e5)\n    d2 = residual_block(u2, f[3])\n    \n    u3 = upsample_concat_block(d2, e4)\n    d3 = residual_block(u3, f[2])\n    \n    u4 = upsample_concat_block(d3, e3)\n    d4 = residual_block(u4, f[1])\n    \n    u5 = upsample_concat_block(d4, e2)\n    d5 = residual_block(u5, f[1])\n    \n    u6 = upsample_concat_block(d5, e1)\n    d6 = residual_block(u6, f[1])\n    \n    outputs = tf.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d6)\n    model = tf.keras.models.Model(inputs, outputs)\n    return model","834509e2":"def dsc(y_true, y_pred):\n    smooth = 1.\n    y_true_f = Flatten()(y_true)\n    y_pred_f = Flatten()(y_pred)\n    intersection = reduce_sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) \/ (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dsc(y_true, y_pred)\n    return loss\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss","6d4d3cbe":"model = ResUNet(img_size)\nadam = tf.keras.optimizers.Adam(lr = 0.01, epsilon = 0.1)\nmodel.compile(optimizer=adam, loss=bce_dice_loss, metrics=[dsc])\n#model.summary() # print out the architecture of our network","605b50f2":"# load a pre trained model here if you wish\n# model.load_weights('..\/input\/resunet-e200-s256\/ResUNet.h5')","04822bea":"# running more epoch to see if we can get better results\nhistory = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=10, verbose=1)","83e0ce41":"model.save('.\/ResUNet.h5')","e21ddf7d":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.figure(figsize=(20,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['dsc'])\nplt.plot(history.history['val_dsc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n\n# summarize history for loss\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","5a2ae15e":"def plot_train(img, mask, pred):\n    \n    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(15,5))\n    \n    ax[0].imshow(img, cmap=plt.cm.bone)\n    ax[0].set_title('Chest X-Ray')\n    \n    ax[1].imshow(mask, cmap=plt.cm.bone)\n    ax[1].set_title('Mask')\n    \n    ax[2].imshow(pred, cmap=plt.cm.bone)\n    ax[2].set_title('Pred Mask')\n    \n    plt.show()","4a34029c":"# lets loop over the predictions and print some good-ish results\ncount = 0\nfor i in range(0,50):\n    if count <= 50:\n        x, y = validation_generator.__getitem__(i)\n        predictions = model.predict(x)\n        for idx, val in enumerate(x):\n            #if y[idx].sum() > 0 and count <= 15: \n                img = np.reshape(x[idx]* 255, (img_size, img_size))\n                mask = np.reshape(y[idx]* 255, (img_size, img_size))\n                pred = np.reshape(predictions[idx], (img_size, img_size))\n                pred = pred > 0.5\n                pred = pred * 255\n                plot_train(img, mask, pred)\n                count += 1","318b8bb9":"def get_test_tensor(file_path, batch_size, img_size, channels):\n    \n        X = np.empty((batch_size, img_size, img_size, channels))\n\n        # Store sample\n        pixel_array = pydicom.read_file(file_path).pixel_array\n        image_resized = cv2.resize(pixel_array, (img_size, img_size))\n        image_resized = np.array(image_resized, dtype=np.float64)\n        image_resized -= image_resized.mean()\n        image_resized \/= image_resized.std()\n        X[0,] = np.expand_dims(image_resized, axis=2)\n\n        return X","d095c9ae":"from skimage import morphology\n\ndef remove_small_regions(img, size):\n    \"\"\"Morphologically removes small (less than size) connected regions of 0s or 1s.\"\"\"\n    img = morphology.remove_small_objects(img, size)\n    img = morphology.remove_small_holes(img, size)\n    return img","27799a22":"submission = []\n\nfor i, row in test_metadata_df.iterrows():\n\n    test_img = get_test_tensor(test_metadata_df['file_path'][i],1,img_size,1)\n    \n    pred_mask = model.predict(test_img).reshape((img_size,img_size))\n    prediction = {}\n    prediction['ImageId'] = str(test_metadata_df['id'][i])\n    pred_mask = cv2.resize(pred_mask.astype('float32'), (1024, 1024))\n    pred_mask = (pred_mask > .5).astype(int)\n    pred_mask = remove_small_regions(pred_mask, 0.02 * np.prod(1024))\n    \n    if pred_mask.sum() < 1:\n        prediction['EncodedPixels']=  -1\n    else:\n        prediction['EncodedPixels'] = mask2rle(pred_mask.T * 255, 1024, 1024)\n        \n    submission.append(prediction)","05ee00bb":"submission_df = pd.DataFrame(submission)\nsubmission_df = submission_df[['ImageId','EncodedPixels']]\n# check out some predictions and see if it looks good\nsubmission_df[ submission_df['EncodedPixels'] != -1].head()","add48092":"submission_df.to_csv('.\/submission.csv', index=False)","a7b89857":"### ResUNet TensorFlow Keras Implementation\n\nResUNet \ubaa8\ub378\uc744 \uad6c\ucd95\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\uc0ac\uc2e4 \uc800\uc790\ub294 [Github](https:\/\/github.com\/nikhilroxtomar\/Deep-Residual-Unet)\uc5d0\uc11c ResUNet\uc758 \uba4b\uc9c4 \uad6c\ud604\uc744 \ucc3e\uc558\uace0 \uc544\ub798 \ucee4\ub110\uc5d0\uc11c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.","03436bc4":"\uc6b0\ub9ac \ubaa8\ub378\uc774 \uc548\ub418\ub294 \uac83\ubcf4\ub2e4 \uc798 \ud55c \uacb0\uacfc\ubb3c\uc744 \ub354 \ub9ce\uc774 \uc5bb\ub294 \uac78 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ube44\ub85d \uc6b0\ub9ac\uc758 \ud3d0 \ubd84\ud560\uc774 \uc644\ubcbd\ud558\uc9c0 \uc54a\uc9c0\ub9cc \uc774\ubbf8\uc9c0\uc758 \uc790\ub974\uae30 \ubc84\uc804\uc740 \uc0ac\uc6a9\ud558\ub294\ub370 \uc720\ub9dd\ud574 \ubcf4\uc785\ub2c8\ub2e4. \ub2e4\uc74c \ucee4\ub110\uc5d0\uc11c Dr. Konya\uac00 \uc190\uc218 \ub9cc\ub4e0 \uc5b4\ub178\ud14c\uc774\uc158\uacfc \uc5bc\ub9c8\ub098 \uac00\uae4c\uc6cc\uc84c\ub294\uc9c0 \ube44\uad50\ud574\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.","35e5e293":"#### Data Generator\n\n\ub370\uc774\ud130\ub97c \uc6b0\ub9ac \ubaa8\ub378\uc5d0 \uc785\ub825\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\uc790 \uc9c0\uc815 \ub370\uc774\ud130 \uc0dd\uc131\uae30\ub97c \ub9cc\ub4ed\ub2c8\ub2e4. \uc0dd\uc131\uae30\ub97c \uc0ac\uc6a9\ud558\uba74 \ub370\uc774\ud130\ub97c \ud55c \ubc88\uc5d0 \ubaa8\ub450 \uba54\ubaa8\ub9ac\uc5d0 \ub85c\ub4dc\ud558\ub294 \ub300\uc2e0 \uc810\uc9c4\uc801\uc73c\ub85c \ub85c\ub4dc\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc0ac\uc6a9\uc790 \uc9c0\uc815 \uc0dd\uc131\uae30\ub97c \uc0ac\uc6a9\ud558\uba74 \ub370\uc774\ud130\ub97c \ub85c\ub4dc\ud558\ub294 \ub3d9\uc548 \ub354 \ub9ce\uc740 \uc0ac\uc6a9\uc790 \uc9c0\uc815\uc5d0 \ub9de\ucd9c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ubaa8\ub378\uc774 GPU\uc5d0\uc11c \ucc98\ub9ac\ub418\uace0 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc0ac\uc6a9\uc790 \uc9c0\uc815 \uc0dd\uc131\uae30\ub97c \ud1b5\ud574 \uc774\ubbf8\uc9c0\ub97c \uc0ac\uc804\uc5d0 \ucc98\ub9ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud604\uc7ac\ub294 \ub2e4\uc911 \ud504\ub85c\uc138\uc11c\ub97c \ud65c\uc6a9\ud558\uc5ec \uc0ac\uc804 \ucc98\ub9ac\ub97c \ubcd1\ub82c\ud654 \ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.","1b5f2339":"\uc6b0\ub9ac\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \ubc29\ubc95\uc73c\ub85c \uc0dd\uc131\uae30 \ud074\ub798\uc2a4\uac00 \uc791\ub3d9\ud558\uace0 \uc62c\ubc14\ub978 \ub370\uc774\ud130\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \uc804\ub2ec\ud558\uace0 \uc788\ub294\uc9c0 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","842e2fae":"\uae30\ud749\uc744 \uc608\uce21\ud558\uace0 \uc2dd\ubcc4\ud558\uae30 \uc704\ud574 \ubc29\uae08 \uad6c\ucd95\ud55c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.","b7e1fba2":"\uc800\uc790\ub294 \uc0ac\uc804\uc5d0 \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 \ub370\uc774\ud130 \uc138\ud2b8\uc640 \ubaa8\ub4e0 \uc0ac\ub78c\uc758 \uc0b6\uc744 \ud3b8\ud558\uac8c \ud558\uae30 \uc704\ud574 \uc0ac\uc804 \ucc98\ub9ac \ub41c \ud3d0 \ubd84\ud560 \ub9c8\uc2a4\ud06c\ub97c [Lung Segmentation For SIIM-ACR Pneumothorax\n](https:\/\/www.kaggle.com\/ekhtiar\/lung-segmentation-for-siimacr-pneumothorax)\uc5d0 \ub9cc\ub4e4\uc5b4 \ub193\uc558\uc2b5\ub2c8\ub2e4.","88a6c5d3":"## ResUNet\n\n\uc774 \uc139\uc158\uc5d0\uc11c\ub294 UNet \ub300\uc2e0 ResUNet\uc744 \uc0ac\uc6a9\ud558\uc5ec \uae30\ud749\uc744 \uc608\uce21\ud569\ub2c8\ub2e4. \uc774 CNN \uc544\ud0a4\ud14d\ucc98\ub97c \uc81c\uc548\ud55c \uc6d0\ubb38 \ub17c\ubb38\uc740 [ResUNet-a: a deep learning framework for semantic segmentation of remotely sensed data](https:\/\/arxiv.org\/abs\/1904.00592) \uc785\ub2c8\ub2e4. \ub9cc\uc57d \ub2f9\uc2e0\uc774 \ub17c\ubb38\uc744 \uc77d\ub294\ub2e4\uba74, \uc774 \ub124\ud2b8\uc6cc\ud06c\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc815\ubcf4\ub97c \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \ucc38\uace0\ud560 \uc218 \uc788\ub3c4\ub85d, \uc544\ub798 \ubaa8\ub378\uc758 \uc544\ud0a4\ud14d\ucc98\ub97c \ucca8\ubd80\ud569\ub2c8\ub2e4.\n\n![ResUNet Architecture](https:\/\/raw.githubusercontent.com\/nikhilroxtomar\/Deep-Residual-Unet\/master\/images\/arch.png)","62b49c11":"#### Checking out our model\n\n\uc6b0\ub9ac\ub294 \uc544\ub798\uc640 \uac19\uc740 \ubc29\ubc95\uc73c\ub85c \ubaa8\ub378\uc5d0 \ub300\ud574 \uc5b4\ub5bb\uac8c \uc791\ub3d9\ud558\ub294\uc9c0 \uc2dc\uac01\uc801\uc73c\ub85c \uc870\uc0ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","a868fc01":"\uc774 \ub300\uc678\uc5d0\uc11c \uc6b0\ub9ac\ub294 \uc544\uc8fc \uc791\uace0 \uc791\uc740 \uc608\uce21\uc744 \ub9ce\uc774 \ud560 \uac83\uc785\ub2c8\ub2e4. \uc9c0\uc5ed\uc774 \ub9e4\uc6b0 \uc791\uc740 \uacbd\uc6b0 \uc77c\ubc18\uc801\uc73c\ub85c \uc81c\uac70\ud558\ub294 \uac83\uc774 \uc88b\uc740 \uc815\ucc45\uc785\ub2c8\ub2e4. \uc544\ub798\uc758 \uae30\ub2a5\uc740 \uc774\ub97c \uc218\ud589\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.","c4f8b9d0":"#### proof of concept\n\uc6b0\ub9ac\uc758 segmentation\uc744 \ud655\uc778\ud558\uace0 \uadf8\uac83\uc774 \uc798 \ub3cc\uc544\uac00\ub294\uc9c0 \uc2dc\uac01\uc801\uc73c\ub85c \ud655\uc778\ud574\ubd05\uc2dc\ub2e4.","747326cf":"#### Plotting Model Training History\n\n\uc774 \uc139\uc158\uc5d0\uc11c\ub294 \ub2e8\uc21c\ud55c non-flashy matplotlib\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ud45c\uc2dc\ud569\ub2c8\ub2e4.","bc1a8d88":"#### Making Predictions\n\n\uc774 \uc139\uc158\uc5d0\uc11c\ub294 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc608\uce21\ud558\uace0 \ub204\ucd9c(leak)\uc744 \uc774\uc6a9\ud558\uc9c0 \uc54a\uace0 \uc81c\ucd9c\ubb3c\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.","84ba6952":"## Introduction\n\n\uc774\uc804 \ucee4\ub110 [(Finding Pneumo: EDA and UNet Starter Code)](https:\/\/www.kaggle.com\/ekhtiar\/finding-pneumo-eda-and-unet-starter-code)\uc5d0\uc11c \uc6b0\ub9ac\ub294 \ub370\uc774\ud130 EDA\ub97c \uc9c4\ud589\ud558\uc600\uace0 \uc791\ub3d9\ud558\uc9c0 \uc54a\uc740 UNet \ubaa8\ub378\uc744 \ud559\uc2b5\ud588\uc2b5\ub2c8\ub2e4. \uc774\ubc88 \ucee4\ub110\uc5d0\uc11c\ub294 \uc77c\ubd80 \uae30\ud749 \uc0ac\ub840\ub97c \uc2dd\ubcc4\ud558\ub294 ResNet \ubaa8\ub378\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n\n**\uc774 \ucee4\ub110\uc5d0\uc11c\ub294 \ub204\ucd9c\uc774 \uae30\ud749 \ud658\uc790\ub97c \uad6c\ud560 \uc218 \uc5c6\uae30 \ub54c\ubb38\uc5d0, \uc5b4\ub5a0\ud55c \ub204\ucd9c\ub3c4 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc744 \uac81\ub2c8\ub2e4.**\n\uc800\uc790\uc758 \ubaa9\ud45c\ub294 \ub370\uc774\ud130 \uc138\ud2b8\uc640 \ub2e4\ub978 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \uc77c\ubc18\uc801\uc778 \uc811\uadfc \ubc29\uc2dd\uacfc \ubaa8\ub378\uc744 \uc2dd\ubcc4\ud558\ub294 \uac83\uc785\ub2c8\ub2e4. \uc774\ub97c \uc704\ud574 \ucee4\ub110\uc758 \uc694\uc57d \uc139\uc158\uc5d0\uc11c ResUNet \uad50\uc721 \uacfc\uc815\uc744 \ubb38\uc11c\ud654 \ud558\uaca0\uc2b5\ub2c8\ub2e4.","bd90c4a0":"## Lung Segmentation\n\uc800\uc790\uc758 \ub9c8\uc9c0\ub9c9 EDA \ub178\ud2b8\ubd81\uacfc discussion \uc139\uc158\uc5d0\uc11c [Dr. Konya](https:\/\/www.kaggle.com\/sandorkonya)\ub294 \uba4b\uc9c4 \uacf5\ud5cc\uc744 \ud588\uc2b5\ub2c8\ub2e4. \uadf8\uac00 \uc5b8\uae09\ud55c \ub9e4\uc6b0 \uc911\uc694\ud558\uace0 \ubd84\uba85\ud55c \uc810\uc740 \uc774 \ub300\ud68c\uc758 \uc0ac\uc6a9 \uc0ac\ub840\uac00 \uc778\uc815\ub418\ub294 \ud55c \uae30\ud749\uc774 \ud3d0\uc5d0\ub9cc \ub098\ud0c0\ub0a0 \uac83\uc774\uae30 \ub54c\ubb38\uc5d0 \uc774 \ub300\ud68c\uc5d0\uc11c \ud3d0 \ubd84\ud560\uc744 \uc218\ud589\ud558\uae30 \uc704\ud574 \uae30\uc874 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574\uc544\ud55c\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n\uc800\uc790\ub294 Github\uc5d0\uc11c \ud6cc\ub96d\ud55c \uc5c5\uc801\uc744 \ubc1c\uacac\ud588\uc2b5\ub2c8\ub2e4. \uadf8 \uc911 \ud558\ub098\ub294 \ud3d0 \ubd84\ud560\uc744 \uc704\ud55c [imlab-uiip](https:\/\/github.com\/imlab-uiip\/lung-segmentation-2d)\uc785\ub2c8\ub2e4. \uadf8\ub4e4\uc740 \ub610\ud55c Github \uc800\uc7a5\uc18c\uc5d0 \uc0ac\uc804 \ud6c8\ub828\ub41c \ubaa8\ub378\uc744 \uc5c5\ub85c\ub4dc \ud588\uc2b5\ub2c8\ub2e4. \uc774 \uc139\uc158\uc5d0\uc11c\ub294 \uc774 \uc0ac\uc804\uc5d0 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc774 \ub300\ud68c\uc758 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \ub9c8\uc2a4\ud06c\ub97c \ub9cc\ub4ed\ub2c8\ub2e4. \ub610\ud55c, \uc774\ubc88 \ub300\ud68c\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 RLE \uae30\ub2a5\uc73c\ub85c \ub9c8\uc2a4\ud06c\ub97c \ud1b5\ud569\ud558\uc5ec \ud5a5\ud6c4 \uc0ac\ub840\uc5d0\uc11c \uc27d\uac8c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \ub9cc\ub4ed\ub2c8\ub2e4.\n\n\uadf8 \ubaa8\ub378\uc744 \ud55c \ubc88 \ub3cc\ub824\ubd24\ub294\ub370, \ud3d0 \ubd84\ud560\uc758 \uc815\ud655\uc131\uc774 \uc644\ubcbd\ud558\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc774 \ubaa8\ub378\uc740 \uc774\ubbf8\uc9c0\uc5d0\uc11c \uc6d0\ud558\uc9c0 \uc54a\ub294 \ubd80\ubd84\uc744 \uc790\ub3d9\uc73c\ub85c \uc790\ub974\ub294\ub370 \ucda9\ubd84\ud560 \uac70 \uac19\uc2b5\ub2c8\ub2e4. \ud1a0\ub860\uc5d0\uc11c [Lung segmentation Dataset of the training images by a radiologist](https:\/\/www.kaggle.com\/c\/siim-acr-pneumothorax-segmentation\/discussion\/100864)\uc640 [Dr. Konya](https:\/\/www.kaggle.com\/sandorkonya)\ub294 \uacbd\uc7c1\uc5d0\uc11c \uc6b0\ub9ac\uc5d0\uac8c \uc911\uc694\ud55c \ubd80\ubd84\ub9cc \uc798\ub77c \ub0b4\uae30 \uc704\ud574 Dr. Konya\uac00 \ud55c \uc8fc\uc11d\uc744 \uc911\uc694\ud558\uac8c \uc9d1\uc5c8\uc2b5\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc774\ub97c \uc790\ub3d9\ud654 \ud558\uace0 \uc138\ubd84\ud654\ub97c \uc704\ud55c \uacbd\uacc4 \uc0c1\uc790\ub97c \uc5bb\uc73c\ub824\uace0\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ubc29\uc2dd\uc73c\ub85c \ub370\uc774\ud130\uc5d0\uc11c \ub9ce\uc740 \ub178\uc774\uc988\ub97c \uc81c\uac70\ud558\uace0 \ubaa8\ub378\uc758 \uc815\ud655\ub3c4\ub97c \ub192\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4."}}