{"cell_type":{"5e41d46d":"code","e4f1ccbf":"code","58611b30":"code","f6e7e649":"code","e9eeb3ba":"code","c5dc906e":"code","fc487400":"code","f9fcfcb8":"code","d4b6c4f9":"code","69614ccc":"code","214a60b1":"code","c68f98b1":"code","cb65e61f":"code","996ecee4":"code","ef05ce72":"code","10cb0ac6":"code","fa5a4901":"code","0a31f736":"code","cd054c96":"code","b3858907":"code","b09c432e":"code","d17d3507":"code","adf4e70e":"code","388ec4fd":"code","38d70251":"code","710b3892":"code","675daede":"code","8061c799":"code","fce61356":"code","194b471e":"code","a7055d00":"code","f2d33888":"code","8507984e":"code","8255f052":"code","be747be6":"code","2c834891":"code","8b0b9866":"code","02a78587":"code","b879f711":"code","a773eac4":"code","f168a550":"code","5247ed43":"code","64a078ee":"code","918e067f":"code","d06177b5":"code","b20de67a":"code","0c788895":"code","692994ce":"code","19ef78c8":"code","af46e207":"code","59217b57":"code","d4347e53":"code","42aa3ce0":"code","92e4f91a":"code","19be562f":"code","df088f3c":"code","05e40197":"code","26cfd4f5":"code","98e33da9":"code","5bdaa3da":"code","01c24d71":"code","b8a869e2":"code","abf3d7dd":"markdown","f0115c47":"markdown","1b1dc4d4":"markdown","5d652c26":"markdown","6d352b48":"markdown","17ddcb29":"markdown","1f928588":"markdown","f4bb5ee1":"markdown","5f197817":"markdown"},"source":{"5e41d46d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e4f1ccbf":"import pandas as pd","58611b30":"train_df=pd.read_csv('..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/train.csv')","f6e7e649":"train_df.head()","e9eeb3ba":"train_df['Class'].value_counts()","c5dc906e":"from keras.preprocessing import image","fc487400":"import matplotlib.pyplot as plt\nimport seaborn as sns","f9fcfcb8":"img=image.load_img('..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/train\/image1000.jpg')","d4b6c4f9":"img=image.img_to_array(img)\/255","69614ccc":"plt.imshow(img)","214a60b1":"print(img.shape)","c68f98b1":"from sklearn.model_selection import StratifiedKFold","cb65e61f":"train_df['Kfold']=-1","996ecee4":"train_df.head()","ef05ce72":"train_df=train_df.sample(frac=1).reset_index(drop=True)","10cb0ac6":"train_df.tail()","fa5a4901":"y=train_df['Class']","0a31f736":"kf=StratifiedKFold(n_splits=5)","cd054c96":"for f,(t_,v_) in enumerate(kf.split(X=train_df,y=y)):\n    train_df.loc[v_,'Kfold']=f","b3858907":"train_df.head()","b09c432e":"train=train_df[train_df['Kfold']!=4]","d17d3507":"valid=train_df[train_df['Kfold']==4]","adf4e70e":"valid.tail()","388ec4fd":"valid['Class'].value_counts()","38d70251":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\n#         shear_range=0.2,\n#         zoom_range=0.2,\n#         horizontal_flip=True,\n#         width_shift_range=0.1,\n#         height_shift_range=0.1)\n\ntrain_generator=train_datagen.flow_from_dataframe(dataframe=train,\n                                            directory=\"..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/train\/\",\n                                            x_col=\"Image\",\n                                            y_col=\"Class\",\n                                            subset=\"training\",\n                                            batch_size=128,\n                                            seed=42,\n                                            shuffle=True,\n                                            class_mode=\"categorical\",\n                                            target_size=(331,331))","710b3892":"from keras.preprocessing.image import ImageDataGenerator\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\n#         shear_range=0.2,\n#         zoom_range=0.2,\n#         horizontal_flip=True,\n#         width_shift_range=0.1,\n#         height_shift_range=0.1)\n\nvalid_generator=valid_datagen.flow_from_dataframe(dataframe=valid,\n                                            directory=\"..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/train\/\",\n                                            x_col=\"Image\",\n                                            y_col=\"Class\",\n                                            subset=\"training\",\n                                            batch_size=128,\n                                            seed=42,\n                                            shuffle=True,\n                                            class_mode=\"categorical\",\n                                            target_size=(331,331))","675daede":"from keras.applications.nasnet import NASNetLarge\n# from keras.applications.resnet50 import preprocess_input,decode_predictions\nfrom keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten\nfrom keras.models import Model\nfrom keras.utils import to_categorical","8061c799":"resnet=NASNetLarge(include_top=True,weights='imagenet')","fce61356":"x=resnet.layers[-2].output\nfc1=Dense(6,activation='softmax')(x)","194b471e":"my_model=Model(inputs=resnet.input,outputs=fc1)","a7055d00":"# my_model.summary()","f2d33888":"from keras.optimizers import Adam","8507984e":"adam=Adam(learning_rate=0.0001)","8255f052":"for l in my_model.layers[:-5]:\n    #print(l)\n    l.trainable = False\nmy_model.compile(optimizer='adam',loss =\"categorical_crossentropy\",metrics=[\"accuracy\"])","be747be6":"my_model.fit_generator(train_generator,steps_per_epoch=5176\/\/128,validation_data=valid_generator,validation_steps=1293\/\/128,epochs=2)","2c834891":"my_model.save('model.h5')","8b0b9866":"# import keras","02a78587":"# my_model=keras.models.load_model('.\/model.h5')","b879f711":"test_datagen = ImageDataGenerator(rescale=1.\/255)","a773eac4":"test_generator = test_datagen.flow_from_directory(\n    directory='..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/test\/',\n    target_size=(331, 331),\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=None,\n    shuffle=False,\n    seed=42\n)","f168a550":"import shutil","5247ed43":"import os","64a078ee":"os.mkdir('test_data')","918e067f":"os.mkdir('test_data\/test')","d06177b5":"for file in os.listdir('..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/test'):\n    shutil.copyfile('..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/test\/' + file,'.\/test_data\/test\/' + file)","b20de67a":"len(os.listdir('.\/test_data\/test'))","0c788895":"test_generator = test_datagen.flow_from_directory(\n    directory='.\/test_data\/',\n    target_size=(331, 331),\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=None,\n    shuffle=False,\n    seed=42\n)","692994ce":"y_pred=my_model.predict_generator(test_generator,\nverbose=1)","19ef78c8":"y_pred_2=np.argmax(y_pred,axis=1)","af46e207":"train_datagen.class_indices","59217b57":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in y_pred_2]","d4347e53":"predictions[:10]","42aa3ce0":"test_name=os.listdir('.\/test_data\/test')","92e4f91a":"import os","19be562f":"name=[]\ny_pred=[]","df088f3c":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())","05e40197":"import numpy as np","26cfd4f5":"s=0\nfor i in os.listdir('..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/test\/'):\n    name.append(i)\n    i='..\/input\/hackereath-holiday-season-deep-learning-contest\/dataset\/test\/'+i\n    img=image.load_img(i,target_size=(331,331,3))\n    img=image.img_to_array(img)\/255\n    pred=my_model.predict(img.reshape(1,331,331,3))\n    y_pred.append(labels[np.argmax(pred[0])])\n    s+=1\n    if s%100==0:\n        print(s)\n\n    ","98e33da9":"data=pd.DataFrame((zip(name,y_pred)),columns=['Image','Class'])","5bdaa3da":"data.head()","01c24d71":"data.to_csv('submission.csv',index=False)\n","b8a869e2":"data.shape","abf3d7dd":"# Loading nasnet large model and setting all layers except last 35 as non trainable so we can generalise our model on our data and also do transfer learning for better results","f0115c47":"Problem statement\n\nAn e-commerce platform is getting all geared up for a season clearance sale and plans to leverage social media as the primary channel to reach their audiences. The campaign\u2019s target group are individuals\/families that have recently posted a picture of their indoor Christmas decor or are traveling during the holidays. \n\nYou work at a leading social media platform and your team has been tasked to build a product recommendation engine for consumers. As part of the development team, your role is to use Deep Learning to develop a model that classifies images based on elements within the picture. These elements should be related to decor or holiday season vacations, such as a snowman, a Christmas tree, flights, and the like. ","1b1dc4d4":"# In this notebook I will be using transfer learning and data augmentation for model training and predicting the result.","5d652c26":"# As the data is large so it will be better to use datagenerator, so I am using keras Imagedatagenerator and we can do data augmentation in this step","6d352b48":"# above test datagenerator code is not working, reason is that we must have another folder inside the test image folder that contains all test images for datagenerator(read_from_directory), So let's do this","17ddcb29":"# But I am not using above method you can try this","1f928588":"# Done.\n## Now there are many ways to improve the results,like changing the trainable layers and model and other try and make good results.\n## Please Upvote the notebook if it was helpful","f4bb5ee1":"# Reading data","5f197817":"# Dividing data in valid and train part using StratifiedKFold as data is skewed"}}