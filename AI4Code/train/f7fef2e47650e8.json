{"cell_type":{"7bb32c43":"code","7a5b8d14":"code","9504b3a4":"code","f1e0dc4f":"code","d24850d8":"code","deef4e73":"code","3181fbc3":"code","30a4099c":"code","d4234269":"code","7cb7ca5d":"code","b2508f41":"code","a89697ad":"code","d9bb2ffa":"code","24a14cbc":"code","e4c56fb6":"code","cc97a767":"code","31f58932":"code","b5464661":"code","7cfc6fa4":"code","4994a5b2":"code","fd93d07d":"code","d522aed0":"code","14c5d9e2":"code","392dd762":"code","9ed883be":"code","37fb2e50":"code","a1a0d6f4":"code","149122c4":"code","9b6eb41b":"code","862cbec9":"code","8e9f66e9":"code","e2ddaf38":"code","d7d0b541":"code","2451cf84":"code","cfe4ab8b":"code","42f264d5":"code","0926ea07":"code","b8b66ba5":"code","b6331dac":"code","492d9881":"code","59ddc27d":"code","82e5005f":"code","d9191e8a":"markdown","82a4653b":"markdown"},"source":{"7bb32c43":"import numpy as np\nimport pandas as pd\nfrom keras.preprocessing.image import img_to_array","7a5b8d14":"train_csv = pd.read_csv('..\/input\/train-csv\/legend.csv')","9504b3a4":"train_csv['emotion'] = train_csv['emotion'].str.lower()","f1e0dc4f":"train_csv.groupby('emotion').count()","d24850d8":"train_csv.replace(\"contempt\", \"anger\", inplace=True)","deef4e73":"train_csv.groupby('emotion').count()","3181fbc3":"mapping_emotion = {'anger': 0, 'disgust': 1, 'fear': 2, 'happiness': 3, 'neutral': 6, 'sadness': 4, 'surprise': 5}\ntrain_csv['label'] = train_csv['emotion'].map(mapping_emotion)","30a4099c":"train_csv.head()","d4234269":"import glob\nimport cv2 as cv\nimport os","7cb7ca5d":"trained = '..\/input\/trainedimages'\n#os.mkdir(trained)","b2508f41":"face_cascade = cv.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')\nimage_train = '..\/input\/trainimages\/images_train\/images'","a89697ad":"deleting = ['Abdul_Majeed_Shobokshi_0001.jpg',\n 'Arsinee_Khanjian_0001.jpg',\n 'Avinash_30.jpg',\n 'Colin_Montgomerie_0004.jpg',\n 'Colin_Powell_0048.jpg',\n 'David_McCullough_0001.jpg',\n 'Donald_Rumsfeld_0117.jpg',\n 'Fernando_Vargas_0004.jpg',\n 'Franz_Muentefering_0003.jpg',\n 'George_HW_Bush_0003.jpg',\n 'George_Pataki_0002.jpg',\n 'Hans_Blix_0016.jpg',\n 'Isaiah_Washington_0002.jpg',\n 'Jeff_Feldman_0001.jpg',\n 'Jiang_Zemin_0002.jpg',\n 'Jiang_Zemin_0007.jpg',\n 'Joe_Vandever_0001.jpg',\n 'John_Wright_0001.jpg',\n 'Kimberly_Bruckner_0001.jpg',\n 'Kimberly_Stewart_0001.jpg',\n 'Kimi_Raikkonen_0001.jpg',\n 'Kimi_Raikkonen_0002.jpg',\n 'Kimi_Raikkonen_0003.jpg',\n 'Kimora_Lee_0001.jpg',\n 'Lin_Yi-fu_0001.jpg',\n 'Luciano_Pavarotti_0002.jpg',\n 'Lynne_Thigpen_0001.jpg',\n 'Michael_Powell_0003.jpg',\n 'Miguel_Contreras_0001.jpg',\n 'Morgan_Freeman_0002.jpg',\n 'Padraig_Harrington_0004.jpg',\n 'Paul_Bremer_0014.jpg',\n 'Pedro_Malan_0003.jpg',\n 'Pierce_Brosnan_0007.jpg',\n 'Pyar_Jung_Thapa_0001.jpg',\n 'Richard_Gephardt_0007.jpg',\n 'Robert_Horan_0002.jpg',\n 'Robert_Zoellick_0005.jpg',\n 'Rob_Moore_0001.jpg',\n 'Scott_McNealy_0001.jpg',\n 'Thomas_Daily_0001.jpg',\n 'Tony_Blair_0090.jpg',\n 'William_Bulger_0002.jpg',\n 'Will_Ferrell_0001.jpg']","d9bb2ffa":"data = []\nlabels = []","24a14cbc":"i = 0\nfor img in glob.glob(image_train+\"\/*.jpg\"):\n    image = cv.imread(img)\n    name = img.split('\/')[-1]\n    \n    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) # convert to greyscale\n    height, width = image.shape[:2]\n    faces = face_cascade.detectMultiScale(gray_image, 1.3, 1)\n    if isinstance(faces, tuple):\n        resized_image = cv.resize(gray_image, (48, 48))\n        cv.imwrite(trained+'\/'+name,resized_image)\n    #print(faces)\n    elif isinstance(faces, np.ndarray):\n        for (x,y,w,h) in faces:\n            if w * h < (height * width) \/ 3:\n                resized_image = cv.resize(gray_image, (48, 48)) \n                cv.imwrite(trained+'\/'+name,resized_image)\n            else:\n                \n                #cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n                roi_gray = gray_image[y:y+h, x:x+w]\n                #print(len(roi_gray))\n                resized_image = cv.resize(roi_gray, (48, 48))\n                cv.imwrite(trained+'\/'+name, resized_image)\n    if not name in deleting:\n        data.append(img_to_array(resized_image))\n        label = int(train_csv[ train_csv['image'] == name][['label']].values)\n        #print(label, type(label), name)\n        labels.append(label)\n    \"\"\"if i == 300:\n        break\n    i = i + 1\"\"\"","e4c56fb6":"int(train_csv[ train_csv['image'] == 'Al_Sharpton_0004.jpg'][['label']].values)","cc97a767":"len(labels), len(data)","31f58932":"type(data), type(labels)","b5464661":"# scale the raw pixel intensities to the range [0, 1]\ndata = np.array(data, dtype=\"float\") \/ 255.0\nlabels = np.array(labels)\nprint(\"[INFO] data matrix: {:.2f}MB\".format(data.nbytes \/ (1024 * 1000.0)))\nprint(data.shape, labels.shape)","7cfc6fa4":"from sklearn.preprocessing import LabelBinarizer\n# binarize the labels\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)","4994a5b2":"# partition the data into training and testing splits using 70% of\n# the data for training and the remaining 30% for testing\nfrom sklearn.model_selection import train_test_split\n(trainX, valX, trainY, valY) = train_test_split(data,labels, test_size=0.3, random_state=42)","fd93d07d":"from keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras import backend as K","d522aed0":"def buildModel(width, height, depth, classes):\n\t\t# initialize the model along with the input shape to be\n\t\t# \"channels last\" and the channels dimension itself\n\t\tmodel = Sequential()\n\t\tinputShape = (height, width, depth)\n\t\tchanDim = -1\n\n\t\t# if we are using \"channels first\", update the input shape\n\t\t# and channels dimension\n\t\tif K.image_data_format() == \"channels_first\":\n\t\t\tinputShape = (depth, height, width)\n\t\t\tchanDim = 1\n\n\t\t# CONV => RELU => POOL\n\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\",\n\t\t\tinput_shape=inputShape))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n\t\tmodel.add(Dropout(0.25))\n\n\t\t# (CONV => RELU) * 2 => POOL\n\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\t\tmodel.add(Dropout(0.25))\n\n\t\t# (CONV => RELU) * 2 => POOL\n\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\t\tmodel.add(Dropout(0.25))\n\n\t\t# first (and only) set of FC => RELU layers\n\t\tmodel.add(Flatten())\n\t\tmodel.add(Dense(1024))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization())\n\t\tmodel.add(Dropout(0.25))\n\n\t\t# softmax classifier\n\t\tmodel.add(Dense(classes))\n\t\tmodel.add(Activation(\"softmax\"))\n\n\t\t# return the constructed network architecture\n\t\treturn model","14c5d9e2":"# initialize the number of epochs to train for, initial learning rate,\n# batch size, and image dimensions\nEPOCHS = 100\nINIT_LR = 1e-3\nBS = 32","392dd762":"model = buildModel(width=48, height=48,depth=1, classes=len(lb.classes_))","9ed883be":"from keras.optimizers import Adam","37fb2e50":"opt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])","a1a0d6f4":"from keras.preprocessing.image import ImageDataGenerator\naug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n\thorizontal_flip=True, fill_mode=\"nearest\")","149122c4":"H = model.fit_generator(\n\taug.flow(trainX, trainY, batch_size=BS),\n\tvalidation_data=(valX, valY),\n\tsteps_per_epoch=len(trainX) \/\/ BS,\n\tepochs=EPOCHS, verbose=1)","9b6eb41b":"model.save('..\/input\/emotion.model')","862cbec9":"import pickle","8e9f66e9":"f = open(\"..\/input\/lb.pickle\", \"wb\")\nf.write(pickle.dumps(lb))\nf.close()","e2ddaf38":"image_path = '..\/input\/prediction\/prediction\/57b.jpg'","d7d0b541":"image = cv.imread(image_path)\nimage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\nimage = cv.resize(image, (48, 48))\nimage = image.astype(\"float\") \/ 255.0\nimage = img_to_array(image)\nimage = np.expand_dims(image, axis=0)","2451cf84":"image.shape","cfe4ab8b":"df_test = pd.read_csv('..\/input\/facial-expression-recognitionferchallenge\/fer2013\/fer2013\/fer2013.csv')","42f264d5":"df_test = df_test.sample(frac=0.10)","0926ea07":"X_test = []\ntest_index = df_test.index\nfor item in df_test.index:\n    pixels = df_test.pixels[item]\n    pixels = pixels.split(' ')\n    piarray = np.asarray(pixels, dtype=np.int64)\n    re = piarray.reshape(48,48)\n    X_test.append(re)","b8b66ba5":"X_test = np.asarray(X_test)\nX_test = np.expand_dims(X_test, axis=-1)","b6331dac":"X_test[0].shape","492d9881":"\"\"\"proba = model.predict(image)[0]\nidx = np.argmax(proba)\nlabel = lb.classes_[idx]\n\"\"\"\nY_predict = []\nfor item in X_test:\n    item = np.expand_dims(item, axis = 0)\n    predict = model.predict(item)\n    idx = np.argmax(predict)\n    label = lb.classes_[idx]\n    Y_predict.append(label)","59ddc27d":"Y_true = df_test.emotion.values","82e5005f":"from sklearn.metrics import accuracy_score\naccuracy_score(Y_true, Y_predict)","d9191e8a":"# Prediction","82a4653b":"# Model"}}