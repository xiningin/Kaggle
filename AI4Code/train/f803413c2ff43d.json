{"cell_type":{"4c6a0981":"code","6f29f563":"code","268628b4":"code","e4116aed":"code","559dcddf":"code","0b119a1f":"code","413f0788":"code","ca166ec3":"code","f07cde23":"code","0aec731a":"code","a051a9ae":"code","9fa21199":"code","6be15f9b":"code","8c6e8c60":"code","a32ccf51":"code","adf4733a":"code","8f905967":"code","838fa4e8":"code","b1a3ec6a":"code","159c839d":"code","3d7a86e4":"code","40aded96":"code","c2211ade":"code","cc8d2bf6":"code","101347f4":"code","e03276d0":"code","4e465afd":"code","1a0e4fbc":"code","194c3a5f":"code","0c02efa4":"code","74dac94d":"code","624ced10":"code","a454bded":"code","241caf4e":"code","35d1dca0":"code","7be3b0a3":"markdown","966f4e55":"markdown","804ae501":"markdown","9c8816f1":"markdown","16314ec3":"markdown","a44c4d9f":"markdown","2362d7a2":"markdown","d1029f37":"markdown","30897a92":"markdown"},"source":{"4c6a0981":"import sys\nsys.path.append('..\/input\/pytorch-efficientnet')\nsys.path.append('..\/input\/multistartifiedkfold')","6f29f563":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport matplotlib.image as immg\nfrom pathlib import Path\nimport os,sys\nimport seaborn as sns\nimport gc\nimport torchvision\nimport cv2\nfrom fastai.data.all import *\nfrom fastai.vision.core import *\nfrom fastai.vision.data import *\nfrom tqdm.notebook import tqdm\nimport zipfile\nimport io\nfrom sklearn.decomposition import PCA\nfrom fastai.vision.all import *","268628b4":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold","e4116aed":"df = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/train.csv')","559dcddf":"df.head()","0b119a1f":"target_cols = ['ETT - Abnormal', 'ETT - Borderline',\n       'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal',\n       'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present']","413f0788":"trn_df = df.sample(frac=1.,random_state = 2020)\ntrn_df['kfold'] = -1\ny = trn_df[target_cols].values\nkf = MultilabelStratifiedKFold(n_splits=5,random_state = 2020,shuffle = True)\nfor fold ,(trn_,val_ )in enumerate(kf.split(X=trn_df,y=y)):\n    trn_df.loc[val_,'kfold'] = fold","ca166ec3":"trn_df.to_csv('train_df_kfold.csv',index=False)","f07cde23":"trn_df.head()","0aec731a":"fig = plt.figure(1,figsize=(20,12))\ncolumns = 4\nrows = 3\nfea_num = 0\nfea_cols = target_cols\nfor i in range(rows*columns):\n    fig.add_subplot(rows, columns, i+1)\n    sns.countplot(df[fea_cols[min(i,10)]])\n    plt.title(fea_cols[min(i,10)])\n    fea_num+=1\nplt.subplots_adjust(wspace=0.3, hspace=0.3)\nplt.show()","a051a9ae":"df[target_cols].sum(axis=0)","9fa21199":"FOLD = 1","6be15f9b":"trn_idx,val_idx = trn_df[trn_df['kfold']!=FOLD].index, trn_df[trn_df['kfold']==FOLD].index","8c6e8c60":"item_tfms = Resize(300)\nbatch_tfms = [*aug_transforms(size=300, max_warp=0), Normalize.from_stats(*imagenet_stats)]\nbs = 8","a32ccf51":"img_path = '..\/input\/ranzor-clip-resized-data-512-256'","adf4733a":"dls = ImageDataLoaders.from_df(trn_df, path=img_path, fn_col = 'StudyInstanceUID', \n                               folder='trainXray_512',label_col=target_cols,suff='.jpg',\n                               bs=bs,y_block=MultiCategoryBlock(encoded=True, vocab=target_cols),\n                               item_tfms=item_tfms,batch_tfms=batch_tfms,val_idxs=val_idx)","8f905967":"dls.show_batch(nrows=3, ncols=3,figsize=(20,12))","838fa4e8":"len(dls.valid_ds),len(dls.train_ds)","b1a3ec6a":"import sklearn.metrics as sklm","159c839d":"def col_mean_aucroc(preds, targs, labels=range(len(target_cols))):\n    # One-hot encode targets\n    return np.mean([sklm.roc_auc_score(targs[:,i], preds[:,i]) for i in labels])\ndef ETTAbnormal_auc(*args):\n    return col_mean_aucroc(*args, labels=[0])\ndef ETTBorderline_auc(*args):\n    return col_mean_aucroc(*args, labels=[1])\ndef ETTNormal_auc(*args):\n    return col_mean_aucroc(*args, labels=[2])\ndef NGTAbnormal_auc(*args):\n    return col_mean_aucroc(*args, labels=[3])\ndef NGTBorderline_auc(*args):\n    return col_mean_aucroc(*args, labels=[4])\ndef NGTIncompletelyImaged_auc(*args):\n    return col_mean_aucroc(*args, labels=[5])\ndef NGTNormal_auc(*args):\n    return col_mean_aucroc(*args, labels=[6])\ndef CVCAbnormal_auc(*args):\n    return col_mean_aucroc(*args, labels=[7])\ndef CVCBorderline_auc(*args):\n    return col_mean_aucroc(*args, labels=[8])\ndef CVCNormal_auc(*args):\n    return col_mean_aucroc(*args, labels=[9])\ndef SwanGanzCatheterPresent_auc(*args):\n    return col_mean_aucroc(*args, labels=[10])","3d7a86e4":"from efficientnet_pytorch import EfficientNet","40aded96":"wp = '..\/input\/efficientnet-pytorch\/efficientnet-b5-586e6cc6.pth'","c2211ade":"class MyModel(Module):\n    def __init__(self, num_classes):\n\n        self.effnet = EfficientNet.from_pretrained(\"efficientnet-b5\",weights_path=wp)\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(2048, num_classes)\n\n    def forward(self, image):\n        batch_size, _, _, _ = image.shape\n\n        x = self.effnet.extract_features(image)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        outputs = self.out(self.dropout(x))\n        return outputs","cc8d2bf6":"effnet_B5 = MyModel(dls.c)","101347f4":"metrics = [ AccumMetric(col_mean_aucroc, flatten=False),#Avg AUCROC\n            AccumMetric(ETTAbnormal_auc, flatten=False),\n            AccumMetric(ETTBorderline_auc, flatten=False),\n            AccumMetric(ETTNormal_auc, flatten=False),\n            AccumMetric(NGTAbnormal_auc, flatten=False),\n            AccumMetric(NGTBorderline_auc, flatten=False),\n            AccumMetric(NGTIncompletelyImaged_auc, flatten=False),\n            AccumMetric(NGTNormal_auc, flatten=False),\n            AccumMetric(CVCAbnormal_auc, flatten=False),\n            AccumMetric(CVCBorderline_auc, flatten=False),\n            AccumMetric(CVCNormal_auc, flatten=False),\n            AccumMetric(SwanGanzCatheterPresent_auc, flatten=False)]","e03276d0":"learn = Learner(dls, \n                effnet_B5, \n                loss_func=BCEWithLogitsLossFlat(),\n                metrics=metrics,\n                model_dir='\/kaggle\/working').to_native_fp16()","4e465afd":"cb1 = SaveModelCallback(monitor='col_mean_aucroc',fname='best_model',comp=np.greater) # Callbacks\ncb2 = ReduceLROnPlateau(monitor='col_mean_aucroc', min_delta=0.1, patience=2,factor=0.2)\nlearn.fit_one_cycle(10, 1e-3, cbs = [cb1,cb2])","1a0e4fbc":"learn.load('best_model');","194c3a5f":"item_tfms = Resize(380)\nbatch_tfms = [*aug_transforms(size=380, max_warp=0), Normalize.from_stats(*imagenet_stats)]\nbs = 8","0c02efa4":"dlsB = ImageDataLoaders.from_df(trn_df, path=img_path, fn_col = 'StudyInstanceUID', \n                               folder='trainXray_512',label_col=target_cols,suff='.jpg',\n                               bs=4,y_block=MultiCategoryBlock(encoded=True, vocab=target_cols),\n                               item_tfms=item_tfms,batch_tfms=batch_tfms,val_idxs=val_idx)","74dac94d":"learn.dls = dlsB","624ced10":"gc.collect()","a454bded":"learn.unfreeze()\ncb1 = SaveModelCallback(monitor='col_mean_aucroc',fname='best_model_380',comp=np.greater) # Callbacks\ncb2 = ReduceLROnPlateau(monitor='col_mean_aucroc', min_delta=0.1, patience=2,factor=0.2)\nlearn.fit_one_cycle(4, 1e-3\/2, cbs = [cb1,cb2])","241caf4e":"learn.load('best_model_380');","35d1dca0":"learn = learn.to_fp32()\nlearn.save('best_model_fp32',with_opt=True);","7be3b0a3":"## Metrics column wise mean aucroc","966f4e55":"### Train and valid idxs","804ae501":"## Work In progress Stay Tuned\n## Please Don't forget to upvote","9c8816f1":"## Metrics of each target columns","16314ec3":"### Let us see total Number of postive sample in each group","a44c4d9f":"## MultiStratifiedKFold","2362d7a2":"## Model EfficientNetB0","d1029f37":"## Making The Model by adding a dropout layer and final output layer","30897a92":"## Target Distribution"}}