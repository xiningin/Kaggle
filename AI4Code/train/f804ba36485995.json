{"cell_type":{"d8c173a1":"code","ec9dbf0a":"code","2843df3a":"code","889e2590":"code","b7c4fdf0":"code","ddac6fb8":"code","4f137996":"code","756dce40":"code","724e8758":"code","e2f76904":"code","c2b4a335":"code","b7098e50":"code","7e041ea4":"code","18b74694":"code","fb155af2":"code","07bb258f":"code","f63f371a":"code","84be1d1a":"code","0db3922e":"code","4f827f87":"code","a971e91f":"code","b070308a":"code","dc3e3b94":"code","735d1257":"code","b41f1661":"code","7431afb9":"code","69b8f362":"code","2926519f":"code","b3ffbcea":"code","a7db0961":"code","22ee90a9":"code","2f4197c6":"code","c3f92651":"code","17a8db91":"code","0aef9abe":"markdown","cde632ee":"markdown","54058702":"markdown","1b0b843f":"markdown"},"source":{"d8c173a1":"try:\n    import resnest\nexcept ModuleNotFoundError:\n    !pip install -q \"..\/input\/resnest50-fast-package\/resnest-0.0.6b20200701\/resnest\"\n    \n!pip install -q ..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\/","ec9dbf0a":"import numpy as np\nimport librosa as lb\nimport soundfile as sf\nimport pandas as pd\nimport cv2\nfrom pathlib import Path\nimport re\n\nimport torch\nfrom torch import nn\nfrom  torch.utils.data import Dataset, DataLoader\n\nfrom tqdm.notebook import tqdm\n\nimport time\nimport timm\nimport cv2\nfrom resnest.torch import resnest50","2843df3a":"NUM_CLASSES = 397\nSR = 32_000\nDURATION = 5\n\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"DEVICE:\", DEVICE)\n\nTEST_AUDIO_ROOT = Path(\"..\/input\/birdclef-2021\/test_soundscapes\")\nSAMPLE_SUB_PATH = \"..\/input\/birdclef-2021\/sample_submission.csv\"\nTARGET_PATH = None\n    \nif not len(list(TEST_AUDIO_ROOT.glob(\"*.ogg\"))):\n    TEST_AUDIO_ROOT = Path(\"..\/input\/birdclef-2021\/train_soundscapes\")\n    SAMPLE_SUB_PATH = None\n    # SAMPLE_SUB_PATH = \"..\/input\/birdclef-2021\/sample_submission.csv\"\n    TARGET_PATH = Path(\"..\/input\/birdclef-2021\/train_soundscape_labels.csv\")","889e2590":"class MelSpecComputer:\n    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax\n        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr\/\/10)\n        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr\/\/(10*4))\n        self.kwargs = kwargs\n\n    def __call__(self, y):\n\n        melspec = lb.feature.melspectrogram(\n            y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n        )\n\n        melspec = lb.power_to_db(melspec).astype(np.float32)\n        return melspec","b7c4fdf0":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) \/ (std + eps)\n    \n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) \/ (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\ndef crop_or_pad(y, length):\n    if len(y) < length:\n        y = np.concatenate([y, length - np.zeros(len(y))])\n    elif len(y) > length:\n        y = y[:length]\n    return y","ddac6fb8":"class BirdCLEFDataset(Dataset):\n    def __init__(self, data, sr=SR, n_mels=128, fmin=0, fmax=None, duration=DURATION, step=None, res_type=\"kaiser_fast\", resample=True):\n        \n        self.data = data\n        \n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr\/\/2\n\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        self.step = step or self.audio_length\n        \n        self.res_type = res_type\n        self.resample = resample\n\n        self.mel_spec_computer = MelSpecComputer(sr=self.sr, n_mels=self.n_mels, fmin=self.fmin,\n                                                 fmax=self.fmax)\n    def __len__(self):\n        return len(self.data)\n    \n    @staticmethod\n    def normalize(image):\n        image = image.astype(\"float32\", copy=False) \/ 255.0\n        image = np.stack([image, image, image])\n        return image\n    \n    def audio_to_image(self, audio):\n        melspec = self.mel_spec_computer(audio) \n        image = mono_to_color(melspec)\n        image = self.normalize(image)\n        return image\n\n    def read_file(self, filepath):\n        audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n\n        if self.resample and orig_sr != self.sr:\n            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n          \n        audios = []\n        for i in range(self.audio_length, len(audio) + self.step, self.step):\n            start = max(0, i - self.audio_length)\n            end = start + self.audio_length\n            audios.append(audio[start:end])\n            \n        if len(audios[-1]) < self.audio_length:\n            audios = audios[:-1]\n            \n        images = [self.audio_to_image(audio) for audio in audios]\n        images = np.stack(images)\n#         images = cv2.resize(images,(128,281))\n        \n        \n        return images\n    \n        \n    def __getitem__(self, idx):\n        return self.read_file(self.data.loc[idx, \"filepath\"])","4f137996":"data = pd.DataFrame(\n     [(path.stem, *path.stem.split(\"_\"), path) for path in Path(TEST_AUDIO_ROOT).glob(\"*.ogg\")],\n    columns = [\"filename\", \"id\", \"site\", \"date\", \"filepath\"]\n)\nprint(data.shape)\ndata.head()","756dce40":"df_train = pd.read_csv(\"..\/input\/birdclef-2021\/train_metadata.csv\")\n\nLABEL_IDS = {label: label_id for label_id,label in enumerate(sorted(df_train[\"primary_label\"].unique()))}\nINV_LABEL_IDS = {val: key for key,val in LABEL_IDS.items()}","724e8758":"values = df_train['primary_label'].value_counts()\nbirdname_groups = {}\nbirdid_groups = {}\nfor k,v in values.items():\n    if v <= 32:\n        birdname_groups[k] = 0\n        birdid_groups[LABEL_IDS[k]] = 0\n    elif v<=64:\n        birdname_groups[k] = 1\n        birdid_groups[LABEL_IDS[k]] = 1\n    elif v<=128:\n        birdname_groups[k] = 2\n        birdid_groups[LABEL_IDS[k]] = 2\n    elif v<=256:\n        birdname_groups[k] = 3\n        birdid_groups[LABEL_IDS[k]] = 3\n    elif v<=512:\n        birdname_groups[k] = 4\n        birdid_groups[LABEL_IDS[k]] = 4","e2f76904":"test_data = BirdCLEFDataset(data=data)\nlen(test_data), test_data[0].shape","c2b4a335":"def load_net(checkpoint_path, num_classes=NUM_CLASSES, model='resnest50'):\n    if 'resnest50' in checkpoint_path:\n        net = resnest50(pretrained=False)\n        net.fc = nn.Linear(net.fc.in_features, num_classes)\n    elif \"densenet\" in checkpoint_path:\n        net = timm.create_model(\"densenet121\", pretrained=False,num_classes=num_classes)\n    elif \"b0\" in checkpoint_path:\n        net = timm.create_model('tf_efficientnet_b0_ns', pretrained=False, num_classes=num_classes)\n    else:\n        net = timm.create_model('tf_efficientnet_b3_ns', pretrained=False, num_classes=num_classes)\n    dummy_device = torch.device(\"cpu\")\n    d = torch.load(checkpoint_path, map_location=dummy_device)\n    for key in list(d.keys()):\n        d[key.replace(\"model.\", \"\").replace(\"encoder.\", \"\")] = d.pop(key)\n    net.load_state_dict(d)\n    net = net.to(DEVICE)\n    net = net.eval()\n    return net","b7098e50":"@torch.no_grad()\ndef get_thresh_preds(out, thresh=None):\n    thresh = thresh or THRESH\n    o = (-out).argsort(1)\n    npreds = (out > thresh).sum(1)\n    preds = []\n    for oo, npred in zip(o, npreds):\n        preds.append(oo[:npred].cpu().numpy().tolist())\n    return preds","7e041ea4":"@torch.no_grad()\ndef get_group_thresh_preds(out, group_thresh=[0.49,0.49,0.49,0.49]):\n    o = (-out).argsort(1)\n    out = out.cpu().numpy()\n    o = o.cpu().numpy()\n    thresh = min(group_thresh)\n    npreds = (out > thresh).sum(1)\n    preds = []\n    for oo,npred,ou in zip(o,npreds,out):\n        p = [] \n        for i in range(npred.item()):\n            t = oo[i]\n            tt = birdid_groups[t]\n            if ou[t] > group_thresh[tt]:\n                p.append(t)\n        preds.append(p)\n    return preds","18b74694":"len(LABEL_IDS)","fb155af2":"sites = [\"COR\",\"COL\",\"SNE\",\"SSW\"]\n# site_group_thresh ={\n#     \"COR\":[0.47,0.47,0.47,0.47,0.47],\n#     \"COL\":[0.47,0.47,0.47,0.47,0.47],\n#     \"SNE\":[0.47,0.47,0.47,0.47,0.47],\n#     \"SSW\":[0.47,0.47,0.47,0.47,0.47],\n# }\nsite_bird_group = {\n    \"COR\":np.zeros(len(LABEL_IDS),dtype = int),\n    \"COL\":np.zeros(len(LABEL_IDS),dtype = int),\n    \"SNE\":np.zeros(len(LABEL_IDS),dtype = int),\n    \"SSW\":np.zeros(len(LABEL_IDS),dtype = int),\n}\n\nbird_info = np.load(\"..\/input\/sites-bird-num\/bird_count800.npy\")\n\nfor k,(site_bird_info) in enumerate(bird_info):\n    for i,(bird_kind) in enumerate(site_bird_info):\n        if bird_kind <= 0:\n            site_bird_group[sites[k]][i] = 0\n        elif bird_kind <= 16:\n            site_bird_group[sites[k]][i] = 1\n        elif bird_kind <= 32:\n            site_bird_group[sites[k]][i] = 2\n        elif bird_kind <= 64:\n            site_bird_group[sites[k]][i] = 3\n        else:\n            site_bird_group[sites[k]][i] = 4","07bb258f":"bird_info[0]","f63f371a":"@torch.no_grad()\ndef get_site_group_thresh_preds(out,site_group_thresh,name = 'COR'):\n    o = (-out).argsort(1)\n    out = out.cpu().numpy()\n    o = o.cpu().numpy()\n    thresh = 0.3\n    npreds = (out > thresh).sum(1)\n    preds = []\n    for oo,npred,ou in zip(o,npreds,out):\n        p = [] \n        for i in range(npred.item()):\n            t = oo[i]\n            tt = site_bird_group[name][t]\n            if ou[t] > site_group_thresh[name][tt]:\n                p.append(t)\n        preds.append(p)\n    return preds","84be1d1a":"def get_bird_names(preds):\n    bird_names = []\n    for pred in preds:\n        if not pred:\n            bird_names.append(\"nocall\")\n        else:\n            bird_names.append(\" \".join([INV_LABEL_IDS[bird_id] for bird_id in pred]))\n    return bird_names","0db3922e":"def predict(nets, test_data, names=True, p=1):\n    preds = []\n        \n    with torch.no_grad():\n\n        for idx in tqdm(list(range(len(test_data)))):\n            xb = torch.from_numpy(test_data[idx]).to(DEVICE)\n            pred = []\n            for i in range(len(nets)):\n                o = nets[i](xb)\n                pred.append(torch.sigmoid(o).cpu().numpy()**p)\n\n#                 if names:\n#                     pred = get_bird_names(get_thresh_preds(pred))\n\n            preds.append(pred)\n    \n    return np.array(preds)\n    \ndef weighted_predict(preds, nets, weights=None):\n    if weights is None:\n        weights = np.ones((len(nets,)))\n        weights \/= len(nets)\n    \n    weighted_pred = np.zeros_like(preds[:,0])\n    for i in range(len(nets)):\n        weighted_pred += preds[:,i]*weights[i]\n        \n    return weighted_pred","4f827f87":"def gen_file_name(data):\n    file_name = []\n    for row in data.itertuples(False):\n        site_params = row.filename.split('_')\n        site_name = site_params[1]\n#         for i in range(num):\n        file_name.append(site_name)\n    return file_name","a971e91f":"def preds_as_df(data, preds):\n    sub = {\n        \"row_id\": [],\n        \"birds\": [],\n    }\n    \n    for row, pred in zip(data.itertuples(False), preds):\n        row_id = [f\"{row.id}_{row.site}_{5*i}\" for i in range(1, len(pred)+1)]\n        sub[\"birds\"] += pred\n        sub[\"row_id\"] += row_id\n        \n    sub = pd.DataFrame(sub)\n    \n    if SAMPLE_SUB_PATH:\n        sample_sub = pd.read_csv(SAMPLE_SUB_PATH, usecols=[\"row_id\"])\n        sub = sample_sub.merge(sub, on=\"row_id\", how=\"left\")\n        sub[\"birds\"] = sub[\"birds\"].fillna(\"nocall\")\n    return sub","b070308a":"checkpoint_paths = [\n    \n    Path(\"..\/input\/kkiller-birdclef-models-public\/birdclef_resnest50_fold0_epoch_10_f1_val_06471_20210417161101.pth\"),\n    \n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold0_epoch_28_f1_val_6962_20210525190516.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold0_epoch_35_f1_val_6890_20210525192227.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold1_epoch_41_f1_val_7025_20210525213011.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold1_epoch_44_f1_val_7002_20210525213737.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold2_epoch_35_f1_val_6997_20210525231559.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold2_epoch_38_f1_val_6964_20210525232335.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold3_epoch_38_f1_val_6732_20210526013148.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold3_epoch_39_f1_val_6721_20210526013422.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold4_epoch_47_f1_val_6992_20210526040142.pth\"),\n    Path(\"..\/input\/bird-b0\/birdclef_tf_efficientnet_b0_ns_fold4_epoch_49_f1_val_7020_20210526040645.pth\"),\n    \n    \n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold0_epoch_34_f1_val_6977_20210526131127.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold0_epoch_43_f1_val_6979_20210526134218.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold1_epoch_29_f1_val_6898_20210526154558.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold1_epoch_34_f1_val_6939_20210526160315.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold2_epoch_34_f1_val_6849_20210526213431.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold2_epoch_39_f1_val_6822_20210526215139.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold3_epoch_41_f1_val_6805_20210527005346.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold3_epoch_42_f1_val_6763_20210527005717.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold4_epoch_23_f1_val_6827_20210527024520.pth'),\n    Path('..\/input\/bird-b3\/birdclef_tf_efficientnet_b3_ns_fold4_epoch_37_f1_val_6827_20210527033438.pth'),\n    \n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold0_epoch_27_f1_val_0.69676_20210525184602.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold0_epoch_42_f1_val_0.701555_20210525220354.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold1_epoch_40_f1_val_0.70515_20210526082159.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold1_epoch_43_f1_val_0.70533_20210526090108.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold2_epoch_19_f1_val_0.7038_20210526143731.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold2_epoch_34_f1_val_0.69693_20210526175322.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold3_epoch_23_f1_val_0.70365_20210527021504.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold3_epoch_29_f1_val_0.7054_20210527033125.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold4_epoch_34_f1_val_0.7007_20210527152318.pth'),\n    Path('..\/input\/resnest50-5folds\/birdclef_resnest50_fold4_epoch_43_f1_val_0.69998_20210527180634.pth'),\n    \n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold0_epoch_34_f1_val_0.68485_20210523162917.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold0_epoch_44_f1_val_0.68239_20210523183252.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold1_epoch_36_f1_val_0.69548_20210524030526.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold1_epoch_39_f1_val_0.6893_20210524034203.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold2_epoch_34_f1_val_0.7000853174_20210524125933.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold2_epoch_40_f1_val_0.70008_20210524141448.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold3_epoch_48_f1_val_0.68559_20210525020059.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold3_epoch_49_f1_val_0.68634_20210525021302.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold4_epoch_24_f1_val_0.69277_20210525071727.pth'),\n    Path('..\/input\/densent121-2fold\/birdclef_densenet121_fold4_epoch_31_f1_val_0.68673_20210525084536.pth'),\n]\n\nnets = [load_net(checkpoint_path.as_posix()) for checkpoint_path in checkpoint_paths]","dc3e3b94":"raw_pred_probas = predict(nets, test_data, names=False, p=0.25)","735d1257":"raw_pred_probas.shape","b41f1661":"weights = [2]+[1\/10]*10+[3\/10]*10+[3\/10]*10+[1\/10]*10\nweights \/= np.sum(weights)\npred_probas = weighted_predict(raw_pred_probas, nets, weights=weights)","7431afb9":"pred_probas.shape","69b8f362":"pred_probas_new = []\n\nfor i in range(len(pred_probas)):\n    p = np.zeros_like(pred_probas[i]) #(120, nclass)\n    for j in range(len(pred_probas[i])):\n        if j == 0:\n            p[j] = pred_probas[i][j]*0.6+pred_probas[i][j+1]*0.4\n        elif j == len(pred_probas[i])-1:\n            p[j] = pred_probas[i][j]*0.6+pred_probas[i][j-1]*0.4\n        else:\n            p[j] = pred_probas[i][j]*0.6+pred_probas[i][j-1]*0.2+pred_probas[i][j+1]*0.2\n        \n    pred_probas_new.append(torch.tensor(p))","2926519f":"site_info = gen_file_name(data)\nprint(len(site_info))","b3ffbcea":"\n# preds = [get_bird_names(get_thresh_preds(pred, thresh=0.49)) for pred in pred_probas_new]\n# preds = [get_bird_names(get_group_thresh_preds(pred,[0.47,0.47,0.47,0.47,0.47])) for pred in pred_probas_new]\n\nsite_group_thresh ={\n    \"COR\":[0.53,0.55,0.49,0.41,0.45],\n    \"COL\":[0.53,0.50,0.49,0.45,0.46],\n    \"SNE\":[0.53,0.50,0.49,0.45,0.45],\n    \"SSW\":[0.53,0.47,0.49,0.49,0.47],\n}\npreds = [get_bird_names(get_site_group_thresh_preds(pred,site_group_thresh,site)) for pred,site in zip(pred_probas_new,site_info)]\n\n# preds = [get_bird_names(get_site_group_thresh_preds(pred,site)) for pred,site in zip(pred_probas_new,site_info)]","a7db0961":"len(preds[0])","22ee90a9":"sub = preds_as_df(data, preds)\n\nsub","2f4197c6":"sub.to_csv(\"submission.csv\", index=False)","c3f92651":"def get_metrics(s_true, s_pred):\n    s_true = set(s_true.split())\n    s_pred = set(s_pred.split())\n    n, n_true, n_pred = len(s_true.intersection(s_pred)), len(s_true), len(s_pred)\n    \n    prec = n\/n_pred\n    rec = n\/n_true\n    f1 = 2*prec*rec\/(prec + rec) if prec + rec else 0\n    \n    return {\"f1\": f1, \"prec\": prec, \"rec\": rec, \"n_true\": n_true, \"n_pred\": n_pred, \"n\": n}","17a8db91":"# best_f1 = 0 \n# best_th = 0\n\n# if TARGET_PATH:\n    \n#     for th in np.arange(0.35, 0.65, 0.02):\n# #         [th,th,th,th,th],\n# #         [0.47,0.47,0.47,0.47,0.47]\n#         site_group_thresh ={\n#             \"COR\":[0.53,0.55,0.49,0.41,0.45],\n#             \"COL\":[0.53,0.50,0.49,0.45,0.46],\n#             \"SNE\":[0.53,0.50,0.49,0.45,0.45],\n#             \"SSW\":[0.53,0.47,0.49,0.49,0.47],\n#         }\n        \n# #         preds = [get_bird_names(get_thresh_preds(pred, thresh=th)) for pred in pred_probas_new]\n#         preds = [get_bird_names(get_site_group_thresh_preds(pred,site_group_thresh,site)) for pred,site in zip(pred_probas_new,site_info)]\n\n#         sub = preds_as_df(data, preds)\n\n#         sub_target = pd.read_csv(TARGET_PATH)\n#         sub_target = sub_target.merge(sub, how=\"left\", on=\"row_id\")\n\n#         df_metrics = pd.DataFrame([get_metrics(s_true, s_pred) for s_true, s_pred in zip(sub_target.birds_x, sub_target.birds_y)])\n\n#         f1 = df_metrics.mean().values[0]\n        \n#         if f1 > best_f1:\n#             best_f1 = f1\n#             best_th = th\n        \n#         print(round(th,3), round(f1,7))\n\n        \n#     print(\"best_f1: {},best_th: {}\".format(best_f1,best_th))","0aef9abe":"# Inference","cde632ee":"# Small validation","54058702":"# Data","1b0b843f":"# Configs"}}