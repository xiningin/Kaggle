{"cell_type":{"f5cf1be0":"code","40bb2d1b":"code","f21c2d15":"code","6428ba29":"code","886fffd5":"code","bc4287f6":"code","37ad4897":"code","1989cf1b":"code","d8a2cb26":"code","194b79fe":"code","b3e22c0f":"code","2a6f4927":"code","30c41374":"code","c2fe5e0c":"code","236b1d86":"code","0c2ed283":"code","f4f67a31":"code","7a72164c":"code","94cc2635":"code","a2f07724":"code","d5bb2917":"code","9bcaa503":"code","69211ed8":"code","e3d9355c":"markdown","609d5846":"markdown","e7792ed0":"markdown","d8a77129":"markdown","2a640529":"markdown","9fa6734d":"markdown","c2437402":"markdown","b35558e6":"markdown","af7ace9d":"markdown","71e8f5a3":"markdown"},"source":{"f5cf1be0":"# unzip data\n!unzip \/kaggle\/input\/restaurant-revenue-prediction\/test.csv.zip\n!unzip \/kaggle\/input\/restaurant-revenue-prediction\/train.csv.zip","40bb2d1b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import BayesianRidge, ElasticNet, Lasso, Ridge, LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import make_scorer, mean_squared_log_error\nfrom sklearn.preprocessing import StandardScaler\nfrom bayes_opt import BayesianOptimization\nimport matplotlib.pyplot as plt","f21c2d15":"from warnings import filterwarnings\nfilterwarnings('ignore')","6428ba29":"def preparing_data(df):\n    \n    # drop Id as useless column\n    df.drop('Id', axis=1, inplace=True)\n\n    # remove revenue outstands\n    df = df[~df['revenue'].ge(1.25 * 10**7)]\n    \n    # convert Open Date to datetime\n    df['Open Date'] = pd.to_datetime(df['Open Date'], format='%m\/%d\/%Y')\n    \n    # create OpenDays column\n    df['OpenDays'] = (df['Open Date'].max() - df['Open Date']).astype('timedelta64[D]').astype(int) + 1\n    \n    # log on OpenDays\n    df['OpenDays'] = np.log(df['OpenDays'])\n\n    # drop Open Date column\n    df.drop('Open Date', axis=1, inplace=True)\n\n    # in test data there are 57 unique cities and int train only 34, so we drop this column\n    df.drop('City', axis=1, inplace=True)\n\n    # get dummies of City Group\n    df = pd.get_dummies(df, columns=['City Group'], drop_first=True)\n\n    # change MB to DT type\n    df['Type'].replace('MB', 'DT', inplace=True)\n\n    # get dummies of Type\n    df = pd.get_dummies(df, columns=['Type'], drop_first=True)\n    \n    # log revenue\n    df['revenue'] = np.log(df['revenue'])\n    \n    return df","886fffd5":"# read data and drop Id column as useless column\ntrain = pd.read_csv('.\/train.csv')\ntest = pd.read_csv('.\/test.csv')\n\n# connect data for preprocessing\ndf = pd.concat([train, test], axis=0)","bc4287f6":"plt.plot(df['revenue'], '.')\nplt.show()","37ad4897":"df['Open Date'].max()","1989cf1b":"# prepare data\ndf = preparing_data(df)","d8a2cb26":"# find columns with high correlation\n# r = df.corr()['revenue']\n# r[r > 0.15]","194b79fe":"# use columns with high correlation\n# df = df[['P2', 'P6', 'P23', 'P28', 'OpenDays', 'revenue']]","b3e22c0f":"df.head()","2a6f4927":"# split df on test and train\ntrain = df[~df['revenue'].isnull()]\ntest = df[df['revenue'].isnull()]","30c41374":"# split test and train on test_X, test_y, train_X\ntrain_X, train_y = train.drop('revenue', axis=1), train['revenue']\ntest_X = test.drop('revenue', axis=1)","c2fe5e0c":"def grid_func(model, train_X, train_y, test_X, file_name):\n    \n    parameters = [{'alpha': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000, 3000, 10000],\n               'normalize': [True, False]}]\n    \n    grid = GridSearchCV(model, parameters)\n    \n    grid.fit(train_X, train_y)\n    \n    print(file_name, ':', grid.best_estimator_)\n    \n    res = grid.predict(test_X)\n    \n    pd.DataFrame(np.e ** res, columns=['Prediction']).to_csv(file_name, index=True, index_label='Id')","236b1d86":"def linear_regression(train_X, train_y, test_X):\n    lr = LinearRegression(normalize=True).fit(train_X, train_y)\n    pd.DataFrame(np.e ** lr.predict(test_X), columns=['Prediction']).to_csv('linear_regression.csv', index=True, index_label='Id')\n\nlinear_regression(train_X, train_y, test_X)","0c2ed283":"grid_func(Ridge(), train_X, train_y, test_X, 'ridge_grid.csv')\ngrid_func(Lasso(), train_X, train_y, test_X, 'lasso_grid.csv')\ngrid_func(ElasticNet(), train_X, train_y, test_X, 'elastic_grid.csv')","f4f67a31":"def ridge_bayesian(train_X, train_y, test_X):\n    ridge_b = BayesianRidge(normalize=True)\n    ridge_b.fit(train_X, train_y)\n    print(ridge_b.alpha_)\n    \n    res = ridge_b.predict(test_X)\n    \n    pd.DataFrame(np.e ** res, columns=['Prediction']).to_csv('ridge_bayesian.csv', index=True, index_label='Id')\n\nridge_bayesian(train_X, train_y, test_X)","7a72164c":"def rmsle(y_true, y_pred):\n    return np.sqrt(mean_squared_log_error(np.expm1(y_true), np.expm1(y_pred)))\n\nneg_rmsle = make_scorer(rmsle, greater_is_better=False)\n\nparams = { 'alpha': (0.001, 1), 'fit_intercept': (0,1.99) }","94cc2635":"def target(**params):\n\n    model = Lasso(alpha = params['alpha'])\n    \n    scores = cross_val_score(model, train_X, train_y, scoring=neg_rmsle, cv=3)\n    return scores.mean()\n\nlasso_alpha = BayesianOptimization(target, params, random_state=101)\n\nlasso_alpha.maximize(init_points=5, n_iter=15, acq='ucb', kappa=2)","a2f07724":"lasso1 = Lasso(alpha=0.02945).fit(train_X, train_y)\npd.DataFrame(np.e ** lasso1.predict(test_X), columns=['Prediction']).to_csv('lasso_bayesian1.csv', index=True, index_label='Id')\n\nlasso2 = Lasso(alpha=0.07492).fit(train_X, train_y)\npd.DataFrame(np.e ** lasso2.predict(test_X), columns=['Prediction']).to_csv('lasso_bayesian2.csv', index=True, index_label='Id')","d5bb2917":"def target(**params):\n    fit_intercept = int(params['fit_intercept'])\n    fit_intercept_dict = { 0: False, 1: True }\n\n    model = ElasticNet(alpha = params['alpha'],\n                    fit_intercept = fit_intercept_dict[fit_intercept],\n                    copy_X = True)\n    \n    scores = cross_val_score(model, train_X, train_y, scoring=neg_rmsle, cv=3)\n    return scores.mean()\n\nelastic_alpha = BayesianOptimization(target, params, random_state=101)\n\nelastic_alpha.maximize(init_points=5, n_iter=15, acq='ucb', kappa=2)","9bcaa503":"el1 = ElasticNet(alpha=0.3077).fit(train_X, train_y)\npd.DataFrame(np.e ** el1.predict(test_X), columns=['Prediction']).to_csv('el1.csv', index=True, index_label='Id')\n\nel2 = ElasticNet(alpha=0.2426).fit(train_X, train_y)\npd.DataFrame(np.e ** el2.predict(test_X), columns=['Prediction']).to_csv('el2.csv', index=True, index_label='Id')\n\nel3 = ElasticNet(alpha=0.04738).fit(train_X, train_y)\npd.DataFrame(np.e ** el3.predict(test_X), columns=['Prediction']).to_csv('el3.csv', index=True, index_label='Id')","69211ed8":"forest = RandomForestRegressor().fit(train_X, train_y)\nforest_res = np.e ** forest.predict(test_X)\n\npd.DataFrame(forest_res, columns=['Prediction']).to_csv('random_forest.csv', index=True, index_label='Id')","e3d9355c":"## Lasso Bayesian","609d5846":"## Ridge Bayesian","e7792ed0":"## Ridge \/ Lasso \/ Elastic Grid","d8a77129":"### Linear Regression \nprivat = 2184958\\\npublic = 2267419\n\n### Ridge Grid\n-> privat = 1856312 <-\\\npublic = 1794325\\\nalpha = 1\n\n### Ridge Bayesian\n-> privat = 1856714 <-\\\npublic = 1786455\\\nalpha = 6.7324\n\n### Lasso Grid\nprivat = 1884336\\\npublic = 1820866\\\nalpha = 0.1\n\n### Lasso Bayesian\nprivat = 1881090\\\npublic = 1845355\\\nalpha = 0.02945\n\nprivat = 1878008\\\npublic = 1803083\\\nalpha = 0.07492\n\n### Elastic Grid\nprivat = 1881090\\\npublic = 1845355\\\nalpha = 0.01\n\n### Elastic Bayesian\nprivat = 1915020\\\npublic = 1872468\\\nalpha = 0.3077\n\nprivat = 1895483\\\npublic = 1840963\\\nalpha = 0.2426\n\nprivat = 1878905\\\npublic = 1777505\\\nalpha = 0.04738\n\n### Random Forest\n-> privat = 1857199 <-\\\npublic = 1859951\n","2a640529":"# Models","9fa6734d":"## Random Forest","c2437402":"# Results","b35558e6":"## Elastic Bayesian\n","af7ace9d":"# Feature preprocessing","71e8f5a3":"## Linear Regression"}}