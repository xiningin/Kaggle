{"cell_type":{"a6f3492b":"code","c3f7b5a8":"code","db2f488b":"code","200dc301":"code","8bfeff01":"code","ab5128a0":"code","c19dbde7":"code","0add9fcc":"code","8fb2b8d5":"code","ebf70912":"code","9be47b3e":"code","f938048e":"code","08423459":"code","7b83fbd4":"code","083f0ebc":"code","a8166947":"code","1fb6db24":"code","4c0a724c":"code","6202f143":"code","19412e1f":"code","e7202cc1":"code","dd040ff4":"code","a49afb11":"code","8846a01c":"code","580cf9a7":"code","627245e1":"code","f589cdce":"code","d130d950":"code","7000b992":"code","8fec5df5":"code","bb6991b8":"code","9cb3b6cb":"code","5378ce20":"code","629a3776":"code","d260ac97":"code","a9c178b7":"code","873e652a":"code","72f57438":"code","e2577d17":"code","98ec18b8":"code","0328684d":"code","7fc45d56":"code","9e9b6fa9":"code","6fcb2d5e":"code","2dff364e":"code","35142f66":"code","82766fdf":"markdown","2e94ca24":"markdown","9b22b2a8":"markdown","572f9d95":"markdown","90452b83":"markdown","10c5978a":"markdown","7352831a":"markdown","22132131":"markdown","a53b227b":"markdown","2ed0c7f6":"markdown","78fa9ecb":"markdown","db40223a":"markdown","cf32ff21":"markdown","7dc35072":"markdown","7bc840fd":"markdown","9aee5bf0":"markdown","9211c7a6":"markdown","a081f238":"markdown","5baeb7ac":"markdown"},"source":{"a6f3492b":"import numpy as np\nimport pandas as pd\nimport tensorflow\nimport seaborn as sns\n","c3f7b5a8":"#train_data = pd.read_csv(\"train.csv\")\n#test_data = pd.read_csv(\"test.csv\")\ntrain_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","db2f488b":"#printing first five rows of  train_dataset\ntrain_data.head() ","200dc301":"test_data.head()","8bfeff01":"# checking shape of train_data\ntrain_data.shape # 891 rows and 12 columns","ab5128a0":"#checking shape of test data\ntest_data.shape","c19dbde7":"train_data.info()","0add9fcc":"test_data.info()","8fb2b8d5":"# sumarie and statistics\ntrain_data.describe()","ebf70912":"test_data.describe()","9be47b3e":"train_data.isnull().sum()","f938048e":"test_data.isnull().sum()","08423459":"# Correlation matrix between numerical values (SibSp Parch Age and Fare values) and Survived \ng = sns.heatmap(train_data[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True\n                , fmt = \".2f\", cmap = \"coolwarm\")","7b83fbd4":"# survival probability\ng1 = sns.barplot(x=\"Sex\",y=\"Survived\",data=train_data)\ng1 = g.set_ylabel(\"Survival Probability\")","083f0ebc":"# handle missing value in train_data\ntrain_data[\"Age\"] = train_data[\"Age\"].fillna(train_data[\"Age\"].mean())","a8166947":"train_data[\"Age\"].head()","1fb6db24":"train_data.isnull().sum()","4c0a724c":"# handle missing value in test_data\ntest_data[\"Age\"] = test_data[\"Age\"].fillna(test_data[\"Age\"].mean())","6202f143":"test_data.isnull().sum()","19412e1f":"# train_data\ntrain_data['Cabin']=train_data['Cabin'].fillna(train_data['Cabin'].mode()[0])\ntrain_data['Embarked']=train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n\n","e7202cc1":"train_data.isnull().sum() # all missing values handle","dd040ff4":"# test_data\ntest_data['Cabin']=test_data['Cabin'].fillna(test_data['Cabin'].mode()[0])\ntest_data['Fare']=test_data['Fare'].fillna(test_data['Fare'].mode()[0])\n","a49afb11":"test_data.isnull().sum()","8846a01c":"dataset =  pd.concat([train_data, test_data], axis=0)","580cf9a7":"dataset.shape","627245e1":"# Fill empty and NaNs values with NaN\ndataset = dataset.fillna(np.nan)","f589cdce":"# drop name column\ndataset.drop(['Name'],axis=1,inplace=True)","d130d950":"dataset.columns","7000b992":"from sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()","8fec5df5":"encode = dataset[['Sex','Ticket','Cabin','Embarked']].apply(enc.fit_transform)\nencode","bb6991b8":"dataset[['Sex','Ticket','Cabin','Embarked']] = encode[['Sex','Ticket','Cabin','Embarked']]","9cb3b6cb":"dataset.head()","5378ce20":"dataset.shape","629a3776":"train_len = len(train_data)","d260ac97":"train = dataset[:train_len]\ntest= dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","a9c178b7":"test.shape","873e652a":"train.shape","72f57438":"train[\"Survived\"] = train[\"Survived\"].astype(int)","e2577d17":"Y_train = train[\"Survived\"]\n\nX_train = train.drop(labels = [\"Survived\"],axis = 1)","98ec18b8":"from sklearn.ensemble import GradientBoostingClassifier\n","0328684d":"#model = GradientBoostingClassifier(learning_rate=0.01,max_depth = 2)\nmodel = GradientBoostingClassifier(learning_rate=0.02,max_depth = 2,n_estimators =100)\nmodel.fit(X_train, Y_train)","7fc45d56":"Score = model.score(X_train, Y_train)\nprint(\"Score: %.2f%%\" % (Score * 100.0))","9e9b6fa9":"predictions = model.predict(test)","6fcb2d5e":"output = pd.DataFrame({'Passenger Id': test_data.PassengerId, 'Survived': predictions})","2dff364e":"output ","35142f66":"output.to_csv('my_submission1.csv', index=False)\nprint(\"Your submission was successfully saved!\")","82766fdf":"# load and check data","2e94ca24":"# Modeling","9b22b2a8":"# numerical_values","572f9d95":"# Data exploratory","90452b83":"# One_Hot_Coding","10c5978a":"#  Saving submission csv file","7352831a":"#  use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","22132131":"\u2022\tIntroduction::\n\u2022\tLoad data\n\u2022\tData exploratory\n\u2022\tCheck missing value\n\u2022\tFeature analysis\n\u2022\tHandle missing values\n\u2022\tJoining test and train data\n\u2022\tOne hot coding\n\u2022\tSplitting data\n\u2022\tTraning model using RandomForestClassifier\n\u2022\tPredication\n\u2022\tSaving submission file in csv format\n","a53b227b":"# Training ","2ed0c7f6":"# How to handle categorical data?","78fa9ecb":"# check missing values in train and test data","db40223a":"If you found this notebook helpful or you just liked it , some upvotes would be very much appreciated - That will keep me motivated :)","cf32ff21":"# handle missing values","7dc35072":"# joining test and train data_set","7bc840fd":"# objective:","9aee5bf0":"# Categorical values","9211c7a6":"# Output","a081f238":"# Predication","5baeb7ac":"# Feature analysis"}}