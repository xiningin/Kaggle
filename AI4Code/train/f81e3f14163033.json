{"cell_type":{"7c9a5540":"code","51bd9e98":"code","72d12cd5":"code","e8387a98":"code","fba27c1b":"code","5c617e95":"code","000bce4e":"code","7b3fcb6f":"code","57558986":"code","286ae048":"code","0babf4d7":"code","40f96fa4":"markdown","3a7833cd":"markdown","15a1e6ca":"markdown","13cb3f01":"markdown","f94ca995":"markdown","72cef9ff":"markdown","23aca6fd":"markdown"},"source":{"7c9a5540":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51bd9e98":"import pandas as pd\nimport numpy as np\nimport  matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ndf = pd.read_csv(\"..\/input\/sms-spam-collection-dataset\/spam.csv\" , encoding=\"ISO-8859-1\")\ndf\ndf.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\ndf.head()","72d12cd5":"df= df.rename(columns={'v1':'spam','v2':'text'})\ndf","e8387a98":"ham = df[df['spam']== 'ham']\nham\nprint ('ham percentage =', (len(ham))\/len(df)*100,'%')","fba27c1b":"spam = df[df['spam']== 'spam']\nprint ('spam percentage =', (len(spam))\/len(df)*100,'%')","5c617e95":"sns.countplot(df['spam'])\n","000bce4e":"import sklearn \nfrom sklearn.feature_extraction.text import CountVectorizer\na= CountVectorizer()\nd = a.fit_transform(df['text'])\nprint(d.toarray())","7b3fcb6f":"label = df['spam'].values\n\nfrom sklearn.naive_bayes import MultinomialNB\nNB= MultinomialNB()\nNB.fit(d, label)\ntest= [' Free entry in cinema  ', 'even my brother speak to Him']\ntesting = a.transform(test)\nham_or_spam =NB.predict(testing )\nham_or_spam","57558986":"X = d\ny = label \ny.shape\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.2)\nfrom sklearn.naive_bayes import MultinomialNB \ne = MultinomialNB()\ne.fit( X_train, y_train)\nfrom sklearn.metrics import classification_report , confusion_matrix\npredict= e.predict (X_train)\ncm = confusion_matrix(y_train, predict)\nsns.heatmap(cm, annot= True )","286ae048":"test_predict= e.predict (X_test)\ncm = confusion_matrix(y_test, test_predict)\nsns.heatmap(cm, annot= True )\ncm","0babf4d7":"print(classification_report(y_test, test_predict))","40f96fa4":"***Check and test , whether it can detect given  sentences are ham or spam*******","3a7833cd":"**now check model performance for testing part **","15a1e6ca":"** **find out the percentage of ham and spam***","13cb3f01":"*** split the dataset into training and testing and sort out the model prediction  then plot its confusion matrix ***","f94ca995":"**classification Report ****","72cef9ff":"******converting Text  it into Array***`*","23aca6fd":"**ploting both spam and ham**"}}