{"cell_type":{"eb35f7eb":"code","54f993e9":"code","acf163d4":"code","f035532d":"code","9b67ca94":"code","26c449d0":"code","8d21cb72":"code","5353e8c1":"code","134d366c":"code","5a4e82c2":"code","5bbfa87e":"code","5b36e4ec":"code","e67a4072":"markdown","bebc7d5b":"markdown","6c3e5b6a":"markdown","a9776306":"markdown","d03b0a91":"markdown","a59b1f6f":"markdown","a0964a9a":"markdown","777b3829":"markdown","43cfe5e2":"markdown","9cda181b":"markdown","54fc10a2":"markdown","85e3575f":"markdown","c67d0e26":"markdown","4a4222cf":"markdown"},"source":{"eb35f7eb":"from fastai.vision.all import *","54f993e9":"path = untar_data(URLs.PETS)","acf163d4":"files = get_image_files(path\/\"images\")\n\nfiles[:5]\n","f035532d":"def label_func(f):\n    return f[0].isupper()","9b67ca94":"dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))","26c449d0":"dls.show_batch(max_n=3)","8d21cb72":"learner = cnn_learner(dls, resnet34, metrics=accuracy)","5353e8c1":"learner.lr_find()","134d366c":"learner.fine_tune(1, base_lr=9e-3)","5a4e82c2":"learner.lr_find()","5bbfa87e":"learner.fit_one_cycle(1, 7e-7)","5b36e4ec":"for data in dls:\n    print(data)\n#     print(X.shape)\n#     print(len(y))\n    dir(data)","e67a4072":"### Creating a dataloader","bebc7d5b":"### Finding the optimal learning rate automatically","6c3e5b6a":"### Looking at DLS","a9776306":"### Looking at the dataset","d03b0a91":"### Fine tuning based on optimal learning rate","a59b1f6f":"### Getting the images from path","a0964a9a":"### Downloading the dataset.\n\nCats and dogs in this case.","777b3829":"### Finding best lr again\n\nSince after fine tuning the best lr changes.","43cfe5e2":"### Label function","9cda181b":"We are getting a good accuracy through minimal code but I want to dig deep and find out how fastai is achieving this.\nI get to it in future.","54fc10a2":"Cats will have label True and dogs False.","85e3575f":"### Creating a nerual network","c67d0e26":"### Loading the fastai library","4a4222cf":"### Finally training on the lr"}}