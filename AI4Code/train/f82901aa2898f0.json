{"cell_type":{"80c14faf":"code","47db945e":"code","981f116e":"code","879d1023":"code","e6d2b169":"code","d134e260":"code","4e52f432":"code","9ba0c991":"markdown"},"source":{"80c14faf":"import os\n\nspam_emails_path = \"..\/input\/ham-and-spam-dataset\/spam\"\nham_emails_path = \"..\/input\/ham-and-spam-dataset\/ham\"\n\nlabeled_file_directories = [(spam_emails_path, 0), (ham_emails_path,1)]","47db945e":"email_corpus = []\nlabels = []\n\nfor class_files, label in labeled_file_directories:\n    files = os.listdir(class_files)\n    for file in files:\n        file_path = os.path.join(class_files, file)\n        try:\n            with open(file_path, \"r\") as currentFile:\n                email_content = currentFile.read().replace(\"\\n\", \"\")\n                email_content = str(email_content)\n                email_corpus.append(email_content)\n                labels.append(label)\n        except:\n            pass\n        ","981f116e":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(email_corpus, labels, test_size=0.2, random_state=11)","879d1023":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\nfrom sklearn import tree\n\nnlp_followed_by_dt = Pipeline(\n    [\n    (\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1,3))),\n    (\"tfidf\", TfidfTransformer(use_idf=True,)),\n    (\"dt\", tree.DecisionTreeClassifier(class_weight=\"balanced\")),\n    ]\n)\n\nnlp_followed_by_dt.fit(X_train, y_train)","e6d2b169":"print(nlp_followed_by_dt.score(X_train, y_train))","d134e260":"nlp_followed_by_dt.score(X_test, y_test)","4e52f432":"from sklearn.metrics import accuracy_score, confusion_matrix\n\ny_test_pred = nlp_followed_by_dt.predict(X_test)\naccuracy_score(y_test, y_test_pred)\nconfusion_matrix(y_test, y_test_pred)\n","9ba0c991":"# Simple spam filtering using scikit learn\n\nWe start by preparing a dataset consisting of raw emails (Step 1), which the reader can\nexamine by looking at the dataset. In Step 2, we specify the paths of the spam and ham\nemails, as well as assign labels to their directories. We proceed to read all of the emails into\nan array, and create a labels array in Step 3. Next, we train-test split our dataset (Step 4), and\nthen fit an NLP pipeline on it in Step 5. Finally, in Step 6, we test our pipeline. We see that\naccuracy is pretty high. Since the dataset is relatively balanced, there is no need to use\nspecial metrics to evaluate success"}}