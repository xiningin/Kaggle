{"cell_type":{"951aa243":"code","43c92581":"code","61fec56a":"code","36817b6c":"code","d1a72751":"code","6387382c":"code","48742e78":"code","0079fbc9":"code","36c3181d":"code","f1b7f02a":"code","ca055731":"code","1cda9e22":"code","e7217d69":"code","e41cfcc6":"code","89e315f7":"code","f96e7933":"code","c7acf89b":"code","e2b4e13a":"code","f71fbf03":"markdown","111e5532":"markdown","6cb9ac16":"markdown","ead371a1":"markdown","7b454926":"markdown","60a9b58e":"markdown"},"source":{"951aa243":"import torch\nfrom torch.utils.data import DataLoader\nfrom torch import optim\nfrom torchvision import datasets\nimport torch.nn as nn\nfrom torchvision import transforms\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport datetime","43c92581":"train=datasets.CIFAR10(root='data',\n                      train=True,\n                      download=True,\n                      transform=transforms.ToTensor())","61fec56a":"test=datasets.CIFAR10(root='data',\n                      train=False,\n                      download=True,\n                      transform=transforms.ToTensor())","36817b6c":"label_class={\n0:'airplane',\n1:'automobile',\n2:'bird',\n3:'cat',\n4:'deer',\n5:'dog',\n6:'frog',\n7:'horse',\n8:'ship',\n9:'truck'\n}","d1a72751":"img,label=train[99]\nplt.title(label_class[label])\nplt.axis('off')\nplt.imshow(img.permute(1,2,0))","6387382c":"img.shape","48742e78":"label_map = {0: 0, 2: 1}\ncifar_2_train=[(img,label_map[label]) for img,label in train if label in [0,2]]\ncifar_2_test=[(img,label_map[label]) for img,label in test if label in [0,2]]","0079fbc9":"train_loader=DataLoader(cifar_2_train, batch_size=64,shuffle=True)","36c3181d":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, padding=1)\n        self.drop_out_1=nn.Dropout2d(p=.4)\n        self.conv2 = nn.Conv2d(128, 32, kernel_size=3, padding=1)\n        self.drop_out_2=nn.Dropout2d(p=.4)\n        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.fc3 = nn.Linear(32, 2)\n    def forward(self, x):\n        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n        out = self.drop_out_1(out)\n        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n        out = self.drop_out_2(out)\n        out = out.view(-1, 32 * 8 * 8)\n        out = torch.tanh(self.fc1(out))\n        out = self.fc2(out)\n        out = self.fc3(out)\n        return out","f1b7f02a":"if torch.cuda.is_available():\n    device=torch.device('cuda')\nelse:\n    device=torch.device('cpu')\n    \nmodel = Net().to(device)","ca055731":"optimizer=optim.Adam(model.parameters(),1e-4)\nloss_fn=nn.CrossEntropyLoss()","1cda9e22":"def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n    for epoch in range(1,n_epochs+1):\n        loss_train = 0.0\n        for imgs,labels in train_loader:\n            imgs=imgs.to(device)\n            labels = labels.to(device)\n            output=model(imgs)\n            \n            loss=loss_fn(output, torch.tensor(labels))\n            \n            #L2 Regularization\n            l2_lambda=0.001\n            l2_norm=sum(p.pow(2).sum() for p in model.parameters())\n            loss=loss+l2_lambda*l2_norm\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            loss_train += loss.item()\n\n        if epoch == 1 or epoch % 10 == 0:\n            print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch,\n                                                         loss_train \/ len(train_loader)))","e7217d69":"training_loop(\nn_epochs = 100,\noptimizer = optimizer,\nmodel = model,\nloss_fn = loss_fn,\ntrain_loader = train_loader)","e41cfcc6":"test_loader=DataLoader(cifar_2_test,batch_size=64,shuffle=False)\ntrain_loader=DataLoader(cifar_2_train,batch_size=64,shuffle=False)","89e315f7":"def validate(model, train_loader, val_loader):\n    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for imgs, labels in loader:\n                imgs=imgs.to(device)\n                labels=labels.to(device)\n                outputs = model(imgs)\n                _, predicted = torch.max(outputs, dim=1)\n                total += labels.shape[0]\n                correct += int((predicted == labels).sum())\n        print(\"Accuracy {}: {:.2f}\".format(name , correct \/ total))","f96e7933":"validate(model, train_loader, test_loader)","c7acf89b":"torch.save(model.state_dict(), '.\/' + 'birds_vs_airplanes.pt')","e2b4e13a":"loaded_model=Net()\nloaded_model.load_state_dict(torch.load('.\/'+ 'birds_vs_airplanes.pt',map_location=device))","f71fbf03":"Since we only need airplane and birds from the Cifar10 dataset which contains 10 different item images, we are going to select only the birds and airplane data from the dataset.","111e5532":"So my new version has a training set accuracy of 95% and a validation set accuracy of 89%  in detecting birds and airplane accurately. Woohoo! That's cool. I have sucessfully built a highly accurate model that can distinguish airplane and birds in the sky. So, what am I waiting for? Let's save the model. ","6cb9ac16":"Lets save the model","ead371a1":"To load the model,","7b454926":"Let's train the model in GPU","60a9b58e":"Jane, our friend at the bird-watching club, has set up a fleet of cameras in the woods\nsouth of the airport. The cameras are supposed to save a shot when something enters\nthe frame and upload it to the club\u2019s real-time bird-watching blog. The problem is\nthat a lot of planes coming and going from the airport end up triggering the camera. so Jane spends a lot of time deleting pictures of airplanes from the blog. What she\nneeds is an automated system that throws away the airplane."}}