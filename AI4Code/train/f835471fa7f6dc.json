{"cell_type":{"8d34d883":"code","9dbf85c1":"code","216d10cf":"code","e9b4f349":"code","e1fe1002":"code","b8a59791":"code","1e6a471a":"code","e8ad358c":"code","dbe35b16":"code","a52fd486":"code","d82c8fd3":"code","8cb330c2":"code","e153a76a":"code","2d58709b":"code","d828f214":"code","1599bbd6":"code","2771caab":"code","42a56c7b":"code","6b53fd47":"code","a7178c43":"code","44ced6a2":"code","09df5a10":"code","cdcaf831":"code","0ed38b73":"code","ee7d40b9":"code","b83e511c":"code","91c18818":"code","f8d8f0c2":"code","c994572d":"code","14760ec7":"code","f7831a1e":"code","05605fd6":"code","b3cea342":"code","ca130b07":"code","63ef4175":"code","3c4563c3":"code","4e10d0b2":"code","acfc2201":"code","72a6e6a9":"code","48a6219e":"code","7d68e0c3":"code","9b4bd9ac":"code","afa75e32":"code","a321f398":"code","8df0556c":"code","d523d60c":"code","6844dc04":"code","277827e1":"code","59656668":"code","c78f4868":"code","703907dc":"code","9fc5b82a":"code","1c603f20":"code","99c4a11c":"code","84efd829":"code","4ae045c9":"code","af2de25e":"code","5d57d22f":"code","fb55507d":"code","9ed83a98":"code","9ec00415":"code","39ebaca3":"code","5fb7cb4c":"code","6bdf6fea":"code","04211c14":"code","453d3287":"code","6116a126":"code","dde2d2f7":"code","fec36abc":"code","8fe6065a":"code","2da7b23e":"code","7af33ed4":"code","b61ddeed":"code","39dfe254":"code","de484a22":"code","ec1f9238":"code","b37bde74":"code","ff540369":"code","42fcf01f":"code","ddf51562":"code","33026810":"code","d949cd4b":"code","5f1476a4":"code","42f7cbf7":"code","35801263":"code","0fc52109":"code","f207b0e7":"code","e72e4b9a":"code","a00c18a3":"code","2551a5de":"code","0956d027":"code","34a95a56":"code","cfce627a":"code","69353c99":"code","8ce2857e":"code","3491cd48":"code","98dafeb6":"code","93d1b8b7":"code","4358d035":"code","73b6f21f":"code","11b4f6a1":"code","a0c45db5":"code","83aad0f8":"code","998b084a":"code","487630c0":"code","fac4a22f":"code","10af5a43":"code","6157de5b":"code","0ca48340":"code","8af253cf":"code","e2a8de1e":"code","ed6e4c12":"code","8f2027b8":"code","cd5942c3":"code","7d966e71":"code","5619e349":"code","b796349a":"code","87420528":"code","b14e3f17":"code","8bece734":"code","18af03d5":"code","39595ebc":"code","75f47793":"code","6496baad":"code","eabb685e":"code","25ac8957":"code","6666e75b":"code","f9577b73":"code","364cebf5":"code","1ad2adfc":"code","08455be5":"code","7d3d1337":"code","47d3846f":"code","bc7bff3f":"code","0f94bdbf":"code","18895a9c":"markdown","95816b28":"markdown","a6f67123":"markdown","9d110c5f":"markdown","5620f942":"markdown","218c55d1":"markdown","19607e2e":"markdown","7448dc8f":"markdown","97320a8c":"markdown","7fdc5c38":"markdown","959ae7ec":"markdown","21850553":"markdown","25515737":"markdown","82effdb5":"markdown","640b3ae8":"markdown","afa76372":"markdown","f8ff4c49":"markdown","004a6bea":"markdown","17d56cc4":"markdown","02500782":"markdown","ce86d0c5":"markdown","8a19093a":"markdown","1d2aac61":"markdown","4556e661":"markdown","b2af9601":"markdown","506e1673":"markdown","95f89a1a":"markdown","f734beed":"markdown","953e770b":"markdown","2f46af38":"markdown","b62ebcac":"markdown","76ebd0b5":"markdown","1ae8f4dd":"markdown","80f70669":"markdown","cc457fba":"markdown","728f169e":"markdown","1e9d537b":"markdown","3a619fb9":"markdown","6e838307":"markdown","b4d07d3e":"markdown","01d64d0e":"markdown","09f3af73":"markdown","244e5333":"markdown","cb7fdc41":"markdown","484f0605":"markdown","cf20819d":"markdown","6e796dbf":"markdown","1b348f25":"markdown","ff916dd6":"markdown","e14889a8":"markdown","2d4090cb":"markdown","2d390ec2":"markdown","fa3f174d":"markdown","342cc1d1":"markdown","8d10b6b8":"markdown","56b96c7f":"markdown","4534b7d4":"markdown","1135783b":"markdown","72f286aa":"markdown","16aa5ac7":"markdown","fd53862e":"markdown"},"source":{"8d34d883":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9dbf85c1":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom geopy.geocoders import Nominatim\nimport folium\nfrom folium.plugins import HeatMap\nfrom folium.plugins import FastMarkerCluster\nfrom plotly import tools\nimport re\nfrom plotly.offline import init_notebook_mode, plot, iplot\nfrom wordcloud import WordCloud, STOPWORDS \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nimport missingno as msno\nimport glob\n\nsns.set_theme(style=\"whitegrid\")\nsns.color_palette(\"cubehelix\")","216d10cf":"path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nall_files = glob.glob(path + \"\/*.csv\")\n\nli = []\n\nfor filename in all_files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    li.append(df)\n    \nengagement_df = pd.concat(li)\nengagement_df = engagement_df.reset_index(drop=True)\nengagement_df.head()","e9b4f349":"engagement_df.shape","e1fe1002":"engagement_df.isna().sum() * 100.0 \/ engagement_df.shape[0]","b8a59791":"engagement_df.nunique()","1e6a471a":"engagement_df.dtypes","e8ad358c":"engagement_df_refined = engagement_df.copy()\nengagement_df_refined.head()","dbe35b16":"engagement_df_refined[\"district_id\"] = engagement_df_refined[\"district_id\"].astype(\"category\")\nengagement_df_refined[\"district_id\"].head()","a52fd486":"engagement_df_refined[\"time\"] = pd.to_datetime(engagement_df_refined[\"time\"])","d82c8fd3":"## The day of the week with Monday=0, Sunday=6.\nengagement_df_refined[\"month\"] = engagement_df_refined[\"time\"].dt.month\nengagement_df_refined[\"dayofweek\"] = engagement_df_refined[\"time\"].dt.dayofweek\nengagement_df_refined[\"weekofyear\"] = engagement_df_refined[\"time\"].dt.weekofyear\nengagement_df_refined.head()","8cb330c2":"engagement_df_refined.describe()","e153a76a":"sns.scatterplot(data=engagement_df_refined\n               ,x=\"pct_access\"\n               ,y=\"engagement_index\")","2d58709b":"((engagement_df_refined[\"pct_access\"] == 0.0) & \n (engagement_df_refined[\"engagement_index\"] > 0.0)).sum()","d828f214":"((engagement_df_refined[\"pct_access\"] > 0.0) & \n (engagement_df_refined[\"engagement_index\"] == 0.0)).sum()","1599bbd6":"engagement_df_refined[  (engagement_df_refined[\"lp_id\"].isna()) \n                      | (engagement_df_refined[\"pct_access\"].isna())\n                      | (engagement_df_refined[\"engagement_index\"].isna())\n                     ].head(10)","2771caab":"((engagement_df_refined[\"pct_access\"] == 0.0) & \n (engagement_df_refined[\"engagement_index\"].isna())).sum()","42a56c7b":"engagement_df_refined[\"engagement_index\"].fillna(value=engagement_df_refined[\"pct_access\"] * 10.\n                                                ,inplace=True)","6b53fd47":"engagement_df_refined[\"pct_access\"].fillna(value=engagement_df_refined[\"engagement_index\"] \/ 10.\n                                          ,inplace=True)","a7178c43":"engagement_df_refined.isna().sum()","44ced6a2":"((engagement_df_refined[\"pct_access\"].isna()) & \n (engagement_df_refined[\"engagement_index\"].isna())).sum()","09df5a10":"engagement_df_refined[\"pct_access\"].fillna(value=0.0 ,inplace=True)","cdcaf831":"engagement_df_refined[\"engagement_index\"].fillna(value=0.0, inplace=True)","0ed38b73":"engagement_df_refined.isna().sum() ","ee7d40b9":"engagement_df_refined[engagement_df_refined[\"lp_id\"].isna()].head(10)","b83e511c":"engagement_df_refined[\"engagement_index_lower_bound\"] = (engagement_df_refined[\"pct_access\"] \/ 100.0) * 1000.0\nengagement_df_refined.head(10)","91c18818":"((engagement_df_refined[\"engagement_index\"] >= engagement_df_refined[\"engagement_index_lower_bound\"])).sum()","f8d8f0c2":"engagement_df_refined[((engagement_df_refined[\"engagement_index\"] < engagement_df_refined[\"engagement_index_lower_bound\"]))].index","c994572d":"engagement_df_refined.drop( engagement_df_refined[((engagement_df_refined[\"engagement_index\"] < engagement_df_refined[\"engagement_index_lower_bound\"]))].index\n                          , inplace=True)\n\nengagement_df_refined.shape","14760ec7":"print(\"Percentage of dropped rows (engagement_index_lower_bound check): \", 1171702 * 100. \/ (1171702 + 21152488))","f7831a1e":"# sns.scatterplot( x=\"pct_access\"\n#                , y=\"engagement_index\"\n#                , data=engagement_df_refined)","05605fd6":"engagement_df_refined[\"pct_access_upper_bound\"] = (engagement_df_refined[\"engagement_index\"] \/ 1000.0) * 100.0\nengagement_df_refined.head(10)","b3cea342":"print(\"pct_access_upper_bound check passed rows: \", (engagement_df_refined[\"pct_access\"] <= engagement_df_refined[\"pct_access_upper_bound\"]).sum())","ca130b07":"print(\"pct_access_upper_bound check falied rows: \", (engagement_df_refined[\"pct_access\"] > engagement_df_refined[\"pct_access_upper_bound\"]).sum())","63ef4175":"engagement_df_refined.drop( engagement_df_refined[((engagement_df_refined[\"pct_access\"] > engagement_df_refined[\"pct_access_upper_bound\"]))].index\n                          , inplace = True)\n\nengagement_df_refined.shape","3c4563c3":"print(\"Percentage of pct_access_upper_bound check failed entries: \", 442 * 100. \/ (1171702 + 442 + 21152488))","4e10d0b2":"engagement_df_refined.describe()","acfc2201":"engagement_df_refined.drop([\"engagement_index_lower_bound\", \n                            \"pct_access_upper_bound\"]\n                           ,axis=1\n                           ,inplace=True\n                          )","72a6e6a9":"sns.scatterplot( data=engagement_df_refined\n                ,x=\"pct_access\"\n                ,y=\"engagement_index\")","48a6219e":"engagement_df_refined[engagement_df_refined[\"lp_id\"].isna()].head(10)","7d68e0c3":"engagement_df_refined[\"lp_id\"].fillna(value=0.0, inplace=True)\n# engagement_df_refined[\"pct_access\"].fillna(value=0.0, inplace=True)\n# engagement_df_refined.dropna(subset=[\"engagement_index\"], inplace=True)","9b4bd9ac":"engagement_df_refined[\"lp_id\"] = engagement_df_refined[\"lp_id\"].astype(\"category\")\nengagement_df_refined[\"month\"] = engagement_df_refined[\"month\"].astype(\"category\")\nengagement_df_refined[\"dayofweek\"] = engagement_df_refined[\"dayofweek\"].astype(\"category\")\nengagement_df_refined[\"weekofyear\"] = engagement_df_refined[\"weekofyear\"].astype(\"category\")","afa75e32":"print(\"before imputation and cleaning: \\n\\n\", engagement_df.nunique())","a321f398":"print(\"after imputation and cleaning: \\n\\n\", engagement_df_refined.nunique())","8df0556c":"print(\"Learning Platforms with wrong relationships = {0} - {1} = {2}\".format(\n        engagement_df[\"lp_id\"].nunique()\n      , engagement_df_refined[\"lp_id\"].nunique()\n      , engagement_df[\"lp_id\"].nunique() - engagement_df_refined[\"lp_id\"].nunique())\n     )","d523d60c":"engagement_df_refined.describe()","6844dc04":"basedate = pd.to_datetime('2020-01-01')\nengagement_df_refined[\"days_since\"] = (engagement_df_refined[\"time\"] - basedate).dt.days\nengagement_df_refined.describe()","277827e1":"sns.distplot( engagement_df_refined[\"pct_access\"]\n            , kde=False)\n\nplt.show()\n\nprint(\"pct_access skew: \", engagement_df_refined[\"pct_access\"].skew())","59656668":"sns.distplot( engagement_df_refined[\"engagement_index\"]\n            , kde=False)\n\nplt.show()\n\nprint(\"engagement_index skew: \", engagement_df_refined[\"engagement_index\"].skew())","c78f4868":"engagement_df_refined[\"district_id\"] = engagement_df_refined[\"district_id\"].astype(\"category\")\nengagement_df_refined[\"days_since\"] = engagement_df_refined[\"days_since\"].astype(\"category\")","703907dc":"grouped = engagement_df_refined.groupby(by=[\"month\"])[\"lp_id\"].unique().reset_index(name=\"lp_id\")\ngrouped","9fc5b82a":"## https:\/\/stackoverflow.com\/questions\/23333786\/reference-values-in-the-previous-row-with-map-or-apply\nnew_col = 'result'\n\ndef apply_func_decorator(func):\n    prev_row = {}\n    def wrapper(curr_row, **kwargs):\n        val = func(curr_row, prev_row)\n        prev_row.update(curr_row)\n        prev_row[new_col] = val\n        return val\n    return wrapper\n\n@apply_func_decorator\ndef running_total(curr_row, prev_row):\n\n      return np.unique(list(curr_row['lp_id'])  + list(prev_row.get(\"result\", [])))","1c603f20":"grouped[\"result\"] = np.nan\ngrouped[\"result\"] = grouped.apply( running_total\n                                 , axis=1)\n\ngrouped[\"result\"]","99c4a11c":"grouped[\"count\"] = grouped[\"result\"].apply(lambda x: len(x))","84efd829":"grouped[\"count\"]","4ae045c9":"plt.figure(figsize=(8, 6))\n\nsns.barplot(data=grouped\n            ,x=\"month\"\n            ,y=\"count\"\n            ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"unique learning platforms\")\nplt.show()","af2de25e":"grouped[\"lp_id\"] = grouped[\"lp_id\"].apply(np.sort)\ngrouped","5d57d22f":"grouped[\"new_count\"] = grouped[\"count\"] - grouped[\"count\"].shift(1)\ngrouped[\"new_count\"].fillna(value=0, inplace=True)","fb55507d":"grouped","9ed83a98":"plt.figure(figsize=(8, 6))\n\nsns.barplot(data=grouped\n            ,x=\"month\"\n            ,y=\"new_count\"\n            ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"Newly-launched Learning Platforms\")\nplt.show()","9ec00415":"grouped[\"prev_result\"] = grouped[\"result\"].shift(1)\ngrouped[\"prev_result\"] = grouped[\"prev_result\"].fillna(\"\").apply(list)","39ebaca3":"grouped[\"discontinued\"] = (grouped[\"prev_result\"].map(set) - grouped[\"lp_id\"].map(set)).apply(list)\ngrouped","5fb7cb4c":"grouped[\"closed_count\"] = grouped[\"discontinued\"].apply(lambda x: len(x))\ngrouped","6bdf6fea":"plt.figure(figsize=(8, 6))\n\nsns.barplot( x=\"month\"\n            ,y=\"closed_count\"\n            ,data=grouped\n            ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"discontinued learning platforms\")\nplt.show()","04211c14":"def intersection(a, b):\n    return list(set(a) & set(b))","453d3287":"grouped[\"common\"] = grouped.apply( lambda x: intersection(x[\"lp_id\"], x[\"prev_result\"])\n                                 , axis=1)\n\ngrouped","6116a126":"grouped[\"common_count\"] = grouped[\"common\"].apply(len)\ngrouped","dde2d2f7":"plt.figure(figsize=(8,6))\n\nsns.barplot(x=\"month\"\n           ,y=\"common_count\"\n           ,data=grouped\n           ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"sustained learning platforms\")\nplt.show()","fec36abc":"engagement_df_refined[\"district_id\"] = engagement_df_refined[\"district_id\"].astype(int)","8fe6065a":"grouped = engagement_df_refined.groupby(by = [\"month\"])[\"district_id\"].unique().reset_index(name=\"district_id\")\ngrouped","2da7b23e":"@apply_func_decorator\ndef get_cumulative(curr_row, prev_row):\n\n    return np.unique(list(curr_row['district_id'])  + list(prev_row.get(\"result\", [])))","7af33ed4":"grouped[\"result\"] = np.nan\ngrouped[\"result\"] = grouped.apply( get_cumulative\n                                  ,axis=1)","b61ddeed":"grouped","39dfe254":"grouped[\"cum_districts_count\"] = grouped[\"result\"].apply(lambda x: len(x))\ngrouped","de484a22":"plt.figure(figsize=(8,6))\n\nsns.barplot( data=grouped\n            ,x=\"month\"\n            ,y=\"cum_districts_count\"\n            ,palette=\"cubehelix_r\"\n           )\n\nplt.ylabel(\"cumulative districts count\")\nplt.show()","ec1f9238":"engagement_df_refined[\"weekofyear\"] = engagement_df_refined[\"weekofyear\"].astype(int)\nengagement_df_refined[\"month\"] = engagement_df_refined[\"month\"].astype(int)\nengagement_df_refined[\"days_since\"] = engagement_df_refined[\"days_since\"].astype(int)\nengagement_df_refined[\"dayofweek\"] = engagement_df_refined[\"dayofweek\"].astype(int)","b37bde74":"grouped = engagement_df_refined.groupby(by=[\"lp_id\", \"district_id\"])[\"weekofyear\"].agg([\"min\", \"max\", \"size\", \"nunique\"]).reset_index()\n\ngrouped = grouped.dropna()\n\ngrouped.rename( columns={ \"min\": \"min_week\"\n                        , \"max\": \"max_week\"\n                        , \"size\": \"total_days_used\"\n                        , \"nunique\": \"total_active_weeks\"\n                        }\n               ,inplace=True\n              )\n\ngrouped[\"total_span_in_weeks\"] = grouped[\"max_week\"] - grouped[\"min_week\"] + 1\n\ngrouped[\"lp_id\"] = grouped[\"lp_id\"].astype(int)\ngrouped[\"max_week\"] = grouped[\"max_week\"].astype(int)\ngrouped[\"min_week\"] = grouped[\"min_week\"].astype(int)\n\ngrouped.head(10)","ff540369":"grouped.describe()","42fcf01f":"plt.figure(figsize=(8, 6))\n\nsns.histplot( x=\"total_span_in_weeks\"\n             ,data=grouped\n             )\n\nplt.xlabel(\"total span (in weeks)\")\nplt.xticks(rotation=30)\nplt.show()","ddf51562":"dict_ = {\"freemium\": (grouped[\"total_span_in_weeks\"] == 1).sum()\n        ,\"paid\": (grouped[\"total_span_in_weeks\"] > 1).sum()\n        }\n\ngrouped_free_or_paid = pd.DataFrame.from_dict(dict_, orient=\"index\").reset_index()\ngrouped_free_or_paid.columns = [\"subscription\", \"count\"]\ngrouped_free_or_paid","33026810":"((grouped[\"total_span_in_weeks\"] > 1) &\n (grouped[\"total_days_used\"] > 1)).sum() * 100. \/ (grouped[\"total_span_in_weeks\"] > 1).sum()","d949cd4b":"((grouped[\"total_span_in_weeks\"] == 1) &\n (grouped[\"total_days_used\"] > 1)).sum() * 100. \/ (grouped[\"total_span_in_weeks\"] == 1).sum()","5f1476a4":"fig = px.pie(\n    grouped_free_or_paid, \n    names='subscription', \n    values='count',\n    color_discrete_sequence=px.colors.sequential.Mint,\n    title='Percentage of Subscription Types', \n    width=700,\n    height=500,\n    hole=0.5\n)\nfig.show()","42f7cbf7":"grouped[grouped[\"total_days_used\"] == 1][\"lp_id\"].nunique() * 100. \/ grouped[\"lp_id\"].nunique()","35801263":"plt.figure(figsize=(12, 6))\n\nsns.countplot(x=\"max_week\"\n             ,data=grouped[ grouped[\"total_span_in_weeks\"] == 1 ]\n             )\n\nplt.title(\"Freemium offers vs. week\")\nplt.xlabel(\"week\")\nplt.ylabel(\"freemium count\")\nplt.xticks(rotation=60)\nplt.show()","0fc52109":"g = grouped[grouped[\"total_span_in_weeks\"] == 1]\n\ni = g['total_days_used'].quantile([0.05, 0.25, 0.5, 0.9, 0.95, 0.99, 0.999])\n# j = g['total_days_used'].agg(['min', 'max'])\n\n# pd.concat([i, j], axis=0)\n\n# g.describe()\n\ndf_percentiles = pd.DataFrame(i).reset_index()\ndf_percentiles.rename(columns={\"index\": \"percentile\"}, inplace=True)\n\nplt.figure(figsize=(8, 6))\n\nsns.lineplot(x=\"percentile\"\n            ,y=\"total_days_used\"\n            ,data=df_percentiles)\n\nplt.title(\"Freemium consumer-bases\")\nplt.ylabel(\"days used\")\nplt.show()","f207b0e7":"plt.figure(figsize=(12, 6))\n\nsns.countplot(x=\"min_week\"\n             ,data=grouped[ grouped[\"total_span_in_weeks\"] > 1 ]\n             )\n\nplt.title(\"Paid registration vs. week\")\nplt.xlabel(\"week\")\nplt.ylabel(\"paid registration count\")\nplt.xticks(rotation=60)\nplt.show()","e72e4b9a":"g = grouped[ grouped[\"total_span_in_weeks\"] > 1 ]\ni = g['total_days_used'].quantile([0.01, 0.05, 0.25, 0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.825, 0.8375, 0.85, 0.9, 0.95, 0.99, 0.995, 0.999])\n# j = g['total_days_used'].agg(['min', 'max'])\n\n# pd.concat([i, j], axis=0)\n\ndf_percentiles = pd.DataFrame(i).reset_index()\ndf_percentiles.rename(columns={\"index\": \"percentile\"}, inplace=True)\n\nplt.figure(figsize=(8, 6))\n\nsns.lineplot(x=\"percentile\"\n            ,y=\"total_days_used\"\n            ,data=df_percentiles)\n\nplt.title(\"Paid consumer-bases\")\nplt.ylabel(\"days used\")\nplt.show()","a00c18a3":"g = grouped[ grouped[\"total_span_in_weeks\"] == 1 ]\n\ng_details = pd.merge(g[[\"lp_id\", \"district_id\", \"min_week\", \"total_days_used\"]]\n                    ,engagement_df_refined[[\"lp_id\", \"district_id\", \"weekofyear\", \"pct_access\", \"engagement_index\"]]\n                    ,how=\"inner\"\n                    ,left_on=[\"lp_id\", \"district_id\", \"min_week\"]\n                    ,right_on=[\"lp_id\", \"district_id\", \"weekofyear\"]\n                    )\n\ng_details[\"lp_id\"] = g_details[\"lp_id\"].astype(int)\n\ng_details.head(10)","2551a5de":"g_details.describe()","0956d027":"g_details_agg = g_details.groupby(by=[\"lp_id\", \"district_id\"]).mean().reset_index()\ng_details_agg.head()","34a95a56":"g_details_agg.describe()","cfce627a":"dict_ = {\"inactive\": (g_details_agg[\"pct_access\"] == 0.).sum()\n        ,\"active\": (g_details_agg[\"pct_access\"] > 0.).sum()\n        }\n\ngrouped_freemium = pd.DataFrame.from_dict(dict_, orient=\"index\").reset_index()\ngrouped_freemium.columns = [\"activity type\", \"count\"]\ngrouped_freemium","69353c99":"fig = px.pie(\n    grouped_freemium, \n    names='activity type', \n    values='count',\n    color_discrete_sequence=px.colors.sequential.Mint,\n    title='Percentage of Active Consumer Bases in Freemium', \n    width=700,\n    height=500,\n    hole=0.5\n)\nfig.show()","8ce2857e":"freemium_inactive = g_details_agg[ g_details_agg[\"pct_access\"] == 0. ]\n\nfreemium_inactive.describe()","3491cd48":"(freemium_inactive[\"total_days_used\"] == 1).sum() * 100. \/ freemium_inactive.shape[0]","98dafeb6":"(freemium_inactive[\"total_days_used\"] > 1).sum() * 100. \/ freemium_inactive.shape[0]","93d1b8b7":"freemium_active = g_details_agg[ g_details_agg[\"pct_access\"] > 0.]\n\nfreemium_active.describe()","4358d035":"freemium_active.shape[0] * 100. \/ g_details_agg.shape[0]","73b6f21f":"# features = g_details_agg[(g_details_agg[\"pct_access\"] > 0) & \n#                          (g_details_agg[\"engagement_index\"] > 0)][[\"pct_access\", \"engagement_index\"]].reset_index(drop=True)\n\nfeatures = freemium_active[[  \"total_days_used\"\n                            , \"pct_access\"\n                            , \"engagement_index\"]].reset_index(drop=True)","11b4f6a1":"features.isna().sum()","a0c45db5":"(freemium_active[\"total_days_used\"] == 1).sum() * 100. \/ freemium_active.shape[0]","83aad0f8":"(freemium_active[\"total_days_used\"] > 1).sum() * 100. \/ freemium_active.shape[0]","998b084a":"features = freemium_active[[  \"lp_id\"\n                            , \"district_id\"\n                            , \"total_days_used\"\n                            , \"pct_access\"\n                            , \"engagement_index\"]].reset_index(drop=True)\nfeatures.shape","487630c0":"features.head()","fac4a22f":"scaler = preprocessing.MinMaxScaler()\nfeatures_normal = scaler.fit_transform(features[[\"pct_access\", \"engagement_index\"]])","10af5a43":"pd.DataFrame(features_normal).describe()","6157de5b":"inertia = []\nK = range(1,10)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k).fit(features_normal)\n    kmeanModel.fit(features_normal)\n    inertia.append(kmeanModel.inertia_)","0ca48340":"# Plot the elbow\nplt.plot(K, inertia, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Inertia')\nplt.show()","8af253cf":"kmeans = KMeans(n_clusters=3, random_state=0).fit(features_normal)","e2a8de1e":"labels = pd.DataFrame(kmeans.labels_) #This is where the label output of the KMeans we just ran lives. Make it a dataframe so we can concatenate back to the original data\nlabeledCombs = pd.concat((features,labels),axis=1)\nlabeledCombs = labeledCombs.rename({0:'labels'},axis=1)","ed6e4c12":"features.shape","8f2027b8":"labeledCombs.shape","cd5942c3":"labeledCombs.isna().sum()","7d966e71":"labeledCombs = labeledCombs[ ~(labeledCombs[\"pct_access\"].isna() & \n                               labeledCombs[\"engagement_index\"].isna()\n                              ) \n                           ]\nlabeledCombs.shape","5619e349":"labeledCombs.head()","b796349a":"sns.lmplot( x='pct_access'\n           ,y='engagement_index'\n           ,data=labeledCombs\n           ,hue='labels'\n           ,fit_reg=False)","87420528":"sns.pairplot(labeledCombs, hue='labels')","b14e3f17":"labeledCombs['Constant'] = \"Data\" #This is just to add something constant for the strip\/swarm plots' X axis. Can be anything you want it to be.","8bece734":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\nfig.suptitle(\"pct_access and engagement_index distribution\")\n\nsns.stripplot( x=labeledCombs['Constant']\n              ,y=labeledCombs['pct_access']\n              ,hue=labeledCombs['labels']\n              ,jitter=True\n              ,ax=axes[0]\n             )\n\nsns.stripplot( x=labeledCombs['Constant']\n              ,y=labeledCombs['engagement_index']\n              ,hue=labeledCombs['labels']\n              ,jitter=True\n              ,ax=axes[1]\n            )\n\nfig.tight_layout()\nfig.show()","18af03d5":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\nfig.suptitle(\"pct_access and engagement_index distribution\")\n\nsns.boxplot( x=\"labels\"\n            ,y=\"pct_access\"\n            ,data=labeledCombs\n            ,ax=axes[0]\n           )\n\nsns.boxplot( x=\"labels\"\n            ,y=\"engagement_index\"\n            ,data=labeledCombs\n            ,ax=axes[1]\n           )\n\nfig.tight_layout()\nfig.show()","39595ebc":"labeledCombs.columns","75f47793":"freemium_inactive.columns","6496baad":"grouped_1wk = pd.concat((labeledCombs.drop([\"Constant\"], axis=1)\n                        ,freemium_inactive.drop([\"min_week\", \"weekofyear\"], axis=1))\n                        ,axis=0)\n\ngrouped_1wk.shape","eabb685e":"grouped_1wk.isna().sum()","25ac8957":"labeledCombs[\"labels\"].unique()","6666e75b":"## Returning customer in Group 3 for the inactive bases.\ngrouped_1wk[\"labels\"].fillna( grouped_1wk[\"total_days_used\"].apply( lambda x: 3 if x > 1 else 0)\n                             ,inplace = True\n                            )\n\ngrouped_1wk.describe()","f9577b73":"grouped_1wk[\"labels\"].unique()","364cebf5":"grouped_1wk[((grouped_1wk[\"labels\"].isin([0, 1, 2]) & (grouped_1wk[\"total_days_used\"] > 1)))].describe()","1ad2adfc":"grouped_1wk.loc[((grouped_1wk[\"labels\"].isin([0, 1, 2]) & (grouped_1wk[\"total_days_used\"] > 1))), \"labels\"] = 4","08455be5":"grouped_1wk.describe()","7d3d1337":"grouped = grouped_1wk.groupby([\"labels\"])[\"lp_id\"]\\\n                     .count()\\\n                     .reset_index(name=\"count\")\n\ngrouped[\"groups\"] = grouped[\"labels\"].map({ 0: \"Group 0 (Low Usage, Non-returning Consumers)\"\n                                          ,1: \"Group 1 (Moderate Usage, Non-returning Consumers)\"\n                                          ,2: \"Group 2 (High Usage, Non-returning Consumers)\"\n                                          ,3: \"Group 3 (Inactive yet Returning Consumers)\"\n                                          ,4: \"Group 4 (Active & Returning Consumers)\"\n                                         })\n\ngrouped","47d3846f":"fig = px.pie(\n    grouped, \n    names='groups', \n    values='count',\n    color_discrete_sequence=px.colors.sequential.Mint,\n    title='Percentage of Groups in the Engagement Information Data:', \n    width=700,\n    height=500,\n    hole=0.5\n)\nfig.show()","bc7bff3f":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\nfig.suptitle('Compare Groups: pct_access and engagement_index')\n\naxes[0].set_title(\"pct_access distribution\")\n\nsns.boxplot( x=\"labels\"\n           , y=\"pct_access\"\n           , data=grouped_1wk\n           , palette=\"cubehelix\"\n           , ax=axes[0]\n           )\n\naxes[0].set_xlabel(\"group\")\n# axes[0].set_xticklabels(grouped_1wk[\"labels\"].unique(), rotation=70)\n\naxes[1].set_title(\"engagement_index distribution\")\n\nsns.boxplot( x=\"labels\"\n           , y=\"engagement_index\"\n           , data=grouped_1wk\n           , palette=\"cubehelix\"\n           , ax=axes[1]\n           )\naxes[1].set_xlabel(\"group\")\n# axes[1].set_xticklabels(grouped_1wk[\"labels\"].unique(), rotation=70)\n\nfig.tight_layout()\nfig.show()","0f94bdbf":"grouped_1wk.groupby([\"labels\"])[[\"pct_access\", \"engagement_index\"]].median()","18895a9c":"- Offline or inactive platform for this combination (pct_access, engagement_index) = (NaN, NaN). Let's impute such entries with 0.0","95816b28":"- **Remark.** ~53.2% Freemium consumer-bases appeared to be inactive or non-responsive.","a6f67123":"## Summary","9d110c5f":"- In the following scatterplot, we can observe a good number of points with pct_access = 0.0 and engagement_index > 0.0. This is counterintuitive because how can a pageload event occur when there are no students online (note that auto pageload events can be scheduled too but those are not our targeted rows)? But it may also happen that the values are too infinitesimal to be captured within 2 decimal places. Therefore, we will focus on the relationships.\n\n    - (pct_access, engagement_index): (0.0, > 0.0) is a valid combination.\n    - (pct_access, engagement_index): (> 0.0, 0.0) is an invalid combination.","5620f942":"- **Remark:** The district-wise coverage remained almost same over various months of the year. It started off with 216 districts in January and then continues to grow by a few districts at each month, thus ended up with 233 districts in November through December.","218c55d1":"- Still some rows available for LP_ID None (even after removing those inactive platforms). These will be imputed after cleaning the data by checking the upper and lower bounds.","19607e2e":"- **Groups.** pct_access looks like the key differentiating factor. A total of 3 groups found.\n\n    - Group 0: Low pct_access. \n    \n    - Group 1: Medium pct_access. \n    \n    - Group 2: High pct_access. \n    \n- Group 0 performed very poorly with respect to the usage pattern. Therefore, some opportunity for expansion may lie in the consumer-bases belonging to Group 1 and Group 2. Later on, we'll strip out the returning users from all these groups and form a new Group for **Active & Returning** consumer-bases.","7448dc8f":"### Active (lp, district) combinations\n\n- ~46.79% of the Freemium consumer-bases showed an active usage habit.\n\n- Let's group those first based on the usage pattern, i.e., pct_access and engagement_index.","97320a8c":"- ~98% learning platforms offered 1-week long freemium subscriptions across all 233 districts. ","7fdc5c38":"- How many rows fail to satisfy the lower_bound of the engagement_index? We should remove those.","959ae7ec":"**engagement_df_refined cleaning done.**","21850553":"## Overview \n\nThis notebook provides a high-level view of the digital learning state in 2020. Specifically, the following areas are being explored:\n\n- **Evolution.** \n\n  The evolution of various types of Learning Platforms (e.g., newly-launched, discontinued etc.) and their coverage over the districts with time.\n  \n- **Opportunity Analysis.** \n\n  After delving into the data, we classify the Learning Platforms into Freemium and Paid types. Later on, the Freemium subscription is categorized into several groups and their opportunities for expansion are unveiled.","25515737":"Let's get ready for the next part of our analysis.","82effdb5":"- **Remark:** Discontinued Learning Platforms are those which stopped providing their service any further.\n\n    - In February, 76 learning platforms from January stopped providing their service. The increasing trend in the discontinuation goes on till the end of year. Note that the number of discontinued platforms tends to get very high after September (the end of financial year); approximately 2X - 2.5X jump in October through December. The maximum number of Discontinued Platforms is observed in December with a value of 2982.","640b3ae8":"- pct_access is defined when any of the following holds true\n\n    - both the $ total\\_online\\_students $ and $ total\\_enrolled\\_students $ are known.\n    \n    - both the $ total\\_online\\_students $ and $ total\\_enrolled\\_students $ are unknown. Mathematically this value is NaN; however, for this specific context, we can define it as 0.0. This is expected for a newly launched platform.\n    \n    - $ total\\_enrolled\\_students $ is known. The value of $ total\\_online\\_students $ can be inferred from the $ total\\_pageload\\_events $. If the latter is 0.0 or NaN, the former will assume the same value; otherwise, we can apply regression to determine this value.\n    \nSimilar notions apply for engagement_index.","afa76372":"- **Remarks:**\n\n    - When total_span_in_weeks > 1, the consumer bases exhibit a returning habit by coming back to the learning platform after the first day.\n\n    - The number of days used follows an exponential pattern. It starts off with a minimum of 2 days, grows to a median of 12 days, crosses 100 days at about 83rd percentile and eventually touches 366 days at about 99.9th percentile. ","f8ff4c49":"**Group performance analysis (ref. following code cell):**\n\n- Group 2 clearly stands out by an engaged user-base (median pct_access 1.975 and enagement_index 44.95).\n\n- Group 1 comes next with a relatively lower engaged user-base (median pct_access 0.33 and enagement_index 5.79).\n\n- Group 4 stays third in the list with engaged & returning consumers, however, median pct_access 0.02 and enagement_index 0.715 (pretty low usage)\n\n- Group 3 is a special one with returning consumers but zero engagement.","004a6bea":"### Sustained Platforms","17d56cc4":"- Note that every student must load at least a page to contribute to the engagement_index. Therefore, we need to check whether the engagement_index given satisfies this lower bound.","02500782":"- **Remark:** Unique Learning Platforms (ULP) are those which don't have any twin star.\n\n    - January got started with 3857 learning platforms. The number of unique platforms  gradually increased linearly till August; then entered the saturation region where the growth is extremely low or not too obvious compared to the first half of the year. \n    \n    - 8583 is the final count of Unique Learning Platforms at Dec, 2020.","ce86d0c5":"Let's see the percentage of NaN values in the data. We'll carry out the cleaning and imputation on these in the subsequent lines of code.","8a19093a":"- **Freemium Active.** Returning habit of active consumer bases:\n\n    - 93.47% didn't return after the first day of usage.\n    \n    - 6.52% used the freemium version for multiple days, therefore there is a strong possibility that they found it useful.","1d2aac61":"- Lets impute these combinations (pct_access, engagement_index): (value, NaN) and (NaN, value) by inferring from the known one.","4556e661":"- Lets see whether the opposite holds true. That is, pct_access satisfies its upper bound.","b2af9601":"### Unique Learning Platforms\n\nNow that the engagement data has been imputed and cleaned, let's explore the evolution of the Learning Platforms over the months in 2020. Let's look through the number of Unique Learning Platforms by month.","506e1673":"- Invalid combinations are not found (see the above line of code).","95f89a1a":"### Inactive (lp, district) combinations\n\nLet's group the inactive consumer-bases based on the returning habit.","f734beed":"- Let's impute those undefined or NaN learning platforms.","953e770b":"## Opportunity Analysis (Freemium):\n\nThe next part of this notebook will provide a glimpse into the Freemium subscription only for brevity.\n\n- **Key Concepts.** Identify prospective consumer-bases or (lp, district) combinations by the following aspects:\n\n    - Returning consumers. Those who viewed the course for multiple days. If a user gets back to the freemium version for several days, there is a strong chance that he\/she found it useful.\n    \n    - Engaged consumers. Those with high access and engagement to the offered course. Sometimes it may happen that a user explored the freemium version in a single day for a significant amount of time (maybe on a weekend or a holiday).","2f46af38":"### Freemium subscription:\n\n- What percentage of Learning Platforms offered Freemium subscriptions?\n\n- Did the offered weeks of Freemium exhibit any trend?\n\n- How did the percentiles of days used evolve for the Freemium version?","b62ebcac":"- All returning consumer bases with pct_access > 0.","76ebd0b5":"- No platform active for this combination (pct_access == 0.0 & engagement_index == NaN)","1ae8f4dd":"- **Freemium Inactive Returning habit.**\n\n    - ~94.24% didn't return after using the freemium version for 1 day.\n    \n    - ~5.76% used the freemium version for multiple days; seems they found it useful.","80f70669":"### Helpful links:\n\n- charting: https:\/\/www.kaggle.com\/niteshyadav3103\/eda-e-commerce-shipping-data\n- multiplot: https:\/\/dev.to\/thalesbruno\/subplotting-with-matplotlib-and-seaborn-5ei8\n- parsing: https:\/\/www.kaggle.com\/girishkumarsahu\/learnplatform-covid-19-impact\n- Percentiles plot: https:\/\/stackoverflow.com\/questions\/47503718\/plot-percentiles-using-matplotlib\n- closest value: https:\/\/stackoverflow.com\/questions\/30112202\/how-do-i-find-the-closest-values-in-a-pandas-series-to-an-input-number\n- fillna with groupby: https:\/\/stackoverflow.com\/questions\/46391128\/pandas-fillna-using-groupby\n- most frequent value: https:\/\/stackoverflow.com\/questions\/15138973\/how-to-get-the-number-of-the-most-frequent-value-in-a-column\n- ref previous row: https:\/\/stackoverflow.com\/questions\/23333786\/reference-values-in-the-previous-row-with-map-or-apply\n- kmeans random state: https:\/\/stats.stackexchange.com\/questions\/224759\/how-to-avoid-k-means-assigning-different-labels-on-different-run\n- dataframe from dict: https:\/\/stackoverflow.com\/questions\/18837262\/convert-python-dict-into-a-dataframe\n- others: https:\/\/online.stat.psu.edu\/stat200\/lesson\/6\/6.4","cc457fba":"- **Remark:** Sustained Learning Platforms are those which carry forward the previously seen learning platforms.\n\n    - Example: In February, 3781 Learning Platforms from January were retained. This growth continued up until September (thus, reaching the peak 6689 LPs) and then gradually followed a declining trend in the final 3 months of the year. Note that, September is the end of financial year in the U.S. \n\n    - The most common number of Sustained Learning Platforms stayed close to 5500 throught the year.\n    \n    - We haven't seen any data in December 2019, that is, the month before January 2020. Therefore, it can be regarded as N\/A. But for the sake of simplicity, we filled it with 0.","728f169e":"- **Freemium consumer-base Statistics.**\n\n    - pct_access: ranges between 0.0% and 7.5%. More than 50% of the consumer-bases appear to be inactive or non-responsive.\n    \n    - engagement_index: ranges between 0.0 and 1451.36. More than 75% of the consumer-bases show extremely low engagement (< 1.0)\n    \n- Let's split the freemium consumer bases into 2 groups:\n\n    - Inactive bases. (lp_id, district_id) with pct_access = 0.\n    \n    - Active bases. (lp_id, district_id) with pct_access > 0.","1e9d537b":"- **Remark:** The offered-week shows a periodic trend for the 1-week long freemium subscription. It reached the first peak at about March 2021 for a small time span only (~3 weeks).","3a619fb9":"### Freemium: Clustering by Access Pattern","6e838307":"Drop upper_bound and lower_bound columns...","b4d07d3e":"- how many of the engagement_index satisfies the lower_bound?","01d64d0e":"### Cleaning\n\nGet rid of all entries which fail to satify the following:\n\n- **engagement_index lower bound.** Note that, every student must load at least a page to contribute to the engagement_index. Therefore, we need to check whether the engagement_index satisfies its lower bound for a specific entry.\n\n- **pct_access upper bound.** Similar logic suggests us to verify whether pct_access satisfies its upper bound or not in a specific entry.","09f3af73":"**Remarks:**\n\n- 70.4% Paid subscriptions. All of those have returning users.\n\n- 29.6% Freemium subscriptions, lasted for 1 week only. ~6.12% of the freemium consumer bases showed returning habit by coming back to the Learning Platform after the first day .","244e5333":"442 rows fail to satisfy the upper bound of pct_access. Let's drop such entries.","cb7fdc41":"- **Remark:** This plot suggest us two subscription categories: Freemium and Paid. The Freemium subscription is represented by the mode of the graph - those lasting for 1-week only.","484f0605":"### Premium (or Paid) subscription:\n\n- How did the registration of consumer bases evolve over time?\n\n- How did the percentiles of days used evolve for the Paid subscription?","cf20819d":"- Let's see the unique values retained before and after the imputation and cleaning.","6e796dbf":"### Imputation\n\n- **Basic Intuition:** Note that, if the pct_access > 0.0 then the engagement_index > 0.0 too. Because we cannot expect too see a pageload when there are no online students.\n\n- **Inactive Learning Platforms:** Let's impute all those entries with 0.0\n\n- **engagement_index = NaN and pct_access != NaN:** Such entries can be filled with pct_access * 10.0, if pct_access is not NaN and greater than 0.0, as each student online is supposed to load a page at least. A more complex approach to determine this is regression.\n\n- **pct_access = NaN and engagement_index != NaN:** Such entries can be filled with engagement_index \/ 10.0, if engagement_index is not NaN and greater than 0.0. Bound the calculated value by 100.0, if exceeded.\n\n- **lp_id NaN and (pct_access, engagement_index) not NaN:** Fill with 0 (Assume, Misc. LP).","1b348f25":"- **Remark:** Newly-launched Learning Platforms (NLP) are those which got a fresh start in providing the digital learning service.\n\n    - In Februrary, 1832 learning platforms got registered; this is the peak of newly-launched ones. However, no specific growth or decline had been manifested later on. Other than a few bounces (~500 platforms), the newly-launched got bounded by ~250 platforms over various months of the year.","ff916dd6":"- **Remark:** The paid registration count remained very high at the initial 2 weeks and then gradually showed a diminishing trend with the approach of the middle of the year.","e14889a8":"### District Coverage\n\nLet's explore the district-wise coverage in 2020.","2d4090cb":"- 1171702 rows fail to satisfy the lower bound of the engagement_index. Let's get rid of those failed ones.","2d390ec2":"## Freemium vs. Paid subscriptions\n\nThis section groups the consumer bases and categorizes those by the duration of the offered weeks. Then it explores the returning habit of the categorized consumers.","fa3f174d":"- We have found some valid yet counter-intuitive combinations above.","342cc1d1":"### Newly-launched Learning Platforms","8d10b6b8":"Label the sequence of days and explore the skew of pct_access and engagement_index.","56b96c7f":"### Discontinued Learning Platforms","4534b7d4":"- **Which groups can be targeted for a Paid subscription ?**\n\n- Prospective target: 100 - 92.4 = 7.6%\n\n    - Returning target: 3.07 + 3.05 = 6.12%\n\n    - Non-returning yet engaged = 1.47 + 0.0245 = 1.4945%","1135783b":"- **Remark:** The percentiles curve shows a sharp step-wise increase at the very end, at the ~94th percentile it rose to 2 days and finally (after the 99th) it took a sharp turn to 3 or more days.","72f286aa":"### Engagement data\n\nThis section performs the loading, cleaning and imputation of the engagement data. ","16aa5ac7":"- **Inactive platform.** A platform is inactive if \n    \n    -  (pct_access, engagement_index) is (0.0, 0.0): No online students; hence no page load events.\n    \n    -  (pct_access, engagement_index) is (0.0, NaN): In case when the pct_access is 0.0 for no online students, the total page load events may be unknown causing the engagement_index to be NaN. Such combination may appear because of some mismanagement in data collection.\n    \n    -  (pct_access, engagement_index) is (NaN, 0.0): This combination should not occur in practice because the total page load events is a multiple of the online students available; therefore, if the latter is NaN, the former must also be NaN. Such combination may still appear because of some mismanagement in data collection.\n    \n    -  (pct_access, engagement_index) is (NaN, NaN).","fd53862e":"### Definition\n\nLet's drill down on the definition and implication of values in the engagement data.\n\n- $$ pct\\_access = \\frac {total\\_online\\_students} {total\\_enrolled\\_students} $$\n\n- $$ engagement\\_index = \\frac {total\\_pageload\\_events} {total\\_enrolled\\_students\\_in\\_thousands} $$"}}