{"cell_type":{"65a86c24":"code","0ed22cc3":"code","8dd4386b":"code","e52d4ecf":"code","9490b868":"code","c7c2c202":"code","6d5d8c8d":"code","751e5cba":"code","d0468771":"code","c6f21e14":"code","85df07ef":"code","81a2baf8":"code","1c83677c":"code","d9e63000":"code","7454c1ee":"code","ff63d10e":"code","b74f160f":"code","f0ed06a8":"code","e053b247":"code","f08cfb99":"code","06449c41":"code","512de5fc":"code","dcf31481":"markdown","9a01dce2":"markdown","605f6fd6":"markdown","03cacb16":"markdown","bba00fe4":"markdown","bf10cf8f":"markdown","82830503":"markdown","ecada968":"markdown","c572e744":"markdown"},"source":{"65a86c24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ed22cc3":"#!pip install graphviz","8dd4386b":"#!pip install folium","e52d4ecf":"from time import time\ndef function_performance_decorator(function):\n  def wrapper_function(*args, **kwargs):\n    t1 = time()\n    result = function(*args, **kwargs)\n    t2 = time()\n    print(f'It took {t2-t1} ms to run {function.__name__} function')\n    return result\n  return wrapper_function","9490b868":"#read data from nodes.csv file\n@function_performance_decorator\ndef read_data_from_csv():\n    nodes_df = pd.read_csv(\"\/kaggle\/input\/nodes-data\/nodes.csv\")\n    return nodes_df\n\nnodes = read_data_from_csv()\n","c7c2c202":"#Create map object \nimport folium\nimport folium.plugins\n\n#baseline map input\nbaseline_lat = 41.8781\nbaseline_long = -87.6298\nbaseline_zoom_start = 14\nbaseline_map_height = 450\nbaseline_map_width = 900\n\n\n@function_performance_decorator\n#plot basic folium map\ndef baseline_map(lat, long):\n  map = folium.Map(location=[lat, long], \n                    zoom_start=baseline_zoom_start, \n                    #width = baseline_map_width, \n                    #height=baseline_map_height, \n                    control_scale=True)\n  return map\n\n\n#Add scroll zoom toggler to the baseline folium map\n@function_performance_decorator\ndef map_with_scroll_zoom_toggler():\n    map = baseline_map(baseline_lat, baseline_long)\n    #mini map\n    mini_map = folium.plugins.MiniMap(toggle_display = True)\n    map.add_child(mini_map)\n    #zoom toggler\n    folium.plugins.ScrollZoomToggler().add_to(map)\n    return map      \n\n\n#plot node on top of map_with_scroll_zoom_toggler\n@function_performance_decorator\ndef plot_nodes_to_map(df):\n  map = map_with_scroll_zoom_toggler()\n  df.apply(lambda row: folium.Marker(location=[row[\"lat\"], row[\"lon\"]], \n                                                icon =folium.Icon(color='red', icon='cloud'),\n                                                tooltip = \"click to view node details\",\n                                                popup = f'<strong>Node Address: {row[\"address\"]} Node ID: {row[\"node_id\"]}<\/strong>'    \n                                                ).add_to(map), axis=1)\n  return map\n\n\n#display map\nmap = plot_nodes_to_map(nodes)\nmap","6d5d8c8d":"import dask\nimport dask.dataframe as dd","751e5cba":"jan12_feb11_data = \"..\/input\/aot200112to200211\/data.csv\"\nfeb1_feb29_data = \"..\/input\/aot200201to200229\/data.csv\"\nmarch1_march31_data = \"..\/input\/aot200301to200331\"\ndata = [jan12_feb11_data, feb1_feb29_data, march1_march31_data]","d0468771":"@function_performance_decorator\ndef read_file_using_dask(file):\n    return dd.read_csv(file)\ndask_df = read_file_using_dask(data)\ndask_df.describe","c6f21e14":"type(dask_df)","85df07ef":"dask.visualize(read_file_using_dask(data))","81a2baf8":"@function_performance_decorator\ndef read_file_using_pandas(file):\n    return pd.read_csv(file)\n","1c83677c":"#pandas_df = read_file_using_pandas(jan12_feb11_data)","d9e63000":"#read_file_using_pandas(jan12_feb11_data)","7454c1ee":"\n\n# \"001e0610ba46\", \"001e06115382\", \"001e06107e5d\", \"001e06113cf1\", \"001e0611536c\"\nloop_nodes = [\"001e06115379\",\"001e0610ba46\", \"001e06115382\", \"001e06107e5d\", \"001e06113cf1\", \"001e0611536c\"]\n    \ndef filter_loop_df(df):\n    loop_df = (df.loc[df[\"node_id\"].isin(loop_nodes)])\n    # filter by sensor \n    loop_df = loop_df.loc[loop_df[\"sensor\"]==\"tmp112\"]\n    return loop_df","ff63d10e":"loop_df = filter_loop_df(dask_df)","b74f160f":"loop_df.head(500)","f0ed06a8":"from dask.diagnostics import ProgressBar\nwith ProgressBar():\n    #use persist only if you have distribute RAM\n    #loop_df = loop_df.persist()\n    #convert to regular pandas df\n    loop_df = loop_df.compute()\n\n","e053b247":"loop_df.describe()","f08cfb99":"loop_df.info","06449c41":"loop_df.memory_usage(deep=True)","512de5fc":"1627408+15460376+14036394+13222690+12815838+13832968+12584087+12790524","dcf31481":"# **Dask vs Pandas**","9a01dce2":"# Plot Nodes their locations","605f6fd6":"A Dask DataFrame is a large parallel DataFrame composed of many smaller Pandas DataFrames, split along the index. ","03cacb16":"# QSN 1: What was the temprature of  Chicago Loop last week? \n\nfine more about \"tmp112\" here: https:\/\/github.com\/waggle-sensor\/sensors\/raw\/master\/sensors\/datasheets\/tmp112.pdf","bba00fe4":"All the nodes in nodes.csv are located in Chicago. To access other nodes information, visit: https:\/\/aot-file-browser.plenar.io\/data-sets","bf10cf8f":"Find more about Array Of Things project\nhttps:\/\/arrayofthings.github.io\/\n\n1.   APIs: Nodes: https:\/\/api.arrayofthings.org\/api\/nodes\n2.   observations: https:\/\/api.arrayofthings.org\/api\/observations \n3.   Sensors: https:\/\/api.arrayofthings.org\/api\/sensors\n4.   Projects: https:\/\/api.arrayofthings.org\/api\/projects\n\nURL to access historical datasets:\n\nhttps:\/\/aot-file-browser.plenar.io\/data-sets\n\n\nURL to previous notebooks:\n\n*      Project2: https:\/\/colab.research.google.com\/drive\/1dNAsJmnnbD4PBh6HsOr7OHQUQ6Eo_hAK?usp=sharing\n*      Project1: https:\/\/colab.research.google.com\/drive\/1lwDPTXXLOwt2EcsDHvfmzS89BJIsJFXn?usp=sharing\n","82830503":"**Import dataset using pandas**","ecada968":"Memory usage is less than 1 GB","c572e744":"**Import dataset using dask**"}}