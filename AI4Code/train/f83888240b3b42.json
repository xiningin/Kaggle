{"cell_type":{"db552245":"code","899e3037":"code","c5767d97":"code","75c78ecc":"code","238a4e46":"code","4ca80c8b":"code","8d62c239":"code","f50b9147":"code","221d4dfa":"markdown","7c1af20a":"markdown","1434e912":"markdown","dc4bce11":"markdown","6a1ba6b5":"markdown","ecb1109c":"markdown","e4b0d5b8":"markdown","8c58e8d2":"markdown","f06daf16":"markdown","a88bc4e6":"markdown"},"source":{"db552245":"import os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\n\nwarnings.filterwarnings('ignore')\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\nprint('-'*100)\nprint(f'Train set dimension: {train.shape} - (rows, columns)')\nprint(f'Test set dimension: {test.shape} - (rows, columns)')\nprint('-'*100)\nprint(f'Independent features: {[i for i in test.columns.values]}')\nprint(f'Independent feature: {list(set(train.columns.values) - set(test.columns.values))}')\nprint('-'*100)\nprint(train.info())\nprint('-'*100)\nprint(test.info())\nprint('-'*100)","899e3037":"# Passenger ID and Passenger Name, Ticket and Cabin are not required.\npassengerids = test.PassengerId\ntrain.drop(['PassengerId'], axis='columns', inplace=True)\ntest.drop(['PassengerId'], axis='columns', inplace=True)\ntrain.drop(['Name'], axis='columns', inplace=True)\ntest.drop(['Name'], axis='columns', inplace=True)\ntrain.drop(['Ticket'], axis='columns', inplace=True)\ntest.drop(['Ticket'], axis='columns', inplace=True)\ntrain.drop(['Cabin'], axis='columns', inplace=True)\ntest.drop(['Cabin'], axis='columns', inplace=True)\n\n# Changing sex to categorical variable\ntrain['Sex'].replace({\"male\":1 , \"female\":0}, inplace=True)\ntest['Sex'].replace({\"male\":1 , \"female\":0}, inplace=True)\n\n# Changing Embarked to categorical variable\ntrain.Embarked = train.Embarked.replace(np.nan, 'N')\ntrain['Embarked'].replace({\"S\":0 , \"C\":1, 'Q':2, 'N': 3}, inplace=True)\ntest['Embarked'].replace({\"S\":0 , \"C\":1, 'Q':2, 'N': 3}, inplace=True)\n\n# Filling missing values with average age\ntrain['Age'].fillna(train['Age'].mean(), inplace=True)\ntest['Age'].fillna(test['Age'].mean(), inplace=True)","c5767d97":"X = train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\ny = train['Survived']","75c78ecc":"depth_values = [i for i in range(1,5)]\nestimator = [i for i in range(10, 100, 10)]\nmetric = ['logloss', 'auc', 'mae']\nparams = {'max_depth': depth_values,'n_estimators': estimator, 'eval_metric': metric}\n\nxgb = xgb.XGBClassifier()\nclf = GridSearchCV(xgb, params, cv=5, scoring='roc_auc', return_train_score=True, n_jobs=-1, verbose=5)\nclf.fit(X, y)\n\nbest_score = clf.best_score_\nbest_params = clf.best_params_","238a4e46":"print(f'Best Score: {round(best_score*100, 2)}%')\nprint(f'Best Params: {best_params}')","4ca80c8b":"import xgboost as xgb\n\nmodel = xgb.XGBClassifier(\n                            max_depth = best_params.get('max_depth'), \n                            n_estimators = best_params.get('n_estimators'),\n                            eval_metric = best_params.get('eval_metric')\n                        )\n\nmodel.fit(X, y)\npredictions = model.predict(test)","8d62c239":"from xgboost import plot_tree\n\nfor i in range(4):\n    fig, ax = plt.subplots(figsize=(10, 10))\n    xgb.plot_tree(model, num_trees=i, ax=ax)\n    plt.show()","f50b9147":"test['Survived'] = predictions\ntest['PassengerId'] = passengerids\n\noutput = test[['PassengerId', 'Survived']]\noutput.to_csv('titanic.csv', index=False) ","221d4dfa":"# <center><u>Fitting and Predicting Based on Best Parameters<\/u><\/center>","7c1af20a":"<center><h1><u>Prediction based on Gradient Boosted Decision Trees<\/u><\/h1><\/center>\n<img src=\"https:\/\/dzone.com\/storage\/temp\/13069534-gradient-boosting-process.png\" width=\"700\" height=\"600\">","1434e912":"# <center><u>Saving the Output<\/u><\/center>","dc4bce11":"# <center><u>Based on Grid Search Cross Validation Finding Best Parameters<\/u><\/center>","6a1ba6b5":"<center><u><h1>About<\/h1><\/u><\/center>\nThe RMS Titanic was a British passenger liner that sank in the North Atlantic Ocean in the early morning hours of 15 April 1912, after it collided with an iceberg during its maiden voyage from Southampton to New York City. There were an estimated 2,224 passengers and crew aboard the ship, and more than 1,500 died, making it one of the deadliest commercial peacetime maritime disasters in modern history. The RMS Titanic was the largest ship afloat at the time it entered service and was the second of three Olympic-class ocean liners operated by the White Star Line. The Titanic was built by the Harland and Wolff shipyard in Belfast. Thomas Andrews, her architect, died in the disaster. RMS Titanic was the largest ship afloat at the time she entered service and was the second of three Olympic-class ocean liners operated by the White Star Line.<br>\n\n<center><h1><u>Series of Events<\/u><\/h1><\/center>\n<img src=\"https:\/\/cdn.britannica.com\/68\/185468-050-C0D53622\/Titanic-iceberg-British-15-1912.jpg\" class=\"center\"><br>\n\n<center><h1><u>London Herald<\/u><\/h1><\/center>\n<img src=\"https:\/\/i.pinimg.com\/474x\/1a\/64\/88\/1a6488954fc80399870c0c0be128b3d5.jpg\" class=\"center\"><br>\n\n## <u>Problem Statement<\/u>: Based on independent features predict whether a passenger on the titanic would have survived or not.<br><u>Dataset<\/u>: https:\/\/www.kaggle.com\/c\/titanic\/data","ecb1109c":"Since all the data points lie within a defined range, data standardization is not required in this case.","e4b0d5b8":"# <center><u>Data Reading and Preprocessing","8c58e8d2":"# <center><u>Segregating Independent and Dependent Features<\/u><\/center>","f06daf16":"<img src=\"https:\/\/www.vmtocloud.com\/wp-content\/uploads\/2015\/05\/thumb.jpg\" width=\"200\" height=\"200\">\n<center><h4>Please upvote if you liked my work<\/h4><\/center>","a88bc4e6":"# <center><u>Plotting First 5 Trees<\/u><\/center>"}}