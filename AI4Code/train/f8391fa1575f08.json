{"cell_type":{"88fac81d":"code","7d363f8f":"code","734afcb1":"code","1b932199":"code","c3226731":"code","239dff81":"code","655975f9":"code","0d9d5a51":"code","f9d0c1ac":"code","a8656187":"code","57d31f5b":"code","4bef7bb3":"code","6dc5c8a7":"code","f7d0c21b":"code","1035307c":"code","ee31ba5e":"code","2cb8a33d":"code","1c674fe8":"code","8e759d36":"code","1c59cac6":"code","160cbe4f":"code","30624380":"code","08942a67":"code","a084df58":"code","02307b4b":"code","a9bddf56":"code","8eb6bef5":"code","900c950c":"code","998e60e8":"code","188678e3":"code","a57d061b":"code","225a8f22":"code","a786542a":"code","56c1e18c":"code","774e87ed":"code","8d5656c2":"code","daeb4607":"code","05dbafaf":"code","8b33c44b":"code","e8ef5d09":"code","86bff10b":"code","cd4ffda6":"code","bbd671af":"code","1b73b1bb":"code","ca197da5":"code","97a99ab2":"code","77193707":"code","b6dc299d":"code","9a9af5ec":"code","584f13a8":"markdown","f801ad1a":"markdown","cceaeab7":"markdown","46a16032":"markdown","df64f97b":"markdown","e5d8e0d9":"markdown","ed2489b8":"markdown","666e8ba8":"markdown","ab02d6c2":"markdown","73943c50":"markdown","76a8ba05":"markdown","205aece2":"markdown","b8a1f9a6":"markdown","fbe7dfa0":"markdown","928ba134":"markdown","451d2792":"markdown","83337c68":"markdown","d4d96afc":"markdown","a4ac8a29":"markdown","d2f09006":"markdown","fe585708":"markdown","1dee1828":"markdown","9a6532b5":"markdown","5330374e":"markdown","f1291935":"markdown","7b5acdc4":"markdown","a971bab6":"markdown","0f79e02a":"markdown","ff5a55e9":"markdown","5e0117be":"markdown","dafdc499":"markdown","51a1c85a":"markdown","f62f597a":"markdown","e66600fd":"markdown","0490c02c":"markdown","0bcbafb5":"markdown","9220aae7":"markdown","f73b4eaf":"markdown","f72da264":"markdown","1b37ff96":"markdown","eadd2833":"markdown","ada9f5d4":"markdown","912f63cd":"markdown","74575032":"markdown","0d18cddc":"markdown"},"source":{"88fac81d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d363f8f":"dataset = pd.read_csv('..\/input\/us-accidents\/US_Accidents_Dec20_Updated.csv')","734afcb1":"dataset.columns","1b932199":"dataset","c3226731":"dataset.shape","239dff81":"dataset.describe","655975f9":"dataset.describe()","0d9d5a51":"dataset.info()","f9d0c1ac":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnumeric_df = dataset.select_dtypes(include=numerics)\nlen(numeric_df.columns)","a8656187":"missing_values_percent_per_col = (dataset.isna().sum().sort_values(ascending = False) \/ len(dataset)) * 100\nmissing_values_percent_per_col","57d31f5b":"import seaborn as sns\nsns.set_style(\"darkgrid\")","4bef7bb3":"import matplotlib.pyplot as plt\nplt.figure(figsize=(20,10))\nmissing_values_percent_per_col[missing_values_percent_per_col != 0].plot.barh(color = 'cornflowerblue')\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=20)\nplt.xlabel('Percentage of missing values', fontsize=20)\nplt.title('Missing values percentage per column', fontsize = 20)\n\nplt.show()\n","6dc5c8a7":"dataset.columns","f7d0c21b":"dataset.City","1035307c":"cities = dataset.City.unique()\nlen(cities)","ee31ba5e":"cities_by_accidents = dataset.City.value_counts()\ncities_by_accidents","2cb8a33d":"cities_by_accidents[:20]","1c674fe8":"'New York' in dataset.City","8e759d36":"'NY' in dataset.State","1c59cac6":"plt.figure(figsize=(20,10))\ncities_by_accidents[:20].plot.barh(color = 'cornflowerblue')\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=20)\nplt.xlabel('Number of accidents', fontsize=20)\nplt.title('Top 20 cities with major accidents in the US', fontsize = 20)\n\nplt.show()","160cbe4f":"plt.figure(figsize=(20,10))\nsns.histplot(cities_by_accidents, log_scale = True, color = 'cornflowerblue')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('Number of accidents on log scale', fontsize=20)\nplt.ylabel('Number of cites', fontsize=20)\n\nplt.title('Distribution of accidents in the cities of the US', fontsize = 20)\n\nplt.show()","30624380":"high_accident_cities = cities_by_accidents[cities_by_accidents >= 1000]\nlow_accident_cities = cities_by_accidents[cities_by_accidents < 1000]","08942a67":"(len(high_accident_cities) \/ len(cities)) * 100","a084df58":"cities_by_accidents[cities_by_accidents ==1]","02307b4b":"dataset.Start_Time","a9bddf56":"dataset.Start_Time = pd.to_datetime(dataset.Start_Time)","8eb6bef5":"dataset.Start_Time[0]","900c950c":"plt.figure(figsize=(20,10))\nsns.histplot(data = dataset.Start_Time.dt.hour, stat = 'density', bins=24, color = 'seagreen')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('24 hours', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents over a period of 24 hours ', fontsize = 20)\n\nplt.show()","998e60e8":"plt.figure(figsize=(10,5))\nsns.histplot(data = dataset.Start_Time.dt.dayofweek,stat = 'density', bins=7, color = 'seagreen')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('Days of week', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents over a week ', fontsize = 20)\n\nplt.show()","188678e3":"weekends_start_time = dataset.Start_Time[dataset.Start_Time.dt.dayofweek >= 5]\nplt.figure(figsize=(20,5))\nplt.subplot(1, 2, 1)\nsns.histplot(data = weekends_start_time.dt.hour, stat = 'density', bins=24, color = 'indigo')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('24 hours of weekends', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents by hour for Weekends ', fontsize = 20)\n\n# subplot method is used to plot the two graphs side by side\n\nweekdays_start_time = dataset.Start_Time[dataset.Start_Time.dt.dayofweek <= 4]\n\nplt.subplot(1, 2, 2)\nsns.histplot(data = weekdays_start_time.dt.hour, stat = 'density', bins=24, color = 'seagreen')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('24 hours of weekdays', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents by hour for Weekdays ', fontsize = 20)\n\nplt.show()","a57d061b":"plt.figure(figsize=(15,8))\nsns.histplot(data = dataset.Start_Time.dt.month, stat = 'density', bins=12, color = 'indigo')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('12 Months', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents for Months ', fontsize = 20)\n\nplt.show()","225a8f22":"dataset_2016 = dataset[dataset.Start_Time.dt.year == 2016]\ndataset_2017 = dataset[dataset.Start_Time.dt.year == 2017]\ndataset_2018 = dataset[dataset.Start_Time.dt.year == 2018]\ndataset_2019 = dataset[dataset.Start_Time.dt.year == 2019]\ndataset_2020 = dataset[dataset.Start_Time.dt.year == 2020]","a786542a":"plt.figure(figsize=(20,15))\nplt.subplot(3, 2, 1)                            # To put more than one plot in a cell\nsns.histplot(data = dataset_2016.Start_Time.dt.month, stat = 'density', bins=12, color = 'indigo')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('Months', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents for 2016 ', fontsize = 20)\n\n# subplot method is used to plot the two graphs side by side\n\nplt.subplot(3, 2, 2)\nsns.histplot(data = dataset_2017.Start_Time.dt.month, stat = 'density', bins=12, color = 'seagreen')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('Months', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents for 2017 ', fontsize = 20)\n\nplt.subplot(3, 2, 3)\nsns.histplot(data = dataset_2018.Start_Time.dt.month, stat = 'density', bins=12, color = 'seagreen')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('Months', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents for 2018 ', fontsize = 20)\n\nplt.subplot(3, 2, 4)\nsns.histplot(data = dataset_2019.Start_Time.dt.month, stat = 'density', bins=12, color = 'seagreen')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('Months', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents for 2019 ', fontsize = 20)\n\nplt.subplot(3, 2, 5)\nsns.histplot(data = dataset_2020.Start_Time.dt.month, stat = 'density', bins=12, color = 'indigo')\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\nplt.xlabel('Months', fontsize=20)\nplt.ylabel('Density of accidents', fontsize=20)\n\nplt.title('Distribution of accidents for 2020 ', fontsize = 20)\n\n\nplt.tight_layout()       # to adjust all the plots in such a way that they do not overlap each other.\nplt.show()","56c1e18c":"accident_count = [dataset_2016.shape[0], dataset_2017.shape[0], dataset_2018.shape[0], dataset_2019.shape[0], dataset_2020.shape[0]]\nyears = [2016, 2017, 2018, 2019, 2020]","774e87ed":"plt.figure(figsize=(10,5))\n\nsns.lineplot(x=years, y=accident_count, color = 'seagreen')\nplt.ticklabel_format(style='plain')\nplt.xticks(fontsize=15)\nplt.xticks(years)\n\nplt.yticks(fontsize=15)\n\nplt.xlabel('Years', fontsize=20)\nplt.ylabel('Number of accidents', fontsize=20)\n\nplt.title('Distribution of accidents year over year ', fontsize = 20)\n","8d5656c2":"dataset.Start_Lat","daeb4607":"dataset.Start_Lng","05dbafaf":"plt.figure(figsize=(10,5))\n\n# Reducing the dataset\nsample_df = dataset.sample(int(0.1 * len(dataset)))     \nsns.scatterplot(x = sample_df.Start_Lng, y = sample_df.Start_Lat, size = 0.001, color = 'blueviolet')\n\nplt.xticks(fontsize=15)\n\nplt.yticks(fontsize=15)\n\nplt.xlabel('Start_Lng',fontsize=20)\nplt.ylabel('Start_Lat', fontsize=20)\n\nplt.title('Distribution of accidents ', fontsize = 20)","8b33c44b":"import folium","e8ef5d09":"# Reducing the number of datapoints to add them on the map\n\nsample1_df = dataset.sample(int(0.001 * len(dataset)))\nlat_lon = list(zip(list(sample1_df.Start_Lat), list(sample1_df.Start_Lng)))","86bff10b":"# Specifying the center coordinates to position the map to show the US\ncenter = [39.8097343, -98.5556199]\n\n# Adding data points on the Map\nmap_us = folium.Map(location=center, zoom_start=4)\nfor i in range(0,len(lat_lon)):\n    folium.Marker(lat_lon[i]).add_to(map_us)\n\n#displaying the map\nmap_us","cd4ffda6":"dataset['Temperature(F)']","bbd671af":"cold_temp_count = len(dataset[dataset['Temperature(F)'] < 70.0])\nhot_temp_count = len(dataset[dataset['Temperature(F)'] >= 70.0])","1b73b1bb":"# Setting up the labels for the pie chart\nlab = ['Accidents in cold climate', 'Accidents in hot climate', 'Accidents without temperature records']","ca197da5":"plt.figure(figsize=(20,10))\nplt.pie([cold_temp_count, hot_temp_count, len(dataset) - cold_temp_count - hot_temp_count], labels = lab, autopct = '%0.2f%%', shadow = True, explode = [0.2,0.2,0.2], textprops={'fontsize': 10})\nplt.title('Accident Percentages in cold and hot climate ', fontsize = 20)\nplt.show()","97a99ab2":"accident_weather_condition = (dataset.Weather_Condition.value_counts() \/ len(dataset)) * 100\naccident_weather_condition = accident_weather_condition.sort_values(ascending = False)","77193707":"plt.figure(figsize=(20,10))\naccident_weather_condition[:20].plot.barh(color = 'cornflowerblue')\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=20)\nplt.xlabel('Percentage of accidents', fontsize=20)\nplt.title('Top 20 weather conditions with associated accident percentages', fontsize = 20)\n\nplt.show()","b6dc299d":"plt.figure(figsize=(20,10))\n(dataset.Weather_Condition.value_counts() \/ len(dataset))[0:12].plot(kind='pie',autopct = '%0.2f%%', normalize = False, shadow = True)\nplt.ylabel(\"\")\nplt.title('Distribution of accidents based on weather condition', fontsize = 20)\nplt.show()","9a9af5ec":"cor= dataset.corr()\nplt.figure(figsize=(25,12))\nsns.heatmap(cor, annot=True)\nplt.show()","584f13a8":"From the above graph, we can observe 2 peaks. This implies that a higher percentage of accidents occur between 6 AM to 10 AM in the morning and 2 PM to 6 PM in the evening probably because people tend to be in a hurry to get to work and return from work. ","f801ad1a":"Thus, this dataset doesnot contain data from New York city.","cceaeab7":"There is a strong correlation between Traffic_calming and Bump.","46a16032":"## Temperature","df64f97b":"Let's plot the distribution of accidents over a week.","e5d8e0d9":"Over 1300 cities have reported just 1 accident throughout the year. This needs to be investigated.","ed2489b8":"Let's have a look at the distribution of accidents for months.","666e8ba8":"Calculating the percentage of accidents on certain weather condition.","ab02d6c2":"From the bar graph, we can see that only few cities have higher number of accidents while the rest have smaller number of accidents. There is an exponential decrease in the number of accidents per city.\nLet's seggregate the cities by high accidents and low accidents.","73943c50":"Let's show the accident points on a map to get a clear picture of the distribution of accidents over the US.","76a8ba05":"From the above two plots, it can be very well observed that the trend of accidents on weekends is entirely different from that on weekdays. \n* The peak for weekends occur between 10 AM to 5 PM unlike that for weekdays.\n","205aece2":"There are so many more columns in this dataset that can be analysed for some interesting insights.","b8a1f9a6":"It shows that about 4 percent of the cities record more than 1000 accidents per year.","fbe7dfa0":"The dataset has been divided based on years. Let's plot the distribution of accidents for these years.","928ba134":"Let's plot a pie chart to better visualize the accidents in cold and hot temperature","451d2792":"From the above bar graph and pie chart, we can observe that the majority of accidents occur in Fair, Clear, Mostly cloudy, Partly cloudy , Cloudy and overcast conditions. The rest conditions result in less than 5 percent accident for each condition.","83337c68":"The Start_Time column of the dataset is of object data type which cannot be used for effective analysis. So, we have to convert its data type from object to datetime format.","d4d96afc":"Let's plot a bar graph for the top 20 cities with major accidents in the US.","a4ac8a29":"To check if a lot of cities have small number of accidents or large number of accidents, we can plot a histogram.","d2f09006":"We can observe from the plot that the distribution of accidents over weekdays almost remain constant while it decreases for weekends probably because of holidays. (0 = Monday, 1 = Tuesday, 2 = Wednesday, 3 = Thursday, 4 = Friday, 5 = Saturday, 6 = Sunday)","fe585708":"We can see from the above scatter plot, that the density of accidents near the coastline is more compared to the center.","1dee1828":"Something about the dataset:\n\n* The dataset contains information about US Accidents\n* Can be useful to prevent accidents\n* This dataset doesnot contain data about New York","9a6532b5":"So this dataset contains 14 numerical columns.\n\nNow lets find the percentage of missing values or incorrect values in this dataset.","5330374e":"Let's make a correlation matrix for all the variables in the dataset.","f1291935":"From the above graph, we can observe an increasing trend in the number of accidents year over year.","7b5acdc4":"From the above chart, we can see that about 62 percent of the accidents occur in colder areas while 35 percent of the accidents occur in hotter areas.","a971bab6":"## Weather Condition","0f79e02a":"It looks like Los Angeles has the highest number of accidents recorded in the US but the most populated city in the US is New york. We have to check if this dataset contains data from New york or not.","ff5a55e9":"## Loading the dataset","5e0117be":"This dataset contains data from 11790 US cities. According to world population review, there are over 19,000 incorporated places registered in the US. This implies that this dataset does not contain information about every city in the US.\n\nWe can see the cities with major number of accidents.","dafdc499":"We can see that some of the columns have missing values in them.\n\nLets show the percentage of missing values on bar plot.\n \nSome of the columns have zero percentages in them. We don't want to show them on plot. So, we will filter out those columns.\n\n","51a1c85a":"We can now pull out pieces of information from the timestamp to get insights like:\n* The distribution of accidents in a day.\n* Day of the week with more accidents.\n* Trend of accidents over a year and so on.","f62f597a":"## Start Latitude and Start Longitude","e66600fd":"Finding the number of numerical columns using pandas.","0490c02c":"## Start Time","0bcbafb5":"Let's find out the percentage of cities with more than 1000 accidents yearly i.e. percentage of high accident cities.","9220aae7":"## Exploratory analysis and Visualization\n\nColumns that we will analyse:\n1. City\n2. Start_Time\n3. Start_Lat, Start_Lng\n4. Temperature(F)\n5. Weather_Condition\n","f73b4eaf":"After looking at the above plots, we observe that, the distribution for the years 2017, 2018 and 2019 seems more or less balanced with slight variation. But, when the trend for the years 2016 and 2020 are compared with that of the rest years, there is a significant variation in the distribution of accidents. This could mean that some data is missing for the years 2016 and 2020. The covid pandemic started in the year 2020 so, it might also be one the reasons for this variation in the trend in the year 2020 because of lockdown all over the US.","f72da264":"Let's check if the distribution of accidents by hour on weekends remains the same as that on weekdays.\n","1b37ff96":"# Summary and conclusions\n### Insights:\n\n* This dataset does not contain data from New York city.\n* There is an exponential decrease in the number of accidents per city.\n* About 4 percent of the cities record more than 1000 accidents per year.\n* Over 1300 cities have reported just 1 accident throughout the year. This needs to be investigated.\n* A higher percentage of accidents occur between 6 AM to 10 AM in the morning and 2 PM to 6 PM in the evening probably because people tend to be in a hurry to get to work and return from work.\n* The peak for weekends occur between 10 AM to 5 PM unlike that for weekdays.\n* More number of accidents occur around the month of december.\n* An increasing trend is observed in the number of accidents year over year.\n* Density of accidents near the coastline is more compared to the center.\n* About 62 percent of the accidents occur in colder areas while 35 percent of the accidents occur in hotter areas.\n* Majority of accidents occur in Fair, Clear, Mostly cloudy, Partly cloudy , Cloudy and overcast conditions.\n","eadd2833":"Let's make a scatter plot to get an idea of the distribution of accidents in the US. But first, we have to reduce the number of points as there are about 3 million data points.","ada9f5d4":"From the above plot, it can be seen that more number of accidents occur around the month of december. \nLet's look at year by year plot to verify that this trend is consistent and to rule out any possibility of missing data.","912f63cd":"Seggregating the accidents based on hot and cold climate. Above 70 degrees F is chosen as hot climate and below it is chosen to be cold climate.","74575032":"## Data preparation and cleaning","0d18cddc":"# Exploratory Data Analysis on US Accidents\n\n### Introduction\nThis dataset contains about 3 million car accident records captured by a variety of entities, such as the US and state departments of transportation, law enforcement agencies, traffic cameras, and traffic sensors within the road-networks. \n\nThe license to use this dataset can be found [here](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/)"}}