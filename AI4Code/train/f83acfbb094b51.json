{"cell_type":{"7504efb0":"code","587fc301":"code","ec2ad7a8":"code","f7608f52":"code","1d1c3f13":"code","1b56dbbd":"code","95570b4c":"code","1f7d46c9":"code","ba6494e2":"code","19fa8918":"code","307ec8e8":"code","6151024a":"code","dff32f8b":"code","8e013e19":"code","db4c2694":"code","2d3c3e58":"code","a42552a1":"code","cb91d43a":"code","51005432":"code","bb54dd5d":"code","3de26bc0":"code","e5aa2e8b":"code","98e6c6ca":"code","67b5a618":"code","188c776e":"code","89326ddd":"code","b748cd2c":"code","296be0db":"code","945cad4f":"code","593f630c":"code","533df005":"code","ef8f2b43":"code","375f651b":"code","4873143f":"code","9807582c":"code","92776173":"markdown","9afe1f11":"markdown","85cc8e7a":"markdown","80931c29":"markdown","1e18c954":"markdown","6f715b5d":"markdown","becbdb60":"markdown","da5ed62d":"markdown","248286bc":"markdown","844bb404":"markdown","de525bc6":"markdown","cc404e53":"markdown","d00b0ceb":"markdown","8b387a1c":"markdown","373ae01f":"markdown","25a0e90c":"markdown","8694c7bb":"markdown"},"source":{"7504efb0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","587fc301":"train_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","ec2ad7a8":"y = train_data['label']\nX = train_data.drop(['label'],axis=1)","f7608f52":"X_test = test_data.drop(['label'],axis=1)\ny_test = test_data['label']","1d1c3f13":"del train_data","1b56dbbd":"del test_data","95570b4c":"X.isnull().all().unique()","1f7d46c9":"y.isnull().any()","ba6494e2":"X_test.isnull().all().unique()","19fa8918":"y_test.isnull().all()","307ec8e8":"label_val = y.value_counts()\nplt.figure(figsize=(12,6))\nsns.barplot(x=label_val.index,y=label_val.values)","6151024a":"X = X.values.reshape(-1,28,28,1)","dff32f8b":"X_test = X_test.values.reshape(-1,28,28,1)","8e013e19":"plt.imshow(X[0][:,:,0])","db4c2694":"plt.imshow(X[7][:,:,0])","2d3c3e58":"X = X \/ 255\nX_test = X_test \/ 255","a42552a1":"import warnings\nwarnings.filterwarnings('ignore')","cb91d43a":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Dropout, BatchNormalization, Flatten, MaxPool2D\nfrom keras.utils.np_utils import to_categorical","51005432":"y = to_categorical(y,num_classes=10)","bb54dd5d":"from keras.callbacks import ModelCheckpoint\ncheckpoint = ModelCheckpoint('BWeight.md5',monitor='val_loss',\n                            save_best_only=True)","3de26bc0":"model = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10,activation='softmax'))","e5aa2e8b":"from keras import optimizers\nsgd = optimizers.SGD(lr=0.001, decay=1e-8, momentum=0.9, nesterov=True)","98e6c6ca":"model.compile(optimizer=sgd,loss = 'categorical_crossentropy', metrics=['accuracy'])","67b5a618":"from keras.preprocessing.image import ImageDataGenerator","188c776e":"datagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        zoom_range = 0.2,\n        width_shift_range=0.3,\n        height_shift_range=0.3,\n        horizontal_flip=True,\n        vertical_flip=False)","89326ddd":"datagen.fit(X)","b748cd2c":"from sklearn.model_selection import train_test_split","296be0db":"X_train, X_val, y_train, y_val = train_test_split(\n...     X, y, test_size=0.1)","945cad4f":"size_batch = 28","593f630c":"history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=size_batch),\n                              epochs = 10,\n                              validation_data = (X_val,y_val),\n                              verbose = 2,\n                              steps_per_epoch = X_train.shape[0] \/\/ size_batch,\n                              callbacks=[checkpoint],\n                             use_multiprocessing=True)","533df005":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","ef8f2b43":"model.load_weights('BWeight.md5')","375f651b":"y_final_preds = model.predict_classes(X_test)","4873143f":"from sklearn.metrics import classification_report","9807582c":"print(classification_report(y_test,y_final_preds))","92776173":"Splitting the train data in train and validation","9afe1f11":"Now we have the data to work with , so lets start building the model using Keras","85cc8e7a":"# Visualization","80931c29":"Now that we have our model ready , lets apply some data augmentation","1e18c954":"Therefore we dont have any null values in both our test and train data","6f715b5d":"# Training","becbdb60":"# Predictions","da5ed62d":"Distribution of labels is relatively similar","248286bc":"Plotting images","844bb404":"# Data Preparation","de525bc6":"# Model Building","cc404e53":"Right now we have flat pixels but our image should be a 2d image with single channel ( since we have grayscale images)\nSo lets reshape the arrays","d00b0ceb":"Loading best weights","8b387a1c":"Lets plot the distribution of labels","373ae01f":"Compiling the model","25a0e90c":"Lets add a checkpoint too , which can be used to save best weights","8694c7bb":"Predicting labels of our test data"}}