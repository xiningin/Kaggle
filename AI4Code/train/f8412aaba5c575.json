{"cell_type":{"5e87b4f6":"code","2bb3c453":"code","7eadca7b":"code","c9d6e48a":"code","e688257c":"code","24b661bb":"code","584fd020":"code","56475077":"code","33ad0e67":"code","dc441e71":"code","f385244a":"code","a2c66333":"code","f731b98f":"code","5d138db3":"code","577ff006":"code","68ccebe1":"code","d5834aa2":"code","b9a4cc1d":"code","22df8332":"code","7b5398b3":"code","3ef97aa6":"code","dacaa807":"code","56818419":"code","baa11c32":"code","549534b1":"code","0809fd58":"code","c4b3dfbc":"code","c63647a3":"code","cab8cc2c":"code","584ed6b9":"code","f8472bb1":"code","8dc78916":"code","267b5c8e":"code","548838f4":"code","5e7fe886":"code","262aeb31":"code","dc3b5a92":"code","a1b98f5f":"code","b869381b":"code","ff231005":"code","8651f873":"code","b6b0c2b6":"code","cc10d0c8":"code","7896257f":"code","1c71f01e":"code","0a90f38a":"code","8d29bf6b":"code","38dcba0b":"code","5798022a":"code","fae283f0":"code","4f7fd43d":"code","68dd9600":"code","6209be24":"code","5b72512d":"code","0a6f599e":"code","9895907d":"code","dc03acae":"code","f9a887f7":"code","4acf4d6c":"code","d39a4d97":"code","a6022865":"code","fa07aeef":"code","9301e0c9":"code","61e1eab7":"code","89f06130":"code","d403bc15":"code","b4012c9d":"code","462d5be5":"code","80072d20":"code","fab9e771":"code","fd125138":"code","c5e7ec55":"code","de60c603":"code","fd1a4c34":"code","6654fe01":"code","963d173e":"code","0bfd5b97":"code","16297ab5":"code","567e536d":"code","d93d78d8":"code","1d4dd3d3":"code","bf42ac3d":"code","cc27810f":"code","2860f7e4":"code","723c5034":"code","5d01afd7":"code","85bb921b":"code","d7b59177":"code","46f32bc2":"code","2bb716d1":"code","6aa3c05a":"code","c70d3abf":"code","aa495977":"code","9644af41":"code","e0da88c7":"code","84fa85be":"code","606fa9c1":"code","c6602e69":"code","613918bd":"code","0dd78dc2":"code","bbb51e8b":"code","a06a3c46":"code","df6567ed":"code","543d267f":"code","747e5e55":"code","552784ab":"code","62bd2f26":"code","fa5efa84":"code","dae50972":"code","b483cd79":"code","68f71b63":"code","0b437d61":"code","b9909a4f":"code","29fff0ff":"code","c309d41d":"code","0fd9661a":"code","c7ed8961":"code","2f2ff79d":"code","e2abfc9f":"code","df2bdfe3":"code","d27f1c65":"code","c54d5bda":"code","241b4049":"code","67cac24f":"code","572b3ae9":"code","df21dd00":"code","73cc2d73":"code","2710c2ed":"code","f9fe26d0":"code","0c31ef7d":"code","74d5eb5e":"code","6b3f4d43":"code","8fc853df":"code","98c35774":"code","132ffad1":"code","7324ff44":"code","2944025f":"code","833e0571":"code","2b1f6ad1":"code","2393c04a":"code","bbabdf36":"code","5c84f69e":"code","1472288d":"code","9fc59aad":"code","f13bc64a":"code","3e6f87da":"code","769ff010":"code","c21320d1":"code","118d8547":"code","5466ebe0":"code","ac5f353e":"code","42e9af0a":"code","753eb958":"code","7fd59627":"code","17844642":"code","6fb7e36a":"code","fc97e464":"code","0cf7927e":"code","e790aee1":"code","c1fd0c50":"code","ae842d9a":"code","6b9bb50f":"code","1d6eadee":"code","bf075b40":"code","128651ff":"code","e09c7aa2":"code","a49f5712":"code","13c3b033":"code","549610c3":"code","744a8182":"code","11af31ba":"code","2b6bfd4a":"code","a3d1f9b9":"code","0c85f7a6":"code","13ce51f7":"code","738d74cc":"code","d1b5cfec":"code","d5c00a23":"code","c74c93be":"code","8e1fdccd":"code","f1803a71":"code","9dbb7801":"code","60695ccb":"code","2fed3e13":"code","375a9ba1":"code","f6fa8e92":"code","fb431410":"code","027e98e6":"code","63398ba2":"code","ec09666c":"code","a8561d4b":"code","96aeb0f6":"code","0c9bb1e5":"code","8404588b":"code","101566c1":"code","ab837259":"code","4070a13e":"code","384286c9":"code","d611428a":"code","8aa0032b":"code","1ea9c7a4":"code","24c547c4":"code","cdd185ba":"code","ef8acc3f":"code","0196f857":"code","7003ca1b":"code","12b5cf98":"code","eb2faa6f":"code","6a9038b3":"code","d7cfdeb5":"code","4e64953f":"code","2fec8feb":"code","545b4ecd":"code","f47f522e":"code","f4751720":"code","cc113e40":"code","14419bd2":"code","39a42cea":"code","40144ccd":"code","29b9e4fe":"code","3236473d":"code","9a84c58e":"code","944843af":"code","ed227d6c":"code","dbe9cea2":"code","3e2abad3":"code","2fbae270":"code","46bc7b2e":"code","31dd66ae":"code","22765078":"code","63961f56":"code","ff30d84b":"code","897a19e8":"code","de609c53":"code","a815676c":"code","dc5e8e44":"code","d5abb88d":"code","173c622b":"code","b81d56e9":"code","55d65613":"code","cbca1cec":"code","645d6592":"code","b4df920d":"code","a8b06bb6":"code","861d97a8":"code","6d72ab3a":"code","db46c615":"code","6abcabfe":"code","40534d46":"code","27bb372b":"code","d5d3a534":"code","95e89dbb":"code","75167b65":"code","7626cfa6":"code","d022ef88":"code","38969703":"code","d201eaf5":"code","f10e4341":"code","0c2eb857":"code","38b5c1fd":"code","652df007":"code","052c30f3":"code","dac205aa":"code","172ae866":"code","b6a4b2e0":"code","655b7487":"code","218b52ae":"code","92f177e0":"code","19b58855":"code","fbd190ef":"code","afbe142e":"code","9fc9321c":"code","14472ee5":"code","6643de91":"code","ee0d0def":"code","86d816f3":"code","76aa1e56":"code","f1edb4af":"code","51a182b2":"code","cdef711d":"code","079a3dad":"code","6bba327b":"code","5f8c0035":"code","6de4e0c1":"code","84baf703":"code","251d4580":"code","d0512473":"code","bf231c4d":"code","1aca066f":"code","7b1ff966":"code","66e8bd32":"code","ddd73d8f":"code","d73ddadf":"code","413e1cf7":"code","59e3a2e9":"code","9799cb63":"code","e77b7dee":"code","d5640290":"code","942ed570":"code","16ec0897":"code","ed0042f0":"code","131e8bb6":"code","de82432c":"code","5022ca7a":"code","6b5ad834":"code","13ee3d2e":"code","b8303146":"code","5873e6a4":"code","fdfd36a6":"code","14c7060b":"code","11f546ea":"code","539dc6fe":"code","016a6250":"code","2263851b":"code","982b5d13":"code","c93a9fe5":"code","f64bed49":"code","d0e34446":"code","a4fe524b":"code","e0c20318":"code","eb9eb6a7":"code","cc8e0b2c":"code","96997cd9":"code","535c4452":"code","6d1a8f80":"code","955cdfe2":"code","92eefdbb":"code","daf97892":"code","5c8c8cdb":"code","ad0ab79b":"code","6c06e644":"code","f8072f95":"code","1ec9ab0c":"code","391d64f4":"code","f53bc422":"code","50eb7ac8":"code","59f3c4c3":"code","9eb8beff":"code","1998bfc5":"code","f6723e6f":"code","913394d6":"code","dcb670ce":"code","05f6e9aa":"code","f66d9686":"code","ac9ff5c1":"code","115b5374":"code","a2bd09f2":"code","297c2d6e":"code","832d30b8":"code","74ac3f51":"code","3e6132ac":"code","b9eecfcb":"code","d22c91ec":"code","ce987b8a":"code","0855802b":"code","a6a689ff":"code","ae1468cd":"code","e3e5c57c":"code","59274b84":"code","b124ab74":"code","d264c37d":"code","46c6a233":"code","c7c47cf8":"code","be030bd6":"code","8b55b2a4":"code","7f9d9842":"code","653770a9":"code","46b465c3":"code","8f5bab7a":"code","11c5b2b9":"code","9dca6edc":"code","df3efcb1":"code","81822c74":"code","6ea71689":"code","c8ccae49":"code","5a71e02e":"code","d94a23ea":"code","f2915f35":"code","e828ad42":"code","c194d3a5":"code","1761df58":"code","e8923f4c":"code","d7df3cbf":"code","392c20f4":"code","c84a9935":"code","2e2f5e64":"code","8a527418":"code","78de86fc":"code","6304b2fd":"code","930d91bb":"code","198c8212":"code","689aa7be":"code","b54f013d":"code","3c73955e":"code","3f1e05e9":"code","a45dcf35":"code","a024557f":"code","37243948":"code","19a235d0":"code","c9d22d5f":"code","5d924c25":"code","ae48be41":"code","655be76b":"code","8e84cd15":"code","91c28f79":"code","f0a1eaf9":"code","cf4724b2":"code","1aedb236":"code","9f8c0707":"code","d7a138a9":"code","89f8a810":"code","f536096e":"code","b5c4b65b":"code","21b4e0ef":"markdown","7022eefa":"markdown","02715a52":"markdown","ee738951":"markdown","0363d96a":"markdown","3951ed88":"markdown","aff165d0":"markdown","8a32fd20":"markdown","9e352a2b":"markdown","f0e49cab":"markdown","cc13c868":"markdown","382b56d8":"markdown","6d7ce535":"markdown","3a4a8775":"markdown","af29045e":"markdown","ca80b536":"markdown","9ae64238":"markdown","fff3ce4f":"markdown","c1d7f6c4":"markdown","ce4ac2fd":"markdown","6256886a":"markdown","cce11ee6":"markdown","d9232da6":"markdown","7c37acfc":"markdown","ba47bcbe":"markdown","8c0ad62c":"markdown","c8a06901":"markdown","e88ebc30":"markdown","8a3dc6a4":"markdown","7a444b57":"markdown","34e74ee8":"markdown","469b5cbd":"markdown","d5b0f631":"markdown","ee95c4f8":"markdown","f42edda5":"markdown","2b875f4c":"markdown","122523f4":"markdown","973f35d7":"markdown","11f27964":"markdown","c6c21545":"markdown","579aa483":"markdown","d5ebd687":"markdown","e3724691":"markdown","90ec3d4c":"markdown","0407f4f4":"markdown","77f3e79a":"markdown","f3e295cf":"markdown","79464f8a":"markdown","ee761c78":"markdown","6af59dc9":"markdown","f3807192":"markdown","9e6c98e9":"markdown","f8215d34":"markdown","0cb58cbf":"markdown","a476f0d5":"markdown","63021a08":"markdown","112696be":"markdown","6e264cc4":"markdown","ac4d5e80":"markdown","84081d23":"markdown","f79714ee":"markdown","7f245661":"markdown","6c2d317e":"markdown","ab7bab59":"markdown","7b30d371":"markdown","517df971":"markdown","7ac21df7":"markdown","d048f2a4":"markdown","1027c3cd":"markdown","612cf9f3":"markdown","5f178081":"markdown","910a1a6d":"markdown","cd765502":"markdown","8b07649b":"markdown","5f75495c":"markdown","c7ab7bfb":"markdown","7d9c8d29":"markdown","51b56df9":"markdown","a1379865":"markdown","a21561ad":"markdown","ba74e615":"markdown","78a5ea3d":"markdown","f0e77029":"markdown","47066f28":"markdown","8c979948":"markdown","e714f825":"markdown","2a485f6a":"markdown","5fac4adb":"markdown","644b048e":"markdown","d44ecdff":"markdown","ba978b3e":"markdown","37d31308":"markdown","d12826d7":"markdown","372f4ff3":"markdown","38291ded":"markdown","cc70249a":"markdown","d66ac04f":"markdown","e96aa576":"markdown","e70d8566":"markdown","40f86820":"markdown","0111b73c":"markdown","7ca224fb":"markdown","658188c0":"markdown","f19eea58":"markdown","5d3f8efd":"markdown","654d1860":"markdown","5bafaee7":"markdown","52d95e30":"markdown","6c9e8850":"markdown","39f98aa2":"markdown","7ffeb385":"markdown","c4ba174d":"markdown","9c8742bd":"markdown","13ea7664":"markdown","5f1ed51a":"markdown","a1d0c8d9":"markdown","185a3a1a":"markdown","0d9d74e4":"markdown","fc68ce5a":"markdown","69355807":"markdown","e6048c19":"markdown","7ad13d8c":"markdown","71853e67":"markdown","3d2e7a99":"markdown","5362da77":"markdown","2c304797":"markdown","f69e620f":"markdown","ce59b0a8":"markdown","49ba9ab3":"markdown","5b73fa33":"markdown","6d057835":"markdown","101aef98":"markdown","c517e6b4":"markdown","4d90d63a":"markdown","ca9525af":"markdown","16d937d3":"markdown","eff43e5e":"markdown","77648565":"markdown","1d805bad":"markdown","571c4ab3":"markdown","ac9b917b":"markdown","3356c6dd":"markdown","3352de0e":"markdown","0da1f9fc":"markdown","aff18361":"markdown","541c5888":"markdown","036ac1f1":"markdown","c6788729":"markdown","654321f2":"markdown","fd2b42b9":"markdown","3e6fee75":"markdown","e3057c14":"markdown","dff5c2d7":"markdown","47fbc95f":"markdown","7f51d997":"markdown","bdcf2fe7":"markdown","73b8a0ad":"markdown","a51f385e":"markdown","c22e94e9":"markdown","db000f77":"markdown","f4d9c111":"markdown","f66cb628":"markdown","7b8edb3f":"markdown","53ce7e2a":"markdown","29f0aef6":"markdown","fba9af26":"markdown","fc63746e":"markdown","28e0b7e1":"markdown","29d022da":"markdown","e5388e59":"markdown","9e81e73e":"markdown","c0dd4134":"markdown","bf01b4b2":"markdown","e4eac88b":"markdown","12b150b8":"markdown","e5020703":"markdown","385fe303":"markdown","b1a99881":"markdown","67cb1d9b":"markdown","c69cd3c6":"markdown","36ed1879":"markdown","d370206c":"markdown","c7f7306d":"markdown","0b135d6b":"markdown","f7bcf20e":"markdown"},"source":{"5e87b4f6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nsns.set_context('notebook')\n%matplotlib inline","2bb3c453":"df = pd.read_csv('\/kaggle\/input\/insurance-company\/Customer_data.csv')","7eadca7b":"df.head()","c9d6e48a":"df.info()","e688257c":"df.describe()","24b661bb":"df.isnull().sum()","584fd020":"df['TARGET'] = df['TARGET'].map({'Y': 1, 'N': 0})","56475077":"ax = sns.countplot(x=\"TARGET\", data=df)\nplt.title('TARGET')\n\ntotal = len(df['TARGET'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","33ad0e67":"df_X = df.drop('TARGET', axis=1)","dc441e71":"cm = df.corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(cm, annot=True, cmap='coolwarm')","f385244a":"cm_X = (df_X).corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(cm_X, annot=True, cmap='coolwarm')","a2c66333":"# https:\/\/stackoverflow.com\/questions\/42658379\/variance-inflation-factor-in-python\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\n\nX_ = add_constant(df)","f731b98f":"pd.Series([variance_inflation_factor(X_.values, i)\n           for i in range(X_.shape[1])],\n          index=X_.columns)\n\n# VIF of 5 or 10 and above indicates a multicollinearity problem.\n# If there is perfect correlation, then VIF = infinity.","5d138db3":"# Distribution\nplt.figure(figsize=(8, 5))\nsns.distplot(df['ID'])","577ff006":"df['ID'].value_counts().head(5)","68ccebe1":"df[df['ID'].duplicated(keep=False)]","d5834aa2":"print(str(np.round((3008\/len(df))*100, decimals=3)) +\n      '% of the samples have a duplicate ID')","b9a4cc1d":"df[df['ID'] == 306]","22df8332":"df['turnover_A'].nunique()","7b5398b3":"# Double check: 11008 unique values and we have 14016 samples\n14016-11008\n# Conclussion: 3008 duplicate records in the dataset","3ef97aa6":"df.shape","dacaa807":"# remove duplicate records\n# there is no timestamp record, so does not matter which of the two duplicate id rows I remove\ndf = df.drop_duplicates(subset=['ID', 'turnover_A'], keep='first')","56818419":"df.shape","baa11c32":"ax = sns.countplot(x=\"TARGET\", data=df)\nplt.title('TARGET')\n\ntotal = len(df['TARGET'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","549534b1":"plt.figure(figsize=(8, 5))\nax = sns.countplot(x=\"loyalty\", data=df)\nplt.title('loyalty')\n\ntotal = len(df['loyalty'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","0809fd58":"# Correlation\nplt.figure(figsize=(8, 5))\ncm = df.corr()\ncm.nlargest(14, 'loyalty')['loyalty'].plot(kind='bar')","c4b3dfbc":"sns.heatmap((df[['loyalty', 'LOR']]).corr(), annot=True)","c63647a3":"# 99 = unclassified (beige lines)\nplt.figure(figsize=(8, 5))\nsns.heatmap(df[['loyalty']])","cab8cc2c":"classified_loyalty = df[df['loyalty'] < 99]","584ed6b9":"plt.figure(figsize=(14, 5))\nax = sns.countplot(x='LOR', hue='loyalty',data=classified_loyalty)\nplt.title('LOR per classified loyalty')\nplt.show()","f8472bb1":"plt.figure(figsize=(14, 5))\nax = sns.countplot(x=\"LOR\", data=classified_loyalty)\nplt.title('LOR for classified loyalty <99')\n\ntotal = len(classified_loyalty['LOR'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","8dc78916":"unclassified_loyalty = df[df['loyalty'] == 99]","267b5c8e":"plt.figure(figsize=(15, 5))\nax = sns.countplot(x=\"LOR\", data=unclassified_loyalty)\nplt.title('LOR for loyalty 99')\n\ntotal = len(unclassified_loyalty['LOR'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","548838f4":"df.shape","5e7fe886":"df = df.drop('loyalty', axis=1)","262aeb31":"df.shape","dc3b5a92":"plt.figure(figsize=(8, 6))\nsns.distplot(df['ID'])\nplt.title('ID distribution')\n# After removing duplicate ID's, majority still has low ID","a1b98f5f":"df_check_under = df[(df['ID'] < 20000)]\nprint(len(df_check_under)\/len(df))","b869381b":"df_check_above = df[(df['ID'] > 20000)]\nprint(len(df_check_above)\/len(df))","ff231005":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(\n    2, 2, figsize=(12, 8), sharey=True,sharex=True)\n\nsns.distplot(df_check_under[df_check_under['TARGET'] == 0]\n             ['ID'], ax=ax1).set_title('ID = <20000; target = 0')\nsns.distplot(df_check_under[df_check_under['TARGET'] == 1]\n             ['ID'], ax=ax2,color='orange').set_title('ID = <20000; target = 1')\nsns.distplot(df_check_above[df_check_above['TARGET'] == 0]\n             ['ID'], ax=ax3).set_title('ID = >20000; target = 0')\nsns.distplot(df_check_above[df_check_above['TARGET'] == 1]\n             ['ID'], ax=ax4,color='orange').set_title('ID = >20000; target = 1')\nfig.tight_layout()","8651f873":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(df['age'],bins=80)\nplt.xticks(np.arange(min(df['age']), max(df['age'])+1, 5))\nplt.title('Raw data age distribution')\nplt.show()","b6b0c2b6":"import scipy.stats as sp\n\nprint(\"Mode: \"+str(df['age'].mode()[0]))\nprint(\"Median: \"+str(df['age'].median()))\nprint(\"Mean: \"+str(np.round(df['age'].mean(), decimals=2)))\nprint(\"Skew: \"+str(np.round(sp.skew(df['age']), decimals=2)))\nprint(\"Kurtosis: \"+str(np.round(sp.kurtosis(df['age']), decimals=2)))\nprint(\"Min: \"+str(df['age'].min()))\nprint(\"Max: \"+str(df['age'].max()))\nprint(\"Range: \"+str((df['age'].max())-(df['age'].min())))","cc10d0c8":"age_log = np.log(df['age'])","7896257f":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(age_log,bins=80)\nplt.xticks(np.arange(min(age_log), max(age_log)+1, 1))\nplt.title('Log of age distribution')\nplt.show()","1c71f01e":"fig = plt.figure(figsize=(16, 6))\nsns_plot = sns.distplot(df['age'], hist=False, rug=True).set_title('Age')\nsns_plot = sns.distplot(df[df['TARGET'] == 0]['age'], hist=False, rug=True)\nsns_plot = sns.distplot(df[df['TARGET'] == 1]['age'], hist=False, rug=True)\nfig.legend(labels=['Combined',\n                   'TARGET = 0',\n                   'TARGET = 1'])\nplt.title('Raw age distribution per target value and combined ')\nplt.xticks(np.arange(min(df['age']), max(df['age'])+1, 2))\nplt.show()\nfig.tight_layout()","0a90f38a":"fig = plt.figure(figsize=(16, 6))\nsns_plot = sns.distplot(df[df['TARGET'] == 0]['age'], hist=False, rug=True)\nsns_plot = sns.distplot(df[df['TARGET'] == 1]['age'], hist=False, rug=True)\nfig.legend(labels=['TARGET = 0',\n                   'TARGET = 1'])\nplt.title('Age distribution per target value after removing outliers')\nplt.xticks(np.arange(min(df['age']), max(df['age'])+1, 2))\nplt.show()","8d29bf6b":"plt.figure(figsize=(12, 6))\nax = sns.boxplot(x=\"age\", y=\"TARGET\", data=df, orient=\"h\")","38dcba0b":"df.shape","5798022a":"df = df.drop('city', axis=1)","fae283f0":"df.shape","4f7fd43d":"plt.figure(figsize=(14, 5))\nax = sns.countplot(df['LOR'])\nplt.title('Length of relationship in years distribution')\n\ntotal = len(df['LOR'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 10,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","68dd9600":"plt.figure(figsize=(14, 5))\nax = sns.countplot(df['lor_M'])\nplt.title('Length of relationship in months distribution')\n\ntotal = len(df['lor_M'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 10,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","6209be24":"df.shape","5b72512d":"df = df.drop(['lor_M'], axis=1)","0a6f599e":"df.shape","9895907d":"plt.figure(figsize=(14, 5))\nax = sns.countplot(x=\"prod_A\", data=df)\nplt.title('Distribution of  prod_A')\n\ntotal = len(df['prod_A'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","dc03acae":"fig = plt.figure(figsize=(14, 5))\nsns_plot = sns.distplot(df[df['prod_A'] == 0]['age'], hist=False, rug=True)\nsns_plot = sns.distplot(df[df['prod_A'] == 1]['age'], hist=False, rug=True)\nfig.legend(labels=['prod_A_0',\n                   'prod_A_1'])\nplt.xticks(np.arange(min(df['age']), max(df['age'])+1, 2))\nplt.show()","f9a887f7":"plt.figure(figsize=(14, 5))\nsns.boxplot(x=\"age\", y=\"prod_A\", data=df, orient=\"h\")","4acf4d6c":"plt.figure(figsize=(14, 5))\nax = sns.countplot(x=\"type_A\", data=df)\nplt.title('Distribution of  type_A')\n\ntotal = len(df['type_A'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","d39a4d97":"df.shape","a6022865":"df = df.drop('type_A', axis=1)","fa07aeef":"df.shape","9301e0c9":"plt.figure(figsize=(14, 5))\nax = sns.countplot(x=\"prod_B\", data=df)\nplt.title('Distribution of  prod_B')\n\ntotal = len(df['prod_B'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","61e1eab7":"plt.figure(figsize=(14, 5))\nax = sns.countplot(x=\"type_B\", data=df)\nplt.title('Distribution of  type_B')\n\ntotal = len(df['type_B'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","89f06130":"df.shape","d403bc15":"# holds quasi the same distribution as prod_B, remove\ndf = df.drop('type_B', axis=1)","b4012c9d":"df.shape","462d5be5":"plt.figure(figsize=(14, 5))\nsns.distplot(df['turnover_A'])","80072d20":"print(\"Mode: \"+str(np.round(df['turnover_A'].mode()[0], decimals=2)))\nprint(\"Median: \"+str(np.round(df['turnover_A'].median(), decimals=2)))\nprint(\"Mean: \"+str(np.round(df['turnover_A'].mean(), decimals=2)))\nprint(\"Skew: \"+str(np.round(sp.skew(df['turnover_A']), decimals=2)))\nprint(\"Kurtosis: \"+str(np.round(sp.kurtosis(df['turnover_A']), decimals=2)))\nprint(\"Min: \"+str(np.round(df['turnover_A'].min(), decimals=2)))\nprint(\"Max: \"+str(np.round(df['turnover_A'].max(), decimals=2)))","fab9e771":"df['turnover_A'].describe()","fd125138":"# plot 40 highest values to check if valid outliers\nplt.figure(figsize=(14, 5))\ndf['turnover_A'].sort_values(ascending=False).head(40).plot(kind='bar')\nplt.xlabel('index')\nplt.ylabel('turnover_A')\nplt.title('Inspect highest turnover_A values')\nplt.show()","c5e7ec55":"df_turnover_A_reduced_plot = df.drop(df[df['turnover_A'] > 400].index)","de60c603":"print(\"Mode: \"+str(np.round(df_turnover_A_reduced_plot['turnover_A'].mode()[0], decimals=2)))\nprint(\"Median: \"+str(np.round(df_turnover_A_reduced_plot['turnover_A'].median(), decimals=2)))\nprint(\"Mean: \"+str(np.round(df_turnover_A_reduced_plot['turnover_A'].mean(), decimals=2)))\nprint(\"Skew: \"+str(np.round(sp.skew(df_turnover_A_reduced_plot['turnover_A']), decimals=2)))\nprint(\"Kurtosis: \"+str(np.round(sp.kurtosis(df_turnover_A_reduced_plot['turnover_A']), decimals=2)))\nprint(\"Min: \"+str(np.round(df_turnover_A_reduced_plot['turnover_A'].min(), decimals=2)))\nprint(\"Max: \"+str(np.round(df_turnover_A_reduced_plot['turnover_A'].max(), decimals=2)))","fd1a4c34":"df_turnover_A_reduced_plot['turnover_A'].describe()","6654fe01":"plt.figure(figsize=(14, 5))\nsns.distplot(df_turnover_A_reduced_plot['turnover_A'])\nplt.show()","963d173e":"df = df.drop(df[df['turnover_A'] > 400].index)","0bfd5b97":"plt.figure(figsize=(14, 5))\nsns.distplot(df['turnover_B'])\nplt.show()","16297ab5":"print(\"Mode: \"+str(np.round(df['turnover_B'].mode()[0], decimals=2)))\nprint(\"Median: \"+str(np.round(df['turnover_B'].median(), decimals=2)))\nprint(\"Mean: \"+str(np.round(df['turnover_B'].mean(), decimals=2)))\nprint(\"Skew: \"+str(np.round(sp.skew(df['turnover_B']), decimals=2)))\nprint(\"Kurtosis: \"+str(np.round(sp.kurtosis(df['turnover_B']), decimals=2)))\nprint(\"Min: \"+str(np.round(df['turnover_B'].min(), decimals=2)))\nprint(\"Max: \"+str(np.round(df['turnover_B'].max(), decimals=2)))","567e536d":"df['turnover_B'].describe()","d93d78d8":"# plot 40 highest values to check if outliers are valid\nplt.figure(figsize=(14, 5))\ndf['turnover_B'].sort_values(ascending=False).head(40).plot(kind='bar')\nplt.xlabel('index')\nplt.ylabel('turnover_B')\nplt.title('Inspect highest turnover_B values')\nplt.show()","1d4dd3d3":"df_TO_A_B_reduced_plot = df_turnover_A_reduced_plot.drop(\n    df_turnover_A_reduced_plot[df_turnover_A_reduced_plot['turnover_B'] >= 260].index)","bf42ac3d":"print(\"Mode: \"+str(np.round(df_TO_A_B_reduced_plot['turnover_B'].mode()[0], decimals=2)))\nprint(\"Median: \"+str(np.round(df_TO_A_B_reduced_plot['turnover_B'].median(), decimals=2)))\nprint(\"Mean: \"+str(np.round(df_TO_A_B_reduced_plot['turnover_B'].mean(), decimals=2)))\nprint(\"Skew: \"+str(np.round(sp.skew(df_TO_A_B_reduced_plot['turnover_B']), decimals=2)))\nprint(\"Kurtosis: \"+str(np.round(sp.kurtosis(df_TO_A_B_reduced_plot['turnover_B']), decimals=2)))\nprint(\"Min: \"+str(np.round(df_TO_A_B_reduced_plot['turnover_B'].min(), decimals=2)))\nprint(\"Max: \"+str(np.round(df_TO_A_B_reduced_plot['turnover_B'].max(), decimals=2)))","cc27810f":"df_TO_A_B_reduced_plot['turnover_B'].describe()","2860f7e4":"fig = plt.figure(figsize=(14, 5))\nsns_plot = sns.distplot(df_TO_A_B_reduced_plot['turnover_A'])\nsns_plot = sns.distplot(df_TO_A_B_reduced_plot['turnover_B'])\nfig.legend(labels=['turnover_A', 'turnover_B'])\nplt.xlabel('Turnover_B and Turnover_A')\nplt.show()\nfig.tight_layout()","723c5034":"df.shape","5d01afd7":"df_TO_A_B_reduced_plot.shape","85bb921b":"df = df.drop(df[df['turnover_B'] >= 260].index)","d7b59177":"df.shape","46f32bc2":"df.shape","2bb716d1":"df['contract'].value_counts()","6aa3c05a":"df = df.drop(['contract'], axis=1)","c70d3abf":"df.shape","aa495977":"sns.heatmap(df[['age_P', 'age']].corr(), annot=True)","9644af41":"df.shape","e0da88c7":"df = df.drop('age_P', axis=1)","84fa85be":"df.shape","606fa9c1":"g = sns.PairGrid(df, hue='TARGET', corner=True)\ng = g.map_diag(plt.hist)\ng = g.map_offdiag(plt.scatter)\ng = g.add_legend()","c6602e69":"df.head()","613918bd":"target_zero = df[df['TARGET'] == 0]\ntarget_one = df[df['TARGET'] == 1]","0dd78dc2":"fig = plt.figure(figsize=(14, 4))\nax = sns.countplot(x=\"TARGET\", data=df)\ntotal = len(df['TARGET'])\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 3,\n            '{:1.3f}%'.format(100*(height\/total)), ha=\"center\")","bbb51e8b":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(target_one['age'], color='orange')\nsns.distplot(target_zero['age'], color='blue')\nfig.legend(labels=['TARGET = 1', 'TARGET = 0'])\nplt.show()\nfig.tight_layout()","a06a3c46":"fig = plt.figure(figsize=(14, 4))\nax = sns.boxplot(x=\"age\", y=\"TARGET\", data=df, orient=\"h\")","df6567ed":"fig = plt.figure(figsize=(14, 4))\nax = df[df['TARGET'] == 1]['age'].value_counts().head(10).plot(kind='bar',color='orange')\ntotal = len(df[df['TARGET'] == 1]['age'])\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 0.5,\n            '{:1.3f}%'.format(100*(height\/total)), ha=\"center\")\n\nplt.title('Top 10 ages buying the new product')\nplt.xlabel('age')\nplt.ylabel('count')\nplt.show()","543d267f":"fig = plt.figure(figsize=(14, 4))\nax = df[df['TARGET'] == 0]['age'].value_counts().head(10).plot(kind='bar')\ntotal = len(df[df['TARGET'] == 0]['age'])\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 1,\n            '{:1.3f}%'.format(100*(height\/total)), ha=\"center\")\n\nplt.title('Top 10 ages not buying the new product')\nplt.xlabel('age')\nplt.ylabel('count')\nplt.show()","747e5e55":"fig = plt.figure(figsize=(14, 4))\nax = sns.countplot(df['LOR'], hue=df['TARGET'])\ntotal = len(df['LOR'])\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 3,\n            '{:1.3f}%'.format(100*(height\/total)), ha=\"center\")\n\nplt.title('Length of relationship vs TARGET')\nplt.show()","552784ab":"fig = plt.figure(figsize=(14, 4))\nax = sns.countplot(df['TARGET'], hue=df['prod_B'])\ntotal = len(df['TARGET'])\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 3,\n            '{:1.3f}%'.format(100*(height\/total)), ha=\"center\")\n\nplt.title('Prod_B vs TARGET')\nplt.show()","62bd2f26":"fig = plt.figure(figsize=(14, 4))\nsns.distplot(target_one['turnover_B'], color='orange')\nsns.distplot(target_zero['turnover_B'], color='blue')\nfig.legend(labels=['TARGET = 1', 'TARGET = 0'])\n\nplt.title('Turnover_B distribution per target value')\nplt.show()","fa5efa84":"fig = plt.figure(figsize=(14, 4))\nax = sns.boxplot(x=\"turnover_B\", y=\"TARGET\",\n                 data=df, orient=\"h\")\nplt.title('turnover_B distribution vs TARGET')\nplt.show()","dae50972":"fig = plt.figure(figsize=(14, 4))\nax = sns.countplot(df['TARGET'], hue=df['prod_A'])\ntotal = len(df['TARGET'])\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 3,\n            '{:1.3f}%'.format(100*(height\/total)), ha=\"center\")\n\nplt.title('Prod_A vs TARGET')\nplt.show()","b483cd79":"fig = plt.figure(figsize=(14, 4))\nsns.distplot(target_one['turnover_A'], color='orange')\nsns.distplot(target_zero['turnover_A'], color='blue')\nfig.legend(labels=['TARGET = 1', 'TARGET = 0'])\nplt.title('Turnover_A distribution per target value')\nplt.show()","68f71b63":"fig = plt.figure(figsize=(14, 4))\nax = sns.boxplot(x=\"turnover_A\", y=\"TARGET\",\n                 data=df, orient=\"h\")\n\nplt.title('Turnover_A distribution per target value')\nplt.show()","0b437d61":"fig = plt.figure(figsize=(12, 5))\nsns.scatterplot(x='ID', y='age', data=df, hue='TARGET')\nfig.tight_layout()\n","b9909a4f":"fig = plt.figure(figsize=(16, 4))\nsns.distplot(target_one['ID'], color='orange')\nsns.distplot(target_zero['ID'], color='blue')\nfig.legend(labels=['TARGET = 1', 'TARGET = 0'])\nplt.xticks(np.arange(min(df['ID'])-1, max(df['ID']), 10000))\nplt.show()","29fff0ff":"df_lower_id = df[(df['ID'] < 20000)]\ndf_higher_id = df[(df['ID'] > 20000)]","c309d41d":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(\n    2, 2, figsize=(12, 8), sharey=True,sharex=True)\n\nax1 = sns.distplot(df_lower_id[df_lower_id['TARGET'] == 0]['ID'], ax=ax1).set_title(\n    'ID = <20000; target = 0', fontweight=\"bold\", size=15)\nax2 = sns.distplot(df_lower_id[df_lower_id['TARGET'] == 1]['ID'], color='orange', ax=ax2).set_title(\n    'ID = <20000; target = 1', fontweight=\"bold\", size=15)\nax3 = sns.distplot(df_higher_id[df_higher_id['TARGET'] == 0]['ID'], ax=ax3).set_title(\n    'ID = >20000; target = 0', fontweight=\"bold\", size=15)\nax4 = sns.distplot(df_higher_id[df_higher_id['TARGET'] == 1]['ID'], color='orange', ax=ax4).set_title(\n    'ID = >20000; target = 1', fontweight=\"bold\", size=15)\nfig.tight_layout()","0fd9661a":"sns.jointplot(x='ID', y='age', data=df_lower_id,\n              color='blue', kind='kde')","c7ed8961":"sns.jointplot(x='ID', y='age', data=df_higher_id,\n              color='blue', kind='kde')","2f2ff79d":"prod_A_zero = df[df['prod_A'] == 0]\nprod_A_one = df[df['prod_A'] == 1]","e2abfc9f":"fig = plt.figure(figsize=(14, 4))\nax = sns.countplot(df['prod_A'], hue=df['TARGET'])\ntotal = len(df['prod_A'])\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 3,\n            '{:1.3f}%'.format(100*(height\/total)), ha=\"center\")\n\nplt.title('Prod_A vs TARGET')\nplt.show()","df2bdfe3":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(prod_A_one['age'], color='orange',bins=44)\nsns.distplot(prod_A_zero['age'], color='blue',bins=44)\nfig.legend(labels=['prod_A=1', 'prod_A=0'])\nfig.tight_layout()","d27f1c65":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(prod_A_one['turnover_B'], color='orange')\nsns.distplot(prod_A_zero['turnover_B'], color='blue')\nfig.legend(labels=['prod_A=1', 'prod_A=0'])\nfig.tight_layout()","c54d5bda":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(prod_A_one['turnover_A'], color='orange')\nsns.distplot(prod_A_zero['turnover_A'], color='blue')\nfig.legend(labels=['prod_A=1', 'prod_A=0'])\nfig.tight_layout()","241b4049":"fig=plt.figure(figsize=(14, 5))\nsns.distplot(prod_A_one['ID'], color='orange')\nsns.distplot(prod_A_zero['ID'], color='blue')\nfig.legend(labels=['prod_A=1', 'prod_A=0'])\nfig.tight_layout()","67cac24f":"fig = plt.figure(figsize=(14, 4))\nax = sns.countplot(df['prod_B'], hue=df['TARGET'])\ntotal = len(df['prod_B'])\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2., height + 3,\n            '{:1.3f}%'.format(100*(height\/total)), ha=\"center\")\n\nplt.title('Prod_B vs TARGET')\nplt.show()","572b3ae9":"prod_B_zero = df[df['prod_B'] == 0]\nprod_B_one = df[df['prod_B'] == 1]","df21dd00":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(prod_B_one['age'], color='orange',bins=44)\nsns.distplot(prod_B_zero['age'], color='blue',bins=44)\nfig.legend(labels=['prod_B=1', 'prod_B=0'])\nfig.tight_layout()","73cc2d73":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(prod_B_one['turnover_B'], color='orange')\nsns.distplot(prod_B_zero['turnover_B'], color='blue')\nfig.legend(labels=['prod_B=1', 'prod_B=0'])\nfig.tight_layout()","2710c2ed":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(prod_B_one['turnover_A'], color='orange')\nsns.distplot(prod_B_zero['turnover_A'], color='blue')\nfig.legend(labels=['prod_B=1', 'prod_B=0'])\nfig.tight_layout()","f9fe26d0":"fig = plt.figure(figsize=(14, 5))\nsns.distplot(prod_B_one['ID'], color='orange')\nsns.distplot(prod_B_zero['ID'], color='blue')\nfig.legend(labels=['prod_B=1', 'prod_B=0'])\nfig.tight_layout()","0c31ef7d":"sns.boxplot(x='TARGET', y='turnover_A', data=df)","74d5eb5e":"sns.jointplot(x='turnover_A', y='age',\n              data=df, color='blue', kind='kde')","6b3f4d43":"sns.jointplot(x='turnover_A', y='LOR',\n              data=df, color='blue', kind='kde')","8fc853df":"sns.jointplot(x='turnover_A', y='turnover_B',\n              data=df, color='blue', kind='kde')","98c35774":"sns.jointplot(x='turnover_A', y='ID', data=df,\n              color='blue', kind='kde')","132ffad1":"sns.jointplot(x='turnover_A', y='prod_B',\n              data=df, color='blue', kind='kde')","7324ff44":"sns.boxplot(x='TARGET', y='turnover_B', data=df)","2944025f":"df[df['TARGET'] == 1]['turnover_B'].median()","833e0571":"df[df['TARGET'] == 0]['turnover_B'].median()","2b1f6ad1":"sns.jointplot(x='turnover_A', y='age',\n              data=df, color='blue', kind='kde')","2393c04a":"sns.jointplot(x='turnover_A', y='LOR',\n              data=df, color='blue', kind='kde')","bbabdf36":"sns.jointplot(x='turnover_A', y='turnover_B',\n              data=df, color='blue', kind='kde')","5c84f69e":"sns.jointplot(x='turnover_A', y='ID', data=df,\n              color='blue', kind='kde')","1472288d":"sns.jointplot(x='turnover_A', y='prod_B',\n              data=df, color='blue', kind='kde')","9fc59aad":"plt.figure(figsize=(14, 5))\nax = sns.countplot(x=\"prod_B\", data=df, hue=df['prod_A'])\nplt.title('Relationship prod_A and prod_B')\n\ntotal = len(df['prod_B'])\n\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","f13bc64a":"sns.heatmap(df[['prod_B', 'prod_A']\n                             ].corr(), annot=True, cmap='coolwarm')","3e6f87da":"fig, axs = plt.subplots(nrows=3, figsize=(15, 10))\n\nsns.boxplot(x=\"age\", y=\"TARGET\", ax=axs[0],data=df, orient=\"h\").set_title('TARGET', fontweight=\"bold\", size=15)\nsns.boxplot(x=\"age\", y=\"prod_A\", ax=axs[1],data=df, orient=\"h\").set_title('prod_A', fontweight=\"bold\", size=15)\nsns.boxplot(x=\"age\", y=\"prod_B\", ax=axs[2],data=df, orient=\"h\").set_title('prod_B', fontweight=\"bold\", size=15)\nplt.tight_layout()","769ff010":"print(\"Median age of people not buying the target product is \" +  \n    str(df[df['TARGET'] == 0]['age'].median()))\nprint(\"Median age of people buying the target product is \" +\n      str(df[df['TARGET'] == 1]['age'].median()))\nprint('-'*30)\nprint(\"Median age of people not buying prod_A is \" +\n      str(df[df['prod_A'] == 0]['age'].median()))\nprint(\"Median age of people buying prod_A is \" +\n      str(df[df['prod_A'] == 1]['age'].median()))\nprint('-'*30)\nprint(\"Median age of people not buying prod_B is \" +\n      str(df[df['prod_B'] == 0]['age'].median()))\nprint(\"Median age of people buying prod_B is \" +\n      str(df[df['prod_B'] == 1]['age'].median()))","c21320d1":"plt.figure(figsize=(14, 5))\nsns.boxplot(x=\"TARGET\", y=\"age\", hue=\"prod_A\",\n            data=df, linewidth=2.5, orient='H')","118d8547":"plt.figure(figsize=(14, 5))\nsns.boxplot(x=\"TARGET\", y=\"age\", hue=\"prod_B\",\n            data=df, linewidth=2.5, orient='H')","5466ebe0":"g = sns.catplot(x=\"age\", y=\"TARGET\",\n                hue=\"LOR\", col=\"prod_A\",\n                data=df, kind=\"box\",\n                height=10, aspect=.7, orient='h')","ac5f353e":"g = sns.catplot(x=\"age\", y=\"TARGET\",\n                hue=\"LOR\", col=\"prod_B\",\n                data=df, kind=\"box\",\n                height=10, aspect=.7, orient='h')","42e9af0a":"cm_combo = df.corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(cm_combo, annot=True, cmap='coolwarm')","753eb958":"cm_X_combo = (df.drop('TARGET', axis=1)).corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(cm_X_combo, annot=True, cmap='coolwarm')","7fd59627":"# https:\/\/stackoverflow.com\/questions\/42658379\/variance-inflation-factor-in-python\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\nX_combo = add_constant(df)","17844642":"pd.Series([variance_inflation_factor(X_combo.values, i)\n           for i in range(X_combo.shape[1])],\n          index=X_combo.columns)\n\n# VIF of 5 or 10 and above indicates a multicollinearity problem.\n# If there is perfect correlation, then VIF = infinity.","6fb7e36a":"df_combo = df.drop('ID', axis=1)","fc97e464":"df_combo_1_LOR_0 = df_combo.drop('LOR', axis=1)\ndf_combo_L0_prod_A_0 = df_combo_1_LOR_0.drop('prod_A', axis=1)\ndf_combo_L0_prod_B_0 = df_combo_1_LOR_0.drop('prod_B', axis=1)\ndf_combo_L0_prod_A_B_0 = df_combo_1_LOR_0.drop(['prod_A', 'prod_B'], axis=1)","0cf7927e":"df_combo_1_LOR_1 = df_combo\ndf_combo_L1_prod_A_0 = df_combo.drop('prod_A', axis=1)\ndf_combo_L1_prod_B_0 = df_combo.drop('prod_B', axis=1)\ndf_combo_L1_prod_A_B_0 = df_combo.drop(['prod_A', 'prod_B'], axis=1)","e790aee1":"cm_df_combo_1_LOR_0 = df_combo_1_LOR_0.corr()\ncm_df_combo_L0_prod_A_0 = df_combo_L0_prod_A_0.corr()\ncm_df_combo_L0_prod_B_0 = df_combo_L0_prod_B_0.corr()\ncm_df_combo_L0_prod_A_B_0 = df_combo_L0_prod_A_B_0.corr()\n\ncm_df_combo_1_LOR_1 = df_combo_1_LOR_1.corr()\ncm_df_combo_L1_prod_A_0 = df_combo_L1_prod_A_0.corr()\ncm_df_combo_L1_prod_B_0 = df_combo_L1_prod_B_0.corr()\ncm_df_combo_L1_prod_A_B_0 = df_combo_L1_prod_A_B_0.corr()\n\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)\n      ) = plt.subplots(4, 2, figsize=(15, 20), sharey=True)\n\nsns.heatmap(cm_df_combo_1_LOR_0, annot=True, cmap='coolwarm', ax=ax1).set_title(\n    'cm_df_combo_1_LOR_0', fontweight=\"bold\", size=15)\nsns.heatmap(cm_df_combo_L0_prod_A_0, annot=True, cmap='coolwarm', ax=ax2).set_title(\n    'cm_df_combo_L0_prod_A_0', fontweight=\"bold\", size=15)\nsns.heatmap(cm_df_combo_L0_prod_B_0, annot=True, cmap='coolwarm', ax=ax3).set_title(\n    'cm_df_combo_L0_prod_B_0', fontweight=\"bold\", size=15)\nsns.heatmap(cm_df_combo_L0_prod_A_B_0, cmap='coolwarm', annot=True, ax=ax4).set_title(\n    'cm_df_combo_L0_prod_A_B_0', fontweight=\"bold\", size=15)\nsns.heatmap(cm_df_combo_1_LOR_1, annot=True, cmap='coolwarm', ax=ax5).set_title(\n    'cm_df_combo_1_LOR_1', fontweight=\"bold\", size=15)\nsns.heatmap(cm_df_combo_L1_prod_A_0, annot=True, cmap='coolwarm', ax=ax6).set_title(\n    'cm_df_combo_L1_prod_A_0', fontweight=\"bold\", size=15)\nsns.heatmap(cm_df_combo_L1_prod_B_0, annot=True, cmap='coolwarm', ax=ax7).set_title(\n    'cm_df_combo_L1_prod_B_0', fontweight=\"bold\", size=15)\nsns.heatmap(cm_df_combo_L1_prod_A_B_0, annot=True, cmap='coolwarm', ax=ax8).set_title(\n    'cm_df_combo_L1_prod_A_B_0', fontweight=\"bold\", size=15)\n\nfig.tight_layout()","c1fd0c50":"fig = plt.figure(figsize=(14, 5))\nax = sns.countplot(x=\"TARGET\", data=df_combo_L0_prod_B_0)\nplt.title('TARGET df_combo_L0_prod_B_0')\ntotal = len(df_combo_L0_prod_B_0['TARGET'])\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","ae842d9a":"fig = plt.figure(figsize=(14, 5))\nax = df_combo_L0_prod_B_0.corr()['TARGET'][1:].sort_values().plot(kind='bar')\nplt.title('TARGET df_combo_L0_prod_B_0')\ntotal = len(df_combo_L0_prod_B_0.corr()['TARGET'][1:].sort_values())\nfor p in ax.patches:\n    height = p.get_height()\n\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 0,\n            '{:1.3f}%'.format(100*(height\/total)),\n            ha=\"center\")","6b9bb50f":"df_alpha_B = df_combo_L0_prod_B_0","1d6eadee":"df_alpha_B['age']=np.log(df_alpha_B['age'])","bf075b40":"X = df_alpha_B.drop('TARGET', axis=1).values\ny = df_alpha_B['TARGET'].values","128651ff":"from sklearn.model_selection import train_test_split","e09c7aa2":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=101)","a49f5712":"from sklearn.preprocessing import MinMaxScaler","13c3b033":"scaler = MinMaxScaler()","549610c3":"scaler.fit(X_train)","744a8182":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","11af31ba":"from sklearn.linear_model import LogisticRegression\n\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train, y_train)","2b6bfd4a":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","a3d1f9b9":"training_predictions = logmodel.predict(X_train)","0c85f7a6":"print(classification_report(y_train, training_predictions))","13ce51f7":"print(confusion_matrix(y_train, training_predictions))","738d74cc":"plot_confusion_matrix(logmodel, X_train, y_train)","d1b5cfec":"test_predictions = logmodel.predict(X_test)","d5c00a23":"print(classification_report(y_test, test_predictions))","c74c93be":"# Remember:\n# 72.674% didn't buy the new product\n# 27.326% bought ..","8e1fdccd":"print(confusion_matrix(y_test, test_predictions))","f1803a71":"# TN FN\n# FP TP\n\n# -TP times the model predicts correctly that a customer will buy TARGET\n# -FP times the model predicts icorrectly that a customer will buy TARGET\n# -FN times the model predicts incorrectly that a customer won't buy TARGET, while he did buy it\n# -TN times the model predicts correctly that a customer does not buy TARGET","9dbb7801":"plot_confusion_matrix(logmodel, X_test, y_test)","60695ccb":"sns.countplot(df_alpha_B['TARGET'])","2fed3e13":"df_alpha_B.shape","375a9ba1":"X = df_alpha_B.drop('TARGET', axis=1).values\ny = df_alpha_B['TARGET'].values","f6fa8e92":"from imblearn.over_sampling import RandomOverSampler","fb431410":"# define oversampling strategy\noversample = RandomOverSampler(sampling_strategy='minority')","027e98e6":"# fit and apply the transform\nX_over, y_over = oversample.fit_resample(X, y)","63398ba2":"from collections import Counter","ec09666c":"# summarize class distribution\nprint(Counter(y))","a8561d4b":"# summarize class distribution\nprint(Counter(y_over))","96aeb0f6":"fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\nsns.countplot(df_alpha_B['TARGET'], ax=ax1).set_title('Before')\nsns.countplot((y_over), ax=ax2).set_title('After')","0c9bb1e5":"X = X_over\ny = y_over","8404588b":"from sklearn.model_selection import train_test_split","101566c1":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=101)","ab837259":"from sklearn.preprocessing import MinMaxScaler","4070a13e":"scaler = MinMaxScaler()","384286c9":"scaler.fit(X_train)","d611428a":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","8aa0032b":"from sklearn.linear_model import LogisticRegression\n\nlogmodel_over = LogisticRegression()\nlogmodel_over.fit(X_train, y_train)","1ea9c7a4":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","24c547c4":"training_predictions = logmodel_over.predict(X_train)","cdd185ba":"print(classification_report(y_train, training_predictions))","ef8acc3f":"print(confusion_matrix(y_train, training_predictions))","0196f857":"plot_confusion_matrix(logmodel_over, X_train, y_train)","7003ca1b":"test_predictions = logmodel_over.predict(X_test)","12b5cf98":"print(classification_report(y_test, test_predictions))","eb2faa6f":"print(confusion_matrix(y_test, test_predictions))","6a9038b3":"plot_confusion_matrix(logmodel_over, X_test, y_test)","d7cfdeb5":"sns.countplot(df_alpha_B['TARGET'])","4e64953f":"df_alpha_B.shape","2fec8feb":"X = df_alpha_B.drop('TARGET', axis=1).values\ny = df_alpha_B['TARGET'].values","545b4ecd":"from imblearn.under_sampling import RandomUnderSampler","f47f522e":"# define undersampling strategy\noversample = RandomUnderSampler(sampling_strategy='majority')","f4751720":"# fit and apply the transform\nX_over, y_over = oversample.fit_resample(X, y)","cc113e40":"from collections import Counter","14419bd2":"# summarize class distribution\nprint(Counter(y))","39a42cea":"# summarize class distribution\nprint(Counter(y_over))","40144ccd":"fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\nsns.countplot(df_alpha_B['TARGET'], ax=ax1).set_title('Before')\nsns.countplot((y_over), ax=ax2).set_title('After')","29b9e4fe":"X = X_over\ny = y_over","3236473d":"from sklearn.model_selection import train_test_split","9a84c58e":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=101)","944843af":"from sklearn.preprocessing import MinMaxScaler","ed227d6c":"scaler = MinMaxScaler()","dbe9cea2":"scaler.fit(X_train)","3e2abad3":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","2fbae270":"from sklearn.linear_model import LogisticRegression\n\nlogmodel_under = LogisticRegression()\nlogmodel_under.fit(X_train, y_train)","46bc7b2e":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","31dd66ae":"training_predictions = logmodel_under.predict(X_train)","22765078":"print(classification_report(y_train, training_predictions))","63961f56":"print(confusion_matrix(y_train, training_predictions))","ff30d84b":"plot_confusion_matrix(logmodel_under, X_train, y_train)","897a19e8":"test_predictions = logmodel_under.predict(X_test)","de609c53":"print(classification_report(y_test, test_predictions))","a815676c":"print(confusion_matrix(y_test, test_predictions))","dc5e8e44":"plot_confusion_matrix(logmodel_under, X_test, y_test)","d5abb88d":"X = df_alpha_B.drop('TARGET', axis=1).values\ny = df_alpha_B['TARGET'].values","173c622b":"from sklearn.model_selection import train_test_split","b81d56e9":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=101)","55d65613":"from sklearn.preprocessing import MinMaxScaler","cbca1cec":"scaler = MinMaxScaler()","645d6592":"scaler.fit(X_train)","b4df920d":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","a8b06bb6":"from sklearn.svm import SVC","861d97a8":"svc_model = SVC()","6d72ab3a":"svc_model.fit(X_train, y_train)","db46c615":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","6abcabfe":"training_predictions = svc_model.predict(X_train)","40534d46":"print(classification_report(y_train, training_predictions))","27bb372b":"print(confusion_matrix(y_train, training_predictions))","d5d3a534":"plot_confusion_matrix(svc_model, X_train, y_train)","95e89dbb":"test_predictions = svc_model.predict(X_test)","75167b65":"print(classification_report(y_test, test_predictions))","7626cfa6":"print(confusion_matrix(y_test, test_predictions))","d022ef88":"plot_confusion_matrix(svc_model, X_test, y_test)","38969703":"sns.countplot(df_alpha_B['TARGET'])","d201eaf5":"df_alpha_B.shape","f10e4341":"X = df_alpha_B.drop('TARGET', axis=1).values\ny = df_alpha_B['TARGET'].values","0c2eb857":"from imblearn.over_sampling import RandomOverSampler","38b5c1fd":"# define oversampling strategy\noversample = RandomOverSampler(sampling_strategy='minority')","652df007":"# fit and apply the transform\nX_over, y_over = oversample.fit_resample(X, y)","052c30f3":"from collections import Counter","dac205aa":"# summarize class distribution\nprint(Counter(y))","172ae866":"# summarize class distribution\nprint(Counter(y_over))","b6a4b2e0":"fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\nsns.countplot(df_alpha_B['TARGET'], ax=ax1).set_title('Before')\nsns.countplot((y_over), ax=ax2).set_title('After')","655b7487":"X = X_over\ny = y_over","218b52ae":"from sklearn.model_selection import train_test_split","92f177e0":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=101)","19b58855":"from sklearn.preprocessing import MinMaxScaler","fbd190ef":"scaler = MinMaxScaler()","afbe142e":"scaler.fit(X_train)","9fc9321c":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","14472ee5":"from sklearn.svm import SVC","6643de91":"SVM_over = SVC()","ee0d0def":"SVM_over.fit(X_train, y_train)","86d816f3":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","76aa1e56":"training_predictions = SVM_over.predict(X_train)","f1edb4af":"print(classification_report(y_train, training_predictions))","51a182b2":"print(confusion_matrix(y_train, training_predictions))","cdef711d":"plot_confusion_matrix(SVM_over, X_train, y_train)","079a3dad":"test_predictions = SVM_over.predict(X_test)","6bba327b":"print(classification_report(y_test, test_predictions))","5f8c0035":"print(confusion_matrix(y_test, test_predictions))","6de4e0c1":"plot_confusion_matrix(SVM_over, X_test, y_test)","84baf703":"sns.countplot(df_alpha_B['TARGET'])","251d4580":"df_alpha_B.shape","d0512473":"X = df_alpha_B.drop('TARGET', axis=1).values\ny = df_alpha_B['TARGET'].values","bf231c4d":"from imblearn.under_sampling import RandomUnderSampler","1aca066f":"# define undersampling strategy\noversample = RandomUnderSampler(sampling_strategy='majority')","7b1ff966":"# fit and apply the transform\nX_over, y_over = oversample.fit_resample(X, y)","66e8bd32":"from collections import Counter","ddd73d8f":"# summarize class distribution\nprint(Counter(y))","d73ddadf":"# summarize class distribution\nprint(Counter(y_over))","413e1cf7":"fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\nsns.countplot(df_alpha_B['TARGET'], ax=ax1).set_title('Before')\nsns.countplot((y_over), ax=ax2).set_title('After')","59e3a2e9":"X = X_over\ny = y_over","9799cb63":"from sklearn.model_selection import train_test_split","e77b7dee":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=101)","d5640290":"from sklearn.preprocessing import MinMaxScaler","942ed570":"scaler = MinMaxScaler()","16ec0897":"scaler.fit(X_train)","ed0042f0":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","131e8bb6":"from sklearn.svm import SVC","de82432c":"SVM_under = SVC()","5022ca7a":"SVM_under.fit(X_train, y_train)","6b5ad834":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","13ee3d2e":"training_predictions = SVM_under.predict(X_train)","b8303146":"print(classification_report(y_train, training_predictions))","5873e6a4":"print(confusion_matrix(y_train, training_predictions))","fdfd36a6":"plot_confusion_matrix(SVM_under, X_train, y_train)","14c7060b":"test_predictions = SVM_under.predict(X_test)","11f546ea":"print(classification_report(y_test, test_predictions))","539dc6fe":"print(confusion_matrix(y_test, test_predictions))","016a6250":"plot_confusion_matrix(SVM_under, X_test, y_test)","2263851b":"# pip install -U imbalanced-learn\n# https:\/\/machinelearningmastery.com\/random-oversampling-and-undersampling-for-imbalanced-classification\/\n# check version number\nimport imblearn\nprint(imblearn.__version__)\n","982b5d13":"sns.countplot(df_alpha_B['TARGET'])","c93a9fe5":"df_alpha_B.shape","f64bed49":"X = df_alpha_B.drop('TARGET', axis=1).values\ny = df_alpha_B['TARGET'].values","d0e34446":"from imblearn.over_sampling import RandomOverSampler","a4fe524b":"# define oversampling strategy\noversample = RandomOverSampler(sampling_strategy='minority')","e0c20318":"# fit and apply the transform\nX_over, y_over = oversample.fit_resample(X, y)","eb9eb6a7":"from collections import Counter","cc8e0b2c":"# summarize class distribution\nprint(Counter(y))","96997cd9":"# summarize class distribution\nprint(Counter(y_over))","535c4452":"fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\nsns.countplot(df_alpha_B['TARGET'], ax=ax1).set_title('Before')\nsns.countplot((y_over), ax=ax2).set_title('After')","6d1a8f80":"X = X_over\ny = y_over","955cdfe2":"from sklearn.model_selection import train_test_split","92eefdbb":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=101)","daf97892":"from sklearn.preprocessing import MinMaxScaler","5c8c8cdb":"scaler = MinMaxScaler()","ad0ab79b":"scaler.fit(X_train)","6c06e644":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","f8072f95":"from sklearn.ensemble import RandomForestClassifier","1ec9ab0c":"RFC_over = RandomForestClassifier(n_estimators=600)","391d64f4":"RFC_over.fit(X_train,y_train)","f53bc422":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","50eb7ac8":"training_predictions = RFC_over.predict(X_train)","59f3c4c3":"print(classification_report(y_train, training_predictions))","9eb8beff":"print(confusion_matrix(y_train, training_predictions))","1998bfc5":"plot_confusion_matrix(RFC_over, X_train, y_train)","f6723e6f":"test_predictions = RFC_over.predict(X_test)","913394d6":"print(classification_report(y_test, test_predictions))","dcb670ce":"print(confusion_matrix(y_test, test_predictions))","05f6e9aa":"plot_confusion_matrix(RFC_over, X_test, y_test)","f66d9686":"sns.countplot(df_alpha_B['TARGET'])","ac9ff5c1":"df_alpha_B.shape","115b5374":"X = df_alpha_B.drop('TARGET', axis=1).values\ny = df_alpha_B['TARGET'].values","a2bd09f2":"from imblearn.under_sampling import RandomUnderSampler","297c2d6e":"# define undersampling strategy\noversample = RandomUnderSampler(sampling_strategy='majority')","832d30b8":"# fit and apply the transform\nX_over, y_over = oversample.fit_resample(X, y)","74ac3f51":"from collections import Counter","3e6132ac":"# summarize class distribution\nprint(Counter(y))","b9eecfcb":"# summarize class distribution\nprint(Counter(y_over))","d22c91ec":"fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\nsns.countplot(df_alpha_B['TARGET'], ax=ax1).set_title('Before')\nsns.countplot((y_over), ax=ax2).set_title('After')","ce987b8a":"X = X_over\ny = y_over","0855802b":"from sklearn.model_selection import train_test_split","a6a689ff":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=101)","ae1468cd":"from sklearn.preprocessing import MinMaxScaler","e3e5c57c":"scaler = MinMaxScaler()","59274b84":"scaler.fit(X_train)","b124ab74":"X_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","d264c37d":"from sklearn.ensemble import RandomForestClassifier","46c6a233":"RFC_under = RandomForestClassifier(n_estimators=600)","c7c47cf8":"RFC_under.fit(X_train,y_train)","be030bd6":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","8b55b2a4":"training_predictions = RFC_under.predict(X_train)","7f9d9842":"print(classification_report(y_train, training_predictions))","653770a9":"print(confusion_matrix(y_train, training_predictions))","46b465c3":"plot_confusion_matrix(RFC_under, X_train, y_train)","8f5bab7a":"test_predictions = RFC_under.predict(X_test)","11c5b2b9":"print(classification_report(y_test, test_predictions))","9dca6edc":"print(confusion_matrix(y_test, test_predictions))","df3efcb1":"plot_confusion_matrix(RFC_under, X_test, y_test)","81822c74":"from sklearn.metrics import f1_score, recall_score","6ea71689":"original_dataset = pd.read_csv('\/kaggle\/input\/insurance-company\/Customer_data.csv')","c8ccae49":"original_dataset = original_dataset.drop(['loyalty', 'ID', 'city',\n                                          'LOR', 'prod_A', 'type_A',\n                                          'type_B', 'contract', 'age_P','lor_M'],axis=1)","5a71e02e":"original_dataset.columns","d94a23ea":"original_dataset['age']=np.log(original_dataset['age'])","f2915f35":"X_test = original_dataset.drop('TARGET', axis=1).values\ny_test = original_dataset['TARGET'].values","e828ad42":"from sklearn.preprocessing import MinMaxScaler","c194d3a5":"scaler = MinMaxScaler()","1761df58":"scaler.fit(X_test)","e8923f4c":"X_test = scaler.transform(X_test)","d7df3cbf":"print(type(X_test))\nprint(len(X_test))\nprint(X_test.shape)","392c20f4":"print(type(y_test))\nprint(len(y_test))\nprint(y_test.shape)","c84a9935":"y_test","2e2f5e64":"df_y_test = pd.DataFrame(data=y_test, columns=[\"true_values\"])","8a527418":"def replace_yn(target):\n    for t in target:\n        if t == 'Y':\n            return int(1)\n        else:\n            return int(0)\n\n\ndf_y_test['true_values'] = df_y_test['true_values'].apply(replace_yn)","78de86fc":"df_y_test.values","6304b2fd":"y_test = df_y_test.values","930d91bb":"test_predictions_logmodel_over = logmodel_over.predict(X_test)","198c8212":"print('1. The F-1 score of the model {}\\n'.format(f1_score(y_test, test_predictions_logmodel_over, average='macro')))\nprint('2. The recall score of the model {}\\n'.format(recall_score(y_test, test_predictions_logmodel_over, average='macro')))\nprint('3. Classification report \\n {} \\n'.format(classification_report(y_test, test_predictions_logmodel_over)))\nprint('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(y_test, test_predictions_logmodel_over)))","689aa7be":"plot_confusion_matrix(logmodel_over, X_test, y_test,normalize='true')","b54f013d":"plot_confusion_matrix(logmodel_over, X_test, y_test)","3c73955e":"test_predictions_logmodel_under = logmodel_under.predict(X_test)","3f1e05e9":"print('1. The F-1 score of the model {}\\n'.format(f1_score(y_test, test_predictions_logmodel_under, average='macro')))\nprint('2. The recall score of the model {}\\n'.format(recall_score(y_test, test_predictions_logmodel_under, average='macro')))\nprint('3. Classification report \\n {} \\n'.format(classification_report(y_test, test_predictions_logmodel_under)))\nprint('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(y_test, test_predictions_logmodel_under)))","a45dcf35":"plot_confusion_matrix(logmodel_under, X_test, y_test,normalize='true')","a024557f":"plot_confusion_matrix(logmodel_under, X_test, y_test)","37243948":"test_predictions_svm_over = SVM_over.predict(X_test)","19a235d0":"print('1. The F-1 score of the model {}\\n'.format(f1_score(y_test, test_predictions_svm_over, average='macro')))\nprint('2. The recall score of the model {}\\n'.format(recall_score(y_test, test_predictions_svm_over, average='macro')))\nprint('3. Classification report \\n {} \\n'.format(classification_report(y_test, test_predictions_svm_over)))\nprint('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(y_test, test_predictions_svm_over)))","c9d22d5f":"plot_confusion_matrix(SVM_over, X_test, y_test,normalize='true')","5d924c25":"plot_confusion_matrix(SVM_over, X_test, y_test)","ae48be41":"test_predictions_svm_under = SVM_under.predict(X_test)","655be76b":"print('1. The F-1 score of the model {}\\n'.format(f1_score(y_test, test_predictions_svm_under, average='macro')))\nprint('2. The recall score of the model {}\\n'.format(recall_score(y_test, test_predictions_svm_under, average='macro')))\nprint('3. Classification report \\n {} \\n'.format(classification_report(y_test, test_predictions_svm_under)))\nprint('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(y_test, test_predictions_svm_under)))","8e84cd15":"plot_confusion_matrix(SVM_under, X_test, y_test,normalize='true')","91c28f79":"plot_confusion_matrix(SVM_under, X_test, y_test)","f0a1eaf9":"test_predictions_RFC_over = RFC_over.predict(X_test)","cf4724b2":"print('1. The F-1 score of the model {}\\n'.format(f1_score(y_test, test_predictions_RFC_over, average='macro')))\nprint('2. The recall score of the model {}\\n'.format(recall_score(y_test, test_predictions_RFC_over, average='macro')))\nprint('3. Classification report \\n {} \\n'.format(classification_report(y_test, test_predictions_RFC_over)))\nprint('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(y_test, test_predictions_RFC_over)))","1aedb236":"plot_confusion_matrix(RFC_over, X_test, y_test,normalize='true')","9f8c0707":"plot_confusion_matrix(RFC_over, X_test, y_test)","d7a138a9":"test_predictions_RFC_under = RFC_under.predict(X_test)","89f8a810":"print('1. The F-1 score of the model {}\\n'.format(f1_score(y_test, test_predictions_RFC_under, average='macro')))\nprint('2. The recall score of the model {}\\n'.format(recall_score(y_test, test_predictions_RFC_under, average='macro')))\nprint('3. Classification report \\n {} \\n'.format(classification_report(y_test, test_predictions_RFC_under)))\nprint('4. Confusion matrix \\n {} \\n'.format(confusion_matrix(y_test, test_predictions_RFC_under)))","f536096e":"plot_confusion_matrix(RFC_under, X_test, y_test,normalize='true')","b5c4b65b":"plot_confusion_matrix(RFC_under, X_test, y_test)","21b4e0ef":"### Predictions RFC over","7022eefa":"2. Measure of success of prediction\n\n![image.png](attachment:image.png)","02715a52":"### df_combo","ee738951":"Findings: <br>\n<ul>\n<li>**contract** = constant variable =  no information<br>\n<\/li> \n<li>**prod_A and type_A** have correlation of 1 = redundant<br>\n<\/li>  \n<li>**age and age_p** have a correlation of 1 = duplicate<br>\n<\/li>   \n<li>**LOR and lor_M** have a correlation of 1 = duplicate<br>\n<\/li>   \n<li>**ID** is highly correlated with TARGET<br>\n<\/li>  \n<li>**Loyalty** is highly correlated with prod_A\/Type_A and prod_B\/Type A<br>\n<\/li>   \n<li>**Loyalty** is highly correlated with LOR and thus also lor_M<\/li> \n<\/ul>\n<\/li>   \n<li>collinearity (independent variables are correlated)<\/li> \n<\/ul>\n","0363d96a":"## prod_B","3951ed88":"### Right skewed distribution\n\n#### Effects of skewness\n\nReal life distributions are usually skewed. If there are too much skewness in the data, then many statistical model don\u2019t work but why.\n\nSo in skewed data, the tail region may act as an outlier for the statistical model and we know that outliers adversely affect the model\u2019s performance. There are statistical model that are robust to outlier like a Tree-based models but it will limit the possibility to try other models. So there is a necessity to transform the skewed data to close enough to a Gaussian distribution or Normal distribution. This will allow us to try more number of statistical model.\n\n","aff165d0":"* Clients with an ID<20000 almost never buy the target.\n* Only data where target = 0 is for ID<20000\n* You can say, why not drop ID column all along? But I look into it for perhaps feature engineering\/extra information.","8a32fd20":"#### Standard confusion matrix","9e352a2b":"#### Model performance on test dataset","f0e49cab":"# Exploration of dataset structure and description ","cc13c868":"### Predictions RFC under","382b56d8":"## SVM","6d7ce535":"* Mean and median closer to each other\n* Distribution closer to normal (see kurt and skew) -> model works best with normal dist","3a4a8775":"#### Model performance on train dataset","af29045e":"### Effect of removing turnover A > 400","ca80b536":"\n#### Scaling Data","9ae64238":"\n#### Scaling Data","fff3ce4f":"## City \n\n* 98% clients city \"2\"\n* Quasi constant variable\n* Remove column","c1d7f6c4":"### Training on imbalanced datasets","ce4ac2fd":"#### Normalized confusion matrix","6256886a":"###  Isolating ID>20000","cce11ee6":"\n#### Scaling Data","d9232da6":"### relation between loyalty and LOR ","7c37acfc":"#### Scaling Data","ba47bcbe":"### Target distribution ID\n\n![image.png](attachment:image.png)","8c0ad62c":"### Correlation matrix per dataframe","c8a06901":"#### Standard confusion matrix","e88ebc30":"## ID (after removing duplicate ID samples)","8a3dc6a4":"## SVM: Support vector machine","7a444b57":"### Remove predictors which the model does not know","34e74ee8":"## TARGET","469b5cbd":"\n#### Scaling Data","d5b0f631":"### Training on imbalanced datasets","ee95c4f8":"#### Creating and training a RF model\n             ","f42edda5":"* \"Knowing your data isn't the most difficult thing in data science, but it is time-consuming.\"\n* \"It's easy to overlook this initial step and jump too soon into the water. Learn how to swim before jumping into the water.\"\n\nIn order to understand the data, we can look at each variable and try to understand their meaning and relevance to the problem.\n\n1. <b>Univariable study<\/b>. Tocus on the dependent variable ('TARGET') and try to know a little bit more about it.\n2. <b>Multivariate study<\/b>. Ttry to understand how the dependent variable and independent variables relate.\n","2b875f4c":"* Looks like they are valid outliers (inverse exponential drop in turnover_A).","122523f4":"#### Model performance on train dataset","973f35d7":"## ID","11f27964":"#### Predictions and Evaluations","c6c21545":"#### VIF: Variance inflation factor \n\n* helps a formal detection-tolerance for multicollinearity. VIF of 5 or 10 and above (depends on the business problem) indicates a multicollinearity problem.","579aa483":"# Predictions on original dataset","d5ebd687":"### Predictions SVM_over","e3724691":"#### Creating and training a RF model\n             ","90ec3d4c":"#### Predictions and Evaluations","0407f4f4":"* LOR, prod_A, prod_B give colinearity","77f3e79a":"Duplicate of age","f3e295cf":"# Analyze, identify patterns, and explore the data","79464f8a":"* Median for target = 1","ee761c78":"## LOR \n\nLength of the relationship in years between the person and the insurance company","6af59dc9":"#### Model performance on test dataset","f3807192":"* Median for target = 0","9e6c98e9":"![image.png](attachment:image.png)","f8215d34":"* 75% of the turnover_A < ~392","0cb58cbf":"## Loyalty ","a476f0d5":"<ul>\n<li>Findings <b>before<\/b> removing duplicate ID's: 49.843% unclassified <\/li> \n<li>Findings <b>after<\/b> removing duplicate ID's: 45.858% unclassified<\/li> \n<\/ul>\n\n\n\n","63021a08":"#### Predictions and Evaluations","112696be":"## Logistic regression","6e264cc4":"## Contract","ac4d5e80":"### Predictions logmodel_under","84081d23":"### Distribution per target value","f79714ee":"## Random forest\n\nOnly train on over and undersampled datasets","7f245661":"#### Standard confusion matrix","6c2d317e":"### Training on oversampled datasets\n\n","ab7bab59":"## Performance metrics\n\n1. Confussion matrix: to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n\n<img src=\"attachment:image.png\" width=\"700\">","7b30d371":"#### Model performance on test dataset","517df971":"#### Normalized confusion matrix","7ac21df7":"### Training on undersampled datasets","d048f2a4":"* Majority has low ID, was the experiment done on loyal\/long time members of the company?","1027c3cd":"### Create left side flowchart","612cf9f3":"* situation 0: (A=0,B=0) \n* sit 1: (A=1,B=0)\n* sit 2: (A=0,B=1) \n* sit 3: (A=1,B=1) ","5f178081":"* Most unclassified samples are LOR 0, unfortunatly there are no LOR 0 voor the classified and thus we can't impute based on that.","910a1a6d":"#### Creating and training a SVM model\n             ","cd765502":"#### Standard confusion matrix","8b07649b":"* 75% of the turnover_B < ~252","5f75495c":"#### Train Test Split","c7ab7bfb":"* Improved skew and kurt and mean closer to median","7d9c8d29":"![image.png](attachment:image.png)","51b56df9":"###  Isolating ID<20000 and ID>20000","a1379865":"### Check for duplicates","a21561ad":"#### Model performance on train dataset","ba74e615":"#### Creating and training a SVM model\n             ","78a5ea3d":"## Age_P \n\n* Duplicate of age (confirmed by insurance company)","f0e77029":"### X and y","47066f28":"###  Isolating ID<20000","8c979948":"### Scaling Data","e714f825":"#### Model performance on test dataset","2a485f6a":"## turnover_A","5fac4adb":"## Logistic regression","644b048e":"#### Standard confusion matrix","d44ecdff":"#### Normalized confusion matrix","ba978b3e":"#### Predictions and Evaluations","37d31308":"### Create right side flowchart","d12826d7":"Constant variable","372f4ff3":"## Age","38291ded":"#### Log transformation \n\nA log transformation can help to fit a very skewed distribution into a more Gaussian one. \n\nWon't do df['age'] = np.log(df['age']) yet! Will do it after analysis and right before modeling.","cc70249a":"## Excluding colinearities\n\nCreate different dataframes to exclude colinearities and have highest correlation with target.","d66ac04f":"### Training on oversampled datasets","e96aa576":"## Shape and datatypes","e70d8566":"\n#### Scaling Data","40f86820":"\n#### Scaling Data","0111b73c":"#### Predictions and Evaluations","7ca224fb":"![image.png](attachment:image.png)","658188c0":"# Problem definition \n\nAn insurance company wants to identify customers willing to buy a new product. They gathered data about customers to whom they offered the new product. You get information about whether they did or did not sign up for the new product, together with some customer information and information about their buying behavior of two other products.","f19eea58":"<b>~72%<\/b> of samples are target = 0 and ID smaller than 20000 ","5d3f8efd":"-df_alpha_B trained with oversampled data gave the best performing SVM performance (7.2.2.11)\n\n* The model uses variables: 'age', 'prod_B', 'turnover_A', 'turnover_B' to make predictions.","654d1860":"## Lor_M \n\n* ~duplicate with LOR\n* Length of the relationship in months between the person and the insurance company\n* For both lor_M and LOR we have 7 categories\n* LOR has lower values, which are better for modeling later on\n* Feedback:  als een export van de gegevens wordt gedaan wordt de LOR berekend.\n* Remove lor_M column","5bafaee7":"## Checklist\n\n* Missing data\n* Outliers <br> \n* Duplicates<br>\n* Constant variables<br> \n* Quasi - constant variables <br>\n* Correlation = same information <br>\n* Redundancy<br> \n* Distribution<br> \n* Turn labels\/strings in categorical variables into numeric data<br> \n* Rare labels<br> \n* Feature magnitude - scale","52d95e30":"-df_alpha_A trained with oversampled data gave the best performing random forest (7.3.1.4)\n\n* The model uses variables: 'age', 'prod_B', 'turnover_A', 'turnover_B' to make predictions.","6c9e8850":"#### Model performance on test dataset","39f98aa2":"### X\n\nCheck for Multicollinearity (independent variables are correlated)\n\nMulticollinearity is a statistical phenomenon in which two of more explanatory variables in a regression model are strongly correlated, which means that one of them can be predicted based on the model. Multicollinearity affects the calculation of the coefficients, as they at least overlap in that case, and thus reduces their reliability.","7ffeb385":"#### Train Test Split","c4ba174d":"#### Predictions and Evaluations","9c8742bd":"* 22% of the samples are people with the age of 23   \n* 20% of the samples are people with the age of 23 AND target = 0 \n* 1.3% of the samples are people with the age of 23 AND target = 1  \n* The mayoritygroup in the dataset is very unlikely to inscribe for TARGET\n* TARGET = 1 mean age = 39.68 \n* TARGET = 1 median age = 38.0","13ea7664":"## Overview per variable","5f1ed51a":"### Load original dataset","a1d0c8d9":"## prod_A","185a3a1a":"### Pairplots","0d9d74e4":"### Effect of removing both turnover  B > 260 and A > 400 \n\n* Temporarily df ","fc68ce5a":"### Statistics","69355807":"#### Creating and training a logistic regression model\n             ","e6048c19":"### Training on undersampled datasets\n\n![image.png](attachment:image.png)\n","7ad13d8c":"### Predictions SVM_over","71853e67":"### X and y","3d2e7a99":"### Rename\n\n* df_combo_L0_prod_B_0 = df_alpha_B","5362da77":"###  Impact on samples\n\n* For removing both turnover_A and _B tail","2c304797":"\n#### Scaling Data","f69e620f":"#### Train Test Split","ce59b0a8":"## Correlation matrix\n* X = independent variables\n* y = dependent variable (TARGET)","49ba9ab3":"#### Unclassified loyalty","5b73fa33":"#### VIF: Variance inflation factor \n\n* helps a formal detection-tolerance for multicollinearity. VIF of 5 or 10 and above (depends on the business problem) indicates a multicollinearity problem.","6d057835":"## Correlation matrix before modeling","101aef98":"#### Predictions and Evaluations","c517e6b4":"## Target (after removing duplicate ID samples)","4d90d63a":"# Modeling and predictions\n\nTechniques:\n\n* Logistic regression\n* SVM\n* Random forest\n\nTo do:\n\n* KNN\n* K-fold CV\n* PCA\n","ca9525af":"## Turnover_A","16d937d3":"## prod_A","eff43e5e":"#### Train Test Split","77648565":"#### Train Test Split","1d805bad":"* For prod_B = 0, loyalty is only unclassified, so no imputation possible via prod_B. High correlation between loyalty and prod_B also caused because 70% unclassified is LOR 0 and LOR 0 are mainly the people not buying prod_B.\n* Decided to drop the loyalty variable, to many unclassified and no good imputation possible.","571c4ab3":"### The chosen one\n\nNo collinearity and highest correlation with target for:\n\n* df_combo_L0_prod_B_0","ac9b917b":"# Collecting raw data and importing libraries\n\n","3356c6dd":"## Turnover_B","3352de0e":"### Training on oversampled datasets\n\n","0da1f9fc":"### Noteworthy\n\n* loyalty: mayority unclassified (99) - correlated with another feature? otherwise remove entirely.\n* city: code -999999 must be an error, resulting in outlier, messing up the city statistics\n* turnover_A: mean 379.16, max 5568.78, outliers?\n* turnover_B: mean 328.62, max 12249.08, outliers?","aff18361":"#### Classified loyalty","541c5888":"#### Model performance on test dataset","036ac1f1":"#### Train Test Split","c6788729":"#### Train Test Split","654321f2":"### Predictions logmodel_over","fd2b42b9":"### Seperate predictors and target","3e6fee75":"#### Model performance on train dataset","e3057c14":"#### Creating and training a logistic regression model\n             ","dff5c2d7":"<ul>\n<li>Findings <b>before<\/b> removing duplicate ID's : <br>57% didn't buy the new product <br>43% bought the new product<br><br><\/li> \n<li>Findings <b>after<\/b> removing duplicate ID's: <br>73% didn't buy the new product <br>27% bought the new product<br><br><\/li>     \nIncrease in imbalance (will reduce model performance).\n\n\n\n\n\n","47fbc95f":"# Feature engineering \/ data cleaning","7f51d997":"#### Model performance on train dataset","bdcf2fe7":"#### Creating and training a logistic regression model\n             ","73b8a0ad":"## type_A \n\n* ~duplicate information about prod_A \n* type_A = 6 barely bought","a51f385e":"## Target","c22e94e9":"### Training on undersampled datasets","db000f77":"### age 20000 < ID < 175000","f4d9c111":"## ID","f66cb628":"6016 rows, thus 3008 rows are a duplicate of an ID.","7b8edb3f":"#### Standard confusion matrix","53ce7e2a":"#### Model performance on train dataset","29f0aef6":"##  turnover_B","fba9af26":"#### Model performance on train dataset","fc63746e":"## Relation prod_A - prod_B","28e0b7e1":"* Prone to overfitting. The effect can be better performance on the training dataset, but worse performance on the holdout or test dataset.","29d022da":"## type_B \n\n* ~duplicate information about prod_B \n* type_A = 6 and 9 barely bought","e5388e59":"#### Model performance on train dataset","9e81e73e":"#### Train Test Split","c0dd4134":"### X\n","bf01b4b2":"## prod_B","e4eac88b":"#### Normalized confusion matrix","12b150b8":"## Statistics per variable","e5020703":"#### Creating and training a SVM model\n             ","385fe303":"## Missing data ","b1a99881":"#### Normalized confusion matrix","67cb1d9b":"#### Model performance on test dataset","c69cd3c6":"#### Model performance on test dataset","36ed1879":"Example: The output is either people buying or not buying the new product.\n\n\nAccuracy\n\n* It\u2019s the ratio of the correctly labeled samples to all the samples.\n* Accuracy is the most intuitive one.\n* Accuracy answers the following question: How many samples did we correctly label out of all the samples?\n* Accuracy = (TP+TN)\/(TP+FP+FN+TN)\n* numerator: all correctly labeled (All trues)\n* denominator: all the samples\n\nPrecision\n\n* Precision is the ratio of the correctly labeled to all positive labeled.\n* Precision answers the following: How many of those the model labeled positive are actually buying?\n* Precision = TP\/(TP+FP)\n* numerator: All the correctly labeled people buying the new product.\n* denominator: all the positively labeled people buying the new product.\n\nRecall (aka Sensitivity)\n\n* Recall is the ratio of the correctly labeled samples by all the people actually buying the new product.\n* Recall answers the following question: Of all the people who buying the new product, how many of those are  predicted correctly?\n* Recall = TP\/(TP+FN)\n* numerator: sampled predicted correctly\n* denominator: all people buying the new product\n\nF1-score (aka F-Score \/ F-Measure)\n\n* F1 Score considers both precision and recall.\n* It is the harmonic mean(average) of the precision and recall.\n* F1 Score is best if there is some sort of balance between precision (p) & recall (r) in the system. Oppositely F1 Score isn\u2019t so high if one measure is improved at the expense of the other.\n* For example, if P is 1 & R is 0, F1 score is 0.\n* F1 Score = 2*(Recall * Precision) \/ (Recall + Precision)","d370206c":"### age 0 < ID < 20000","c7f7306d":"## Random forest ","0b135d6b":"#### Predictions and Evaluations","f7bcf20e":"#### Normalized confusion matrix"}}