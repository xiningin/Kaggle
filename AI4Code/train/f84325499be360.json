{"cell_type":{"833aeee6":"code","1e731f89":"code","80611573":"code","41a05fd6":"code","0a5ffe75":"code","d5c64266":"code","97f30b75":"code","1ce3896f":"markdown"},"source":{"833aeee6":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom transformers import TFAutoModelForSequenceClassification, AutoTokenizer","1e731f89":"tf.keras.backend.clear_session()","80611573":"def regular_encode(texts, tokenizer, max_len=256):\n    enc_di = tokenizer.batch_encode_plus(\n        texts,\n        return_attention_mask=True,\n        return_token_type_ids=False,\n        padding='max_length',\n        max_length=max_len,\n        truncation=True,\n    )\n\n    return {\n            \"input_ids\": np.array(enc_di[\"input_ids\"]),\n            \"attention_mask\": np.array(enc_di[\"attention_mask\"]),\n        }\n\ndef generate_predictions(model_path, max_len, file_name, x_column=\"excerpt\"):\n    model = TFAutoModelForSequenceClassification.from_pretrained(model_path, from_pt=True)\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n    df = pd.read_csv(file_name)\n    \n    dataset = regular_encode(df[x_column].tolist(), tokenizer=tokenizer, max_len=max_len)\n\n    input_ids = tf.keras.layers.Input((max_len,), dtype=tf.int32, name=\"input_ids\")\n    attention_mask = tf.keras.layers.Input((max_len,), dtype=tf.int32, name=\"attention_mask\")\n    output_layer = model(input_ids=input_ids, attention_mask=attention_mask)\n    reg_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output_layer)\n\n    final_output = reg_model.predict(dataset, verbose=1, batch_size=16)\n    final_output = sum(final_output.logits.tolist(), [])\n    \n    return np.array(final_output)","41a05fd6":"preds1 = generate_predictions(\"..\/input\/modelf1\/\", max_len=256, file_name=\"..\/input\/commonlitreadabilityprize\/test.csv\")\npreds2 = generate_predictions(\"..\/input\/modelf2\/\", max_len=256, file_name=\"..\/input\/commonlitreadabilityprize\/test.csv\")\npreds3 = generate_predictions(\"..\/input\/modelf3\/\", max_len=256, file_name=\"..\/input\/commonlitreadabilityprize\/test.csv\")\npreds4 = generate_predictions(\"..\/input\/modelf4\/\", max_len=256, file_name=\"..\/input\/commonlitreadabilityprize\/test.csv\")\npreds5 = generate_predictions(\"..\/input\/modelf5\/\", max_len=256, file_name=\"..\/input\/commonlitreadabilityprize\/test.csv\")\npreds6 = generate_predictions(\"..\/input\/a81657\/\", max_len=256, file_name=\"..\/input\/commonlitreadabilityprize\/test.csv\")\n","0a5ffe75":"weights_pos = [2.29301865e-08 ,9.18492143e-02 ,3.56011564e-01, 5.34926853e-09,\n 8.52853500e-02 ,4.66853844e-01]\n","d5c64266":"weights = weights_pos\npreds = preds1*weights[0] + preds2*weights[1] + preds3*weights[2]+ preds4*weights[3] + preds5*weights[4]+ preds6*weights[5]","97f30b75":"submission = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/sample_submission.csv\")\nsubmission.target = preds\nsubmission.to_csv(\"submission.csv\", index=False)","1ce3896f":"Original Notebook in Pytorch by @abhishek: Original Notebook: https:\/\/www.kaggle.com\/abhishek\/yum-yum-yum\n\nPublic Score: 0.488 "}}