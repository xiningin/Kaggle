{"cell_type":{"f8af0401":"code","6f69997d":"code","790e704d":"code","8f26a726":"code","1c0f3c29":"code","9beca887":"code","23655233":"code","74285304":"code","f19ca9fb":"code","b92bc59f":"code","6f6f2454":"code","2c42dc52":"code","c3c24c9f":"code","489be2e5":"code","5dc3a792":"code","272af86b":"code","1c2f3505":"code","183cca94":"code","87bfc8a7":"code","6168eb09":"code","add8266e":"code","9633fd65":"code","691ea67d":"code","cbacac39":"code","8d3fb3db":"code","3730b35e":"code","ad3f2e49":"code","09719844":"code","422a0e43":"code","8b8e118f":"code","d27f7b80":"code","d74176c6":"code","c7511f49":"code","b054e37b":"code","e6c43e25":"code","c4b25243":"code","f24031b2":"code","ab719438":"code","be56b65a":"code","f5665c32":"code","a671a800":"code","7643dd58":"code","3524cc9a":"code","39ee328f":"code","b5ffa6ec":"code","c4cf2f5f":"code","938a11a7":"code","0edce1f2":"code","f80d0068":"code","23095e4d":"code","f9eef004":"code","09c94e07":"code","758652c3":"code","9b228124":"code","713f972f":"code","cb5e3381":"code","bb5ea110":"code","d9914093":"code","56397010":"code","f9fe4fbb":"code","c5de3d73":"code","34e4b255":"code","d0896e89":"code","e667ac84":"code","77e4d046":"markdown","e37c3add":"markdown","b3e2bd26":"markdown","83add8df":"markdown","bc97fefa":"markdown"},"source":{"f8af0401":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f69997d":"train = pd.read_csv('\/kaggle\/input\/softec21-artificial-intelligence-competition\/train_set.csv')\ntrain.describe()","790e704d":"train.head()","8f26a726":"train.Source.value_counts().to_frame().rename(columns={0:\"# of articles\"}).style.background_gradient(cmap=\"plasma\")","1c0f3c29":"train.info()","9beca887":"#train.Html[1]","23655233":"!pip install newspaper3k","74285304":"from newspaper import Article\n\nurl = train.Html[1]\narticle = Article(url)","f19ca9fb":"#article.parse()","b92bc59f":"#article.download()\n#article.parse()","6f6f2454":"from newspaper import fulltext\nimport requests\n\n#html = requests.get(...).text\nurl = train.Html[4]\ntext = fulltext(url)\ntext\n\n\n\n#train.Html[1]","2c42dc52":"text","c3c24c9f":"!pip install trafilatura","489be2e5":"import trafilatura\n\nfeed = trafilatura.metadata.extract_metadata(url)\nfeed","5dc3a792":"feed['hostname']","272af86b":"#train.Html[1]\n\ndef get_host(html):\n    try:\n        title = trafilatura.metadata.extract_metadata(html)['title']\n        author = trafilatura.metadata.extract_metadata(html)['author']\n        url = trafilatura.metadata.extract_metadata(html)['url']\n        hostname = trafilatura.metadata.extract_metadata(html)['hostname']\n        description = trafilatura.metadata.extract_metadata(html)['description']\n        sitename = trafilatura.metadata.extract_metadata(html)['sitename']\n        date = trafilatura.metadata.extract_metadata(html)['date']\n        categories = trafilatura.metadata.extract_metadata(html)['categories']\n        tags = trafilatura.metadata.extract_metadata(html)['tags']\n        fingerprint = trafilatura.metadata.extract_metadata(html)['fingerprint']\n        ids = trafilatura.metadata.extract_metadata(html)['id']\n        license = trafilatura.metadata.extract_metadata(html)['license']\n        #print(feed)\n        return title, author, url, hostname, description, sitename, date, categories, tags, fingerprint, ids, license\n    except:\n        pass\n#['title', 'author', 'url', 'hostname', 'description', 'sitename', 'date', 'categories', 'tags', 'fingerprint', 'id', 'license']","1c2f3505":"#meta = pd.DataFrame()\n\nmeta = train.Html.apply(get_host)\nmeta","183cca94":"meta.value_counts()","87bfc8a7":"host = train.Html.apply(get_host)\nhost","6168eb09":"host.value_counts()","add8266e":"meta_data = pd.DataFrame({'title': title,\n                         'author': author,\n                         'url': url,\n                         'hostname': hostname,\n                         'description': description,\n                         'sitename': sitename,\n                         'date': date,\n                         'categories': description,\n                         'tags': tags,\n                         'fingerprint': fingerprint,\n                         'id': ids,\n                         'license': license})","9633fd65":"import trafilatura","691ea67d":"meta_data = pd.DataFrame.from_dict([train.Html.apply(get_host).items()], orient='index',columns=['title', 'author', 'url', 'hostname', 'description', 'sitename', 'date', 'categories', 'tags', 'fingerprint', 'id', 'license'])\n\nmeta_data","cbacac39":"title, author, url, hostname, description, sitename, date, categories, tags, fingerprint, ids, license = train.Html.apply(get_host)","8d3fb3db":"# .items()], columns=['title', 'author', 'url', 'hostname', 'description', 'sitename', 'date', 'categories', 'tags', 'fingerprint', 'id', 'license']\nmeta_data","3730b35e":"train.shape","ad3f2e49":"def get_host(html):\n    try:\n        return trafilatura.metadata.extract_metadata(html)['hostname']\n    except:\n        pass\n    \ndef get_sitename(html):\n    try:\n        return trafilatura.metadata.extract_metadata(html)['sitename']\n    except:\n        pass\n\ndef get_author(html):\n    try:\n        return trafilatura.metadata.extract_metadata(html)['author']\n    except:\n        pass\n    \ndef get_url(html):\n    try:\n        return trafilatura.metadata.extract_metadata(html)['url']\n    except:\n        pass\n\n","09719844":"train['hostname'] = train.Html.apply(get_host)\ntrain['url'] = train.Html.apply(get_url)\ntrain['author'] = train.Html.apply(get_author)\ntrain['sitename'] = train.Html.apply(get_sitename)","422a0e43":"train.head(2)","8b8e118f":"train.isnull().sum()","d27f7b80":"#grouped = train.groupby('author').groups #['Source']\ngrouped = train.groupby('author')['Source']# .groups\ngrouped","d74176c6":"for state, frame in grouped:\n    print(f\"First 2 entries for {state!r}\")\n    print(\"------------------------\")\n    print(frame.head(10), end=\"\\n\\n\")","c7511f49":"grouped = train.groupby('hostname')['Source']# .groups\nfor state, frame in grouped:\n    print(f\"First 2 entries for {state!r}\")\n    print(\"------------------------\")\n    print(frame.head(10), end=\"\\n\\n\")","b054e37b":"grouped = train.groupby('Source')['hostname']# .groups\nfor state, frame in grouped:\n    print(f\"First 2 entries for {state!r}\")\n    print(\"------------------------\")\n    print(frame.head(10), end=\"\\n\\n\")","e6c43e25":"predict, ground = [*grouped]","c4b25243":"grouped = train.groupby(['hostname', 'sitename'])['Source']# .groups\nfor state, frame in grouped:\n    print(f\"First 2 entries for {state!r}\")\n    print(\"------------------------\")\n    print(frame.head(10), end=\"\\n\\n\")","f24031b2":"converter = pd.DataFrame(grouped)\nconverter","ab719438":"# drop None\ntrain.loc[train.sitename.notnull()]","be56b65a":"rep = train['Source']","f5665c32":"replacer = {}\n#converter_df = pd.DataFrame({'sitename': train['sitename'],\n#                            'Source': train['Source']})\n\nfor index, row in train.iterrows():\n    replacer[row['sitename']] = row['Source']\nreplacer    ","a671a800":"from fuzzywuzzy import process\n\nprocess.extractOne(query, choices=result)[0]","7643dd58":"# Read csv file\ntest = pd.read_csv('\/kaggle\/input\/softec21-artificial-intelligence-competition\/test_data.csv')\n\n# extract data\ntest['hostname'] = test.Html.apply(get_host)\ntest['url'] = test.Html.apply(get_url)\ntest['author'] = test.Html.apply(get_author)\ntest['sitename'] = test.Html.apply(get_sitename)\n\n# Create submisstion CSV","3524cc9a":"test","39ee328f":"result","b5ffa6ec":"from fuzzywuzzy import process\n\n#process.extractOne(query, choices=result)[0]","c4cf2f5f":"result = []\nfor index, row in test.iterrows():\n    key = row['sitename']\n    print(key)\n    #print(key in replacer)\n    try:        \n        if key in replacer:\n            #x = process.extractOne(query=replacer[key], choices=rep) #[0]\n            result.append(process.extractOne(query=replacer[key], choices=rep)[0])\n            #print(x)\n            #result.append(replacer[key])\n        else:\n            result.append(process.extractOne(query=replacer[key], choices=rep)[0])\n            #pass\n            #result.append(key)\n    except:\n        #result = process.extractOne(query=replacer[key], choices=rep)[0]\n        #pass\n        result.append(key)\nresult","938a11a7":"#replacer['MarketBeatCom']\n\nreplacer['Hits Radio']","0edce1f2":"test.loc[test.sitename.notnull()]\n#= [test['sitename']]","f80d0068":"train","23095e4d":"test.sample(10)","f9eef004":"# 1916 \ntrain.sample(10)","09c94e07":"converter_df = pd.DataFrame({'sitename': train['sitename'],\n                            'Source': train['Source']})\n\nconverter_df.shape","758652c3":"converter_df = converter_df.drop(converter_df[(converter_df['sitename'] == 'None') | (converter_df['sitename'] == 'Are you a robot?')].index)","9b228124":"converter_df.shape","713f972f":"converter_df","cb5e3381":"converter_df['replacer'] = converter_df.apply(lambda row: {row['sitename']:row['Source']}, axis=1)","bb5ea110":"converter_df","d9914093":"test['sitename'].to_csv('sumission.csv', index=True)","56397010":"sub_df = pd.DataFrame({'Id': [],\n                      'Publisher': []}) #'Id': [],\nsub_df['Id'] = [*range(1, 689)]\nsub_df['Publisher'] = result ","f9fe4fbb":"sub_df['Id'] = [*range(1, 689)]\nsub_df['Publisher'] = result # test['sitename']","c5de3d73":"sub_df.to_csv('submission.csv', index=False)","34e4b255":"sub_df.shape","d0896e89":"test.shape","e667ac84":"test","77e4d046":"# Score 0.88357","e37c3add":"# group by author\ncover hostname, sitename","b3e2bd26":"# Let's work on Test data and submit now","83add8df":"# Fuzzy Wazzy | String Matching","bc97fefa":"# MultiIndex"}}