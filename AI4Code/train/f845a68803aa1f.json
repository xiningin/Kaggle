{"cell_type":{"b1e6beab":"code","b0b20e60":"code","deaa4761":"code","8f0fa4c3":"code","88d835ab":"code","c70f8039":"code","803bef22":"code","f9a62948":"code","847c0400":"code","ad8bb125":"code","13533347":"code","129f7c2a":"code","b42783aa":"code","c357817c":"code","a545e461":"code","0216314e":"code","25346989":"code","254a4fea":"code","b27c96b8":"code","7c718e97":"code","4d1119ff":"code","8da3002b":"code","33cf40fe":"code","4459120d":"code","47ae71a7":"code","25a06b8e":"code","0600ab5a":"code","623ee6d5":"code","d4885425":"code","0034cb5d":"code","aedd110c":"code","7bbcef96":"code","7e1e9857":"code","7c1a19a8":"code","77216d55":"code","068d4ab7":"code","98e8cc95":"code","cbd44f97":"code","aabdbabf":"code","b7432f54":"markdown","6321705c":"markdown","b3dabf38":"markdown","3f3eaa63":"markdown","ea93b8af":"markdown"},"source":{"b1e6beab":"import os\nprint(os.listdir(\"..\/input\/data-for-lab-2\"))","b0b20e60":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import linear_model as lm","deaa4761":"#Declaring an array\narr = np.array([[1,2,3],[4,5,6]])\n\nprint(\"Array dimensions:\\n\", arr.shape)\nprint(\"Array preview:\\n\", arr)","8f0fa4c3":"#Function to generate a Matrix with all values as 1.\nidentityMatrix = np.ones((2,2))\nprint(\"Identity Matrix:\\n\",identityMatrix)\n\n#Function to stack so as to make a single Matrix horizontally.\nx = np.hstack((identityMatrix,arr))\nprint(\"Stacking arrays:\\n\",x)","88d835ab":"#Dot Product \n#Calculation: [[7*11+8*13, 7*12+8*14],[9*11+10*13, 9*12+10*14]]\na = np.array([[7,8],[9,10]]) \nb = np.array([[11,12],[13,14]]) \nprint(np.dot(a,b))","c70f8039":"#Transpose\nmat = np.array([[7,8],[9,10],[11,12],[13,14]]) \n\nprint(\"Original Matrix:\\n\", mat)\nprint(\"Tranposed Matrix:\\n\", np.transpose(mat))","803bef22":"# Function to calculate the inverse of a matrix\nmat = np.array([[7,8],[9,10]])\nprint(\"Matrix Inverse:\\n\", np.linalg.inv(mat))","f9a62948":"# 'x1' functions as an independent variable and 'y' as a dependent variable \ny = np.array([[1.55],[0.42],[1.29],[0.73],[0.76],[-1.09],[1.41],[-0.32]])\nx1 = np.array([[1.13],[-0.73],[0.12],[0.52],[-0.54],[-1.15],[0.20],[-1.09]])","847c0400":"#Generating regression coefficients\nid = np.ones((8,1))\nx = np.hstack((id,x1))\nbeta=(np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),y))\nprint(beta)","ad8bb125":"#Result - Calculation\nyp1 = beta[0]+beta[1]*x1\nprint(np.hstack((x1,y,yp1)))","13533347":"#Input Dataframe\nd = pd.DataFrame(np.hstack((x1,y)))\nd.columns = [\"x1\",\"y\"]\nprint(d)","129f7c2a":"#Linear Regression - model fitting\nmodel = lm.LinearRegression()\nresults = model.fit(x1,y)\nprint (results)\nprint(model.intercept_, model.coef_)","b42783aa":"#Result: Scikit-Learn\nyp2 = model.predict(x1)\nprint(yp2)","c357817c":"#Linear Regression representation using scatter plot\nplt.scatter(x1,y)\nplt.plot(x1,yp2, color=\"blue\")\nplt.show()","a545e461":"#Prediction for new values\nx1new = pd.DataFrame(np.hstack(np.array([[1],[0],[-0.12],[0.52]])))\nx1new.columns=[\"x1\"]\nyp2new = model.predict(x1new)\nprint(x1new)\nprint(yp2new)","0216314e":"# Input Dataframe\ny = np.array([[1.55],[0.42],[1.29],[0.73],[0.76],[-1.09],[1.41],[-0.32]])\nx1 = np.array([[1.13],[-0.73],[0.12],[0.52],[-0.54],[-1.15],[0.20],[-1.09]])\nx2 = np.array([[1],[0],[1],[1],[0],[1],[0],[1]])","25346989":"id = np.ones((8,1))\nx = np.hstack((id,x1,x2))\nprint(x)","254a4fea":"# Calculating regression coefficients \nbeta=(np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),y))\nprint(beta)","b27c96b8":"#Result - Calculation\nyp1 = beta[0]+beta[1]*x1+beta[2]*x2\nprint(np.hstack((x,y,yp1)))","7c718e97":"#Input Dataframe\nd = pd.DataFrame(np.hstack((x1,x2,y)))\nd.columns = [\"x1\",\"x2\",\"y\"]\nprint(d)","4d1119ff":"#Multiple Linear Regression - Model Fitting\ninputDF = d[[\"x1\",\"x2\"]]\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,y)\nprint(model.intercept_, model.coef_)","8da3002b":"#Result: Scikit-Learn\nyp2 = model.predict(inputDF)\nprint(yp2)","33cf40fe":"#Prediction for new values\nx1new = pd.DataFrame(np.hstack((np.array([[1],[0],[-0.12],[0.52]]),np.array([[1],[-1],[2],[0.77]]))))\nx1new.columns=[\"x1\",\"x2\"]\nprint(x1new)\nyp2new = model.predict(x1new)\nprint(np.hstack((x1new,yp2new)))","4459120d":"d=pd.read_csv(\"..\/input\/data-for-lab-2\/survey.csv\")\nd=d.rename(index=str,columns={\"Wr.Hnd\":\"WrHnd\"})\nprint(d.head())\nd = d[[\"WrHnd\",\"Height\"]]\nprint(d.head())\nprint(d.isnull().values.any())\nprint(d.isnull().sum())","47ae71a7":"#Checking for Null\/NaN values\nd = d.dropna()\nprint(\"Check for NaN\/null values:\\n\",d.isnull().values.any())\nprint(\"Number of NaN\/null values:\\n\",d.isnull().sum())","25a06b8e":"# Simple Linear Regression \ninputDF = d[[\"WrHnd\"]]\noutcomeDF = d[[\"Height\"]]\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,outcomeDF)\n\nprint(model.intercept_, model.coef_)","0600ab5a":"d = pd.read_csv(\"..\/input\/data-for-lab-2\/clock.csv\")\nprint(d.head())\nprint(\"Check for NaN\/null values:\\n\",d.isnull().values.any())\nprint(\"Number of NaN\/null values:\\n\",d.isnull().sum())","623ee6d5":"#Multiple Linear Regression\ninputDF = d[[\"Bidders\",\"Age\"]]\noutputDF = d[[\"Price\"]]\n\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,outputDF)\n\nprint(model.intercept_, model.coef_)","d4885425":"OutputDF_Predict = model.predict(inputDF)\nprint(np.hstack((inputDF,outputDF, OutputDF_Predict)))","0034cb5d":"# HOME WORK_W3\n# Part A\nimport os\nprint(os.listdir(\"..\/input\/udemy-courses\"))","aedd110c":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nfrom sklearn import linear_model as lm\nimport seaborn as sns","7bbcef96":"# Udemy Courses dataset\n\nd = pd.read_csv(\"..\/input\/udemy-courses\/udemy_courses.csv\")\nprint(d.head())\nprint(\"Check for NaN\/null values:\\n\",d.isnull().values.any())\nprint(\"Number of NaN\/null values:\\n\",d.isnull().sum())","7e1e9857":"#Multiple Linear Regression\ninputDF = d[[\"price\",\"num_reviews\"]]\noutputDF = d[[\"num_subscribers\"]]\n\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,outputDF)\n\nprint(model.intercept_, model.coef_)","7c1a19a8":"outputDF_predict = model.predict(inputDF)\nprint(np.hstack((inputDF,outputDF, outputDF_predict)))","77216d55":"#Linear Regression representation using scatter plot\nplt.scatter(inputDF.num_reviews,outputDF)\nplt.plot(inputDF.num_reviews, outputDF_predict, color=\"blue\")\nplt.show()","068d4ab7":"# Part B.\n\ny = np.array([[2147],[2792],[2174],[513],[300],[901]])\nx1 = np.array([[23],[923],[74],[169],[31],[36]])\nid = np.ones((6,1))\nx = np.hstack((id,x1))\n\nbeta=(np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),y))\nprint(\"beta:\\n\",beta)\nyp1 = beta[0]+beta[1]*x1\nprint(\"prediction:\\n\",np.hstack((x1,y,yp1)))","98e8cc95":"plt.boxplot(x1)\nplt.show()\nplt.boxplot(y)\nplt.show()\n","cbd44f97":"plt.scatter(x1,y)\nplt.plot(x1,yp1,color=\"blue\")","aabdbabf":"#sum of squares of residuals\nr = y - yp1\nnp.sum(r*r)","b7432f54":"Kevin> as as predictor variables are clustered in between 0 and 5000,overall outcome of the linear regression seemed toe be influenced.","6321705c":"Boxplot(x1)shows there is one outlier that was excluded in the boxplot.\nBoxplot(y) shows mean value is about 1500 and interquatile value is about 1500 as well.","b3dabf38":"most numbers are located in between 0 and 200 and one seems outlier. This is similar to the observation from the boxplot.\nBut, the prediction shows the linear regression but I doubt as most numbers are clustered.","3f3eaa63":"**Voil\u00e0! This is the end of the lab session for week 2.** <br>\nDo not forget to commit your notebook and set the access to private. Share the notebook with Prof. Karim (Kaggle id: karimshaikh) and Manish Varma (Kaggle id: manishvarma).","ea93b8af":"#  **Simple and Multiple Linear Regression**\nLab Exercises - Week 2\n\n----------"}}