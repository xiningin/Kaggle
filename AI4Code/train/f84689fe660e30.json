{"cell_type":{"979a23e9":"code","e3c5d9a2":"code","8aad9d01":"code","2e445cdf":"code","a7cce37e":"code","c3f0ad8a":"code","66fa8dfc":"code","e57ca2c5":"code","5dfc74be":"code","2525cb00":"code","7d6ee3ed":"code","e65cce03":"code","5a406d0a":"code","df31a0aa":"code","369d7521":"code","483ddf7a":"code","6e89b791":"code","875d7cc7":"code","4e6f3abc":"code","5694017d":"code","d5157ca9":"code","064db11c":"code","099927aa":"code","e29dd385":"code","9c090a12":"code","860a3ccd":"code","9b8fc7d9":"code","7c4be91d":"code","a80f1981":"code","004c3b85":"code","58ad28b7":"code","9bd7c1e9":"code","3c94df9f":"code","0c592144":"markdown","a1785c66":"markdown","2b3bb492":"markdown","2540add7":"markdown","8fa1f867":"markdown","5330a3e3":"markdown","ebb75795":"markdown","2529cdb8":"markdown","58ff788a":"markdown","104d5ea6":"markdown","2215bc3a":"markdown","e6470832":"markdown","4792a921":"markdown","88d8454c":"markdown","7f337e17":"markdown","3a267ce7":"markdown","4ab17d06":"markdown","6e3fd8a3":"markdown","aee245bc":"markdown","f478b45a":"markdown"},"source":{"979a23e9":"%matplotlib inline\n    \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","e3c5d9a2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","8aad9d01":"import os\nfrom PIL import Image, ImageEnhance\n\ndef load_images(path):\n    images = []\n    for i in os.listdir(path):\n        img_path = os.path.join(path, i)\n        images.append(Image.open(img_path))\n    return images","2e445cdf":"english_dataset = np.array(pd.read_csv('..\/input\/az-handwritten-alphabets-in-csv-format\/A_Z Handwritten Data.csv'))\n\nenglish_alphabet = pd.DataFrame(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n                                 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n                                'u', 'v', 'w', 'x', 'y', 'z'], [i for i in range(1, 27)])\nenglish_alphabet","a7cce37e":"X, y = english_dataset[:, 1:], english_dataset[:, 0]","c3f0ad8a":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nX.shape, y.shape","66fa8dfc":"def plot_letters(images, labels, width=14, height=14):\n    rows, cols = 4, 6\n\n    fig=plt.figure(figsize=(14, 14))\n    sub_plot_i = 1\n\n    for i in range(0, 20):\n        fig.add_subplot(rows, cols, sub_plot_i)\n        sub_plot_i += 1\n        image = images[i].reshape(width, height)\n        plt.imshow(image, cmap='gray')\n        label = labels[i].astype(int) + 1\n        plt.title(english_alphabet.loc[label][0])\n\n\n    fig.tight_layout()    \n    plt.show()","e57ca2c5":"plot_letters(X_train, y_train, 28, 28)","5dfc74be":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass ImageTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, width=14, height=14,  is_img=False):\n        self.width = width\n        self.height = height\n        self.is_img = is_img\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        if self.is_img:\n            images = []\n            # load the image and convert to grayscale\n            for img in X:                \n                \n                image = img.convert('L').resize((self.width, self.height))\n                \n                enhancer = ImageEnhance.Contrast(image)\n                image = enhancer.enhance(1.0)\n                \n                images.append(np.asarray(image).reshape(-1))\n            return np.array(images)\n        else:\n            return X","2525cb00":"from sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n\npreprocessing_pipeline = Pipeline([\n    ('image_trf', ImageTransformer()),\n    ('scaler', StandardScaler()),\n])\n\nwidth, height = 28, 28\npreprocessing_pipeline.set_params(image_trf__width=width, image_trf__height=height, image_trf__is_img=False)\nX_train_proc = preprocessing_pipeline.fit_transform(X_train)\nX_test = preprocessing_pipeline.transform(X_test)","7d6ee3ed":"from sklearn.model_selection import cross_val_score, cross_val_predict \nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix","e65cce03":"import itertools\n\ndef display_conf_mat(model, X, y):\n    _, ax = plt.subplots(figsize=(20, 20))\n    plot_confusion_matrix(model, X, y, \n                          display_labels=np.array(english_alphabet[0]).astype(str),\n                          cmap=plt.cm.Blues, ax=ax)\n    plt.show()\n    \n\ndef custom_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(14, 12))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","5a406d0a":"from sklearn.linear_model import LogisticRegression\n\nscores = cross_val_score(LogisticRegression(max_iter=1000), X_train_proc[:2000], y_train[:2000], cv=5)\nscores.mean()","df31a0aa":"log_clf = LogisticRegression(max_iter=1000)\nlog_clf.fit(X_train_proc[:2000], y_train[:2000])\ndisplay_conf_mat(log_clf, X_test, y_test)","369d7521":"from sklearn.svm import LinearSVC\n\nscores = cross_val_score(LinearSVC(max_iter=2000), X_train_proc[:2000], y_train[:2000], cv=5)\nscores.mean()","483ddf7a":"lin_svc_clf = LinearSVC(max_iter=2000)\nlin_svc_clf.fit(X_train_proc[:2000], y_train[:2000])\ndisplay_conf_mat(lin_svc_clf, X_test, y_test)","6e89b791":"from sklearn.svm import SVC\n\nscores = cross_val_score(SVC(), X_train_proc[:2000], y_train[:2000], cv=5)\nscores.mean()","875d7cc7":"svc_clf = SVC()\nsvc_clf.fit(X_train_proc[:2000], y_train[:2000])\ndisplay_conf_mat(svc_clf, X_test, y_test)","4e6f3abc":"from sklearn.ensemble import RandomForestClassifier\n\nscores = cross_val_score(RandomForestClassifier(max_depth=10), X_train_proc, y_train, cv=5)\nscores.mean()","5694017d":"forest_clf = RandomForestClassifier(max_depth=10)\nforest_clf.fit(X_train_proc[:5000], y_train[:5000])\ndisplay_conf_mat(forest_clf, X_test, y_test)","d5157ca9":"y_pred_forest = forest_clf.predict(X_test)\naccuracy_score(y_pred_forest, y_test)","064db11c":"# Reshape for CNN\nfrom sklearn.preprocessing import OneHotEncoder\n\nX_train_proc_cnn = X_train_proc.reshape((-1, 28, 28, 1))\ny_train_proc_cnn = OneHotEncoder().fit_transform(y_train.reshape(-1, 1)).toarray()\n\nX_test_cnn = X_test.reshape((-1, 28, 28, 1))","099927aa":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\nl2 = 0.001\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=((28, 28, 1))))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (1, 1), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2)))\nmodel.add(layers.Dense(26, activation='softmax'))\n\nmodel.summary()","e29dd385":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\nhistory = model.fit(X_train_proc_cnn, y_train_proc_cnn, batch_size=256, epochs=5)","9c090a12":"from sklearn.metrics import accuracy_score, confusion_matrix\n\npredictions = model.predict(X_test_cnn)\ny_pred_cnn = tf.argmax(predictions, axis=1)\ny_pred_cnn = np.array(y_pred_cnn)\naccuracy_score(y_pred_cnn, y_test)","860a3ccd":"conf_mx = confusion_matrix(y_pred_cnn, y_test)\ncustom_confusion_matrix(cm=conf_mx, normalize=False,\n                        target_names=np.array(english_alphabet[0]).astype(str),\n                        title= \"CNN Confusion Matrix\")","9b8fc7d9":"plt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","7c4be91d":"def predict_letters(images, width=14, height=14, alphabet=None, model=None):\n    rows, cols = 1, len(images)\n\n    fig=plt.figure(figsize=(width, height))\n    sub_plot_i = 1\n\n    for i in range(0, len(images)):\n        fig.add_subplot(rows, cols, sub_plot_i)\n        sub_plot_i += 1\n        image = images[i]\n        plt.imshow(image, cmap='gray')\n    fig.tight_layout()    \n    plt.show()\n    \n    predictions = tf.argmax(model.predict(images), axis=1).numpy() + 1\n    predictions = [alphabet.loc[p][0] for p in predictions]\n    \n    return predictions","a80f1981":"def look_for_characters(chars, alphabet=None):\n    char_idx = [alphabet[alphabet[0] == p].index[0] for p in chars]\n    return [list(y_test).index(c - 1) for c in char_idx]","004c3b85":"to_read = ['i', 'n', 't', 'r', 'u', 'd', 'e', 'r',  'a', 'l', 'e', 'r', 't']\nread_chars = look_for_characters(to_read, english_alphabet)\npred_read = predict_letters(X_test_cnn[read_chars], width=14, height=14, alphabet=english_alphabet, model=model)\nprint(pred_read)","58ad28b7":"!pip install gTTS","9bd7c1e9":"from gtts import gTTS\nimport os\n  \n# The text that you want to convert to audio\n# mytext = 'Welcome to the new world'\nmytext = ''.join(pred_read)\n  \n# Language in which you want to convert\nlanguage = 'en'\n  \n# Passing the text and language to the engine, \n# here we have marked slow=False. Which tells \n# the module that the converted audio should \n# have a high speed\nmyobj = gTTS(text=mytext, lang=language, slow=False)\n  \n# Saving the converted audio in a mp3 file named\n# welcome \nmyobj.save(\".\/welcome.mp3\")\n\n# Playing the converted file\nos.system(\"mpg321 .\/welcome.mp3\")","3c94df9f":"from pydub import AudioSegment\nimport IPython\n\npath = '.\/welcome.mp3'\n\nIPython.display.Audio(path)","0c592144":"Provided a good data machine learning models can do a good job at predicting handwriten characters. The next step for this algorithm would be to pair it with an object-detection model that would detect and extract characters from pictures","a1785c66":"**Random Forest**","2b3bb492":"# Conclutions","2540add7":"**LinearSVC**","8fa1f867":"# Frame the Problem","5330a3e3":"Now lets read our predictions out loud using a text to speech algorithm","ebb75795":"The dataset consists of:\n\n* handwritten (A-Z) images in size 2828 pixels\n* each alphabet in the image is centre fitted to 2020 pixel box.\n* each image is stored as Gray-level","2529cdb8":"We will pick some letters manualy to form a word, and make our CNN model predict them","58ff788a":"# Train and Compare Models","104d5ea6":"**Covolutional Neural Network**","2215bc3a":"*The data used for this notebook are provided from Kaggle by user 'Sachin Patel' and are free to use*\n","e6470832":"# Get the Data","4792a921":"**Visualizing data**","88d8454c":"# Utilities","7f337e17":"# Prepare the Data","3a267ce7":"# Explore the Data","4ab17d06":"**Logistic Regression**","6e3fd8a3":"* This notebook is about making an analysis on whether we can create a high accuracy classifier of handwritten english letters\n* This model will be part of a solution that reads handwritten letters out of digitized documents\n* The problem can be framed as an offline supervised classification problem\n* The performance will be measured using accuracy score with a target of ~= 95%","aee245bc":"# Lets have some fun","f478b45a":"**SVC with RBF**"}}