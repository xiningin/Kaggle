{"cell_type":{"8c716c01":"code","5d0581b7":"code","dd352cc8":"code","ccbcead2":"code","b0fbca86":"code","bc1934c5":"code","b2c8f310":"code","66737ebf":"code","232acb71":"code","d834796b":"code","214ce29f":"code","6d21615b":"code","345eb696":"code","7a9fb6ba":"markdown","a98b134a":"markdown"},"source":{"8c716c01":"import tensorflow as tf\nimport numpy as np","5d0581b7":"fas_mnist=tf.keras.datasets.fashion_mnist","dd352cc8":"(train_images,train_labels),(test_images,test_labels)=fas_mnist.load_data()","ccbcead2":"train_images=train_images.reshape(60000, 28, 28, 1)\ntrain_images=train_images \/ 255.0 #Standardising\ntest_images = test_images.reshape(10000, 28, 28, 1)\ntest_images=test_images\/255.0 #Standardising","b0fbca86":"train_images.shape","bc1934c5":"test_images.shape","b2c8f310":"model = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(256, (3,3), activation='relu', input_shape=(28, 28, 1)), # Here 256 feature detector are used, normally 64 is enough\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu',input_shape=(28, 28, )),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\n\n","66737ebf":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","232acb71":"model.summary()","d834796b":"model.fit(train_images, train_labels, epochs=10)","214ce29f":"model.predict(test_images)","6d21615b":"test_loss = model.evaluate(test_images, test_labels)","345eb696":"# Seeing some convulation layer effect on different images\n# This is optional\nimport matplotlib.pyplot as plt\nf, axarr = plt.subplots(3,4)\nFIRST_IMAGE=0\nSECOND_IMAGE=7\nTHIRD_IMAGE=9299\nCONVOLUTION_NUMBER = 210\nfrom tensorflow.keras import models\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\nfor x in range(0,4):\n  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[0,x].grid(False)\n  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[1,x].grid(False)\n  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[2,x].grid(False)","7a9fb6ba":"## This Fashion MNIST dataset included in Tensorflow Library","a98b134a":"### Python script implementation is here https:\/\/github.com\/Ankan1998\/Fashion-MNIST"}}