{"cell_type":{"7f8f54e7":"code","f5c5ff77":"code","bc14550b":"code","5cf5d50f":"code","93ef0655":"code","342738c2":"code","4c762724":"code","093a25f3":"code","1b5c831d":"code","901fc30f":"code","98be8320":"code","c00d7316":"code","40f0aa03":"code","3b93cb72":"code","ddd4c974":"code","554cfbe1":"code","b6614fd6":"code","824ad7f0":"code","f6f21c8d":"code","3895dcf9":"code","df65bf33":"code","d12584ca":"code","4827262c":"code","b4b4b42e":"code","f4e57989":"code","19fc5402":"code","7e3ca2b6":"code","0fc3e93c":"code","a4db2598":"code","4efd2c19":"code","23fe8613":"code","d2427748":"markdown","64d6ec12":"markdown","2fb586d0":"markdown","f8a887e3":"markdown","dc8a76b8":"markdown","b6b2c68c":"markdown","21736a88":"markdown","8a96972d":"markdown","91f34f68":"markdown","e9009c77":"markdown","31181918":"markdown","58c3e0cc":"markdown","dbcdb64e":"markdown","19b08e22":"markdown","05dde0be":"markdown","7e9c8717":"markdown","1a4e60de":"markdown","c2c58ec0":"markdown"},"source":{"7f8f54e7":"from IPython.display import HTML\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport itertools\nfrom itertools import groupby\nimport pickle\nimport os\nimport sklearn \nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Imputer\n\npd.options.mode.chained_assignment = None \n\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\nsns.set(style='white', context='notebook', font_scale=1.5)","f5c5ff77":"import json  # need it for json.dumps\nimport altair as alt\nfrom altair.vega import v3\nalt.renderers.enable('notebook')\n\n##-----------------------------------------------------------\n# This whole section \nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v3.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\",\n    \"This code block sets up embedded rendering in HTML output and provides the function `render(chart, id='vega-chart')` for use below. <br\/>\",\n    \"Credits to kaggle use @notslush for this plug. <br\/>\"\n    \"Check out and vote his\/her awesome notebook: https:\/\/www.kaggle.com\/notslush\/altair-visualization-2018-stackoverflow-survey\/notebook\"\n)))","bc14550b":"df_results = pd.read_csv('..\/input\/formula-1-race-data-19502017\/results.csv')\ndf_results.head()","5cf5d50f":"df_qualifying = pd.read_csv('..\/input\/formula-1-race-data-19502017\/qualifying.csv')\ndf_qualifying.head()","93ef0655":"df_pitStops = pd.read_csv('..\/input\/formula-1-race-data-19502017\/pitStops.csv')\ndf_pitStops.head()","342738c2":"weather = pd.read_csv('..\/input\/formula-1-race-finish-status\/Weather_SafetyCar.csv')\nweather.head()","4c762724":"selected_sets = pd.read_csv('..\/input\/formula-1-race-finish-status\/Selected_Tyre_Sets.csv')\nselected_sets.head()","093a25f3":"df_drivers = pd.read_csv('..\/input\/formula-1-race-data-19502017\/drivers.csv', encoding ='ISO-8859-1')\ndf_races = pd.read_csv('..\/input\/formula-1-race-data-19502017\/races.csv',  encoding ='ISO-8859-1')\n\n# Cleaning:\n# Some drivers have the same surnames, resolve this by replacing driverRef of the non-current driver with the full name\ndf_results.replace(\"max_verstappen\", \"verstappen\", inplace=True)\ndf_results.replace(\"jolyon_palmer\", \"palmer\", inplace=True)\ndf_results.replace(\"kevin_magnussen\", \"magnussen\", inplace=True)\ndf_results.replace(\"brandon_hartley\", \"hartley\", inplace=True)\n\ndf_drivers.replace(\"max_verstappen\", \"verstappen\", inplace=True)\ndf_drivers.replace(\"jolyon_palmer\", \"palmer\", inplace=True)\ndf_drivers.replace(\"kevin_magnussen\", \"magnussen\", inplace=True)\ndf_drivers.replace(\"brandon_hartley\", \"hartley\", inplace=True)\n\ndf_drivers.loc[75, \"driverRef\"] = 'jan_magnussen'\ndf_drivers.loc[49, \"driverRef\"] = 'jos_verstappen'\ndf_drivers.loc[155, \"driverRef\"] = 'jonathan_palmer'\ndf_drivers.loc[155, \"driverRef\"] = 'jonathan_palmer'\ndf_drivers.loc[813, \"driverRef\"] = 'di resta'\n\ndf_races.loc[942, \"name\"] = \"Azerbaijan Grand Prix\"","1b5c831d":"df_drivers.head()","901fc30f":"df_races.head()","98be8320":"template = selected_sets[['year', 'name', 'driverRef']]","c00d7316":"class DataPreprocess():\n    \n    \"\"\"\n    This class contains functions that help to pre-process data for feature engineeering.\n    \"\"\"\n    def __init__(self, results, year_range, calc_method):\n        self.results = results\n        self.year_range = year_range\n        self.calc_method = calc_method\n\n    def remove_outliers(self, df, groupby_fields, agg_method, col, threshold):\n\n        g = df.groupby(groupby_fields)[col].agg(agg_method).reset_index()\n        return g[g[col] < g[col].quantile([0, threshold])[threshold]]\n\n    def calc_stats_wrapper(self, function, df, col, groupby_field, agg_method):\n\n        g_all = pd.DataFrame()\n\n        if (self.calc_method == \"rolling_value\"):\n\n            ranges = [range(self.year_range[idx]-3, self.year_range[idx]) for idx,value in enumerate(self.year_range)]\n\n            for r in ranges:\n                g = function(df, r, col, groupby_field, agg_method)\n                g['year'] = r[-1] + 1\n                g_all = pd.concat([g_all, g])\n                \n                results = self.results[self.results['year'] == r[-1]+1]\n                drivers = list(results.driverRef.unique())\n                if groupby_field[0]=='driverRef':\n                    g_all = g_all[g_all['driverRef'].isin(drivers)]\n\n            return g_all\n\n        elif (self.calc_method == 'one_year'):\n\n            for r in self.year_range:\n                try:\n                    g = function(df, [r], col, groupby_field, agg_method)\n                    g['year'] = r\n                    g_all = pd.concat([g_all, g])\n                except:\n                    pass\n            return g_all\n\n        raise ValueError(\"Only rolling_value and one_year are available options for calc_method\")\n\n        \n    def calc_proportion(self, df, yr_range, col, groupby_field, agg_method):\n        \"\"\"\n        A multi-purpose function to find proportion of an element amongst a group.\n        \"\"\"  \n        \n        df = df[df['year'].isin([yr_range[-1]])] \n        g = df.groupby(groupby_field)[col].agg([agg_method]).reset_index()\n        \n        # Because we are finding the proportion amongst the drivers participating in a season, filter the drivers accordingly.\n        results = self.results[self.results['year'] == yr_range[-1]+1]\n        drivers = list(results.driverRef.unique())\n        df = df[df['driverRef'].isin(drivers)]\n        \n        if len(groupby_field) > 1:\n\n            df_overall = df.groupby(groupby_field[1:])[col].agg([agg_method]).reset_index()\n            df_overall.rename(columns={agg_method: agg_method+' (overall)'}, inplace=True)\n            df_new = pd.merge(g, df_overall, on=groupby_field[1:], how='left')\n\n            df_new['proportion'] = (df_new[agg_method] \/ df_new[agg_method+' (overall)'])\n            df_new.drop([agg_method, agg_method +' (overall)'], axis=1, inplace=True)\n\n            return df_new\n\n        elif len(groupby_field) == 1:\n\n            total = float(df[col].agg([agg_method])[agg_method])\n\n            for i, row in g.iterrows():\n                g.loc[i, 'proportion'] = float(g.loc[i, agg_method]) \/ total\n            g.drop([agg_method], axis=1, inplace=True)\n\n            return g\n        \n        \n    def calc_avg(self, df, yr_range, col, groupby_field, agg_method):\n        \"\"\"\n        Functions to calculate average count of an element within a group over a specified range of years.\n        \"\"\"    \n        df = df[df['year'].isin(yr_range)] \n        g = df.groupby(groupby_field)[col].agg([agg_method]).reset_index()\n        return g\n        \n        \n    def calc_rate(self, df, yr_range, col, groupby_fields, agg_method):\n        \"\"\"\n        Function to calculate percentage\/rate of an element occurring over a specified range of years\n        \"\"\"     \n        df = df[df['year'].isin(yr_range)] \n\n        g = pd.DataFrame(df.groupby(groupby_fields)[col].value_counts())\n        g.rename(columns={col:agg_method}, inplace=True)\n        g = g.reset_index()\n\n        g_overall = pd.DataFrame(df.groupby(groupby_fields)[col].agg(agg_method).rename(\"total\")).reset_index()\n\n        g = pd.merge(g, g_overall, on=groupby_fields, how='left')\n        g['percentage'] = (g[agg_method] \/ g['total']).apply(lambda x: round(x,2))\n\n        gPT = pd.pivot_table(g, index=groupby_fields, columns=[col], values='percentage').reset_index()\n        gPT.fillna(0, inplace=True)\n\n        return gPT","40f0aa03":"class CreateFeatures():\n    \n    def __init__(self, year_range, calc_method):\n        self.calc_method = calc_method\n        self.year_range = year_range\n        \n    def calc_indiv_stats(self, df_qualifying, df_results, weather, df_pitStops, df_races, df_drivers):\n        \n        # Feature: Qualifying position\n        qual = self.preprocess_results(df_qualifying, df_races, df_drivers)\n        qual = qual[['year', 'name', 'driverRef', 'position']]\n        \n        df_results_new = self.preprocess_results(df_results, df_races, df_drivers)\n        results = self.categorize_finish_pos_status(df_results_new)\n        \n        # Initialze class to calculate statistics\n        PP = DataPreprocess(results, self.year_range, self.calc_method)\n        \n        # Feature: Race finish status\n        status = PP.calc_stats_wrapper(PP.calc_rate, results, 'statusId', ['driverRef', 'name'], 'count')\n        \n        # Feature: DNF reason category\n        pos = PP.calc_stats_wrapper(PP.calc_rate, results, 'position', ['driverRef', 'name'], 'count')\n    \n        weather = self.SC_binary_label(weather)\n    \n        # Feature: Safety car\n        sc = PP.calc_stats_wrapper(PP.calc_rate, weather, 'SC', ['name'], 'count')\n\n        # Feature: Wet weather rate\n        ww = PP.calc_stats_wrapper(PP.calc_rate, weather, 'weather', ['name'], 'count')\n\n        pitStops = self.preprocess_pitstops(df_pitStops, qual)\n        pS_notouliers = PP.remove_outliers(pitStops, ['driverRef', 'name', 'year'], 'sum', \"milliseconds\", 0.95)\n        \n        # Feature: Average pitStop timing per driver for the past 3 season\n        pS_avg = PP.calc_stats_wrapper(PP.calc_avg, pS_notouliers, 'milliseconds', ['driverRef', 'name'], 'mean')\n        pS_avg = pS_avg.rename(columns={'mean': 'pitStop timing (avg)'})\n        \n        # Feature: Proportion of pitStop timings amongst drivers for the past year.\n        pS_d = PP.calc_stats_wrapper(PP.calc_proportion, pS_notouliers, 'milliseconds', ['driverRef'], 'sum')\n        pS_d = pS_d.rename(columns={'proportion': 'pitStop timing prop(driver)'})\n\n        # Target Variable: StatusId\n        target_var = self.extract_target_variable(results)\n\n        return results, weather, pitStops, qual, status, pos, sc, ww, pS_avg, pS_d, target_var\n   \n\n    def preprocess_results(self, data, df_races, df_drivers):\n        # Merge reference names to IDs\n        results = pd.merge(data, df_drivers[['driverId', 'driverRef']], on=['driverId'], how='left')\n        results = pd.merge(results, df_races[['raceId', 'year', 'name']], on=['raceId'], how='left')\n        \n        return results\n    \n    def preprocess_qualifying_pos(self, data, df_races, df_drivers):\n\n        qual_pos = data[['raceId', 'driverId', 'position']]\n        qual_pos = self.preprocess_results(qual_pos, df_races, df_drivers)\n        qual_pos = qual_pos[qual_pos['year'].isin(self.year_range)]\n        qual_pos.drop(['raceId', 'driverId'], axis=1, inplace=True)\n        \n        return qual_pos\n    \n    def categorize_finish_pos_status(self, data):\n    \n        # Feature: Finish position\n        results = data.copy()\n        results['position'] = results['position'].replace(range(1,4) ,\"Podium\")\n        results['position'] = results['position'].replace(range(5,10) , \"Pos 4 to 10\")\n        results['position'] = results['position'].replace(np.nan , \"Did not finish\")\n        mask = ~results['position'].isin(['Podium',\"Pos 4 to 10\", \"Did not finish\"])\n        results['position'] = results['position'].mask(mask, \"Pos > 10\")\n\n        # Feature: Reason category for not finishing race\n        results['statusId'] = results['statusId'].replace([1,11,12,13,14] ,\"Finished\")\n        results['statusId'] = results['statusId'].replace([3,4] , \"Accident \/ Collision\")\n        mask = ~results['statusId'].isin(['Finished',\"Accident \/ Collision\"])\n        results['statusId'] = results['statusId'].mask(mask, \"Technical Failure\")\n\n        return results  \n    \n    def SC_binary_label(self, data):\n        \n        data['SC Laps'].fillna(0, inplace=True)\n        data['SC'] = np.where(data['SC Laps'] > 0, \"SC\", \"No SC\")\n        \n        return data\n            \n    def preprocess_pitstops(self, data, qual):\n    \n        pitStops = self.preprocess_results(data, df_races, df_drivers)\n        g = pd.merge(qual[['year', 'name', 'driverRef']], pitStops, on=['year', 'name', 'driverRef'], how='left').fillna(0)\n        g = g.sort_values('stop', ascending=False).groupby(['year', 'name', 'driverRef']).first().reset_index()  \n\n        return g\n    \n    def extract_target_variable(self, data):\n        \n        status = data[['year', 'name', 'driverRef', 'statusId']]\n        status.replace('Finished', 1, inplace=True)\n        status.replace('Accident \/ Collision', 0, inplace=True)\n        status.replace('Technical Failure', 0, inplace=True)\n\n        return status\n","3b93cb72":"cf = CreateFeatures([2015, 2016, 2017], 'rolling_value')\nresults, weather, pitStops, qual, status, pos, sc, ww, pS_avg, pS_d, target_var = cf.calc_indiv_stats(df_qualifying, df_results, weather, df_pitStops, df_races, df_drivers)","ddd4c974":"class CreateDataset():\n    def __init__(self, add_qual_pos=True, add_status=True, add_finish_pos=True, add_safety_car=True, add_weather=True, add_pitStop=True, add_tyre_sets=True):\n\n        self.add_qual_pos = add_qual_pos\n        self.add_status = add_status\n        self.add_finish_pos = add_finish_pos\n        self.add_safety_car = add_safety_car\n        self.add_weather = add_weather\n        self.add_pitStop = add_pitStop\n        self.add_tyre_sets = add_tyre_sets\n\n    def merge_all_stats(self, template, qual, status, pos, sc, ww, pS_avg, pS_d, target_var, tyre_sets):\n\n        # Template to merge all feature to\n        df = template.copy()\n        \n        # Merge dataframe containing target variable\n        df = pd.merge(df, target_var, on=['year', 'name', 'driverRef'], how='left')\n        \n        # Feature: Qualifying position\n        if self.add_qual_pos==True:   \n            df = pd.merge(df, qual, on=['year', 'name', 'driverRef'], how='left')\n        \n        # Feature: Finishing position category\n        if self.add_finish_pos==True:   \n            pos = pos.drop(['Pos > 10'], axis=1)\n            df = pd.merge(df, pos, on=['year','name', 'driverRef'], how='left')\n\n        # Feature: DNF reason category\n        if self.add_status==True:\n            status = status.drop(['Technical Failure', 'Finished'], axis=1)\n            df = pd.merge(df, status, on=['year','name', 'driverRef'], how='left')\n          \n        # Feature: Safety Car\n        if self.add_safety_car==True:\n            sc = sc.drop(['No SC'], axis=1)\n            df = pd.merge(df, sc, on=['year','name'], how='left')\n           \n        # Feature: Wet weather rate\n        if self.add_weather==True:\n            ww = ww.drop(['Varied'], axis=1)\n            df = pd.merge(df, ww, on=['year','name'], how='left') \n            \n        # Feature: Pitstop Timings\n        if self.add_pitStop==True:\n            df = pd.merge(df, pS_avg, on=['year', 'name', 'driverRef'], how='left')  \n            df = pd.merge(df, pS_d, on=['year', 'driverRef'], how='left')   \n            \n        # Feature: Selected Tyre Sets as ordinal categorical vaues\n        if self.add_tyre_sets == True:\n            df = pd.merge(df, selected_sets, on=['year', 'name', 'driverRef'], how='left') \n\n        return df\n    \n    def handling_missing_values(self, df):\n        \n        # Handle null values for specific columns in a specific way\n        df = self.miscellaneous_cleaning(df)\n        # Rest of null values belong to new drivers(rookies) and new tracks because they do not have any historical information \n        # Inpute null values with the column's median values\n        imputer = Imputer(missing_values='NaN', strategy='median', axis=0)\n        df_new = pd.DataFrame(imputer.fit_transform(df.drop(['year', 'name', 'driverRef', 'statusId'], axis=1)))\n        df_new = pd.concat([df[['year', 'name', 'driverRef', 'statusId']], df_new], axis=1)\n        df_new.columns = df.columns \n        \n        return df_new\n\n    def miscellaneous_cleaning(self, df):\n        \n        # Null values belong to drivers who did not set a qual time or participate in qualifying\n        if self.add_qual_pos==True: \n            df['position'].fillna(22, inplace=True)\n\n        # Null values belong to drivers who did not set a pitStop time during a race\n        if self.add_pitStop==True: \n            df['pitStop timing (avg)'].fillna(0, inplace=True)\n            \n        return df","554cfbe1":"cd = CreateDataset()\ndataset = cd.merge_all_stats(template, qual, status, pos, sc, ww, pS_avg, pS_d, target_var, selected_sets)\ndataset.isnull().sum()","b6614fd6":"dataset_new = cd.handling_missing_values(dataset)\ndataset_new.isnull().sum()","824ad7f0":"# There are 4 rows with null values for statusId. \n# They belong to hartley, a driver who joined toro rosso only in the lasst 4 races. Seems that the Eargast API results were not updated to reflect the changes.\ndataset_new[dataset_new['statusId'].isnull()]","f6f21c8d":"# Cleaning: Check the official results and inpute the statusId accordingly.\ndataset_new.loc[16, 'statusId'] = 0\ndataset_new.loc[32, 'statusId'] = 0\ndataset_new.loc[52, 'statusId'] = 1\ndataset_new.loc[372, 'statusId'] = 1","3895dcf9":"dataset_new.head()","df65bf33":"dataset_new.to_csv('dataset.csv', index = False)","d12584ca":"hover = alt.selection_single(on='mouseover', nearest=True, fields=['name'], empty='all')\n\nbase_ww = alt.Chart(ww).properties(\n    width=700,\n    height=100,\n    title=\"Relationship between probability of Dry weather occurring and number of DNFs\"\n).add_selection(hover)\n\npoints_ww = base_ww.mark_rect().encode(\n    x='name',\n    y='year:O',\n    color=alt.condition(hover, 'Dry:O', alt.value('lightgray'))\n).interactive()\n\nbar_ww = alt.Chart(weather).mark_bar().encode(\n    x='year:O',\n    y='weather',\n    color=alt.Color('count()', legend=None)\n).transform_filter(\n    hover\n)\n\nbase_sc = alt.Chart(sc).properties(\n    width=700,\n    height=100,\n    title=\"Probability of Safety Car occurring at a race\"\n).add_selection(hover)\n\npoints_sc = base_sc.mark_circle().encode(\n    x='name',\n    y='year:O',\n    size=alt.Size('SC:O'),\n    color=alt.condition(hover, alt.value('black'), alt.value('grey')),\n).interactive()\n\nbar_sc = alt.Chart(weather).mark_bar().encode(\n    x='year:O',\n    y='SC:O',\n    color=alt.Color('count()', legend=None)\n).transform_filter(\n    hover\n)\n\nbar_sclaps = alt.Chart(weather).mark_bar(color='black').encode(\n    x='year:O',\n    y='SC Laps:Q',\n).transform_filter(\n    hover\n)\n\ntext = alt.Chart(dataset_new).mark_text(baseline='middle').encode(\n    x='name',\n    y='year:O',\n    text='count()',\n    color=alt.condition(alt.datum['SC'] == 1.0, alt.value('white'), alt.value('black'))\n).transform_filter(\n    alt.datum.statusId == 0\n)\n\nrender(points_ww + text & bar_ww & points_sc & bar_sc & bar_sclaps)","4827262c":"results1317 = results[results['year'] > 2011]\n\nhover = alt.selection_single(on='mouseover', nearest=True, fields=['driverRef'])\n\nbase_pos = alt.Chart(pos).properties(\n    width=700,\n    height=100,\n    title=\"Relationship between probability of driver not finishing a race and actual DNF occurrence\"\n).add_selection(hover)\n\npoints_pos = base_pos.mark_rect().encode(\n    x='driverRef',\n    y='year:O',\n    color=alt.condition(hover, 'Did not finish:O', alt.value('lightgray')),\n).interactive()\n\n\nline_pos = alt.Chart(pos).mark_point().encode(\n    x='name',\n    y='year:O',\n    color=alt.Color('Did not finish:O'),\n).transform_filter(\n    hover\n).properties(\n    width=700,\n    height=100,\n    title=\"Probability of driver being involved in an accident\/collision\"\n)\n\nbar_pos = alt.Chart(results1317).mark_bar().encode(\n    x='year:O',\n    y='position',\n    color=alt.Color('count()', legend=None)\n).transform_filter(\n    hover\n)\n\nbar_pos1 = alt.Chart(results1317).mark_bar().encode(\n    x='name',\n    y='year:O',\n    color=alt.Color('position', scale=alt.Scale(domain=['Did not finish', 'Pos > 10', 'Pos 4 to 10', 'Podium'], range=['crimson', 'sandybrown', 'lightgreen', 'seagreen']))\n).transform_filter(\n    hover\n)\n\ntext = alt.Chart(dataset_new).mark_text(baseline='middle').encode(\n    x='driverRef',\n    y='year:O',\n    text='count()',\n    color=alt.condition(alt.datum['SC'] == 1, alt.value('white'), alt.value('black'))\n).transform_filter(\n    alt.datum.statusId == 0\n)\n\nrender(points_pos + text &  bar_pos & line_pos & bar_pos1)","b4b4b42e":"index_list = ['year', 'name', 'driverRef']\ntarget_var_list = ['statusId']\n\n# List of drivers participating in the respective seasons\ndrivers16 = results[results['year'] == 2016].driverRef.unique()\ndrivers17 = results[results['year'] == 2017].driverRef.unique()\n\n# Find the differences in drivers particiapting in 2016 and 2017\ndrivers_toremove = list(set(drivers16) - set(drivers17)) + list(set(drivers17) - set(drivers16))\ndrivers_toremove.extend(['hartley', 'vandoorne', 'button'])\n\n# Data transformation: Qualifying position\ndef scoring(x):\n    return x * x.name\n\nqual_crosstab = pd.crosstab(dataset_new['driverRef'], dataset_new['position'])\nqual_crosstab = qual_crosstab.apply(lambda x: scoring(x))\nqual_crosstab['total'] = qual_crosstab.sum(axis=1)\nqual_crosstab.sort_values('total', ascending=True, inplace=True)\n\n# List of best qualifiers\nqual_crosstab = qual_crosstab.reset_index()\nqual_crosstab = qual_crosstab[~qual_crosstab['driverRef'].isin(drivers_toremove)]\nbest_qualifiers = list(qual_crosstab.driverRef)\n\ndef dnf_acc_plot():\n    \n    flatui = [\"#ffb347\", \"#659CCA\"]\n    sns.set_palette(flatui)\n\n    g = sns.factorplot(x=\"driverRef\",\n                       y=\"Did not finish\",\n                       order=best_qualifiers, # sort x-axis by best qualifying drivers\n                       hue=\"year\", \n                       data=dataset_new,\n                       kind=\"violin\", \n                       split=True, \n                       scale=\"count\", \n                       inner=\"stick\",\n                       cut=0, \n                       bw=.5,\n                       size=7, aspect=3)\n    \n    for ax in g.axes.flat: \n        plt.setp(ax.get_xticklabels(), rotation=45, ha='right') \n\n    plt.suptitle('Distribution of probability of drivers not finishing races', y=1.05, fontsize=20)\n    plt.title(\"x-axis is sorted by 2017's best to worst qualifying drivers from left to right\", fontsize=16)\n    \ndnf_acc_plot()","f4e57989":"pitStops16 = pitStops[(pitStops['year'] == 2016) & ~(pitStops['driverRef'].isin(drivers_toremove))]\npitStops17 = pitStops[(pitStops['year'] == 2017) & ~(pitStops['driverRef'].isin(drivers_toremove))]\n\nheatmap_16 = alt.Chart(pitStops16).mark_rect().encode(\n    x='name',\n    y='driverRef',\n    color=alt.Color('mean(milliseconds):Q', scale=alt.Scale(zero=False, domain=[0, 40000], scheme='redyellowblue'))\n).properties(\n    width=600,\n    height=500\n)\n\nheatmap_17 = alt.Chart(pitStops17).mark_rect().encode(\n    x='name',\n    y='driverRef',\n    color=alt.Color('mean(milliseconds):Q', title=\"Pit Stop Timing (in milliseconds)\", scale=alt.Scale(zero=False, domain=[0, 40000], scheme='redyellowblue'))\n).properties(\n    width=600,\n    height=500\n)\n\ntext_16 = alt.Chart(pitStops16).mark_text(baseline='middle').encode(\n    x='name',\n    y='driverRef',\n    text='stop',\n    color=alt.condition((alt.datum['milliseconds'] ==0) and (alt.datum['milliseconds'] >35000), alt.value('white'), alt.value('black'))\n)\n\ntext_17 = alt.Chart(pitStops17).mark_text(baseline='middle').encode(\n    x='name',\n    y='driverRef',\n    text='stop',\n    color=alt.condition((alt.datum['milliseconds'] ==0) and (alt.datum['milliseconds'] >35000), alt.value('white'), alt.value('black'))\n)\n\npitStop_plot = alt.vconcat(\n                    heatmap_16 + text_16, \n                    heatmap_17 + text_17,\n                    title=\"Average Pit Stop Timings & Count of Pit Stops per race: 2016-2017\"\n                )\n\nrender(pitStop_plot)","19fc5402":"circ = alt.Chart(dataset_new).mark_point().encode(\n    x='name',\n    y='driverRef',\n    size=alt.Size('position', title=\"Qualifying Position\", scale=alt.Scale(range=[0, 500])),\n    color=alt.Color('year:N', scale=alt.Scale(range=[\"#ffb347\", \"#659CCA\"])),\n).properties(\n    width=600,\n    height=600\n)\n\nfill_16 = circ.mark_point().encode(\n    fill=alt.FillValue(\"#ffb347\"),\n    shape=alt.Shape('statusId', legend=alt.Legend(title=\"DNF\"))\n).transform_filter(\n    (alt.datum.statusId == 0) & (alt.datum.year == 2016)\n)\n\nfill_17 = circ.mark_point().encode(\n    fill=alt.FillValue(\"#659CCA\"),\n    shape=alt.Shape('statusId', legend=alt.Legend(title=\"DNF\"))\n).transform_filter(\n    (alt.datum.statusId == 0) & (alt.datum.year == 2017)\n)\n\nbar_H = alt.Chart(dataset_new).mark_line(opacity=0.6).encode(\n    x='name',\n    y=alt.Y('count()', title='Number of drivers who Did Not Finish a race'),\n    color=alt.Color('year:N', scale=alt.Scale(range=[\"#ffb347\", \"#659CCA\"])),\n).transform_filter(\n    (alt.datum.statusId == 0) \n).properties(\n    width=600\n)\n\nbar_V = alt.Chart(dataset_new).mark_line(opacity=0.6).encode(\n    x=alt.X('count()', title='Number of races where driver Did Not Finish'),\n    y='driverRef',\n    color=alt.Color('year:N', scale=alt.Scale(range=[\"#ffb347\", \"#659CCA\"])),\n).transform_filter(\n    (alt.datum.statusId == 0)\n).properties(\n    height=600\n)\n\nVC = alt.vconcat(\n    circ+fill_16+fill_17,\n    bar_H,\n    title=\"(Filled circles indicate that driver DNF race)\"\n)\n\nqual_plot = alt.hconcat(\n    VC,\n    bar_V,\n    title=\"Driver's Qualifying Position vs Race Finish Status: 2016-2017\"\n)\n\nrender(qual_plot)","7e3ca2b6":"def boxplot(df, index_list, target_var_list):\n    \n    df_new = df.drop(index_list+target_var_list, axis=1)\n\n    nrows = len(df_new.columns)\/\/3\n    ncols = 3\n    fig, axes = plt.subplots(nrows, ncols, figsize=(15,20))\n    \n    my_pal = {0.0: \"#FF0000\", 1.0: \"#88e188\"}\n    \n    i=0\n    for row in range(nrows):\n        for col in range(ncols):\n            g = sns.boxplot(y=df_new.iloc[:,i], x=df[target_var_list[0]], palette=my_pal, ax=axes[row][col])\n            i=i+1\n    plt.tight_layout(pad=0.8, w_pad=0.8, h_pad=1.0)\n    \nboxplot(dataset_new, index_list, target_var_list)","0fc3e93c":"def barplots(df):\n    \n    df1 = df.drop(index_list, axis=1)\n    \n    def sephist(df, col):\n        yes = df[df['statusId'] == 1][col]\n        no = df[df['statusId'] == 0][col]\n        return yes, no\n\n    plt.figure(figsize=(20,30))\n    for num in range(len(df1.columns)-1):\n        plt.subplot(len(df1.columns)\/\/2, 2, num+1)\n        plt.hist((sephist(df1, df1.iloc[:,num].name)[0], sephist(df1, df1.iloc[:,num].name)[1]), bins=25, alpha=0.5, label=['FIN', 'DNF'], color=[\"#88e188\", \"#FF0000\"])\n        plt.legend(loc='upper right')\n        plt.title(df1.iloc[:,num].name)\n    plt.tight_layout(pad=0.8, w_pad=0.8, h_pad=1.0)\n    \nbarplots(dataset_new)","a4db2598":"scatterplot = alt.Chart(dataset_new).mark_circle(opacity=0.7).encode(\n        alt.X(alt.repeat(\"column\"), type='quantitative', scale=alt.Scale(domain=[-0.1, 1.1])),\n        alt.Y(alt.repeat(\"row\"), type='quantitative', scale=alt.Scale(domain=[-0.1, 1.1])),\n        alt.Color('statusId:N', scale=alt.Scale(range=[\"#FF0000\", \"#88e188\"])),\n        alt.Size('count()', scale=alt.Scale(range=[0, 3000]))\n    ).properties(\n        width=250,\n        height=250,\n    ).repeat(\n        row=['Did not finish', 'Accident \/ Collision', 'SC', 'Wet'],\n        column=['Wet', 'SC', 'Accident \/ Collision', 'Did not finish'],\n        title=\"Relationship between probabilites of various race scenarios occuring and driver's actual race finish status: 2016-2017\"\n    ).interactive()\n\nrender(scatterplot)","4efd2c19":"from pandas.plotting import parallel_coordinates\n\ndef parallel_coordinates_plot(df):\n    \n    df_new = df.drop(index_list+target_var_list, axis=1)\n    \n    SS = StandardScaler()\n    Xs_train = pd.DataFrame(SS.fit_transform(df_new))\n    Xs_train.columns = df_new.columns\n    Xs_train_new = pd.concat([Xs_train.reset_index(drop=True), df[target_var_list].reset_index(drop=True)], axis=1)\n    \n    plt.figure(figsize=(15,10))\n    parallel_coordinates(Xs_train_new, \"statusId\", color=[\"#FF0000\", \"#88e188\"])\n    plt.title('Parallel Coordinates Plot', fontsize=20, fontweight='bold')\n    plt.xlabel('Features', fontsize=15)\n    plt.ylabel('Features values', fontsize=15)\n    plt.legend(loc=1, prop={'size': 15}, frameon=True,shadow=True, facecolor=\"white\", edgecolor=\"black\")\n    plt.xticks(rotation=90)\n    plt.show()\n    \nparallel_coordinates_plot(dataset_new)","23fe8613":"from pandas.plotting import radviz\n\ndef classification_radviz(df):\n    \n    df_new = df.drop(index_list+target_var_list, axis=1)\n    \n    SS = StandardScaler()\n    Xs_train = pd.DataFrame(SS.fit_transform(df_new))\n    Xs_train.columns = df_new.columns\n    Xs_train_new = pd.concat([Xs_train.reset_index(drop=True), df[target_var_list].reset_index(drop=True)], axis=1)\n    \n    plt.figure(figsize=(10,10))\n    radviz(Xs_train_new, 'statusId', color=[\"#FF0000\", \"#88e188\"])\n    plt.show()\n    \nclassification_radviz(dataset_new)","d2427748":"## Create dataset\n#### The below code block contains functions to create a master dataset containing the feature columns (allows flexibility in choosing which features to include in dataset)","64d6ec12":"#### 3) Dataframe containing pitstop information at each race","2fb586d0":"#### Import dataframes of drivers and race identification information","f8a887e3":"## Create features\n#### The below code block is a class containing functions enabling feature engineering. As explained above, to derive feature values, we are creating sub-models.","dc8a76b8":" ## Pre-process data\n \n** Now that we have imported some datasets, let's check which columns can be utilized as features. (The dataframe name is in brackets after the column name)**\n- Ordinal variables:\n    *     position (df_results): Race finish position\n    *     position (df_qualifying):  Qualifying position\n- Continuous variables:\n    *    milliseconds (df_pitStops): Time to complete a pit stop\n    *    Medium, Soft, Super Soft, Ultra Soft, Hard (selected_sets): Number of tyre sets of each type which each driver has confirmed pre-race to be bring along to a race weekend\n    *    SC Laps (weather): Total number of laps led by a Safety Car in a race\n- Categorical variables:\n    *    Weather (weather):  Dry, Varied, Wet\n    *    statusId (df_results): Refer to this [glossary](http:\/\/ergast.com\/api\/f1\/status) provided by Ergast API for what each ID represents.\n    \n** Data Transformation to be done:**\n1.  All categorical variables  will be dummy coded. A dummy variable represents one level of a categorical variable. \n    - Weather: Straightforward way of dummy coding. For example, presence of Dry weather is represented by 1 and absence is represented by 0.\n    - statusId: I choose to  re-categorize the IDs (to narrow down the number of categories) before dummy coding: \n        - 1: Finished\n        - 3: Accident \n        - 4: Collision (Group ID 3 and 4 together)\n        - 11: +1 Lap (It actually indicates that a driver has a finished the race, albeit one lap slower than the race leader)\n        - 12, 13, 14: +2 Lap, +3 Lap, +4 Lap\n        - Other statuses will be categorized as \"Technical Failure\"\n\n**Can we move on to creating a master dataset of these features? Not so fast.... Ground truth values for some features do not exist pre-race. In fact, only qualifying positions and selected tyre sets are known pre-race. How do we know before a race starts that there will be 5 Safety Car laps?  Or that a driver will complete a pit stop at a certain timing? By simply using these values as they are in our training and test sets, we are committing a serious  offence of data leakage.**\n  \n Let's detour for a bit and **create sub-models**  to derive new feature values:\n\n**Approach 1:  aggregate historical information (scope: past 3 seasons) to estimate a probabilty of an event occurring. This 'probability' will then be used as a new feature.**\n - statusId: For eg. if a driver was involved in a race collision for only 1 out of the past 3 Australian Grand Prixs (AUS GP), then 'Accident Probability'  for this driver at the  2018 AUS GP will be 33%. This is repeated for each status category.\n - weather: For eg. if there was rain for none of the past 3 Australian Grand Prixs, then 'Wet Weather Probability'  for this race in 2018 will be 0%.\n - SC Laps: Instead of predicting the number of SC laps, I simplify the SC prediction model to just a boolean category of SC or no SC occurring.  For eg. if a SC appeared in all past 3 AUS GP,, then 'SC Probability'  for this race in 2018 will be 100%.\n - milliseconds: For each race per driver for the past 3 seasons, sum up the pitstop timings and divide by 3.\n - position (race finish position): Convert the ordinal variables to categories first. The categories are: Podium, 4th to 10th position,  More than 10th position, Did Not Finish. Next, calculate probabilities of occurrence of each category.\n - *Pros*: This approach helps to overcome the fact that we have incomplete data during data modeling phase by estimating data instead. It is quick to code.\n - *Cons:*  Potential Information loss because this simple aggregation does not utilize 'year' as an identifier.\n  \n**Approach 2: categorize historical information.**\n - For eg. if a driver was involved in a race collision in the 2014 AUS GP only,  suffered a technical failure in 2015 AUS GP but completed the 2016 AUS GP, then I will assign a value of 1. \n - For each combination of race scenarios, a different category value will be assigned.  \n - *Pros*: Prevents information loss as 'year' which race event occurred is taken\n into consideration in the categorization.\n - *Cons:*, because of the large number of possible combinations, it becomes tedious to assign categorical values and also results in large number of dummy variables. Downstream, there could be many iterations of feature selection required.\n\n**The below code block is  a class containing functions that help to pre-process data for feature engineeering using Approach 1.**","b6b2c68c":"## Import datasets\n\n#### Where can I find publicly available Formula 1 data? What are the potential features that could help  **identify whether a driver will finish a race or not**? These are the questions I had when i first started out on this crazy project to use machine learning algorithms to predict race finishes.\n#### Initial brainstorming based on my contextual knoweledge of the sport threw up these potential areas to look into:\n- Weather\n- Safety Car appearances\n- Qualifying position\n- Pitstops\n- Tyres\n- Overtaking\n    \n#### 1. I found a [kaggle dataset](https:\/\/www.kaggle.com\/cjgdev\/formula-1-race-data-19502017) that contains information of qualifying position, pit stop timings and  race results. This same data can also be extracted with an API call from the [Ergast Developer API](The Ergast Developer API). \n\n#### 2. As for weather and safety car statistics, I pieced together the information myself for each race based on information published on [this blog](http:\/\/www.f1strategyreport.com\/). This blog is also an excellent resource to gain insight to race strategy!\n\n#### 3. Pirelli has a[ section on its site](https:\/\/racingspot.pirelli.com\/global\/en-ww\/infographics) dedicated to its infographics which details each race's allocated tyre types, number of tyre sets per type each driver chooses to bring along for each race, as well as each driver's stint length (ie. number of laps spent on a tyre type). The infographics are all images, so unfortunately there is manual work involved in recording the information.\n\n#### 4. Race overtaking information can be gained by have a paid account with [www.cliptheapex.com.](http:\/\/www.cliptheapex.com) Because the overtaking information is only available to paid users, I will not share it publicly on kaggle. \n\n#### Below, I import all the relevant datasets.","21736a88":"#### 4) Dataframe containing weather labels and SC appearance labels (Overtaking figures and SC Laps can be ignored)","8a96972d":"## This is Part 1 of a project where i attempt to classify race finish status of drivers at each race of a Formula 1 season.\n### In this notebook, i will create the dataset containing selected features and perform EDA (mainly with the help of Altair package), while in [Part 2](https:\/\/www.kaggle.com\/coolcat\/f1-binary-classification-of-race-finish-status), I will perform the classification.\n","91f34f68":" # EDA","e9009c77":"#### Hover over the dashboard to analyse information from individual races\/drivers. (To remove the filter, move the cursor to the right edge of the plot, then gradually slide it to the right)\n-  As mentioned above, the logic i put in place to derive new feature values is by aggregating  historical information (scope: past 3 seasons).\n- Hovering over \"Australian Grand Prix\"' in the races dashboard below, we can see that the \"Dry Weather Probability\" value for the 2017 Australian Grand Prix is 100% because the track was dry (ie. no rain\/wet weather) from 2014 to 2016. From the dashboard, we can also see that the track is prone to having a Safety Car appearance. The \"SC Probability\" value for 2017 AUS GP is 100% because there has been at least one SC appearance for 2014, 2015 and 2016's races. However, the sub-model's prediction is wrong, as in fact, there was no SC for 2017 AUS GP\n- Similarly, hovering over 'hamilton' in the drivers dashboard below, we can see that the \"Accident Probability\" value for Hamilton for the 2015 Belgian Grand Prix is 67% because he failed to finish the race in 2012 and 2014. Similarly,  Hamilton has a 0% \"Accident Probability\" for the 2017 Austrian Grand Prix because he has successfully finished all the races from 2014 to 2016.\n ","31181918":"### From the graphs above, there is no clear linear relationship between features and target variable, meaning that none of the features except for qualifying position give a good indication whether or not a driver will finish a race or not.  I expect that classification of race finish status will not be an easy task. Since we have non-linearly separable data, perhaps trees-based classifiers and neural networks will perform best with this dataset. Head over to [Part 2 ](https:\/\/www.kaggle.com\/coolcat\/f1-binary-classification-of-race-finish-status) to find out.","58c3e0cc":"#### DATASET TEMPLATE\/FRAME","dbcdb64e":"## How well do the predictors relate to the target variable?","19b08e22":"#### 5) Dataframe containing number an type of tyre sets selected by each driver at each race. ","05dde0be":"#### Import packages and setup","7e9c8717":"### Detailed explanation of each  column in dataset\n* ** statusId**: Binary value. 1 -> Driver finished a race. 0-> Driver did not finish a race\n* ** position:** Qualifying position of driver (Depends on the number of drivers participating per season. If a driver did not set a qualifying time, then null value will be imputed with 23.)\n* ** Podium: **Probability of driver finishing race in podium position. (Percentage figure derived by aggregating the occurrences of driver finishing in podium position at the same race over the past 3 seasons.)\n* ** Pos 4 to 10:** Probability of driver finishing in top 4 to 10 position.  (Percentage figure derived by aggregating the occurrences of driver finishing in top 4 to 10 position at the same race over the past 3 seasons.)\n* ** Accident \/ Collision: **Probability of driver being involved in an accident in a particular race (Percentage figure derived by aggregating the occurrences of driver being involved in an accident at the same race over the past 3 seasons.)\n* ** SC:** Probability of a Safety Car appearing at least once in a race. (Percentage figure derived by aggregating the occurrences of SC appearing >= 1 at the same race over the past 3 seasons.)\n* ** Dry:** Probability of having a race in dry weather conditions.  (Percentage figure derived by aggregating the dry weather occurrences at the same race over the past 3 seasons.)\n* ** Wet: **Probability of having a race in wet weather conditions.  (Percentage figure derived by aggregating the wet weather occurrences at the same race over the past 3 seasons.)\n* **pitStop timing prop(driver):** Average Pit Stop Timing (time to complete a pitstop) for each driver in the past season as a proportion of the total pitstop timings of that season\n* **pitStop timing (avg)**: Average Pit Stop Timing for each driver at each race aggregated over the past 3 seasons.\n* ** Medium: **Number of Medium tyres that a driver brought to a race weekend for the free pracice, qualifying and race sessions.. (Note: This is not the number of tyres which a driver used in the race, nor is it the number of tyres left for the race) \n","1a4e60de":"#### 1) Dataframe of Race finish statuses and position numbers","c2c58ec0":"#### 2) Dataframe containing qualifying information of each driver at each race"}}