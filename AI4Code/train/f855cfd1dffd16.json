{"cell_type":{"9f9ca86f":"code","5d510d15":"code","e93cf89a":"code","186ee5c9":"code","80bf0723":"code","96e44d8c":"code","6369edcf":"code","a9379e25":"code","ca74b3f8":"code","fe292ab2":"code","6ac1751d":"code","126f50ed":"code","ba43c1d0":"code","2bcb577e":"code","15904c3e":"code","7af28035":"code","930c531f":"code","1c4395ca":"code","e6b5e10a":"code","76a93fd3":"code","90fc3633":"code","b31dbabc":"code","4a99c6f0":"code","075c0061":"code","af2031fb":"code","695ac05b":"code","de2d4307":"markdown","47bdac9f":"markdown","6ae65198":"markdown","cd0ef760":"markdown","c823227e":"markdown","c7237050":"markdown"},"source":{"9f9ca86f":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport os\nfrom torchvision import transforms,models\nimport torchvision\nimport shutil\nfrom tqdm.autonotebook import tqdm\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport copy\nimport torch.nn.functional as F\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score","5d510d15":"os.listdir('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/')","e93cf89a":"class config:\n    data_root = '\/kaggle\/working\/'\n    data_path = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/'\n    n_folds = 5\n    augmentation = False\n    batch_size = 64\n    epochs = 20","186ee5c9":"train_dir = 'train'\nval_dir = 'val'\n\nclass_names = ['NORMAL','PNEUMONIA']","80bf0723":"mpl.rcParams['axes.grid'] = False\nmpl.rcParams['image.interpolation'] = 'nearest'\nmpl.rcParams['figure.figsize'] = 15, 25\n\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\n\ndef show_dataset(dataset, n = 6,n_sample = 0):\n  if n_sample == 0: n_sample = len(dataset)\n  img = np.vstack((np.hstack((np.asarray(dataset[i][0].permute(1, 2, 0).numpy() * std + mean )for _ in range(n)))\n                   for i in range(n_sample)))\n    \n  plt.imshow(img)\n  plt.axis('off')","96e44d8c":"train_transforms = transforms.Compose([\n    transforms.Resize((165,165)),                                              \n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((165,165)),                                              \n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_transforms_aug = transforms.Compose([\n    transforms.Resize((325,325)),\n    transforms.RandomCrop((165,165)),                                                  \n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","6369edcf":"dataset_example =  torchvision.datasets.ImageFolder(config.data_path + '\/val\/',train_transforms)","a9379e25":"show_dataset(dataset_example, n = 4,n_sample = 4)","ca74b3f8":"dataset_example =  torchvision.datasets.ImageFolder(config.data_path + '\/val\/',train_transforms_aug)","fe292ab2":"show_dataset(dataset_example, n = 4,n_sample = 5)","6ac1751d":"def train_model(fold,model, loss, optimizer, scheduler, num_epochs,early_stop,train_dataloader,val_dataloader,device):\n    \n    \n    loss_history = []\n    acc_history = []\n  \n    best_loss_val = 1000000\n    \n    improve_count = 0\n    for epoch in range(num_epochs):\n        print('\\nEpoch {}\/{}:'.format(epoch, num_epochs - 1), flush=True)\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                scheduler.step()\n                model.train()  \n            else:\n                dataloader = val_dataloader\n                model.eval()\n\n            running_loss = 0.\n            running_acc = 0.\n            running_recall = 0.\n            no_pos = 0\n            for inputs, labels in dataloader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                \n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    \n                    preds = F.log_softmax(preds, dim=1)\n                    \n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n                if sum(labels.data) > 0: running_recall += (preds_class[labels.data == 1] == 1).float().mean()\n                else: no_pos+=1\n\n            epoch_loss = running_loss \/ len(dataloader)\n            epoch_acc = running_acc \/ len(dataloader)\n            epoch_recall = running_recall \/ (len(dataloader)-no_pos)\n            \n            print('{} Loss: {:.4f} Acc: {:.4f} Recall: {:.4f}'.format(phase, epoch_loss, epoch_acc, epoch_recall), flush=True)\n            \n            if phase == 'train':\n              improve_count+=1 \n              loss_history.append(epoch_loss)\n              acc_history.append(epoch_acc)\n              \n            \n            elif phase == 'val' and best_loss_val > epoch_loss:\n              best_loss_val = epoch_loss    \n              best_model_val = copy.deepcopy(model)\n              save_epoch_val = epoch\n\n              improve_count = 0\n                \n              print('| save')\n\n            \n            if(phase == 'val' and improve_count == early_stop):\n                print('\\nLoss does not decrease {} epochs, learning is stopped'.format(early_stop))\n                \n                print('\\nModel from the {}th epoch with the best loss on val'.format(save_epoch_val))\n                \n                return loss_history,acc_history,best_model_val\n                    \n    print('\\nModel from the {}th epoch with the best loss on val'.format(save_epoch_val))\n    \n    return loss_history,acc_history,best_model_val","126f50ed":"class mod_AlexNet(torch.nn.Module):\n    def __init__(self,pooling = 'max'):\n        \n        super(mod_AlexNet,self).__init__()\n        \n        if pooling == 'max':\n            pooling_layer = torch.nn.MaxPool2d(kernel_size = 3,stride  = 2)\n        elif pooling == 'avg':\n            pooling_layer = torch.nn.AvgPool2d(kernel_size = 3,stride  = 2)\n        else:\n            raise NotImplementError\n        self.act = torch.nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.bn0 = torch.nn.BatchNorm2d(num_features = 3)\n        self.pool = pooling_layer\n        \n        self.conv1 = torch.nn.Conv2d(in_channels = 3,out_channels = 96,kernel_size = 11,padding = 5,stride = 3)\n        self.bn1 = torch.nn.BatchNorm2d(num_features = 96)\n        # pooling(96,27,27)\n        \n        self.conv2 = torch.nn.Conv2d(in_channels = 96,out_channels = 256,kernel_size = 3,padding = 1)\n        self.bn2= torch.nn.BatchNorm2d(num_features = 256)\n        # pooling(256,13,13)\n        \n        self.conv3 = torch.nn.Conv2d(in_channels = 256,out_channels = 384,kernel_size = 3,padding = 1)\n        self.bn3 = torch.nn.BatchNorm2d(num_features = 384)\n        \n        self.conv4 = torch.nn.Conv2d(in_channels = 384,out_channels = 384,kernel_size = 3,padding = 1)\n        self.bn4 = torch.nn.BatchNorm2d(num_features = 384)\n        \n        self.conv5 = torch.nn.Conv2d(in_channels = 384,out_channels = 256,kernel_size = 3,padding = 1)\n        self.bn5 = torch.nn.BatchNorm2d(num_features = 256)\n        # pooling(256,6,6)\n        \n        self.fc1 = torch.nn.Linear(6*6*256,4096)\n        \n        self.fc2 = torch.nn.Linear(4096,4096)\n        self.fc3 = torch.nn.Linear(4096,2)\n    \n    def forward(self,x):\n        \n        \n        x = self.bn0(x)\n        \n        x = self.pool(self.bn1(self.act(self.conv1(x))))\n        x = self.pool(self.bn2(self.act(self.conv2(x))))\n        x = self.bn3(self.act(self.conv3(x)))\n        x = self.bn4(self.act(self.conv4(x)))\n        \n        x = self.pool(self.bn5(self.act(self.conv5(x))))\n        \n        x = x.view(x.size(0),x.size(1)*x.size(2)*x.size(3))\n        \n        x = self.act(self.fc1(x))\n        x = self.dropout(x)\n        \n        x = self.act(self.fc2(x))\n        \n        x = self.dropout(x)\n        \n        x = self.fc3(x)\n        \n        return x","ba43c1d0":"def run(fold):\n    \n    for dir_name in [train_dir,val_dir]:\n        for class_name in class_names:\n            os.makedirs(os.path.join(config.data_root,str(fold)+'_fold',dir_name,class_name))\n            \n    for class_name in class_names:\n        source_dir = os.path.join(config.data_path,'train',class_name)\n        for i,file_name in enumerate(os.listdir(source_dir)):\n            if (i + 1 + fold ) % (config.n_folds) == 0:\n                dest_dir = os.path.join(config.data_root,str(fold)+'_fold',val_dir, class_name)\n            else: dest_dir = os.path.join(config.data_root,str(fold)+'_fold',train_dir, class_name)\n            shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))\n            \n    model = mod_AlexNet(pooling = 'avg')\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    class_weights = torch.tensor([3.0544, 1.0583]).to(device)\n    loss = nn.NLLLoss(class_weights)\n\n    optimizer = torch.optim.SGD(model.parameters(), lr=1.0e-3)\n\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.1)\n    \n    if config.augmentation: train_transform = train_transforms_aug\n    else: train_transform = train_transforms\n        \n    batch_size = config.batch_size\n    \n    train_dataset =  torchvision.datasets.ImageFolder(config.data_root+str(fold) + '_fold\/'+'train',train_transform)\n    val_dataset =  torchvision.datasets.ImageFolder(config.data_root+str(fold) + '_fold\/'+'val',val_transforms)\n    \n    train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size,\n                                               num_workers = 4,shuffle = True)\n    val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size = batch_size,\n                                             num_workers = 4,shuffle = False)\n    \n    _,_,model = train_model(fold,model, loss, optimizer, scheduler, num_epochs  = config.epochs,early_stop = 5,train_dataloader = train_dataloader,val_dataloader = val_dataloader,device = device);\n    \n    torch.save(model.state_dict(), str(fold) + '_model.pth')\n    \n    del model\n    \n    shutil.rmtree(\"\/kaggle\/working\/\"+str(fold)+\"_fold\")\n    ","2bcb577e":"run(fold = 0)","15904c3e":"run(fold = 1)","7af28035":"run(fold = 2)","930c531f":"run(fold = 3)","1c4395ca":"run(fold = 4)","e6b5e10a":"test_dir = 'test'\nshutil.copytree(os.path.join(config.data_path, 'test'), os.path.join(config.data_root,test_dir, 'unknown'))","76a93fd3":"test_dataset = torchvision.datasets.ImageFolder(os.path.join(config.data_root,test_dir, 'unknown'), val_transforms)\n#test_dataset = torchvision.datasets.ImageFolder(config.data_root + '\/0_fold\/val\/',val_transforms)\nbatch_size = config.batch_size\n\ntest_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size = 64,\n                                               num_workers = 4,shuffle = False)","90fc3633":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","b31dbabc":"model0 = mod_AlexNet(pooling = 'avg')\nmodel0.to(device)\nmodel0.load_state_dict(torch.load(\"0_model.pth\"))\nmodel0.eval()\n\nmodel1 = mod_AlexNet(pooling = 'avg')\nmodel1.to(device)\nmodel1.load_state_dict(torch.load(\"1_model.pth\"))\nmodel1.eval()\n\nmodel2 = mod_AlexNet(pooling = 'avg')\nmodel2.to(device)\nmodel2.load_state_dict(torch.load(\"2_model.pth\"))\nmodel2.eval()\n\nmodel3 = mod_AlexNet(pooling = 'avg')\nmodel3.to(device)\nmodel3.load_state_dict(torch.load(\"3_model.pth\"))\nmodel3.eval()\n\nmodel4 = mod_AlexNet(pooling = 'avg')\nmodel4.to(device)\nmodel4.load_state_dict(torch.load(\"4_model.pth\"))\nmodel4.eval();","4a99c6f0":"true_labels = []\n\npred_0,pred_1,pred_2,pred_3,pred_4,pred = [],[],[],[],[],[]\n\nfor inputs, labels in tqdm(test_dataloader):\n    inputs, labels = inputs.to(device), labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds0 = F.softmax(model0(inputs),1).cpu().numpy()\n        preds1 = F.softmax(model1(inputs),1).cpu().numpy()\n        preds2 = F.softmax(model2(inputs),1).cpu().numpy()\n        preds3 = F.softmax(model3(inputs),1).cpu().numpy()\n        preds4 = F.softmax(model4(inputs),1).cpu().numpy()\n        \n    pred_0 += list(np.argmax(preds0,1))\n    pred_1 += list(np.argmax(preds1,1))\n    pred_2 += list(np.argmax(preds2,1))\n    pred_3 += list(np.argmax(preds3,1))\n    pred_4 += list(np.argmax(preds4,1))\n    \n    pred += list(preds0[:,1] + preds1[:,1] + preds2[:,1] + preds3[:,1] + preds4[:,1])\n    true_labels += list(labels.cpu().numpy())\n    ","075c0061":"print('ACC 0 model {:.4f} Recall {:.4f}'.format(accuracy_score(true_labels,pred_0),recall_score(true_labels,pred_0)))\nprint('ACC 1 model {:.4f} Recall {:.4f}'.format(accuracy_score(true_labels,pred_1),recall_score(true_labels,pred_1)))\nprint('ACC 2 model {:.4f} Recall {:.4f}'.format(accuracy_score(true_labels,pred_2),recall_score(true_labels,pred_2)))\nprint('ACC 3 model {:.4f} Recall {:.4f}'.format(accuracy_score(true_labels,pred_3),recall_score(true_labels,pred_3)))\nprint('ACC 4 model {:.4f} Recall {:.4f}'.format(accuracy_score(true_labels,pred_4),recall_score(true_labels,pred_4)))","af2031fb":"pred = np.array(pred)\/5\nanswer = [1 if p > 0.5 else 0 for p in pred]","695ac05b":"print('Final ACC: {:.4f} Recall: {:.4f}'.format(accuracy_score(true_labels,answer),recall_score(true_labels,answer)))","de2d4307":"dataset without augmentation","47bdac9f":"## Test","6ae65198":"### Data Augmentation","cd0ef760":"with augmentation","c823227e":"Neural network and training function ","c7237050":"Train models"}}