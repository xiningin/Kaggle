{"cell_type":{"0dcf458d":"code","3f8fd106":"code","457fb8aa":"code","3a5e73a2":"code","21f8fa4f":"code","5c796d61":"code","93eca8a0":"code","72820cfa":"code","b5443137":"code","6f6a111d":"code","aca722d3":"code","3dd04b79":"code","9a1824bd":"code","398ffc45":"code","b045185b":"code","e4dfb790":"code","0fdb2fab":"code","d33a5c50":"code","901e9b4d":"code","d751fdcb":"code","c471c608":"code","98a4e8ba":"code","3a4151c5":"markdown","faa97708":"markdown","2315d7e2":"markdown","df89d05e":"markdown","8b3d52bf":"markdown","2e8519c2":"markdown","a4f248c3":"markdown","b3d48a48":"markdown","e62b2cd0":"markdown","c28e1228":"markdown","4a807cda":"markdown","afa6610f":"markdown","f6a522c6":"markdown","5ec7c934":"markdown","85289a32":"markdown","1c871217":"markdown","59d208dd":"markdown"},"source":{"0dcf458d":"import numpy as np\nimport pandas as pd\nimport gc\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, Ridge, Lasso\nfrom sklearn.model_selection import KFold\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nimport warnings\nwarnings.filterwarnings(\"ignore\")","3f8fd106":"data = pd.read_csv('..\/input\/train.csv', index_col='id')\ntest = pd.read_csv('..\/input\/test.csv', index_col='id')","457fb8aa":"def process_datetime(df):\n    df['date'] = pd.to_datetime(df['date'].astype('str').str[:8])\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df = df.drop('date', axis=1)\n    return df\n\ndata = process_datetime(data)\ntest = process_datetime(test)","3a5e73a2":"x_data = data[[col for col in data.columns if col != 'price']]\ny_data = np.log1p(data['price'])\ndel data; gc.collect();","21f8fa4f":"def rmse(pred, true):\n    return -np.sqrt(np.mean((pred-true)**2))","5c796d61":"max_iterations = 10**5\nlgb_model = LGBMRegressor(objective='regression', num_iterations=max_iterations)\nxgb_model = XGBRegressor(objective='reg:linear', n_estimators=max_iterations)\ncb_model = CatBoostRegressor(loss_function='RMSE', iterations=max_iterations, allow_writing_files = False, depth=4, l2_leaf_reg=1, bootstrap_type='Bernoulli', subsample=0.5)","93eca8a0":"%%time\narchive = pd.DataFrame(columns=['models', 'prediction', 'score'])\nfor model in [lgb_model, xgb_model, cb_model]:\n    models = []\n    prediction = np.zeros(len(x_data))\n    for t, v in KFold(5, random_state=0).split(x_data):\n        x_train = x_data.iloc[t]\n        x_val = x_data.iloc[v]\n        y_train = y_data.iloc[t]\n        y_val = y_data.iloc[v]\n        model.fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False, early_stopping_rounds=100)\n        models.append(model)\n        prediction[v] = model.predict(x_val)\n    score = rmse(np.expm1(prediction), np.expm1(y_data))\n    print(score)\n    archive = archive.append({'models': models, 'prediction': prediction, 'score': score}, ignore_index=True)","72820cfa":"test_predictions = np.array([np.mean([model.predict(test) for model in models], axis=0) for models in archive['models']])","b5443137":"archive.head()","6f6a111d":"mean_stacked_prediction = np.mean([np.expm1(pred) for pred in archive['prediction']], axis=0)\nmean_stacked_score = rmse(mean_stacked_prediction, np.expm1(y_data))\nmean_stacked_score","aca722d3":"x_stack = np.array([np.expm1(pred) for pred in archive['prediction']]).transpose()\ny_stack = np.expm1(y_data)","3dd04b79":"lr_stacker = LinearRegression()\nridge_stacker = RidgeCV(alphas=np.logspace(-2, 3))\nlasso_stacker = LassoCV()","9a1824bd":"%%time\nstack_archive = pd.DataFrame(columns=['models', 'prediction', 'score'])\nfor stacker in [lr_stacker, ridge_stacker, lasso_stacker]:\n    prediction = np.zeros(len(x_stack))\n    models = []\n    for t, v in KFold(5, random_state=0).split(x_stack):\n        x_train = x_stack[t]\n        x_val = x_stack[v]\n        y_train = y_stack.iloc[t]\n        y_val = y_stack.iloc[v]\n        stacker.fit(x_train, y_train)\n        prediction[v] = stacker.predict(x_val)\n        models.append(stacker)\n    score = rmse(prediction, y_stack)\n    print(score)\n    stack_archive = stack_archive.append({'models': models, 'prediction': prediction, 'score': score}, ignore_index=True)","398ffc45":"stack_archive.head()","b045185b":"# linear regression\nnp.mean([model.coef_ for model in stack_archive.iloc[0, 0]], axis=0)","e4dfb790":"# ridge regression\nnp.mean([model.coef_ for model in stack_archive.iloc[1, 0]], axis=0)","0fdb2fab":"# lasso regression\nnp.mean([model.coef_ for model in stack_archive.iloc[2, 0]], axis=0)","d33a5c50":"mean_test_prediction = np.mean(np.expm1(test_predictions), axis=0)","901e9b4d":"lr_stacker = LinearRegression()\nlr_stacker.fit(x_stack, y_stack)\nlr_test_prediction = lr_stacker.predict(np.expm1(test_predictions).transpose())","d751fdcb":"ridge_stacker = Ridge(alpha=np.mean([model.alpha_ for model in stack_archive.iloc[1, 0]]))\nridge_stacker.fit(x_stack, y_stack)\nridge_test_prediction = ridge_stacker.predict(np.expm1(test_predictions).transpose())","c471c608":"lasso_stacker = Lasso(alpha=np.mean([model.alpha_ for model in stack_archive.iloc[2, 0]]))\nlasso_stacker.fit(x_stack, y_stack)\nlasso_test_prediction = lasso_stacker.predict(np.expm1(test_predictions).transpose())","98a4e8ba":"pd.DataFrame({'id': test.index, 'price': mean_test_prediction}).to_csv('mean_test_prediction.csv', index=False)\npd.DataFrame({'id': test.index, 'price': lr_test_prediction}).to_csv('lr_test_prediction.csv', index=False)\npd.DataFrame({'id': test.index, 'price': ridge_test_prediction}).to_csv('ridge_test_prediction.csv', index=False)\npd.DataFrame({'id': test.index, 'price': lasso_test_prediction}).to_csv('lasso_test_prediction.csv', index=False)","3a4151c5":"\uac00\uc7a5 \uc131\ub2a5\uc774 \uc88b\uc558\ub358 xgboost\uc5d0 \ub354 \ub192\uc740 \ube44\uc911\uc744 \uc8fc\uace0 \uc788\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\ub2e4.","faa97708":"## metric \uc815\uc758","2315d7e2":"## test prediction\n\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c mean stacking, lr stacking, ridge stacking, lasso stacking \ub124 \uac00\uc9c0\ub85c test prediction\uc744 \ub9cc\ub4e4\uc5b4 \uc81c\ucd9c\ud574\ubcf4\uc790.","df89d05e":"## \ubaa8\ub4c8 import \ubc0f \ub370\uc774\ud130 \uc77d\uae30","8b3d52bf":"## \uacb0\ub860\n\nsimple average\ubcf4\ub2e4 linear regression\uc73c\ub85c stack\ud558\ub294 \uac83\uc774 \uc131\ub2a5\uc774 \uc870\uae08\uc774\ub098\ub9c8 \ub354 \uc88b\uac8c \ub098\uc654\ub2e4.\n\nstacking diversity\ub97c \uc704\ud574 \uc131\ub2a5\uc774 \ube44\uad50\uc801 \ub5a8\uc5b4\uc9c0\ub294 \ub2e4\ub978 \ubaa8\ub378\ub4e4\uc744 \uc4f4\ub2e4\uba74 linear regression stacking\uc774 \uac16\ub294 \ud798\uc774 \ub354\uc6b1 \ucee4\uc9c8 \uac83\uc774\ub2e4.","2e8519c2":"## \ubaa8\ub378 \uc0dd\uc131\n\n\ncatboost\ub294 \uae30\ubcf8 \ud30c\ub77c\ubbf8\ud130\ub85c \ud6c8\ub828\uc2dc\ud0ac \uacbd\uc6b0 \uc810\uc218\uac00 \ub108\ubb34 \ub0ae\uac8c \ub098\uc640\uc11c \ud30c\ub77c\ubbf8\ud130\ub97c \uba87 \uac1c \ubcc0\uacbd\ud574\uc92c\uc2b5\ub2c8\ub2e4.","a4f248c3":"public leaderboard \uc810\uc218: 113536","b3d48a48":"## \ub2e8\uc21c \ud3c9\uade0 stacking","e62b2cd0":"linear stacking\uc774 mean stacking\ubcf4\ub2e4 \uadfc\uc18c\ud558\uac8c \uc131\ub2a5\uc774 \uc88b\uac8c \ub098\uc654\ub2e4.","c28e1228":"## \ud559\uc2b5\n\noof \uae30\ubc95\uc744 \uae30\ubcf8\uc73c\ub85c \uc138 \ubaa8\ub378\uc744 \uac01\uac01 \ud559\uc2b5\uc2dc\ud0a8 \ub4a4, archive\uc5d0 \uadf8 \uacb0\uacfc\ub97c \uae30\ub85d\ud569\ub2c8\ub2e4.","4a807cda":"## linear model\uc758 \uacc4\uc218","afa6610f":"public leaderboard \uc810\uc218: 110454","f6a522c6":"public leaderboard \uc810\uc218: 110454","5ec7c934":"## \uc804\ucc98\ub9ac\n\n\ub192\uc740 \uc810\uc218\ub97c \uc5bb\uae30 \uc704\ud55c \ucee4\ub110\uc774 \uc544\ub2c8\ubbc0\ub85c \uae30\ubcf8\uc801\uc778 feature engineering\ub9cc \ud588\uc2b5\ub2c8\ub2e4. (\ub0a0\uc9dc \ucc98\ub9ac, skewed target\uc5d0 log \ubcc0\ud658)","85289a32":"## \ub4e4\uc5b4\uac00\uae30 \uc804\uc5d0\n\n\ub300\ud68c\uc5d0\uc11c\ub294 \uc870\uae08\uc774\ub77c\ub3c4 \ub354 \ub192\uc740 \uc810\uc218\ub97c \uc5bb\uae30 \uc704\ud574 \uc5ec\ub7ec\uac1c\uc758 \ud6c8\ub828\ub41c \ubaa8\ub378\ub4e4\uc744 \ubaa8\ub450 \ud65c\uc6a9\ud558\ub294 stacking\uc774\ub77c\ub294 \uae30\ubc95\uc774 \uc790\uc8fc \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\n\ubaa8\ub378\uc758 \uc608\uce21\uac12\ub4e4\uc744 \ub2e8\uc21c\ud788 \ud3c9\uade0\ub0b4\ub294 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud560\uc218\ub3c4 \uc788\uc9c0\ub9cc, \uc608\uce21\uac12\ub4e4\uc744 \ub2e4\uc2dc linear regression \ubaa8\ub378\uc758 input\uc73c\ub85c \uc9d1\uc5b4\ub123\uc5b4 stacking\uc744 \uc704\ud55c \ubaa8\ub378\uc744 \ud558\ub098 \ub354 \ub9cc\ub4e4 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ucee4\ub110\uc5d0\uc11c\ub294 \uc774 \ub450 \ubc29\ubc95\uc744 \ube44\uad50\ud574\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\ubaa8\ub378\uc740 gbm\uc758 3\ub300\uc7a5 lightgbm, xgboost, catboost\ub97c \uc4f0\uaca0\uc2b5\ub2c8\ub2e4.","1c871217":"public leaderboard \uc810\uc218: 110491","59d208dd":"## stacking with regressor\n\n\ucc38\uace0\ub85c stacking \ud558\uae30 \uc804 input\uacfc target\uc744 np.expm1\uc73c\ub85c \uc6d0\uc0c1\ubcf5\uad6c \ud574\uc8fc\ub294 \uac83\uc774 \ub354 \uc810\uc218\uac00 \uc88b\uc558\ub2e4."}}