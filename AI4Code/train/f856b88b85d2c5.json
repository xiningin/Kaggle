{"cell_type":{"1a5380cb":"code","27139a07":"code","eff0e0d5":"code","6cdb4f11":"code","465408aa":"code","08cbe0a3":"code","d4c5ea16":"code","b18274b4":"code","66f42de3":"code","076aed47":"code","eba137a1":"code","235aaa63":"code","11aec4c8":"code","d1a89815":"code","b4207abf":"code","f94322d2":"code","f5abe1d9":"code","ea8c3272":"code","9b8f19c9":"code","ceafaf32":"code","01e1d0f6":"code","4666a137":"code","1654e2bd":"code","910065fd":"code","41306ec5":"code","6ebc5a2b":"code","080a41c8":"code","2a5a087b":"code","940084f1":"code","daf7a6b3":"code","09405cab":"code","5b9d7d6d":"code","88ae69d1":"code","143c4408":"code","d539166b":"code","d4f5481f":"code","d43287e7":"code","0f096a42":"code","795b9711":"code","df32e8ed":"code","d0c41ab1":"code","a0992ccb":"code","1c578b31":"code","fc9ba9dc":"code","5da2ce1a":"code","affe4ddb":"code","936eef3b":"code","9b252a5e":"code","b88dade7":"code","1fbd705a":"code","5410f9c8":"code","549a3cde":"code","c5a3cc35":"code","7bb8472f":"code","afe20006":"code","69034cbb":"code","f638d1ef":"code","d9957bdb":"code","c69709d8":"code","de5eb1cf":"markdown","f377e619":"markdown","c07cf11d":"markdown","e117c6d3":"markdown","2a978cac":"markdown","7398d64f":"markdown","1becfa44":"markdown","3008171c":"markdown","6873b9de":"markdown","d72cdcce":"markdown","ca030dfb":"markdown","818b4a01":"markdown","e94b256d":"markdown","e945b7b2":"markdown","1d529cbd":"markdown","e2875eb3":"markdown","dc033cf2":"markdown","131f553f":"markdown","3c6d6dd4":"markdown","98fac84f":"markdown","a30c1472":"markdown","9b248e3d":"markdown","5bedb46d":"markdown","4ff9789e":"markdown","c6e54878":"markdown","61ab2a40":"markdown","3cb72197":"markdown","48973e3b":"markdown","21e5d643":"markdown","02b8fb6b":"markdown","8646bbd5":"markdown","e7e3f4c9":"markdown","5846fe15":"markdown","2da96060":"markdown","38f6b606":"markdown","10d7e3e2":"markdown"},"source":{"1a5380cb":"# controlls the number of entries to be read in by the kernel\n# can speed up processing, is a small number if set here\nmax_events = None","27139a07":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D # needed for 3D scatter plots\n%matplotlib inline \nimport seaborn as sns\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nPATH='..\/input\/'\n\nimport os\nprint(os.listdir(PATH))","eff0e0d5":"train = pd.read_csv('{}\/train.csv'.format(PATH), nrows=max_events)\ntest  = pd.read_csv('{}\/test.csv'.format(PATH), nrows=max_events)\n\ny = train['Cover_Type']\ntrain.drop('Cover_Type', axis=1, inplace=True)\n\ntrain.drop('Id', axis=1, inplace=True)\ntest.drop('Id', axis=1, inplace=True)","6cdb4f11":"print('Train shape: {}'.format(train.shape))\nprint('Test  shape: {}'.format(test.shape))","465408aa":"train.info(verbose=False)","08cbe0a3":"y.value_counts()","d4c5ea16":"def convert_OHE2LE(df):\n    tmp_df = df.copy(deep=True)\n    for s_ in ['Soil_Type', 'Wilderness_Area']:\n        cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n        #deal with those OHE, where there is a sum over columns == 0\n        if 0 in sum_ohe:\n            print('The OHE in {} is incomplete. A new column will be added before label encoding'\n                  .format(s_))\n            # dummy colmn name to be added\n            col_dummy = s_+'_dummy'\n            # add the column to the dataframe\n            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n            # add the name to the list of columns to be label-encoded\n            cols_s_.append(col_dummy)\n            # proof-check, that now the category is complete\n            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n            if 0 in sum_ohe:\n                 print(\"The category completion did not work\")\n        tmp_df[s_ + '_LE'] = tmp_df[cols_s_].idxmax(axis=1).str.replace(s_,'').astype(np.uint16)\n        tmp_df.drop(cols_s_, axis=1, inplace=True)\n    return tmp_df\n\n\n\ndef train_test_apply_func(train_, test_, func_):\n    xx = pd.concat([train_, test_])\n    xx_func = func_(xx)\n    train_ = xx_func.iloc[:train_.shape[0], :]\n    test_  = xx_func.iloc[train_.shape[0]:, :]\n\n    del xx, xx_func\n    return train_, test_","b18274b4":"train_x, test_x = train_test_apply_func(train, test, convert_OHE2LE)","66f42de3":"train_x.head()","076aed47":"train_x.hist(figsize=(16,12),bins=40)\nplt.show()","eba137a1":"test_x.hist(figsize=(16,12), bins=40)\nplt.show()","235aaa63":"test_weight_orig_map = {1: 0.37053, 2: 0.49681, 3: 0.05936, 4:0.00103, 5: 0.01295, 6: 0.02687, 7: 0.03242}\ntrain_x.hist(figsize=(16,12),bins=40, weights=y.map(test_weight_orig_map))\nplt.show()","11aec4c8":"# Parametrise aspect function using a simle fit closely following solution from https:\/\/stackoverflow.com\/a\/16716964\/9640384\ny_, x_, _ = plt.hist(test_x['Aspect'], bins=30)\n\nt = x_[:-1] + np.diff(x_)\/2\ndata = y_\n\nfrom scipy.optimize import leastsq\n\n#def func_aspect(x)\n\nguess_mean = np.mean(y_)\nguess_std = np.std(y_)\nguess_phase = 0\nguess_freq = np.pi\/360\n\noptimize_func = lambda x: (x[0]*np.cos(x[1]*t+x[2]) + x[3] - data)\/np.sqrt(data)\nest_amp, est_freq, est_phase, est_mean = leastsq(optimize_func, [guess_std, guess_freq, guess_phase, guess_mean])[0]\n\nfine_t = np.arange(0,max(t),0.1)\ndata_fit = est_amp*np.cos(est_freq*fine_t+est_phase)+est_mean\ndata_first_guess = guess_std*np.cos(guess_freq*fine_t+guess_phase) + guess_mean\n\nplt.plot(fine_t, data_first_guess, label='first guess')\nplt.plot(fine_t, data_fit, label='after fitting')\nplt.xlabel('Aspect')\nplt.legend()\nplt.show()\n\nprint('Fit parameters: \\n Amplitude = {:.1f}\\n Frequency = {:.4f}\\n Phase shift = {:.4f}\\n Pedestal = {:.1f}'.format(est_amp, est_freq, est_phase, est_mean))","d1a89815":"def plot3D_hillshade(X_, y_, x_str='Aspect', y_str='Slope', z_str='Hillshade_3pm', figsize=(17,8)):\n    fig = plt.figure(figsize=figsize)\n    ax = plt.axes(projection='3d')\n\n    p = ax.scatter(X_[x_str], X_[y_str], X_[z_str], c=(y_ if y_ is not None else X_[z_str]))\n    _ = ax.set_xlabel(x_str)\n    _ = ax.set_ylabel(y_str)\n    _ = ax.set_zlabel(z_str)\n    plt.colorbar(p, ax=ax)","b4207abf":"plot3D_hillshade(train_x, None, z_str='Hillshade_3pm')\n_ = plt.title('TRAIN sample')","f94322d2":"plot3D_hillshade(test_x, None, z_str='Hillshade_3pm')\n_ = plt.title('TEST sample')","f5abe1d9":"# define a grid for visualisation\nx_aspect = np.linspace(0, 360, 360)\nx_slope  = np.linspace(0, 60, 60)\ngrid_aspect, grid_slope = np.meshgrid(x_aspect, x_slope)\ngrid_aspect = grid_aspect.ravel()\ngrid_slope = grid_slope.ravel()\n\n# a simplified version of `plot3D_hillshade` function\ndef plot3D_basic(x, y, z, figsize=(17,8)):\n    fig = plt.figure(figsize=figsize)\n    ax = plt.axes(projection='3d')\n    p = ax.scatter(x, y, z, c=z)\n    plt.colorbar(p, ax=ax)\n\n# select the training data with non-zero `Hillshade_3pm`\ntrain_nonzero_3pm = train_x.query('Hillshade_3pm >= 1')\n    \n# train a KNN model on the full train set for illustration purpose only\nfrom sklearn.neighbors import KNeighborsRegressor\nk=100\nknn = KNeighborsRegressor(n_neighbors=k).fit(train_nonzero_3pm[['Aspect', 'Slope']], \n                                             train_nonzero_3pm['Hillshade_3pm'])\n#predict on the predefined grid for plotting\npreds_3pm = knn.predict(pd.DataFrame({'Aspect': grid_aspect,\n                                      'Slope':  grid_slope}))\n#Do the final plot\nplot3D_basic(grid_aspect, grid_slope, preds_3pm)\n_ = plt.title('KNN: {}'.format(k))","ea8c3272":"plot3D_hillshade(train_x, None, z_str='Hillshade_Noon')","9b8f19c9":"plot3D_hillshade(train_x, None, z_str='Hillshade_9am')","ceafaf32":"plot3D_hillshade(train_x, None, x_str='Hillshade_9am', y_str='Hillshade_Noon', z_str='Hillshade_3pm')","01e1d0f6":"# import plotly\n# import plotly.plotly as py\n# import plotly.graph_objs as go\n# plotly.offline.init_notebook_mode(connected=True)\n# import cufflinks as cf","4666a137":"# train_x.iplot(kind='scatter3D', x='Aspect', y='Slope', z='Hillshade_3pm', bgcolor='yellowgreen')","1654e2bd":"#plotly.__version__","910065fd":"def plotc(c1, c2, labels, size=10, doGrid=True):\n    fig = plt.figure(figsize=(16,8))\n\n    plt.scatter(c1, c2, c=labels.values, s=size)\n    plt.colorbar()\n    plt.xlabel(c1.name)\n    plt.ylabel(c2.name)\n    if doGrid:\n        plt.grid(True)","41306ec5":"plotc(train_x['Vertical_Distance_To_Hydrology'],  train_x['Elevation'], y, size=10)","6ebc5a2b":"plotc(train_x['Vertical_Distance_To_Hydrology'], train_x['Elevation']-train_x['Vertical_Distance_To_Hydrology'], y, size=10)","080a41c8":"plotc(train_x['Horizontal_Distance_To_Hydrology'], train_x['Elevation'],   y)","2a5a087b":"plotc(train_x['Horizontal_Distance_To_Hydrology'], train_x['Elevation']- train_x['Horizontal_Distance_To_Hydrology']*0.2,  y)","940084f1":"def preprocess(df_):\n    #df_.drop('Elevation', axis=1, inplace=True)\n    df_['fe_E_Min_02HDtH'] = df_['Elevation']- df_['Horizontal_Distance_To_Hydrology']*0.2\n    df_['fe_Distance_To_Hydrology'] = np.sqrt(df_['Horizontal_Distance_To_Hydrology']**2 + \n                                              df_['Vertical_Distance_To_Hydrology']**2)\n    \n    feats_sub = [('E_Min_VDtH', 'Elevation', 'Vertical_Distance_To_Hydrology'),\n                 ('HD_Hydrology_Min_Roadways', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways'),\n                 ('HD_Hydrology_Min_Fire', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points'),\n                 ('Hillshade_9am_Min_Noon', 'Hillshade_9am', 'Hillshade_Noon'),\n                 ('Hillshade_Noon_Min_3pm', 'Hillshade_Noon', 'Hillshade_3pm'),\n                 ('Hillshade_9am_Min_3pm', 'Hillshade_9am', 'Hillshade_3pm')\n                ]\n    feats_add = [('E_Add_VDtH', 'Elevation', 'Vertical_Distance_To_Hydrology'),\n                 ('HD_Hydrology_Add_Roadways', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways'),\n                 ('HD_Hydrology_Add_Fire', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points'),\n                 ('Hillshade_9am_Add_Noon', 'Hillshade_9am', 'Hillshade_Noon'),\n                 ('Hillshade_Noon_Add_3pm', 'Hillshade_Noon', 'Hillshade_3pm'),\n                 ('Hillshade_9am_Add_3pm', 'Hillshade_9am', 'Hillshade_3pm')\n                ]\n    \n    for f_new, f1, f2 in feats_sub:\n        df_['fe_' + f_new] = df_[f1] - df_[f2]\n    for f_new, f1, f2 in feats_add:\n        df_['fe_' + f_new] = df_[f1] + df_[f2]\n        \n    df_['fe_Hillshade_Mean'] = (df_['Hillshade_9am'] + df_['Hillshade_Noon'] + df_['Hillshade_3pm'])\/3\n    df_['fe_Hillshade_Mean_Div_E'] = (df_['fe_Hillshade_Mean'] \/ df_['Elevation']).clip(upper=255)\n    df_['fe_Hillshade_Mean_Div_Aspect'] = (df_['fe_Hillshade_Mean'] \/ df_['Aspect']).clip(upper=255)\n    \n    # A few composite variables\n    df_['fe_Hillshade_Ratio1'] = (df_['fe_Hillshade_9am_Min_Noon'] \/ df_['fe_Hillshade_Noon_Min_3pm']).clip(lower=-5, upper=2)\n    df_['fe_Hillshade_Ratio2'] = (df_['fe_Hillshade_9am_Min_3pm']  \/ df_['Hillshade_Noon']).clip(lower=-2, upper=2)\n        \n    # The feature is advertised in https:\/\/douglas-fraser.com\/forest_cover_management.pdf\n    df_['fe_Shade9_Mul_VDtH'] = df_['Hillshade_9am'] * df_['Vertical_Distance_To_Hydrology']\n    \n    # Features inherited from https:\/\/www.kaggle.com\/leannelong3\/r-random-forest\n    df_['Elevation_bins50'] = np.floor_divide(df_['Elevation'], 50)\n    df_['fe_Horizontal_Distance_To_Roadways_Log'] = np.log1p(df_['Horizontal_Distance_To_Roadways'])\n\n    # this mapping comes from https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/covtype\/covtype.info\n    climatic_zone = {}\n    geologic_zone = {}\n    for i in range(1,41):\n        if i <= 6:\n            climatic_zone[i] = 2\n            geologic_zone[i] = 7\n        elif i <= 8:\n            climatic_zone[i] = 3\n            geologic_zone[i] = 5\n        elif i == 9:\n            climatic_zone[i] = 4\n            geologic_zone[i] = 2\n        elif i <= 13:\n            climatic_zone[i] = 4\n            geologic_zone[i] = 7\n        elif i <= 15:\n            climatic_zone[i] = 5\n            geologic_zone[i] = 1\n        elif i <= 17:\n            climatic_zone[i] = 6\n            geologic_zone[i] = 1\n        elif i == 18:\n            climatic_zone[i] = 6\n            geologic_zone[i] = 7\n        elif i <= 21:\n            climatic_zone[i] = 7\n            geologic_zone[i] = 1\n        elif i <= 23:\n            climatic_zone[i] = 7\n            geologic_zone[i] = 2\n        elif i <= 34:\n            climatic_zone[i] = 7\n            geologic_zone[i] = 7\n        else:\n            climatic_zone[i] = 8\n            geologic_zone[i] = 7\n            \n    df_['Climatic_zone_LE'] = df_['Soil_Type_LE'].map(climatic_zone).astype(np.uint8)\n    df_['Geologic_zone_LE'] = df_['Soil_Type_LE'].map(geologic_zone).astype(np.uint8)\n    \n    for c in df_.columns:\n        if c.startswith('fe_'):\n            df_[c] = df_[c].astype(np.float32)\n    return df_","daf7a6b3":"train_x = preprocess(train_x)\ntest_x = preprocess(test_x)","09405cab":"from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom  sklearn.linear_model import LogisticRegression\nimport lightgbm as lgb","5b9d7d6d":"y = y-1","88ae69d1":"X_train, X_test, y_train, y_test = train_test_split(train_x, y, test_size=0.15, random_state=315, stratify=None)","143c4408":"test_weight_map = {0: 0.37053, 1: 0.49681, 2: 0.05936, 3:0.00103, 4: 0.01295, 5: 0.02687,6 : 0.03242}","d539166b":"train_x.describe()","d4f5481f":"def learning_rate_decay_power_0995(current_iter):\n    base_learning_rate = 0.15\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return lr if lr > 1e-2 else 1e-2\n\nclf_inputs = {'rf': (RandomForestClassifier(n_estimators=200, max_depth=1, random_state=314, n_jobs=4),\n               {'max_depth': 30}, \n               {}),\n        'rf_test': (RandomForestClassifier(n_estimators=200, max_depth=1, random_state=314, n_jobs=4,\n                                           class_weight=test_weight_map),\n               {'max_depth': 30}, \n               {}),\n        'xt400': (ExtraTreesClassifier(n_estimators=400, max_depth=1, max_features='auto',random_state=314, n_jobs=4,\n                                       criterion='entropy'),\n               {'max_depth': 25},\n               {}),\n        'xt400_test': (ExtraTreesClassifier(n_estimators=400, max_depth=1, max_features='auto',random_state=314, n_jobs=4,\n                                            class_weight=test_weight_map, criterion='entropy'),\n               {'max_depth': 25},\n               {}),\n        'lgbm': (lgb.LGBMClassifier(max_depth=-1, min_child_samples=400, \n                                 random_state=314, silent=True, metric='None', \n                                 n_jobs=4, n_estimators=5000, learning_rate=0.1), \n                 {'loss': 'multiclass', 'colsample_bytree': 0.75, 'min_child_weight': 1, 'num_leaves': 20, 'subsample': 0.75}, \n                 {'eval_set': [(X_train, y_train), (X_test, y_test)], \n                  'eval_names': ['train', 'early_stop'],\n                  'eval_metric': 'multi_error', 'verbose':500, 'early_stopping_rounds':100, \n                  'callbacks':[lgb.reset_parameter(learning_rate=learning_rate_decay_power_0995)]}\n                ),\n        'lgbm_test': (lgb.LGBMClassifier(max_depth=-1, min_child_samples=400, \n                                 random_state=314, silent=True, metric='None', \n                                 n_jobs=4, n_estimators=5000, learning_rate=0.1,\n                                        class_weight=test_weight_map), \n                 {'loss': 'multiclass', 'colsample_bytree': 0.75, 'min_child_weight': 1, 'num_leaves': 20, 'subsample': 0.75}, \n                 {'eval_set': [(X_train, y_train), (X_test, y_test)], \n                  'eval_names': ['train', 'early_stop'],\n                  'eval_class_weight': [{}, test_weight_map],\n                  'eval_metric': 'multi_error', 'verbose':500, 'early_stopping_rounds':100, \n                  'callbacks':[lgb.reset_parameter(learning_rate=learning_rate_decay_power_0995)]}\n                )\n       }","d43287e7":"clfs = {}\nfor name, (clf, clf_pars, fit_pars) in clf_inputs.items():\n    print('--------------- {} -----------'.format(name))\n    clf.set_params(**clf_pars)\n    clf = clf.fit(X_train, y_train, **fit_pars)\n    acc_pars={}\n    print('{}: with\/without weight  train = {:.4f}\/{:.4f}, test = {:.4f}\/{:.4f}'.format(name,\n        accuracy_score(y_train, clf.predict(X_train), sample_weight=y_train.map(test_weight_map)),\n        accuracy_score(y_train, clf.predict(X_train)),\n        accuracy_score(y_test,  clf.predict(X_test), sample_weight=y_test.map(test_weight_map)),\n        accuracy_score(y_test,  clf.predict(X_test))\n                                                     )\n         )\n    clfs[name] = clf.fit(train_x, y, **fit_pars)","0f096a42":"def display_importances(feature_importance_df_, n_feat=30, silent=False, dump_strs=[], fout_name=None):\n    '''\n    Make a plot of most important features from a tree-based model\n\n    Parameters\n    ----------\n    feature_importance_df_ : pd.DataFrame\n        The input dataframe. \n        Must contain columns `'feature'` and `'importance'`.\n        The dataframe will be first grouped by `'feature'` and the mean `'importance'` will be calculated.\n        This allows to calculate and plot importance averaged over folds, \n        when the same features appear in the dataframe as many time as there are folds in CV.\n    n_feats : int [default: 20]\n        The maximum number of the top features to be plotted\n    silent : bool [default: False]\n        Dump additionsl information, in particular the mean importances for features \n        defined by `dump_strs` and the features with zero (<1e-3) importance\n    dump_strs : list of strings [default: []]\n        Features containing either of these srings will be printed to the screen\n    fout_name : str or None [default: None]\n        The name of the file to dump the figure. \n        If `None`, no file is created (to be used in notebooks)\n    '''\n    # Plot feature importances\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n            by=\"importance\", ascending=False)[:n_feat].index  \n    \n    mean_imp = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\n    df_2_neglect = mean_imp[mean_imp['importance'] < 1e-3]\n    \n    if not silent:\n        print('The list of features with 0 importance: ')\n        print(df_2_neglect.index.values.tolist())\n\n        pd.set_option('display.max_rows', 500)\n        pd.set_option('display.max_columns', 500)\n        for feat_prefix in dump_strs:\n            feat_names = [x for x in mean_imp.index if feat_prefix in x]\n            print(mean_imp.loc[feat_names].sort_values(by='importance', ascending=False))\n    del mean_imp, df_2_neglect\n    \n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    \n    plt.figure(figsize=(8,10))\n    sns.barplot(x=\"importance\", y=\"feature\", \n                data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('Features (avg over folds)')\n    plt.tight_layout()\n\n    if fout_name is not None:\n        plt.savefig(fout_name)","795b9711":"display_importances(pd.DataFrame({'feature': train_x.columns,\n                                  'importance': clfs['xt400_test'].feature_importances_}),\n                    silent=True)","df32e8ed":"display_importances(pd.DataFrame({'feature': train_x.columns,\n                                  'importance': clfs['xt400'].feature_importances_}),\n                    silent=True)","d0c41ab1":"display_importances(pd.DataFrame({'feature': train_x.columns,\n                                  'importance': clfs['rf_test'].feature_importances_}),\n                    silent=True)","a0992ccb":"display_importances(pd.DataFrame({'feature': train_x.columns,\n                                  'importance': clfs['rf'].feature_importances_}),\n                    silent=True)","1c578b31":"display_importances(pd.DataFrame({'feature': train_x.columns,\n                                  'importance': clfs['lgbm_test'].feature_importances_}),\n                    silent=True)","fc9ba9dc":"display_importances(pd.DataFrame({'feature': train_x.columns,\n                                  'importance': clfs['lgbm'].feature_importances_}),\n                    silent=True)","5da2ce1a":"display_importances(pd.DataFrame({'feature': train_x.columns,\n                                  'importance': clfs['lgbm_test'].booster_.feature_importance('gain')}),\n                    silent=True)","affe4ddb":"import shap\nshap_values = shap.TreeExplainer(clfs['lgbm'].booster_).shap_values(X_test)\nshap.summary_plot(shap_values, X_test, plot_type='bar')","936eef3b":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\nclass VotingPrefitClassifier(VotingClassifier):\n    '''\n    This implements the VotingClassifier with prefitted classifiers\n    '''\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        self.estimators_ = [x[1] for x in self.estimators]\n        self.le_ = LabelEncoder().fit(y)\n        self.classes_ = self.le_.classes_\n        \n        return self","9b252a5e":"# clf_inputs = {\n#         'xt200_test': (ExtraTreesClassifier(n_estimators=200, max_depth=1, max_features='auto',random_state=314, n_jobs=4,\n#                                             class_weight=test_weight_map),\n#                {'max_depth': 25},\n#                {})\n#        }","b88dade7":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.base import clone\n\ndef train_single_model(clf_, X_, y_, random_state_=314, opt_parameters_={}, fit_params_={}):\n    c = clone(clf_)\n    c.set_params(**opt_parameters_)\n    c.set_params(random_state=random_state_)\n    return c.fit(X_, y_, **fit_params_)\n\ndef train_model_in_nestedCV(model, X, y, metric, metric_args={},\n                            model_name='xmodel',\n                            inner_seed=31416, inner_n=10, outer_seed=314, outer_n=10,\n                            opt_parameters_={}, fit_params_={},\n                            verbose=True):\n    # the list of classifiers for voting ensable\n    clfs = []\n    # performance \n    perf_eval = {'score_i_oof': [],\n                 'score_i_ave': [],\n                 'score_i_std': [],\n                 'score_i_early_stop_ave': [],\n                 'score_o_early_stop': [],\n                 'score_o_early_stop_vc_w0_soft': [],\n                 'score_o_early_stop_vc_w0_hard': []\n                }\n    # full-sample oof prediction\n    y_full_oof = pd.Series(np.zeros(shape=(y.shape[0],)), \n                          index=y.index)\n    \n    if 'sample_weight' in metric_args:\n        sample_weight=metric_args['sample_weight']\n\n    outer_cv = StratifiedKFold(outer_n, shuffle=True, random_state=outer_seed)\n    for n_outer_fold, (outer_trn_idx, outer_val_idx) in enumerate(outer_cv.split(X,y)):\n        print('--- Outer loop iteration: {} ---'.format(n_outer_fold))\n        X_out, y_out = X.iloc[outer_trn_idx], y.iloc[outer_trn_idx]\n        X_stp, y_stp = X.iloc[outer_val_idx], y.iloc[outer_val_idx]\n\n        inner_cv = StratifiedKFold(inner_n, shuffle=True, random_state=inner_seed+n_outer_fold)\n        # The out-of-fold (oof) prediction for the k-1 sample in the outer CV loop\n        y_outer_oof = pd.Series(np.zeros(shape=(X_out.shape[0],)), \n                          index=X_out.index)\n        scores_inner = []\n        clfs_inner = []\n\n        for n_inner_fold, (inner_trn_idx, inner_val_idx) in enumerate(inner_cv.split(X_out,y_out)):\n            X_trn, y_trn = X_out.iloc[inner_trn_idx], y_out.iloc[inner_trn_idx]\n            X_val, y_val = X_out.iloc[inner_val_idx], y_out.iloc[inner_val_idx]\n\n            if fit_params_:\n                # use _stp data for early stopping\n                fit_params_[\"eval_set\"] = [(X_trn,y_trn), (X_stp,y_stp)]\n                fit_params_['verbose'] = False\n\n            clf = train_single_model(model, X_trn, y_trn, 314+n_inner_fold, opt_parameters_, fit_params_)\n\n            clfs_inner.append(('{}{}_inner'.format(model_name,n_inner_fold), clf))\n            # evaluate performance\n            y_outer_oof.iloc[inner_val_idx] = clf.predict(X_val)\n            if 'sample_weight' in metric_args:\n                metric_args['sample_weight'] = y_val.map(sample_weight)\n            scores_inner.append(metric(y_val, y_outer_oof.iloc[inner_val_idx], **metric_args))\n            #cleanup\n            del X_trn, y_trn, X_val, y_val\n\n        # Store performance info for this outer fold\n        if 'sample_weight' in metric_args:\n            metric_args['sample_weight'] = y_outer_oof.map(sample_weight)\n        perf_eval['score_i_oof'].append(metric(y_out, y_outer_oof, **metric_args))\n        perf_eval['score_i_ave'].append(np.mean(scores_inner))\n        perf_eval['score_i_std'].append(np.std(scores_inner))\n        \n        # Do the predictions for early-stop sub-sample for comparison with VotingPrefitClassifier\n        if 'sample_weight' in metric_args:\n            metric_args['sample_weight'] = y_stp.map(sample_weight)\n        score_inner_early_stop = [metric(y_stp, clf_.predict(X_stp), **metric_args)\n                                   for _,clf_ in clfs_inner]\n        perf_eval['score_i_early_stop_ave'].append(np.mean(score_inner_early_stop))\n        \n        # Record performance of Voting classifiers\n        w = np.array(scores_inner)\n        for w_, w_name_ in [(None, '_w0')#,\n                            #(w\/w.sum(), '_w1'),\n                            #((w**2)\/np.sum(w**2), '_w2')\n                           ]:\n            vc = VotingPrefitClassifier(clfs_inner, weights=w_).fit(X_stp, y_stp)\n            for vote_type in ['soft', 'hard']:\n                vc.voting = vote_type\n                if 'sample_weight' in metric_args:\n                    metric_args['sample_weight'] = y_stp.map(sample_weight)\n                perf_eval['score_o_early_stop_vc{}_{}'.format(w_name_, vote_type)].append(metric(y_stp, vc.predict(X_stp), **metric_args))\n\n        if fit_params_:\n            # Train main model for the voting average\n            fit_params_[\"eval_set\"] = [(X_out,y_out), (X_stp,y_stp)]\n            if verbose:\n                fit_params_['verbose'] = 200\n        #print('Fit the final model on the outer loop iteration: ')\n        clf = train_single_model(model, X_out, y_out, 314+n_outer_fold, opt_parameters_, fit_params_)\n        if 'sample_weight' in metric_args:\n            metric_args['sample_weight'] = y_stp.map(sample_weight)\n        perf_eval['score_o_early_stop'].append(metric(y_stp, clf.predict(X_stp), **metric_args))\n        clfs.append(('{}{}'.format(model_name,n_outer_fold), clf))\n        y_full_oof.iloc[outer_val_idx] = clf.predict(X_stp)\n        # cleanup\n        del inner_cv, X_out, y_out, X_stp, y_stp, clfs_inner\n\n    return clfs, perf_eval, y_full_oof\n\ndef print_nested_perf_clf(name, perf_eval):\n    print('Performance of the inner-loop model (the two should agree):')\n    print('  Mean(mean(Val)) score inner {} Classifier: {:.4f}+-{:.4f}'.format(name, \n                                                                      np.mean(perf_eval['score_i_ave']),\n                                                                      np.std(perf_eval['score_i_ave'])\n                                                                     ))\n    print('  Mean(mean(EarlyStop)) score inner {} Classifier: {:.4f}+-{:.4f}'.format(name, \n                                                                      np.mean(perf_eval['score_i_early_stop_ave']),\n                                                                      np.std(perf_eval['score_i_early_stop_ave'])\n                                                                     ))\n    print('Mean(inner OOF) score inner {} Classifier: {:.4f}+-{:.4f}'.format(name, \n                                                                       np.mean(perf_eval['score_i_oof']), \n                                                                       np.std(perf_eval['score_i_oof'])\n                                                                      ))\n    print('Mean(EarlyStop) score outer {} Classifier: {:.4f}+-{:.4f}'.format(name, \n                                                                      np.mean(perf_eval['score_o_early_stop']),\n                                                                      np.std(perf_eval['score_o_early_stop'])\n                                                                     ))\n    print('Mean(EarlyStop) outer VotingPrefit SOFT: {:.4f}+-{:.4f}'.format(np.mean(perf_eval['score_o_early_stop_vc_w0_soft']),\n                                                                           np.std(perf_eval['score_o_early_stop_vc_w0_soft'])                                                                    \n                                                                    ))\n    print('Mean(EarlyStop) outer VotingPrefit HARD: {:.4f}+-{:.4f}'.format(np.mean(perf_eval['score_o_early_stop_vc_w0_hard']),\n                                                                           np.std(perf_eval['score_o_early_stop_vc_w0_hard'])\n                                                                    ))","1fbd705a":"for k in [name for name in clf_inputs if '_test' not in name]:\n    del clf_inputs[k]\n\nclfss = {}\nvcs = {}\nresults = {}\nfor name, (clf, clf_pars, fit_pars) in clf_inputs.items():\n    print('--------------- {} -----------'.format(name))\n    clfs_, perf_eval, y_full_oof = train_model_in_nestedCV(clf, train_x, y, accuracy_score, \n                                                          metric_args={} if '_test' not in name else {'sample_weight': test_weight_map},\n                                                          model_name=name, \n                                                          opt_parameters_=clf_pars,\n                                                          fit_params_=fit_pars, \n                                                          inner_n=10, outer_n=10,\n                                                          verbose=False)\n    results[name] = perf_eval\n    clfss[name] = clfs_\n    ws = [(None, '_w0')#,\n      #(w\/w.sum(), '_w1'),\n      #((w**2)\/np.sum(w**2), '_w2')\n     ]\n    vcs[name] = {}\n    for w_, w_name_ in ws:\n        vcs[name]['vc{}'.format(w_name_)] = VotingPrefitClassifier(clfs_, weights=w_).fit(train_x, y)\n\n    print_nested_perf_clf(name, perf_eval)\n    print('Outer OOF score {} Classifier: {:.4f}'.format(name, accuracy_score(y, y_full_oof, sample_weight=y.map(test_weight_map))))\n    ","5410f9c8":"pd.DataFrame(results['xt400_test'])","549a3cde":"!ls ..\/input\/","c5a3cc35":"sub = pd.read_csv(PATH + 'sample_submission.csv')","7bb8472f":"for name,clf in clfs.items():\n    print('------ {} -----------'.format(name))\n    sub['Cover_Type'] = clf.predict(test_x) + 1\n    sub.to_csv('submission_{}.csv'.format(name), index=False)","afe20006":"!ls","69034cbb":"for name,x in vcs.items():\n    print('------ {} -----------'.format(name))\n    clf = x['vc_w0']\n    sub['Cover_Type'] = clf.predict(test_x) + 1\n    sub.to_csv('submission_voting_{}.csv'.format(name), index=False)","f638d1ef":"vc_global_1 = VotingPrefitClassifier([(n, vcs[n]['vc_w0']) for n in vcs.keys()]).fit(train_x, y)\nl = []\nfor n in vcs.keys():\n    l = l + vcs[n]['vc_w0'].estimators\nvc_global_2 = VotingPrefitClassifier(l).fit(train_x, y)","d9957bdb":"for vote_type in ['hard']:\n    vc_global_1.voting = vote_type\n    vc_global_2.voting = vote_type\n    sub['Cover_Type'] = vc_global_1.predict(test_x) + 1\n    sub.to_csv('submission_voting_global_1_{}.csv'.format(vote_type), index=False)\n    sub['Cover_Type'] = vc_global_2.predict(test_x) + 1\n    sub.to_csv('submission_voting_global_2_{}.csv'.format(vote_type), index=False)","c69709d8":"vc_g","de5eb1cf":"# How to impute Hillside_3pm?\nLet's follow the proposal by @jmcminis in [this post](https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/discussion\/10693#62731):","f377e619":"Helper function to transfer One-Hot Encoding (OHE) into a Label Encoding (LE). It was taken from https:\/\/www.kaggle.com\/mlisovyi\/lighgbm-hyperoptimisation-with-f1-macro\n\nThe reason to convert OHE into LE is that we plan to use a tree-based model and such models are dealing well with simple interger-label encoding. Note, that this way we introduce an ordering between categories, which is not there in reality, but in practice in most use cases GBMs handle it well anyway.","c07cf11d":"# Feature importance with SHAP\n","e117c6d3":"# Voting classifier with nested CV evaluation","2a978cac":"Predictions for the global voting","7398d64f":"Note, that the proportion of the different classes in test is: `0.37053 : 0.49681 : 0.05936 : 0.00103 : 0.01295 : 0.02687 : 0.03242`, as is discussed in https:\/\/www.kaggle.com\/mlisovyi\/class-fractions-in-the-test","1becfa44":"# General configuration and imports","3008171c":"One little caveat: looking through the OHE, `Soil_Type 7, 15`, are present in the test, but not in the training data","6873b9de":"The head of the training dataset","d72cdcce":"These are the weights that correspond to the test\/submission class mixture. using these will allow to adjust importance of mistakes on different classes","ca030dfb":"# How do other Hillside_ variables look like?","818b4a01":"Note the spike at `Hillshade_3pm==0` that was originally pointed out by @aguschin in https:\/\/github.com\/aguschin\/kaggle\/blob\/master\/forestCoverType_featuresEngineering.ipynb\n\n### How do feature distributions look in the test sample?","e94b256d":"Most distributions look similar, but note that **`Elevation` profile is totally different between train and test samples**. There are also minor differences in `Soil_Type`. \n\nThe little spike at `Hillshade_3pm==0` is also present in the test sample.\n\n## Can we reroduce the test distributions? \nHow will the training dataset look like if we apply the mixing from the test sample?","e945b7b2":"# Contents and goals\nThis kernel shows how to:\n\n - retreave the data;\n - preprocess the data (transforming One-Hot Encoding into Label Encoding);\n - visualise of the data in 1, 2 and 3 dimentions;\n - engineer new features inspired by the visualisation done in the previous step;\n - **use proportion of target classes in the test data in the training and model evaluation to improve consistency between local CV and LB**. This is extremely important, as it brings the class mixture in agreemnet between available training and submission datasets, thus making local performance evaluation meaningful. Many kernels in the comp either do not have model performance evaluation, or do it without weights, which leads to a gap between local and LB scores.\n - build various models on the train\/test spit of the data and evaluate their performance. Hyper-parameters of the models are optimised in a dedicated kernel:  https:\/\/www.kaggle.com\/mlisovyi\/hyper-parameter-optimisation;\n - build voting classifiers and evaluated their performance in a nested cross-validation (CV);\n - prepare submissions\n \n Note, that the proportion of the different classes in test is: `0.37053 : 0.49681 : 0.05936 : 0.00103 : 0.01295 : 0.02687 : 0.03242`, as is discussed in https:\/\/www.kaggle.com\/mlisovyi\/class-fractions-in-the-test","1d529cbd":"# Train various classifiers","e2875eb3":"## Feature importances in the tree models\nNote that all models report different order of importance","dc033cf2":"The train\/test split is used in simple model training","131f553f":"## Aspect shape\nLet's parametrise `Aspect` feature, which looks like a cosine function. **We will not use it, but it is fun :)**","3c6d6dd4":"Here there is also a linear dependence, but it is weaker than what we saw before. We use the linear combination developed by @aguschin:","98fac84f":"# Access the data","a30c1472":"Is the sample imbalanced?","9b248e3d":"## Interactive 3D plots\nAt the moment `cufflinks` do not support `plotly>=3.0.0` (see [issue #119 on github](https:\/\/github.com\/santosjorge\/cufflinks\/issues\/119)) and kaggle docker image has `plotly==3.1.1`. So cufflinks are useless.  \n\nWriting directly in plotly is combersome, so this section is commented out for the time being","5bedb46d":"We see that the location of the `Hillshade_3pm==0` events is the same between train and test samples. The best way would be to parametrise `Hillshade_3pm` as a function of `Aspect` and `Slope`. But this requires parametric form, that is not trivial. \n\nThe simpler solution is to **run KNN algorithm and assign the `Hillshade_3pm` values for these tricky events  using `Aspect` and `Slope` as inputs**. Note, that one would want to do it on the data subset used for training only and predict with such learned model for the test\/validation subset as well as for the submission dataset. The same applies for a CV loop\n\nThe following suits only as an illustration and proof-of-consept","4ff9789e":"Some of the models (LightGBM in particular) expect the labels to start from 0","c6e54878":"## Plot distributions of individual features","61ab2a40":"# EDA\nThe scatter-plot implementation and visualisation come from https:\/\/github.com\/aguschin\/kaggle\/blob\/master\/forestCoverType_featuresEngineering.ipynb. The plotting function will highlight different target classes with different colours.","3cb72197":"Preditions for individual voting classifiers","48973e3b":"These inclined structures indicate a linear dependence between the two variables. However, such linear dependence is hard to capture with decision trees, so one typicaly introduces linear combinations of such features","21e5d643":"# Let's do actual Feature engineering","02b8fb6b":"With such new feature it will be much easier for a decision tree to separate between classes with cuts on the X axis. \nThis shows the importance of the difference variables","8646bbd5":"Various machine-learning models to be used to model the data","e7e3f4c9":"Train: sample","5846fe15":"Yahoo! **Application of weights allows to reproduce the distributions of variables in the submission sample very closely.**","2da96060":"Test sample:","38f6b606":"## OHE into LE","10d7e3e2":"# Save submission"}}