{"cell_type":{"f7461d96":"code","1679c906":"code","93f0f04c":"code","de770f28":"code","4edc60b4":"code","894426c2":"code","0b3e321d":"code","84c5fcc7":"code","581a6a26":"code","ace6e0f5":"code","4a46504d":"code","9237a9f2":"code","ffcee90c":"code","87398fff":"code","1deea1a1":"code","cf21fbe5":"code","43fbb1c9":"code","9248b4c0":"code","7a395a79":"code","4fa01dcd":"code","3b9b6fd3":"code","6d934852":"code","00c47d52":"code","ccd9d5b7":"code","3d8ffcf9":"code","60ed35a7":"code","2c875cf5":"markdown","9660d02b":"markdown","70901112":"markdown","953b4d87":"markdown","d718e095":"markdown","976b101b":"markdown","74c75725":"markdown","6b500961":"markdown","6be0a078":"markdown","10a0b04e":"markdown","eca6fb62":"markdown","a4f87628":"markdown","2ee55b3b":"markdown","773fc1ce":"markdown"},"source":{"f7461d96":"from keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import confusion_matrix\nfrom glob import glob\nfrom keras.utils.np_utils import to_categorical #Converting to one hot encoding \nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers.normalization import BatchNormalization","1679c906":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings \nwarnings.filterwarnings(\"ignore\")","93f0f04c":"train = pd.read_csv(\"\/kaggle\/input\/mnist-in-csv\/mnist_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/mnist-in-csv\/mnist_test.csv\")","de770f28":"print(\"Train shape : %s  \\nTest: Shape : %s\"%(train.shape,test.shape))","4edc60b4":"train.head(10)","894426c2":"train.label.nunique() # We got 10 Classes(Labels)","0b3e321d":"test.label.nunique()","84c5fcc7":"print(train.label.value_counts())\nplt.figure(figsize = (12,10))\nsns.countplot(train.label, palette =\"cubehelix\")","581a6a26":"#Visualizing with PieChart \nlabelsx = train.label.value_counts().index\ncolors = [\"grey\",\"red\",\"blue\",\"yellow\",\"brown\",\"orange\",\"pink\",\"green\",\"purple\",\"indigo\"]\nexplode = [0,0,0,0,0,0,0,0,0,0]\nsizes = train.label.value_counts().values\n\nplt.figure(figsize = (9,9))\nplt.pie(sizes,explode = explode, labels = labelsx, colors = colors, autopct =\"%1.1f%%\")\nplt.title(\"Label Counting by using PieChart (Seaborn)\",color = \"violet\",fontsize = 15, fontstyle =\"oblique\")\nplt.show()","ace6e0f5":"print(test.label.value_counts())\nplt.figure(figsize = (12,10))\nsns.countplot(test.label, palette = \"icefire\")","4a46504d":"#Train Dataset\nY_train = train.label\nX_train = train.drop(labels = [\"label\"], axis = 1)","9237a9f2":"#Test Dataset\nY_test = test.label\nX_test = test.drop(labels = [\"label\"],axis = 1)","ffcee90c":"plt.subplot(3,2,1)\nimg1 = X_train.iloc[0].to_numpy().reshape((28,28))\nplt.imshow(img1,cmap='gray')\nplt.subplot(3,2,2)\nimg2 = X_train.iloc[10].to_numpy().reshape((28,28))\nplt.imshow(img2,cmap='gray')\nplt.subplot(3,2,3)\nimg3 = X_train.iloc[98].to_numpy().reshape((28,28))\nplt.imshow(img3,cmap='gray')\nplt.subplot(3,2,4)\nimg4 = X_train.iloc[25].to_numpy().reshape((28,28))\nplt.imshow(img4,cmap='gray')\nplt.subplot(3,2,5)\nimg5 = X_train.iloc[120].to_numpy().reshape((28,28))\nplt.imshow(img5,cmap='gray')\nplt.subplot(3,2,6)\nimg6 = X_train.iloc[264].to_numpy().reshape((28,28))\nplt.imshow(img6,cmap='gray')\n\nplt.show()","87398fff":"#Normalization\nX_train = X_train.astype(\"float32\")\nX_test = X_test.astype(\"float32\")\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0\nprint(\"X_train Shape : %s \\nX_Test Shape :%s\"%(X_train.shape,X_test.shape))","1deea1a1":"#Reshaping \nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\nprint(\"X_train shape : \",X_train.shape)\nprint(\"X_Test shape : \",X_test.shape)","cf21fbe5":"#Label Encoding - IF there more Labels we could use Glob Function\nfrom keras.utils.np_utils import to_categorical \nY_train = to_categorical(Y_train,num_classes = 10)\nY_test = to_categorical(Y_test,num_classes = 10)","43fbb1c9":"from sklearn.model_selection import train_test_split \nX_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train, test_size = 0.15,random_state = 42)\nprint(\"X_train shape\",X_train.shape)\nprint(\"X_val shape\",X_val.shape)\nprint(\"Y_train shape\",Y_train.shape)\nprint(\"Y_val shape\",Y_val.shape)","9248b4c0":"from sklearn.metrics import confusion_matrix\nimport itertools \n\nfrom keras.utils.np_utils import to_categorical #Converting to one hot encoding \nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers.normalization import BatchNormalization\n\nepochs = 75\nbatch_size = 240\nnum_of_classes = 10\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding =\"same\",\n                 activation =\"relu\", input_shape =(28,28,1)))\nmodel.add(MaxPooling2D(pool_size =(3,3)))\n\nmodel.add(Conv2D(64,3,3))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(3,3))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))  #Hidden layer1\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(num_of_classes)) # Output layer size must equal to number of classes (labels)\nmodel.add(Activation(\"softmax\"))","7a395a79":"learning_rate_optimizer = ReduceLROnPlateau(monitor = \"val_accuracy\",\n                                           patience = 2, verbose = 1,\n                                           factor = 0.5, min_lr = 0.000001)","4fa01dcd":"optimizer = RMSprop()\nmodel.compile(optimizer = optimizer, loss  =\"categorical_crossentropy\", metrics =[\"accuracy\"])","3b9b6fd3":"model.summary()","6d934852":"datagen = ImageDataGenerator( \n        shear_range = 0.2,\n        zoom_range = 0.1,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip = True,\n        vertical_flip = True)\n\ndatagen.fit(X_train)","00c47d52":"history = model.fit(datagen.flow(X_train,Y_train, \n                                batch_size = batch_size), \n                                epochs = epochs,\n                                validation_data = (X_val,Y_val),\n                                steps_per_epoch = X_train.shape[0]\/\/batch_size,\n                                callbacks = [learning_rate_optimizer])","ccd9d5b7":"score = model.evaluate(X_test, Y_test, verbose = 0)\nprint(\"Test Loss : %f \\nTest Accuracy : %f \"%(score[0],score[1]))","3d8ffcf9":"print(history.history.keys())\nplt.plot(history.history[\"loss\"], label =\"Train Loss\")\nplt.plot(history.history[\"val_loss\"], label =\"Test Loss\")\nplt.legend()\nplt.show()\n\n#-----------------------------------------------------------------------\n\nprint(history.history.keys())\nplt.plot(history.history[\"accuracy\"], label =\"Train Accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label =\"Test Accuracy\")\nplt.legend()\nplt.show()","60ed35a7":"import seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(15,15))\nsns.heatmap(confusion_mtx, annot=True, cmap=\"cubehelix\", linewidths=0.01,linecolor=\"green\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","2c875cf5":"***CALLBACK*** - Learning Rate Optimizer","9660d02b":"### Confusion Matrix ","70901112":"### Seperating Label from the Datasets","953b4d87":"- We need to use categorical_crossentropy as loss function because we used softmax as a last activation func and that's one of the multiclasses act function. ","d718e095":"## CNN Architecture \n<a href=\"https:\/\/ibb.co\/sKHpTLb\"><img src=\"https:\/\/i.ibb.co\/8rcnyFN\/gec2.jpg\" alt=\"9\" border=\"0\"><\/a>\n\n- Create Model >> Conv - Max Pooling - Dropout - Conv - Max Pool Dropout - Fully Connected\n- Dropout is a technique where randomly selected neurons are ignored during training - We apply this technique to avoid overfitting","976b101b":"### Model Evaluation ","74c75725":"### Libraries","6b500961":"### Train and Test(Validation) Split \n- %15 Validation \n- %85 Train ","6be0a078":"### Plotting Some of the Examples","10a0b04e":"***Compiling Model***","eca6fb62":"### Normalization - Reshaping and Label Encoding","a4f87628":"### Train the Model ","2ee55b3b":"### Data Augmentation ","773fc1ce":"### Test Data Results "}}