{"cell_type":{"1053f5ac":"code","95bb4c64":"code","72400bc5":"code","d0d29587":"code","ec527e17":"code","e462527d":"code","09bb7b11":"code","3a712ef7":"code","55e5669c":"code","a3731185":"code","1752dc31":"code","89e729bb":"code","717a0da5":"code","adba5b53":"code","4f41cc95":"code","87b6a836":"code","d268ec2d":"code","e1daf729":"code","e9fe7a1b":"code","720799de":"code","904cbccb":"code","6037c147":"code","daff98e5":"code","b428e662":"code","f7c5a4a2":"code","7051b812":"code","f737cbb8":"code","a0befb3d":"markdown","b5947dfd":"markdown","01d8ae98":"markdown","c1c5a0d0":"markdown","f5cba05e":"markdown","1f53b376":"markdown","1ea763b5":"markdown","ee25f4e6":"markdown"},"source":{"1053f5ac":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler","95bb4c64":"train_original = pd.read_csv('..\/input\/train.csv')\ntest  = pd.read_csv('..\/input\/test.csv')","72400bc5":"train = train_original.copy()","d0d29587":"train.head()","ec527e17":"for i in train[[\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Embarked\"]]:\n    print(train[i].value_counts())\n    print(\"\\n\\n\\n\")","e462527d":"train.hist(figsize=(20,20))","09bb7b11":"train.describe(include=\"all\")","3a712ef7":"(train.groupby('Embarked').mean())['Survived']#persentage of people how survived \n#based on embarked\n#c has the most survival ratio","55e5669c":"train.head()","a3731185":"train.groupby('Sex').sum()['Survived'].plot(kind=\"bar\",stacked=True)#more survived female than males","1752dc31":"train.groupby('Embarked').sum()['Survived'].plot(kind=\"bar\",stacked=True)","89e729bb":"sns.violinplot(x=\"Age\",y=\"Sex\",hue=\"Survived\",data=train,split=True)","717a0da5":"def comb(x):\n    if(pd.isna(x)):\n        return 'N';\n    return x[0]\n\n\ntrain['Cabin'] = train['Cabin'].apply(comb)\nle_cabin = LabelEncoder()\nhot_cabin = OneHotEncoder()\nle_cabin.fit(train['Cabin'])\nhot_cabin.fit(le_cabin.transform(train['Cabin']).reshape(-1,1))\n\nage_scaler = StandardScaler()\nage_scaler.fit(np.array(train['Age']).reshape(-1,1))\n\nfare_scaler = StandardScaler()\nfare_scaler.fit(np.array(train['Fare']).reshape(-1,1))\n\ndef drop_columns(df,col): # col = [\"Name\",'PassengerId',\"Ticket\"]\n    df.drop(col,axis=1,inplace=True)\n\n\n\ndef cabin_2(df):\n    df['Cabin'] = df['Cabin'].apply(comb)\n\ndef one_hot_encoder_cabin(df):\n    i='Cabin'\n    con = le_cabin.transform(df[i])\n    hot_encoder = hot_cabin.transform(con.reshape(-1,1)).toarray()\n    df_hot_encoded = pd.DataFrame(hot_encoder,columns = ['Cabin ('+j+')' for j in (le_cabin.classes_)])\n    df = pd.concat([df,df_hot_encoded],axis=1)\n    df.drop(i,axis=1,inplace=True)\n    return df\n\n\ndef fill_nan_with_mostcommon(df):\n    for i in df.columns:\n        df[i].fillna(df[i].mode()[0],inplace=True)\n\n\ndef one_hot_encoder_embarked(df):\n    m = {\"S\":1,\"Q\":2,\"C\":3}\n    df['Embarked'] = df['Embarked'].map(m)\n    hot = OneHotEncoder()\n    hot_encoder = hot.fit_transform(np.array(df['Embarked']).reshape(-1,1) ).toarray()\n    df_hot_encoded = pd.DataFrame(hot_encoder,columns = ['Embarked(S)','Embarked(Q)','Embarked(C)'] )\n    df = pd.concat([df,df_hot_encoded],axis=1)\n    df.drop(\"Embarked\",axis=1,inplace=True)\n    return df\n\n\n    \ndef map_sex(df):\n    m = {\"male\":1,\"female\":2}\n    df['Sex'] = df['Sex'].map(m)\n    \ndef one_hot_encoder_pclass(df):\n    hot = OneHotEncoder()\n    hot_encoder = hot.fit_transform(np.array(df['Pclass']).reshape(-1,1) ).toarray()\n    df_hot_encoded = pd.DataFrame(hot_encoder,columns = ['Pclass(1)','Pclass(2)','Pclass(3)'] )\n    df = pd.concat([df,df_hot_encoded],axis=1)\n    df.drop(\"Pclass\",axis=1,inplace=True)\n    return df\n\n\ndef Age_Fare_Scaling(df):\n    df['Age'] = age_scaler.transform(np.array(df['Age']).reshape(-1,1))\n    df['Fare'] = fare_scaler.transform(np.array(df['Fare']).reshape(-1,1))\n\n","adba5b53":"def change(df):\n    col_to_drop = [\"Name\",'PassengerId',\"Ticket\"] \n    scaling = ['Age','Fare']\n    \n    drop_columns(df,col_to_drop)\n    cabin_2(df)\n    fill_nan_with_mostcommon(df)\n    map_sex(df)\n    df = one_hot_encoder_embarked(df)\n    df = one_hot_encoder_cabin(df)\n    df = one_hot_encoder_pclass(df)\n    Age_Fare_Scaling(df)\n    \n    return df\n    ","4f41cc95":"train = change(train)","87b6a836":"train.head()","d268ec2d":"testing = test.copy()\ntesting = change(testing)\ntesting.head()","e1daf729":"test.head()","e9fe7a1b":"from sklearn.model_selection import train_test_split\n\ndef split_feature_labels(train,labels_name):\n    x_train =  train.drop(labels_name, axis=1)\n    y_train =  train[labels_name]\n    return x_train,y_train\n\ntrain_set,validation_set = train_test_split(train,test_size=0.2,random_state=42)\n\nx_train,y_train = split_feature_labels(train_set,\"Survived\")\nx_validation,y_validation = split_feature_labels(validation_set,\"Survived\")","720799de":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nparam_grid = [\n    {'n_estimators': [3, 10, 30,70,100,130], 'max_features': [0.5,1,2, 4, 6, 8,10]},\n  ]\n\nforest_reg = RandomForestClassifier(random_state=42)\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,scoring='accuracy', return_train_score=True)\ngrid_search.fit(x_train, y_train)","904cbccb":"print(\"Training Accuracy :\",grid_search.score(x_train,y_train))\nprint(\"Validation Accuracy :\",grid_search.score(x_validation,y_validation))","6037c147":"forest_reg = RandomForestClassifier(random_state=42,max_features=5,n_estimators=100)\nforest_reg.fit(x_train, y_train)\nprint(\"Training Accuracy :\",forest_reg.score(x_train,y_train))\nprint(\"Validation Accuracy :\",forest_reg.score(x_validation,y_validation))\n","daff98e5":"output = forest_reg.predict(testing)","b428e662":"out = pd.read_csv('..\/input\/gender_submission.csv')","f7c5a4a2":"out.Survived = output","7051b812":"out.head()","f737cbb8":"out.to_csv('submission.csv', index=False)","a0befb3d":"# import libraries","b5947dfd":"### Creating small validation set","01d8ae98":"# Feature Engineering\n\n## we want to do the next\n#### 1- fill all null values with the median if it was number or fill it with the most common  if it's character\n#### 2- mapping embarked c=1,q=2,s=3      convert cabin to one hot encoded after taking only first chacacter\n#### 3- scale all numbers\n#### 4 - drop name and passenger id\n","c1c5a0d0":"# Exploaring the Data","f5cba05e":"# loading the Data","1f53b376":"# Machine learning Part","1ea763b5":"### Testing with random forest","ee25f4e6":"#### Random forest is overfiting the so let's try another Algorithm and see what happen"}}