{"cell_type":{"3453bb78":"code","d47dc624":"code","616e1d4a":"code","85afa8d8":"code","ae769c22":"code","c560de39":"code","83554c24":"code","dd18b188":"code","d1f04a57":"code","dba3f28d":"code","427c567c":"code","bb40b685":"code","79f728f0":"code","220f3088":"code","af2f0361":"markdown","988e3b1d":"markdown","346f1811":"markdown","2ecfc031":"markdown","4c09c55c":"markdown","d9c99d1a":"markdown","9aac4dca":"markdown","da43f150":"markdown","2dd116c9":"markdown","3322b83a":"markdown","5d90a0ca":"markdown","b75667a8":"markdown"},"source":{"3453bb78":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#Pandas and Numpy\nimport pandas as pd\nimport numpy as np\nfrom pandas.core.frame import DataFrame\n\n\n#SKlearn Functions\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier as GBC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LinearRegression, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d47dc624":"#Easy dummy variable creator\ndef swap_for_dummies(X, column_name) :\n\n    Dummy_data = pd.get_dummies(X[column_name], drop_first=True)\n\n    X = X.drop(column_name, axis=1)\n\n    X = pd.concat([X, Dummy_data], axis=1)\n\n    return X\n\n#Pipline\ndef pipe(X) :\n    X = swap_for_dummies(X, \"Sex\")\n    X = swap_for_dummies(X, \"Embarked\")\n    \n    X[\"Age\"] = X[\"Age\"].astype(\"int\")\n    #X[\"Fare\"] = X[\"Fare\"].astype(\"int\")\n    \n    return X\n\n#Train Test Split pipeline\ndef TTS_configured(Train, Test) :\n\n    y_train = Train[\"Survived\"]\n    X_train = Train.drop(\"Survived\", axis=1)\n\n    return X_train, y_train, Test","616e1d4a":"Train_CSV = \"\/kaggle\/input\/titanic\/train.csv\"\nData_train = pd.read_csv(Train_CSV)\n\nto_drop = [\"Name\", \"Cabin\", \"Ticket\", \"Fare\"]\nData_train = Data_train.drop(to_drop, axis=1)\n\nprint(Data_train.head(10))","85afa8d8":"mean = Data_train[\"Age\"].mean()\nData_train[\"Age\"].fillna(mean, inplace=True)\n\nData_train = pipe(Data_train)\n\nprint(Data_train.head(10))","ae769c22":"Test_CSV = \"\/kaggle\/input\/titanic\/test.csv\"\nData_test = pd.read_csv(Test_CSV)\n\nto_drop = [\"Name\", \"Cabin\", \"Ticket\", \"Fare\"]\nData_test = Data_test.drop(to_drop, axis=1)\n\nprint(Data_test.head(10))","c560de39":"Data_test[\"Age\"].fillna(mean, inplace=True)\n\nData_test = pipe(Data_test)\n\nprint(Data_test.head(10))","83554c24":"X_train, y_train, X_test = TTS_configured(Data_train, Data_test)","dd18b188":"L_rates = np.linspace(0.001, 1, 10)\nn_estimators = np.arange(100, 1001, 200)\n\nGbc_dict = {\n    \"learning_rate\" : L_rates,\n    \"n_estimators\" : n_estimators\n}\n\nGbc = GridSearchCV(\n    estimator=GBC(),\n    param_grid=Gbc_dict,\n\n    scoring=\"accuracy\",\n    cv=5,\n\n    refit=True,\n    return_train_score=True\n)\n\nprint(n_estimators)","d1f04a57":"depths = []\ndepths = np.arange(1, 11, 2)\nprint(depths)\n\ntree_dict = {\n    \"max_depth\" : depths,\n    \"random_state\" : [42]\n}\n\ntree = GridSearchCV(\n    estimator=DecisionTreeClassifier(),\n    param_grid=tree_dict,\n    \n    scoring=\"accuracy\",\n    cv=5,\n\n    refit=True,\n    return_train_score=True\n)","dba3f28d":"linear_dict = {\n    \"fit_intercept\" : [True],\n    \"normalize\" : [True, False]\n}\n\nlinear = GridSearchCV(\n    estimator = LinearRegression(),\n    param_grid = linear_dict,\n    \n    scoring=\"accuracy\",\n    cv=5,\n\n    refit=True,\n    return_train_score=True\n)","427c567c":"alphas = np.linspace(0.0001, 0.1, 10)\nmax_iters = np.arange(100, 1001, 200)\n\nSGD_dict = {\n    \"penalty\" : [\"l1\", \"l2\", \"elasticnet\"],\n    \"alpha\" : alphas,\n    \"max_iter\" : max_iters\n}\n\nsgd = GridSearchCV(\n    estimator = SGDClassifier(),\n    param_grid = SGD_dict,\n    \n    scoring=\"accuracy\",\n    cv=5,\n\n    refit=True,\n    return_train_score=True\n)","bb40b685":"n_neighbors = np.arange(1, 11, 2)\np = [2, 3]\n\nknn_dict = {\n    \"n_neighbors\" : n_neighbors\n}\n\nknn = GridSearchCV(\n    estimator = KNeighborsClassifier(),\n    param_grid = knn_dict,\n    \n    scoring=\"accuracy\",\n    cv=5,\n\n    refit=True,\n    return_train_score=True\n)","79f728f0":"Classifiers = [Gbc, tree, linear, sgd, knn]\n\npredictions = []\nscores =[]\n\nfor c in Classifiers :\n    c.fit(X_train, y_train)\n    print(c.best_estimator_)\n    \n    best = c.best_estimator_\n    \n    best.fit(X_train, y_train)\n    \n    predictions.append(best.predict(X_test))\n    scores.append(best.score(X_train, y_train))\n\nprint(scores)\n\nmax_score = max(scores)\nmax_index = scores.index(max_score)","220f3088":"output = pd.DataFrame({\n    'PassengerId': X_test[\"PassengerId\"],\n    'Survived': predictions[max_index]\n})\noutput.to_csv('Titantic_sub.csv', index=False)\n\nprint(max_index)\n\nprint(output.shape)\nprint(output.head(20))","af2f0361":"Read In Training Data","988e3b1d":"Fill NaN & Get Dummy Values","346f1811":"Generate Output CSV","2ecfc031":"Fill NaN & Get Dummy Values","4c09c55c":"Train Test Split","d9c99d1a":"Linear Regression : GSCV","9aac4dca":"Function Definitions","da43f150":"SGD Classifier : GSCV","2dd116c9":"KNN Classifier : GSCV","3322b83a":"Gradient Boosting Classifier : GSCV","5d90a0ca":"Import Test Data","b75667a8":"Decision Tree : GSCV"}}