{"cell_type":{"69e89b99":"code","ac40e7f8":"code","4a64b5d9":"code","573b0d45":"code","92db0b27":"code","03393d59":"code","63eaa21d":"code","fb09a1be":"code","82dd8df3":"code","05862b66":"code","490c9cfa":"code","724eb72e":"code","6f591cca":"code","9b49b0f9":"code","bdb8a20e":"code","b6178b5b":"code","04f0f4aa":"code","c8e236f2":"code","9902598e":"code","3a33dc97":"code","7c70cc94":"code","dbe77ac9":"code","4f7347d7":"code","148d7e9a":"code","7e4ca8ab":"code","9f8e55a1":"code","8726b5a3":"code","2032ffcf":"code","0bbb4c5e":"markdown","01020c15":"markdown","c51d86b3":"markdown"},"source":{"69e89b99":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, \\\n    classification_report\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nimport warnings\n\nwarnings.simplefilter(action=\"ignore\")","ac40e7f8":"!pip install lightgbm","4a64b5d9":"df = pd.read_csv(\"..\/input\/diabetes\/diabetes.csv\")","573b0d45":"# The first 5 observation \ndf.head()","92db0b27":"# The size of the data set \ndf.shape","03393d59":"# Feature information\ndf.info()","63eaa21d":"df.describe().T","fb09a1be":"df.describe([.01,.05,.25,.50,.75,.99]).T","82dd8df3":"df[\"Outcome\"].value_counts() \/ len(df) * 100","05862b66":"df[[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]] = df[[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]].replace(0,np.NaN)","490c9cfa":"df.head()","724eb72e":"df.isnull().sum()","6f591cca":"mis_value = [\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]","9b49b0f9":"for i in mis_value:\n    df[i][(df[i].isnull()) & (df[\"Outcome\"] == 0)] = df[i][(df[i].isnull()) & (df[\"Outcome\"] == 0)].fillna(df[i][df[\"Outcome\"] == 0].mean())\n    df[i][(df[i].isnull()) & (df[\"Outcome\"] == 1)] = df[i][(df[i].isnull()) & (df[\"Outcome\"] == 1)].fillna(df[i][df[\"Outcome\"] == 1].mean())","bdb8a20e":"df.head()","b6178b5b":"def outlier_thresholds(dataframe,variable):\n    q1 = dataframe[variable].quantile(0.25)\n    q3 = dataframe[variable].quantile(0.75)\n    IQR = q3 - q1\n    low_limit = q1 - 1.5 * IQR\n    up_limit = q3 + 1.5 * IQR\n    return low_limit,up_limit","04f0f4aa":"def has_outliers(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    if dataframe[(dataframe[variable] < low_limit) | (dataframe[variable] > up_limit)].any(axis=None):\n        print(variable, \"yes\")","c8e236f2":"for col in df.columns:\n    has_outliers(df,col)","9902598e":"outlier_columns = [col for col in df.columns if col not in \"Outcome\"]","3a33dc97":"outlier_columns","7c70cc94":"for col in df.columns:\n    outlier_thresholds(df,col)","dbe77ac9":"df.describe([0.01,0.25,0.50,0.75,0.99]).T","4f7347d7":"def replace_with_thresholds(dataframe,variable):\n    low_limit,up_limit = outlier_thresholds(dataframe,variable)\n    dataframe.loc[(dataframe[variable] < low_limit),variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit),variable] = up_limit","148d7e9a":"for col in outlier_columns:\n    replace_with_thresholds(df,col)","7e4ca8ab":"y = df[\"Outcome\"]\nX = df.drop(\"Outcome\",axis = 1)","9f8e55a1":"models = [('LR', LogisticRegression()),\n          ('KNN', KNeighborsClassifier()),\n          ('CART', DecisionTreeClassifier()),\n          ('RF', RandomForestClassifier()),\n          ('SVM', SVC(gamma='auto')),\n          ('XGB', GradientBoostingClassifier()),\n          (\"LightGBM\", LGBMClassifier())]","8726b5a3":"results = []\nnames = []","2032ffcf":"for name, model in models:\n    kfold = KFold(n_splits=10, random_state=123456)\n    cv_results = cross_val_score(model, X, y, cv=10, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","0bbb4c5e":"# Model","01020c15":"### <font color='blue'> ***Task*** <\/font> \n\n#### We will try to build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?\n\n### <font color='blue'> Details about the dataset <\/font> \n***The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.***\n\n- **Pregnancies: Number of times pregnant**\n\n- **Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test**\n\n- **BloodPressure: Diastolic blood pressure (mm Hg)**\n\n- **SkinThickness: Triceps skin fold thickness (mm)**\n\n- **Insulin: 2-Hour serum insulin (mu U\/ml)**\n\n- **BMI: Body mass index (weight in kg\/(height in m)^2)**\n\n- **DiabetesPedigreeFunction: Diabetes pedigree function**\n\n- **Age: Age (years)**\n\n- **Outcome: Class variable (0 or 1)**\n\n- **Number of Observation Units: 768**\n\n- **Variable Number: 9**\n\n- **Result; The model created as a result of LightGBM hyperparameter optimization became the model with the lowest Cross Validation Score value. (0.889388)**","c51d86b3":"> # <font color='red'> Diabetes Prediction Using Machine Learning<\/font> \n"}}