{"cell_type":{"743337af":"code","12e848f8":"code","0597fa87":"code","7e4f4d5d":"code","8db3ab26":"code","44069e17":"code","50fa8c9e":"code","cf7d6539":"code","8b50255d":"code","6a03d504":"code","0e464f4c":"code","d5377537":"code","7c7bee00":"code","83726390":"code","d0c3e81e":"code","40b59e75":"code","56a2b4ee":"code","3c94831d":"code","25094061":"code","4a6b6488":"code","c96d2f97":"code","4d224766":"code","6b197078":"code","c8af8943":"code","708a8b0b":"code","ab104b27":"code","365183c9":"code","0c078038":"code","305b7b70":"code","edd4bf31":"code","5c7c98c4":"code","78305d22":"code","de6b35a1":"code","0e407ff5":"code","4bdf80b3":"code","c87d03b5":"code","30b8bebd":"code","2b70f79d":"code","a5464eea":"code","6ece87eb":"code","cc5cc4bb":"code","6959ad36":"code","f7e8d385":"markdown","20964653":"markdown","50fa748c":"markdown","32f0d011":"markdown","e6e927b8":"markdown","55ac4325":"markdown","692384e9":"markdown","21502376":"markdown","aec2c0d7":"markdown","cce77ee3":"markdown","291eb2b4":"markdown","234db22f":"markdown","2f2fcd86":"markdown","1c2fe216":"markdown","26887b50":"markdown","17b0cb8b":"markdown","7aabf762":"markdown","02fa06a7":"markdown","70041e59":"markdown","6c68ab8f":"markdown","d778c52e":"markdown","61d8c07c":"markdown","f0c19e3a":"markdown","4cc06150":"markdown","a7ed8f3f":"markdown","9546a9a5":"markdown","89607509":"markdown","bf624349":"markdown","a3203fd5":"markdown"},"source":{"743337af":"!wget \"https:\/\/github.com\/valerio-unifei\/UNIFEI-IA-Aulas\/raw\/main\/benchmark-datasets.zip\" -O datasets.zip\n!unzip datasets.zip\n!rm datasets.zip","12e848f8":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import ExtraTreeClassifier","0597fa87":"df = pd.read_csv('letter.csv')\ndf.head()","7e4f4d5d":"df.info()","8db3ab26":"df.describe()","44069e17":"df.groupby([' Class'])[' Class'].count().plot(kind='bar')","50fa8c9e":"df2 = df.copy()\ndf2 = df2.sort_values(by=[' Class'], ascending=True)\ndf2.head()","cf7d6539":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(df2[' Class'])\nprint(le.classes_)\ndf2[' Class'] = le.transform(df2[' Class'])\ndf2.head()","8b50255d":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,12))\nsns.heatmap(df2.corr().round(4), annot=True)\nplt.show()","6a03d504":"df2.columns","0e464f4c":"vars = [' Y-bar',' X2ybr',' Xegvy']\n\nplt.figure(figsize=(20,30))\nfor v in range(len(vars)):\n  plt.subplot(3,1,v+1)\n  sns.boxplot(y=vars[v],x=' Class', data=df, order=le.classes_)\n  plt.ylabel(vars[v])\n  plt.xlabel('Class')\nplt.show()","d5377537":"plt.figure(figsize=(20,10))\nsns.boxplot(y=' Y-box',x=' Class', data=df, order=le.classes_)\nplt.ylabel(' Y-box')\nplt.xlabel('Class')","7c7bee00":"x_vars = vars\nx_vars.append(' Y-box')\nsns.pairplot(df2, y_vars=' Class', x_vars=x_vars, kind='reg')","83726390":"X = df[df.columns[:-1]]\ny = df[' Class']","d0c3e81e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=42)","40b59e75":"!pip install scikit-optimize\nfrom skopt import gp_minimize","56a2b4ee":"from sklearn.metrics import accuracy_score","3c94831d":"def train_ExtraTree(params):\n    max_depth = params[0]\n    min_samples_split = params[1]\n    min_samples_leaf = params[2]\n    \n    model = ExtraTreeClassifier(\n        splitter='best',\n        max_depth=max_depth,\n        min_samples_split=min_samples_split,\n        min_samples_leaf=min_samples_leaf,\n        random_state=42\n    )\n    \n    model.fit(X_train,y_train)\n    pred = model.predict(X_test)\n    return -accuracy_score(y_test,pred)","25094061":"params = [\n          (2,100),\n          (2,100),\n          (1,100)\n]\n\nres = gp_minimize(train_ExtraTree, params, random_state=42, verbose=1, n_calls=30, n_random_starts=10)\nres.x","4a6b6488":"et1 = ExtraTreeClassifier(\n        splitter='best',\n        max_depth=29,\n        min_samples_split=2,\n        min_samples_leaf=1,\n        random_state=42\n)","c96d2f97":"def train_Bagging(params):\n    n_estimators = params[0]\n    max_features = params[1]\n    \n    model = BaggingClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        random_state=42\n    )\n    \n    model.fit(X_train,y_train)\n    pred = model.predict(X_test)\n    return -accuracy_score(y_test,pred)","4d224766":"params = [\n          (10,100),\n          (1,16)\n]\n\nres = gp_minimize(train_Bagging, params, random_state=42, verbose=1, n_calls=30, n_random_starts=10)\nres.x","6b197078":"bg1 = BaggingClassifier(\n        n_estimators=100,\n        max_features=9,\n        random_state=42\n)","c8af8943":"X2 = X.copy()\ny2 = y.copy()","708a8b0b":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(X2)\nX2 = scaler.transform(X2)","ab104b27":"X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,test_size=0.25, random_state=42)","365183c9":"def train_ExtraTree2(params):\n    max_depth = params[0]\n    min_samples_split = params[1]\n    min_samples_leaf = params[2]\n    \n    model = ExtraTreeClassifier(\n        splitter='best',\n        max_depth=max_depth,\n        min_samples_split=min_samples_split,\n        min_samples_leaf=min_samples_leaf,\n        random_state=42\n    )\n    \n    model.fit(X_train2,y_train2)\n    pred = model.predict(X_test2)\n    return -accuracy_score(y_test2,pred)","0c078038":"params = [\n          (2,100),\n          (2,100),\n          (1,100)\n]\n\nres = gp_minimize(train_ExtraTree2, params, random_state=42, verbose=1, n_calls=30, n_random_starts=10)\nres.x","305b7b70":"et2 = ExtraTreeClassifier(\n        splitter='best',\n        max_depth=79,\n        min_samples_split=2,\n        min_samples_leaf=1,\n        random_state=42\n)","edd4bf31":"def train_Bagging2(params):\n    n_estimators = params[0]\n    max_features = params[1]\n    \n    model = BaggingClassifier(\n        n_estimators=n_estimators,\n        max_features=max_features,\n        random_state=42\n    )\n    \n    model.fit(X_train2,y_train2)\n    pred = model.predict(X_test2)\n    return -accuracy_score(y_test2,pred)","5c7c98c4":"params = [\n          (10,100),\n          (1,16)\n]\n\nres = gp_minimize(train_Bagging2, params, random_state=42, verbose=1, n_calls=30, n_random_starts=10)\nres.x","78305d22":"bg2 = BaggingClassifier(\n        n_estimators=100,\n        max_features=10,\n        random_state=42\n)","de6b35a1":"models1 = [et1, bg1]\nmodels2 = [et2, bg2]","0e407ff5":"from sklearn.model_selection import cross_validate\n\ncv_results1 = []\ncv_results2 = []\n\nfor model in models1:\n  cv_results1.append(cross_validate(model,X,y,cv=10,scoring=['accuracy','recall_macro','precision_macro']))\n\nfor model in models2:\n  cv_results2.append(cross_validate(model,X2,y2,cv=10,scoring=['accuracy','recall_macro','precision_macro']))","4bdf80b3":"cv_results1[0].keys()","c87d03b5":"modelos = ['ExtraTreeClassifier1','BaggingClassifier1','ExtraTreeClassifier2','BaggingClassifier2']\nacc_mean = [\n            cv_results1[0]['test_accuracy'].mean(), \n            cv_results1[1]['test_accuracy'].mean(),\n            cv_results2[0]['test_accuracy'].mean(),\n            cv_results2[1]['test_accuracy'].mean()]\nrecall_mean = [\n               cv_results1[0]['test_recall_macro'].mean(),\n               cv_results1[1]['test_recall_macro'].mean(),\n               cv_results2[0]['test_recall_macro'].mean(),\n               cv_results2[1]['test_recall_macro'].mean()\n]\nprecision_mean = [\n                  cv_results1[0]['test_precision_macro'].mean(),\n                  cv_results1[1]['test_precision_macro'].mean(),\n                  cv_results2[0]['test_precision_macro'].mean(),\n                  cv_results2[1]['test_precision_macro'].mean()\n]\n\nresults = pd.DataFrame()\nresults['modelo'] = modelos\nresults['acc_mean'] = acc_mean\nresults['recall_mean'] = recall_mean\nresults['precision_mean'] = precision_mean","30b8bebd":"results","2b70f79d":"from sklearn.metrics import classification_report\n\nfor model in models1:\n  model.fit(X_train,y_train)\n  pred = model.predict(X_test)\n  print(model)\n  print(classification_report(y_test, pred))\n  print('===============================================')\n\nfor model in models2:\n  model.fit(X_train2,y_train2)\n  pred = model.predict(X_test2)\n  print(model)\n  print(classification_report(y_test2, pred))\n  print('===============================================')","a5464eea":"import numpy as np\nimport itertools\n\n\ndef plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n    plt.figure(figsize=(20, 20))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","6ece87eb":"from sklearn.metrics import confusion_matrix\nbg1.fit(X_train,y_train)\npred = bg1.predict(X_test)\nplot_confusion_matrix(confusion_matrix(y_test,pred), le.classes_ )","cc5cc4bb":"bg1","6959ad36":"results","f7e8d385":"## Divis\u00e3o do conjunto de dados","20964653":"## Quantidade de ocorr\u00eancia de cada classe","50fa748c":"### Classification report\n","32f0d011":"# An\u00e1lise Explorat\u00f3ria","e6e927b8":"## BaggingClassifier","55ac4325":"A distribui\u00e7\u00e3o das features para cada letra \u00e9 bem diferente e a maioria cont\u00e9m outliers. \n\nAgora, vamos analisar a feature de menor correla\u00e7\u00e3o: Y-box (0.0015)","692384e9":"# **Aplica\u00e7\u00e3o dos modelos**\nPara cada modelo, ser\u00e1 feito o teste com e sem normaliza\u00e7\u00e3o da base de dados (preprocessing.StandardScaler).\n\n### **Otimiza\u00e7\u00e3o dos hiperpar\u00e2metros do modelo**\nPara a otimiza\u00e7\u00e3o dos hiperpar\u00e2metros do modelo foi utilizado o 'gp_minimize' da biblioteca 'skopt'. O par\u00e2metro n_calls indica que essa otimiza\u00e7\u00e3o ser\u00e1 executada 30 vezes (n_calls=30), sendo 10 vezes rand\u00f4micas (n_random_starts=10) e as restantes utilizam o conhecimento adquirido nas 10 itera\u00e7\u00f5es iniciais. O retorno recebe o sinal negativo, pois como \u00e9 uma fun\u00e7\u00e3o de minimiza\u00e7\u00e3o ela ir\u00e1 nos retornar o valor de maior score.\n\n\nNa otimiza\u00e7\u00e3o ser\u00e1 considerado apenas um conjunto de treinamento e teste, n\u00e3o sendo utilizado o k-fold.\n\n### **Defini\u00e7\u00e3o dos modelos treinados sem a normaliza\u00e7\u00e3o da base de dados**","21502376":"##Sorteio\nMatr\u00edcula: 2017006999 <\/br>\nDataset: letter <\/br>\nAprendizado 1: ExtraTreeClassifier <\/br>\nAprendizado 2: BaggingClassifier <\/br>\n\n##Comparativo (m\u00e9dia) \nAprendizado 1: 0.750 <\/br>\nAprendizado 2: 0.917 <\/br>\n","aec2c0d7":"### ExtraTreeClassifier\nClassificador de \u00e1rvore extremamente aleat\u00f3rio.","cce77ee3":"# Considera\u00e7\u00f5es Finais","291eb2b4":"Temos 4 modelos de aprendizado de m\u00e1quina supervisionados classificador inicializados, sendo eles:\n\n**et1**: ExtraTreeClassifier sem normaliza\u00e7\u00e3o dos dados <\/br>\n**et2**: ExtraTreeClassifier com normaliza\u00e7\u00e3o dos dados <\/br>\n<\/br>\n\n**bg1**: BaggingClassifier sem normaliza\u00e7\u00e3o dos dados <\/br>\n**bg2**: BaggingClassifier com normaliza\u00e7\u00e3o dos dados\n\n","234db22f":"### ExtraTreeClassifier","2f2fcd86":"### Matriz de Confus\u00e3o\n\nMatriz de confus\u00e3o com a melhor t\u00e9cnica selecionada: BaggingClassifier 1 (sem normaliza\u00e7\u00e3o nos dados)","1c2fe216":"Analisando a correla\u00e7\u00e3o da classe com os demais atributos, percebemos que as maiores correla\u00e7\u00f5es s\u00e3o Y-bar (0.31), X2ybr (0.39) e Xegvy (0.34). ","26887b50":"Para a feature Y-box j\u00e1 podemos perceber que a distribui\u00e7\u00e3o para as diferentes letras j\u00e1 \u00e9 mais parecida. ","17b0cb8b":"## Pairplot\n\nAgora vamos observar a rela\u00e7\u00e3o entre classe e as demais features por meio do gr\u00e1fico de dispers\u00e3o. Lembrando que o df2 \u00e9 uma c\u00f3pia do df por\u00e9m com as letras representadas por n\u00fameros, sendo A:0 e Z:25.","7aabf762":"A quantidade de ocorr\u00eancias de cada letra \u00e9 parecida e desta forma, n\u00e3o deve tendenciar o resultado do modelo.","02fa06a7":"**As considera\u00e7\u00f5es finais foram escritas conforme enunciado do trabalho proposto na disciplina.**","70041e59":"## Boxplot\nO boxplot \u00e9 um gr\u00e1fico que nos permite ver a distribui\u00e7\u00e3o de uma determinada vari\u00e1vel e visualizar se h\u00e1 presen\u00e7a de outliers.\n\nO primeiro tra\u00e7o do ret\u00e2ngulo representa 25%, o tra\u00e7o do meio representa a mediana (50%) e o tra\u00e7o superior 75%. Os valores representados por s\u00edmbolos fora da linha ligada ao quadrado s\u00e3o os outliers.\n\nPara que a distribui\u00e7\u00e3o seja considerada normal, os quadrados divididos pela mediana precisam ser o mais parecidos poss\u00edvel, caso contr\u00e1rio, a distribui\u00e7\u00e3o ser\u00e1 assim\u00e9trica.","6c68ab8f":"### **Defini\u00e7\u00e3o dos modelos treinados com a normaliza\u00e7\u00e3o da base de dados**","d778c52e":"## Sobre a base de dados\nEsse dataset foi produzido com 20.000 est\u00edmulos \u00fanicos, obtidos a partir de imagens de letras escritas em 20 diferentes fontes em que cada leta dentro destas fontes foi distorcida. Cada um desses est\u00edmulos foi convertido em 16 atributos num\u00e9ricos que foram dimensionados para caber em uma faixa de inteiros de 0 a 15.","61d8c07c":"## Matriz de Correla\u00e7\u00e3o\n\nO coeficiente de correla\u00e7\u00e3o entre duas vari\u00e1veis assume um valor entre -1 (correla\u00e7\u00e3o negativa perfeita) e 1 (correla\u00e7\u00e3o positiva perfeita). Valores pr\u00f3ximos a 0 indicam a aus\u00eancia de correla\u00e7\u00e3o entre as vari\u00e1veis.","f0c19e3a":"Considerando todas as m\u00e9tricas avaliadas, o modelo de melhor desempenho foi o BaggingClassifier sem normaliza\u00e7\u00e3o nos dados. Ele foi iniciado com os valores diferentes do padr\u00e3o da classe, sendo max_features=9 (padr\u00e3o=1) e n_estimators=100 (padr\u00e3o=10). O resultado dos modelos BaggingClassifier com e sem normaliza\u00e7\u00e3o apresentam desempenho muito semelhante, sendo o sem normaliza\u00e7\u00e3o um pouco melhor. \n\nPor outro lado, comparando o BaggingClassifier com o ExtraTreeClassifier nota-se uma diferen\u00e7a nas m\u00e9tricas de aproximadamente 10%, sendo que para algumas letras o ExtraTreeClassifier possui f1 inferior a 80%. Um exemplo \u00e9 a letra R que os modelos de BaggingClassifier possuem um f1 de aproximadamente 91% e o ExtraTreeClassifier de aproximadamente 72%. Essa grande diferen\u00e7a tamb\u00e9m acontece para diversas outras letras, o que faz com que o BaggingClassifier seja o modelo de melhor desempenho.   \n\nA tabela results mostrada acima mostra os valores m\u00e9dios das m\u00e9tricas obtidas por meio do treinamento via valida\u00e7\u00e3o cruzada com 10 camadas. \n\nDe acordo com a tabela fornecida para compara\u00e7\u00e3o, o valor de refer\u00eancia para o ExtraTreeClassifier \u00e9 0.750 e para o BaggingClassifier \u00e9 0.917. Em todos os modelos instanciados, a acur\u00e1cia \u00e9 superior a da tabela.\n\n\n\n","4cc06150":"## Avalia\u00e7\u00e3o dos modelos","a7ed8f3f":"De acordo com a matriz de confus\u00e3o, a letra com menos acertos foi H (90%), sendo confundida na maioria das vezes com K (4%) e R (3%). O erro entre essas classes se d\u00e1 possivelmente pela semelhan\u00e7a da escrita dessas letras em alguns tipos de fontes.\n\nAs letras com maiores acertos (99%) foram A, B, M, X e Y. \n\nDe modo geral, o desempenho do modelo foi bom, acertando mais de 90% de todas as letras. ","9546a9a5":"### BaggingClassifier","89607509":"Considerando a tabela de resultados acima, as melhores m\u00e9tricas s\u00e3o obtidas pelo modelo **BaggingClassifier** sem normaliza\u00e7\u00e3o dos dados, sendo a accuracy 0.96630, recall 0.966023 e precision 0.966964.","bf624349":"Vamos utilizar o label encoder para transformar a representa\u00e7\u00e3o das letras em n\u00fameros, e assim, podermos observar a correla\u00e7\u00e3o dos atributos com a classe. ","a3203fd5":"Na figura acima podemos ver graficamente a dispers\u00e3o entre a classe e as demais vari\u00e1veis e, consequentemente, a correla\u00e7\u00e3o encontrada anteriormente no heatmap. A linha inclinada positivamente indica a exist\u00eancia de uma correla\u00e7\u00e3o positiva entre as vari\u00e1veis e a linha horizontal indica a aus\u00eancia de correla\u00e7\u00e3o. "}}