{"cell_type":{"1ec8322b":"code","825f9dc2":"code","0edb6e28":"code","e373bb18":"code","a2ce7b7a":"code","7fc20f63":"code","5c1aaa93":"code","107abb96":"code","18d5fd38":"code","7d367015":"code","2e000b6f":"code","90ff1020":"code","a1783d38":"code","3ca2bf0e":"code","94b47006":"code","46c90d3f":"code","36abb4ae":"code","9c24ee11":"markdown","9c61a469":"markdown","312cd344":"markdown","20c9b306":"markdown","e0bd205a":"markdown","53b1f046":"markdown","c0130445":"markdown"},"source":{"1ec8322b":"# import libraries\nimport pandas as pd\nimport numpy as np\nfrom sqlalchemy import create_engine\nimport sqlite3","825f9dc2":"# load messages dataset\nmessages = pd.read_csv(\"..\/input\/disaster_messages.csv\")\nmessages.head()","0edb6e28":"# load categories dataset\ncategories = pd.read_csv(\"..\/input\/disaster_categories.csv\")\ncategories.head()","e373bb18":"categories[\"categories\"][0]","a2ce7b7a":"# merge datasets\ndf = messages.merge(categories, on=[\"id\"])\ndf.head()","7fc20f63":"# create a dataframe of the 36 individual category columns\ncategories = df[\"categories\"].str.split(\";\", expand=True)\ncategories.head()","5c1aaa93":"# select the first row of the categories dataframe\nrow = categories.head(1)\n\n# use this row to extract a list of new column names for categories one way is to apply a lambda function that takes everything \n# up to the second to last character of each string with slicing\ncategory_colnames = row.applymap(lambda x: x[:-2]).iloc[0, :].tolist()\nprint(category_colnames)","107abb96":"# rename the columns of categories\ncategories.columns = category_colnames\ncategories.head()","18d5fd38":"for column in categories:\n    # set each value to be the last character of the string\n    categories[column] = categories[column].astype(str).str[-1]\n    \n    # conversoin - convert column from string to numeric\n    categories[column] = categories[column].astype(int)\ncategories.head()","7d367015":"# drop the original categories column from `data frame - df`\ndf.drop(\"categories\", axis=1, inplace=True)\n\ndf.head()","2e000b6f":"# concatenate the original dataframe with the new `categories` dataframe df\ndf = pd.concat([df,categories], axis=1)\ndf.head()","90ff1020":"print(\"Count of duplicate : {}\", format(df[df.duplicated].count()))","a1783d38":"# check number of duplicates\ndf[df.duplicated].shape\n#df.duplicated","3ca2bf0e":"# drop duplicates\ndf.drop_duplicates(inplace=True)","94b47006":"# check number of duplicates\ndf[df.duplicated].count()","46c90d3f":"#engine = create_engine('sqlite:\/\/\/db_disaster_messages.db')\n#df.to_sql('tbl_disaster_messages', engine, index=False)","36abb4ae":"# Create database\ndatabase = 'database.db'\nconn = sqlite3.connect(database)\ndf.to_sql('table1', conn, index=False)","9c24ee11":"# ETL Pipeline Preparation\nFollow the instructions below to help you create your ETL pipeline.\n### 1. Import libraries and load datasets.\n- Import Python libraries\n- Load `messages.csv` into a dataframe and inspect the first few lines.\n- Load `categories.csv` into a dataframe and inspect the first few lines.","9c61a469":"### 4. Convert category values to just numbers 0 or 1.\n- Iterate through the category columns in df to keep only the last character of each string (the 1 or 0). For example, `related-0` becomes `0`, `related-1` becomes `1`. Convert the string to a numeric value.\n- You can perform [normal string actions on Pandas Series](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/text.html#indexing-with-str), like indexing, by including `.str` after the Series. You may need to first convert the Series to be of type string, which you can do with `astype(str)`.","312cd344":"### 2. Merge datasets.\n- Merge the messages and categories datasets using the common id\n- Assign this combined dataset to `df`, which will be cleaned in the following steps","20c9b306":"### 5. Replace `categories` column in `df` with new category columns.\n- Drop the categories column from the df dataframe since it is no longer needed.\n- Concatenate df and categories data frames.","e0bd205a":"### 6. Remove duplicates.\n- Check how many duplicates are in this dataset.\n- Drop the duplicates.\n- Confirm duplicates were removed.","53b1f046":"### 7. Save the clean dataset into an sqlite database.\nYou can do this with pandas [`to_sql` method](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.to_sql.html) combined with the SQLAlchemy library. Remember to import SQLAlchemy's `create_engine` in the first cell of this notebook to use it below.","c0130445":"### 3. Split `categories` into separate category columns.\n- Split the values in the `categories` column on the `;` character so that each value becomes a separate column. You'll find [this method](https:\/\/pandas.pydata.org\/pandas-docs\/version\/0.23\/generated\/pandas.Series.str.split.html) very helpful! Make sure to set `expand=True`.\n- Use the first row of categories dataframe to create column names for the categories data.\n- Rename columns of `categories` with new column names."}}