{"cell_type":{"9e5a416f":"code","bcd9b9cd":"code","58a73093":"code","e2e7c822":"code","be714708":"code","11ab7356":"code","013e0439":"code","261338e8":"code","5f343733":"code","a36e4d46":"code","72ae0a93":"code","f3a64a20":"code","334e6056":"code","671c633c":"code","4d899f23":"code","8156468f":"code","cc22bfee":"code","920b93d1":"code","5720bd02":"markdown","18baa22a":"markdown","78524600":"markdown","4519e7a1":"markdown","ac5090d2":"markdown"},"source":{"9e5a416f":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt","bcd9b9cd":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58a73093":"df = pd.read_csv('\/kaggle\/input\/coronary-prediction\/coronary_prediction.csv')","e2e7c822":"df","be714708":"def draw_missing_data_table(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data","11ab7356":"draw_missing_data_table(df)","013e0439":"df =  df.dropna()\ndf.isnull().sum()","261338e8":"from scipy.stats import norm\nfigure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\nfigure.set_size_inches(200,30)\nsns.distplot(df['age'], fit=norm, ax=ax1)","5f343733":"df.corr()[\"BMI\"].sort_values(ascending=False)","a36e4d46":"X_train = df[['sysBP','diaBP','prevalentHyp']].values\nY_train = df['BMI'].values","72ae0a93":"from sklearn.model_selection import train_test_split\nXtrain, Xtest, Ytrain, Ytest = train_test_split(X_train,Y_train,test_size=0.4,random_state=3500)","f3a64a20":"def print_evaluate(predicted,true):  \n    R2 = metrics.r2_score(true, predicted)\n    print('R2:', R2)","334e6056":"from sklearn.ensemble import GradientBoostingRegressor\ngb = GradientBoostingRegressor()\ngb.fit(Xtrain,Ytrain)\npgb = gb.predict(Xtest)\nprint_evaluate(pgb,Ytest)","671c633c":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(Xtrain,Ytrain)\nplr = lr.predict(Xtest)\nprint_evaluate(plr,Ytest)","4d899f23":"from sklearn.ensemble import RandomForestRegressor\nparams = {\n    'bootstrap': [True],\n    'max_depth': [1,10,30,50, 75],\n    'max_features': ['auto'],\n    'min_samples_leaf': [1],\n    'min_samples_split': [3],\n    'n_estimators': [1,10,100,200]}\nrfr = RandomForestRegressor()\nrf_grid=GridSearchCV(rfr, params, n_jobs=1, cv=3,scoring='neg_mean_squared_error')\nrf_grid.fit(Xtrain,Ytrain)\nprf = rf_grid.predict(Xtest)\nprint_evaluate(prf,Ytest)","8156468f":"from sklearn.linear_model import Lasso\nparams = {\n    'alpha' : [.01, .1, .5, .7, .9, .95, .99, 1, 5, 10, 20],\n    'fit_intercept' : [True, False],\n    'normalize' : [True,False],\n    'tol' : [0.0001, 0.001, 0.01, 0.1,0.5,1],\n    \"random_state\" : [50] }\n\nlasso = Lasso()\nlasso_grid = GridSearchCV(lasso, params, scoring='neg_mean_squared_error', cv=5, n_jobs=1)\nlasso_grid.fit(Xtrain, Ytrain)\npla = lasso_grid.predict(Xtest)\nprint_evaluate(pla,Ytest)","cc22bfee":"from sklearn.linear_model import Ridge\nparams = {\n    \"alpha\" : [.01, .1, .95, .99, 1, 5],\n    \"fit_intercept\" : [True, False],\n    \"normalize\" : [True,False],\n    \"solver\" : ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n    \"tol\" : [0.001, 0.01, 0.1],\n    \"random_state\" : [50]}\n\nridge = Ridge()\nridge_grid = GridSearchCV(ridge, params, scoring='neg_mean_squared_error', cv=5, n_jobs=1)\nridge_grid.fit(Xtrain, Ytrain)\npr = ridge_grid.predict(Xtest)\nprint_evaluate(pr,Ytest)","920b93d1":"from sklearn.ensemble import VotingRegressor\nvoting = VotingRegressor([('Gradient',gb),('Randomforest',rf_grid)])\nvoting.fit(Xtrain, Ytrain)\nvote = voting.predict(Xtest)\nprint_evaluate(vote,Ytest)","5720bd02":"# **Importing Dataset**","18baa22a":"# **Ensemble Learning (Voting)**","78524600":"# **Model**","4519e7a1":"# **Importing Libraries**","ac5090d2":"# **Data Preprocess**"}}