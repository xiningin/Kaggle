{"cell_type":{"7d3bbb31":"code","901556aa":"code","52323afd":"code","aa07d1cd":"code","4307ecd7":"code","b9e66836":"code","f909af1b":"code","70822d71":"code","2d259e1c":"code","5e4badc8":"code","20e0b906":"code","74342da7":"code","5d302b0c":"code","58bdb2f3":"code","8796d700":"code","a5d9278b":"code","3e4f5a4c":"code","4152654a":"code","1bee74b8":"code","6b47dd2f":"code","40621988":"markdown","ff5decdf":"markdown","fa28bc52":"markdown","fe6f81de":"markdown","5c32cbb7":"markdown","ad58034a":"markdown","17f46ba6":"markdown"},"source":{"7d3bbb31":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport os\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk import PorterStemmer\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","901556aa":"os.listdir('..\/input\/')","52323afd":"data = pd.read_csv('..\/input\/spam_or_not_spam.csv')\ndata.head()","aa07d1cd":"data.dropna(inplace=True)\nchange_labels = lambda x: 1 if x==0 else 0\ndata['label'] = data['label'].apply(change_labels)\ndata.head()","4307ecd7":"remove_non_alphabets =lambda x: re.sub(r'[^a-zA-Z]',' ',x)","b9e66836":"tokenize = lambda x: word_tokenize(x)","f909af1b":"ps = PorterStemmer()\nstem = lambda w: [ ps.stem(x) for x in w ]","70822d71":"lemmatizer = WordNetLemmatizer()\nleammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]","2d259e1c":"print('Processing : [=', end='')\ndata['email'] = data['email'].apply(remove_non_alphabets)\nprint('=', end='')\ndata['email'] = data['email'].apply(tokenize) # [ word_tokenize(row) for row in data['email']]\nprint('=', end='')\ndata['email'] = data['email'].apply(stem)\nprint('=', end='')\ndata['email'] = data['email'].apply(leammtizer)\nprint('=', end='')\ndata['email'] = data['email'].apply(lambda x: ' '.join(x))\nprint('] : Completed', end='')\ndata.head()","5e4badc8":"max_words = 10000\ncv = CountVectorizer(max_features=max_words, stop_words='english')\nsparse_matrix = cv.fit_transform(data['email']).toarray()","20e0b906":"sparse_matrix.shape","74342da7":"x_train, x_test, y_train, y_test = train_test_split(sparse_matrix, np.array(data['label']))","5d302b0c":"class LogisticRegression(nn.Module):\n    def __init__(self):\n        super(LogisticRegression, self).__init__()\n        self.linear1 = nn.Linear(10000, 100)\n        self.linear2 = nn.Linear(100, 10)\n        self.linear3 = nn.Linear(10, 2)\n        \n    def forward(self, x):\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x","58bdb2f3":"model = LogisticRegression()","8796d700":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)","a5d9278b":"x_train = Variable(torch.from_numpy(x_train)).float()\ny_train = Variable(torch.from_numpy(y_train)).long()","3e4f5a4c":"x_test = Variable(torch.from_numpy(x_test)).float()\ny_test = Variable(torch.from_numpy(y_test)).long()","4152654a":"epochs = 20\nmodel.train()\nloss_values_train = []\nloss_values_valid = []\nfor epoch in range(epochs):\n    print(epoch)\n    print('Train:')\n    optimizer.zero_grad()\n    y_pred = model(x_train)\n    loss = criterion(y_pred, y_train)\n    loss_values_train.append(loss.item())\n    pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n    acc = pred * 100.0 \/ len(x_train)\n    print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n    loss.backward()\n    optimizer.step()\n    print('Eval:')\n    model.eval()\n    with torch.no_grad():\n        y_pred = model(x_test)\n        loss = criterion(y_pred, y_test)\n        pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n        print (\"Accuracy : {}%\".format(100*pred\/len(x_test)))\n        loss_values_valid.append(loss.item())\n\n","1bee74b8":"plt.plot(loss_values_train)\nplt.plot(loss_values_valid\n        )\nplt.legend([\"Train\", \"Validation\"])\nplt.title('Loss Value vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n#plt.legend(['Loss'])\nplt.show()","6b47dd2f":"model.eval()\nwith torch.no_grad():\n    y_pred = model(x_test)\n    loss = criterion(y_pred, y_test)\n    pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n    print (\"Accuracy : {}%\".format(100*pred\/len(x_test)))\n","40621988":"#### Changing lables for ease of understanding","ff5decdf":"> New to Pytorch Trying out stuff","fa28bc52":"# Testing","fe6f81de":"## Reading Data","5c32cbb7":"#### Let's Preprocess text data\n* We will remove non words, lower it, then Tokenize, Lemmatize and Vectorize and Remove Stopwords from the data","ad58034a":"# Creating a Spam and Not Spam Classifier with PyTorch","17f46ba6":"## Preprocessing Data"}}