{"cell_type":{"0176ed93":"code","46b57837":"code","a334d1d2":"code","84df8d3e":"code","a0ee13b0":"code","4f6fe211":"code","86350b91":"code","9869b9e7":"code","6057e4ed":"code","06e9c3c6":"code","94895515":"code","7849a8dc":"code","2649a1bf":"code","1f11fa85":"code","0756c23d":"code","abd0c77f":"code","f2b82ae4":"code","57be8418":"code","26b0b980":"code","d297aa0d":"code","107348dc":"code","12a3f3ed":"code","3c448e66":"code","00c421a8":"code","1cdd20cd":"code","fdcf5a26":"code","71c2b8aa":"code","6a18b4c8":"code","a6def658":"code","f2a0f11f":"code","098505a6":"code","6facf14f":"code","5d8a0b34":"code","780f235c":"code","ddcf65c1":"code","7288a1ae":"code","05fd4bfc":"code","0ca6d7a7":"code","24e0f7b6":"code","0353a0a0":"code","30976b63":"code","9fa70e32":"code","a009736a":"code","20b9f28f":"code","72bd3ae9":"code","1fbd3d7c":"code","cf2398b3":"code","2ff1540b":"code","6f9a8f7c":"code","a9d1cb1e":"code","88606aa0":"code","b4fa601b":"code","994f06bb":"code","0a5b9877":"code","a2c02cfc":"code","7545570a":"code","f266d808":"code","ba3cf301":"code","c7f8f899":"code","054c65b9":"code","44016e37":"code","749ed2a0":"code","fe849a4f":"code","d2b66561":"code","286af94d":"code","8c7acdd0":"code","55852290":"code","bc68b955":"code","3a959ef3":"code","a9d28e13":"code","986ace7e":"code","9e9c7c5d":"code","ecf4ae37":"code","105f8453":"code","96f99277":"code","7548e415":"code","e40cb146":"code","2d95a97a":"code","8c4c8462":"code","f6de84cb":"code","7daaea24":"code","95aa49f0":"code","96704b1e":"code","bd441c25":"code","f6f337c9":"code","47751d48":"code","1c23a2de":"code","07a26a91":"code","9a3b900b":"code","cc41ae99":"code","94a7d2d5":"code","c1f8a037":"code","6abd3888":"code","a1611c82":"code","84be160f":"code","623d92cb":"code","c7b93d14":"code","b3dd6656":"code","f6e0674e":"code","06e97b81":"code","a09e1124":"code","2f318ede":"code","6ea0f1ec":"markdown","df419a39":"markdown","31723868":"markdown","8d5f1de2":"markdown","538e4c73":"markdown","73409741":"markdown","e9066d78":"markdown","6251adcd":"markdown","3f43edb3":"markdown","0f764b02":"markdown","f6eec8ae":"markdown","e4c4e6b3":"markdown","1d607f3e":"markdown","85d662d8":"markdown","9bc7e50b":"markdown","bc56888a":"markdown","a637ebef":"markdown","a8fbf171":"markdown","4415c030":"markdown","8aeec64a":"markdown","97ded0fa":"markdown","2911eec3":"markdown","1188d66d":"markdown","30d1a302":"markdown","e0533d65":"markdown","aa5eb24b":"markdown","36e8c104":"markdown","5166f227":"markdown","d4b8bdde":"markdown","a65beeac":"markdown","f6091f3e":"markdown","4f724c12":"markdown","49de98eb":"markdown","f3532146":"markdown","64bbe8d3":"markdown","d3eb83df":"markdown","2030a5e6":"markdown","a6cb698e":"markdown","baaab242":"markdown","0b7a8169":"markdown","3302877c":"markdown","bb7229d1":"markdown","836994eb":"markdown","1bd417e7":"markdown","77d66f95":"markdown","e6554934":"markdown","d0984bb1":"markdown"},"source":{"0176ed93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46b57837":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic-machine-learning-from-disaster\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic-machine-learning-from-disaster\/test.csv\")","a334d1d2":"test_PassengerId  = test_df[\"PassengerId\"]","84df8d3e":"train_df.head()","a0ee13b0":"train_df.info()","4f6fe211":"def bar_plot(variable): \n\n    ### input: variable ex: \"Sex\"\n    ### output: barplot & value count \n\n    \n    # get feature\n    var = train_df[variable]\n    \n    # count number of categorical variable\n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n  {}\".format(variable,varValue))","86350b91":"train_df.columns","9869b9e7":"category1 = ['Survived', 'Pclass', 'Sex', 'SibSp','Parch','Embarked']\nfor c in category1:\n    bar_plot(c)\n    \n    ## **Conclusion**\n    # 'Survived';  inbalance variable\n    # 'Pclass';    related Embarked\n    # 'Sex';       inbalance variable\n    # 'SibSp';\n    # 'Parch';\n    # 'Embarked';  related Pclass","6057e4ed":"category2 = [\"Cabin\",\"Name\",\"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","06e9c3c6":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","94895515":"numericVar = [\"Fare\",\"Age\",\"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)\n    \n    ## **Conclusion**\n    # \"Fare\" ;         \n    # \"Age\" ;         \n    # \"PassengerId\" ;  rubbish\n","7849a8dc":"train_df[[\"Pclass\" , \"Survived\"]]","2649a1bf":"# Pclass - Survived\ntrain_df[[\"Pclass\" , \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","1f11fa85":"# Sex - Survived\ntrain_df[[\"Sex\" , \"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","0756c23d":"# SibSp - Survived\ntrain_df[[\"SibSp\" , \"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","abd0c77f":"# SibSp - Survived\ntrain_df[[\"Parch\" , \"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","f2b82ae4":"# Exp 1\n# Check list\na = [\"a\",\"a\",\"b\",\"a\",\"c\",\"a\",\"b\"]\nCounter(a)\n","57be8418":"def detect_outliers(df,features):\n    outlier_indices= []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        \n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n\n        # IQR\n        IQR = Q3 - Q1\n        \n        # Outlier step\n        outlier_step = IQR * 1.5\n        \n        # Detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1- outlier_step) | (df[c] >  Q3 + outlier_step)].index\n                               \n        # Store indeces\n        outlier_indices.extend(outlier_list_col)\n                               \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2) # look for Exp1; i = a,b... v = count\n                                                            \n    return multiple_outliers    ","26b0b980":"train_df.iloc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","d297aa0d":"# Drop ouyliers\ntrain_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]), axis = 0).reset_index(drop = True)\n","107348dc":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop = True)","12a3f3ed":"train_df.head()","3c448e66":"train_df.columns[train_df.isnull().any()]","00c421a8":"train_df.isnull().sum()","1cdd20cd":"train_df[train_df[\"Embarked\"].isnull()]","fdcf5a26":"train_df.boxplot(column = \"Fare\", by=\"Embarked\")\nplt.show()\n# ","71c2b8aa":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","6a18b4c8":"train_df[train_df[\"Fare\"].isnull()]","a6def658":"train_df[train_df[\"Pclass\"] == 3]","f2a0f11f":"np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"])","098505a6":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))\ntrain_df[train_df[\"Fare\"].isnull()]","6facf14f":"list1 = [\"SibSp\" , \"Parch\" , \"Age\" , \"Fare\" , \"Survived\"]\nsns.heatmap(train_df[list1].corr(),annot = True, fmt = \".2f\")","5d8a0b34":"g = sns.factorplot(x = \"SibSp\" , y = \"Survived\", data = train_df, kind = \"bar\", size = 6 )\ng.set_ylabels(\"Survived Probability\")\nplt.show()\n","780f235c":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()\n","ddcf65c1":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","7288a1ae":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","05fd4bfc":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 3)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","0ca6d7a7":"g = sns.FacetGrid(train_df, row= \"Embarked\", size = 3)\ng.map(sns.pointplot,  \"Pclass\" , \"Survived\" , \"Sex\")\ng.add_legend()\nplt.show()","24e0f7b6":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","0353a0a0":"train_df[train_df[\"Age\"].isnull()]","30976b63":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind=\"box\")\nplt.show()","9fa70e32":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\", hue = \"Pclass\")\nplt.show()","a009736a":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\n\nplt.show()","20b9f28f":"train_df[\"Sex_N\"] = [1 if i == \"male\" else 0  for i in train_df[\"Sex\"]]","72bd3ae9":"sns.heatmap(train_df[[\"Age\",\"Sex_N\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","1fbd3d7c":"train_df[train_df[\"Age\"].isnull()]","cf2398b3":"train_df[\"Age\"][train_df[\"Age\"].isnull()]","2ff1540b":"train_df.head()","6f9a8f7c":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"])\n                               &\n                               (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])\n                               &\n                               (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"])                    \n                               )].median()\n    age_med = train_df[\"Age\"].median()\n    \n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","a9d1cb1e":"train_df[train_df[\"Age\"].isnull()]","88606aa0":"train_df[\"Name\"].head()","b4fa601b":"s = \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\"\ns.split(\".\")[0].split(\",\")[1].strip()","994f06bb":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","0a5b9877":"train_df[\"Title\"].head(10)","a2c02cfc":"sns.countplot(x = \"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","7545570a":"train_df[\"Title\"].unique()","f266d808":"# convert to categuniquel\ntrain_df[\"Title_N\"] = train_df[\"Title\"].replace(['Don', 'Rev', 'Dr',\n       'Major', 'Lady', 'Sir', 'Col', 'Capt', 'the Countess',\n       'Jonkheer', 'Dona'],\"Other\")\n\ntrain_df[\"Title_N\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title_N\"].head(20)","ba3cf301":"sns.countplot(x = \"Title_N\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","c7f8f899":"g = sns.factorplot(x = \"Title_N\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","054c65b9":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","44016e37":"train_df.head()","749ed2a0":"train_df = pd.get_dummies(train_df,columns = [\"Title_N\"])\ntrain_df.head()","fe849a4f":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\ntrain_df.head()","d2b66561":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","286af94d":"train_df[\"Family_Scategory\"] = [    0 if i > 4.5\n                               else 2 if i < 2\n                               else 1 \n                           \n                               for i in train_df[\"Fsize\"]]","8c7acdd0":"train_df.head(10)","55852290":"## train_df[\"Family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]] (model upgraded )","bc68b955":"sns.countplot(x = \"Family_Scategory\", data = train_df )\nplt.show()","3a959ef3":"g = sns.factorplot(x = \"Family_Scategory\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"LargeFamily\",\"SmallFamily\",\"AloneCowBoy\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","a9d28e13":"train_df = pd.get_dummies(train_df, columns = [\"Family_Scategory\"] )\ntrain_df.head()","986ace7e":"train_df[\"Embarked\"].head()","9e9c7c5d":"sns.countplot(x = \"Embarked\",data = train_df)\nplt.show()","ecf4ae37":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","105f8453":"train_df[\"Ticket\"].head(20)","96f99277":"a = \" A\/5. 2151  \"\na.replace(\".\",\"\")","7548e415":"a = \" A\/5. 2151  \"\na.replace(\".\",\"\").replace(\"\/\",\"\")","e40cb146":"a = \" A\/5. 2151  \"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip()","2d95a97a":"a = \" A\/5. 2151  \"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")","8c4c8462":"a = \" A\/5. 2151  \"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","f6de84cb":"tickets = []\nfor i in list(train_df[\"Ticket\"]):\n    if not i.isdigit():\n            tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n            tickets.append(\"x\")\ntrain_df[\"Ticket_N\"] = tickets","7daaea24":"train_df[\"Ticket_N\"].head(20)","95aa49f0":"train_df.head()","96704b1e":"train_df = pd.get_dummies(train_df, columns = [\"Ticket_N\"], prefix = \"T\")\ntrain_df.head()","bd441c25":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Pclass\"])\ntrain_df.head()","f6f337c9":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Sex\"])\ntrain_df.head()","47751d48":"train_df.columns","1c23a2de":"train_df.head()","07a26a91":"train_df.drop(labels = ['PassengerId', 'Cabin', 'Title', 'Fsize', 'Parch', 'SibSp', \"Ticket\", \"Sex_N\" ] , axis = 1, inplace = True)","9a3b900b":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","cc41ae99":"train_df_len","94a7d2d5":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"], axis = 1, inplace = True)","c1f8a037":"test.head()","6abd3888":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\n\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","a1611c82":"test.info()","84be160f":"logreg = LogisticRegression(solver='liblinear')\nlogreg.fit(X_train,y_train)\nacc_log_train = round(logreg.score(X_train,y_train)*100,2)\nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","623d92cb":"## https:\/\/www.udemy.com\/course\/machine-learning-ve-python-adan-zye-makine-ogrenmesi-4\/learn\/lecture\/17902832#questions","c7b93d14":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","b3dd6656":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","f6e0674e":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")\nplt.show()","06e97b81":"best_estimators","a09e1124":"votingC = VotingClassifier(estimators = [(\"DecisionTreeClassifier\",best_estimators[0]),\n                                        (\"SVC\",best_estimators[1]),\n                                        (\"RandomForestClassifier\",best_estimators[2])],\n                                        voting = \"hard\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","2f318ede":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","6ea0f1ec":"<a id=\"1\"><\/a>\n## Load and Check Data","df419a39":"* age <= 10 has a high survival rate,\n* oldest passengers (80) survived,\n* large number of 20 years old did not survive,\n* most passengers are in 15-35 age range,\n* use age feature in training\n* use age distribution for missing value of age","31723868":"<a id=\"2\"><\/a>\n## Variable Description\n\n![image.png](attachment:e18ad50c-94b7-413b-b21e-4799a0f00881.png)\n\n![image.png](attachment:637460f4-2334-4986-9d3f-ff6dedfdb5b3.png)","8d5f1de2":"* Having a lot of SibSp have less chance to survive.\n* if sibsp == 0 or 1 or 2, passenger has more chance to survive\n* we can consider a new feature describing these categories.","538e4c73":"<a id=\"33\"><\/a>\n## Ensemble Modeling","73409741":"<a id=\"27\"><\/a>\n## Sex","e9066d78":"<a id=\"14\"><\/a>\n### Parch -- Survived","6251adcd":"* Sex is not informative for age prediction, age distribution seems to be same.\n\n","3f43edb3":"<a id=\"12\"><\/a>\n### Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived","0f764b02":"<a id=\"3\"><\/a>\n\n## Univariate Variable Analysis\n\nCategorical Variable Analysis :  Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch\n\nNumerical Variable Analysis :   Fare, Age and PassengerId","f6eec8ae":"<a id=\"11\"><\/a>\n## Visualization","e4c4e6b3":"<a id=\"19\"><\/a>\n### Embarked -- Sex -- Fare -- Survived","1d607f3e":"<a id=\"13\"><\/a>\n### SibSp -- Survived","85d662d8":"<a id=\"17\"><\/a>\n### Pclass -- Survived -- Age","9bc7e50b":"<a id=\"22\"><\/a>\n## Name -- Title","bc56888a":"<a id=\"34\"><\/a>\n## Prediction and Submission","a637ebef":"<a id=\"26\"><\/a>\n## Pclass","a8fbf171":"* It's a clear feature for train our model.","4415c030":"* Female passengers have much better survival rate than males.\n* males have better surv\u015fval rate in pclass 3 in C.\n* embarked and sex will be used in training.","8aeec64a":"<a id=\"6\"><\/a>\n## Basic Data Analysis\n\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","97ded0fa":"<a id=\"32\"><\/a>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\n\nWe will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","2911eec3":"<a id=\"30\"><\/a>\n## Train - Test Split","1188d66d":"<a id=\"21\"><\/a>\n# Feature Engineering\n\n* Name -- Title\n* Family Size\n* Embarked\n* Ticket\n* Pclass\n* Sex\n* Drop Passenger ID and Cabin","30d1a302":"<a id=\"18\"><\/a>\n### Embarked -- Sex -- Pclass -- Survived","e0533d65":"# Inroduction\n\nRMS Titanic was a British passenger liner, operated by the White Star Line, which sank in the North Atlantic Ocean on 15 April 1912 after striking an iceberg during her maiden voyage from Southampton, UK, to New York City. Of the estimated 2,224 passengers and crew aboard, more than 1,500 died, which made the sinking possibly one of the deadliest for a single ship up to that time.\n\n<font color = \"blue\">\n\nContent:\n   \n    \n1. [Load and Check Data](#1)\n1. [Variable Description](#2)\n    1. [Univariate Variable Analysis](#3)\n    1. [Categorical Variable Analysis](#4)\n    1. [Numerical Variable Analysis](#5)\n1. [Basic Data Analysis](#6)\n1. [Outlier Detection](#7)\n1. [Missing Value](#8)\n    1. [Find Missing Value](#9)\n    1. [Fill Missing Value](#10)\n1. [Visualization](#11)\n    1. [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    1. [SibSp -- Survived](#13)\n    1. [Parch -- Survived](#14)\n    1. [Pclass -- Survived](#15)\n    1. [Age -- Survived](#16)\n    1. [Pclass -- Survived -- Age](#17)\n    1. [Embarked -- Sex -- Pclass -- Survived](#18)\n    1. [Embarked -- Sex -- Fare -- Survived](#19)\n    1. [Fill Missing: Age Feature](#20)\n1. [Feature Engineering](#21)\n    1. [Name -- Title](#22)\n    1. [Family Size](#23)\n    1. [Embarked](#24)\n    1. [Ticket](#25)\n    1. [Pclass](#26)\n    1. [Sex](#27)\n    1. [Drop Passenger ID and Cabin](#28)\n1. [Modeling](#29)\n    1. [Train - Test Split](#30)\n    1. [Simple Logistic Regression](#31)\n    1. [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    1. [Ensemble Modeling](#33)\n    1. [Prediction and Submission](#34)\n        \n\n","aa5eb24b":"<a id=\"16\"><\/a>\n### Age -- Survived","36e8c104":"<a id=\"1\"><\/a>\n","5166f227":"* Passsengers who pay higher fare have better survival. Fare can be used as categorical for training.\n","d4b8bdde":"* Sibsp and parch can be used for new feature extraction with th = 3\n* small familes have more chance to survive.\n* there is a std in survival of passenger with parch = 3","a65beeac":"<a id=\"25\"><\/a>\n## Ticket","f6091f3e":"<a id=\"7\"><\/a>\n## Outlier Detection","4f724c12":"<a id=\"20\"><\/a>\n### Fill Missing: Age Feature","49de98eb":"<a id=\"29\"><\/a>\n# Modeling","f3532146":"* Small familes have more chance to survive than large families.\n* Also AloneCowBoy have more chance to survive than large families.","64bbe8d3":"<a id=\"23\"><\/a>\n## Family Size","d3eb83df":"<a id=\"5\"><\/a>\n### Numerical Variable Analysis","2030a5e6":"<a id=\"9\"><\/a>\n### Find Missing Value","a6cb698e":"<a id=\"24\"><\/a>\n## Embarked","baaab242":"<a id=\"8\"><\/a>\n## Missing Value\n* Find Missing Value\n* Fill Missing Value","0b7a8169":"<a id=\"28\"><\/a>\n## Drop Passenger ID and Cabin","3302877c":"<a id=\"10\"><\/a>\n### Fill Missing Value\n* Embarked has 2,\n* Fare has only 1,\n* Age has 256,\n* Cabin has 1007  missing value","bb7229d1":"* Age is not correlated with sex but it is correlated with parch, sibsp and pclass.\n\n","836994eb":"* pclass is important feature for model training.\n","1bd417e7":"<a id=\"4\"><\/a>\n### Categorical Variable Analysis\n","77d66f95":"* 1st class passengers are older than 2nd, and 2nd is older than 3rd class.\n\n","e6554934":"<a id=\"31\"><\/a>\n## Simple Logistic Regression","d0984bb1":"<a id=\"15\"><\/a>\n### Pclass -- Survived"}}