{"cell_type":{"dcf70796":"code","92ad5735":"code","8a7d378d":"code","6be63710":"code","b4f4fcf0":"code","307aa369":"code","882162f1":"code","adf38a56":"code","8b1aeec3":"markdown","334f70c6":"markdown","1819e797":"markdown","6548665d":"markdown"},"source":{"dcf70796":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.utils.data as Data\nimport torchvision\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n\n# Any results you write to the current directory are saved as output.","92ad5735":"#Reading MNIST Datasets\npath=\"..\/input\/\"\ntrainset=pd.read_csv(path+'train.csv')\ntestset=pd.read_csv(path+'test.csv')","8a7d378d":"#Defining hyperparameters\nbatchsize=200 #size of minibatch\nEpoch=100 #the number iteration\nLR=0.001 #learning rate","6be63710":"#Data preprocessing\ntrainset_x=np.array(trainset.iloc[:,1:]) #Turn trainset features series into array\ntrainset_y=np.array(trainset['label']) #Turn trainset labels serie into array\n\ntrainset_x=np.reshape(trainset_x,(-1,batchsize,28,28)) #Reshape trainset features into 210*200*28*28\ntrainset_y=trainset_y.reshape(-1,batchsize) #Reshape trainset labels into 210*200\n\ntrx=torch.from_numpy(trainset_x) #Turn array into tensor","b4f4fcf0":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN,self).__init__()\n        self.ksize_conv=5 #kernel size of Convolution Layers\n        self.ksize_maxpool=2 #kernel size of Max Pool Layers\n        self.stride_conv=1 #the step of Convolution Kernel\n        self.padding=2 #padding number of Convolution Layers\n        self.channel_conv1=16 #output channel number of Convolution Layer 1\n        self.channel_conv2=32 #output channel number of Convolution Layer 1\n        # Convolution layer 1\n        self.conv1=nn.Sequential(nn.Conv2d(1,self.channel_conv1,self.ksize_conv,stride=self.stride_conv,padding=self.padding),#input shape(1,28,28),output shape(16,28,28)\n                                 nn.BatchNorm2d(self.channel_conv1), #Batch normalization\n                                nn.ReLU(), #Activation layer\n                                nn.MaxPool2d(self.ksize_maxpool)) #input shape(16,28,28),output shape(16,14,14)\n        self.conv2=nn.Sequential(nn.Conv2d(self.channel_conv1,self.channel_conv2,self.ksize_conv,stride=self.stride_conv,padding=self.padding),#input shape(16,14,14),output shape(32,14,14)\n                                 nn.BatchNorm2d(self.channel_conv2), #Batch normalization\n                                nn.ReLU(), #Activation layer\n                                nn.MaxPool2d(self.ksize_maxpool)) #input shape(32,14,14),output shape(32,7,7)\n        self.out=nn.Linear(32*7*7,10) #fully connected layer, output 10 classes\n        \n    def forward(self,x): #forward propagation\n        x=self.conv1(x)\n        x=self.conv2(x)\n        x=x.view(x.size(0),-1) #flattern tensor into (batchsize,32*7*7)\n        output = self.out(x)\n        return output\n    \ncnn=CNN() #bulid CNN model    \noptimizer = torch.optim.Adam(cnn.parameters(),lr=LR) # optimize all cnn parameters\nloss_func = nn.CrossEntropyLoss() #softmax and cross entropy loss","307aa369":"for epoch in range(Epoch):\n    for step in range(0,42000\/\/batchsize):\n        x=Variable(trx[step].view(batchsize,1,28,28).float()) #warp tarinning set feature into Variable\n        y=Variable(torch.Tensor(trainset_y[step]).long()) #warp tarinning set label into Variable\n        output = cnn(x) #fit the model\n        loss = loss_func(output,y) #calculate the loss\n        optimizer.zero_grad() # clear gradients for this training step\n        loss.backward() #backward propagation\n        optimizer.step() # apply gradients\n        #print('Epoch: ', epoch, 'Batch: ', step, '| train loss: %.4f' % loss.data.item())\n    print('Epoch: ', epoch, 'Batch: ', step, '| train loss: %.4f' % loss.data.item())\n","882162f1":"test_x=Variable(torch.Tensor(np.array(testset)).view(-1,1,28,28))\noutput=cnn(test_x)\ny = torch.max(output,1)[1].data.numpy().squeeze()\ny","adf38a56":"submit=pd.read_csv(path+'sample_submission.csv')\nsubmit['Label']=y\nsubmit\nsubmit.to_csv(path_or_buf='submission.csv',index=False)","8b1aeec3":"**Training the model**","334f70c6":"**Making Prediction**","1819e797":"**Building CNN Model**","6548665d":"**Preprocessing**"}}