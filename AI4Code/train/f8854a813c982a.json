{"cell_type":{"70181391":"code","665eee0b":"code","61cdbca2":"code","1676427d":"code","16982898":"code","754794ef":"code","101e25c6":"code","78507f3b":"code","479421b4":"code","d972f015":"code","bdfe8b0e":"code","e5ef9d6f":"code","12785da1":"code","c9445420":"code","23aa8003":"code","a92c10b8":"code","b83ae589":"code","7160c4af":"code","89411a99":"code","d793197f":"code","910c020f":"code","4923d438":"code","5ddaa977":"code","bc2c3c5e":"code","f77cb62b":"code","6f674395":"code","9518fc06":"code","4bc2c204":"code","bd680007":"code","bd1388ae":"code","559b98e5":"code","47ef8e59":"code","9222bba5":"code","61114bc4":"code","d49ffa88":"code","9325c515":"code","f6b8a4db":"code","210f8806":"code","3cc2f604":"code","b531f99b":"code","63da7286":"code","6233cdb6":"code","e80d1934":"code","c4dd0520":"code","b6c327b9":"code","90174b3f":"code","b649a7fe":"code","978f8bc8":"code","e6e5ea3f":"code","e8888b31":"code","c5d3792b":"code","570c4e54":"code","82082000":"code","c8517c7e":"code","854361b2":"code","573333f6":"code","6f987fcd":"code","f94b20a6":"code","6ecb48e3":"markdown","85441262":"markdown","7a933815":"markdown","2433326d":"markdown","4a7a6429":"markdown","3fab3843":"markdown","9590b85b":"markdown","ace962ab":"markdown","cad1521b":"markdown","62bc0cc7":"markdown","7eaa62e2":"markdown","9aad1751":"markdown","1aa0276f":"markdown","ed4c254c":"markdown"},"source":{"70181391":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom wordcloud import WordCloud,STOPWORDS\nimport io\nimport base64\nfrom matplotlib import rc,animation\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.basemap import Basemap\nimport folium\nimport folium.plugins\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport os\nprint(os.listdir(\"..\/input\"))\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","665eee0b":"# get the number of missing data points per column\ndef missing_data(df):\n    total = df.isnull().sum()\n    percent = (df.isnull().sum()\/df.isnull().count()*100).sort_values(ascending = False)\n    types = df.dtypes\n    unieq = df.select_dtypes(include = [object,float,int]).apply(pd.Series.nunique, axis = 0)\n    df_mis = pd.concat([total, percent ,unieq,types], axis=1, keys=['Sum_Mis', 'Per_Mis','Unieq', 'Types'])\n    \n    return df_mis.head(len(df_mis))","61cdbca2":"prev = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/previous_application.csv')\npos = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/POS_CASH_balance.csv')\nins = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/installments_payments.csv')\ncc = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/credit_card_balance.csv')","1676427d":"def heatmap(df):\n    df = df.corr()\n    plt.figure(figsize = (28, 26))\n\n    # Heatmap of correlations\n    sns.heatmap(df, cmap = plt.cm.RdYlBu_r, vmin = -0.25,fmt='.0g', annot = True, vmax = 0.6)\n    plt.title('Correlation Heatmap')","16982898":"heatmap(prev)\nheatmap(pos)\nheatmap(ins)\nheatmap(cc)","754794ef":" missing_data(prev)","101e25c6":"fig = plt.figure(figsize=(18,6))\npa_dr = pd.DataFrame((pa.isnull().sum())*100\/pa.shape[0]).reset_index()\npa_dr[\"type\"] = \"pre_app\"\nax = sns.pointplot(\"index\",0,data=pa_dr,hue=\"type\")\nplt.xticks(rotation =90,fontsize =7)\nplt.title(\"Percentage of Missing values in application pre_app\")\nplt.ylabel(\"PERCENTAGE\")\nplt.xlabel(\"COLUMNS\")\nax.set_facecolor(\"k\")\nfig.set_facecolor(\"lightgrey\")","78507f3b":"pa = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/previous_application.csv')\n\npreappcorr = pa.corr()\nplt.figure(figsize = (28, 26))\n\n# Heatmap of correlations\nsns.heatmap(preappcorr, cmap = plt.cm.RdYlBu_r, vmin = -0.25,fmt='.0g', annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap')\n\nmissing_data(pa)\n\n# pre_app char plot\n\nimport missingno as msno\nmsno.bar(pa);\n\n# % 99 olan iki stunu (RATE_INTEREST_PRIMARY','RATE_INTEREST_PRIVILEGED) drop ediyoruz\n\npa.drop(pa[['RATE_INTEREST_PRIMARY','RATE_INTEREST_PRIVILEGED']],axis=1,inplace=True) \n\n# pre_app missin data nan to 0\n\ndf1 = pa[(pa.AMT_ANNUITY.isna() == True) & (pa.AMT_APPLICATION == 0 )].fillna(0)\ndf2 = pa[(pa.AMT_ANNUITY.isna() == True) & (pa.AMT_APPLICATION != 0 )]\ndf3 = pa[(pa.AMT_ANNUITY.isna() == False) & (pa.AMT_APPLICATION == 0 )]\ndf4 = pa[(pa.AMT_ANNUITY.isna() == False) & (pa.AMT_APPLICATION != 0 )]\npa = pd.concat([df1, df2, df3, df4])\ndisplay(missing_data(pa))\ndisplay(pa.shape)\n\nmsno.bar(pa);\n\npa['NAME_TYPE_SUITE'].value_counts()\n\npa['NAME_TYPE_SUITE'].isnull().sum()\n\npa['NAME_TYPE_SUITE'].replace(0 , 'Unaccompanied', inplace = True)\npa['NAME_TYPE_SUITE'].replace(np.nan , 'Unaccompanied', inplace = True)\npa['NAME_TYPE_SUITE'].value_counts()\n\nmsno.bar(pa);\n\npa['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\npa['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\npa['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\npa['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\npa['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n\nmsno.bar(pa);\n\nmissing_data(pa)\n\n# pre_app categoric values\n\npa.select_dtypes(include = [object]).columns\n\npa_cat = pa[['index','NAME_CONTRACT_TYPE', 'WEEKDAY_APPR_PROCESS_START',\n       'FLAG_LAST_APPL_PER_CONTRACT', 'NAME_CASH_LOAN_PURPOSE',\n       'NAME_CONTRACT_STATUS', 'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON',\n       'NAME_TYPE_SUITE', 'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY',\n       'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE',\n       'NAME_SELLER_INDUSTRY', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION']]\n\npa_cat.select_dtypes(include = [object]).apply(pd.Series.nunique, axis = 0)\n\npa_cat = pa_cat.sort_index()\npa_cat\n\nmissing_data(pa_cat)\n\nprint('pa_cat shape:',pa_cat.shape)\n\n# numeric values\n\npa_num = pa.select_dtypes(include = ['float64','int64'])\npa_num.columns\n\npa.groupby('SK_ID_CURR')['AMT_ANNUITY', 'AMT_APPLICATION',\n       'AMT_CREDIT', 'AMT_DOWN_PAYMENT', 'AMT_GOODS_PRICE',\n       'HOUR_APPR_PROCESS_START', 'NFLAG_LAST_APPL_IN_DAY',\n       'RATE_DOWN_PAYMENT', 'DAYS_DECISION', 'SELLERPLACE_AREA', 'CNT_PAYMENT',\n       'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION',\n       'DAYS_LAST_DUE', 'DAYS_TERMINATION', 'NFLAG_INSURED_ON_APPROVAL'].mean()\n\n# pre_app numeric values\n\npa_num = pa.select_dtypes(include = ['float64','int64'])\npa_drop = pa[['index', 'SK_ID_PREV', 'SK_ID_CURR', ]]\npa_num.drop(['SK_ID_CURR','SK_ID_PREV'],axis=1,inplace=True)\nmissing_data(pa_num)\n\npa_drop\n\n!pip install ycimpute\n\nnp.array(pa_num)[0:5]\n\n# pre_app numeric values to fill\n\nfrom ycimpute.imputer import EM\npa_num_nnul = EM().complete(np.array(pa_num))\n\n\nvar_names = list(pa_num)\npa_num_nnul = pd.DataFrame(pa_num_nnul, columns = var_names)\nmissing_data(pa_num_nnul)\n\npre_app_num_corr = pa_num_nnul.corr()\nplt.figure(figsize = (28, 26))\n# Heatmap of correlations\nsns.heatmap(pre_app_num_corr, cmap = plt.cm.RdYlBu_r, vmin = -0.25,fmt='.0g', annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap')\n\n# OUTLIER\n\npa_num_nnul.shape\n\ndef iqr(df):\n    IQR = df.describe().T\n    IQR['lower'] = IQR['25%']-1.5*(IQR['75%']-IQR['25%'])\n    IQR['upper'] = IQR['75%']+1.5*(IQR['75%']-IQR['25%'])\n    upper_count = []\n    i = 0\n    for col in df:\n        upper_count.append(len(df[df[col] > IQR.iloc[i][-1]]))\n        i +=1\n    print(upper_count)\n    lower_count = []\n    i = 0\n    for col in df:\n        lower_count.append(len(df[df[col] < IQR.iloc[i][-2]]))\n        i +=1\n    print(lower_count)\n    IQR['lower_count'] = lower_count\n    IQR['upper_count'] = upper_count\n    IQR['out_percent'] = (IQR['upper_count'] + IQR['lower_count'])\/IQR['count']\n    return IQR\n\niqr(pa_num_nnul)\n\n#  %10 dan daha buyukler baskilama ile outlier lardan temizliyoruz\n\npa_num_nnul.loc[pa_num_nnul['AMT_APPLICATION'] > 422820.00,'AMT_APPLICATION'] = 422820.00\npa_num_nnul.loc[pa_num_nnul['AMT_CREDIT'] > 504805.50,'AMT_CREDIT'] = 504805.50\npa_num_nnul.loc[pa_num_nnul['AMT_GOODS_PRICE'] > 422932.5,'AMT_GOODS_PRICE'] = 422932.5\npa_num_nnul.loc[pa_num_nnul['SELLERPLACE_AREA'] > 206.50,'SELLERPLACE_AREA'] = 206.50\npa_num_nnul.loc[pa_num_nnul['DAYS_LAST_DUE_1ST_VERSION'] > 870.00,'DAYS_LAST_DUE_1ST_VERSION'] = 870.00\npa_num_nnul.loc[pa_num_nnul['DAYS_LAST_DUE_1ST_VERSION'] < -1450.00,'DAYS_LAST_DUE_1ST_VERSION'] = -1450.00\n\niqr(pa_num_nnul)\n\npa.sort_values(by=['index'])\n\npa_cat\n\npa_num_nnul.sort_values(by=['index'])\n\npa_drop.sort_index()\n\nresult = pd.merge(pa_drop, pa_num_nnul)\nresult\n\nmissing_data(result)\n\nresult = pd.concat([panew, df_cat], axis=1)\n\n\nresult = result[['SK_ID_CURR', 'NAME_CONTRACT_TYPE','AMT_ANNUITY',\n       'AMT_APPLICATION', 'AMT_CREDIT', 'AMT_DOWN_PAYMENT', 'AMT_GOODS_PRICE',\n       'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START',\n       'FLAG_LAST_APPL_PER_CONTRACT', 'NFLAG_LAST_APPL_IN_DAY',\n       'RATE_DOWN_PAYMENT', 'NAME_CASH_LOAN_PURPOSE', 'NAME_CONTRACT_STATUS',\n       'DAYS_DECISION', 'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON',\n       'NAME_TYPE_SUITE', 'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY',\n       'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE',\n       'SELLERPLACE_AREA', 'NAME_SELLER_INDUSTRY', 'CNT_PAYMENT',\n       'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION', 'DAYS_FIRST_DRAWING',\n       'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE',\n       'DAYS_TERMINATION', 'NFLAG_INSURED_ON_APPROVAL']]\nresult.shape\n\nresult\n\npre_app[pre_app.SK_ID_CURR == 175704]\n\nresult[result.SK_ID_CURR == 175704]\n\ndef aykiri(df):\n    display(df.head())\n    Q1=df.quantile(0.25)\n    Q3=df.quantile(0.75)\n    IQR=Q3-Q1\n    alt_sinir=Q1-1.5*IQR\n    ust_sinir=Q3+1.5*IQR\n    sns.boxplot(x=df);\n    aykiri_alt = (df < alt_sinir)\n    aykiri_ust = (df > ust_sinir)\n    #df[aykiri_alt] = alt_sinir\n    #df[aykiri_ust] = ust_sinir\n    print(alt_sinir,ust_sinir,(len(df[aykiri_ust])+len(df[aykiri_alt]))\/len(df))","479421b4":"preappcorr = pa.corr()\nplt.figure(figsize = (28, 26))\n\n# Heatmap of correlations\nsns.heatmap(preappcorr, cmap = plt.cm.RdYlBu_r, vmin = -0.25,fmt='.0g', annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap')","d972f015":"prev = pd.read_csv('previous_application.csv')\npos = pd.read_csv('POS_CASH_balance.csv')\nins = pd.read_csv('installments_payments.csv')\ncc = pd.read_csv('credit_card_balance.csv')","bdfe8b0e":"import missingno as msno\nmsno.bar(pa);","e5ef9d6f":"pa.drop(pa[['RATE_INTEREST_PRIMARY','RATE_INTEREST_PRIVILEGED']],axis=1,inplace=True) ","12785da1":"df1 = pa[(pa.AMT_ANNUITY.isna() == True) & (pa.AMT_APPLICATION == 0 )].fillna(0)\ndf2 = pa[(pa.AMT_ANNUITY.isna() == True) & (pa.AMT_APPLICATION != 0 )]\ndf3 = pa[(pa.AMT_ANNUITY.isna() == False) & (pa.AMT_APPLICATION == 0 )]\ndf4 = pa[(pa.AMT_ANNUITY.isna() == False) & (pa.AMT_APPLICATION != 0 )]\npa = pd.concat([df1, df2, df3, df4])\ndisplay(missing_data(pa))\ndisplay(pa.shape)","c9445420":"msno.bar(pa);","23aa8003":"pa['NAME_TYPE_SUITE'].value_counts()","a92c10b8":"pa['NAME_TYPE_SUITE'].isnull().sum()","b83ae589":"pa['NAME_TYPE_SUITE'].replace(0 , 'Unaccompanied', inplace = True)\npa['NAME_TYPE_SUITE'].replace(np.nan , 'Unaccompanied', inplace = True)\npa['NAME_TYPE_SUITE'].value_counts()","7160c4af":"msno.bar(pa);","89411a99":"pa['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\npa['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\npa['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\npa['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\npa['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)","d793197f":"msno.bar(pa);","910c020f":"missing_data(pa)","4923d438":"pa.select_dtypes(include = [object]).columns","5ddaa977":"pa_cat = pa[['index','NAME_CONTRACT_TYPE', 'WEEKDAY_APPR_PROCESS_START',\n       'FLAG_LAST_APPL_PER_CONTRACT', 'NAME_CASH_LOAN_PURPOSE',\n       'NAME_CONTRACT_STATUS', 'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON',\n       'NAME_TYPE_SUITE', 'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY',\n       'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE',\n       'NAME_SELLER_INDUSTRY', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION']]","bc2c3c5e":"pa_cat.select_dtypes(include = [object]).apply(pd.Series.nunique, axis = 0)","f77cb62b":"pa_cat = pa_cat.sort_index()\npa_cat","6f674395":"missing_data(pa_cat)","9518fc06":"print('pa_cat shape:',pa_cat.shape)","4bc2c204":"pa_num = pa.select_dtypes(include = ['float64','int64'])\npa_num.columns","bd680007":"pa.groupby('SK_ID_CURR')['AMT_ANNUITY', 'AMT_APPLICATION',\n       'AMT_CREDIT', 'AMT_DOWN_PAYMENT', 'AMT_GOODS_PRICE',\n       'HOUR_APPR_PROCESS_START', 'NFLAG_LAST_APPL_IN_DAY',\n       'RATE_DOWN_PAYMENT', 'DAYS_DECISION', 'SELLERPLACE_AREA', 'CNT_PAYMENT',\n       'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION',\n       'DAYS_LAST_DUE', 'DAYS_TERMINATION', 'NFLAG_INSURED_ON_APPROVAL'].mean()","bd1388ae":"pa_num = pa.select_dtypes(include = ['float64','int64'])\npa_drop = pa[['index', 'SK_ID_PREV', 'SK_ID_CURR', ]]\npa_num.drop(['SK_ID_CURR','SK_ID_PREV'],axis=1,inplace=True)\nmissing_data(pa_num)","559b98e5":"pa_drop","47ef8e59":"!pip install ycimpute","9222bba5":"np.array(pa_num)[0:5]","61114bc4":"from ycimpute.imputer import EM\npa_num_nnul = EM().complete(np.array(pa_num))\n","d49ffa88":"var_names = list(pa_num)\npa_num_nnul = pd.DataFrame(pa_num_nnul, columns = var_names)\nmissing_data(pa_num_nnul)","9325c515":"pre_app_num_corr = pa_num_nnul.corr()\nplt.figure(figsize = (28, 26))\n# Heatmap of correlations\nsns.heatmap(pre_app_num_corr, cmap = plt.cm.RdYlBu_r, vmin = -0.25,fmt='.0g', annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap')","f6b8a4db":"pa_num_nnul.shape","210f8806":"def iqr(df):\n    IQR = df.describe().T\n    IQR['lower'] = IQR['25%']-1.5*(IQR['75%']-IQR['25%'])\n    IQR['upper'] = IQR['75%']+1.5*(IQR['75%']-IQR['25%'])\n    upper_count = []\n    i = 0\n    for col in df:\n        upper_count.append(len(df[df[col] > IQR.iloc[i][-1]]))\n        i +=1\n    print(upper_count)\n    lower_count = []\n    i = 0\n    for col in df:\n        lower_count.append(len(df[df[col] < IQR.iloc[i][-2]]))\n        i +=1\n    print(lower_count)\n    IQR['lower_count'] = lower_count\n    IQR['upper_count'] = upper_count\n    IQR['out_percent'] = (IQR['upper_count'] + IQR['lower_count'])\/IQR['count']\n    return IQR","3cc2f604":"iqr(pa_num_nnul)","b531f99b":"pa_num_nnul.loc[pa_num_nnul['AMT_APPLICATION'] > 422820.00,'AMT_APPLICATION'] = 422820.00\npa_num_nnul.loc[pa_num_nnul['AMT_CREDIT'] > 504805.50,'AMT_CREDIT'] = 504805.50\npa_num_nnul.loc[pa_num_nnul['AMT_GOODS_PRICE'] > 422932.5,'AMT_GOODS_PRICE'] = 422932.5\npa_num_nnul.loc[pa_num_nnul['SELLERPLACE_AREA'] > 206.50,'SELLERPLACE_AREA'] = 206.50\npa_num_nnul.loc[pa_num_nnul['DAYS_LAST_DUE_1ST_VERSION'] > 870.00,'DAYS_LAST_DUE_1ST_VERSION'] = 870.00\npa_num_nnul.loc[pa_num_nnul['DAYS_LAST_DUE_1ST_VERSION'] < -1450.00,'DAYS_LAST_DUE_1ST_VERSION'] = -1450.00","63da7286":"iqr(pa_num_nnul)","6233cdb6":"pa.sort_values(by=['index'])","e80d1934":"pa_cat","c4dd0520":"pa_num_nnul.sort_values(by=['index'])","b6c327b9":"pa_drop.sort_index()","90174b3f":"result = pd.merge(pa_drop, pa_num_nnul)\nresult","b649a7fe":"missing_data(result)","978f8bc8":"result = pd.concat([panew, df_cat], axis=1)\n\n\nresult = result[['SK_ID_CURR', 'NAME_CONTRACT_TYPE','AMT_ANNUITY',\n       'AMT_APPLICATION', 'AMT_CREDIT', 'AMT_DOWN_PAYMENT', 'AMT_GOODS_PRICE',\n       'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START',\n       'FLAG_LAST_APPL_PER_CONTRACT', 'NFLAG_LAST_APPL_IN_DAY',\n       'RATE_DOWN_PAYMENT', 'NAME_CASH_LOAN_PURPOSE', 'NAME_CONTRACT_STATUS',\n       'DAYS_DECISION', 'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON',\n       'NAME_TYPE_SUITE', 'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY',\n       'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE',\n       'SELLERPLACE_AREA', 'NAME_SELLER_INDUSTRY', 'CNT_PAYMENT',\n       'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION', 'DAYS_FIRST_DRAWING',\n       'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE',\n       'DAYS_TERMINATION', 'NFLAG_INSURED_ON_APPROVAL']]\nresult.shape","e6e5ea3f":"result","e8888b31":"pre_app[pre_app.SK_ID_CURR == 175704]","c5d3792b":"result[result.SK_ID_CURR == 175704]","570c4e54":"def aykiri(df):\n    display(df.head())\n    Q1=df.quantile(0.25)\n    Q3=df.quantile(0.75)\n    IQR=Q3-Q1\n    alt_sinir=Q1-1.5*IQR\n    ust_sinir=Q3+1.5*IQR\n    sns.boxplot(x=df);\n    aykiri_alt = (df < alt_sinir)\n    aykiri_ust = (df > ust_sinir)\n    #df[aykiri_alt] = alt_sinir\n    #df[aykiri_ust] = ust_sinir\n    print(alt_sinir,ust_sinir,(len(df[aykiri_ust])+len(df[aykiri_alt]))\/len(df))","82082000":"posc = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/POS_CASH_balance.csv')\ndisplay(posc)\nmissing_data(posc)\n\nposc[(posc.CNT_INSTALMENT.isna() == True) & posc.CNT_INSTALMENT_FUTURE.isna() == False]\n\ninstall = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/installments_payments.csv')\ndisplay(install)\nmissing_data(install)\n\ncrec = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/credit_card_balance.csv')\ndisplay(crec)\nmissing_data(crec)\n\ncrec[crec.AMT_DRAWINGS_ATM_CURRENT.isna() == True].sample(20)\n\ncrec[crec.AMT_DRAWINGS_ATM_CURRENT.isna() == False].sample(20)","c8517c7e":"posc[(posc.CNT_INSTALMENT.isna() == True) & posc.CNT_INSTALMENT_FUTURE.isna() == False]","854361b2":"install = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/installments_payments.csv')\ndisplay(install)\nmissing_data(install)","573333f6":"crec = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/credit_card_balance.csv')\ndisplay(crec)\nmissing_data(crec)","6f987fcd":"crec[crec.AMT_DRAWINGS_ATM_CURRENT.isna() == True].sample(20)","f94b20a6":"crec[crec.AMT_DRAWINGS_ATM_CURRENT.isna() == False].sample(20)","6ecb48e3":"# POS_CASH_balance","85441262":"\n# Data\n\nThe data is provided by [Home Credit](http:\/\/www.homecredit.net\/about-us.aspx), a service dedicated to provided lines of credit (loans) to the unbanked population. Predicting whether or not a client will repay a loan or have difficulty is a critical business need, and Home Credit is hosting this competition on Kaggle to see what sort of models the machine learning community can develop to help them in this task. \n\nThere are 7 different sources of data:\n\n* application_train\/application_test: the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature `SK_ID_CURR`. The training application data comes with the `TARGET` indicating 0: the loan was repaid or 1: the loan was not repaid. \n* bureau: data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits.\n* bureau_balance: monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length. \n* previous_application: previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature `SK_ID_PREV`. \n* POS_CASH_BALANCE: monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows.\n* credit_card_balance: monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows.\n* installments_payment: payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment. \n\nThis diagram shows how all of the data is related:\n\n![image](https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/home-credit\/home_credit.png)\n\nMoreover, we are provided with the definitions of all the columns (in `HomeCredit_columns_description.csv`) and an example of the expected submission file. \n\nIn this notebook, we will stick to using only the main application training and testing data. Although if we want to have any hope of seriously competing, we need to use all the data, for now we will stick to one file which should be more manageable. This will let us establish a baseline that we can then improve upon. With these projects, it's best to build up an understanding of the problem a little at a time rather than diving all the way in and getting completely lost! ","7a933815":"# missing data fonksiyon","2433326d":"# pre_app numeric values to fill","4a7a6429":"# OUTLIER","3fab3843":"# missing data gorsel","9590b85b":"# % 99 olan iki stunu (RATE_INTEREST_PRIMARY','RATE_INTEREST_PRIVILEGED) drop ediyoruz","ace962ab":"# pre_app missin data nan to 0","cad1521b":"# pre_app char plot","62bc0cc7":"# previous_application","7eaa62e2":"# numeric values","9aad1751":"# pre_app categoric values","1aa0276f":"#  %10 dan daha buyukler baskilama ile outlier lardan temizliyoruz","ed4c254c":"# pre_app numeric values"}}