{"cell_type":{"14441c14":"code","35d800d6":"code","0a2c9208":"code","780fd41b":"code","e340c5df":"code","0259fcea":"code","23f854c4":"code","84a021ec":"code","b7d2c709":"code","5e14ccc2":"code","a2227de9":"code","1dd05b9a":"code","a0982464":"code","f98b4d4b":"code","317be3a2":"code","ed5f62c2":"code","401a31e3":"code","3dba1bad":"code","eb2af5d1":"code","542e6f5d":"code","0e77afab":"markdown","227a34b5":"markdown","6946076a":"markdown","0da72190":"markdown","cd304b90":"markdown","8e2dc41f":"markdown"},"source":{"14441c14":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","35d800d6":"import  sklearn\nfrom    sklearn.model_selection import train_test_split\nimport  pandas as pd\n\nimport  torch\nimport  torch.nn as nn\nimport  torchvision.transforms as transforms\nimport  torch.nn.functional as F\nfrom    torch.utils.data import Dataset, DataLoader\n\nimport  random\nimport  time\n\nimport  matplotlib.pyplot as plt\nimport  PIL\nfrom    PIL import Image\n\nimport  os\nimport  glob\nfrom    pathlib import Path","0a2c9208":"main_directory = os.listdir(\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\")\ndirectory = (\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\")\n\ndata_path = Path(directory)","780fd41b":"# Path for all the files in a 'png' format.\nimage_path = list(data_path.glob('**\/*.png')) ","e340c5df":"# Separate Segmented from Non-Segmented Images\n\nnon_segmented_images = [img for img in image_path if 'GT' not in str(img)]\nlabels_non_segment = [img.parts[-3] for img in non_segmented_images]\n\nsegmented_images = [img for img in image_path if 'GT' in str(img)]\nlables_segment = [img.parts[-3] for img in segmented_images]\n\nclasses = list(set(lables_segment))\n\nprint(f\"Available Classes: {classes}\")","0259fcea":"# Convert String Labels to int\n\nint_classes = {fish:i for i,fish in enumerate(classes)}\n\nlables = [int_classes[lable] for lable in labels_non_segment]\n\n# Label Dictionary\nprint(int_classes)","23f854c4":"# Saving in a DataFrame\nimage_data = pd.DataFrame({'Path': non_segmented_images,\\\n              'labels': lables})","84a021ec":"image_data.head()","b7d2c709":"train,test, train_labels, test_labels = train_test_split(image_data.Path, image_data.labels, test_size=0.2, shuffle=True)\n\ntrain,val, train_labels, val_labels = train_test_split(train, train_labels, test_size=0.2, shuffle=True)","5e14ccc2":"class FishDataset(Dataset):\n    def __init__(self, images, labels, transform = None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.images.iloc[idx])\n        if self.transform:\n            img = self.transform(img)\n            label = self.labels.iloc[idx]\n        return img, label","a2227de9":"def get_loaders(train, train_labels, val, val_labels,test, test_labels, batch_size, num_workers, train_transform, test_transform):\n    \"\"\"\n    Returns the Train, Validation and Test DataLoaders.\n    \"\"\"\n\n    train_ds = FishDataset(images = train, labels = train_labels, transform = train_transform)\n    val_ds = FishDataset(images = val, labels = val_labels, transform = test_transforms)\n    test_ds = FishDataset(images = test, labels = test_labels, transform = test_transforms)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size,num_workers=num_workers,\n                            shuffle= True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size,num_workers=num_workers,\n                            shuffle= False)\n    test_loader = DataLoader(test_ds, batch_size=batch_size,num_workers=num_workers,\n                          shuffle= False)\n    return train_loader, val_loader, test_loader","1dd05b9a":"##########################\n### FISH DATASET\n##########################\n\ntrain_transform = transforms.Compose([transforms.Resize((64,64)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n                                      ])\n\ntest_transforms = transforms.Compose([transforms.Resize((64,64)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])","a0982464":"# Architecture\nclass ConvNet(torch.nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.layers = torch.nn.Sequential(\n            # 1st Convolution\n            torch.nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n            torch.nn.BatchNorm2d(64),\n            torch.nn.LeakyReLU(0.1, inplace=True),\n            # 2nd Convolution\n            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            torch.nn.BatchNorm2d(64),\n            torch.nn.LeakyReLU(0.1, inplace=True),\n            # 3rd Convolution\n            torch.nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n            torch.nn.BatchNorm2d(64),\n            torch.nn.LeakyReLU(0.1, inplace=True),\n            # MLP Layer\n            torch.nn.Flatten(),\n            torch.nn.Linear(16384, 128),\n            torch.nn.BatchNorm1d(128),\n            torch.nn.LeakyReLU(0.1, inplace=True),\n            torch.nn.Dropout(0.5),\n            #\n            torch.nn.Linear(128, num_classes),\n            )\n    def forward(self, x):\n        logits = self.layers(x)\n        return logits","f98b4d4b":"##########################\n### SETTINGS\n##########################\n\nRANDOM_SEED = 123\nBATCH_SIZE = 128\nNUM_EPOCHS = 10\nWORKERS = 0\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","317be3a2":"def set_all_seeds(seed):\n    \"\"\"For consistency\"\"\"\n    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)","ed5f62c2":"set_all_seeds(RANDOM_SEED)","401a31e3":"# Create Data Loaders\ntrain_loader, val_loader, test_loader = get_loaders(train,train_labels,val, val_labels, test,test_labels, BATCH_SIZE,WORKERS,\n                                                    train_transform, test_transforms)","3dba1bad":"model = ConvNet(num_classes=9)\n\nmodel = model.to(DEVICE)\n\noptimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.1)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                       factor=0.1,\n                                                       mode='max',\n                                                       verbose=True)","eb2af5d1":"# helper for computing Test Accuracy\ndef compute_accuracy(model, data_loader, device):\n    model.eval\n    with torch.no_grad():\n        correct_pred, num_examples = 0, 0\n\n    for i, (features, targets) in enumerate(data_loader):\n        features = features.to(device)\n        targets = targets.float().to(device)\n\n        logits = model(features)\n        _, predicted_labels = torch.max(logits, 1)\n\n        num_examples += targets.size(0)\n        correct_pred += (predicted_labels == targets).sum()\n    return correct_pred.float()\/num_examples * 100","542e6f5d":"logging_interval = 50\nscheduler_on='minibatch_loss'\nstart_time = time.time()\n\nminibatch_loss_list, train_acc_list, valid_acc_list = [],[],[]\n\nfor epoch in range(NUM_EPOCHS):\n  # Start Training\n    model.train()\n    for batch_idx, (features, target) in enumerate(train_loader):\n        features = features.to(DEVICE)\n        targets = target.to(DEVICE)\n        # Forward and BackPropagation\n        logits = model(features)\n        loss = F.cross_entropy(logits, targets)\n        optimizer.zero_grad()\n        loss.backward()\n\n        # Update Model Parameters\n        optimizer.step()\n\n        ## LOGGING\n        minibatch_loss_list.append(loss.item())\n        if not batch_idx % logging_interval:\n            print(f\"Epoch = {epoch+1:03d}\/{NUM_EPOCHS:03d}\"\n                  f\"| Batch {batch_idx:04d}\/{len(train_loader):04d}\"\n                  f\"| Loss: {loss:.4f}\")\n\n    ## Validation\n    model.eval()\n    with torch.no_grad():\n        train_acc = compute_accuracy(model, train_loader, DEVICE)\n        valid_acc = compute_accuracy(model, val_loader, DEVICE)\n        print(f'Epoch: {epoch+1}\/{NUM_EPOCHS:03d} '\n            f'| Train: {train_acc :.2f}% '\n            f'| Validation: {valid_acc :.2f}%')\n        train_acc_list.append(train_acc)\n        valid_acc_list.append(valid_acc)\n    \nelapsed = (time.time() - start_time)\/60\nprint(f'Time elapsed: {elapsed:.2f} min')\n\nif scheduler is not None:\n    if scheduler_on == \"valid_acc\":\n        scheduler.step(valid_acc_list[-1])\n    if scheduler_on == 'minibatch_loss':\n        scheduler.step(minibatch_loss_list[-1])\n    else:\n        raise ValueError(\"Invalid `scheduler_on` choice\")\n\ntotal_elapsed = (time.time() - start_time)\/60\nprint(f'Total Training Time: {total_elapsed:.2f} min')\n\n# Compute Test Accuracy\ntest_acc = compute_accuracy(model, test_loader, device=DEVICE)\n\nprint(f\"Test accuracy: {test_acc:0.3f}\")","0e77afab":"## Model Training","227a34b5":"- Implementation of a simple 3-layer CNN on Fish Dataset using PyTorch.\n- Notebook prepared on Colab.\n- The Test Data consisted of 20% data\n- Test Accuracy: __98.5%__\n- Applications of [AlexNet Architecture](https:\/\/s-b-iqbal.github.io\/Reflexione\/alexnet\/pytorch\/image%20classification\/2021\/07\/18\/AlexNet-Scratch.html) and [Transfer Learning](https:\/\/colab.research.google.com\/github\/S-B-Iqbal\/Reflexione\/blob\/master\/_notebooks\/2021-07-23-Transfer-Learning.ipynb) on the same dataset. Please have a look and comment on making further improvements.","6946076a":"### Data Split: Train\/Val\/Test","0da72190":"### Data transformation\n\nIn Image datasets, we usually apply different transformers to train and validation sets. For instance, We might take a random croppped region `torchvision.transform.RandomCrop()` within the Train Dataset but for Test Set we might use cropped from centre image `torchvision.transform.CenterCrop()`. \n\nSo, we can do the following:    \n1. Save the image path and label in a dataframe.\n2. Split the dataframe into Train\/Val\/Test using sklearn's `train_test_split`\n3. Load the different datasets using the custom Data-loading class `FishDataset`\n\nA well explained tutorial on it is available on [Sebastian Raschka's Repo](https:\/\/nbviewer.jupyter.org\/github\/rasbt\/deeplearning-models\/blob\/master\/pytorch_ipynb\/mechanics\/custom-dataloader-png\/custom-dataloader-example.ipynb)","cd304b90":"## ConvNet","8e2dc41f":"### Data Pre-Processing"}}