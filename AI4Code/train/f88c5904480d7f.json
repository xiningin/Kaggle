{"cell_type":{"3a4f3f91":"code","4f9a6f4c":"code","087817df":"code","66c6e439":"code","99d8a1e3":"code","30651eeb":"code","ef401600":"code","254dbcbc":"code","1fdea6cd":"code","0ac5b6d7":"code","0d820174":"code","0cde6278":"code","8ab87dc1":"code","d3517e48":"code","08ce57dc":"code","5433fb7b":"markdown","83882f81":"markdown","918462c0":"markdown","50c489a3":"markdown","c7c7935f":"markdown","0c2637ed":"markdown"},"source":{"3a4f3f91":"import pandas as pd\nimport numpy as np","4f9a6f4c":"from load_kaggle import load_kaggle","087817df":"train, test, subm = load_kaggle()\nprint(train.shape, test.shape, subm.shape)\ntrain.head()","66c6e439":"!pip install autoviml","99d8a1e3":"from autoviml.Auto_ViML import Auto_ViML","30651eeb":"target = 'Survived'","ef401600":"from autoviml.Auto_NLP import Auto_NLP","254dbcbc":"nlp_column = 'Name'\nmodeltype = 'Classification'\nscore_type = 'balanced_accuracy'\ntrain_nlp, test_nlp, best_nlp_transformer,_ = Auto_NLP(\n                nlp_column, train, test, target, score_type,\n                modeltype,top_num_features=50, verbose=0)","1fdea6cd":"scoring_parameter = 'balanced-accuracy'\nsample_submission = ''","0ac5b6d7":"#### Using Linear model, KMEans=True and all other flag set to False except feature reduction which is True\n#### gets the highest ROC_AUC score of 90% for Titanic Data set using Missing_Flag columns!!\nm, feats, trainm, testm = Auto_ViML(train_nlp, target, test_nlp, sample_submission='',\n                                    scoring_parameter=scoring_parameter,\n                                    hyper_param='GS',feature_reduction=True,\n                                     Boosting_Flag=\"CatBoost\",Binning_Flag=True,\n                                    Add_Poly=0, Stacking_Flag=False, \n                                    Imbalanced_Flag=False,KMeans_Featurizer=True, \n                                    verbose=2)                        ","0d820174":"testm.head()","0cde6278":"modelname = 'Ensembled'","8ab87dc1":"y_preds = testm[target+'_'+modelname+'_predictions'].values.astype(int)\ny_preds[:5]","d3517e48":"subm[target] = y_preds\nsubm.head()","08ce57dc":"subm.to_csv('titanic_autoviml_cat8.csv', index=False)","5433fb7b":"## Now we will take predictions from a single model and then ensemble model to test","83882f81":"## We can see that from Name feature alone, we are able to predict with ~78% accuracy whether a passenger will survive or not. Why?\n\nThat is because Name field contains Mr, Mrs, Jr, etc initials that tell the model whether they are Male or Female or Children. This enables the model to predict their survival probabilities. Let us feed this learning to the next library, AutoViML","918462c0":"# Notice that among the Top 10 features the model correctly used the Master_Bin and the Miss_Bin to predict whether a Passenger will survive or not! That is the power of NLP!!","50c489a3":"### first we will load_kaggle which you can add to your notebooks as \"Utility Script\" from the \"File Menu\" on top. It makes it cleaner to load Kaggle datasets in the current notebook.","c7c7935f":"# We will use Auto_NLP and Auto_ViML to try to set a new benchmark in Titanic using the fewest lines of code. Take a look and see for yourself whether we have done that.\n\nAuto_NLP is a NLP preparation library to prepare your NLP text columns to feed to an AutoML model. This enables the AutoML model to learn from your text columns to deliver better predictions. AutoViML and Auto_NLP are part of the same package below.\n\nGithub Found here: https:\/\/github.com\/AutoViML\/Auto_ViML","0c2637ed":"## Let us first extract some unseful information from Name column (using NLP)"}}