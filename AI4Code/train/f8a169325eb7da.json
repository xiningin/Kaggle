{"cell_type":{"9291d709":"code","31dcd65a":"code","b74c8a4c":"code","0a5dff21":"code","622ebfae":"code","dc5d362f":"code","0df3bf59":"code","7938adbc":"code","7996563d":"code","9d8435f4":"code","41e8acef":"markdown"},"source":{"9291d709":"!pip install -q -U albumentations","31dcd65a":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport random\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D,Dropout, Concatenate, Conv2DTranspose\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras import backend as K\nfrom albumentations import (\n    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n    Rotate,GridDistortion,ElasticTransform\n)","b74c8a4c":"# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(9, 9))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image, cmap = 'bone')\n    plt.show()","0a5dff21":"transforms = Compose([\n        ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n        GridDistortion(p=0.5),\n#         OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1),\n#         VerticalFlip(p=0.5),\n        \n])\n","622ebfae":"def load_data(x_path, y_path):\n    images = os.listdir(x_path)\n    masks = os.listdir(y_path)\n    \n    train_x = [os.path.join(x_path, image) for image in images]\n#     train_y = [os.path.join(y_path, mask) for mask in masks]\n    \n    train_y = list(map(lambda x : x.replace('.jpg', '.tiff'), train_x))\n    train_y = list(map(lambda x : x.replace('train_images\/train_images', 'train_masks\/train_masks'), train_y))\n    \n    \n    train_x, valid_x = train_test_split(train_x, test_size=0.15, random_state=42)\n    train_y, valid_y = train_test_split(train_y, test_size=0.15, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y)\n\n\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n    x = x \/ 255.0\n    x = x.astype(np.float32)\n    return x\n\n\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = x.astype(np.int32)\n    return x\n\n\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n    dataset = dataset.shuffle(buffer_size= 5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(2)\n    return dataset\n\n\ndef preprocess(x,y):\n    \n    def aug_fn(image, mask):\n        img_data = {\"image\":image}\n        mask_data = {\"mask\":mask}\n        img_data = transforms(**image)\n        mask_data = transforms(**mask)\n        aug_img = img_data[\"image\"]\n        aug_mask = mask_data[\"mask\"]\n        return aug_img, aug_mask\n    \n    def f(x,y):\n        x = x.decode()\n        y = y.decode()\n        \n        image = read_image(x)\n        mask = read_mask(y)\n        augmented = transforms(image=image,mask=mask)\n        aug_img=augmented['image']\n        aug_mask = augmented['mask']\n        \n        return aug_img, aug_mask\n    \n    image, mask = tf.numpy_function(f, [x,y], [tf.float32, tf.int32])\n#     image, mask = tf.numpy_function(aug_fn,[image, mask],[tf.float32, tf.int32])\n    mask = tf.one_hot(mask, 3, dtype = tf.int32)\n    image.set_shape([256,256,3])\n    mask.set_shape([256,256,3])\n    \n    return image, mask","dc5d362f":"def conv_block(inputs, filters, pool=True):\n    x = Conv2D(filters, 3, padding=\"same\", activation='relu')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    if pool == True:\n        p = MaxPool2D((2, 2))(x)\n        return x, p\n    else:\n        return x\n\ndef build_unet(shape, num_classes):\n    inputs = Input(shape)\n\n    \"\"\" Encoder \"\"\"\n    x1, p1 = conv_block(inputs, 16, pool=True)\n    x2, p2 = conv_block(p1, 32, pool=True)\n    x3, p3 = conv_block(p2, 64, pool=True)\n    #drop3 = Dropout(0.1)(x3)\n    x4, p4 = conv_block(p3, 128, pool=True)\n    #drop4 = Dropout(0.1)(x4)\n    \n    \"\"\" Bridge \"\"\"\n    b1 = conv_block(p4, 256, pool=False)\n    b2 = conv_block(b1, 256, pool=False)\n\n    \"\"\" Decoder \"\"\"\n    #u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n    u1 = Conv2DTranspose(128, (3,3), strides = (2,2), padding=\"same\")(b2)\n    c1 = Concatenate()([u1, x4])\n    x5 = conv_block(c1, 128, pool=False)\n\n#     u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n    u2 = Conv2DTranspose(64, (3,3), strides = (2,2), padding=\"same\")(x5)\n    c2 = Concatenate()([u2, x3])\n    x6 = conv_block(c2, 64, pool=False)\n\n#     u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n    u3 = Conv2DTranspose(32, (3,3), strides = (2,2), padding=\"same\")(x6)\n    c3 = Concatenate()([u3, x2])\n    x7 = conv_block(c3, 32, pool=False)\n\n#     u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n    u4 = Conv2DTranspose(16, (3,3), strides = (2,2), padding=\"same\")(x7)\n    c4 = Concatenate()([u4, x1])\n    x8 = conv_block(c4, 16, pool=False)\n\n    #b2, x5, x6, x7, x8\n                                             #input size\n    b2_new = conv_block(b2, 16, pool=False)  #16,16,256\n    x5_new = conv_block(x5, 16, pool=False)  #32,32,128\n    x6_new = conv_block(x6, 16, pool=False)  #64,64,64   \n    x7_new = conv_block(x7, 16, pool=False)  #128,128,32\n    x8_new = conv_block(x8, 16, pool=False)  #256,256,16\n    \n    #all layers except x8_new need to transposed to dimension 256,256,16\n    \n    b2_transposed = Conv2DTranspose(16, (3,3), strides = (16,16))(b2_new)\n    x5_transposed = Conv2DTranspose(16, (3,3), strides = (8,8))(x5_new)  \n    x6_transposed = Conv2DTranspose(16, (3,3), strides = (4,4))(x6_new)     \n    x7_transposed = Conv2DTranspose(16, (3,3), strides = (2,2), padding = 'same')(x7_new)  \n    x8_transposed = x8_new\n    \n    concat_output = Concatenate()([b2_transposed, x5_transposed, x6_transposed, x7_transposed, x8_transposed ])\n                    #o\/p shape = 256,256,90\n    \n    \n    \"\"\" Output layer \"\"\"\n    #x9 = Conv2D(16, (3,3), padding = \"same\", activation = \"relu\")(x8)  #end result not good enough\n    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(concat_output)\n\n    return Model(inputs, output)\n","0df3bf59":"def dice_coef(y_true, y_pred, smooth=1):\n    \"\"\"\n    Dice = (2*|X & Y|)\/ (|X|+ |Y|)\n         =  2*sum(|A*B|)\/(sum(A^2)+sum(B^2))\n    ref: https:\/\/arxiv.org\/pdf\/1606.04797v1.pdf\n    \"\"\"\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    \n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) \/ (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","7938adbc":"if __name__ == \"__main__\":\n    \n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    i = random.randint(0,49000)\n    \n    \"\"\" Dataset \"\"\"\n    train_frame_path = '..\/input\/lits-256x256\/train_images\/train_images'\n    train_mask_path = '..\/input\/lits-256x256\/train_masks\/train_masks'\n    \n    (train_x, train_y), (valid_x, valid_y) = load_data(train_frame_path, train_mask_path)\n    \n    visualize(image = read_image(train_x[i]), mask = read_mask(train_y[i]))\n    \n    \n    #hyperparameters\n    shape = (256,256,3)\n    classes = 3\n    lr = 1e-4\n    batch_size = 64\n    epochs = 14\n    \n    \"\"\" Model \"\"\"\n    model = build_unet(shape, classes)\n    model.compile(loss=dice_coef_loss , optimizer=tf.keras.optimizers.Adam(lr), metrics = [dice_coef] )\n    model.summary()\n    \n    train_dataset = tf_dataset(train_x, train_y, batch = batch_size)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch = batch_size)\n    \n    train_steps = len(train_x)\/\/batch_size\n    valid_steps = len(valid_x)\/\/batch_size\n        \n    callbacks = [\n        ModelCheckpoint(\"best_model.h5\", verbose=1, save_best_model=True),\n        ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-6),\n        EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1,min_delta=0.001)\n    ]\n    \n    history = model.fit(train_dataset,\n        steps_per_epoch=train_steps,\n        validation_data=valid_dataset,\n        validation_steps=valid_steps,\n        epochs=epochs,\n        callbacks=callbacks,\n        verbose = 1\n    )\n    \n    model.save('.\/final_model.h5')","7996563d":"train_steps","9d8435f4":"import gc\ngc.collect()","41e8acef":"Multiple Feature Pyramind Network Unet -- MFP unet\n\nhttps:\/\/arxiv.org\/ftp\/arxiv\/papers\/1906\/1906.10486.pdf\n\nImplementation of "}}