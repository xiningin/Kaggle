{"cell_type":{"6adbfa3d":"code","35d2d212":"code","10e8f192":"code","47a5e390":"code","f9288f6d":"code","1687662f":"code","c0d1a6a5":"code","225c67bf":"code","69bf9050":"code","6c369717":"code","e6df0332":"code","abbafcc9":"code","ad302fda":"code","d5fcd6af":"code","0d7e8805":"code","e60b2cfd":"code","1eff1883":"code","a0e73dea":"code","238d5b15":"code","23e813d6":"code","cb561c21":"code","c4cfc49b":"code","67bea846":"code","a5461392":"code","a80f34c8":"code","626fbf11":"code","9f5bccf5":"code","f0e0a15d":"code","1dd4e8fb":"code","e09063b0":"code","b18a2bc8":"code","6c82fd81":"code","6e6709bc":"code","d1f1e253":"code","0fc07197":"code","a8d960aa":"code","9e1d4062":"code","d5adb569":"code","a9ea2905":"code","0a8b9e87":"code","f6a564ba":"code","36c24abb":"code","c9cafbdf":"code","513ae345":"code","73affb6e":"code","3a6e7182":"code","f927370f":"code","0f61f1a9":"code","e5fbd7e6":"code","e9378afe":"code","b67f22b8":"code","c2420edd":"code","cc14700a":"code","a91ab3b1":"code","88fda4e0":"code","432948df":"code","b42ecd0e":"code","5a21bf10":"code","6c268a48":"code","abc03833":"code","fecf99e3":"code","0e54fa0e":"code","7066e793":"code","f1cc5c80":"code","f15197b7":"code","c82ca3f4":"code","64caa715":"code","bade6782":"code","71a5bee8":"code","7039d88a":"code","9079b655":"code","d64643cf":"code","072465f2":"code","2110551f":"code","f48d6162":"code","576ea4ee":"code","3bc0e5bb":"code","37c7e967":"code","2ff0a769":"code","af8ac744":"code","4153ead5":"code","45a7a14e":"code","dba5773d":"code","5bb1e430":"code","d9fbfb1f":"code","7d43b2dc":"code","e43e0307":"code","0fa2bd6b":"code","7fa4f08e":"code","c4a72cbb":"code","e5a5a133":"code","b5daf04f":"code","0154ce58":"code","ac6294a5":"code","4dfce56e":"code","893f1420":"code","1c81002d":"code","4366105a":"code","d91eda06":"code","2f3ae0af":"code","74dfcd1d":"code","7f33823e":"code","cd91d792":"code","b5269962":"code","b71dea2c":"code","27478389":"code","a974056e":"code","54903686":"code","241d5b5e":"code","a6fd79f4":"code","cce7010c":"code","44499cbf":"code","fde47319":"code","ff598b53":"code","173ea76f":"code","b876cb3b":"code","a217a923":"code","6b4df874":"code","0efa8d19":"code","6b1d02cb":"code","168b0821":"code","2fd79cfe":"code","52dccbcb":"code","985de02c":"code","aafbf82b":"code","bdd45831":"code","6e0cb429":"code","e462efb7":"code","47850e82":"code","7277ce26":"markdown","280bac22":"markdown"},"source":{"6adbfa3d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","35d2d212":"# train_trans=pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv')\n# train_trans","10e8f192":"# target=train_trans[['TransactionID','isFraud']]\n# target","47a5e390":"# test_trans=pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv')\n# test_trans","f9288f6d":"train_iden=pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_identity.csv')\ntrain_iden","1687662f":"test_iden=pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_identity.csv')\ntest_iden","c0d1a6a5":"test_iden.columns=list(train_iden.columns)\ntest_iden","225c67bf":"train_iden=pd.concat([train_iden,test_iden])\ntrain_iden","69bf9050":"train_iden.columns","6c369717":"pd.set_option('display.max_columns', None)","e6df0332":"cols=train_iden.columns.tolist()\ncols","abbafcc9":"train_iden.isnull().sum()","ad302fda":"(np.sum(pd.isnull(train_iden)).sort_values(ascending=False)\/len(train_iden))*100","d5fcd6af":"train_iden.info()","0d7e8805":"for i in [1,2,3,4,5,6,7,8,9,10,11,13,14,17,18,19,20,21,22,24,25,26,32]:\n    \n    if i<10:\n        x='id_0'+str(i)\n    else:\n        x='id_'+str(i)\n        \n    if train_iden[x].nunique()>100:\n        num_of_unique=100\n    else:\n        num_of_unique=train_iden[x].nunique()\n    \n    print('Column: '+x)\n    print('--------------------------------------')\n    print('Number of unique value: '+ str(train_iden[x].nunique()))\n    print('--------------------------------------')\n    print(train_iden[x].value_counts(dropna=False, normalize=True))\n    \n    plt.hist(train_iden[x], bins=num_of_unique)\n    plt.title('Distribution of '+x+' variable')\n    plt.show()","e60b2cfd":"#print(train_iden['id_01'].nunique())\n#print(train_iden['id_01'].value_counts(dropna=False, normalize=True))\n\n#plt.hist(train_iden['id_01'], bins=train_iden['id_01'].nunique());\n#plt.title('Distribution of id_01 variable');","1eff1883":"for i in ['id_12', 'id_15', 'id_16', 'id_23','id_27','id_28', 'id_29', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']:\n    df=train_iden[i].fillna('Null').value_counts(dropna=False).reset_index().rename(columns={'index':'title',i:'value'})\n    sns.barplot(x='title', y='value', data=df).set_title(i)\n    plt.show()","a0e73dea":"train_iden.id_30.value_counts(dropna=False, normalize=True)","238d5b15":"train_iden.id_31.value_counts(dropna=False, normalize=True)","23e813d6":"train_iden.id_33.value_counts(dropna=False, normalize=True)","cb561c21":"train_iden.DeviceType.value_counts(dropna=False, normalize=True)","c4cfc49b":"train_iden.DeviceInfo.value_counts(dropna=False, normalize=True)","67bea846":"fig, ax = plt.subplots(figsize=(10,10)) \nsns.heatmap(train_iden.isnull(), cbar=False)","a5461392":"cor=train_iden.corr()\ncor","a80f34c8":"a=cor.abs()<1\nb=cor.abs()>0.5\ncor.abs()[a&b]\n#cor.columns.apply(lambda x:x if (x>0.9)|(x<-0.9) else nan)","626fbf11":"# take a copy of train_iden for making comparation later\nc_train_iden=train_iden","9f5bccf5":"# filling Nan values with mean value\n\nfor i in [2,5,6,11,13,17,19,20]:\n    \n    if i<10:\n        x='id_0'+str(i)\n    else:\n        x='id_'+str(i)\n        \n    c_train_iden[x].fillna(c_train_iden[x].mean(),inplace=True)","f0e0a15d":"# filling Nan values based on distribution of the values in the column\n\nfor i in [3,4,9,10,14,18,32]:\n    \n    if i<10:\n        x='id_0'+str(i)\n    else:\n        x='id_'+str(i)\n\n    s = c_train_iden[x].value_counts(normalize=True)\n    missing = c_train_iden[x].isnull()\n    c_train_iden.loc[missing,x] = np.random.choice(s.index, size=len(c_train_iden[missing]),p=s.values)","1dd4e8fb":"# filling Nan values with mod\n\nfor i in [15,28,29,31,35,36,37,38]:\n    \n    if i<10:\n        x='id_0'+str(i)\n    else:\n        x='id_'+str(i)\n        \n    c_train_iden[x].fillna(c_train_iden[x].mode()[0],inplace=True)","e09063b0":"# filling Nan values based on distribution of the values in the column\n\nfor i in [16,30,33,34]:\n    \n    if i<10:\n        x='id_0'+str(i)\n    else:\n        x='id_'+str(i)\n\n    s = c_train_iden[x].value_counts(normalize=True)\n    missing = c_train_iden[x].isnull()\n    c_train_iden.loc[missing,x] = np.random.choice(s.index, size=len(c_train_iden[missing]),p=s.values)","b18a2bc8":"# Filling Device Type with mod, Device info with distribution\n\nc_train_iden['DeviceType'].fillna(c_train_iden['DeviceType'].mode()[0],inplace=True)\n\ns = c_train_iden['DeviceInfo'].value_counts(normalize=True)\nmissing = c_train_iden['DeviceInfo'].isnull()\nc_train_iden.loc[missing,'DeviceInfo'] = np.random.choice(s.index, size=len(c_train_iden[missing]),p=s.values)","6c82fd81":"(np.sum(pd.isnull(c_train_iden)).sort_values(ascending=False)\/len(c_train_iden))*100","6e6709bc":"drop_columns=['id_07', 'id_08', 'id_21', 'id_22', 'id_24', 'id_25', 'id_26', 'id_23','id_27']\nc_train_iden=c_train_iden.drop(drop_columns, axis=1)","d1f1e253":"(np.sum(pd.isnull(c_train_iden)).sort_values(ascending=False)\/len(c_train_iden))*100","0fc07197":"pd.set_option(\"display.max_rows\", 1000, \"display.max_columns\", 1000)","a8d960aa":"c_train_iden.id_30.value_counts()","9e1d4062":"c_train_iden.id_30=c_train_iden.id_30.map(lambda x:'Windows' if 'Windows' in x else('iOS' if ('iOS' or 'MAC') in x else ('Linux'if 'Linux' in x else('Android' if 'Android' in x else 'Other'))))","d5adb569":"c_train_iden.id_30.value_counts()","a9ea2905":"# d_train_iden=c_train_iden.copy()\n# for i in range(len(c_train_iden.id_30)):\n#     if 'Windows' in c_train_iden.iloc[i]['id_30']:\n#         c_train_iden.iloc[i]['id_30']='Windows'\n#     elif ('OS' in c_train_iden.iloc[i]['id_30'])|('iOS' in c_train_iden.iloc[i]['id_30']):\n#         c_train_iden.iloc[i]['id_30']='OS'\n#     elif 'Android' in c_train_iden.iloc[i]['id_30']:\n#         c_train_iden.iloc[i]['id_30']='Android'","0a8b9e87":"c_train_iden.id_31.value_counts()","f6a564ba":"c_train_iden.id_31=c_train_iden.id_31.map(lambda x:'chrome' if 'chrome' in x else('safari' if 'safari' in x else ('ie'if 'ie' in x else('edge' if 'edge' in x else('firefox' if 'firefox' in x else('samsung' if ('samsung' or 'Samsung') in x else ('opera' if 'opera' in x else 'Other')))))))","36c24abb":"c_train_iden.id_31.value_counts()","c9cafbdf":"c_train_iden.id_33.value_counts()","513ae345":"c_train_iden.id_33","73affb6e":"c_train_iden.id_33=c_train_iden.id_33.map(lambda x:'Small' if int(x.split('x')[0])*int(x.split('x')[0])<480*854 else ('Medium' if int(x.split('x')[0])*int(x.split('x')[0])<1024*640 else 'Large'))","3a6e7182":"c_train_iden.id_33.value_counts()","f927370f":"c_train_iden.DeviceInfo.value_counts().head(100)","0f61f1a9":"c_train_iden.DeviceInfo=c_train_iden.DeviceInfo.map(lambda x:'Windows' if 'Windows' in x else('Mac' if ('MacOS' or 'iOS') in x else 'Other'))","e5fbd7e6":"c_train_iden.DeviceInfo.value_counts()","e9378afe":"c_train_iden.id_32.value_counts()","b67f22b8":"# print(c_train_iden.id_02.value_counts())\n\n# print('-------------------------------')\n\n# print(c_train_iden.id_02.min(),c_train_iden.id_02.max(),c_train_iden.id_02.nunique())\n\n# print('-------------------------------')\n\n# step = 100000\n# max_val = c_train_iden.id_02.max()\n# min_val= c_train_iden.id_02.min()\n# bins = list(range(int(np.floor(min_val\/step))*step,int(np.ceil(max_val\/step))*step+step,step))\n# clusters = pd.cut(c_train_iden.id_02,bins,labels=bins[1:])\n# print(clusters.value_counts())","c2420edd":"# c_train_iden=pd.merge(left=c_train_iden, right=target, on='TransactionID', how='left')\n# c_train_iden","cc14700a":"# sample1=c_train_iden[['id_03', 'id_04', 'id_09', 'id_10']]\n# cor=sample1.corr()\n# cor","a91ab3b1":"# from sklearn.preprocessing import StandardScaler\n# from sklearn.decomposition import PCA\n# features = ['id_03', 'id_04', 'id_09', 'id_10']\n# # Separating out the features\n# x = c_train_iden.loc[:, features].values\n# # Separating out the target\n# y = c_train_iden.loc[:,['isFraud']].values\n","88fda4e0":"#scale it\n# x = StandardScaler().fit_transform(x)\n\n# pca = PCA()\n# principalComponents = pca.fit_transform(x)","432948df":"# pca.explained_variance_ratio_","b42ecd0e":"# represent=np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)\n# print(represent)","5a21bf10":"# plt.plot(represent)\n# plt.xlabel('number of components')\n# plt.ylabel('cumulative explained variances')\n# plt.show()","6c268a48":"# df_ans=pd.DataFrame({'var':pca.explained_variance_ratio_,\n#                    'PC':['PC1','PC2','PC3','PC4']})\n# df_ans\n","abc03833":"# sns.barplot(x='PC',y='var', data=df_ans, color='c')\n# plt.ylabel('Variance Explained')\n# plt.xlabel('Principle Components')\n# plt.show()","fecf99e3":"# sample2=c_train_iden[['id_19', 'id_20']]\n# cor=sample2.corr()\n# cor","0e54fa0e":"# features = ['id_19', 'id_20']\n# # Separating out the features\n# x = c_train_iden.loc[:, features].values\n# # Separating out the target\n# y = c_train_iden.loc[:,['isFraud']].values\n\n# x = StandardScaler().fit_transform(x)\n\n# pca = PCA()\n# principalComponents = pca.fit_transform(x)\n\n# pca.explained_variance_ratio_\n","7066e793":"# df_ans=pd.DataFrame({'var':pca.explained_variance_ratio_,\n#                    'PC':['PC1','PC2']})\n# sns.barplot(x='PC',y='var', data=df_ans, color='c')\n# plt.ylabel('Variance Explained')\n# plt.xlabel('Principle Components')\n# plt.show()","f1cc5c80":"# (np.sum(pd.isnull(c_train_iden)).sort_values(ascending=False)\/len(c_train_iden))*100","f15197b7":"# c_train_iden.info()","c82ca3f4":"#Kategorik veriler:\n#id_12,id_15,id_16,id_28,id_29,id_30,id_31,id_33,id_34,id_35,id_36,id_37,id_38,DeviceInfo,DeviceType","64caa715":"for i in ['id_12', 'id_15', 'id_16','id_28', 'id_29', 'id_30','id_31','id_33','id_34', 'id_35', 'id_36', 'id_37', 'id_38','DeviceInfo','DeviceType']:\n    df=c_train_iden[i].value_counts(dropna=False).reset_index().rename(columns={'index':'title',i:'value'})\n    sns.barplot(x='title', y='value', data=df).set_title(i)\n    plt.show()","bade6782":"# def create_dummies( df, colname ):\n#     col_dummies = pd.get_dummies(df[colname], prefix=colname)\n    \n#     df = pd.concat([df, col_dummies], axis=1)\n#     df.drop( colname, axis = 1, inplace = True )\n#     return df\n\n# colname= ['id_12', 'id_15', 'id_16','id_28', 'id_29', 'id_30','id_31','id_33','id_34', 'id_35', 'id_36', 'id_37', 'id_38','DeviceInfo','DeviceType']\n# create_dummies(c_train_iden,colname)","71a5bee8":"def frekans(data,columns,n_label=\"NONE\"):\n    \n    for col in columns:\n        data[col].fillna(n_label,inplace=True)\n        fq_encode = data[col].value_counts(dropna=False).to_dict()   \n        data[col+\"_Fr\"] = data[col].map(fq_encode)\n        data=data.drop(col,axis=1)\n    return data\n\ncolumns= ['id_12', 'id_15', 'id_16','id_28', 'id_29', 'id_30','id_31','id_33','id_34', 'id_35', 'id_36', 'id_37', 'id_38','DeviceInfo','DeviceType']\nc_train_iden=frekans(c_train_iden,columns)","7039d88a":"c_train_iden.head()","9079b655":"#### Ersinin kisim","d64643cf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport datetime\n\n\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial.distance import cdist, pdist","072465f2":"## Function to reduce the DF size\n# https:\/\/www.kaggle.com\/kabure\/almost-complete-feature-engineering-ieee-data\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\ndef PCA_change(df, cols, n_components, prefix='PCA_', rand_seed=4):\n    pca = PCA(n_components=n_components, random_state=rand_seed)\n\n    principalComponents = pca.fit_transform(df[cols])\n\n    principalDf = pd.DataFrame(principalComponents)\n\n    df.drop(cols, axis=1, inplace=True)\n\n    principalDf.rename(columns=lambda x: str(prefix)+str(x), inplace=True)\n\n    df = pd.concat([df, principalDf], axis=1)\n    \n    print(pca.explained_variance_ratio_)\n    \n    return df","2110551f":"# CALISACAGIM DATASET\ntrain_transaction=pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv',index_col='TransactionID')\ntest_transaction=pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/test_transaction.csv',index_col='TransactionID')\n# test_transaction setinde isFraud sutunu bulunmadigindan concat oncesi yeni ekliyoruz ve 2 degerini dolduruyoruz\ntest_transaction['isFraud']=2","f48d6162":"train_transaction = reduce_mem_usage(train_transaction)\ntest_transaction = reduce_mem_usage(test_transaction)","576ea4ee":"# train_transaction ve test_transaction setlerini concat ediyoruz\ntransaction=pd.concat([train_transaction, test_transaction], axis=0, sort=False )\ntransaction = transaction.reset_index()","3bc0e5bb":"transaction = reduce_mem_usage(transaction)","37c7e967":"# BENIM KISIM OLAN COLUMNLARI BASKA BIR VARIABLE ATIYORUZ ve CALISMAMIZDA COPYASINI KULLANIYORUZ\ntransaction_mycolumns=transaction.iloc[:,0:55]\nmy_transaction=transaction_mycolumns.copy()","2ff0a769":"print('Shape before PCA')\nmy_transaction.shape","af8ac744":"# Eksik verileri oransal bar ile gorsellestirme\nfig, ax = plt.subplots(figsize=(30,20)) \nsns.heatmap(my_transaction.isnull(), cbar=False)","4153ead5":"# Kolonlarda ne kadar eksik veri var - bunun yuzdesini  nedir --> yuksekten asagi siraladik(TAM OLANLAR HARIC)\n\nmis_value = my_transaction.isnull().sum()\nmis_value_percent = 100*my_transaction.isnull().sum()\/len(my_transaction)\nmis_dtype = my_transaction.dtypes\n\nmis_value_table = pd.concat([mis_value,mis_value_percent,mis_dtype], axis = 1)\nmis_value_table.columns=['count', 'percent','type']\nmis_value_table = mis_value_table.sort_values('percent',ascending=False)\nmis_value_table = mis_value_table[mis_value_table['percent']>0]\npd.set_option('display.max_rows', None)\nmis_value_table","45a7a14e":"# % 85 den fazla Eksik Veri olan 5 sutunu siliyoruz\n# dist2,D7 D8 D9 D12\n\nmis_value_table_per80 = mis_value_table[mis_value_table['percent']>85]\ndrop_index_column_name=mis_value_table_per80.index[:]\n\nfor column_name in drop_index_column_name:\n    my_transaction.drop(column_name, axis=1, inplace=True)","dba5773d":"my_transaction.columns","5bb1e430":"c_feat = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n              'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14']\n\nfor col in c_feat:\n    my_transaction[col] = my_transaction[col].fillna((my_transaction[col].min() - 1))\n    my_transaction[col] = (minmax_scale(my_transaction[col], feature_range=(0,1)))\n  \nmy_transaction = PCA_change(my_transaction, c_feat, prefix='PCA_C_', n_components=3)\n\nc_features = ['PCA_C_0', 'PCA_C_1', 'PCA_C_2']\n\nkm = KMeans(n_clusters=4)\nkm = km.fit(my_transaction[c_features])\nmy_transaction['clusters_C'] = km.predict(my_transaction[c_features])","d9fbfb1f":"my_transaction = reduce_mem_usage(my_transaction)\nmy_transaction.shape","7d43b2dc":"d_features = ['D1', 'D2', 'D3', 'D4', 'D5', 'D6','D10', 'D11', 'D13', 'D14', 'D15']\n\none_fill = ['D1', 'D2', 'D3', 'D5', 'D6','D10', 'D11', 'D13', 'D14']\n\nnn_fill = ['D4', 'D15']\n\nfor col in one_fill:\n    my_transaction[col] = (minmax_scale(my_transaction[col], feature_range=(0,1)))\n    my_transaction[col] = my_transaction[col].fillna(-1)\n    \nfor col in nn_fill:\n    my_transaction[col] = (minmax_scale(my_transaction[col], feature_range=(0,1)))\n    my_transaction[col] = my_transaction[col].fillna(-1)\n  \n\n\nmy_transaction = PCA_change(my_transaction, d_features, prefix='PCA_D_', n_components=8)\n\npca_d = ['PCA_D_0', 'PCA_D_1', 'PCA_D_2', 'PCA_D_3',\n         'PCA_D_4', 'PCA_D_5', 'PCA_D_6', 'PCA_D_7']\n\nkm = KMeans(n_clusters=8)\nkm = km.fit(my_transaction[pca_d])\nmy_transaction['clusters_D'] = km.predict(my_transaction[pca_d])","e43e0307":"my_transaction = reduce_mem_usage(my_transaction)\nmy_transaction.shape","0fa2bd6b":"my_transaction.head()","7fa4f08e":"my_transaction['addr1'] = my_transaction['addr1'].fillna(0)\nmy_transaction['addr2'] = my_transaction['addr2'].fillna(0)\n\nmy_transaction['diff_adrr'] = my_transaction.addr1 - my_transaction.addr2\nmy_transaction['diff_adrr_plus'] = my_transaction.addr1 + my_transaction.addr2\n\nmy_transaction['first_value_addr1'] = my_transaction['addr1'].astype(str).str[0:1].astype(float)\nmy_transaction['two_value_addr1'] = my_transaction['addr1'].astype(str).str[0:2].astype(float)","c4a72cbb":"## Filling Dist1 Nan's\nmy_transaction['dist1'] = my_transaction['dist1'].fillna(-1)","e5a5a133":"# card1 de missing value yok \n# card2 yi inceleyelim 1.603 nan degeri median(Ortanca De\u011fer) ile dolduruyoruz\nmy_transaction.card2.describe()\nmy_transaction['card2'].fillna(my_transaction['card2'].median(),inplace=True)","b5daf04f":"# card3 4567 Nan degerini modu olan 150 degeri ile dolduruyoruz %87 si bu degerde\nmy_transaction.card3.fillna(my_transaction['card3'].mode()[0],inplace=True)","0154ce58":"# card4 ve card6 Kategorik degerleri incelerken dolduracagiz\n# card5 8806 nan degeri median() ile dolduracagiz\nmy_transaction['card5'].fillna(my_transaction['card5'].median(),inplace=True) ","ac6294a5":"my_transaction = reduce_mem_usage(my_transaction)\nmy_transaction.shape","4dfce56e":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', \n          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', \n          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', \n          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', \n          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', \n          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', \n          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', \n          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n\nus_emails = ['gmail', 'net', 'edu']\n\n# https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/100499#latest-579654\nfor c in ['P_emaildomain', 'R_emaildomain']:\n    my_transaction[c + '_bin'] = my_transaction[c].map(emails)\n    my_transaction[c + '_suffix'] = my_transaction[c].map(lambda x: str(x).split('.')[-1])\n    my_transaction[c + '_suffix'] = my_transaction[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    my_transaction.drop(c, axis=1, inplace=True)","893f1420":"# Kategorik degerlerin eksik degerlerini NONE ile doldurma \n# ve sonrasinda kategorik degiskeni Frekansi ile numerik hale getirme\ndef frekans(data,columns,n_label=\"NONE\"):\n    \n    for col in columns:\n        data[col].fillna(n_label,inplace=True)\n        fq_encode = data[col].value_counts(dropna=False).to_dict()   \n        data[col+\"_Fr\"] = data[col].map(fq_encode)\n        data=data.drop(col,axis=1)\n    return data","1c81002d":"M_columns = ['M1','M2','M3','M4','M5','M6','M7','M8','M9']\n\nmy_transaction=frekans(my_transaction,M_columns)","4366105a":"my_transaction.card4.replace('american express','other',inplace=True)\nmy_transaction.card4.replace('discover','other',inplace=True)\nmy_transaction=frekans(my_transaction,[\"card4\"],n_label=\"other\")","d91eda06":"my_transaction.card6.replace('debit or credit','debit',inplace=True)\nmy_transaction.card6.replace('charge card','debit',inplace=True)\nmy_transaction=frekans(my_transaction,[\"card6\"],n_label=\"debit\")","2f3ae0af":"object_columns_name=my_transaction.select_dtypes(include='object').columns","74dfcd1d":"my_transaction=frekans(my_transaction,['ProductCD'])","7f33823e":"mail_columns = ['P_emaildomain_bin','P_emaildomain_suffix','R_emaildomain_bin','R_emaildomain_suffix']\nmy_transaction=frekans(my_transaction,mail_columns)","cd91d792":"for i in my_transaction.columns:\n    my_transaction[i].value_counts(normalize=True)\n    print(i)\n    print(my_transaction[i].value_counts(normalize=True))\n    print ('\\n')","b5269962":"my_transaction = reduce_mem_usage(my_transaction)\nmy_transaction.shape","b71dea2c":"my_transaction.info()","27478389":"# Preprocess date column\nSTART_DATE = '2017-12-01'\nmy_transaction = my_transaction.rename(columns={'TransactionDT': 'TransactionDate'})\nstartdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\nmy_transaction['TransactionDate'] = my_transaction['TransactionDate'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n\n\nprint(my_transaction['TransactionDate'].head())\nprint(my_transaction['TransactionDate'].tail())","a974056e":"import seaborn as sns\nmy_transaction_TransactionAmt_Fraud=my_transaction[['isFraud','TransactionAmt']]\nfig, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(my_transaction_TransactionAmt_Fraud.corr(), ax=ax,linewidths=.5,annot=True)\nplt.show()","54903686":"# boxplot\nsns.boxplot(x=my_transaction['TransactionAmt']);","241d5b5e":"# boxplot da esik deger atama\nQ1=my_transaction['TransactionAmt'].quantile(0.25)\nQ3=my_transaction['TransactionAmt'].quantile(0.75)\nIQR=Q3-Q1\nmy_TransactionAmt_Alt_Sinir = Q1-2.5*IQR\nmy_TransactionAmt_Ust_Sinir = Q3 + 2.5*IQR\n\nQ1, Q3 , IQR,my_TransactionAmt_Alt_Sinir,my_TransactionAmt_Ust_Sinir","a6fd79f4":"# boxplot ile belirlenen aykiri degerlere erismek\naykiri_TF=(my_transaction['TransactionAmt']<my_TransactionAmt_Alt_Sinir)|(my_transaction['TransactionAmt']>my_TransactionAmt_Ust_Sinir)\nmy_transaction[aykiri_TF].index","cce7010c":"# baskilama ile ust deger sonrasi degerlere ust degeri, alt deger sonrasina ise alt degeri atama\ndef AykiriDegeriBaskila(deger):\n    \n    if deger > my_TransactionAmt_Ust_Sinir:\n       \n        deger=my_TransactionAmt_Ust_Sinir\n    elif deger < my_TransactionAmt_Alt_Sinir:\n       \n        deger=-my_TransactionAmt_Alt_Sinir\n    \n    return deger\n\nmy_transaction['TransactionAmt'] = my_transaction['TransactionAmt'].apply(lambda x: AykiriDegeriBaskila(x))","44499cbf":"# Hakanin kisim","fde47319":"import numpy as np\nimport pandas as pd\n\n\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\nimport seaborn as sns\n\nimport gc","ff598b53":"def PCA_(df, cols, prefix='PCA_', rand_seed=4):\n    pca = PCA(random_state=rand_seed)\n    pca.fit_transform(df[cols])\n    represent=np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)\n    print(represent)\n    n_components=0\n    for i in represent:\n        \n        n_components+=1\n        if i >=98:\n            print(\"n_components= \",n_components)\n            break\n            \n    pca = PCA(random_state=rand_seed,n_components=n_components)\n    principalComponents = pca.fit_transform(df[cols])\n    \n    principalDf = pd.DataFrame(principalComponents)\n\n    df.drop(cols, axis=1, inplace=True)\n\n    principalDf.rename(columns=lambda x: str(prefix)+str(x), inplace=True)\n\n    df = pd.concat([df, principalDf], axis=1)\n    print(pca.explained_variance_ratio_)\n    return df","173ea76f":"transaction_V = transaction.iloc[:,55:]","b876cb3b":"V_columns= transaction_V.columns\n\nfor col in V_columns:\n    transaction_V[col] = transaction_V[col].fillna((transaction_V[col].min() - 1))\n    transaction_V[col] = (minmax_scale(transaction_V[col], feature_range=(0,1)))\ntransaction_V=PCA_(transaction_V,V_columns,prefix='PCA_V_')","a217a923":"my_transaction.drop(['clusters_C','clusters_D'], axis=1, inplace=True)\nmy_transaction.head()","6b4df874":"print(len(my_transaction))","0efa8d19":"transaction_V.head()","6b1d02cb":"print(len(transaction_V))","168b0821":"transaction_V.info()","2fd79cfe":"sum_trans=pd.concat([my_transaction, transaction_V], axis=1)","52dccbcb":"del my_transaction","985de02c":"del transaction_V","aafbf82b":"sum_trans = reduce_mem_usage(sum_trans)","bdd45831":"sum_trans.head(100)","6e0cb429":"c_train_iden.head(100)","e462efb7":"final_data=pd.merge(left=sum_trans, right=c_train_iden, on='TransactionID', how='left')\nfinal_data.head(100)","47850e82":"final_data.tail(100)","7277ce26":"- Transaction ID, id_01. id_12 Nan deger yok.\n\nSayisal veriler\n\n- id_02, id_05, id_06, id_11, id_13, id_17 degerler benzemiyor, Nan az, ort ile doldurulabilir.\n- id_03, id_04, id_09, id_10 degerler birbirine benziyor, Nan+0 degerler %98 sini olusturuyor, Nan degerleri dagit.\n- id_07, id_08, id_21, id_22, id_24, id_25, id_26 %96'si Nan degerden olusuyor.\n- id_14, id_18 unique deger az, Nan deger fazla, nan degerleri dagit.\n- id_19, id_20  degerler (100-600 arasinda) birbirine benziyor,  Nan az, ort ile doldur.\n- id_32 Nan degerleri ort ile doldur, unique az.\n\nKategorik veriler\n\n- id_15, id_28, id_29, id_31, id_35, id_36, id_37, id_38, DeviceType Nan degerler az, mod ile doldur.\n- id_23,id_27 %96'si Nan degerden olusuyor.\n- id_16, id_30, id_33, id_34, DeviceInfo Nan degerler fazla, unique degerler az, dagit.","280bac22":"Yapilacaklar\n\nSayisal veriler\n\n- id_02, id_05, id_06, id_11, id_13, id_14,id_17,id_18 kendi icinde gruplandirarak unique degerleri azalt, kategorik degiskene cevirebildiklerini cevir.\n- id_03, id_04, id_09, id_10 degerler birbirine benziyor, PCA uygula.\n- id_07, id_08, id_21, id_22, id_24, id_25, id_26 sutunlarini at.\n- id_19, id_20 degerler birbirine benziyor, PCA uygula.\n- id_32 3 unique deger var, kategorik degiskene cevir.\n\nKategorik veriler\n\n- id_12, id_15, id_16, id_28, id_29, id_34, id_35, id_36, id_37, id_38, DeviceType sutunlari hazir.\n- id_23,id_27 sutunlarini at.\n- id_30, id_31, id_33, DeviceInfo kendi icinde gruplandirarak unique degerleri azalt.\n\ngrafikleri tekrar cizdirip karsilastir."}}