{"cell_type":{"a62d53f5":"code","3df8e58b":"code","e1b9aca3":"code","085b0e78":"code","f9558ec1":"code","c05cd6a0":"code","4f6602e7":"code","598e2a5b":"code","e7f2849c":"code","d565c0bf":"code","b32a3db7":"markdown","f014ae71":"markdown"},"source":{"a62d53f5":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.preprocessing import image\nimport os\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split as tts","3df8e58b":"train_path = '\/kaggle\/input\/petfinder-pawpularity-score\/train\/'","e1b9aca3":"data = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/train.csv\")","085b0e78":"d = [\"_size_1\", '_size_2', \"st_size\", \"format\", 'size']\nd = {i:[] for i in d}\ny = 0\nfor i in data[\"Id\"]:\n    img_path = os.path.join(train_path, i+\".jpg\")\n    x = os.stat(img_path)\n    file_pr = {k: getattr(x, k) for k in dir(x) if k in d}\n    for i in file_pr:\n        d[i].append(file_pr[i])\n    \n    img = image.load_img(img_path)\n    img_pr = img.__dict__\n    try:\n        _size_1, _size_2 = img_pr.get(\"_size\")\n    except:\n        print(img_pr.get(\"_size\"))\n    d[\"_size_1\"].append(_size_1)\n    d['_size_2'].append(_size_2)\n    d['size'].append(str(_size_1)+str(_size_2))\n    \n    if _size_1==_size_2:\n        fm =  \"sqr\"\n    elif _size_1<_size_2:\n        fm =  \"horiz\"\n    elif _size_1>_size_2:\n        fm =  \"vert\"\n    d[\"format\"].append(fm)    ","f9558ec1":"img_info = pd.DataFrame.from_dict(d)","c05cd6a0":"train = pd.concat([data, img_info], axis=1)","4f6602e7":"y = train['Pawpularity']\nX = train.drop([\"Pawpularity\", \"Id\"],axis=1)\nX_train, X_test, Y_train, Y_test = tts(X, y, test_size=0.2, random_state=2)","598e2a5b":"from catboost import CatBoostRegressor\n\nmodel = CatBoostRegressor(iterations=100000,\n#                           learning_rate=0.001,\n                          depth=3)\n# cat_features_ids = [\"Id\"]\nmodel.fit(X_train, Y_train,verbose=1, eval_set=[(X_test, Y_test)], early_stopping_rounds=1000, metric_period=1000, cat_features=['size', 'format'])\ny_pred = model.predict(X_test)\n# y_pred = y_pred.round()","e7f2849c":"plt.figure(figsize= (15, 15))\nsns.heatmap(train.corr(), annot=True, fmt='.1g' )\nplt.title('Correlation Matrix', fontweight='bold', fontsize=20)\nplt.show()","d565c0bf":"import shap\nshap.initjs()\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X)\nshap.summary_plot(shap_values, features=X, feature_names=X.columns)","b32a3db7":"# Conclusion\nAs we can see on the shap plot, the additional characteristics have a great impact on the model evaluation, and st_size, _size_1 and size exceed all the original metadata","f014ae71":"# Intro\nWhen we deal with photos, we usually hope to get all the necessary information from the image itself using CNN or other features, but in this contest I don't think this is the best way to get the maximum score, case, as many of us have noticet, that the photos do not represent a real Pawpularity score. So I'm trying to find proxy characteristics with high correlation with the target.\nIn this notebook, I extract the features that we lose when preparing photos for CNN, such as image size, height and weight."}}