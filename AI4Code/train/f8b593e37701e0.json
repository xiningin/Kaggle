{"cell_type":{"b3c1639d":"code","d0c39228":"code","cee7dfed":"code","db2a8f0d":"code","2b0434ec":"code","b79d4af5":"code","5ef1f32c":"code","e9788711":"code","4e2bbe75":"code","bc943feb":"code","3381c27c":"code","6ce0b4e8":"code","592a9882":"code","2e0395b1":"code","5e5d36a9":"code","3839c304":"code","f71c4b10":"code","81227869":"code","d4102eed":"code","a20820e1":"code","02f6dcfa":"markdown","99551666":"markdown","bfcb6c4d":"markdown","22371b1d":"markdown","198d4f21":"markdown","40cd8802":"markdown","f35a922b":"markdown","68639ecb":"markdown","31ffa827":"markdown","6f86d568":"markdown","01a132af":"markdown","bc336103":"markdown","8a89d98e":"markdown","7b82ab98":"markdown","f1cb9b7f":"markdown","a581b267":"markdown","e6842e42":"markdown","5434947e":"markdown","d93c9841":"markdown","840c1a5d":"markdown","5fa1be6f":"markdown","fd15e886":"markdown","8f874999":"markdown","ebc6ca6e":"markdown"},"source":{"b3c1639d":"# 2.1 Importing necessary libraries \n\nimport pandas as pd # Data manipulation \nimport numpy as np # lin. algebra\nimport seaborn as sns # Data visualization \nimport copy # Python copying\n# Set up matplot \n%matplotlib inline\nimport matplotlib.pyplot as plt # Data graph manipulation ","d0c39228":"# 2.2 Loading the data, cutting it down to only include Maryland. \n\nfull_raw_data = pd.read_csv('..\/input\/us-counties-covid-19-dataset\/us-counties.csv') # Keep the entire dataset in a variable... in case it is needed.\n                                                                         \nmaryland_raw_data = full_raw_data[full_raw_data.state == \"Maryland\"]","cee7dfed":"maryland_raw_data.head()","db2a8f0d":"maryland_raw_data.info()","2b0434ec":"# Total number of entries\ntotal_entries = len(maryland_raw_data.index) # Keep track of the number of total entries. \nprint(\"Total number of entries: %s\" % total_entries)\n\n# Total number of missing values from the fips category\ntotal_fips_null = maryland_raw_data['fips'].isna().sum()\nprint(\"Total missing values: %s\" % total_fips_null)\n\n# Thus... total valid entries\nprint(\"Total valid entries: %s\" % (total_entries - total_fips_null))\n\n# Let's compile a list of all the rows with missing values, and take a look at it\nmissing_value_rows = maryland_raw_data[maryland_raw_data.isnull().any(axis=1)]","b79d4af5":"missing_value_rows.head()","5ef1f32c":"maryland_raw_data = maryland_raw_data.dropna()\n# Verify it worked... check that the total length is = (total_entries - total_fips_null)\nprint(\"(New length):%s =? (total - null):%s\" % (len(maryland_raw_data), total_entries - total_fips_null))\nif len(maryland_raw_data) != (total_entries - total_fips_null):\n    # An error has occurred! Let's make it clear\n    print(\"Procedural error! Mistake handling missing values, total entries - removed missing values != length of new raw_data array\")\nelse:\n    print(\"Correct! Missing values removed!\")","e9788711":"maryland_data = maryland_raw_data.copy()\nmaryland_data.index = maryland_raw_data.date","4e2bbe75":"maryland_data.head()","bc943feb":"zero_case_set = maryland_data[maryland_data.cases == 0]\nprint(\"Any rows with zero cases...? :: %s\" % len(zero_case_set))\nif len(zero_case_set) == 0:\n    print(\"No rows with zero cases\")\nelse:\n    print(\"%s rows with zero cases\" % len(zero_case_set))","3381c27c":"# Let's get the first date present in the data by checking the first row.\nprint(maryland_data.iloc[0]['date'])\n\nfirst_date_string = maryland_data.iloc[0]['date']","6ce0b4e8":"# Define our date class...\nclass Date: \n    def __init__(self, date_string = \"\", year = None, month = None, day = None): # format for the date_string is \"yyyy-mm-dd\", dashes included!\n        if date_string != \"\":\n            self.year = int(date_string[:4])\n            self.month = int(date_string[5:7])\n            self.day = int(date_string[8:])\n        else:\n            self.year = year\n            self.month = month\n            self.day = day\n            \n        \n    def __str__(self):\n        return \"%s-%s-%s\" % (self.year, self.month, self.day)\n    \n    def __eq__(self, other):\n        y_b = self.year == other.year\n        m_b = self.month == other.month\n        d_b = self.day == other.day\n        \n        if y_b == False: \n            if m_b == False: \n                if d_b == False:\n                    return False\n        else:\n            return True\n    \n    def copy_add_year(self, amount):\n        self.year += amount\n        return Date(\"\", self.year, self.month,self.day)\n        \n    def copy_add_month(self, amount):\n        self.month += amount\n        return Date(\"\", self.year, self.month,self.day)\n    \n    def copy_add_day(self, amount):\n        self.day += amount\n        return Date(\"\", self.year, self.month,self.day)\n    \n    def return_raw_string(self):\n        if self.month < 10: \n            mangled_month = \"0\" + str(self.month)\n        else:\n            mangled_month = str(self.month)\n            \n        if self.day < 10: \n            mangled_day = \"0\" + str(self.day)\n        else:\n            mangled_day = str(self.day)\n            \n        return \"%s-%s-%s\" % (self.year, mangled_month, mangled_day)\n            \n        \nprint(type(maryland_data.iloc[0]['date'])) # Proof that the type is a string...\ntest_date = Date(maryland_data.iloc[0]['date'])\nprint(test_date) # Test that our date class is working\n\n# assign our first date\nfirst_date = Date(first_date_string)","592a9882":"# Let's figure out what the first month of cases looked like in Maryland\n# I'll provide a heatmap, as well as a bar graph of the first month of cases compared to the most recent data.\n\n\nfig = plt.figure(figsize=(7, 15)) # make a figure\nfirst_month_heat_ax = fig.add_subplot(2, 1, 1) # make a new axis. \nfirst_month_heat_ax.set_title(\"First Month\")\nbar_ax = fig.add_subplot(2, 1, 2) # make an axis for the barplot\nfinal_date = Date(maryland_data.iloc[len(maryland_data) - 1]['date'])\n\n# Heatmap creation technique: This covers one month in to the pandemic. \n\none_month_in_date = first_date.copy_add_month(1) \ntemp_data = maryland_data[maryland_data.date == one_month_in_date.return_raw_string()]\nfirst_month_cases_data = {'Counties' : temp_data['county'], 'Cases' : temp_data['cases']}\ntemp_data = maryland_data[maryland_data.date == final_date.return_raw_string()]\nlast_day_cases_data = {'Counties' : temp_data['county'], 'Cases' : temp_data['cases']}\nfirst_month_df = pd.DataFrame(first_month_cases_data)\nlast_day_df = pd.DataFrame(last_day_cases_data)\n\nfirst_month_df.index = first_month_df.Counties\nax_3 = sns.barplot(x='Cases', y='Counties', data=last_day_df, label=\"Last Day Values\", color='red', ax=bar_ax)\nax_2 = sns.barplot(x='Cases', y='Counties', data=first_month_df, label=\"First Month Values\", color='blue', ax=bar_ax) \n                                                                              #This comes first to avoid the mentioned error below\nplt.legend(title='Day')\n#bar_ax.legend(labels=['Last Day Values','First Month Values'])\nsns.despine(left=True, bottom=True)\n\ndel first_month_df['Counties'] # This needs to be deleted for the heatmap to work\nprint(first_month_df) # print our dataframe to see the exact numbers\n\nax_1 = sns.heatmap(data=first_month_df, ax=first_month_heat_ax)\nplt.tight_layout()\n","2e0395b1":"# We need to set the x-axis to be our dates and the y-axis to be our case numbers. To make things readable, we'll create a seperate line for each county. \nplt.figure(figsize=(32, 16))\ncounty_names = maryland_data.county.unique() # Get all of the different county names, to plot each county\ncounter = 0 # Prepare a counter variable, in order to print our progress\nfor county in county_names: \n    counter += 1 # Update our counter. 1 will be the first value\n    print(\"Processing: %s --> %s \/ %s\" % (county, counter, len(county_names))) # Print progress\n    temp_data = maryland_data[maryland_data.county == county] # get a subset of the data that ONLY INCLUDES THE CURRENT COUNTY\n    graph = sns.lineplot(x='date', y='cases', data=temp_data, err_style=\"bars\", label=county, legend=False) # plot the data for that county\n    \nplt.legend(loc='upper left') # place the legend, update it\nxticks = graph.xaxis.get_major_ticks()\ngraph = graph.set_xticklabels(temp_data['date'], rotation=90) # make sure the date values are rotated\ninital_i = 0\nfor i in range(len(xticks)):\n    if inital_i == i or inital_i + 4 == i :\n        xticks[i].set_visible(True)\n        inital_i = i\n    else:\n        xticks[i].set_visible(False)","5e5d36a9":"#  Calculate instaneous derivatives for each county's cases on different dates. \n\nplt.figure(figsize=(32, 16)) # Prepare our plot... size it so it's readable\n\n\nfrom numpy import diff # Import a function to help us calculate the derivative \ndx = 1.0 # The change on the x axis will be ONE DAY (the meaning of 1.0). Thus, dy\/dx will be dy change for each DAY. \ncounter = 0 # Prepare a counter variable, in order to print our progress\nfor county in county_names: \n    counter += 1 # Update our counter. 1 will be the first value\n    print(\"Processing: %s --> %s \/ %s\" % (county, counter, len(county_names))) # Print progress\n    temp_data = maryland_data[maryland_data.county == county] # get a subset of the data that ONLY INCLUDES THE CURRENT COUNTY, this will be our y.\n    y = temp_data['cases'].tolist() # Convert our cases to a list so the numpy.diff function will work\n    dy = diff(y) \/ dx # REMEMBER, when we're calculating derivates simply by taking differences, the last value in the data will NOT BE INCLUDED\n    #  This is handled below... in the graphing function. y = derivative of the cases, and the data includes all values but the last. \n    graph = sns.lineplot(x='date', y=dy, data=temp_data[:len(temp_data.index) - 1], err_style=\"bars\", label=county, legend=False) # plot the data for that county\n\nplt.legend(loc='upper left') # place the legend, update it\nxticks = graph.xaxis.get_major_ticks()\ngraph = graph.set_xticklabels(temp_data['date'], rotation=90) # make sure the date values are rotated\n\ninital_i = 0\nfor i in range(len(xticks)):\n    if inital_i == i or inital_i + 4 == i :\n        xticks[i].set_visible(True)\n        inital_i = i\n    else:\n        xticks[i].set_visible(False)\n    \n\nplt.show()","3839c304":"#### IMPORTANT !!! #####\nderivative_smoothed_graphs = [] # List to hold each derivative smoothed graph. \nsmoothed_d_graph = None # Variable to hold each respective graph\n#  Method 1, average all 7 days' values.\n\nplt.figure(figsize=(32, 16)) # Prepare our plot... size it so it's readable\n\n### DECLARE VARIABLES ###\n\ncounter = 0 # reset our counter (for printing progress) to zero. \naveraged_derivatives_cases_dataframes = [] # create a list of dataframes for the derivative data, averaged, from each county.\naveraged_derivatives_cases_dataframe = None # create a dataframe for ALL the derivative data, averaged, to be sorted by date (not county)\n\n### ###\n\n### PROCESS DERIVATIVES AND AVERAGES### \nfor county in county_names: # For each county...\n    counter += 1 # Update our counter. 1 will be the first value\n    \n    method_counter = 0 # Variable to help us keep track of our every 7 days averaging requirement \n    dy_averaged = [] # list of derivatives, averaged for 7 days.\n    averaged_dates = [] # list of every 7 days. \n    continous_average = 0 # The average of the past 7 days (with the exception of the FIRST entry)\n    average_denominator = 1 # The denominator for the average calculation. Set to 1 for the first entry\n    \n    print(\"Processing Derivative: %s --> %s \/ %s\" % (county, counter, len(county_names))) # Print progress\n\n    \n    temp_data = maryland_data[maryland_data.county == county] # get a subset of the data that ONLY INCLUDES THE CURRENT COUNTY, this will be our y.\n    y = temp_data['cases'].tolist() # Convert our cases to a list so the numpy.diff function will work\n    dy = diff(y) \/ dx # REMEMBER, when we're calculating derivates simply by taking differences, the last value in the data will NOT BE INCLUDED\n    \n    for i in range(len(dy)): # for each day and each derivative\n        if method_counter == 0: # if we're on the first value, or the start of a week...\n            continous_average = sum(dy[:(i+1)]) \/ (i + 1) # calculate the average\n            dy_averaged.append(continous_average) # append the current average \n            averaged_dates.append(temp_data.iloc[i]['date']) # append the current date so that the average is tracked\n            method_counter += 1 # Next day!\n        elif method_counter == 6: # Last day of the week, reset to zero so the first day of the NEXT week is recorded\n            method_counter = 0 \n        else: # Next day... next day... etc.\n            method_counter += 1\n            \n    \n    df = pd.DataFrame({'date' : averaged_dates, 'averaged derivatives of cases' : dy_averaged, 'county' : [\n        county for c in range(len(averaged_dates))\n    ]}) # Create a dataframe to hold all our dates, and all the averaged derivatives for EACH couonty\n    df.index = df.date # set the index to date\n    averaged_derivatives_cases_dataframes.append(df) # Append it to our list\n\n### ###\n\n### MERGE DATAFRAMES ###\n    \nprint(\"Progress: Merging county derivative data\")\naveraged_derivatives_cases_dataframe = pd.concat(averaged_derivatives_cases_dataframes, axis=0) # conc. all the different counties' data. \naveraged_derivatives_cases_dataframe.index = averaged_derivatives_cases_dataframe['date'] # set the index (be sure the index is correct)\n\naveraged_derivatives_cases_dataframe['date'] = pd.to_datetime(averaged_derivatives_cases_dataframe.date) # convert the date to datetime, so we can sort\naveraged_derivatives_cases_dataframe.sort_index() # sort based on the datetime index\n\n### ###\n\n### GRAPH EVERYTHING! ###\n\ncounter = 0\nfor county in county_names:\n    counter += 1 # Update our counter. 1 will be the first value\n    \n    print(\"Processing: %s --> %s \/ %s\" % (county, counter, len(county_names))) # Print progress\n    temp_data = averaged_derivatives_cases_dataframe[averaged_derivatives_cases_dataframe.county == county] # get a subset of the data that \n        #  ONLY INCLUDES THE CURRENT COUNTY\n        \n    smoothed_d_graph = sns.lineplot(x='date', y='averaged derivatives of cases', data=temp_data, err_style=\"bars\", label=county, legend='full') # plot the data for that \n        #  county\n### ###\n\nderivative_smoothed_graphs.append(smoothed_d_graph) # Add the final version of the graph to the list for plotting later\nplt.legend(loc='upper left') # place the legend, update it\n","f71c4b10":"#  Method 2, pick the median value for all 7 days of the week.\n\nfrom statistics import median\nplt.figure(figsize=(32, 16)) # Prepare our plot... size it so it's readable\n\n### DECLARE VARIABLES ###\n\ncounter = 0 # reset our counter (for printing progress) to zero. \nmedian_derivatives_cases_dataframes = [] # create a list of dataframes for the derivative data, median, from each county.\nmedian_derivatives_cases_dataframe = None # create a dataframe for ALL the derivative data, median, to be sorted by date (not county)\n\n### ###\n\n### PROCESS DERIVATIVES AND MEDIAN ### \nfor county in county_names: # For each county...\n    counter += 1 # Update our counter. 1 will be the first value\n    \n    method_counter = 0 # Variable to help us keep track of our every 7 days median requirement \n    dy_median = [] # list of derivatives, median for 7 days.\n    median_dates = [] # list of every 7 days. \n    continous_median = 0 # The median of the past 7 days (with the exception of the FIRST entry)\n    \n    print(\"Processing Derivative: %s --> %s \/ %s\" % (county, counter, len(county_names))) # Print progress\n\n    \n    temp_data = maryland_data[maryland_data.county == county] # get a subset of the data that ONLY INCLUDES THE CURRENT COUNTY, this will be our y.\n    y = temp_data['cases'].tolist() # Convert our cases to a list so the numpy.diff function will work\n    dy = diff(y) \/ dx # REMEMBER, when we're calculating derivates simply by taking differences, the last value in the data will NOT BE INCLUDED\n    \n    for i in range(len(dy)): # for each day and each derivative\n        if method_counter == 0: # if we're on the first value, or the start of a week...\n            continous_median = median(dy[:(i+1)]) # calculate the median\n            dy_median.append(continous_median) # append the current median \n            median_dates.append(temp_data.iloc[i]['date']) # append the current date so that the median is tracked\n            method_counter += 1 # Next day!\n        elif method_counter == 6: # Last day of the week, reset to zero so the first day of the NEXT week is recorded\n            method_counter = 0 \n        else: # Next day... next day... etc.\n            method_counter += 1\n            \n    \n    df = pd.DataFrame({'date' : median_dates, 'median derivatives of cases' : dy_median, 'county' : [\n        county for c in range(len(median_dates))\n    ]}) # Create a dataframe to hold all our dates, and all the median derivatives for EACH couonty\n    df.index = df.date # set the index to date\n    median_derivatives_cases_dataframes.append(df) # Append it to our list\n\n### ###\n\n### MERGE DATAFRAMES ###\n    \nprint(\"Progress: Merging county derivative data\")\nmedian_derivatives_cases_dataframe = pd.concat(median_derivatives_cases_dataframes, axis=0) # conc. all the different counties' data. \nmedian_derivatives_cases_dataframe.index = median_derivatives_cases_dataframe['date'] # set the index (be sure the index is correct)\n\nmedian_derivatives_cases_dataframe['date'] = pd.to_datetime(median_derivatives_cases_dataframe.date) # convert the date to datetime, so we can sort\nmedian_derivatives_cases_dataframe.sort_index() # sort based on the datetime index\n\n### ###\n\n### GRAPH EVERYTHING! ###\n\ncounter = 0\nfor county in county_names:\n    counter += 1 # Update our counter. 1 will be the first value\n    \n    print(\"Processing: %s --> %s \/ %s\" % (county, counter, len(county_names))) # Print progress\n    temp_data = median_derivatives_cases_dataframe[median_derivatives_cases_dataframe.county == county] # get a subset of the data that \n        #  ONLY INCLUDES THE CURRENT COUNTY\n        \n    smoothed_d_graph = sns.lineplot(x='date', y='median derivatives of cases', data=temp_data, err_style=\"bars\", label=county, legend='full') # plot the data for that \n        #  county\n### ###\n\nderivative_smoothed_graphs.append(smoothed_d_graph) # Add the final version of the graph to the list in case it's needed\nplt.legend(loc='upper left') # place the legend, update it\n","81227869":"fig_avg, ax_avg = plt.subplots()\nfig_avg = plt.gcf()\nfig_avg.set_size_inches(32, 16)\n# Method 1\nfor county in county_names:    \n    temp_data = median_derivatives_cases_dataframe[median_derivatives_cases_dataframe.county == county] # get a subset of the data that \n        #  ONLY INCLUDES THE CURRENT COUNTY\n    temp_graph = sns.lineplot(x='date', y='median derivatives of cases', data=temp_data, err_style=\"bars\", \n                              ax=ax_avg, \n                              label=county, legend='full').set_title(\"Averaged Instaneous Derivatives for Cases (Every 7 days)\")# plot the data for that county\n        \n##\nfig_med, ax_med = plt.subplots()\nfig_med = plt.gcf()\nfig_med.set_size_inches(32, 16)## \n# Method 2\nfor county in county_names:    \n    temp_data = averaged_derivatives_cases_dataframe[averaged_derivatives_cases_dataframe.county == county] # get a subset of the data that \n        #  ONLY INCLUDES THE CURRENT COUNTY\n    temp_graph = sns.lineplot(x='date', y='averaged derivatives of cases', data=temp_data, err_style=\"bars\", \n                              ax=ax_med, \n                              label=county, legend='full').set_title(\"Median Instaneous Derivatives for Cases (Every 7 days)\") # plot the data for that county\nplt.legend(loc='upper left') # place the legend, update it\n","d4102eed":"fig = plt.figure(figsize=(15, 15))\ncases_ax = fig.add_subplot(1, 2, 1)\ndeaths_ax = fig.add_subplot(1, 2, 2)\n\nfinal_date = maryland_data.iloc[len(maryland_data) - 1]['date']\nprint(\"Final date in the dataset is: %s\" % final_date)\n\ntemp_data = maryland_data[maryland_data.date == final_date]\ncases_data = {'Counties' : temp_data['county'], 'Cases' : temp_data['cases']}\ndeaths_data = {'Counties' : temp_data['county'], 'Deaths' : temp_data['deaths']}\n\ncases_df = pd.DataFrame(cases_data)\ncases_df.index = cases_df.Counties\ndel cases_df['Counties']\ndeaths_df = pd.DataFrame(deaths_data)\ndeaths_df.index = deaths_df.Counties\ndel deaths_df['Counties']\n\nax_1 = sns.heatmap(data=cases_df, ax=cases_ax)\nax_2 = sns.heatmap(data=deaths_df, ax=deaths_ax)\nplt.tight_layout()","a20820e1":"fig = plt.figure(figsize=(30, 30))\ngraphs = [] # Hold our heatmaps\nmonths_axs = [] # Hold matplotlib axes\ndframes = [] # Hold each temporary dataframe\n\n# How many \"1st's\" are in the dataset? April 1st, May 1st, June 1st... etc.\nnum_months = 0\ncleared_months = []\nfor entry in maryland_data.iloc:\n    loop_date = Date(entry.date) # The date we're looping with \n    if loop_date.day == 1 and not (loop_date.year, loop_date.month, loop_date.day) in cleared_months: # If this is the first datapoint of that month\n        cleared_months.append((loop_date.year, loop_date.month, loop_date.day)) # Add the date\n        num_months += 1 # increment the number of months\n\n# Create axes (cleaner to seperate this from the following loop)\n\ncols = 0 # Number of cols for our graph to have\nrows = 0 # Number of rows for our graph to have\nremainder = num_months % 2 # Are we working with an even or odd number? remainder = 1 if odd, 0 if even\nif remainder == 0:\n    cols = num_months \/ 2\n    rows = num_months \/ cols \nelif remainder == 1:\n    cols = ((num_months - 1) \/ 2) + 1\n    rows = num_months \/ cols\nelse:\n    print(\"Error: remainder is not 1 or 0.\")\n    \nfor i in range(0, num_months): # For each month\n    splot = fig.add_subplot(int(rows), int(cols), i + 1) # Add an axis\n    splot.set_title(\"Month: %s\" % (i + 1)) # Make unique titles for each plot to be clearly seperated\n    months_axs.append(splot)\n\n# For each number 1 date\nfor i in range(0, num_months):\n    loop_date = Date(\"\", cleared_months[i][0], cleared_months[i][1], cleared_months[i][2])\n    print(\"Processing: %s\" % loop_date)\n    temp_data = maryland_data[maryland_data.date == loop_date.return_raw_string()] # Get all dates with the loop date\n    temp_data = {'Counties' : temp_data['county'], 'Cases' : temp_data['cases']} # Make a new neater dataframe\n    temp_df = pd.DataFrame(temp_data) # ... see above\n    \n    temp_df.index = temp_df.Counties # reset the index, date is not needed here.\n    del temp_df['Counties'] # Get rid of the extra column. \n    dframes.append(temp_df)\n    gr = sns.heatmap(data=dframes[i], ax=months_axs[i]) # make our graph, use a new axis and dataframe each time\n    graphs.append(gr) # append it for safekeeping\n\n\nplt.tight_layout() # Adjust the layout of our graph to be tight and neat. ","02f6dcfa":"***Important Note about the data: ***\n\nThe us-counties-covid-19-dataset provided by the New York Times tracks *cumulative* case\/death counts, not cases at a given moment.","99551666":"Alright now that we've taken care of that, we've got only one last step remaining... handling missing values. Let's head our data, and determine what we've got, and what it looks like.","bfcb6c4d":"# Table of Contents\n\n1. Introduction\n2. Data Manipulation\/Code Setup\n3. Visualizations \n4. Visualiations -- At a Glance \n5. Concluding Note","22371b1d":"Next, why don't we take a look at every single month for COVID-19 so far. We'll start with April 1st (as the data doesn't reliably have all counties until then), then May 1st, etc. etc. \n\nThis is a more heartfelt way of tracking progression over time. ","198d4f21":"**Latest Update Section:**\nThis section describes the latest updates to the document: Starting 1\/05\/2021\n\nUpdated 1\/05\/2021: Adding a number of new heatmap visualizations. Updated conclusions. Added images\n\nUpdated 1\/12\/2021: Fixed a number of mistakes in wording and conclusions. \n\nUpdated 1\/17\/2021: Added clarification regarding the dataset, changed goals, fixed a mistake removing Washington county from the data. **Predictions will be done in a seperate notebook due to current resources used by this notebook**. This requires extra data and research, whereas this notebook serves as the introduction to the next.\n\nFurther updates: Further updates will include merely updating the dataset for the most updated picture of the spread. This notebook is purely the **visualization** of COVID-19 in Maryland. The predictions are being split into a second notebook to both segment the project into two parts, and improve the running speed of the notebook for editing. It will use the dataset discoverable [here](https:\/\/www.kaggle.com\/binarydragon\/median-household-income-maryland-2018) as well as the us-counties-covid-19 dataset already in use.\n\nThe predictions notebook will be discoverable soon at: *link* WIP","40cd8802":"**Heat Map:**\n\nA heat map is presented below for a county by county analysis of cases, as well as deaths, for the most recent day in the dataset. ","f35a922b":"It's already quite clear then, that *not all values are null, or zero, if the **fips** value is null*. Some of the rows with missing fips values include case numbers as well, and death numbers, it's just that the counties are unknown. This data will be held, and kept, in case it's needed for further analysis at a later date... though, for now, it will be removed from the dataset over all (as this data will not aid in a county-by-county analysis). ","68639ecb":"Interesting... considering that this dataset might be updated, we're going to save our total number of entries into a variable, and extract information from there. Though it's already clear that only fips contains missing values (note this may mean other fields will be invalid... if fips is missing, county is likely missing... as an example), as all the other columns are at the max number of entries, as of the most recent update. As such, for the purposes of the analyses in this notebook, **it will be assumed that the number of missing entries is equivalent to the number of missing fips values**. ","31ffa827":"Eek... this is a little messy. Seeing as the data varies so much, the derivatives are all over the place. What we're really hoping to see are negative derivatives, as then the case numbers would be decreasing.... but sadly we're not seeing enough of them to really be able to claim that it's not necessairly an error in the data. Let's see if we can try to *smooth* the derivatves so we can see a clear trend in the derivatives over time. \n\nThere are a couple different methods we can apply to try and smooth our data. Here are the ones we'll apply, and the each one will be presented at the bottom for conculsions. **As such, the code to create each one, and the output, will be hidden, though can be viewed by clicking the code button below**. \n\n*We will be applying our smoothing for 7 days... so each week will have the same values depending on the smoothing technique.*\n\n1. Average the values for all 7 days of the week. (Derivatives!) \n2. Pick the median value for all 7 days of the week. (Derivatives!)","6f86d568":"Let's plot the instaneous derivatives (the rate of change from day to day) of the case values, by county, for each day in the dataset. ","01a132af":"# 2. Data Manipulation\/Code Setup\n\nBelow we'll be importing the libraries we need for our work, as well doing preliminary data manipulation. In short, this section will be broken down as follows...\n\n1. Importing necessary libraries\n2. Cutting our data down to only include Maryland counties\n3. Checking for missing values, handling them. ","bc336103":"*One more thing, the tpye of the values in the date column are strings, despite being dates. So, to make extraction easier (as they follow a common format... yyyy-mm-dd), we'll define a date class to use, personalized for our uses. To keep this notebook to the essentials, it's defined in a hidden code cell below, as well as the proof of the type.*","8a89d98e":"Next question, do we have county data for each data? \nAh... questions could be brought up, and answered, again and again when we're only working with text data. Let's map out each county's cases over time. Note, that there are not entries for all counties until the beginning of April, which is where the graphs will begin (as... again, there are not data for each county). ","7b82ab98":"# 4. Visualizations -- At a Glance\n\nThe following section will present more visualizations by county so that the spread of this disease, county by county, can be better analyzed. In other words, this section is to *visualize* the change in COVID-19 cases quickly for easy reading. Heat Graphs, in my opinion, are more effective at giving an \"at a glance\" view of data.","f1cb9b7f":"Great! So we've handled missing variables! Now we've got just the pure data we want to analyze. Let's go ahead and make a copy of our data, and call it our official data *\\\"maryland_data\\\"*. \n\nWell, I spoke too soon. For ease of use in visualizations, this isn't a pure copy, as we'll be changing the index, or the value used to keep track of all the data in a list, into the dates. \n\n***As such, when a numerical index is needed, maryland_raw_data will be used, but maryland_data will be used for date indexes*** ","a581b267":"# 3. Visualizations\n\nHere we are! Finally time to take a look at the data we've got, and understand the spread of this disease, county by county. Let's head the data one more time, and take a look at the first few entries.","e6842e42":"![image.png](attachment:image.png)","5434947e":"# COVID-19 County Breakdown -- Maryland\n\nThis project is meant to provide an accurate picture of the progression of COVID-19 cases in Maryland, US. I hope this information is found to be useful and informative! This is my second notebook so far, so please note that some of my approaches may be weaker than professional data scientists and feel free to leave comemnts on how to improve! ","d93c9841":"To explain the above graph, this presents a county-by-county presentation of the cases and deaths in Maryland on the latest day of data, with a color scale (lighter being greater numbers) to show current numbers.","840c1a5d":"It would seem as if the very first entries for Maryland began after cases were officially detected. Let's verify this, and check if there were ever zero cases recorded. ","5fa1be6f":"# 1. Introduction\n\nTo begin this project, we must first lay out our goals. This is not for a competition, and this is not following some set guideline(s) for data exploration. Instead, this notebook will set its own goals for exploration, with the hope of building a basis for later work to be built upon, or learned from. The COVID situation is continually evolving and, as such, this notebook will reflect that. Periodic updates may be applied to conclusions and predictions based on updates to the data from which said predictions are made. \n\nTherefore, to begin, let's lay out our goals, and a few important notes.\n    \n*Note 1:*\n    \nThis *particular* notebook will be focused on the US State of Maryland, only, for the time being. This same level of analysis may be expanded to other states as well, time permitting. \n\n*Note 2:*\n\nDue to the uncertainity of wide-spread testing in the United States, including the state of Maryland, these numbers may not be wholly accurate, or present the entire situation.\n\n**Goal 1:** \n\nThe data in the input category covers a date of entry, county, state, cases, and deaths. Namely, the \"us-counties.csv\" file. This data is enough to visualize the progression of COVID-19 in Maryland. As such, our first goal will be to map out the progression of COVID-19 in Maryland, county by county.","fd15e886":"That presents a bit of a problem, as it becomes a little more difficult, now, to track the spread of the virus across Maryland. If recording started so late, then it's likely it did in other counties as well, meaning tracking how the disease entered the state is much much more difficult. \n\n**Q: What did Maryland look like at the beginning of the pandemic?**\n\nPlease note the data is arranged chronologically.","8f874999":"What we've done seems to have worked, and we've narrowed it down to only Maryland entries. But... as it is our job to deal with missing values, let's try and figure out how many missing values we have for each column.","ebc6ca6e":"# Conclusion\n\nWhile this is not a grand work, and while it only pertains to one state of 50 in the US, this notebook is meant to give viewers a little picture of the way the virus is proceeding in Maryland. \n\nThank you for your time! I sincerly hope this project is helpful! \nAs this is only my second notebook, any comments you may have would be a wonderful help below!"}}