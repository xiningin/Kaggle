{"cell_type":{"f0657a7b":"code","476455bf":"code","2334a5a2":"code","126e3b1a":"code","8bc300ca":"code","f1178afc":"code","5b8e1cbb":"code","e611e7e2":"code","8cebfedb":"code","73d36930":"code","3e8b771a":"code","19881fdb":"code","7140d413":"code","913bf34e":"code","b52678bf":"code","29dae4dc":"code","d66b8649":"code","92805e75":"code","a3c19a31":"code","1b622a91":"code","d8bf9118":"code","566e8813":"code","1784e195":"code","66b6a7fb":"code","5ab89109":"code","ce583ba6":"code","a9e544f8":"code","5c179f96":"code","84ed0489":"code","0e63489b":"code","fac6ffdd":"code","dca6a35b":"code","e09e12ae":"code","c30b1cc3":"code","dfd9931d":"code","7ee291ee":"markdown","17818456":"markdown","12cd2f72":"markdown","1f34dbae":"markdown","0885eca7":"markdown","46350221":"markdown","43007799":"markdown","f671d6bf":"markdown","edb61600":"markdown","e55f72a5":"markdown","abdbd93e":"markdown","88c8a216":"markdown","34b4990f":"markdown","fc92ddce":"markdown","27d18cda":"markdown","6323913e":"markdown","af8a3f44":"markdown","939268fd":"markdown","a51476ee":"markdown"},"source":{"f0657a7b":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","476455bf":"# Load and peek training data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanicdata\/train.csv\")\ntrain_data.head()","2334a5a2":"# Get some information about training data\ntrain_data.info()","126e3b1a":"test_data = pd.read_csv(\"\/kaggle\/input\/titanicdata\/test.csv\")\ntest_data.head()","8bc300ca":"test_data.info()","f1178afc":"# Concatenate the two data sets to create a big dataset. This will be useful to process data\ndataset =  pd.concat(objs=[train_data, test_data], axis=0).reset_index(drop=True)\ndataset.info()","5b8e1cbb":"# Looking for missing data on train dataset\nplt.pcolor(train_data.isnull())\nplt.xticks(np.arange(0.0, len(train_data.columns), 1), train_data.columns, rotation='vertical')\nplt.show()","e611e7e2":"# Looking for missing data on train dataset\nplt.pcolor(dataset.isnull())\nplt.xticks(np.arange(0.0, len(dataset.columns), 1), dataset.columns, rotation='vertical')\nplt.show()","8cebfedb":"# Correlation between survived and other data\nnumerical_features = [\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]\nplt.pcolor(dataset[numerical_features].corr(), cmap='plasma')\nplt.xticks(np.arange(0, 5), numerical_features, rotation='vertical')\nplt.yticks(np.arange(0, 5), numerical_features)\nplt.colorbar()\nplt.show()","73d36930":"# Split the data of people who survived and not survived to further analysis\nsurvived_data = dataset[dataset['Survived'] == 1.0]\nnot_survived_data = dataset[dataset['Survived'] == 0.0]","3e8b771a":"# Plot histogram with the age distributions of people who survived or not\nfig, axes = plt.subplots(1,2, figsize=(15,5))\naxes[0].hist(not_survived_data['Age'], bins=10)\naxes[0].set(title='Age of people who NOT survived');\naxes[0].set_ylim(0,120);\n\naxes[1].hist(survived_data['Age'], bins=10)\naxes[1].set(title='Age of people who survived');\naxes[1].set_ylim(0,120);\n\nplt.subplots_adjust(wspace=0.2, hspace=0)","19881fdb":"# Explore the Age vs Survived features in a grid view\nfig = sns.FacetGrid(train_data, hue = 'Survived', aspect = 4)\nfig.map(sns.kdeplot, 'Age' , shade = True)\nfig.set(xlim = (0, dataset['Age'].max()))\nfig.add_legend()","7140d413":"# Explore the Age vs Passengers class features\nfacet = sns.FacetGrid(dataset, hue=\"Pclass\", aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, dataset['Age'].max()))\nfacet.add_legend()\nplt.show()","913bf34e":"# Explore the Age vs Passengers class features using boxplot \nPA = sns.catplot(data = dataset , x = 'Pclass' , y = 'Age', kind = 'box')","b52678bf":"# Filling missing data on age with average of PClass\n# using a custom function for age imputation\ndef AgeImpute(df):\n    Age = df[0]\n    Pclass = df[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1: return 37\n        elif Pclass == 2: return 29\n        else: return 24\n    else:\n        return Age\n\n# Age Impute\ndataset['Age'] = dataset[['Age' , 'Pclass']].apply(AgeImpute, axis = 1)","29dae4dc":"# Looking for missing data on train dataset\nplt.pcolor(dataset.isnull())\nplt.xticks(np.arange(0.0, len(dataset.columns), 1), dataset.columns, rotation='vertical')\nplt.show()","d66b8649":"dataset[\"Fare\"].isnull().sum()","92805e75":"dataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())","a3c19a31":"# Reviewing missing data on full dataset\nplt.pcolor(dataset.isnull())\nplt.xticks(np.arange(0.0, len(dataset.columns), 1), dataset.columns, rotation='vertical')\nplt.show()","1b622a91":"dataset.head()","d8bf9118":"# 'Embarked' vs 'Survived'\nsns.barplot(dataset['Embarked'], dataset['Survived']);\n","566e8813":"dataset[\"Embarked\"].value_counts()","1784e195":"dataset[\"Embarked\"].isnull().sum()","66b6a7fb":"# Count missing values\nprint(dataset[\"Embarked\"].isnull().sum()) # 2\n\n# Fill Embarked nan values of dataset set with 'S' most frequent value\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")","5ab89109":"# Use one hot encoding to transform \"Embarked\" into values\nembarked = pd.get_dummies(dataset['Embarked'], drop_first = True)\ndataset = pd.concat([dataset,embarked], axis = 1)\n\n# We can drop the non-numerical feature now\ndataset.drop(['Embarked'] , axis = 1 , inplace = True)","ce583ba6":"# Convert Sex column into categorical value 0 for male and 1 for female\nsex = pd.get_dummies(dataset['Sex'], drop_first = True)\ndataset = pd.concat([dataset,sex], axis = 1)\n\n# After now, we really don't need to Sex features, we can drop it.\ndataset.drop(['Sex'] , axis = 1 , inplace = True)\ndataset.head()","a9e544f8":"# using Countplot to estimate amount of people who survived related to the sex\nsns.countplot(data = train_data , x = 'Survived' , hue = 'Sex')\n","5c179f96":"# Let's see the percentage\ntrain_data[[\"Sex\",\"Survived\"]].groupby('Sex').mean()\n","84ed0489":"# Reviewing missing data on full dataset\nplt.pcolor(dataset.isnull())\nplt.xticks(np.arange(0.0, len(dataset.columns), 1), dataset.columns, rotation='vertical')\nplt.show()","0e63489b":"dataset.head()","fac6ffdd":"# Split train and test data again\ntrain_data = dataset[0:891][:]\ntrain_data['Survived'] = train_data['Survived'].astype(int)","dca6a35b":"test_data.tail()","e09e12ae":"test_data = dataset[891:][:]\ntest_data = test_data.drop('Survived', axis=1)","c30b1cc3":"from sklearn.ensemble import RandomForestClassifier\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"male\", \"Q\", \"S\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.head()","dfd9931d":"output.to_csv('titanic_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","7ee291ee":"Now we only need to address \"Embarked\" to make it become a numeric value ","17818456":"* We saw that fare has a considerable correlation with tickets fare. The more expensive the ticket, better the class that this passenger will travel\n* Lets try to explore the age vs passagenger class now","12cd2f72":" **MISSING VALUES ON CATEGORICAL FEATURES**","1f34dbae":"Understanding relationship between Embarked column and survival rate","0885eca7":"* Most people who survived were something between 20 and 30 years old","46350221":"# Handling missing data","43007799":"**MISSING VALUES ON NUMERICAL FEATURES**","f671d6bf":"* Age distributions are not the same in the survived and not survived subpopulations\n* Old passengers survived less","edb61600":"* 1st class passengers are older than 2nd class passengers\n* 2nd class passengers are older than 3rd class passengers\n* There are more young people in 3rd class 3\n* There are more aged passengers in 1st class\n* +- 37, 29, 24 respectively are the median values for age of each class\n* We can use the median age of similar rows to fill missing values for age","e55f72a5":"**Searching for a good way to fill AGE missing values**","abdbd93e":"# Training the model","88c8a216":"**Searching for a good way to fill FARE missing values**","34b4990f":"1. **Understanding relationship between \"Sex\" column and survival rate**","fc92ddce":"* Fare seems to have a significative correlation with the survival probability.\n* In fact, fare seems to be correlated with all other numeric features","27d18cda":"Fare has only one missing value - we can fill it with the median","6323913e":"* PassengerId: Unique identification of the passenger. It shouldn't be necessary for the machine learning model.\n* Survived: Survival (0 = No, 1 = Yes). Binary variable that will be our target variable.\n* Pclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd).\n* Name: Name of the passenger. We need to parse before using it.\n* Sex: Gender Categorical variable that should be encoded. We can use dummy -variable to encode it.\n* Age: Age in years.\n* SibSp: # of siblings or spouses aboard the Titanic.\n* Parch: Parents \/ Children aboard the Titanic.\n* Ticket: Ticket number\n* Fare: Ticket fare\n* Cabin: Cabin number\n* Embarked: Port of Embarkation , C = Cherbourg, Q = Queenstown, S = Southampton. ","af8a3f44":"* We have to predict the value for \"Survived\" column\n* **This is a binary classification problem**\n","939268fd":"It is clearly obvious that Female survived more. This is very an important feature for our prediction task.","a51476ee":"This notebook is based on tutorial available on\nhttps:\/\/www.codementor.io\/@innat_2k14\/titanic-kaggle-machine-learning-from-disaster-part-1-10gbvqzguc"}}