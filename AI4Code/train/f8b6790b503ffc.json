{"cell_type":{"424bde30":"code","0893aee7":"code","b8fffa54":"code","627aff85":"code","51e844a0":"code","c39f0e56":"code","d90f7322":"code","9ba4bc1c":"code","11b3201d":"code","76f7dad3":"code","76ea3dd0":"code","024fb16d":"code","e5fa9d8f":"code","6cfb8bd4":"code","680e7a5d":"code","5491f44a":"code","6c525096":"code","277850de":"code","3022eee6":"code","de441d98":"code","29fcb178":"code","a990fdc0":"code","4519d11d":"code","66dc8706":"code","890d1902":"code","37211146":"code","05ffd725":"code","a5517aaf":"code","4973a441":"code","258db341":"code","cf7ccb22":"code","8f5996e0":"code","bde07d8e":"code","38e9065c":"code","7b0fa955":"code","a920bce2":"code","9e5e5ee4":"code","41cfc6dd":"code","882c9e29":"code","06284501":"code","a9a818dc":"code","5378960f":"code","237d4d04":"code","6beddd99":"code","0403ab0c":"code","ad35fc35":"code","f7a289d3":"code","e7f76931":"code","a7698c14":"code","d3ddaab8":"code","3360768d":"code","c2c2b258":"code","84732db1":"code","ccc85f67":"code","ad5f6a9f":"code","769ff17e":"code","a7a07e10":"code","d4c75fd9":"code","053eb89e":"code","6d751cc2":"code","6308575b":"code","001aa464":"code","9ea41e2a":"code","01100dce":"code","95500de2":"code","cefd22fa":"code","35945ae8":"code","42b5aa6b":"code","3803cca2":"code","52d3a750":"code","a3ffb8cd":"code","ad520b01":"code","83986fdd":"code","9629f564":"code","125efa4d":"code","f6cec781":"code","64a528d8":"code","f5f043ff":"code","9ae4ba41":"code","783a01bb":"code","0d794447":"code","3c5262e8":"code","962c5868":"code","22cc04ca":"code","8a9f5c70":"code","051625a1":"markdown","32e54141":"markdown","72b1ec99":"markdown","23385114":"markdown","142874b9":"markdown","e63138d2":"markdown","899e0871":"markdown","37b9455f":"markdown","f9730b5d":"markdown","4f44ec30":"markdown","0aeaed7a":"markdown","756cf678":"markdown","d3ec12cf":"markdown","8b269158":"markdown","f5d9d8b4":"markdown","6e0c06b0":"markdown","170148c8":"markdown","2ee741f3":"markdown","634ae7d3":"markdown","a7ced28b":"markdown","d2032ea1":"markdown","0274a479":"markdown","c0f32281":"markdown","a86b41b4":"markdown","1fcf0a27":"markdown","86f4e940":"markdown","6fd05499":"markdown","7bf5e4aa":"markdown","854bf797":"markdown","98aa58f3":"markdown","bb5ccfc5":"markdown","a831e756":"markdown","8a3d9e8e":"markdown","71f3c50c":"markdown","b8db97d8":"markdown","c7a75773":"markdown","29261896":"markdown","5c748467":"markdown","67bd27ef":"markdown","ed2844eb":"markdown","ba680aa6":"markdown","0036ff4e":"markdown","95c2d3c0":"markdown","9fdc8e54":"markdown","48fcf9ae":"markdown","f76f5d3b":"markdown","2d5b003e":"markdown"},"source":{"424bde30":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0893aee7":"# Importing other Necessary Libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nSEED = 42\nnp.random.seed(SEED)\n%matplotlib inline","b8fffa54":"df = pd.read_csv(\"\/kaggle\/input\/income-classification\/income_evaluation.csv\")\ndf_copy = df.copy()","627aff85":"df.info()","51e844a0":"# Renaming Columns\n\ncol_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n\ndf.columns = col_names\n\ndf.columns","c39f0e56":"# Shape \n\ndf.shape","d90f7322":"# Statistical distribution of the data\n\ndf.describe().T","9ba4bc1c":"# Checking for missing values\n\ndf.isnull().sum()","11b3201d":"df.columns","76f7dad3":"categorical = []\nnumerical = []\n\nfor i in df.columns:\n    if df[i].dtype=='O':\n        categorical.append(i)\n    else:\n        numerical.append(i)","76ea3dd0":"# Categorical columns\n\nprint(categorical)","024fb16d":"# Numerical Columns\n\nprint(numerical)","e5fa9d8f":"# Categorical columns\n\nprint(categorical)","6cfb8bd4":"df[categorical].isnull().sum()","680e7a5d":"for i in categorical:\n    print(df[i].value_counts())","5491f44a":"# Let us explore our target variable first - 'income'\n\ndf['income'].value_counts()","6c525096":"# Let us visualise it through pie chart and countplot\n\nfig, ax=plt.subplots(1,2,figsize=(18,8))\n\nax[0].pie(df['income'].value_counts(),labels=['<=50K','>50K'],explode=[0,0.2],shadow=True)\nax[1] = sns.countplot('income',data=df,palette='coolwarm')\nplt.tight_layout()\nplt.show()","277850de":"# Visualise 'income' wrt 'sex' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.countplot(df['income'],hue=df['sex'])\nplt.tight_layout()\nplt.show()","3022eee6":"# Visualise 'income' wrt 'workclass' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.countplot(df['income'],hue=df['workclass'])\nplt.tight_layout()\nplt.show()","de441d98":"# Visualise 'income' wrt 'occupation' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.countplot(df['income'],hue=df['occupation'])\nplt.tight_layout()\nplt.show()","29fcb178":"# Visualise 'income' wrt 'race' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.countplot(df['income'],hue=df['race'])\nplt.tight_layout()\nplt.show()","a990fdc0":"# Let us explore 'workclass' categorical column.\n\ndf['workclass'].value_counts()","4519d11d":"# Let us visualise it through pie chart and countplot\n\nfig, ax=plt.subplots(1,2,figsize=(18,8))\n\nax[0].pie(df['workclass'].value_counts(),labels=df['workclass'].value_counts().index,shadow=True)\nax[1] = sns.countplot('workclass',data=df,palette='coolwarm')\nplt.tight_layout()\nplt.show()","66dc8706":"# Visualise 'workclass' wrt 'race' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.countplot(df['workclass'],hue=df['race'])\nplt.tight_layout()\nplt.show()","890d1902":"# Let us explore 'occupation' categorical column.\n\ndf['occupation'].value_counts()","37211146":"# Let us visualise it through pie chart and countplot\n\nfig, ax=plt.subplots(1,2,figsize=(23,10))\n\nax[0].pie(df['occupation'].value_counts(),labels=df['occupation'].value_counts().index,shadow=True)\nax[1] = sns.countplot('occupation',data=df,palette='coolwarm')\nplt.tight_layout()\nplt.show()","05ffd725":"# Visualise 'occupation' wrt 'race' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.countplot(df['occupation'],hue=df['sex'])\nplt.tight_layout()\nplt.show()","a5517aaf":"# Let us explore 'native-country' categorical column.\n\ndf['native_country'].value_counts()","4973a441":"fig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.countplot(df['native_country'])\nplt.tight_layout()\nplt.show()","258db341":"# Replacing '?' with np.nan values.\n\ndf.replace(' ?',np.NaN,inplace=True)","cf7ccb22":"# Checking for missing values.\n\ndf.isnull().sum()","8f5996e0":"# Numerical columns\n\nprint(numerical)","bde07d8e":"df[numerical].isnull().sum()","38e9065c":"# Pairwise plot of all the numerical features.\n\nsns.pairplot(df[numerical])\nplt.tight_layout()\nplt.show()","7b0fa955":"# We will first explore 'age' feature \n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.distplot(df['age'])\nplt.tight_layout()\nplt.show()","a920bce2":"fig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.boxplot(y=df['age'])\nplt.tight_layout()\nplt.show()","9e5e5ee4":"# Visualise 'age' wrt to 'sex' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.boxplot(x=df[\"sex\"],y=df['age'])\nplt.tight_layout()\nplt.show()","41cfc6dd":"# Visualise 'age' wrt to 'sex' and 'race' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.boxplot(x=df[\"sex\"],y=df['age'],hue=df[\"race\"])\nplt.tight_layout()\nplt.show()","882c9e29":"# Visualise 'age' wrt to 'income' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.boxplot(x=df[\"income\"],y=df['age'])\nplt.tight_layout()\nplt.show()","06284501":"# Visualise 'age' wrt to 'income' and 'sex' feature\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.boxplot(x=df[\"income\"],y=df['age'],hue=df[\"sex\"])\nplt.tight_layout()\nplt.show()","a9a818dc":"# Checking for correlation between numerical features\n\nfig, ax=plt.subplots(1,1,figsize=(18,8))\nax = sns.heatmap(df[numerical].corr(),annot=True)\nplt.tight_layout()\nplt.show()","5378960f":"X = df.drop('income',axis=1)\ny = df[\"income\"]","237d4d04":"# Splitting the data\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)","6beddd99":"X_train.shape, X_test.shape","0403ab0c":"# Filling missing values in train data\n\nX_train[\"workclass\"].fillna(X_train[\"workclass\"].mode()[0],inplace=True)\nX_train[\"occupation\"].fillna(X_train[\"occupation\"].mode()[0],inplace=True)\nX_train[\"native_country\"].fillna(X_train[\"native_country\"].mode()[0],inplace=True)","ad35fc35":"# Filling missing values in test data\n\nX_test[\"workclass\"].fillna(X_test[\"workclass\"].mode()[0],inplace=True)\nX_test[\"occupation\"].fillna(X_test[\"occupation\"].mode()[0],inplace=True)\nX_test[\"native_country\"].fillna(X_test[\"native_country\"].mode()[0],inplace=True)","f7a289d3":"# checking for missing values in train data\n\nX_train.isnull().sum()","e7f76931":"# checking for missing values in test data\n\nX_test.isnull().sum()","a7698c14":"# Encoding Categorical features using One-Hot Encoding\n\nimport category_encoders as ce","d3ddaab8":"encoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country'])\n\nX_train = encoder.fit_transform(X_train)\n\nX_test = encoder.transform(X_test)","3360768d":"X_train.head()","c2c2b258":"X_test.head()","84732db1":"from sklearn.preprocessing import RobustScaler","ccc85f67":"cols = X_train.columns\nscaler = RobustScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","ad5f6a9f":"X_train = pd.DataFrame(X_train,columns=[cols])\nX_test = pd.DataFrame(X_test,columns=[cols])","769ff17e":"X_train.head()","a7a07e10":"X_test.head()","d4c75fd9":"from sklearn.ensemble import RandomForestClassifier","053eb89e":"rc = RandomForestClassifier(n_estimators=100,random_state=42)","6d751cc2":"rc.fit(X_train,y_train)","6308575b":"feature_score = pd.Series(rc.feature_importances_,X_train.columns).sort_values(ascending=False)","001aa464":"feature_score","9ea41e2a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost","01100dce":"# Metrics\n\nfrom sklearn.metrics import classification_report,confusion_matrix, precision_score, recall_score, f1_score","95500de2":"y_train = pd.get_dummies(y_train,drop_first=True)\ny_train.columns= ['income']","cefd22fa":"y_test = pd.get_dummies(y_test,drop_first=True)\ny_test.columns= ['income']","35945ae8":"# Logistic Regression\n\nlr = LogisticRegression(solver='liblinear',random_state=42)\nlr.fit(X_train,y_train.values.ravel())","42b5aa6b":"# Train accuracy\n\ny_pred = lr.predict(X_train)\nprint(classification_report(y_train,y_pred))\nprint(f'F1 Score for train data is {f1_score(y_train,y_pred)}')","3803cca2":"# Test accuracy\n\ny_pred = lr.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(f'F1 Score for test data is {f1_score(y_test,y_pred)}')","52d3a750":"# Support Vector Machine\n\nsvc = SVC(random_state=42)\nsvc.fit(X_train,y_train.values.ravel())","a3ffb8cd":"# Train accuracy\n\ny_pred = svc.predict(X_train)\nprint(classification_report(y_train,y_pred))\nprint(f'F1 Score for train data is {f1_score(y_train,y_pred)}')","ad520b01":"# Test accuracy\n\ny_pred = svc.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(f'F1 Score for test data is {f1_score(y_test,y_pred)}')","83986fdd":"# Random Forest Classifier\n\nrc = RandomForestClassifier(n_estimators=100,random_state=42)\nrc.fit(X_train,y_train.values.ravel())","9629f564":"# Train accuracy\n\ny_pred = rc.predict(X_train)\nprint(classification_report(y_train,y_pred))\nprint(f'F1 Score for train data is {f1_score(y_train,y_pred)}')","125efa4d":"# Test accuracy\n\ny_pred = rc.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(f'F1 Score for test data is {f1_score(y_test,y_pred)}')","f6cec781":"# XGBoost Classifier\n\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(random_state=42)\nxgb.fit(X_train,y_train.values.ravel())","64a528d8":"# Train accuracy\n\ny_pred = xgb.predict(X_train)\nprint(classification_report(y_train,y_pred))\nprint(f'F1 Score for train data is {f1_score(y_train,y_pred)}')","f5f043ff":"# Test accuracy\n\ny_pred = xgb.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(f'F1 Score for test data is {f1_score(y_test,y_pred)}')","9ae4ba41":"from sklearn.model_selection import RandomizedSearchCV","783a01bb":"rc = RandomForestClassifier(random_state=42)","0d794447":"n_estimators = [500,800,1500,1200,2500,5000,6000]\nmax_features = ['auto','sqrt','log2']\nmax_depth = [5, 8, 15, 25, 30,10, 20, 40, 50]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10, 15, 20, 100]\nmin_samples_leaf = [1, 2, 5, 10, 15, 20] \n\nparams = dict(n_estimators = n_estimators, max_features = max_features, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf)","3c5262e8":"grid = RandomizedSearchCV(rc,params,n_jobs=-1,cv=10,verbose=3)\ngrid.fit(X_train,y_train.values.ravel())","962c5868":"grid.best_params_","22cc04ca":"# Train accuracy\n\ny_pred = grid.predict(X_train)\nprint(classification_report(y_train,y_pred))\nprint(f'F1 Score for train data is {f1_score(y_train,y_pred)}')","8a9f5c70":"# Test accuracy\n\ny_pred = grid.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(f'F1 Score for test data is {f1_score(y_test,y_pred)}')","051625a1":"* **In \"Adm-clerical\", \"Other-service\" and \"Priv-house-serv\" females are dominating whereas in rest males are more in count.**","32e54141":"## Feature Engineering","72b1ec99":"* **Let us visualise each numerical features one by one.**","23385114":"* **In terms of training accuracy, Random Forset Classifier performs best. We will try to reduce variance by tuning hyperparameters.**","142874b9":"* **Median of Male is more than the Female wrt 'age' feature.**","e63138d2":"* **We observe few categories to have '?' value which indicates NULL value which are:-**\n\n    1. **workclass**\n    2. **occupation**\n    3. **native-country**","899e0871":"* **We have nine categorical columns including the target variable.**","37b9455f":"## Hyperparameter Optimization","f9730b5d":"* **We have six numerical columns.**","4f44ec30":"* **Now, let us analyze each feature and make intuition out of it.**","0aeaed7a":"* **We are going to work on four models for our classification problem that are:-**\n\n1. LogisticRegression\n2. Support Vector Machine\n3. Naive Bayes Classifier\n4. XGBoost\n","756cf678":"## 2) Importing Dataset","d3ec12cf":"## 3.2) Exploring Numerical Columns","8b269158":"* **We will not use accuracy as a metrics since we are having imbalanced dataset.**","f5d9d8b4":"## 1) Importing Libraries","6e0c06b0":"* **Encoded >50K - 1**\n* **Encoded <=50K - 0**","170148c8":"* **We will now perform separate analysis on categorical as well as numerical features.**","2ee741f3":"# Thank You!!\n\n* **If you find this notebook interesting, do upvote it.**","634ae7d3":"* **It seems like XGBoost performance is better than Random Forset after hyperparameetr optimization.**\n* **We reduced overfitting in Random Forest but not significant increase in Test F1 Score.**","a7ced28b":"* **We need to replace '?' with np.nan values.**","d2032ea1":"**Interpretation: Rows = 32,561 | Cols = 15**","0274a479":"* **Private 'workclass' gets high income than other types.**","c0f32281":"* **Next, we are going to select best features using embedding method.**","a86b41b4":"* **We have two unique values in target variable with title '<=50K' and '>50K'.**\n* **Count of '<=50K' and '>50K' is 24720 and 7841 respectively.**","1fcf0a27":"* **White people are taking more salary their home than any other race.**","86f4e940":"* **We are using RobustScaler for scaling purpose as it is robust to outliers.**\n* **We have previously seen that there are outliers in our data.**","6fd05499":"# Detailed Working on Income Dataset\n\nHello everyone, I'm Rishabh, a pre-final year student of IIIT Gwalior. This notebook includes detailed working on income-classification dataset. It includes **Exploratory Data Analysis, Feature Engineering, Feature Scaling, Feature Selection, Modeling and Hyperparameter Optimization** techniques. I hope you will find this notebook informative. Thanks!!","7bf5e4aa":"* We can't see any missing value in categorical columns.","854bf797":"* **There is higher percentage of '<=50K' than '>50K'.**","98aa58f3":"## 3.1) Exploring Categorical Columns","bb5ccfc5":"* **We are facing missing values in three columns. We will deal with it later in Feature Engineering section.**","a831e756":"## Feature Selection","8a3d9e8e":"* **Most Important Feature - 'fnlwgt'**\n* **Leat Important Feature - 'native_country_37'**","71f3c50c":"* **In boxplot, outlier values are denoted by black dots.**\n* **Clearly, we can see many outliers in the 'age' feature.**","b8db97d8":"* **We will use RandomizedSearchCV for hyperparameter optimization.**","c7a75773":"* **We encounter overfitting in case of random forest.**","29261896":"## Modelling","5c748467":"* **Fortunately, we don't encounter the problem of multi-collinearity which can create obstacle in creating linear model.**","67bd27ef":"## 3) Exploratory Data Analysis","ed2844eb":"* **There are no missing values in numerical columns.**","ba680aa6":"* **It's is obvious that people with more age will have more salary.**","0036ff4e":"* **White people are dominating in every workclass.**","95c2d3c0":"* **In terms of native-country, United-States is clearly dominating than any other country.**","9fdc8e54":"* **The distribution of 'age' variable is positively skewed.**","48fcf9ae":"**Interpretation: There are 6 columns with int64 dtype and 9 columns with object dtype.**","f76f5d3b":"* **Next, we are going to perform scaling and transformation texhniques to our features.**","2d5b003e":"## Feature Scaling \/ Feature Transformation"}}