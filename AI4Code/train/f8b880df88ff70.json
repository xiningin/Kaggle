{"cell_type":{"2b0a1c4d":"code","6a444b76":"code","ec9b9e11":"code","a6dbc242":"code","23cae17b":"code","01a1a4d0":"code","d1b174ec":"code","2bd8c370":"code","acd32947":"code","8a1575e5":"code","9ecc44d8":"code","a26f6aa6":"code","cbac74ca":"code","32d14a48":"code","c9c4b154":"code","400ca1bc":"code","d00f00c1":"code","b5905d60":"code","d9ba5cc2":"code","592cc2bd":"code","aca217c4":"code","013622c3":"markdown","43203d69":"markdown","159faa21":"markdown","2fd0f7ef":"markdown","91a4763d":"markdown","a84bece6":"markdown","2b7c8ba7":"markdown","f5c388ea":"markdown","b160bb91":"markdown","c3e5b3dc":"markdown","d508b797":"markdown","3837f03d":"markdown","0333577c":"markdown"},"source":{"2b0a1c4d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import rcParams\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n%matplotlib inline\nrcParams['figure.figsize'] = 10,8\nsns.set(style='whitegrid', palette='muted',\n        rc={'figure.figsize': (12,8)})\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# print(os.listdir(\"..\/input\"))","6a444b76":"# Load data as Pandas dataframe\ntrain = pd.read_csv('..\/input\/train.csv', )\ntest = pd.read_csv('..\/input\/test.csv')\ndf = pd.concat([train, test], axis=0, sort=True)","ec9b9e11":"df.head()","a6dbc242":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)\n\n        \ndisplay_all(df.describe(include='all').T)","23cae17b":"df['Survived'].value_counts()","01a1a4d0":"# create new Title column\ndf['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)","d1b174ec":"df.head()","2bd8c370":"df['Title'].value_counts()","acd32947":"# replace rare titles with more common ones\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\n           'Don': 'Mr', 'Mme': 'Mrs', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\n           'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ndf.replace({'Title': mapping}, inplace=True)","8a1575e5":"# confirm that we are left with just six values\ndf['Title'].value_counts()","9ecc44d8":"# impute missing Age values using median of Title groups\ntitle_ages = dict(df.groupby('Title')['Age'].median())\n\n# create a column of the average ages\ndf['age_med'] = df['Title'].apply(lambda x: title_ages[x])\n\n# replace all missing ages with the value in this column\ndf['Age'].fillna(df['age_med'], inplace=True, )\ndel df['age_med']","a26f6aa6":"sns.barplot(x='Title', y='Age', data=df, estimator=np.median, ci=None, palette='Blues_d')\nplt.xticks(rotation=45)\nplt.show()","cbac74ca":"sns.countplot(x='Title', data=df, palette='hls', hue='Survived')\nplt.xticks(rotation=45)\nplt.show()","32d14a48":"sns.swarmplot(x='Sex', y='Fare', hue='Survived', data=df)\nplt.show()","c9c4b154":"# impute missing Fare values using median of Pclass groups\nclass_fares = dict(df.groupby('Pclass')['Fare'].median())\n\n# create a column of the average fares\ndf['fare_med'] = df['Pclass'].apply(lambda x: class_fares[x])\n\n# replace all missing fares with the value in this column\ndf['Fare'].fillna(df['fare_med'], inplace=True, )\ndel df['fare_med']","400ca1bc":"sns.catplot(x='Embarked', y='Survived', data=df,\n            kind='bar', palette='muted', ci=None)\nplt.show()","d00f00c1":"df['Embarked'].fillna(method='backfill', inplace=True)","b5905d60":"# create Family_Size column (Parch +)\ndf['Family_Size'] = df['Parch'] + df['SibSp']","d9ba5cc2":"display_all(df.describe(include='all').T)","592cc2bd":"train = df[pd.notnull(df['Survived'])]\ntest = df[pd.isnull(df['Survived'])]","aca217c4":"train.to_csv('train_clean.csv', index=False)\ntest.to_csv('test_clean.csv', index=False)","013622c3":"# Table of Contents:\n\n- **1. [Load Packages and Data](#loading)**\n- **2. [Imputation](#impute-missing)**\n  - **2.1. [Age](#age)**\n  - **2.1. [Fare](#fare)**\n  - **2.1. [Embarked](#embarked)**\n- **3. [Feature engineering](#feature-engineering)**","43203d69":"### Use median of title group\nNow, for each missing age value, we will impute the age using the median age for all people with the same title.","159faa21":"<a id=\"feature-engineering\"><\/a>\n# 3. Add family size column\nWe can use the two variables of **Parch** and **SibSp** to create a new variable called **Family_Size**. This is simply done by adding `Parch` and `SibSp` together.","2fd0f7ef":"As we can see above, there are quite a few different titles. However, many of these titles are just French versions of the more common English titles, e.g. Mme = Madame = Mrs.   \n\nWe will use the six most common titles, replacing all other titles with the most appropriate of these six.","91a4763d":"We can visualize the median ages for each title group. Below, we see that each title has a distinctly different median age. \n> **Note**: There is no risk in doing this after imputation, as the median of an age group has not been affected by our actions.","a84bece6":"<a id=\"embarked\"><\/a>\n## 2.3. Impute missing \"embarked\" value\nThere are also just two missing values in the `Embarked` column. Here we will just use the Pandas 'backfill' method.\n","2b7c8ba7":"<a id=\"fare\"><\/a>\n## 2.2. Impute missing fare values\nFor the single missing fare value, I also use the median fare value for the passenger's class.   \n\n> Perhaps you could come up with a cooler way of visualising the relationship between the price a passenger paid for their ticket and their chances of survival?","f5c388ea":"<a id=\"loading\"><\/a>\n# 1. Load packages and data\nFirst step, as always, is to import the necessary Python packages and load the input data as a Pandas dataframe.\n\nI chose to combine the train and test set into one. Since we will have to impute some missing age and fare values, I prefer to do this across the entire dataset, rather than separately across train and test sets. ","b160bb91":"# Titanic challenge part 1\nIn this notebook, we will be covering all of the steps required to wrangle the Titanic data set into a format that is suitable for machine learning.   \nWe will do each of the following:\n  - impute missing values\n  - create new features (feature engineering)\n  \n[**Part 2**](https:\/\/www.kaggle.com\/jamesleslie\/titanic-random-forest-grid-search) of this challenge involves fitting and tuning a **random forest** to make predictions.","c3e5b3dc":"### Extract title from name\nWe can use a regular expression to extract the title from the `Name` column. We will do this by finding the adjacent letters that are immediately followed by a full stop.\n","d508b797":"<a id=\"impute-missing\"><\/a>\n# 2. Imputation \nWe can see above that there are a few columns with missing values. The `Cabin` column is missing over 1000 values, so we won't use that for predictions, but the `Age`, `Embarked` and `Fare` columns are all complete enough that we can fill in the missing values through imputation.   \n<a id=\"age\"><\/a>\n## 2.1. Impute missing age values\nA simple option for the missing age values is to use the median age value. Let's go a little further and use each passenger's *Title* to estimate their age. E.g. if a passenger has the title of *Dr*, I will give them the median age value for all other passengers with the same title.","3837f03d":"# 4. Save cleaned version\nFinally, let's save our cleaned data set so we can use it in other notebooks.","0333577c":"### Use only the most common titles\nLet's take a look at the unique titles across all passengers:"}}