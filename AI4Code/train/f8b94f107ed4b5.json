{"cell_type":{"ee7e4b17":"code","4a31848f":"code","51a44aaf":"code","abe5264c":"code","ce572555":"code","46ab2fcf":"code","26cbf16f":"code","42871e35":"code","ee2d65c2":"code","4b108640":"code","7680c799":"code","73cd2f21":"code","6461a841":"code","8e8f1f2f":"code","21612c0d":"code","5174cfd6":"code","edcd1def":"code","b39e63a1":"code","b8067ceb":"code","1452bb0e":"code","fc4a105d":"code","871f0ac6":"code","0805d89c":"code","1ca1f4a6":"code","0e76d787":"code","abecfc34":"code","d6cea810":"code","36c5d13f":"code","dda22267":"markdown","1919b2ca":"markdown","29c425de":"markdown","f0a3f204":"markdown","649b3058":"markdown","9db123c9":"markdown","0124c2e5":"markdown"},"source":{"ee7e4b17":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error, log_loss\nfrom tqdm import tqdm_notebook\nimport seaborn as sns\nimport imageio\nfrom IPython.display import HTML\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.datasets import make_blobs","4a31848f":"my_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\",[\"red\",\"yellow\",\"green\"])","51a44aaf":"np.random.seed(0)","abe5264c":"data, labels = make_blobs(n_samples=1000, centers=4, n_features=2, random_state=0)\nprint(data.shape, labels.shape)","ce572555":"plt.scatter(data[:,0], data[:,1], c=labels, cmap=my_cmap)\nplt.show()","46ab2fcf":"labels_orig = labels\nlabels = np.mod(labels_orig, 2)","26cbf16f":"plt.scatter(data[:,0], data[:,1], c=labels, cmap=my_cmap)\nplt.show()","42871e35":"X_train, X_val, Y_train, Y_val = train_test_split(data, labels, stratify=labels, random_state=0)\nprint(X_train.shape, X_val.shape)","ee2d65c2":"class FFNetworkW1:\n    \n    def __init__(self):\n        self.w1 = np.random.randn()\n        self.w2 = np.random.randn()\n        self.w3 = np.random.randn()\n        self.w4 = np.random.randn()\n        self.w5 = np.random.randn()\n        self.w6 = np.random.randn()\n        self.b1 = 0\n        self.b2 = 0\n        self.b3 = 0\n    \n    def sigmoid(self, x):\n        return 1.0\/(1.0 + np.exp(-x))\n    \n    def forward_pass(self, x):\n        self.x1, self.x2 = x\n        self.a1 = self.w1*self.x1 + self.w2*self.x2 + self.b1\n        self.h1 = self.sigmoid(self.a1)\n        self.a2 = self.w3*self.x1 + self.w4*self.x2 + self.b2\n        self.h2 = self.sigmoid(self.a2)\n        self.a3 = self.w5*self.h1 + self.w6*self.h2 + self.b3\n        self.h3 = self.sigmoid(self.a3)\n        return self.h3\n    \n    def grad(self, x, y):\n        self.forward_pass(x)\n        self.dw1 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1) * self.x1\n    \n    def fit(self, X, Y, epochs=1, learning_rate=1, display_loss=False):\n        \n        if display_loss:\n            loss = {}\n            w1 = {}\n            \n        for i in tqdm_notebook(range(epochs), total = epochs, unit=\"epoch\"):\n            \n            dw1, dw2, dw3, dw4, dw5, dw6, db1, db2, db3 = [0]*9\n            \n            for x, y in zip(X, Y):\n                self.grad(x, y)\n                dw1 += self.dw1\n            \n            m = X.shape[0]\n            self.w1 -= learning_rate * dw1 \/ m\n            \n            if display_loss:\n                w1[i] = self.w1\n                Y_pred = self.predict(X)\n                loss[i] = mean_squared_error(Y_pred, Y)\n                \n        if display_loss:\n            plt.tight_layout()\n            \n            plt.subplot(2,1,1)\n#             plt.plot(w1.values())\n            plt.plot(np.fromiter(w1.values(), dtype = float))\n            plt.xlabel('Epochs')\n            plt.ylabel('W1')\n            \n            plt.subplot(2,1,2)\n#             plt.plot(loss.values())\n            plt.plot(np.fromiter(loss.values(), dtype = float))\n            plt.xlabel('Epochs')\n            plt.ylabel('Mean Squared Error')\n            \n            plt.show()\n        \n    def predict(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(y_pred)\n        return np.array(Y_pred)","4b108640":"ffnw1 = FFNetworkW1()\nffnw1.fit(X_train, Y_train, epochs=500, learning_rate=1, display_loss=True)","7680c799":"class FirstFFNetwork:\n    \n    def __init__(self):\n        np.random.seed(0)\n        self.w1 = np.random.randn()\n        self.w2 = np.random.randn()\n        self.w3 = np.random.randn()\n        self.w4 = np.random.randn()\n        self.w5 = np.random.randn()\n        self.w6 = np.random.randn()\n        self.b1 = 0\n        self.b2 = 0\n        self.b3 = 0\n    \n    def sigmoid(self, x):\n        return 1.0\/(1.0 + np.exp(-x))\n    \n    def forward_pass(self, x):\n        self.x1, self.x2 = x\n        self.a1 = self.w1*self.x1 + self.w2*self.x2 + self.b1\n        self.h1 = self.sigmoid(self.a1)\n        self.a2 = self.w3*self.x1 + self.w4*self.x2 + self.b2\n        self.h2 = self.sigmoid(self.a2)\n        self.a3 = self.w5*self.h1 + self.w6*self.h2 + self.b3\n        self.h3 = self.sigmoid(self.a3)\n        return self.h3\n    \n    def grad(self, x, y):\n        self.forward_pass(x)\n        \n        self.dw5 = (self.h3-y) * self.h3*(1-self.h3) * self.h1\n        self.dw6 = (self.h3-y) * self.h3*(1-self.h3) * self.h2\n        self.db3 = (self.h3-y) * self.h3*(1-self.h3)\n        \n        self.dw1 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1) * self.x1\n        self.dw2 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1) * self.x2\n        self.db1 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1)\n        \n        self.dw3 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2 * (1-self.h2) * self.x1\n        self.dw4 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2 * (1-self.h2) * self.x2\n        self.db2 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2 * (1-self.h2)\n        \n    def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, display_loss=False, display_weight=False):\n        \n        # initialise w, b\n        if initialise:\n            np.random.seed(0)\n            self.w1 = np.random.randn()\n            self.w2 = np.random.randn()\n            self.w3 = np.random.randn()\n            self.w4 = np.random.randn()\n            self.w5 = np.random.randn()\n            self.w6 = np.random.randn()\n            self.b1 = 0\n            self.b2 = 0\n            self.b3 = 0\n        \n        if display_loss:\n            loss = {}\n            w1 = {}\n            \n        for i in tqdm_notebook(range(epochs), total = epochs, unit=\"epoch\"):\n            \n            dw1, dw2, dw3, dw4, dw5, dw6, db1, db2, db3 = [0]*9\n            \n            for x, y in zip(X, Y):\n                self.grad(x, y)\n                dw1 += self.dw1\n                dw2 += self.dw2\n                dw3 += self.dw3\n                dw4 += self.dw4\n                dw5 += self.dw5\n                dw6 += self.dw6\n                db1 += self.db1\n                db2 += self.db2\n                db3 += self.db3\n            \n            m = X.shape[0]\n            self.w1 -= learning_rate * dw1 \/ m\n            self.w2 -= learning_rate * dw2 \/ m\n            self.w3 -= learning_rate * dw3 \/ m\n            self.w4 -= learning_rate * dw4 \/ m\n            self.w5 -= learning_rate * dw5 \/ m\n            self.w6 -= learning_rate * dw6 \/ m\n            self.b1 -= learning_rate * db1 \/ m\n            self.b2 -= learning_rate * db2 \/ m\n            self.b3 -= learning_rate * db3 \/ m\n            \n            if display_loss:\n                Y_pred = self.predict(X)\n                loss[i] = mean_squared_error(Y_pred, Y)\n            \n            if display_weight:\n                weight_matrix = np.array([[0, self.b3, self.w5, self.w6, 0, 0], [self.b1, self.w1, self.w2, self.b2, self.w3, self.w4]])\n                weight_matrices.append(weight_matrix)\n            \n        if display_loss:\n            plt.plot(np.fromiter(loss.values(), dtype = float))\n            plt.xlabel('Epochs')\n            plt.ylabel('Mean Squared Error')\n            plt.show()\n        \n    def predict(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(y_pred)\n        return np.array(Y_pred)\n    \n    def predict_h1(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h1)\n        return np.array(Y_pred)\n\n    def predict_h2(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h2)\n        return np.array(Y_pred)\n\n    def predict_h3(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h3)\n        return np.array(Y_pred)","73cd2f21":"weight_matrices=[]\nffn = FirstFFNetwork()\nffn.fit(X_train, Y_train, epochs=2000, learning_rate=5, display_loss=True, display_weight=True)","6461a841":"def make_meshgrid(x, y, h=.2):\n    x_min, x_max = x.min() - 0.5, x.max() + 0.5\n    y_min, y_max = y.min() - 0.5, y.max() + 0.5\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    return xx, yy\n\ndef plot_contours(ax, predict, xx, yy, **params):\n    Z = predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    out = ax.contourf(xx, yy, Z, **params)\n\n    return out\n\ndef plot_boundary():\n    xx, yy = make_meshgrid(X_train[:,0], X_train[:,1])\n    predict_functions = [ffn.predict_h1, ffn.predict_h2, ffn.predict_h3]\n    \n    for i in range(3):\n        \n        fig, ax = plt.subplots(figsize=(10,5))\n        plot_contours(ax, predict_functions[i], xx, yy,\n                      cmap=my_cmap, alpha=0.2)\n        ax.scatter(X_train[:,0], X_train[:,1], c=Y_train, cmap=my_cmap, alpha=0.8)\n        ax.set_xlim(xx.min(),xx.max())\n        ax.set_ylim(yy.min(),yy.max())\n        ax.set_xlabel('X1')\n        ax.set_ylabel('X2')\n        ax.set_title(\"h\"+str(i+1))\n        \n    return True\n\nplot_boundary()","8e8f1f2f":"def plot_heat_map(epoch):\n    fig = plt.figure(figsize=(10, 1))\n    sns.heatmap(weight_matrices[epoch], annot = True, cmap=my_cmap, vmin=-3, vmax=3)\n    plt.title(\"Epoch\" + str(epoch))\n    \n    fig.canvas.draw()\n    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n    \n    return image","21612c0d":"imageio.mimsave('.\/weights_viz.gif',[plot_heat_map(i) for i in range(0, len(weight_matrices),len(weight_matrices)\/\/50)],fps=1)","5174cfd6":"from IPython import display\nHTML('<img src = \"weights_viz.gif\">')","edcd1def":"Y_pred_train = ffn.predict(X_train)\nY_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\nY_pred_val = ffn.predict(X_val)\nY_pred_binarised_val = (Y_pred_val >= 0.5).astype(\"int\").ravel()\naccuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\naccuracy_val = accuracy_score(Y_pred_binarised_val, Y_val)\n\nprint(\"Training accuracy\", round(accuracy_train, 2))\nprint(\"Validation accuracy\", round(accuracy_val, 2))","b39e63a1":"plt.scatter(X_train[:,0], X_train[:,1], c=Y_pred_binarised_train, cmap=my_cmap, s=15*(np.abs(Y_pred_binarised_train-Y_train)+.2))\nplt.show()","b8067ceb":"X_train, X_val, Y_train, Y_val = train_test_split(data, labels_orig, stratify=labels_orig, random_state=0)\nprint(X_train.shape, X_val.shape, labels_orig.shape)","1452bb0e":"enc = OneHotEncoder()\n# 0 -> (1, 0, 0, 0), 1 -> (0, 1, 0, 0), 2 -> (0, 0, 1, 0), 3 -> (0, 0, 0, 1)\ny_OH_train = enc.fit_transform(np.expand_dims(Y_train,1)).toarray()\ny_OH_val = enc.fit_transform(np.expand_dims(Y_val,1)).toarray()\nprint(y_OH_train.shape, y_OH_val.shape)","fc4a105d":"plt.scatter(X_train[:,0], X_train[:,1], c=Y_train, cmap=my_cmap)\nplt.show()","871f0ac6":"class FFSN_MultiClass_Specific:\n    \n    def __init__(self):\n        np.random.seed(0)\n        self.w1 = np.random.randn()\n        self.w2 = np.random.randn()\n        self.w3 = np.random.randn()\n        self.w4 = np.random.randn()\n        self.w5 = np.random.randn()\n        self.w6 = np.random.randn()\n        self.w7 = np.random.randn()\n        self.w8 = np.random.randn()\n        self.w9 = np.random.randn()\n        self.w10 = np.random.randn()\n        self.w11 = np.random.randn()\n        self.w12 = np.random.randn()\n        self.b1 = 0\n        self.b2 = 0\n        self.b3 = 0\n        self.b4 = 0\n        self.b5 = 0\n        self.b6 = 0\n        \n    def sigmoid(self, x):\n        return 1.0\/(1.0 + np.exp(-x))\n    \n    def forward_pass(self, x):\n        # input layer\n        self.x1, self.x2 = x\n        \n        # hidden layer\n        self.a1 = self.w1*self.x1 + self.w2*self.x2 + self.b1\n        self.h1 = self.sigmoid(self.a1)\n        self.a2 = self.w3*self.x1 + self.w4*self.x2 + self.b2\n        self.h2 = self.sigmoid(self.a2)\n        \n        # output layer\n        self.a3 = self.w5*self.h1 + self.w6*self.h2 + self.b3\n        self.a4 = self.w7*self.h1 + self.w8*self.h2 + self.b4\n        self.a5 = self.w9*self.h1 + self.w10*self.h2 + self.b5\n        self.a6 = self.w11*self.h1 + self.w12*self.h2 + self.b6\n        sum_exps = np.sum([np.exp(self.a3), np.exp(self.a4), np.exp(self.a5), np.exp(self.a6)])\n        self.h3 = np.exp(self.a3)\/sum_exps\n        self.h4 = np.exp(self.a4)\/sum_exps\n        self.h5 = np.exp(self.a5)\/sum_exps\n        self.h6 = np.exp(self.a6)\/sum_exps\n        \n        return np.array([self.h3, self.h4, self.h5, self.h6])\n    \n    def grad(self, x, y):\n        self.forward_pass(x)\n        self.y1, self.y2, self.y3, self.y4 = y\n        \n        self.dw5 = (self.h3-self.y1) * self.h1\n        self.dw6 = (self.h3-self.y1) * self.h2\n        self.db3 = (self.h3-self.y1)\n        \n        self.dw7 = (self.h4-self.y2) * self.h1\n        self.dw8 = (self.h4-self.y2) * self.h2\n        self.db4 = (self.h4-self.y2)\n        \n        self.dw9 = (self.h5-self.y3) * self.h1\n        self.dw10 = (self.h5-self.y3) * self.h2\n        self.db5 = (self.h5-self.y3)\n        \n        self.dw11 = (self.h6-self.y4) * self.h1\n        self.dw12 = (self.h6-self.y4) * self.h2\n        self.db6 = (self.h6-self.y4)\n        \n        self.dh1 = (self.h3-self.y1)*self.w5 + (self.h4-self.y2)*self.w7 + (self.h5-self.y3)*self.w9 + (self.h6-self.y4)*self.w11\n        self.dw1 = self.dh1 * self.h1*(1-self.h1) * self.x1\n        self.dw2 = self.dh1 * self.h1*(1-self.h1) * self.x2\n        self.db1 = self.dh1 * self.h1*(1-self.h1)\n        \n        self.dh2 = (self.h3-self.y1)*self.w6 + (self.h4-self.y2)*self.w8 + (self.h5-self.y3)*self.w10 + (self.h6-self.y4)*self.w12\n        self.dw3 = self.dh2 * self.h2*(1-self.h2) * self.x1\n        self.dw4 = self.dh2 * self.h2*(1-self.h2) * self.x2\n        self.db2 = self.dh2 * self.h2*(1-self.h2)\n        \n    def grad_short(self, x, y):\n        self.forward_pass(x)\n        self.y1, self.y2, self.y3, self.y4 = y\n        \n        self.da3 = (self.h3-self.y1)\n        self.da4 = (self.h4-self.y2)\n        self.da5 = (self.h5-self.y3)\n        self.da6 = (self.h6-self.y4)\n        \n        self.dw5 = self.da3*self.h1\n        self.dw6 = self.da3*self.h2\n        self.db3 = self.da3\n        \n        self.dw7 = self.da4*self.h1\n        self.dw8 = self.da4*self.h2\n        self.db4 = self.da4\n        \n        self.dw9 = self.da5*self.h1\n        self.dw10 = self.da5*self.h2\n        self.db5 = self.da5\n        \n        self.dw11 = self.da6*self.h1\n        self.dw12 = self.da6*self.h2\n        self.db6 = self.da6\n        \n        self.dh1 = self.da3*self.w5 + self.da4*self.w7 + self.da5*self.w9 + self.da6*self.w11\n        self.dh2 = self.da3*self.w6 + self.da4*self.w8 + self.da5*self.w10 + self.da6*self.w12\n        \n        self.da1 = self.dh1 * self.h1*(1-self.h1)\n        self.da2 = self.dh2 * self.h2*(1-self.h2)\n        \n        self.dw1 = self.da1*self.x1\n        self.dw2 = self.da1*self.x2\n        self.db1 = self.da1\n        \n        self.dw3 = self.da2*self.x1\n        self.dw4 = self.da2*self.x2\n        self.db2 = self.da2\n    \n    def fit(self, X, Y, epochs=1, learning_rate=1, display_loss=False, display_weight=False):\n        \n        if display_loss:\n            loss = {}\n            \n        for i in tqdm_notebook(range(epochs), total=epochs, unit='epoch'):\n            dw1, dw2, dw3, dw4, dw5, dw6, dw7, dw8, dw9, dw10, dw11, dw12, db1, db2, db3, db4, db5, db6  = [0]*18\n            \n            for x, y in zip(X, Y):\n                self.grad_short(x, y)\n                dw1 += self.dw1\n                dw2 += self.dw2\n                dw3 += self.dw3\n                dw4 += self.dw4\n                dw5 += self.dw5\n                dw6 += self.dw6\n                dw7 += self.dw7\n                dw8 += self.dw8\n                dw9 += self.dw9\n                dw10 += self.dw10\n                dw11 += self.dw11\n                dw12 += self.dw12\n                db1 += self.db1\n                db2 += self.db2\n                db3 += self.db3\n                db4 += self.db4\n                db5 += self.db5\n                db6 += self.db6\n            \n            m = X.shape[0]\n            self.w1 -= learning_rate * dw1 \/ m\n            self.w2 -= learning_rate * dw2 \/ m\n            self.w3 -= learning_rate * dw3 \/ m\n            self.w4 -= learning_rate * dw4 \/ m\n            self.w5 -= learning_rate * dw5 \/ m\n            self.w6 -= learning_rate * dw6 \/ m\n            self.w7 -= learning_rate * dw7 \/ m\n            self.w8 -= learning_rate * dw8 \/ m\n            self.w9 -= learning_rate * dw9 \/ m\n            self.w10 -= learning_rate * dw10 \/ m\n            self.w11 -= learning_rate * dw11 \/ m\n            self.w12 -= learning_rate * dw12 \/ m\n            self.b1 -= learning_rate * db1 \/ m\n            self.b2 -= learning_rate * db2 \/ m\n            self.b3 -= learning_rate * db3 \/ m\n            self.b4 -= learning_rate * db4 \/ m\n            self.b5 -= learning_rate * db5 \/ m\n            self.b6 -= learning_rate * db6 \/ m\n            \n            if display_loss:\n                Y_pred = self.predict(X)\n                loss[i] = log_loss(np.argmax(Y, axis=1), Y_pred)\n                \n            if display_weight:\n                weight_matrix = np.array([[self.b3, self.w5, self.w6, \n                                           self.b4, self.w7, self.w8, \n                                           self.b5, self.w9, self.w10, \n                                           self.b6, self.w11, self.w12], \n                                          [0, 0, 0,\n                                           self.b1, self.w1, self.w2,\n                                           self.b2, self.w3, self.w4, \n                                           0, 0, 0]])\n                weight_matrices.append(weight_matrix)\n        \n        if display_loss:\n            plt.plot(np.fromiter(loss.values(), dtype = float))\n            plt.xlabel('Epochs')\n            plt.ylabel('Log Loss')\n            plt.show()\n            \n    \n    def predict(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(y_pred)\n        return np.array(Y_pred)\n\n    def predict_h1(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h1)\n        return np.array(Y_pred)\n\n    def predict_h2(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h2)\n        return np.array(Y_pred)\n\n    def predict_h3(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h3)\n        return np.array(Y_pred)\n\n    def predict_h4(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h4)\n        return np.array(Y_pred)\n\n    def predict_h5(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h5)\n        return np.array(Y_pred)\n\n    def predict_h6(self, X):\n        Y_pred = []\n        for x in X:\n            y_pred = self.forward_pass(x)\n            Y_pred.append(self.h6)\n        return np.array(Y_pred)","0805d89c":"weight_matrices = []\nffsn_multi_specific = FFSN_MultiClass_Specific()\nffsn_multi_specific.fit(X_train,y_OH_train,epochs=2000,learning_rate=1,display_loss=True, display_weight=True)","1ca1f4a6":"def make_meshgrid(x, y, h=.2):\n    x_min, x_max = x.min() - 0.5, x.max() + 0.5\n    y_min, y_max = y.min() - 0.5, y.max() + 0.5\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    return xx, yy\n\ndef plot_contours(ax, predict, xx, yy, **params):\n    Z = predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    out = ax.contourf(xx, yy, Z, **params)\n\n    return out\n\ndef plot_boundary():\n    xx, yy = make_meshgrid(X_train[:,0], X_train[:,1])\n    predict_functions = [ffsn_multi_specific.predict_h1, ffsn_multi_specific.predict_h2, ffsn_multi_specific.predict_h3,\n                         ffsn_multi_specific.predict_h4, ffsn_multi_specific.predict_h5, ffsn_multi_specific.predict_h6]\n    \n    for i in range(6):\n        \n        fig, ax = plt.subplots(figsize=(10,5))\n        plot_contours(ax, predict_functions[i], xx, yy,\n                      cmap=my_cmap, alpha=0.2)\n        ax.scatter(X_train[:,0], X_train[:,1], c=Y_train, cmap=my_cmap, alpha=0.8)\n        ax.set_xlim(xx.min(),xx.max())\n        ax.set_ylim(yy.min(),yy.max())\n        ax.set_xlabel('X1')\n        ax.set_ylabel('X2')\n        ax.set_title(\"h\"+str(i+1))\n        \n    return True\n\nplot_boundary()","0e76d787":"imageio.mimsave('.\/weights_viz_multi_class.gif', [plot_heat_map(i) for i in range(0,len(weight_matrices),len(weight_matrices)\/\/20)], fps=1)","abecfc34":"HTML('<img src=\"weights_viz_multi_class.gif\">')","d6cea810":"Y_pred_train = ffsn_multi_specific.predict(X_train)\nY_pred_train = np.argmax(Y_pred_train,1)\n\nY_pred_val = ffsn_multi_specific.predict(X_val)\nY_pred_val = np.argmax(Y_pred_val,1)\n\naccuracy_train = accuracy_score(Y_pred_train, Y_train)\naccuracy_val = accuracy_score(Y_pred_val, Y_val)\n\nprint(\"Training accuracy\", round(accuracy_train, 2))\nprint(\"Validation accuracy\", round(accuracy_val, 2))","36c5d13f":"plt.scatter(X_train[:,0], X_train[:,1], c=Y_pred_train, cmap=my_cmap, s=15*(np.abs(np.sign(Y_pred_train-Y_train))+.1))\nplt.show()","dda22267":"### Generate Data","1919b2ca":"### Outline \n1. Use generated data and classes from before\n2. Code the back propagation algorithm for our first FF Netwrok - single weight and all weights.\n3. Visualize working of our first FF network\n4. Code the back propogation algorithm for a larger FF network.\n5. Understand the iterative kernal within the back propagation algorithm","29c425de":"### Our First FF Network","f0a3f204":"### Multi Class Classificatin","649b3058":"<img src='https:\/\/github.com\/taruntiwarihp\/raw_images\/blob\/master\/FirstNetwork-1553414815807.png?raw=true'>","9db123c9":"<img src='https:\/\/github.com\/taruntiwarihp\/raw_images\/blob\/master\/SecondNetwork-1553414815809.png?raw=true'>","0124c2e5":"### Setup"}}