{"cell_type":{"4750a925":"code","5fed2f35":"code","afedb424":"code","606de8a4":"code","5dd42a97":"code","eb1a5770":"code","97e455a3":"code","48da259b":"code","c601294d":"code","85c5689d":"code","16af01df":"code","437a6517":"code","f361d2ae":"code","2f014127":"code","b5b57452":"code","4cbf52fe":"code","b7aaea1e":"code","ea808006":"code","8088be80":"code","9a86ae0e":"code","9bbf8f5f":"code","826d3781":"code","9676467c":"code","0ad8cb9a":"code","52af46b5":"code","d128ded4":"code","19310ad7":"code","0972925d":"code","d1019ab5":"code","d4816cb0":"code","859d1c35":"code","2709ef0c":"code","0e818c12":"code","6e333e90":"code","2814c88d":"code","89b469b6":"code","b66d3ce1":"code","f869fd47":"code","0b3f6329":"code","bb299c6a":"code","fbcf1209":"code","d9304b3e":"code","2803c65f":"code","fcbd6314":"markdown","4c528f6b":"markdown","465f5c3f":"markdown","082be065":"markdown","a4ab5eea":"markdown","a7d4d5e0":"markdown","58fe0b20":"markdown","6ce6a58d":"markdown","3b78ac6a":"markdown","7cee67c3":"markdown","a146840e":"markdown","b5ca26fd":"markdown","4754b833":"markdown","89c8e22f":"markdown","81713b50":"markdown","9624dbb5":"markdown","69267e35":"markdown","627ce098":"markdown","55b34ada":"markdown","aa0c65c7":"markdown","799d897c":"markdown","a24d8ae8":"markdown","603925fc":"markdown","40bb766d":"markdown","ecaf6faa":"markdown","9c18d487":"markdown","0a8ff59d":"markdown","c52b0ec1":"markdown","51203b95":"markdown","6a2febc7":"markdown","a612a5a1":"markdown","9927d616":"markdown","1c3bfdde":"markdown","c87d6ade":"markdown","188dd08f":"markdown","d20714a7":"markdown","7435205d":"markdown","2d8b8808":"markdown","2e76190d":"markdown","189f247d":"markdown","d9904830":"markdown"},"source":{"4750a925":"import os\nimport re\nimport cv2\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nsns.set_style(\"whitegrid\")\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nwarnings.filterwarnings('ignore')\nimport xml.etree.ElementTree as ET\nfrom wordcloud import WordCloud, ImageColorGenerator","5fed2f35":"cwd = os.getcwd()","afedb424":"import tarfile\nimages = tarfile.open('..\/input\/images\/NLMCXR_png.tgz')\nimages.extractall(cwd+'\/xray_images\/')","606de8a4":"xml = tarfile.open('..\/input\/reports\/NLMCXR_reports.tgz')\nxml.extractall(cwd+'\/xray_reports\/')","5dd42a97":"with open(\".\/xray_reports\/ecgen-radiology\/1.xml\", 'r') as f:\n    print(f.read())","eb1a5770":"print('Total Images in data : ', len(os.listdir('.\/xray_images')))\nprint('Total Reports in data : ', len(os.listdir('.\/xray_reports\/ecgen-radiology')))","97e455a3":"#list of count of images\nimg_count = [] \nfor file in os.listdir('.\/xray_reports\/ecgen-radiology'):\n  xml_file = os.path.join('.\/xray_reports\/ecgen-radiology',file)\n  #reading the xml data\n  with open(xml_file, 'r') as f:  \n    data = f.read()\n  #getting all the image names\n  regex = r\"parentImage id.*\" \n  k  = re.findall(regex,data)\n  temp = len(k)\n  img_count.append(temp)\n\nprint(\"The max number of images associated with a report:\",np.array(img_count).max())\nprint(\"The min number of images associated with a report:\",np.array(img_count).min())","48da259b":"plt.figure(figsize = (6,5))\nax = pd.Series(img_count).plot(kind='hist',color='brown')\nax.set_xlabel('Number of images associated with report')\nax.set_title(\"Frequency VS Number of images associated with report\")\nplt.show()","c601294d":"print(\"Images per patient :\\n\")\nprint(pd.Series(img_count).value_counts())","85c5689d":"#Reference : https:\/\/stackoverflow.com\/questions\/2723015\/how-to-find-recursively-for-a-tag-of-xml-using-lxml\n\ncolumns = [\"image_name\", \"image_caption\", \"comparison\", \"indication\", \"findings\", \"impression\"]\ndataframe = pd.DataFrame(columns = columns)\nfor file in tqdm(os.listdir('.\/xray_reports\/ecgen-radiology\/')):\n    #find files with .xml extension only\n    if file.endswith(\".xml\"):\n        # finding root element \n        tree = ET.parse('.\/xray_reports\/ecgen-radiology\/'+file)#parse the xml file\n        \n        findings = tree.find(\".\/\/AbstractText[@Label='FINDINGS']\").text\n        indication = tree.find(\".\/\/AbstractText[@Label='INDICATION']\").text\n        comparision = tree.find(\".\/\/AbstractText[@Label='COMPARISON']\").text\n        impression = tree.find(\".\/\/AbstractText[@Label='IMPRESSION']\").text\n\n        caption = set()\n        name_img = set()\n        #find images in each parentImage tag\n        for iterator in tree.findall(\"parentImage\"):\n            img = iterator.attrib['id']+\".png\"\n            name_img.add(img)\n            #add the corresponding report for each image\n            caption.add('' if iterator.find('caption').text is None else iterator.find('caption').text)\n            \n        # add image details and reports to dataframe\n        dataframe = dataframe.append(pd.Series([','.join(name_img), ','.join(caption), comparision, indication, findings, impression],\n                                                         index = columns), ignore_index = True)\n","16af01df":"dataframe.head()","437a6517":"# Shape of the DataFrame\nprint('Shape of the Dataframe : ', dataframe.shape)","f361d2ae":"# function for obtaining the different information part of the xml report file and preprocessing them and also adding the concernced image and report information to the dataframe\ndef decontracted(phrase): #https:\/\/stackoverflow.com\/a\/47091490\n  \"\"\"\n  performs text decontraction of words like won't to will not\n  \"\"\"\n  # specific\n  phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n  phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n  # general\n  phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n  phrase = re.sub(r\"\\'re\", \" are\", phrase)\n  phrase = re.sub(r\"\\'s\", \" is\", phrase)\n  phrase = re.sub(r\"\\'d\", \" would\", phrase)\n  phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n  phrase = re.sub(r\"\\'t\", \" not\", phrase)\n  phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n  phrase = re.sub(r\"\\'m\", \" am\", phrase)\n  return phrase\n","2f014127":"def preprocess_text(data): #https:\/\/regex101.com\/\n  \"\"\"\n  extracts the information data from the xml file and does text preprocessing on them\n  here info can be 1 value in this list [\"COMPARISON\",\"INDICATION\",\"FINDINGS\",\"IMPRESSION\"]\n  \"\"\"\n  preprocessed = []\n\n  for sentence in tqdm(data.values):\n\n    sentence = BeautifulSoup(sentence, 'lxml').get_text()\n\n    regex = r\"\\d.\" \n    sentence = re.sub(regex,\"\",sentence) #removing all values like \"1.\" and \"2.\" etc\n\n    regex = r\"X+\"\n    sentence = re.sub(regex,\"\",sentence) #removing words like XXXX\n\n    regex = r\"[^.a-zA-Z]\" \n    sentence = re.sub(regex,\" \",sentence) #removing all special characters except for full stop\n\n    regex = r\"http\\S+\"\n    sentence = re.sub(regex,\"\", sentence)\n    sentence = re.sub(r\"[-()\\\"#\/@;:<>{}`+=~|.!?$%^&*'\/+\\[\\]_]+\", \"\", sentence)\n    sentence = re.sub('&', 'and',sentence)\n    sentence = re.sub('@', 'at',sentence)\n    sentence = re.sub('0', 'zero',sentence)\n    sentence = re.sub('1', 'one',sentence)\n    sentence = re.sub('2', 'two',sentence)\n    sentence = re.sub('3', 'three',sentence)\n    sentence = re.sub('4', 'four',sentence)\n    sentence = re.sub('5', 'five',sentence)\n    sentence = re.sub('6', 'six',sentence)\n    sentence = re.sub('7', 'seven',sentence)\n    sentence = re.sub('8', 'eight',sentence)\n    sentence = re.sub('9', 'nine',sentence)\n    sentence = re.sub('year old', \"\", sentence)#Occur multiple times in Indication feature but not necessary     \n    sentence = re.sub('yearold', \"\", sentence)\n    sentence = decontracted(sentence) #perform decontraction\n    sentence = sentence.strip().lower() #strips the begining and end of the string of spaces and converts all into lowercase\n    sentence = \" \".join(sentence.split()) #removes unwanted spaces\n    if sentence==\"\": #if the resulting sentence is an empty string return null value\n      sentence = np.nan\n    preprocessed.append(sentence)\n  return preprocessed","b5b57452":"#Check for Null values in Text columns\nNaN = dataframe.isnull().sum()\nprint(\"Total Nan Values in caption columns -\",NaN[1])\nprint(\"Total Nan Values in comparison columns -\",NaN[2])\nprint(\"Total Nan Values in Indication columns -\",NaN[3])\nprint(\"Total Nan Values in findings columns   -\",NaN[4])\nprint(\"Total Nan Values in Impression columns -\",NaN[5])","4cbf52fe":"#Replacing the nan values\ndataframe['image_caption'] = dataframe['image_caption'].fillna('Unknown')\ndataframe['comparison'] = dataframe['comparison'].fillna('No Comparison')\ndataframe['indication'] = dataframe['indication'].fillna('No Indication')\ndataframe['findings'] = dataframe['findings'].fillna('No Findings')\ndataframe['impression'] = dataframe['impression'].fillna('No Impression')","b7aaea1e":"#Check for Null values in Text columns\nNaN = dataframe.isnull().sum()\nprint(\"Total Nan Values in caption columns -\",NaN[1])\nprint(\"Total Nan Values in comparison columns -\",NaN[2])\nprint(\"Total Nan Values in Indication columns -\",NaN[3])\nprint(\"Total Nan Values in findings columns   -\",NaN[4])\nprint(\"Total Nan Values in Impression columns -\",NaN[5])","ea808006":"#Preprocessing of text features\ndataframe['image_caption'] = preprocess_text(dataframe['image_caption'])\ndataframe['comparison'] = preprocess_text(dataframe['comparison'])\ndataframe['indication'] = preprocess_text(dataframe['indication'])\ndataframe['findings'] = preprocess_text(dataframe['findings'])\ndataframe['impression'] = preprocess_text(dataframe['impression'])","8088be80":"dataframe.head()","9a86ae0e":"dataframe.replace(\"\", float(\"NaN\"), inplace=True)","9bbf8f5f":"#percentage missing values\nprint(dataframe.isnull().sum()*100\/dataframe.shape[0] )","826d3781":"dataframe.dropna(subset = [\"image_name\"], inplace=True)\ndataframe.shape","9676467c":"dataframe.head()","0ad8cb9a":"dataframe['image_count'] = dataframe['image_name'].astype(str).str.split(',').apply(len)","52af46b5":"#Adding word count feature for indication, findings and impression\ndataframe['indication_count'] = dataframe['indication'].astype(str).str.split().apply(lambda x: 0 if x==None else len(x))\ndataframe['findings_count'] = dataframe['findings'].astype(str).str.split().apply(lambda x: 0 if x==None else len(x))\ndataframe['impression_count'] = dataframe['impression'].astype(str).str.split().apply(lambda x: 0 if x==None else len(x))\ndataframe.head()","d128ded4":"#Displaying sample 9 patient X-Ray\nfig, axs = plt.subplots(3, 3, figsize = (9,9), tight_layout=True)\nfor row, figure in zip(dataframe[0:10].itertuples(), axs.flatten()):\n    image=mpimg.imread(\".\/xray_images\/\"+row.image_name.split(',')[0])\n    figure.imshow(image)\nplt.show()","19310ad7":"def show_image_captions(df,sample):\n    '''This function prints the sample images and its other text features.\n       Parameters :\n       - df: dataframe\n       - sample: Number of datapoints'''\n    \n    sampled_row = df.sample(sample)\n\n    for count, row in sampled_row.iterrows():\n        print(\"Caption :\",row['image_caption'])\n        imgs = row[\"image_name\"].split(',')\n        fig, axs = plt.subplots(1, len(imgs), figsize = (10,10), tight_layout=True)\n        iterator = 0\n\n        for img, figure in zip(imgs, axs.flat):\n            image= mpimg.imread(\".\/xray_images\/\"+img)\n            imgplot = axs[iterator].imshow(image)\n            iterator +=1\n        \n        plt.show()\n        print(\"\\nComparision :\",row.get('comparision'))\n        print(\"\\nIndication :\",row.get('indication'))\n        print(\"\\nFindings :\",row.get('findings'))\n        print(\"\\nImpression :\",row.get('impression'))\n        print(\"=\"*100,'\\n')","0972925d":"#showing sample 2 datapoints\nshow_image_captions(dataframe, 2)","d1019ab5":"k = dataframe.loc[(dataframe.comparison == 'none') | (dataframe.comparison == 'no comparison')]\nprint(\"Number of rows with no informnation in comparision label:\",k.shape[0])","d4816cb0":"def unique_words_features(df):\n    '''This function takes pandas dataframe and show barplot of features unique and repeated words \n       Input  =  pandas dataframe or numpy arrays\n       Output =  barplot of the unique words of dataframe '''\n\n    #length of the feature\n    len_total = len(df.tolist())\n\n    #length of unique words in the featue\n    len_unique = len(np.unique(df.tolist()))\n\n    x = ['Total Values', 'Unique Values']\n    y =  [len_total, len_unique]\n\n    plt.bar(x,y,color = 'Teal')\n    plt.ylabel('Word-Count')\n    for index,data in enumerate(y):\n        plt.text(x=index , y =data+1 , s=f\"{data}\" , fontdict=dict(fontsize=15))\n    \n    plt.ylabel('Word-Count')","859d1c35":"plt.figure(figsize = (20,7))\nplt.subplot(131)\nunique_words_features(dataframe['indication'])\nplt.title('Unique-Words in Indication')\nplt.subplot(132)\nunique_words_features(dataframe['findings'])\nplt.title('Unique-Words in Findings')\nplt.subplot(133)\nunique_words_features(dataframe['impression'])\nplt.title('Unique-Words in Impression')\nplt.show()","2709ef0c":"#Printing min,max and median of word_count\nprint(\"Minimum number of word count for Indication is:\",np.min(dataframe.indication_count.values))\nprint(\"Maximum number of word count for Indication is:\",np.max(dataframe.indication_count.values))\nprint(\"median number of word count for Indication is:\",np.median(dataframe.indication_count.values))","0e818c12":"#Plotting PDF and CDF for word_count distribution of Indication feature\nplt.figure(figsize = (12,5))\n# Seaborn PDF\nplt.subplot(121)\nsns.kdeplot(dataframe['indication_count'],shade=True,color='Red')\nplt.title(\"PDF Word-count distribution\")\nplt.subplot(122)\n# Seaborn CDF\nsns.distplot(dataframe['indication_count'], kde_kws={'cumulative': True,'shade': True}, hist=False,color='Lime')\nplt.title(\"CDF Word-count distribution\")\nplt.show()","6e333e90":"#Plotting top 50 frequent sentences of Indication feature\nsentences = dataframe['indication'].value_counts()[:50]\nplt.figure(figsize=(20,5))\nsns.barplot(sentences.index, sentences.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=10)\nplt.xticks(fontsize='large',rotation=90)\nplt.title(\"Indication-Unique sentences\")\nplt.show()","2814c88d":"wordcloud = WordCloud(max_words=500, background_color=\"black\", colormap=\"Set3\").generate(' '.join(dataframe['indication'].astype(str)))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","89b469b6":"#Printing min,max and median of word_count\nprint(\"Minimum number of word count for finding is:\",np.min(dataframe.findings_count.values))\nprint(\"Maximum number of word count for finding is:\",np.max(dataframe.findings_count.values))\nprint(\"Median number of word count for finding is:\",np.median(dataframe.findings_count.values))","b66d3ce1":"#Plotting the PDF for word_count distribution of Findings feature\nplt.figure(figsize = (12,5))\n# Seaborn PDF\nplt.subplot(121)\nsns.kdeplot(dataframe['findings_count'],shade=True,color='Magenta')\nplt.title(\"PDF Word-count distribution\")\nplt.subplot(122)\n# Seaborn CDF\nsns.distplot(dataframe['findings_count'], kde_kws={'cumulative': True,'shade': True}, hist=False,color='Lime')\nplt.title(\"CDF Word-count distribution\")\nplt.show()","f869fd47":"#Plotting top 50 frequent sentences of Findings feature\nsentences = dataframe['findings'].value_counts()[:50]\nplt.figure(figsize=(20,5))\nsns.barplot(sentences.index, sentences.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=10)\nplt.xticks(fontsize='large',rotation=90)\nplt.title(\"Findings-Unique sentences\")\nplt.show()","0b3f6329":"wordcloud = WordCloud(max_words=500, background_color=\"black\", colormap=\"Set3\").generate(' '.join(dataframe['findings'].astype(str)))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","bb299c6a":"#Printing min,max and median of word_count\nprint(\"Minimum number of word count for Impression is:\",np.min(dataframe.impression_count.values))\nprint(\"Maximum number of word count for Impression is:\",np.max(dataframe.impression_count.values))\nprint(\"Median number of word count for Impression is:\",np.median(dataframe.impression_count.values))","fbcf1209":"#Plotting PDF and CDF for word_count distribution of Impression feature\nplt.figure(figsize = (12,5))\n# Seaborn PDF\nplt.subplot(121)\nsns.kdeplot(dataframe['impression_count'],shade=True,color='Red')\nplt.title(\"PDF Word-count distribution\")\nplt.subplot(122)\n# Seaborn CDF\nsns.distplot(dataframe['impression_count'], kde_kws={'cumulative': True,'shade': True}, hist=False,color='Lime')\nplt.title(\"CDF Word-count distribution\")\nplt.show()","d9304b3e":"#Plotting top 50 frequent sentences of Impression feature\nsentences = dataframe['impression'].value_counts()[:50]\nplt.figure(figsize=(20,5))\nsns.barplot(sentences.index, sentences.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=10)\nplt.xticks(fontsize='large',rotation=90)\nplt.title(\"Impression-Unique sentences\")\nplt.show()","2803c65f":"wordcloud = WordCloud(max_words=500, background_color=\"black\", colormap=\"Set3\").generate(' '.join(dataframe['impression'].astype(str)))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","fcbd6314":"<h3>Exploring the Image features :<\/h3>","4c528f6b":"**Displaying Sample Images + Caption :**","465f5c3f":"**Display an XML :**","082be065":"**Observations for Indication feature :**\n\n* Top two most impression are 'no actue cardiopulmonary abnormality' and 'no actue cardiopulmonary findings' above 400 counts in feature.\n* In indication feature, 50% data have less than 4 words per impression, it means only few impression have less words. 99% data have less than 39 words per impression. Only 1% data have legnth above 39.\n* From wordcloud : actue cardiopulmonary, cardiopulmonary abnormality, disease acute, heart size are the highlighted words i.e. these are important words.","a4ab5eea":"**Dataset Preparation :**\n\nReports are in xml format. Need to do xml parsing to read the data and convert it into csv format.\n\n> **Input Features :** Images and we will also take abstract, comparison, indication, findings as text input features.\n\n> **Target variable :** Impression (Text feature).","a7d4d5e0":"Top 50 frequent sentences of Indication feature :","58fe0b20":"**Observation :** We conclude from above features bar plot, That all of them are text features as there are total 3851 entries and and a good chunk of values are unique in all of them i.e, They never repeated. So, they can not be categorical features.","6ce6a58d":"**Observation :** We can see that there are still missing values in the data. We could remove all rows where image_name are null since they represent below 3% of the total datapoints.","3b78ac6a":"**P.S : Initially, I made this notebook on google colab. So, I have used the data from original source by manually uploading it on kaggle, just to keep the path same. We can use the given dataset as well.**","7cee67c3":"**Note :** For text feature analysis, I will not consider the \"Comparision\" label\/feature. The reason behind this is, comparision label has most of its values as 'none' and 'no comparision' (which I had put in place of missing values). So, this will be not much helpful to predict the Target.","a146840e":"**Observation :** \n\n* I did some text preprocessing in XML, for four labels (comparision,indcation, impression and findings). I analyze the text data, then perform tasks like decontraction (can't ---> can not), remove special character, convert in lowercase.\n\n* I have also preprocessed Image caption feature, For getting additional information about the corrosponding image.\n\n* Missing values are also present in image_name feature. As at some place nothing is assigned on image_name.","b5ca26fd":"**Analysis of Findings feature :**","4754b833":"Observations :\n\n* There are 7471 images(X-rays) and 3955 reports in dataset.\n* Few reports have more than image associated with them.","89c8e22f":"**Analysis of Target Feature : Impression**","81713b50":"<h3>Exploring the Text features :<\/h3>","9624dbb5":"**Total Observations :**\n\n* The dataset contains chest X-ray images and radiology text reports. Each image has been paired with four captions such as Impressions, Findings, Comparison and Indication that provide clear descriptions of the salient entities and events.. All the raw texts from xml files are parsed and created the dataset.\n\n* Images are in different shapes. All the X-Ray images are human upper body particularly about Chest part.\n\n* Each patient have multiple x-rays associated with them. The maximum number of images associated with a report can be 5 while the minimum is 0. The highest frequecy of being associated with a report are 2 images.\n\n* Data is incomplete. Because all the features have few missing values except caption. We have to impute the missing values in data preprocessing step.\n\n* In text features there are some unknown values like XXXX XXXXX these are replaced with empty string.\n\n* We have total of 3955 records and Impression is our target variable.\n\n* Most occurring words of diffrent features:\n    > Indication: Chest pain\n\n    > Findings: Pleural effusion\n\n    > Impression: acute cardiopulmonary\n\n* I created wordcloud, for 500 most frequent words of the feature. These are important words. Some of them are: acute, findings, disease, abnormality, high, right, impression, etc.","69267e35":"**Observation :**\n\nWe can see that the maximum number of images associated with a report can be 5 while the minimum is 0. The highest frequecy of being associated with a report are 2 images.","627ce098":"**Observations for Findings feature :**\n\n* In finding feature, 50% data have less than 20 words per findings, 99% data have less than 48 words per findings. Only 1% data have legnth above 48.\n* From wordcloud : pleural, effusion, silhouette, within, normal, lungs, cardiomediastinal are the highlighted words i.e. these are important words.","55b34ada":"**Preprocessing :**","aa0c65c7":"**Add Image count feature :**","799d897c":"Plotting PDF and CDF for word_count distribution of Indication feature :","a24d8ae8":"Word cloud on Impression feature : max 500 words","603925fc":"**Import all the libraries :**","40bb766d":"Word cloud on Indication feature : max 500 words","ecaf6faa":"**Observation :** Out of 3851 rows in data, 2805 rows have No Information in comparision feature\/label.","9c18d487":"Top 50 frequent sentences of Impression feature :","0a8ff59d":"**Feature Identification : Text or Categorical ?**\n\n**Note :** It seems all of the text features are just text features. We can't consider any of them as categorical. We can confirm that by finding unique values and analysing them. Because if it is categorical, then we could get better predictions compared to giving it as a text feature.\n","c52b0ec1":"Plotting PDF and CDF for word_count distribution of Impression feature :","51203b95":"**Below is the sample image and the report :**\n\n\n![](https:\/\/i.imgur.com\/PWo3x47.png)","6a2febc7":"**Adding word count feature for indication, findings and impression :**\n","a612a5a1":"Plotting PDF and CDF for word_count distribution of Findings feature :","9927d616":"Top 50 frequent sentences of Findings feature :","1c3bfdde":"**Observations :**\n\n* Images are in different shapes.\n* All the X-Ray images are human upper body particularly about Chest part.","c87d6ade":"**Displaying sample 9 patient X-Ray :**","188dd08f":"<h2>Business Problem\/Problem Statement :<\/h2>\n\n> Clinical imaging captures enormous amounts of information but most radio-logic data are reported in qualitative and subjective terms. X-Rays are a form of Electromagnetic Radiation that is used for medical imaging. Analysis of X-ray reports is a very important task of radiologists and pathologists to recommend the correct diagnosis to the patients. In this project, we are tackling the image captioning problem for a dataset containing Chest X-ray images. With the help of the state of the art deep learning architecture and optimizing parameters of the architecture. The problem statement here is to find the impression from the given chest X-Ray images. These images are in two types: Frontal and Lateral view of the chest. With these two types of images as input we need to find the impression for given X-Ray. To resolve this problem statement, we will be building a predictive model which involves both image and text processing to build a deep learning model. Image captioning is an interesting problem, where we can learn both Natural Language Processing(NLP) and Computer Vision(CV) techniques.\n\n<h2>Dataset Overview :<\/h2>\n\nOriginal data source : https:\/\/openi.nlm.nih.gov\/\n\nThe dataset contains chest X-ray images and radiology text reports. Each image has been paired with four captions such as Impressions, Findings, Comparison and Indication that provide clear descriptions of the salient entities and events.\n\n> Chest X-ray -There are 7,471 images in .png file format (contain lateral view and frontal view of each patient).\n\n> Radiology Report -There are about 3955 patients text reports available in .XML format.\n\n<h2>Mapping the real-world problem to Machine Learning problem :<\/h2>\n\n> The problem we are going to solve in this case study is Medical Image Captioning. Basically, we have to extract features from images using a Convolutional Neural Network(CNN) from scratch or using transfer learning (preferable as we have less amount of data). Then use these extracted features to predict the captions LSTMs or GRUs. The output would be a sequence of words.\n\n<h2>Real-world constraints :<\/h2>\n\n> Interpretability is moderately important.\n\n> There are no latency constraints.\n\n> As the cost of mistakes in the Medical domain is very high the model should be very good in its predictions. \n\n\n<h2>Performance Metric :<\/h2>\n\n> To evaluate the model performance, I will use bilingual evaluation understudy (BLEU) score. BLEU is a well-acknowledged metric to measure the similarity of one hypothesis sentence to multiple reference sentences. Given a single hypothesis sentence and multiple reference sentences, it returns value between 0 and 1. The metric close to 1 means that the two are very similar. Apparently we need to have a higher BLEU score.\n","d20714a7":"**Observations :**\n\nThe fields which seem to be important and userful are :\n\n* pmcid : Patient id\n* COMPARISION\n* INDICATION\n* FINDINGS\n* IMPRESSIONS (Target Variable)\n* Image id\n\nWe can see there are two image files associated with this report. First I will check the stats of data. Then we will see the maximum and minimum possible value for number of images that are associated with a report.","7435205d":"<h1>Medical Report Generation From X-Ray Images :<\/h1>\n","2d8b8808":"**Observations for Indication feature :**\n\n* Top two most frequent words are 'no indication' and 'chest pain' above 300 counts in feature.\n* In indication feature, 50% data have 7-8 words, 99% text data have less than 10 words in rows. Only 1% data have legnth above 10.\n* From wordcloud : chest, pain, shortness, breath, indication are the highlighted words i.e. these are important words.","2e76190d":"**Checking the data stats :**","189f247d":"Word cloud on Findings feature : max 500 words","d9904830":"**Analysis of Indication feature :**"}}