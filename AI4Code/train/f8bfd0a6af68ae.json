{"cell_type":{"e3de08ac":"code","1980fa0b":"code","637e5b21":"code","b0fe0a85":"code","18372da9":"code","685471ef":"code","3e63956f":"markdown","395781c8":"markdown","462f2887":"markdown","4a3a604f":"markdown","1a1a4fd5":"markdown","4ad3bc1c":"markdown","1d286e7c":"markdown"},"source":{"e3de08ac":"import numpy as np\nimport csv\nimport scipy\nfrom scipy.io import wavfile\nimport os\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, ParameterGrid\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report","1980fa0b":"def custom_database_import(in_path):\n    index_list = os.listdir(in_path)\n    in_all_audios = []\n    # in_class_cnt = {}\n    in_y = []\n\n    index_list = sorted(index_list, key=lambda x: int(x[:-6]))\n    \n    for elem in index_list:\n        in_y.append(elem[-5])\n\n    for filename in index_list:\n        filename = in_path + f\"{filename}\"\n        in_all_audios.append(scipy.io.wavfile.read(filename, mmap=False))\n\n    out_y = np.array(in_y)\n    return in_all_audios, out_y\n\n\ndef custom_eval_database_import(in_path):\n    index_list = os.listdir(in_path)\n    in_all_audios = []\n\n    index_list = sorted(index_list, key=lambda x: int(x[:-4]))\n\n    for filename in index_list:\n        filename = in_path + f\"{filename}\"\n        in_all_audios.append(scipy.io.wavfile.read(filename, mmap=False))\n\n    return in_all_audios\n\n\n\ndef custom_csv_print(in_labels, filename):\n    list_to_print = []\n    for index in range(0, len(in_labels)):\n        row_to_print = []\n        row_to_print.append(index)\n        row_to_print.append(in_labels[index])\n        list_to_print.append(row_to_print)\n\n    with open(filename, 'w', newline='', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Id', 'Predicted'])\n        for index in range(0, len(list_to_print)):\n            writer.writerow(list_to_print[index])\n    return\n\n\ndef custom_preprocess(in_all_audios):\n    frequency_preprocessed = []\n    all_normalized_audios = []\n    all_samples_processed = []\n\n    # Normalization\n    for i in range(0, len(in_all_audios)):\n        single_normalized_audio = in_all_audios[i][1] \/ np.max(np.abs(in_all_audios[i][1]))\n        all_normalized_audios.append(single_normalized_audio)\n\n    # Frequency Domain\n    for i in range(0, len(all_normalized_audios)):\n        freq = np.abs(np.fft.fft(all_normalized_audios[i]))\n        frequency_preprocessed.append(freq[:freq.shape[0]\/\/2])\n\n    # Sampling\n    in_flag = 32\n    for i in range(0, len(frequency_preprocessed)):\n        single_sample_processed = []\n        if in_flag == 32:\n            single_sample_processed.append(\n                np.mean(frequency_preprocessed[i][:1 * len(frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   1 * len(frequency_preprocessed[i]) \/\/ 32:2 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   2 * len(frequency_preprocessed[i]) \/\/ 32:3 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   3 * len(frequency_preprocessed[i]) \/\/ 32:4 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   4 * len(frequency_preprocessed[i]) \/\/ 32:5 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   5 * len(frequency_preprocessed[i]) \/\/ 32:6 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   6 * len(frequency_preprocessed[i]) \/\/ 32:7 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   7 * len(frequency_preprocessed[i]) \/\/ 32:8 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   8 * len(frequency_preprocessed[i]) \/\/ 32:9 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   9 * len(frequency_preprocessed[i]) \/\/ 32:10 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   10 * len(frequency_preprocessed[i]) \/\/ 32:11 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   11 * len(frequency_preprocessed[i]) \/\/ 32:12 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   12 * len(frequency_preprocessed[i]) \/\/ 32:13 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   13 * len(frequency_preprocessed[i]) \/\/ 32:14 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   14 * len(frequency_preprocessed[i]) \/\/ 32:15 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   15 * len(frequency_preprocessed[i]) \/\/ 32:16 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   16 * len(frequency_preprocessed[i]) \/\/ 32:17 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   17 * len(frequency_preprocessed[i]) \/\/ 32:18 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   18 * len(frequency_preprocessed[i]) \/\/ 32:19 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   19 * len(frequency_preprocessed[i]) \/\/ 32:20 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   20 * len(frequency_preprocessed[i]) \/\/ 32:21 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   21 * len(frequency_preprocessed[i]) \/\/ 32:22 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   22 * len(frequency_preprocessed[i]) \/\/ 32:23 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   23 * len(frequency_preprocessed[i]) \/\/ 32:24 * len(\n                                                       frequency_preprocessed[i]) \/\/ 16]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   24 * len(frequency_preprocessed[i]) \/\/ 32:25 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   25 * len(frequency_preprocessed[i]) \/\/ 32:26 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   26 * len(frequency_preprocessed[i]) \/\/ 32:27 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   27 * len(frequency_preprocessed[i]) \/\/ 32:28 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   28 * len(frequency_preprocessed[i]) \/\/ 32:29 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   29 * len(frequency_preprocessed[i]) \/\/ 32:30 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   30 * len(frequency_preprocessed[i]) \/\/ 32:31 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n            single_sample_processed.append(np.mean(frequency_preprocessed[i][\n                                                   31 * len(frequency_preprocessed[i]) \/\/ 32:32 * len(\n                                                       frequency_preprocessed[i]) \/\/ 32]))\n\n        all_samples_processed.append(single_sample_processed)\n\n    return all_samples_processed","637e5b21":"all_test_audios, y = custom_database_import(\"..\/input\/dev\/\")\n\nX = np.array(custom_preprocess(all_test_audios))","b0fe0a85":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nhyp_parameters = {\n    \"random_state\": [0],\n    \"n_estimators\": [100, 1000],\n    \"max_depth\": [None, 2, 4],\n    \"max_features\": ['auto', 'sqrt']\n}\n\nconfig_cnt = 0\ntot_config = 2 * 3 * 2\nmax_f1 = 0\n\nfor config in ParameterGrid(hyp_parameters):\n    config_cnt += 1\n    print(f'Analizing config {config_cnt} of {tot_config} || Config: {config}')\n\n    clf = RandomForestClassifier(**config)\n    clf.fit(X_train, y_train)\n    y_test_pred = clf.predict(X_test)\n    acc = accuracy_score(y_test_pred, y_test)\n    p1, r1, f11, s1 = precision_recall_fscore_support(y_test, y_test_pred)\n    macro_f1 = f11.mean()\n\n    if macro_f1 > max_f1:\n        max_f1 = macro_f1\n        print(f\"-----> Score: {macro_f1}\")\n        print()","18372da9":"hyp_parameters = {\n    \"random_state\": [0],\n    \"hidden_layer_sizes\": [100, 1000],\n    \"activation\": ['logistic', 'relu'],\n    \"alpha\": [0.00001, 0.0001, 0.001]\n}\n\nconfig_cnt = 0\ntot_config = 2 * 2 * 3\nmax_f1 = 0\n\nfor config in ParameterGrid(hyp_parameters):\n    config_cnt += 1\n    print(f'Analizing config {config_cnt} of {tot_config} || Config: {config}')\n\n    clf = MLPClassifier(**config)\n    clf.fit(X_train, y_train)\n    y_test_pred = clf.predict(X_test)\n    acc = accuracy_score(y_test_pred, y_test)\n    p1, r1, f11, s1 = precision_recall_fscore_support(y_test, y_test_pred)\n    macro_f1 = f11.mean()\n\n    if macro_f1 > max_f1:\n        max_f1 = macro_f1\n        print(f\"-----> Score: {macro_f1}\")\n        print()","685471ef":"all_eval_audios = custom_eval_database_import(\"..\/input\/eval\/\")\nX_eval = np.array(custom_preprocess(all_eval_audios))\n\nforest_clf = RandomForestClassifier(max_depth=None, n_estimators=1000)\nforest_clf.fit(X, y)\nforest_y_final_pred = forest_clf.predict(X_eval)\n\nMLP_clf = MLPClassifier(activation='relu', alpha=0.001, hidden_layer_sizes=1000)\nMLP_clf.fit(X, y)\nMLP_y_final_pred = MLP_clf.predict(X_eval)\n\ncustom_csv_print(forest_y_final_pred, 'forest_out')\ncustom_csv_print(MLP_y_final_pred, 'MLP_out')","3e63956f":"We now split the development dataset in test and training in order to tune our model's hyperparameters and check their scores. In this notebook we'll use two simple models:\n- RandomForest Classifier\n- MLP Classifier\n\nThe ParameterGrid cycle will print the score only if it is better than the last best score, the first is always printed.","395781c8":"Setup 1 of 2\n\nLet's import first the libraries we will use.","462f2887":"# AUDIO CLASSIFICATION BEGINNER TUTORIAL\n\nWelcome!\n\nIn this notebook we will build a complete data analytics pipeline to pre-process audio signals and build a classification model able to distinguish between the classes available in the dataset. More specifically, we will load, analyze and prepare the Free Spoken Digit dataset to train and validate a classification model.\n\nAbout the dataset:\nThe dataset for this notebook has been inspired by the Free Spoken Digit Dataset.\nIt is composed of 2,000 recordings of numbers from 0 to 9 with english pronunciation by 4 speakers.\nThus, each digit has a total of 50 recordings per speaker. Each recording is a mono wav file.\nThe sampling rate is 8 kHz.\nThe recordings are trimmed so that they have near minimal silence at the beginnings and ends.\nThe data has been distributed uniformly in two separate collections:\n- Development (dev): a collection composed of 1500 recordings with the ground-truth labels. This collection of data has to be used during the development of the classification model. Each file in this portion of the dataset is a recording named with the following format <Id>_<Label>.wav.\n- Evaluation (eval): a collection composed of 500 recordings without the labels. This collection of data has to be used to produce the submission file containing the labels predicted for each evaluation recording, exploiting the previously built model. Each file in this portion of the dataset is a recording named with the following format <Id>.wav.\n","4a3a604f":"Setup 2 of 2\n\nFirst of all it is better to define two distinct functions to load the data from the input folder, one for the development part of the dataset, one for the evaluation part. Since the labels for the development files are encoded in the name of each recording we will have to retrieve and store that information.\n\nIn these functions we can use the wavfile package from scipy.io to read the wav audio files.\nLoading the data exploiting the wavfile.read() function gives us two main information:\n- The sampling rate of the signal (in samples\/sec)\n- The array with the amplitudes of the signal recorded for each sample\n\nFurthermore we'll define a function for generating the submission file (in case of competition) and a funtion for pre-process the files with three minimal stages in our case:\n- Normalization\n- Frequency domain transformation\n- Sampling","1a1a4fd5":"This conclude the basic audio classification exercise. Better score can be achieved through a better preprocessing, choice of classification algorithm and hyperparameter tuning.\n\nHope you find this notebook helpful and if you do please upvote :)\n\nAlberto","4ad3bc1c":"Finally, after importing the evaluation dataset, we train our models again with the best hyperparameters configurations found but this time on the entire dataset, then we can proceed to classify the evaluation dataset.\n\nRandomForest:\n\nAnalizing config 2 of 12 || Config: {'max_depth': None, 'max_features': 'auto', 'n_estimators': 1000, 'random_state': 0}\n-----> Score: 0.9335100125387632\n\n\nMLP:\n\nAnalizing config 12 of 12 || Config: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 1000, 'random_state': 0}\n-----> Score: 0.9660739092226359","1d286e7c":"We can now start loading the development dataset and pre-process the audio files"}}