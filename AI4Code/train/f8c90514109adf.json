{"cell_type":{"08622f2b":"code","c8e2a4fc":"code","99ac30d3":"code","52f23099":"code","c69a35a1":"code","cd30981a":"code","163f0fbb":"code","02c550a4":"code","72860051":"code","a31331b7":"code","082e7b96":"code","9df28c4e":"code","1ea2ea03":"code","192fd782":"code","789b1ceb":"code","9f6d56e4":"code","b693fa6c":"code","d4bbe8c9":"markdown","c7de3319":"markdown","063e3888":"markdown","fa4972df":"markdown","67489d3d":"markdown","2bc40eca":"markdown","f7b54ab6":"markdown","6612dcf1":"markdown","75cb0aff":"markdown","d95c1134":"markdown","95e3911a":"markdown","c6626a37":"markdown","5b06d423":"markdown","947b9137":"markdown","cd655218":"markdown","1d3b38b4":"markdown"},"source":{"08622f2b":"!pip install -U -t \/kaggle\/working\/ git+https:\/\/github.com\/Kaggle\/learntools.git\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning.ex_tpu import *\nstep_1.check()","c8e2a4fc":"from petal_helper import *","99ac30d3":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","52f23099":"ds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Training:\", ds_train)\nprint (\"Validation:\", ds_valid)\nprint(\"Test:\", ds_test)","c69a35a1":"print(\"Number of classes: {}\".format(len(CLASSES)))\n\nprint(\"First five classes, sorted alphabetically:\")\nfor name in sorted(CLASSES)[:5]:\n    print(name)\n\nprint (\"Number of training images: {}\".format(NUM_TRAINING_IMAGES))","cd30981a":"print(\"Training data shapes:\")\nfor image, label in ds_train.take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy())","163f0fbb":"print(\"Test data shapes:\")\nfor image, idnum in ds_test.take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\nprint(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string","02c550a4":"one_batch = next(iter(ds_train.unbatch().batch(20)))\ndisplay_batch_of_images(one_batch)","72860051":"with strategy.scope():\n    pretrained_model = tf.keras.applications.VGG16(\n        include_top=False,\n        weights=\"imagenet\",\n        input_tensor=None,\n        #input_shape=None,\n        pooling=None,\n        classes=1000,\n        classifier_activation=\"softmax\",\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n    pretrained_model.trainable = False\n    \n    model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        #tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Conv2D(256,4, activation='relu', input_shape=IMAGE_SIZE),\n        #tf.keras.layers.Conv2D(128,2, activation='relu', input_shape=IMAGE_SIZE),\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\n    model.compile(\n        optimizer='adam',\n        loss = 'sparse_categorical_crossentropy',\n        metrics=['sparse_categorical_accuracy'],\n    )\n\nmodel.summary()","a31331b7":"# Define the batch size. This will be 16 with TPU off and 128 with TPU on\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\n\n# Define training epochs for committing\/submitting. (TPU on)\nEPOCHS = 12\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n)","082e7b96":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211,\n)\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    'accuracy',\n    212,\n)","9df28c4e":"cmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\ncm_probabilities = model.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T \/ cmat.sum(axis=1)).T # normalize","1ea2ea03":"score = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\ndisplay_confusion_matrix(cmat, score, precision, recall)","192fd782":"dataset = get_validation_dataset()\ndataset = dataset.unbatch().batch(20)\nbatch = iter(dataset)","789b1ceb":"images, labels = next(batch)\nprobabilities = model.predict(images)\npredictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","9f6d56e4":"test_ds = get_test_dataset(ordered=True)\n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","b693fa6c":"print('Generating submission.csv file...')\n\n# Get image ids from test set and convert to integers\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')\n\n# Write the submission file\nnp.savetxt(\n    'submission.csv',\n    np.rec.fromarrays([test_ids, predictions]),\n    fmt=['%s', '%d'],\n    delimiter=',',\n    header='id,label',\n    comments='',\n)\n\n# Look at the first few predictions\n!head submission.csv","d4bbe8c9":"## Test Predictions ##\n\nCreate predictions to submit to the competition.","c7de3319":"## Explore the Data ##\n\nTry using some of the helper functions described in the **Getting Started** tutorial to explore the dataset.","063e3888":"In this exercise, you'll make your first submission to the [**Petals to the Metal**](https:\/\/www.kaggle.com\/c\/tpu-getting-started) competition.  You'll learn how to accept the competition rules, run a notebook on Kaggle that uses (free!) TPUs, and how to submit your results to the leaderboard.\n\nWe won't cover the code in detail here, but if you'd like to dive into the details, you're encouraged to check out the [tutorial notebook](https:\/\/www.kaggle.com\/ryanholbrook\/create-your-first-submission).\n\nBegin by running the next code cell to set up the notebook.","fa4972df":"Look at examples from the dataset, with true and predicted classes.","67489d3d":"# Going Further #\n\nNow that you've joined the **Petals to the Metal** competition, why not try your hand at improving the model and see if you can climb the ranks! If you're looking for ideas, the *original* flower competition, [Flower Classification with TPUs](https:\/\/www.kaggle.com\/c\/flower-classification-with-tpus), has a wealth of information in its notebooks and discussion forum. Check it out!","2bc40eca":"## Train Model ##","f7b54ab6":"Examine training curves.","6612dcf1":"Examine the shape of the data.","75cb0aff":"## Define Model #","d95c1134":"---\n**[Deep Learning Home Page](https:\/\/www.kaggle.com\/learn\/deep-learning)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum\/161321) to chat with other Learners.*","95e3911a":"## Loading the Competition Data ##","c6626a37":"# Code #\n\nThe code reproduces the code we covered together in **[the tutorial](https:\/\/www.kaggle.com\/ryanholbrook\/create-your-first-submission)**.  If you commit the notebook by following the instructions above, then the code is run for you.\n\n## Load Helper Functions ##","5b06d423":"## Validation ##\n\nCreate a confusion matrix.","947b9137":"**[Deep Learning Home Page](https:\/\/www.kaggle.com\/learn\/deep-learning)**\n\n---\n","cd655218":"Peek at training data.","1d3b38b4":"## Create Distribution Strategy ##"}}