{"cell_type":{"ba395d0a":"code","3a61c4e6":"code","b45dcc28":"code","215fdd88":"code","728fb79f":"code","f75ff78e":"code","d17b2d66":"code","5f20b9ca":"code","30316880":"code","ce543c1b":"code","e351b455":"code","7b9147b3":"code","2f65f2cd":"code","cc6f27c1":"code","67cefcac":"code","b94437fc":"code","87745300":"code","6973fd88":"code","bb2bb542":"code","6fbb4e37":"code","1de3b270":"code","6c02acd9":"code","a5044198":"code","a113533c":"code","f57e68e2":"code","fbcb65c2":"code","cbee7780":"code","e824b5a0":"code","0400c00f":"code","bf2a5e33":"code","258cceb5":"code","e9ab226d":"code","ae7f0593":"code","d8b4bf28":"code","d7d48979":"code","dfc38617":"code","9ba3ade6":"code","35a22fbe":"code","4f1fcb2c":"code","cacd9469":"markdown","2f9b6238":"markdown","73e84928":"markdown","e4adc867":"markdown","c65f0038":"markdown","40a9139e":"markdown","b26b9f62":"markdown","60a0ebf2":"markdown","436be88f":"markdown","183004b7":"markdown","50411322":"markdown","676c0379":"markdown","6817f152":"markdown","9d3d3e1b":"markdown","8972e58a":"markdown","548dd439":"markdown","abf2e47a":"markdown","6536f8e4":"markdown","5afb635d":"markdown","116d9b29":"markdown","af7ff323":"markdown","61247ed9":"markdown","f96473e8":"markdown","edc6b7d4":"markdown","18d40480":"markdown","cba718a8":"markdown","3402793c":"markdown","770801d7":"markdown","937b1e9e":"markdown","445e1d5d":"markdown","3a68172d":"markdown","bd77319f":"markdown","ddac6bae":"markdown"},"source":{"ba395d0a":"import os\nimport pandas as pd\nfrom kaggle.competitions import nflrush\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom keras import Sequential\nfrom keras.layers import Dense,BatchNormalization,Dropout\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import ReduceLROnPlateau\nimport datetime\nimport tqdm","3a61c4e6":"env=nflrush.make_env()\ndf_train=pd.read_csv('..\/input\/nfl-big-data-bowl-2020\/train.csv',low_memory=False)","b45dcc28":"print('The train dataframe contrains {} rows and {} columns'.format(df_train.shape[0],df_train.shape[1]))\n","215fdd88":"df_train.isna().sum().sort_values(ascending=False)","728fb79f":"df_train['WindSpeed'].value_counts()","f75ff78e":"def windspeed(x):\n    x=str(x)\n    if x.isdigit():\n        return int(x)\n    elif (x.isalpha()):\n        return 0\n    elif (x.isalnum()):\n        return int(x.upper().split('M')[0])                             #return 12 incase of 12mp or 12 MPH\n    elif '-' in x:\n        return int((int(x.split('-')[0])+int(x.split('-')[1]))\/2)   # return average windspeed incase of 11 - 20 etc..\n    else:\n        return 0","d17b2d66":"df_train['WindSpeed']=df_train['WindSpeed'].apply(windspeed)\ndf_train['WindSpeed'].fillna(df_train['WindSpeed'].mean(),inplace=True)","5f20b9ca":"sns.distplot(df_train['WindSpeed'])","30316880":"df_train['WindDirection'].value_counts()","ce543c1b":"# This function has been updated to reflect what Subin An (https:\/\/www.kaggle.com\/subinium) mentioned in comments below.\n# WindDirection is indicated by the direction that wind is flowing FROM - https:\/\/en.wikipedia.org\/wiki\/Wind_direction\n\ndef clean_wind_direction(wind_direction):\n    wd = str(wind_direction).upper()\n    if wd == 'N' or 'FROM N' in wd:\n        return 'north'\n    if wd == 'S' or 'FROM S' in wd:\n        return 'south'\n    if wd == 'W' or 'FROM W' in wd:\n        return 'west'\n    if wd == 'E' or 'FROM E' in wd:\n        return 'east'\n    \n    if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n        return 'south west'\n    if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n        return 'south east'\n    if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n        return 'north west'\n    if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n        return 'north east'\n    \n    if 'NW' in wd or 'NORTHWEST' in wd:\n        return 'north west'\n    if 'NE' in wd or 'NORTH EAST' in wd:\n        return 'north east'\n    if 'SW' in wd or 'SOUTHWEST' in wd:\n        return 'south west'\n    if 'SE' in wd or 'SOUTHEAST' in wd:\n        return 'south east'\n\n    return 'none'\n\ndf_train['WindDirection'] = df_train['WindDirection'].apply(clean_wind_direction)","e351b455":"df_train['Humidity'].fillna(method='ffill', inplace=True)\ndf_train['Temperature'].fillna(method='ffill', inplace=True)\n","7b9147b3":"na_map = {\n    'Orientation': df_train['Orientation'].mean(),\n    'Dir': df_train['Dir'].mean(),\n    'DefendersInTheBox': np.math.ceil(df_train['DefendersInTheBox'].mean()),\n    'OffenseFormation': 'UNKNOWN'\n}\n\ndf_train.fillna(na_map, inplace=True)\n","2f65f2cd":"def group_game_weather(weather):\n    rain = [\n        'Rainy', 'Rain Chance 40%', 'Showers',\n        'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n        'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain'\n    ]\n    overcast = [\n        'Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n        'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n        'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n        'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n        'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n        'Partly Cloudy', 'Cloudy'\n    ]\n    clear = [\n        'Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n        'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n        'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n        'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n        'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n        'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny'\n    ]\n    snow  = ['Heavy lake effect snow', 'Snow']\n    none  = ['N\/A Indoor', 'Indoors', 'Indoor', 'N\/A (Indoors)', 'Controlled Climate']\n    \n    if weather in rain:\n        return 'rain'\n    elif weather in overcast:\n        return 'overcast'\n    elif weather in clear:\n        return 'clear'\n    elif weather in snow:\n        return 'snow'\n    elif weather in none:\n        return 'none'\n    \n    return 'none'\n\ndf_train['GameWeather'] = df_train['GameWeather'].apply(group_game_weather)\n\ndf_train['FieldPosition'] = np.where(df_train['YardLine'] == 50, df_train['PossessionTeam'], df_train['FieldPosition'])","cc6f27c1":"def group_stadium_types(stadium):\n    outdoor       = [\n        'Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', \n        'Outdor', 'Ourdoor', 'Outside', 'Outddors', \n        'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl'\n    ]\n    indoor_closed = [\n        'Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', \n        'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed',\n    ]\n    indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n    dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n    dome_open     = ['Domed, Open', 'Domed, open']\n    \n    if stadium in outdoor:\n        return 'outdoor'\n    elif stadium in indoor_closed:\n        return 'indoor closed'\n    elif stadium in indoor_open:\n        return 'indoor open'\n    elif stadium in dome_closed:\n        return 'dome closed'\n    elif stadium in dome_open:\n        return 'dome open'\n    else:\n        return 'unknown'\n    \ndf_train['StadiumType'] = df_train['StadiumType'].apply(group_stadium_types)","67cefcac":"df_train['TimeHandoff'] = df_train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\ndf_train['TimeSnap'] = df_train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\ndf_train['TimeDelta'] = df_train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\ndf_train.drop(['TimeSnap','TimeHandoff'],axis=1,inplace=True)","b94437fc":"df_train['BirthYear']=df_train['PlayerBirthDate'].apply(lambda x : int(x.split('\/')[2]))\ndf_train['GameHour']=df_train['GameClock'].apply(lambda x : int(x.split(':')[0]))\n\ndf_train.drop(['PlayerBirthDate',\"GameClock\"],axis=1,inplace=True)","87745300":"df_train['PlayerHeight']=df_train['PlayerHeight'].apply(lambda x : np.mean(list(map(int,x.split('-')))))\n#df_train.drop('PlayerHeight',axis=1,inplace=True)                                                       ","6973fd88":"def process_defense(x):\n    num=[]\n    num=x.split(',')\n    dl=int(num[0].split(' ')[0])\n    lb=int(num[1].split(' ')[1])\n    db=int(num[2].split(' ')[1])\n    if(len(num)>3):\n         ol=int(num[3].split(' ')[1])\n    else:\n         ol=0\n    return [dl,lb,db,ol]\n\nvalues=df_train['DefensePersonnel'].apply(process_defense)\n","bb2bb542":"u,v,x,y=list(map(list,zip(*values)))","6fbb4e37":"df_train['DL']=u\ndf_train['LB']=v\ndf_train['BL']=x\ndf_train['OL']=y\ndf_train.drop(['DefensePersonnel'],axis=1,inplace=True)","1de3b270":"df_train.shape","6c02acd9":"new_obj=[]\nfor c in df_train.columns:\n    if(df_train[c].dtype != int):\n            try:\n                df_train[c]=df_train[c].astype('float16')\n            except:\n                new_obj.append(c)","a5044198":"lbdic={}\nfor c in new_obj:\n    lb=LabelEncoder()\n    lb=lb.fit(df_train[c].values)\n    lbdic[c]=lb\n    df_train[c]=lb.transform(df_train[c].values)","a113533c":"columns_drop=['GameId','PlayId','NflId','NflIdRusher']\none=[]\ntwo=[]\nmore=[]\nfor col in df_train.drop(columns_drop,axis=1).columns:\n    if df_train[col][:22].nunique() <2:\n        one.append(col)\n    elif df_train[col][:22].nunique() <=2:\n        two.append(col)\n    else:\n        more.append(col)\n        ","f57e68e2":"print('The number of attributes for preprocessing =',len(one)+len(two)+len(more))","fbcb65c2":"new_cols=[]\nfor col in more:\n    for i in range(0,11):\n        new_cols.append(str(col)+'A'+str(i))\n    for i in range(0,11):\n         new_cols.append(str(col)+'B'+str(i))\n        \n        ","cbee7780":"train=pd.DataFrame()\nx=np.tile(np.arange(0,22),14)","e824b5a0":"out=[]\nfor c in more:\n\n    for  i in range(0,22):\n         out.append(df_train[i:len(df_train):22][c].values)\n        \n        \n        \nfor col in zip(new_cols,np.arange(len(out))):\n    train[col]=out[i]\nout=np.array(out).transpose()","0400c00f":"train=pd.DataFrame(data=out,columns=new_cols)\n    ","bf2a5e33":"train.head()","258cceb5":"df_one=df_train.groupby(['PlayId'])[one].first()\nfor col in df_one.columns:\n    train[col]=df_one[col].values","e9ab226d":"sns.distplot(train['Yards'].values)","ae7f0593":"not_object=[]\nobj=[]\nfor col in more+one:\n    if df_train[col].dtype != 'object':\n        not_object.append(col)\n    else:\n        obj.append(col)","d8b4bf28":"X=train.drop('Yards',axis=1)\ny=train['Yards']\n","d7d48979":"def create_model():\n    model=Sequential()\n    model.add(Dense(356,input_shape=[X.shape[1]],activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.4))\n    model.add(Dense(200,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.4))\n    model.add(Dense(256,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.3))\n    model.add(Dense(212,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.3))\n    model.add(Dense(199,activation='sigmoid'))\n\n    optimizer=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)\n    model.compile(optimizer=optimizer,loss=['mse'],metrics=['accuracy'])\n    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                                patience=3, \n                                                verbose=1, \n                                                factor=0.5, \n                                                min_lr=0.00001)\n    return model\n","dfc38617":"def transform_y(X_train,y_train):\n    Y_train=np.zeros((X_train.shape[0],199))\n    for i,yard in enumerate(y_train):\n        Y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n    \n    return Y_train\n\n","9ba3ade6":"from sklearn.model_selection import KFold\nkfold=KFold(n_splits=3,shuffle=True)\n\nfor train_ind,val in kfold.split(X,y):\n    \n    x_train,xval = X.iloc[train_ind],X.iloc[val]\n    y_train,yval= y.iloc[train_ind],y.iloc[val]\n    \n    y_train=transform_y(x_train,y_train)\n    y_val=transform_y(xval,yval)\n    \n    model=None\n    model=create_model()\n    \n    history=model.fit(x_train,y_train,epochs=20,validation_data=[xval,y_val],verbose=0)\n    print('validation accuracy : {}'.format(np.mean(history.history['val_accuracy'])))\n    ","35a22fbe":"def make_prediction(test,sample,env,model,df_train):\n    \n    na_map = {\n    'Orientation': df_train['Orientation'].mean(),\n    'Dir': df_train['Dir'].mean(),\n    'DefendersInTheBox': 7.0,\n    'OffenseFormation': 'UNKNOWN','WindSpeed':df_train['WindSpeed'].mean()\n    }\n\n    test.fillna(na_map, inplace=True)\n    test['Temperature'].fillna(61.0,inplace=True)\n    test['WindSpeed']=test['WindSpeed'].apply(windspeed)\n    #test['WindSpeed'].fillna(df_train['WindSpeed'].mean(),inplace=True)\n\n    test['GameWeather'] = test['GameWeather'].apply(group_game_weather)\n    test['FieldPosition'] = np.where(test['YardLine'] == 50, test['PossessionTeam'], test['FieldPosition'])\n    test['StadiumType'] = test['StadiumType'].apply(group_stadium_types)\n    test['WindDirection'] = test['WindDirection'].apply(clean_wind_direction)\n    \n    test['TimeHandoff'] = test['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    test['TimeSnap'] = test['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    test['TimeDelta'] = test.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    test.drop(['TimeSnap','TimeHandoff'],axis=1,inplace=True)\n   \n    test['PlayerHeight']=test['PlayerHeight'].apply(lambda x : np.mean(list(map(int,x.split('-')))))\n\n\n\n\n    test['BirthYear']=test['PlayerBirthDate'].apply(lambda x : int(x.split('\/')[2]))\n    test['GameHour']=test['GameClock'].apply(lambda x : int(x.split(':')[0]))\n    test.drop(['PlayerBirthDate',\"GameClock\"],axis=1,inplace=True)\n\n    values=test['DefensePersonnel'].apply(process_defense)\n    u,v,x,y=list(map(list,zip(*values)))\n    test['DL']=u\n    test['LB']=v\n    test['BL']=x\n    test['OL']=y\n    test.drop(['DefensePersonnel'],axis=1,inplace=True)\n    \n    new_obj=[]\n    for c in test.columns:\n        if(test[c].dtype != int):\n                try:\n                    test[c]=test[c].astype('float16')\n                except:\n                    new_obj.append(c)\n\n    for c in new_obj:\n        try:\n            test[c]=lbdic[c].transform(test[c].values)\n        except:\n            l=LabelEncoder()\n            test[c]=l.fit_transform(test[c].values)\n            \n    \n    columns_drop=['GameId','PlayId','NflId','NflIdRusher']\n    one=[]\n    two=[]\n    more=[]\n    for col in test.drop(columns_drop,axis=1).columns:\n        if test[col][:22].nunique() <2:\n            one.append(col)\n        elif test[col][:22].nunique() <=2:\n            two.append(col)\n        else:\n            more.append(col)\n        \n\n    new_cols=[]\n    for col in more:\n        for i in range(0,11):\n            new_cols.append(str(col)+'A'+str(i))\n        for i in range(0,11):\n             new_cols.append(str(col)+'B'+str(i))\n\n    \n\n    out=[]\n    for c in more:\n        out.append(test[c].values)\n    \n   \n    new_out=[]\n    for i in out:\n        for j in i:\n            new_out.append(j)\n\n    new_test=pd.DataFrame(data=[new_out],columns=new_cols)\n\n    df_one=test.groupby(['PlayId'])[one].first()\n    for col in df_one.columns:\n        new_test[col]=df_one[col].values\n\n    \n    new_test.fillna(na_map,inplace=True)\n    new_test['Temperature'].fillna(61.0,inplace=True)\n        \n    y_pred=np.zeros((1,199))\n    \n    y_pred = model.predict(new_test)\n    \n        \n    for pred in y_pred:\n        prev = 0\n        for i in range(len(pred)):\n            if pred[i]<prev:\n                pred[i]=prev\n            prev=pred[i]\n    \n    y_pred[:, -1] = np.ones(shape=(y_pred.shape[0], 1))\n    y_pred[:, 0] = np.zeros(shape=(y_pred.shape[0], 1))\n  \n    pred=pd.DataFrame(data=y_pred,columns=sample.columns)\n    env.predict(pred)\n\n    return y_pred\n\n        \n","4f1fcb2c":"#model=create_model()\nfor test, sample in tqdm.tqdm(env.iter_test()):\n    make_prediction(test,sample,env,model,df_train)\n    \nenv.write_submission_file()","cacd9469":"- We will also use learning rate reducer to reduce learning rate and help it converge easily to minima point.","2f9b6238":"Lets check our target variable distribution..","73e84928":"![](https:\/\/media.giphy.com\/media\/Vj9cncmZLtXG0\/giphy.gif)","e4adc867":"- There are many different type of values in Windspeed,we will clean them.\n- We will remove mph\/MPH if its present\n- we will return average value if there is a range of values eg(11 - 15).\n","c65f0038":"### Handling humidity and Temperature\n- We will just fill the values using forward filling technique","40a9139e":"<font color='red' size=5 >Please do upvote if you like my work..<\/font>\n\n<p><font color='blue' size=4>Comments are most welcomed<\/font><\/p>\n\n<font color='green' size=3>Kernel under construction !!!<\/font>\n","b26b9f62":"<font color='red' size=5>Please consider giving an upvote if you feel this notebook was helpful<\/font>\n### Importing Required Libraries","60a0ebf2":"- This function is to prepare and predict on test data.\n- We will have to replicate all the data processing steps that we have done above in this function.\n- This ensures that our data is made fit for prediction.\n- In this competition we will have to use **env.iter_test()** and **env.predict()**.\n","436be88f":"<font color='violet' size=5> What is in this kernel?<\/font>\n- Getting basic idea about the problem.\n- Handling Missing values.\n- Data preparation and processing.\n- Baseline model.\n- Evaluation.\n- Predicting on test. \n- Making our submission.\n","183004b7":"Yeh,We have cleaned all the windspeed values.\n\n### WindDirection values","50411322":" - We will split the DefensePersonnel variable into **DL , LB ,  BL , OL**\n - We will filter them and store them as int variables.","676c0379":"### Handling Game wheather and Stadium types","6817f152":"##  handling missing values...\nThanks to this wonderful\n[Kernel](https:\/\/www.kaggle.com\/jastornaut\/nfl-eda-ftw-lean-clean-and-astroturf-green) by  Jeff Astor.","9d3d3e1b":"## Getting a basic Idea\n- Each row of the train dataframe contains the attributes of a single player in the match with the target value.\n- There are 22 players in a single game.\n- Each of this 22 player participating in game has a row.\n- This mean that we have 509762 \/ 22 = 23171 samples effectively.\n- There are many missing values in different columns,WindSpeed, WindDirection, Temperature, GameWeather, Humidity, StadiumType, and FieldPosition.\n- We will preprocess the data and make it in a trainable form.\n\n","8972e58a":"## Encoding values..\n- In this step we will encode all categorical variables.\n- we will use Label Encoding for this.\n- we will store each of instances in a dictionary for later use during test set preparation.","548dd439":"### DefensePersonnel\n","abf2e47a":"### Submitting to competition..","6536f8e4":"## Gathering Domain knowledge\nI haven't yet watched American football ! If you are a guy like me,this video might be helpful to understand how the game works.To proceed with this competition we need a bit of domain knowledge.So try watching this video..\n[Youtube](https:\/\/www.youtube.com\/watch?v=Ddwp1HyEFRE)\n","5afb635d":"- We will also convert our Target variable to appropriate form.Ie 199 x 1 array.","116d9b29":"## Data preparation","af7ff323":"## Making prediction","61247ed9":"### BirthDate, GameHour and Time\n- we will extract and consider Birth year of each player\n- We will extract and consider Hour from GameClock\n- We will calucate TimeDelta by subtracting TimeSnap from TimeHandoff .\n","f96473e8":"## KFold cross validation..","edc6b7d4":"**Unhide above cell**","18d40480":"## Keras model\n- In this section we will use keras Sequencial models to build our model.\n- We will use Dropout and BatchNormalization.\n","cba718a8":"During the next steps we will actually convert the data to our required form.Each row in the output dataframe will represent a game.Our target variable is Yards,which is the the yardage gained on the play.","3402793c":"#### Setting up the environment","770801d7":"- We will split our train and taget variables.","937b1e9e":"**Unhide above cell**\n- The stadium types and weather is cleaned.","445e1d5d":"In the below session we will process and prepare data inorder to feed it to our model.\n- First,we will drop some columns which are not relevant.\n- we will classify our varibles into three lists ,is one,two and more.\n- one contains variable having unique values.\n- more contains variables having more than 2 different values.","3a68172d":"### Handling values in windspeed","bd77319f":"### Check windspeed","ddac6bae":"In the next step we will group our dataframe using PlayId and select values from columns which are labelled as **one**."}}