{"cell_type":{"3fe31127":"code","6f0d4aa4":"code","d29bd482":"code","0c3d97e1":"code","c86f1ec1":"code","eecb8826":"code","c2731c47":"code","d53c37cf":"code","53f56646":"code","d926f392":"code","14bc71e7":"code","5b809135":"code","881f62e2":"code","e3548192":"code","6b698df2":"code","78736377":"code","973b0ff9":"code","ccd6dc15":"code","d816a869":"code","dccfcddc":"code","f667e72b":"code","7634f78f":"code","1e9dc15e":"markdown"},"source":{"3fe31127":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f0d4aa4":"data = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv')","d29bd482":"pd.set_option(\"display.max_columns\",25)","0c3d97e1":"data.head()","c86f1ec1":"target = data['class'].copy()","eecb8826":"data.drop('class', axis=1, inplace=True)","c2731c47":"data.shape","d53c37cf":"from sklearn.model_selection import train_test_split\n\ntrain_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2, random_state=42)","53f56646":"train_x.info()","d926f392":"train_x.nunique()","14bc71e7":"test_x.nunique()","5b809135":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder()\ntrain_x_enc = ohe.fit_transform(train_x)","881f62e2":"train_x_enc[0,:].todense()","e3548192":"test_x_enc = ohe.transform(test_x)","6b698df2":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\nrfc = RandomForestClassifier()\ndtc = DecisionTreeClassifier(random_state=0)","78736377":"dtc.fit(train_x_enc, train_y)","973b0ff9":"predict = dtc.predict(test_x_enc)\npredict","ccd6dc15":"from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, f1_score, classification_report\n\nprint(confusion_matrix(test_y, predict))","d816a869":"accuracy_score(test_y, predict)","dccfcddc":"f1_score(test_y, predict, average='weighted')","f667e72b":"print(classification_report(test_y, predict))","7634f78f":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncm = confusion_matrix(test_y, predict)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm, annot=True, fmt='d')  # d for decimal\nplt.show()","1e9dc15e":"I will use One Hot Encoder for Encoding the data."}}