{"cell_type":{"8a7cb496":"code","6d5b4d2e":"code","57bdf57a":"code","0a47ed94":"code","4c819718":"code","a5dffa78":"code","f0b5da3d":"code","1af77e01":"code","394a0be1":"code","27f9197d":"code","f322a559":"code","8c4a947c":"code","234b9868":"code","d5ce83e3":"code","2e6ca2c1":"code","ebdc9244":"code","97333468":"code","beba87af":"code","8addcfa8":"code","83a6a23a":"code","dcc947f5":"code","0710baa4":"code","ebaa4c6c":"code","f9db33fd":"markdown","060f2b5f":"markdown","27d7c0a1":"markdown","77a50a13":"markdown","e69ca5b3":"markdown","40721ce8":"markdown","8fa29409":"markdown","23aa20e9":"markdown","07b0aaab":"markdown","18f8a0c1":"markdown","7ceef431":"markdown","e94106ee":"markdown","a41637cd":"markdown","c47d99b6":"markdown","e29beefe":"markdown","71814ae6":"markdown","7b64c09c":"markdown","4643d9fe":"markdown","75ec01b8":"markdown","98538af3":"markdown","052fcfe0":"markdown","24e9641c":"markdown","698cf658":"markdown","04183b1d":"markdown","acfe4d35":"markdown","8c494785":"markdown","47bc8265":"markdown","8faa8047":"markdown","06a2146a":"markdown","c11aa82e":"markdown"},"source":{"8a7cb496":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d5b4d2e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport cufflinks as cf\ncf.go_offline()","57bdf57a":"df=pd.read_csv(\"..\/input\/loan_data.csv\")\ndf.head(3)","0a47ed94":"df.info() \n#There 9578 rows and 14 columns in our dataset","4c819718":"df.describe(include=\"all\") \n#Here we get overall statistical information about the data","a5dffa78":"plt.figure(figsize=(15,10))\ndf[df[\"credit.policy\"] == 1][\"fico\"].hist(color=\"blue\",bins=50,label=\"Credit Policy = 1\",alpha=0.4)\ndf[df[\"credit.policy\"] == 0][\"fico\"].hist(color=\"red\",bins=50,label=\"Credit Policy = 0\",alpha=0.4)\nplt.legend()\n#here we make two different histogram one for those who have credit policy 1 score and the other for those who have 0 score\n# we compare their relative fico credit scores","f0b5da3d":"df[df[\"credit.policy\"] == 1][\"fico\"].iplot(kind=\"hist\",bins=24,colors=\"blue\")\ndf[df[\"credit.policy\"] == 0][\"fico\"].iplot(kind=\"hist\",bins=24,colors=\"orange\")\n#Here we do the same histogram with iplot library because it is interactive\n# this means that when we click somewhere we can get exact score ","1af77e01":"plt.figure(figsize=(15,10))\ndf[df[\"not.fully.paid\"] ==1][\"fico\"].hist(label=\"not fully paid = 1\",alpha=0.6,color=\"blue\",bins=30)\ndf[df[\"not.fully.paid\"] ==0][\"fico\"].hist(label=\"not fully paid = 0\",alpha=0.6,color=\"red\",bins=30)\nplt.xlabel(\"FICO\")\nplt.title(\"The FICO credit score of the borrower\")\nplt.legend()","394a0be1":"plt.figure(figsize=(15,10))\nsns.countplot(x=\"purpose\",hue=\"not.fully.paid\", data=df, palette=\"Set1\")\nplt.title(\"The Counts of Loans by Purpose\")\nplt.legend()","27f9197d":"sns.jointplot(x=\"fico\",y=\"int.rate\",data=df,color=\"green\",space=0.2)","f322a559":"sns.lmplot(x=\"fico\",y=\"int.rate\",data=df,palette=\"Set1\",hue=\"credit.policy\",col=\"not.fully.paid\")","8c4a947c":"df.info() # we look again the overall information about the data","234b9868":"cat_feature=[\"purpose\"]\nfinal_data= pd.get_dummies(df,columns=cat_feature,drop_first=True)\nfinal_data.info()","d5ce83e3":"final_data.head()\n#Now all of the features in the data has been tranformed into 0 and 1 by adding a new column for each of them","2e6ca2c1":"X=final_data.drop(\"not.fully.paid\",axis=1) # All of the columns except from the target column has assigned as the X\ny=final_data[\"not.fully.paid\"] # \"not.fully.paid\" column has been assigned as the target column","ebdc9244":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3) # Here we split our data as training and test dataset","97333468":"from sklearn.tree import DecisionTreeClassifier\ndtree=DecisionTreeClassifier()\ndtree.fit(X_train,y_train) ","beba87af":"predictions=dtree.predict(X_test)\n#df_pred=pd.DataFrame(predictions)\nplt.figure(figsize=(15,10))\nsns.countplot(predictions,palette=\"Set1\")\n","8addcfa8":"from sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(y_test,predictions))","83a6a23a":"print(confusion_matrix(y_test,predictions))","dcc947f5":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=300)","0710baa4":"rfc.fit(X_train,y_train) # We make th new algorithm fit with the training set\nrfc_predictions=rfc.predict(X_test) #We make the algorith to predict y test values","ebaa4c6c":"print(classification_report(y_test,rfc_predictions))\nprint(5*\"\\n\")\nprint(confusion_matrix(y_test,rfc_predictions))","f9db33fd":"**What performed better the random forest or the decision tree?**","060f2b5f":"*Here we create a countplot using seaborn showing the counts of loans by purpose, with the color hue defined by not.fully.paid. ","27d7c0a1":"*The figure shows that the majority of people pay these loans\n\n*The loans fully paid or not fully paid has almost the same distribution, but those not fully paid has lower fico scores","77a50a13":"## 6. Training the Random Forest model\n\n*Now its time to train our new model\n\n* we will create an instance of the RandomForestClassifier class and fit it to our training data from the previous step","e69ca5b3":"Here are what the columns represent:\n* credit.policy: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n* purpose: The purpose of the loan (takes values \"credit_card\", \"debt_consolidation\", \"educational\", \"major_purchase\", \"small_business\", and \"all_other\").\n* int.rate: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n* installment: The monthly installments owed by the borrower if the loan is funded.\n* log.annual.inc: The natural log of the self-reported annual income of the borrower.\n* dti: The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n* fico: The FICO credit score of the borrower.\n* days.with.cr.line: The number of days the borrower has had a credit line.\n* revol.bal: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n* revol.util: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n* inq.last.6mths: The borrower's number of inquiries by creditors in the last 6 months.\n* delinq.2yrs: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n* pub.rec: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).","40721ce8":"* Here we will see the trend between FICO score and interest rate with the following jointplot","8fa29409":"## 7. Predictions and Evaluation\n\n","23aa20e9":"# Great Job!","07b0aaab":"*col parameter of lmplot  gives us the possiblity to create more than one plot according to the number of items inside defined column\n\n*for example in the column \"not fully paid\", we have just two value, so we get two separate plots because we assigned \"not fully paid\" as col parameter\n\n*Here we get more detailed version of the previous plot and get more complex relationship between columns in a single plot","18f8a0c1":"# 2.Exploratory Data Analysis","7ceef431":"## 5. Predictions and Evaluation of Decision Tree Model\n\n**We will make predictions from the test set and create a classification report and a confusion matrix to compare the results","e94106ee":"For this notebook project, we will explore a loan data  which connects people who need money (borrowers) with people who have money (investors). We try to predict whether an investor will invest in people who showed a profile of borrowers with some features.\n","a41637cd":"# 3. Feature Engineering:\n\n","c47d99b6":"*This figure shows that people who have lower FICO score tends to have a credit policy of 0,\nthis means that they do not meet the criteria of borrowing money\n\n*People who have 660 or fewer fico socre do not meet the criteria ","e29beefe":"*The figure above shows that the more fico score increase, the lower interest rate people have better credit get and vice versa","71814ae6":"get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None) -> 'DataFrame'\n    Convert categorical variable into dummy\/indicator variables.\n\nIt turns a categorical variable into a series of zeros and ones, which makes them a lot easier to quantify and compare.","7b64c09c":"*According to classification report; \n            Precision:True Positive\/Total Predicted Positivemacro average of precision(averaging the unweighted mean per label) 0.54(%85 for 0's and %22 for 1's);weighted average (averaging the support-weighted mean per label) is 0.75\n            \n\n","4643d9fe":"According to confusion matrix; \n\n            -True Negatives: 2019\n            -False Positive:398\n            -False Negative:345\n            -True Positive:112","75ec01b8":"*here wreate a histogram of two FICO distributions on top of each other, one for each credit.policy outcome","98538af3":"# 1.Import Libraries and Data\n","052fcfe0":"**Now we will create a classification report from the results. ","24e9641c":"*We need to dela with categorical columns \n\n*We have  a categorical column as **purpose** column \n\n*This means we need to transform the values in this column by using dummy variables so sklearn will be able to understand them. ","698cf658":"* Here we create the following lmplots to see whether the trend between not.fully.paid and credit policy columns. ","04183b1d":"**Show the Confusion Matrix for the predictions.**","acfe4d35":"*Based on countplot of purpose of loan, we can say that debt consolidation is the most popular reason for loan\n\n*Secondly the ratio of fully paid and not fully paid is almost similar across different purposes of loan","8c494785":"* Here we create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.","47bc8265":"*When we compare the results from both of the models we use, Random Forest model performs better than Decision Tree Model\n\n*However, when it comes to the resuts for target column=1 of recall and f1 score, Decision Tree Model performs far better than the other one\n\n*Therefore, before choosing an algorithm we have to keep in mind our priorities and pros and cons of different ML models","8faa8047":"*The results are not good, so we will try Random Forest Model and compare the results with Decision Tree Model","06a2146a":"* Now we will create a similar figure, except this time select by the not.fully.paid column as our target column\n\n*","c11aa82e":"## 4. Splitting the Data and Training Decision Three Model\n\n*Now its time to split our data into a training set and a testing set before applying the algorithm\n\n*we use sklearn to split our data into a training set and a testing set"}}