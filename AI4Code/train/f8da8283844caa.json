{"cell_type":{"c0e94b44":"code","22264c83":"code","f5a51d45":"code","be05e8df":"code","dff9134b":"code","ec4d6e2c":"code","87e6c7ee":"code","3a279ece":"code","b47f711a":"code","ce5f8847":"code","5fbd5026":"code","b5e1af3f":"code","b56099a9":"code","88571344":"code","6e39446d":"code","de67013d":"code","3a98c0ff":"code","aaefe574":"code","6c3b86d8":"code","88bbba78":"code","9654b838":"code","19c1d8ea":"code","e319f835":"code","bd57c998":"code","9152cdb2":"code","063cb360":"code","7a877332":"markdown","cb445a55":"markdown","32b63db7":"markdown","9b03b1c1":"markdown","d0754bd5":"markdown","3a8b1619":"markdown","37e79e25":"markdown","6a6c4fdd":"markdown","2321804d":"markdown","62c268b6":"markdown","bf8703a2":"markdown","6533bfcf":"markdown","f9ae60c0":"markdown"},"source":{"c0e94b44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22264c83":"!\/opt\/conda\/bin\/python3.7 -m pip install --upgrade pip","f5a51d45":"# A dependency of the preprocessing for BERT inputs\n!pip install -q tensorflow-text","be05e8df":"!pip install tf-models-official","dff9134b":"import os\nimport shutil\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nfrom official.nlp import optimization  # to create AdamW optmizer\n\nimport matplotlib.pyplot as plt\n\ntf.get_logger().setLevel('ERROR')","ec4d6e2c":"print(tf.__version__)","87e6c7ee":"# !pip install -q tf-models-official","3a279ece":"!pip install tensorflow-gpu","b47f711a":"tf.test.is_gpu_available(True) # returns True","ce5f8847":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","5fbd5026":"url = 'https:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/aclImdb_v1.tar.gz'\n\ndataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n                                  untar=True, cache_dir='.',\n                                  cache_subdir='')\n\ndataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n\ntrain_dir = os.path.join(dataset_dir, 'train')\n\nprint(train_dir)\n\n# remove unused folders to make it easier to load the data\nremove_dir = os.path.join(train_dir, 'unsup')\nshutil.rmtree(remove_dir)","b5e1af3f":"AUTOTUNE = tf.data.AUTOTUNE\nbatch_size = 32\nseed = 42\n\nraw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    'aclImdb\/train',\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='training',\n    seed=seed)\n\nclass_names = raw_train_ds.class_names\ntrain_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\nval_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    'aclImdb\/train',\n    batch_size=batch_size,\n    validation_split=0.2,\n    subset='validation',\n    seed=seed)\n\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\ntest_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    'aclImdb\/test',\n    batch_size=batch_size)\n\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","b56099a9":"for text_batch, label_batch in train_ds.take(1):\n  for i in range(3):\n    print(f'Review: {text_batch.numpy()[i]}')\n    label = label_batch.numpy()[i]\n    print(f'Label : {label} ({class_names[label]})')","88571344":"bert_model_name = 'small_bert\/bert_en_uncased_L-4_H-512_A-8' \n\nmap_name_to_handle = {\n    'bert_en_uncased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-12_H-768_A-12\/3',\n    'bert_en_cased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_cased_L-12_H-768_A-12\/3',\n    'bert_multi_cased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_multi_cased_L-12_H-768_A-12\/3',\n    'small_bert\/bert_en_uncased_L-2_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-2_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-2_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-2_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-2_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-2_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-2_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-2_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-4_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-4_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-4_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-4_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-4_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-4_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-4_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-4_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-6_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-6_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-6_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-6_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-6_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-6_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-6_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-6_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-8_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-8_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-8_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-8_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-8_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-8_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-8_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-8_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-10_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-10_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-10_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-10_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-10_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-10_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-10_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-10_H-768_A-12\/1',\n    'small_bert\/bert_en_uncased_L-12_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-12_H-128_A-2\/1',\n    'small_bert\/bert_en_uncased_L-12_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-12_H-256_A-4\/1',\n    'small_bert\/bert_en_uncased_L-12_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-12_H-512_A-8\/1',\n    'small_bert\/bert_en_uncased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/small_bert\/bert_en_uncased_L-12_H-768_A-12\/1',\n    'albert_en_base':\n        'https:\/\/tfhub.dev\/tensorflow\/albert_en_base\/2',\n    'electra_small':\n        'https:\/\/tfhub.dev\/google\/electra_small\/2',\n    'electra_base':\n        'https:\/\/tfhub.dev\/google\/electra_base\/2',\n    'experts_pubmed':\n        'https:\/\/tfhub.dev\/google\/experts\/bert\/pubmed\/2',\n    'experts_wiki_books':\n        'https:\/\/tfhub.dev\/google\/experts\/bert\/wiki_books\/2',\n    'talking-heads_base':\n        'https:\/\/tfhub.dev\/tensorflow\/talkheads_ggelu_bert_en_base\/1',\n}\n\nmap_model_to_preprocess = {\n    'bert_en_uncased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'bert_en_cased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_cased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-2_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-2_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-2_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-2_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-4_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-4_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-4_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-4_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-6_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-6_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-6_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-6_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-8_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-8_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-8_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-8_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-10_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-10_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-10_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-10_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-12_H-128_A-2':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-12_H-256_A-4':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-12_H-512_A-8':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'small_bert\/bert_en_uncased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'bert_multi_cased_L-12_H-768_A-12':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_multi_cased_preprocess\/2',\n    'albert_en_base':\n        'https:\/\/tfhub.dev\/tensorflow\/albert_en_preprocess\/2',\n    'electra_small':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'electra_base':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'experts_pubmed':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'experts_wiki_books':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n    'talking-heads_base':\n        'https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/2',\n}\n\ntfhub_handle_encoder = map_name_to_handle[bert_model_name]\ntfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n\nprint(f'BERT model selected           : {tfhub_handle_encoder}')\nprint(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')","6e39446d":"bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)","de67013d":"text_test = ['this is such an amazing movie!']\ntext_preprocessed = bert_preprocess_model(text_test)\n\nprint(f'Keys       : {list(text_preprocessed.keys())}')\nprint(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\nprint(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\nprint(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\nprint(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')","3a98c0ff":"bert_model = hub.KerasLayer(tfhub_handle_encoder)","aaefe574":"bert_results = bert_model(text_preprocessed)\n\nprint(f'Loaded BERT: {tfhub_handle_encoder}')\nprint(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\nprint(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\nprint(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\nprint(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')","6c3b86d8":"def build_classifier_model():\n  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n  encoder_inputs = preprocessing_layer(text_input)\n  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n  outputs = encoder(encoder_inputs)\n  net = outputs['pooled_output']\n  net = tf.keras.layers.Dropout(0.1)(net)\n  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n  return tf.keras.Model(text_input, net)","88bbba78":"classifier_model = build_classifier_model()\nbert_raw_result = classifier_model(tf.constant(text_test))\nprint(tf.sigmoid(bert_raw_result))","9654b838":"tf.keras.utils.plot_model(classifier_model)","19c1d8ea":"loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nmetrics = tf.metrics.BinaryAccuracy()","e319f835":"epochs = 5\nsteps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\nnum_train_steps = steps_per_epoch * epochs\nnum_warmup_steps = int(0.1*num_train_steps)\n\ninit_lr = 3e-5\noptimizer = optimization.create_optimizer(init_lr=init_lr,\n                                          num_train_steps=num_train_steps,\n                                          num_warmup_steps=num_warmup_steps,\n                                          optimizer_type='adamw')","bd57c998":"classifier_model.compile(optimizer=optimizer,\n                         loss=loss,\n                         metrics=metrics)","9152cdb2":"print(f'Training model with {tfhub_handle_encoder}')\nhistory = classifier_model.fit(x=train_ds,\n                               validation_data=val_ds,\n                               epochs=epochs)","063cb360":"loss, accuracy = classifier_model.evaluate(test_ds)\n\nprint(f'Loss: {loss}')\nprint(f'Accuracy: {accuracy}')","7a877332":"## Using the BERT model","cb445a55":"## Selecting BERT Model","32b63db7":"## References\nhttps:\/\/www.tensorflow.org\/tutorials\/text\/classify_text_with_bert\n","9b03b1c1":"## Define Your Model","d0754bd5":"## Loading the BERT model and training","3a8b1619":"## Imports","37e79e25":"## Optimizer","6a6c4fdd":"## Loading Dataset","2321804d":"## Checking GPU Availability","62c268b6":"## Model Training","bf8703a2":"## Installing Dependencies(if needed)","6533bfcf":"## The Preprocessing Model","f9ae60c0":"## Evaluate the model"}}