{"cell_type":{"f98748ee":"code","c0fde9e3":"code","e3900e22":"code","05ce2610":"code","8e8c41ec":"code","251f6234":"code","4dba6e92":"code","b5035a24":"code","e3a3a4dc":"code","6a2f7ac2":"code","17d24f40":"code","821c30bf":"code","40e32898":"code","309a9386":"code","20debf0a":"code","e794a0b0":"code","6a77cafa":"code","3279da44":"code","e2bd07ca":"code","44ac6943":"code","fbb56e26":"code","cac1f19e":"code","3cb04252":"code","566f2718":"code","21fc6a4a":"code","38c5eda4":"code","80ec660d":"code","4a3cfec0":"code","65ac35a8":"code","9b07ca21":"code","05bc24e7":"markdown","e30999ac":"markdown","cc238317":"markdown","110115f0":"markdown","97ad1fa6":"markdown","67484454":"markdown","13114669":"markdown","8ee1c438":"markdown","1ecd9bf0":"markdown","d25e4c70":"markdown","e633177c":"markdown","b013ac0a":"markdown","e411d6af":"markdown","8c219f90":"markdown","aeb9f1c3":"markdown","a3b7e1dd":"markdown","3920d3ec":"markdown","9cf934d6":"markdown"},"source":{"f98748ee":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport os\nimport tensorflow as tf","c0fde9e3":"df = pd.read_csv(\"\/kaggle\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_Metadata.csv\")","e3900e22":"df","05ce2610":"#Splitting train and test data\ndf_train = df[df[\"Dataset_type\"] == \"TRAIN\"]\ndf_test = df[df[\"Dataset_type\"] == \"TEST\"]","8e8c41ec":"import missingno\nmissingno.matrix(df, figsize = (30,10))\n","251f6234":"df.isnull().sum() #check for number of null values","4dba6e92":"df['Label_1_Virus_category']= df['Label_1_Virus_category'].fillna(\"None\")\ndf_train['Label_1_Virus_category']= df_train['Label_1_Virus_category'].fillna(\"None\")\ndf_test['Label_1_Virus_category']=df_test['Label_1_Virus_category'].fillna(\"None\")","b5035a24":"df[df['Label_1_Virus_category'] == \"None\"][\"Label_2_Virus_category\"] = \"None\"\ndf_train[df_train['Label_1_Virus_category'] == \"None\"][\"Label_2_Virus_category\"] = \"None\"\ndf_test[df_test['Label_1_Virus_category'] == \"None\"][\"Label_2_Virus_category\"] = \"None\"","e3a3a4dc":"df.Label.value_counts()","6a2f7ac2":"df.Dataset_type.value_counts()","17d24f40":"print(df_train.Label_2_Virus_category.value_counts())","821c30bf":"print(df_test.Label_2_Virus_category.value_counts())","40e32898":"print(df_train.Label_1_Virus_category.value_counts())","309a9386":"print(df_test.Label_1_Virus_category.value_counts())","20debf0a":"#get test and train dir\ntest_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test'\ntrain_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train'","e794a0b0":"#Here I am loading all the names of different image\nimage_train = os.listdir(train_img_dir)\nimage_train = sorted(image_train)\nimage_train\ndf_train = df_train.sort_values(\"X_ray_image_name\")\n\nimage_test = os.listdir(test_img_dir)\nimage_test = sorted(image_test)\nimage_test\ndf_test = df_test.sort_values(\"X_ray_image_name\")\n\ntrain_images_name = df_train[\"X_ray_image_name\"]\ntest_images_name= df_test[\"X_ray_image_name\"]","6a77cafa":"#Now I am building the numpy array for train images\nimport cv2\nTrainImages = []\nfor i in image_train:\n    if i in train_images_name.values:\n        img = cv2.imread(train_img_dir+'\/'+i)\n        img = cv2.resize(img, (200,200)) #if I dont rescale to (200,200), the memory cannot take it. Also, its good to have all the images in the same size.\n        TrainImages.append(img)\nTrainImages= np.array(TrainImages)\nTrainImages.shape","3279da44":"#I build the numpy array for test images\nTestImages = []\nfor i in image_test:\n    if i in test_images_name.values:\n        img = cv2.imread(test_img_dir+'\/'+i)\n        img = cv2.resize(img, (200,200))    \n        TestImages.append(img)\nTestImages= np.array(TestImages)\nTestImages.shape","e2bd07ca":"#Lets view some of the images, it looks like the image is still fine (I dont know how X ray image works)\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.imshow(TrainImages[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()","44ac6943":"#Lets view some of the images, it looks like te image is still fine (I dont know how X ray image works)\nplt.figure()\nplt.imshow(TrainImages[1])\nplt.colorbar()\nplt.grid(False)\nplt.show()","fbb56e26":"#Create train and test labels for neural network models\ntrain_labels = df_train[\"Label\"] == \"Pnemonia\"\ntrain_labels = np.array(train_labels).astype(int)\ntest_labels = df_test[\"Label\"] == \"Pnemonia\"\ntest_labels = np.array(test_labels).astype(int)","cac1f19e":"#from keras.preprocessing.image import ImageDataGenerator \n#aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, \n#                         height_shift_range=0.2, shear_range=0.15, \n#                         horizontal_flip=True, fill_mode=\"nearest\")","3cb04252":"#Scaling the image\nTrainImages = TrainImages\/255\nTestImages = TestImages\/255","566f2718":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\nTrainImages, train_labels, test_size=0.2, random_state=0)","21fc6a4a":"list = [df, df_train, df_test, train_img_dir, test_img_dir, TrainImages, train_labels, img, train_images_name, test_images_name, image_test, image_train]\ndel list\nimport gc\ngc.collect()\ndf = pd.DataFrame()\ndf_train= pd.DataFrame()\ndf_test=pd.DataFrame()\ntrain_img_dir= []\ntest_img_dir = []\nTrainImages= []\ntrain_labels= []\nimg = []\ntest_images_name = []\ntest_images_name = []\nimg_train = []\nimg_test = []","38c5eda4":"df = pd.DataFrame()","80ec660d":"from tensorflow import keras\n#Initialize the model\nmodel = keras.Sequential()\n#Convolutional layers\nmodel.add(keras.layers.Conv2D(filters = 32, kernel_size = (3, 3),activation='relu', input_shape= (200,200,3)))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(keras.layers.Conv2D(filters = 64, kernel_size = (3, 3),activation='relu', input_shape= (200,200,3)))\nmodel.add(keras.layers.MaxPooling2D(pool_size = 2, strides=2))\nmodel.add(keras.layers.Dropout(0.5))\n\n#Dense layers\nmodel.add(keras.layers.Flatten())\n\n\nmodel.add(keras.layers.Dense(30, activation='relu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(2, activation='softmax'))\n\n#Choose compiler\nmodel.compile(optimizer = 'adam', \n              loss='sparse_categorical_crossentropy',\n              metrics = ['accuracy'])","4a3cfec0":"#What the model looks like\nmodel.summary()","65ac35a8":"#Here I found out that my data augmentation wasnt helping.\n#history = model.fit_generator(aug.flow(X_train, y_train, batch_size= 32),\n#                    epochs = 6, validation_data= (X_test, y_test))\nmodel.fit(X_train, y_train, epochs = 5,validation_data=(X_test, y_test))","9b07ca21":"model.evaluate(TestImages, test_labels)","05bc24e7":"# Data Preprocessing\nWe create numpy arrays with 1 as Pnemonia and 0 as normal\nWe also scale the image to 0 and 1.","e30999ac":"# Scaleimage","cc238317":"## Split train and test data","110115f0":"# Missing values\nFrom looking at the missing value graph, we see that most of the virus name is missing, and some of the virus category is missing.\n\nThere are 1576 Missing values on Virus type (Label 1 Virus Category). That just means the person is normal. We can fill the data on Label 1 Virus Category with None. We can also set Label_2_Virus_category to None\n","97ad1fa6":"# Load the data","67484454":"## Check for values in each column\nSO we have 1576 normal patients to compare with 4334 Corona Patients.\n\nWe dont know most of the source of Corona, only a few labels are provided in Label_2_Virus_category.","13114669":"# Introduction","8ee1c438":"# Import Initial Library","1ecd9bf0":"# Use the model on the test data\nI get about 0.74 accuracy on test model, which is a huge loss of accuracy from validation. I am not sure why this is the case.","d25e4c70":"## Train and Evaluate the model\nbest CV score I can get is about 0.97","e633177c":"## Data Augmentation\nActually, I received lower validation accuracy when doing data augmentation. My theory is because that the X-ray is pretty standard so augment it hurts the prediction","b013ac0a":"# Build the model\nFor the model, similar to other image recognition project, I use CNN.\n\nBy changing different Dense nodes, I find that 30 dense nodes yields better accuracy than (50,100,150) nodes.\n\nFrom some previous experience with image recognition, I only use one Dense hidden layer\n\nI try to use 2 Convolution layers followed by Maxpooling and find that it works the best\n\nI also find that 1 epoch works the best.\n\n","e411d6af":"## View the data\nFrom Viewing the data, I find that there are 2 types of Dataset: TRAIN and TEST, so I split them into df_train and df_test","8c219f90":"Thank you for Kaggle to provide this dataset.\n\nThe purpose of my work is to provide a machine learning model that can predict if a person has corona from their Xray. This can assist doctors when they diagnose corona.\n\nThe dataset includes Xray images of patients with Corona from multiple sources: Virus such as COVID 19 and SARS, bacteria such as Streptococcus, and stress smoking such as ARDS.\n\nI get a high cross-validation result: 0.96 accuracy from the time I run the model. But applying the model with highest cross validation result to the test data only results in 0.75 accuracy","aeb9f1c3":"# Load images\nIn short, I load images and then put them into numpy array to put in the CNN model.\nI rescale the image, which can create some potential problems when dealing with test data.\n","a3b7e1dd":"## Create dummy labels","3920d3ec":"# Exploratory Data Analysis\/Data cleaning\nIts important to understand the data :) \n","9cf934d6":"# Delete the df to release some memory\n\nBasically, Kaggle has a 13gb RAM limit, so I delete some dataframes to safe RAM.\n"}}