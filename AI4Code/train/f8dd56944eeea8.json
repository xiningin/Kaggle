{"cell_type":{"6a25be42":"code","4eb6c6fd":"code","07b05378":"code","58a991e9":"code","c76679e8":"code","5b050067":"code","e1cb88b8":"code","0e8e3a02":"code","01065dc6":"code","b33fdad7":"code","02c4201b":"code","bcad3a00":"code","3e1038ab":"code","440a3b84":"code","2de43eb3":"code","079d5722":"code","4e844eb2":"code","c21352f6":"code","01cb5604":"code","f7f6ad2a":"code","656791f1":"code","e4c08667":"code","df710fe2":"code","2ef63133":"code","2c628778":"code","5b767e91":"code","c4b04a94":"code","e25225cb":"code","30d07002":"code","c416cf23":"code","1ac8f926":"code","ab32f098":"code","1534616b":"code","809da0bb":"code","d812f57f":"code","08d9f61c":"code","4918ca5b":"code","087932f4":"code","2a4be113":"code","eafd6615":"code","3cf71bb0":"code","66954a64":"code","bd941d9a":"code","22b21339":"code","18f0e459":"code","91ea9223":"code","9e8e7af5":"code","a46111c7":"code","fadb5d82":"code","b415268c":"code","c7cd3dae":"code","2d6497c3":"code","2e8a3217":"code","c8bce2dd":"code","e1887b29":"code","be02f533":"code","a78a1efa":"code","1ae05b3e":"code","2d11d7c1":"code","d2405546":"code","e9a0e49a":"code","540fe925":"code","2ff07235":"code","2e9f2b70":"code","d4646a73":"markdown","24be0ae5":"markdown","59b6fcd4":"markdown","6354ab63":"markdown","8751493e":"markdown","c25000ac":"markdown"},"source":{"6a25be42":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-whitegrid')\n\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import KFold, train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom keras.models import Sequential\nfrom keras.models import Model as KerasModel\nfrom keras.layers import Input, Dense, Activation, Reshape,  Conv1D, MaxPooling1D, Flatten\n#Merge,\nfrom keras.layers import Concatenate\nfrom keras.layers.embeddings import Embedding\nfrom keras.callbacks import ModelCheckpoint\n\nimport pickle\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom lightgbm import LGBMRegressor\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport warnings\nwarnings.simplefilter('ignore')","4eb6c6fd":"import tensorflow as tf\nimport tensorflow._api.v2.compat.v1 as tf","07b05378":"df = pd.read_csv('..\/input\/craigslist-carstrucks-data\/vehicles.csv')\ndf.head(2)","58a991e9":"df.shape","c76679e8":"df= df.drop(columns=['id','url', 'region_url',  'image_url', 'description',\n                     'lat', 'long','region','posting_date','Unnamed: 0','paint_color'], axis=1)\n\n'vin','county',","5b050067":"TARGET_COLS = ['price']","e1cb88b8":"numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = df.columns.values.tolist()\nfor col in features:\n    if df[col].dtype in numerics: continue\n    categorical_columns.append(col)","0e8e3a02":"for cat_var in categorical_columns:\n    print (cat_var, df[cat_var].nunique())","01065dc6":"df.loc[df[\"odometer\"]>=3000000.0].shape\ndf.drop(df[df[\"odometer\"]>=3000000.0].index,inplace=True)","b33fdad7":"excellent_odo_mean = df[df['condition'] == 'excellent']['odometer'].mean()\ngood_odo_mean = df[df['condition'] == 'good']['odometer'].mean()\nlike_new_odo_mean = df[df['condition'] == 'like new']['odometer'].mean()\nsalvage_odo_mean = df[df['condition'] == 'salvage']['odometer'].mean()\nfair_odo_mean = df[df['condition'] == 'fair']['odometer'].mean()","02c4201b":"df.loc[df.year>=2019, 'condition'] = df.loc[df.year>=2019, 'condition'].fillna('new')","bcad3a00":"df.loc[df['odometer'] <= like_new_odo_mean, 'condition'] = df.loc[df['odometer'] <= like_new_odo_mean, 'condition'].fillna('like new')\n\ndf.loc[df['odometer'] >= fair_odo_mean, 'condition'] = df.loc[df['odometer'] >= fair_odo_mean, 'condition'].fillna('fair')\n\ndf.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= excellent_odo_mean)), 'condition'] = df.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= excellent_odo_mean)), 'condition'].fillna('excellent')\n\ndf.loc[((df['odometer'] > like_new_odo_mean) & \n       (df['odometer'] <= good_odo_mean)), 'condition'] = df.loc[((df['odometer'] > like_new_odo_mean) & \n       (df['odometer'] <= good_odo_mean)), 'condition'].fillna('good')\n\ndf.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= fair_odo_mean)), 'condition'] = df.loc[((df['odometer'] > good_odo_mean) & \n       (df['odometer'] <= fair_odo_mean)), 'condition'].fillna('salvage')","3e1038ab":"# Odometer - fill with mean\ndf['odometer'] = df.groupby(['year'], sort=False)['odometer'].apply(lambda x: x.fillna(x.mean()))\ndf['odometer'] = df['odometer'].fillna(method=\"ffill\")\ndf['odometer'].isnull().sum()","440a3b84":"#df['paint_color'] = df['paint_color'].fillna(method='ffill')\ndf['drive'] = df['drive'].fillna(method='ffill')\ndf['type'] = df['type'].fillna(method='ffill')\ndf['cylinders'] = df['cylinders'].fillna(method='ffill')\ndf['condition'] = df.groupby(['year'], sort=False)['condition'].apply(lambda x: x.fillna(x.mode()))\ndf['type'] = df.groupby(['year'], sort=False)['type'].apply(lambda x: x.fillna(x.mode()))\ndf['condition'] = df['condition'].fillna(method='ffill')\ndf['type'] = df['type'].fillna(method='ffill')\n\n#data['paint_color'].fillna(data['paint_color'].mode()[0], inplace=True)","2de43eb3":"df.drop(df[df[\"year\"].isna()].index,inplace=True)\ndf['year'] = (df['year']-1900).astype(int)\ndf['odometer'] = df['odometer'].astype(int)","079d5722":"## Price\nrr=sorted(df[\"price\"])\nquantile1, quantile3= np.percentile(rr,[10,90])\n#print(quantile1,quantile3)\n\ndf=df[(df.price < 31500) & (df.price >= 390 )]\n#df.shape","4e844eb2":"df=df.drop([\"size\"],axis=1)","c21352f6":"df['year'] = df['year'].astype(float)\ndf['odometer'] = df['odometer'].astype(float)\ndf['price'] = df['price'].astype(float)\n","01cb5604":"#import pandas_profiling as pp\n#pp.ProfileReport(df)","f7f6ad2a":"df.drop(df[df[\"manufacturer\"].isna()].index,inplace=True)\ndf.drop(df[df[\"model\"].isna()].index,inplace=True)\ndf.drop(df[df[\"fuel\"].isna()].index,inplace=True)\ndf.drop(df[df[\"title_status\"].isna()].index,inplace=True)\ndf.drop(df[df[\"transmission\"].isna()].index,inplace=True)","656791f1":"df= df.drop(columns=['VIN'], axis=1)","e4c08667":"null_values_per_variable = 100 * (df.isnull().sum()\/df.shape[0]).round(3)#.reset_index()\nnull_values_per_variable.sort_values(ascending=False)","df710fe2":"df.shape","2ef63133":"##","2c628778":"X_train, X_test, y_train, y_test = train_test_split(df, df[TARGET_COLS], test_size=0.2, random_state=0)","5b767e91":"np.random.seed(10)\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Concatenate, Reshape, Dropout\nfrom keras.layers.embeddings import Embedding\n\nfrom sklearn.model_selection import StratifiedKFold","c4b04a94":"numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = df.columns.values.tolist()\nfor col in features:\n    if df[col].dtype in numerics: continue\n    categorical_columns.append(col)\n\nfor cat_var in categorical_columns:\n    print (cat_var, df[cat_var].nunique())","e25225cb":"other_cols = [c for c in X_train.columns if (not c in categorical_columns)]","30d07002":"other_cols","c416cf23":"# add both categorical and numerical variables\ncols_use = categorical_columns + other_cols\n\nX_train = X_train[cols_use]\nX_test = X_test[cols_use]\n\ncol_vals_dict = {c: list(X_train[c].unique()) for c in X_train.columns}\n\nembed_cols = []\nfor c in col_vals_dict:\n    if len(col_vals_dict[c])>2:\n        embed_cols.append(c)\n        print(c + ': %d values' % len(col_vals_dict[c])) #look at value counts to know the embedding dimensions\n\nprint('\\n')","1ac8f926":"def getVar(categorical_var):\n    no_of_unique_cat  = df[categorical_var].nunique()\n    embedding_size = min(np.ceil((no_of_unique_cat)\/2), 50 )\n    embedding_size = int(embedding_size)\n    vocab  = no_of_unique_cat #+1\n    return vocab,embedding_size,no_of_unique_cat","ab32f098":"def build_embedding_network():\n    \n    inputs = []\n    embeddings = []\n    \n    # Manufacturer\n    input_manufacturer_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('manufacturer')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_manufacturer_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_manufacturer_cat)\n    embeddings.append(embedding)\n    \n    #model\n    input_model_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('model')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_model_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_model_cat)\n    embeddings.append(embedding)\n    \n    #condition\n    input_condition_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('condition')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_condition_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_condition_cat)\n    embeddings.append(embedding)    \n    \n    #cylinders\n    input_cylinders_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('cylinders')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_cylinders_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_cylinders_cat)\n    embeddings.append(embedding)\n    \n    #fuel\n    input_fuel_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('fuel')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_fuel_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_fuel_cat)\n    embeddings.append(embedding)    \n    \n    #title_status\n    input_title_status_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('title_status')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_title_status_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_title_status_cat)\n    embeddings.append(embedding)    \n\n    #transmission\n    input_transmission_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('transmission')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_transmission_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_transmission_cat)\n    embeddings.append(embedding)    \n\n    #drive\n    input_drive_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('drive')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_drive_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_drive_cat)\n    embeddings.append(embedding)   \n    \n    #type\n    input_type_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('type')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_type_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_type_cat)\n    embeddings.append(embedding)     \n\n    #paint_color\n#     input_paint_color_cat = Input(shape=(1,))\n#     vocab,embedding_size, no_of_unique_cat = getVar('paint_color')\n#     embedding = Embedding(vocab, embedding_size, input_length=1)(input_paint_color_cat)\n#     embedding = Reshape(target_shape=(embedding_size,))(embedding)\n#     inputs.append(input_paint_color_cat)\n#     embeddings.append(embedding)\n    \n    #state\n    input_state_cat = Input(shape=(1,))\n    vocab,embedding_size, no_of_unique_cat = getVar('state')\n    embedding = Embedding(vocab, embedding_size, input_length=1)(input_state_cat)\n    embedding = Reshape(target_shape=(embedding_size,))(embedding)\n    inputs.append(input_state_cat)\n    embeddings.append(embedding)\n\n    #Numeric Variables\n    input_numeric = Input(shape=(3,))\n    embedding_numeric = Dense(8)(input_numeric) \n    inputs.append(input_numeric)\n    embeddings.append(embedding_numeric)\n    \n\n    x = Concatenate()(embeddings)\n    x = Dense(80, activation='relu')(x)\n    x = Dropout(.35)(x)\n    x = Dense(20, activation='relu')(x)\n    x = Dropout(.15)(x)\n    x = Dense(10, activation='relu')(x)\n    x = Dropout(.15)(x)\n    output = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(inputs, output)\n\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    \n    return model","1534616b":"K = 8\nruns_per_fold = 3\nn_epochs = 15\n","809da0bb":"NN = build_embedding_network()","d812f57f":"NN.summary()","08d9f61c":"#NN.summary()\nfrom tensorflow import keras\nkeras.utils.plot_model(NN, show_shapes=True, rankdir=\"LR\")","4918ca5b":"# #X_train['paint_color'].value_counts()\n# X_train['paint_color']=X_train['paint_color'].astype('object')\n# X_train['paint_color'] = X_train['paint_color'].fillna(method='ffill')\n# np.unique(X_train['type'])","087932f4":"## https:\/\/www.kaggle.com\/aquatic\/entity-embedding-neural-net\n\n#converting data to list format to match the network structure\ndef preproc(X_train, X_val, X_test,embed_cols):\n\n    input_list_train = []\n    input_list_val = []\n    input_list_test = []\n    \n    #the cols to be embedded: rescaling to range [0, # values)\n    for c in embed_cols:\n        print(\"NEW COL :\" + c)\n        #raw_vals = np.unique(X_train[c])\n        raw_vals = X_train[c].unique()\n        \n        #print(\"Raw_vals\" + c + str(len(raw_vals)))\n        val_map = {}\n        for i in range(len(raw_vals)):\n            val_map[raw_vals[i]] = i  \n        #print(\"FIN COLUMNS0\")    \n        input_list_train.append(X_train[c].map(val_map).values)\n        input_list_val.append(X_val[c].map(val_map).fillna(0).values)\n        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\n        #print(\"FIN COLUMNS1\")    \n     \n    #the rest of the columns\n    #print(\"OTHER COLUMNS\")\n    other_cols = [c for c in X_train.columns if (not c in categorical_columns)]\n    \n    from sklearn.preprocessing import MinMaxScaler\n    scaler =  MinMaxScaler()\n    X_train[other_cols] = scaler.fit_transform(X_train[other_cols])\n    X_val[other_cols] =  scaler.fit_transform(X_val[other_cols])\n    X_test[other_cols] =  scaler.fit_transform(X_test[other_cols])\n    \n    input_list_train.append(np.array(X_train[other_cols].values,dtype=np.float))\n    input_list_val.append(np.array(X_val[other_cols].values,dtype=np.float))\n    input_list_test.append(np.array(X_test[other_cols].values,dtype=np.float))\n    \n    return input_list_train, input_list_val, input_list_test  ","2a4be113":"trainX, ValX, trainy, Valy = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\nproc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(trainX, ValX, X_test,categorical_columns)\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\nNN.fit(proc_X_train_f,trainy, epochs=2, validation_data=proc_X_val_f)\n","eafd6615":"# len(X_train.columns)\n# other_cols = [c for c in X_train.columns if (not c in categorical_columns)]\n# X_train[other_cols].columns\n\n# proc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(trainX, ValX, X_test,categorical_columns)\n","3cf71bb0":"prediction = NN.predict(proc_X_val_f)\nrms = sqrt(mean_squared_error(prediction, Valy.values))","66954a64":"prediction = NN.predict(proc_X_test_f)\nrms = sqrt(mean_squared_error(prediction, y_test.values))","bd941d9a":"rms","22b21339":"len(prediction),len(y_test)","18f0e459":"categorical_columns","91ea9223":"dfembeddings = pd.DataFrame()\niLayer = 10\nfor each in categorical_columns:    \n    #print(iLayer)\n    dftemp = pd.DataFrame(NN.layers[iLayer].get_weights()[0],\n             columns=[each + str(a) for a in range(NN.layers[iLayer].get_weights()[0].shape[1])])\n    dftemp[each + 'orig'] = df[each].unique()\n    X_train = pd.merge(X_train,dftemp,how='inner', left_on=each, right_on=each + 'orig')\n    \n    #dfembeddings = pd.concat([dfembeddings,dftemp],axis=1)\n    iLayer = iLayer + 1\n    \n#dfembeddings.shape","9e8e7af5":"dfembeddings = pd.DataFrame()\niLayer = 10\nfor each in categorical_columns:    \n    #print(iLayer)\n    dftemp = pd.DataFrame(NN.layers[iLayer].get_weights()[0],\n             columns=[each + str(a) for a in range(NN.layers[iLayer].get_weights()[0].shape[1])])\n    dftemp[each + 'orig'] = df[each].unique()\n    X_test = pd.merge(X_test,dftemp,how='inner', left_on=each, right_on=each + 'orig')\n    \n    #dfembeddings = pd.concat([dfembeddings,dftemp],axis=1)\n    iLayer = iLayer + 1","a46111c7":"X_test.shape,X_train.shape\n","fadb5d82":"# manufacturer: 40 values\n# model: 15288 values\n# condition: 6 values\n# cylinders: 8 values\n# fuel: 5 values\n# title_status: 6 values\n# transmission: 3 values\n# drive: 3 values\n# type: 13 values\n# paint_color: 12 values\n# state: 51 values\n\n# manufacturer = NN.layers[0].get_weights()[0]\n# model = models[1].layers[0].get_weights()[0]\n# condition = models[2].layers[0].get_weights()[0]\n# cylinders = models[3].layers[0].get_weights()[0]\n# fuel = models[4].layers[0].get_weights()[0]","b415268c":"import lightgbm as lgb","c7cd3dae":"params = {\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': {'l2', 'l1'},\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': 0\n}","2d6497c3":"excludecols = ['stateorig','manufacturerorig','conditionorig','cylindersorig',\n               'fuelorig','title_statusorig','modelorig',\n               'transmissionorig','driveorig','typeorig','stateorig']","2e8a3217":"excludecols = excludecols + categorical_columns\ncols = [col for col in X_train.columns if col not in excludecols]\ncols","c8bce2dd":"# create dataset for lightgbm\ntrainX, ValX, trainy, Valy = train_test_split(X_train[cols], y_train, test_size=0.2, random_state=0)\n\n#other_cols = [c for c in df.columns if (not c in categorical_columns)]\n#proc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(trainX, ValX, X_test,categorical_columns,other_cols)\n\nlgb_train = lgb.Dataset(trainX, trainy)\nlgb_eval = lgb.Dataset(ValX, Valy, reference=lgb_train)\n","e1887b29":"print('Starting training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=20,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=5)","be02f533":"y_pred = gbm.predict(X_test[cols], num_iteration=gbm.best_iteration)","a78a1efa":"rms = sqrt(mean_squared_error(y_pred, y_test.values))","1ae05b3e":"rms","2d11d7c1":"no_of_unique_cat  = df['manufacturer'].nunique()\nno_of_unique_cat","d2405546":"!pip install deeptables","e9a0e49a":"import numpy as np\nfrom deeptables.models import deeptable, deepnets\nfrom deeptables.datasets import dsutils\nfrom sklearn.model_selection import train_test_split","540fe925":"%%time\n#y = df.pop('price')\nX = df\ny = y.astype('float64')\nconf = deeptable.ModelConfig(\n    metrics=['RootMeanSquaredError'],\n    nets=['dnn_nets'],\n    #fixed_embedding_dim=True,\n    #stacking_op = 'add',\n    #output_use_bias = False,\n    categorical_columns = categorical_columns,\n    embeddings_output_dim = 20,\n    dnn_params={\n        'hidden_units': ((300, 0.3, True), (300, 0.3, True)),\n        'dnn_activation': 'relu',\n    },\n    earlystopping_patience=5,\n)\n\ndt = deeptable.DeepTable(config=conf)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel, history = dt.fit(X_train, y_train, epochs=100)\n\nscore = dt.evaluate(X_test, y_test)","2ff07235":"score","2e9f2b70":"## finish","d4646a73":"### Data Cleaning","24be0ae5":"### Light GBM","59b6fcd4":"# Approach 2 - DeepTables","6354ab63":"### Neural Network with Embeddings","8751493e":"### Predicting Used Cars Price with Deep Tables and Embeddings","c25000ac":"### Embeddings from Fast AI"}}