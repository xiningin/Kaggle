{"cell_type":{"d8fd93c2":"code","cb8110f0":"code","899733c3":"code","01a1e0fe":"code","7413d30a":"code","d8b93827":"code","925dc1e0":"code","9e189b1b":"code","72cccc23":"code","ecfcc5e9":"markdown","65efa9b8":"markdown","d2ddb2be":"markdown","cf9a659f":"markdown"},"source":{"d8fd93c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb8110f0":"import time\nimport matplotlib.pyplot as plt\nimport seaborn as sns","899733c3":"dirname =  '\/kaggle\/input\/singlecell-rnaseq-exposed-to-multiple-compounds\/'\n\nsubdataset_prefix = 'sciPlex1'\n\nl = os.listdir('\/kaggle\/input\/singlecell-rnaseq-exposed-to-multiple-compounds\/')\nl = list( filter(lambda x: subdataset_prefix  in x, l ) )\nprint(l)\nl","01a1e0fe":"ll = list( filter(lambda x: 'gene.annotations' in x, l ) )\nprint(ll)\ngenes = pd.read_csv(dirname + ll[0], sep = '\\t', header = None)\n\ndisplay(genes)\nll = list( filter(lambda x: 'cell.annotations' in x, l ) )\nprint(ll)\ncells = pd.read_csv(dirname + ll[0], sep = '\\t', header = None)\ndisplay(cells)\n\nll = list( filter(lambda x: 'hashTable' in x, l ) )\nprint(ll)\ninfo_dict_cells2drugs = pd.read_csv(dirname + ll[0],sep = '\\t', header = None)\ndisplay(info_dict_cells2drugs)\ns = set(cells[0]) & set( info_dict_cells2drugs[1] ) \nprint( len(s), len(cells) )\n\nll = list( filter(lambda x: 'hashSampleSheet' in x, l ) )\nprint(ll)\nhashSampleSheet = pd.read_csv(dirname + ll[0],sep = '   ', header = None)\ndisplay(hashSampleSheet)\n\nll = list( filter(lambda x: 'pData' in x, l ) )\nprint(ll)\npData = pd.read_csv(dirname + ll[0],sep = ' ')# , header = None)\ndisplay(pData)\n\n","7413d30a":"print()\nt0 = time.time()\nll = list( filter(lambda x: 'count.matrix' in x, l ) )\nexpression_matrix_in_sparse_form = pd.read_csv( dirname + ll[0], sep = '\\t', header = None)\nprint(np.round(time.time() - t0,2),'seconds passed' )\nprint('Each row in file has format - (i,j, value) - that means that count_matrix[i,j]=value')\nexpression_matrix_in_sparse_form[0] -= 1\nexpression_matrix_in_sparse_form[1] -= 1\ndisplay(expression_matrix_in_sparse_form)\n\nfrom scipy.sparse import csr_matrix\nm = csr_matrix((expression_matrix_in_sparse_form[2].values, (expression_matrix_in_sparse_form[0].values, \n                     expression_matrix_in_sparse_form[1].values))) # , shape=(len(genes), len(cells) ))#.toarray()\n\nprint(m.shape)","d8b93827":"m.shape\nm = m.transpose()\nm.shape","925dc1e0":"pData.head(2)","9e189b1b":"df = pd.DataFrame(index = pData.index, data = range(len(pData) ), columns = ['i'] )\ndf['n.umi'] = pData['n.umi']\ndf['Size_Factor'] = pData['Size_Factor']\n\nf = lambda x: x if not isinstance(x, str)  else x.split('_')[0]\ndf['cell'] = pData['top_oligo'].apply(f )\nprint(( df['cell'].value_counts()) )\n\n#f = lambda x: x if not isinstance(x, str)  else float(x.split('_')[1])\n#df['dose'] = pData['top_oligo'].apply(f )\n#print(np.sort( df['dose'].unique()), df['dose'].isnull().sum() )\n#print(( df['dose'].value_counts()) )\n\n\ndf","72cccc23":"# Consistency check. Check that 'n_umi' is exactly the m.sum(axis = 1)\n(m.sum(axis = 1).ravel() != df['n.umi'].values ).sum()","ecfcc5e9":"# What is about\n\nThe data consists of 4 subdatasets.\nThey are indexed by prefixes 'sciPlex1', 'sciPlex2', 'sciPlex3', 'sciPlex4' in the filenames.\n\nHere is  example how to load sciPlex1.\nOthers can be treated similarly.\nHowever,there are small differnces -  some files (same named)  in different subdatasets use different separators between columns - sometimes '\\t' or ' ' or '   ', and header may exist or not - be careful.\n\nSciPlex3 - is the main (very huge) dataset, see other notebook for details. \n\n\n### 'sciPlex1' brief info\n\n'sciPlex1' - is small subdataset  3025 cells, from human and mouse cell lines. \nIt is \"barnyard\" experiment  mentioned in the paper - mixture of human and mouse -  to demonstrate that technology works quite correctly.\nThat means that there ARE(!) incorrect identifications, but their number is relatively small.\n\nSo in particular, in that data one can rarely see  mouse genes expressed for human cells and vice versa - but it is reasonably rare.\n\n\n#### \"pData\" file contains main info on cells\n\n\nFile 'GSM4150376_sciPlex1_pData.txt' contains information on: cell+drugs+doses+etc... There are 3025 rows - one row - one cell.\n\n\nThe index (=row number) of cell in that file corresponds to its index in the countmatrix  (after transforming csv file with count matrix to sparse countmatrix)\n\n\n\n","65efa9b8":"# Create columns with information on each cell (celltype, etc)","d2ddb2be":"# Load information files: genes annotations, cells info etc...","cf9a659f":"# Load count matrix and convert it to sparse matrix csr_matrix\n"}}