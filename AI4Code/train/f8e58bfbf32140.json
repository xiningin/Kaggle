{"cell_type":{"022979e6":"code","150d9d54":"code","42db3ab5":"code","8f87d8a5":"code","ef057d5e":"code","3fadce7c":"code","5186787f":"code","f262b7c1":"code","e2550c72":"code","5d618c49":"code","d54141c7":"code","5a5db1ab":"code","9ea01ef8":"code","59f0d27c":"code","4491a4b4":"code","1eb56ce2":"code","fa7ab54a":"code","416a96bf":"code","3e6b80bc":"code","6f70e2d8":"code","0e0bb7bd":"code","bde9a176":"code","52857289":"code","64703f71":"code","0ee313a6":"code","a67c1738":"code","cc53bfaf":"code","73ccd6ae":"code","f189c968":"code","e68f29b4":"code","77a55a0c":"code","8f168cdb":"code","a85ac355":"code","6ac4844b":"code","5ec529ea":"code","2adc2288":"code","e8f0eddf":"code","857ce87d":"code","cca2dd4b":"code","b607302d":"code","d63a5ed7":"code","e92719bc":"code","c519dc25":"code","5d99dcb4":"code","fa87590f":"code","4a625946":"code","a3452f1d":"code","50082938":"code","f8af2f41":"code","2cb3b8c2":"code","d44aec9b":"code","e477f97d":"code","0bd1bef4":"code","52c858e1":"code","e41dfada":"code","e006a3cb":"code","b211a4e1":"code","813128f0":"code","64788dcd":"code","b3b87070":"code","0fb92cbb":"markdown","056d3a0d":"markdown","05e9d5ba":"markdown","5f3494da":"markdown","3f6fd2b9":"markdown","3c8ac467":"markdown"},"source":{"022979e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","150d9d54":"import pandas as pd\ndf=pd.read_csv('\/kaggle\/input\/salary-data-simple-linear-regression\/Salary_Data.csv')\n\ndf.head()","42db3ab5":"df.info()","8f87d8a5":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","ef057d5e":"x=df.iloc[:,:-1]\n\nx.head()","3fadce7c":"y=df.iloc[:,-1]\n\ny.head()","5186787f":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20)","f262b7c1":"from sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.linear_model import LinearRegression","e2550c72":"model_1 = LinearRegression()\nmodel_2 = xgb.XGBRegressor()\nmodel_3 = RandomForestRegressor()","5d618c49":"model_1.fit(x_train, y_train)\nmodel_2.fit(x_train, y_train)\nmodel_3.fit(x_train, y_train)","d54141c7":"pred_1 = model_1.predict(x_test)\npred_2 = model_2.predict(x_test)\npred_3 = model_3.predict(x_test)","5a5db1ab":"pred_final = (pred_1+pred_2+pred_3)\/3.0","9ea01ef8":"print(mean_squared_error(y_test, pred_final))","59f0d27c":"from sklearn.ensemble import GradientBoostingRegressor","4491a4b4":"model = GradientBoostingRegressor()","1eb56ce2":"model.fit(x_train, y_train)","fa7ab54a":"pred_final = model.predict(x_test)","416a96bf":"print(mean_squared_error(y_test, pred_final))","3e6b80bc":"import pandas as pd\ndf=pd.read_csv('\/kaggle\/input\/housedata\/data.csv')\n\ndf.head()","6f70e2d8":"df.info()","0e0bb7bd":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","bde9a176":"x=df.iloc[:,[2,3,4,5,6,7,8,9,10,11,12,13]]\n\nx.head()","52857289":"y=df.iloc[:,1]\n\ny.head()","64703f71":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)","0ee313a6":"from sklearn.ensemble import GradientBoostingRegressor","a67c1738":"model = GradientBoostingRegressor()","cc53bfaf":"model.fit(x_train, y_train)","73ccd6ae":"pred_final = model.predict(x_test)","f189c968":"print(mean_squared_error(y_test, pred_final))","e68f29b4":"from sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.linear_model import LinearRegression","77a55a0c":"model_1 = LinearRegression()\nmodel_2 = xgb.XGBRegressor()\nmodel_3 = RandomForestRegressor()","8f168cdb":"model_1.fit(x_train, y_train)\nmodel_2.fit(x_train, y_train)\nmodel_3.fit(x_train, y_train)","a85ac355":"pred_1 = model_1.predict(x_test)\npred_2 = model_2.predict(x_test)\npred_3 = model_3.predict(x_test)","6ac4844b":"pred_final = (pred_1+pred_2+pred_3)\/3.0","5ec529ea":"print(mean_squared_error(y_test, pred_final))","2adc2288":"df=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\ndf.head()","e8f0eddf":"df.info()","857ce87d":"df.isnull().sum()","cca2dd4b":"df.describe()","b607302d":"df.shape","d63a5ed7":"r=['PassengerId','Name','Ticket','Cabin']\ndf1=df.drop(r,axis=1).copy()\ndf1.head()","e92719bc":"df1.info()","c519dc25":"df1.isnull().sum()","5d99dcb4":"df1[\"Embarked\"]=df1[\"Embarked\"].fillna(df1[\"Embarked\"].mode()[0])\n\ndf1['Age']=df1['Age'].fillna(df1['Age'].mean())","fa87590f":"df1.head()","4a625946":"cc=['Sex','Embarked']\n\ndummy=pd.get_dummies(df1[cc])\ndummy.head()","a3452f1d":"df1=df1.drop(cc,axis=1)\n\ndf1","50082938":"df2=pd.concat([df1,dummy],axis=1)\n\ndf2.head()","f8af2f41":"x=df2.iloc[:,1:]\n\nx.head()","2cb3b8c2":"y=df2.iloc[:,0]\n\ny.head()\n\ny.unique()\n\ny.value_counts()","d44aec9b":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,stratify=y,test_size=0.25)","e477f97d":"from sklearn.metrics import log_loss\nfrom sklearn.ensemble import VotingClassifier","0bd1bef4":"from sklearn import tree\ndtc = tree.DecisionTreeClassifier(random_state=0)\ndtc.fit(x_train, y_train)\n\ndtc.score(x_test,y_test)","52c858e1":"from sklearn.ensemble import RandomForestClassifier\n\nclf=RandomForestClassifier(n_estimators=30)\nclf.fit(x_train,y_train)\n\nclf.score(x_test,y_test)","e41dfada":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(x_train,y_train)\n\nnb.score(x_test,y_test)","e006a3cb":"model_1 = tree.DecisionTreeClassifier(random_state=0)\nmodel_2 = RandomForestClassifier(n_estimators=30)\nmodel_3 = GaussianNB()","b211a4e1":"final_model = VotingClassifier(\n    estimators=[('dtc', model_1), ('clf', model_2), ('nb', model_3)], voting='hard')","813128f0":"final_model.fit(x_train, y_train)","64788dcd":"pred_final = final_model.predict(x_test)","b3b87070":"print(log_loss(y_test, pred_final))","0fb92cbb":"Averaging method","056d3a0d":"Ada Boost Technique","05e9d5ba":"Voting method","5f3494da":"Ada Boost method","3f6fd2b9":"2nd Dataset","3c8ac467":"Averaging technique"}}