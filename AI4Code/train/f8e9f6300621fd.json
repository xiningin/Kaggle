{"cell_type":{"716409a3":"code","0dc325f5":"code","c92c69b3":"code","49ef0a4a":"code","9e081d4b":"code","ad32fa6f":"code","9e1b0dac":"code","c512169c":"code","a60a6218":"code","7083b97f":"code","74284d32":"code","c6d92511":"code","af304ae3":"code","4c8ce0d9":"code","678fdb13":"code","71c3f4f9":"code","100d25f3":"code","117a2709":"code","3131a5a3":"code","dd59077b":"code","42d4be01":"code","71f60d2c":"markdown","a225c68b":"markdown","af0f9bf9":"markdown","d1ec5ad1":"markdown","3c653e2e":"markdown","a06ea54f":"markdown","1097c509":"markdown"},"source":{"716409a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0dc325f5":"df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","c92c69b3":"df.describe()","49ef0a4a":"X = df.iloc[:, 1:]\ny = df.iloc[:, 0]\nX\/=255","9e081d4b":"from sklearn.model_selection import train_test_split\nimport tensorflow as tf\n","ad32fa6f":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.03, stratify=y)","9e1b0dac":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)","c512169c":"y_train = pd.get_dummies(y_train).values\ny_test = pd.get_dummies(y_test).values","a60a6218":"X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","7083b97f":"input_shape = X_train.shape[1:]","74284d32":"from tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\n","c6d92511":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epochs,logs={}):\n        if logs.get('val_loss') < 0.007:\n            print(\"\\nReached desired loss\")\n            self.model.stop_training = True\n\ncallbacks = myCallback()","af304ae3":"X_input = Input(input_shape)\n\nX = Conv2D(24, (5, 5), strides = (1, 1), name = 'conv0')(X_input)\nX = BatchNormalization(axis = -1, name = 'bn1')(X)\nX = Activation('relu')(X)\nX = Dropout(0.2)(X)\nX = MaxPooling2D((2, 2), name='max_pool')(X)\nX = Conv2D(48, (3, 3), strides = (1, 1), name = 'conv1')(X)\nX = BatchNormalization(axis = -1, name = 'bn2')(X)\nX = Activation('relu')(X)\nX = Dropout(0.2)(X)\nX = MaxPooling2D((2, 2), name='max_pool2')(X)\nX = Conv2D(96, (3, 3), strides = (1, 1), padding='same',name = 'conv2')(X)\nX = BatchNormalization(axis = -1, name = 'bn2_2')(X)\nX = Activation('relu')(X)\nX = Dropout(0.2)(X)\nX = Flatten()(X)\n\nX = Dense(128, name = 'lay3')(X)\nX = BatchNormalization(axis = -1, name = 'bn3')(X)\nX = Activation('relu')(X)\n\n\nX = Dense(10, activation='softmax', name='output')(X)\nmodel = Model(inputs = X_input, outputs = X, name='MnistDigit')","4c8ce0d9":"model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","678fdb13":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rotation_range=15,  \n        zoom_range = 0.10,  \n        width_shift_range=0.1, \n        height_shift_range=0.1)\n\ndatagen.fit(X_train)\n#datagen = keras.preprocessing.image.ImageDataGenerator()\n#datagen =  datagen.fit(X_train)","71c3f4f9":"#model.fit(x=X_train, y = y_train, validation_data=(X_test,y_test), epochs = 450, batch_size=128, callbacks=[callbacks])\n\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n          epochs=100,validation_data=(X_test,y_test), callbacks=[callbacks])","100d25f3":"df_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nX_pred = np.array(df_test)\nX_pred = X_pred\/255.0","117a2709":"X_pred = X_pred.reshape((X_pred.shape[0], 28, 28, 1))\ny_pred = model.predict(X_pred)","3131a5a3":"y_pred = np.argmax(y_pred, axis=1)\ny_pred[:5]","dd59077b":"result = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nresult['Label'] = y_pred\nresult.head()","42d4be01":"result.to_csv('result.csv', index=False)","71f60d2c":"### Data Augmentation step","a225c68b":"## One-hot for y (10-digits)","af0f9bf9":"### CNN implementation with use of GPU power","d1ec5ad1":"## Because large amount of data, test_size percentage is lowered","3c653e2e":"## Extract X and y with normalization of X","a06ea54f":"## Preparing input for CNN","1097c509":"### 3 Conv2D layers without with 2 Pooling layers. (BN Dropout + Data Augmentation)"}}