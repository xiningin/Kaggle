{"cell_type":{"ba126446":"code","fb6fa28b":"code","0650281d":"code","caebf17d":"code","8527cfa1":"code","6e6d1fc8":"code","fe695914":"code","fc73b358":"code","9ea101bb":"code","5ce6c6e0":"code","2c8e1f7f":"code","f50e3fb0":"code","b8599f7c":"code","7fba94c6":"code","b822382e":"code","2ae7fe3b":"markdown","60b50111":"markdown","6c1fd39c":"markdown","d66465fc":"markdown","17a77105":"markdown","ef4223b9":"markdown","dfddf67a":"markdown","cdbfd9da":"markdown","83eb4327":"markdown","cc52ba46":"markdown","a1b08bae":"markdown","198dda42":"markdown","7d7c8581":"markdown","4af47a60":"markdown","2350f14c":"markdown","cc151251":"markdown"},"source":{"ba126446":"%pylab inline --no-import-all\nimport pandas as pd\nimport seaborn as sns\nimport tqdm\nimport ipywidgets as widgets\nimport gc\nimport pickle\nimport re\nimport os","fb6fa28b":"DATA_PATH = \"..\/input\/data-conversion-to-speedup-future-imports\/\"\nSAVE_PATH = \".\"","0650281d":"INTERACTIVE = False","caebf17d":"with open(os.path.join(DATA_PATH, \"train.pkl\"), 'rb') as f:\n    train_data = pickle.load(f)\nprint(f\"loaded train data with {len(train_data)} rows\")\ngc.collect()","8527cfa1":"nas_df = pd.DataFrame([0 for col in train_data.columns], columns=[\"NA's count\"], index=train_data.columns)\nfor col in train_data.columns:\n    nas = train_data[col].isna().sum()\n    nas_df.loc[col, (\"NA's count\")] = nas\n    \nnas_df = nas_df[nas_df[\"NA's count\"] != 0]\nnas_df.sort_values(by=\"NA's count\", ascending=False, inplace=True)\n\nnas_df[\"% of NA's\"] = nas_df[\"NA's count\"] * 100 \/ len(train_data)\nnas_df","6e6d1fc8":"to_del = [\n    'DefaultBrowsersIdentifier',\n    'Census_ProcessorClass',\n    'Census_InternalBatteryType',\n    'Census_IsFlightingInternal',\n    'Census_IsWIMBootEnabled'\n]\ntrain_data.drop(columns=to_del, inplace=True)","fe695914":"train_data.SmartScreen.describe()","fc73b358":"train_data.OrganizationIdentifier.astype('category').describe()","9ea101bb":"def replace_nas(data: pd.DataFrame, col: str, type_: str):\n    nas = data[col].isna().sum()\n    if nas > 0:        \n        if type_ == 'category' or type_ == 'bool':\n            mode = data[col].mode().values[0]\n            print(f\"replacing NAs in {col} with {mode}\")\n            data.loc[:, col][data.loc[:, col].isna()] = mode\n        else:\n            median = data[col].median()\n            print(f\"replacing NAs in {col} with {median}\")\n            data.loc[:, col][data.loc[:, col].isna()] = median\n\ndef convert_types(data: pd.DataFrame):\n    converter_rules = {\n        ('category',)         : ['MachineIdentifier', 'OsBuildLab'],\n        ('int32',)            : ['AVProductsInstalled', 'AVProductsEnabled', 'Census_ProcessorCoreCount'],\n        ('bool',)             : ['(.*_)?Is.*', '(.*_)?Has.*', 'Firewall'],\n        ('int32', 'category') : ['SMode', 'RtpStateBitfield', 'Census_OSBuildRevision', \n                                 'CityIdentifier', 'AVProductStatesIdentifier', 'UacLuaenable',\n                                 'Census_OEMModelIdentifier', 'Census_FirmwareVersionIdentifier'],\n        ('int16', 'category') : ['.*Identifier.*', 'OsBuild', 'OsSuite', 'Census_OSBuildNumber']\n    }\n    \n    used_cols = set()\n    for types, columns in converter_rules.items():\n        for col_rule in columns:\n            for col in data.columns:\n                if col not in used_cols and re.match(col_rule, col):\n                    replace_nas(data, col, types[-1])\n                    for type_ in types:\n                        data[col] = data[col].astype(type_)\n                    used_cols.add(col)\n    rest_cols = set(data.columns).difference(used_cols)\n    for col in data.columns:\n        replace_nas(data, col, data[col].dtype.name)","5ce6c6e0":"convert_types(train_data)","2c8e1f7f":"correlations = train_data.corr()['HasDetections'].abs().sort_values(0, False)\n\ncheckboxes = []\nlabels = []\nvalues = []\ndisabled = [\n    'Census_IsPortableOperatingSystem',\n    'HasTpm',\n    'Census_IsSecureBootEnabled',\n    'Census_IsFlightingInternal',\n    'Census_IsPenCapable',\n    'Firewall',\n    'Census_IsFlightsDisabled',\n    'IsBeta',\n    'Census_IsWIMBootEnabled',\n]\n\nif INTERACTIVE:\n    for i, val in correlations.iteritems():\n        value = (i not in disabled)\n\n        checkboxes.append(widgets.Checkbox(value=value))\n        labels.append(widgets.Label(f\"{i} ({train_data[i].dtype})\"))\n        values.append(widgets.Label(str(val)))\n\n    button = widgets.Button(description=\"Process\")    \n    def on_button_clicked(b):\n        global train_data\n        to_del = [col for box, col in zip(checkboxes, correlations.index) if box.value == False]\n        train_data.drop(columns=to_del, inplace=True)\n\n    button.on_click(on_button_clicked)\n    \n    w = widgets.VBox([\n        widgets.HBox([widgets.VBox(w) for w in (checkboxes, labels, values)]),\n        button\n    ])\nelse:\n    max_col_len = max(map(len, correlations.index)) + 15\n\n    for i, val in correlations.iteritems():\n        mark = \"v\" if i not in disabled else \"x\"\n        key = f\"{i} ({train_data[i].dtype})\".ljust(max_col_len)\n        print(f\"{mark} {key} : {val}\")\n        \n        if i in disabled:\n            train_data.drop(columns=[str(i)], inplace=True)\n    \n    w = \"\"\n    \nw","f50e3fb0":"values = []\ndisabled = [\n    'Census_OSSkuName',\n    'Census_MDC2FormFactor',\n    'Census_OSEdition',\n    'Census_OSBuildNumber',\n    'Census_PowerPlatformRoleName',\n    'Census_OSArchitecture'\n]\nN = 3\n\n\nif INTERACTIVE:\n    columns = [str(col) for col in train_data.columns if train_data[col].dtype.name]\n    columns.remove('MachineIdentifier')\n\n    boxes = [widgets.Checkbox(value=(c not in disabled)) for c in columns]\n    keys = [widgets.Label(c) for c in columns]\n\n\n    for i, (idx, row) in enumerate(train_data.head(3)[columns].iterrows()):\n        values.append(widgets.VBox([widgets.Label(str(v)) for k, v in row.iteritems()]))\n    \n\n    button = widgets.Button(description=\"Process\")\n    def on_click(b):\n        global train_data\n        to_del = [col.value for box, col in zip(boxes, keys) if box.value == False]\n        train_data.drop(columns=to_del, inplace=True)\n\n    button.on_click(on_click)\n    \n    w = widgets.VBox([\n        widgets.HBox([widgets.VBox(boxes), widgets.VBox(keys), *values]),\n        button\n    ])\n\nelse:\n    columns = [str(col) for col in train_data.columns if train_data[col].dtype.name]\n    columns.remove('MachineIdentifier')\n\n    max_col_len = max(map(len, columns)) + 5\n    \n    val_lens = [[len(str(train_data.loc[i, c])) for c in columns] for i in range(N)]\n    max_val_lens = list(map(max, val_lens))\n\n    def description(c):\n        key = c\n        strip_idx = int(max_col_len * 0.5)\n        if len(key) > strip_idx:\n            key = key[:strip_idx] + \"...\"\n            \n        key = key.ljust(max_col_len, \" \")\n        \n        values = \"\"\n        for i, v in enumerate(train_data[c].head(3).tolist()):\n            val = str(v)\n            strip_idx = int(max_val_lens[i] * 0.5)\n            if len(val) > strip_idx:\n                val = val[:strip_idx] + \"...\"\n                \n            val = val.ljust(max_val_lens[i], \" \")\n            values = values + val\n            \n        return f\"{key}: {values}\"\n    \n    for c in columns:\n        mark = \"v\" if c not in disabled else \"x\"\n        print(f\"{mark} {description(c)}\")\n        \n    for c in disabled:\n        train_data.drop(columns=[str(c)], inplace=True)\n        \n    w = \"\"\n    \nw","b8599f7c":"USED_COLS = train_data.columns.drop(\"HasDetections\")\n\nwith open(os.path.join(SAVE_PATH, \"train_clean.pkl\"), 'wb') as f:\n    pickle.dump(train_data, f)   \n\ndel(train_data)\ngc.collect()","7fba94c6":"with open(os.path.join(DATA_PATH, \"test.pkl\"), 'rb') as f:\n    test_data = pickle.load(f)\nprint(f\"loaded test data with {len(test_data)} rows\")\n\ntest_data = test_data.loc[:, USED_COLS]\ngc.collect()\n\nconvert_types(test_data)","b822382e":"with open(os.path.join(SAVE_PATH, \"test_clean.pkl\"), 'wb') as f:\n    pickle.dump(test_data, f)   ","2ae7fe3b":"Print count of NA's for each column","60b50111":"## Clean data saving","6c1fd39c":"## Data loading","d66465fc":"SmartScreen looks suspiciously with its 35% of NA's","17a77105":"We see that top category value is very common, so I think we can just replace all the NA's with its mode, just like I will do for another categorical columns","ef4223b9":"Let's take a look at first 3 rows and clean repeating columns","dfddf67a":"\"Some columns have so many NA's so I don't even want to care about them ","cdbfd9da":"Take a look at correlation with HasDetections column.\nIf you suppose that correlation is a good metric of feature importance, you can uncheck some columns and click Process to delete them.\nI disabled some bool features which have low correlation with the target ","83eb4327":"## Data cleaning","cc52ba46":"Remember remaining columns list, save clean train data and delete it to respect your RAM ","a1b08bae":"Very deep magic function to convert dtypes and replace NA's with:\n* median for numeric columns\n* mode for category columns","198dda42":"Save clean test data","7d7c8581":"Load test data and repeat cleaning stage just as for train data above","4af47a60":"## Columns selection","2350f14c":"The same with OrganizationIdentifier","cc151251":"If you use this ipynb from jupyter-notebook, set INTERACTIVE=True, and you will have interactive widgets for columns selection. Unfortunatelly, kaggle kernels can't display them"}}