{"cell_type":{"49ee564a":"code","b10eee23":"code","85a6f5d9":"code","bac24ad6":"code","9ba37c21":"code","731490b1":"code","b12d3938":"code","5c52de2e":"code","b48a82bd":"code","98c6ee81":"code","5d3ba708":"code","a130b4fc":"code","3297044f":"code","42557b02":"code","4f6de4c2":"code","d726ab95":"code","1cfb440a":"code","2da1899d":"code","9326d229":"code","7d1b2153":"code","953a899f":"markdown","d9239ed8":"markdown","23b0d275":"markdown","43c84409":"markdown","9dedd53a":"markdown","7d295d6e":"markdown","ec7e4036":"markdown","c4220ae5":"markdown","55e77ec6":"markdown","9287693a":"markdown","80d571b6":"markdown"},"source":{"49ee564a":"## Leave commented out if already done\n# pip install Pillow","b10eee23":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sn\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D, LeakyReLU\nfrom tensorflow.keras.callbacks import TensorBoard\nimport pickle\nfrom PIL import Image\nimport time\nimport os\nfrom PIL import Image\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.model_selection import train_test_split\n\n# from sklearn.model_selection import KFold\n\nstart = time.time()","85a6f5d9":"## variables for the fiddling with (99% val_acc with .0339 val_loss)\n\ndim = (176,208)               # input image dimensions                                              (176,208)\ntest_split_percent = .1       # % of total data for testing                                         .1\nvalidation_split_percent = .2 # % of total data for validation                                      .2\nzoom = [.99,1.01]             # zoom range (for a fixed zoom put the same value in both parameters)[.99,1.01]\nbright_range = [.8,1.2]       # brightness range                                                    [.8,1.2] \nlayers_unlocked = True        # unlock the imported pre-training layers?                            False  \nlr = 0.0001                   # learning rate for optimizer                                         0.0001\nbatch = 20                    # batch size for model fitting                                        20\neps = 5                      # number of epochs to run                                             50\nmomentum = .9                 # momentum of SGD                                                     .9\n\nsave_model_name = \"val%2d_epochs%d\"%(validation_split_percent*100,eps)   # automatically generate a model save name\nprint(save_model_name)\n\n# k_folds = 10                # number of folds for k-fold validation                              #k-folds someday","bac24ad6":"# This section uses the ImageDataGenerator and flow_from_directory functions to sort the images by label\n#actual dimensions 176x208x1\n\n# introduced zoom, blew up the image of the brain itself, and brightness range to adjust for different brightness\ntrain_dr = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,fill_mode='constant',cval=0,\n                                                           brightness_range=bright_range,zoom_range=zoom,\n                                                           data_format='channels_last',zca_whitening=False)\n\ntrain_data_gen = train_dr.flow_from_directory(directory=\"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train\/\",target_size=dim,\n                                              batch_size=5000)\n\n# Change to zoom = [1,1] to use normal test data\ntest_dr = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,fill_mode='constant',cval=0,zoom_range=[1,1],\n                                                          data_format='channels_last') \ntest_data_gen = test_dr.flow_from_directory(directory=\"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/\",target_size=dim,batch_size=5000,\n                                           shuffle = False) # test data should not be shuffled to keep labels","9ba37c21":"# This section assigns the images to numpy arrays for the data and labels\n# EX: train_data = numpy array of image data, train_labels = numpy array of labels \n\ntrain_data,train_labels =  train_data_gen.next()\ntest_data,test_labels = test_data_gen.next()\n\n# val_data,val_labels = val_data_gen.next()","731490b1":"# cocatenate arrays, combining all data\ntotal_data = np.concatenate((train_data,test_data))\ntotal_labels = np.concatenate((train_labels,test_labels))\nprint(total_data.shape)\nprint(total_labels.shape)","b12d3938":"# train test split\n\ninitial_split = test_split_percent+validation_split_percent\ntest_val_split = test_split_percent\/initial_split\n\n# split into training and (test + validation)\ntrain_data, test_val_data, train_labels, test_val_labels = train_test_split(total_data,total_labels,\n                                                                            test_size=initial_split)\n\n# split (test + validation) into test and validation sets\ntest_data, val_data, test_labels, val_labels = train_test_split(test_val_data,test_val_labels,\n                                                                test_size=test_val_split)\n\nprint('train: ',train_data.shape)\nprint('validation',val_data.shape)\nprint('test',test_data.shape)","5c52de2e":"# Check array dimensions\nprint(train_data.shape)\nprint(train_labels.shape)\nprint(val_data.shape)\nprint(val_labels.shape)\nprint(test_data.shape)\nprint(test_labels.shape)","b48a82bd":"# check some images\nplt.subplot(221)\nplt.imshow(train_data[1,:,:,:])\nplt.subplot(222)\nplt.imshow(train_data[2,:,:,:])\nplt.subplot(223)\nplt.imshow(val_data[3,:,:,:])\nplt.subplot(224)\nplt.imshow(val_data[4,:,:,:])\nplt.show()\nplt.subplot(221)\nplt.imshow(test_data[5,:,:,:])\nplt.subplot(222)\nplt.imshow(test_data[154,:,:,:])","98c6ee81":"# preprocess the images in the same manner as those trained on original model\n#train_data = preprocess_input(train_data)\n#val_data = preprocess_input(val_data)\n#test_data = preprocess_input(test_data)\nprint(np.amax(train_data))\nprint(np.amin(train_data))\nprint(np.amax(val_data))\nprint(np.amin(val_data))","5d3ba708":"# check image channels\nplt.subplot(141)\nplt.imshow(train_data[3,:,:,0])\nplt.subplot(142)\nplt.imshow(train_data[3,:,:,1])\nplt.subplot(143)\nplt.imshow(train_data[3,:,:,2])\nplt.subplot(144)\nplt.imshow(train_data[3,:,:,:])","a130b4fc":"# import pre-trained VGG16 model\n\nvg_model = tf.keras.applications.vgg16.VGG16(include_top=False,input_shape=(dim[0],dim[1],3), pooling = 'max') #added pooling\n\n## IF YOU LOADED A MODEL AND WANT TO CONTINUE TRAINING, comment above, uncomment below\n# vg_model = vg_model(include_top=False,input_shape=(dim[0],dim[1],3), pooling = 'max') #added pooling","3297044f":"## CHANGE MODEL STRUCTURE ##\n\n# retrain some of the convolutional layers deep in the model, but not the fully connected layers at the end\nvg_model.get_layer('block1_conv1').trainable = layers_unlocked\nvg_model.get_layer('block1_conv2').trainable = layers_unlocked\nvg_model.get_layer('block2_conv1').trainable = layers_unlocked\nvg_model.get_layer('block2_conv2').trainable = layers_unlocked\nvg_model.get_layer('block3_conv1').trainable = layers_unlocked\nvg_model.get_layer('block3_conv2').trainable = layers_unlocked\nvg_model.get_layer('block3_conv3').trainable = layers_unlocked\nvg_model.get_layer('block4_conv1').trainable = layers_unlocked\nvg_model.get_layer('block4_conv2').trainable = layers_unlocked\nvg_model.get_layer('block4_conv3').trainable = layers_unlocked\n\n## always leave last layer trainable ##\n# vg_model.get_layer('block5_conv1').trainable = False\n# vg_model.get_layer('block5_conv2').trainable = False\n# vg_model.get_layer('block5_conv3').trainable = False\n\n## Add new trainable FC layers ##\nflat = Flatten()(vg_model.output)\nfc1 = Dense(1024,activation='relu', kernel_initializer='he_uniform')(flat) # put in kernel initializer he-uniform\ndp1 = Dropout(0.25)(fc1)                                                   # changed dropout here from .5\noutput = Dense(4,activation='softmax')(dp1)                                # changed to sigmoid from softmax\nvg_model = Model(inputs=vg_model.inputs, outputs=output)\n\nvg_model.summary()","42557b02":"# compile the model\n#changed from tf.keras.optimizers.Adam(learning_rate=.0001) to SGD+nest.+momentum\nopt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum, nesterov=True,name='SGD') \n\nvg_model.compile(optimizer=opt, loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])","4f6de4c2":"# train the model\nmodel_history = vg_model.fit(train_data,train_labels,validation_data=(val_data,val_labels),\n                             epochs=eps,batch_size=batch, shuffle=True) #changed batch size from 15\nscores = vg_model.evaluate(train_data, train_labels)\nprint(\"Accuracy: %.2f%%\" %(scores[1]*100))","d726ab95":"# plot accuracy\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\nplt.title('Accuracy per Epoch')\nplt.plot(np.linspace(1,eps,num=eps),model_history.history['acc'], label = 'Training Accuracy')\nplt.plot(np.linspace(1,eps,num=eps),model_history.history['val_acc'], label = 'Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n# print(np.amax.model_history.history['val_acc'])\n\n#Plot loss\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\nplt.title('Loss per Epoch')\nplt.plot(np.linspace(1,eps,num=eps),model_history.history['loss'], label = 'Training Loss')\nplt.plot(np.linspace(1,eps,num=eps),model_history.history['val_loss'], label = 'Validation Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()\n\n# print out variable values\nprint('image dimensions: ',dim)\nprint('validation split percentage: ',validation_split_percent)\nprint('zoom: ',zoom)\nprint('Learning Rate: ',lr)\nprint('batch size: ',batch)\nprint('epochs: ',eps)\nprint('brightness range: ',bright_range)\nprint('Model trained from scratch? : ',layers_unlocked)\nend = time.time()\nprint('Total Time Elapsed = %.2d minutes'%((end - start)\/60))","1cfb440a":"### PERFORMANCE EVALUATION ##\ntrain_scores = vg_model.evaluate(train_data, train_labels)\nval_scores = vg_model.evaluate(val_data,val_labels)\ntest_scores = vg_model.evaluate(test_data, test_labels)\n\nprint('Train Accuracy: %.2f%%'%(train_scores[1]*100))\nprint('Validation Accuracy: %.2f%%'%(val_scores[1]*100))\nprint('Test Accuracy: %.2f%%'%(test_scores[1]*100))","2da1899d":"## CONFUSION MATRIX ##\n\npredic = vg_model.predict(test_data)\n\npredic = np.argmax(predic, axis=1)\nlabels = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(labels, predic)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\nax = sn.heatmap(conf_arr, cmap='Blues', annot=True, fmt='d', xticklabels= ['Mild', 'Moderate', 'Normal', 'VeryMild'],\n                yticklabels=['Mild', 'Moderate', 'Normal', 'VeryMild'])\nplt.title('Alzheimer\\'s Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\n# plt.subplots(figsize=(9, 6))\nplt.show(ax)\n","9326d229":"# ## saving in HDF5 format\n# save_name = '%s_testacc%2d.h5'%(save_model_name,(test_scores[1]*100))\n# vg_model.save('\/kaggle\/input\/%s'%save_name)\n# print(save_name)\n\n\n# ## save the model_history\n","7d1b2153":"## choose the model to load ##\n## comment out when not using ##\n\nvg_model = load_model(\"\/kaggle\/input\/valsplit20-epochs50-testacc98h5\/valsplit20_epochs50_testacc98.h5\") \n","953a899f":"# Create Model\nor to load a model, skip down to \"Load Model\", then you can either continue training that model by skipping the next cell, or jump to \"Evaluate Model\"","d9239ed8":"Developed by Bryce Smith, Zachary Burns, and Derrick Cosmas. June 2020\n\nTo load our pretrained model, download it from my personal files and go to \"Load\" at the end of this code. then run all the code except for training the model.\n\nTo run our model yourself:\nFor maximum accuracy you will need to download and run for 50 epochs (the \"eps\" param). kaggle does not alot enough memory for this.\n\nyou need to enable internet in preferences to run this as it uses a pretrained vgg16 model.\n\n\nnotes:\nthe test files provided were not of a uniform distribution, as the training set was.\\nwe resolve this by reshuffling all the files, and then splitting into training and test sets prior to training the model\n\nwe realize this makes our results invalid by the rules of the competition, but from a machine learning stand point the approach is valid.\nwe would reccomend making our method standard for future test set creation.","23b0d275":"# Variables","43c84409":"Code from 6\/4\/20\n","9dedd53a":"# Saving the Model","7d295d6e":"# Train the Model\n\n","ec7e4036":"# Plots and Values","c4220ae5":"# Import Data From Local Drive","55e77ec6":"# Load Model","9287693a":"# Sanity Checks","80d571b6":"# Performance Evaluation\nCome here after loading model"}}