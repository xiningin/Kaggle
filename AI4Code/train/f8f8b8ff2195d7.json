{"cell_type":{"1f87bac2":"code","6ece7426":"code","924306be":"code","0a52bacd":"code","95489571":"code","0ee7a51c":"code","38ec001c":"code","13fbb4f9":"code","30d2884b":"code","9043cd4d":"code","f8f1eb45":"code","77968589":"code","c6424282":"code","5896b43b":"code","780a3c5b":"code","ead1c6d2":"code","7554bcc2":"code","67a799d8":"code","feaa811b":"code","24dcbc0a":"code","c2aa9b0e":"code","6dcd553c":"code","bb547048":"code","5b029d77":"code","eae01e8c":"code","e4693444":"code","e4309b33":"code","64894cff":"code","58ab929a":"code","67fe827b":"code","6212efce":"code","66d0ae4a":"markdown","c278e2af":"markdown","6b026942":"markdown","8b3c033d":"markdown","3cb3c0bc":"markdown","8c0319b2":"markdown","ee11e2b2":"markdown","0943897e":"markdown","fc935da8":"markdown","2cbe2b2e":"markdown","78491dad":"markdown","e46973fc":"markdown","698ed91c":"markdown","ee01adfe":"markdown","c9018d43":"markdown","db4eb88c":"markdown","c08afb24":"markdown","b75e8359":"markdown","0eb220c3":"markdown","5033c4a2":"markdown","b378cb4c":"markdown","ef499b3a":"markdown","9f27dd4b":"markdown","879ce5e1":"markdown","44f3fa0e":"markdown","3324602e":"markdown","8d116187":"markdown","ab21b0f0":"markdown","f41d15f6":"markdown","a56a5789":"markdown"},"source":{"1f87bac2":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt","6ece7426":"imdb_reviews_word_ds = tfds.load(\"imdb_reviews\", as_supervised=True)\nimdb_reviews_word_ds_training = list(imdb_reviews_word_ds[\"train\"])\nimdb_reviews_word_ds_validation = list(imdb_reviews_word_ds[\"test\"])","924306be":"x_train_word_ds = []\ny_train_word_ds = []\n\nfor text, label in imdb_reviews_word_ds_training:\n    \n    x_train_word_ds.append(text.numpy().decode(\"utf-8\"))\n    y_train_word_ds.append(label.numpy())\n    \n\nx_validation_word_ds = []\ny_validation_word_ds = []\n\nfor text, label in imdb_reviews_word_ds_validation:\n    \n    x_validation_word_ds.append(text.numpy().decode(\"utf-8\"))\n    y_validation_word_ds.append(label.numpy())","0a52bacd":"tokenizer = keras.preprocessing.text.Tokenizer(num_words=12000, oov_token=\"<OOV>\")","95489571":"tokenizer.fit_on_texts(texts=x_train_word_ds)","0ee7a51c":"tokenizer.word_index","38ec001c":"x_train_word_ds = tokenizer.texts_to_sequences(texts=x_train_word_ds)\nx_validation_word_ds = tokenizer.texts_to_sequences(texts=x_validation_word_ds)","13fbb4f9":"x_train_word_ds = keras.preprocessing.sequence.pad_sequences(sequences=x_train_word_ds,\n                                                             maxlen=128,\n                                                             padding=\"post\",\n                                                             truncating=\"post\")\n\nx_validation_word_ds = keras.preprocessing.sequence.pad_sequences(sequences=x_validation_word_ds,\n                                                                  maxlen=128,\n                                                                  padding=\"post\",\n                                                                  truncating=\"post\")","30d2884b":"# word dataset for training\ntemp_dict = {\"Text (Word)\": list(x_train_word_ds),\n             \"Label (int)\": y_train_word_ds}\n\npd.DataFrame.from_dict(temp_dict)","9043cd4d":"# word dataset for validation\ntemp_dict = {\"Text (Word)\": list(x_validation_word_ds),\n             \"Label (int)\": y_validation_word_ds}\n\npd.DataFrame.from_dict(temp_dict)","f8f1eb45":"x_train_word_ds = np.array(x_train_word_ds)\ny_train_word_ds = np.array(y_train_word_ds)\nprint(\"Type of word dataset for training (Text): \", type(x_train_word_ds))\nprint(\"Type of word dataset for training (Label): \", type(y_train_word_ds))\n\nprint()\n\nx_validation_word_ds = np.array(x_validation_word_ds)\ny_validation_word_ds = np.array(y_validation_word_ds)\nprint(\"Type of word dataset for validation (Text): \", type(x_validation_word_ds))\nprint(\"Type of word dataset for validation (Label): \", type(y_validation_word_ds))","77968589":"print(\"Shape of word dataset for training (Text): \", x_train_word_ds.shape)\nprint(\"Shape of word dataset for training (Label): \", y_train_word_ds.shape)\nprint(\"Shape of word dataset for validation (Text): \", x_validation_word_ds.shape)\nprint(\"Shape of word dataset for validation (Label): \", y_validation_word_ds.shape)","c6424282":"imdb_reviews_subword_ds, info = tfds.load(\"imdb_reviews\/subwords8k\", as_supervised=True, with_info=True)\nimdb_reviews_subword_ds_training = list(imdb_reviews_subword_ds[\"train\"])\nimdb_reviews_subword_ds_validation = list(imdb_reviews_subword_ds[\"test\"])","5896b43b":"x_train_subword_ds = []\ny_train_subword_ds = []\n\nfor text, label in imdb_reviews_subword_ds_training:\n    \n    x_train_subword_ds.append(text.numpy())\n    y_train_subword_ds.append(label.numpy())\n    \n\nx_validation_subword_ds = []\ny_validation_subword_ds = []\n\nfor text, label in imdb_reviews_subword_ds_validation:\n    \n    x_validation_subword_ds.append(text.numpy())\n    y_validation_subword_ds.append(label.numpy())","780a3c5b":"x_train_subword_ds = keras.preprocessing.sequence.pad_sequences(sequences=x_train_subword_ds,\n                                                                maxlen=200,\n                                                                padding=\"post\",\n                                                                truncating=\"post\")\n\nx_validation_subword_ds = keras.preprocessing.sequence.pad_sequences(sequences=x_validation_subword_ds,\n                                                                     maxlen=200,\n                                                                     padding=\"post\",\n                                                                     truncating=\"post\")","ead1c6d2":"# subword dataset for training\ntemp_dict = {\"Text (Subword)\": list(x_train_subword_ds),\n             \"Label (int)\": y_train_subword_ds}\n\npd.DataFrame.from_dict(temp_dict)","7554bcc2":"# subword dataset for validation\ntemp_dict = {\"Text (Subword)\": list(x_validation_subword_ds),\n             \"Label (int)\": y_validation_subword_ds}\n\npd.DataFrame.from_dict(temp_dict)","67a799d8":"x_train_subword_ds = np.array(x_train_subword_ds)\ny_train_subword_ds = np.array(y_train_subword_ds)\nprint(\"Type of subword dataset for training (Text): \", type(x_train_subword_ds))\nprint(\"Type of subword dataset for training (Label): \", type(y_train_subword_ds))\n\nprint()\n\nx_validation_subword_ds = np.array(x_validation_subword_ds)\ny_validation_subword_ds = np.array(y_validation_subword_ds)\nprint(\"Type of subword dataset for validation (Text): \", type(x_validation_subword_ds))\nprint(\"Type of subword dataset for validation (Label): \", type(y_validation_subword_ds))","feaa811b":"print(\"Shape of subword dataset for training (Text): \", x_train_subword_ds.shape)\nprint(\"Shape of subword dataset for training (Label): \", y_train_subword_ds.shape)\nprint(\"Shape of subword dataset for validation (Text): \", x_validation_subword_ds.shape)\nprint(\"Shape of subword dataset for validation (Label): \", y_validation_subword_ds.shape)","24dcbc0a":"model_word = keras.models.Sequential()\nmodel_word.add(keras.layers.Embedding(input_dim=12000, output_dim=32, input_length=128))\nmodel_word.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=True)))\nmodel_word.add(keras.layers.Bidirectional(keras.layers.LSTM(units=64)))\nmodel_word.add(keras.layers.Dense(units=16, activation=\"relu\"))\nmodel_word.add(keras.layers.Dense(units=1, activation=\"sigmoid\"))","c2aa9b0e":"model_word.summary()","6dcd553c":"model_word.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"acc\"])","bb547048":"class CustomCallback(keras.callbacks.Callback):\n    \n    def on_epoch_end(self, epochs, logs):\n        if logs[\"acc\"] >= 0.99:\n            self.model.stop_training = True\n\nmy_callback = CustomCallback()","5b029d77":"model_subword = keras.models.Sequential()\nmodel_subword.add(keras.layers.Embedding(input_dim=info.features[\"text\"].encoder.vocab_size, output_dim=32, input_length=200))\nmodel_subword.add(keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=True)))\nmodel_subword.add(keras.layers.Bidirectional(keras.layers.LSTM(units=64)))\nmodel_subword.add(keras.layers.Dense(units=16, activation=\"relu\"))\nmodel_subword.add(keras.layers.Dense(units=1, activation=\"sigmoid\"))","eae01e8c":"model_subword.summary()","e4693444":"model_subword.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"acc\"])","e4309b33":"pass","64894cff":"history_word = model_word.fit(x=x_train_word_ds,\n               y=y_train_word_ds,\n               batch_size=32,\n               epochs=50,\n               callbacks=my_callback,\n               validation_data=(x_validation_word_ds, y_validation_word_ds))","58ab929a":"histroy_subword = model_subword.fit(x=x_train_subword_ds,\n                                    y=y_train_subword_ds,\n                                    batch_size=32,\n                                    epochs=50,\n                                    callbacks=my_callback,\n                                    validation_data=(x_validation_subword_ds, y_validation_subword_ds))","67fe827b":"training_acc = history_word.history[\"acc\"]\nvalidation_acc = history_word.history[\"val_acc\"]\nepochs = list(range(len(validation_acc)))\n\nplt.plot(epochs, training_acc, color=\"blue\", label=\"Training Acc\")\nplt.plot(epochs, validation_acc, color=\"red\", label=\"Validation Acc\")\nplt.legend()\nplt.show()","6212efce":"training_acc = histroy_subword.history[\"acc\"]\nvalidation_acc = histroy_subword.history[\"val_acc\"]\nepochs = list(range(len(validation_acc)))\n\nplt.plot(epochs, training_acc, color=\"blue\", label=\"Training Acc\")\nplt.plot(epochs, validation_acc, color=\"red\", label=\"Validation Acc\")\nplt.legend()\nplt.show()","66d0ae4a":"## Load & Prepare Dataset","c278e2af":"### => Compilation","6b026942":"### => Prepare Training & Validation Dataset","8b3c033d":"## Import Package","3cb3c0bc":"### Download IMDB Reviews Dataset in Subword","8c0319b2":"### => Callback","ee11e2b2":"### Word Model","0943897e":"### => Covert Prepared Dataset to Numpy Array","fc935da8":"### => Callback","2cbe2b2e":"## Define Model","78491dad":"### => Have a Look on Prepared Dataset","e46973fc":"### => Pad the Sequences","698ed91c":"### => Covert Prepared Dataset to Numpy Array","ee01adfe":"### => Compilation","c9018d43":"### => Have a Look on Prepared Dataset","db4eb88c":"### Model for Word Dataset","c08afb24":"## Check the Training History => Overfitting","b75e8359":"### => Architecture","0eb220c3":"### => Shape of Training & Validation Dataset","5033c4a2":"### Download IMDB Reviews Dataset in Plain Text (Word)","b378cb4c":"## Train Model","ef499b3a":"### Train Model for Word Dataset","9f27dd4b":"### Subword Model","879ce5e1":"### => Tokenize Plain Text","44f3fa0e":"### Train Model for Subword Dataset","3324602e":"### => Shape of Training & Validation Dataset","8d116187":"### => Prepare Training & Validation Dataset","ab21b0f0":"### => Pad the Sequences","f41d15f6":"### Model for Subword Dataset","a56a5789":"### => Architecture"}}