{"cell_type":{"39fd62cb":"code","b5badf30":"code","64d7ae07":"code","937f040b":"code","fe7d235a":"code","13bcbf6e":"code","d1b414d1":"code","9f1336ce":"code","87c5a7f4":"code","33028d52":"code","19713b19":"code","211f3d48":"code","d4a8976a":"code","d20e38b8":"code","994b505f":"code","562a3f10":"code","818dac1c":"code","22d4be37":"code","0b6a3d59":"code","0d0667f6":"code","00074aee":"code","504b8db2":"code","6e4c6a7c":"code","275bc170":"code","5bb569e4":"code","31541c18":"code","ab237bc0":"code","53ef0ac7":"code","436eb9f0":"code","61a496fd":"code","cd9d5fba":"code","efde829c":"code","04ebb91f":"code","ba69f612":"code","d6b92114":"markdown","00c30fb8":"markdown","9d0ba5d5":"markdown","ff51532d":"markdown","d85f2b9e":"markdown","f8ecac8b":"markdown","a3a7e343":"markdown","1d369183":"markdown"},"source":{"39fd62cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport plotly.express as px\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom sklearn import preprocessing\nimport optuna\nfrom optuna.samplers import TPESampler","b5badf30":"train = pd.read_csv('\/kaggle\/input\/av-healthcare-analytics-ii\/healthcare\/train_data.csv')\ntest = pd.read_csv('\/kaggle\/input\/av-healthcare-analytics-ii\/healthcare\/test_data.csv')\ntrain = train.drop(['case_id'], axis=1)\ntest = test.drop(['case_id'], axis=1)\ntrain['dataset'] = 'train'\ntest['dataset'] = 'test'\ndf = pd.concat([train, test])","64d7ae07":"df","937f040b":"ds = df.groupby(['Hospital_code', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['hospital', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='hospital', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Cases per hospital distribution', \n    width=800,\n    height=700\n)\nfig.show()","fe7d235a":"ds = df.groupby(['Hospital_type_code', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['hospital', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='hospital', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Cases hospital type distribution', \n    width=800,\n    height=600\n)\nfig.show()","13bcbf6e":"ds = df.groupby(['Hospital_region_code', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['hospital', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='hospital', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Cases hospital region distribution', \n    width=800,\n    height=500\n)\nfig.show()","d1b414d1":"ds = df.groupby(['Department', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['department', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='department', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Department distribution', \n    width=800,\n    height=600\n)\nfig.show()","9f1336ce":"ds = df.groupby(['Ward_Type', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['Ward_Type', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='Ward_Type', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Ward Type distribution', \n    width=800,\n    height=600\n)\nfig.show()","87c5a7f4":"ds = ds[ds['dataset']=='train']\nfig = px.pie(\n    ds, \n    names='Ward_Type', \n    values=\"count\", \n    title='Ward type pie chart for train set', \n    width=700,\n    height=600\n)\nfig.show()","33028d52":"ds = df.groupby(['Ward_Facility_Code', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['Ward_Facility_Code', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='Ward_Facility_Code', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Ward Facility Code distribution', \n    width=900,\n    height=600\n)\nfig.show()","19713b19":"ds = df.groupby(['Bed Grade', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['bed_grade', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='bed_grade', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Bed_grade distribution', \n    width=900,\n    height=600\n)\nfig.show()","211f3d48":"ds = df.groupby(['Age', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['age', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='age', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Age distribution', \n    width=900,\n    height=600\n)\nfig.show()","d4a8976a":"\nds = df.groupby(['Type of Admission', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['admission', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='admission', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Admission type distribution', \n    width=900,\n    height=600\n)\nfig.show()","d20e38b8":"ds = df.groupby(['Severity of Illness', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['Severity of Illness', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='Severity of Illness', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Severity of Illness type distribution', \n    width=900,\n    height=600\n)\nfig.show()","994b505f":"ds = df.groupby(['Stay', 'dataset'])['patientid'].count().reset_index()\nds.columns = ['Stay', 'dataset', 'count']\nfig = px.bar(\n    ds, \n    x='Stay', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='Stay length distribution', \n    width=900,\n    height=600\n)\nfig.show()","562a3f10":"data = df['patientid'].value_counts().reset_index()\ndata.columns = ['patientid', 'cases']\ndata['patientid'] = 'patient ' + data['patientid'].astype(str)\ndata = data.sort_values('cases')\nfig = px.bar(\n    data.tail(50), \n    x=\"cases\", \n    y=\"patientid\", \n    orientation='h', \n    title='Top 50 patients',\n    width=800,\n    height=900\n)\nfig.show()","818dac1c":"fig = px.histogram(\n    df, \n    \"City_Code_Patient\", \n    nbins=40, \n    color = 'dataset',\n    barmode='group',\n    title='City_Code_Patient', \n    width=700,\n    height=600\n)\nfig.show()","22d4be37":"fig = px.histogram(\n    df, \n    \"Visitors with Patient\", \n    nbins=40, \n    color = 'dataset',\n    barmode='group',\n    title='Visitors with Patient', \n    width=700,\n    height=600\n)\nfig.show()","0b6a3d59":"fig = px.histogram(\n    df, \n    \"Admission_Deposit\", \n    nbins=50, \n    color = 'dataset',\n    barmode='group',\n    title='Admission Deposit destribution', \n    width=700,\n    height=600\n)\nfig.show()","0d0667f6":"df.loc[df['Stay'] == '0-10', 'Stay'] = 0\ndf.loc[df['Stay'] == '11-20', 'Stay'] = 1\ndf.loc[df['Stay'] == '21-30', 'Stay'] = 2\ndf.loc[df['Stay'] == '31-40', 'Stay'] = 3\ndf.loc[df['Stay'] == '41-50', 'Stay'] = 4\ndf.loc[df['Stay'] == '51-60', 'Stay'] = 5\ndf.loc[df['Stay'] == '61-70', 'Stay'] = 6\ndf.loc[df['Stay'] == '71-80', 'Stay'] = 7\ndf.loc[df['Stay'] == '81-90', 'Stay'] = 8\ndf.loc[df['Stay'] == '91-100', 'Stay'] = 9\ndf.loc[df['Stay'] == 'More than 100 Days', 'Stay'] = 10","00074aee":"train = df[df['dataset']=='train']\ntest = df[df['dataset']=='test']\n\ntarget = train['Stay']\n\nfeatures = ['Available Extra Rooms in Hospital', 'Bed Grade', 'Visitors with Patient', 'Admission_Deposit']\n\ntrain = train[features]\ntrain = train.fillna(0)\ntest = test[features]","504b8db2":"X, X_val, y, y_val = train_test_split(train, target, random_state=0, test_size=0.2, shuffle=True)\ny=y.astype('int')\ny_val=y_val.astype('int')","6e4c6a7c":"model = LogisticRegression(random_state=666)\nmodel.fit(X, y)\npreds = model.predict(X_val)\nprint('Baseline accuracy: ', accuracy_score(y_val, preds)*100, '%')","275bc170":"fig, ax = plt.subplots(figsize=(10, 10))\nplot_confusion_matrix(model, X_val, y_val, ax=ax)","5bb569e4":"need_to_encode = ['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness']\nfor column in need_to_encode:\n    le = preprocessing.LabelEncoder()\n    le.fit(df[column])\n    df[column] = le.transform(df[column])","31541c18":"df.loc[df['Age'] == '0-10', 'Age'] = 0\ndf.loc[df['Age'] == '11-20', 'Age'] = 1\ndf.loc[df['Age'] == '21-30', 'Age'] = 2\ndf.loc[df['Age'] == '31-40', 'Age'] = 3\ndf.loc[df['Age'] == '41-50', 'Age'] = 4\ndf.loc[df['Age'] == '51-60', 'Age'] = 5\ndf.loc[df['Age'] == '61-70', 'Age'] = 6\ndf.loc[df['Age'] == '71-80', 'Age'] = 7\ndf.loc[df['Age'] == '81-90', 'Age'] = 8\ndf.loc[df['Age'] == '91-100', 'Age'] = 9","ab237bc0":"categorical = ['Hospital_code', 'Hospital_type_code', 'City_Code_Hospital', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code', \n              'City_Code_Patient', 'Type of Admission', 'Severity of Illness']","53ef0ac7":"train = df[df['dataset']=='train']\ntest = df[df['dataset']=='test']\n\ntarget = train['Stay']\ntrain = train.fillna(0)\ntest = test.fillna(0)\ntrain = train.drop(['patientid', 'dataset', 'Stay'], axis=1)\ntest = test.drop(['patientid', 'dataset'], axis=1)\ntrain","436eb9f0":"X, X_val, y, y_val = train_test_split(train, target, random_state=0, test_size=0.2, shuffle=True)\ny=y.astype('int')\ny_val=y_val.astype('int')","61a496fd":"model = LGBMClassifier(random_state=666)\nmodel.fit(X, y, categorical_feature=categorical)\npreds = model.predict(X_val)\nprint('LGBM accuracy: ', accuracy_score(y_val, preds)*100, '%')","cd9d5fba":"fig, ax = plt.subplots(figsize=(10, 10))\nplot_confusion_matrix(model, X_val, y_val, ax=ax)","efde829c":"sampler = TPESampler(seed=0)\ndef create_model(trial):\n    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.0000001, 1)\n    num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n    min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n    model = LGBMClassifier(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth, num_leaves=num_leaves, min_child_samples=min_child_samples,\n                           random_state=0)\n    return model\n\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(X, y)\n    preds = model.predict(X_val)\n    return accuracy_score(y_val, preds)\n\ndef optimize():\n    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n    study.optimize(objective, n_trials=50)\n    return study.best_params\n\nparams = optimize()","04ebb91f":"params['random_state'] = 666\nmodel = LGBMClassifier(**params)\nmodel.fit(X, y, categorical_feature=categorical)\npreds = model.predict(X_val)\nprint('LGBM accuracy: ', accuracy_score(y_val, preds)*100, '%')","ba69f612":"fig, ax = plt.subplots(figsize=(10, 10))\nplot_confusion_matrix(model, X_val, y_val, ax=ax)","d6b92114":"### We can see that we improved our score without any serious preprocessing of data and hyperparameters tunning. Let's do it next.","00c30fb8":"### Let's build LightGBM classifier","9d0ba5d5":"### Time to start preparing dataset for modeling","ff51532d":"### Lets try first linear model only on numerical features","d85f2b9e":"<h1><center>Healthcare Analytics. Data analysis, modeling and classification<\/center><\/h1>\n\n<center><img src=\"https:\/\/pbs.twimg.com\/media\/EdNIyWiXsAEHY1w.png\"><\/center>","f8ecac8b":"### Optuna optimization","a3a7e343":"## Next we will continue with data understanding, feature creation part and will build a model.","1d369183":"# Work in progress"}}