{"cell_type":{"4a21aa4d":"code","cbbafa98":"code","2844f051":"code","0f410d83":"code","fb29a8c3":"code","4fce0419":"code","0bc9692d":"code","f4940511":"code","aee44a83":"code","d8f5d757":"code","f92002d8":"code","50e72010":"code","c539ec2e":"markdown","47826d7d":"markdown","2a46e2a0":"markdown","b5ff4366":"markdown"},"source":{"4a21aa4d":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nimport os","cbbafa98":"data_dir = '..\/input\/pytorchtransferlearningtutorial\/hymenoptera_data'\nimage_size = 224\n# \u52a0\u8f7d\u7684\u8fc7\u7a0b\u5c06\u4f1a\u5bf9\u56fe\u50cf\u81ea\u52a8\u4f5c\u5982\u4e0b\u7684\u56fe\u50cf\u589e\u5f3a\u64cd\u4f5c\uff1a\n# 1. \u968f\u673a\u4ece\u539f\u59cb\u56fe\u50cf\u4e2d\u5207\u4e0b\u6765\u4e00\u5757224*224\u5927\u5c0f\u7684\u533a\u57df\n# 2. \u968f\u673a\u6c34\u5e73\u7ffb\u8f6c\u56fe\u50cf\n# 3. \u5c06\u56fe\u50cf\u7684\u8272\u5f69\u6570\u503c\u6807\u51c6\u5316\ntrain_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'),\n                                    transforms.Compose([\n                                        transforms.RandomResizedCrop(image_size),\n                                        transforms.RandomHorizontalFlip(),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                    ])\n                                    )\n\n# \u52a0\u8f7d\u6821\u9a8c\u6570\u636e\u96c6\uff0c\u5bf9\u6bcf\u4e2a\u52a0\u8f7d\u7684\u6570\u636e\u8fdb\u884c\u5982\u4e0b\u5904\u7406\uff1a\n# 1. \u653e\u5927\u5230256*256\u50cf\u7d20\n# 2. \u4ece\u4e2d\u5fc3\u533a\u57df\u5207\u5272\u4e0b224*224\u5927\u5c0f\u7684\u56fe\u50cf\u533a\u57df\n# 3. \u5c06\u56fe\u50cf\u7684\u8272\u5f69\u6570\u503c\u6807\u51c6\u5316\nval_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'),\n                                  transforms.Compose([\n                                      transforms.Resize(256),\n                                      transforms.CenterCrop(image_size),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                  ])\n                                  )\n\n# \u521b\u5efa\u76f8\u5e94\u7684\u6570\u636e\u52a0\u8f7d\u5668\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=4)\n\n# \u8bfb\u53d6\u5f97\u51fa\u6570\u636e\u4e2d\u7684\u5206\u7c7b\u7c7b\u522b\u6570['ants', 'bees']\nnum_classes = len(train_dataset.classes)\n\n# \u68c0\u6d4b\u672c\u673a\u5668\u662f\u5426\u5b89\u88c5GPU\uff0c\u5c06\u68c0\u6d4b\u7ed3\u679c\u8bb0\u5f55\u5728\u5e03\u5c14\u53d8\u91cfuse_cuda\u4e2d\nuse_cuda = torch.cuda.is_available()\n\n# \u5f53\u53ef\u7528GPU\u7684\u65f6\u5019\uff0c\u5c06\u65b0\u5efa\u7acb\u7684\u5f20\u91cf\u81ea\u52a8\u52a0\u8f7d\u5230GPU\u4e2d\ndtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\nitype = torch.cuda.LongTensor if use_cuda else torch.LongTensor","2844f051":"print(use_cuda)","0f410d83":"def imshow(inp, title=None):\n    # \u5c06\u4e00\u5f20\u56fe\u6253\u5370\u663e\u793a\u51fa\u6765\uff0cinp\u4e3a\u4e00\u4e2a\u5f20\u91cf\uff0ctitle\u4e3a\u663e\u793a\u5728\u56fe\u50cf\u4e0a\u7684\u6587\u5b57\n    \n    #\u4e00\u822c\u7684\u5f20\u91cf\u683c\u5f0f\u4e3a\uff1achannels*image_width*image_height\n    #\u800c\u4e00\u822c\u7684\u56fe\u50cf\u4e3aimage_width*image_height*channels\u6240\u4ee5\uff0c\u9700\u8981\u5c06channels\u8f6c\u6362\u5230\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\n    inp = inp.cpu() if use_cuda else inp\n    inp = inp.numpy().transpose((1, 2, 0))\n    \n    #\u7531\u4e8e\u5728\u8bfb\u5165\u56fe\u50cf\u7684\u65f6\u5019\u6240\u6709\u56fe\u50cf\u7684\u8272\u5f69\u90fd\u6807\u51c6\u5316\u4e86\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u5148\u8c03\u56de\u53bb\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    \n    #\u5c06\u56fe\u50cf\u7ed8\u5236\u51fa\u6765\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)\n    \n# \u83b7\u53d6\u7b2c\u4e00\u4e2a\u56fe\u50cfbatch\u548c\u6807\u7b7e(\u6807\u7b7e\u5bf9\u5e94\u6587\u4ef6\u5939)\nimages, labels = next(iter(train_loader)) \nprint(\"images_size:\", images.shape)\n\n# \u5c06\u8fd9\u4e2abatch\u4e2d\u7684\u56fe\u50cf\u5236\u6210\u8868\u683c\u7ed8\u5236\u51fa\u6765\nout = torchvision.utils.make_grid(images)\nprint(\"out_size:\", out.shape)\n\nimshow(out, title=[train_dataset.classes[x] for x in labels])","fb29a8c3":"# \u52a0\u8f7d\u6a21\u578b\u5e93\u4e2d\u7684residual network\uff0c\u5e76\u8bbe\u7f6epretrained\u4e3atrue\uff0c\u8fd9\u6837\u4fbf\u53ef\u52a0\u8f7d\u76f8\u5e94\u7684\u6743\u91cd\nnet = models.resnet18(pretrained=True)\n# \u5982\u679c\u5b58\u5728GPU\uff0c\u5c31\u5c06\u7f51\u7edc\u52a0\u8f7d\u5230GPU\u4e0a\nnet = net.cuda() if use_cuda else net\n# \u5c06\u7f51\u7edc\u7684\u67b6\u6784\u6253\u5370\u51fa\u6765\nnet","4fce0419":"def rightness(predictions, labels):\n    \"\"\"\u8ba1\u7b97\u9884\u6d4b\u9519\u8bef\u7387\u7684\u51fd\u6570\uff0c\u5176\u4e2dpredictions\u662f\u6a21\u578b\u7ed9\u51fa\u7684\u4e00\u7ec4\u9884\u6d4b\u7ed3\u679c\uff0cbatch_size\u884c10\u5217\u7684\u77e9\u9635\uff0clabels\u662f\u6570\u636e\u4e4b\u4e2d\u7684\u6b63\u786e\u7b54\u6848\"\"\"\n    pred = torch.max(predictions.data, 1)[1] # \u5bf9\u4e8e\u4efb\u610f\u4e00\u884c\uff08\u4e00\u4e2a\u6837\u672c\uff09\u7684\u8f93\u51fa\u503c\u7684\u7b2c1\u4e2a\u7ef4\u5ea6\uff0c\u6c42\u6700\u5927\uff0c\u5f97\u5230\u6bcf\u4e00\u884c\u7684\u6700\u5927\u5143\u7d20\u7684\u4e0b\u6807\n    rights = pred.eq(labels.data.view_as(pred)).sum() #\u5c06\u4e0b\u6807\u4e0elabels\u4e2d\u5305\u542b\u7684\u7c7b\u522b\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u7d2f\u8ba1\u5f97\u5230\u6bd4\u8f83\u6b63\u786e\u7684\u6570\u91cf\n    rights = rights.cpu() if use_cuda else rights\n    return rights, len(labels) #\u8fd4\u56de\u6b63\u786e\u7684\u6570\u91cf\u548c\u8fd9\u4e00\u6b21\u4e00\u5171\u6bd4\u8f83\u4e86\u591a\u5c11\u5143\u7d20","0bc9692d":"# \u91cd\u65b0\u5b9a\u4e49\u4e00\u4e2a\u5168\u65b0\u7684\u7ebf\u6027\u5c42\uff0c\u5b83\u7684\u8f93\u51fa\u4e3a2\uff0c\u539f\u672c\u662f1000\nnum_ftrs = net.fc.in_features\nnet.fc = nn.Linear(num_ftrs, 2)\nnet.fc = net.fc.cuda() if use_cuda else net.fc\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\nrecord = [] #\u8bb0\u5f55\u51c6\u786e\u7387\u7b49\u6570\u503c\u7684\u5bb9\u5668\n\n#\u5f00\u59cb\u8bad\u7ec3\u5faa\u73af\nnum_epochs = 20\nnet.train(True)\nbest_model = net\nbest_r = 0.0\nfor epoch in range(num_epochs):\n    train_rights = []\n    train_losses = []\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.clone().detach().requires_grad_(True), target.clone().detach()\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        output = net(data)\n        loss = criterion(output, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        right = rightness(output, target)\n        train_rights.append(right)\n        loss = loss.cpu() if use_cuda else loss\n        train_losses.append(loss.data.numpy())\n        \n    # train_r\u4e3a\u4e00\u4e2a\u4e8c\u5143\u7ec4\uff0c\u5206\u522b\u8bb0\u5f55\u8bad\u7ec3\u96c6\u4e2d\u5206\u7c7b\u6b63\u786e\u7684\u6570\u91cf\u548c\u8be5\u96c6\u5408\u4e2d\u603b\u7684\u6837\u672c\u6570\n    train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n    \n    #\u5728\u6d4b\u8bd5\u96c6\u4e0a\u5206\u6279\u8fd0\u884c\uff0c\u5e76\u8ba1\u7b97\u603b\u7684\u6b63\u786e\u7387\n    net.eval()\n    vals = []\n    for data, target in val_loader:\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = data.clone().detach().requires_grad_(False), target.clone().detach()\n        output = net(data)\n        val = rightness(output, target)\n        vals.append(val)\n    \n    #\u8ba1\u7b97\u51c6\u786e\u7387\n    val_r = (sum([tup[0] for tup in vals]), sum([tup[1] for tup in vals]))\n    val_ratio = 1.0*val_r[0].numpy()\/val_r[1]\n    \n    if val_ratio > best_r:\n        best_r = val_ratio\n        best_model = copy.deepcopy(net)\n    #\u6253\u5370\u51c6\u786e\u7387\u7b49\u6570\u503c\uff0c\u5176\u4e2d\u6b63\u786e\u7387\u4e3a\u672c\u8bad\u7ec3\u5468\u671fEpoch\u5f00\u59cb\u540e\u5230\u76ee\u524d\u64ae\u7684\u6b63\u786e\u7387\u7684\u5e73\u5747\u503c\n    print('\u8bad\u7ec3\u5468\u671f: {} \\tLoss: {:.6f}\\t\u8bad\u7ec3\u6b63\u786e\u7387: {:.2f}%, \u6821\u9a8c\u6b63\u786e\u7387: {:.2f}%'.format(\n        epoch, np.mean(train_losses), 100. * train_r[0].numpy() \/ train_r[1], 100. * val_r[0].numpy()\/val_r[1]))       \n    record.append([np.mean(train_losses), train_r[0].numpy() \/ train_r[1], val_r[0].numpy()\/val_r[1]])  ","f4940511":"# \u6253\u5370\u8bef\u5dee\u7387\u66f2\u7ebf\ny = [1 - x[1] for x in record]\nz = [1 - x[2] for x in record]\nplt.figure(figsize = (10, 7))\nplt.plot(y)\nplt.plot(z)\nplt.xlabel('Epoch')\nplt.ylabel('Error Rate')","aee44a83":"# \u5c06\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u7528\u8bed\u6d4b\u8bd5\u6570\u636e\uff0c\u6253\u5370\u5176\u5206\u7c7b\u6548\u679c\ndef visualize_model(model, num_images=6):\n    images_so_far = 0\n    fig = plt.figure(figsize=(15, 10))\n    \n    for i, data in enumerate(val_loader):\n        inputs, labels = data\n        if use_cuda:\n            inputs, labels = inputs.cuda(), labels.cuda()\n        outputs = model(inputs)\n        _, preds = torch.max(outputs.data, 1)\n        preds = preds.cpu().numpy() if use_cuda else preds.numpy()\n        for j in range(inputs.size()[0]):\n            images_so_far += 1\n            ax = plt.subplot(2, num_images\/\/2, images_so_far)\n            ax.axis('off')\n            ax.set_title('predictes: {}'.format(val_dataset.classes[preds[j]]))\n            imshow(inputs[j])\n            \n            if images_so_far == num_images:\n                return \n\nplt.ion()\nvisualize_model(net)\nplt.ioff()","d8f5d757":"# \u52a0\u8f7dresidual\u7f51\u7edc\u6a21\u578b\nnet = torchvision.models.resnet18(pretrained=True)\n# \u5c06\u6a21\u578b\u653e\u5165GPU\u4e2d\nnet = net.cuda() if use_cuda else net\n\n# \u5faa\u73af\u7f51\u7edc\uff0c\u5c06\u6240\u6709\u53c2\u6570\u8bbe\u4e3a\u4e0d\u66f4\u65b0\u68af\u5ea6\u4fe1\u606f\nfor param in net.parameters():\n    param.requires_grad = False\n\n# \u5c06\u7f51\u7edc\u6700\u540e\u4e00\u5c42\u73b0\u884c\u5c42\u6362\u6389\nnum_ftrs = net.fc.in_features\nnet.fc = nn.Linear(num_ftrs, 2)\nnet.fc = net.fc.cuda() if use_cuda else net.fc\n\ncriterion = nn.CrossEntropyLoss() #Loss\u51fd\u6570\u7684\u5b9a\u4e49\n# \u4ec5\u5c06\u7ebf\u6027\u5c42\u7684\u53c2\u6570\u653e\u5165\u4f18\u5316\u5668\u4e2d\noptimizer = optim.SGD(net.fc.parameters(), lr = 0.001, momentum=0.9)\n\nrecord = [] #\u8bb0\u5f55\u51c6\u786e\u7387\u7b49\u6570\u503c\u7684\u5bb9\u5668\n\n#\u5f00\u59cb\u8bad\u7ec3\u5faa\u73af\nnum_epochs = 20\nnet.train(True) # \u7ed9\u7f51\u7edc\u6a21\u578b\u505a\u6807\u8bb0\uff0c\u6807\u5fd7\u8bf4\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\nbest_model = net\nbest_r = 0.0\nfor epoch in range(num_epochs):\n    #optimizer = exp_lr_scheduler(optimizer, epoch)\n    train_rights = [] #\u8bb0\u5f55\u8bad\u7ec3\u6570\u636e\u96c6\u51c6\u786e\u7387\u7684\u5bb9\u5668\n    train_losses = []\n    for batch_idx, (data, target) in enumerate(train_loader):  #\u9488\u5bf9\u5bb9\u5668\u4e2d\u7684\u6bcf\u4e00\u4e2a\u6279\u8fdb\u884c\u5faa\u73af\n        data, target = data.clone().detach().requires_grad_(True), target.clone().detach() #data\u4e3a\u56fe\u50cf\uff0ctarget\u4e3a\u6807\u7b7e\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        output = net(data) #\u5b8c\u6210\u4e00\u6b21\u9884\u6d4b\n        loss = criterion(output, target) #\u8ba1\u7b97\u8bef\u5dee\n        optimizer.zero_grad() #\u6e05\u7a7a\u68af\u5ea6\n        loss.backward() #\u53cd\u5411\u4f20\u64ad\n        optimizer.step() #\u4e00\u6b65\u968f\u673a\u68af\u5ea6\u4e0b\u964d\n        right = rightness(output, target) #\u8ba1\u7b97\u51c6\u786e\u7387\u6240\u9700\u6570\u503c\uff0c\u8fd4\u56de\u6b63\u786e\u7684\u6570\u503c\u4e3a\uff08\u6b63\u786e\u6837\u4f8b\u6570\uff0c\u603b\u6837\u672c\u6570\uff09\n        train_rights.append(right) #\u5c06\u8ba1\u7b97\u7ed3\u679c\u88c5\u5230\u5217\u8868\u5bb9\u5668\u4e2d\n        loss = loss.cpu() if use_cuda else loss\n        train_losses.append(loss.data.numpy())\n\n    \n     #train_r\u4e3a\u4e00\u4e2a\u4e8c\u5143\u7ec4\uff0c\u5206\u522b\u8bb0\u5f55\u8bad\u7ec3\u96c6\u4e2d\u5206\u7c7b\u6b63\u786e\u7684\u6570\u91cf\u548c\u8be5\u96c6\u5408\u4e2d\u603b\u7684\u6837\u672c\u6570\n    train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n\n    #\u5728\u6d4b\u8bd5\u96c6\u4e0a\u5206\u6279\u8fd0\u884c\uff0c\u5e76\u8ba1\u7b97\u603b\u7684\u6b63\u786e\u7387\n    net.eval() #\u6807\u5fd7\u6a21\u578b\u5f53\u524d\u4e3a\u8fd0\u884c\u9636\u6bb5\n    vals = []\n    #\u5bf9\u6d4b\u8bd5\u6570\u636e\u96c6\u8fdb\u884c\u5faa\u73af\n    for data, target in val_loader:\n        data, target = data.clone().detach().requires_grad_(False), target.clone().detach()\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        output = net(data) #\u5c06\u7279\u5f81\u6570\u636e\u5582\u5165\u7f51\u7edc\uff0c\u5f97\u5230\u5206\u7c7b\u7684\u8f93\u51fa\n        val = rightness(output, target) #\u83b7\u5f97\u6b63\u786e\u6837\u672c\u6570\u4ee5\u53ca\u603b\u6837\u672c\u6570\n        vals.append(val) #\u8bb0\u5f55\u7ed3\u679c\n\n    #\u8ba1\u7b97\u51c6\u786e\u7387\n    val_r = (sum([tup[0] for tup in vals]), sum([tup[1] for tup in vals]))\n    val_ratio = 1.0*val_r[0].numpy()\/val_r[1]\n    \n    if val_ratio > best_r:\n        best_r = val_ratio\n        best_model = copy.deepcopy(net)\n    #\u6253\u5370\u51c6\u786e\u7387\u7b49\u6570\u503c\uff0c\u5176\u4e2d\u6b63\u786e\u7387\u4e3a\u672c\u8bad\u7ec3\u5468\u671fEpoch\u5f00\u59cb\u540e\u5230\u76ee\u524d\u64ae\u7684\u6b63\u786e\u7387\u7684\u5e73\u5747\u503c\n    print('\u8bad\u7ec3\u5468\u671f: {} \\tLoss: {:.6f}\\t\u8bad\u7ec3\u6b63\u786e\u7387: {:.2f}%, \u6821\u9a8c\u6b63\u786e\u7387: {:.2f}%'.format(\n        epoch, np.mean(train_losses), 100. * train_r[0].numpy() \/ train_r[1], 100. * val_r[0].numpy()\/val_r[1]))       \n    record.append([np.mean(train_losses), train_r[0].numpy() \/ train_r[1], val_r[0].numpy()\/val_r[1]])","f92002d8":"# \u6253\u5370\u8bef\u5dee\u66f2\u7ebf\nx = [x[0] for x in record]\ny = [1 - x[1] for x in record]\nz = [1 - x[2] for x in record]\n#plt.plot(x)\nplt.figure(figsize = (10, 7))\nplt.plot(y)\nplt.plot(z)\nplt.xlabel('Epoch')\nplt.ylabel('Error Rate')","50e72010":"# \u5c55\u793a\u5206\u7c7b\u7ed3\u679c\nvisualize_model(best_model)\n\nplt.ioff()\nplt.show()","c539ec2e":"## \u56db\u3001\u8fc1\u79fbResidual\u7f51\u7edc\u5e76\u56fa\u5b9a\u6743\u503c","47826d7d":"# \u8fc1\u79fb\u5927\u578b\u7f51\u7edc\n\n\u5728\u8fd9\u8282\u8bfe\u4e2d\uff0c\u6211\u4eec\u5c06\u5b66\u4f1a\u5982\u4f55\u8fc1\u79fb\u4e00\u4e2a\u5927\u578b\n\u7684\u5df2\u7ecf\u88ab\u8bad\u7ec3\u597d\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u5e2e\u52a9\u6211\u4eec\u5728\u5f88\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u5b8c\u6210\u8bad\u7ec3\uff0c\u5e76\u5f97\u5230\u6bd4\u8f83\u9ad8\u7684\u8bc6\u522b\u7cbe\u5ea6\u3002\n\u540c\u65f6\uff0c\u5728\u672c\u6587\u4ef6\u4e2d\uff0c\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u5b9e\u7528GPU\u6765\u8fdb\u884c\u8ba1\u7b97","2a46e2a0":"## \u4e00\u3001\u52a0\u8f7d\u6570\u636e\n\n\u5728\u8fd9\u91cc\u6211\u4eec\u5c06\u5b66\u4f1a\u5982\u4f55\u8fd0\u7528PyTorch\u7684dataset\u6765\u52a0\u8f7d\u786c\u76d8\u4e0a\u7684\u5927\u91cf\u56fe\u50cf  \n\u53ea\u8981\u6211\u4eec\u5c06\u5927\u91cf\u7684\u56fe\u50cf\u6587\u4ef6\u90fd\u653e\u5165\u6307\u5b9a\u7684\u6587\u4ef6\u5939\u4e0b(\u8bad\u7ec3\u6570\u636e\u96c6\u5728data\/train\u4e0b\u9762\uff0c\u6821\u9a8c\u6570\u636e\u96c6\u5728data\/val\u4e0b\u9762)  \n\u5e76\u4e14\u5c06\u4e0d\u540c\u7684\u7c7b\u522b\u5206\u522b\u653e\u5230\u4e0d\u540c\u7684\u6587\u4ef6\u5939\u4e0b\u3002  \n\u4f8b\u5982\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u6709\u4e24\u4e2a\u7c7b\u522b\uff1abees\u548cants\uff0c\u6211\u5c31\u9700\u8981\u5728\u786c\u76d8\u4e0a\u5efa\u7acb\u4e24\u4e2a\u6587\u4ef6\u5939\uff1abees\u548cants\u3002","b5ff4366":"## \u4e8c\u3001\u52a0\u8f7d\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u5bf9\u6bd4\n## \u4e09\u3001\u52a0\u8f7d\u5df2\u8bad\u7ec3\u597d\u7684Residual Network\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u9884\u8bad\u7ec3"}}