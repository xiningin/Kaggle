{"cell_type":{"4ad4fc77":"code","5a2f49eb":"code","302ed4e1":"code","663c38b7":"code","daa6ab3a":"code","8bc73144":"code","d693c48f":"code","6ca6d6e7":"code","fc42e3e6":"code","8c9f39e5":"code","0bd7478b":"code","f7c7578c":"code","ee8bbd78":"code","54749a1d":"code","9dde7503":"code","c70d05b9":"markdown","e7daa67c":"markdown","fd21b4f0":"markdown","2c23abc3":"markdown","22989a3e":"markdown","aef389f9":"markdown","690ce1bb":"markdown","e19af5c7":"markdown","33eeec2d":"markdown","4ad1184b":"markdown","ccc02337":"markdown"},"source":{"4ad4fc77":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5a2f49eb":"#se incluyen las librerias para el analisis\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n","302ed4e1":"# se importa el dataframe \ndf = pd.read_csv(\"..\/input\/top-5000-albums-of-all-time-rateyourmusiccom\/rym_top_5000_all_time.csv\")\n\n# dimensiones del dataframe\nprint('dimensiones del dataframe: ',df.shape)\ndf.head()","663c38b7":"# informacion general del dataframe\ndf.info()","daa6ab3a":"# descripcion estadistica \ndf.describe()","8bc73144":"# cuantos son valores NaN en la columna Descriptors\nprint('Valores NaN en la columna \"Descriptors\":', len(df[pd.isnull(df['Descriptors'])]))","d693c48f":"# Se reemplazan los valores NaN para la columna Descriptors\ndf['Descriptors'] = df['Descriptors'].fillna('Info no disponible')","6ca6d6e7":"# se convierte la columna de 'date_added' en formato fecha\ndf[\"Release Date\"] = pd.to_datetime(df['Release Date'])\n\n#se crea una columna con la informacion del a\u00f1o\ndf['year_added'] = df['Release Date'].dt.year\n\ndf.head()","fc42e3e6":"# distribucion de puntajes promedio\ncol = \"Average Rating\"\n\nvc1 = df[col].value_counts().reset_index()\nvc1 = vc1.rename(columns = {col : \"count\", \"index\" : col})\nvc1['percent'] = vc1['count'].apply(lambda x : 100*x\/sum(vc1['count']))\nvc1 = vc1.sort_values(col)\n\ntrace1 = go.Bar(x=vc1[col], y=vc1[\"count\"], name=\"Puntuacion\", marker=dict(color=\"#b20710\"))\n\ndata = [trace1]\nlayout = go.Layout(title=\"Distribuci\u00f3n de puntajes promedio\", legend=dict(x=1.1, y=1.1, orientation=\"h\"))\nfig = go.Figure(data, layout=layout)\nfig.show()","8c9f39e5":"import collections\ncol = \"Genres\"\ncategories = \", \".join(df['Genres']).split(\", \")\ncounter_list = collections.Counter(categories).most_common(10)\nlabels = [_[0] for _ in counter_list][::-1]\nvalues = [_[1] for _ in counter_list][::-1]\ntrace1 = go.Bar(y=labels, x=values, orientation=\"h\", name=\"Generos\", marker=dict(color=\"#221f1f\"))\n\ndata = [trace1]\nlayout = go.Layout(title=\"N\u00famero de rese\u00f1as por g\u00e9nero (top 10)\", legend=dict(x=0.1, y=1.1, orientation=\"h\"))\nfig = go.Figure(data, layout=layout)\nfig.show()","0bd7478b":"years = df['year_added']\n\nintervalos = range(min(df['year_added']), max(df['year_added'])) #calculamos los extremos de los intervalos\n\nplt.hist(x=years, bins=intervalos, color=\"#b20710\",ec='white')\nplt.title('Numero de publicaciones de albunes por a\u00f1o', size = '15')\nplt.xlabel('a\u00f1o')\nplt.ylabel('Numero de publicaiones')\n\nplt.show() #dibujamos el histograma","f7c7578c":"# se importa WordCloud\nfrom wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image","ee8bbd78":"descriptors = ''\nfor i in range(len(df.Descriptors) - 1):\n    descriptors = descriptors + df.Descriptors[i]\n    \n# se carga una marcara (disco de vinilo)\n# disc_mask = np.array(Image.open('disc2.jpg'))\n\n#Se configuran los parametros para la nube de palabras\nwc = WordCloud(width=200,\n               height=200,\n               max_words=150,\n               colormap='Dark2',\n               #mask=disc_mask,\n               collocations=True,\n               contour_color='black',\n               contour_width=0.5,\n               max_font_size=122, \n               background_color='white').generate_from_text(descriptors)\n    \n\nplt.figure(figsize=(10,10))\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","54749a1d":"import collections\nartist = \", \".join(df['Artist Name']).split(\", \")\ncounter_list = collections.Counter(artist).most_common(10)\nlabels = [_[0] for _ in counter_list][::-1]\nvalues = [_[1] for _ in counter_list][::-1]\ntrace1 = go.Bar(y=labels, x=values, orientation=\"h\", name=\"Generos\", marker=dict(color=\"#221f1f\"))\n\ndata = [trace1]\nlayout = go.Layout(title=\"Artistas con mas albunes (top 10)\", legend=dict(x=0.1, y=1.1, orientation=\"h\"))\nfig = go.Figure(data, layout=layout)\nfig.show()","9dde7503":"for_rating = df.sort_values('Average Rating', ascending=False)\n\nlabels = for_rating['Artist Name'][:10]\nvalues = for_rating['Average Rating'][:10]\ntrace2 = go.Line(y=labels, x=values, orientation=\"h\", name=\"Artistas\", marker=dict(color=\"#221f1f\"))\n\ndata = [trace2]\nlayout = go.Line(title=\"Artistas con mejor puntaje (top 10)\", legend=dict(x=1.1, y=1.1, orientation=\"h\"),autosize=False,height=500)\nfig = go.Figure(data, layout=layout)\nfig.show()","c70d05b9":"La nube de palabras nos deja ver que los t\u00e9rminos m\u00e1s utilizados en las descripciones de los \u00e1lbumes son:\nmale vocals, melodic, rhythmic passionate, melancholic, atmospheric, estre los m\u00e1s sobresalientes\n\nVisualizamos ahora el n\u00famero de \u00e1lbumes publicados por artista","e7daa67c":"Podemos revisar el n\u00famero de publicaciones realizada a trav\u00e9s de los a\u00f1os ","fd21b4f0":"La descripci\u00f3n estad\u00edstica de los datos arroja el an\u00e1lisis sobre las caracter\u00edsticas num\u00e9ricas del dataframe, lo que indica que el resto de las caracter\u00edsticas son de tipo objeto\n\nLa informaci\u00f3n general del dataframe corrobora que solo 3 de las 9 caracter\u00edsticas son num\u00e9ricas mientras las dem\u00e1s son de tipo objeto. tambi\u00e9n se observa que la caracter\u00edstica \"descriptors\" contiene elementos NaN","2c23abc3":"Base de datos de kaglee\nhttps:\/\/www.kaggle.com\/michaelbryantds\/top-5000-albums-of-all-time-rateyourmusiccom\n\nEste conjunto de datos contiene los mejores 5000 \u00e1lbumes de todos los tiempos seg\u00fan lo decidido por los usuarios de rateyourmusic.com \n\nEn este notebook nos ocuparemos de realizar un an\u00e1lisis exploratorio de los datos de los 5000 \u00e1lbumes m\u00e1s sobresalientes de todos los tiempos e identificar sus atributos m\u00e1s relevantes.","22989a3e":"Una caracter\u00edstica de inter\u00e9s para este caso es la puntuaci\u00f3n promedio, por lo que podemos graficar su distribuci\u00f3n.","aef389f9":"# **EDA con Phyton: Top 5000 \u00e1lbumes de todos los tiempos**","690ce1bb":"La distribuci\u00f3n de calificaciones promedio muestra que la calificaci\u00f3n m\u00e1s recurrente esta entre 3.6 y 3.7.\n\nLos g\u00e9neros existentes es bastante amplio por lo que graficamos solo para los 10 g\u00e9neros con m\u00e1s rese\u00f1as","e19af5c7":"Se identificaron 114 valores NaN en la columna \"descriptors\", los cuales fueron reemplazados por \"Info no disponible\". Esto anterior permite mantener las dimensiones de la columna sin afectar la informaci\u00f3n contenida, dado que es un numero peque\u00f1o de elementos comparado con el tama\u00f1o del dataframe,(2.28%). \n\nLa columna \"Release Date\" contiene la informaci\u00f3n de la fecha de publicaci\u00f3n del \u00e1lbum. Esta es una informaci\u00f3n interesante para el an\u00e1lisis, por lo que para este caso se puede separar el a\u00f1o en una nueva columna.","33eeec2d":"La grafica de numero de \u00e1lbumes publicados por a\u00f1o muestra el principio de las d\u00e9cada de los 70's como la d\u00e9cada con mayor n\u00famero de publicaciones\n\nResulta interesante ver los t\u00e9rminos con mayor frecuencia en las descripciones de los \u00e1lbumes y ver cu\u00e1les son los m\u00e1s recurrentes. Para esto realizaremos una nube de palabras (WordCloud)","4ad1184b":"la mayor\u00eda de los \u00e1lbumes corresponden a \"varios artistas\", seguido por Miles Davis como artista con m\u00e1s \u00e1lbumes como cantante individual.\n\nPor ultimo finalizaremos revisando los artistas que obtuvieron los mayores puntajes promedio ","ccc02337":"Se puede observar que la mayor calificaci\u00f3n promedio la obtuvo Mingus con 4.34 seguido de Jhon Coltrane y King Crismson con una calificaci\u00f3n de 4.3. se muestran solo los 10 mejores puntajes debido a la cantidad de artistas del dataframe."}}