{"cell_type":{"e1abc5f8":"code","90836472":"code","27002c1e":"code","bf3d37af":"code","25ec643b":"code","5222737a":"code","b7d0d95f":"code","db6cabeb":"code","f50960ae":"code","ab2e1cc6":"code","16f726b7":"code","d6c6caed":"code","820a7c1b":"code","108126be":"code","8e7bdafd":"code","ddba525d":"code","416b2424":"code","d1f8880f":"code","e1c51baf":"code","b5107e8a":"code","1fe256d5":"code","44f60981":"markdown","15db3f2c":"markdown","bcaaec09":"markdown","789316f2":"markdown","880d47ea":"markdown","26f47e4b":"markdown","05920e2b":"markdown","843c9a48":"markdown","9248abc3":"markdown","7553a31a":"markdown","66700a00":"markdown","a5342f4f":"markdown","5f44b3cf":"markdown","8fd33efa":"markdown","86a735a2":"markdown"},"source":{"e1abc5f8":"import pandas as pd\nimport numpy as np\n\nfrom pathlib import Path","90836472":"DATA = Path('..\/input\/dat801-2021-assignment1')\ndf_train = pd.read_csv(DATA\/'train.csv')\ndf_test = pd.read_csv(DATA\/'test.csv')","27002c1e":"df_train.drop('id', axis=1, inplace=True)\ndf_train.head()","bf3d37af":"df_train['target'].hist()","25ec643b":"df_train.median().value_counts()","5222737a":"df_train.max().max()","b7d0d95f":"df_train.isnull().sum().sum()","db6cabeb":"X = df_train.drop('target', axis=1)\ny = df_train.target\nX_test = df_test.drop('id', axis=1)","f50960ae":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.7, random_state=123)","ab2e1cc6":"from catboost import CatBoostClassifier, metrics\nfrom sklearn.metrics import accuracy_score\n","16f726b7":"cb_clf = CatBoostClassifier(\n    eval_metric=metrics.Accuracy(),\n    loss_function='MultiClass',\n    random_seed=123,\n    #logging_level='Silent'\n)","d6c6caed":"cb_clf.fit(X_train, y_train, eval_set=(X_val, y_val), plot=True)","820a7c1b":"print('Default accuracy: {:.4}'.format(\n    accuracy_score(y_val, cb_clf.predict(X_val))\n))","108126be":"from catboost import cv, Pool\nparams = {\n    'iterations': 500,\n    'learning_rate': 0.1,\n    'eval_metric': metrics.Accuracy(),\n    'random_seed': 123,\n    'logging_level': 'Silent',\n    'use_best_model': False\n}\ntrain_pool = Pool(X_train, y_train)\nvalidate_pool = Pool(X_val, y_val)","8e7bdafd":"model = CatBoostClassifier(**params)\nmodel.fit(train_pool, eval_set=validate_pool)\n\nbest_model_params = params.copy()\nbest_model_params.update({\n    'use_best_model': True\n})\nbest_model = CatBoostClassifier(**best_model_params)\nbest_model.fit(train_pool, eval_set=validate_pool);\n\nprint('Simple model validation accuracy: {:.4}'.format(\n    accuracy_score(y_val, model.predict(X_val))\n))\nprint('')\n\nprint('Best model validation accuracy: {:.4}'.format(\n    accuracy_score(y_val, best_model.predict(X_val))\n))","ddba525d":"model = CatBoostClassifier(\n    #l2_leaf_reg=int(best['l2_leaf_reg']),\n    l2_leaf_reg=4.0,\n    #learning_rate=best['learning_rate'],\n    learning_rate=0.03504763112221998,\n    iterations=500,\n    eval_metric=metrics.Accuracy(),\n    random_seed=123,\n    verbose=False,\n    loss_function='MultiClass',\n)\ncv_data = cv(Pool(X, y), model.get_params())","416b2424":"print('Mean accuracy score: {}'.format(np.max(cv_data['test-Accuracy-mean'])))","d1f8880f":"model.get_params()","e1c51baf":"model.fit(X, y)","b5107e8a":"submission = pd.DataFrame()\nsubmission['id'] = df_test['id']\nsubmission['target'] = model.predict(X_test)\nsubmission.head()","1fe256d5":"submission.to_csv('submission.csv', index=False)","44f60981":"Neste utfordring er dataene som ikke f\u00f8lger en normalfordeling.","15db3f2c":"Fors\u00f8ker med hyperopt: http:\/\/hyperopt.github.io\/hyperopt\/","bcaaec09":"...og enkeltverdier ligger p\u00e5 helt opp til over 300.","789316f2":"Pr\u00f8ver en alternativ metode og med learning_rate = 0.1:","880d47ea":"Kan l\u00f8nne seg \u00e5 lese manualen n\u00e5r det gjelder optimale dataformat. Litt som xgboost har DMatrix s\u00e5 har catboost en klasse som heter FeaturesData.","26f47e4b":"import hyperopt\ndef hyperopt_objective(params):\n    model = CatBoostClassifier(\n        l2_leaf_reg=int(params['l2_leaf_reg']),\n        learning_rate=params['learning_rate'],\n        iterations=500,\n        eval_metric=metrics.Accuracy(),\n        random_seed=123,\n        verbose=False,\n        loss_function='MultiClass',\n    )\n    \n    cv_data = cv(\n        Pool(X, y),\n        model.get_params()\n    )\n    best_accuracy = np.max(cv_data['test-Accuracy-mean'])\n    \n    return 1 - best_accuracy # as hyperopt minimises","05920e2b":"{'l2_leaf_reg': 4.0, 'learning_rate': 0.03504763112221998}","843c9a48":"catboost, xgboost, samt dypl\u00e6ringsbiblioteker som fastai tar seg av manglende data s\u00e5 her overlates jobben til catboost. Av og til kan manglende data settes til f.eks. -900 eller lignende, men i f\u00f8lge manualen s\u00e5 gjenkjennes de fleste typer nan-betegnelser for catboost: https:\/\/catboost.ai\/en\/concepts\/algorithm-missing-values-processing.","9248abc3":"Medianene ligger p\u00e5 0, 1 og 2 (5 er klasse)...","7553a31a":"Og til slutt \u00f8rten tusen nans... :-)","66700a00":"De 9 klassene er skjevt fordelt. Det skal g\u00e5 an \u00e5 over- og undsersample for \u00e5 f\u00e5 tilbake  samme st\u00f8rrelse p\u00e5 datasettet, men med lik fordeling, men det gj\u00f8res ikke her.","a5342f4f":"### En l\u00f8sning med catboost som det g\u00e5r an \u00e5 eksperimentere litt med.\ncatboost: https:\/\/catboost.ai\/en\/docs\/\n\nhyperopt: http:\/\/hyperopt.github.io\/hyperopt\/","5f44b3cf":"Tilpasning med default parametre. catboost tar vare p\u00e5 optimalt antall iterasjoner.","8fd33efa":"Laster inn dataset from hell... ;-)","86a735a2":"from numpy.random import RandomState\n\nparams_space = {\n    'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n    'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 5e-1),\n}\n\ntrials = hyperopt.Trials()\n\nbest = hyperopt.fmin(\n    hyperopt_objective,\n    space=params_space,\n    algo=hyperopt.tpe.suggest,\n    max_evals=50,\n    trials=trials,\n    rstate=RandomState(123)\n)\n\nprint(best)"}}