{"cell_type":{"7df04774":"code","b59eac80":"code","889da3a2":"code","4b8cd440":"code","529e6c44":"code","949f5b99":"code","7c638121":"code","8d2c3ec3":"code","90dca181":"code","d4de4439":"code","e1e7c0b0":"code","cb484a2a":"code","04be1261":"code","96ca4ecd":"markdown","21bc285f":"markdown","496e8af8":"markdown"},"source":{"7df04774":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b59eac80":"# First we create a dataframe with the raw sales data, which we'll reformat later\nDATA = '..\/input\/'\nsales = pd.read_csv(DATA+'sales_train.csv', parse_dates=['date'], infer_datetime_format=True, dayfirst=True)\nsales.head()","889da3a2":"# Let's also get the test data\ntest = pd.read_csv(DATA+'test.csv')\ntest.head()","4b8cd440":"# Now we convert the raw sales data to monthly sales, broken out by item & shop\n# This placeholder dataframe will be used later to create the actual training set\ndf = sales.groupby([sales.date.apply(lambda x: x.strftime('%Y-%m')),'item_id','shop_id']).sum().reset_index()\ndf = df[['date','item_id','shop_id','item_cnt_day']]\ndf = df.pivot_table(index=['item_id','shop_id'], columns='date',values='item_cnt_day',fill_value=0).reset_index()\ndf.head()","529e6c44":"# Merge the monthly sales data to the test data\n# This placeholder dataframe now looks similar in format to our training data\ndf_test = pd.merge(test, df, on=['item_id','shop_id'], how='left')\ndf_test = df_test.fillna(0)\ndf_test.head()","949f5b99":"# Remove the categorical data from our test data, we're not using it\ndf_test = df_test.drop(labels=['ID', 'shop_id', 'item_id'], axis=1)\ndf_test.head()","7c638121":"# Now we finally create the actual training set\n# Let's use the '2015-10' sales column as the target to predict\nTARGET = '2015-10'\ny_train = df_test[TARGET]\nX_train = df_test.drop(labels=[TARGET], axis=1)\n\nprint(y_train.shape)\nprint(X_train.shape)\nX_train.head()","8d2c3ec3":"# To make the training set friendly for keras, we convert it to a numpy matrix\n# X_train = X_train.as_matrix()\n# X_train = X_train.reshape((214200, 33, 1))\n\n# y_train = y_train.as_matrix()\n# y_train = y_train.reshape(214200, 1)\n\nprint(y_train.shape)\nprint(X_train.shape)\n\n# X_train[:1]","90dca181":"# Lastly we create the test set by converting the test data to a numpy matrix\n# We drop the first month so that our trained LSTM can output predictions beyond the known time range\nX_test = df_test.drop(labels=['2013-01'],axis=1)\n# X_test = X_test.as_matrix()\n# X_test = X_test.reshape((214200, 33, 1))\nprint(X_test.shape)","d4de4439":"from lightgbm import LGBMRegressor","e1e7c0b0":"model=LGBMRegressor(\n        n_estimators=200,\n        learning_rate=0.03,\n        num_leaves=32,\n        colsample_bytree=0.9497036,\n        subsample=0.8715623,\n        max_depth=8,\n        reg_alpha=0.04,\n        reg_lambda=0.073,\n        min_split_gain=0.0222415,\n        min_child_weight=40)\n\n","cb484a2a":"print('Training time, it is...')\nmodel.fit(X_train, y_train,\n          \n         )","04be1261":"# Get the test set predictions and clip values to the specified range\ny_pred = model.predict(X_test).clip(0., 20.)\n\n# Create the submission file and submit!\npreds = pd.DataFrame(y_pred, columns=['item_cnt_month'])\npreds.to_csv('submission.csv',index_label='ID')","96ca4ecd":"## Build and Train the model","21bc285f":"## Get test set predictions and Create submission","496e8af8":"## Create training and test sets"}}