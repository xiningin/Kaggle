{"cell_type":{"622e0385":"code","d09b0f68":"code","f6cf30eb":"code","446d028f":"code","d0f87dde":"code","56dbc9d6":"code","beb218dc":"code","5559628d":"code","6c0a03b3":"code","f20616a5":"code","7e41a3ff":"code","edb79fde":"code","2e9900a5":"code","e6fa7f71":"code","69bbacbc":"code","318bc8e6":"code","a94f9959":"code","f175afed":"code","05082e18":"code","24213ef7":"code","06c38c4f":"code","13dfd6b5":"code","dd2756de":"code","d9401670":"code","cd2c0607":"code","be4196e5":"code","1709b0b2":"code","cc85811f":"code","acf9eaa6":"code","9f4e8c54":"code","bfab322d":"code","54e60be2":"code","cc568b45":"code","82b5f708":"code","e28c885b":"code","c286144f":"code","54fe1c20":"code","739e56ba":"code","b14bab78":"code","bfbb954d":"code","3535277c":"code","9b71d007":"code","18b58c4c":"code","f2e47cd0":"code","ad59f694":"code","c995717e":"code","0d5cc3a1":"markdown","feb55538":"markdown","26693a73":"markdown","e8204d5b":"markdown","ef47e6a4":"markdown","b482458f":"markdown","5def7c9b":"markdown","7402d6f4":"markdown","d68bd081":"markdown","539d7a58":"markdown","c47fb736":"markdown","5cef6929":"markdown","74684fe9":"markdown","370fb374":"markdown","01461091":"markdown","2de21eaf":"markdown","15122d8d":"markdown","97a8e052":"markdown","8a71c1b0":"markdown","414e45a5":"markdown","d6e411fb":"markdown","6929e654":"markdown","98da03e9":"markdown","cd8738d3":"markdown","7b81ae25":"markdown","c655b815":"markdown","dafcf91b":"markdown","e78a596b":"markdown","245f7a94":"markdown","48b9c950":"markdown","e7cf63c2":"markdown","da1b83e6":"markdown","9ece56ba":"markdown","5f7f7928":"markdown","0d5c7e95":"markdown","0e408ace":"markdown","3612ffef":"markdown","ba19e62a":"markdown","f008e61e":"markdown","e8056f09":"markdown","dc856481":"markdown","5aaa838f":"markdown","51fcc527":"markdown","68839f79":"markdown","ea9ef26d":"markdown","df2cbe2a":"markdown","54cb9afc":"markdown","40b7029f":"markdown","c794a9b3":"markdown"},"source":{"622e0385":"!pip install fastai --upgrade -q","d09b0f68":"from fastai.vision.all import *","f6cf30eb":"# download a sample of MNIST that contains images of just 3 and 7\npath = untar_data(URLs.MNIST_SAMPLE)","446d028f":"# displays the count of items, before listing the items. \npath.ls()","d0f87dde":"# the dataset has seperate training and valid sets.\n# lets look into training set\n(path\/'train').ls()","56dbc9d6":"# Let's take a look into one of its folders\n# Here, we use sorted to ensure we all get the same order of files\nthrees = (path\/'train'\/'3').ls().sorted()\nsevens = (path\/'train'\/'7').ls().sorted()\n\n# let's see number of images each folder contains\nlen(threes), len(sevens)","beb218dc":"im3_path = threes[1]\nim3 = Image.open(im3_path)\n\nim3","5559628d":"# NumPy array\n# Here, 4:10 indicates we requested the rows from index 4 (inclusice) to 10 (exclusive)\narray(im3)[4:10,4:10]","6c0a03b3":"# PyTorch tensor\ntensor(im3)[4:10,4:10]","f20616a5":"im3_t =tensor(im3)\n\ndf = pd.DataFrame(im3_t[4:25,4:25])\n\ndf.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')","7e41a3ff":"seven_tensors = [tensor(Image.open(o)) for o in sevens]\nthree_tensors = [tensor(Image.open(o)) for o in threes]\n\n# let's check the length of each category again.\nlen(seven_tensors), len(three_tensors)\n","edb79fde":"show_image(three_tensors[1])","2e9900a5":"stacked_sevens = torch.stack(seven_tensors).float()\/255\nstacked_threes = torch.stack(three_tensors).float()\/255\n\n\nstacked_threes.shape","e6fa7f71":"len(stacked_sevens.shape), stacked_sevens.ndim","69bbacbc":"mean3 = stacked_threes.mean(0)\n\nprint(\"This is the ideal number 3!!\")\nshow_image(mean3)","318bc8e6":"mean7 = stacked_sevens.mean(0)\n\nprint(\"This is the ideal number 7!!\")\nshow_image(mean7)","a94f9959":"# Let's take a sample 3.\na_3 = stacked_threes[1]\n\n# display the image.\nshow_image(a_3)","f175afed":"# With ideal 3.\ndist_3_l1 = (a_3 - mean3).abs().mean()\ndist_3_l2 = ((a_3 - mean3)**2).mean().sqrt()\n\nprint(\"Dist with ideal 3: L1\",dist_3_l1,', L2',dist_3_l2)\n\n# With ideal 7.\ndist_7_l1 = (a_3 - mean7).abs().mean()\ndist_7_l2 = ((a_3 - mean7)**2).mean().sqrt()\n\nprint(\"Dist with ideal 37: L1\",dist_7_l1,', L2',dist_7_l2)","05082e18":"F.l1_loss(a_3.float(),mean3), F.mse_loss(a_3,mean3).sqrt()","24213ef7":"valid_3_tensors = torch.stack([tensor(Image.open(o)) for o in (path\/'valid'\/'3').ls()])\nvalid_3_tensors = valid_3_tensors.float()\/255\n\nvalid_7_tensors = torch.stack([tensor(Image.open(o)) for o in (path\/'valid'\/'7').ls()])\nvalid_7_tensors = valid_7_tensors.float()\/255\n\nvalid_3_tensors.shape, valid_7_tensors.shape","06c38c4f":"def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\n\nmnist_distance(a_3, mean3)","13dfd6b5":"valid_3_dist = mnist_distance(valid_3_tensors, mean3)\n\nvalid_3_dist, valid_3_dist.shape","dd2756de":"def is_3(x):\n    return mnist_distance(x,mean3) < mnist_distance(x,mean7)\n\nis_3(a_3), is_3(a_3).float()","d9401670":"# Now, let's check for the whole validation set.\nis_3(valid_3_tensors)","cd2c0607":"acc_3 = is_3(valid_3_tensors).float().mean()\nacc_7 = 1- is_3(valid_7_tensors).float().mean()\n\nacc_3, acc_7, (acc_3 + acc_7)\/2","be4196e5":"def pr_eight(x,w):\n    (x*w).sum()","1709b0b2":"def f(x):\n    return x**2\n\n\ndef plot_function(f, tx=None, ty=None, title=None, min=-2, max=2, figsize=(6,4)):\n    x = torch.linspace(min,max)\n    fig,ax = plt.subplots(figsize=figsize)\n    ax.plot(x,f(x))\n    if tx is not None: ax.set_xlabel(tx)\n    if ty is not None: ax.set_ylabel(ty)\n    if title is not None: ax.set_title(title)\n\n# Plot a graph of this function.\nplot_function(f,'x','x**2')","cc85811f":"# picking a random value for x and plotting it on the graph.\nplot_function(f,'x','x**2')\nplt.scatter(-1.5,f(-1.5),color = 'red')","acf9eaa6":"xt = tensor(3.).requires_grad_()\n\n# we calcualte our function with that value.\nyt = f(xt)\nyt","9f4e8c54":"yt.backward()\n\n# Now, let's veiw the gradients.\nxt.grad","bfab322d":"xt = tensor([3.,4.,10.]).requires_grad_()\n\n# we'll add sum to our function so that it can take a vector and return a scalar.\ndef f(x):\n    return (x**2).sum()\n\nyt= f(xt)\nprint(yt)\n\n# calculating gradients.\nyt.backward()\nxt.grad","54e60be2":"# train and valid sets.\ntrain_x = torch.cat([stacked_threes, stacked_sevens]).view(-1,28*28)\nvalid_x = torch.cat([valid_3_tensors, valid_7_tensors]).view(-1,28*28)\n\n\n# Labels. 1 for 3's and 0 for 7's\ntrain_y = tensor([1] * len(threes) + [0] * len(sevens)).unsqueeze(1)\nvalid_y = tensor([1] * len(valid_3_tensors) + [0] * len(valid_7_tensors)).unsqueeze(1)","cc568b45":"dset = list(zip(train_x, train_y))\nvalid_dset = list(zip(valid_x, valid_y))\n\n# lets check first item\nx,y = dset[0]\nx.shape, y","82b5f708":"def init_params(size, std = 1.0):\n    return (torch.randn(size)*std).requires_grad_()\n\nweights = init_params((28*28,1))\n\nbias = init_params(1)","e28c885b":"def linear1(xb):\n    return xb@weights + bias\n\npreds = linear1(train_x)\npreds","c286144f":"corrects = (preds > 0.0).float() == train_y\ncorrects","54fe1c20":"# now accuracy for the first epoch( still we didn't back propogate)\ncorrects.float().mean().item()","739e56ba":"dl = DataLoader(dset, batch_size = 256)\nvalid_dl = DataLoader(valid_dset, batch_size= 256)","b14bab78":"def mnist_loss(preds , trgts):\n    preds = preds.sigmoid()\n    return torch.where(trgts ==1, 1-preds, preds).mean()\n\ndef calc_grad(xb, yb, model):\n    preds = model(xb)\n    loss = mnist_loss(preds, yb)\n    loss.backward()\n\ndef train_epoch(model, lr, params):\n    for xb, yb in dl:\n        calc_grad(xb, yb, model)\n        for p in params:\n            p.data -= p.grad*lr\n            p.grad.zero_()","bfbb954d":"def batch_acc(xb, yb):\n    preds = xb.sigmoid()\n    crct = (preds > 0.5) == yb\n    return crct.float().mean()\n\n\ndef validate_epoch(model):\n    accs = [batch_acc(model(xb),yb) for xb,yb in valid_dl]\n    return round(torch.stack(accs).mean().item(),4)","3535277c":"lr = 1\nparams = weights, bias\ntrain_epoch(linear1, lr, params)\nvalidate_epoch(linear1)","9b71d007":"for i in range(20):\n    train_epoch(linear1, lr, params)\n    print(validate_epoch(linear1))\n    ","18b58c4c":"linear_model= nn.Linear(28*28,1)","f2e47cd0":"opt = SGD(linear_model.parameters(),lr)\n\ndef train_epoch(model):\n    for xb, yb in dl:\n        calc_grad(xb, yb, model)\n        opt.step()\n        opt.zero_grad()","ad59f694":"def train_model(model, epochs):\n    for i in range(epochs):\n        train_epoch(model)\n        print(validate_epoch(model))\n        \n\n        \ntrain_model(linear_model, 20)","c995717e":"dls = DataLoaders(dl, valid_dl)\n\n\nlearn = Learner(dls, linear_model, opt_func= SGD,\n               loss_func= mnist_loss, metrics= batch_acc)\n\nlearn.fit(10, lr =lr)","0d5cc3a1":"The gradients only tell us the slope of our function, they don't actually tell us exactly how far to adjust the parameters. \n\nBut it gives us some idea of how far; if the slope is very large, then that may suggest that we have more adjustments to do, whereas if the slope is very small, that may suggest that we are close to the optimal value.","feb55538":"To turn this function into a machine learning classifier:\n\n1. Initialize the weights.\n2. For each image, use these weights to predict whether it appears to be a 3 or a 7.\n3. Based on these predictions, calculate how good the model is (its loss).\n4. Calculate the gradient, which measures for each weight, how changing that weight would change the loss\n5. Step (that is, change) all the weights based on that calculation.\n6. Go back to the step 2, and repeat the process.\n7. Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer).","26693a73":"That's our starting point. Let's train for one epoch and see if the accuracy increases.\n","e8204d5b":"Now, we can use Pandas DataFrame to color code these values using a gradient.","ef47e6a4":"Now, let's do it for our MNIST_SAMPLE dataset.","b482458f":"**PyTorch** is able to automatically compute the derivate of nearly any function!. \n\n\nNotice the special method *requires_grad_*? That's the magical incantation we use to tell PyTorch that we want to calculate gradients with respect to that variable at that value.\n\n\nFirst, let's pick a tensor value at which we want gradients.","5def7c9b":"#### Finally, we can compute what \"ideal\" 3 looks like. we calculate the mean of all image tensors by taking along dimension 0 of our stacked, rank-3 tensor,","7402d6f4":"Let's illustrate with a simple case. Define a simple function, the quadratic and let's pretend this is our loss function, and x is a weight parameter of the function.\n\nAnd a simple function *plot_function* which plots a graph for the given function.","d68bd081":"To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0, so our accuracy for each item can be calculated (using broadcasting, so no loops!)","539d7a58":"Measuring distance between our sample image and ideal images. And we'll be doing this using *mean squared error*\nand *mean absolute error*\n","c47fb736":"Now, lets do for few more epochs","5cef6929":"Now, we'll tell **PyTorch** to calculate gradients.\n\nThe \"backward\" here refers to backpropagation, which is the name given to the process of calculating the derivative of each layer.","74684fe9":"#### Stepping your parameters using an Optimization step.\n\nw -= w.grad * learning_rate\n\n* learning rate is often a number between 0.001 and 0.1\n\nIf you pick a learning rate that's too low, it can mean having to do a lot of steps.\n\nBut picking a learning rate that's too high is even worse\u2014it can actually result in the loss getting worse.\n\nIf the learning rate is too high, it may also \"bounce\" around, rather than actually diverging;\n\n","370fb374":"Now, we can calculate the accuracy for each of 3's and 7's, by taking average of all 3's and it's inverse for 7's.","01461091":"* Now, Pick an arbritrary 3 and let's measure it's distance from our \"ideal digits\"\n\n#### There are two main ways to measure distance.\n\n* Take the mean of the *absolute value* of differences. This is called *mean absolute difference* or *L1 norm*.\n\n* Take the mean of *square* of differences and then take the square root. This is called *root mean squared error* (RMSE) or *L2 norm*.","2de21eaf":"## Now we'll try to build a baseline model totally from scratch.\n\n### Approach: Pixel Similarity\n\n1. Find the pixel value for every pixel of the 3's, then do the same for the 7's.\n\n2. This us two group averages, from which we can call \"ideal\" 3 and 7.\n\n3. Then, to classify an image as one digit or the other, we will see which of these two ideal digits the image is most similar to. \n\n","15122d8d":"* The most important attribute of a tensor is it's shape. Shape is the size of each axis of a tensor.\n\n* And the length of tensor's shape is it's **rank**. Rank is the number of axes or dimensions in a tensor.\n\n* And one more way to get the rank is using `ndim`.\n","97a8e052":"#### Creating an Optimizer.\n\nIt will handle the SGD process for us.","8a71c1b0":"x is the image, with all of the rows stacked up end to end into a single long line.And we are assuming that the weights are a vector w. \n\nIf we have this function, then we just need some way to update the weights to make them a little bit better. \n\nWith such an approach, we can repeat that step a number of times, making the weights better and better, until they are as good as we can make them.\n\nWe want to find the specific values for the vector w that causes the result of our function to be high for those images that are actually 8s, and low for those images that are not. ","414e45a5":"#### Stochastic Gradient Descent (SGD):\n\nInstead of trying to find the similarity between an image and an \"ideal image,\" we could instead look at each individual pixel and come up with a set of weights for each one, such that the highest weights are associated with those pixels most likely to be black for a particular category.\n\nFor instance, pixels toward the bottom right are not very likely to be activated for a 7, so they should have a low weight for a 7, but they are likely to be activated for an 8, so they should have a high weight for an 8.\n\nThis can be represented as a function and set of weight values for each possible category\u2014for instance the probability of being the number 8:","d6e411fb":"A Dataset in PyTorch is required to return a tuple of (x,y) when indexed. Python provides a zip function which, when combined with list, provides a simple way to get this functionality","6929e654":"So, is our baseline model any good? To Quantify this, we must define a metric.\n\n\n#### Metric:\nIt's a number that is calculated based on the predictions of our model and the correct labels in our dataset, in order to tell how good our model is. We normally use *accuracy* as the metric for classification models. We want to calculate our metric over a *validation set*.","98da03e9":"Now, let's write a function `is_3` to tell whether a number is 3 or not!","cd8738d3":"Now, our training loop can be simplified.\n\nand using fastai's SGD class as an optimizer.","7b81ae25":"Let's take a look at one now. we'll use *Image* class from the *Python Imaging Library*(PIL), which is widely used for Opening, Manipulating and viewing Images. \n","c655b815":"#### Basic training loop for an epoch.","dafcf91b":"#### Calculating the gradients.\n\nThe one magic step is to calculate the gradients. The gradients will tell us how much we have to change each weight yo make our model better.\n\n**The derivative of a function tells you how much a change in it's parameters will change in it's result.**\n\nThe derivative calculates the change,rather than the value.\n\nYou can calculate the derivative with respect to one weight, and treat all the other ones as constant, then repeat that for each other weight. This is how all of the gradients are calculated, for every weight.","e78a596b":"In computers, everything is represented as number. To view the numbers that make up this image, we have to convert it to a *NumPy array* or a *PyTorch tensor*.","245f7a94":"Randomly Initialize weight for every pixel.\n\nThe function *weights x pixels* won't be flexible enough\u2014it is always equal to 0 when the pixels are equal to 0 (i.e., its intercept is 0).\n\nYou might remember from high school math that the formula for a line is y=w*x+b; we still need the b. We'll initialize it to a random number too.","48b9c950":"Now,we want to compute the average over all the images of the intensity of that pixel. \n\n* To do this, first we'll combine all these images in this list into a single 3D tensor or a *rank-3 tensor*. So we need to stack up individual tensors into a single tensor.\n\n* **PyTorch** comes with a function called `stack` which can be used for this purpose.\n\n**Note**:\n\n1. To take a mean, we have to cast our *integer* types to *float* types.\n\n2. Generally, when images are floats, the pixel values are expected to be between 0 and 1. So, we divide by 255 here.\n\n\n\n","e7cf63c2":"By using `ls()` which return an object of a special fastai class called L, which has same functionality of Python's built-in list, plus a lot more. ","da1b83e6":"### Fastai provides learner.fit which can be used instead of train_model. To create a Learner we first need to create a DataLoaders, by passing in our training and validation DataLoaders:","9ece56ba":"The magic of calculus allows us to directly figure out in which direction, and by roughly how much, to change each weight, without having to try all these small changes. The way to do this is by calculating **gradients**.","5f7f7928":"#### Model Training.","0d5c7e95":"For overall accuracy, we need to calculate the distance to ideal 3 for every image in the validation set.","0e408ace":"We have to create a DataLoader from our dataset.","3612ffef":"we can change our weight by a litle in the direction of slope, calculate our loss and then adjust again, and repeat this a few times. Eventually, we will go to the lowest point on the curve.","ba19e62a":"Now, let's create a function which defines our model.\n","f008e61e":"Now, we need to define a notion of *distance* -- that is, a function that calcualtes the distance between two images.","e8056f09":"* we're getting over 90% accuracy on both 3's and 7's with our simplest model.\n\nBut our Pixel similarity approach doesn't learn from it's experience. In other words, we can't reall improve our pixel similarity approach by modifying a set of parameters.\n\nTo do better, the system should start some real learning, One that can automatically modify itself to improve its performance. In other words, let's talk about the training process and the SGD.\n\n","dc856481":"We can use fastai's `show_image` function to display an image.","5aaa838f":"#### For validation accuracy\n","51fcc527":"#### Our Simple Model gave us the right prediction in this case","68839f79":"In both cases, the distance between our 3 and the \"ideal\" 3 is less than distance between the \"ideal\" 7.\n\n#### Let's calculate these loss functions with in-built PyTorch methods.\n\n* You'll find these inside `torch.nn.functional`.","ea9ef26d":"**Step 1**:\n\nLet's create a tensor containing all of our 3's together. But to create a tensor containing all the images in a directory, we'll use Python list comprehension to create a plain list of the single image tensors.\n","df2cbe2a":"The first thing we do is to replace our linear function with PyTorch's nn.Linear module.\n\nnn.Linear does the same thing as our init_params and Linear together. It contains both weights and bias in a single class.","54cb9afc":"## Create a Simple model that can clasify any image as a 3 or 7.","40b7029f":"Now, let's do this with an vector argutment.","c794a9b3":"#### Now, let's do the same thing for 7."}}