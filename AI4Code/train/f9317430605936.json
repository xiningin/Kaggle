{"cell_type":{"3968d82e":"code","7c99e908":"code","523bbbbb":"code","ab5801fa":"code","a79d0117":"code","a3194eb8":"code","f3dbc44e":"code","4ba06de8":"code","cf165253":"code","1e83e7f8":"code","840b3994":"code","2fc4a531":"code","224ab16b":"code","d9adacc7":"code","c8d96458":"code","053f7d1c":"code","7bed12da":"code","9885aec0":"code","52cde1e7":"code","228aaefe":"code","e8ae1a9b":"code","6693b6f9":"markdown","f8745320":"markdown","91800cb1":"markdown","7b16084c":"markdown","f51784cf":"markdown","ba122818":"markdown","70d0171b":"markdown","b1c90174":"markdown","6b34884d":"markdown","dfc2e096":"markdown","3700d93e":"markdown","a2398568":"markdown","8bb723c8":"markdown","42533644":"markdown","ec2e8ed1":"markdown","8285b864":"markdown","984d8bec":"markdown","ff71118d":"markdown","d5518eaf":"markdown","0154d75f":"markdown","fbdaad27":"markdown","c1c8f2e8":"markdown","ddae187c":"markdown"},"source":{"3968d82e":"!pip install --upgrade seaborn","7c99e908":"import os\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom matplotlib.pyplot import figure\nimport matplotlib.pyplot as plt","523bbbbb":"df_responses = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\ndf_responses = df_responses.drop([0])\ndf_responses","ab5801fa":"df_responses[df_responses['Q3']=='South Korea']","a79d0117":"df_responses[df_responses['Q3']=='Republic of Korea']","a3194eb8":"df_responses.loc[df_responses.Q3 =='Republic of Korea', 'Q3'] = 'South Korea'","f3dbc44e":"df_responses[df_responses['Q3']=='South Korea']","4ba06de8":"figure(num=None, figsize=(10, 14), dpi=80, facecolor='w', edgecolor='k')\nsns.histplot(df_responses, y=\"Q3\", hue=\"Q8\", stat=\"probability\", multiple=\"fill\", shrink=.6)","cf165253":"df_temp = df_responses.copy()\ndf_temp.loc[df_temp['Q8'] == 'Python'] = None\ndf_temp = df_temp[df_temp['Q8'].notna()]\n\nfigure(num=None, figsize=(10, 14), dpi=80, facecolor='w', edgecolor='k')\nsns.histplot(df_temp, y=\"Q3\", hue=\"Q8\", stat=\"probability\", multiple=\"fill\", shrink=.6)","1e83e7f8":"df_responses['Q7'] = df_responses[df_responses.columns[7:19]].apply(lambda x: len(x.dropna().astype(str)),axis=1)\n\nfigure(num=None, figsize=(10, 14), dpi=80, facecolor='w', edgecolor='k')\nsns.histplot(df_responses, y=\"Q3\", hue=\"Q7\", stat=\"probability\", multiple=\"fill\", shrink=.6)","840b3994":"df_responses['Q14'] = df_responses[df_responses.columns[53:63]].apply(lambda x: len(x.dropna().astype(str)),axis=1)\n\ndf_temp = df_responses.copy()\ndf_temp = df_temp[df_temp['Q14'].notna()]\n\nfigure(num=None, figsize=(10, 14), dpi=80, facecolor='w', edgecolor='k')\nsns.histplot(df_temp, y=\"Q3\", hue=\"Q14\", stat=\"probability\", multiple=\"fill\", shrink=.6)","2fc4a531":"figure(num=None, figsize=(10, 14), dpi=120, facecolor='w', edgecolor='k')\nsns.histplot(df_responses, y=\"Q3\", hue=\"Q15\", stat=\"count\", multiple=\"stack\", shrink=.6)","224ab16b":"df_temp = df_responses.copy()\ndf_temp.loc[ df_temp['Q15'] == '1-2 years' ] = None\ndf_temp.loc[ df_temp['Q15'] == '3-4 years' ] = None\ndf_temp.loc[ df_temp['Q15'] == 'I do not use machine learning methods' ] = None\ndf_temp.loc[ df_temp['Q15'] == 'Under 1 year' ] = None\ndf_temp.loc[ df_temp['Q15'] == '2-3 years' ] = None\ndf_temp.loc[ df_temp['Q15'] == '4-5 years' ] = None\ndf_temp = df_temp[df_temp['Q15'].notna()]\n\nfigure(num=None, figsize=(10, 14), dpi=120, facecolor='w', edgecolor='k')\nsns.histplot(df_temp, y=\"Q3\", hue=\"Q15\", stat=\"count\", multiple=\"stack\", shrink=.6)","d9adacc7":"df_tmps = []\ncols = ['Scikit-learn', 'TensorFlow', 'Keras', 'PyTorch', 'Fast.ai', 'MXNet', 'Xgboost', 'LightGBM', 'CatBoost', 'Prophet', 'H2O 3', 'Caret', 'Tidymodels', 'JAX']\nfor i in range(1, 1+len(cols)):\n    df_tmp = df_responses.groupby(['Q3', 'Q16_Part_'+str(i)]).size().reset_index(name=cols[i-1])\n    df_tmp = df_tmp.drop(['Q16_Part_'+str(i)], axis=1)\n    df_tmps.append(df_tmp)\n    \ndf_tmp_all = df_tmps[0]\nfor df in df_tmps[1:]:\n    df_tmp_all = df_tmp_all.merge(df, how='outer').fillna(0)\n    \ndf_tmp_all.head()","c8d96458":"corr = df_tmp_all.drop('Q3', axis=1).corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nfigure(num=None, figsize=(6, 6), dpi=120, facecolor='w', edgecolor='k')\nsns.heatmap(corr, mask=mask, cmap='YlGnBu')","053f7d1c":"df_tmps = []\ncols = ['Linear or Logistic Regression', 'Decision Trees or Random Forests', 'Gradient Boosting Machines', 'Bayesian Approaches',\n        'Evolutionary Approaches', 'Dense Neural Networks', 'Convolutional Neural Networks', 'Generative Adversarial Networks',\n        'Recurrent Neural Networks', 'Transformer Networks']\nfor i in range(1, 1+len(cols)):\n    df_tmp = df_responses.groupby(['Q3', 'Q17_Part_'+str(i)]).size().reset_index(name=cols[i-1])\n    df_tmp = df_tmp.drop(['Q17_Part_'+str(i)], axis=1)\n    df_tmps.append(df_tmp)\n    \ndf_tmp_all = df_tmps[0]\nfor df in df_tmps[1:]:\n    df_tmp_all = df_tmp_all.merge(df, how='outer').fillna(0)\n    \ncorr = df_tmp_all.drop('Q3', axis=1).corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nfigure(num=None, figsize=(6, 6), dpi=120, facecolor='w', edgecolor='k')\nsns.heatmap(corr, mask=mask, cmap='YlGnBu')","7bed12da":"df_tmps = []\ncols = ['Scikit-learn', 'TensorFlow', 'Keras', 'PyTorch', 'Fast.ai', 'MXNet', 'Xgboost', 'LightGBM', 'CatBoost', 'Prophet', 'H2O 3', 'Caret', 'Tidymodels', 'JAX']\nfor i in range(1, 1+len(cols)):\n    df_tmp = df_responses.groupby(['Q17_Part_8', 'Q16_Part_'+str(i)]).size().reset_index(name=cols[i-1])\n    df_tmp = df_tmp.drop(['Q16_Part_'+str(i)], axis=1)\n    df_tmps.append(df_tmp)\n    \ndf_tmp_all = df_tmps[0]\nfor df in df_tmps[1:]:\n    df_tmp_all = df_tmp_all.merge(df, how='outer').fillna(0)\n    \ndf_tmp_all.head()","9885aec0":"figure(num=None, figsize=(14, 6), dpi=120, facecolor='w', edgecolor='k')\nax = sns.barplot(data=df_tmp_all)","52cde1e7":"df_tmps = []\ncols = ['Analyze and understand data to influence product or business decisions',\n        'Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data',\n        'Build prototypes to explore applying machine learning to new areas',\n        'Build and\/or run a machine learning service that operationally improves my product or workflows',\n        'Experimentation and iteration to improve existing ML models',\n        'Do research that advances the state of the art of machine learning',\n        'None of these activities are an important part of my role at work', \n        'Other',]\nfor i in range(1, len(cols)):\n    df_tmp = df_responses.groupby(['Q3', 'Q23_Part_'+str(i)]).size().reset_index(name=cols[i-1])\n    df_tmp = df_tmp.drop(['Q23_Part_'+str(i)], axis=1)\n    df_tmps.append(df_tmp)\ndf_tmp = df_responses.groupby(['Q3', 'Q23_OTHER']).size().reset_index(name=cols[i])\ndf_tmp = df_tmp.drop(['Q23_OTHER'], axis=1)\ndf_tmps.append(df_tmp)\n    \ndf_tmp_all = df_tmps[0]\nfor df in df_tmps[1:]:\n    df_tmp_all = df_tmp_all.merge(df, how='outer').fillna(0)\n    \ndf_tmp_all.head()","228aaefe":"df_tmp_desc = df_tmp_all.describe().transpose()\ndf_tmp_desc = df_tmp_desc.drop(['25%', '50%', '75%', 'count'], axis=1)\ndf_tmp_desc.head()","e8ae1a9b":"unstacked_data = df_tmp_desc.unstack()\nunstacked_data = unstacked_data.reset_index()\nunstacked_data.columns = ['metric', 'Answer', 'value']\n\nfigure(num=None, figsize=(16, 10), dpi=120, facecolor='w', edgecolor='k')\nsns.barplot(data=unstacked_data, x=\"metric\", y=\"value\", hue=\"Answer\" )","6693b6f9":"## 4. Analysis of machine learning experiences by country (Q3 & Q15)","f8745320":"## 2. Analysis of the number of languages used on a regular basis by country (Q3 & Q7_part_1~12+Other)","91800cb1":"# EDA for Languages & Frameworks by countries\n\n> Focusing on the languages and frameworks used by country. I have analyzed using Kaggle's ML & DS survey data. This notebook is not good enough, but I ask for a lot of interest and comment.\n\n\n1. Analysis of importance of language by country using (Q3 & Q8)\n2. Analysis of the number of languages used on a regular basis by country (Q3 & Q7_part_1~12+Other)\n3. Analysis of the number of visualization libraries used on a regular basis by country (Q3 & Q14_part_1~11+Other)\n4. Analysis of machine learning experiences by country (Q3 & Q15)\n5. Analysis of machine learning framework by country (Q3 & Q16_Part_1~15+Other)\n6. Analysis of important activities by country (Q3 & Q23_Part_1~7+Other)\n7. (ing)\n8. (ing)\n9. (ing)\n10. (ing)","7b16084c":"# preprocess for Rebpulic of Korea.","f51784cf":"Let's start with the Pearson correlation between the frameworks used. \n\nPersonally, I use lightGBM a lot, but the user relationship between xgboost and deep learning framework seems to be high!","ba122818":"And look at the Pearson correlation between the ML algorithms used. \n\nThe correlation value is very high overall. It can be seen that Kagglers research and develop without being constrained by ML algorithms.","70d0171b":"I think I got the answer I wanted in that there are more Tensorflow and keras users than pytorch, but it was surprising that there were many scikit-learn users. Rather than a connection with GAN, experts who use GAN should take it as meaning that they know how to handle scikit-learn of course.","b1c90174":"Talking about how many data visualization libraries are handled is no different from the language. IMHO, people usually think that it's okay to choose 1-3 things they know how to do.\n\n[Q14] What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice\n","6b34884d":"Since the proportion of Python is high, excluding Python is as follows.","dfc2e096":"![image.png](attachment:image.png)","3700d93e":"I wondered how many great people there are with more than 5 years of experience.","a2398568":"There are some standard deviations, but on average, \"Analyze and understand data to influence product or business decisions\" seems to be the most important.","8bb723c8":"We can analyze which languages are important to each country through Q3 and Q8.\n\nPython is considered overwhelmingly important. After that, many people think R is important, but there are cases where it is not considered important by country. As for SQL and C++, it can be seen that opinions differ greatly by country.\n\n- [Q3]  'In which country do you currently reside?'\n- [Q8] 'What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice'","42533644":"Let's look at the distribution of machine learning experiences by country.\n\n[Q15] For how many years have you used machine learning methods?","ec2e8ed1":"It was nice to have shared some interesting data on Kaggle. It was a little disappointing that there was no data on the Tier. However, it was interesting to note that the use of each country was different.","8285b864":"## 1. Analysis of importance of language by country using (Q3 & Q8)","984d8bec":" Q7 consists of 12 parts and indicates which language is used on a regular basis. Since multiple selections are possible, combining this information will reveal how many languages are spoken per person. Let's look at it by country.\n \n We can see that there are many people who speak one to three languages. \n \n - [Q7] What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python, R, SQL, C, C++, Java, Javascript, Julia, Swift, Bash, MATLAB, None, Other","ff71118d":"## 6. Analysis of important activities by country (Q3 & Q23_Part_1~7+Other)\n\nQ: Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice\n- Analyze and understand data to influence product or business decisions\n- Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\n- Build prototypes to explore applying machine learning to new areas\n- Build and\/or run a machine learning service that operationally improves my product or workflows\n- Experimentation and iteration to improve existing ML models\n- Do research that advances the state of the art of machine learning\n- None of these activities are an important part of my role at work\n- Other","d5518eaf":"Through [Hoyeol Kim](https:\/\/www.kaggle.com\/elibooklover)'s comment, I found that the country (Q3) South Korea is divided into South Korea and Republic of Korea. Although actually used as two names, they represent the same country.","0154d75f":"## 3. Analysis of the number of visualization libraries used on a regular basis by country (Q3 & Q14_part_1~11+Other)","fbdaad27":"# EDA","c1c8f2e8":"## 5. Analysis of machine learning framework by country (Q3 & Q16_Part_1~15+Other)\n\nI am sorry that I didn't seem to be able to do the group efficiently.\nIf there is any better way, please let me know.","ddae187c":"Personally, I was curious about which framework GAN users prefer."}}