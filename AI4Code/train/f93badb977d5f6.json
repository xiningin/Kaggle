{"cell_type":{"1db753ed":"code","52219cf5":"code","8e41c759":"code","5d1133b0":"code","1cd4bed5":"code","d9788ed4":"code","a2583910":"code","1a436a24":"code","a1f8641e":"code","c80b5564":"code","c1967fd9":"code","3b5d7d1c":"code","c3abe028":"code","d189232c":"code","becf3632":"code","5fbf0af6":"code","dde27f18":"code","5dd2e935":"code","de895f5b":"code","0dce5833":"code","762589a9":"code","2670e7dd":"code","5a68e75d":"code","a91de0d6":"code","cf5715c4":"code","e51ab518":"code","304a5eea":"markdown","f43f5886":"markdown","2d90af13":"markdown","61128e5e":"markdown","2919c5e9":"markdown","9535403f":"markdown","aa40e6f3":"markdown"},"source":{"1db753ed":"# import all required libraries for reading, analysing and visualizing data\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\n\nimport os\nimport random\nimport cv2\nfrom tqdm import tqdm","52219cf5":"labels = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\nIMG_SIZE = 124","8e41c759":"# load all the images\ndef loadData(DIR):\n    X = []\n    Y = []\n    for label in labels:\n        path = os.path.join(DIR, label)\n        class_num = labels.index(label)\n        for img in tqdm(os.listdir(path)):\n            try:\n                arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                resized_arr = cv2.resize(arr, (IMG_SIZE, IMG_SIZE))\n                X.append(resized_arr)\n                Y.append(class_num)\n            except Exception as e:\n                print(e)\n    return (np.array(X), np.array(Y))","5d1133b0":"DIR = '\/kaggle\/input\/flowers-recognition\/flowers'\n(X, Y) = loadData(DIR)","1cd4bed5":"l = []\nfor img in Y:\n    l.append(labels[img])\nsns.countplot(l);","d9788ed4":"# any 10 random images\nfig, ax = plt.subplots(5, 2)\nfig.set_size_inches(15, 20)\nfor i in range(5):\n    for j in range(2):\n        l = random.randint(0, len(X))\n        ax[i, j].imshow(X[l])\n        ax[i, j].set_title('Flower: ' + labels[Y[l]])","a2583910":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","1a436a24":"# normalize the data\nX = X \/ 255\n\n# reshape the data\nX = X.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\nY = Y.reshape(-1, 1)\nY = keras.utils.to_categorical(Y, 5)","a1f8641e":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3)\n\n# Explore the dataset\nprint(\"X_train shape:\" + str(X_train.shape))\nprint(\"Y_train shape:\" + str(Y_train.shape))\nprint(\"X_test shape:\" + str(X_test.shape))\nprint(\"Y_test shape:\" + str(Y_test.shape))","c80b5564":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dropout, Flatten\nfrom keras.layers import Dense","c1967fd9":"model = Sequential(\n    [\n        Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', activation = 'relu', input_shape = (IMG_SIZE, IMG_SIZE, 3)),\n        MaxPool2D(pool_size = (2, 2), strides = (2, 2)),\n        \n        Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n        MaxPool2D(pool_size = (2, 2), strides = (2, 2)),\n        \n        Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n        MaxPool2D(pool_size = (2, 2), strides = (2, 2)),\n        \n        Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n        MaxPool2D(pool_size = (2, 2), strides = (2, 2)),\n        \n        Conv2D(filters = 512, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n        MaxPool2D(pool_size = (2, 2), strides = (2, 2)),\n        \n        Flatten(),\n        Dense(1024, activation = 'relu'),\n        Dropout(0.5),\n        Dense(5, activation = 'softmax')\n    ]\n)","3b5d7d1c":"model.summary()","c3abe028":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","d189232c":"history = model.fit(X_train, Y_train, epochs = 8, validation_split = 0.2)","becf3632":"# plot training and validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Val'], loc = 'upper left')\nplt.show()\n\n# plot training and validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Val'], loc = 'upper left')\nplt.show()","5fbf0af6":"# find the accuracy on train and test set\ntrain_loss, train_acc = model.evaluate(X_train, Y_train)\ntest_loss, test_acc = model.evaluate(X_test, Y_test)\nprint(\"Accuracy on train set is %f\" %(train_acc * 100)  + \"%\")\nprint(\"Accuracy on validation set is %f\" %(test_acc * 100)  + \"%\")","dde27f18":"from keras.applications import VGG19","5dd2e935":"pre_trained_model = VGG19(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')\n\nfor layer in pre_trained_model.layers[:19]:\n    layer.trainable = False\n\nmodel = Sequential(\n    [\n        pre_trained_model,\n        Flatten(),\n        Dense(5, activation = 'softmax')\n    ]\n)","de895f5b":"model.summary()","0dce5833":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","762589a9":"history = model.fit(X_train, Y_train, epochs = 6, validation_split = 0.2)","2670e7dd":"# plot training and validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Val'], loc = 'upper left')\nplt.show()\n\n# plot training and validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Val'], loc = 'upper left')\nplt.show()","5a68e75d":"# find the accuracy on train and test set\ntrain_loss, train_acc = model.evaluate(X_train, Y_train)\ntest_loss, test_acc = model.evaluate(X_test, Y_test)\nprint(\"Accuracy on train set is %f\" %(train_acc * 100)  + \"%\")\nprint(\"Accuracy on validation set is %f\" %(test_acc * 100)  + \"%\")","a91de0d6":"Y_pred = model.predict(X_test)\nY_pred = np.argmax(Y_pred, axis = 1)\nY_test = np.argmax(Y_test, axis = 1)\n\n# get the correctly and incorrectly labelled images\ncorrect = np.nonzero(Y_pred == Y_test)[0]\nincorrect = np.nonzero(Y_pred != Y_test)[0]\n\nprint(\"correct shape:\" + str(correct.shape))\nprint(\"incorrect shape:\" + str(incorrect.shape))\n\n# Classification Report\nprint(classification_report(Y_test, Y_pred))","cf5715c4":"# subset of correcly predicted images\nfig, ax = plt.subplots(3, 2)\nfig.set_size_inches(12, 16)\ncur = 0\nfor i in range(3):\n    for j in range(2):\n        ax[i, j].imshow(X_test[correct[cur]])\n        ax[i, j].set_title(\"Predicted {}\\nActual {}\".format(labels[Y_pred[correct[cur]]], labels[Y_test[correct[cur]]]))\n        cur = cur + 1","e51ab518":"# subset of incorrecly predicted images\nfig, ax = plt.subplots(3, 2)\nfig.set_size_inches(12, 16)\ncur = 0\nfor i in range(3):\n    for j in range(2):\n        ax[i, j].imshow(X_test[incorrect[cur]])\n        ax[i, j].set_title(\"Predicted {}\\nActual {}\".format(labels[Y_pred[incorrect[cur]]], labels[Y_test[incorrect[cur]]]))\n        cur = cur + 1","304a5eea":"## Preprocessing of data","f43f5886":"## Load the dataset\n\nType of flowers in our dataset - \n* Daisy\n* Dandelion\n* Rose\n* Sunflower\n* Tulip","2d90af13":"## CNN Model from scratch","61128e5e":"## Visualizing the predictions","2919c5e9":"## Using pre-trained VGG19 model","9535403f":"## Data Visualization","aa40e6f3":"# Flower Recognition\n\nGiven the images of different types of flowers, we have to classify them according to their type."}}