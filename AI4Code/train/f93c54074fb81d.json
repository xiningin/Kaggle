{"cell_type":{"c9b652c8":"code","ee6c9f73":"code","48a0c37d":"code","fc73e81e":"code","0f6a7a8a":"code","4209dc66":"code","a285150c":"code","db787fda":"code","601b9934":"code","a42ccb93":"code","49f012d2":"code","4bc9af83":"code","06a3a97e":"code","b469c1b5":"code","16eade66":"code","bbeaa23d":"code","84ee3ca7":"code","c1af86c9":"code","8b71cf4c":"code","f1872221":"code","aec0fa1d":"markdown","d16211b6":"markdown","e895837a":"markdown","68b70ed9":"markdown","b7ad1a6a":"markdown","43327de4":"markdown","58d5d75f":"markdown","9444bdd4":"markdown","e370f796":"markdown"},"source":{"c9b652c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee6c9f73":"DATA_PATH = '\/kaggle\/input\/rs6-attrition-predict\/'\ntrain = pd.read_csv(f'{DATA_PATH}\/train.csv')\ntest = pd.read_csv(f'{DATA_PATH}\/test.csv')","48a0c37d":"len(train), len(test)","fc73e81e":"train.head()","0f6a7a8a":"test.head()","4209dc66":"train.columns","a285150c":"train.YearsAtCompany.unique()","db787fda":"id_col = 'user_id'\ntarget_col = 'Attrition'\n\ndigital_cols = ['Age', 'DailyRate', 'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike',\n                'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\ncategory_cols = ['BusinessTravel', 'Department', 'DistanceFromHome', 'Education', 'EducationField',\n                'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel',\n                'JobRole', 'JobSatisfaction', 'MaritalStatus', 'Over18', 'OverTime',\n                'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel', 'TrainingTimesLastYear',\n                'WorkLifeBalance']","601b9934":"for col in category_cols:\n    nunique_tr = train[col].nunique()\n    nunique_te = test[col].nunique()\n    na_tr = len(train.loc[train[col].isna()]) \/ len(train)\n    na_te = len(test.loc[test[col].isna()]) \/ len(test)\n    print(f'Col name:{col:30}\\tunique cate num in train:{nunique_tr:5}\\tunique cate num in train:{nunique_te:5}\\tnull sample in train:{na_tr:.2f}\\tnull sample in test:{na_te:.2f}')\n    ","a42ccb93":"for col in digital_cols:\n    min_tr = train[col].min()\n    max_tr = train[col].max()\n    mean_tr = train[col].mean()\n    median_tr = train[col].median()\n    std_tr = train[col].std()\n    \n    min_te = test[col].min()\n    max_te = test[col].max()\n    mean_te = test[col].mean()\n    median_te = test[col].median()\n    std_te = test[col].std()\n    \n    na_tr = len(train.loc[train[col].isna()]) \/ len(train)\n    na_te = len(test.loc[test[col].isna()]) \/ len(test)\n    print(f'Col name:{col:30}')\n    print(f'\\tIn train data: min value:{min_tr:.2f}\\tmax value:{max_tr:.2f}\\tmean value:{mean_tr:.2f}\\tmedian value:{median_tr:.2f}\\tstd value:{std_tr:.2f}\\tnan sample rate:{na_tr:.2f}\\t')\n    print(f'\\tIn  test data: min value:{min_te:.2f}\\tmax value:{max_te:.2f}\\tmean value:{mean_te:.2f}\\tmedian value:{median_te:.2f}\\tstd value:{std_te:.2f}\\tnan sample rate:{na_te:.2f}\\t')","49f012d2":"train[target_col].unique()","4bc9af83":"from sklearn.preprocessing import MinMaxScaler\n\nsacalar = MinMaxScaler()\ntrain_digital = sacalar.fit_transform(train[digital_cols])\ntest_digital = sacalar.transform(test[digital_cols])","06a3a97e":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\ntrain_category, test_category = None, None\ndrop_cols = ['EmployeeNumber', 'Over18', 'StandardHours']\nfor col in [var for var in category_cols if var not in drop_cols]:\n    lbe, ohe = LabelEncoder(), OneHotEncoder()\n    \n    lbe.fit(pd.concat([train[col], test[col]]).values.reshape(-1, 1))\n    train[col] = lbe.transform(train[col])\n    test[col] = lbe.transform(test[col])\n    \n    ohe.fit(pd.concat([train[col], test[col]]).values.reshape(-1, 1))\n    oht_train = ohe.transform(train[col].values.reshape(-1, 1)).todense()\n    oht_test = ohe.transform(test[col].values.reshape(-1, 1)).todense()\n    \n    if train_category is None:\n        train_category = oht_train\n        test_category = oht_test\n    else:\n        train_category = np.hstack((train_category, oht_train))\n        test_category = np.hstack((test_category, oht_test))","b469c1b5":"train_digital.shape, test_digital.shape, train_category.shape, test_category.shape","16eade66":"train_features = np.hstack((train_digital, train_category))\ntest_features = np.hstack((test_digital, test_category))\ntrain_features.shape, test_features.shape","bbeaa23d":"target_col_dict = {'Yes': 1, 'No': 0}\ntrain_labels = train[target_col].map(target_col_dict).values\ntrain_labels.shape","84ee3ca7":"from sklearn.linear_model import LinearRegression\n\nclf = LinearRegression()\nclf.fit(train_features, train_labels)","c1af86c9":"predictions = clf.predict(test_features)\npredictions.shape","8b71cf4c":"predictions.mean()","f1872221":"sub = test[['user_id']].copy()\nsub['Attrition'] = predictions\nsub['Attrition'] = sub['Attrition'].apply(lambda x: x if x >=0 else 0.0005)\nsub.to_csv('submission.csv', index=False)","aec0fa1d":"2. for category cols","d16211b6":"## Predicting","e895837a":"3. for labels","68b70ed9":"1. for digital cols","b7ad1a6a":"## Simple data eda","43327de4":"## Submit","58d5d75f":"## Data process","9444bdd4":"## Load data","e370f796":"## Train LR model"}}