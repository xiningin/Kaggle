{"cell_type":{"d18a4007":"code","2d41bf2d":"code","1e81dc60":"code","80899589":"code","14973266":"code","ec51f698":"code","592461d4":"code","d4104f5b":"code","08d5ec6d":"markdown","2df02273":"markdown","7e6146f5":"markdown"},"source":{"d18a4007":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import fbeta_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.display import display\nfrom time import time\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfilepath = '\/kaggle\/input\/udacity-mlcharity-competition\/'\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2d41bf2d":"data=pd.read_csv(filepath+'\/census.csv')\ndata.head(5)","1e81dc60":"subs_df=pd.read_csv('..\/input\/udacity-mlcharity-competition\/example_submission.csv')\ntest_census_df= pd.read_csv(filepath+'\/test_census.csv')\ntest_census_df.head(5)","80899589":"vis = sns.boxplot(data=data, x=data['income'], y=data['age'])\nfig = vis.get_figure()","14973266":"# TODO: Total number of records\nn_records = data.shape[0]\n\n# TODO: Number of records where individual's income is more than $50,000\nn_greater_50k = data[data['income'] == '>50K'].shape[0]\n\n# TODO: Number of records where individual's income is at most $50,000\nn_at_most_50k = data[data['income']  == '<=50K'].shape[0]\n\n# TODO: Percentage of individuals whose income is more than $50,000\ngreater_percent = float(n_greater_50k)*100\/n_records\n\n# Print the results\nprint(\"Total number of records: {}\".format(n_records))\nprint(\"Individuals making more than $50,000: {}\".format(n_greater_50k))\nprint(\"Individuals making at most $50,000: {}\".format(n_at_most_50k))\nprint(\"Percentage of individuals making more than $50,000: {}%\".format(greater_percent))","ec51f698":"income_raw = data['income']\nfeatures_raw = data.drop('income', axis = 1)\n\nplt.figure(figsize=(17,7))\nplt.subplot(2,2,1)\nsns.distplot(a=data['capital-gain'],hist=True,kde=False, color='r')\nplt.legend()\nplt.subplot(2,2,2)\nsns.distplot(a=data['capital-loss'],hist=True,kde=False, color='blue')\nplt.legend()","592461d4":"skewed = ['capital-gain', 'capital-loss']\nfeatures_log_transform = pd.DataFrame(data=features_raw)\nfeatures_log_transform[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n","d4104f5b":"subs_df.to_csv('sample_submission.csv',index=False)\nprint('Successful Submission!!')","08d5ec6d":"# Featureset Exploration\nage: continuous.\n\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, \n\nDoctorate, 5th-6th, Preschool.\n\neducation-num: continuous.\n\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n\nrace: Black, White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other.\n\nsex: Female, Male.\n\ncapital-gain: continuous.\n\ncapital-loss: continuous.\n\nhours-per-week: continuous.\n\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n\n**Preparing the Data**\n\nBefore data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured \u2014 this is typically known as preprocessing. Fortunately, for this dataset, there are no invalid or missing entries we must deal with, however, there are some qualities about certain features that must be adjusted. This preprocessing can help tremendously with the outcome and predictive power of nearly all learning algorithms.\n\n# Transforming Skewed Continuous Features\nA dataset may sometimes contain at least one feature whose values tend to lie near a single number, but will also have a non-trivial number of vastly larger or smaller values than that single number. Algorithms can be sensitive to such distributions of values and can underperform if the range is not properly normalized. With the census dataset two features fit this description: 'capital-gain' and 'capital-loss'.\n\nRun the code cell below to plot a histogram of these two features. Note the range of the values present and how they are distributed.","2df02273":"So we have been able to observe that the distribution curve of Capital-gain and loss is highly skewed, one way of tackling this is using logarithmic transformation on these columns","7e6146f5":"# Implementation: Data Exploration\nA cursory investigation of the dataset will determine how many individuals fit into either group, and will tell us about the percentage of these individuals making more than \\$50,000. In the code cell below, you will need to compute the following:\n\nThe total number of records, 'n_records'\nThe number of individuals making more than \\$50,000 annually, 'n_greater_50k'.\nThe number of individuals making at most \\$50,000 annually, 'n_at_most_50k'.\nThe percentage of individuals making more than \\$50,000 annually, 'greater_percent'."}}