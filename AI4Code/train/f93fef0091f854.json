{"cell_type":{"972447fc":"code","5600a93b":"code","85a18470":"code","be9ff7e3":"code","658469d0":"code","e42c29fa":"code","21b5d80e":"code","1bc64f3a":"code","fedf5106":"code","a95ecf89":"code","7888fafe":"code","bb7ab59d":"code","dbba213c":"code","3071f1d4":"code","d9ba760b":"code","a0a4a638":"code","a9abd1ad":"code","e4408aa4":"code","32dbac28":"code","fc689da9":"code","bc63368e":"code","479cc154":"code","a9888bfc":"code","194d3eea":"markdown","b6fba71d":"markdown","08a02152":"markdown","cce363e8":"markdown","f36ee068":"markdown","ea8e31b5":"markdown","ec3540c0":"markdown","1991099d":"markdown","29204447":"markdown","0535c068":"markdown","0462d347":"markdown","1c976f1b":"markdown","8b26c9be":"markdown","60a988b9":"markdown","f4efe3aa":"markdown","3d258af9":"markdown","83aaa385":"markdown","00d774d8":"markdown"},"source":{"972447fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5600a93b":"# Reading the train and test data\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\n\nprint(train.shape)\nprint(test.shape)","85a18470":"train.head()","be9ff7e3":"X_train = train.drop(['label'], axis = 1) #dependent variables \ny_train = train['label'] #independent variable\nX_test = test","658469d0":"X_train.isnull().sum()","e42c29fa":"X_test.isnull().sum()","21b5d80e":"X_train = X_train.values.reshape(-1,28,28,1)\nX_test = X_test.values.reshape(-1,28,28,1)\n","1bc64f3a":"X_train  = X_train\/255\nX_test  = X_test\/255\n#The above step can also be done in image augmentation part","fedf5106":"\nplt.imshow(X_test[7][:,:,0])","a95ecf89":"sns.barplot(x = y_train.value_counts().index, y =y_train.value_counts())","7888fafe":" y_train  = tf.keras.utils.to_categorical(y_train)","bb7ab59d":"\n# Creating Training and Validation Datasets\n\nfrom keras.preprocessing.image import ImageDataGenerator\nBS = 32    # Batch Size\n\ntrain_datagen = ImageDataGenerator(\n    shear_range=0.1,\n    zoom_range=0.2,\n    validation_split = 0.2)\n\ntraining_set = train_datagen.flow(\n    x = X_train,\n    y = y_train,\n    batch_size = BS,\n    shuffle = True,\n    subset = 'training')\n\nvalidation_set = train_datagen.flow(\n    x = X_train,\n    y = y_train,\n    batch_size = BS,\n    shuffle = True,\n    subset = 'validation')\n\n","dbba213c":"# Generating test data\n# Do not perform augmentation operation on test data\ntest_datagen = ImageDataGenerator()\ntest_set = test_datagen.flow(\n    x = X_test,\n    y = None,\n    batch_size = BS,\n    shuffle = False)\n","3071f1d4":"cnn = tf.keras.models.Sequential()\ncnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 5, activation = 'relu', input_shape = (28,28,1)))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 1))\n\ncnn.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 1))\n\ncnn.add(tf.keras.layers.Flatten())\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\ncnn.add(tf.keras.layers.Dense(units = 10, activation = 'softmax'))","d9ba760b":"EPOCHS = 25 # No. of Epochs\ncnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\ntest_model = cnn.fit(training_set, validation_data = validation_set, epochs = EPOCHS)","a0a4a638":"print(test_model.history.keys())","a9abd1ad":"# Plotting training accuracy and validaiton accuracy \nplt.plot(test_model.history['accuracy'])\nplt.plot(test_model.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train Accuracy', 'Validation Accuracy'], loc = 'upper right')\nplt.show()","e4408aa4":"# Plotting training loss and validaiton loss\nplt.plot(test_model.history['loss'])\nplt.plot(test_model.history['val_loss'])\nplt.title('Model Loss Performance')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train Loss', 'Validation Loss'], loc = 'upper right')\nplt.show()","32dbac28":"# Final model\ncnn.fit(training_set, validation_data = validation_set, epochs = 4)","fc689da9":"# Testing a sample image \n# test_image = X_test[7][:,:,0]\n# print(type(test_image))\n# test_image = np.expand_dims(test_image, axis = 2)\n# test_image.shape","bc63368e":"predict = cnn.predict_classes(test_set)","479cc154":"# Writing the test results to a separate dataframe\nsubmission = pd.DataFrame()\nsubmission['ImageId'] = pd.Series(range(1,28001))\nsubmission['Label'] = predict\nsubmission.to_csv('submission.csv', index = False)","a9888bfc":"# plt.imshow(test_set[0][15][:,:,0]","194d3eea":"## 5. Testing\n\nThe final model is used to predict the test data","b6fba71d":"## 3. Modelling CNN\n\nI used a 5 layered CNN architecture as the model. At the initial stage, it is prefearrable to use higher filter size ($ 5 \\times 5 $ is used in this case) to capture more information. In the second stage the filter size is decreased to $ 3 \\times 3 $. The pooling size is chosen as  $ 2 $. \n\nRelu is chosen as the activation function in hidden stages for faster convergence and adding non linearity to the network. The output of convolution and maxpooling layers is flattened and is fed as input to a 3 layered fully connected (dense) ANN. Relu is also chosen as the activation in these hidden layers also. At the output the softmax is chosen as the activation function which gives the probability distribution of the labels for a given input.\n","08a02152":"Initially, for low values of epochs (less than 4), the training accuracy is low which indicates underfitting. \nFor number of epochs around 4, the training and validation accuracies are almost the same. \nAs the value is increased beyond 8, the both patterns begins to diverge whcih clearly indicates overfitting. Hence for optimal model fitting, the number of epochs is chosen  as 4.","cce363e8":"## 2. Image Augmentation\n\nIn simple terms,image augmentation is done to prevent overfitting. For example, if I feed the trained model with a new image for testing, the model should be able to recognize the image even if it is rotated or enlarged or flipped. Hence from the given data, we could generate additonal training data by performing above operations (but vertical flip is not recommended since it could confuse the model from distinguishing 6 and 9). Also, training data is again split into validation set for evaluating the performance. \n","f36ee068":"## 1. Data Preparation\n\n","ea8e31b5":"Hence, the dataset is almost balanced. Before proceeding to image augmentation part, there is an additional step : One Hot encoding the class labels. In one hot encoding, a binary vector is created corresponding to each classes","ec3540c0":"# Digit Recognition Using Tensorflow\n\nMNIST Digit Recognition can be regarded as a 'Hello World' into Deep Learning based Computer Vision problems. \nMNIST dataset consists of images of handwritten digits (from 0 to 9). The objective is to recognize any handwritten digit outside the training data. Accuracy is chosen as the performance metric. \n\nI used Keras API for modelling the 5 layered CNN architecture. This is the overview on the steps I followed:\n After data preparation and checking the missing values, I performed  data augmentation - a way to prevent overfittng and to increase the capability to generalise. Then I modelled a Convolutional Neural Network architecture for solving\nOverview: \n 1. Data Preparation\n 2. Image Augmentation\n 3. Modelling CNN\n 4. Training and Validation to get appropriate model\n 5. Testing","1991099d":"## 4. Training and Validation\n\nInitially, the number of epochs is chosen as 25 (arbitrary value). ","29204447":"Now, we can proceed to image augmentation","0535c068":"Above data is in vectorial form (pixel values arranged in a single array). Hence it should be reshaped into the form of 2D images. This is necessary since we are training the data using CNN. ","0462d347":"In the image data, higher intensity values are represented as $ 255 $, while lower values are represened by $0$ values. However, it is better to normalize the data before training for faster convergence. A simple way to normalize is to divide the whole data by the maximum value (255).","1c976f1b":"There are 42000 training samples and 28000 testing samples. To get an overview, lets see some samples of training data.\n","8b26c9be":"Lets see if there are any missing values in train and test data","60a988b9":"Lets see a sample image","f4efe3aa":"In the provided dataset, images are represented as csv data where each entry indicates the intensity value of corresponding pixel. Hence, for a $ 28 \\times 28  $ image, there will be $ 28 \\times 28 = 784 $ pixel values. So the first step is to prepare the data into appropriate form.  ","3d258af9":"To check the distribution of the classes:\n","83aaa385":"With the final model, I was able to achieve **98.79% accuracy**. I think it is possible to improve the accuracy with a better hyperparameter tuning (no. of hidden layers, no of neurons, optimizer, etc.). I admit earlystopping is the more ideal method to find the optimal number of epochs. But I used  my approach to get a more intuitive feeling of what's really happening. ","00d774d8":"The first column of the training sample indicates the label and rest indicates the pixel values. Hence, we need to split the train data into dependent and independent variables and reshape the whole dataset into 2D images."}}