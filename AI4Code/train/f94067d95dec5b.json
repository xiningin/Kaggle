{"cell_type":{"3b65b5b6":"code","f4fb5749":"code","9fe49c95":"code","fb976af0":"code","f92ffd78":"code","cbf84871":"code","15fd69fe":"code","813dcb7d":"code","cbd9c974":"code","3059430e":"code","020a9263":"code","62a1a779":"code","5def4c9b":"code","7c51652a":"code","29a1c7a2":"code","0c4935ba":"code","5045d777":"code","301f58e5":"code","4c136083":"code","08128ef7":"code","2cb6701f":"code","104c9ec9":"code","ef61c43c":"code","7899b80a":"code","9a1918ad":"code","76d2d515":"code","51323bfc":"code","af0ef4a7":"code","0b322c2a":"code","f0cad11d":"code","e1763889":"code","d27dcff2":"code","68580729":"code","296139b8":"markdown","2250f3a5":"markdown","8d4b9ee2":"markdown","e3dee18f":"markdown","55df9cba":"markdown","1653fd37":"markdown","d2181a91":"markdown","88f4d593":"markdown","bf3ff69f":"markdown","830a44a6":"markdown","776c57d0":"markdown","cf9480d5":"markdown","76ccb7d6":"markdown","75898d6d":"markdown","d8026929":"markdown","d874d3db":"markdown","a2882d38":"markdown","15849d20":"markdown"},"source":{"3b65b5b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4fb5749":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9fe49c95":"tomato = \"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\"\nos.listdir(tomato)\n","fb976af0":"tomato_train = os.path.join(tomato, \"train\")\nprint(os.listdir(tomato_train))\nprint(\"*\"*100)\ntomato_test = os.path.join(tomato, \"valid\")\nprint(os.listdir(tomato_test))\n\n","f92ffd78":"# The glob module finds all the pathnames matching a specified pattern\nfrom glob import glob\nfolders = glob(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/*\")\nfolders","cbf84871":"# Lets dive into the image data. Lets go through few images\n# Diseased leaf\nplt.imshow(plt.imread\n           ('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Bacterial_spot\/00416648-be6e-4bd4-bc8d-82f43f8a7240___GCREC_Bact.Sp 3110.JPG'))\nplt.title('Bacterial spot');","15fd69fe":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Early_blight\/0034a551-9512-44e5-ba6c-827f85ecc688___RS_Erly.B 9432.JPG\"))\nplt.title(\"Early_blight\");\n\n","813dcb7d":"plt.imshow(plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Late_blight\/0003faa8-4b27-4c65-bf42-6d9e352ca1a5___RS_Late.B 4946.JPG\"))\nplt.title(\"Late_blight\");\n\n","cbd9c974":"plt.imshow(plt.imread\n           ('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Leaf_Mold\/00694db7-3327-45e0-b4da-a8bb7ab6a4b7___Crnl_L.Mold 6923.JPG'))\nplt.title('Leaf Mold')","3059430e":"plt.imshow(plt.imread\n           ('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Septoria_leaf_spot\/002533c1-722b-44e5-9d2e-91f7747b2543___Keller.St_CG 1831.JPG'))\nplt.title('Septoria leaf');","020a9263":"# Healthy leaf\nplt.imshow(plt.imread\n           ('..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___healthy\/000146ff-92a4-4db6-90ad-8fce2ae4fddd___GH_HL Leaf 259.1.JPG'))\nplt.title('Healthy leaf');","62a1a779":"import tensorflow as tf","5def4c9b":"tf.__version__","7c51652a":"\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential","29a1c7a2":"IMAGE_SIZE = [224, 224]","0c4935ba":"vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n","5045d777":"for layer in vgg16.layers:\n    layer.trainable = False","301f58e5":"x = Flatten()(vgg16.output)\n","4c136083":"len(folders)","08128ef7":"prediction= Dense(len(folders), activation = 'softmax')(x)","2cb6701f":"model = Model(inputs= vgg16.input, outputs= prediction)","104c9ec9":"model.summary()","ef61c43c":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","7899b80a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_data = ImageDataGenerator(rescale=1.\/255,\n                               shear_range=0.2,\n                               zoom_range=0.2,\n                               horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n","9a1918ad":"training_set = train_data.flow_from_directory(tomato_train, \n                                             target_size=(224, 224),\n                                             batch_size=32,\n                                             class_mode='categorical')","76d2d515":"testing_set = test_datagen.flow_from_directory(tomato_test,\n                                                 target_size=(224, 224),\n                                                 batch_size=32,\n                                                 class_mode=\"categorical\")","51323bfc":"r= model.fit_generator(training_set,\n                       validation_data=testing_set,\n                       epochs= 5,\n                       steps_per_epoch=len(training_set),\n                       validation_steps=len(testing_set)\n)","af0ef4a7":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\nplt.plot(r.history['accuracy'], label='train accuracy')\nplt.plot(r.history['val_accuracy'], label='val accuracy')\nplt.legend()\nplt.show()","0b322c2a":"y_pred = model.predict(testing_set)\ny_pred","f0cad11d":"y_pred = np.argmax(y_pred, axis=1)\n","e1763889":"y_pred","d27dcff2":"image_test = plt.imread(\"..\/input\/tomato\/New Plant Diseases Dataset(Augmented)\/train\/Tomato___Bacterial_spot\/00416648-be6e-4bd4-bc8d-82f43f8a7240___GCREC_Bact.Sp 3110.JPG\")","68580729":"plt.imshow(image_test)","296139b8":"## Please do upvote","2250f3a5":"### Lets take only 5 epochs due the computational speed limitation. Apply 30 epochs i recommend.\n","8d4b9ee2":" #### A \"Dense\" layer feeds all outputs from the previous layer to all its neurons, each neuron providing one output to the next layer. It's the most basic layer in neural networks. A Dense(10) has ten neurons.","e3dee18f":"### Join the train and test data","55df9cba":"#### A \"Sequential model\" is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.","1653fd37":"### Training and testing images","d2181a91":"### \u091f\u092e\u093e\u091f\u0930  - Tomato\n","88f4d593":"### Import the appropriate libraries","bf3ff69f":"#### \"Flattening\" is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer. In other words, we put all the pixel data in one line and make connections with the final layer.","830a44a6":"### Please do upvote and share your valuable feedback.","776c57d0":"### Read the data","cf9480d5":"### Model compilation","76ccb7d6":"### Data augmentation","75898d6d":"#### TensorFlow is an open source library for numerical computation and large-scale machine learning.","d8026929":"#### \"ImageDataGenerator\" generates batches of tensor image data with real-time data augmentation. The output images generated by the generator will have the same output dimensions as the input images.","d874d3db":"#### In many cases, where the size of the array is too large, it takes too much time to find the maximum elements from them. For this purpose, the numpy module of Python provides a function called numpy. argmax(). This function returns indices of the maximum values are returned along with the specified axis.","a2882d38":"#### \"VGG16\" is a convolutional neural network architecture ","15849d20":"### Thank you"}}