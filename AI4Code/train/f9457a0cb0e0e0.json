{"cell_type":{"f56f1211":"code","a66d4c06":"code","7b935eae":"code","0041233e":"code","ca2d81d4":"code","a508ffbc":"code","9641b71c":"code","3c382a18":"code","451760b9":"code","9a60ef9b":"code","7c7f930a":"code","35ead6e4":"code","1b5e690b":"code","7b3aa27a":"markdown","62f91b52":"markdown","12df3356":"markdown"},"source":{"f56f1211":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a66d4c06":"df=pd.read_csv('\/kaggle\/input\/mall-customers\/Mall_Customers.csv')\ndf.head()","7b935eae":"X=df.iloc[:,[3,4]].values","0041233e":"from sklearn.cluster import DBSCAN","ca2d81d4":"dbscan=DBSCAN(eps=3,min_samples=4)","a508ffbc":"model=dbscan.fit(X)","9641b71c":"labels=model.labels_","3c382a18":"from sklearn import metrics\nsample_cores=np.zeros_like(labels,dtype=bool)","451760b9":"#Intialy thw whole is false\nsample_cores","9a60ef9b":"sample_cores[dbscan.core_sample_indices_]=True","7c7f930a":"sample_cores","35ead6e4":"n_cluster=len(set(labels))-(1 if -1 in labels else 0)\nn_cluster","1b5e690b":"print(metrics.silhouette_score(X,labels))","7b3aa27a":"**Fitting**","62f91b52":"**Load the dataset**","12df3356":"**Import DBSAN from sklearn**"}}