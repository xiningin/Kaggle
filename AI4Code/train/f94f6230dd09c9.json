{"cell_type":{"f36d7d60":"code","3c4ed942":"code","4a329c7b":"code","72cab3d3":"code","d3462d70":"code","af33d27b":"code","d590e1f0":"code","3ea72e05":"code","74b721f7":"code","47dc1e43":"code","bb4bf5f0":"code","4917decb":"code","89674dbe":"code","c4ee56db":"code","98632806":"code","43ebfaa1":"code","74ce3d7b":"code","322c52b7":"code","48f2eedd":"code","dcd8d116":"code","b38f3fc1":"code","68024ab5":"code","ae0cfbe3":"code","526b74ae":"code","28322157":"code","2c10014b":"code","90924140":"code","37b5bd51":"code","00ec9d66":"code","a4d3ed50":"code","142af9ca":"code","ae05eb25":"code","25cd78b3":"code","4ae91c72":"code","f91b3b71":"code","b3692b7f":"code","06275708":"code","20768303":"code","0e67ce7d":"code","7b291e6a":"code","f2e8fd01":"code","7303ba34":"code","b693aa92":"code","a3e591ea":"code","8c2631d0":"code","0c3a1ac8":"code","aa081098":"code","e7b4d357":"code","a0789f38":"code","52a1c48f":"code","e49abcc6":"code","813494ad":"code","994c4375":"code","b62d0144":"code","54b0d2fc":"code","2f4e56f7":"code","7523bd16":"code","00582649":"code","ac0c3a96":"code","bf4d2f6f":"code","ca9dead8":"code","d29e4237":"code","83ab6df2":"code","8e8633a4":"code","a9ec8ce2":"code","20bb5bb2":"code","917367f3":"code","c623595b":"code","0e8b02b5":"code","7781107c":"code","c59a6e20":"code","a83bc17e":"code","764e47b9":"code","706a0473":"code","b3023f59":"code","2b92f211":"code","70bac907":"code","ba4ba5ef":"code","18f6e804":"code","4569dbb4":"code","ea5fec9c":"code","4d5aeff9":"code","b9b8e6f1":"code","aa313ec9":"code","e986c6c9":"code","d8102450":"code","bd81a940":"code","508e0705":"code","377b7c18":"code","06e8a954":"code","f19bf06e":"code","ec62128c":"code","21760300":"code","ad5a3977":"code","8820b467":"code","80be7dbb":"code","c69062f7":"code","5867eb0d":"code","cd1ab8b8":"code","9b44bb72":"code","8ba29a4a":"code","20435881":"code","7f2cb9ba":"code","2cb85701":"code","b8026790":"code","550089e3":"markdown","c4caf613":"markdown","13df5550":"markdown","76bd7366":"markdown","f35a0d05":"markdown","d564fbfc":"markdown","426fcbf7":"markdown","9dfef19c":"markdown","6866bc0d":"markdown","8b93b91e":"markdown","080cb197":"markdown","a3e19dd4":"markdown"},"source":{"f36d7d60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/feedback-prize-2021\/train\/'):\n    filenum = 1\n    for filename in filenames:\n        f = open(os.path.join(dirname, filename),'r')\n        doc = f.read()\n        doc_id = filename[:filename.find('.txt')]\n        doc_len = len(doc.split())\n        doc_df = pd.DataFrame([[doc_id,doc,doc_len]], columns=['id','text','word_num'])\n        if filenum == 1:\n            docs = doc_df\n        else:\n            docs = docs.append(doc_df, ignore_index=True)\n        filenum += 1\n        f.close()\n\ncsv_dirname = '\/kaggle\/input\/feedback-prize-2021\/'\ncsv_filename = 'train.csv'        \ndf = pd.read_csv(os.path.join(csv_dirname, csv_filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3c4ed942":"import seaborn as sns\nimport matplotlib.pyplot as plt","4a329c7b":"import nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize\n\n#stokenizer = nltk.data.load('tokenizers\/punkt\/english.pickle')","72cab3d3":"labels = df.discourse_type.unique()\nlabels_map = {'NO_TAG':0, 'Lead':1, 'Position':2, 'Evidence':3, 'Claim':4, 'Concluding Statement':5,\n             'Counterclaim':6, 'Rebuttal':7}\niob_labels = dict()\nindex = 0\nfor label in labels_map:\n    if label != 'NO_TAG':\n        iob_label = 'B-'+label\n        index +=1\n        iob_labels[iob_label] = index\n        iob_label = 'I-'+label\n        index +=1\n        iob_labels[iob_label] = index\n    else:\n        iob_labels[label] = index","d3462d70":"!pip install distilbert-punctuator","af33d27b":"#from dbpunctuator.inference import Inference, InferenceArguments\n#from dbpunctuator.utils import DEFAULT_ENGLISH_TAG_PUNCTUATOR_MAP\n#args = InferenceArguments(\n#        model_name_or_path=\"Qishuai\/distilbert_punctuator_en\",\n#        tokenizer_name=\"Qishuai\/distilbert_punctuator_en\",\n#        tag2punctuator=DEFAULT_ENGLISH_TAG_PUNCTUATOR_MAP\n#    )\n#punctuator_model = Inference(inference_args=args, \n#                             verbose=False)","d590e1f0":"def get_sentences(txt, txt_id):\n    sentences = sent_tokenize(txt)\n    sent_len = []\n    for sentence in sentences:\n        sent_len.append(len(sentence.split()))\n    df_sent = pd.DataFrame(sentences, columns=['sentences'])\n    df_sent['sentence_len'] = sent_len\n    df_sent['id'] = txt_id\n    return df_sent","3ea72e05":"docs['word_num'].describe()","74b721f7":"f, ax = plt.subplots(figsize=(10,2))\ndocs.boxplot(column='word_num', vert=False)\nplt.show","47dc1e43":"initial_docs = docs # keeping initial dataset for futur investigation\ndocs  = docs[docs.word_num <= 800]\ndocs.info()","bb4bf5f0":"kept_ids = docs.id.unique()","4917decb":"initial_df = df\ndf = df[df.id.isin(kept_ids)]\ndf.info()","89674dbe":"initial_df.head()","c4ee56db":"sns.countplot(df['discourse_type'], palette='gist_rainbow',)\nplt.xticks(rotation=45)\nplt.show()","98632806":"df.discourse_type.value_counts()","43ebfaa1":"from bs4 import BeautifulSoup","74ce3d7b":"for index, row in docs.iterrows():\n    raw_txt = row['text']\n    cleaned_txt = BeautifulSoup(raw_txt, \"lxml\").text\n    #txt_edit = punctuator_model.punctuation([cleaned_txt])[0]\n    #txt = txt_edit[0]\n    txt = cleaned_txt\n    docs.at[index,'processed_text'] = txt\n    txt_id = row['id']\n    df_sent = get_sentences(txt, txt_id)\n    prev = -1\n    for i,r in df_sent.iterrows():\n        df_sent.at[i,'word_start'] = prev+1\n        df_sent.at[i,'word_end'] = prev + r['sentence_len']\n        prev = df_sent.loc[i,'word_end']\n        \n    if index==0:\n        df_sentences = df_sent\n    else:\n        df_sentences = df_sentences.append(df_sent, ignore_index=True)\n    \n    ","322c52b7":"df_sentences.info()","48f2eedd":"df_sentences.head()","dcd8d116":"df_sentences.sentence_len.describe()","b38f3fc1":"f, ax = plt.subplots(figsize=(10,2))\ndf_sentences.boxplot(column='sentence_len', vert=False)\nplt.show","68024ab5":"df_sentences = df_sentences[df_sentences.sentence_len <= 25]","ae0cfbe3":"df_sentences = df_sentences[df_sentences.sentence_len > 2]","526b74ae":"df_sentences.info()","28322157":"df['discours_start_word'] = df['predictionstring'].apply(lambda l: float(l.split()[0]))\ndf['discours_end_word'] = df['predictionstring'].apply(lambda l: float(l.split()[-1]))","2c10014b":"df.head()","90924140":"def label_sentences(s, tags):\n    for index, row in s.iterrows():\n        sentence_start = row['word_start']\n        sentence_end = row['word_end']\n        # get all lignes corresponding to the sentence from tags\n        # if only on line is returned. - copy label\n        # if more than one - copy each slice\n        tags = tags.reset_index(drop=True)\n        left = tags[tags.discours_start_word >= sentence_start]\n        sentences_tags = left[left.discours_end_word <= sentence_end]\n    \n        returned_num = sentences_tags.shape[0]\n        #print(sentences_tags.shape[0])\n        if returned_num == 1:\n            s.at[index,'label'] = sentences_tags.iloc[0,5]\n            s.at[index,'discourse_text'] = sentences_tags.iloc[0,4]\n    \n        if returned_num == 0:\n            case2 = tags[tags.discours_start_word <= sentence_start]\n            discourse = case2[case2.discours_end_word >= sentence_end]\n            if discourse.shape[0] >0:\n                s.at[index,'label'] = discourse.iloc[0,5]\n                s.at[index,'discourse_text'] = discourse.iloc[0,4]\n    \n        if returned_num > 1:\n            # check if sentence is fully covered by discourses\n            #min_slice_start = sentences_tags.discours_start_word.min()\n            #max_slice_end = sentences_tags.discours_end_word.max()\n            #if sentence_start == min_slice_start and sentence_end == max_slice_end:\n            \n            s.at[index,'label'] = sentences_tags.iloc[0,5]\n            s.at[index,'discourse_text'] = sentences_tags.iloc[0,4]\n            \n    \n    return s\n        #s.at[index,'label'] = \"that's yet to be done\"\n        #s.at[index,'discourse_text'] = \"that's yet to be done\"\n        \n    #case 1: one sentence - one discours - one label\n    #case 2: a sentence is a part of discours, more than one sentence share the same label \n    #case 3: a sentences contains more than one discours\/label\n    ","37b5bd51":"first = True\nfor txt_id in kept_ids:\n    s = df_sentences[df_sentences.id == txt_id]\n    tags = df[df.id == txt_id]\n    labelled = label_sentences(s, tags)\n    # for each sentence in sentences map all its label and corresponding discours text\n    if first:\n        data = labelled\n        first = False\n    else:\n        data = data.append(labelled, ignore_index=True)\n    ","00ec9d66":"data.head()","a4d3ed50":"data.info()","142af9ca":"data = data.fillna('NO_TAG')","ae05eb25":"data.info()","25cd78b3":"import json\n\noutput_path = '\/kaggle\/working\/'\noutput_file = 'labeled_sentences.json'\ndfj = data.to_json(orient='index')\n\nwith open(os.path.join(output_path, output_file), 'w') as f:\n    json.dump(dfj, f)","4ae91c72":"from sklearn.model_selection import train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score,precision_score,recall_score\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV\nimport warnings \nwarnings.filterwarnings('ignore')","f91b3b71":"#X_train, X_test, y_train, y_test = train_test_split(data.id.values, \n#                                                    data.label.values, \n#                                                    test_size=0.2, \n#                                                    random_state=35)","b3692b7f":"#data['data_type'] = ['not_set']*data.shape[0]\n#data.loc[data.id.isin(X_train.tolist()), 'data_type'] = 'train'\n#data.loc[data.id.isin(X_test.tolist()), 'data_type'] = 'test'","06275708":"data.head()","20768303":"data = data[['sentences','id','label']]","0e67ce7d":"data['lbl'] = data['label'].apply(lambda x: labels_map[x])","7b291e6a":"X_train, X_test, y_train, y_test = train_test_split(data[['sentences']], \n                                                    data[['lbl']], \n                                                    test_size=0.2, \n                                                    random_state=35)","f2e8fd01":"X_train_ind, X_test_ind, y_train_ind, y_test_ind = train_test_split(data.index.values, \n                                                                    data.label.values, \n                                                                    test_size=0.2, \n                                                                    random_state=35)","7303ba34":"data['data_type'] = ['not_set']*data.shape[0]\ndata.loc[X_train_ind, 'data_type'] = 'train'\ndata.loc[X_test_ind, 'data_type'] = 'test'\n\ndata.groupby(['label', 'data_type']).count()","b693aa92":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = CountVectorizer()\ntfidf = TfidfVectorizer()","a3e591ea":"X_train.head()","8c2631d0":"print(\"Number of data points in train data :\", y_train.shape)\nprint(\"Number of data points in test data :\", y_test.shape)","0c3a1ac8":"from sklearn.metrics import f1_score,precision_score,recall_score","aa081098":"import multiprocessing\nimport gensim\nfrom sklearn import preprocessing","e7b4d357":"# Dimensionality of the resulting word vectors.\n#more dimensions, more computationally expensive to train\n#but also more accurate\n#more dimensions = more generalized\nnum_features = 200\n# Minimum word count threshold.\nmin_word_count = 1\n\n# Number of threads to run in parallel.\n#more workers, faster we train\nnum_workers = multiprocessing.cpu_count()\n\n# Context window length.\ncontext_size = 7\n\n# Downsample setting for frequent words.\n#0 - 1e-5 is good for this\ndownsampling = 1e-1\n\n# Seed for the RNG, to make the results reproducible.\n#random number generator\n#deterministic, good for debugging\nseed = 1","a0789f38":"def format_gensim(txt):\n    #tokenizer = nltk.RegexpTokenizer(r'\\w+')\n    tokens = txt.split()\n    return tokens\nposts = data['sentences'].apply(lambda x: format_gensim(x))","52a1c48f":"posts2vec = gensim.models.word2vec.Word2Vec(\n    workers=num_workers,\n    min_count=min_word_count,\n    window=context_size\n)\n\nposts2vec.build_vocab(posts)","e49abcc6":"def postVector(row):\n    vector_sum = 0\n    sentence = row.split()\n    #print(sentence)\n    for word in sentence:\n        vector_sum = vector_sum + posts2vec.wv[word]\n    vector_sum = vector_sum.reshape(1,-1)\n    normalised_vector_sum = preprocessing.normalize(vector_sum)\n    return normalised_vector_sum","813494ad":"def transform_text(in_data):\n    data = in_data.copy()\n    data['vector'] = data['sentences'].apply(lambda txt: postVector(txt))\n    data = data.drop(columns=['sentences'])\n    return data","994c4375":"x_train_vectors = transform_text(X_train)\ntrain_vectors = []\nfor vector in x_train_vectors['vector']:\n    train_vectors.append(vector)\nx_train_w2v = np.array(train_vectors).reshape((x_train_vectors.shape[0], 100))\n","b62d0144":"x_test_vectors = transform_text(X_test)\ntest_vectors = []\nfor vector in x_test_vectors['vector']:\n    test_vectors.append(vector)\nx_test_w2v = np.array(test_vectors).reshape((x_test_vectors.shape[0], 100))","54b0d2fc":"from gensim.models.doc2vec import Doc2Vec, TaggedDocument","2f4e56f7":"dt = data.copy()\ntexts = dt.to_dict('records')    #### DATAFRAME TO DICTIONARY FORMAT .\ndocuments = [TaggedDocument(text['sentences'].split(), [text['label']])  for text in texts]\nmodel = Doc2Vec(vector_size=100, window=2, min_count=1, workers=11,alpha=0.025, min_alpha=0.025, epochs=20)\nmodel.build_vocab(documents)\nmodel.train(documents, epochs=model.epochs, total_examples=model.corpus_count)\n\nX_train['doc_vector'] = X_train['sentences'].apply(lambda x: model.infer_vector(x.split()))\nX_test['doc_vector'] = X_test['sentences'].apply(lambda x: model.infer_vector(x.split()))","7523bd16":"x_train_vectors = X_train.drop(columns=['sentences'])\nx_test_vectors = X_test.drop(columns=['sentences'])","00582649":"x_train_vectors.head()","ac0c3a96":"train_vectors = []\nfor vector in x_train_vectors['doc_vector']:\n    train_vectors.append(vector)\nx_train_d2v = np.array(train_vectors).reshape((x_train_vectors.shape[0], 100))\n\n\ntest_vectors = []\nfor vector in x_test_vectors['doc_vector']:\n    test_vectors.append(vector)\nx_test_d2v = np.array(test_vectors).reshape((x_test_vectors.shape[0], 100))\n\n","bf4d2f6f":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score,precision_score,recall_score\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.model_selection import cross_val_score\nimport warnings \nwarnings.filterwarnings('ignore')","ca9dead8":"alpha_lst = [10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3]","d29e4237":"micro_f1_scores = []\nfor alpha_ in alpha_lst:\n    classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=alpha_, penalty='l1'))\n    cv_scores = cross_val_score(classifier,x_train_d2v, y_train, cv=3, scoring='f1_micro')\n    micro_f1_scores.append(cv_scores.mean())","83ab6df2":"# plot alpha vs micro f1 score\nplt.plot(alpha_lst,micro_f1_scores)\nfor i in range (0,len(alpha_lst)):\n    plt.annotate('%s' %alpha_lst[i], xy=(alpha_lst[i],micro_f1_scores[i]))\nplt.show()\nbest_alpha = alpha_lst[np.argmax(micro_f1_scores)]\nprint('\\nThe best value of alpha is %s.' %best_alpha)","8e8633a4":"classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=best_alpha, penalty='l1'))","a9ec8ce2":"y_test.shape","20bb5bb2":"x_test_d2v.shape","917367f3":"#classifier.fit(x_train_w2v, y_train)\n#y_pred_w2v = classifier.predict(x_test_w2v)\n\nclassifier.fit(x_train_d2v, y_train)\ny_pred_d2v = classifier.predict(x_test_d2v)\n\nprecision = precision_score(y_test, y_pred_d2v, average='macro')\nrecall = recall_score(y_test, y_pred_d2v, average='macro')\nf1 = f1_score(y_test, y_pred_d2v, average='macro')\n\nprint(\"Macro-average quality numbers\")\nprint(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n","c623595b":"from sklearn.metrics import confusion_matrix\nplt.figure(figsize=(15,15))\nsns.heatmap(confusion_matrix(y_test, y_pred_d2v),annot=True)","0e8b02b5":"from sklearn.multiclass import OutputCodeClassifier\nfrom sklearn.svm import LinearSVC\n\nclf = OutputCodeClassifier(LinearSVC(random_state=0),\n                           code_size=2, random_state=0)\n#y_pred_w2v = clf.fit(x_train_w2v, y_train).predict(x_test_w2v)\ny_pred_d2v = clf.fit(x_train_d2v, y_train).predict(x_test_d2v)","7781107c":"precision = precision_score(y_test, y_pred_d2v, average='macro')\nrecall = recall_score(y_test, y_pred_d2v, average='macro')\nf1 = f1_score(y_test, y_pred_d2v, average='macro')\n\nprint(\"Macro-average quality numbers\")\nprint(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n\n","c59a6e20":"plt.figure(figsize=(15,15))\nsns.heatmap(confusion_matrix(y_test, y_pred_d2v),annot=True)","a83bc17e":"data.head()","764e47b9":"from transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nimport torch\nfrom tqdm.notebook import tqdm","706a0473":"BERTtokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True)","b3023f59":"encoded_data_train = BERTtokenizer.batch_encode_plus(\n    data[data.data_type=='train'].sentences.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\nencoded_data_val = BERTtokenizer.batch_encode_plus(\n    data[data.data_type=='test'].sentences.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(data[data.data_type=='train'].lbl.values)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(data[data.data_type=='test'].lbl.values)","2b92f211":"dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","70bac907":"from transformers import BertForSequenceClassification\n\nBERTmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(labels_map),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)\n","ba4ba5ef":"batch_size = 32\n\ndataloader_train = DataLoader(dataset_train, \n                              sampler=RandomSampler(dataset_train), \n                              batch_size=batch_size)\n\ndataloader_validation = DataLoader(dataset_val, \n                                   sampler=SequentialSampler(dataset_val), \n                                   batch_size=batch_size)","18f6e804":"optimizer = AdamW(BERTmodel.parameters(),\n                  lr=1e-5, \n                  eps=1e-8)\nepochs = 3\n\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0,\n                                            num_training_steps=len(dataloader_train)*epochs)","4569dbb4":"from sklearn.metrics import f1_score\ndef f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='macro')","ea5fec9c":"def evaluate(dataloader_val):\n\n    BERTmodel.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in dataloader_val:\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = BERTmodel(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total\/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","4d5aeff9":"import random\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nBERTmodel.to(device)\n\nprint(device)","b9b8e6f1":"#for epoch in tqdm(range(1, epochs+1)):\n    \n#    BERTmodel.train()\n    \n#    loss_train_total = 0\n\n#    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n#    for batch in progress_bar:\n\n#        BERTmodel.zero_grad()\n        \n#        batch = tuple(b.to(device) for b in batch)\n        \n#        inputs = {'input_ids':      batch[0],\n#                  'attention_mask': batch[1],\n#                  'labels':         batch[2],\n#                 }       \n\n#        outputs = BERTmodel(**inputs)\n        \n#        loss = outputs[0]\n#        loss_train_total += loss.item()\n#        loss.backward()\n\n #       torch.nn.utils.clip_grad_norm_(BERTmodel.parameters(), 1.0)\n\n #       optimizer.step()\n #       scheduler.step()\n        \n #       progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()\/len(batch))})\n         \n        \n #   torch.save(BERTmodel.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n        \n #   tqdm.write(f'\\nEpoch {epoch}')\n    \n #   loss_train_avg = loss_train_total\/len(dataloader_train)            \n #   tqdm.write(f'Training loss: {loss_train_avg}')\n    \n #   val_loss, predictions, true_vals = evaluate(dataloader_validation)\n #   val_f1 = f1_score_func(predictions, true_vals)\n #   tqdm.write(f'Validation loss: {val_loss}')\n #   tqdm.write(f'F1 Score (Weighted): {val_f1}')","aa313ec9":"#plt.figure(figsize=(15,15))\n#sns.heatmap(confusion_matrix(true_vals, predictions),annot=True)","e986c6c9":"for dirname, _, filenames in os.walk('\/kaggle\/input\/feedback-prize-2021\/test\/'):\n    filenum = 1\n    for filename in filenames:\n        f = open(os.path.join(dirname, filename),'r')\n        doc = f.read()\n        doc_id = filename[:filename.find('.txt')]\n        doc_len = len(doc.split())\n        doc_df = pd.DataFrame([[doc_id,doc,doc_len]], columns=['id','text','word_num'])\n        if filenum == 1:\n            test_df = doc_df\n        else:\n            test_df = test_df.append(doc_df, ignore_index=True)\n        filenum += 1\n        f.close()","d8102450":"test_df.info()","bd81a940":"test_df","508e0705":"for index, row in test_df.iterrows():\n    raw_txt = row['text']\n    cleaned_txt = BeautifulSoup(raw_txt, \"lxml\").text\n    txt_edit = punctuator_model.punctuation([cleaned_txt])[0]\n    txt = txt_edit[0]\n    docs.at[index,'processed_text'] = txt\n    txt_id = row['id']\n    df_sent = get_sentences(txt, txt_id)\n    prev = -1\n    for i,r in df_sent.iterrows():\n        df_sent.at[i,'word_start'] = prev+1\n        df_sent.at[i,'word_end'] = prev + r['sentence_len']\n        prev = df_sent.loc[i,'word_end']\n        \n    if index==0:\n        df_test_sentences = df_sent\n    else:\n        df_test_sentences = df_test_sentences.append(df_sent, ignore_index=True)","377b7c18":"df_test_sentences.info()","06e8a954":"df_test_sentences['sentence_len'].describe()","f19bf06e":"df_test_sentences['doc_vector'] = df_test_sentences['sentences'].apply(lambda x: model.infer_vector(x.split()))\n\ntest_vectors = []\nfor vector in df_test_sentences['doc_vector']:\n    test_vectors.append(vector)\ntest_d2v = np.array(test_vectors).reshape((df_test_sentences.shape[0], 100))\npred_d2v = classifier.predict(test_d2v)\n","ec62128c":"pred_d2v","21760300":"df_test_sentences['prediction_num'] = pred_d2v.tolist()","ad5a3977":"df_test_sentences.head()","8820b467":"def get_class(x):\n    return list(labels_map.keys())[list(labels_map.values()).index(x)]","80be7dbb":"df_test_sentences['class'] = df_test_sentences['prediction_num'].apply(lambda x: get_class(x))","c69062f7":"def get_words(start, end):\n    words=[str(x) for x in list(range(start, end+1))]\n    s=' '.join(words)\n    return s","5867eb0d":"df_test_sentences_copy = df_test_sentences","cd1ab8b8":"df_test_sentences['predictionstring'] = df_test_sentences.apply(lambda r: get_words(int(r['word_start']),int(r['word_end'])), axis=1)","9b44bb72":"df_test_sentences.head()","8ba29a4a":"df_test_sentences = df_test_sentences[df_test_sentences.prediction_num != 0]","20435881":"df_test_sentences.info()","7f2cb9ba":"for_submission = df_test_sentences[['id','class','predictionstring']]","2cb85701":"for_submission","b8026790":"for_submission.to_csv('submission.csv', index=False)","550089e3":"![image.png](attachment:98e55956-2c70-4292-a051-da653f15a659.png)","c4caf613":"## Getting label for each sentence (by comparing \"start word\" of sentence and \"end word\" of sentence with predictionstring of train.csv","13df5550":"## Train-test split","76bd7366":"## Sentences segmentation","f35a0d05":"## Try the models","d564fbfc":"**The text need a correction of punctuation to get sentences rigth. To fix I'm using the distilbert-punctuator**","426fcbf7":"## Encoding with word2vec","9dfef19c":"There are 3 cases of labelling Sentence vs Discours vs Label (discours_type)\n1. Sentence 1 -> Discours 1 -> Label 1\n\n   Sentence 2 -> Discours 2 -> Label 2\n   \n2. Sentence 1 -> Discours 1 -> Label 1\n\n   Sentence 2 -> Discours 1 -> Label 1 \n   \n3. Sentence 1 -> Discours 1 -> Label 1\n\n   Sentence 1 -> Discours 2 -> Label 2\n   \n   \n Cases 1 and 2 are quite straightforward to label. Case 3 is less obvious. For the first version I just keep the label for the first part of sentence. To be improved later. \n \n First step is to assess the case for each sentence. \n For this purpose: get discours_start and discours_end expressed in words (first and last word indexes from predictionstring)","6866bc0d":"## Doc2vec","8b93b91e":"## Trying BERT ","080cb197":"As the text > 512 tokens longs is an issue, for a moment I'll remove outliers by word_len from dataset. Later I'll find a solution for remaining.","a3e19dd4":"## Create output CSV\n\n### Read test folder\n### Segment to sentences\n### Vectorize each sentence with doc2vec\n### Predict label for each sentence\n### Encode each sentence with corresponding words' indexes\n### Group by id, label concatenate sentence_codes"}}