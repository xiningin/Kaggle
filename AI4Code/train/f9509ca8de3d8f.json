{"cell_type":{"e7bbdaae":"code","158d0613":"code","319d93a7":"code","bc781f0b":"code","f1369feb":"code","690ff616":"code","3a49916b":"code","7fc07633":"code","0ef834bf":"code","54af6c0d":"code","9fc10a65":"code","d4c1f955":"code","1ddefed4":"code","23ee219a":"code","e642c6c6":"code","153b50ba":"code","e9895971":"code","6b8da56e":"code","aec21339":"code","3bbf638f":"code","58d6aa73":"code","1b37965e":"code","dd855311":"code","eb7c3bc8":"code","1f82b044":"code","a0c6fc1c":"code","7b022576":"code","9a0ed155":"code","596b6055":"code","e4c792e8":"code","4b79eee4":"code","f141f36f":"code","45f0ea15":"markdown","215e0383":"markdown","969bf984":"markdown","30269b66":"markdown","73f1efb7":"markdown","260023c4":"markdown","2d972e75":"markdown","5e28d049":"markdown","357549cb":"markdown","4e9b2ed7":"markdown","f27a1dda":"markdown","2fa1bf59":"markdown","71682f6a":"markdown"},"source":{"e7bbdaae":"%matplotlib inline","158d0613":"import numpy as np\nimport pandas as pd","319d93a7":"from sklearn.model_selection import train_test_split","bc781f0b":"import matplotlib.pyplot as plt","f1369feb":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision","690ff616":"# \u56e0\u4e3a\u662f\u56fe\u50cf\u6570\u636e\uff0c\u6570\u636e\u96c6\u4e2d\u503c\u7684\u8303\u56f4\u662f[0, 255]\uff0c\u6240\u4ee5\u8fd9\u91cc\u8bbe\u7f6e\u6570\u636e\u7c7b\u578b\u4e3auint8\u7c7b\u578b\ndf = pd.read_csv('..\/input\/digit-recognizer\/train.csv', dtype='uint8')\ndf.head()","3a49916b":"# \u5212\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u6bd4\u4f8b\u9ed8\u8ba4\u4e3a0.75\u548c0.25\ntrain_df, test_df = train_test_split(df, shuffle=True)","7fc07633":"temp_data = df.iloc[3]\nimage = temp_data.to_numpy()[1:].reshape((28, 28))\nplt.imshow(image)\nplt.show()","0ef834bf":"class DigitDataset(Dataset):\n    \"\"\"\u5c06\u5b98\u65b9\u63d0\u4f9b\u7684CSV\u6570\u636e\u5c01\u88c5\u4e3a\u9002\u5408Pytorch\u7f16\u5199\u7684NN\u4f7f\u7528\u7684\u6570\u636e\u96c6\u7c7b\"\"\"\n    def __init__(self, df, with_label, transform=None):\n        \"\"\" df\uff1aDataFrame\u7c7b\u578b\u7684\u6570\u636e\n            with_label\uff1a\u662f\u5426\u5177\u6709label\uff0c\u7528\u4e8e\u5206\u8fa8train.csv\u548ctest.csv\u7684\u6570\u636e\n            transform\uff1a\u8868\u793a\u9700\u8981\u8fdb\u884c\u7684\u56fe\u50cf\u53d8\u6362\n        \"\"\"\n\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.with_label = with_label\n\n    def __len__(self):\n        \"\"\"\u8fd4\u56de\u6574\u4e2aDaTaset\u7684\u5927\u5c0f\"\"\"\n\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        \"\"\"\u5bf9Dataset\u4e2d\u7b2cidx\u884c\u7684\u6570\u636e\u8fdb\u884c\u6570\u636e\u9884\u5904\u7406\uff0c\u8fd4\u56de\u5904\u7406\u540e\u7684\u6570\u636e\u548c\u5176label\"\"\"\n\n        # \u53d6\u51fa\u7b2ci\u884c\u6570\u636e\n        temp_data = self.df.iloc[idx].to_numpy()\n\n        # \u5982\u679c\u6570\u636e\u96c6\u6709label\uff0c\u5219\u8fd4\u56delabel\n        if self.with_label is True:\n            # \u7b2c0\u4e2a\u6570\u636e\u662flabel\n            target = int(temp_data[0])\n            # \u5c06\u56fe\u50cf\u7684\u6570\u636e\u8f6c\u6362\u6210\u4e00\u4e2aw*h*c\u76843\u7ef4\u6570\u7ec4\n            image = temp_data[1:].reshape((28, 28, 1))\n            # \u5bf9\u6bcf\u4e2a\u6570\u636e\u8fdb\u884c\u9884\u5904\u7406\u8f6c\u6362\n            if self.transform is not None:\n                image = self.transform(image)\n\n            return image, target\n        else:\n            # \u5c06\u56fe\u50cf\u7684\u6570\u636e\u8f6c\u6362\u6210\u4e00\u4e2aw*h*c\u76843\u7ef4\u6570\u7ec4\n            image = temp_data.reshape((28, 28, 1))\n            # \u5bf9\u6bcf\u4e2a\u6570\u636e\u8fdb\u884c\u9884\u5904\u7406\u8f6c\u6362\n            if self.transform is not None:\n                image = self.transform(image)\n\n            return image","54af6c0d":"# \u5bf9\u6bcf\u4e2a\u6570\u636e\u8fdb\u884cResize\u548cToTensor\u64cd\u4f5c\ntemp_data_loader = DataLoader(dataset=DigitDataset(train_df, True, transforms.Compose([transforms.ToPILImage(),\n                                                                                 transforms.Resize((32, 32)),\n                                                                                 transforms.ToTensor()])), \n                               batch_size=64, \n                               shuffle=True)\ntemp_data_iter = iter(temp_data_loader)","9fc10a65":"images, targets = next(temp_data_iter)","d4c1f955":"targets","1ddefed4":"# \u8fd9\u91cc\u7684\u6570\u636e\u5df2\u7ecf\u662fTensor\u683c\u5f0f\nimages.shape","23ee219a":"# \u5c0664\u5f20\u56fe\u50cf\u62fc\u5728\u4e00\u8d77\ngrid_image = torchvision.utils.make_grid(images)\ngrid_image.shape","e642c6c6":"# plt\u7ed8\u5236\u56fe\u50cf\u7684\u65f6\u5019\uff0c\u8981\u6c42\u6570\u636eshape\u4e3a[H, W, C](RGB)\u6216\u8005[H, W](BOOL)\uff0c\u6240\u4ee5\u9700\u8981\u5c06\u56fe\u50cf\u7684shape\u8c03\u4e00\u4e0b\nplt.imshow(np.transpose(grid_image, [1, 2, 0]))\nplt.show()","153b50ba":"images.shape","e9895971":"plt.imshow(images[0][0])\nplt.show()","6b8da56e":"class LeNet5(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n\n        # \u5b9a\u4e49LeNet5\u7684\u7ed3\u6784\n        # 1,32*32 --> 6,28*28 --> 6,14*14\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5)),\n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size=(2, 2))\n        )\n\n        # 6,14*14 --> 16,10*10 --> 16,5*5\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5)),\n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size=(2, 2))\n        )\n\n        # 16,5*5 --> 120\n        self.fc1 = nn.Sequential(\n            nn.Linear(in_features=16 * 5 * 5, out_features=120), \n            nn.ReLU()\n        )\n\n        # 120 --> 84\n        self.fc2 = nn.Sequential(\n            nn.Linear(in_features=120, out_features=84),\n            nn.ReLU()\n        )\n\n        # 84 --> 10\n        self.fc3 = nn.Linear(in_features=84, out_features=10)\n\n    def forward(self, x):\n        \"\"\"\u63cf\u8ff0\u8f93\u5165\u7684\u6570\u636e\u5728\u7f51\u8def\u5185\u90e8\u7684\u524d\u5411\u4f20\u9012\u8fc7\u7a0b\"\"\"\n        \n        x = self.conv1(x)\n        x = self.conv2(x)\n        # \u5728\u8f93\u5165FC\u5c42\u4e4b\u524d\uff0c\u5c06\u6570\u636e\u62c9\u4f38\u4e3a\u4e00\u884c\n        x = x.view(-1, self.get_flat_features_num(x))\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n\n        return x\n\n    def get_flat_features_num(self, x):\n        \"\"\"\u8fd4\u56de\u5c06\u5f20\u91cf\u62c9\u4f38\u4e3a\u884c\u5411\u91cf\u65f6\u7684\u603b\u7684\u7279\u5f81\u6570\"\"\"\n        \n        num = 1\n        for s in x.size()[1:]:\n            num *= s\n\n        return num","aec21339":"# \u8d85\u53c2\u6570\nBATCH_SIZE = 512\nEPOCHS = 50\nLR = 0.001\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","3bbf638f":"model = LeNet5().to(DEVICE)\n# \u4f7f\u7528\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u591a\u5206\u7c7b\u7684\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528Adam\u4f5c\u4e3a\u635f\u5931\u7684\u4f18\u5316\u51fd\u6570\nloss_fun = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)","58d6aa73":"# \u521d\u59cb\u5316\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u7684dataloader\uff0c\u5c06\u6570\u636eResize\u4e3a32*32\ntrain_data_loader = DataLoader(dataset=DigitDataset(train_df, \n                                                    True, \n                                                    transforms.Compose([transforms.ToPILImage(),\n                                                                        transforms.Resize((32, 32)),\n                                                                        transforms.ToTensor(),\n                                                                        transforms.Normalize((0.1307,), (0.3081,))])),\n                               batch_size=BATCH_SIZE,\n                               shuffle=True)\n\ntest_data_loader = DataLoader(dataset=DigitDataset(test_df, \n                                                   True, \n                                                   transforms.Compose([transforms.ToPILImage(),\n                                                                       transforms.Resize((32, 32)),\n                                                                       transforms.ToTensor(),\n                                                                       transforms.Normalize((0.1307,), (0.3081,))])),\n                              batch_size=BATCH_SIZE,\n                              shuffle=True)","1b37965e":"%%time\nfor epoch in range(EPOCHS):\n    # Train\n    # \u5f00\u542f\u6a21\u578b\u7684train\u6a21\u5f0f\uff0c\u542f\u7528BatchNormalization\u548cDropout\n    model.train()\n    for batch_index, (data, target) in enumerate(train_data_loader):\n        # \u5c06\u6570\u636e\u79fb\u52a8\u5230\u8bbe\u5907\u4e0a\n        data, target = data.to(DEVICE), target.to(DEVICE)\n\n        # \u6bcf\u6b21\u6570\u636e\u6570\u636e\u524d\uff0c\u5148\u6e05\u7a7a\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u4fe1\u606f\n        optimizer.zero_grad()\n        output = model(data)\n        loss = loss_fun(output, target)\n        # \u8bef\u5dee\u53cd\u5411\u4f20\u9012\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u53c2\u6570\u7684\u68af\u5ea6\n        loss.backward()\n        # \u66f4\u65b0\u6bcf\u4e2a\u53c2\u6570\n        optimizer.step()\n\n        if batch_index % 30 == 0:\n            print('Train Epoch: {} [{}\/{} {:.2f}%]\\t Loss: {:.5f}'.format(\n                epoch, batch_index, len(train_data_loader), 100 * batch_index \/ len(train_data_loader), loss.item()))\n            \n    # Test\n    # \u5f00\u542f\u6a21\u578b\u7684evaluate\u6a21\u5f0f\uff0c\u542f\u7528BatchNormalization\u548cDropout\n    model.eval()\n    test_loss = 0\n    test_correct_num = 0\n    # \u6d4b\u8bd5\u65f6\uff0c\u4e0d\u8ba1\u7b97\u68af\u5ea6\n    with torch.no_grad():\n        for data, target in test_data_loader:\n            data, target = data.to(DEVICE), target.to(DEVICE)\n            \n            output = model(data)\n            test_loss += loss_fun(output, target).item()\n            # \u83b7\u5f97\u6bcf\u4e2a\u6570\u636e\u7684\u9884\u6d4b\u7684\u7c7b\u522b\n            pred = output.max(dim=1, keepdim=True)[1]\n            test_correct_num += pred.eq(target.view_as(pred)).sum().item()        \n        \n        average_loss = test_loss \/ len(test_data_loader.dataset)\n        average_accuracy = test_correct_num \/ len(test_data_loader.dataset)\n            \n        print('Test: Average Loss: {:.5f}\\t Accuracy: {}\/{} ({:.3f})\\n'.format(\n            average_loss, test_correct_num, len(test_data_loader.dataset), average_accuracy))","dd855311":"torch.save(model, 'LeNet5.pkl')","eb7c3bc8":"# \u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\nmodel = torch.load('LeNet5.pkl')","1f82b044":"eval_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv', dtype='uint8')\neval_df.head()","a0c6fc1c":"eval_data_loader = DataLoader(dataset=DigitDataset(eval_df, \n                                                   False, \n                                                   transforms.Compose([transforms.ToPILImage(),\n                                                                       transforms.Resize((32, 32)),\n                                                                       transforms.ToTensor(),\n                                                                       transforms.Normalize((0.1307,), (0.3081,))])),\n                              batch_size=BATCH_SIZE)","7b022576":"images = iter(eval_data_loader).next()\ngrid_image = torchvision.utils.make_grid(images)\n\nplt.imshow(np.transpose(grid_image, [1, 2, 0]))\nplt.show()","9a0ed155":"%%time\n# \u8bb0\u5f55\u6ca1\u6279\u6570\u636e\u9884\u6d4b\u7684\u7c7b\u522b\npred_label = torch.tensor([], dtype=torch.int64).to(DEVICE)\n# \u4e0d\u8bad\u7ec3\u65f6\uff0c\u8bb0\u5f97\u4f7f\u7528no_grad\u4e0emodel.eval()\nwith torch.no_grad():\n    model.eval()\n    for batch_index, data in enumerate(eval_data_loader):\n        data = data.to(DEVICE)\n\n        output = model(data)\n        # \u83b7\u5f97\u8be5\u6279\u6570\u636e\u6700\u540e\u8f93\u51fa\u7684\u6700\u5927\u7684\u5206\u6570\u6240\u5bf9\u5e94\u7684\u7c7b\u522b\n        batch_pred_label = output.max(dim=1, keepdim=False)[1]\n        pred_label = torch.cat([pred_label, batch_pred_label])\n\n        if batch_index % 5 == 0:\n            print('Eval: {}\/{} has finished!'.format(batch_index, len(eval_data_loader)))\n    print('OK!')","596b6055":"pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv').head()","e4c792e8":"ImageId = np.arange(1, len(pred_label) + 1)\nLabel = pred_label.cpu().numpy()","4b79eee4":"pred_df = pd.DataFrame({'ImageId': ImageId, 'Label': Label})\npred_df.head()","f141f36f":"pred_df.to_csv('submission1.csv', index=False)","45f0ea15":"## \u8bad\u7ec3\u6a21\u578b","215e0383":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#\u51c6\u5907\" data-toc-modified-id=\"\u51c6\u5907-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>\u51c6\u5907<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#\u7f16\u5199\u6570\u636e\u96c6\u5bf9\u5e94\u7684Dataset\u7c7b\" data-toc-modified-id=\"\u7f16\u5199\u6570\u636e\u96c6\u5bf9\u5e94\u7684Dataset\u7c7b-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>\u7f16\u5199\u6570\u636e\u96c6\u5bf9\u5e94\u7684Dataset\u7c7b<\/a><\/span><\/li><li><span><a href=\"#\u7f16\u5199LeNet5\u6a21\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u7c7b\" data-toc-modified-id=\"\u7f16\u5199LeNet5\u6a21\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u7c7b-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;<\/span>\u7f16\u5199LeNet5\u6a21\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u7c7b<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#\u8bad\u7ec3\u6a21\u578b\" data-toc-modified-id=\"\u8bad\u7ec3\u6a21\u578b-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>\u8bad\u7ec3\u6a21\u578b<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#\u8bad\u7ec3\u8fc7\u7a0b\u7684\u8d85\u53c2\u6570\u548c\u5176\u4ed6\u8bbe\u7f6e\" data-toc-modified-id=\"\u8bad\u7ec3\u8fc7\u7a0b\u7684\u8d85\u53c2\u6570\u548c\u5176\u4ed6\u8bbe\u7f6e-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span>\u8bad\u7ec3\u8fc7\u7a0b\u7684\u8d85\u53c2\u6570\u548c\u5176\u4ed6\u8bbe\u7f6e<\/a><\/span><\/li><li><span><a href=\"#\u521b\u5efa\u53ef\u89c6\u5316\u7684\u7ed8\u56fe\u73af\u5883\" data-toc-modified-id=\"\u521b\u5efa\u53ef\u89c6\u5316\u7684\u7ed8\u56fe\u73af\u5883-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;<\/span>\u521b\u5efa\u53ef\u89c6\u5316\u7684\u7ed8\u56fe\u73af\u5883<\/a><\/span><\/li><li><span><a href=\"#\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b\" data-toc-modified-id=\"\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;<\/span>\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b<\/a><\/span><\/li><li><span><a href=\"#\u4fdd\u5b58\u6a21\u578b\" data-toc-modified-id=\"\u4fdd\u5b58\u6a21\u578b-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;<\/span>\u4fdd\u5b58\u6a21\u578b<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#\u9884\u6d4b\u6570\u636e\" data-toc-modified-id=\"\u9884\u6d4b\u6570\u636e-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>\u9884\u6d4b\u6570\u636e<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#\u9884\u6d4b\" data-toc-modified-id=\"\u9884\u6d4b-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;<\/span>\u9884\u6d4b<\/a><\/span><\/li><li><span><a href=\"#\u5bfc\u51fa\u4e3aCSV\" data-toc-modified-id=\"\u5bfc\u51fa\u4e3aCSV-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;<\/span>\u5bfc\u51fa\u4e3aCSV<\/a><\/span><\/li><\/ul><\/li><\/ul><\/div>","969bf984":"### \u7f16\u5199LeNet5\u6a21\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u7c7b\n\n- 2\u4e2aConv\u5c42\uff0c\u6bcf\u5c42\u540e\u9762\u63a5\u4e00\u4e2aReLU\u5c42\u4f5c\u4e3a\u6fc0\u52b1\u51fd\u6570\uff0c\u518d\u8fdb\u884cMaxPool\u5904\u7406\n- 3\u4e2aFC\u5c42\uff0c\u6bcf\u5c42\u540e\u9762\u63a5\u4e00\u4e2aReLU\u5c42\n\n![](https:\/\/ss1.bdstatic.com\/70cFvXSh_Q1YnxGkpoWK1HF6hhy\/it\/u=449995924,781664481&fm=26&gp=0.jpg)","30269b66":"## \u51c6\u5907","73f1efb7":"### \u4fdd\u5b58\u6a21\u578b","260023c4":"### \u5bfc\u51fa\u4e3aCSV","2d972e75":"## \u9884\u6d4b\u6570\u636e","5e28d049":"### \u8bad\u7ec3\u8fc7\u7a0b\u7684\u8d85\u53c2\u6570\u548c\u5176\u4ed6\u8bbe\u7f6e","357549cb":"### \u5f00\u59cb\u8bad\u7ec3\u6a21\u578b","4e9b2ed7":"### \u7f16\u5199\u6570\u636e\u96c6\u5bf9\u5e94\u7684Dataset\u7c7b","f27a1dda":"**\u6ce8\u610f\uff1a\u5355\u4e2a\u56fe\u50cf\u539f\u59cb\u6570\u636e\u7684shape\u5e94\u8be5\u4e3a(H, W, C)\uff0c\u800c\u5176Tensor\u683c\u5f0f\u7684\u6570\u636e\u7684shape\u4e3a(C, H, W)**","2fa1bf59":"# \u57fa\u4e8eLeNet5\u5b9e\u73b0\u5bf9MNIST\u624b\u5199\u6570\u5b57\u8bc6\u522b\n\n[Kaggle-Digit Recognizer](https:\/\/www.kaggle.com\/c\/digit-recognizer)\n\n- \u8bad\u7ec3\u6a21\u578b\uff1a\n    1. \u4ecetrain.csv\u5185\u8bfb\u53d6\u6570\u636e\uff0c\u5e76\u5212\u5206\u4e3atrain\u3001test\u6570\u636e\u96c6\n    2. \u7ee7\u627f`torch.utils.data.Dataset`\u7c7b\uff0c\u5bf9\u6570\u636e\u7684\u8bfb\u53d6\u8fdb\u884c\u5c01\u88c5\uff08\u8981\u6c42\u80fd\u591f\u540c\u65f6\u5bf9\u6570\u636e\u8fdb\u884c\u9884\u5904\u7406\uff09\uff0c\u4fbf\u4e8e\u540e\u9762\u5229\u7528`torch.utils.DataLoader`\u5411LeNet5\u4e2d\u6279\u91cf\u8f93\u5165\u6570\u636e\n    3. \u7ee7\u627f`torch.nn.Module`\uff0c\u7f16\u5199LeNet5\u7f51\u7edc\u7c7b\n    4. \u8bbe\u7f6e\u7f51\u7edc\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u4e00\u4e9b\u8d85\u53c2\u6570\uff08DEVICE, BATCH_SIZE, EPOCHS\uff09\n    6. \u5b9e\u4f8b\u5316train\u548ctest\u7684dataloader\n    7. \u5f00\u59cb\u8bad\u7ec3\u3001\u6d4b\u8bd5\u7f51\u7edc\uff0c\u5e76\u53ef\u89c6\u5316\u8fc7\u7a0b\n    8. \u4fdd\u5b58\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u7ed3\u6784\u4e0e\u6570\u636e\n\n\n- \u9884\u6d4b\u6570\u636e\uff1a\n    1. \u4ecetest.csv\u5185\u8bfb\u53d6\u6570\u636e\uff0c\u5b9e\u4f8b\u5316dataloader\n    2. \u8bfb\u53d6\u4fdd\u5b58\u7684\u6a21\u578b\n    3. \u5c06\u6570\u636e\u6279\u91cf\u8f93\u5165\u7f51\u7edc\uff0c\u83b7\u5f97\u9884\u6d4b\u8f93\u51fa\n    4. \u5c06\u9884\u6d4b\u7ed3\u679c\u5bfc\u51fa\u4e3acsv\u6587\u4ef6","71682f6a":"### \u9884\u6d4b"}}