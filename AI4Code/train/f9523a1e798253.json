{"cell_type":{"1d86ce04":"code","b1c7579c":"code","0aa59ae8":"code","7f3b76dc":"code","618f2077":"code","0a4f55e1":"code","b74cb88c":"code","8cebc6f5":"code","24bcb07c":"code","a78e71e5":"code","fd0ddf87":"code","c066174d":"code","ba6fc1a0":"code","c00ad3cd":"code","22e97ffe":"code","1f04889a":"code","1908e765":"code","92cbf11b":"markdown","ed2972d8":"markdown","752ff518":"markdown","5060e223":"markdown","31cac510":"markdown"},"source":{"1d86ce04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b1c7579c":"#Importing Basic Packages\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas_profiling\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.model_selection import GridSearchCV","0aa59ae8":"#Load the Training DataSet\n\ndf = pd.read_csv(\"\/kaggle\/input\/crop-recommendation-dataset\/Crop_recommendation.csv\")","7f3b76dc":"#Checking the imported Data\n\ndf.head()","618f2077":"#Values count for crop column\n\ndf['label'].value_counts()","0a4f55e1":"#Shape of the dataset\n\ndf.shape","b74cb88c":"#Info about the data\n\ndf.info()","8cebc6f5":"df.describe()","24bcb07c":"#Let's confirm for null values.\n\ndf.isnull().sum()","a78e71e5":"report = pandas_profiling.ProfileReport(df)\nreport","fd0ddf87":"# Count plot for crop column\nsns.countplot(y=df['label'])","c066174d":"# Assigning x and y variables for model building\ny = df['label']\nX = df.drop('label',1)","ba6fc1a0":"# Splitting the dataset to train and test\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=2,test_size=0.25)","c00ad3cd":"#Decision Tree\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\ndt_pred = dt.predict(X_test)","22e97ffe":"# Classification Report\nprint(metrics.classification_report(dt_pred,y_test))","1f04889a":"#Random Forest\n\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\nrf_pred = rf.predict(X_test)","1908e765":"print(metrics.classification_report(rf_pred,y_test))","92cbf11b":"Observation: Clearly a very balanced dataset.","ed2972d8":"**Observation:** Clearly there are no missing values. And also, the data is equally distributed.","752ff518":"Observations:\n\n1- There are 7 Numerical columns and 1 Categorical column.<br>\n2- There are 2200 entires out of which no missing value or null value present. Temperature has zero but it is allowed. <br>\n3- P and K are a bit highly correlated rest all seems to be okay.<br>","5060e223":"Observation: Since Mean and Median are almost similar, no scaling is required.","31cac510":"Observation: So as said earlier, this confirms there are no missing or null values in the dataset.\n\nNote: I would do EDA but I Prefer pandas profiling as it gives a detailed report on how the data is behabing for the mkost part."}}