{"cell_type":{"1d81a84e":"code","f8dc8be8":"code","f8f4f4d4":"code","ac261b53":"code","f5473dbe":"code","38ab21dd":"code","b17e17e6":"code","b80906c6":"code","76cc4d28":"code","4fdcc948":"code","15dc144f":"code","888dac94":"code","fe1865f4":"code","a9208da8":"code","7b7327bc":"code","bafa2ce7":"code","fff0dbbc":"code","7978c86a":"code","fd124ee0":"markdown","5a65c75a":"markdown","2da1e06a":"markdown","536bebca":"markdown","9579c91e":"markdown"},"source":{"1d81a84e":"from IPython.display import clear_output\n!git clone https:\/\/github.com\/atakanady\/Mask_RCNN-_V1.git # Maske R-CNN kod uygulamas\u0131n\u0131 y\u00fckle\n!git clone https:\/\/github.com\/atakanady\/brain-tumor.git \n!pip install pycocotools #COCO, nesne alg\u0131lama i\u00e7in tasarlanm\u0131\u015f b\u00fcy\u00fck bir g\u00f6r\u00fcnt\u00fc veri k\u00fcmesidir\n#!rm -rf brain-tumor\/.git\/\n#!rm -rf Mask_RCNN-_V1\/.git\/\n\nclear_output()","f8dc8be8":"import os \nimport sys\nfrom tqdm import tqdm\nimport cv2\nimport numpy as np\nimport json\nimport skimage.draw\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport random\n\n# Projenin k\u00f6k dizini;\nROOT_DIR = os.path.abspath('Mask_RCNN-_V1\/')\nsys.path.append(ROOT_DIR) \n\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nfrom mrcnn.model import log\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nsys.path.append(os.path.join(ROOT_DIR, 'samples\/coco\/'))\nimport coco\n\nplt.rcParams['figure.facecolor'] = 'white' #g\u00f6rsellerin arka plan\u0131n\u0131n renk se\u00e7imi.\n\nclear_output()","f8f4f4d4":"#G\u00f6r\u00fcnt\u00fclerin ne kadar b\u00fcy\u00fck olu\u015fturulaca\u011f\u0131n\u0131 kontrol etmek i\u00e7in olu\u015fturlan fonk.\ndef get_ax(rows=1, cols=1, size=7):\n    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n    return ax","ac261b53":"MODEL_DIR = os.path.join(ROOT_DIR, 'logs') # E\u011fitimli modeli kaydetmek.\nDATASET_DIR = 'brain-tumor\/data_cleaned\/' #G\u00f6r\u00fcnt\u00fc verilerini i\u00e7eren dizin.\nDEFAULT_LOGS_DIR = 'logs' \n\n# E\u011fitilmi\u015f a\u011f\u0131rl\u0131klar dosya yolu.\nCOCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n\n# E\u011fitilmi\u015f modelden bilgi al\u0131namaz ise COCO e\u011fitimli a\u011f\u0131rl\u0131klar\u0131 s\u00fcr\u00fcmlerden indir.\nif not os.path.exists(COCO_MODEL_PATH):\n    utils.download_trained_weights(COCO_MODEL_PATH)","f5473dbe":"class TumorConfig(Config):\n    \n    # Yap\u0131land\u0131r\u0131lmaya ad ekleniyor.\n    NAME = 'tumor_detector'\n    #Ne kadar GPU deste\u011fi sa\u011flanaca\u011f\u0131n\u0131 belirtiyoruz.\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n    \n    #S\u0131n\u0131f say\u0131s\u0131 (arka plan dahil)\n    NUM_CLASSES = 1 + 1  # arkaplan + t\u00fcmor\n    \n    # Daha h\u0131zl\u0131 e\u011fitim i\u00e7in k\u00fc\u00e7\u00fck resimler kullan\u0131n. K\u00fc\u00e7\u00fck taraf\u0131n s\u0131n\u0131rlar\u0131n\u0131 belirler,\n    # b\u00fcy\u00fck taraf ve bu g\u00f6r\u00fcnt\u00fc \u015feklini belirler.\n    #IMAGE_MIN_DIM = 128\n    #IMAGE_MAX_DIM = 128\n    \n    DETECTION_MIN_CONFIDENCE = 0.85    \n    STEPS_PER_EPOCH = 100\n    LEARNING_RATE = 0.001\n    \nconfig = TumorConfig()\nconfig.display()","38ab21dd":"class BrainScanDataset(utils.Dataset):\n       # \u015eekiller sentetik veri k\u00fcmesini olu\u015fturur. Veri k\u00fcmesi basitten olu\u015fur\n        #\u015fekiller (\u00fc\u00e7genler, kareler, daireler) bo\u015f bir y\u00fczeye rastgele yerle\u015ftirilir.\n        #G\u00f6r\u00fcnt\u00fcler an\u0131nda olu\u015fturulur. Dosya eri\u015fimi gerekmez.\n    def load_brain_scan(self, dataset_dir, subset):\n        \n        #istenen say\u0131da sentetik g\u00f6r\u00fcnt\u00fc \u00fcretin.\n        #count: olu\u015fturulacak g\u00f6r\u00fcnt\u00fc say\u0131s\u0131.\n        #y\u00fckseklik, geni\u015flik: olu\u015fturulan g\u00f6r\u00fcnt\u00fclerin boyutu\n        \n        #class ekleniyor\n        self.add_class(\"tumor\", 1, \"tumor\")\n        \n        assert subset in [\"train\", \"val\", 'test']\n        dataset_dir = os.path.join(dataset_dir, subset)\n\n        annotations = json.load(open(os.path.join(DATASET_DIR, subset, 'annotations_'+subset+'.json')))\n        annotations = list(annotations.values()) # dict anahtarlara gerek yok\n\n        # VIA arac\u0131, g\u00f6r\u00fcnt\u00fcleri olmasa bile g\u00f6r\u00fcnt\u00fcleri JSON'a kaydeder.\n        annotations = [a for a in annotations if a['regions']]\n\n        # Resim ekle\n        for a in annotations:\n            # X ,Y kordinatlar\u0131 al\u0131n\u0131r\n            # x1 ve x2 versiyonlar\u0131n\u0131 desteklemek i\u00e7in if fonk. gerekli.\n            if type(a['regions']) is dict:\n                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n            else:\n                polygons = [r['shape_attributes'] for r in a['regions']]\n\n            # load_mask(), \u00e7okgenleri maskelere d\u00f6n\u00fc\u015ft\u00fcrmek i\u00e7in g\u00f6r\u00fcnt\u00fc boyutuna ihtiya\u00e7 duyar.\n            # Ne yaz\u0131k ki, VIA onu JSON'a dahil etmiyor, bu y\u00fczden okumal\u0131y\u0131z.\n            image_path = os.path.join(dataset_dir, a['filename'])\n            image = skimage.io.imread(image_path)\n            height, width = image.shape[:2]\n\n            self.add_image(\n                \"tumor\",\n                image_id=a['filename'],  # use file name as a unique image id\n                path=image_path,\n                width=width, \n                height=height,\n                polygons=polygons\n            )\n\n    def load_mask(self, image_id):\n\n        # farm_cow veri k\u00fcmesi g\u00f6r\u00fcnt\u00fcs\u00fc de\u011filse, \u00fcst s\u0131n\u0131fa yetki verin.\n        image_info = self.image_info[image_id]\n        if image_info[\"source\"] != \"tumor\":\n            return super(self.__class__, self).load_mask(image_id)\n        \n        # \u00c7okgenleri bir bitmap \u015fekil maskesine d\u00f6n\u00fc\u015ft\u00fcr\u00fcn\n        # [y\u00fckseklik, geni\u015flik, \u00f6rnek_say\u0131s\u0131]\n        \n        info = self.image_info[image_id]\n        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n                        dtype=np.uint8)\n        for i, p in enumerate(info[\"polygons\"]):\n        # \u00c7okgenin i\u00e7indeki piksel dizinlerini al\u0131n ve 1'e ayarlay\u0131n\n            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n            mask[rr, cc, i] = 1\n            \n        # D\u00f6nd\u00fcrme maskesi ve her \u00f6rne\u011fin s\u0131n\u0131f kimlikleri dizisi.Sahip oldu\u011fumuzdan beri yaln\u0131zca bir s\u0131n\u0131f kimli\u011fi, 1'lik bir dizi d\u00f6nd\u00fcr\u00fcr\u00fcz.\n        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n\n    def image_reference(self, image_id):\n        #G\u00f6r\u00fcnt\u00fc yolunu d\u00f6nd\u00fcr\n        \n        info = self.image_info[image_id]\n        if info[\"source\"] == \"tumor\":\n            return info[\"path\"]\n        else:\n            super(self.__class__, self).image_reference(image_id)\n","b17e17e6":"#E\u011fitim moduna model olu\u015fturma.\nmodel = modellib.MaskRCNN(\n    mode='training', \n    config=config, \n    model_dir=DEFAULT_LOGS_DIR\n)\n\nmodel.load_weights(\n    COCO_MODEL_PATH, \n    by_name=True, \n    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"]\n)","b80906c6":"#E\u011fitim veri Seti\ndataset_train = BrainScanDataset()\ndataset_train.load_brain_scan(DATASET_DIR, 'train')\ndataset_train.prepare()\n\n#Do\u011frulama Veri Seti\ndataset_val = BrainScanDataset()\ndataset_val.load_brain_scan(DATASET_DIR, 'val')\ndataset_val.prepare()\n\n#Test Veri Seti\ndataset_test = BrainScanDataset()\ndataset_test.load_brain_scan(DATASET_DIR, 'test')\ndataset_test.prepare()\n\n# \u00c7ok k\u00fc\u00e7\u00fck bir veri seti kulland\u0131\u011f\u0131m\u0131zdan ve COCO e\u011fitimli a\u011f\u0131rl\u0131klar, \u00e7ok uzun s\u00fcre \u00e7al\u0131\u015fmam\u0131za gerek yok. Overfitting moduna girmemesi \u00f6nemli.\nprint(\"E\u011fitim A\u011f\u0131\")\nmodel.train(\n    dataset_train, dataset_val,\n    learning_rate=config.LEARNING_RATE,\n    epochs=15,\n    layers='heads'\n)","76cc4d28":"# Modeli \u00e7\u0131kar\u0131m modunda yeniden olu\u015fturun\n\nmodel = modellib.MaskRCNN(\n    mode=\"inference\", \n    config=config,\n    model_dir=DEFAULT_LOGS_DIR\n)\n\n# Kaydedilmi\u015f a\u011f\u0131rl\u0131klara giden yolu al\u0131n\n# Ya belirli bir yol belirleyin ya da son e\u011fitilmi\u015f a\u011f\u0131rl\u0131klar\u0131 bulun\n# model_path = os.path.join(ROOT_DIR, \".h5 dosya ad\u0131 burada\")\nmodel_path = model.find_last()\n\n# Load trained weights\nprint(\"A\u011f\u0131rl\u0131klar y\u00fckleniyor\", model_path)\nmodel.load_weights(model_path, by_name=True)","4fdcc948":"def predict_and_plot_differences(dataset, img_id):\n    original_image, image_meta, gt_class_id, gt_box, gt_mask =\\\n        modellib.load_image_gt(dataset, config, \n                               img_id, use_mini_mask=False)\n\n    results = model.detect([original_image], verbose=0)\n    r = results[0]\n\n    visualize.display_differences(\n        original_image,\n        gt_box, gt_class_id, gt_mask,\n        r['rois'], r['class_ids'], r['scores'], r['masks'],\n        class_names = ['tumor'], title=\"\", ax=get_ax(),\n        show_mask=True, show_box=True)","15dc144f":"def display_image(dataset, ind):\n    plt.figure(figsize=(3,5))\n    plt.imshow(dataset.load_image(ind))\n    plt.xticks([])\n    plt.yticks([])\n    plt.title('Orjinal Resim')\n","888dac94":"ind = 0\ndisplay_image(dataset_val, ind)\npredict_and_plot_differences(dataset_val, ind)","fe1865f4":"ind = 7\ndisplay_image(dataset_val, ind)\npredict_and_plot_differences(dataset_val, ind)","a9208da8":"ind = 4\ndisplay_image(dataset_val, ind)\npredict_and_plot_differences(dataset_val, ind)","7b7327bc":"ind = 0\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","bafa2ce7":"ind = 3\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","fff0dbbc":"ind = 2\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","7978c86a":"ind = 0\ndisplay_image(dataset_test, ind)\npredict_and_plot_differences(dataset_test, ind)","fd124ee0":"## Deneme seti\n\nModelin daha \u00f6nce g\u00f6rmedi\u011fi g\u00f6r\u00fcnt\u00fclerde nas\u0131l performans g\u00f6sterdi\u011fini g\u00f6rece\u011fiz.","5a65c75a":"## Do\u011frulama Seti","2da1e06a":"**RESNET M\u0130MAR\u0130S\u0130**\n\n![](https:\/\/miro.medium.com\/max\/500\/1*JEGNYy9rXMj_XN7W1Qjo9g.png)\n\nVGG 19 modelini, ortada 34 parametre katman\u0131na sahip d\u00fcz bir a\u011f\u0131 ve sa\u011fda 34 parametre katman\u0131na sahip art\u0131k a\u011f modelini yukar\u0131da g\u00f6rmektesiniz. Model, VGG a\u011flar\u0131ndan daha az filtreye ve daha d\u00fc\u015f\u00fck karma\u015f\u0131kl\u0131\u011fa sahiptir.\n\n**ResNet 101**\n\nDaha fazla 3 katmanl\u0131 blok kullanarak 101 katmanl\u0131 ResNet\u2019ler olu\u015fturulur. 50\/101\/152-katmanl\u0131 ResNet\u2019ler, 34-katmanl\u0131 olanlardan \u00f6nemli \u00f6l\u00e7\u00fcde daha do\u011frudur. Art\u0131k a\u011flar sayesinde bozulma problemlerinin \u00f6n\u00fcne ge\u00e7ilerek \u00f6nemli \u00f6l\u00e7\u00fcde artan derinlikten \u00f6nemli do\u011fruluk kazan\u0131mlar\u0131 elde edilmi\u015ftir.\n\n**COCO alg\u0131lama ve COCO segmentasyon g\u00f6revlerinde ResNet birinci olmu\u015ftur.**","536bebca":"**<center><font size=5>Maske R-CNN ile Beyin T\u00fcm\u00f6r\u00fc Tespiti<\/font><\/center>**\n\n\nAtakan ADIYAMAN\n07 Aral\u0131k 2021\n","9579c91e":"# <a id='import'>R-CNN Model<\/a>"}}