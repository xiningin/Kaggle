{"cell_type":{"bd7644b3":"code","86a199f8":"code","1886c29b":"code","4add5a39":"code","b6b65cb5":"code","f9ad3539":"code","17be7748":"code","573e4042":"code","054d4a6e":"code","32dc6d8c":"code","6644ec6d":"code","f763cfca":"code","53b8baaf":"code","a4f152da":"code","e3cad4d1":"code","eda46851":"code","0c5be8b6":"code","9b86e499":"code","75f99183":"code","72f5acb7":"code","4db8c763":"code","03a2aebd":"code","5c28a948":"code","f726ca3b":"code","80cf3354":"code","bd7db069":"code","62416adf":"code","9fe8f0d8":"code","9ef082ce":"code","73999f42":"code","183ac5b9":"code","5f130aae":"code","8fffa9f7":"code","cfa905a9":"code","9456e26d":"code","ab0dbf43":"code","309a4c5f":"code","a5806ca5":"code","f5e5df14":"code","8362f6a1":"code","ecbe8e96":"code","051c00a9":"code","3e93dbd1":"code","c4fa347c":"code","6ecf9e0e":"code","73dc380f":"code","9da1da17":"code","d5af10fd":"markdown","d104a679":"markdown","1ba68b12":"markdown","b5d6cd3e":"markdown","d099a0e1":"markdown","11023d68":"markdown","60773dcb":"markdown","f7a811e4":"markdown","3209579a":"markdown","105af667":"markdown","8b19f214":"markdown","90418e25":"markdown","8516ed70":"markdown","6a5e4b10":"markdown","9dab02f2":"markdown","61073242":"markdown","7f8f0e99":"markdown","5ba7200d":"markdown","875fc800":"markdown","9b5cf563":"markdown","2a4f57bc":"markdown"},"source":{"bd7644b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport numpy as np\nimport matplotlib as mp\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport random\n\nimport cv2   # object detection\nimport tensorflow as tf  # deeplearning library\nfrom tensorflow import keras\nfrom keras import applications\nfrom keras.models import load_model\n\nfrom sklearn.model_selection import train_test_split  # splitting my nn data easily\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\n\n\nimport sys\nimport os\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/natural-images\"))\n\n\nfrom distutils.version import StrictVersion\nfrom collections import defaultdict\nfrom io import StringIO\n\nsys.path.append(\"..\")\n","86a199f8":"#from imageai.Detection import ObjectDetection\nprint(tf.__version__)","1886c29b":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","4add5a39":"inp_img_width  = 224 #200\ninp_img_height = 224 #100\nimg_size = inp_img_height * inp_img_width","b6b65cb5":"def load_images(image_dir):\n    \"\"\"Loads all images inside the imageDir into an array.\"\"\"\n    image_bond = [] # array for all images  \n    image_path_list = []\n    VALID_IMAGE_EXTENSIONS = [\".jpg\", \".jpeg\", \".png\"] # valid extensions\n\n    for file in os.listdir(image_dir):\n        extension = os.path.splitext(file)[1]\n        if extension.lower() not in VALID_IMAGE_EXTENSIONS:\n            continue\n        image_path_list.append(os.path.join(image_dir, file))\n        \n    for imagePath in image_path_list:       \n        img = cv2.imread(imagePath)  # reads all the images from the given path\n        if img is None: # choose next\n            continue\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        image_bond.append(img)\n        \n    return(image_bond)\n\n\ndef resize_images(img_arr, width, height):\n    \"\"\"Resizes a single image\"\"\" \n    img_res_arr = []\n    width = width\n    height = height\n    \n    for img in img_arr:\n        img = cv2.resize(img,(width, height))\n        img_res_arr.append(img)\n    \n    return img_res_arr\n\ndef gray_images(img_arr):\n    img_arr_gray = []\n    for img in img_arr:\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        img_arr_gray.append(img)\n    return img_arr_gray\n\ndef assign_images(img_arr,assignment):\n    #img_arr_assigned = []\n    #assignment_arr = [assignment]\n    img_arr_assigned = [assignment for img in img_arr]\n    #for img in img_arr:\n    #    img_arr_assigned.append(assignment)\n    return img_arr_assigned","f9ad3539":"## Load images, resize and gray them and at least assign the correct object type\n\n## Airplanes\nimages_airplanes = load_images('..\/input\/natural-images\/natural_images\/airplane\/')          ## Load image into array of arrays\nimages_airplanes = resize_images(images_airplanes, inp_img_width,inp_img_height)  ## Resize the image to the predefined size\n#images_airplanes = gray_images(images_airplanes)                                  ## Gray images \nimages_airplanes_assigned = assign_images(images_airplanes,'airplane')            ## Assign the correct object to the image (our target)\n\n## Motorbike\nimages_motorbikes = load_images('..\/input\/natural-images\/natural_images\/motorbike\/')\nimages_motorbikes = resize_images(images_motorbikes, inp_img_width,inp_img_height)\n#images_motorbikes = gray_images(images_motorbikes)\nimages_motorbikes_assigned = assign_images(images_motorbikes,'motorbike')\n\n# Cars\nimages_cars      = load_images('..\/input\/natural-images\/natural_images\/car\/')\nimages_cars      = resize_images(images_cars, inp_img_width,inp_img_height)\n#images_cars      = gray_images(images_cars)\nimages_cars_assigned = assign_images(images_cars,'car')\n\n# Cats\nimages_cats       = load_images('..\/input\/natural-images\/natural_images\/cat\/')\nimages_cats       = resize_images(images_cats, inp_img_width,inp_img_height)\n#images_cats       = gray_images(images_cats)\nimages_cats_assigned = assign_images(images_cats,'cat')\n\n# Persons\nimages_persons    = load_images('..\/input\/natural-images\/natural_images\/person\/')\nimages_persons    = resize_images(images_persons, inp_img_width,inp_img_height)\n#images_persons    = gray_images(images_persons)\nimages_persons_assigned = assign_images(images_persons,'person')","17be7748":"images_features = images_airplanes + images_motorbikes + images_cars + images_cats + images_persons\nprint('lenght of feature set: ',len(images_features))","573e4042":"images_targets = images_airplanes_assigned + images_motorbikes_assigned + images_cars_assigned + images_cats_assigned + images_persons_assigned\nprint('lenght of target set: ',len(images_targets))","054d4a6e":"# combine them in one list\ncomb_list = list(zip(images_features, images_targets))\n\nrandom.seed(45)\n\n# shuffle both list equaly\nrandom.shuffle(comb_list)\n\n# splitt them again\nimages_features, images_targets = zip(*comb_list)","32dc6d8c":"from IPython.display import display\n\ndisplay(Image.fromarray(images_features[0]))\ndisplay(images_targets[0])","6644ec6d":"display(Image.fromarray(images_features[1]))\ndisplay(images_targets[1])","f763cfca":"display(Image.fromarray(images_features[10]))\ndisplay(images_targets[10])","53b8baaf":"# splitting features and targets into train- and test- set\nX_train, X_test, y_train, y_test = train_test_split(images_features, images_targets, test_size = 0.20, random_state = 45)","a4f152da":"# scaling, normalizing the image pixels (between 0 and 1)\nX_train = tf.keras.utils.normalize(np.asfarray(X_train))#, axis = -1) \nX_test = tf.keras.utils.normalize(np.asfarray(X_test))#, axis = -1)","e3cad4d1":"#X_train = np.asfarray(X_train)\n#X_test = np.asfarray(X_test)","eda46851":"# join train and test to encode(get_dummies) all categories in the same way \ny = y_train + y_test\ndf_y = pd.DataFrame(y) ","0c5be8b6":"# Label encoding of the targets\nle = LabelEncoder()\nle.fit(df_y)\ndf_y_hot = le.transform(df_y)","9b86e499":"# reshaping for the neural network\ndf_y_hot = pd.DataFrame(df_y_hot)\ndf_y_hot = np.asfarray(df_y_hot)","75f99183":"# write the created dummies back again\n# just to make this clear: I used the length of the train data set to split the combined lists into train ([:len(y_train)]) and test([len(y_train):]) again.\n#  in the same way I convert the result into in array, which is necessary for the use of an nn.\ny_train = np.asfarray( df_y_hot[:len(y_train)] )#.reshape(1,-5)\ny_test = np.asfarray( df_y_hot[len(y_train):] )#.reshape(1,-5)","72f5acb7":"from keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n","4db8c763":"# Dataframes with all targets\ndf_y = pd.DataFrame(y)","03a2aebd":"# Drop all duplicates to just get the unique target values\ndf_y = df_y.drop_duplicates(subset = [0])\ndf_y","5c28a948":"resnet = ResNet50(weights='imagenet', include_top=False, input_shape = (inp_img_width, inp_img_height,3) )","f726ca3b":"## Github Pull: https:\/\/github.com\/keras-team\/keras\/pull\/9965\n\n## From: https:\/\/keras.io\/api\/layers\/normalization_layers\/batch_normalization\/\n# Batch normalization applies a transformation \n# that maintains the mean output close to 0 and the output standard deviation close to 1.\nfor layer in resnet.layers:\n    if isinstance(layer, tf.python.keras.layers.BatchNormalization):\n        layer.trainable = True\n    else:\n        layer.trainable = False","80cf3354":"#for layer in resnet.layers:\n#    layer.trainable = False\n\nresnet.summary()","bd7db069":"model = tf.keras.models.Sequential()","62416adf":"model.add(resnet)","9fe8f0d8":"model.add(tf.keras.layers.Flatten())","9ef082ce":"# Fully connected layer with 5 neurons (our final prediction classes)\nmodel.add(Dense(5, activation=\"softmax\"))","73999f42":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy']\n             )\n","183ac5b9":"print(\"Number of weights after calling the model:\", len(model.weights))","5f130aae":"model.summary()\n","8fffa9f7":"model.fit(X_train, \n          y_train,\n          steps_per_epoch=3483, # X_train.shape[1]\n          epochs = 250\n         )\n\n","cfa905a9":"weights_path = \"..\/output\/weights\"\n\nmodel.save_weights('..\/output\/weights')","9456e26d":"model.save('..\/output\/model') ","ab0dbf43":"# Re-evaluate the model\nloss, acc = model.evaluate(X_test,  y_test, verbose=2)\nprint(\"Trained model, accuracy: {:5.2f}%\".format(100*acc))","309a4c5f":"# Create new model based on original one\nnew_model = tf.keras.models.load_model('..\/output\/model')\n\n# Check its architecture\nnew_model.summary()","a5806ca5":"# Loads the weights\nnew_model.load_weights('..\/output\/weights')","f5e5df14":"# Re-evaluate the model\nloss, acc = new_model.evaluate(X_test,  y_test, verbose=2)\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))","8362f6a1":"# laoding and resizing the image\nsingle_image = load_images('..\/input\/single-picture\/')          ## Load image into array of arrays\nsingle_image = resize_images(single_image, inp_img_width,inp_img_height)  ## Resize the image to the predefined size\n   ","ecbe8e96":"display(Image.fromarray(single_image[0]))","051c00a9":"## Normalizing the image \n# Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\nsingle_image_norm = tf.keras.utils.normalize(np.asfarray(single_image))","3e93dbd1":"# Shape of the new image list list (first number is the amount of images in this list -> so one :D )\nsingle_image_norm.shape","c4fa347c":"# Hot econded categorical given clases \nle.classes_","6ecf9e0e":"# Predict a single image) by letting the correct neuron fire (here it should be the one at position 3 or index position 2 \n# according to the labelencoded list above)\n### new_model(single_image_norm)","73dc380f":"# Answer at index number 2 \n###le.inverse_transform([2])","9da1da17":"# Testing the origin model with this prediction\nmodel(single_image_norm)","d5af10fd":"The following part will load, resize and gray the image for the neural network. Because there are no predefined targets for the images I need to create them by myself based on the image foldername.","d104a679":"# The Model","1ba68b12":"### Random Shuffle of the two Lists\nI will use here a random shuffle for this two lists in a combined way to make sure all targets fit to their features and vice versa. It would be easier to hold both values (array-list based features and the targets) in one list instead of in two ones, but according to the array-list based features, it was difficult for me to find a good version that did not provoke the performances of this notebook. If you have any suggestions, please let me know in the comments.","b5d6cd3e":"### Compile and Save","d099a0e1":"## Model Load","11023d68":"#### Targets","60773dcb":"## Model Building with Transfer Learning on ResNet50","f7a811e4":"#### Features","3209579a":"## Preparing Training\nIn this chapter I will prepare the training set which will be a training set from different images of vehicles, persons and animals.","105af667":"## Evaluate Model","8b19f214":"## Test Loaded Model With Totaly Unknown Image","90418e25":"# Introduction","8516ed70":"## Global Vars","6a5e4b10":"#### Targets","9dab02f2":"Next step will be the combination of all the lists above into two lists:\n\n* features and\n* targets","61073242":"Here the test now that feature (image) and target (typ) map.","7f8f0e99":"## Env Setup","5ba7200d":"## Imports","875fc800":"#### Features","9b5cf563":"## Define the Image-Sets","2a4f57bc":"# Installs"}}