{"cell_type":{"ba7ef3a3":"code","773e6512":"code","2b2c480c":"code","e702d035":"code","845bba2d":"code","123a361d":"code","1935d4aa":"code","b075eff5":"markdown","b9d22c6c":"markdown","cb186c87":"markdown","0e8aa018":"markdown","a2ee8369":"markdown","656b9a0e":"markdown"},"source":{"ba7ef3a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","773e6512":"!pip install tensorflow==1.15.0\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nprint(tf.__version__)","2b2c480c":"def load_data(filefolder):\n    data = np.load(os.path.abspath(filefolder + '\/names_onehots.npy'), allow_pickle=True).item()\n    data = data['onehots']\n    label = pd.read_csv(os.path.abspath(filefolder + '\/names_labels.txt'), sep=',')\n    label = label['Label'].values\n    return data, label","e702d035":"class MyModel(tf.keras.Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.conv1_layer = tf.keras.layers.Conv2D(32, 5, 1, 'same', activation=tf.nn.relu)\n        self.pool1_layer = tf.keras.layers.MaxPool2D(2, 2)\n        self.conv2_layer = tf.keras.layers.Conv2D(32, 3, (1, 2), 'same', activation=tf.nn.relu)\n        self.pool2_layer = tf.keras.layers.MaxPool2D(2, 2)\n        # flat\n        self.FCN = tf.keras.layers.Dense(2)\n        # softmax\n\n    def call(self, inputs):\n        x = self.conv1_layer(inputs)\n        x = self.pool1_layer(x)\n        x = self.conv2_layer(x)\n        x = self.pool2_layer(x)\n        flat = tf.reshape(x, [-1, 18*50*32])\n        output = self.FCN(flat)\n        output_with_sm = tf.nn.softmax(output)\n        return output, output_with_sm","845bba2d":"# parameters\nLR = 0.01\nBatchSize = 128\nEPOCH = 2\n\ntrain_data_path = \"\/kaggle\/input\/cs410-2020-fall-ai-project-1\/data\/train\/\"\nvalidation_data_path = \"\/kaggle\/input\/cs410-2020-fall-ai-project-1\/data\/validation\/\"\n# data\ntrain_x, train_y = load_data(train_data_path)\nvalid_x, valid_y = load_data(validation_data_path)\n\n\n# model & input and output of model\nmodel = MyModel()\n\nonehots_shape = list(train_x.shape[1:])\ninput_place_holder = tf.placeholder(tf.float32, [None] + onehots_shape, name='input')\ninput_place_holder_reshaped = tf.reshape(input_place_holder, [-1] + onehots_shape + [1])\nlabel_place_holder = tf.placeholder(tf.int32, [None], name='label')\nlabel_place_holder_2d = tf.one_hot(label_place_holder, 2)\noutput, output_with_sm = model(input_place_holder_reshaped)\nmodel.summary()  # show model's structure\n\n# loss\nbce = tf.keras.losses.BinaryCrossentropy()  # compute cost\nloss = bce(label_place_holder_2d, output_with_sm)\n\n# Optimizer\ntrain_op = tf.train.AdamOptimizer(LR).minimize(loss)\n\n# auc\nprediction_place_holder = tf.placeholder(tf.float64, [None], name='pred')\nauc, update_op = tf.metrics.auc(labels=label_place_holder, predictions=prediction_place_holder)\n\n# run\ninit_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\nwith tf.Session() as sess:\n    sess.run(init_op)\n\n    saver = tf.train.Saver()\n\n    train_size = train_x.shape[0]\n    best_val_auc = 0\n    for epoch in range(EPOCH):\n        for i in range(0, train_size, BatchSize):\n            b_x, b_y = train_x[i:i + BatchSize], train_y[i:i + BatchSize]\n            _, loss_ = sess.run([train_op, loss], {'input:0': b_x, 'label:0': b_y})\n\n            print(\"Epoch {}: [{}\/{}], training set loss: {:.4}\".format(epoch, i, train_size, loss_))\n\n        if epoch % 1 == 0:\n            val_prediction = sess.run(output_with_sm, {'input:0': valid_x})\n            val_prediction = val_prediction[:, 1]\n            auc_value = sess.run(update_op, feed_dict={prediction_place_holder: val_prediction, label_place_holder: valid_y})\n            print(\"auc_value\", auc_value)\n            if auc_value > best_val_auc:\n                best_val_auc = auc_value\n                saver.save(sess, '\/kaggle\/working\/weights\/model')\n                ","123a361d":"def load_test_data_name(filefolder):\n    data = np.load(os.path.abspath(filefolder + '\/names_onehots.npy'), allow_pickle=True).item()\n    onehots = data['onehots']\n    name = data['names']\n    return onehots, name","1935d4aa":"# data\ntest_path = \"\/kaggle\/input\/cs410-2020-fall-ai-project-1\/data\/test\/\"\ntest_data, test_name = load_test_data_name(test_path)\nname = test_name\n\n# model\ntf.reset_default_graph()  # \nmodel = MyModel()\ninput_place_holder = tf.placeholder(tf.float32, [None] + list(test_data.shape[1:]), name='input')\ninput_place_holder_reshaped = tf.reshape(input_place_holder, [-1] + list(test_data.shape[1:]) + [1])\noutput, output_with_sm = model(input_place_holder_reshaped)\n\n# Predict on the test set\ndata_size = test_data.shape[0]\nwith tf.Session() as sess:\n    saver = tf.train.Saver()\n    saver.restore(sess, os.path.abspath('\/kaggle\/working\/weights\/model'))\n    # saver.restore(sess, os.path.abspath('fds'))\n    prediction = []\n    for i in range(0, data_size, BatchSize):\n        print(i)\n        test_output = sess.run(output, {input_place_holder: test_data[i:i + BatchSize]})\n        test_output_with_sm = sess.run(output_with_sm, {input_place_holder: test_data[i:i + BatchSize]})\n        pred = test_output_with_sm[:, 1]\n        prediction.extend(list(pred))\nsess.close()\nf = open('output_518000001.txt', 'w')\nf.write('Chemical,Label\\n')\nfor i, v in enumerate(prediction):\n    f.write(name[i] + ',%f\\n' % v)\nf.close()","b075eff5":"# Define Model","b9d22c6c":"# Load Data","cb186c87":"# Load Test Set","0e8aa018":"# Import Package","a2ee8369":"# Train","656b9a0e":"# Predict on the test data"}}