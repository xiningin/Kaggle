{"cell_type":{"0a217cc7":"code","e8cc92c9":"code","76dab0c9":"code","1790a2d7":"code","8803293f":"code","f5bea374":"code","93ffe61e":"code","09cc7746":"code","58a58868":"code","0b78946d":"code","ae363ea4":"code","39681f55":"markdown","2baf328b":"markdown","9f7ca4d8":"markdown","678b1495":"markdown","3fcfa9f0":"markdown","e74149f0":"markdown","4bb0f923":"markdown"},"source":{"0a217cc7":"import json\nimport ast\nimport base64\nimport numpy as np\nimport random\nfrom PIL import Image, ImageDraw, ImageFont\nfrom io import BytesIO","e8cc92c9":"with open('\/kaggle\/input\/ocr-data\/extras\/single_example\/example.json') as f:\n    data = json.load(f)\n\nwith open('\/kaggle\/input\/ocr-data\/extras\/single_example\/visible_char_map_colors.json') as f:\n    colors = json.load(f)\n    # Tuples cannot be stored as json, change color assignments to tuples\n    colors = {key: tuple(color) for key, color in colors.items()}","76dab0c9":"data.keys()","1790a2d7":"data['image_data'].keys()","8803293f":"def convert_string_to_bytes(string):\n    \"\"\"\n    Converts a string representation of bytes back to bytes.\n\n    Parameters\n    ----------\n    string : str\n        A string of a bytes-like object.\n\n    Returns\n    ----------\n    bytes : bytes\n        bytes (i.e 'b\\'\\\\x89PNG\\\\r\\\\n ... ' -> '\\\\x89PNG\\\\r\\\\n ...').\n\n    \"\"\"\n    return ast.literal_eval(string)\n\n\ndef unpack_list_of_masks(string_list):\n    \"\"\"\n    Unpacks a list of string represented bytes objects and returns a list of bytes objects.\n\n    Parameters\n    ----------\n    string_list : list\n        A list of string representation bytes-like objects\n\n    Returns\n    ----------\n    mask_bytes: list\n        A list of png masks as bytes.\n    \"\"\"\n    return [convert_string_to_bytes(string) for string in string_list]","f5bea374":"def convert_mask_bytes_to_rgba_color_scheme(mask_bytes, label):\n    \"\"\"\n    This function makes the png-masks transparent everywhere except the masked area of interest, enhancing the visualization. PNG masks are not inherently RGBA, this function adds the fourth depth of 'alpha' or transparency.\n    \n    Parameters\n    ----------\n    mask_bytes : list\n        A png masks as bytes.\n    label :\n        The png mask's corresponding label. (Used for coloring the mask)\n    \n    Returns\n    ----------\n    mask: PIL.Image.Image\n        An RGBA Image object representing the mask of interest as RGBA, appropriately colored.\n    \"\"\"\n    # Open the mask.\n    mask = Image.open(BytesIO(mask_bytes))\n    mask = mask.convert(\"RGBA\")\n    datas = mask.getdata()\n    \n    newData = []\n\n    # Iterate through the pixel items of the mask. Masks are inverted when saved (i.e. white is the mask, black is the background). Find black pixels and replace with transparent pixels. Replace the mask with the label color.\n    for item in datas:\n        if item[0] == 0 and item[1] == 0 and item[2] == 0:\n            # Make it transparent.\n            newData.append((255, 255, 255, 0))\n        else:\n            # Assign color.\n            newData.append(colors[label])\n\n    mask.putdata(newData)\n    return mask","93ffe61e":"def overlay_masks_on_image(img, rgba_masks):\n    \"\"\"\n    Modifies the source image in place to show the colored masks for each character.\n    \n    Parameters\n    ----------\n    img : PIL.Image.Image\n        The source image.\n    rgba_masks : list\n        A list of masks appropriately converted to RGBA Image objects.\n\n    Returns\n    ----------\n    None\n    \"\"\"\n    for mask in rgba_masks:\n        img.paste(mask, (0,0), mask)\n\ndef add_text_border(draw_obj, font, text, xmin, ymin):\n    \"\"\"\n    Add a thin black border around the text, helps with visualization. Modifies the draw object in place.\n    \n    Parameters\n    ----------\n    draw_obj : PIL.ImageDraw.ImageDraw\n        The draw object.\n    font : PIL.ImageFont.FreeTypeFont\n        The ImageFont to add a border to.\n    text : str\n        The precise text being outlined, generally the label.\n    xmin, ymin: int\n        The xmin and ymin for the starting point of the text. (Top-Left)\n    \n    Returns\n    ----------\n    None\n    \"\"\"\n    # Add a thin border.\n    draw_obj.text((xmin-2, ymin), text, font=font, fill=\"black\")\n    draw_obj.text((xmin+2, ymin), text, font=font, fill=\"black\")\n    draw_obj.text((xmin, ymin-2), text, font=font, fill=\"black\")\n    draw_obj.text((xmin, ymin+2), text, font=font, fill=\"black\")\n\ndef draw_bounding_boxes_on_image(img, xmins, ymins, xmaxs, ymaxs, labels):\n    \"\"\"\n    Draws and labels bounding boxes on source image using ground truth lists of details pertaining to the source image. Modifies the source image in place.\n    \n    Parameters\n    ----------\n    img : PIL.Image.Image\n        The source image.\n    xmins, ymins, xmaxs, ymaxs : list\n        A list of the respectful coordinates for the image\n    labels : list\n        A list of labels for each character to be drawn.\n\n    Returns\n    ----------\n    None\n    \"\"\"\n    draw_obj = ImageDraw.Draw(img)\n    font_file = \"\/kaggle\/input\/ocr-data\/extras\/single_example\/Roboto-Regular.ttf\"\n    font = ImageFont.truetype(font_file, 32)\n    for xmin, ymin, xmax, ymax, label in zip(xmins, ymins, xmaxs, ymaxs, labels):\n        draw_obj.rectangle([xmin, ymin, xmax, ymax], outline=colors[label], width=3)\n        text = str(label)\n        add_text_border(draw_obj, font, text, xmin, ymin)\n        draw_obj.text((xmin, ymin), text, font=font, fill=colors[label])","09cc7746":"# Open the test image.\nexample_img = Image.open(\"\/kaggle\/input\/ocr-data\/extras\/single_example\/example_img.jpg\")\n\n# Gather appropriate items from the data json for the image.\nxmins = data[\"image_data\"][\"xmins_raw\"]\nymins = data[\"image_data\"][\"ymins_raw\"]\nxmaxs = data[\"image_data\"][\"xmaxs_raw\"]\nymaxs = data[\"image_data\"][\"ymaxs_raw\"]\nlabels = data['image_data']['visible_latex_chars']\n\n# Unpack and convert serialized pngs.\nmasks = unpack_list_of_masks(data[\"image_data\"][\"png_masks\"])","58a58868":"# Convert masks to correct colors and to RGBA format, can take a few seconds.\nrgba_masks = [convert_mask_bytes_to_rgba_color_scheme(mask, label) for mask, label in zip(masks, labels)]","0b78946d":"# Overlay masks on the image.\noverlay_masks_on_image(example_img, rgba_masks)\n\n# Add bounding boxes.\ndraw_bounding_boxes_on_image(example_img, xmins, ymins, xmaxs, ymaxs, labels)","ae363ea4":"# Visualize!\ndisplay(Image.open(\"\/kaggle\/input\/ocr-data\/extras\/single_example\/example_img.jpg\"))\ndisplay(example_img)","39681f55":"## Visualize an example image\nOpen the example image, gather the appropriate details required to visualize bounding boxes and masks. Note: the source image is modified in place, starting with masks, then adding bounding boxes.","2baf328b":"## Load the Data\nLoad the example JSON and the color scheme for characters. The example JSON is 1 entry in the exact same formatting of the ground truth JSONs with each batch. These starting functions could be extended to review any image from any of the 10 batches.","9f7ca4d8":"Each image has several fields of meta data included in its JSON - at the highest level, `uuid` is the identifier the synthetic image was generated with and `filename` will always be uuid + jpg. `latex` and `unicode_str` are the ground truth math expressions being represented in the image. Lastly, `font` is the identifier used for the font the image was generated with.","678b1495":"Additionally, each image has a `image_data` dictionary which gives the ground truth representations of boxes, masks, and other details of interest. All lists are in the same index, that is, `xmins[1]` is the xmin of the box for `visible_latex_chars[1]`. Fields of `_raw` are the values as they relate to the image height and width, if no designation is made, the values are normalized between 0.0 - 1.0. \n\n`png_masks` are serialized, binary pngs of masks for each character. This is the preferred format of masks when converting training data into TFRecord file format, see [Tensorflow's Object Detection Github](https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/object_detection\/g3doc\/instance_segmentation.md) for more details.","3fcfa9f0":"## Imports","e74149f0":"# Aida Calculus Math Handwriting Recognition Dataset\n\n## Visualizing Ground Truth from JSON\n\n---\n\n## Introduction\n\nThis dataset contains several JSON files that serve as the \"ground truth\" for the images. There are several fields that communicate a story through EDA, addressed in another notebook, however, there are some fields specific to the OCR task (mask\/pixel and bounding box ground truth). This notebook serves as a starting place to visualize the information contained within the ground truth JSONs. This notebook heavily uses the [Pillow](https:\/\/pillow.readthedocs.io\/en\/stable\/reference\/index.html) library, it is advised to review the official documentation of that library before starting.","4bb0f923":"## Create helper functions for visualization\nThese functions will help facilitate visualizing masks and bounding boxes on images."}}