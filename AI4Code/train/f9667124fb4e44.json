{"cell_type":{"4bbf1380":"code","a3dcb01c":"code","8122a678":"code","9265b575":"code","945cadd7":"code","6186b25f":"code","58998e44":"code","8dbe2056":"code","2de93b49":"code","085245ed":"code","df2c1a0b":"code","1e69adf8":"code","bdc731a6":"code","4fdd1b2d":"code","522646ac":"code","63d97da7":"markdown","0602e366":"markdown","5423a89d":"markdown","ac5c47c3":"markdown","12f04e1f":"markdown","2457aca2":"markdown","fcc6cc62":"markdown","7b8735d2":"markdown","455603ce":"markdown","39eafdec":"markdown","11451000":"markdown","e903a043":"markdown","d952fab5":"markdown","cd54ba6b":"markdown","ed504825":"markdown","76a1a551":"markdown"},"source":{"4bbf1380":"import numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator \n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization","a3dcb01c":"n_classes = 3 #number of classes\nlabel_shape = (n_classes,) #input shape of label\nbatch_size = 32 #size of batch (2^n)\nepochs = 10 #count of epochs \n\nimage_size = (224, 224) #size of image, read from directory\ninput_shape = (image_size[0], image_size[1], 3) #input shape for NN ","8122a678":"path_to_data = \"..\/input\/fruits\/DataSetFruits\"\n\nimage_generator = ImageDataGenerator(\n                                     validation_split=0.1, \n                                     rescale=1.\/255, \n                                     rotation_range=5, \n                                     zoom_range=0.1,\n                                     width_shift_range=0.1, \n                                     height_shift_range=0.1, \n                                     shear_range=0.2,\n                                     fill_mode=\"nearest\") \n\ntrain_dataset = image_generator.flow_from_directory(\n                                                 directory=path_to_data,\n                                                 subset=\"training\",\n                                                 seed = 42, \n                                                 target_size=image_size,\n                                                 batch_size=batch_size,\n                                                 shuffle=True,\n                                                 color_mode = \"rgb\",\n                                                 class_mode=\"categorical\")\n\ntest_dataset = image_generator.flow_from_directory(\n                                                 directory=path_to_data,\n                                                 subset=\"validation\",\n                                                 seed = 42, \n                                                 target_size=image_size,\n                                                 batch_size=batch_size,\n                                                 shuffle=True,\n                                                 color_mode = \"rgb\",\n                                                 class_mode=\"categorical\")","9265b575":"images, labels = next(test_dataset)\n\nplt.figure(figsize=(5, 5))\nplt.imshow(images[0])\nprint(labels[0]) #print the class of the image (e.g. [0. 0. 1] is a coconut)\nprint(images[0].shape) #print the image size","945cadd7":"# Initialize the convultional neural network\nmodel = Sequential()\n\n#Step-1: Convolution\nmodel.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=input_shape, activation = 'relu'))\n\n#Step-1: Max Pooling\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\nmodel.add(BatchNormalization())\n\n#Step-2: Convolution \nmodel.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n\n#Step-2: Max Pooling\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\nmodel.add(BatchNormalization())\n\n#Step-3: Convolution\nmodel.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nmodel.add(BatchNormalization())\n\n#Step-4: Convolution\nmodel.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nmodel.add(BatchNormalization())\n\n#Step-5: Convolution\nmodel.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n\n# Max Pooling Step 3\nmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\nmodel.add(BatchNormalization())\n\n# Flattening Step\nmodel.add(Flatten())\n\n# Full Connection Step\nmodel.add(Dense(units = 4096, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units = 4096, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units = 1000, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units = n_classes, activation = 'softmax'))\n","6186b25f":"model.summary()","58998e44":"model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.001),\n              loss=keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n","8dbe2056":"callbacks = [\n    keras.callbacks.ModelCheckpoint(filepath='Alexnet_fruits_batch_' + str(batch_size) + \\\n                                    '_epoch_{epoch:02d}_acc_{accuracy:.4f}_val_acc_{val_accuracy:.4f}.h5'),\n    keras.callbacks.TensorBoard(log_dir='.\/logs'),\n    keras.callbacks.EarlyStopping(monitor='val_loss',\n                                  min_delta=0,\n                                  patience=1,\n                                  verbose=0, \n                                  mode='auto')\n]","2de93b49":"H = model.fit(train_dataset, \n              callbacks=callbacks, \n              validation_data=test_dataset,\n              epochs=epochs, \n              verbose=1)","085245ed":"plt.figure(figsize = (8, 5))\nplt.plot(H.history['accuracy'], label='train', color='k')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.grid()\nplt.show()\n\n\nplt.figure(figsize = (8, 5))\nplt.plot(H.history['val_accuracy'], label='valid', color='k')\nplt.legend(loc='upper left')\nplt.title('Model validation accuracy')\nplt.ylabel('Validation accuracy')\nplt.xlabel('Epoch')\nplt.grid()\nplt.show()\n\n\nplt.figure(figsize = (8, 5))\nplt.plot(H.history['loss'], label='train', color='k')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.grid()\nplt.show()\n\n\nplt.figure(figsize = (8, 5))\nplt.plot(H.history['val_loss'], label='test', color='k')\nplt.legend(loc='upper right')\nplt.title('Model validation cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.grid()\nplt.show()","df2c1a0b":"eval = model.evaluate(test_dataset)\nprint(\"Model loss:\", eval[0])\nprint(\"Model accuracy:\", eval[1])","1e69adf8":"images, labels = next(test_dataset) #images and labels in one batch of test_dataset","bdc731a6":"y_prob = model.predict(images) #make predictions for all images in a batch\ny_classes = y_prob.argmax(axis=-1)\nprint(\"ttl imgs in a current batch: \", len(y_classes))","4fdd1b2d":"plt.figure(figsize=(5, 5))\nplt.imshow(images[0]) #take the 1st img in a batch\ny = np.argmax(labels[0], axis=-1)","522646ac":"print(\"\u2022 Classes:\\n- 0 - Apple\\n- 1 - Banana\\n- 2 - Coconut (Cocos)\\n\")\nprint(\"\u2022 Prediction results:\")\nprint(\"- predicted class for first img in a batch:\", y_classes[0]) \nprint(\"- real class for first img in a batch:     \", y)","63d97da7":"A [callback](https:\/\/keras.io\/api\/callbacks\/) is an object that can perform actions at various stages of training (e.g. at the start or end of an epoch, before or after a single batch, etc).\n\nHere we would like to save our trained model after each epoch, save logs and have an [early stopping](https:\/\/keras.io\/api\/callbacks\/#earlystopping).\n[Early stopping](https:\/\/stackoverflow.com\/questions\/43906048\/which-parameters-should-be-used-for-early-stopping) is basically stopping the training once your loss starts to increase (or in other words validation accuracy starts to decrease). The example is shown in a figure below.\n![image.png](attachment:e801e02e-8aa8-4f15-bc51-40bfb9c22602.png)","0602e366":"# 7. INPUT DATA VISUALIZATION\nHere we just check is dataset was correctly loaded. We take the batch of data via **next()** function and view the image via *'plt'*.","5423a89d":"# 9. TRAIN VISUALIZATION\nVisualizing helps you to understand your data. Let's build *'accuracy'*, *'validation accuracy'*, *'loss'* and *'validation loss'*. ","ac5c47c3":"Also, we can check the created model via **summary()** function.","12f04e1f":"# 1. TASK FORMULATION\nWe have dataset that constists of three classes (Apple, Banana, Cocos (Coconut)). Our aim is to classify this images. For this task we are going to use neural networks as the apparatus of Artificial Intelligence (AI). ","2457aca2":"# 4. LIBRARIES\nSo, let think, which libraries we should use to make our project right:\n1. [NumPy](https:\/\/numpy.org\/) - for matrices and arrays, has a lot of math functions.\n2. [Keras](https:\/\/keras.io\/) - for making and training neural networks\n3. [Matplotlib](https:\/\/matplotlib.org\/) - for visualizations, like plots","fcc6cc62":"# 5. CONSTANTS\nAlso, we should define some variables, like:\n- number of classes (three: apple, banana, coconut); \n- labels for classes (e.g. 0 - apple, 1 - banana, 2 - coconut); \n- size of batch for training (for best performing, it should be equal to 2^n); \n- count of epochs (as we have small dataset, we don't need to have very big number of epochs); \n- image size and input shape for neural network (as example, for AlexNet is better to set (224, 224, 3) size of image).","7b8735d2":"# 8. CONSTUCTION OF NEURAL NETWORK\nThe code model structure was taken from [here](https:\/\/www.kaggle.com\/vipoooool\/plant-diseases-classification-using-alexnet). Here we build the AlexNet using the the structure, that was written in the paper. It is show in paragraph **[3. ALEXNET]** of this article.","455603ce":"# CLASSIFICATION TASK USING NEURAL NETWORKS (KERAS LIBRARY) FOR BEGINNERS\nHi everyone! And welcome to my third notebook! Today we will learn how to build and train simple neural network using keras library. We are goin to solve classification task with dataset [Fruits](https:\/\/www.kaggle.com\/kyrodonte\/fruits) as an example.\n\n**This article has a lot of explanations, so it will be very helpful for beginners.**\n\nSo, let's start!","39eafdec":"# 10. TEST NEURAL NETWORK\nAfter the model has been trained, we can evaluate the quality of the model in train and on test datasets. Firstly, we can evaluate our model via **evaluate()**. ","11451000":"Once the model is created, you can config the model with losses and metrics with **model.compile()**.","e903a043":"# 11. CONCLUSION\nThank you so much for reading my new article! I hope, it was interesting and you liked it! If you have any questions, you can comment and I will try to answer them.\n\nHere you can read my previous Kaggle Notebooks: \n- [Retail Trade Report Department Stores (LSTM)](https:\/\/www.kaggle.com\/maricinnamon\/retail-trade-report-department-stores-lstm)\n- [Fetal Health Classification for beginners sklearn](https:\/\/www.kaggle.com\/maricinnamon\/fetal-health-classification-for-beginners-sklearn)","d952fab5":"# 2. NEURAL NETWORKS\n**Artificial Neural Networks (ANN or NN)** are special computing systems, which are used to solve some problems such as: \n* classification tasks (e.g. classify whether it is cat or dog in the image)\n* forecasting tasks (e.g. predict future sales of shops in the U.S.)\n* clusterization (e.g. divide numerical data into some classes, but we do not know exactly in advance what class this data belongs to)\n* other problems\n\nANN are **inspired by** the biological neural networks. Moreover, for different tasks we can use different types of neural networks. I will name some of them:\n* Multilayer perceptron, one of the simpliest examples\n* Radial basis network\n* Kohonen neural network (as Competitive layers)\n* Kohonen neural network (as a Self-Organizing Map, SOM)\n* Recurrent neural networks (RNN, e.g. Hopfield Network, LSTM, [here you can find my example of LSTM in Python](https:\/\/www.kaggle.com\/maricinnamon\/retail-trade-report-department-stores-lstm) )\n* Convolutional neural networks (e.g. [LeNet](http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-98.pdf), [AlexNet](https:\/\/papers.nips.cc\/paper\/2012\/file\/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf), [Xception](https:\/\/arxiv.org\/abs\/1610.02357), etc)\n* other neural networks\n","cd54ba6b":"# 6. READ IMAGES \nIn this section we are going to read images from our folders. As you can see, we have folder \"DataSetFruits\" that consists of three folders (Apple, Banana, Cocos). Each folder represents a certain class (Apple, Banana, Cocos).\n\n\u2666 So, here we set the path to data and set some parameters it via **ImageDataGenerator()**. And there are some important stages.\n\n1. Firsty, we should **split the dataset into train and test data**. Let it will be 90%:10% respectively. You can also try it with another ratio, like 60%:40%, 70%:30%, 80%:20% and so on. I decided to make such a proportion, because our dataset is very small, so we need to have enough data to train our neural network. But, for larger datasets, I prefer to have ratio from 70%:30% to 80%:20%.\n2. Then, we shoud **normalize** our input data via *'rescale=1.\/255'*. The goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information. [Here](https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/normalize-data) you can read more. So, the input images will be not in range [0,255], but they will be in range [0,1].\n3. We can do some **data augmentation** while reading our image data. *Note, that this will not increase your dataset size, it just is used here to make some transformations with input data, like rotation, zoom and so on. It means, that the input of neural network will be fed with a little bit transformed images, that we have in dataset.*\n4. After *'image_generator'* variable was made via ImageDataGenerator(), we can read our data.\n\n\n\u2666 So, for reading our data from folders, we need **flow_from_directory()** function.\n1. We set path to our root folder with image folders.\n2. We say, whether it is *'training'* or *'validation'* subset.\n3. Also, *'seed'* is used for random.\n4. We aslo set target size of image to be reshaped. \n5. Moreover, we need to specify batch size for images, that will be fed to neural network.\n6. Also, we say that we want to shuffle our data while reading it. \n7. As we have RGB images, we set color mode as *'rgb'*.\n8. And the fill mode for images, after transforming them is also specified.\n\n[Here](https:\/\/keras.io\/api\/preprocessing\/image\/) is the full explanation. \n","ed504825":"It's time to do the model prediction with **model.predict()**.","76a1a551":"# 3. ALEXNET\nAlready in 2012, a group of researchers led by Alex Kryzhevsky, developed their own architecture of a convolutional neural network - [AlexNet](https:\/\/www.cs.toronto.edu\/~kriz\/imagenet_classification_with_deep_convolutional.pdf). It was presented during the [ILSVRC (ImageNet Large Scale Visual Recognition Challenge)](http:\/\/www.image-net.org\/challenges\/LSVRC\/), where they took first place. And a year after the publication of this article, all contestants began to use a convolutional neural network to solve the problem of classification. \n\nTherefore, we will use this convolutional neural network to solve the image classification problem. It's structure is represented below.\n![image.png](attachment:c4d3a641-24c5-49d8-9ce3-e5369311a70e.png)\n[A. Krizhevsky, I. Sutskever, G.E. Hinton, ImageNet Classification with Deep Convolutional Neural Networks, 2012]\n"}}