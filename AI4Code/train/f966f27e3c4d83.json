{"cell_type":{"62fd588f":"code","3cee946e":"code","c163bd6f":"code","239650a1":"code","c48873be":"code","ef58ff9b":"code","9ae60e23":"code","388d2fbc":"code","7554e9ef":"code","56cebab3":"code","90a1251c":"code","1ff13174":"code","737e511e":"code","d20c1f18":"markdown","dc5bf4b4":"markdown"},"source":{"62fd588f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\nimport keras\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/dataset\/dataset\"))\n\n# Any results you write to the current directory are saved as output.","3cee946e":"#define number image and size\nW=H = 224\nnumber_classes = 17\nbatch_size=32","c163bd6f":"#get image name\ndef getname(img_path):\n    return img_path.split('\/')[-2]","239650a1":"#read image\nroot_dir = '..\/input\/dataset\/dataset'\nall_path_imgs = glob.glob(os.path.join(root_dir, '*\/*.jpg'))\nprint(all_path_imgs[0])\nnp.random.shuffle(all_path_imgs)\n\nimgs = []\nlabels = []\nfor img_path in all_path_imgs:\n    img = load_img(img_path, target_size=(W,H))\n    img = img_to_array(img)\n    imgs.append(img)\n    \n    name = getname(img_path)\n    labels.append(name)\ntrain_data = np.array(imgs)\nle = LabelEncoder()\ny_encode = le.fit_transform(labels)\ntrain_labels = to_categorical(y_encode)\n\n","c48873be":"#plot data \nimport matplotlib.pyplot as plt\nfig = plt.figure(figsize=(20,20))\nrow = col = 9\nfor i in range(1, row*col+1):\n    k = np.random.randint(1, len(train_data))\n    fig.add_subplot(row, col, i)\n    img = load_img(all_path_imgs[k], target_size=(80,80))\n    plt.imshow(img)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(labels[k])\nplt.show()\n","ef58ff9b":"#train test split \nfrom sklearn.model_selection import train_test_split\nX_train, X_test , y_train , y_test = train_test_split(train_data, train_labels, test_size = 0.2, random_state = 16)","9ae60e23":"# augmentation cho training data\naug_train = keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, \n                         zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n# augementation cho test\naug_test= keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)","388d2fbc":"#load vgg16\nvgg = keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(W,H,3))\n\nvgg_layers = len(vgg.layers)\nprint('Number vgg layers: '+ str(vgg_layers))\n\nvgg_shape = vgg.output_shape\nprint('Number vgg_shape: '+ str(vgg_shape))\n\n","7554e9ef":"from keras import models\nfrom keras import layers\n\n#define top model\nflatten = layers.Flatten()(vgg.output)\n\nfc = layers.Dense(256, activation='relu')(flatten)\nfc = layers.Dropout(0.5)(fc)\n\nfc = layers.Dense(number_classes, activation='softmax')(fc)\n\n#new model \nmodel = models.Model(vgg.input, fc)","56cebab3":"#freeze vgg model \nfor layer in vgg.layers:\n    layer.trainable=False\n\nopt = keras.optimizers.RMSprop(0.001)\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=(['acc']))\nnetwork = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=batch_size),\n                              steps_per_epoch=len(X_train)\/\/batch_size,\n                              validation_data=aug_test.flow(X_test, y_test, batch_size),\n                              validation_steps=len(X_test)\/\/batch_size,\n                              epochs=25)","90a1251c":"#unfreeze vgg model \nfor layer in vgg.layers[15:]:\n    layer.trainable=True\n\nopt = keras.optimizers.SGD(0.001)\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=(['acc']))\nnetwork = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=batch_size),\n                              steps_per_epoch=len(X_train)\/\/batch_size,\n                              validation_data=aug_test.flow(X_test, y_test, batch_size),\n                              validation_steps=len(X_test)\/\/batch_size,\n                              epochs=35)","1ff13174":"#visualize \nhistory_dict = network.history\nhistory_dict.keys()","737e511e":"epochs = range(1, len(history_dict['acc'])+1)\nplt.plot(epochs, history_dict['acc'], 'b', label='acc')\nplt.plot(epochs, history_dict['val_acc'], 'r', label='val_acc')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.title(\"Training and validation acc\")\nplt.legend()\nplt.figure()\nplt.plot(epochs, history_dict['loss'], 'b', label='loss')\nplt.plot(epochs, history_dict['val_loss'], 'r', label='val_loss')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.title(\"Training and validation loss\")\nplt.legend()","d20c1f18":"**3.Architect**","dc5bf4b4":"**2.EDA**"}}