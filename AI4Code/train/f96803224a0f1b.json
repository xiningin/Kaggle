{"cell_type":{"bb3a9a69":"code","d17c5664":"code","20b5ffb7":"code","37a42105":"code","52a805b9":"code","87447237":"code","6cf92084":"code","f7671a38":"code","fde093ca":"code","3bae357d":"code","d60a1248":"code","85adc526":"code","b09729a4":"code","b6f118bb":"markdown","8d54162e":"markdown","71070d04":"markdown"},"source":{"bb3a9a69":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nfrom kaggle.competitions import twosigmanews\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.preprocessing.sequence import pad_sequences\nfrom itertools import chain\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import accuracy_score\nenv = twosigmanews.make_env()\n(market_train_df, news_train_df) = env.get_training_data()","d17c5664":"limit = 2000000\nmarket_train = market_train_df.tail(limit)\ndel market_train_df, news_train_df\ngc.collect()","20b5ffb7":"def market_preprocessing(market_df):\n    \n    market_df['time'] = market_df['time'].dt.floor('1D')\n    \n    num_cols = [col for col in market_df.columns if col not in ['universe', 'time', 'assetCode', 'assetName']]\n    market_df.loc[:, num_cols] = market_df.loc[:, num_cols].fillna(0)\n    \n    for col in num_cols:\n        market_df = market_df[np.abs(market_df[col]-market_df[col].mean()) \\\n                                <= (3*market_df[col].std())]\n        \n#     https:\/\/www.kaggle.com\/rspadim\/parse-ric-stock-code-exchange-asset\n    market_df['assetCode_exchange'] = market_df['assetCode']\n    map_a = {}\n    for i in market_df['assetCode'].unique():\n        _, a = i.split('.')\n        map_a[i] = a\n    market_df['assetCode_exchange'] = market_df['assetCode_exchange'].map(map_a)\n    \n    market_df = one_hot_encode(market_df, ['assetCode_exchange'])\n    \n    try:\n        market_df.returnsOpenNextMktres10 = market_df.returnsOpenNextMktres10.clip(-1, 1)\n        market_df['label'] = market_df.returnsOpenNextMktres10.map(lambda x: 0 if x < 0 else 1)\n    except:\n        pass\n    \n    return market_df\n\ndef one_hot_encode(df, columns):\n    \n    categorical_df = pd.get_dummies(df[columns].astype(str))\n    df.drop(columns=columns, inplace=True)\n    df = pd.concat([df, categorical_df], axis=1)  \n    \n    del categorical_df\n    \n    return df\n\ndef split(*arg, test_size=0.25):\n    sets = []\n    for i in range(len(arg)):\n        data = arg[i]\n        limit = int(len(data) * (1 - test_size))\n        sets.append(data[:limit].copy())\n        sets.append(data[limit+1000:].copy())\n    return sets","37a42105":"%%time\nprint(market_train.shape)\nmarket_train = market_preprocessing(market_train)\nprint(market_train.shape)\nmarket_train.sort_values(by=['time'], inplace=True)","52a805b9":"num_cols = [col for col in market_train.columns if col not in ['time','assetCode', 'universe', 'label', 'assetName',\n                                                               'assetCode_exchange_A', 'assetCode_exchange_N', 'assetCode_exchange_O',\n                                                               'assetCode_exchange_OB', 'assetCode_exchange_UNKNOWN', 'returnsOpenNextMktres10']]\nscaler = StandardScaler(copy=False)\nmarket_train[num_cols] = market_train[num_cols].fillna(0)\nmarket_train.loc[:, num_cols] = scaler.fit_transform(market_train.loc[:, num_cols])","87447237":"class SequenceGenerator:\n    def __init__(self, df, cols, window=10, batch_size=64, train=True):\n        self.groupby_obj = df.groupby(['assetCode'], sort=False)\n        self.cols = cols\n        self.batch_size = batch_size\n        self.train = train\n        self.window = window\n\n    def generate(self):\n        \n        while True:\n            \n            X, y, d, r, u = [], [], [], [], []\n            \n            for _, data in self.groupby_obj:\n                \n                data = data.sort_values(by=['time'])\n                num_sequences = data.shape[0] - self.window \n                \n                for seq in range(num_sequences):\n                    X.append(data[self.cols].iloc[seq:seq+self.window].values)\n                    y.append(data.label.iloc[seq+self.window-1])\n                    d.append(data.time.iloc[seq+self.window-1])\n                    r.append(data.returnsOpenNextMktres10.iloc[seq+self.window-1])\n                    u.append(data.universe.iloc[seq+self.window-1])\n                    \n                    if len(X) == self.batch_size:\n                        X_, y_, = np.array(X), np.array(y) \n                        r_, u_, d_ = np.array(r),np.array(u), np.array(d)\n                        X, y, d, r, u = [], [], [], [], []\n                        if self.train:\n                            yield X_, y_\n                        else:\n                            yield X_, y_, r_, u_, d_\n                            \n    def steps(self):\n        # get number of steps per epoch\n        steps = 0\n        for _, data in self.groupby_obj:\n            num_sequences = data.shape[0] - self.window \n            steps += num_sequences\/\/self.batch_size\n        return steps","6cf92084":"train_df, val_df = split(market_train)","f7671a38":"cols = [col for col in market_train.columns if col not in ['time','assetCode', 'universe', 'label', 'assetName', 'returnsOpenNextMktres10']]\ntrain_gen = SequenceGenerator(train_df, cols, batch_size=64)\ntest_gen = SequenceGenerator(val_df, cols, batch_size=64)\ntrain_steps = train_gen.steps()\ntest_steps = test_gen.steps()","fde093ca":"#test on a fixed validation set\ntest = SequenceGenerator(val_df, cols, batch_size=100000, train=False)\nX_val, y_val, r_val, u_val, d_val =  next(test.generate())","3bae357d":"from keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization, Dropout, LSTM, GRU\nfrom keras.losses import binary_crossentropy, mse\n\n\nmodel = Sequential()\nmodel.add(LSTM(16, input_shape=(10, len(cols)), return_sequences=False))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam',loss=binary_crossentropy, metrics=['accuracy'])","d60a1248":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n\ncheck_point = ModelCheckpoint('model.hdf5',verbose=True, save_best_only=True)\nearly_stop = EarlyStopping(patience=5,verbose=True)\nmodel.fit_generator(train_gen.generate(),\n          validation_data=test_gen.generate(),\n          epochs=1,\n          steps_per_epoch=train_steps, \n          validation_steps=test_steps,\n          callbacks=[early_stop,check_point]) ","85adc526":"# distribution of confidence that will be used as submission\nmodel.load_weights('model.hdf5')\nconfidence_valid = np.array([model.predict(X.reshape(1,10,16))[0][0] for X in X_val]) * 2 - 1\nprint(accuracy_score(confidence_valid>0, r_val>0))\nfig, ax = plt.subplots(1,2, figsize=(10, 5))\nax[0].hist(confidence_valid, bins='auto')\nax[0].set_title(\"Predicted Confidence\")\nax[1].hist(r_val, bins='auto')\nax[1].set_title(\"returnsOpenNextMktres10\")\nplt.show()","b09729a4":"# https:\/\/www.kaggle.com\/davero\/market-data-only-baseline\n# calculation of actual metric that is used to calculate final score\nx_t_i = confidence_valid * r_val * u_val\ndata = {'day' : d_val, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_valid = mean \/ std\nprint(score_valid)","b6f118bb":"# Defining model","8d54162e":"# Data preparation","71070d04":"# Data generator for LSTM model"}}