{"cell_type":{"3c6871cc":"code","867bdfbe":"code","b953ed46":"code","de6aa2fc":"code","c49a1135":"code","698c72d0":"code","bc8b99e1":"code","c41407a4":"code","9dd2064a":"code","01b9297d":"code","c767b68d":"code","a876acc3":"code","e13378c0":"code","007bd39c":"code","53e2028f":"code","4d284482":"code","df1891d9":"code","7c8d30c7":"code","a9069160":"code","aee5232c":"markdown","d5e2f709":"markdown","3851f8e5":"markdown","2d6acbe3":"markdown","2ba3ea3a":"markdown","04c77ecd":"markdown","054b24b9":"markdown","5365b5fb":"markdown","4d198052":"markdown","97ad56f5":"markdown","a84e3981":"markdown"},"source":{"3c6871cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd\nimport librosa\nimport librosa.display\nimport os","867bdfbe":"GENRES = ['classical','hiphop']\nnum_lines = sum(1 for line in open('\/kaggle\/input\/audio-path\/audio_path.txt'))\nnum_lines\n\nrotulos = []\n\nfile = open(\"\/kaggle\/input\/audio-path\/audio_path.txt\", \"r\")\npaths = []\nfor i, line in enumerate(file):\n    \n    for j, genre in enumerate(GENRES):\n        if genre in line:\n            rotulos.append(j)\n            if (i < num_lines -1):\n                paths.append(line[:-1])\n            else:\n               paths.append(line) \n    \npaths = np.asarray(paths)\nrotulos = np.asarray(rotulos)\n\n","b953ed46":"def import_signal(path):\n    s, sr = librosa.core.load(path)\n    # slice em 660000 pois \u00e9 o minimo de todos os audios\n    return s[:660000]\n\n\nsignals = []\n\nfor p in paths:\n    signals.append(import_signal(p))\n\nsignals = np.asarray(signals)\n","de6aa2fc":"# return magnitude S\ndef stft(signal):\n    S, phase = librosa.magphase(np.abs(librosa.stft(signal, hop_length=1024)))\n    return S\n\nsignals_stft = []\nfor s in signals:\n    signals_stft.append(stft(s))\n\nsignals_stft = np.asarray(signals_stft)\nsignals_stft.shape\n\n","c49a1135":"def get_features(signals_stft, rotulos):\n    def get_centroid(S):\n        return librosa.feature.spectral_centroid(S=S)\n    def get_flatness(S):\n        return librosa.feature.spectral_flatness(S=S)\n    def get_rms(s):\n        return librosa.feature.rms(s, hop_length=1024)\n\n    info = {'Centroid Mean':[], \n        'Centroid STD': [], \n        'Flatness Mean':[],\n        'Flatness STD':[],\n        'RMS':[],\n        'Target': []} \n\n    \n    for s, rotulo in zip(signals_stft, rotulos):\n      \n        info['Target'].append(rotulo)\n        \n        '''\n            Obtendo centroide, flatness e RMS\n        '''\n        c = get_centroid(s)\n        c = c[0]\n        info['Centroid Mean'].append(np.mean(c))\n        info['Centroid STD'].append(np.std(c))\n        \n        \n        f = get_flatness(s)\n        f = f[0]\n        info['Flatness Mean'].append(np.mean(f))\n        info['Flatness STD'].append(np.std(f))\n        \n        r = get_rms(s)\n        r = round(r[0][0],3)\n        info['RMS'].append(r)\n        \n        \n        \n    return pd.DataFrame(info)","698c72d0":"df = get_features(signals_stft, rotulos)\ndf","bc8b99e1":"from sklearn.preprocessing import StandardScaler","c41407a4":"scaler = StandardScaler()\n\nX,y = df.iloc[:,0:-1], df['Target'].values\nscaler.fit(X)\nX = scaler.transform(X)","9dd2064a":"# splitting the data into training and test sets (80:20)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(X_train[0])\nprint(y_train[0])\n\n","01b9297d":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics","c767b68d":"#Try running from k=1 through 30 and record testing accuracy\nk_range = range(1,31)\nscores = {}\nscores_list = []\nfor k in k_range:\n        knn = KNeighborsClassifier(n_neighbors = k)\n        knn.fit(X_train,y_train)\n        y_pred = knn.predict(X_test)\n        scores[k] = metrics.accuracy_score(y_test,y_pred)\n        scores_list.append(metrics.accuracy_score(y_test,y_pred))\n\nprint(scores)\n","a876acc3":"def plot_scores(x,y):\n    fig, a = plt.subplots(1, figsize = (10, 8))\n    title = \"Accuracy Score by K values\"\n    plt.title(title)\n    plt.xlabel('Value of K for KNN')\n    plt.ylabel('Testing Accuracy')\n    a.plot(x, y)\n    \nplot_scores(list(k_range), scores_list)","e13378c0":"k = max(scores, key= scores.get)\nprint(k)\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train,y_train)\ny_pred = knn.predict(X_test)\nprint(y_pred)\nmetrics.accuracy_score(y_test,y_pred)","007bd39c":"from sklearn.decomposition import PCA\nimport pylab","53e2028f":"pca1 = PCA(2)\ntrans_pca1 = pca1.fit_transform(X_test)\nprint(pca1.explained_variance_ratio_)\n\npca2 = PCA(2)\npca2.fit(X_train)\ntrans_pca2 = pca2.transform(X_test)\nprint(pca2.explained_variance_ratio_)\n\n\nfor i, _ in enumerate(GENRES):\n    pylab.scatter(trans_pca1[:,0][y_test==i], trans_pca1[:,1][y_test==i],cmap='jet',label=GENRES[i])\npylab.xlabel(\"PC1\")\npylab.ylabel(\"PC2\")\npylab.legend()\npylab.show()\n\nfor i, _ in enumerate(GENRES):\n    pylab.scatter(trans_pca2[:,0][y_test==i], trans_pca2[:,1][y_test==i],cmap='jet',label=GENRES[i])\npylab.xlabel(\"PC1\")\npylab.ylabel(\"PC2\")\npylab.legend()\npylab.show()\n\n\n","4d284482":"pca = PCA(2)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\n\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train,y_train)\ny_pred = knn.predict(X_test)\nprint(y_pred)\nmetrics.accuracy_score(y_test,y_pred)","df1891d9":"import seaborn as sns","7c8d30c7":"trans_pca1 = pd.DataFrame(trans_pca1)\ntrans_pca1['Genres'] = [g for y in y_test for i, g in enumerate(GENRES) if y==i]\ntrans_pca1.columns = ['PC1', 'PC2', 'Genres']\ntrans_pca1.head()\n","a9069160":"sns.scatterplot(x=trans_pca1['PC1'], y=trans_pca1['PC2'], hue=trans_pca1['Genres'])","aee5232c":"# 6.1 Normalizando os dados","d5e2f709":"# 6. Treinando o modelo","3851f8e5":"Dividindo o dataset em dados de treino e teste","2d6acbe3":"# 2. Transformada de Fourier de Curto Termo","2ba3ea3a":"Importando 100 m\u00fasicas de diferentes g\u00eaneros musicais. Dependendo do g\u00eanero musical identificado no diret\u00f3rio, j\u00e1 fazemos o r\u00f3tulo que ser\u00e1 utilizado posteriormente na predi\u00e7\u00e3o.","04c77ecd":"# 4. Features","054b24b9":"E se utilizar o PCA no modelo de predi\u00e7\u00e3o?","5365b5fb":"# 6.2 Escolhendo o n\u00famero k de vizinhos","4d198052":"**hop_length** : int > 0 [scalar] - Usamos 1024\n\n    number of audio samples between adjacent STFT columns.","97ad56f5":"# 6.3 Treinando o modelo com k de maior acur\u00e1cia","a84e3981":"# 1. Importando os Arquivos de \u00c1udio"}}