{"cell_type":{"25004e46":"code","d2a13eef":"code","08089485":"code","42d19271":"code","a861f159":"code","5cb2ac18":"code","bf6d3b49":"code","10cacbea":"code","4ee5885a":"code","bdc3d1e6":"code","90bf467d":"code","6220c2a3":"code","11312893":"code","40b056c0":"code","c295fe0b":"code","cd6099bc":"code","719b2495":"code","0b5cac16":"code","370c8b1c":"code","29a3e2e9":"code","b3510398":"code","dd17b935":"code","bed94e4c":"code","b618fd2e":"markdown","e9037cdb":"markdown","9ed7039a":"markdown","95286edb":"markdown","1d953cd8":"markdown","a5d76c6d":"markdown","f1838ae6":"markdown","c8c203f1":"markdown","1ab087cf":"markdown","45b38d39":"markdown","a3753a14":"markdown","1c2c68c1":"markdown","a4dcfde6":"markdown","bfab8c84":"markdown","9060e0c8":"markdown","68a6495f":"markdown","bdd6fc25":"markdown","18e14ecb":"markdown","81b5300e":"markdown","64c58562":"markdown","7006fb9f":"markdown","cf14b7b1":"markdown","78c75ab6":"markdown","ee573c03":"markdown"},"source":{"25004e46":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d2a13eef":"input_path='\/kaggle\/input\/iris\/Iris.csv'\ndf=pd.read_csv(input_path)\ndf.head()","08089485":"df.drop('Id',axis=1,inplace=True)\ndf.info()","42d19271":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr(),annot=True,cmap=plt.cm.Spectral)","a861f159":"plt.figure(figsize=(10,5))\nsns.countplot(x='Species',data=df)\nplt.grid()","5cb2ac18":"le=LabelEncoder()\ndf['Species_type']=le.fit_transform(df['Species'])","bf6d3b49":"def scatterplot(X,Y):\n    sns.scatterplot(data=df,x=X,y=Y,hue='Species')\n    plt.title(X+\" vs \"+Y)\n    plt.grid()\n    plt.show()","10cacbea":"plt.figure(figsize=(10,6))\nscatterplot('SepalWidthCm','SepalLengthCm')\nplt.figure(figsize=(10,6))\nscatterplot('PetalWidthCm','PetalLengthCm')\nplt.tight_layout()","4ee5885a":"sns.pairplot(df,hue='Species',palette='Dark2')","bdc3d1e6":"df.boxplot(by=\"Species_type\", figsize=(12, 6))","90bf467d":"df.drop('Species_type',axis=1).hist(edgecolor='black', linewidth=1.2)\nfig=plt.gcf()\nfig.set_size_inches(12,6)\nplt.show()","6220c2a3":"X_train,X_test,Y_train,Y_test = train_test_split(df.drop(['Species_type','Species'],axis=1),df['Species_type'],test_size=0.25,random_state=8)","11312893":"plt.figure(figsize=(8,5))\nsns.countplot(x=Y_test)\nplt.title(\"Count of each type in Testing Set\")\nplt.grid()\nplt.figure(figsize=(8,5))\nsns.countplot(x=Y_train)\nplt.title(\"Count of each type in Training Set\")\nplt.grid()","40b056c0":"models = ['random_forest','svm','decision_tree','logistic_regression','knn']\nmodel_train_acc=[]\nmodel_test_acc=[]","c295fe0b":"svm= SVC()\nsvm.fit(X_train,Y_train)\ny_hat_train = svm.predict(X_train)\ny_hat_test = svm.predict(X_test)\ntrain_acc = np.round(accuracy_score(y_hat_train,Y_train),3)\ntest_acc =  np.round(accuracy_score(y_hat_test,Y_test),3)\n\nmodel_train_acc.append(train_acc)\nmodel_test_acc.append(test_acc)\n\nprint(\"Accuracy Score on train data using SVM: \",train_acc)\nprint(\"Accuracy Score on test data using SVM: \",test_acc)","cd6099bc":"rfc = RandomForestClassifier()\nrfc.fit(X_train,Y_train)\ny_hat_train = rfc.predict(X_train)\ny_hat_test = rfc.predict(X_test)\ntrain_acc = np.round(accuracy_score(y_hat_train,Y_train),3)\ntest_acc =  np.round(accuracy_score(y_hat_test,Y_test),3)\n\nmodel_train_acc.append(train_acc)\nmodel_test_acc.append(test_acc)\n\nprint(\"Accuracy Score on train data using Decision tree: \",train_acc)\nprint(\"Accuracy Score on test data using Decision tree: \",test_acc)","719b2495":"tree = DecisionTreeClassifier()\ntree.fit(X_train,Y_train)\ny_hat_train = tree.predict(X_train)\ny_hat_test = tree.predict(X_test)\ntrain_acc = np.round(accuracy_score(y_hat_train,Y_train),3)\ntest_acc =  np.round(accuracy_score(y_hat_test,Y_test),3)\n\nmodel_train_acc.append(train_acc)\nmodel_test_acc.append(test_acc)\n\nprint(\"Accuracy Score on train data using Decision tree: \",train_acc)\nprint(\"Accuracy Score on test data using Decision tree: \",test_acc)","0b5cac16":"lr = LogisticRegression(max_iter=200)\nlr.fit(X_train,Y_train)\ny_hat_train = lr.predict(X_train)\ny_hat_test = lr.predict(X_test)\ntrain_acc = np.round(accuracy_score(y_hat_train,Y_train),3)\ntest_acc =  np.round(accuracy_score(y_hat_test,Y_test),3)\n\nmodel_train_acc.append(train_acc)\nmodel_test_acc.append(test_acc)\n\nprint(\"Accuracy Score on train data using Decision tree: \",train_acc)\nprint(\"Accuracy Score on test data using Decision tree: \",test_acc)","370c8b1c":"def select_neighbors():\n    knn_train_acc=[]\n    knn_test_acc=[]\n    for i in range(1,11):\n        knn = KNeighborsClassifier(n_neighbors=i)\n        knn.fit(X_train,Y_train)\n        y_hat_train = knn.predict(X_train)\n        y_hat_test = knn.predict(X_test)\n        knn_train_acc.append(accuracy_score(y_hat_train,Y_train))\n        knn_test_acc.append(accuracy_score(y_hat_test,Y_test))\n        \n    return knn_train_acc,knn_test_acc","29a3e2e9":"knn_train,knn_test = select_neighbors()\nx = np.linspace(1,10,10)\n\nplt.figure(figsize=(10,4))\nplt.plot(x,knn_test,color='red')\nplt.title(\"Neighbors vs Accuracy on Test Data using KNN\")\nplt.xticks(x)\nplt.grid()\n\nplt.figure(figsize=(10,4))\nplt.plot(x,knn_train,color='red')\nplt.title(\"Neighbors vs Accuracy on Train Data using KNN\")\nplt.xticks(x)\nplt.grid()","b3510398":"train_acc = np.round(knn_train[6],3)\ntest_acc = np.round(knn_test[6],3)\n\nmodel_train_acc.append(train_acc)\nmodel_test_acc.append(test_acc)\n\nprint(\"Accuracy Score on train data using Decision tree: \",train_acc)\nprint(\"Accuracy Score on test data using Decision tree: \",test_acc)","dd17b935":"model_performance = pd.DataFrame({\n    'model':models,\n    'train_acc':model_train_acc,\n    'test_acc':model_test_acc\n})\nmodel_performance","bed94e4c":"plt.figure(figsize=(8,5))\nplt.plot(model_performance['model'],model_performance['train_acc'],label='train_accuracy')\nplt.plot(model_performance['model'],model_performance['test_acc'],label='test_accuracy')\nplt.grid()\nplt.show()","b618fd2e":"# 4.Model Performance\n<a id='performance'><\/a>","e9037cdb":"<h3>C) Analysis of Data using Scatter Plot<\/h3>","9ed7039a":"<h3>C)Data Summary<\/h3>","95286edb":"<h3>D)Pairplot for Data Analysis<\/h3>","1d953cd8":"<a id='techniques'><\/a>\n# 2.Visualization Tehniques","a5d76c6d":"<center><h1 style='color:orange'>Iris Species Prediction<\/h1><\/center>","f1838ae6":"<h3>A)Importing Libraries<\/h3>","c8c203f1":"<h3>B)Loading Data<\/h3>","1ab087cf":"<h3>B) Finding Best Model<\/h3>","45b38d39":"<h3>A)Creating DataFrame for storing results<\/h3>","a3753a14":"<h3>B)Count of Each Species<\/h3>","1c2c68c1":"<h3>A)Train-Test Split<\/h3>","a4dcfde6":"# 3.Model Building\n<a id='model'><\/a>","bfab8c84":"We will choose neighbors as n=6 in KNN algo since it gives highest accuracy on both training and testing data","9060e0c8":"<h3>F)Histogram for Speices Analysis<\/h3>","68a6495f":"<h3>A)Correlation Graph<\/h3>","bdd6fc25":"<a id='library'><\/a>\n# 1.Libraries","18e14ecb":"The Kernel is divided into:<br>\n![](http:\/\/)[1)Importing Libraries](#library)<br>\n[](http:\/\/)[2)Visualization Techniques](#techniques)<br>\n[](http:\/\/)[3)Building Model](#model)<br>\n[](http:\/\/)[4)ModelPerformance](#performance)","81b5300e":"<h3>C)Model Training<\/h3>","64c58562":"<h3><i style='color:blue;font-family:cursive'>It can be seen that K Neighbors Classifier model does best on both training and testing data than any other models with a accuracy of around 97% on both training and testing dataset.<\/i><\/h3>","7006fb9f":"<h3>B)Finding species of each type after data splitting<\/h3>","cf14b7b1":"<h4>The Iris dataset was used in R.A. Fisher's classic 1936 paper which included 50 data of each species.\n<br>\nIn this kernel we will use the dataset to predict the flower in 3 types of species namely:\n<span style='color:red'>Setosa,Versicolor,Virginica<\/span> using- <br><br>\n<span style='color:blue'>1]SepalLengthCm<br>\n2]SepalWidthCm<br>\n3]PetalLengthCm<br>\n4]PetalWidthCm<\/span><br><br>\n\nWe would be using various Machine Learning techniques to predict the Iris Species in the kernel.\n<\/h4>","78c75ab6":"<h3>E)Using Box Plot <\/h3>","ee573c03":"![](https:\/\/www.almanac.com\/sites\/default\/files\/image_nodes\/iris-flowers.jpg)"}}