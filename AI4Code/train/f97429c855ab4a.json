{"cell_type":{"8a6a7065":"code","352d7fd1":"code","35f680a2":"code","97303c21":"code","6b7be8b2":"code","057fbc49":"code","8644465a":"code","c71b97d4":"code","4d2ac67a":"code","2e8d1980":"markdown"},"source":{"8a6a7065":"import pandas as pd\nimport numpy as np\nimport pickle\nimport itertools\nimport gc\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\nfrom datetime import datetime\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nfrom sklearn.preprocessing import StandardScaler, QuantileTransformer, LabelEncoder, minmax_scale\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Dropout, Input, InputLayer, Flatten, LayerNormalization, BatchNormalization","352d7fd1":"def plot_history(history, *, n_epochs=None, plot_lr=False, plot_acc=True, title=None, bottom=None, top=None):\n    \"\"\"Plot (the last unique n_epochs epochs of) the training history\"\"\"\n    plt.figure(figsize=(15, 6))\n    from_epoch = 0 if n_epochs is None else len(history['loss']) - n_epochs\n    \n    # Plot training and validation losses\n    plt.plot(np.arange(from_epoch, len(history['loss'])), history['loss'][from_epoch:], label='Training loss')\n    try:\n        plt.plot(np.arange(from_epoch, len(history['loss'])), history['val_loss'][from_epoch:], label='Validation loss')\n        best_epoch = np.argmin(np.array(history['val_loss']))\n        best_val_loss = history['val_loss'][best_epoch]\n        if best_epoch >= from_epoch:\n            plt.scatter([best_epoch], [best_val_loss], c='r', label=f'Best val_loss = {best_val_loss:.5f}')\n        if best_epoch > 0:\n            almost_epoch = np.argmin(np.array(history['val_loss'])[:best_epoch])\n            almost_val_loss = history['val_loss'][almost_epoch]\n            if almost_epoch >= from_epoch:\n                plt.scatter([almost_epoch], [almost_val_loss], c='orange', label='Second best val_loss')\n    except KeyError:\n        pass\n    if bottom is not None: plt.ylim(bottom=bottom)\n    if top is not None: plt.ylim(top=top)\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='lower left')\n    if title is not None: plt.title(title)\n        \n    # Plot validation metrics\n    if plot_acc:\n        best_epoch = np.argmax(np.array(history['val_acc']))\n        best_val_acc = history['val_acc'][best_epoch]\n        ax2 = plt.gca().twinx()\n        ax2.plot(np.arange(from_epoch, len(history['loss'])), np.array(history['val_acc'][from_epoch:]), color='r', label='Validation accuracy')\n        if best_epoch >= from_epoch:\n            plt.scatter([best_epoch], [best_val_acc], c='r', label=f'Best val_acc = {best_val_acc:.5f}')\n        ax2.set_ylabel('Accuracy')\n        ax2.legend(loc='center right')\n        \n    # Plot learning rate\n    if plot_lr:\n        ax2 = plt.gca().twinx()\n        ax2.plot(np.arange(from_epoch, len(history['loss'])), np.array(history['lr'][from_epoch:]), color='g', label='Learning rate')\n        ax2.set_ylabel('Learning rate')\n        ax2.legend(loc='upper right')\n        \n    plt.show()","35f680a2":"# Show the confusion matrix\n    def plot_confusion_matrix(cm, classes, cm_type='recall'):\n        if cm_type == 'recall':\n            cm = cm \/ cm.sum(axis=1).reshape(-1, 1)\n            colors = cm\n            cell_format = '.0%'\n            plt.title('Confusion matrix (sum of every row is 100 %, diagonal shows recall)', fontweight='bold', pad=15)\n        elif cm_type == 'precision':\n            cm = cm \/ cm.sum(axis=0).reshape(1, -1)\n            colors = cm\n            cell_format = '.0%'\n            plt.title('Confusion matrix (sum of every column is 100 %, diagonal shows precision)', fontweight='bold', pad=15)\n        elif cm_type == 'accuracy':\n            cm = cm \/ cm.sum()\n            colors = minmax_scale(cm.reshape(-1, 1)).reshape(cm.shape[0], cm.shape[1]) ** 0.3 # make the low-to-medium cells darker\n            cell_format = '.2%'\n            plt.title('Confusion matrix (sum of matrix is 100 %, sum of diagonal shows accuracy)', fontweight='bold', pad=15)\n        elif cm_type == 'count':\n            colors = minmax_scale(cm.reshape(-1, 1)).reshape(cm.shape[0], cm.shape[1]) ** 0.3 # make the low-to-medium cells darker\n            cell_format = 'd'\n            plt.title('Confusion matrix (sample counts)', fontweight='bold', pad=15)\n        else: raise ValueError(f'Illegal value for parameter cm_type: {cm_type}')\n        plt.imshow(colors, interpolation='nearest', cmap=plt.cm.Blues) # or cmap='hot'\n        #plt.colorbar()\n        tick_marks = np.arange(len(classes))\n        plt.xticks(tick_marks, classes, rotation=0)\n        plt.yticks(tick_marks, classes)\n\n        thresh = colors.max() \/ 2.\n        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n            value = cm[i, j]\n            plt.text(j, i, format(value, cell_format),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if colors[i, j] > thresh else \"black\")\n\n        plt.ylabel('True label', fontweight='bold')\n        plt.xlabel('Predicted label', fontweight='bold')\n        plt.tight_layout()","97303c21":"train_df = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/test.csv')\n","6b7be8b2":"features = [f for f in test_df.columns if f != 'Id' and f != 'Cover_Type']\n\n# Show  class distribution\nprint(\"\u0421lass distribution:\")\n\ntrain_df.groupby('Cover_Type').Id.nunique()","057fbc49":"le = LabelEncoder()\ntarget = le.fit_transform(train_df.Cover_Type)","8644465a":"EPOCHS = 20\nVERBOSE = 0 # set to 0 for less output, or to 2 for more output\nBATCH_SIZE = 1024\nFOLDS = 2 \n\ndef my_model(X):\n    model = Sequential()\n    model.add(InputLayer(input_shape=(X.shape[-1]))) # input layer with X size shape\n\n    # Add the hidden layers\n    # Dense, BatchNorm pare added per layer\n    for size in [128, 64, 64]:\n        model.add(Dense(size, activation='selu'))\n        model.add(BatchNormalization())\n        #model.add(Dropout(rate=0.1)) \n\n    model.add(Dense(len(le.classes_), activation='softmax'))\n    \n    model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['acc'])\n    return model\n\n# Make the results reproducible\nnp.random.seed(2021)\ntf.random.set_seed(2021)\n\ntotal_start_time = datetime.now()\nscore_list, test_pred_list, history_list = [], [], []\noof_list = [np.full((len(train_df), len(le.classes_)), -1.0, dtype='float32') for run in range(RUNS)]\n\nkf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=1)\nfor fold, (train_idx, val_idx) in enumerate(kf.split(train_df, y=train_df.Cover_Type)):\n    print(f\"Fold {run}.{fold}\")\n    start_time = datetime.now()\n    X_tr = train_df.iloc[train_idx]\n    X_va = train_df.iloc[val_idx]\n    y_tr = target[train_idx]\n    y_va = target[val_idx]\n    X_tr = X_tr[features]\n    X_va = X_va[features]\n\n    # Train\n    preproc = StandardScaler() \n    X_tr = preproc.fit_transform(X_tr)\n    X_va = preproc.transform(X_va)\n    model = my_model(X_tr)\n\n    # Train and save the model\n    history = model.fit(X_tr, y_tr, \n                        validation_data=(X_va, y_va), \n                        epochs=EPOCHS,\n                        verbose=VERBOSE,\n                        batch_size=BATCH_SIZE, \n                        validation_batch_size=len(X_va),\n                        shuffle=True)\n    history_list.append(history.history)\n    model.save(f\"model{run}.{fold}\")\n\n    # Inference for validation after last epoch of fold\n    y_va_pred = model.predict(X_va, batch_size=len(X_va))\n    oof_list[run][val_idx] = y_va_pred\n    y_va_pred = np.argmax(y_va_pred, axis=1)\n\n    # Evaluation\n    accuracy = accuracy_score(y_va, y_va_pred)\n    score_list.append((accuracy, datetime.now() - start_time))\n    print(f\"Fold {run}.{fold} | {str(datetime.now() - start_time)[-12:-7]} | Epochs: {len(history_list[-1]['loss'])} | Accuracy: {accuracy:.5f}\")\n    \n    plot_history(history_list[-1], title=f\"Accuracy: {accuracy:.5f}\")\n\n    # Inference for test: keep the predicted probabilities\n    test_pred_list.append(model.predict(preproc.transform(test_df[features]), batch_size=BATCH_SIZE))\n\n    # Clean up the memory (it seems that Keras doesn't clean up everything at keyboard interrupts)\n    del model, y_va_pred\n    gc.collect()\n        \n\n# Save all oof and test predictions to later determine ensemble weights\nwith open('oof_list.pickle', 'wb') as handle: pickle.dump(oof_list, handle)\nwith open('test_pred_list.pickle', 'wb') as handle: pickle.dump(test_pred_list, handle)\n    \ntotal_time = datetime.now() - total_start_time","c71b97d4":"if oof_list[0].min() >= 0: \n    \n    # Evaluate the overall cv score\n    print(f\"Single-model Accuracy: {sum([accuracy_score(train_df.Cover_Type, le.inverse_transform(np.argmax(oof, axis=1))) for oof in oof_list]) \/ len(oof_list):.5f}\")\n\n    # Evaluate the number of epochs and the time taken\n    print(f\"Average epochs: {sum([len(h['loss']) for h in history_list]) \/ len(history_list):.0f}\")\n    print(f\"Maximum epochs: {max([len(h['loss']) for h in history_list]) \/ len(history_list):.0f}\")\n    print(f\"Stopped early in {sum([len(h['loss']) < EPOCHS for h in history_list]) \/ len(history_list):.0%} of runs\")\n    print(f\"Total elapsed time: {str(total_time)[-14:-7]} for {len(history_list)} trainings\") \n    print()\n\n    \n    # Print the classification report\n    print(classification_report(train_df.Cover_Type, le.inverse_transform(np.argmax(oof_list[0], axis=1))))","4d2ac67a":"# Create the submission file\nsub = test_df[['Id']].copy()\nsub['Cover_Type'] = le.inverse_transform(np.argmax(sum(test_pred_list), axis=1)) # soft voting by adding the probabilities of all models in the ensemble\nsub.to_csv('submission.csv', index=False)\n\nsub.head()","2e8d1980":"https:\/\/www.kaggle.com\/ambrosm\/tpsdec21-01-keras-quickstart - base code"}}