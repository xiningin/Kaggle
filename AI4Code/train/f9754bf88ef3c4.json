{"cell_type":{"e6e71479":"code","c442be8d":"code","da2cbfe3":"code","9864a8d6":"code","13b35bd1":"code","1441018b":"code","84a7f49e":"code","cc9388ec":"code","4accd61c":"code","375357cb":"code","a85ed339":"code","2a1e773c":"code","a3bdc639":"code","2aaeb71a":"code","d4c643fb":"code","b5253289":"code","996a0b8a":"code","748fa000":"code","6f70f49e":"code","fbb18fc5":"code","ca3f40e9":"code","fa1e589a":"code","4dd28ef8":"code","0ee6f2c8":"code","88891661":"code","16e69bb9":"code","f9f5a6ad":"code","b7d54725":"code","bde20dda":"code","3797e779":"code","12252da4":"code","24cd7087":"code","5d0e7ccc":"code","dfb9829c":"code","7ffccd0a":"code","d7a1b032":"code","32f487de":"code","c7472663":"code","1f5871c3":"code","edc762fe":"code","946402b4":"code","4d221be1":"code","ab739134":"code","eb71e016":"code","4bcdeb99":"code","76dd72e2":"code","eb8a80bf":"code","7a26d399":"markdown","22d8c0ba":"markdown","3e0c0a13":"markdown","d7987338":"markdown","fa996a51":"markdown","0ee68d87":"markdown","48a15cf2":"markdown","c127311a":"markdown","0f0c9982":"markdown","f323043c":"markdown","2a651515":"markdown","1a619945":"markdown","fd80b4bf":"markdown","4931d293":"markdown","196f8974":"markdown","a6d6ac62":"markdown","b7f3c076":"markdown","b756509b":"markdown","e7069b53":"markdown","1a38b5cf":"markdown","e554391e":"markdown"},"source":{"e6e71479":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.preprocessing import StandardScaler\nimport scipy.sparse as sparse\nfrom scipy.sparse import hstack, csr_matrix\n\nimport warnings\nwarnings.simplefilter(action='ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c442be8d":"train_data = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip')\ntest_data = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip')","da2cbfe3":"# we have six types of labels: toxic, severe_toxic, obscene, threat, insult, identity_hate\n\ntrain_data.head()","9864a8d6":"test_data.head()","13b35bd1":"print(train_data.shape, test_data.shape)","1441018b":"# take only comments from test and train sets\n\ntrain_text = train_data['comment_text']\ntest_text = test_data['comment_text']\n\ntexts_data = pd.concat([train_text, test_text]).to_frame()\ntexts_data.head()","84a7f49e":"train_data['total_length'] = train_data['comment_text'].apply(len)\ntrain_data['uppercase'] = train_data['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\ntrain_data['exclamation_punctuation'] = train_data['comment_text'].apply(lambda comment: comment.count('!'))\ntrain_data['num_punctuation'] = train_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:?'))\ntrain_data['num_symbols'] = train_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\ntrain_data['num_words'] = train_data['comment_text'].apply(lambda comment: len(comment.split()))\ntrain_data['num_happy_smilies'] = train_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\ntrain_data['num_sad_smilies'] = train_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-(', ':(', ';-(', ';(')))","cc9388ec":"test_data['total_length'] = test_data['comment_text'].apply(len)\ntest_data['uppercase'] = test_data['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\ntest_data['exclamation_punctuation'] = test_data['comment_text'].apply(lambda comment: comment.count('!'))\ntest_data['num_punctuation'] = test_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:?'))\ntest_data['num_symbols'] = test_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\ntest_data['num_words'] = test_data['comment_text'].apply(lambda comment: len(comment.split()))\ntest_data['num_happy_smilies'] = test_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\ntest_data['num_sad_smilies'] = test_data['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-(', ':(', ';-(', ';(')))","4accd61c":"train_data.head()","375357cb":"# Spearman correlation. \n\ncorr = train_data.corr(method='spearman')\nf, ax = plt.subplots(figsize=(20, 10))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, annot = True)","a85ed339":"# let's drop one of the features which have a high correlation with another feature\n# in our case, num_words have a very high correlation with the total length\n\ntrain_data = train_data.drop(['num_words'], axis = 1)","2a1e773c":"# Spearman correlation. \n\ncorr = train_data.corr(method='spearman')\nf, ax = plt.subplots(figsize=(20, 10))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, annot = True)","a3bdc639":"train_features_data = train_data\ntrain_features_data.head()","2aaeb71a":"train_features_data['toxic_type'] = ''\ntrain_features_data['toxic_type'].loc[train_features_data['toxic'] == 1] += 'toxic '\ntrain_features_data['toxic_type'].loc[train_features_data['severe_toxic'] == 1] += 'severe_toxic '\ntrain_features_data['toxic_type'].loc[train_features_data['obscene'] == 1] += 'obscene '\ntrain_features_data['toxic_type'].loc[train_features_data['threat'] == 1] += 'threat '\ntrain_features_data['toxic_type'].loc[train_features_data['insult'] == 1] += 'insult '\ntrain_features_data['toxic_type'].loc[train_features_data['identity_hate'] == 1] += 'identity_hate '","d4c643fb":"table_top = train_features_data['toxic_type'].value_counts().to_frame()[:10].style.background_gradient(cmap=cmap)\ntable_top","b5253289":"train_features_data.head()","996a0b8a":"df_toxic = train_features_data.loc[train_features_data['toxic'] == 1]\ndf_severe_toxic = train_features_data.loc[train_features_data['severe_toxic'] == 1]\ndf_obscene = train_features_data.loc[train_features_data['obscene'] == 1]\ndf_threat = train_features_data.loc[train_features_data['threat'] == 1]\ndf_insult = train_features_data.loc[train_features_data['insult'] == 1]\ndf_identity_hate = train_features_data.loc[train_features_data['identity_hate'] == 1]\ndf_normal = train_features_data.loc[train_features_data['toxic_type'] == '']","748fa000":"import plotly.graph_objects as go\n\nfig = go.Figure()\n\nfig.add_trace(go.Histogram(x=df_toxic.total_length, name='toxic'))\nfig.add_trace(go.Histogram(x=df_severe_toxic.total_length, name='severe_toxic'))\nfig.add_trace(go.Histogram(x=df_obscene.total_length, name='obscene'))\nfig.add_trace(go.Histogram(x=df_threat.total_length, name='threat'))\nfig.add_trace(go.Histogram(x=df_insult.total_length, name='insult'))\nfig.add_trace(go.Histogram(x=df_identity_hate.total_length, name='identity hate'))\nfig.add_trace(go.Histogram(x=df_normal.total_length, name='normal'))\n\n# Overlay both histograms\nfig.update_layout(barmode='overlay')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.5)\nfig.show()","6f70f49e":"train_features_data['list_toxic_type'] = train_features_data['toxic_type'].apply(lambda row: row.split(' '))\ntrain_features_data['list_toxic_type'] =train_features_data['list_toxic_type'].apply(lambda row: len(row)-1)\ntable_types = train_features_data['list_toxic_type'].value_counts().to_frame().style.background_gradient(cmap=cmap)\ntable_types","fbb18fc5":"train_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==0] = 'normal comment'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==1] = 'has one type of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==2] = 'has two types of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==3] = 'has three types of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==4] = 'has four types of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==5] = 'has five types of toxic'\ntrain_features_data['list_toxic_type'].loc[train_features_data['list_toxic_type']==6] = 'has six types of toxic'","ca3f40e9":"types = ['normal comment', 'has one type of toxic', 'has two types of toxic', 'has three types of toxic',\n         'has four types of toxic', 'has five types of toxic', 'has six types of toxic']\n\ncolumns = ['total_length', 'uppercase', 'exclamation_punctuation',\n                                'num_punctuation', 'num_symbols', 'num_happy_smilies', 'num_sad_smilies']\n\ndf_mean = pd.DataFrame(columns=columns)","fa1e589a":"for i, toxic_type in enumerate(types):\n    for col in columns:    \n        df_mean.at[i, col] = train_features_data[col].loc[train_features_data['list_toxic_type'] == toxic_type].mean()","4dd28ef8":"df_mean['toxic_types'] = types ","0ee6f2c8":" df_mean","88891661":"df_mean['total_length'] = pd.to_numeric(df_mean['total_length'])\ndf_mean['uppercase'] = pd.to_numeric(df_mean['uppercase'])\ndf_mean['exclamation_punctuation'] = pd.to_numeric(df_mean['exclamation_punctuation'])\ndf_mean['num_punctuation'] = pd.to_numeric(df_mean['num_punctuation'])\ndf_mean['num_symbols'] = pd.to_numeric(df_mean['num_symbols'])\ndf_mean['num_happy_smilies'] = pd.to_numeric(df_mean['num_happy_smilies'])\ndf_mean['num_sad_smilies'] = pd.to_numeric(df_mean['num_sad_smilies'])","16e69bb9":"import plotly.express as px\n\n\npx.scatter(df_mean, x=\"exclamation_punctuation\", y=\"num_punctuation\",\n           size=\"total_length\", color=\"toxic_types\", hover_name=\"toxic_types\",\n           size_max=55)","f9f5a6ad":"types = ['toxic', 'severe_toxic', 'obscene', 'threat',\n         'insult', 'identity_hate']\n\ndf_types_mean = pd.DataFrame(columns=columns)","b7d54725":"for i, toxic_type in enumerate(types):\n    for col in columns:    \n        df_types_mean.at[i, col] = train_features_data[col].loc[train_features_data[toxic_type] == 1].mean()","bde20dda":"for col in columns:    \n        df_types_mean.at[6, col] = train_features_data[col].loc[train_features_data['toxic'] == 0] \\\n                                                        .loc[train_features_data['severe_toxic'] == 0] \\\n                                                        .loc[train_features_data['obscene'] == 0] \\\n                                                        .loc[train_features_data['threat'] == 0] \\\n                                                        .loc[train_features_data['insult'] == 0] \\\n                                                        .loc[train_features_data['identity_hate'] == 0] \\\n                                                        .mean()","3797e779":"df_types_mean","12252da4":"types.append('normal comment')\n\ndf_types_mean['type'] = types\ndf_types_mean","24cd7087":"df_types_mean['total_length'] = pd.to_numeric(df_types_mean['total_length'])\ndf_types_mean['uppercase'] = pd.to_numeric(df_types_mean['uppercase'])\ndf_types_mean['exclamation_punctuation'] = pd.to_numeric(df_types_mean['exclamation_punctuation'])\ndf_types_mean['num_punctuation'] = pd.to_numeric(df_types_mean['num_punctuation'])\ndf_types_mean['num_symbols'] = pd.to_numeric(df_types_mean['num_symbols'])\ndf_types_mean['num_happy_smilies'] = pd.to_numeric(df_types_mean['num_happy_smilies'])\ndf_types_mean['num_sad_smilies'] = pd.to_numeric(df_types_mean['num_sad_smilies'])","5d0e7ccc":"px.scatter(df_types_mean, x=\"exclamation_punctuation\", y=\"num_punctuation\",\n           size=\"total_length\", color=\"type\", hover_name=\"type\",\n           size_max=55)","dfb9829c":"fig = px.scatter_3d(df_types_mean, x='exclamation_punctuation', y='num_punctuation', z='uppercase', size='total_length', color='type',\n                    hover_data=['type'])\nfig.update_layout(scene_zaxis_type=\"log\")\nfig.show()","7ffccd0a":"px.scatter(df_types_mean, x=\"uppercase\", y=\"num_punctuation\",\n           size=\"total_length\", color=\"type\", hover_name=\"type\",\n           size_max=55)","d7a1b032":"px.scatter(df_types_mean, x=\"uppercase\", y=\"num_symbols\",\n           size=\"total_length\", color=\"type\", hover_name=\"type\",\n           size_max=55)","32f487de":"px.scatter(df_types_mean, x=\"uppercase\", y=\"exclamation_punctuation\",\n           size=\"total_length\", color=\"type\", hover_name=\"type\",\n           size_max=55)","c7472663":"tvec = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 1),\n    max_features=10000\n)\n\ntvec.fit(train_data['comment_text'])\n\ntrain_texts = tvec.transform(train_data['comment_text'])\ntest_texts = tvec.transform(test_data['comment_text'])","1f5871c3":"# If we want to work with frames from pandas for algorithms in Scikit-Learn, we could use a special module for that - Sklearn-pandas\n# This module provides a bridge between Scikit-Learn's machine learning methods and pandas-style Data Frames.\n\nmapper = DataFrameMapper([\n      (['uppercase'], StandardScaler()),\n      (['exclamation_punctuation'], StandardScaler()),\n      (['num_punctuation'], StandardScaler()),\n      (['num_symbols'], StandardScaler()),\n      (['num_happy_smilies'],StandardScaler()),\n      (['num_sad_smilies'],StandardScaler()),\n      (['total_length'],StandardScaler())\n], df_out=True)","edc762fe":"numeric_features_train = train_data.iloc[:, 8:15]\nnumeric_features_train.head()","946402b4":"x_train = np.round(mapper.fit_transform(numeric_features_train.copy()), 2).values\nx_train","4d221be1":"x_train_features = sparse.hstack((csr_matrix(x_train), train_texts))","ab739134":"numeric_features_test = test_data.iloc[:, 1:]\nnumeric_features_test.head()","eb71e016":"x_test = np.round(mapper.fit_transform(numeric_features_test.copy()), 2).values\nx_test","4bcdeb99":"x_test_features = sparse.hstack((csr_matrix(x_test), test_texts))","76dd72e2":"train_features = x_train_features\ntest_features  = x_test_features","eb8a80bf":"scores = []\nclass_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\nfor class_name in class_names:\n  train_target = train_data[class_name]\n  classifier = LogisticRegression(C=0.1, solver='sag')\n  cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n  scores.append(cv_score)\n  print('CV score for class {} is {}'.format(class_name, cv_score))\n\n  classifier.fit(train_features, train_target)\n\nprint('Total CV score is {}'.format(np.mean(scores)))","7a26d399":"The fisrt value is ''. It means, we have a lot of comment without any toxic.","22d8c0ba":"## Generate numeric and text testing features","3e0c0a13":"Scikit-Learn's cross_val_score now could work with DataFrameMapper.\n\nAnd  we can estimate with cross_val_score our solution quality:","d7987338":"## DataFrameMapper for joining numerical and text features:","fa996a51":"Let`s try to create some features and explore how they useful are:\n\n* comment length - angry comments may be short, I mean, that the more aggressive the comment, the shorter it is;\n* uppercase - angry comments usually have a lot of uppercase letters;\n* emoji - angry users maybe not use a happy emoji (and emoji in general), also we could have a situation, in which emoji means sarcasm;\n* punctuation - angry persons usually do not use , . : ? and etc, they maybe use a lot of \"!\" ;\n* number of symbols - people usually encoded bad words with special symbols '@', '$' and etc;\n* specific words for each category - with term frequency we can find the most common words in the category.","0ee68d87":"> ## Explore each type of toxic comments:","48a15cf2":"### Explore each toxic type:","c127311a":"## Logistic regression, cross_val_score:","0f0c9982":"### Explore how much types has each comment:\n\n- how much types has each comments;\n- visualization means for that;\n","f323043c":"## Generate numeric and text training features","2a651515":"## TF-IDF for comments (text data):","1a619945":"- in each case we can see that severe toxic is far from other types;\n- toxic, insult, obscene always are very close;\n- normal comments always at the origin of coordinates;","fd80b4bf":"### Explore length of comments:","4931d293":"**It`s not final version.**\n","196f8974":"Well, assumption about length is true. Non-toxic comments have a higher length.","a6d6ac62":"# EDA and Feature engineering:\n","b7f3c076":"- the comments with four toxic types are far from others;\n- the comments with six toxic types have a lot of punctuation and an average number of exclamation punctuation;\n- the normal types of comments have an average number of  punctuation and a low number of exclamation punctuation.","b756509b":"# Read the data:","e7069b53":"### plans to carry out text processing and build word clouds for each text in train and test data.","1a38b5cf":"# Logistic regression with TF-IDF and numeric features:","e554391e":"- we can see four \"clusters\": 1 - threat, severe toxic, 2 -  normal comments, 3 - toxic, obscene, insult, identity hate."}}