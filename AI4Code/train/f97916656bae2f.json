{"cell_type":{"5827f1bc":"code","dce82fdc":"code","552e4c21":"code","07e2101b":"code","0cd7f251":"code","765b258e":"code","c591d47a":"code","5afb4aa9":"code","9fb6998e":"code","ac19b7d4":"code","73c537c7":"code","7e855e83":"markdown","ed1e5971":"markdown","7e13188e":"markdown","5960d19e":"markdown","99b4f89a":"markdown","e6c402d7":"markdown","ddc02609":"markdown","1b8dcde1":"markdown","2ea38fb9":"markdown"},"source":{"5827f1bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dce82fdc":"iris_data = pd.read_csv('..\/input\/iris\/Iris.csv')\niris_data.head()","552e4c21":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(iris_data[\"Species\"])\niris_data[\"Species\"] = le.transform(iris_data[\"Species\"])\n\niris_label = iris_data[\"Species\"] # save labels for visualize\n\ndel iris_data[\"Id\"]\ndel iris_data[\"Species\"]\n\niris_data.head()","07e2101b":"def visualize_plots(iris_data, ax1_name, ax2_name, kmeans = None, is_ax1_kmeans = False, is_ax2_kmeans = False) :\n    \n    fig, (ax1, ax2) = plt.subplots(figsize = (9, 5), ncols = 2)\n\n    for i, marker in enumerate(['s', 'o', '^']) :\n        x_axis_data = iris_data[iris_data['cluster'] == i]['SepalLengthCm']\n        y_axis_data = iris_data[iris_data['cluster'] == i]['SepalWidthCm']\n        ax1.scatter(x_axis_data, y_axis_data, marker=marker)\n\n        x_axis_data = iris_data[iris_data['target'] == i]['SepalLengthCm']\n        y_axis_data = iris_data[iris_data['target'] == i]['SepalWidthCm']\n        ax2.scatter(x_axis_data, y_axis_data, marker=marker)\n    \n    if is_ax1_kmeans : ax1.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], marker=\"*\") #visualize center points of clusters\n    elif is_ax2_kmeans : ax2.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], marker=\"*\") #visualize center points of clusters\n        \n    ax1.set_title(ax1_name)\n    ax2.set_title(ax2_name)\n    \n    plt.show()","0cd7f251":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.pyplot as plt\n\n\ncluster_nums = [2, 3, 4, 5]\nnums_cnt = len(cluster_nums)\n\nfig, ax = plt.subplots(figsize = (16, 4), nrows = 1, ncols = nums_cnt)\nfor i, cluster_num in enumerate(cluster_nums) :\n    cluster = KMeans(n_clusters = cluster_num, max_iter = 100, random_state = 0)\n    predict = cluster.fit_predict(iris_data)\n    \n    sil_avg = silhouette_score(iris_data, predict)\n    sil_val = silhouette_samples(iris_data, predict)\n    \n    y_lower = 10\n    ax[i].set_title('Clusters : {0}\\nSilhoutteScore : {1:.4f}'.format(cluster_num, sil_avg))\n    ax[i].set_xlabel('Silhouette coefficient values')\n    ax[i].set_ylabel('Cluster')\n    \n    for j in range(cluster_num) :\n        cluster_val = sil_val[predict == j]\n        cluster_val.sort()\n        y_upper = y_lower + cluster_val.shape[0]\n        \n        ax[i].fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_val, alpha = 0.7)\n        ax[i].text(-0.05, y_lower + 0.5 * cluster_val.shape[0], str(j))\n        y_lower = y_upper + 10\n    \n    ax[i].axvline(x = sil_avg, color = \"red\", linestyle = \"--\")","765b258e":"from sklearn.cluster import KMeans\n\niris_kmeans = iris_data.copy()\n\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 100, random_state = 0)\nkmeans.fit(iris_kmeans)\n\niris_kmeans[\"target\"] = iris_label\niris_kmeans[\"cluster\"] = kmeans.labels_\n\nvisualize_plots(iris_kmeans, ax1_name = 'k-means', ax2_name = 'original', kmeans = kmeans, is_ax1_kmeans = True)","c591d47a":"from sklearn.decomposition import PCA\n\niris_pca = iris_data.copy()\n\npca = PCA(n_components=2) # For visualize in 2D shape\npca_predict = pca.fit_transform(iris_pca)\n\niris_pca = pd.DataFrame(pca_predict, columns=['pca_x', 'pca_y'])\niris_pca['target'] = iris_label\n\nfig, (ax1, ax2) = plt.subplots(figsize = (9, 5), ncols = 2)\n\nfor i, marker in enumerate(['s', 'o', '^']) :\n    mark = iris_pca[iris_pca['target'] == i].index\n    ax1.scatter(x = iris_pca.loc[mark, 'pca_x'], y = iris_pca.loc[mark, 'pca_y'], marker = marker)\n\n    x_axis_data = iris_kmeans[iris_kmeans['cluster'] == i]['SepalLengthCm']\n    y_axis_data = iris_kmeans[iris_kmeans['cluster'] == i]['SepalWidthCm']\n    ax2.scatter(x_axis_data, y_axis_data, marker=marker)\n    \nax2.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], marker=\"*\") #visualize center points of clusters\nax1.set_title('2 PCA Components clustering')\nax2.set_title('K-Means')","5afb4aa9":"from sklearn.cluster import MeanShift, estimate_bandwidth\nfrom scipy import stats\n\niris_ms = iris_data.copy()\n\n#\ucd5c\uc801\uc758 \ub300\uc5ed\ud3ed \uacc4\uc0b0 : estimate the best bandwidth\nbandwidth = estimate_bandwidth(iris_ms)\nmeanshift = MeanShift(bandwidth = bandwidth)\nlabels = meanshift.fit_predict(iris_ms)\n\niris_ms['target'] = iris_label\niris_ms['cluster'] =  labels\n\nvisualize_plots(iris_ms, ax1_name = 'mean-shift', ax2_name = 'original')","9fb6998e":"from sklearn.mixture import GaussianMixture\n\niris_gmm = iris_data.copy()\n\ngmm = GaussianMixture(n_components=3, random_state = 0).fit(iris_gmm)\ngmm_cluster = gmm.predict(iris_gmm)\n\niris_gmm['cluster'] = gmm_cluster\niris_gmm['target'] = iris_label\n\n\nvisualize_plots(iris_gmm, ax1_name = 'gmm', ax2_name = 'original')","ac19b7d4":"from sklearn.cluster import DBSCAN\n\niris_dbs = iris_data.copy()\n\ndbscan = DBSCAN(eps=0.6, min_samples = 8, metric='euclidean')\ndbscan_cluster = dbscan.fit_predict(iris_data)\n\niris_dbs['cluster'] = dbscan_cluster\niris_dbs['target'] = iris_label\n\n\nvisualize_plots(iris_dbs, ax1_name = 'DBSCAN', ax2_name = 'original')","73c537c7":"def visualize_cluster_plot(clusterobj, dataframe, label_name, iscenter=True):\n    if iscenter :\n        centers = clusterobj.cluster_centers_\n\n    unique_labels = np.unique(dataframe[label_name].values)\n    markers=['o', 's', '^', 'x', '*']\n    isNoise=False\n\n    for label in unique_labels:\n        label_cluster = dataframe[dataframe[label_name]==label]\n        if label == -1:\n            cluster_legend = 'Noise'\n            isNoise=True\n        else :\n            cluster_legend = 'Cluster '+str(label)\n\n        plt.scatter(x=label_cluster['pca1'], y=label_cluster['pca2'], s=70, edgecolor='k', marker=markers[label], label=cluster_legend)\n\n        if iscenter:\n            center_x_y = centers[label]\n            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=250, color='white',\n                        alpha=0.9, edgecolor='k', marker=markers[label])\n            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k',\\\n                        edgecolor='k', marker='$%d$' % label)\n    if isNoise: legend_loc='upper center'\n    else: legend_loc='upper right'\n\n    plt.legend(loc=legend_loc)\n    plt.show()\n    \n\npca = PCA(n_components=2, random_state = 0)\npca_transformed = pca.fit_transform(iris_data)\n\niris_dbs['pca1'] = pca_transformed[:,0]\niris_dbs['pca2'] = pca_transformed[:,1]\n\nvisualize_cluster_plot(dbscan, iris_dbs, 'cluster',iscenter=False)\n\n\n# eps\uac00 \uc904\uc5b4\ub4e4\uac70\ub098, min_samples\uac00 \ub298\uc5b4\ub098\uba74 \ub178\uc774\uc988 \uc99d\uac00\n# Reducing eps or increasing min_samples increases noise\ndbscan = DBSCAN(eps=0.4, min_samples = 8, metric='euclidean')\ndbscan_labels = dbscan.fit_predict(iris_data)\n\niris_dbs = iris_data.copy()\niris_dbs['cluster'] = dbscan_labels\niris_dbs['target'] = iris_label\n\niris_dbs['pca1'] = pca_transformed[:,0]\niris_dbs['pca2'] = pca_transformed[:,1]\n\nvisualize_cluster_plot(dbscan, iris_dbs, 'cluster',iscenter=False)\n\n\n# eps\uac00 \ub298\uc5b4\ub098\uac70\ub098, min_samples\uac00 \uc904\uc5b4\ub4e4\uba74 \ub178\uc774\uc988 \uac10\uc18c\n# Increasing eps or reducing min_samples decreases noise\ndbscan = DBSCAN(eps=0.6, min_samples = 12, metric='euclidean')\ndbscan_labels = dbscan.fit_predict(iris_data)\n\niris_dbs = iris_data.copy()\niris_dbs['cluster'] = dbscan_labels\niris_dbs['target'] = iris_label\n\niris_dbs['pca1'] = pca_transformed[:,0]\niris_dbs['pca2'] = pca_transformed[:,1]\n\nvisualize_cluster_plot(dbscan, iris_dbs, 'cluster',iscenter=False)","7e855e83":"##### \uc2e4\ub8e8\uc5e3 \uacc4\uc218\ub97c \ud1b5\ud574 \uba87 \uac1c\uc758 \ub370\uc774\ud130 \uc14b\uc73c\ub85c \uad70\uc9d1\ud654\ud574\uc57c \uc88b\uc740\uc9c0 \ud30c\uc545 \uac00\ub2a5.\n\n##### Determine how many datasets I need to cluster together by using Silhouette Score.\n","ed1e5971":"# DBSCAN (\ubc00\ub3c4 \uae30\ubc18 \uad70\uc9d1\ud654, Density Based Spatial Clustering of Applications with Noise)","7e13188e":"# GMM (\uac00\uc6b0\uc2dc\uc548 \ud63c\ud569 \ubaa8\ub378, Gaussian Mixture Model)","5960d19e":"##### DBSCAN\uc740 \uad70\uc9d1 \uc218\ub97c \uc790\ub3d9\uc73c\ub85c \uc815\ud558\uae30\uc5d0, \ub178\uc774\uc988\ub97c \ub9ce\uc774 \ub9cc\ub4e4 \uc218 \uc788\uc74c.\n##### DBSCAN automatically determines the number of clusters, which can make a lot of noise.\n##### \n##### PCA\ub97c \ud568\uaed8 \uc0ac\uc6a9\ud558\uba74 \ub178\uc774\uc988 \uc2dc\uac01\ud654 \uac00\ub2a5.\n##### PCA can be used together to visualize noise.","99b4f89a":"##### \ubd84\ub958\uac00 \uc544\ub2c8\ub77c \uad70\uc9d1\ud654\ub97c \ud560 \uac70\ub77c Species\ub294 \ud544\uc694\uac00 \uc5c6\uc74c.\n\n##### I'm going to cluster, not classification. So I don't need Species.","e6c402d7":"# Mean Shift","ddc02609":"##### 3\uc774 \uc81c\uc77c \uc88b\uc544\ubcf4\uc784.\n##### 3 looks best","1b8dcde1":"# K-Means","2ea38fb9":"# PCA (\uc8fc\uc131\ubd84\ubd84\uc11d, Principal component analysis)"}}