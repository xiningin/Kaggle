{"cell_type":{"5490c667":"code","adc2b0d8":"code","d3ecdb4f":"code","3d74ee74":"code","063c3cd2":"code","198722a4":"code","17efdffe":"code","43ad8c73":"code","f2517646":"code","9ddfa774":"code","ecd85ff6":"code","a28c1ff6":"code","670d3f92":"code","3792f61a":"code","503ee28b":"code","652b7a98":"code","47b16c9d":"code","306b6668":"code","7602d5ce":"code","6473c88b":"code","fd3f068c":"code","3a79e1af":"code","3231008e":"code","ab9878b3":"code","7c47a7a6":"code","cbb33501":"code","6640d365":"code","7447f811":"code","ef155b3e":"code","8d094e90":"code","10800c9c":"code","6e49e8f9":"code","35520599":"code","705baab6":"code","9c42d96f":"code","d252a048":"code","25661c4f":"code","9541b270":"code","2b548473":"code","98e1ddd4":"code","251ece8d":"code","12505941":"code","7ee38ca0":"code","72d49f4d":"code","a7f38db9":"code","3d545804":"code","718991ec":"code","98105b63":"code","7ee3e68d":"code","c73cab5b":"code","9683e719":"markdown","d3afeafe":"markdown","671b7e76":"markdown","351933d6":"markdown","de532d18":"markdown","f5028fef":"markdown","4434c08a":"markdown","2c2c0fb3":"markdown","5454eedb":"markdown","88fe220c":"markdown","c0b00b37":"markdown","c6709c3c":"markdown","c0a3f147":"markdown","e9564caf":"markdown","79de7063":"markdown","29b8dc31":"markdown","1f30d474":"markdown","0bb3bb15":"markdown","d0f2db92":"markdown","f327119a":"markdown","13786f10":"markdown","a9d6de3b":"markdown","dbc6bdba":"markdown","a9df93b0":"markdown","6bbdfe0f":"markdown","ef9bcb20":"markdown","baa5a50d":"markdown","5b6e0b37":"markdown","275b8f0e":"markdown","e341fdd4":"markdown","c9fc5b8c":"markdown","1a83b5d7":"markdown","6f0f2476":"markdown","fd327281":"markdown","0d7cf7e5":"markdown","e4ca9662":"markdown","f99693bf":"markdown","5b328fb9":"markdown","ae739942":"markdown","8ebdc0be":"markdown","b4c17cd7":"markdown","58b62321":"markdown","dab38846":"markdown","34406922":"markdown","d56fd851":"markdown","02e5533c":"markdown","5364ccbd":"markdown","0719e0a3":"markdown","b48293f3":"markdown","f8cb651c":"markdown","013be5dc":"markdown","d9e3ef56":"markdown","94951a4e":"markdown","6b781af0":"markdown","5dbc8181":"markdown","beb0d74f":"markdown","9f19372e":"markdown","2226b897":"markdown"},"source":{"5490c667":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","adc2b0d8":"books = pd.read_csv('..\/input\/goodreadsbooks\/books.csv',error_bad_lines = False)","d3ecdb4f":"books.head()","3d74ee74":"books.shape","063c3cd2":"#List of columns\nlist(books.columns)","198722a4":"books.rename(columns={'  num_pages':'num_pages'}, inplace=True)","17efdffe":"books.index = books['bookID']","43ad8c73":"print(\"Dataset contains {} rows and {} columns\".format(books.shape[0], books.shape[1]))","f2517646":"books.replace(to_replace='J.K. Rowling-Mary GrandPr\u00e9', value = 'J.K. Rowling', inplace=True)\nbooks.replace(to_replace='J.K. Rowling\/Mary GrandPr\u00e9', value = 'J.K. Rowling', inplace=True)","9ddfa774":"books.head(5)","ecd85ff6":"books.isnull().values.any()","a28c1ff6":"books.duplicated()","670d3f92":"plt.figure(figsize=(30,5))\nsns.boxplot(x=books['average_rating'],palette = 'colorblind')","3792f61a":"plt.figure(figsize=(30,10))\nsns.boxplot(x=books['ratings_count'],palette = 'colorblind')","503ee28b":"for feature in books.columns:\n    uniq = np.unique(books[feature])\n    print('{}: {} distinct values\\n'.format(feature,len(uniq)))","652b7a98":"#Taking the first 20:\n\nsns.set_context('poster')\nplt.figure(figsize=(20,15))\nbook = books['title'].value_counts()[:20]\nrating = books.average_rating[:20]\nsns.barplot(x = book, y = book.index, palette='deep')\nplt.title(\"Most Occurring Books\")\nplt.xlabel(\"Number of occurances\")\nplt.ylabel(\"Books\")\nplt.show()","47b16c9d":"sns.set_context('paper')\nplt.figure(figsize=(15,10))\nax = books.groupby('language_code')['title'].count().plot.bar()\nplt.title('Language Code')\nplt.xticks(fontsize = 15)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x()-0.3, p.get_height()+100))","306b6668":"most_rated = books.sort_values('ratings_count', ascending = False).head(10).set_index('title')\nplt.figure(figsize=(15,10))\nsns.barplot(most_rated['ratings_count'], most_rated.index, palette='rocket')","7602d5ce":"sns.set_context('talk')\nmost_books = books.groupby('authors')['title'].count().reset_index().sort_values('title', ascending=False).head(10).set_index('authors')\nplt.figure(figsize=(15,10))\nax = sns.barplot(most_books['title'], most_books.index, palette='icefire_r')\nax.set_title(\"Top 10 authors with most books\")\nax.set_xlabel(\"Total number of books\")\nfor i in ax.patches:\n    ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 10, color = 'k')","6473c88b":"sns.set_context('talk')\nmost_books = books.groupby('publisher')['title'].count().reset_index().sort_values('title', ascending=False).head(10).set_index('publisher')\nplt.figure(figsize=(15,10))\nax = sns.barplot(most_books['title'], most_books.index, palette='icefire_r')\nax.set_title(\"Top 10 publishers with most books\")\nax.set_xlabel(\"Total number of books\")\nfor i in ax.patches:\n    ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 10, color = 'k')","fd3f068c":"plt.figure(figsize=(10,10))\nrating= books.average_rating.astype(float)\nsns.distplot(rating, bins=20)","3a79e1af":"def segregation(data):\n    values = []\n    for val in data.average_rating:\n        if val>=0 and val<=1:\n            values.append(\"Between 0 and 1\")\n        elif val>1 and val<=2:\n            values.append(\"Between 1 and 2\")\n        elif val>2 and val<=3:\n            values.append(\"Between 2 and 3\")\n        elif val>3 and val<=4:\n            values.append(\"Between 3 and 4\")\n        elif val>4 and val<=5:\n            values.append(\"Between 4 and 5\")\n        else:\n            values.append(\"NaN\")\n    print(len(values))\n    return values","3231008e":"books['Ratings_Dist'] = segregation(books)\nratings_pie = books['Ratings_Dist'].value_counts().reset_index()\nlabels = ratings_pie['index']\ncolors = ['lightblue','darkmagenta','coral','bisque', 'black']\npercent = 100.*ratings_pie['Ratings_Dist']\/ratings_pie['Ratings_Dist'].sum()\nfig, ax1 = plt.subplots()\nax1.pie(ratings_pie['Ratings_Dist'],colors = colors, \n        pctdistance=0.85, startangle=90, explode=(0.05, 0.05, 0.05, 0.05, 0.05))\n#Draw a circle now:\ncentre_circle = plt.Circle((0,0), 0.70, fc ='white')\nfig1 = plt.gcf()\nfig1.gca().add_artist(centre_circle)\n#Equal Aspect ratio ensures that pie is drawn as a circle\nplt.axis('equal')\nplt.tight_layout()\nlabels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(labels, percent)]\nplt.legend( labels, loc = 'best',bbox_to_anchor=(-0.1, 1.),)","ab9878b3":"#Checking for any relation between them.\nplt.figure(figsize=(15,10))\nbooks.dropna(0, inplace=True)\nsns.set_context('paper')\nax =sns.jointplot(x=\"average_rating\",y='text_reviews_count', kind='scatter',  data= books[['text_reviews_count', 'average_rating']])\nax.set_axis_labels(\"Average Rating\", \"Text Review Count\")\nplt.show()","7c47a7a6":"plt.figure(figsize=(15,10))\nsns.set_context('paper')\nax = sns.jointplot(x=\"average_rating\", y=\"num_pages\", data = books, color = 'crimson')\nax.set_axis_labels(\"Average Rating\", \"Number of Pages\")","cbb33501":"trial = books[~(books['num_pages']>1000)]","6640d365":"ax = sns.jointplot(x=\"average_rating\", y=\"num_pages\", data = trial, color = 'darkcyan')\nax.set_axis_labels(\"Average Rating\", \"Number of Pages\")","7447f811":"sns.set_context('paper')\nax = sns.jointplot(x=\"average_rating\", y=\"ratings_count\", data = books, color = 'blueviolet')\nax.set_axis_labels(\"Average Rating\", \"Ratings Count\")","ef155b3e":"trial = books[~(books.ratings_count>2000000)]","8d094e90":"sns.set_context('paper')\nax = sns.jointplot(x=\"average_rating\", y=\"ratings_count\", data = trial, color = 'brown')\nax.set_axis_labels(\"Average Rating\", \"Ratings Count\")","10800c9c":"most_text = books.sort_values('text_reviews_count', ascending = False).head(10).set_index('title')\nplt.figure(figsize=(15,10))\nsns.set_context('poster')\nax = sns.barplot(most_text['text_reviews_count'], most_text.index, palette='magma')\nfor i in ax.patches:\n    ax.text(i.get_width()+2, i.get_y()+0.5,str(round(i.get_width())), fontsize=10,color='black')\nplt.show()","6e49e8f9":"from sklearn.cluster import KMeans\nfrom sklearn import neighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.cluster.vq import kmeans, vq\nfrom matplotlib.lines import Line2D","35520599":"trial = books[['average_rating', 'ratings_count']]\ndata = np.asarray([np.asarray(trial['average_rating']), np.asarray(trial['ratings_count'])]).T","705baab6":"X = data\ndistortions = []\nfor k in range(2,30):\n    k_means = KMeans(n_clusters = k)\n    k_means.fit(X)\n    distortions.append(k_means.inertia_)\n\nfig = plt.figure(figsize=(15,10))\nplt.plot(range(2,30), distortions, 'bx-')\nplt.title(\"Elbow Curve\")\n","9c42d96f":"#Computing K means with K = 5, thus, taking it as 5 clusters\ncentroids, _ = kmeans(data, 5)\n\n#assigning each sample to a cluster\n#Vector Quantisation:\n\nidx, _ = vq(data, centroids)","d252a048":"# some plotting using numpy's logical indexing\nsns.set_context('paper')\nplt.figure(figsize=(15,10))\nplt.plot(data[idx==0,0],data[idx==0,1],'or',#red circles\n     data[idx==1,0],data[idx==1,1],'ob',#blue circles\n     data[idx==2,0],data[idx==2,1],'oy', #yellow circles\n     data[idx==3,0],data[idx==3,1],'om', #magenta circles\n     data[idx==4,0],data[idx==4,1],'ok',#black circles\n    \n     \n        \n        \n        \n        \n        )\nplt.plot(centroids[:,0],centroids[:,1],'sg',markersize=8, )\n\n\n\n\ncircle1 = Line2D(range(1), range(1), color = 'red', linewidth = 0, marker= 'o', markerfacecolor='red')\ncircle2 = Line2D(range(1), range(1), color = 'blue', linewidth = 0,marker= 'o', markerfacecolor='blue')\ncircle3 = Line2D(range(1), range(1), color = 'yellow',linewidth=0,  marker= 'o', markerfacecolor='yellow')\ncircle4 = Line2D(range(1), range(1), color = 'magenta', linewidth=0,marker= 'o', markerfacecolor='magenta')\ncircle5 = Line2D(range(1), range(1), color = 'black', linewidth = 0,marker= 'o', markerfacecolor='black')\n\nplt.legend((circle1, circle2, circle3, circle4, circle5)\n           , ('Cluster 1','Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5'), numpoints = 1, loc = 0, )\n\n\nplt.show()","25661c4f":"trial.idxmax()","9541b270":"trial.drop(41865, inplace = True)","2b548473":"data = np.asarray([np.asarray(trial['average_rating']), np.asarray(trial['ratings_count'])]).T","98e1ddd4":"#Computing K means with K = 8, thus, taking it as 8 clusters\ncentroids, _ = kmeans(data, 5)\n\n#assigning each sample to a cluster\n#Vector Quantisation:\n\nidx, _ = vq(data, centroids)","251ece8d":"# some plotting using numpy's logical indexing\nsns.set_context('paper')\nplt.figure(figsize=(15,10))\nplt.plot(data[idx==0,0],data[idx==0,1],'or',#red circles\n     data[idx==1,0],data[idx==1,1],'ob',#blue circles\n     data[idx==2,0],data[idx==2,1],'oy', #yellow circles\n     data[idx==3,0],data[idx==3,1],'om', #magenta circles\n     data[idx==4,0],data[idx==4,1],'ok',#black circles\n    \n     \n        \n        \n        \n        \n        )\nplt.plot(centroids[:,0],centroids[:,1],'sg',markersize=8, )\n\n\n\n\ncircle1 = Line2D(range(1), range(1), color = 'red', linewidth = 0, marker= 'o', markerfacecolor='red')\ncircle2 = Line2D(range(1), range(1), color = 'blue', linewidth = 0,marker= 'o', markerfacecolor='blue')\ncircle3 = Line2D(range(1), range(1), color = 'yellow',linewidth=0,  marker= 'o', markerfacecolor='yellow')\ncircle4 = Line2D(range(1), range(1), color = 'magenta', linewidth=0,marker= 'o', markerfacecolor='magenta')\ncircle5 = Line2D(range(1), range(1), color = 'black', linewidth = 0,marker= 'o', markerfacecolor='black')\n\nplt.legend((circle1, circle2, circle3, circle4, circle5)\n           , ('Cluster 1','Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5'), numpoints = 1, loc = 0, )\n\n\nplt.show()","12505941":"books_features = pd.concat([books['Ratings_Dist'].str.get_dummies(sep=\",\"), books['average_rating'], books['ratings_count']], axis=1)","7ee38ca0":"books_features.head()","72d49f4d":"min_max_scaler = MinMaxScaler()\nbooks_features = min_max_scaler.fit_transform(books_features)","a7f38db9":"np.round(books_features, 2)","3d545804":"model = neighbors.NearestNeighbors(n_neighbors=6, algorithm='ball_tree')\nmodel.fit(books_features)\ndistance, indices = model.kneighbors(books_features)","718991ec":"def get_index_from_name(name):\n    return books[books[\"title\"]==name].index.tolist()[0]\n\nall_books_names = list(books.title.values)\n\ndef get_id_from_partial_name(partial):\n    for name in all_books_names:\n        if partial in name:\n            print(name,all_books_names.index(name))\n            \ndef print_similar_books(query=None,id=None):\n    if id:\n        for id in indices[id][1:]:\n            print(books.iloc[id][\"title\"])\n    if query:\n        found_id = get_index_from_name(query)\n        for id in indices[found_id][1:]:\n            print(books.iloc[id][\"title\"])","98105b63":"print_similar_books(\"The Catcher in the Rye\")","7ee3e68d":"print_similar_books(\"The Hobbit\")\n","c73cab5b":"print_similar_books(\"The Iliad\")\n","9683e719":"In a setting such as this, the unsupervised learning takes place, with the similar neighbors being recommended. For the given list, if I ask recommendations for \"The Catcher in the Rye\", five books related to it would appear. ","d3afeafe":"### Is there any realationship between number of pages and average rating?","671b7e76":"The rename function is used to rename columns","351933d6":"Importing some importants libraries","de532d18":"Creating specific functions to help in finding the book names: \n- Get index from Title\n- Get ID from partial name (Because not everyone can remember all the names) \n- Print the similar books from the feature dataset. \n *(This uses the Indices metric from the nearest neighbors to pick the books.)*","f5028fef":"Even now, we can see that most of the 5 star rating is for books having pages less than 400.","4434c08a":"### Is there any relationship between average rating and the numbers of rating received?","2c2c0fb3":"### What is the percentage of books lying between various points?","5454eedb":"The min-max scaler is used to reduce the bias which would have been present due to some books having a massive amount of features, yet the rest having less. Min-Max scaler would find the median for them all and equalize it. \n","88fe220c":"# Exploratory Data Analysis","c0b00b37":"We can use the ```.index``` to set an index column explicitly ","c6709c3c":"Let's see if we have null values. The ```isnull``` is used for the same ","c0a3f147":"Here too we can see that the outliers are affecting the plot. Hence we will take a temporary dataframe having number of rantings more than 2000000","e9564caf":"Clearly we can see that english is the most frequent language.","79de7063":"To see the number of books lying in different points, we try to classify them. The function, ```segregation``` below does the same. <br>\nPoints 0 to 1 (Under Average books)\n\nPoints 1 to 2 (Average books)\n\nPoints 2 to 3 (Good books)\n\nPoints 3 to 4 (Very Good books)\n\nPoints 4 to 5 (Excellent books)\n","29b8dc31":"Here because of the outliers, we can see that the whole graph is getting positively skewed. For this we will try to plot a graph having books with pages not more than 1000.","1f30d474":"Creating a books features table, based on the Ratings Distribution, which classifies the books into ratings scale such as: \n- Between 0 and 1\n- Between 1 and 2\n- Between 2 and 3\n- Between 3 and 4\n- Between 4 and 5\n\nBroadly, the recommendations then consider the average ratings and ratings cout for the query entered.","0bb3bb15":"# Recommendation Engine","d0f2db92":"We can see that,The lliad and The brothers karamazov are the books with most occurances. This shows that the books have aged well.","f327119a":"Cool","13786f10":"### Which are the authors in the dataset, with maximum number of books? ","a9d6de3b":"From the above plot, we can see that the elbow lies around the value K=5, so that's what we will attempt it with","dbc6bdba":"# KMeans Clustering","a9df93b0":"Finding the outliers and then removing them.","6bbdfe0f":"Printing the length and breadth of the dataset","ef9bcb20":"### Which book has got the most number of ratings?","baa5a50d":"I attempt to find a relationship or groups between the rating count and average rating value.","5b6e0b37":"### Which is the most frequent language?","275b8f0e":"### Is there any relationship between average rating and number of reviews?","e341fdd4":"### Which books have got the highest text reviews, i.e comments too?","c9fc5b8c":"Lets see if we have any duplicate values","1a83b5d7":"#### Columns Description: \n\n- **bookID** Contains the unique ID for each book\/series\n- **title** contains the titles of the books\n- **authors** contains the author of the particular book\n- **average_rating** the average rating of the books, as decided by the users\n- **ISBN** ISBN(10) number, tells the information about a book - such as edition and publisher\n- **ISBN 13** The new format for ISBN, implemented in 2007. 13 digits\n- **language_code** Tells the language for the books\n- **Num_pages** Contains the number of pages for the book\n- **Ratings_count** Contains the number of ratings given for the book\n- **text_reviews_count** has the count of reviews left by users","6f0f2476":"Here too, we cannot see any abnormal values","fd327281":"Even now, we can see that most of the ratings are at 4.","0d7cf7e5":"We can see that there are no outlier in ```average_rating```","e4ca9662":"# Data Cleaning","f99693bf":"Twilight(Twilight #1) is the most rated book. But no other book from twilight series can be seen in the list.","5b328fb9":"Importing libraries","ae739942":"### What is the average rating in the dataset?","8ebdc0be":"Replacing the author. Though I respect Mary GrandPr\u00e9 for her illustrations, but here I am taking J.K, Rowling only, for the sake of simplcity","b4c17cd7":"# BOOKS EDA AND RECOMMENDER SYSTEM","58b62321":"We can see that there are no null values","dab38846":"Checking out the Workings of the System, let's try with following examples. \n\n- System by name: The Catcher in the Rye\n- System by Name: The Hobbit\n- System by partial name: Harry Potter (Book 5)\n","34406922":"![Good books image](https:\/\/images.unsplash.com\/photo-1481627834876-b7833e8f5570?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1441&q=80)","d56fd851":"### Which are the books with most occurances in the list?<a id=\"4\"><\/a> <br>","02e5533c":"We can see that, most of the reviews were done for ratings around 4. This means that very less number of people give either full or 0 marks,","5364ccbd":"Clearly we can see that Twilight(Twilight#) has got the highest text review.","0719e0a3":"Let us see what are the unique values present in the dataset. <br> For this, ```unique``` method is used.","b48293f3":"KMeans clustering is a type of unsupervised learning which groups unlabelled data. The goal is to find groups in data.\n\nWith this, I attempt to find a relationship or groups between the rating count and average rating value.","f8cb651c":"From the dataset we can see that, the things that are needed to do are.\n\n1. Remove the extra spaces before ```num_pages```\n2. Keep bookID as the index\n3. Replace \"J.K. Rowling-Mary GrandPr\u00e9\" to \"J.K. Rowling\"\n4. Check for null values\n5. Check for duplicates\n6. Check for outliers","013be5dc":"# The Model","d9e3ef56":"Let us see if the changes have reflected or not","94951a4e":"We can see from the above plot, that because of two outliers, the whole clustering algortihm is skewed. Let's remove them and form inferences","6b781af0":"# KMeans with Optimisation","5dbc8181":"### Which publishing house is the most frequent in the dataset?","beb0d74f":"## Sneak Peak of Dataset","9f19372e":"From the above plot, now we can see that once the whole system can be classified into clusters. As the count increases, the rating would end up near the cluster given above. The green squares are the centroids for the given clusters.\n\nAs the rating count seems to decrease, the average rating seems to become sparser, with higher volatility and less accuracy.","2226b897":"Since KNN clustering is pretty basic and makes clusters, even though specified k is wrong, so we are using the Elbow Curve method for finding the number of clusters for the data"}}