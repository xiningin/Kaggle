{"cell_type":{"1b1cebc5":"code","97253650":"code","0628db1f":"code","1f064563":"code","8fd6f069":"code","12cc732c":"code","d95bbf69":"code","1f9e6dc4":"code","ed3c5dd9":"code","7e0b52b9":"code","6654fff7":"code","6e1df9eb":"code","baa975bc":"code","c688029b":"code","9d822f94":"code","12392358":"code","d440e062":"code","d41ac23f":"code","3981447c":"code","e2cde416":"code","67a9dceb":"code","453cb7c5":"code","e9988fb6":"code","ab605265":"code","b1c90add":"code","9c3c4896":"code","4507e37a":"code","0339d9ac":"code","7e49d9b2":"code","893d7400":"code","66f33ee0":"code","3208c5a4":"code","522dd41e":"code","6c14815a":"code","ea67a816":"code","86d29b40":"code","2dcb68b4":"code","aa195921":"code","5ea6bc81":"code","1f7f60fb":"code","a20b1648":"code","1c429b8c":"code","770e464f":"code","056a7383":"code","2b1dae3e":"code","e9c989ae":"code","ea3f5a62":"code","88b0d43f":"code","558ba9e9":"code","6bc5b16d":"markdown","b6ef7f1f":"markdown","ea924511":"markdown","a1db6563":"markdown","144e1eb3":"markdown","a7d92efb":"markdown","8c2f1801":"markdown","334ff782":"markdown","c5af8e43":"markdown","d3392b14":"markdown","515d46b0":"markdown","04366c13":"markdown","6e406533":"markdown","52cd9595":"markdown","07785d69":"markdown","ec62c678":"markdown","d8322f9b":"markdown","81836ff7":"markdown","1dd1235a":"markdown","3435d202":"markdown","ecf6c510":"markdown","26af53ed":"markdown","6aa46a4c":"markdown","d4001d33":"markdown","648a3e1f":"markdown","9288405c":"markdown","9bb987da":"markdown","2360f7f2":"markdown","b7d00a5c":"markdown","298f43ba":"markdown"},"source":{"1b1cebc5":"import os\nimport glob\nimport re\n\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport matplotlib as mpl\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n","97253650":"TAB_DATA_PATH = \"..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/ClinicalReadings\/\"\nIMGS_PATH = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\/'\nMASKS_PATH = \"..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/masks\/\"\nTEST_IMG_PATH = \"..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/test\/\"\nIMG_SIZE = 128","0628db1f":"def get_df_with_patients_info(path=TAB_DATA_PATH):\n\n    tab_data_txt = os.listdir(path)\n    ids = ' '.join(map(str, tab_data_txt)).replace(\".txt\", \"\").split()\n    tabular_data = []\n\n    for idx, one_diagnosis in zip(ids, tab_data_txt):\n        #print(idx, one_diagnosis)\n        with open(TAB_DATA_PATH + one_diagnosis) as f:\n            info = []\n            for line in f:\n\n                line = line.lower().strip()\n\n                if \"mal\" in line and \"normal\" not in line and len(line) < 20:\n\n\n                    line = line.replace(\",\", \"\")\n                    line = line.replace(\" \", \"\")\n\n                    match = re.match(r\"([a-z]+)([0-9]+)\", line, re.I)\n                    if match:\n                        line = \" \".join(match.groups())\n\n                    sex, age = zip(line.split())\n                    info.extend([list(sex), list(age)])\n                    continue\n\n                info.append([line])\n\n            info = [i for i in info if i != ['']]\n            info.insert(0, [idx])\n            info[3:] = [[i[0] for i in info[3:]]]\n            info = [i[0] for i in info]\n\n            tabular_data.append(info)\n            \n    pd.DataFrame(tabular_data, \n             columns=[\"Id\", \"Sex\", \"Age\", \"Diagnosis\"]).to_csv(\"raw_patients_info.csv\",\n                                                               index=False)\n            \nget_df_with_patients_info()","1f064563":"raw_df = pd.read_csv(\"raw_patients_info.csv\")\nraw_df","8fd6f069":"raw_df[\"Sex\"].value_counts()","12cc732c":"raw_df[\"Sex\"] = raw_df[\"Sex\"].replace({\"patient's sex: f\": \"female\",\n                                       \"patient's sex: m\": \"male\",\n                                       \"femal\": \"female\",\n                                      \"patient's sex: o\": \"male\"})\n\nraw_df[\"Sex\"].value_counts()","d95bbf69":"fig, ax = plt.subplots(figsize=(15, 8))\n\nage_dist = sns.countplot(raw_df[\"Sex\"], palette=\"viridis\",\n             order = raw_df[\"Sex\"].value_counts().index, ax=ax)\n\nsns.set(font_scale=1)\nage_dist.set_title('Gender distribution', fontsize=20, y=1.01)\nage_dist.set_ylabel(\"Count\", fontsize=15)\nage_dist.set_xlabel(\"Gender\", fontsize=15)\nvalue = raw_df[\"Sex\"].value_counts().values\n\n\n\nfor p, label in zip(age_dist.patches, value):\n    age_dist.annotate(label, (p.get_x()+0.35, p.get_height()+4))","1f9e6dc4":"raw_df[\"Age\"].value_counts()","ed3c5dd9":"age_list = raw_df[\"Age\"].apply(lambda line: re.findall(r'([1-9]\\d+|[1-9])', line)).values\n\nraw_df[\"Age\"] = [int(age[0]) for age in age_list]\nraw_df[\"Age\"].value_counts()","7e0b52b9":"fig, ax = plt.subplots(figsize=(18, 10))\n\nsns.countplot(raw_df[\"Age\"], ax=ax)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=9);\nax.set_ylabel(\"Count\", fontsize=15)\nax.set_xlabel(\"Age\", fontsize=15)\nax.set_title(\"Distribution of Ages\", fontsize=20, y=1.01)\n              \nannotate = raw_df[\"Age\"].describe().to_dict()\nannotate = [str(key) + \": \" + str(value)+\"\\n\" for key, value in annotate.items()]\nax.legend([\"\".join(annotate)], prop={'size': 8});","6654fff7":"fig, ax = plt.subplots(figsize=(12, 8))\n\nsns.kdeplot(raw_df.loc[raw_df['Sex'] == 'male', 'Age'], label = 'Male', ax=ax,shade=True)\n\nsns.kdeplot(raw_df.loc[raw_df['Sex'] == 'female', 'Age'], label = 'Female', ax=ax, shade=True)\n\nplt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');","6e1df9eb":"raw_df[\"Diagnosis\"].value_counts()","baa975bc":"from wordcloud import WordCloud\n\ndef get_wordcloud(data_list, \n                  cmap=\"cool\",\n                  min_word_length=2, \n                 title=False):\n    \n    wordcloud = WordCloud(\n        background_color='black',\n        max_words=50000,\n        max_font_size=70,\n        min_word_length=min_word_length,\n        scale=5,\n        random_state=1,\n        colormap=cmap,\n        collocations=False,\n        normalize_plurals=False\n    ).generate(data_list)\n\n\n    plt.figure(figsize = (15, 10))\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.tight_layout(pad = 0.1)\n\n    if title:\n        plt.title(\"Top words from diagnosis\", fontsize=20)\n        \n    plt.savefig('wordcloud_diagnosis.png', bbox_inches = 'tight', pad_inches=0.)\n    \n    return plt.show()\n\nget_wordcloud(data_list=' '.join(raw_df[\"Diagnosis\"].values.tolist()))\n\n\"\"\"cmaps = [\"prism\", \"ocean\", \"gist_earth\", \"terrain\", \"gnuplot\", \"rainbow\", \"PuRd\", \"BuPu\", \"cool\", \"winter\", \"twilight\"]\nfor cmap in cmaps:\n    get_wordcloud(data_list=' '.join(raw_df[\"Diagnosis\"].values.tolist()), cmap=cmap)\"\"\";","c688029b":"raw_df[\"disease\"] = \"_\"\n\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"granulomas|granuloma|cavitary\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"granuloma|cavitary\"\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"pneumothorax|volume loss\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"pneumothorax\"\n\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"atelectasis\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"atelectasis\"\n\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"pleurisy\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"pleurisy\"\n\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"pneumonia\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"pneumonia\"\n\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"pleural thickening\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"pleural thickening\"\n\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"infiltrate\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"infiltrate\"\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"fibrous|fibrosis|scar\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"fibrosis\"\n\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"stb|ptb|tb|tuberculosis\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"tuberculosis\"\n\n\nraw_df.loc[(raw_df[\"Diagnosis\"].str.contains(\"nolrmale\") & (raw_df[\"disease\"] == \"_\")), [\"disease\"]] = \"no pathology\"\nraw_df.loc[(raw_df[\"Diagnosis\"] == \"normal\") & (raw_df[\"disease\"] == \"_\"), [\"disease\"]] = \"no pathology\"\n\nraw_df.loc[raw_df[\"disease\"] == \"_\", [\"disease\"]] = \"unknown\"","9d822f94":"raw_df[\"disease\"].value_counts()","12392358":"fig, ax = plt.subplots(figsize=(15, 8))\n\nsns.countplot(raw_df[\"disease\"], palette=\"rainbow\",\n             order = raw_df[\"disease\"].value_counts().index, ax=ax)\n\nax.set_title('Distribution by \"diseases\"', fontsize=20, y=1.01)\nax.set_ylabel(\"Count\", fontsize=18)\nax.set_xlabel(\"Disease\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(), rotation=15, ha=\"right\", fontsize=12);\n\nvalue = raw_df[\"disease\"].value_counts().values\n\nfor p, label in zip(ax.patches, value):\n    ax.annotate(label, (p.get_x()+0.35, p.get_height()+4))","d440e062":"raw_df[\"target\"] = 0\nraw_df.loc[raw_df[\"disease\"] != \"no pathology\", [\"target\"]] = 1\nraw_df","d41ac23f":"# \"CHNCXR\", \"MCUCXR\"\nraw_df[\"location\"] = \"_\"\n\nraw_df.loc[~raw_df.apply(lambda row: row.str.contains('CHNCXR').any(), axis=1), [\"location\"]] = \"Montgomery\"\nraw_df.loc[raw_df.apply(lambda row: row.str.contains('CHNCXR').any(), axis=1), [\"location\"]] = \"Shenzhen\"\n\n\nfig, ax = plt.subplots(figsize=(15, 8))\n\nsns.countplot(raw_df[\"location\"], palette=\"rainbow\",\n              order = raw_df[\"location\"].value_counts().index, ax=ax)\n\n\nax.set_title('Distribution of data sources', fontsize=20, y=1.01)\nax.set_ylabel(\"Total Images\", fontsize=15)\nax.set_xlabel(\"Location\", fontsize=15)\nvalue = raw_df[\"location\"].value_counts().values\n\n\n\nfor p, label in zip(ax.patches, value):\n    ax.annotate(label, (p.get_x()+0.35, p.get_height()+4))","3981447c":"x = raw_df.groupby(['location', 'target', \"Sex\"])[\"Id\"].count().to_frame().reset_index()\nx.style.background_gradient(cmap='Reds')  ","e2cde416":"sns.catplot(x='target',y='Id', hue='Sex', data=x, kind=\"bar\", height=5.5, aspect=2, palette=\"cool\", capsize=.05)\nplt.ylabel('Count', fontsize=15)\nplt.xlabel('without pathology:0 vs with pathology:1', fontsize=15);\n\n","67a9dceb":"# list of test samples(without masks)\ntest_samples = os.listdir(TEST_IMG_PATH)\ndef f(x):return x[:-4]\ntest_samples = [f(x) for x in test_samples]\n\n# this column will tell us an image for a test or for training\nraw_df[\"is_train\"] = 0\nraw_df.loc[~raw_df['Id'].isin(test_samples), [\"is_train\"]] = 1\nraw_df","453cb7c5":"raw_df[\"mask_path\"] = \"_\"\n\n\n# sort df and list of masks path then merge them\nmasks_ids =  sorted(os.listdir(MASKS_PATH),\n                   key=lambda x : x[:len(\"MCUCXR_0015_0\")])\n\n\nraw_df = raw_df.sort_values(by=\"Id\",  ascending=True).reset_index(drop=True)\n\nraw_df.loc[raw_df[\"is_train\"] == 1, [\"mask_path\"]] = masks_ids\n\nraw_df","e9988fb6":"from sklearn.model_selection import train_test_split\n\ntrain_df = raw_df[~raw_df['Id'].isin(test_samples)]\ntest_df = raw_df[raw_df['Id'].isin(test_samples)].reset_index(drop=True)\n\ntrain_df, val_df = train_test_split(train_df, \n                                   test_size=0.1,\n                                   stratify=train_df[\"target\"], \n                                   random_state=36)\n\ntrain_df, val_df = train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n\nprint(\"Train df: {}\\nVal df: {}\\nTest df: {}\\n\"\\\n      .format(train_df.shape, val_df.shape, test_df.shape))","ab605265":"raw_df.to_csv(\"tabular_data.csv\", index=False)","b1c90add":"def get_sites_imgs(df):\n\n    samples_for_viz = df.sample(25).values\n    # visualization data list\n    sample_imgs = []\n\n    # lists for 5x5 images\n    imgs_5x = []\n    masks_5x= []\n\n    for i in samples_for_viz:\n\n        #print(IMGS_PATH+i+\".png\", \"\\n\", MASKS_PATH+i+\"_mask.png\")\n\n        img = cv2.resize(cv2.imread(IMGS_PATH+i[0]+\".png\"), (IMG_SIZE, IMG_SIZE))\n        mask = cv2.resize(cv2.imread(MASKS_PATH+i[8]), (IMG_SIZE, IMG_SIZE))\n        sample_imgs.extend([img, mask])\n\n    imgs = np.array(sample_imgs[::2])\n    masks = np.array(sample_imgs[1::2])\n\n    print(imgs.shape, masks.shape)\n\n    # lists with 5x5 images\n    imgs_5x = []\n    masks_5x= []\n\n    for i in range(5, 25+5, 5):\n\n        imgs_5x.append(np.hstack(np.array(imgs[i-5:i])))\n        masks_5x.append(np.hstack(np.array(masks[i-5:i])))\n\n\n    imgs = np.array(imgs_5x)\n    masks = np.array(masks_5x)\n    print(imgs.shape, masks.shape)\n    \n    return imgs, masks","9c3c4896":"shenzhen_set_bad = train_df[(train_df[\"target\"] == 1) & (train_df[\"location\"] == \"Shenzhen\")]\nshenzhen_set_good = train_df[(train_df[\"target\"] == 0) & (train_df[\"location\"] == \"Shenzhen\")]\nmontgomery_set_bad = train_df[(train_df[\"target\"] == 1) & (train_df[\"location\"] == \"Montgomery\")]\nmontgomery_set_good = train_df[(train_df[\"target\"] == 0) & (train_df[\"location\"] == \"Montgomery\")]","4507e37a":"shenzhen_set_bad_imgs, shenzhen_set_bad_masks = get_sites_imgs(shenzhen_set_bad)\nshenzhen_set_good_imgs, shenzhen_set_good_masks = get_sites_imgs(shenzhen_set_good)\n\nmontgomery_set_bad_imgs, montgomery_set_bad_masks = get_sites_imgs(montgomery_set_bad)\nmontgomery_set_good_imgs, montgomery_set_good_masks = get_sites_imgs(montgomery_set_good)","0339d9ac":"# Data to visualization\n\ndef plot_data(imgs, masks, cmap=\"rainbow\", title=\"Title\"):\n    \n    with plt.style.context('dark_background'):\n\n        # Plot\n        fig = plt.figure(figsize=(25., 25.))\n        grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                         nrows_ncols=(5, 1),  # creates 5x1 grid of axes\n                         axes_pad=0.1,  # pad between axes in inch.\n                         )\n\n        grid[0].imshow(imgs[0][:,:,0], cmap=\"bone\")\n        grid[0].imshow(np.ma.masked_where(masks[0][:,:,0] == False, \n                                          masks[0][:,:,0]), cmap=cmap, alpha=0.3)#winter\n        grid[0].axis(\"off\")\n\n        grid[1].imshow(imgs[1][:,:,0], cmap=\"bone\")\n        grid[1].imshow(np.ma.masked_where(masks[1][:,:,0] == False,\n                                          masks[1][:,:,0]), cmap=cmap, alpha=0.3)\n        grid[1].axis(\"off\")\n\n        grid[2].imshow(imgs[2][:,:,0], cmap=\"bone\")\n        grid[2].imshow(np.ma.masked_where(masks[2][:,:,0] == False,\n                                          masks[2][:,:,0]), cmap=cmap, alpha=0.3)\n\n        grid[2].axis(\"off\")\n\n        grid[3].imshow(imgs[3][:,:,0], cmap=\"bone\")\n        grid[3].imshow(np.ma.masked_where(masks[3][:,:,0] == False,\n                                          masks[3][:,:,0]), cmap=cmap, alpha=0.3)\n\n        grid[3].axis(\"off\")\n\n        grid[4].imshow(imgs[4][:,:,0], cmap=\"bone\")\n        grid[4].imshow(np.ma.masked_where(masks[4][:,:,0] == False,\n                                          masks[4][:,:,0]), cmap=cmap, alpha=0.3)\n\n        grid[4].axis(\"off\")\n        #grid[0].set_title(f\"{title}\", fontsize=30, weight=\"bold\", color=\"#00ffcc\", y=1.05)\n        plt.suptitle(f\"{title}\", fontsize=30, weight=\"bold\", color=\"#00ffcc\", y=.99)#y=.93\n\n        plt.savefig(f'dataset_{\"\".join(title.split())}.png', \n                    bbox_inches = 'tight', pad_inches=0.,\n                    transparent=False, facecolor='black')\n    \n    return plt.show()\n\n\nplot_data(shenzhen_set_bad_imgs, shenzhen_set_bad_masks,\n          title=\"Shenzhen Set - Chest X-ray\\nwith pathologies\")\nplot_data(shenzhen_set_good_imgs, shenzhen_set_good_masks,\n          cmap='winter', title=\"Shenzhen Set - Chest X-ray\\nwithout pathologies\")\n\nplot_data(montgomery_set_bad_imgs, montgomery_set_bad_masks, \n          title=\"Montgomery County Chest X-ray Set\\nwith pathologies\")\nplot_data(montgomery_set_good_imgs, montgomery_set_good_masks,\n          cmap='winter', title=\"Montgomery County Chest X-ray Set\\nwithout pathologies\")\n","7e49d9b2":"!pip install torchviz","893d7400":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport albumentations as A\nfrom torchviz import make_dot\n\nIMG_SIZE = 512\nBATCH_SIZE = 2\nMEAN =  np.array([0.485, 0.456, 0.406]) \nSTD =  np.array([0.229, 0.224, 0.225])\nDEVICE = \"cuda:0\"","66f33ee0":"class LungsDataset(Dataset):\n    \n    def __init__(self, df, img_dir, mask_dir, aug_transform):\n        \n        self.df = df\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.aug_transform = aug_transform\n        self.norm_transform = A.Normalize(mean=MEAN, std=STD)\n        \n    def __getitem__(self, idx):\n        \n        img_path = self.img_dir + self.df.iloc[idx, 0] + \".png\"\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.mask_dir is not None:\n            \n            mask_path = self.mask_dir + self.df.iloc[idx, 8]\n            mask = cv2.imread(mask_path)[:, :, 0]\n            mask = np.clip(mask, 0, 1).astype(\"float32\")\n\n            augmented = self.aug_transform(image=img, mask=mask)\n            img = augmented['image']\n            mask = augmented['mask']\n            img = self.norm_transform(image=img)[\"image\"]\n            \n            return torch.FloatTensor(img), torch.FloatTensor(mask)\n    \n        else:\n            augmented = self.aug_transform(image=img)\n            img = augmented['image']\n            \n            img = self.norm_transform(image=img)[\"image\"]\n            \n            return torch.FloatTensor(img)\n        \n    def __len__(self):\n        return len(self.df)\n        ","3208c5a4":"transforms = A.Compose([\n    A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.RandomRotate90(p=0.4),\n    A.Transpose(p=0.4),\n    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n        ])\n\ntest_transforms = A.Compose([\n    A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n        ])","522dd41e":"# train\ntrain_dataset = LungsDataset(df=train_df, img_dir=IMGS_PATH, \n                             mask_dir=MASKS_PATH, aug_transform=transforms)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=4, \n                              shuffle=True)\n\n# validation\nval_dataset = LungsDataset(df=val_df, img_dir=IMGS_PATH, \n                             mask_dir=MASKS_PATH, aug_transform=transforms)\n\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=4, \n                            shuffle=True)\n\n# test\ntest_dataset = LungsDataset(df=test_df, img_dir=IMGS_PATH, \n                             mask_dir=None, aug_transform=test_transforms)\n\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=4, \n                             shuffle=True)","6c14815a":"def show_aug(inputs, nrows=1, ncols=2, image=True):\n    plt.figure(figsize=(12, 12))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i_ = 0\n    \n    if len(inputs) > 2:\n        inputs = inputs[:2]\n        \n    for idx in range(len(inputs)):\n    \n        # normalization\n        if image is True:           \n            img = inputs[idx].numpy()#.transpose(1,2,0)\n            #mean = [0.485, 0.456, 0.406]\n            #std = [0.229, 0.224, 0.225] \n            #img = (img*std+mean).astype(np.float32)\n            #img = np.clip(img, 0,1)\n        else:\n            img = inputs[idx].numpy().astype(np.float32)\n        \n        print(img.max(), len(np.unique(img)), img.mean())\n        plt.subplot(nrows, ncols, i_+1)\n        plt.imshow(img); \n        plt.axis('off')\n \n        i_ += 1\n        \n    return plt.show()\n\n    \nimages, masks = next(iter(train_dataloader))\nprint(images.shape, masks.shape)\n\nshow_aug(images)\nshow_aug(masks, image=False)","ea67a816":"def convrelu(in_channels, out_channels, kernel, padding):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n        nn.ReLU(inplace=True),\n    )\n\nclass ResNetUNet(nn.Module):\n\n    def __init__(self, n_classes=1):\n        super().__init__()\n        \n        self.base_model = torchvision.models.resnet50(pretrained=False)\n        \n        self.base_layers = list(self.base_model.children())                \n        \n        self.layer0 = nn.Sequential(*self.base_layers[:3])\n        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n        self.layer1 = nn.Sequential(*self.base_layers[3:5])        \n        self.layer1_1x1 = convrelu(256, 256, 1, 0)       \n        self.layer2 = self.base_layers[5]         \n        self.layer2_1x1 = convrelu(512, 512, 1, 0)  \n        self.layer3 = self.base_layers[6]         \n        self.layer3_1x1 = convrelu(1024, 1024, 1, 0)  \n        self.layer4 = self.base_layers[7] \n        self.layer4_1x1 = convrelu(2048, 2048, 1, 0)  \n        \n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        \n        self.conv_up3 = convrelu(1024 + 2048, 1024, 3, 1)\n        self.conv_up2 = convrelu(512 + 1024, 512, 3, 1)\n        self.conv_up1 = convrelu(256 + 512, 256, 3, 1)\n        self.conv_up0 = convrelu(64 + 256, 64, 3, 1)\n        \n        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n        self.conv_original_size2 = convrelu(128, 64, 3, 1)\n        \n        self.conv_last = nn.Conv2d(64, n_classes, 1)\n        \n    def forward(self, input):\n        x_original = self.conv_original_size0(input)\n        x_original = self.conv_original_size1(x_original)\n        \n        layer0 = self.layer0(input)\n        layer1 = self.layer1(layer0)\n        layer2 = self.layer2(layer1)\n        layer3 = self.layer3(layer2) \n        layer4 = self.layer4(layer3)\n        \n        layer4 = self.layer4_1x1(layer4)\n        x = self.upsample(layer4)\n        layer3 = self.layer3_1x1(layer3)\n        x = torch.cat([x, layer3], dim=1)\n        x = self.conv_up3(x)\n        x = self.upsample(x)\n        layer2 = self.layer2_1x1(layer2)\n        x = torch.cat([x, layer2], dim=1)\n        x = self.conv_up2(x)\n        x = self.upsample(x)\n        layer1 = self.layer1_1x1(layer1)\n        x = torch.cat([x, layer1], dim=1)\n        x = self.conv_up1(x)\n        x = self.upsample(x)\n        layer0 = self.layer0_1x1(layer0)\n        x = torch.cat([x, layer0], dim=1)\n        x = self.conv_up0(x)\n        x = self.upsample(x)\n        x = torch.cat([x, x_original], dim=1)\n        x = self.conv_original_size2(x)\n        \n        out = torch.sigmoid(self.conv_last(x))  \n\n        return out","86d29b40":"\"\"\"model = ResNetUNet()\nx = torch.randn(1, 3, 512, 512).requires_grad_(True)\ny = model(x)\nmake_dot(y, params=dict(list(model.named_parameters()) + [('x', x)]))\n\ndel model, x, y\"\"\";\nmodel = ResNetUNet().to(DEVICE);","2dcb68b4":"## Metric\n\ndef jaccard_coef_metric(inputs, target, eps=1e-7):\n    intersection = (target * inputs).sum()\n    union = (target.sum() + inputs.sum()) - intersection + eps\n\n    if target.sum() == 0 and inputs.sum() == 0:\n        return 1.0\n\n    return (intersection + eps) \/ union\n\ndef dice_coef_metric(inputs, target):\n    intersection = 2.0 * (target * inputs).sum()\n    union = target.sum() + inputs.sum()\n    if target.sum() == 0 and inputs.sum() == 0:\n        return 1.0\n\n    return intersection \/ union\n\n## Loss\n\ndef dice_coef_loss(inputs, target):\n    smooth = 1.0\n    intersection = 2.0 * ((target * inputs).sum()) + smooth\n    union = target.sum() + inputs.sum() + smooth\n\n    return 1 - (intersection \/ union)\n\n\ndef bce_dice_loss(inputs, target):\n    dicescore = dice_coef_loss(inputs, target)\n    bcescore = nn.BCELoss()\n    bceloss = bcescore(inputs, target)\n\n    return bceloss + dicescore","aa195921":"def train_one_epoch(model, optimizer, lr_scheduler, metric,\n                    dataloader, epoch, criterion=bce_dice_loss):\n    \n    print(\"Start Train ...\")\n    model.train()\n\n    losses = []\n    accur = []\n\n    for data, target in dataloader:\n\n        data = data.permute(0,3,1,2).to(DEVICE)\n        targets = target.unsqueeze(1).to(DEVICE)\n\n        outputs = model(data)\n\n        out_cut = np.copy(outputs.data.cpu().numpy())\n        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n\n        train_dice = metric(out_cut, targets.data.cpu().numpy())\n\n        loss = criterion(outputs, targets)\n\n        losses.append(loss.item())\n        accur.append(train_dice)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    if lr_scheduler is not None:\n        lr_scheduler.step()\n\n    lr = lr_scheduler.get_last_lr()[0]\n    print(\"Epoch [%d]\" % (epoch),\n          \"Mean loss on train:\", np.array(losses).mean(), \n          \"Mean DICE on train:\", np.array(accur).mean(), \n          \"Learning Rate:\", lr)\n\n    \n    return np.array(losses).mean(), np.array(accur).mean(), lr\n\n\ndef val_epoch(model, metric, dataloader, epoch, threshold=0.5):\n    \n    print(\"Start Validation ...\")\n    model.eval()\n    \n    val_acc = []\n\n    with torch.no_grad():\n        for data, targets in dataloader:\n\n            data = data.permute(0,3,1,2).to(DEVICE)\n            targets = targets.unsqueeze(1).to(DEVICE)\n\n            outputs = model(data)\n\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n\n            val_dice = metric(out_cut, targets.data.cpu().numpy())\n            val_acc.append(val_dice)\n\n        print(\"Epoch:  \" + str(epoch) + \"  Threshold:  \" + str(threshold)\\\n              + \" Mean Validation DICE Score:\", np.array(val_acc).mean())\n        \n        return  np.array(val_acc).mean()","5ea6bc81":"for param in model.parameters():\n    param.requires_grad = True\n    \nparams = [p for p in model.parameters() if p.requires_grad]\n\nstage_epoch = [12, 8, 5]#[20, 15, 10]\nstage_optimizer = [\n    torch.optim.Adamax(params, lr=0.0002),\n    torch.optim.SGD(params, lr=0.00009, momentum=0.9),\n    torch.optim.Adam(params, lr=0.00005),\n]\n\nstage_scheduler = [\n    torch.optim.lr_scheduler.CosineAnnealingLR(stage_optimizer[0], 4, 1e-6),\n    torch.optim.lr_scheduler.CyclicLR(stage_optimizer[1], base_lr=1e-5, max_lr=2e-4),\n    torch.optim.lr_scheduler.CosineAnnealingLR(stage_optimizer[2], 4, 1e-6),\n]\n","1f7f60fb":"weights_dir = \"weights\"\nif os.path.exists(weights_dir) == False:\n    os.mkdir(weights_dir)\n\n\nloss_history = []\ntrain_dice_history = []\nval_dice_history = []\nlr_history = []\n\nfor k, (num_epochs, optimizer, lr_scheduler) in enumerate(zip(stage_epoch, stage_optimizer, stage_scheduler)):\n    for epoch in range(num_epochs):\n        \n        \n        loss, train_dice, lr = train_one_epoch(model, optimizer, lr_scheduler, \n                                               dice_coef_metric, train_dataloader, epoch)\n    \n        val_dice = val_epoch(model, dice_coef_metric, val_dataloader, epoch)\n        \n        \n        # train history\n        loss_history.append(loss)\n        train_dice_history.append(train_dice)\n        lr_history.append(lr)\n        val_dice_history.append(val_dice)\n\n        # save best weights\n        best_dice = max(val_dice_history)\n        if val_dice >= best_dice:\n            torch.save({'state_dict': model.state_dict()},\n                        os.path.join(weights_dir, f\"{val_dice:0.6f}_.pth\"))\n    \n    print(\"\\nNext stage\\n\")\n    # Load the best weights\n    best_weights =  sorted(glob.glob(weights_dir + \"\/*\"),\n                       key= lambda x: x[8:-5])[-1]\n    checkpoint = torch.load(best_weights)\n    model.load_state_dict(checkpoint['state_dict'])\n\n    print(f'Loaded model: {best_weights.split(\"\/\")[1]}')","a20b1648":"df_logs = pd.DataFrame(\n    {'loss': loss_history,\n     \"lr\" : lr_history,\n     'train_dice':train_dice_history,\n     'val_dice': val_dice_history\n    })\ndf_logs.to_csv(\"train_logs.csv\", index=False)","1c429b8c":"df_logs","770e464f":"#print(plt.style.available)\nplt.style.use(\"seaborn-colorblind\")#seaborn-bright#seaborn-colorblind#seaborn-dark#seaborn-dark-palette#seaborn-poster#white\n\ndef get_history_plot(df, y_title, x_title, title, color=None):\n    \n    fig, ax = plt.subplots(figsize=(12, 6))\n    \n    sns.lineplot(data=df, ax=ax, color=color)\n    plt.ylabel(f\"{y_title}\", fontsize=15)\n    plt.xlabel(f\"{x_title}\", fontsize=15)\n    plt.title(f\"{title}\", fontsize=18)\n    plt.legend(fontsize=15);\n    \n    return plt.show()\n\nget_history_plot(df=df_logs.iloc[:, 2:].apply(lambda x:x*100),\n                 y_title=\"Percentage Dice coefficient\",\n                 x_title=\"Epoch\", \n                 title=\"Metric\")\n\nget_history_plot(df=df_logs.iloc[:, 0],\n                 y_title=\"dice+bce\",\n                 x_title=\"Epoch\",\n                 title=\"Loss\",\n                 color=\"purple\")\n\nget_history_plot(df=df_logs.iloc[:, 1],\n                 y_title=\"Value\",\n                 x_title=\"Epoch\", \n                 title=\"Learning Rate\",\n                 color=\"green\")","056a7383":"# adapted from https:\/\/www.kaggle.com\/eduardomineo\/u-net-lung-segmentation-montgomery-shenzhen\/data\ndef add_colored_mask(image, mask_image1):\n    image  = (image*STD+MEAN).astype(np.float32)\n    mask_image = cv2.cvtColor(mask_image1, cv2.COLOR_GRAY2BGR)\n    mask_image_gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY).astype(\"uint8\")\n    \n    mask = cv2.bitwise_and(mask_image, mask_image, mask=mask_image_gray)\n    \n    mask_coord = np.where(mask!=[0,0,0])\n\n    mask[mask_coord[0],mask_coord[1],:]=[255,0,0]\n\n    ret = cv2.addWeighted(image, 0.7, mask, 0.3, 0)\n\n    return ret","2b1dae3e":"model.eval()\nthreshold = 0.5\n\n# Define the codec and create VideoWrite object\nvideo_name = 'test_data.avi'\nframerate=2\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nvideo = cv2.VideoWriter(video_name, fourcc, framerate, (IMG_SIZE, IMG_SIZE))\n\nwith torch.no_grad():\n    for data_batch in test_dataloader:\n\n        data_batch = data_batch.permute(0,3,1,2).to(DEVICE)\n\n        outputs = model(data_batch)\n\n\n        out_cut = np.copy(outputs.data.cpu().numpy())\n        out_cut[np.nonzero(out_cut < threshold)] = 0.0\n        out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n        \n        for image, mask in zip(data_batch.data.cpu().numpy(), out_cut):\n\n            result = add_colored_mask(image.transpose(1, 2, 0), mask.transpose(1, 2, 0))\n            video.write((result*255).astype(\"uint8\"))\n            \n    cv2.destroyAllWindows()\n    video.release()","e9c989ae":"!pip install youtube_dl -qq \n","ea3f5a62":"# https:\/\/stackoverflow.com\/questions\/27473526\/download-only-audio-from-youtube-video-using-youtube-dl-in-python-script\nfrom __future__ import unicode_literals\nimport youtube_dl\n\n\nydl_opts = {\n    'format': 'bestaudio\/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192',\n    }],\n}\nwith youtube_dl.YoutubeDL(ydl_opts) as ydl:\n    ydl.download(['https:\/\/www.youtube.com\/watch?v=5YQPydQnaoo']);","88b0d43f":"# convert from avi to mp4 \n!ffmpeg -i test_data.avi -strict -2 test_data.mp4\n\n# adding sound\n!ffmpeg  -stream_loop -1 -i \"Deus Ex - Human Revolution Soundtrack - LIMB Clinic-5YQPydQnaoo.mp3\" -c copy -v 0 -f nut - | ffmpeg -thread_queue_size 10K -i - -i test_data.mp4 -c copy -map 1:v -map 0:a -shortest -y test_data_with_sound.mp4","558ba9e9":"%%HTML\n<video width=\"550\" height=\"550\" controls>\n  <source src=\".\/test_data_with_sound.mp4\" type=\"video\/mp4\">\n<\/video>","6bc5b16d":"### **Sex**","b6ef7f1f":"and also need to add a column with \"target\" values","ea924511":"### **Age**","a1db6563":"### Gender vs Target ","144e1eb3":"adding sound","a7d92efb":"let's look at the distribution by this domain","8c2f1801":"## Unet","334ff782":"## Train history","c5af8e43":"### **Splitting data frame into train, val, and test**","d3392b14":"## Diagnosis","515d46b0":"# Tabular Data","04366c13":"### Augmentations","6e406533":"### New data frame","52cd9595":"Images with masks have different lengths of names, so for convenience we add them to the df too","07785d69":"# Test (without masks)","ec62c678":"# Image Data","d8322f9b":"We can simply equate all values that are not \u201cnormal\u201d as \u201cnot normal\u201d, but let's try to come up with something better.\n\nFirst, using the wordcloud, let's look at the most frequent words","81836ff7":"### Data Generators","1dd1235a":"### Gender vs Target vs Location","3435d202":"# Steps:\n\n+ **Exploratory data analysis**:\n     + work with tabular data:\n\n     + work with images\n     \n+ **Training process**:\n    + train loop\n    + train history\n\n+ **Test**","ecf6c510":"### Dataset","26af53ed":"### *Top words from diagnosis*","6aa46a4c":"## Exploratory data analysis","d4001d33":"We have text in rows, so we need to extract numbers from all string rows","648a3e1f":"# Training process","9288405c":"## Metrics and Loss","9bb987da":"let's look at the distribution by this domain","2360f7f2":"# Train loop","b7d00a5c":"After viewing the picture with the most popular words and 10 minutes of google, I found the following diagnoses (which are certainly far-fetched and not trustworthy):\n\n+ something related with granuloma and cavitary\n+ pneumothorax\n+ atelectasis\n+ pleurisy\n+ pneumonia\n+ pleural thickening\n+ infiltrate\n+ something related with scars and fibrosis\n+ stb | ptb | tb | tuberculosis\n\nBased on these words we will create a new column **\"disease\"**\n\n+ [clarification of some obscure abbreviations](https:\/\/www.reddit.com\/r\/medicalschool\/comments\/1yr4r5\/what_does_the_x_in_rx_dx_tx_stand_for_in_the\/)\n","298f43ba":"### Distribution of data sources"}}