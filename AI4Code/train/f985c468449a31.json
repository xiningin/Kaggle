{"cell_type":{"199b394b":"code","45825448":"code","496b86d8":"code","eae30077":"code","476e9614":"code","b200ddb9":"code","02826d6d":"code","48e5129c":"code","d2dd1460":"code","0ad9e952":"code","3a413a6a":"code","36b26481":"code","b0457ad5":"code","37628a2c":"code","43bd74d0":"code","dc8d6fdf":"code","9163f096":"code","456c4b22":"code","ae12c6f3":"code","81dcff78":"code","4dccb5cb":"code","fb37df8f":"code","1b833c00":"code","a5ffae9d":"code","40adcaaf":"code","eed21d8f":"code","e27d70b8":"code","b558df91":"code","10f1ee64":"code","088f4ad3":"code","f373bcb6":"code","f951d9bd":"code","53ed8be4":"code","0b35fc5e":"code","4f79747e":"code","6e85912c":"code","def233d0":"code","9b27769f":"code","137adfae":"code","163d6819":"code","38028260":"code","4d65ba5c":"code","1958a268":"code","7c24948e":"code","0e6cd487":"code","82e3fbd0":"code","40c10afc":"code","1307c7ce":"code","5b40f189":"code","b4a72d73":"code","70ee70a3":"code","187f94ab":"code","f99752b3":"code","6d06c8a7":"code","06cdbbf1":"code","c717d1bd":"code","14d85c02":"code","80285a81":"code","7affd822":"code","19f3a99c":"code","9c6ccc7d":"code","5617cfff":"code","82da24bf":"code","93032ada":"code","1c0aed0c":"code","96e02344":"code","49f73910":"code","8b9ecdbe":"code","3a172522":"markdown","b8d167ad":"markdown","0aab1fcf":"markdown","ee02b002":"markdown","cf9d8014":"markdown","2485ccaa":"markdown","a25e7308":"markdown","a94ddfea":"markdown","fe8c05d9":"markdown","0d59896f":"markdown","f115f1e7":"markdown","99bcf27e":"markdown","7e8a0526":"markdown","a2cdccad":"markdown","1e48a431":"markdown","45fa2682":"markdown","fe8da262":"markdown","5a8146be":"markdown","32dcaffa":"markdown"},"source":{"199b394b":"from IPython.display import Image\nimport os\n#!ls ..\/input\/\nImage(\"..\/input\/loanpaymentimage\/stacking.jpg\")","45825448":"# Loading Libraries\nimport pandas as pd # for data analysis\nimport numpy as np # for scientific calculation\nimport seaborn as sns # for statistical plotting\nimport datetime # for working with date fields\nimport matplotlib.pyplot as plt # for plotting\n%matplotlib inline\nimport math # for mathematical calculation","496b86d8":"#Reading Loan Payment given Data Set.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/loan-payment\/Loan_payments_data.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","eae30077":"# Reading Loan Payment .csv file.\nloanpayment = pd.read_csv(\"..\/input\/loan-payment\/Loan_payments_data.csv\")                             # Reading data using simple Pandas","476e9614":"# Describe method is used to view some basic statistical details like percentile, mean, std etc. of a data frame of numeric values.\nloanpayment.describe()","b200ddb9":"#Checking shape of data\nloanpayment.shape","02826d6d":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n# Verifying top 3 sample records of data.\nloanpayment.head(3)\n# Checking Null Values : We can see there are No Null Values \nloanpayment.isnull().sum()\n# Checking the data information.\n# Observation: No missing values\nloanpayment.info()","48e5129c":"loanpayment['loan_status'].value_counts()","d2dd1460":"loanpayment['education'].value_counts()","0ad9e952":"loanpayment['Gender'].value_counts()","3a413a6a":"loanpayment['terms'].value_counts()","36b26481":"loanpayment.groupby(by=['Gender','education','loan_status'])['loan_status'].count()","b0457ad5":"print(np.min(loanpayment.age))\nprint(np.max(loanpayment.age))","37628a2c":"loanpayment['age_bins'] = pd.cut(x=loanpayment['age'], bins=[18, 20, 30, 40, 50, 60])","43bd74d0":"plt.rcParams['figure.figsize'] = (20.0, 10.0)\nplt.rcParams['font.family'] = \"serif\"\nfig, ax =plt.subplots(3,2)\nsns.countplot(loanpayment['Gender'], ax=ax[0,0])\nsns.countplot(loanpayment['education'], ax=ax[0,1])\nsns.countplot(loanpayment['loan_status'], ax=ax[1,0])\nsns.countplot(loanpayment['Principal'], ax=ax[1,1])\nsns.countplot(loanpayment['terms'], ax=ax[2,0])\nsns.countplot(loanpayment['age_bins'], ax=ax[2,1])\nfig.show();","dc8d6fdf":"import plotly.express as px\n\nfig = px.histogram(loanpayment, x=\"terms\", y=\"Principal\", color = 'Gender',\n                   marginal=\"violin\", # or violin, rug,\n                   color_discrete_sequence=['indianred','lightblue'],\n                   )\n\nfig.update_layout(\n    title=\"Gender wise segregation of loan terms and principal\",\n    xaxis_title=\"Loan Term\",\n    yaxis_title=\"Principal Count\/Gender Segregation\",\n)\nfig.update_yaxes(tickangle=-30, tickfont=dict(size=7.5))\n\nfig.show()","9163f096":"fig = px.scatter_3d(loanpayment,z=\"age\",x=\"Principal\",y=\"terms\",\n    color = 'Gender', size_max = 18,\n    color_discrete_sequence=['indianred','lightblue']\n    )\n\nfig.show()","456c4b22":"loanpayment.head(1)","ae12c6f3":"for dataset in [loanpayment]:\n    dataset.loc[dataset['age'] <= 20,'age']=0\n    dataset.loc[(dataset['age']>20) & (dataset['age']<=25),'age']=1\n    dataset.loc[(dataset['age']>25) & (dataset['age']<=30),'age']=2\n    dataset.loc[(dataset['age']>30) & (dataset['age']<=35),'age']=3\n    dataset.loc[(dataset['age']>35) & (dataset['age']<=40),'age']=4\n    dataset.loc[(dataset['age']>40) & (dataset['age']<=45),'age']=5\n    dataset.loc[(dataset['age']>45) & (dataset['age']<=50),'age']=6\n    dataset.loc[(dataset['age']>50) & (dataset['age']<=55),'age']=7","81dcff78":"loanpayment.head(1)","4dccb5cb":"# Import label encoder \nfrom sklearn import preprocessing \n  \n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder() \nloanpayment_fe=loanpayment.copy()\n# Encode labels in column 'education'. \nloanpayment_fe['education_label']= label_encoder.fit_transform(loanpayment_fe['education']) \n#loanpayment_fe['education_label'].unique() \n# Encode labels in column 'loan_status'. \nloanpayment_fe['loan_status_label']= label_encoder.fit_transform(loanpayment_fe['loan_status']) \n#loanpayment_fe['loan_status_label'].unique() \n# Encode labels in column 'Gender'. \nloanpayment_fe['gender_label']= label_encoder.fit_transform(loanpayment_fe['Gender']) \n#loanpayment_fe['gender_label'].unique() ","fb37df8f":"loanpayment_fe.head(1)","1b833c00":"loanpayment_fe=loanpayment_fe.drop(['Loan_ID','loan_status','education','Gender','age_bins'],axis=1)\nloanpayment_fe.head(1)","a5ffae9d":"loanpayment_fe['effective_date']= pd.to_datetime(loanpayment_fe['effective_date']) \nloanpayment_fe['due_date']= pd.to_datetime(loanpayment_fe['due_date']) \nloanpayment_fe['paid_off_time']= pd.to_datetime(loanpayment_fe['paid_off_time']) \nloanpayment_fe.info()","40adcaaf":"loanpayment_fe['actual_tenure_days'] = loanpayment_fe['due_date'] - loanpayment_fe['effective_date']\nloanpayment_fe['actual_tenure_days']=loanpayment_fe['actual_tenure_days']\/np.timedelta64(1,'D')","eed21d8f":"print(np.min(loanpayment_fe['actual_tenure_days']))\nprint(np.max(loanpayment_fe['actual_tenure_days']))","e27d70b8":"loanpayment_fe['paidoff_tenure_days'] = loanpayment_fe['paid_off_time'] - loanpayment_fe['effective_date']\nloanpayment_fe['paidoff_tenure_days']=loanpayment_fe['paidoff_tenure_days']\/np.timedelta64(1,'D')","b558df91":"print(np.min(loanpayment_fe['paidoff_tenure_days']))\nprint(np.max(loanpayment_fe['paidoff_tenure_days']))","10f1ee64":"loanpayment_fe.isnull().sum()","088f4ad3":"loanpayment_fe.describe().T","f373bcb6":"loanpayment_fe=loanpayment_fe.drop(['past_due_days'],axis=1)","f951d9bd":"null_data = loanpayment_fe[loanpayment_fe.isnull().any(axis=1)]\nnull_data.head(2)","53ed8be4":"notnull_data = loanpayment_fe[loanpayment_fe.notnull().any(axis=1)]\nnotnull_data.head(2)","0b35fc5e":"loanpayment_fe['paidoff_tenure_days'] = loanpayment_fe.groupby(['Principal','terms','age','education_label','gender_label'])['paidoff_tenure_days'].transform(lambda x:x.fillna(x.mean()))\nloanpayment_fe['paidoff_tenure_days'] = loanpayment_fe['paidoff_tenure_days'].fillna(0)","4f79747e":"\nloanpayment_fe.isnull().sum()","6e85912c":"loanpayment_fe=loanpayment_fe.drop(['effective_date','due_date','paid_off_time'],axis=1)\nloanpayment_fe.head(1)","def233d0":"loanpayment_fe['paidoff_tenure_days']=loanpayment_fe['paidoff_tenure_days'].round().astype(int)","9b27769f":"loanpayment_fe['paidoff_tenure_days'].value_counts().head(2)","137adfae":"loanpayment_fe.info()","163d6819":"loanpayment_fe.head(2)","38028260":"loanpayment_fe['loan_status_label'].value_counts().plot.bar();","4d65ba5c":"X2=loanpayment_fe.drop(['loan_status_label'],axis=1)\nX1=preprocessing.scale(X2)\nX=pd.DataFrame(X1)\ny=loanpayment_fe['loan_status_label']","1958a268":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,stratify = y)","7c24948e":"print(len(y_train[y_train==0]), len(y_train[y_train==1]), len(y_train[y_train==2]))","0e6cd487":"#!pip install imblearn","82e3fbd0":"from imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\noversampler = SMOTE(random_state=0)\nX_train ,y_train = oversampler.fit_sample(X_train, y_train)","40c10afc":"print(len(X_train[X_train==0]), len(X_train[X_train==1]), len(X_train[X_train==2]))\nprint(len(y_train[y_train==0]), len(y_train[y_train==1]), len(y_train[y_train==2]))","1307c7ce":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","5b40f189":"#importing predictive models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import StratifiedKFold","b4a72d73":"def model_predictions(model, X_train, y_train, X_test):\n    \n    #train the model\n    model.fit(X_train,y_train)\n    \n    #storing predictions for train and test\n    pred_train=model.predict(X_train)\n    pred_test=model.predict(X_test)\n    return pred_train, pred_test","70ee70a3":"#Model 1 - Decision Tree\nDT=DecisionTreeClassifier(random_state= 123)\nM1_train, M1_test = model_predictions(DT, X_train, y_train, X_test)","187f94ab":"#Model 2 - Logistic Regression\nLR=LogisticRegression(random_state= 123)\nM2_train, M2_test = model_predictions(LR, X_train, y_train, X_test)","f99752b3":"#Model 3 - k Nearest Neighbour\nknn=KNeighborsClassifier()\nM3_train, M3_test = model_predictions(knn, X_train, y_train, X_test)","6d06c8a7":"#Creating a New train dataframe\ntrain_prediction = {\n              'DT': M1_train,\n              'LR': M2_train,\n              'knn': M3_train\n              }\ntrain_predictions = pd.DataFrame(train_prediction)\ntrain_predictions.head()","06cdbbf1":"#Creating a New test dataframe\ntest_prediction = {\n              'DT': M1_test,\n              'LR': M2_test,\n              'knn': M3_test\n              }\ntest_predictions = pd.DataFrame(test_prediction)\ntest_predictions.head()","c717d1bd":"# Stacker Model\nmodel = LogisticRegression()\nmodel.fit(train_predictions, y_train)\nmodel.score(test_predictions,y_test)","14d85c02":"def Stacking(model,train,y,test,n_fold):\n    folds=StratifiedKFold(n_splits=n_fold,shuffle = True,random_state=123)\n    test_pred=np.empty((test.shape[0],1),float)\n    train_pred=np.empty((0,1),float)\n    #print(test_pred.shape)\n    for train_indices,val_indices in folds.split(train,y.values):\n        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n\n        model.fit(X=x_train,y=y_train)\n        train_pred=np.append(train_pred,model.predict(x_val))\n        print(train_pred.shape)\n    #test_pred=np.append(test_pred,model.predict(test))\n    test_pred=model.predict(test)\n    test_pred=test_pred.reshape(-1,1)\n    print(train_pred.shape,test_pred.shape)\n    return test_pred,train_pred","80285a81":"X_test.shape","7affd822":"model_DT = DecisionTreeClassifier(random_state=123)\n\ntest_pred_dt ,train_pred_dt=Stacking(model=model_DT,n_fold=10, train=X_train,test=X_test,y=y_train)\ntrain_pred_dt=pd.DataFrame(train_pred_dt)\ntest_pred_dt=pd.DataFrame(test_pred_dt)\n","19f3a99c":"model_KNN = KNeighborsClassifier()\n\ntest_pred_knn ,train_pred_knn=Stacking(model=model_KNN,n_fold=10,train=X_train,test=X_test,y=y_train)\ntrain_pred_knn=pd.DataFrame(train_pred_knn)\ntest_pred_knn=pd.DataFrame(test_pred_knn)","9c6ccc7d":"train_pred_dt.shape\ntest_pred_dt.shape, y_test.shape","5617cfff":"df = pd.concat([train_pred_dt, train_pred_knn], axis=1)\ndf_test = pd.concat([test_pred_dt, test_pred_knn], axis=1)\nprint(df.shape,df_test.shape,y_train.shape,y_test.shape)\nmodel = LogisticRegression(random_state=1)\nmodel.fit(df,y_train)\nmodel.score(df_test, y_test)","82da24bf":"from sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom mlxtend.classifier import StackingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nimport numpy as np\nimport warnings\n\nwarnings.simplefilter('ignore')\n\nclf1 = KNeighborsClassifier(n_neighbors=1)\nclf2 = RandomForestClassifier(random_state=123)\nclf3 = GaussianNB()\nlr = LogisticRegression()\nsclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n                          meta_classifier=lr)\n\nprint('3-fold cross validation:\\n')\n\nfor clf, label in zip([clf1, clf2, clf3, sclf], \n                      ['KNN', \n                       'Random Forest', \n                       'Naive Bayes',\n                       'StackingClassifier']):\n\n    cv = StratifiedKFold(n_splits=10, random_state=123, shuffle=True)\n    scores = model_selection.cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n    predicted = model_selection.cross_val_predict(clf,X_test,y_test,cv=cv) \n    test_scores = accuracy_score(y_test, predicted)    \n\n    print(\"Train Accuracy: %0.2f (+\/- %0.2f) [%s]\" \n          % (scores.mean(), scores.std(), label))\n   # print(\"Test Accuracy: %0.2f (+\/- %0.2f) [%s]\" \n         # % (test_scores.mean(),scores.std(),label))\n    print (\"Test accuracy\",accuracy_score(y_test, predicted))\n    print (\"classification_report\", classification_report(y_test, predicted))\n","93032ada":"def validationset(train,test,y):\n    folds=StratifiedKFold(n_splits=2,shuffle = True,random_state=123)\n    test_pred=np.empty((test.shape[0],1),float)\n    train_pred=np.empty((0,1),float)\n    for train_indices,val_indices in folds.split(train,y.values):\n        X_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n    return X_train,x_val,y_train,y_val","1c0aed0c":"X_train,x_val,y_train,y_val = validationset(X_train,X_test,y_train)\n    \nblend_model_DT = DecisionTreeClassifier(random_state=123)\nblend_model_DT.fit(X_train, y_train)\nval_pred_dt=blend_model_DT.predict(x_val)\ntest_pred_dt=blend_model_DT.predict(X_test)\nval_pred_dt=pd.DataFrame(val_pred_dt)\ntest_pred_dt=pd.DataFrame(test_pred_dt)\nprint(val_pred_dt.shape,test_pred_dt.shape)\n\nblend_model_KNN = KNeighborsClassifier()\nblend_model_KNN.fit(X_train,y_train)\nval_pred_knn=blend_model_KNN.predict(x_val)\ntest_pred_knn=blend_model_KNN.predict(X_test)\nval_pred_knn=pd.DataFrame(val_pred_knn)\ntest_pred_knn=pd.DataFrame(test_pred_knn)\nprint(val_pred_knn.shape,test_pred_knn.shape)","96e02344":"print(val_pred_dt.shape,val_pred_knn.shape)\nprint(test_pred_dt.shape,test_pred_knn.shape)\ndf_val=pd.concat([val_pred_dt,val_pred_knn],axis=1)\ndf_test=pd.concat([test_pred_dt,test_pred_knn],axis=1)\n\nprint(df_val.shape,df_test.shape)\nmodel = LogisticRegression()\nmodel.fit(df_val,y_val)\nmodel.score(df_test,y_test)","49f73910":"Image(\"..\/input\/loanpaymentimage\/Staking_Flow.PNG\")","8b9ecdbe":"Image(\"..\/input\/loanpaymentimage\/Blending_Flow.PNG\")","3a172522":"* [Table of Contents](#Tableofcontents)\n<a id=\"EnsembleIntroduction\"><\/a>\n# Ensemble Introduction\n\n## What is Ensemble Learning\n**Wikipedia Defination:** Ensemble learning is a type of machine learning that studies algorithms and architectures that build collections, or ensembles, of statistical classifiers that are more accurate than a single classifier.\n                                                            (or)\nIn statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.\n\nLet\u2019s understand the concept of ensemble learning with an example. Suppose you are a movie director and you have created a short movie on a very important and interesting topic. Now, you want to take preliminary feedback (ratings) on the movie before making it public. What are the possible ways by which you can do that?\n\nA: You may ask one of your friends to rate the movie for you.\n\nNow it\u2019s entirely possible that the person you have chosen loves you very much and doesn\u2019t want to break your heart by providing a 1-star rating to the horrible work you have created.\n\nB: Another way could be by asking 5 colleagues of yours to rate the movie.\n\nThis should provide a better idea of the movie. This method may provide honest ratings for your movie. But a problem still exists. These 5 people may not be \u201cSubject Matter Experts\u201d on the topic of your movie. Sure, they might understand the cinematography, the shots, or the audio, but at the same time may not be the best judges of dark humour.\n\nC: How about asking 50 people to rate the movie?\n\nSome of which can be your friends, some of them can be your colleagues and some may even be total strangers.\n\nThe responses, in this case, would be more generalized and diversified since now you have people with different sets of skills. And as it turns out \u2013 this is a better approach to get honest ratings than the previous cases we saw.\n\nWith these examples, you can infer that a diverse group of people are likely to make better decisions as compared to individuals. Similar is true for a diverse set of models in comparison to single models. This diversification in Machine Learning is achieved by a technique called Ensemble Learning.","b8d167ad":"<a id=\"Tableofcontents\"><\/a>\n# Table of Contents\n\n* [Introduction](#Introduction)\n* [EDA](#EDA)\n* [Data Visualizations](#DataVisualizations)\n* [Feature Engineering](#FeatureEngineering)\n* [Train and Test Split](#TrainandTestSplit)\n* [SMOTE to Balance Data](#SMOTE)\n* [Ensemble Introduction](#EnsembleIntroduction)\n* [Stacking Introduction](#StackingIntroduction)\n* [Stacking Method 1](#StackingMethod1)\n* [Stacking Method 2](#StackingMethod2)\n* [Stacking Method 3](#StackingMethod3)\n* [Blending](#Blending)\n* [Stacking and Blending Flows](#StackingandBlendingFlow)\n* [References](#References)\n","0aab1fcf":"* [Table of Contents](#Tableofcontents)\n<a id=\"DataVisualizations\"><\/a>\n\n# Data Visualizations","ee02b002":"* [Table of Contents](#Tableofcontents)\n<a id=\"StackingandBlendingFlow\"><\/a>\n# Stacking and Blending Flows:","cf9d8014":"Stacking is an ensemble learning technique that uses predictions from multiple models (for example decision tree, knn or svm) to build a new model. This model is used for making predictions on the test set. \n\n1. The train set is split into 10 parts.\n2. A base model (suppose a decision tree) is fitted on 9 parts and predictions are made for the 10th part. This is done for each part of the train set.\n3. The base model (in this case, decision tree) is then fitted on the whole train dataset\n4. Using this model, predictions are made on the test set.\n5. Steps 2 to 4 are repeated for another base model (say knn) resulting in another set of predictions for the train set and test set.\n6. The predictions from the train set are used as features to build a new model.\n7. This model is used to make final predictions on the test prediction set.","2485ccaa":"* [Table of Contents](#Tableofcontents)\n<a id=\"FeatureEngineering\"><\/a>\n# Feature Engineering","a25e7308":"* [Table of Contents](#Tableofcontents)\n<a id=\"StackingIntroduction\"><\/a>\n# Stacking","a94ddfea":"### Main intension of developing this project is to understand the Ensemble Technique Stacking and Blending concepts. Used 3 different methods of Stacking coding techniques to understand the accuracy for the multi classification problem with Loan Payment Dataset.\n\n#### Happy Learning!!!","fe8c05d9":"* [Table of Contents](#Tableofcontents)\n<a id=\"Blending\"><\/a>\n## Blending","0d59896f":"Blending follows the same approach as stacking but uses only a holdout (validation) set from the train set to make predictions. In other words, unlike stacking, the predictions are made on the holdout set only. The holdout set and the predictions are used to build a model which is run on the test set. \n\n1. The train set is split into training and validation sets.\n2. Model(s) are fitted on the training set.\n3. The predictions are made on the validation set and the test set.\n4. The validation set and its predictions are used as features to build a new model.\n5. This model is used to make final predictions on the test and meta-features.","f115f1e7":"* [Table of Contents](#Tableofcontents)\n<a id=\"SMOTE\"><\/a>\n# SMOTE to Balance Data","99bcf27e":"* [Table of Contents](#Tableofcontents)\n<a id=\"EDA\"><\/a>\n\n# EDA","7e8a0526":"* [Table of Contents](#Tableofcontents)\n<a id=\"StackingMethod2\"><\/a>\n# Stacking Method 2","a2cdccad":"* [Table of Contents](#Tableofcontents)\n<a id=\"References\"><\/a>\n# References:\n1. https:\/\/www.analyticsvidhya.com\/blog\/2018\/06\/comprehensive-guide-for-ensemble-models\/\n2. https:\/\/www.geeksforgeeks.org\/stacking-in-machine-learning\/\n3. https:\/\/www.mygreatlearning.com\/blog\/ensemble-learning\/\n4. http:\/\/rasbt.github.io\/mlxtend\/user_guide\/classifier\/StackingClassifier\/\n5. https:\/\/machinelearningmastery.com\/stacking-ensemble-machine-learning-with-python\/\n6. https:\/\/www.programcreek.com\/python\/example\/91159\/sklearn.model_selection.cross_val_predict\n7. https:\/\/stackoverflow.com\/questions\/41458834\/how-is-scikit-learn-cross-val-predict-accuracy-score-calculated","1e48a431":"* [Table of Contents](#Tableofcontents)\n<a id=\"Introduction\"><\/a>\n# Introduction\n### Domain : Banking\n\n### Dataset: Loan Payment data\n\n### Attributes:\n\n1. Loan_id : A unique loan number assigned to each loan customers\n2. Loan_status: Whether a loan is paid off, in collection, new customer yet to payoff, or paid off after the collection efforts\n3. Principal: Basic principal loan amount at the origination terms, could be weekly (7 days), biweekly, and monthly payoff schedule\n4. effective_date: When the loan got originated and took effects\n5. due_date: Since it\u2019s one-time payoff schedule, each loan has one single due date\n6. paidoff_time: The actual time a customer pays off the loan\n7. pastdue_days: How many days a loan has been past due age, education, Gender: A customer\u2019s basic demographic information","45fa2682":"* [Table of Contents](#Tableofcontents)\n<a id=\"TrainandTestSplit\"><\/a>\n# Train and Test Split","fe8da262":"* [Table of Contents](#Tableofcontents)\n<a id=\"StackingMethod3\"><\/a>\n# Stacking Method 3","5a8146be":"Model Training and Predictions","32dcaffa":"* [Table of Contents](#Tableofcontents)\n<a id=\"StackingMethod1\"><\/a>\n# Stacking Method 1"}}