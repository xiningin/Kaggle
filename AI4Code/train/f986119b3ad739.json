{"cell_type":{"d0139f13":"code","8a12c9e9":"code","77ecd294":"code","fe4fb8cd":"code","b0b8b1cf":"code","f80084de":"code","e6b1742d":"code","86b2971e":"code","723bc630":"code","206c66f3":"code","dc7c19a3":"code","18387985":"code","66942788":"code","9f9a0ff9":"code","2d959003":"code","f8b2f067":"code","b053f22e":"code","4e438866":"code","998b3a60":"markdown","a6dd2efe":"markdown","b50fd1f9":"markdown"},"source":{"d0139f13":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" if torch.cuda.is_available() \n                 else \"cpu\")","8a12c9e9":"class TData(tds):\n    def __init__(self,X,y):   \n        self.X=torch.tensor(X,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        train_img,train_lbl=self.X[index],self.y[index]\n        return train_img,train_lbl\n    def __len__(self):\n        return self.y.shape[0]\ndef model_acc(model,data_loader):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs=model(features)\n        _,pred_labels=torch.max(probs,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()\/num_examples*100","77ecd294":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.to(dev)\n            targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnnf.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%300:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)\/\/batch_size,cost))           \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train accuracy: %.2f%%'%\\\n                  (epoch+1,epochs,model_acc(model,train_loader)))\n@register_line_magic\ndef print_acc(t):\n    if t=='test':\n        print('Test accuracy: %.4f%%'%\\\n        (model_acc(model,test_loader)))\n    if t=='train':\n        print('Train accuracy: %.4f%%'%\\\n        (model_acc(model,train_loader)))","fe4fb8cd":"@register_line_magic\ndef train_run2(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.to(dev)\n            targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnnf.cross_entropy(logits,targets)\n            optimizer2.zero_grad(); cost.backward()\n            optimizer2.step()\n            if not batch_ids%300:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)\/\/batch_size,cost))           \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train accuracy: %.2f%%'%\\\n                  (epoch+1,epochs,model_acc(model,train_loader)))\n@register_line_magic\ndef print_acc2(t):\n    if t=='test':\n        print('Test accuracy: %.4f%%'%\\\n        (model_acc(model,test_loader)))\n    if t=='train':\n        print('Train accuracy: %.4f%%'%\\\n        (model_acc(model,train_loader)))","b0b8b1cf":"@register_line_magic\ndef train_run3(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        for batch_ids,(features,targets) in enumerate(train_loader2):        \n            features=features.to(dev)\n            targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnnf.cross_entropy(logits,targets.long())\n            optimizer3.zero_grad(); cost.backward()\n            optimizer3.step()\n            if not batch_ids%100:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train2)\/\/batch_size2,cost))           \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train accuracy: %.2f%%'%\\\n                  (epoch+1,epochs,model_acc(model,train_loader2)))\n@register_line_magic\ndef print_acc3(t):\n    if t=='test':\n        print('Test accuracy: %.4f%%'%\\\n        (model_acc(model,test_loader2)))\n    if t=='train':\n        print('Train accuracy: %.4f%%'%\\\n        (model_acc(model,train_loader2)))","f80084de":"random_seed=23; batch_size=128\ntrain=tmnist(root='data',train=True,download=True,\n            transform=transforms.ToTensor())\ntest=tmnist(root='data',train=False, \n            transform=transforms.ToTensor())\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","e6b1742d":"for images,labels in train_loader:  \n    print('Image dimensions: %s'%str(images.shape))\n    print('Label dimensions: %s'%str(labels.shape))\n    n=np.random.randint(1,50)\n    fig=pl.figure(figsize=(11,4))\n    for i in range(n,n+5):\n        ax=fig.add_subplot(1,5,i-n+1,\\\n        xticks=[],yticks=[],title=labels[i])\n        ax.imshow((images[i]).reshape(28,28),\n                  cmap=pl.cm.bone)\n    break","86b2971e":"fpath='..\/input\/classification-of-handwritten-letters\/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')\/255\nx=(np.dot(x,[.299,.587,.114])).reshape(-1,1,32,32)\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.2*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_train=x[:n],x[n:]\ny_test,y_train=y[:n],y[n:]\nx_train.shape,y_train.shape\nfig=pl.figure(figsize=(11,4))\nn=np.random.randint(1,50)\nfor i in range(n,n+5):\n    ax=fig.add_subplot(1,5,i-n+1,\\\n    xticks=[],yticks=[],title=y_test[i])\n    ax.imshow((x_test[i].reshape(32,32)),\n              cmap=pl.cm.bone)","723bc630":"random_seed=1; batch_size2=128\ntrain2=TData(x_train,y_train)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,batch_size=batch_size2,shuffle=True)\ntest_loader2=tdl(dataset=test2,batch_size=batch_size2,shuffle=False)\nfor images,labels in train_loader2:  \n    print('Image dimensions: %s'%str(images.shape))\n    print('Label dimensions: %s'%str(labels.shape))\n    break","206c66f3":"class CNN(torch.nn.Module):\n    def __init__(self,num_classes):\n        super(CNN,self).__init__()\n        # 28x28x1 => 28x28x8; (1*(28-1)-28+3)\/2=1\n        self.conv1=torch.nn\\\n        .Conv2d(in_channels=1,out_channels=8,\n                kernel_size=(3,3),\n                stride=(1,1),padding=1)\n        # 28x28x8 => 14x14x8; (2*(14-1)-28+2)=0 \n        self.pool1=torch.nn\\\n        .MaxPool2d(kernel_size=(2,2),\n                   stride=(2,2),padding=0)                                      \n        # 14x14x8 => 14x14x16; (1*(14-1)-14+3)\/2=1\n        self.conv2=torch.nn\\\n        .Conv2d(in_channels=8,out_channels=16,\n                kernel_size=(3,3),\n                stride=(1,1),padding=1)                \n        # 14x14x16 => 7x7x16; (2*(7-1)-14+2)=0                            \n        self.pool2=torch.nn\\\n        .MaxPool2d(kernel_size=(2,2),\n                   stride=(2,2),padding=0)\n        self.linear1=torch.nn.Linear(7*7*16,num_classes)\n        for m in self.modules():\n            if isinstance(m,torch.nn.Conv2d) or \\\n            isinstance(m,torch.nn.Linear):\n                m.weight.data.normal_(0.,.01)\n                m.bias.data.zero_()\n                if m.bias is not None:\n                    m.bias.detach().zero_()\n    def forward(self,x):\n        y=self.conv1(x); y=tnnf.relu(y)\n        y=self.pool1(y)\n        y=self.conv2(y); y=tnnf.relu(y)\n        y=self.pool2(y)        \n        logits=self.linear1(y.view(-1,7*7*16))\n        probs=tnnf.softmax(logits,dim=1)\n        return logits,probs\ntorch.manual_seed(random_seed)\nnum_classes=10; learning_rate=.1\nmodel=CNN(num_classes=num_classes)\nmodel=model.to(dev)\noptimizer=torch.optim\\\n.SGD(model.parameters(),lr=learning_rate)  ","dc7c19a3":"%train_run 30","18387985":"%print_acc train\n%print_acc test","66942788":"class CNN2(torch.nn.Module):\n    def __init__(self,num_classes):\n        super(CNN2,self).__init__()\n        # 28x28x1 => 28x28x16; (1*(28-1)-28+5)\/2=2\n        self.conv1=torch.nn\\\n        .Conv2d(in_channels=1,out_channels=16,\n                kernel_size=(5,5),\n                stride=(1,1),padding=2)\n        # 28x28x16 => 14x14x16; (2*(14-1)-28+2)=0 \n        self.pool1=torch.nn\\\n        .MaxPool2d(kernel_size=(2,2),\n                   stride=(2,2),padding=0)                                      \n        # 14x14x16 => 14x14x256; (1*(14-1)-14+5)\/2=2\n        self.conv2=torch.nn\\\n        .Conv2d(in_channels=16,out_channels=256,\n                kernel_size=(5,5),\n                stride=(1,1),padding=2)                \n        # 14x14x256 => 7x7x256; (2*(7-1)-14+2)=0                            \n        self.pool2=torch.nn\\\n        .MaxPool2d(kernel_size=(2,2),\n                   stride=(2,2),padding=0)\n        self.linear1=torch.nn.Linear(7*7*256,256)\n        self.linear2=torch.nn.Linear(256,num_classes)\n    def forward(self,x):\n        y=self.conv1(x); y=tnnf.relu(y)\n        y=self.pool1(y)\n        y=self.conv2(y); y=tnnf.relu(y)\n        y=self.pool2(y)\n        y=y.view(-1,7*7*256)\n        y=self.linear1(y)\n        y=tnnf.relu(y)\n        logits=self.linear2(y)\n        probs=tnnf.softmax(logits,dim=1)\n        return logits,probs\ntorch.manual_seed(random_seed)\nnum_classes=10; learning_rate=.05\nmodel=CNN2(num_classes=num_classes)\nmodel=model.to(dev)\noptimizer2=torch.optim\\\n.SGD(model.parameters(),lr=learning_rate,momentum=.9) ","9f9a0ff9":"%train_run2 7","2d959003":"%print_acc2 train\n%print_acc2 test","f8b2f067":"class CNN3(torch.nn.Module):\n    def __init__(self,num_classes):\n        super(CNN3,self).__init__()\n        # 32x32x1 => 32x32x32; (1*(32-1)-32+5)\/2=2\n        self.conv1=torch.nn\\\n        .Conv2d(in_channels=1,out_channels=32,\n                kernel_size=(5,5),\n                stride=(1,1),padding=2)\n        # 32x32x32 => 16x16x32; (2*(16-1)-32+2)=0 \n        self.pool1=torch.nn\\\n        .MaxPool2d(kernel_size=(2,2),\n                   stride=(2,2),padding=0)                                      \n        # 16x16x32 => 16x16x196; (1*(16-1)-16+5)\/2=2\n        self.conv2=torch.nn\\\n        .Conv2d(in_channels=32,out_channels=196,\n                kernel_size=(5,5),\n                stride=(1,1),padding=2)                \n        # 16x16x196 => 8x8x196; (2*(8-1)-16+2)=0                            \n        self.pool2=torch.nn\\\n        .MaxPool2d(kernel_size=(2,2),\n                   stride=(2,2),padding=0)\n        self.linear1=torch.nn.Linear(8*8*196,1024)\n        self.linear2=torch.nn.Linear(1024,num_classes)\n#        for m in self.modules():\n#            if isinstance(m,torch.nn.Conv2d):\n#                torch.nn.init.kaiming_normal_(m.weight.detach())\n#                m.bias.detach().zero_()\n#            elif isinstance(m,torch.nn.Linear):\n#                torch.nn.init.kaiming_normal_(m.weight.detach())\n#                m.bias.detach().zero_()\n    def forward(self,x):\n        y=self.conv1(x); y=tnnf.relu(y)\n        y=self.pool1(y)\n        y=self.conv2(y); y=tnnf.relu(y)\n        y=self.pool2(y)\n        y=y.view(-1,8*8*196)\n        y=self.linear1(y)\n        y=tnnf.relu(y)\n        logits=self.linear2(y)\n        probs=tnnf.softmax(logits,dim=1)\n        return logits,probs\ntorch.manual_seed(random_seed)\nnum_classes=33; learning_rate=.05\nmodel=CNN3(num_classes=num_classes)\nmodel=model.to(dev)\noptimizer3=torch.optim\\\n.SGD(model.parameters(),lr=learning_rate,momentum=.9) ","b053f22e":"%train_run3 30","4e438866":"%print_acc3 train\n%print_acc3 test","998b3a60":"Reading classics [Deep Learning Models](https:\/\/nbviewer.jupyter.org\/github\/rasbt\/deeplearning-models\/blob\/master\/pytorch_ipynb\/cnn\/cnn-basic.ipynb)\n\n## Code Modules & Functions","a6dd2efe":"## Data","b50fd1f9":"## Simple CNN"}}