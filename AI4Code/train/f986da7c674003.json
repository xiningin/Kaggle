{"cell_type":{"d3606699":"code","e4785c84":"code","bee9bc4f":"code","8752e62a":"code","f8def5a0":"code","04f4d791":"code","87b7ab4e":"code","f59f4402":"code","dce49d9d":"code","5d71e936":"code","20c7776a":"code","7587c404":"markdown","ea2e51f3":"markdown","79e3eeb0":"markdown"},"source":{"d3606699":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\nfrom sklearn.model_selection import GroupKFold\nimport os\nimport random\n\n\nfrom tqdm import tqdm\nfrom random import choices\n\nimport kerastuner as kt","e4785c84":"from janestreet_utils import *","bee9bc4f":"%%time\nFOLDS = 5\nSEED = 1111\nTRAINING = True\nUSE_FINETUNE = True\nFILE_NAME = 'jane-street-market-prediction'\n\nprint('FOLDS : {}\\nSEED : {}\\nTRAINING : {}\\nUSE_FINETUNE : {}\\nFILE_NAME : {}'.format(FOLDS, SEED, TRAINING,\n                                                                                       USE_FINETUNE, FILE_NAME))","8752e62a":"def check_random(SEED=SEED):\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['PYTHONHASHSEED']=str(SEED)\n    random.seed(SEED)\n    np.random.seed(SEED)\n    tf.random.set_seed(SEED)\n\n\ncheck_random()","f8def5a0":"train = dt.fread('..\/input\/jane-street-market-prediction\/train.csv').to_pandas()","04f4d791":"train = train.query('date > 85').reset_index(drop = True) \ntrain = train[train['weight'] != 0]\n\ntrain.fillna(train.mean(),inplace=True)\n\ntrain['action'] = ((train['resp'].values) > 0).astype(int)\n\n\nfeatures = [c for c in train.columns if \"feature\" in c]\n\nf_mean = np.mean(train[features[1:]].values,axis=0)\n\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\n\ny_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T","87b7ab4e":"def create_mlp(\n    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n):\n\n    inp = tf.keras.layers.Input(shape=(num_columns,))\n    inp_1 = tf.keras.backend.square(inp)\n#     inp_2 = tf.keras.backend.cos(inp)\n    \n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n\n    x_1 = tf.keras.layers.BatchNormalization()(inp_1)\n    x_1 = tf.keras.layers.Dropout(dropout_rates[0])(x_1)\n    for i in range(len(hidden_units)):\n        x_1 = tf.keras.layers.Dense(hidden_units[i])(x_1)\n        x_1 = tf.keras.layers.BatchNormalization()(x_1)\n        x_1 = tf.keras.layers.Activation(tf.keras.activations.swish)(x_1)\n        x_1 = tf.keras.layers.Dropout(dropout_rates[i + 1])(x_1)\n    \n    x = tf.keras.layers.Concatenate(axis=-1)([x, x_1])\n\n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n    )\n\n    return model","f59f4402":"# batch_size = 5000\n# hidden_units = [160, 160, 160]\n# dropout_rates = [0.25, 0.25, 0.25, 0.25]\n# label_smoothing = 1e-2\n# learning_rate = 1e-3 \n\nbatch_size = 5000\nhidden_units = [150, 150, 150]\ndropout_rates = [0.20, 0.20, 0.20, 0.20]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3\n\nclf = create_mlp(\n    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n    )\nclf.summary()","dce49d9d":"check_random()\nclf.fit(X_train, y_train, epochs=200, batch_size=5000)","5d71e936":"models = []\n\nmodels.append(clf)\n\nth = 0.5000\nprint(th)","20c7776a":"print('predict')\nf = np.median\nmodels = models[-3:]\nimport janestreet\nenv = janestreet.make_env()\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n        pred = f(pred)\n        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","7587c404":"# Load data","ea2e51f3":"# import","79e3eeb0":"# Submission"}}