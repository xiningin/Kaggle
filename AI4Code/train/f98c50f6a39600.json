{"cell_type":{"6f34bc58":"code","54722320":"code","ec208091":"code","e597516d":"code","2ac22a84":"code","89f5a6ab":"code","5c08a41b":"code","316b54e6":"code","6913e388":"code","5cba2254":"code","0ae96d2b":"code","679a6e4d":"code","f318d86c":"code","52b55f59":"code","b8bc1159":"code","6bec5de3":"code","75f700f8":"code","d08e139f":"code","cf148c4d":"code","67a4b368":"code","553f3112":"code","4fcc2c12":"code","50886de5":"code","0539bf98":"code","536cb640":"code","a54411b1":"code","add69c2f":"code","2d29e735":"code","081a54a8":"code","462f8370":"code","30417036":"code","64b8da30":"code","35921294":"code","28cd16b4":"code","faffff0f":"code","d550cbe8":"code","d32c1414":"markdown","d6882ea3":"markdown","0afa1003":"markdown","50448d52":"markdown","ec274ddb":"markdown","664b2ace":"markdown","b466c319":"markdown","fa47dc0c":"markdown","d61dabf8":"markdown","79426dc8":"markdown","4bfbe3c0":"markdown","2e1668c9":"markdown","a5a4732b":"markdown","2c037077":"markdown","d8940151":"markdown","392f014d":"markdown","3a04d6c9":"markdown","090c2463":"markdown","2f50b1a6":"markdown","ea222f20":"markdown","109453a5":"markdown","30203ec3":"markdown","d52c56ed":"markdown","bdd9348a":"markdown","fe253b23":"markdown","26456f96":"markdown","ee96ac5e":"markdown","b3807a13":"markdown","cfb65d06":"markdown","a15ac2bd":"markdown","f6964d67":"markdown","0da9f0b9":"markdown","8aa069e7":"markdown","7f6d7ada":"markdown"},"source":{"6f34bc58":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport datetime as dt\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor","54722320":"df = pd.read_csv('\/kaggle\/input\/appliances-energy-prediction-data-set\/energydata_complete.csv')\ndf.head()","ec208091":"df.isnull().sum()","e597516d":"df.describe()","2ac22a84":"# Downcast in order to save memory\ndef downcast(df):\n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            df[cols[i]] = pd.to_datetime(df[cols[i]], format='%d-%m-%Y %H:%M')\n    return df\n                \ndf = downcast(df)","89f5a6ab":"# make a copy of df that we can modify and explore\n# we will also use 1\/8 of the data for some EDA since to better identify trends\n# 19735 rows in total, so we want 19735\/8 ~= 2467 rows (2 weeks)\nedadf = df.copy()\nedadfsmall = df[0:2467].copy()","5c08a41b":"fig = px.line(edadf, x='date', y=edadf.columns[:], title='All Features over time')\nfig.show()","316b54e6":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=edadfsmall['date'], y=edadfsmall['Appliances'], \n               name=\"Appliances\",\n               mode='lines'),\n    secondary_y=False,\n)\n\n\n\nfig.add_trace(\n    go.Scatter(x=edadfsmall['date'], y=edadfsmall['lights'], \n               name='lights',\n               mode='lines'),\n    secondary_y=True,\n)\n\nfig.update_layout(\n    title='Appliance and Light usage over two weeks',\n    xaxis_title=\"Date\")\n    \nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", secondary_y=False, color=\"blue\")\nfig.update_yaxes(title_text=\"Lights Usage (in Wh)\", secondary_y=True, color=\"red\")\n    \nfig.show()","6913e388":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=edadfsmall['date'], y=edadfsmall['Appliances'], \n               name=\"Appliances\",\n               mode='lines'),\n    secondary_y=False,\n)\ntempcolumns = ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T_out']\n\nfor i in tempcolumns:\n    fig.add_trace(\n        go.Scatter(x=edadfsmall['date'], y=edadfsmall[i], \n                   name=i,\n                   mode='lines'),\n        secondary_y=True,\n    )\n\nfig.update_layout(\n    title='Appliance usage and Temperature over two weeks',\n    xaxis_title=\"Date\")\n    \nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", secondary_y=False, color=\"blue\")\nfig.update_yaxes(title_text=\"Temperature (in Celsius)\", secondary_y=True)    \n    \nfig.show()","5cba2254":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=edadfsmall['date'], y=edadfsmall['Appliances'], \n               name=\"Appliances\",\n               mode='lines'),\n    secondary_y=False,\n)\nhumiditycolumns = ['RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'RH_out']\n\nfor i in humiditycolumns:\n    fig.add_trace(\n        go.Scatter(x=edadfsmall['date'], y=edadfsmall[i], \n                   name=i,\n                   mode='lines'),\n        secondary_y=True,\n    )\n\nfig.update_layout(\n    title='Appliance usage and Humidity over two weeks',\n    xaxis_title=\"Date\")\n    \nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", secondary_y=False, color=\"blue\")\nfig.update_yaxes(title_text=\"humidity (in %)\", secondary_y=True)    \n    \nfig.show()","0ae96d2b":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=edadfsmall['date'], y=edadfsmall['Appliances'], \n               name=\"Appliances\",\n               mode='lines'),\n    secondary_y=False,\n)\nhumiditycolumns = ['T_out', 'Press_mm_hg', 'RH_out', 'Windspeed', 'Visibility', 'Tdewpoint']\n\nfor i in humiditycolumns:\n    fig.add_trace(\n        go.Scatter(x=edadfsmall['date'], y=edadfsmall[i], \n                   name=i,\n                   mode='lines'),\n        secondary_y=True,\n    )\n    \nfig.update_layout(\n    title='Appliance and Outside Variables over two weeks',\n    xaxis_title=\"Date\")\n    \nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", secondary_y=False, color=\"blue\")\nfig.update_yaxes(title_text=\"Arbitrary values\", secondary_y=True)\n\nfig.show()","679a6e4d":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=edadfsmall['date'], y=edadfsmall['Appliances'], \n               name=\"Appliances\",\n               mode='lines'),\n    secondary_y=False,\n)\nhumiditycolumns = ['rv1', 'rv2']\n\nfor i in humiditycolumns:\n    fig.add_trace(\n        go.Scatter(x=edadfsmall['date'], y=edadfsmall[i], \n                   name=i,\n                   mode='lines'),\n        secondary_y=True,\n    )\n    \nfig.update_layout(\n    title='Appliance usage and Random variables over two weeks',\n    xaxis_title=\"Date\")\n    \nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", secondary_y=False, color=\"blue\")\nfig.update_yaxes(title_text=\"arbitrary value\", secondary_y=True)\n\nfig.show()","f318d86c":"fedf = df.copy()","52b55f59":"# create column to distinguish between day and night for plot\nedadfsmall['daytime'] = [1100 if i.hour < 24 and i.hour > 6 else 0 for i in edadfsmall['date']]\n\n# Create figure\nfig = make_subplots()\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=edadfsmall['date'], y=edadfsmall['Appliances'], \n               name=\"Appliances\",\n               mode='lines')\n)\n\nfig.add_trace(\n    go.Scatter(x=edadfsmall['date'], y=edadfsmall['daytime'],\n               name='daytime (7am - midnight)',\n               mode='none',\n               fill='tozeroy'))\n\nfig.update_layout(\n    title='Appliance usage during daytime over two weeks',\n    xaxis_title=\"Date\",\n    yaxis_range=(0, 1100)\n)\n    \nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", color=\"blue\")\nfig.show()","b8bc1159":"df['is_daytime'] = [1 if i.hour < 24 and i.hour > 6 else 0 for i in df['date']] # 1 if daytime, 0 if nighttime","6bec5de3":"# weekday column for plotting \nweekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nweekdaysnum = [0,1,2,3,4,5,6] # The day of the week with Monday=0 to Sunday=6 with pd.dayofweek\n\nfor a,b in zip(weekdays, weekdaysnum):  \n    fedf[a] = [1100 if i.dayofweek == b else 0 for i in fedf['date']]\n# Create figure\nfig = make_subplots()\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=fedf['date'], y=fedf['Appliances'], \n               name=\"Appliances\",\n               mode='lines')\n)\n\nfor i in weekdays:\n    fig.add_trace(\n        go.Scatter(x=fedf['date'], y=fedf[i],\n                   name=i,\n                   mode='none',\n                   fill='tozeroy'))\n\nfig.update_layout(\n    title='Appliance per weekday overtime',\n    xaxis_title=\"Date\",\n    yaxis_range=(0, 1100)\n)\nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", color=\"blue\")\n\nfig.show()","75f700f8":"# Heatmap\n\n# weekday column \nfedf['weekday'] = [i.dayofweek for i in fedf['date']] # The day of the week with Monday=0 to Sunday=6.\n\nfor a,b in zip(weekdays, weekdaysnum):\n    fedf['weekday'] = fedf['weekday'].replace(b, a)\n\n# weeknum column\nfedf['week'] = fedf['date'].dt.isocalendar().week\n\nheatdf = pd.DataFrame(fedf.groupby(['week', 'weekday'])['Appliances'].sum()).reset_index()\n\n# Create figure\nfig = make_subplots()\n\nfig.add_trace(\n    go.Heatmap(x=heatdf['week'], y=heatdf['weekday'], z=heatdf['Appliances'],\n               colorbar=dict(title='Appliance Usage (in Wh)'))\n)\n\nfig.update_layout(\n    title='Total Appliance usage per weekday',\n    xaxis_title=\"Week # in the year\",\n    yaxis={'categoryarray': weekdays}\n)\n\nfig.update_yaxes(title_text=\"Weekday\")\n\nfig.show()","d08e139f":"# The day of the week with Monday=0 to Sunday=6.\ndf['weekday'] = [i.dayofweek for i in df['date']]","cf148c4d":"# week or weekend column for plotting\nweekorweekend = ['weekday', 'weekend']\nweeknums = [[0,1,2,3,4], [5,6]]\n\nfor a,b in zip(weekorweekend, weeknums):\n    fedf[a] = [1100 if i.dayofweek in b else 0 for i in fedf['date']]\n\n# Create figure\nfig = make_subplots()\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=fedf['date'], y=fedf['Appliances'], \n               name=\"Appliances\",\n               mode='lines')\n)\n\nfor i in weekorweekend:\n    fig.add_trace(\n        go.Scatter(x=fedf['date'], y=fedf[i],\n                   name=i,\n                   mode='none',\n                   fill='tozeroy'))\n\nfig.update_layout(\n    title='Appliance usage per weekday and weekend overtime',\n    xaxis_title=\"Date\",\n    yaxis_range=(0, 1100)\n)\nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", color=\"blue\")\nfig.show()","67a4b368":"# Heatmap\n\n# weekday column \nfedf['is_weekday'] = ['Weekday' if i.dayofweek in weeknums[0] else 'Weekend' for i in fedf['date']]\n\n# weekend column\nfedf['week'] = fedf['date'].dt.isocalendar().week\n\n# must standardize weekday and weekend columns (To evenly compare 5 days and 2 days of appliance usage)\nfedf['stdappliances'] = fedf['Appliances']\nmask1 = fedf['is_weekday'] == 'Weekday'\nmask2 = fedf['is_weekday'] == 'Weekend'\nfedf.loc[mask1, 'stdappliances'] = fedf['Appliances'].mask(mask1, fedf['Appliances'] * (2\/7))\nfedf.loc[mask2, 'stdappliances'] = fedf['Appliances'].mask(mask2, fedf['Appliances'] * (5\/7))\n\n# heatmap\nheatdf = pd.DataFrame(fedf.groupby(['week', 'is_weekday'])['stdappliances'].sum()).reset_index()\n\n# Create figure\nfig = make_subplots()\n\nfig.add_trace(\n    go.Heatmap(x=heatdf['week'], y=heatdf['is_weekday'], z=heatdf['stdappliances'],\n               colorbar=dict(title='Appliance Usage (in Wh)'\n               )))\n\nfig.update_layout(\n    title='Total Appliance usage per Weekend and Weekday',\n    xaxis_title=\"Week # in the year\"\n)\n\nfig.show()","553f3112":"# is_weekday with weekday=1 and weekend=0\ndf['is_weekday'] = [1 if i.dayofweek in weeknums[0] else 0 for i in df['date']]","4fcc2c12":"df['logappliances'] = df['Appliances'].apply(lambda x: np.log2(x+1))\n\nfig, ax = plt.subplots(1,2, figsize=(16,6))\n\nsns.histplot(x='Appliances', data=df, binwidth=20, ax=ax[0])\nsns.histplot(x='logappliances', data=df, binwidth=0.5, ax=ax[1])\n\nax[0].set_title('Appliance Usage Distribution')\nax[1].set_title('LogAppliance Usage Distribution')\n\nplt.show()\n","50886de5":"df['weekday_appliance_avg'] = df.groupby('weekday')['logappliances'].transform('mean').astype(np.float16)","0539bf98":"# Introduce lags\n# Note every consecutive data point is a 10 min difference\n# Lets choose 10min, 30min, 60(1 hour), 180(3 hours), 360(6 hours), 1440(1 day)\nlags = [1,3,6,18,36,144]\nfor lag in lags:\n    df['logappliances_lag_'+str(lag)] = df['logappliances'].shift(lag).astype(np.float16)\n    \n# remove null values created by lag\ndf = df.iloc[144:]","536cb640":"# Break down date to month, day of month, hour, minute and day of year(to ID and split the data)\ndf['month'] = df['date'].dt.month\ndf['day_of_month'] = df['date'].dt.day\ndf['hour'] = df['date'].dt.hour\ndf['minute'] = df['date'].dt.minute\ndf['day_of_year'] = df['date'].dt.day_of_year\n\n# drop date\ndf = df.drop(columns=['date'], axis=1)","a54411b1":"df.info()","add69c2f":"dfm = df.drop(['Appliances'], axis=1) # replaced with logappliances","2d29e735":"# Split the data:\n# Training: First 108 days\n# Validation: day 109 - 122\n# Test: day 123 - 137\n\nX_train, y_train = dfm[dfm['day_of_year'] < 109].drop('logappliances', axis=1), dfm[dfm['day_of_year'] < 109]['logappliances']\nX_valid = dfm[(dfm['day_of_year']>= 109) & (dfm['day_of_year'] < 123)].drop('logappliances',axis=1)\ny_valid = dfm[(dfm['day_of_year']>= 109) & (dfm['day_of_year'] < 123)]['logappliances']\nX_test, y_test = dfm[dfm['day_of_year'] >= 123].drop('logappliances',axis=1), dfm[dfm['day_of_year'] >= 123]['logappliances']\n\n# drop day of year (acted as an id for each row to split data)\nX_train = X_train.drop(columns=['day_of_year'], axis=1)\nX_valid = X_valid.drop(columns=['day_of_year'], axis=1)\nX_test = X_test.drop(columns=['day_of_year'], axis=1)","081a54a8":"# Create lagless dataset\n\nlogcolumns = ['logappliances_lag_1', 'logappliances_lag_3',\n              'logappliances_lag_6', 'logappliances_lag_18', \n              'logappliances_lag_36', 'logappliances_lag_144']\n\nX_trainnolag = X_train.copy().drop(columns=logcolumns, axis=1)\nX_validnolag = X_valid.copy().drop(columns=logcolumns, axis=1)\nX_testnolag = X_test.copy().drop(columns=logcolumns, axis=1)","462f8370":"# create empty dataframe to hold model evaluations\n\nresults = pd.DataFrame(columns=['feature', 'model', 'train rmse', 'valid rmse'])\n\ndef addresult(feature, model, trainrmse, validrmse):\n    modelname = type(model).__name__\n    return {'feature':feature, 'model':modelname, 'train rmse':trainrmse, 'valid rmse':validrmse}","30417036":"# Train + Valdiate\n\nlbgm = LGBMRegressor()\nlbgm.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)],\n         eval_metric='rmse', verbose=None, early_stopping_rounds=20)\nlbgmresults = list(lbgm.best_score_.items())\nresults = results.append(addresult('lag', lbgm, lbgmresults[0][1]['rmse'], \n                                   lbgmresults[1][1]['rmse']), ignore_index=True)\n\n\nlbgmnolag = LGBMRegressor()\nlbgmnolag.fit(X_trainnolag, y_train, eval_set=[(X_trainnolag, y_train), (X_validnolag, y_valid)],\n              eval_metric='rmse', verbose=None, early_stopping_rounds=20)\nlbgmnolagresults = list(lbgmnolag.best_score_.items())\nresults = results.append(addresult('no lag', lbgmnolag, lbgmnolagresults[0][1]['rmse'], \n                                   lbgmnolagresults[1][1]['rmse']), ignore_index=True)\n\n\nmodels = [SVR(), RandomForestRegressor(random_state=1)]\n\ndef evalmodel(model, xtrain, ytrain, xvalid, yvalid):\n    mod = model\n    mod.fit(xtrain, ytrain)\n    rmsetrain = round(mean_squared_error(ytrain, mod.predict(xtrain), squared=False),3)\n    rmsevalid = round(mean_squared_error(yvalid, mod.predict(xvalid), squared=False),3)\n    return rmsetrain, rmsevalid\n\nfor i in models:\n    rmsetrain, rmsevalid = evalmodel(i, X_train, y_train, X_valid, y_valid)\n    results = results.append(addresult('lag', i, rmsetrain, rmsevalid), ignore_index=True)\n    rmsetrain, rmsevalid = evalmodel(i, X_trainnolag, y_train, X_validnolag, y_valid)\n    results = results.append(addresult('no lag', i, rmsetrain, rmsevalid), ignore_index=True)","64b8da30":"results","35921294":"lagrmse = mean_squared_error(y_test, lbgm.predict(X_test), squared=False)\nnolagrmse = mean_squared_error(y_test, lbgmnolag.predict(X_testnolag), squared=False)\n\nprint('LGBMRegressor \\nRMSE with lag feature: ' + str(round(lagrmse, 3)) + \n      '\\nRMSE with no lag feature: ' + str(round(nolagrmse,3)))","28cd16b4":"# get date data to combine with predictions\nedadf['day_of_year'] = edadf['date'].dt.day_of_year\nX_eda = edadf[edadf['day_of_year'] >= 123]['date']\n\n# convert prediction values from log2 transformation\n\ny_pred = lbgm.predict(X_test)\ny_pred = 2**(y_pred) - 1\n\ny_prednolag = lbgmnolag.predict(X_testnolag)\ny_prednolag = 2**(y_prednolag) - 1\n\npred = zip(X_eda, y_pred)\ntestpreds = pd.DataFrame(pred,\n                        columns=['date', 'testpred'] )\n\nprednolag = zip(X_eda, y_prednolag)\ntestpredsnolag = pd.DataFrame(prednolag,\n                        columns=['date', 'testpred'] )","faffff0f":"# Create figure\nfig = make_subplots(rows=2, cols=1,\n                    subplot_titles=('Predictions with lag feature', 'Predictions without lag feature')\n                   )\n\n# Add traces\n\nfig.add_trace(\n    go.Scatter(x=edadf['date'], y=edadf['Appliances'], \n               name=\"Appliances\",\n               mode='lines'),\n               row=1, col=1\n)\n\n\nfig.add_trace(\n    go.Scatter(x=testpreds['date'], y=testpreds['testpred'], \n               name='prediction',\n               mode='lines'),\n               row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=edadf['date'], y=edadf['Appliances'], \n               name=\"Appliances\",\n               mode='lines',\n               line=dict(color='blue')),\n               row=2, col=1\n)\n\n\nfig.add_trace(\n    go.Scatter(x=testpredsnolag['date'], y=testpredsnolag['testpred'], \n               name='no lag prediction',\n               mode='lines',\n               line=dict(color='#d62728')),\n               row=2, col=1\n)\n\nfig.update_layout(\n    title='Appliance usage Predictions',\n    yaxis_range=(0, 1100)\n)\nfig.update_yaxes(title_text=\"Appliance Usage (in Wh)\", color=\"blue\")\nfig.update_xaxes(title_text=\"Date\")\nfig.show()","d550cbe8":"# create dataframe for features and importance\nfeats = zip(X_train.columns, lbgm.feature_importances_)\n\nfeatimportance = pd.DataFrame(feats,\n                             columns = ['features', 'importance'])\n\nfeatsnolag = zip(X_trainnolag.columns, lbgmnolag.feature_importances_)\nfeatimportancenolag = pd.DataFrame(featsnolag,\n                             columns = ['features', 'importance'])\n\n# figure\nfig, ax = plt.subplots(1,2, figsize=(20,10))\n\nsns.barplot(x='importance', y='features', data=featimportance.sort_values(by='importance', ascending=False), ax=ax[0])\nsns.barplot(x='importance', y='features', data=featimportancenolag.sort_values(by='importance', ascending=False), ax=ax[1])\n\nax[0].set_title('feature importance with lag')\nax[1].set_title('feature importance without lag')\n\n\nplt.tight_layout()\nplt.show()","d32c1414":"lag features seems to contribute significantly to the model prediction","d6882ea3":"# EDA","0afa1003":"- Outside Temperature and Tdewpoint seem to correlate well\n    - The small fluctuations in temp and Tdewpoint represent day and night time. During daytime, the the temperature naturally rises with the sun as well as Tdewpoint. We can assume that the residents in the home are active during the daytime and so we see a correlation between appliance usage and temperature or Tdewpoint\n\n- There seems to be no other clear correlation or trend between outside conditions from the weather station and Appliance usage.","50448d52":"When T6 and T_out are filtered out, we can see that the temperature of the rest of the rooms spike up when appliance usage peaks.\n\nWhen Appliances, T6 and T_out are selected only, we can still see temperature spikes that very roughly follow along appliance usage.","ec274ddb":"Note that total appliance usages in weekend and weekday are standardized. \n- Weekday was multiplied by 2\/7\n- Weekend was multiplied by 5\/7\n\nCannot see any clear patterns or trends from the heatmap","664b2ace":"Thanks for getting to the end of my notebook. Comments and feedback are much appreciated!","b466c319":"# Appliances and Humidity","fa47dc0c":"### Distribution of Appliances (Target Variable)","d61dabf8":"Better with transformation, but visually still slightly skewed","79426dc8":"### Is Weekday","4bfbe3c0":"# Feature Engineering","2e1668c9":"# Appliances and Random Variables","a5a4732b":"We can see that there is almost no appliance usage during nighttime","2c037077":"- RandomForestRegressor is overfitting.\n- LBGMRegressor has the lowest validation set RMSE.","d8940151":"We can see that there are peaks of high appliance usage and low appliance usage. It seems like this is following a night time and daytime routine.\n\nLight usage matches well with appliance usage.","392f014d":"We don't see any obvious trends or patterns for particular weekdays","3a04d6c9":"# Modeling","090c2463":"# Downcasting\n\n- Downcast to save cpu resources\n- Note that there are only numerical features","2f50b1a6":"- RH5 is the bathroom, so it makes sense that the humidity spikes sharply due to the water from showering\/bathing.\n- RH5 spikes with appliance usage, but not all appliance usage spikes with RH5.\n- All other variables except RH_6 and RH_out (both are humidity outside) peak when appliance usage is low or not peaking.","ea222f20":"# Appliances and Lights","109453a5":"# Appliances and Temperatures","30203ec3":"# Mean encoding Weekday\n\nMean encoding is the conditioanl probability of your target variable based on each value of the feature. weekday is our only applicable categorical variable","d52c56ed":"# Test set ","bdd9348a":"### Attribute info:\n\n- date time year-month-day hour:minute:second\n- Appliances, energy use in Wh (target variable for prediction)\n- lights, energy use of light fixtures in the house in Wh\n- T1, Temperature in kitchen area, in Celsius\n- RH_1, Humidity in kitchen area, in %\n- T2, Temperature in living room area, in Celsius\n- RH_2, Humidity in living room area, in %\n- T3, Temperature in laundry room area\n- RH_3, Humidity in laundry room area, in %\n- T4, Temperature in office room, in Celsius\n- RH_4, Humidity in office room, in %\n- T5, Temperature in bathroom, in Celsius\n- RH_5, Humidity in bathroom, in %\n- T6, Temperature outside the building (north side), in Celsius\n- RH_6, Humidity outside the building (north side), in %\n- T7, Temperature in ironing room , in Celsius\n- RH_7, Humidity in ironing room, in %\n- T8, Temperature in teenager room 2, in Celsius\n- RH_8, Humidity in teenager room 2, in %\n- T9, Temperature in parents room, in Celsius\n- RH_9, Humidity in parents room, in %\n- To, Temperature outside (from Chievres weather station), in Celsius\n- Pressure (from Chievres weather station), in mm Hg\n- RH_out, Humidity outside (from Chievres weather station), in %\n- Wind speed (from Chievres weather station), in m\/s\n- Visibility (from Chievres weather station), in km\n- Tdewpoint (from Chievres weather station), \u00c2\u00b0C\n- rv1, Random variable 1, nondimensional\n- rv2, Random variable 2, nondimensional","fe253b23":"# Overview","26456f96":"# Feature Importance","ee96ac5e":"### Weekday","b3807a13":"# Appliances and Outside Variables","cfb65d06":"### Time Period","a15ac2bd":"Here is an overview of the entire timeline and all variables.\n\n- We can see that there peaks of high appliance usage and low appliance usage. Probably indicating night time and daytime. \n\n- Note that there are two large gaps in appliance usage. (potential outliers)\n    - between 27-1-2016 and 30-1-2016\n    - between 01-4-2016 and 03-04-2016\n    \n    \nI will be using only two weeks of data for the next section of data exploration to better depict patterns and trends","f6964d67":"Can't visually make out any patterns or trends","0da9f0b9":"### Lags","8aa069e7":"Hard to visually find clear patterns\/trends from weekdays or weekends","7f6d7ada":"### Is Daytime\n- We can see that during the daytime, the residents are presumably active and awake and so appliance usage peaks during this time.\n\n- choose daytime to be from 7:00am - 12:00am (roughly estimated visually on appliance usage)"}}