{"cell_type":{"e2097ad1":"code","6ba10492":"code","1b38a16a":"code","bdd53b42":"code","80ad2798":"code","4efc04ce":"code","16f243f1":"code","84a33e63":"code","4d4be274":"code","ce54d416":"code","c15ed265":"code","dccda8db":"code","745276bf":"code","85b6d00e":"code","4fdbee90":"code","1d7866e5":"code","f2f422e5":"code","9ba28af1":"code","8ea3b893":"code","500a7729":"code","c55a53b7":"code","1699d7ac":"code","236d754d":"code","fa108ab2":"code","fb3d1c2b":"code","ab370c0a":"code","368e393c":"markdown"},"source":{"e2097ad1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6ba10492":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1b38a16a":"folder = '\/kaggle\/input\/ventilator-pressure-prediction\/'","bdd53b42":"train = pd.read_csv(folder + '\/train.csv')\ntest = pd.read_csv(folder + '\/test.csv')","80ad2798":"sample_submission = pd.read_csv(folder + '\/sample_submission.csv')","4efc04ce":"train['time_id'] = np.concatenate([range(1, 81)] * len(train['breath_id'].unique()))\ntest['time_id'] = np.concatenate([range(1, 81)] * len(test['breath_id'].unique()))","16f243f1":"# Cumulative sum of u_in\n\ntrain['cumsum'] = train.groupby('breath_id')['u_in'].cumsum()\ntest['cumsum'] = test.groupby('breath_id')['u_in'].cumsum()","84a33e63":"# Add previous values of u_in\n\ndef add_prevs(data, n_shifts=20):\n    for i in range(1, n_shifts):\n        data['prev_u_in' + str(i)] = data['u_in'].shift(i)\n        data.loc[data['time_id'] < i + 1, 'prev_u_in' + str(i)] = 0","4d4be274":"add_prevs(train)\nadd_prevs(test)","ce54d416":"def add_futs(data, n_shifts=20):\n    for i in range(1, n_shifts):\n        data['fut_u_in' + str(i)] = data['u_in'].shift(i)\n        data.loc[data['time_id'] > 80 - i, 'fut_u_in' + str(i)] = 0","c15ed265":"add_futs(train)\nadd_futs(test)","dccda8db":"# Add differences of u_in \n\ndef add_diffs(data, n_shifts=20):\n    for i in range(1, n_shifts):\n        data['diff_u_in' + str(i)] = data['u_in'].diff(i)\n        data.loc[data['time_id'] < i + 1, 'diff_u_in' + str(i)] = 0\n","745276bf":"add_diffs(train)\nadd_diffs(test)","85b6d00e":"from sklearn.metrics import mean_absolute_error as mae","4fdbee90":"# Prepare dataset\n\nX = train.drop(columns=['id', 'pressure'])\ny = train['pressure']","1d7866e5":"# Train_test splitter\n# Two instances with the same id must be in the same set\n\ndef train_test_split(X, y, drop_id=True, test_size=0.3):\n    ids = X['breath_id'].unique()\n    train_ids = np.random.choice(ids, replace=False, size=int(len(ids) * (1 - test_size)))\n    \n    if drop_id:\n        X_train = X[X['breath_id'].isin(train_ids)].drop(columns='breath_id')\n        X_test = X[~X['breath_id'].isin(train_ids)].drop(columns='breath_id')\n    else: \n        X_train = X[X['breath_id'].isin(train_ids)]\n        X_test = X[~X['breath_id'].isin(train_ids)]\n        \n        \n    y_train = y[X['breath_id'].isin(train_ids)]\n    y_test = y[~X['breath_id'].isin(train_ids)]\n    \n    return X_train, X_test, y_train, y_test","f2f422e5":"# Train\/Test split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)","9ba28af1":"print('N features: ', X_train.shape[1])","8ea3b893":"del X, y, train","500a7729":"import lightgbm as lgb","c55a53b7":"reg = lgb.LGBMRegressor(num_leaves=2048, n_estimators=3000, learning_rate=0.1)\nreg.fit(X_train, y_train)","1699d7ac":"del X_train, y_train","236d754d":"print('Test mae: ', mae(y_test, reg.predict(X_test)))","fa108ab2":"pred = reg.predict(test.drop(columns=['id', 'breath_id']))","fb3d1c2b":"sample_submission['pressure'] = pred","ab370c0a":"sample_submission.to_csv('submission.csv', index=False)","368e393c":"# Train"}}