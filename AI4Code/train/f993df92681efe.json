{"cell_type":{"f39986c6":"code","d4cf76f4":"code","b8b22e39":"code","63667fc0":"code","aefdce38":"code","cbfbdc2c":"code","818b7c1e":"code","51df0700":"code","6d42447b":"code","cfc37c57":"code","50f87ea2":"code","183ea9e4":"code","1bba0722":"code","edbb27c2":"code","e771e3fc":"code","e8369b3e":"code","081d4ddf":"code","84765b70":"markdown","e57ab560":"markdown","be18a1b3":"markdown","9a83929b":"markdown","04ab162c":"markdown","68eef8f5":"markdown","fa0fe96d":"markdown","47a9d2f6":"markdown","5906da3f":"markdown","f4ef80a8":"markdown","610997da":"markdown","da59b903":"markdown","59214bb7":"markdown","69b45a79":"markdown","51a858dc":"markdown","62a83812":"markdown","7114d988":"markdown"},"source":{"f39986c6":"import numpy as np\nimport pandas as pd\nimport joblib\nfrom sklearn.preprocessing import MinMaxScaler","d4cf76f4":"df = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf","b8b22e39":"y_data = df.pop(\"label\")\ny_data","63667fc0":"import numpy as np\nfrom sklearn import preprocessing\n\n\ndef transform_labels(labels_array, labels):\n    lb = preprocessing.LabelBinarizer()\n    lb.fit(labels)\n    new_labels_array = []\n    for l in labels_array:\n        transformed_labels = lb.transform([l])\n        transformed_labels = transformed_labels.reshape((transformed_labels.shape[1],))\n        new_labels_array.append(transformed_labels)\n\n    new_labels_array = np.array(new_labels_array)\n    return new_labels_array\n\ny_data = transform_labels(y_data, list(range(0, 10)))\ny_data","aefdce38":"X_data = df.to_numpy()\nprint(X_data.shape)\nX_data = X_data.reshape((X_data.shape[0], 28, 28, 1))\nX_data.shape","cbfbdc2c":"X_data = X_data \/ 255","818b7c1e":"import matplotlib.pyplot as plt\n\ni = 10\nplt.imshow(X_data[i].reshape((28, 28)))\nprint(y_data[i])","51df0700":"import tensorflow as tf\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import RMSprop\n\n\ndef model_fn(input_shape, classes):\n    x_inputs = Input(input_shape)\n\n    x = Conv2D(filters = 64, kernel_size = (5,5), activation ='relu')(x_inputs)\n    x = BatchNormalization()(x)\n    x = Conv2D(filters = 64, kernel_size = (5,5), activation ='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2,2))(x)\n    x = Dropout(0.10)(x)\n\n    x = Conv2D(filters = 128, kernel_size = (3,3), activation ='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(filters = 128, kernel_size = (3,3), activation ='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n    x = Dropout(0.25)(x)\n\n    x = Conv2D(filters = 512, kernel_size = (3,3), activation ='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n\n    x = Flatten()(x)\n    x = Dense(1024, activation = \"relu\")(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(10, activation = \"softmax\")(x)\n    \n    model = Model(inputs=x_inputs, outputs=x)\n    \n    model.compile(loss=\"categorical_crossentropy\",\n                  optimizer='adam',\n                  metrics=[\"accuracy\"])\n\n    return model","6d42447b":"from IPython.display import Image\n\n\nmodel = model_fn((28, 28, 1), 10)\n\n\ntf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\nImage(\"model.png\")","cfc37c57":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nmodel_dir = '\/kaggle\/working\/'\ncheckpoint_path = \"{dir}\/model.ckpt\".format(dir=model_dir)\n\nlatest = tf.train.latest_checkpoint(model_dir)\n\nif latest:\n    print(\"Loading model...\")\n    model.load_weights(latest)\n\n# Save model\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, save_best_only=True)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n                monitor='val_loss', min_delta=0, patience=5, verbose=0,\n                mode='auto',\n                baseline=None, restore_best_weights=True\n            )\n\n\n\ncallbacks = [checkpoint, early_stopping]","50f87ea2":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data,\n                                                  test_size=0.1,\n                                                  random_state=1)\n\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train,\n                                                  test_size=0.1,\n                                                  random_state=1)\n\nX_train.shape, y_train.shape, X_validation.shape, y_validation.shape, X_test.shape, y_test.shape","183ea9e4":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#Data Augmentation \ndatagen = ImageDataGenerator(\n        featurewise_center=False, # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","1bba0722":"history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=256),\n                              epochs = 100, \n                              validation_data = (X_validation, y_validation),\n                              verbose = 1,\n                              use_multiprocessing=True,\n                              workers=4,\n                              callbacks=callbacks)","edbb27c2":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","e771e3fc":"latest = tf.train.latest_checkpoint(model_dir)\n\nif latest:\n    print(\"Loading model...\")\n    model.load_weights(latest)","e8369b3e":"test_results = model.evaluate(X_test, y_test, batch_size=1024)","081d4ddf":"test_df = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\nX_predict = test_df.to_numpy()\n\nX_predict = X_predict.reshape((X_predict.shape[0], 28, 28, 1))\n\nreescaled_data = []\nfor x in X_predict:\n    reescaled_image = (x - x.min(axis=0)) \/ ((x.max(axis=0) - x.min(axis=0) + 0.0000001))\n    reescaled_data.append(reescaled_image)\n\nX_predict = np.array(reescaled_data)\n\npredicted = model.predict(X_predict)\npredicted_values = np.array(tf.argmax(predicted, axis=1))\n\nmy_submission = pd.DataFrame({'ImageId': list(range(1, len(predicted_values)+1)), 'Label': predicted_values})\nmy_submission.to_csv('submission.csv', index=False)","84765b70":"# Training model","e57ab560":"# Normalize images","be18a1b3":"# Build labels","9a83929b":"# Plot images","04ab162c":"# Build images","68eef8f5":"<img width=\"400\" src=\"attachment:image.png\">","fa0fe96d":"# Split train and test sets","47a9d2f6":"# Testing model","5906da3f":"# Create CNN model","f4ef80a8":"# Data Augmentation","610997da":"# Create checkpoint callback","da59b903":"# Predict test data","59214bb7":"![](https:\/\/docs.microsoft.com\/pt-br\/azure\/machine-learning\/algorithm-module-reference\/media\/module\/aml-normalization-minmax.png)","69b45a79":"# Draw the loss and accuracy curves","51a858dc":"# Requirements","62a83812":"# Load best model","7114d988":"# Load dataset"}}