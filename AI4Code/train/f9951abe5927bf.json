{"cell_type":{"03a7c462":"code","d4a63a34":"code","647897c7":"code","e97cc477":"code","c4f6a108":"code","cbb06220":"code","d73820fb":"code","482c25b7":"code","0ab8f973":"code","d3ee635c":"code","eb50e165":"code","70559a48":"code","35fac74a":"code","29a55b75":"code","7d92b822":"code","105d0438":"code","374f7aa6":"code","71446065":"code","3fa0a403":"code","eafda8fe":"code","c5df1281":"code","707ad382":"code","757d6b3e":"code","88459e7f":"code","3ff46bf2":"code","ac86809e":"code","760d2e66":"code","e1fba4d3":"code","46da4ffd":"code","cae7d3fd":"code","7e9dcef8":"code","1f1a99df":"markdown","d98c9a81":"markdown","6e7fa9ec":"markdown","b994ff9d":"markdown","a10fa276":"markdown","15f5704c":"markdown","948346ec":"markdown","8ff0b3ea":"markdown","ed94c375":"markdown","5c9dce1d":"markdown","543c5655":"markdown","ae7efc92":"markdown","4a5a1570":"markdown","e7c8332f":"markdown","835b934d":"markdown","944ba880":"markdown","49e460ec":"markdown","2ab9d701":"markdown","322a22be":"markdown","24691c70":"markdown","76dcf9bc":"markdown","fe0c1cc4":"markdown","ee249a7b":"markdown","95afe00c":"markdown","1b9ab4aa":"markdown","3fb0afa3":"markdown","ad2fa3de":"markdown","bee71073":"markdown","6df0db4f":"markdown"},"source":{"03a7c462":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.tokenize import word_tokenize","d4a63a34":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","647897c7":"df = pd.read_csv(\"\/kaggle\/input\/content_by_synopsis.csv\")\ndf.head()","e97cc477":"bow = CountVectorizer(stop_words=\"english\", tokenizer=word_tokenize)\nbank = bow.fit_transform(df['overview'])","c4f6a108":"idx = 0 # Toy Story","cbb06220":"content = df.loc[idx, \"overview\"]\ncontent","d73820fb":"code = bow.transform([content])\ncode","482c25b7":"pd.DataFrame(code.toarray())","0ab8f973":"from sklearn.metrics.pairwise import cosine_distances","d3ee635c":"distance = cosine_distances(code, bank)\npd.DataFrame(distance)","eb50e165":"rec_idx = distance.argsort()[0, 1:11]\nrec_idx","70559a48":"df.loc[rec_idx]","35fac74a":"from sklearn.metrics.pairwise import cosine_distances\n\nclass RecommenderSystem:\n    def __init__(self, data, content_col):\n        self.df = pd.read_csv(data)\n        self.content_col = content_col\n        self.encoder = None\n        self.bank = None\n        \n    def fit(self):\n        self.encoder = CountVectorizer(stop_words=\"english\", tokenizer=word_tokenize)\n        self.bank = self.encoder.fit_transform(self.df[self.content_col])\n        \n    def recommend(self, idx, topk=10):\n        content = df.loc[idx, self.content_col]\n        code = self.encoder.transform([content])\n        dist = cosine_distances(code, self.bank)\n        rec_idx = dist.argsort()[0, 1:(topk+1)]\n        return self.df.loc[rec_idx] ","29a55b75":"recsys = RecommenderSystem(\"\/kaggle\/input\/content_by_synopsis.csv\", content_col=\"overview\")\nrecsys.fit()","7d92b822":"recsys.recommend(0) # Toy Story","105d0438":"recsys.recommend(1) # Jumanji","374f7aa6":"recsys.recommend(579) # Home Alone","71446065":"df = pd.read_csv(\"\/kaggle\/input\/content_by_multiple.csv\")\ndf.head()","3fa0a403":"recsys = RecommenderSystem(\"\/kaggle\/input\/content_by_multiple.csv\", content_col='metadata')\nrecsys.fit()","eafda8fe":"recsys.recommend(0) # Toy Story","c5df1281":"recsys.recommend(1) # Jumanji","707ad382":"recsys.recommend(579) # Home Alone","757d6b3e":"df = pd.read_csv(\"\/kaggle\/input\/content_by_synopsis.csv\")\ndf.head()","88459e7f":"df1 = pd.read_csv(\"\/kaggle\/input\/content_by_multiple.csv\")\n#df1 = df1[['title','metadata']]\ndf1.head()","3ff46bf2":"df = df1.set_index('title').join(df.set_index('title'))\ndf['join'] = df['overview'] + df['metadata']\ndf.reset_index(inplace=True)\ndf.head()","ac86809e":"df.fillna('', inplace=True)","760d2e66":"from sklearn.metrics.pairwise import cosine_distances\n\nclass RecommenderSystem_df:\n    def __init__(self, data, content_col):\n        self.df = pd.DataFrame(data) #sebelumnya csv, sekarang ubah jadi dataframe\n        self.content_col = content_col\n        self.encoder = None\n        self.bank = None\n        \n    def fit(self):\n        self.encoder = CountVectorizer(stop_words=\"english\", tokenizer=word_tokenize)\n        self.bank = self.encoder.fit_transform(self.df[self.content_col])\n        \n    def recommend(self, idx, topk=10):\n        content = df.loc[idx, self.content_col]\n        code = self.encoder.transform([content])\n        dist = cosine_distances(code, self.bank)\n        rec_idx = dist.argsort()[0, 1:(topk+1)]\n        return self.df.loc[rec_idx] ","e1fba4d3":"recsys = RecommenderSystem_df(df, content_col='join')\nrecsys.fit()","46da4ffd":"recsys.recommend(0) # Toy Story","cae7d3fd":"recsys.recommend(1) # Jumanji","7e9dcef8":"recsys.recommend(579) # Home Alone","1f1a99df":"Caranya sama seperti sebelumnya, yang membedakan kali ini kita ada step menggabungkan data. Kalo di Dragonball, ibaratnya seperti Fusion, hahaha.\n\nBack to the topic, kita import data pertama.","d98c9a81":"Data kita memiliki kolom overview yang nantinya akan kita gunakan untuk mengukur tingkat kemiripan suatu film.\n\nNext, kita buat Bag of Words.","6e7fa9ec":"## Bag of Words \n\nApa itu BoW ? BoW adalah teknik untuk mengekstrak text menjadi vector. Text yang merupakan unstructured data akan diubah menjadi data tabular (structured), yang nantinya bisa dimanfaatkan untuk kebutuhan machine learning. Dan mohon maaf saya tidak akan menjelaskannya secara detil karena bukan itu fokus bahasan kita kali ini hehe.\n\nBuat variabel \"bank\" untuk menampung BoW","b994ff9d":"## Step 3: Rekomendasikan","a10fa276":"## Modeling\n\nBerikut adalah step-step yang akan kita lakukan:\n\n- Step 1: Encode film yang user lihat\n- Step 2: Cari kesamaan\n- Step 3: Rekomendasikan","15f5704c":"Kita gabungkan kolom 'overview' dan 'metadata'.","948346ec":"Hasilnya sudah lumayan bagus, bisa kita lihat hampir semua rekomendasi memiliki genre yang sama, yang jadi pertanyaan, apakah akan menjadi lebih bagus rekomendasinya jika kita gabungkan kedua data diatas ? dengan asumsi bahwa semakin banyak data = semakin banyak informasi yang diserap = semakin bagus akurasi kemiripannya. Kita coba saja ya :)","8ff0b3ea":"## Import Data","ed94c375":"## Step 2: Cari kesamaan","5c9dce1d":"Import data kedua.","543c5655":"## Step 1: Encode film apa yang user lihat","ae7efc92":"Namun cara diatas masih memiliki kekurangan, karena tingkat kemiripan hanya dihitung berdasarkan overview saja, sehingga hasilnya tidak begitu bagus. Contohnya film \"The 40 Year Old Virgin\", film itu tidak memiliki kemiripan sama sekali dengan film \"Toy Story\", kemiripan yang dimiliki hanya berdasarkan kata \"Andy\" yang sama-sama sering mucul dikedua film tersebut. Tapi hal yang perlu diingat, dalam rekomendasi sistem tidak ada jawaban yang benar, jadi rekomendasi diatas sah-sah saja.\n\nNantinya kita akan coba dengan data yang berbeda dan data campuran, akankah hasilnya akan jadi lebih bagus? kita lihat saja nanti. Sebelum itu, kita rangkum dulu semua code diatas kedalam Class agar code lebih mudah untuk digunakan kembali.","4a5a1570":"Setelah disorting, tinggal direkomendasikan deh.","e7c8332f":"Kita coba tes gunakan Class yang sudah kita buat. Untuk kedepannya Kita akan coba tampilkan film Toy Story, Jumanji, dan Home Alone.","835b934d":"Bisa dilihat, semua value memiliki jarak antara 0-1, nah distance yang paling kecillah yang akan kita rekomendasikan, distance yang paling kecil artinya film tersebut memiliki tingkat kemiripan paling tinggi.\n\nLangkah selanjutnya, kita akan sorting 10 film yang memiliki tingkat kemiripan paling tinggi.","944ba880":"Kita gunakan index untuk mengetahui sinopsis dari film yang di tonton user. Contohnya, jika user melihat film \"Toy Story\", maka kita tidak perlu repot menulis judulnya, cukup gunakan index 0.","49e460ec":"Isi nan value dengan string kosong, karena BoW kita tidak menerima nan value.","2ab9d701":"## Content Based Filtering menggunakan Metadata yang berbeda","322a22be":"### Import Data","24691c70":"Kita akan gunakan Cosine Distance untuk menghitung similarity nya. Karena secara umum memang Cosine Distancelah yang digunakan untuk mengukur kesamaan document.","76dcf9bc":"Hitung cosine distance.","fe0c1cc4":"Kita edit sedikit Class yang sudah dibuat sebelumnya, jika sebelumnya Class kita meminta file csv, sekarang kita ganti menjadi dataframe.","ee249a7b":"Bagaimana menurut kalian? apakah hasil rekomendasinya lebih bagus atau tidak jika dibandingkan dengan sebelumnya? Sekali lagi saya ingatkan kembali bahwa rekomendasi sistem tidak ada jawaban pastinya, semuanya tergantung subjektifitas kita dalam menilai kemiripan. \n\nKalau saya pribadi, saya lebih suka hasil dari data kedua, karena hasilnya banyak merekomnedasikan genre yang tepat. Penambahan kolom 'overview' di data gabungan ini tidak banyak membantu, malah menambah noise saja, karena kolom 'overview' isinya berupa kalimat, dimana semakin banyak kata yang memiliki frekuensi kemunculan yang tinggi, dia akan berpeluang besar untuk direkomendasikan. Seperti yang sudah saya jelaskan sebelumnya, film \"The 40 Year Old Virgin\", film itu tidak memiliki kemiripan sama sekali dengan film \"Toy Story\", kemiripan yang dimiliki hanya berdasarkan kata \"Andy\" yang sama-sama sering mucul dikedua film tersebut.\n\nMungkin itu dulu dari saya, jika ada pertanyaan atau masukan, bisa kalian tulis di kolom komentar atau boleh japri di ig saya: al.fath.terry\n\nDan mohon di upvote jika dirasa bermanfaat.\n\nTerimakasih :)","95afe00c":"Setelah overview dari filmya diambil, selanjutnya kita akan melakukan encoding.","1b9ab4aa":"Data kali ini memiliki kolom \"metadata\" yang merupakan rangkuman dari keseluruhan kolom-kolom sebelumnya, dan kolom inilah yang akan kita coba gunakan untuk mencari kesamaan.\n\nSama seperti sebelumnya, next step kita akan fit dan rekomendasikan.","3fb0afa3":"Fit dan rekomendasikan.","ad2fa3de":"## Import Packages","bee71073":"# Recommendation System (Content Based Filtering)\n\nHalo teman-teman, bagaimana kabar kalian semua? saya harap kalian semua baik-baik saja ya. Dikesempatan kali ini saya ingin mendemonstrasikan cara membuat Recommendation System berdasarkan kemiripan atribut item (Content Based Filtering).\n\nContent Based Filtering adalah teknik sistem rekomendasi yang merekomendasikan item berdasarkan kemiripan atribut yang dimiliki suatu item. Contohnya jika seseorang menonton film X, maka dia akan direkomendasikan film yang mirip dengan film X (atributnya memiliki kemiripan, seperti nama artis, alur cerita, dll), dan inilah yang akan kita buat.\n\nGoal utama yang akan kita lakukan adalah: merekomendasikan beberapa list film, berdasarkan kemiripan film yang di tonton oleh user.\n\nBiar lebih jelas, kita langsung ke materinya ya.","6df0db4f":"## Content Based Filtering menggunakan data gabungan"}}