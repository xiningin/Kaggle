{"cell_type":{"dfd5ad31":"code","a42041b3":"code","4f5ffd57":"code","c97bc683":"code","8234b3a0":"code","c74bbfa8":"code","b4162c47":"code","f1c90c4b":"code","7838f895":"markdown"},"source":{"dfd5ad31":"# Import Packages\n\n## Basic\nimport pandas as pd\nimport time\nimport random\n\n## Web Scraping\nimport requests\nfrom bs4 import BeautifulSoup\n\n## NLP\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n## ML\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import classification_report","a42041b3":"train_df = pd.read_csv('https:\/\/www.dropbox.com\/s\/ia4tpu47h5f5ptd\/train.csv?raw=1')\ntest_df = pd.read_csv('https:\/\/www.dropbox.com\/s\/7mjx3ulzrf2pde5\/test.csv?raw=1')","4f5ffd57":"# Functions\n\ndef search_genre(str_variable, keyword):\n  return len(re.findall(keyword, str_variable))\n\ndef populate_df(dataframe, genres = None):\n  if genres is None:\n    selection_list = []\n    genre_list = []\n    for genre in dataframe.Genre.unique():\n      genre_list.append(genre)\n      if (genre == 'romance'):\n        genre = 'roman'\n      dataframe[genre] = dataframe.new_scrape.apply(lambda x: search_genre(str(x), genre))\n      selection_list.append(genre)\n    return dataframe[selection_list+['Plot']], genre_list\n  else:\n    selection_list = []\n    for genre in genres:\n      if (genre == 'romance'):\n        genre = 'roman'\n      dataframe[genre] = dataframe.new_scrape.apply(lambda x: search_genre(str(x), genre))\n      selection_list.append(genre)\n    return dataframe[selection_list+['Plot']]\n\ndef builf_tfidf_model(train_frame, test_frame, features):\n  tf_vector = TfidfVectorizer(lowercase    =  True, \n                              ngram_range  = (1,1),\n                              stop_words   = 'english',\n                              max_features = features)\n\n  # Training Set\n  tf_vector.fit(train_frame['Plot'].values)\n  train_tfidf = tf_vector.transform(train_frame['Plot'].values)\n  tfidf_frame = pd.DataFrame(train_tfidf.toarray(), columns = tf_vector.get_feature_names())\n  train_frame = train_frame.reset_index(drop=True)\n  train_final = pd.concat([train_frame.drop('Plot', axis=1),tfidf_frame], axis=1)\n  display(train_final.sample(3))\n\n  # Test Set\n  test_tfidf = tf_vector.transform(test_frame['Plot'].values)\n  tfidf_frame_test = pd.DataFrame(test_tfidf.toarray(), columns = tf_vector.get_feature_names())\n  test_frame = test_frame.reset_index(drop=True)\n  test_final = pd.concat([test_frame.drop('Plot', axis=1), tfidf_frame_test], axis=1)\n  display(test_final.sample(3))\n\n  # Return\n  return train_final, test_final","c97bc683":"# Scrape More Wiki for Train Set\n\ntemp_text_arr = []\ncounter = 1\n\nfor wiki_url in train_df['Wiki Page'].values:\n  \n  temp_text = ''\n\n  ## Fetch and Parse\n  response = requests.get(url=wiki_url)\n  soup = BeautifulSoup(response.content, 'html.parser')\n\n  ## Get Initial Paragraphs\n  if (len(soup.find_all('p')) >= 2):\n      temp_text += soup.find_all('p')[0].get_text() + soup.find_all('p')[1].get_text()\n  else:\n    try:\n      temp_text += soup.find_all('p')[0].get_text()\n    except:\n      temp_text = ''\n\n  ## Store in an Array\n  temp_text_arr.append(temp_text)\n\n  ## Sleeps and Verbose\n  if (counter % 100 == 0):\n    time.sleep(random.randint(1,15))\n  if (counter % 1000 == 0):\n    print('Completed Iteration:'.ljust(21), counter)\n    time.sleep(30) \n  counter += 1\n\ntrain_df['new_scrape'] = temp_text_arr\ntrain_df.to_csv('movies_train_enhanced.csv')","8234b3a0":"# Scrape More Wiki for Test Set\n\ntemp_text_arr = []\ncounter = 1\n\nfor wiki_url in test_df['Wiki Page'].values:\n  \n  temp_text = ''\n\n  ## Fetch and Parse\n  response = requests.get(url=wiki_url)\n  soup = BeautifulSoup(response.content, 'html.parser')\n\n  ## Get Initial Paragraphs\n  if (len(soup.find_all('p')) >= 2):\n      temp_text += soup.find_all('p')[0].get_text() + soup.find_all('p')[1].get_text()\n  else:\n    try:\n      temp_text += soup.find_all('p')[0].get_text()\n    except:\n      temp_text = ''\n\n  ## Store in an Array\n  temp_text_arr.append(temp_text)\n\n  ## Sleeps and Verbose\n  if (counter % 100 == 0):\n    time.sleep(random.randint(1,15))\n  if (counter % 1000 == 0):\n    print('Completed Iteration:'.ljust(21), counter)\n    time.sleep(30) \n  counter += 1\n\ntest_df['new_scrape'] = temp_text_arr\ntest_df.to_csv('movies_test_enhanced.csv')","c74bbfa8":"# Create Features\n\ntrain_labels = train_df['Genre']\ntrain_df, genre_list = populate_df(train_df)\ntest_df = populate_df(test_df, genre_list)\ntrain_predictors, test_predictors = builf_tfidf_model(train_df, test_df, 1000)","b4162c47":"# Logistic Regression with One-vs-Rest Strategy\n\nlr_classifier = LogisticRegression(max_iter=10000, solver='liblinear')\novr = OneVsRestClassifier(lr_classifier)\novr.fit(train_predictors, train_labels)\nprediction = ovr.predict(train_predictors)\nprint('Train Set Classification Report: \\n', classification_report(train_labels, prediction))","f1c90c4b":"# Submission\n\nsubmission_frame = pd.read_csv('https:\/\/www.dropbox.com\/s\/7mjx3ulzrf2pde5\/test.csv?raw=1')\nsubmission_frame['Predicted'] = ovr.predict(test_predictors)\nsubmission_frame[['Id','Predicted']].to_csv('my_submissions.csv', index=False)","7838f895":"**Thinking out of the box or cheating?**"}}