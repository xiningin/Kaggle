{"cell_type":{"bb8ddf74":"code","65be84f2":"code","a8db126f":"code","96de88f5":"code","ab3870cd":"code","ae0b84eb":"code","21a5df26":"code","c75883f4":"code","f41fd490":"code","99fb3377":"code","24e40a91":"code","fa805a51":"markdown","aff52c10":"markdown","568056c2":"markdown","387c8a0e":"markdown","7db6dd6a":"markdown","4fc33198":"markdown","dd67e121":"markdown"},"source":{"bb8ddf74":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom sklearn.metrics import r2_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings        \n# ignore filters\nwarnings.filterwarnings(\"ignore\") # if there is a warning after some codes, this will avoid us to see them.\n\nplt.style.use('ggplot') # style of plots. ggplot is one of the most used style, I also like it.\n# Any results you write to the current directory are saved as output.","65be84f2":"bfop_df1=pd.read_csv(\"\/kaggle\/input\/biomechanical-features-of-orthopedic-patients\/column_3C_weka.csv\")\n\nbfop_df2=pd.read_csv(\"\/kaggle\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv\")","a8db126f":"bfop_df1.head(10)","96de88f5":"bfop_df1.info()","ab3870cd":"bfop_df2.head(10)","ae0b84eb":"bfop_df2.info()","21a5df26":"from sklearn.linear_model import LinearRegression\n\nlinear_reg=LinearRegression()\n\nx=bfop_df1.pelvic_incidence.values.reshape(-1,1)\ny=bfop_df1.pelvic_radius.values.reshape(-1,1)\n\nlinear_reg.fit(x,y)\n\nminimum=int(min(x))\nmaximum=int(max(x))\n\n#array=linear_reg.predict(x)\n\nplt.scatter(x,y)\n\ny_head=linear_reg.predict(x)\n\nplt.plot(x,y_head,color=\"blue\")\nplt.show()\n\nprint(\"r_score:\",r2_score(y,y_head))","c75883f4":"from sklearn.linear_model import LinearRegression\n\nmultiple_linear_regression=LinearRegression()\n\nx=bfop_df2.iloc[:,[0,1]].values # pelvic incidence and pelvic tilt numeric\ny=bfop_df2.pelvic_radius.values.reshape(-1,1)\n\n\n\nmultiple_linear_regression.fit(x,y)\n\narray=[]\n\nfor i in np.array(range(35,88)):\n    \n    print(multiple_linear_regression.predict([[i,i]]),\"\\n\")\n\n","f41fd490":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\npolynomial_regression=PolynomialFeatures(degree=4)\n\nx=bfop_df1.lumbar_lordosis_angle.values.reshape(-1,1)\ny=bfop_df1.sacral_slope.values.reshape(-1,1)\n\nx_polynomial=polynomial_regression.fit_transform(x)\n\nlinear_regression2=LinearRegression()\nlinear_regression2.fit(x_polynomial,y)\n\ny_head=linear_regression2.predict(x_polynomial)\n\nplt.scatter(x,y)\nplt.xlabel(\"Lumbar Lordosis Angle\")\nplt.ylabel(\"Sacral Slope\")\nplt.plot(x,y_head,color=\"blue\")\nplt.show()\n\nprint(\"r_score:\",r2_score(y,y_head))","99fb3377":"from sklearn.tree import DecisionTreeRegressor\n\nx=bfop_df2.pelvic_incidence.values.reshape(-1,1)\ny=bfop_df2.pelvic_radius.values.reshape(-1,1)\n\ntree_reg=DecisionTreeRegressor()\ntree_reg.fit(x,y)\n\nx_=np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head=tree_reg.predict(x_)\ny_head2=tree_reg.predict(x)\n\nplt.scatter(x,y)\nplt.plot(x_,y_head,color=\"blue\")\nplt.show()\n\nprint(\"r_score:\",r2_score(y,y_head2))","24e40a91":"from sklearn.ensemble import RandomForestRegressor\n\nrf=RandomForestRegressor(n_estimators=100, random_state=42)\n\nx=bfop_df2.lumbar_lordosis_angle.values.reshape(-1,1)\ny=bfop_df2.sacral_slope.values.reshape(-1,1)\n\nrf.fit(x,y)\n\ny_head=rf.predict(x)\n\nplt.scatter(x,y)\nplt.plot(x,y_head,color=\"blue\")\nplt.show()\n\nprint(\"r_score:\",r2_score(y,y_head))","fa805a51":"<a id=\"7\"><\/a><br>\n# Evaluation Regression Models","aff52c10":"<a id=\"2\"><\/a><br>\n# Linear Regression","568056c2":"<a id=\"1\"><\/a><br>\n# Loading and Checking Data","387c8a0e":"# Introduction \n\n1. [Loading and Checking Data](#1)\n1. [Linear Regression](#2)\n1. [Multiple Linear Regression](#3)\n1. [Polynomial Linear Regression](#4)\n1. [Decision Tree Regression](#5)\n1. [Random Forest Regression](#6)\n1. [Evaluation Regression Models](#7)","7db6dd6a":"<a id=\"4\"><\/a><br>\n# Polynomial Linear Regression","4fc33198":"<a id=\"3\"><\/a><br>\n# Multiple Linear Regression","dd67e121":"<a id=\"5\"><\/a><br>\n# Decision Tree Regression"}}