{"cell_type":{"719cea92":"code","ea37d38c":"code","bc6edc8e":"code","d383dc4f":"code","9124a675":"code","74ceabf2":"code","a4a19e27":"code","c0b65d28":"code","37b2bff3":"code","bd37941d":"code","2f7dd326":"code","951227b8":"code","434ba1c0":"code","73e4a436":"code","a2250e87":"code","ca73d7d8":"code","f4a2f5d9":"code","5e256d09":"code","a1591a17":"code","21535c1d":"code","0fc4c405":"code","7ca22981":"code","2d352720":"code","6681b20c":"markdown","8dec689e":"markdown","5f611ab6":"markdown","ebb8c05f":"markdown","80e73d41":"markdown","b5d39108":"markdown"},"source":{"719cea92":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport random","ea37d38c":"def set_random_seed():\n    random.seed(2021)\n    tf.random.set_seed(2020)\n    np.random.seed(2019)\nset_random_seed()","bc6edc8e":"# CONFIG\nmodel_version = 'v0'\nBATCH_SIZE = 128\nEPOCHS = 15\nSPLITS = 10","d383dc4f":"TRAIN_FEATURES = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\nTRAIN_FEATURES.describe()","9124a675":"TEST_FEATURES = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\nTEST_FEATURES.describe()","74ceabf2":"# cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle)\ntrain_cp_type = np.unique(TRAIN_FEATURES['cp_type'])\nprint(\"Train cp types:\", train_cp_type)\n\n# cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) and dose (high or low)\ntrain_cp_dose = np.unique(TRAIN_FEATURES['cp_dose'])\nprint(\"Train cp_dose:\", train_cp_dose)","a4a19e27":"# Check for column correlation\n# TRAIN_FEATURES.corr(method='pearson')","c0b65d28":"TRAIN_FEATURES = pd.get_dummies(TRAIN_FEATURES, columns=['cp_type', 'cp_dose'])\nTRAIN_FEATURES.head()","37b2bff3":"TEST_FEATURES = pd.get_dummies(TEST_FEATURES, columns=['cp_type', 'cp_dose'])\nTEST_FEATURES.head()","bd37941d":"MEAN_STD = {}\ntraining_features = TRAIN_FEATURES.columns.tolist()\ntraining_features.remove('sig_id')\nfor column in training_features:\n    # Skip categorical column\n    if len(np.unique(TRAIN_FEATURES[column])) == 2 or column == 'sig_id':\n        print(\"Skip categorical column: \", column)\n        continue\n    # Standardize continous column\n    (mu, sigma) = TRAIN_FEATURES[column].mean(), TRAIN_FEATURES[column].std()\n    TRAIN_FEATURES[column] = (TRAIN_FEATURES[column] - mu) \/ sigma\n    TEST_FEATURES[column] = (TEST_FEATURES[column] - mu) \/ sigma\n    MEAN_STD[column] = (mu, sigma)\nprint(TRAIN_FEATURES.describe())\nprint(TEST_FEATURES.describe())","2f7dd326":"TRAIN_TARGETS = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\nTRAIN_TARGETS.describe()","951227b8":"targets = TRAIN_TARGETS.columns.tolist()\ntargets.remove('sig_id')\nprint(\"Num of classes: \", len(targets))","434ba1c0":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\ndef dense_layer(x, num_of_nodes=1024, activation='tanh'):\n    d = Dense(num_of_nodes)(x)\n    b = BatchNormalization()(d)\n    a = Activation(activation)(b)\n    return a\n\ndef build_model():\n    inp = Input(shape=(len(training_features),))\n    d = dense_layer(inp, 1024, 'tanh')\n    d = dense_layer(d, 1024, 'tanh')\n    out = Dense(len(targets), activation='sigmoid')(d)\n    \n    model = Model(inputs = inp, outputs = out)\n    model.compile(optimizer=Adam(), loss=BinaryCrossentropy())\n    \n    return model \n\nmodel = build_model()\nmodel.summary()","73e4a436":"TRAIN_DF = pd.merge(TRAIN_FEATURES, TRAIN_TARGETS, on=['sig_id'])\n# TRAIN_DF.d\nTRAIN_DF.head()","a2250e87":"X, y = TRAIN_DF[training_features].values, TRAIN_DF[targets].values\nX = np.asarray(X, dtype='float32')\ny = np.asarray(y, dtype='float32')\nprint(\"Shape of X training: \", X.shape)\nprint(\"Shape of y training: \", y.shape)","ca73d7d8":"from tensorflow.keras.callbacks import *\ndef get_callback(fold):\n    return [\n#         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, min_lr=1e-5),\n        ModelCheckpoint(f'model_{model_version}_{fold}.h5', monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=1)\n    ]","f4a2f5d9":"from sklearn.model_selection import KFold\nimport tensorflow.keras.backend as K\nimport gc\nkfold = KFold(n_splits=SPLITS)\nfold = 0\nhistory = []\nfor train_idx, test_idx in kfold.split(X, y):\n    K.clear_session()\n    gc.collect()\n    print(\"FOLD \", fold)\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_test, y_test = X[test_idx], y[test_idx]\n    \n    callbacks = get_callback(fold)\n    \n    model = build_model()\n    hist = model.fit(X_train, y_train, \n                     batch_size = BATCH_SIZE,\n                     epochs = EPOCHS,\n                     validation_data=(X_test, y_test), \n                     callbacks = callbacks)\n    \n    \n    history.append(hist)\n    fold += 1\n    K.clear_session()\n    gc.collect()","5e256d09":"best_val_loss = [np.min(hist.history['val_loss']) for hist in history]\nprint(\"Best val loss for each fold: \", best_val_loss)\nprint(\"OOF val loss: \", np.mean(best_val_loss))","a1591a17":"# Plot learning curve for each fold\nfor fold in range(SPLITS):\n    fig, ax = plt.subplots()\n    ax.plot(history[fold].history['loss'])\n    ax.plot(history[fold].history['val_loss'])\n    ax.legend(['train', 'test'], loc='upper left')\nplt.show()","21535c1d":"models = []\npredictions = []\nfor i in range(SPLITS):\n    model = build_model()\n    model.load_weights(f'model_{model_version}_{i}.h5')\n    models.append(model)\n    \nX_test = np.asarray(TEST_FEATURES[training_features].values, dtype='float32')\nfor model in models:\n    predictions.append(model.predict(X_test, verbose=1))\n    \nfinal_prediction = predictions[0]\nfor i in range(1, SPLITS):\n    final_prediction += predictions[i]\nfinal_prediction \/= len(models)","0fc4c405":"print(final_prediction.shape)","7ca22981":"submission_data = {}\nsubmission_data['sig_id'] = TEST_FEATURES.sig_id.values\nfor i, target in enumerate(targets):\n    submission_data[target] = final_prediction[:, i]\nsubmission_csv = pd.DataFrame(data=submission_data)\nsubmission_csv.to_csv('submission.csv', index=False)\nsubmission_csv.head()","2d352720":"print(\"Done!\")","6681b20c":"## Data preprocessing\n* One hot encode categorical data\n* Standardize continuous features","8dec689e":"## Features description\n* g- signify gene expression data, and c- signify cell viability data\n* cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle)\n* cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) and dose (high or low)","5f611ab6":"# MoA Prediction using deep neural network","ebb8c05f":"## Deep Neural Network Modelling (Simple modelling for now)","80e73d41":"## Training 5-Fold CV","b5d39108":"## Inference on test set"}}