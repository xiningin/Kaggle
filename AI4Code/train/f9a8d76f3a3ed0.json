{"cell_type":{"d49afd50":"code","fa1e0088":"code","4048130c":"code","774c5e9b":"code","fac6ce8a":"code","7c5ae4b0":"code","15e0e122":"code","883b56ef":"code","7886d2c9":"code","ec6b6c85":"code","93c04ac8":"code","d72d8c3b":"code","0c5c1ea8":"code","c8d5091e":"code","a08812ea":"code","dce604c0":"code","77d30400":"code","1024446a":"code","5df80371":"code","73a4e663":"code","55f4680d":"code","55facbb1":"code","9f9ffff5":"code","0ca01ac3":"code","2b0f5800":"code","34fb1754":"code","ce9732f4":"code","36f7fe6b":"code","b66116c5":"code","a3f18617":"code","d3b3267e":"code","3e511b10":"code","0f15c597":"code","0a609cef":"code","a09ab00b":"code","8dcf50f4":"code","b8ea7aaa":"code","dc1d37e9":"code","6b7e58d3":"code","6023d5ac":"code","58509c1f":"code","76bcd07d":"code","b4e01b2f":"code","c1d1561c":"markdown","8903ee28":"markdown","9f965e95":"markdown","9638a839":"markdown","8500d4a7":"markdown","4f35c867":"markdown","a7997416":"markdown","86f85905":"markdown","3188d5cf":"markdown","4f41fda3":"markdown","7591d1b1":"markdown","842d1d21":"markdown","da543f1e":"markdown","2509daa1":"markdown","fa1acd0c":"markdown","cadc950a":"markdown","e6f45c94":"markdown","792cc749":"markdown","7be708dc":"markdown","2dcdbc1b":"markdown","59b8e960":"markdown","86d2b8be":"markdown","b9055cea":"markdown","9662a8b6":"markdown","db6191b3":"markdown","ec57a0b5":"markdown","f802a2d1":"markdown","7f1582ba":"markdown","d5ebf371":"markdown","491b0aed":"markdown","98eab1e5":"markdown","4e677de5":"markdown","d0c0b4a6":"markdown","34df3f29":"markdown","112ec523":"markdown","60f22b03":"markdown","92fd5dd2":"markdown","391b6e3f":"markdown","8e2cce5f":"markdown","91da7dd7":"markdown","c9d5b5d3":"markdown","d4c3c56a":"markdown","0422c89f":"markdown","eeebd818":"markdown"},"source":{"d49afd50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import plot_tree\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa1e0088":"data = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","4048130c":"print(data.head())","774c5e9b":"data.head(5)","fac6ce8a":"print(data.shape)","7c5ae4b0":"data.columns","15e0e122":"data['quality'].max()","883b56ef":"data['quality'].min()","7886d2c9":"data['quality'].value_counts().plot(kind='bar', figsize=(10,5))","ec6b6c85":"data.hist(bins=50, figsize=(20,15)) \nplt.show()","93c04ac8":"sns.scatterplot(x=\"alcohol\", y='quality', data=data )","d72d8c3b":"data.info()\n","0c5c1ea8":"print(data.isna().sum())","c8d5091e":"print(data.describe())","a08812ea":"plt.figure(figsize=(12,10))\ncor = data.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","dce604c0":"data['quality' ] = data['quality' ].map (lambda x: x >= 6)","77d30400":"sns.countplot(x=\"quality\",data=data)","1024446a":"X = data[[\"alcohol\", \"sulphates\",\"residual sugar\", \"citric acid\", \"fixed acidity\"]]\ny = data[\"quality\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","5df80371":"# Create Objekt KNeighborsClassifier\nclf = KNeighborsClassifier()","73a4e663":"# Defnieren von Parametern\nparams = {\n    'n_neighbors' : [1, 2, 3, 4, 5, 6, 7, 8, 10, 25],\n    'weights': ['uniform', 'distance']\n}\n\n# Verwendung von GridSearch\ngrid_clf = GridSearchCV(estimator = clf,\n                        param_grid = params,\n                        scoring = 'accuracy', \n                        cv = 10, \n                        verbose = 1,\n                        n_jobs = -1)","55f4680d":"# Trainieren\ngrid_clf.fit(X_train, y_train)","55facbb1":"grid_clf.best_estimator_","9f9ffff5":"# Ausgabe der besten Parametern\nbest_n_neighbors = grid_clf.best_params_['n_neighbors']  \nbest_weights      = grid_clf.best_params_['weights']\n\n\nprint(f\"Beste Cross-Validation Klassifikationsgenauigkeit: {grid_clf.best_score_:.3f}\")\nprint(f\"Bester n_neighbors Wert: {best_n_neighbors}\")\nprint(f\"Bester weights Wert: {best_weights}\")","0ca01ac3":"grid_clf.score(X_test, y_test)","2b0f5800":"clf = KNeighborsClassifier(n_neighbors=3, weights='distance')","34fb1754":"clf.fit(X_train, y_train)\n","ce9732f4":"clf.score(X_test, y_test)","36f7fe6b":"# Vorhersage von dem Testdatensatz \ny_predict = clf.predict(X_test)","b66116c5":"# Ausgabe von dem Klassifikation Report\nprint(classification_report(y_test, y_predict))","a3f18617":"ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict)).plot()","d3b3267e":"# Create Objekt DecisionTreeClassifier\ndtree = DecisionTreeClassifier()\n\n# Festlegen von Parametern\nparams = {'max_depth': np.arange(1, 18, 1),\n         'criterion': ['gini', 'entropy'],\n         'min_samples_leaf': np.arange(1,6, 1)}","3e511b10":"# Verwendung von GridSearch\ngrid_tree = GridSearchCV(estimator=dtree,\n                       param_grid=params,\n                       scoring='accuracy',\n                       return_train_score=True,\n                       verbose=1,\n                       cv=10,\n                       n_jobs= -1)","0f15c597":"# Trainieren\ngrid_tree.fit(X_train, y_train)","0a609cef":"grid_tree.best_params_","a09ab00b":"# Bestes Ergebnis\ngrid_tree.best_score_","8dcf50f4":"# Verwendung der besten Daten\nbest_clf = grid_tree.best_estimator_\nbest_clf.fit(X_train, y_train)","b8ea7aaa":"# Vorhersage von dem Testdatensatz \ny_predtree = best_clf.predict(X_test)","dc1d37e9":"cmtree = metrics.confusion_matrix(y_test, y_predtree)\n\ndisp = metrics.ConfusionMatrixDisplay(cmtree)\ndisp.plot()","6b7e58d3":"from sklearn.metrics import plot_roc_curve\nsvc_disp = plot_roc_curve(clf, X_test, y_test)\nplt.show()","6023d5ac":"# Ausgabe von dem classification_report\nprint(metrics.classification_report(y_test, y_predtree, digits=3))","58509c1f":"# Ausgabe von dem Decistion Tree\nplt.figure(figsize=(30,20))\n\nplot_tree(best_clf, max_depth =3,feature_names=list(X.columns), class_names=['False', 'True'], filled=True);","76bcd07d":"print(classification_report(y_test,y_predict))","b4e01b2f":"print(metrics.classification_report(y_test, y_predtree))","c1d1561c":"print(data.info()) --> Ausgabe von allen Spalten mit den jeweiligen Eigenschaften","8903ee28":"Es wird ein Split von den Daten in Test- und Trainingsdaten  vorgenommen. \nWir haben dabei die Daten aus den Spalten \"alcohol\", \"sulphates\",\"residual sugar\", \"citric acid\", \"fixed acidity\" verwendet, aufgrund, dass diese Eigenschaften einen positiven Zusammenhang zu der \"quality\" haben. Die Haupteigenschaft ist hier die Spalte bzw. Eigenschaft \"Quality\".","9f965e95":"# 1. Allgemeine Informationen\n Gruppe Teilnehmer: \n Pascale Sch\u00f6nitz (Matrikelnummer: 1825404), \n Gina-Maria F\u00e4rber (Matrikelnummer: 1826704)\n\nDatensatz: Red Wine Quality","9638a839":"Um die Daten noch besser verstehen zu k\u00f6nnen wird hier nochmal f\u00fcr jede Spalte in dem Datensatz ein Histogramm angezeigt. Anhand von den Histogrammen kann man die Daten der jeweiligen Spalten nochmal gesammelt betrachten. ","8500d4a7":"Wir lassen uns die h\u00f6chste und niedrigste Qualit\u00e4tsbewertung aus der Tabelle ausgeben. ","4f35c867":"Das allgemeine Problem f\u00fcr die Wein Hersteller ist vorherzusagen wie die Qualit\u00e4t von Ihren Wein sein k\u00f6nnte.\nDas Modell kann dazu vorhersagen, wie die Qualit\u00e4t von dem hergestellten Wein ist. Nat\u00fcrlich gibt es Abweichungen, da es eine Vorhersage ist jedoch bringt, dies dem Hersteller bereits im Vorfeld eine Richtung in die die Qualit\u00e4t bei der Herstellung geht.\nSomit ist es f\u00fcr das Unternehmen m\u00f6glich vorherzusagen zu k\u00f6nnen, welche Qualit\u00e4t der Hergestellte Wein hat und kann anhand von der Qualit\u00e4tsbewertung auch die Qualit\u00e4t anpassen, sodass der Wein eine bessere Qualit\u00e4t hat.\nErw\u00e4hnenswert ist gleichzeitig, dass auch die Eigenschaften, die die Qualit\u00e4t beeintr\u00e4chtigen analysiert werden k\u00f6nnen und auch da eine gezieltere Verbesserung vorgenommen werden kann.  ","a7997416":"Auf der folgenden Abbildung k\u00f6nnen Sie nochmal den Zusammenhang zwischen der quality und alcohol erkennen. In allen Qualit\u00e4tsbereichen von dem Wein ist der Inhalt von alcohol zu sehen. Jedoch ist der Alkoholgehalt sehr unterschiedlich.","86f85905":"# 7. M\u00f6glicher Gesch\u00e4ftseinsatz","3188d5cf":"# 4. Datenaufbereitung","4f41fda3":"Balkendiagramm: Es wird die Verteilung der Bewertungen der Qualit\u00e4t von den Weinen dargestellt. Wie erkennbar ist, haben die meisten Weine eine Bewertung von f\u00fcnf und nur die zwei wenigsten Bewertung haben Weine mit der besten Qualit\u00e4t.","7591d1b1":"**Decision Tree**","842d1d21":"Um den Datensatz noch besser zu betrachten, lassen wir uns die Gr\u00f6\u00dfe von dem Data Frame anzeigen.\nWir haben in dem Datensatz 12 Spalten und 1599 Zeilen.","da543f1e":"Wir gelangen nun an den Punkt der Modelbildung. Wir haben uns als erstes f\u00fcr das Modell KNN \"K-Nearest Neighbor\" entschieden.\n\nBei dem KNN Algorithmus existiert keine Trainingsphase, es wird der am Anfang verwendete Trainingsdatensatz f\u00fcr die Klassifizierung verwendet. Dem Algorithmus muss einen Wert K gegeben werden, wobei er anschlie\u00dfend nach den k n\u00e4chsten Nachbarn sucht. Au\u00dferdem wird anhand von dem Abstand von den gegebenen k Nachbarn und den aus den aus den urspr\u00fcnglichen Datensatz die n\u00e4chsten Nachbarn gefunden. Sobald die k Nachbarn gefunden worden, wird durch den Algorithmus bestimmt zu welcher Klasse die Nachbarn geh\u00f6ren.","2509daa1":"Quelle: M\u00fcller, R. (2020), 30.11.2020 Grid Searc, URL: https:\/\/www.kaggle.com\/rolandmueller\/30-11-2020-grid-search [02.02.2022].\n\nNavlani, A (2018): Decision Tree Classification in Python, https:\/\/www.datacamp.com\/community\/tutorials\/decision-tree-classification-python [02.02.2022].","fa1acd0c":"# 2. Gesch\u00e4ftsproblem \nOn datasets are included, related to red vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests.\n\nEs geht um roten Wein aus dem Norden von Portugal. Das Ziel ist es eine Modellierung durchzuf\u00fchren bei der die Qualit\u00e4t des Weines anhand der physikalisch-chemischer Tests betrachtet wird durchzuf\u00fchren. ","cadc950a":"**Laden der Daten aus der csv. Datei**","e6f45c94":"Um guten und schlechten Wein voneinander zu trennen verwenden wir den folgenden Befehl. \nDieser teilt  die Spalte \"quality\" in true and false ein. Wir definieren guten Wein so ein, dass wenn der Wein eine Bewertung von sechs, sieben oder acht Punkten hat ein guter Wein ist. Wenn der Wein unter sechs Bewertungspunkte besitzt, ist es kein guter Wein. \n\nQuelle: Schneider, J. (2021), Wine Quality, URL: https:\/\/www.kaggle.com\/janschneiderhwr\/wine-quality [01.02.2022].","792cc749":"Betrachten wir nun nach der erstellung die Heat-Map.\nDie Haupteigenschaft ist hier die \"qualitiy\". Als ein Beispiel \"alcohol\" hat einen halben Zusammenhang zu der Qualit\u00e4t und volatile chlorides hat einen negativen Zusammenhang mit zu der \"qualitiy\".","7be708dc":"* Wie haben Sie die Daten aufgeteilt ? \n","2dcdbc1b":"# 3. Datenverst\u00e4ndnis (Exploratory Data Analysis)\n\n* Beschreibung des Datensatzes\nDer Datensatz beinhaltet Informationen rund um den roten Wein aus dem Norden Portugal. Der Datensatz enth\u00e4lt zw\u00f6lf Spalten und 1599 Zeilen an Daten.\n\n\n\n* fixed acidity= Anteil an S\u00e4uren\n* volatile acidity= Menge an Essigs\u00e4uren in den Wein\n* citric acid= Zitronens\u00e4ure kleinen Anteil in Wein\n* residual sugar= Zuckermenge in einem Wein\n* chlorides= Menge an Salz in einem Wein\n* free sulfur dioxide= Freie From von S02 -nachweisbar in Wein\n* total sulfur dioxide=Menge an freien und gebundenen Formen von S02- kleinen Mengen nicht nachweisbar in einem Wein\n* density - Dichte an Wasser\n* pH - Der pH Wert zeigt auf wie Sauer ein Wein ist.\n* sulphates-Ist ein Weinzusatzstoff\n* alcohol= Alkoholgehalt in Wein\n* quality= Qualit\u00e4t des Wein zwischen 0 und 10\n\n","59b8e960":"Wir lassen uns die Klassifikationsgenauigkeit ausrechen und vorhersagen.","86d2b8be":"#  6. Modellevaluierung","b9055cea":"* **K-Nearest Neighbor (KNN)** ","9662a8b6":"Das GridSearch wird verwendet um f\u00fcr ein die besten Hyperparameter zu errechnen und diese anschlie\u00dfend f\u00fcr das Modell an den Datensatz anzupassen.","db6191b3":"**K-Nearest Neighbor (KNN)** ","ec57a0b5":"Wir lassen uns anhand von den Daten eine Confusion Matrix ausgeben, diese hier eine visuelle Abbildung darstellt.","f802a2d1":"Wir wollen in dem n\u00e4chsten Schritt den Datensatz auf fehlenden Daten \u00fcberpr\u00fcfen. Dazu verwenden wir den Befehl \"data.info()\".\nBei der Ausf\u00fchrung von dem Befehl werden die Spalten von dem Datensatz angezeigt und die jeweiligen Datentypen. Aber es wird auch angezeigt, ob es fehlende Daten in den jeweiligen Spalten gibt. \n\nWir haben auch nochmal den Befehl \"print(data.isna().sum())\" angewendet, dies ist nicht n\u00f6tig, aufgrund, dass dieser Befehl ebenfalls nochmal angibt ob es fehlende Daten gibt. Zur Vereinfachung der Ansicht haben wir uns dies nochmals angezeigt.\n\nEs fehlen keinerlei an Daten in der Tabelle, dies ist erkennbar daran, dass in der Darstellung oben \u00fcberall zu jeder Spalte non-null und bei den Ergebnissen von dem zweiten Befehl \u00fcberall bei den Ergebnissen 0 steht.\n","7f1582ba":"Bei dem Punkt Datenaufbereitung haben wir uns als erstes eine \u00dcbersicht \u00fcber die Daten anzeigen lassen. Im folgenden Schritt haben wir eine Heat Map zu weiterer Bestimmung der Features erstellt.","d5ebf371":"Betrachten wir abschlie\u00dfend auch nochmal den Klassifikation Report der beiden Modelle.\nBeide Modelle haben eine gute Verteilung bei dem Support von False und True. Wir haben bei dem Modell KNN eine accuracy von 0,72 und bei dem Decision Tree Model 0,75. Somit haben wir einen guten Wert. Jedoch hat das Decision Tree Modell die besseren Werte, daher w\u00fcrde sich dies eher f\u00fcr den Einsatz nutzen.\n\nJedoch sind beide Modelle von den Daten sehr \u00e4hnlich, also der precision Wert, also die Richtigkeit von allen Positiven Vorhersagen und dem recall Wert, also der Wert welcher die wirklich richtigen aus den tats\u00e4chlichen positven vorhersagt. Der F1 Score repr\u00e4sentiert den gewichteten Durchschnitt von dem precsion und dem recall Wert.\n\nBetrachten wir aber auch nochmal die Ergebnisse aus der Confusion Matrix ist festzustellen, dass die Daten von der Confusion Matrix auch sehr \u00e4hnlich sind und sich die Differenzen jedoch ausgleichen.\n\nQuellen:\nKumar, A (2022): Accuracy, Precision, Recall & F1-Score \u2013 Python Examples, URL: https:\/\/vitalflux.com\/accuracy-precision-recall-f1-score-python-example\/ [02.02.2022].\nExsilio Solutions (2016): Accuracy, Precision, Recall & F1 Score: Interpretation of Performance Measures URL:\nhttps:\/\/blog.exsilio.com\/all\/accuracy-precision-recall-f1-score-interpretation-of-performance-measures\/ [02.02.2022].\n","491b0aed":"*  Analyse von fehlenden Daten","98eab1e5":"# 5. Modellbildung","4e677de5":"Mit dem n\u00e4chsten Code Abschnitt werden die besten bzw. optimalen hyperparameter Werte identifiziert.","d0c0b4a6":"Ausgabe von dem Klassifikation Report, anhand diesen ist es m\u00f6glich die accuracy, welche hier bei 0,72 liegt abzulesen.","34df3f29":"Der KNN Algorithmus wird spezifiziert in dem die besten Werte eingesetzt werden.","112ec523":"\n\nDie Confusion Matrix, wird in dem folgenden Schritt erstellt und visualisiert.\n\nDie Confusion Matrix sagt aus, dass die Klassifikation 155-mal einen schlechten Wein richtig vorhersagt und in 58-mal als einen guten Wein.\n\nZum anderen sagt Sie aus, dass Sie 61-mal einen guten Wein richtig vorhersagt und 206-mal einen Wein als schlecht vorhersagt, wohl er ein guter Wein ist.\n\nQuelle: Python-Kurs (o. J.): Metriken zu Evaluation, URL: https:\/\/www.python-kurs.eu\/metriken.php [02.0.2022].","60f22b03":"* **Decision Tree**","92fd5dd2":"* Daten-Visualisierung","391b6e3f":"Quelle: Wiedemann, T. (2021), Marketing Analytics Project, URL: https:\/\/www.kaggle.com\/tillwiedemann\/marketing-analytics-project\n[01.02.2022].","8e2cce5f":" Die erste f\u00fcnf Zeilen von der Tabelle werden ausgeben. Es k\u00f6nnen von den ersten f\u00fcnf Zeilen zu den jeweiligen Spalten die Daten betrachtet werden.","91da7dd7":"Der Decision Tree ist eine Baumartige Darstellung, welche wir im folgenden Teil bearbeiten und erstellen.\nDer Knotenpunkt stellt ein Merkmal da, die Kante von der Baumstruktur ist die Darstellung von dem Test Split von dem Attribut. Auf dem Blattknoten befinden sich die Klasse.","c9d5b5d3":"Es werden nochmal alle Spalten von dem Datensatz ausgegeben.","d4c3c56a":"Es wurde wie angesprochen eine Heat-Map erstellt. Die Heat-Map dient dazu zu erkennen, wie der Zusammenhang zu der Haupteigenschaft ist.\n\nDie Heat-Map stellt die Daten aus den Spalten aus dem Datensatz farbig in der folgenden Abbildung grafisch dar.","0422c89f":"Der Entscheidungsbaum wird trainiert.","eeebd818":"Quelle: M\u00fcller, R. (2020), Grid Search KNN IRIS, URL: https:\/\/www.kaggle.com\/rolandmueller\/grid-search-knn-iris [01.02.2022].\n\nQuelle: section (2021), Using Grid Search to Optimize Hyperparameters, URL: \nhttps:\/\/www.section.io\/engineering-education\/grid-search\/ [01.02.2022]."}}