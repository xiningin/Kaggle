{"cell_type":{"a6958a5a":"code","75d296ff":"code","32f52324":"code","f8021af0":"code","6132827c":"code","bf3b5778":"code","ed44ae4b":"code","07550a80":"code","90f6c91b":"code","0b3e6c2e":"code","fc6f7889":"code","1e9ad60e":"code","d5db5f78":"code","e3cdcd36":"code","713874d3":"code","b9fd0238":"code","48d25efe":"code","20129553":"code","e4074f9e":"code","8eb59657":"code","9c429179":"code","9ae57286":"code","c429a7bb":"code","3a416539":"code","3fac88fb":"code","4edc63d9":"code","4bedfa25":"code","9d39a5d0":"markdown","cf08655e":"markdown","ffa8c72c":"markdown","a640e52c":"markdown","4de65f07":"markdown","3e1a4842":"markdown","f87c514d":"markdown","95947cb8":"markdown"},"source":{"a6958a5a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","75d296ff":"import cv2\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\nfrom PIL import Image\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nfrom keras.utils import np_utils","32f52324":"parasitized_data = os.listdir('..\/input\/cell_images\/cell_images\/Parasitized\/')\nprint(parasitized_data[:10]) #the output we get are the .png files\n\nuninfected_data = os.listdir('..\/input\/cell_images\/cell_images\/Uninfected\/')\nprint('\\n')\nprint(uninfected_data[:10])","f8021af0":"plt.figure(figsize = (12,12))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    img = cv2.imread('..\/input\/cell_images\/cell_images\/Parasitized' + \"\/\" + parasitized_data[i])\n    plt.imshow(img)\n    plt.title('PARASITIZED : 1')\n    plt.tight_layout()\nplt.show()","6132827c":"plt.figure(figsize = (12,12))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    img = cv2.imread('..\/input\/cell_images\/cell_images\/Uninfected' + \"\/\" + uninfected_data[i+1])\n    plt.imshow(img)\n    plt.title('UNINFECTED : 0')\n    plt.tight_layout()\nplt.show()","bf3b5778":"data = []\nlabels = []\nfor img in parasitized_data:\n    try:\n        img_read = plt.imread('..\/input\/cell_images\/cell_images\/Parasitized\/' + \"\/\" + img)\n        img_resize = cv2.resize(img_read, (50, 50))\n        img_array = img_to_array(img_resize)\n        data.append(img_array)\n        labels.append(1)\n    except:\n        None\n        \nfor img in uninfected_data:\n    try:\n        img_read = plt.imread('..\/input\/cell_images\/cell_images\/Uninfected' + \"\/\" + img)\n        img_resize = cv2.resize(img_read, (50, 50))\n        img_array = img_to_array(img_resize)\n        data.append(img_array)\n        labels.append(0)\n    except:\n        None","ed44ae4b":"plt.imshow(data[0])\nplt.show()","07550a80":"image_data = np.array(data)\nlabels = np.array(labels)","90f6c91b":"idx = np.arange(image_data.shape[0])\nnp.random.shuffle(idx)\nimage_data = image_data[idx]\nlabels = labels[idx]","0b3e6c2e":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size = 0.2, random_state = 101)","fc6f7889":"y_train = np_utils.to_categorical(y_train, num_classes = 2)\ny_test = np_utils.to_categorical(y_test, num_classes = 2)","1e9ad60e":"print(f'SHAPE OF TRAINING IMAGE DATA : {x_train.shape}')\nprint(f'SHAPE OF TESTING IMAGE DATA : {x_test.shape}')\nprint(f'SHAPE OF TRAINING LABELS : {y_train.shape}')\nprint(f'SHAPE OF TESTING LABELS : {y_test.shape}')","d5db5f78":"import keras\nfrom keras.layers import Dense, Conv2D\nfrom keras.layers import Flatten\nfrom keras.layers import MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nfrom keras.models import Sequential\nfrom keras import backend as K\n\nfrom keras import optimizers","e3cdcd36":"def CNNbuild(height, width, classes, channels):\n    model = Sequential()\n    \n    inputShape = (height, width, channels)\n    chanDim = -1\n    \n    if K.image_data_format() == 'channels_first':\n        inputShape = (channels, height, width)\n    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = inputShape))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = chanDim))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(32, (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = chanDim))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(32, (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = chanDim))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    \n    model.add(Dense(512, activation = 'relu'))\n    model.add(BatchNormalization(axis = chanDim))\n    model.add(Dropout(0.5))\n    model.add(Dense(classes, activation = 'softmax'))\n    \n    return model","713874d3":"#instantiate the model\nheight = 50\nwidth = 50\nclasses = 2\nchannels = 3\nmodel = CNNbuild(height = height, width = width, classes = classes, channels = channels)\nmodel.summary()","b9fd0238":"#compile the model\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])","48d25efe":"#fit the model onto the dataset\nh = model.fit(x_train, y_train, epochs = 20, batch_size = 32)","20129553":"plt.figure(figsize = (18,8))\nplt.plot(range(20), h.history['acc'], label = 'Training Accuracy')\nplt.plot(range(20), h.history['loss'], label = 'Taining Loss')\n#ax1.set_xticks(np.arange(0, 31, 5))\nplt.xlabel(\"Number of Epoch's\")\nplt.ylabel('Accuracy\/Loss Value')\nplt.title('Training Accuracy and Training Loss')\nplt.legend(loc = \"best\")\n\n# ax2.plot(range(20), h.history['loss'], label = 'Training Loss')\n# ax2.plot(range(20), h.history['val_loss'], label = 'Validation Loss')\n# #ax2.set_xticks(np.arange(0, 31, 5))\n# ax2.set_xlabel(\"Number of Epoch's\")\n# ax2.set_ylabel('Loss Value')\n# ax2.set_title('Training Loss vs Validation Loss')\n# ax2.legend(loc = \"best\")","e4074f9e":"#evaluate the model on test data\npredictions = model.evaluate(x_test, y_test)","8eb59657":"print(f'LOSS : {predictions[0]}')\nprint(f'ACCURACY : {predictions[1]}')","9c429179":"from keras.preprocessing.image import ImageDataGenerator","9ae57286":"train_datagen = ImageDataGenerator(rescale = 1\/255.,\n                                  horizontal_flip = True,\n                                  width_shift_range = 0.2,\n                                  height_shift_range = 0.2,\n                                  fill_mode = 'nearest',\n                                  zoom_range = 0.3,\n                                  rotation_range = 30)\nval_datagen = ImageDataGenerator(rescale = 1\/255.)\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size = 64, shuffle = False)\nval_generator = val_datagen.flow(x_test, y_test, batch_size = 64, shuffle = False)","c429a7bb":"#calling the same model as above\nmodel_aug = CNNbuild(height = height, width = width, classes = classes, channels = channels)","3a416539":"#compile the model\noptim = optimizers.Adam(lr = 0.001, decay = 0.001 \/ 64)\nmodel_aug.compile(loss = 'categorical_crossentropy', optimizer = optim, metrics = ['accuracy'])","3fac88fb":"#fit the model on the augmented dataset\nh_aug = model_aug.fit_generator(train_generator, steps_per_epoch = len(x_train) \/\/ 64, epochs = 50)","4edc63d9":"#evaluate the model on augmented test data\npredict = model_aug.evaluate_generator(val_generator, steps = 5)","4bedfa25":"print(f'LOSS ON TEST DATA AFTER DATA AUGMENTATION : {predict[0]}')\nprint(f'ACCURACY ON TEST DATA AFTER DATA AUGMENTATION : {predict[1]}')","9d39a5d0":"**1. PARASITIZED DATA**","cf08655e":"**As you can see there is a slight improvement on the testing accuracy on the augmented dataset as comapred to dataset without data augmentation.\nSo data augmentation can prove very useful when the amount of dataset availabe at hand is very less.**","ffa8c72c":"**2. UNINFECTTED DATA**","a640e52c":"**WITH DATA AUGMENTATION**","4de65f07":"**The performance of the model on the test data seems to fairly good with 95.77% accuracy.**","3e1a4842":"* **BUILDING THE CNN MODEL (without data augmentation)**","f87c514d":"**DATA VISUALIZATION**[](http:\/\/)","95947cb8":"**One can clearly see the difference between the infected and uninfected. You can observe a small clot inside the cellular image for infected while for the uninfected the cellular image is clean without any clots.**"}}