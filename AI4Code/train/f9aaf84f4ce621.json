{"cell_type":{"23bc328e":"code","e76f3822":"code","dfee9bb2":"code","16aa008d":"code","e64e13e3":"code","32f12dbf":"code","02f14901":"code","9ac0d456":"code","79cbb3fe":"code","be241c3f":"code","e863ef1e":"code","67132ae0":"code","3c1788d4":"code","6688380a":"code","6518df61":"code","d53fcdb4":"code","46254a90":"code","186000de":"code","27b73a86":"code","40ee9027":"markdown","18aba7c9":"markdown","1e935175":"markdown","69cc1912":"markdown","fb9b7173":"markdown","4a88b9c8":"markdown","89769ceb":"markdown","2619e23c":"markdown","2d635353":"markdown","cdbc199c":"markdown"},"source":{"23bc328e":"import time\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBClassifier\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset","e76f3822":"PATH = \"\/kaggle\/input\/digit-recognizer\/\"\n\ntorch.manual_seed(2020)\nnp.random.seed(2020)\nrandom.seed(2020)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif device.type == \"cuda\":\n    torch.cuda.get_device_name()","dfee9bb2":"embedding_dims = 2\nbatch_size = 32\nepochs = 50","16aa008d":"train_df = pd.read_csv(PATH+\"train.csv\")\ntest_df = pd.read_csv(PATH+\"test.csv\")\n\ntrain_df.head()","e64e13e3":"class MNIST(Dataset):\n    def __init__(self, df, train=True, transform=None):\n        self.is_train = train\n        self.transform = transform\n        self.to_pil = transforms.ToPILImage()\n        \n        if self.is_train:            \n            self.images = df.iloc[:, 1:].values.astype(np.uint8)\n            self.labels = df.iloc[:, 0].values\n            self.index = df.index.values\n        else:\n            self.images = df.values.astype(np.uint8)\n        \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, item):\n        anchor_img = self.images[item].reshape(28, 28, 1)\n        \n        if self.is_train:\n            anchor_label = self.labels[item]\n\n            positive_list = self.index[self.index!=item][self.labels[self.index!=item]==anchor_label]\n\n            positive_item = random.choice(positive_list)\n            positive_img = self.images[positive_item].reshape(28, 28, 1)\n            \n            negative_list = self.index[self.index!=item][self.labels[self.index!=item]!=anchor_label]\n            negative_item = random.choice(negative_list)\n            negative_img = self.images[negative_item].reshape(28, 28, 1)\n            \n            if self.transform:\n                anchor_img = self.transform(self.to_pil(anchor_img))\n                positive_img = self.transform(self.to_pil(positive_img))\n                negative_img = self.transform(self.to_pil(negative_img))\n            \n            return anchor_img, positive_img, negative_img, anchor_label\n        \n        else:\n            if self.transform:\n                anchor_img = self.transform(self.to_pil(anchor_img))\n            return anchor_img\n        ","32f12dbf":"train_ds = MNIST(train_df, \n                 train=True,\n                 transform=transforms.Compose([\n                     transforms.ToTensor()\n                 ]))\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)","02f14901":"test_ds = MNIST(test_df, train=False, transform=transforms.ToTensor())\ntest_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)","9ac0d456":"class TripletLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(TripletLoss, self).__init__()\n        self.margin = margin\n        \n    def calc_euclidean(self, x1, x2):\n        return (x1 - x2).pow(2).sum(1)\n    \n    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n        distance_positive = self.calc_euclidean(anchor, positive)\n        distance_negative = self.calc_euclidean(anchor, negative)\n        losses = torch.relu(distance_positive - distance_negative + self.margin)\n\n        return losses.mean()","79cbb3fe":"class Network(nn.Module):\n    def __init__(self, emb_dim=128):\n        super(Network, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 32, 5),\n            nn.PReLU(),\n            nn.MaxPool2d(2, stride=2),\n            nn.Dropout(0.3),\n            nn.Conv2d(32, 64, 5),\n            nn.PReLU(),\n            nn.MaxPool2d(2, stride=2),\n            nn.Dropout(0.3)\n        )\n        \n        self.fc = nn.Sequential(\n            nn.Linear(64*4*4, 512),\n            nn.PReLU(),\n            nn.Linear(512, emb_dim)\n        )\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = x.view(-1, 64*4*4)\n        x = self.fc(x)\n        # x = nn.functional.normalize(x)\n        return x","be241c3f":"def init_weights(m):\n    if isinstance(m, nn.Conv2d):\n        torch.nn.init.kaiming_normal_(m.weight)","e863ef1e":"model = Network(embedding_dims)\nmodel.apply(init_weights)\nmodel = torch.jit.script(model).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch.jit.script(TripletLoss())","67132ae0":"model.train()\nfor epoch in tqdm(range(epochs), desc=\"Epochs\"):\n    running_loss = []\n    for step, (anchor_img, positive_img, negative_img, anchor_label) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n        anchor_img = anchor_img.to(device)\n        positive_img = positive_img.to(device)\n        negative_img = negative_img.to(device)\n        \n        optimizer.zero_grad()\n        anchor_out = model(anchor_img)\n        positive_out = model(positive_img)\n        negative_out = model(negative_img)\n        \n        loss = criterion(anchor_out, positive_out, negative_out)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss.append(loss.cpu().detach().numpy())\n    print(\"Epoch: {}\/{} - Loss: {:.4f}\".format(epoch+1, epochs, np.mean(running_loss)))\n","3c1788d4":"torch.save({\"model_state_dict\": model.state_dict(),\n            \"optimzier_state_dict\": optimizer.state_dict()\n           }, \"trained_model.pth\")","6688380a":"train_results = []\nlabels = []\n\nmodel.eval()\nwith torch.no_grad():\n    for img, _, _, label in tqdm(train_loader):\n        train_results.append(model(img.to(device)).cpu().numpy())\n        labels.append(label)\n        \ntrain_results = np.concatenate(train_results)\nlabels = np.concatenate(labels)\ntrain_results.shape","6518df61":"plt.figure(figsize=(15, 10), facecolor=\"azure\")\nfor label in np.unique(labels):\n    tmp = train_results[labels==label]\n    plt.scatter(tmp[:, 0], tmp[:, 1], label=label)\n\nplt.legend()\nplt.show()","d53fcdb4":"tree = XGBClassifier(seed=2020)\ntree.fit(train_results, labels)","46254a90":"test_results = []\ntest_labels = []\n\nmodel.eval()\nwith torch.no_grad():\n    for img in tqdm(test_loader):\n        test_results.append(model(img.to(device)).cpu().numpy())\n        \ntest_results = np.concatenate(test_results)\n\nplt.figure(figsize=(15, 10), facecolor=\"azure\")\nplt.scatter(test_results[:, 0], test_results[:, 1], label=label)\n\ntest_results.shape","186000de":"submit = pd.read_csv(PATH+\"sample_submission.csv\")\nsubmit.Label = tree.predict(test_results)\n\nsubmit.head()","27b73a86":"submit.to_csv(\"submission.csv\", index=False)","40ee9027":"## Submit","18aba7c9":"### Create Instances\nUse JIT compilation for high speed.","1e935175":"## Define TripletLoss","69cc1912":"## Visualization ","fb9b7173":"## Training Loop","4a88b9c8":"## Define class MNIST\nI'll define `class MNIST` which was inherited `torch.utils.data.Dataset`.","89769ceb":"### weight initialize","2619e23c":"## Save Params","2d635353":"## Training XGBoost Model","cdbc199c":"## Define Neural Network"}}