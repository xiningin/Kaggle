{"cell_type":{"042f99a3":"code","6025da56":"code","6e9dae66":"code","eb211f81":"code","24f85065":"code","6d6c187b":"code","cf8f6bf2":"code","04646c63":"code","2895f65f":"code","86a6d34b":"code","db47a358":"code","e4301c45":"code","6eb00638":"code","6f6a1fc9":"code","ef8f28f4":"code","4d6478f3":"code","55cffb48":"code","a935d619":"markdown","a4a225fc":"markdown","7bf83922":"markdown","9830b629":"markdown","ccb899b3":"markdown","38014988":"markdown","84ce0379":"markdown","945bcd94":"markdown","9ca339e5":"markdown","5ce9fad4":"markdown","2236cdd4":"markdown","4a2d6ce8":"markdown","41a8d554":"markdown"},"source":{"042f99a3":"!pip install ..\/input\/timmwhl\/timm-0.3.3-py3-none-any.whl","6025da56":"import random\nimport os\nimport sys\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom tqdm import tqdm\nimport torch.nn.functional as F\n\nimport albumentations as A\nfrom albumentations import Compose\nfrom albumentations.pytorch import ToTensorV2\nimport cv2","6e9dae66":"import warnings\nwarnings.filterwarnings(\"ignore\")","eb211f81":"sys.path.append('..\/input\/pytorchimagemodelsmaster\/pytorch-image-models-master')","24f85065":"DATA_PATH = '..\/input\/cassava-leaf-disease-classification\/'\nbs = 16\nsz = 448\nTIMM_MODEL = 'resnet50'","6d6c187b":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nSEED = 1234\nseed_everything(SEED)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","cf8f6bf2":"class CassavaDataset(Dataset):\n    \n    def __init__(self, dataframe, root_dir, transforms=None):\n        super().__init__()\n        self.dataframe = dataframe\n        self.root_dir = root_dir\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.dataframe)\n    \n    def get_img_bgr_to_rgb(self, path):\n        im_bgr = cv2.imread(path)\n        im_rgb = im_bgr[:, :, ::-1]\n        return im_rgb\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img_name = os.path.join(self.root_dir,\n                                self.dataframe.iloc[idx, 0])\n        image = self.get_img_bgr_to_rgb(img_name)\n        if self.transforms:\n            image = self.transforms(image=image)['image']\n        csv_row = self.dataframe.iloc[idx, 1:]\n        sample = {\n            'image': image, \n            'label': csv_row.label,\n        }\n        return sample","04646c63":"def test_transforms():\n    return Compose([\n            A.Resize(sz, sz),\n            A.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225], \n                        max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","2895f65f":"class CassavaNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        backbone = timm.create_model(TIMM_MODEL, pretrained=False)\n        n_features = backbone.fc.in_features\n        self.backbone = nn.Sequential(*backbone.children())[:-2]\n        self.classifier = nn.Linear(n_features, 5)\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n\n    def forward_features(self, x):\n        x = self.backbone(x)\n        return x\n\n    def forward(self, x):\n        feats = self.forward_features(x) #self.backbone(x)\n        x = self.pool(feats).view(x.size(0), -1) # avg pool and flattening\n        x = self.classifier(x) # Linear classifier\n        return x, feats","86a6d34b":"model = CassavaNet().to(device)","db47a358":"def predict(model, ckpts, dataloader):    \n    predict_list=[]\n    with torch.no_grad():\n            for _, data in enumerate(dataloader):\n                avg_preds = []\n                for ckpt in ckpts:\n                    model.load_state_dict(ckpt['state_dict'])\n                    model.eval()                    \n                    images, label = data.values()\n                    images =  images.to(device)\n                    outputs, _ = model(images)\n                    preds = F.softmax(outputs).to('cpu').numpy()\n                    avg_preds.append(preds)                \n                predict_list.append(np.mean(avg_preds, axis=0))            \n            predict_list = np.concatenate(predict_list)\n                \n    return predict_list.argmax(axis=1)","e4301c45":"test_df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\n\ntest_dir = '..\/input\/cassava-leaf-disease-classification\/test_images\/'\n\ntest_ds = CassavaDataset(dataframe=test_df,\n                         root_dir=test_dir,\n                         transforms=test_transforms())\n\ntest_dl = DataLoader(test_ds, batch_size=bs, \n                                      shuffle=False, num_workers=8, \n                                      pin_memory=True)","6eb00638":"ckpts=[]\ntrained_model_path = \"..\/input\/cassavalblsmoothingresnet50\"\nfor path in os.listdir(trained_model_path):\n    ckpts.append(torch.load(os.path.join(trained_model_path, path)))\n","6f6a1fc9":"test_predict_list=predict(model, ckpts, test_dl)","ef8f28f4":"test_predict_list","4d6478f3":"test_df","55cffb48":"test_df['label'] = test_predict_list\ntest_df[['image_id', 'label']].to_csv('submission.csv', index=False)\ntest_df.head()","a935d619":"### If you like the notebook, please upvote !!","a4a225fc":"# Model Loading","7bf83922":"# Transforms for test data using albumentations","9830b629":"# Prediction","ccb899b3":"# Required Variables","38014988":"# Information about the notebook\n\nThis notebook is an example of PyTorch Inference for ongoing Cassava Leaf Disease Classification. \n\nFor the training of the model, I have forked this excellent [notebook](https:\/\/www.kaggle.com\/sachinprabhu\/pytorch-resnet50-snapmix-train-pipeline) with little tweak of label smoothing loss. **Resnet50 + SnapMix + Label Smoothing Loss** combinations are used for training of the models.\n\nLabel Smoothing Loss is implemented like this - [Source](https:\/\/medium.com\/towards-artificial-intelligence\/how-to-use-label-smoothing-for-regularization-aa349f7f1dbb)  \n\n\n    def linear_combination(x, y, epsilon): \n        return epsilon*x + (1-epsilon)*y\n\n    def reduce_loss(loss, reduction='mean'):\n        return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n\n\n    class LabelSmoothingCrossEntropy(nn.Module):\n        def __init__(self, epsilon:float=0.1, reduction='mean'):\n            super().__init__()\n            self.epsilon = epsilon\n            self.reduction = reduction\n    \n        def forward(self, preds, target):\n            n = preds.size()[-1]\n            log_preds = F.log_softmax(preds, dim=-1)\n            loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n            nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n            return linear_combination(loss\/n, nll, self.epsilon)\n","84ce0379":"# Data Loading","945bcd94":"# Import required libs","9ca339e5":"# Model","5ce9fad4":"# Adding sys path for offline import","2236cdd4":"# Inference","4a2d6ce8":"# Submission ","41a8d554":"# Cassava Dataset"}}