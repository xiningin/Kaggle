{"cell_type":{"cc87ace0":"code","740d4f47":"code","79bf06c6":"code","db3b807d":"code","f67a9266":"code","04dca7b9":"code","1242244c":"code","8822f1b9":"code","9044af78":"code","b37a0180":"code","ededc656":"code","751f9374":"code","a339951a":"code","b5738fcd":"code","a8726e06":"code","d2dc5b07":"code","7de9c99a":"code","4abf079f":"code","c9282b12":"code","f52da6c2":"code","6233cfba":"code","eedc2952":"code","e2d2c1e8":"code","e829592a":"code","7f665db2":"code","ca200c66":"code","782f1f2a":"code","dba99f08":"code","cf49d460":"code","4dbf7fde":"code","cf0b708f":"code","1149f475":"code","782d2f6a":"code","5ecc2906":"code","4a160164":"code","1665ff48":"code","965fcd72":"code","c15f9fbb":"code","d4c7561c":"code","ac8dbf9e":"code","df0602b8":"code","045ea0f4":"code","b88921cd":"code","9b3c647d":"code","00fbbb19":"markdown","100e0e8a":"markdown","aaf86f0a":"markdown","311a4bdf":"markdown","3441703f":"markdown","88759d19":"markdown","995e3e8b":"markdown","ca004bd9":"markdown","5477efcd":"markdown","6abcc2f4":"markdown","291cc68c":"markdown","0a2c05dc":"markdown","f9595c5f":"markdown","0f0f1e1f":"markdown","b8bc3a38":"markdown","d476d116":"markdown","2821c64e":"markdown","a1ed902e":"markdown","f8c68177":"markdown","6dd2db5e":"markdown","dc81f0d8":"markdown","8200ea66":"markdown","aec9b60a":"markdown","b316eebe":"markdown","d05766c0":"markdown","c272df3b":"markdown","efb582e0":"markdown"},"source":{"cc87ace0":"import re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nimport warnings\nfrom sklearn.model_selection import StratifiedShuffleSplit,train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder,OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\nwarnings.filterwarnings('ignore')\n%config Completer.use_jedi = False","740d4f47":"df=pd.read_csv('..\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv')\ndf","79bf06c6":"df.info()","db3b807d":"df.describe()","f67a9266":"strings=[]\nfor i in df['total_sqft']:\n    res = ''.join(re.findall(\"[a-zA-Z]+\",i))\n    if res not in strings:\n        strings.append(res)\nstrings.append('-')\nstrings.remove('')\nstrings=np.array([i[0] for i in strings])\nstrigs=np.unique(strings)","04dca7b9":"for i in strings:\n    df.drop(df.loc[df['total_sqft'].str.contains(i)].index,axis=0,inplace=True)\ndf['total_sqft']=[float(i) for i in df['total_sqft']]","1242244c":"figure,axis=plt.subplots(figsize=(20,5),nrows=1,ncols=3)\nsns.set_style('darkgrid')\nj=0\nfor i in df.columns[6:]:\n    sns.histplot(df[i],kde=True,ax=axis[j])\n    j+=1","8822f1b9":"# !pip install opencage\n# from opencage.geocoder import OpenCageGeocode\n\n# key = 'hi'\n\n# geocoder = OpenCageGeocode(key)\n\n# list_lat = []   \n# list_long = []\n# unavailable=[]\n\n# for i in df['location'].unique(): \n#     query = str(i)+','+ 'bangalore'\n#     results = geocoder.geocode(query) \n#     if results==[]:\n#         unavailable.append(i)\n#         continue\n#     else:\n#         lat = results[0]['geometry']['lat']\n#         long = results[0]['geometry']['lng']\n\n#         list_lat.append(lat)\n#         list_long.append(long)\n","9044af78":"# location_details=pd.DataFrame(columns=['lattitude','longitude'])\n# location_details['lattitude']=np.array(list_lat)\n# location_details['longitude']=np.array(list_long)\n","b37a0180":"# location_details\n# location_details.to_csv('location_details.csv', header=True, index=True)","ededc656":"unavailable=['Near Electronic City,','bsk 6th stage 2ad block near sri conversation hall'] # results of unfindable locations\nfor i in unavailable:\n    df.drop(df.loc[df['location']==i].index,axis=0,inplace=True)","751f9374":"#loading the saved location info containing latitude and longitude of each unique location\nlocation_details=pd.read_csv('..\/input\/location-detailsplaces-in-bangalore\/location_details.csv')\nlocation_details=location_details[['lattitude','longitude']]","a339951a":"df['latitude']=df['location']\ndf['longitude']=df['location']\nlatitude={df['location'].unique()[i]:location_details['lattitude'][i] for i in range(len(location_details['lattitude']))}\nlongitude={df['location'].unique()[i]:location_details['longitude'][i] for i in range(len(location_details['lattitude']))}\ndf['latitude'] =df['latitude'].map(latitude)\ndf['longitude'] =df['longitude'].map(longitude)","b5738fcd":"# attribute size has some outliers removing them\noutliers=df['size'].value_counts()<=2\nvals=outliers[outliers].index\nfor i in vals:\n    df.drop(df.loc[df['size']==i].index,axis=0,inplace=True)","a8726e06":"df.corr() \ndf['total_sqft'].describe()\nplt.figure(figsize=(8,5))\nsns.scatterplot(df['total_sqft'],df['price'],alpha=0.7)\nplt.show()  ","d2dc5b07":"train_data,test_data=train_test_split(df,test_size=0.2,random_state=42)","7de9c99a":"sns.scatterplot(train_data['total_sqft'],df['price'])\nplt.show()","4abf079f":"train_data_copy=train_data.copy() # a copy of the data for safe use","c9282b12":"plt.figure(figsize=(10,5))\nsns.violinplot(x='area_type',y='price',data=train_data,split=True)\nplt.show()","f52da6c2":"plt.figure(figsize=(10,5))\nsns.boxplot(x='bath',y='price',data=train_data)\nplt.show()","6233cfba":"plt.figure(figsize=(10,5))\nsns.violinplot(x='balcony',y='price',data=train_data,split=True)\nplt.show()","eedc2952":"figure=plt.figure(figsize=(10,5))\nprice_filt1=train_data.loc[train_data['price']<200]\nsns.scatterplot(train_data['longitude'],train_data['latitude'],hue=price_filt1['price'],palette='rocket',alpha=0.7,size=train_data['price'],sizes=(40,400))\nplt.legend(bbox_to_anchor=(1, 1), loc='upper left')\nplt.show()","e2d2c1e8":"#dropping society,location replaced by latitude ad longitude\ntrain_data.drop(columns={'location','society'},inplace=True)","e829592a":"sns.countplot(train_data['area_type'])\nfor i in train_data['area_type'].unique():\n    type_=train_data.loc[train_data['area_type']==i]\n    average_price=type_['price'].sum(axis=0)\/type_.shape[0]\n    print(f'areatype {i} average price = {average_price}')","7f665db2":"area_encoder={'Super built-up  Area':3 ,'Plot  Area':4 ,'Built-up  Area':2,'Carpet  Area':1}\ntrain_data['area_type']=train_data['area_type'].map(area_encoder)","ca200c66":"plt.figure(figsize=(5,20))\ntrain_data['availability'].unique()\nax=sns.scatterplot(train_data.price,train_data['availability'])\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)\nplt.show()","782f1f2a":"availability_enco={train_data['availability'].unique()[i]:0 for i in range(len(train_data['availability'].unique()))}\navailability_enco['Ready To Move']=1\navailability_enco['Immediate Possession']=1\ntrain_data['availability']=train_data['availability'].map(availability_enco)","dba99f08":"plt.figure(figsize=(10,5))\nsns.stripplot(x='balcony',y='price',data=train_data, jitter=True, \n              hue='availability', dodge=True)\nplt.show()","cf49d460":"plt.figure(figsize=(10,5))\nsns.stripplot(x='area_type',y='price',data=train_data, jitter=True, \n              hue='availability', dodge=True)\nplt.show()","4dbf7fde":"plt.figure(figsize=(10,5))\nsns.stripplot(x='bath',y='price',data=train_data, jitter=True, \n              hue='availability', dodge=True)\nplt.show()","cf0b708f":"sns.scatterplot(train_data['price'],train_data['size'])\nplt.show()","1149f475":"train_data.drop(train_data.loc[train_data['size'].isna()==True].index,axis=0,inplace=True)","782d2f6a":"sizes=['1 Bedroom','2 Bedroom','1 RK','3 Bedroom','1 BHK','4 Bedroom','2 BHK','5 Bedroom','3 BHK','6 Bedroom','4 BHK', '7 Bedroom','5 BHK','8 Bedroom','6 BHK','9 Bedroom','7 BHK', '10 Bedroom', '8 BHK','9 BHK','10 BHK', '14 BHK', '19 BHK']\noe=OrdinalEncoder(categories=[sizes])\ntrain_data['size']=oe.fit_transform(train_data['size'].to_numpy().reshape(-1,1))","5ecc2906":"mms=minmax_scale\ntrain_data[['total_sqft','price']]=mms(train_data[['total_sqft','price']],feature_range=(0,10))","4a160164":"nrows=3\nncols=3\ncolumns=train_data.columns\nfigure,axis=plt.subplots(nrows=3,ncols=3,figsize=(20,10))\nvalue=0\nfor i in range(nrows):\n    for j in range(ncols):\n        x=train_data[columns[value]]\n        sns.distplot(x,ax=axis[i][j],color='orange')\n        value+=1","1665ff48":"plt.figure(figsize=(10,7))\nsns.heatmap(train_data.corr(),annot=True,cmap='Blues')\nplt.show()","965fcd72":"def data_operations(data):\n    data.drop(columns={'location','society'},inplace=True)\n    area_encoder={'Super built-up  Area':3 ,'Plot  Area':4 ,'Built-up  Area':2,'Carpet  Area':1}\n    data['area_type']=data['area_type'].map(area_encoder).astype(np.float64)\n    availability_enco={data['availability'].unique()[i]:0 for i in range(len(train_data['availability'].unique()))}\n    availability_enco['Ready To Move']=1\n    availability_enco['Immediate Possession']=1\n    data['availability']=data['availability'].map(availability_enco)\n    data.drop(data.loc[data['size'].isna()==True].index,axis=0,inplace=True)\n    sizes=['1 Bedroom', '2 Bedroom', '1 RK', '3 Bedroom', '1 BHK','4 Bedroom', '2 BHK','5 Bedroom','3 BHK','6 Bedroom','4 BHK','7 Bedroom','5 BHK','8 Bedroom','6 BHK','9 Bedroom','7 BHK','10 Bedroom','8 BHK','11 Bedroom','9 BHK','12 Bedroom','10 BHK', '11 BHK','14 BHK','16 BHK','19 BHK','27 BHK']\n    oe=OrdinalEncoder(categories=[sizes])\n    data['size']=oe.fit_transform(data['size'].to_numpy().reshape(-1,1))\n    mms=minmax_scale\n    data[['total_sqft','price']]=mms(data[['total_sqft','price']],feature_range=(0,10))\n    return data","c15f9fbb":"test=data_operations(test_data)\ntrain=data_operations(train_data_copy)\n\ntrainx = train.drop('price',1)\ntrainy = train['price']\ntestx = test.drop('price',1)\ntesty = test['price']","d4c7561c":"pipeline_1 = Pipeline([('imputer',SimpleImputer(strategy=\"median\")),\n                     ('scaler',StandardScaler()),\n                     ('regressior',LinearRegression())\n                      ])\n                     \npipeline_2 = Pipeline([('imputer',SimpleImputer(strategy='median')),\n                      ('scaler',StandardScaler()),\n                       ('regressor',DecisionTreeRegressor())\n                      ])\n\npipeline_3 = Pipeline([('imputer',SimpleImputer(strategy=\"median\")),\n                     ('scaler',StandardScaler()),\n                     ('regressior',RandomForestRegressor())\n                      ])\n                     \npipeline_4 = Pipeline([('imputer',SimpleImputer(strategy='median')),\n                      ('scaler',StandardScaler()),\n                       ('regressor',KNeighborsRegressor())\n                      ])\npipeline_5 = Pipeline([('imputer',SimpleImputer(strategy='median')),\n                      ('scaler',StandardScaler()),\n                       ('regressor',XGBRegressor())\n                      ])","ac8dbf9e":"pipelines=[pipeline_1,pipeline_2,pipeline_3,pipeline_4,pipeline_5]\nfrom sklearn.model_selection import cross_val_score\ndef cross(pipeline):\n    scores=cross_val_score(pipeline,trainx,trainy,cv=5,scoring=\"neg_mean_squared_error\")\n    rmse=np.sqrt(-scores)\n    return rmse.mean(),rmse.std()","df0602b8":"mean=[]\nstd=[]\nfor pipeline in pipelines:\n    a,b=cross(pipeline)\n    mean.append(a)\n    std.append(b)\n    \nresults=pd.DataFrame(columns=['mean','std'])\nresults['mean']=mean\nresults['std']=std\nresults.index=['p1','p2','p3','p4','p5']    ","045ea0f4":"results","b88921cd":"pipeline_5.fit(trainx,trainy)\npreds=pipeline_5.predict(testx)\nmse=mean_squared_error(preds,testy)\nmae=metrics.mean_absolute_error(preds,testy)\nrmse=np.sqrt(mse)\n","9b3c647d":"print(f'''\nMAE on test_data = {mae}\nMSE on test_data = {mse}\nRMSE on test_data = {rmse}''')","00fbbb19":"total_sqft contains some data that are in other units we can drop them","100e0e8a":"## Model Building\n#### Setting up Pipelines\n1. we will setup pipelines for the following algorithms\n*     linearregression\n*     decisiontreeregressor\n*     randomforestregressor\n*     kneighborsregressor\n*     xgbregressor\n\n1. we use root mean square error as our evaluation metric\n1. we will look at which model fits best in the training data after running cross validation \n1. we will use the same model in the test data and see the predictions","aaf86f0a":"#### Making a function (the proper way)\n1. all of the transformation we have done to the trin_data has to be applied o the test data as well \n1. so its safe to make a class or a function that does all of that so that everything can well be a part of a pipeline\n1. so the function below does all the things that we have done so far","311a4bdf":"\n\n#### **If you have any suggestions or questions,please consider posting them!**\n\n#### **If you liked the notebook please upvote.**","3441703f":"## Data Preprocessing & EDA","88759d19":"#### Correlation","995e3e8b":"**Imports**","ca004bd9":"## Data","5477efcd":"#### Getting Latitude, Longitude\n* Based on the location we can take latitude,longitude from web\n* so once we get the location info we can output it to a different file,then import it to concatenate with the original dataframe replacing the originat df['location'] so that we dont have to run this code many times,its a litle time consuming\n* also often times its not worth adding features like latitude,longitude. yet, why not try it!","6abcc2f4":"At this point we can split the data.but before that, lets look at the most correlated attributes and see if we want to shuffle split on the basis of most correlated attributes","291cc68c":"\n![1_ii46F2WDo9mvFvdxzUvGbQ.png](attachment:bd0aabc4-fa17-459c-90ad-d8a8fc355d94.png)","0a2c05dc":"**takeaways:**\n* \"ready to move\" are often being asked more price(but most of the datapoints are 'ready to move'. hence the second point)\n* most of them under construction tent to ask a discounted price. maybe to attract customers or something","f9595c5f":"#### Joining location information on the dataframe","0f0f1e1f":"#### Dealing with attribute 'availability'\n* from the plot below i dont think its an important parameter but,\n* most of the high priced apartments are status-'ready to move', also in some places its 'immediate posession' more or less the same thing.\n* so lets try labelling - ready to move or immediate possession = 0 | else 1 ","b8bc3a38":"### Splitting to train and test data\n* the reason why am doing split now has nothing to do with the transformations i'm gonna do on training data\n* all the transformations will be the same on both sets of datas.\n* 1but for the further exploitation of the data it is safe to only look at the training data","d476d116":"\n![download.jpg](attachment:4a723a7b-0892-472f-a8db-ab6805f52e3c.jpg)","2821c64e":"## Training results","a1ed902e":"#### Dealing with atribute 'size'\n* size really is, howmany rooms are there in the apartment \n* so i'm making a separate dictionary that translates howmany rooms in an apartment(for example 2bhk=4 rooms)\n* then there are some outliers.we will drop them","f8c68177":"#### Scaling\n1. price and total sqft must be scaled\n1. using minmax scale in range-(0,10)","6dd2db5e":"#### Looking at the train data","dc81f0d8":"#### Distribution plots","8200ea66":"#### Looking at how the data is srpead in space","aec9b60a":"## Bangalore House Price Prediction:Regression","b316eebe":"#### Dealing with attribute 'area_type'","d05766c0":"## Test result","c272df3b":"#### A density plot to understand all the numerical attributes\n","efb582e0":"### **END OF THE NOTEBOOK**"}}