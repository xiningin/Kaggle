{"cell_type":{"0af8122b":"code","8e3a9242":"code","ccc16e0f":"code","bb60e214":"code","ac9607ba":"code","400ae7c8":"code","b3b9dec3":"code","4bb96f5c":"markdown","f40af2b7":"markdown","cf2e3bc7":"markdown","a9ead8e7":"markdown","e37e2f78":"markdown","544b8b24":"markdown"},"source":{"0af8122b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e3a9242":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nfrom __future__ import print_function, division\nfrom builtins import range, input\n# Note: you may need to update your version of future\n# sudo pip install -U future\n\nfrom keras.models import Model\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\n\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ccc16e0f":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nimage_path = '..\/input\/peanut-stnds\/train'\nimage_files = glob(image_path +  '\/*\/*.jpeg')# original was *.JP*G, then I changed to jpeg to avoid error \"ValueError: 'a' cannot be empty unless no samples are taken\"","bb60e214":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# look at an image for fun\n\nplt.imshow(image.load_img(np.random.choice(image_files)));","ac9607ba":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# add preprocessing layer to the front of VGG\nresnet = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n\n# view the structure of the model\n# if you want to confirm we need activation_49\nresnet.summary()","400ae7c8":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# make a model to get output before flatten\nactivation_layer = resnet.get_layer('conv5_block3_out')\n\n# create a model object\nmodel = Model(inputs=resnet.input, outputs=activation_layer.output)","b3b9dec3":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# get the feature map weights\nfinal_dense = resnet.get_layer('predictions')\nW = final_dense.get_weights()[0]\n\n#while True:\ni = 0\nfor i in range(10):\n  img = image.load_img(np.random.choice(image_files), target_size=(224, 224))\n  x = preprocess_input(np.expand_dims(img, 0))\n  fmaps = model.predict(x)[0] # 7 x 7 x 2048\n\n  # get predicted class\n  probs = resnet.predict(x)\n  classnames = decode_predictions(probs)[0]\n  print(classnames)\n  classname = classnames[0][1]\n  pred = np.argmax(probs[0])\n\n  # get the 2048 weights for the relevant class\n  w = W[:, pred]\n\n  # \"dot\" w with fmaps\n  cam = fmaps.dot(w)\n\n  # upsample to 224 x 224\n  # 7 x 32 = 224\n  cam = sp.ndimage.zoom(cam, (32, 32), order=1)\n\n  plt.subplot(1,2,1)\n  plt.imshow(img, alpha=0.8)\n  plt.imshow(cam, cmap='jet', alpha=0.5)\n  plt.subplot(1,2,2)\n  plt.imshow(img)\n  plt.title(classname)\n  plt.show();","4bb96f5c":"#Acknowledgment:\n\nYvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map","f40af2b7":"#Build the model","cf2e3bc7":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSZeLVWB3sjUmWZUg4bOdSXrbo4gI1tDtXAlQ&usqp=CAU)arXiv-vanity.com","a9ead8e7":"#Image files","e37e2f78":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map","544b8b24":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #0000FF;\"><b style=\"color:orange;\">Class Activation Map<\/b><\/h1><\/center>\n\n\"Class Activation Maps (CAM) is a powerful technique used in Computer Vision for classification tasks. It allows the scientist to inspect the image to be categorized and understand which parts\/pixels of that image have contributed more to the final output of the model.\"\n\nhttps:\/\/valentinaalto.medium.com\/class-activation-maps-in-deep-learning-14101e2ec7e1#:~:text=Class%20Activation%20Maps%20(CAM)%20is,final%20output%20of%20the%20model."}}