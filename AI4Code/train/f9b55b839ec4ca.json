{"cell_type":{"5f96fa96":"code","c420fa7c":"code","1371327d":"code","ded9910f":"code","7d68dd64":"code","d1d71640":"code","0a707f35":"code","16b2eed5":"code","3cc51fa7":"code","da6022fe":"code","e40ca292":"code","ff374b2e":"code","8c474e80":"code","929dcad0":"code","dddee073":"code","7187db11":"code","4711545e":"code","6cdaf2e5":"code","b12ed838":"code","93282330":"code","2367e5ae":"code","d84f68ac":"code","4ad6a07d":"code","37ca6539":"code","50e9f668":"code","1dfb4b2a":"code","a8090dc6":"code","457ccf1c":"code","c1f3f755":"code","4815e879":"code","8a147702":"code","de425709":"code","e3769aa5":"code","6ed9a8ca":"code","df10428c":"code","70e41a2c":"code","54702e3c":"code","b92e8295":"code","be66004a":"code","1ce56c0a":"code","9f017565":"code","2da67811":"code","19c33b59":"code","037d7c07":"code","af413c84":"code","c043d519":"code","3edce402":"code","bf9e4ac5":"code","d152e501":"code","8ac933ed":"code","1f60e79d":"code","bdb78bd1":"code","3e346bbf":"code","35faa2c0":"code","081cbc86":"code","f73cfc56":"code","a31c4ab9":"code","0e4c4098":"code","b059c73e":"code","544459f7":"code","9aca1e9c":"code","d669e487":"code","f1860bfe":"code","92e943dd":"code","80e0850e":"code","6f7734c0":"code","db99c30d":"code","61591f70":"code","ebd3765e":"markdown","7eac1ec5":"markdown","aeed57d6":"markdown","c0f80bd0":"markdown","600d8aff":"markdown","acb0659d":"markdown","e3b1e461":"markdown","68370e21":"markdown","fa308908":"markdown","55e2d28e":"markdown","48279ceb":"markdown","25088285":"markdown","40cb132b":"markdown","fc0c8415":"markdown","a3fe7ab5":"markdown","7055b820":"markdown","98763b5c":"markdown","75fc99f8":"markdown","98d3e004":"markdown","13c7410c":"markdown","90861dfc":"markdown","2791a9d7":"markdown","ca184501":"markdown","ef7d6a78":"markdown","c068f806":"markdown","1449c7ad":"markdown","0d671e2a":"markdown","a314b141":"markdown","8c61e64b":"markdown","4d7eded2":"markdown","f266367a":"markdown","08b633be":"markdown","a816c0d7":"markdown","ec637cf6":"markdown","cef7c173":"markdown","8bd02678":"markdown","f26e91f5":"markdown","4e917d6f":"markdown","db8d043e":"markdown","aa7f8da0":"markdown","e3804450":"markdown","14127b41":"markdown","42c6ca16":"markdown","ed9add6e":"markdown","b9d2607c":"markdown","bed07c4f":"markdown","7da714b5":"markdown","f400e784":"markdown","0b3a4d52":"markdown","e47958e7":"markdown","55c5e217":"markdown","5ac4f56d":"markdown","74679aa0":"markdown","75554f11":"markdown","35fd1fdf":"markdown","3b4d7b8a":"markdown","78f7d79f":"markdown","342ef45f":"markdown","2a5e0386":"markdown","b24567b9":"markdown","7b7b039f":"markdown","6852ab87":"markdown","2a67c4e7":"markdown","1428eba5":"markdown"},"source":{"5f96fa96":"!conda install -c conda-forge gdcm -y","c420fa7c":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pydicom\nimport scipy.ndimage\nimport gdcm\n\nfrom skimage import measure \nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage.morphology import disk, opening, closing\nfrom tqdm import tqdm\n\nfrom IPython.display import HTML\nfrom PIL import Image\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nfrom os import listdir, mkdir","1371327d":"HTML('<iframe width=\"800\" height=\"400\" src=\"https:\/\/www.youtube.com\/embed\/QPKrUd3uOJ8\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","ded9910f":"basepath = \"..\/input\/osic-pulmonary-fibrosis-progression\/\"\nlistdir(basepath)","7d68dd64":"train = pd.read_csv(basepath + \"train.csv\")\ntest = pd.read_csv(basepath + \"test.csv\")","d1d71640":"train.shape","0a707f35":"def load_scans(dcm_path):\n    files = listdir(dcm_path)\n    file_nums = [np.int(file.split(\".\")[0]) for file in files]\n    sorted_file_nums = np.sort(file_nums)[::-1]\n    slices = [pydicom.dcmread(dcm_path + \"\/\" + str(file_num) + \".dcm\" ) for file_num in sorted_file_nums]\n    return slices","16b2eed5":"example = basepath + \"train\/\" + train.Patient.values[0]\nfile_names = listdir(example)\n\nnumbers = []\nlocations = []\nfor name in file_names:\n    file = pydicom.dcmread(example + \"\/\" + name)\n    locations.append(file.SliceLocation)\n    numbers.append(np.int(name.split(\".\")[0]))\n    \nlocations = np.array(locations)\nlocations[np.argsort(numbers)[::-1]]","3cc51fa7":"scans = load_scans(example)","da6022fe":"scans[0]","e40ca292":"HTML('<iframe width=\"600\" height=\"400\" src=\"https:\/\/www.youtube.com\/embed\/KZld-5W99cI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","ff374b2e":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nfor n in range(10):\n    image = scans[n].pixel_array.flatten()\n    rescaled_image = image * scans[n].RescaleSlope + scans[n].RescaleIntercept\n    sns.distplot(image.flatten(), ax=ax[0]);\n    sns.distplot(rescaled_image.flatten(), ax=ax[1])\nax[0].set_title(\"Raw pixel array distributions for 10 examples\")\nax[1].set_title(\"HU unit distributions for 10 examples\");","8c474e80":"def transform_to_hu(slices):\n    images = np.stack([file.pixel_array for file in slices])\n    images = images.astype(np.int16)\n\n    # convert ouside pixel-values to air:\n    # I'm using <= -1000 to be sure that other defaults are captured as well\n    images[images <= -1000] = 0\n    \n    # convert to HU\n    for n in range(len(slices)):\n        \n        intercept = slices[n].RescaleIntercept\n        slope = slices[n].RescaleSlope\n        \n        if slope != 1:\n            images[n] = slope * images[n].astype(np.float64)\n            images[n] = images[n].astype(np.int16)\n            \n        images[n] += np.int16(intercept)\n    \n    return np.array(images, dtype=np.int16)","929dcad0":"hu_scans = transform_to_hu(scans)","dddee073":"fig, ax = plt.subplots(1,4,figsize=(20,3))\nax[0].set_title(\"Original CT-scan\")\nax[0].imshow(scans[0].pixel_array, cmap=\"bone\")\nax[1].set_title(\"Pixelarray distribution\");\nsns.distplot(scans[0].pixel_array.flatten(), ax=ax[1]);\n\nax[2].set_title(\"CT-scan in HU\")\nax[2].imshow(hu_scans[0], cmap=\"bone\")\nax[3].set_title(\"HU values distribution\");\nsns.distplot(hu_scans[0].flatten(), ax=ax[3]);\n\nfor m in [0,2]:\n    ax[m].grid(False)","7187db11":"def get_window_value(feature):\n    if type(feature) == pydicom.multival.MultiValue:\n        return np.int(feature[0])\n    else:\n        return np.int(feature)\n\npixelspacing_r = []\npixelspacing_c = []\nslice_thicknesses = []\npatient_id = []\npatient_pth = []\nrow_values = []\ncolumn_values = []\nwindow_widths = []\nwindow_levels = []\n\nfor patient in train.Patient.unique():\n    patient_id.append(patient)\n    example_dcm = listdir(basepath + \"train\/\" + patient + \"\/\")[0]\n    patient_pth.append(basepath + \"train\/\" + patient)\n    dataset = pydicom.dcmread(basepath + \"train\/\" + patient + \"\/\" + example_dcm)\n    \n    window_widths.append(get_window_value(dataset.WindowWidth))\n    window_levels.append(get_window_value(dataset.WindowCenter))\n    \n    spacing = dataset.PixelSpacing\n    slice_thicknesses.append(dataset.SliceThickness)\n    \n    row_values.append(dataset.Rows)\n    column_values.append(dataset.Columns)\n    pixelspacing_r.append(spacing[0])\n    pixelspacing_c.append(spacing[1])\n    \nscan_properties = pd.DataFrame(data=patient_id, columns=[\"patient\"])\nscan_properties.loc[:, \"rows\"] = row_values\nscan_properties.loc[:, \"columns\"] = column_values\nscan_properties.loc[:, \"area\"] = scan_properties[\"rows\"] * scan_properties[\"columns\"]\nscan_properties.loc[:, \"pixelspacing_r\"] = pixelspacing_r\nscan_properties.loc[:, \"pixelspacing_c\"] = pixelspacing_c\nscan_properties.loc[:, \"pixelspacing_area\"] = scan_properties.pixelspacing_r * scan_properties.pixelspacing_c\nscan_properties.loc[:, \"slice_thickness\"] = slice_thicknesses\nscan_properties.loc[:, \"patient_pth\"] = patient_pth\nscan_properties.loc[:, \"window_width\"] = window_widths\nscan_properties.loc[:, \"window_level\"] = window_levels\nscan_properties.head()","4711545e":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.distplot(pixelspacing_r, ax=ax[0], color=\"Limegreen\", kde=False)\nax[0].set_title(\"Pixel spacing distribution \\n in row direction \")\nax[0].set_ylabel(\"Counts in train\")\nax[0].set_xlabel(\"mm\")\nsns.distplot(pixelspacing_c, ax=ax[1], color=\"Mediumseagreen\", kde=False)\nax[1].set_title(\"Pixel spacing distribution \\n in column direction\");\nax[1].set_ylabel(\"Counts in train\");\nax[1].set_xlabel(\"mm\");","6cdaf2e5":"counts = scan_properties.groupby([\"rows\", \"columns\"]).size()\ncounts = counts.unstack()\ncounts.fillna(0, inplace=True)\n\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.distplot(slice_thicknesses, color=\"orangered\", kde=False, ax=ax[0])\nax[0].set_title(\"Slice thicknesses of all patients\");\nax[0].set_xlabel(\"Slice thickness in mm\")\nax[0].set_ylabel(\"Counts in train\");\n\nfor n in counts.index.values:\n    for m in counts.columns.values:\n        ax[1].scatter(n, m, s=counts.loc[n,m], c=\"midnightblue\")\nax[1].set_xlabel(\"rows\")\nax[1].set_ylabel(\"columns\")\nax[1].set_title(\"Pixel area of ct-scan per patient\");","b12ed838":"scan_properties[\"r_distance\"] = scan_properties.pixelspacing_r * scan_properties.rows\nscan_properties[\"c_distance\"] = scan_properties.pixelspacing_c * scan_properties[\"columns\"]\nscan_properties[\"area_cm2\"] = 0.1* scan_properties[\"r_distance\"] * 0.1*scan_properties[\"c_distance\"]\nscan_properties[\"slice_volume_cm3\"] = 0.1*scan_properties.slice_thickness * scan_properties.area_cm2","93282330":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.distplot(scan_properties.area_cm2, ax=ax[0], color=\"purple\")\nsns.distplot(scan_properties.slice_volume_cm3, ax=ax[1], color=\"magenta\")\nax[0].set_title(\"CT-slice area in $cm^{2}$\")\nax[1].set_title(\"CT-slice volume in $cm^{3}$\")\nax[0].set_xlabel(\"$cm^{2}$\")\nax[1].set_xlabel(\"$cm^{3}$\");","2367e5ae":"max_path = scan_properties[\n    scan_properties.area_cm2 == scan_properties.area_cm2.max()].patient_pth.values[0]\nmin_path = scan_properties[\n    scan_properties.area_cm2 == scan_properties.area_cm2.min()].patient_pth.values[0]\n\nmin_scans = load_scans(min_path)\nmin_hu_scans = transform_to_hu(min_scans)\n\nmax_scans = load_scans(max_path)\nmax_hu_scans = transform_to_hu(max_scans)\n\nbackground_water_hu_scans = max_hu_scans.copy()","d84f68ac":"def set_manual_window(hu_image, custom_center, custom_width):\n    w_image = hu_image.copy()\n    min_value = custom_center - (custom_width\/2)\n    max_value = custom_center + (custom_width\/2)\n    w_image[w_image < min_value] = min_value\n    w_image[w_image > max_value] = max_value\n    return w_image","4ad6a07d":"fig, ax = plt.subplots(1,2,figsize=(20,10))\nax[0].imshow(set_manual_window(min_hu_scans[np.int(len(min_hu_scans)\/2)], -500, 1000), cmap=\"YlGnBu\")\nax[1].imshow(set_manual_window(max_hu_scans[np.int(len(max_hu_scans)\/2)], -500, 1000), cmap=\"YlGnBu\");\nax[0].set_title(\"CT-scan with small slice area\")\nax[1].set_title(\"CT-scan with large slice area\");\nfor n in range(2):\n    ax[n].axis(\"off\")","37ca6539":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.distplot(max_hu_scans[np.int(len(max_hu_scans)\/2)].flatten(), kde=False, ax=ax[1])\nax[1].set_title(\"Large area image\")\nsns.distplot(min_hu_scans[np.int(len(min_hu_scans)\/2)].flatten(), kde=False, ax=ax[0])\nax[0].set_title(\"Small area image\")\nax[0].set_xlabel(\"HU values\")\nax[1].set_xlabel(\"HU values\");","50e9f668":"max_path = scan_properties[\n    scan_properties.slice_volume_cm3 == scan_properties.slice_volume_cm3.max()].patient_pth.values[0]\nmin_path = scan_properties[\n    scan_properties.slice_volume_cm3 == scan_properties.slice_volume_cm3.min()].patient_pth.values[0]\n\nmin_scans = load_scans(min_path)\nmin_hu_scans = transform_to_hu(min_scans)\n\nmax_scans = load_scans(max_path)\nmax_hu_scans = transform_to_hu(max_scans)","1dfb4b2a":"fig, ax = plt.subplots(1,2,figsize=(20,10))\nax[0].imshow(set_manual_window(min_hu_scans[np.int(len(min_hu_scans)\/2)], -500, 1000), cmap=\"YlGnBu\")\nax[1].imshow(set_manual_window(max_hu_scans[np.int(len(max_hu_scans)\/2)], -500, 1000), cmap=\"YlGnBu\");\nax[0].set_title(\"CT-scan with small slice volume\")\nax[1].set_title(\"CT-scan with large slice volume\");\nfor n in range(2):\n    ax[n].axis(\"off\")","a8090dc6":"fig, ax = plt.subplots(1,2,figsize=(20,5))\nsns.distplot(max_hu_scans[np.int(len(max_hu_scans)\/2)].flatten(), kde=False, ax=ax[1])\nax[1].set_title(\"Large slice volume\")\nsns.distplot(min_hu_scans[np.int(len(min_hu_scans)\/2)].flatten(), kde=False, ax=ax[0])\nax[0].set_title(\"Small slice volume\")\nax[0].set_xlabel(\"HU values\")\nax[1].set_xlabel(\"HU values\");","457ccf1c":"def plot_3d(image, threshold=700, color=\"navy\"):\n    \n    # Position the scan upright, \n    # so the head of the patient would be at the top facing the camera\n    p = image.transpose(2,1,0)\n    \n    verts, faces,_,_ = measure.marching_cubes_lewiner(p, threshold)\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n    mesh = Poly3DCollection(verts[faces], alpha=0.2)\n    mesh.set_facecolor(color)\n    ax.add_collection3d(mesh)\n\n    ax.set_xlim(0, p.shape[0])\n    ax.set_ylim(0, p.shape[1])\n    ax.set_zlim(0, p.shape[2])\n\n    plt.show()","c1f3f755":"plot_3d(max_hu_scans)","4815e879":"old_distribution = max_hu_scans.flatten()","8a147702":"example = basepath + \"train\/\" + train.Patient.values[0]\nscans = load_scans(example)\nhu_scans = transform_to_hu(scans)","de425709":"plot_3d(hu_scans)","e3769aa5":"plt.figure(figsize=(20,5))\nsns.distplot(old_distribution, label=\"weak 3d plot\")\nsns.distplot(hu_scans.flatten(), label=\"strong 3d plot\")\nplt.title(\"HU value distribution\")\nplt.legend();","6ed9a8ca":"print(len(max_hu_scans), len(hu_scans))","df10428c":"def resample(image, scan, new_spacing=[1,1,1]):\n    # Determine current pixel spacing\n    spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32)\n\n    resize_factor = spacing \/ new_spacing\n    new_real_shape = image.shape * resize_factor\n    new_shape = np.round(new_real_shape)\n    real_resize_factor = new_shape \/ image.shape\n    new_spacing = spacing \/ real_resize_factor\n    \n    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n    \n    return image, new_spacing","70e41a2c":"pix_resampled, spacing = resample(max_hu_scans, scans, [1,1,1])\nprint(\"Shape before resampling\\t\", hu_scans.shape)\nprint(\"Shape after resampling\\t\", pix_resampled.shape)","54702e3c":"def largest_label_volume(im, bg=-1):\n    vals, counts = np.unique(im, return_counts=True)\n\n    counts = counts[vals != bg]\n    vals = vals[vals != bg]\n\n    if len(counts) > 0:\n        return vals[np.argmax(counts)]\n    else:\n        return None\n    \ndef fill_lungs(binary_image):\n    image = binary_image.copy()\n    # For every slice we determine the largest solid structure\n    for i, axial_slice in enumerate(image):\n        axial_slice = axial_slice - 1\n        labeling = measure.label(axial_slice)\n        l_max = largest_label_volume(labeling, bg=0)\n\n        if l_max is not None: #This slice contains some lung\n            image[i][labeling != l_max] = 1\n    return image\n","b92e8295":"def segment_lung_mask(image):\n    segmented = np.zeros(image.shape)   \n    \n    for n in range(image.shape[0]):\n        binary_image = np.array(image[n] > -320, dtype=np.int8)+1\n        labels = measure.label(binary_image)\n        \n        background_label_1 = labels[0,0]\n        background_label_2 = labels[0,-1]\n        background_label_3 = labels[-1,0]\n        background_label_4 = labels[-1,-1]\n    \n        #Fill the air around the person\n        binary_image[background_label_1 == labels] = 2\n        binary_image[background_label_2 == labels] = 2\n        binary_image[background_label_3 == labels] = 2\n        binary_image[background_label_4 == labels] = 2\n    \n        #We have a lot of remaining small signals outside of the lungs that need to be removed. \n        #In our competition closing is superior to fill_lungs \n        selem = disk(4)\n        binary_image = closing(binary_image, selem)\n    \n        binary_image -= 1 #Make the image actual binary\n        binary_image = 1-binary_image # Invert it, lungs are now 1\n        \n        segmented[n] = binary_image.copy() * image[n]\n    \n    return segmented","be66004a":"plt.figure(figsize=(20,5))\nsns.distplot(hu_scans[20], kde=False)\nplt.title(\"Example HU value distribution\");\nplt.xlabel(\"HU-value\")\nplt.ylabel(\"count\")","1ce56c0a":"binary_image = np.array((hu_scans[20]>-320), dtype=np.int8) + 1\nnp.unique(binary_image)","9f017565":"labels = measure.label(binary_image)\n\nbackground_label_1 = labels[0,0]\nbackground_label_2 = labels[0,-1]\nbackground_label_3 = labels[-1,0]\nbackground_label_4 = labels[-1,-1]","2da67811":"binary_image_2 = binary_image.copy()\nbinary_image_2[background_label_1 == labels] = 2\nbinary_image_2[background_label_2 == labels] = 2\nbinary_image_2[background_label_3 == labels] = 2\nbinary_image_2[background_label_4 == labels] = 2","19c33b59":"fig, ax = plt.subplots(1,3,figsize=(20,7))\nax[0].imshow(binary_image, cmap=\"binary\", interpolation='nearest')\nax[1].imshow(labels, cmap=\"jet\", interpolation='nearest')\nax[2].imshow(binary_image_2, cmap=\"binary\", interpolation='nearest')\n\nax[0].set_title(\"Binary image\")\nax[1].set_title(\"Labelled image\");\nax[2].set_title(\"Binary image - background removed\");","037d7c07":"selem = disk(4)\nclosed_binary_2 = closing(binary_image_2, selem)\n\nclosed_binary_2 -= 1 #Make the image actual binary\nclosed_binary_2 = 1-closed_binary_2 # Invert it, lungs are now 1","af413c84":"filled_lungs_binary = fill_lungs(binary_image_2)","c043d519":"air_pocket_binary = closed_binary_2.copy()\n# Remove other air pockets insided body\nlabels_2 = measure.label(air_pocket_binary, background=0)\nl_max = largest_label_volume(labels_2, bg=0)\nif l_max is not None: # There are air pockets\n    air_pocket_binary[labels_2 != l_max] = 0","3edce402":"fig, ax = plt.subplots(1,3,figsize=(20,7))\n\nax[0].imshow(closed_binary_2, cmap=\"binary\", interpolation='nearest')\nax[1].imshow(filled_lungs_binary, cmap=\"binary\", interpolation='nearest')\nax[2].imshow(air_pocket_binary, cmap=\"binary\", interpolation='nearest')\n\n\nax[0].set_title(\"Morphological closing\");\nax[1].set_title(\"Guidos filling lung structures\");\nax[2].set_title(\"Guidos air pocket removal\");","bf9e4ac5":"segmented = segment_lung_mask(np.array([hu_scans[20]]))\n\nfig, ax = plt.subplots(1,2,figsize=(20,10))\nax[0].imshow(hu_scans[20], cmap=\"Blues_r\")\nax[1].imshow(segmented[0], cmap=\"Blues_r\");","d152e501":"segmented_lungs = segment_lung_mask(hu_scans)","8ac933ed":"fig, ax = plt.subplots(6,5, figsize=(20,20))\nfor n in range(6):\n    for m in range(5):\n        ax[n,m].imshow(segmented_lungs[n*5+m], cmap=\"Blues_r\")","1f60e79d":"plot_3d(segmented_lungs, threshold=-600)","bdb78bd1":"image_sizes = scan_properties.groupby([\"rows\", \"columns\"]).size().sort_values(ascending=False)\nimage_sizes","3e346bbf":"plt.figure(figsize=(8,8))\nfor n in counts.index.values:\n    for m in counts.columns.values:\n        plt.scatter(n, m, s=counts.loc[n,m], c=\"dodgerblue\", alpha=0.7)\nplt.xlabel(\"rows\")\nplt.ylabel(\"columns\")\nplt.title(\"Pixel area of ct-scan per patient\");\nplt.plot(np.arange(0,1400), '-.', c=\"purple\", label=\"squared\")\nplt.plot(888 * np.ones(1400), '-.', c=\"crimson\", label=\"888 rows\");\nplt.legend();","35faa2c0":"class ImageObserver:\n    \n    def __init__(self, scan_properties, batch_size):\n        self.scan_properties = scan_properties\n        self.batch_size = batch_size\n    \n    def select_group(self, group=(512,512)):\n        self.group = group\n        self.name = \"rows {}, columns {}\".format(group[0], group[1])\n        self.batch_shape = (self.batch_size, group[0], group[1])\n        self.selection = self.scan_properties[\n            (self.scan_properties[\"rows\"]==group[0]) & (self.scan_properties[\"columns\"]==group[1])\n        ].copy()\n        self.patient_pths = self.selection.patient_pth.unique()\n    \n    \n    def get_loader(self):\n        \n        idx=0\n        images = np.zeros(self.batch_shape)\n        \n        for path in self.patient_pths:\n            \n            scans = load_scans(path)\n            hu_scans = transform_to_hu(scans)\n            images[idx,:,:] = hu_scans[0]\n            \n            idx += 1\n            if idx == self.batch_shape[0]:\n                yield images\n                images = np.zeros(self.batch_shape)\n                idx = 0\n        if idx > 0:\n            yield images","081cbc86":"my_choice = image_sizes.index.values[9]\nprint(my_choice)\nto_display = 4","f73cfc56":"observer = ImageObserver(scan_properties, to_display)\nobserver.select_group(my_choice)\nobserver_iterator = observer.get_loader()","a31c4ab9":"images = next(observer_iterator)","0e4c4098":"fig, ax = plt.subplots(1,to_display,figsize=(20,5))\n\n\nfor m in range(to_display):\n    image = images[m]\n    ax[m].imshow(set_manual_window(image, -500, 1000), cmap=\"YlGnBu\")\n    ax[m].set_title(observer.name)","b059c73e":"scan_properties.shape","544459f7":"scan_properties.head(1)","9aca1e9c":"def resize_scan(scan, new_shape):\n    # read slice as 32 bit signed integers\n    img = Image.fromarray(scan, mode=\"I\")\n    # do the resizing\n    img = img.resize(new_shape, resample=Image.LANCZOS)\n    # convert back to 16 bit integers\n    resized_scan = np.array(img, dtype=np.int16)\n    return resized_scan","d669e487":"def crop_scan(scan):\n    img = Image.fromarray(scan, mode=\"I\")\n    \n    left = (scan.shape[0]-512)\/2\n    right = (scan.shape[0]+512)\/2\n    top = (scan.shape[1]-512)\/2\n    bottom = (scan.shape[1]+512)\/2\n\n    img = img.crop((left, top, right, bottom))\n    # convert back to 16 bit integers\n    cropped_scan = np.array(img, dtype=np.int16)\n    return cropped_scan","f1860bfe":"def crop_and_resize(scan, new_shape):\n    img = Image.fromarray(scan, mode=\"I\")\n    \n    left = (scan.shape[0]-512)\/2\n    right = (scan.shape[0]+512)\/2\n    top = (scan.shape[1]-512)\/2\n    bottom = (scan.shape[1]+512)\/2\n    \n    img = img.crop((left, top, right, bottom))\n    img = img.resize(new_shape, resample=Image.LANCZOS)\n    \n    cropped_resized_scan = np.array(img, dtype=np.int16)\n    return cropped_resized_scan","92e943dd":"def preprocess_to_hu_scans(scan_properties, my_shape, output_dir):\n    \n    for i, patient in enumerate(tqdm(scan_properties.patient.values)):\n        pth = scan_properties.loc[scan_properties.patient==patient].patient_pth.values[0]\n        scans = load_scans(pth)\n        hu_scans = transform_to_hu(scans) \n        prepared_scans = np.zeros((hu_scans.shape[0], my_shape[0], my_shape[1]), dtype=np.int16)\n        \n        # if squared:\n        if hu_scans.shape[1] == hu_scans.shape[2]:\n            \n            # if size is as desired\n            if hu_scans.shape[1] == my_shape[0]:\n                continue\n            # else resize:\n            else:\n               # as we have not converted to jpeg to keep all information, we need to do a workaround\n                hu_scans = hu_scans.astype(np.int32)\n                for s in range(hu_scans.shape[0]): \n                    prepared_scans[s] = resize_scan(hu_scans[s,:,:], my_shape)\n\n        # if non-squared - do a center crop to 512, 512 and then resize to desired shape\n        else:\n            hu_scans = hu_scans.astype(np.int32)\n            for s in range(hu_scans.shape[0]):\n                # if desired shape is 512x512:\n                if my_shape[0]==512:\n                    prepared_scans[s] = crop_scan(hu_scans[s,:,:])\n                else:\n                    prepared_scans[s] = crop_and_resize(hu_scans[s,:,:], my_shape)\n                \n        # save the prepared scans of patient:\n        np.save(output_dir + \"\/\" + patient + '_hu_scans', prepared_scans)","80e0850e":"generate_512_512 = False\n\nif generate_512_512:\n    output_dir = \"scans_512x512\"\n    mkdir(output_dir)\n    my_shape = (512, 512)\n    preprocess_to_hu_scans(scan_properties, my_shape, output_dir)","6f7734c0":"generate_224_224 = False\n\nif generate_224_224:\n    output_dir = \"scans_224x224\"\n    mkdir(output_dir)\n    my_shape = (224, 224)\n    preprocess_to_hu_scans(scan_properties, my_shape, output_dir)","db99c30d":"generate_128_128 = False\n\nif generate_128_128:\n    output_dir = \"scans_128x128\"\n    mkdir(output_dir)\n    my_shape = (128, 128)\n    preprocess_to_hu_scans(scan_properties, my_shape, output_dir)","61591f70":"generate_64_64 = False\n\nif generate_64_64:\n    output_dir = \"scans_64x64\"\n    mkdir(output_dir)\n    my_shape = (64, 64)\n    preprocess_to_hu_scans(scan_properties, my_shape, output_dir)","ebd3765e":"Now we can set all labelled regions of the binary image that correspond to these corner-labels to the \"not-lung\"-value 2:","7eac1ec5":"This is now the segmentation function I am using:","aeed57d6":"# Prepare to start <a class=\"anchor\" id=\"prepare\"><\/a>","c0f80bd0":"### Smallest and largest CT-slice volume","600d8aff":"### Pixelspacing\n\n* The pixelspacing attribute you can find in the dicom files is an important one. It tells us how much physical distance is covered by one pixel. You can see that there are only 2 values that describe the x- and y-direction in the plane of a transversal slice. \n* For one patient this pixelspacing is usually the same for all slices.\n* But between patients the pixelspacing can differ due to personal or institutional preferences of doctors and the clinic and it also depends on the scanner type. Consequently if you compare two images in the size of the lungs it does not automatically mean that the bigger one is really larger in the physical size of the organ!\n\nLet's explore the distributions of the patients pixelspacing widths and heights of this competition:","acb0659d":"### Insights\n\n* Taking a look at one slice of a scan with smallest and largest slice area, we can see that the large one has a lot of useless region covered. We could crop it.\n* Strange... in the second image with the large area the outside region of the scanner tube is not set to the value of air but rather to some value in the middle of the range -1000 to 1000.","e3b1e461":"## Data Science Bowl 2017 - Preprocessing Tutorial by Guido Zuidhof <a class=\"anchor\" id=\"bowl_2017\"><\/a>\n\nOnce upon a time there was a data science bowl about lung cancer detection that had a fantastic preprocessing tutorial: https:\/\/www.kaggle.com\/gzuidhof\/full-preprocessing-tutorial ;-)\n\n* My notebook heavily uses the concepts and code snippets of this notebook by Guido Zuidhof. \n* With my work I like to bring back his ideas to this competition and I like to add a few more explanations while writing it. \n* Furthermore I hope that I can generate a dataset in the end that contains the preprocessed data to feed into your models.","68370e21":"Let's compare with Guidos fill-lungs method:","fa308908":"To remove the signals we can use morphological closing. If you like play with the disk value. It must be large enough to cancel the body signals but small enough to keep enough details inside the lungs:","55e2d28e":"If you haven't worked with dicom so far, I can recommend this video. If you like to speed up, start at 7 min:","48279ceb":"### Adding further information\n\n1. The CT-scan captures information about the radiodensity of an object or tissue exposed to x-rays. A transversal slice of a scan is reconstructed after taking measurements from several different directions.\n2. We need to transform to Hounsfield units as the spectral composition of the x-rays depends on the measurement settings like acquisition parameters and tube voltage. By normalizing to values of water and air (water has HU 0 and air -1000) the images of different measurements are becoming comparable.\n3. A ct-scanner yields roughly 4000 grey values that can't be captured by our eyes. This is why windowing is performed. This way the image is displayed in a HU range that suites most to the region of interest. ","25088285":"Interesting! The strong plot has a more flattened hu value distribution that the weak one!","40cb132b":"And with his air-pocket removal:","fc0c8415":"Let's load the csv-files:","a3fe7ab5":"## CT-scan slice area and volume - EDA <a class=\"anchor\" id=\"scan_eda\"><\/a>","7055b820":"### Slice thickness and pixel area\n\nThe slice thickness tells us how much distance is covered in Z-direction by one slice. Let's plot the distribution of it as well. Furthermore the pixel_array of raw values covers a specific area given by row and column values. Let's take a look at it as well: ","98763b5c":"The plot_3d works well in the Data Science Bowl 2017 but in our case the results are not so well. It depends on the threshold but so far I don't know why our reconstructions often look blurred or show tube regions as well. :-(","75fc99f8":"## Physical area & slice volume covered by a single ct-scan","98d3e004":"### Insights\n\n1. The first image shows the raw binary. In this case we find air as background and we need to set it to the \"not-lung\" value of 2.\n2. For this purpose we label all connected regions in the binary image. There are many different labelled regions but the only ones we are interested in are the 4 corner regions at (0,0), (0,500), (500,0) and (500,500).\n3. Knowing the related labels help us to manually set the background to the value 2 (black).\n4. In the end we can see that the lungs are white (1) but we still find a lot of remaining signals that correspond to body tissue that we still need to remove.","13c7410c":"## Loading CT-scans per patient <a class=\"anchor\" id=\"ct_scans\"><\/a>\n\n* For each patient we have given **ONE baseline CT-scan** for train and test data. For the training data we can find the history of FVC measurements of a patient whose time periods are relative to this baseline scan. \n* To load the full 3D-scan we need to order the single dicom files\/slices by the ImagePosition: ","90861dfc":"## 3D-reconstruction of CT-scans <a class=\"anchor\" id=\"reconstruction\"><\/a>","2791a9d7":"Such kind of obvious patterns are always worth to take a look at. Perhaps we can find some kind of rule that allows us to create a good resizing strategy.","ca184501":"## Generating non-segmented, original raw image data <a class=\"anchor\" id=\"non_segmented_original\"><\/a>\n\nhttps:\/\/www.kaggle.com\/allunia\/osic-pulmonary-fibrosis-progression-huscans","ef7d6a78":"### Insights\n\nBrowse through the different groups and you will find out that...\n\n* The large squared image sizes often show resolutions higher than with 512 rows and 512 columns. Here resizing to the two major groups (512, 512) or (768, 768) makes sense.\n* In the non-squared cases a center crops should work best as they only have more background values but still belong to the major groups in the inside-scanner-region.","c068f806":"Compare to above this one looks far better. Let's plot the distributions. Perhaps we can understand what's going wrong by taking a look at them:","1449c7ad":"## Tissue segmentation <a class=\"anchor\" id=\"segmentation\"><\/a>","0d671e2a":"Ohoh! We have some images with extreme large sliche areas and volumes! I think it's time to do some EDA regarding these features! ","a314b141":"### Final solution","8c61e64b":"### Understanding the segmentation step by step:","4d7eded2":"You can see that this looks quite different to this one:","f266367a":"Before starting, let's plot the pixelarray distribution of some dicom files to get an impression of the raw data:","08b633be":"## Table of contents\n\n1. [What is pulmonary fibrosis?](#fibrosis)\n2. [References](#references)\n    * [Data Science Bowl 2017 - Preprocessing Tutorial by Guido Zuidhof](#bowl_2017)\n    * [Papers](#papers)\n2. [Prepare to start](#prepare)\n3. [Working with dicom files](#dicom)\n    * [Loading CT-scans per patient](#ct_scans)\n    * [Transforming to Hounsfield Units](#hunits)\n    * [The voxel size](#voxel)\n    * [CT-scan slice area and volume - EDA](#scan_eda)\n    * [3D-reconstruction of CT-scans](#reconstruction)\n    * [Tissue segmentation](#segmentation)\n4. [Generating a dataset for preprocessed files](#datagenerator)\n    * [Link to public dataset](https:\/\/www.kaggle.com\/allunia\/osic-pulmonary-fibrosis-progression-huscans)","a816c0d7":"The least we can do is to resize and crop all those images that don't have a shape of (512,512) and to transform their values to Hounsfield units. Furthermore we can create smaller images by resizing to a desired shape. As far as I know this is not that easy as it sounds as we won't use common Image dtypes but rather original HU values without converting them. Most image preprocessing packages I found can't easily deal with numpy arrays. For this reason I used a workaround:\n\n* I changed the dytpe of my hu-transformed numpy-array scans to Int32\n* This way I can pass them to PILs Image class using fromarray with mode=\"I\"\n* Then I can use the resize and crop method of this package\n* After that the array turns back to Int16 as I like to reduce memory cost\n\nHmm... still feels not good and I'm also a bit confused. You can see that dicom can also be covered with most common Image preprocessing packages this way:\n\n* https:\/\/www.kaggle.com\/onealbao\/dicom-to-jpeg-conversion-kernel\n\nI still need to read about converting dicom or \"how to loose or not loose information\"! ;-)","ec637cf6":"First of all we are separating between \"potentially lung\" with values smaller or equal to 320. Why 320? I just kept the value of Guidos old notebook. Try out your own values if you like. ;-) Before you do so, you make like to take a look at the hu_value distribution again:","cef7c173":"## Resampling the voxel size","8bd02678":"176 different patients in train!","f26e91f5":"# Working with dicom files <a class=\"anchor\" id=\"dicom\"><\/a>","4e917d6f":"Now, we know some important quantities to compute the physical distance covered by a ct-scan!","db8d043e":"Lungs have values of 1 as well as air backgrounds. In contrast water-like default backgrounds and many other organic tissues or fluids have values of 2. As we only like to segment the lungs, we need to remove the background. In the case of air and air-like default values we need to do set their values manually to 2. We can do so by labelling connected regions in the binary image and extracting the labels of each region that corresponds to the corners of the 2D image slice:","aa7f8da0":"Hmm I can't see a great difference. Perhaps the one with the large slice volume looks a bit more blurred. But as above there is an outside-scanner region that was set to the walue of water (HU value of 0) instead of air.","e3804450":"## Transforming to Hounsfield Units <a class=\"anchor\" id=\"hunits\"><\/a>","14127b41":"The result of these steps looks as follows:","42c6ca16":"## The voxel size <a class=\"anchor\" id=\"voxel\"><\/a>\n\nThe voxel stands for the 3D-pixel that is given in a CT-scan. As far as I know it is spanned by the 2d-plane of the pixelspacing attribute in x- and y-direction and the slice thickness in z-direction.","ed9add6e":"We can see that there are some raw values at -2000. They correspond to images with a circular boundary within the image. The \"outside\" of this circle value is often set to -2000 (or in other competitions I found also -3000) by default.","b9d2607c":"Let's take a look at the first dicom file of our example patient:","bed07c4f":"And we can also check how it looks in the 3D case:","7da714b5":"Ihh... it was set to water by default in the large image... why?! That's bad! We need to find some strategy to deal with this problem. It's not good that we sometimes have \"water\"-like outside regions and sometimes \"air\"-like regions.","f400e784":"# References <a class=\"anchor\" id=\"references\"><\/a>","0b3a4d52":"If you like try to improve the segmentation and play with your own ideas and concepts! :-) I like to create two datasets - one with segmentation already done and one without. So you can decide on your own if you like to build a custom augmentation that performs the segmentation on the fly when loading your batches.","e47958e7":"But it has less number of slices. I think we need to understand the marching_cubes_lewiner algorithm to understand why the plot sometimes works nice and sometimes not. But I think this is not really important for the competition itself. At the moment I don't like to spend more time on that topic. Perhaps it's more important to keep in mind that the overall distributions can be different.","55c5e217":"Interesting that we still have some signals outside of the lungs:","5ac4f56d":"### Insights\n\n* The morphological closing worked better than Guidos method. But we are often missing a lot of information inside the lungs just to remove these body signals. There is definitely room for improvements! ;-)\n* In contrast the fill-lung method has troubles with the remaining singals of the body and yields not what we like to obtain.\n* Furthermore the air-pocket removal does also not work well.\n\nFor this reason I just stayed with the simplest solution of morphological closing.","74679aa0":"# What is pulmonary fibrosis? <a class=\"anchor\" id=\"fibrosis\"><\/a>","75554f11":"With -320 we are separating between lungs (-700) \/air (-1000) and tissue with values close to water (0).","35fd1fdf":"It's interesting that we have two different kind of patterns:","3b4d7b8a":"# Generating a dataset for preprocessed files <a class=\"anchor\" id=\"datagenerator\"><\/a>\n\n\n## Dealing with different image-scan sizes <a class=\"anchor\" id=\"image_sizes\"><\/a>\n\nTo generate the data, we should take a look again at the different images sizes: We have two major size groups and some minor outliers. For example we could manually resize or crop the outliers and find a strategy for the two major groups. Let's take a look at the sizes again:","78f7d79f":"Ok great. The scan of our example patient had a circular boundary and now all raw values per slice are scaled to H-units.","342ef45f":"## Papers <a class=\"anchor\" id=\"papers\"><\/a>\n\nTo understand what and why we are doing these concepts here, I started to read a few papers:\n\n* [Intrinsic dependencies of CT radiomic features on voxel size and number of gray levels](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC5462462\/)","2a5e0386":"I built this solution upon Guidos that did not work well in this competition. Here is code I won't use but I kept it to show by example why I found it not helpful:","b24567b9":"We can see that the values really vary a lot from patient to patient! As they are given in mm and ct-scans usually cover 512 row and column values... **oh wait! we need to check this!** ... we can compute the minimum and maximum distance that is covered by the images:","7b7b039f":"### Smallest and larges CT-slice area","6852ab87":"* Very thin slices allow more details to be shown. On the other hand thick slices contain less noise but are more prone to artifacts. Hmm... I'm very excited to see some examples here as well. \n* Even though it is common to have 512x512 pixel size areas, we can see that this is not always true!! We can find a lot of exceptions and even one or a few very large pixel areas (1300x1300)!!!\n* Proper preprocessing of these scans might be very important... we have to check it.","2a67c4e7":"I'm not sure if it's really important to do this resampling, because we can already do a lot with augmentations. We can resize, crop, blur and shift intensities. Also the background-problem with outside scanner regions set to water HU-values can be solved. For this reason I don't like to do the resampling. ;-) Perhaps you like to do it. For this purpose I leave the code from Guidos notebook: ","1428eba5":"And here is how it looks like if we mask the original image with the segmented binary lungs in our 2D example:"}}