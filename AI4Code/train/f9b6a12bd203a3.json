{"cell_type":{"a11af38d":"code","93f6cde6":"code","319359f9":"code","f28df68a":"code","d001c174":"code","0bb73010":"code","b4fc7cf3":"code","981a04e6":"code","4b4c6bdc":"code","b13bcf0d":"code","c1d6e003":"code","82bc8f6e":"code","7f1fcc9b":"code","cb790439":"code","4a965c4e":"code","6e8a5d5e":"code","a3ad3440":"code","ab7ed085":"code","ec55d167":"code","7ec67cd1":"code","53b2bd0e":"code","3089bb2d":"code","fa3578d1":"code","9fe5aef2":"code","a984d563":"code","254dede6":"code","24ab7904":"code","b384c1aa":"code","647a8c9e":"code","bc156842":"code","f34db4fc":"code","7efba98a":"markdown","2a176ad1":"markdown","326533c3":"markdown","c58d2e6c":"markdown","96e5cb7c":"markdown","63697e8b":"markdown","c8992982":"markdown","b23fd9d0":"markdown","22f7e33f":"markdown","92d6a047":"markdown","05f0a47c":"markdown","062d298d":"markdown"},"source":{"a11af38d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93f6cde6":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd","319359f9":"df = pd.read_csv('..\/input\/us-airbnb-open-data\/AB_US_2020.csv')","f28df68a":"df.head(10)","d001c174":"df.describe()","0bb73010":"df.info()","b4fc7cf3":"df.isna().sum()","981a04e6":"df1=df.dropna()\ndf1.info()","4b4c6bdc":"unique_columns1= [df1[col].nunique() for col in df1]\ncount=pd.DataFrame({\"Unique\" : unique_columns1})\ncount['Column']=list(df1.columns)\ncount","b13bcf0d":"df1.name = df1.name.astype(str)\ndf1.name=df1.name.str.lower()\ndf1.name=df1.name.replace(['-','@','$','&','!'],'',regex=True)","c1d6e003":"from wordcloud import WordCloud,STOPWORDS\ncomment_words = '' \nstopwords = set(STOPWORDS) \nfor val in df1.name: \n    val = str(val) \n    tokens = val.split() \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower()       \n    comment_words += \" \".join(tokens)+\" \"  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words)                        \nplt.figure(figsize = (8, 12), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)   \nplt.show() ","82bc8f6e":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english')) ","7f1fcc9b":"df1[\"unigrams\"] = df1[\"name\"].apply(nltk.word_tokenize)\ndf1[\"unigrams\"] =df1[\"unigrams\"].apply(lambda x: [item for item in x if item not in stop_words])","cb790439":"\nrslt=pd.Series(np.concatenate([x for x in df1.unigrams])).value_counts()\nrslt = pd.DataFrame({'ngrams': list(rslt.keys()),\n                   'count': list(rslt[:])})\nrslt=rslt[rslt.ngrams != '.' ]\nrslt=rslt.head(20)\nrslt1=rslt['ngrams'][1:20]\nrslt1","4a965c4e":"\ndef inner(text):    \n    for word in text.split(' '):\n        for c in rslt1:\n            if word==c:\n               return c\n    return 'Null'       \nc1=[]\nfor text in df1['name']:\n    c1.append(inner(text))\ndf1['Name1']=c1\ndf1.info()","6e8a5d5e":"df2=df1[['Name1','neighbourhood_group','room_type',\n        'city','price']]\n\nplt.hist(df2['price'], bins =20)\nplt.show()","a3ad3440":"df2=df2[(df2['price']<1000)  ]","ab7ed085":"\nnames = list(df2.columns)\nfig, axs = plt.subplots(4, 1,figsize=(15,15))\nplt.subplots_adjust(left = 0.25, right = 0.9, bottom = 0.1, top = 1.5,\n                        wspace = 0.2, hspace = 1.2)\n\nfor column_name in names[:-1]: \n    ax = axs[names.index(column_name)]\n    cd= df2[column_name].value_counts()[:5]\n    cd1= pd.DataFrame({'label': list(cd.keys()),\n                   'count': list(cd[:])})\n    s=cd1['label']\n    \n    for s1 in s:\n        # Subset to the airline\n        subset = df2[df2[column_name] == s1]\n        \n        # Draw the density plot\n        sns.distplot(subset['price'], hist = False, kde = True,\n                     kde_kws = {'shade': True,'linewidth': 1},ax=ax,\n                     label = s1).set(xlim=(0))\n        ax.set_xlabel( ' Target Price')\n        ax.set_title(column_name + ' density')\n        ax.grid('on')","ec55d167":"df_group = df2.groupby('Name1').mean()  \ndf_group.sort_values(by=['price'], ascending=False) \n","7ec67cd1":"names = ['Name1','price']\n\n\nfor column_name in names[:-1]: \n    cd=['ocean','beach','Null','cozy','room']\n    cd1= pd.DataFrame(cd,columns=['label'])\n    s=cd1['label']\n    \n    for s1 in s:\n        # Subset to the airline\n        subset = df2[df2[column_name] == s1]\n        \n        # Draw the density plot\n        ax=sns.distplot(subset['price'], hist = False, kde=True,\n                     kde_kws = {'shade': True,'linewidth': 2},\n                     label = s1).set(xlim=(0))","53b2bd0e":"x1=[]\nfor c in df1.last_review:\n    x1.append([c[:2],c[3:5],c[6:8]])\ndt = pd.DataFrame(x1, columns=['day', 'month', 'year'],index=df1.index)\ndt[['day', 'month', 'year']] = dt[['day', 'month', 'year']].astype(int)\ndt.year=dt.year+2000\n\nimport datetime\n\ndt['rev']= pd.to_datetime(dt.year*10000+dt.month*100+dt.day,format='%Y%m%d')\ndt['rev']= dt['rev'].dt.date\ndt['now']=datetime.date.today()\ndt['dif']=dt.now-dt.rev\ndf1['days']=dt['dif']\ndf1['days']=(df1['days']\/np.timedelta64(1, 'D')).astype(np.int64)\n\ndf1=df1[(df1['price']<1000)]\ndf1.info()","3089bb2d":"df1 = df1.drop([  'id','host_id','latitude','longitude','last_review'], axis = 1)\ncorr = df1.corr()\nprint(corr)\nplt.figure(figsize=(20,10))\nsns.heatmap(corr, annot=True)\nplt.show()","fa3578d1":"dummy = pd.get_dummies(df1[['neighbourhood_group','room_type',\n        'city','Name1']])\n\ndf11 = pd.concat([df1, dummy], axis = 1)\nx = df11.drop(['Name1','neighbourhood_group','room_type',\n        'city','price','name','host_name','neighbourhood','unigrams'], axis = 1)\nx= (x-np.min(x)) \/ (np.max(x)-np.min(x))\ny = df11['price']\ny= (y-np.min(y)) \/ (np.max(y)-np.min(y))\nx.info()","9fe5aef2":"                   \nfrom sklearn.model_selection import train_test_split\nx_train , x_test , y_train, y_test = train_test_split(x,y,test_size = 0.2 , random_state = 21)\n","a984d563":"from sklearn.linear_model import LinearRegression\n\nreg = LinearRegression().fit(x_train, y_train)\nreg.score(x_train, y_train)\ny1=reg.predict(x_test)\n","254dede6":"from sklearn.metrics import mean_squared_error, r2_score\n\nmse = mean_squared_error(y_test, y1)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, y1)\nprint(\"R2:\", r2)","24ab7904":"plt.scatter(y_test, y1)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nz = np.polyfit(y_test, y1, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='red')\nplt.show()\n","b384c1aa":"from sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\nmodel=regressor.fit(x, y)  \ny1 = model.predict(x_test)","647a8c9e":"mse = mean_squared_error(y_test, y1)\nprint(\"MSE:\", mse)\nrmse = np.sqrt(mse)\nprint(\"RMSE:\", rmse)\nr2 = r2_score(y_test, y1)\nprint(\"R2:\", r2)","bc156842":"plt.scatter(y_test, y1)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\nz = np.polyfit(y_test, y1, 1)\np = np.poly1d(z)\nplt.plot(y_test,p(y_test), color='red')\nplt.show()\n","f34db4fc":"n_nodes = []\nmax_depths = []\nfor ind_tree in model.estimators_:\n    n_nodes.append(ind_tree.tree_.node_count)\n    max_depths.append(ind_tree.tree_.max_depth)\n    \nprint(f'Average number of nodes {int(np.mean(n_nodes))}')\nprint(f'Average maximum depth {int(np.mean(max_depths))}')\n","7efba98a":"# Data Processing","2a176ad1":"Comparison of distribution of price for top two mean price vs bottom two mean price based on text (name)","326533c3":"# Data Understanding\n","c58d2e6c":"Loading stop words to exclude them from the text in columns","96e5cb7c":"20 most frequently observed words in Name column","63697e8b":"Number of days since last review. For cases where ","c8992982":"Density distribution for top 5 frequencies of Name1, neighbourhood group,room type and city against Price.","b23fd9d0":"To replace special characters from name column","22f7e33f":"considering those cases with price less than $ 1000","92d6a047":"Will exclude the rows having Null values.","05f0a47c":"# Random Forest Regressor","062d298d":"# Linear Regression"}}