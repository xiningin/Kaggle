{"cell_type":{"0533e478":"code","41210517":"code","b3effc40":"code","1ea50671":"code","a5298e79":"code","685c5273":"code","96053037":"code","b7a6f23c":"code","de3729d6":"code","7691a3c6":"code","31438206":"code","6442c9fb":"code","99139976":"code","2c181768":"code","f927b910":"code","abd96a97":"code","57d2947c":"code","00eaea84":"code","e370f617":"code","ab918835":"code","aec9fadd":"code","313fd02a":"code","d8404d9d":"code","ab2083e5":"code","e4017caa":"code","525eaac3":"code","4135d9e5":"code","a7b31ea0":"code","666e5161":"code","5fa6fc6c":"code","7e6aea7f":"code","5c818f6a":"code","f248f28e":"code","7302e688":"code","6dc02380":"code","85593d48":"code","c0191e15":"code","90ae72fd":"code","dcc4b2e5":"code","f068257f":"code","e77491e2":"code","00a18fe4":"code","2247991f":"code","fb015d49":"code","d54aa06f":"code","449bcc9b":"code","9427f781":"code","4f850ca1":"code","7d0a3d39":"code","9cc63b79":"code","70fc5c4d":"code","55f036cf":"code","b567dd3c":"code","98c40d03":"code","98fd19ff":"code","34b00082":"code","6273c683":"code","2e2353e7":"code","78f6688c":"code","ccf91e32":"code","db60d27c":"code","b0b1b692":"code","66a2aa8b":"code","e263828d":"code","de693159":"code","0715df7a":"code","3b7f849a":"code","3cd592b4":"code","3fa618b1":"code","7ecdc698":"code","cf2fcb1a":"code","e3839f93":"code","eb47e58c":"code","515c0c96":"code","25406ecb":"code","29a6f102":"code","fe6b743f":"code","62386e4f":"code","e216e881":"code","f53d836d":"code","fd18466d":"code","decb79f4":"code","f1aa72b8":"code","66400016":"code","970c0d96":"code","3fd3180f":"code","ccefcb4e":"code","54d90176":"code","c2d9c996":"code","b469c380":"code","b327b67b":"code","97fb8bb8":"code","7475efac":"code","36acd672":"code","cd51908b":"code","c7f1069e":"code","4700a234":"code","d1cf2f9a":"code","822eed83":"code","7df66d4e":"code","abacc693":"code","a02aa33a":"code","6a72fe95":"code","cb2bf3b6":"code","5dd43894":"code","c71e38ce":"code","1dd4c293":"code","29ec4acb":"code","7234a4e5":"code","c68f4b4b":"code","b9418993":"code","4afc86ec":"code","8b4e48a7":"code","a2cb8369":"code","da077101":"code","918fb8ab":"code","03982c3c":"code","dd37e811":"code","792c3a02":"code","277b4490":"code","16d2cf96":"code","3829df60":"code","7b1d933b":"code","86b78c8b":"code","46d6fce0":"code","a5910053":"code","197289ef":"code","c5283772":"code","2ec4935c":"code","8ab8e653":"code","9ea0d144":"code","b211d8d0":"code","7ccd58ff":"code","64eeba5f":"markdown","92f7857a":"markdown","6f1e2f11":"markdown","f1c846a3":"markdown","3b94248b":"markdown","a04f08d4":"markdown","6902c788":"markdown","a187acfa":"markdown","405c9e62":"markdown","fa2636eb":"markdown","eebdd3c0":"markdown","c997c6cb":"markdown","68d29c94":"markdown","2ec1c106":"markdown","9ad7835c":"markdown","536a2abe":"markdown","8234a988":"markdown","2ea0da6f":"markdown","a7a6c968":"markdown","5bc460ef":"markdown","5621d7dc":"markdown","b65e0230":"markdown","175208c1":"markdown"},"source":{"0533e478":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.impute import SimpleImputer\nplt.style.use('fivethirtyeight')","41210517":"Xtrain = pd.read_csv('..\/input\/cs5228-2021s1\/Xtrain.csv')\nYtrain = pd.read_csv('..\/input\/cs5228-2021s1\/Ytrain.csv')\n# Ytrain = pd.DataFrame(Ytrain,columns=['Default'])\nXYtrain = Xtrain.merge(Ytrain, on='Id')\nXYtrain.head()","b3effc40":"## Remove anormalidies \n# BalanceGross','DisbursementGross','GrAppv','SBA_Appv contains symbols that needs to be removed\nprint(XYtrain[['BalanceGross','DisbursementGross','GrAppv','SBA_Appv']].head())\n\ndef fix_num(number):\n    num = number.replace(\"$\", \"\")\n    num = num.replace(\",\",\"\")\n    num = num.replace(\" \",\"\")\n    return float(num)\n\nXYtrain['BalanceGross'] = XYtrain['BalanceGross'].apply(lambda x: fix_num(x))\nXYtrain['DisbursementGross'] = XYtrain['DisbursementGross'].apply(lambda x: fix_num(x))\nXYtrain['GrAppv'] = XYtrain['GrAppv'].apply(lambda x: fix_num(x))\nXYtrain['SBA_Appv'] = XYtrain['SBA_Appv'].apply(lambda x: fix_num(x))\n\nprint(XYtrain[['BalanceGross','DisbursementGross','GrAppv','SBA_Appv']].head())","1ea50671":"## Remove anormalities\n# ApprovalFY contain anormalities year value with A value behind that needs to be removed. \nprint(XYtrain['ApprovalFY'].unique())\n# Create a function to apply formatting to the records of str type only\ndef clean_str(x):\n    if isinstance(x, str):\n        return x.replace('A', '')\n    return x\n\n\nXYtrain['ApprovalFY'] = XYtrain['ApprovalFY'].apply(clean_str).astype('int64')\nprint(XYtrain['ApprovalFY'].unique())\n","a5298e79":"## DisbursementDate should not be later than 2014 or earlier than ApprovalDate\n## These dates should be removed.\nXYtrain[['ApprovalDate', 'DisbursementDate']] = XYtrain[['ApprovalDate', 'DisbursementDate']].apply(pd.to_datetime)\n\n\nXYtrain['DisbursementDate'].describe()\n\nimport datetime\nd1 = datetime.datetime(2014, 12, 31)\nd2 = datetime.datetime(1987, 1, 1)\nprint(XYtrain[XYtrain['DisbursementDate']>d1]['DisbursementDate'])\nprint(XYtrain[XYtrain['DisbursementDate']<XYtrain['ApprovalDate']][['DisbursementDate','ApprovalDate']])\n\n#we remove all the illogical dates\nXYtrain=XYtrain[XYtrain['DisbursementDate']<d1]\nXYtrain=XYtrain[XYtrain['DisbursementDate']>XYtrain['ApprovalDate']]\n","685c5273":"#NewExist\n# Change NewExist field from value 2(exist) and 1(not exist) to 1(exist) and 1(not exist). \nXYtrain.loc[(XYtrain['NewExist'] == 0), 'IsNewExist'] = np.nan\nXYtrain.loc[(XYtrain['NewExist'] == 1), 'IsNewExist'] = 0\nXYtrain.loc[(XYtrain['NewExist'] == 2), 'IsNewExist'] = 1\nXYtrain['IsNewExist'].unique()\n\nprint(XYtrain['IsNewExist'].value_counts(dropna=False))\n","96053037":"#Franchise\n#FranchiseCode is not really important here. It is important to consider whether the loan is given to a business with or without a franchise\n\nXYtrain.loc[(XYtrain['FranchiseCode'] <= 1), 'IsFranchise'] = 0\nXYtrain.loc[(XYtrain['FranchiseCode'] > 1), 'IsFranchise'] = 1\nXYtrain['IsFranchise'].unique()\n\nprint(XYtrain['IsFranchise'].value_counts(dropna=False))\n","b7a6f23c":"#UrbanRural\n#Change value 0 to nan, as it is undefined. Also Change UrbanRural to binary\nXYtrain.loc[(XYtrain['UrbanRural'] == 0 ), 'IsUrban'] = 'Others'\nXYtrain.loc[(XYtrain['UrbanRural'] == 1), 'IsUrban'] = 'Urban'\nXYtrain.loc[(XYtrain['UrbanRural'] == 2), 'IsUrban'] = 'Rural'\nXYtrain['IsUrban'].value_counts()\nprint(XYtrain['IsUrban'].value_counts(dropna=False))\n","de3729d6":"# #RevLineCr \nprint(XYtrain['RevLineCr'].unique())\nXYtrain.loc[(XYtrain['RevLineCr'] != 'Y'), 'HasRevLine'] = np.nan\nXYtrain.loc[(XYtrain['RevLineCr'] != 'N'), 'HasRevLine'] = np.nan\nXYtrain.loc[(XYtrain['RevLineCr'] == 'Y'), 'HasRevLine'] = 1\nXYtrain.loc[(XYtrain['RevLineCr'] == 'N'), 'HasRevLine'] = 0\n\nprint(XYtrain['HasRevLine'].value_counts(dropna=False))\n","7691a3c6":"#LowDoc\n#LowDoc contains many unrecognised labels, so we need to set them as nan except \"Y\" or \"N\"\nprint(XYtrain['LowDoc'].unique())\nXYtrain.loc[(XYtrain['LowDoc'] != 'Y'), 'IsLowDoc'] = np.nan\nXYtrain.loc[(XYtrain['LowDoc'] != 'N'), 'IsLowDoc'] = np.nan\nXYtrain.loc[(XYtrain['LowDoc'] == 'Y'), 'IsLowDoc'] = 1\nXYtrain.loc[(XYtrain['LowDoc'] == 'N'), 'IsLowDoc'] = 0\n\nprint(XYtrain['IsLowDoc'].value_counts(dropna=False))\n","31438206":"#Recession\n#We create a Within_rec_year feature that is if recession year falls within the dates of DisbursementDate plus the term date, we label it 1. If not, we label it 0. \n\nimport datetime\nfrom dateutil.relativedelta import relativedelta\nXYtrain['Loan_Date_End_Date'] = XYtrain[['DisbursementDate','Term']].apply(lambda x: x['DisbursementDate']+relativedelta(months=x['Term']),axis=1)\n\ndef financial_crisis_year_check(date_start,date_end):\n  rec = 0\n  if ((datetime.date(2007, 12, 1)< date_end) and (date_end< datetime.date(2009, 6 , 30))):\n    rec = 1\n  if ((datetime.date(2001, 3, 1)< date_end) and (date_end< datetime.date(2001, 11 , 30))):\n    rec = 1\n  if ((datetime.date(1990, 7, 1)< date_end) and (date_end< datetime.date(1991, 3 , 31))):\n    rec = 1\n  if ((datetime.date(1981, 7, 1)< date_end) and (date_end< datetime.date(1982, 11 , 30))):\n    rec = 1\n  if ((datetime.date(1980, 1, 31)< date_end) and (date_end< datetime.date(1980, 7 , 31))):\n    rec = 1\n  if ((datetime.date(1973, 11, 30)< date_end) and (date_end< datetime.date(1975, 3 , 31))):\n    rec = 1\n  if ((datetime.date(1969, 12, 31)< date_end) and (date_end<datetime.date(1970, 11 , 30))):\n    rec = 1\n  \n  return rec\n\n\nXYtrain['Within_rec_year'] = XYtrain[['DisbursementDate','Loan_Date_End_Date']].apply(lambda x: financial_crisis_year_check(x['DisbursementDate'],x['Loan_Date_End_Date']),axis=1)\n# XYtrain['Within_rec_year']= XYtrain['Within_rec_year'].fillna(1)\nXYtrain['Within_rec_year'].value_counts(dropna=False)\n","6442c9fb":"Within_rec_year_Default = XYtrain.groupby(['Within_rec_year'])['ChargeOff'].mean()\n\n## default rate\na4_dims = (5, 5)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = Within_rec_year_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Overall ChargeOff Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\n","99139976":"## Unique values in NAICS\nXYtrain['NAICS'].value_counts()","2c181768":"## NAICS (North America Industry Classification System)\n## Mapping the first two digit of the NAICS code to its industry\nXYtrain['Industry'] = XYtrain['NAICS'].astype('str').apply(lambda x: x[:2])\nXYtrain['Industry'] = XYtrain['Industry'].map({\n    '11': 'Ag\/For\/Fish\/Hunt',\n    '21': 'Min\/Quar\/Oil_Gas_ext',\n    '22': 'Utilities',\n    '23': 'Construction',\n    '31': 'Manufacturing',\n    '32': 'Manufacturing',\n    '33': 'Manufacturing',\n    '42': 'Wholesale_trade',\n    '44': 'Retail_trade',\n    '45': 'Retail_trade',\n    '48': 'Trans\/Ware',\n    '49': 'Trans\/Ware',\n    '51': 'Information',\n    '52': 'Finance\/Insurance',\n    '53': 'RE\/Rental\/Lease',\n    '54': 'Prof\/Science\/Tech',\n    '55': 'Mgmt_comp',\n    '56': 'Admin_sup\/Waste_Mgmt_Rem',\n    '61': 'Educational',\n    '62': 'Healthcare\/Social_assist',\n    '71': 'Arts\/Entertain\/Rec',\n    '72': 'Accom\/Food_serv',\n    '81': 'Other_no_pub',\n    '92': 'Public_Admin'\n})\n\nXYtrain['Industry'].value_counts(dropna=False)","f927b910":"#RealEstate Collateral\n\n#SBA loans with over a 20 year Term have to be backed by real estate, so I'd like to create a binary variable for RealEstate. \nXYtrain['RealEstate_Collatoral'] = (XYtrain['Term'] > 240).astype(str)\nXYtrain['RealEstate_Collatoral'] = XYtrain['RealEstate_Collatoral'].replace({'False':'0','True':'1'},regex=True).astype(int)\nXYtrain['RealEstate_Collatoral'].value_counts()\n","abd96a97":"#we dropped the old features that has been converted to binary and keep the ones below:\ncolumns_to_keep=['City', 'State', 'Zip', 'Bank', 'BankState',\n       'ApprovalDate', 'ApprovalFY', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob', 'DisbursementDate', \n        'DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv', 'IsNewExist',\n       'IsFranchise', 'IsUrban', 'HasRevLine', 'IsLowDoc',\n        'Within_rec_year', 'Industry',\n       'RealEstate_Collatoral','ChargeOff']\nXYtrain=XYtrain[columns_to_keep]\nXYtrain.head()","57d2947c":"#Overall Charge Off Rate\ndefault_count = XYtrain['ChargeOff'].value_counts()\/XYtrain['ChargeOff'].count()\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Overall Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\n","00eaea84":"#We create a numerical category that separate from the categorical feature for easier processing.\nnum_feature = ['ApprovalFY','Term','NoEmp','CreateJob','RetainedJob','DisbursementGross','BalanceGross','GrAppv','SBA_Appv']\nXtrain_num_feature = XYtrain[num_feature]\nXtrain_num_feature.describe().round(2)","e370f617":"#We plot the distriubtion below \nfig = plt.figure(figsize=(16,12))\nplt.title('Numerical Feature (before Logging)')\nfor i in range(len(Xtrain_num_feature.columns)):\n    fig.add_subplot(3,3,i+1)\n    sns.distplot(Xtrain_num_feature.iloc[:,i])\n    plt.xlabel(Xtrain_num_feature.columns[i])\n\nplt.tight_layout()\nplt.show()","ab918835":"#Log the skewed feature\nXtrain_num_feature['NoEmp']=np.log(Xtrain_num_feature['NoEmp']+1)\nsns.distplot(Xtrain_num_feature['NoEmp'])","aec9fadd":"#Log the skewed feature\nXtrain_num_feature['CreateJob']=np.log(Xtrain_num_feature['CreateJob']+1)\nsns.distplot(Xtrain_num_feature['CreateJob'])","313fd02a":"#Log the skewed feature\nXtrain_num_feature['RetainedJob']=np.log(Xtrain_num_feature['RetainedJob']+1)\nsns.distplot(Xtrain_num_feature['RetainedJob'])","d8404d9d":"#Log the skewed feature\nXtrain_num_feature['DisbursementGross']=np.log(Xtrain_num_feature['DisbursementGross']+1)\nsns.distplot(Xtrain_num_feature['DisbursementGross'])","ab2083e5":"#Log the skewed feature\nXtrain_num_feature['BalanceGross']=np.log(Xtrain_num_feature['BalanceGross']+1)\nsns.distplot(Xtrain_num_feature['BalanceGross'])","e4017caa":"#Log the skewed feature\nXtrain_num_feature['GrAppv']=np.log(Xtrain_num_feature['GrAppv']+1)\nsns.distplot(Xtrain_num_feature['GrAppv'])","525eaac3":"#Log the skewed feature\nXtrain_num_feature['SBA_Appv']=np.log(Xtrain_num_feature['SBA_Appv']+1)\nsns.distplot(Xtrain_num_feature['SBA_Appv'])","4135d9e5":"#Log the skewed feature\nXtrain_num_feature=Xtrain_num_feature.drop('BalanceGross',axis=1)","a7b31ea0":"#We plot the numerical feature again after processing\nfig = plt.figure(figsize=(16,12))\nplt.title('Numerical Feature (After logging)')\nfor i in range(len(Xtrain_num_feature.columns)):\n    fig.add_subplot(3,3,i+1)\n    sns.distplot(Xtrain_num_feature.iloc[:,i])\n    plt.xlabel(Xtrain_num_feature.columns[i])\n\nplt.tight_layout()\nplt.show()","666e5161":"#plot correlation chart\ncorrelation = Xtrain_num_feature.corr()\n\nf, ax = plt.subplots(figsize=(14,12))\nplt.title('Correlation of numerical attributes', size=30)\nsns.heatmap(correlation, annot = True)\nplt.show()\n\ncorrelation","5fa6fc6c":"#plot correlation chart against the targer variable\n\ny_corr = pd.DataFrame(Xtrain_num_feature.corrwith(XYtrain['ChargeOff']),columns=[\"Correlation with target variable\"])\ny_corr_sorted= y_corr.sort_values(by=['Correlation with target variable'],ascending=False)\n\nfig = plt.figure(figsize=(10,6))\nplt.title('Correlation with target variable')\na=sns.barplot(y_corr_sorted.index,y_corr_sorted.iloc[:,0],data=y_corr)\na.set_xticklabels(labels=y_corr_sorted.index,rotation=45)\nplt.tight_layout()\nplt.show()\n# plt.hist(y_corr)","7e6aea7f":"# We separate out the categorical feature\ncat_features = ['City', 'State','Bank','BankState',\n       'Industry','IsNewExist', 'IsFranchise', 'IsUrban', 'ApprovalFY',\n       'HasRevLine', 'IsLowDoc','Within_rec_year', 'RealEstate_Collatoral','ChargeOff']\nXtrain_cat_features = XYtrain[cat_features]\n","5c818f6a":"#We plot the state's charge off rate\nState_Default = Xtrain_cat_features.groupby(['State'])['ChargeOff'].mean()\n\n## Charge off rate \na4_dims = (14, 5)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = State_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Overall ChargeOff Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black',rotation=90)\nfor item in splot.get_xticklabels():\n    item.set_rotation(90)\n","f248f28e":"#We plot the bank state's charge off rate\n\nBankState_Default = Xtrain_cat_features.groupby(['BankState'])['ChargeOff'].mean()\n\n## default rate\na4_dims = (14, 7)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = BankState_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Overall Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black',rotation=90)\nfor item in splot.get_xticklabels():\n    item.set_rotation(90)\n","7302e688":"#We plot the state's Industry's charge off rate\n\n\nIndustry_Default = Xtrain_cat_features.groupby(['Industry'])['ChargeOff'].mean()\n\n## default rate\na4_dims = (14, 5)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = Industry_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Overall Charge Off Rate')\n\n\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black',rotation=90)\nfor item in splot.get_xticklabels():\n    item.set_rotation(90)\n","6dc02380":"# NewExist's Charge Off Rate\nIsNewExist_Default = Xtrain_cat_features.groupby(['IsNewExist'])['ChargeOff'].mean()\n\n## default rate\na4_dims = (3, 3)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = IsNewExist_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')","85593d48":"#IsFranchise 's Charge Off rate\nIsFranchise_Default = Xtrain_cat_features.groupby(['IsFranchise'])['ChargeOff'].mean()\n\n## default rate\na4_dims = (3, 3)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = IsFranchise_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')","c0191e15":"#IsUrban's Charge Off rate\nIsUrban_Default= Xtrain_cat_features.groupby(['IsUrban'])['ChargeOff'].mean()\n\n\n## default rate\na4_dims = (3, 3)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = IsUrban_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')","90ae72fd":"#HasRevLine's ChargeOff rate\nHasRevLine_Default = Xtrain_cat_features.groupby(['HasRevLine'])['ChargeOff'].mean()\n\n## default rate\na4_dims = (3, 3)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = HasRevLine_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')","dcc4b2e5":"#We plot IsLowDoc's charge off rate\n\nIsLowDoc_Default = Xtrain_cat_features.groupby(['IsLowDoc'])['ChargeOff'].mean()\n\n\n## default rate\na4_dims = (3, 3)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = IsLowDoc_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')","f068257f":"# RealEstate_collatoral's charge off rate\nRealEstate_Collatoral_Default = Xtrain_cat_features.groupby(['RealEstate_Collatoral'])['ChargeOff'].mean()  \n\n## default rate\na4_dims = (3, 3)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = RealEstate_Collatoral_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')","e77491e2":"# Within recession year's charge off rate\nWithin_rec_year_Default = Xtrain_cat_features.groupby(['Within_rec_year'])['ChargeOff'].mean()\n\n## default rate\na4_dims = (3, 3)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = Within_rec_year_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')","00a18fe4":"#ApprovalFY's charge off rate \nApprovalFY_Default = Xtrain_cat_features.groupby(['ApprovalFY'])['ChargeOff'].mean()\n\n## default rate\na4_dims = (14, 5)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = ApprovalFY_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Charge Off Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black',rotation=90)\nfor item in splot.get_xticklabels():\n    item.set_rotation(90)\n","2247991f":"#Count of approvalFY\nApprovalFY_Default_count = Xtrain_cat_features.groupby(['ApprovalFY'])['ChargeOff'].count()\n## default rate\na4_dims = (20, 10)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = ApprovalFY_Default_count\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Data Count')\nfor p in splot.patches:\n    splot.annotate('{:}'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black',\n                    ).set_rotation(90)\nfor item in splot.get_xticklabels():\n    item.set_rotation(90)\n","fb015d49":"#Convert from ApprovalDate to Approvate Month\nXtrain_cat_features['ApprovalMonth']=XYtrain['ApprovalDate'].dt.strftime('%b')\nXtrain_cat_features['ApprovalMonth']","d54aa06f":"#plot ApprovalMonth's charge off rate\nApprovalMonth_Default = Xtrain_cat_features.groupby(['ApprovalMonth'])['ChargeOff'].mean()\nApprovalMonth_Default= ApprovalMonth_Default[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']]\n\n## default rate\na4_dims = (20, 10)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = ApprovalMonth_Default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Overall Default Rate')\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nfor item in splot.get_xticklabels():\n    item.set_rotation(90)\n","449bcc9b":"#ApprovalMonth's count\nApprovalMonth_Default_count = Xtrain_cat_features.groupby(['ApprovalMonth'])['ChargeOff'].count()\nApprovalMonth_Default_count=ApprovalMonth_Default_count[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']]\n\n## default rate\na4_dims = (20, 10)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = ApprovalMonth_Default_count\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Data Count')\nfor p in splot.patches:\n    splot.annotate('{:}'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black',\n                    ).set_rotation(90)\nfor item in splot.get_xticklabels():\n    item.set_rotation(90)\n","9427f781":"!pip install uszipcode\nfrom uszipcode import SearchEngine, SimpleZipcode, Zipcode\nfrom operator import itemgetter\n\nsearch = SearchEngine(simple_zipcode=False)\ndef determine_majority_population(zipcode):\n    zipcode = search.by_zipcode(zipcode)\n    zip_race = zipcode.population_by_race\n    if zip_race:\n        zip_race_racial_values=zip_race[0]['values']\n        newlist = sorted(zip_race_racial_values, key=itemgetter('y'), reverse=True)\n        return newlist[0]['x']        \n\nXtrain_cat_features['racial_community_majority'] = XYtrain['Zip'].apply(determine_majority_population)\n","4f850ca1":"racial_community_default = Xtrain_cat_features.groupby(['racial_community_majority'])['ChargeOff'].mean()\n\n\n## default rate\na4_dims = (14, 3)\n\nfig, ax = plt.subplots(figsize=a4_dims)\ndefault_count = racial_community_default\nsplot = sns.barplot(default_count.index, default_count.values)\nsplot.set_title('Overall Charge Off Rate')\n\n\nfor p in splot.patches:\n    splot.annotate('{:.2f}%'.format(p.get_height()*100), (p.get_x()+0.3, p.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\nfor item in splot.get_xticklabels():\n    item.set_rotation(45)\n","7d0a3d39":"#We filter the list of important feature\nXtrain_cat_features = Xtrain_cat_features[['State','BankState', 'Industry', 'IsNewExist',\n       'IsFranchise', 'IsUrban', 'HasRevLine', 'IsLowDoc', 'Within_rec_year',\n       'RealEstate_Collatoral','ApprovalMonth','racial_community_majority','ChargeOff']]\n\n","9cc63b79":"#We map each categorical feature to its own group default rate\nXtrain_num_feature['State_Default']=Xtrain_cat_features['State'].map(State_Default)\nXtrain_num_feature['BankState_Default']=Xtrain_cat_features['BankState'].map(BankState_Default)\nXtrain_num_feature['IsNewExist_Default']=Xtrain_cat_features['IsNewExist'].map(IsNewExist_Default)\nXtrain_num_feature['IsFranchise_Default']=Xtrain_cat_features['IsFranchise'].map(IsFranchise_Default)\nXtrain_num_feature['IsUrban_Default']=Xtrain_cat_features['IsUrban'].map(IsUrban_Default)\nXtrain_num_feature['HasRevLine_Default']=Xtrain_cat_features['HasRevLine'].map(HasRevLine_Default)\nXtrain_num_feature['IsLowDoc_Default']=Xtrain_cat_features['IsLowDoc'].map(IsLowDoc_Default)\nXtrain_num_feature['Within_rec_year_Default']=Xtrain_cat_features['Within_rec_year'].map(Within_rec_year_Default)\nXtrain_num_feature['Industry_Default']=Xtrain_cat_features['Industry'].map(Industry_Default)\nXtrain_num_feature['ApprovalMonth_Default']=Xtrain_cat_features['ApprovalMonth'].map(ApprovalMonth_Default)\nXtrain_num_feature['RealEstate_Collatoral_Default']=Xtrain_cat_features['RealEstate_Collatoral'].map(RealEstate_Collatoral_Default)\nXtrain_num_feature['ApprovalFY_Default']=XYtrain['ApprovalFY'].map(ApprovalFY_Default)\nXtrain_num_feature['racial_community_default']=Xtrain_cat_features['racial_community_majority'].map(racial_community_default)","70fc5c4d":"#Normalized all the numerical feature\nfrom sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler().fit(Xtrain_num_feature)\nXtrain_num_feature_norm_scaled = scaler.transform(Xtrain_num_feature)\nXtrain_num_feature_norm_scaled = pd.DataFrame(Xtrain_num_feature_norm_scaled, columns=Xtrain_num_feature.columns, index=Xtrain_num_feature.index)\nXtrain_num_feature_norm_scaled","55f036cf":"#Correlation chart of the normalized features.\ncorrelation1 = Xtrain_num_feature[['State_Default','BankState_Default','IsNewExist_Default','IsFranchise_Default','IsUrban_Default','HasRevLine_Default','IsLowDoc_Default','Within_rec_year_Default','Industry_Default','ApprovalMonth_Default','racial_community_default']].corr()\n\nf, ax = plt.subplots(figsize=(14,12))\nplt.title('Correlation of numerical attributes', size=30)\nsns.heatmap(correlation1, annot = True)\nplt.show()\n\ncorrelation1","b567dd3c":"XYtrain.columns","98c40d03":"Xtrain_cat_features.info()","98fd19ff":"Xtrain_num_feature_norm_scaled.info()","34b00082":"#Missing values of our merged dataframe with ful llist of features\nfulldf=pd.merge(Xtrain_num_feature_norm_scaled,Xtrain_cat_features,how='left',left_index=True,right_index =True)\nfulldf.isnull().sum()","6273c683":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix","2e2353e7":"#Encode all catergorical feature into One Hot Encode\nSelected_feature_set_1_df = fulldf[['State', 'BankState', 'ApprovalMonth', 'ApprovalFY', 'Term', 'NoEmp', 'CreateJob', \n                                              'RetainedJob', 'DisbursementGross', 'IsNewExist', 'IsFranchise', 'IsUrban', 'HasRevLine', \n                                              'IsLowDoc', 'Within_rec_year', 'Industry', \n                                              'RealEstate_Collatoral', 'ChargeOff']]\n\nSelected_feature_set_1_df = Selected_feature_set_1_df.dropna()\nSelected_feature_set_1_df = pd.get_dummies(Selected_feature_set_1_df, drop_first=True)\n\nSelected_feature_set_1_df.info()","78f6688c":"#Map all catorical feature according to its default rate\n\nSelected_feature_set_2_df = fulldf[['State_Default', 'BankState_Default', 'ApprovalMonth_Default', 'ApprovalFY_Default', 'Term', 'NoEmp', 'CreateJob', \n                                              'RetainedJob', 'DisbursementGross', 'IsNewExist_Default', 'IsFranchise_Default', 'IsUrban_Default', 'HasRevLine_Default', \n                                              'IsLowDoc_Default', 'Within_rec_year_Default', 'Industry_Default', \n                                              'RealEstate_Collatoral_Default', 'ChargeOff']]\nSelected_feature_set_2_df.info()                                 ","ccf91e32":"## Handling Missing Value technique 1 Multiple imputation by chained equations\nfrom fancyimpute import IterativeImputer\n\nitr_ipt = IterativeImputer()\ny_df = Selected_feature_set_2_df['ChargeOff']\nX_df = Selected_feature_set_2_df.drop('ChargeOff',axis=1)\nX_df_impute = itr_ipt.fit_transform(X_df)\nX_df = pd.DataFrame(X_df_impute, columns= X_df.columns, index=X_df.index)\nSelected_feature_set_2_mice_inpute_df = X_df.merge(y_df,left_index=True, right_index=True)\nSelected_feature_set_2_mice_inpute_df.info()","db60d27c":"## Handling Missing Value technique 2 drop data\nSelected_feature_set_2_drop_allna_df = Selected_feature_set_2_df.dropna()\nSelected_feature_set_2_drop_allna_df.info()","b0b1b692":"#Hybrid combination of one hot encoding and default rate mapping\nSelected_feature_set_3_df = fulldf[['ApprovalFY','Term','NoEmp','CreateJob','RetainedJob','DisbursementGross','IsNewExist','IsFranchise','HasRevLine',\n                                    'IsLowDoc','Within_rec_year','RealEstate_Collatoral','Industry_Default','ApprovalMonth_Default',\n                                    'IsUrban_Default','State_Default','BankState_Default','ChargeOff']]\n\n\nSelected_feature_set_3_df.info()","66a2aa8b":"## Handling Missing Value technique 1 Multiple imputation by chained equations\nfrom fancyimpute import IterativeImputer\n\nitr_ipt = IterativeImputer()\ny_df = Selected_feature_set_3_df['ChargeOff']\nX_df = Selected_feature_set_3_df.drop('ChargeOff',axis=1)\nX_df_impute = itr_ipt.fit_transform(X_df)\nX_df = pd.DataFrame(X_df_impute, columns= X_df.columns, index=X_df.index)\nSelected_feature_set_3_mice_inpute_df = X_df.merge(y_df,left_index=True, right_index=True)\nSelected_feature_set_3_mice_inpute_df.info()","e263828d":"##Handling Missing Value technique 2 drop data\nSelected_feature_set_3_drop_allna_df = Selected_feature_set_3_df.dropna()\nSelected_feature_set_3_drop_allna_df.info()","de693159":"from sklearn.ensemble import GradientBoostingClassifier\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression","0715df7a":"#Run LR on feature set 1\n\ny = Selected_feature_set_1_df['ChargeOff']\nX = Selected_feature_set_1_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","3b7f849a":"#Run Gradient Boosting on feature set 1\n\ny = Selected_feature_set_1_df['ChargeOff']\nX = Selected_feature_set_1_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","3cd592b4":"#Run XGBoost on feature set 1\nimport xgboost as xgb\n\ny = Selected_feature_set_1_df['ChargeOff']\nX = Selected_feature_set_1_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = xgb.XGBClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","3fa618b1":"#Run LR on feature set 2 - MICE imputation\ny = Selected_feature_set_2_mice_inpute_df['ChargeOff']\nX = Selected_feature_set_2_mice_inpute_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = LogisticRegression(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","7ecdc698":"#Run Gradient Boosting on feature set 2 - MICE imputation\ny = Selected_feature_set_2_mice_inpute_df['ChargeOff']\nX = Selected_feature_set_2_mice_inpute_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","cf2fcb1a":"#Run XGB on feature set 2 - MICE imputation\ny = Selected_feature_set_2_mice_inpute_df['ChargeOff']\nX = Selected_feature_set_2_mice_inpute_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = xgb.XGBClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","e3839f93":"#Run LR on feature set 2 - dropped all missing \ny = Selected_feature_set_2_drop_allna_df['ChargeOff']\nX = Selected_feature_set_2_drop_allna_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","eb47e58c":"#Run LR on feature set 2 - dropped all missing \ny = Selected_feature_set_2_drop_allna_df['ChargeOff']\nX = Selected_feature_set_2_drop_allna_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","515c0c96":"#Run XGB on feature set 2 - dropped all missing \ny = Selected_feature_set_2_drop_allna_df['ChargeOff']\nX = Selected_feature_set_2_drop_allna_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = xgb.XGBClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","25406ecb":"#Run LR on feature set 3 - MICE imputation\ny = Selected_feature_set_3_mice_inpute_df['ChargeOff']\nX = Selected_feature_set_3_mice_inpute_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","29a6f102":"#Run LR on feature set 3 - MICE imputation\ny = Selected_feature_set_3_mice_inpute_df['ChargeOff']\nX = Selected_feature_set_3_mice_inpute_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","fe6b743f":"#Run LR on feature set 3 - MICE imputation\ny = Selected_feature_set_3_mice_inpute_df['ChargeOff']\nX = Selected_feature_set_3_mice_inpute_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = xgb.XGBClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","62386e4f":"#Run LR on feature set 3 - dropped all missing\ny = Selected_feature_set_3_drop_allna_df['ChargeOff']\nX = Selected_feature_set_3_drop_allna_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","e216e881":"#Run LR on feature set 3 - dropped all missing\ny = Selected_feature_set_3_drop_allna_df['ChargeOff']\nX = Selected_feature_set_3_drop_allna_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = LogisticRegression(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","f53d836d":"#Run LR on feature set 3 - dropped all missing\ny = Selected_feature_set_3_drop_allna_df['ChargeOff']\nX = Selected_feature_set_3_drop_allna_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","fd18466d":"#Run LR on feature set 3 - dropped all missing\ny = Selected_feature_set_3_drop_allna_df['ChargeOff']\nX = Selected_feature_set_3_drop_allna_df.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = xgb.XGBClassifier(random_state=0).fit(X_train, y_train)\npred_y = clf.predict(X_test)\n\naccuracy_score(y_test, pred_y)","decb79f4":"#Feature set 2 with all missing value dropped set is our chosen set\nchosen_set = Selected_feature_set_3_drop_allna_df\nchosen_set","f1aa72b8":"%%time\n#LR\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = LogisticRegression(random_state=0).fit(X_train, y_train)\nprob_y = clf.predict_proba(X_test)[:,1]\npred_y =clf.predict(X_test)\n\nprint('Accuracy Score: {}'.format(accuracy_score(y_test, pred_y)))\nprint('F1: {}'.format(f1_score(y_test, pred_y)))\nprint('AUC: {}'.format(roc_auc_score(y_test, prob_y)))\n\nprint('\\nConfusion Matrix\\n{}'.format(confusion_matrix(y_test, pred_y)))\nprint('\\nClassification Repot\\n{}'.format(classification_report(y_test, pred_y)))","66400016":"%%time\n#RF\nfrom sklearn.ensemble import RandomForestClassifier\n\n\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = RandomForestClassifier(random_state=0).fit(X_train, y_train)\nprob_y = clf.predict_proba(X_test)[:,1]\npred_y =clf.predict(X_test)\n\nprint('Accuracy Score: {}'.format(accuracy_score(y_test, pred_y)))\nprint('F1: {}'.format(f1_score(y_test, pred_y)))\nprint('AUC: {}'.format(roc_auc_score(y_test, prob_y)))\n\nprint('\\nConfusion Matrix\\n{}'.format(confusion_matrix(y_test, pred_y)))\nprint('\\nClassification Repot\\n{}'.format(classification_report(y_test, pred_y)))","970c0d96":"%%time \n#svm\nfrom sklearn.svm import SVC\n\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = SVC(random_state=0).fit(X_train, y_train)\n# prob_y = clf.predict_proba(X_test)[:,1]\npred_y =clf.predict(X_test)\n\nprint('Accuracy Score: {}'.format(accuracy_score(y_test, pred_y)))\nprint('F1: {}'.format(f1_score(y_test, pred_y)))\nprint('AUC: {}'.format(roc_auc_score(y_test, prob_y)))\n\nprint('\\nConfusion Matrix\\n{}'.format(confusion_matrix(y_test, pred_y)))\nprint('\\nClassification Repot\\n{}'.format(classification_report(y_test, pred_y)))","3fd3180f":"%%time\nfrom sklearn.naive_bayes import GaussianNB\n\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = GaussianNB().fit(X_train, y_train)\nprob_y = clf.predict_proba(X_test)[:,1]\npred_y =clf.predict(X_test)\n\nprint('Accuracy Score: {}'.format(accuracy_score(y_test, pred_y)))\nprint('F1: {}'.format(f1_score(y_test, pred_y)))\nprint('AUC: {}'.format(roc_auc_score(y_test, prob_y)))\n\nprint('\\nConfusion Matrix\\n{}'.format(confusion_matrix(y_test, pred_y)))\nprint('\\nClassification Repot\\n{}'.format(classification_report(y_test, pred_y)))","ccefcb4e":"%%time\nimport xgboost as xgb\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = xgb.XGBClassifier(random_state=0).fit(X_train, y_train)\nprob_y = clf.predict_proba(X_test)[:,1]\npred_y =clf.predict(X_test)\n\nprint('Accuracy Score: {}'.format(accuracy_score(y_test, pred_y)))\nprint('F1: {}'.format(f1_score(y_test, pred_y)))\nprint('AUC: {}'.format(roc_auc_score(y_test, prob_y)))\n\nprint('\\nConfusion Matrix\\n{}'.format(confusion_matrix(y_test, pred_y)))\nprint('\\nClassification Repot\\n{}'.format(classification_report(y_test, pred_y)))","54d90176":"%%time\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\nprob_y = clf.predict_proba(X_test)[:,1]\npred_y =clf.predict(X_test)\n\nprint('Accuracy Score: {}'.format(accuracy_score(y_test, pred_y)))\nprint('F1: {}'.format(f1_score(y_test, pred_y)))\nprint('AUC: {}'.format(roc_auc_score(y_test, prob_y)))\n\nprint('\\nConfusion Matrix\\n{}'.format(confusion_matrix(y_test, pred_y)))\nprint('\\nClassification Repot\\n{}'.format(classification_report(y_test, pred_y)))","c2d9c996":"%%time\n\nfrom sklearn.model_selection import GridSearchCV\n\npredictors = X.columns\nparam_test7 = {'min_samples_split':[1400,1600,1800]}\ngsearch7 = GridSearchCV(estimator = GradientBoostingClassifier(subsample=0.8,max_features = 11 ,n_estimators=800, learning_rate=0.1,random_state=10,max_depth=5, min_samples_split=1600, min_samples_leaf=40), \nparam_grid = param_test7, n_jobs=-1,iid=False, cv=5)\ngsearch7.fit(X,y)\nprint(gsearch7)\n\n\n\nprint('\\n cv results: \\n{}\\n'.format(gsearch7.cv_results_))\nprint('\\n best params: \\n{}\\n'.format(gsearch7.best_params_))\nprint('\\n best accuracy score: \\n{}\\n'.format(gsearch7.best_score_))","b469c380":"%%time\n\nfrom sklearn.model_selection import GridSearchCV\nparam_test7 = {\n    'min_child_weight': [1,2,3]\n}\n\nxgbsearch7 = GridSearchCV(estimator = xgb.XGBClassifier( subsample=0.8,colsample_bytree=0.7, min_child_weight=1,max_depth=9, learning_rate =0.05, n_estimators=380,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=10, reg_alpha=1e-10), \n param_grid = param_test7,n_jobs=-1,iid=False, cv=5)\nxgbsearch7.fit(X, y)\n\nprint(xgbsearch7)\nprint('\\n cv results: \\n{}\\n'.format(xgbsearch7.cv_results_))\nprint('\\n best params: \\n{}\\n'.format(xgbsearch7.best_params_))\nprint('\\n best accuracy score: \\n{}\\n'.format(xgbsearch7.best_score_))","b327b67b":"xgbsearch7","97fb8bb8":"%%time\n\n#RF\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\n\npredictors = X.columns\nparam_test1 = {'n_estimators':[1000,2000]}\nrfsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=10, min_samples_leaf=1,bootstrap=True, criterion='gini',random_state=10), \nparam_grid = param_test1,n_jobs=-1,iid=False, cv=5)\nrfsearch1.fit(X,y)\nprint(rfsearch1)\n\n\nprint('\\n cv results: \\n{}\\n'.format(rfsearch1.cv_results_))\nprint('\\n best params: \\n{}\\n'.format(rfsearch1.best_params_))\nprint('\\n best accuracy score: \\n{}\\n'.format(rfsearch1.best_score_))","7475efac":"# from sklearn.model_selection import GridSearchCV\n","36acd672":"# print(gsearch7.cv_results_)\n# print(gsearch7.best_params_)\n# print(gsearch7.best_score_)","cd51908b":"# %%time\n# predictors = X.columns\n# param_test2 = {'min_samples_split':range(5,21,5)}\n# gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(max_depth = 22, n_estimators=290, learning_rate=1, min_samples_leaf=50,max_features='sqrt',subsample=0.8,random_state=10), \n# param_grid = param_test2 ,n_jobs=-1,iid=False, cv=5)\n# gsearch2.fit(X,y)\n\n# print('\\n cv results: \\n{}\\n'.format(gsearch2.cv_results_))\n# print('\\n best params: \\n{}\\n'.format(gsearch2.best_params_))\n# print('\\n best accuracy score: \\n{}\\n'.format(gsearch2.best_score_))","c7f1069e":"# %%time\n# predictors = X.columns\n# param_test3 = {'max_depth':range(5,16,2)}\n# gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(max_depth = 22, n_estimators=290, learning_rate=1,subsample=0.8,random_state=10, min_samples_split=5), \n# param_grid = param_test3 ,n_jobs=-1,iid=False, cv=5)\n# gsearch3.fit(X,y)\n\n# print('\\n cv results: \\n{}\\n'.format(gsearch3.cv_results_))\n# print('\\n best params: \\n{}\\n'.format(gsearch3.best_params_))\n# print('\\n best accuracy score: \\n{}\\n'.format(gsearch3.best_score_))","4700a234":"# feature_score = pd.DataFrame(gsearch1.best_estimator_.feature_importances_, index=X.columns, columns=['Feature Importance Score']).sort_values(by='Feature Importance Score',ascending=False)\n\n# fig, ax = plt.subplots(figsize=(20,5))\n# splot = sns.barplot(score.index, score.iloc[:,0])\n# splot.set_title('Feature Importance Score')\n# for item in splot.get_xticklabels():\n#     item.set_rotation(90)\n","d1cf2f9a":"\n# %%time\n# predictors = X.columns\n# param_test7 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n# gsearch7 = GridSearchCV(estimator = GradientBoostingClassifier(max_features = 17, max_depth = 22, n_estimators=290, learning_rate=0.02,random_state=10, min_samples_split=100), \n# param_grid = param_test7, n_jobs=-1,iid=False, cv=5)\n# gsearch7.fit(X,y)\n\n","822eed83":"\n# %%time\n# predictors = X.columns\n# gsearch8 = GradientBoostingClassifier(subsample=0.8,max_features = 11 ,n_estimators=500, learning_rate=0.2,random_state=10,max_depth=5, min_samples_split=1600, min_samples_leaf=40)\n# gsearch8.fit(X,y)\n\n","7df66d4e":"# prob_y = gsearch8.predict_proba(X_test)[:,1]\n# pred_y =gsearch8.predict(X_test)\n\n# print(accuracy_score(y_test, pred_y))\n# print(confusion_matrix(y_test, pred_y))\n# print(roc_auc_score(y_test, prob_y))\n# print(classification_report(y_test, pred_y))","abacc693":"\n# %%time\n# predictors = X.columns\n# gsearch9 = GradientBoostingClassifier(subsample=0.8,max_features = 11 ,n_estimators=1000, learning_rate=0.1,random_state=10,max_depth=5, min_samples_split=1600, min_samples_leaf=40)\n# gsearch9.fit(X,y)\n\n","a02aa33a":"# prob_y = gsearch9.predict_proba(X_test)[:,1]\n# pred_y =gsearch9.predict(X_test)\n\n# print(accuracy_score(y_test, pred_y))\n# print(confusion_matrix(y_test, pred_y))\n# print(roc_auc_score(y_test, prob_y))\n# print(classification_report(y_test, pred_y))","6a72fe95":"# %%time\n# predictors = X.columns\n# param_test1 = {'n_estimators':range(280,321,10)}\n# gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=1, min_samples_split=1500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n# param_grid = param_test1,n_jobs=-1,iid=False, cv=5)\n# gsearch1.fit(X,y)\n\n\n# print('\\n cv results: \\n{}\\n'.format(gsearch1.cv_results_))\n# print('\\n best params: \\n{}\\n'.format(gsearch1.best_params_))\n# print('\\n best accuracy score: \\n{}\\n'.format(gsearch1.best_score_))","cb2bf3b6":"X_rawtest = pd.read_csv('..\/input\/cs5228-2021s1\/Xtest.csv')\nX_rawtest.info()","5dd43894":"def fix_num(number):\n    num = number.replace(\"$\", \"\")\n    num = num.replace(\",\",\"\")\n    num = num.replace(\" \",\"\")\n    return float(num)\n\nX_rawtest['BalanceGross'] = X_rawtest['BalanceGross'].apply(lambda x: fix_num(x))\nX_rawtest['DisbursementGross'] = X_rawtest['DisbursementGross'].apply(lambda x: fix_num(x))\nX_rawtest['GrAppv'] = X_rawtest['GrAppv'].apply(lambda x: fix_num(x))\nX_rawtest['SBA_Appv'] = X_rawtest['SBA_Appv'].apply(lambda x: fix_num(x))\n\nprint(X_rawtest[['BalanceGross','DisbursementGross','GrAppv','SBA_Appv']].head())\n","c71e38ce":"## Remove anormalities\nprint(X_rawtest['ApprovalFY'].unique())\n# Create a function to apply formatting to the records of str type only\ndef clean_str(x):\n    if isinstance(x, str):\n        return x.replace('A', '')\n    return x\n\n\nX_rawtest['ApprovalFY'] = X_rawtest['ApprovalFY'].apply(clean_str).astype('int64')\nprint(X_rawtest['ApprovalFY'].unique())\n","1dd4c293":"X_rawtest[['ApprovalDate', 'DisbursementDate']] = X_rawtest[['ApprovalDate', 'DisbursementDate']].apply(pd.to_datetime)\n","29ec4acb":"#NewExist\nprint(X_rawtest['NewExist'].unique())\n\n# Change NewExist field from value 2(exist) and 1(not exist) to 1(exist) and 1(not exist). \nX_rawtest.loc[(X_rawtest['NewExist'] == 0), 'IsNewExist'] = np.nan\nX_rawtest.loc[(X_rawtest['NewExist'] == 1), 'IsNewExist'] = 0\nX_rawtest.loc[(X_rawtest['NewExist'] == 2), 'IsNewExist'] = 1\nX_rawtest['IsNewExist'].unique()\n\nprint(X_rawtest['IsNewExist'].value_counts(dropna=False))\n","7234a4e5":"#Franchise\n\n#FranchiseCode is not really important here. It is important to consider whether the loan is given to a business with or without a franchise\n\nprint(X_rawtest['FranchiseCode'].unique())\n\nX_rawtest.loc[(X_rawtest['FranchiseCode'] <= 1), 'IsFranchise'] = 0\nX_rawtest.loc[(X_rawtest['FranchiseCode'] > 1), 'IsFranchise'] = 1\nX_rawtest['IsFranchise'].unique()\n\nprint(X_rawtest['IsFranchise'].value_counts(dropna=False))\n","c68f4b4b":"#UrbanRural\nprint(X_rawtest['UrbanRural'].unique())\n\n#Change value 0 to nan, as it is undefined. Also Change UrbanRural to binary\nX_rawtest.loc[(X_rawtest['UrbanRural'] == 0 ), 'IsUrban'] = 'Others'\nX_rawtest.loc[(X_rawtest['UrbanRural'] == 1), 'IsUrban'] = 'Urban'\nX_rawtest.loc[(X_rawtest['UrbanRural'] == 2), 'IsUrban'] = 'Rural'\nX_rawtest['IsUrban'].value_counts()\nprint(X_rawtest['IsUrban'].value_counts(dropna=False))\n","b9418993":"# #RevLineCr \nprint(X_rawtest['RevLineCr'].unique())\nX_rawtest.loc[(X_rawtest['RevLineCr'] != 'Y'), 'HasRevLine'] = np.nan\nX_rawtest.loc[(X_rawtest['RevLineCr'] != 'N'), 'HasRevLine'] = np.nan\nX_rawtest.loc[(X_rawtest['RevLineCr'] == 'Y'), 'HasRevLine'] = 1\nX_rawtest.loc[(X_rawtest['RevLineCr'] == 'N'), 'HasRevLine'] = 0\n\nprint(X_rawtest['HasRevLine'].value_counts(dropna=False))\n","4afc86ec":"#LowDoc\n\n#LowDoc contains many unrecognised labels, so we need to set them as nan except \"Y\" or \"N\"\nprint(X_rawtest['LowDoc'].unique())\nX_rawtest.loc[(X_rawtest['LowDoc'] != 'Y'), 'IsLowDoc'] = np.nan\nX_rawtest.loc[(X_rawtest['LowDoc'] != 'N'), 'IsLowDoc'] = np.nan\nX_rawtest.loc[(X_rawtest['LowDoc'] == 'Y'), 'IsLowDoc'] = 1\nX_rawtest.loc[(X_rawtest['LowDoc'] == 'N'), 'IsLowDoc'] = 0\n\nprint(X_rawtest['IsLowDoc'].value_counts(dropna=False))\n","8b4e48a7":"#Recession\nX_rawtest['DisbursementDate'] = X_rawtest['DisbursementDate'].fillna(X_rawtest['DisbursementDate'].mean())\n#We create a Within_rec_year feature that is if recession year falls within the dates of DisbursementDate plus the term date, we label it 1. If not, we label it 0. \nimport datetime\nfrom dateutil.relativedelta import relativedelta\nX_rawtest['Loan_Date_End_Date'] = X_rawtest[['DisbursementDate','Term']].apply(lambda x: x['DisbursementDate']+relativedelta(months=x['Term']),axis=1)\n\ndef financial_crisis_year_check(date_start,date_end):\n  rec = 0\n  if ((datetime.date(2007, 12, 1)< date_end) and (date_end< datetime.date(2009, 6 , 30))):\n    rec = 1\n  if ((datetime.date(2001, 3, 1)< date_end) and (date_end< datetime.date(2001, 11 , 30))):\n    rec = 1\n  if ((datetime.date(1990, 7, 1)< date_end) and (date_end< datetime.date(1991, 3 , 31))):\n    rec = 1\n  if ((datetime.date(1981, 7, 1)< date_end) and (date_end< datetime.date(1982, 11 , 30))):\n    rec = 1\n  if ((datetime.date(1980, 1, 31)< date_end) and (date_end< datetime.date(1980, 7 , 31))):\n    rec = 1\n  if ((datetime.date(1973, 11, 30)< date_end) and (date_end< datetime.date(1975, 3 , 31))):\n    rec = 1\n  if ((datetime.date(1969, 12, 31)< date_end) and (date_end<datetime.date(1970, 11 , 30))):\n    rec = 1\n  \n  return rec\n\nX_rawtest['Within_rec_year'] = X_rawtest[['DisbursementDate','Loan_Date_End_Date']].apply(lambda x: financial_crisis_year_check(x['DisbursementDate'],x['Loan_Date_End_Date']),axis=1)\n# XYtrain['Within_rec_year']= XYtrain['Within_rec_year'].fillna(1)\nX_rawtest['Within_rec_year'].value_counts(dropna=False)\n","a2cb8369":"#RealEstate Collateral\n\n#SBA loans with over a 20 year Term have to be backed by real estate, so I'd like to create a binary variable for RealEstate. \nX_rawtest['RealEstate_Collatoral'] = (X_rawtest['Term'] > 240).astype(str)\nX_rawtest['RealEstate_Collatoral'] = X_rawtest['RealEstate_Collatoral'].replace({'False':'0','True':'1'},regex=True).astype(int)\nX_rawtest['RealEstate_Collatoral'].value_counts()\n","da077101":"num_feature = ['ApprovalFY','Term','NoEmp','CreateJob','RetainedJob','DisbursementGross','BalanceGross','GrAppv','SBA_Appv']\nX_rawtest_num_feature = X_rawtest[num_feature]\nX_rawtest_num_feature.describe().round(3)","918fb8ab":"X_rawtest_num_feature['CreateJob']=np.log(X_rawtest_num_feature['CreateJob']+1)\nX_rawtest_num_feature['RetainedJob']=np.log(X_rawtest_num_feature['RetainedJob']+1)\nX_rawtest_num_feature['DisbursementGross']=np.log(X_rawtest_num_feature['DisbursementGross']+1)\nX_rawtest_num_feature['BalanceGross']=np.log(X_rawtest_num_feature['BalanceGross']+1)\nX_rawtest_num_feature['GrAppv']=np.log(X_rawtest_num_feature['GrAppv']+1)\nX_rawtest_num_feature['SBA_Appv']=np.log(X_rawtest_num_feature['SBA_Appv']+1)\n","03982c3c":"X_rawtest['Industry'] = X_rawtest['NAICS'].astype('str').apply(lambda x: x[:2])\nX_rawtest['Industry'] = X_rawtest['Industry'].map({\n    '11': 'Ag\/For\/Fish\/Hunt',\n    '21': 'Min\/Quar\/Oil_Gas_ext',\n    '22': 'Utilities',\n    '23': 'Construction',\n    '31': 'Manufacturing',\n    '32': 'Manufacturing',\n    '33': 'Manufacturing',\n    '42': 'Wholesale_trade',\n    '44': 'Retail_trade',\n    '45': 'Retail_trade',\n    '48': 'Trans\/Ware',\n    '49': 'Trans\/Ware',\n    '51': 'Information',\n    '52': 'Finance\/Insurance',\n    '53': 'RE\/Rental\/Lease',\n    '54': 'Prof\/Science\/Tech',\n    '55': 'Mgmt_comp',\n    '56': 'Admin_sup\/Waste_Mgmt_Rem',\n    '61': 'Educational',\n    '62': 'Healthcare\/Social_assist',\n    '71': 'Arts\/Entertain\/Rec',\n    '72': 'Accom\/Food_serv',\n    '81': 'Other_no_pub',\n    '92': 'Public_Admin'\n})\n\nXYtrain['Industry'].value_counts(dropna=False)","dd37e811":"X_rawtest_cat_feature = ['City', 'State','Bank','BankState',\n       'Industry','IsNewExist', 'IsFranchise', 'IsUrban', 'ApprovalFY',\n       'HasRevLine', 'IsLowDoc','Within_rec_year', 'RealEstate_Collatoral']\n\nX_rawtest_cat_feature = X_rawtest[X_rawtest_cat_feature]\nX_rawtest_cat_feature","792c3a02":"X_rawtest_cat_feature['ApprovalMonth']=X_rawtest['ApprovalDate'].dt.strftime('%b')\nX_rawtest_cat_feature['ApprovalMonth']","277b4490":"X_rawtest_num_feature['State_Default']=X_rawtest_cat_feature['State'].map(State_Default)\nX_rawtest_num_feature['BankState_Default']=X_rawtest_cat_feature['BankState'].map(BankState_Default)\nX_rawtest_num_feature['IsNewExist_Default']=X_rawtest_cat_feature['IsNewExist'].map(IsNewExist_Default)\nX_rawtest_num_feature['IsFranchise_Default']=X_rawtest_cat_feature['IsFranchise'].map(IsFranchise_Default)\nX_rawtest_num_feature['IsUrban_Default']=X_rawtest_cat_feature['IsUrban'].map(IsUrban_Default)\nX_rawtest_num_feature['HasRevLine_Default']=X_rawtest_cat_feature['HasRevLine'].map(HasRevLine_Default)\nX_rawtest_num_feature['IsLowDoc_Default']=X_rawtest_cat_feature['IsLowDoc'].map(IsLowDoc_Default)\nX_rawtest_num_feature['Within_rec_year_Default']=X_rawtest_cat_feature['Within_rec_year'].map(Within_rec_year_Default)\nX_rawtest_num_feature['Industry_Default']=X_rawtest_cat_feature['Industry'].map(Industry_Default)\nX_rawtest_num_feature['ApprovalMonth_Default']=X_rawtest_cat_feature['ApprovalMonth'].map(ApprovalMonth_Default)\nX_rawtest_num_feature['RealEstate_Collatoral_Default']=X_rawtest_cat_feature['RealEstate_Collatoral'].map(RealEstate_Collatoral_Default)\nX_rawtest_num_feature['ApprovalFY_Default']=X_rawtest['ApprovalFY'].map(ApprovalFY_Default)\n","16d2cf96":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler().fit(X_rawtest_num_feature)\nX_rawtest_num_feature_norm_scaled = scaler.transform(X_rawtest_num_feature)\nX_rawtest_num_feature_norm_scaled = pd.DataFrame(X_rawtest_num_feature_norm_scaled, columns=X_rawtest_num_feature.columns, index=X_rawtest_num_feature.index)\nX_rawtest_num_feature_norm_scaled","3829df60":"X_rawtest_cat_feature=X_rawtest_cat_feature.drop('ApprovalFY',axis=1)\ntest_fulldf=pd.merge(X_rawtest_num_feature_norm_scaled,X_rawtest_cat_feature,how='left',left_index=True,right_index =True)\ntest_fulldf.info()","7b1d933b":"test_Selected_feature_set_3_df = test_fulldf[['ApprovalFY','Term','NoEmp','CreateJob','RetainedJob','DisbursementGross','IsNewExist','IsFranchise','HasRevLine',\n                                    'IsLowDoc','Within_rec_year','RealEstate_Collatoral','Industry_Default','ApprovalMonth_Default',\n                                    'IsUrban_Default','State_Default','BankState_Default']]\ntest_Selected_feature_set_3_df.head()","86b78c8b":"test_Selected_feature_set_3_df.info()","46d6fce0":"from sklearn.impute import SimpleImputer\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\ntest_Selected_feature_set_3_df_impute = imp_mean.fit_transform(test_Selected_feature_set_3_df)\ntest_Selected_feature_set_3_df = pd.DataFrame(test_Selected_feature_set_3_df_impute, columns= test_Selected_feature_set_3_df.columns, index=test_Selected_feature_set_3_df.index)\ntest_Selected_feature_set_3_df.info()\n\n# from fancyimpute import IterativeImputer\n\n# Selected_feature_set_3_df = Selected_feature_set_3_df.dropna()\n# Selected_feature_set_3_df.info()\n# itr_ipt = IterativeImputer()\n# test_Selected_feature_set_3_df_impute = itr_ipt.fit_transform(test_Selected_feature_set_3_df)\n# test_Selected_feature_set_3_df = pd.DataFrame(test_Selected_feature_set_3_df_impute, columns= test_Selected_feature_set_3_df.columns, index=test_Selected_feature_set_3_df.index)","a5910053":"test_Selected_feature_set_3_df.info()","197289ef":"test_Selected_feature_set_3_df.head()","c5283772":"%%time\npred_y=0 \ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\n\ngsearch8 = GradientBoostingClassifier(subsample=0.8,max_features = 11 ,n_estimators=800, learning_rate=0.1,random_state=10,max_depth=5, min_samples_split=1600, min_samples_leaf=40)\ngsearch8.fit(X,y)\ngb_pred_y =gsearch8.predict(test_Selected_feature_set_3_df)\ngb_pred_y","2ec4935c":"%%time\n\nfrom xgboost.sklearn import XGBClassifier\n\npred_y=0\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\nxgbsearch8 = XGBClassifier(base_score=None, booster=None,\n                                     colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=0.7, gamma=None,\n                                     gpu_id=None, importance_type='gain',\n                                     interaction_constraints=None,\n                                     learning_rate=0.05, max_delta_step=None,\n                                     max_depth=9, min_child_weight=1,\n                                     monotone_constraints=None,\n                                     n_estimators=380, n_jobs=None, nthread=4,\n                                     num_parallel_tree=None, random_state=None,\n                                     reg_alpha=1e-10, reg_lambda=None,\n                                     scale_pos_weight=1, seed=10, subsample=0.8,\n                                     tree_method=None, validate_parameters=None,\n                                     verbosity=None)\n\nxgbsearch8.fit(X,y)\nxgb_pred_y =xgbsearch8.predict(test_Selected_feature_set_3_df)\nxgb_pred_y","8ab8e653":"%%time\n\nfrom sklearn.ensemble import RandomForestClassifier\npred_y=0\ny = chosen_set['ChargeOff']\nX = chosen_set.drop('ChargeOff',axis=1)\nrfsearch = RandomForestClassifier(min_samples_split=10, min_samples_leaf=1,bootstrap=True, criterion='gini')\n\nrfsearch.fit(X,y)\nrf_pred_y =rfsearch.predict(test_Selected_feature_set_3_df)\nrf_pred_y","9ea0d144":"#output gradient boosting predictions\noutput = pd.DataFrame(gb_pred_y)\noutput.columns = ['ChargeOff']\noutput['Id']=output.index\no = output[['Id','ChargeOff']]\no.index = output['Id']\no = o.drop('Id',axis=1)\no.to_csv('gradientboosting_pred_y_2.csv')","b211d8d0":"#output xgb predictions\noutput = pd.DataFrame(xgb_pred_y)\noutput.columns = ['ChargeOff']\noutput['Id']=output.index\no = output[['Id','ChargeOff']]\no.index = output['Id']\no = o.drop('Id',axis=1)\no.to_csv('xgb_pred_y_1.csv')","7ccd58ff":"#output random forest predictions\noutput = pd.DataFrame(rf_pred_y)\noutput.columns = ['ChargeOff']\noutput['Id']=output.index\no = output[['Id','ChargeOff']]\no.index = output['Id']\no = o.drop('Id',axis=1)\no.to_csv('randomforest_pred_y.csv')","64eeba5f":"# Gradient Boosting Parameter Tuning -> Final Tuning Step","92f7857a":"# Outputting the predictions","6f1e2f11":"# Feature Set 2 ","f1c846a3":"# Feature Selection","3b94248b":"# Racial Community from zipcode","a04f08d4":"# XGBoost Parameter Tuning -> Final Tuning Step","6902c788":"# Running Baseline Logistics Regression on our 3 datasets\n\n\n","a187acfa":"# Feature Set 1 (All One Hot Encode)","405c9e62":"# Support Vector Machine - Baseline","fa2636eb":"# Merging Numerical Features and Categorical Features to form the Full Feature Set","eebdd3c0":"# Naive Bayes - Baseline","c997c6cb":"# Data Cleaning","68d29c94":"# Exploratory Data Analaysis","2ec1c106":"# Running Prediction on the test set","9ad7835c":"# Feature Set 3","536a2abe":"# XGBoosting - Baseline","8234a988":"# Random Forest Parameter Tuning -> Final Tuning Step","2ea0da6f":"# Categorical Feature","a7a6c968":"# Processing the Test train set according to the Train set without dropping any rows","5bc460ef":"# Importing Data","5621d7dc":"# Gradient Boosting - Baseline","b65e0230":"# Random Forest","175208c1":"# Logistics Regression - Baseline"}}