{"cell_type":{"db470be7":"code","4eb568d5":"code","59c53a31":"code","fc751b1e":"code","2f388f04":"code","8e8cc736":"code","204433d8":"code","0f239555":"code","eb0cafb3":"code","ec93994d":"code","0300e8f3":"code","b8ce95a1":"code","6b9a804b":"code","04eea2a7":"code","5128ff6e":"code","41b098a1":"code","076ef9c5":"code","5df0cf3c":"code","08a007dc":"code","73e2b7f1":"code","e825c61a":"code","01de1618":"code","f84545bc":"code","8cbd6708":"code","62278aeb":"code","99ca4116":"code","eb6d516a":"code","2e7ff695":"code","bf1da402":"code","6ff2dbd4":"code","1af36717":"code","9f44a160":"code","2c9adeb0":"code","4bbfc3a9":"code","66f658d5":"code","fda2e550":"code","f6b8aa8d":"code","06500d94":"code","d0499066":"code","edadd12e":"code","87c6a565":"code","b716b924":"code","d2333804":"code","63f94f99":"code","cca0796d":"code","f6126670":"code","07c898f5":"code","4017ce36":"code","51d4f295":"code","a6626d4d":"code","3feae77a":"code","96c04a97":"code","e6b1ca99":"code","27c3b6a0":"code","f4ee8a9a":"code","a6d0e261":"markdown","66d88d6f":"markdown","1e9d30cb":"markdown","b15f379b":"markdown","3b686d44":"markdown","ae879201":"markdown","9f0be2bc":"markdown","fec0807a":"markdown","9e78c669":"markdown","6cc2f4d5":"markdown","a75ac1cd":"markdown","8fb116d6":"markdown","df1c5e0f":"markdown","5662d7e2":"markdown"},"source":{"db470be7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","4eb568d5":"df_train = pd.read_csv('..\/input\/neolen-house-price-prediction\/train.csv')\ndf_test = pd.read_csv('..\/input\/neolen-house-price-prediction\/test.csv')\ndf = pd.concat([df_train, df_test])\n","59c53a31":"df_train.describe()","fc751b1e":"#descriptive statistics summary for SalePrice\ndf_train['SalePrice'].describe()","2f388f04":"#SalePrice histogram\nsns.distplot(df_train['SalePrice'])","8e8cc736":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","204433d8":"#Finding the columns with more correlation with SalePrice\ndf_train.corr()['SalePrice'].sort_values(ascending = False)","0f239555":"#scatter plot of Above ground living area vs. saleprice\nvar = 'GrLivArea'\ndf_train.plot.scatter(x=var, y='SalePrice', ylim=(0,800000))\nprint(df_train['SalePrice'].corr(df_train[var]))","eb0cafb3":"#scatter plot of Above ground living area vs. saleprice\nvar = 'GarageArea'\ndf_train.plot.scatter(x=var, y='SalePrice', ylim=(0,800000))\nprint(df_train['SalePrice'].corr(df_train[var]))","ec93994d":"#scatter plot of Total square feet of basement area vs. saleprice\nvar = 'TotalBsmtSF'\ndf_train.plot.scatter(x=var, y='SalePrice', ylim=(0,800000))\nprint(df_train['SalePrice'].corr(df_train[var]))","0300e8f3":"#box plot of overallqual vs. saleprice\nvar = 'OverallQual'\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=df_train)\nfig.axis(ymin=0, ymax=800000)","b8ce95a1":"#box plot of year-built vs. saleprice\nvar = 'YearBuilt'\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=df_train)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);","6b9a804b":"def show_missing(df):\n    #Shows percentage of null values in each column\n    pd.options.display.max_rows = None\n    display(((df.isnull().sum()\/len(df))*100))","04eea2a7":"show_missing(df)","5128ff6e":"#DROP the columns which has more than 50% null values\ndf_train.drop(['Alley','MiscFeature','PoolQC','Fence','Id'],axis = 1, inplace = True)\ndf_test.drop(['Alley','MiscFeature','PoolQC','Fence', 'Id'],axis = 1, inplace = True)","41b098a1":"df = pd.concat([df_train, df_test])","076ef9c5":"#Finding numerical data column names\nnum_variables = [ i for i in df.columns if df.dtypes[i]!='object' ]","5df0cf3c":"num_variables","08a007dc":"df_train.corr()['SalePrice'].sort_values(ascending = False)","73e2b7f1":"#Get columns with correlation less than 0.1 for removing\nnum_del = [i for i in num_variables if df_train.corr()['SalePrice'][i] < 0.1]\nnum_del","e825c61a":"#Droping the columns and updating the changes in df \ndf_train.drop(num_del,axis = 1 ,  inplace = True)\ndf_test.drop(num_del,axis = 1 ,  inplace = True)\ndf = pd.concat([df_train, df_test])","01de1618":"show_missing(df)","f84545bc":"def impute_null(df):\n    cat_v=  [ i for i in df.columns if df.dtypes[i]=='object' if df[i].isnull().values.any()]\n    num_v = [ i for i in df.columns if df.dtypes[i]!='object' if df[i].isnull().values.any()]\n    for i in num_v:\n        df[i].fillna(df_train[i].median(), inplace =True)\n    for i in cat_v:\n        df[i].fillna(df_train[i].mode()[0], inplace =True)","8cbd6708":"impute_null(df_train)\nimpute_null(df_test)","62278aeb":"df = pd.concat([df_train, df_test])","99ca4116":"show_missing(df_train)","eb6d516a":"show_missing(df_test)","2e7ff695":"show_missing(df)","bf1da402":"cat_variables =  [ i for i in df.columns if df.dtypes[i]=='object' ]\ncat_variables","6ff2dbd4":"#Handling Ordinal categories using LabelEncoder \nord_dict = {\"LotShape\": ['Reg','IR1','IR2','IR3'],\n            \"LandSlope\" : [\"Gtl\", \"Mod\", \"Sev\" ],\n            \"ExterQual\": [  \"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\" ],\n            \"ExterCond\": [  \"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\" ],\n            \"BsmtQual\": [  \"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"NB\" ],\n            \"BsmtCond\":[  \"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"NB\" ],\n            \"BsmtExposure\": [\"Gd\", \"Av\", \"Mn\", \"No\", \"NB\"],\n            \"BsmtFinType1\":[ \"GLQ\",\"ALQ\",\"BLQ\",\"Rec\",\"LwQ\",\"Unf\",\"NB\"],\n            \"BsmtFinType2\":[ \"GLQ\",\"ALQ\",\"BLQ\",\"Rec\",\"LwQ\",\"Unf\",\"NB\"],\n            \"HeatingQC\": [  \"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\"],\n            \"KitchenQual\": [  \"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\"],\n            \"GarageQual\":[  \"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"NG\"],\n            \"GarageCond\": [  \"Ex\", \"Gd\", \"TA\", \"Fa\", \"Po\", \"NG\" ],\n            \"Utilities\":  ['AllPub','NoSeWa']\n        }\ncols_ord = ord_dict.keys()\nle = LabelEncoder()\n\nfor col in cols_ord:\n    le.fit(ord_dict[col])\n    df_train[col] = le.transform(df_train[col])\n    df_test[col] = le.transform(df_test[col])\n    ","1af36717":"df = pd.concat([df_train, df_test])\ndf.head()","9f44a160":"#Updating columnn names\ncat_variables =  [ i for i in df.columns if df.dtypes[i]=='object' ]\nnum_variables = [ i for i in df.columns if df.dtypes[i]!='object' ]","2c9adeb0":"df_train.describe()","4bbfc3a9":"train_copy = df_train.copy()\nq1 = df_train.quantile(0.25)\nq3 = df_train.quantile(0.75)\niqr = q3 - q1\ncutoff  = 3*iqr\ncols = df_train\nlower, upper = q1 - cutoff, q3+cutoff\n\ndef TotalOutliers(df, columns, l, u):\n    fin= {}\n    for i in columns:\n        a = df[df[i] > u[i]].shape[0]\n        b = df[df[i] < l[i]].shape[0]\n        fin[i] = a+b\n        a = 0\n        b = 0\n    \n    return fin\n        \noutliers = TotalOutliers(train_copy, num_variables, lower, upper)\n","66f658d5":"#Printing the number of outliers in each column.\noutliers","fda2e550":"#Droping columns which has more outliers \ndf_train.drop(['BsmtFinType2','ExterCond','BsmtCond','GarageQual','GarageCond','ScreenPorch'], axis = 1,inplace  =True)\ndf_test.drop(['BsmtFinType2','ExterCond','BsmtCond','GarageQual','GarageCond','ScreenPorch'], axis = 1, inplace  =True)\ndf = pd.concat([df_train, df_test])","f6b8aa8d":"# Log tranformation for SalePrice\ndf_train['SalePrice'] = np.log(df_train['SalePrice'])","06500d94":"sns.distplot(df_train['SalePrice'])","d0499066":"sns.distplot(df_train['GrLivArea'])","edadd12e":"df_train['GrLivArea'] = np.log(df_train['GrLivArea'])\ndf_test['GrLivArea'] = np.log(df_test['GrLivArea'])","87c6a565":"sns.distplot(df_train['GrLivArea'])","b716b924":"sns.distplot(df_train['TotalBsmtSF'])","d2333804":"df = pd.concat([df_train, df_test])","63f94f99":"dff = pd.get_dummies(df)","cca0796d":"df_tr = dff[dff['SalePrice'].isnull()==False]\ndf_te = dff[dff['SalePrice'].isnull()]","f6126670":"df_te.drop(['SalePrice'], axis = 1, inplace = True)\n","07c898f5":"model = LinearRegression()\n\n#Seperating training dataset into test and train for cross validation purpose\nx_train, x_test, y_train, y_test = train_test_split(df_tr.drop(['SalePrice'], axis = 1), df_tr['SalePrice'], test_size = 0.2, random_state = 0)","4017ce36":"model.fit(x_train, y_train)","51d4f295":"r_sq = model.score(x_train, y_train)\nprint('coefficient of determination:', r_sq)\n","a6626d4d":"y_pred = model.predict(x_test)","3feae77a":"print('Validation RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","96c04a97":"model.fit(df_tr.drop(['SalePrice'], axis = 1), df_tr['SalePrice'])\npredictions = model.predict(df_te)","e6b1ca99":"#Applying exponent for the predicted values because we have used log transformation\npredictions = np.expm1(predictions)","27c3b6a0":"predictions","f4ee8a9a":"#Submit the predictions\ndf_test = pd.read_csv('..\/input\/neolen-house-price-prediction\/test.csv')\nsample_submission= pd.DataFrame({'Id':np.asarray(df_test.Id), 'SalePrice':predictions})\nsample_submission.to_csv(\"submission.csv\", index=False)","a6d0e261":"**We conclude: 1- It deviates from the normal distribution. 2- It is right skewed (positive skewness).**","66d88d6f":"# Preprocessing\n**Goal: remove some columns which are not going to be usefull for our model and impute null values of the numerical and categorical variables with median and mode.**","1e9d30cb":"**SalePrice is related to overall quality, where the box plot shows how sales prices increase with the overall quality.**","b15f379b":"**We could conclude that more money is spent on new houses than on old ones.**","3b686d44":"**The SalePrice data is highly right skewed as the skewness > 1 and has heavy outliers(leptokurtic) as the kurtosis > 3**\n","ae879201":"# Linear Regression Model","9f0be2bc":"**From the correlation coefficient and the above graph we conclude that: there is a positive correlation between the above ground living area and the price so as the first increases the second increases accordingly.**","fec0807a":"### Imputing the missing values in all columns","9e78c669":"**One Hot Encoding for nominal features**","6cc2f4d5":"### Feature Encoding\n#### Label Encoding for ordinal features","a75ac1cd":"**From the correlation coefficient and the above graph we conclude that: there is a positive correlation between the total square feet of basement area and the price so as the first increases the second increases accordingly.**","8fb116d6":"### Handling Outliers\n#### The values which are outside the specified interquartile range are removed","df1c5e0f":"### Data Imputation","5662d7e2":"### Feature Transformation\n**Apply log transformation to transform some important features which contributes more to our model so that they can perform better. Data will be normally distributed which is good for the ML algorithm.**"}}