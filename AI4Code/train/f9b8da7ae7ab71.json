{"cell_type":{"928c1406":"code","25f1d49e":"code","ccd8f161":"code","e16a61ea":"code","10833ecd":"code","e7e3ecc6":"code","e4bc6302":"code","2172fcb5":"code","ed283ef0":"code","df9e6b46":"code","d51069e5":"code","7e74f0c7":"code","ef835538":"code","916c2c2e":"code","b53145f3":"code","d4823f78":"code","cbc8b6cc":"code","402ee668":"code","64886b56":"code","03cd120f":"code","72decd6f":"code","60f94cb1":"code","e9333499":"markdown","9ca654fc":"markdown","ba917a85":"markdown","aef2071c":"markdown","c49a56b5":"markdown","f6d56169":"markdown","a8eedd46":"markdown","03c0ea7d":"markdown","f7bc7942":"markdown","935580a4":"markdown","182cfd4a":"markdown","f8d40cb7":"markdown","f7bba6b3":"markdown","1a38f8f1":"markdown","f7f83d56":"markdown","45a97437":"markdown"},"source":{"928c1406":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","25f1d49e":"df = pd.read_csv(\"..\/input\/unsupervised-learning-on-country-data\/Country-data.csv\")","ccd8f161":"df.head()","e16a61ea":"X = np.array((df[['income', 'gdpp']]).astype(float))\nX.shape","10833ecd":"n = X.shape[1]\nfor j in range(n):\n    X[:, j] -= np.mean(X[:, j])\n    print(np.mean(X[:, j]))","e7e3ecc6":"k = 3\n(m, n) = X.shape\nmu = np.random.randint(1, 10, (k, n))\nprint(mu)","e4bc6302":"def find_closest_centroids(X, mu):\n    m = X.shape[0]\n    k = mu.shape[0]\n    c = np.zeros([m, 1])\n    distance = np.zeros([m, k])\n    for i in range(m):\n        for j in range(k):\n            distance[i, j] = np.sum((X[i, :] - mu[j, :])**2)\n        dist = list(distance[i, :])\n        c[i, 0] = dist.index(min(dist))\n    return c","2172fcb5":"c = find_closest_centroids(X, mu)\nprint(c[:5])","ed283ef0":"def compute_centroids(X, c, mu):\n    (k, n) = mu.shape\n    m = X.shape[0]\n    for i in range(k):\n        points = []\n        for j in range(m):\n            if c[j, 0] == i:\n                points.append(j)\n        for j in range(n):\n            mu[i, j] = np.mean(X[points, j])\n    return mu","df9e6b46":"compute_centroids(X, c, mu)","d51069e5":"def cost_function(X, mu, c):\n    m = X.shape[0]\n    J = 0\n    for i in range(m):\n        idx = int(c[i, 0])\n        J += np.sum((X[i, :] - mu[idx, :])**2)\n    return J \/ m","7e74f0c7":"k = 3\nmax_iters = 25\nnp.random.seed(0)\nmu = np.random.randint(1, 10, (k, n))\nfor i in range(max_iters):\n    idx = find_closest_centroids(X, mu)\n    centroids = compute_centroids(X, idx, mu)\n    plt.figure(figsize = (12, 8))\n    color = ['r', 'g', 'b']\n    mark = ['+', 'o', '*']\n    for i in range(k):\n        points = []\n        for j in range(m):\n            if idx[j, 0] == i:\n                points.append(j)\n        plt.scatter(X[points, 0], X[points, 1], c = color[i], marker = mark[i], s = 100)\n    plt.xlabel(\"Income\")\n    plt.ylabel(\"GDP\")","ef835538":"plt.figure(figsize = (12, 8))\ncolor = ['r', 'g', 'b']\nmark = ['+', 'o', '*']\nfor i in range(k):\n    points = []\n    for j in range(m):\n        if idx[j, 0] == i:\n            points.append(j)\n    plt.scatter(X[points, 0], X[points, 1], c = color[i], marker = mark[i], s = 100)\nplt.xlabel(\"Income\")\nplt.ylabel(\"GDP\")","916c2c2e":"cost_function(X, centroids, idx)","b53145f3":"k = 3\n(m, n) = X.shape\nindexes = []\ncosts = []\nfor i in range(100):\n    mu = np.random.randint(1, 10, (k, n))\n    idx = find_closest_centroids(X, mu)\n    if (0 not in idx) or (1 not in idx) or (2 not in idx):\n        pass\n        #print(\"something's missing\")\n    else:\n        centroids = compute_centroids(X, idx, mu)\n        J = cost_function(X, centroids, idx)\n        #print(J)\n        costs.append(J)\n        indexes.append(idx)\ni_min = costs.index(min(costs))\nbest_clusters = indexes[i_min]\nprint(f\"minimum cost: {costs[i_min]}\")\n\nplt.figure(figsize = (12, 8))\ncolor = ['r', 'g', 'b']\nmark = ['+', 'o', '*']\nfor i in range(k):\n    points = []\n    for j in range(m):\n        if best_clusters[j, 0] == i:\n            points.append(j)\n    plt.scatter(X[points, 0], X[points, 1], c = color[i], marker = mark[i], s = 100)\nplt.xlabel(\"Income\")\nplt.ylabel(\"GDP\")","d4823f78":"features = np.array(df.drop(['country'], axis = 1))\nprint(features.shape)","cbc8b6cc":"m = features.shape[0]\nsigma = np.dot(features.T, features) \/ m\nprint(sigma.shape)","402ee668":"u, s, v = np.linalg.svd(sigma)\nprint(u.shape, s.shape, v.shape)","64886b56":"dim = range(1, 9)\nvariance = []\nfor i in dim:\n    v = np.sum(s[:i]) \/ np.sum(s)\n    variance.append(v)\nprint(variance)","03cd120f":"d = 2\nu_reduce = u[:, 0:d]\nprint(u_reduce.shape)","72decd6f":"z = np.dot(features, u_reduce)\nprint(z.shape)","60f94cb1":"max_iters = 5\nk = 3\n(m, n) = z.shape\nnp.random.seed(0)\nmu = np.random.randn(k, n)\nfor i in range(max_iters):\n    idx = find_closest_centroids(z, mu)\n    centroids = compute_centroids(z, idx, mu)\n    plt.figure(figsize = (12, 8))\n    color = ['r', 'g', 'b']\n    mark = ['+', 'o', '*']\n    for i in range(k):\n        points = []\n        for j in range(m):\n            if idx[j, 0] == i:\n                points.append(j)\n        plt.scatter(z[points, 0], z[points, 1], c = color[i], marker = mark[i], s = 100)","e9333499":"**It can be easily observed that even after using 100 random samples, it cannot give a better result. Still the iteration method of finding best position for cluster centroids gives a better output with just 5 iterations.**\n\nHence our implementation of K-Means Clustering from Scratch works just fine.","9ca654fc":"# Mean Normalization","ba917a85":"# K-Means by Monte-Carlo Method","aef2071c":"## Applying K-Means Clustering","c49a56b5":"# Optimization Objective \/ Cost Function","f6d56169":"***For taking a suitable dimension for PCA variance retained should be greater than 0.99, which is we're getting for 2 dimension for columns of the data. Hence we can reduce the data upto 2D.***","a8eedd46":"# Prinicipal Component Analysis (PCA)","03c0ea7d":"Getting reduced dimension data with all training examples & the new features","f7bc7942":"# K-Means Clustering","935580a4":"# Compute Centroids","182cfd4a":"# Initializing Centroids","f8d40cb7":"## Iterations showing clusters imporoved by K-Means Algorithm after every iteration","f7bba6b3":"**As it can be observed from the last two plots that they are exactly same, hence concludes the K-Means Algorithm trying to find best clusters for the given data.**","1a38f8f1":"Well, no wonder the results are not good, because we only use PCA in case we do not get our desired results with the data. If we'll apply PCA to every problem unnecessarily, then it will end up getting worse, still the target of the implementation was to get understanding of how PCA works and how is it implemented & that is achieved.","f7f83d56":"# Finding Closest Centroids","45a97437":"## Final K-Means Plot"}}