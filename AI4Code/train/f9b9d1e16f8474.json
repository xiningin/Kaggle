{"cell_type":{"dae462ac":"code","371ab968":"code","e9c62123":"code","2e1ef490":"code","b76c1bb0":"code","9b2294cc":"code","f44a8835":"code","3b36b4b7":"code","cf84d994":"code","a140abca":"code","6792e381":"code","993ac6fa":"code","336d0433":"code","dd118e62":"markdown","68f92f72":"markdown","2bb3db0b":"markdown","cddd5d41":"markdown","b82559f3":"markdown","add3ad79":"markdown"},"source":{"dae462ac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","371ab968":"#Import dataset\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","e9c62123":"X_train = train_data[['Pclass', 'Sex', 'Age', 'SibSp','Parch']]\ny_train = train_data[['Survived']].values\ny_train = y_train.reshape(len(y_train),1)\nX_train","2e1ef490":"X_train = X_train.replace(\"male\",1)\nX_train = X_train.replace(\"female\",0)\nX_train\n","b76c1bb0":"X_train.isnull().sum()","9b2294cc":"from sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X_train.iloc[:, 2:3])\nX_train.iloc[:, 2:3] = imputer.transform(X_train.iloc[:, 2:3])\nprint(X_train)\n","f44a8835":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nX_test = test_data[['Pclass', 'Sex', 'Age', 'SibSp','Parch']]\ntest_data.head()","3b36b4b7":"X_test = X_test.replace(\"male\",1)\nX_test = X_test.replace(\"female\",0)\nX_test\n","cf84d994":"X_test.isnull().sum()","a140abca":"from sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(X_test.iloc[:, 2:3])\nX_test.iloc[:, 2:3] = imputer.transform(X_test.iloc[:, 2:3])\nprint(X_test)","6792e381":"# Feature Scaling\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Training the Random Forest Classification model on the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ny_pred\n","993ac6fa":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred})\noutput.to_csv('submission.csv', index=False)\noutput","336d0433":"print(\"Your submission was successfully saved!\")","dd118e62":"# **Random Forest**","68f92f72":"#Imputation transformer for completing missing values.\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nnumeric_features = ['Age', 'Fare']\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())])\n\ncategorical_features = ['Sex', 'Pclass']\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])\npreprocessor=preprocessor.fit(X_train)\nX_train = preprocessor.transform(X_train)\nX_train","2bb3db0b":"# **Import dataset**","cddd5d41":"# **Missing values**","b82559f3":"# **X and y**","add3ad79":"# Encoding categorical data\n# Encoding the Independent Variable\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\nX_train = np.array(ct.fit_transform(X_train))\nX_train"}}