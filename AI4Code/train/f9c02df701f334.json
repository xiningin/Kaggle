{"cell_type":{"a3a649f8":"code","f3c4f279":"code","53e8f340":"code","89b4962a":"code","2f096744":"code","5171eebe":"code","807f5ac0":"code","cedb81d3":"code","43ef08c6":"code","ed5f7969":"code","839930a8":"code","f032166b":"code","69a342fa":"code","18847582":"code","0e092b65":"code","3b9416ae":"code","22bcbab0":"code","842bcb26":"code","93218f78":"code","553280a6":"code","96d8bb57":"code","f554fcf6":"code","04303420":"code","3dba02ba":"code","4d715d3e":"markdown","36f190ad":"markdown","75e98b80":"markdown","d04a3ec7":"markdown"},"source":{"a3a649f8":"import warnings \nwarnings.filterwarnings(\"ignore\")\n\n# Base libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport re\nimport string\nimport math\nfrom IPython.display import display_html\nimport tqdm\nimport wandb\n\n\n## visualization libraries\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport matplotlib.patches as patches\nimport seaborn as sns\n!pip install pywaffle\nfrom pywaffle import Waffle\n\n%matplotlib inline\nsns.set(style=\"darkgrid\")\npd.set_option('display.float_format', lambda x: '%.2f' % x)","f3c4f279":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","53e8f340":"# read data\nsales_train = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nitems = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_categories = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ntest = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')","89b4962a":"#Let's start with merge of the datasets\nsales_train.head()","2f096744":"shops.head()","5171eebe":"items.head()","807f5ac0":"item_categories.head()","cedb81d3":"merge_1 = sales_train.merge(shops, on=\"shop_id\")\nmerge_2 = items.merge(item_categories, on=\"item_category_id\")\ndf = merge_1.merge(merge_2, on=\"item_id\")\ndf.head()\n\ndef eda(data):\n    print(\"----------Top-5 Records----------\")\n    print(data.head(5))\n    print(\"-----------Information-----------\")\n    print(data.info())\n    print(\"-----------Data Types-----------\")\n    print(data.dtypes)\n    print(\"----------Missing value-----------\")\n    print(data.isnull().sum())\n    print(\"----------Null value-----------\")\n    print(data.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(data.shape)\n    \neda(df)\n#train = sales.join(items, on='item_id', rsuffix='_').join(shops, on='shop_id', rsuffix='_').join(item_categories, on='item_category_id', rsuffix='_').drop(['item_id_', 'shop_id_', 'item_category_id_'], axis=1)","43ef08c6":"df.describe()","ed5f7969":"#We saw that there is a min of -1 on the price, let's see it\nprint(df[df[\"item_price\"] < 0])","839930a8":"df.shape","f032166b":"#Check for nulls or duplicates\ndf.isnull().any().sum()\ndf.duplicated().value_counts()","69a342fa":"df['date'] = pd.to_datetime(df['date'])","18847582":"print('Min date from train set: %s' % df['date'].min().date())\nprint('Max date from train set: %s' % df['date'].max().date())","0e092b65":"#Year where there were more sells\ndf.groupby([df['date'].apply(lambda x: x.strftime(format=\"%Y\"))])['item_cnt_day', 'item_price'].sum()","3b9416ae":"#Sells over the months\nplt.figure(figsize=(20,5))\nax = sns.countplot(x=\"date_block_num\", data=df, palette=\"husl\")\nplt.title(\"Count of Sales each month\")\nplt.show()","22bcbab0":"#Most sales in one day\ndf.groupby([df['date']])['item_cnt_day'].sum().sort_values(ascending=False)[:25]","842bcb26":"print(\"There are\", df['shop_id'].nunique(), \"unique shops.\")\nprint(\"There are\", df['item_id'].nunique(), \"unique items\")\nprint(\"There are\", df['item_category_id'].nunique(), \"unique items\")","93218f78":"plt.figure(figsize=(20,5))\nax = sns.countplot(x=\"shop_id\", data=df, palette=\"husl\")\nplt.title(\"Count of Sales on each Shop\")\nplt.show()","553280a6":"df['item_category_id'].value_counts()[:25]","96d8bb57":"df['item_id'].value_counts()[:25]","f554fcf6":"df['Revenues'] = df['item_cnt_day']*df['item_price']","04303420":"#Revenues by year\ndf.groupby([df['date'].apply(lambda x: x.strftime(format=\"%Y\"))])['Revenues'].sum()","3dba02ba":"#Revenues by month\ndf.groupby([df['date'].apply(lambda x: x.strftime(format=\"%B\"))])['Revenues'].sum().sort_values(ascending=False)","4d715d3e":"### Let's join the datasets\n","36f190ad":"### The task is to forecast the total amount of products sold in every shop for the test set.\n\nI'm going to use the numerical values only for my dataset;\nI have to transform the dataset to have only monthly data","75e98b80":"Questions:\n- Year that sold the most;\n- Sells over the months;\n- Shop that sells the most;\n- Item most sold;\n- Category most important;\n- Revenues for year, month","d04a3ec7":"### File descriptions\n- sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n- test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n- sample_submission.csv - a sample submission file in the correct format.\n- items.csv - supplemental information about the items\/products.\n- item_categories.csv  - supplemental information about the items categories.\n- shops.csv- supplemental information about the shops.\n### Data fields\n- ID - an Id that represents a (Shop, Item) tuple within the test set\n- shop_id - unique identifier of a shop\n- item_id - unique identifier of a product\n- item_category_id - unique identifier of item category\n- item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n- item_price - current price of an item\n- date - date in format dd\/mm\/yyyy\n- date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n- item_name - name of item\n- shop_name - name of shop\n- item_category_name - name of item category"}}