{"cell_type":{"9fb0ae0e":"code","fb7105e7":"code","39958b1d":"code","966c69ec":"code","c1e84302":"code","878dc85e":"code","e411ed89":"code","4937ff72":"code","12e15e06":"code","ac9c4609":"code","f617fc49":"code","e7e3065e":"code","8b8bda43":"code","627b6c80":"code","5f2068af":"code","5b42f3e2":"code","a7ef1d0e":"code","934318c7":"code","b3168f2b":"code","b75c98ea":"code","a91f0611":"code","a5ae6ab8":"code","2565fcf9":"code","7054aa13":"code","8306963c":"code","6c79d7ce":"code","1e82b087":"code","3e8f0b03":"code","56dbd47c":"code","05d6131a":"markdown","035432d0":"markdown","3d4660d0":"markdown","e14e0b26":"markdown","a413884d":"markdown"},"source":{"9fb0ae0e":"import pandas as pd\n\nimport numpy as np\n\nimport torch\n\nfrom collections import OrderedDict\n\nimport glob\nimport cv2\n\nimport matplotlib.pyplot as plt","fb7105e7":"labels = {'buildings':0,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}","39958b1d":"def get_train_data():\n    pq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/buildings\/*'):\n        mat = cv2.imread(i)\n        pq[''.join(i.split('\/')[-2:])] = mat\n\n    sq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/forest\/*'):\n        mat = cv2.imread(i)\n        sq[''.join(i.split('\/')[-2:])] = mat\n\n\n    rq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/glacier\/*'):\n        mat = cv2.imread(i)\n        rq[''.join(i.split('\/')[-2:])] = mat\n\n    qq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/mountain\/*'):\n        mat = cv2.imread(i)\n        qq[''.join(i.split('\/')[-2:])] = mat\n\n    aq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/sea\/*'):\n        mat = cv2.imread(i)\n        aq[''.join(i.split('\/')[-2:])] = mat\n\n    bq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/street\/*'):\n        mat = cv2.imread(i)\n        bq[''.join(i.split('\/')[-2:])] = mat\n    return pq, sq, rq, qq, aq, bq","966c69ec":"def get_test_data():\n    pq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_test\/seg_test\/buildings\/*'):\n        mat = cv2.imread(i)\n        pq[''.join(i.split('\/')[-2:])] = mat\n\n    sq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_test\/seg_test\/forest\/*'):\n        mat = cv2.imread(i)\n        sq[''.join(i.split('\/')[-2:])] = mat\n\n\n    rq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_test\/seg_test\/glacier\/*'):\n        mat = cv2.imread(i)\n        rq[''.join(i.split('\/')[-2:])] = mat\n\n    qq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_test\/seg_test\/mountain\/*'):\n        mat = cv2.imread(i)\n        qq[''.join(i.split('\/')[-2:])] = mat\n\n    aq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_test\/seg_test\/sea\/*'):\n        mat = cv2.imread(i)\n        aq[''.join(i.split('\/')[-2:])] = mat\n\n    bq = dict()\n    for i in glob.glob('..\/input\/intel-image-classification\/seg_test\/seg_test\/street\/*'):\n        mat = cv2.imread(i)\n        bq[''.join(i.split('\/')[-2:])] = mat\n    return pq, sq, rq, qq, aq, bq","c1e84302":"finalize = []","878dc85e":"def get_images(pq, sq, rq, qq, aq, bq):\n    finalize = []\n    for i,j,k,l,m,n in zip(pq.items(),sq.items(),rq.items(),qq.items(),aq.items(),bq.items()):\n        if 'buildings' in i[0]:\n            finalize.append((torch.FloatTensor(cv2.resize(i[1], (120,120))).permute((2,1,0)), labels['buildings']))\n        if 'forest' in j[0]:\n            finalize.append((torch.FloatTensor(cv2.resize(j[1], (120,120))).permute((2,1,0)), labels['forest']))\n        if 'glacier'in k[0]:\n            finalize.append((torch.FloatTensor(cv2.resize(k[1], (120,120))).permute((2,1,0)), labels['glacier']))\n        if 'mountain' in l[0]:\n            finalize.append((torch.FloatTensor(cv2.resize(l[1], (120,120))).permute((2,1,0)), labels['mountain']))\n        if 'sea' in m[0]:\n            finalize.append((torch.FloatTensor(cv2.resize(m[1], (120,120))).permute((2,1,0)), labels['sea']))\n        if 'street' in n[0]:\n            finalize.append((torch.FloatTensor(cv2.resize(n[1], (120,120))).permute((2,1,0)), labels['street']))\n    return finalize","e411ed89":"a, b, c, d, e, f = get_train_data()\ntrain_data = get_images(a, b, c, d, e, f)","4937ff72":"a, b, c, d, e, f = get_test_data()\ntest_ds = get_images(a, b, c, d, e, f)","12e15e06":"from sklearn.model_selection import train_test_split","ac9c4609":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim = 1)\n    return torch.tensor(torch.sum(preds == labels).item()\/len(preds))","f617fc49":"len(train_data)","e7e3065e":"class LogsModel(torch.nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.model = torch.nn.Sequential(\n            OrderedDict([\n                ('conv1', torch.nn.Conv2d(3, 32, kernel_size=2, padding=1, padding_mode='reflect')),\n                ('activation1', torch.nn.LeakyReLU()),\n                ('pool1', torch.nn.MaxPool2d(3, padding=1)),\n                ('activation12', torch.nn.LeakyReLU()),\n                ('conv2', torch.nn.Conv2d(32, 64, kernel_size=5, padding=1, padding_mode='reflect')),\n                ('activation2', torch.nn.LeakyReLU()),\n                ('pool2', torch.nn.MaxPool2d(2, padding=1)),\n                ('activation22', torch.nn.LeakyReLU()),\n                ('avg_pool1', torch.nn.AvgPool2d(2, padding=1)),\n                ('conv3', torch.nn.Conv2d(64, 128, kernel_size=2, padding=1, padding_mode='reflect')),\n                ('activation31', torch.nn.LeakyReLU()),\n                ('pool3', torch.nn.MaxPool2d(3, padding=1)),\n                ('activation33', torch.nn.LeakyReLU()),\n                ('conv4', torch.nn.Conv2d(128, 256, kernel_size=5, padding=1, padding_mode='reflect')),\n                ('activation32', torch.nn.LeakyReLU()),\n                ('pool4', torch.nn.MaxPool2d(2, padding=1)),\n                ('avg_pool12', torch.nn.AvgPool2d(2, padding=1)),\n                ('activation33', torch.nn.LeakyReLU()),\n                ('Dropout1', torch.nn.Dropout2d(p=0.4)),\n                ('flatten', torch.nn.Flatten()),\n                ('linear1', torch.nn.Linear(1024, 128)),\n                ('linear3', torch.nn.Linear(128, len(labels)))\n           ]) \n        )\n        \n    def forward(self, img):\n#         xb = img.reshape(-1, input_features)\n        preds = self.model(img)\n        return preds\n    \n    def train_epoch(self, batch):\n        images, preds = batch\n        out = self(images)\n        cross = torch.nn.CrossEntropyLoss()\n        loss = cross(out, preds)\n        return loss\n    \n    def val_step(self, batch):\n        images, preds = batch\n        out = self(images)\n        cross = torch.nn.CrossEntropyLoss()\n        loss = cross(out, preds)\n        acc = accuracy(out, preds)\n        return {\"val_loss\":loss, \"val_acc\":acc}\n    \n    def val_end(self, outputs):\n        val_acc = [x[\"val_acc\"] for x in outputs]\n        epoch_acc = torch.stack(val_acc).mean()\n        val_loss = [x[\"val_loss\"] for x in outputs]\n        epoch_loss = torch.stack(val_loss).mean()\n        return {\"val_loss\": epoch_loss.item(),\"val_acc\": epoch_acc.item()}\n    \n    def print_step(self, epoch, result, num_epochs):\n        print(\"Epoch [{}\/{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch+1, \n                                                                        num_epochs, \n                                                                        result['val_loss'], \n                                                                        result['val_acc']))","8b8bda43":"def evaluate(model, val_load):\n    model.eval()\n    result = [model.val_step(batch) for batch in val_load]\n    return model.val_end(result)","627b6c80":"def fit(epochs, lr, model, train_loader, val_load, opt_func= torch.optim.Adam):\n    history = []\n    opt = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        \n        for batch in train_loader:\n            model.train()\n            loss  = model.train_epoch(batch)\n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n\n        result = evaluate(model, val_load)\n        if (epoch +1) % 10 == 0:\n            model.print_step(epoch, result, epochs)\n        history.append(result)\n    return history","5f2068af":"train_ds_i, val_ds_i = torch.utils.data.random_split(train_data, [10955, 2191])","5b42f3e2":"train_loader_i = torch.utils.data.DataLoader(train_ds_i,shuffle=True, batch_size = 128, pin_memory=True, num_workers=8)\nval_loader_i = torch.utils.data.DataLoader(val_ds_i, shuffle=False, batch_size= 128, pin_memory=True, num_workers=8)\ntest_loader = torch.utils.data.DataLoader(test_ds, shuffle = True, batch_size = 64, pin_memory=True, num_workers=8)","a7ef1d0e":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","934318c7":"device = get_default_device()\ndevice","b3168f2b":"model = to_device(LogsModel(), device)\ntrain_loader_g = DeviceDataLoader(train_loader_i, device)\nval_loader_g = DeviceDataLoader(val_loader_i, device)","b75c98ea":"hist = []","a91f0611":"model(torch.unsqueeze(train_data[0][0], 0).cuda()).shape","a5ae6ab8":"hist+=fit(200, 0.00001, model, train_loader_g, val_loader_g)","2565fcf9":"plt.plot([x[\"val_acc\"] for x in hist],'-b')","7054aa13":"plt.plot([x[\"val_loss\"] for x in hist],'-k')","8306963c":"total  = 0\nfor x in hist:\n    total+=x[\"val_acc\"]","6c79d7ce":"total\/2.00","1e82b087":"test_loader = DeviceDataLoader(test_loader, device)","3e8f0b03":"test_acc = 0\ncounter = 0\nfor d1 in test_loader:\n    test_acc+=model.val_step(d1)[\"val_acc\"]\n    counter+=1","56dbd47c":"test_acc\/counter","05d6131a":"## Fitting manually with backprop using Adam Optimizer","035432d0":"## Next one I will be trying a 4 layer conv with max pooling ","3d4660d0":"## Accuracy of 81.433 % for version 1\n## Test accuracy of 84.21% for Version 1","e14e0b26":"## Pytorch on the Intel Classification","a413884d":"## Manual Evaluate"}}