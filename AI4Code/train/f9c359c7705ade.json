{"cell_type":{"124583b3":"code","6002e36e":"code","148e0943":"code","639c0bbb":"code","239d283e":"code","06ce448d":"code","5c68b6d6":"code","4655c2dc":"code","2c096d99":"code","acb87569":"code","e8527bed":"code","22089fce":"code","ea3f2384":"code","a3951c70":"code","ea1e1af6":"code","1c837892":"code","da405431":"code","33877c45":"code","0604601b":"code","b9cca33d":"code","7433923f":"code","1c00a935":"code","2da98242":"code","8763c147":"code","b7becdc5":"code","29b2343e":"code","70f4cc86":"code","1cba89e0":"code","7eff07c6":"code","543eea7e":"code","7c2f021d":"code","d470b4d9":"code","e41df645":"code","355cce98":"code","94d15570":"code","2e152829":"code","55cfceb3":"code","c735e333":"code","47c309b1":"code","734627ca":"code","b44ad26b":"code","1fb42fc6":"code","0fb69b97":"code","73a0802c":"code","b86bb97a":"code","0cfc20d7":"code","11861403":"code","1fa2663e":"code","f0389f14":"code","cddd2ea0":"code","54cfcefc":"code","1018e0a0":"code","77870f26":"code","b51a23c4":"code","f596034d":"code","1a4781ef":"code","f797bb78":"code","413ac4c8":"code","c2bcda52":"code","feb803ce":"code","5874a7ef":"code","a0f94ee0":"code","80560411":"code","0b50e26d":"code","b27456b2":"code","04d03789":"code","195c48ff":"code","b6bf276e":"code","a82831dd":"code","b39a7420":"code","9cf7d95a":"code","2b49b491":"code","12196230":"markdown","551e19f2":"markdown","b20e7601":"markdown","bb872c24":"markdown","6dcde617":"markdown","bc5947ad":"markdown","3a9370e2":"markdown","5bf8290a":"markdown","d22984ce":"markdown","a7486642":"markdown","e1997f0b":"markdown","48cdebf4":"markdown","fa8e2adf":"markdown","665259f3":"markdown","00bf8698":"markdown"},"source":{"124583b3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport warnings\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, log_loss","6002e36e":"%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\nplt.rcParams['figure.figsize'] = (10, 6)\npd.options.display.max_rows = 50\npd.options.display.max_columns = 100","148e0943":"def plot_categorical_feature_relation(data, feature, hue):\n    sns.barplot(data=data, x=hue, y=feature, orient='h', ci=None, ec='black')\n    plt.tight_layout()\n    plt.show()","639c0bbb":"def plot_numerical_feature_distribution(data, feature, target):\n    sns.distplot(data.loc[data[target]==0, feature].dropna(), kde=False, label='0')\n    sns.distplot(data.loc[data[target]==1, feature].dropna(), kde=False, label='1')\n    plt.legend(title=target, loc='best')\n    plt.ylabel('Frequency')\n    plt.tight_layout()\n    plt.show()","239d283e":"def get_title(data):\n    title_series = data['Name'].str.split('.').str[0].str.split(' ').str[-1]\n    title_series.loc[title_series=='Mme'] = 'Mrs'\n    title_series.loc[title_series.isin(['Mlle', 'Ms'])] = 'Miss'\n    title_series.loc[~(title_series.isin(['Mr', 'Master', 'Mrs', 'Miss']))] = 'Other'\n    title_series.name = 'Title'\n    return title_series.to_frame()","06ce448d":"def get_family_size(data):\n    family_size_series = (data['SibSp'] + data['Parch'] + 1)\n    family_size_series.name = 'FamilySize'\n    return family_size_series.to_frame()","5c68b6d6":"def get_is_alone(data):\n    return pd.DataFrame(np.where(data['SibSp']+data['Parch']==0, 1, 0), index=data.index, columns=['IsAlone'])","4655c2dc":"def mode(data):\n    return stats.mode(data)[0]","2c096d99":"def undersample(X_train, y_train):\n    sample_size = y_train.value_counts().min()\n    y_train_sampled = pd.concat([y_train[y_train==1].sample(sample_size, random_state=1),\n                                y_train[y_train==0].sample(sample_size, random_state=1)], axis=0)                                 \n    X_train_sampled = X_train.loc[y_train_sampled.index]\n    return X_train_sampled, y_train_sampled","acb87569":"def create_grid_search(est, p_grid, X_train, y_train, scr, refit, n=2):\n    cv = StratifiedKFold(n_splits=n, shuffle=True, random_state=1)  \n    return GridSearchCV(estimator=est, param_grid=p_grid, scoring=scr, n_jobs=4, cv=cv, verbose=0, refit=refit)","e8527bed":"def compute_nested_score(est, X_train, y_train, scr, n=5):\n    cv = StratifiedKFold(n_splits=n, shuffle=True, random_state=1)\n    \n    # undersampling\n    X_train_sampled, y_train_sampled = undersample(X_train, y_train)\n    \n    # scaling\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train_sampled.astype(float))\n    \n    nested_score = pd.DataFrame(cross_validate(est, X=X_train_scaled, y=y_train_sampled, cv=cv, n_jobs=4, scoring=scr, return_train_score=True))\n    return {'mean_score': nested_score.mean().to_dict(), 'std_score':nested_score.std().to_dict()}","22089fce":"def compare_models(est_dict, X_train, y_train, scr, n=5):\n    return {name: compute_nested_score(est, X_train, y_train, scr, n) for name, est in est_dict.items()}","ea3f2384":"train_raw = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', index_col='PassengerId')\ntest_raw = pd.read_csv('\/kaggle\/input\/titanic\/test.csv', index_col='PassengerId')","a3951c70":"print(train_raw.shape)\ntrain_raw.head()","ea1e1af6":"print(test_raw.shape)\ntest_raw.head()","1c837892":"target='Survived'","da405431":"# dtypes and number of non-null values in train data\ntrain_raw.info()","33877c45":"# dtypes and number of non-null values in test data\ntest_raw.info()","0604601b":" train_raw[target].value_counts()\/train_raw.shape[0]","b9cca33d":"# Upper class passengers are more likely to survive.\nplot_categorical_feature_relation(train_raw, 'Pclass', target)","7433923f":"# Female passengers are more likely to survive.\nplot_categorical_feature_relation(train_raw, 'Sex', target)","1c00a935":"# Passengers who embarked at Cherbourg are more likely to survive\nplot_categorical_feature_relation(train_raw, 'Embarked', target)","2da98242":"sns.pairplot(data=train_raw, vars=['Age', 'SibSp', 'Parch', 'Fare'], hue=target, diag_kind='kde', markers='.', \n             diag_kws={'linewidth':.5}, height=3)\nplt.tight_layout()\nplt.show()","8763c147":"# Some age groups are more likely to survive (e.g. Age<5).\n# Some age groups are less likely to survive (e.g. 15<Age<30).\nplot_numerical_feature_distribution(train_raw, 'Age', target)","b7becdc5":"# Passengers who do not have any siblings\/spouses are less likely to survive.\nplot_numerical_feature_distribution(train_raw, 'SibSp', target)","29b2343e":"# Passengers who do not have any parents\/childen are less likely to survive.\nplot_numerical_feature_distribution(train_raw, 'Parch', target)","70f4cc86":"# Passengers who pays less fare are less likely to survive\nplot_numerical_feature_distribution(train_raw, 'Fare', target)","1cba89e0":"train_titles = get_title(train_raw)\ntest_titles = get_title(test_raw)","7eff07c6":"train_family_size = get_family_size(train_raw)\ntest_family_size = get_family_size(test_raw)","543eea7e":"train_is_alone = get_is_alone(train_raw)\ntest_is_alone = get_is_alone(test_raw)","7c2f021d":"train = pd.concat([train_raw, train_titles, train_family_size, train_is_alone], axis=1)\ntest = pd.concat([test_raw, test_titles, test_family_size, test_is_alone], axis=1)","d470b4d9":"# Passengers with Mrs, Miss or Master titles are more likely to survive.\nplot_categorical_feature_relation(train, 'Title', target)","e41df645":"# Passengers who travel alone are more likely to survive\nplot_categorical_feature_relation(train, 'IsAlone', target)","355cce98":"# Passengers who have large families are less likely to survive\nplot_numerical_feature_distribution(train, 'FamilySize', target)","94d15570":"corr_matrix = train.corr()\nmasked_corr_matrix = corr_matrix.where(np.tril(np.ones(corr_matrix.shape), k=-1).astype(np.bool))\n\nplt.figure(figsize=(10,10))\nsns.heatmap(masked_corr_matrix, cmap='coolwarm', square=True, annot=True, annot_kws={'size':8}, fmt='.2f', cbar=False)\nplt.tight_layout()\nplt.show()","2e152829":"to_drop = ['Ticket', 'Cabin', 'Name', 'Parch', 'SibSp']","55cfceb3":"train = train.drop(to_drop, 1)\ntest = test.drop(to_drop, 1)","c735e333":"train.groupby('Pclass').agg({'Age':'mean'}).sort_values('Age', ascending=False)","47c309b1":"train.groupby('Sex').agg({'Age':'mean'}).sort_values('Age', ascending=False)","734627ca":"train.groupby('Title').agg({'Age':'mean'}).sort_values('Age', ascending=False)","b44ad26b":"train.groupby('Embarked').agg({'Age':'mean'}).sort_values('Age', ascending=False)","1fb42fc6":"train.groupby('IsAlone').agg({'Age':'mean'}).sort_values('Age', ascending=False)","0fb69b97":"train.groupby('Pclass').agg({'Fare':'mean'}).sort_values('Fare', ascending=False)","73a0802c":"train.groupby('Sex').agg({'Fare':'mean'}).sort_values('Fare', ascending=False)","b86bb97a":"train.groupby('Title').agg({'Fare':'mean'}).sort_values('Fare', ascending=False)","0cfc20d7":"train.groupby('Embarked').agg({'Fare':'mean'}).sort_values('Fare', ascending=False)","11861403":"train.groupby('IsAlone').agg({'Fare':'mean'}).sort_values('Fare', ascending=False)","1fa2663e":"train.groupby('Pclass').agg({'Embarked': mode})","f0389f14":"train.groupby('Sex').agg({'Embarked': mode})","cddd2ea0":"train.groupby('Title').agg({'Embarked': mode})","54cfcefc":"train.groupby('IsAlone').agg({'Embarked': mode})","1018e0a0":"# Filling null values in Age with mean Age per Title and Pclass in train data\nage_lookup = train.groupby(['Pclass', 'Title'], as_index=False).agg({'Age':'mean'})\n\ntrain_missing_age_values = pd.merge(train[train['Age'].isnull()][['Pclass', 'Title']], age_lookup, on=['Pclass','Title'], how='left')['Age'].tolist()\ntrain.loc[train['Age'].isnull(), 'Age'] = train_missing_age_values\n\ntest_missing_age_values = pd.merge(test[test['Age'].isnull()][['Pclass', 'Title']], age_lookup, on=['Pclass','Title'], how='left')['Age'].tolist()\ntest.loc[test['Age'].isnull(), 'Age'] = test_missing_age_values","77870f26":"# Filling null values in Fare with mean Fare per IsAlone, Pclass and Embarked in train data\nfare_lookup = train.groupby(['IsAlone', 'Pclass', 'Embarked'], as_index=False).agg({'Fare':'mean'})\n\ntest_missing_fare_values = pd.merge(test[test['Fare'].isnull()][['IsAlone', 'Pclass', 'Embarked']], fare_lookup, on=['IsAlone', 'Pclass', 'Embarked'], how='left')['Fare'].tolist()\ntest.loc[test['Fare'].isnull(), 'Fare'] = test_missing_fare_values","b51a23c4":"# Filling null values in Embarked with most common Embarked value in train data\ntest.loc[test['Embarked'].isnull(), 'Embarked'] = 'S'","f596034d":"train.head(5)","1a4781ef":"test.head(5)","f797bb78":"train = pd.get_dummies(train, drop_first=True)","413ac4c8":"test = pd.get_dummies(test, drop_first=True)","c2bcda52":"X_train = train.drop([target], 1)\ny_train = train[target]\nX_test = test","feb803ce":"X_train.shape","5874a7ef":"y_train.shape","a0f94ee0":"lr = LogisticRegression(solver='liblinear')\nrf = RandomForestClassifier(random_state=1, n_jobs=4)\ngb = GradientBoostingClassifier(random_state=1)\nknn = KNeighborsClassifier()\n\np_grid_lr = [{'penalty': ['l1', 'l2'], 'C': [.5, 1, 2]}]\np_grid_rf = [{'n_estimators': [50, 100, 200], 'min_samples_split': [2, 5, 10]}]\np_grid_gb = [{'n_estimators': [50, 100, 200], 'learning_rate':[.05, .1, .15], \n              'min_samples_split': [2, 5], 'max_depth': [3, 5, 10]}]\np_grid_knn = [{'n_neighbors' : [3, 5, 9]}]\n\np_grid_list = [p_grid_lr, p_grid_rf, p_grid_gb, p_grid_knn]\n\nest_names = ['LogisticRegression', 'RandomForest', 'GradientBoosting', 'KNearestNeighbours']\nest_list = [lr, rf, gb, knn]\nest_dict = dict(zip(est_names, est_list))\n\nscoring = {\"accuracy\": 'accuracy', 'precision': 'precision', 'recall': 'recall', 'roc_auc': 'roc_auc'} ","80560411":"# Estimator dictionary with tuned parameters\ngrid_search_dict = {name: create_grid_search(est, p_grid, X_train, y_train, scr='roc_auc', refit='roc_auc', n=2) for name, est, p_grid in zip(est_names, est_list, p_grid_list)}","0b50e26d":"# Comparison of estimators with tuned parameters\nresult = compare_models(grid_search_dict, X_train, y_train, scr=scoring, n=5)","b27456b2":"# Result of estimator comparison in terms of roc_auc\npd.concat({k: pd.DataFrame(v).unstack().to_frame().T for k, v in result.items()})","04d03789":"# Undersampling\nX_train_sampled, y_train_sampled = undersample(X_train, y_train)\n\n# Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_sampled.astype(float))\nX_test_scaled = scaler.transform(X_test.astype(float))","195c48ff":"best_algo = grid_search_dict['GradientBoosting']\nbest_algo.fit(X_train_scaled, y_train_sampled)\nbest_params = best_algo.best_params_","b6bf276e":"best_params","a82831dd":"train_accuracy = accuracy_score(y_train_sampled, best_algo.predict(X_train_scaled))\ntrain_precision = precision_score(y_train_sampled, best_algo.predict(X_train_scaled))\ntrain_recall = recall_score(y_train_sampled, best_algo.predict(X_train_scaled))\ntrain_roc_auc = roc_auc_score(y_train_sampled, best_algo.predict(X_train_scaled))","b39a7420":"print('Train accuracy is: {}'.format(train_accuracy))\nprint('Train precision is: {}'.format(train_precision))\nprint('Train recall is: {}'.format(train_recall))\nprint('Train roc-auc is: {}'.format(train_roc_auc))","9cf7d95a":"pd.Series(best_algo.best_estimator_.feature_importances_, index=X_train_sampled.columns).plot(kind='barh')\nplt.xlabel('FeatureImportance')\nplt.show()","2b49b491":"test_predictions = pd.DataFrame(best_algo.predict(X_test_scaled), index=X_test.index, columns=['Predictions'])\ntest_predictions.head()","12196230":"### Filling Null Values\nThere exists missing values in Age, Fare and Embarked fields. Distribution of those fields are examined with respect to other categorical variables like Pclass, Sex, Title etc. Using this distributions, lookup tables are created and missing values are filled.","551e19f2":"**Fare vs  Categorical Features:** Predictably IsAlone, Pclass and Embarked fields seem related with Fare field.","b20e7601":"### Reading Train and Test Datasets","bb872c24":"**Age vs Categorical Variables:** Pclass and Title fields are chosen. Sex field is not chosen as it is mostly represented in Title field.\n","6dcde617":"#### Parameter Optimization and Model Selection\n- Logistic regression, Random Forest, Gradient Boosting and KNN models are used in classification.\n- Parameter optimization and model comparison tasks performed with nested cross validation using grid search and stratified k fold cross validation. \n- In first step, parameters of each model are tuned and best estimator from each model is compared to each other.\n- Comparison metrics are accuracy, precision, recall and roc_auc.\n- During cross validation, undersampling is applied to data since the target variable has imbalanced distribution. Additionally, features are standardized.","bc5947ad":"### Creating New Features\nTitle, FamilySize and IsAlone features are created.","3a9370e2":"### Numerical Features vs Target\nDistribution of the feature is examined with respect to target variable's different values (1\/0)","5bf8290a":"### Prediction\n Gradient Boosting and Random Forest gave very similar results. Gradient Boosting is selected arbitrarily as best model. Best model is trained with all train data and test data is predicted.","d22984ce":"**Embarked vs Categorical Features:** Most common Embarked value in all categories is S.\n","a7486642":"### Target Variable Distribution\nTarget variable distribution is imbalanced.","e1997f0b":"### Exploratory Data Analytics","48cdebf4":"Dummy variables are created for categorical features. Pclass is intentionally treated as ordinal variable.","fa8e2adf":"### Functions","665259f3":"#### Correlation Heatmap","00bf8698":"### Categorical Features vs Target\nMean values of target variable is examined with respect to different values in categorical features.\nEmbarked and Sex are categorical features. Pclass is ordinal."}}