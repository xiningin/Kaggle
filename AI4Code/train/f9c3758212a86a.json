{"cell_type":{"4898c441":"code","92234f5f":"code","412f019f":"code","046141e3":"code","9f640aeb":"code","fdfe43d4":"code","bb86c799":"code","3b040ee9":"code","4c07c346":"code","8338eb22":"markdown","fba3eddd":"markdown","701289d4":"markdown","1ee0eaaf":"markdown"},"source":{"4898c441":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport gc\nimport datatable as dt\nimport math\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pyplot as plt","92234f5f":"df = dt.fread('..\/input\/jane-street-market-prediction\/train.csv').to_pandas()\nprint(df.shape)\n\nfeatures = [c for c in df.columns if 'feature' in c]","412f019f":"train = df[df['date'] <= 188]\ntest = df[df['date'] >= (500-188)]","046141e3":"param = {'num_leaves': 50,\n         'min_data_in_leaf': 30, \n         'objective':'binary',\n         'max_depth': 5,\n         'learning_rate': 0.2,\n         \"min_child_samples\": 20,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 44,\n         \"metric\": 'auc',\n         \"verbosity\": -1}","9f640aeb":"def covariate_shift(feature):\n    df_train = pd.DataFrame(data = {feature: train[feature], 'isTest':0})\n    df_test = pd.DataFrame(data = {feature: test[feature], 'isTest': 1})\n    \n    # Creating a single dataframe\n    df_merge = pd.concat([df_train, df_test], ignore_index=True)\n    \n    # Splitting it to a training and testing set\n    X_train, X_test, y_train, y_test = train_test_split(df_merge[feature], df_merge['isTest'].values, test_size=0.33,\n                                                        random_state=47, stratify=df_merge['isTest'].values)\n    # prepare data for lgb\n    train_ = lgb.Dataset(np.expand_dims(X_train,axis=-1), label=y_train)\n    \n    clf = lgb.train(param, train_, 50)\n    roc_auc =  roc_auc_score(y_test, clf.predict(np.expand_dims(X_test,axis=-1)))\n\n    del X_train, y_train, X_test, y_test\n    gc.collect();\n    \n    return roc_auc","fdfe43d4":"scores = []\nfor f in features:\n    score = covariate_shift(f)\n    scores.append(score)\n    print('{feature} : {score}'.format(feature = f, score = score))","bb86c799":"# normalise scores by looking at absolute difference from 0.5\nnorm_scores = [abs(x-0.5) for x in scores]","3b040ee9":"plt.figure(figsize=(20,10))\nplt.plot([*range(0,130)], norm_scores)\nplt.ylabel('Norm Scores')\nplt.xlabel('Feature');","4c07c346":"top_features = sorted(range(len(norm_scores)), key=lambda i: norm_scores[i], reverse=True)[:5]\nprint('Top Five Features with Highest Covariate Shifts:')\nfor x in top_features:\n    print('feature_{x} : {norm_score}'.format(x = x, norm_score = norm_scores[x]))","8338eb22":"ROC AUC score close to 0.5 --> the feature does not have any shift across the 6-month gap as the auxiliary model cannot distinguish the features values between first 188 and last 188 dates.","fba3eddd":"Lets look at the top five features with highest norm scores","701289d4":"We will normalise the ROC AUC scores across the features and create a plot for visualise inspection.","1ee0eaaf":"In my previous notebook [JS Adversarial Validation: Time Consistency](http:\/\/www.kaggle.com\/gerwynng\/js-adversarial-validation-time-consistency), i have explored a one-fit-size-all approach to test for time consistency. \n\nIn this notebook, i extended the analysis to look at **the individual features to see how they 'shift' across time.** Again, i will mimic the private leaderboard by creating a 6-month gap (~125 days) to see how consistent the features are across time. That is, we split the train data into two subsets:\n 1. first 188 days\n 2. last 188 days\n \n \nDoing so will give us more ideas on how each individual feature shift across time.\n\n\n[Reference kernel](https:\/\/www.kaggle.com\/nroman\/eda-for-cis-fraud-detection)\n"}}