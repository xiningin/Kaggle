{"cell_type":{"a186a711":"code","d5e3039d":"code","2da6f7a3":"code","b37142f7":"code","95d18381":"code","5447e81c":"code","72feeb98":"code","5af375a9":"code","592c4c1b":"code","edd57e3c":"code","b679d6aa":"code","63c9ef55":"code","8a8329eb":"code","4d45fc39":"code","185a9320":"code","bd377d62":"code","ac5a6af7":"code","b70fb04b":"code","d1b03f94":"code","98e41973":"code","c84f783b":"code","a5c5c1ef":"code","6348452c":"code","321ded93":"code","e433a5f7":"code","8c3a7186":"code","a1199deb":"code","e715f8e1":"code","ca3647a8":"markdown","7d050073":"markdown","33ea3d25":"markdown","72f6df36":"markdown","880b2a91":"markdown","52c529ea":"markdown","4ef6bc21":"markdown","e84f1d50":"markdown","bcde33ef":"markdown","d29b498e":"markdown","047b61f4":"markdown","2271e306":"markdown","1d376e4b":"markdown","5d9174e4":"markdown","fe0e5148":"markdown","dc185167":"markdown","6bcf7f65":"markdown","10cc268d":"markdown","8409d6f4":"markdown","4f4a4e35":"markdown","cf58ecc3":"markdown","f724d887":"markdown","ee7d827a":"markdown","17edd78a":"markdown","c27417d3":"markdown","1ad13bee":"markdown","45a43bf5":"markdown","13a0dd37":"markdown"},"source":{"a186a711":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d5e3039d":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\nsns.set()\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)","2da6f7a3":"data = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\ndata.head(3)","b37142f7":"# Dataset provider note\ndata = data.iloc[:,:-2]\n\n# Drop identity\ndata.drop('CLIENTNUM',axis=1, inplace=True)\ndata.head(3)","95d18381":"print('Input shape =',data.shape)","5447e81c":"data.info()","72feeb98":"cat_cols = data.select_dtypes(include='object')\nnum_cols = data.select_dtypes(exclude='object')","5af375a9":"# Categorical Columns\ncat_cols.head(3)","592c4c1b":"# Numerical Columns\nnum_cols.head(3)","edd57e3c":"loss = sns.color_palette(\"Paired\")[5]\nstill = sns.color_palette(\"Paired\")[1]","b679d6aa":"fig,axes = plt.subplots(1,6)\nfig.set_size_inches(23,6)\nj=0\nfor col in cat_cols.columns:\n    if col=='Attrition_Flag':\n        color='darkorange'\n    else:\n        color='mediumpurple'\n    sns.countplot(data=data, x=col, ax=axes[j], color=color)\n    axes[j].set_xticklabels( data[col].unique(), rotation=90)\n    axes[j].set_ylabel('')\n    axes[j].xaxis.set_label_coords(0.5,1.05)\n    j+=1\n\nplt.show()","63c9ef55":"fig, ax = plt.subplots(1,2)\nfig.set_size_inches(12,4)\nsns.countplot(data=cat_cols, x='Education_Level', hue='Marital_Status', ax=ax[0])\nax[0].tick_params(axis='x', labelrotation= 40.0)\nax[0].xaxis.set_label_coords(0.5,1.1)\nsns.countplot(data=cat_cols, hue='Education_Level', x='Marital_Status', ax=ax[1], hue_order=['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'])\nax[1].tick_params(axis='x', labelrotation= 40.0)\nax[1].xaxis.set_label_coords(0.5,1.1)\nplt.show()","8a8329eb":"fig, ax = plt.subplots(1,2)\nfig.set_size_inches(12,4)\n\nsns.countplot(ax=ax[0], data=cat_cols, x='Education_Level', hue='Income_Category', color='indigo',hue_order=['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])\nax[0].tick_params('x', labelrotation=30)\nax[0].xaxis.set_label_coords(0.5,1.1)\n\nsns.countplot(ax=ax[1], data=cat_cols, hue='Education_Level', x='Income_Category')\nax[1].set_xticklabels(['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'], Rotation= 30)\nax[1].xaxis.set_label_coords(0.5,1.1)\n\nplt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n\nplt.show()","4d45fc39":"fig, ax = plt.subplots(1,2)\nfig.set_size_inches(12,4)\nsns.countplot(data=cat_cols, x='Marital_Status', hue='Income_Category', ax=ax[0], color='indigo',hue_order=['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'])\nax[0].tick_params(axis='x', labelrotation= 40.0)\nax[0].xaxis.set_label_coords(0.5,1.1)\nsns.countplot(data=cat_cols, x='Income_Category', hue='Marital_Status', ax=ax[1])\nax[1].set_xticklabels(['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'], Rotation= 40)\nax[1].xaxis.set_label_coords(0.5,1.1)\nplt.show()","185a9320":"cat_cols.isnull().sum()","bd377d62":"for col in cat_cols.columns:\n    print('---------'+col+'---------')\n    print(cat_cols[col].value_counts())","ac5a6af7":"# Display the missing values\npd.Series(cat_cols.replace('Unknown', np.nan).isnull().sum()\/len(cat_cols)*100, name='Missing value').apply(lambda x:round(x,4)).apply(lambda x:str(x)+' %')","b70fb04b":"Edu_level = {'Uneducated':0, 'High School':1, 'College':2, 'Graduate':3, 'Post-Graduate':4, 'Doctorate':5, 'Unknown':15\/6}\nIncome_cat = {'Less than $40K':0, '$40K - $60K':1, '$60K - $80K':2, '$80K - $120K':3,  '$120K +':4, 'Unknown':10\/4}\nCard_cat = {'Blue':0, 'Silver':1, 'Gold':2, 'Platinum':3}\n\ndata_ordinal_encoded = data.copy()\ndata_ordinal_encoded['Education_Level'] = data_ordinal_encoded['Education_Level'].map(Edu_level)\ndata_ordinal_encoded['Income_Category'] = data_ordinal_encoded['Income_Category'].map(Income_cat)\ndata_ordinal_encoded['Card_Category'] = data_ordinal_encoded['Card_Category'].map(Card_cat)\ndata_ordinal_encoded.head(3)","d1b03f94":"num_cols.isnull().sum()","98e41973":"fig,ax=plt.subplots()\nfig.set_size_inches(10,10)\nsns.heatmap(data=num_cols.corr(), ax=ax, annot=True, fmt='.1f')\nplt.show()","c84f783b":"data_var = pd.DataFrame(data.var(), columns=['Var']).apply(lambda x:round(x,2))\ndata_var.style.background_gradient(sns.light_palette('green',as_cmap=True))","a5c5c1ef":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, plot_roc_curve","6348452c":"X = data_ordinal_encoded.drop('Attrition_Flag',axis=1)\nY = data_ordinal_encoded['Attrition_Flag']\n\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, stratify=Y)\n\nct = ColumnTransformer(\n    [(\"one hot encode\",OneHotEncoder(sparse=False),[1,4]),\n     (\"scale\", StandardScaler(), [e for e in range(len(X.columns)) if e not in {1,4}])],\n    remainder='passthrough')\nX_train = ct.fit_transform(X_train)\nX_test = ct.transform(X_test)\n\nle=LabelEncoder()\nY_train = le.fit_transform(Y_train)\nY_test = le.transform(Y_test)","321ded93":"rfe = RFE(estimator = RandomForestClassifier(), n_features_to_select=11, verbose=1)\nrfe.fit(X_train, Y_train)","e433a5f7":"X_train = X_train[:,rfe.support_]\nX_test = X_test[:,rfe.support_]","8c3a7186":"rf = RandomForestClassifier().fit(X_train, Y_train)","a1199deb":"y_pred = rf.predict(X_test)\n\nprint('Confusion matrix\\n',confusion_matrix(y_pred, Y_test))\nprint('\\nroc_auc_score\\n',roc_auc_score(Y_test, y_pred))\nprint('\\nClassification report\\n',classification_report(y_pred, Y_test))","e715f8e1":"plot_roc_curve(rf, X_test, Y_test)\nplt.show()","ca3647a8":"### Missing values","7d050073":"We don't see any missing value which is kinf of wierd. <br>","33ea3d25":"# 4) Feature selection, One-hot encoding, and Scaling","72f6df36":"# 3) Continuous columns","880b2a91":"### Mark color to each target <br>\n- loss : is a color for customer who move to other company (Churn).\n- still : is a color for customer who doesn't churn.","52c529ea":"We see that **Months_on_book** and **Customer_Age**  , **Total_Trans_Amt** and **Total_Trans_Ct** are highly linearly correlated.","4ef6bc21":"# 5) Building models","e84f1d50":"We see the exact same distribution of 'Education_Level' in 'Marital_Status', and vice-versa.","bcde33ef":"### Correlation","d29b498e":"We'll do ordinal encoding to 'Education_Level', 'Income_Category', and 'Card_Category' feature. For 'Unknown' category, we will replace it with average of order.","047b61f4":"Declare categorical, numerical columns.","2271e306":"# 2) Categorical columns","1d376e4b":"We see that Random Forest has done a very good job!!","5d9174e4":"## 2.1) Ordinal encoding, manually","fe0e5148":"Let's try looking into each value in each category.","dc185167":"We'll use Random Forest Classifier with its default parameter.","6bcf7f65":"Other categorical columns will be one-hot encoded in the later section. This means we consider 'Unknown' value in 'Marital_Status' as a new class.","10cc268d":"### Missing value","8409d6f4":"# 1) Import data","4f4a4e35":"### Pairwise scatterplot of continuous variables\nThe picture is in ..\\scatterplot\\\\.png","cf58ecc3":"### Variance.","f724d887":"### Distribution of each categorical column.","ee7d827a":"### Note: <br>\nLucklily we don't have a problem here.<br> \nFor small dataset, I recommend **fit the OneHotEncoder object to entire dataset** instead of X_train because ,after splitting the data, X_train sometimes might not contain all the unique values of all categories. If so, there will be a problem when trying to transform X_test since OneHotEncoder object doesn't know some values occured in X_test (but didn't occur in X_train that it fits).","17edd78a":"We will deal with cantinuous features using RFE(Recursive Feature Elimination) in the next section. <br>\nRecursive feature elimination (RFE) is a **feature selection** method that do \n1. fitting a model\n2. removes the weakest feature(s) by feature importance.<br>Features' importances are ranked by the model\u2019s **coef_** or **feature\\_importances\\_** attributes, and by recursively eliminating a small number of features per loop, RFE attempts to eliminate dependencies and collinearity that may exist in the model.\n3. repeat until the specified number of features is reached\n","c27417d3":"# Predict the test set","1ad13bee":"We see that missing values are denoted with 'unknown'. So, we have to replace 'unknown' with NaN.","45a43bf5":"## Feature Selected","13a0dd37":"We see the same distribution of 'Income' in all 'Education_Level', and vice-versa. <br>\nMost people have $<40K income in all types of 'Education_Level' even in 'Doctorate'. <br>\nIn all Income range, Graduate have the largest number."}}