{"cell_type":{"e452878a":"code","649b2f05":"code","1ac18dfd":"code","e3031ddf":"code","7cdb3a39":"code","80f7ca0b":"code","e694b334":"code","2d724037":"code","ce04565e":"code","f9839e5f":"code","855967c4":"code","fa7eb94a":"code","be788868":"code","174a3d20":"code","096fa622":"code","2e0941be":"code","66f58d99":"code","ad46fbe8":"code","ed83f087":"code","b5ab155f":"code","95e5b760":"code","2b87ca7c":"code","5c9602e9":"code","b6e0eac2":"code","249caf51":"code","88e261e0":"code","5dfd115a":"code","6981b1cb":"code","642ecff2":"code","d05162d0":"code","cd7239b4":"markdown","16e76a74":"markdown","eb3811eb":"markdown","d33581f2":"markdown","98e1ecf1":"markdown"},"source":{"e452878a":"!pip install py7zr","649b2f05":"################################### IMPORTS ###################################\n###\nimport numpy as np\nimport pandas as pd\nimport os\nimport copy\nimport matplotlib.pyplot as plt\n\n###\nfrom PIL import Image\n\n###\nimport torch\n# neural network modules, nn.Linear, nn.Conv2d, loss functions\nimport torch.nn as nn\n# activation functions\nimport torch.nn.functional as F\n# optimizers\nimport torch.optim as optim\n# transformations \nimport torchvision.transforms as transforms\n\nfrom torchvision import models\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset, Subset\n\n###\nfrom sklearn.model_selection import train_test_split\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n###\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n###\nfrom py7zr import unpack_7zarchive\nimport shutil\nshutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)","1ac18dfd":"################################# HYPERPARAMS #################################\n\nnum_epochs = 3\nbatch_size = 64\nlr = 0.01","e3031ddf":"############################# CUSTOM DATASET CLASS #############################\n\nclass CifarLoader(Dataset):\n  def __init__(self, root_dir, csv_file = None, transform = None):\n\n    # images directory \n    self.root_dir = root_dir\n    # transformations if any\n    self.transform = transform\n\n    if csv_file:\n      # read csv file\n      self.df = pd.read_csv(csv_file)\n\n      # {class: lbl}\n      self.annot_dict = {}\n\n      for i, lbl in enumerate(self.df['label'].unique()):\n        self.annot_dict[lbl] = i\n\n      # {lbl: class}\n      self.annot_dict_reversed = {v:k for k,v in self.annot_dict.items()}\n\n      # add a column with decoded labels\n      self.df['encoded'] = self.df['label'].map(self.annot_dict)\n\n    else: \n      # if no csv file provided -> create a df, fill labels with 0's\n      self.df = pd.DataFrame({\n          'id': list(range(1, len(os.listdir(self.root_dir)) + 1)),\n          'label': np.zeros(len(os.listdir(self.root_dir))),\n          'encoded': np.zeros(len(os.listdir(self.root_dir)))\n      })\n\n\n  def __len__(self):\n    # num of records in the df\n    return len(self.df)\n\n  def __getitem__(self, index):\n    # path to the image\n    img_path = os.path.join(self.root_dir, str(self.df.iloc[index, 0]) + '.png')\n    # read image\n    image = np.array(Image.open(img_path).convert('RGB'))\n    # get label\n    y_label = torch.tensor(int(self.df.iloc[index, 2]))\n\n    # apply transformations\n    if self.transform:\n      image = self.transform(image)\n    \n    return (image, y_label)\n","7cdb3a39":"# transform tensors to normalized range form [0, 1] to [-1, 1]\nmean = np.array([0.5, 0.5, 0.5])\nstd = np.array([0.5, 0.5, 0.5])\n\ntr = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),  \n        transforms.ToTensor(),        \n        transforms.Normalize(mean, std)\n    ])","80f7ca0b":"# unzip train and test data\nshutil.unpack_archive('..\/input\/cifar-10\/train.7z')\nshutil.unpack_archive('..\/input\/cifar-10\/test.7z')","e694b334":"dataset = CifarLoader(csv_file = '..\/input\/cifar-10\/trainLabels.csv', \n                      root_dir = '.\/train',\n                      transform = tr)\n\nprint(dataset.df.head())","2d724037":"############################### SPLIT THE DATA #################################\n\nindexes = list(range(len(dataset)))\n\ntrain_indexes, val_indexes = train_test_split(indexes, test_size=0.2)\n\ndata = {}\ndata['train'] = Subset(dataset, train_indexes)\ndata['val'] = Subset(dataset, val_indexes)\n\ndataloader_train = DataLoader(dataset = data['train'], batch_size = batch_size, shuffle=False)\ndataloader_val = DataLoader(dataset = data['val'], batch_size = batch_size, shuffle=False)","ce04565e":"print(len(train_indexes), len(val_indexes))","f9839e5f":"################################ SHOW IMAGES ##################################\n\ndef images_show(images, lbls=None):\n  # show only 4 first images from each batch\n  for i in range(4):\n    plt.subplot(1, 4, i + 1)\n    # convert to numpy\n    img = images[i].numpy().transpose((1, 2, 0))\n    # unnormalize\n    img = img * std + mean \n    img = np.clip(img, a_min=0, a_max=1)\n    plt.imshow(img)\n \n    if lbls != None:\n      # decode labels using reversed annotation dictionary\n      plt.title(dataset.annot_dict_reversed[lbls[i].item()])\n    plt.axis('off')\n  plt.tight_layout(pad=0.5)\n  plt.show()","855967c4":"dataiter = iter(dataloader_train)\nimages, labels = dataiter.next()\n\nprint(f'Shape: {images.shape}')\nprint(f'Max: {torch.max(images[0]):.2f}')\nprint(f'Min: {torch.min(images[0]):.2f}')\n\nfor i in range(3):\n  images, labels = dataiter.next()\n  images_show(images, labels)","fa7eb94a":"################################ FINETUNING ##################################\n\n# Load a pretrained model and reset final fully connected layer\n\n# load a pretrained model \nmodel = models.densenet121(pretrained=True)\n\n# reset final fully connected layer\nnum_ftrs = model.classifier.in_features\n\nmodel.classifier = nn.Sequential(\n                        nn.Linear(num_ftrs, 256),  \n                        nn.ReLU(), \n                        nn.Dropout(0.3),\n                        nn.Linear(256, 10))\n\n# copy weights for futher retraining on full train dataset\nmodel_wts = copy.deepcopy(model.state_dict())\n\n# move model to a device\nmodel = model.to(device)\n\n# loss\ncriterion = nn.CrossEntropyLoss()\n\n# all parameters are being optimized\noptimizer = optim.SGD(model.parameters(), lr=lr)","be788868":"################################ TRAINING FUNC ################################\n\ndef train(model, criterion, optimizer, num_epochs, \n          dataloader_train, dataloader_val = None):\n\n  history = {\n        'loss': [],\n        'accuracy': [],\n        'val_loss': [],\n        'val_accuracy': [],\n        'best train acc': (0, 0)\n        }\n\n  best_model_wts = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n\n\n  for epoch in range(num_epochs):\n    print('Epoch {}\/{}'.format(epoch + 1, num_epochs))\n\n    # set model to the training mode\n    model.train()\n\n    n_samples = 0\n    correct_train = 0\n    epoch_loss_train = 0\n    epoch_loss_val = 0\n\n\n    for i, (images, labels) in enumerate(dataloader_train):\n      # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n    \n      images = images.to(device)\n      labels = labels.to(device)\n\n      # forward pass (pred)\n      pred = model(images)\n\n      # loss\n      loss = criterion(pred, labels)\n\n      # mean loss * num samples in batch\n      epoch_loss_train += labels.shape[0] * loss.item()\n\n      # empty gradients\n      optimizer.zero_grad()\n\n      # gradient (backpropagation)\n      loss.backward()\n\n      # update weights\n      optimizer.step()\n\n      # values, indexes\n      value, predicted = torch.max(pred, 1)\n\n      # += batch_size\n      n_samples += labels.shape[0]\n      # num of correctly predicted in this batch\n      correct_train += (predicted==labels).sum().item()\n\n    # train acc per epoch\n    train_acc = 100 * correct_train \/ n_samples\n    # train loss per epoch\n    epoch_loss_train = epoch_loss_train \/ n_samples\n\n    print(f'Train accuracy: {train_acc:.2f}, loss: {epoch_loss_train:.2f}')\n    #print(f'Best accuracy: {best_acc:.2f}')\n\n    history['accuracy'].append(train_acc)\n    history['loss'].append(epoch_loss_train)\n\n    # find best accuracy on training data\n    if train_acc > best_acc:\n\n      #print('*New best accuracy*')\n      best_acc = train_acc\n\n      # copy current model weights\n      best_model_wts = copy.deepcopy(model.state_dict())\n      history['best train acc'] = (epoch, best_acc)\n\n\n\n    if dataloader_val:\n\n      # evaluation mode\n      model.eval()\n\n      with torch.no_grad():\n        correct_val = 0\n        n_samples = 0\n\n        for images, labels in dataloader_val: \n          images = images.to(device)\n          labels = labels.to(device)\n\n          outputs = model(images)\n\n          loss = criterion(outputs, labels)\n          epoch_loss_val += labels.shape[0] * loss.item()\n\n          # value, index\n          _, pred = torch.max(outputs, 1)\n          n_samples += labels.shape[0]\n          correct_val += (pred==labels).sum().item()\n\n        # calculate validation accuracy and loss for each epoch\n        val_acc = 100 * correct_val \/ len(data['val'])\n        epoch_loss_val = epoch_loss_val \/ len(data['val'])\n\n        print(f'Val accuracy: {val_acc:.2f}, loss: {epoch_loss_val:.2f}')\n\n        history['val_accuracy'].append(val_acc)\n        history['val_loss'].append(epoch_loss_val)\n      \n    print('=' * 80)\n\n\n  print('Best train acc: {:2f}'.format(best_acc))\n\n  # load best weights\n  model.load_state_dict(best_model_wts)\n\n  return model, history","174a3d20":"model, history = train(model, criterion, optimizer, num_epochs, \n                       dataloader_train, dataloader_val)","096fa622":"def plot_history(history):\n   \n    loss = history['loss']\n    accuracy = history['accuracy']\n    val_loss = history['val_loss']\n    val_accuracy = history['val_accuracy']\n    x = range(len(loss))\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(x, accuracy, label='Training acc', color='#03045e', linewidth=2)\n    if len(val_loss) != 0:\n      plt.plot(x, val_accuracy, label='Validation acc', color='#48cae4', linewidth=2)\n    plt.plot(history['best train acc'][0], \n             history['best train acc'][1], \n             'bo', label='Best train acc', markersize=7, color='black')\n    plt.title('Accuracy')\n    plt.grid(True)\n    plt.legend()\n    \n    \n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, label='Training loss', color='#03045e', linewidth=2)\n    if len(val_loss) != 0:\n      plt.plot(x, val_loss, label='Validation loss', color='#48cae4', linewidth=2)\n    plt.title('Loss')\n    plt.grid(True)\n    plt.legend()","2e0941be":"plot_history(history)","66f58d99":"################################## EVALUATE ##################################\ndef evaluate(model, dataloader):\n\n  with torch.no_grad():\n    model.eval()\n    n_correct = 0\n    n_samples = 0\n\n    for images, labels in dataloader: \n      images = images.to(device)\n      labels = labels.to(device)\n\n      outputs = model(images)\n\n      # value, index\n      v, pred = torch.max(outputs, 1)\n\n      n_samples += labels.shape[0]\n      n_correct += (pred==labels).sum().item()\n\n    acc = 100.0 * n_correct \/ n_samples\n    print(acc)","ad46fbe8":"evaluate(model, dataloader_val)","ed83f087":"############################## COMPLETE DATASET ###############################\n\ndataloader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle=False)","b5ab155f":"dataset_test = CifarLoader(root_dir = '.\/test',\n                      transform = tr)\n\ndataloader_test = DataLoader(dataset = dataset_test, \n                             batch_size = batch_size, shuffle=False)","95e5b760":"################################# RESET MODEL ##################################\n\nmodel.load_state_dict(model_wts)\n\n# loss\ncriterion = nn.CrossEntropyLoss()\n\n# all parameters are being optimized\noptimizer = optim.SGD(model.parameters(), lr=lr)","2b87ca7c":"model, history = train(model, criterion, optimizer, 3, dataloader)","5c9602e9":"print(len(dataset_test))","b6e0eac2":"################################### PREDICT ####################################\n\npredictions = np.array([])\n\nwith torch.no_grad():\n    model.eval()\n\n    for images, _ in dataloader_test:\n      images = images.to(device)\n\n      outputs = model(images)\n\n      # value, index\n      v, pred = torch.max(outputs, 1)\n\n      pred = pred.cpu().numpy()\n\n      predictions = np.concatenate((predictions, pred), axis = None)","249caf51":"dataset_test.df['encoded'] = predictions.astype(int)","88e261e0":"dataset_test.df['label'] = dataset_test.df['encoded'].map(dataset.annot_dict_reversed)","5dfd115a":"dataset_test.df.head()","6981b1cb":"dataiter = iter(dataloader_test)\nimages, labels = dataiter.next()\n\nfor i in range(3):\n  images, labels = dataiter.next()\n  images_show(images, labels)","642ecff2":"dataset_test.df.drop(columns ='encoded', inplace=True)\ndataset_test.df.to_csv('submission.csv', index=False)","d05162d0":"%rm -rf .\/train\n%rm -rf .\/test","cd7239b4":"Retrain model on full training set.","16e76a74":"Load pretrained DenseNet-121.","eb3811eb":"Load data.","d33581f2":"Submission file:","98e1ecf1":"Imports & installs."}}