{"cell_type":{"92220a57":"code","84e7e8a7":"code","df0e42c4":"code","32fd62cd":"code","fb4c3235":"code","f4cfa494":"code","d02ec9a2":"code","a9d17214":"code","70e9a648":"code","97179d07":"code","8d03c9dc":"code","c4cdde94":"code","1dcac823":"code","1715c1d8":"code","9e4e5b9f":"code","baa57f1c":"code","d62c5376":"code","33b6fee5":"code","81f0337b":"code","1f46ce98":"code","e4ca92b8":"code","a2e8b08e":"code","1a3e3a20":"code","f17ec346":"code","ae5dea7c":"code","476fa006":"code","53b32260":"code","a2b0536c":"code","1b071e2e":"code","ae4b5de2":"code","b843006a":"code","c4c2ede6":"code","d1c81bee":"markdown","5fbeb403":"markdown","398d3bf0":"markdown","7e97208a":"markdown"},"source":{"92220a57":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","84e7e8a7":"from mlxtend.classifier import StackingClassifier","df0e42c4":"import pandas as pd\nimport numpy as np\nimport scipy as sp\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nimport re","32fd62cd":"from sklearn.cross_validation import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom sklearn.cross_validation import StratifiedShuffleSplit\nfrom sklearn.metrics.pairwise import manhattan_distances\nfrom sklearn.naive_bayes import MultinomialNB, GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn import svm, grid_search, datasets\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics","fb4c3235":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer","f4cfa494":"train = pd.read_csv('..\/input\/train.tsv',sep = '\\t')\ntest = pd.read_csv('..\/input\/test.tsv',sep = '\\t')\nsub = pd.read_csv('..\/input\/sampleSubmission.csv' , sep = ',')","d02ec9a2":"test['Sentiment'] = -12345\ntrain_test = pd.concat([train,test],ignore_index=True)\ntrain_test['clean_phrase'] = train_test['Phrase'].map(lambda x: re.sub('[^a-zA-Z]',' ',x))\ntrain_test['clean_phrase'] = train_test['Phrase'].map(lambda x: x.lower())\ntrain_clean = train_test[train_test.Sentiment != -12345]\ntest_clean = train_test[train_test.Sentiment == -12345]\ntest_clean.drop(['Sentiment'], axis=1, inplace=True)\nprint(train_clean.shape)\nprint(test_clean.shape)","a9d17214":"train_clean.head()","70e9a648":"test_clean.head()","97179d07":"y_train = train_clean.Sentiment.values\nX_train_clean = train_clean.clean_phrase.values","8d03c9dc":"print (\"y_train\" + str(y_train.shape))\nprint (\"X_train_clean\"  + str(X_train_clean.shape))","c4cdde94":"vect = TfidfVectorizer(ngram_range=(1,3))","1dcac823":"X_tfidf = vect.fit_transform(X_train_clean) # Using original phrase\nX_tfidf.shape","1715c1d8":"from sklearn.model_selection import train_test_split\nX_train , X_test, y_train , y_test = train_test_split(X_tfidf,y_train,test_size = 0.2)","9e4e5b9f":"clf1 = MultinomialNB()\nclf2 = LinearSVC(multi_class='ovr')\n#clf3 = AdaBoostClassifier(n_estimators = 30)\nlr = LogisticRegression()\nsclf = StackingClassifier(classifiers=[clf1, clf2], meta_classifier=lr)","baa57f1c":"%%time\nsclf.fit(X_train,y_train)\nstacked_clf = sclf.predict(X_test)","d62c5376":"print (\"Accuracy for Stacking 1 :\" + str(metrics.accuracy_score(y_test, stacked_clf)))","33b6fee5":"clf1 = MultinomialNB()\nclf2 = LinearSVC(multi_class='ovr')\nclf3 = AdaBoostClassifier(n_estimators = 30)\nlr = LogisticRegression()\nsclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)","81f0337b":"%%time\nsclf.fit(X_train,y_train)\nstacked_clf = sclf.predict(X_test)","1f46ce98":"print (\"Accuracy for Stacking 2:\" + str(metrics.accuracy_score(y_test, stacked_clf)))","e4ca92b8":"clf1 = LogisticRegression()\nclf2 = LinearSVC(multi_class='ovr')\nclf3 = AdaBoostClassifier(n_estimators = 30)\nnb = MultinomialNB()\nsclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=nb)","a2e8b08e":"%%time\nsclf.fit(X_train,y_train)\nstacked_clf = sclf.predict(X_test)","1a3e3a20":"print (\"Accuracy for Stacking 3:\" + str(metrics.accuracy_score(y_test, stacked_clf)))","f17ec346":"clf1 = MultinomialNB()\nclf2 = LinearSVC(multi_class='ovr')\nclf3 = AdaBoostClassifier()\nlr = LogisticRegression()\nsclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)","ae5dea7c":"%%time\nsclf.fit(X_train,y_train)\nstacked_clf = sclf.predict(X_test)","476fa006":"print (\"Accuracy for Stacking 4:\" + str(metrics.accuracy_score(y_test, stacked_clf)))","53b32260":"%%time\ngbc = GradientBoostingClassifier()\ngbc.fit(X_train,y_train)\ny_pred_gbc = gbc.predict(X_test)","a2b0536c":"print (\"Accuracy for GBC:\" + str(metrics.accuracy_score(y_test, y_pred_gbc)))","1b071e2e":"%%time\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred_rf = rf.predict(X_test)","ae4b5de2":"print (\"Accuracy for RF:\" + str(metrics.accuracy_score(y_test, y_pred_rf)))","b843006a":"%%time\nknn = KNeighborsClassifier()\nknn.fit(X_train,y_train)\ny_pred_knn = knn.predict(X_test)","c4c2ede6":"print (\"Accuracy for RF:\" + str(metrics.accuracy_score(y_test, y_pred_knn)))","d1c81bee":"We will further explore this by using our top 4 classifiers and varying meta-classifiers between NaiveBayes and Logistics Regression to explore changes.","5fbeb403":"Using NB(Multinomial) and Linear SVC as our classifier and Logistic Regression as our meta-classifier has produced the above accuracy; which produced lower accuracy than using Linear SVC alone but higher accuracy compared to our previous ensembles.","398d3bf0":"Testing other ML","7e97208a":"Running the stacking algorithm again but removing the AdaBoost limit"}}