{"cell_type":{"934146b2":"code","971d9c1a":"code","bd8cddb3":"code","116be5a4":"code","82c29d50":"code","07e8b941":"code","0f99f47e":"code","c836e031":"code","95b12cd7":"code","d660fe9f":"code","8b4033bf":"code","de59b6cb":"code","afba7f03":"code","a9485b52":"code","26f682dd":"code","da0d4eea":"code","72e347df":"code","deabf40f":"code","117b29a4":"code","5a619560":"code","fc58a828":"code","4470a082":"code","14e532c8":"code","ce6e52eb":"code","5260066f":"code","34cc5114":"code","d4b63366":"code","8aa1d010":"code","b51fe105":"code","8b0ff84b":"code","98e04ac2":"code","119ecb2b":"code","ca22c672":"code","cbd7023b":"code","6d4f6711":"code","49c2afb7":"code","b22fb164":"code","afe13910":"code","f6b843fd":"code","9a9621ea":"code","8151d17b":"code","d8c6e507":"code","05b1fd17":"code","f1f229bb":"code","3cf8d27d":"code","b9b97000":"markdown","12c8c810":"markdown","6f5f7993":"markdown","5eb7ccea":"markdown","1f96b0be":"markdown","9cf9a44d":"markdown","15bebe92":"markdown","a0be566c":"markdown","e581a23d":"markdown","40ea8630":"markdown","1a9f0acf":"markdown","e335ecfe":"markdown","ae1aa6c9":"markdown","686d867a":"markdown","380dbb9e":"markdown","7c89d146":"markdown","eccdf765":"markdown","3950221d":"markdown","bd5f96bd":"markdown","23f502e3":"markdown","3c63604e":"markdown","06f39ce4":"markdown","484f8860":"markdown","419a4301":"markdown","c4c77954":"markdown","2774ed24":"markdown","db08f44a":"markdown","0966b099":"markdown","1768e561":"markdown","121b5e40":"markdown","7b5528d0":"markdown","e776d0ba":"markdown","c888f56c":"markdown","95fff4d9":"markdown","91be5ec8":"markdown","4879d2fd":"markdown","7badd367":"markdown","99aebc22":"markdown","4352e0d6":"markdown","bb4df00d":"markdown","a907f168":"markdown","d2849ddc":"markdown","0d239981":"markdown","bb9ebfcb":"markdown","5b78db66":"markdown","ff3a0a64":"markdown","923f174e":"markdown","c86843f5":"markdown","29a8484d":"markdown","3309afc0":"markdown","0c9e26d3":"markdown","4760eab5":"markdown","dc32f488":"markdown","4b7dd59d":"markdown","d390839d":"markdown","3777abdd":"markdown","2821d22f":"markdown","51c7ca49":"markdown","34180f38":"markdown","359fc480":"markdown","1a2cd352":"markdown","f20a143e":"markdown"},"source":{"934146b2":"%%javascript\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n\n","971d9c1a":"# import the necessary libraries\nfrom IPython.display import display, HTML\nimport numpy as np \nimport pandas as pd \nfrom datetime import datetime\nimport itertools\nimport collections\nfrom wordcloud import WordCloud\n\n# Visualisation libraries\n#matplotlib & Seaborn\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n\n#Plotly\nfrom plotly.offline import init_notebook_mode, iplot \nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\nimport pycountry\npy.init_notebook_mode(connected=True)\n\n#Folium\nimport folium \nfrom folium import plugins\n\n#Twitter data\n!pip install tweepy -q\nimport tweepy as tw\nimport nltk\nfrom nltk import bigrams\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport networkx\n\n# sklearn \nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n\n# Graphics in retina format \n%config InlineBackend.figure_format = 'retina' \n\n\n#Disable warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","bd8cddb3":"plt.rcParams.update({'font.size': 13})\n\nnames = ['AutoWeka', 'Auto-sklearn', ' TPOT', 'Auto-ml', 'Auto-Keras', \n        ' Datarobot', ' H2O-Automl', 'H2O-DriverlessAI', 'Darwin', 'Google Cloud Automl', \n        'Microsoft AzureML', ' TransmogrifAI' ,'Ludwig','MLjar']\ndates = ['2013', '2014', '2015', '2016','2017', '2015', '2016',\n        '2017', '2018', '2017', '2018', '2018' ,'2019','2018']\n \n# Convert date strings (e.g. 2014-10-18) to datetime\ndates = [datetime.strptime(d, \"%Y\") for d in dates]\n#dates = [d.year for d in dates]\n \n# Choose some nice levels\nlevels = np.tile([-5, 5, -3, 3, -1, 1],\n                 int(np.ceil(len(dates)\/6)))[:len(dates)]\n\n \n# Create figure and plot a stem plot with the date\nfig, ax = plt.subplots(figsize=(14, 6), constrained_layout=True)\nax.set(title=\"AutoML Tools history\")\nmarkerline, stemline, baseline = ax.stem(dates, levels,\n                                         linefmt=\"C3-\", basefmt=\"k-\",\n                                         use_line_collection=True)\nplt.setp(markerline, mec=\"k\", mfc=\"w\", zorder=3)\n \n# Shift the markers to the baseline by replacing the y-data by zeros.\nmarkerline.set_ydata(np.zeros(len(dates)))\n \n# annotate lines\nvert = np.array(['top', 'bottom'])[(levels > 0).astype(int)]\nfor d, l, r, va in zip(dates, levels, names, vert):\n    ax.annotate(r, xy=(d, l), xytext=(-3, np.sign(l)*3),\n                textcoords=\"offset points\", va=va, ha=\"left\")\n# format xaxis \n#ax.get_xaxis().set_major_locator(mdates.YearLocator())\n#ax.get_xaxis().set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\nplt.setp(ax.get_xticklabels(), rotation=30, ha=\"right\")\n \n# remove y axis and spines\nax.get_yaxis().set_visible(False)\nfor spine in [\"left\", \"top\", \"right\"]:\n    ax.spines[spine].set_visible(True)\nax.margins(y=0.1)\n\nplt.show()\n\nprint('This timeline chart has been created in Matplotlib \ud83d\ude03')\n","116be5a4":"# Importing the 2017,2018 and 2019 and 2020 survey dataset\n\n#Importing the 2020 Dataset\ndf_2020 = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\",low_memory=False)\n#df_2020.columns = df_2020.iloc[0]\n#df_2020=df_2020.drop([0])\n\n#Importing the 2019 Dataset\ndf_2019 = pd.read_csv('..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv',low_memory=False)\n#df_2019.columns = df_2019.iloc[0]\n#df_2019=df_2019.drop([0])\n\n#Importing the 2018 Dataset\ndf_2018 = pd.read_csv('..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv',low_memory=False)\n#df_2018.columns = df_2018.iloc[0]\n#df_2018=df_2018.drop([0])\n\n#Importing the 2017 Dataset\ndf_2017=pd.read_csv('..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv',encoding='ISO-8859-1',low_memory=False)\n\n\n\n# Helper functions( Source: https:\/\/www.kaggle.com\/paultimothymooney\/2020-kaggle-data-science-machine-learning-survey?select=kaggle_survey_2020_responses.csv)\n\n\ndef count_then_return_percent(dataframe,column_name):\n    '''\n    A helper function to return value counts as percentages.\n    \n    '''\n    counts = dataframe[column_name].value_counts(dropna=False)\n    percentages = round(counts*100\/(dataframe[column_name].count()),1)\n    return percentages\n\ndef count_then_return_percent_for_multiple_column_questions(dataframe,list_of_columns_for_a_single_question,dictionary_of_counts_for_a_single_question):\n    '''\n    A helper function to convert counts to percentages.\n    \n    '''\n    \n    df = dataframe\n    subset = list_of_columns_for_a_single_question\n    df = df[subset]\n    df = df.dropna(how='all')\n    total_count = len(df) \n    dictionary = dictionary_of_counts_for_a_single_question\n    for i in dictionary:\n        dictionary[i] = round(float(dictionary[i]*100\/total_count),1)\n    return dictionary \n\ndef create_dataframe_of_counts(dataframe,column,rename_index,rename_column,return_percentages=False):\n    '''\n    A helper function to create a dataframe of either counts \n    or percentages, for a single multiple choice question.\n     \n    '''\n    df = dataframe[column].value_counts().reset_index() \n    if return_percentages==True:\n        df[column] = (df[column]*100)\/(df[column].sum())\n    df = pd.DataFrame(df) \n    df = df.rename({'index':rename_index, 'Q3':rename_column}, axis='columns')\n    return df\n\ndef sort_dictionary_by_percent(dataframe,list_of_columns_for_a_single_question,dictionary_of_counts_for_a_single_question): \n    ''' \n    A helper function that can be used to sort a dictionary.\n    \n    It is an adaptation of a similar function\n    from https:\/\/www.kaggle.com\/sonmou\/what-topics-from-where-to-learn-data-science.\n    \n    '''\n    dictionary = count_then_return_percent_for_multiple_column_questions(dataframe,\n                                                                list_of_columns_for_a_single_question,\n                                                                dictionary_of_counts_for_a_single_question)\n    dictionary = {v:k    for(k,v) in dictionary.items()}\n    list_tuples = sorted(dictionary.items(), reverse=False) \n    dictionary = {v:k for (k,v) in list_tuples}   \n    return dictionary\n\n","82c29d50":"# https:\/\/www.kaggle.com\/paultimothymooney\/2020-kaggle-data-science-machine-learning-survey?select=kaggle_survey_2020_responses.csv\n\n# lists of answer choices and dictionaries of value counts (for the multiple choice multiple selection questions)\n\n# Questions where respondents can select more than one answer choice have been split into multiple columns.\n# These dictionaries contain value counts for every answer choice for every multiple-column question.\n\nresponses_df = df_2020\n\n\nq23_dictionary_of_counts = {\n    'Analyze and understand data to influence product or business decisions' : (responses_df['Q23_Part_1'].count()),\n    'Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data': (responses_df['Q23_Part_2'].count()),\n    'Build prototypes to explore applying machine learning to new areas' : (responses_df['Q23_Part_3'].count()),\n    'Build and\/or run a machine learning service that operationally improves my product or workflows' : (responses_df['Q23_Part_4'].count()),\n    'Experimentation and iteration to improve existing ML models' : (responses_df['Q23_Part_5'].count()),\n    'Do research that advances the state of the art of machine learning' : (responses_df['Q23_Part_6'].count()),\n    'None of these activities are an important part of my role at work' : (responses_df['Q23_Part_7'].count()),\n    'Other' : (responses_df['Q23_OTHER'].count())\n}\n\n\nq26a_dictionary_of_counts = {\n    'Amazon Web Services (AWS)' : (responses_df['Q26_A_Part_1'].count()),\n    'Microsoft Azure': (responses_df['Q26_A_Part_2'].count()),\n    'Google Cloud Platform (GCP)' : (responses_df['Q26_A_Part_3'].count()),\n    'IBM Cloud \/ Red Hat' : (responses_df['Q26_A_Part_4'].count()),\n    'Oracle Cloud' : (responses_df['Q26_A_Part_5'].count()),\n    'SAP Cloud' : (responses_df['Q26_A_Part_6'].count()),\n    'Salesforce Cloud' : (responses_df['Q26_A_Part_7'].count()),\n    'VMware Cloud' : (responses_df['Q26_A_Part_8'].count()),\n    'Alibaba Cloud' : (responses_df['Q26_A_Part_9'].count()),\n    'Tencent Cloud' : (responses_df['Q26_A_Part_10'].count()),\n    'None' : (responses_df['Q26_A_Part_11'].count()),\n    'Other' : (responses_df['Q26_A_OTHER'].count())\n}\n\nq26b_dictionary_of_counts = {\n    'Amazon Web Services (AWS)' : (responses_df['Q26_B_Part_1'].count()),\n    'Microsoft Azure': (responses_df['Q26_B_Part_2'].count()),\n    'Google Cloud Platform (GCP)' : (responses_df['Q26_B_Part_3'].count()),\n    'IBM Cloud \/ Red Hat' : (responses_df['Q26_B_Part_4'].count()),\n    'Oracle Cloud' : (responses_df['Q26_B_Part_5'].count()),\n    'SAP Cloud' : (responses_df['Q26_B_Part_6'].count()),\n    'Salesforce Cloud' : (responses_df['Q26_B_Part_7'].count()),\n    'VMware Cloud' : (responses_df['Q26_B_Part_8'].count()),\n    'Alibaba Cloud' : (responses_df['Q26_B_Part_9'].count()),\n    'Tencent Cloud' : (responses_df['Q26_B_Part_10'].count()),\n    'None' : (responses_df['Q26_B_Part_11'].count()),\n    'Other' : (responses_df['Q26_B_OTHER'].count())\n}\n\nq27a_dictionary_of_counts = {\n    'Amazon EC2' : (responses_df['Q27_A_Part_1'].count()),\n    'AWS Lambda': (responses_df['Q27_A_Part_2'].count()),\n    'Amazon Elastic Container Service' : (responses_df['Q27_A_Part_3'].count()),\n    'Azure Cloud Services' : (responses_df['Q27_A_Part_4'].count()),\n    'Microsoft Azure Container Instances' : (responses_df['Q27_A_Part_5'].count()),\n    'Azure Functions' : (responses_df['Q27_A_Part_6'].count()),\n    'Google Cloud Compute Engine' : (responses_df['Q27_A_Part_7'].count()),\n    'Google Cloud Functions' : (responses_df['Q27_A_Part_8'].count()),\n    'Google Cloud Run' : (responses_df['Q27_A_Part_9'].count()),\n    'Google Cloud App Engine' : (responses_df['Q27_A_Part_10'].count()),\n    'No \/ None' : (responses_df['Q27_A_Part_11'].count()),\n    'Other' : (responses_df['Q27_A_OTHER'].count())\n}\n\nq27b_dictionary_of_counts = {\n    'Amazon EC2' : (responses_df['Q27_B_Part_1'].count()),\n    'AWS Lambda': (responses_df['Q27_B_Part_2'].count()),\n    'Amazon Elastic Container Service' : (responses_df['Q27_B_Part_3'].count()),\n    'Azure Cloud Services' : (responses_df['Q27_B_Part_4'].count()),\n    'Microsoft Azure Container Instances' : (responses_df['Q27_B_Part_5'].count()),\n    'Azure Functions' : (responses_df['Q27_B_Part_6'].count()),\n    'Google Cloud Compute Engine' : (responses_df['Q27_B_Part_7'].count()),\n    'Google Cloud Functions' : (responses_df['Q27_B_Part_8'].count()),\n    'Google Cloud Run' : (responses_df['Q27_B_Part_9'].count()),\n    'Google Cloud App Engine' : (responses_df['Q27_B_Part_10'].count()),\n    'No \/ None' : (responses_df['Q27_B_Part_11'].count()),\n    'Other' : (responses_df['Q27_B_OTHER'].count())\n}\n\nq28a_dictionary_of_counts = {\n    'Amazon SageMaker' : (responses_df['Q28_A_Part_1'].count()),\n    'Amazon Forecast': (responses_df['Q28_A_Part_2'].count()),\n    'Amazon Rekognition' : (responses_df['Q28_A_Part_3'].count()),\n    'Azure Machine Learning Studio' : (responses_df['Q28_A_Part_4'].count()),\n    'Azure Cognitive Services' : (responses_df['Q28_A_Part_5'].count()),\n    'Google Cloud AI Platform \/ Google Cloud ML Engine' : (responses_df['Q28_A_Part_6'].count()),\n    'Google Cloud Video AI' : (responses_df['Q28_A_Part_7'].count()),\n    'Google Cloud Natural Language' : (responses_df['Q28_A_Part_8'].count()),\n    'Google Cloud Vision AI' : (responses_df['Q28_A_Part_9'].count()),\n    'No \/ None' : (responses_df['Q28_A_Part_10'].count()),\n    'Other' : (responses_df['Q28_A_OTHER'].count())\n}\n\nq28b_dictionary_of_counts = {\n    'Amazon SageMaker' : (responses_df['Q28_B_Part_1'].count()),\n    'Amazon Forecast': (responses_df['Q28_B_Part_2'].count()),\n    'Amazon Rekognition' : (responses_df['Q28_B_Part_3'].count()),\n    'Azure Machine Learning Studio' : (responses_df['Q28_B_Part_4'].count()),\n    'Azure Cognitive Services' : (responses_df['Q28_B_Part_5'].count()),\n    'Google Cloud AI Platform \/ Google Cloud ML Engine' : (responses_df['Q28_B_Part_6'].count()),\n    'Google Cloud Video AI' : (responses_df['Q28_B_Part_7'].count()),\n    'Google Cloud Natural Language' : (responses_df['Q28_B_Part_8'].count()),\n    'Google Cloud Vision AI' : (responses_df['Q28_B_Part_9'].count()),\n    'No \/ None' : (responses_df['Q28_B_Part_10'].count()),\n    'Other' : (responses_df['Q28_B_OTHER'].count())\n}\n\n\n\n\nq33a_dictionary_of_counts = {\n    'Automated data augmentation (e.g. imgaug, albumentations)' : (responses_df['Q33_A_Part_1'].count()),\n    'Automated feature engineering\/selection (e.g. tpot, boruta_py)': (responses_df['Q33_A_Part_2'].count()),\n    'Automated model selection (e.g. auto-sklearn, xcessiv)' : (responses_df['Q33_A_Part_3'].count()),\n    'Automated model architecture searches (e.g. darts, enas)' : (responses_df['Q33_A_Part_4'].count()),\n    'Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier)' : (responses_df['Q33_A_Part_5'].count()),\n    'Automation of full ML pipelines (e.g. Google AutoML, H20 Driverless AI)' : (responses_df['Q33_A_Part_6'].count()),\n    'No \/ None' : (responses_df['Q33_A_Part_7'].count()),\n    'Other' : (responses_df['Q33_A_OTHER'].count())\n}\n\nq33b_dictionary_of_counts = {\n    'Automated data augmentation (e.g. imgaug, albumentations)' : (responses_df['Q33_B_Part_1'].count()),\n    'Automated feature engineering\/selection (e.g. tpot, boruta_py)': (responses_df['Q33_B_Part_2'].count()),\n    'Automated model selection (e.g. auto-sklearn, xcessiv)' : (responses_df['Q33_B_Part_3'].count()),\n    'Automated model architecture searches (e.g. darts, enas)' : (responses_df['Q33_B_Part_4'].count()),\n    'Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier)' : (responses_df['Q33_B_Part_5'].count()),\n    'Automation of full ML pipelines (e.g. Google AutoML, H20 Driverless AI)' : (responses_df['Q33_B_Part_6'].count()),\n    'No \/ None' : (responses_df['Q33_B_Part_7'].count()),\n    'Other' : (responses_df['Q33_B_OTHER'].count())\n}\n\nq34a_dictionary_of_counts = {\n    'Google Cloud AutoML' : (responses_df['Q34_A_Part_1'].count()),\n    'H20 Driverless AI': (responses_df['Q34_A_Part_2'].count()),\n    'Databricks AutoML' : (responses_df['Q34_A_Part_3'].count()),\n    'DataRobot AutoML' : (responses_df['Q34_A_Part_4'].count()),\n    'Tpot' : (responses_df['Q34_A_Part_5'].count()),\n    'Auto-Keras' : (responses_df['Q34_A_Part_6'].count()),\n    'Auto-Sklearn' : (responses_df['Q34_A_Part_7'].count()),\n    'Auto_ml' : (responses_df['Q34_A_Part_8'].count()),\n    'Xcessiv' : (responses_df['Q34_A_Part_9'].count()),\n    'MLbox' : (responses_df['Q34_A_Part_10'].count()),\n    'No \/ None' : (responses_df['Q34_A_Part_11'].count()),\n    'Other' : (responses_df['Q34_A_OTHER'].count())\n}\n\nq34b_dictionary_of_counts = {\n    'Google Cloud AutoML' : (responses_df['Q34_B_Part_1'].count()),\n    'H20 Driverless AI': (responses_df['Q34_B_Part_2'].count()),\n    'Databricks AutoML' : (responses_df['Q34_B_Part_3'].count()),\n    'DataRobot AutoML' : (responses_df['Q34_B_Part_4'].count()),\n    'Tpot' : (responses_df['Q34_B_Part_5'].count()),\n    'Auto-Keras' : (responses_df['Q34_B_Part_6'].count()),\n    'Auto-Sklearn' : (responses_df['Q34_B_Part_7'].count()),\n    'Auto_ml' : (responses_df['Q34_B_Part_8'].count()),\n    'Xcessiv' : (responses_df['Q34_B_Part_9'].count()),\n    'MLbox' : (responses_df['Q34_B_Part_10'].count()),\n    'No \/ None' : (responses_df['Q34_B_Part_11'].count()),\n    'Other' : (responses_df['Q34_B_OTHER'].count())\n}\n\n\n\n\n# Questions where respondents can select more than one answer choice have been split into multiple columns.\n# These lists delineate every sub-column for every multiple-column question.\n\n\n\nq23_list_of_columns = ['Q23_Part_1',\n                       'Q23_Part_2',\n                       'Q23_Part_3',\n                       'Q23_Part_4',\n                       'Q23_Part_5',\n                       'Q23_Part_6',\n                       'Q23_Part_7',\n                       'Q23_OTHER']\n\nq26a_list_of_columns = ['Q26_A_Part_1',\n                        'Q26_A_Part_2',\n                        'Q26_A_Part_3',\n                        'Q26_A_Part_4',\n                        'Q26_A_Part_5',\n                        'Q26_A_Part_6',\n                        'Q26_A_Part_7',\n                        'Q26_A_Part_8',\n                        'Q26_A_Part_9',\n                        'Q26_A_Part_10',\n                        'Q26_A_Part_11',\n                        'Q26_A_OTHER']\n\nq26b_list_of_columns = ['Q26_B_Part_1',\n                        'Q26_B_Part_2',\n                        'Q26_B_Part_3',\n                        'Q26_B_Part_4',\n                        'Q26_B_Part_5',\n                        'Q26_B_Part_6',\n                        'Q26_B_Part_7',\n                        'Q26_B_Part_8',\n                        'Q26_B_Part_9',\n                        'Q26_B_Part_10',\n                        'Q26_B_Part_11',\n                        'Q26_B_OTHER']\n\nq27a_list_of_columns = ['Q27_A_Part_1',\n                        'Q27_A_Part_2',\n                        'Q27_A_Part_3',\n                        'Q27_A_Part_4',\n                        'Q27_A_Part_5',\n                        'Q27_A_Part_6',\n                        'Q27_A_Part_7',\n                        'Q27_A_Part_8',\n                        'Q27_A_Part_9',\n                        'Q27_A_Part_10',\n                        'Q27_A_Part_11',\n                        'Q27_A_OTHER']\n\nq27b_dictionary_of_counts = ['Q27_B_Part_1',\n                             'Q27_B_Part_2',\n                             'Q27_B_Part_3',\n                             'Q27_B_Part_4',\n                             'Q27_B_Part_5',\n                             'Q27_B_Part_6',\n                             'Q27_B_Part_7',\n                             'Q27_B_Part_8',\n                             'Q27_B_Part_9',\n                             'Q27_B_Part_10',\n                             'Q27_B_Part_11',\n                             'Q27_B_OTHER']\n\nq28a_list_of_columns = ['Q28_A_Part_1',\n                        'Q28_A_Part_2',\n                        'Q28_A_Part_3',\n                        'Q28_A_Part_4',\n                        'Q28_A_Part_5',\n                        'Q28_A_Part_6',\n                        'Q28_A_Part_7',\n                        'Q28_A_Part_8',\n                        'Q28_A_Part_9',\n                        'Q28_A_Part_10',\n                        'Q28_A_OTHER']\n\nq28b_list_of_columns = ['Q28_B_Part_1',\n                        'Q28_B_Part_2',\n                        'Q28_B_Part_3',\n                        'Q28_B_Part_4',\n                        'Q28_B_Part_5',\n                        'Q28_B_Part_6',\n                        'Q28_B_Part_7',\n                        'Q28_B_Part_8',\n                        'Q28_B_Part_9',\n                        'Q28_B_Part_10',\n                        'Q28_B_OTHER']\n\n\n\nq33a_list_of_columns = ['Q33_A_Part_1',\n                        'Q33_A_Part_2',\n                        'Q33_A_Part_3',\n                        'Q33_A_Part_4',\n                        'Q33_A_Part_5',\n                        'Q33_A_Part_6',\n                        'Q33_A_Part_7',\n                        'Q33_A_OTHER']\n\nq33b_list_of_columns = ['Q33_B_Part_1',\n                        'Q33_B_Part_2',\n                        'Q33_B_Part_3',\n                        'Q33_B_Part_4',\n                        'Q33_B_Part_5',\n                        'Q33_B_Part_6',\n                        'Q33_B_Part_7',\n                        'Q33_B_OTHER']\n\nq34a_list_of_columns = ['Q34_A_Part_1',\n                        'Q34_A_Part_2',\n                        'Q34_A_Part_3',\n                        'Q34_A_Part_4',\n                        'Q34_A_Part_5',\n                        'Q34_A_Part_6',\n                        'Q34_A_Part_7',\n                        'Q34_A_Part_8',\n                        'Q34_A_Part_9',\n                        'Q34_A_Part_10',\n                        'Q34_A_Part_11',\n                        'Q34_A_OTHER']\n\nq34b_list_of_columns = ['Q34_B_Part_1',\n                        'Q34_B_Part_2',\n                        'Q34_B_Part_3',\n                        'Q34_B_Part_4',\n                        'Q34_B_Part_5',\n                        'Q34_B_Part_6',\n                        'Q34_B_Part_7',\n                        'Q34_B_Part_8',\n                        'Q34_B_Part_9',\n                        'Q34_B_Part_10',\n                        'Q34_B_Part_11',\n                        'Q34_B_OTHER']\n\n\n","07e8b941":"df_all_surveys = pd.DataFrame(\n    data=[len(df_2017), len(df_2018)-1, len(df_2019)-1, len(df_2020)-1],\n    columns=[\"Number of responses\"],\n    index=[\"2017\", \"2018\", \"2019\", \"2020\"]\n)\ndf_all_surveys.index.names = [\"Year of Survey\"]\ndf = df_all_surveys.reset_index(level=0)\n\n\nx = df['Number of responses'].index\ny = df['Number of responses'].values\n\ntrace0 = go.Bar(\n            x=['Year 2017','Year 2018','Year 2019','Year 2020'],\n            y=y,\n            text=y,\n            width=0.4,\n            textposition='auto',\n            marker_color='#48C9B0')\n\ntrace1 = go.Scatter(\n            x=['Year 2017','Year 2018','Year 2019','Year 2020'],\n            y=y,\n            text=y,\n            marker_color='black')\n\ndata = [trace0,trace1]\n\nlayout = go.Layout(yaxis=dict(title='Number of Respondents'),width=700,height=500,showlegend=False,\n                  title='Total number of respondents over the years',title_x=0.5,plot_bgcolor='white',\n                  xaxis=dict(title='Survey Year'))\n\nfigure = go.Figure(data=data, layout = layout)\nfigure.show()","0f99f47e":"# survey 2020\nstart_index_2020 = df_2020.columns.get_loc(\"Q33_A_Part_1\")\nend_index_2020 = df_2020.columns.get_loc(\"Q33_A_OTHER\")\nautoml_categories_2020 = df_2020.iloc[:,start_index_2020:end_index_2020+1]\nautoml_categories_2020 = automl_categories_2020.drop([0])\n\nrespondents_who_have_answered_2020 = automl_categories_2020.dropna(how='all')\nrespondents_who_have_answered_2020['Q33_A_Part_7'] = respondents_who_have_answered_2020['Q33_A_Part_7'].replace(np.nan, 'Use')\nrespondents_not_using_automl_2020 = automl_categories_2020['Q33_A_Part_7'].value_counts(dropna=False)['No \/ None']\nrespondents_using_automl_2020 = len(respondents_who_have_answered_2020) - respondents_not_using_automl_2020\nrespondents_who_havenot_answered_at_all_2020 = automl_categories_2020['Q33_A_Part_7'].value_counts(dropna=False)[0] - respondents_using_automl_2020\n\nrespondents_who_have_answered_2020['Q33_A_Part_7'] = respondents_who_have_answered_2020['Q33_A_Part_7'].replace(np.nan, 'Use')\n\n# survey 2019\nstart_index_2019 = df_2019.columns.get_loc(\"Q25_Part_1\")\nend_index_2019 = df_2019.columns.get_loc(\"Q25_Part_8\")\nautoml_categories_2019 = df_2019.iloc[:,start_index_2019:end_index_2019+1]\nautoml_categories_2019 = automl_categories_2019.drop([0])\n\n\nrespondents_who_have_answered_2019 = automl_categories_2019.dropna(how='all')\nrespondents_who_have_answered_2019['Q25_Part_7'] = respondents_who_have_answered_2019['Q25_Part_7'].replace(np.nan, 'Use')\nrespondents_not_using_automl_2019 = automl_categories_2019['Q25_Part_7'].value_counts(dropna=False)['None']\nrespondents_using_automl_2019 = len(respondents_who_have_answered_2019) - respondents_not_using_automl_2019\nrespondents_who_havenot_answered_at_all_2019 = automl_categories_2019['Q25_Part_7'].value_counts(dropna=False)[0] - respondents_using_automl_2019\n\nrespondents_who_have_answered_2019['Q25_Part_7'] = respondents_who_have_answered_2019['Q25_Part_7'].replace(np.nan, 'Use')\n\n\n\n\ncolors = ['mediumturquoise','gold' ]\ncolors1 = ['#F4D03F','#82E0AA', \"#F1948A\",]\n\n\n\nlabels = ['Didnot Answer','Use some form of AutoML','Donot use AutoML']\nvalues1 = [respondents_who_havenot_answered_at_all_2019,respondents_using_automl_2019,respondents_not_using_automl_2019 ]\nvalues2 = [respondents_who_havenot_answered_at_all_2020,respondents_using_automl_2020,respondents_not_using_automl_2020 ]\n\n\"\"\"\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=labels, values=values2,name=\"2020\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=labels, values=values1, name=\"2019\"),\n              1, 2)\n\n#Use `hole` to create a donut-like pie chart\n\nfig.update_traces(hole=.4, hoverinfo='label+value', textinfo='percent', textfont_size=15,\n                  marker=dict(colors=colors1, line=dict(color='#000000', width=1)))\n\nfig.update_layout(\n    title_text=\"Participants who responded to AutoML question\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='2020', \n                      x=0.18, \n                      y=0.5, \n                      font_size=15, \n                      showarrow=False),\n                \n                \n                  dict(text='2019', \n                       x=0.81, \n                       y=0.5, \n                       font_size=15, \n                       showarrow=False)])\n\nfig.show()\n\"\"\"\n\n\n# Use `hole` to create a donut-like pie chart\nfig = go.Figure(data=[go.Pie(labels=labels, values=values2, hole=.4)])\n\nfig.update_traces(hoverinfo='label+value', textinfo='percent', textfont_size=15,\n                  marker=dict(colors=colors1, line=dict(color='#000000', width=1)))\n\nfig.update_layout(\n    title_text=\"Respondents for the AutoML question \",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Year 2020', x=0.5, y=0.5, font_size=20, showarrow=False)])\nfig.show()","c836e031":"#colors = ['mediumturquoise','gold' ]\ncolors = [\"#82E0AA\", \"#F1948A\"]\n\nlabels = ['Use some form of AutoML','Donot use AutoML']\n#values1 = [respondents_using_automl_2019,respondents_not_using_automl_2019 ]\nvalues2 = [respondents_using_automl_2020,respondents_not_using_automl_2020 ]\n\n\n\n\n\n# Use `hole` to create a donut-like pie chart\nfig = go.Figure(data=[go.Pie(labels=labels, values=values2, hole=.4)])\n\nfig.update_traces(hoverinfo='label+value', textinfo='percent', textfont_size=15,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=1)))\n\nfig.update_layout(\n    title_text=\"Respondents for the AutoML question \",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Year 2020', x=0.5, y=0.5, font_size=20, showarrow=False)])\nfig.show()","95b12cd7":"# subsetting the dataset for people who responded to the AutoML question in 2020\n\ndf_2020 = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\",low_memory=False)\nautoml_users = df_2020.loc[(df_2020['Q33_A_Part_1'].notnull()) | (df_2020['Q33_A_Part_2'].notnull())  | (df_2020['Q33_A_Part_3'].notnull()) | (df_2020['Q33_A_Part_4'].notnull()) | (df_2020['Q33_A_Part_5'].notnull()) | (df_2020['Q33_A_Part_6'].notnull()) | (df_2020[1:]['Q33_A_OTHER'].notnull())] \nautoml_users['Q33_A_Part_7'] = automl_users['Q33_A_Part_7'].replace(np.nan,'Use')     \n\n\ndonot_use_automl = df_2020[1:][df_2020[1:]['Q33_A_Part_7']=='No \/ None']\n\nautoml_2020_respondents = pd.concat([automl_users, donot_use_automl], axis=0)\n\n\n\nautoml_users_2019 = df_2019.loc[(df_2019['Q25_Part_1'].notnull()) | (df_2019['Q25_Part_2'].notnull()) | (df_2019['Q25_Part_3'].notnull()) | (df_2019['Q25_Part_4'].notnull()) | (df_2019['Q25_Part_5'].notnull()) | (df_2019['Q25_Part_6'].notnull()) | (df_2019[1:]['Q25_Part_8'].notnull())] \nautoml_users_2019['Q25_Part_7'] = automl_users_2019['Q25_Part_7'].replace(np.nan,'Use')     \n\n\ndonot_use_automl_2019 = df_2019[1:][df_2019[1:]['Q25_Part_7']=='None']\n\nautoml_2019_respondents = pd.concat([automl_users_2019, donot_use_automl_2019], axis=0)\n","d660fe9f":"values = [['Automated data augmentation', \n           'Automated feature engineering\/selection', \n           'Automated model selection', \n           'Automated model architecture searches',\n           'Automated hyperparameter tuning',\n           'Automation of full ML pipelines'], \n          \n          [\"This process includes techniques that enhance the size and quality of training datasets eg Imgaug and Albumentationsl.\",\n           \"This process involves creating new feature sets iteratively until the ML model achieves a satisfactory accuracy score. Typical examples include:\",\n           \"This process involves automatically searching for the right learning algorithm for a new machine learning dataset\",\n           \"This process involves automatically identifying architectures that are superior to hand-designed ones.\",\n           \"The process of tuning machine learning hyperparameters automatically\",\n           \"The process of automating the complete Machine Learning Pipeline\"]]\n\nfig = go.Figure(data=[go.Table(\n  columnorder = [1,2],\n  columnwidth = [80,400],\n  header = dict(\n    values = [['<b>AutoML Category<\/b>'],\n                  ['<b>DESCRIPTION<\/b>']],\n    line_color='darkslategray',\n    fill_color='#82E0AA',\n    align=['left','center'],\n    font=dict(color='black', size=12),\n    height=40\n  ),\n  cells=dict(\n    values=values,\n    line_color='darkslategray',\n    fill=dict(color=['#ABEBC6', 'white']),\n    align=['left', 'left'],\n    font_size=12,\n    height=30)\n    )\n])\nfig.show()","8b4033bf":"responses_df = automl_2020_respondents[automl_2020_respondents['Q33_A_Part_7']=='Use']\nq33a_dictionary_of_counts = {\n    'Automated data augmentation (e.g. imgaug, albumentations)' : (responses_df['Q33_A_Part_1'].count()),\n    'Automated feature engineering\/selection (e.g. tpot, boruta_py)': (responses_df['Q33_A_Part_2'].count()),\n    'Automated model selection (e.g. auto-sklearn, xcessiv)' : (responses_df['Q33_A_Part_3'].count()),\n    'Automated model architecture searches (e.g. darts, enas)' : (responses_df['Q33_A_Part_4'].count()),\n    'Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier)' : (responses_df['Q33_A_Part_5'].count()),\n    'Automation of full ML pipelines (e.g. Google AutoML, H20 Driverless AI)' : (responses_df['Q33_A_Part_6'].count()),\n    'Other' : (responses_df['Q33_A_OTHER'].count())\n}\n\ndictionary_of_counts = sort_dictionary_by_percent(responses_df,\n                                                  q33a_list_of_columns,\n                                                  q33a_dictionary_of_counts)\ntitle_for_chart = 'Most common categories of AutoML (or partial AutoML) tools'\ntitle_for_y_axis = '% of respondents'\norientation_for_chart = 'h'\n  \nautoml_categories1 = pd.DataFrame(dictionary_of_counts.items(),columns=['Most common categories of AutoML (or partial AutoML) tools', '% of respondents'])    \n\ndata = automl_categories1\n\ntrace = go.Bar(\n                    #y = automl_categories[\"Most common categories of AutoML (or partial AutoML) tools\"],\n                    y = ['Others',\n                           'Auto-model<br> architecture searches',\n                           'Automated<br> feature engineering',\n                           'Automation of<br> full ML pipelines',\n                           'Automated<br> data augmentation',\n                           'Automated<br> hyperparameter tuning',\n                           'Automated<br> model selection'],\n                    x = automl_categories1['% of respondents'] ,\n                    orientation='h',\n                    marker=dict(color='#17A589', opacity=0.6),\n                    #line=dict(color='black',width=1)),\n                    )\ndata = [trace]\nlayout = go.Layout(barmode = \"group\",width=1000, height=500, \n                       #xaxis= dict(title='No of times ranked higest'),\n                       #yaxis=dict(autorange=\"reversed\"),\n                       showlegend=False)\n\n    \nfig = go.Figure(data = data, layout = layout)\nfig.update_traces(texttemplate='%{x:.2s}', textposition='outside')\n#fig.update_layout(uniformtext_minsize=5.5, uniformtext_mode='hide')\nfig.update_layout(plot_bgcolor='white',title='AutoML usage category wise')\nfig.update_xaxes(showgrid=False, zeroline=False, title=\"% of AutoML Users \")\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()    \n","de59b6cb":"%%html\n\n<div class='tableauPlaceholder' id='viz1609687289227' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Au&#47;AutoML&#47;UsageofDifferenttools&#47;1_rss.png' style='border: none' \/><\/a><\/noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' \/> <param name='embed_code_version' value='3' \/> <param name='site_root' value='' \/><param name='name' value='AutoML&#47;UsageofDifferenttools' \/><param name='tabs' value='no' \/><param name='toolbar' value='yes' \/><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Au&#47;AutoML&#47;UsageofDifferenttools&#47;1.png' \/> <param name='animate_transition' value='yes' \/><param name='display_static_image' value='yes' \/><param name='display_spinner' value='yes' \/><param name='display_overlay' value='yes' \/><param name='display_count' value='yes' \/><param name='language' value='en' \/><param name='filter' value='publish=yes' \/><\/object><\/div>                <script type='text\/javascript'>                    var divElement = document.getElementById('viz1609687289227');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https:\/\/public.tableau.com\/javascripts\/api\/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                <\/script>","afba7f03":"from IPython.display import display, HTML\n\ntools = pd.DataFrame({'AutoML_Tools': ['Google Cloud AutoML', 'H2O DriverlessAI','Databricks AutoML' ,'DataRobot AutoML','Xcessiv' ,'MLbox','Tpot', 'Auto_ml','Auto-Keras','Auto-Sklearn'],\n     'Type': ['Enterprise', 'Enterprise', 'Enterprise', 'Enterprise','Open-Source','Open-Source','Open-Source','Open-Source','Open-Source','Open-Source'],\n     'Website\/Github link': ['https:\/\/cloud.google.com\/automl',\n                             'https:\/\/www.h2o.ai\/products\/h2o-driverless-ai\/',\n                            'https:\/\/databricks.com\/product\/automl-on-databricks',\n                            'https:\/\/www.datarobot.com\/platform\/automated-machine-learning\/',\n                            'https:\/\/github.com\/reiinakano\/xcessiv',\n                            'https:\/\/github.com\/AxeldeRomblay\/MLBox',\n                            'https:\/\/github.com\/EpistasisLab\/tpot',\n                            'https:\/\/github.com\/ClimbsRocks\/auto_ml',\n                            'https:\/\/autokeras.com\/',\n                             'https:\/\/automl.github.io\/auto-sklearn\/master\/']})\n\n# render dataframe as html\nhtml = tools.to_html(render_links=True, index=False).replace('<th>','<th style = \"background-color: #48c980\">')\n# write html to file \ntext_file = open(\"AutoML_Tools.html\", \"w\") \ntext_file.write(html) \ntext_file.close() \nHTML('AutoML_Tools.html')","a9485b52":"\nquestion_named = 'Q34-A'\ndictionary_of_counts = sort_dictionary_by_percent(df_2020[1:],\n                                                  q34a_list_of_columns,\n                                                  q34a_dictionary_of_counts)\ntitle_for_chart = 'Most common AutoML (or partial AutoML) tools'\ntitle_for_y_axis = '% of respondents'\norientation_for_chart = 'h'\n  \nautoml_tools = pd.DataFrame( q34a_dictionary_of_counts.items(),columns=['Most common  AutoML (or partial AutoML) tools', '% of respondents_2020'])    \nautoml_tools = automl_tools.sort_values('% of respondents_2020',ascending=True)\ndata = automl_tools\n\ntrace = go.Bar(\n                    y = data[\"Most common  AutoML (or partial AutoML) tools\"],\n                    x = data['% of respondents_2020'] ,\n                    orientation='h',\n                    marker=dict(color='#48C9B0', opacity=0.6),\n                    #line=dict(color='black',width=1)),\n                    )\ndata = [trace]\nlayout = go.Layout(barmode = \"group\",width=1000, height=500, \n                       #xaxis= dict(title='No of times ranked higest'),\n                       #yaxis=dict(autorange=\"reversed\"),\n                       showlegend=False)\n\n    \nfig = go.Figure(data = data, layout = layout)\nfig.update_traces(texttemplate='%{x:.2s}', textposition='outside')\n#fig.update_layout(uniformtext_minsize=5.5, uniformtext_mode='hide')\nfig.update_layout(plot_bgcolor='white',title='AutoML usage in 2020')\nfig.update_xaxes(showgrid=False, zeroline=False, title=\"% of AutoML respondents in 2020\")\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","26f682dd":"#AutoML usage in 2019\n\nquestion_named = 'Q33'\n\nq33_2019_list_of_columns = [ 'Q33_Part_1',\n                         'Q33_Part_2',\n                         'Q33_Part_3',\n                         'Q33_Part_4',\n                         'Q33_Part_5',\n                         'Q33_Part_6',\n                         'Q33_Part_7',\n                         'Q33_Part_8',\n                         'Q33_Part_9',\n                         'Q33_Part_10',\n                         'Q33_Part_11',\n                         'Q33_Part_12']\n\nq33_2019_dictionary_of_counts = {\n    'Google Cloud AutoML' : (df_2019['Q33_Part_1'].count()),\n    'H20 Driverless AI': (df_2019['Q33_Part_2'].count()),\n    'Databricks AutoML' : (df_2019['Q33_Part_3'].count()),\n    'DataRobot AutoML' : (df_2019['Q33_Part_4'].count()),\n    'Tpot' : (df_2019['Q33_Part_5'].count()),\n    'Auto-Keras' : (df_2019['Q33_Part_6'].count()),\n    'Auto-Sklearn' : (df_2019['Q33_Part_7'].count()),\n    'Auto_ml' : (df_2019['Q33_Part_8'].count()),\n    'Xcessiv' : (df_2019['Q33_Part_9'].count()),\n    'MLbox' : (df_2019['Q33_Part_10'].count()),\n    'No \/ None' : (df_2019['Q33_Part_11'].count()),\n    'Other' : (df_2019['Q33_Part_12'].count())\n}\n\ndictionary_of_counts_2019 = sort_dictionary_by_percent(df_2019[1:],\n                                                  q33_2019_list_of_columns,\n                                                  q33_2019_dictionary_of_counts)\ntitle_for_chart = 'Most common AutoML (or partial AutoML) tools'\ntitle_for_y_axis = '% of respondents'\norientation_for_chart = 'h'\n  \nautoml_tools_2019 = pd.DataFrame(q33_2019_dictionary_of_counts.items(),columns=['Most common  AutoML (or partial AutoML) tools', '% of respondents_2019'])    \nautoml_tools_2019 = automl_tools_2019.sort_values('% of respondents_2019',ascending=True)\ndata = automl_tools_2019\n\n","da0d4eea":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n\nfig = make_subplots(\n    rows=1, cols=1,\n    specs=[[{\"type\": \"xy\"}]])\n \n\n\n\nfig.add_trace(go.Bar(\n                    y = automl_tools_2019[\"Most common  AutoML (or partial AutoML) tools\"][:-1],\n            \n                    \n                    x = automl_tools_2019['% of respondents_2019'] ,\n                    orientation='h',\n                    name=\"2019\",\n                    marker=dict(color='#F1C40F', opacity=0.6)),\n                    row=1, col=1)\n\n\nfig.add_trace(go.Bar(\n                    y = automl_tools[\"Most common  AutoML (or partial AutoML) tools\"][:-1],\n                 \n                    \n                    x = automl_tools['% of respondents_2020'] ,\n                    orientation='h',\n                    name=\"2020\",\n                    marker=dict(color='#48C9B0', opacity=0.6)),\n                    row=1, col=1)\n\n\nfig.update_layout(plot_bgcolor='white',height=700, showlegend=True,\n                  title='AutoML Tools usage in 2020 vs 2019 ',\n                 legend = dict(orientation = \"h\", x = 0.1, y = 1.11))\n\n\nfig.show()","72e347df":"\ndfg = pd.concat([automl_tools, automl_tools_2019], axis=1)\ncolumn_numbers = [x for x in range(dfg.shape[1])]  # list of columns' integer indices\n\ncolumn_numbers .remove(2) \ndfg = dfg.iloc[:, column_numbers] #return all columns except the 0th column\ndfg = dfg[:-2]\n\ndfg.set_index(dfg.columns[0]).iplot(kind='scatter',\n                                    mode='markers+lines',\n                                    #annotations = {6 : 'maximum<br> rise in adoption'},\n                                    title='Growth in AutoML Tools Adoption(2019 to 2020)',\n                                    xTitle='AutoML Tools',\n                                    yTitle='Percentage',\n                                    theme='white',\n                                    colors = ['#F1C40F','#48C9B0'],\n                                    gridcolor='white')","deabf40f":"#Q5: Select the title most similar to your current role (or most recent title if retired): \n\ncolumns = ['Automated data<br> augmentation','Automated feature<br> engineering','Automated model<br> selection','Automated model<br> architecture searches','Automated<br> hyperparameter tuning','Automation of<br> full ML pipelines']\norder = ['Data Scientist',\n            'Machine Learning Engineer',\n            'Data Analyst',\n            'Data Engineer',\n            'DBA\/Database Engineer',\n            'DBA\/Database Engineer',\n            'Research Scientist',\n            'Statistician',\n            'Business Analyst',\n            'Product\/Project Manager',\n            'Other']\n\ntitle_per = automl_users[1:]['Q5'].value_counts(normalize=True)*100\n\"\"\"\ntitle_per.round(1).sort_values(ascending=True).round(1).iplot(kind='barh',theme='white',\n                                                     title = 'Job title of AutoML users',\n                                                     xTitle='% of AutoML Users in 2020',\n                                                     gridcolor='white', color='#48c980')\n\n\"\"\"\ndf = title_per.to_frame().round(1)\nfig = px.pie(df, values=df['Q5'].values, names=df.index, color_discrete_sequence=px.colors.sequential.YlGnBu,title='Job title of AutoML users')\nfig.update_traces(textposition='inside', textinfo='percent')\nfig.show()","117b29a4":"\ntitle1 = automl_users[1:].groupby(['Q5'])['Q33_A_Part_1','Q33_A_Part_2','Q33_A_Part_3','Q33_A_Part_4','Q33_A_Part_5','Q33_A_Part_6'].count()\ntitle_per1 = ((title1.T\/title1.T.sum().values))*100\n\n\nimport plotly.figure_factory as ff\nz=title_per1.round(0)\nx= ['Automated data<br> augmentation',\n       'Automated feature<br> engineering',\n       'Automated model<br> selection',\n       'Automated model<br> architecture searches',\n       'Automated<br> hyperparameter tuning',\n       'Automation of<br> full ML pipelines']\ny = ['Business Analyst', 'DBA\/Database Engineer', 'Data Analyst',\n       'Data Engineer', 'Data Scientist', 'Machine Learning Engineer',\n       'Other', 'Product\/Project Manager', 'Research Scientist',\n       'Software Engineer', 'Statistician']\nfig = ff.create_annotated_heatmap(z=z.values,y=x,x=y,colorscale='gnbu')\nfig.show()\n\n\n\n\n","5a619560":"title11 = automl_users[1:].groupby(['Q5'])['Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10'].count()\ntitle_per11 = ((title11.T\/title11.T.sum().values))*100\ntitle_per11.index = ['Google Cloud AutoML',\n                    'H20 Driverless AI',\n                    'Databricks AutoML',\n                    'DataRobot AutoML',\n                    'Tpot',\n                    'Auto-Keras',\n                    'Auto-Sklearn',\n                    'Auto_ml',\n                    'Xcessiv',\n                    'MLbox']\ntitle_per11.T.round(1).iplot(kind='barh',gridcolor='white',theme='white',\n                              barmode = 'stack',\n                              title='Job titles vs AutoML Tools usage',\n                              xTitle='% of AutoML Users in 2020')","fc58a828":"theme='white'\n\nresponses_in_order = ['I do not use machine learning methods',\n                      'Under 1 year','1-2 years','2-3 years',\n                      '3-4 years','4-5 years','5-10 years',\n                     '10-20 years', '20 or more years']\n\nexp_usage = automl_users[1:].groupby(['Q15'])['Q33_A_Part_7'].count().T\nexp_usage_per = ((exp_usage.T\/exp_usage.T.sum()).T)*100\nexp_usage_per[responses_in_order].sort_values(ascending=True).round(1).iplot(kind='barh',theme='white',\n                                                         title='Machine Learning experience of AutoML users',\n                                                         xTitle='% of AutoML Users in 2020',\n                                                         gridcolor='white',color='#48c980')\n\n\n\n","4470a082":"exp_usage11 = automl_users[1:].groupby(['Q15'])['Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10'].count()\nexp_usage_per11 = ((exp_usage11.T\/exp_usage11.T.sum().values))*100\nexp_usage_per11.index = ['Google Cloud AutoML',\n                    'H20 Driverless AI',\n                    'Databricks AutoML',\n                    'DataRobot AutoML',\n                    'Tpot',\n                    'Auto-Keras',\n                    'Auto-Sklearn',\n                    'Auto_ml',\n                    'Xcessiv',\n                    'MLbox']\nexp_usage_per11.T.round(1).iplot(kind='bar',theme=theme,gridcolor='white',\n                              #barmode = 'stack',\n                              title='Machine Learning experience vs AutoML Tools usage',\n                              xTitle='% of AutoML Users in 2020')","14e532c8":"pd.crosstab(index=automl_users[1:]['Q5'], columns=automl_users[1:]['Q15']).T.iplot(kind='scatter',\n                                    mode='markers',\n                                    \n                                    title='Machine learning experience vs Job Title',\n                                    xTitle='Machine Learning Experience',\n                                    yTitle='AutoML users',\n                                    theme='white',size=15,\n                                    #colors = ['orange','lightpink'],\n                                    gridcolor='white')","ce6e52eb":"\ncoding_usage_per = automl_users[1:]['Q6'].value_counts(normalize=True)*100\ncoding_usage_per.sort_values(ascending=True).round(1).iplot(kind='barh',theme='white',\n                                                            title= 'Coding experience of AutoML users',\n                                                            xTitle='% of AutoML Users',\n                                                            gridcolor='white',bargap = 0.3, color='#48c980' )\n\n","5260066f":"coding_usage = automl_users[1:].groupby(['Q6'])['Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10'].count()\ncoding_usage_per = ((coding_usage.T\/coding_usage.T.sum().values))*100\ncoding_usage_per.index = ['Google Cloud AutoML',\n                    'H20 Driverless AI',\n                    'Databricks AutoML',\n                    'DataRobot AutoML',\n                    'Tpot',\n                    'Auto-Keras',\n                    'Auto-Sklearn',\n                    'Auto_ml',\n                    'Xcessiv',\n                    'MLbox']\ncoding_usage_per.T.round(1).iplot(kind='barh',theme='white',gridcolor='white',\n                              barmode = 'stack',\n                              title='Coding experience vs AutoML Tools usage',\n                              xTitle='% of AutoML Users in 2020')","34cc5114":"plt.rcParams.update({'font.size': 12})\n\ncoding_vs_ml_exp = pd.crosstab(index=automl_users[1:]['Q15'], columns=automl_users[1:]['Q6'])\ncoding_vs_ml_exp_per = (((coding_vs_ml_exp.T\/coding_vs_ml_exp.T.sum()).T)*100).astype('int')\n\nplt.figure(figsize=(10,6))\n\nsns.heatmap(coding_vs_ml_exp_per,\n            cmap = \"YlGnBu\", annot=True, cbar=False)\n\nplt.xlabel('Coding experience')\nplt.ylabel('ML experience')\nprint('All values are in percent')\n\n\n\n","d4b63366":"question_name = 'Q23-A'\n\nq23_automl_list_of_columns = [ 'Q23_Part_1',\n                         'Q23_Part_2',\n                         'Q23_Part_3',\n                         'Q23_Part_4',\n                         'Q23_Part_5',\n                         'Q23_Part_6',\n                         'Q23_Part_7',\n                         'Q23_Other']\n\nq23_automl_dictionary_of_counts = {\n    'Analyze and understand data to influence product or business decisions' : (automl_users['Q23_Part_1'].count()),\n    'Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data': (automl_users['Q23_Part_2'].count()),\n    'Build prototypes to explore applying machine learning to new areas' : (automl_users['Q23_Part_3'].count()),\n    'Build and\/or run a machine learning service that operationally improves my product or workflows' : (automl_users['Q23_Part_4'].count()),\n    'Experimentation and iteration to improve existing ML models' : (automl_users['Q23_Part_5'].count()),\n    'Do research that advances the state of the art of machine learning' : (automl_users['Q23_Part_6'].count()),\n    'None of these activities are an important part of my role at work' : (automl_users['Q23_Part_7'].count()),\n    'Other' : (automl_users['Q23_OTHER'].count())\n}\n\n\ndictionary_of_counts = sort_dictionary_by_percent(automl_users[1:],\n                                                  q23_list_of_columns,\n                                                  q23_dictionary_of_counts)\n\ntitle_for_chart = ' Activities that make up an important part of your role at work'\ntitle_for_y_axis = '% of respondents'\norientation_for_chart = 'h'\n  \njob_role = pd.DataFrame(dictionary_of_counts.items(),columns=[' activities that make up an important part of your role at work', '% of respondents'])    \n\ndata = job_role\n\ntrace = go.Bar(\n                   #y = data[\" activities that make up an important part of your role at work\"],\n                    y =   ['Other',\n                           'None of these activities<br> are an important part<br> of my role at work',\n                          'Do research that advances<br> the state of the<br> art of machine learning' ,\n                          'Build and\/or run a machine learning<br> service that operationally improves<br> my product or workflows',  \n                          'Experimentation and iteration<br> to improve existing ML models',\n                          'Build and\/or run<br> the data infrastructure that my<br> business uses for storing, analyzing,<br> and operationalizing data',\n                          'Build prototypes to explore<br> applying machine learning<br> to new areas',                \n                          'Analyze and understand<br> data to influence product<br> or business decisions'],\n                    x = data['% of respondents'] ,\n                    orientation='h',\n                    marker=dict(color='#48c980', opacity=0.6),\n                    #line=dict(color='black',width=1)),\n                    )\ndata = [trace]\nlayout = go.Layout(barmode = \"group\",width=1500, height=700, \n                       #xaxis= dict(title='No of times ranked higest'),\n                       #yaxis=dict(autorange=\"reversed\"),\n                       showlegend=False)\n\n    \nfig = go.Figure(data = data, layout = layout)\nfig.update_traces(texttemplate='%{x:.2s}', textposition='outside')\n#fig.update_layout(uniformtext_minsize=5.5, uniformtext_mode='hide')\nfig.update_layout(plot_bgcolor='white')\nfig.update_xaxes(showgrid=False, zeroline=False, title=\"% of Respondents\")\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()\n\n\n\n\n\n","8aa1d010":"responses_in_order = ['0-49 employees',\n                      '50-249 employees','250-999 employees',\n                      \"1000-9,999 employees\",\"10,000 or more employees\"]\n\n\nsize = automl_users[1:].groupby(['Q20'])['Q33_A_Part_7'].count().T\nsize = size[responses_in_order]\nsize_per = ((size.T\/size.T.sum()).T)*100\nsize_per.round(1).iplot(kind='barh',xTitle='% of AutoML Users',gridcolor='rgb(250, 242, 242)',\n                        bargap = 0.4,color='#48c980',\n                        theme='white',\n                        bgcolor='white',\n                        title='Company size of AutoML users ')\n","b51fe105":"\nML_in_company = automl_users[1:].groupby(['Q22'])['Q33_A_Part_7'].count().T\nML_in_company.index = [\"don't know\",'No','exploring<br> ML methods',' well established<br> ML methods','recently started<br> using ML methods','use ML methods for<br> generating insights (but do not<br> put working models into production)'] \nML_in_company_per = ((ML_in_company.T\/ML_in_company.T.sum()).T)*100\nML_in_company_per.sort_values(ascending=True).round(1).iplot(kind='barh',\n                                                             xTitle='% of AutoML Users',\n                                                             gridcolor='white',color='#48c980',\n                                                             theme='white')\n\n","8b0ff84b":"responses_in_order = ['0','1-2','3-4','5-9','10-14','15-19','20+']\nds_team = automl_users[1:].groupby(['Q21'])['Q33_A_Part_7'].count().T\nds_team = ds_team.reindex(index=responses_in_order)\nds_team_per = ((ds_team.T\/size.T.sum()).T)*100\n#ds_team_per.index = responses_in_order\nds_team_per.round(1).iplot(kind='barh',xTitle='% of AutoML Users',\n                                        gridcolor='white',color='#48c980',\n                                        bargap = 0.3,\n                                         theme='white')\n","98e04ac2":"plt.figure(figsize=(10,6))\ncompany_vs_teamsize= pd.crosstab(index=automl_users[1:]['Q20'], columns=automl_users[1:]['Q21'])\ncompany_vs_teamsize_per = (((company_vs_teamsize.T\/company_vs_teamsize.T.sum()).T)*100).astype('int')\nsns.heatmap(company_vs_teamsize_per,\n            cmap=\"YlGnBu\", annot=True, cbar=False)\nplt.xlabel('Data Science Team size')\nplt.ylabel('Size of the entire company')\nprint('All values are in percent')\nplt.show()\n","119ecb2b":"# source: https:\/\/www.kaggle.com\/shivamb\/spending-for-ms-in-data-science-worth-it\nd = {\n        '0 USD': 2,\n        '100-999 USD': 24,\n        '1000-9,999 USD': 28,\n        '1-99 USD': 16.8,\n        '10,000-99,999 USD': 18,\n        '100,000 or more USD': 12\n}\n\nxx = [\"0 USD\",'1-99 USD',\"100-999 USD\", \"1000-9,999 USD\", \"10,000-99,999 USD\", \"100,000 or more USD\"]\nxx = [_ + \"<br>(\" +str(d[_])+ \"%)\" for _ in xx]\nyy = [\"\"]*len(d)\nzz = [11, 40, 80, 95, 50, 30]\ncc = ['red', 'green', 'purple', 'orange', \"blue\", \"cyan\"] \n\ntrace1 = go.Scatter(x = xx, y = [\"\"]*len(d), mode='markers', name=\"\", marker=dict(color=cc, opacity=0.4, size = zz))\nlayout = go.Layout(barmode='stack', height=300, margin=dict(l=100), title='Money you (or your team) spent on machine learning and\/or cloud computing services',\n                   legend = dict(orientation=\"h\", x=0.1, y=1.15), plot_bgcolor='#fff', paper_bgcolor='#fff', \n                   showlegend=False)\n\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","ca22c672":"#2020\n\nautoml_users[1:]['Q25'] = automl_users[1:]['Q25'].str.replace('$','')\nmoney_spent_cloud  = automl_users[1:]['Q25'].value_counts(normalize=True)*100\n\n#2019\nautoml_users_2019['Q11'].replace({'> 100,000 (USD)':'100,000 or more (USD)'},inplace=True)\nautoml_users_2019[1:]['Q11'] = automl_users_2019[1:]['Q11'].str.replace('$','')\nmoney_spent_cloud_2019  = automl_users_2019[1:]['Q11'].value_counts(normalize=True)*100\n\ncloud_spending_comparison = pd.concat([money_spent_cloud_2019,money_spent_cloud], axis=1)\ncloud_spending_comparison.rename(columns={'Q25': 2020, 'Q11': 2019},inplace=True)\ncloud_spending_comparison.round(0).iplot(kind='scatter',mode='lines+markers',\n                            \n                                    \n                                    title='Money spent on cloud computing products(2020 vs 2019)',\n                                     xTitle='Money spent(USD)',\n                                     yTitle='% of AutoML users',\n                                    theme='white',\n                                    colors = ['#f1c40f','#48c980'],\n                                    gridcolor='white')\n","cbd7023b":"automl_users[1:]['Q25'] = automl_users[1:]['Q25'].str.replace('$','')\nmoney_spent_cloud  = automl_users[1:]['Q25'].value_counts(normalize=True)*100\n\nresponses_in_order1 = ['0-49 employees',\n                      '50-249 employees','250-999 employees',\n                      \"1000-9,999 employees\",\"10,000 or more employees\"]\n\nresponses_in_order2 = ['0(USD)','1-99','100-999','1000-9,999','10,000-99,999','100,000 or more (USD)']\n\nxc = pd.crosstab(index=automl_users[1:]['Q25'], columns=automl_users[1:]['Q20']).T\nxc_per = ((xc.T\/xc.T.sum()).T)*100\nxc_per = xc_per.reindex(index=responses_in_order1)\nxc_per.round(0).iplot(kind='bar',barmode='stack',\n         #mode='markers+lines',\n         title='Money spent on cloud computing products vs Company size',\n         yTitle='Money spent(USD)',\n         xTitle='Company size',\n         theme='white',symbol='circle-open-dot',\n         #colors = ['orange','lightpink'],\n         gridcolor='white')","6d4f6711":"\nautoml_countries = automl_users[1:]['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country','Q3':'Respondents'})\nautoml_countries['Percentage'] = (automl_countries['Respondents']*100)\/len(automl_users['Q3'])\nautoml_countries['Percentage'] = automl_countries['Percentage'].round(1)\n\n# Replacing the ambigious countries name with Standard names\nautoml_countries['Country'].replace({'United States of America':'United States',\n                                    'Viet Nam':'Vietnam',\n                                    \"People 's Republic of China\":'China',\n                                    \"United Kingdom of Great Britain and Northern Ireland\":'United Kingdom',\n                                     \"Republic of Korea\":'South Korea',\n                                     \"Iran, Islamic Republic of...\":'Iran',\n                                    \"Hong Kong (S.A.R.)\":\"Hong Kong\"},inplace=True)\n\n\nworldmap = [dict(type = 'choropleth', locations = automl_countries['Country'], locationmode = 'country names',\n                 z = automl_countries['Percentage'], colorscale = \"Greens\", reversescale = True, \n                 marker = dict(line = dict( width = 0.5)), \n                 colorbar = dict(autotick = False, title = '% of AutoML users'))]\n\nlayout = dict(title = 'Countrywise adoption of AutoML', geo = dict(showframe = False, showcoastlines = True, \n                                                                projection = dict(type = 'Mercator')))\n\nfig = dict(data=worldmap, layout=layout)\npy.iplot(fig, validate=False)","49c2afb7":"automl_countries['Region'] = np.where(automl_countries['Country'].isin(['Argentina','Brazil','Chile','Colombia','Mexico','Peru'])\n                                      ,'South\/Latin America',automl_countries['Country'])\n\nautoml_countries['Region'] = np.where(automl_countries['Country'].isin(['Ghana','Kenya','Nigeria','South Africa','Morocco','Tunisia'])\n                                      ,'Africa',automl_countries['Region'])\nautoml_countries['Region'] = np.where(automl_countries['Country'].isin(['Australia','Bangladesh','China','India','Israel','Indonesia','Japan','Malaysia','Nepal','Pakistan',\n                                                                        'Philippines','South Korea','Singapore','Republic of Korea','Sri Lanka','Taiwan','Thailand','Vietnam'])\n                                      ,'Asia & Pacific(APAC)',automl_countries['Region'])\nautoml_countries['Region'] = np.where(automl_countries['Country'].isin(['Belarus','Belgium','France','Germany','Greece','Ireland','Italy','Netherlands',\n                                                                        'Poland','Portugal','Romania','Russia','Spain','Sweden','Switzerland','Turkey',\n                                                                        'Ukraine','United Kingdom','Egypt','Iran','Saudi Arabia','United Arab Emirates'])\n                                      ,'Europe & Middle East(EMEA)',automl_countries['Region'])\nautoml_countries['Region'] = np.where(automl_countries['Country'].isin(['Canada','United States'])\n                                      ,'North America',automl_countries['Region'])\n","b22fb164":"# Importing the world_coordinates dataset\nworld_coordinates = pd.read_csv('..\/input\/iso-country-codes-global\/wikipedia-iso-country-codes.csv')\nworld_coordinates.rename(columns={'English short name lower case':'Country'},inplace=True)\n\n# Merging the coordinates dataframe with original dataframe\nautoml_countries = pd.merge(automl_countries, world_coordinates,on='Country')\n\n\n\n\n","afe13910":"\n\nfig = px.scatter_geo(automl_countries, locations=\"Alpha-3 code\", color=\"Region\",\n                    size=\"Percentage\",text='Country',size_max = 35,title='Region wise adoption of AutoML in 2020',\n                     projection=\"natural earth\")\nfig.show()","f6b843fd":"timeline= pd.read_csv('..\/input\/automl-google-trends-data\/Searches.csv')\ngeomap= pd.read_csv('..\/input\/automl-google-trends-data\/geoMap.csv')\nrelated_entities = pd.read_csv('..\/input\/automl-google-trends-data\/relatedEntities.csv')\nrelated_queries = pd.read_csv('..\/input\/automl-google-trends-data\/relatedQueries.csv')\n\n# Convert string to datetime64\ntimeline['Date'] = timeline['Date'].apply(pd.to_datetime)\ntimeline.set_index('Date',inplace=True)\n","9a9621ea":"# Image source: https:\/\/support.google.com\/trends\/answer\/4359550?hl=en&ref_topic=4365530\n\nfrom PIL import Image\nimport urllib.request\n#url = 'http:\/\/www.example.com\/my_image_is_not_your_image.png'\n\n\nimage_path = '..\/input\/interest-over-time\/interest_over_time.png'\ntrace = go.Scatter(\n                    x = timeline.index,\n                    y = timeline['Search Interest'] ,\n                    orientation='v',\n                    marker = dict(color='#48c980',opacity=0.6,\n                                 line=dict(color='red',width=6)\n                                ),\n                    )\ndata = [trace]\nlayout= go.Layout(title= \" AutoML searches over the years\",\n                  xaxis=dict(title='Years'),\n                  yaxis=dict(title=\"Search Interest\"),\n                  plot_bgcolor='white',\n                  images= [dict(\n                          source=Image.open(image_path),\n                          xref= \"paper\",\n                          yref= \"paper\",\n                          x= 0.4,\n                          y= 1,\n                          sizex= 0.4,\n                          sizey= 0.4,\n                          \n              \n                          opacity= 1,\n                          xanchor= \"right\", \n                          yanchor=\"top\",\n                          layer= \"above\")])\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","8151d17b":"worldmap = [dict(type = 'choropleth', locations = geomap['Country'], locationmode = 'country names',\n                 z = geomap['Number of Searches'], colorscale = \"Greens\", reversescale = True,autocolorscale=False, \n                 marker = dict(line = dict( width = 1)), \n                 colorbar = dict(autotick = False, title = 'Search Interest'))]\n\nlayout = dict(title = 'AutoML searches trend on Google', geo = dict(showframe = False, showcoastlines = True, \n                                                                projection = dict(type = 'equirectangular')))\n\nfig = dict(data=worldmap, layout=layout)\npy.iplot(fig, validate=False)","d8c6e507":"fig, (ax1, ax2,) = plt.subplots(1, 2, figsize=[26, 8])\nsns.set_color_codes(\"pastel\")\n\nfont = '..\/input\/quicksandboldttf\/Quicksand-Bold.ttf'\nwordcloud = WordCloud(font_path=font,\n                       width=1000,\n                       height=800,\n                       colormap='PuRd', \n                       margin=0,\n                       max_words=2000, # Maximum numbers of words we want to see \n                       min_word_length=3, # Minimum numbers of letters of each word to be part of the cloud\n                       max_font_size=80, min_font_size=2,  # Font size range\n                       background_color=\"white\").generate((\" \").join(related_entities['Related Entities'].to_list()))\n\n\nax2= sns.barplot(x=\"Search Interest\", y=\"Related Queries\", data=related_queries,\n            label=\"Total\")\nax2.set_ylabel('')  \nax2.set_title('Queries related to AutoML');\n\n\n\nax1.imshow(wordcloud)\nax1.axis('off')\nax1.set_title('Topics related to AutoML');\n\n\n","05b1fd17":"\nstop_words = set(stopwords.words('english'))\n\n# text preprocessing helper functions\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n\ndef text_preprocessing(text):\n    \"\"\"\n    Cleaning and parsing the text.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(remove_stopwords)\n    return combined_text\n\n# Applying the cleaning function to both test and training datasets\n\ntweet_df = pd.read_csv('..\/input\/tweets-related-to-automl-in-2020\/tweets_data.csv')\ntweet_df['text'] = tweet_df['text'].apply(str).apply(lambda x: text_preprocessing(x))\n\n\nwords_in_tweet = [tweet.lower().split() for tweet in tweet_df['text']]\n\n\n# List of all words across tweets\nall_words = list(itertools.chain(*words_in_tweet))\n\n# Create counter for common words\ncounts_words = collections.Counter(all_words)\n\nclean_tweets = pd.DataFrame(counts_words.most_common(20),\n                             columns=['words', 'count'])\n\n\n# Plot horizontal bar graph\nclean_tweets.sort_values(by='count').iplot(kind='barh',x='words',\n                      y='count',title='Top 20 most Common Words Found in Tweets',\n                      gridcolor='white',color='#48c980', theme='white',xTitle='count')\n\n\n\n\n\n\n","f1f229bb":"# Create list of lists containing bigrams in tweets\nterms_bigram = [list(bigrams(tweet)) for tweet in words_in_tweet]\n\n# Flatten list of bigrams in clean tweets\nbigrams_all = list(itertools.chain(*terms_bigram))\n\n# Create counter of words in clean bigrams\nbigram_counts = collections.Counter(bigrams_all)\n\nbigram_df = pd.DataFrame(bigram_counts.most_common(40),\n                             columns=['bigram', 'count'])\n\n# Plot horizontal bar graph\nfig, ax = plt.subplots(figsize=(10, 8))\n\nbigram_df[:20].sort_values(by='count').plot.barh(x='bigram',\n                      y='count',\n                      ax=ax,\n                      color='#48c980')\n\nplt.show()\n","3cf8d27d":"import networkx as nx\n\n# Create dictionary of bigrams and their counts\nd = bigram_df.set_index('bigram').T.to_dict('records')\n\n# Create network plot \nG = nx.Graph()\n\n# Create connections between nodes\nfor k, v in d[0].items():\n    G.add_edge(k[0], k[1], weight=(v * 5))\n\n#G.add_node(\"automl\", weight=100)\n\nfig, ax = plt.subplots(figsize=(18, 10))\n\npos = nx.spring_layout(G, k=2)\n\n# Plot networks\nnx.draw_networkx(G, pos,\n                 font_size=16,\n                 width=3,\n                 edge_color='grey',\n                 node_color='green',\n                 with_labels = False,\n                 ax=ax)\n\n# Create offset labels\nfor key, value in pos.items():\n    x, y = value[0]+.135, value[1]+.045\n    ax.text(x, y,\n            s=key,\n            bbox=dict(facecolor='yellow', alpha=0.25),\n            horizontalalignment='center', fontsize=13)\n    \nplt.show()","b9b97000":"> **\ud83d\udccc Key Points\u00a0:**\n* Automatic model selection is most used followed closely by Automatic Hyerparameter and Automatic data Augmentation. \n* The usage of Automatic feature engineering is less as compared to others. One of the plausible reasons could be that since feature engineering relies heavily on domain expertise, people prefer to do it manually.\n* Automatic data Augmentation and Automatic Hyprparameter tuning are used together by most of the users.\n* The Year 2020 has seen a better adoption of the AutoML tools as compared to 2019.\n* The adoption of opensource AutoML tools is higher than enterprise AutoML tools. AutoSklearn has shown maximum rise in adoption. In the enterprise domain, Google Cloud gained about 11% growth in adoption and 4% by H2O Driverless AI. \n\n*****\n<a href=\"#101\">Back to Top<\/a>","12c8c810":"> **\ud83d\udccc Key Points\u00a0:**\n* It appears most of the AutoML users work for smaller 'Startup' type companies having a strength of less than 50 employees.","6f5f7993":"\n<div id=\"22\"><\/div>\n\n<font color='#1E8449' size=5>2.2 People who responded to the AutoML question in 2020.<\/font><br>\n\nSo there are **20036 respondents** this year. Let's look at how many of these use the AutoML tool in some form. For this, *I analysed the Question 33_A_Part_7: Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis* ? since it gives a direct understanding into the use of AutoML.","5eb7ccea":"> **\ud83d\udccc Key Points\u00a0:**\n>\n> *  Even though there are more than [five million registered users on Kaggle](https:\/\/www.kaggle.com\/general\/164795), the survey numbers are quite less.\n> \n> * The resuts show that around 67% of the total respondents in 2020 didnot answer the question pertaining to AutoML. Out of the 33% who answered the AutoML question, only about 10% actually use AutoML tools in some form.\n>\n> * Another way to look at this is that out of the people who answered the AutoML question, **30% use AutoML tools in some form**. In the next part of the analysis, we'll focus our attenton only on the AutoML users.\n\n\n*****\n<a href=\"#101\">Back to Top<\/a>\n","1f96b0be":"![](https:\/\/imgur.com\/Ydtf8b2.png)\n\n\n*****\n<a href=\"#101\">Back to Top<\/a>\n\n","9cf9a44d":"<div id=\"72\"><\/div>\n\n<font color='#1E8449' size=5 >7.2 AutoML - Regionwise adoption in 2020<\/font><br> \n\nWhile a contrywise usage analysis is useful, focussing on regions than countries could give us more insight if we look at it from a business point of view. Here the countries have been grouped into five major regions i.e\n\n* Asia & Pacific or APAC\n* North America\n* Europe & Middle East or EMEA\n* Latin America or LATAM\n* Africa\n","15bebe92":"\n<div id=\"4\"><\/div>\n\n<font color='#1E8449' size=6>4. Analysis of AutoML Users<\/font><br> \n\nWe now have an idea about the different kinds of AutoML tools and techniques being used by respondents.Let's now analyse the AutoML users under the following heads:\n* Job titles, \n* Machine learning & Coding Experience, and their\n* Job Role\n\nA comprehensive relationship analysis has been done between various attribute of AutoML users and the graphs below are self explanatory.Click on the legend in the graphs to isolate a particluar category. Here is a demo screengrab to demonstrate the process:\n![](https:\/\/imgur.com\/mFUTL7I.gif)\n\n\n<div id=\"41\"><\/div>\n\n<font color='#1E8449' size=5>4.1 Current Job Titles<\/font><br> \n\nAnalysing the Job Titles of the AutoML users and comparing it with the usage of different AutoML categories should give us good insights about the prederence of the users. We'll first look at the job titles of the users and then see if there is a relation between the titles and the usage of various AutoML tools. Specifically we want to look if there is relation between the two.","a0be566c":"<div id=\"8231\"><\/div>\n\n<font color='#1E8449' size=3.5 >8.2.2.1 Visualizing Networks of Co-occurring Word<\/font><br> \n\nWe shall now use these bigrams to visualize the top occurring bigrams as networks using the Python package NetworkX. ","e581a23d":"<div align='center'><font size=\"5\" color=\"#1E8449\">An analysis of the 2020 Kaggle ML and DS\u00a0Survey for the adoption of Automated Machine Learning in the industry<\/font><\/div>\n\n<hr>\n\n<img src='https:\/\/image.freepik.com\/free-vector\/dashboard-consolidating-metrics-computer-screen-business-intelligence-dashboard-business-analytics-tool-business-intelligence-metrics-concept_335657-1890.jpg' width=600>\n<div align=\"center\"><font size=\"2\">Source: <a href=\"https:\/\/www.freepik.com\/vectors\/computer\">Computer vector created by vectorjuice - www.freepik.com<\/a><\/font><\/div>  \n","40ea8630":"As expected words like automl, datascience, machinelearning and ai occur quite frequently in the tweets.","1a9f0acf":"\n<div id=\"44\"><\/div>\n<font color='#1E8449' size=5>4.4 Job Roles<\/font><br>\n\nIn this section we'll see at different kinds of activities that the AutoML users are involved in as part of their job role.","e335ecfe":"> **\ud83d\udccc Key Points\u00a0:**\n* Most AutoML users analyze and understand data to influence product or business decisions. This means ultimately the use of AutoML is tied to ROI on business and providing results for stakeholders.\n\n","ae1aa6c9":"<div id=\"42\"><\/div>\n\n<font color='#1E8449' size=5>4.2 Machine Learning Experience<\/font><br>\n\nWe looked at the various titles of the AutoML users, it now time to look their experiences wrt Machine Learning and see how it relates to AutoML use in general.","686d867a":"This is interesting. Automatic data Augmentation and Automatic Hyprparameter tuning are used together by most of the users.Again, Automatic data augmentaton is mstly used with Automatic model selection. This shows there isn't a clear pattern and the usage largely depends upon the experience and task at hand.\n\n\n<div id=\"33\"><\/div>\n\n<font color='#1E8449' size=5>3.3  AutoML tools and their usage<\/font><br>\nHaving looked at the categories, we'll now look at the specific AutoML tools and  their adoption among the respondents of the survey. The tools are fairly known known names in the data science space but if here I have included links to their source incase you want to study more about them.","380dbb9e":"\n<div id=\"5\"><\/div>\n\n<font color='#1E8449' size=6>5. Companywise AutoML usage analysis<\/font><br>\n\n<div id=\"51\"><\/div>\n\n<font color='#1E8449' size=5>5.1 Company size of the AutoML users<\/font><br>\n\nWe've analysed the usage and the kind of AutoML tools preferred by AutoML users. However, looking at users in isolation without looking at the companies that they work for isn't advisable. In this section we look at the overall companies' size and then the Data Science Team size to see if there is a relationship bwtween the two. Just like in the previous section, we'll use these details to identify the most preferred company portfolio b the AutoML users.\n","7c89d146":">  ### *AI and machine learning is still a field with high barriers to entry that requires expertise and resources that few companies can afford on their own: Fei-Fei\u00a0Li*\n\n\nArtificial Intelligence(AI) has the potential to make a big difference in every facet of our lives, especially in areas like healthcare, education, and environmental conservation. However, many enterprises still struggle to deploy machine learning solutions effectively. It is primarily due to the issues of talent, time, and trust, which is prevalent in many businesses.\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*ykOYaXTmv8Mrb8uYYESMfA.png)\n\n\n* The traditional machine learning(ML) process heavily relies on human expertise. As a result, before starting on the ML journey, a company needs to invest in expert data scientists, researchers, and mathematicians. Unfortunately, there is a considerable **talent gap** with an [acute shortage of experienced and seasoned data scientists in the industry today](http:\/\/https:\/\/www.theverge.com\/2017\/12\/5\/16737224\/global-ai-talent-shortfall-tencent-report).\u00a0\n* Secondly, **time** is of the essence here. When machine learning solutions drive business decisions, it is crucial to get the results quickly. Some of the current ML solutions take months to deploy, which affects their outcomes. Also, due to the heavy manual dependence, there are chances of errors creeping in the workflow.\u00a0\n* Finally, it is imperative to tackle the issue of **trust**. A lot of companies fail to translate model predictions into understandable terms for stakeholders. Although there are systems in place for interpretability and explainability in conventional ML systems, lack of knowledge and experience makes the implementation hard.\n\n\nAutoML is an effort towards democratizing machine learning by making its power available to everybody, rather than a select few. AutoML enables people with diverse skillsets to work on ML problems. By automating the repetitive tasks, it allows data scientists to focus on essential aspects of ML pipeline like data gathering and model deployment. \n\n\n<font color='#1E8449' size=6>Motivation and Methodology<\/font><br>\n\nThis notebook is a deep dive into the current AutoML solutions and preactises. The idea is to:\n* Utilise the Kaggle survey data to see how the AutoML solutions have penetrated the AI ecosystem and what the future holds for this industry. \n* Secondly, **I work as a Data Science Evangelist for H2O.ai** - An AutoML company,Hence, this analysis will be a way for me to understand how Kagglers' in particluar engage with AutoML tools. \n\nIn this notebook, we shall analyze the AutoML usage and adoption in the survey under six different categories, namely:\n![](https:\/\/imgur.com\/oQTjHhe.png)\n*****\n\n<div id=\"101\"><\/div>\n\n<font color='#1E8449' size=6>Contents<\/font><br>\n\n<a href=\"#1\">1. Automated Machine Learning : An Introduction<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#11\">- 1.1 Background and History<\/a>   \n\n<a href=\"#2\">2. An Overview of the Respondents<\/a>  \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#21\">- 2.1 Total number of Survey respondents<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#22\">- 2.2 People who responded to the AutoML question in 2020<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#23\">- 2.3 AutoML usage by respondents<\/a> \n\n<a href=\"#3\">3. Common categories and types of AutoML tools<\/a>  \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#31\">- 3.1 AutoML - Category wise usage in 2020<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#32\">- 3.2 AutoML Categories frequently used together<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#33\">- 3.3 AutoML tools and their usage<\/a> \n\n<a href=\"#4\">4. Analysis of AutoML Users<\/a>  \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#41\">- 4.1 Current Job Titles<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#411\">- 4.1.1 Job titles vs AutoML Categories usage<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#412\">- 4.1.2 Job titles vs AutoML Tools usage<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#42\">- 4.2 Machine Learning Experience<\/a>  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#421\">- 4.2.1 Machine Learning experience vs AutoML Tools usage<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#422\">- 4.2.2 Machine Learning experience vs Job Title<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#43\">- 4.3 Coding Experience<\/a> \n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#431\">- 4.2.1 Coding experience vs AutoML Tools usage<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#432\">- 4.2.2 Coding experience vs Machine Learning experience <\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#44\">- 4.4 Job Role<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#45\">- 4.5 AutoML Users Personas<\/a>\n\n<a href=\"#5\">5. Companywise AutoML usage analysis<\/a>  \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#51\">- 5.1 Company size of the AutoML users<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#52\">- 5.2 Machine learning maturity in business<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#53\">- 5.3 Data Science Team Size<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#531\">- 5.3.1 Relationship between Company Size and Data Science Team Size<\/a>\n\n<a href=\"#6\">6. Infrastructure<\/a> \n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#61\">- 6.1 Money spent on Cloud Computing in 2020<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#611\">- 6.1.1 A comparison between expenditure in 2020 and 2019<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#62\">- 6.2 Money spent vs Company size<\/a>\n\n<a href=\"#7\">7. AutoML users around the globe<\/a>  \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#71\">- 7.1 AutoML - Countrywise adoption in 2020<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#72\">- 7.2 AutoML - Regionwise adoption in 2020<\/a>   \n\n<a href=\"#8\">8. Social Media Analysis : Twitter and Google Trends<\/a>  \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#81\">- 8.1 Google Trends data analysis<\/a> \n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#811\">- 8.1.1 Interest over time<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#812\">- 8.1.2 Interest over Region<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#813\">- 8.1.3 Related Topics and Queries related to AutoML<\/a> \n<br>&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#82\">- 8.2 Twitter data analysis<\/a> \n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#821\">- 8.2.1 Common Words Found in Tweets<\/a>\n<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#822\">- 8.2.2 Exploring Co-occurring Words (Bigrams)<\/a>\n\n<a href=\"#9\">9. Conclusion<\/a> \n\n<a href=\"#10\">10. References<\/a> \n","eccdf765":"> **\ud83d\udccc Key Points\u00a0:**\n* Most AutoML users have 1-2 years or less than an year of machine learning experence.\n* Another unique thing to notice here is that people donot use machine learning methods also use AutoML methods.\n* Most of the Data Scientists have ether 1-2 years of experience followed by 5-10 years.\n\n","3950221d":"\nThe pattern for spend remains the same in 2020 and 2019 except that there are two important things to gain from this analysis:\n* More people\/companies are spending on cloud compute in 2020 as compared to 2019\n* In 2019 around 24% people didnot spend anything on cloud compute. The percentage has fallen to 2 in 2020.\n\n\n<div id=\"62\"><\/div>\n\n<font color='#1E8449' size=5>6.2 Money spent vs Company size<\/font><br>\n\nDo bigger companies spend more?","bd5f96bd":"> **\ud83d\udccc Key Points\u00a0:**\n* Maximum adoption of AutoML is by Data Scientists and Machine Learning Engineers.This shows tha AutoML usage is now becoming an important part of the ML workflow.\n* Adoption of Automated Model Architecture search tools is comparatively less.\n* Both Enterprise based and Open source AutoML tools are used with Auto-Sklearn showing a massive adoption followed by Google AutoML.","23f502e3":"<div id=\"10\"><\/div>\n\n<font color='#1E8449' size=6 >10. References & Acknowledgement<\/font><br> \n\n\n* Title Image: <a href=\"http:\/\/www.freepik.com\">Designed by Freepik<\/a>\n* [2020 Kaggle Data Science & Machine Learning Survey](https:\/\/www.kaggle.com\/paultimothymooney\/2020-kaggle-data-science-machine-learning-survey) by Paul Mooney\n* [Spending $$$ for MS in Data Science - Worth it ?](https:\/\/www.kaggle.com\/shivamb\/spending-for-ms-in-data-science-worth-it) by Shivam Bansal\n* https:\/\/arxiv.org\/pdf\/1908.05557.pdf\n* [what-topics-from-where-to-learn-data-science](https:\/\/www.kaggle.com\/sonmou\/what-topics-from-where-to-learn-data-science)  \n* [Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence](https:\/\/arxiv.org\/abs\/2002.04803)\n* https:\/\/www.prnewswire.com\/news-releases\/automated-machine-learning-automl-market-301035747.html\n* https:\/\/trends.google.com\/trends\/explore?q=AutoML\n\n*****\n","3c63604e":"\n<div id=\"412\"><\/div>\n\n<font color='#1E8449' size=4>4.1.2 Job titles vs AutoML Tools usage<\/font><br> ","06f39ce4":"So, **Automatic model selection is used by almost 40% of the AutoML users**. The next in line is Automatic hyperparameter tuning and Automatic data Augmentation.\n\n<div id=\"32\"><\/div>\n\n<font color='#1E8449' size=5>3.2  AutoML Categories frequently used together<\/font><br>\nLet's see which categories are used together often. This will give an idea of the preferences of the users.\n\n","484f8860":"\n<div id=\"82\"><\/div>\n\n<font color='#1E8449' size=5 >8.2 Twitter data analysis<\/font><br> \n\nFinally, we are going to use of Twitter as a source of information to  understand the sentiment around AutoML. Since this can be a vast source of information, we'll limit the data around the popular hasthags i.e #automl, #AutoML, #automl and #AutomatedML. The tweets have been collected from 1st Jan 2020 uptill 31st Dec 2020.You can access this data [here](https:\/\/www.kaggle.com\/parulpandey\/tweets-related-to-automl-in-2020).\n\n\n<div id=\"821\"><\/div>\n\n<font color='#1E8449' size=4.5 >8.2.1 Common Words Found in Tweets<\/font><br> \n\nLet's start by analysing the common words in the tweets. For this we'll need to clean the data and get rid of characters like - RT,#,@ etc. Additionally, we'll also remove the stop words. The cleaned form of tweets look like this:\n\n","419a4301":"<div id=\"31\"><\/div>\n\n<font color='#1E8449' size=5>3.1 AutoML -  Category wise\u00a0usage in 2020<\/font><br>\nFirst, let's have a look at the overall AutoML usage i.e AutoML usage with respect to all the respondents.","c4c77954":"There are some pretty obvious bigrams like datascience and python; python and r; machinelearning and deeplearning etc but there are also words like nlp and nosql and nosql and iot which occur together. This is petty interesting.","2774ed24":"<div id=\"3\"><\/div>\n\n<font color='#1E8449' size=6>3. Common categories and types of AutoML tools<\/font><br>\nLet's now focus our analysis on the six key areas -  AutoML Tools, Users, Location, Company & Teams, Age, Infrastructure and social media analysis wrt the year 2020\n\nWe'll start by going deeper into the analyses of the different categories and types of AutoML tools given in the survey, But before that it is important to understand what each of the categories  means.      ","db08f44a":"<div id=\"7\"><\/div>\n\n<font color='#1E8449' size=6 >7. AutoML users around the globe<\/font><br> \n\n\nWe have seen how different companies and teams are adopting and using AutoML tools and technologies.However, a geographical analysis is also important to understand where the different users are located in the world. We'll be assesing **countrywise** as well as **region wise** adoption of AutoML. This could be particularly useful from business and marketing point of view.\n\n<div id=\"71\"><\/div>\n\n<font color='#1E8449' size=5 >7.1 AutoML - Countrywise adoption in 2020<\/font><br> \n","0966b099":"\n<div id=\"52\"><\/div>\n\n<font color='#1E8449' size=5>5.2 Machine learning maturity in business<\/font><br>\n\nSo, what is kind of machine learning work that these companies are engaged in? Let's find out.","1768e561":"*****\n<a href=\"#101\">Back to Top<\/a>\n","121b5e40":"> **\ud83d\udccc Key Points\u00a0:**\n* It is interesting to see that although most of AutoML users work for smaller companies, the ML methods used in these companies  are pretty mature as compared to their counterparts.","7b5528d0":"Among the specific AutoML tools, Auto-Sklearn shows the maximum usage followed by another opensource tool called Autokeras.This is the findings for the year 2020. it'll also be helpful to look at the pattern for year 2019 to see which tool has witnessed the maximum growth in terms of usage.","e776d0ba":"> **\ud83d\udccc Key Points\u00a0:**\n* Most AutoML users have 3-5 years  of coding experence.\n* A large percent of AutoML users without any ML experience have sufficient coding experience.\n* For others the ML experience correlated with the coding experience.","c888f56c":"> **\ud83d\udccc Key Points\u00a0:**\n* As per the available data, most of the AutoML users belong to India and the US. This is true since most of the respondents are also from these two countries only.\n* Another way to look at this data is from a Region wise perspective. The Asia Pacific or the APAC Region shows maximum adoption followed by North America & European market. Interestingly, the same results are observed during a market research study done by [psmarketresearch.com.](https:\/\/www.prnewswire.com\/) Here is a [link](https:\/\/www.psmarketresearch.com\/market-analysis\/automated-machine-learning-market) to their report. The figure below has been borrowed from the same report.\n\n![](https:\/\/www.psmarketresearch.com\/img\/GLOBAL-AUTOMATED-MACHINE-LEARNING-MARKET.png)\n\n###### source: https:\/\/www.prnewswire.com\/news-releases\/automated-machine-learning-automl-market-301035747.html\n\n******\n\n\n<a href=\"#101\">Back to Top<\/a>","95fff4d9":"<div id=\"45\"><\/div>\n\n<font color='#1e8449' size=5>4.5 AutoML Users Personas<\/font><br>\n\nBased on the analysis in this section, four major types of personas can be identified amongst AutoML users who participated in the survey. These personas dhoul give a good idea about the kind of people usng the AutoML tools and their preferences could help the companies designing and building such tools.\n\n<img src='https:\/\/imgur.com\/KV7LhNW.png' width=1000>\n\n\n<a href=\"#101\">Back to Top<\/a>\n\n*****","91be5ec8":"<div id=\"8\"><\/div>\n\n<font color='#1E8449' size=6 >8. Social Media Analysis : Twitter and Google Trends<\/font><br> \n\nNo analysis today is complete without having a look at what the social media handles and the Google trends say.Not only does this data give an idea about the general sentiment of the public, but it also offers a way to understand how a particluar tool or product is received by the public. For this particular I used the data from two sources:\n* Twitter data pertaining to AutoML for the year 2020, and\n* Google trends data for the year 2020 for AutoML and related searches.\n\nThe dataset has been uploaded on Kaggle and made publically available here and here. More details into collecting the data has been mentioned in the description of each dataset. Hence, in this notebook I shall limit myself to only the analysis of the data to see if we can actually discover something useful.\n\n\n<div id=\"81\"><\/div>\n\n<font color='#1E8449' size=5 >8.1 Google Trends data analysis<\/font><br> \n\nGoogle Trends is a website by Google that analyzes the popularity of top search queries in Google Search across various regions and languages. The website uses graphs to compare the search volume of different queries over time.[[Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Google_Trends)]\n\nThe dataset consists of four filess:\n\n* Timeline Data\n* GeoMap data\n* Related Entities data\n* Related Queries data\n\nLet's look at what each of them signifies.\n\n<div id=\"811\"><\/div>\n\n<font color='#1E8449' size=4.5 >8.1.1 Interest over time <\/font><br> \n\nTo gauge AutoML searches interest over time, I looked at data for the past five years for the search term :  AutoML and Automated machine learning. The numbers below represent search interest relative to the highest point on the chart for the given region and time. A value of 100 is the peak popularity for the term while 50 means that the term is half as popular. A score of 0 means that there was not enough data for this term. \n","4879d2fd":"<div id=\"812\"><\/div>\n\n<font color='#1E8449' size=4.5 >8.1.2. Interest by Region in 2020 <\/font><br> \n\nLet's see in which location the above terms were most popular during the specified time frame. Again the values are calculated on a scale from 0 to 100, where 100 is the location with the most popularity as a fraction of total searches in that location. A value of 50 indicates a location which is half as popular. A value of 0 indicates a location where there was not enough data for this term.\n","7badd367":"> **\ud83d\udccc Key Points\u00a0:**\n>\nThe social media analysis releals some interesting insights. Let's summarize the important ones:\n\n* There has been increase in the search interest for the term AutoML, since 2017.China shows maximum searches related to the word AutoML. \n* As far as twitter data analysis is concerned, we got some interesting words linked to #automl like machinelearning, datascience, iot, serverless and kubernetes etc.\n\n*****\n\n<div id=\"9\"><\/div>\n\n<font color='#1E8449' size=6 >9. Conclusion & Key Findings<\/font><br> \n\nIn this study, I have presented the findings related to AutoML usage and adoption as per the data available in the 2020 Kaggle survey.There is no doubt that the results reflect the general perception of the Kaggle users, but since the survey pool is large we can definitely get some useful insights for the overall AutoML users' population as well.\n\n\n\ud83d\udd11 The Year 2020 has seen a better adoption of the AutoML tools as compared to 2019. AutoSklearn and AutoKeras lead the opensource brigade while Google AutoML and Driverless AI lead in enterprise versions.\n\n\ud83d\udd11Maximum adoption of AutoML is by Data Scientists who mostly use machine learning to analyze and understand data to influence product or business decisions. Multiple years of experience increases the likelihood of AutoML adoption.\n\n\ud83d\udd11 Most AutoML users work for Startups or small-sized companies having well-established Machine Learning methods.\n\n\ud83d\udd11 The proportion of AutoML users spending on cloud computing has seen an increase in 2020 as compared to 2019, with the average spend being around 10,000 USD.\n\n\ud83d\udd11Overall, the APAC Region shows maximum AutoML adoption followed by North America & EMEA markets.\n\n\ud83d\udd11 There has been an increasing trend in the search interest in AutoML since the beginning of 2017. The advances in AI algorithms and the increasing popularity of automation technologies might be the reasons for this growth.\n\n*****","99aebc22":"\n<div id=\"4\"><\/div>\n\n<font color='#1E8449' size=5>4.3. Coding Experience<\/font><br>\n\nHaving an idea about the ML experience is good, but let's look at how the coding experience of AutoML users affect their choice of usage of AutoML tools.\n","4352e0d6":"<div id=\"2\"><\/div>\n\n<font color='#1E8449' size=6 >2. An Overview of the Respondents<\/font><br>  \nLet's begin by analyzing the 2020 survey's dataset to get a big picture. We shall begin by importing the dataset and the necessary libraries for the analysis. \n\n","bb4df00d":"\n<div id=\"53\"><\/div>\n\n<font color='#1E8449' size=5>5.3 Data Science Team Size<\/font><br>\n\nIt is also important to look at the the strength of Data Science Teams and whether they correlate with the company size in general.\n","a907f168":"Most of the companies\/users spent around 1000-10000 USD on cloud compute in 2020.Even A lot of companies or users also didnot spend anything too. \n\n\n<div id=\"611\"><\/div>\n\n<font color='#1E8449' size=4>6.1.2. A comparison between expenditure in 2020 and 2019<\/font><br>\n\n\n* The AutoML is definitely maturing seeing the usage, but has effet also penetrated into the money being spent on cloud infrastructure?","d2849ddc":"<div id=\"421\"><\/div>\n<font color='#1E8449' size=4>4.2.1 Machine Learning experience vs AutoML Tools usage<\/font><br>","0d239981":"> **\ud83d\udccc Key Points\u00a0:**\n* Well,this shows a trend. Companies having greater than 10,000 employees tend to have larger DS teams and vice versa. ","bb9ebfcb":"\n<div id=\"822\"><\/div>\n\n<font color='#1E8449' size=4.5 >8.2.2 Exploring Co-occurring Words (Bigrams)<\/font><br> \n\nLet's now explore certain words which occuur together in the tweets. Such words are called bigrams.[A bigram or digram is a sequence of two adjacent elements from a string of tokens, which are typically letters, syllables, or words](https:\/\/en.wikipedia.org\/wiki\/Bigram#:~:text=A%20bigram%20or%20digram%20is,%2Dgram%20for%20n%3D2.)\n\n","5b78db66":"India and the US shine when it comes to usage. This is expected since most of the respondents are fro these two countries.","ff3a0a64":"The Google trends show that the word AutoML\/Automated Machine learning has been very popular in **China**. \n\n<div id=\"813\"><\/div>\n\n<font color='#1E8449' size=4.5 >8.1.3. Related Topics and Queries related to AutoML in 2020 <\/font><br> \n\nFinally, we look at two more metrics:\n* Related topics - Users searching for your term also searched for these topics\n* Related queries - Users searching for your term also searched for these queries","923f174e":"<div id=\"6\"><\/div>\n\n<font color='#1E8449' size=6>6. Infrastructure<\/font><br>\n\nOver the past two decades, the cloud computing model has changed the way that most enterprise organizations manage their information technology systems and resources.Cloud computing has created the opportunity for organizations to access the data storage and computing capabilities that they require, on an as-needed basis[[Source](https:\/\/www.sumologic.com\/glossary\/cloud-infrastructure\/)]. Keeping this in mind, we'll see how the AutoML users or the companies they work for utilise the cloud capabilities and their expenditure on them.\n\n\n<div id=\"61\"><\/div>\n\n<font color='#1E8449' size=5>6.1 Money spent on Cloud Computing in 2020<\/font><br>\n\nWe'll start by looking at an overview of the money spent either individually or via team\/company on the cloud computing products in general.","c86843f5":"\nWhen we look at the interest in autoML, we observe an increasing trend since the beginning of 2017. The advances in AI algorithms and the increasing popularity of automation technologies might be the reasons for this growth. ","29a8484d":"More users in larger companies spend above 100000 USD on cloud compute as compared to other categories.Users working in mid size companies tend to spend under 10000 USD, generally. \n\n> **\ud83d\udccc Key Points\u00a0:**\n* Most users\/copmanies using AutoML spend less than 10,000 USD on cloud compute.\n* The proportion of AutoML users spending on cloud has definitely increased in 2020 as compared to 2019 with fewer not spending a single dollar.\n* People working in larger companies tend to spend more as compared to their counterparts in smaller companies. Hoowever, there isn't a clear demarcation and people with different spending habits are found in all categories.\n\n*****\n<a href=\"#101\">Back to Top<\/a>","3309afc0":"![](https:\/\/chart-studio.plotly.com\/create\/?_ga=2.198211114.44164853.1608599147-14683959.1602473809&fid=parulnith:10&fid=parulnith:9)","0c9e26d3":"AutoSklearn and Google Cloud AutoML show maximum increase in usage from 2019. Infact all the tools show an incraese in adoption and usage. Ths will be quite evident from the line chart below.","4760eab5":"<div id=\"11\"><\/div>\n\n<font color='#1E8449' size=5 >1.1 Background and History<\/font><br>  \n\nAutoML solutions have been around for quite some time now. The early AutoML solutions like [AutoWeka](https:\/\/www.cs.ubc.ca\/labs\/beta\/Projects\/autoweka\/) [originated in academia](https:\/\/arxiv.org\/pdf\/1908.05557.pdf) in 2013, followed by [Auto-sklearn](https:\/\/automl.github.io\/auto-sklearn\/master\/) and [TPOT](http:\/\/automl.info\/tpot\/). This triggered a new wave of machine learning and the coming years saw many other AutoML solutions including [Auto-ml](https:\/\/github.com\/ClimbsRocks\/auto_ml), and [Auto-Keras](https:\/\/autokeras.com\/) hitting the market. Simultaneously startups like [H2O.ai](https:\/\/www.h2o.ai\/) and [DataRobot](https:\/\/www.datarobot.com\/) came out with their own versions of automated solutions. More recently, companies like [Amazon](https:\/\/aws.amazon.com\/sagemaker\/autopilot\/), [Google](https:\/\/cloud.google.com\/automl), and [Microsoft](https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/automatedml\/) have also joined the bandwagon.\n\nSome of the solutions like AutoWeka, Auto-Sklearn, TPOT, H2OAutoML are fully open-sourced while DataRobot, Amazon Sagemaker, Google\u2019s AutoML, and DriverlessAI are enterprise-based. There are some other automl solutions also like Uber\u2019s [Ludwig](https:\/\/uber.github.io\/ludwig\/) and Saleforces\u2019s [TransmogrifAI](https:\/\/docs.transmogrif.ai\/en\/stable\/), which are also open-source. This isn\u2019t an exhaustive list but covers the ones that are being used commonly today.\n\n\n\n","dc32f488":"\n<div id=\"411\"><\/div>\n\n<font color='#1E8449' size=4>4.1.1 Job titles vs AutoML Categories usage<\/font><br> ","4b7dd59d":"<div id=\"531\"><\/div>\n\n<font color='#1E8449' size=4>5.3.1 Relationship between Company Size and Data Science Team Size<\/font><br>\n\nThe heatmap below shows the relationship between the Company size and the Data Science Team size in terms of percentage of AutoML users.\n","d390839d":"<div id=\"432\"><\/div>\n<font color='#1E8449' size=4>4.3.2 Coding experience vs ML experience<\/font><br>","3777abdd":"<div id=\"54\"><\/div>\n\n<font color='#1E8449' size=5>5.4 AutoML Users' Company Profile<\/font><br>\n\nBased on our analysis from the given data, we obtain a company profile which related to most of the AutoML users.","2821d22f":"> **\ud83d\udccc Key Points\u00a0:**\n* The data shows that most of the AutoML users work in Data Science teams having more than 20 members or 1-2 members.One of the possible reasons for these two extreme numbers could be that the DS teams depend on the size of the company too. Let's analyse it further.","51c7ca49":"<div id=\"23\"><\/div>\n\n<font color='#1E8449' size=5>2.3 AutoML usage by respondents<\/font><br>\nSo only about 10% of the total survey respondents use AutoML in some form.A lot people left this question blank.This is because a lot of them were not showed this question based on their earlier responses. Therefore to get a better perspective, let's look at the percentage of users out of the people who answered the AutoML question.\n\n","34180f38":"<div id=\"422\"><\/div>\n<font color='#1E8449' size=4>4.2.2 Machine learning experience vs Job Title<\/font><br>","359fc480":"<div id=\"21\"><\/div>\n\n<font color='#1E8449' size=5>2.1 Total number of Survey respondents<\/font><br>\n\nLet's first look at the total respondents who have been participating in the survey since 2017. This should give us an idea of the participants pool.","1a2cd352":"<div id=\"431\"><\/div>\n<font color='#1E8449' size=4>4.3.1 Coding experience vs AutoML Tools usage<\/font><br>","f20a143e":"*****\n\n<div id=\"1\"><\/div>\n\n<font color='#1E8449' size=6 >1. Automated Machine Learning : An Introduction<\/font><br> \n\nAutomated Machine Learning, also known as AutoML, is the process of automating the end to end process of applying machine learning to real-world problems. A typical machine learning process consists of several steps, including ingesting and preprocessing data, feature engineering, model training, and deployment. In conventional machine learning, every step in this pipeline is monitored and executed by humans. [Tools for automatic machine learning (AutoML) aims to automate one or more stages of these machine learning pipelines](https:\/\/arxiv.org\/abs\/2002.04803) making it easier for non-experts to build machine learning models while removing repetitive tasks and enabling seasoned\nmachine learning engineers to build better models faster.\n\n![](https:\/\/opendatascience.com\/wp-content\/uploads\/2019\/07\/Screen-Shot-2019-07-15-at-11.43.38-AM.png)"}}