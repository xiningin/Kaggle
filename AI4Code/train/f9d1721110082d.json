{"cell_type":{"b5ef7145":"code","55f20acc":"code","edb7c1c9":"code","481186bf":"code","4cc0d738":"code","f7f48aba":"code","3db00fba":"code","03f27adf":"code","2ba090bb":"code","12eb9321":"code","333f4215":"code","597704d6":"code","3fc8be39":"code","32efaa06":"code","edc6869e":"code","f74b85b7":"code","7374d453":"code","9475138b":"code","c1faf83d":"code","78e9d930":"code","a34b913f":"code","fcae5ee8":"code","24c5284d":"code","f3427b50":"code","62574340":"code","ceb28380":"code","c72ed020":"code","a2d4b05c":"code","a092c928":"code","600cc91d":"code","b772735d":"code","9b4c931a":"code","16f4f7fb":"code","c141aedd":"code","0048b6f3":"code","a1034c07":"code","9e833e25":"code","f3cb83f7":"code","4e25e5cc":"code","789ab37b":"markdown","fa3f4042":"markdown","ad328d8e":"markdown","ef8ac57b":"markdown","fd80d278":"markdown","09bd1b54":"markdown","b67d8f60":"markdown","caa9fab7":"markdown","3ace1221":"markdown","b70814a2":"markdown","dd492315":"markdown","31da331a":"markdown","d0bfc337":"markdown","37cecde5":"markdown","b3c82628":"markdown","b9e893c7":"markdown","b892a164":"markdown","9aa7c29d":"markdown","88754173":"markdown","14a4fd93":"markdown","3344c9eb":"markdown","3b2c57da":"markdown","7e56af8c":"markdown","310b2f1e":"markdown","f28c943c":"markdown","9c9463a4":"markdown","9e19dd7e":"markdown","180a5795":"markdown","bc2fc125":"markdown"},"source":{"b5ef7145":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","55f20acc":"data = pd.read_csv(\"\/kaggle\/input\/tesla-stock-price\/Tesla.csv - Tesla.csv.csv\")","edb7c1c9":"data.head()","481186bf":"data.info()","4cc0d738":"length_data = len(data)     # rows that data has\nsplit_ratio = 0.7           # %70 train + %30 validation\nlength_train = round(length_data * split_ratio)  \nlength_validation = length_data - length_train\nprint(\"Data length :\", length_data)\nprint(\"Train data length :\", length_train)\nprint(\"Validation data lenth :\", length_validation)","f7f48aba":"train_data = data[:length_train].iloc[:,:2] \ntrain_data['Date'] = pd.to_datetime(train_data['Date'])  # converting to date time object\ntrain_data","3db00fba":"validation_data = data[length_train:].iloc[:,:2]\nvalidation_data['Date'] = pd.to_datetime(validation_data['Date'])  # converting to date time object\nvalidation_data","03f27adf":"dataset_train = train_data.Open.values\ndataset_train.shape","2ba090bb":"# Change 1d array to 2d array\n# Changing shape from (1692,) to (1692,1)\ndataset_train = np.reshape(dataset_train, (-1,1))\ndataset_train.shape","12eb9321":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0,1))\n\n\n# scaling dataset\ndataset_train_scaled = scaler.fit_transform(dataset_train)\n\ndataset_train_scaled.shape","333f4215":"plt.subplots(figsize = (15,6))\nplt.plot(dataset_train_scaled)\nplt.xlabel(\"Days as 1st, 2nd, 3rd..\")\nplt.ylabel(\"Open Price\")\nplt.show()","597704d6":"X_train = []\ny_train = []\n\ntime_step = 50\n\nfor i in range(time_step, length_train):\n    X_train.append(dataset_train_scaled[i-time_step:i,0])\n    y_train.append(dataset_train_scaled[i,0])\n    \n# convert list to array\nX_train, y_train = np.array(X_train), np.array(y_train)\n","3fc8be39":"print(\"Shape of X_train before reshape :\",X_train.shape)\nprint(\"Shape of y_train before reshape :\",y_train.shape)","32efaa06":"X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\ny_train = np.reshape(y_train, (y_train.shape[0],1))\n\nprint(\"Shape of X_train after reshape :\",X_train.shape)\nprint(\"Shape of y_train after reshape :\",y_train.shape)","edc6869e":"X_train[0]","f74b85b7":"y_train[0]","7374d453":"# importing libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout\n\n# initializing the RNN\nregressor = Sequential()\n\n# adding first RNN layer and dropout regulatization\nregressor.add(\n    SimpleRNN(units = 50, \n              activation = \"tanh\", \n              return_sequences = True, \n              input_shape = (X_train.shape[1],1))\n             )\n\nregressor.add(\n    Dropout(0.2)\n             )\n\n\n# adding second RNN layer and dropout regulatization\n\nregressor.add(\n    SimpleRNN(units = 50, \n              activation = \"tanh\", \n              return_sequences = True)\n             )\n\nregressor.add(\n    Dropout(0.2)\n             )\n\n# adding third RNN layer and dropout regulatization\n\nregressor.add(\n    SimpleRNN(units = 50, \n              activation = \"tanh\", \n              return_sequences = True)\n             )\n\nregressor.add(\n    Dropout(0.2)\n             )\n\n# adding fourth RNN layer and dropout regulatization\n\nregressor.add(\n    SimpleRNN(units = 50)\n             )\n\nregressor.add(\n    Dropout(0.2)\n             )\n\n# adding the output layer\nregressor.add(Dense(units = 1))\n\n# compiling RNN\nregressor.compile(\n    optimizer = \"adam\", \n    loss = \"mean_squared_error\",\n    metrics = [\"accuracy\"])\n\n# fitting the RNN\nhistory = regressor.fit(X_train, y_train, epochs = 50, batch_size = 32)","9475138b":"# Losses\nhistory.history[\"loss\"]","c1faf83d":"# Plotting Loss vs Epochs\nplt.figure(figsize =(10,7))\nplt.plot(history.history[\"loss\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Losses\")\nplt.title(\"Simple RNN model, Loss vs Epoch\")\nplt.show()","78e9d930":"# Plotting Accuracy vs Epochs\nplt.figure(figsize =(10,5))\nplt.plot(history.history[\"accuracy\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracies\")\nplt.title(\"Simple RNN model, Accuracy vs Epoch\")\nplt.show()","a34b913f":"y_pred = regressor.predict(X_train)  # predictions\ny_pred = scaler.inverse_transform(y_pred) # scaling back from 0-1 to original\ny_pred.shape","fcae5ee8":"y_train = scaler.inverse_transform(y_train) # scaling back from 0-1 to original\ny_train.shape","24c5284d":"# visualisation\nplt.figure(figsize = (30,10))\nplt.plot(y_pred, color = \"b\", label = \"y_pred\" )\nplt.plot(y_train, color = \"g\", label = \"y_train\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Open price\")\nplt.title(\"Simple RNN model, Predictions with input X_train vs y_train\")\nplt.legend()\nplt.show()\n","f3427b50":"dataset_validation = validation_data.Open.values  # getting \"open\" column and converting to array\ndataset_validation = np.reshape(dataset_validation, (-1,1))  # converting 1D to 2D array\nscaled_dataset_validation =  scaler.fit_transform(dataset_validation)  # scaling open values to between 0 and 1\nprint(\"Shape of scaled validation dataset :\",scaled_dataset_validation.shape)","62574340":"# Creating X_test and y_test\nX_test = []\ny_test = []\n\nfor i in range(time_step, length_validation):\n    X_test.append(scaled_dataset_validation[i-time_step:i,0])\n    y_test.append(scaled_dataset_validation[i,0])","ceb28380":"# Converting to array\nX_test, y_test = np.array(X_test), np.array(y_test)","c72ed020":"print(\"Shape of X_test before reshape :\",X_test.shape)\nprint(\"Shape of y_test before reshape :\",y_test.shape)","a2d4b05c":"X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))  # reshape to 3D array\ny_test = np.reshape(y_test, (-1,1))  # reshape to 2D array","a092c928":"print(\"Shape of X_test after reshape :\",X_test.shape)\nprint(\"Shape of y_test after reshape :\",y_test.shape)","600cc91d":"# predictions with X_test data\ny_pred_of_test = regressor.predict(X_test)\n# scaling back from 0-1 to original\ny_pred_of_test = scaler.inverse_transform(y_pred_of_test) \nprint(\"Shape of y_pred_of_test :\",y_pred_of_test.shape)","b772735d":"# visualisation\nplt.figure(figsize = (30,10))\nplt.plot(y_pred_of_test, label = \"y_pred_of_test\", c = \"orange\")\nplt.plot(scaler.inverse_transform(y_test), label = \"y_test\", c = \"g\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Open price\")\nplt.title(\"Simple RNN model, Prediction with input X_test vs y_test\")\nplt.legend()\nplt.show()","9b4c931a":"# Visualisation\nplt.subplots(figsize =(30,12))\nplt.plot(train_data.Date, train_data.Open, label = \"train_data\", color = \"b\")\nplt.plot(validation_data.Date, validation_data.Open, label = \"validation_data\", color = \"g\")\nplt.plot(train_data.Date.iloc[time_step:], y_pred, label = \"y_pred\", color = \"r\")\nplt.plot(validation_data.Date.iloc[time_step:], y_pred_of_test, label = \"y_pred_of_test\", color = \"orange\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Open price\")\nplt.title(\"Simple RNN model, Train-Validation-Prediction\")\nplt.legend()\nplt.show()","16f4f7fb":"y_train = scaler.fit_transform(y_train)","c141aedd":"from keras.layers import LSTM\n\nmodel_lstm = Sequential()\nmodel_lstm.add(\n    LSTM(64,return_sequences=True,input_shape = (X_train.shape[1],1))) #64 lstm neuron block\nmodel_lstm.add(\n    LSTM(64, return_sequences= False))\nmodel_lstm.add(Dense(32))\nmodel_lstm.add(Dense(1))\nmodel_lstm.compile(loss = \"mean_squared_error\", optimizer = \"adam\", metrics = [\"accuracy\"])\nhistory2 = model_lstm.fit(X_train, y_train, epochs = 10, batch_size = 10)\n","0048b6f3":"plt.figure(figsize =(10,5))\nplt.plot(history2.history[\"loss\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Losses\")\nplt.title(\"LSTM model, Accuracy vs Epoch\")\nplt.show()","a1034c07":"plt.subplots(figsize =(30,12))\nplt.plot(scaler.inverse_transform(model_lstm.predict(X_test)), label = \"y_pred_of_test\", c = \"orange\" )\nplt.plot(scaler.inverse_transform(y_test), label = \"y_test\", color = \"g\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"Open price\")\nplt.title(\"LSTM model, Predictions with input X_test vs y_test\")\nplt.legend()\nplt.show()","9e833e25":"data.iloc[-1]","f3cb83f7":"X_input = data.iloc[-time_step:].Open.values               # getting last 50 rows and converting to array\nX_input = scaler.fit_transform(X_input.reshape(-1,1))      # converting to 2D array and scaling\nX_input = np.reshape(X_input, (1,50,1))                    # reshaping : converting to 3D array\nprint(\"Shape of X_input :\", X_input.shape)\nX_input","4e25e5cc":"simple_RNN_prediction = scaler.inverse_transform(regressor.predict(X_input))\nLSTM_prediction = scaler.inverse_transform(model_lstm.predict(X_input))\nprint(\"Simple RNN, Open price prediction for 3\/18\/2017      :\", simple_RNN_prediction[0,0])\nprint(\"LSTM prediction, Open price prediction for 3\/18\/2017 :\", LSTM_prediction[0,0])","789ab37b":"### Reshape","fa3f4042":"## Thanks for reading, please upvote:)","ad328d8e":"* Which day is the last day in our data?","ef8ac57b":"* Check the first item in y_train\n* It is the price of 50th day","fd80d278":"* We have train data composed of stock open prices over days\n* So, it has 1184 prices corresponding 1184 days\n* My aim is to predict the open price of the next day.\n* I can use a time step of 50 days.\n* I will pick first 50 open prices (0 to 50), 1st 50 price will be in X_train data\n* Then predict the price of 51th day; and 51th price will be in y_train data\n* Again, i will pick prices from 1 to 51, those will be in X_train data\n* Then predict the next days price, 52nd price will be in y_train data","09bd1b54":"<a id=\"10\"><\/a>\n## 10.Creating LSTM Model","b67d8f60":"![image.png](attachment:image.png)","caa9fab7":"## Model predictions for train data ","3ace1221":"* We will get Open column as our dataset\n* Dataset to be converted to array by adding `.values`","b70814a2":"In this notebook, i tried to predict the open price of Tesla Stock by simple RNN Model and LSTM model.<br>\nThose who want to have detailed info on simple RNN and LSTM, may refer to great post below:<br>\nhttp:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs\/\n","dd492315":"* [1. Loading Data](#1) <br>\n* [2.Spliting Data as Train and Validation](#2) <br>\n* [3.Creating Train Dataset from Train split](#3) <br>\n* [4.Normalization \/ Feature Scaling](#4) <br>\n* [5.Creating X_train and y_train from Train data](#5) <br>\n* [6.Creating Simple RNN model](#6) <br>\n* [7.Evaluating Model](#7) <br>\n* [8.Creating Test Dataset from Validation Data](#8) <br>\n* [9.Evaluating with Validation Data](#9) <br>\n* [10.Creating LSTM model](#10) <br>\n* [11.Evaluating LSTM model](#11) <br>\n* [12.Future price prediction](#12) <br>\n","31da331a":"<a id=\"6\"><\/a>\n## 6.Creating RNN model ","d0bfc337":"<a id=\"11\"><\/a>\n## 11.Evaluating LSTM Model","37cecde5":"<a id=\"5\"><\/a>\n## 5.Creating X_train and y_train from Train data","b3c82628":"<a id=\"2\"><\/a>\n## 2.Spliting Data as Train and Validation","b9e893c7":"<a id=\"3\"><\/a>\n## 3.Creating Train Dataset from Train split","b892a164":"* We can predict the open price for the day after 3\/17\/2017--> for  3\/18\/2017.\n* We will use last 50 days Open price as input of our model for this prediction\n* Let us prepare it:","9aa7c29d":"#### <a id=\"4\"><\/a>\n## 4.Normalization \/ Feature Scaling","88754173":"### Converting array and scaling","14a4fd93":"<a id=\"7\"><\/a>\n## 7.Evaluating Model","3344c9eb":"* Dataset values will be in between 0 and 1 after scaling","3b2c57da":"<a id=\"12\"><\/a>\n## 12.Future price prediction","7e56af8c":"<a id=\"9\"><\/a>\n## 9.Evaluating with Validation Data ","310b2f1e":"## Reshape","f28c943c":"<a id=\"1\"><\/a>\n## 1.Loading Data","9c9463a4":"<a id=\"8\"><\/a>\n## 8.Creating Test Dataset from Validation Data ","9e19dd7e":"### Converting to array","180a5795":"* Shape of X_train : 1134 x 50 x 1\n* That means we have 1134 rows, each row has 50 rows and 1 column\n* Lets check the first row: it has 50 rows (open prices of 49 days)","bc2fc125":"### Creating X_test and y_test"}}