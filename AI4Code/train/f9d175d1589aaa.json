{"cell_type":{"3ed2f9b5":"code","b5ca0372":"code","4b9de8e5":"code","5504c661":"code","3ce13a10":"code","6cffabd2":"code","454bc4bb":"code","4ca08c8b":"code","e7f65f4b":"code","d51697b2":"code","dcc99b45":"code","822c7c40":"code","8deff455":"code","57dcc5c5":"code","a884d5c8":"code","0be11332":"code","c9f0711c":"code","d8039e2c":"code","f8d9bbc0":"code","07d77fd6":"code","6359d8c8":"code","306419aa":"code","17121526":"markdown","5d055770":"markdown","44a3e515":"markdown","1b32913a":"markdown","f02c2a91":"markdown","a31309a6":"markdown"},"source":{"3ed2f9b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5ca0372":"import numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n\n# Using Tensorflow Keras instead of the original Keras\nfrom mlxtend.data import loadlocal_mnist\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense","4b9de8e5":"x_train_path = '..\/input\/mnist-dataset\/train-images.idx3-ubyte'\ny_train_path = '..\/input\/mnist-dataset\/train-labels.idx1-ubyte'\n\nx_test_path = '..\/input\/mnist-dataset\/t10k-images.idx3-ubyte'\ny_test_path = '..\/input\/mnist-dataset\/t10k-labels.idx1-ubyte'","5504c661":"x_train, y_train = loadlocal_mnist(x_train_path, y_train_path)\n\nx_test, y_test = loadlocal_mnist(x_test_path, y_test_path)","3ce13a10":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","6cffabd2":"plt.imshow(x_train[5].reshape(28,28),cmap='gray')","454bc4bb":"y_train[5]","4ca08c8b":"plt.imshow(x_train[10].reshape(28,28),cmap='gray')","e7f65f4b":"y_train[10]","d51697b2":"print(x_train.shape, x_test.shape)","dcc99b45":"from tensorflow import keras\n\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)","822c7c40":"#normalize the data \nx_train = x_train \/ 255 \nx_test = x_test \/ 255 ","8deff455":"# Initialize the constructor\n\nmodel = Sequential()","57dcc5c5":"# Define model architecture\n\nmodel.add(Dense(784,activation='relu'))\nmodel.add(Dense(100, activation ='relu'))\nmodel.add(Dense(10,activation='softmax'))","a884d5c8":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","0be11332":"model.fit(x_train, y_train, epochs=10, batch_size=256, verbose=1) ","c9f0711c":"loss, acc = model.evaluate(x_test, y_test, verbose=0)\nprint('Accuracy: %.3f'  % acc)\nprint('Loss: %.3f' % loss)","d8039e2c":"y_predict = model.predict(x_test)","f8d9bbc0":"y_predict = model.predict(x_test)","07d77fd6":"np.argmax(y_predict[0])","6359d8c8":"from keras.layers import Dropout\nmodel2 = Sequential()\n\nmodel2.add(Dense(units=256, input_dim=784,activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(units=128, activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(units=32, activation='relu'))\nmodel2.add(Dense(units=10, activation='softmax'))\n\nmodel2.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel2.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=.1)","306419aa":"loss, acc = model2.evaluate(x_test, y_test, verbose=0)\nprint('Accuracy: %.3f'  % acc)\nprint('Loss: %.3f' % loss)","17121526":"**Getting data**","5d055770":"# Model building","44a3e515":"# Optiimizing using Dropout\n\nDeep learning neural networks are likely to quickly overfit a training dataset \nThe use of droupout regularize\/reduce overfitting. Hence the deeep neural network ","1b32913a":"# Exploratory Data Analysis","f02c2a91":"# Deep Learning mnist ","a31309a6":"**Importing libraries**"}}