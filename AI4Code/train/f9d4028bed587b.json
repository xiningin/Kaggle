{"cell_type":{"3c048546":"code","b1b6d1e5":"code","8044a81a":"code","e09f14bc":"code","c15f5ed3":"code","797c6932":"code","d7305867":"code","7a7f53fa":"code","71c1b87c":"code","b2647a93":"code","7975a9f1":"code","73c2ea04":"code","ff67bbd9":"code","3c6fe1d1":"code","591fd775":"code","aa5f318f":"code","701c11eb":"code","777c70fd":"code","f9911706":"code","4b849b3c":"code","603a4cea":"code","05184e65":"code","24375f79":"code","cfbc445a":"code","c0534a17":"code","fd12f763":"code","f599ccc9":"code","d32d281f":"code","046eecdc":"code","a3b6ec85":"code","98a1476f":"code","af451094":"code","0822adcd":"code","22d8d7fd":"code","2481986b":"code","58415388":"code","c1dc786f":"code","2454a7a3":"code","0ae33959":"code","96edef7a":"code","4e2de663":"code","82a29cd4":"code","dd2a66f1":"code","d4d42ea5":"code","9d1597e1":"markdown","d22687af":"markdown","26561da5":"markdown","8a8a2a5f":"markdown","a79f72bc":"markdown","3f08aa29":"markdown","222038b5":"markdown","d012e8f5":"markdown","1efc17e6":"markdown","6bb7afd6":"markdown","46958bfc":"markdown","ebd55dd3":"markdown","10374522":"markdown","6ec5f397":"markdown","987a9905":"markdown","f23e771e":"markdown","20bff4aa":"markdown","117324f5":"markdown","e50d5a8c":"markdown","cf040ad3":"markdown","3ca43536":"markdown","8453893b":"markdown","7faae894":"markdown"},"source":{"3c048546":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif\nfrom sklearn.svm import LinearSVC # faster then SVC\nimport multiprocessing\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b1b6d1e5":"MAX_CORE_COUNT = multiprocessing.cpu_count()","8044a81a":"train = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')","e09f14bc":"print(f'train shape -  {train.shape}')\ntrain.head()","c15f5ed3":"train.describe().T","797c6932":"train.isna().sum().unique() # not nan","d7305867":"train.target.unique() # binary classification","7a7f53fa":"sns.countplot(train.target) \nplt.title('Count of target types')\nplt.xlabel('Target')\nplt.ylabel('Count')\nplt.show()","71c1b87c":"train.drop(['id', 'target'], axis = 1).hist(figsize = (30, 30)) \nplt.show()","b2647a93":"plt.figure(figsize = (20, 12))\nsns.heatmap(train.corr(), annot = False) ","7975a9f1":"X = train.drop(['id', 'target'], axis = 1)\ny = train.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)","73c2ea04":"# sc = dabl.SimpleClassifier().fit(X_train, y_train)\n# sc.score(X_test, y_test)\n# sc.log_\nsimple_clf = DecisionTreeClassifier()\nbaseline = np.mean(cross_val_score(simple_clf, X_train, y_train, scoring = 'roc_auc', n_jobs = MAX_CORE_COUNT))\n#score of simple classifier without tuning","ff67bbd9":"print(f'roc auc score baseline - {baseline}')","3c6fe1d1":"rndf_clf = RandomForestClassifier()\nstandart_pipeline = Pipeline([('standart_scaler', StandardScaler()), ('model', rndf_clf)])\nminmax_pipeline = Pipeline([('min_max_scaler', MinMaxScaler()), ('model', rndf_clf)])","591fd775":"rndf_clf_pipeline_dict = {\n    'standart' : standart_pipeline,\n    'min_max' : minmax_pipeline\n}\nrandom_forest_score_list = {}","aa5f318f":"def model_cross_val_score(my_pipeline_dict):\n    \"\"\"Function for calculating mean cross validation roc auc score for my pipelines\"\"\"\n    for key, pipe in my_pipeline_dict.items():\n        cv_scores = np.mean(cross_val_score(pipe,X_train, y_train, scoring = 'roc_auc', n_jobs = MAX_CORE_COUNT))\n        print(f\"mean roc auc score: {cv_scores}, for scaler {key}\")","701c11eb":"model_cross_val_score(rndf_clf_pipeline_dict) \n# StandardScaler, MinMaxScaler\n# would like 4 scalers(StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer)\n# but training is so long","777c70fd":"grad_boost_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, loss = 'deviance',\\\n                                           criterion = 'mse')\nstandart_pipeline = Pipeline([('standart_scaler', StandardScaler()), ('model', grad_boost_clf)])\nminmax_pipeline = Pipeline([('min_max_scaler', MinMaxScaler()), ('model', grad_boost_clf)])","f9911706":"grad_boost_clf_pipeline_dict = {\n    'standart' : standart_pipeline,\n    'min_max' : minmax_pipeline\n}\ngrad_boost_score_list = {}","4b849b3c":"#bad score\nmodel_cross_val_score(grad_boost_clf_pipeline_dict) \n# StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer","603a4cea":"k_neigh_clf = KNeighborsClassifier()\nstandart_pipeline = Pipeline([('standart_scaler', StandardScaler()), ('model', k_neigh_clf)])\nminmax_pipeline = Pipeline([('min_max_scaler', MinMaxScaler()), ('model', k_neigh_clf)])","05184e65":"k_neigh_clf_pipeline_dict = {\n    'standart' : standart_pipeline,\n    'min_max' : minmax_pipeline\n}\nk_neigh_score_list = {}","24375f79":"# model_cross_val_score(k_neigh_clf_pipeline_dict) \n# I decided dont use this model, its very slow","cfbc445a":"log_reg_clf = LogisticRegression()\nstandart_pipeline = Pipeline([('standart_scaler', StandardScaler()), ('model', log_reg_clf)])\nminmax_pipeline = Pipeline([('min_max_scaler', MinMaxScaler()), ('model', log_reg_clf)])","c0534a17":"log_reg_clf_pipeline_dict = {\n    'standart' : standart_pipeline,\n    'min_max' : minmax_pipeline\n}\nlog_reg_clf_score_list = {}","fd12f763":"model_cross_val_score(log_reg_clf_pipeline_dict) \n#best score for standart scaler","f599ccc9":"gauss_clf = GaussianNB()\nstandart_pipeline = Pipeline([('standart_scaler', StandardScaler()), ('model', gauss_clf)])\nminmax_pipeline = Pipeline([('min_max_scaler', MinMaxScaler()), ('model', gauss_clf)])","d32d281f":"gauss_clf_pipeline_dict = {\n    'standart' : standart_pipeline,\n    'min_max' : minmax_pipeline    \n}\ngauss_clf_score_list = {}","046eecdc":"model_cross_val_score(gauss_clf_pipeline_dict) \n# so bad","a3b6ec85":"svc_clf = LinearSVC(max_iter=4000)\nstandart_pipeline = Pipeline([('standart_scaler', StandardScaler()), ('model', svc_clf)])\nminmax_pipeline = Pipeline([('min_max_scaler', MinMaxScaler()), ('model', svc_clf)])","98a1476f":"svc_clf_pipeline_dict = {\n    'standart' : standart_pipeline,\n    'min_max' : minmax_pipeline    \n}\nsvc_clf_score_list = {}","af451094":"model_cross_val_score(svc_clf_pipeline_dict) ","0822adcd":"scaler = StandardScaler()","22d8d7fd":"X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","2481986b":"model = LogisticRegression()\nparams = {'max_iter' : range(1000, 12000, 1000), 'C' : np.arange(0.2, 2, 0.2), \\\n         'n_jobs' : [MAX_CORE_COUNT]}","58415388":"grid = GridSearchCV(model, params, cv = 5, scoring='roc_auc', verbose = 3)","c1dc786f":"grid.fit(X_train, y_train)\n#tried to tune solver but got an error","2454a7a3":"grid.best_score_","0ae33959":"grid.best_params_","96edef7a":"best_model = grid.best_estimator_","4e2de663":"not_need_feature = ['id', 'target']\nfeatures = [f for f in train.columns if f not in not_need_feature]","82a29cd4":"x_pred = test[features].values\nx_pred = scaler.transform(x_pred)","dd2a66f1":"test['target'] = best_model.predict(x_pred)","d4d42ea5":"test[['id', 'target']].to_csv('tab_comp_log_reg_pred.csv', index = False)","9d1597e1":"Make a baseline prediction. Use simple model without tuning. Score - mean roc auc score 0.5517265092369377","d22687af":"## COMPETITION LINK \nhttps:\/\/www.kaggle.com\/c\/tabular-playground-series-nov-2021\/overview\n### My kaggle account https:\/\/www.kaggle.com\/jokkojja","26561da5":"# DATA EXPROLATION","8a8a2a5f":"# TUNING","a79f72bc":"Not nan values in train","3f08aa29":"## SVC","222038b5":"# MODELING","d012e8f5":"## RandomForestClassifier","1efc17e6":"Huge std, need to scale data.","6bb7afd6":"## GaussianNB ","46958bfc":"We have train dataset with 102 rows and 600000 columns","ebd55dd3":"Not medium or strong correlation","10374522":"# BASELINE","6ec5f397":"Bimodal distribution and many outliers","987a9905":"binary classification","f23e771e":"## LogisticRegression","20bff4aa":"Need to tune hyperparametrs for best model to get the best score.","117324f5":"# Prediction and make submission","e50d5a8c":"I decided to use pipelines with 2 type of scalers. Min max scaler and standart scaler","cf040ad3":"## KNeighborsClassifier","3ca43536":"Train is balanced dataset","8453893b":"## GradientBoostingClassifier","7faae894":"Logistic regression with standart scaler is the best. KNeighborsClassifier is very slow, I'll comment the cell"}}