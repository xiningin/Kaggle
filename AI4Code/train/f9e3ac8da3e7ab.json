{"cell_type":{"19e4d4be":"code","8567c349":"code","6d3c2bad":"code","84db7f80":"code","7d475d11":"code","4b01a397":"code","57b91543":"code","2c2da116":"code","1578c4a7":"code","c207b1d1":"code","1f427e1f":"code","453d2231":"code","945e345b":"code","42d235e4":"code","055dae5c":"code","12536026":"code","536fd0d1":"code","875f2f40":"code","583ff357":"markdown","aa00fea1":"markdown","ffe92ca7":"markdown","42939821":"markdown","2e958bde":"markdown","2e29bf44":"markdown","53e26645":"markdown","5d6e6900":"markdown","90ce7ae3":"markdown"},"source":{"19e4d4be":"from fastai import *\nfrom fastai.vision import *","8567c349":"!pwd #current directory","6d3c2bad":"!ls ..\/","84db7f80":"!ls ..\/input","7d475d11":"!ls ..\/input\/train","4b01a397":"!ls ..\/input\/train\/train","57b91543":"!ls ..\/input\/train\/train | wc -l #number of classes in train set","2c2da116":"!ls ..\/input\/test","1578c4a7":"!ls ..\/input\/test\/test | wc -l #number of images in dataset","c207b1d1":"path = Path('..\/input') #parent path\n\n#low res data\ndata_64 = (ImageList.from_folder(path\/'train') #have specified the train directory as it has a child dir named train which contains all the classes in folders\n                .split_by_rand_pct(0.1, seed=33) #since there is no validation set, we are taking 10% of the train set as validation set\n                .label_from_folder()#to label the images based on thier folder name\/class\n                .add_test_folder('..'\/path\/'test')#came out of the current directory and specified where test set is at, as it doesnt follow the imagenet style of file structure\n                .transform(get_transforms(), size=64)#using the default transforms and initial size of 64x64\n                .databunch(bs=256)#batch size of 256, be cautious of OOM error when you increase the size of the image decrease the batchsize to be able to fit in the memory\n                .normalize(imagenet_stats))#normalizing to the imagenet stats\n\n#high res data\ndata_256 = (ImageList.from_folder(path\/'train')\n                .split_by_rand_pct(0.1, seed=33)\n                .label_from_folder()\n                .add_test_folder('..'\/path\/'test')\n                .transform(get_transforms(), size=256)\n                .databunch(bs=64)\n                .normalize(imagenet_stats))","1f427e1f":"data_64 #verifying the no. of images, split of different sets and you can observe test has no labels","453d2231":"data_64.c #verifying the no. of classes","945e345b":"learn = cnn_learner(data_64, #training on low res first \n                    models.resnet18, #loading the resenet18 arch with pretrained weights\n                    metrics=accuracy, \n                    model_dir='\/tmp\/model\/') #specifying a different directory as \/input is a read-only directory and will throw an error while using lr_find()","42d235e4":"learn.lr_find() #finds the change in loss with respect to the learning rate\nlearn.recorder.plot()#plots that change","055dae5c":"learn.fit_one_cycle(1, 1e-2)","12536026":"learn.data = data_256 #loading the high res images\nlearn.unfreeze() #unfreezing the inital layers","536fd0d1":"learn.lr_find()\nlearn.recorder.plot()","875f2f40":"learn.fit_one_cycle(1, slice(1e-4,1e-3))","583ff357":"# Progressive resizing | Deatailed walkthrough of the code | Training the whole architecture\n* Trained only 2 epochs and acheived 90%+ accuracy\n* Have used 64x64 res images and 256x256 res images, feel free to fiddle around this to add more such changes or trying different resolutions","aa00fea1":"Thus this is the structure of the dataset\n![struc.jpeg](attachment:struc.jpeg)","ffe92ca7":"### Loading the data to fastai \n* From the last section we know the strcuture of our dataset\n* We shall use the data_block api, you can find about it [here](https:\/\/docs.fast.ai\/data_block.html) and how they expect the file structure to be if you're using `from_folder`","42939821":"### Model | Trasnfer Learning","2e958bde":"### Unfreezing | Resizing \n* Considering the model has beem trained on apt amount of epochs we can now unfreeze the initial layers, to update thier weights \n* Using of high res images now, allowing the model to learn more features","2e29bf44":"Finding the best LR to train on is a important step, as it'll help you converge faster without overshooting.\n\nChoosing 1e-2(10^-2) as the LR as there is a steep drop in loss.","53e26645":"### Importing fastai","5d6e6900":"Using slice to provide the initial layers with lower LR so as to not to change much of its weights","90ce7ae3":"### Browsing the Dataset Structure"}}