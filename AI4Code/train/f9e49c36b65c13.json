{"cell_type":{"0ce9303f":"code","55d993e7":"code","86719667":"code","f0f448eb":"code","bdf31b7a":"code","14fddbfe":"code","cae7e08d":"code","c4e5559a":"code","5819a604":"code","90998c8b":"code","40ccf9e2":"code","e147b279":"code","0834cc67":"code","ebc2ffcd":"code","ec7f4fa2":"code","c1fd73a3":"code","fcda27de":"code","9dfcb256":"code","cbcf87c3":"code","c48613a4":"code","3c049651":"code","e259dc8f":"code","228ab1ce":"code","00cd4782":"code","e73177f2":"code","485c728b":"code","65f768fd":"markdown","bb859689":"markdown","e3795824":"markdown","ce666490":"markdown","215d636e":"markdown","370d8e76":"markdown","3632a0c8":"markdown","edb080e1":"markdown","14fc9fc1":"markdown","5e5fd714":"markdown","f044963a":"markdown","4f76ad8f":"markdown"},"source":{"0ce9303f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","55d993e7":"import glob\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio, display\nimport matplotlib.pyplot as plt\n","86719667":"def read_path_audio_and_target(is_train=True):\n    paths, targets = [], []\n    \n    if is_train:\n        name = 'train'\n    else:\n        name = 'valid'\n        \n    for cls in ['student', 'professor']:\n        path = glob.glob(f'\/kaggle\/input\/mini-speech-diarization\/dataset\/{name}\/{cls}\/*')\n    \n        if cls == 'student':\n            target = [0 for _ in range(len(path))]\n        else:\n            target = [1 for _ in range(len(path))]\n\n        paths.extend(path)\n        targets.extend(target)\n    \n    return paths, targets","f0f448eb":"paths_train, targets_train = read_path_audio_and_target(is_train=True)\npaths_test, targets_test = read_path_audio_and_target(is_train=False)","bdf31b7a":"print(paths_train[0])\nsample_student, sr = librosa.load(paths_train[0])\ndisplay(Audio(sample_student, rate=sr))","14fddbfe":"print(paths_train[-1])\nsample_professor, sr = librosa.load(paths_train[-1])\ndisplay(Audio(sample_professor, rate=sr))","cae7e08d":"def reshape_sound_and_target(path_sound, targets, segment_size_t=1):\n    \"\"\"\n    \n    Parameters:\n    path_sound, \n    targets, \n    segment_size_t: segment size in seconds\n    \"\"\"\n    segments_sound, segments_target = [], []\n    \n    for i in range(len(path_sound)):\n        # load\n        y, sr = librosa.load(path_sound[i])\n\n        signal_len = len(y) \n        # segment size in samples\n        segment_size = int(segment_size_t * sr)  \n        # Break signal into list of segments in a single-line Python code\n        segments = [y[x:x + segment_size] for x in np.arange(0, signal_len, segment_size)]\n\n        target = [targets[i] for _ in range(len(segments))]\n\n        segments_sound.extend(segments)\n        segments_target.extend(target)\n\n    segments_sound = np.array(segments_sound)\n    segments_target = np.array(segments_target)\n    \n    return segments_sound, segments_target, sr","c4e5559a":"segment_size_t = 0.5\n\nsegments_sound_train, segments_target_train, sr = reshape_sound_and_target(paths_train, targets_train, segment_size_t)\nsegments_sound_test, segments_target_test, _ = reshape_sound_and_target(paths_test, targets_test, segment_size_t)","5819a604":"segments_sound_train.shape, segments_target_train.shape, sr","90998c8b":"def create_feature(segments, sr):\n    features = [\n            ('chroma_stft', librosa.feature.chroma_stft),\n            ('rms', librosa.feature.rms),\n            ('spectral_centroid', librosa.feature.spectral_centroid),\n            ('spectral_bandwidth', librosa.feature.spectral_bandwidth),\n            ('spectral_rolloff', librosa.feature.spectral_rolloff),\n            ('zero_crossing_rate', librosa.feature.zero_crossing_rate),\n            ('mfcc', librosa.feature.mfcc)\n    ]\n\n    features_segmentation = []\n\n    for seg in segments:\n        feature_segmentation = []\n        try:\n            for name, func in features:\n\n                if name in ['rms', 'zero_crossing_rate']:\n                    y0 = func(y=seg)\n                    feature_segmentation.append(np.mean(y0))\n\n                elif name == 'mfcc':\n                    y0 = func(y=seg, sr=sr)\n                    for i, m in enumerate(y0, 1):\n                        feature_segmentation.append(np.mean(m))\n\n                else:\n                    y0 = func(y=seg, sr=sr)\n                    feature_segmentation.append(np.mean(y0)) \n\n        except Exception as e:\n            print(e)        \n\n        features_segmentation.append(feature_segmentation)\n\n    features_segmentation = np.array(features_segmentation)\n    return features_segmentation","40ccf9e2":"feature_train = create_feature(segments_sound_train, sr)\nfeature_test = create_feature(segments_sound_test, sr)\n\nfeature_train.shape, feature_test.shape","e147b279":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(feature_train)","0834cc67":"feature_train_scaler = scaler.transform(feature_train)\nfeature_test_scaler = scaler.transform(feature_test)\n\nfeature_train_scaler.shape, feature_test_scaler.shape","ebc2ffcd":"plt.figure(figsize=(20,20))\nfor i in range(0, feature_train_scaler.shape[1]):\n    plt.subplot(7,4,i+1)\n    plt.hist(feature_train_scaler[:,i][segments_target_train == 0], bins=30, alpha=0.5)\n    plt.hist(feature_train_scaler[:,i][segments_target_train == 1], bins=30, alpha=0.5)\n    plt.legend(['student', 'professor'])\nplt.show()","ec7f4fa2":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report","c1fd73a3":"model_svc = SVC(C=0.1)\nmodel_svc.fit(feature_train_scaler, segments_target_train)","fcda27de":"pred = model_svc.predict(feature_test_scaler)\nprint(classification_report(segments_target_test, pred, target_names=['student', 'professor']))","9dfcb256":"model_rfc = RandomForestClassifier(random_state=13)\nmodel_rfc.fit(feature_train_scaler, segments_target_train)","cbcf87c3":"pred = model_rfc.predict(feature_test_scaler)\nprint(classification_report(segments_target_test, pred, target_names=['student', 'professor']))","c48613a4":"def read_and_reshape_sound(path, segment_size_t = 0.5):\n    # load\n    sound, sr = librosa.load(path)\n\n    signal_len = len(sound)\n    # segment size in samples\n    segment_size = int(segment_size_t * sr)\n    # Break signal into list of segments in a single-line Python code\n    segments = np.array([sound[x:x + segment_size] for x in np.arange(0, signal_len, segment_size)])\n    return segments, sr","3c049651":"path = '\/kaggle\/input\/mini-speech-diarization\/dataset\/test\/test.wav'\nsegment_size_t = 0.5\nsegments, sr = read_and_reshape_sound(path, segment_size_t)\n\ndisplay(Audio(np.concatenate(segments), rate=sr))","e259dc8f":"feature_valid = create_feature(segments, sr)\nfeature_valid_scaler = scaler.transform(feature_valid)\nfeature_valid_scaler.shape","228ab1ce":"pred = model_rfc.predict(feature_valid_scaler)\npred","00cd4782":"student_sound = np.concatenate(segments[pred == 0])\nprofessor_sound = np.concatenate(segments[pred == 1])","e73177f2":"display(Audio(student_sound, rate=sr))","485c728b":"display(Audio(professor_sound, rate=sr))","65f768fd":"## Segmenting audio student and teacher","bb859689":"# Reshape audio and classes ","e3795824":"## Professor segmented sound ","ce666490":"# Create Feature","215d636e":"## Student segmented sound ","370d8e76":"## Model - RandomForestClassifier","3632a0c8":"## Model - SVC","edb080e1":"# Getting file paths and audio class ","14fc9fc1":"## Histogram training data of each feuture for student (blue) and teacher (orange) ","5e5fd714":"# Model","f044963a":"# StandardScaler","4f76ad8f":"# Segmenting student and teacher audio in test data "}}