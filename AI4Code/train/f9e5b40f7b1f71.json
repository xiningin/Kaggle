{"cell_type":{"547ab9ff":"code","bdada740":"code","b870870c":"code","16e700ba":"code","902cf39f":"code","1686fbda":"code","5134a0a7":"code","366fc397":"code","691768a6":"code","f24f877d":"code","55c2ef97":"code","698cc353":"code","a4682e59":"code","f78fafe8":"code","c0f6baf6":"code","1339d0c0":"code","edddb2d0":"code","2fa8742e":"code","caddfe33":"code","f54c0751":"code","4473b6cb":"markdown","463d0f16":"markdown","5de2ed46":"markdown","4587893a":"markdown","c307b724":"markdown","a9b9bbf3":"markdown"},"source":{"547ab9ff":"import numpy as np \nimport cv2\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nimport string\nfrom mlxtend.plotting import plot_decision_regions\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn import metrics\n\nprint(os.listdir(\"..\/input\"))\ndim = 100","bdada740":"def getYourFruits(fruits, data_type, print_n=False, k_fold=False):\n    images = []\n    labels = []\n    val = ['Training', 'Test']\n    if not k_fold:\n        path = \"..\/input\/*\/fruits-360\/\" + data_type + \"\/\"\n        for i,f in enumerate(fruits):\n            p = path + f\n            j=0\n            for image_path in glob.glob(os.path.join(p, \"*.jpg\")):\n                image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n                image = cv2.resize(image, (dim, dim))\n                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n                images.append(image)\n                labels.append(i)\n                j+=1\n            if(print_n):\n                print(\"There are \" , j , \" \" , data_type.upper(), \" images of \" , fruits[i].upper())\n        images = np.array(images)\n        labels = np.array(labels)\n        return images, labels\n    else:\n        for v in val:\n            path = \"..\/input\/*\/fruits-360\/\" + v + \"\/\"\n            for i,f in enumerate(fruits):\n                p = path + f\n                j=0\n                for image_path in glob.glob(os.path.join(p, \"*.jpg\")):\n                    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n                    image = cv2.resize(image, (dim, dim))\n                    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n                    images.append(image)\n                    labels.append(i)\n                    j+=1\n        images = np.array(images)\n        labels = np.array(labels)\n        return images, labels\n    \ndef getAllFruits():\n    fruits = []\n    for fruit_path in glob.glob(\"..\/input\/*\/fruits-360\/Training\/*\"):\n        fruit = fruit_path.split(\"\/\")[-1]\n        fruits.append(fruit)\n    return fruits\n    ","b870870c":"#Choose your Fruits\nfruits = ['Banana' , 'Pineapple', 'Orange'] #Binary classification\n\n#Get Images and Labels \nX_t, y_train =  getYourFruits(fruits, 'Training', print_n=True, k_fold=False)\nX_test, y_test = getYourFruits(fruits, 'Test', print_n=True, k_fold=False)\n\n#Get data for k-fold\nX,y = getYourFruits(fruits, '', print_n=True, k_fold=True)\n\n#Scale Data Images\nscaler = StandardScaler()\nX_train = scaler.fit_transform([i.flatten() for i in X_t])\nX_test = scaler.fit_transform([i.flatten() for i in X_test])\nX = scaler.fit_transform([i.flatten() for i in X])","16e700ba":"def plot_image_grid(images, nb_rows, nb_cols, figsize=(15, 15)):\n    assert len(images) == nb_rows*nb_cols, \"Number of images should be the same as (nb_rows*nb_cols)\"\n    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=figsize)\n    \n    n = 0\n    for i in range(0, nb_rows):\n        for j in range(0, nb_cols):\n            axs[i, j].axis('off')\n            axs[i, j].imshow(images[n])\n            n += 1      ","902cf39f":"print(fruits[y_train[0]])\nplot_image_grid(X_t[0:100], 10, 10)","1686fbda":"print(fruits[y_train[490]])\nplot_image_grid(X_t[490:590], 10, 10)","5134a0a7":"print(fruits[y_train[990]])\nplot_image_grid(X_t[990:1090], 10, 10)","366fc397":"def getClassNumber(y):\n    v =[]\n    i=0\n    count = 0\n    for index in y:\n        if(index == i):\n            count +=1\n        else:\n            v.append(count)\n            count = 1\n            i +=1\n    v.append(count)        \n    return v\n\ndef plotPrincipalComponents(X, dim):\n    v = getClassNumber(y_train)\n    colors = 'b', 'g', 'r', 'c', 'm', 'y', 'k', 'grey', 'orange', 'purple'\n    markers = ['o', 'x' , 'v', 'd']\n    tot = len(X)\n    start = 0 \n    if(dim == 2):\n        for i,index in enumerate(v):\n            end = start + index\n            plt.scatter(X[start:end,0],X[start:end,1] , color=colors[i%len(colors)], marker=markers[i%len(markers)], label = fruits[i])\n            start = end\n        plt.xlabel('PC1')\n        plt.ylabel('PC2')\n    \n    if(dim == 3):\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection='3d')\n        for i,index in enumerate(v):\n            end = start + index\n            ax.scatter(X[start:end,0], X[start:end,1], X[start:end,2], color=colors[i%len(colors)], marker=markers[i%len(markers)], label = fruits[i])\n            start = end\n        ax.set_xlabel('PC1')\n        ax.set_ylabel('PC2')\n        ax.set_zlabel('PC3')\n\n\n    plt.legend(loc='lower left')\n    plt.xticks()\n    plt.yticks()\n    plt.show()\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = metrics.confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = unique_labels(y_true, y_pred)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=fruits, yticklabels=fruits,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return cm,ax","691768a6":"pca = PCA(n_components=2)\ndataIn2D = pca.fit_transform(X_train)\nplotPrincipalComponents(dataIn2D, 2)","f24f877d":"pca = PCA(n_components=3)\ndataIn3D = pca.fit_transform(X_train)\nplotPrincipalComponents(dataIn3D, 3)","55c2ef97":"def showPCA(image,X2, X10, X50):\n    fig = plt.figure(figsize=(15,15))\n    ax1 = fig.add_subplot(1,4,1)\n    ax1.axis('off')\n    ax1.set_title('Original image')\n    plt.imshow(image)\n    ax1 = fig.add_subplot(1,4,2)\n    ax1.axis('off') \n    ax1.set_title('50 PC')\n    plt.imshow(X50)\n    ax1 = fig.add_subplot(1,4,3)\n    ax1.axis('off') \n    ax1.set_title('10 PC')\n    plt.imshow(X10)\n    ax2 = fig.add_subplot(1,4,4)\n    ax2.axis('off') \n    ax2.set_title('2 PC')\n    plt.imshow(X2)\n    plt.show()\n\ndef computePCA(n, im_scaled, image_id):\n    pca = PCA(n)\n    principalComponents = pca.fit_transform(im_scaled)\n    im_reduced = pca.inverse_transform(principalComponents)\n    newImage = scaler.inverse_transform(im_reduced[image_id])\n    return newImage\n\ndef showVariance(X_train):\n    #Compute manually the principal components\n    cov_matr=np.dot(X_train, X_train.T)\n    eigval,eigvect=np.linalg.eig(cov_matr)\n\n    index=np.argsort(eigval)[::-1] #take in order the index of ordered vector (ascending order)\n\n    #eigvect[:,i] is associated to eigval[i] so \n    eigvect=eigvect[:,index]\n    eigval=eigval[index]\n\n    n_PC=[]\n    var_explained=[]\n    var_temp=[]\n    var_tmp=0\n    for i in range(10):\n        var_tmp=var_tmp+eigval[i]\n        n_PC.append(i)\n        var_temp.append(eigval[i]\/(eigval.sum())*100)\n        var_explained.append(var_tmp\/(eigval.sum())*100)\n\n    fig, ax = plt.subplots(figsize=(8,8))\n\n    ind = np.arange(10)    \n    width = 0.35         # the width of the bars\n    p1 = ax.bar(ind, var_temp, width, color='b')\n    p2 = ax.bar(ind + width, var_explained, width, color='r')\n\n    ax.legend((p1[0], p2[0]), ('Individual explained variance', 'Cumulative explained variance'))\n\n    ax.set_title('Variance explained using PCs')\n    ax.set_xticks(ind + width \/ 2)\n    ax.set_xticklabels(('1', '2', '3', '4', '5', '6', '7', '8', '9', '10'))\n\n    plt.xlabel('Number of PC')\n    plt.ylabel('Variance exaplained in %')\n\n    ax.autoscale_view()\n\n    plt.show()","698cc353":"image_id = 2\nimage = X_t[image_id]\n\n#Compute PCA\nX_2 = computePCA(2, X_train,image_id)\nX_10 = computePCA(10, X_train,image_id)\nX_50 = computePCA(50, X_train,image_id)\n\n#Reshape in order to plot images\nX2 = np.reshape(X_2, (dim,dim,3)).astype(int)\nX10 = np.reshape(X_10, (dim,dim,3)).astype(int)\nX50 = np.reshape(X_50, (dim,dim,3)).astype(int)\n\n#Plot\nshowPCA(image, X2, X10, X50)","a4682e59":"from sklearn.preprocessing import StandardScaler\n","f78fafe8":"scaler = StandardScaler()","c0f6baf6":"scaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","1339d0c0":"from sklearn.neural_network import MLPClassifier","edddb2d0":"mlpc = MLPClassifier().fit(X_train_scaled, y_train)","2fa8742e":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n","caddfe33":"y_pred = mlpc.predict(X_test_scaled)\naccuracy_score(y_test, y_pred)","f54c0751":"cross_val_score(mlpc, X_test_scaled, y_test, cv = 10)","4473b6cb":"## PCA \u00d6rne\u011fi;","463d0f16":"## PCA\n\nPca kullanarak \u00f6znitelik se\u00e7imi yap\u0131yoruz.\n","5de2ed46":"meyvelerin baz\u0131lar\u0131na bakal\u0131m.","4587893a":"## Model ","c307b724":"bu veri seti i\u00e7inden  meyveyi se\u00e7ip s\u0131n\u0131rland\u0131rma yap\u0131yorum.","a9b9bbf3":"#### Yorum\nBurada meyveyi k\u00fc\u00e7\u00fck bir boyuta d\u00fc\u015f\u00fcr\u00fcyoruz. Bu y\u00fczden s\u0131n\u0131fland\u0131rman\u0131n ba\u015far\u0131 puan\u0131 d\u00fc\u015fecektir fakat bu i\u015flemi yaparak \u00f6\u011frenmeyi h\u0131zland\u0131rm\u0131\u015f oluyoruz."}}