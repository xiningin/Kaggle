{"cell_type":{"febb77fa":"code","a519e735":"code","3403bfa0":"code","ee6210e5":"code","7f0a84e0":"code","e29ebbc7":"code","6d93ab9f":"code","76c77e8f":"code","5572a181":"code","9e0c4aae":"code","7c94bc33":"code","e09b1f2a":"code","da2711c1":"code","e6536783":"code","3529ad9b":"code","6d9f0d65":"code","faf44536":"code","953a8957":"code","da573ea8":"code","234fc430":"code","197daabf":"code","c02492c4":"code","45782968":"code","086e1366":"code","4800b62f":"code","b5cac9c4":"code","9e86ef13":"code","58e68fc4":"code","a68c2e8f":"code","ee9e82b9":"code","7e1dffb5":"code","c7e58b23":"code","ac30062d":"code","15db1b50":"code","2323c81d":"code","24496a4f":"code","d34483ce":"code","fc1a3ffb":"code","f200a3b4":"code","fd21eb87":"code","9b7a2f99":"code","95ea6b41":"code","191672b1":"code","2cb8832b":"code","74c23fcc":"code","4e44900e":"code","98b8b5d3":"code","036e5d75":"markdown","c5f5ff2b":"markdown","94a52592":"markdown","085ff95b":"markdown","f88fb108":"markdown","98d37dcd":"markdown","8f2872aa":"markdown","2e83b670":"markdown","a3cfd099":"markdown","699a1bfe":"markdown","02faa18a":"markdown","de11aa4e":"markdown"},"source":{"febb77fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a519e735":"from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.utils import plot_model\nimport scikitplot\nfrom matplotlib import pyplot","3403bfa0":"# Set Seed\nimport random\nnp.random.seed(11)\n# set_seed(11)\nrandom.seed(11)","ee6210e5":"df = pd.read_csv('..\/input\/facial-expression-recognitionferchallenge\/fer2013\/fer2013\/fer2013.csv')","7f0a84e0":"df.head()","e29ebbc7":"df.count()","6d93ab9f":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\n","76c77e8f":"df.columns\n","5572a181":"emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]","9e0c4aae":"df[\"emotion\"].value_counts()","7c94bc33":"train = df.loc[df['Usage']=='Training']\nprint('train:'+ str(train.shape))\nprivateTest = df.loc[df['Usage']=='PrivateTest']\nprint('privateTest:'+ str(privateTest.shape))\npublicTest = df.loc[df['Usage']=='PublicTest']\nprint('train:'+ str(publicTest.shape))","e09b1f2a":"train_labels = df[\"emotion\"]\ntrain_labels = to_categorical(train_labels)\ntrain_labels","da2711c1":"train.shape","e6536783":"df","3529ad9b":"img_labels = df[\"emotion\"]\nimg_labels = to_categorical(img_labels)\n\nimg_pixels = df[\"pixels\"].str.split(\" \").tolist()\nimg_pixels = np.uint8(img_pixels)\nimg_pixels = img_pixels.reshape((35887, 48, 48, 1))\nimg_pixels = img_pixels.astype(\"float32\") \/ 255","6d9f0d65":"train_labels = train[\"emotion\"]\ntrain_labels = to_categorical(train_labels)\n\ntrain_pixels = train[\"pixels\"].str.split(\" \").tolist()\ntrain_pixels = np.uint8(train_pixels)\ntrain_pixels = train_pixels.reshape((28709, 48, 48, 1))\ntrain_pixels = train_pixels.astype(\"float32\") \/ 255","faf44536":"private_labels = privateTest[\"emotion\"]\nprivate_labels = to_categorical(private_labels)\n\nprivate_pixels = privateTest[\"pixels\"].str.split(\" \").tolist()\nprivate_pixels = np.uint8(private_pixels)\nprivate_pixels = private_pixels.reshape((3589, 48, 48, 1))\nprivate_pixels = private_pixels.astype(\"float32\") \/ 255","953a8957":"public_labels = publicTest[\"emotion\"]\npublic_labels = to_categorical(public_labels)\n\npublic_pixels = publicTest[\"pixels\"].str.split(\" \").tolist()\npublic_pixels = np.uint8(public_pixels)\npublic_pixels = public_pixels.reshape((3589, 48, 48, 1))\npublic_pixels = public_pixels.astype(\"float32\") \/ 255","da573ea8":"train_pixels.shape","234fc430":"X_train, X_valid, y_train, y_valid = train_test_split(img_pixels, img_labels,\n                                                    shuffle=True, stratify=img_labels,\n                                                    test_size=0.1, random_state=42)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","197daabf":"plt.figure(0, figsize=(12,6))\n# for i in range(1, 13):\n#     plt.subplot(3,4,i)\n#     plt.imshow(train_pixels[i, :, :, 0], cmap=\"gray\")\nplt.imshow(train_pixels[0,:48,:48,0], cmap=\"gray\")\nplt.show()\ntrain_labels[0]\n\n","c02492c4":"fig = pyplot.figure(1, (14, 14))\n\nk = 0\nfor label in sorted(df.emotion.unique()):\n    for j in range(7):\n        px = df[df.emotion==label].pixels.iloc[k]\n        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n\n        k += 1\n        ax = pyplot.subplot(7, 7, k)\n        ax.imshow(px, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(emotion_labels[label])\n        pyplot.tight_layout()","45782968":"# Model configuration\nbatch_size = 32\nloss_function = \"categorical_crossentropy\"\nno_classes = 7 # 7 emotions\nno_epochs = 50\noptims = optimizers.Nadam(learning_rate=0.0003, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam')\noptimizer = optims\nverbosity = 1\nnum_folds = 10\ninput_shape = (48, 48, 1)\n\n","086e1366":"# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []","4800b62f":"batch_size = 64 #batch size of 32 performs the best.\nepochs = 100\noptims = [\n    optimizers.Nadam(learning_rate=0.0006, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n    optimizers.Adam(0.001),\n]","b5cac9c4":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    zoom_range=0.15,\n    horizontal_flip=True,\n)\ntrain_datagen.fit(X_train)","9e86ef13":"\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00005,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n]","58e68fc4":"# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1\nfor i, j in kfold.split(X_train, y_train):\n    net = models.Sequential(name=\"DCNN\")\n    net.add(\n    Conv2D(\n            filters=64,\n            kernel_size=(5,5),\n    #         input_shape=(img_width, img_height, img_depth),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_1'))\n    net.add(\n        Conv2D(\n            filters=64,\n            kernel_size=(5,5),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_2'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_2'))\n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n    net.add(Dropout(0.4, name='dropout_1'))\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_3'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_3'))\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_4'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_4'))\n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n    net.add(Dropout(0.4, name='dropout_2'))\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_5'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_5'))\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_6'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_6'))\n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n    net.add(Dropout(0.5, name='dropout_3'))\n    net.add(Flatten(name='flatten'))\n    net.add(\n        Dense(\n            128,\n            activation='elu',\n            kernel_initializer='he_normal',\n            name='dense_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_7'))\n    net.add(Dropout(0.6, name='dropout_4')) # 60% to shut the neural and change in order to improve the output\n    net.add(\n        Dense(7,\n            activation='softmax',\n            name='out_layer'\n        )\n    )\n     # Compile the model\n    net.compile(loss=loss_function,\n                  optimizer=optims[0],\n                  metrics=['accuracy']) \n    # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'training for fold {fold_no} ...')   \n    # Fit data to model\n    history = net.fit(X_train[i], y_train[i],\n                batch_size=batch_size,\n                epochs=no_epochs,\n                verbose=verbosity)  \n    # Generate generalization metrics\n    scores = net.evaluate(X_train[j], y_train[j], verbose=0)\n    print(f'Score for fold {fold_no}: {net.metrics_names[0]} of {scores[0]}; {net.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0]) \n    # Increase fold number\n    fold_no = fold_no + 1","a68c2e8f":"# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n  print('------------------------------------------------------------------------')\n  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","ee9e82b9":"def build_net(optims):\n    # Set Seed\n    np.random.seed(11)\n    random.seed(11)\n    net = models.Sequential(name=\"DCNN\")\n    net.add(\n    Conv2D( #batch size,h,w,d : batch size is no. of img\n            filters=64, # change depth(channel) from 1 to 64\n            kernel_size=(5,5), #kernel that we use to filter img\n    #         input_shape=(img_width, img_height, img_depth),\n            activation='elu', #function used to get output of the node\n            padding='same', # \n            kernel_initializer='he_normal',\n            name='conv2d_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_1'))\n    net.add(\n        Conv2D(\n            filters=64,\n            kernel_size=(5,5),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_2'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_2'))\n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n    net.add(Dropout(0.4, name='dropout_1'))\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_3'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_3'))\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_4'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_4'))\n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n    net.add(Dropout(0.4, name='dropout_2'))\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_5'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_5'))\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_6'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_6'))\n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n    net.add(Dropout(0.5, name='dropout_3'))\n    net.add(Flatten(name='flatten'))\n    net.add(\n        Dense(\n            128,\n            activation='elu',\n            kernel_initializer='he_normal',\n            name='dense_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_7'))\n    net.add(Dropout(0.6, name='dropout_4')) # 60% to shut the neural and change in order to improve the output\n    net.add(\n        Dense(7,\n            activation='softmax',\n            name='out_layer'\n        )\n    )\n    net.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims,\n        metrics=['accuracy']\n    )\n    net.build((35887, 48, 48, 1))\n\n    net.summary()\n    return net","7e1dffb5":"\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00005,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau( #Reduce learning rate when a metric has stopped improving.\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n#     early_stopping,\n    lr_scheduler,\n]","c7e58b23":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    zoom_range=0.15,\n    horizontal_flip=True,\n)\ntrain_datagen.fit(X_train)","ac30062d":"batch_size = 64 #batch size of 32 performs the best.\nepochs = 100\noptims = [\n    optimizers.Nadam(learning_rate=0.0006, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n    optimizers.Adam(0.001),\n]\n\n\n# I tried both `Nadam` and `Adam`, the difference in results is not different but I finally went with Nadam as it is more popular.\nnet = build_net(optims[1]) \nprint(net)\nhistory = net.fit_generator(\n    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n    validation_data=(X_valid, y_valid),\n    steps_per_epoch=len(X_train) \/ batch_size,\n    epochs=epochs,\n    callbacks=callbacks,\n    use_multiprocessing=True\n)","15db1b50":"acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, \"g\", label = \"Training acc\")\nplt.plot(epochs, val_acc, \"r\", label = \"Validation acc\")\nplt.title(\"Accuracy\")\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, \"g\", label = \"Training Loss\")\nplt.plot(epochs, val_loss, \"r\", label = \"Validation Loss\")\nplt.title(\"Loss\")\n\nplt.legend()\nplt.show()","2323c81d":"batch_size = 32 #batch size of 32 performs the best.\nepochs = 50\noptims = optimizers.Nadam(learning_rate=0.0009, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam')\n","24496a4f":"net.save('..\/input\/my_facial_expression_reg_0.69')\n","d34483ce":"net.compile(optimizer = optims, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n\nhistory_2 = net.fit(X_train, y_train, batch_size = batch_size, epochs = epochs,\n                validation_data = (X_valid, y_valid))","fc1a3ffb":"net.save('..\/output\/my_facial_expression_reg')","f200a3b4":"yhat_train = net.predict_classes(X_train)\nscikitplot.metrics.plot_confusion_matrix(np.argmax(y_train, axis=1), yhat_train, figsize=(7,7))\n\nprint(f'total wrong validation predictions: {np.sum(np.argmax(y_train, axis=1) != yhat_train)}\\n\\n')\n","fd21eb87":"yhat_valid = net.predict_classes(X_valid)\nscikitplot.metrics.plot_confusion_matrix(np.argmax(y_valid, axis=1), yhat_valid, figsize=(7,7))\n\nprint(f'total wrong validation predictions: {np.sum(np.argmax(y_valid, axis=1) != yhat_valid)}\\n\\n')\n\n","9b7a2f99":"yhat_valid = net.predict_classes(public_pixels)\nscikitplot.metrics.plot_confusion_matrix(np.argmax(public_labels, axis=1), yhat_valid, figsize=(7,7))\n\nprint(f'total wrong validation predictions: {np.sum(np.argmax(public_labels, axis=1) != yhat_valid)}\\n\\n')","95ea6b41":"emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]","191672b1":"from sklearn.metrics import classification_report\nprint(classification_report(np.argmax(y_valid, axis=1), yhat_valid))","2cb8832b":"n = net.predict_classes(train_pixels)\nt = train_labels","74c23fcc":"import cv2\nimport numpy as np","4e44900e":"img = cv2.imread('..\/input\/mind-angry\/angrymind.jpg',0)\nimg = cv2.resize(img,(48,48))\nimg = np.reshape(img,[1,48,48,1])\nimg_pixels = img.astype(\"float32\") \/ 255\nclasses = net.predict_classes(img)\n# print classes","98b8b5d3":"emotion_labels[classes[0]]","036e5d75":"**Change ' ' to list ( , , )**\n> df[\"pixels\"].str.split(\" \").tolist()\n\n1. To make the labels be categorical\n\n - Converts a class vector (integers) to binary class matrix.\n\n\n2. To reshape img to be 48* 48 type float32 = 0-1","c5f5ff2b":"K-fold","94a52592":"**Image Seperation**","085ff95b":"The confusion matrix shows that the model is doing good but it's performance is low on class Fear, Sad, and Neutral. One of the reason for this issue may happen because the images are hard to identify the emotion even by human. If I reduce the number of class the result will be better but for the whole 7 classes, I got the best accuracy at 70%.","f88fb108":"Save model","98d37dcd":"The result by confusion matrix is ok but can be better by difference model.","8f2872aa":"Arguments\n\nlearning_rate: A Tensor or a floating point value. The learning rate.\n\nbeta_1: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n\nbeta_2: A float value or a constant float tensor. The exponential decay rate for the exponentially weighted infinity norm.\n\nepsilon: A small constant for numerical stability.\n\nname: Optional name for the operations created when applying gradients. Defaults to \"Nadam\".","2e83b670":"**Add machine learning model**","a3cfd099":"# **I reduced *batch_size* and *epochs* , increase *learning_rate* when the model seems to stuck at 0.69 val_accuracy** ","699a1bfe":"One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.\n\nSince one epoch is too big to feed to the computer at once we divide it in several smaller batches.","02faa18a":"**Type of data**","de11aa4e":"Test our image\n"}}