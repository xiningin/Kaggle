{"cell_type":{"8f323569":"code","31d2c1f6":"code","ccccee23":"code","550e38de":"code","8f61dfa2":"code","2f2d2c09":"code","02973468":"code","23d292f5":"code","c3f979b9":"code","260a9bcb":"code","4d97f87e":"code","97374759":"code","19861ae8":"code","f36d79e2":"code","769ce24a":"code","24843a14":"code","22cb718b":"code","175a99c0":"code","9847efa1":"code","746d2bcf":"code","c8dcea61":"code","5b7f3a9d":"code","c8c780ea":"code","b6e12b67":"code","41168a5f":"code","998f7694":"code","fd4cf7a0":"code","c3305b9d":"code","fef89793":"code","05783eae":"code","76203d40":"code","47c261bf":"code","10be786f":"code","71ece139":"code","199bd56b":"code","a297fd21":"code","1a9bb902":"code","da319541":"code","26ee6f2b":"code","92d699a6":"code","da3de6e0":"code","fe188b6c":"code","38a86e6c":"markdown","522d3e51":"markdown","39f7ac14":"markdown","c218305c":"markdown","1edf8e44":"markdown","a9b262d3":"markdown","f1b3f204":"markdown","b2066560":"markdown","20f94e98":"markdown","c6032c81":"markdown","c99deb00":"markdown","81635547":"markdown","9fc89e08":"markdown","ad9ad2a8":"markdown","6e8eb5ce":"markdown","a0897a26":"markdown","454ddd97":"markdown","e26b74c9":"markdown","c8c5e212":"markdown","25af7fc7":"markdown","cab186d8":"markdown","3abb4210":"markdown","1455bd85":"markdown","921b922d":"markdown","808e8b22":"markdown","8757340b":"markdown","e1a70059":"markdown","d6256189":"markdown","a4c5dbb1":"markdown","e8b493d3":"markdown","6d63e070":"markdown","a80809af":"markdown","4719abcb":"markdown","31112bf7":"markdown","561dcefb":"markdown","d9fc5bf9":"markdown","0bc62745":"markdown","79d50980":"markdown","23f604ae":"markdown","1dbd0a0f":"markdown"},"source":{"8f323569":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","31d2c1f6":"df = pd.read_csv('..\/input\/kuc-hackathon-winter-2018\/drugsComTrain_raw.csv')\ntest = pd.read_csv('..\/input\/kuc-hackathon-winter-2018\/drugsComTest_raw.csv')\ndf.head()","ccccee23":"# as both the dataset contains same columns we can combine them for better analysis\n\ndata = pd.concat([df, test])\ndata.head()","550e38de":"# describing the data\n\ndata.describe()","8f61dfa2":"# taking out information from the data\n\ndata.info()","2f2d2c09":"# get the datatype of columns\n\ndata.dtypes","02973468":"# checking if the data contains any NULL values\n\ndata.isnull().any()","23d292f5":"# let's see the words cloud for the reviews \n\n# most popular drugs\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(background_color = 'orange', stopwords = stopwords, width = 1200, height = 800).generate(str(data['drugName']))\n\nplt.rcParams['figure.figsize'] = (15, 15)\nplt.title('Word Cloud - Drug Names', fontsize = 25)\nprint(wordcloud)\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.show()","c3f979b9":"# This barplot shows the top 20 drugs with the 10\/10 rating\n\n# Setting the Parameter\nsns.set(font_scale = 1.2, style = 'darkgrid')\nplt.rcParams['figure.figsize'] = [15, 8]\n\nrating = dict(data.loc[data.rating == 10, \"drugName\"].value_counts())\ndrugname = list(rating.keys())\ndrug_rating = list(rating.values())\n\nsns_rating = sns.barplot(x = drugname[0:20], y = drug_rating[0:20])\n\nsns_rating.set_title('Top 20 drugs with 10\/10 rating')\nsns_rating.set_ylabel(\"Number of Ratings\")\nsns_rating.set_xlabel(\"Drug Names\")\nplt.setp(sns_rating.get_xticklabels(), rotation=90);","260a9bcb":"# This barplot shows the Top 20 drugs with the 1\/10 rating\n\n# Setting the Parameter\nsns.set(font_scale = 1.2, style = 'darkgrid')\nplt.rcParams['figure.figsize'] = [15, 8]\n\nrating = dict(data.loc[data.rating == 1, \"drugName\"].value_counts())\ndrugname = list(rating.keys())\ndrug_rating = list(rating.values())\n\nsns_rating = sns.barplot(x = drugname[0:20], y = drug_rating[0:20], palette = 'winter')\n\nsns_rating.set_title('Top 20 drugs with 1\/10 rating')\nsns_rating.set_ylabel(\"Number of Ratings\")\nsns_rating.set_xlabel(\"Drug Names\")\nplt.setp(sns_rating.get_xticklabels(), rotation=90);","4d97f87e":"# making a donut chart to represent share of each ratings\n\nsize = [68005, 46901, 36708, 25046, 12547, 10723, 8462, 6671]\ncolors = ['pink', 'cyan', 'maroon',  'magenta', 'orange', 'navy', 'lightgreen', 'yellow']\nlabels = \"10\", \"1\", \"9\", \"8\", \"7\", \"5\", \"6\", \"4\"\n\nmy_circle = plt.Circle((0, 0), 0.7, color = 'white')\n\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.pie(size, colors = colors, labels = labels, autopct = '%.2f%%')\nplt.axis('off')\nplt.title('Pie Chart Representation of Ratings', fontsize = 25)\np = plt.gcf()\nplt.gca().add_artist(my_circle)\nplt.legend()\nplt.show()","97374759":"# A countplot of the ratings so we can see the distribution of the ratings\nplt.rcParams['figure.figsize'] = [20,8]\nsns.set(font_scale = 1.4, style = 'darkgrid')\nfig, ax = plt.subplots(1, 2)\n\nsns_1 = sns.countplot(data['rating'], palette = 'spring', order = list(range(10, 0, -1)), ax = ax[0])\nsns_2 = sns.distplot(data['rating'], ax = ax[1])\nsns_1.set_title('Count of Ratings')\nsns_1.set_xlabel(\"Rating\")\n\nsns_2.set_title('Distribution of Ratings')\nsns_2.set_xlabel(\"Rating\")","19861ae8":"# This barplot show the top 10 conditions the people are suffering.\ncond = dict(data['condition'].value_counts())\ntop_condition = list(cond.keys())[0:10]\nvalues = list(cond.values())[0:10]\nsns.set(style = 'darkgrid', font_scale = 1.3)\nplt.rcParams['figure.figsize'] = [18, 7]\n\nsns_ = sns.barplot(x = top_condition, y = values, palette = 'winter')\nsns_.set_title(\"Top 10 conditions\")\nsns_.set_xlabel(\"Conditions\")\nsns_.set_ylabel(\"Count\");","f36d79e2":"# Top 10 drugs which are used for the top condition, that is Birth Control\ndf1 = data[data['condition'] == 'Birth Control']['drugName'].value_counts()[0: 10]\nsns.set(font_scale = 1.2, style = 'darkgrid')\n\nsns_ = sns.barplot(x = df1.index, y = df1.values, palette = 'summer')\nsns_.set_xlabel('Drug Names')\nsns_.set_title(\"Top 10 Drugs used for Birth Control\")\nplt.setp(sns_.get_xticklabels(), rotation = 90);","769ce24a":"# let's see the words cloud for the reviews \n\n# most popular drugs\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(background_color = 'lightblue', stopwords = stopwords, width = 1200, height = 800).generate(str(data['review']))\n\nplt.rcParams['figure.figsize'] = (15, 15)\nplt.title('WORD CLOUD OF REVIEWS', fontsize = 25)\nprint(wordcloud)\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.show()","24843a14":"# feature engineering \n# let's make a new column review sentiment \n\ndata.loc[(data['rating'] >= 5), 'Review_Sentiment'] = 1\ndata.loc[(data['rating'] < 5), 'Review_Sentiment'] = 0\n\ndata['Review_Sentiment'].value_counts()","22cb718b":"# a pie chart to represent the sentiments of the patients\n\nsize = [161491, 53572]\ncolors = ['lightblue', 'navy']\nlabels = \"Positive Sentiment\",\"Negative Sentiment\"\nexplode = [0, 0.1]\n\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.pie(size, colors = colors, labels = labels, explode = explode, autopct = '%.2f%%')\nplt.axis('off')\nplt.title('Pie Chart Representation of Sentiments', fontsize = 25)\nplt.legend()\nplt.show()","175a99c0":"\n# making Words cloud for the postive sentiments\n\npositive_sentiments = \" \".join([text for text in data['review'][data['Review_Sentiment'] == 1]])\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\n\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'magenta', stopwords = stopwords, width = 1200, height = 800).generate(positive_sentiments)\n\nplt.rcParams['figure.figsize'] = (15, 15)\nplt.title('Word Cloud of Positive Reviews', fontsize = 30)\nprint(wordcloud)\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.show()","9847efa1":"# making wordscloud for the Negative sentiments\n\nnegative_sentiments = \" \".join([text for text in data['review'][data['Review_Sentiment'] == 0]])\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\n\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'cyan', stopwords = stopwords, width = 1200, height = 800).generate(negative_sentiments)\n\nplt.rcParams['figure.figsize'] = (15, 15)\nplt.title('Word Cloud of Negative Reviews', fontsize = 30)\nprint(wordcloud)\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.show()","746d2bcf":"# converting the date into datetime format\ndata['date'] = pd.to_datetime(data['date'], errors = 'coerce')\n\n# now extracting year from date\ndata['Year'] = data['date'].dt.year\n\n# extracting the month from the date\ndata['month'] = data['date'].dt.month\n\n# extracting the days from the date\ndata['day'] = data['date'].dt.day","c8dcea61":"# looking at the no. of reviews in each of the year\n\nplt.rcParams['figure.figsize'] = (19, 8)\nsns.countplot(data['Year'], palette ='colorblind')\nplt.title('The No. of Reviews each year', fontsize = 30)\nplt.xlabel('Year', fontsize = 15)\nplt.ylabel('Count of Reviews', fontsize = 15)\nplt.show()","5b7f3a9d":"# looking at the no. of reviews in each of the months\n\nplt.rcParams['figure.figsize'] = (19, 8)\nsns.countplot(data['month'], palette ='tab10')\nplt.title('The No. of Reviews each Month', fontsize = 30)\nplt.xlabel('Months', fontsize = 15)\nplt.ylabel('Ratings', fontsize = 15)\nplt.show()","c8c780ea":"# looking at the no. of reviews in each of the day\n\nplt.rcParams['figure.figsize'] = (19, 8)\nsns.countplot(data['day'], palette ='colorblind')\nplt.title('The No. of Reviews each day', fontsize = 30)\nplt.xlabel('Days', fontsize = 15)\nplt.ylabel('Count of Reviews', fontsize = 15)\nplt.show()","b6e12b67":"# plotting a dist plot\n\nplt.rcParams['figure.figsize'] = (15, 8)\nsns.distplot(data['usefulCount'], color = 'orange')\nplt.title('The Distribution of Useful Counts', fontsize = 30)\nplt.xlabel('Range of Useful Counts', fontsize = 15)\nplt.ylabel('No. of Useful Counts', fontsize = 15)\nplt.show()","41168a5f":"def review_clean(review): \n    # changing to lower case\n    lower = review.str.lower()\n    \n    # Replacing the repeating pattern of &#039;\n    pattern_remove = lower.str.replace(\"&#039;\", \"\")\n    \n    # Removing all the special Characters\n    special_remove = pattern_remove.str.replace(r'[^\\w\\d\\s]',' ')\n    \n    # Removing all the non ASCII characters\n    ascii_remove = special_remove.str.replace(r'[^\\x00-\\x7F]+',' ')\n    \n    # Removing the leading and trailing Whitespaces\n    whitespace_remove = ascii_remove.str.replace(r'^\\s+|\\s+?$','')\n    \n    # Replacing multiple Spaces with Single Space\n    multiw_remove = whitespace_remove.str.replace(r'\\s+',' ')\n    \n    # Replacing Two or more dots with one\n    dataframe = multiw_remove.str.replace(r'\\.{2,}', ' ')\n    \n    return dataframe","998f7694":"data['review_clean'] = review_clean(data['review'])","fd4cf7a0":"from textblob import TextBlob\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport warnings; warnings.simplefilter('ignore')\nimport nltk\nimport string\nfrom nltk import ngrams\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer\n\n# Removing the stopwords\nstop_words = set(stopwords.words('english'))\ndata['review_clean'] = data['review_clean'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))","c3305b9d":"# Removing the word stems using the Snowball Stemmer\nSnow_ball = SnowballStemmer(\"english\")\ndata['review_clean'] = data['review_clean'].apply(lambda x: \" \".join(Snow_ball.stem(word) for word in x.split()))","fef89793":"data.head(3)","05783eae":"def sentiment(review):\n    # Sentiment polarity of the reviews\n    pol = []\n    for i in review:\n        analysis = TextBlob(i)\n        pol.append(analysis.sentiment.polarity)\n    return pol","76203d40":"data['sentiment'] = sentiment(data['review'])","47c261bf":"data['sentiment_clean'] = sentiment(data['review_clean'])","10be786f":"# Cleaning the reviews without removing the stop words and using snowball stemmer\ndata['review_clean_ss'] = review_clean(data['review'])\ndata['sentiment_clean_ss'] = sentiment(data['review_clean_ss'])","71ece139":"data = data.dropna(how=\"any\", axis=0)","199bd56b":"\n#Word count in each review\ndata['count_word']=data[\"review_clean_ss\"].apply(lambda x: len(str(x).split()))\n\n#Unique word count \ndata['count_unique_word']=data[\"review_clean_ss\"].apply(lambda x: len(set(str(x).split())))\n\n#Letter count\ndata['count_letters']=data[\"review_clean_ss\"].apply(lambda x: len(str(x)))\n\n#punctuation count\ndata[\"count_punctuations\"] = data[\"review\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n\n#upper case words count\ndata[\"count_words_upper\"] = data[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n\n#title case words count\ndata[\"count_words_title\"] = data[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n\n#Number of stopwords\ndata[\"count_stopwords\"] = data[\"review\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n\n#Average length of the words\ndata[\"mean_word_len\"] = data[\"review_clean_ss\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))","a297fd21":"data.columns","1a9bb902":"# Correlation Heatmap of the features engineered\nplt.rcParams['figure.figsize'] = [17,15]\nsns.set(font_scale = 1.2)\ncorr = data.select_dtypes(include = 'int64').corr()\nsns_ = sns.heatmap(corr, annot = True, cmap = 'Wistia')\nplt.setp(sns_.get_xticklabels(), rotation = 45);","da319541":"\n# Label Encoding Drugname and Conditions\nfrom sklearn.preprocessing import LabelEncoder\nlabel_encoder_feat = {}\nfor feature in ['drugName', 'condition']:\n    label_encoder_feat[feature] = LabelEncoder()\n    data[feature] = label_encoder_feat[feature].fit_transform(data[feature])","26ee6f2b":"# Importing Libraries for the Machine Learning Model\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMModel,LGBMClassifier, plot_importance\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split","92d699a6":"# Defining Features and splitting the data as train and test set\n\nfeatures = data[['condition', 'usefulCount', 'sentiment', 'day', 'month', 'Year',\n                   'sentiment_clean_ss', 'count_word', 'count_unique_word', 'count_letters',\n                   'count_punctuations', 'count_words_upper', 'count_words_title',\n                   'count_stopwords', 'mean_word_len']]\n\ntarget = data['Review_Sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)\nprint (\"The Train set size \", X_train.shape)\nprint (\"The Test set size \", X_test.shape)","da3de6e0":"# Training Model - I\nclf = LGBMClassifier(\n        n_estimators=10000,\n        learning_rate=0.10,\n        num_leaves=30,\n        subsample=.9,\n        max_depth=7,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01,\n        min_child_weight=2,\n        silent=-1,\n        verbose=-1,\n        )\nmodel = clf.fit(X_train, y_train)\n\n# Predictions\npredictions = model.predict(X_test)\nprint (\"The Accuracy of the model is : \", accuracy_score(y_test, predictions))\nprint (\"The confusion Matrix is \")\nconfusion_matrix(y_test, predictions)","fe188b6c":"# Feature Importance Plot using LGBM\nplt.rcParams['figure.figsize'] = [12, 9]\nsns.set(style = 'darkgrid', font_scale = 1.2)\nplot_importance(model);","38a86e6c":"<ul>\n    <li style=\"font-size:150%;\">The is a bar graph which shows the top 20 drugs given in the data set with a rating of 10\/10. 'Levonorgestrel' is the drug with the highest number of 10\/10 ratings, about 1883 Ratings in the data set for 'Levonorgestrel'. <\/li>\n<ul>","522d3e51":"<ul>\n    <li style=\"font-size:150%;\">This is a word cloud for the reviews.<\/li>\n<ul>","39f7ac14":"<ul>\n    <li style=\"font-size:150%;\">The is a Bar graph that shows the number of reviews in the data set per year. It can be inferred that most ratings are given in 2016 and 2008 has the least number of reviews.<\/li>\n<ul>","c218305c":"<ul>\n    <li style=\"font-size:150%;\">CREDIT GOES TO - Mr. Sumit(Don't Know his kaggle Id), His Work Helped me to Create this Notebook. Thank You So Much.<\/li>\n    <li style=\"font-size:150%;\">IF YOU LIKE THIS NOTEBOOK, GIVE AN UPVOTE. PLEASE DON'T IGNORE. THANK YOU.<\/li>\n<ul>","1edf8e44":"<ul>\n    <li style=\"font-size:150%;\">The new features engineered are 'count_word' which is the number of words in each review, 'count_unique_word' which is the number of the unique words in the reviews. 'count_letters' is the letter count, 'punctuation_count' is the punctuation count, 'count_words_upper' is the upper case word count,'count_words_title' is the title case word counts, 'count_stopwords' is the number of stop words in the review, and the 'mean_word_len' is the average length of the words in the review. The date is also divided into three columns which are day, month and year for separate features for training.<\/li>\n<ul> ","a9b262d3":"<ul>\n    <li style=\"font-size:150%;\">This Pie Chart represents the Sentiments of the Reviews.<\/li>\n<ul>","f1b3f204":"<center style=\"font-family:cursive;\"><h1 style=\"font-size:200%; padding: 20px; background: #001f3f;\"><i><b style=\"color:orange;\">DATA PREPROCESSING \/ FEATURE ENGINEERING<\/b><\/i><\/h1><\/center>","b2066560":"<h1 style=\"font-size:180%; color:orange;\"><i><b>VISUALIZATION OF REVIEWS BASED ON DATETIME<\/b><\/i><\/h1>","20f94e98":"<ul>\n    <li style=\"font-size:150%;\">The is a bar graph which exhibits the top 10 drug names for the people suffering from Birth Control. In this data set 'Etonogestrel' is the most prominent drug by a very big margin.<\/li>\n<ul>","c6032c81":"<ul>\n    <li style=\"font-size:150%;\">LightGBM is a gradient boosting framework that uses treebased learning algorithms. It's designed to be distributed and efficient. It has many advantages like faster training speed and higher efficiency, lower memory usage, better accuracy and support of parallel and GPU learning, since it is based on decision tree algorithms, it splits the tree leaf wise with the best fit.<\/li>\n<ul>","c99deb00":"<ul>\n    <li style=\"font-size:150%;\">The Label Encoder is used to change the categorical values of Drug Names and the conditions in to numerical values for the machine learning modelling. There are 3,667 unique drugs in the dataset that's why One hot encoder is not used as it would generate 3,667 new features and it would be very computationally expensive.<\/li>\n<ul>","81635547":"<h1 style=\"font-size:200%; color:navy;\"><i><b>Descriptive Statistics<\/b><\/i><\/h1>","9fc89e08":"<h1 style=\"font-size:180%; color:orange;\"><i><b>VISUALIZATION OF REVIEWS<\/b><\/i><\/h1>","ad9ad2a8":"<ul>\n    <li style=\"font-size:150%;\">I have used textblob module to give the sentiment polarity of the review. This polarity is given to both the cleaned and uncleaned review<\/li>\n<ul> ","6e8eb5ce":"<ul>\n    <li style=\"font-size:150%;\">The is a bar graph thatshows the top 20 drugs given in the data set with a rating of 1\/10. 'Miconazole' is the drug with the highest number of 1\/10 ratings, about 767. <\/li>\n<ul>","a0897a26":"<ul>\n    <li style=\"font-size:150%;\">This Pie Chart reprents the Rating of Reviews. <\/li>\n<ul>","454ddd97":"<h1 style=\"font-size:180%; color:orange;\"><i><b>LABEL ENCODING<\/b><\/i><\/h1>","e26b74c9":"<ul>\n    <li style=\"font-size:150%;\">This is a word cloud for the Positive Sentiments.<\/li>\n<ul>","c8c5e212":"<center style=\"font-family:cursive;\"><h1 style=\"font-size:200%; padding: 20px; background: #001f3f;\"><i><b style=\"color:orange;\">DATA VISUALIZATION<\/b><\/i><\/h1><\/center>","25af7fc7":"<ul>\n    <li style=\"font-size:150%;\">Correlation Heatmap is plotted using seaborn which contains all the new features engineered and the old features.<\/li>\n<ul>","cab186d8":"<h1 style=\"font-size:200%; color:navy;\"><i><b>Import Required Libraries and Load Dataset<\/b><\/i><\/h1>","3abb4210":"<ul>\n    <li style=\"font-size:150%;\">The is a Bar graph that shows the number of reviews in the data set per day.<\/li>\n<ul>","1455bd85":"<ul>\n    <li style=\"font-size:150%;\">The shows a distribution plot on the right hand side and a bar graph of the same on the left hand side. This shows the distribution of the ratings from 1 to 10 in the data set.<\/li>\n<ul>","921b922d":"<ul>\n    <li style=\"font-size:150%;\">The is a Bar graph that shows the number of reviews in the data set per month.<\/li>\n<ul>","808e8b22":"<ul>\n    <li style=\"font-size:150%;\">The is a bar graph which exhibits the top 10 conditions the people are suffering from. In this data set 'Birth Control' is the most prominent condition by a very big margin followed by Depression and pain.<\/li>\n<ul>","8757340b":"<center style=\"font-family:cursive;\"><h1 style=\"font-size:200%; padding: 20px; background: #001f3f;\"><b style=\"color:orange;\">Let's Start the Implementation<\/b><\/h1><\/center>","e1a70059":"<center style=\"font-family:cursive;\"><h1 style=\"font-size:350%; padding: 20px; background: #001f3f;\"><b style=\"color:orange;\">DRUGS REVIEW - SENTIMENT ANALYSIS<\/b><\/h1><\/center>","d6256189":"![](https:\/\/miro.medium.com\/max\/1250\/1*fpKIE34xAR22c2Ti50OHqw.jpeg)","a4c5dbb1":"<ul>\n    <li style=\"font-size:150%;\">The Confusion Matrix for the LGBM model is given above, it can be seen that the accuracy of the LGBM is 0.9014 (90%).<\/li>\n<ul>","e8b493d3":"<center style=\"font-family:cursive;\"><h1 style=\"font-size:200%; padding: 10px; background: #001f3f;\"><b style=\"color:orange;\">ABOUT NOTEBOOK<\/b><\/h1><\/center>\n\n\n<p style=\"font-size:150%;\">The objective of this Notebook is to predict the sentiment of the drug Users, according to their reviews and various other features like the condition they are suffering from, the rating of the drug used, Date of the usage, and others.<\/p>\n\n<h1 style=\"font-size:180%; color:navy;\"><i><b>Steps Performed<\/b><\/i><\/h1>\n\n<ul>\n    <li style=\"font-size:150%;\">DESCRIPTIVE STATISTICS<\/li>\n    <li style=\"font-size:150%;\">DATA VISUALIZATION<\/li>\n    <li style=\"font-size:150%;\">DATA PREPROCESSING & FEATURE ENGINEERING<\/li>\n    <li style=\"font-size:150%;\">LIGHT GBM MODEL BUILDING<\/li>\n<\/ul>\n\n<h1 style=\"font-size:180%; color:navy;\"><i><b>About Dataset<\/b><\/i><\/h1>\n\n<ul>\n    <li style=\"font-size:150%;\">The Drug Review Dataset is taken from the UCI Machine Learning Repository. This Dataset provides patient reviews\non specific drugs along with related conditions and a 10-star patient rating reflecting the overall patient satisfaction. The data was obtained by crawling online pharmaceutical review sites. The Drug Review Data Set is of shape (161297, 7) i.e. It has 7 features including the review and 161297 Data Points or entries. <\/li>\n    <li style=\"font-size:150%;\">The features are 'drugName' which is the name of the drug, 'condition' which is the condition the patient is suffering from, 'review' is the patients review, 'rating' is the 10-star patient rating for the drug, 'date' is the date of the entry and the 'usefulcount' is the number of users who found the review useful. <\/li>\n    <li style=\"font-size:150%;\">Here the sentiment of the review is the target variable that needs to be predicted. here we can notice that the sentiment of any review is not given, so we have to give the sentiment to the rating first and then use it as the target variable. <\/li>\n<\/ul>","6d63e070":"<h1 style=\"font-size:180%; color:orange;\"><i><b>LIGHT GBM MODEL<\/b><\/i><\/h1>","a80809af":"<ul>\n    <li style=\"font-size:150%;\">This is a word cloud for the DRUG NAMES <\/li>\n<ul>","4719abcb":"<ul>\n    <li style=\"font-size:150%;\">This is a word cloud for the Negative Sentiments.<\/li>\n<ul>","31112bf7":"<center style=\"font-family:cursive;\"><h1 style=\"font-size:200%; padding: 20px; background: #001f3f;\"><i><b style=\"color:orange;\">CONCLUSION<\/b><\/i><\/h1><\/center>","561dcefb":"<ul>\n    <li style=\"font-size:150%;\">Above figure depicts the feature importance plot using the LightGBM. It can be inferred that the most importance feature is the mean word length and after that the condition of the patient. The least important feature of them all is the upper-case word count.<\/li>\n<ul>","d9fc5bf9":"<ul>\n    <li style=\"font-size:150%;\">70% of the dataset is used for the training and the rest of the data i.e. 30% is used for the testing purpose. The shape of the training set is (149708, 15) and the shape of  the test set is (64161, 15).<\/li>\n<ul>","0bc62745":"<ul>\n    <li style=\"font-size:150%;\">This shows the distribution of the useful Counts in the data set.<\/li>\n<ul>","79d50980":"<h1 style=\"font-size:180%; color:orange;\"><i><b>CORRELATION MATRIX<\/b><\/i><\/h1>","23f604ae":"<h1 style=\"font-size:180%; color:orange;\"><i><b>VISUALIZATION OF USEFUL COUNT<\/b><\/i><\/h1>","1dbd0a0f":"<h1 style=\"font-size:180%; color:orange;\"><i><b>VISUALIZATION OF DRUG NAMES \/ RATINGS \/ CONDITIONS<\/b><\/i><\/h1>"}}