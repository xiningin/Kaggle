{"cell_type":{"795054a1":"code","fb957fca":"code","d8eaa648":"code","5eb7005d":"code","c0ba6b9d":"code","0e4fa1d9":"code","74fc2dba":"code","3069704c":"code","5c2be7d6":"code","da612382":"code","e48c2eef":"code","2c7e0b6f":"code","dbae0f4a":"code","43f973f4":"code","1123a6fc":"code","d0376968":"code","620aa992":"code","ab63748f":"code","700861e1":"code","e7523f7b":"code","5bce0ded":"code","5b2d3473":"code","460c071e":"code","2605ae30":"code","ff1c1869":"code","b716e1b5":"code","83448d25":"code","98b7ac88":"markdown","10cd19a0":"markdown","3fc6ba28":"markdown","ca3318ae":"markdown","19d303a5":"markdown","384d2621":"markdown","dc205f9a":"markdown"},"source":{"795054a1":"import os\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport nltk\nimport collections\nfrom time import time\nfrom tqdm import tqdm, trange\nfrom nltk import sent_tokenize, word_tokenize\nfrom torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.utils.data.sampler import RandomSampler, SequentialSampler\nfrom nltk.corpus import stopwords\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint()\nnltk.download('punkt')\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","fb957fca":"t = time()\nwith open('..\/input\/pickled-glove840b300d-for-10sec-loading\/glove.840B.300d.pkl', 'rb') as fp:\n    glove = pickle.load(fp)\nprint(time()-t)","d8eaa648":"train_data = pd.read_csv('\/kaggle\/input\/dsa5204-project-data\/train_dat.csv')\ndev_data = pd.read_csv('\/kaggle\/input\/dsa5204-project-data\/dev_dat.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/dsa5204-project-data\/test_dat.csv')","5eb7005d":"train_data.head(1)","c0ba6b9d":"PADDING_TOKEN = '<PAD>'\n\nSPECIAL_TOKENS = [PADDING_TOKEN]\nunique_tokens = {x for x in SPECIAL_TOKENS}","0e4fa1d9":"unique_tokens.update({x for l in map(word_tokenize, train_data['sentence']) for x in l})\nunique_tokens.update({x for l in map(word_tokenize, dev_data['sentence']) for x in l})\nunique_tokens.update({x for l in map(word_tokenize, test_data['sentence']) for x in l})\n\nunique_tokens.update({x for l in map(word_tokenize, train_data['T-A']) for x in l})\nunique_tokens.update({x for l in map(word_tokenize, dev_data['T-A']) for x in l})\nunique_tokens.update({x for l in map(word_tokenize, test_data['T-A']) for x in l})","74fc2dba":"token2idx = {t: i for i, t in enumerate(unique_tokens)}\nidx2token = {i: t for t, i in token2idx.items()}","3069704c":"glovevalues = list(filter(lambda x: 300==len(x), glove.values()))\nmean_vec = np.mean(list(glovevalues), axis=0)\n\nword_embeddings = {k: glove[k] for k in unique_tokens if k in glove}\nword_embeddings.update({k: mean_vec for k in unique_tokens if k not in glove})","5c2be7d6":"len(word_embeddings)","da612382":"with open(\"word_embeddings.pickle\", \"wb\") as fp:\n    pickle.dump(word_embeddings, fp)","e48c2eef":"embedding_matrix = [word_embeddings[t][:] for _, t in idx2token.items()]","2c7e0b6f":"torch.tensor(embedding_matrix).shape","dbae0f4a":"with open(\"embeddings.pickle\", \"wb\") as fp:\n    all_infos = {\n        'SPECIAL_TOKENS': {\n            'PADDING_TOKEN': PADDING_TOKEN\n        },\n        'word_embeddings': word_embeddings,\n        'embedding_matrix': embedding_matrix,\n        'token2idx': token2idx,\n        'idx2token': idx2token\n    }\n    pickle.dump(all_infos, fp)","43f973f4":"with open(\"..\/input\/dsa5204-proj-lstm\/embeddings.pickle\", \"rb\") as fp:\n    all_infos = pickle.load(fp)\n    \nPADDING_TOKEN = all_infos['SPECIAL_TOKENS']['PADDING_TOKEN']\nword_embeddings = all_infos['word_embeddings']\nembedding_matrix = all_infos['embedding_matrix']\ntoken2idx = all_infos['token2idx']\nidx2token = all_infos['idx2token']","1123a6fc":"label2idx = {\"Negative\": 0, \"None\": 1, \"Positive\": 2}","d0376968":"train_data['label'] = train_data['label'].map(label2idx)\ndev_data['label'] = dev_data['label'].map(label2idx)\ntest_data['label'] = test_data['label'].map(label2idx)","620aa992":"train_data.head(1)","ab63748f":"def sentence2word_idx(s):\n    tokens = word_tokenize(s)\n    return [token2idx[t] for t in tokens][:PADDING_LEN] + [token2idx[PADDING_TOKEN]] * (PADDING_LEN - len(tokens)), min(len(tokens), PADDING_LEN)\n\ndef word_idx2sentence(s):\n    return [idx2token[i] for i in s if idx2token[i] is not PADDING_TOKEN]","700861e1":"PADDING_LEN = 64\ntrain_sentences, train_sentences_length = list(map(list, zip(*(map(sentence2word_idx, train_data['sentence'])))))\ntrain_sentences, train_sentences_length = torch.tensor(train_sentences), torch.tensor(train_sentences_length)\n\nPADDING_LEN = 10\ntrain_ta, train_ta_length = list(map(list, zip(*(map(sentence2word_idx, train_data['T-A'])))))\ntrain_ta, train_ta_length = torch.tensor(train_ta), torch.tensor(train_ta_length)\n\ntrain_labels = torch.tensor(train_data['label'])","e7523f7b":"def sentence2word_idx(s):\n    tokens = word_tokenize(s)\n    return [token2idx[t] for t in tokens][:PADDING_LEN] + [token2idx[PADDING_TOKEN]] * (PADDING_LEN - len(tokens)), min(len(tokens), PADDING_LEN)\n\nPADDING_LEN = 64\ndev_sentences, dev_sentences_length = list(map(list, zip(*(map(sentence2word_idx, dev_data['sentence'])))))\ndev_sentences, dev_sentences_length = torch.tensor(dev_sentences), torch.tensor(dev_sentences_length)\n\nPADDING_LEN = 10\ndev_ta, dev_ta_length = list(map(list, zip(*(map(sentence2word_idx, dev_data['T-A'])))))\ndev_ta, dev_ta_length = torch.tensor(dev_ta), torch.tensor(dev_ta_length)\n\ndev_labels = torch.tensor(dev_data['label'])","5bce0ded":"# weights = list(collections.Counter(train_labels.tolist()).values())\ntrain_counter = collections.Counter(train_labels.tolist())\ntrain_weights = [100.\/train_counter[label] for label in train_labels.tolist()]","5b2d3473":"from torch.utils.data.sampler import WeightedRandomSampler\n\nsampler = WeightedRandomSampler(torch.DoubleTensor(train_weights), len(train_weights), replacement=True)\n\ntrain_dataset = TensorDataset(train_sentences, train_sentences_length, train_ta, train_ta_length, train_labels)\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n\ndev_dataset = TensorDataset(dev_sentences, dev_sentences_length, dev_ta, dev_ta_length, dev_labels)\ndev_dataloader = DataLoader(dev_dataset, batch_size=32, shuffle=True)","460c071e":"class LSTMModel(nn.Module):\n    \"\"\" \n        - Bidrectional LSTM Encoder\n        - Unidirection LSTM Decoder\n        - Global Attention Model (Luong, et al. 2015)\n    \"\"\"\n    def __init__(self, embed_size, hidden_size, embedding_matrix, sentiment_size=3, dropout_rate=0.2):\n        \"\"\" Init Attention Model. \"\"\"\n        super(LSTMModel, self).__init__()\n        self.model_embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n        \n        self.hidden_size = hidden_size\n        self.dropout_rate = dropout_rate\n        self.sentiment_size = sentiment_size\n        # self.vocab = vocab\n\n        # default values\n        self.encoder = None \n        self.decoder = None\n        self.h_projection = None\n        self.c_projection = None\n        self.att_projection = None\n        self.combined_output_projection = None\n        self.sentiment_projection = None\n        self.dropout = None\n\n\n        self.encoder = nn.LSTM(embed_size, self.hidden_size, bidirectional=True)\n        self.decoder = nn.LSTM(embed_size, self.hidden_size, bidirectional=True)\n        self.combined_output_projection = nn.Linear(4 * self.hidden_size, self.hidden_size, False)\n        self.sentiment_projection = nn.Linear(self.hidden_size, self.sentiment_size)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.relu = nn.ReLU()\n\n        ### END YOUR CODE\n\n\n    def forward(self, sentence_1, lengths_1, sentence_2, lengths_2, label): # -> torch.Tensor\n        ''' Embedding Part '''\n        sentence_1 = self.model_embeddings(sentence_1)\n        sentence_2 = self.model_embeddings(sentence_2)\n#         print(sentence_1.shape, sentence_2.shape)\n        \n        ''' Encoding Part '''\n        # enc_hiddens, dec_init_state = self.encode(source_padded, source_lengths)\n        sorted_lengths_1, idx = lengths_1.sort(descending=True)\n        sorted_sentence_1 = sentence_1.index_select(0, idx).permute(1, 0, 2)\n        sorted_sentence_2 = sentence_2.index_select(0, idx).permute(1, 0, 2)\n        sorted_lengths_2 = lengths_2.index_select(0, idx)\n        sorted_label = label.index_select(0, idx)\n        \n        # print(sorted_sentence_2.size(), sorted_lengths_2)\n        enc_hiddens, dec_init_state = self.encode(sorted_sentence_1, sorted_lengths_1) # Encoder\n\n        dec_output, dec_out_state = self.decode(sorted_sentence_2, sorted_lengths_2) # Decoder\n\n        combined_state = torch.cat((dec_init_state, dec_out_state), dim=1)\n        \n        dec_output = self.combined_output_projection(torch.tanh(combined_state))\n        \n        P = F.log_softmax(self.sentiment_projection(self.relu(dec_output)), dim=-1).index_select(0, idx)\n        \n        return P\n\n\n    def encode(self, source_padded, source_lengths): #  -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]\n\n        enc_hiddens, dec_init_state = None, None\n\n        enc_hiddens = torch.nn.utils.rnn.pack_padded_sequence(source_padded, source_lengths.tolist())\n\n        lstm_output, temp_tuple = self.encoder(enc_hiddens)\n        last_hidden, last_cell = temp_tuple\n\n        X_pad_packed_sequence, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_output)\n        enc_hiddens = X_pad_packed_sequence.permute(1, 0, 2)\n        dec_init_state = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n\n        return enc_hiddens, dec_init_state\n\n\n    def decode(self, aux_padded, aux_lengths): #-> torch.Tensor\n\n        sorted_lengths_2, idx = aux_lengths.sort(descending=True)\n        \n        sorted_sentence_2 = aux_padded.index_select(1, idx) # The dim of batch index is 1 here\n\n        dec_hiddens = torch.nn.utils.rnn.pack_padded_sequence(sorted_sentence_2, sorted_lengths_2.tolist())\n        lstm_output, temp_tuple = self.decoder(dec_hiddens)\n        last_hidden, last_cell = temp_tuple\n        X_pad_packed_sequence, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_output)\n        dec_hiddens = X_pad_packed_sequence.permute(1, 0, 2)\n        dec_out_state = torch.cat((last_hidden[0], last_hidden[1]), dim=1).index_select(0, idx)\n\n        return dec_hiddens, dec_out_state","2605ae30":"model = LSTMModel(300, 128, embedding_matrix)","ff1c1869":"EPOCH = 10\n\nloss_function = nn.NLLLoss().to(device)\nlr = [1e-4] * 2 + [1e-5] * 2 + [5e-6] * 2+ [1e-6] * 2 + [5e-7] * 2\nstarttime = time()\n\nfor epoch in range(0, EPOCH):\n    # For evaluation\n    correct_num = 0\n    total_num = 0\n    tr_count_dict = dict()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr[epoch])\n\n    print('-' * 30 + \" Epoch {}\/{} \".format(epoch+1, EPOCH) + '-' * 30)\n    model.train()\n    train_preds = []\n    tr_loss = 0\n    tr_num = 0\n    for step, batch in enumerate(train_dataloader):\n        batch = tuple(t.to(device) for t in batch)\n        sent_tensor, sent_tensor_lengths, aux_tensor, aux_tensor_lengths, sent_labels = batch\n        sentiment_scores = model(sent_tensor, sent_tensor_lengths, aux_tensor, aux_tensor_lengths, sent_labels)\n        temp_batch_size = len(sent_tensor)\n        \n        optimizer.zero_grad()\n        loss = loss_function(sentiment_scores, sent_labels).mean()\n        loss.backward()\n        optimizer.step()\n        tr_loss += loss.item() * temp_batch_size\n        tr_num += temp_batch_size\n        \n        # Evaluation\n        logits = sentiment_scores.argmax(dim=1)\n        train_preds.extend(logits.tolist())\n        out_labels = sent_labels\n        correct_num += torch.sum(logits==out_labels)\n        total_num += temp_batch_size\n        if step % 100 == 0:\n            print(f\"Step: {step: 4d}\/{len(train_dataloader)}, Loss: {loss:.5f}, Train accu: {correct_num\/total_num:.5f}, time: {time()-starttime:.2f}s\")\n    train_accuracy = correct_num \/ total_num\n    tr_loss \/= tr_num\n    \n    # Dev set evalution\n    model.eval()\n    \n    eval_preds = []\n    correct_num = 0\n    total_num = 0\n    dev_count_dict = dict()\n    dev_loss = 0\n    for step, batch in enumerate(dev_dataloader):\n        # print(step)\n        batch = tuple(t.to(device) for t in batch)\n        sent_tensor, sent_tensor_lengths, aux_tensor, aux_tensor_lengths, sent_labels = batch\n        temp_batch_size = len(sent_tensor)\n        \n        with torch.no_grad():\n            sentiment_scores = model(sent_tensor, sent_tensor_lengths, aux_tensor, aux_tensor_lengths, sent_labels)\n            dev_loss += loss_function(sentiment_scores, sent_labels).item()\n            \n        logits = sentiment_scores.argmax(dim=1)\n        eval_preds.extend(logits.tolist())\n        out_labels = sent_labels\n        correct_num += torch.sum(logits==out_labels)\n        total_num += temp_batch_size\n        \n    dev_accuracy = correct_num \/ total_num\n    dev_loss \/= total_num\n    \n    print()\n    print(\"Train accuracy: {}\".format(train_accuracy))\n    print(\"Train loss: \\t{}\".format(tr_loss))\n    print(\"Train preds: \\t{}\".format(collections.Counter(train_preds)))\n    print(\"Dev accuracy: \\t{}\".format(dev_accuracy))\n    print(\"Dev loss: \\t{}\".format(dev_loss))\n    print(\"Eval preds: \\t{}\".format(collections.Counter(eval_preds)))\n    \n    print(\"Time Consumed: \\t{}\".format(time() - starttime))\n    print()","b716e1b5":"starttime = time()\n\npreds = []\n\nmodel.eval()\n\ncorrect_num = 0\ntotal_num = 0\ndev_count_dict = dict()\ndev_loss = 0\n\nfor step, batch in enumerate(dev_dataloader):\n    # print(step)\n    batch = tuple(t.to(device) for t in batch)\n    sent_tensor, sent_tensor_lengths, aux_tensor, aux_tensor_lengths, sent_labels = batch\n    temp_batch_size = len(sent_tensor)\n\n    with torch.no_grad():\n        sentiment_scores = model(sent_tensor, sent_tensor_lengths, aux_tensor, aux_tensor_lengths, sent_labels)\n        dev_loss += loss_function(sentiment_scores, sent_labels).item()\n\n    logits = sentiment_scores.argmax(dim=1)\n    preds.extend(logits.tolist())\n    out_labels = sent_labels\n    correct_num += torch.sum(logits==out_labels)\n    total_num += temp_batch_size\n\ndev_accuracy = correct_num \/ total_num\ndev_loss \/= total_num\n\nprint(\"Dev accuracy: \\t{}\".format(dev_accuracy))\nprint(\"Dev loss: \\t{}\".format(dev_loss))\nprint(\"Time Consumed: \\t{}\".format(time() - starttime))\nprint(\"Eval preds: \\t{}\".format(collections.Counter(preds)))\nprint()","83448d25":"torch.save(model.state_dict(), f'lstm_for_5204.model')","98b7ac88":"# Process Data","10cd19a0":"# Read Glove Pickle\n\n(Around 30-40s)","3fc6ba28":"# Prepare word embedding (from Glove)\n\n## Read data","ca3318ae":"# Model definition","19d303a5":"## Prepare embeddings","384d2621":"# Model training","dc205f9a":"## Labels"}}