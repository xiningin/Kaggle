{"cell_type":{"8a7cbdd1":"code","3222da00":"code","c79a8556":"code","8fc9e604":"code","fc3c09d6":"code","3cb73398":"code","dc812ce6":"code","e681a9dd":"code","f895922d":"code","f63ca7fa":"code","4002fe41":"code","766bf959":"code","c287017b":"code","0f146de9":"code","72f88e03":"code","cad4434b":"code","d1230112":"code","21fa8033":"code","1e5c0173":"code","ad0d54dd":"code","b4064e2e":"code","f4941286":"code","a5218f5d":"code","b19f7b56":"markdown","7fdc6086":"markdown","c7b449f7":"markdown","967b4cb0":"markdown","f1676f52":"markdown","81b59581":"markdown","13623ad8":"markdown","fe9d2f2b":"markdown","01795603":"markdown","afecdde0":"markdown","c257462b":"markdown","78a29f5f":"markdown","d7fa1536":"markdown","e59826a2":"markdown","f42a57cc":"markdown","87d1a488":"markdown","f44640f4":"markdown"},"source":{"8a7cbdd1":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#ignore warning messages\nimport warnings\nwarnings.filterwarnings('ignore')\nimport plotly\nplotly.offline.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom wordcloud import WordCloud\nfrom wordcloud import WordCloud,STOPWORDS\n!pip3 install flair\nfrom flair.data import Sentence\nfrom flair.models import TextClassifier\nfrom time import time","3222da00":"df = pd.read_csv('..\/input\/trumps-legacy\/Trumps Legcy.csv')","c79a8556":"df[\"date\"] = pd.to_datetime(df[\"date\"])\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day'] = df['date'].dt.day\ndf['hour'] = df['date'].dt.hour\n\n# Consider data from 2017\ndf_2017 = df[df.year>2017].copy();\ndf_2017.shape","8fc9e604":"def flair_sentiment(texts, classifier):\n    sentences = [Sentence(text) for text in texts]\n    classifier.predict(sentences, mini_batch_size=1024)\n    result_ = [-1*sent.labels[0].score if sent.labels[0].value == 'NEGATIVE'\\\n               else sent.labels[0].score \\\n               for sent in sentences]\n    return result_\n\nclassifier = TextClassifier.load('sentiment-fast')\n\n# start_time = time()\n# tweets = 10 * [\n#     \"For what a beautiful day. #elated\",\n#     \"It's broken\"\n# ]\n# sentiments = flair_sentiment(tweets, classifier)\n# print(sentiments)","fc3c09d6":"df_2017.head()","3cb73398":"df_2017.shape","dc812ce6":"df_2017['sentiments'] = flair_sentiment(df_2017.text, classifier) ","e681a9dd":"df_2017_sentiment = df_2017[['text', 'sentiments']]\ndf_2017_sentiment['text'] = df_2017_sentiment['text'].str.lower()\ndf_2017_sentiment.to_csv(\".\/df_2017_sentiment.csv\", index=False)","f895922d":"df_2017_sentiment = pd.read_csv(\".\/df_2017_sentiment.csv\")","f63ca7fa":"words = ['korea', 'india', 'china','pakistan', 'mexico']\ndf_2017_sentiment[df_2017_sentiment.text.str.contains('|'.join(words))].count()","4002fe41":"df_2017_sentiment.head()","766bf959":"df_2017_sentiment.loc[df_2017_sentiment.text.str.contains('korea'), 'Tag']='KOR'\ndf_2017_sentiment.loc[df_2017_sentiment.text.str.contains('mexico'), 'Tag']='MEX'\ndf_2017_sentiment.loc[df_2017_sentiment.text.str.contains('pakistan'), 'Tag']='PAK'\ndf_2017_sentiment.loc[df_2017_sentiment.text.str.contains('india'), 'Tag']='IND'\ndf_2017_sentiment.loc[df_2017_sentiment.text.str.contains('china'), 'Tag']='CHN'","c287017b":"df_2017_sentiment['Tag'].value_counts()","0f146de9":" def showWordCloud(data):\n    words = ' '.join(data)\n    STOPWORDS.update([\"https\",\"t\",\"co\",\"u\",\"s\",\"rt\", \"amp\",\"china\"])    \n    cleaned_word = \" \".join([word for word in words.split()])\n    wordcloud = WordCloud(stopwords = STOPWORDS,\n                         background_color = 'black',\n                         width = 2500,\n                         height = 2500\n                         ).generate(cleaned_word)\n    plt.figure(1,figsize = (13,13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\nshowWordCloud(df_2017_sentiment.loc[df_2017_sentiment.Tag == 'CHN']['text'])","72f88e03":"print(\"Positive tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'CHN']['sentiments']>0).sum())\nprint(\"Negative tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'CHN']['sentiments']<0).sum())","cad4434b":" def showWordCloud(data):\n    words = ' '.join(data)\n    STOPWORDS.update([\"https\",\"t\",\"co\",\"u\",\"s\",\"rt\", \"amp\",\"mexico\"])    \n    cleaned_word = \" \".join([word for word in words.split()])\n    wordcloud = WordCloud(stopwords = STOPWORDS,\n                         background_color = 'black',\n                         width = 2500,\n                         height = 2500\n                         ).generate(cleaned_word)\n    plt.figure(1,figsize = (13,13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\nshowWordCloud(df_2017_sentiment.loc[df_2017_sentiment.Tag == 'MEX']['text'])","d1230112":"print(\"Positive tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'MEX']['sentiments']>0).sum())\nprint(\"Negative tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'MEX']['sentiments']<0).sum())","21fa8033":" def showWordCloud(data):\n    words = ' '.join(data)\n    STOPWORDS.update([\"https\",\"t\",\"co\",\"u\",\"s\",\"rt\", \"amp\",\"korea\"])    \n    cleaned_word = \" \".join([word for word in words.split()])\n    wordcloud = WordCloud(stopwords = STOPWORDS,\n                         background_color = 'black',\n                         width = 2500,\n                         height = 2500\n                         ).generate(cleaned_word)\n    plt.figure(1,figsize = (13,13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\nshowWordCloud(df_2017_sentiment.loc[df_2017_sentiment.Tag == 'KOR']['text'])","1e5c0173":"print(\"Positive tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'KOR']['sentiments']>0).sum())\nprint(\"Negative tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'KOR']['sentiments']<0).sum())","ad0d54dd":" def showWordCloud(data):\n    words = ' '.join(data)\n    STOPWORDS.update([\"https\",\"t\",\"co\",\"u\",\"s\",\"rt\", \"amp\",\"india\", \"indian\", \"indiana\"])    \n    cleaned_word = \" \".join([word for word in words.split()])\n    wordcloud = WordCloud(stopwords = STOPWORDS,\n                         background_color = 'black',\n                         width = 2500,\n                         height = 2500\n                         ).generate(cleaned_word)\n    plt.figure(1,figsize = (13,13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\nshowWordCloud(df_2017_sentiment.loc[df_2017_sentiment.Tag == 'IND']['text'])","b4064e2e":"print(\"Positive tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'IND']['sentiments']>0).sum())\nprint(\"Negative tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'IND']['sentiments']<0).sum())","f4941286":" def showWordCloud(data):\n    words = ' '.join(data)\n    STOPWORDS.update([\"https\",\"t\",\"co\",\"u\",\"s\",\"rt\", \"amp\",\"pakistan\"])    \n    cleaned_word = \" \".join([word for word in words.split()])\n    wordcloud = WordCloud(stopwords = STOPWORDS,\n                         background_color = 'black',\n                         width = 2500,\n                         height = 2500\n                         ).generate(cleaned_word)\n    plt.figure(1,figsize = (13,13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\nshowWordCloud(df_2017_sentiment.loc[df_2017_sentiment.Tag == 'PAK']['text'])","a5218f5d":"print(\"Positive tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'PAK']['sentiments']>0).sum())\nprint(\"Negative tweets: \", (df_2017_sentiment.loc[df_2017_sentiment.Tag == 'PAK']['sentiments']<0).sum())","b19f7b56":"# Conclusion\n* Trump is very active talking about countries and mostly negative :)\n* key issues are clear from wordclouds of respective country tweets\n\n# Please **comment** and **upvote** which will motivate me for more notebooks.","7fdc6086":"# India","c7b449f7":"# How many times Trump discussed a particular country in his tweets and if we can label the sentiments? (North Korea, India, Pakistan, Mexico?)","967b4cb0":"Consider the tweets from 2017 i.e, time when he became President of US","f1676f52":"# Let me tag based on tweets containing the country names","81b59581":"# Korea","13623ad8":"# Trumps Legacy\n![trump-legacy.png](attachment:trump-legacy.png)\n\nUnited States 45th President Donald Trump has used Twitter as no one else. He primarily ran his government from a twitter firehose. Twitter has officially banned his account on January 8th 2021 after a deadly riot at Capitol on January 6th 2021. Twitter cites its World Leaders on Twitter: Principles and Approach as a guide to adhere to for public leaders.\n\nTrump tweets and policies have far reaching effects that one can realize or he would accept to realize himself. Since, twitter is suspended there is no public way to read his past tweets and analyze it for public policy outcome or link it with global issues.\n\nHere we are presenting the complete treasure trove of President Trump's tweet, all 56,572 for the public, data scientists and researchers.\n\nIm trying to look around below question hinted by respected Dataset Master\n\n* How many times Trump discussed a particular country in his tweets and if we can label the sentiments? (North Korea, India, Pakistan, Mexico?)\n","fe9d2f2b":"> Tweets are talking about trade, tariffs, virus","01795603":"# China","afecdde0":"# Mexico","c257462b":"# Load Libraries and Download Data","78a29f5f":"# Predict results of all tweets from 2017","d7fa1536":"# Running on full batch of tweets from 2017","e59826a2":"# Lets look at what Trump saying about each country","f42a57cc":"# Pakistan","87d1a488":"# Quick Test on flair model for batch prediction","f44640f4":"> Total of 996 tweets are about the countries"}}