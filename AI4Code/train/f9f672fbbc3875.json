{"cell_type":{"6a4f9be5":"code","aa1939a0":"code","d1bed412":"code","57116408":"code","3bdd4cb3":"code","1c0aebf9":"code","d551c4c4":"code","e7d1771e":"code","58ef335f":"code","ab242e3d":"code","5b8a80e3":"code","1e890acf":"code","057cd14d":"code","d957ef17":"code","f9036ea6":"markdown","b546b5c7":"markdown"},"source":{"6a4f9be5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","aa1939a0":"!git clone https:\/\/github.com\/spMohanty\/PlantVillage-Dataset","d1bed412":"import shutil\nimport glob\n\nif (os.path.exists(os.getcwd()+\"\/TomatoDataset\") is False):\n    os.mkdir(\"TomatoDataset\")\n\n    for path in glob.glob(os.getcwd()+\"\/PlantVillage-Dataset\/raw\/color\/Tomato*\"):\n        shutil.move(path, os.getcwd()+\"\/TomatoDataset\/\"+path.split('\/')[-1])","57116408":"!rm -r PlantVillage-Dataset #delete the cloned repository to free space","3bdd4cb3":"# I am using split-folders for the task, you could use other methods\n! pip install split-folders\n\n! split_folders .\/TomatoDataset --ratio .6 .2 .2\n\n# rename the folder to for better description\n# split-folder output folder is named output, we had to change that\n! mv output TomatoDatasetTrainTestValSplit\n\n# the folder structure will be\n# |--TomatoDatasetTrainTestValSplit\n# |  |--train\n# |     |--{the tomato classes folder1}\n# |     |--{the tomato classes folder2}  \n# |     |             .\n# |     |             .\n# |     |             .\n# |     |--{the tomato classes folderN}\n# |  |--test\n# |     |--{the tomato classes folder1}\n# |     |--{the tomato classes folder2}\n# |     |             .\n# |     |             .\n# |     |             .\n# |     |--{the tomato classes folderN}\n# |  |--val\n# |     |--{the tomato classes folder1}\n# |     |--{the tomato classes folder2}\n# |     |             .\n# |     |             .\n# |     |             .\n# |     |--{the tomato classes folderN}","1c0aebf9":"train_data_dir = '.\/TomatoDatasetTrainTestValSplit\/train'\nval_data_dir = '.\/TomatoDatasetTrainTestValSplit\/val'\ntest_data_dir = '.\/TomatoDatasetTrainTestValSplit\/test'","d551c4c4":"import math \n\nbatch_size = 64\nimage_size = (224,224)\n\nnum_train_samples = sum([len(files) for root, directory, files in os.walk(train_data_dir)])\nnum_train_steps = math.floor(num_train_samples\/batch_size)\n\nnum_val_samples = sum([len(files) for root, directory, files in os.walk(val_data_dir)])\nnum_val_steps = math.floor(num_val_samples\/batch_size)","e7d1771e":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_data_generator = ImageDataGenerator(\n    rotation_range=10,\n    horizontal_flip=True,\n    vertical_flip=True,\n    width_shift_range=0.1,\n     height_shift_range=0.1,\n    rescale=1.\/255,\n     fill_mode='constant'\n)\n\ntrain_generator = train_data_generator.flow_from_directory(\n    train_data_dir, # the location of the training folder\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='sparse', # there are 2 types, sparse or binary (if we are predicting only disease and non disease, thats when we use binary, else we use sparse when its more than 2)\n    color_mode='rgb', # we can skip this line cos our image is rgb, but if we want ti to be grey we can change it\n    shuffle=True # this just determines the order in which the generator will give us the images, random is ususlly better\n)\ntrain_generator.class_indices\n\nval_data_generator = ImageDataGenerator(rescale=1.\/255)\n\nval_generator = val_data_generator.flow_from_directory(\n    val_data_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='sparse',\n    color_mode='rgb',\n    shuffle=True\n)","58ef335f":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense ,BatchNormalization, Dropout\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.callbacks import EarlyStopping\n\ninput_tensor = Input(shape=(224,224,3))\n\nbase_model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n\nfor i, layer in enumerate(base_model.layers):\n  print(i, layer.name)","ab242e3d":" for layer in base_model.layers:\n    layer.trainable=True\n  \nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(10,activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=x)\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","5b8a80e3":"epochs = 1000\n\nearly_stopping =  EarlyStopping(monitor='val_accuracy', patience=15, mode='auto', min_delta=0.95)\n\n\nprint('starting model training and saving history')\nhistory = model.fit_generator(\n    train_generator,\n    epochs=epochs,\n    validation_data=val_generator,\n    callbacks=[early_stopping]\n)","1e890acf":"history.history.keys()","057cd14d":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","d957ef17":"import pandas as pd\n\nif (os.path.exists(os.getcwd()+\"\/models\") is False):\n  os.mkdir(\"models\")\n  pd.DataFrame(history.history).to_csv('.\/models\/inveption_v3_tl_history_0_10.csv')\n  model.save(\".\/models\/inveption_v3_tl_model_0_10.h5\")","f9036ea6":"**Prepare Dataset**","b546b5c7":"**Start Building Model**"}}