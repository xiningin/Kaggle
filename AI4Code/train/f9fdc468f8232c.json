{"cell_type":{"51b04e7f":"code","53f81bcd":"code","b3fafcfe":"code","04141baa":"code","c609452d":"code","20ec248e":"code","093b2e18":"code","e0d47976":"code","14d3ee55":"code","5ac70839":"code","7eaf5918":"code","55bfff77":"code","63981e5f":"code","fe215155":"code","aabfead9":"code","2d02b4c5":"code","5941a5d1":"code","18200716":"code","da1588ab":"code","6fbbd279":"code","db86ed22":"markdown","5237c48a":"markdown","98b02f9b":"markdown","54a28389":"markdown"},"source":{"51b04e7f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import datasets\nimport seaborn as sn\nfrom plotnine.data import economics\n#from plotnine import ggplot, aes, geom_line\nfrom plotnine import *\n\n%matplotlib inline","53f81bcd":"dataset=pd.read_csv('..\/input\/iriscsv\/Iris (2).csv')\niris_df = pd.DataFrame(dataset)\niris_df # See the first 5 rows","b3fafcfe":"\nggplot(iris_df, aes(x='SepalLengthCm', fill = 'Species'))+ theme_bw()+geom_density(alpha=0.25)\n","04141baa":"iris_df.shape","c609452d":"iris_df.Species.unique()","20ec248e":"iris_df.isnull().sum()","093b2e18":"iris_df.duplicated().any()","e0d47976":"iris_df.describe()","14d3ee55":"iris_df.drop(['Id'],axis=1, inplace =True)","5ac70839":"from sklearn.preprocessing import LabelEncoder\nl = LabelEncoder()\niris_df['Species'] = l.fit_transform(iris_df['Species'])\n","7eaf5918":"x=iris_df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\n\nx","55bfff77":"from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt","63981e5f":"#within cluster sum of square\nx=iris_df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\nwcss = []\nfor i in range(1, 15):\n    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 15), wcss)\nplt.plot(np.arange(1, 15), wcss,'o')\n\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","fe215155":"# Applying kmeans to the dataset \/ Creating the kmeans classifier\nkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\nk_model=kmeans.fit(x)\niris_df['cluster']=kmeans.predict(x)\n","aabfead9":"#return the cluster vector\nclusters=k_model.labels_\nclusters\n","2d02b4c5":"iris_df['cluster'] = clusters\n","5941a5d1":"plt.show()\nplt.scatter(x.iloc[:,0], x.iloc[:,1])\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=100, c='red',label='centroid')\nplt.title('Clusters ')\nplt.legend()\nplt.show()\nplt.show()\n","18200716":"y=iris_df.Species","da1588ab":"from mpl_toolkits.mplot3d import Axes3D\n","6fbbd279":"v = np.random.rand(10,4)\nv[:,3] = np.random.randint(0,2,size=10)\niris_df = pd.DataFrame(v, columns=['SepalLengthCm','SepalWidthCm','PetalLengthCm',\"Cluster\"])\nprint (iris_df)\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nx = np.array(iris_df['SepalLengthCm'])\ny = np.array(iris_df['SepalWidthCm'])\nz = np.array(iris_df['PetalLengthCm'])\n\nax.scatter(x,y,z, marker=\"s\", c=iris_df[\"Cluster\"], s=40, cmap=\"RdBu\")\n\nplt.show()\n","db86ed22":"### TASK-02 Prediction using Unsupervised ML\n","5237c48a":"##### AUTHOR-HIMANI CHHOKAR","98b02f9b":"#### lets visualize the set before clustering","54a28389":"## clustering \nClustering is the task of dividing the population or data points into a number of groups such that data points in the same groups are more similar to other data points in the same group than those in other groups. In simple words, the aim is to segregate groups with similar traits and assign them into clusters. The goal of the k-means algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided.\n\n\nK-Means Clustering algorithm used for unsupervised learning for clustering problem. K- variable value easily decide based \non the number of clusters business is looking for.Popular Distance measures to use: Euclidean distance.Specify number \nof clusters K.Initialize centroids by first shuffling the dataset and then randomly selecting K data points for the\ncentroids without replacement.Keep iterating until there is no change to the centroids. i.e assignment of data points\nto clusters isn\u2019t changing.\n"}}