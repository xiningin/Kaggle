{"cell_type":{"a460acbc":"code","76e92407":"code","7a1c3a03":"code","174ddbbf":"code","dfc97034":"code","1e718045":"code","bcec5c73":"code","0ea97bae":"code","dc8bdbb2":"code","d6bf0369":"code","32796c96":"code","6a3d2fd2":"code","426309a3":"code","c0d17958":"code","f645a5ca":"code","97fee2aa":"markdown","4fcb55ea":"markdown","8e6cbb70":"markdown","6a29c4a0":"markdown","bcfb148c":"markdown","4a247567":"markdown"},"source":{"a460acbc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","76e92407":"# Import our libraries we are going to use for our data analysis.\nimport tensorflow as tf\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Plotly visualizations\nfrom plotly import tools\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n# plotly.tools.set_credentials_file(username='AlexanderBach', api_key='o4fx6i1MtEIJQxfWYvU1')\n\n\n# For oversampling Library (Dealing with Imbalanced Datasets)\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\n# Other Libraries\nimport time","7a1c3a03":"df= pd.read_csv('..\/input\/lc_2016_2017.csv', low_memory=False)\ndf.head()","174ddbbf":"df_sample = df.sample(frac=0.1)\ndf_sample.shape","dfc97034":"df_sample.isnull().sum()","1e718045":"df_sample1=df_sample.dropna(thresh=df_sample.shape[0]*0.9,how='all',axis=1)\ndf_sample1.isnull().sum()","bcec5c73":"df_sample1.shape","0ea97bae":"import plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport warnings\nfrom collections import Counter","dc8bdbb2":"\ntrace0 = go.Bar(\n    x = df_sample1.emp_title.value_counts()[:30].index.values,\n    y = df_sample1.emp_title.value_counts()[:30].values,\n    marker=dict(\n        color=df_sample1.emp_title.value_counts()[:30].values\n    ),\n)\n\ndata = [trace0]\n\nlayout = go.Layout(\n    yaxis=dict(\n        title='Count'\n    ),\n    xaxis=dict(\n        title='Employment name'\n    ),\n    title='TOP 40 Employment Title'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='emp-title-bar')","d6bf0369":"print(pd.crosstab(df_sample1[\"emp_length\"], df_sample1[\"application_type\"]))\n\nfig, ax = plt.subplots(2,1, figsize=(12,10))\ng = sns.boxplot(x=\"emp_length\", y=\"int_rate\", data=df_sample1,\n              palette=\"hls\",ax=ax[0],\n               order=[\"n\/a\",'< 1 year','1 year','2 years','3 years','4 years', '5 years',\n                      '6 years', '7 years', '8 years','9 years','10+ years'])\n\nz = sns.violinplot(x=\"emp_length\", y=\"loan_amnt\",data=df_sample1, \n               palette=\"hls\", ax=ax[1],\n               order=[\"n\/a\",'< 1 year','1 year','2 years','3 years','4 years', '5 years',\n                      '6 years', '7 years', '8 years','9 years','10+ years'])\n               \nplt.legend(loc='upper left')\nplt.show()","32796c96":"fig, ax = plt.subplots(2, 1, figsize=(12, 8))\nplt.subplots_adjust(wspace=1.0, hspace=0.50)\ndf_sample1.emp_length.value_counts().plot(kind=\"bar\", ax=ax[0])\nax[0].set_title(\"Employment Length Count\")\ndf_sample1.purpose.value_counts().plot(kind=\"bar\", ax=ax[1])\nax[1].set_title(\"Loan Purposes\")\nplt.xticks(rotation=60)","6a3d2fd2":"df_sample1.emp_title.value_counts()\ndf_sample1.title.value_counts()\ndf_sample2 = df_sample1.dropna(subset=['revol_util','dti', 'title','mths_since_rcnt_il','all_util','inq_fi','total_cu_tl','inq_last_12m'])\ndf_sample2.isnull().sum()\ndf_sample3=df_sample2.drop(['last_pymnt_d','emp_title'],axis=1)","426309a3":"df_sample3[\"emp_length\"]=df_sample3[\"emp_length\"].fillna(\"< 1 year\")","c0d17958":"tot_cel = df_sample3.isnull().sum().sum()\nprint(tot_cel)\nplt.figure(figsize=(15,4))\nsns.heatmap(df_sample3.isnull(), cbar = False, yticklabels=False, cmap=\"magma\" )","f645a5ca":"df_sample3.isnull().sum()","97fee2aa":"Becasue the dataset is very large, we randomly select 10% of the orginal data","4fcb55ea":"We only uses data set from 2016-2017","8e6cbb70":"Type mployment titles span from teacher, manager to truck driver and has more 20K different entries, this is mainly because those data were entered by applicants\/borrowers themselves. To simplify our work, we decided to drop this column.","6a29c4a0":"Drop missing value columns","bcfb148c":"**Check the missing value of the new df**","4a247567":"We only keep columns that has >90% not null data "}}