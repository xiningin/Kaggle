{"cell_type":{"e9940e7a":"code","5598f8e1":"code","95b066cd":"code","81f45e6c":"code","f1b11c9a":"code","b4549aa5":"code","af5dfa29":"code","ca8ac69b":"code","91122855":"code","3d731369":"code","d9856d3e":"code","f3443594":"code","646524c6":"code","3787d84b":"code","61e46fb2":"code","29fcbfe2":"code","c714292c":"code","d929746a":"code","dc9927dc":"code","4993be7d":"code","7198293e":"code","2503c9df":"code","45835fe2":"code","6113519b":"code","24b87aeb":"code","1c2d7407":"code","77c91e72":"code","be645776":"code","9d08d201":"code","f51f9bf9":"code","177a7df6":"code","3c707aac":"code","57222bc2":"code","f7641d73":"markdown","4b610ec2":"markdown","7c51bfda":"markdown","6042a3ff":"markdown","656c158a":"markdown","8c30f6db":"markdown","fea143cd":"markdown","d6d86fb8":"markdown","5abfbf4b":"markdown","81342c6f":"markdown","9738d5bc":"markdown","538fda47":"markdown","1a197988":"markdown","358804e2":"markdown","bd9ec0f3":"markdown","f51cbad8":"markdown","87de2a33":"markdown","0b39bc87":"markdown","5ef76be6":"markdown","2449229b":"markdown","080df6bc":"markdown","566b8524":"markdown","3932cceb":"markdown","cb8fa9a8":"markdown","81f65fab":"markdown","4ba917e8":"markdown","5d15fe9e":"markdown","2ddef051":"markdown","408c8ec3":"markdown"},"source":{"e9940e7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5598f8e1":"df = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\nimport matplotlib.pyplot as plt\nimport seaborn as sns","95b066cd":"#df.columns = df.columns.str.strip()\n#df.columns = df.columns.str.replace(' ', '')","81f45e6c":"def coldat0(serie):\n    X0 = df[[i for i in df.columns if serie in i]]\n    X = pd.Series(dtype='int')\n    for i in X0.columns:\n        X[X0[i].value_counts().index[0]] = X0[i].count()\n    return X.sort_values()\ndef coldat2(serie):\n    dman = df[(df['Q2']=='Man').values]\n    dwoman = df[(df['Q2']=='Woman').values]  \n    man0 = dman[[i for i in df.columns if serie in i]]\n    man = pd.Series(dtype='int')\n    woman0 = dwoman[[i for i in df.columns if serie in i]]\n    woman = pd.Series(dtype='int')\n    for i in man0.columns:\n        man[man0[i].value_counts().index[0]] = man0[i].count()\n    for i in woman0.columns:\n        woman[woman0[i].value_counts().index[0]] = -woman0[i].count()    \n    return man.sort_values(), woman.sort_values()","f1b11c9a":"def Plot_dix(title, serie, order):\n    check = ['Q7', 'Q9', 'Q10', 'Q12', 'Q14', 'Q16', 'Q17', 'Q18', 'Q19', 'Q23','Q26_A','Q26_B','Q27_A','Q27_B','Q28_A','Q28_B',\n             'Q29_A','Q29_B', 'Q31_A', 'Q31_B','Q33_A','Q33_B', 'Q34_A', 'Q34_B','Q35_A','Q35_B','Q36', 'Q37', 'Q39']\n        \n    f = plt.figure(figsize=(24,7)) \n    \n    ax=f.add_subplot(121)\n    if serie in check:\n        X = coldat0(serie)\n    else:\n        X = df[serie].value_counts()[order]\n    ax.bar(X.index, X, width=0.4,edgecolor='darkgreen', color='grey',linewidth=0.7)\n    ma = round(X.max()+1000,3) * 0.02\n    for i in X.index:\n        ax.annotate(f\"{X[i]}\", xy=(i, X[i] + ma), va = 'center', ha='center',fontweight='light', fontsize=12, fontfamily='serif',color='black')\n    ax.set_xticklabels(X.index, fontfamily='serif',rotation=90, fontweight='bold', fontsize=14)\n    f.text(0.1, 0.95, title, fontsize=16, fontweight='bold', fontfamily='serif')   \n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\n    ax=f.add_subplot(122)    \n    if serie in check:\n        man, woman = coldat2(serie)\n    else:\n        dman = df[(df['Q2']=='Man').values]\n        dwoman = df[(df['Q2']=='Woman').values]\n        man = dman[serie].value_counts()[order]\n        woman = -dwoman[serie].value_counts()[order]\n    mp = round(man.max()+1000,3) * 0.02\n    mn = - round(woman.min()-1000,3) * 0.05\n    ax.bar(man.index, man, width=0.4, color='green', alpha=0.8, label='Man')\n    ax.bar(woman.index, woman, width=0.4, color='red', alpha=0.8, label='Woman')\n    for i in man.index:\n        ax.annotate(f\"{man[i]}\", xy=(i, man[i] + mp),va = 'center', ha='center',fontsize=12,fontfamily='serif',color='black')\n    for i in woman.index:\n        ax.annotate(f\"{-woman[i]}\", xy=(i, woman[i] - mn), va = 'center', ha='center',fontsize=12,fontfamily='serif',color='black')    \n    \n    ax.set_xticklabels(man.index, fontfamily='serif', rotation =90, fontweight='bold', fontsize=14)\n    ax.legend()\n    f.text(0.55, 0.95, title + '\\n of man vs woman', fontsize=16, fontweight='bold', fontfamily='serif')  ","b4549aa5":"def Plot_heatmap(title, serie1, order1, serie2, order2):\n    df['count'] = 1\n    fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n\n    sns.heatmap(pd.pivot_table(df, values='count', index=[serie1], columns=[serie2], aggfunc=np.sum).loc[order1, order2],cmap='viridis', square=True, linewidth=3, cbar=False, ax=ax,annot=True, fmt='n')\n    \n    fig.text(0.4, 1, title, fontweight='bold', fontfamily='serif', fontsize=15)\n    ax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=12)\n    ax.set_xticklabels(ax.get_xticklabels(), fontfamily='serif', rotation = 90, fontsize=12)\n    plt.tight_layout()\n    plt.show()","af5dfa29":"def Plot_Muldix(title, serie1, serie2, order2):\n    didj = pd.pivot_table(df, values='count', index=[serie1], columns=[serie2], aggfunc=np.sum).fillna(0).astype(int).loc[:,order2]\n    didj = (didj.T \/ didj.sum(axis=1))\n    \n    fig, ax = plt.subplots(len(didj.columns),1,figsize=(13, 25), sharex=True)\n    for idx2, idx1 in enumerate(didj.columns):\n        ax[idx2].text(-1.6 ,0 ,idx1, fontfamily='serif', fontsize=11,ha=\"right\")\n        ax[idx2].bar(didj[idx1].index, didj[idx1], color='green', edgecolor='black', linewidth=0.6, width=0.6)\n        ax[idx2].set_yticks([])\n    \n    fig.text(0.13, 0.90, title, fontsize=17, fontweight='bold', fontfamily='serif') \n    plt.subplots_adjust(hspace=0)\n    ax[-1].set_xticklabels(order2, fontfamily='serif', rotation=90)\n    plt.show()","ca8ac69b":"# https:\/\/stackoverflow.com\/questions\/56337732\/how-to-plot-scatter-pie-chart-using-matplotlib\ndef drawPieMarker(xs, ys, ratios, sizes, colors, ax):\n    markers = []\n    previous = 0\n    # calculate the points of the pie pieces\n    for color, ratio in zip(colors, ratios):\n        this = 2 * np.pi * ratio + previous\n        x  = [0] + np.cos(np.linspace(previous, this, 30)).tolist() + [0]\n        y  = [0] + np.sin(np.linspace(previous, this, 30)).tolist() + [0]\n        xy = np.column_stack([x, y])\n        previous = this\n        markers.append({'marker':xy, 's':np.abs(xy).max()**2*np.array(sizes), 'facecolor':color})\n    # scatter each of the pie pieces to create pies\n    for marker in markers:\n        ax.scatter(xs, ys, **marker, alpha=0.7)\n\ndef Pivot_ij(serie1, serie2, order1, order2):\n    return pd.pivot_table(df, values='count', index=[serie1], columns=[serie2],aggfunc=np.sum).fillna(0).astype(int).loc[order1, order2].stack()\n\ndef Pivot_ijk(serie1, serie2, order1, order2, gender):\n    return pd.pivot_table(df[df['Q2']==gender], values='count', index=[serie1], columns=[serie2],aggfunc=np.sum).fillna(0).astype(int).loc[order1, order2].stack()","91122855":"def Plot_matrix0(title, serie1, order1, serie2,  order2):\n    \n    fig = plt.figure(figsize=(20, 23), dpi=200)\n    gs = fig.add_gridspec(5, 5)\n\n    ax_plot = fig.add_subplot(gs[1:4, 0:4]) \n    data_ij = Pivot_ij(serie1, serie2, order1, order2)   \n    for idx1 in order1[::-1]:\n        for idx2 in order2:\n            dat = data_ij[idx1][idx2]\n            ax_plot.scatter(idx2, idx1, s=dat, color='darkblue')\n    ax_plot.grid(linewidth=0.2, zorder=0)        \n    ax_plot.set_yticklabels(idx1, fontfamily='serif', fontsize=15)\n    ax_plot.set_xticklabels(idx2, fontfamily='serif', fontsize=15, rotation=90)\n# Pos\n    ax_pos = fig.add_subplot(gs[0, :4], sharex=ax_plot) \n    data_j = df[serie2].value_counts()[order2]\n    ax_pos.bar(data_j.index, data_j, width=0.35, alpha=0.85, color='darkblue')\n    plt.setp(ax_pos.get_xticklabels(), visible=False)\n# Exp\n    ax_exp = fig.add_subplot(gs[1:4, 4], sharey=ax_plot) \n    data_i = df[serie1].value_counts()[order1]\n    ax_exp.barh(data_i.index[::-1], data_i[::-1], height=0.35, alpha=0.85, color='darkblue')\n    plt.setp(ax_exp.get_yticklabels(), visible=False)\n# Spines\n    for s in ['top', 'left', 'right', 'bottom']:\n        ax_plot.spines[s].set_visible(False)\n        ax_pos.spines[s].set_visible(False)\n        ax_exp.spines[s].set_visible(False)\n    fig.text(0.8, 0.9, title, fontweight='bold', fontfamily='serif', fontsize=35, ha='right') \n    plt.tight_layout()\n    plt.show()","3d731369":"def Plot_matrix2(title, serie1, order1, serie2,  order2):\n    \n    data_ij = Pivot_ij(serie1, serie2, order1, order2)\n    data_ij_man = Pivot_ijk(serie1, serie2, order1, order2, 'Man')\n    data_ij_woman = Pivot_ijk(serie1,serie2, order1, order2, 'Woman')\n\n    fig = plt.figure(figsize=(20, 23), dpi=200)\n    gs = fig.add_gridspec(5, 5)\n    ax_plot = fig.add_subplot(gs[1:4, 0:4])\n    for idx1 in order1[::-1]:\n        for idx2 in order2:\n            man = data_ij_man[idx1][idx2]\n            woman = data_ij_woman[idx1][idx2]\n            manwoman = data_ij[idx1][idx2]\n            drawPieMarker([idx2],[idx1], [man\/(man+woman), woman\/(man+woman)] ,[manwoman*2.5], ['darkblue', '#990000'], ax=ax_plot)\n    ax_plot.grid(linewidth=0.2, zorder=0)        \n    ax_plot.set_yticklabels(idx1, fontfamily='serif', fontsize=15)\n    ax_plot.set_xticklabels(idx2, fontfamily='serif', fontsize=15, rotation=90)\n    ax_pos = fig.add_subplot(gs[0, :4], sharex=ax_plot) \n    data_j_woman = df[df['Q2']=='Woman'][serie2].value_counts()[order2]\n    ax_pos.bar(data_j_woman.index, data_j_woman, width=0.4, alpha=0.7, color='#990000')\n    data_j_man = df[df['Q2']=='Man'][serie2].value_counts()[order2]\n    ax_pos.bar(data_j_man.index, data_j_man, bottom=data_j_woman , width=0.4, alpha=0.7, color='darkblue')\n    plt.setp(ax_pos.get_xticklabels(), visible=False)\n# Exp\n    ax_exp = fig.add_subplot(gs[1:4, 4], sharey=ax_plot) \n    data_i_woman = df[df['Q2']=='Woman'][serie1].value_counts()[order1]\n    ax_exp.barh(data_i_woman.index[::-1], data_i_woman[::-1], height=0.4, alpha=0.7, color='#990000')\n    data_i_man = df[df['Q2']=='Man'][serie1].value_counts()[order1]\n    ax_exp.barh(data_i_man.index[::-1], data_i_man[::-1], left= data_i_woman[::-1],height=0.4, alpha=0.7, color='darkblue')\n    plt.setp(ax_exp.get_yticklabels(), visible=False)\n    fig.text(0.7, 0.9, title, fontweight='bold', fontfamily='serif', fontsize=20, ha='right') \n    plt.show()","d9856d3e":"q1order = ['18-21','22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54','55-59', '60-69', '70+']\nq3order = ['India','United States of America','Brazil','Japan','Russia',\n           'United Kingdom of Great Britain and Northern Ireland','Nigeria','China','Germany','Turkey',\n           'Spain','France','Canada','Indonesia','Pakistan','Taiwan','Italy','Australia','Mexico', 'South Korea']\nq4order = ['I prefer not to answer','No formal education past high school','Professional degree','Some college\/university study without earning a bachelor\u2019s degree',\n    'Bachelor\u2019s degree','Master\u2019s degree','Doctoral degree']\nq5order =['Currently not employed', 'Student','Data Analyst','Business Analyst', 'Data Scientist','Software Engineer',\n          'Research Scientist', 'Machine Learning Engineer', 'Product\/Project Manager', 'Data Engineer', 'Statistician',\n          'DBA\/Database Engineer','Other']\nq6order = ['I have never written code','< 1 years','1-2 years','3-5 years', '5-10 years', '10-20 years', '20+ years']\nq7order = ['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None','Other']\nq8order = ['Python','R','C++','SQL','Java','MATLAB','C','Javascript','Julia','Swift','Bash','None','Other']\nq9order = ['PyCharm','Notepad++','MATLAB','Sublime Text','Vim \/ Emacs','Visual Studio Code (VSCode)',\n           'Spyder','RStudio','Visual Studio','Jupyter (JupyterLab, Jupyter Notebooks, etc)','None','Other']\nq10order = ['None','Other']\nq11order = ['A personal computer or laptop','A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc)',\n            'A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)','None','Other']\nq12order = ['GPUs','TPUs','None']\nq13order = ['Never','Once','2-5 times','6-25 times','More than 25 times']\nq14order = ['Matplotlib','Seaborn','Plotly \/ Plotly Express','Ggplot \/ ggplot2','Shiny','D3 js','Altair','Bokeh','Geoplotlib','Leaflet \/ Folium','None','Other']\nq15order = ['I do not use machine learning methods','Under 1 year','1-2 years','2-3 years','3-4 years','4-5 years',\n            '5-10 years','10-20 years','20 or more years']\nq16order = ['None']\nq17order = ['Linear or Logistic Regression','Decision Trees or Random Forests','Gradient Boosting Machines (xgboost, lightgbm, etc)',\n            'Bayesian Approaches','Evolutionary Approaches', 'Dense Neural Networks (MLPs, etc)','Convolutional Neural Networks',\n            'Generative Adversarial Networks','Recurrent Neural Networks','Transformer Networks (BERT, gpt-3, etc)','None','Other']\nq18order = ['None']\nq19order = ['None']\nq20order = ['0-49 employees','50-249 employees','250-999 employees','1000-9,999 employees','10,000 or more employees']\nq21order = ['0','1-2','3-4','5-9','10-14','15-19','20+']\nq22order = ['I do not know','No (we do not use ML methods)',\n            'We use ML methods for generating insights (but do not put working models into production)',\n            'We are exploring ML methods (and may one day put a model into production)',\n            'We recently started using ML methods (i.e., models in production for less than 2 years)',\n            'We have well established ML methods (i.e., models in production for more than 2 years)']\nq23order = ['Other','Analyze and understand data to influence product or business decisions',\n            'Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data',\n            'Build prototypes to explore applying machine learning to new areas',\n            'Build and\/or run a machine learning service that operationally improves my product or workflows',\n            'Experimentation and iteration to improve existing ML models',\n            'None of these activities are an important part of my role at work',\n            'Do research that advances the state of the art of machine learning']\nq24order = ['$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999', '4,000-4,999', '5,000-7,499', '7,500-9,999',\n'10,000-14,999','15,000-19,999', '20,000-24,999', '25,000-29,999', '30,000-39,999', '40,000-49,999', '50,000-59,999', '60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999',\n'100,000-124,999', '125,000-149,999',  '150,000-199,999', '200,000-249,999',  '250,000-299,999', '300,000-500,000', '> $500,000']\nq25order = ['$0 ($USD)','$1-$99','$100-$999','$1000-$9,999','$10,000-$99,999','$100,000 or more ($USD)']\nq26aorder = ['None']\nq27aorder = ['None']\nq28aorder = ['None']\nq29aorder = ['None']\nq30order = ['MySQL ','PostgresSQL ','Microsoft SQL Server ','MongoDB ','Oracle Database ','Google Cloud BigQuery ',\n           'SQLite ','Amazon Redshift ','Microsoft Azure Data Lake Storage ','Amazon Athena ','Snowflake ',\n           'IBM Db2 ','Amazon DynamoDB ','Google Cloud SQL ','Microsoft Access ','Google Cloud Firestore ','Other']\nq31aorder = ['None','Other']\nq32order = ['Microsoft Power BI','Tableau','Google Data Studio','Other','SAP Analytics Cloud ','TIBCO Spotfire',\n            'Qlik','Salesforce','Looker','Amazon QuickSight','Alteryx ','Domo']\nq33aorder = ['None','Other']\nq34aorder = ['None','Other']\nq35aorder = ['None','Other']\nq36order = ['None','Other']\nq37order = ['None','Other']\nq38order = ['Local development environments (RStudio, JupyterLab, etc.)',\n            'Basic statistical software (Microsoft Excel, Google Sheets, etc.)',\n            'Business intelligence software (Salesforce, Tableau, Spotfire, etc.)',\n            'Cloud-based data software & APIs (AWS, GCP, Azure, etc.)',\n            'Advanced statistical software (SPSS, SAS, etc.)','Other']\nq39order = ['None','Other']","f3443594":"Plot_dix('Regular basis programming languages','Q7',q7order)","646524c6":"Plot_dix('Recommended programming language data scientist firstly learn', 'Q8', q8order)","3787d84b":"Plot_heatmap('Pivot Table : Programming language & Salary','Q8', q8order, 'Q24',  q24order)","61e46fb2":"Plot_matrix2('Age & Programming language','Q1',  q1order, 'Q8', q8order)","29fcbfe2":"Plot_dix('Regular basis used of IDE distribution', 'Q9', q9order)","c714292c":"Plot_dix('Primary tool used at work or school to analyze data','Q38',q38order)","d929746a":"Plot_dix('Number of years used machine learning methods', 'Q15', q15order)","dc9927dc":"Plot_dix('Incorporation of machine learning methods into business', 'Q22', q22order)","4993be7d":"Plot_heatmap('Machine learning & company size', 'Q22',  q22order,'Q20', q20order)","7198293e":"Plot_dix('Most used big data products','Q30',q30order)","2503c9df":"Plot_dix('Regular basis big data products distribution', 'Q29_A', q29aorder)","45835fe2":"Plot_heatmap('Most used big data products & Size of company','Q30', q30order, 'Q20',  q20order)","6113519b":"Plot_dix('Important activities for work', 'Q23', q23order)","24b87aeb":"Plot_dix('Computing platform most used for data science projects', 'Q11', q11order)","1c2d7407":"Plot_heatmap('Pivot Table : Computers plaform & Company size', 'Q11', q11order, 'Q20', q20order)","77c91e72":"Plot_dix('Regular basis data visualization libraries distribution', 'Q14', q14order)","be645776":"Plot_dix('Regular basis business intelligence tools','Q31_A',q31aorder)","9d08d201":"Plot_dix('Most often used business intelligence tools','Q32',q32order)","f51f9bf9":"Plot_heatmap('Pivot Table : BI tools and Salary', 'Q32',  q32order,'Q24', q24order)","177a7df6":"Plot_matrix2('BI tools and company size', 'Q32',  q32order,'Q20',q20order)","3c707aac":"Plot_heatmap('Pivot Table : BI tools and Age', 'Q32',  q32order,'Q1', q1order)","57222bc2":"Plot_heatmap('Pivot Table : BI tools and Education', 'Q32',  q32order,'Q4', q4order)","f7641d73":"The results of this survey are not so surprising as Python is the regular basis programming language in the field of data analytic. Maybe Python is not too complicated for new learner, is popular and \"beautiful\". Besides, SQL and R are \"equally\" popular. But note that, C++ or Java or MATLAB are still popular over the years. \nHowever, we might need a recommendation, particularly for the new commers !","4b610ec2":"Like Python dominates in programming languages, SQL is most commonly used in the big-data products.","7c51bfda":"<h3> In this part, the survey results on skills and work experience required for Data Analytist are very useful, which can also be a starting guiding-point for those who want to be a new member in this industry. Some notable results related to skills and experience can be summarized as follows: <h3>\n\n+ Python is the first recommended programming language for Data Analytist.\n+ Next to Python, SQL and R are very important skills, and every professional should prepare.\n+ If you start learning Python, the recommended IDE could be Jupyter.\n+ In addition, it is necessary to prepare more skills in using of statistical tools, such as MS Excel.\n+ Machine learning may be a common skill in the future, in the near future, ML can be a booming phenomenon when small and medium-sized companies have been well-prepared and put into operation.\n+ The skill \"analyzing and understanding data\" is important to new Data Analytist, which is also an important activity work for most Data jobs.\n+ If you want to focus in the \"big-data\" field, skills related to SQL may need to be considered in the first priority.\n+ Skills and experience exploiting\/ using the \"Matplotlib\" and \"Seaborn\" libraries are very important for data visualization.\n+ Tableau and MS Power BI are still two great business intellegent tools.","6042a3ff":"* **<h3> Topic 5: Visualization & BI tools <h3>**\n    \n    + Q14_Part_1: What data visualization libraries or tools do you use on a regular basis?\n    + Q31_A_Part_1: Which of the following business intelligence tools do you use on a regular basis?\n    + Q32: Which of the following business intelligence tools do you use most often?\n    + Q38: What is the primary tool that you use at work or school to analyze data?","656c158a":"This topic has 11 questions with suggestions and statistics about the skills and working experience required for Data analytic jobs. We consider firstly with the question relating to the programming language.","8c30f6db":"As such, it is clear that machine learning is being developed and applied by big companies. This trend can be predicted to be inevitable in the near future, while small companies are focusing on starting, exploring, etablishing to apply machine learning methods in the very near future.","fea143cd":"<H3> Let's start <h3>\n    \n <h3> Topic 4: Skills & working experience <h3>\n     \n     + Q7_Part_1: What programming languages do you use on a regular basis?\n     + Q8: What programming language would you recommend an aspiring data scientist to learn first?\n     + Q9_Part_1: Which of the following integrated development environments (IDE's) do you use on a regular basis?\n     + Q15: For how many years have you used machine learning methods?\n     + Q22: Does your current employer incorporate machine learning methods into their business?\n     + Q23_Part_1: Select any activities that make up an important part of your role at work?\n     + Q25: Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services at home (or at work) in the past 5 years (approximate $USD)?\n     + Q26_A_Part_1: Which of the following cloud computing platforms do you use on a regular basis?\n     + Q30: Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?\n     + Q35_A_Part_1: Do you use any tools to help manage machine learning experiments?\n     + Q37_Part_1: On which platforms have you begun or completed data science courses?","d6d86fb8":"It can be seen that data analysic jobs are probably very busy and take a lot of time? A question could be considered during the next survey is: \"Do you work overtime or work from home? how many hour per week?\".","5abfbf4b":"Yeah, MS Power BI and Tableau and then Google Data Studio are the most important BI tools that a Data Analytist has to master, especially for high-paying job positions.\n\nSo where are these tools commonly used? Which companies usually use?","81342c6f":"As seen, there are 80% of surveyed-people answered questions related to \"machine learning\", upto 73% of respondents have less than 2 years of experience in this field. The proportion of men accounted for 82% of the respondents and increased gradually to 94% in the group with more than 20 years of experience.","9738d5bc":"And it's clear now with the question Q8, Python is the recommended programming language for all future Data Analytist, firstly learn. In addition, R and SQL are the recommended languages to learn after Python rather than others, this could be the trend of future programming and future data analysts should be aware of.\nSo what is really important to prioritize learning Python?","538fda47":"<h2> Conclusion for PART II <h2>","1a197988":"... to be continued in part III.","358804e2":"Yes, as expected, Tableau and MS Power BI are still two great business intelligence tools. I love these tools, since they are not too hard to learn \/ explore and are widely used. This is confirmed by the survey results with the highest utilization rate among the remaining tools, reflected in the following question Q32.","bd9ec0f3":"Finally, what is the expectation for Data Analytist in the next 2 years? The final PART of this series of Notbooks will summary the survey results.","f51cbad8":"So ML is still new, right? This conclusion is somewhat confirmed in this survey result (question Q22). These survey results show more clearly and in detail about the \"Incorporation of machine learning methods into business\". With a response rate of 55% when asked, more than 67% of respondents said that they have not applied or will apply it in the near future.","87de2a33":"Well, 34% of people agree that the most important part is \"analyzing and understanding data\". Perhaps, the parts of the work that are important to the data analyst should be examined more closely, so that the newcomers to this industry have the opportunity to learn and prepare.\n<img align = \"center\" src=\"https:\/\/i.postimg.cc\/sxYrqn0Y\/Data-science-minimum.png\" width=400>","0b39bc87":"<h1 align=\"center\"> IS DATA SCIENCE A RISING CAREER IN 2020? <\/h1>\n<h1 align=\"center\"> PART II: SKILLS & WORKING EXPERIENCE <\/h1>\n<img align = \"center\" src=\"https:\/\/i.postimg.cc\/zv50Hrh9\/data-science-rising-career.jpg\" width=500>\n\n\n<h3> \n    Hello to all experts on Kaggle. Next to the firt PART \"Education & jobs\", this second PART will discuss about Skills & working experience for Data analytic jobs. <h3>","5ef76be6":"After all, what is the most important activity for work of a Data Analytist?","2449229b":"This is well confirmed that SQL is the most used, including small companies as well as very big companies.","080df6bc":"Regardless of the size of the company, personal computers are used at a rate of up to 75%, cloud computing plaform onlhy accounts for 16%.","566b8524":"Yes, to analyze data, Data Analytist not only use local development environments, but also needs to master another very important tools, such as statistical software (MS Excel is good).\n\nSo, what will be the next level of Data Analytic? Machine learning? Big-data?","3932cceb":"We might have a clear answer when considering the relationship between programming language and Salary. If the salary is above 70k yearly, remember Python, R and SQL are the most common requirements, except for some special cases ('Other').\nCome here, we wonder again, is it difficult to learn programming? Any special request? Or is it related to age?","cb8fa9a8":"In 2020, Matplotlib and Seaborn are still the two most popular libraries. I have also tried to use other libraries like Bokeh or Folium, which showed great visualization results, but they are not really popular yet, at least at the time of survey.\nIs there any news relating to the Data visualization?","81f65fab":"This result is very interesting, the majority of people using BI tools are under 40 years old, however, it is not that older people cannot use it.","4ba917e8":"Yeah, it's clearly confirmed: Jupyter is the most used IDE (you know I started learning Python using Pycharm), and the rate of using Pycharm is not bad. It's probably that Jupyter\/ Pycharm are \"easy\" to create programs with very nice interfaces? Interestingly, the ratio of men to women using IDEs for programming is about the same for all basis.\n\nIs this enough? or is there any additional suggestion?","5d15fe9e":"Very interesting, as small and very large companies use MS Power BI and Tableau more than mid-range companies.","2ddef051":"It can be a bit difficult for people over 50 who want to learn to code (Python, R and SQL), but not necessarily.\n\nOnce again, the question might be, what IDE should I use on a regular basis when learning Python?","408c8ec3":"It's also not surprising that the majority of people who use MS Power BI, Tableau or Google Data Studio have degrees of Bachelor or higher. However, these results do not confirm or conclude anything relationship between using of BI tools and Education level."}}