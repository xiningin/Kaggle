{"cell_type":{"25103577":"code","748d9dba":"code","68c7952c":"code","68684c6c":"code","341eb7d4":"code","de26e93b":"code","1dd1d104":"code","7c0e2eb1":"code","7e693e16":"code","38bc044b":"code","923d9956":"code","454117da":"code","88fad508":"code","0404614e":"markdown","3c7c2412":"markdown","ab36c653":"markdown","d5490c47":"markdown","21eee5e1":"markdown","de85fe6b":"markdown","b1fbd54b":"markdown","d77f1ef5":"markdown","5c743615":"markdown","4fb8a1aa":"markdown","8e83cea1":"markdown","bedd04e1":"markdown"},"source":{"25103577":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#plotting libs\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#sklearn libs\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","748d9dba":"star_data = pd.read_csv(\"..\/input\/star-dataset\/6 class csv.csv\")\nstar_data.head()","68c7952c":"star_types = {0:\"Brown Dwarf\", 1:\"Red Dwarf\", 2:\"White Dwarf\", 3:\"Main Sequence\", 4:\"Supergiant\", 5:\"Hypergiant\"}\nstar_data[\"Star type Decoded\"] = star_data[\"Star type\"].map(star_types) ","68684c6c":"star_data.isnull().sum()","341eb7d4":"star_data[\"Spectral Class\"].value_counts()","de26e93b":"star_data[\"Star color\"].value_counts()","1dd1d104":"star_data[\"Star color\"] = star_data[\"Star color\"].str.lower()\nstar_data[\"Star color\"] = star_data[\"Star color\"].str.replace(' ','')\nstar_data[\"Star color\"] = star_data[\"Star color\"].str.replace('-','')\nstar_data[\"Star color\"] = star_data[\"Star color\"].str.replace('yellowwhite','whiteyellow')\nstar_data[\"Star color\"].value_counts()","7c0e2eb1":"le_specClass = LabelEncoder()\nstar_data[\"SpecClassEnc\"] = le_specClass.fit_transform(star_data[\"Spectral Class\"])\nprint(\"Encoded Spectral Classes: \" + str(le_specClass.classes_))","7e693e16":"le_starCol = LabelEncoder()\nstar_data[\"StarColEnc\"] = le_starCol.fit_transform(star_data[\"Star color\"])\nprint(\"Encoded Star colors: \" + str(le_starCol.classes_))","38bc044b":"sns.pairplot(star_data.drop([\"Star color\", \"Spectral Class\"], axis=1), hue=\"Star type Decoded\", diag_kind=None)\nplt.show()","923d9956":"sns.catplot(x=\"Spectral Class\", y=\"Absolute magnitude(Mv)\", data=star_data, hue=\"Star type Decoded\", order=['O', 'B', 'A', 'F', 'G', 'K', 'M'], height=9)\nplt.gca().invert_yaxis()","454117da":"#select all features for learning and the feature we want to predict\nx = star_data.select_dtypes(exclude=\"object\").drop(\"Star type\", axis=1)\ny = star_data[\"Star type\"]\n\n#split out dataset into a training and a test dataset\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=star_data[\"Star type\"])\n\nscaler = StandardScaler()\n\n#use the scaler to scale our data\nx_train_sc = scaler.fit_transform(x_train)\nx_test_sc = scaler.transform(x_test)\n\n#since we want to have our dataframe we need to replace it in the corresponding sets\nx_train = pd.DataFrame(x_train_sc, index=x_train.index, columns=x_train.columns)\nx_test = pd.DataFrame(x_test_sc, index=x_test.index, columns=x_test.columns)\n","88fad508":"xgb = XGBClassifier(n_estimators=1000, n_jobs=-1, random_state=42)\n\nxgb.fit(x_train, y_train)\n\ny_pred = xgb.predict(x_test)\npredictions = [round(value) for value in y_pred]\n\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","0404614e":"As we can see there is no missing data. Next we should take a look at the categorical features and on how we want to deal with them. If there are entries with the same meaning that only differ in the way they are written then we should replace them.","3c7c2412":"First we have to load the dataset.","ab36c653":"We do the same thing for the star colors.","d5490c47":"Before we create our model we should split it into a training and a test set. Then use the StandardScaler() on both of them. ","21eee5e1":"This is much better and now we can encode every label. Here I will use a LabelEncoder.","de85fe6b":"As mentioned above there are colors that are written just a bit differently.   ","b1fbd54b":"As we can see we have 7 different Spectral classes which we could encode right now. But first let's check the star color feature.","d77f1ef5":"From this we see that one of our most important features we will be Absolute magnitude(Mv) since we already see that in combination with every other feature every star type can be easily separated by each other. If we plot the \"Absolute magnitude(Mv)\" over the \"Spectral Class\" with regard to the different \"Star types\" then we can see the separation of each type more clearly. (note: if you google for spectral classes you will find the same picture)","5c743615":"We have 2 categorical features \"Star color\" and \"Spectral Class\". A google search reveals that both couls be useful since every spectral class is associated with a certain color. The star type in this dataset is the feature that we want to predict. Additionally we create a dictionary with the corrsponding types and add it to this dataset. The only reason we are doing this is because it will be useful when we visualize the data.","4fb8a1aa":"Since this is a small dataset with just a few features we can use a pairplot to visualize all combinations between these features.","8e83cea1":"Since we have 6 different star types and we want to train on every class we use stratify from train_test_split to use 80% of all features for every type in our training dataset. Also we use the standardscaler separately on our training and our test set. This way we can prevent leaking of the information about the distribution of our test set into our model.\n\nFinally we can start building our model. Here we will use the XGBoost classifier.","bedd04e1":"Next we need to check if there is missing data."}}