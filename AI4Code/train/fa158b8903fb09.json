{"cell_type":{"be4a8868":"code","f5efaffd":"code","0f23145e":"code","460718fb":"code","990d18c8":"code","4faec9ef":"code","5afff62a":"code","785ba8f4":"code","46ef07ac":"code","4fc94d70":"code","82d662bb":"code","c2522b0c":"code","15b41141":"code","2119fb2c":"code","7d0ab41b":"code","5a8b42e5":"code","36b3b4ed":"markdown","d79c7b91":"markdown","9baeaa9b":"markdown","b215af49":"markdown"},"source":{"be4a8868":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import load_img\n\nfrom keras_preprocessing.image import ImageDataGenerator\n\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Lambda, Input\nfrom tensorflow.keras.models import Model\nfrom keras import regularizers, optimizers\nfrom keras.utils import to_categorical\nimport pandas as pd\nimport numpy as np\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport gc\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5efaffd":"traindf=pd.read_csv('..\/input\/dog-breed-identification\/labels.csv',dtype=str)\ntestdf=pd.read_csv(\"..\/input\/dog-breed-identification\/sample_submission.csv\",dtype=str)","0f23145e":"def append_ext(fn):\n    return fn+\".jpg\"\n\ntraindf[\"id\"]=traindf[\"id\"].apply(append_ext)\ntestdf[\"id\"]=testdf[\"id\"].apply(append_ext)","460718fb":"traindf.head(5)","990d18c8":"#Create list of alphabetically sorted labels.\nclasses = sorted(list(set(traindf['breed'])))\nn_classes = len(classes)\nprint('Total unique breed {}'.format(n_classes))\n\n#Map each label string to an integer label.\nclass_to_num = dict(zip(classes, range(n_classes)))\nclass_to_num","4faec9ef":"input_shape = (331,331,3)\n\n# Transform image to matrice\ndef images_to_array(directory, label_dataframe, target_size = input_shape):\n    \n    image_labels = label_dataframe['breed']\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8) #as we have huge data and limited ram memory. uint8 takes less memory\n    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n    \n    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n        img_dir = os.path.join(directory, image_name)\n        img = load_img(img_dir, target_size = target_size)\n        images[ix]=img\n        del img\n        \n        dog_breed = image_labels[ix]\n        y[ix] = class_to_num[dog_breed]\n    \n    y = to_categorical(y)\n    \n    return images,y\n\nX,y = images_to_array('\/kaggle\/input\/dog-breed-identification\/train', traindf[:])","5afff62a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)","785ba8f4":"del X,y #to free up some ram memory\ngc.collect()","46ef07ac":"from keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras.layers.experimental import preprocessing\n\nmodel1 = InceptionV3(weights='imagenet', include_top=False)\n\nfor layer in model1.layers:\n    layer.trainable = False\n    \ninputs = Input(shape=(331,331,3))\n\nmodel_in = Lambda(preprocess_input)(inputs) # normalize image according to InceptionV3 preprocess input \n\n# Apply some modifications to images present in dataset\nmodel_in = preprocessing.RandomFlip('horizontal')(model_in)\nmodel_in = preprocessing.RandomContrast(0.5)(model_in)\n\nmodel1_out = model1(model_in)\nmodel1_out= GlobalAveragePooling2D()(model1_out)\n\nx = Dropout(0.7)(model1_out)\n\nx = Dense(n_classes, activation='softmax')(x)\n\nmodel = Model(inputs=inputs,outputs=x)","4fc94d70":"model.compile(optimizer = 'adam', loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","82d662bb":"EarlyStop = EarlyStopping(monitor='val_loss', patience = 3, restore_best_weights=True)\n\nhistory = model.fit(X_train,y_train,\n            validation_split=0.2,\n            batch_size = 32,\n            epochs=10,\n            callbacks=[EarlyStop])","c2522b0c":"#Plot accuracy and loss performance\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","15b41141":"from sklearn.metrics import confusion_matrix\n\ny_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)\ny_test = np.argmax(y_test, axis=1)\n\ncm = confusion_matrix(y_test, y_pred)","2119fb2c":"plt.figure(figsize=(20,20))\nsns.heatmap(cm, fmt=\"d\", xticklabels = classes, yticklabels = classes, annot = True, cmap='Blues', cbar=False)\nplt.show()","7d0ab41b":"#Custom input\n\nfrom IPython.display import display, Image\n\ndef import_image(image_path, target_size = (331,331,3)):\n    display(Image(image_path))\n    \n    #reading the image and converting it into an np array\n    img_g = load_img(image_path,target_size = target_size)\n    img_g = np.expand_dims(img_g, axis=0) # as we trained our model in (row, img_height, img_width, img_rgb) format, np.expand_dims convert the image into this format\n    # img_g\n    \n    prediction = model.predict(img_g)\n\n    print(f\"Max value (probability of prediction): {np.max(prediction[0])}\") # the max probability value predicted by the model\n    print(f\"Max index: {np.argmax(prediction[0])}\") # the index of where the max value in predictions[0] occurs\n    print(f\"Predicted label: {classes[np.argmax(prediction[0])]}\")","5a8b42e5":"import_image('..\/input\/dog-breed-identification\/test\/000621fb3cbb32d8935728e48679680e.jpg')","36b3b4ed":"## Step 4 - Make predictions with custom images","d79c7b91":"## Step 3 - Confusion Matrix","9baeaa9b":"## Step 1 - Data Preprocessing","b215af49":"## Step 2 - Transfer learning using InceptionV3"}}