{"cell_type":{"818efc72":"code","e796db07":"code","7bd33f23":"code","7be80274":"code","0e50635a":"code","74934a8b":"code","ebf71234":"code","0f2aaaaa":"code","fe30642b":"code","ed3d3f25":"code","847d39f9":"code","ad26e38f":"code","48c74990":"code","cc06567f":"code","a0f99dc1":"code","52c0e98a":"code","930a367d":"markdown","4b962f77":"markdown","fa65eab9":"markdown","e6e0dc9b":"markdown","aa6ea30a":"markdown","573c4d70":"markdown","165e95eb":"markdown","f6a0ba8a":"markdown"},"source":{"818efc72":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torchvision\n\nfrom PIL import Image","e796db07":"# path\ninput_path = \"..\/input\/alien-vs-predator-images\/data\/\"","7bd33f23":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\ndata_transforms = {\n    'train':\n    transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize\n    ]),\n    'validation':\n    transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        normalize\n    ]),\n}\n\nimage_datasets = {\n    'train': \n    datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n    'validation': \n    datasets.ImageFolder(input_path + 'validation', data_transforms['validation'])\n}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=32,\n                                shuffle=True,\n                                num_workers=0),  # for Kaggle\n    'validation':\n    torch.utils.data.DataLoader(image_datasets['validation'],\n                                batch_size=32,\n                                shuffle=False,\n                                num_workers=0)  # for Kaggle\n}","7be80274":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","0e50635a":"model = models.resnet101(pretrained=True).to(device)\n    \nfor param in model.parameters():\n    param.requires_grad = False   \n    \nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 2)).to(device)","74934a8b":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters())","ebf71234":"def train_model(model, criterion, optimizer, num_epochs=3):\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        for phase in ['train', 'validation']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                _, preds = torch.max(outputs, 1)\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(image_datasets[phase])\n            epoch_acc = running_corrects.double() \/ len(image_datasets[phase])\n\n            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n                                                        epoch_loss,\n                                                        epoch_acc))\n    return model","0f2aaaaa":"model_trained = train_model(model, criterion, optimizer, num_epochs=30)","fe30642b":"!mkdir models\n!mkdir models\/pytorch","ed3d3f25":"torch.save(model_trained.state_dict(), 'models\/pytorch\/weights.h5')","847d39f9":"model = models.resnet101(pretrained=False).to(device)\nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 2)).to(device)\nmodel.load_state_dict(torch.load('models\/pytorch\/weights.h5'))","ad26e38f":"validation_img_paths = [\"validation\/alien\/2.jpg\",\"validation\/alien\/32.jpg\",\n                        \"validation\/predator\/62.jpg\",\"validation\/predator\/16.jpg\"]\nimg_list = [Image.open(input_path + img_path) for img_path in validation_img_paths]","48c74990":"validation_batch = torch.stack([data_transforms['validation'](img).to(device)\n                                for img in img_list])","cc06567f":"pred_logits_tensor = model(validation_batch)\npred_logits_tensor","a0f99dc1":"pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\npred_probs","52c0e98a":"fig, axs = plt.subplots(1, len(img_list), figsize=(15, 10))\nfor i, img in enumerate(img_list):\n    ax = axs[i]\n    ax.axis('off')\n    ax.set_title(\"{:.0f}% Alien, {:.0f}% Predator\".format(100*pred_probs[i,0],\n                                                            100*pred_probs[i,1]))\n    ax.imshow(img)","930a367d":"## Save and load Model","4b962f77":"In this notebook I am going to classify the alien and predator images.I will be going to use Transfer Learning ResNet-101 model.**Transfer Learning** is the reuse of a pre-trained model on a new problem.I am writing this notebook using pytorch documentation.If you want to learn more on pytorch I would recommend you go to pytorch documentation.","fa65eab9":"## Import Libraries","e6e0dc9b":"## Create the network","aa6ea30a":"## Create Pytorch Data Generators","573c4d70":"First of all we are going to import all the required libraries","165e95eb":"## Prediction","f6a0ba8a":"## Train Model"}}