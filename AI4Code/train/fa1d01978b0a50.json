{"cell_type":{"07a2fad9":"code","9dd47af3":"code","47bb6e18":"code","699906ed":"code","17aebda2":"code","616dff87":"code","4e69d815":"code","c6c064e7":"code","12c4e6b6":"code","bfe87705":"code","c9606a5c":"code","0a6e5112":"code","a992909f":"markdown"},"source":{"07a2fad9":"from tensorflow import lite\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport pandas as pd\nimport random, os\nimport shutil\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.metrics import categorical_accuracy, AUC\nfrom sklearn.model_selection import train_test_split\n\n!pip install tensorflow-addons==0.9.1\nimport tensorflow_addons\nfrom tensorflow_addons.metrics import F1Score, CohenKappa","9dd47af3":"# Add an additional column, mapping to the type\ndf = pd.read_csv('..\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/train.csv')\n\ndiagnosis_dict_binary = {\n    0: 'No_DR',\n    1: 'DR',\n    2: 'DR',\n    3: 'DR',\n    4: 'DR'\n}\n\ndiagnosis_dict = {\n    0: 'No_DR',\n    1: 'Mild',\n    2: 'Moderate',\n    3: 'Severe',\n    4: 'Proliferate_DR',\n}\n\n\ndf['binary_type'] =  df['diagnosis'].map(diagnosis_dict_binary.get)\ndf['type'] = df['diagnosis'].map(diagnosis_dict.get)\ndf.head()","47bb6e18":"df['type'].value_counts().plot(kind='barh')","699906ed":"df['binary_type'].value_counts().plot(kind='barh')","17aebda2":"# Split into stratified train, val, and test sets\ntrain_intermediate, val = train_test_split(df, test_size = 0.15, stratify = df['type'])\ntrain, test = train_test_split(train_intermediate, test_size = 0.15 \/ (1 - 0.15), stratify = train_intermediate['type'])\n\nprint(train['type'].value_counts(), '\\n')\nprint(val['type'].value_counts(), '\\n')\nprint(test['type'].value_counts(), '\\n')","616dff87":"# Create working directories for train\/val\/test\nbase_dir = ''\n\ntrain_dir = os.path.join(base_dir, 'train')\nval_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')\n\nif os.path.exists(base_dir):\n    shutil.rmtree(base_dir)\n\nif os.path.exists(train_dir):\n    shutil.rmtree(train_dir)\nos.makedirs(train_dir)\n\nif os.path.exists(val_dir):\n    shutil.rmtree(val_dir)\nos.makedirs(val_dir)\n\nif os.path.exists(test_dir):\n    shutil.rmtree(test_dir)\nos.makedirs(test_dir)\n","4e69d815":"# Copy images to respective working directory\nsrc_dir = '..\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images\/'\nfor index, row in train.iterrows():\n    diagnosis = row['type']\n    binary_diagnosis = row['binary_type']\n    id_code = row['id_code'] + \".png\"\n    srcfile = os.path.join(src_dir, diagnosis, id_code)\n    dstfile = os.path.join(train_dir, diagnosis)\n    os.makedirs(dstfile, exist_ok = True)\n    shutil.copy(srcfile, dstfile)\n\nfor index, row in val.iterrows():\n    diagnosis = row['type']\n    binary_diagnosis = row['binary_type']\n    id_code = row['id_code'] + \".png\"\n    srcfile = os.path.join(src_dir, diagnosis, id_code)\n    dstfile = os.path.join(val_dir, diagnosis)\n    os.makedirs(dstfile, exist_ok = True)\n    shutil.copy(srcfile, dstfile)\n\nfor index, row in test.iterrows():\n    diagnosis = row['type']\n    binary_diagnosis = row['binary_type']\n    id_code = row['id_code'] + \".png\"\n    srcfile = os.path.join(src_dir, diagnosis, id_code)\n    dstfile = os.path.join(test_dir, diagnosis)\n    os.makedirs(dstfile, exist_ok = True)\n    shutil.copy(srcfile, dstfile)\n","c6c064e7":"# Setting up ImageDataGenerator for train\/val\/test \n\ntrain_path = 'train'\nval_path = 'val'\ntest_path = 'test'\n\ntrain_batches = ImageDataGenerator(rescale = 1.\/255).flow_from_directory(train_path, target_size=(224,224), shuffle = True)\nval_batches = ImageDataGenerator(rescale = 1.\/255).flow_from_directory(val_path, target_size=(224,224), shuffle = True)\ntest_batches = ImageDataGenerator(rescale = 1.\/255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)\n","12c4e6b6":"# Building the model\n\nmodel = tf.keras.Sequential([\n    layers.Conv2D(16, (3,3), padding=\"same\", input_shape=(224,224,3), activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(32, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(32, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(64, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(64, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n \n    layers.Conv2D(128, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(256, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.BatchNormalization(),\n    \n    layers.Conv2D(128, (3,3), padding=\"same\", activation = 'relu'),\n    layers.MaxPooling2D(pool_size=(1,1)),\n    layers.BatchNormalization(),\n    \n    layers.Flatten(),\n    layers.Dense(8, activation = 'relu'),\n    layers.Dropout(0.15),\n    layers.Dense(5, activation = 'softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-5),\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=['acc','AUC',tensorflow_addons.metrics.F1Score(num_classes=5, average='weighted'),tensorflow_addons.metrics.CohenKappa(num_classes=5)])\n\nhistory = model.fit(train_batches,\n                    epochs=12,\n                    validation_data=val_batches)","bfe87705":"acc = model.evaluate_generator(test_batches, verbose=1)\nprint(\"Accuracy: \", acc[1])","c9606a5c":"plt.subplot(1,2,1)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.ylabel('acc')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='lower right')\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='lower right')\n","0a6e5112":"#  Predict the label of the test_images\npred = model.predict(test_batches)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_batches.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\n# Display the result\nprint(f'The first 5 predictions: {pred[:5]}')","a992909f":"# 8 Layer CNN Model"}}