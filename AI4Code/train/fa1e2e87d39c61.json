{"cell_type":{"f3341b7a":"code","4d72a135":"code","91bcb99e":"code","c367d14e":"code","1f700596":"code","a31508c8":"code","968e6c66":"code","8ca8c33e":"code","0e3d5e20":"code","89b37b90":"code","0d9b9b3d":"code","7b10dc5b":"code","d051cb9a":"code","1473c3ac":"code","613a7b77":"code","2fef82cf":"markdown","cd7517bd":"markdown","e498e74f":"markdown","46aaa398":"markdown","47ddff38":"markdown","72144ecc":"markdown","7b7c4c02":"markdown","261a1bec":"markdown","2dbcf657":"markdown","31f5b74d":"markdown","4047f764":"markdown","053c773e":"markdown","79b2cc2e":"markdown","171171ce":"markdown","0dcb21c1":"markdown"},"source":{"f3341b7a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical, normalize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","4d72a135":"df_train = pd.read_csv('..\/input\/glass.csv')\nprint(f'The train set contain {df_train.shape[0]} examples')\nprint(f'The train set contain {df_train.shape[1]} features')\ndf_train.head()","91bcb99e":"X_train = df_train.drop('Type', axis = 1)\ny_train = df_train['Type']","c367d14e":"glass_classes = y_train.unique()\nvalues = y_train.value_counts()\n\nplt.bar(glass_classes, values)\nplt.title('Train set')\nplt.xlabel('Glass Classes')\nplt.ylabel('Examples count')\nplt.show()","1f700596":"X_train.describe()","a31508c8":"X_train = df_train.values\nX_train = normalize(X_train)\nprint(X_train[0])","968e6c66":"y_train = to_categorical(y_train)\ny_train.shape","8ca8c33e":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\nX_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5)","0e3d5e20":"model = tf.keras.models.Sequential([\n       \n    tf.keras.layers.Dense(256, input_shape=(10,), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    \n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    \n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n            \n    tf.keras.layers.Dense(8, activation='softmax')\n])\n\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(0.0001),\n              metrics=['acc'])\n\nmodel","89b37b90":"model.summary()","0d9b9b3d":"history = model.fit(X_train, y_train,\n                    epochs=400,\n                    validation_data=(X_val, y_val),\n                    verbose=2,\n                   )","7b10dc5b":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","d051cb9a":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","1473c3ac":"model.evaluate(X_test, y_test)","613a7b77":"y_pred = model.predict(X_test)\ny_pred_cl = np.argmax(y_pred, axis = 1)\ny_true = np.argmax(y_test, axis = 1)\n\nconfusion_matrix(y_true, y_pred_cl)","2fef82cf":"After finishing playing with model and we are happy with achieved accuracy, evaluate your model on the test set.","cd7517bd":"Looks like we have a pretty small data set.\n\nThe last column contains labels.\n\nExtract Labels to a different data frame.","e498e74f":"## Create the model.\n\nOur playground. Feel free to try a different variation","46aaa398":"Let's plot the training set.\n\nSeem like dataset is not very good balanced.","47ddff38":"## Exploring data\n\nLoad the training data and explore it","72144ecc":"## **Initial step**\n\nBasic initial step import required libraries\n\n*   pandas - reading and manipulating data\n*   numpy - linear algebra\n*   matplotlib - plot graphs\n*   tensorflow - self-explanatory\n*   sklearn - only for data splitting and confusion matrix","7b7c4c02":"Good job.\n\nLet's look at the confusion matrix.","261a1bec":"Explore the values.\n\nMax value is 78.41 and min is 0.29.\n\nThis data need to normalize.","2dbcf657":"Now we need to convert our label to \"one hot vector\". Print shape of the new data frame to make sure everything is right.","31f5b74d":"### Training\n\n\nFinally, train the model.","4047f764":"Split the dataset into three sets.\n\nSince data it significantly small we will split to:\n\ntrain - 80%\nvalid - 10%\ntest - 10%","053c773e":"keras.utils.normalize don't work with a pandas data frame. \n\nConvert it to array and then normalize.\n\nPrint the first item of the new array.","79b2cc2e":"## Evaluate the model\n\nPlot our accuracy and loss for understanding problems: \"high bias\" and \"high variance\".\n","171171ce":"## Glass Classification | Deep Learning | Keras\n*   Initial step\n*   Exploring data\n*   Create the model\n*   Evaluate the model","0dcb21c1":"Explore the model."}}