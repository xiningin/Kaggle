{"cell_type":{"d501a190":"code","26b45d4d":"code","05395ff5":"code","b91ed87f":"code","c8a6bee0":"code","18818a23":"code","0acb1d21":"code","940def30":"code","089327de":"code","72b11b52":"code","d889026b":"code","14382c46":"code","bb9a5b0c":"code","78ff66ad":"code","da66b78e":"code","2c626391":"code","03ee7d51":"code","42fd45d2":"code","3fc2a02b":"code","828f2ce0":"code","26167d04":"code","c362e2e8":"code","afbca916":"code","9d9c45c1":"code","ccf9c311":"code","14afd71e":"code","994e924d":"code","468a5eca":"code","b963c5c1":"code","69f42cc1":"code","34e1ac90":"code","1f641700":"code","d6743cd3":"code","e592fa2d":"code","a8d310c1":"code","18f17da2":"code","dfeb80f4":"markdown","e657081e":"markdown","864cee30":"markdown","c646ad7d":"markdown","f0295a0d":"markdown","f42467f7":"markdown","9a146ce3":"markdown","b6176832":"markdown","c6fb28ff":"markdown","9b6b738a":"markdown","fb6ac961":"markdown","7aa562af":"markdown","4584b62b":"markdown","6d6bf871":"markdown","0d43993a":"markdown","391d4e12":"markdown","754d11e1":"markdown","1f251215":"markdown","ea173d88":"markdown","06b4223f":"markdown","7453816c":"markdown","6977d3c2":"markdown","641a4cd1":"markdown","01e4dd6a":"markdown","54a826f2":"markdown","08f1dd4d":"markdown","ca047845":"markdown"},"source":{"d501a190":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26b45d4d":"df = pd.read_csv('..\/input\/reddit-vaccine-myths\/reddit_vm.csv')","05395ff5":"df = df[df.title != 'Comment']","b91ed87f":"df.head()","c8a6bee0":"%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfig = sns.displot(x=df.title.str.len(), data=df, color='black', kde=False, height=6, kind='hist')\n\nprint(df.title.str.len().min())\nprint(df.title.str.len().max())\nprint(df.title.str.len().mean())","18818a23":"%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntemp = df.title.str.split().map(lambda x: len(x))\n\nfig = sns.displot(x=temp, color='blue', kde=False, height=6, kind='hist')\n\nprint(temp.min())\nprint(temp.max())\nprint(temp.mean())","0acb1d21":"%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntemp = df.title.str.split().apply(lambda x: [len(i) for i in x]).map(lambda x: np.mean(x))\n\nfig = sns.displot(x=temp, color='red', kde=False, height=6, aspect=2, kind='hist')\n\nprint(temp.min())\nprint(temp.max())\nprint(temp.mean())","940def30":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nstop = set(stopwords.words('english'))","089327de":"corpus = []\ntitle = df.title.str.split()\ntitle = title.values.tolist()\ncorpus = [word for i in title for word in i]\n\nfrom collections import defaultdict\n\ndic = defaultdict(int)\n\nfor word in corpus:\n    if word in stop:\n        dic[word] += 1","72b11b52":"sorted_dic = list(reversed(sorted(list(dic.items()), key=lambda x: x[1])))\n\nkeys = [i[0] for i in sorted_dic[:10]]\nvalues = [i[1] for i in sorted_dic[:10]]\n\nsns.set(rc={'figure.figsize':(10,10)})\n\nfig = sns.barplot(x=keys, y=values, palette='colorblind')","d889026b":"from collections import Counter\nfrom nltk.stem import PorterStemmer\n\nps = PorterStemmer()\ncounter = Counter(corpus)\nmost = counter.most_common()\n\nx, y = [], []\nlookup = []\nfor word,count in most[:120]:\n    if (word.lower() not in stop) and (ps.stem(word.lower()) not in lookup) and word.isalpha():\n        x.append(word)\n        y.append(count)\n        lookup.append(ps.stem(word.lower()))\n        \nsns.barplot(x=y,y=x)","14382c46":"from sklearn.feature_extraction.text import CountVectorizer\n\ndef get_top_ngram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    fwords_freq = []\n    for i in words_freq:\n        temp = 0\n        for j in i[0].split():\n            if j in stop:\n                temp += 1\n        if temp != len(i[0].split()):\n            fwords_freq.append(i)\n    words_freq = fwords_freq\n    words_freq =sorted(words_freq, key=lambda x: x[1], reverse=True)\n    return words_freq[:10]","bb9a5b0c":"top_n_bigrams = get_top_ngram(df.title, 2)[:10]\n\nx, y = map(list, zip(*top_n_bigrams)) \n\nsns.barplot(x=y, y=x, palette='hls')","78ff66ad":"top_n_trigrams = get_top_ngram(df.title, 3)[:10]\n\nx, y = map(list, zip(*top_n_trigrams)) \n\nsns.barplot(x=y, y=x, palette='coolwarm')","da66b78e":"import nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk import word_tokenize\n\ndef preprocess_news(df):\n    corpus = []\n    stem = PorterStemmer()\n    lem = WordNetLemmatizer()\n    for news in df.title:\n        words = [w for w in word_tokenize(news) if (w.lower() not in stop and w.isalpha())]\n        words = [lem.lemmatize(w) for w in words if len(w) > 2]\n        corpus.append(words)\n    return corpus\n\ncorpus = preprocess_news(df)","2c626391":"import gensim\n\ndic = gensim.corpora.Dictionary(corpus)\nbow_corpus = [dic.doc2bow(doc) for doc in corpus]","03ee7d51":"lda_model = gensim.models.LdaMulticore(bow_corpus, \n                                   num_topics = 5, \n                                   id2word = dic,                                    \n                                   passes = 10,\n                                   workers = 2)\nlda_model.show_topics()","42fd45d2":"import pyLDAvis\nimport pyLDAvis.gensim_models\n\nLDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dic)\npyLDAvis.display(LDAvis_prepared)","3fc2a02b":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\ndef show_wordcloud(data):\n    wordcloud = WordCloud(\n        background_color=None,\n        stopwords=stopwords,\n        max_words=1000,\n        max_font_size=30,\n        scale=4,\n        random_state=42,\n        mode='RGBA',\n        colormap='plasma')\n   \n    wordcloud=wordcloud.generate(str(data))\n\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n\n    plt.imshow(wordcloud)\n    plt.show()\n\nshow_wordcloud(corpus)","828f2ce0":"from textblob import TextBlob\n\ndef polarity(text):\n    return TextBlob(text).sentiment.polarity\n\ndf.polarity_score = df.title.apply(lambda x : polarity(x))\ndf.polarity_score.hist(color='skyblue')","26167d04":"def sentiment(x):\n    if x < 0:\n        return 'neg'\n    elif x == 0:\n        return 'neu'\n    else:\n        return 'pos'\n    \ndf.sentiment = df.polarity_score.map(lambda x: sentiment(x))\n\nsns.barplot(x=df.sentiment.value_counts().index, y=df.sentiment.value_counts(), palette='coolwarm')","c362e2e8":"for i in df[df.sentiment == 'pos'].title.head():\n    print(i)\n    print()","afbca916":"for i in df[df.sentiment == 'neg'].title.head():\n    print(i)\n    print()","9d9c45c1":"! python -m spacy download en_core_web_sm","ccf9c311":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")","14afd71e":"def ner(text):\n    doc = nlp(text)\n    return [X.label_ for X in doc.ents]\n\nent = df.title.apply(lambda x : ner(x))\nent = [x for sub in ent for x in sub]\n\ncounter = Counter(ent)\ncount = counter.most_common()","994e924d":"x, y = map(list, zip(*count))\nsns.barplot(x=y, y=x, palette='husl')","468a5eca":"def ner(text, ent=\"ORG\"):\n    doc = nlp(text)\n    return [X.text for X in doc.ents if X.label_ == ent]\n\norg = df.title.apply(lambda x: ner(x))\norg = [i for x in org for i in x]\ncounter = Counter(org)\n\nx,y=map(list,zip(*counter.most_common(10)))\nsns.barplot(y, x, palette='coolwarm')","b963c5c1":"def ner(text, ent=\"PERSON\"):\n    doc = nlp(text)\n    return [X.text for X in doc.ents if X.label_ == ent]\n\nperson = df.title.apply(lambda x: ner(x))\nperson = [i for x in person for i in x]\ncounter = Counter(person)\n\nx,y=map(list,zip(*counter.most_common(10)))\nsns.barplot(y, x, palette='viridis')","69f42cc1":"def ner(text, ent=\"CARDINAL\"):\n    doc = nlp(text)\n    return [X.text for X in doc.ents if X.label_ == ent]\n\ncardinal = df.title.apply(lambda x: ner(x))\ncardinal = [i for x in cardinal for i in x]\ncounter = Counter(cardinal)\n\nx,y=map(list,zip(*counter.most_common(10)))\nsns.barplot(y, x, palette='twilight')","34e1ac90":"def pos(text):\n    pos = nltk.pos_tag(word_tokenize(text))\n    pos = list(map(list,zip(*pos)))[1]\n    return pos\n\ntags = df.title.apply(lambda x : pos(x))\ntags = [x for l in tags for x in l]\ncounter = Counter(tags)\n\nx, y = list(map(list,zip(*counter.most_common(6))))\nsns.barplot(x=y, y=x, palette='coolwarm')","1f641700":"def get_nouns(text):\n    noun = []\n    pos = nltk.pos_tag(word_tokenize(text))\n    for word, tag in pos:\n        if tag == 'NN':\n            noun.append(word)\n    return noun\n\nwords = df.title.apply(lambda x : get_nouns(x))\nwords = [x for l in words for x in l]\ncounter = Counter(words)\n\nx, y = list(map(list,zip(*counter.most_common(10))))\nsns.barplot(x=y, y=x, palette='magma')","d6743cd3":"def get_nouns(text):\n    noun = []\n    pos = nltk.pos_tag(word_tokenize(text))\n    for word, tag in pos:\n        if tag == 'NNS':\n            noun.append(word)\n    return noun\n\nwords = df.title.apply(lambda x : get_nouns(x))\nwords = [x for l in words for x in l]\ncounter = Counter(words)\n\nx, y = list(map(list,zip(*counter.most_common(10))))\nsns.barplot(x=y, y=x, palette='Accent')","e592fa2d":"! pip install textstat","a8d310c1":"from textstat import flesch_reading_ease\n\ndf.title.apply(lambda x : flesch_reading_ease(x)).hist(color='black')","18f17da2":"df['reading'] = df.title.apply(lambda x : flesch_reading_ease(x))\n\nfor i in df[df.reading < 5].title:\n    print(i)\n    print()","dfeb80f4":"## We see nouns topping the charts followed by plural nouns and interjections. The facts are presented as is and not embellished (other adjectives would be there).\n## Let's see the most prevalent nouns used.","e657081e":"## The histogram shows that the titles range from 1 to 298 characters and generally, it is 99 characters on average.","864cee30":"# Topic Modelling","c646ad7d":"## N-Gram Exploration","f0295a0d":"## We see that majority of the titles have a neutral polarity.","f42467f7":"# Sentiment Analysis","9a146ce3":"# POS Tagging\nNoun (NN)- Joseph, London, table, cat, teacher, pen, city\n\nVerb (VB)- read, speak, run, eat, play, live, walk, have, like, are, is\n\nAdjective(JJ)- beautiful, happy, sad, young, fun, three\n\nAdverb(RB)- slowly, quietly, very, always, never, too, well, tomorrow\n\nPreposition (IN)- at, on, in, from, with, near, between, about, under\n\nConjunction (CC)- and, or, but, because, so, yet, unless, since, if\n\nPronoun(PRP)- I, you, we, they, he, she, it, me, us, them, him, her, this\n\nInterjection (INT)- Ouch! Wow! Great! Help! Oh! Hey! Hi!","b6176832":"## We see the usage of vaccines, children, people, Vaccines, measles, parents, vaccinations, kids, studies and years.\n## Let's explore the complexity of text used in the titles.","c6fb28ff":"## We see that short titles which convey no meaning have the least readability score.","9b6b738a":"## The average word length ranges between 1 to 26 with 5 being the most common length.","fb6ac961":"## The number of words in titles ranges from 1 to 50 words and is mostly 17 words.","7aa562af":"## We see that organizations like CDC, FDA, Pfizer and Monsanto are the prime focus.","4584b62b":"## We see the highest usage of vaccine (of course!), followed by vaccination, autism, polio, child, anyone, disease, risk and cause.\n## Let's see the plural nouns used.","6d6bf871":"## We see the most common words used in titles apart from the stopwords. 'vaccine' obviously dominates the tally. Other noteworthy words are 'polio', 'autism', 'flu', 'measles', 'CDC' and 'diseases'.","0d43993a":"## We see that ORG, PERSON and CARDINAL entities dominate the tally.","391d4e12":"## The negative titles are around COVID-19 vaccine, Anti-Vaxxers and Dangerous Myths.","754d11e1":"## We discover the most talked about topics relate vaccination with autism, measles, polio and cancer.","1f251215":"## We see that bigram like 'big pharma', 'anti vax', 'covid 19' and bigrams related to vaccines dominate the titles.","ea173d88":"## We see the readibility scores for the titles mostly fall after 50. This means the titles can be easily read and understood.\n## Let's also check the titles with less readibility score.","06b4223f":"## We see a lot of numbers mentioned in the titles. Numbers work as a support for the argument, hence, their abundance in titles.","7453816c":"## We observe the following:\n## * The Reddit is US centric due to presence of trigram 'in the us'.\n## * People are talking about 'covid 19 vaccine'.\n## * People are against vaccines due to the trigram 'vaccines are bad'.\n## * People are worried about unvaccinated children due to the trigram: 'an unvaccinated child'.\n## * People are talking about 'anti vaccination movement'.\n## * People want to discover the 'truth about vaccines'.","6977d3c2":"## We see Bill Gates mentioned in the titles.","641a4cd1":"## We see that 46% of the titles have a neutral sentiment, 31% have a positive sentiment and 23% have a negative sentiment.\n## Let's take a look at some of the positive and negative titles.","01e4dd6a":"## We see from the wordcloud that most important words are vaccine, vaccination, kid, child, parent, Big Pharma, measles and autism.","54a826f2":"## We see the top 10 most used stopwords in all the titles.","08f1dd4d":"## The positive titles are around COVID-19 vaccine and Anti-Vaxxers.","ca047845":"## The number of characters present in each sentence:"}}