{"cell_type":{"f82571a4":"code","cff3e8b5":"code","c05b69ba":"code","8435e50d":"code","5bf18a23":"code","40829484":"code","52855d9c":"code","bac89c57":"code","b5bcbefd":"code","91f93fb2":"code","6f3ef470":"code","4cb93aee":"code","41ed08ee":"code","2627de79":"code","55d3f3fb":"code","db2c7052":"code","7350856b":"code","915665f9":"code","592bed71":"code","1e5f1a7f":"code","7141aecf":"code","619df866":"code","478d0a95":"code","d6f018e0":"code","498972ec":"code","009d6d79":"code","46cf9ba1":"code","809d6c2b":"code","3c52e90c":"markdown","0dccc7a0":"markdown","c976af49":"markdown","b1883c15":"markdown","71971731":"markdown","b45257f7":"markdown","ebb7f1b3":"markdown","9c7918ef":"markdown","5fe5fdc9":"markdown","3be8c278":"markdown","4aa25068":"markdown","43d824be":"markdown","254b9be5":"markdown","345fb0be":"markdown","07c507f7":"markdown","25c16bbe":"markdown"},"source":{"f82571a4":"!pip install chart_studio","cff3e8b5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom PIL import Image\nimport re\nimport gc\nimport sys\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport emoji\nimport random\nimport unicodedata\nimport multiprocessing\nimport seaborn as sns\nfrom functools import partial, lru_cache\nfrom tqdm import tqdm_notebook\nfrom wordcloud import WordCloud, STOPWORDS\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom plotly import tools\nimport chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom nltk import TweetTokenizer\nfrom nltk.stem import PorterStemmer, SnowballStemmer\nfrom nltk.stem.lancaster import LancasterStemmer","c05b69ba":"train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nsub = pd.read_csv(\"\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv\")","8435e50d":"train_len, test_len = len(train.index), len(test.index)\nprint(\"Train Size:\", train_len)\nprint(\"Test Size:\", test_len)\nprint(\"Train shape: \", train.shape)","5bf18a23":"train.head()","40829484":"test.head()","52855d9c":"train.info()","bac89c57":"test.info()","b5bcbefd":"sns.countplot(train[\"sentiment\"])","91f93fb2":"train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\ntest[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\ntrain['select_num_words'] = train[\"selected_text\"].apply(lambda x: len(str(x).split()))\n\n## Number of unique words in the text ##\ntrain[\"num_unique_words\"] = train[\"text\"].apply(lambda x: len(set(str(x).split())))\ntest[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\ntrain['select_num_unique_words'] = train[\"selected_text\"].apply(lambda x: len(set(str(x).split())))\n\n## Number of characters in the text ##\ntrain[\"num_chars\"] = train[\"text\"].apply(lambda x: len(str(x)))\ntest[\"num_chars\"] = test[\"text\"].apply(lambda x: len(str(x)))\ntrain['select_num_chars'] = train[\"selected_text\"].apply(lambda x: len(str(x)))","6f3ef470":"def target_plot(column, title):\n    fig = go.Figure()\n    fig.add_trace(go.Histogram(x=train[str(column)],name = title + ' : train data'))\n    fig.add_trace(go.Histogram(x=test[str(column)],name = title + ' : test data'))\n    fig.add_trace(go.Histogram(x=train['select_'+str(column)],name =  title + ': selected text'))\n    fig.update_layout(barmode='stack')\n    fig.update_traces(opacity=0.75)\n    fig.show()","4cb93aee":"target_plot(column='num_words', title=\"Number of words\")","41ed08ee":"target_plot(column=\"num_chars\", title=\"Number of characters\")","2627de79":"target_plot(column=\"num_unique_words\", title=\"Number of unique words\")","55d3f3fb":"stopwords = set(STOPWORDS)\ndef generate_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        max_words=100,\n        max_font_size=40, \n        scale=5,\n        random_state=23\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(20,20))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","db2c7052":"generate_wordcloud(train['text'], title = 'Prevalent words in tweets - train data')","7350856b":"generate_wordcloud(test['text'], title = 'Prevalent words in tweets - test data')","915665f9":"generate_wordcloud(train.loc[train['sentiment']=='neutral']['text'], title = 'Prevalent Neutral words in tweets - train data')","592bed71":"generate_wordcloud(train.loc[train['sentiment']=='positive']['text'], title = 'Prevalent Positive words in tweets - train data')","1e5f1a7f":"generate_wordcloud(train.loc[train['sentiment']=='negative']['text'], title = 'Prevalent Negative words in tweets - train data')","7141aecf":"def extract_emojis(string):\n    return [c for c in str(string) if c in emoji.UNICODE_EMOJI]\n\ntrain['emojis_count'] = train['text'].apply(lambda x: len(extract_emojis(x)))\nprint(\"Maximum Number of Emojis: \", max(train[\"emojis_count\"]))","619df866":"PORTER_STEMMER = PorterStemmer()\nLANCASTER_STEMMER = LancasterStemmer()\nSNOWBALL_STEMMER = SnowballStemmer(\"english\")\n\ndef word_forms(word):\n    yield word\n    yield word.lower()\n    yield word.upper()\n    yield word.capitalize()\n    yield PORTER_STEMMER.stem(word)\n    yield LANCASTER_STEMMER.stem(word)\n    yield SNOWBALL_STEMMER.stem(word)","478d0a95":"TABLE = str.maketrans(\n    {\n        \"\\xad\": None,\n        \"\\x7f\": None,\n        \"\\ufeff\": None,\n        \"\\u200b\": None,\n        \"\\u200e\": None,\n        \"\\u202a\": None,\n        \"\\u202c\": None,\n        \"\u2018\": \"'\",\n        \"\u2019\": \"'\",\n        \"`\": \"'\",\n        \"\u201c\": '\"',\n        \"\u201d\": '\"',\n        \"\u00ab\": '\"',\n        \"\u00bb\": '\"',\n        \"\u0262\": \"G\",\n        \"\u026a\": \"I\",\n        \"\u0274\": \"N\",\n        \"\u0280\": \"R\",\n        \"\u028f\": \"Y\",\n        \"\u0299\": \"B\",\n        \"\u029c\": \"H\",\n        \"\u029f\": \"L\",\n        \"\u0493\": \"F\",\n        \"\u1d00\": \"A\",\n        \"\u1d04\": \"C\",\n        \"\u1d05\": \"D\",\n        \"\u1d07\": \"E\",\n        \"\u1d0a\": \"J\",\n        \"\u1d0b\": \"K\",\n        \"\u1d0d\": \"M\",\n        \"\u039c\": \"M\",\n        \"\u1d0f\": \"O\",\n        \"\u1d18\": \"P\",\n        \"\u1d1b\": \"T\",\n        \"\u1d1c\": \"U\",\n        \"\u1d21\": \"W\",\n        \"\u1d20\": \"V\",\n        \"\u0138\": \"K\",\n        \"\u0432\": \"B\",\n        \"\u043c\": \"M\",\n        \"\u043d\": \"H\",\n        \"\u0442\": \"T\",\n        \"\u0455\": \"S\",\n        \"\u2014\": \"-\",\n        \"\u2013\": \"-\",\n    }\n)\n\nRE_SPACE = re.compile(r\"\\s\")\nRE_MULTI_SPACE = re.compile(r\"\\s+\")\nRE_URL = re.compile('http[s]?:\/\/\\S+')","d6f018e0":"def normalize(text: str):\n    text = RE_URL.sub(\"URL\", text)\n    text = RE_SPACE.sub(\" \", text)\n    text = unicodedata.normalize(\"NFKD\", text)\n    text = text.translate(TABLE)\n    text = RE_MULTI_SPACE.sub(\" \", text).strip()\n    return text","498972ec":"X_train = train.copy()\nX_train[\"text\"] = [str(x) for x in X_train[\"text\"]]\nX_train[\"selected_text\"] = [str(x) for x in X_train[\"selected_text\"]]","009d6d79":"%%time\nwith multiprocessing.Pool(processes=3) as pool:\n    selected_train_list = pool.map(normalize, X_train.selected_text.tolist())\n    train_list = pool.map(normalize, X_train.text.tolist())\n    test_list = pool.map(normalize, test.text.tolist())","46cf9ba1":"X_train['preprocessed_selected_text'] = selected_train_list\nX_train['preprocessed_text'] = train_list\ntest['preprocessed_text'] = test_list","809d6c2b":"import pickle\nwith open('train.pickle', 'wb') as file:\n    pickle.dump(X_train, file, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('test.pickle', 'wb') as file:\n    pickle.dump(test, file, protocol=pickle.HIGHEST_PROTOCOL)","3c52e90c":"### Target Plots","0dccc7a0":"## Preprocessing","c976af49":"No missing values here either.","b1883c15":"Let's save this data for easier acess in the future.","71971731":"## Imports","b45257f7":"***Do upvote if you find this useful. More to come.***","ebb7f1b3":"Let's do some very basic feature engineering","9c7918ef":"No missing values here.","5fe5fdc9":"**NOTE**: Need to remove links from the analysis.","3be8c278":"Good to see `oprah` there haha.","4aa25068":"Well, clearly there are no emojis in these tweets. This simplifies the preprocessing process a bit.","43d824be":"### Emoji analysis","254b9be5":"Wonder how `http` and `Julie` made the cut.","345fb0be":"## Understanding data","07c507f7":"Good to see that the data isn't too skewed to any one class.","25c16bbe":"### Wordclouds"}}