{"cell_type":{"bcb27b81":"code","aaf5fd22":"code","fb48b4f1":"code","ceacf77c":"code","1b770b4c":"code","c1b8a976":"code","02c0e4f0":"code","782e95ae":"code","442cd8b7":"code","01693c23":"code","39ed992c":"code","7f5d45b8":"code","803037ad":"code","9f699441":"code","002241f1":"code","4f5b9574":"code","935aed96":"code","85a9ef94":"code","88e773d6":"code","1fbde0f5":"code","c486037b":"code","56441d4f":"code","976cd9e3":"code","05b7974f":"code","2de004ae":"code","e3910558":"code","2f5aa4a6":"code","8bf45784":"code","bbffc73e":"code","cb5af7e1":"code","e1063cbf":"code","24c34125":"code","8c913cac":"code","2e58f008":"code","58a08e9c":"code","048287cf":"code","876f40d3":"code","a4329dd3":"code","82ee5f9f":"code","72fb26a8":"code","2fc02d3c":"code","de4f8467":"code","49775cd8":"code","d6a8e24b":"markdown","fdfaefad":"markdown","2ead6c43":"markdown","4ee37c28":"markdown","da5ec33e":"markdown","ff09529d":"markdown","d56b1d19":"markdown","a591c153":"markdown","d45ef8ef":"markdown","f405371c":"markdown","90625331":"markdown","6cac49b4":"markdown","33bbdaf6":"markdown","81cef4ce":"markdown","39a6cafc":"markdown","164f3674":"markdown","25fb07b4":"markdown","c9b00236":"markdown","ea5b73dc":"markdown","0aebd854":"markdown","c97a1647":"markdown","82c38657":"markdown","3c825c8e":"markdown","37424797":"markdown","fca2d272":"markdown","83e02ea6":"markdown","1e016d3d":"markdown","bd9d2881":"markdown","9b096c8a":"markdown","ef3d96da":"markdown"},"source":{"bcb27b81":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_rows',None)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aaf5fd22":"df = pd.read_csv(\"..\/input\/car-dataset\/Cars Data.csv\")\ndf.head(5)","fb48b4f1":"df.tail()","ceacf77c":"df.dtypes","1b770b4c":"df.shape","c1b8a976":"df.info()","02c0e4f0":"df.columns","782e95ae":"df.index","442cd8b7":"df.style.hide_index()","01693c23":"## Here we will check the percentage of nan values present in each feature\n## 1 -step make the list of features which has missing values\nfeatures_with_na=[features for features in df.columns if df[features].isnull().sum()>1]\n\n## 2- step print the feature name and the percentage of missing values\nfor feature in features_with_na:\n    print(feature, np.round(df[feature].isnull().mean(), 4),  ' % missing values')","39ed992c":"# Remove two columns\ndf.drop(['Unnamed: 16', 'Unnamed: 15'], axis = 1,inplace =True)\ndf.head(10)","7f5d45b8":"# list of numerical variables\nnumerical_features = [feature for feature in df.columns if df[feature].dtypes != 'O']\n\nprint('Number of numerical variables: ', len(numerical_features))\n\n# visualise the numerical variables\ndf[numerical_features].head()","803037ad":"## Numerical variables are usually of 2 type\n#Continous variable and Discrete Variables\n\ndiscrete_feature=[feature for feature in numerical_features if len(df[feature].unique())<25]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","9f699441":"print(discrete_feature)","002241f1":"df[discrete_feature].head()","4f5b9574":"for feature in discrete_feature:\n    print('The feature is {} and number of discrete_feature are {}'.format(feature,len(df[feature].unique())))","935aed96":"plt.figure(figsize=(10, 7))\nsns.countplot(x=\"Cylinders\", data=df, facecolor=(0.8 ,0.9, 0.7), linewidth=8,\n                  edgecolor=sns.color_palette(\"BuGn_r\",20)).set_title(\"Distribution of Cylinders\",fontsize= 24)\nsns.set_style(\"whitegrid\")\nplt.xlabel('Cylinders',fontsize= 15)\nplt.ylabel('Frequency of the Cylinders',fontsize= 15)","85a9ef94":"#Continuous Variable\ncontinuous_feature=[feature for feature in numerical_features if feature not in discrete_feature]\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))","88e773d6":"print(continuous_feature)","1fbde0f5":"df[continuous_feature].head()","c486037b":"for feature in continuous_feature:\n    print('The feature is {} and number of continuous_feature are {}'.format(feature,len(df[feature].unique())))","56441d4f":"for feature in continuous_feature:\n    data=df.copy()\n    data[feature].hist(bins=25,align='left', color='#cce6b3', edgecolor='green',\n              linewidth=3)\n    plt.xlabel(feature,fontsize= 15)\n    plt.ylabel(\"Count\",fontsize= 15)\n    plt.title(feature,fontsize= 20)\n    plt.show()","976cd9e3":"#Categorical Variables\ncategorical_features=[feature for feature in df.columns if df[feature].dtypes=='O']\ncategorical_features","05b7974f":"df[categorical_features].head()","2de004ae":"for feature in categorical_features:\n    print('The feature is {} and number of categories are {}'.format(feature,len(df[feature].unique())))","e3910558":"df[categorical_features].head()","2f5aa4a6":"plt.figure(figsize=(10, 7))\nsns.countplot(x=\"Origin\", data=df, facecolor=(0.8 ,0.9, 0.7), linewidth=4,\n                  edgecolor=sns.color_palette(\"BuGn_r\",20)).set_title(\"Distribution of Origin\",fontsize= 24)\nsns.set_style(\"whitegrid\")\nplt.xlabel('Origin',fontsize= 15)\nplt.ylabel('Frequency of the Origin',fontsize= 15)","8bf45784":"plt.figure(figsize=(10, 7))\nsns.countplot(x=\"Type\", data=df, facecolor=(0.8 ,0.9, 0.7), linewidth=4,\n                  edgecolor=sns.color_palette(\"BuGn_r\",20)).set_title(\"Distribution of Type\",fontsize= 24)\nsns.set_style(\"whitegrid\")\nplt.xlabel('Type',fontsize= 15)\nplt.ylabel('Frequency of the Type',fontsize= 15)","bbffc73e":"plt.figure(figsize=(10, 7))\nsns.countplot(x=\"DriveTrain\", data=df, facecolor=(0.8 ,0.9, 0.7), linewidth=4,\n                  edgecolor=sns.color_palette(\"BuGn_r\",20)).set_title(\"Distribution of DriveTrain\",fontsize= 24)\nsns.set_style(\"whitegrid\")\n\nplt.xlabel('DriveTrain',fontsize= 15)\nplt.ylabel('Frequency of the DriveTrain',fontsize= 15)","cb5af7e1":"#Check the duplicates\ndf[df.duplicated()] ","e1063cbf":"df.isnull().sum()","24c34125":"import seaborn as sns\nsns.heatmap(df.isnull(),cmap=\"YlGnBu\")","8c913cac":"df['Cylinders'] = df['Cylinders'].fillna(df['Cylinders'].mean())","2e58f008":"import seaborn as sns\nsns.heatmap(df.isnull())","58a08e9c":"df.head(2)","048287cf":"df['Make'].value_counts()","876f40d3":"df.head(2)","a4329dd3":"df[~(df[\"Weight\"]>4000)]","82ee5f9f":"df.head(2)","72fb26a8":"df[(df[\"Origin\"]==\"Asia\")|(df[\"Origin\"]==\"Europe\")]","2fc02d3c":"df.head(2)","de4f8467":"df[\"MPG_City\"]=df[\"MPG_City\"].apply(lambda x:x+3)","49775cd8":"df.head(2)","d6a8e24b":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:center;border-radius:10px 10px\">4.Show all the records where \"Origin\" is \"Asia\" or \"Europe\"?<\/p><\/h1><\/header> ","fdfaefad":"<header>\n<h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">OBSERVATIONS :-<\/p>\n    \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-From the plot we can clearly see that \"FRONT\" has top highest no. of frequency as per the dataset.<\/p>\n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"REAR\" is the second highest as per the dataset.<\/p> \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"ALL\" has least no. of frequency as per the dataset.<\/p><\/h1><\/header> ","2ead6c43":"<article>\n  <header><h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:130%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:7px;border-color:#000000;\">TABLE OF CONTENTS<\/p><\/h1><\/header>\n    \n[1. IMPORTING LIBRARIES](#1)\n    \n[2. LOADING DATA](#2)\n    \n[3. EXAMINE THE DATASET](#3)\n    \n[4. FINDING THE MISSING VALUE IF ANY?](#4)\n    \n[5. NUMERICAL VARIABLE ANALYSIS(Discrete and Continous Variable)](#5)\n    \n[6. CATEGORICAL VARIABLE ANALYSIS](#6)   \n    \n[7.CHECKING THE DUPLICATE RECORDS](#7)\n    \n[8.QUESTIONS ON THE DATASET](#8)\n    \n     \n","4ee37c28":"<header> <h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:80%;text-align:center;border-radius:10px 10px;border-style:dashed;border-width:4px;border-color:#000000;\">2.CONTINOUS VARIABLES<\/p><\/h1> <\/header> ","da5ec33e":"![](https:\/\/media3.giphy.com\/media\/QsaPruMLFHUt5AJM5M\/giphy.gif)","ff09529d":"<header><h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:90%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:5px;border-color:#000000;\">7.CHECKING THE DUPLICATE RECORDS<\/p><\/h1><\/header> ","d56b1d19":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:center;border-radius:10px 10px\">2.Check what are the different type of \"Make\" are there in our dataset.And,what is the count of each make in data?<\/p><\/h1><\/header> ","a591c153":"<header>\n<h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">In this project, I am working on a car dataset. Here I am trying some things new for instance whenever you do exploratory data analysis you need to focus on every variable one after the other. But here I have segregated Numerical(Continuous and Discrete) variables and categorical variables. After the segregation, I tried to understand the distribution of every variable and also gave observations below. After that, I tried to answer some of the analytical questions.<\/p><\/h1><\/header> ","d45ef8ef":"<article><header>\n<h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:center;border-radius:10px 10px\">3.Remove all the records(rows) where \"weight\"(column) is above 4000?<\/p><\/h1><\/header> ","f405371c":"<header><h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:90%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:5px;border-color:#000000;\">1.IMPORTING LIBRARIES<\/p><\/h1><\/header>","90625331":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:center;border-radius:10px 10px\">5.Increase all the values of \"MPG-City\" by \"3\"?<\/p><\/h1><\/header> ","6cac49b4":"<article>\n  <header>\n    <h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:90%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:5px;border-color:#000000;\">5.NUMERICAL VARIABLE ANALYSIS<\/p><\/h1>\n  <\/header> ","33bbdaf6":"<article>\n  <header>\n    <h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:90%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:5px;border-color:#000000;\">4.FINDING THE MISSING VALUE IF ANY?<\/p><\/h1>\n  <\/header>","81cef4ce":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:center;border-radius:10px 10px\">1.Find all the null value in the dataset.If there is any value in any column then fill it with the mean of that column?<\/p><\/h1><\/header> ","39a6cafc":"<header><h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:90%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:5px;border-color:#000000;\">3.EXAMINE THE DATASET<\/p><\/h1><\/header>","164f3674":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">OBSERVATIONS :-<\/p>\n    \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-We have 428 rows and 17 columns in the dataset.<\/p>\n<\/h1><\/header> ","25fb07b4":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">OBSERVATIONS :-<\/p>\n    \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-Both \"Unnamed: 15\" and \"Unnamed: 16\" variables has only NAN values.Which we can drop immediately.<\/p><\/h1><\/header> ","c9b00236":"\n  <header>\n    <h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:130%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:7px;border-color:#000000;\">ABOUT THE DATASET<\/p><\/h1><\/header>\n    \n* Make\n* Model\n* Type\n* Origin\n* DriveTrain\n* MSRP\n* Invoice\n* EngineSize\n* Cylinders\n* Horsepower\n* MPG_City\n* MPG_Highway\n* Weight\n* Wheelbase\n* Length\n     \n     \n     ","ea5b73dc":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">OBSERVATIONS :-<\/p>\n    <p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-From the plot we can clearly see that \"6.0\" has top highest no. of frequency as per the dataset.<\/p>\n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"4.0\" is the second highest as per the dataset.<\/p>    \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"3.0\", \"5.807511\", \"12.0\" and \"10.0\" has least no. of frequency as per the dataset.<\/p><\/h1><\/header> ","0aebd854":"<header><h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:90%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:5px;border-color:#000000;\">6.CATEGORICAL VARIABLE ANALYSIS<\/p><\/h1><\/header> ","c97a1647":"<article>\n  <header>\n    <h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:80%;text-align:center;border-radius:10px 10px;border-style:dashed;border-width:4px;border-color:#000000;\">1.DISCRETE VARIABLES<\/p><\/h1>\n  <\/header> ","82c38657":"<header>\n    <h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:130%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:7px;border-color:#000000;\">INTRODUCTION<\/p><\/h1>\n<\/header>","3c825c8e":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">OBSERVATIONS :-<\/p>\n    \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-From the plot we can clearly see that \"SEDAN\" has top highest no. of frequency as per the dataset.<\/p>\n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"SUV\" and \"SPORTS\" is the second highest as per the dataset.<\/p> \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"WAGON\",\"TRUCK\" has almost same no. of frequency as per the dataset.<\/p>\n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"HYBRID\" has least no. of frequency as per the dataset.<\/p><\/h1><\/header> ","37424797":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">OBSERVATIONS :-<\/p>\n    <p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-There are \"7\" Objects in the dataset.<\/p>\n     <p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-There are \"4\" Float64 in the dataset.<\/p>    \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-There are \"6\" Int64 in the dataset.<\/p><\/h1><\/header> ","fca2d272":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">OBSERVATIONS :-<\/p>\n    <p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-From the plot we can clearly see that \"ASIA\" has top highest no. of frequency as per the dataset.<\/p>\n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"USA\" is the second highest as per the dataset.<\/p>    \n<p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-\"EUROPE\" has least no. of frequency as per the dataset.<\/p><\/h1><\/header> ","83e02ea6":"<header>\n    <h1><p style= \"background-color:#127c39;font-family:Georgia;color:#ffffff;font-size:170%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:7px;border-color:#000000;\"> WELCOME TO CAR ANALYSIS<\/p><\/h1>\n  <\/header>","1e016d3d":"<header><h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:90%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:5px;border-color:#000000;\">2.LOADING DATA<\/p><\/h1><\/header>","bd9d2881":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:left;border-radius:10px 10px\">OBSERVATIONS :-<\/p>\n    <p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:50%;text-align:left;border-radius:10px 10px\">-We have overall 10 Numerical variables in the dataset.<\/p>\n    <\/h1><\/header> ","9b096c8a":"<header><h1><p style= \"background-color:#ffffff;font-family:Georgia;color:#127c30;font-size:70%;text-align:center;border-radius:10px 10px\">Thank you for reading, I hope you enjoy it. If you find any mistakes and have any critics, please let me know.\nAlso, don't forget to VOTE UP\ud83d\ude0a.<\/p><\/h1><\/header> ","ef3d96da":"<header><h1><p style= \"background-color:#127c39;font-family:Georgia;color:#FFFFFF;font-size:90%;text-align:center;border-radius:10px 10px;border-style:solid;border-width:5px;border-color:#000000;\">8.QUESTIONS ON THE DATASET<\/p><\/h1><\/header> \n    \n"}}